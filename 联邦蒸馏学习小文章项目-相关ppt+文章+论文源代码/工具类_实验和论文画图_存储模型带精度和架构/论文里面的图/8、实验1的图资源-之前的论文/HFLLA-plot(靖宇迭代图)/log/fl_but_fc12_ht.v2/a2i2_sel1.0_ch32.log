#clients of iccad2012: 2
#clients of asml1: 2
select ratio: 1.0
Total num clients: 4
client model path: ['models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0', 'models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1', 'models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0', 'models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Resampled dataset to size (32814, 144, 32)
Using transform option: train
#pos = 17102, #neg = 15712
Allocated dataset with size (24958, 144, 32)
Resampled dataset to size (32737, 144, 32)
Using transform option: train
#pos = 17179, #neg = 15558
loading data into the main memory...
Allocated dataset with size (9150, 144, 32)
Resampled dataset to size (16703, 144, 32)
Using transform option: train
#pos = 8134, #neg = 8569
Allocated dataset with size (9150, 144, 32)
Resampled dataset to size (16626, 144, 32)
Using transform option: train
#pos = 8099, #neg = 8527
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 32)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.45554 | Reg=0.00359 | acc=0.4219 | L2-Norm=18.953 | L2-Norm(final)=2.033 | 1284.1 samples/s | 20.1 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.32352 | Reg=0.00344 | acc=0.7031 | L2-Norm=18.555 | L2-Norm(final)=2.019 | 5412.6 samples/s | 84.6 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.30740 | Reg=0.00337 | acc=0.7344 | L2-Norm=18.364 | L2-Norm(final)=2.027 | 5477.5 samples/s | 85.6 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.30012 | Reg=0.00333 | acc=0.7188 | L2-Norm=18.254 | L2-Norm(final)=2.039 | 5528.9 samples/s | 86.4 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.29674 | Reg=0.00331 | acc=0.7031 | L2-Norm=18.189 | L2-Norm(final)=2.051 | 5565.8 samples/s | 87.0 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.29033 | Reg=0.00329 | acc=0.7500 | L2-Norm=18.146 | L2-Norm(final)=2.060 | 5625.8 samples/s | 87.9 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.28920 | Reg=0.00328 | acc=0.6094 | L2-Norm=18.119 | L2-Norm(final)=2.070 | 5371.3 samples/s | 83.9 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.28700 | Reg=0.00328 | acc=0.6250 | L2-Norm=18.104 | L2-Norm(final)=2.079 | 5535.2 samples/s | 86.5 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.28462 | Reg=0.00328 | acc=0.6562 | L2-Norm=18.097 | L2-Norm(final)=2.087 | 5419.1 samples/s | 84.7 steps/s
[Step= 450 Epoch= 0.9] | Loss=0.28107 | Reg=0.00327 | acc=0.7500 | L2-Norm=18.094 | L2-Norm(final)=2.097 | 5626.8 samples/s | 87.9 steps/s
[Step= 500 Epoch= 1.0] | Loss=0.27888 | Reg=0.00327 | acc=0.7812 | L2-Norm=18.095 | L2-Norm(final)=2.109 | 7341.5 samples/s | 114.7 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.0] | Loss=0.26839 | Reg=0.00329 | acc=0.7188 | L2-Norm=18.133 | L2-Norm(final)=2.224 | 6059.1 samples/s | 94.7 steps/s
[Step= 550 Epoch= 1.1] | Loss=0.24782 | Reg=0.00329 | acc=0.8750 | L2-Norm=18.133 | L2-Norm(final)=2.225 | 4279.1 samples/s | 66.9 steps/s
[Step= 600 Epoch= 1.2] | Loss=0.22026 | Reg=0.00330 | acc=0.7812 | L2-Norm=18.152 | L2-Norm(final)=2.235 | 4425.6 samples/s | 69.2 steps/s
[Step= 650 Epoch= 1.3] | Loss=0.20029 | Reg=0.00330 | acc=0.8750 | L2-Norm=18.171 | L2-Norm(final)=2.246 | 4447.7 samples/s | 69.5 steps/s
[Step= 700 Epoch= 1.4] | Loss=0.18528 | Reg=0.00331 | acc=0.8906 | L2-Norm=18.186 | L2-Norm(final)=2.253 | 4459.9 samples/s | 69.7 steps/s
[Step= 750 Epoch= 1.5] | Loss=0.17312 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.200 | L2-Norm(final)=2.262 | 4632.3 samples/s | 72.4 steps/s
[Step= 800 Epoch= 1.6] | Loss=0.16418 | Reg=0.00332 | acc=0.8594 | L2-Norm=18.213 | L2-Norm(final)=2.268 | 4265.2 samples/s | 66.6 steps/s
[Step= 850 Epoch= 1.7] | Loss=0.15836 | Reg=0.00332 | acc=0.9062 | L2-Norm=18.225 | L2-Norm(final)=2.274 | 4566.8 samples/s | 71.4 steps/s
[Step= 900 Epoch= 1.8] | Loss=0.15195 | Reg=0.00333 | acc=0.8594 | L2-Norm=18.239 | L2-Norm(final)=2.280 | 4451.5 samples/s | 69.6 steps/s
[Step= 950 Epoch= 1.9] | Loss=0.14722 | Reg=0.00333 | acc=0.9219 | L2-Norm=18.252 | L2-Norm(final)=2.286 | 4402.1 samples/s | 68.8 steps/s
[Step=1000 Epoch= 2.0] | Loss=0.14242 | Reg=0.00334 | acc=0.9375 | L2-Norm=18.264 | L2-Norm(final)=2.291 | 5789.6 samples/s | 90.5 steps/s
[Step=1050 Epoch= 2.0] | Loss=0.13683 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.276 | L2-Norm(final)=2.296 | 2442.4 samples/s | 38.2 steps/s
[Step=1100 Epoch= 2.1] | Loss=0.13176 | Reg=0.00335 | acc=0.9531 | L2-Norm=18.289 | L2-Norm(final)=2.301 | 4409.0 samples/s | 68.9 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.12704 | Reg=0.00335 | acc=0.9219 | L2-Norm=18.301 | L2-Norm(final)=2.306 | 4461.3 samples/s | 69.7 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.12317 | Reg=0.00335 | acc=0.9375 | L2-Norm=18.312 | L2-Norm(final)=2.311 | 4410.8 samples/s | 68.9 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.11946 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.323 | L2-Norm(final)=2.315 | 4413.0 samples/s | 69.0 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.11696 | Reg=0.00336 | acc=0.9219 | L2-Norm=18.333 | L2-Norm(final)=2.320 | 4466.2 samples/s | 69.8 steps/s
[Step=1350 Epoch= 2.6] | Loss=0.11443 | Reg=0.00337 | acc=0.8906 | L2-Norm=18.344 | L2-Norm(final)=2.324 | 4559.5 samples/s | 71.2 steps/s
[Step=1400 Epoch= 2.7] | Loss=0.11199 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.354 | L2-Norm(final)=2.327 | 4420.1 samples/s | 69.1 steps/s
[Step=1450 Epoch= 2.8] | Loss=0.11009 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.363 | L2-Norm(final)=2.330 | 4486.1 samples/s | 70.1 steps/s
[Step=1500 Epoch= 2.9] | Loss=0.10793 | Reg=0.00338 | acc=0.9219 | L2-Norm=18.371 | L2-Norm(final)=2.333 | 4834.1 samples/s | 75.5 steps/s
[Step=1550 Epoch= 3.0] | Loss=0.10580 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.380 | L2-Norm(final)=2.336 | 2637.1 samples/s | 41.2 steps/s
[Step=1600 Epoch= 3.1] | Loss=0.10360 | Reg=0.00338 | acc=1.0000 | L2-Norm=18.390 | L2-Norm(final)=2.339 | 4401.4 samples/s | 68.8 steps/s
[Step=1650 Epoch= 3.2] | Loss=0.10129 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.401 | L2-Norm(final)=2.343 | 4515.6 samples/s | 70.6 steps/s
[Step=1700 Epoch= 3.3] | Loss=0.09908 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.411 | L2-Norm(final)=2.346 | 4487.1 samples/s | 70.1 steps/s
[Step=1750 Epoch= 3.4] | Loss=0.09733 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.421 | L2-Norm(final)=2.349 | 4447.7 samples/s | 69.5 steps/s
[Step=1800 Epoch= 3.5] | Loss=0.09564 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.431 | L2-Norm(final)=2.352 | 4513.0 samples/s | 70.5 steps/s
[Step=1850 Epoch= 3.6] | Loss=0.09428 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.441 | L2-Norm(final)=2.354 | 4424.5 samples/s | 69.1 steps/s
[Step=1900 Epoch= 3.7] | Loss=0.09298 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.450 | L2-Norm(final)=2.357 | 4415.1 samples/s | 69.0 steps/s
[Step=1950 Epoch= 3.8] | Loss=0.09141 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.459 | L2-Norm(final)=2.359 | 4672.9 samples/s | 73.0 steps/s
[Step=2000 Epoch= 3.9] | Loss=0.09029 | Reg=0.00341 | acc=0.9531 | L2-Norm=18.467 | L2-Norm(final)=2.362 | 4388.6 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step2000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.35655 | Reg=0.00356 | acc=0.5312 | L2-Norm=18.878 | L2-Norm(final)=2.002 | 6695.6 samples/s | 104.6 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.32512 | Reg=0.00334 | acc=0.6875 | L2-Norm=18.287 | L2-Norm(final)=1.987 | 4848.5 samples/s | 75.8 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.31204 | Reg=0.00324 | acc=0.7344 | L2-Norm=18.009 | L2-Norm(final)=1.991 | 5345.5 samples/s | 83.5 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.30158 | Reg=0.00319 | acc=0.7188 | L2-Norm=17.861 | L2-Norm(final)=2.004 | 5463.3 samples/s | 85.4 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.29675 | Reg=0.00316 | acc=0.7969 | L2-Norm=17.777 | L2-Norm(final)=2.017 | 5466.6 samples/s | 85.4 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.29258 | Reg=0.00314 | acc=0.6875 | L2-Norm=17.728 | L2-Norm(final)=2.031 | 5500.2 samples/s | 85.9 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.28897 | Reg=0.00313 | acc=0.7969 | L2-Norm=17.698 | L2-Norm(final)=2.043 | 5510.1 samples/s | 86.1 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.28633 | Reg=0.00313 | acc=0.7812 | L2-Norm=17.678 | L2-Norm(final)=2.055 | 5492.2 samples/s | 85.8 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.28329 | Reg=0.00312 | acc=0.7500 | L2-Norm=17.664 | L2-Norm(final)=2.066 | 5418.5 samples/s | 84.7 steps/s
[Step= 450 Epoch= 0.9] | Loss=0.28065 | Reg=0.00312 | acc=0.8125 | L2-Norm=17.656 | L2-Norm(final)=2.079 | 5438.8 samples/s | 85.0 steps/s
[Step= 500 Epoch= 1.0] | Loss=0.27846 | Reg=0.00312 | acc=0.7188 | L2-Norm=17.654 | L2-Norm(final)=2.093 | 7739.8 samples/s | 120.9 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.0] | Loss=0.17437 | Reg=0.00312 | acc=0.8438 | L2-Norm=17.655 | L2-Norm(final)=2.229 | 6422.8 samples/s | 100.4 steps/s
[Step= 550 Epoch= 1.1] | Loss=0.25575 | Reg=0.00312 | acc=0.7812 | L2-Norm=17.668 | L2-Norm(final)=2.215 | 4030.7 samples/s | 63.0 steps/s
[Step= 600 Epoch= 1.2] | Loss=0.22106 | Reg=0.00314 | acc=0.8281 | L2-Norm=17.709 | L2-Norm(final)=2.223 | 4512.2 samples/s | 70.5 steps/s
[Step= 650 Epoch= 1.3] | Loss=0.20137 | Reg=0.00315 | acc=0.9062 | L2-Norm=17.738 | L2-Norm(final)=2.229 | 4533.8 samples/s | 70.8 steps/s
[Step= 700 Epoch= 1.4] | Loss=0.19075 | Reg=0.00315 | acc=0.9062 | L2-Norm=17.758 | L2-Norm(final)=2.232 | 4383.4 samples/s | 68.5 steps/s
[Step= 750 Epoch= 1.5] | Loss=0.17948 | Reg=0.00316 | acc=0.8906 | L2-Norm=17.777 | L2-Norm(final)=2.237 | 4555.6 samples/s | 71.2 steps/s
[Step= 800 Epoch= 1.6] | Loss=0.17155 | Reg=0.00317 | acc=0.9062 | L2-Norm=17.793 | L2-Norm(final)=2.242 | 4473.3 samples/s | 69.9 steps/s
[Step= 850 Epoch= 1.7] | Loss=0.16442 | Reg=0.00317 | acc=0.9219 | L2-Norm=17.807 | L2-Norm(final)=2.247 | 4339.1 samples/s | 67.8 steps/s
[Step= 900 Epoch= 1.8] | Loss=0.15858 | Reg=0.00318 | acc=0.9688 | L2-Norm=17.823 | L2-Norm(final)=2.252 | 4479.8 samples/s | 70.0 steps/s
[Step= 950 Epoch= 1.9] | Loss=0.15176 | Reg=0.00318 | acc=0.9375 | L2-Norm=17.838 | L2-Norm(final)=2.257 | 4481.3 samples/s | 70.0 steps/s
[Step=1000 Epoch= 2.0] | Loss=0.14706 | Reg=0.00319 | acc=0.9688 | L2-Norm=17.850 | L2-Norm(final)=2.262 | 5925.1 samples/s | 92.6 steps/s
[Step=1050 Epoch= 2.1] | Loss=0.14176 | Reg=0.00319 | acc=0.9062 | L2-Norm=17.862 | L2-Norm(final)=2.266 | 2403.2 samples/s | 37.6 steps/s
[Step=1100 Epoch= 2.2] | Loss=0.13654 | Reg=0.00319 | acc=0.9375 | L2-Norm=17.873 | L2-Norm(final)=2.270 | 4470.0 samples/s | 69.8 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.13194 | Reg=0.00320 | acc=0.9375 | L2-Norm=17.885 | L2-Norm(final)=2.275 | 4580.6 samples/s | 71.6 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.12812 | Reg=0.00320 | acc=0.9375 | L2-Norm=17.898 | L2-Norm(final)=2.279 | 4398.1 samples/s | 68.7 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.12452 | Reg=0.00321 | acc=0.9531 | L2-Norm=17.910 | L2-Norm(final)=2.283 | 4418.4 samples/s | 69.0 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.12181 | Reg=0.00321 | acc=0.9062 | L2-Norm=17.923 | L2-Norm(final)=2.286 | 4395.9 samples/s | 68.7 steps/s
[Step=1350 Epoch= 2.6] | Loss=0.11869 | Reg=0.00322 | acc=0.9688 | L2-Norm=17.935 | L2-Norm(final)=2.290 | 4409.4 samples/s | 68.9 steps/s
[Step=1400 Epoch= 2.7] | Loss=0.11632 | Reg=0.00322 | acc=0.9688 | L2-Norm=17.947 | L2-Norm(final)=2.293 | 4508.1 samples/s | 70.4 steps/s
[Step=1450 Epoch= 2.8] | Loss=0.11403 | Reg=0.00323 | acc=0.9375 | L2-Norm=17.959 | L2-Norm(final)=2.297 | 4463.8 samples/s | 69.7 steps/s
[Step=1500 Epoch= 2.9] | Loss=0.11247 | Reg=0.00323 | acc=0.9062 | L2-Norm=17.970 | L2-Norm(final)=2.299 | 4867.1 samples/s | 76.0 steps/s
[Step=1550 Epoch= 3.0] | Loss=0.11007 | Reg=0.00323 | acc=0.9375 | L2-Norm=17.982 | L2-Norm(final)=2.302 | 2612.7 samples/s | 40.8 steps/s
[Step=1600 Epoch= 3.1] | Loss=0.10741 | Reg=0.00324 | acc=0.9844 | L2-Norm=17.995 | L2-Norm(final)=2.306 | 4454.0 samples/s | 69.6 steps/s
[Step=1650 Epoch= 3.2] | Loss=0.10511 | Reg=0.00324 | acc=0.9531 | L2-Norm=18.007 | L2-Norm(final)=2.309 | 4380.2 samples/s | 68.4 steps/s
[Step=1700 Epoch= 3.3] | Loss=0.10310 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.019 | L2-Norm(final)=2.312 | 4472.8 samples/s | 69.9 steps/s
[Step=1750 Epoch= 3.4] | Loss=0.10112 | Reg=0.00325 | acc=0.8906 | L2-Norm=18.030 | L2-Norm(final)=2.316 | 4533.5 samples/s | 70.8 steps/s
[Step=1800 Epoch= 3.5] | Loss=0.09955 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.041 | L2-Norm(final)=2.318 | 4413.4 samples/s | 69.0 steps/s
[Step=1850 Epoch= 3.6] | Loss=0.09809 | Reg=0.00326 | acc=0.9688 | L2-Norm=18.051 | L2-Norm(final)=2.321 | 4450.9 samples/s | 69.5 steps/s
[Step=1900 Epoch= 3.7] | Loss=0.09647 | Reg=0.00326 | acc=0.9531 | L2-Norm=18.063 | L2-Norm(final)=2.324 | 4474.3 samples/s | 69.9 steps/s
[Step=1950 Epoch= 3.8] | Loss=0.09553 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.074 | L2-Norm(final)=2.327 | 4412.0 samples/s | 68.9 steps/s
[Step=2000 Epoch= 3.9] | Loss=0.09403 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.086 | L2-Norm(final)=2.329 | 4479.4 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step2000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.32400 | Reg=0.00176 | acc=0.4688 | L2-Norm=13.276 | L2-Norm(final)=1.871 | 7108.7 samples/s | 111.1 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.27103 | Reg=0.00170 | acc=0.8281 | L2-Norm=13.026 | L2-Norm(final)=1.882 | 4195.6 samples/s | 65.6 steps/s
[Step= 100 Epoch= 0.4] | Loss=0.22994 | Reg=0.00168 | acc=0.9375 | L2-Norm=12.955 | L2-Norm(final)=1.919 | 5039.1 samples/s | 78.7 steps/s
[Step= 150 Epoch= 0.6] | Loss=0.20500 | Reg=0.00168 | acc=0.8750 | L2-Norm=12.949 | L2-Norm(final)=1.962 | 5110.5 samples/s | 79.9 steps/s
[Step= 200 Epoch= 0.8] | Loss=0.18926 | Reg=0.00168 | acc=0.9219 | L2-Norm=12.959 | L2-Norm(final)=1.996 | 5069.4 samples/s | 79.2 steps/s
[Step= 250 Epoch= 1.0] | Loss=0.17485 | Reg=0.00168 | acc=0.9531 | L2-Norm=12.976 | L2-Norm(final)=2.027 | 7345.8 samples/s | 114.8 steps/s
[Step= 300 Epoch= 1.1] | Loss=0.16563 | Reg=0.00169 | acc=0.9062 | L2-Norm=12.998 | L2-Norm(final)=2.055 | 2513.4 samples/s | 39.3 steps/s
[Step= 350 Epoch= 1.3] | Loss=0.15774 | Reg=0.00170 | acc=0.9375 | L2-Norm=13.021 | L2-Norm(final)=2.080 | 5132.6 samples/s | 80.2 steps/s
[Step= 400 Epoch= 1.5] | Loss=0.15102 | Reg=0.00170 | acc=0.9688 | L2-Norm=13.043 | L2-Norm(final)=2.104 | 5166.5 samples/s | 80.7 steps/s
[Step= 450 Epoch= 1.7] | Loss=0.14524 | Reg=0.00171 | acc=0.9531 | L2-Norm=13.066 | L2-Norm(final)=2.125 | 5037.8 samples/s | 78.7 steps/s
[Step= 500 Epoch= 1.9] | Loss=0.14063 | Reg=0.00171 | acc=0.9531 | L2-Norm=13.088 | L2-Norm(final)=2.145 | 6034.1 samples/s | 94.3 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.9] | Loss=0.05721 | Reg=0.00177 | acc=0.9531 | L2-Norm=13.308 | L2-Norm(final)=2.341 | 5827.1 samples/s | 91.0 steps/s
[Step= 550 Epoch= 2.1] | Loss=0.10517 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.286 | L2-Norm(final)=2.333 | 3966.0 samples/s | 62.0 steps/s
[Step= 600 Epoch= 2.3] | Loss=0.07256 | Reg=0.00177 | acc=0.9688 | L2-Norm=13.314 | L2-Norm(final)=2.343 | 4197.1 samples/s | 65.6 steps/s
[Step= 650 Epoch= 2.5] | Loss=0.05579 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.344 | L2-Norm(final)=2.351 | 4268.5 samples/s | 66.7 steps/s
[Step= 700 Epoch= 2.7] | Loss=0.04541 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.367 | L2-Norm(final)=2.358 | 4216.4 samples/s | 65.9 steps/s
[Step= 750 Epoch= 2.9] | Loss=0.03835 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.385 | L2-Norm(final)=2.365 | 5725.7 samples/s | 89.5 steps/s
[Step= 800 Epoch= 3.1] | Loss=0.03300 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.400 | L2-Norm(final)=2.370 | 2274.9 samples/s | 35.5 steps/s
[Step= 850 Epoch= 3.3] | Loss=0.02851 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.414 | L2-Norm(final)=2.375 | 4321.7 samples/s | 67.5 steps/s
[Step= 900 Epoch= 3.4] | Loss=0.02503 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.423 | L2-Norm(final)=2.379 | 4247.4 samples/s | 66.4 steps/s
[Step= 950 Epoch= 3.6] | Loss=0.02237 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.430 | L2-Norm(final)=2.383 | 4158.7 samples/s | 65.0 steps/s
[Step=1000 Epoch= 3.8] | Loss=0.02025 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.435 | L2-Norm(final)=2.386 | 4823.7 samples/s | 75.4 steps/s
[Step=1050 Epoch= 4.0] | Loss=0.01847 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.438 | L2-Norm(final)=2.389 | 2464.0 samples/s | 38.5 steps/s
[Step=1100 Epoch= 4.2] | Loss=0.01694 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.439 | L2-Norm(final)=2.392 | 4334.3 samples/s | 67.7 steps/s
[Step=1150 Epoch= 4.4] | Loss=0.01566 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.438 | L2-Norm(final)=2.395 | 4165.4 samples/s | 65.1 steps/s
[Step=1200 Epoch= 4.6] | Loss=0.01455 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.436 | L2-Norm(final)=2.397 | 4236.5 samples/s | 66.2 steps/s
[Step=1250 Epoch= 4.8] | Loss=0.01359 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.433 | L2-Norm(final)=2.399 | 4224.3 samples/s | 66.0 steps/s
[Step=1300 Epoch= 5.0] | Loss=0.01274 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.429 | L2-Norm(final)=2.401 | 2671.6 samples/s | 41.7 steps/s
[Step=1350 Epoch= 5.2] | Loss=0.01200 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.425 | L2-Norm(final)=2.402 | 4206.1 samples/s | 65.7 steps/s
[Step=1400 Epoch= 5.4] | Loss=0.01134 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.419 | L2-Norm(final)=2.404 | 4212.9 samples/s | 65.8 steps/s
[Step=1450 Epoch= 5.6] | Loss=0.01074 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.413 | L2-Norm(final)=2.405 | 4266.5 samples/s | 66.7 steps/s
[Step=1500 Epoch= 5.7] | Loss=0.01021 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.406 | L2-Norm(final)=2.406 | 4216.9 samples/s | 65.9 steps/s
[Step=1550 Epoch= 5.9] | Loss=0.00972 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.398 | L2-Norm(final)=2.408 | 2652.9 samples/s | 41.5 steps/s
[Step=1600 Epoch= 6.1] | Loss=0.00928 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.391 | L2-Norm(final)=2.409 | 4223.0 samples/s | 66.0 steps/s
[Step=1650 Epoch= 6.3] | Loss=0.00888 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.382 | L2-Norm(final)=2.410 | 4231.0 samples/s | 66.1 steps/s
[Step=1700 Epoch= 6.5] | Loss=0.00851 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.374 | L2-Norm(final)=2.411 | 4244.8 samples/s | 66.3 steps/s
[Step=1750 Epoch= 6.7] | Loss=0.00818 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.365 | L2-Norm(final)=2.412 | 4227.6 samples/s | 66.1 steps/s
[Step=1800 Epoch= 6.9] | Loss=0.00786 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=2.413 | 6324.3 samples/s | 98.8 steps/s
[Step=1850 Epoch= 7.1] | Loss=0.00757 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.346 | L2-Norm(final)=2.413 | 2212.6 samples/s | 34.6 steps/s
[Step=1900 Epoch= 7.3] | Loss=0.00730 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.336 | L2-Norm(final)=2.414 | 4217.2 samples/s | 65.9 steps/s
[Step=1950 Epoch= 7.5] | Loss=0.00705 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.326 | L2-Norm(final)=2.415 | 4226.4 samples/s | 66.0 steps/s
[Step=2000 Epoch= 7.7] | Loss=0.00682 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.315 | L2-Norm(final)=2.416 | 4219.5 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step2000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.31420 | Reg=0.00175 | acc=0.5156 | L2-Norm=13.236 | L2-Norm(final)=1.910 | 5774.1 samples/s | 90.2 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.25630 | Reg=0.00172 | acc=0.9062 | L2-Norm=13.114 | L2-Norm(final)=1.936 | 4677.6 samples/s | 73.1 steps/s
[Step= 100 Epoch= 0.4] | Loss=0.22589 | Reg=0.00172 | acc=0.9062 | L2-Norm=13.131 | L2-Norm(final)=1.977 | 5217.7 samples/s | 81.5 steps/s
[Step= 150 Epoch= 0.6] | Loss=0.20161 | Reg=0.00173 | acc=0.8750 | L2-Norm=13.168 | L2-Norm(final)=2.011 | 5090.3 samples/s | 79.5 steps/s
[Step= 200 Epoch= 0.8] | Loss=0.18537 | Reg=0.00175 | acc=0.8906 | L2-Norm=13.214 | L2-Norm(final)=2.042 | 5165.3 samples/s | 80.7 steps/s
[Step= 250 Epoch= 1.0] | Loss=0.17186 | Reg=0.00176 | acc=0.8594 | L2-Norm=13.260 | L2-Norm(final)=2.071 | 7546.5 samples/s | 117.9 steps/s
[Step= 300 Epoch= 1.2] | Loss=0.16107 | Reg=0.00177 | acc=0.9062 | L2-Norm=13.306 | L2-Norm(final)=2.098 | 2606.7 samples/s | 40.7 steps/s
[Step= 350 Epoch= 1.3] | Loss=0.15443 | Reg=0.00178 | acc=0.9219 | L2-Norm=13.352 | L2-Norm(final)=2.123 | 4800.6 samples/s | 75.0 steps/s
[Step= 400 Epoch= 1.5] | Loss=0.14792 | Reg=0.00179 | acc=0.9531 | L2-Norm=13.394 | L2-Norm(final)=2.146 | 5227.6 samples/s | 81.7 steps/s
[Step= 450 Epoch= 1.7] | Loss=0.14235 | Reg=0.00181 | acc=0.9688 | L2-Norm=13.434 | L2-Norm(final)=2.168 | 5008.8 samples/s | 78.3 steps/s
[Step= 500 Epoch= 1.9] | Loss=0.13822 | Reg=0.00182 | acc=0.9219 | L2-Norm=13.472 | L2-Norm(final)=2.189 | 6296.7 samples/s | 98.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.9] | Loss=0.06948 | Reg=0.00191 | acc=0.9375 | L2-Norm=13.833 | L2-Norm(final)=2.388 | 5950.8 samples/s | 93.0 steps/s
[Step= 550 Epoch= 2.1] | Loss=0.07249 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.865 | L2-Norm(final)=2.400 | 3985.1 samples/s | 62.3 steps/s
[Step= 600 Epoch= 2.3] | Loss=0.05237 | Reg=0.00193 | acc=0.9688 | L2-Norm=13.889 | L2-Norm(final)=2.408 | 4179.8 samples/s | 65.3 steps/s
[Step= 650 Epoch= 2.5] | Loss=0.03987 | Reg=0.00193 | acc=0.9844 | L2-Norm=13.903 | L2-Norm(final)=2.418 | 4231.5 samples/s | 66.1 steps/s
[Step= 700 Epoch= 2.7] | Loss=0.03282 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.914 | L2-Norm(final)=2.426 | 4215.7 samples/s | 65.9 steps/s
[Step= 750 Epoch= 2.9] | Loss=0.02835 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.925 | L2-Norm(final)=2.432 | 5787.7 samples/s | 90.4 steps/s
[Step= 800 Epoch= 3.1] | Loss=0.02510 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.931 | L2-Norm(final)=2.438 | 2301.3 samples/s | 36.0 steps/s
[Step= 850 Epoch= 3.3] | Loss=0.02194 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.938 | L2-Norm(final)=2.443 | 4226.6 samples/s | 66.0 steps/s
[Step= 900 Epoch= 3.5] | Loss=0.01966 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.942 | L2-Norm(final)=2.447 | 4230.2 samples/s | 66.1 steps/s
[Step= 950 Epoch= 3.7] | Loss=0.01771 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.944 | L2-Norm(final)=2.452 | 4340.7 samples/s | 67.8 steps/s
[Step=1000 Epoch= 3.8] | Loss=0.01605 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.945 | L2-Norm(final)=2.455 | 4812.6 samples/s | 75.2 steps/s
[Step=1050 Epoch= 4.0] | Loss=0.01463 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.944 | L2-Norm(final)=2.459 | 2455.2 samples/s | 38.4 steps/s
[Step=1100 Epoch= 4.2] | Loss=0.01343 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.942 | L2-Norm(final)=2.462 | 4188.7 samples/s | 65.4 steps/s
[Step=1150 Epoch= 4.4] | Loss=0.01241 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.939 | L2-Norm(final)=2.465 | 4368.6 samples/s | 68.3 steps/s
[Step=1200 Epoch= 4.6] | Loss=0.01153 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.934 | L2-Norm(final)=2.468 | 4152.2 samples/s | 64.9 steps/s
[Step=1250 Epoch= 4.8] | Loss=0.01078 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.929 | L2-Norm(final)=2.470 | 4302.2 samples/s | 67.2 steps/s
[Step=1300 Epoch= 5.0] | Loss=0.01011 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.923 | L2-Norm(final)=2.472 | 2602.9 samples/s | 40.7 steps/s
[Step=1350 Epoch= 5.2] | Loss=0.00952 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.916 | L2-Norm(final)=2.474 | 4154.0 samples/s | 64.9 steps/s
[Step=1400 Epoch= 5.4] | Loss=0.00899 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.908 | L2-Norm(final)=2.476 | 4284.8 samples/s | 67.0 steps/s
[Step=1450 Epoch= 5.6] | Loss=0.00852 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.900 | L2-Norm(final)=2.477 | 4205.9 samples/s | 65.7 steps/s
[Step=1500 Epoch= 5.8] | Loss=0.00810 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.892 | L2-Norm(final)=2.479 | 4235.0 samples/s | 66.2 steps/s
[Step=1550 Epoch= 6.0] | Loss=0.00772 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.882 | L2-Norm(final)=2.480 | 2664.6 samples/s | 41.6 steps/s
[Step=1600 Epoch= 6.2] | Loss=0.00737 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.873 | L2-Norm(final)=2.482 | 4228.5 samples/s | 66.1 steps/s
[Step=1650 Epoch= 6.4] | Loss=0.00705 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.863 | L2-Norm(final)=2.483 | 4224.9 samples/s | 66.0 steps/s
[Step=1700 Epoch= 6.5] | Loss=0.00676 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.853 | L2-Norm(final)=2.484 | 4209.1 samples/s | 65.8 steps/s
[Step=1750 Epoch= 6.7] | Loss=0.00649 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.842 | L2-Norm(final)=2.485 | 4198.6 samples/s | 65.6 steps/s
[Step=1800 Epoch= 6.9] | Loss=0.00624 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.831 | L2-Norm(final)=2.486 | 6985.4 samples/s | 109.1 steps/s
[Step=1850 Epoch= 7.1] | Loss=0.00601 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.820 | L2-Norm(final)=2.487 | 2166.0 samples/s | 33.8 steps/s
[Step=1900 Epoch= 7.3] | Loss=0.00580 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.809 | L2-Norm(final)=2.488 | 4173.0 samples/s | 65.2 steps/s
[Step=1950 Epoch= 7.5] | Loss=0.00560 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.797 | L2-Norm(final)=2.489 | 4247.6 samples/s | 66.4 steps/s
[Step=2000 Epoch= 7.7] | Loss=0.00541 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.785 | L2-Norm(final)=2.490 | 4191.6 samples/s | 65.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07733 | acc=0.9484 | tpr=0.9693 | fpr=0.0971 | 5077.2 samples/s | 19.8 steps/s
Avg test loss: 0.07785, Avg test acc: 0.94783, Avg tpr: 0.96742, Avg fpr: 0.09524, total FA: 743

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07988 | acc=0.9413 | tpr=0.9491 | fpr=0.0758 | 5324.7 samples/s | 20.8 steps/s
Avg test loss: 0.08131, Avg test acc: 0.94190, Avg tpr: 0.94853, Avg fpr: 0.07268, total FA: 567

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.59394 | acc=0.3175 | tpr=0.0186 | fpr=0.0334 | 5127.0 samples/s | 20.0 steps/s
Avg test loss: 4.59663, Avg test acc: 0.31517, Avg tpr: 0.01801, Avg fpr: 0.03128, total FA: 244

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.39411 | acc=0.3152 | tpr=0.0212 | fpr=0.0463 | 5337.6 samples/s | 20.9 steps/s
Avg test loss: 4.40018, Avg test acc: 0.31305, Avg tpr: 0.02057, Avg fpr: 0.04371, total FA: 341

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.41067 | acc=0.1180 | tpr=0.8805 | fpr=0.8957 | 4901.0 samples/s | 19.1 steps/s
[Step= 100] | Loss=2.40260 | acc=0.1190 | tpr=0.8763 | fpr=0.8951 | 6924.6 samples/s | 27.0 steps/s
[Step= 150] | Loss=2.40619 | acc=0.1191 | tpr=0.8689 | fpr=0.8947 | 7943.0 samples/s | 31.0 steps/s
[Step= 200] | Loss=2.40129 | acc=0.1201 | tpr=0.8721 | fpr=0.8936 | 7889.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=2.39752 | acc=0.1213 | tpr=0.8742 | fpr=0.8924 | 7419.0 samples/s | 29.0 steps/s
[Step= 300] | Loss=2.39667 | acc=0.1212 | tpr=0.8662 | fpr=0.8923 | 8117.4 samples/s | 31.7 steps/s
[Step= 350] | Loss=2.39581 | acc=0.1213 | tpr=0.8647 | fpr=0.8922 | 7412.4 samples/s | 29.0 steps/s
[Step= 400] | Loss=2.39486 | acc=0.1215 | tpr=0.8621 | fpr=0.8919 | 8201.4 samples/s | 32.0 steps/s
[Step= 450] | Loss=2.39548 | acc=0.1214 | tpr=0.8681 | fpr=0.8922 | 7427.0 samples/s | 29.0 steps/s
[Step= 500] | Loss=2.39606 | acc=0.1209 | tpr=0.8648 | fpr=0.8925 | 7903.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=2.39515 | acc=0.1208 | tpr=0.8687 | fpr=0.8928 | 13589.9 samples/s | 53.1 steps/s
Avg test loss: 2.39569, Avg test acc: 0.12071, Avg tpr: 0.86846, Avg fpr: 0.89288, total FA: 123975

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=2.49883 | acc=0.1263 | tpr=0.9159 | fpr=0.8879 | 4987.4 samples/s | 19.5 steps/s
[Step= 100] | Loss=2.49279 | acc=0.1293 | tpr=0.8934 | fpr=0.8850 | 6883.7 samples/s | 26.9 steps/s
[Step= 150] | Loss=2.49597 | acc=0.1290 | tpr=0.8833 | fpr=0.8849 | 7679.7 samples/s | 30.0 steps/s
[Step= 200] | Loss=2.49202 | acc=0.1296 | tpr=0.8896 | fpr=0.8842 | 7889.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=2.49107 | acc=0.1298 | tpr=0.8891 | fpr=0.8840 | 7858.1 samples/s | 30.7 steps/s
[Step= 300] | Loss=2.48779 | acc=0.1306 | tpr=0.8844 | fpr=0.8831 | 7563.5 samples/s | 29.5 steps/s
[Step= 350] | Loss=2.48453 | acc=0.1309 | tpr=0.8867 | fpr=0.8828 | 7645.9 samples/s | 29.9 steps/s
[Step= 400] | Loss=2.48152 | acc=0.1311 | tpr=0.8857 | fpr=0.8826 | 8280.5 samples/s | 32.3 steps/s
[Step= 450] | Loss=2.48087 | acc=0.1314 | tpr=0.8905 | fpr=0.8824 | 7795.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=2.48082 | acc=0.1311 | tpr=0.8885 | fpr=0.8826 | 7434.4 samples/s | 29.0 steps/s
[Step= 550] | Loss=2.48141 | acc=0.1311 | tpr=0.8822 | fpr=0.8826 | 14819.8 samples/s | 57.9 steps/s
Avg test loss: 2.48199, Avg test acc: 0.13094, Avg tpr: 0.88273, Avg fpr: 0.88273, total FA: 122565

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.06986 | acc=0.9823 | tpr=0.9248 | fpr=0.0166 | 4949.7 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.07107 | acc=0.9824 | tpr=0.9360 | fpr=0.0167 | 7003.2 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.07484 | acc=0.9815 | tpr=0.9366 | fpr=0.0177 | 7826.5 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.07560 | acc=0.9813 | tpr=0.9399 | fpr=0.0179 | 7683.9 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.07572 | acc=0.9813 | tpr=0.9362 | fpr=0.0179 | 7533.5 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.07682 | acc=0.9811 | tpr=0.9338 | fpr=0.0181 | 7915.5 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.07723 | acc=0.9808 | tpr=0.9355 | fpr=0.0184 | 7745.0 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.07773 | acc=0.9804 | tpr=0.9294 | fpr=0.0186 | 7455.6 samples/s | 29.1 steps/s
[Step= 450] | Loss=0.07912 | acc=0.9802 | tpr=0.9260 | fpr=0.0188 | 7920.4 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.07869 | acc=0.9803 | tpr=0.9273 | fpr=0.0188 | 7977.5 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.07825 | acc=0.9804 | tpr=0.9256 | fpr=0.0186 | 14287.1 samples/s | 55.8 steps/s
Avg test loss: 0.07821, Avg test acc: 0.98042, Avg tpr: 0.92552, Avg fpr: 0.01858, total FA: 2580

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.05949 | acc=0.9827 | tpr=0.9159 | fpr=0.0161 | 5051.3 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.06298 | acc=0.9823 | tpr=0.9318 | fpr=0.0168 | 6694.9 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.06601 | acc=0.9815 | tpr=0.9352 | fpr=0.0177 | 7846.3 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.06785 | acc=0.9810 | tpr=0.9344 | fpr=0.0181 | 8121.6 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.06761 | acc=0.9811 | tpr=0.9275 | fpr=0.0179 | 7629.8 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.06863 | acc=0.9808 | tpr=0.9244 | fpr=0.0181 | 8024.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.06943 | acc=0.9807 | tpr=0.9267 | fpr=0.0183 | 7847.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.06966 | acc=0.9806 | tpr=0.9223 | fpr=0.0183 | 7900.1 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.07105 | acc=0.9803 | tpr=0.9197 | fpr=0.0186 | 7919.4 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.07061 | acc=0.9803 | tpr=0.9216 | fpr=0.0187 | 7837.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.07035 | acc=0.9803 | tpr=0.9200 | fpr=0.0186 | 13645.9 samples/s | 53.3 steps/s
Avg test loss: 0.07022, Avg test acc: 0.98036, Avg tpr: 0.92036, Avg fpr: 0.01855, total FA: 2576

server round 1/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 3.9] | Loss=0.15120 | Reg=0.00327 | acc=0.8594 | L2-Norm=18.094 | L2-Norm(final)=2.433 | 6971.6 samples/s | 108.9 steps/s
[Step=2050 Epoch= 4.0] | Loss=0.11871 | Reg=0.00328 | acc=0.8906 | L2-Norm=18.113 | L2-Norm(final)=2.441 | 4521.2 samples/s | 70.6 steps/s
[Step=2100 Epoch= 4.1] | Loss=0.11324 | Reg=0.00329 | acc=0.9531 | L2-Norm=18.132 | L2-Norm(final)=2.452 | 5072.3 samples/s | 79.3 steps/s
[Step=2150 Epoch= 4.2] | Loss=0.11128 | Reg=0.00330 | acc=0.8750 | L2-Norm=18.156 | L2-Norm(final)=2.465 | 5022.2 samples/s | 78.5 steps/s
[Step=2200 Epoch= 4.3] | Loss=0.11006 | Reg=0.00331 | acc=0.8906 | L2-Norm=18.183 | L2-Norm(final)=2.477 | 4972.0 samples/s | 77.7 steps/s
[Step=2250 Epoch= 4.4] | Loss=0.10945 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.212 | L2-Norm(final)=2.489 | 4973.9 samples/s | 77.7 steps/s
[Step=2300 Epoch= 4.5] | Loss=0.10781 | Reg=0.00333 | acc=0.9219 | L2-Norm=18.241 | L2-Norm(final)=2.501 | 4991.4 samples/s | 78.0 steps/s
[Step=2350 Epoch= 4.6] | Loss=0.10707 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.269 | L2-Norm(final)=2.511 | 5030.1 samples/s | 78.6 steps/s
[Step=2400 Epoch= 4.7] | Loss=0.10698 | Reg=0.00335 | acc=0.8594 | L2-Norm=18.297 | L2-Norm(final)=2.521 | 5032.9 samples/s | 78.6 steps/s
[Step=2450 Epoch= 4.8] | Loss=0.10592 | Reg=0.00336 | acc=0.9062 | L2-Norm=18.327 | L2-Norm(final)=2.530 | 5047.7 samples/s | 78.9 steps/s
[Step=2500 Epoch= 4.9] | Loss=0.10742 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.357 | L2-Norm(final)=2.538 | 6667.4 samples/s | 104.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.9] | Loss=0.08430 | Reg=0.00348 | acc=0.9375 | L2-Norm=18.662 | L2-Norm(final)=2.614 | 6918.3 samples/s | 108.1 steps/s
[Step=2550 Epoch= 5.0] | Loss=0.10580 | Reg=0.00350 | acc=0.8594 | L2-Norm=18.695 | L2-Norm(final)=2.621 | 3974.3 samples/s | 62.1 steps/s
[Step=2600 Epoch= 5.1] | Loss=0.10577 | Reg=0.00350 | acc=0.8906 | L2-Norm=18.719 | L2-Norm(final)=2.618 | 4370.9 samples/s | 68.3 steps/s
[Step=2650 Epoch= 5.2] | Loss=0.10069 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.735 | L2-Norm(final)=2.620 | 4450.0 samples/s | 69.5 steps/s
[Step=2700 Epoch= 5.3] | Loss=0.09611 | Reg=0.00352 | acc=0.9062 | L2-Norm=18.749 | L2-Norm(final)=2.622 | 4422.6 samples/s | 69.1 steps/s
[Step=2750 Epoch= 5.4] | Loss=0.09578 | Reg=0.00352 | acc=0.9375 | L2-Norm=18.767 | L2-Norm(final)=2.623 | 4534.3 samples/s | 70.8 steps/s
[Step=2800 Epoch= 5.5] | Loss=0.09335 | Reg=0.00353 | acc=0.9375 | L2-Norm=18.782 | L2-Norm(final)=2.623 | 4423.2 samples/s | 69.1 steps/s
[Step=2850 Epoch= 5.6] | Loss=0.09161 | Reg=0.00353 | acc=0.9062 | L2-Norm=18.794 | L2-Norm(final)=2.623 | 4502.9 samples/s | 70.4 steps/s
[Step=2900 Epoch= 5.7] | Loss=0.08976 | Reg=0.00354 | acc=0.9375 | L2-Norm=18.806 | L2-Norm(final)=2.623 | 4434.4 samples/s | 69.3 steps/s
[Step=2950 Epoch= 5.8] | Loss=0.08809 | Reg=0.00354 | acc=0.9375 | L2-Norm=18.816 | L2-Norm(final)=2.624 | 4421.9 samples/s | 69.1 steps/s
[Step=3000 Epoch= 5.9] | Loss=0.08658 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.826 | L2-Norm(final)=2.624 | 5707.9 samples/s | 89.2 steps/s
[Step=3050 Epoch= 5.9] | Loss=0.08365 | Reg=0.00355 | acc=0.9375 | L2-Norm=18.836 | L2-Norm(final)=2.624 | 2381.0 samples/s | 37.2 steps/s
[Step=3100 Epoch= 6.0] | Loss=0.08081 | Reg=0.00355 | acc=0.9688 | L2-Norm=18.846 | L2-Norm(final)=2.626 | 4610.2 samples/s | 72.0 steps/s
[Step=3150 Epoch= 6.1] | Loss=0.07861 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.855 | L2-Norm(final)=2.628 | 4318.3 samples/s | 67.5 steps/s
[Step=3200 Epoch= 6.2] | Loss=0.07617 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.864 | L2-Norm(final)=2.630 | 4381.1 samples/s | 68.5 steps/s
[Step=3250 Epoch= 6.3] | Loss=0.07453 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.874 | L2-Norm(final)=2.631 | 4486.7 samples/s | 70.1 steps/s
[Step=3300 Epoch= 6.4] | Loss=0.07269 | Reg=0.00357 | acc=0.9688 | L2-Norm=18.883 | L2-Norm(final)=2.633 | 4426.6 samples/s | 69.2 steps/s
[Step=3350 Epoch= 6.5] | Loss=0.07178 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.890 | L2-Norm(final)=2.634 | 4412.1 samples/s | 68.9 steps/s
[Step=3400 Epoch= 6.6] | Loss=0.07111 | Reg=0.00357 | acc=0.9375 | L2-Norm=18.897 | L2-Norm(final)=2.635 | 4403.4 samples/s | 68.8 steps/s
[Step=3450 Epoch= 6.7] | Loss=0.07005 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.904 | L2-Norm(final)=2.635 | 4438.0 samples/s | 69.3 steps/s
[Step=3500 Epoch= 6.8] | Loss=0.06891 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.910 | L2-Norm(final)=2.636 | 4768.4 samples/s | 74.5 steps/s
[Step=3550 Epoch= 6.9] | Loss=0.06796 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.917 | L2-Norm(final)=2.637 | 2638.7 samples/s | 41.2 steps/s
[Step=3600 Epoch= 7.0] | Loss=0.06643 | Reg=0.00358 | acc=0.9688 | L2-Norm=18.925 | L2-Norm(final)=2.638 | 4429.3 samples/s | 69.2 steps/s
[Step=3650 Epoch= 7.1] | Loss=0.06508 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.932 | L2-Norm(final)=2.640 | 4374.4 samples/s | 68.4 steps/s
[Step=3700 Epoch= 7.2] | Loss=0.06376 | Reg=0.00359 | acc=0.9688 | L2-Norm=18.939 | L2-Norm(final)=2.641 | 4481.6 samples/s | 70.0 steps/s
[Step=3750 Epoch= 7.3] | Loss=0.06263 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.946 | L2-Norm(final)=2.642 | 4449.1 samples/s | 69.5 steps/s
[Step=3800 Epoch= 7.4] | Loss=0.06171 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.954 | L2-Norm(final)=2.643 | 4404.5 samples/s | 68.8 steps/s
[Step=3850 Epoch= 7.5] | Loss=0.06106 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.960 | L2-Norm(final)=2.644 | 4415.4 samples/s | 69.0 steps/s
[Step=3900 Epoch= 7.6] | Loss=0.06034 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.967 | L2-Norm(final)=2.646 | 4467.7 samples/s | 69.8 steps/s
[Step=3950 Epoch= 7.7] | Loss=0.05964 | Reg=0.00360 | acc=0.9375 | L2-Norm=18.973 | L2-Norm(final)=2.647 | 4431.5 samples/s | 69.2 steps/s
[Step=4000 Epoch= 7.8] | Loss=0.05910 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.980 | L2-Norm(final)=2.648 | 4443.3 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step4000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 3.9] | Loss=0.15491 | Reg=0.00316 | acc=0.8438 | L2-Norm=17.780 | L2-Norm(final)=2.412 | 6238.4 samples/s | 97.5 steps/s
[Step=2050 Epoch= 4.0] | Loss=0.13277 | Reg=0.00318 | acc=0.9219 | L2-Norm=17.827 | L2-Norm(final)=2.408 | 4652.3 samples/s | 72.7 steps/s
[Step=2100 Epoch= 4.1] | Loss=0.12341 | Reg=0.00319 | acc=0.9219 | L2-Norm=17.871 | L2-Norm(final)=2.408 | 4905.3 samples/s | 76.6 steps/s
[Step=2150 Epoch= 4.2] | Loss=0.12095 | Reg=0.00321 | acc=0.9062 | L2-Norm=17.907 | L2-Norm(final)=2.416 | 5036.9 samples/s | 78.7 steps/s
[Step=2200 Epoch= 4.3] | Loss=0.12126 | Reg=0.00322 | acc=0.8594 | L2-Norm=17.943 | L2-Norm(final)=2.426 | 4981.0 samples/s | 77.8 steps/s
[Step=2250 Epoch= 4.4] | Loss=0.12010 | Reg=0.00323 | acc=0.9688 | L2-Norm=17.972 | L2-Norm(final)=2.435 | 4873.2 samples/s | 76.1 steps/s
[Step=2300 Epoch= 4.5] | Loss=0.11833 | Reg=0.00324 | acc=0.8750 | L2-Norm=17.998 | L2-Norm(final)=2.445 | 5088.8 samples/s | 79.5 steps/s
[Step=2350 Epoch= 4.6] | Loss=0.11643 | Reg=0.00325 | acc=0.9375 | L2-Norm=18.026 | L2-Norm(final)=2.457 | 4948.4 samples/s | 77.3 steps/s
[Step=2400 Epoch= 4.7] | Loss=0.11500 | Reg=0.00326 | acc=0.8750 | L2-Norm=18.054 | L2-Norm(final)=2.470 | 5031.5 samples/s | 78.6 steps/s
[Step=2450 Epoch= 4.8] | Loss=0.11290 | Reg=0.00327 | acc=0.9375 | L2-Norm=18.084 | L2-Norm(final)=2.484 | 4959.2 samples/s | 77.5 steps/s
[Step=2500 Epoch= 4.9] | Loss=0.11144 | Reg=0.00328 | acc=0.9062 | L2-Norm=18.110 | L2-Norm(final)=2.497 | 6828.2 samples/s | 106.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.9] | Loss=0.10376 | Reg=0.00337 | acc=0.8594 | L2-Norm=18.371 | L2-Norm(final)=2.635 | 6309.8 samples/s | 98.6 steps/s
[Step=2550 Epoch= 5.0] | Loss=0.11115 | Reg=0.00339 | acc=0.8750 | L2-Norm=18.409 | L2-Norm(final)=2.644 | 4122.7 samples/s | 64.4 steps/s
[Step=2600 Epoch= 5.1] | Loss=0.10958 | Reg=0.00340 | acc=0.9375 | L2-Norm=18.449 | L2-Norm(final)=2.643 | 4315.3 samples/s | 67.4 steps/s
[Step=2650 Epoch= 5.2] | Loss=0.10648 | Reg=0.00341 | acc=0.9062 | L2-Norm=18.479 | L2-Norm(final)=2.642 | 4483.6 samples/s | 70.1 steps/s
[Step=2700 Epoch= 5.3] | Loss=0.10483 | Reg=0.00342 | acc=0.9531 | L2-Norm=18.500 | L2-Norm(final)=2.640 | 4435.1 samples/s | 69.3 steps/s
[Step=2750 Epoch= 5.4] | Loss=0.10013 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.518 | L2-Norm(final)=2.640 | 4426.1 samples/s | 69.2 steps/s
[Step=2800 Epoch= 5.5] | Loss=0.09622 | Reg=0.00343 | acc=0.9531 | L2-Norm=18.533 | L2-Norm(final)=2.640 | 4451.0 samples/s | 69.5 steps/s
[Step=2850 Epoch= 5.6] | Loss=0.09356 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.546 | L2-Norm(final)=2.640 | 4483.5 samples/s | 70.1 steps/s
[Step=2900 Epoch= 5.7] | Loss=0.09023 | Reg=0.00344 | acc=0.9531 | L2-Norm=18.560 | L2-Norm(final)=2.641 | 4436.6 samples/s | 69.3 steps/s
[Step=2950 Epoch= 5.8] | Loss=0.08854 | Reg=0.00345 | acc=0.8906 | L2-Norm=18.573 | L2-Norm(final)=2.643 | 4446.5 samples/s | 69.5 steps/s
[Step=3000 Epoch= 5.9] | Loss=0.08629 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.585 | L2-Norm(final)=2.643 | 5875.3 samples/s | 91.8 steps/s
[Step=3050 Epoch= 6.0] | Loss=0.08345 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.596 | L2-Norm(final)=2.643 | 2379.0 samples/s | 37.2 steps/s
[Step=3100 Epoch= 6.1] | Loss=0.08071 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.607 | L2-Norm(final)=2.644 | 4409.7 samples/s | 68.9 steps/s
[Step=3150 Epoch= 6.2] | Loss=0.07908 | Reg=0.00347 | acc=0.9531 | L2-Norm=18.619 | L2-Norm(final)=2.646 | 4480.9 samples/s | 70.0 steps/s
[Step=3200 Epoch= 6.3] | Loss=0.07768 | Reg=0.00347 | acc=0.9375 | L2-Norm=18.631 | L2-Norm(final)=2.648 | 4401.4 samples/s | 68.8 steps/s
[Step=3250 Epoch= 6.4] | Loss=0.07618 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.643 | L2-Norm(final)=2.650 | 4468.4 samples/s | 69.8 steps/s
[Step=3300 Epoch= 6.5] | Loss=0.07500 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.656 | L2-Norm(final)=2.651 | 4452.1 samples/s | 69.6 steps/s
[Step=3350 Epoch= 6.5] | Loss=0.07327 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.669 | L2-Norm(final)=2.653 | 4511.1 samples/s | 70.5 steps/s
[Step=3400 Epoch= 6.6] | Loss=0.07171 | Reg=0.00349 | acc=0.9531 | L2-Norm=18.681 | L2-Norm(final)=2.654 | 4426.4 samples/s | 69.2 steps/s
[Step=3450 Epoch= 6.7] | Loss=0.07078 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.693 | L2-Norm(final)=2.655 | 4405.2 samples/s | 68.8 steps/s
[Step=3500 Epoch= 6.8] | Loss=0.06997 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.706 | L2-Norm(final)=2.656 | 4887.0 samples/s | 76.4 steps/s
[Step=3550 Epoch= 6.9] | Loss=0.06865 | Reg=0.00350 | acc=0.9219 | L2-Norm=18.718 | L2-Norm(final)=2.657 | 2566.4 samples/s | 40.1 steps/s
[Step=3600 Epoch= 7.0] | Loss=0.06731 | Reg=0.00351 | acc=0.9375 | L2-Norm=18.730 | L2-Norm(final)=2.658 | 4430.3 samples/s | 69.2 steps/s
[Step=3650 Epoch= 7.1] | Loss=0.06611 | Reg=0.00351 | acc=0.9688 | L2-Norm=18.742 | L2-Norm(final)=2.659 | 4431.7 samples/s | 69.2 steps/s
[Step=3700 Epoch= 7.2] | Loss=0.06537 | Reg=0.00352 | acc=0.9062 | L2-Norm=18.754 | L2-Norm(final)=2.661 | 4357.9 samples/s | 68.1 steps/s
[Step=3750 Epoch= 7.3] | Loss=0.06443 | Reg=0.00352 | acc=0.9375 | L2-Norm=18.767 | L2-Norm(final)=2.663 | 4463.9 samples/s | 69.7 steps/s
[Step=3800 Epoch= 7.4] | Loss=0.06382 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.780 | L2-Norm(final)=2.664 | 4417.5 samples/s | 69.0 steps/s
[Step=3850 Epoch= 7.5] | Loss=0.06288 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.792 | L2-Norm(final)=2.665 | 4349.3 samples/s | 68.0 steps/s
[Step=3900 Epoch= 7.6] | Loss=0.06200 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.804 | L2-Norm(final)=2.666 | 4466.8 samples/s | 69.8 steps/s
[Step=3950 Epoch= 7.7] | Loss=0.06117 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.816 | L2-Norm(final)=2.668 | 4503.3 samples/s | 70.4 steps/s
[Step=4000 Epoch= 7.8] | Loss=0.06049 | Reg=0.00354 | acc=0.9688 | L2-Norm=18.827 | L2-Norm(final)=2.669 | 4438.4 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step4000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 7.7] | Loss=0.02136 | Reg=0.00172 | acc=0.9844 | L2-Norm=13.097 | L2-Norm(final)=2.438 | 6186.8 samples/s | 96.7 steps/s
[Step=2050 Epoch= 7.9] | Loss=0.04445 | Reg=0.00172 | acc=0.9688 | L2-Norm=13.130 | L2-Norm(final)=2.440 | 4139.5 samples/s | 64.7 steps/s
[Step=2100 Epoch= 8.0] | Loss=0.04046 | Reg=0.00174 | acc=0.9688 | L2-Norm=13.173 | L2-Norm(final)=2.452 | 4712.1 samples/s | 73.6 steps/s
[Step=2150 Epoch= 8.2] | Loss=0.03753 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.227 | L2-Norm(final)=2.467 | 4619.5 samples/s | 72.2 steps/s
[Step=2200 Epoch= 8.4] | Loss=0.03584 | Reg=0.00176 | acc=0.9375 | L2-Norm=13.275 | L2-Norm(final)=2.481 | 4757.1 samples/s | 74.3 steps/s
[Step=2250 Epoch= 8.6] | Loss=0.03481 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.320 | L2-Norm(final)=2.494 | 6431.1 samples/s | 100.5 steps/s
[Step=2300 Epoch= 8.8] | Loss=0.03382 | Reg=0.00179 | acc=0.9688 | L2-Norm=13.364 | L2-Norm(final)=2.507 | 2412.2 samples/s | 37.7 steps/s
[Step=2350 Epoch= 9.0] | Loss=0.03250 | Reg=0.00180 | acc=0.9844 | L2-Norm=13.408 | L2-Norm(final)=2.520 | 4740.9 samples/s | 74.1 steps/s
[Step=2400 Epoch= 9.2] | Loss=0.03206 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.450 | L2-Norm(final)=2.534 | 4728.4 samples/s | 73.9 steps/s
[Step=2450 Epoch= 9.4] | Loss=0.03130 | Reg=0.00182 | acc=0.9844 | L2-Norm=13.487 | L2-Norm(final)=2.547 | 4768.1 samples/s | 74.5 steps/s
[Step=2500 Epoch= 9.6] | Loss=0.03075 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.523 | L2-Norm(final)=2.560 | 5363.8 samples/s | 83.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 9.6] | Loss=0.00630 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.885 | L2-Norm(final)=2.689 | 6469.4 samples/s | 101.1 steps/s
[Step=2550 Epoch= 9.8] | Loss=0.04589 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.051 | L2-Norm(final)=2.676 | 3680.8 samples/s | 57.5 steps/s
[Step=2600 Epoch=10.0] | Loss=0.03214 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.127 | L2-Norm(final)=2.672 | 4157.3 samples/s | 65.0 steps/s
[Step=2650 Epoch=10.2] | Loss=0.02425 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.158 | L2-Norm(final)=2.673 | 4236.9 samples/s | 66.2 steps/s
[Step=2700 Epoch=10.3] | Loss=0.01917 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.173 | L2-Norm(final)=2.675 | 4188.5 samples/s | 65.4 steps/s
[Step=2750 Epoch=10.5] | Loss=0.01590 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.179 | L2-Norm(final)=2.678 | 5674.7 samples/s | 88.7 steps/s
[Step=2800 Epoch=10.7] | Loss=0.01388 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.183 | L2-Norm(final)=2.681 | 2276.2 samples/s | 35.6 steps/s
[Step=2850 Epoch=10.9] | Loss=0.01205 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.186 | L2-Norm(final)=2.683 | 4317.6 samples/s | 67.5 steps/s
[Step=2900 Epoch=11.1] | Loss=0.01056 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.186 | L2-Norm(final)=2.685 | 4055.3 samples/s | 63.4 steps/s
[Step=2950 Epoch=11.3] | Loss=0.00948 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.184 | L2-Norm(final)=2.687 | 4165.2 samples/s | 65.1 steps/s
[Step=3000 Epoch=11.5] | Loss=0.00854 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.181 | L2-Norm(final)=2.689 | 4759.0 samples/s | 74.4 steps/s
[Step=3050 Epoch=11.7] | Loss=0.00778 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.177 | L2-Norm(final)=2.691 | 2491.2 samples/s | 38.9 steps/s
[Step=3100 Epoch=11.9] | Loss=0.00713 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.171 | L2-Norm(final)=2.692 | 4103.3 samples/s | 64.1 steps/s
[Step=3150 Epoch=12.1] | Loss=0.00658 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.164 | L2-Norm(final)=2.694 | 4241.6 samples/s | 66.3 steps/s
[Step=3200 Epoch=12.3] | Loss=0.00612 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.157 | L2-Norm(final)=2.695 | 4225.2 samples/s | 66.0 steps/s
[Step=3250 Epoch=12.5] | Loss=0.00571 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.149 | L2-Norm(final)=2.696 | 4165.4 samples/s | 65.1 steps/s
[Step=3300 Epoch=12.6] | Loss=0.00536 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.140 | L2-Norm(final)=2.697 | 2669.2 samples/s | 41.7 steps/s
[Step=3350 Epoch=12.8] | Loss=0.00504 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.131 | L2-Norm(final)=2.698 | 4131.2 samples/s | 64.6 steps/s
[Step=3400 Epoch=13.0] | Loss=0.00477 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.121 | L2-Norm(final)=2.699 | 4156.3 samples/s | 64.9 steps/s
[Step=3450 Epoch=13.2] | Loss=0.00452 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.111 | L2-Norm(final)=2.700 | 4282.1 samples/s | 66.9 steps/s
[Step=3500 Epoch=13.4] | Loss=0.00429 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.101 | L2-Norm(final)=2.700 | 4246.3 samples/s | 66.3 steps/s
[Step=3550 Epoch=13.6] | Loss=0.00409 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.090 | L2-Norm(final)=2.701 | 2593.5 samples/s | 40.5 steps/s
[Step=3600 Epoch=13.8] | Loss=0.00390 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.079 | L2-Norm(final)=2.702 | 4175.7 samples/s | 65.2 steps/s
[Step=3650 Epoch=14.0] | Loss=0.00373 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.068 | L2-Norm(final)=2.702 | 4160.1 samples/s | 65.0 steps/s
[Step=3700 Epoch=14.2] | Loss=0.00358 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.057 | L2-Norm(final)=2.703 | 4221.8 samples/s | 66.0 steps/s
[Step=3750 Epoch=14.4] | Loss=0.00344 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.045 | L2-Norm(final)=2.704 | 4172.4 samples/s | 65.2 steps/s
[Step=3800 Epoch=14.6] | Loss=0.00330 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.033 | L2-Norm(final)=2.704 | 6292.7 samples/s | 98.3 steps/s
[Step=3850 Epoch=14.8] | Loss=0.00318 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.021 | L2-Norm(final)=2.705 | 2192.4 samples/s | 34.3 steps/s
[Step=3900 Epoch=14.9] | Loss=0.00307 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.009 | L2-Norm(final)=2.705 | 4227.2 samples/s | 66.1 steps/s
[Step=3950 Epoch=15.1] | Loss=0.00296 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.996 | L2-Norm(final)=2.706 | 4163.8 samples/s | 65.1 steps/s
[Step=4000 Epoch=15.3] | Loss=0.00287 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.983 | L2-Norm(final)=2.706 | 4180.4 samples/s | 65.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step4000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 7.7] | Loss=0.39474 | Reg=0.00183 | acc=0.6875 | L2-Norm=13.522 | L2-Norm(final)=2.513 | 6311.2 samples/s | 98.6 steps/s
[Step=2050 Epoch= 7.9] | Loss=0.08781 | Reg=0.00187 | acc=0.9688 | L2-Norm=13.676 | L2-Norm(final)=2.464 | 4107.8 samples/s | 64.2 steps/s
[Step=2100 Epoch= 8.1] | Loss=0.06424 | Reg=0.00189 | acc=0.9531 | L2-Norm=13.734 | L2-Norm(final)=2.462 | 4722.2 samples/s | 73.8 steps/s
[Step=2150 Epoch= 8.3] | Loss=0.05691 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.768 | L2-Norm(final)=2.469 | 4803.3 samples/s | 75.1 steps/s
[Step=2200 Epoch= 8.5] | Loss=0.05029 | Reg=0.00191 | acc=0.9844 | L2-Norm=13.802 | L2-Norm(final)=2.480 | 4614.7 samples/s | 72.1 steps/s
[Step=2250 Epoch= 8.7] | Loss=0.04735 | Reg=0.00191 | acc=0.9688 | L2-Norm=13.835 | L2-Norm(final)=2.491 | 6764.1 samples/s | 105.7 steps/s
[Step=2300 Epoch= 8.9] | Loss=0.04497 | Reg=0.00192 | acc=0.9688 | L2-Norm=13.865 | L2-Norm(final)=2.502 | 2489.5 samples/s | 38.9 steps/s
[Step=2350 Epoch= 9.0] | Loss=0.04331 | Reg=0.00193 | acc=0.9844 | L2-Norm=13.896 | L2-Norm(final)=2.514 | 4389.4 samples/s | 68.6 steps/s
[Step=2400 Epoch= 9.2] | Loss=0.04193 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.926 | L2-Norm(final)=2.525 | 4702.1 samples/s | 73.5 steps/s
[Step=2450 Epoch= 9.4] | Loss=0.04044 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.955 | L2-Norm(final)=2.537 | 4833.6 samples/s | 75.5 steps/s
[Step=2500 Epoch= 9.6] | Loss=0.03901 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.984 | L2-Norm(final)=2.549 | 5507.0 samples/s | 86.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 9.6] | Loss=0.01454 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.274 | L2-Norm(final)=2.668 | 7219.4 samples/s | 112.8 steps/s
[Step=2550 Epoch= 9.8] | Loss=0.10531 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.452 | L2-Norm(final)=2.618 | 3501.0 samples/s | 54.7 steps/s
[Step=2600 Epoch=10.0] | Loss=0.06078 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.550 | L2-Norm(final)=2.616 | 4285.3 samples/s | 67.0 steps/s
[Step=2650 Epoch=10.2] | Loss=0.04409 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.594 | L2-Norm(final)=2.620 | 4219.6 samples/s | 65.9 steps/s
[Step=2700 Epoch=10.4] | Loss=0.03449 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.620 | L2-Norm(final)=2.625 | 4131.2 samples/s | 64.6 steps/s
[Step=2750 Epoch=10.6] | Loss=0.02831 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=2.629 | 5734.2 samples/s | 89.6 steps/s
[Step=2800 Epoch=10.8] | Loss=0.02372 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=2.633 | 2271.8 samples/s | 35.5 steps/s
[Step=2850 Epoch=11.0] | Loss=0.02051 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=2.637 | 4137.9 samples/s | 64.7 steps/s
[Step=2900 Epoch=11.2] | Loss=0.01807 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=2.641 | 4243.3 samples/s | 66.3 steps/s
[Step=2950 Epoch=11.4] | Loss=0.01636 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=2.644 | 4158.4 samples/s | 65.0 steps/s
[Step=3000 Epoch=11.5] | Loss=0.01496 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=2.647 | 4987.0 samples/s | 77.9 steps/s
[Step=3050 Epoch=11.7] | Loss=0.01365 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=2.650 | 2450.9 samples/s | 38.3 steps/s
[Step=3100 Epoch=11.9] | Loss=0.01253 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=2.652 | 4128.9 samples/s | 64.5 steps/s
[Step=3150 Epoch=12.1] | Loss=0.01157 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=2.655 | 4239.5 samples/s | 66.2 steps/s
[Step=3200 Epoch=12.3] | Loss=0.01075 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=2.657 | 4162.0 samples/s | 65.0 steps/s
[Step=3250 Epoch=12.5] | Loss=0.01004 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=2.659 | 4314.5 samples/s | 67.4 steps/s
[Step=3300 Epoch=12.7] | Loss=0.00942 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=2.661 | 2630.4 samples/s | 41.1 steps/s
[Step=3350 Epoch=12.9] | Loss=0.00887 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=2.662 | 4116.0 samples/s | 64.3 steps/s
[Step=3400 Epoch=13.1] | Loss=0.00838 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=2.664 | 4199.7 samples/s | 65.6 steps/s
[Step=3450 Epoch=13.3] | Loss=0.00794 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=2.665 | 4173.2 samples/s | 65.2 steps/s
[Step=3500 Epoch=13.5] | Loss=0.00755 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=2.667 | 4298.8 samples/s | 67.2 steps/s
[Step=3550 Epoch=13.7] | Loss=0.00719 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=2.668 | 2605.3 samples/s | 40.7 steps/s
[Step=3600 Epoch=13.9] | Loss=0.00686 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.635 | L2-Norm(final)=2.669 | 4172.1 samples/s | 65.2 steps/s
[Step=3650 Epoch=14.1] | Loss=0.00657 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=2.670 | 4192.5 samples/s | 65.5 steps/s
[Step=3700 Epoch=14.2] | Loss=0.00629 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=2.671 | 4233.1 samples/s | 66.1 steps/s
[Step=3750 Epoch=14.4] | Loss=0.00604 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=2.672 | 4193.4 samples/s | 65.5 steps/s
[Step=3800 Epoch=14.6] | Loss=0.00581 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.605 | L2-Norm(final)=2.673 | 6915.0 samples/s | 108.0 steps/s
[Step=3850 Epoch=14.8] | Loss=0.00560 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=2.674 | 2128.4 samples/s | 33.3 steps/s
[Step=3900 Epoch=15.0] | Loss=0.00540 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.588 | L2-Norm(final)=2.675 | 4218.7 samples/s | 65.9 steps/s
[Step=3950 Epoch=15.2] | Loss=0.00521 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.579 | L2-Norm(final)=2.676 | 4210.3 samples/s | 65.8 steps/s
[Step=4000 Epoch=15.4] | Loss=0.00504 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=2.677 | 4177.6 samples/s | 65.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07112 | acc=0.9525 | tpr=0.9652 | fpr=0.0751 | 5134.8 samples/s | 20.1 steps/s
Avg test loss: 0.07272, Avg test acc: 0.95076, Avg tpr: 0.96404, Avg fpr: 0.07845, total FA: 612

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07289 | acc=0.9498 | tpr=0.9666 | fpr=0.0865 | 5078.1 samples/s | 19.8 steps/s
Avg test loss: 0.07472, Avg test acc: 0.94883, Avg tpr: 0.96515, Avg fpr: 0.08704, total FA: 679

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.66442 | acc=0.3125 | tpr=0.0090 | fpr=0.0285 | 4885.9 samples/s | 19.1 steps/s
Avg test loss: 4.68824, Avg test acc: 0.30868, Avg tpr: 0.00833, Avg fpr: 0.03077, total FA: 240

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.51179 | acc=0.3102 | tpr=0.0250 | fpr=0.0706 | 4992.8 samples/s | 19.5 steps/s
Avg test loss: 4.51538, Avg test acc: 0.30844, Avg tpr: 0.02495, Avg fpr: 0.06807, total FA: 531

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.86513 | acc=0.1421 | tpr=0.7522 | fpr=0.8689 | 4941.9 samples/s | 19.3 steps/s
[Step= 100] | Loss=2.85753 | acc=0.1438 | tpr=0.7569 | fpr=0.8677 | 7065.4 samples/s | 27.6 steps/s
[Step= 150] | Loss=2.85774 | acc=0.1448 | tpr=0.7622 | fpr=0.8666 | 7894.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=2.85534 | acc=0.1451 | tpr=0.7650 | fpr=0.8662 | 7667.7 samples/s | 30.0 steps/s
[Step= 250] | Loss=2.85272 | acc=0.1467 | tpr=0.7738 | fpr=0.8647 | 7722.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=2.85132 | acc=0.1470 | tpr=0.7680 | fpr=0.8643 | 8168.1 samples/s | 31.9 steps/s
[Step= 350] | Loss=2.84860 | acc=0.1460 | tpr=0.7602 | fpr=0.8652 | 8164.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=2.84765 | acc=0.1467 | tpr=0.7648 | fpr=0.8646 | 7290.8 samples/s | 28.5 steps/s
[Step= 450] | Loss=2.84879 | acc=0.1466 | tpr=0.7678 | fpr=0.8646 | 8074.3 samples/s | 31.5 steps/s
[Step= 500] | Loss=2.85049 | acc=0.1461 | tpr=0.7674 | fpr=0.8651 | 7889.3 samples/s | 30.8 steps/s
[Step= 550] | Loss=2.84955 | acc=0.1460 | tpr=0.7676 | fpr=0.8653 | 14104.1 samples/s | 55.1 steps/s
Avg test loss: 2.84991, Avg test acc: 0.14592, Avg tpr: 0.76743, Avg fpr: 0.86538, total FA: 120156

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.04685 | acc=0.1370 | tpr=0.9248 | fpr=0.8772 | 4940.6 samples/s | 19.3 steps/s
[Step= 100] | Loss=3.03790 | acc=0.1378 | tpr=0.9232 | fpr=0.8769 | 7350.1 samples/s | 28.7 steps/s
[Step= 150] | Loss=3.04519 | acc=0.1366 | tpr=0.9164 | fpr=0.8777 | 7731.7 samples/s | 30.2 steps/s
[Step= 200] | Loss=3.03900 | acc=0.1359 | tpr=0.9148 | fpr=0.8783 | 7657.5 samples/s | 29.9 steps/s
[Step= 250] | Loss=3.03844 | acc=0.1351 | tpr=0.9153 | fpr=0.8791 | 7802.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=3.03587 | acc=0.1350 | tpr=0.9135 | fpr=0.8792 | 7677.8 samples/s | 30.0 steps/s
[Step= 350] | Loss=3.03661 | acc=0.1346 | tpr=0.9105 | fpr=0.8795 | 7887.7 samples/s | 30.8 steps/s
[Step= 400] | Loss=3.03820 | acc=0.1348 | tpr=0.9081 | fpr=0.8793 | 7867.2 samples/s | 30.7 steps/s
[Step= 450] | Loss=3.03880 | acc=0.1348 | tpr=0.9124 | fpr=0.8793 | 8012.5 samples/s | 31.3 steps/s
[Step= 500] | Loss=3.04057 | acc=0.1348 | tpr=0.9145 | fpr=0.8792 | 7619.7 samples/s | 29.8 steps/s
[Step= 550] | Loss=3.04231 | acc=0.1346 | tpr=0.9133 | fpr=0.8796 | 14481.7 samples/s | 56.6 steps/s
Avg test loss: 3.04312, Avg test acc: 0.13448, Avg tpr: 0.91284, Avg fpr: 0.87967, total FA: 122140

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10419 | acc=0.9818 | tpr=0.9071 | fpr=0.0169 | 4933.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.10792 | acc=0.9814 | tpr=0.9318 | fpr=0.0177 | 7189.4 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.11424 | acc=0.9805 | tpr=0.9308 | fpr=0.0186 | 8017.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.11719 | acc=0.9804 | tpr=0.9344 | fpr=0.0187 | 7421.2 samples/s | 29.0 steps/s
[Step= 250] | Loss=0.11515 | acc=0.9807 | tpr=0.9328 | fpr=0.0184 | 7959.6 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11680 | acc=0.9803 | tpr=0.9287 | fpr=0.0187 | 8213.5 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.11747 | acc=0.9801 | tpr=0.9305 | fpr=0.0190 | 7863.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.11846 | acc=0.9798 | tpr=0.9256 | fpr=0.0192 | 7720.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.12034 | acc=0.9796 | tpr=0.9265 | fpr=0.0195 | 7716.8 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.11972 | acc=0.9797 | tpr=0.9269 | fpr=0.0194 | 8131.9 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.11893 | acc=0.9799 | tpr=0.9276 | fpr=0.0192 | 13695.4 samples/s | 53.5 steps/s
Avg test loss: 0.11864, Avg test acc: 0.97986, Avg tpr: 0.92750, Avg fpr: 0.01919, total FA: 2664

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09649 | acc=0.9818 | tpr=0.9425 | fpr=0.0175 | 5071.5 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.10335 | acc=0.9811 | tpr=0.9510 | fpr=0.0184 | 7185.7 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.10918 | acc=0.9799 | tpr=0.9553 | fpr=0.0196 | 7444.1 samples/s | 29.1 steps/s
[Step= 200] | Loss=0.11097 | acc=0.9799 | tpr=0.9541 | fpr=0.0197 | 7599.3 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.11013 | acc=0.9799 | tpr=0.9476 | fpr=0.0196 | 8527.6 samples/s | 33.3 steps/s
[Step= 300] | Loss=0.11196 | acc=0.9795 | tpr=0.9469 | fpr=0.0199 | 7339.0 samples/s | 28.7 steps/s
[Step= 350] | Loss=0.11237 | acc=0.9794 | tpr=0.9493 | fpr=0.0201 | 7886.2 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.11356 | acc=0.9790 | tpr=0.9469 | fpr=0.0204 | 7784.2 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.11562 | acc=0.9786 | tpr=0.9464 | fpr=0.0208 | 7807.8 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.11476 | acc=0.9786 | tpr=0.9476 | fpr=0.0208 | 7712.9 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.11376 | acc=0.9788 | tpr=0.9467 | fpr=0.0206 | 14214.2 samples/s | 55.5 steps/s
Avg test loss: 0.11351, Avg test acc: 0.97882, Avg tpr: 0.94612, Avg fpr: 0.02058, total FA: 2858

server round 2/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 7.8] | Loss=0.14227 | Reg=0.00345 | acc=0.8594 | L2-Norm=18.563 | L2-Norm(final)=2.678 | 6258.7 samples/s | 97.8 steps/s
[Step=4050 Epoch= 7.9] | Loss=0.11946 | Reg=0.00346 | acc=0.9219 | L2-Norm=18.610 | L2-Norm(final)=2.714 | 4505.6 samples/s | 70.4 steps/s
[Step=4100 Epoch= 8.0] | Loss=0.11138 | Reg=0.00348 | acc=0.8906 | L2-Norm=18.651 | L2-Norm(final)=2.739 | 5075.9 samples/s | 79.3 steps/s
[Step=4150 Epoch= 8.1] | Loss=0.10823 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.696 | L2-Norm(final)=2.764 | 4943.3 samples/s | 77.2 steps/s
[Step=4200 Epoch= 8.2] | Loss=0.10667 | Reg=0.00351 | acc=0.9062 | L2-Norm=18.742 | L2-Norm(final)=2.787 | 4982.5 samples/s | 77.9 steps/s
[Step=4250 Epoch= 8.3] | Loss=0.10633 | Reg=0.00353 | acc=0.9062 | L2-Norm=18.786 | L2-Norm(final)=2.811 | 5072.3 samples/s | 79.3 steps/s
[Step=4300 Epoch= 8.4] | Loss=0.10462 | Reg=0.00355 | acc=0.8750 | L2-Norm=18.830 | L2-Norm(final)=2.834 | 4894.1 samples/s | 76.5 steps/s
[Step=4350 Epoch= 8.5] | Loss=0.10397 | Reg=0.00356 | acc=0.9375 | L2-Norm=18.871 | L2-Norm(final)=2.854 | 5107.6 samples/s | 79.8 steps/s
[Step=4400 Epoch= 8.6] | Loss=0.10342 | Reg=0.00358 | acc=0.8281 | L2-Norm=18.912 | L2-Norm(final)=2.874 | 5010.9 samples/s | 78.3 steps/s
[Step=4450 Epoch= 8.7] | Loss=0.10293 | Reg=0.00359 | acc=0.8906 | L2-Norm=18.954 | L2-Norm(final)=2.896 | 4883.0 samples/s | 76.3 steps/s
[Step=4500 Epoch= 8.8] | Loss=0.10117 | Reg=0.00361 | acc=0.8906 | L2-Norm=18.996 | L2-Norm(final)=2.918 | 6731.2 samples/s | 105.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.8] | Loss=0.05979 | Reg=0.00377 | acc=0.9531 | L2-Norm=19.411 | L2-Norm(final)=3.151 | 6027.9 samples/s | 94.2 steps/s
[Step=4550 Epoch= 8.9] | Loss=0.09559 | Reg=0.00378 | acc=0.9219 | L2-Norm=19.453 | L2-Norm(final)=3.147 | 4149.0 samples/s | 64.8 steps/s
[Step=4600 Epoch= 9.0] | Loss=0.08950 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.475 | L2-Norm(final)=3.139 | 4542.2 samples/s | 71.0 steps/s
[Step=4650 Epoch= 9.1] | Loss=0.08351 | Reg=0.00380 | acc=0.9062 | L2-Norm=19.494 | L2-Norm(final)=3.137 | 4440.4 samples/s | 69.4 steps/s
[Step=4700 Epoch= 9.2] | Loss=0.07998 | Reg=0.00381 | acc=0.9375 | L2-Norm=19.508 | L2-Norm(final)=3.133 | 4317.2 samples/s | 67.5 steps/s
[Step=4750 Epoch= 9.3] | Loss=0.07989 | Reg=0.00381 | acc=0.9375 | L2-Norm=19.518 | L2-Norm(final)=3.127 | 4448.2 samples/s | 69.5 steps/s
[Step=4800 Epoch= 9.4] | Loss=0.07748 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.531 | L2-Norm(final)=3.121 | 4502.7 samples/s | 70.4 steps/s
[Step=4850 Epoch= 9.5] | Loss=0.07649 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.547 | L2-Norm(final)=3.117 | 4475.8 samples/s | 69.9 steps/s
[Step=4900 Epoch= 9.6] | Loss=0.07473 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.561 | L2-Norm(final)=3.114 | 4453.2 samples/s | 69.6 steps/s
[Step=4950 Epoch= 9.7] | Loss=0.07328 | Reg=0.00383 | acc=0.9219 | L2-Norm=19.574 | L2-Norm(final)=3.111 | 4471.4 samples/s | 69.9 steps/s
[Step=5000 Epoch= 9.8] | Loss=0.07145 | Reg=0.00384 | acc=0.9531 | L2-Norm=19.587 | L2-Norm(final)=3.109 | 5637.4 samples/s | 88.1 steps/s
[Step=5050 Epoch= 9.8] | Loss=0.06960 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.597 | L2-Norm(final)=3.106 | 2397.1 samples/s | 37.5 steps/s
[Step=5100 Epoch= 9.9] | Loss=0.06748 | Reg=0.00385 | acc=0.9062 | L2-Norm=19.609 | L2-Norm(final)=3.105 | 4491.4 samples/s | 70.2 steps/s
[Step=5150 Epoch=10.0] | Loss=0.06621 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.621 | L2-Norm(final)=3.103 | 4396.1 samples/s | 68.7 steps/s
[Step=5200 Epoch=10.1] | Loss=0.06464 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.632 | L2-Norm(final)=3.102 | 4477.8 samples/s | 70.0 steps/s
[Step=5250 Epoch=10.2] | Loss=0.06335 | Reg=0.00386 | acc=0.9375 | L2-Norm=19.642 | L2-Norm(final)=3.100 | 4427.3 samples/s | 69.2 steps/s
[Step=5300 Epoch=10.3] | Loss=0.06215 | Reg=0.00386 | acc=0.9219 | L2-Norm=19.651 | L2-Norm(final)=3.098 | 4459.9 samples/s | 69.7 steps/s
[Step=5350 Epoch=10.4] | Loss=0.06082 | Reg=0.00386 | acc=0.9531 | L2-Norm=19.659 | L2-Norm(final)=3.097 | 4322.9 samples/s | 67.5 steps/s
[Step=5400 Epoch=10.5] | Loss=0.05956 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.666 | L2-Norm(final)=3.096 | 4480.5 samples/s | 70.0 steps/s
[Step=5450 Epoch=10.6] | Loss=0.05845 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.672 | L2-Norm(final)=3.095 | 4464.6 samples/s | 69.8 steps/s
[Step=5500 Epoch=10.7] | Loss=0.05792 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.677 | L2-Norm(final)=3.094 | 4693.5 samples/s | 73.3 steps/s
[Step=5550 Epoch=10.8] | Loss=0.05707 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.682 | L2-Norm(final)=3.093 | 2607.1 samples/s | 40.7 steps/s
[Step=5600 Epoch=10.9] | Loss=0.05599 | Reg=0.00388 | acc=0.9531 | L2-Norm=19.688 | L2-Norm(final)=3.093 | 4432.3 samples/s | 69.3 steps/s
[Step=5650 Epoch=11.0] | Loss=0.05488 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.693 | L2-Norm(final)=3.093 | 4445.5 samples/s | 69.5 steps/s
[Step=5700 Epoch=11.1] | Loss=0.05399 | Reg=0.00388 | acc=0.9844 | L2-Norm=19.699 | L2-Norm(final)=3.093 | 4439.2 samples/s | 69.4 steps/s
[Step=5750 Epoch=11.2] | Loss=0.05320 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.704 | L2-Norm(final)=3.092 | 4422.6 samples/s | 69.1 steps/s
[Step=5800 Epoch=11.3] | Loss=0.05253 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.709 | L2-Norm(final)=3.092 | 4409.1 samples/s | 68.9 steps/s
[Step=5850 Epoch=11.4] | Loss=0.05167 | Reg=0.00389 | acc=0.9375 | L2-Norm=19.713 | L2-Norm(final)=3.091 | 4466.7 samples/s | 69.8 steps/s
[Step=5900 Epoch=11.5] | Loss=0.05100 | Reg=0.00389 | acc=0.9531 | L2-Norm=19.717 | L2-Norm(final)=3.091 | 4460.1 samples/s | 69.7 steps/s
[Step=5950 Epoch=11.6] | Loss=0.05066 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.722 | L2-Norm(final)=3.090 | 4418.0 samples/s | 69.0 steps/s
[Step=6000 Epoch=11.7] | Loss=0.05013 | Reg=0.00389 | acc=0.9375 | L2-Norm=19.726 | L2-Norm(final)=3.090 | 4452.6 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step6000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 7.8] | Loss=0.12607 | Reg=0.00341 | acc=0.9062 | L2-Norm=18.475 | L2-Norm(final)=2.702 | 6891.4 samples/s | 107.7 steps/s
[Step=4050 Epoch= 7.9] | Loss=0.12913 | Reg=0.00342 | acc=0.9375 | L2-Norm=18.500 | L2-Norm(final)=2.736 | 4358.8 samples/s | 68.1 steps/s
[Step=4100 Epoch= 8.0] | Loss=0.12177 | Reg=0.00344 | acc=0.8594 | L2-Norm=18.534 | L2-Norm(final)=2.761 | 4968.7 samples/s | 77.6 steps/s
[Step=4150 Epoch= 8.1] | Loss=0.11957 | Reg=0.00345 | acc=0.8906 | L2-Norm=18.567 | L2-Norm(final)=2.782 | 5067.3 samples/s | 79.2 steps/s
[Step=4200 Epoch= 8.2] | Loss=0.11773 | Reg=0.00346 | acc=0.9219 | L2-Norm=18.600 | L2-Norm(final)=2.802 | 4986.3 samples/s | 77.9 steps/s
[Step=4250 Epoch= 8.3] | Loss=0.11572 | Reg=0.00347 | acc=0.9375 | L2-Norm=18.636 | L2-Norm(final)=2.824 | 4951.4 samples/s | 77.4 steps/s
[Step=4300 Epoch= 8.4] | Loss=0.11477 | Reg=0.00349 | acc=0.8906 | L2-Norm=18.669 | L2-Norm(final)=2.844 | 5069.7 samples/s | 79.2 steps/s
[Step=4350 Epoch= 8.5] | Loss=0.11426 | Reg=0.00350 | acc=0.8750 | L2-Norm=18.703 | L2-Norm(final)=2.866 | 5025.4 samples/s | 78.5 steps/s
[Step=4400 Epoch= 8.6] | Loss=0.11359 | Reg=0.00351 | acc=0.9375 | L2-Norm=18.738 | L2-Norm(final)=2.887 | 5175.7 samples/s | 80.9 steps/s
[Step=4450 Epoch= 8.7] | Loss=0.11237 | Reg=0.00352 | acc=0.8594 | L2-Norm=18.774 | L2-Norm(final)=2.909 | 4813.8 samples/s | 75.2 steps/s
[Step=4500 Epoch= 8.8] | Loss=0.11215 | Reg=0.00354 | acc=0.8594 | L2-Norm=18.809 | L2-Norm(final)=2.930 | 6941.7 samples/s | 108.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.8] | Loss=0.11329 | Reg=0.00367 | acc=0.9375 | L2-Norm=19.164 | L2-Norm(final)=3.137 | 6297.7 samples/s | 98.4 steps/s
[Step=4550 Epoch= 8.9] | Loss=0.10250 | Reg=0.00368 | acc=0.8906 | L2-Norm=19.196 | L2-Norm(final)=3.140 | 4159.0 samples/s | 65.0 steps/s
[Step=4600 Epoch= 9.0] | Loss=0.09573 | Reg=0.00370 | acc=0.9688 | L2-Norm=19.235 | L2-Norm(final)=3.125 | 4283.6 samples/s | 66.9 steps/s
[Step=4650 Epoch= 9.1] | Loss=0.08621 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.265 | L2-Norm(final)=3.121 | 4491.0 samples/s | 70.2 steps/s
[Step=4700 Epoch= 9.2] | Loss=0.08248 | Reg=0.00372 | acc=0.9219 | L2-Norm=19.285 | L2-Norm(final)=3.118 | 4394.3 samples/s | 68.7 steps/s
[Step=4750 Epoch= 9.3] | Loss=0.07991 | Reg=0.00373 | acc=0.9688 | L2-Norm=19.305 | L2-Norm(final)=3.115 | 4394.4 samples/s | 68.7 steps/s
[Step=4800 Epoch= 9.4] | Loss=0.07788 | Reg=0.00373 | acc=0.9219 | L2-Norm=19.323 | L2-Norm(final)=3.112 | 4484.8 samples/s | 70.1 steps/s
[Step=4850 Epoch= 9.5] | Loss=0.07556 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.340 | L2-Norm(final)=3.110 | 4445.5 samples/s | 69.5 steps/s
[Step=4900 Epoch= 9.6] | Loss=0.07401 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.356 | L2-Norm(final)=3.106 | 4384.2 samples/s | 68.5 steps/s
[Step=4950 Epoch= 9.7] | Loss=0.07267 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.369 | L2-Norm(final)=3.102 | 4501.2 samples/s | 70.3 steps/s
[Step=5000 Epoch= 9.8] | Loss=0.07151 | Reg=0.00376 | acc=0.9219 | L2-Norm=19.381 | L2-Norm(final)=3.099 | 5857.0 samples/s | 91.5 steps/s
[Step=5050 Epoch= 9.9] | Loss=0.06903 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.393 | L2-Norm(final)=3.097 | 2394.2 samples/s | 37.4 steps/s
[Step=5100 Epoch=10.0] | Loss=0.06669 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.404 | L2-Norm(final)=3.096 | 4423.4 samples/s | 69.1 steps/s
[Step=5150 Epoch=10.1] | Loss=0.06454 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.416 | L2-Norm(final)=3.095 | 4446.4 samples/s | 69.5 steps/s
[Step=5200 Epoch=10.2] | Loss=0.06316 | Reg=0.00377 | acc=0.9531 | L2-Norm=19.427 | L2-Norm(final)=3.095 | 4417.1 samples/s | 69.0 steps/s
[Step=5250 Epoch=10.3] | Loss=0.06188 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.438 | L2-Norm(final)=3.095 | 4417.1 samples/s | 69.0 steps/s
[Step=5300 Epoch=10.4] | Loss=0.06114 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.450 | L2-Norm(final)=3.094 | 4466.0 samples/s | 69.8 steps/s
[Step=5350 Epoch=10.5] | Loss=0.06042 | Reg=0.00379 | acc=0.9375 | L2-Norm=19.462 | L2-Norm(final)=3.093 | 4421.5 samples/s | 69.1 steps/s
[Step=5400 Epoch=10.6] | Loss=0.05937 | Reg=0.00379 | acc=0.9375 | L2-Norm=19.474 | L2-Norm(final)=3.092 | 4540.3 samples/s | 70.9 steps/s
[Step=5450 Epoch=10.7] | Loss=0.05869 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.484 | L2-Norm(final)=3.091 | 4419.1 samples/s | 69.0 steps/s
[Step=5500 Epoch=10.8] | Loss=0.05817 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.494 | L2-Norm(final)=3.089 | 4893.3 samples/s | 76.5 steps/s
[Step=5550 Epoch=10.9] | Loss=0.05766 | Reg=0.00380 | acc=0.9688 | L2-Norm=19.504 | L2-Norm(final)=3.088 | 2597.2 samples/s | 40.6 steps/s
[Step=5600 Epoch=10.9] | Loss=0.05675 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.515 | L2-Norm(final)=3.087 | 4403.2 samples/s | 68.8 steps/s
[Step=5650 Epoch=11.0] | Loss=0.05563 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.526 | L2-Norm(final)=3.087 | 4458.8 samples/s | 69.7 steps/s
[Step=5700 Epoch=11.1] | Loss=0.05485 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.537 | L2-Norm(final)=3.087 | 4402.1 samples/s | 68.8 steps/s
[Step=5750 Epoch=11.2] | Loss=0.05410 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.548 | L2-Norm(final)=3.087 | 4434.7 samples/s | 69.3 steps/s
[Step=5800 Epoch=11.3] | Loss=0.05352 | Reg=0.00383 | acc=0.9688 | L2-Norm=19.559 | L2-Norm(final)=3.087 | 4429.9 samples/s | 69.2 steps/s
[Step=5850 Epoch=11.4] | Loss=0.05275 | Reg=0.00383 | acc=0.9688 | L2-Norm=19.570 | L2-Norm(final)=3.087 | 4456.3 samples/s | 69.6 steps/s
[Step=5900 Epoch=11.5] | Loss=0.05220 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.582 | L2-Norm(final)=3.087 | 4446.0 samples/s | 69.5 steps/s
[Step=5950 Epoch=11.6] | Loss=0.05157 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.593 | L2-Norm(final)=3.088 | 4437.3 samples/s | 69.3 steps/s
[Step=6000 Epoch=11.7] | Loss=0.05083 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.604 | L2-Norm(final)=3.088 | 4405.3 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step6000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=15.3] | Loss=0.15007 | Reg=0.00185 | acc=0.8438 | L2-Norm=13.586 | L2-Norm(final)=2.719 | 6703.9 samples/s | 104.7 steps/s
[Step=4050 Epoch=15.5] | Loss=0.03240 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.638 | L2-Norm(final)=2.714 | 3943.5 samples/s | 61.6 steps/s
[Step=4100 Epoch=15.7] | Loss=0.02559 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.678 | L2-Norm(final)=2.730 | 4655.7 samples/s | 72.7 steps/s
[Step=4150 Epoch=15.9] | Loss=0.02300 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.710 | L2-Norm(final)=2.746 | 4698.5 samples/s | 73.4 steps/s
[Step=4200 Epoch=16.1] | Loss=0.02247 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.741 | L2-Norm(final)=2.762 | 4768.5 samples/s | 74.5 steps/s
[Step=4250 Epoch=16.3] | Loss=0.02108 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.771 | L2-Norm(final)=2.779 | 6594.6 samples/s | 103.0 steps/s
[Step=4300 Epoch=16.5] | Loss=0.01972 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.799 | L2-Norm(final)=2.797 | 2475.8 samples/s | 38.7 steps/s
[Step=4350 Epoch=16.7] | Loss=0.01934 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.829 | L2-Norm(final)=2.815 | 4455.5 samples/s | 69.6 steps/s
[Step=4400 Epoch=16.9] | Loss=0.01846 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.859 | L2-Norm(final)=2.834 | 4758.3 samples/s | 74.3 steps/s
[Step=4450 Epoch=17.1] | Loss=0.01761 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.888 | L2-Norm(final)=2.853 | 4632.9 samples/s | 72.4 steps/s
[Step=4500 Epoch=17.2] | Loss=0.01685 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.919 | L2-Norm(final)=2.873 | 5483.6 samples/s | 85.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=17.2] | Loss=0.02665 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.220 | L2-Norm(final)=3.076 | 6277.4 samples/s | 98.1 steps/s
[Step=4550 Epoch=17.4] | Loss=0.03368 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.351 | L2-Norm(final)=3.056 | 3829.7 samples/s | 59.8 steps/s
[Step=4600 Epoch=17.6] | Loss=0.02337 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.438 | L2-Norm(final)=3.043 | 4105.4 samples/s | 64.1 steps/s
[Step=4650 Epoch=17.8] | Loss=0.01787 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=3.041 | 4220.3 samples/s | 65.9 steps/s
[Step=4700 Epoch=18.0] | Loss=0.01440 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=3.041 | 4160.1 samples/s | 65.0 steps/s
[Step=4750 Epoch=18.2] | Loss=0.01231 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.509 | L2-Norm(final)=3.043 | 5704.1 samples/s | 89.1 steps/s
[Step=4800 Epoch=18.4] | Loss=0.01066 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.517 | L2-Norm(final)=3.045 | 2250.3 samples/s | 35.2 steps/s
[Step=4850 Epoch=18.6] | Loss=0.00917 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=3.047 | 4237.2 samples/s | 66.2 steps/s
[Step=4900 Epoch=18.8] | Loss=0.00804 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.519 | L2-Norm(final)=3.049 | 4232.0 samples/s | 66.1 steps/s
[Step=4950 Epoch=19.0] | Loss=0.00716 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.516 | L2-Norm(final)=3.051 | 4164.5 samples/s | 65.1 steps/s
[Step=5000 Epoch=19.2] | Loss=0.00646 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=3.053 | 4807.5 samples/s | 75.1 steps/s
[Step=5050 Epoch=19.3] | Loss=0.00588 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=3.055 | 2467.7 samples/s | 38.6 steps/s
[Step=5100 Epoch=19.5] | Loss=0.00539 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=3.057 | 4144.3 samples/s | 64.8 steps/s
[Step=5150 Epoch=19.7] | Loss=0.00498 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.484 | L2-Norm(final)=3.058 | 4194.8 samples/s | 65.5 steps/s
[Step=5200 Epoch=19.9] | Loss=0.00462 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.474 | L2-Norm(final)=3.060 | 4256.7 samples/s | 66.5 steps/s
[Step=5250 Epoch=20.1] | Loss=0.00432 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.463 | L2-Norm(final)=3.061 | 4183.3 samples/s | 65.4 steps/s
[Step=5300 Epoch=20.3] | Loss=0.00405 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.451 | L2-Norm(final)=3.063 | 2625.3 samples/s | 41.0 steps/s
[Step=5350 Epoch=20.5] | Loss=0.00381 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.438 | L2-Norm(final)=3.065 | 4205.1 samples/s | 65.7 steps/s
[Step=5400 Epoch=20.7] | Loss=0.00360 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.425 | L2-Norm(final)=3.067 | 4214.7 samples/s | 65.9 steps/s
[Step=5450 Epoch=20.9] | Loss=0.00341 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.412 | L2-Norm(final)=3.070 | 4239.9 samples/s | 66.2 steps/s
[Step=5500 Epoch=21.1] | Loss=0.00324 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.398 | L2-Norm(final)=3.072 | 4218.3 samples/s | 65.9 steps/s
[Step=5550 Epoch=21.3] | Loss=0.00309 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=3.074 | 2683.3 samples/s | 41.9 steps/s
[Step=5600 Epoch=21.5] | Loss=0.00295 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.369 | L2-Norm(final)=3.077 | 4073.7 samples/s | 63.7 steps/s
[Step=5650 Epoch=21.6] | Loss=0.00282 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.354 | L2-Norm(final)=3.080 | 4229.1 samples/s | 66.1 steps/s
[Step=5700 Epoch=21.8] | Loss=0.00271 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.338 | L2-Norm(final)=3.083 | 4224.0 samples/s | 66.0 steps/s
[Step=5750 Epoch=22.0] | Loss=0.00260 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.323 | L2-Norm(final)=3.086 | 4213.3 samples/s | 65.8 steps/s
[Step=5800 Epoch=22.2] | Loss=0.00250 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.307 | L2-Norm(final)=3.089 | 6259.0 samples/s | 97.8 steps/s
[Step=5850 Epoch=22.4] | Loss=0.00241 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.291 | L2-Norm(final)=3.093 | 2215.9 samples/s | 34.6 steps/s
[Step=5900 Epoch=22.6] | Loss=0.00232 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.275 | L2-Norm(final)=3.096 | 4164.2 samples/s | 65.1 steps/s
[Step=5950 Epoch=22.8] | Loss=0.00224 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.258 | L2-Norm(final)=3.100 | 4294.5 samples/s | 67.1 steps/s
[Step=6000 Epoch=23.0] | Loss=0.00217 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.241 | L2-Norm(final)=3.104 | 4182.9 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step6000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=15.4] | Loss=0.05568 | Reg=0.00201 | acc=0.9531 | L2-Norm=14.195 | L2-Norm(final)=2.700 | 6274.0 samples/s | 98.0 steps/s
[Step=4050 Epoch=15.6] | Loss=0.03483 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.225 | L2-Norm(final)=2.697 | 4162.4 samples/s | 65.0 steps/s
[Step=4100 Epoch=15.8] | Loss=0.03095 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.271 | L2-Norm(final)=2.711 | 4794.4 samples/s | 74.9 steps/s
[Step=4150 Epoch=16.0] | Loss=0.02837 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.315 | L2-Norm(final)=2.726 | 4671.2 samples/s | 73.0 steps/s
[Step=4200 Epoch=16.2] | Loss=0.02590 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.352 | L2-Norm(final)=2.743 | 4796.7 samples/s | 74.9 steps/s
[Step=4250 Epoch=16.4] | Loss=0.02511 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.386 | L2-Norm(final)=2.758 | 6716.1 samples/s | 104.9 steps/s
[Step=4300 Epoch=16.6] | Loss=0.02379 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.416 | L2-Norm(final)=2.772 | 2426.3 samples/s | 37.9 steps/s
[Step=4350 Epoch=16.7] | Loss=0.02304 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.447 | L2-Norm(final)=2.787 | 4698.1 samples/s | 73.4 steps/s
[Step=4400 Epoch=16.9] | Loss=0.02203 | Reg=0.00210 | acc=0.9688 | L2-Norm=14.477 | L2-Norm(final)=2.803 | 4692.8 samples/s | 73.3 steps/s
[Step=4450 Epoch=17.1] | Loss=0.02126 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.508 | L2-Norm(final)=2.820 | 4771.9 samples/s | 74.6 steps/s
[Step=4500 Epoch=17.3] | Loss=0.02081 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.539 | L2-Norm(final)=2.836 | 5526.2 samples/s | 86.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=17.3] | Loss=0.00488 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.855 | L2-Norm(final)=2.998 | 6246.2 samples/s | 97.6 steps/s
[Step=4550 Epoch=17.5] | Loss=0.02448 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=3.000 | 3777.7 samples/s | 59.0 steps/s
[Step=4600 Epoch=17.7] | Loss=0.01889 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=2.992 | 4238.2 samples/s | 66.2 steps/s
[Step=4650 Epoch=17.9] | Loss=0.01430 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.079 | L2-Norm(final)=2.993 | 4200.5 samples/s | 65.6 steps/s
[Step=4700 Epoch=18.1] | Loss=0.01287 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.106 | L2-Norm(final)=2.993 | 4265.6 samples/s | 66.6 steps/s
[Step=4750 Epoch=18.3] | Loss=0.01179 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=2.992 | 5316.3 samples/s | 83.1 steps/s
[Step=4800 Epoch=18.5] | Loss=0.00993 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.142 | L2-Norm(final)=2.993 | 2199.0 samples/s | 34.4 steps/s
[Step=4850 Epoch=18.7] | Loss=0.00857 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=2.994 | 4229.2 samples/s | 66.1 steps/s
[Step=4900 Epoch=18.9] | Loss=0.00759 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.153 | L2-Norm(final)=2.995 | 4231.3 samples/s | 66.1 steps/s
[Step=4950 Epoch=19.1] | Loss=0.00678 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.153 | L2-Norm(final)=2.997 | 4129.4 samples/s | 64.5 steps/s
[Step=5000 Epoch=19.2] | Loss=0.00613 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=2.999 | 4881.9 samples/s | 76.3 steps/s
[Step=5050 Epoch=19.4] | Loss=0.00558 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.146 | L2-Norm(final)=3.001 | 2437.6 samples/s | 38.1 steps/s
[Step=5100 Epoch=19.6] | Loss=0.00513 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.140 | L2-Norm(final)=3.002 | 4087.0 samples/s | 63.9 steps/s
[Step=5150 Epoch=19.8] | Loss=0.00474 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=3.004 | 4238.6 samples/s | 66.2 steps/s
[Step=5200 Epoch=20.0] | Loss=0.00441 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=3.005 | 4195.7 samples/s | 65.6 steps/s
[Step=5250 Epoch=20.2] | Loss=0.00411 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=3.007 | 4247.4 samples/s | 66.4 steps/s
[Step=5300 Epoch=20.4] | Loss=0.00386 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.104 | L2-Norm(final)=3.008 | 2577.7 samples/s | 40.3 steps/s
[Step=5350 Epoch=20.6] | Loss=0.00363 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=3.009 | 4244.9 samples/s | 66.3 steps/s
[Step=5400 Epoch=20.8] | Loss=0.00343 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=3.010 | 4167.7 samples/s | 65.1 steps/s
[Step=5450 Epoch=21.0] | Loss=0.00325 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=3.011 | 4129.1 samples/s | 64.5 steps/s
[Step=5500 Epoch=21.2] | Loss=0.00309 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=3.012 | 4180.8 samples/s | 65.3 steps/s
[Step=5550 Epoch=21.4] | Loss=0.00294 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=3.013 | 2638.7 samples/s | 41.2 steps/s
[Step=5600 Epoch=21.6] | Loss=0.00281 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=3.013 | 4197.5 samples/s | 65.6 steps/s
[Step=5650 Epoch=21.7] | Loss=0.00269 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=3.014 | 4167.7 samples/s | 65.1 steps/s
[Step=5700 Epoch=21.9] | Loss=0.00258 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=3.015 | 4348.9 samples/s | 68.0 steps/s
[Step=5750 Epoch=22.1] | Loss=0.00247 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=3.015 | 4028.1 samples/s | 62.9 steps/s
[Step=5800 Epoch=22.3] | Loss=0.00238 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=3.016 | 6854.1 samples/s | 107.1 steps/s
[Step=5850 Epoch=22.5] | Loss=0.00229 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=3.017 | 2121.3 samples/s | 33.1 steps/s
[Step=5900 Epoch=22.7] | Loss=0.00221 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=3.018 | 4155.0 samples/s | 64.9 steps/s
[Step=5950 Epoch=22.9] | Loss=0.00213 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=3.018 | 4201.8 samples/s | 65.7 steps/s
[Step=6000 Epoch=23.1] | Loss=0.00206 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.908 | L2-Norm(final)=3.019 | 4203.8 samples/s | 65.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07355 | acc=0.9534 | tpr=0.9653 | fpr=0.0723 | 4876.8 samples/s | 19.1 steps/s
Avg test loss: 0.07276, Avg test acc: 0.95332, Avg tpr: 0.96503, Avg fpr: 0.07243, total FA: 565

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07655 | acc=0.9531 | tpr=0.9618 | fpr=0.0657 | 4985.0 samples/s | 19.5 steps/s
Avg test loss: 0.07947, Avg test acc: 0.95108, Avg tpr: 0.96025, Avg fpr: 0.06909, total FA: 539

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.96074 | acc=0.3145 | tpr=0.0070 | fpr=0.0176 | 4947.1 samples/s | 19.3 steps/s
Avg test loss: 4.97192, Avg test acc: 0.31132, Avg tpr: 0.00659, Avg fpr: 0.01846, total FA: 144

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.58389 | acc=0.3136 | tpr=0.0119 | fpr=0.0312 | 4900.3 samples/s | 19.1 steps/s
Avg test loss: 5.58760, Avg test acc: 0.31293, Avg tpr: 0.01236, Avg fpr: 0.02602, total FA: 203

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.06285 | acc=0.1127 | tpr=0.8451 | fpr=0.9004 | 4757.5 samples/s | 18.6 steps/s
[Step= 100] | Loss=4.04933 | acc=0.1128 | tpr=0.8252 | fpr=0.9005 | 7280.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=4.04881 | acc=0.1126 | tpr=0.8271 | fpr=0.9006 | 8019.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=4.05171 | acc=0.1123 | tpr=0.8164 | fpr=0.9005 | 7598.0 samples/s | 29.7 steps/s
[Step= 250] | Loss=4.05071 | acc=0.1135 | tpr=0.8131 | fpr=0.8992 | 7988.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=4.04787 | acc=0.1136 | tpr=0.8102 | fpr=0.8991 | 7847.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=4.04893 | acc=0.1132 | tpr=0.8065 | fpr=0.8994 | 7856.8 samples/s | 30.7 steps/s
[Step= 400] | Loss=4.05123 | acc=0.1137 | tpr=0.8113 | fpr=0.8990 | 7883.0 samples/s | 30.8 steps/s
[Step= 450] | Loss=4.05208 | acc=0.1135 | tpr=0.8101 | fpr=0.8992 | 7456.7 samples/s | 29.1 steps/s
[Step= 500] | Loss=4.05292 | acc=0.1134 | tpr=0.8106 | fpr=0.8992 | 8004.5 samples/s | 31.3 steps/s
[Step= 550] | Loss=4.05367 | acc=0.1134 | tpr=0.8118 | fpr=0.8993 | 14019.1 samples/s | 54.8 steps/s
Avg test loss: 4.05544, Avg test acc: 0.11327, Avg tpr: 0.81220, Avg fpr: 0.89944, total FA: 124885

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.22016 | acc=0.1341 | tpr=0.8584 | fpr=0.8790 | 5044.4 samples/s | 19.7 steps/s
[Step= 100] | Loss=4.19446 | acc=0.1361 | tpr=0.8124 | fpr=0.8766 | 6726.4 samples/s | 26.3 steps/s
[Step= 150] | Loss=4.19222 | acc=0.1342 | tpr=0.8112 | fpr=0.8783 | 7809.2 samples/s | 30.5 steps/s
[Step= 200] | Loss=4.18342 | acc=0.1344 | tpr=0.8033 | fpr=0.8778 | 7452.4 samples/s | 29.1 steps/s
[Step= 250] | Loss=4.17572 | acc=0.1343 | tpr=0.8105 | fpr=0.8780 | 7876.9 samples/s | 30.8 steps/s
[Step= 300] | Loss=4.16880 | acc=0.1341 | tpr=0.8051 | fpr=0.8781 | 7636.4 samples/s | 29.8 steps/s
[Step= 350] | Loss=4.16984 | acc=0.1345 | tpr=0.8053 | fpr=0.8777 | 7604.6 samples/s | 29.7 steps/s
[Step= 400] | Loss=4.17033 | acc=0.1347 | tpr=0.8074 | fpr=0.8775 | 7601.4 samples/s | 29.7 steps/s
[Step= 450] | Loss=4.17184 | acc=0.1346 | tpr=0.8130 | fpr=0.8777 | 7770.2 samples/s | 30.4 steps/s
[Step= 500] | Loss=4.17630 | acc=0.1348 | tpr=0.8110 | fpr=0.8774 | 7838.3 samples/s | 30.6 steps/s
[Step= 550] | Loss=4.17882 | acc=0.1344 | tpr=0.8054 | fpr=0.8778 | 13555.2 samples/s | 53.0 steps/s
Avg test loss: 4.18000, Avg test acc: 0.13424, Avg tpr: 0.80586, Avg fpr: 0.87797, total FA: 121904

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09743 | acc=0.9830 | tpr=0.9381 | fpr=0.0162 | 4924.7 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.10071 | acc=0.9818 | tpr=0.9467 | fpr=0.0175 | 7007.0 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.10483 | acc=0.9808 | tpr=0.9452 | fpr=0.0185 | 7545.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.10653 | acc=0.9807 | tpr=0.9464 | fpr=0.0187 | 7899.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.10507 | acc=0.9810 | tpr=0.9441 | fpr=0.0183 | 7554.8 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.10599 | acc=0.9809 | tpr=0.9418 | fpr=0.0184 | 7562.7 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.10622 | acc=0.9807 | tpr=0.9424 | fpr=0.0186 | 7893.4 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.10726 | acc=0.9805 | tpr=0.9371 | fpr=0.0187 | 7758.8 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10967 | acc=0.9803 | tpr=0.9377 | fpr=0.0190 | 7706.5 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.10893 | acc=0.9803 | tpr=0.9388 | fpr=0.0189 | 7782.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.10816 | acc=0.9805 | tpr=0.9383 | fpr=0.0187 | 13598.3 samples/s | 53.1 steps/s
Avg test loss: 0.10791, Avg test acc: 0.98051, Avg tpr: 0.93740, Avg fpr: 0.01870, total FA: 2597

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11084 | acc=0.9777 | tpr=0.9425 | fpr=0.0216 | 4846.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.11659 | acc=0.9781 | tpr=0.9574 | fpr=0.0215 | 7030.1 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.12424 | acc=0.9770 | tpr=0.9553 | fpr=0.0226 | 7376.6 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.12654 | acc=0.9771 | tpr=0.9563 | fpr=0.0226 | 7959.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.12579 | acc=0.9771 | tpr=0.9537 | fpr=0.0225 | 7907.2 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.12775 | acc=0.9768 | tpr=0.9520 | fpr=0.0227 | 7763.4 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.12886 | acc=0.9767 | tpr=0.9537 | fpr=0.0229 | 7694.9 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.13008 | acc=0.9766 | tpr=0.9530 | fpr=0.0230 | 7575.0 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.13211 | acc=0.9762 | tpr=0.9537 | fpr=0.0233 | 7760.6 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13113 | acc=0.9764 | tpr=0.9551 | fpr=0.0232 | 7648.4 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.12992 | acc=0.9767 | tpr=0.9538 | fpr=0.0229 | 13837.4 samples/s | 54.1 steps/s
Avg test loss: 0.12960, Avg test acc: 0.97672, Avg tpr: 0.95404, Avg fpr: 0.02287, total FA: 3175

server round 3/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=11.7] | Loss=0.09412 | Reg=0.00370 | acc=0.9219 | L2-Norm=19.235 | L2-Norm(final)=3.071 | 6136.4 samples/s | 95.9 steps/s
[Step=6050 Epoch=11.8] | Loss=0.07896 | Reg=0.00372 | acc=0.9062 | L2-Norm=19.278 | L2-Norm(final)=3.111 | 4454.8 samples/s | 69.6 steps/s
[Step=6100 Epoch=11.9] | Loss=0.07576 | Reg=0.00373 | acc=0.9531 | L2-Norm=19.306 | L2-Norm(final)=3.128 | 5004.4 samples/s | 78.2 steps/s
[Step=6150 Epoch=12.0] | Loss=0.07603 | Reg=0.00374 | acc=0.9375 | L2-Norm=19.328 | L2-Norm(final)=3.144 | 4871.8 samples/s | 76.1 steps/s
[Step=6200 Epoch=12.1] | Loss=0.07526 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.354 | L2-Norm(final)=3.159 | 4987.1 samples/s | 77.9 steps/s
[Step=6250 Epoch=12.2] | Loss=0.07358 | Reg=0.00376 | acc=0.9219 | L2-Norm=19.382 | L2-Norm(final)=3.181 | 4954.8 samples/s | 77.4 steps/s
[Step=6300 Epoch=12.3] | Loss=0.07227 | Reg=0.00377 | acc=0.9531 | L2-Norm=19.408 | L2-Norm(final)=3.199 | 5009.6 samples/s | 78.3 steps/s
[Step=6350 Epoch=12.4] | Loss=0.07088 | Reg=0.00378 | acc=0.9531 | L2-Norm=19.435 | L2-Norm(final)=3.217 | 4941.3 samples/s | 77.2 steps/s
[Step=6400 Epoch=12.5] | Loss=0.07052 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.460 | L2-Norm(final)=3.234 | 5110.0 samples/s | 79.8 steps/s
[Step=6450 Epoch=12.6] | Loss=0.07033 | Reg=0.00380 | acc=0.9062 | L2-Norm=19.485 | L2-Norm(final)=3.252 | 4859.6 samples/s | 75.9 steps/s
[Step=6500 Epoch=12.7] | Loss=0.06971 | Reg=0.00381 | acc=0.9375 | L2-Norm=19.510 | L2-Norm(final)=3.269 | 6678.3 samples/s | 104.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.7] | Loss=0.05947 | Reg=0.00391 | acc=0.9531 | L2-Norm=19.770 | L2-Norm(final)=3.443 | 6623.7 samples/s | 103.5 steps/s
[Step=6550 Epoch=12.8] | Loss=0.07214 | Reg=0.00392 | acc=0.9375 | L2-Norm=19.803 | L2-Norm(final)=3.444 | 4005.5 samples/s | 62.6 steps/s
[Step=6600 Epoch=12.9] | Loss=0.07233 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.827 | L2-Norm(final)=3.433 | 4433.3 samples/s | 69.3 steps/s
[Step=6650 Epoch=13.0] | Loss=0.07174 | Reg=0.00394 | acc=0.9375 | L2-Norm=19.852 | L2-Norm(final)=3.423 | 4348.8 samples/s | 68.0 steps/s
[Step=6700 Epoch=13.1] | Loss=0.06790 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.878 | L2-Norm(final)=3.415 | 4385.3 samples/s | 68.5 steps/s
[Step=6750 Epoch=13.2] | Loss=0.06674 | Reg=0.00396 | acc=0.9375 | L2-Norm=19.901 | L2-Norm(final)=3.408 | 4382.7 samples/s | 68.5 steps/s
[Step=6800 Epoch=13.3] | Loss=0.06631 | Reg=0.00397 | acc=0.8750 | L2-Norm=19.921 | L2-Norm(final)=3.401 | 4508.8 samples/s | 70.4 steps/s
[Step=6850 Epoch=13.4] | Loss=0.06330 | Reg=0.00398 | acc=0.9688 | L2-Norm=19.940 | L2-Norm(final)=3.394 | 4429.9 samples/s | 69.2 steps/s
[Step=6900 Epoch=13.5] | Loss=0.06211 | Reg=0.00398 | acc=0.9219 | L2-Norm=19.957 | L2-Norm(final)=3.388 | 4396.6 samples/s | 68.7 steps/s
[Step=6950 Epoch=13.6] | Loss=0.06044 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.973 | L2-Norm(final)=3.384 | 4523.8 samples/s | 70.7 steps/s
[Step=7000 Epoch=13.7] | Loss=0.05971 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.987 | L2-Norm(final)=3.380 | 5589.5 samples/s | 87.3 steps/s
[Step=7050 Epoch=13.8] | Loss=0.05793 | Reg=0.00400 | acc=0.9844 | L2-Norm=20.001 | L2-Norm(final)=3.376 | 2381.3 samples/s | 37.2 steps/s
[Step=7100 Epoch=13.8] | Loss=0.05661 | Reg=0.00401 | acc=0.9219 | L2-Norm=20.015 | L2-Norm(final)=3.373 | 4446.0 samples/s | 69.5 steps/s
[Step=7150 Epoch=13.9] | Loss=0.05502 | Reg=0.00401 | acc=0.9688 | L2-Norm=20.028 | L2-Norm(final)=3.371 | 4457.3 samples/s | 69.6 steps/s
[Step=7200 Epoch=14.0] | Loss=0.05386 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.040 | L2-Norm(final)=3.369 | 4472.8 samples/s | 69.9 steps/s
[Step=7250 Epoch=14.1] | Loss=0.05258 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.050 | L2-Norm(final)=3.367 | 4410.6 samples/s | 68.9 steps/s
[Step=7300 Epoch=14.2] | Loss=0.05179 | Reg=0.00402 | acc=0.9531 | L2-Norm=20.060 | L2-Norm(final)=3.365 | 4424.6 samples/s | 69.1 steps/s
[Step=7350 Epoch=14.3] | Loss=0.05042 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.069 | L2-Norm(final)=3.363 | 4398.7 samples/s | 68.7 steps/s
[Step=7400 Epoch=14.4] | Loss=0.04989 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.078 | L2-Norm(final)=3.361 | 4439.2 samples/s | 69.4 steps/s
[Step=7450 Epoch=14.5] | Loss=0.04915 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.088 | L2-Norm(final)=3.360 | 4409.6 samples/s | 68.9 steps/s
[Step=7500 Epoch=14.6] | Loss=0.04858 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.097 | L2-Norm(final)=3.359 | 4770.5 samples/s | 74.5 steps/s
[Step=7550 Epoch=14.7] | Loss=0.04781 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.106 | L2-Norm(final)=3.357 | 2602.7 samples/s | 40.7 steps/s
[Step=7600 Epoch=14.8] | Loss=0.04665 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.115 | L2-Norm(final)=3.356 | 4464.1 samples/s | 69.8 steps/s
[Step=7650 Epoch=14.9] | Loss=0.04578 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.124 | L2-Norm(final)=3.356 | 4425.5 samples/s | 69.1 steps/s
[Step=7700 Epoch=15.0] | Loss=0.04497 | Reg=0.00405 | acc=0.9531 | L2-Norm=20.134 | L2-Norm(final)=3.357 | 4483.4 samples/s | 70.1 steps/s
[Step=7750 Epoch=15.1] | Loss=0.04437 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.143 | L2-Norm(final)=3.357 | 4375.6 samples/s | 68.4 steps/s
[Step=7800 Epoch=15.2] | Loss=0.04417 | Reg=0.00406 | acc=0.9375 | L2-Norm=20.153 | L2-Norm(final)=3.357 | 4482.1 samples/s | 70.0 steps/s
[Step=7850 Epoch=15.3] | Loss=0.04370 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.163 | L2-Norm(final)=3.357 | 4281.2 samples/s | 66.9 steps/s
[Step=7900 Epoch=15.4] | Loss=0.04354 | Reg=0.00407 | acc=0.9531 | L2-Norm=20.172 | L2-Norm(final)=3.357 | 4453.9 samples/s | 69.6 steps/s
[Step=7950 Epoch=15.5] | Loss=0.04319 | Reg=0.00407 | acc=0.9688 | L2-Norm=20.182 | L2-Norm(final)=3.357 | 4467.7 samples/s | 69.8 steps/s
[Step=8000 Epoch=15.6] | Loss=0.04287 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.190 | L2-Norm(final)=3.356 | 4394.1 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step8000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=11.7] | Loss=0.05349 | Reg=0.00372 | acc=0.9688 | L2-Norm=19.284 | L2-Norm(final)=3.101 | 5542.1 samples/s | 86.6 steps/s
[Step=6050 Epoch=11.8] | Loss=0.08543 | Reg=0.00374 | acc=0.9219 | L2-Norm=19.329 | L2-Norm(final)=3.127 | 4705.7 samples/s | 73.5 steps/s
[Step=6100 Epoch=11.9] | Loss=0.08408 | Reg=0.00375 | acc=0.9219 | L2-Norm=19.362 | L2-Norm(final)=3.154 | 4854.0 samples/s | 75.8 steps/s
[Step=6150 Epoch=12.0] | Loss=0.08254 | Reg=0.00376 | acc=0.9219 | L2-Norm=19.391 | L2-Norm(final)=3.175 | 5140.6 samples/s | 80.3 steps/s
[Step=6200 Epoch=12.1] | Loss=0.08289 | Reg=0.00377 | acc=0.9219 | L2-Norm=19.421 | L2-Norm(final)=3.196 | 4889.2 samples/s | 76.4 steps/s
[Step=6250 Epoch=12.2] | Loss=0.08065 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.454 | L2-Norm(final)=3.215 | 4947.7 samples/s | 77.3 steps/s
[Step=6300 Epoch=12.3] | Loss=0.07883 | Reg=0.00380 | acc=0.9688 | L2-Norm=19.488 | L2-Norm(final)=3.238 | 4988.9 samples/s | 78.0 steps/s
[Step=6350 Epoch=12.4] | Loss=0.07829 | Reg=0.00381 | acc=0.9375 | L2-Norm=19.521 | L2-Norm(final)=3.258 | 4983.7 samples/s | 77.9 steps/s
[Step=6400 Epoch=12.5] | Loss=0.07715 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.553 | L2-Norm(final)=3.277 | 5066.7 samples/s | 79.2 steps/s
[Step=6450 Epoch=12.6] | Loss=0.07674 | Reg=0.00384 | acc=0.9219 | L2-Norm=19.583 | L2-Norm(final)=3.295 | 5004.2 samples/s | 78.2 steps/s
[Step=6500 Epoch=12.7] | Loss=0.07578 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.613 | L2-Norm(final)=3.314 | 6689.5 samples/s | 104.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.7] | Loss=0.03743 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.909 | L2-Norm(final)=3.506 | 6549.5 samples/s | 102.3 steps/s
[Step=6550 Epoch=12.8] | Loss=0.07537 | Reg=0.00398 | acc=0.9531 | L2-Norm=19.949 | L2-Norm(final)=3.506 | 3994.5 samples/s | 62.4 steps/s
[Step=6600 Epoch=12.9] | Loss=0.07464 | Reg=0.00399 | acc=0.9531 | L2-Norm=19.979 | L2-Norm(final)=3.499 | 4385.4 samples/s | 68.5 steps/s
[Step=6650 Epoch=13.0] | Loss=0.06838 | Reg=0.00400 | acc=0.9531 | L2-Norm=20.006 | L2-Norm(final)=3.495 | 4396.9 samples/s | 68.7 steps/s
[Step=6700 Epoch=13.1] | Loss=0.06855 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.035 | L2-Norm(final)=3.491 | 4402.6 samples/s | 68.8 steps/s
[Step=6750 Epoch=13.2] | Loss=0.06720 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.059 | L2-Norm(final)=3.485 | 4453.4 samples/s | 69.6 steps/s
[Step=6800 Epoch=13.3] | Loss=0.06529 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.079 | L2-Norm(final)=3.480 | 4515.9 samples/s | 70.6 steps/s
[Step=6850 Epoch=13.4] | Loss=0.06440 | Reg=0.00404 | acc=0.9531 | L2-Norm=20.096 | L2-Norm(final)=3.474 | 4426.5 samples/s | 69.2 steps/s
[Step=6900 Epoch=13.5] | Loss=0.06285 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.111 | L2-Norm(final)=3.469 | 4388.0 samples/s | 68.6 steps/s
[Step=6950 Epoch=13.6] | Loss=0.06190 | Reg=0.00405 | acc=0.9531 | L2-Norm=20.124 | L2-Norm(final)=3.465 | 4420.3 samples/s | 69.1 steps/s
[Step=7000 Epoch=13.7] | Loss=0.06147 | Reg=0.00405 | acc=0.9531 | L2-Norm=20.137 | L2-Norm(final)=3.460 | 5861.1 samples/s | 91.6 steps/s
[Step=7050 Epoch=13.8] | Loss=0.05874 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.149 | L2-Norm(final)=3.456 | 2361.9 samples/s | 36.9 steps/s
[Step=7100 Epoch=13.9] | Loss=0.05713 | Reg=0.00406 | acc=0.9531 | L2-Norm=20.161 | L2-Norm(final)=3.454 | 4460.6 samples/s | 69.7 steps/s
[Step=7150 Epoch=14.0] | Loss=0.05598 | Reg=0.00407 | acc=0.9688 | L2-Norm=20.172 | L2-Norm(final)=3.452 | 4516.7 samples/s | 70.6 steps/s
[Step=7200 Epoch=14.1] | Loss=0.05452 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.183 | L2-Norm(final)=3.449 | 4388.8 samples/s | 68.6 steps/s
[Step=7250 Epoch=14.2] | Loss=0.05378 | Reg=0.00408 | acc=0.9375 | L2-Norm=20.192 | L2-Norm(final)=3.447 | 4398.4 samples/s | 68.7 steps/s
[Step=7300 Epoch=14.3] | Loss=0.05301 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.202 | L2-Norm(final)=3.445 | 4509.6 samples/s | 70.5 steps/s
[Step=7350 Epoch=14.4] | Loss=0.05223 | Reg=0.00408 | acc=0.9531 | L2-Norm=20.210 | L2-Norm(final)=3.443 | 4528.6 samples/s | 70.8 steps/s
[Step=7400 Epoch=14.5] | Loss=0.05168 | Reg=0.00409 | acc=0.9531 | L2-Norm=20.219 | L2-Norm(final)=3.441 | 4302.5 samples/s | 67.2 steps/s
[Step=7450 Epoch=14.6] | Loss=0.05104 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.227 | L2-Norm(final)=3.439 | 4422.4 samples/s | 69.1 steps/s
[Step=7500 Epoch=14.7] | Loss=0.05026 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.235 | L2-Norm(final)=3.438 | 4901.6 samples/s | 76.6 steps/s
[Step=7550 Epoch=14.8] | Loss=0.04933 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.244 | L2-Norm(final)=3.437 | 2582.2 samples/s | 40.3 steps/s
[Step=7600 Epoch=14.9] | Loss=0.04834 | Reg=0.00410 | acc=0.9844 | L2-Norm=20.252 | L2-Norm(final)=3.436 | 4413.6 samples/s | 69.0 steps/s
[Step=7650 Epoch=15.0] | Loss=0.04742 | Reg=0.00410 | acc=0.9375 | L2-Norm=20.259 | L2-Norm(final)=3.436 | 4442.0 samples/s | 69.4 steps/s
[Step=7700 Epoch=15.1] | Loss=0.04658 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.266 | L2-Norm(final)=3.435 | 4406.5 samples/s | 68.9 steps/s
[Step=7750 Epoch=15.2] | Loss=0.04623 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.273 | L2-Norm(final)=3.435 | 4509.8 samples/s | 70.5 steps/s
[Step=7800 Epoch=15.2] | Loss=0.04560 | Reg=0.00411 | acc=0.8906 | L2-Norm=20.280 | L2-Norm(final)=3.434 | 4511.5 samples/s | 70.5 steps/s
[Step=7850 Epoch=15.3] | Loss=0.04502 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.287 | L2-Norm(final)=3.434 | 4301.2 samples/s | 67.2 steps/s
[Step=7900 Epoch=15.4] | Loss=0.04443 | Reg=0.00412 | acc=0.9375 | L2-Norm=20.294 | L2-Norm(final)=3.433 | 4438.0 samples/s | 69.3 steps/s
[Step=7950 Epoch=15.5] | Loss=0.04397 | Reg=0.00412 | acc=0.9688 | L2-Norm=20.300 | L2-Norm(final)=3.433 | 4482.0 samples/s | 70.0 steps/s
[Step=8000 Epoch=15.6] | Loss=0.04347 | Reg=0.00412 | acc=0.9375 | L2-Norm=20.305 | L2-Norm(final)=3.432 | 4459.5 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step8000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=23.0] | Loss=0.16926 | Reg=0.00189 | acc=0.8750 | L2-Norm=13.730 | L2-Norm(final)=3.222 | 6671.3 samples/s | 104.2 steps/s
[Step=6050 Epoch=23.2] | Loss=0.02581 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.905 | L2-Norm(final)=3.183 | 3943.2 samples/s | 61.6 steps/s
[Step=6100 Epoch=23.4] | Loss=0.01694 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.973 | L2-Norm(final)=3.178 | 4767.0 samples/s | 74.5 steps/s
[Step=6150 Epoch=23.6] | Loss=0.01429 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.003 | L2-Norm(final)=3.181 | 4675.9 samples/s | 73.1 steps/s
[Step=6200 Epoch=23.8] | Loss=0.01249 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.024 | L2-Norm(final)=3.186 | 4651.8 samples/s | 72.7 steps/s
[Step=6250 Epoch=23.9] | Loss=0.01087 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.041 | L2-Norm(final)=3.194 | 6474.9 samples/s | 101.2 steps/s
[Step=6300 Epoch=24.1] | Loss=0.00987 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.057 | L2-Norm(final)=3.205 | 2394.9 samples/s | 37.4 steps/s
[Step=6350 Epoch=24.3] | Loss=0.00899 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.072 | L2-Norm(final)=3.217 | 5001.9 samples/s | 78.2 steps/s
[Step=6400 Epoch=24.5] | Loss=0.00854 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.086 | L2-Norm(final)=3.230 | 4439.8 samples/s | 69.4 steps/s
[Step=6450 Epoch=24.7] | Loss=0.00799 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.098 | L2-Norm(final)=3.242 | 4674.6 samples/s | 73.0 steps/s
[Step=6500 Epoch=24.9] | Loss=0.00763 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.108 | L2-Norm(final)=3.255 | 5478.8 samples/s | 85.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=24.9] | Loss=0.00147 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.214 | L2-Norm(final)=3.378 | 5743.8 samples/s | 89.7 steps/s
[Step=6550 Epoch=25.1] | Loss=0.02297 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.378 | L2-Norm(final)=3.364 | 3911.8 samples/s | 61.1 steps/s
[Step=6600 Epoch=25.3] | Loss=0.02018 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=3.338 | 4264.3 samples/s | 66.6 steps/s
[Step=6650 Epoch=25.5] | Loss=0.01570 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.594 | L2-Norm(final)=3.324 | 4178.8 samples/s | 65.3 steps/s
[Step=6700 Epoch=25.7] | Loss=0.01267 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=3.320 | 4136.3 samples/s | 64.6 steps/s
[Step=6750 Epoch=25.9] | Loss=0.01088 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=3.320 | 5691.1 samples/s | 88.9 steps/s
[Step=6800 Epoch=26.1] | Loss=0.00941 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=3.320 | 2280.0 samples/s | 35.6 steps/s
[Step=6850 Epoch=26.2] | Loss=0.00811 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=3.322 | 4192.6 samples/s | 65.5 steps/s
[Step=6900 Epoch=26.4] | Loss=0.00723 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.687 | L2-Norm(final)=3.323 | 4259.8 samples/s | 66.6 steps/s
[Step=6950 Epoch=26.6] | Loss=0.00645 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=3.325 | 4223.6 samples/s | 66.0 steps/s
[Step=7000 Epoch=26.8] | Loss=0.00582 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=3.327 | 4620.0 samples/s | 72.2 steps/s
[Step=7050 Epoch=27.0] | Loss=0.00530 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=3.329 | 2470.7 samples/s | 38.6 steps/s
[Step=7100 Epoch=27.2] | Loss=0.00486 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=3.331 | 4173.9 samples/s | 65.2 steps/s
[Step=7150 Epoch=27.4] | Loss=0.00448 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=3.334 | 4367.6 samples/s | 68.2 steps/s
[Step=7200 Epoch=27.6] | Loss=0.00417 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=3.337 | 4063.1 samples/s | 63.5 steps/s
[Step=7250 Epoch=27.8] | Loss=0.00389 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=3.340 | 4215.8 samples/s | 65.9 steps/s
[Step=7300 Epoch=28.0] | Loss=0.00365 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=3.343 | 2624.6 samples/s | 41.0 steps/s
[Step=7350 Epoch=28.2] | Loss=0.00344 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=3.346 | 4259.2 samples/s | 66.6 steps/s
[Step=7400 Epoch=28.4] | Loss=0.00325 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=3.349 | 4084.8 samples/s | 63.8 steps/s
[Step=7450 Epoch=28.5] | Loss=0.00308 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=3.352 | 4257.0 samples/s | 66.5 steps/s
[Step=7500 Epoch=28.7] | Loss=0.00292 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.587 | L2-Norm(final)=3.354 | 4235.4 samples/s | 66.2 steps/s
[Step=7550 Epoch=28.9] | Loss=0.00278 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=3.357 | 2609.5 samples/s | 40.8 steps/s
[Step=7600 Epoch=29.1] | Loss=0.00266 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.559 | L2-Norm(final)=3.360 | 4246.9 samples/s | 66.4 steps/s
[Step=7650 Epoch=29.3] | Loss=0.00254 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=3.363 | 4170.4 samples/s | 65.2 steps/s
[Step=7700 Epoch=29.5] | Loss=0.00244 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=3.366 | 4150.7 samples/s | 64.9 steps/s
[Step=7750 Epoch=29.7] | Loss=0.00234 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.514 | L2-Norm(final)=3.368 | 4298.1 samples/s | 67.2 steps/s
[Step=7800 Epoch=29.9] | Loss=0.00225 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.498 | L2-Norm(final)=3.371 | 6171.9 samples/s | 96.4 steps/s
[Step=7850 Epoch=30.1] | Loss=0.00217 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.482 | L2-Norm(final)=3.374 | 2191.2 samples/s | 34.2 steps/s
[Step=7900 Epoch=30.3] | Loss=0.00209 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.466 | L2-Norm(final)=3.376 | 4180.8 samples/s | 65.3 steps/s
[Step=7950 Epoch=30.5] | Loss=0.00202 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.449 | L2-Norm(final)=3.379 | 4135.3 samples/s | 64.6 steps/s
[Step=8000 Epoch=30.7] | Loss=0.00195 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.432 | L2-Norm(final)=3.381 | 4207.0 samples/s | 65.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step8000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=23.1] | Loss=0.06632 | Reg=0.00206 | acc=0.9219 | L2-Norm=14.356 | L2-Norm(final)=3.042 | 5716.9 samples/s | 89.3 steps/s
[Step=6050 Epoch=23.3] | Loss=0.01406 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.421 | L2-Norm(final)=3.044 | 4078.1 samples/s | 63.7 steps/s
[Step=6100 Epoch=23.5] | Loss=0.01244 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.463 | L2-Norm(final)=3.052 | 4718.9 samples/s | 73.7 steps/s
[Step=6150 Epoch=23.7] | Loss=0.01129 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.500 | L2-Norm(final)=3.064 | 4818.0 samples/s | 75.3 steps/s
[Step=6200 Epoch=23.9] | Loss=0.00969 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=3.079 | 4627.9 samples/s | 72.3 steps/s
[Step=6250 Epoch=24.1] | Loss=0.00929 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.562 | L2-Norm(final)=3.096 | 6748.1 samples/s | 105.4 steps/s
[Step=6300 Epoch=24.3] | Loss=0.00867 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=3.113 | 2409.7 samples/s | 37.7 steps/s
[Step=6350 Epoch=24.4] | Loss=0.00823 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=3.130 | 4644.4 samples/s | 72.6 steps/s
[Step=6400 Epoch=24.6] | Loss=0.00796 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=3.148 | 4680.0 samples/s | 73.1 steps/s
[Step=6450 Epoch=24.8] | Loss=0.00756 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.680 | L2-Norm(final)=3.166 | 4699.5 samples/s | 73.4 steps/s
[Step=6500 Epoch=25.0] | Loss=0.00722 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=3.185 | 5603.3 samples/s | 87.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=25.0] | Loss=0.00117 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=3.370 | 6589.0 samples/s | 103.0 steps/s
[Step=6550 Epoch=25.2] | Loss=0.04393 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=3.323 | 3637.8 samples/s | 56.8 steps/s
[Step=6600 Epoch=25.4] | Loss=0.03099 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.216 | L2-Norm(final)=3.272 | 4339.5 samples/s | 67.8 steps/s
[Step=6650 Epoch=25.6] | Loss=0.02182 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=3.257 | 4117.6 samples/s | 64.3 steps/s
[Step=6700 Epoch=25.8] | Loss=0.01732 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=3.253 | 4231.2 samples/s | 66.1 steps/s
[Step=6750 Epoch=26.0] | Loss=0.01460 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.308 | L2-Norm(final)=3.252 | 5662.6 samples/s | 88.5 steps/s
[Step=6800 Epoch=26.2] | Loss=0.01240 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=3.253 | 2267.4 samples/s | 35.4 steps/s
[Step=6850 Epoch=26.4] | Loss=0.01086 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.318 | L2-Norm(final)=3.255 | 4206.5 samples/s | 65.7 steps/s
[Step=6900 Epoch=26.6] | Loss=0.00956 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=3.256 | 4215.0 samples/s | 65.9 steps/s
[Step=6950 Epoch=26.8] | Loss=0.00851 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=3.259 | 4155.2 samples/s | 64.9 steps/s
[Step=7000 Epoch=26.9] | Loss=0.00767 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=3.261 | 4942.4 samples/s | 77.2 steps/s
[Step=7050 Epoch=27.1] | Loss=0.00698 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.301 | L2-Norm(final)=3.263 | 2421.7 samples/s | 37.8 steps/s
[Step=7100 Epoch=27.3] | Loss=0.00641 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.291 | L2-Norm(final)=3.265 | 4163.1 samples/s | 65.0 steps/s
[Step=7150 Epoch=27.5] | Loss=0.00592 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.281 | L2-Norm(final)=3.266 | 4205.7 samples/s | 65.7 steps/s
[Step=7200 Epoch=27.7] | Loss=0.00550 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=3.268 | 4175.5 samples/s | 65.2 steps/s
[Step=7250 Epoch=27.9] | Loss=0.00513 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=3.270 | 4271.3 samples/s | 66.7 steps/s
[Step=7300 Epoch=28.1] | Loss=0.00481 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.244 | L2-Norm(final)=3.271 | 2604.5 samples/s | 40.7 steps/s
[Step=7350 Epoch=28.3] | Loss=0.00453 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=3.272 | 4196.1 samples/s | 65.6 steps/s
[Step=7400 Epoch=28.5] | Loss=0.00428 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.215 | L2-Norm(final)=3.274 | 4235.5 samples/s | 66.2 steps/s
[Step=7450 Epoch=28.7] | Loss=0.00405 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=3.275 | 4157.9 samples/s | 65.0 steps/s
[Step=7500 Epoch=28.9] | Loss=0.00385 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=3.276 | 4161.6 samples/s | 65.0 steps/s
[Step=7550 Epoch=29.1] | Loss=0.00367 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=3.277 | 2662.5 samples/s | 41.6 steps/s
[Step=7600 Epoch=29.3] | Loss=0.00350 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.153 | L2-Norm(final)=3.278 | 4156.5 samples/s | 64.9 steps/s
[Step=7650 Epoch=29.4] | Loss=0.00335 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=3.279 | 4213.8 samples/s | 65.8 steps/s
[Step=7700 Epoch=29.6] | Loss=0.00321 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=3.280 | 4375.4 samples/s | 68.4 steps/s
[Step=7750 Epoch=29.8] | Loss=0.00308 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=3.281 | 4062.0 samples/s | 63.5 steps/s
[Step=7800 Epoch=30.0] | Loss=0.00297 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=3.282 | 6856.7 samples/s | 107.1 steps/s
[Step=7850 Epoch=30.2] | Loss=0.00286 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=3.282 | 2082.6 samples/s | 32.5 steps/s
[Step=7900 Epoch=30.4] | Loss=0.00275 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=3.283 | 4194.9 samples/s | 65.5 steps/s
[Step=7950 Epoch=30.6] | Loss=0.00266 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=3.284 | 4237.4 samples/s | 66.2 steps/s
[Step=8000 Epoch=30.8] | Loss=0.00257 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=3.285 | 4185.9 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06520 | acc=0.9596 | tpr=0.9682 | fpr=0.0590 | 5041.7 samples/s | 19.7 steps/s
Avg test loss: 0.06740, Avg test acc: 0.95857, Avg tpr: 0.96759, Avg fpr: 0.06127, total FA: 478

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07740 | acc=0.9497 | tpr=0.9488 | fpr=0.0483 | 5122.5 samples/s | 20.0 steps/s
Avg test loss: 0.07849, Avg test acc: 0.95032, Avg tpr: 0.94947, Avg fpr: 0.04781, total FA: 373

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.16752 | acc=0.3135 | tpr=0.0078 | fpr=0.0225 | 5019.2 samples/s | 19.6 steps/s
Avg test loss: 4.17934, Avg test acc: 0.31228, Avg tpr: 0.00828, Avg fpr: 0.01910, total FA: 149

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.96801 | acc=0.3181 | tpr=0.0106 | fpr=0.0141 | 4873.2 samples/s | 19.0 steps/s
Avg test loss: 4.98901, Avg test acc: 0.31549, Avg tpr: 0.01055, Avg fpr: 0.01384, total FA: 108

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.44358 | acc=0.1243 | tpr=0.7301 | fpr=0.8866 | 5090.0 samples/s | 19.9 steps/s
[Step= 100] | Loss=4.42392 | acc=0.1243 | tpr=0.7271 | fpr=0.8870 | 6450.5 samples/s | 25.2 steps/s
[Step= 150] | Loss=4.42643 | acc=0.1240 | tpr=0.7089 | fpr=0.8867 | 7967.8 samples/s | 31.1 steps/s
[Step= 200] | Loss=4.42883 | acc=0.1242 | tpr=0.7060 | fpr=0.8864 | 8016.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=4.42632 | acc=0.1244 | tpr=0.7135 | fpr=0.8863 | 7920.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=4.42296 | acc=0.1250 | tpr=0.7105 | fpr=0.8857 | 7664.8 samples/s | 29.9 steps/s
[Step= 350] | Loss=4.42410 | acc=0.1244 | tpr=0.7076 | fpr=0.8862 | 7784.7 samples/s | 30.4 steps/s
[Step= 400] | Loss=4.42625 | acc=0.1246 | tpr=0.7101 | fpr=0.8861 | 8024.7 samples/s | 31.3 steps/s
[Step= 450] | Loss=4.43064 | acc=0.1250 | tpr=0.7123 | fpr=0.8857 | 7873.6 samples/s | 30.8 steps/s
[Step= 500] | Loss=4.42994 | acc=0.1247 | tpr=0.7079 | fpr=0.8858 | 7786.8 samples/s | 30.4 steps/s
[Step= 550] | Loss=4.43180 | acc=0.1243 | tpr=0.7047 | fpr=0.8862 | 13462.6 samples/s | 52.6 steps/s
Avg test loss: 4.43330, Avg test acc: 0.12425, Avg tpr: 0.70483, Avg fpr: 0.88630, total FA: 123061

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.74170 | acc=0.1335 | tpr=0.8009 | fpr=0.8785 | 4975.8 samples/s | 19.4 steps/s
[Step= 100] | Loss=4.72281 | acc=0.1353 | tpr=0.7932 | fpr=0.8770 | 7077.9 samples/s | 27.6 steps/s
[Step= 150] | Loss=4.72128 | acc=0.1355 | tpr=0.7954 | fpr=0.8766 | 7758.1 samples/s | 30.3 steps/s
[Step= 200] | Loss=4.71144 | acc=0.1348 | tpr=0.7858 | fpr=0.8770 | 7809.9 samples/s | 30.5 steps/s
[Step= 250] | Loss=4.70187 | acc=0.1347 | tpr=0.7738 | fpr=0.8769 | 7885.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=4.69921 | acc=0.1353 | tpr=0.7760 | fpr=0.8764 | 7646.4 samples/s | 29.9 steps/s
[Step= 350] | Loss=4.69680 | acc=0.1351 | tpr=0.7677 | fpr=0.8764 | 7743.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=4.69985 | acc=0.1355 | tpr=0.7659 | fpr=0.8760 | 7872.8 samples/s | 30.8 steps/s
[Step= 450] | Loss=4.70404 | acc=0.1355 | tpr=0.7687 | fpr=0.8760 | 7767.0 samples/s | 30.3 steps/s
[Step= 500] | Loss=4.70835 | acc=0.1353 | tpr=0.7718 | fpr=0.8762 | 7913.3 samples/s | 30.9 steps/s
[Step= 550] | Loss=4.71038 | acc=0.1350 | tpr=0.7680 | fpr=0.8765 | 13696.5 samples/s | 53.5 steps/s
Avg test loss: 4.71124, Avg test acc: 0.13486, Avg tpr: 0.76902, Avg fpr: 0.87666, total FA: 121723

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11619 | acc=0.9797 | tpr=0.9204 | fpr=0.0192 | 4931.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.12308 | acc=0.9789 | tpr=0.9211 | fpr=0.0200 | 7094.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.12906 | acc=0.9780 | tpr=0.9280 | fpr=0.0210 | 7593.3 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.13173 | acc=0.9782 | tpr=0.9344 | fpr=0.0210 | 7724.8 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.12901 | acc=0.9784 | tpr=0.9336 | fpr=0.0208 | 8182.1 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.13128 | acc=0.9783 | tpr=0.9353 | fpr=0.0209 | 7542.2 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.13237 | acc=0.9780 | tpr=0.9374 | fpr=0.0213 | 7932.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.13309 | acc=0.9779 | tpr=0.9344 | fpr=0.0213 | 7928.1 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.13539 | acc=0.9777 | tpr=0.9352 | fpr=0.0215 | 7811.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.13422 | acc=0.9778 | tpr=0.9348 | fpr=0.0214 | 7686.6 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.13314 | acc=0.9780 | tpr=0.9351 | fpr=0.0212 | 14213.4 samples/s | 55.5 steps/s
Avg test loss: 0.13290, Avg test acc: 0.97802, Avg tpr: 0.93502, Avg fpr: 0.02120, total FA: 2943

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13119 | acc=0.9770 | tpr=0.9381 | fpr=0.0223 | 4862.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.13492 | acc=0.9774 | tpr=0.9488 | fpr=0.0220 | 7326.0 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.14234 | acc=0.9761 | tpr=0.9524 | fpr=0.0234 | 7564.3 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.14498 | acc=0.9762 | tpr=0.9574 | fpr=0.0234 | 7854.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.14232 | acc=0.9766 | tpr=0.9546 | fpr=0.0230 | 7990.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14398 | acc=0.9764 | tpr=0.9535 | fpr=0.0232 | 8005.9 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.14530 | acc=0.9762 | tpr=0.9543 | fpr=0.0234 | 7457.0 samples/s | 29.1 steps/s
[Step= 400] | Loss=0.14590 | acc=0.9760 | tpr=0.9530 | fpr=0.0236 | 8089.0 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14843 | acc=0.9755 | tpr=0.9533 | fpr=0.0240 | 7620.1 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.14731 | acc=0.9757 | tpr=0.9529 | fpr=0.0239 | 7799.5 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.14631 | acc=0.9758 | tpr=0.9526 | fpr=0.0237 | 13993.7 samples/s | 54.7 steps/s
Avg test loss: 0.14608, Avg test acc: 0.97585, Avg tpr: 0.95246, Avg fpr: 0.02372, total FA: 3294

server round 4/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=15.6] | Loss=0.08626 | Reg=0.00393 | acc=0.9219 | L2-Norm=19.816 | L2-Norm(final)=3.334 | 6386.8 samples/s | 99.8 steps/s
[Step=8050 Epoch=15.7] | Loss=0.08322 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.876 | L2-Norm(final)=3.395 | 4543.0 samples/s | 71.0 steps/s
[Step=8100 Epoch=15.8] | Loss=0.07550 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.933 | L2-Norm(final)=3.443 | 5027.2 samples/s | 78.6 steps/s
[Step=8150 Epoch=15.9] | Loss=0.07329 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.980 | L2-Norm(final)=3.475 | 5022.8 samples/s | 78.5 steps/s
[Step=8200 Epoch=16.0] | Loss=0.07221 | Reg=0.00401 | acc=0.9688 | L2-Norm=20.026 | L2-Norm(final)=3.507 | 4877.0 samples/s | 76.2 steps/s
[Step=8250 Epoch=16.1] | Loss=0.07178 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.071 | L2-Norm(final)=3.537 | 4981.4 samples/s | 77.8 steps/s
[Step=8300 Epoch=16.2] | Loss=0.07127 | Reg=0.00405 | acc=0.9375 | L2-Norm=20.113 | L2-Norm(final)=3.565 | 5037.6 samples/s | 78.7 steps/s
[Step=8350 Epoch=16.3] | Loss=0.07014 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.152 | L2-Norm(final)=3.594 | 4892.2 samples/s | 76.4 steps/s
[Step=8400 Epoch=16.4] | Loss=0.06915 | Reg=0.00408 | acc=0.9375 | L2-Norm=20.191 | L2-Norm(final)=3.623 | 4970.6 samples/s | 77.7 steps/s
[Step=8450 Epoch=16.5] | Loss=0.06814 | Reg=0.00409 | acc=0.9688 | L2-Norm=20.231 | L2-Norm(final)=3.651 | 5016.7 samples/s | 78.4 steps/s
[Step=8500 Epoch=16.6] | Loss=0.06725 | Reg=0.00411 | acc=0.9531 | L2-Norm=20.271 | L2-Norm(final)=3.680 | 6774.8 samples/s | 105.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.6] | Loss=0.08152 | Reg=0.00427 | acc=0.9531 | L2-Norm=20.662 | L2-Norm(final)=3.964 | 6414.0 samples/s | 100.2 steps/s
[Step=8550 Epoch=16.7] | Loss=0.05728 | Reg=0.00429 | acc=0.9375 | L2-Norm=20.707 | L2-Norm(final)=3.972 | 4021.5 samples/s | 62.8 steps/s
[Step=8600 Epoch=16.8] | Loss=0.06634 | Reg=0.00430 | acc=0.9375 | L2-Norm=20.737 | L2-Norm(final)=3.956 | 4419.3 samples/s | 69.1 steps/s
[Step=8650 Epoch=16.9] | Loss=0.06597 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.766 | L2-Norm(final)=3.943 | 4414.4 samples/s | 69.0 steps/s
[Step=8700 Epoch=17.0] | Loss=0.06381 | Reg=0.00432 | acc=0.9688 | L2-Norm=20.788 | L2-Norm(final)=3.929 | 4387.3 samples/s | 68.6 steps/s
[Step=8750 Epoch=17.1] | Loss=0.06048 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.805 | L2-Norm(final)=3.918 | 4423.6 samples/s | 69.1 steps/s
[Step=8800 Epoch=17.2] | Loss=0.05900 | Reg=0.00433 | acc=0.9375 | L2-Norm=20.820 | L2-Norm(final)=3.911 | 4424.6 samples/s | 69.1 steps/s
[Step=8850 Epoch=17.3] | Loss=0.05870 | Reg=0.00434 | acc=0.9375 | L2-Norm=20.834 | L2-Norm(final)=3.902 | 4399.6 samples/s | 68.7 steps/s
[Step=8900 Epoch=17.4] | Loss=0.05778 | Reg=0.00435 | acc=0.9375 | L2-Norm=20.848 | L2-Norm(final)=3.895 | 4504.0 samples/s | 70.4 steps/s
[Step=8950 Epoch=17.5] | Loss=0.05604 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.859 | L2-Norm(final)=3.888 | 4526.5 samples/s | 70.7 steps/s
[Step=9000 Epoch=17.6] | Loss=0.05494 | Reg=0.00436 | acc=0.9219 | L2-Norm=20.871 | L2-Norm(final)=3.882 | 5556.6 samples/s | 86.8 steps/s
[Step=9050 Epoch=17.7] | Loss=0.05309 | Reg=0.00436 | acc=0.9531 | L2-Norm=20.881 | L2-Norm(final)=3.878 | 2398.1 samples/s | 37.5 steps/s
[Step=9100 Epoch=17.7] | Loss=0.05124 | Reg=0.00436 | acc=1.0000 | L2-Norm=20.891 | L2-Norm(final)=3.874 | 4342.4 samples/s | 67.8 steps/s
[Step=9150 Epoch=17.8] | Loss=0.04985 | Reg=0.00437 | acc=0.9844 | L2-Norm=20.899 | L2-Norm(final)=3.871 | 4344.8 samples/s | 67.9 steps/s
[Step=9200 Epoch=17.9] | Loss=0.04865 | Reg=0.00437 | acc=0.9531 | L2-Norm=20.906 | L2-Norm(final)=3.869 | 4456.4 samples/s | 69.6 steps/s
[Step=9250 Epoch=18.0] | Loss=0.04766 | Reg=0.00437 | acc=0.9688 | L2-Norm=20.914 | L2-Norm(final)=3.867 | 4487.2 samples/s | 70.1 steps/s
[Step=9300 Epoch=18.1] | Loss=0.04674 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.920 | L2-Norm(final)=3.866 | 4403.9 samples/s | 68.8 steps/s
[Step=9350 Epoch=18.2] | Loss=0.04611 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.927 | L2-Norm(final)=3.864 | 4396.3 samples/s | 68.7 steps/s
[Step=9400 Epoch=18.3] | Loss=0.04541 | Reg=0.00438 | acc=0.9375 | L2-Norm=20.933 | L2-Norm(final)=3.862 | 4495.5 samples/s | 70.2 steps/s
[Step=9450 Epoch=18.4] | Loss=0.04491 | Reg=0.00438 | acc=0.9375 | L2-Norm=20.940 | L2-Norm(final)=3.860 | 4377.0 samples/s | 68.4 steps/s
[Step=9500 Epoch=18.5] | Loss=0.04409 | Reg=0.00439 | acc=0.9531 | L2-Norm=20.946 | L2-Norm(final)=3.857 | 4750.7 samples/s | 74.2 steps/s
[Step=9550 Epoch=18.6] | Loss=0.04337 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.952 | L2-Norm(final)=3.855 | 2643.5 samples/s | 41.3 steps/s
[Step=9600 Epoch=18.7] | Loss=0.04243 | Reg=0.00439 | acc=0.9688 | L2-Norm=20.956 | L2-Norm(final)=3.854 | 4298.2 samples/s | 67.2 steps/s
[Step=9650 Epoch=18.8] | Loss=0.04168 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.961 | L2-Norm(final)=3.853 | 4470.7 samples/s | 69.9 steps/s
[Step=9700 Epoch=18.9] | Loss=0.04112 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.964 | L2-Norm(final)=3.852 | 4470.6 samples/s | 69.9 steps/s
[Step=9750 Epoch=19.0] | Loss=0.04045 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.968 | L2-Norm(final)=3.851 | 4497.3 samples/s | 70.3 steps/s
[Step=9800 Epoch=19.1] | Loss=0.03972 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.972 | L2-Norm(final)=3.850 | 4337.1 samples/s | 67.8 steps/s
[Step=9850 Epoch=19.2] | Loss=0.03931 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.975 | L2-Norm(final)=3.849 | 4457.5 samples/s | 69.6 steps/s
[Step=9900 Epoch=19.3] | Loss=0.03903 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.978 | L2-Norm(final)=3.848 | 4372.2 samples/s | 68.3 steps/s
[Step=9950 Epoch=19.4] | Loss=0.03872 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.982 | L2-Norm(final)=3.847 | 4420.3 samples/s | 69.1 steps/s
[Step=10000 Epoch=19.5] | Loss=0.03863 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.986 | L2-Norm(final)=3.845 | 4488.9 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step10000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=15.6] | Loss=0.14754 | Reg=0.00394 | acc=0.9062 | L2-Norm=19.847 | L2-Norm(final)=3.426 | 5811.0 samples/s | 90.8 steps/s
[Step=8050 Epoch=15.7] | Loss=0.07879 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.886 | L2-Norm(final)=3.472 | 4652.6 samples/s | 72.7 steps/s
[Step=8100 Epoch=15.8] | Loss=0.07977 | Reg=0.00397 | acc=0.9219 | L2-Norm=19.922 | L2-Norm(final)=3.503 | 5015.0 samples/s | 78.4 steps/s
[Step=8150 Epoch=15.9] | Loss=0.07502 | Reg=0.00398 | acc=0.9375 | L2-Norm=19.957 | L2-Norm(final)=3.540 | 5055.4 samples/s | 79.0 steps/s
[Step=8200 Epoch=16.0] | Loss=0.07296 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.994 | L2-Norm(final)=3.577 | 4944.8 samples/s | 77.3 steps/s
[Step=8250 Epoch=16.1] | Loss=0.07279 | Reg=0.00401 | acc=0.9219 | L2-Norm=20.028 | L2-Norm(final)=3.608 | 4997.2 samples/s | 78.1 steps/s
[Step=8300 Epoch=16.2] | Loss=0.07215 | Reg=0.00403 | acc=0.9531 | L2-Norm=20.063 | L2-Norm(final)=3.638 | 4961.1 samples/s | 77.5 steps/s
[Step=8350 Epoch=16.3] | Loss=0.07221 | Reg=0.00404 | acc=0.9531 | L2-Norm=20.097 | L2-Norm(final)=3.666 | 5004.9 samples/s | 78.2 steps/s
[Step=8400 Epoch=16.4] | Loss=0.07171 | Reg=0.00405 | acc=0.9531 | L2-Norm=20.128 | L2-Norm(final)=3.692 | 4917.2 samples/s | 76.8 steps/s
[Step=8450 Epoch=16.5] | Loss=0.07084 | Reg=0.00407 | acc=0.8750 | L2-Norm=20.162 | L2-Norm(final)=3.720 | 5042.8 samples/s | 78.8 steps/s
[Step=8500 Epoch=16.6] | Loss=0.07028 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.195 | L2-Norm(final)=3.746 | 6953.0 samples/s | 108.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.6] | Loss=0.04647 | Reg=0.00421 | acc=0.9531 | L2-Norm=20.514 | L2-Norm(final)=4.003 | 6199.5 samples/s | 96.9 steps/s
[Step=8550 Epoch=16.7] | Loss=0.06293 | Reg=0.00422 | acc=0.9375 | L2-Norm=20.552 | L2-Norm(final)=4.003 | 4026.7 samples/s | 62.9 steps/s
[Step=8600 Epoch=16.8] | Loss=0.06096 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.588 | L2-Norm(final)=3.995 | 4504.3 samples/s | 70.4 steps/s
[Step=8650 Epoch=16.9] | Loss=0.06167 | Reg=0.00425 | acc=0.9219 | L2-Norm=20.615 | L2-Norm(final)=3.989 | 4429.9 samples/s | 69.2 steps/s
[Step=8700 Epoch=17.0] | Loss=0.06007 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.638 | L2-Norm(final)=3.982 | 4403.3 samples/s | 68.8 steps/s
[Step=8750 Epoch=17.1] | Loss=0.06024 | Reg=0.00427 | acc=0.9688 | L2-Norm=20.660 | L2-Norm(final)=3.973 | 4377.8 samples/s | 68.4 steps/s
[Step=8800 Epoch=17.2] | Loss=0.05936 | Reg=0.00428 | acc=0.9375 | L2-Norm=20.680 | L2-Norm(final)=3.964 | 4462.2 samples/s | 69.7 steps/s
[Step=8850 Epoch=17.3] | Loss=0.05895 | Reg=0.00428 | acc=0.9375 | L2-Norm=20.698 | L2-Norm(final)=3.953 | 4386.0 samples/s | 68.5 steps/s
[Step=8900 Epoch=17.4] | Loss=0.05784 | Reg=0.00429 | acc=0.9219 | L2-Norm=20.714 | L2-Norm(final)=3.944 | 4422.8 samples/s | 69.1 steps/s
[Step=8950 Epoch=17.5] | Loss=0.05719 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.728 | L2-Norm(final)=3.935 | 4468.0 samples/s | 69.8 steps/s
[Step=9000 Epoch=17.6] | Loss=0.05555 | Reg=0.00430 | acc=0.9844 | L2-Norm=20.742 | L2-Norm(final)=3.928 | 5848.0 samples/s | 91.4 steps/s
[Step=9050 Epoch=17.7] | Loss=0.05312 | Reg=0.00431 | acc=1.0000 | L2-Norm=20.754 | L2-Norm(final)=3.924 | 2368.0 samples/s | 37.0 steps/s
[Step=9100 Epoch=17.8] | Loss=0.05167 | Reg=0.00431 | acc=0.9375 | L2-Norm=20.765 | L2-Norm(final)=3.920 | 4383.8 samples/s | 68.5 steps/s
[Step=9150 Epoch=17.9] | Loss=0.04995 | Reg=0.00432 | acc=0.9688 | L2-Norm=20.774 | L2-Norm(final)=3.917 | 4348.9 samples/s | 68.0 steps/s
[Step=9200 Epoch=18.0] | Loss=0.04902 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.783 | L2-Norm(final)=3.915 | 4454.2 samples/s | 69.6 steps/s
[Step=9250 Epoch=18.1] | Loss=0.04822 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.792 | L2-Norm(final)=3.912 | 4476.4 samples/s | 69.9 steps/s
[Step=9300 Epoch=18.2] | Loss=0.04710 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.799 | L2-Norm(final)=3.910 | 4399.8 samples/s | 68.7 steps/s
[Step=9350 Epoch=18.3] | Loss=0.04647 | Reg=0.00433 | acc=0.9375 | L2-Norm=20.806 | L2-Norm(final)=3.908 | 4483.2 samples/s | 70.1 steps/s
[Step=9400 Epoch=18.4] | Loss=0.04577 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.812 | L2-Norm(final)=3.906 | 4411.9 samples/s | 68.9 steps/s
[Step=9450 Epoch=18.5] | Loss=0.04540 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.819 | L2-Norm(final)=3.904 | 4433.7 samples/s | 69.3 steps/s
[Step=9500 Epoch=18.6] | Loss=0.04500 | Reg=0.00434 | acc=0.9531 | L2-Norm=20.825 | L2-Norm(final)=3.901 | 4840.8 samples/s | 75.6 steps/s
[Step=9550 Epoch=18.7] | Loss=0.04393 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.831 | L2-Norm(final)=3.899 | 2604.0 samples/s | 40.7 steps/s
[Step=9600 Epoch=18.8] | Loss=0.04306 | Reg=0.00434 | acc=0.9688 | L2-Norm=20.837 | L2-Norm(final)=3.898 | 4397.6 samples/s | 68.7 steps/s
[Step=9650 Epoch=18.9] | Loss=0.04222 | Reg=0.00434 | acc=0.9688 | L2-Norm=20.841 | L2-Norm(final)=3.896 | 4468.7 samples/s | 69.8 steps/s
[Step=9700 Epoch=19.0] | Loss=0.04162 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.845 | L2-Norm(final)=3.895 | 4353.5 samples/s | 68.0 steps/s
[Step=9750 Epoch=19.1] | Loss=0.04099 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.849 | L2-Norm(final)=3.894 | 4480.4 samples/s | 70.0 steps/s
[Step=9800 Epoch=19.2] | Loss=0.04039 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.853 | L2-Norm(final)=3.892 | 4361.9 samples/s | 68.2 steps/s
[Step=9850 Epoch=19.3] | Loss=0.03984 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.857 | L2-Norm(final)=3.891 | 4452.5 samples/s | 69.6 steps/s
[Step=9900 Epoch=19.4] | Loss=0.03941 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.860 | L2-Norm(final)=3.890 | 4371.6 samples/s | 68.3 steps/s
[Step=9950 Epoch=19.5] | Loss=0.03908 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.863 | L2-Norm(final)=3.888 | 4394.6 samples/s | 68.7 steps/s
[Step=10000 Epoch=19.5] | Loss=0.03897 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.867 | L2-Norm(final)=3.886 | 4463.2 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step10000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=30.7] | Loss=0.08221 | Reg=0.00190 | acc=0.9531 | L2-Norm=13.799 | L2-Norm(final)=3.456 | 6203.3 samples/s | 96.9 steps/s
[Step=8050 Epoch=30.8] | Loss=0.01124 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.856 | L2-Norm(final)=3.443 | 4397.4 samples/s | 68.7 steps/s
[Step=8100 Epoch=31.0] | Loss=0.00784 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.901 | L2-Norm(final)=3.450 | 4536.6 samples/s | 70.9 steps/s
[Step=8150 Epoch=31.2] | Loss=0.00656 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.927 | L2-Norm(final)=3.463 | 4777.9 samples/s | 74.7 steps/s
[Step=8200 Epoch=31.4] | Loss=0.00590 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.946 | L2-Norm(final)=3.477 | 4615.4 samples/s | 72.1 steps/s
[Step=8250 Epoch=31.6] | Loss=0.00544 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.960 | L2-Norm(final)=3.491 | 6533.8 samples/s | 102.1 steps/s
[Step=8300 Epoch=31.8] | Loss=0.00495 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.974 | L2-Norm(final)=3.505 | 2430.6 samples/s | 38.0 steps/s
[Step=8350 Epoch=32.0] | Loss=0.00450 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.989 | L2-Norm(final)=3.520 | 4657.1 samples/s | 72.8 steps/s
[Step=8400 Epoch=32.2] | Loss=0.00435 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.003 | L2-Norm(final)=3.536 | 4668.7 samples/s | 72.9 steps/s
[Step=8450 Epoch=32.4] | Loss=0.00413 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.015 | L2-Norm(final)=3.551 | 4875.0 samples/s | 76.2 steps/s
[Step=8500 Epoch=32.6] | Loss=0.00391 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.026 | L2-Norm(final)=3.566 | 5320.1 samples/s | 83.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=32.6] | Loss=0.01696 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.131 | L2-Norm(final)=3.717 | 5841.3 samples/s | 91.3 steps/s
[Step=8550 Epoch=32.8] | Loss=0.03478 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.349 | L2-Norm(final)=3.661 | 4003.4 samples/s | 62.6 steps/s
[Step=8600 Epoch=33.0] | Loss=0.02443 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=3.594 | 4150.6 samples/s | 64.9 steps/s
[Step=8650 Epoch=33.1] | Loss=0.01816 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=3.571 | 4138.2 samples/s | 64.7 steps/s
[Step=8700 Epoch=33.3] | Loss=0.01451 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=3.565 | 4227.3 samples/s | 66.1 steps/s
[Step=8750 Epoch=33.5] | Loss=0.01229 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=3.565 | 5603.7 samples/s | 87.6 steps/s
[Step=8800 Epoch=33.7] | Loss=0.01068 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=3.566 | 2272.7 samples/s | 35.5 steps/s
[Step=8850 Epoch=33.9] | Loss=0.00926 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=3.568 | 4269.9 samples/s | 66.7 steps/s
[Step=8900 Epoch=34.1] | Loss=0.00817 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.731 | L2-Norm(final)=3.571 | 4135.0 samples/s | 64.6 steps/s
[Step=8950 Epoch=34.3] | Loss=0.00730 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=3.574 | 4156.1 samples/s | 64.9 steps/s
[Step=9000 Epoch=34.5] | Loss=0.00658 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=3.578 | 4744.7 samples/s | 74.1 steps/s
[Step=9050 Epoch=34.7] | Loss=0.00598 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=3.582 | 2437.7 samples/s | 38.1 steps/s
[Step=9100 Epoch=34.9] | Loss=0.00549 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=3.587 | 4223.5 samples/s | 66.0 steps/s
[Step=9150 Epoch=35.1] | Loss=0.00507 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=3.592 | 4278.9 samples/s | 66.9 steps/s
[Step=9200 Epoch=35.3] | Loss=0.00471 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=3.596 | 4162.5 samples/s | 65.0 steps/s
[Step=9250 Epoch=35.4] | Loss=0.00440 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=3.601 | 4224.0 samples/s | 66.0 steps/s
[Step=9300 Epoch=35.6] | Loss=0.00412 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=3.605 | 2645.1 samples/s | 41.3 steps/s
[Step=9350 Epoch=35.8] | Loss=0.00388 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=3.609 | 4175.2 samples/s | 65.2 steps/s
[Step=9400 Epoch=36.0] | Loss=0.00367 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=3.613 | 4184.4 samples/s | 65.4 steps/s
[Step=9450 Epoch=36.2] | Loss=0.00347 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=3.617 | 4253.7 samples/s | 66.5 steps/s
[Step=9500 Epoch=36.4] | Loss=0.00330 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=3.621 | 4124.8 samples/s | 64.5 steps/s
[Step=9550 Epoch=36.6] | Loss=0.00314 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=3.625 | 2656.7 samples/s | 41.5 steps/s
[Step=9600 Epoch=36.8] | Loss=0.00300 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=3.628 | 4169.0 samples/s | 65.1 steps/s
[Step=9650 Epoch=37.0] | Loss=0.00287 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=3.632 | 4241.4 samples/s | 66.3 steps/s
[Step=9700 Epoch=37.2] | Loss=0.00275 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.590 | L2-Norm(final)=3.635 | 4178.4 samples/s | 65.3 steps/s
[Step=9750 Epoch=37.4] | Loss=0.00264 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.575 | L2-Norm(final)=3.638 | 4177.6 samples/s | 65.3 steps/s
[Step=9800 Epoch=37.6] | Loss=0.00254 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=3.642 | 6213.0 samples/s | 97.1 steps/s
[Step=9850 Epoch=37.7] | Loss=0.00245 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.545 | L2-Norm(final)=3.645 | 2203.0 samples/s | 34.4 steps/s
[Step=9900 Epoch=37.9] | Loss=0.00236 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=3.648 | 4134.2 samples/s | 64.6 steps/s
[Step=9950 Epoch=38.1] | Loss=0.00228 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.513 | L2-Norm(final)=3.651 | 4323.9 samples/s | 67.6 steps/s
[Step=10000 Epoch=38.3] | Loss=0.00220 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=3.654 | 4253.6 samples/s | 66.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step10000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=30.8] | Loss=0.01500 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.366 | L2-Norm(final)=3.307 | 6085.8 samples/s | 95.1 steps/s
[Step=8050 Epoch=31.0] | Loss=0.00904 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.409 | L2-Norm(final)=3.316 | 4261.3 samples/s | 66.6 steps/s
[Step=8100 Epoch=31.2] | Loss=0.00804 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.442 | L2-Norm(final)=3.338 | 4592.3 samples/s | 71.8 steps/s
[Step=8150 Epoch=31.4] | Loss=0.00722 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.470 | L2-Norm(final)=3.362 | 4733.6 samples/s | 74.0 steps/s
[Step=8200 Epoch=31.6] | Loss=0.00674 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.505 | L2-Norm(final)=3.387 | 4705.2 samples/s | 73.5 steps/s
[Step=8250 Epoch=31.8] | Loss=0.00645 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.535 | L2-Norm(final)=3.412 | 6587.8 samples/s | 102.9 steps/s
[Step=8300 Epoch=31.9] | Loss=0.00575 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=3.436 | 2391.6 samples/s | 37.4 steps/s
[Step=8350 Epoch=32.1] | Loss=0.00529 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.580 | L2-Norm(final)=3.460 | 4674.3 samples/s | 73.0 steps/s
[Step=8400 Epoch=32.3] | Loss=0.00497 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=3.484 | 4762.6 samples/s | 74.4 steps/s
[Step=8450 Epoch=32.5] | Loss=0.00489 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=3.507 | 4712.4 samples/s | 73.6 steps/s
[Step=8500 Epoch=32.7] | Loss=0.00472 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=3.531 | 5459.3 samples/s | 85.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=32.7] | Loss=0.00120 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=3.773 | 6639.6 samples/s | 103.7 steps/s
[Step=8550 Epoch=32.9] | Loss=0.02054 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.941 | L2-Norm(final)=3.769 | 3897.0 samples/s | 60.9 steps/s
[Step=8600 Epoch=33.1] | Loss=0.01609 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=3.746 | 4109.8 samples/s | 64.2 steps/s
[Step=8650 Epoch=33.3] | Loss=0.01459 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=3.735 | 4195.0 samples/s | 65.5 steps/s
[Step=8700 Epoch=33.5] | Loss=0.01141 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=3.733 | 4224.2 samples/s | 66.0 steps/s
[Step=8750 Epoch=33.7] | Loss=0.00960 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=3.734 | 5721.4 samples/s | 89.4 steps/s
[Step=8800 Epoch=33.9] | Loss=0.00808 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=3.736 | 2267.6 samples/s | 35.4 steps/s
[Step=8850 Epoch=34.1] | Loss=0.00695 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=3.738 | 4097.2 samples/s | 64.0 steps/s
[Step=8900 Epoch=34.3] | Loss=0.00609 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=3.741 | 4200.3 samples/s | 65.6 steps/s
[Step=8950 Epoch=34.5] | Loss=0.00542 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=3.743 | 4250.0 samples/s | 66.4 steps/s
[Step=9000 Epoch=34.6] | Loss=0.00489 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=3.746 | 4919.0 samples/s | 76.9 steps/s
[Step=9050 Epoch=34.8] | Loss=0.00445 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.155 | L2-Norm(final)=3.748 | 2417.3 samples/s | 37.8 steps/s
[Step=9100 Epoch=35.0] | Loss=0.00408 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=3.750 | 4275.4 samples/s | 66.8 steps/s
[Step=9150 Epoch=35.2] | Loss=0.00377 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=3.752 | 4121.1 samples/s | 64.4 steps/s
[Step=9200 Epoch=35.4] | Loss=0.00350 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=3.754 | 4211.4 samples/s | 65.8 steps/s
[Step=9250 Epoch=35.6] | Loss=0.00327 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=3.756 | 4277.5 samples/s | 66.8 steps/s
[Step=9300 Epoch=35.8] | Loss=0.00307 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=3.757 | 2630.1 samples/s | 41.1 steps/s
[Step=9350 Epoch=36.0] | Loss=0.00289 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.053 | L2-Norm(final)=3.759 | 4186.1 samples/s | 65.4 steps/s
[Step=9400 Epoch=36.2] | Loss=0.00273 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=3.760 | 4223.8 samples/s | 66.0 steps/s
[Step=9450 Epoch=36.4] | Loss=0.00258 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=3.762 | 4145.6 samples/s | 64.8 steps/s
[Step=9500 Epoch=36.6] | Loss=0.00246 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=3.763 | 4202.0 samples/s | 65.7 steps/s
[Step=9550 Epoch=36.8] | Loss=0.00234 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=3.764 | 2630.8 samples/s | 41.1 steps/s
[Step=9600 Epoch=37.0] | Loss=0.00223 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=3.765 | 4247.3 samples/s | 66.4 steps/s
[Step=9650 Epoch=37.1] | Loss=0.00214 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=3.766 | 4205.1 samples/s | 65.7 steps/s
[Step=9700 Epoch=37.3] | Loss=0.00205 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.909 | L2-Norm(final)=3.767 | 4236.3 samples/s | 66.2 steps/s
[Step=9750 Epoch=37.5] | Loss=0.00197 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=3.768 | 4246.7 samples/s | 66.4 steps/s
[Step=9800 Epoch=37.7] | Loss=0.00189 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=3.769 | 6847.5 samples/s | 107.0 steps/s
[Step=9850 Epoch=37.9] | Loss=0.00182 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=3.770 | 2101.5 samples/s | 32.8 steps/s
[Step=9900 Epoch=38.1] | Loss=0.00176 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.819 | L2-Norm(final)=3.771 | 4210.2 samples/s | 65.8 steps/s
[Step=9950 Epoch=38.3] | Loss=0.00170 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=3.772 | 4213.5 samples/s | 65.8 steps/s
[Step=10000 Epoch=38.5] | Loss=0.00164 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=3.773 | 4234.0 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07465 | acc=0.9584 | tpr=0.9709 | fpr=0.0686 | 5131.4 samples/s | 20.0 steps/s
Avg test loss: 0.07379, Avg test acc: 0.95765, Avg tpr: 0.97016, Avg fpr: 0.06986, total FA: 545

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07189 | acc=0.9604 | tpr=0.9707 | fpr=0.0619 | 5030.1 samples/s | 19.6 steps/s
Avg test loss: 0.07344, Avg test acc: 0.95885, Avg tpr: 0.96899, Avg fpr: 0.06345, total FA: 495

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.12543 | acc=0.3101 | tpr=0.0032 | fpr=0.0235 | 5071.8 samples/s | 19.8 steps/s
Avg test loss: 4.12205, Avg test acc: 0.30784, Avg tpr: 0.00402, Avg fpr: 0.02397, total FA: 187

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.91136 | acc=0.3116 | tpr=0.0067 | fpr=0.0263 | 4866.5 samples/s | 19.0 steps/s
Avg test loss: 5.91729, Avg test acc: 0.31020, Avg tpr: 0.00799, Avg fpr: 0.02512, total FA: 196

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.67048 | acc=0.1246 | tpr=0.7566 | fpr=0.8868 | 5126.4 samples/s | 20.0 steps/s
[Step= 100] | Loss=4.64993 | acc=0.1247 | tpr=0.7569 | fpr=0.8871 | 6942.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.65269 | acc=0.1238 | tpr=0.7478 | fpr=0.8877 | 7557.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=4.64724 | acc=0.1246 | tpr=0.7541 | fpr=0.8869 | 7660.1 samples/s | 29.9 steps/s
[Step= 250] | Loss=4.64140 | acc=0.1246 | tpr=0.7502 | fpr=0.8868 | 8026.3 samples/s | 31.4 steps/s
[Step= 300] | Loss=4.64055 | acc=0.1251 | tpr=0.7455 | fpr=0.8862 | 8020.4 samples/s | 31.3 steps/s
[Step= 350] | Loss=4.64310 | acc=0.1246 | tpr=0.7383 | fpr=0.8866 | 7707.1 samples/s | 30.1 steps/s
[Step= 400] | Loss=4.64591 | acc=0.1249 | tpr=0.7391 | fpr=0.8863 | 7931.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=4.64830 | acc=0.1251 | tpr=0.7400 | fpr=0.8861 | 7827.8 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.64791 | acc=0.1249 | tpr=0.7396 | fpr=0.8862 | 7546.1 samples/s | 29.5 steps/s
[Step= 550] | Loss=4.64931 | acc=0.1247 | tpr=0.7366 | fpr=0.8864 | 14691.7 samples/s | 57.4 steps/s
Avg test loss: 4.65121, Avg test acc: 0.12454, Avg tpr: 0.73574, Avg fpr: 0.88657, total FA: 123099

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.77757 | acc=0.1231 | tpr=0.7965 | fpr=0.8890 | 4936.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.74903 | acc=0.1241 | tpr=0.7804 | fpr=0.8882 | 7054.7 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.75077 | acc=0.1227 | tpr=0.7565 | fpr=0.8890 | 7751.9 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.73916 | acc=0.1220 | tpr=0.7475 | fpr=0.8894 | 7954.2 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.73260 | acc=0.1227 | tpr=0.7485 | fpr=0.8887 | 7541.5 samples/s | 29.5 steps/s
[Step= 300] | Loss=5.73317 | acc=0.1228 | tpr=0.7520 | fpr=0.8887 | 8485.3 samples/s | 33.1 steps/s
[Step= 350] | Loss=5.73181 | acc=0.1224 | tpr=0.7514 | fpr=0.8890 | 7219.1 samples/s | 28.2 steps/s
[Step= 400] | Loss=5.73572 | acc=0.1228 | tpr=0.7527 | fpr=0.8886 | 8900.1 samples/s | 34.8 steps/s
[Step= 450] | Loss=5.74056 | acc=0.1231 | tpr=0.7556 | fpr=0.8884 | 7316.1 samples/s | 28.6 steps/s
[Step= 500] | Loss=5.73965 | acc=0.1232 | tpr=0.7559 | fpr=0.8883 | 7705.9 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.74390 | acc=0.1227 | tpr=0.7509 | fpr=0.8887 | 14223.5 samples/s | 55.6 steps/s
Avg test loss: 5.74527, Avg test acc: 0.12258, Avg tpr: 0.75079, Avg fpr: 0.88884, total FA: 123413

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11269 | acc=0.9799 | tpr=0.9027 | fpr=0.0187 | 5034.1 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.11556 | acc=0.9800 | tpr=0.9211 | fpr=0.0189 | 6797.4 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12012 | acc=0.9792 | tpr=0.9280 | fpr=0.0198 | 7795.0 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.12263 | acc=0.9791 | tpr=0.9322 | fpr=0.0200 | 7915.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.12028 | acc=0.9794 | tpr=0.9293 | fpr=0.0197 | 7534.6 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.12271 | acc=0.9791 | tpr=0.9280 | fpr=0.0200 | 7902.7 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.12330 | acc=0.9789 | tpr=0.9292 | fpr=0.0202 | 7572.0 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.12414 | acc=0.9788 | tpr=0.9256 | fpr=0.0203 | 7712.1 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.12574 | acc=0.9785 | tpr=0.9245 | fpr=0.0205 | 7634.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.12508 | acc=0.9786 | tpr=0.9260 | fpr=0.0205 | 8020.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.12423 | acc=0.9788 | tpr=0.9236 | fpr=0.0202 | 13469.1 samples/s | 52.6 steps/s
Avg test loss: 0.12408, Avg test acc: 0.97878, Avg tpr: 0.92314, Avg fpr: 0.02021, total FA: 2806

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12644 | acc=0.9787 | tpr=0.9248 | fpr=0.0204 | 4661.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.12646 | acc=0.9790 | tpr=0.9382 | fpr=0.0203 | 7613.8 samples/s | 29.7 steps/s
[Step= 150] | Loss=0.13393 | acc=0.9778 | tpr=0.9467 | fpr=0.0216 | 7462.5 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.13709 | acc=0.9777 | tpr=0.9486 | fpr=0.0218 | 7895.4 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.13461 | acc=0.9779 | tpr=0.9450 | fpr=0.0215 | 7582.4 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.13703 | acc=0.9776 | tpr=0.9476 | fpr=0.0219 | 7643.8 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.13773 | acc=0.9774 | tpr=0.9487 | fpr=0.0221 | 7957.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.13890 | acc=0.9772 | tpr=0.9475 | fpr=0.0223 | 7794.9 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.14149 | acc=0.9768 | tpr=0.9469 | fpr=0.0227 | 7651.5 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.14054 | acc=0.9769 | tpr=0.9480 | fpr=0.0225 | 7550.8 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.13961 | acc=0.9771 | tpr=0.9483 | fpr=0.0223 | 14059.4 samples/s | 54.9 steps/s
Avg test loss: 0.13938, Avg test acc: 0.97715, Avg tpr: 0.94810, Avg fpr: 0.02232, total FA: 3099

server round 5/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=19.5] | Loss=0.10642 | Reg=0.00420 | acc=0.9062 | L2-Norm=20.495 | L2-Norm(final)=3.789 | 6609.1 samples/s | 103.3 steps/s
[Step=10050 Epoch=19.6] | Loss=0.07063 | Reg=0.00422 | acc=0.9219 | L2-Norm=20.535 | L2-Norm(final)=3.828 | 4307.6 samples/s | 67.3 steps/s
[Step=10100 Epoch=19.7] | Loss=0.06516 | Reg=0.00423 | acc=0.8906 | L2-Norm=20.578 | L2-Norm(final)=3.869 | 4813.8 samples/s | 75.2 steps/s
[Step=10150 Epoch=19.8] | Loss=0.06341 | Reg=0.00425 | acc=0.9375 | L2-Norm=20.618 | L2-Norm(final)=3.904 | 4919.6 samples/s | 76.9 steps/s
[Step=10200 Epoch=19.9] | Loss=0.06200 | Reg=0.00427 | acc=0.9219 | L2-Norm=20.658 | L2-Norm(final)=3.937 | 5017.8 samples/s | 78.4 steps/s
[Step=10250 Epoch=20.0] | Loss=0.06193 | Reg=0.00428 | acc=0.9531 | L2-Norm=20.694 | L2-Norm(final)=3.965 | 5023.3 samples/s | 78.5 steps/s
[Step=10300 Epoch=20.1] | Loss=0.06122 | Reg=0.00430 | acc=0.9688 | L2-Norm=20.729 | L2-Norm(final)=3.991 | 5007.8 samples/s | 78.2 steps/s
[Step=10350 Epoch=20.2] | Loss=0.05973 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.767 | L2-Norm(final)=4.017 | 4932.7 samples/s | 77.1 steps/s
[Step=10400 Epoch=20.3] | Loss=0.05912 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.801 | L2-Norm(final)=4.043 | 4777.1 samples/s | 74.6 steps/s
[Step=10450 Epoch=20.4] | Loss=0.05881 | Reg=0.00434 | acc=0.9531 | L2-Norm=20.834 | L2-Norm(final)=4.069 | 4863.8 samples/s | 76.0 steps/s
[Step=10500 Epoch=20.5] | Loss=0.05790 | Reg=0.00435 | acc=0.9219 | L2-Norm=20.867 | L2-Norm(final)=4.093 | 6419.3 samples/s | 100.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=20.5] | Loss=0.04768 | Reg=0.00449 | acc=0.9531 | L2-Norm=21.196 | L2-Norm(final)=4.338 | 6429.2 samples/s | 100.5 steps/s
[Step=10550 Epoch=20.6] | Loss=0.06182 | Reg=0.00451 | acc=0.9531 | L2-Norm=21.238 | L2-Norm(final)=4.347 | 3856.5 samples/s | 60.3 steps/s
[Step=10600 Epoch=20.7] | Loss=0.06616 | Reg=0.00453 | acc=0.9375 | L2-Norm=21.283 | L2-Norm(final)=4.311 | 4228.8 samples/s | 66.1 steps/s
[Step=10650 Epoch=20.8] | Loss=0.06207 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.316 | L2-Norm(final)=4.287 | 4277.0 samples/s | 66.8 steps/s
[Step=10700 Epoch=20.9] | Loss=0.05896 | Reg=0.00455 | acc=0.9219 | L2-Norm=21.340 | L2-Norm(final)=4.269 | 4258.0 samples/s | 66.5 steps/s
[Step=10750 Epoch=21.0] | Loss=0.05671 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.357 | L2-Norm(final)=4.254 | 4288.9 samples/s | 67.0 steps/s
[Step=10800 Epoch=21.1] | Loss=0.05606 | Reg=0.00457 | acc=0.9688 | L2-Norm=21.371 | L2-Norm(final)=4.243 | 4290.6 samples/s | 67.0 steps/s
[Step=10850 Epoch=21.2] | Loss=0.05456 | Reg=0.00457 | acc=0.9375 | L2-Norm=21.382 | L2-Norm(final)=4.232 | 4338.1 samples/s | 67.8 steps/s
[Step=10900 Epoch=21.3] | Loss=0.05312 | Reg=0.00458 | acc=0.9531 | L2-Norm=21.392 | L2-Norm(final)=4.222 | 4378.8 samples/s | 68.4 steps/s
[Step=10950 Epoch=21.4] | Loss=0.05174 | Reg=0.00458 | acc=0.9688 | L2-Norm=21.401 | L2-Norm(final)=4.216 | 4441.5 samples/s | 69.4 steps/s
[Step=11000 Epoch=21.5] | Loss=0.05044 | Reg=0.00458 | acc=0.9375 | L2-Norm=21.410 | L2-Norm(final)=4.210 | 5781.4 samples/s | 90.3 steps/s
[Step=11050 Epoch=21.6] | Loss=0.04872 | Reg=0.00459 | acc=0.9844 | L2-Norm=21.419 | L2-Norm(final)=4.206 | 2395.9 samples/s | 37.4 steps/s
[Step=11100 Epoch=21.6] | Loss=0.04719 | Reg=0.00459 | acc=0.9844 | L2-Norm=21.427 | L2-Norm(final)=4.202 | 4444.6 samples/s | 69.4 steps/s
[Step=11150 Epoch=21.7] | Loss=0.04570 | Reg=0.00459 | acc=0.9844 | L2-Norm=21.435 | L2-Norm(final)=4.199 | 4293.7 samples/s | 67.1 steps/s
[Step=11200 Epoch=21.8] | Loss=0.04540 | Reg=0.00460 | acc=0.9844 | L2-Norm=21.443 | L2-Norm(final)=4.196 | 4486.1 samples/s | 70.1 steps/s
[Step=11250 Epoch=21.9] | Loss=0.04485 | Reg=0.00460 | acc=0.9062 | L2-Norm=21.450 | L2-Norm(final)=4.192 | 4366.5 samples/s | 68.2 steps/s
[Step=11300 Epoch=22.0] | Loss=0.04396 | Reg=0.00460 | acc=0.9531 | L2-Norm=21.456 | L2-Norm(final)=4.189 | 4477.2 samples/s | 70.0 steps/s
[Step=11350 Epoch=22.1] | Loss=0.04330 | Reg=0.00461 | acc=1.0000 | L2-Norm=21.462 | L2-Norm(final)=4.185 | 4388.9 samples/s | 68.6 steps/s
[Step=11400 Epoch=22.2] | Loss=0.04281 | Reg=0.00461 | acc=0.9688 | L2-Norm=21.467 | L2-Norm(final)=4.181 | 4440.1 samples/s | 69.4 steps/s
[Step=11450 Epoch=22.3] | Loss=0.04186 | Reg=0.00461 | acc=0.9688 | L2-Norm=21.473 | L2-Norm(final)=4.178 | 4543.8 samples/s | 71.0 steps/s
[Step=11500 Epoch=22.4] | Loss=0.04133 | Reg=0.00461 | acc=1.0000 | L2-Norm=21.478 | L2-Norm(final)=4.175 | 4691.6 samples/s | 73.3 steps/s
[Step=11550 Epoch=22.5] | Loss=0.04036 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.484 | L2-Norm(final)=4.172 | 2605.9 samples/s | 40.7 steps/s
[Step=11600 Epoch=22.6] | Loss=0.03956 | Reg=0.00462 | acc=0.9844 | L2-Norm=21.488 | L2-Norm(final)=4.170 | 4463.5 samples/s | 69.7 steps/s
[Step=11650 Epoch=22.7] | Loss=0.03870 | Reg=0.00462 | acc=1.0000 | L2-Norm=21.492 | L2-Norm(final)=4.169 | 4390.9 samples/s | 68.6 steps/s
[Step=11700 Epoch=22.8] | Loss=0.03826 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.496 | L2-Norm(final)=4.167 | 4468.4 samples/s | 69.8 steps/s
[Step=11750 Epoch=22.9] | Loss=0.03775 | Reg=0.00462 | acc=0.9844 | L2-Norm=21.499 | L2-Norm(final)=4.165 | 4496.9 samples/s | 70.3 steps/s
[Step=11800 Epoch=23.0] | Loss=0.03722 | Reg=0.00462 | acc=0.9844 | L2-Norm=21.502 | L2-Norm(final)=4.163 | 4367.1 samples/s | 68.2 steps/s
[Step=11850 Epoch=23.1] | Loss=0.03680 | Reg=0.00463 | acc=0.9844 | L2-Norm=21.506 | L2-Norm(final)=4.161 | 4518.9 samples/s | 70.6 steps/s
[Step=11900 Epoch=23.2] | Loss=0.03661 | Reg=0.00463 | acc=0.9844 | L2-Norm=21.509 | L2-Norm(final)=4.159 | 4360.5 samples/s | 68.1 steps/s
[Step=11950 Epoch=23.3] | Loss=0.03625 | Reg=0.00463 | acc=0.9844 | L2-Norm=21.512 | L2-Norm(final)=4.157 | 4318.6 samples/s | 67.5 steps/s
[Step=12000 Epoch=23.4] | Loss=0.03603 | Reg=0.00463 | acc=1.0000 | L2-Norm=21.516 | L2-Norm(final)=4.154 | 4471.2 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step12000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=19.6] | Loss=0.06372 | Reg=0.00414 | acc=0.9219 | L2-Norm=20.354 | L2-Norm(final)=3.839 | 6730.7 samples/s | 105.2 steps/s
[Step=10050 Epoch=19.6] | Loss=0.06276 | Reg=0.00416 | acc=0.9688 | L2-Norm=20.387 | L2-Norm(final)=3.869 | 4397.1 samples/s | 68.7 steps/s
[Step=10100 Epoch=19.7] | Loss=0.06096 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.413 | L2-Norm(final)=3.904 | 5035.0 samples/s | 78.7 steps/s
[Step=10150 Epoch=19.8] | Loss=0.05941 | Reg=0.00418 | acc=0.9375 | L2-Norm=20.439 | L2-Norm(final)=3.934 | 5042.8 samples/s | 78.8 steps/s
[Step=10200 Epoch=19.9] | Loss=0.05727 | Reg=0.00419 | acc=0.9219 | L2-Norm=20.469 | L2-Norm(final)=3.964 | 4873.6 samples/s | 76.2 steps/s
[Step=10250 Epoch=20.0] | Loss=0.05672 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.500 | L2-Norm(final)=3.991 | 4972.0 samples/s | 77.7 steps/s
[Step=10300 Epoch=20.1] | Loss=0.05625 | Reg=0.00422 | acc=0.9375 | L2-Norm=20.533 | L2-Norm(final)=4.022 | 5006.5 samples/s | 78.2 steps/s
[Step=10350 Epoch=20.2] | Loss=0.05542 | Reg=0.00423 | acc=0.9688 | L2-Norm=20.565 | L2-Norm(final)=4.051 | 4940.4 samples/s | 77.2 steps/s
[Step=10400 Epoch=20.3] | Loss=0.05515 | Reg=0.00424 | acc=0.9375 | L2-Norm=20.595 | L2-Norm(final)=4.075 | 5063.3 samples/s | 79.1 steps/s
[Step=10450 Epoch=20.4] | Loss=0.05477 | Reg=0.00425 | acc=0.9688 | L2-Norm=20.623 | L2-Norm(final)=4.099 | 4939.8 samples/s | 77.2 steps/s
[Step=10500 Epoch=20.5] | Loss=0.05484 | Reg=0.00426 | acc=0.9531 | L2-Norm=20.650 | L2-Norm(final)=4.122 | 6773.8 samples/s | 105.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=20.5] | Loss=0.04116 | Reg=0.00438 | acc=0.9688 | L2-Norm=20.926 | L2-Norm(final)=4.351 | 5953.2 samples/s | 93.0 steps/s
[Step=10550 Epoch=20.6] | Loss=0.05649 | Reg=0.00439 | acc=0.9531 | L2-Norm=20.959 | L2-Norm(final)=4.363 | 4216.6 samples/s | 65.9 steps/s
[Step=10600 Epoch=20.7] | Loss=0.05256 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.988 | L2-Norm(final)=4.355 | 4529.8 samples/s | 70.8 steps/s
[Step=10650 Epoch=20.8] | Loss=0.05193 | Reg=0.00441 | acc=0.9531 | L2-Norm=21.008 | L2-Norm(final)=4.346 | 4282.6 samples/s | 66.9 steps/s
[Step=10700 Epoch=20.9] | Loss=0.05308 | Reg=0.00442 | acc=0.9688 | L2-Norm=21.033 | L2-Norm(final)=4.338 | 4491.4 samples/s | 70.2 steps/s
[Step=10750 Epoch=21.0] | Loss=0.05261 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.059 | L2-Norm(final)=4.329 | 4298.1 samples/s | 67.2 steps/s
[Step=10800 Epoch=21.1] | Loss=0.05017 | Reg=0.00444 | acc=0.9375 | L2-Norm=21.083 | L2-Norm(final)=4.322 | 4471.3 samples/s | 69.9 steps/s
[Step=10850 Epoch=21.2] | Loss=0.04990 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.104 | L2-Norm(final)=4.315 | 4466.3 samples/s | 69.8 steps/s
[Step=10900 Epoch=21.3] | Loss=0.04963 | Reg=0.00446 | acc=0.9531 | L2-Norm=21.123 | L2-Norm(final)=4.309 | 4397.4 samples/s | 68.7 steps/s
[Step=10950 Epoch=21.4] | Loss=0.04900 | Reg=0.00447 | acc=0.9688 | L2-Norm=21.140 | L2-Norm(final)=4.303 | 4468.7 samples/s | 69.8 steps/s
[Step=11000 Epoch=21.5] | Loss=0.04838 | Reg=0.00448 | acc=0.9688 | L2-Norm=21.156 | L2-Norm(final)=4.298 | 5852.1 samples/s | 91.4 steps/s
[Step=11050 Epoch=21.6] | Loss=0.04715 | Reg=0.00448 | acc=0.9844 | L2-Norm=21.170 | L2-Norm(final)=4.293 | 2410.1 samples/s | 37.7 steps/s
[Step=11100 Epoch=21.7] | Loss=0.04597 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.183 | L2-Norm(final)=4.289 | 4353.5 samples/s | 68.0 steps/s
[Step=11150 Epoch=21.8] | Loss=0.04451 | Reg=0.00449 | acc=0.9688 | L2-Norm=21.194 | L2-Norm(final)=4.285 | 4409.4 samples/s | 68.9 steps/s
[Step=11200 Epoch=21.9] | Loss=0.04351 | Reg=0.00450 | acc=0.9844 | L2-Norm=21.205 | L2-Norm(final)=4.282 | 4374.1 samples/s | 68.3 steps/s
[Step=11250 Epoch=22.0] | Loss=0.04248 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.216 | L2-Norm(final)=4.280 | 4479.0 samples/s | 70.0 steps/s
[Step=11300 Epoch=22.1] | Loss=0.04181 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.226 | L2-Norm(final)=4.279 | 4519.0 samples/s | 70.6 steps/s
[Step=11350 Epoch=22.2] | Loss=0.04110 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.236 | L2-Norm(final)=4.277 | 4388.6 samples/s | 68.6 steps/s
[Step=11400 Epoch=22.3] | Loss=0.04035 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.245 | L2-Norm(final)=4.276 | 4506.8 samples/s | 70.4 steps/s
[Step=11450 Epoch=22.4] | Loss=0.03989 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.253 | L2-Norm(final)=4.274 | 4430.6 samples/s | 69.2 steps/s
[Step=11500 Epoch=22.5] | Loss=0.03924 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.261 | L2-Norm(final)=4.273 | 4927.2 samples/s | 77.0 steps/s
[Step=11550 Epoch=22.6] | Loss=0.03861 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.269 | L2-Norm(final)=4.272 | 2581.2 samples/s | 40.3 steps/s
[Step=11600 Epoch=22.7] | Loss=0.03783 | Reg=0.00453 | acc=0.9531 | L2-Norm=21.276 | L2-Norm(final)=4.271 | 4359.3 samples/s | 68.1 steps/s
[Step=11650 Epoch=22.8] | Loss=0.03726 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.282 | L2-Norm(final)=4.270 | 4415.1 samples/s | 69.0 steps/s
[Step=11700 Epoch=22.9] | Loss=0.03677 | Reg=0.00453 | acc=0.9688 | L2-Norm=21.289 | L2-Norm(final)=4.269 | 4391.5 samples/s | 68.6 steps/s
[Step=11750 Epoch=23.0] | Loss=0.03635 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.295 | L2-Norm(final)=4.269 | 4537.1 samples/s | 70.9 steps/s
[Step=11800 Epoch=23.1] | Loss=0.03581 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.302 | L2-Norm(final)=4.268 | 4346.2 samples/s | 67.9 steps/s
[Step=11850 Epoch=23.2] | Loss=0.03544 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.309 | L2-Norm(final)=4.268 | 4449.2 samples/s | 69.5 steps/s
[Step=11900 Epoch=23.3] | Loss=0.03512 | Reg=0.00454 | acc=0.9531 | L2-Norm=21.315 | L2-Norm(final)=4.267 | 4479.0 samples/s | 70.0 steps/s
[Step=11950 Epoch=23.4] | Loss=0.03480 | Reg=0.00455 | acc=0.9688 | L2-Norm=21.322 | L2-Norm(final)=4.266 | 4462.9 samples/s | 69.7 steps/s
[Step=12000 Epoch=23.5] | Loss=0.03458 | Reg=0.00455 | acc=0.9688 | L2-Norm=21.329 | L2-Norm(final)=4.265 | 4297.6 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step12000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=38.3] | Loss=0.00129 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.761 | L2-Norm(final)=3.741 | 6329.6 samples/s | 98.9 steps/s
[Step=10050 Epoch=38.5] | Loss=0.00388 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.779 | L2-Norm(final)=3.747 | 4162.2 samples/s | 65.0 steps/s
[Step=10100 Epoch=38.7] | Loss=0.00286 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.794 | L2-Norm(final)=3.765 | 4730.0 samples/s | 73.9 steps/s
[Step=10150 Epoch=38.9] | Loss=0.00243 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.810 | L2-Norm(final)=3.786 | 4642.0 samples/s | 72.5 steps/s
[Step=10200 Epoch=39.1] | Loss=0.00236 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.819 | L2-Norm(final)=3.804 | 4763.2 samples/s | 74.4 steps/s
[Step=10250 Epoch=39.3] | Loss=0.00223 | Reg=0.00191 | acc=0.9844 | L2-Norm=13.829 | L2-Norm(final)=3.821 | 6502.2 samples/s | 101.6 steps/s
[Step=10300 Epoch=39.5] | Loss=0.00202 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.839 | L2-Norm(final)=3.838 | 2401.6 samples/s | 37.5 steps/s
[Step=10350 Epoch=39.7] | Loss=0.00192 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.847 | L2-Norm(final)=3.854 | 4703.3 samples/s | 73.5 steps/s
[Step=10400 Epoch=39.8] | Loss=0.00181 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.854 | L2-Norm(final)=3.871 | 4743.3 samples/s | 74.1 steps/s
[Step=10450 Epoch=40.0] | Loss=0.00170 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.860 | L2-Norm(final)=3.887 | 4635.0 samples/s | 72.4 steps/s
[Step=10500 Epoch=40.2] | Loss=0.00158 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.865 | L2-Norm(final)=3.902 | 5438.0 samples/s | 85.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=40.2] | Loss=0.00014 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.907 | L2-Norm(final)=4.053 | 6252.3 samples/s | 97.7 steps/s
[Step=10550 Epoch=40.4] | Loss=0.01632 | Reg=0.00195 | acc=0.9688 | L2-Norm=13.981 | L2-Norm(final)=4.040 | 3687.3 samples/s | 57.6 steps/s
[Step=10600 Epoch=40.6] | Loss=0.02424 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.185 | L2-Norm(final)=3.925 | 4256.3 samples/s | 66.5 steps/s
[Step=10650 Epoch=40.8] | Loss=0.01778 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.290 | L2-Norm(final)=3.871 | 4188.1 samples/s | 65.4 steps/s
[Step=10700 Epoch=41.0] | Loss=0.01397 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.344 | L2-Norm(final)=3.851 | 4093.0 samples/s | 64.0 steps/s
[Step=10750 Epoch=41.2] | Loss=0.01138 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=3.842 | 5699.7 samples/s | 89.1 steps/s
[Step=10800 Epoch=41.4] | Loss=0.00957 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.392 | L2-Norm(final)=3.839 | 2253.9 samples/s | 35.2 steps/s
[Step=10850 Epoch=41.6] | Loss=0.00824 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.402 | L2-Norm(final)=3.837 | 4238.6 samples/s | 66.2 steps/s
[Step=10900 Epoch=41.8] | Loss=0.00722 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.406 | L2-Norm(final)=3.837 | 4204.2 samples/s | 65.7 steps/s
[Step=10950 Epoch=42.0] | Loss=0.00643 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.405 | L2-Norm(final)=3.838 | 4170.7 samples/s | 65.2 steps/s
[Step=11000 Epoch=42.1] | Loss=0.00579 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.402 | L2-Norm(final)=3.839 | 4743.9 samples/s | 74.1 steps/s
[Step=11050 Epoch=42.3] | Loss=0.00527 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.397 | L2-Norm(final)=3.840 | 2445.4 samples/s | 38.2 steps/s
[Step=11100 Epoch=42.5] | Loss=0.00483 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.391 | L2-Norm(final)=3.841 | 4157.8 samples/s | 65.0 steps/s
[Step=11150 Epoch=42.7] | Loss=0.00447 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=3.842 | 4172.0 samples/s | 65.2 steps/s
[Step=11200 Epoch=42.9] | Loss=0.00415 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.373 | L2-Norm(final)=3.844 | 4260.5 samples/s | 66.6 steps/s
[Step=11250 Epoch=43.1] | Loss=0.00387 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.364 | L2-Norm(final)=3.845 | 4217.8 samples/s | 65.9 steps/s
[Step=11300 Epoch=43.3] | Loss=0.00363 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.353 | L2-Norm(final)=3.846 | 2632.0 samples/s | 41.1 steps/s
[Step=11350 Epoch=43.5] | Loss=0.00342 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.342 | L2-Norm(final)=3.848 | 4133.3 samples/s | 64.6 steps/s
[Step=11400 Epoch=43.7] | Loss=0.00323 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.330 | L2-Norm(final)=3.849 | 4160.6 samples/s | 65.0 steps/s
[Step=11450 Epoch=43.9] | Loss=0.00306 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.317 | L2-Norm(final)=3.850 | 4217.6 samples/s | 65.9 steps/s
[Step=11500 Epoch=44.1] | Loss=0.00291 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.305 | L2-Norm(final)=3.851 | 4211.7 samples/s | 65.8 steps/s
[Step=11550 Epoch=44.3] | Loss=0.00277 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.292 | L2-Norm(final)=3.853 | 2678.9 samples/s | 41.9 steps/s
[Step=11600 Epoch=44.4] | Loss=0.00265 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.278 | L2-Norm(final)=3.854 | 4110.1 samples/s | 64.2 steps/s
[Step=11650 Epoch=44.6] | Loss=0.00253 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.264 | L2-Norm(final)=3.855 | 4164.3 samples/s | 65.1 steps/s
[Step=11700 Epoch=44.8] | Loss=0.00243 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.250 | L2-Norm(final)=3.856 | 4196.4 samples/s | 65.6 steps/s
[Step=11750 Epoch=45.0] | Loss=0.00233 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.236 | L2-Norm(final)=3.858 | 4144.8 samples/s | 64.8 steps/s
[Step=11800 Epoch=45.2] | Loss=0.00224 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.221 | L2-Norm(final)=3.859 | 6274.7 samples/s | 98.0 steps/s
[Step=11850 Epoch=45.4] | Loss=0.00216 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=3.860 | 2184.8 samples/s | 34.1 steps/s
[Step=11900 Epoch=45.6] | Loss=0.00208 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.191 | L2-Norm(final)=3.861 | 4313.3 samples/s | 67.4 steps/s
[Step=11950 Epoch=45.8] | Loss=0.00201 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.176 | L2-Norm(final)=3.862 | 4210.3 samples/s | 65.8 steps/s
[Step=12000 Epoch=46.0] | Loss=0.00195 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.160 | L2-Norm(final)=3.863 | 4122.0 samples/s | 64.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step12000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=38.5] | Loss=0.03888 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.175 | L2-Norm(final)=3.796 | 6297.5 samples/s | 98.4 steps/s
[Step=10050 Epoch=38.7] | Loss=0.00671 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.242 | L2-Norm(final)=3.776 | 4023.3 samples/s | 62.9 steps/s
[Step=10100 Epoch=38.9] | Loss=0.00534 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.279 | L2-Norm(final)=3.795 | 4875.8 samples/s | 76.2 steps/s
[Step=10150 Epoch=39.1] | Loss=0.00444 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.310 | L2-Norm(final)=3.815 | 4603.9 samples/s | 71.9 steps/s
[Step=10200 Epoch=39.3] | Loss=0.00401 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.332 | L2-Norm(final)=3.836 | 4665.8 samples/s | 72.9 steps/s
[Step=10250 Epoch=39.5] | Loss=0.00398 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.349 | L2-Norm(final)=3.854 | 6596.4 samples/s | 103.1 steps/s
[Step=10300 Epoch=39.6] | Loss=0.00361 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=3.872 | 2391.7 samples/s | 37.4 steps/s
[Step=10350 Epoch=39.8] | Loss=0.00335 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.378 | L2-Norm(final)=3.891 | 4598.8 samples/s | 71.9 steps/s
[Step=10400 Epoch=40.0] | Loss=0.00319 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.389 | L2-Norm(final)=3.910 | 4771.1 samples/s | 74.5 steps/s
[Step=10450 Epoch=40.2] | Loss=0.00298 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.401 | L2-Norm(final)=3.931 | 4712.0 samples/s | 73.6 steps/s
[Step=10500 Epoch=40.4] | Loss=0.00287 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.412 | L2-Norm(final)=3.952 | 5471.7 samples/s | 85.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=40.4] | Loss=0.00012 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.528 | L2-Norm(final)=4.158 | 5576.1 samples/s | 87.1 steps/s
[Step=10550 Epoch=40.6] | Loss=0.02531 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.685 | L2-Norm(final)=4.122 | 3990.5 samples/s | 62.4 steps/s
[Step=10600 Epoch=40.8] | Loss=0.01996 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.877 | L2-Norm(final)=4.061 | 4197.5 samples/s | 65.6 steps/s
[Step=10650 Epoch=41.0] | Loss=0.01674 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=4.037 | 4230.0 samples/s | 66.1 steps/s
[Step=10700 Epoch=41.2] | Loss=0.01472 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=4.023 | 4166.6 samples/s | 65.1 steps/s
[Step=10750 Epoch=41.4] | Loss=0.01234 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=4.016 | 5783.0 samples/s | 90.4 steps/s
[Step=10800 Epoch=41.6] | Loss=0.01040 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=4.015 | 2249.1 samples/s | 35.1 steps/s
[Step=10850 Epoch=41.8] | Loss=0.00896 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=4.015 | 4219.1 samples/s | 65.9 steps/s
[Step=10900 Epoch=42.0] | Loss=0.00792 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.124 | L2-Norm(final)=4.016 | 4262.0 samples/s | 66.6 steps/s
[Step=10950 Epoch=42.2] | Loss=0.00743 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=4.017 | 4125.9 samples/s | 64.5 steps/s
[Step=11000 Epoch=42.3] | Loss=0.00676 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=4.017 | 4937.1 samples/s | 77.1 steps/s
[Step=11050 Epoch=42.5] | Loss=0.00627 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.138 | L2-Norm(final)=4.018 | 2422.8 samples/s | 37.9 steps/s
[Step=11100 Epoch=42.7] | Loss=0.00576 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.138 | L2-Norm(final)=4.019 | 4215.0 samples/s | 65.9 steps/s
[Step=11150 Epoch=42.9] | Loss=0.00533 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=4.020 | 4195.8 samples/s | 65.6 steps/s
[Step=11200 Epoch=43.1] | Loss=0.00498 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=4.022 | 4131.8 samples/s | 64.6 steps/s
[Step=11250 Epoch=43.3] | Loss=0.00465 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=4.024 | 4333.3 samples/s | 67.7 steps/s
[Step=11300 Epoch=43.5] | Loss=0.00436 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=4.026 | 2586.4 samples/s | 40.4 steps/s
[Step=11350 Epoch=43.7] | Loss=0.00410 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.110 | L2-Norm(final)=4.028 | 4150.9 samples/s | 64.9 steps/s
[Step=11400 Epoch=43.9] | Loss=0.00388 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.100 | L2-Norm(final)=4.030 | 4233.4 samples/s | 66.1 steps/s
[Step=11450 Epoch=44.1] | Loss=0.00367 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=4.032 | 4270.0 samples/s | 66.7 steps/s
[Step=11500 Epoch=44.3] | Loss=0.00349 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=4.033 | 4158.3 samples/s | 65.0 steps/s
[Step=11550 Epoch=44.5] | Loss=0.00333 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=4.035 | 2601.3 samples/s | 40.6 steps/s
[Step=11600 Epoch=44.7] | Loss=0.00317 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.051 | L2-Norm(final)=4.036 | 4162.9 samples/s | 65.0 steps/s
[Step=11650 Epoch=44.8] | Loss=0.00304 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=4.037 | 4241.8 samples/s | 66.3 steps/s
[Step=11700 Epoch=45.0] | Loss=0.00291 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=4.039 | 4210.0 samples/s | 65.8 steps/s
[Step=11750 Epoch=45.2] | Loss=0.00279 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=4.040 | 4258.4 samples/s | 66.5 steps/s
[Step=11800 Epoch=45.4] | Loss=0.00269 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=4.041 | 6684.2 samples/s | 104.4 steps/s
[Step=11850 Epoch=45.6] | Loss=0.00259 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=4.042 | 2118.4 samples/s | 33.1 steps/s
[Step=11900 Epoch=45.8] | Loss=0.00250 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=4.043 | 4124.4 samples/s | 64.4 steps/s
[Step=11950 Epoch=46.0] | Loss=0.00241 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=4.044 | 4217.2 samples/s | 65.9 steps/s
[Step=12000 Epoch=46.2] | Loss=0.00233 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=4.045 | 4234.3 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06300 | acc=0.9595 | tpr=0.9695 | fpr=0.0624 | 5264.3 samples/s | 20.6 steps/s
Avg test loss: 0.06456, Avg test acc: 0.95909, Avg tpr: 0.96969, Avg fpr: 0.06422, total FA: 501

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07044 | acc=0.9597 | tpr=0.9716 | fpr=0.0662 | 5084.9 samples/s | 19.9 steps/s
Avg test loss: 0.07231, Avg test acc: 0.95961, Avg tpr: 0.97272, Avg fpr: 0.06922, total FA: 540

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.07825 | acc=0.3102 | tpr=0.0045 | fpr=0.0258 | 5089.0 samples/s | 19.9 steps/s
Avg test loss: 4.08001, Avg test acc: 0.30768, Avg tpr: 0.00513, Avg fpr: 0.02692, total FA: 210

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.28390 | acc=0.3162 | tpr=0.0095 | fpr=0.0178 | 4909.1 samples/s | 19.2 steps/s
Avg test loss: 6.28364, Avg test acc: 0.31325, Avg tpr: 0.00968, Avg fpr: 0.01910, total FA: 149

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.21440 | acc=0.1245 | tpr=0.7345 | fpr=0.8865 | 5077.2 samples/s | 19.8 steps/s
[Step= 100] | Loss=4.18543 | acc=0.1260 | tpr=0.7356 | fpr=0.8854 | 7008.6 samples/s | 27.4 steps/s
[Step= 150] | Loss=4.18373 | acc=0.1250 | tpr=0.7104 | fpr=0.8857 | 7391.6 samples/s | 28.9 steps/s
[Step= 200] | Loss=4.17687 | acc=0.1249 | tpr=0.7093 | fpr=0.8857 | 7942.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=4.17180 | acc=0.1250 | tpr=0.7092 | fpr=0.8857 | 7654.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=4.17215 | acc=0.1253 | tpr=0.7084 | fpr=0.8853 | 7768.4 samples/s | 30.3 steps/s
[Step= 350] | Loss=4.17095 | acc=0.1249 | tpr=0.7038 | fpr=0.8856 | 8200.2 samples/s | 32.0 steps/s
[Step= 400] | Loss=4.17119 | acc=0.1253 | tpr=0.7095 | fpr=0.8853 | 7797.8 samples/s | 30.5 steps/s
[Step= 450] | Loss=4.17543 | acc=0.1256 | tpr=0.7186 | fpr=0.8851 | 7695.5 samples/s | 30.1 steps/s
[Step= 500] | Loss=4.17518 | acc=0.1258 | tpr=0.7194 | fpr=0.8849 | 7968.9 samples/s | 31.1 steps/s
[Step= 550] | Loss=4.17609 | acc=0.1253 | tpr=0.7195 | fpr=0.8854 | 13508.7 samples/s | 52.8 steps/s
Avg test loss: 4.17728, Avg test acc: 0.12527, Avg tpr: 0.71910, Avg fpr: 0.88553, total FA: 122954

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.26044 | acc=0.1272 | tpr=0.7212 | fpr=0.8835 | 5109.2 samples/s | 20.0 steps/s
[Step= 100] | Loss=5.24418 | acc=0.1271 | tpr=0.7122 | fpr=0.8838 | 6805.7 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.24051 | acc=0.1276 | tpr=0.7061 | fpr=0.8830 | 7919.7 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.23583 | acc=0.1277 | tpr=0.7082 | fpr=0.8829 | 7815.8 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.23362 | acc=0.1279 | tpr=0.7135 | fpr=0.8828 | 7754.4 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.23683 | acc=0.1278 | tpr=0.7105 | fpr=0.8829 | 7611.1 samples/s | 29.7 steps/s
[Step= 350] | Loss=5.23885 | acc=0.1273 | tpr=0.7038 | fpr=0.8832 | 7954.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.23972 | acc=0.1277 | tpr=0.7101 | fpr=0.8829 | 7276.9 samples/s | 28.4 steps/s
[Step= 450] | Loss=5.24905 | acc=0.1278 | tpr=0.7123 | fpr=0.8828 | 8282.0 samples/s | 32.4 steps/s
[Step= 500] | Loss=5.25144 | acc=0.1278 | tpr=0.7154 | fpr=0.8829 | 8136.5 samples/s | 31.8 steps/s
[Step= 550] | Loss=5.25402 | acc=0.1271 | tpr=0.7115 | fpr=0.8835 | 12942.3 samples/s | 50.6 steps/s
Avg test loss: 5.25488, Avg test acc: 0.12700, Avg tpr: 0.71038, Avg fpr: 0.88361, total FA: 122687

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12110 | acc=0.9775 | tpr=0.9336 | fpr=0.0217 | 4854.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.12415 | acc=0.9778 | tpr=0.9339 | fpr=0.0214 | 7237.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.12885 | acc=0.9775 | tpr=0.9352 | fpr=0.0217 | 7698.2 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.13090 | acc=0.9774 | tpr=0.9366 | fpr=0.0219 | 7589.7 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.12838 | acc=0.9777 | tpr=0.9380 | fpr=0.0216 | 8110.5 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.13062 | acc=0.9775 | tpr=0.9382 | fpr=0.0218 | 7673.7 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.13095 | acc=0.9774 | tpr=0.9399 | fpr=0.0219 | 7903.8 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.13197 | acc=0.9772 | tpr=0.9354 | fpr=0.0220 | 7672.1 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.13389 | acc=0.9771 | tpr=0.9338 | fpr=0.0222 | 8091.6 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.13285 | acc=0.9771 | tpr=0.9335 | fpr=0.0221 | 7525.5 samples/s | 29.4 steps/s
[Step= 550] | Loss=0.13177 | acc=0.9773 | tpr=0.9339 | fpr=0.0219 | 14867.7 samples/s | 58.1 steps/s
Avg test loss: 0.13156, Avg test acc: 0.97729, Avg tpr: 0.93384, Avg fpr: 0.02192, total FA: 3043

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11286 | acc=0.9792 | tpr=0.9425 | fpr=0.0201 | 4853.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.11699 | acc=0.9787 | tpr=0.9296 | fpr=0.0204 | 7255.7 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.12295 | acc=0.9776 | tpr=0.9380 | fpr=0.0217 | 7899.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.12488 | acc=0.9777 | tpr=0.9399 | fpr=0.0216 | 7897.4 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.12232 | acc=0.9780 | tpr=0.9328 | fpr=0.0212 | 7608.8 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.12509 | acc=0.9776 | tpr=0.9302 | fpr=0.0216 | 7783.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.12519 | acc=0.9774 | tpr=0.9330 | fpr=0.0217 | 7514.5 samples/s | 29.4 steps/s
[Step= 400] | Loss=0.12653 | acc=0.9774 | tpr=0.9322 | fpr=0.0218 | 8130.2 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.12881 | acc=0.9771 | tpr=0.9328 | fpr=0.0221 | 7806.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.12792 | acc=0.9773 | tpr=0.9335 | fpr=0.0219 | 7822.3 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12707 | acc=0.9775 | tpr=0.9327 | fpr=0.0217 | 14080.8 samples/s | 55.0 steps/s
Avg test loss: 0.12685, Avg test acc: 0.97751, Avg tpr: 0.93225, Avg fpr: 0.02166, total FA: 3008

server round 6/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=23.4] | Loss=0.06018 | Reg=0.00441 | acc=0.9688 | L2-Norm=21.011 | L2-Norm(final)=4.084 | 6654.6 samples/s | 104.0 steps/s
[Step=12050 Epoch=23.5] | Loss=0.06187 | Reg=0.00443 | acc=0.9688 | L2-Norm=21.042 | L2-Norm(final)=4.157 | 4296.9 samples/s | 67.1 steps/s
[Step=12100 Epoch=23.6] | Loss=0.05886 | Reg=0.00445 | acc=0.9531 | L2-Norm=21.084 | L2-Norm(final)=4.209 | 5038.4 samples/s | 78.7 steps/s
[Step=12150 Epoch=23.7] | Loss=0.05672 | Reg=0.00446 | acc=0.9531 | L2-Norm=21.126 | L2-Norm(final)=4.248 | 5036.0 samples/s | 78.7 steps/s
[Step=12200 Epoch=23.8] | Loss=0.05554 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.164 | L2-Norm(final)=4.281 | 4945.9 samples/s | 77.3 steps/s
[Step=12250 Epoch=23.9] | Loss=0.05597 | Reg=0.00449 | acc=0.9375 | L2-Norm=21.200 | L2-Norm(final)=4.312 | 5011.1 samples/s | 78.3 steps/s
[Step=12300 Epoch=24.0] | Loss=0.05489 | Reg=0.00451 | acc=0.9531 | L2-Norm=21.233 | L2-Norm(final)=4.341 | 4994.3 samples/s | 78.0 steps/s
[Step=12350 Epoch=24.1] | Loss=0.05441 | Reg=0.00452 | acc=0.9531 | L2-Norm=21.265 | L2-Norm(final)=4.371 | 5035.9 samples/s | 78.7 steps/s
[Step=12400 Epoch=24.2] | Loss=0.05331 | Reg=0.00454 | acc=0.9375 | L2-Norm=21.297 | L2-Norm(final)=4.399 | 4867.2 samples/s | 76.0 steps/s
[Step=12450 Epoch=24.3] | Loss=0.05343 | Reg=0.00455 | acc=0.9375 | L2-Norm=21.329 | L2-Norm(final)=4.426 | 5070.0 samples/s | 79.2 steps/s
[Step=12500 Epoch=24.4] | Loss=0.05315 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.360 | L2-Norm(final)=4.451 | 6649.9 samples/s | 103.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=24.4] | Loss=0.03181 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.674 | L2-Norm(final)=4.711 | 6353.0 samples/s | 99.3 steps/s
[Step=12550 Epoch=24.5] | Loss=0.05460 | Reg=0.00472 | acc=0.9688 | L2-Norm=21.717 | L2-Norm(final)=4.719 | 4002.5 samples/s | 62.5 steps/s
[Step=12600 Epoch=24.6] | Loss=0.05796 | Reg=0.00474 | acc=0.9062 | L2-Norm=21.768 | L2-Norm(final)=4.689 | 4458.3 samples/s | 69.7 steps/s
[Step=12650 Epoch=24.7] | Loss=0.05551 | Reg=0.00475 | acc=0.9688 | L2-Norm=21.804 | L2-Norm(final)=4.667 | 4510.9 samples/s | 70.5 steps/s
[Step=12700 Epoch=24.8] | Loss=0.05343 | Reg=0.00477 | acc=0.9688 | L2-Norm=21.837 | L2-Norm(final)=4.653 | 4395.8 samples/s | 68.7 steps/s
[Step=12750 Epoch=24.9] | Loss=0.05303 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.865 | L2-Norm(final)=4.641 | 4450.1 samples/s | 69.5 steps/s
[Step=12800 Epoch=25.0] | Loss=0.05060 | Reg=0.00479 | acc=0.9531 | L2-Norm=21.888 | L2-Norm(final)=4.632 | 4355.9 samples/s | 68.1 steps/s
[Step=12850 Epoch=25.1] | Loss=0.04926 | Reg=0.00480 | acc=0.9375 | L2-Norm=21.908 | L2-Norm(final)=4.624 | 4387.9 samples/s | 68.6 steps/s
[Step=12900 Epoch=25.2] | Loss=0.04815 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.924 | L2-Norm(final)=4.617 | 4458.5 samples/s | 69.7 steps/s
[Step=12950 Epoch=25.3] | Loss=0.04654 | Reg=0.00481 | acc=0.9688 | L2-Norm=21.938 | L2-Norm(final)=4.611 | 4482.7 samples/s | 70.0 steps/s
[Step=13000 Epoch=25.4] | Loss=0.04610 | Reg=0.00482 | acc=0.9688 | L2-Norm=21.949 | L2-Norm(final)=4.606 | 5686.3 samples/s | 88.8 steps/s
[Step=13050 Epoch=25.5] | Loss=0.04476 | Reg=0.00482 | acc=0.9844 | L2-Norm=21.959 | L2-Norm(final)=4.600 | 2391.1 samples/s | 37.4 steps/s
[Step=13100 Epoch=25.6] | Loss=0.04318 | Reg=0.00483 | acc=0.9688 | L2-Norm=21.966 | L2-Norm(final)=4.594 | 4453.3 samples/s | 69.6 steps/s
[Step=13150 Epoch=25.6] | Loss=0.04225 | Reg=0.00483 | acc=0.9688 | L2-Norm=21.972 | L2-Norm(final)=4.590 | 4471.8 samples/s | 69.9 steps/s
[Step=13200 Epoch=25.7] | Loss=0.04095 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.977 | L2-Norm(final)=4.585 | 4255.1 samples/s | 66.5 steps/s
[Step=13250 Epoch=25.8] | Loss=0.04009 | Reg=0.00483 | acc=0.9844 | L2-Norm=21.981 | L2-Norm(final)=4.581 | 4447.0 samples/s | 69.5 steps/s
[Step=13300 Epoch=25.9] | Loss=0.03927 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.984 | L2-Norm(final)=4.578 | 4404.5 samples/s | 68.8 steps/s
[Step=13350 Epoch=26.0] | Loss=0.03834 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.987 | L2-Norm(final)=4.575 | 4444.8 samples/s | 69.4 steps/s
[Step=13400 Epoch=26.1] | Loss=0.03749 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.989 | L2-Norm(final)=4.573 | 4578.6 samples/s | 71.5 steps/s
[Step=13450 Epoch=26.2] | Loss=0.03688 | Reg=0.00484 | acc=0.9531 | L2-Norm=21.991 | L2-Norm(final)=4.570 | 4320.2 samples/s | 67.5 steps/s
[Step=13500 Epoch=26.3] | Loss=0.03649 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.992 | L2-Norm(final)=4.567 | 4770.5 samples/s | 74.5 steps/s
[Step=13550 Epoch=26.4] | Loss=0.03587 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.994 | L2-Norm(final)=4.564 | 2608.3 samples/s | 40.8 steps/s
[Step=13600 Epoch=26.5] | Loss=0.03531 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.995 | L2-Norm(final)=4.561 | 4392.9 samples/s | 68.6 steps/s
[Step=13650 Epoch=26.6] | Loss=0.03468 | Reg=0.00484 | acc=1.0000 | L2-Norm=21.996 | L2-Norm(final)=4.559 | 4364.8 samples/s | 68.2 steps/s
[Step=13700 Epoch=26.7] | Loss=0.03422 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.996 | L2-Norm(final)=4.557 | 4465.9 samples/s | 69.8 steps/s
[Step=13750 Epoch=26.8] | Loss=0.03369 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.996 | L2-Norm(final)=4.555 | 4424.4 samples/s | 69.1 steps/s
[Step=13800 Epoch=26.9] | Loss=0.03320 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.997 | L2-Norm(final)=4.553 | 4412.2 samples/s | 68.9 steps/s
[Step=13850 Epoch=27.0] | Loss=0.03302 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.998 | L2-Norm(final)=4.551 | 4462.0 samples/s | 69.7 steps/s
[Step=13900 Epoch=27.1] | Loss=0.03283 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.999 | L2-Norm(final)=4.549 | 4427.7 samples/s | 69.2 steps/s
[Step=13950 Epoch=27.2] | Loss=0.03261 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.001 | L2-Norm(final)=4.547 | 4441.1 samples/s | 69.4 steps/s
[Step=14000 Epoch=27.3] | Loss=0.03234 | Reg=0.00484 | acc=0.9688 | L2-Norm=22.003 | L2-Norm(final)=4.545 | 4377.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step14000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=23.5] | Loss=0.05716 | Reg=0.00437 | acc=0.9844 | L2-Norm=20.910 | L2-Norm(final)=4.231 | 6375.2 samples/s | 99.6 steps/s
[Step=12050 Epoch=23.6] | Loss=0.06796 | Reg=0.00439 | acc=0.9688 | L2-Norm=20.953 | L2-Norm(final)=4.285 | 4486.3 samples/s | 70.1 steps/s
[Step=12100 Epoch=23.7] | Loss=0.06262 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.006 | L2-Norm(final)=4.324 | 5021.4 samples/s | 78.5 steps/s
[Step=12150 Epoch=23.8] | Loss=0.06147 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.057 | L2-Norm(final)=4.361 | 5097.6 samples/s | 79.6 steps/s
[Step=12200 Epoch=23.9] | Loss=0.05902 | Reg=0.00445 | acc=0.9219 | L2-Norm=21.099 | L2-Norm(final)=4.393 | 4884.3 samples/s | 76.3 steps/s
[Step=12250 Epoch=23.9] | Loss=0.05877 | Reg=0.00447 | acc=0.9375 | L2-Norm=21.139 | L2-Norm(final)=4.428 | 5042.0 samples/s | 78.8 steps/s
[Step=12300 Epoch=24.0] | Loss=0.05907 | Reg=0.00448 | acc=0.9531 | L2-Norm=21.176 | L2-Norm(final)=4.456 | 5007.4 samples/s | 78.2 steps/s
[Step=12350 Epoch=24.1] | Loss=0.05875 | Reg=0.00450 | acc=0.9688 | L2-Norm=21.211 | L2-Norm(final)=4.483 | 5028.5 samples/s | 78.6 steps/s
[Step=12400 Epoch=24.2] | Loss=0.05767 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.245 | L2-Norm(final)=4.511 | 4956.4 samples/s | 77.4 steps/s
[Step=12450 Epoch=24.3] | Loss=0.05659 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.278 | L2-Norm(final)=4.539 | 4953.3 samples/s | 77.4 steps/s
[Step=12500 Epoch=24.4] | Loss=0.05610 | Reg=0.00454 | acc=0.9531 | L2-Norm=21.311 | L2-Norm(final)=4.568 | 6855.2 samples/s | 107.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=24.4] | Loss=0.04217 | Reg=0.00468 | acc=0.9688 | L2-Norm=21.634 | L2-Norm(final)=4.848 | 6430.6 samples/s | 100.5 steps/s
[Step=12550 Epoch=24.5] | Loss=0.05311 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.672 | L2-Norm(final)=4.858 | 3958.8 samples/s | 61.9 steps/s
[Step=12600 Epoch=24.6] | Loss=0.05575 | Reg=0.00471 | acc=0.9688 | L2-Norm=21.714 | L2-Norm(final)=4.848 | 4478.5 samples/s | 70.0 steps/s
[Step=12650 Epoch=24.7] | Loss=0.05492 | Reg=0.00473 | acc=0.9375 | L2-Norm=21.750 | L2-Norm(final)=4.834 | 4452.8 samples/s | 69.6 steps/s
[Step=12700 Epoch=24.8] | Loss=0.05465 | Reg=0.00474 | acc=0.9219 | L2-Norm=21.782 | L2-Norm(final)=4.817 | 4376.5 samples/s | 68.4 steps/s
[Step=12750 Epoch=24.9] | Loss=0.05244 | Reg=0.00476 | acc=0.9688 | L2-Norm=21.809 | L2-Norm(final)=4.807 | 4433.0 samples/s | 69.3 steps/s
[Step=12800 Epoch=25.0] | Loss=0.05113 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.833 | L2-Norm(final)=4.798 | 4399.6 samples/s | 68.7 steps/s
[Step=12850 Epoch=25.1] | Loss=0.05075 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.853 | L2-Norm(final)=4.789 | 4434.5 samples/s | 69.3 steps/s
[Step=12900 Epoch=25.2] | Loss=0.04968 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.870 | L2-Norm(final)=4.780 | 4424.1 samples/s | 69.1 steps/s
[Step=12950 Epoch=25.3] | Loss=0.04855 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.886 | L2-Norm(final)=4.772 | 4420.4 samples/s | 69.1 steps/s
[Step=13000 Epoch=25.4] | Loss=0.04721 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.899 | L2-Norm(final)=4.766 | 5860.4 samples/s | 91.6 steps/s
[Step=13050 Epoch=25.5] | Loss=0.04588 | Reg=0.00480 | acc=0.9688 | L2-Norm=21.911 | L2-Norm(final)=4.760 | 2362.8 samples/s | 36.9 steps/s
[Step=13100 Epoch=25.6] | Loss=0.04430 | Reg=0.00480 | acc=0.9531 | L2-Norm=21.920 | L2-Norm(final)=4.756 | 4525.9 samples/s | 70.7 steps/s
[Step=13150 Epoch=25.7] | Loss=0.04294 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.928 | L2-Norm(final)=4.753 | 4358.1 samples/s | 68.1 steps/s
[Step=13200 Epoch=25.8] | Loss=0.04207 | Reg=0.00481 | acc=0.9375 | L2-Norm=21.935 | L2-Norm(final)=4.751 | 4364.2 samples/s | 68.2 steps/s
[Step=13250 Epoch=25.9] | Loss=0.04104 | Reg=0.00481 | acc=0.9531 | L2-Norm=21.942 | L2-Norm(final)=4.749 | 4437.9 samples/s | 69.3 steps/s
[Step=13300 Epoch=26.0] | Loss=0.04006 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.949 | L2-Norm(final)=4.747 | 4427.7 samples/s | 69.2 steps/s
[Step=13350 Epoch=26.1] | Loss=0.03982 | Reg=0.00482 | acc=0.9688 | L2-Norm=21.956 | L2-Norm(final)=4.745 | 4458.2 samples/s | 69.7 steps/s
[Step=13400 Epoch=26.2] | Loss=0.03922 | Reg=0.00482 | acc=0.9844 | L2-Norm=21.963 | L2-Norm(final)=4.743 | 4421.2 samples/s | 69.1 steps/s
[Step=13450 Epoch=26.3] | Loss=0.03895 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.970 | L2-Norm(final)=4.740 | 4458.9 samples/s | 69.7 steps/s
[Step=13500 Epoch=26.4] | Loss=0.03852 | Reg=0.00483 | acc=0.9688 | L2-Norm=21.978 | L2-Norm(final)=4.737 | 4865.5 samples/s | 76.0 steps/s
[Step=13550 Epoch=26.5] | Loss=0.03772 | Reg=0.00483 | acc=0.9688 | L2-Norm=21.985 | L2-Norm(final)=4.735 | 2580.5 samples/s | 40.3 steps/s
[Step=13600 Epoch=26.6] | Loss=0.03714 | Reg=0.00484 | acc=1.0000 | L2-Norm=21.991 | L2-Norm(final)=4.733 | 4388.4 samples/s | 68.6 steps/s
[Step=13650 Epoch=26.7] | Loss=0.03658 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.998 | L2-Norm(final)=4.731 | 4365.3 samples/s | 68.2 steps/s
[Step=13700 Epoch=26.8] | Loss=0.03609 | Reg=0.00484 | acc=0.9688 | L2-Norm=22.005 | L2-Norm(final)=4.730 | 4460.9 samples/s | 69.7 steps/s
[Step=13750 Epoch=26.9] | Loss=0.03576 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.011 | L2-Norm(final)=4.728 | 4491.0 samples/s | 70.2 steps/s
[Step=13800 Epoch=27.0] | Loss=0.03528 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.016 | L2-Norm(final)=4.726 | 4366.7 samples/s | 68.2 steps/s
[Step=13850 Epoch=27.1] | Loss=0.03486 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.021 | L2-Norm(final)=4.724 | 4457.3 samples/s | 69.6 steps/s
[Step=13900 Epoch=27.2] | Loss=0.03446 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.026 | L2-Norm(final)=4.722 | 4465.0 samples/s | 69.8 steps/s
[Step=13950 Epoch=27.3] | Loss=0.03414 | Reg=0.00485 | acc=0.9531 | L2-Norm=22.031 | L2-Norm(final)=4.720 | 4394.5 samples/s | 68.7 steps/s
[Step=14000 Epoch=27.4] | Loss=0.03386 | Reg=0.00486 | acc=0.9844 | L2-Norm=22.036 | L2-Norm(final)=4.718 | 4427.8 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step14000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=46.0] | Loss=0.02183 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.670 | L2-Norm(final)=3.897 | 6309.6 samples/s | 98.6 steps/s
[Step=12050 Epoch=46.2] | Loss=0.00375 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.721 | L2-Norm(final)=3.905 | 4169.6 samples/s | 65.1 steps/s
[Step=12100 Epoch=46.4] | Loss=0.00278 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.743 | L2-Norm(final)=3.915 | 4705.3 samples/s | 73.5 steps/s
[Step=12150 Epoch=46.6] | Loss=0.00230 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.760 | L2-Norm(final)=3.931 | 4678.3 samples/s | 73.1 steps/s
[Step=12200 Epoch=46.7] | Loss=0.00227 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.776 | L2-Norm(final)=3.951 | 4810.9 samples/s | 75.2 steps/s
[Step=12250 Epoch=46.9] | Loss=0.00189 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.791 | L2-Norm(final)=3.970 | 6361.7 samples/s | 99.4 steps/s
[Step=12300 Epoch=47.1] | Loss=0.00173 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.801 | L2-Norm(final)=3.986 | 2416.5 samples/s | 37.8 steps/s
[Step=12350 Epoch=47.3] | Loss=0.00153 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.809 | L2-Norm(final)=4.001 | 4705.8 samples/s | 73.5 steps/s
[Step=12400 Epoch=47.5] | Loss=0.00144 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.816 | L2-Norm(final)=4.016 | 4670.2 samples/s | 73.0 steps/s
[Step=12450 Epoch=47.7] | Loss=0.00134 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.825 | L2-Norm(final)=4.030 | 4741.0 samples/s | 74.1 steps/s
[Step=12500 Epoch=47.9] | Loss=0.00126 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.833 | L2-Norm(final)=4.045 | 5386.7 samples/s | 84.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=47.9] | Loss=0.00003 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.890 | L2-Norm(final)=4.191 | 5638.7 samples/s | 88.1 steps/s
[Step=12550 Epoch=48.1] | Loss=0.01845 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.068 | L2-Norm(final)=4.164 | 3948.8 samples/s | 61.7 steps/s
[Step=12600 Epoch=48.3] | Loss=0.02271 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.343 | L2-Norm(final)=4.071 | 4214.0 samples/s | 65.8 steps/s
[Step=12650 Epoch=48.5] | Loss=0.01791 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.473 | L2-Norm(final)=4.013 | 4156.8 samples/s | 65.0 steps/s
[Step=12700 Epoch=48.7] | Loss=0.01385 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.540 | L2-Norm(final)=3.987 | 4217.6 samples/s | 65.9 steps/s
[Step=12750 Epoch=48.9] | Loss=0.01154 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=3.975 | 5579.3 samples/s | 87.2 steps/s
[Step=12800 Epoch=49.0] | Loss=0.01008 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=3.967 | 2273.2 samples/s | 35.5 steps/s
[Step=12850 Epoch=49.2] | Loss=0.00870 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=3.962 | 4226.9 samples/s | 66.0 steps/s
[Step=12900 Epoch=49.4] | Loss=0.00778 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=3.958 | 4219.8 samples/s | 65.9 steps/s
[Step=12950 Epoch=49.6] | Loss=0.00693 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.644 | L2-Norm(final)=3.956 | 4221.1 samples/s | 66.0 steps/s
[Step=13000 Epoch=49.8] | Loss=0.00624 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=3.955 | 4744.3 samples/s | 74.1 steps/s
[Step=13050 Epoch=50.0] | Loss=0.00568 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=3.954 | 2420.0 samples/s | 37.8 steps/s
[Step=13100 Epoch=50.2] | Loss=0.00521 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=3.954 | 4179.7 samples/s | 65.3 steps/s
[Step=13150 Epoch=50.4] | Loss=0.00481 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=3.954 | 4249.3 samples/s | 66.4 steps/s
[Step=13200 Epoch=50.6] | Loss=0.00447 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=3.954 | 4172.9 samples/s | 65.2 steps/s
[Step=13250 Epoch=50.8] | Loss=0.00417 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=3.954 | 4189.8 samples/s | 65.5 steps/s
[Step=13300 Epoch=51.0] | Loss=0.00391 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=3.954 | 2642.2 samples/s | 41.3 steps/s
[Step=13350 Epoch=51.2] | Loss=0.00368 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=3.955 | 4252.4 samples/s | 66.4 steps/s
[Step=13400 Epoch=51.3] | Loss=0.00348 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=3.955 | 4133.6 samples/s | 64.6 steps/s
[Step=13450 Epoch=51.5] | Loss=0.00329 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=3.955 | 4266.2 samples/s | 66.7 steps/s
[Step=13500 Epoch=51.7] | Loss=0.00313 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.588 | L2-Norm(final)=3.955 | 4093.6 samples/s | 64.0 steps/s
[Step=13550 Epoch=51.9] | Loss=0.00298 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=3.956 | 2648.3 samples/s | 41.4 steps/s
[Step=13600 Epoch=52.1] | Loss=0.00285 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.567 | L2-Norm(final)=3.956 | 4297.2 samples/s | 67.1 steps/s
[Step=13650 Epoch=52.3] | Loss=0.00272 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.555 | L2-Norm(final)=3.956 | 4071.8 samples/s | 63.6 steps/s
[Step=13700 Epoch=52.5] | Loss=0.00261 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=3.957 | 4281.1 samples/s | 66.9 steps/s
[Step=13750 Epoch=52.7] | Loss=0.00251 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=3.957 | 4150.0 samples/s | 64.8 steps/s
[Step=13800 Epoch=52.9] | Loss=0.00241 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.519 | L2-Norm(final)=3.958 | 6147.5 samples/s | 96.1 steps/s
[Step=13850 Epoch=53.1] | Loss=0.00232 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.506 | L2-Norm(final)=3.958 | 2193.1 samples/s | 34.3 steps/s
[Step=13900 Epoch=53.3] | Loss=0.00224 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.493 | L2-Norm(final)=3.958 | 4173.2 samples/s | 65.2 steps/s
[Step=13950 Epoch=53.5] | Loss=0.00216 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.480 | L2-Norm(final)=3.959 | 4136.0 samples/s | 64.6 steps/s
[Step=14000 Epoch=53.6] | Loss=0.00209 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.467 | L2-Norm(final)=3.959 | 4231.4 samples/s | 66.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step14000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=46.2] | Loss=0.02729 | Reg=0.00201 | acc=0.9688 | L2-Norm=14.183 | L2-Norm(final)=4.074 | 6756.3 samples/s | 105.6 steps/s
[Step=12050 Epoch=46.4] | Loss=0.00637 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.223 | L2-Norm(final)=4.067 | 4017.2 samples/s | 62.8 steps/s
[Step=12100 Epoch=46.6] | Loss=0.00464 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.255 | L2-Norm(final)=4.086 | 4576.9 samples/s | 71.5 steps/s
[Step=12150 Epoch=46.8] | Loss=0.00415 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.281 | L2-Norm(final)=4.112 | 4580.9 samples/s | 71.6 steps/s
[Step=12200 Epoch=47.0] | Loss=0.00364 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.304 | L2-Norm(final)=4.134 | 4667.0 samples/s | 72.9 steps/s
[Step=12250 Epoch=47.2] | Loss=0.00322 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.329 | L2-Norm(final)=4.158 | 6797.1 samples/s | 106.2 steps/s
[Step=12300 Epoch=47.3] | Loss=0.00279 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.348 | L2-Norm(final)=4.180 | 2401.0 samples/s | 37.5 steps/s
[Step=12350 Epoch=47.5] | Loss=0.00250 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=4.201 | 4619.6 samples/s | 72.2 steps/s
[Step=12400 Epoch=47.7] | Loss=0.00235 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=4.221 | 4702.0 samples/s | 73.5 steps/s
[Step=12450 Epoch=47.9] | Loss=0.00216 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.386 | L2-Norm(final)=4.240 | 4772.9 samples/s | 74.6 steps/s
[Step=12500 Epoch=48.1] | Loss=0.00216 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.395 | L2-Norm(final)=4.258 | 5544.8 samples/s | 86.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=48.1] | Loss=0.00038 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.491 | L2-Norm(final)=4.432 | 5851.9 samples/s | 91.4 steps/s
[Step=12550 Epoch=48.3] | Loss=0.00027 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.480 | L2-Norm(final)=4.445 | 3864.5 samples/s | 60.4 steps/s
[Step=12600 Epoch=48.5] | Loss=0.00896 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.518 | L2-Norm(final)=4.444 | 4160.3 samples/s | 65.0 steps/s
[Step=12650 Epoch=48.7] | Loss=0.01911 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=4.376 | 4375.7 samples/s | 68.4 steps/s
[Step=12700 Epoch=48.9] | Loss=0.01585 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.824 | L2-Norm(final)=4.331 | 4127.2 samples/s | 64.5 steps/s
[Step=12750 Epoch=49.1] | Loss=0.01361 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=4.310 | 5755.4 samples/s | 89.9 steps/s
[Step=12800 Epoch=49.3] | Loss=0.01148 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=4.297 | 2223.7 samples/s | 34.7 steps/s
[Step=12850 Epoch=49.5] | Loss=0.01019 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=4.291 | 4154.1 samples/s | 64.9 steps/s
[Step=12900 Epoch=49.7] | Loss=0.00895 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=4.288 | 4246.8 samples/s | 66.4 steps/s
[Step=12950 Epoch=49.8] | Loss=0.00800 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=4.286 | 4163.8 samples/s | 65.1 steps/s
[Step=13000 Epoch=50.0] | Loss=0.00725 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.049 | L2-Norm(final)=4.286 | 4932.1 samples/s | 77.1 steps/s
[Step=13050 Epoch=50.2] | Loss=0.00661 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=4.287 | 2386.9 samples/s | 37.3 steps/s
[Step=13100 Epoch=50.4] | Loss=0.00607 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=4.288 | 4197.1 samples/s | 65.6 steps/s
[Step=13150 Epoch=50.6] | Loss=0.00560 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=4.290 | 4192.8 samples/s | 65.5 steps/s
[Step=13200 Epoch=50.8] | Loss=0.00521 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=4.293 | 4218.5 samples/s | 65.9 steps/s
[Step=13250 Epoch=51.0] | Loss=0.00486 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=4.295 | 4236.5 samples/s | 66.2 steps/s
[Step=13300 Epoch=51.2] | Loss=0.00456 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=4.297 | 2568.9 samples/s | 40.1 steps/s
[Step=13350 Epoch=51.4] | Loss=0.00429 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=4.299 | 4243.6 samples/s | 66.3 steps/s
[Step=13400 Epoch=51.6] | Loss=0.00405 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=4.301 | 4211.8 samples/s | 65.8 steps/s
[Step=13450 Epoch=51.8] | Loss=0.00384 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=4.303 | 4164.4 samples/s | 65.1 steps/s
[Step=13500 Epoch=52.0] | Loss=0.00365 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=4.305 | 4179.1 samples/s | 65.3 steps/s
[Step=13550 Epoch=52.2] | Loss=0.00348 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=4.307 | 2603.4 samples/s | 40.7 steps/s
[Step=13600 Epoch=52.4] | Loss=0.00332 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.997 | L2-Norm(final)=4.309 | 4189.2 samples/s | 65.5 steps/s
[Step=13650 Epoch=52.5] | Loss=0.00317 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=4.311 | 4222.5 samples/s | 66.0 steps/s
[Step=13700 Epoch=52.7] | Loss=0.00304 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=4.313 | 4250.3 samples/s | 66.4 steps/s
[Step=13750 Epoch=52.9] | Loss=0.00292 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=4.315 | 4192.7 samples/s | 65.5 steps/s
[Step=13800 Epoch=53.1] | Loss=0.00281 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=4.316 | 6718.0 samples/s | 105.0 steps/s
[Step=13850 Epoch=53.3] | Loss=0.00271 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=4.318 | 2104.3 samples/s | 32.9 steps/s
[Step=13900 Epoch=53.5] | Loss=0.00261 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=4.320 | 4187.6 samples/s | 65.4 steps/s
[Step=13950 Epoch=53.7] | Loss=0.00252 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.899 | L2-Norm(final)=4.321 | 4181.7 samples/s | 65.3 steps/s
[Step=14000 Epoch=53.9] | Loss=0.00244 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=4.323 | 4160.4 samples/s | 65.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06641 | acc=0.9578 | tpr=0.9610 | fpr=0.0491 | 5015.6 samples/s | 19.6 steps/s
Avg test loss: 0.06759, Avg test acc: 0.95789, Avg tpr: 0.95990, Avg fpr: 0.04653, total FA: 363

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07014 | acc=0.9584 | tpr=0.9732 | fpr=0.0736 | 4931.0 samples/s | 19.3 steps/s
Avg test loss: 0.07287, Avg test acc: 0.95781, Avg tpr: 0.97068, Avg fpr: 0.07050, total FA: 550

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.37477 | acc=0.3132 | tpr=0.0047 | fpr=0.0168 | 5024.3 samples/s | 19.6 steps/s
Avg test loss: 5.39136, Avg test acc: 0.31028, Avg tpr: 0.00495, Avg fpr: 0.01820, total FA: 142

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.72213 | acc=0.3082 | tpr=0.0092 | fpr=0.0426 | 5092.4 samples/s | 19.9 steps/s
Avg test loss: 5.72252, Avg test acc: 0.30740, Avg tpr: 0.01078, Avg fpr: 0.04025, total FA: 314

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.98149 | acc=0.1466 | tpr=0.6681 | fpr=0.8628 | 4834.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=4.94609 | acc=0.1475 | tpr=0.6333 | fpr=0.8615 | 6983.4 samples/s | 27.3 steps/s
[Step= 150] | Loss=4.94510 | acc=0.1473 | tpr=0.6398 | fpr=0.8618 | 8187.7 samples/s | 32.0 steps/s
[Step= 200] | Loss=4.94123 | acc=0.1475 | tpr=0.6328 | fpr=0.8614 | 7710.9 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.94071 | acc=0.1474 | tpr=0.6454 | fpr=0.8617 | 7979.0 samples/s | 31.2 steps/s
[Step= 300] | Loss=4.93900 | acc=0.1477 | tpr=0.6407 | fpr=0.8613 | 6089.4 samples/s | 23.8 steps/s
[Step= 350] | Loss=4.94060 | acc=0.1473 | tpr=0.6437 | fpr=0.8617 | 8150.9 samples/s | 31.8 steps/s
[Step= 400] | Loss=4.94128 | acc=0.1478 | tpr=0.6433 | fpr=0.8613 | 7490.6 samples/s | 29.3 steps/s
[Step= 450] | Loss=4.94965 | acc=0.1472 | tpr=0.6470 | fpr=0.8619 | 7014.9 samples/s | 27.4 steps/s
[Step= 500] | Loss=4.94758 | acc=0.1470 | tpr=0.6493 | fpr=0.8621 | 8969.1 samples/s | 35.0 steps/s
[Step= 550] | Loss=4.95148 | acc=0.1469 | tpr=0.6502 | fpr=0.8622 | 12163.2 samples/s | 47.5 steps/s
Avg test loss: 4.95323, Avg test acc: 0.14678, Avg tpr: 0.64976, Avg fpr: 0.86237, total FA: 119738

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.59931 | acc=0.1266 | tpr=0.7832 | fpr=0.8852 | 5020.6 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.57395 | acc=0.1264 | tpr=0.7740 | fpr=0.8856 | 6675.1 samples/s | 26.1 steps/s
[Step= 150] | Loss=5.57394 | acc=0.1254 | tpr=0.7723 | fpr=0.8865 | 8606.0 samples/s | 33.6 steps/s
[Step= 200] | Loss=5.56897 | acc=0.1260 | tpr=0.7639 | fpr=0.8856 | 7247.4 samples/s | 28.3 steps/s
[Step= 250] | Loss=5.56390 | acc=0.1269 | tpr=0.7686 | fpr=0.8848 | 5972.4 samples/s | 23.3 steps/s
[Step= 300] | Loss=5.55983 | acc=0.1268 | tpr=0.7665 | fpr=0.8848 | 8068.8 samples/s | 31.5 steps/s
[Step= 350] | Loss=5.56430 | acc=0.1264 | tpr=0.7608 | fpr=0.8851 | 7603.0 samples/s | 29.7 steps/s
[Step= 400] | Loss=5.55759 | acc=0.1270 | tpr=0.7626 | fpr=0.8846 | 7910.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.56504 | acc=0.1270 | tpr=0.7653 | fpr=0.8846 | 7249.0 samples/s | 28.3 steps/s
[Step= 500] | Loss=5.56444 | acc=0.1268 | tpr=0.7648 | fpr=0.8847 | 8547.1 samples/s | 33.4 steps/s
[Step= 550] | Loss=5.56732 | acc=0.1266 | tpr=0.7644 | fpr=0.8850 | 13175.5 samples/s | 51.5 steps/s
Avg test loss: 5.56862, Avg test acc: 0.12643, Avg tpr: 0.76466, Avg fpr: 0.88517, total FA: 122904

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13233 | acc=0.9809 | tpr=0.9159 | fpr=0.0179 | 5050.5 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.13664 | acc=0.9813 | tpr=0.9360 | fpr=0.0178 | 7087.4 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.14376 | acc=0.9807 | tpr=0.9366 | fpr=0.0185 | 7701.2 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.14640 | acc=0.9806 | tpr=0.9355 | fpr=0.0186 | 7814.3 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.14395 | acc=0.9807 | tpr=0.9319 | fpr=0.0184 | 6035.1 samples/s | 23.6 steps/s
[Step= 300] | Loss=0.14633 | acc=0.9804 | tpr=0.9324 | fpr=0.0187 | 7796.0 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.14690 | acc=0.9800 | tpr=0.9317 | fpr=0.0191 | 7822.0 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.14816 | acc=0.9798 | tpr=0.9251 | fpr=0.0192 | 7917.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.15054 | acc=0.9796 | tpr=0.9241 | fpr=0.0194 | 7462.8 samples/s | 29.2 steps/s
[Step= 500] | Loss=0.14946 | acc=0.9796 | tpr=0.9247 | fpr=0.0194 | 7722.0 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.14831 | acc=0.9799 | tpr=0.9240 | fpr=0.0191 | 13345.9 samples/s | 52.1 steps/s
Avg test loss: 0.14803, Avg test acc: 0.97983, Avg tpr: 0.92353, Avg fpr: 0.01914, total FA: 2658

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10020 | acc=0.9805 | tpr=0.9292 | fpr=0.0185 | 5017.5 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.10352 | acc=0.9807 | tpr=0.9446 | fpr=0.0186 | 7179.8 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.11013 | acc=0.9795 | tpr=0.9496 | fpr=0.0200 | 7785.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.11271 | acc=0.9794 | tpr=0.9475 | fpr=0.0201 | 7381.0 samples/s | 28.8 steps/s
[Step= 250] | Loss=0.11072 | acc=0.9795 | tpr=0.9467 | fpr=0.0199 | 6570.7 samples/s | 25.7 steps/s
[Step= 300] | Loss=0.11280 | acc=0.9791 | tpr=0.9455 | fpr=0.0202 | 7662.7 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.11341 | acc=0.9790 | tpr=0.9455 | fpr=0.0204 | 7645.9 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.11418 | acc=0.9789 | tpr=0.9447 | fpr=0.0205 | 6314.5 samples/s | 24.7 steps/s
[Step= 450] | Loss=0.11586 | acc=0.9786 | tpr=0.9455 | fpr=0.0208 | 8266.6 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.11526 | acc=0.9787 | tpr=0.9458 | fpr=0.0207 | 7584.1 samples/s | 29.6 steps/s
[Step= 550] | Loss=0.11442 | acc=0.9788 | tpr=0.9443 | fpr=0.0206 | 14349.0 samples/s | 56.1 steps/s
Avg test loss: 0.11445, Avg test acc: 0.97881, Avg tpr: 0.94374, Avg fpr: 0.02055, total FA: 2854

server round 7/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=27.3] | Loss=0.09688 | Reg=0.00463 | acc=0.9219 | L2-Norm=21.516 | L2-Norm(final)=4.490 | 5727.0 samples/s | 89.5 steps/s
[Step=14050 Epoch=27.4] | Loss=0.06604 | Reg=0.00464 | acc=0.8594 | L2-Norm=21.551 | L2-Norm(final)=4.540 | 4764.6 samples/s | 74.4 steps/s
[Step=14100 Epoch=27.5] | Loss=0.06096 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.593 | L2-Norm(final)=4.574 | 4832.0 samples/s | 75.5 steps/s
[Step=14150 Epoch=27.6] | Loss=0.05902 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.635 | L2-Norm(final)=4.607 | 4885.7 samples/s | 76.3 steps/s
[Step=14200 Epoch=27.7] | Loss=0.05740 | Reg=0.00470 | acc=0.9375 | L2-Norm=21.677 | L2-Norm(final)=4.638 | 4927.9 samples/s | 77.0 steps/s
[Step=14250 Epoch=27.8] | Loss=0.05578 | Reg=0.00472 | acc=0.9219 | L2-Norm=21.716 | L2-Norm(final)=4.668 | 4874.8 samples/s | 76.2 steps/s
[Step=14300 Epoch=27.9] | Loss=0.05461 | Reg=0.00473 | acc=0.9531 | L2-Norm=21.756 | L2-Norm(final)=4.697 | 4978.2 samples/s | 77.8 steps/s
[Step=14350 Epoch=28.0] | Loss=0.05345 | Reg=0.00475 | acc=0.9688 | L2-Norm=21.797 | L2-Norm(final)=4.725 | 4835.2 samples/s | 75.6 steps/s
[Step=14400 Epoch=28.1] | Loss=0.05272 | Reg=0.00477 | acc=0.9219 | L2-Norm=21.835 | L2-Norm(final)=4.753 | 4873.3 samples/s | 76.1 steps/s
[Step=14450 Epoch=28.2] | Loss=0.05157 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.873 | L2-Norm(final)=4.781 | 4959.4 samples/s | 77.5 steps/s
[Step=14500 Epoch=28.3] | Loss=0.05142 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.909 | L2-Norm(final)=4.807 | 6510.7 samples/s | 101.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=28.3] | Loss=0.03823 | Reg=0.00496 | acc=0.9844 | L2-Norm=22.267 | L2-Norm(final)=5.061 | 6436.9 samples/s | 100.6 steps/s
[Step=14550 Epoch=28.4] | Loss=0.04686 | Reg=0.00497 | acc=0.9531 | L2-Norm=22.298 | L2-Norm(final)=5.071 | 3891.6 samples/s | 60.8 steps/s
[Step=14600 Epoch=28.5] | Loss=0.04747 | Reg=0.00499 | acc=0.9844 | L2-Norm=22.331 | L2-Norm(final)=5.049 | 4345.9 samples/s | 67.9 steps/s
[Step=14650 Epoch=28.6] | Loss=0.04801 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.360 | L2-Norm(final)=5.032 | 4348.7 samples/s | 67.9 steps/s
[Step=14700 Epoch=28.7] | Loss=0.04836 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.388 | L2-Norm(final)=5.016 | 4333.9 samples/s | 67.7 steps/s
[Step=14750 Epoch=28.8] | Loss=0.04689 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.413 | L2-Norm(final)=5.003 | 4338.4 samples/s | 67.8 steps/s
[Step=14800 Epoch=28.9] | Loss=0.04577 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.434 | L2-Norm(final)=4.993 | 4318.1 samples/s | 67.5 steps/s
[Step=14850 Epoch=29.0] | Loss=0.04510 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.451 | L2-Norm(final)=4.983 | 4355.0 samples/s | 68.0 steps/s
[Step=14900 Epoch=29.1] | Loss=0.04487 | Reg=0.00505 | acc=0.9531 | L2-Norm=22.467 | L2-Norm(final)=4.974 | 4362.8 samples/s | 68.2 steps/s
[Step=14950 Epoch=29.2] | Loss=0.04425 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.482 | L2-Norm(final)=4.964 | 4367.6 samples/s | 68.2 steps/s
[Step=15000 Epoch=29.3] | Loss=0.04331 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.495 | L2-Norm(final)=4.956 | 5584.7 samples/s | 87.3 steps/s
[Step=15050 Epoch=29.4] | Loss=0.04186 | Reg=0.00507 | acc=0.9688 | L2-Norm=22.506 | L2-Norm(final)=4.948 | 2342.2 samples/s | 36.6 steps/s
[Step=15100 Epoch=29.5] | Loss=0.04040 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.515 | L2-Norm(final)=4.942 | 4373.0 samples/s | 68.3 steps/s
[Step=15150 Epoch=29.5] | Loss=0.03901 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.521 | L2-Norm(final)=4.937 | 4370.6 samples/s | 68.3 steps/s
[Step=15200 Epoch=29.6] | Loss=0.03838 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.526 | L2-Norm(final)=4.933 | 4271.8 samples/s | 66.7 steps/s
[Step=15250 Epoch=29.7] | Loss=0.03770 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.532 | L2-Norm(final)=4.928 | 4336.3 samples/s | 67.8 steps/s
[Step=15300 Epoch=29.8] | Loss=0.03692 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.536 | L2-Norm(final)=4.925 | 4405.9 samples/s | 68.8 steps/s
[Step=15350 Epoch=29.9] | Loss=0.03579 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.539 | L2-Norm(final)=4.922 | 4317.1 samples/s | 67.5 steps/s
[Step=15400 Epoch=30.0] | Loss=0.03554 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.542 | L2-Norm(final)=4.919 | 4365.4 samples/s | 68.2 steps/s
[Step=15450 Epoch=30.1] | Loss=0.03514 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.544 | L2-Norm(final)=4.916 | 4463.8 samples/s | 69.7 steps/s
[Step=15500 Epoch=30.2] | Loss=0.03503 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.546 | L2-Norm(final)=4.912 | 4786.1 samples/s | 74.8 steps/s
[Step=15550 Epoch=30.3] | Loss=0.03438 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.549 | L2-Norm(final)=4.908 | 2604.4 samples/s | 40.7 steps/s
[Step=15600 Epoch=30.4] | Loss=0.03377 | Reg=0.00509 | acc=0.9531 | L2-Norm=22.551 | L2-Norm(final)=4.905 | 4218.6 samples/s | 65.9 steps/s
[Step=15650 Epoch=30.5] | Loss=0.03319 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.553 | L2-Norm(final)=4.902 | 4254.9 samples/s | 66.5 steps/s
[Step=15700 Epoch=30.6] | Loss=0.03272 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.555 | L2-Norm(final)=4.899 | 4280.6 samples/s | 66.9 steps/s
[Step=15750 Epoch=30.7] | Loss=0.03247 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.557 | L2-Norm(final)=4.897 | 4294.4 samples/s | 67.1 steps/s
[Step=15800 Epoch=30.8] | Loss=0.03222 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.559 | L2-Norm(final)=4.895 | 4358.5 samples/s | 68.1 steps/s
[Step=15850 Epoch=30.9] | Loss=0.03168 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.560 | L2-Norm(final)=4.892 | 4159.3 samples/s | 65.0 steps/s
[Step=15900 Epoch=31.0] | Loss=0.03144 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.562 | L2-Norm(final)=4.890 | 4281.1 samples/s | 66.9 steps/s
[Step=15950 Epoch=31.1] | Loss=0.03100 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.564 | L2-Norm(final)=4.888 | 4316.3 samples/s | 67.4 steps/s
[Step=16000 Epoch=31.2] | Loss=0.03080 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.565 | L2-Norm(final)=4.886 | 4267.6 samples/s | 66.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step16000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=27.4] | Loss=0.05431 | Reg=0.00463 | acc=0.9531 | L2-Norm=21.513 | L2-Norm(final)=4.661 | 5774.6 samples/s | 90.2 steps/s
[Step=14050 Epoch=27.5] | Loss=0.06014 | Reg=0.00464 | acc=0.9375 | L2-Norm=21.535 | L2-Norm(final)=4.696 | 4337.7 samples/s | 67.8 steps/s
[Step=14100 Epoch=27.6] | Loss=0.05772 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.569 | L2-Norm(final)=4.722 | 4850.6 samples/s | 75.8 steps/s
[Step=14150 Epoch=27.7] | Loss=0.05628 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.600 | L2-Norm(final)=4.749 | 5088.3 samples/s | 79.5 steps/s
[Step=14200 Epoch=27.8] | Loss=0.05397 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.627 | L2-Norm(final)=4.776 | 4880.1 samples/s | 76.3 steps/s
[Step=14250 Epoch=27.9] | Loss=0.05366 | Reg=0.00469 | acc=0.9375 | L2-Norm=21.652 | L2-Norm(final)=4.798 | 5019.8 samples/s | 78.4 steps/s
[Step=14300 Epoch=28.0] | Loss=0.05298 | Reg=0.00470 | acc=0.9062 | L2-Norm=21.680 | L2-Norm(final)=4.820 | 5024.9 samples/s | 78.5 steps/s
[Step=14350 Epoch=28.1] | Loss=0.05234 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.706 | L2-Norm(final)=4.844 | 4998.1 samples/s | 78.1 steps/s
[Step=14400 Epoch=28.2] | Loss=0.05198 | Reg=0.00472 | acc=1.0000 | L2-Norm=21.733 | L2-Norm(final)=4.868 | 5156.9 samples/s | 80.6 steps/s
[Step=14450 Epoch=28.2] | Loss=0.05125 | Reg=0.00473 | acc=0.9375 | L2-Norm=21.758 | L2-Norm(final)=4.894 | 4843.7 samples/s | 75.7 steps/s
[Step=14500 Epoch=28.3] | Loss=0.05064 | Reg=0.00474 | acc=0.9219 | L2-Norm=21.782 | L2-Norm(final)=4.920 | 6808.8 samples/s | 106.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=28.3] | Loss=0.06076 | Reg=0.00485 | acc=0.9688 | L2-Norm=22.029 | L2-Norm(final)=5.170 | 6191.5 samples/s | 96.7 steps/s
[Step=14550 Epoch=28.4] | Loss=0.04474 | Reg=0.00487 | acc=0.9688 | L2-Norm=22.068 | L2-Norm(final)=5.187 | 4177.9 samples/s | 65.3 steps/s
[Step=14600 Epoch=28.5] | Loss=0.04403 | Reg=0.00489 | acc=0.9844 | L2-Norm=22.112 | L2-Norm(final)=5.180 | 4512.2 samples/s | 70.5 steps/s
[Step=14650 Epoch=28.6] | Loss=0.04187 | Reg=0.00491 | acc=0.9688 | L2-Norm=22.150 | L2-Norm(final)=5.173 | 4474.6 samples/s | 69.9 steps/s
[Step=14700 Epoch=28.7] | Loss=0.04234 | Reg=0.00492 | acc=0.9062 | L2-Norm=22.184 | L2-Norm(final)=5.167 | 4334.3 samples/s | 67.7 steps/s
[Step=14750 Epoch=28.8] | Loss=0.04239 | Reg=0.00493 | acc=0.9219 | L2-Norm=22.211 | L2-Norm(final)=5.160 | 4416.4 samples/s | 69.0 steps/s
[Step=14800 Epoch=28.9] | Loss=0.04222 | Reg=0.00494 | acc=0.9688 | L2-Norm=22.236 | L2-Norm(final)=5.150 | 4523.6 samples/s | 70.7 steps/s
[Step=14850 Epoch=29.0] | Loss=0.04184 | Reg=0.00495 | acc=0.9531 | L2-Norm=22.256 | L2-Norm(final)=5.142 | 4380.5 samples/s | 68.4 steps/s
[Step=14900 Epoch=29.1] | Loss=0.04161 | Reg=0.00496 | acc=0.9844 | L2-Norm=22.275 | L2-Norm(final)=5.134 | 4465.1 samples/s | 69.8 steps/s
[Step=14950 Epoch=29.2] | Loss=0.04012 | Reg=0.00497 | acc=1.0000 | L2-Norm=22.294 | L2-Norm(final)=5.129 | 4468.1 samples/s | 69.8 steps/s
[Step=15000 Epoch=29.3] | Loss=0.03955 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.311 | L2-Norm(final)=5.124 | 5790.4 samples/s | 90.5 steps/s
[Step=15050 Epoch=29.4] | Loss=0.03843 | Reg=0.00498 | acc=0.9688 | L2-Norm=22.326 | L2-Norm(final)=5.120 | 2389.9 samples/s | 37.3 steps/s
[Step=15100 Epoch=29.5] | Loss=0.03688 | Reg=0.00499 | acc=0.9844 | L2-Norm=22.338 | L2-Norm(final)=5.117 | 4443.4 samples/s | 69.4 steps/s
[Step=15150 Epoch=29.6] | Loss=0.03597 | Reg=0.00499 | acc=0.9844 | L2-Norm=22.348 | L2-Norm(final)=5.114 | 4419.8 samples/s | 69.1 steps/s
[Step=15200 Epoch=29.7] | Loss=0.03545 | Reg=0.00500 | acc=0.9688 | L2-Norm=22.359 | L2-Norm(final)=5.111 | 4390.0 samples/s | 68.6 steps/s
[Step=15250 Epoch=29.8] | Loss=0.03493 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.368 | L2-Norm(final)=5.108 | 4444.7 samples/s | 69.4 steps/s
[Step=15300 Epoch=29.9] | Loss=0.03482 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.376 | L2-Norm(final)=5.105 | 4469.9 samples/s | 69.8 steps/s
[Step=15350 Epoch=30.0] | Loss=0.03414 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.385 | L2-Norm(final)=5.101 | 4391.6 samples/s | 68.6 steps/s
[Step=15400 Epoch=30.1] | Loss=0.03407 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.392 | L2-Norm(final)=5.098 | 4467.7 samples/s | 69.8 steps/s
[Step=15450 Epoch=30.2] | Loss=0.03403 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.400 | L2-Norm(final)=5.094 | 4449.8 samples/s | 69.5 steps/s
[Step=15500 Epoch=30.3] | Loss=0.03373 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.407 | L2-Norm(final)=5.091 | 4877.8 samples/s | 76.2 steps/s
[Step=15550 Epoch=30.4] | Loss=0.03339 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.414 | L2-Norm(final)=5.088 | 2572.2 samples/s | 40.2 steps/s
[Step=15600 Epoch=30.5] | Loss=0.03289 | Reg=0.00503 | acc=0.9688 | L2-Norm=22.421 | L2-Norm(final)=5.086 | 4445.9 samples/s | 69.5 steps/s
[Step=15650 Epoch=30.6] | Loss=0.03221 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.427 | L2-Norm(final)=5.084 | 4429.8 samples/s | 69.2 steps/s
[Step=15700 Epoch=30.7] | Loss=0.03151 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.432 | L2-Norm(final)=5.082 | 4478.1 samples/s | 70.0 steps/s
[Step=15750 Epoch=30.8] | Loss=0.03097 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.437 | L2-Norm(final)=5.081 | 4511.4 samples/s | 70.5 steps/s
[Step=15800 Epoch=30.9] | Loss=0.03080 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.441 | L2-Norm(final)=5.080 | 4287.3 samples/s | 67.0 steps/s
[Step=15850 Epoch=31.0] | Loss=0.03055 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.444 | L2-Norm(final)=5.078 | 4459.9 samples/s | 69.7 steps/s
[Step=15900 Epoch=31.1] | Loss=0.03036 | Reg=0.00504 | acc=0.9688 | L2-Norm=22.448 | L2-Norm(final)=5.077 | 4531.8 samples/s | 70.8 steps/s
[Step=15950 Epoch=31.2] | Loss=0.03031 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.452 | L2-Norm(final)=5.075 | 4374.1 samples/s | 68.3 steps/s
[Step=16000 Epoch=31.3] | Loss=0.03011 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.455 | L2-Norm(final)=5.073 | 4414.2 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step16000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=53.6] | Loss=0.02606 | Reg=0.00193 | acc=0.9688 | L2-Norm=13.910 | L2-Norm(final)=3.970 | 5806.7 samples/s | 90.7 steps/s
[Step=14050 Epoch=53.8] | Loss=0.00420 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.965 | L2-Norm(final)=3.972 | 4449.8 samples/s | 69.5 steps/s
[Step=14100 Epoch=54.0] | Loss=0.00407 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.988 | L2-Norm(final)=3.992 | 4589.5 samples/s | 71.7 steps/s
[Step=14150 Epoch=54.2] | Loss=0.00310 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.009 | L2-Norm(final)=4.005 | 4707.9 samples/s | 73.6 steps/s
[Step=14200 Epoch=54.4] | Loss=0.00259 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.026 | L2-Norm(final)=4.022 | 4817.3 samples/s | 75.3 steps/s
[Step=14250 Epoch=54.6] | Loss=0.00217 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.037 | L2-Norm(final)=4.040 | 6401.1 samples/s | 100.0 steps/s
[Step=14300 Epoch=54.8] | Loss=0.00196 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.044 | L2-Norm(final)=4.058 | 2408.7 samples/s | 37.6 steps/s
[Step=14350 Epoch=55.0] | Loss=0.00190 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.051 | L2-Norm(final)=4.074 | 4785.1 samples/s | 74.8 steps/s
[Step=14400 Epoch=55.2] | Loss=0.00172 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.057 | L2-Norm(final)=4.088 | 4600.5 samples/s | 71.9 steps/s
[Step=14450 Epoch=55.4] | Loss=0.00156 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=4.102 | 4713.9 samples/s | 73.7 steps/s
[Step=14500 Epoch=55.6] | Loss=0.00145 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=4.116 | 5419.7 samples/s | 84.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=55.6] | Loss=0.00099 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.085 | L2-Norm(final)=4.254 | 5771.1 samples/s | 90.2 steps/s
[Step=14550 Epoch=55.8] | Loss=0.01541 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.235 | L2-Norm(final)=4.212 | 3915.8 samples/s | 61.2 steps/s
[Step=14600 Epoch=55.9] | Loss=0.01430 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.417 | L2-Norm(final)=4.141 | 4193.2 samples/s | 65.5 steps/s
[Step=14650 Epoch=56.1] | Loss=0.01132 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.512 | L2-Norm(final)=4.104 | 4195.1 samples/s | 65.5 steps/s
[Step=14700 Epoch=56.3] | Loss=0.00884 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.565 | L2-Norm(final)=4.088 | 4264.1 samples/s | 66.6 steps/s
[Step=14750 Epoch=56.5] | Loss=0.00726 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=4.081 | 5582.4 samples/s | 87.2 steps/s
[Step=14800 Epoch=56.7] | Loss=0.00629 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=4.077 | 2266.3 samples/s | 35.4 steps/s
[Step=14850 Epoch=56.9] | Loss=0.00545 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=4.075 | 4236.9 samples/s | 66.2 steps/s
[Step=14900 Epoch=57.1] | Loss=0.00479 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=4.074 | 4163.0 samples/s | 65.0 steps/s
[Step=14950 Epoch=57.3] | Loss=0.00427 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.630 | L2-Norm(final)=4.073 | 4157.4 samples/s | 65.0 steps/s
[Step=15000 Epoch=57.5] | Loss=0.00384 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=4.073 | 4764.1 samples/s | 74.4 steps/s
[Step=15050 Epoch=57.7] | Loss=0.00349 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=4.073 | 2453.1 samples/s | 38.3 steps/s
[Step=15100 Epoch=57.9] | Loss=0.00320 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=4.074 | 4160.5 samples/s | 65.0 steps/s
[Step=15150 Epoch=58.0] | Loss=0.00296 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.611 | L2-Norm(final)=4.074 | 4277.9 samples/s | 66.8 steps/s
[Step=15200 Epoch=58.2] | Loss=0.00275 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.602 | L2-Norm(final)=4.074 | 4146.7 samples/s | 64.8 steps/s
[Step=15250 Epoch=58.4] | Loss=0.00256 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=4.075 | 4169.4 samples/s | 65.1 steps/s
[Step=15300 Epoch=58.6] | Loss=0.00240 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=4.075 | 1919.2 samples/s | 30.0 steps/s
[Step=15350 Epoch=58.8] | Loss=0.00226 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.572 | L2-Norm(final)=4.076 | 4203.9 samples/s | 65.7 steps/s
[Step=15400 Epoch=59.0] | Loss=0.00214 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=4.076 | 4246.4 samples/s | 66.3 steps/s
[Step=15450 Epoch=59.2] | Loss=0.00203 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=4.076 | 4004.2 samples/s | 62.6 steps/s
[Step=15500 Epoch=59.4] | Loss=0.00192 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.536 | L2-Norm(final)=4.077 | 4205.1 samples/s | 65.7 steps/s
[Step=15550 Epoch=59.6] | Loss=0.00183 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.523 | L2-Norm(final)=4.078 | 2598.8 samples/s | 40.6 steps/s
[Step=15600 Epoch=59.8] | Loss=0.00175 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=4.078 | 4124.5 samples/s | 64.4 steps/s
[Step=15650 Epoch=60.0] | Loss=0.00167 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=4.079 | 4259.5 samples/s | 66.6 steps/s
[Step=15700 Epoch=60.2] | Loss=0.00160 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.483 | L2-Norm(final)=4.080 | 4211.6 samples/s | 65.8 steps/s
[Step=15750 Epoch=60.3] | Loss=0.00154 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.469 | L2-Norm(final)=4.081 | 4143.8 samples/s | 64.7 steps/s
[Step=15800 Epoch=60.5] | Loss=0.00148 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.455 | L2-Norm(final)=4.082 | 6324.6 samples/s | 98.8 steps/s
[Step=15850 Epoch=60.7] | Loss=0.00143 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.440 | L2-Norm(final)=4.083 | 2173.1 samples/s | 34.0 steps/s
[Step=15900 Epoch=60.9] | Loss=0.00138 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.426 | L2-Norm(final)=4.084 | 4193.8 samples/s | 65.5 steps/s
[Step=15950 Epoch=61.1] | Loss=0.00133 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.411 | L2-Norm(final)=4.085 | 4203.7 samples/s | 65.7 steps/s
[Step=16000 Epoch=61.3] | Loss=0.00128 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.395 | L2-Norm(final)=4.087 | 4167.0 samples/s | 65.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step16000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=53.9] | Loss=0.02084 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.327 | L2-Norm(final)=4.369 | 6004.2 samples/s | 93.8 steps/s
[Step=14050 Epoch=54.1] | Loss=0.00423 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=4.362 | 4252.5 samples/s | 66.4 steps/s
[Step=14100 Epoch=54.3] | Loss=0.00324 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.408 | L2-Norm(final)=4.379 | 4687.1 samples/s | 73.2 steps/s
[Step=14150 Epoch=54.5] | Loss=0.00287 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.430 | L2-Norm(final)=4.396 | 4621.5 samples/s | 72.2 steps/s
[Step=14200 Epoch=54.7] | Loss=0.00252 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.449 | L2-Norm(final)=4.416 | 4771.1 samples/s | 74.5 steps/s
[Step=14250 Epoch=54.9] | Loss=0.00250 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.465 | L2-Norm(final)=4.434 | 6704.0 samples/s | 104.7 steps/s
[Step=14300 Epoch=55.0] | Loss=0.00232 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.479 | L2-Norm(final)=4.450 | 2354.4 samples/s | 36.8 steps/s
[Step=14350 Epoch=55.2] | Loss=0.00212 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.492 | L2-Norm(final)=4.467 | 4834.9 samples/s | 75.5 steps/s
[Step=14400 Epoch=55.4] | Loss=0.00192 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.502 | L2-Norm(final)=4.484 | 4676.8 samples/s | 73.1 steps/s
[Step=14450 Epoch=55.6] | Loss=0.00179 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=4.502 | 4598.5 samples/s | 71.9 steps/s
[Step=14500 Epoch=55.8] | Loss=0.00166 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.519 | L2-Norm(final)=4.519 | 5670.0 samples/s | 88.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=55.8] | Loss=0.00005 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=4.688 | 6535.6 samples/s | 102.1 steps/s
[Step=14550 Epoch=56.0] | Loss=0.00598 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.649 | L2-Norm(final)=4.694 | 3682.0 samples/s | 57.5 steps/s
[Step=14600 Epoch=56.2] | Loss=0.01629 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.870 | L2-Norm(final)=4.646 | 4229.3 samples/s | 66.1 steps/s
[Step=14650 Epoch=56.4] | Loss=0.01414 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=4.593 | 4346.5 samples/s | 67.9 steps/s
[Step=14700 Epoch=56.6] | Loss=0.01179 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=4.569 | 4060.5 samples/s | 63.4 steps/s
[Step=14750 Epoch=56.8] | Loss=0.01012 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=4.558 | 5659.3 samples/s | 88.4 steps/s
[Step=14800 Epoch=57.0] | Loss=0.00856 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=4.553 | 2304.0 samples/s | 36.0 steps/s
[Step=14850 Epoch=57.2] | Loss=0.00737 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.227 | L2-Norm(final)=4.551 | 4047.9 samples/s | 63.2 steps/s
[Step=14900 Epoch=57.4] | Loss=0.00649 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=4.551 | 4138.0 samples/s | 64.7 steps/s
[Step=14950 Epoch=57.5] | Loss=0.00579 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=4.552 | 4223.7 samples/s | 66.0 steps/s
[Step=15000 Epoch=57.7] | Loss=0.00521 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=4.553 | 4870.8 samples/s | 76.1 steps/s
[Step=15050 Epoch=57.9] | Loss=0.00474 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=4.555 | 2408.5 samples/s | 37.6 steps/s
[Step=15100 Epoch=58.1] | Loss=0.00435 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.252 | L2-Norm(final)=4.556 | 4275.8 samples/s | 66.8 steps/s
[Step=15150 Epoch=58.3] | Loss=0.00402 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.247 | L2-Norm(final)=4.557 | 4159.2 samples/s | 65.0 steps/s
[Step=15200 Epoch=58.5] | Loss=0.00373 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=4.558 | 4251.9 samples/s | 66.4 steps/s
[Step=15250 Epoch=58.7] | Loss=0.00348 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=4.560 | 4281.4 samples/s | 66.9 steps/s
[Step=15300 Epoch=58.9] | Loss=0.00326 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=4.561 | 2604.9 samples/s | 40.7 steps/s
[Step=15350 Epoch=59.1] | Loss=0.00307 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.215 | L2-Norm(final)=4.562 | 4239.6 samples/s | 66.2 steps/s
[Step=15400 Epoch=59.3] | Loss=0.00290 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=4.563 | 4026.4 samples/s | 62.9 steps/s
[Step=15450 Epoch=59.5] | Loss=0.00275 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=4.563 | 4178.8 samples/s | 65.3 steps/s
[Step=15500 Epoch=59.7] | Loss=0.00261 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=4.564 | 4236.8 samples/s | 66.2 steps/s
[Step=15550 Epoch=59.9] | Loss=0.00249 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=4.565 | 2628.0 samples/s | 41.1 steps/s
[Step=15600 Epoch=60.1] | Loss=0.00238 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=4.566 | 4223.6 samples/s | 66.0 steps/s
[Step=15650 Epoch=60.2] | Loss=0.00227 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=4.567 | 4237.1 samples/s | 66.2 steps/s
[Step=15700 Epoch=60.4] | Loss=0.00218 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=4.568 | 4111.3 samples/s | 64.2 steps/s
[Step=15750 Epoch=60.6] | Loss=0.00209 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=4.570 | 4246.6 samples/s | 66.4 steps/s
[Step=15800 Epoch=60.8] | Loss=0.00201 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.097 | L2-Norm(final)=4.571 | 6892.1 samples/s | 107.7 steps/s
[Step=15850 Epoch=61.0] | Loss=0.00194 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=4.572 | 2100.7 samples/s | 32.8 steps/s
[Step=15900 Epoch=61.2] | Loss=0.00187 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=4.573 | 4226.8 samples/s | 66.0 steps/s
[Step=15950 Epoch=61.4] | Loss=0.00180 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=4.574 | 4206.5 samples/s | 65.7 steps/s
[Step=16000 Epoch=61.6] | Loss=0.00174 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=4.575 | 4187.5 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07321 | acc=0.9631 | tpr=0.9728 | fpr=0.0580 | 4946.0 samples/s | 19.3 steps/s
Avg test loss: 0.07238, Avg test acc: 0.96238, Avg tpr: 0.97208, Avg fpr: 0.05897, total FA: 460

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06825 | acc=0.9597 | tpr=0.9653 | fpr=0.0525 | 4870.3 samples/s | 19.0 steps/s
Avg test loss: 0.07061, Avg test acc: 0.95853, Avg tpr: 0.96427, Avg fpr: 0.05410, total FA: 422

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.89519 | acc=0.3144 | tpr=0.0063 | fpr=0.0166 | 5051.6 samples/s | 19.7 steps/s
Avg test loss: 5.89613, Avg test acc: 0.31168, Avg tpr: 0.00670, Avg fpr: 0.01756, total FA: 137

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.14360 | acc=0.3123 | tpr=0.0134 | fpr=0.0387 | 5033.6 samples/s | 19.7 steps/s
Avg test loss: 6.15456, Avg test acc: 0.30940, Avg tpr: 0.01341, Avg fpr: 0.03961, total FA: 309

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.66984 | acc=0.1346 | tpr=0.6991 | fpr=0.8755 | 4904.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.61859 | acc=0.1349 | tpr=0.6652 | fpr=0.8750 | 7235.4 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.62463 | acc=0.1349 | tpr=0.6556 | fpr=0.8746 | 7647.8 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.61949 | acc=0.1346 | tpr=0.6536 | fpr=0.8748 | 7784.6 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.61693 | acc=0.1353 | tpr=0.6655 | fpr=0.8744 | 8091.1 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.61562 | acc=0.1357 | tpr=0.6633 | fpr=0.8739 | 7839.8 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.61571 | acc=0.1353 | tpr=0.6569 | fpr=0.8742 | 7723.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.61684 | acc=0.1357 | tpr=0.6543 | fpr=0.8737 | 7738.6 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.62218 | acc=0.1356 | tpr=0.6607 | fpr=0.8739 | 7728.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.62048 | acc=0.1360 | tpr=0.6626 | fpr=0.8735 | 7891.3 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.62370 | acc=0.1360 | tpr=0.6578 | fpr=0.8735 | 13860.6 samples/s | 54.1 steps/s
Avg test loss: 5.62549, Avg test acc: 0.13582, Avg tpr: 0.65729, Avg fpr: 0.87366, total FA: 121306

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.98473 | acc=0.1445 | tpr=0.7035 | fpr=0.8656 | 5044.2 samples/s | 19.7 steps/s
[Step= 100] | Loss=5.95860 | acc=0.1428 | tpr=0.7143 | fpr=0.8679 | 6881.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=5.95599 | acc=0.1424 | tpr=0.7161 | fpr=0.8682 | 7650.8 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.95500 | acc=0.1436 | tpr=0.7180 | fpr=0.8669 | 7887.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.94614 | acc=0.1437 | tpr=0.7170 | fpr=0.8667 | 7754.9 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.94944 | acc=0.1440 | tpr=0.7127 | fpr=0.8663 | 7876.8 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.95167 | acc=0.1439 | tpr=0.7095 | fpr=0.8664 | 7927.6 samples/s | 31.0 steps/s
[Step= 400] | Loss=5.94952 | acc=0.1441 | tpr=0.7062 | fpr=0.8661 | 7713.7 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.95227 | acc=0.1442 | tpr=0.7084 | fpr=0.8660 | 8111.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.95128 | acc=0.1442 | tpr=0.7101 | fpr=0.8660 | 7471.8 samples/s | 29.2 steps/s
[Step= 550] | Loss=5.95699 | acc=0.1441 | tpr=0.7099 | fpr=0.8662 | 14395.1 samples/s | 56.2 steps/s
Avg test loss: 5.95844, Avg test acc: 0.14395, Avg tpr: 0.70998, Avg fpr: 0.86634, total FA: 120289

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14382 | acc=0.9788 | tpr=0.9292 | fpr=0.0203 | 5098.6 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.15104 | acc=0.9786 | tpr=0.9339 | fpr=0.0206 | 6728.9 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.15628 | acc=0.9778 | tpr=0.9366 | fpr=0.0214 | 7864.1 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.15880 | acc=0.9778 | tpr=0.9366 | fpr=0.0214 | 7547.1 samples/s | 29.5 steps/s
[Step= 250] | Loss=0.15702 | acc=0.9781 | tpr=0.9380 | fpr=0.0212 | 8377.9 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.15913 | acc=0.9778 | tpr=0.9360 | fpr=0.0214 | 7585.0 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.16055 | acc=0.9777 | tpr=0.9380 | fpr=0.0216 | 7620.2 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.16228 | acc=0.9774 | tpr=0.9327 | fpr=0.0217 | 7448.6 samples/s | 29.1 steps/s
[Step= 450] | Loss=0.16495 | acc=0.9772 | tpr=0.9323 | fpr=0.0220 | 7741.2 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.16448 | acc=0.9772 | tpr=0.9330 | fpr=0.0220 | 7634.6 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.16401 | acc=0.9774 | tpr=0.9324 | fpr=0.0218 | 14623.8 samples/s | 57.1 steps/s
Avg test loss: 0.16366, Avg test acc: 0.97736, Avg tpr: 0.93225, Avg fpr: 0.02182, total FA: 3030

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14595 | acc=0.9770 | tpr=0.9159 | fpr=0.0219 | 5008.2 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.14921 | acc=0.9773 | tpr=0.9296 | fpr=0.0218 | 6799.0 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.15480 | acc=0.9764 | tpr=0.9481 | fpr=0.0231 | 7611.7 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.15902 | acc=0.9762 | tpr=0.9486 | fpr=0.0233 | 7937.1 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.15681 | acc=0.9763 | tpr=0.9415 | fpr=0.0231 | 7658.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.16034 | acc=0.9760 | tpr=0.9411 | fpr=0.0233 | 7761.3 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.16067 | acc=0.9759 | tpr=0.9443 | fpr=0.0235 | 7905.6 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.16158 | acc=0.9759 | tpr=0.9415 | fpr=0.0234 | 7741.4 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.16368 | acc=0.9756 | tpr=0.9421 | fpr=0.0238 | 7801.1 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.16274 | acc=0.9758 | tpr=0.9423 | fpr=0.0236 | 7921.6 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.16185 | acc=0.9760 | tpr=0.9419 | fpr=0.0234 | 13457.9 samples/s | 52.6 steps/s
Avg test loss: 0.16165, Avg test acc: 0.97599, Avg tpr: 0.94176, Avg fpr: 0.02339, total FA: 3247

server round 8/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=31.2] | Loss=0.09385 | Reg=0.00485 | acc=0.9219 | L2-Norm=22.018 | L2-Norm(final)=4.831 | 6347.2 samples/s | 99.2 steps/s
[Step=16050 Epoch=31.3] | Loss=0.05725 | Reg=0.00485 | acc=0.9688 | L2-Norm=22.032 | L2-Norm(final)=4.849 | 4537.2 samples/s | 70.9 steps/s
[Step=16100 Epoch=31.4] | Loss=0.05285 | Reg=0.00487 | acc=0.9531 | L2-Norm=22.067 | L2-Norm(final)=4.885 | 4857.1 samples/s | 75.9 steps/s
[Step=16150 Epoch=31.5] | Loss=0.05166 | Reg=0.00489 | acc=0.9688 | L2-Norm=22.105 | L2-Norm(final)=4.914 | 4977.7 samples/s | 77.8 steps/s
[Step=16200 Epoch=31.6] | Loss=0.05052 | Reg=0.00490 | acc=0.9531 | L2-Norm=22.143 | L2-Norm(final)=4.943 | 4961.0 samples/s | 77.5 steps/s
[Step=16250 Epoch=31.7] | Loss=0.04961 | Reg=0.00492 | acc=0.9531 | L2-Norm=22.178 | L2-Norm(final)=4.973 | 5012.9 samples/s | 78.3 steps/s
[Step=16300 Epoch=31.8] | Loss=0.04878 | Reg=0.00493 | acc=0.9844 | L2-Norm=22.211 | L2-Norm(final)=4.999 | 4976.7 samples/s | 77.8 steps/s
[Step=16350 Epoch=31.9] | Loss=0.04768 | Reg=0.00495 | acc=0.9219 | L2-Norm=22.240 | L2-Norm(final)=5.026 | 4870.4 samples/s | 76.1 steps/s
[Step=16400 Epoch=32.0] | Loss=0.04739 | Reg=0.00496 | acc=0.9844 | L2-Norm=22.269 | L2-Norm(final)=5.051 | 4979.9 samples/s | 77.8 steps/s
[Step=16450 Epoch=32.1] | Loss=0.04630 | Reg=0.00497 | acc=0.9844 | L2-Norm=22.299 | L2-Norm(final)=5.077 | 5000.8 samples/s | 78.1 steps/s
[Step=16500 Epoch=32.2] | Loss=0.04567 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.329 | L2-Norm(final)=5.103 | 6479.2 samples/s | 101.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=32.2] | Loss=0.06286 | Reg=0.00512 | acc=0.9375 | L2-Norm=22.621 | L2-Norm(final)=5.372 | 5630.5 samples/s | 88.0 steps/s
[Step=16550 Epoch=32.3] | Loss=0.03955 | Reg=0.00513 | acc=0.9219 | L2-Norm=22.660 | L2-Norm(final)=5.377 | 4338.3 samples/s | 67.8 steps/s
[Step=16600 Epoch=32.4] | Loss=0.04378 | Reg=0.00516 | acc=0.9531 | L2-Norm=22.708 | L2-Norm(final)=5.361 | 4400.0 samples/s | 68.8 steps/s
[Step=16650 Epoch=32.5] | Loss=0.04311 | Reg=0.00518 | acc=0.9375 | L2-Norm=22.751 | L2-Norm(final)=5.345 | 4452.0 samples/s | 69.6 steps/s
[Step=16700 Epoch=32.6] | Loss=0.04245 | Reg=0.00519 | acc=0.9844 | L2-Norm=22.787 | L2-Norm(final)=5.332 | 4385.0 samples/s | 68.5 steps/s
[Step=16750 Epoch=32.7] | Loss=0.04297 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.815 | L2-Norm(final)=5.319 | 4381.3 samples/s | 68.5 steps/s
[Step=16800 Epoch=32.8] | Loss=0.04133 | Reg=0.00522 | acc=0.9844 | L2-Norm=22.840 | L2-Norm(final)=5.308 | 4375.7 samples/s | 68.4 steps/s
[Step=16850 Epoch=32.9] | Loss=0.04174 | Reg=0.00523 | acc=0.9375 | L2-Norm=22.861 | L2-Norm(final)=5.298 | 4460.1 samples/s | 69.7 steps/s
[Step=16900 Epoch=33.0] | Loss=0.04111 | Reg=0.00523 | acc=0.9688 | L2-Norm=22.878 | L2-Norm(final)=5.289 | 4456.9 samples/s | 69.6 steps/s
[Step=16950 Epoch=33.1] | Loss=0.04069 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.892 | L2-Norm(final)=5.280 | 4294.2 samples/s | 67.1 steps/s
[Step=17000 Epoch=33.2] | Loss=0.03933 | Reg=0.00525 | acc=0.9844 | L2-Norm=22.906 | L2-Norm(final)=5.274 | 5711.4 samples/s | 89.2 steps/s
[Step=17050 Epoch=33.3] | Loss=0.03802 | Reg=0.00525 | acc=1.0000 | L2-Norm=22.918 | L2-Norm(final)=5.269 | 2350.5 samples/s | 36.7 steps/s
[Step=17100 Epoch=33.4] | Loss=0.03683 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.928 | L2-Norm(final)=5.265 | 4353.9 samples/s | 68.0 steps/s
[Step=17150 Epoch=33.4] | Loss=0.03595 | Reg=0.00526 | acc=0.9844 | L2-Norm=22.936 | L2-Norm(final)=5.261 | 4428.2 samples/s | 69.2 steps/s
[Step=17200 Epoch=33.5] | Loss=0.03525 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.942 | L2-Norm(final)=5.258 | 4373.0 samples/s | 68.3 steps/s
[Step=17250 Epoch=33.6] | Loss=0.03475 | Reg=0.00527 | acc=0.9531 | L2-Norm=22.949 | L2-Norm(final)=5.256 | 4552.4 samples/s | 71.1 steps/s
[Step=17300 Epoch=33.7] | Loss=0.03378 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.955 | L2-Norm(final)=5.253 | 4344.8 samples/s | 67.9 steps/s
[Step=17350 Epoch=33.8] | Loss=0.03336 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.960 | L2-Norm(final)=5.251 | 4386.6 samples/s | 68.5 steps/s
[Step=17400 Epoch=33.9] | Loss=0.03284 | Reg=0.00527 | acc=0.9844 | L2-Norm=22.965 | L2-Norm(final)=5.249 | 4360.2 samples/s | 68.1 steps/s
[Step=17450 Epoch=34.0] | Loss=0.03272 | Reg=0.00528 | acc=0.9688 | L2-Norm=22.970 | L2-Norm(final)=5.246 | 4386.8 samples/s | 68.5 steps/s
[Step=17500 Epoch=34.1] | Loss=0.03225 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.975 | L2-Norm(final)=5.243 | 4768.2 samples/s | 74.5 steps/s
[Step=17550 Epoch=34.2] | Loss=0.03182 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.980 | L2-Norm(final)=5.239 | 2581.1 samples/s | 40.3 steps/s
[Step=17600 Epoch=34.3] | Loss=0.03113 | Reg=0.00528 | acc=0.9688 | L2-Norm=22.984 | L2-Norm(final)=5.236 | 4402.0 samples/s | 68.8 steps/s
[Step=17650 Epoch=34.4] | Loss=0.03084 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.988 | L2-Norm(final)=5.233 | 4349.0 samples/s | 68.0 steps/s
[Step=17700 Epoch=34.5] | Loss=0.03042 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.993 | L2-Norm(final)=5.231 | 4364.8 samples/s | 68.2 steps/s
[Step=17750 Epoch=34.6] | Loss=0.02998 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.996 | L2-Norm(final)=5.228 | 4407.0 samples/s | 68.9 steps/s
[Step=17800 Epoch=34.7] | Loss=0.02980 | Reg=0.00529 | acc=1.0000 | L2-Norm=23.000 | L2-Norm(final)=5.225 | 4390.6 samples/s | 68.6 steps/s
[Step=17850 Epoch=34.8] | Loss=0.02971 | Reg=0.00529 | acc=0.9531 | L2-Norm=23.005 | L2-Norm(final)=5.222 | 4347.3 samples/s | 67.9 steps/s
[Step=17900 Epoch=34.9] | Loss=0.02961 | Reg=0.00529 | acc=0.9531 | L2-Norm=23.010 | L2-Norm(final)=5.219 | 4416.7 samples/s | 69.0 steps/s
[Step=17950 Epoch=35.0] | Loss=0.02936 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.014 | L2-Norm(final)=5.216 | 4406.1 samples/s | 68.8 steps/s
[Step=18000 Epoch=35.1] | Loss=0.02915 | Reg=0.00530 | acc=0.9688 | L2-Norm=23.018 | L2-Norm(final)=5.213 | 4403.6 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step18000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=31.3] | Loss=0.03705 | Reg=0.00482 | acc=0.9844 | L2-Norm=21.948 | L2-Norm(final)=5.016 | 6341.3 samples/s | 99.1 steps/s
[Step=16050 Epoch=31.4] | Loss=0.05123 | Reg=0.00482 | acc=0.9531 | L2-Norm=21.962 | L2-Norm(final)=5.049 | 4813.2 samples/s | 75.2 steps/s
[Step=16100 Epoch=31.5] | Loss=0.05028 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.993 | L2-Norm(final)=5.074 | 4953.3 samples/s | 77.4 steps/s
[Step=16150 Epoch=31.6] | Loss=0.04881 | Reg=0.00485 | acc=0.9531 | L2-Norm=22.018 | L2-Norm(final)=5.085 | 4939.7 samples/s | 77.2 steps/s
[Step=16200 Epoch=31.7] | Loss=0.04732 | Reg=0.00486 | acc=0.9375 | L2-Norm=22.038 | L2-Norm(final)=5.098 | 4916.5 samples/s | 76.8 steps/s
[Step=16250 Epoch=31.8] | Loss=0.04560 | Reg=0.00487 | acc=0.9844 | L2-Norm=22.058 | L2-Norm(final)=5.114 | 4957.4 samples/s | 77.5 steps/s
[Step=16300 Epoch=31.9] | Loss=0.04484 | Reg=0.00487 | acc=0.9375 | L2-Norm=22.077 | L2-Norm(final)=5.129 | 4917.3 samples/s | 76.8 steps/s
[Step=16350 Epoch=32.0] | Loss=0.04385 | Reg=0.00488 | acc=0.9375 | L2-Norm=22.098 | L2-Norm(final)=5.145 | 5038.4 samples/s | 78.7 steps/s
[Step=16400 Epoch=32.1] | Loss=0.04355 | Reg=0.00489 | acc=0.9688 | L2-Norm=22.117 | L2-Norm(final)=5.161 | 5019.0 samples/s | 78.4 steps/s
[Step=16450 Epoch=32.2] | Loss=0.04377 | Reg=0.00490 | acc=0.9531 | L2-Norm=22.139 | L2-Norm(final)=5.177 | 5155.6 samples/s | 80.6 steps/s
[Step=16500 Epoch=32.3] | Loss=0.04323 | Reg=0.00491 | acc=1.0000 | L2-Norm=22.163 | L2-Norm(final)=5.194 | 6170.8 samples/s | 96.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=32.3] | Loss=0.07579 | Reg=0.00501 | acc=0.9375 | L2-Norm=22.392 | L2-Norm(final)=5.372 | 6265.0 samples/s | 97.9 steps/s
[Step=16550 Epoch=32.4] | Loss=0.03363 | Reg=0.00503 | acc=0.9375 | L2-Norm=22.428 | L2-Norm(final)=5.396 | 4025.5 samples/s | 62.9 steps/s
[Step=16600 Epoch=32.5] | Loss=0.03955 | Reg=0.00505 | acc=0.9375 | L2-Norm=22.472 | L2-Norm(final)=5.383 | 4349.3 samples/s | 68.0 steps/s
[Step=16650 Epoch=32.6] | Loss=0.03993 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.510 | L2-Norm(final)=5.371 | 4357.7 samples/s | 68.1 steps/s
[Step=16700 Epoch=32.6] | Loss=0.03939 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.544 | L2-Norm(final)=5.359 | 4459.2 samples/s | 69.7 steps/s
[Step=16750 Epoch=32.7] | Loss=0.03835 | Reg=0.00509 | acc=0.9688 | L2-Norm=22.569 | L2-Norm(final)=5.350 | 4356.2 samples/s | 68.1 steps/s
[Step=16800 Epoch=32.8] | Loss=0.03838 | Reg=0.00510 | acc=0.9531 | L2-Norm=22.591 | L2-Norm(final)=5.342 | 4484.8 samples/s | 70.1 steps/s
[Step=16850 Epoch=32.9] | Loss=0.03776 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.611 | L2-Norm(final)=5.335 | 4308.9 samples/s | 67.3 steps/s
[Step=16900 Epoch=33.0] | Loss=0.03855 | Reg=0.00512 | acc=0.9531 | L2-Norm=22.630 | L2-Norm(final)=5.329 | 4439.4 samples/s | 69.4 steps/s
[Step=16950 Epoch=33.1] | Loss=0.03732 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.648 | L2-Norm(final)=5.324 | 4456.3 samples/s | 69.6 steps/s
[Step=17000 Epoch=33.2] | Loss=0.03686 | Reg=0.00514 | acc=0.9844 | L2-Norm=22.664 | L2-Norm(final)=5.320 | 5742.7 samples/s | 89.7 steps/s
[Step=17050 Epoch=33.3] | Loss=0.03585 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.681 | L2-Norm(final)=5.316 | 2349.9 samples/s | 36.7 steps/s
[Step=17100 Epoch=33.4] | Loss=0.03468 | Reg=0.00515 | acc=0.9531 | L2-Norm=22.696 | L2-Norm(final)=5.313 | 4397.1 samples/s | 68.7 steps/s
[Step=17150 Epoch=33.5] | Loss=0.03377 | Reg=0.00516 | acc=0.9844 | L2-Norm=22.712 | L2-Norm(final)=5.311 | 4410.6 samples/s | 68.9 steps/s
[Step=17200 Epoch=33.6] | Loss=0.03294 | Reg=0.00516 | acc=0.9844 | L2-Norm=22.726 | L2-Norm(final)=5.309 | 4398.2 samples/s | 68.7 steps/s
[Step=17250 Epoch=33.7] | Loss=0.03266 | Reg=0.00517 | acc=0.9375 | L2-Norm=22.739 | L2-Norm(final)=5.307 | 4360.4 samples/s | 68.1 steps/s
[Step=17300 Epoch=33.8] | Loss=0.03230 | Reg=0.00518 | acc=1.0000 | L2-Norm=22.752 | L2-Norm(final)=5.304 | 4456.2 samples/s | 69.6 steps/s
[Step=17350 Epoch=33.9] | Loss=0.03184 | Reg=0.00518 | acc=0.9688 | L2-Norm=22.763 | L2-Norm(final)=5.302 | 4364.3 samples/s | 68.2 steps/s
[Step=17400 Epoch=34.0] | Loss=0.03144 | Reg=0.00519 | acc=0.9688 | L2-Norm=22.773 | L2-Norm(final)=5.300 | 4409.5 samples/s | 68.9 steps/s
[Step=17450 Epoch=34.1] | Loss=0.03118 | Reg=0.00519 | acc=0.9688 | L2-Norm=22.783 | L2-Norm(final)=5.297 | 4364.1 samples/s | 68.2 steps/s
[Step=17500 Epoch=34.2] | Loss=0.03069 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.792 | L2-Norm(final)=5.295 | 4916.3 samples/s | 76.8 steps/s
[Step=17550 Epoch=34.3] | Loss=0.03052 | Reg=0.00520 | acc=0.9688 | L2-Norm=22.801 | L2-Norm(final)=5.292 | 2530.1 samples/s | 39.5 steps/s
[Step=17600 Epoch=34.4] | Loss=0.03020 | Reg=0.00520 | acc=1.0000 | L2-Norm=22.809 | L2-Norm(final)=5.289 | 4439.8 samples/s | 69.4 steps/s
[Step=17650 Epoch=34.5] | Loss=0.02986 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.817 | L2-Norm(final)=5.286 | 4337.9 samples/s | 67.8 steps/s
[Step=17700 Epoch=34.6] | Loss=0.02942 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.825 | L2-Norm(final)=5.283 | 4405.3 samples/s | 68.8 steps/s
[Step=17750 Epoch=34.7] | Loss=0.02899 | Reg=0.00521 | acc=0.9531 | L2-Norm=22.833 | L2-Norm(final)=5.281 | 4401.3 samples/s | 68.8 steps/s
[Step=17800 Epoch=34.8] | Loss=0.02843 | Reg=0.00522 | acc=0.9688 | L2-Norm=22.840 | L2-Norm(final)=5.279 | 4421.2 samples/s | 69.1 steps/s
[Step=17850 Epoch=34.9] | Loss=0.02822 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.847 | L2-Norm(final)=5.277 | 4366.7 samples/s | 68.2 steps/s
[Step=17900 Epoch=35.0] | Loss=0.02810 | Reg=0.00522 | acc=0.9375 | L2-Norm=22.854 | L2-Norm(final)=5.274 | 4415.3 samples/s | 69.0 steps/s
[Step=17950 Epoch=35.1] | Loss=0.02800 | Reg=0.00523 | acc=0.9688 | L2-Norm=22.860 | L2-Norm(final)=5.271 | 4449.8 samples/s | 69.5 steps/s
[Step=18000 Epoch=35.2] | Loss=0.02783 | Reg=0.00523 | acc=0.9688 | L2-Norm=22.867 | L2-Norm(final)=5.268 | 4364.8 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step18000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=61.3] | Loss=0.00276 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.966 | L2-Norm(final)=4.128 | 5921.0 samples/s | 92.5 steps/s
[Step=16050 Epoch=61.5] | Loss=0.00204 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.989 | L2-Norm(final)=4.143 | 4178.6 samples/s | 65.3 steps/s
[Step=16100 Epoch=61.7] | Loss=0.00208 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.020 | L2-Norm(final)=4.159 | 4687.3 samples/s | 73.2 steps/s
[Step=16150 Epoch=61.9] | Loss=0.00160 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=4.176 | 4636.4 samples/s | 72.4 steps/s
[Step=16200 Epoch=62.1] | Loss=0.00146 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.067 | L2-Norm(final)=4.194 | 4776.6 samples/s | 74.6 steps/s
[Step=16250 Epoch=62.3] | Loss=0.00146 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.084 | L2-Norm(final)=4.210 | 6420.7 samples/s | 100.3 steps/s
[Step=16300 Epoch=62.5] | Loss=0.00128 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=4.226 | 2391.8 samples/s | 37.4 steps/s
[Step=16350 Epoch=62.6] | Loss=0.00113 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.110 | L2-Norm(final)=4.241 | 4601.3 samples/s | 71.9 steps/s
[Step=16400 Epoch=62.8] | Loss=0.00105 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.118 | L2-Norm(final)=4.256 | 4608.0 samples/s | 72.0 steps/s
[Step=16450 Epoch=63.0] | Loss=0.00097 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=4.270 | 4746.6 samples/s | 74.2 steps/s
[Step=16500 Epoch=63.2] | Loss=0.00089 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.130 | L2-Norm(final)=4.284 | 5336.0 samples/s | 83.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=63.2] | Loss=0.00006 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.172 | L2-Norm(final)=4.422 | 6321.8 samples/s | 98.8 steps/s
[Step=16550 Epoch=63.4] | Loss=0.00019 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.155 | L2-Norm(final)=4.427 | 3653.8 samples/s | 57.1 steps/s
[Step=16600 Epoch=63.6] | Loss=0.00831 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.214 | L2-Norm(final)=4.417 | 4201.2 samples/s | 65.6 steps/s
[Step=16650 Epoch=63.8] | Loss=0.01376 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.426 | L2-Norm(final)=4.343 | 4233.6 samples/s | 66.2 steps/s
[Step=16700 Epoch=64.0] | Loss=0.01146 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.566 | L2-Norm(final)=4.296 | 4223.0 samples/s | 66.0 steps/s
[Step=16750 Epoch=64.2] | Loss=0.00968 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=4.268 | 5576.1 samples/s | 87.1 steps/s
[Step=16800 Epoch=64.4] | Loss=0.00837 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=4.252 | 2257.8 samples/s | 35.3 steps/s
[Step=16850 Epoch=64.6] | Loss=0.00721 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=4.242 | 4250.9 samples/s | 66.4 steps/s
[Step=16900 Epoch=64.8] | Loss=0.00633 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=4.235 | 4221.0 samples/s | 66.0 steps/s
[Step=16950 Epoch=64.9] | Loss=0.00564 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=4.231 | 4164.9 samples/s | 65.1 steps/s
[Step=17000 Epoch=65.1] | Loss=0.00520 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.799 | L2-Norm(final)=4.228 | 4669.5 samples/s | 73.0 steps/s
[Step=17050 Epoch=65.3] | Loss=0.00474 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=4.226 | 2395.5 samples/s | 37.4 steps/s
[Step=17100 Epoch=65.5] | Loss=0.00440 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=4.225 | 3978.0 samples/s | 62.2 steps/s
[Step=17150 Epoch=65.7] | Loss=0.00411 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=4.225 | 4054.1 samples/s | 63.3 steps/s
[Step=17200 Epoch=65.9] | Loss=0.00384 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=4.225 | 4056.0 samples/s | 63.4 steps/s
[Step=17250 Epoch=66.1] | Loss=0.00359 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=4.225 | 4141.0 samples/s | 64.7 steps/s
[Step=17300 Epoch=66.3] | Loss=0.00337 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=4.226 | 2511.4 samples/s | 39.2 steps/s
[Step=17350 Epoch=66.5] | Loss=0.00317 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=4.227 | 4035.0 samples/s | 63.0 steps/s
[Step=17400 Epoch=66.7] | Loss=0.00300 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.822 | L2-Norm(final)=4.228 | 4056.8 samples/s | 63.4 steps/s
[Step=17450 Epoch=66.9] | Loss=0.00285 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.818 | L2-Norm(final)=4.228 | 4116.0 samples/s | 64.3 steps/s
[Step=17500 Epoch=67.1] | Loss=0.00271 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.813 | L2-Norm(final)=4.230 | 4165.3 samples/s | 65.1 steps/s
[Step=17550 Epoch=67.2] | Loss=0.00258 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=4.231 | 2647.9 samples/s | 41.4 steps/s
[Step=17600 Epoch=67.4] | Loss=0.00246 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.801 | L2-Norm(final)=4.232 | 4149.6 samples/s | 64.8 steps/s
[Step=17650 Epoch=67.6] | Loss=0.00236 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=4.233 | 4178.8 samples/s | 65.3 steps/s
[Step=17700 Epoch=67.8] | Loss=0.00226 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=4.234 | 4173.6 samples/s | 65.2 steps/s
[Step=17750 Epoch=68.0] | Loss=0.00217 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.777 | L2-Norm(final)=4.234 | 4299.2 samples/s | 67.2 steps/s
[Step=17800 Epoch=68.2] | Loss=0.00208 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=4.235 | 6050.4 samples/s | 94.5 steps/s
[Step=17850 Epoch=68.4] | Loss=0.00201 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.758 | L2-Norm(final)=4.236 | 2181.2 samples/s | 34.1 steps/s
[Step=17900 Epoch=68.6] | Loss=0.00194 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=4.237 | 4209.5 samples/s | 65.8 steps/s
[Step=17950 Epoch=68.8] | Loss=0.00187 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.738 | L2-Norm(final)=4.238 | 4170.0 samples/s | 65.2 steps/s
[Step=18000 Epoch=69.0] | Loss=0.00181 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=4.239 | 4164.0 samples/s | 65.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step18000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=61.6] | Loss=0.01146 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.407 | L2-Norm(final)=4.610 | 6057.3 samples/s | 94.6 steps/s
[Step=16050 Epoch=61.8] | Loss=0.00267 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.479 | L2-Norm(final)=4.618 | 4034.0 samples/s | 63.0 steps/s
[Step=16100 Epoch=62.0] | Loss=0.00291 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=4.640 | 4729.8 samples/s | 73.9 steps/s
[Step=16150 Epoch=62.2] | Loss=0.00229 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=4.659 | 4727.7 samples/s | 73.9 steps/s
[Step=16200 Epoch=62.4] | Loss=0.00191 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.575 | L2-Norm(final)=4.675 | 4784.6 samples/s | 74.8 steps/s
[Step=16250 Epoch=62.6] | Loss=0.00170 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.587 | L2-Norm(final)=4.692 | 6523.0 samples/s | 101.9 steps/s
[Step=16300 Epoch=62.7] | Loss=0.00151 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=4.708 | 2356.2 samples/s | 36.8 steps/s
[Step=16350 Epoch=62.9] | Loss=0.00133 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=4.723 | 4666.5 samples/s | 72.9 steps/s
[Step=16400 Epoch=63.1] | Loss=0.00120 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.611 | L2-Norm(final)=4.738 | 4718.7 samples/s | 73.7 steps/s
[Step=16450 Epoch=63.3] | Loss=0.00110 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=4.752 | 4610.5 samples/s | 72.0 steps/s
[Step=16500 Epoch=63.5] | Loss=0.00102 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.615 | L2-Norm(final)=4.765 | 5595.1 samples/s | 87.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=63.5] | Loss=0.00013 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=4.901 | 6540.2 samples/s | 102.2 steps/s
[Step=16550 Epoch=63.7] | Loss=0.00182 | Reg=0.00214 | acc=0.9688 | L2-Norm=14.622 | L2-Norm(final)=4.908 | 3699.3 samples/s | 57.8 steps/s
[Step=16600 Epoch=63.9] | Loss=0.01122 | Reg=0.00218 | acc=0.9688 | L2-Norm=14.751 | L2-Norm(final)=4.866 | 4128.1 samples/s | 64.5 steps/s
[Step=16650 Epoch=64.1] | Loss=0.01069 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=4.807 | 4187.9 samples/s | 65.4 steps/s
[Step=16700 Epoch=64.3] | Loss=0.01088 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=4.774 | 4272.9 samples/s | 66.8 steps/s
[Step=16750 Epoch=64.5] | Loss=0.00979 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.084 | L2-Norm(final)=4.752 | 5547.8 samples/s | 86.7 steps/s
[Step=16800 Epoch=64.7] | Loss=0.00832 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=4.740 | 2245.3 samples/s | 35.1 steps/s
[Step=16850 Epoch=64.9] | Loss=0.00718 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=4.732 | 4219.2 samples/s | 65.9 steps/s
[Step=16900 Epoch=65.1] | Loss=0.00629 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=4.728 | 4168.5 samples/s | 65.1 steps/s
[Step=16950 Epoch=65.2] | Loss=0.00560 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.190 | L2-Norm(final)=4.725 | 4269.7 samples/s | 66.7 steps/s
[Step=17000 Epoch=65.4] | Loss=0.00505 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=4.723 | 4864.2 samples/s | 76.0 steps/s
[Step=17050 Epoch=65.6] | Loss=0.00459 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=4.722 | 2394.0 samples/s | 37.4 steps/s
[Step=17100 Epoch=65.8] | Loss=0.00421 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=4.722 | 4150.0 samples/s | 64.8 steps/s
[Step=17150 Epoch=66.0] | Loss=0.00389 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=4.721 | 4212.4 samples/s | 65.8 steps/s
[Step=17200 Epoch=66.2] | Loss=0.00361 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=4.721 | 4146.7 samples/s | 64.8 steps/s
[Step=17250 Epoch=66.4] | Loss=0.00337 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=4.721 | 4350.3 samples/s | 68.0 steps/s
[Step=17300 Epoch=66.6] | Loss=0.00316 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=4.721 | 2583.1 samples/s | 40.4 steps/s
[Step=17350 Epoch=66.8] | Loss=0.00298 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=4.721 | 4197.5 samples/s | 65.6 steps/s
[Step=17400 Epoch=67.0] | Loss=0.00281 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.155 | L2-Norm(final)=4.722 | 4311.9 samples/s | 67.4 steps/s
[Step=17450 Epoch=67.2] | Loss=0.00266 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=4.722 | 4095.0 samples/s | 64.0 steps/s
[Step=17500 Epoch=67.4] | Loss=0.00253 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=4.723 | 4138.0 samples/s | 64.7 steps/s
[Step=17550 Epoch=67.6] | Loss=0.00241 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=4.724 | 2627.9 samples/s | 41.1 steps/s
[Step=17600 Epoch=67.7] | Loss=0.00230 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=4.725 | 4170.8 samples/s | 65.2 steps/s
[Step=17650 Epoch=67.9] | Loss=0.00220 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=4.726 | 4285.4 samples/s | 67.0 steps/s
[Step=17700 Epoch=68.1] | Loss=0.00211 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=4.727 | 4197.5 samples/s | 65.6 steps/s
[Step=17750 Epoch=68.3] | Loss=0.00203 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=4.729 | 4147.2 samples/s | 64.8 steps/s
[Step=17800 Epoch=68.5] | Loss=0.00195 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=4.730 | 6918.6 samples/s | 108.1 steps/s
[Step=17850 Epoch=68.7] | Loss=0.00188 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=4.732 | 2085.8 samples/s | 32.6 steps/s
[Step=17900 Epoch=68.9] | Loss=0.00181 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=4.734 | 4244.1 samples/s | 66.3 steps/s
[Step=17950 Epoch=69.1] | Loss=0.00175 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=4.735 | 4185.5 samples/s | 65.4 steps/s
[Step=18000 Epoch=69.3] | Loss=0.00169 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=4.737 | 4188.8 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07688 | acc=0.9595 | tpr=0.9661 | fpr=0.0550 | 4873.7 samples/s | 19.0 steps/s
Avg test loss: 0.07612, Avg test acc: 0.95981, Avg tpr: 0.96695, Avg fpr: 0.05589, total FA: 436

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07094 | acc=0.9623 | tpr=0.9719 | fpr=0.0587 | 5112.3 samples/s | 20.0 steps/s
Avg test loss: 0.07327, Avg test acc: 0.96162, Avg tpr: 0.97103, Avg fpr: 0.05909, total FA: 461

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.52900 | acc=0.3117 | tpr=0.0050 | fpr=0.0223 | 5015.1 samples/s | 19.6 steps/s
Avg test loss: 5.54782, Avg test acc: 0.30832, Avg tpr: 0.00501, Avg fpr: 0.02461, total FA: 192

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.87067 | acc=0.3161 | tpr=0.0099 | fpr=0.0191 | 4953.9 samples/s | 19.4 steps/s
Avg test loss: 5.86049, Avg test acc: 0.31361, Avg tpr: 0.01043, Avg fpr: 0.01961, total FA: 153

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.22100 | acc=0.1379 | tpr=0.6460 | fpr=0.8712 | 5181.4 samples/s | 20.2 steps/s
[Step= 100] | Loss=6.19336 | acc=0.1376 | tpr=0.6034 | fpr=0.8711 | 6629.0 samples/s | 25.9 steps/s
[Step= 150] | Loss=6.20016 | acc=0.1358 | tpr=0.5850 | fpr=0.8725 | 7758.9 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.19341 | acc=0.1356 | tpr=0.5825 | fpr=0.8725 | 7772.9 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.19285 | acc=0.1349 | tpr=0.5939 | fpr=0.8735 | 7998.7 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.18502 | acc=0.1348 | tpr=0.5942 | fpr=0.8736 | 7765.9 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.19140 | acc=0.1340 | tpr=0.5855 | fpr=0.8742 | 7730.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.19505 | acc=0.1345 | tpr=0.5837 | fpr=0.8737 | 7962.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.20196 | acc=0.1348 | tpr=0.5906 | fpr=0.8735 | 7682.9 samples/s | 30.0 steps/s
[Step= 500] | Loss=6.19977 | acc=0.1348 | tpr=0.5859 | fpr=0.8734 | 8027.2 samples/s | 31.4 steps/s
[Step= 550] | Loss=6.20347 | acc=0.1344 | tpr=0.5854 | fpr=0.8738 | 13461.3 samples/s | 52.6 steps/s
Avg test loss: 6.20522, Avg test acc: 0.13433, Avg tpr: 0.58597, Avg fpr: 0.87388, total FA: 121336

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.22461 | acc=0.1373 | tpr=0.7168 | fpr=0.8732 | 5030.1 samples/s | 19.6 steps/s
[Step= 100] | Loss=6.18551 | acc=0.1366 | tpr=0.6695 | fpr=0.8733 | 6982.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.18740 | acc=0.1357 | tpr=0.6643 | fpr=0.8741 | 7485.6 samples/s | 29.2 steps/s
[Step= 200] | Loss=6.18335 | acc=0.1354 | tpr=0.6612 | fpr=0.8742 | 7946.2 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.17946 | acc=0.1348 | tpr=0.6629 | fpr=0.8748 | 7650.4 samples/s | 29.9 steps/s
[Step= 300] | Loss=6.17603 | acc=0.1349 | tpr=0.6524 | fpr=0.8745 | 8046.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.17894 | acc=0.1344 | tpr=0.6456 | fpr=0.8749 | 7424.2 samples/s | 29.0 steps/s
[Step= 400] | Loss=6.17837 | acc=0.1346 | tpr=0.6493 | fpr=0.8747 | 8364.8 samples/s | 32.7 steps/s
[Step= 450] | Loss=6.18396 | acc=0.1350 | tpr=0.6538 | fpr=0.8744 | 7856.5 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.18205 | acc=0.1353 | tpr=0.6581 | fpr=0.8742 | 7792.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=6.18713 | acc=0.1352 | tpr=0.6598 | fpr=0.8744 | 13718.6 samples/s | 53.6 steps/s
Avg test loss: 6.18929, Avg test acc: 0.13510, Avg tpr: 0.65967, Avg fpr: 0.87443, total FA: 121413

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15023 | acc=0.9789 | tpr=0.9336 | fpr=0.0203 | 4802.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.15661 | acc=0.9788 | tpr=0.9382 | fpr=0.0205 | 7361.7 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.16311 | acc=0.9780 | tpr=0.9424 | fpr=0.0213 | 7661.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.16485 | acc=0.9780 | tpr=0.9421 | fpr=0.0214 | 8037.2 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.16141 | acc=0.9785 | tpr=0.9397 | fpr=0.0208 | 7937.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.16392 | acc=0.9781 | tpr=0.9382 | fpr=0.0212 | 7373.8 samples/s | 28.8 steps/s
[Step= 350] | Loss=0.16504 | acc=0.9778 | tpr=0.9386 | fpr=0.0215 | 8077.4 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.16654 | acc=0.9777 | tpr=0.9344 | fpr=0.0215 | 7931.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.16925 | acc=0.9774 | tpr=0.9357 | fpr=0.0218 | 7664.0 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.16801 | acc=0.9775 | tpr=0.9361 | fpr=0.0217 | 8144.3 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.16709 | acc=0.9777 | tpr=0.9359 | fpr=0.0215 | 13531.2 samples/s | 52.9 steps/s
Avg test loss: 0.16683, Avg test acc: 0.97774, Avg tpr: 0.93582, Avg fpr: 0.02150, total FA: 2985

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12840 | acc=0.9798 | tpr=0.9513 | fpr=0.0196 | 5075.3 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.13441 | acc=0.9786 | tpr=0.9510 | fpr=0.0209 | 6985.4 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.14109 | acc=0.9775 | tpr=0.9597 | fpr=0.0222 | 7633.0 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.14445 | acc=0.9774 | tpr=0.9563 | fpr=0.0222 | 7920.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14196 | acc=0.9776 | tpr=0.9459 | fpr=0.0218 | 7900.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.14479 | acc=0.9774 | tpr=0.9462 | fpr=0.0220 | 7724.7 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.14507 | acc=0.9774 | tpr=0.9487 | fpr=0.0221 | 8068.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.14563 | acc=0.9773 | tpr=0.9464 | fpr=0.0221 | 7526.5 samples/s | 29.4 steps/s
[Step= 450] | Loss=0.14787 | acc=0.9769 | tpr=0.9460 | fpr=0.0226 | 7659.1 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.14679 | acc=0.9769 | tpr=0.9454 | fpr=0.0225 | 8047.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.14618 | acc=0.9772 | tpr=0.9451 | fpr=0.0223 | 13961.4 samples/s | 54.5 steps/s
Avg test loss: 0.14600, Avg test acc: 0.97716, Avg tpr: 0.94493, Avg fpr: 0.02225, total FA: 3090

server round 9/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=35.1] | Loss=0.03667 | Reg=0.00507 | acc=0.9688 | L2-Norm=22.523 | L2-Norm(final)=5.127 | 6258.8 samples/s | 97.8 steps/s
[Step=18050 Epoch=35.2] | Loss=0.04127 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.548 | L2-Norm(final)=5.163 | 4465.7 samples/s | 69.8 steps/s
[Step=18100 Epoch=35.3] | Loss=0.03754 | Reg=0.00510 | acc=0.9844 | L2-Norm=22.580 | L2-Norm(final)=5.206 | 5079.5 samples/s | 79.4 steps/s
[Step=18150 Epoch=35.4] | Loss=0.03666 | Reg=0.00511 | acc=0.9531 | L2-Norm=22.605 | L2-Norm(final)=5.241 | 4844.8 samples/s | 75.7 steps/s
[Step=18200 Epoch=35.5] | Loss=0.03554 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.628 | L2-Norm(final)=5.270 | 5071.3 samples/s | 79.2 steps/s
[Step=18250 Epoch=35.6] | Loss=0.03484 | Reg=0.00513 | acc=0.9844 | L2-Norm=22.650 | L2-Norm(final)=5.297 | 4823.9 samples/s | 75.4 steps/s
[Step=18300 Epoch=35.7] | Loss=0.03549 | Reg=0.00514 | acc=0.9844 | L2-Norm=22.674 | L2-Norm(final)=5.320 | 4720.5 samples/s | 73.8 steps/s
[Step=18350 Epoch=35.8] | Loss=0.03499 | Reg=0.00515 | acc=1.0000 | L2-Norm=22.698 | L2-Norm(final)=5.343 | 4909.0 samples/s | 76.7 steps/s
[Step=18400 Epoch=35.9] | Loss=0.03470 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.719 | L2-Norm(final)=5.366 | 4893.9 samples/s | 76.5 steps/s
[Step=18450 Epoch=36.0] | Loss=0.03435 | Reg=0.00517 | acc=0.9844 | L2-Norm=22.738 | L2-Norm(final)=5.388 | 4854.1 samples/s | 75.8 steps/s
[Step=18500 Epoch=36.1] | Loss=0.03434 | Reg=0.00518 | acc=0.9844 | L2-Norm=22.759 | L2-Norm(final)=5.411 | 6590.0 samples/s | 103.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=36.1] | Loss=0.03577 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.973 | L2-Norm(final)=5.627 | 6578.9 samples/s | 102.8 steps/s
[Step=18550 Epoch=36.2] | Loss=0.02868 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.996 | L2-Norm(final)=5.639 | 4021.9 samples/s | 62.8 steps/s
[Step=18600 Epoch=36.3] | Loss=0.03668 | Reg=0.00530 | acc=0.9688 | L2-Norm=23.021 | L2-Norm(final)=5.636 | 4266.1 samples/s | 66.7 steps/s
[Step=18650 Epoch=36.4] | Loss=0.03917 | Reg=0.00531 | acc=0.9531 | L2-Norm=23.053 | L2-Norm(final)=5.628 | 4413.0 samples/s | 69.0 steps/s
[Step=18700 Epoch=36.5] | Loss=0.03659 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.086 | L2-Norm(final)=5.619 | 4341.9 samples/s | 67.8 steps/s
[Step=18750 Epoch=36.6] | Loss=0.03800 | Reg=0.00534 | acc=0.9531 | L2-Norm=23.114 | L2-Norm(final)=5.611 | 4257.2 samples/s | 66.5 steps/s
[Step=18800 Epoch=36.7] | Loss=0.03751 | Reg=0.00536 | acc=0.9688 | L2-Norm=23.141 | L2-Norm(final)=5.602 | 4344.5 samples/s | 67.9 steps/s
[Step=18850 Epoch=36.8] | Loss=0.03694 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.164 | L2-Norm(final)=5.594 | 4400.5 samples/s | 68.8 steps/s
[Step=18900 Epoch=36.9] | Loss=0.03649 | Reg=0.00537 | acc=0.9531 | L2-Norm=23.184 | L2-Norm(final)=5.586 | 4355.4 samples/s | 68.1 steps/s
[Step=18950 Epoch=37.0] | Loss=0.03610 | Reg=0.00538 | acc=0.9531 | L2-Norm=23.201 | L2-Norm(final)=5.577 | 4359.1 samples/s | 68.1 steps/s
[Step=19000 Epoch=37.1] | Loss=0.03606 | Reg=0.00539 | acc=0.9844 | L2-Norm=23.216 | L2-Norm(final)=5.570 | 5585.8 samples/s | 87.3 steps/s
[Step=19050 Epoch=37.2] | Loss=0.03506 | Reg=0.00540 | acc=0.9688 | L2-Norm=23.230 | L2-Norm(final)=5.564 | 2322.1 samples/s | 36.3 steps/s
[Step=19100 Epoch=37.3] | Loss=0.03397 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.243 | L2-Norm(final)=5.559 | 4297.6 samples/s | 67.2 steps/s
[Step=19150 Epoch=37.3] | Loss=0.03314 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.253 | L2-Norm(final)=5.555 | 4351.4 samples/s | 68.0 steps/s
[Step=19200 Epoch=37.4] | Loss=0.03279 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.263 | L2-Norm(final)=5.551 | 4338.6 samples/s | 67.8 steps/s
[Step=19250 Epoch=37.5] | Loss=0.03205 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.273 | L2-Norm(final)=5.547 | 4343.8 samples/s | 67.9 steps/s
[Step=19300 Epoch=37.6] | Loss=0.03141 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.281 | L2-Norm(final)=5.544 | 4361.3 samples/s | 68.1 steps/s
[Step=19350 Epoch=37.7] | Loss=0.03104 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.290 | L2-Norm(final)=5.540 | 4319.3 samples/s | 67.5 steps/s
[Step=19400 Epoch=37.8] | Loss=0.03070 | Reg=0.00543 | acc=0.9531 | L2-Norm=23.299 | L2-Norm(final)=5.537 | 4341.6 samples/s | 67.8 steps/s
[Step=19450 Epoch=37.9] | Loss=0.03056 | Reg=0.00543 | acc=0.9375 | L2-Norm=23.307 | L2-Norm(final)=5.533 | 4349.0 samples/s | 68.0 steps/s
[Step=19500 Epoch=38.0] | Loss=0.03033 | Reg=0.00544 | acc=0.9688 | L2-Norm=23.315 | L2-Norm(final)=5.530 | 4627.1 samples/s | 72.3 steps/s
[Step=19550 Epoch=38.1] | Loss=0.02982 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.324 | L2-Norm(final)=5.526 | 2535.6 samples/s | 39.6 steps/s
[Step=19600 Epoch=38.2] | Loss=0.02930 | Reg=0.00544 | acc=0.9531 | L2-Norm=23.331 | L2-Norm(final)=5.523 | 4323.0 samples/s | 67.5 steps/s
[Step=19650 Epoch=38.3] | Loss=0.02917 | Reg=0.00545 | acc=0.9844 | L2-Norm=23.339 | L2-Norm(final)=5.520 | 4336.4 samples/s | 67.8 steps/s
[Step=19700 Epoch=38.4] | Loss=0.02880 | Reg=0.00545 | acc=0.9688 | L2-Norm=23.346 | L2-Norm(final)=5.517 | 4266.0 samples/s | 66.7 steps/s
[Step=19750 Epoch=38.5] | Loss=0.02846 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.353 | L2-Norm(final)=5.514 | 4290.2 samples/s | 67.0 steps/s
[Step=19800 Epoch=38.6] | Loss=0.02824 | Reg=0.00546 | acc=0.9531 | L2-Norm=23.359 | L2-Norm(final)=5.511 | 4254.5 samples/s | 66.5 steps/s
[Step=19850 Epoch=38.7] | Loss=0.02800 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.365 | L2-Norm(final)=5.508 | 4169.8 samples/s | 65.2 steps/s
[Step=19900 Epoch=38.8] | Loss=0.02784 | Reg=0.00546 | acc=0.9531 | L2-Norm=23.372 | L2-Norm(final)=5.505 | 4336.3 samples/s | 67.8 steps/s
[Step=19950 Epoch=38.9] | Loss=0.02775 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.378 | L2-Norm(final)=5.502 | 4377.9 samples/s | 68.4 steps/s
[Step=20000 Epoch=39.0] | Loss=0.02761 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.384 | L2-Norm(final)=5.499 | 4332.8 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step20000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=35.2] | Loss=0.04167 | Reg=0.00504 | acc=0.9688 | L2-Norm=22.459 | L2-Norm(final)=5.188 | 6180.3 samples/s | 96.6 steps/s
[Step=18050 Epoch=35.3] | Loss=0.03683 | Reg=0.00505 | acc=0.9531 | L2-Norm=22.471 | L2-Norm(final)=5.217 | 4614.3 samples/s | 72.1 steps/s
[Step=18100 Epoch=35.4] | Loss=0.03507 | Reg=0.00505 | acc=0.9531 | L2-Norm=22.480 | L2-Norm(final)=5.247 | 4706.4 samples/s | 73.5 steps/s
[Step=18150 Epoch=35.5] | Loss=0.03489 | Reg=0.00506 | acc=0.9219 | L2-Norm=22.490 | L2-Norm(final)=5.274 | 4910.1 samples/s | 76.7 steps/s
[Step=18200 Epoch=35.6] | Loss=0.03610 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.500 | L2-Norm(final)=5.296 | 4815.4 samples/s | 75.2 steps/s
[Step=18250 Epoch=35.7] | Loss=0.03637 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.514 | L2-Norm(final)=5.314 | 4874.6 samples/s | 76.2 steps/s
[Step=18300 Epoch=35.8] | Loss=0.03576 | Reg=0.00507 | acc=0.9688 | L2-Norm=22.527 | L2-Norm(final)=5.335 | 4869.8 samples/s | 76.1 steps/s
[Step=18350 Epoch=35.9] | Loss=0.03516 | Reg=0.00508 | acc=0.9531 | L2-Norm=22.542 | L2-Norm(final)=5.357 | 4986.0 samples/s | 77.9 steps/s
[Step=18400 Epoch=36.0] | Loss=0.03454 | Reg=0.00509 | acc=0.9531 | L2-Norm=22.556 | L2-Norm(final)=5.378 | 4859.2 samples/s | 75.9 steps/s
[Step=18450 Epoch=36.1] | Loss=0.03387 | Reg=0.00509 | acc=0.9688 | L2-Norm=22.571 | L2-Norm(final)=5.399 | 4910.3 samples/s | 76.7 steps/s
[Step=18500 Epoch=36.2] | Loss=0.03346 | Reg=0.00510 | acc=0.9375 | L2-Norm=22.586 | L2-Norm(final)=5.420 | 6695.1 samples/s | 104.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=36.2] | Loss=0.02826 | Reg=0.00517 | acc=0.9688 | L2-Norm=22.730 | L2-Norm(final)=5.633 | 6536.8 samples/s | 102.1 steps/s
[Step=18550 Epoch=36.3] | Loss=0.02449 | Reg=0.00518 | acc=0.9688 | L2-Norm=22.759 | L2-Norm(final)=5.659 | 3966.2 samples/s | 62.0 steps/s
[Step=18600 Epoch=36.4] | Loss=0.03558 | Reg=0.00520 | acc=0.9688 | L2-Norm=22.813 | L2-Norm(final)=5.649 | 4421.3 samples/s | 69.1 steps/s
[Step=18650 Epoch=36.5] | Loss=0.03734 | Reg=0.00522 | acc=0.9688 | L2-Norm=22.858 | L2-Norm(final)=5.637 | 4337.3 samples/s | 67.8 steps/s
[Step=18700 Epoch=36.6] | Loss=0.03631 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.891 | L2-Norm(final)=5.628 | 4334.1 samples/s | 67.7 steps/s
[Step=18750 Epoch=36.7] | Loss=0.03623 | Reg=0.00525 | acc=0.9844 | L2-Norm=22.920 | L2-Norm(final)=5.619 | 4217.6 samples/s | 65.9 steps/s
[Step=18800 Epoch=36.8] | Loss=0.03571 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.944 | L2-Norm(final)=5.612 | 4336.2 samples/s | 67.8 steps/s
[Step=18850 Epoch=36.9] | Loss=0.03596 | Reg=0.00527 | acc=0.9844 | L2-Norm=22.966 | L2-Norm(final)=5.606 | 4224.3 samples/s | 66.0 steps/s
[Step=18900 Epoch=36.9] | Loss=0.03610 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.986 | L2-Norm(final)=5.599 | 4277.1 samples/s | 66.8 steps/s
[Step=18950 Epoch=37.0] | Loss=0.03580 | Reg=0.00529 | acc=0.9688 | L2-Norm=23.006 | L2-Norm(final)=5.592 | 4291.3 samples/s | 67.1 steps/s
[Step=19000 Epoch=37.1] | Loss=0.03511 | Reg=0.00530 | acc=0.9531 | L2-Norm=23.025 | L2-Norm(final)=5.585 | 5592.0 samples/s | 87.4 steps/s
[Step=19050 Epoch=37.2] | Loss=0.03386 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.042 | L2-Norm(final)=5.579 | 2270.0 samples/s | 35.5 steps/s
[Step=19100 Epoch=37.3] | Loss=0.03309 | Reg=0.00532 | acc=0.9531 | L2-Norm=23.057 | L2-Norm(final)=5.573 | 4278.9 samples/s | 66.9 steps/s
[Step=19150 Epoch=37.4] | Loss=0.03208 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.069 | L2-Norm(final)=5.569 | 4253.4 samples/s | 66.5 steps/s
[Step=19200 Epoch=37.5] | Loss=0.03206 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.081 | L2-Norm(final)=5.564 | 4289.9 samples/s | 67.0 steps/s
[Step=19250 Epoch=37.6] | Loss=0.03151 | Reg=0.00533 | acc=0.9844 | L2-Norm=23.092 | L2-Norm(final)=5.559 | 4465.5 samples/s | 69.8 steps/s
[Step=19300 Epoch=37.7] | Loss=0.03113 | Reg=0.00534 | acc=0.9688 | L2-Norm=23.103 | L2-Norm(final)=5.554 | 4426.0 samples/s | 69.2 steps/s
[Step=19350 Epoch=37.8] | Loss=0.03065 | Reg=0.00534 | acc=0.9844 | L2-Norm=23.113 | L2-Norm(final)=5.549 | 4413.5 samples/s | 69.0 steps/s
[Step=19400 Epoch=37.9] | Loss=0.03021 | Reg=0.00535 | acc=1.0000 | L2-Norm=23.124 | L2-Norm(final)=5.544 | 4431.4 samples/s | 69.2 steps/s
[Step=19450 Epoch=38.0] | Loss=0.03009 | Reg=0.00535 | acc=0.9844 | L2-Norm=23.134 | L2-Norm(final)=5.539 | 4400.1 samples/s | 68.8 steps/s
[Step=19500 Epoch=38.1] | Loss=0.02968 | Reg=0.00536 | acc=0.9688 | L2-Norm=23.144 | L2-Norm(final)=5.534 | 4897.7 samples/s | 76.5 steps/s
[Step=19550 Epoch=38.2] | Loss=0.02968 | Reg=0.00536 | acc=0.9688 | L2-Norm=23.155 | L2-Norm(final)=5.529 | 2559.7 samples/s | 40.0 steps/s
[Step=19600 Epoch=38.3] | Loss=0.02927 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.166 | L2-Norm(final)=5.525 | 4387.8 samples/s | 68.6 steps/s
[Step=19650 Epoch=38.4] | Loss=0.02899 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.176 | L2-Norm(final)=5.520 | 4442.3 samples/s | 69.4 steps/s
[Step=19700 Epoch=38.5] | Loss=0.02841 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.186 | L2-Norm(final)=5.516 | 4395.3 samples/s | 68.7 steps/s
[Step=19750 Epoch=38.6] | Loss=0.02801 | Reg=0.00538 | acc=0.9844 | L2-Norm=23.195 | L2-Norm(final)=5.513 | 4418.8 samples/s | 69.0 steps/s
[Step=19800 Epoch=38.7] | Loss=0.02775 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.203 | L2-Norm(final)=5.510 | 4542.8 samples/s | 71.0 steps/s
[Step=19850 Epoch=38.8] | Loss=0.02760 | Reg=0.00539 | acc=0.9844 | L2-Norm=23.211 | L2-Norm(final)=5.507 | 4266.4 samples/s | 66.7 steps/s
[Step=19900 Epoch=38.9] | Loss=0.02741 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.219 | L2-Norm(final)=5.504 | 4416.9 samples/s | 69.0 steps/s
[Step=19950 Epoch=39.0] | Loss=0.02716 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.226 | L2-Norm(final)=5.501 | 4511.0 samples/s | 70.5 steps/s
[Step=20000 Epoch=39.1] | Loss=0.02694 | Reg=0.00540 | acc=0.9844 | L2-Norm=23.233 | L2-Norm(final)=5.498 | 4459.5 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step20000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=69.0] | Loss=0.05648 | Reg=0.00203 | acc=0.9688 | L2-Norm=14.251 | L2-Norm(final)=4.262 | 5754.1 samples/s | 89.9 steps/s
[Step=18050 Epoch=69.2] | Loss=0.00463 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.286 | L2-Norm(final)=4.255 | 4254.0 samples/s | 66.5 steps/s
[Step=18100 Epoch=69.4] | Loss=0.00318 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.304 | L2-Norm(final)=4.256 | 4774.7 samples/s | 74.6 steps/s
[Step=18150 Epoch=69.5] | Loss=0.00233 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.313 | L2-Norm(final)=4.261 | 4639.7 samples/s | 72.5 steps/s
[Step=18200 Epoch=69.7] | Loss=0.00191 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.318 | L2-Norm(final)=4.270 | 4611.8 samples/s | 72.1 steps/s
[Step=18250 Epoch=69.9] | Loss=0.00174 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.321 | L2-Norm(final)=4.280 | 6664.7 samples/s | 104.1 steps/s
[Step=18300 Epoch=70.1] | Loss=0.00152 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.329 | L2-Norm(final)=4.291 | 2378.4 samples/s | 37.2 steps/s
[Step=18350 Epoch=70.3] | Loss=0.00133 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.333 | L2-Norm(final)=4.301 | 4783.1 samples/s | 74.7 steps/s
[Step=18400 Epoch=70.5] | Loss=0.00121 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.334 | L2-Norm(final)=4.311 | 4688.2 samples/s | 73.3 steps/s
[Step=18450 Epoch=70.7] | Loss=0.00111 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.335 | L2-Norm(final)=4.321 | 4703.5 samples/s | 73.5 steps/s
[Step=18500 Epoch=70.9] | Loss=0.00102 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.336 | L2-Norm(final)=4.332 | 5346.8 samples/s | 83.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=70.9] | Loss=0.00009 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.341 | L2-Norm(final)=4.434 | 5636.8 samples/s | 88.1 steps/s
[Step=18550 Epoch=71.1] | Loss=0.01264 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.482 | L2-Norm(final)=4.394 | 3978.2 samples/s | 62.2 steps/s
[Step=18600 Epoch=71.3] | Loss=0.01250 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=4.341 | 4102.7 samples/s | 64.1 steps/s
[Step=18650 Epoch=71.5] | Loss=0.00904 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.804 | L2-Norm(final)=4.322 | 4251.5 samples/s | 66.4 steps/s
[Step=18700 Epoch=71.7] | Loss=0.00787 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.856 | L2-Norm(final)=4.317 | 4260.4 samples/s | 66.6 steps/s
[Step=18750 Epoch=71.8] | Loss=0.00667 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.889 | L2-Norm(final)=4.310 | 5517.9 samples/s | 86.2 steps/s
[Step=18800 Epoch=72.0] | Loss=0.00558 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.908 | L2-Norm(final)=4.305 | 2254.1 samples/s | 35.2 steps/s
[Step=18850 Epoch=72.2] | Loss=0.00487 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=4.302 | 4194.0 samples/s | 65.5 steps/s
[Step=18900 Epoch=72.4] | Loss=0.00435 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=4.300 | 4159.4 samples/s | 65.0 steps/s
[Step=18950 Epoch=72.6] | Loss=0.00390 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=4.300 | 4166.4 samples/s | 65.1 steps/s
[Step=19000 Epoch=72.8] | Loss=0.00351 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.928 | L2-Norm(final)=4.300 | 4761.3 samples/s | 74.4 steps/s
[Step=19050 Epoch=73.0] | Loss=0.00322 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=4.301 | 2408.4 samples/s | 37.6 steps/s
[Step=19100 Epoch=73.2] | Loss=0.00296 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.921 | L2-Norm(final)=4.301 | 4246.1 samples/s | 66.3 steps/s
[Step=19150 Epoch=73.4] | Loss=0.00273 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=4.302 | 4256.5 samples/s | 66.5 steps/s
[Step=19200 Epoch=73.6] | Loss=0.00254 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.909 | L2-Norm(final)=4.303 | 4206.4 samples/s | 65.7 steps/s
[Step=19250 Epoch=73.8] | Loss=0.00237 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=4.304 | 4235.7 samples/s | 66.2 steps/s
[Step=19300 Epoch=74.0] | Loss=0.00222 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.892 | L2-Norm(final)=4.305 | 2528.4 samples/s | 39.5 steps/s
[Step=19350 Epoch=74.1] | Loss=0.00209 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=4.306 | 4366.7 samples/s | 68.2 steps/s
[Step=19400 Epoch=74.3] | Loss=0.00198 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.873 | L2-Norm(final)=4.306 | 4061.4 samples/s | 63.5 steps/s
[Step=19450 Epoch=74.5] | Loss=0.00187 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.862 | L2-Norm(final)=4.307 | 4161.6 samples/s | 65.0 steps/s
[Step=19500 Epoch=74.7] | Loss=0.00178 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.851 | L2-Norm(final)=4.308 | 4309.5 samples/s | 67.3 steps/s
[Step=19550 Epoch=74.9] | Loss=0.00169 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=4.309 | 2583.1 samples/s | 40.4 steps/s
[Step=19600 Epoch=75.1] | Loss=0.00162 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=4.310 | 4156.1 samples/s | 64.9 steps/s
[Step=19650 Epoch=75.3] | Loss=0.00155 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=4.311 | 4229.7 samples/s | 66.1 steps/s
[Step=19700 Epoch=75.5] | Loss=0.00148 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.802 | L2-Norm(final)=4.311 | 4245.0 samples/s | 66.3 steps/s
[Step=19750 Epoch=75.7] | Loss=0.00142 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.789 | L2-Norm(final)=4.312 | 4100.9 samples/s | 64.1 steps/s
[Step=19800 Epoch=75.9] | Loss=0.00137 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.775 | L2-Norm(final)=4.313 | 6273.1 samples/s | 98.0 steps/s
[Step=19850 Epoch=76.1] | Loss=0.00132 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=4.314 | 2162.0 samples/s | 33.8 steps/s
[Step=19900 Epoch=76.2] | Loss=0.00127 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=4.315 | 4200.5 samples/s | 65.6 steps/s
[Step=19950 Epoch=76.4] | Loss=0.00123 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=4.315 | 4305.1 samples/s | 67.3 steps/s
[Step=20000 Epoch=76.6] | Loss=0.00119 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=4.316 | 4012.3 samples/s | 62.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step20000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=69.3] | Loss=0.00502 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.481 | L2-Norm(final)=4.796 | 6138.9 samples/s | 95.9 steps/s
[Step=18050 Epoch=69.5] | Loss=0.00155 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=4.824 | 4302.3 samples/s | 67.2 steps/s
[Step=18100 Epoch=69.7] | Loss=0.00152 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=4.841 | 4515.3 samples/s | 70.6 steps/s
[Step=18150 Epoch=69.9] | Loss=0.00127 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.547 | L2-Norm(final)=4.857 | 4721.8 samples/s | 73.8 steps/s
[Step=18200 Epoch=70.1] | Loss=0.00116 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=4.873 | 4747.1 samples/s | 74.2 steps/s
[Step=18250 Epoch=70.3] | Loss=0.00102 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.566 | L2-Norm(final)=4.887 | 6823.8 samples/s | 106.6 steps/s
[Step=18300 Epoch=70.4] | Loss=0.00088 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=4.901 | 2359.9 samples/s | 36.9 steps/s
[Step=18350 Epoch=70.6] | Loss=0.00077 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.571 | L2-Norm(final)=4.913 | 4593.6 samples/s | 71.8 steps/s
[Step=18400 Epoch=70.8] | Loss=0.00069 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=4.925 | 4637.9 samples/s | 72.5 steps/s
[Step=18450 Epoch=71.0] | Loss=0.00063 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.568 | L2-Norm(final)=4.935 | 4733.6 samples/s | 74.0 steps/s
[Step=18500 Epoch=71.2] | Loss=0.00060 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.566 | L2-Norm(final)=4.946 | 5692.9 samples/s | 89.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=71.2] | Loss=0.00325 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=5.051 | 6076.3 samples/s | 94.9 steps/s
[Step=18550 Epoch=71.4] | Loss=0.00530 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=5.056 | 3732.7 samples/s | 58.3 steps/s
[Step=18600 Epoch=71.6] | Loss=0.02048 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.909 | L2-Norm(final)=4.986 | 4242.9 samples/s | 66.3 steps/s
[Step=18650 Epoch=71.8] | Loss=0.01637 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.105 | L2-Norm(final)=4.938 | 4215.6 samples/s | 65.9 steps/s
[Step=18700 Epoch=72.0] | Loss=0.01274 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=4.916 | 4176.6 samples/s | 65.3 steps/s
[Step=18750 Epoch=72.2] | Loss=0.01059 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.264 | L2-Norm(final)=4.905 | 5591.1 samples/s | 87.4 steps/s
[Step=18800 Epoch=72.4] | Loss=0.00900 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.302 | L2-Norm(final)=4.898 | 2223.6 samples/s | 34.7 steps/s
[Step=18850 Epoch=72.6] | Loss=0.00785 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=4.894 | 4213.1 samples/s | 65.8 steps/s
[Step=18900 Epoch=72.8] | Loss=0.00691 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=4.891 | 4256.8 samples/s | 66.5 steps/s
[Step=18950 Epoch=72.9] | Loss=0.00615 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=4.889 | 4120.2 samples/s | 64.4 steps/s
[Step=19000 Epoch=73.1] | Loss=0.00554 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=4.888 | 4899.5 samples/s | 76.6 steps/s
[Step=19050 Epoch=73.3] | Loss=0.00504 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.358 | L2-Norm(final)=4.887 | 2407.1 samples/s | 37.6 steps/s
[Step=19100 Epoch=73.5] | Loss=0.00462 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=4.887 | 4173.0 samples/s | 65.2 steps/s
[Step=19150 Epoch=73.7] | Loss=0.00427 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=4.887 | 4270.0 samples/s | 66.7 steps/s
[Step=19200 Epoch=73.9] | Loss=0.00396 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=4.887 | 4177.5 samples/s | 65.3 steps/s
[Step=19250 Epoch=74.1] | Loss=0.00370 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=4.887 | 4236.9 samples/s | 66.2 steps/s
[Step=19300 Epoch=74.3] | Loss=0.00347 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=4.887 | 2637.6 samples/s | 41.2 steps/s
[Step=19350 Epoch=74.5] | Loss=0.00327 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=4.887 | 4047.3 samples/s | 63.2 steps/s
[Step=19400 Epoch=74.7] | Loss=0.00308 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=4.888 | 4185.7 samples/s | 65.4 steps/s
[Step=19450 Epoch=74.9] | Loss=0.00292 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=4.888 | 4253.7 samples/s | 66.5 steps/s
[Step=19500 Epoch=75.1] | Loss=0.00278 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.299 | L2-Norm(final)=4.888 | 4269.6 samples/s | 66.7 steps/s
[Step=19550 Epoch=75.3] | Loss=0.00265 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=4.889 | 2588.2 samples/s | 40.4 steps/s
[Step=19600 Epoch=75.4] | Loss=0.00253 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.278 | L2-Norm(final)=4.889 | 4334.0 samples/s | 67.7 steps/s
[Step=19650 Epoch=75.6] | Loss=0.00242 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.266 | L2-Norm(final)=4.889 | 4145.6 samples/s | 64.8 steps/s
[Step=19700 Epoch=75.8] | Loss=0.00232 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=4.890 | 4216.8 samples/s | 65.9 steps/s
[Step=19750 Epoch=76.0] | Loss=0.00222 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=4.890 | 4139.6 samples/s | 64.7 steps/s
[Step=19800 Epoch=76.2] | Loss=0.00214 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.229 | L2-Norm(final)=4.891 | 6721.5 samples/s | 105.0 steps/s
[Step=19850 Epoch=76.4] | Loss=0.00206 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.216 | L2-Norm(final)=4.891 | 2089.5 samples/s | 32.6 steps/s
[Step=19900 Epoch=76.6] | Loss=0.00199 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.203 | L2-Norm(final)=4.892 | 4340.6 samples/s | 67.8 steps/s
[Step=19950 Epoch=76.8] | Loss=0.00192 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=4.892 | 4105.3 samples/s | 64.1 steps/s
[Step=20000 Epoch=77.0] | Loss=0.00185 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=4.893 | 4256.0 samples/s | 66.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07082 | acc=0.9608 | tpr=0.9637 | fpr=0.0456 | 4847.1 samples/s | 18.9 steps/s
Avg test loss: 0.06837, Avg test acc: 0.96134, Avg tpr: 0.96334, Avg fpr: 0.04307, total FA: 336

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07126 | acc=0.9624 | tpr=0.9709 | fpr=0.0560 | 4994.9 samples/s | 19.5 steps/s
Avg test loss: 0.07497, Avg test acc: 0.96113, Avg tpr: 0.97045, Avg fpr: 0.05935, total FA: 463

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.97604 | acc=0.3068 | tpr=0.0094 | fpr=0.0473 | 4942.2 samples/s | 19.3 steps/s
Avg test loss: 4.99771, Avg test acc: 0.30515, Avg tpr: 0.01014, Avg fpr: 0.04602, total FA: 359

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.20610 | acc=0.3159 | tpr=0.0132 | fpr=0.0268 | 4968.9 samples/s | 19.4 steps/s
Avg test loss: 5.20138, Avg test acc: 0.31265, Avg tpr: 0.01323, Avg fpr: 0.02884, total FA: 225

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.50590 | acc=0.1578 | tpr=0.5708 | fpr=0.8496 | 5017.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.43608 | acc=0.1571 | tpr=0.5565 | fpr=0.8503 | 7228.3 samples/s | 28.2 steps/s
[Step= 150] | Loss=5.44725 | acc=0.1552 | tpr=0.5634 | fpr=0.8523 | 7413.3 samples/s | 29.0 steps/s
[Step= 200] | Loss=5.45255 | acc=0.1555 | tpr=0.5596 | fpr=0.8519 | 7860.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.45303 | acc=0.1553 | tpr=0.5581 | fpr=0.8520 | 8041.7 samples/s | 31.4 steps/s
[Step= 300] | Loss=5.44909 | acc=0.1555 | tpr=0.5535 | fpr=0.8518 | 7496.9 samples/s | 29.3 steps/s
[Step= 350] | Loss=5.45254 | acc=0.1550 | tpr=0.5423 | fpr=0.8520 | 7780.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.45632 | acc=0.1550 | tpr=0.5388 | fpr=0.8520 | 7713.2 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.46119 | acc=0.1549 | tpr=0.5394 | fpr=0.8521 | 7978.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.46120 | acc=0.1548 | tpr=0.5405 | fpr=0.8522 | 7798.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.46888 | acc=0.1542 | tpr=0.5364 | fpr=0.8528 | 13605.1 samples/s | 53.1 steps/s
Avg test loss: 5.47136, Avg test acc: 0.15402, Avg tpr: 0.53724, Avg fpr: 0.85295, total FA: 118430

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.34130 | acc=0.1149 | tpr=0.7345 | fpr=0.8962 | 5268.6 samples/s | 20.6 steps/s
[Step= 100] | Loss=8.28425 | acc=0.1128 | tpr=0.6823 | fpr=0.8979 | 6606.8 samples/s | 25.8 steps/s
[Step= 150] | Loss=8.30862 | acc=0.1127 | tpr=0.6816 | fpr=0.8978 | 7473.5 samples/s | 29.2 steps/s
[Step= 200] | Loss=8.29636 | acc=0.1132 | tpr=0.6831 | fpr=0.8971 | 7707.4 samples/s | 30.1 steps/s
[Step= 250] | Loss=8.28205 | acc=0.1130 | tpr=0.6812 | fpr=0.8973 | 7855.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=8.28524 | acc=0.1124 | tpr=0.6713 | fpr=0.8978 | 7950.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=8.28486 | acc=0.1119 | tpr=0.6688 | fpr=0.8982 | 7978.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=8.28333 | acc=0.1117 | tpr=0.6685 | fpr=0.8984 | 7812.5 samples/s | 30.5 steps/s
[Step= 450] | Loss=8.28931 | acc=0.1118 | tpr=0.6738 | fpr=0.8984 | 7386.3 samples/s | 28.9 steps/s
[Step= 500] | Loss=8.28991 | acc=0.1115 | tpr=0.6700 | fpr=0.8986 | 8053.6 samples/s | 31.5 steps/s
[Step= 550] | Loss=8.29568 | acc=0.1115 | tpr=0.6701 | fpr=0.8987 | 13890.6 samples/s | 54.3 steps/s
Avg test loss: 8.29822, Avg test acc: 0.11139, Avg tpr: 0.67036, Avg fpr: 0.89877, total FA: 124792

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12674 | acc=0.9781 | tpr=0.9292 | fpr=0.0210 | 4949.6 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.13590 | acc=0.9775 | tpr=0.9339 | fpr=0.0217 | 6937.5 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.13948 | acc=0.9771 | tpr=0.9323 | fpr=0.0220 | 8139.4 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.14128 | acc=0.9773 | tpr=0.9355 | fpr=0.0219 | 7323.0 samples/s | 28.6 steps/s
[Step= 250] | Loss=0.13954 | acc=0.9775 | tpr=0.9345 | fpr=0.0217 | 8182.8 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.14107 | acc=0.9773 | tpr=0.9353 | fpr=0.0219 | 7728.7 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.14234 | acc=0.9771 | tpr=0.9361 | fpr=0.0222 | 7892.2 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.14372 | acc=0.9770 | tpr=0.9316 | fpr=0.0222 | 7797.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.14672 | acc=0.9768 | tpr=0.9338 | fpr=0.0224 | 7791.6 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.14604 | acc=0.9769 | tpr=0.9366 | fpr=0.0223 | 7943.4 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.14557 | acc=0.9771 | tpr=0.9363 | fpr=0.0221 | 13523.7 samples/s | 52.8 steps/s
Avg test loss: 0.14535, Avg test acc: 0.97716, Avg tpr: 0.93621, Avg fpr: 0.02210, total FA: 3068

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14057 | acc=0.9777 | tpr=0.9248 | fpr=0.0214 | 4913.0 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.14643 | acc=0.9771 | tpr=0.9424 | fpr=0.0222 | 7055.8 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.15143 | acc=0.9766 | tpr=0.9452 | fpr=0.0228 | 8003.4 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.15341 | acc=0.9766 | tpr=0.9464 | fpr=0.0228 | 7604.0 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.15144 | acc=0.9768 | tpr=0.9485 | fpr=0.0227 | 7496.5 samples/s | 29.3 steps/s
[Step= 300] | Loss=0.15373 | acc=0.9766 | tpr=0.9491 | fpr=0.0229 | 8037.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.15380 | acc=0.9766 | tpr=0.9493 | fpr=0.0230 | 7776.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.15429 | acc=0.9766 | tpr=0.9464 | fpr=0.0229 | 7943.9 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.15649 | acc=0.9762 | tpr=0.9469 | fpr=0.0232 | 8020.1 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.15580 | acc=0.9763 | tpr=0.9458 | fpr=0.0231 | 7624.4 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.15480 | acc=0.9765 | tpr=0.9455 | fpr=0.0229 | 13635.8 samples/s | 53.3 steps/s
Avg test loss: 0.15449, Avg test acc: 0.97656, Avg tpr: 0.94532, Avg fpr: 0.02287, total FA: 3176

server round 10/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=39.0] | Loss=0.02641 | Reg=0.00528 | acc=0.9688 | L2-Norm=22.975 | L2-Norm(final)=5.405 | 6739.0 samples/s | 105.3 steps/s
[Step=20050 Epoch=39.1] | Loss=0.03601 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.975 | L2-Norm(final)=5.425 | 4276.2 samples/s | 66.8 steps/s
[Step=20100 Epoch=39.2] | Loss=0.03501 | Reg=0.00528 | acc=0.9531 | L2-Norm=22.978 | L2-Norm(final)=5.449 | 5052.6 samples/s | 78.9 steps/s
[Step=20150 Epoch=39.3] | Loss=0.03661 | Reg=0.00528 | acc=0.9688 | L2-Norm=22.984 | L2-Norm(final)=5.471 | 5013.1 samples/s | 78.3 steps/s
[Step=20200 Epoch=39.4] | Loss=0.03583 | Reg=0.00529 | acc=0.9844 | L2-Norm=22.990 | L2-Norm(final)=5.490 | 4916.1 samples/s | 76.8 steps/s
[Step=20250 Epoch=39.5] | Loss=0.03545 | Reg=0.00529 | acc=0.9844 | L2-Norm=22.998 | L2-Norm(final)=5.509 | 4918.3 samples/s | 76.8 steps/s
[Step=20300 Epoch=39.6] | Loss=0.03440 | Reg=0.00529 | acc=1.0000 | L2-Norm=23.004 | L2-Norm(final)=5.528 | 5009.9 samples/s | 78.3 steps/s
[Step=20350 Epoch=39.7] | Loss=0.03359 | Reg=0.00529 | acc=0.9531 | L2-Norm=23.011 | L2-Norm(final)=5.547 | 4997.6 samples/s | 78.1 steps/s
[Step=20400 Epoch=39.8] | Loss=0.03302 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.016 | L2-Norm(final)=5.563 | 5009.7 samples/s | 78.3 steps/s
[Step=20450 Epoch=39.9] | Loss=0.03217 | Reg=0.00530 | acc=0.9688 | L2-Norm=23.021 | L2-Norm(final)=5.580 | 5057.5 samples/s | 79.0 steps/s
[Step=20500 Epoch=40.0] | Loss=0.03156 | Reg=0.00530 | acc=0.9688 | L2-Norm=23.025 | L2-Norm(final)=5.597 | 6591.5 samples/s | 103.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=40.0] | Loss=0.04805 | Reg=0.00532 | acc=0.9688 | L2-Norm=23.068 | L2-Norm(final)=5.758 | 5659.2 samples/s | 88.4 steps/s
[Step=20550 Epoch=40.1] | Loss=0.02419 | Reg=0.00532 | acc=0.9688 | L2-Norm=23.074 | L2-Norm(final)=5.769 | 4317.0 samples/s | 67.5 steps/s
[Step=20600 Epoch=40.2] | Loss=0.02382 | Reg=0.00533 | acc=0.9531 | L2-Norm=23.077 | L2-Norm(final)=5.774 | 4473.4 samples/s | 69.9 steps/s
[Step=20650 Epoch=40.3] | Loss=0.02180 | Reg=0.00533 | acc=0.9688 | L2-Norm=23.077 | L2-Norm(final)=5.777 | 4427.2 samples/s | 69.2 steps/s
[Step=20700 Epoch=40.4] | Loss=0.02152 | Reg=0.00533 | acc=0.9844 | L2-Norm=23.076 | L2-Norm(final)=5.780 | 4435.4 samples/s | 69.3 steps/s
[Step=20750 Epoch=40.5] | Loss=0.02071 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.076 | L2-Norm(final)=5.781 | 4474.2 samples/s | 69.9 steps/s
[Step=20800 Epoch=40.6] | Loss=0.02030 | Reg=0.00532 | acc=0.9531 | L2-Norm=23.074 | L2-Norm(final)=5.782 | 4412.6 samples/s | 68.9 steps/s
[Step=20850 Epoch=40.7] | Loss=0.02059 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.071 | L2-Norm(final)=5.783 | 4400.0 samples/s | 68.7 steps/s
[Step=20900 Epoch=40.8] | Loss=0.02007 | Reg=0.00532 | acc=0.9688 | L2-Norm=23.068 | L2-Norm(final)=5.784 | 4347.2 samples/s | 67.9 steps/s
[Step=20950 Epoch=40.9] | Loss=0.01984 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.064 | L2-Norm(final)=5.785 | 4506.3 samples/s | 70.4 steps/s
[Step=21000 Epoch=41.0] | Loss=0.01948 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.060 | L2-Norm(final)=5.786 | 5701.4 samples/s | 89.1 steps/s
[Step=21050 Epoch=41.1] | Loss=0.01913 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.056 | L2-Norm(final)=5.787 | 2371.8 samples/s | 37.1 steps/s
[Step=21100 Epoch=41.2] | Loss=0.01848 | Reg=0.00531 | acc=0.9688 | L2-Norm=23.052 | L2-Norm(final)=5.788 | 4513.5 samples/s | 70.5 steps/s
[Step=21150 Epoch=41.3] | Loss=0.01806 | Reg=0.00531 | acc=0.9844 | L2-Norm=23.047 | L2-Norm(final)=5.790 | 4379.0 samples/s | 68.4 steps/s
[Step=21200 Epoch=41.3] | Loss=0.01768 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.043 | L2-Norm(final)=5.792 | 4366.4 samples/s | 68.2 steps/s
[Step=21250 Epoch=41.4] | Loss=0.01766 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.038 | L2-Norm(final)=5.794 | 4504.2 samples/s | 70.4 steps/s
[Step=21300 Epoch=41.5] | Loss=0.01752 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.034 | L2-Norm(final)=5.795 | 4489.6 samples/s | 70.2 steps/s
[Step=21350 Epoch=41.6] | Loss=0.01724 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.029 | L2-Norm(final)=5.797 | 4302.7 samples/s | 67.2 steps/s
[Step=21400 Epoch=41.7] | Loss=0.01701 | Reg=0.00530 | acc=0.9688 | L2-Norm=23.025 | L2-Norm(final)=5.798 | 4421.0 samples/s | 69.1 steps/s
[Step=21450 Epoch=41.8] | Loss=0.01689 | Reg=0.00530 | acc=0.9531 | L2-Norm=23.020 | L2-Norm(final)=5.799 | 4413.0 samples/s | 69.0 steps/s
[Step=21500 Epoch=41.9] | Loss=0.01660 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.015 | L2-Norm(final)=5.800 | 4643.5 samples/s | 72.6 steps/s
[Step=21550 Epoch=42.0] | Loss=0.01644 | Reg=0.00529 | acc=0.9844 | L2-Norm=23.010 | L2-Norm(final)=5.801 | 2628.3 samples/s | 41.1 steps/s
[Step=21600 Epoch=42.1] | Loss=0.01616 | Reg=0.00529 | acc=0.9844 | L2-Norm=23.004 | L2-Norm(final)=5.802 | 4366.5 samples/s | 68.2 steps/s
[Step=21650 Epoch=42.2] | Loss=0.01585 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.998 | L2-Norm(final)=5.803 | 4411.0 samples/s | 68.9 steps/s
[Step=21700 Epoch=42.3] | Loss=0.01563 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.993 | L2-Norm(final)=5.805 | 4465.4 samples/s | 69.8 steps/s
[Step=21750 Epoch=42.4] | Loss=0.01542 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.987 | L2-Norm(final)=5.806 | 4464.0 samples/s | 69.7 steps/s
[Step=21800 Epoch=42.5] | Loss=0.01524 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.981 | L2-Norm(final)=5.807 | 4353.0 samples/s | 68.0 steps/s
[Step=21850 Epoch=42.6] | Loss=0.01527 | Reg=0.00528 | acc=0.9688 | L2-Norm=22.974 | L2-Norm(final)=5.808 | 4479.2 samples/s | 70.0 steps/s
[Step=21900 Epoch=42.7] | Loss=0.01514 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.967 | L2-Norm(final)=5.809 | 4398.4 samples/s | 68.7 steps/s
[Step=21950 Epoch=42.8] | Loss=0.01499 | Reg=0.00527 | acc=0.9844 | L2-Norm=22.961 | L2-Norm(final)=5.810 | 4333.6 samples/s | 67.7 steps/s
[Step=22000 Epoch=42.9] | Loss=0.01484 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.954 | L2-Norm(final)=5.812 | 4466.1 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step22000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=39.1] | Loss=0.03062 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.823 | L2-Norm(final)=5.409 | 5991.6 samples/s | 93.6 steps/s
[Step=20050 Epoch=39.2] | Loss=0.04004 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.826 | L2-Norm(final)=5.426 | 4648.2 samples/s | 72.6 steps/s
[Step=20100 Epoch=39.3] | Loss=0.03691 | Reg=0.00521 | acc=0.9531 | L2-Norm=22.828 | L2-Norm(final)=5.452 | 4941.0 samples/s | 77.2 steps/s
[Step=20150 Epoch=39.4] | Loss=0.03586 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.830 | L2-Norm(final)=5.475 | 5089.9 samples/s | 79.5 steps/s
[Step=20200 Epoch=39.5] | Loss=0.03469 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.833 | L2-Norm(final)=5.493 | 4954.6 samples/s | 77.4 steps/s
[Step=20250 Epoch=39.6] | Loss=0.03327 | Reg=0.00521 | acc=0.9531 | L2-Norm=22.834 | L2-Norm(final)=5.511 | 4957.3 samples/s | 77.5 steps/s
[Step=20300 Epoch=39.7] | Loss=0.03299 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.835 | L2-Norm(final)=5.526 | 4911.5 samples/s | 76.7 steps/s
[Step=20350 Epoch=39.8] | Loss=0.03198 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.835 | L2-Norm(final)=5.540 | 5025.7 samples/s | 78.5 steps/s
[Step=20400 Epoch=39.9] | Loss=0.03129 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.836 | L2-Norm(final)=5.553 | 5012.4 samples/s | 78.3 steps/s
[Step=20450 Epoch=40.0] | Loss=0.03093 | Reg=0.00522 | acc=0.9844 | L2-Norm=22.837 | L2-Norm(final)=5.566 | 5023.6 samples/s | 78.5 steps/s
[Step=20500 Epoch=40.1] | Loss=0.03073 | Reg=0.00522 | acc=0.9531 | L2-Norm=22.840 | L2-Norm(final)=5.579 | 6870.4 samples/s | 107.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=40.1] | Loss=0.02364 | Reg=0.00523 | acc=0.9688 | L2-Norm=22.863 | L2-Norm(final)=5.702 | 6068.1 samples/s | 94.8 steps/s
[Step=20550 Epoch=40.2] | Loss=0.02276 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.867 | L2-Norm(final)=5.717 | 4310.2 samples/s | 67.3 steps/s
[Step=20600 Epoch=40.3] | Loss=0.02087 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.874 | L2-Norm(final)=5.726 | 4409.3 samples/s | 68.9 steps/s
[Step=20650 Epoch=40.4] | Loss=0.02205 | Reg=0.00523 | acc=0.9688 | L2-Norm=22.878 | L2-Norm(final)=5.731 | 4435.0 samples/s | 69.3 steps/s
[Step=20700 Epoch=40.5] | Loss=0.02165 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.881 | L2-Norm(final)=5.732 | 4383.4 samples/s | 68.5 steps/s
[Step=20750 Epoch=40.6] | Loss=0.02142 | Reg=0.00524 | acc=0.9688 | L2-Norm=22.883 | L2-Norm(final)=5.733 | 4411.8 samples/s | 68.9 steps/s
[Step=20800 Epoch=40.7] | Loss=0.02068 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.883 | L2-Norm(final)=5.733 | 4449.1 samples/s | 69.5 steps/s
[Step=20850 Epoch=40.8] | Loss=0.02058 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.882 | L2-Norm(final)=5.734 | 4459.3 samples/s | 69.7 steps/s
[Step=20900 Epoch=40.9] | Loss=0.02019 | Reg=0.00524 | acc=0.9688 | L2-Norm=22.881 | L2-Norm(final)=5.734 | 4431.9 samples/s | 69.2 steps/s
[Step=20950 Epoch=41.0] | Loss=0.01976 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.880 | L2-Norm(final)=5.735 | 4514.8 samples/s | 70.5 steps/s
[Step=21000 Epoch=41.1] | Loss=0.01988 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.878 | L2-Norm(final)=5.735 | 5726.8 samples/s | 89.5 steps/s
[Step=21050 Epoch=41.2] | Loss=0.01928 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.876 | L2-Norm(final)=5.736 | 2349.1 samples/s | 36.7 steps/s
[Step=21100 Epoch=41.2] | Loss=0.01866 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.873 | L2-Norm(final)=5.736 | 4466.3 samples/s | 69.8 steps/s
[Step=21150 Epoch=41.3] | Loss=0.01837 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.870 | L2-Norm(final)=5.737 | 4426.5 samples/s | 69.2 steps/s
[Step=21200 Epoch=41.4] | Loss=0.01793 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.866 | L2-Norm(final)=5.738 | 4367.8 samples/s | 68.2 steps/s
[Step=21250 Epoch=41.5] | Loss=0.01748 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.862 | L2-Norm(final)=5.739 | 4417.9 samples/s | 69.0 steps/s
[Step=21300 Epoch=41.6] | Loss=0.01725 | Reg=0.00522 | acc=0.9844 | L2-Norm=22.857 | L2-Norm(final)=5.739 | 4463.6 samples/s | 69.7 steps/s
[Step=21350 Epoch=41.7] | Loss=0.01703 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.853 | L2-Norm(final)=5.740 | 4392.3 samples/s | 68.6 steps/s
[Step=21400 Epoch=41.8] | Loss=0.01682 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.848 | L2-Norm(final)=5.741 | 4499.1 samples/s | 70.3 steps/s
[Step=21450 Epoch=41.9] | Loss=0.01648 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.843 | L2-Norm(final)=5.742 | 4433.0 samples/s | 69.3 steps/s
[Step=21500 Epoch=42.0] | Loss=0.01612 | Reg=0.00522 | acc=0.9844 | L2-Norm=22.838 | L2-Norm(final)=5.744 | 4815.2 samples/s | 75.2 steps/s
[Step=21550 Epoch=42.1] | Loss=0.01587 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.833 | L2-Norm(final)=5.746 | 2545.5 samples/s | 39.8 steps/s
[Step=21600 Epoch=42.2] | Loss=0.01566 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.828 | L2-Norm(final)=5.747 | 4440.8 samples/s | 69.4 steps/s
[Step=21650 Epoch=42.3] | Loss=0.01543 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.822 | L2-Norm(final)=5.748 | 4391.6 samples/s | 68.6 steps/s
[Step=21700 Epoch=42.4] | Loss=0.01519 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.817 | L2-Norm(final)=5.750 | 4457.3 samples/s | 69.6 steps/s
[Step=21750 Epoch=42.5] | Loss=0.01509 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.811 | L2-Norm(final)=5.751 | 4476.1 samples/s | 69.9 steps/s
[Step=21800 Epoch=42.6] | Loss=0.01489 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.805 | L2-Norm(final)=5.753 | 4390.4 samples/s | 68.6 steps/s
[Step=21850 Epoch=42.7] | Loss=0.01472 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.799 | L2-Norm(final)=5.754 | 4441.6 samples/s | 69.4 steps/s
[Step=21900 Epoch=42.8] | Loss=0.01456 | Reg=0.00520 | acc=0.9688 | L2-Norm=22.793 | L2-Norm(final)=5.756 | 4371.7 samples/s | 68.3 steps/s
[Step=21950 Epoch=42.9] | Loss=0.01450 | Reg=0.00519 | acc=1.0000 | L2-Norm=22.787 | L2-Norm(final)=5.757 | 4436.6 samples/s | 69.3 steps/s
[Step=22000 Epoch=43.0] | Loss=0.01439 | Reg=0.00519 | acc=1.0000 | L2-Norm=22.781 | L2-Norm(final)=5.758 | 4407.4 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step22000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=76.6] | Loss=0.03821 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.324 | L2-Norm(final)=4.339 | 6827.7 samples/s | 106.7 steps/s
[Step=20050 Epoch=76.8] | Loss=0.00221 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.337 | L2-Norm(final)=4.340 | 4012.0 samples/s | 62.7 steps/s
[Step=20100 Epoch=77.0] | Loss=0.00152 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.342 | L2-Norm(final)=4.346 | 4691.1 samples/s | 73.3 steps/s
[Step=20150 Epoch=77.2] | Loss=0.00124 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.346 | L2-Norm(final)=4.354 | 4761.7 samples/s | 74.4 steps/s
[Step=20200 Epoch=77.4] | Loss=0.00102 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.349 | L2-Norm(final)=4.362 | 4849.9 samples/s | 75.8 steps/s
[Step=20250 Epoch=77.6] | Loss=0.00088 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.352 | L2-Norm(final)=4.369 | 6235.7 samples/s | 97.4 steps/s
[Step=20300 Epoch=77.8] | Loss=0.00089 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.354 | L2-Norm(final)=4.375 | 2364.5 samples/s | 36.9 steps/s
[Step=20350 Epoch=78.0] | Loss=0.00080 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.356 | L2-Norm(final)=4.381 | 4741.6 samples/s | 74.1 steps/s
[Step=20400 Epoch=78.2] | Loss=0.00078 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.357 | L2-Norm(final)=4.387 | 4674.6 samples/s | 73.0 steps/s
[Step=20450 Epoch=78.4] | Loss=0.00072 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.359 | L2-Norm(final)=4.392 | 4605.7 samples/s | 72.0 steps/s
[Step=20500 Epoch=78.5] | Loss=0.00069 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.360 | L2-Norm(final)=4.398 | 5504.9 samples/s | 86.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=78.6] | Loss=0.00112 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.370 | L2-Norm(final)=4.459 | 5954.8 samples/s | 93.0 steps/s
[Step=20550 Epoch=78.7] | Loss=0.00015 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=4.465 | 3834.5 samples/s | 59.9 steps/s
[Step=20600 Epoch=78.9] | Loss=0.00051 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.360 | L2-Norm(final)=4.469 | 4139.8 samples/s | 64.7 steps/s
[Step=20650 Epoch=79.1] | Loss=0.00046 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.364 | L2-Norm(final)=4.472 | 4194.1 samples/s | 65.5 steps/s
[Step=20700 Epoch=79.3] | Loss=0.00063 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.367 | L2-Norm(final)=4.476 | 4213.9 samples/s | 65.8 steps/s
[Step=20750 Epoch=79.5] | Loss=0.00070 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=4.478 | 5614.8 samples/s | 87.7 steps/s
[Step=20800 Epoch=79.7] | Loss=0.00074 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=4.482 | 2249.6 samples/s | 35.1 steps/s
[Step=20850 Epoch=79.9] | Loss=0.00072 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.390 | L2-Norm(final)=4.485 | 4218.2 samples/s | 65.9 steps/s
[Step=20900 Epoch=80.1] | Loss=0.00072 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.396 | L2-Norm(final)=4.488 | 4175.3 samples/s | 65.2 steps/s
[Step=20950 Epoch=80.3] | Loss=0.00072 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.400 | L2-Norm(final)=4.490 | 4170.0 samples/s | 65.2 steps/s
[Step=21000 Epoch=80.5] | Loss=0.00112 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.406 | L2-Norm(final)=4.491 | 4727.9 samples/s | 73.9 steps/s
[Step=21050 Epoch=80.7] | Loss=0.00103 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.412 | L2-Norm(final)=4.490 | 2436.8 samples/s | 38.1 steps/s
[Step=21100 Epoch=80.8] | Loss=0.00094 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.416 | L2-Norm(final)=4.489 | 4193.6 samples/s | 65.5 steps/s
[Step=21150 Epoch=81.0] | Loss=0.00087 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.418 | L2-Norm(final)=4.489 | 4298.4 samples/s | 67.2 steps/s
[Step=21200 Epoch=81.2] | Loss=0.00081 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.419 | L2-Norm(final)=4.488 | 4134.8 samples/s | 64.6 steps/s
[Step=21250 Epoch=81.4] | Loss=0.00076 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.419 | L2-Norm(final)=4.488 | 4336.7 samples/s | 67.8 steps/s
[Step=21300 Epoch=81.6] | Loss=0.00072 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.418 | L2-Norm(final)=4.488 | 2551.7 samples/s | 39.9 steps/s
[Step=21350 Epoch=81.8] | Loss=0.00068 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.416 | L2-Norm(final)=4.488 | 4207.0 samples/s | 65.7 steps/s
[Step=21400 Epoch=82.0] | Loss=0.00064 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.414 | L2-Norm(final)=4.489 | 4244.1 samples/s | 66.3 steps/s
[Step=21450 Epoch=82.2] | Loss=0.00061 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.411 | L2-Norm(final)=4.489 | 4194.1 samples/s | 65.5 steps/s
[Step=21500 Epoch=82.4] | Loss=0.00058 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.407 | L2-Norm(final)=4.489 | 4165.8 samples/s | 65.1 steps/s
[Step=21550 Epoch=82.6] | Loss=0.00055 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.403 | L2-Norm(final)=4.489 | 2686.2 samples/s | 42.0 steps/s
[Step=21600 Epoch=82.8] | Loss=0.00052 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.398 | L2-Norm(final)=4.489 | 4038.9 samples/s | 63.1 steps/s
[Step=21650 Epoch=83.0] | Loss=0.00050 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.394 | L2-Norm(final)=4.490 | 4168.7 samples/s | 65.1 steps/s
[Step=21700 Epoch=83.1] | Loss=0.00048 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.388 | L2-Norm(final)=4.490 | 4177.1 samples/s | 65.3 steps/s
[Step=21750 Epoch=83.3] | Loss=0.00046 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=4.490 | 4217.5 samples/s | 65.9 steps/s
[Step=21800 Epoch=83.5] | Loss=0.00044 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.377 | L2-Norm(final)=4.490 | 6044.0 samples/s | 94.4 steps/s
[Step=21850 Epoch=83.7] | Loss=0.00043 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.371 | L2-Norm(final)=4.490 | 2180.6 samples/s | 34.1 steps/s
[Step=21900 Epoch=83.9] | Loss=0.00041 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.364 | L2-Norm(final)=4.491 | 4185.1 samples/s | 65.4 steps/s
[Step=21950 Epoch=84.1] | Loss=0.00040 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=4.491 | 4126.2 samples/s | 64.5 steps/s
[Step=22000 Epoch=84.3] | Loss=0.00039 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.351 | L2-Norm(final)=4.491 | 4264.6 samples/s | 66.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step22000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=77.0] | Loss=0.00024 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=4.909 | 6451.7 samples/s | 100.8 steps/s
[Step=20050 Epoch=77.2] | Loss=0.00190 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=4.906 | 4086.5 samples/s | 63.9 steps/s
[Step=20100 Epoch=77.4] | Loss=0.00197 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=4.915 | 4574.5 samples/s | 71.5 steps/s
[Step=20150 Epoch=77.6] | Loss=0.00163 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=4.922 | 4705.9 samples/s | 73.5 steps/s
[Step=20200 Epoch=77.8] | Loss=0.00145 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=4.929 | 4787.6 samples/s | 74.8 steps/s
[Step=20250 Epoch=78.0] | Loss=0.00128 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=4.935 | 6502.7 samples/s | 101.6 steps/s
[Step=20300 Epoch=78.1] | Loss=0.00112 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=4.941 | 2375.9 samples/s | 37.1 steps/s
[Step=20350 Epoch=78.3] | Loss=0.00101 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=4.946 | 4685.5 samples/s | 73.2 steps/s
[Step=20400 Epoch=78.5] | Loss=0.00093 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=4.952 | 4646.7 samples/s | 72.6 steps/s
[Step=20450 Epoch=78.7] | Loss=0.00085 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=4.957 | 4778.2 samples/s | 74.7 steps/s
[Step=20500 Epoch=78.9] | Loss=0.00080 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=4.963 | 5485.1 samples/s | 85.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=78.9] | Loss=0.00010 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=5.019 | 6572.5 samples/s | 102.7 steps/s
[Step=20550 Epoch=79.1] | Loss=0.00017 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=5.025 | 3644.4 samples/s | 56.9 steps/s
[Step=20600 Epoch=79.3] | Loss=0.00015 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=5.028 | 4161.7 samples/s | 65.0 steps/s
[Step=20650 Epoch=79.5] | Loss=0.00014 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.644 | L2-Norm(final)=5.032 | 4201.4 samples/s | 65.6 steps/s
[Step=20700 Epoch=79.7] | Loss=0.00012 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.635 | L2-Norm(final)=5.036 | 4222.8 samples/s | 66.0 steps/s
[Step=20750 Epoch=79.9] | Loss=0.00011 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=5.038 | 5703.1 samples/s | 89.1 steps/s
[Step=20800 Epoch=80.1] | Loss=0.00009 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=5.041 | 2229.7 samples/s | 34.8 steps/s
[Step=20850 Epoch=80.3] | Loss=0.00008 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.602 | L2-Norm(final)=5.043 | 4174.4 samples/s | 65.2 steps/s
[Step=20900 Epoch=80.5] | Loss=0.00007 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=5.045 | 4238.0 samples/s | 66.2 steps/s
[Step=20950 Epoch=80.6] | Loss=0.00007 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.579 | L2-Norm(final)=5.046 | 4118.9 samples/s | 64.4 steps/s
[Step=21000 Epoch=80.8] | Loss=0.00006 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.567 | L2-Norm(final)=5.047 | 4933.7 samples/s | 77.1 steps/s
[Step=21050 Epoch=81.0] | Loss=0.00006 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.554 | L2-Norm(final)=5.048 | 2400.3 samples/s | 37.5 steps/s
[Step=21100 Epoch=81.2] | Loss=0.00005 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=5.049 | 4139.7 samples/s | 64.7 steps/s
[Step=21150 Epoch=81.4] | Loss=0.00005 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=5.050 | 4181.3 samples/s | 65.3 steps/s
[Step=21200 Epoch=81.6] | Loss=0.00005 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.516 | L2-Norm(final)=5.051 | 4145.3 samples/s | 64.8 steps/s
[Step=21250 Epoch=81.8] | Loss=0.00004 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=5.052 | 4326.0 samples/s | 67.6 steps/s
[Step=21300 Epoch=82.0] | Loss=0.00004 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.490 | L2-Norm(final)=5.053 | 2567.4 samples/s | 40.1 steps/s
[Step=21350 Epoch=82.2] | Loss=0.00004 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.477 | L2-Norm(final)=5.053 | 4222.1 samples/s | 66.0 steps/s
[Step=21400 Epoch=82.4] | Loss=0.00004 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.463 | L2-Norm(final)=5.054 | 4180.5 samples/s | 65.3 steps/s
[Step=21450 Epoch=82.6] | Loss=0.00003 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.450 | L2-Norm(final)=5.055 | 4257.5 samples/s | 66.5 steps/s
[Step=21500 Epoch=82.8] | Loss=0.00003 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.436 | L2-Norm(final)=5.055 | 4044.3 samples/s | 63.2 steps/s
[Step=21550 Epoch=83.0] | Loss=0.00003 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.422 | L2-Norm(final)=5.056 | 2677.5 samples/s | 41.8 steps/s
[Step=21600 Epoch=83.1] | Loss=0.00003 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.408 | L2-Norm(final)=5.056 | 4054.4 samples/s | 63.3 steps/s
[Step=21650 Epoch=83.3] | Loss=0.00003 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.394 | L2-Norm(final)=5.057 | 4270.9 samples/s | 66.7 steps/s
[Step=21700 Epoch=83.5] | Loss=0.00003 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.380 | L2-Norm(final)=5.058 | 4133.8 samples/s | 64.6 steps/s
[Step=21750 Epoch=83.7] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=5.058 | 4184.8 samples/s | 65.4 steps/s
[Step=21800 Epoch=83.9] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.351 | L2-Norm(final)=5.059 | 6980.6 samples/s | 109.1 steps/s
[Step=21850 Epoch=84.1] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.336 | L2-Norm(final)=5.059 | 2077.3 samples/s | 32.5 steps/s
[Step=21900 Epoch=84.3] | Loss=0.00002 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.321 | L2-Norm(final)=5.060 | 4206.7 samples/s | 65.7 steps/s
[Step=21950 Epoch=84.5] | Loss=0.00002 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.306 | L2-Norm(final)=5.060 | 4206.4 samples/s | 65.7 steps/s
[Step=22000 Epoch=84.7] | Loss=0.00002 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.291 | L2-Norm(final)=5.061 | 4199.6 samples/s | 65.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07417 | acc=0.9648 | tpr=0.9708 | fpr=0.0483 | 4930.8 samples/s | 19.3 steps/s
Avg test loss: 0.07140, Avg test acc: 0.96538, Avg tpr: 0.97156, Avg fpr: 0.04820, total FA: 376

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07054 | acc=0.9683 | tpr=0.9804 | fpr=0.0580 | 5087.1 samples/s | 19.9 steps/s
Avg test loss: 0.07182, Avg test acc: 0.96678, Avg tpr: 0.97960, Avg fpr: 0.06140, total FA: 479

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.09048 | acc=0.2997 | tpr=0.0114 | fpr=0.0743 | 4820.8 samples/s | 18.8 steps/s
Avg test loss: 7.08470, Avg test acc: 0.29638, Avg tpr: 0.01212, Avg fpr: 0.07845, total FA: 612

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.27178 | acc=0.3148 | tpr=0.0204 | fpr=0.0458 | 5106.4 samples/s | 19.9 steps/s
Avg test loss: 6.25426, Avg test acc: 0.31184, Avg tpr: 0.02145, Avg fpr: 0.04948, total FA: 386

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.33762 | acc=0.1427 | tpr=0.4735 | fpr=0.8633 | 4815.0 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.30934 | acc=0.1425 | tpr=0.4627 | fpr=0.8635 | 7483.1 samples/s | 29.2 steps/s
[Step= 150] | Loss=6.31040 | acc=0.1423 | tpr=0.4496 | fpr=0.8633 | 7698.3 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.29738 | acc=0.1424 | tpr=0.4525 | fpr=0.8632 | 7878.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.29446 | acc=0.1424 | tpr=0.4620 | fpr=0.8635 | 7767.2 samples/s | 30.3 steps/s
[Step= 300] | Loss=6.29308 | acc=0.1418 | tpr=0.4625 | fpr=0.8640 | 7760.0 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.29530 | acc=0.1414 | tpr=0.4565 | fpr=0.8644 | 7625.3 samples/s | 29.8 steps/s
[Step= 400] | Loss=6.29669 | acc=0.1414 | tpr=0.4508 | fpr=0.8642 | 7999.7 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.30251 | acc=0.1413 | tpr=0.4537 | fpr=0.8644 | 7799.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.30197 | acc=0.1414 | tpr=0.4555 | fpr=0.8642 | 8084.2 samples/s | 31.6 steps/s
[Step= 550] | Loss=6.30688 | acc=0.1414 | tpr=0.4564 | fpr=0.8643 | 13344.8 samples/s | 52.1 steps/s
Avg test loss: 6.30930, Avg test acc: 0.14134, Avg tpr: 0.45761, Avg fpr: 0.86441, total FA: 120022

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.87899 | acc=0.1152 | tpr=0.7345 | fpr=0.8960 | 5062.9 samples/s | 19.8 steps/s
[Step= 100] | Loss=8.84244 | acc=0.1136 | tpr=0.7143 | fpr=0.8976 | 6835.4 samples/s | 26.7 steps/s
[Step= 150] | Loss=8.85045 | acc=0.1133 | tpr=0.7075 | fpr=0.8977 | 7901.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=8.83413 | acc=0.1128 | tpr=0.7016 | fpr=0.8979 | 7291.1 samples/s | 28.5 steps/s
[Step= 250] | Loss=8.82076 | acc=0.1123 | tpr=0.6969 | fpr=0.8984 | 8045.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=8.81704 | acc=0.1121 | tpr=0.6916 | fpr=0.8985 | 8320.1 samples/s | 32.5 steps/s
[Step= 350] | Loss=8.82115 | acc=0.1120 | tpr=0.6832 | fpr=0.8984 | 7560.5 samples/s | 29.5 steps/s
[Step= 400] | Loss=8.82256 | acc=0.1119 | tpr=0.6811 | fpr=0.8985 | 7803.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=8.83250 | acc=0.1119 | tpr=0.6821 | fpr=0.8985 | 7756.7 samples/s | 30.3 steps/s
[Step= 500] | Loss=8.83366 | acc=0.1120 | tpr=0.6868 | fpr=0.8984 | 8144.1 samples/s | 31.8 steps/s
[Step= 550] | Loss=8.84048 | acc=0.1121 | tpr=0.6864 | fpr=0.8984 | 13768.7 samples/s | 53.8 steps/s
Avg test loss: 8.84237, Avg test acc: 0.11204, Avg tpr: 0.68661, Avg fpr: 0.89840, total FA: 124741

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15816 | acc=0.9800 | tpr=0.9159 | fpr=0.0188 | 4842.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.16203 | acc=0.9800 | tpr=0.9275 | fpr=0.0190 | 7784.2 samples/s | 30.4 steps/s
[Step= 150] | Loss=0.16894 | acc=0.9794 | tpr=0.9294 | fpr=0.0197 | 7621.2 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.17350 | acc=0.9792 | tpr=0.9322 | fpr=0.0199 | 7465.6 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.17101 | acc=0.9795 | tpr=0.9301 | fpr=0.0196 | 7815.0 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.17399 | acc=0.9792 | tpr=0.9287 | fpr=0.0199 | 7882.7 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.17496 | acc=0.9789 | tpr=0.9317 | fpr=0.0203 | 7816.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.17669 | acc=0.9787 | tpr=0.9294 | fpr=0.0204 | 7774.9 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.17975 | acc=0.9784 | tpr=0.9275 | fpr=0.0207 | 7629.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.17819 | acc=0.9786 | tpr=0.9295 | fpr=0.0205 | 7856.6 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.17694 | acc=0.9788 | tpr=0.9296 | fpr=0.0203 | 14185.6 samples/s | 55.4 steps/s
Avg test loss: 0.17651, Avg test acc: 0.97882, Avg tpr: 0.92987, Avg fpr: 0.02029, total FA: 2817

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14637 | acc=0.9772 | tpr=0.9381 | fpr=0.0221 | 4938.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.15008 | acc=0.9774 | tpr=0.9510 | fpr=0.0221 | 7051.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.15645 | acc=0.9771 | tpr=0.9553 | fpr=0.0225 | 7871.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.15986 | acc=0.9770 | tpr=0.9552 | fpr=0.0226 | 7923.2 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.15717 | acc=0.9774 | tpr=0.9546 | fpr=0.0222 | 7807.1 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.16006 | acc=0.9770 | tpr=0.9498 | fpr=0.0225 | 7630.6 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.15949 | acc=0.9772 | tpr=0.9512 | fpr=0.0224 | 7938.3 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.16073 | acc=0.9770 | tpr=0.9480 | fpr=0.0225 | 7869.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.16362 | acc=0.9766 | tpr=0.9484 | fpr=0.0229 | 7573.9 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.16260 | acc=0.9767 | tpr=0.9489 | fpr=0.0228 | 8318.5 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.16142 | acc=0.9770 | tpr=0.9495 | fpr=0.0225 | 13352.2 samples/s | 52.2 steps/s
Avg test loss: 0.16120, Avg test acc: 0.97700, Avg tpr: 0.94929, Avg fpr: 0.02250, total FA: 3124

server round 11/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=42.9] | Loss=0.00600 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.526 | L2-Norm(final)=5.847 | 6140.7 samples/s | 95.9 steps/s
[Step=22050 Epoch=43.0] | Loss=0.01516 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.522 | L2-Norm(final)=5.854 | 4695.5 samples/s | 73.4 steps/s
[Step=22100 Epoch=43.1] | Loss=0.01443 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.520 | L2-Norm(final)=5.866 | 4899.1 samples/s | 76.5 steps/s
[Step=22150 Epoch=43.2] | Loss=0.01382 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.519 | L2-Norm(final)=5.878 | 5020.6 samples/s | 78.4 steps/s
[Step=22200 Epoch=43.3] | Loss=0.01311 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.517 | L2-Norm(final)=5.889 | 4993.9 samples/s | 78.0 steps/s
[Step=22250 Epoch=43.4] | Loss=0.01313 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.515 | L2-Norm(final)=5.900 | 5050.5 samples/s | 78.9 steps/s
[Step=22300 Epoch=43.5] | Loss=0.01299 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.513 | L2-Norm(final)=5.910 | 4945.2 samples/s | 77.3 steps/s
[Step=22350 Epoch=43.6] | Loss=0.01315 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.511 | L2-Norm(final)=5.920 | 4917.0 samples/s | 76.8 steps/s
[Step=22400 Epoch=43.7] | Loss=0.01285 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.509 | L2-Norm(final)=5.931 | 5064.5 samples/s | 79.1 steps/s
[Step=22450 Epoch=43.8] | Loss=0.01263 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.507 | L2-Norm(final)=5.942 | 5158.9 samples/s | 80.6 steps/s
[Step=22500 Epoch=43.9] | Loss=0.01273 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.505 | L2-Norm(final)=5.952 | 6527.6 samples/s | 102.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=43.9] | Loss=0.00816 | Reg=0.00505 | acc=0.9844 | L2-Norm=22.483 | L2-Norm(final)=6.056 | 6192.3 samples/s | 96.8 steps/s
[Step=22550 Epoch=44.0] | Loss=0.01349 | Reg=0.00506 | acc=0.9531 | L2-Norm=22.485 | L2-Norm(final)=6.064 | 4078.5 samples/s | 63.7 steps/s
[Step=22600 Epoch=44.1] | Loss=0.01570 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.489 | L2-Norm(final)=6.061 | 4413.0 samples/s | 69.0 steps/s
[Step=22650 Epoch=44.2] | Loss=0.01563 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.493 | L2-Norm(final)=6.061 | 4435.9 samples/s | 69.3 steps/s
[Step=22700 Epoch=44.3] | Loss=0.01657 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.494 | L2-Norm(final)=6.060 | 4507.8 samples/s | 70.4 steps/s
[Step=22750 Epoch=44.4] | Loss=0.01617 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.494 | L2-Norm(final)=6.061 | 4321.5 samples/s | 67.5 steps/s
[Step=22800 Epoch=44.5] | Loss=0.01590 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.495 | L2-Norm(final)=6.062 | 4518.0 samples/s | 70.6 steps/s
[Step=22850 Epoch=44.6] | Loss=0.01665 | Reg=0.00506 | acc=0.9688 | L2-Norm=22.496 | L2-Norm(final)=6.063 | 4417.0 samples/s | 69.0 steps/s
[Step=22900 Epoch=44.7] | Loss=0.01677 | Reg=0.00506 | acc=0.9531 | L2-Norm=22.497 | L2-Norm(final)=6.062 | 4431.8 samples/s | 69.2 steps/s
[Step=22950 Epoch=44.8] | Loss=0.01669 | Reg=0.00506 | acc=0.9688 | L2-Norm=22.499 | L2-Norm(final)=6.063 | 4448.6 samples/s | 69.5 steps/s
[Step=23000 Epoch=44.9] | Loss=0.01669 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.501 | L2-Norm(final)=6.063 | 5741.2 samples/s | 89.7 steps/s
[Step=23050 Epoch=45.0] | Loss=0.01650 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.502 | L2-Norm(final)=6.064 | 2390.1 samples/s | 37.3 steps/s
[Step=23100 Epoch=45.1] | Loss=0.01603 | Reg=0.00506 | acc=0.9531 | L2-Norm=22.502 | L2-Norm(final)=6.066 | 4385.2 samples/s | 68.5 steps/s
[Step=23150 Epoch=45.2] | Loss=0.01602 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.503 | L2-Norm(final)=6.067 | 4353.9 samples/s | 68.0 steps/s
[Step=23200 Epoch=45.2] | Loss=0.01569 | Reg=0.00506 | acc=0.9688 | L2-Norm=22.502 | L2-Norm(final)=6.068 | 4322.8 samples/s | 67.5 steps/s
[Step=23250 Epoch=45.3] | Loss=0.01553 | Reg=0.00506 | acc=0.9531 | L2-Norm=22.501 | L2-Norm(final)=6.070 | 4265.2 samples/s | 66.6 steps/s
[Step=23300 Epoch=45.4] | Loss=0.01539 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.501 | L2-Norm(final)=6.071 | 4263.8 samples/s | 66.6 steps/s
[Step=23350 Epoch=45.5] | Loss=0.01527 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.499 | L2-Norm(final)=6.072 | 4497.4 samples/s | 70.3 steps/s
[Step=23400 Epoch=45.6] | Loss=0.01513 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.498 | L2-Norm(final)=6.074 | 4375.7 samples/s | 68.4 steps/s
[Step=23450 Epoch=45.7] | Loss=0.01521 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.496 | L2-Norm(final)=6.075 | 4438.7 samples/s | 69.4 steps/s
[Step=23500 Epoch=45.8] | Loss=0.01510 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.495 | L2-Norm(final)=6.075 | 4759.1 samples/s | 74.4 steps/s
[Step=23550 Epoch=45.9] | Loss=0.01496 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.492 | L2-Norm(final)=6.076 | 2477.6 samples/s | 38.7 steps/s
[Step=23600 Epoch=46.0] | Loss=0.01476 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.490 | L2-Norm(final)=6.077 | 4299.9 samples/s | 67.2 steps/s
[Step=23650 Epoch=46.1] | Loss=0.01446 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.487 | L2-Norm(final)=6.078 | 4338.2 samples/s | 67.8 steps/s
[Step=23700 Epoch=46.2] | Loss=0.01437 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.483 | L2-Norm(final)=6.079 | 4334.9 samples/s | 67.7 steps/s
[Step=23750 Epoch=46.3] | Loss=0.01423 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.479 | L2-Norm(final)=6.080 | 4322.4 samples/s | 67.5 steps/s
[Step=23800 Epoch=46.4] | Loss=0.01405 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.475 | L2-Norm(final)=6.080 | 4421.2 samples/s | 69.1 steps/s
[Step=23850 Epoch=46.5] | Loss=0.01388 | Reg=0.00505 | acc=0.9844 | L2-Norm=22.471 | L2-Norm(final)=6.081 | 4341.1 samples/s | 67.8 steps/s
[Step=23900 Epoch=46.6] | Loss=0.01375 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.467 | L2-Norm(final)=6.082 | 4276.0 samples/s | 66.8 steps/s
[Step=23950 Epoch=46.7] | Loss=0.01367 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.462 | L2-Norm(final)=6.083 | 4372.3 samples/s | 68.3 steps/s
[Step=24000 Epoch=46.8] | Loss=0.01360 | Reg=0.00504 | acc=0.9688 | L2-Norm=22.457 | L2-Norm(final)=6.085 | 4299.3 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step24000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=43.0] | Loss=0.02311 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.374 | L2-Norm(final)=5.794 | 5909.3 samples/s | 92.3 steps/s
[Step=22050 Epoch=43.1] | Loss=0.01589 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.373 | L2-Norm(final)=5.800 | 4408.6 samples/s | 68.9 steps/s
[Step=22100 Epoch=43.2] | Loss=0.01334 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.377 | L2-Norm(final)=5.810 | 4879.0 samples/s | 76.2 steps/s
[Step=22150 Epoch=43.3] | Loss=0.01325 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.377 | L2-Norm(final)=5.823 | 4916.0 samples/s | 76.8 steps/s
[Step=22200 Epoch=43.4] | Loss=0.01305 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.375 | L2-Norm(final)=5.835 | 4937.6 samples/s | 77.1 steps/s
[Step=22250 Epoch=43.5] | Loss=0.01303 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.374 | L2-Norm(final)=5.846 | 4882.8 samples/s | 76.3 steps/s
[Step=22300 Epoch=43.6] | Loss=0.01316 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.373 | L2-Norm(final)=5.856 | 4812.5 samples/s | 75.2 steps/s
[Step=22350 Epoch=43.7] | Loss=0.01328 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.373 | L2-Norm(final)=5.866 | 4874.8 samples/s | 76.2 steps/s
[Step=22400 Epoch=43.8] | Loss=0.01308 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.373 | L2-Norm(final)=5.876 | 4883.3 samples/s | 76.3 steps/s
[Step=22450 Epoch=43.9] | Loss=0.01327 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.373 | L2-Norm(final)=5.884 | 4938.9 samples/s | 77.2 steps/s
[Step=22500 Epoch=44.0] | Loss=0.01339 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.373 | L2-Norm(final)=5.892 | 6785.7 samples/s | 106.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=44.0] | Loss=0.02676 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.367 | L2-Norm(final)=5.973 | 6384.7 samples/s | 99.8 steps/s
[Step=22550 Epoch=44.1] | Loss=0.01353 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.370 | L2-Norm(final)=5.982 | 3923.5 samples/s | 61.3 steps/s
[Step=22600 Epoch=44.2] | Loss=0.01401 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.375 | L2-Norm(final)=5.988 | 4334.0 samples/s | 67.7 steps/s
[Step=22650 Epoch=44.3] | Loss=0.01595 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.379 | L2-Norm(final)=5.992 | 4429.7 samples/s | 69.2 steps/s
[Step=22700 Epoch=44.4] | Loss=0.01779 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.382 | L2-Norm(final)=5.992 | 4233.9 samples/s | 66.2 steps/s
[Step=22750 Epoch=44.5] | Loss=0.01744 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.387 | L2-Norm(final)=5.992 | 4308.9 samples/s | 67.3 steps/s
[Step=22800 Epoch=44.6] | Loss=0.01807 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.390 | L2-Norm(final)=5.992 | 4395.0 samples/s | 68.7 steps/s
[Step=22850 Epoch=44.7] | Loss=0.01808 | Reg=0.00501 | acc=0.9531 | L2-Norm=22.393 | L2-Norm(final)=5.992 | 4383.0 samples/s | 68.5 steps/s
[Step=22900 Epoch=44.8] | Loss=0.01806 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.395 | L2-Norm(final)=5.993 | 4357.1 samples/s | 68.1 steps/s
[Step=22950 Epoch=44.9] | Loss=0.01784 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.397 | L2-Norm(final)=5.994 | 4331.4 samples/s | 67.7 steps/s
[Step=23000 Epoch=45.0] | Loss=0.01775 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.400 | L2-Norm(final)=5.994 | 5726.7 samples/s | 89.5 steps/s
[Step=23050 Epoch=45.1] | Loss=0.01743 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.401 | L2-Norm(final)=5.995 | 2334.8 samples/s | 36.5 steps/s
[Step=23100 Epoch=45.2] | Loss=0.01741 | Reg=0.00502 | acc=0.9531 | L2-Norm=22.403 | L2-Norm(final)=5.996 | 4298.7 samples/s | 67.2 steps/s
[Step=23150 Epoch=45.3] | Loss=0.01689 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.403 | L2-Norm(final)=5.997 | 4384.5 samples/s | 68.5 steps/s
[Step=23200 Epoch=45.4] | Loss=0.01655 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.403 | L2-Norm(final)=5.998 | 4310.7 samples/s | 67.4 steps/s
[Step=23250 Epoch=45.5] | Loss=0.01623 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.402 | L2-Norm(final)=5.999 | 4366.2 samples/s | 68.2 steps/s
[Step=23300 Epoch=45.6] | Loss=0.01600 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.401 | L2-Norm(final)=6.000 | 4311.1 samples/s | 67.4 steps/s
[Step=23350 Epoch=45.6] | Loss=0.01599 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.399 | L2-Norm(final)=6.001 | 4340.5 samples/s | 67.8 steps/s
[Step=23400 Epoch=45.7] | Loss=0.01599 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.398 | L2-Norm(final)=6.002 | 4370.0 samples/s | 68.3 steps/s
[Step=23450 Epoch=45.8] | Loss=0.01575 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.397 | L2-Norm(final)=6.002 | 4312.7 samples/s | 67.4 steps/s
[Step=23500 Epoch=45.9] | Loss=0.01573 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.395 | L2-Norm(final)=6.003 | 4672.6 samples/s | 73.0 steps/s
[Step=23550 Epoch=46.0] | Loss=0.01547 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.393 | L2-Norm(final)=6.004 | 2475.3 samples/s | 38.7 steps/s
[Step=23600 Epoch=46.1] | Loss=0.01516 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.391 | L2-Norm(final)=6.005 | 4385.5 samples/s | 68.5 steps/s
[Step=23650 Epoch=46.2] | Loss=0.01487 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.388 | L2-Norm(final)=6.007 | 4254.7 samples/s | 66.5 steps/s
[Step=23700 Epoch=46.3] | Loss=0.01468 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.385 | L2-Norm(final)=6.008 | 4387.7 samples/s | 68.6 steps/s
[Step=23750 Epoch=46.4] | Loss=0.01451 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.382 | L2-Norm(final)=6.009 | 4481.9 samples/s | 70.0 steps/s
[Step=23800 Epoch=46.5] | Loss=0.01425 | Reg=0.00501 | acc=0.9688 | L2-Norm=22.379 | L2-Norm(final)=6.010 | 4423.0 samples/s | 69.1 steps/s
[Step=23850 Epoch=46.6] | Loss=0.01416 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.375 | L2-Norm(final)=6.011 | 4424.3 samples/s | 69.1 steps/s
[Step=23900 Epoch=46.7] | Loss=0.01410 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.371 | L2-Norm(final)=6.012 | 4315.9 samples/s | 67.4 steps/s
[Step=23950 Epoch=46.8] | Loss=0.01403 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.367 | L2-Norm(final)=6.013 | 4253.6 samples/s | 66.5 steps/s
[Step=24000 Epoch=46.9] | Loss=0.01405 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.363 | L2-Norm(final)=6.014 | 4306.5 samples/s | 67.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step24000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=84.3] | Loss=0.00015 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.097 | L2-Norm(final)=4.497 | 5491.0 samples/s | 85.8 steps/s
[Step=22050 Epoch=84.5] | Loss=0.00010 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.093 | L2-Norm(final)=4.499 | 4213.6 samples/s | 65.8 steps/s
[Step=22100 Epoch=84.7] | Loss=0.00007 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.092 | L2-Norm(final)=4.501 | 4539.8 samples/s | 70.9 steps/s
[Step=22150 Epoch=84.9] | Loss=0.00012 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.090 | L2-Norm(final)=4.504 | 4572.9 samples/s | 71.5 steps/s
[Step=22200 Epoch=85.1] | Loss=0.00010 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.089 | L2-Norm(final)=4.509 | 4548.5 samples/s | 71.1 steps/s
[Step=22250 Epoch=85.3] | Loss=0.00009 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.088 | L2-Norm(final)=4.512 | 6239.7 samples/s | 97.5 steps/s
[Step=22300 Epoch=85.4] | Loss=0.00008 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.086 | L2-Norm(final)=4.515 | 2310.8 samples/s | 36.1 steps/s
[Step=22350 Epoch=85.6] | Loss=0.00007 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.083 | L2-Norm(final)=4.518 | 4558.4 samples/s | 71.2 steps/s
[Step=22400 Epoch=85.8] | Loss=0.00007 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.080 | L2-Norm(final)=4.520 | 4650.3 samples/s | 72.7 steps/s
[Step=22450 Epoch=86.0] | Loss=0.00006 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.077 | L2-Norm(final)=4.522 | 4859.6 samples/s | 75.9 steps/s
[Step=22500 Epoch=86.2] | Loss=0.00006 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.074 | L2-Norm(final)=4.524 | 5204.4 samples/s | 81.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=86.2] | Loss=0.00003 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.043 | L2-Norm(final)=4.547 | 6219.9 samples/s | 97.2 steps/s
[Step=22550 Epoch=86.4] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.034 | L2-Norm(final)=4.549 | 3708.2 samples/s | 57.9 steps/s
[Step=22600 Epoch=86.6] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.021 | L2-Norm(final)=4.550 | 4133.3 samples/s | 64.6 steps/s
[Step=22650 Epoch=86.8] | Loss=0.00002 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.008 | L2-Norm(final)=4.551 | 4286.0 samples/s | 67.0 steps/s
[Step=22700 Epoch=87.0] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.995 | L2-Norm(final)=4.552 | 4174.7 samples/s | 65.2 steps/s
[Step=22750 Epoch=87.2] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.981 | L2-Norm(final)=4.554 | 5600.2 samples/s | 87.5 steps/s
[Step=22800 Epoch=87.4] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.968 | L2-Norm(final)=4.555 | 2262.2 samples/s | 35.3 steps/s
[Step=22850 Epoch=87.6] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=4.556 | 4165.0 samples/s | 65.1 steps/s
[Step=22900 Epoch=87.7] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.940 | L2-Norm(final)=4.556 | 4280.5 samples/s | 66.9 steps/s
[Step=22950 Epoch=87.9] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=4.557 | 4113.7 samples/s | 64.3 steps/s
[Step=23000 Epoch=88.1] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.912 | L2-Norm(final)=4.558 | 4726.4 samples/s | 73.8 steps/s
[Step=23050 Epoch=88.3] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.898 | L2-Norm(final)=4.558 | 2437.0 samples/s | 38.1 steps/s
[Step=23100 Epoch=88.5] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.884 | L2-Norm(final)=4.559 | 4171.4 samples/s | 65.2 steps/s
[Step=23150 Epoch=88.7] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.869 | L2-Norm(final)=4.560 | 4281.8 samples/s | 66.9 steps/s
[Step=23200 Epoch=88.9] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.854 | L2-Norm(final)=4.560 | 4236.2 samples/s | 66.2 steps/s
[Step=23250 Epoch=89.1] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.840 | L2-Norm(final)=4.561 | 4046.4 samples/s | 63.2 steps/s
[Step=23300 Epoch=89.3] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.825 | L2-Norm(final)=4.561 | 2617.5 samples/s | 40.9 steps/s
[Step=23350 Epoch=89.5] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.810 | L2-Norm(final)=4.562 | 4258.4 samples/s | 66.5 steps/s
[Step=23400 Epoch=89.7] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.795 | L2-Norm(final)=4.563 | 4314.0 samples/s | 67.4 steps/s
[Step=23450 Epoch=89.9] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.779 | L2-Norm(final)=4.563 | 4108.1 samples/s | 64.2 steps/s
[Step=23500 Epoch=90.0] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.764 | L2-Norm(final)=4.564 | 4166.1 samples/s | 65.1 steps/s
[Step=23550 Epoch=90.2] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.748 | L2-Norm(final)=4.564 | 2620.1 samples/s | 40.9 steps/s
[Step=23600 Epoch=90.4] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.733 | L2-Norm(final)=4.565 | 4172.6 samples/s | 65.2 steps/s
[Step=23650 Epoch=90.6] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=4.565 | 4138.4 samples/s | 64.7 steps/s
[Step=23700 Epoch=90.8] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.701 | L2-Norm(final)=4.566 | 4241.7 samples/s | 66.3 steps/s
[Step=23750 Epoch=91.0] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.685 | L2-Norm(final)=4.566 | 4242.5 samples/s | 66.3 steps/s
[Step=23800 Epoch=91.2] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.669 | L2-Norm(final)=4.567 | 6133.3 samples/s | 95.8 steps/s
[Step=23850 Epoch=91.4] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.652 | L2-Norm(final)=4.567 | 2171.9 samples/s | 33.9 steps/s
[Step=23900 Epoch=91.6] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.636 | L2-Norm(final)=4.568 | 4270.5 samples/s | 66.7 steps/s
[Step=23950 Epoch=91.8] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=4.568 | 4099.3 samples/s | 64.1 steps/s
[Step=24000 Epoch=92.0] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.602 | L2-Norm(final)=4.569 | 4257.7 samples/s | 66.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step24000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=84.7] | Loss=0.00000 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.202 | L2-Norm(final)=5.076 | 6085.3 samples/s | 95.1 steps/s
[Step=22050 Epoch=84.9] | Loss=0.00033 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.196 | L2-Norm(final)=5.082 | 4102.5 samples/s | 64.1 steps/s
[Step=22100 Epoch=85.1] | Loss=0.00032 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.197 | L2-Norm(final)=5.089 | 4724.3 samples/s | 73.8 steps/s
[Step=22150 Epoch=85.3] | Loss=0.00024 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.198 | L2-Norm(final)=5.093 | 4848.6 samples/s | 75.8 steps/s
[Step=22200 Epoch=85.5] | Loss=0.00021 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.197 | L2-Norm(final)=5.097 | 4685.8 samples/s | 73.2 steps/s
[Step=22250 Epoch=85.6] | Loss=0.00018 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.195 | L2-Norm(final)=5.102 | 6423.0 samples/s | 100.4 steps/s
[Step=22300 Epoch=85.8] | Loss=0.00017 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.193 | L2-Norm(final)=5.106 | 2426.2 samples/s | 37.9 steps/s
[Step=22350 Epoch=86.0] | Loss=0.00015 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.191 | L2-Norm(final)=5.110 | 4523.5 samples/s | 70.7 steps/s
[Step=22400 Epoch=86.2] | Loss=0.00014 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.188 | L2-Norm(final)=5.114 | 4753.1 samples/s | 74.3 steps/s
[Step=22450 Epoch=86.4] | Loss=0.00012 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.185 | L2-Norm(final)=5.117 | 4623.3 samples/s | 72.2 steps/s
[Step=22500 Epoch=86.6] | Loss=0.00011 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.182 | L2-Norm(final)=5.120 | 5618.0 samples/s | 87.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=86.6] | Loss=0.00004 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.143 | L2-Norm(final)=5.149 | 5864.4 samples/s | 91.6 steps/s
[Step=22550 Epoch=86.8] | Loss=0.00002 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.126 | L2-Norm(final)=5.151 | 3869.4 samples/s | 60.5 steps/s
[Step=22600 Epoch=87.0] | Loss=0.00002 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.103 | L2-Norm(final)=5.153 | 4239.5 samples/s | 66.2 steps/s
[Step=22650 Epoch=87.2] | Loss=0.00001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.079 | L2-Norm(final)=5.154 | 4152.1 samples/s | 64.9 steps/s
[Step=22700 Epoch=87.4] | Loss=0.00001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=5.155 | 4295.9 samples/s | 67.1 steps/s
[Step=22750 Epoch=87.6] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.033 | L2-Norm(final)=5.156 | 5641.5 samples/s | 88.1 steps/s
[Step=22800 Epoch=87.8] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.009 | L2-Norm(final)=5.157 | 2233.7 samples/s | 34.9 steps/s
[Step=22850 Epoch=88.0] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.985 | L2-Norm(final)=5.158 | 4314.1 samples/s | 67.4 steps/s
[Step=22900 Epoch=88.2] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.961 | L2-Norm(final)=5.159 | 4110.8 samples/s | 64.2 steps/s
[Step=22950 Epoch=88.3] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=5.160 | 4184.4 samples/s | 65.4 steps/s
[Step=23000 Epoch=88.5] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.913 | L2-Norm(final)=5.161 | 4933.3 samples/s | 77.1 steps/s
[Step=23050 Epoch=88.7] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.889 | L2-Norm(final)=5.161 | 2402.1 samples/s | 37.5 steps/s
[Step=23100 Epoch=88.9] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=5.162 | 4129.6 samples/s | 64.5 steps/s
[Step=23150 Epoch=89.1] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.840 | L2-Norm(final)=5.162 | 4224.3 samples/s | 66.0 steps/s
[Step=23200 Epoch=89.3] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.815 | L2-Norm(final)=5.163 | 4145.7 samples/s | 64.8 steps/s
[Step=23250 Epoch=89.5] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.791 | L2-Norm(final)=5.164 | 4344.4 samples/s | 67.9 steps/s
[Step=23300 Epoch=89.7] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.766 | L2-Norm(final)=5.164 | 2569.6 samples/s | 40.1 steps/s
[Step=23350 Epoch=89.9] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.741 | L2-Norm(final)=5.165 | 4271.7 samples/s | 66.7 steps/s
[Step=23400 Epoch=90.1] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.716 | L2-Norm(final)=5.165 | 4178.1 samples/s | 65.3 steps/s
[Step=23450 Epoch=90.3] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.690 | L2-Norm(final)=5.166 | 4167.0 samples/s | 65.1 steps/s
[Step=23500 Epoch=90.5] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.665 | L2-Norm(final)=5.166 | 4133.7 samples/s | 64.6 steps/s
[Step=23550 Epoch=90.7] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.640 | L2-Norm(final)=5.167 | 2642.3 samples/s | 41.3 steps/s
[Step=23600 Epoch=90.8] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.614 | L2-Norm(final)=5.167 | 4139.7 samples/s | 64.7 steps/s
[Step=23650 Epoch=91.0] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=5.168 | 4257.5 samples/s | 66.5 steps/s
[Step=23700 Epoch=91.2] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.563 | L2-Norm(final)=5.168 | 4205.1 samples/s | 65.7 steps/s
[Step=23750 Epoch=91.4] | Loss=0.00000 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.537 | L2-Norm(final)=5.169 | 4136.8 samples/s | 64.6 steps/s
[Step=23800 Epoch=91.6] | Loss=0.00000 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.511 | L2-Norm(final)=5.169 | 6980.3 samples/s | 109.1 steps/s
[Step=23850 Epoch=91.8] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.484 | L2-Norm(final)=5.170 | 2096.5 samples/s | 32.8 steps/s
[Step=23900 Epoch=92.0] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.458 | L2-Norm(final)=5.170 | 4190.9 samples/s | 65.5 steps/s
[Step=23950 Epoch=92.2] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.432 | L2-Norm(final)=5.171 | 4235.1 samples/s | 66.2 steps/s
[Step=24000 Epoch=92.4] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.405 | L2-Norm(final)=5.171 | 4276.4 samples/s | 66.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07674 | acc=0.9665 | tpr=0.9702 | fpr=0.0416 | 4989.5 samples/s | 19.5 steps/s
Avg test loss: 0.07363, Avg test acc: 0.96654, Avg tpr: 0.97016, Avg fpr: 0.04140, total FA: 323

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06827 | acc=0.9662 | tpr=0.9726 | fpr=0.0478 | 4888.7 samples/s | 19.1 steps/s
Avg test loss: 0.07023, Avg test acc: 0.96506, Avg tpr: 0.97208, Avg fpr: 0.05038, total FA: 393

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.30297 | acc=0.3019 | tpr=0.0188 | fpr=0.0835 | 4962.2 samples/s | 19.4 steps/s
Avg test loss: 6.30185, Avg test acc: 0.29766, Avg tpr: 0.01993, Avg fpr: 0.09153, total FA: 714

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.78052 | acc=0.3130 | tpr=0.0257 | fpr=0.0632 | 4688.6 samples/s | 18.3 steps/s
Avg test loss: 6.76583, Avg test acc: 0.31064, Avg tpr: 0.02786, Avg fpr: 0.06743, total FA: 526

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.51527 | acc=0.1510 | tpr=0.4735 | fpr=0.8548 | 4816.3 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.47717 | acc=0.1518 | tpr=0.4392 | fpr=0.8535 | 6861.3 samples/s | 26.8 steps/s
[Step= 150] | Loss=6.47677 | acc=0.1520 | tpr=0.4424 | fpr=0.8534 | 8548.5 samples/s | 33.4 steps/s
[Step= 200] | Loss=6.47175 | acc=0.1536 | tpr=0.4459 | fpr=0.8517 | 7615.4 samples/s | 29.7 steps/s
[Step= 250] | Loss=6.46932 | acc=0.1545 | tpr=0.4533 | fpr=0.8509 | 8058.8 samples/s | 31.5 steps/s
[Step= 300] | Loss=6.46316 | acc=0.1545 | tpr=0.4516 | fpr=0.8509 | 7543.5 samples/s | 29.5 steps/s
[Step= 350] | Loss=6.46675 | acc=0.1540 | tpr=0.4458 | fpr=0.8513 | 7768.3 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.46940 | acc=0.1540 | tpr=0.4447 | fpr=0.8512 | 7841.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=6.47262 | acc=0.1540 | tpr=0.4513 | fpr=0.8514 | 7677.2 samples/s | 30.0 steps/s
[Step= 500] | Loss=6.47090 | acc=0.1541 | tpr=0.4568 | fpr=0.8513 | 7826.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=6.47489 | acc=0.1541 | tpr=0.4584 | fpr=0.8515 | 14335.5 samples/s | 56.0 steps/s
Avg test loss: 6.47716, Avg test acc: 0.15396, Avg tpr: 0.45919, Avg fpr: 0.85159, total FA: 118241

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.18686 | acc=0.1304 | tpr=0.6106 | fpr=0.8782 | 4984.4 samples/s | 19.5 steps/s
[Step= 100] | Loss=7.15856 | acc=0.1309 | tpr=0.5778 | fpr=0.8774 | 6884.2 samples/s | 26.9 steps/s
[Step= 150] | Loss=7.15573 | acc=0.1310 | tpr=0.5648 | fpr=0.8770 | 7919.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=7.15240 | acc=0.1321 | tpr=0.5628 | fpr=0.8758 | 7913.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=7.14005 | acc=0.1322 | tpr=0.5616 | fpr=0.8756 | 7704.3 samples/s | 30.1 steps/s
[Step= 300] | Loss=7.13808 | acc=0.1322 | tpr=0.5535 | fpr=0.8755 | 7845.9 samples/s | 30.6 steps/s
[Step= 350] | Loss=7.14348 | acc=0.1317 | tpr=0.5429 | fpr=0.8758 | 7749.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=7.14385 | acc=0.1314 | tpr=0.5399 | fpr=0.8760 | 7983.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=7.15123 | acc=0.1312 | tpr=0.5433 | fpr=0.8763 | 7850.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=7.15240 | acc=0.1311 | tpr=0.5449 | fpr=0.8764 | 7711.1 samples/s | 30.1 steps/s
[Step= 550] | Loss=7.15945 | acc=0.1311 | tpr=0.5452 | fpr=0.8764 | 13549.0 samples/s | 52.9 steps/s
Avg test loss: 7.16184, Avg test acc: 0.13104, Avg tpr: 0.54556, Avg fpr: 0.87650, total FA: 121700

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13340 | acc=0.9805 | tpr=0.9469 | fpr=0.0189 | 4918.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13840 | acc=0.9802 | tpr=0.9510 | fpr=0.0193 | 7130.2 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.14449 | acc=0.9793 | tpr=0.9452 | fpr=0.0200 | 7361.2 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.14744 | acc=0.9793 | tpr=0.9475 | fpr=0.0201 | 8344.1 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.14532 | acc=0.9796 | tpr=0.9424 | fpr=0.0198 | 7746.2 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.14716 | acc=0.9793 | tpr=0.9425 | fpr=0.0200 | 7441.0 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.14759 | acc=0.9791 | tpr=0.9449 | fpr=0.0202 | 7964.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14918 | acc=0.9790 | tpr=0.9404 | fpr=0.0203 | 8042.6 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.15157 | acc=0.9787 | tpr=0.9387 | fpr=0.0206 | 7606.0 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.15025 | acc=0.9788 | tpr=0.9396 | fpr=0.0204 | 7968.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.14890 | acc=0.9791 | tpr=0.9403 | fpr=0.0201 | 13732.2 samples/s | 53.6 steps/s
Avg test loss: 0.14862, Avg test acc: 0.97915, Avg tpr: 0.94017, Avg fpr: 0.02014, total FA: 2797

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15872 | acc=0.9773 | tpr=0.9469 | fpr=0.0222 | 4892.4 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.16326 | acc=0.9770 | tpr=0.9531 | fpr=0.0226 | 7371.7 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.17030 | acc=0.9765 | tpr=0.9597 | fpr=0.0232 | 7536.6 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.17309 | acc=0.9767 | tpr=0.9596 | fpr=0.0230 | 7994.8 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.17041 | acc=0.9770 | tpr=0.9572 | fpr=0.0226 | 7879.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.17327 | acc=0.9767 | tpr=0.9542 | fpr=0.0228 | 7552.0 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.17327 | acc=0.9767 | tpr=0.9549 | fpr=0.0229 | 7867.8 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.17469 | acc=0.9766 | tpr=0.9535 | fpr=0.0229 | 7819.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.17774 | acc=0.9763 | tpr=0.9523 | fpr=0.0233 | 8332.6 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.17652 | acc=0.9764 | tpr=0.9524 | fpr=0.0231 | 7219.9 samples/s | 28.2 steps/s
[Step= 550] | Loss=0.17506 | acc=0.9768 | tpr=0.9534 | fpr=0.0228 | 14547.5 samples/s | 56.8 steps/s
Avg test loss: 0.17481, Avg test acc: 0.97678, Avg tpr: 0.95365, Avg fpr: 0.02280, total FA: 3166

server round 12/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=46.8] | Loss=0.01104 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.897 | L2-Norm(final)=6.122 | 6255.8 samples/s | 97.7 steps/s
[Step=24050 Epoch=46.9] | Loss=0.00946 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.894 | L2-Norm(final)=6.129 | 4525.3 samples/s | 70.7 steps/s
[Step=24100 Epoch=47.0] | Loss=0.00812 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.889 | L2-Norm(final)=6.137 | 5100.8 samples/s | 79.7 steps/s
[Step=24150 Epoch=47.1] | Loss=0.00837 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.883 | L2-Norm(final)=6.145 | 4949.7 samples/s | 77.3 steps/s
[Step=24200 Epoch=47.2] | Loss=0.00868 | Reg=0.00479 | acc=0.9844 | L2-Norm=21.875 | L2-Norm(final)=6.152 | 4801.7 samples/s | 75.0 steps/s
[Step=24250 Epoch=47.3] | Loss=0.00883 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.869 | L2-Norm(final)=6.159 | 5001.9 samples/s | 78.2 steps/s
[Step=24300 Epoch=47.4] | Loss=0.00869 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.864 | L2-Norm(final)=6.166 | 4972.0 samples/s | 77.7 steps/s
[Step=24350 Epoch=47.5] | Loss=0.00864 | Reg=0.00478 | acc=0.9844 | L2-Norm=21.859 | L2-Norm(final)=6.173 | 4919.9 samples/s | 76.9 steps/s
[Step=24400 Epoch=47.6] | Loss=0.00911 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.854 | L2-Norm(final)=6.180 | 4978.6 samples/s | 77.8 steps/s
[Step=24450 Epoch=47.7] | Loss=0.00918 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.849 | L2-Norm(final)=6.185 | 5202.7 samples/s | 81.3 steps/s
[Step=24500 Epoch=47.8] | Loss=0.00919 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.845 | L2-Norm(final)=6.191 | 6512.4 samples/s | 101.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=47.8] | Loss=0.00327 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.799 | L2-Norm(final)=6.246 | 5710.6 samples/s | 89.2 steps/s
[Step=24550 Epoch=47.9] | Loss=0.00723 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.794 | L2-Norm(final)=6.253 | 4292.4 samples/s | 67.1 steps/s
[Step=24600 Epoch=48.0] | Loss=0.01081 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.791 | L2-Norm(final)=6.256 | 4485.1 samples/s | 70.1 steps/s
[Step=24650 Epoch=48.1] | Loss=0.01256 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.793 | L2-Norm(final)=6.255 | 4438.9 samples/s | 69.4 steps/s
[Step=24700 Epoch=48.2] | Loss=0.01345 | Reg=0.00475 | acc=0.9688 | L2-Norm=21.796 | L2-Norm(final)=6.255 | 4316.0 samples/s | 67.4 steps/s
[Step=24750 Epoch=48.3] | Loss=0.01393 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.801 | L2-Norm(final)=6.257 | 4406.7 samples/s | 68.9 steps/s
[Step=24800 Epoch=48.4] | Loss=0.01405 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.806 | L2-Norm(final)=6.260 | 4452.7 samples/s | 69.6 steps/s
[Step=24850 Epoch=48.5] | Loss=0.01500 | Reg=0.00476 | acc=0.9688 | L2-Norm=21.812 | L2-Norm(final)=6.262 | 4465.0 samples/s | 69.8 steps/s
[Step=24900 Epoch=48.6] | Loss=0.01527 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.817 | L2-Norm(final)=6.263 | 4419.3 samples/s | 69.1 steps/s
[Step=24950 Epoch=48.7] | Loss=0.01538 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.821 | L2-Norm(final)=6.265 | 4470.5 samples/s | 69.9 steps/s
[Step=25000 Epoch=48.8] | Loss=0.01580 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.825 | L2-Norm(final)=6.266 | 5641.0 samples/s | 88.1 steps/s
[Step=25050 Epoch=48.9] | Loss=0.01546 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.829 | L2-Norm(final)=6.267 | 2382.5 samples/s | 37.2 steps/s
[Step=25100 Epoch=49.0] | Loss=0.01536 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.832 | L2-Norm(final)=6.268 | 4326.4 samples/s | 67.6 steps/s
[Step=25150 Epoch=49.1] | Loss=0.01515 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.835 | L2-Norm(final)=6.269 | 4401.4 samples/s | 68.8 steps/s
[Step=25200 Epoch=49.1] | Loss=0.01492 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.837 | L2-Norm(final)=6.271 | 4435.0 samples/s | 69.3 steps/s
[Step=25250 Epoch=49.2] | Loss=0.01477 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.838 | L2-Norm(final)=6.272 | 4482.5 samples/s | 70.0 steps/s
[Step=25300 Epoch=49.3] | Loss=0.01465 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.839 | L2-Norm(final)=6.274 | 4434.5 samples/s | 69.3 steps/s
[Step=25350 Epoch=49.4] | Loss=0.01463 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.839 | L2-Norm(final)=6.275 | 4432.5 samples/s | 69.3 steps/s
[Step=25400 Epoch=49.5] | Loss=0.01443 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.839 | L2-Norm(final)=6.277 | 4436.1 samples/s | 69.3 steps/s
[Step=25450 Epoch=49.6] | Loss=0.01421 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.839 | L2-Norm(final)=6.279 | 4441.3 samples/s | 69.4 steps/s
[Step=25500 Epoch=49.7] | Loss=0.01413 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.838 | L2-Norm(final)=6.282 | 4705.9 samples/s | 73.5 steps/s
[Step=25550 Epoch=49.8] | Loss=0.01392 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.837 | L2-Norm(final)=6.284 | 2588.4 samples/s | 40.4 steps/s
[Step=25600 Epoch=49.9] | Loss=0.01369 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.835 | L2-Norm(final)=6.286 | 4363.3 samples/s | 68.2 steps/s
[Step=25650 Epoch=50.0] | Loss=0.01356 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.834 | L2-Norm(final)=6.288 | 4446.6 samples/s | 69.5 steps/s
[Step=25700 Epoch=50.1] | Loss=0.01343 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.831 | L2-Norm(final)=6.289 | 4505.3 samples/s | 70.4 steps/s
[Step=25750 Epoch=50.2] | Loss=0.01326 | Reg=0.00477 | acc=0.9688 | L2-Norm=21.829 | L2-Norm(final)=6.291 | 4312.5 samples/s | 67.4 steps/s
[Step=25800 Epoch=50.3] | Loss=0.01318 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.827 | L2-Norm(final)=6.293 | 4508.8 samples/s | 70.4 steps/s
[Step=25850 Epoch=50.4] | Loss=0.01312 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.824 | L2-Norm(final)=6.294 | 4423.1 samples/s | 69.1 steps/s
[Step=25900 Epoch=50.5] | Loss=0.01300 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.821 | L2-Norm(final)=6.296 | 4412.4 samples/s | 68.9 steps/s
[Step=25950 Epoch=50.6] | Loss=0.01291 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.817 | L2-Norm(final)=6.297 | 4393.2 samples/s | 68.6 steps/s
[Step=26000 Epoch=50.7] | Loss=0.01281 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.814 | L2-Norm(final)=6.299 | 4454.5 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step26000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=46.9] | Loss=0.01224 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.799 | L2-Norm(final)=6.033 | 5315.3 samples/s | 83.1 steps/s
[Step=24050 Epoch=47.0] | Loss=0.01013 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.792 | L2-Norm(final)=6.040 | 4752.3 samples/s | 74.3 steps/s
[Step=24100 Epoch=47.1] | Loss=0.00985 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.786 | L2-Norm(final)=6.049 | 5074.6 samples/s | 79.3 steps/s
[Step=24150 Epoch=47.2] | Loss=0.00927 | Reg=0.00474 | acc=0.9688 | L2-Norm=21.778 | L2-Norm(final)=6.059 | 4856.6 samples/s | 75.9 steps/s
[Step=24200 Epoch=47.3] | Loss=0.00874 | Reg=0.00474 | acc=0.9844 | L2-Norm=21.772 | L2-Norm(final)=6.069 | 4987.1 samples/s | 77.9 steps/s
[Step=24250 Epoch=47.4] | Loss=0.00897 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.766 | L2-Norm(final)=6.079 | 4939.9 samples/s | 77.2 steps/s
[Step=24300 Epoch=47.5] | Loss=0.00896 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.759 | L2-Norm(final)=6.087 | 4945.7 samples/s | 77.3 steps/s
[Step=24350 Epoch=47.6] | Loss=0.00908 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.753 | L2-Norm(final)=6.095 | 4982.4 samples/s | 77.9 steps/s
[Step=24400 Epoch=47.7] | Loss=0.00907 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.746 | L2-Norm(final)=6.102 | 5104.1 samples/s | 79.8 steps/s
[Step=24450 Epoch=47.8] | Loss=0.00895 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.739 | L2-Norm(final)=6.108 | 5033.3 samples/s | 78.6 steps/s
[Step=24500 Epoch=47.9] | Loss=0.00885 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.732 | L2-Norm(final)=6.114 | 6645.0 samples/s | 103.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=47.9] | Loss=0.00425 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.667 | L2-Norm(final)=6.180 | 6089.6 samples/s | 95.1 steps/s
[Step=24550 Epoch=48.0] | Loss=0.00918 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.663 | L2-Norm(final)=6.184 | 4217.5 samples/s | 65.9 steps/s
[Step=24600 Epoch=48.1] | Loss=0.01246 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.669 | L2-Norm(final)=6.183 | 4362.8 samples/s | 68.2 steps/s
[Step=24650 Epoch=48.2] | Loss=0.01309 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.672 | L2-Norm(final)=6.184 | 4367.7 samples/s | 68.2 steps/s
[Step=24700 Epoch=48.3] | Loss=0.01287 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.675 | L2-Norm(final)=6.187 | 4449.6 samples/s | 69.5 steps/s
[Step=24750 Epoch=48.4] | Loss=0.01296 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.677 | L2-Norm(final)=6.189 | 4442.1 samples/s | 69.4 steps/s
[Step=24800 Epoch=48.5] | Loss=0.01349 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.680 | L2-Norm(final)=6.192 | 4517.6 samples/s | 70.6 steps/s
[Step=24850 Epoch=48.6] | Loss=0.01383 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.684 | L2-Norm(final)=6.193 | 4367.0 samples/s | 68.2 steps/s
[Step=24900 Epoch=48.7] | Loss=0.01447 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.688 | L2-Norm(final)=6.194 | 4474.1 samples/s | 69.9 steps/s
[Step=24950 Epoch=48.8] | Loss=0.01470 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.691 | L2-Norm(final)=6.195 | 4398.9 samples/s | 68.7 steps/s
[Step=25000 Epoch=48.9] | Loss=0.01472 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.695 | L2-Norm(final)=6.196 | 5836.8 samples/s | 91.2 steps/s
[Step=25050 Epoch=49.0] | Loss=0.01457 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.699 | L2-Norm(final)=6.197 | 2364.6 samples/s | 36.9 steps/s
[Step=25100 Epoch=49.1] | Loss=0.01417 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.702 | L2-Norm(final)=6.198 | 4348.0 samples/s | 67.9 steps/s
[Step=25150 Epoch=49.2] | Loss=0.01410 | Reg=0.00471 | acc=0.9688 | L2-Norm=21.703 | L2-Norm(final)=6.201 | 4446.2 samples/s | 69.5 steps/s
[Step=25200 Epoch=49.3] | Loss=0.01406 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.705 | L2-Norm(final)=6.202 | 4592.6 samples/s | 71.8 steps/s
[Step=25250 Epoch=49.4] | Loss=0.01389 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.705 | L2-Norm(final)=6.204 | 4252.8 samples/s | 66.5 steps/s
[Step=25300 Epoch=49.5] | Loss=0.01385 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.706 | L2-Norm(final)=6.206 | 4533.5 samples/s | 70.8 steps/s
[Step=25350 Epoch=49.6] | Loss=0.01378 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.706 | L2-Norm(final)=6.207 | 4414.6 samples/s | 69.0 steps/s
[Step=25400 Epoch=49.7] | Loss=0.01366 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.706 | L2-Norm(final)=6.209 | 4363.9 samples/s | 68.2 steps/s
[Step=25450 Epoch=49.8] | Loss=0.01373 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.706 | L2-Norm(final)=6.211 | 4405.4 samples/s | 68.8 steps/s
[Step=25500 Epoch=49.9] | Loss=0.01370 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.706 | L2-Norm(final)=6.212 | 4945.7 samples/s | 77.3 steps/s
[Step=25550 Epoch=49.9] | Loss=0.01369 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.705 | L2-Norm(final)=6.214 | 2578.4 samples/s | 40.3 steps/s
[Step=25600 Epoch=50.0] | Loss=0.01361 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.704 | L2-Norm(final)=6.215 | 4428.3 samples/s | 69.2 steps/s
[Step=25650 Epoch=50.1] | Loss=0.01345 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.703 | L2-Norm(final)=6.216 | 4581.4 samples/s | 71.6 steps/s
[Step=25700 Epoch=50.2] | Loss=0.01330 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.703 | L2-Norm(final)=6.218 | 4283.6 samples/s | 66.9 steps/s
[Step=25750 Epoch=50.3] | Loss=0.01320 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.702 | L2-Norm(final)=6.220 | 4458.6 samples/s | 69.7 steps/s
[Step=25800 Epoch=50.4] | Loss=0.01301 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.700 | L2-Norm(final)=6.222 | 4414.4 samples/s | 69.0 steps/s
[Step=25850 Epoch=50.5] | Loss=0.01293 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.698 | L2-Norm(final)=6.224 | 4381.4 samples/s | 68.5 steps/s
[Step=25900 Epoch=50.6] | Loss=0.01278 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.697 | L2-Norm(final)=6.226 | 4403.8 samples/s | 68.8 steps/s
[Step=25950 Epoch=50.7] | Loss=0.01277 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.695 | L2-Norm(final)=6.228 | 4474.7 samples/s | 69.9 steps/s
[Step=26000 Epoch=50.8] | Loss=0.01275 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.694 | L2-Norm(final)=6.229 | 4437.9 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step26000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=92.0] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.364 | L2-Norm(final)=4.586 | 6359.8 samples/s | 99.4 steps/s
[Step=24050 Epoch=92.2] | Loss=0.00020 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.372 | L2-Norm(final)=4.595 | 4098.0 samples/s | 64.0 steps/s
[Step=24100 Epoch=92.3] | Loss=0.00023 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.382 | L2-Norm(final)=4.602 | 4751.8 samples/s | 74.2 steps/s
[Step=24150 Epoch=92.5] | Loss=0.00032 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.390 | L2-Norm(final)=4.610 | 4603.7 samples/s | 71.9 steps/s
[Step=24200 Epoch=92.7] | Loss=0.00036 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.398 | L2-Norm(final)=4.619 | 4742.5 samples/s | 74.1 steps/s
[Step=24250 Epoch=92.9] | Loss=0.00033 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.411 | L2-Norm(final)=4.628 | 6426.0 samples/s | 100.4 steps/s
[Step=24300 Epoch=93.1] | Loss=0.00029 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.421 | L2-Norm(final)=4.635 | 2374.1 samples/s | 37.1 steps/s
[Step=24350 Epoch=93.3] | Loss=0.00026 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.427 | L2-Norm(final)=4.641 | 4730.3 samples/s | 73.9 steps/s
[Step=24400 Epoch=93.5] | Loss=0.00023 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.431 | L2-Norm(final)=4.646 | 4764.3 samples/s | 74.4 steps/s
[Step=24450 Epoch=93.7] | Loss=0.00021 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.433 | L2-Norm(final)=4.651 | 4758.5 samples/s | 74.4 steps/s
[Step=24500 Epoch=93.9] | Loss=0.00019 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.435 | L2-Norm(final)=4.655 | 5204.9 samples/s | 81.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=93.9] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.442 | L2-Norm(final)=4.696 | 5749.6 samples/s | 89.8 steps/s
[Step=24550 Epoch=94.1] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.425 | L2-Norm(final)=4.698 | 3801.7 samples/s | 59.4 steps/s
[Step=24600 Epoch=94.3] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.402 | L2-Norm(final)=4.699 | 4066.3 samples/s | 63.5 steps/s
[Step=24650 Epoch=94.5] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.378 | L2-Norm(final)=4.700 | 4035.5 samples/s | 63.1 steps/s
[Step=24700 Epoch=94.6] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.356 | L2-Norm(final)=4.702 | 4157.2 samples/s | 65.0 steps/s
[Step=24750 Epoch=94.8] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.332 | L2-Norm(final)=4.703 | 5626.3 samples/s | 87.9 steps/s
[Step=24800 Epoch=95.0] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.309 | L2-Norm(final)=4.704 | 2282.8 samples/s | 35.7 steps/s
[Step=24850 Epoch=95.2] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.285 | L2-Norm(final)=4.705 | 4128.6 samples/s | 64.5 steps/s
[Step=24900 Epoch=95.4] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.261 | L2-Norm(final)=4.706 | 4306.1 samples/s | 67.3 steps/s
[Step=24950 Epoch=95.6] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.237 | L2-Norm(final)=4.706 | 4090.9 samples/s | 63.9 steps/s
[Step=25000 Epoch=95.8] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.212 | L2-Norm(final)=4.707 | 4727.2 samples/s | 73.9 steps/s
[Step=25050 Epoch=96.0] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.188 | L2-Norm(final)=4.707 | 2434.1 samples/s | 38.0 steps/s
[Step=25100 Epoch=96.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.163 | L2-Norm(final)=4.708 | 4173.3 samples/s | 65.2 steps/s
[Step=25150 Epoch=96.4] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.138 | L2-Norm(final)=4.708 | 4162.3 samples/s | 65.0 steps/s
[Step=25200 Epoch=96.6] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.114 | L2-Norm(final)=4.709 | 4250.1 samples/s | 66.4 steps/s
[Step=25250 Epoch=96.7] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.088 | L2-Norm(final)=4.709 | 4167.3 samples/s | 65.1 steps/s
[Step=25300 Epoch=96.9] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.063 | L2-Norm(final)=4.710 | 2620.6 samples/s | 40.9 steps/s
[Step=25350 Epoch=97.1] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.038 | L2-Norm(final)=4.710 | 4160.9 samples/s | 65.0 steps/s
[Step=25400 Epoch=97.3] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.013 | L2-Norm(final)=4.710 | 4158.4 samples/s | 65.0 steps/s
[Step=25450 Epoch=97.5] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.987 | L2-Norm(final)=4.711 | 4236.1 samples/s | 66.2 steps/s
[Step=25500 Epoch=97.7] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.962 | L2-Norm(final)=4.711 | 4207.7 samples/s | 65.7 steps/s
[Step=25550 Epoch=97.9] | Loss=0.00000 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.936 | L2-Norm(final)=4.712 | 2596.0 samples/s | 40.6 steps/s
[Step=25600 Epoch=98.1] | Loss=0.00000 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.910 | L2-Norm(final)=4.712 | 4274.3 samples/s | 66.8 steps/s
[Step=25650 Epoch=98.3] | Loss=0.00000 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.884 | L2-Norm(final)=4.712 | 4174.1 samples/s | 65.2 steps/s
[Step=25700 Epoch=98.5] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.858 | L2-Norm(final)=4.713 | 4286.6 samples/s | 67.0 steps/s
[Step=25750 Epoch=98.7] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.831 | L2-Norm(final)=4.713 | 4193.1 samples/s | 65.5 steps/s
[Step=25800 Epoch=98.9] | Loss=0.00000 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.805 | L2-Norm(final)=4.714 | 6190.2 samples/s | 96.7 steps/s
[Step=25850 Epoch=99.0] | Loss=0.00000 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.778 | L2-Norm(final)=4.714 | 2170.1 samples/s | 33.9 steps/s
[Step=25900 Epoch=99.2] | Loss=0.00000 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.752 | L2-Norm(final)=4.715 | 4207.6 samples/s | 65.7 steps/s
[Step=25950 Epoch=99.4] | Loss=0.00000 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.725 | L2-Norm(final)=4.715 | 4156.9 samples/s | 65.0 steps/s
[Step=26000 Epoch=99.6] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.698 | L2-Norm(final)=4.715 | 4237.0 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step26000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=92.4] | Loss=0.00004 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.357 | L2-Norm(final)=5.187 | 5919.2 samples/s | 92.5 steps/s
[Step=24050 Epoch=92.6] | Loss=0.00097 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.356 | L2-Norm(final)=5.191 | 4029.2 samples/s | 63.0 steps/s
[Step=24100 Epoch=92.8] | Loss=0.00099 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.382 | L2-Norm(final)=5.192 | 4720.7 samples/s | 73.8 steps/s
[Step=24150 Epoch=93.0] | Loss=0.00115 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.409 | L2-Norm(final)=5.192 | 4801.1 samples/s | 75.0 steps/s
[Step=24200 Epoch=93.2] | Loss=0.00089 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.426 | L2-Norm(final)=5.192 | 4605.8 samples/s | 72.0 steps/s
[Step=24250 Epoch=93.3] | Loss=0.00073 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.436 | L2-Norm(final)=5.194 | 6763.4 samples/s | 105.7 steps/s
[Step=24300 Epoch=93.5] | Loss=0.00062 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.442 | L2-Norm(final)=5.196 | 2407.2 samples/s | 37.6 steps/s
[Step=24350 Epoch=93.7] | Loss=0.00054 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.446 | L2-Norm(final)=5.198 | 4622.0 samples/s | 72.2 steps/s
[Step=24400 Epoch=93.9] | Loss=0.00047 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.448 | L2-Norm(final)=5.200 | 4737.1 samples/s | 74.0 steps/s
[Step=24450 Epoch=94.1] | Loss=0.00043 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.449 | L2-Norm(final)=5.202 | 4715.7 samples/s | 73.7 steps/s
[Step=24500 Epoch=94.3] | Loss=0.00039 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.450 | L2-Norm(final)=5.204 | 5672.1 samples/s | 88.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=94.3] | Loss=0.00006 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.453 | L2-Norm(final)=5.224 | 6327.1 samples/s | 98.9 steps/s
[Step=24550 Epoch=94.5] | Loss=0.00003 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.427 | L2-Norm(final)=5.226 | 3726.2 samples/s | 58.2 steps/s
[Step=24600 Epoch=94.7] | Loss=0.00163 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.422 | L2-Norm(final)=5.228 | 4260.1 samples/s | 66.6 steps/s
[Step=24650 Epoch=94.9] | Loss=0.00881 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.507 | L2-Norm(final)=5.210 | 4139.1 samples/s | 64.7 steps/s
[Step=24700 Epoch=95.1] | Loss=0.00871 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=5.187 | 4235.9 samples/s | 66.2 steps/s
[Step=24750 Epoch=95.3] | Loss=0.00737 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=5.172 | 5760.9 samples/s | 90.0 steps/s
[Step=24800 Epoch=95.5] | Loss=0.00626 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.659 | L2-Norm(final)=5.162 | 2279.9 samples/s | 35.6 steps/s
[Step=24850 Epoch=95.7] | Loss=0.00540 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=5.157 | 4073.9 samples/s | 63.7 steps/s
[Step=24900 Epoch=95.8] | Loss=0.00478 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.697 | L2-Norm(final)=5.153 | 4231.1 samples/s | 66.1 steps/s
[Step=24950 Epoch=96.0] | Loss=0.00426 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.708 | L2-Norm(final)=5.151 | 4174.5 samples/s | 65.2 steps/s
[Step=25000 Epoch=96.2] | Loss=0.00383 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.716 | L2-Norm(final)=5.149 | 4884.5 samples/s | 76.3 steps/s
[Step=25050 Epoch=96.4] | Loss=0.00349 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.722 | L2-Norm(final)=5.148 | 2398.8 samples/s | 37.5 steps/s
[Step=25100 Epoch=96.6] | Loss=0.00320 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=5.147 | 4272.2 samples/s | 66.8 steps/s
[Step=25150 Epoch=96.8] | Loss=0.00295 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.729 | L2-Norm(final)=5.146 | 4115.1 samples/s | 64.3 steps/s
[Step=25200 Epoch=97.0] | Loss=0.00275 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.730 | L2-Norm(final)=5.146 | 4235.7 samples/s | 66.2 steps/s
[Step=25250 Epoch=97.2] | Loss=0.00256 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.730 | L2-Norm(final)=5.145 | 4256.4 samples/s | 66.5 steps/s
[Step=25300 Epoch=97.4] | Loss=0.00240 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.730 | L2-Norm(final)=5.145 | 2623.7 samples/s | 41.0 steps/s
[Step=25350 Epoch=97.6] | Loss=0.00226 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.729 | L2-Norm(final)=5.145 | 4078.7 samples/s | 63.7 steps/s
[Step=25400 Epoch=97.8] | Loss=0.00214 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.728 | L2-Norm(final)=5.145 | 4260.9 samples/s | 66.6 steps/s
[Step=25450 Epoch=98.0] | Loss=0.00203 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=5.145 | 4156.1 samples/s | 64.9 steps/s
[Step=25500 Epoch=98.2] | Loss=0.00193 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.723 | L2-Norm(final)=5.145 | 4218.4 samples/s | 65.9 steps/s
[Step=25550 Epoch=98.4] | Loss=0.00184 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.720 | L2-Norm(final)=5.145 | 2616.9 samples/s | 40.9 steps/s
[Step=25600 Epoch=98.5] | Loss=0.00175 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=5.145 | 4162.0 samples/s | 65.0 steps/s
[Step=25650 Epoch=98.7] | Loss=0.00168 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.714 | L2-Norm(final)=5.145 | 4229.3 samples/s | 66.1 steps/s
[Step=25700 Epoch=98.9] | Loss=0.00161 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.710 | L2-Norm(final)=5.145 | 4286.2 samples/s | 67.0 steps/s
[Step=25750 Epoch=99.1] | Loss=0.00154 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.706 | L2-Norm(final)=5.145 | 4124.5 samples/s | 64.4 steps/s
[Step=25800 Epoch=99.3] | Loss=0.00148 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.702 | L2-Norm(final)=5.145 | 6864.6 samples/s | 107.3 steps/s
[Step=25850 Epoch=99.5] | Loss=0.00143 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.698 | L2-Norm(final)=5.146 | 2078.0 samples/s | 32.5 steps/s
[Step=25900 Epoch=99.7] | Loss=0.00138 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.693 | L2-Norm(final)=5.146 | 4091.9 samples/s | 63.9 steps/s
[Step=25950 Epoch=99.9] | Loss=0.00133 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.689 | L2-Norm(final)=5.146 | 3957.9 samples/s | 61.8 steps/s
[Step=26000 Epoch=100.1] | Loss=0.00129 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.684 | L2-Norm(final)=5.146 | 4158.8 samples/s | 65.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07838 | acc=0.9668 | tpr=0.9779 | fpr=0.0572 | 4975.1 samples/s | 19.4 steps/s
Avg test loss: 0.07553, Avg test acc: 0.96682, Avg tpr: 0.97756, Avg fpr: 0.05679, total FA: 443

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07011 | acc=0.9652 | tpr=0.9733 | fpr=0.0523 | 5061.1 samples/s | 19.8 steps/s
Avg test loss: 0.07310, Avg test acc: 0.96358, Avg tpr: 0.97185, Avg fpr: 0.05461, total FA: 426

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.30114 | acc=0.2959 | tpr=0.0171 | fpr=0.0986 | 4810.5 samples/s | 18.8 steps/s
Avg test loss: 6.30001, Avg test acc: 0.29293, Avg tpr: 0.01784, Avg fpr: 0.10204, total FA: 796

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.18178 | acc=0.3109 | tpr=0.0089 | fpr=0.0332 | 4904.4 samples/s | 19.2 steps/s
Avg test loss: 6.17854, Avg test acc: 0.30884, Avg tpr: 0.01014, Avg fpr: 0.03423, total FA: 267

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.36464 | acc=0.1134 | tpr=0.6460 | fpr=0.8962 | 4935.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=7.31377 | acc=0.1129 | tpr=0.6162 | fpr=0.8965 | 7065.7 samples/s | 27.6 steps/s
[Step= 150] | Loss=7.32214 | acc=0.1131 | tpr=0.5994 | fpr=0.8958 | 7809.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=7.31664 | acc=0.1139 | tpr=0.5989 | fpr=0.8949 | 7601.7 samples/s | 29.7 steps/s
[Step= 250] | Loss=7.31896 | acc=0.1140 | tpr=0.6026 | fpr=0.8949 | 7967.4 samples/s | 31.1 steps/s
[Step= 300] | Loss=7.31900 | acc=0.1146 | tpr=0.5956 | fpr=0.8941 | 7651.6 samples/s | 29.9 steps/s
[Step= 350] | Loss=7.32355 | acc=0.1145 | tpr=0.5861 | fpr=0.8941 | 7446.1 samples/s | 29.1 steps/s
[Step= 400] | Loss=7.32648 | acc=0.1141 | tpr=0.5848 | fpr=0.8945 | 8498.6 samples/s | 33.2 steps/s
[Step= 450] | Loss=7.33204 | acc=0.1139 | tpr=0.5915 | fpr=0.8948 | 7637.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=7.33269 | acc=0.1139 | tpr=0.5925 | fpr=0.8948 | 7893.7 samples/s | 30.8 steps/s
[Step= 550] | Loss=7.33773 | acc=0.1136 | tpr=0.5877 | fpr=0.8950 | 13341.7 samples/s | 52.1 steps/s
Avg test loss: 7.34008, Avg test acc: 0.11354, Avg tpr: 0.58835, Avg fpr: 0.89509, total FA: 124282

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.71302 | acc=0.1398 | tpr=0.6283 | fpr=0.8690 | 4905.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.69153 | acc=0.1384 | tpr=0.5757 | fpr=0.8698 | 6949.3 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.68559 | acc=0.1389 | tpr=0.5793 | fpr=0.8692 | 8225.1 samples/s | 32.1 steps/s
[Step= 200] | Loss=6.68145 | acc=0.1394 | tpr=0.5770 | fpr=0.8686 | 7705.3 samples/s | 30.1 steps/s
[Step= 250] | Loss=6.67204 | acc=0.1395 | tpr=0.5729 | fpr=0.8684 | 7619.4 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.67308 | acc=0.1399 | tpr=0.5738 | fpr=0.8680 | 8031.8 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.68242 | acc=0.1394 | tpr=0.5679 | fpr=0.8683 | 7785.4 samples/s | 30.4 steps/s
[Step= 400] | Loss=6.68265 | acc=0.1395 | tpr=0.5656 | fpr=0.8682 | 7740.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=6.69062 | acc=0.1397 | tpr=0.5662 | fpr=0.8680 | 7610.7 samples/s | 29.7 steps/s
[Step= 500] | Loss=6.69032 | acc=0.1399 | tpr=0.5670 | fpr=0.8678 | 8003.3 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.69685 | acc=0.1400 | tpr=0.5674 | fpr=0.8678 | 13735.8 samples/s | 53.7 steps/s
Avg test loss: 6.69944, Avg test acc: 0.13987, Avg tpr: 0.56775, Avg fpr: 0.86791, total FA: 120507

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14742 | acc=0.9795 | tpr=0.9513 | fpr=0.0200 | 4833.5 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.14995 | acc=0.9797 | tpr=0.9488 | fpr=0.0197 | 7300.0 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.15726 | acc=0.9787 | tpr=0.9467 | fpr=0.0207 | 7537.2 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.16050 | acc=0.9787 | tpr=0.9486 | fpr=0.0208 | 8256.1 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.15800 | acc=0.9790 | tpr=0.9459 | fpr=0.0204 | 7425.6 samples/s | 29.0 steps/s
[Step= 300] | Loss=0.16009 | acc=0.9787 | tpr=0.9418 | fpr=0.0207 | 8248.8 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.16051 | acc=0.9786 | tpr=0.9430 | fpr=0.0208 | 7578.9 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.16228 | acc=0.9784 | tpr=0.9409 | fpr=0.0209 | 8066.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.16500 | acc=0.9780 | tpr=0.9391 | fpr=0.0212 | 8059.2 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.16369 | acc=0.9782 | tpr=0.9392 | fpr=0.0211 | 7971.9 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.16221 | acc=0.9784 | tpr=0.9407 | fpr=0.0209 | 12860.5 samples/s | 50.2 steps/s
Avg test loss: 0.16196, Avg test acc: 0.97842, Avg tpr: 0.94057, Avg fpr: 0.02089, total FA: 2901

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13263 | acc=0.9778 | tpr=0.9558 | fpr=0.0218 | 4956.5 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.13442 | acc=0.9777 | tpr=0.9680 | fpr=0.0222 | 7037.3 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.14181 | acc=0.9760 | tpr=0.9654 | fpr=0.0238 | 7741.3 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.14428 | acc=0.9759 | tpr=0.9639 | fpr=0.0239 | 7922.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14163 | acc=0.9763 | tpr=0.9590 | fpr=0.0234 | 7790.9 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.14418 | acc=0.9759 | tpr=0.9585 | fpr=0.0237 | 7724.1 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.14472 | acc=0.9757 | tpr=0.9587 | fpr=0.0240 | 7757.8 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.14585 | acc=0.9755 | tpr=0.9573 | fpr=0.0241 | 8123.5 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.14864 | acc=0.9751 | tpr=0.9562 | fpr=0.0245 | 7973.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.14768 | acc=0.9752 | tpr=0.9555 | fpr=0.0244 | 7329.7 samples/s | 28.6 steps/s
[Step= 550] | Loss=0.14643 | acc=0.9756 | tpr=0.9554 | fpr=0.0241 | 14883.9 samples/s | 58.1 steps/s
Avg test loss: 0.14631, Avg test acc: 0.97558, Avg tpr: 0.95483, Avg fpr: 0.02404, total FA: 3338

server round 13/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=50.7] | Loss=0.00093 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.323 | L2-Norm(final)=6.348 | 6089.0 samples/s | 95.1 steps/s
[Step=26050 Epoch=50.8] | Loss=0.01248 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.322 | L2-Norm(final)=6.362 | 4661.7 samples/s | 72.8 steps/s
[Step=26100 Epoch=50.9] | Loss=0.01129 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.320 | L2-Norm(final)=6.377 | 5043.0 samples/s | 78.8 steps/s
[Step=26150 Epoch=51.0] | Loss=0.01157 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.318 | L2-Norm(final)=6.390 | 4952.1 samples/s | 77.4 steps/s
[Step=26200 Epoch=51.1] | Loss=0.01082 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.315 | L2-Norm(final)=6.402 | 5123.6 samples/s | 80.1 steps/s
[Step=26250 Epoch=51.2] | Loss=0.01075 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.311 | L2-Norm(final)=6.414 | 4926.4 samples/s | 77.0 steps/s
[Step=26300 Epoch=51.3] | Loss=0.01052 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.308 | L2-Norm(final)=6.426 | 5031.4 samples/s | 78.6 steps/s
[Step=26350 Epoch=51.4] | Loss=0.01040 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.305 | L2-Norm(final)=6.436 | 5039.0 samples/s | 78.7 steps/s
[Step=26400 Epoch=51.5] | Loss=0.01006 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.302 | L2-Norm(final)=6.446 | 5037.4 samples/s | 78.7 steps/s
[Step=26450 Epoch=51.6] | Loss=0.00977 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.300 | L2-Norm(final)=6.456 | 5230.5 samples/s | 81.7 steps/s
[Step=26500 Epoch=51.7] | Loss=0.00974 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.298 | L2-Norm(final)=6.466 | 6483.6 samples/s | 101.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=51.7] | Loss=0.00050 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.276 | L2-Norm(final)=6.562 | 6167.2 samples/s | 96.4 steps/s
[Step=26550 Epoch=51.8] | Loss=0.01106 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.279 | L2-Norm(final)=6.568 | 4202.4 samples/s | 65.7 steps/s
[Step=26600 Epoch=51.9] | Loss=0.01529 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.281 | L2-Norm(final)=6.561 | 4434.9 samples/s | 69.3 steps/s
[Step=26650 Epoch=52.0] | Loss=0.01479 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.286 | L2-Norm(final)=6.558 | 4527.8 samples/s | 70.7 steps/s
[Step=26700 Epoch=52.1] | Loss=0.01548 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.290 | L2-Norm(final)=6.558 | 4316.2 samples/s | 67.4 steps/s
[Step=26750 Epoch=52.2] | Loss=0.01680 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.298 | L2-Norm(final)=6.556 | 4474.5 samples/s | 69.9 steps/s
[Step=26800 Epoch=52.3] | Loss=0.01701 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.307 | L2-Norm(final)=6.554 | 4472.7 samples/s | 69.9 steps/s
[Step=26850 Epoch=52.4] | Loss=0.01738 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.315 | L2-Norm(final)=6.553 | 4515.1 samples/s | 70.5 steps/s
[Step=26900 Epoch=52.5] | Loss=0.01759 | Reg=0.00455 | acc=0.9531 | L2-Norm=21.323 | L2-Norm(final)=6.553 | 4388.5 samples/s | 68.6 steps/s
[Step=26950 Epoch=52.6] | Loss=0.01746 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.330 | L2-Norm(final)=6.552 | 4454.7 samples/s | 69.6 steps/s
[Step=27000 Epoch=52.7] | Loss=0.01756 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.336 | L2-Norm(final)=6.552 | 5756.6 samples/s | 89.9 steps/s
[Step=27050 Epoch=52.8] | Loss=0.01720 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.343 | L2-Norm(final)=6.553 | 2369.9 samples/s | 37.0 steps/s
[Step=27100 Epoch=52.9] | Loss=0.01680 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.347 | L2-Norm(final)=6.555 | 4536.9 samples/s | 70.9 steps/s
[Step=27150 Epoch=53.0] | Loss=0.01645 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.352 | L2-Norm(final)=6.556 | 4379.5 samples/s | 68.4 steps/s
[Step=27200 Epoch=53.1] | Loss=0.01630 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.356 | L2-Norm(final)=6.558 | 4445.3 samples/s | 69.5 steps/s
[Step=27250 Epoch=53.1] | Loss=0.01587 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.359 | L2-Norm(final)=6.560 | 4460.6 samples/s | 69.7 steps/s
[Step=27300 Epoch=53.2] | Loss=0.01555 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.361 | L2-Norm(final)=6.562 | 4483.4 samples/s | 70.1 steps/s
[Step=27350 Epoch=53.3] | Loss=0.01548 | Reg=0.00456 | acc=0.9688 | L2-Norm=21.363 | L2-Norm(final)=6.563 | 4373.2 samples/s | 68.3 steps/s
[Step=27400 Epoch=53.4] | Loss=0.01548 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.365 | L2-Norm(final)=6.565 | 4461.3 samples/s | 69.7 steps/s
[Step=27450 Epoch=53.5] | Loss=0.01517 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.367 | L2-Norm(final)=6.566 | 4453.2 samples/s | 69.6 steps/s
[Step=27500 Epoch=53.6] | Loss=0.01514 | Reg=0.00457 | acc=0.9688 | L2-Norm=21.368 | L2-Norm(final)=6.567 | 4813.5 samples/s | 75.2 steps/s
[Step=27550 Epoch=53.7] | Loss=0.01488 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.369 | L2-Norm(final)=6.568 | 2632.1 samples/s | 41.1 steps/s
[Step=27600 Epoch=53.8] | Loss=0.01466 | Reg=0.00457 | acc=0.9531 | L2-Norm=21.369 | L2-Norm(final)=6.569 | 4409.0 samples/s | 68.9 steps/s
[Step=27650 Epoch=53.9] | Loss=0.01445 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.369 | L2-Norm(final)=6.570 | 4445.5 samples/s | 69.5 steps/s
[Step=27700 Epoch=54.0] | Loss=0.01428 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.369 | L2-Norm(final)=6.571 | 4464.7 samples/s | 69.8 steps/s
[Step=27750 Epoch=54.1] | Loss=0.01422 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.369 | L2-Norm(final)=6.573 | 4410.0 samples/s | 68.9 steps/s
[Step=27800 Epoch=54.2] | Loss=0.01418 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.368 | L2-Norm(final)=6.574 | 4461.8 samples/s | 69.7 steps/s
[Step=27850 Epoch=54.3] | Loss=0.01403 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.368 | L2-Norm(final)=6.575 | 4494.9 samples/s | 70.2 steps/s
[Step=27900 Epoch=54.4] | Loss=0.01389 | Reg=0.00457 | acc=0.9844 | L2-Norm=21.367 | L2-Norm(final)=6.576 | 4419.2 samples/s | 69.0 steps/s
[Step=27950 Epoch=54.5] | Loss=0.01384 | Reg=0.00457 | acc=0.9844 | L2-Norm=21.367 | L2-Norm(final)=6.578 | 4476.8 samples/s | 70.0 steps/s
[Step=28000 Epoch=54.6] | Loss=0.01371 | Reg=0.00456 | acc=0.9688 | L2-Norm=21.366 | L2-Norm(final)=6.579 | 4508.1 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step28000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=50.8] | Loss=0.00921 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.253 | L2-Norm(final)=6.279 | 6498.1 samples/s | 101.5 steps/s
[Step=26050 Epoch=50.9] | Loss=0.01103 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.251 | L2-Norm(final)=6.293 | 4373.6 samples/s | 68.3 steps/s
[Step=26100 Epoch=51.0] | Loss=0.01155 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.250 | L2-Norm(final)=6.313 | 4922.2 samples/s | 76.9 steps/s
[Step=26150 Epoch=51.1] | Loss=0.01147 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.249 | L2-Norm(final)=6.328 | 4973.5 samples/s | 77.7 steps/s
[Step=26200 Epoch=51.2] | Loss=0.01070 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.248 | L2-Norm(final)=6.342 | 5079.7 samples/s | 79.4 steps/s
[Step=26250 Epoch=51.3] | Loss=0.01065 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.247 | L2-Norm(final)=6.356 | 4975.5 samples/s | 77.7 steps/s
[Step=26300 Epoch=51.4] | Loss=0.01085 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.246 | L2-Norm(final)=6.367 | 5006.8 samples/s | 78.2 steps/s
[Step=26350 Epoch=51.5] | Loss=0.01067 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.245 | L2-Norm(final)=6.379 | 5087.3 samples/s | 79.5 steps/s
[Step=26400 Epoch=51.6] | Loss=0.01098 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.244 | L2-Norm(final)=6.390 | 4994.9 samples/s | 78.0 steps/s
[Step=26450 Epoch=51.7] | Loss=0.01076 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.244 | L2-Norm(final)=6.401 | 5013.8 samples/s | 78.3 steps/s
[Step=26500 Epoch=51.8] | Loss=0.01081 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.243 | L2-Norm(final)=6.411 | 6877.3 samples/s | 107.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=51.8] | Loss=0.00280 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.232 | L2-Norm(final)=6.510 | 6926.8 samples/s | 108.2 steps/s
[Step=26550 Epoch=51.9] | Loss=0.00943 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.235 | L2-Norm(final)=6.518 | 3777.2 samples/s | 59.0 steps/s
[Step=26600 Epoch=52.0] | Loss=0.01189 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.240 | L2-Norm(final)=6.521 | 4422.7 samples/s | 69.1 steps/s
[Step=26650 Epoch=52.1] | Loss=0.01202 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.245 | L2-Norm(final)=6.524 | 4267.9 samples/s | 66.7 steps/s
[Step=26700 Epoch=52.2] | Loss=0.01227 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.249 | L2-Norm(final)=6.527 | 4291.1 samples/s | 67.0 steps/s
[Step=26750 Epoch=52.3] | Loss=0.01341 | Reg=0.00452 | acc=0.9688 | L2-Norm=21.254 | L2-Norm(final)=6.529 | 4313.2 samples/s | 67.4 steps/s
[Step=26800 Epoch=52.4] | Loss=0.01375 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.261 | L2-Norm(final)=6.532 | 4366.8 samples/s | 68.2 steps/s
[Step=26850 Epoch=52.5] | Loss=0.01411 | Reg=0.00452 | acc=0.9688 | L2-Norm=21.268 | L2-Norm(final)=6.535 | 4324.3 samples/s | 67.6 steps/s
[Step=26900 Epoch=52.6] | Loss=0.01466 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.275 | L2-Norm(final)=6.537 | 4449.2 samples/s | 69.5 steps/s
[Step=26950 Epoch=52.7] | Loss=0.01453 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.281 | L2-Norm(final)=6.540 | 4277.2 samples/s | 66.8 steps/s
[Step=27000 Epoch=52.8] | Loss=0.01428 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.287 | L2-Norm(final)=6.543 | 5707.7 samples/s | 89.2 steps/s
[Step=27050 Epoch=52.9] | Loss=0.01400 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.290 | L2-Norm(final)=6.545 | 2311.3 samples/s | 36.1 steps/s
[Step=27100 Epoch=53.0] | Loss=0.01370 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.293 | L2-Norm(final)=6.548 | 4344.5 samples/s | 67.9 steps/s
[Step=27150 Epoch=53.1] | Loss=0.01371 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.296 | L2-Norm(final)=6.550 | 4343.3 samples/s | 67.9 steps/s
[Step=27200 Epoch=53.2] | Loss=0.01359 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.298 | L2-Norm(final)=6.553 | 4426.1 samples/s | 69.2 steps/s
[Step=27250 Epoch=53.3] | Loss=0.01341 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.301 | L2-Norm(final)=6.556 | 4273.0 samples/s | 66.8 steps/s
[Step=27300 Epoch=53.4] | Loss=0.01327 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.303 | L2-Norm(final)=6.558 | 4344.9 samples/s | 67.9 steps/s
[Step=27350 Epoch=53.5] | Loss=0.01332 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.305 | L2-Norm(final)=6.561 | 4448.2 samples/s | 69.5 steps/s
[Step=27400 Epoch=53.6] | Loss=0.01325 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.307 | L2-Norm(final)=6.563 | 4226.9 samples/s | 66.0 steps/s
[Step=27450 Epoch=53.7] | Loss=0.01324 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.309 | L2-Norm(final)=6.565 | 4322.4 samples/s | 67.5 steps/s
[Step=27500 Epoch=53.8] | Loss=0.01314 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.310 | L2-Norm(final)=6.568 | 4818.5 samples/s | 75.3 steps/s
[Step=27550 Epoch=53.9] | Loss=0.01300 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.312 | L2-Norm(final)=6.570 | 2539.7 samples/s | 39.7 steps/s
[Step=27600 Epoch=54.0] | Loss=0.01299 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.313 | L2-Norm(final)=6.573 | 4261.6 samples/s | 66.6 steps/s
[Step=27650 Epoch=54.1] | Loss=0.01293 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.315 | L2-Norm(final)=6.575 | 4384.5 samples/s | 68.5 steps/s
[Step=27700 Epoch=54.2] | Loss=0.01278 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.317 | L2-Norm(final)=6.577 | 4306.8 samples/s | 67.3 steps/s
[Step=27750 Epoch=54.3] | Loss=0.01266 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.318 | L2-Norm(final)=6.580 | 4229.3 samples/s | 66.1 steps/s
[Step=27800 Epoch=54.3] | Loss=0.01255 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.318 | L2-Norm(final)=6.582 | 4210.6 samples/s | 65.8 steps/s
[Step=27850 Epoch=54.4] | Loss=0.01257 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.319 | L2-Norm(final)=6.584 | 4321.9 samples/s | 67.5 steps/s
[Step=27900 Epoch=54.5] | Loss=0.01263 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.319 | L2-Norm(final)=6.586 | 4436.7 samples/s | 69.3 steps/s
[Step=27950 Epoch=54.6] | Loss=0.01255 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.319 | L2-Norm(final)=6.588 | 4237.6 samples/s | 66.2 steps/s
[Step=28000 Epoch=54.7] | Loss=0.01246 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.319 | L2-Norm(final)=6.590 | 4350.0 samples/s | 68.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step28000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=99.6] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.893 | L2-Norm(final)=4.729 | 5896.1 samples/s | 92.1 steps/s
[Step=26050 Epoch=99.8] | Loss=0.00043 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.895 | L2-Norm(final)=4.736 | 4183.9 samples/s | 65.4 steps/s
[Step=26100 Epoch=100.0] | Loss=0.00046 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.916 | L2-Norm(final)=4.748 | 4591.2 samples/s | 71.7 steps/s
[Step=26150 Epoch=100.2] | Loss=0.00034 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.931 | L2-Norm(final)=4.760 | 4649.3 samples/s | 72.6 steps/s
[Step=26200 Epoch=100.4] | Loss=0.00027 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.938 | L2-Norm(final)=4.770 | 4521.0 samples/s | 70.6 steps/s
[Step=26250 Epoch=100.6] | Loss=0.00023 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.941 | L2-Norm(final)=4.778 | 6401.9 samples/s | 100.0 steps/s
[Step=26300 Epoch=100.8] | Loss=0.00020 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.943 | L2-Norm(final)=4.785 | 2332.8 samples/s | 36.5 steps/s
[Step=26350 Epoch=101.0] | Loss=0.00017 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.943 | L2-Norm(final)=4.791 | 4647.5 samples/s | 72.6 steps/s
[Step=26400 Epoch=101.2] | Loss=0.00015 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.942 | L2-Norm(final)=4.796 | 4656.7 samples/s | 72.8 steps/s
[Step=26450 Epoch=101.3] | Loss=0.00014 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.941 | L2-Norm(final)=4.802 | 4625.3 samples/s | 72.3 steps/s
[Step=26500 Epoch=101.5] | Loss=0.00013 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.940 | L2-Norm(final)=4.806 | 5154.3 samples/s | 80.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=101.5] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=4.855 | 6283.3 samples/s | 98.2 steps/s
[Step=26550 Epoch=101.7] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=4.857 | 3584.4 samples/s | 56.0 steps/s
[Step=26600 Epoch=101.9] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.842 | L2-Norm(final)=4.859 | 4111.8 samples/s | 64.2 steps/s
[Step=26650 Epoch=102.1] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.793 | L2-Norm(final)=4.860 | 4171.7 samples/s | 65.2 steps/s
[Step=26700 Epoch=102.3] | Loss=0.00067 | Reg=0.00163 | acc=0.9844 | L2-Norm=12.752 | L2-Norm(final)=4.861 | 4165.8 samples/s | 65.1 steps/s
[Step=26750 Epoch=102.5] | Loss=0.00312 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.778 | L2-Norm(final)=4.847 | 5305.3 samples/s | 82.9 steps/s
[Step=26800 Epoch=102.7] | Loss=0.00374 | Reg=0.00164 | acc=0.9844 | L2-Norm=12.814 | L2-Norm(final)=4.828 | 2235.3 samples/s | 34.9 steps/s
[Step=26850 Epoch=102.9] | Loss=0.00330 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.844 | L2-Norm(final)=4.815 | 4152.6 samples/s | 64.9 steps/s
[Step=26900 Epoch=103.1] | Loss=0.00294 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.866 | L2-Norm(final)=4.805 | 4173.4 samples/s | 65.2 steps/s
[Step=26950 Epoch=103.3] | Loss=0.00270 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.883 | L2-Norm(final)=4.799 | 4022.4 samples/s | 62.8 steps/s
[Step=27000 Epoch=103.5] | Loss=0.00246 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.896 | L2-Norm(final)=4.793 | 4560.2 samples/s | 71.3 steps/s
[Step=27050 Epoch=103.6] | Loss=0.00225 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.906 | L2-Norm(final)=4.790 | 2308.9 samples/s | 36.1 steps/s
[Step=27100 Epoch=103.8] | Loss=0.00207 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.913 | L2-Norm(final)=4.787 | 4017.5 samples/s | 62.8 steps/s
[Step=27150 Epoch=104.0] | Loss=0.00191 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=4.785 | 4075.0 samples/s | 63.7 steps/s
[Step=27200 Epoch=104.2] | Loss=0.00178 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.923 | L2-Norm(final)=4.783 | 4033.8 samples/s | 63.0 steps/s
[Step=27250 Epoch=104.4] | Loss=0.00166 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=4.781 | 4012.5 samples/s | 62.7 steps/s
[Step=27300 Epoch=104.6] | Loss=0.00156 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.928 | L2-Norm(final)=4.780 | 2496.1 samples/s | 39.0 steps/s
[Step=27350 Epoch=104.8] | Loss=0.00147 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.929 | L2-Norm(final)=4.779 | 4093.1 samples/s | 64.0 steps/s
[Step=27400 Epoch=105.0] | Loss=0.00138 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.929 | L2-Norm(final)=4.778 | 4168.1 samples/s | 65.1 steps/s
[Step=27450 Epoch=105.2] | Loss=0.00131 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.928 | L2-Norm(final)=4.778 | 4089.9 samples/s | 63.9 steps/s
[Step=27500 Epoch=105.4] | Loss=0.00125 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.927 | L2-Norm(final)=4.777 | 4123.6 samples/s | 64.4 steps/s
[Step=27550 Epoch=105.6] | Loss=0.00119 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=4.777 | 2581.9 samples/s | 40.3 steps/s
[Step=27600 Epoch=105.8] | Loss=0.00113 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.924 | L2-Norm(final)=4.777 | 4168.7 samples/s | 65.1 steps/s
[Step=27650 Epoch=105.9] | Loss=0.00109 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.921 | L2-Norm(final)=4.776 | 4163.6 samples/s | 65.1 steps/s
[Step=27700 Epoch=106.1] | Loss=0.00104 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=4.776 | 4146.6 samples/s | 64.8 steps/s
[Step=27750 Epoch=106.3] | Loss=0.00100 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.916 | L2-Norm(final)=4.776 | 4194.8 samples/s | 65.5 steps/s
[Step=27800 Epoch=106.5] | Loss=0.00096 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.912 | L2-Norm(final)=4.776 | 6119.6 samples/s | 95.6 steps/s
[Step=27850 Epoch=106.7] | Loss=0.00093 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.909 | L2-Norm(final)=4.776 | 2170.6 samples/s | 33.9 steps/s
[Step=27900 Epoch=106.9] | Loss=0.00089 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.905 | L2-Norm(final)=4.776 | 4064.2 samples/s | 63.5 steps/s
[Step=27950 Epoch=107.1] | Loss=0.00086 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.901 | L2-Norm(final)=4.776 | 4183.7 samples/s | 65.4 steps/s
[Step=28000 Epoch=107.3] | Loss=0.00083 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.897 | L2-Norm(final)=4.776 | 4277.3 samples/s | 66.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step28000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=100.1] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.186 | L2-Norm(final)=5.153 | 5240.8 samples/s | 81.9 steps/s
[Step=26050 Epoch=100.3] | Loss=0.00008 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.183 | L2-Norm(final)=5.155 | 4274.0 samples/s | 66.8 steps/s
[Step=26100 Epoch=100.5] | Loss=0.00021 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.183 | L2-Norm(final)=5.158 | 4868.4 samples/s | 76.1 steps/s
[Step=26150 Epoch=100.7] | Loss=0.00017 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.184 | L2-Norm(final)=5.162 | 4543.2 samples/s | 71.0 steps/s
[Step=26200 Epoch=100.9] | Loss=0.00017 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.184 | L2-Norm(final)=5.165 | 4642.5 samples/s | 72.5 steps/s
[Step=26250 Epoch=101.0] | Loss=0.00016 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.184 | L2-Norm(final)=5.168 | 6678.9 samples/s | 104.4 steps/s
[Step=26300 Epoch=101.2] | Loss=0.00014 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.184 | L2-Norm(final)=5.172 | 2387.8 samples/s | 37.3 steps/s
[Step=26350 Epoch=101.4] | Loss=0.00013 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.183 | L2-Norm(final)=5.175 | 4552.7 samples/s | 71.1 steps/s
[Step=26400 Epoch=101.6] | Loss=0.00012 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.182 | L2-Norm(final)=5.177 | 4695.3 samples/s | 73.4 steps/s
[Step=26450 Epoch=101.8] | Loss=0.00012 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.181 | L2-Norm(final)=5.180 | 4678.4 samples/s | 73.1 steps/s
[Step=26500 Epoch=102.0] | Loss=0.00011 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.180 | L2-Norm(final)=5.183 | 5546.9 samples/s | 86.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=102.0] | Loss=0.00004 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.168 | L2-Norm(final)=5.212 | 5856.7 samples/s | 91.5 steps/s
[Step=26550 Epoch=102.2] | Loss=0.00005 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.162 | L2-Norm(final)=5.214 | 3930.5 samples/s | 61.4 steps/s
[Step=26600 Epoch=102.4] | Loss=0.00004 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.154 | L2-Norm(final)=5.217 | 4076.3 samples/s | 63.7 steps/s
[Step=26650 Epoch=102.6] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.144 | L2-Norm(final)=5.218 | 4195.9 samples/s | 65.6 steps/s
[Step=26700 Epoch=102.8] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.135 | L2-Norm(final)=5.220 | 4176.1 samples/s | 65.3 steps/s
[Step=26750 Epoch=103.0] | Loss=0.00003 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.126 | L2-Norm(final)=5.221 | 5666.4 samples/s | 88.5 steps/s
[Step=26800 Epoch=103.2] | Loss=0.00003 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.116 | L2-Norm(final)=5.223 | 2218.2 samples/s | 34.7 steps/s
[Step=26850 Epoch=103.4] | Loss=0.00002 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.107 | L2-Norm(final)=5.224 | 4189.3 samples/s | 65.5 steps/s
[Step=26900 Epoch=103.5] | Loss=0.00002 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.097 | L2-Norm(final)=5.225 | 4168.9 samples/s | 65.1 steps/s
[Step=26950 Epoch=103.7] | Loss=0.00002 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.087 | L2-Norm(final)=5.226 | 4153.2 samples/s | 64.9 steps/s
[Step=27000 Epoch=103.9] | Loss=0.00002 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.077 | L2-Norm(final)=5.226 | 4880.7 samples/s | 76.3 steps/s
[Step=27050 Epoch=104.1] | Loss=0.00002 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.067 | L2-Norm(final)=5.227 | 2355.1 samples/s | 36.8 steps/s
[Step=27100 Epoch=104.3] | Loss=0.00002 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.057 | L2-Norm(final)=5.228 | 4163.7 samples/s | 65.1 steps/s
[Step=27150 Epoch=104.5] | Loss=0.00002 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.046 | L2-Norm(final)=5.229 | 4167.3 samples/s | 65.1 steps/s
[Step=27200 Epoch=104.7] | Loss=0.00002 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.036 | L2-Norm(final)=5.229 | 4167.5 samples/s | 65.1 steps/s
[Step=27250 Epoch=104.9] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.025 | L2-Norm(final)=5.230 | 4277.2 samples/s | 66.8 steps/s
[Step=27300 Epoch=105.1] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.015 | L2-Norm(final)=5.231 | 2545.0 samples/s | 39.8 steps/s
[Step=27350 Epoch=105.3] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.004 | L2-Norm(final)=5.231 | 4233.0 samples/s | 66.1 steps/s
[Step=27400 Epoch=105.5] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.993 | L2-Norm(final)=5.232 | 4093.6 samples/s | 64.0 steps/s
[Step=27450 Epoch=105.7] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.982 | L2-Norm(final)=5.232 | 4183.4 samples/s | 65.4 steps/s
[Step=27500 Epoch=105.9] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.971 | L2-Norm(final)=5.233 | 4104.8 samples/s | 64.1 steps/s
[Step=27550 Epoch=106.1] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.959 | L2-Norm(final)=5.233 | 2574.9 samples/s | 40.2 steps/s
[Step=27600 Epoch=106.2] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.948 | L2-Norm(final)=5.234 | 4256.4 samples/s | 66.5 steps/s
[Step=27650 Epoch=106.4] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.937 | L2-Norm(final)=5.235 | 4209.3 samples/s | 65.8 steps/s
[Step=27700 Epoch=106.6] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.925 | L2-Norm(final)=5.235 | 4090.0 samples/s | 63.9 steps/s
[Step=27750 Epoch=106.8] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.914 | L2-Norm(final)=5.236 | 4157.5 samples/s | 65.0 steps/s
[Step=27800 Epoch=107.0] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.902 | L2-Norm(final)=5.236 | 6840.6 samples/s | 106.9 steps/s
[Step=27850 Epoch=107.2] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=5.237 | 2089.7 samples/s | 32.7 steps/s
[Step=27900 Epoch=107.4] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.878 | L2-Norm(final)=5.237 | 4262.2 samples/s | 66.6 steps/s
[Step=27950 Epoch=107.6] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.866 | L2-Norm(final)=5.238 | 4106.9 samples/s | 64.2 steps/s
[Step=28000 Epoch=107.8] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.854 | L2-Norm(final)=5.238 | 4153.3 samples/s | 64.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07962 | acc=0.9682 | tpr=0.9749 | fpr=0.0463 | 4810.3 samples/s | 18.8 steps/s
Avg test loss: 0.07913, Avg test acc: 0.96735, Avg tpr: 0.97418, Avg fpr: 0.04769, total FA: 372

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08388 | acc=0.9649 | tpr=0.9734 | fpr=0.0535 | 4847.9 samples/s | 18.9 steps/s
Avg test loss: 0.08245, Avg test acc: 0.96398, Avg tpr: 0.97162, Avg fpr: 0.05281, total FA: 412

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.80328 | acc=0.3075 | tpr=0.0114 | fpr=0.0496 | 4877.9 samples/s | 19.1 steps/s
Avg test loss: 4.80311, Avg test acc: 0.30447, Avg tpr: 0.01241, Avg fpr: 0.05320, total FA: 415

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.42309 | acc=0.3123 | tpr=0.0254 | fpr=0.0649 | 4835.2 samples/s | 18.9 steps/s
Avg test loss: 6.40379, Avg test acc: 0.31088, Avg tpr: 0.02687, Avg fpr: 0.06448, total FA: 503

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.75696 | acc=0.1365 | tpr=0.5619 | fpr=0.8712 | 4879.7 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.70854 | acc=0.1368 | tpr=0.5373 | fpr=0.8707 | 7086.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.71983 | acc=0.1361 | tpr=0.5375 | fpr=0.8712 | 7655.7 samples/s | 29.9 steps/s
[Step= 200] | Loss=6.71004 | acc=0.1364 | tpr=0.5388 | fpr=0.8709 | 7779.6 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.70546 | acc=0.1368 | tpr=0.5459 | fpr=0.8707 | 7893.6 samples/s | 30.8 steps/s
[Step= 300] | Loss=6.70032 | acc=0.1372 | tpr=0.5411 | fpr=0.8702 | 7756.0 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.70723 | acc=0.1368 | tpr=0.5341 | fpr=0.8704 | 7394.9 samples/s | 28.9 steps/s
[Step= 400] | Loss=6.71734 | acc=0.1369 | tpr=0.5301 | fpr=0.8703 | 7955.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.72072 | acc=0.1366 | tpr=0.5278 | fpr=0.8705 | 7975.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=6.72150 | acc=0.1363 | tpr=0.5264 | fpr=0.8707 | 7600.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=6.72387 | acc=0.1364 | tpr=0.5265 | fpr=0.8706 | 13842.1 samples/s | 54.1 steps/s
Avg test loss: 6.72608, Avg test acc: 0.13634, Avg tpr: 0.52773, Avg fpr: 0.87078, total FA: 120906

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=9.32568 | acc=0.1127 | tpr=0.6504 | fpr=0.8970 | 4723.4 samples/s | 18.5 steps/s
[Step= 100] | Loss=9.27164 | acc=0.1129 | tpr=0.6226 | fpr=0.8967 | 7143.7 samples/s | 27.9 steps/s
[Step= 150] | Loss=9.28907 | acc=0.1119 | tpr=0.6210 | fpr=0.8975 | 7891.8 samples/s | 30.8 steps/s
[Step= 200] | Loss=9.27819 | acc=0.1123 | tpr=0.6153 | fpr=0.8968 | 7809.9 samples/s | 30.5 steps/s
[Step= 250] | Loss=9.26473 | acc=0.1123 | tpr=0.6148 | fpr=0.8968 | 7771.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=9.26633 | acc=0.1122 | tpr=0.6065 | fpr=0.8968 | 7811.1 samples/s | 30.5 steps/s
[Step= 350] | Loss=9.27354 | acc=0.1122 | tpr=0.5992 | fpr=0.8966 | 7565.0 samples/s | 29.6 steps/s
[Step= 400] | Loss=9.27271 | acc=0.1120 | tpr=0.5990 | fpr=0.8968 | 8024.6 samples/s | 31.3 steps/s
[Step= 450] | Loss=9.28254 | acc=0.1119 | tpr=0.6022 | fpr=0.8970 | 7655.5 samples/s | 29.9 steps/s
[Step= 500] | Loss=9.28358 | acc=0.1122 | tpr=0.6031 | fpr=0.8967 | 7635.3 samples/s | 29.8 steps/s
[Step= 550] | Loss=9.29073 | acc=0.1120 | tpr=0.5973 | fpr=0.8968 | 13926.7 samples/s | 54.4 steps/s
Avg test loss: 9.29347, Avg test acc: 0.11190, Avg tpr: 0.59786, Avg fpr: 0.89694, total FA: 124538

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13118 | acc=0.9793 | tpr=0.9204 | fpr=0.0196 | 4905.8 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13497 | acc=0.9789 | tpr=0.9360 | fpr=0.0203 | 6992.6 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.13957 | acc=0.9780 | tpr=0.9352 | fpr=0.0212 | 7820.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.14210 | acc=0.9781 | tpr=0.9377 | fpr=0.0212 | 7974.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.13925 | acc=0.9784 | tpr=0.9354 | fpr=0.0208 | 7683.7 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.14129 | acc=0.9782 | tpr=0.9338 | fpr=0.0210 | 7867.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.14176 | acc=0.9782 | tpr=0.9343 | fpr=0.0210 | 7598.2 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.14283 | acc=0.9781 | tpr=0.9316 | fpr=0.0210 | 7996.3 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.14548 | acc=0.9778 | tpr=0.9309 | fpr=0.0213 | 7567.2 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.14448 | acc=0.9780 | tpr=0.9330 | fpr=0.0212 | 7899.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.14336 | acc=0.9782 | tpr=0.9331 | fpr=0.0210 | 13702.7 samples/s | 53.5 steps/s
Avg test loss: 0.14306, Avg test acc: 0.97819, Avg tpr: 0.93304, Avg fpr: 0.02099, total FA: 2914

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14953 | acc=0.9768 | tpr=0.9469 | fpr=0.0227 | 5045.3 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.14920 | acc=0.9772 | tpr=0.9595 | fpr=0.0225 | 6781.9 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.15690 | acc=0.9762 | tpr=0.9597 | fpr=0.0235 | 7735.7 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.15994 | acc=0.9761 | tpr=0.9596 | fpr=0.0236 | 8123.4 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.15735 | acc=0.9766 | tpr=0.9581 | fpr=0.0230 | 7771.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.16049 | acc=0.9761 | tpr=0.9542 | fpr=0.0235 | 7787.2 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.16057 | acc=0.9761 | tpr=0.9549 | fpr=0.0235 | 7690.7 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.16177 | acc=0.9762 | tpr=0.9530 | fpr=0.0234 | 7642.7 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.16475 | acc=0.9757 | tpr=0.9523 | fpr=0.0239 | 7681.4 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.16361 | acc=0.9758 | tpr=0.9520 | fpr=0.0237 | 8040.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.16209 | acc=0.9762 | tpr=0.9526 | fpr=0.0234 | 13532.8 samples/s | 52.9 steps/s
Avg test loss: 0.16202, Avg test acc: 0.97621, Avg tpr: 0.95246, Avg fpr: 0.02336, total FA: 3243

server round 14/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=54.6] | Loss=0.00660 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.014 | L2-Norm(final)=6.626 | 6653.8 samples/s | 104.0 steps/s
[Step=28050 Epoch=54.7] | Loss=0.00777 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.010 | L2-Norm(final)=6.636 | 4613.5 samples/s | 72.1 steps/s
[Step=28100 Epoch=54.8] | Loss=0.00820 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.007 | L2-Norm(final)=6.647 | 4859.0 samples/s | 75.9 steps/s
[Step=28150 Epoch=54.9] | Loss=0.00891 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.005 | L2-Norm(final)=6.658 | 5067.6 samples/s | 79.2 steps/s
[Step=28200 Epoch=55.0] | Loss=0.00855 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.003 | L2-Norm(final)=6.668 | 5087.8 samples/s | 79.5 steps/s
[Step=28250 Epoch=55.1] | Loss=0.00895 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.001 | L2-Norm(final)=6.679 | 4910.4 samples/s | 76.7 steps/s
[Step=28300 Epoch=55.2] | Loss=0.00917 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.999 | L2-Norm(final)=6.687 | 4872.4 samples/s | 76.1 steps/s
[Step=28350 Epoch=55.3] | Loss=0.00909 | Reg=0.00441 | acc=0.9688 | L2-Norm=20.997 | L2-Norm(final)=6.696 | 5172.4 samples/s | 80.8 steps/s
[Step=28400 Epoch=55.4] | Loss=0.00882 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.995 | L2-Norm(final)=6.705 | 5035.5 samples/s | 78.7 steps/s
[Step=28450 Epoch=55.5] | Loss=0.00853 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.992 | L2-Norm(final)=6.715 | 4815.6 samples/s | 75.2 steps/s
[Step=28500 Epoch=55.6] | Loss=0.00861 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.989 | L2-Norm(final)=6.724 | 6583.4 samples/s | 102.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=55.6] | Loss=0.00798 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.959 | L2-Norm(final)=6.811 | 6325.2 samples/s | 98.8 steps/s
[Step=28550 Epoch=55.7] | Loss=0.00954 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.955 | L2-Norm(final)=6.817 | 4047.3 samples/s | 63.2 steps/s
[Step=28600 Epoch=55.8] | Loss=0.01127 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.956 | L2-Norm(final)=6.818 | 4415.5 samples/s | 69.0 steps/s
[Step=28650 Epoch=55.9] | Loss=0.01377 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.964 | L2-Norm(final)=6.817 | 4404.7 samples/s | 68.8 steps/s
[Step=28700 Epoch=56.0] | Loss=0.01363 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.973 | L2-Norm(final)=6.819 | 4460.9 samples/s | 69.7 steps/s
[Step=28750 Epoch=56.1] | Loss=0.01386 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.982 | L2-Norm(final)=6.821 | 4398.7 samples/s | 68.7 steps/s
[Step=28800 Epoch=56.2] | Loss=0.01347 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.990 | L2-Norm(final)=6.825 | 4460.8 samples/s | 69.7 steps/s
[Step=28850 Epoch=56.3] | Loss=0.01340 | Reg=0.00441 | acc=0.9688 | L2-Norm=20.996 | L2-Norm(final)=6.828 | 4420.4 samples/s | 69.1 steps/s
[Step=28900 Epoch=56.4] | Loss=0.01367 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.002 | L2-Norm(final)=6.831 | 4376.7 samples/s | 68.4 steps/s
[Step=28950 Epoch=56.5] | Loss=0.01394 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.008 | L2-Norm(final)=6.834 | 4495.9 samples/s | 70.2 steps/s
[Step=29000 Epoch=56.6] | Loss=0.01421 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.014 | L2-Norm(final)=6.837 | 5745.2 samples/s | 89.8 steps/s
[Step=29050 Epoch=56.7] | Loss=0.01427 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.020 | L2-Norm(final)=6.839 | 2377.7 samples/s | 37.2 steps/s
[Step=29100 Epoch=56.8] | Loss=0.01396 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.025 | L2-Norm(final)=6.842 | 4433.8 samples/s | 69.3 steps/s
[Step=29150 Epoch=56.9] | Loss=0.01387 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.029 | L2-Norm(final)=6.845 | 4439.8 samples/s | 69.4 steps/s
[Step=29200 Epoch=57.0] | Loss=0.01380 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.033 | L2-Norm(final)=6.848 | 4431.5 samples/s | 69.2 steps/s
[Step=29250 Epoch=57.0] | Loss=0.01344 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.036 | L2-Norm(final)=6.851 | 4362.2 samples/s | 68.2 steps/s
[Step=29300 Epoch=57.1] | Loss=0.01324 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.038 | L2-Norm(final)=6.854 | 4423.2 samples/s | 69.1 steps/s
[Step=29350 Epoch=57.2] | Loss=0.01324 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.041 | L2-Norm(final)=6.856 | 4561.5 samples/s | 71.3 steps/s
[Step=29400 Epoch=57.3] | Loss=0.01309 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.043 | L2-Norm(final)=6.859 | 4324.9 samples/s | 67.6 steps/s
[Step=29450 Epoch=57.4] | Loss=0.01289 | Reg=0.00443 | acc=0.9688 | L2-Norm=21.044 | L2-Norm(final)=6.862 | 4515.3 samples/s | 70.6 steps/s
[Step=29500 Epoch=57.5] | Loss=0.01290 | Reg=0.00443 | acc=0.9688 | L2-Norm=21.045 | L2-Norm(final)=6.865 | 4712.7 samples/s | 73.6 steps/s
[Step=29550 Epoch=57.6] | Loss=0.01272 | Reg=0.00443 | acc=0.9688 | L2-Norm=21.046 | L2-Norm(final)=6.868 | 2578.9 samples/s | 40.3 steps/s
[Step=29600 Epoch=57.7] | Loss=0.01262 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.047 | L2-Norm(final)=6.870 | 4499.3 samples/s | 70.3 steps/s
[Step=29650 Epoch=57.8] | Loss=0.01252 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.047 | L2-Norm(final)=6.873 | 4326.9 samples/s | 67.6 steps/s
[Step=29700 Epoch=57.9] | Loss=0.01239 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.047 | L2-Norm(final)=6.875 | 4393.6 samples/s | 68.7 steps/s
[Step=29750 Epoch=58.0] | Loss=0.01231 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.047 | L2-Norm(final)=6.877 | 4442.6 samples/s | 69.4 steps/s
[Step=29800 Epoch=58.1] | Loss=0.01223 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.047 | L2-Norm(final)=6.880 | 4444.6 samples/s | 69.4 steps/s
[Step=29850 Epoch=58.2] | Loss=0.01226 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.047 | L2-Norm(final)=6.882 | 4420.2 samples/s | 69.1 steps/s
[Step=29900 Epoch=58.3] | Loss=0.01214 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.047 | L2-Norm(final)=6.884 | 4417.5 samples/s | 69.0 steps/s
[Step=29950 Epoch=58.4] | Loss=0.01208 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.046 | L2-Norm(final)=6.886 | 4472.7 samples/s | 69.9 steps/s
[Step=30000 Epoch=58.5] | Loss=0.01206 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.046 | L2-Norm(final)=6.888 | 4412.8 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step30000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=54.7] | Loss=0.01003 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.989 | L2-Norm(final)=6.652 | 6356.8 samples/s | 99.3 steps/s
[Step=28050 Epoch=54.8] | Loss=0.00988 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.987 | L2-Norm(final)=6.660 | 4394.0 samples/s | 68.7 steps/s
[Step=28100 Epoch=54.9] | Loss=0.01042 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.987 | L2-Norm(final)=6.668 | 5035.4 samples/s | 78.7 steps/s
[Step=28150 Epoch=55.0] | Loss=0.00974 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.986 | L2-Norm(final)=6.676 | 4885.8 samples/s | 76.3 steps/s
[Step=28200 Epoch=55.1] | Loss=0.00968 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.985 | L2-Norm(final)=6.686 | 5009.9 samples/s | 78.3 steps/s
[Step=28250 Epoch=55.2] | Loss=0.00927 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.984 | L2-Norm(final)=6.697 | 5184.5 samples/s | 81.0 steps/s
[Step=28300 Epoch=55.3] | Loss=0.00906 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.982 | L2-Norm(final)=6.708 | 4781.5 samples/s | 74.7 steps/s
[Step=28350 Epoch=55.4] | Loss=0.00898 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.981 | L2-Norm(final)=6.719 | 5012.8 samples/s | 78.3 steps/s
[Step=28400 Epoch=55.5] | Loss=0.00914 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.979 | L2-Norm(final)=6.730 | 5115.5 samples/s | 79.9 steps/s
[Step=28450 Epoch=55.6] | Loss=0.00911 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.979 | L2-Norm(final)=6.740 | 4882.8 samples/s | 76.3 steps/s
[Step=28500 Epoch=55.7] | Loss=0.00893 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.978 | L2-Norm(final)=6.751 | 6695.7 samples/s | 104.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=55.7] | Loss=0.00259 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.966 | L2-Norm(final)=6.849 | 6957.1 samples/s | 108.7 steps/s
[Step=28550 Epoch=55.8] | Loss=0.00792 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.964 | L2-Norm(final)=6.856 | 4040.4 samples/s | 63.1 steps/s
[Step=28600 Epoch=55.9] | Loss=0.00909 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.964 | L2-Norm(final)=6.860 | 4317.6 samples/s | 67.5 steps/s
[Step=28650 Epoch=56.0] | Loss=0.00995 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.964 | L2-Norm(final)=6.865 | 4582.5 samples/s | 71.6 steps/s
[Step=28700 Epoch=56.1] | Loss=0.01043 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.966 | L2-Norm(final)=6.869 | 4348.4 samples/s | 67.9 steps/s
[Step=28750 Epoch=56.2] | Loss=0.01144 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.971 | L2-Norm(final)=6.873 | 4387.3 samples/s | 68.6 steps/s
[Step=28800 Epoch=56.3] | Loss=0.01251 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.981 | L2-Norm(final)=6.876 | 4430.1 samples/s | 69.2 steps/s
[Step=28850 Epoch=56.4] | Loss=0.01290 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.992 | L2-Norm(final)=6.879 | 4456.9 samples/s | 69.6 steps/s
[Step=28900 Epoch=56.5] | Loss=0.01339 | Reg=0.00441 | acc=0.9688 | L2-Norm=21.002 | L2-Norm(final)=6.883 | 4363.5 samples/s | 68.2 steps/s
[Step=28950 Epoch=56.6] | Loss=0.01391 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.012 | L2-Norm(final)=6.886 | 4410.0 samples/s | 68.9 steps/s
[Step=29000 Epoch=56.7] | Loss=0.01440 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.022 | L2-Norm(final)=6.888 | 5881.7 samples/s | 91.9 steps/s
[Step=29050 Epoch=56.8] | Loss=0.01422 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.032 | L2-Norm(final)=6.890 | 2377.3 samples/s | 37.1 steps/s
[Step=29100 Epoch=56.9] | Loss=0.01398 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.040 | L2-Norm(final)=6.893 | 4315.7 samples/s | 67.4 steps/s
[Step=29150 Epoch=57.0] | Loss=0.01384 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.047 | L2-Norm(final)=6.895 | 4457.2 samples/s | 69.6 steps/s
[Step=29200 Epoch=57.1] | Loss=0.01373 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.054 | L2-Norm(final)=6.898 | 4455.8 samples/s | 69.6 steps/s
[Step=29250 Epoch=57.2] | Loss=0.01376 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.060 | L2-Norm(final)=6.901 | 4344.2 samples/s | 67.9 steps/s
[Step=29300 Epoch=57.3] | Loss=0.01386 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.066 | L2-Norm(final)=6.903 | 4391.9 samples/s | 68.6 steps/s
[Step=29350 Epoch=57.4] | Loss=0.01396 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.071 | L2-Norm(final)=6.905 | 4445.0 samples/s | 69.5 steps/s
[Step=29400 Epoch=57.5] | Loss=0.01398 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.077 | L2-Norm(final)=6.907 | 4431.5 samples/s | 69.2 steps/s
[Step=29450 Epoch=57.6] | Loss=0.01392 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.081 | L2-Norm(final)=6.909 | 4446.7 samples/s | 69.5 steps/s
[Step=29500 Epoch=57.7] | Loss=0.01388 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.085 | L2-Norm(final)=6.910 | 4941.1 samples/s | 77.2 steps/s
[Step=29550 Epoch=57.8] | Loss=0.01367 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.089 | L2-Norm(final)=6.912 | 2585.0 samples/s | 40.4 steps/s
[Step=29600 Epoch=57.9] | Loss=0.01340 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.092 | L2-Norm(final)=6.915 | 4438.3 samples/s | 69.3 steps/s
[Step=29650 Epoch=58.0] | Loss=0.01336 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.094 | L2-Norm(final)=6.917 | 4326.0 samples/s | 67.6 steps/s
[Step=29700 Epoch=58.1] | Loss=0.01317 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.096 | L2-Norm(final)=6.919 | 4293.4 samples/s | 67.1 steps/s
[Step=29750 Epoch=58.2] | Loss=0.01304 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.098 | L2-Norm(final)=6.921 | 4455.4 samples/s | 69.6 steps/s
[Step=29800 Epoch=58.3] | Loss=0.01295 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.099 | L2-Norm(final)=6.923 | 4558.9 samples/s | 71.2 steps/s
[Step=29850 Epoch=58.4] | Loss=0.01293 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.100 | L2-Norm(final)=6.925 | 4332.1 samples/s | 67.7 steps/s
[Step=29900 Epoch=58.5] | Loss=0.01278 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.100 | L2-Norm(final)=6.927 | 4453.9 samples/s | 69.6 steps/s
[Step=29950 Epoch=58.6] | Loss=0.01278 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.100 | L2-Norm(final)=6.929 | 4479.7 samples/s | 70.0 steps/s
[Step=30000 Epoch=58.6] | Loss=0.01274 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.101 | L2-Norm(final)=6.931 | 4387.7 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step30000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=107.3] | Loss=0.00064 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.778 | 5753.0 samples/s | 89.9 steps/s
[Step=28050 Epoch=107.5] | Loss=0.00023 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.784 | 4337.3 samples/s | 67.8 steps/s
[Step=28100 Epoch=107.7] | Loss=0.00014 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.788 | 4728.3 samples/s | 73.9 steps/s
[Step=28150 Epoch=107.9] | Loss=0.00016 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.792 | 4621.1 samples/s | 72.2 steps/s
[Step=28200 Epoch=108.1] | Loss=0.00015 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.795 | 4733.2 samples/s | 74.0 steps/s
[Step=28250 Epoch=108.2] | Loss=0.00014 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.823 | L2-Norm(final)=4.799 | 6677.7 samples/s | 104.3 steps/s
[Step=28300 Epoch=108.4] | Loss=0.00012 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.823 | L2-Norm(final)=4.803 | 2392.8 samples/s | 37.4 steps/s
[Step=28350 Epoch=108.6] | Loss=0.00011 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.823 | L2-Norm(final)=4.806 | 4644.6 samples/s | 72.6 steps/s
[Step=28400 Epoch=108.8] | Loss=0.00010 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=4.809 | 4777.8 samples/s | 74.7 steps/s
[Step=28450 Epoch=109.0] | Loss=0.00010 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.821 | L2-Norm(final)=4.812 | 4584.7 samples/s | 71.6 steps/s
[Step=28500 Epoch=109.2] | Loss=0.00009 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.821 | L2-Norm(final)=4.815 | 5368.3 samples/s | 83.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=109.2] | Loss=0.00006 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.811 | L2-Norm(final)=4.844 | 6309.5 samples/s | 98.6 steps/s
[Step=28550 Epoch=109.4] | Loss=0.00002 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.805 | L2-Norm(final)=4.846 | 3658.7 samples/s | 57.2 steps/s
[Step=28600 Epoch=109.6] | Loss=0.00002 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.795 | L2-Norm(final)=4.847 | 4318.3 samples/s | 67.5 steps/s
[Step=28650 Epoch=109.8] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.785 | L2-Norm(final)=4.849 | 4181.5 samples/s | 65.3 steps/s
[Step=28700 Epoch=110.0] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.776 | L2-Norm(final)=4.850 | 4143.0 samples/s | 64.7 steps/s
[Step=28750 Epoch=110.2] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.766 | L2-Norm(final)=4.852 | 5678.2 samples/s | 88.7 steps/s
[Step=28800 Epoch=110.4] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.756 | L2-Norm(final)=4.853 | 2253.4 samples/s | 35.2 steps/s
[Step=28850 Epoch=110.5] | Loss=0.00002 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.746 | L2-Norm(final)=4.855 | 4197.0 samples/s | 65.6 steps/s
[Step=28900 Epoch=110.7] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.735 | L2-Norm(final)=4.856 | 4222.0 samples/s | 66.0 steps/s
[Step=28950 Epoch=110.9] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.725 | L2-Norm(final)=4.857 | 4198.3 samples/s | 65.6 steps/s
[Step=29000 Epoch=111.1] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.714 | L2-Norm(final)=4.858 | 4655.5 samples/s | 72.7 steps/s
[Step=29050 Epoch=111.3] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.703 | L2-Norm(final)=4.859 | 2470.1 samples/s | 38.6 steps/s
[Step=29100 Epoch=111.5] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.692 | L2-Norm(final)=4.860 | 4030.8 samples/s | 63.0 steps/s
[Step=29150 Epoch=111.7] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.681 | L2-Norm(final)=4.860 | 4201.9 samples/s | 65.7 steps/s
[Step=29200 Epoch=111.9] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.670 | L2-Norm(final)=4.861 | 4199.0 samples/s | 65.6 steps/s
[Step=29250 Epoch=112.1] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.659 | L2-Norm(final)=4.862 | 4223.2 samples/s | 66.0 steps/s
[Step=29300 Epoch=112.3] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.647 | L2-Norm(final)=4.863 | 2614.7 samples/s | 40.9 steps/s
[Step=29350 Epoch=112.5] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.636 | L2-Norm(final)=4.863 | 4243.5 samples/s | 66.3 steps/s
[Step=29400 Epoch=112.7] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.624 | L2-Norm(final)=4.864 | 4239.5 samples/s | 66.2 steps/s
[Step=29450 Epoch=112.8] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.612 | L2-Norm(final)=4.865 | 4088.6 samples/s | 63.9 steps/s
[Step=29500 Epoch=113.0] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.600 | L2-Norm(final)=4.865 | 4191.2 samples/s | 65.5 steps/s
[Step=29550 Epoch=113.2] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.588 | L2-Norm(final)=4.866 | 2619.2 samples/s | 40.9 steps/s
[Step=29600 Epoch=113.4] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=4.867 | 4170.8 samples/s | 65.2 steps/s
[Step=29650 Epoch=113.6] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.563 | L2-Norm(final)=4.868 | 4152.9 samples/s | 64.9 steps/s
[Step=29700 Epoch=113.8] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.551 | L2-Norm(final)=4.868 | 4233.9 samples/s | 66.2 steps/s
[Step=29750 Epoch=114.0] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.538 | L2-Norm(final)=4.869 | 4227.8 samples/s | 66.1 steps/s
[Step=29800 Epoch=114.2] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.525 | L2-Norm(final)=4.869 | 6171.2 samples/s | 96.4 steps/s
[Step=29850 Epoch=114.4] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.513 | L2-Norm(final)=4.870 | 2141.5 samples/s | 33.5 steps/s
[Step=29900 Epoch=114.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.500 | L2-Norm(final)=4.871 | 4217.2 samples/s | 65.9 steps/s
[Step=29950 Epoch=114.8] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.486 | L2-Norm(final)=4.871 | 4164.5 samples/s | 65.1 steps/s
[Step=30000 Epoch=114.9] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.473 | L2-Norm(final)=4.872 | 4183.3 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step30000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=107.8] | Loss=0.00036 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.888 | L2-Norm(final)=5.254 | 6765.4 samples/s | 105.7 steps/s
[Step=28050 Epoch=108.0] | Loss=0.00008 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.883 | L2-Norm(final)=5.259 | 3855.3 samples/s | 60.2 steps/s
[Step=28100 Epoch=108.2] | Loss=0.00017 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.884 | L2-Norm(final)=5.265 | 4703.1 samples/s | 73.5 steps/s
[Step=28150 Epoch=108.4] | Loss=0.00013 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=5.269 | 4730.8 samples/s | 73.9 steps/s
[Step=28200 Epoch=108.6] | Loss=0.00012 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.892 | L2-Norm(final)=5.274 | 4591.9 samples/s | 71.7 steps/s
[Step=28250 Epoch=108.7] | Loss=0.00010 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.892 | L2-Norm(final)=5.279 | 6740.1 samples/s | 105.3 steps/s
[Step=28300 Epoch=108.9] | Loss=0.00009 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.892 | L2-Norm(final)=5.283 | 2389.8 samples/s | 37.3 steps/s
[Step=28350 Epoch=109.1] | Loss=0.00008 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.891 | L2-Norm(final)=5.287 | 4637.9 samples/s | 72.5 steps/s
[Step=28400 Epoch=109.3] | Loss=0.00007 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=5.291 | 4978.9 samples/s | 77.8 steps/s
[Step=28450 Epoch=109.5] | Loss=0.00007 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.888 | L2-Norm(final)=5.295 | 4465.6 samples/s | 69.8 steps/s
[Step=28500 Epoch=109.7] | Loss=0.00006 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.886 | L2-Norm(final)=5.298 | 5639.6 samples/s | 88.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=109.7] | Loss=0.00002 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.865 | L2-Norm(final)=5.333 | 6505.0 samples/s | 101.6 steps/s
[Step=28550 Epoch=109.9] | Loss=0.00002 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.850 | L2-Norm(final)=5.336 | 3590.4 samples/s | 56.1 steps/s
[Step=28600 Epoch=110.1] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.830 | L2-Norm(final)=5.338 | 4117.9 samples/s | 64.3 steps/s
[Step=28650 Epoch=110.3] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.809 | L2-Norm(final)=5.340 | 4162.3 samples/s | 65.0 steps/s
[Step=28700 Epoch=110.5] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.789 | L2-Norm(final)=5.341 | 4244.6 samples/s | 66.3 steps/s
[Step=28750 Epoch=110.7] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.768 | L2-Norm(final)=5.343 | 5754.0 samples/s | 89.9 steps/s
[Step=28800 Epoch=110.9] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.747 | L2-Norm(final)=5.345 | 2256.9 samples/s | 35.3 steps/s
[Step=28850 Epoch=111.1] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.726 | L2-Norm(final)=5.346 | 4279.9 samples/s | 66.9 steps/s
[Step=28900 Epoch=111.2] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.705 | L2-Norm(final)=5.347 | 4182.4 samples/s | 65.4 steps/s
[Step=28950 Epoch=111.4] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.684 | L2-Norm(final)=5.348 | 4081.7 samples/s | 63.8 steps/s
[Step=29000 Epoch=111.6] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.663 | L2-Norm(final)=5.350 | 4905.4 samples/s | 76.6 steps/s
[Step=29050 Epoch=111.8] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.642 | L2-Norm(final)=5.351 | 2366.4 samples/s | 37.0 steps/s
[Step=29100 Epoch=112.0] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.620 | L2-Norm(final)=5.351 | 4220.1 samples/s | 65.9 steps/s
[Step=29150 Epoch=112.2] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.599 | L2-Norm(final)=5.352 | 4236.9 samples/s | 66.2 steps/s
[Step=29200 Epoch=112.4] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.577 | L2-Norm(final)=5.353 | 4129.9 samples/s | 64.5 steps/s
[Step=29250 Epoch=112.6] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.556 | L2-Norm(final)=5.354 | 4311.2 samples/s | 67.4 steps/s
[Step=29300 Epoch=112.8] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.534 | L2-Norm(final)=5.355 | 2544.4 samples/s | 39.8 steps/s
[Step=29350 Epoch=113.0] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.512 | L2-Norm(final)=5.356 | 4273.1 samples/s | 66.8 steps/s
[Step=29400 Epoch=113.2] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.490 | L2-Norm(final)=5.356 | 4195.2 samples/s | 65.6 steps/s
[Step=29450 Epoch=113.4] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.468 | L2-Norm(final)=5.357 | 4172.4 samples/s | 65.2 steps/s
[Step=29500 Epoch=113.6] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.445 | L2-Norm(final)=5.358 | 4155.3 samples/s | 64.9 steps/s
[Step=29550 Epoch=113.7] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.423 | L2-Norm(final)=5.359 | 2640.7 samples/s | 41.3 steps/s
[Step=29600 Epoch=113.9] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.400 | L2-Norm(final)=5.360 | 4087.1 samples/s | 63.9 steps/s
[Step=29650 Epoch=114.1] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.378 | L2-Norm(final)=5.360 | 4168.7 samples/s | 65.1 steps/s
[Step=29700 Epoch=114.3] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.355 | L2-Norm(final)=5.361 | 4315.6 samples/s | 67.4 steps/s
[Step=29750 Epoch=114.5] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.332 | L2-Norm(final)=5.362 | 4131.0 samples/s | 64.5 steps/s
[Step=29800 Epoch=114.7] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.309 | L2-Norm(final)=5.363 | 6959.3 samples/s | 108.7 steps/s
[Step=29850 Epoch=114.9] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.286 | L2-Norm(final)=5.364 | 2111.4 samples/s | 33.0 steps/s
[Step=29900 Epoch=115.1] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.263 | L2-Norm(final)=5.365 | 4168.6 samples/s | 65.1 steps/s
[Step=29950 Epoch=115.3] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.239 | L2-Norm(final)=5.365 | 4200.8 samples/s | 65.6 steps/s
[Step=30000 Epoch=115.5] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.216 | L2-Norm(final)=5.366 | 4150.3 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08196 | acc=0.9658 | tpr=0.9790 | fpr=0.0629 | 4937.4 samples/s | 19.3 steps/s
Avg test loss: 0.07995, Avg test acc: 0.96634, Avg tpr: 0.97931, Avg fpr: 0.06217, total FA: 485

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07431 | acc=0.9660 | tpr=0.9744 | fpr=0.0523 | 4917.7 samples/s | 19.2 steps/s
Avg test loss: 0.07557, Avg test acc: 0.96570, Avg tpr: 0.97424, Avg fpr: 0.05307, total FA: 414

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.47941 | acc=0.3003 | tpr=0.0208 | fpr=0.0927 | 5002.9 samples/s | 19.5 steps/s
Avg test loss: 5.47735, Avg test acc: 0.29802, Avg tpr: 0.02174, Avg fpr: 0.09435, total FA: 736

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.18438 | acc=0.3154 | tpr=0.0310 | fpr=0.0671 | 4795.1 samples/s | 18.7 steps/s
Avg test loss: 6.16542, Avg test acc: 0.31445, Avg tpr: 0.03375, Avg fpr: 0.06820, total FA: 532

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.43414 | acc=0.1065 | tpr=0.5575 | fpr=0.9016 | 5159.9 samples/s | 20.2 steps/s
[Step= 100] | Loss=7.38227 | acc=0.1057 | tpr=0.5394 | fpr=0.9024 | 6646.2 samples/s | 26.0 steps/s
[Step= 150] | Loss=7.39042 | acc=0.1056 | tpr=0.5346 | fpr=0.9023 | 7623.6 samples/s | 29.8 steps/s
[Step= 200] | Loss=7.38090 | acc=0.1055 | tpr=0.5301 | fpr=0.9022 | 8098.4 samples/s | 31.6 steps/s
[Step= 250] | Loss=7.37027 | acc=0.1062 | tpr=0.5476 | fpr=0.9018 | 7665.3 samples/s | 29.9 steps/s
[Step= 300] | Loss=7.36245 | acc=0.1061 | tpr=0.5418 | fpr=0.9018 | 7720.0 samples/s | 30.2 steps/s
[Step= 350] | Loss=7.36776 | acc=0.1059 | tpr=0.5354 | fpr=0.9019 | 8029.8 samples/s | 31.4 steps/s
[Step= 400] | Loss=7.37279 | acc=0.1054 | tpr=0.5312 | fpr=0.9023 | 7666.8 samples/s | 29.9 steps/s
[Step= 450] | Loss=7.38015 | acc=0.1053 | tpr=0.5375 | fpr=0.9026 | 7751.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=7.38061 | acc=0.1054 | tpr=0.5392 | fpr=0.9024 | 7787.3 samples/s | 30.4 steps/s
[Step= 550] | Loss=7.38525 | acc=0.1053 | tpr=0.5436 | fpr=0.9027 | 13969.0 samples/s | 54.6 steps/s
Avg test loss: 7.38805, Avg test acc: 0.10525, Avg tpr: 0.54477, Avg fpr: 0.90274, total FA: 125344

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.00444 | acc=0.1148 | tpr=0.6018 | fpr=0.8940 | 4994.4 samples/s | 19.5 steps/s
[Step= 100] | Loss=7.97006 | acc=0.1132 | tpr=0.5416 | fpr=0.8948 | 7066.2 samples/s | 27.6 steps/s
[Step= 150] | Loss=7.97982 | acc=0.1128 | tpr=0.5259 | fpr=0.8948 | 7799.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=7.96759 | acc=0.1134 | tpr=0.5224 | fpr=0.8940 | 7779.8 samples/s | 30.4 steps/s
[Step= 250] | Loss=7.95734 | acc=0.1137 | tpr=0.5275 | fpr=0.8938 | 7955.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=7.95509 | acc=0.1141 | tpr=0.5222 | fpr=0.8933 | 7791.2 samples/s | 30.4 steps/s
[Step= 350] | Loss=7.96249 | acc=0.1142 | tpr=0.5147 | fpr=0.8931 | 7687.9 samples/s | 30.0 steps/s
[Step= 400] | Loss=7.96562 | acc=0.1137 | tpr=0.5098 | fpr=0.8935 | 7740.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=7.97477 | acc=0.1137 | tpr=0.5146 | fpr=0.8936 | 8040.1 samples/s | 31.4 steps/s
[Step= 500] | Loss=7.97294 | acc=0.1139 | tpr=0.5141 | fpr=0.8934 | 7699.7 samples/s | 30.1 steps/s
[Step= 550] | Loss=7.97926 | acc=0.1138 | tpr=0.5141 | fpr=0.8934 | 13667.5 samples/s | 53.4 steps/s
Avg test loss: 7.98206, Avg test acc: 0.11376, Avg tpr: 0.51347, Avg fpr: 0.89351, total FA: 124062

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13700 | acc=0.9788 | tpr=0.9336 | fpr=0.0204 | 4927.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13889 | acc=0.9793 | tpr=0.9467 | fpr=0.0201 | 7042.3 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.14522 | acc=0.9780 | tpr=0.9467 | fpr=0.0214 | 7874.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.14855 | acc=0.9778 | tpr=0.9464 | fpr=0.0217 | 7782.7 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.14587 | acc=0.9782 | tpr=0.9459 | fpr=0.0212 | 7647.0 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.14758 | acc=0.9779 | tpr=0.9418 | fpr=0.0215 | 7885.4 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.14833 | acc=0.9778 | tpr=0.9436 | fpr=0.0216 | 7816.3 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.14980 | acc=0.9777 | tpr=0.9398 | fpr=0.0217 | 7638.9 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.15254 | acc=0.9773 | tpr=0.9391 | fpr=0.0220 | 8075.9 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.15136 | acc=0.9775 | tpr=0.9396 | fpr=0.0218 | 7940.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.14975 | acc=0.9778 | tpr=0.9411 | fpr=0.0215 | 13404.2 samples/s | 52.4 steps/s
Avg test loss: 0.14957, Avg test acc: 0.97780, Avg tpr: 0.94097, Avg fpr: 0.02153, total FA: 2990

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15612 | acc=0.9766 | tpr=0.9646 | fpr=0.0231 | 4969.8 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.15666 | acc=0.9767 | tpr=0.9701 | fpr=0.0232 | 7477.6 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.16431 | acc=0.9757 | tpr=0.9683 | fpr=0.0241 | 7120.0 samples/s | 27.8 steps/s
[Step= 200] | Loss=0.16748 | acc=0.9757 | tpr=0.9661 | fpr=0.0241 | 8141.5 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.16463 | acc=0.9760 | tpr=0.9624 | fpr=0.0237 | 7699.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.16777 | acc=0.9754 | tpr=0.9585 | fpr=0.0243 | 7906.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.16788 | acc=0.9754 | tpr=0.9593 | fpr=0.0243 | 7705.2 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.16899 | acc=0.9754 | tpr=0.9579 | fpr=0.0243 | 7842.3 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.17205 | acc=0.9749 | tpr=0.9567 | fpr=0.0248 | 7884.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.17110 | acc=0.9750 | tpr=0.9559 | fpr=0.0246 | 7932.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.16948 | acc=0.9754 | tpr=0.9562 | fpr=0.0242 | 13313.0 samples/s | 52.0 steps/s
Avg test loss: 0.16941, Avg test acc: 0.97545, Avg tpr: 0.95602, Avg fpr: 0.02420, total FA: 3360

server round 15/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=58.5] | Loss=0.00252 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.612 | L2-Norm(final)=6.949 | 6478.5 samples/s | 101.2 steps/s
[Step=30050 Epoch=58.6] | Loss=0.00701 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.608 | L2-Norm(final)=6.957 | 4395.8 samples/s | 68.7 steps/s
[Step=30100 Epoch=58.7] | Loss=0.00708 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.602 | L2-Norm(final)=6.966 | 5072.5 samples/s | 79.3 steps/s
[Step=30150 Epoch=58.8] | Loss=0.00722 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.598 | L2-Norm(final)=6.975 | 5209.9 samples/s | 81.4 steps/s
[Step=30200 Epoch=58.9] | Loss=0.00742 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.593 | L2-Norm(final)=6.981 | 4733.4 samples/s | 74.0 steps/s
[Step=30250 Epoch=59.0] | Loss=0.00725 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.587 | L2-Norm(final)=6.987 | 5009.4 samples/s | 78.3 steps/s
[Step=30300 Epoch=59.1] | Loss=0.00714 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.582 | L2-Norm(final)=6.993 | 5037.5 samples/s | 78.7 steps/s
[Step=30350 Epoch=59.2] | Loss=0.00747 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.577 | L2-Norm(final)=6.999 | 5033.4 samples/s | 78.6 steps/s
[Step=30400 Epoch=59.3] | Loss=0.00776 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.572 | L2-Norm(final)=7.003 | 5044.1 samples/s | 78.8 steps/s
[Step=30450 Epoch=59.4] | Loss=0.00768 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.567 | L2-Norm(final)=7.007 | 5029.4 samples/s | 78.6 steps/s
[Step=30500 Epoch=59.5] | Loss=0.00753 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.562 | L2-Norm(final)=7.012 | 6604.4 samples/s | 103.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=59.5] | Loss=0.00157 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.509 | L2-Norm(final)=7.062 | 6774.4 samples/s | 105.8 steps/s
[Step=30550 Epoch=59.6] | Loss=0.01028 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.514 | L2-Norm(final)=7.066 | 3890.1 samples/s | 60.8 steps/s
[Step=30600 Epoch=59.7] | Loss=0.01137 | Reg=0.00421 | acc=0.9844 | L2-Norm=20.523 | L2-Norm(final)=7.069 | 4475.4 samples/s | 69.9 steps/s
[Step=30650 Epoch=59.8] | Loss=0.01223 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.536 | L2-Norm(final)=7.070 | 4359.9 samples/s | 68.1 steps/s
[Step=30700 Epoch=59.9] | Loss=0.01339 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.552 | L2-Norm(final)=7.072 | 4457.4 samples/s | 69.6 steps/s
[Step=30750 Epoch=60.0] | Loss=0.01487 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.567 | L2-Norm(final)=7.074 | 4433.6 samples/s | 69.3 steps/s
[Step=30800 Epoch=60.1] | Loss=0.01500 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.581 | L2-Norm(final)=7.076 | 4521.1 samples/s | 70.6 steps/s
[Step=30850 Epoch=60.2] | Loss=0.01617 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.593 | L2-Norm(final)=7.077 | 4395.3 samples/s | 68.7 steps/s
[Step=30900 Epoch=60.3] | Loss=0.01600 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.603 | L2-Norm(final)=7.078 | 4403.6 samples/s | 68.8 steps/s
[Step=30950 Epoch=60.4] | Loss=0.01607 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.613 | L2-Norm(final)=7.079 | 4418.1 samples/s | 69.0 steps/s
[Step=31000 Epoch=60.5] | Loss=0.01602 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.621 | L2-Norm(final)=7.081 | 5732.2 samples/s | 89.6 steps/s
[Step=31050 Epoch=60.6] | Loss=0.01590 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.629 | L2-Norm(final)=7.083 | 2392.9 samples/s | 37.4 steps/s
[Step=31100 Epoch=60.7] | Loss=0.01563 | Reg=0.00426 | acc=0.9844 | L2-Norm=20.637 | L2-Norm(final)=7.085 | 4420.7 samples/s | 69.1 steps/s
[Step=31150 Epoch=60.8] | Loss=0.01517 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.644 | L2-Norm(final)=7.088 | 4526.9 samples/s | 70.7 steps/s
[Step=31200 Epoch=60.9] | Loss=0.01495 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.649 | L2-Norm(final)=7.091 | 4403.4 samples/s | 68.8 steps/s
[Step=31250 Epoch=60.9] | Loss=0.01505 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.654 | L2-Norm(final)=7.094 | 4435.1 samples/s | 69.3 steps/s
[Step=31300 Epoch=61.0] | Loss=0.01465 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.658 | L2-Norm(final)=7.096 | 4396.9 samples/s | 68.7 steps/s
[Step=31350 Epoch=61.1] | Loss=0.01438 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.661 | L2-Norm(final)=7.098 | 4417.7 samples/s | 69.0 steps/s
[Step=31400 Epoch=61.2] | Loss=0.01417 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.664 | L2-Norm(final)=7.100 | 4481.6 samples/s | 70.0 steps/s
[Step=31450 Epoch=61.3] | Loss=0.01396 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.667 | L2-Norm(final)=7.102 | 4452.1 samples/s | 69.6 steps/s
[Step=31500 Epoch=61.4] | Loss=0.01388 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.669 | L2-Norm(final)=7.105 | 4800.8 samples/s | 75.0 steps/s
[Step=31550 Epoch=61.5] | Loss=0.01374 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.671 | L2-Norm(final)=7.107 | 2632.9 samples/s | 41.1 steps/s
[Step=31600 Epoch=61.6] | Loss=0.01347 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.673 | L2-Norm(final)=7.109 | 4406.2 samples/s | 68.8 steps/s
[Step=31650 Epoch=61.7] | Loss=0.01343 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.674 | L2-Norm(final)=7.111 | 4427.0 samples/s | 69.2 steps/s
[Step=31700 Epoch=61.8] | Loss=0.01325 | Reg=0.00427 | acc=0.9688 | L2-Norm=20.675 | L2-Norm(final)=7.113 | 4385.1 samples/s | 68.5 steps/s
[Step=31750 Epoch=61.9] | Loss=0.01315 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.675 | L2-Norm(final)=7.115 | 4503.6 samples/s | 70.4 steps/s
[Step=31800 Epoch=62.0] | Loss=0.01304 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.675 | L2-Norm(final)=7.117 | 4409.5 samples/s | 68.9 steps/s
[Step=31850 Epoch=62.1] | Loss=0.01280 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.675 | L2-Norm(final)=7.119 | 4467.1 samples/s | 69.8 steps/s
[Step=31900 Epoch=62.2] | Loss=0.01263 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.675 | L2-Norm(final)=7.121 | 4433.4 samples/s | 69.3 steps/s
[Step=31950 Epoch=62.3] | Loss=0.01254 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.674 | L2-Norm(final)=7.122 | 4553.9 samples/s | 71.2 steps/s
[Step=32000 Epoch=62.4] | Loss=0.01245 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.673 | L2-Norm(final)=7.124 | 4376.3 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step32000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=58.7] | Loss=0.00199 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.647 | L2-Norm(final)=6.975 | 5761.7 samples/s | 90.0 steps/s
[Step=30050 Epoch=58.7] | Loss=0.00750 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.642 | L2-Norm(final)=6.986 | 4476.6 samples/s | 69.9 steps/s
[Step=30100 Epoch=58.8] | Loss=0.00743 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.637 | L2-Norm(final)=6.995 | 4913.7 samples/s | 76.8 steps/s
[Step=30150 Epoch=58.9] | Loss=0.00740 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.630 | L2-Norm(final)=7.003 | 5008.6 samples/s | 78.3 steps/s
[Step=30200 Epoch=59.0] | Loss=0.00709 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.624 | L2-Norm(final)=7.011 | 5084.4 samples/s | 79.4 steps/s
[Step=30250 Epoch=59.1] | Loss=0.00705 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.619 | L2-Norm(final)=7.019 | 4985.9 samples/s | 77.9 steps/s
[Step=30300 Epoch=59.2] | Loss=0.00708 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.614 | L2-Norm(final)=7.026 | 4986.6 samples/s | 77.9 steps/s
[Step=30350 Epoch=59.3] | Loss=0.00705 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.610 | L2-Norm(final)=7.034 | 5044.0 samples/s | 78.8 steps/s
[Step=30400 Epoch=59.4] | Loss=0.00713 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.605 | L2-Norm(final)=7.040 | 5035.4 samples/s | 78.7 steps/s
[Step=30450 Epoch=59.5] | Loss=0.00713 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.600 | L2-Norm(final)=7.046 | 5090.2 samples/s | 79.5 steps/s
[Step=30500 Epoch=59.6] | Loss=0.00713 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.596 | L2-Norm(final)=7.052 | 6589.6 samples/s | 103.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=59.6] | Loss=0.01216 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.546 | L2-Norm(final)=7.112 | 6576.6 samples/s | 102.8 steps/s
[Step=30550 Epoch=59.7] | Loss=0.00778 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.543 | L2-Norm(final)=7.117 | 3970.6 samples/s | 62.0 steps/s
[Step=30600 Epoch=59.8] | Loss=0.00941 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.544 | L2-Norm(final)=7.120 | 4503.4 samples/s | 70.4 steps/s
[Step=30650 Epoch=59.9] | Loss=0.00860 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.546 | L2-Norm(final)=7.124 | 4393.5 samples/s | 68.6 steps/s
[Step=30700 Epoch=60.0] | Loss=0.00928 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.547 | L2-Norm(final)=7.129 | 4478.5 samples/s | 70.0 steps/s
[Step=30750 Epoch=60.1] | Loss=0.00965 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.549 | L2-Norm(final)=7.132 | 4477.9 samples/s | 70.0 steps/s
[Step=30800 Epoch=60.2] | Loss=0.00982 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.552 | L2-Norm(final)=7.136 | 4505.8 samples/s | 70.4 steps/s
[Step=30850 Epoch=60.3] | Loss=0.01046 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.553 | L2-Norm(final)=7.139 | 4360.1 samples/s | 68.1 steps/s
[Step=30900 Epoch=60.4] | Loss=0.01092 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.554 | L2-Norm(final)=7.142 | 4451.8 samples/s | 69.6 steps/s
[Step=30950 Epoch=60.5] | Loss=0.01105 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.556 | L2-Norm(final)=7.144 | 4429.5 samples/s | 69.2 steps/s
[Step=31000 Epoch=60.6] | Loss=0.01140 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.557 | L2-Norm(final)=7.146 | 5875.5 samples/s | 91.8 steps/s
[Step=31050 Epoch=60.7] | Loss=0.01141 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.560 | L2-Norm(final)=7.147 | 2377.3 samples/s | 37.1 steps/s
[Step=31100 Epoch=60.8] | Loss=0.01106 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.562 | L2-Norm(final)=7.149 | 4483.3 samples/s | 70.1 steps/s
[Step=31150 Epoch=60.9] | Loss=0.01109 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.564 | L2-Norm(final)=7.152 | 4523.0 samples/s | 70.7 steps/s
[Step=31200 Epoch=61.0] | Loss=0.01109 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.566 | L2-Norm(final)=7.154 | 4392.0 samples/s | 68.6 steps/s
[Step=31250 Epoch=61.1] | Loss=0.01143 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.569 | L2-Norm(final)=7.156 | 4450.3 samples/s | 69.5 steps/s
[Step=31300 Epoch=61.2] | Loss=0.01161 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.572 | L2-Norm(final)=7.158 | 4356.7 samples/s | 68.1 steps/s
[Step=31350 Epoch=61.3] | Loss=0.01159 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.575 | L2-Norm(final)=7.160 | 4454.2 samples/s | 69.6 steps/s
[Step=31400 Epoch=61.4] | Loss=0.01166 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.579 | L2-Norm(final)=7.162 | 4543.3 samples/s | 71.0 steps/s
[Step=31450 Epoch=61.5] | Loss=0.01175 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.582 | L2-Norm(final)=7.164 | 4443.6 samples/s | 69.4 steps/s
[Step=31500 Epoch=61.6] | Loss=0.01196 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.586 | L2-Norm(final)=7.166 | 4890.7 samples/s | 76.4 steps/s
[Step=31550 Epoch=61.7] | Loss=0.01206 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.590 | L2-Norm(final)=7.169 | 2578.6 samples/s | 40.3 steps/s
[Step=31600 Epoch=61.8] | Loss=0.01198 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.595 | L2-Norm(final)=7.171 | 4529.6 samples/s | 70.8 steps/s
[Step=31650 Epoch=61.9] | Loss=0.01188 | Reg=0.00424 | acc=0.9688 | L2-Norm=20.599 | L2-Norm(final)=7.173 | 4312.5 samples/s | 67.4 steps/s
[Step=31700 Epoch=62.0] | Loss=0.01188 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.603 | L2-Norm(final)=7.175 | 4471.0 samples/s | 69.9 steps/s
[Step=31750 Epoch=62.1] | Loss=0.01189 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.607 | L2-Norm(final)=7.178 | 4389.8 samples/s | 68.6 steps/s
[Step=31800 Epoch=62.2] | Loss=0.01189 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.610 | L2-Norm(final)=7.180 | 4408.0 samples/s | 68.9 steps/s
[Step=31850 Epoch=62.3] | Loss=0.01185 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.614 | L2-Norm(final)=7.183 | 4304.5 samples/s | 67.3 steps/s
[Step=31900 Epoch=62.4] | Loss=0.01188 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.618 | L2-Norm(final)=7.185 | 4239.1 samples/s | 66.2 steps/s
[Step=31950 Epoch=62.5] | Loss=0.01197 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.622 | L2-Norm(final)=7.188 | 4356.1 samples/s | 68.1 steps/s
[Step=32000 Epoch=62.6] | Loss=0.01196 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.625 | L2-Norm(final)=7.190 | 4374.1 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step32000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=115.0] | Loss=0.00035 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.350 | L2-Norm(final)=4.892 | 6238.7 samples/s | 97.5 steps/s
[Step=30050 Epoch=115.1] | Loss=0.00019 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.353 | L2-Norm(final)=4.900 | 3950.9 samples/s | 61.7 steps/s
[Step=30100 Epoch=115.3] | Loss=0.00044 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.373 | L2-Norm(final)=4.903 | 4672.8 samples/s | 73.0 steps/s
[Step=30150 Epoch=115.5] | Loss=0.00039 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.388 | L2-Norm(final)=4.909 | 4559.2 samples/s | 71.2 steps/s
[Step=30200 Epoch=115.7] | Loss=0.00031 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.399 | L2-Norm(final)=4.917 | 4617.1 samples/s | 72.1 steps/s
[Step=30250 Epoch=115.9] | Loss=0.00026 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.405 | L2-Norm(final)=4.924 | 6438.7 samples/s | 100.6 steps/s
[Step=30300 Epoch=116.1] | Loss=0.00023 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.409 | L2-Norm(final)=4.931 | 2368.2 samples/s | 37.0 steps/s
[Step=30350 Epoch=116.3] | Loss=0.00020 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.412 | L2-Norm(final)=4.937 | 4579.1 samples/s | 71.5 steps/s
[Step=30400 Epoch=116.5] | Loss=0.00018 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.413 | L2-Norm(final)=4.942 | 4566.0 samples/s | 71.3 steps/s
[Step=30450 Epoch=116.7] | Loss=0.00016 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.414 | L2-Norm(final)=4.947 | 4679.7 samples/s | 73.1 steps/s
[Step=30500 Epoch=116.9] | Loss=0.00015 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.414 | L2-Norm(final)=4.951 | 5213.2 samples/s | 81.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=116.9] | Loss=0.00004 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.413 | L2-Norm(final)=4.995 | 6066.4 samples/s | 94.8 steps/s
[Step=30550 Epoch=117.1] | Loss=0.00002 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.399 | L2-Norm(final)=4.998 | 3714.2 samples/s | 58.0 steps/s
[Step=30600 Epoch=117.2] | Loss=0.00003 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.382 | L2-Norm(final)=5.002 | 4260.9 samples/s | 66.6 steps/s
[Step=30650 Epoch=117.4] | Loss=0.00002 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.363 | L2-Norm(final)=5.005 | 4059.8 samples/s | 63.4 steps/s
[Step=30700 Epoch=117.6] | Loss=0.00002 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.344 | L2-Norm(final)=5.007 | 4143.6 samples/s | 64.7 steps/s
[Step=30750 Epoch=117.8] | Loss=0.00002 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.324 | L2-Norm(final)=5.009 | 5428.1 samples/s | 84.8 steps/s
[Step=30800 Epoch=118.0] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.304 | L2-Norm(final)=5.011 | 2205.8 samples/s | 34.5 steps/s
[Step=30850 Epoch=118.2] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.283 | L2-Norm(final)=5.012 | 4139.9 samples/s | 64.7 steps/s
[Step=30900 Epoch=118.4] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.262 | L2-Norm(final)=5.014 | 4123.8 samples/s | 64.4 steps/s
[Step=30950 Epoch=118.6] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.240 | L2-Norm(final)=5.015 | 4135.6 samples/s | 64.6 steps/s
[Step=31000 Epoch=118.8] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.219 | L2-Norm(final)=5.016 | 4654.5 samples/s | 72.7 steps/s
[Step=31050 Epoch=119.0] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.197 | L2-Norm(final)=5.017 | 2381.5 samples/s | 37.2 steps/s
[Step=31100 Epoch=119.2] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.175 | L2-Norm(final)=5.018 | 4091.4 samples/s | 63.9 steps/s
[Step=31150 Epoch=119.4] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.153 | L2-Norm(final)=5.018 | 4094.0 samples/s | 64.0 steps/s
[Step=31200 Epoch=119.5] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.130 | L2-Norm(final)=5.019 | 4157.3 samples/s | 65.0 steps/s
[Step=31250 Epoch=119.7] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.108 | L2-Norm(final)=5.020 | 4102.5 samples/s | 64.1 steps/s
[Step=31300 Epoch=119.9] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.085 | L2-Norm(final)=5.020 | 2548.5 samples/s | 39.8 steps/s
[Step=31350 Epoch=120.1] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.062 | L2-Norm(final)=5.021 | 4111.4 samples/s | 64.2 steps/s
[Step=31400 Epoch=120.3] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.039 | L2-Norm(final)=5.022 | 4087.3 samples/s | 63.9 steps/s
[Step=31450 Epoch=120.5] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.015 | L2-Norm(final)=5.022 | 4115.3 samples/s | 64.3 steps/s
[Step=31500 Epoch=120.7] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.992 | L2-Norm(final)=5.023 | 4079.2 samples/s | 63.7 steps/s
[Step=31550 Epoch=120.9] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.968 | L2-Norm(final)=5.024 | 2571.8 samples/s | 40.2 steps/s
[Step=31600 Epoch=121.1] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.945 | L2-Norm(final)=5.024 | 4122.3 samples/s | 64.4 steps/s
[Step=31650 Epoch=121.3] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.921 | L2-Norm(final)=5.025 | 4103.6 samples/s | 64.1 steps/s
[Step=31700 Epoch=121.5] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.897 | L2-Norm(final)=5.025 | 4138.1 samples/s | 64.7 steps/s
[Step=31750 Epoch=121.7] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.872 | L2-Norm(final)=5.026 | 4099.8 samples/s | 64.1 steps/s
[Step=31800 Epoch=121.8] | Loss=0.00000 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.848 | L2-Norm(final)=5.027 | 6140.4 samples/s | 95.9 steps/s
[Step=31850 Epoch=122.0] | Loss=0.00000 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.823 | L2-Norm(final)=5.027 | 2144.9 samples/s | 33.5 steps/s
[Step=31900 Epoch=122.2] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.799 | L2-Norm(final)=5.028 | 4200.0 samples/s | 65.6 steps/s
[Step=31950 Epoch=122.4] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.774 | L2-Norm(final)=5.029 | 4244.3 samples/s | 66.3 steps/s
[Step=32000 Epoch=122.6] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.749 | L2-Norm(final)=5.029 | 4147.0 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step32000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=115.5] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.299 | L2-Norm(final)=5.392 | 5880.4 samples/s | 91.9 steps/s
[Step=30050 Epoch=115.7] | Loss=0.00181 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.349 | L2-Norm(final)=5.383 | 3971.8 samples/s | 62.1 steps/s
[Step=30100 Epoch=115.9] | Loss=0.00115 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.383 | L2-Norm(final)=5.390 | 4551.8 samples/s | 71.1 steps/s
[Step=30150 Epoch=116.1] | Loss=0.00080 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.402 | L2-Norm(final)=5.399 | 4515.5 samples/s | 70.6 steps/s
[Step=30200 Epoch=116.3] | Loss=0.00061 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.412 | L2-Norm(final)=5.405 | 4538.0 samples/s | 70.9 steps/s
[Step=30250 Epoch=116.4] | Loss=0.00054 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.418 | L2-Norm(final)=5.410 | 6512.2 samples/s | 101.8 steps/s
[Step=30300 Epoch=116.6] | Loss=0.00046 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.425 | L2-Norm(final)=5.415 | 2309.3 samples/s | 36.1 steps/s
[Step=30350 Epoch=116.8] | Loss=0.00040 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.429 | L2-Norm(final)=5.419 | 4493.3 samples/s | 70.2 steps/s
[Step=30400 Epoch=117.0] | Loss=0.00035 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.432 | L2-Norm(final)=5.423 | 4578.5 samples/s | 71.5 steps/s
[Step=30450 Epoch=117.2] | Loss=0.00032 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.434 | L2-Norm(final)=5.427 | 4558.5 samples/s | 71.2 steps/s
[Step=30500 Epoch=117.4] | Loss=0.00029 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.435 | L2-Norm(final)=5.430 | 5402.0 samples/s | 84.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=117.4] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.445 | L2-Norm(final)=5.462 | 5917.0 samples/s | 92.5 steps/s
[Step=30550 Epoch=117.6] | Loss=0.00843 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.471 | L2-Norm(final)=5.458 | 3935.2 samples/s | 61.5 steps/s
[Step=30600 Epoch=117.8] | Loss=0.00795 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.603 | L2-Norm(final)=5.423 | 4046.4 samples/s | 63.2 steps/s
[Step=30650 Epoch=118.0] | Loss=0.00753 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.677 | L2-Norm(final)=5.403 | 4255.0 samples/s | 66.5 steps/s
[Step=30700 Epoch=118.2] | Loss=0.00587 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.720 | L2-Norm(final)=5.391 | 4206.8 samples/s | 65.7 steps/s
[Step=30750 Epoch=118.4] | Loss=0.00490 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.746 | L2-Norm(final)=5.385 | 5698.6 samples/s | 89.0 steps/s
[Step=30800 Epoch=118.6] | Loss=0.00410 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.763 | L2-Norm(final)=5.382 | 2230.6 samples/s | 34.9 steps/s
[Step=30850 Epoch=118.8] | Loss=0.00353 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.774 | L2-Norm(final)=5.380 | 4164.4 samples/s | 65.1 steps/s
[Step=30900 Epoch=118.9] | Loss=0.00309 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.781 | L2-Norm(final)=5.379 | 4198.2 samples/s | 65.6 steps/s
[Step=30950 Epoch=119.1] | Loss=0.00275 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.786 | L2-Norm(final)=5.379 | 4137.9 samples/s | 64.7 steps/s
[Step=31000 Epoch=119.3] | Loss=0.00248 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.789 | L2-Norm(final)=5.379 | 4926.6 samples/s | 77.0 steps/s
[Step=31050 Epoch=119.5] | Loss=0.00225 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.790 | L2-Norm(final)=5.379 | 2387.0 samples/s | 37.3 steps/s
[Step=31100 Epoch=119.7] | Loss=0.00207 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.791 | L2-Norm(final)=5.379 | 4189.1 samples/s | 65.5 steps/s
[Step=31150 Epoch=119.9] | Loss=0.00191 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.791 | L2-Norm(final)=5.379 | 4129.0 samples/s | 64.5 steps/s
[Step=31200 Epoch=120.1] | Loss=0.00178 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.790 | L2-Norm(final)=5.379 | 4245.2 samples/s | 66.3 steps/s
[Step=31250 Epoch=120.3] | Loss=0.00166 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.788 | L2-Norm(final)=5.379 | 4231.7 samples/s | 66.1 steps/s
[Step=31300 Epoch=120.5] | Loss=0.00156 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.786 | L2-Norm(final)=5.380 | 2561.4 samples/s | 40.0 steps/s
[Step=31350 Epoch=120.7] | Loss=0.00146 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.784 | L2-Norm(final)=5.380 | 4223.8 samples/s | 66.0 steps/s
[Step=31400 Epoch=120.9] | Loss=0.00138 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.781 | L2-Norm(final)=5.380 | 4232.4 samples/s | 66.1 steps/s
[Step=31450 Epoch=121.1] | Loss=0.00131 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.779 | L2-Norm(final)=5.381 | 4162.4 samples/s | 65.0 steps/s
[Step=31500 Epoch=121.3] | Loss=0.00125 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.776 | L2-Norm(final)=5.381 | 4283.2 samples/s | 66.9 steps/s
[Step=31550 Epoch=121.4] | Loss=0.00119 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.772 | L2-Norm(final)=5.382 | 2548.7 samples/s | 39.8 steps/s
[Step=31600 Epoch=121.6] | Loss=0.00113 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.769 | L2-Norm(final)=5.382 | 4193.7 samples/s | 65.5 steps/s
[Step=31650 Epoch=121.8] | Loss=0.00109 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.765 | L2-Norm(final)=5.383 | 4244.8 samples/s | 66.3 steps/s
[Step=31700 Epoch=122.0] | Loss=0.00104 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.761 | L2-Norm(final)=5.383 | 4151.0 samples/s | 64.9 steps/s
[Step=31750 Epoch=122.2] | Loss=0.00100 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.757 | L2-Norm(final)=5.384 | 4125.6 samples/s | 64.5 steps/s
[Step=31800 Epoch=122.4] | Loss=0.00096 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.753 | L2-Norm(final)=5.384 | 6947.4 samples/s | 108.6 steps/s
[Step=31850 Epoch=122.6] | Loss=0.00093 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.749 | L2-Norm(final)=5.384 | 2083.3 samples/s | 32.6 steps/s
[Step=31900 Epoch=122.8] | Loss=0.00089 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.744 | L2-Norm(final)=5.385 | 4223.2 samples/s | 66.0 steps/s
[Step=31950 Epoch=123.0] | Loss=0.00086 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.740 | L2-Norm(final)=5.385 | 4155.0 samples/s | 64.9 steps/s
[Step=32000 Epoch=123.2] | Loss=0.00083 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.735 | L2-Norm(final)=5.386 | 4219.5 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07744 | acc=0.9671 | tpr=0.9784 | fpr=0.0575 | 4866.1 samples/s | 19.0 steps/s
Avg test loss: 0.07646, Avg test acc: 0.96718, Avg tpr: 0.97838, Avg fpr: 0.05743, total FA: 448

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07533 | acc=0.9682 | tpr=0.9784 | fpr=0.0540 | 4943.9 samples/s | 19.3 steps/s
Avg test loss: 0.07980, Avg test acc: 0.96614, Avg tpr: 0.97727, Avg fpr: 0.05833, total FA: 455

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.66177 | acc=0.3021 | tpr=0.0154 | fpr=0.0753 | 4917.0 samples/s | 19.2 steps/s
Avg test loss: 5.66300, Avg test acc: 0.29902, Avg tpr: 0.01638, Avg fpr: 0.07935, total FA: 619

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.05092 | acc=0.3126 | tpr=0.0091 | fpr=0.0285 | 4959.8 samples/s | 19.4 steps/s
Avg test loss: 6.04485, Avg test acc: 0.31068, Avg tpr: 0.00985, Avg fpr: 0.02769, total FA: 216

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.10775 | acc=0.1237 | tpr=0.5885 | fpr=0.8847 | 5035.6 samples/s | 19.7 steps/s
[Step= 100] | Loss=7.07440 | acc=0.1244 | tpr=0.5586 | fpr=0.8837 | 6858.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=7.08751 | acc=0.1230 | tpr=0.5476 | fpr=0.8848 | 7364.2 samples/s | 28.8 steps/s
[Step= 200] | Loss=7.08299 | acc=0.1234 | tpr=0.5486 | fpr=0.8843 | 8371.3 samples/s | 32.7 steps/s
[Step= 250] | Loss=7.07802 | acc=0.1237 | tpr=0.5572 | fpr=0.8842 | 7749.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=7.06886 | acc=0.1232 | tpr=0.5535 | fpr=0.8847 | 7708.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=7.07505 | acc=0.1230 | tpr=0.5473 | fpr=0.8847 | 8063.9 samples/s | 31.5 steps/s
[Step= 400] | Loss=7.08040 | acc=0.1229 | tpr=0.5438 | fpr=0.8848 | 7559.6 samples/s | 29.5 steps/s
[Step= 450] | Loss=7.08517 | acc=0.1226 | tpr=0.5453 | fpr=0.8851 | 7840.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=7.08571 | acc=0.1224 | tpr=0.5436 | fpr=0.8852 | 8000.0 samples/s | 31.2 steps/s
[Step= 550] | Loss=7.09051 | acc=0.1223 | tpr=0.5424 | fpr=0.8854 | 13360.5 samples/s | 52.2 steps/s
Avg test loss: 7.09426, Avg test acc: 0.12218, Avg tpr: 0.54319, Avg fpr: 0.88547, total FA: 122946

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.00726 | acc=0.1145 | tpr=0.5177 | fpr=0.8927 | 4918.0 samples/s | 19.2 steps/s
[Step= 100] | Loss=7.95901 | acc=0.1145 | tpr=0.4670 | fpr=0.8921 | 6997.4 samples/s | 27.3 steps/s
[Step= 150] | Loss=7.95758 | acc=0.1136 | tpr=0.4683 | fpr=0.8929 | 7768.1 samples/s | 30.3 steps/s
[Step= 200] | Loss=7.95014 | acc=0.1146 | tpr=0.4623 | fpr=0.8918 | 7888.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=7.93532 | acc=0.1150 | tpr=0.4707 | fpr=0.8915 | 7627.1 samples/s | 29.8 steps/s
[Step= 300] | Loss=7.93154 | acc=0.1154 | tpr=0.4647 | fpr=0.8910 | 7986.8 samples/s | 31.2 steps/s
[Step= 350] | Loss=7.93605 | acc=0.1152 | tpr=0.4565 | fpr=0.8910 | 7628.9 samples/s | 29.8 steps/s
[Step= 400] | Loss=7.94041 | acc=0.1149 | tpr=0.4530 | fpr=0.8912 | 8064.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=7.94682 | acc=0.1148 | tpr=0.4557 | fpr=0.8914 | 7658.1 samples/s | 29.9 steps/s
[Step= 500] | Loss=7.94722 | acc=0.1150 | tpr=0.4604 | fpr=0.8912 | 7628.8 samples/s | 29.8 steps/s
[Step= 550] | Loss=7.95426 | acc=0.1149 | tpr=0.4616 | fpr=0.8914 | 14125.0 samples/s | 55.2 steps/s
Avg test loss: 7.95762, Avg test acc: 0.11483, Avg tpr: 0.46197, Avg fpr: 0.89148, total FA: 123780

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13846 | acc=0.9786 | tpr=0.9336 | fpr=0.0206 | 4795.9 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.13984 | acc=0.9790 | tpr=0.9403 | fpr=0.0203 | 7537.7 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.14560 | acc=0.9780 | tpr=0.9424 | fpr=0.0213 | 7549.3 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.14962 | acc=0.9778 | tpr=0.9432 | fpr=0.0216 | 7878.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.14704 | acc=0.9782 | tpr=0.9432 | fpr=0.0212 | 7991.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14900 | acc=0.9778 | tpr=0.9396 | fpr=0.0215 | 7788.5 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.14950 | acc=0.9777 | tpr=0.9411 | fpr=0.0216 | 7548.7 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.15115 | acc=0.9777 | tpr=0.9382 | fpr=0.0216 | 8257.2 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.15395 | acc=0.9773 | tpr=0.9362 | fpr=0.0220 | 7340.4 samples/s | 28.7 steps/s
[Step= 500] | Loss=0.15289 | acc=0.9774 | tpr=0.9374 | fpr=0.0219 | 7815.2 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.15116 | acc=0.9777 | tpr=0.9391 | fpr=0.0216 | 14683.7 samples/s | 57.4 steps/s
Avg test loss: 0.15099, Avg test acc: 0.97773, Avg tpr: 0.93899, Avg fpr: 0.02157, total FA: 2995

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11875 | acc=0.9791 | tpr=0.9248 | fpr=0.0200 | 4910.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.12155 | acc=0.9786 | tpr=0.9446 | fpr=0.0208 | 7263.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.12520 | acc=0.9778 | tpr=0.9481 | fpr=0.0216 | 7477.3 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.12787 | acc=0.9779 | tpr=0.9497 | fpr=0.0216 | 7868.2 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12648 | acc=0.9781 | tpr=0.9493 | fpr=0.0214 | 7932.8 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.12936 | acc=0.9776 | tpr=0.9462 | fpr=0.0219 | 7591.6 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.12884 | acc=0.9777 | tpr=0.9468 | fpr=0.0217 | 7632.2 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.12971 | acc=0.9776 | tpr=0.9458 | fpr=0.0219 | 8344.2 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.13147 | acc=0.9773 | tpr=0.9440 | fpr=0.0221 | 7623.3 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.13071 | acc=0.9774 | tpr=0.9449 | fpr=0.0221 | 7821.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12974 | acc=0.9776 | tpr=0.9459 | fpr=0.0218 | 10150.8 samples/s | 39.7 steps/s
Avg test loss: 0.12973, Avg test acc: 0.97760, Avg tpr: 0.94572, Avg fpr: 0.02182, total FA: 3030

server round 16/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=62.4] | Loss=0.01157 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.267 | L2-Norm(final)=7.181 | 6471.0 samples/s | 101.1 steps/s
[Step=32050 Epoch=62.5] | Loss=0.00867 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.265 | L2-Norm(final)=7.194 | 4454.8 samples/s | 69.6 steps/s
[Step=32100 Epoch=62.6] | Loss=0.00967 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.263 | L2-Norm(final)=7.209 | 4908.9 samples/s | 76.7 steps/s
[Step=32150 Epoch=62.7] | Loss=0.00985 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.261 | L2-Norm(final)=7.219 | 5006.9 samples/s | 78.2 steps/s
[Step=32200 Epoch=62.8] | Loss=0.00935 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.261 | L2-Norm(final)=7.229 | 5097.0 samples/s | 79.6 steps/s
[Step=32250 Epoch=62.9] | Loss=0.00873 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.260 | L2-Norm(final)=7.241 | 5013.3 samples/s | 78.3 steps/s
[Step=32300 Epoch=63.0] | Loss=0.00852 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.259 | L2-Norm(final)=7.252 | 4908.9 samples/s | 76.7 steps/s
[Step=32350 Epoch=63.1] | Loss=0.00833 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.257 | L2-Norm(final)=7.263 | 5043.7 samples/s | 78.8 steps/s
[Step=32400 Epoch=63.2] | Loss=0.00837 | Reg=0.00410 | acc=0.9688 | L2-Norm=20.256 | L2-Norm(final)=7.274 | 5034.2 samples/s | 78.7 steps/s
[Step=32450 Epoch=63.3] | Loss=0.00827 | Reg=0.00410 | acc=0.9844 | L2-Norm=20.254 | L2-Norm(final)=7.284 | 4862.3 samples/s | 76.0 steps/s
[Step=32500 Epoch=63.4] | Loss=0.00827 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.252 | L2-Norm(final)=7.293 | 6655.0 samples/s | 104.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=63.4] | Loss=0.00385 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.237 | L2-Norm(final)=7.384 | 6281.8 samples/s | 98.2 steps/s
[Step=32550 Epoch=63.5] | Loss=0.00771 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.237 | L2-Norm(final)=7.390 | 4030.6 samples/s | 63.0 steps/s
[Step=32600 Epoch=63.6] | Loss=0.00789 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.236 | L2-Norm(final)=7.393 | 4437.2 samples/s | 69.3 steps/s
[Step=32650 Epoch=63.7] | Loss=0.00887 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.236 | L2-Norm(final)=7.397 | 4516.8 samples/s | 70.6 steps/s
[Step=32700 Epoch=63.8] | Loss=0.00976 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.242 | L2-Norm(final)=7.399 | 4431.6 samples/s | 69.2 steps/s
[Step=32750 Epoch=63.9] | Loss=0.01171 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.252 | L2-Norm(final)=7.401 | 4353.1 samples/s | 68.0 steps/s
[Step=32800 Epoch=64.0] | Loss=0.01282 | Reg=0.00411 | acc=0.9688 | L2-Norm=20.264 | L2-Norm(final)=7.401 | 4428.9 samples/s | 69.2 steps/s
[Step=32850 Epoch=64.1] | Loss=0.01348 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.276 | L2-Norm(final)=7.402 | 4366.4 samples/s | 68.2 steps/s
[Step=32900 Epoch=64.2] | Loss=0.01408 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.288 | L2-Norm(final)=7.402 | 4433.4 samples/s | 69.3 steps/s
[Step=32950 Epoch=64.3] | Loss=0.01434 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.299 | L2-Norm(final)=7.403 | 4443.8 samples/s | 69.4 steps/s
[Step=33000 Epoch=64.4] | Loss=0.01484 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.310 | L2-Norm(final)=7.403 | 5707.4 samples/s | 89.2 steps/s
[Step=33050 Epoch=64.5] | Loss=0.01470 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.320 | L2-Norm(final)=7.403 | 2382.7 samples/s | 37.2 steps/s
[Step=33100 Epoch=64.6] | Loss=0.01452 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.329 | L2-Norm(final)=7.405 | 4505.3 samples/s | 70.4 steps/s
[Step=33150 Epoch=64.7] | Loss=0.01411 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.338 | L2-Norm(final)=7.407 | 4431.3 samples/s | 69.2 steps/s
[Step=33200 Epoch=64.8] | Loss=0.01392 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.346 | L2-Norm(final)=7.409 | 4287.5 samples/s | 67.0 steps/s
[Step=33250 Epoch=64.9] | Loss=0.01374 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.352 | L2-Norm(final)=7.412 | 4414.5 samples/s | 69.0 steps/s
[Step=33300 Epoch=64.9] | Loss=0.01386 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.359 | L2-Norm(final)=7.414 | 4497.8 samples/s | 70.3 steps/s
[Step=33350 Epoch=65.0] | Loss=0.01375 | Reg=0.00415 | acc=0.9375 | L2-Norm=20.365 | L2-Norm(final)=7.416 | 4463.1 samples/s | 69.7 steps/s
[Step=33400 Epoch=65.1] | Loss=0.01368 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.371 | L2-Norm(final)=7.418 | 4476.5 samples/s | 69.9 steps/s
[Step=33450 Epoch=65.2] | Loss=0.01372 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.377 | L2-Norm(final)=7.420 | 4412.7 samples/s | 68.9 steps/s
[Step=33500 Epoch=65.3] | Loss=0.01377 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.382 | L2-Norm(final)=7.421 | 4763.2 samples/s | 74.4 steps/s
[Step=33550 Epoch=65.4] | Loss=0.01366 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.387 | L2-Norm(final)=7.423 | 2569.6 samples/s | 40.1 steps/s
[Step=33600 Epoch=65.5] | Loss=0.01345 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.392 | L2-Norm(final)=7.425 | 4299.3 samples/s | 67.2 steps/s
[Step=33650 Epoch=65.6] | Loss=0.01323 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.396 | L2-Norm(final)=7.428 | 4428.2 samples/s | 69.2 steps/s
[Step=33700 Epoch=65.7] | Loss=0.01302 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.400 | L2-Norm(final)=7.430 | 4416.8 samples/s | 69.0 steps/s
[Step=33750 Epoch=65.8] | Loss=0.01288 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.403 | L2-Norm(final)=7.432 | 4440.4 samples/s | 69.4 steps/s
[Step=33800 Epoch=65.9] | Loss=0.01279 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.405 | L2-Norm(final)=7.434 | 4481.7 samples/s | 70.0 steps/s
[Step=33850 Epoch=66.0] | Loss=0.01271 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.407 | L2-Norm(final)=7.436 | 4495.9 samples/s | 70.2 steps/s
[Step=33900 Epoch=66.1] | Loss=0.01266 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.409 | L2-Norm(final)=7.438 | 4388.3 samples/s | 68.6 steps/s
[Step=33950 Epoch=66.2] | Loss=0.01257 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.411 | L2-Norm(final)=7.439 | 4427.1 samples/s | 69.2 steps/s
[Step=34000 Epoch=66.3] | Loss=0.01253 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.413 | L2-Norm(final)=7.441 | 4362.3 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step34000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=62.6] | Loss=0.01126 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.315 | L2-Norm(final)=7.265 | 5563.8 samples/s | 86.9 steps/s
[Step=32050 Epoch=62.7] | Loss=0.00947 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.314 | L2-Norm(final)=7.276 | 4622.4 samples/s | 72.2 steps/s
[Step=32100 Epoch=62.8] | Loss=0.00843 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.312 | L2-Norm(final)=7.288 | 5035.5 samples/s | 78.7 steps/s
[Step=32150 Epoch=62.9] | Loss=0.00851 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.309 | L2-Norm(final)=7.300 | 4963.3 samples/s | 77.6 steps/s
[Step=32200 Epoch=63.0] | Loss=0.00866 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.307 | L2-Norm(final)=7.311 | 5006.8 samples/s | 78.2 steps/s
[Step=32250 Epoch=63.0] | Loss=0.00862 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.307 | L2-Norm(final)=7.322 | 5085.8 samples/s | 79.5 steps/s
[Step=32300 Epoch=63.1] | Loss=0.00864 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.306 | L2-Norm(final)=7.331 | 4830.9 samples/s | 75.5 steps/s
[Step=32350 Epoch=63.2] | Loss=0.00849 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.305 | L2-Norm(final)=7.340 | 5016.9 samples/s | 78.4 steps/s
[Step=32400 Epoch=63.3] | Loss=0.00846 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.304 | L2-Norm(final)=7.349 | 4989.6 samples/s | 78.0 steps/s
[Step=32450 Epoch=63.4] | Loss=0.00836 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.303 | L2-Norm(final)=7.358 | 4884.3 samples/s | 76.3 steps/s
[Step=32500 Epoch=63.5] | Loss=0.00843 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.301 | L2-Norm(final)=7.368 | 6856.2 samples/s | 107.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=63.5] | Loss=0.00338 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.287 | L2-Norm(final)=7.461 | 6009.6 samples/s | 93.9 steps/s
[Step=32550 Epoch=63.6] | Loss=0.00800 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.287 | L2-Norm(final)=7.470 | 4154.6 samples/s | 64.9 steps/s
[Step=32600 Epoch=63.7] | Loss=0.00937 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.290 | L2-Norm(final)=7.476 | 4394.9 samples/s | 68.7 steps/s
[Step=32650 Epoch=63.8] | Loss=0.00997 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.294 | L2-Norm(final)=7.480 | 4423.9 samples/s | 69.1 steps/s
[Step=32700 Epoch=63.9] | Loss=0.01149 | Reg=0.00412 | acc=0.9688 | L2-Norm=20.300 | L2-Norm(final)=7.483 | 4588.6 samples/s | 71.7 steps/s
[Step=32750 Epoch=64.0] | Loss=0.01238 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.306 | L2-Norm(final)=7.484 | 4340.8 samples/s | 67.8 steps/s
[Step=32800 Epoch=64.1] | Loss=0.01217 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.312 | L2-Norm(final)=7.485 | 4297.8 samples/s | 67.2 steps/s
[Step=32850 Epoch=64.2] | Loss=0.01186 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.317 | L2-Norm(final)=7.487 | 4456.0 samples/s | 69.6 steps/s
[Step=32900 Epoch=64.3] | Loss=0.01194 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.321 | L2-Norm(final)=7.490 | 4593.1 samples/s | 71.8 steps/s
[Step=32950 Epoch=64.4] | Loss=0.01182 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.326 | L2-Norm(final)=7.494 | 4294.2 samples/s | 67.1 steps/s
[Step=33000 Epoch=64.5] | Loss=0.01204 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.330 | L2-Norm(final)=7.498 | 5860.1 samples/s | 91.6 steps/s
[Step=33050 Epoch=64.6] | Loss=0.01185 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.334 | L2-Norm(final)=7.502 | 2364.1 samples/s | 36.9 steps/s
[Step=33100 Epoch=64.7] | Loss=0.01154 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.337 | L2-Norm(final)=7.506 | 4417.3 samples/s | 69.0 steps/s
[Step=33150 Epoch=64.8] | Loss=0.01184 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.340 | L2-Norm(final)=7.509 | 4410.0 samples/s | 68.9 steps/s
[Step=33200 Epoch=64.9] | Loss=0.01201 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.343 | L2-Norm(final)=7.511 | 4324.9 samples/s | 67.6 steps/s
[Step=33250 Epoch=65.0] | Loss=0.01195 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.346 | L2-Norm(final)=7.514 | 4503.9 samples/s | 70.4 steps/s
[Step=33300 Epoch=65.1] | Loss=0.01208 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.350 | L2-Norm(final)=7.517 | 4420.6 samples/s | 69.1 steps/s
[Step=33350 Epoch=65.2] | Loss=0.01206 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.354 | L2-Norm(final)=7.520 | 4485.3 samples/s | 70.1 steps/s
[Step=33400 Epoch=65.3] | Loss=0.01219 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.358 | L2-Norm(final)=7.522 | 4414.9 samples/s | 69.0 steps/s
[Step=33450 Epoch=65.4] | Loss=0.01229 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.362 | L2-Norm(final)=7.525 | 4479.0 samples/s | 70.0 steps/s
[Step=33500 Epoch=65.5] | Loss=0.01210 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.366 | L2-Norm(final)=7.528 | 4891.6 samples/s | 76.4 steps/s
[Step=33550 Epoch=65.6] | Loss=0.01230 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.369 | L2-Norm(final)=7.530 | 2532.3 samples/s | 39.6 steps/s
[Step=33600 Epoch=65.7] | Loss=0.01211 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.373 | L2-Norm(final)=7.533 | 4390.3 samples/s | 68.6 steps/s
[Step=33650 Epoch=65.8] | Loss=0.01198 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.376 | L2-Norm(final)=7.536 | 4382.7 samples/s | 68.5 steps/s
[Step=33700 Epoch=65.9] | Loss=0.01189 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.378 | L2-Norm(final)=7.539 | 4516.8 samples/s | 70.6 steps/s
[Step=33750 Epoch=66.0] | Loss=0.01183 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.380 | L2-Norm(final)=7.542 | 4460.5 samples/s | 69.7 steps/s
[Step=33800 Epoch=66.1] | Loss=0.01176 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.382 | L2-Norm(final)=7.545 | 4328.6 samples/s | 67.6 steps/s
[Step=33850 Epoch=66.2] | Loss=0.01172 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.384 | L2-Norm(final)=7.548 | 4554.3 samples/s | 71.2 steps/s
[Step=33900 Epoch=66.3] | Loss=0.01165 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.385 | L2-Norm(final)=7.550 | 4342.3 samples/s | 67.8 steps/s
[Step=33950 Epoch=66.4] | Loss=0.01155 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.386 | L2-Norm(final)=7.554 | 4408.3 samples/s | 68.9 steps/s
[Step=34000 Epoch=66.5] | Loss=0.01156 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.387 | L2-Norm(final)=7.557 | 4405.4 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step34000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=122.6] | Loss=0.00044 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.027 | L2-Norm(final)=5.051 | 6498.9 samples/s | 101.5 steps/s
[Step=32050 Epoch=122.8] | Loss=0.00132 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.086 | L2-Norm(final)=5.045 | 3960.1 samples/s | 61.9 steps/s
[Step=32100 Epoch=123.0] | Loss=0.00072 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.108 | L2-Norm(final)=5.054 | 4633.9 samples/s | 72.4 steps/s
[Step=32150 Epoch=123.2] | Loss=0.00052 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.116 | L2-Norm(final)=5.061 | 4818.7 samples/s | 75.3 steps/s
[Step=32200 Epoch=123.4] | Loss=0.00057 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.121 | L2-Norm(final)=5.067 | 4710.4 samples/s | 73.6 steps/s
[Step=32250 Epoch=123.6] | Loss=0.00050 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.128 | L2-Norm(final)=5.072 | 6393.4 samples/s | 99.9 steps/s
[Step=32300 Epoch=123.8] | Loss=0.00042 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.133 | L2-Norm(final)=5.078 | 2385.8 samples/s | 37.3 steps/s
[Step=32350 Epoch=124.0] | Loss=0.00037 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.137 | L2-Norm(final)=5.083 | 4894.5 samples/s | 76.5 steps/s
[Step=32400 Epoch=124.1] | Loss=0.00033 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.140 | L2-Norm(final)=5.088 | 4491.7 samples/s | 70.2 steps/s
[Step=32450 Epoch=124.3] | Loss=0.00030 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.142 | L2-Norm(final)=5.092 | 4939.1 samples/s | 77.2 steps/s
[Step=32500 Epoch=124.5] | Loss=0.00027 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.143 | L2-Norm(final)=5.097 | 5253.7 samples/s | 82.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=124.5] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.153 | L2-Norm(final)=5.139 | 6818.7 samples/s | 106.5 steps/s
[Step=32550 Epoch=124.7] | Loss=0.00004 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.123 | L2-Norm(final)=5.142 | 3612.4 samples/s | 56.4 steps/s
[Step=32600 Epoch=124.9] | Loss=0.00368 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.182 | L2-Norm(final)=5.131 | 4196.8 samples/s | 65.6 steps/s
[Step=32650 Epoch=125.1] | Loss=0.00440 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.287 | L2-Norm(final)=5.111 | 4318.9 samples/s | 67.5 steps/s
[Step=32700 Epoch=125.3] | Loss=0.00361 | Reg=0.00153 | acc=0.9844 | L2-Norm=12.358 | L2-Norm(final)=5.101 | 4047.3 samples/s | 63.2 steps/s
[Step=32750 Epoch=125.5] | Loss=0.00357 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.404 | L2-Norm(final)=5.093 | 5661.6 samples/s | 88.5 steps/s
[Step=32800 Epoch=125.7] | Loss=0.00308 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.436 | L2-Norm(final)=5.088 | 2249.6 samples/s | 35.2 steps/s
[Step=32850 Epoch=125.9] | Loss=0.00265 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.458 | L2-Norm(final)=5.085 | 4228.9 samples/s | 66.1 steps/s
[Step=32900 Epoch=126.1] | Loss=0.00236 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.474 | L2-Norm(final)=5.083 | 4255.9 samples/s | 66.5 steps/s
[Step=32950 Epoch=126.3] | Loss=0.00211 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.486 | L2-Norm(final)=5.082 | 4185.9 samples/s | 65.4 steps/s
[Step=33000 Epoch=126.4] | Loss=0.00202 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.495 | L2-Norm(final)=5.081 | 4741.0 samples/s | 74.1 steps/s
[Step=33050 Epoch=126.6] | Loss=0.00185 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.503 | L2-Norm(final)=5.081 | 2393.3 samples/s | 37.4 steps/s
[Step=33100 Epoch=126.8] | Loss=0.00170 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.509 | L2-Norm(final)=5.081 | 4209.4 samples/s | 65.8 steps/s
[Step=33150 Epoch=127.0] | Loss=0.00157 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.513 | L2-Norm(final)=5.081 | 4192.0 samples/s | 65.5 steps/s
[Step=33200 Epoch=127.2] | Loss=0.00146 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.516 | L2-Norm(final)=5.082 | 4274.9 samples/s | 66.8 steps/s
[Step=33250 Epoch=127.4] | Loss=0.00136 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.518 | L2-Norm(final)=5.082 | 4136.6 samples/s | 64.6 steps/s
[Step=33300 Epoch=127.6] | Loss=0.00128 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.519 | L2-Norm(final)=5.083 | 2613.4 samples/s | 40.8 steps/s
[Step=33350 Epoch=127.8] | Loss=0.00120 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.520 | L2-Norm(final)=5.083 | 4213.7 samples/s | 65.8 steps/s
[Step=33400 Epoch=128.0] | Loss=0.00114 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.519 | L2-Norm(final)=5.084 | 4085.4 samples/s | 63.8 steps/s
[Step=33450 Epoch=128.2] | Loss=0.00108 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.519 | L2-Norm(final)=5.084 | 4206.0 samples/s | 65.7 steps/s
[Step=33500 Epoch=128.4] | Loss=0.00102 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.518 | L2-Norm(final)=5.085 | 4176.1 samples/s | 65.3 steps/s
[Step=33550 Epoch=128.6] | Loss=0.00098 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.516 | L2-Norm(final)=5.086 | 2621.6 samples/s | 41.0 steps/s
[Step=33600 Epoch=128.7] | Loss=0.00093 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.514 | L2-Norm(final)=5.086 | 4225.6 samples/s | 66.0 steps/s
[Step=33650 Epoch=128.9] | Loss=0.00089 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.512 | L2-Norm(final)=5.087 | 4244.1 samples/s | 66.3 steps/s
[Step=33700 Epoch=129.1] | Loss=0.00086 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.510 | L2-Norm(final)=5.088 | 4162.6 samples/s | 65.0 steps/s
[Step=33750 Epoch=129.3] | Loss=0.00082 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.507 | L2-Norm(final)=5.088 | 4148.4 samples/s | 64.8 steps/s
[Step=33800 Epoch=129.5] | Loss=0.00079 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.504 | L2-Norm(final)=5.089 | 6180.8 samples/s | 96.6 steps/s
[Step=33850 Epoch=129.7] | Loss=0.00076 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.501 | L2-Norm(final)=5.090 | 2175.0 samples/s | 34.0 steps/s
[Step=33900 Epoch=129.9] | Loss=0.00073 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.498 | L2-Norm(final)=5.090 | 4234.4 samples/s | 66.2 steps/s
[Step=33950 Epoch=130.1] | Loss=0.00071 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.495 | L2-Norm(final)=5.091 | 4148.4 samples/s | 64.8 steps/s
[Step=34000 Epoch=130.3] | Loss=0.00069 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.491 | L2-Norm(final)=5.092 | 4194.2 samples/s | 65.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step34000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=123.2] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.253 | L2-Norm(final)=5.400 | 6231.7 samples/s | 97.4 steps/s
[Step=32050 Epoch=123.4] | Loss=0.00027 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.255 | L2-Norm(final)=5.401 | 4049.4 samples/s | 63.3 steps/s
[Step=32100 Epoch=123.6] | Loss=0.00019 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=5.406 | 4663.6 samples/s | 72.9 steps/s
[Step=32150 Epoch=123.8] | Loss=0.00015 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=5.410 | 4718.1 samples/s | 73.7 steps/s
[Step=32200 Epoch=124.0] | Loss=0.00012 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.255 | L2-Norm(final)=5.413 | 4661.1 samples/s | 72.8 steps/s
[Step=32250 Epoch=124.1] | Loss=0.00011 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.255 | L2-Norm(final)=5.417 | 6754.5 samples/s | 105.5 steps/s
[Step=32300 Epoch=124.3] | Loss=0.00010 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.254 | L2-Norm(final)=5.420 | 2369.7 samples/s | 37.0 steps/s
[Step=32350 Epoch=124.5] | Loss=0.00009 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.253 | L2-Norm(final)=5.423 | 4740.3 samples/s | 74.1 steps/s
[Step=32400 Epoch=124.7] | Loss=0.00009 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.253 | L2-Norm(final)=5.426 | 4706.8 samples/s | 73.5 steps/s
[Step=32450 Epoch=124.9] | Loss=0.00008 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.252 | L2-Norm(final)=5.429 | 4725.9 samples/s | 73.8 steps/s
[Step=32500 Epoch=125.1] | Loss=0.00008 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.251 | L2-Norm(final)=5.432 | 5480.3 samples/s | 85.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=125.1] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.242 | L2-Norm(final)=5.462 | 5608.9 samples/s | 87.6 steps/s
[Step=32550 Epoch=125.3] | Loss=0.00003 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.236 | L2-Norm(final)=5.465 | 3980.4 samples/s | 62.2 steps/s
[Step=32600 Epoch=125.5] | Loss=0.00003 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.229 | L2-Norm(final)=5.467 | 4166.4 samples/s | 65.1 steps/s
[Step=32650 Epoch=125.7] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.222 | L2-Norm(final)=5.470 | 4259.6 samples/s | 66.6 steps/s
[Step=32700 Epoch=125.9] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.214 | L2-Norm(final)=5.472 | 4217.5 samples/s | 65.9 steps/s
[Step=32750 Epoch=126.1] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.207 | L2-Norm(final)=5.474 | 5701.8 samples/s | 89.1 steps/s
[Step=32800 Epoch=126.3] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.199 | L2-Norm(final)=5.475 | 2238.7 samples/s | 35.0 steps/s
[Step=32850 Epoch=126.5] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.190 | L2-Norm(final)=5.477 | 4193.0 samples/s | 65.5 steps/s
[Step=32900 Epoch=126.6] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.182 | L2-Norm(final)=5.478 | 4204.7 samples/s | 65.7 steps/s
[Step=32950 Epoch=126.8] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.174 | L2-Norm(final)=5.479 | 4171.2 samples/s | 65.2 steps/s
[Step=33000 Epoch=127.0] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.165 | L2-Norm(final)=5.480 | 4933.0 samples/s | 77.1 steps/s
[Step=33050 Epoch=127.2] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.156 | L2-Norm(final)=5.482 | 2435.4 samples/s | 38.1 steps/s
[Step=33100 Epoch=127.4] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.148 | L2-Norm(final)=5.483 | 4080.8 samples/s | 63.8 steps/s
[Step=33150 Epoch=127.6] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.139 | L2-Norm(final)=5.484 | 4160.6 samples/s | 65.0 steps/s
[Step=33200 Epoch=127.8] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.130 | L2-Norm(final)=5.485 | 4148.8 samples/s | 64.8 steps/s
[Step=33250 Epoch=128.0] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.121 | L2-Norm(final)=5.486 | 4290.3 samples/s | 67.0 steps/s
[Step=33300 Epoch=128.2] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.112 | L2-Norm(final)=5.487 | 2599.6 samples/s | 40.6 steps/s
[Step=33350 Epoch=128.4] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.102 | L2-Norm(final)=5.488 | 4178.5 samples/s | 65.3 steps/s
[Step=33400 Epoch=128.6] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.093 | L2-Norm(final)=5.488 | 4297.4 samples/s | 67.1 steps/s
[Step=33450 Epoch=128.8] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.084 | L2-Norm(final)=5.489 | 4129.9 samples/s | 64.5 steps/s
[Step=33500 Epoch=129.0] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.074 | L2-Norm(final)=5.490 | 4182.5 samples/s | 65.4 steps/s
[Step=33550 Epoch=129.1] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.065 | L2-Norm(final)=5.491 | 2593.1 samples/s | 40.5 steps/s
[Step=33600 Epoch=129.3] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.055 | L2-Norm(final)=5.492 | 4260.7 samples/s | 66.6 steps/s
[Step=33650 Epoch=129.5] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.045 | L2-Norm(final)=5.493 | 4209.7 samples/s | 65.8 steps/s
[Step=33700 Epoch=129.7] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.035 | L2-Norm(final)=5.494 | 4166.5 samples/s | 65.1 steps/s
[Step=33750 Epoch=129.9] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.025 | L2-Norm(final)=5.494 | 4165.6 samples/s | 65.1 steps/s
[Step=33800 Epoch=130.1] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.015 | L2-Norm(final)=5.495 | 6868.0 samples/s | 107.3 steps/s
[Step=33850 Epoch=130.3] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.005 | L2-Norm(final)=5.496 | 2114.4 samples/s | 33.0 steps/s
[Step=33900 Epoch=130.5] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.995 | L2-Norm(final)=5.497 | 4125.8 samples/s | 64.5 steps/s
[Step=33950 Epoch=130.7] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.984 | L2-Norm(final)=5.498 | 4227.5 samples/s | 66.1 steps/s
[Step=34000 Epoch=130.9] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.974 | L2-Norm(final)=5.499 | 4189.0 samples/s | 65.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08855 | acc=0.9644 | tpr=0.9750 | fpr=0.0587 | 4935.1 samples/s | 19.3 steps/s
Avg test loss: 0.08408, Avg test acc: 0.96586, Avg tpr: 0.97634, Avg fpr: 0.05717, total FA: 446

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08181 | acc=0.9678 | tpr=0.9734 | fpr=0.0444 | 5096.8 samples/s | 19.9 steps/s
Avg test loss: 0.08296, Avg test acc: 0.96622, Avg tpr: 0.97202, Avg fpr: 0.04653, total FA: 363

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.57016 | acc=0.3091 | tpr=0.0049 | fpr=0.0305 | 5063.1 samples/s | 19.8 steps/s
Avg test loss: 5.56320, Avg test acc: 0.30527, Avg tpr: 0.00536, Avg fpr: 0.03512, total FA: 274

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.25298 | acc=0.3111 | tpr=0.0248 | fpr=0.0671 | 4996.8 samples/s | 19.5 steps/s
Avg test loss: 6.23236, Avg test acc: 0.30956, Avg tpr: 0.02623, Avg fpr: 0.06730, total FA: 525

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.65853 | acc=0.1207 | tpr=0.5531 | fpr=0.8871 | 5086.3 samples/s | 19.9 steps/s
[Step= 100] | Loss=7.61210 | acc=0.1195 | tpr=0.5394 | fpr=0.8883 | 5821.1 samples/s | 22.7 steps/s
[Step= 150] | Loss=7.62402 | acc=0.1186 | tpr=0.5231 | fpr=0.8889 | 7815.8 samples/s | 30.5 steps/s
[Step= 200] | Loss=7.61630 | acc=0.1183 | tpr=0.5202 | fpr=0.8890 | 6932.7 samples/s | 27.1 steps/s
[Step= 250] | Loss=7.61108 | acc=0.1182 | tpr=0.5249 | fpr=0.8893 | 7792.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=7.60226 | acc=0.1183 | tpr=0.5236 | fpr=0.8891 | 7956.6 samples/s | 31.1 steps/s
[Step= 350] | Loss=7.60734 | acc=0.1181 | tpr=0.5229 | fpr=0.8893 | 8074.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=7.61351 | acc=0.1179 | tpr=0.5181 | fpr=0.8894 | 7257.9 samples/s | 28.4 steps/s
[Step= 450] | Loss=7.61926 | acc=0.1178 | tpr=0.5195 | fpr=0.8894 | 7814.5 samples/s | 30.5 steps/s
[Step= 500] | Loss=7.62183 | acc=0.1178 | tpr=0.5203 | fpr=0.8895 | 7915.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=7.62694 | acc=0.1177 | tpr=0.5225 | fpr=0.8897 | 13251.4 samples/s | 51.8 steps/s
Avg test loss: 7.63033, Avg test acc: 0.11758, Avg tpr: 0.52338, Avg fpr: 0.88980, total FA: 123547

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.49727 | acc=0.1463 | tpr=0.6239 | fpr=0.8623 | 4969.0 samples/s | 19.4 steps/s
[Step= 100] | Loss=6.47144 | acc=0.1475 | tpr=0.5906 | fpr=0.8608 | 5285.9 samples/s | 20.6 steps/s
[Step= 150] | Loss=6.47744 | acc=0.1473 | tpr=0.5821 | fpr=0.8607 | 7693.0 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.47313 | acc=0.1478 | tpr=0.5705 | fpr=0.8599 | 8040.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.46670 | acc=0.1485 | tpr=0.5721 | fpr=0.8592 | 7798.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=6.46006 | acc=0.1491 | tpr=0.5651 | fpr=0.8585 | 7515.3 samples/s | 29.4 steps/s
[Step= 350] | Loss=6.46568 | acc=0.1490 | tpr=0.5636 | fpr=0.8586 | 7910.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=6.46930 | acc=0.1487 | tpr=0.5585 | fpr=0.8588 | 7990.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.47436 | acc=0.1484 | tpr=0.5623 | fpr=0.8591 | 7578.8 samples/s | 29.6 steps/s
[Step= 500] | Loss=6.47992 | acc=0.1487 | tpr=0.5626 | fpr=0.8588 | 7877.5 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.48652 | acc=0.1485 | tpr=0.5599 | fpr=0.8589 | 13521.2 samples/s | 52.8 steps/s
Avg test loss: 6.48937, Avg test acc: 0.14840, Avg tpr: 0.56062, Avg fpr: 0.85909, total FA: 119283

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11708 | acc=0.9817 | tpr=0.9381 | fpr=0.0175 | 4529.6 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.12250 | acc=0.9816 | tpr=0.9382 | fpr=0.0175 | 6777.2 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.12979 | acc=0.9804 | tpr=0.9380 | fpr=0.0189 | 7004.6 samples/s | 27.4 steps/s
[Step= 200] | Loss=0.13210 | acc=0.9804 | tpr=0.9421 | fpr=0.0189 | 7001.8 samples/s | 27.4 steps/s
[Step= 250] | Loss=0.13041 | acc=0.9804 | tpr=0.9362 | fpr=0.0188 | 8052.0 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.13289 | acc=0.9800 | tpr=0.9353 | fpr=0.0191 | 7809.0 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.13324 | acc=0.9798 | tpr=0.9355 | fpr=0.0194 | 7893.1 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.13500 | acc=0.9796 | tpr=0.9322 | fpr=0.0195 | 7954.1 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.13801 | acc=0.9793 | tpr=0.9309 | fpr=0.0199 | 7401.5 samples/s | 28.9 steps/s
[Step= 500] | Loss=0.13704 | acc=0.9793 | tpr=0.9317 | fpr=0.0198 | 7904.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.13598 | acc=0.9795 | tpr=0.9339 | fpr=0.0196 | 14400.6 samples/s | 56.3 steps/s
Avg test loss: 0.13567, Avg test acc: 0.97954, Avg tpr: 0.93384, Avg fpr: 0.01963, total FA: 2725

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13856 | acc=0.9777 | tpr=0.9558 | fpr=0.0220 | 4600.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.14026 | acc=0.9782 | tpr=0.9680 | fpr=0.0216 | 6664.8 samples/s | 26.0 steps/s
[Step= 150] | Loss=0.14619 | acc=0.9773 | tpr=0.9654 | fpr=0.0224 | 6715.1 samples/s | 26.2 steps/s
[Step= 200] | Loss=0.14907 | acc=0.9773 | tpr=0.9650 | fpr=0.0225 | 7683.1 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.14681 | acc=0.9775 | tpr=0.9624 | fpr=0.0223 | 7642.4 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.15017 | acc=0.9769 | tpr=0.9585 | fpr=0.0228 | 7932.7 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.14983 | acc=0.9769 | tpr=0.9580 | fpr=0.0228 | 7780.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.15116 | acc=0.9768 | tpr=0.9557 | fpr=0.0229 | 7689.3 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.15365 | acc=0.9764 | tpr=0.9542 | fpr=0.0232 | 7900.2 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.15279 | acc=0.9765 | tpr=0.9537 | fpr=0.0230 | 7908.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.15133 | acc=0.9769 | tpr=0.9538 | fpr=0.0227 | 13773.0 samples/s | 53.8 steps/s
Avg test loss: 0.15121, Avg test acc: 0.97688, Avg tpr: 0.95365, Avg fpr: 0.02270, total FA: 3152

server round 17/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=66.3] | Loss=0.00102 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.179 | L2-Norm(final)=7.490 | 6273.0 samples/s | 98.0 steps/s
[Step=34050 Epoch=66.4] | Loss=0.01144 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.189 | L2-Norm(final)=7.500 | 4545.8 samples/s | 71.0 steps/s
[Step=34100 Epoch=66.5] | Loss=0.01046 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.196 | L2-Norm(final)=7.516 | 5052.2 samples/s | 78.9 steps/s
[Step=34150 Epoch=66.6] | Loss=0.01139 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.201 | L2-Norm(final)=7.530 | 4911.8 samples/s | 76.7 steps/s
[Step=34200 Epoch=66.7] | Loss=0.01102 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.205 | L2-Norm(final)=7.543 | 5014.9 samples/s | 78.4 steps/s
[Step=34250 Epoch=66.8] | Loss=0.01079 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.209 | L2-Norm(final)=7.555 | 5096.2 samples/s | 79.6 steps/s
[Step=34300 Epoch=66.9] | Loss=0.01048 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.212 | L2-Norm(final)=7.568 | 5115.7 samples/s | 79.9 steps/s
[Step=34350 Epoch=67.0] | Loss=0.01014 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.214 | L2-Norm(final)=7.580 | 4766.9 samples/s | 74.5 steps/s
[Step=34400 Epoch=67.1] | Loss=0.01022 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.215 | L2-Norm(final)=7.591 | 5185.6 samples/s | 81.0 steps/s
[Step=34450 Epoch=67.2] | Loss=0.01038 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.218 | L2-Norm(final)=7.602 | 5010.7 samples/s | 78.3 steps/s
[Step=34500 Epoch=67.3] | Loss=0.01044 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.220 | L2-Norm(final)=7.612 | 6651.6 samples/s | 103.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=67.3] | Loss=0.00176 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.242 | L2-Norm(final)=7.715 | 6394.2 samples/s | 99.9 steps/s
[Step=34550 Epoch=67.4] | Loss=0.01043 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.248 | L2-Norm(final)=7.724 | 2595.7 samples/s | 40.6 steps/s
[Step=34600 Epoch=67.5] | Loss=0.01127 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.252 | L2-Norm(final)=7.727 | 4493.5 samples/s | 70.2 steps/s
[Step=34650 Epoch=67.6] | Loss=0.01139 | Reg=0.00410 | acc=0.9844 | L2-Norm=20.256 | L2-Norm(final)=7.728 | 4210.1 samples/s | 65.8 steps/s
[Step=34700 Epoch=67.7] | Loss=0.01140 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.258 | L2-Norm(final)=7.731 | 4443.2 samples/s | 69.4 steps/s
[Step=34750 Epoch=67.8] | Loss=0.01223 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.260 | L2-Norm(final)=7.732 | 4282.4 samples/s | 66.9 steps/s
[Step=34800 Epoch=67.9] | Loss=0.01292 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.265 | L2-Norm(final)=7.732 | 4487.2 samples/s | 70.1 steps/s
[Step=34850 Epoch=68.0] | Loss=0.01316 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.271 | L2-Norm(final)=7.733 | 4467.2 samples/s | 69.8 steps/s
[Step=34900 Epoch=68.1] | Loss=0.01326 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.277 | L2-Norm(final)=7.733 | 4264.6 samples/s | 66.6 steps/s
[Step=34950 Epoch=68.2] | Loss=0.01319 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.283 | L2-Norm(final)=7.734 | 4424.0 samples/s | 69.1 steps/s
[Step=35000 Epoch=68.3] | Loss=0.01371 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.289 | L2-Norm(final)=7.735 | 5727.0 samples/s | 89.5 steps/s
[Step=35050 Epoch=68.4] | Loss=0.01378 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.295 | L2-Norm(final)=7.735 | 2370.9 samples/s | 37.0 steps/s
[Step=35100 Epoch=68.5] | Loss=0.01366 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.301 | L2-Norm(final)=7.736 | 4402.7 samples/s | 68.8 steps/s
[Step=35150 Epoch=68.6] | Loss=0.01345 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.306 | L2-Norm(final)=7.737 | 4462.7 samples/s | 69.7 steps/s
[Step=35200 Epoch=68.7] | Loss=0.01356 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.311 | L2-Norm(final)=7.738 | 4471.2 samples/s | 69.9 steps/s
[Step=35250 Epoch=68.8] | Loss=0.01365 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.316 | L2-Norm(final)=7.738 | 4450.3 samples/s | 69.5 steps/s
[Step=35300 Epoch=68.8] | Loss=0.01353 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.321 | L2-Norm(final)=7.739 | 4488.6 samples/s | 70.1 steps/s
[Step=35350 Epoch=68.9] | Loss=0.01346 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.325 | L2-Norm(final)=7.741 | 4343.4 samples/s | 67.9 steps/s
[Step=35400 Epoch=69.0] | Loss=0.01332 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.329 | L2-Norm(final)=7.742 | 4446.0 samples/s | 69.5 steps/s
[Step=35450 Epoch=69.1] | Loss=0.01331 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.333 | L2-Norm(final)=7.743 | 4480.9 samples/s | 70.0 steps/s
[Step=35500 Epoch=69.2] | Loss=0.01324 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.337 | L2-Norm(final)=7.744 | 4805.6 samples/s | 75.1 steps/s
[Step=35550 Epoch=69.3] | Loss=0.01332 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.340 | L2-Norm(final)=7.745 | 2593.3 samples/s | 40.5 steps/s
[Step=35600 Epoch=69.4] | Loss=0.01326 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.344 | L2-Norm(final)=7.746 | 4549.7 samples/s | 71.1 steps/s
[Step=35650 Epoch=69.5] | Loss=0.01318 | Reg=0.00414 | acc=0.9688 | L2-Norm=20.347 | L2-Norm(final)=7.747 | 4355.7 samples/s | 68.1 steps/s
[Step=35700 Epoch=69.6] | Loss=0.01302 | Reg=0.00414 | acc=0.9688 | L2-Norm=20.350 | L2-Norm(final)=7.748 | 4508.1 samples/s | 70.4 steps/s
[Step=35750 Epoch=69.7] | Loss=0.01287 | Reg=0.00414 | acc=0.9688 | L2-Norm=20.352 | L2-Norm(final)=7.749 | 4398.5 samples/s | 68.7 steps/s
[Step=35800 Epoch=69.8] | Loss=0.01273 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.355 | L2-Norm(final)=7.750 | 4463.7 samples/s | 69.7 steps/s
[Step=35850 Epoch=69.9] | Loss=0.01277 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.357 | L2-Norm(final)=7.752 | 4469.7 samples/s | 69.8 steps/s
[Step=35900 Epoch=70.0] | Loss=0.01273 | Reg=0.00414 | acc=0.9688 | L2-Norm=20.359 | L2-Norm(final)=7.753 | 4444.9 samples/s | 69.5 steps/s
[Step=35950 Epoch=70.1] | Loss=0.01264 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.361 | L2-Norm(final)=7.754 | 4435.2 samples/s | 69.3 steps/s
[Step=36000 Epoch=70.2] | Loss=0.01253 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.363 | L2-Norm(final)=7.755 | 4448.5 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step36000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=66.5] | Loss=0.01798 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.170 | L2-Norm(final)=7.642 | 5718.6 samples/s | 89.4 steps/s
[Step=34050 Epoch=66.6] | Loss=0.01164 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.169 | L2-Norm(final)=7.643 | 4442.2 samples/s | 69.4 steps/s
[Step=34100 Epoch=66.7] | Loss=0.01245 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.171 | L2-Norm(final)=7.650 | 5020.4 samples/s | 78.4 steps/s
[Step=34150 Epoch=66.8] | Loss=0.01146 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.171 | L2-Norm(final)=7.658 | 4889.3 samples/s | 76.4 steps/s
[Step=34200 Epoch=66.9] | Loss=0.01143 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.172 | L2-Norm(final)=7.667 | 5056.8 samples/s | 79.0 steps/s
[Step=34250 Epoch=67.0] | Loss=0.01113 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.172 | L2-Norm(final)=7.676 | 4950.0 samples/s | 77.3 steps/s
[Step=34300 Epoch=67.1] | Loss=0.01080 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.173 | L2-Norm(final)=7.685 | 5054.0 samples/s | 79.0 steps/s
[Step=34350 Epoch=67.2] | Loss=0.01043 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.173 | L2-Norm(final)=7.694 | 5028.4 samples/s | 78.6 steps/s
[Step=34400 Epoch=67.3] | Loss=0.01031 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.174 | L2-Norm(final)=7.704 | 5115.7 samples/s | 79.9 steps/s
[Step=34450 Epoch=67.3] | Loss=0.01001 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.174 | L2-Norm(final)=7.713 | 4929.3 samples/s | 77.0 steps/s
[Step=34500 Epoch=67.4] | Loss=0.00986 | Reg=0.00407 | acc=0.9531 | L2-Norm=20.174 | L2-Norm(final)=7.723 | 6924.1 samples/s | 108.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=67.4] | Loss=0.00582 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.175 | L2-Norm(final)=7.820 | 6342.9 samples/s | 99.1 steps/s
[Step=34550 Epoch=67.5] | Loss=0.01285 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.179 | L2-Norm(final)=7.823 | 3927.5 samples/s | 61.4 steps/s
[Step=34600 Epoch=67.6] | Loss=0.01379 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.188 | L2-Norm(final)=7.823 | 4444.4 samples/s | 69.4 steps/s
[Step=34650 Epoch=67.7] | Loss=0.01314 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.199 | L2-Norm(final)=7.826 | 4498.8 samples/s | 70.3 steps/s
[Step=34700 Epoch=67.8] | Loss=0.01349 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.206 | L2-Norm(final)=7.829 | 4455.0 samples/s | 69.6 steps/s
[Step=34750 Epoch=67.9] | Loss=0.01401 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.213 | L2-Norm(final)=7.831 | 4403.9 samples/s | 68.8 steps/s
[Step=34800 Epoch=68.0] | Loss=0.01402 | Reg=0.00409 | acc=0.9688 | L2-Norm=20.220 | L2-Norm(final)=7.834 | 4565.5 samples/s | 71.3 steps/s
[Step=34850 Epoch=68.1] | Loss=0.01446 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.227 | L2-Norm(final)=7.838 | 4325.5 samples/s | 67.6 steps/s
[Step=34900 Epoch=68.2] | Loss=0.01443 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.235 | L2-Norm(final)=7.840 | 4447.5 samples/s | 69.5 steps/s
[Step=34950 Epoch=68.3] | Loss=0.01436 | Reg=0.00410 | acc=0.9688 | L2-Norm=20.244 | L2-Norm(final)=7.842 | 4421.5 samples/s | 69.1 steps/s
[Step=35000 Epoch=68.4] | Loss=0.01432 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.254 | L2-Norm(final)=7.845 | 5791.9 samples/s | 90.5 steps/s
[Step=35050 Epoch=68.5] | Loss=0.01417 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.262 | L2-Norm(final)=7.847 | 2393.3 samples/s | 37.4 steps/s
[Step=35100 Epoch=68.6] | Loss=0.01396 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.270 | L2-Norm(final)=7.849 | 4487.6 samples/s | 70.1 steps/s
[Step=35150 Epoch=68.7] | Loss=0.01358 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.278 | L2-Norm(final)=7.852 | 4355.0 samples/s | 68.0 steps/s
[Step=35200 Epoch=68.8] | Loss=0.01350 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.285 | L2-Norm(final)=7.855 | 4496.0 samples/s | 70.3 steps/s
[Step=35250 Epoch=68.9] | Loss=0.01343 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.291 | L2-Norm(final)=7.858 | 4399.0 samples/s | 68.7 steps/s
[Step=35300 Epoch=69.0] | Loss=0.01345 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.296 | L2-Norm(final)=7.860 | 4374.3 samples/s | 68.3 steps/s
[Step=35350 Epoch=69.1] | Loss=0.01341 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.301 | L2-Norm(final)=7.863 | 4523.6 samples/s | 70.7 steps/s
[Step=35400 Epoch=69.2] | Loss=0.01312 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.306 | L2-Norm(final)=7.865 | 4395.6 samples/s | 68.7 steps/s
[Step=35450 Epoch=69.3] | Loss=0.01307 | Reg=0.00412 | acc=0.9688 | L2-Norm=20.310 | L2-Norm(final)=7.867 | 4473.5 samples/s | 69.9 steps/s
[Step=35500 Epoch=69.4] | Loss=0.01298 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.314 | L2-Norm(final)=7.870 | 4909.6 samples/s | 76.7 steps/s
[Step=35550 Epoch=69.5] | Loss=0.01279 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.317 | L2-Norm(final)=7.872 | 2563.7 samples/s | 40.1 steps/s
[Step=35600 Epoch=69.6] | Loss=0.01263 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.320 | L2-Norm(final)=7.874 | 4475.3 samples/s | 69.9 steps/s
[Step=35650 Epoch=69.7] | Loss=0.01243 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.322 | L2-Norm(final)=7.876 | 4544.6 samples/s | 71.0 steps/s
[Step=35700 Epoch=69.8] | Loss=0.01234 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.323 | L2-Norm(final)=7.879 | 4310.7 samples/s | 67.4 steps/s
[Step=35750 Epoch=69.9] | Loss=0.01216 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.325 | L2-Norm(final)=7.881 | 4393.0 samples/s | 68.6 steps/s
[Step=35800 Epoch=70.0] | Loss=0.01207 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.327 | L2-Norm(final)=7.883 | 4587.4 samples/s | 71.7 steps/s
[Step=35850 Epoch=70.1] | Loss=0.01192 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.328 | L2-Norm(final)=7.885 | 4316.2 samples/s | 67.4 steps/s
[Step=35900 Epoch=70.2] | Loss=0.01183 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.330 | L2-Norm(final)=7.888 | 4507.3 samples/s | 70.4 steps/s
[Step=35950 Epoch=70.3] | Loss=0.01181 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.331 | L2-Norm(final)=7.890 | 4491.8 samples/s | 70.2 steps/s
[Step=36000 Epoch=70.4] | Loss=0.01184 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.333 | L2-Norm(final)=7.893 | 4458.1 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step36000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=130.3] | Loss=0.00014 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.175 | L2-Norm(final)=5.114 | 6642.1 samples/s | 103.8 steps/s
[Step=34050 Epoch=130.5] | Loss=0.00012 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.178 | L2-Norm(final)=5.118 | 3936.7 samples/s | 61.5 steps/s
[Step=34100 Epoch=130.7] | Loss=0.00010 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.185 | L2-Norm(final)=5.124 | 4752.8 samples/s | 74.3 steps/s
[Step=34150 Epoch=130.9] | Loss=0.00008 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=5.129 | 4866.1 samples/s | 76.0 steps/s
[Step=34200 Epoch=131.0] | Loss=0.00007 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.187 | L2-Norm(final)=5.132 | 4620.4 samples/s | 72.2 steps/s
[Step=34250 Epoch=131.2] | Loss=0.00007 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=5.135 | 6501.6 samples/s | 101.6 steps/s
[Step=34300 Epoch=131.4] | Loss=0.00007 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=5.139 | 2408.6 samples/s | 37.6 steps/s
[Step=34350 Epoch=131.6] | Loss=0.00006 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=5.142 | 4738.4 samples/s | 74.0 steps/s
[Step=34400 Epoch=131.8] | Loss=0.00006 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=5.145 | 4663.3 samples/s | 72.9 steps/s
[Step=34450 Epoch=132.0] | Loss=0.00006 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.185 | L2-Norm(final)=5.148 | 4706.3 samples/s | 73.5 steps/s
[Step=34500 Epoch=132.2] | Loss=0.00005 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.184 | L2-Norm(final)=5.151 | 5424.9 samples/s | 84.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=132.2] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.174 | L2-Norm(final)=5.178 | 6067.2 samples/s | 94.8 steps/s
[Step=34550 Epoch=132.4] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.168 | L2-Norm(final)=5.181 | 3807.9 samples/s | 59.5 steps/s
[Step=34600 Epoch=132.6] | Loss=0.00003 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.161 | L2-Norm(final)=5.184 | 4054.1 samples/s | 63.3 steps/s
[Step=34650 Epoch=132.8] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.153 | L2-Norm(final)=5.187 | 4053.8 samples/s | 63.3 steps/s
[Step=34700 Epoch=133.0] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.145 | L2-Norm(final)=5.189 | 4150.1 samples/s | 64.8 steps/s
[Step=34750 Epoch=133.1] | Loss=0.00002 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.137 | L2-Norm(final)=5.190 | 5434.7 samples/s | 84.9 steps/s
[Step=34800 Epoch=133.3] | Loss=0.00002 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.129 | L2-Norm(final)=5.192 | 2220.6 samples/s | 34.7 steps/s
[Step=34850 Epoch=133.5] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.120 | L2-Norm(final)=5.193 | 4037.0 samples/s | 63.1 steps/s
[Step=34900 Epoch=133.7] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.112 | L2-Norm(final)=5.194 | 4091.0 samples/s | 63.9 steps/s
[Step=34950 Epoch=133.9] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.103 | L2-Norm(final)=5.195 | 4140.5 samples/s | 64.7 steps/s
[Step=35000 Epoch=134.1] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.094 | L2-Norm(final)=5.197 | 4672.4 samples/s | 73.0 steps/s
[Step=35050 Epoch=134.3] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.085 | L2-Norm(final)=5.198 | 2391.0 samples/s | 37.4 steps/s
[Step=35100 Epoch=134.5] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.076 | L2-Norm(final)=5.199 | 4115.2 samples/s | 64.3 steps/s
[Step=35150 Epoch=134.7] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.067 | L2-Norm(final)=5.199 | 4077.8 samples/s | 63.7 steps/s
[Step=35200 Epoch=134.9] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.058 | L2-Norm(final)=5.200 | 4136.9 samples/s | 64.6 steps/s
[Step=35250 Epoch=135.1] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.049 | L2-Norm(final)=5.201 | 4109.4 samples/s | 64.2 steps/s
[Step=35300 Epoch=135.3] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.039 | L2-Norm(final)=5.202 | 2600.4 samples/s | 40.6 steps/s
[Step=35350 Epoch=135.4] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.030 | L2-Norm(final)=5.203 | 4038.3 samples/s | 63.1 steps/s
[Step=35400 Epoch=135.6] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.020 | L2-Norm(final)=5.204 | 4168.5 samples/s | 65.1 steps/s
[Step=35450 Epoch=135.8] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.011 | L2-Norm(final)=5.205 | 4109.5 samples/s | 64.2 steps/s
[Step=35500 Epoch=136.0] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.001 | L2-Norm(final)=5.205 | 4054.7 samples/s | 63.4 steps/s
[Step=35550 Epoch=136.2] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.991 | L2-Norm(final)=5.206 | 2539.1 samples/s | 39.7 steps/s
[Step=35600 Epoch=136.4] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.981 | L2-Norm(final)=5.207 | 4139.9 samples/s | 64.7 steps/s
[Step=35650 Epoch=136.6] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.971 | L2-Norm(final)=5.208 | 4118.9 samples/s | 64.4 steps/s
[Step=35700 Epoch=136.8] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=5.209 | 4122.4 samples/s | 64.4 steps/s
[Step=35750 Epoch=137.0] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.951 | L2-Norm(final)=5.209 | 4137.9 samples/s | 64.7 steps/s
[Step=35800 Epoch=137.2] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.940 | L2-Norm(final)=5.210 | 6116.9 samples/s | 95.6 steps/s
[Step=35850 Epoch=137.4] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.930 | L2-Norm(final)=5.211 | 2123.6 samples/s | 33.2 steps/s
[Step=35900 Epoch=137.6] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.919 | L2-Norm(final)=5.212 | 4055.9 samples/s | 63.4 steps/s
[Step=35950 Epoch=137.7] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.908 | L2-Norm(final)=5.213 | 4204.3 samples/s | 65.7 steps/s
[Step=36000 Epoch=137.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.898 | L2-Norm(final)=5.213 | 4111.7 samples/s | 64.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step36000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=130.9] | Loss=0.00003 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.114 | L2-Norm(final)=5.523 | 6304.3 samples/s | 98.5 steps/s
[Step=34050 Epoch=131.1] | Loss=0.00086 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.130 | L2-Norm(final)=5.536 | 4025.9 samples/s | 62.9 steps/s
[Step=34100 Epoch=131.3] | Loss=0.00077 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.164 | L2-Norm(final)=5.546 | 4646.3 samples/s | 72.6 steps/s
[Step=34150 Epoch=131.5] | Loss=0.00053 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.181 | L2-Norm(final)=5.555 | 4675.6 samples/s | 73.1 steps/s
[Step=34200 Epoch=131.6] | Loss=0.00041 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.189 | L2-Norm(final)=5.562 | 4534.8 samples/s | 70.9 steps/s
[Step=34250 Epoch=131.8] | Loss=0.00034 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.193 | L2-Norm(final)=5.567 | 6377.4 samples/s | 99.6 steps/s
[Step=34300 Epoch=132.0] | Loss=0.00032 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.197 | L2-Norm(final)=5.572 | 2334.9 samples/s | 36.5 steps/s
[Step=34350 Epoch=132.2] | Loss=0.00028 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.201 | L2-Norm(final)=5.577 | 4655.5 samples/s | 72.7 steps/s
[Step=34400 Epoch=132.4] | Loss=0.00025 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.203 | L2-Norm(final)=5.582 | 4541.8 samples/s | 71.0 steps/s
[Step=34450 Epoch=132.6] | Loss=0.00022 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.204 | L2-Norm(final)=5.586 | 4747.9 samples/s | 74.2 steps/s
[Step=34500 Epoch=132.8] | Loss=0.00021 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.205 | L2-Norm(final)=5.590 | 5388.5 samples/s | 84.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=132.8] | Loss=0.00002 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.210 | L2-Norm(final)=5.636 | 6113.7 samples/s | 95.5 steps/s
[Step=34550 Epoch=133.0] | Loss=0.00003 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.201 | L2-Norm(final)=5.639 | 3698.5 samples/s | 57.8 steps/s
[Step=34600 Epoch=133.2] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.185 | L2-Norm(final)=5.642 | 4209.4 samples/s | 65.8 steps/s
[Step=34650 Epoch=133.4] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.168 | L2-Norm(final)=5.644 | 4209.9 samples/s | 65.8 steps/s
[Step=34700 Epoch=133.6] | Loss=0.00002 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.150 | L2-Norm(final)=5.646 | 4256.5 samples/s | 66.5 steps/s
[Step=34750 Epoch=133.8] | Loss=0.00002 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.133 | L2-Norm(final)=5.647 | 5410.8 samples/s | 84.5 steps/s
[Step=34800 Epoch=134.0] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.115 | L2-Norm(final)=5.649 | 2155.2 samples/s | 33.7 steps/s
[Step=34850 Epoch=134.2] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.097 | L2-Norm(final)=5.650 | 4068.4 samples/s | 63.6 steps/s
[Step=34900 Epoch=134.3] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.079 | L2-Norm(final)=5.651 | 4049.5 samples/s | 63.3 steps/s
[Step=34950 Epoch=134.5] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.061 | L2-Norm(final)=5.652 | 4006.9 samples/s | 62.6 steps/s
[Step=35000 Epoch=134.7] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.043 | L2-Norm(final)=5.653 | 4759.4 samples/s | 74.4 steps/s
[Step=35050 Epoch=134.9] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.024 | L2-Norm(final)=5.654 | 2309.5 samples/s | 36.1 steps/s
[Step=35100 Epoch=135.1] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.005 | L2-Norm(final)=5.655 | 4060.8 samples/s | 63.4 steps/s
[Step=35150 Epoch=135.3] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.987 | L2-Norm(final)=5.656 | 4061.8 samples/s | 63.5 steps/s
[Step=35200 Epoch=135.5] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.968 | L2-Norm(final)=5.656 | 4058.5 samples/s | 63.4 steps/s
[Step=35250 Epoch=135.7] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.949 | L2-Norm(final)=5.657 | 4258.2 samples/s | 66.5 steps/s
[Step=35300 Epoch=135.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.930 | L2-Norm(final)=5.657 | 2532.3 samples/s | 39.6 steps/s
[Step=35350 Epoch=136.1] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.911 | L2-Norm(final)=5.658 | 4217.7 samples/s | 65.9 steps/s
[Step=35400 Epoch=136.3] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.891 | L2-Norm(final)=5.659 | 4243.5 samples/s | 66.3 steps/s
[Step=35450 Epoch=136.5] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.872 | L2-Norm(final)=5.659 | 4194.5 samples/s | 65.5 steps/s
[Step=35500 Epoch=136.7] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.852 | L2-Norm(final)=5.660 | 4199.6 samples/s | 65.6 steps/s
[Step=35550 Epoch=136.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.832 | L2-Norm(final)=5.660 | 2614.9 samples/s | 40.9 steps/s
[Step=35600 Epoch=137.0] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.813 | L2-Norm(final)=5.661 | 4104.9 samples/s | 64.1 steps/s
[Step=35650 Epoch=137.2] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.793 | L2-Norm(final)=5.662 | 4201.2 samples/s | 65.6 steps/s
[Step=35700 Epoch=137.4] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.773 | L2-Norm(final)=5.662 | 4224.8 samples/s | 66.0 steps/s
[Step=35750 Epoch=137.6] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.752 | L2-Norm(final)=5.663 | 4124.9 samples/s | 64.5 steps/s
[Step=35800 Epoch=137.8] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.732 | L2-Norm(final)=5.663 | 7010.9 samples/s | 109.5 steps/s
[Step=35850 Epoch=138.0] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.712 | L2-Norm(final)=5.664 | 2095.1 samples/s | 32.7 steps/s
[Step=35900 Epoch=138.2] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.691 | L2-Norm(final)=5.664 | 4172.1 samples/s | 65.2 steps/s
[Step=35950 Epoch=138.4] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.670 | L2-Norm(final)=5.665 | 4340.7 samples/s | 67.8 steps/s
[Step=36000 Epoch=138.6] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.649 | L2-Norm(final)=5.666 | 4028.7 samples/s | 62.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07321 | acc=0.9676 | tpr=0.9743 | fpr=0.0471 | 4830.6 samples/s | 18.9 steps/s
Avg test loss: 0.07258, Avg test acc: 0.96682, Avg tpr: 0.97400, Avg fpr: 0.04897, total FA: 382

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08361 | acc=0.9660 | tpr=0.9781 | fpr=0.0602 | 4874.7 samples/s | 19.0 steps/s
Avg test loss: 0.08338, Avg test acc: 0.96530, Avg tpr: 0.97750, Avg fpr: 0.06153, total FA: 480

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.74493 | acc=0.3003 | tpr=0.0100 | fpr=0.0694 | 5069.6 samples/s | 19.8 steps/s
Avg test loss: 5.73929, Avg test acc: 0.29790, Avg tpr: 0.01102, Avg fpr: 0.07114, total FA: 555

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.21967 | acc=0.3123 | tpr=0.0251 | fpr=0.0639 | 4943.6 samples/s | 19.3 steps/s
Avg test loss: 6.20764, Avg test acc: 0.31028, Avg tpr: 0.02664, Avg fpr: 0.06589, total FA: 514

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.19171 | acc=0.1516 | tpr=0.5973 | fpr=0.8564 | 4841.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.16015 | acc=0.1519 | tpr=0.5757 | fpr=0.8560 | 7291.5 samples/s | 28.5 steps/s
[Step= 150] | Loss=6.16882 | acc=0.1515 | tpr=0.5764 | fpr=0.8563 | 7676.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.16181 | acc=0.1517 | tpr=0.5694 | fpr=0.8559 | 7976.6 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.15589 | acc=0.1519 | tpr=0.5747 | fpr=0.8558 | 7777.0 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.14539 | acc=0.1525 | tpr=0.5687 | fpr=0.8551 | 7800.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=6.15013 | acc=0.1521 | tpr=0.5617 | fpr=0.8553 | 7869.4 samples/s | 30.7 steps/s
[Step= 400] | Loss=6.15537 | acc=0.1519 | tpr=0.5558 | fpr=0.8554 | 7528.2 samples/s | 29.4 steps/s
[Step= 450] | Loss=6.16096 | acc=0.1515 | tpr=0.5579 | fpr=0.8559 | 8000.9 samples/s | 31.3 steps/s
[Step= 500] | Loss=6.16287 | acc=0.1514 | tpr=0.5586 | fpr=0.8559 | 8169.3 samples/s | 31.9 steps/s
[Step= 550] | Loss=6.16895 | acc=0.1514 | tpr=0.5599 | fpr=0.8560 | 13140.1 samples/s | 51.3 steps/s
Avg test loss: 6.17135, Avg test acc: 0.15137, Avg tpr: 0.56062, Avg fpr: 0.85607, total FA: 118863

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.90295 | acc=0.1135 | tpr=0.6681 | fpr=0.8965 | 4927.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=8.85350 | acc=0.1125 | tpr=0.6055 | fpr=0.8967 | 6969.7 samples/s | 27.2 steps/s
[Step= 150] | Loss=8.85958 | acc=0.1123 | tpr=0.6081 | fpr=0.8969 | 7940.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=8.84893 | acc=0.1131 | tpr=0.6044 | fpr=0.8959 | 7641.3 samples/s | 29.8 steps/s
[Step= 250] | Loss=8.84548 | acc=0.1131 | tpr=0.6061 | fpr=0.8959 | 7859.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=8.83639 | acc=0.1133 | tpr=0.6015 | fpr=0.8956 | 7765.8 samples/s | 30.3 steps/s
[Step= 350] | Loss=8.84339 | acc=0.1131 | tpr=0.5961 | fpr=0.8957 | 8101.7 samples/s | 31.6 steps/s
[Step= 400] | Loss=8.84595 | acc=0.1128 | tpr=0.5914 | fpr=0.8959 | 7798.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=8.85323 | acc=0.1126 | tpr=0.5964 | fpr=0.8962 | 7677.4 samples/s | 30.0 steps/s
[Step= 500] | Loss=8.85537 | acc=0.1127 | tpr=0.5965 | fpr=0.8960 | 7801.6 samples/s | 30.5 steps/s
[Step= 550] | Loss=8.86065 | acc=0.1125 | tpr=0.5945 | fpr=0.8962 | 14112.0 samples/s | 55.1 steps/s
Avg test loss: 8.86339, Avg test acc: 0.11245, Avg tpr: 0.59469, Avg fpr: 0.89632, total FA: 124452

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12988 | acc=0.9796 | tpr=0.9381 | fpr=0.0196 | 5084.6 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.13353 | acc=0.9800 | tpr=0.9446 | fpr=0.0193 | 6828.8 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.13966 | acc=0.9793 | tpr=0.9452 | fpr=0.0201 | 7620.7 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.14332 | acc=0.9792 | tpr=0.9475 | fpr=0.0202 | 7813.9 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.14122 | acc=0.9793 | tpr=0.9459 | fpr=0.0200 | 8075.7 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.14354 | acc=0.9790 | tpr=0.9404 | fpr=0.0203 | 7757.0 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.14382 | acc=0.9790 | tpr=0.9424 | fpr=0.0204 | 7695.4 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.14577 | acc=0.9789 | tpr=0.9404 | fpr=0.0204 | 7768.3 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.14869 | acc=0.9785 | tpr=0.9387 | fpr=0.0208 | 7943.9 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14753 | acc=0.9786 | tpr=0.9396 | fpr=0.0207 | 7732.2 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.14604 | acc=0.9790 | tpr=0.9415 | fpr=0.0203 | 13878.4 samples/s | 54.2 steps/s
Avg test loss: 0.14579, Avg test acc: 0.97898, Avg tpr: 0.94136, Avg fpr: 0.02033, total FA: 2823

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14635 | acc=0.9780 | tpr=0.9558 | fpr=0.0216 | 4788.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.14940 | acc=0.9783 | tpr=0.9680 | fpr=0.0215 | 7264.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.15735 | acc=0.9771 | tpr=0.9654 | fpr=0.0226 | 7955.6 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.16085 | acc=0.9771 | tpr=0.9650 | fpr=0.0227 | 7853.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.15844 | acc=0.9772 | tpr=0.9616 | fpr=0.0225 | 8230.4 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.16164 | acc=0.9768 | tpr=0.9607 | fpr=0.0229 | 7592.5 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.16152 | acc=0.9766 | tpr=0.9612 | fpr=0.0231 | 7392.1 samples/s | 28.9 steps/s
[Step= 400] | Loss=0.16311 | acc=0.9766 | tpr=0.9601 | fpr=0.0231 | 7987.4 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.16586 | acc=0.9762 | tpr=0.9581 | fpr=0.0235 | 7887.0 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.16479 | acc=0.9764 | tpr=0.9577 | fpr=0.0233 | 7861.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.16306 | acc=0.9767 | tpr=0.9578 | fpr=0.0229 | 13755.3 samples/s | 53.7 steps/s
Avg test loss: 0.16289, Avg test acc: 0.97674, Avg tpr: 0.95761, Avg fpr: 0.02291, total FA: 3181

server round 18/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=70.2] | Loss=0.02411 | Reg=0.00400 | acc=0.9844 | L2-Norm=20.009 | L2-Norm(final)=7.797 | 6288.0 samples/s | 98.3 steps/s
[Step=36050 Epoch=70.3] | Loss=0.00893 | Reg=0.00400 | acc=1.0000 | L2-Norm=20.006 | L2-Norm(final)=7.803 | 4436.8 samples/s | 69.3 steps/s
[Step=36100 Epoch=70.4] | Loss=0.00824 | Reg=0.00400 | acc=1.0000 | L2-Norm=20.002 | L2-Norm(final)=7.810 | 5054.6 samples/s | 79.0 steps/s
[Step=36150 Epoch=70.5] | Loss=0.00775 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.997 | L2-Norm(final)=7.816 | 5147.9 samples/s | 80.4 steps/s
[Step=36200 Epoch=70.6] | Loss=0.00682 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.992 | L2-Norm(final)=7.823 | 4844.1 samples/s | 75.7 steps/s
[Step=36250 Epoch=70.7] | Loss=0.00669 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.986 | L2-Norm(final)=7.830 | 4928.9 samples/s | 77.0 steps/s
[Step=36300 Epoch=70.8] | Loss=0.00673 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.980 | L2-Norm(final)=7.837 | 5015.2 samples/s | 78.4 steps/s
[Step=36350 Epoch=70.9] | Loss=0.00685 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.975 | L2-Norm(final)=7.843 | 5105.2 samples/s | 79.8 steps/s
[Step=36400 Epoch=71.0] | Loss=0.00679 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.970 | L2-Norm(final)=7.848 | 4942.0 samples/s | 77.2 steps/s
[Step=36450 Epoch=71.1] | Loss=0.00699 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.966 | L2-Norm(final)=7.854 | 5153.9 samples/s | 80.5 steps/s
[Step=36500 Epoch=71.2] | Loss=0.00690 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.961 | L2-Norm(final)=7.860 | 6444.0 samples/s | 100.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=71.2] | Loss=0.00429 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.914 | L2-Norm(final)=7.915 | 5933.1 samples/s | 92.7 steps/s
[Step=36550 Epoch=71.3] | Loss=0.00594 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.910 | L2-Norm(final)=7.921 | 4154.0 samples/s | 64.9 steps/s
[Step=36600 Epoch=71.4] | Loss=0.00829 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.908 | L2-Norm(final)=7.924 | 4484.0 samples/s | 70.1 steps/s
[Step=36650 Epoch=71.5] | Loss=0.00885 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.907 | L2-Norm(final)=7.926 | 4499.2 samples/s | 70.3 steps/s
[Step=36700 Epoch=71.6] | Loss=0.00964 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.907 | L2-Norm(final)=7.928 | 4493.8 samples/s | 70.2 steps/s
[Step=36750 Epoch=71.7] | Loss=0.01011 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.909 | L2-Norm(final)=7.929 | 4287.7 samples/s | 67.0 steps/s
[Step=36800 Epoch=71.8] | Loss=0.01036 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.911 | L2-Norm(final)=7.932 | 4445.9 samples/s | 69.5 steps/s
[Step=36850 Epoch=71.9] | Loss=0.01054 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.915 | L2-Norm(final)=7.936 | 4445.5 samples/s | 69.5 steps/s
[Step=36900 Epoch=72.0] | Loss=0.01108 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.919 | L2-Norm(final)=7.938 | 4457.4 samples/s | 69.6 steps/s
[Step=36950 Epoch=72.1] | Loss=0.01133 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.924 | L2-Norm(final)=7.940 | 4433.7 samples/s | 69.3 steps/s
[Step=37000 Epoch=72.2] | Loss=0.01157 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.928 | L2-Norm(final)=7.943 | 5754.1 samples/s | 89.9 steps/s
[Step=37050 Epoch=72.3] | Loss=0.01143 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.932 | L2-Norm(final)=7.945 | 2367.1 samples/s | 37.0 steps/s
[Step=37100 Epoch=72.4] | Loss=0.01146 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.936 | L2-Norm(final)=7.947 | 4453.7 samples/s | 69.6 steps/s
[Step=37150 Epoch=72.5] | Loss=0.01143 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.940 | L2-Norm(final)=7.950 | 4455.4 samples/s | 69.6 steps/s
[Step=37200 Epoch=72.6] | Loss=0.01138 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.945 | L2-Norm(final)=7.952 | 4398.6 samples/s | 68.7 steps/s
[Step=37250 Epoch=72.7] | Loss=0.01130 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.950 | L2-Norm(final)=7.954 | 4438.9 samples/s | 69.4 steps/s
[Step=37300 Epoch=72.7] | Loss=0.01131 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.954 | L2-Norm(final)=7.957 | 4473.6 samples/s | 69.9 steps/s
[Step=37350 Epoch=72.8] | Loss=0.01150 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.959 | L2-Norm(final)=7.959 | 4390.1 samples/s | 68.6 steps/s
[Step=37400 Epoch=72.9] | Loss=0.01181 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.963 | L2-Norm(final)=7.961 | 4441.4 samples/s | 69.4 steps/s
[Step=37450 Epoch=73.0] | Loss=0.01190 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.967 | L2-Norm(final)=7.963 | 4423.7 samples/s | 69.1 steps/s
[Step=37500 Epoch=73.1] | Loss=0.01189 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.971 | L2-Norm(final)=7.966 | 4754.1 samples/s | 74.3 steps/s
[Step=37550 Epoch=73.2] | Loss=0.01195 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.975 | L2-Norm(final)=7.968 | 2579.9 samples/s | 40.3 steps/s
[Step=37600 Epoch=73.3] | Loss=0.01183 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.979 | L2-Norm(final)=7.971 | 4469.7 samples/s | 69.8 steps/s
[Step=37650 Epoch=73.4] | Loss=0.01162 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.982 | L2-Norm(final)=7.973 | 4363.7 samples/s | 68.2 steps/s
[Step=37700 Epoch=73.5] | Loss=0.01152 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.985 | L2-Norm(final)=7.976 | 4443.0 samples/s | 69.4 steps/s
[Step=37750 Epoch=73.6] | Loss=0.01141 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.988 | L2-Norm(final)=7.979 | 4448.1 samples/s | 69.5 steps/s
[Step=37800 Epoch=73.7] | Loss=0.01139 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.990 | L2-Norm(final)=7.981 | 4421.5 samples/s | 69.1 steps/s
[Step=37850 Epoch=73.8] | Loss=0.01140 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.992 | L2-Norm(final)=7.984 | 4425.4 samples/s | 69.1 steps/s
[Step=37900 Epoch=73.9] | Loss=0.01141 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.994 | L2-Norm(final)=7.986 | 4444.5 samples/s | 69.4 steps/s
[Step=37950 Epoch=74.0] | Loss=0.01144 | Reg=0.00400 | acc=0.9688 | L2-Norm=19.996 | L2-Norm(final)=7.988 | 4433.4 samples/s | 69.3 steps/s
[Step=38000 Epoch=74.1] | Loss=0.01151 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.998 | L2-Norm(final)=7.990 | 4412.6 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step38000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=70.4] | Loss=0.01124 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.971 | L2-Norm(final)=7.951 | 5478.9 samples/s | 85.6 steps/s
[Step=36050 Epoch=70.5] | Loss=0.00938 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.969 | L2-Norm(final)=7.957 | 4592.4 samples/s | 71.8 steps/s
[Step=36100 Epoch=70.6] | Loss=0.00771 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.965 | L2-Norm(final)=7.967 | 4988.9 samples/s | 78.0 steps/s
[Step=36150 Epoch=70.7] | Loss=0.00738 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.960 | L2-Norm(final)=7.976 | 5174.9 samples/s | 80.9 steps/s
[Step=36200 Epoch=70.8] | Loss=0.00712 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.955 | L2-Norm(final)=7.984 | 4842.4 samples/s | 75.7 steps/s
[Step=36250 Epoch=70.9] | Loss=0.00691 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.949 | L2-Norm(final)=7.992 | 5045.6 samples/s | 78.8 steps/s
[Step=36300 Epoch=71.0] | Loss=0.00691 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.945 | L2-Norm(final)=8.000 | 4884.5 samples/s | 76.3 steps/s
[Step=36350 Epoch=71.1] | Loss=0.00684 | Reg=0.00398 | acc=0.9688 | L2-Norm=19.940 | L2-Norm(final)=8.007 | 5184.8 samples/s | 81.0 steps/s
[Step=36400 Epoch=71.2] | Loss=0.00697 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.934 | L2-Norm(final)=8.013 | 4867.1 samples/s | 76.0 steps/s
[Step=36450 Epoch=71.3] | Loss=0.00686 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.929 | L2-Norm(final)=8.019 | 4924.7 samples/s | 76.9 steps/s
[Step=36500 Epoch=71.4] | Loss=0.00677 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.924 | L2-Norm(final)=8.026 | 6900.0 samples/s | 107.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=71.4] | Loss=0.00590 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.877 | L2-Norm(final)=8.088 | 6258.0 samples/s | 97.8 steps/s
[Step=36550 Epoch=71.5] | Loss=0.00756 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.875 | L2-Norm(final)=8.093 | 4117.4 samples/s | 64.3 steps/s
[Step=36600 Epoch=71.6] | Loss=0.00937 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.874 | L2-Norm(final)=8.095 | 4332.6 samples/s | 67.7 steps/s
[Step=36650 Epoch=71.6] | Loss=0.00961 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.876 | L2-Norm(final)=8.095 | 4457.2 samples/s | 69.6 steps/s
[Step=36700 Epoch=71.7] | Loss=0.00982 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.879 | L2-Norm(final)=8.097 | 4437.2 samples/s | 69.3 steps/s
[Step=36750 Epoch=71.8] | Loss=0.01059 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.883 | L2-Norm(final)=8.100 | 4384.4 samples/s | 68.5 steps/s
[Step=36800 Epoch=71.9] | Loss=0.01065 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.887 | L2-Norm(final)=8.102 | 4386.2 samples/s | 68.5 steps/s
[Step=36850 Epoch=72.0] | Loss=0.01084 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.891 | L2-Norm(final)=8.106 | 4474.1 samples/s | 69.9 steps/s
[Step=36900 Epoch=72.1] | Loss=0.01090 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.894 | L2-Norm(final)=8.109 | 4389.2 samples/s | 68.6 steps/s
[Step=36950 Epoch=72.2] | Loss=0.01102 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.897 | L2-Norm(final)=8.112 | 4500.8 samples/s | 70.3 steps/s
[Step=37000 Epoch=72.3] | Loss=0.01127 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.899 | L2-Norm(final)=8.114 | 5795.0 samples/s | 90.5 steps/s
[Step=37050 Epoch=72.4] | Loss=0.01163 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.903 | L2-Norm(final)=8.116 | 2363.9 samples/s | 36.9 steps/s
[Step=37100 Epoch=72.5] | Loss=0.01146 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.907 | L2-Norm(final)=8.118 | 4430.0 samples/s | 69.2 steps/s
[Step=37150 Epoch=72.6] | Loss=0.01144 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.911 | L2-Norm(final)=8.121 | 4468.4 samples/s | 69.8 steps/s
[Step=37200 Epoch=72.7] | Loss=0.01156 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.914 | L2-Norm(final)=8.125 | 4352.3 samples/s | 68.0 steps/s
[Step=37250 Epoch=72.8] | Loss=0.01174 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.918 | L2-Norm(final)=8.127 | 4526.5 samples/s | 70.7 steps/s
[Step=37300 Epoch=72.9] | Loss=0.01198 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.922 | L2-Norm(final)=8.128 | 4382.0 samples/s | 68.5 steps/s
[Step=37350 Epoch=73.0] | Loss=0.01206 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.928 | L2-Norm(final)=8.130 | 4398.4 samples/s | 68.7 steps/s
[Step=37400 Epoch=73.1] | Loss=0.01223 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.933 | L2-Norm(final)=8.131 | 4472.1 samples/s | 69.9 steps/s
[Step=37450 Epoch=73.2] | Loss=0.01232 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.938 | L2-Norm(final)=8.133 | 4487.2 samples/s | 70.1 steps/s
[Step=37500 Epoch=73.3] | Loss=0.01252 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.943 | L2-Norm(final)=8.135 | 4887.6 samples/s | 76.4 steps/s
[Step=37550 Epoch=73.4] | Loss=0.01239 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.949 | L2-Norm(final)=8.137 | 2543.3 samples/s | 39.7 steps/s
[Step=37600 Epoch=73.5] | Loss=0.01242 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.955 | L2-Norm(final)=8.139 | 4535.6 samples/s | 70.9 steps/s
[Step=37650 Epoch=73.6] | Loss=0.01246 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.961 | L2-Norm(final)=8.141 | 4467.1 samples/s | 69.8 steps/s
[Step=37700 Epoch=73.7] | Loss=0.01252 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.967 | L2-Norm(final)=8.144 | 4308.3 samples/s | 67.3 steps/s
[Step=37750 Epoch=73.8] | Loss=0.01244 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.972 | L2-Norm(final)=8.145 | 4457.2 samples/s | 69.6 steps/s
[Step=37800 Epoch=73.9] | Loss=0.01240 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.977 | L2-Norm(final)=8.148 | 4380.5 samples/s | 68.4 steps/s
[Step=37850 Epoch=74.0] | Loss=0.01234 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.983 | L2-Norm(final)=8.150 | 4425.9 samples/s | 69.2 steps/s
[Step=37900 Epoch=74.1] | Loss=0.01228 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.987 | L2-Norm(final)=8.152 | 4503.1 samples/s | 70.4 steps/s
[Step=37950 Epoch=74.2] | Loss=0.01223 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.992 | L2-Norm(final)=8.154 | 4377.4 samples/s | 68.4 steps/s
[Step=38000 Epoch=74.3] | Loss=0.01214 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.996 | L2-Norm(final)=8.156 | 4441.6 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step38000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=137.9] | Loss=0.00007 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.793 | L2-Norm(final)=5.238 | 5888.1 samples/s | 92.0 steps/s
[Step=36050 Epoch=138.1] | Loss=0.00008 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.793 | L2-Norm(final)=5.244 | 4079.9 samples/s | 63.7 steps/s
[Step=36100 Epoch=138.3] | Loss=0.00009 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.799 | L2-Norm(final)=5.256 | 4690.9 samples/s | 73.3 steps/s
[Step=36150 Epoch=138.5] | Loss=0.00010 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.806 | L2-Norm(final)=5.268 | 4863.8 samples/s | 76.0 steps/s
[Step=36200 Epoch=138.7] | Loss=0.00009 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.815 | L2-Norm(final)=5.278 | 4642.7 samples/s | 72.5 steps/s
[Step=36250 Epoch=138.9] | Loss=0.00013 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.824 | L2-Norm(final)=5.289 | 6406.8 samples/s | 100.1 steps/s
[Step=36300 Epoch=139.1] | Loss=0.00011 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.831 | L2-Norm(final)=5.298 | 2398.8 samples/s | 37.5 steps/s
[Step=36350 Epoch=139.3] | Loss=0.00010 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.836 | L2-Norm(final)=5.306 | 4653.4 samples/s | 72.7 steps/s
[Step=36400 Epoch=139.5] | Loss=0.00010 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.839 | L2-Norm(final)=5.314 | 4689.2 samples/s | 73.3 steps/s
[Step=36450 Epoch=139.7] | Loss=0.00009 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.842 | L2-Norm(final)=5.321 | 4766.9 samples/s | 74.5 steps/s
[Step=36500 Epoch=139.9] | Loss=0.00009 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.843 | L2-Norm(final)=5.328 | 5396.4 samples/s | 84.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=139.9] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.856 | L2-Norm(final)=5.390 | 5905.8 samples/s | 92.3 steps/s
[Step=36550 Epoch=140.0] | Loss=0.00002 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.844 | L2-Norm(final)=5.394 | 3879.3 samples/s | 60.6 steps/s
[Step=36600 Epoch=140.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.827 | L2-Norm(final)=5.396 | 4337.6 samples/s | 67.8 steps/s
[Step=36650 Epoch=140.4] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.810 | L2-Norm(final)=5.399 | 4030.9 samples/s | 63.0 steps/s
[Step=36700 Epoch=140.6] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.794 | L2-Norm(final)=5.401 | 4238.0 samples/s | 66.2 steps/s
[Step=36750 Epoch=140.8] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.776 | L2-Norm(final)=5.403 | 5677.5 samples/s | 88.7 steps/s
[Step=36800 Epoch=141.0] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.759 | L2-Norm(final)=5.405 | 2264.4 samples/s | 35.4 steps/s
[Step=36850 Epoch=141.2] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.741 | L2-Norm(final)=5.406 | 4185.7 samples/s | 65.4 steps/s
[Step=36900 Epoch=141.4] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.722 | L2-Norm(final)=5.408 | 4201.9 samples/s | 65.7 steps/s
[Step=36950 Epoch=141.6] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.704 | L2-Norm(final)=5.409 | 4149.6 samples/s | 64.8 steps/s
[Step=37000 Epoch=141.8] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.685 | L2-Norm(final)=5.410 | 4794.6 samples/s | 74.9 steps/s
[Step=37050 Epoch=142.0] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.666 | L2-Norm(final)=5.411 | 2443.8 samples/s | 38.2 steps/s
[Step=37100 Epoch=142.2] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.647 | L2-Norm(final)=5.412 | 4222.2 samples/s | 66.0 steps/s
[Step=37150 Epoch=142.3] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.628 | L2-Norm(final)=5.413 | 4237.4 samples/s | 66.2 steps/s
[Step=37200 Epoch=142.5] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.609 | L2-Norm(final)=5.414 | 4146.3 samples/s | 64.8 steps/s
[Step=37250 Epoch=142.7] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.589 | L2-Norm(final)=5.414 | 4147.2 samples/s | 64.8 steps/s
[Step=37300 Epoch=142.9] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.570 | L2-Norm(final)=5.415 | 2600.6 samples/s | 40.6 steps/s
[Step=37350 Epoch=143.1] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.550 | L2-Norm(final)=5.416 | 4218.3 samples/s | 65.9 steps/s
[Step=37400 Epoch=143.3] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.530 | L2-Norm(final)=5.417 | 4184.5 samples/s | 65.4 steps/s
[Step=37450 Epoch=143.5] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.510 | L2-Norm(final)=5.418 | 4221.6 samples/s | 66.0 steps/s
[Step=37500 Epoch=143.7] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.490 | L2-Norm(final)=5.419 | 4219.7 samples/s | 65.9 steps/s
[Step=37550 Epoch=143.9] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.470 | L2-Norm(final)=5.420 | 2610.4 samples/s | 40.8 steps/s
[Step=37600 Epoch=144.1] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.450 | L2-Norm(final)=5.420 | 4134.9 samples/s | 64.6 steps/s
[Step=37650 Epoch=144.3] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=5.421 | 4290.9 samples/s | 67.0 steps/s
[Step=37700 Epoch=144.5] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.408 | L2-Norm(final)=5.422 | 4167.8 samples/s | 65.1 steps/s
[Step=37750 Epoch=144.6] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.388 | L2-Norm(final)=5.423 | 4139.3 samples/s | 64.7 steps/s
[Step=37800 Epoch=144.8] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.367 | L2-Norm(final)=5.424 | 6280.0 samples/s | 98.1 steps/s
[Step=37850 Epoch=145.0] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.346 | L2-Norm(final)=5.425 | 2176.6 samples/s | 34.0 steps/s
[Step=37900 Epoch=145.2] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.324 | L2-Norm(final)=5.426 | 4159.2 samples/s | 65.0 steps/s
[Step=37950 Epoch=145.4] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.303 | L2-Norm(final)=5.427 | 4246.3 samples/s | 66.3 steps/s
[Step=38000 Epoch=145.6] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.281 | L2-Norm(final)=5.428 | 4163.0 samples/s | 65.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step38000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=138.6] | Loss=0.00033 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.789 | L2-Norm(final)=5.684 | 6703.8 samples/s | 104.7 steps/s
[Step=36050 Epoch=138.8] | Loss=0.00007 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.786 | L2-Norm(final)=5.691 | 4256.5 samples/s | 66.5 steps/s
[Step=36100 Epoch=139.0] | Loss=0.00011 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.791 | L2-Norm(final)=5.704 | 4495.0 samples/s | 70.2 steps/s
[Step=36150 Epoch=139.2] | Loss=0.00009 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.800 | L2-Norm(final)=5.717 | 4626.3 samples/s | 72.3 steps/s
[Step=36200 Epoch=139.3] | Loss=0.00008 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.805 | L2-Norm(final)=5.728 | 4789.8 samples/s | 74.8 steps/s
[Step=36250 Epoch=139.5] | Loss=0.00007 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.807 | L2-Norm(final)=5.738 | 6616.9 samples/s | 103.4 steps/s
[Step=36300 Epoch=139.7] | Loss=0.00006 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.808 | L2-Norm(final)=5.747 | 2372.0 samples/s | 37.1 steps/s
[Step=36350 Epoch=139.9] | Loss=0.00006 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.809 | L2-Norm(final)=5.754 | 4749.7 samples/s | 74.2 steps/s
[Step=36400 Epoch=140.1] | Loss=0.00005 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.808 | L2-Norm(final)=5.761 | 4687.0 samples/s | 73.2 steps/s
[Step=36450 Epoch=140.3] | Loss=0.00005 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.807 | L2-Norm(final)=5.768 | 4643.0 samples/s | 72.5 steps/s
[Step=36500 Epoch=140.5] | Loss=0.00005 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.806 | L2-Norm(final)=5.774 | 5502.7 samples/s | 86.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=140.5] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.793 | L2-Norm(final)=5.835 | 5995.9 samples/s | 93.7 steps/s
[Step=36550 Epoch=140.7] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.767 | L2-Norm(final)=5.839 | 3798.7 samples/s | 59.4 steps/s
[Step=36600 Epoch=140.9] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.736 | L2-Norm(final)=5.844 | 4199.3 samples/s | 65.6 steps/s
[Step=36650 Epoch=141.1] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.703 | L2-Norm(final)=5.848 | 4261.5 samples/s | 66.6 steps/s
[Step=36700 Epoch=141.3] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.668 | L2-Norm(final)=5.851 | 4204.0 samples/s | 65.7 steps/s
[Step=36750 Epoch=141.5] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.632 | L2-Norm(final)=5.853 | 5663.3 samples/s | 88.5 steps/s
[Step=36800 Epoch=141.7] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.596 | L2-Norm(final)=5.855 | 2255.5 samples/s | 35.2 steps/s
[Step=36850 Epoch=141.9] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.559 | L2-Norm(final)=5.856 | 4125.6 samples/s | 64.5 steps/s
[Step=36900 Epoch=142.0] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.521 | L2-Norm(final)=5.857 | 4272.2 samples/s | 66.8 steps/s
[Step=36950 Epoch=142.2] | Loss=0.00001 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.484 | L2-Norm(final)=5.859 | 4144.4 samples/s | 64.8 steps/s
[Step=37000 Epoch=142.4] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.447 | L2-Norm(final)=5.860 | 4886.1 samples/s | 76.3 steps/s
[Step=37050 Epoch=142.6] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.409 | L2-Norm(final)=5.861 | 2417.6 samples/s | 37.8 steps/s
[Step=37100 Epoch=142.8] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.371 | L2-Norm(final)=5.862 | 4209.2 samples/s | 65.8 steps/s
[Step=37150 Epoch=143.0] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.334 | L2-Norm(final)=5.862 | 4137.4 samples/s | 64.6 steps/s
[Step=37200 Epoch=143.2] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.296 | L2-Norm(final)=5.863 | 4219.8 samples/s | 65.9 steps/s
[Step=37250 Epoch=143.4] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.258 | L2-Norm(final)=5.864 | 4319.8 samples/s | 67.5 steps/s
[Step=37300 Epoch=143.6] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.220 | L2-Norm(final)=5.865 | 2591.6 samples/s | 40.5 steps/s
[Step=37350 Epoch=143.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.182 | L2-Norm(final)=5.866 | 4098.0 samples/s | 64.0 steps/s
[Step=37400 Epoch=144.0] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.144 | L2-Norm(final)=5.867 | 4256.9 samples/s | 66.5 steps/s
[Step=37450 Epoch=144.2] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.106 | L2-Norm(final)=5.868 | 4180.5 samples/s | 65.3 steps/s
[Step=37500 Epoch=144.4] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.067 | L2-Norm(final)=5.868 | 4295.0 samples/s | 67.1 steps/s
[Step=37550 Epoch=144.5] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.029 | L2-Norm(final)=5.869 | 2590.1 samples/s | 40.5 steps/s
[Step=37600 Epoch=144.7] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.991 | L2-Norm(final)=5.870 | 4260.9 samples/s | 66.6 steps/s
[Step=37650 Epoch=144.9] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.953 | L2-Norm(final)=5.872 | 4286.2 samples/s | 67.0 steps/s
[Step=37700 Epoch=145.1] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.914 | L2-Norm(final)=5.873 | 4071.0 samples/s | 63.6 steps/s
[Step=37750 Epoch=145.3] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.876 | L2-Norm(final)=5.874 | 4238.6 samples/s | 66.2 steps/s
[Step=37800 Epoch=145.5] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.837 | L2-Norm(final)=5.875 | 6838.2 samples/s | 106.8 steps/s
[Step=37850 Epoch=145.7] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.798 | L2-Norm(final)=5.876 | 2103.9 samples/s | 32.9 steps/s
[Step=37900 Epoch=145.9] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.760 | L2-Norm(final)=5.878 | 4167.0 samples/s | 65.1 steps/s
[Step=37950 Epoch=146.1] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.721 | L2-Norm(final)=5.879 | 4215.4 samples/s | 65.9 steps/s
[Step=38000 Epoch=146.3] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.681 | L2-Norm(final)=5.880 | 4233.5 samples/s | 66.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07188 | acc=0.9669 | tpr=0.9757 | fpr=0.0523 | 4800.3 samples/s | 18.8 steps/s
Avg test loss: 0.07050, Avg test acc: 0.96630, Avg tpr: 0.97523, Avg fpr: 0.05333, total FA: 416

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07741 | acc=0.9664 | tpr=0.9779 | fpr=0.0585 | 4975.5 samples/s | 19.4 steps/s
Avg test loss: 0.07938, Avg test acc: 0.96630, Avg tpr: 0.97774, Avg fpr: 0.05884, total FA: 459

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.80283 | acc=0.3005 | tpr=0.0127 | fpr=0.0746 | 4897.4 samples/s | 19.1 steps/s
Avg test loss: 5.79611, Avg test acc: 0.29750, Avg tpr: 0.01422, Avg fpr: 0.07948, total FA: 620

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.11045 | acc=0.3158 | tpr=0.0183 | fpr=0.0382 | 4829.7 samples/s | 18.9 steps/s
Avg test loss: 6.09701, Avg test acc: 0.31317, Avg tpr: 0.01929, Avg fpr: 0.04051, total FA: 316

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.90882 | acc=0.1432 | tpr=0.5487 | fpr=0.8641 | 4866.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.89164 | acc=0.1425 | tpr=0.5117 | fpr=0.8644 | 7060.8 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.89273 | acc=0.1432 | tpr=0.5000 | fpr=0.8634 | 7777.1 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.88175 | acc=0.1430 | tpr=0.4918 | fpr=0.8633 | 7905.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=5.87896 | acc=0.1435 | tpr=0.5031 | fpr=0.8630 | 7635.4 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.86829 | acc=0.1436 | tpr=0.4975 | fpr=0.8629 | 7715.2 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.87448 | acc=0.1434 | tpr=0.4972 | fpr=0.8631 | 8098.9 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.88132 | acc=0.1435 | tpr=0.4951 | fpr=0.8628 | 7757.6 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.88910 | acc=0.1439 | tpr=0.4985 | fpr=0.8626 | 7793.1 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.89121 | acc=0.1441 | tpr=0.5004 | fpr=0.8623 | 7643.8 samples/s | 29.9 steps/s
[Step= 550] | Loss=5.89579 | acc=0.1440 | tpr=0.4998 | fpr=0.8625 | 14149.1 samples/s | 55.3 steps/s
Avg test loss: 5.89773, Avg test acc: 0.14393, Avg tpr: 0.50040, Avg fpr: 0.86255, total FA: 119763

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.82776 | acc=0.1226 | tpr=0.6858 | fpr=0.8875 | 4754.8 samples/s | 18.6 steps/s
[Step= 100] | Loss=7.80710 | acc=0.1230 | tpr=0.6652 | fpr=0.8871 | 7276.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=7.82177 | acc=0.1219 | tpr=0.6628 | fpr=0.8880 | 7934.9 samples/s | 31.0 steps/s
[Step= 200] | Loss=7.82048 | acc=0.1228 | tpr=0.6612 | fpr=0.8870 | 7564.6 samples/s | 29.5 steps/s
[Step= 250] | Loss=7.81170 | acc=0.1228 | tpr=0.6541 | fpr=0.8869 | 8032.9 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.80183 | acc=0.1230 | tpr=0.6509 | fpr=0.8866 | 8034.0 samples/s | 31.4 steps/s
[Step= 350] | Loss=7.81158 | acc=0.1226 | tpr=0.6399 | fpr=0.8868 | 7231.8 samples/s | 28.2 steps/s
[Step= 400] | Loss=7.81418 | acc=0.1225 | tpr=0.6335 | fpr=0.8867 | 8121.7 samples/s | 31.7 steps/s
[Step= 450] | Loss=7.82388 | acc=0.1224 | tpr=0.6339 | fpr=0.8869 | 7641.5 samples/s | 29.8 steps/s
[Step= 500] | Loss=7.82663 | acc=0.1225 | tpr=0.6326 | fpr=0.8867 | 7687.3 samples/s | 30.0 steps/s
[Step= 550] | Loss=7.83453 | acc=0.1226 | tpr=0.6327 | fpr=0.8867 | 14111.7 samples/s | 55.1 steps/s
Avg test loss: 7.83741, Avg test acc: 0.12244, Avg tpr: 0.63352, Avg fpr: 0.88685, total FA: 123137

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14144 | acc=0.9783 | tpr=0.9381 | fpr=0.0210 | 4880.7 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.14345 | acc=0.9789 | tpr=0.9339 | fpr=0.0203 | 6954.9 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.14960 | acc=0.9780 | tpr=0.9366 | fpr=0.0212 | 7902.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.15344 | acc=0.9781 | tpr=0.9410 | fpr=0.0213 | 7970.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.15060 | acc=0.9784 | tpr=0.9415 | fpr=0.0209 | 7305.3 samples/s | 28.5 steps/s
[Step= 300] | Loss=0.15285 | acc=0.9781 | tpr=0.9382 | fpr=0.0212 | 7961.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.15310 | acc=0.9780 | tpr=0.9405 | fpr=0.0214 | 7969.8 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.15504 | acc=0.9779 | tpr=0.9382 | fpr=0.0214 | 8237.5 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.15797 | acc=0.9775 | tpr=0.9367 | fpr=0.0218 | 7732.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.15688 | acc=0.9776 | tpr=0.9379 | fpr=0.0216 | 7970.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.15531 | acc=0.9779 | tpr=0.9387 | fpr=0.0213 | 13457.0 samples/s | 52.6 steps/s
Avg test loss: 0.15509, Avg test acc: 0.97794, Avg tpr: 0.93859, Avg fpr: 0.02134, total FA: 2963

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13583 | acc=0.9794 | tpr=0.9425 | fpr=0.0200 | 4916.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13869 | acc=0.9794 | tpr=0.9488 | fpr=0.0201 | 7001.0 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.14597 | acc=0.9783 | tpr=0.9510 | fpr=0.0212 | 7875.9 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.14963 | acc=0.9781 | tpr=0.9530 | fpr=0.0214 | 7470.6 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.14704 | acc=0.9782 | tpr=0.9485 | fpr=0.0212 | 7989.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14956 | acc=0.9779 | tpr=0.9462 | fpr=0.0215 | 7678.6 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.14954 | acc=0.9779 | tpr=0.9474 | fpr=0.0216 | 7763.4 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.15110 | acc=0.9777 | tpr=0.9453 | fpr=0.0217 | 8148.7 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.15376 | acc=0.9773 | tpr=0.9440 | fpr=0.0221 | 7491.7 samples/s | 29.3 steps/s
[Step= 500] | Loss=0.15284 | acc=0.9775 | tpr=0.9449 | fpr=0.0220 | 7616.4 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.15130 | acc=0.9777 | tpr=0.9455 | fpr=0.0217 | 14820.0 samples/s | 57.9 steps/s
Avg test loss: 0.15114, Avg test acc: 0.97773, Avg tpr: 0.94532, Avg fpr: 0.02168, total FA: 3010

server round 19/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=74.1] | Loss=0.00494 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.421 | L2-Norm(final)=8.047 | 6793.0 samples/s | 106.1 steps/s
[Step=38050 Epoch=74.2] | Loss=0.00743 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.421 | L2-Norm(final)=8.057 | 4448.2 samples/s | 69.5 steps/s
[Step=38100 Epoch=74.3] | Loss=0.00804 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.418 | L2-Norm(final)=8.066 | 4822.7 samples/s | 75.4 steps/s
[Step=38150 Epoch=74.4] | Loss=0.00795 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.414 | L2-Norm(final)=8.075 | 5077.3 samples/s | 79.3 steps/s
[Step=38200 Epoch=74.5] | Loss=0.00776 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.410 | L2-Norm(final)=8.083 | 4833.3 samples/s | 75.5 steps/s
[Step=38250 Epoch=74.6] | Loss=0.00751 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.406 | L2-Norm(final)=8.090 | 4909.0 samples/s | 76.7 steps/s
[Step=38300 Epoch=74.7] | Loss=0.00735 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=8.097 | 4925.8 samples/s | 77.0 steps/s
[Step=38350 Epoch=74.8] | Loss=0.00737 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.399 | L2-Norm(final)=8.103 | 5063.4 samples/s | 79.1 steps/s
[Step=38400 Epoch=74.9] | Loss=0.00726 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.396 | L2-Norm(final)=8.109 | 4920.9 samples/s | 76.9 steps/s
[Step=38450 Epoch=75.0] | Loss=0.00717 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.393 | L2-Norm(final)=8.114 | 4987.3 samples/s | 77.9 steps/s
[Step=38500 Epoch=75.1] | Loss=0.00725 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.391 | L2-Norm(final)=8.120 | 6750.9 samples/s | 105.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=75.1] | Loss=0.01554 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.365 | L2-Norm(final)=8.174 | 5863.0 samples/s | 91.6 steps/s
[Step=38550 Epoch=75.2] | Loss=0.00630 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.363 | L2-Norm(final)=8.182 | 4201.6 samples/s | 65.7 steps/s
[Step=38600 Epoch=75.3] | Loss=0.00758 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.364 | L2-Norm(final)=8.188 | 4473.5 samples/s | 69.9 steps/s
[Step=38650 Epoch=75.4] | Loss=0.00935 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.370 | L2-Norm(final)=8.191 | 4422.3 samples/s | 69.1 steps/s
[Step=38700 Epoch=75.5] | Loss=0.00974 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.378 | L2-Norm(final)=8.196 | 4471.4 samples/s | 69.9 steps/s
[Step=38750 Epoch=75.6] | Loss=0.01051 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.387 | L2-Norm(final)=8.201 | 4513.3 samples/s | 70.5 steps/s
[Step=38800 Epoch=75.7] | Loss=0.01129 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.395 | L2-Norm(final)=8.206 | 4396.2 samples/s | 68.7 steps/s
[Step=38850 Epoch=75.8] | Loss=0.01175 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=8.210 | 4537.1 samples/s | 70.9 steps/s
[Step=38900 Epoch=75.9] | Loss=0.01212 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.412 | L2-Norm(final)=8.214 | 4401.0 samples/s | 68.8 steps/s
[Step=38950 Epoch=76.0] | Loss=0.01220 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.420 | L2-Norm(final)=8.218 | 4450.0 samples/s | 69.5 steps/s
[Step=39000 Epoch=76.1] | Loss=0.01247 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.428 | L2-Norm(final)=8.222 | 5763.8 samples/s | 90.1 steps/s
[Step=39050 Epoch=76.2] | Loss=0.01285 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.435 | L2-Norm(final)=8.225 | 2369.4 samples/s | 37.0 steps/s
[Step=39100 Epoch=76.3] | Loss=0.01239 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.441 | L2-Norm(final)=8.229 | 4255.6 samples/s | 66.5 steps/s
[Step=39150 Epoch=76.4] | Loss=0.01230 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.447 | L2-Norm(final)=8.233 | 4291.5 samples/s | 67.1 steps/s
[Step=39200 Epoch=76.5] | Loss=0.01211 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.452 | L2-Norm(final)=8.238 | 4346.0 samples/s | 67.9 steps/s
[Step=39250 Epoch=76.6] | Loss=0.01211 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.457 | L2-Norm(final)=8.242 | 4218.3 samples/s | 65.9 steps/s
[Step=39300 Epoch=76.7] | Loss=0.01209 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.462 | L2-Norm(final)=8.246 | 4227.0 samples/s | 66.0 steps/s
[Step=39350 Epoch=76.7] | Loss=0.01212 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.467 | L2-Norm(final)=8.249 | 4286.9 samples/s | 67.0 steps/s
[Step=39400 Epoch=76.8] | Loss=0.01215 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.472 | L2-Norm(final)=8.253 | 4300.4 samples/s | 67.2 steps/s
[Step=39450 Epoch=76.9] | Loss=0.01219 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.476 | L2-Norm(final)=8.256 | 4314.7 samples/s | 67.4 steps/s
[Step=39500 Epoch=77.0] | Loss=0.01217 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.480 | L2-Norm(final)=8.260 | 4590.8 samples/s | 71.7 steps/s
[Step=39550 Epoch=77.1] | Loss=0.01244 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.485 | L2-Norm(final)=8.263 | 2533.4 samples/s | 39.6 steps/s
[Step=39600 Epoch=77.2] | Loss=0.01235 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.491 | L2-Norm(final)=8.266 | 4464.1 samples/s | 69.8 steps/s
[Step=39650 Epoch=77.3] | Loss=0.01238 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.496 | L2-Norm(final)=8.269 | 4446.9 samples/s | 69.5 steps/s
[Step=39700 Epoch=77.4] | Loss=0.01233 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.501 | L2-Norm(final)=8.272 | 4445.6 samples/s | 69.5 steps/s
[Step=39750 Epoch=77.5] | Loss=0.01225 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.505 | L2-Norm(final)=8.275 | 4396.1 samples/s | 68.7 steps/s
[Step=39800 Epoch=77.6] | Loss=0.01227 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.509 | L2-Norm(final)=8.278 | 4421.4 samples/s | 69.1 steps/s
[Step=39850 Epoch=77.7] | Loss=0.01226 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.513 | L2-Norm(final)=8.281 | 4409.1 samples/s | 68.9 steps/s
[Step=39900 Epoch=77.8] | Loss=0.01222 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.517 | L2-Norm(final)=8.284 | 4511.6 samples/s | 70.5 steps/s
[Step=39950 Epoch=77.9] | Loss=0.01213 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.522 | L2-Norm(final)=8.288 | 4426.0 samples/s | 69.2 steps/s
[Step=40000 Epoch=78.0] | Loss=0.01210 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.526 | L2-Norm(final)=8.291 | 4471.0 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step40000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=74.3] | Loss=0.00024 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.431 | L2-Norm(final)=8.220 | 5654.2 samples/s | 88.3 steps/s
[Step=38050 Epoch=74.4] | Loss=0.00693 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=8.228 | 4410.9 samples/s | 68.9 steps/s
[Step=38100 Epoch=74.5] | Loss=0.00775 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.426 | L2-Norm(final)=8.238 | 4942.0 samples/s | 77.2 steps/s
[Step=38150 Epoch=74.6] | Loss=0.00708 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.424 | L2-Norm(final)=8.247 | 5134.4 samples/s | 80.2 steps/s
[Step=38200 Epoch=74.7] | Loss=0.00712 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.421 | L2-Norm(final)=8.255 | 4881.1 samples/s | 76.3 steps/s
[Step=38250 Epoch=74.8] | Loss=0.00723 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.419 | L2-Norm(final)=8.263 | 4982.3 samples/s | 77.8 steps/s
[Step=38300 Epoch=74.9] | Loss=0.00723 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.416 | L2-Norm(final)=8.270 | 5036.3 samples/s | 78.7 steps/s
[Step=38350 Epoch=75.0] | Loss=0.00734 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.413 | L2-Norm(final)=8.277 | 5068.5 samples/s | 79.2 steps/s
[Step=38400 Epoch=75.1] | Loss=0.00705 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.410 | L2-Norm(final)=8.284 | 5024.8 samples/s | 78.5 steps/s
[Step=38450 Epoch=75.2] | Loss=0.00700 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.407 | L2-Norm(final)=8.291 | 5170.0 samples/s | 80.8 steps/s
[Step=38500 Epoch=75.3] | Loss=0.00703 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=8.298 | 6644.7 samples/s | 103.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=75.3] | Loss=0.01706 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.365 | L2-Norm(final)=8.367 | 5768.3 samples/s | 90.1 steps/s
[Step=38550 Epoch=75.4] | Loss=0.00739 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.363 | L2-Norm(final)=8.371 | 4204.4 samples/s | 65.7 steps/s
[Step=38600 Epoch=75.5] | Loss=0.00791 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.364 | L2-Norm(final)=8.374 | 4488.9 samples/s | 70.1 steps/s
[Step=38650 Epoch=75.6] | Loss=0.00924 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.365 | L2-Norm(final)=8.376 | 4443.1 samples/s | 69.4 steps/s
[Step=38700 Epoch=75.7] | Loss=0.01006 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.369 | L2-Norm(final)=8.378 | 4451.6 samples/s | 69.6 steps/s
[Step=38750 Epoch=75.8] | Loss=0.01100 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.376 | L2-Norm(final)=8.380 | 4445.9 samples/s | 69.5 steps/s
[Step=38800 Epoch=75.9] | Loss=0.01163 | Reg=0.00376 | acc=0.9531 | L2-Norm=19.386 | L2-Norm(final)=8.383 | 4462.0 samples/s | 69.7 steps/s
[Step=38850 Epoch=76.0] | Loss=0.01174 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.396 | L2-Norm(final)=8.386 | 4462.2 samples/s | 69.7 steps/s
[Step=38900 Epoch=76.0] | Loss=0.01203 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.406 | L2-Norm(final)=8.389 | 4437.8 samples/s | 69.3 steps/s
[Step=38950 Epoch=76.1] | Loss=0.01221 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.416 | L2-Norm(final)=8.393 | 4393.9 samples/s | 68.7 steps/s
[Step=39000 Epoch=76.2] | Loss=0.01244 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.427 | L2-Norm(final)=8.397 | 5846.1 samples/s | 91.3 steps/s
[Step=39050 Epoch=76.3] | Loss=0.01249 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.436 | L2-Norm(final)=8.401 | 2373.1 samples/s | 37.1 steps/s
[Step=39100 Epoch=76.4] | Loss=0.01271 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.446 | L2-Norm(final)=8.405 | 4466.4 samples/s | 69.8 steps/s
[Step=39150 Epoch=76.5] | Loss=0.01238 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.455 | L2-Norm(final)=8.409 | 4411.3 samples/s | 68.9 steps/s
[Step=39200 Epoch=76.6] | Loss=0.01242 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.463 | L2-Norm(final)=8.414 | 4428.7 samples/s | 69.2 steps/s
[Step=39250 Epoch=76.7] | Loss=0.01224 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.471 | L2-Norm(final)=8.418 | 4453.5 samples/s | 69.6 steps/s
[Step=39300 Epoch=76.8] | Loss=0.01197 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.477 | L2-Norm(final)=8.422 | 4455.0 samples/s | 69.6 steps/s
[Step=39350 Epoch=76.9] | Loss=0.01188 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.483 | L2-Norm(final)=8.426 | 4468.4 samples/s | 69.8 steps/s
[Step=39400 Epoch=77.0] | Loss=0.01185 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.488 | L2-Norm(final)=8.430 | 4398.9 samples/s | 68.7 steps/s
[Step=39450 Epoch=77.1] | Loss=0.01173 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.492 | L2-Norm(final)=8.434 | 4506.1 samples/s | 70.4 steps/s
[Step=39500 Epoch=77.2] | Loss=0.01180 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.496 | L2-Norm(final)=8.438 | 4845.5 samples/s | 75.7 steps/s
[Step=39550 Epoch=77.3] | Loss=0.01170 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.500 | L2-Norm(final)=8.441 | 2588.8 samples/s | 40.5 steps/s
[Step=39600 Epoch=77.4] | Loss=0.01177 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.504 | L2-Norm(final)=8.445 | 4424.7 samples/s | 69.1 steps/s
[Step=39650 Epoch=77.5] | Loss=0.01173 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.507 | L2-Norm(final)=8.448 | 4452.1 samples/s | 69.6 steps/s
[Step=39700 Epoch=77.6] | Loss=0.01159 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.511 | L2-Norm(final)=8.451 | 4428.6 samples/s | 69.2 steps/s
[Step=39750 Epoch=77.7] | Loss=0.01153 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.514 | L2-Norm(final)=8.454 | 4503.6 samples/s | 70.4 steps/s
[Step=39800 Epoch=77.8] | Loss=0.01150 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.516 | L2-Norm(final)=8.458 | 4323.4 samples/s | 67.6 steps/s
[Step=39850 Epoch=77.9] | Loss=0.01146 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.519 | L2-Norm(final)=8.461 | 4501.4 samples/s | 70.3 steps/s
[Step=39900 Epoch=78.0] | Loss=0.01149 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.521 | L2-Norm(final)=8.464 | 4430.9 samples/s | 69.2 steps/s
[Step=39950 Epoch=78.1] | Loss=0.01144 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.523 | L2-Norm(final)=8.467 | 4451.3 samples/s | 69.6 steps/s
[Step=40000 Epoch=78.2] | Loss=0.01133 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.525 | L2-Norm(final)=8.470 | 4458.9 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step40000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=145.6] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.003 | L2-Norm(final)=5.458 | 6153.2 samples/s | 96.1 steps/s
[Step=38050 Epoch=145.8] | Loss=0.00084 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.039 | L2-Norm(final)=5.475 | 4108.7 samples/s | 64.2 steps/s
[Step=38100 Epoch=146.0] | Loss=0.00047 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.070 | L2-Norm(final)=5.493 | 4637.2 samples/s | 72.5 steps/s
[Step=38150 Epoch=146.2] | Loss=0.00038 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.082 | L2-Norm(final)=5.505 | 4732.8 samples/s | 73.9 steps/s
[Step=38200 Epoch=146.4] | Loss=0.00031 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.093 | L2-Norm(final)=5.517 | 4698.3 samples/s | 73.4 steps/s
[Step=38250 Epoch=146.6] | Loss=0.00028 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.102 | L2-Norm(final)=5.527 | 6666.2 samples/s | 104.2 steps/s
[Step=38300 Epoch=146.8] | Loss=0.00025 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.108 | L2-Norm(final)=5.537 | 2439.8 samples/s | 38.1 steps/s
[Step=38350 Epoch=146.9] | Loss=0.00022 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.112 | L2-Norm(final)=5.545 | 4620.3 samples/s | 72.2 steps/s
[Step=38400 Epoch=147.1] | Loss=0.00021 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.116 | L2-Norm(final)=5.554 | 4787.6 samples/s | 74.8 steps/s
[Step=38450 Epoch=147.3] | Loss=0.00020 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.119 | L2-Norm(final)=5.561 | 4664.0 samples/s | 72.9 steps/s
[Step=38500 Epoch=147.5] | Loss=0.00018 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.122 | L2-Norm(final)=5.569 | 5443.9 samples/s | 85.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=147.5] | Loss=0.00002 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.143 | L2-Norm(final)=5.638 | 6168.6 samples/s | 96.4 steps/s
[Step=38550 Epoch=147.7] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.121 | L2-Norm(final)=5.641 | 3741.8 samples/s | 58.5 steps/s
[Step=38600 Epoch=147.9] | Loss=0.00002 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.093 | L2-Norm(final)=5.643 | 4287.3 samples/s | 67.0 steps/s
[Step=38650 Epoch=148.1] | Loss=0.00071 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.070 | L2-Norm(final)=5.645 | 4168.5 samples/s | 65.1 steps/s
[Step=38700 Epoch=148.3] | Loss=0.00599 | Reg=0.00124 | acc=0.9844 | L2-Norm=11.127 | L2-Norm(final)=5.630 | 4223.8 samples/s | 66.0 steps/s
[Step=38750 Epoch=148.5] | Loss=0.00553 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.186 | L2-Norm(final)=5.611 | 5630.2 samples/s | 88.0 steps/s
[Step=38800 Epoch=148.7] | Loss=0.00480 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.229 | L2-Norm(final)=5.601 | 2262.2 samples/s | 35.3 steps/s
[Step=38850 Epoch=148.9] | Loss=0.00416 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.260 | L2-Norm(final)=5.594 | 4172.4 samples/s | 65.2 steps/s
[Step=38900 Epoch=149.1] | Loss=0.00365 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.283 | L2-Norm(final)=5.590 | 4213.0 samples/s | 65.8 steps/s
[Step=38950 Epoch=149.2] | Loss=0.00328 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.301 | L2-Norm(final)=5.588 | 4243.2 samples/s | 66.3 steps/s
[Step=39000 Epoch=149.4] | Loss=0.00296 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.316 | L2-Norm(final)=5.586 | 4740.7 samples/s | 74.1 steps/s
[Step=39050 Epoch=149.6] | Loss=0.00270 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=5.585 | 2429.5 samples/s | 38.0 steps/s
[Step=39100 Epoch=149.8] | Loss=0.00247 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.335 | L2-Norm(final)=5.584 | 4227.1 samples/s | 66.0 steps/s
[Step=39150 Epoch=150.0] | Loss=0.00229 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.342 | L2-Norm(final)=5.584 | 4217.4 samples/s | 65.9 steps/s
[Step=39200 Epoch=150.2] | Loss=0.00212 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.348 | L2-Norm(final)=5.584 | 4185.7 samples/s | 65.4 steps/s
[Step=39250 Epoch=150.4] | Loss=0.00198 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.352 | L2-Norm(final)=5.583 | 4166.4 samples/s | 65.1 steps/s
[Step=39300 Epoch=150.6] | Loss=0.00186 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=5.583 | 2497.7 samples/s | 39.0 steps/s
[Step=39350 Epoch=150.8] | Loss=0.00175 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.358 | L2-Norm(final)=5.584 | 4134.8 samples/s | 64.6 steps/s
[Step=39400 Epoch=151.0] | Loss=0.00165 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.359 | L2-Norm(final)=5.584 | 4060.9 samples/s | 63.5 steps/s
[Step=39450 Epoch=151.2] | Loss=0.00157 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=5.584 | 4157.1 samples/s | 65.0 steps/s
[Step=39500 Epoch=151.4] | Loss=0.00149 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=5.584 | 4081.5 samples/s | 63.8 steps/s
[Step=39550 Epoch=151.5] | Loss=0.00142 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.362 | L2-Norm(final)=5.584 | 2544.3 samples/s | 39.8 steps/s
[Step=39600 Epoch=151.7] | Loss=0.00136 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=5.585 | 4143.5 samples/s | 64.7 steps/s
[Step=39650 Epoch=151.9] | Loss=0.00130 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=5.585 | 4193.6 samples/s | 65.5 steps/s
[Step=39700 Epoch=152.1] | Loss=0.00124 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=5.586 | 4154.6 samples/s | 64.9 steps/s
[Step=39750 Epoch=152.3] | Loss=0.00119 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.359 | L2-Norm(final)=5.586 | 4072.8 samples/s | 63.6 steps/s
[Step=39800 Epoch=152.5] | Loss=0.00115 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.358 | L2-Norm(final)=5.586 | 6032.9 samples/s | 94.3 steps/s
[Step=39850 Epoch=152.7] | Loss=0.00111 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.357 | L2-Norm(final)=5.587 | 2137.7 samples/s | 33.4 steps/s
[Step=39900 Epoch=152.9] | Loss=0.00107 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=5.587 | 4028.6 samples/s | 62.9 steps/s
[Step=39950 Epoch=153.1] | Loss=0.00103 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.353 | L2-Norm(final)=5.588 | 4141.6 samples/s | 64.7 steps/s
[Step=40000 Epoch=153.3] | Loss=0.00100 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.351 | L2-Norm(final)=5.588 | 4110.5 samples/s | 64.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step40000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=146.3] | Loss=0.00001 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.892 | L2-Norm(final)=5.921 | 6544.3 samples/s | 102.3 steps/s
[Step=38050 Epoch=146.5] | Loss=0.00117 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.940 | L2-Norm(final)=5.936 | 4172.9 samples/s | 65.2 steps/s
[Step=38100 Epoch=146.7] | Loss=0.00205 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.981 | L2-Norm(final)=5.944 | 4715.3 samples/s | 73.7 steps/s
[Step=38150 Epoch=146.9] | Loss=0.00147 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.016 | L2-Norm(final)=5.945 | 4453.9 samples/s | 69.6 steps/s
[Step=38200 Epoch=147.0] | Loss=0.00118 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.036 | L2-Norm(final)=5.948 | 4627.5 samples/s | 72.3 steps/s
[Step=38250 Epoch=147.2] | Loss=0.00096 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.050 | L2-Norm(final)=5.952 | 6577.4 samples/s | 102.8 steps/s
[Step=38300 Epoch=147.4] | Loss=0.00080 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.060 | L2-Norm(final)=5.955 | 2317.1 samples/s | 36.2 steps/s
[Step=38350 Epoch=147.6] | Loss=0.00069 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.066 | L2-Norm(final)=5.958 | 4667.4 samples/s | 72.9 steps/s
[Step=38400 Epoch=147.8] | Loss=0.00061 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.070 | L2-Norm(final)=5.960 | 4605.7 samples/s | 72.0 steps/s
[Step=38450 Epoch=148.0] | Loss=0.00055 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.074 | L2-Norm(final)=5.963 | 4545.8 samples/s | 71.0 steps/s
[Step=38500 Epoch=148.2] | Loss=0.00050 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.076 | L2-Norm(final)=5.965 | 5535.5 samples/s | 86.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=148.2] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.096 | L2-Norm(final)=5.988 | 6192.6 samples/s | 96.8 steps/s
[Step=38550 Epoch=148.4] | Loss=0.01095 | Reg=0.00125 | acc=0.9844 | L2-Norm=11.173 | L2-Norm(final)=5.963 | 3698.1 samples/s | 57.8 steps/s
[Step=38600 Epoch=148.6] | Loss=0.01088 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=5.926 | 4044.4 samples/s | 63.2 steps/s
[Step=38650 Epoch=148.8] | Loss=0.00856 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.364 | L2-Norm(final)=5.907 | 4194.1 samples/s | 65.5 steps/s
[Step=38700 Epoch=149.0] | Loss=0.00692 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.402 | L2-Norm(final)=5.898 | 4132.0 samples/s | 64.6 steps/s
[Step=38750 Epoch=149.2] | Loss=0.00560 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.427 | L2-Norm(final)=5.893 | 5554.6 samples/s | 86.8 steps/s
[Step=38800 Epoch=149.4] | Loss=0.00471 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.443 | L2-Norm(final)=5.891 | 2192.7 samples/s | 34.3 steps/s
[Step=38850 Epoch=149.5] | Loss=0.00405 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=5.890 | 4122.4 samples/s | 64.4 steps/s
[Step=38900 Epoch=149.7] | Loss=0.00358 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.462 | L2-Norm(final)=5.889 | 4149.1 samples/s | 64.8 steps/s
[Step=38950 Epoch=149.9] | Loss=0.00318 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.468 | L2-Norm(final)=5.889 | 4108.2 samples/s | 64.2 steps/s
[Step=39000 Epoch=150.1] | Loss=0.00289 | Reg=0.00132 | acc=0.9844 | L2-Norm=11.472 | L2-Norm(final)=5.890 | 4771.3 samples/s | 74.6 steps/s
[Step=39050 Epoch=150.3] | Loss=0.00264 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.475 | L2-Norm(final)=5.890 | 2352.4 samples/s | 36.8 steps/s
[Step=39100 Epoch=150.5] | Loss=0.00243 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=5.891 | 4151.1 samples/s | 64.9 steps/s
[Step=39150 Epoch=150.7] | Loss=0.00224 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.479 | L2-Norm(final)=5.892 | 4113.8 samples/s | 64.3 steps/s
[Step=39200 Epoch=150.9] | Loss=0.00208 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.480 | L2-Norm(final)=5.892 | 4090.7 samples/s | 63.9 steps/s
[Step=39250 Epoch=151.1] | Loss=0.00194 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.481 | L2-Norm(final)=5.893 | 4246.7 samples/s | 66.4 steps/s
[Step=39300 Epoch=151.3] | Loss=0.00182 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.480 | L2-Norm(final)=5.893 | 2558.3 samples/s | 40.0 steps/s
[Step=39350 Epoch=151.5] | Loss=0.00172 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.480 | L2-Norm(final)=5.894 | 4251.7 samples/s | 66.4 steps/s
[Step=39400 Epoch=151.7] | Loss=0.00162 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.479 | L2-Norm(final)=5.894 | 4121.8 samples/s | 64.4 steps/s
[Step=39450 Epoch=151.9] | Loss=0.00154 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=5.895 | 4084.5 samples/s | 63.8 steps/s
[Step=39500 Epoch=152.1] | Loss=0.00146 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.476 | L2-Norm(final)=5.895 | 4024.5 samples/s | 62.9 steps/s
[Step=39550 Epoch=152.2] | Loss=0.00139 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.474 | L2-Norm(final)=5.896 | 2488.6 samples/s | 38.9 steps/s
[Step=39600 Epoch=152.4] | Loss=0.00133 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.472 | L2-Norm(final)=5.896 | 4064.4 samples/s | 63.5 steps/s
[Step=39650 Epoch=152.6] | Loss=0.00127 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.470 | L2-Norm(final)=5.897 | 4044.2 samples/s | 63.2 steps/s
[Step=39700 Epoch=152.8] | Loss=0.00122 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.468 | L2-Norm(final)=5.897 | 3996.3 samples/s | 62.4 steps/s
[Step=39750 Epoch=153.0] | Loss=0.00117 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.465 | L2-Norm(final)=5.898 | 4117.7 samples/s | 64.3 steps/s
[Step=39800 Epoch=153.2] | Loss=0.00113 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.463 | L2-Norm(final)=5.898 | 6441.3 samples/s | 100.6 steps/s
[Step=39850 Epoch=153.4] | Loss=0.00108 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.460 | L2-Norm(final)=5.899 | 2026.1 samples/s | 31.7 steps/s
[Step=39900 Epoch=153.6] | Loss=0.00104 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.457 | L2-Norm(final)=5.899 | 4197.4 samples/s | 65.6 steps/s
[Step=39950 Epoch=153.8] | Loss=0.00101 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=5.899 | 4183.0 samples/s | 65.4 steps/s
[Step=40000 Epoch=154.0] | Loss=0.00098 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.451 | L2-Norm(final)=5.900 | 4165.3 samples/s | 65.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07483 | acc=0.9670 | tpr=0.9701 | fpr=0.0399 | 5063.7 samples/s | 19.8 steps/s
Avg test loss: 0.07202, Avg test acc: 0.96670, Avg tpr: 0.97027, Avg fpr: 0.04115, total FA: 321

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07879 | acc=0.9664 | tpr=0.9732 | fpr=0.0483 | 4855.1 samples/s | 19.0 steps/s
Avg test loss: 0.08043, Avg test acc: 0.96562, Avg tpr: 0.97202, Avg fpr: 0.04846, total FA: 378

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.45320 | acc=0.3102 | tpr=0.0084 | fpr=0.0344 | 4838.0 samples/s | 18.9 steps/s
Avg test loss: 4.45660, Avg test acc: 0.30748, Avg tpr: 0.00962, Avg fpr: 0.03743, total FA: 292

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.63004 | acc=0.3081 | tpr=0.0162 | fpr=0.0580 | 4890.5 samples/s | 19.1 steps/s
Avg test loss: 5.62513, Avg test acc: 0.30595, Avg tpr: 0.01725, Avg fpr: 0.05909, total FA: 461

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.41262 | acc=0.1594 | tpr=0.3805 | fpr=0.8446 | 4980.0 samples/s | 19.5 steps/s
[Step= 100] | Loss=5.38378 | acc=0.1595 | tpr=0.3646 | fpr=0.8443 | 7170.6 samples/s | 28.0 steps/s
[Step= 150] | Loss=5.39247 | acc=0.1582 | tpr=0.3530 | fpr=0.8454 | 7750.0 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.38803 | acc=0.1581 | tpr=0.3552 | fpr=0.8455 | 7618.0 samples/s | 29.8 steps/s
[Step= 250] | Loss=5.37799 | acc=0.1584 | tpr=0.3633 | fpr=0.8454 | 7677.3 samples/s | 30.0 steps/s
[Step= 300] | Loss=5.36707 | acc=0.1587 | tpr=0.3622 | fpr=0.8450 | 7898.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.37199 | acc=0.1586 | tpr=0.3575 | fpr=0.8450 | 7930.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=5.37490 | acc=0.1588 | tpr=0.3534 | fpr=0.8447 | 7861.1 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.37913 | acc=0.1587 | tpr=0.3569 | fpr=0.8449 | 7605.2 samples/s | 29.7 steps/s
[Step= 500] | Loss=5.37944 | acc=0.1589 | tpr=0.3577 | fpr=0.8447 | 8029.4 samples/s | 31.4 steps/s
[Step= 550] | Loss=5.38434 | acc=0.1589 | tpr=0.3573 | fpr=0.8447 | 13825.3 samples/s | 54.0 steps/s
Avg test loss: 5.38628, Avg test acc: 0.15874, Avg tpr: 0.35737, Avg fpr: 0.84487, total FA: 117309

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.71230 | acc=0.1382 | tpr=0.5841 | fpr=0.8698 | 4847.8 samples/s | 18.9 steps/s
[Step= 100] | Loss=7.69318 | acc=0.1392 | tpr=0.5394 | fpr=0.8683 | 7272.9 samples/s | 28.4 steps/s
[Step= 150] | Loss=7.69486 | acc=0.1398 | tpr=0.5389 | fpr=0.8676 | 7687.6 samples/s | 30.0 steps/s
[Step= 200] | Loss=7.68222 | acc=0.1404 | tpr=0.5399 | fpr=0.8669 | 7763.9 samples/s | 30.3 steps/s
[Step= 250] | Loss=7.67372 | acc=0.1404 | tpr=0.5362 | fpr=0.8668 | 7954.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=7.66085 | acc=0.1412 | tpr=0.5353 | fpr=0.8660 | 7603.4 samples/s | 29.7 steps/s
[Step= 350] | Loss=7.66880 | acc=0.1407 | tpr=0.5272 | fpr=0.8663 | 7814.5 samples/s | 30.5 steps/s
[Step= 400] | Loss=7.66705 | acc=0.1406 | tpr=0.5186 | fpr=0.8663 | 8084.2 samples/s | 31.6 steps/s
[Step= 450] | Loss=7.67132 | acc=0.1403 | tpr=0.5175 | fpr=0.8665 | 7481.3 samples/s | 29.2 steps/s
[Step= 500] | Loss=7.67644 | acc=0.1408 | tpr=0.5216 | fpr=0.8661 | 7911.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=7.68099 | acc=0.1406 | tpr=0.5217 | fpr=0.8663 | 14173.1 samples/s | 55.4 steps/s
Avg test loss: 7.68337, Avg test acc: 0.14051, Avg tpr: 0.52298, Avg fpr: 0.86644, total FA: 120304

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12192 | acc=0.9785 | tpr=0.9204 | fpr=0.0204 | 5007.5 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.12273 | acc=0.9796 | tpr=0.9360 | fpr=0.0196 | 7029.5 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.12635 | acc=0.9790 | tpr=0.9395 | fpr=0.0202 | 7728.9 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.13036 | acc=0.9789 | tpr=0.9443 | fpr=0.0204 | 7445.4 samples/s | 29.1 steps/s
[Step= 250] | Loss=0.12792 | acc=0.9792 | tpr=0.9415 | fpr=0.0201 | 8065.7 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.13070 | acc=0.9788 | tpr=0.9404 | fpr=0.0205 | 7851.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.13101 | acc=0.9787 | tpr=0.9430 | fpr=0.0207 | 7319.3 samples/s | 28.6 steps/s
[Step= 400] | Loss=0.13232 | acc=0.9784 | tpr=0.9398 | fpr=0.0209 | 8416.6 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.13496 | acc=0.9780 | tpr=0.9372 | fpr=0.0212 | 7716.2 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.13421 | acc=0.9782 | tpr=0.9392 | fpr=0.0211 | 7803.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13319 | acc=0.9784 | tpr=0.9399 | fpr=0.0209 | 13618.1 samples/s | 53.2 steps/s
Avg test loss: 0.13293, Avg test acc: 0.97840, Avg tpr: 0.93938, Avg fpr: 0.02089, total FA: 2900

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14888 | acc=0.9783 | tpr=0.9381 | fpr=0.0210 | 4951.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.15214 | acc=0.9775 | tpr=0.9531 | fpr=0.0220 | 7069.3 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.15891 | acc=0.9766 | tpr=0.9582 | fpr=0.0231 | 7518.0 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.16136 | acc=0.9762 | tpr=0.9563 | fpr=0.0234 | 7975.1 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.15823 | acc=0.9765 | tpr=0.9537 | fpr=0.0230 | 7898.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.16149 | acc=0.9761 | tpr=0.9455 | fpr=0.0233 | 7588.9 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.16143 | acc=0.9761 | tpr=0.9474 | fpr=0.0234 | 8087.2 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.16224 | acc=0.9759 | tpr=0.9464 | fpr=0.0235 | 7677.1 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.16509 | acc=0.9757 | tpr=0.9455 | fpr=0.0238 | 7925.6 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.16390 | acc=0.9758 | tpr=0.9449 | fpr=0.0236 | 7731.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.16310 | acc=0.9760 | tpr=0.9447 | fpr=0.0234 | 13875.5 samples/s | 54.2 steps/s
Avg test loss: 0.16277, Avg test acc: 0.97605, Avg tpr: 0.94453, Avg fpr: 0.02338, total FA: 3246

server round 20/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=78.0] | Loss=0.01772 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.406 | L2-Norm(final)=8.382 | 6599.4 samples/s | 103.1 steps/s
[Step=40050 Epoch=78.1] | Loss=0.01523 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.409 | L2-Norm(final)=8.389 | 4354.8 samples/s | 68.0 steps/s
[Step=40100 Epoch=78.2] | Loss=0.01552 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.412 | L2-Norm(final)=8.400 | 4864.1 samples/s | 76.0 steps/s
[Step=40150 Epoch=78.3] | Loss=0.01450 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.415 | L2-Norm(final)=8.410 | 5003.0 samples/s | 78.2 steps/s
[Step=40200 Epoch=78.4] | Loss=0.01401 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.417 | L2-Norm(final)=8.418 | 5096.8 samples/s | 79.6 steps/s
[Step=40250 Epoch=78.5] | Loss=0.01387 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.418 | L2-Norm(final)=8.426 | 4873.2 samples/s | 76.1 steps/s
[Step=40300 Epoch=78.6] | Loss=0.01343 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.420 | L2-Norm(final)=8.434 | 5002.1 samples/s | 78.2 steps/s
[Step=40350 Epoch=78.7] | Loss=0.01317 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.421 | L2-Norm(final)=8.442 | 5063.0 samples/s | 79.1 steps/s
[Step=40400 Epoch=78.8] | Loss=0.01303 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.423 | L2-Norm(final)=8.450 | 4991.2 samples/s | 78.0 steps/s
[Step=40450 Epoch=78.9] | Loss=0.01289 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.425 | L2-Norm(final)=8.458 | 4984.5 samples/s | 77.9 steps/s
[Step=40500 Epoch=79.0] | Loss=0.01265 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.426 | L2-Norm(final)=8.466 | 6683.4 samples/s | 104.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=79.0] | Loss=0.00469 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.443 | L2-Norm(final)=8.547 | 5584.9 samples/s | 87.3 steps/s
[Step=40550 Epoch=79.1] | Loss=0.00779 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.445 | L2-Norm(final)=8.555 | 4313.3 samples/s | 67.4 steps/s
[Step=40600 Epoch=79.2] | Loss=0.00878 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.446 | L2-Norm(final)=8.561 | 4397.8 samples/s | 68.7 steps/s
[Step=40650 Epoch=79.3] | Loss=0.00884 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.447 | L2-Norm(final)=8.565 | 4525.8 samples/s | 70.7 steps/s
[Step=40700 Epoch=79.4] | Loss=0.00852 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.447 | L2-Norm(final)=8.569 | 4342.3 samples/s | 67.8 steps/s
[Step=40750 Epoch=79.5] | Loss=0.00847 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.447 | L2-Norm(final)=8.573 | 4371.3 samples/s | 68.3 steps/s
[Step=40800 Epoch=79.6] | Loss=0.00869 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.446 | L2-Norm(final)=8.576 | 4466.6 samples/s | 69.8 steps/s
[Step=40850 Epoch=79.7] | Loss=0.00874 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.446 | L2-Norm(final)=8.579 | 4503.0 samples/s | 70.4 steps/s
[Step=40900 Epoch=79.8] | Loss=0.00882 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.445 | L2-Norm(final)=8.581 | 4425.8 samples/s | 69.2 steps/s
[Step=40950 Epoch=79.9] | Loss=0.00855 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=8.584 | 4332.8 samples/s | 67.7 steps/s
[Step=41000 Epoch=80.0] | Loss=0.00832 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.442 | L2-Norm(final)=8.586 | 5759.6 samples/s | 90.0 steps/s
[Step=41050 Epoch=80.1] | Loss=0.00823 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.441 | L2-Norm(final)=8.589 | 2397.8 samples/s | 37.5 steps/s
[Step=41100 Epoch=80.2] | Loss=0.00799 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.440 | L2-Norm(final)=8.592 | 4370.6 samples/s | 68.3 steps/s
[Step=41150 Epoch=80.3] | Loss=0.00779 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.438 | L2-Norm(final)=8.594 | 4421.2 samples/s | 69.1 steps/s
[Step=41200 Epoch=80.4] | Loss=0.00778 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.436 | L2-Norm(final)=8.597 | 4364.5 samples/s | 68.2 steps/s
[Step=41250 Epoch=80.5] | Loss=0.00767 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.434 | L2-Norm(final)=8.599 | 4509.6 samples/s | 70.5 steps/s
[Step=41300 Epoch=80.6] | Loss=0.00764 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.432 | L2-Norm(final)=8.601 | 4384.3 samples/s | 68.5 steps/s
[Step=41350 Epoch=80.6] | Loss=0.00758 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=8.604 | 4355.0 samples/s | 68.0 steps/s
[Step=41400 Epoch=80.7] | Loss=0.00760 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.428 | L2-Norm(final)=8.606 | 4431.3 samples/s | 69.2 steps/s
[Step=41450 Epoch=80.8] | Loss=0.00757 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.425 | L2-Norm(final)=8.608 | 4590.7 samples/s | 71.7 steps/s
[Step=41500 Epoch=80.9] | Loss=0.00748 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.423 | L2-Norm(final)=8.610 | 4601.7 samples/s | 71.9 steps/s
[Step=41550 Epoch=81.0] | Loss=0.00737 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.420 | L2-Norm(final)=8.612 | 2626.7 samples/s | 41.0 steps/s
[Step=41600 Epoch=81.1] | Loss=0.00738 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.418 | L2-Norm(final)=8.614 | 4471.5 samples/s | 69.9 steps/s
[Step=41650 Epoch=81.2] | Loss=0.00724 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.415 | L2-Norm(final)=8.615 | 4304.9 samples/s | 67.3 steps/s
[Step=41700 Epoch=81.3] | Loss=0.00725 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.412 | L2-Norm(final)=8.617 | 4452.2 samples/s | 69.6 steps/s
[Step=41750 Epoch=81.4] | Loss=0.00719 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.409 | L2-Norm(final)=8.619 | 4384.9 samples/s | 68.5 steps/s
[Step=41800 Epoch=81.5] | Loss=0.00715 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.407 | L2-Norm(final)=8.621 | 4367.6 samples/s | 68.2 steps/s
[Step=41850 Epoch=81.6] | Loss=0.00715 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.404 | L2-Norm(final)=8.623 | 4425.1 samples/s | 69.1 steps/s
[Step=41900 Epoch=81.7] | Loss=0.00727 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.401 | L2-Norm(final)=8.624 | 4564.0 samples/s | 71.3 steps/s
[Step=41950 Epoch=81.8] | Loss=0.00732 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.398 | L2-Norm(final)=8.626 | 4469.7 samples/s | 69.8 steps/s
[Step=42000 Epoch=81.9] | Loss=0.00723 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.396 | L2-Norm(final)=8.627 | 4322.7 samples/s | 67.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step42000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=78.2] | Loss=0.00603 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.395 | L2-Norm(final)=8.560 | 5669.0 samples/s | 88.6 steps/s
[Step=40050 Epoch=78.3] | Loss=0.01501 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.400 | L2-Norm(final)=8.563 | 4489.9 samples/s | 70.2 steps/s
[Step=40100 Epoch=78.4] | Loss=0.01488 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.403 | L2-Norm(final)=8.569 | 4894.0 samples/s | 76.5 steps/s
[Step=40150 Epoch=78.5] | Loss=0.01477 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.405 | L2-Norm(final)=8.575 | 5051.9 samples/s | 78.9 steps/s
[Step=40200 Epoch=78.6] | Loss=0.01374 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.406 | L2-Norm(final)=8.582 | 4974.9 samples/s | 77.7 steps/s
[Step=40250 Epoch=78.7] | Loss=0.01315 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.408 | L2-Norm(final)=8.589 | 4935.3 samples/s | 77.1 steps/s
[Step=40300 Epoch=78.8] | Loss=0.01287 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.410 | L2-Norm(final)=8.597 | 4995.4 samples/s | 78.1 steps/s
[Step=40350 Epoch=78.9] | Loss=0.01299 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.412 | L2-Norm(final)=8.604 | 5083.8 samples/s | 79.4 steps/s
[Step=40400 Epoch=79.0] | Loss=0.01280 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.414 | L2-Norm(final)=8.612 | 5080.1 samples/s | 79.4 steps/s
[Step=40450 Epoch=79.1] | Loss=0.01277 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.416 | L2-Norm(final)=8.619 | 4966.1 samples/s | 77.6 steps/s
[Step=40500 Epoch=79.2] | Loss=0.01279 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.417 | L2-Norm(final)=8.626 | 6770.6 samples/s | 105.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=79.2] | Loss=0.00738 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.433 | L2-Norm(final)=8.696 | 6725.5 samples/s | 105.1 steps/s
[Step=40550 Epoch=79.3] | Loss=0.01068 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.436 | L2-Norm(final)=8.703 | 3851.4 samples/s | 60.2 steps/s
[Step=40600 Epoch=79.4] | Loss=0.01063 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.440 | L2-Norm(final)=8.707 | 4370.9 samples/s | 68.3 steps/s
[Step=40650 Epoch=79.5] | Loss=0.01075 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.442 | L2-Norm(final)=8.711 | 4475.6 samples/s | 69.9 steps/s
[Step=40700 Epoch=79.6] | Loss=0.00964 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=8.715 | 4389.0 samples/s | 68.6 steps/s
[Step=40750 Epoch=79.7] | Loss=0.00932 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=8.719 | 4481.7 samples/s | 70.0 steps/s
[Step=40800 Epoch=79.8] | Loss=0.00935 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=8.722 | 4520.4 samples/s | 70.6 steps/s
[Step=40850 Epoch=79.9] | Loss=0.00915 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.444 | L2-Norm(final)=8.724 | 4377.8 samples/s | 68.4 steps/s
[Step=40900 Epoch=80.0] | Loss=0.00879 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=8.727 | 4347.0 samples/s | 67.9 steps/s
[Step=40950 Epoch=80.1] | Loss=0.00860 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.443 | L2-Norm(final)=8.730 | 4432.7 samples/s | 69.3 steps/s
[Step=41000 Epoch=80.2] | Loss=0.00872 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.442 | L2-Norm(final)=8.733 | 5855.7 samples/s | 91.5 steps/s
[Step=41050 Epoch=80.3] | Loss=0.00852 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.441 | L2-Norm(final)=8.735 | 2394.0 samples/s | 37.4 steps/s
[Step=41100 Epoch=80.3] | Loss=0.00827 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.440 | L2-Norm(final)=8.738 | 4362.3 samples/s | 68.2 steps/s
[Step=41150 Epoch=80.4] | Loss=0.00820 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.438 | L2-Norm(final)=8.740 | 4421.7 samples/s | 69.1 steps/s
[Step=41200 Epoch=80.5] | Loss=0.00806 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.436 | L2-Norm(final)=8.743 | 4396.1 samples/s | 68.7 steps/s
[Step=41250 Epoch=80.6] | Loss=0.00790 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.434 | L2-Norm(final)=8.745 | 4483.1 samples/s | 70.0 steps/s
[Step=41300 Epoch=80.7] | Loss=0.00796 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.432 | L2-Norm(final)=8.747 | 4376.9 samples/s | 68.4 steps/s
[Step=41350 Epoch=80.8] | Loss=0.00797 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=8.749 | 4373.2 samples/s | 68.3 steps/s
[Step=41400 Epoch=80.9] | Loss=0.00789 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.428 | L2-Norm(final)=8.751 | 4502.1 samples/s | 70.3 steps/s
[Step=41450 Epoch=81.0] | Loss=0.00786 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.426 | L2-Norm(final)=8.753 | 4454.8 samples/s | 69.6 steps/s
[Step=41500 Epoch=81.1] | Loss=0.00784 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.423 | L2-Norm(final)=8.755 | 4866.2 samples/s | 76.0 steps/s
[Step=41550 Epoch=81.2] | Loss=0.00774 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.421 | L2-Norm(final)=8.756 | 2575.9 samples/s | 40.2 steps/s
[Step=41600 Epoch=81.3] | Loss=0.00761 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.418 | L2-Norm(final)=8.758 | 4514.3 samples/s | 70.5 steps/s
[Step=41650 Epoch=81.4] | Loss=0.00751 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.416 | L2-Norm(final)=8.760 | 4321.6 samples/s | 67.5 steps/s
[Step=41700 Epoch=81.5] | Loss=0.00739 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.413 | L2-Norm(final)=8.762 | 4388.1 samples/s | 68.6 steps/s
[Step=41750 Epoch=81.6] | Loss=0.00733 | Reg=0.00377 | acc=0.9531 | L2-Norm=19.410 | L2-Norm(final)=8.763 | 4431.5 samples/s | 69.2 steps/s
[Step=41800 Epoch=81.7] | Loss=0.00728 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.407 | L2-Norm(final)=8.765 | 4435.4 samples/s | 69.3 steps/s
[Step=41850 Epoch=81.8] | Loss=0.00727 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.404 | L2-Norm(final)=8.767 | 4441.6 samples/s | 69.4 steps/s
[Step=41900 Epoch=81.9] | Loss=0.00724 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.402 | L2-Norm(final)=8.769 | 4418.7 samples/s | 69.0 steps/s
[Step=41950 Epoch=82.0] | Loss=0.00725 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.399 | L2-Norm(final)=8.770 | 4464.0 samples/s | 69.7 steps/s
[Step=42000 Epoch=82.1] | Loss=0.00723 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.396 | L2-Norm(final)=8.772 | 4368.2 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step42000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=153.3] | Loss=0.00014 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.315 | L2-Norm(final)=5.603 | 6269.9 samples/s | 98.0 steps/s
[Step=40050 Epoch=153.5] | Loss=0.00022 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.318 | L2-Norm(final)=5.607 | 4186.1 samples/s | 65.4 steps/s
[Step=40100 Epoch=153.6] | Loss=0.00019 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.319 | L2-Norm(final)=5.610 | 4652.8 samples/s | 72.7 steps/s
[Step=40150 Epoch=153.8] | Loss=0.00015 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=5.613 | 4745.4 samples/s | 74.1 steps/s
[Step=40200 Epoch=154.0] | Loss=0.00015 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=5.615 | 4701.7 samples/s | 73.5 steps/s
[Step=40250 Epoch=154.2] | Loss=0.00016 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.321 | L2-Norm(final)=5.617 | 6586.5 samples/s | 102.9 steps/s
[Step=40300 Epoch=154.4] | Loss=0.00015 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.321 | L2-Norm(final)=5.619 | 2398.3 samples/s | 37.5 steps/s
[Step=40350 Epoch=154.6] | Loss=0.00014 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.321 | L2-Norm(final)=5.621 | 4856.9 samples/s | 75.9 steps/s
[Step=40400 Epoch=154.8] | Loss=0.00013 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=5.623 | 4539.5 samples/s | 70.9 steps/s
[Step=40450 Epoch=155.0] | Loss=0.00013 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=5.625 | 4788.8 samples/s | 74.8 steps/s
[Step=40500 Epoch=155.2] | Loss=0.00012 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=5.627 | 5249.9 samples/s | 82.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=155.2] | Loss=0.00012 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.324 | L2-Norm(final)=5.646 | 6237.0 samples/s | 97.5 steps/s
[Step=40550 Epoch=155.4] | Loss=0.00010 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.323 | L2-Norm(final)=5.648 | 3740.5 samples/s | 58.4 steps/s
[Step=40600 Epoch=155.6] | Loss=0.00007 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=5.650 | 4225.9 samples/s | 66.0 steps/s
[Step=40650 Epoch=155.8] | Loss=0.00006 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=5.651 | 4215.7 samples/s | 65.9 steps/s
[Step=40700 Epoch=155.9] | Loss=0.00005 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.317 | L2-Norm(final)=5.653 | 4181.6 samples/s | 65.3 steps/s
[Step=40750 Epoch=156.1] | Loss=0.00005 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.314 | L2-Norm(final)=5.654 | 5689.8 samples/s | 88.9 steps/s
[Step=40800 Epoch=156.3] | Loss=0.00004 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.312 | L2-Norm(final)=5.655 | 2250.9 samples/s | 35.2 steps/s
[Step=40850 Epoch=156.5] | Loss=0.00004 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.309 | L2-Norm(final)=5.656 | 4171.8 samples/s | 65.2 steps/s
[Step=40900 Epoch=156.7] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.306 | L2-Norm(final)=5.656 | 4342.3 samples/s | 67.8 steps/s
[Step=40950 Epoch=156.9] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.303 | L2-Norm(final)=5.657 | 4105.3 samples/s | 64.1 steps/s
[Step=41000 Epoch=157.1] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=5.658 | 4761.9 samples/s | 74.4 steps/s
[Step=41050 Epoch=157.3] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.297 | L2-Norm(final)=5.659 | 2453.9 samples/s | 38.3 steps/s
[Step=41100 Epoch=157.5] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.293 | L2-Norm(final)=5.659 | 4165.1 samples/s | 65.1 steps/s
[Step=41150 Epoch=157.7] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.290 | L2-Norm(final)=5.660 | 4212.0 samples/s | 65.8 steps/s
[Step=41200 Epoch=157.9] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.286 | L2-Norm(final)=5.661 | 4173.2 samples/s | 65.2 steps/s
[Step=41250 Epoch=158.1] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.283 | L2-Norm(final)=5.661 | 4140.9 samples/s | 64.7 steps/s
[Step=41300 Epoch=158.2] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.279 | L2-Norm(final)=5.662 | 2616.0 samples/s | 40.9 steps/s
[Step=41350 Epoch=158.4] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.276 | L2-Norm(final)=5.663 | 4172.0 samples/s | 65.2 steps/s
[Step=41400 Epoch=158.6] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.272 | L2-Norm(final)=5.663 | 4278.0 samples/s | 66.8 steps/s
[Step=41450 Epoch=158.8] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.269 | L2-Norm(final)=5.664 | 4148.9 samples/s | 64.8 steps/s
[Step=41500 Epoch=159.0] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.265 | L2-Norm(final)=5.665 | 4228.6 samples/s | 66.1 steps/s
[Step=41550 Epoch=159.2] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.261 | L2-Norm(final)=5.665 | 2583.2 samples/s | 40.4 steps/s
[Step=41600 Epoch=159.4] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.257 | L2-Norm(final)=5.666 | 4245.2 samples/s | 66.3 steps/s
[Step=41650 Epoch=159.6] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.253 | L2-Norm(final)=5.667 | 4187.0 samples/s | 65.4 steps/s
[Step=41700 Epoch=159.8] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.249 | L2-Norm(final)=5.667 | 4271.3 samples/s | 66.7 steps/s
[Step=41750 Epoch=160.0] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.245 | L2-Norm(final)=5.668 | 4193.7 samples/s | 65.5 steps/s
[Step=41800 Epoch=160.2] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.241 | L2-Norm(final)=5.668 | 6087.3 samples/s | 95.1 steps/s
[Step=41850 Epoch=160.4] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.237 | L2-Norm(final)=5.669 | 2186.2 samples/s | 34.2 steps/s
[Step=41900 Epoch=160.5] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.233 | L2-Norm(final)=5.670 | 4178.5 samples/s | 65.3 steps/s
[Step=41950 Epoch=160.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.229 | L2-Norm(final)=5.670 | 4268.6 samples/s | 66.7 steps/s
[Step=42000 Epoch=160.9] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.224 | L2-Norm(final)=5.671 | 4146.9 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step42000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=154.0] | Loss=0.00032 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.270 | L2-Norm(final)=5.912 | 5411.4 samples/s | 84.6 steps/s
[Step=40050 Epoch=154.2] | Loss=0.00030 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.271 | L2-Norm(final)=5.912 | 4276.3 samples/s | 66.8 steps/s
[Step=40100 Epoch=154.4] | Loss=0.00026 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.273 | L2-Norm(final)=5.915 | 4661.7 samples/s | 72.8 steps/s
[Step=40150 Epoch=154.6] | Loss=0.00020 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.274 | L2-Norm(final)=5.918 | 4662.2 samples/s | 72.8 steps/s
[Step=40200 Epoch=154.7] | Loss=0.00018 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.274 | L2-Norm(final)=5.920 | 4733.5 samples/s | 74.0 steps/s
[Step=40250 Epoch=154.9] | Loss=0.00015 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.922 | 6555.9 samples/s | 102.4 steps/s
[Step=40300 Epoch=155.1] | Loss=0.00014 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.924 | 2352.1 samples/s | 36.8 steps/s
[Step=40350 Epoch=155.3] | Loss=0.00013 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.926 | 4762.8 samples/s | 74.4 steps/s
[Step=40400 Epoch=155.5] | Loss=0.00013 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.928 | 4699.0 samples/s | 73.4 steps/s
[Step=40450 Epoch=155.7] | Loss=0.00012 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.930 | 4653.7 samples/s | 72.7 steps/s
[Step=40500 Epoch=155.9] | Loss=0.00011 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.276 | L2-Norm(final)=5.932 | 5650.0 samples/s | 88.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=155.9] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.277 | L2-Norm(final)=5.950 | 5815.3 samples/s | 90.9 steps/s
[Step=40550 Epoch=156.1] | Loss=0.00006 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.275 | L2-Norm(final)=5.952 | 3875.4 samples/s | 60.6 steps/s
[Step=40600 Epoch=156.3] | Loss=0.00005 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.272 | L2-Norm(final)=5.953 | 4198.1 samples/s | 65.6 steps/s
[Step=40650 Epoch=156.5] | Loss=0.00004 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.270 | L2-Norm(final)=5.955 | 4260.5 samples/s | 66.6 steps/s
[Step=40700 Epoch=156.7] | Loss=0.00004 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.267 | L2-Norm(final)=5.956 | 4148.5 samples/s | 64.8 steps/s
[Step=40750 Epoch=156.9] | Loss=0.00004 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.264 | L2-Norm(final)=5.958 | 5775.0 samples/s | 90.2 steps/s
[Step=40800 Epoch=157.1] | Loss=0.00004 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.261 | L2-Norm(final)=5.959 | 2232.5 samples/s | 34.9 steps/s
[Step=40850 Epoch=157.2] | Loss=0.00003 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.258 | L2-Norm(final)=5.960 | 4240.5 samples/s | 66.3 steps/s
[Step=40900 Epoch=157.4] | Loss=0.00003 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.255 | L2-Norm(final)=5.961 | 4126.6 samples/s | 64.5 steps/s
[Step=40950 Epoch=157.6] | Loss=0.00003 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.252 | L2-Norm(final)=5.962 | 4189.5 samples/s | 65.5 steps/s
[Step=41000 Epoch=157.8] | Loss=0.00003 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.249 | L2-Norm(final)=5.963 | 4906.3 samples/s | 76.7 steps/s
[Step=41050 Epoch=158.0] | Loss=0.00003 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.245 | L2-Norm(final)=5.964 | 2467.8 samples/s | 38.6 steps/s
[Step=41100 Epoch=158.2] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.242 | L2-Norm(final)=5.964 | 4049.5 samples/s | 63.3 steps/s
[Step=41150 Epoch=158.4] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.239 | L2-Norm(final)=5.965 | 4198.5 samples/s | 65.6 steps/s
[Step=41200 Epoch=158.6] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.235 | L2-Norm(final)=5.966 | 4291.5 samples/s | 67.1 steps/s
[Step=41250 Epoch=158.8] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.232 | L2-Norm(final)=5.967 | 4165.4 samples/s | 65.1 steps/s
[Step=41300 Epoch=159.0] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.228 | L2-Norm(final)=5.967 | 2585.4 samples/s | 40.4 steps/s
[Step=41350 Epoch=159.2] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.224 | L2-Norm(final)=5.968 | 4134.5 samples/s | 64.6 steps/s
[Step=41400 Epoch=159.4] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.221 | L2-Norm(final)=5.969 | 4249.1 samples/s | 66.4 steps/s
[Step=41450 Epoch=159.6] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.217 | L2-Norm(final)=5.969 | 4172.4 samples/s | 65.2 steps/s
[Step=41500 Epoch=159.7] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.213 | L2-Norm(final)=5.970 | 4222.6 samples/s | 66.0 steps/s
[Step=41550 Epoch=159.9] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.209 | L2-Norm(final)=5.971 | 2603.9 samples/s | 40.7 steps/s
[Step=41600 Epoch=160.1] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.205 | L2-Norm(final)=5.971 | 4202.3 samples/s | 65.7 steps/s
[Step=41650 Epoch=160.3] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.201 | L2-Norm(final)=5.972 | 4162.9 samples/s | 65.0 steps/s
[Step=41700 Epoch=160.5] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.197 | L2-Norm(final)=5.973 | 4155.3 samples/s | 64.9 steps/s
[Step=41750 Epoch=160.7] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.193 | L2-Norm(final)=5.973 | 4265.3 samples/s | 66.6 steps/s
[Step=41800 Epoch=160.9] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.188 | L2-Norm(final)=5.974 | 6828.3 samples/s | 106.7 steps/s
[Step=41850 Epoch=161.1] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.184 | L2-Norm(final)=5.975 | 2098.2 samples/s | 32.8 steps/s
[Step=41900 Epoch=161.3] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.180 | L2-Norm(final)=5.976 | 4278.0 samples/s | 66.8 steps/s
[Step=41950 Epoch=161.5] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.175 | L2-Norm(final)=5.976 | 4094.4 samples/s | 64.0 steps/s
[Step=42000 Epoch=161.7] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.171 | L2-Norm(final)=5.977 | 4146.2 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07741 | acc=0.9691 | tpr=0.9784 | fpr=0.0510 | 4925.7 samples/s | 19.2 steps/s
Avg test loss: 0.07627, Avg test acc: 0.96927, Avg tpr: 0.97756, Avg fpr: 0.04897, total FA: 382

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08028 | acc=0.9677 | tpr=0.9795 | fpr=0.0577 | 4991.0 samples/s | 19.5 steps/s
Avg test loss: 0.08091, Avg test acc: 0.96739, Avg tpr: 0.97925, Avg fpr: 0.05871, total FA: 458

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.03180 | acc=0.3015 | tpr=0.0153 | fpr=0.0771 | 5028.3 samples/s | 19.6 steps/s
Avg test loss: 5.02800, Avg test acc: 0.29946, Avg tpr: 0.01638, Avg fpr: 0.07794, total FA: 608

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.50183 | acc=0.3045 | tpr=0.0278 | fpr=0.0946 | 5037.8 samples/s | 19.7 steps/s
Avg test loss: 5.48428, Avg test acc: 0.30203, Avg tpr: 0.03025, Avg fpr: 0.10024, total FA: 782

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.36407 | acc=0.1349 | tpr=0.5752 | fpr=0.8730 | 5201.4 samples/s | 20.3 steps/s
[Step= 100] | Loss=7.31400 | acc=0.1336 | tpr=0.5544 | fpr=0.8742 | 6937.7 samples/s | 27.1 steps/s
[Step= 150] | Loss=7.32400 | acc=0.1336 | tpr=0.5331 | fpr=0.8737 | 7552.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=7.31211 | acc=0.1339 | tpr=0.5366 | fpr=0.8735 | 7659.5 samples/s | 29.9 steps/s
[Step= 250] | Loss=7.30246 | acc=0.1336 | tpr=0.5389 | fpr=0.8738 | 7663.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=7.29313 | acc=0.1336 | tpr=0.5345 | fpr=0.8737 | 7953.2 samples/s | 31.1 steps/s
[Step= 350] | Loss=7.29880 | acc=0.1333 | tpr=0.5291 | fpr=0.8739 | 7835.2 samples/s | 30.6 steps/s
[Step= 400] | Loss=7.30239 | acc=0.1332 | tpr=0.5230 | fpr=0.8739 | 7728.2 samples/s | 30.2 steps/s
[Step= 450] | Loss=7.30480 | acc=0.1329 | tpr=0.5229 | fpr=0.8742 | 7994.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=7.30693 | acc=0.1331 | tpr=0.5233 | fpr=0.8739 | 7891.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=7.31358 | acc=0.1331 | tpr=0.5237 | fpr=0.8740 | 13361.3 samples/s | 52.2 steps/s
Avg test loss: 7.31538, Avg test acc: 0.13298, Avg tpr: 0.52496, Avg fpr: 0.87414, total FA: 121373

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.23659 | acc=0.1117 | tpr=0.7080 | fpr=0.8990 | 4869.8 samples/s | 19.0 steps/s
[Step= 100] | Loss=8.20664 | acc=0.1114 | tpr=0.6887 | fpr=0.8994 | 7292.7 samples/s | 28.5 steps/s
[Step= 150] | Loss=8.20650 | acc=0.1103 | tpr=0.6801 | fpr=0.9002 | 7681.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=8.19855 | acc=0.1108 | tpr=0.6831 | fpr=0.8996 | 7631.5 samples/s | 29.8 steps/s
[Step= 250] | Loss=8.19076 | acc=0.1105 | tpr=0.6760 | fpr=0.8998 | 7855.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=8.18154 | acc=0.1104 | tpr=0.6705 | fpr=0.8998 | 8134.4 samples/s | 31.8 steps/s
[Step= 350] | Loss=8.18967 | acc=0.1099 | tpr=0.6662 | fpr=0.9002 | 7657.2 samples/s | 29.9 steps/s
[Step= 400] | Loss=8.19168 | acc=0.1097 | tpr=0.6565 | fpr=0.9003 | 7836.2 samples/s | 30.6 steps/s
[Step= 450] | Loss=8.19978 | acc=0.1095 | tpr=0.6519 | fpr=0.9004 | 7794.4 samples/s | 30.4 steps/s
[Step= 500] | Loss=8.20283 | acc=0.1099 | tpr=0.6533 | fpr=0.9000 | 7890.2 samples/s | 30.8 steps/s
[Step= 550] | Loss=8.20969 | acc=0.1097 | tpr=0.6510 | fpr=0.9001 | 13415.3 samples/s | 52.4 steps/s
Avg test loss: 8.21186, Avg test acc: 0.10965, Avg tpr: 0.65135, Avg fpr: 0.90020, total FA: 124991

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13745 | acc=0.9776 | tpr=0.9381 | fpr=0.0217 | 4826.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.13854 | acc=0.9783 | tpr=0.9446 | fpr=0.0210 | 7582.6 samples/s | 29.6 steps/s
[Step= 150] | Loss=0.14411 | acc=0.9776 | tpr=0.9481 | fpr=0.0219 | 7612.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.14763 | acc=0.9775 | tpr=0.9475 | fpr=0.0219 | 7758.0 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.14485 | acc=0.9778 | tpr=0.9459 | fpr=0.0217 | 7561.5 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.14705 | acc=0.9774 | tpr=0.9425 | fpr=0.0219 | 7935.5 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.14729 | acc=0.9774 | tpr=0.9449 | fpr=0.0220 | 7618.9 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.14881 | acc=0.9774 | tpr=0.9442 | fpr=0.0220 | 7726.2 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.15152 | acc=0.9770 | tpr=0.9426 | fpr=0.0224 | 8100.1 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.15049 | acc=0.9771 | tpr=0.9436 | fpr=0.0223 | 7766.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.14938 | acc=0.9773 | tpr=0.9439 | fpr=0.0221 | 13736.3 samples/s | 53.7 steps/s
Avg test loss: 0.14909, Avg test acc: 0.97732, Avg tpr: 0.94374, Avg fpr: 0.02207, total FA: 3065

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14479 | acc=0.9756 | tpr=0.9602 | fpr=0.0241 | 4997.8 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.14643 | acc=0.9760 | tpr=0.9701 | fpr=0.0239 | 6838.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.15386 | acc=0.9751 | tpr=0.9697 | fpr=0.0248 | 7948.6 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.15698 | acc=0.9750 | tpr=0.9672 | fpr=0.0248 | 7933.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.15445 | acc=0.9754 | tpr=0.9633 | fpr=0.0244 | 7586.3 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.15749 | acc=0.9750 | tpr=0.9600 | fpr=0.0248 | 7704.3 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.15729 | acc=0.9750 | tpr=0.9606 | fpr=0.0247 | 7640.5 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.15851 | acc=0.9750 | tpr=0.9590 | fpr=0.0247 | 8345.3 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.16121 | acc=0.9746 | tpr=0.9567 | fpr=0.0251 | 7795.1 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.16023 | acc=0.9747 | tpr=0.9559 | fpr=0.0250 | 7648.7 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.15906 | acc=0.9750 | tpr=0.9574 | fpr=0.0247 | 14442.4 samples/s | 56.4 steps/s
Avg test loss: 0.15882, Avg test acc: 0.97497, Avg tpr: 0.95721, Avg fpr: 0.02471, total FA: 3431

server round 21/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=81.9] | Loss=0.00077 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.220 | L2-Norm(final)=8.677 | 6266.1 samples/s | 97.9 steps/s
[Step=42050 Epoch=82.0] | Loss=0.00730 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.218 | L2-Norm(final)=8.682 | 4503.3 samples/s | 70.4 steps/s
[Step=42100 Epoch=82.1] | Loss=0.00668 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.216 | L2-Norm(final)=8.687 | 4938.3 samples/s | 77.2 steps/s
[Step=42150 Epoch=82.2] | Loss=0.00645 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.213 | L2-Norm(final)=8.692 | 5086.7 samples/s | 79.5 steps/s
[Step=42200 Epoch=82.3] | Loss=0.00621 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.210 | L2-Norm(final)=8.697 | 5029.9 samples/s | 78.6 steps/s
[Step=42250 Epoch=82.4] | Loss=0.00618 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.207 | L2-Norm(final)=8.702 | 4908.6 samples/s | 76.7 steps/s
[Step=42300 Epoch=82.5] | Loss=0.00597 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.204 | L2-Norm(final)=8.708 | 4945.3 samples/s | 77.3 steps/s
[Step=42350 Epoch=82.6] | Loss=0.00615 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.201 | L2-Norm(final)=8.713 | 5085.6 samples/s | 79.5 steps/s
[Step=42400 Epoch=82.7] | Loss=0.00610 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.199 | L2-Norm(final)=8.718 | 4954.7 samples/s | 77.4 steps/s
[Step=42450 Epoch=82.8] | Loss=0.00604 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.196 | L2-Norm(final)=8.722 | 5037.6 samples/s | 78.7 steps/s
[Step=42500 Epoch=82.9] | Loss=0.00603 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.193 | L2-Norm(final)=8.727 | 6618.9 samples/s | 103.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=82.9] | Loss=0.00424 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.164 | L2-Norm(final)=8.776 | 6573.5 samples/s | 102.7 steps/s
[Step=42550 Epoch=83.0] | Loss=0.00641 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.162 | L2-Norm(final)=8.779 | 3962.9 samples/s | 61.9 steps/s
[Step=42600 Epoch=83.1] | Loss=0.00690 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.160 | L2-Norm(final)=8.783 | 4463.5 samples/s | 69.7 steps/s
[Step=42650 Epoch=83.2] | Loss=0.00752 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.158 | L2-Norm(final)=8.786 | 4385.4 samples/s | 68.5 steps/s
[Step=42700 Epoch=83.3] | Loss=0.00821 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.157 | L2-Norm(final)=8.787 | 4424.5 samples/s | 69.1 steps/s
[Step=42750 Epoch=83.4] | Loss=0.00816 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=8.788 | 4374.7 samples/s | 68.4 steps/s
[Step=42800 Epoch=83.5] | Loss=0.00825 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.156 | L2-Norm(final)=8.791 | 4487.9 samples/s | 70.1 steps/s
[Step=42850 Epoch=83.6] | Loss=0.00856 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.155 | L2-Norm(final)=8.793 | 4399.2 samples/s | 68.7 steps/s
[Step=42900 Epoch=83.7] | Loss=0.00861 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=8.795 | 4405.6 samples/s | 68.8 steps/s
[Step=42950 Epoch=83.8] | Loss=0.00861 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=8.798 | 4388.8 samples/s | 68.6 steps/s
[Step=43000 Epoch=83.9] | Loss=0.00858 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=8.800 | 5780.8 samples/s | 90.3 steps/s
[Step=43050 Epoch=84.0] | Loss=0.00837 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.155 | L2-Norm(final)=8.803 | 2376.3 samples/s | 37.1 steps/s
[Step=43100 Epoch=84.1] | Loss=0.00837 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.154 | L2-Norm(final)=8.805 | 4429.8 samples/s | 69.2 steps/s
[Step=43150 Epoch=84.2] | Loss=0.00819 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.153 | L2-Norm(final)=8.808 | 4410.9 samples/s | 68.9 steps/s
[Step=43200 Epoch=84.3] | Loss=0.00814 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.151 | L2-Norm(final)=8.810 | 4421.1 samples/s | 69.1 steps/s
[Step=43250 Epoch=84.4] | Loss=0.00818 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.150 | L2-Norm(final)=8.813 | 4481.2 samples/s | 70.0 steps/s
[Step=43300 Epoch=84.5] | Loss=0.00819 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.148 | L2-Norm(final)=8.815 | 4356.9 samples/s | 68.1 steps/s
[Step=43350 Epoch=84.5] | Loss=0.00813 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.146 | L2-Norm(final)=8.817 | 4371.0 samples/s | 68.3 steps/s
[Step=43400 Epoch=84.6] | Loss=0.00814 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.144 | L2-Norm(final)=8.819 | 4454.1 samples/s | 69.6 steps/s
[Step=43450 Epoch=84.7] | Loss=0.00804 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.142 | L2-Norm(final)=8.821 | 4456.0 samples/s | 69.6 steps/s
[Step=43500 Epoch=84.8] | Loss=0.00801 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.140 | L2-Norm(final)=8.824 | 4815.0 samples/s | 75.2 steps/s
[Step=43550 Epoch=84.9] | Loss=0.00806 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.138 | L2-Norm(final)=8.826 | 2604.7 samples/s | 40.7 steps/s
[Step=43600 Epoch=85.0] | Loss=0.00795 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.136 | L2-Norm(final)=8.828 | 4440.2 samples/s | 69.4 steps/s
[Step=43650 Epoch=85.1] | Loss=0.00784 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.134 | L2-Norm(final)=8.830 | 4447.3 samples/s | 69.5 steps/s
[Step=43700 Epoch=85.2] | Loss=0.00774 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.131 | L2-Norm(final)=8.832 | 4346.0 samples/s | 67.9 steps/s
[Step=43750 Epoch=85.3] | Loss=0.00763 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.129 | L2-Norm(final)=8.834 | 4445.8 samples/s | 69.5 steps/s
[Step=43800 Epoch=85.4] | Loss=0.00766 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.126 | L2-Norm(final)=8.836 | 4515.1 samples/s | 70.5 steps/s
[Step=43850 Epoch=85.5] | Loss=0.00763 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.124 | L2-Norm(final)=8.838 | 4495.5 samples/s | 70.2 steps/s
[Step=43900 Epoch=85.6] | Loss=0.00756 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.121 | L2-Norm(final)=8.841 | 4409.2 samples/s | 68.9 steps/s
[Step=43950 Epoch=85.7] | Loss=0.00755 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.119 | L2-Norm(final)=8.843 | 4406.3 samples/s | 68.8 steps/s
[Step=44000 Epoch=85.8] | Loss=0.00751 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.116 | L2-Norm(final)=8.845 | 4442.3 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step44000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=82.1] | Loss=0.00037 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.219 | L2-Norm(final)=8.823 | 5496.2 samples/s | 85.9 steps/s
[Step=42050 Epoch=82.2] | Loss=0.00543 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.216 | L2-Norm(final)=8.826 | 4592.3 samples/s | 71.8 steps/s
[Step=42100 Epoch=82.3] | Loss=0.00667 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.213 | L2-Norm(final)=8.831 | 5027.3 samples/s | 78.6 steps/s
[Step=42150 Epoch=82.4] | Loss=0.00613 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.210 | L2-Norm(final)=8.837 | 4991.9 samples/s | 78.0 steps/s
[Step=42200 Epoch=82.5] | Loss=0.00604 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.207 | L2-Norm(final)=8.843 | 4944.1 samples/s | 77.3 steps/s
[Step=42250 Epoch=82.6] | Loss=0.00591 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.205 | L2-Norm(final)=8.849 | 5016.5 samples/s | 78.4 steps/s
[Step=42300 Epoch=82.7] | Loss=0.00586 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.203 | L2-Norm(final)=8.855 | 4998.5 samples/s | 78.1 steps/s
[Step=42350 Epoch=82.8] | Loss=0.00596 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.201 | L2-Norm(final)=8.861 | 5223.8 samples/s | 81.6 steps/s
[Step=42400 Epoch=82.9] | Loss=0.00601 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.199 | L2-Norm(final)=8.866 | 4834.0 samples/s | 75.5 steps/s
[Step=42450 Epoch=83.0] | Loss=0.00595 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.197 | L2-Norm(final)=8.872 | 5005.7 samples/s | 78.2 steps/s
[Step=42500 Epoch=83.1] | Loss=0.00597 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.195 | L2-Norm(final)=8.877 | 6777.6 samples/s | 105.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=83.1] | Loss=0.00140 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=8.930 | 6348.6 samples/s | 99.2 steps/s
[Step=42550 Epoch=83.2] | Loss=0.00653 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=8.935 | 4020.2 samples/s | 62.8 steps/s
[Step=42600 Epoch=83.3] | Loss=0.00759 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=8.939 | 4475.0 samples/s | 69.9 steps/s
[Step=42650 Epoch=83.4] | Loss=0.00757 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=8.943 | 4445.3 samples/s | 69.5 steps/s
[Step=42700 Epoch=83.5] | Loss=0.00785 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=8.947 | 4473.4 samples/s | 69.9 steps/s
[Step=42750 Epoch=83.6] | Loss=0.00765 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.174 | L2-Norm(final)=8.951 | 4433.9 samples/s | 69.3 steps/s
[Step=42800 Epoch=83.7] | Loss=0.00776 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.174 | L2-Norm(final)=8.954 | 4445.2 samples/s | 69.5 steps/s
[Step=42850 Epoch=83.8] | Loss=0.00796 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.174 | L2-Norm(final)=8.956 | 4423.9 samples/s | 69.1 steps/s
[Step=42900 Epoch=83.9] | Loss=0.00803 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=8.959 | 4456.9 samples/s | 69.6 steps/s
[Step=42950 Epoch=84.0] | Loss=0.00816 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=8.962 | 4457.6 samples/s | 69.7 steps/s
[Step=43000 Epoch=84.1] | Loss=0.00816 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=8.965 | 5804.3 samples/s | 90.7 steps/s
[Step=43050 Epoch=84.2] | Loss=0.00792 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.171 | L2-Norm(final)=8.967 | 2394.2 samples/s | 37.4 steps/s
[Step=43100 Epoch=84.3] | Loss=0.00783 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.170 | L2-Norm(final)=8.970 | 4439.6 samples/s | 69.4 steps/s
[Step=43150 Epoch=84.4] | Loss=0.00768 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.169 | L2-Norm(final)=8.973 | 4405.4 samples/s | 68.8 steps/s
[Step=43200 Epoch=84.5] | Loss=0.00770 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.168 | L2-Norm(final)=8.976 | 4476.4 samples/s | 69.9 steps/s
[Step=43250 Epoch=84.6] | Loss=0.00755 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.166 | L2-Norm(final)=8.979 | 4411.6 samples/s | 68.9 steps/s
[Step=43300 Epoch=84.7] | Loss=0.00741 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.164 | L2-Norm(final)=8.982 | 4519.3 samples/s | 70.6 steps/s
[Step=43350 Epoch=84.7] | Loss=0.00753 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.162 | L2-Norm(final)=8.985 | 4360.6 samples/s | 68.1 steps/s
[Step=43400 Epoch=84.8] | Loss=0.00762 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.160 | L2-Norm(final)=8.987 | 4513.0 samples/s | 70.5 steps/s
[Step=43450 Epoch=84.9] | Loss=0.00757 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.158 | L2-Norm(final)=8.990 | 4410.8 samples/s | 68.9 steps/s
[Step=43500 Epoch=85.0] | Loss=0.00756 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=8.992 | 4968.9 samples/s | 77.6 steps/s
[Step=43550 Epoch=85.1] | Loss=0.00753 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.154 | L2-Norm(final)=8.994 | 2571.9 samples/s | 40.2 steps/s
[Step=43600 Epoch=85.2] | Loss=0.00749 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.152 | L2-Norm(final)=8.997 | 4375.8 samples/s | 68.4 steps/s
[Step=43650 Epoch=85.3] | Loss=0.00738 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.149 | L2-Norm(final)=8.999 | 4370.1 samples/s | 68.3 steps/s
[Step=43700 Epoch=85.4] | Loss=0.00737 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.147 | L2-Norm(final)=9.001 | 4445.0 samples/s | 69.5 steps/s
[Step=43750 Epoch=85.5] | Loss=0.00733 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.145 | L2-Norm(final)=9.003 | 4446.2 samples/s | 69.5 steps/s
[Step=43800 Epoch=85.6] | Loss=0.00735 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.142 | L2-Norm(final)=9.005 | 4480.7 samples/s | 70.0 steps/s
[Step=43850 Epoch=85.7] | Loss=0.00730 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.140 | L2-Norm(final)=9.008 | 4418.6 samples/s | 69.0 steps/s
[Step=43900 Epoch=85.8] | Loss=0.00737 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.138 | L2-Norm(final)=9.010 | 4506.2 samples/s | 70.4 steps/s
[Step=43950 Epoch=85.9] | Loss=0.00730 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.136 | L2-Norm(final)=9.012 | 4446.0 samples/s | 69.5 steps/s
[Step=44000 Epoch=86.0] | Loss=0.00729 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.133 | L2-Norm(final)=9.014 | 4462.8 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step44000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=160.9] | Loss=0.00009 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.217 | L2-Norm(final)=5.689 | 5161.4 samples/s | 80.6 steps/s
[Step=42050 Epoch=161.1] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.215 | L2-Norm(final)=5.690 | 4409.6 samples/s | 68.9 steps/s
[Step=42100 Epoch=161.3] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.215 | L2-Norm(final)=5.692 | 4724.2 samples/s | 73.8 steps/s
[Step=42150 Epoch=161.5] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.214 | L2-Norm(final)=5.694 | 4749.9 samples/s | 74.2 steps/s
[Step=42200 Epoch=161.7] | Loss=0.00003 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.214 | L2-Norm(final)=5.696 | 4851.3 samples/s | 75.8 steps/s
[Step=42250 Epoch=161.9] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.213 | L2-Norm(final)=5.698 | 6380.4 samples/s | 99.7 steps/s
[Step=42300 Epoch=162.1] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.213 | L2-Norm(final)=5.700 | 2421.2 samples/s | 37.8 steps/s
[Step=42350 Epoch=162.3] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.212 | L2-Norm(final)=5.702 | 4682.3 samples/s | 73.2 steps/s
[Step=42400 Epoch=162.5] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.211 | L2-Norm(final)=5.704 | 4733.9 samples/s | 74.0 steps/s
[Step=42450 Epoch=162.7] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.211 | L2-Norm(final)=5.706 | 4642.6 samples/s | 72.5 steps/s
[Step=42500 Epoch=162.8] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.210 | L2-Norm(final)=5.707 | 5501.2 samples/s | 86.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=162.8] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.202 | L2-Norm(final)=5.726 | 6476.5 samples/s | 101.2 steps/s
[Step=42550 Epoch=163.0] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.198 | L2-Norm(final)=5.728 | 3740.8 samples/s | 58.4 steps/s
[Step=42600 Epoch=163.2] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.191 | L2-Norm(final)=5.729 | 4166.1 samples/s | 65.1 steps/s
[Step=42650 Epoch=163.4] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.184 | L2-Norm(final)=5.731 | 4228.5 samples/s | 66.1 steps/s
[Step=42700 Epoch=163.6] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.177 | L2-Norm(final)=5.732 | 4334.6 samples/s | 67.7 steps/s
[Step=42750 Epoch=163.8] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.170 | L2-Norm(final)=5.733 | 5445.0 samples/s | 85.1 steps/s
[Step=42800 Epoch=164.0] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.163 | L2-Norm(final)=5.734 | 2251.4 samples/s | 35.2 steps/s
[Step=42850 Epoch=164.2] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.155 | L2-Norm(final)=5.735 | 4226.3 samples/s | 66.0 steps/s
[Step=42900 Epoch=164.4] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.148 | L2-Norm(final)=5.736 | 4245.4 samples/s | 66.3 steps/s
[Step=42950 Epoch=164.6] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.140 | L2-Norm(final)=5.737 | 4196.8 samples/s | 65.6 steps/s
[Step=43000 Epoch=164.8] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.132 | L2-Norm(final)=5.738 | 4810.9 samples/s | 75.2 steps/s
[Step=43050 Epoch=165.0] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.124 | L2-Norm(final)=5.738 | 2454.2 samples/s | 38.3 steps/s
[Step=43100 Epoch=165.1] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.116 | L2-Norm(final)=5.739 | 4120.9 samples/s | 64.4 steps/s
[Step=43150 Epoch=165.3] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.108 | L2-Norm(final)=5.740 | 4200.3 samples/s | 65.6 steps/s
[Step=43200 Epoch=165.5] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.100 | L2-Norm(final)=5.741 | 4234.7 samples/s | 66.2 steps/s
[Step=43250 Epoch=165.7] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.091 | L2-Norm(final)=5.741 | 4216.9 samples/s | 65.9 steps/s
[Step=43300 Epoch=165.9] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.083 | L2-Norm(final)=5.742 | 2600.7 samples/s | 40.6 steps/s
[Step=43350 Epoch=166.1] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.074 | L2-Norm(final)=5.743 | 4285.2 samples/s | 67.0 steps/s
[Step=43400 Epoch=166.3] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.065 | L2-Norm(final)=5.743 | 4290.5 samples/s | 67.0 steps/s
[Step=43450 Epoch=166.5] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.057 | L2-Norm(final)=5.744 | 4210.7 samples/s | 65.8 steps/s
[Step=43500 Epoch=166.7] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.048 | L2-Norm(final)=5.745 | 4141.6 samples/s | 64.7 steps/s
[Step=43550 Epoch=166.9] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.039 | L2-Norm(final)=5.745 | 2640.8 samples/s | 41.3 steps/s
[Step=43600 Epoch=167.1] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.030 | L2-Norm(final)=5.746 | 4177.0 samples/s | 65.3 steps/s
[Step=43650 Epoch=167.3] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.021 | L2-Norm(final)=5.747 | 4224.0 samples/s | 66.0 steps/s
[Step=43700 Epoch=167.4] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.011 | L2-Norm(final)=5.747 | 4241.8 samples/s | 66.3 steps/s
[Step=43750 Epoch=167.6] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.002 | L2-Norm(final)=5.748 | 4231.2 samples/s | 66.1 steps/s
[Step=43800 Epoch=167.8] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.992 | L2-Norm(final)=5.749 | 6213.6 samples/s | 97.1 steps/s
[Step=43850 Epoch=168.0] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.983 | L2-Norm(final)=5.750 | 2192.8 samples/s | 34.3 steps/s
[Step=43900 Epoch=168.2] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.973 | L2-Norm(final)=5.750 | 4128.3 samples/s | 64.5 steps/s
[Step=43950 Epoch=168.4] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.963 | L2-Norm(final)=5.751 | 4217.5 samples/s | 65.9 steps/s
[Step=44000 Epoch=168.6] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.953 | L2-Norm(final)=5.752 | 4176.9 samples/s | 65.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step44000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=161.7] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.167 | L2-Norm(final)=6.001 | 6309.5 samples/s | 98.6 steps/s
[Step=42050 Epoch=161.9] | Loss=0.00003 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.166 | L2-Norm(final)=6.003 | 4158.9 samples/s | 65.0 steps/s
[Step=42100 Epoch=162.1] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.165 | L2-Norm(final)=6.004 | 4641.4 samples/s | 72.5 steps/s
[Step=42150 Epoch=162.3] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.164 | L2-Norm(final)=6.006 | 4678.0 samples/s | 73.1 steps/s
[Step=42200 Epoch=162.4] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.164 | L2-Norm(final)=6.008 | 4641.2 samples/s | 72.5 steps/s
[Step=42250 Epoch=162.6] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.163 | L2-Norm(final)=6.010 | 6589.3 samples/s | 103.0 steps/s
[Step=42300 Epoch=162.8] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.162 | L2-Norm(final)=6.011 | 2318.4 samples/s | 36.2 steps/s
[Step=42350 Epoch=163.0] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.161 | L2-Norm(final)=6.013 | 4753.7 samples/s | 74.3 steps/s
[Step=42400 Epoch=163.2] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.160 | L2-Norm(final)=6.015 | 4400.2 samples/s | 68.8 steps/s
[Step=42450 Epoch=163.4] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.159 | L2-Norm(final)=6.017 | 4759.2 samples/s | 74.4 steps/s
[Step=42500 Epoch=163.6] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.158 | L2-Norm(final)=6.019 | 5323.1 samples/s | 83.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=163.6] | Loss=0.00004 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.149 | L2-Norm(final)=6.038 | 5719.7 samples/s | 89.4 steps/s
[Step=42550 Epoch=163.8] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.144 | L2-Norm(final)=6.040 | 3823.9 samples/s | 59.7 steps/s
[Step=42600 Epoch=164.0] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.137 | L2-Norm(final)=6.042 | 4098.3 samples/s | 64.0 steps/s
[Step=42650 Epoch=164.2] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.130 | L2-Norm(final)=6.044 | 4135.1 samples/s | 64.6 steps/s
[Step=42700 Epoch=164.4] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.122 | L2-Norm(final)=6.046 | 4122.6 samples/s | 64.4 steps/s
[Step=42750 Epoch=164.6] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.114 | L2-Norm(final)=6.047 | 5663.6 samples/s | 88.5 steps/s
[Step=42800 Epoch=164.8] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.107 | L2-Norm(final)=6.049 | 2204.6 samples/s | 34.4 steps/s
[Step=42850 Epoch=164.9] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.099 | L2-Norm(final)=6.050 | 4219.2 samples/s | 65.9 steps/s
[Step=42900 Epoch=165.1] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.091 | L2-Norm(final)=6.051 | 3991.1 samples/s | 62.4 steps/s
[Step=42950 Epoch=165.3] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.082 | L2-Norm(final)=6.052 | 4135.1 samples/s | 64.6 steps/s
[Step=43000 Epoch=165.5] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.074 | L2-Norm(final)=6.053 | 4799.9 samples/s | 75.0 steps/s
[Step=43050 Epoch=165.7] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.066 | L2-Norm(final)=6.054 | 2378.2 samples/s | 37.2 steps/s
[Step=43100 Epoch=165.9] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.057 | L2-Norm(final)=6.055 | 4044.8 samples/s | 63.2 steps/s
[Step=43150 Epoch=166.1] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.049 | L2-Norm(final)=6.056 | 4108.2 samples/s | 64.2 steps/s
[Step=43200 Epoch=166.3] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.040 | L2-Norm(final)=6.057 | 4140.5 samples/s | 64.7 steps/s
[Step=43250 Epoch=166.5] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.031 | L2-Norm(final)=6.058 | 4207.5 samples/s | 65.7 steps/s
[Step=43300 Epoch=166.7] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.022 | L2-Norm(final)=6.059 | 2500.8 samples/s | 39.1 steps/s
[Step=43350 Epoch=166.9] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.013 | L2-Norm(final)=6.060 | 4252.0 samples/s | 66.4 steps/s
[Step=43400 Epoch=167.1] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.004 | L2-Norm(final)=6.061 | 4008.4 samples/s | 62.6 steps/s
[Step=43450 Epoch=167.3] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.995 | L2-Norm(final)=6.062 | 4195.3 samples/s | 65.6 steps/s
[Step=43500 Epoch=167.4] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.985 | L2-Norm(final)=6.063 | 4075.8 samples/s | 63.7 steps/s
[Step=43550 Epoch=167.6] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.976 | L2-Norm(final)=6.064 | 2580.9 samples/s | 40.3 steps/s
[Step=43600 Epoch=167.8] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.966 | L2-Norm(final)=6.065 | 4080.9 samples/s | 63.8 steps/s
[Step=43650 Epoch=168.0] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.957 | L2-Norm(final)=6.066 | 4161.5 samples/s | 65.0 steps/s
[Step=43700 Epoch=168.2] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.947 | L2-Norm(final)=6.067 | 4126.0 samples/s | 64.5 steps/s
[Step=43750 Epoch=168.4] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.937 | L2-Norm(final)=6.068 | 4136.7 samples/s | 64.6 steps/s
[Step=43800 Epoch=168.6] | Loss=0.00001 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.927 | L2-Norm(final)=6.069 | 6659.0 samples/s | 104.0 steps/s
[Step=43850 Epoch=168.8] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.917 | L2-Norm(final)=6.070 | 2102.7 samples/s | 32.9 steps/s
[Step=43900 Epoch=169.0] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.907 | L2-Norm(final)=6.071 | 4018.4 samples/s | 62.8 steps/s
[Step=43950 Epoch=169.2] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.897 | L2-Norm(final)=6.072 | 4161.0 samples/s | 65.0 steps/s
[Step=44000 Epoch=169.4] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.886 | L2-Norm(final)=6.073 | 4049.2 samples/s | 63.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08114 | acc=0.9693 | tpr=0.9803 | fpr=0.0545 | 4705.1 samples/s | 18.4 steps/s
Avg test loss: 0.07911, Avg test acc: 0.96919, Avg tpr: 0.97978, Avg fpr: 0.05410, total FA: 422

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08268 | acc=0.9673 | tpr=0.9807 | fpr=0.0617 | 4796.6 samples/s | 18.7 steps/s
Avg test loss: 0.08329, Avg test acc: 0.96771, Avg tpr: 0.98129, Avg fpr: 0.06217, total FA: 485

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.43521 | acc=0.2978 | tpr=0.0144 | fpr=0.0867 | 4822.4 samples/s | 18.8 steps/s
Avg test loss: 5.43219, Avg test acc: 0.29630, Avg tpr: 0.01615, Avg fpr: 0.08755, total FA: 683

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.73200 | acc=0.3090 | tpr=0.0300 | fpr=0.0852 | 4734.1 samples/s | 18.5 steps/s
Avg test loss: 5.71512, Avg test acc: 0.30776, Avg tpr: 0.03229, Avg fpr: 0.08640, total FA: 674

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.81301 | acc=0.1173 | tpr=0.5929 | fpr=0.8912 | 5054.8 samples/s | 19.7 steps/s
[Step= 100] | Loss=7.76327 | acc=0.1168 | tpr=0.5928 | fpr=0.8921 | 6736.0 samples/s | 26.3 steps/s
[Step= 150] | Loss=7.77075 | acc=0.1173 | tpr=0.5749 | fpr=0.8912 | 7891.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=7.75831 | acc=0.1171 | tpr=0.5770 | fpr=0.8913 | 7761.6 samples/s | 30.3 steps/s
[Step= 250] | Loss=7.74850 | acc=0.1168 | tpr=0.5755 | fpr=0.8916 | 7670.6 samples/s | 30.0 steps/s
[Step= 300] | Loss=7.73819 | acc=0.1170 | tpr=0.5731 | fpr=0.8913 | 7917.5 samples/s | 30.9 steps/s
[Step= 350] | Loss=7.74334 | acc=0.1167 | tpr=0.5629 | fpr=0.8914 | 7620.2 samples/s | 29.8 steps/s
[Step= 400] | Loss=7.74753 | acc=0.1166 | tpr=0.5553 | fpr=0.8913 | 7762.0 samples/s | 30.3 steps/s
[Step= 450] | Loss=7.75150 | acc=0.1162 | tpr=0.5545 | fpr=0.8917 | 8068.1 samples/s | 31.5 steps/s
[Step= 500] | Loss=7.75406 | acc=0.1164 | tpr=0.5524 | fpr=0.8915 | 7705.6 samples/s | 30.1 steps/s
[Step= 550] | Loss=7.75914 | acc=0.1165 | tpr=0.5511 | fpr=0.8914 | 14003.5 samples/s | 54.7 steps/s
Avg test loss: 7.76115, Avg test acc: 0.11640, Avg tpr: 0.55230, Avg fpr: 0.89152, total FA: 123786

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.87512 | acc=0.1102 | tpr=0.7212 | fpr=0.9008 | 5083.9 samples/s | 19.9 steps/s
[Step= 100] | Loss=8.84931 | acc=0.1101 | tpr=0.6972 | fpr=0.9009 | 6822.6 samples/s | 26.7 steps/s
[Step= 150] | Loss=8.84770 | acc=0.1105 | tpr=0.6873 | fpr=0.9001 | 7560.8 samples/s | 29.5 steps/s
[Step= 200] | Loss=8.84204 | acc=0.1109 | tpr=0.6885 | fpr=0.8996 | 7914.0 samples/s | 30.9 steps/s
[Step= 250] | Loss=8.83478 | acc=0.1109 | tpr=0.6873 | fpr=0.8996 | 7799.5 samples/s | 30.5 steps/s
[Step= 300] | Loss=8.82814 | acc=0.1106 | tpr=0.6807 | fpr=0.8998 | 7602.8 samples/s | 29.7 steps/s
[Step= 350] | Loss=8.83735 | acc=0.1104 | tpr=0.6738 | fpr=0.8998 | 8278.8 samples/s | 32.3 steps/s
[Step= 400] | Loss=8.83848 | acc=0.1102 | tpr=0.6685 | fpr=0.8999 | 7528.4 samples/s | 29.4 steps/s
[Step= 450] | Loss=8.84663 | acc=0.1097 | tpr=0.6650 | fpr=0.9003 | 7668.7 samples/s | 30.0 steps/s
[Step= 500] | Loss=8.85005 | acc=0.1102 | tpr=0.6643 | fpr=0.8998 | 7766.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=8.85611 | acc=0.1101 | tpr=0.6626 | fpr=0.9000 | 14251.4 samples/s | 55.7 steps/s
Avg test loss: 8.85830, Avg test acc: 0.11004, Avg tpr: 0.66284, Avg fpr: 0.90001, total FA: 124965

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14137 | acc=0.9777 | tpr=0.9381 | fpr=0.0216 | 4868.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.14314 | acc=0.9786 | tpr=0.9424 | fpr=0.0207 | 6986.2 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.14926 | acc=0.9779 | tpr=0.9452 | fpr=0.0215 | 8005.0 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.15293 | acc=0.9779 | tpr=0.9454 | fpr=0.0215 | 7809.8 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.15007 | acc=0.9782 | tpr=0.9441 | fpr=0.0212 | 8077.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.15218 | acc=0.9779 | tpr=0.9425 | fpr=0.0214 | 8040.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.15250 | acc=0.9778 | tpr=0.9449 | fpr=0.0216 | 7404.5 samples/s | 28.9 steps/s
[Step= 400] | Loss=0.15423 | acc=0.9778 | tpr=0.9442 | fpr=0.0216 | 7715.5 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.15718 | acc=0.9774 | tpr=0.9435 | fpr=0.0220 | 7945.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15609 | acc=0.9774 | tpr=0.9441 | fpr=0.0220 | 7952.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.15480 | acc=0.9776 | tpr=0.9443 | fpr=0.0217 | 13239.3 samples/s | 51.7 steps/s
Avg test loss: 0.15454, Avg test acc: 0.97765, Avg tpr: 0.94414, Avg fpr: 0.02174, total FA: 3018

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14646 | acc=0.9767 | tpr=0.9558 | fpr=0.0229 | 5078.8 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.14791 | acc=0.9767 | tpr=0.9659 | fpr=0.0231 | 6676.5 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.15584 | acc=0.9757 | tpr=0.9669 | fpr=0.0241 | 7864.4 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.15903 | acc=0.9755 | tpr=0.9639 | fpr=0.0242 | 7631.0 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.15639 | acc=0.9758 | tpr=0.9581 | fpr=0.0238 | 7971.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.15927 | acc=0.9754 | tpr=0.9564 | fpr=0.0242 | 7947.8 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.15910 | acc=0.9755 | tpr=0.9574 | fpr=0.0242 | 7552.9 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.16037 | acc=0.9755 | tpr=0.9573 | fpr=0.0242 | 7568.3 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.16324 | acc=0.9751 | tpr=0.9557 | fpr=0.0245 | 8117.9 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.16216 | acc=0.9752 | tpr=0.9551 | fpr=0.0245 | 7990.5 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.16079 | acc=0.9755 | tpr=0.9554 | fpr=0.0242 | 13424.3 samples/s | 52.4 steps/s
Avg test loss: 0.16060, Avg test acc: 0.97548, Avg tpr: 0.95523, Avg fpr: 0.02415, total FA: 3353

server round 22/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=85.8] | Loss=0.00766 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.851 | L2-Norm(final)=8.906 | 6382.1 samples/s | 99.7 steps/s
[Step=44050 Epoch=85.9] | Loss=0.00651 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.848 | L2-Norm(final)=8.908 | 4402.7 samples/s | 68.8 steps/s
[Step=44100 Epoch=86.0] | Loss=0.00578 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.844 | L2-Norm(final)=8.912 | 5007.0 samples/s | 78.2 steps/s
[Step=44150 Epoch=86.1] | Loss=0.00575 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.841 | L2-Norm(final)=8.917 | 5131.7 samples/s | 80.2 steps/s
[Step=44200 Epoch=86.2] | Loss=0.00557 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.837 | L2-Norm(final)=8.922 | 4821.8 samples/s | 75.3 steps/s
[Step=44250 Epoch=86.3] | Loss=0.00581 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.833 | L2-Norm(final)=8.926 | 4958.1 samples/s | 77.5 steps/s
[Step=44300 Epoch=86.4] | Loss=0.00565 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.830 | L2-Norm(final)=8.931 | 5017.4 samples/s | 78.4 steps/s
[Step=44350 Epoch=86.5] | Loss=0.00571 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.827 | L2-Norm(final)=8.936 | 4989.6 samples/s | 78.0 steps/s
[Step=44400 Epoch=86.6] | Loss=0.00565 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.824 | L2-Norm(final)=8.941 | 5019.7 samples/s | 78.4 steps/s
[Step=44450 Epoch=86.7] | Loss=0.00560 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.820 | L2-Norm(final)=8.946 | 4930.3 samples/s | 77.0 steps/s
[Step=44500 Epoch=86.8] | Loss=0.00580 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.817 | L2-Norm(final)=8.951 | 6559.0 samples/s | 102.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=86.8] | Loss=0.00219 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.785 | L2-Norm(final)=9.000 | 6752.6 samples/s | 105.5 steps/s
[Step=44550 Epoch=86.9] | Loss=0.00540 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.784 | L2-Norm(final)=9.005 | 3893.4 samples/s | 60.8 steps/s
[Step=44600 Epoch=87.0] | Loss=0.00572 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.782 | L2-Norm(final)=9.008 | 4362.2 samples/s | 68.2 steps/s
[Step=44650 Epoch=87.1] | Loss=0.00685 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.780 | L2-Norm(final)=9.010 | 4494.9 samples/s | 70.2 steps/s
[Step=44700 Epoch=87.2] | Loss=0.00679 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.780 | L2-Norm(final)=9.012 | 4370.8 samples/s | 68.3 steps/s
[Step=44750 Epoch=87.3] | Loss=0.00725 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.779 | L2-Norm(final)=9.015 | 4532.0 samples/s | 70.8 steps/s
[Step=44800 Epoch=87.4] | Loss=0.00739 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.780 | L2-Norm(final)=9.018 | 4403.1 samples/s | 68.8 steps/s
[Step=44850 Epoch=87.5] | Loss=0.00742 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.781 | L2-Norm(final)=9.021 | 4314.2 samples/s | 67.4 steps/s
[Step=44900 Epoch=87.6] | Loss=0.00761 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.781 | L2-Norm(final)=9.024 | 4468.7 samples/s | 69.8 steps/s
[Step=44950 Epoch=87.7] | Loss=0.00775 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.782 | L2-Norm(final)=9.027 | 4393.6 samples/s | 68.7 steps/s
[Step=45000 Epoch=87.8] | Loss=0.00802 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.783 | L2-Norm(final)=9.030 | 5788.6 samples/s | 90.4 steps/s
[Step=45050 Epoch=87.9] | Loss=0.00797 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.783 | L2-Norm(final)=9.033 | 2376.6 samples/s | 37.1 steps/s
[Step=45100 Epoch=88.0] | Loss=0.00804 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.783 | L2-Norm(final)=9.036 | 4438.8 samples/s | 69.4 steps/s
[Step=45150 Epoch=88.1] | Loss=0.00801 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.782 | L2-Norm(final)=9.038 | 4460.3 samples/s | 69.7 steps/s
[Step=45200 Epoch=88.2] | Loss=0.00787 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.782 | L2-Norm(final)=9.041 | 4360.4 samples/s | 68.1 steps/s
[Step=45250 Epoch=88.3] | Loss=0.00780 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.781 | L2-Norm(final)=9.044 | 4359.4 samples/s | 68.1 steps/s
[Step=45300 Epoch=88.4] | Loss=0.00765 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.780 | L2-Norm(final)=9.047 | 4441.9 samples/s | 69.4 steps/s
[Step=45350 Epoch=88.5] | Loss=0.00754 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.779 | L2-Norm(final)=9.050 | 4363.1 samples/s | 68.2 steps/s
[Step=45400 Epoch=88.5] | Loss=0.00752 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.777 | L2-Norm(final)=9.053 | 4476.0 samples/s | 69.9 steps/s
[Step=45450 Epoch=88.6] | Loss=0.00752 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.776 | L2-Norm(final)=9.056 | 4452.2 samples/s | 69.6 steps/s
[Step=45500 Epoch=88.7] | Loss=0.00755 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.775 | L2-Norm(final)=9.058 | 4716.1 samples/s | 73.7 steps/s
[Step=45550 Epoch=88.8] | Loss=0.00752 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.773 | L2-Norm(final)=9.061 | 2587.2 samples/s | 40.4 steps/s
[Step=45600 Epoch=88.9] | Loss=0.00751 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.772 | L2-Norm(final)=9.064 | 4421.6 samples/s | 69.1 steps/s
[Step=45650 Epoch=89.0] | Loss=0.00739 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.770 | L2-Norm(final)=9.067 | 4324.6 samples/s | 67.6 steps/s
[Step=45700 Epoch=89.1] | Loss=0.00732 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.768 | L2-Norm(final)=9.069 | 4477.2 samples/s | 70.0 steps/s
[Step=45750 Epoch=89.2] | Loss=0.00727 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.766 | L2-Norm(final)=9.072 | 4409.2 samples/s | 68.9 steps/s
[Step=45800 Epoch=89.3] | Loss=0.00721 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.764 | L2-Norm(final)=9.075 | 4405.6 samples/s | 68.8 steps/s
[Step=45850 Epoch=89.4] | Loss=0.00719 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.762 | L2-Norm(final)=9.077 | 4447.8 samples/s | 69.5 steps/s
[Step=45900 Epoch=89.5] | Loss=0.00715 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.760 | L2-Norm(final)=9.080 | 4492.8 samples/s | 70.2 steps/s
[Step=45950 Epoch=89.6] | Loss=0.00710 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.758 | L2-Norm(final)=9.082 | 4404.0 samples/s | 68.8 steps/s
[Step=46000 Epoch=89.7] | Loss=0.00714 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.755 | L2-Norm(final)=9.085 | 4424.3 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step46000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=86.0] | Loss=0.00629 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.867 | L2-Norm(final)=9.081 | 6006.0 samples/s | 93.8 steps/s
[Step=44050 Epoch=86.1] | Loss=0.00620 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.865 | L2-Norm(final)=9.084 | 4631.7 samples/s | 72.4 steps/s
[Step=44100 Epoch=86.2] | Loss=0.00551 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.862 | L2-Norm(final)=9.088 | 4897.8 samples/s | 76.5 steps/s
[Step=44150 Epoch=86.3] | Loss=0.00519 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.859 | L2-Norm(final)=9.093 | 5056.4 samples/s | 79.0 steps/s
[Step=44200 Epoch=86.4] | Loss=0.00529 | Reg=0.00356 | acc=0.9844 | L2-Norm=18.856 | L2-Norm(final)=9.098 | 5089.7 samples/s | 79.5 steps/s
[Step=44250 Epoch=86.5] | Loss=0.00538 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.853 | L2-Norm(final)=9.103 | 4895.7 samples/s | 76.5 steps/s
[Step=44300 Epoch=86.6] | Loss=0.00531 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.850 | L2-Norm(final)=9.109 | 4967.7 samples/s | 77.6 steps/s
[Step=44350 Epoch=86.7] | Loss=0.00529 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.847 | L2-Norm(final)=9.114 | 5056.3 samples/s | 79.0 steps/s
[Step=44400 Epoch=86.8] | Loss=0.00513 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.844 | L2-Norm(final)=9.118 | 5066.3 samples/s | 79.2 steps/s
[Step=44450 Epoch=86.9] | Loss=0.00515 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.841 | L2-Norm(final)=9.123 | 4897.7 samples/s | 76.5 steps/s
[Step=44500 Epoch=87.0] | Loss=0.00514 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.837 | L2-Norm(final)=9.128 | 6809.8 samples/s | 106.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=87.0] | Loss=0.00668 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.803 | L2-Norm(final)=9.175 | 6152.2 samples/s | 96.1 steps/s
[Step=44550 Epoch=87.1] | Loss=0.00596 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.802 | L2-Norm(final)=9.180 | 4210.1 samples/s | 65.8 steps/s
[Step=44600 Epoch=87.2] | Loss=0.00650 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.800 | L2-Norm(final)=9.182 | 4378.5 samples/s | 68.4 steps/s
[Step=44650 Epoch=87.3] | Loss=0.00705 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.800 | L2-Norm(final)=9.185 | 4447.3 samples/s | 69.5 steps/s
[Step=44700 Epoch=87.4] | Loss=0.00706 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.800 | L2-Norm(final)=9.188 | 4473.2 samples/s | 69.9 steps/s
[Step=44750 Epoch=87.5] | Loss=0.00736 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.799 | L2-Norm(final)=9.191 | 4417.8 samples/s | 69.0 steps/s
[Step=44800 Epoch=87.6] | Loss=0.00755 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.798 | L2-Norm(final)=9.194 | 4417.6 samples/s | 69.0 steps/s
[Step=44850 Epoch=87.7] | Loss=0.00752 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.798 | L2-Norm(final)=9.196 | 4430.5 samples/s | 69.2 steps/s
[Step=44900 Epoch=87.8] | Loss=0.00751 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.797 | L2-Norm(final)=9.198 | 4403.1 samples/s | 68.8 steps/s
[Step=44950 Epoch=87.9] | Loss=0.00748 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.797 | L2-Norm(final)=9.200 | 4457.0 samples/s | 69.6 steps/s
[Step=45000 Epoch=88.0] | Loss=0.00754 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.796 | L2-Norm(final)=9.203 | 5864.9 samples/s | 91.6 steps/s
[Step=45050 Epoch=88.1] | Loss=0.00751 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.796 | L2-Norm(final)=9.206 | 2369.7 samples/s | 37.0 steps/s
[Step=45100 Epoch=88.2] | Loss=0.00744 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.795 | L2-Norm(final)=9.209 | 4497.2 samples/s | 70.3 steps/s
[Step=45150 Epoch=88.3] | Loss=0.00778 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.794 | L2-Norm(final)=9.211 | 4393.8 samples/s | 68.7 steps/s
[Step=45200 Epoch=88.4] | Loss=0.00761 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.793 | L2-Norm(final)=9.214 | 4395.3 samples/s | 68.7 steps/s
[Step=45250 Epoch=88.5] | Loss=0.00753 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.792 | L2-Norm(final)=9.216 | 4393.4 samples/s | 68.6 steps/s
[Step=45300 Epoch=88.6] | Loss=0.00759 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.791 | L2-Norm(final)=9.219 | 4492.9 samples/s | 70.2 steps/s
[Step=45350 Epoch=88.7] | Loss=0.00754 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.789 | L2-Norm(final)=9.221 | 4331.8 samples/s | 67.7 steps/s
[Step=45400 Epoch=88.8] | Loss=0.00752 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.788 | L2-Norm(final)=9.224 | 4429.7 samples/s | 69.2 steps/s
[Step=45450 Epoch=88.9] | Loss=0.00753 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.787 | L2-Norm(final)=9.226 | 4498.8 samples/s | 70.3 steps/s
[Step=45500 Epoch=89.0] | Loss=0.00751 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.785 | L2-Norm(final)=9.228 | 4909.8 samples/s | 76.7 steps/s
[Step=45550 Epoch=89.0] | Loss=0.00747 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.784 | L2-Norm(final)=9.231 | 2544.6 samples/s | 39.8 steps/s
[Step=45600 Epoch=89.1] | Loss=0.00739 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.783 | L2-Norm(final)=9.233 | 4443.1 samples/s | 69.4 steps/s
[Step=45650 Epoch=89.2] | Loss=0.00740 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.781 | L2-Norm(final)=9.236 | 4342.8 samples/s | 67.9 steps/s
[Step=45700 Epoch=89.3] | Loss=0.00727 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.780 | L2-Norm(final)=9.238 | 4482.2 samples/s | 70.0 steps/s
[Step=45750 Epoch=89.4] | Loss=0.00723 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.778 | L2-Norm(final)=9.240 | 4452.9 samples/s | 69.6 steps/s
[Step=45800 Epoch=89.5] | Loss=0.00717 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.776 | L2-Norm(final)=9.243 | 4371.0 samples/s | 68.3 steps/s
[Step=45850 Epoch=89.6] | Loss=0.00716 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.775 | L2-Norm(final)=9.245 | 4447.4 samples/s | 69.5 steps/s
[Step=45900 Epoch=89.7] | Loss=0.00708 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.773 | L2-Norm(final)=9.248 | 4438.8 samples/s | 69.4 steps/s
[Step=45950 Epoch=89.8] | Loss=0.00712 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.771 | L2-Norm(final)=9.250 | 4516.9 samples/s | 70.6 steps/s
[Step=46000 Epoch=89.9] | Loss=0.00710 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.769 | L2-Norm(final)=9.252 | 4362.5 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step46000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=168.6] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.920 | L2-Norm(final)=5.773 | 5861.0 samples/s | 91.6 steps/s
[Step=44050 Epoch=168.8] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.917 | L2-Norm(final)=5.776 | 4216.5 samples/s | 65.9 steps/s
[Step=44100 Epoch=169.0] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.916 | L2-Norm(final)=5.780 | 4727.5 samples/s | 73.9 steps/s
[Step=44150 Epoch=169.2] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.916 | L2-Norm(final)=5.785 | 4750.1 samples/s | 74.2 steps/s
[Step=44200 Epoch=169.4] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.915 | L2-Norm(final)=5.789 | 4728.2 samples/s | 73.9 steps/s
[Step=44250 Epoch=169.6] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.915 | L2-Norm(final)=5.793 | 6479.0 samples/s | 101.2 steps/s
[Step=44300 Epoch=169.7] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.914 | L2-Norm(final)=5.796 | 2398.4 samples/s | 37.5 steps/s
[Step=44350 Epoch=169.9] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.913 | L2-Norm(final)=5.800 | 4723.8 samples/s | 73.8 steps/s
[Step=44400 Epoch=170.1] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.912 | L2-Norm(final)=5.804 | 4628.5 samples/s | 72.3 steps/s
[Step=44450 Epoch=170.3] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.911 | L2-Norm(final)=5.807 | 4804.2 samples/s | 75.1 steps/s
[Step=44500 Epoch=170.5] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.910 | L2-Norm(final)=5.811 | 5343.2 samples/s | 83.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=170.5] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.899 | L2-Norm(final)=5.847 | 6142.9 samples/s | 96.0 steps/s
[Step=44550 Epoch=170.7] | Loss=0.00002 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.889 | L2-Norm(final)=5.851 | 3776.7 samples/s | 59.0 steps/s
[Step=44600 Epoch=170.9] | Loss=0.00001 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.874 | L2-Norm(final)=5.855 | 4174.5 samples/s | 65.2 steps/s
[Step=44650 Epoch=171.1] | Loss=0.00001 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.859 | L2-Norm(final)=5.858 | 4231.0 samples/s | 66.1 steps/s
[Step=44700 Epoch=171.3] | Loss=0.00001 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.843 | L2-Norm(final)=5.860 | 4173.8 samples/s | 65.2 steps/s
[Step=44750 Epoch=171.5] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.827 | L2-Norm(final)=5.862 | 5606.8 samples/s | 87.6 steps/s
[Step=44800 Epoch=171.7] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.810 | L2-Norm(final)=5.864 | 2218.8 samples/s | 34.7 steps/s
[Step=44850 Epoch=171.8] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.793 | L2-Norm(final)=5.866 | 4159.2 samples/s | 65.0 steps/s
[Step=44900 Epoch=172.0] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.776 | L2-Norm(final)=5.868 | 4253.7 samples/s | 66.5 steps/s
[Step=44950 Epoch=172.2] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.758 | L2-Norm(final)=5.869 | 4139.0 samples/s | 64.7 steps/s
[Step=45000 Epoch=172.4] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.740 | L2-Norm(final)=5.870 | 4750.0 samples/s | 74.2 steps/s
[Step=45050 Epoch=172.6] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.723 | L2-Norm(final)=5.872 | 2440.2 samples/s | 38.1 steps/s
[Step=45100 Epoch=172.8] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.705 | L2-Norm(final)=5.873 | 4158.3 samples/s | 65.0 steps/s
[Step=45150 Epoch=173.0] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.687 | L2-Norm(final)=5.874 | 4220.8 samples/s | 66.0 steps/s
[Step=45200 Epoch=173.2] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.668 | L2-Norm(final)=5.876 | 4158.3 samples/s | 65.0 steps/s
[Step=45250 Epoch=173.4] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.650 | L2-Norm(final)=5.877 | 4161.6 samples/s | 65.0 steps/s
[Step=45300 Epoch=173.6] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.631 | L2-Norm(final)=5.878 | 2618.9 samples/s | 40.9 steps/s
[Step=45350 Epoch=173.8] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.613 | L2-Norm(final)=5.880 | 4147.5 samples/s | 64.8 steps/s
[Step=45400 Epoch=174.0] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.594 | L2-Norm(final)=5.881 | 4184.6 samples/s | 65.4 steps/s
[Step=45450 Epoch=174.1] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.575 | L2-Norm(final)=5.882 | 4231.1 samples/s | 66.1 steps/s
[Step=45500 Epoch=174.3] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.556 | L2-Norm(final)=5.884 | 4143.0 samples/s | 64.7 steps/s
[Step=45550 Epoch=174.5] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=5.885 | 2609.2 samples/s | 40.8 steps/s
[Step=45600 Epoch=174.7] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.517 | L2-Norm(final)=5.886 | 4216.6 samples/s | 65.9 steps/s
[Step=45650 Epoch=174.9] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.497 | L2-Norm(final)=5.888 | 4256.5 samples/s | 66.5 steps/s
[Step=45700 Epoch=175.1] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.477 | L2-Norm(final)=5.889 | 4164.1 samples/s | 65.1 steps/s
[Step=45750 Epoch=175.3] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.457 | L2-Norm(final)=5.891 | 4231.6 samples/s | 66.1 steps/s
[Step=45800 Epoch=175.5] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.437 | L2-Norm(final)=5.892 | 6218.0 samples/s | 97.2 steps/s
[Step=45850 Epoch=175.7] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=5.894 | 2159.5 samples/s | 33.7 steps/s
[Step=45900 Epoch=175.9] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.397 | L2-Norm(final)=5.895 | 4173.2 samples/s | 65.2 steps/s
[Step=45950 Epoch=176.1] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=5.897 | 4170.9 samples/s | 65.2 steps/s
[Step=46000 Epoch=176.3] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.356 | L2-Norm(final)=5.898 | 4276.2 samples/s | 66.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step46000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=169.4] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.859 | L2-Norm(final)=6.105 | 6126.6 samples/s | 95.7 steps/s
[Step=44050 Epoch=169.6] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.856 | L2-Norm(final)=6.108 | 4205.5 samples/s | 65.7 steps/s
[Step=44100 Epoch=169.8] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.855 | L2-Norm(final)=6.112 | 4713.9 samples/s | 73.7 steps/s
[Step=44150 Epoch=170.0] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.855 | L2-Norm(final)=6.117 | 4801.9 samples/s | 75.0 steps/s
[Step=44200 Epoch=170.1] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.854 | L2-Norm(final)=6.121 | 4509.5 samples/s | 70.5 steps/s
[Step=44250 Epoch=170.3] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.853 | L2-Norm(final)=6.126 | 6794.2 samples/s | 106.2 steps/s
[Step=44300 Epoch=170.5] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.852 | L2-Norm(final)=6.131 | 2424.3 samples/s | 37.9 steps/s
[Step=44350 Epoch=170.7] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.851 | L2-Norm(final)=6.135 | 4624.2 samples/s | 72.3 steps/s
[Step=44400 Epoch=170.9] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.850 | L2-Norm(final)=6.140 | 4788.1 samples/s | 74.8 steps/s
[Step=44450 Epoch=171.1] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.849 | L2-Norm(final)=6.145 | 4612.3 samples/s | 72.1 steps/s
[Step=44500 Epoch=171.3] | Loss=0.00002 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.848 | L2-Norm(final)=6.149 | 5653.3 samples/s | 88.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=171.3] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.837 | L2-Norm(final)=6.195 | 6300.9 samples/s | 98.5 steps/s
[Step=44550 Epoch=171.5] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.824 | L2-Norm(final)=6.200 | 3744.4 samples/s | 58.5 steps/s
[Step=44600 Epoch=171.7] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.808 | L2-Norm(final)=6.204 | 4205.9 samples/s | 65.7 steps/s
[Step=44650 Epoch=171.9] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.791 | L2-Norm(final)=6.207 | 4151.2 samples/s | 64.9 steps/s
[Step=44700 Epoch=172.1] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.774 | L2-Norm(final)=6.211 | 4184.7 samples/s | 65.4 steps/s
[Step=44750 Epoch=172.3] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.757 | L2-Norm(final)=6.214 | 5760.6 samples/s | 90.0 steps/s
[Step=44800 Epoch=172.5] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.739 | L2-Norm(final)=6.217 | 2273.4 samples/s | 35.5 steps/s
[Step=44850 Epoch=172.6] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.721 | L2-Norm(final)=6.219 | 4131.9 samples/s | 64.6 steps/s
[Step=44900 Epoch=172.8] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.703 | L2-Norm(final)=6.221 | 4146.6 samples/s | 64.8 steps/s
[Step=44950 Epoch=173.0] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.685 | L2-Norm(final)=6.224 | 4188.2 samples/s | 65.4 steps/s
[Step=45000 Epoch=173.2] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.666 | L2-Norm(final)=6.226 | 4890.9 samples/s | 76.4 steps/s
[Step=45050 Epoch=173.4] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.648 | L2-Norm(final)=6.228 | 2383.8 samples/s | 37.2 steps/s
[Step=45100 Epoch=173.6] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.629 | L2-Norm(final)=6.230 | 4213.4 samples/s | 65.8 steps/s
[Step=45150 Epoch=173.8] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.610 | L2-Norm(final)=6.232 | 4255.5 samples/s | 66.5 steps/s
[Step=45200 Epoch=174.0] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.591 | L2-Norm(final)=6.234 | 4125.6 samples/s | 64.5 steps/s
[Step=45250 Epoch=174.2] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.572 | L2-Norm(final)=6.236 | 4268.9 samples/s | 66.7 steps/s
[Step=45300 Epoch=174.4] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.553 | L2-Norm(final)=6.238 | 2571.0 samples/s | 40.2 steps/s
[Step=45350 Epoch=174.6] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.533 | L2-Norm(final)=6.240 | 4149.0 samples/s | 64.8 steps/s
[Step=45400 Epoch=174.8] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.513 | L2-Norm(final)=6.242 | 4238.1 samples/s | 66.2 steps/s
[Step=45450 Epoch=175.0] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.494 | L2-Norm(final)=6.244 | 4202.2 samples/s | 65.7 steps/s
[Step=45500 Epoch=175.1] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.474 | L2-Norm(final)=6.246 | 4277.4 samples/s | 66.8 steps/s
[Step=45550 Epoch=175.3] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.454 | L2-Norm(final)=6.248 | 2585.8 samples/s | 40.4 steps/s
[Step=45600 Epoch=175.5] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.434 | L2-Norm(final)=6.250 | 4198.3 samples/s | 65.6 steps/s
[Step=45650 Epoch=175.7] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.413 | L2-Norm(final)=6.253 | 4190.3 samples/s | 65.5 steps/s
[Step=45700 Epoch=175.9] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.393 | L2-Norm(final)=6.255 | 4127.8 samples/s | 64.5 steps/s
[Step=45750 Epoch=176.1] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.372 | L2-Norm(final)=6.257 | 4149.9 samples/s | 64.8 steps/s
[Step=45800 Epoch=176.3] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.352 | L2-Norm(final)=6.259 | 6833.9 samples/s | 106.8 steps/s
[Step=45850 Epoch=176.5] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=6.262 | 2111.5 samples/s | 33.0 steps/s
[Step=45900 Epoch=176.7] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.310 | L2-Norm(final)=6.264 | 4137.6 samples/s | 64.7 steps/s
[Step=45950 Epoch=176.9] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.289 | L2-Norm(final)=6.266 | 4182.8 samples/s | 65.4 steps/s
[Step=46000 Epoch=177.1] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.267 | L2-Norm(final)=6.269 | 4161.7 samples/s | 65.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07937 | acc=0.9667 | tpr=0.9765 | fpr=0.0545 | 4825.5 samples/s | 18.8 steps/s
Avg test loss: 0.07745, Avg test acc: 0.96606, Avg tpr: 0.97470, Avg fpr: 0.05294, total FA: 413

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08394 | acc=0.9686 | tpr=0.9805 | fpr=0.0572 | 4922.0 samples/s | 19.2 steps/s
Avg test loss: 0.08458, Avg test acc: 0.96739, Avg tpr: 0.98024, Avg fpr: 0.06089, total FA: 475

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.40981 | acc=0.2994 | tpr=0.0107 | fpr=0.0738 | 4831.5 samples/s | 18.9 steps/s
Avg test loss: 5.40549, Avg test acc: 0.29646, Avg tpr: 0.01131, Avg fpr: 0.07640, total FA: 596

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.66363 | acc=0.3124 | tpr=0.0245 | fpr=0.0624 | 4997.2 samples/s | 19.5 steps/s
Avg test loss: 5.64919, Avg test acc: 0.31072, Avg tpr: 0.02640, Avg fpr: 0.06397, total FA: 499

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.10574 | acc=0.1339 | tpr=0.5885 | fpr=0.8743 | 4919.7 samples/s | 19.2 steps/s
[Step= 100] | Loss=7.05446 | acc=0.1359 | tpr=0.5842 | fpr=0.8724 | 7300.4 samples/s | 28.5 steps/s
[Step= 150] | Loss=7.06353 | acc=0.1365 | tpr=0.5749 | fpr=0.8716 | 7655.8 samples/s | 29.9 steps/s
[Step= 200] | Loss=7.05416 | acc=0.1371 | tpr=0.5738 | fpr=0.8709 | 7758.4 samples/s | 30.3 steps/s
[Step= 250] | Loss=7.04668 | acc=0.1378 | tpr=0.5817 | fpr=0.8703 | 7659.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=7.03587 | acc=0.1381 | tpr=0.5775 | fpr=0.8699 | 7811.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=7.04104 | acc=0.1376 | tpr=0.5698 | fpr=0.8702 | 8077.4 samples/s | 31.6 steps/s
[Step= 400] | Loss=7.04362 | acc=0.1377 | tpr=0.5629 | fpr=0.8701 | 7579.2 samples/s | 29.6 steps/s
[Step= 450] | Loss=7.04785 | acc=0.1371 | tpr=0.5618 | fpr=0.8706 | 7534.5 samples/s | 29.4 steps/s
[Step= 500] | Loss=7.05059 | acc=0.1374 | tpr=0.5612 | fpr=0.8703 | 8101.3 samples/s | 31.6 steps/s
[Step= 550] | Loss=7.05561 | acc=0.1374 | tpr=0.5631 | fpr=0.8704 | 13834.8 samples/s | 54.0 steps/s
Avg test loss: 7.05739, Avg test acc: 0.13730, Avg tpr: 0.56379, Avg fpr: 0.87046, total FA: 120861

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.01094 | acc=0.1185 | tpr=0.6947 | fpr=0.8918 | 4726.0 samples/s | 18.5 steps/s
[Step= 100] | Loss=7.98621 | acc=0.1181 | tpr=0.6695 | fpr=0.8922 | 7357.4 samples/s | 28.7 steps/s
[Step= 150] | Loss=7.99575 | acc=0.1179 | tpr=0.6744 | fpr=0.8924 | 7926.0 samples/s | 31.0 steps/s
[Step= 200] | Loss=7.98895 | acc=0.1180 | tpr=0.6721 | fpr=0.8921 | 7480.9 samples/s | 29.2 steps/s
[Step= 250] | Loss=7.98115 | acc=0.1180 | tpr=0.6725 | fpr=0.8921 | 8254.4 samples/s | 32.2 steps/s
[Step= 300] | Loss=7.97375 | acc=0.1175 | tpr=0.6647 | fpr=0.8925 | 7865.3 samples/s | 30.7 steps/s
[Step= 350] | Loss=7.98042 | acc=0.1174 | tpr=0.6581 | fpr=0.8924 | 7626.7 samples/s | 29.8 steps/s
[Step= 400] | Loss=7.98248 | acc=0.1173 | tpr=0.6472 | fpr=0.8924 | 7771.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=7.98708 | acc=0.1169 | tpr=0.6446 | fpr=0.8927 | 8107.6 samples/s | 31.7 steps/s
[Step= 500] | Loss=7.99047 | acc=0.1171 | tpr=0.6458 | fpr=0.8924 | 7751.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=7.99780 | acc=0.1169 | tpr=0.6431 | fpr=0.8926 | 13957.5 samples/s | 54.5 steps/s
Avg test loss: 7.99969, Avg test acc: 0.11683, Avg tpr: 0.64342, Avg fpr: 0.89275, total FA: 123956

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13787 | acc=0.9777 | tpr=0.9425 | fpr=0.0216 | 4961.9 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.14004 | acc=0.9787 | tpr=0.9446 | fpr=0.0207 | 6913.8 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.14588 | acc=0.9779 | tpr=0.9467 | fpr=0.0215 | 8007.8 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.14975 | acc=0.9780 | tpr=0.9464 | fpr=0.0214 | 7570.3 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.14691 | acc=0.9782 | tpr=0.9450 | fpr=0.0211 | 7546.7 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.14902 | acc=0.9779 | tpr=0.9433 | fpr=0.0215 | 8141.1 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.14929 | acc=0.9779 | tpr=0.9443 | fpr=0.0215 | 7938.5 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.15098 | acc=0.9778 | tpr=0.9431 | fpr=0.0216 | 7565.3 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.15377 | acc=0.9774 | tpr=0.9426 | fpr=0.0220 | 7904.2 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.15273 | acc=0.9775 | tpr=0.9432 | fpr=0.0219 | 7856.6 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.15139 | acc=0.9777 | tpr=0.9435 | fpr=0.0217 | 13561.2 samples/s | 53.0 steps/s
Avg test loss: 0.15114, Avg test acc: 0.97768, Avg tpr: 0.94334, Avg fpr: 0.02169, total FA: 3012

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14293 | acc=0.9771 | tpr=0.9558 | fpr=0.0225 | 4868.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.14547 | acc=0.9770 | tpr=0.9638 | fpr=0.0228 | 7021.6 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.15301 | acc=0.9758 | tpr=0.9625 | fpr=0.0239 | 7650.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.15637 | acc=0.9756 | tpr=0.9617 | fpr=0.0242 | 8157.5 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.15379 | acc=0.9758 | tpr=0.9581 | fpr=0.0238 | 8004.6 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.15635 | acc=0.9755 | tpr=0.9564 | fpr=0.0242 | 7516.7 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.15638 | acc=0.9755 | tpr=0.9580 | fpr=0.0242 | 7921.8 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.15772 | acc=0.9755 | tpr=0.9568 | fpr=0.0242 | 7828.8 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.16058 | acc=0.9751 | tpr=0.9557 | fpr=0.0245 | 7573.4 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.15963 | acc=0.9752 | tpr=0.9559 | fpr=0.0244 | 8042.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.15816 | acc=0.9755 | tpr=0.9562 | fpr=0.0242 | 13717.8 samples/s | 53.6 steps/s
Avg test loss: 0.15800, Avg test acc: 0.97548, Avg tpr: 0.95602, Avg fpr: 0.02416, total FA: 3355

server round 23/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=89.7] | Loss=0.00436 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.322 | L2-Norm(final)=9.160 | 6011.4 samples/s | 93.9 steps/s
[Step=46050 Epoch=89.8] | Loss=0.00596 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.323 | L2-Norm(final)=9.165 | 4630.9 samples/s | 72.4 steps/s
[Step=46100 Epoch=89.9] | Loss=0.00558 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.322 | L2-Norm(final)=9.170 | 4962.6 samples/s | 77.5 steps/s
[Step=46150 Epoch=90.0] | Loss=0.00560 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.320 | L2-Norm(final)=9.176 | 4926.6 samples/s | 77.0 steps/s
[Step=46200 Epoch=90.1] | Loss=0.00561 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.318 | L2-Norm(final)=9.182 | 5015.8 samples/s | 78.4 steps/s
[Step=46250 Epoch=90.2] | Loss=0.00557 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.315 | L2-Norm(final)=9.188 | 5118.5 samples/s | 80.0 steps/s
[Step=46300 Epoch=90.3] | Loss=0.00559 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.313 | L2-Norm(final)=9.194 | 4955.7 samples/s | 77.4 steps/s
[Step=46350 Epoch=90.4] | Loss=0.00562 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.310 | L2-Norm(final)=9.199 | 4920.9 samples/s | 76.9 steps/s
[Step=46400 Epoch=90.5] | Loss=0.00568 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.308 | L2-Norm(final)=9.204 | 5062.3 samples/s | 79.1 steps/s
[Step=46450 Epoch=90.6] | Loss=0.00560 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.305 | L2-Norm(final)=9.210 | 5107.6 samples/s | 79.8 steps/s
[Step=46500 Epoch=90.7] | Loss=0.00567 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.303 | L2-Norm(final)=9.215 | 6463.4 samples/s | 101.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=90.7] | Loss=0.01252 | Reg=0.00334 | acc=0.9844 | L2-Norm=18.283 | L2-Norm(final)=9.265 | 6140.5 samples/s | 95.9 steps/s
[Step=46550 Epoch=90.8] | Loss=0.00492 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.283 | L2-Norm(final)=9.270 | 4192.8 samples/s | 65.5 steps/s
[Step=46600 Epoch=90.9] | Loss=0.00678 | Reg=0.00334 | acc=0.9844 | L2-Norm=18.283 | L2-Norm(final)=9.274 | 4378.6 samples/s | 68.4 steps/s
[Step=46650 Epoch=91.0] | Loss=0.00771 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.284 | L2-Norm(final)=9.277 | 4365.6 samples/s | 68.2 steps/s
[Step=46700 Epoch=91.1] | Loss=0.00777 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.286 | L2-Norm(final)=9.282 | 4594.0 samples/s | 71.8 steps/s
[Step=46750 Epoch=91.2] | Loss=0.00804 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.287 | L2-Norm(final)=9.286 | 4350.0 samples/s | 68.0 steps/s
[Step=46800 Epoch=91.3] | Loss=0.00793 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.288 | L2-Norm(final)=9.291 | 4348.9 samples/s | 68.0 steps/s
[Step=46850 Epoch=91.4] | Loss=0.00809 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.289 | L2-Norm(final)=9.295 | 4436.0 samples/s | 69.3 steps/s
[Step=46900 Epoch=91.5] | Loss=0.00818 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.289 | L2-Norm(final)=9.299 | 4466.0 samples/s | 69.8 steps/s
[Step=46950 Epoch=91.6] | Loss=0.00807 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.290 | L2-Norm(final)=9.303 | 4398.6 samples/s | 68.7 steps/s
[Step=47000 Epoch=91.7] | Loss=0.00797 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.291 | L2-Norm(final)=9.308 | 5717.7 samples/s | 89.3 steps/s
[Step=47050 Epoch=91.8] | Loss=0.00794 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.292 | L2-Norm(final)=9.312 | 2413.9 samples/s | 37.7 steps/s
[Step=47100 Epoch=91.9] | Loss=0.00798 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.292 | L2-Norm(final)=9.317 | 4307.7 samples/s | 67.3 steps/s
[Step=47150 Epoch=92.0] | Loss=0.00782 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.321 | 4513.3 samples/s | 70.5 steps/s
[Step=47200 Epoch=92.1] | Loss=0.00763 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.325 | 4402.2 samples/s | 68.8 steps/s
[Step=47250 Epoch=92.2] | Loss=0.00767 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.329 | 4408.7 samples/s | 68.9 steps/s
[Step=47300 Epoch=92.3] | Loss=0.00750 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.293 | L2-Norm(final)=9.334 | 4548.8 samples/s | 71.1 steps/s
[Step=47350 Epoch=92.4] | Loss=0.00756 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.338 | 4385.3 samples/s | 68.5 steps/s
[Step=47400 Epoch=92.4] | Loss=0.00749 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.341 | 4441.1 samples/s | 69.4 steps/s
[Step=47450 Epoch=92.5] | Loss=0.00774 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.345 | 4415.3 samples/s | 69.0 steps/s
[Step=47500 Epoch=92.6] | Loss=0.00767 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.348 | 4832.7 samples/s | 75.5 steps/s
[Step=47550 Epoch=92.7] | Loss=0.00774 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.293 | L2-Norm(final)=9.352 | 2601.6 samples/s | 40.6 steps/s
[Step=47600 Epoch=92.8] | Loss=0.00765 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.293 | L2-Norm(final)=9.355 | 4407.6 samples/s | 68.9 steps/s
[Step=47650 Epoch=92.9] | Loss=0.00762 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.293 | L2-Norm(final)=9.359 | 4424.8 samples/s | 69.1 steps/s
[Step=47700 Epoch=93.0] | Loss=0.00755 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.293 | L2-Norm(final)=9.362 | 4462.1 samples/s | 69.7 steps/s
[Step=47750 Epoch=93.1] | Loss=0.00750 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.292 | L2-Norm(final)=9.366 | 4360.8 samples/s | 68.1 steps/s
[Step=47800 Epoch=93.2] | Loss=0.00747 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.292 | L2-Norm(final)=9.369 | 4537.5 samples/s | 70.9 steps/s
[Step=47850 Epoch=93.3] | Loss=0.00740 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.291 | L2-Norm(final)=9.372 | 4425.8 samples/s | 69.2 steps/s
[Step=47900 Epoch=93.4] | Loss=0.00740 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.291 | L2-Norm(final)=9.376 | 4378.0 samples/s | 68.4 steps/s
[Step=47950 Epoch=93.5] | Loss=0.00741 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.290 | L2-Norm(final)=9.379 | 4463.1 samples/s | 69.7 steps/s
[Step=48000 Epoch=93.6] | Loss=0.00735 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.289 | L2-Norm(final)=9.383 | 4442.7 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step48000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=89.9] | Loss=0.00928 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.350 | L2-Norm(final)=9.322 | 6457.7 samples/s | 100.9 steps/s
[Step=46050 Epoch=90.0] | Loss=0.00685 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.349 | L2-Norm(final)=9.326 | 4396.7 samples/s | 68.7 steps/s
[Step=46100 Epoch=90.1] | Loss=0.00714 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.348 | L2-Norm(final)=9.331 | 5104.6 samples/s | 79.8 steps/s
[Step=46150 Epoch=90.2] | Loss=0.00640 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.346 | L2-Norm(final)=9.337 | 4919.0 samples/s | 76.9 steps/s
[Step=46200 Epoch=90.3] | Loss=0.00663 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.345 | L2-Norm(final)=9.342 | 4892.7 samples/s | 76.4 steps/s
[Step=46250 Epoch=90.4] | Loss=0.00667 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.343 | L2-Norm(final)=9.347 | 5124.2 samples/s | 80.1 steps/s
[Step=46300 Epoch=90.5] | Loss=0.00649 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.342 | L2-Norm(final)=9.351 | 4951.5 samples/s | 77.4 steps/s
[Step=46350 Epoch=90.6] | Loss=0.00628 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.341 | L2-Norm(final)=9.357 | 4933.6 samples/s | 77.1 steps/s
[Step=46400 Epoch=90.7] | Loss=0.00631 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.340 | L2-Norm(final)=9.363 | 5010.5 samples/s | 78.3 steps/s
[Step=46450 Epoch=90.8] | Loss=0.00602 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.339 | L2-Norm(final)=9.368 | 5174.3 samples/s | 80.8 steps/s
[Step=46500 Epoch=90.9] | Loss=0.00589 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.338 | L2-Norm(final)=9.374 | 6676.9 samples/s | 104.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=90.9] | Loss=0.01042 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.326 | L2-Norm(final)=9.431 | 6142.6 samples/s | 96.0 steps/s
[Step=46550 Epoch=91.0] | Loss=0.00677 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.327 | L2-Norm(final)=9.436 | 4057.8 samples/s | 63.4 steps/s
[Step=46600 Epoch=91.1] | Loss=0.00724 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.331 | L2-Norm(final)=9.442 | 4464.5 samples/s | 69.8 steps/s
[Step=46650 Epoch=91.2] | Loss=0.00799 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.334 | L2-Norm(final)=9.447 | 4507.4 samples/s | 70.4 steps/s
[Step=46700 Epoch=91.3] | Loss=0.00823 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.337 | L2-Norm(final)=9.452 | 4436.9 samples/s | 69.3 steps/s
[Step=46750 Epoch=91.4] | Loss=0.00863 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.341 | L2-Norm(final)=9.456 | 4463.5 samples/s | 69.7 steps/s
[Step=46800 Epoch=91.5] | Loss=0.00869 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.344 | L2-Norm(final)=9.460 | 4432.8 samples/s | 69.3 steps/s
[Step=46850 Epoch=91.6] | Loss=0.00879 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.348 | L2-Norm(final)=9.465 | 4455.0 samples/s | 69.6 steps/s
[Step=46900 Epoch=91.7] | Loss=0.00857 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.351 | L2-Norm(final)=9.469 | 4450.2 samples/s | 69.5 steps/s
[Step=46950 Epoch=91.8] | Loss=0.00862 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.355 | L2-Norm(final)=9.474 | 4486.7 samples/s | 70.1 steps/s
[Step=47000 Epoch=91.9] | Loss=0.00863 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.358 | L2-Norm(final)=9.479 | 5825.4 samples/s | 91.0 steps/s
[Step=47050 Epoch=92.0] | Loss=0.00837 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.361 | L2-Norm(final)=9.483 | 2379.3 samples/s | 37.2 steps/s
[Step=47100 Epoch=92.1] | Loss=0.00814 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.363 | L2-Norm(final)=9.488 | 4543.8 samples/s | 71.0 steps/s
[Step=47150 Epoch=92.2] | Loss=0.00805 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.364 | L2-Norm(final)=9.493 | 4350.0 samples/s | 68.0 steps/s
[Step=47200 Epoch=92.3] | Loss=0.00802 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.365 | L2-Norm(final)=9.497 | 4460.6 samples/s | 69.7 steps/s
[Step=47250 Epoch=92.4] | Loss=0.00795 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.366 | L2-Norm(final)=9.500 | 4449.2 samples/s | 69.5 steps/s
[Step=47300 Epoch=92.5] | Loss=0.00783 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.367 | L2-Norm(final)=9.504 | 4550.8 samples/s | 71.1 steps/s
[Step=47350 Epoch=92.6] | Loss=0.00785 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.368 | L2-Norm(final)=9.507 | 4432.4 samples/s | 69.3 steps/s
[Step=47400 Epoch=92.7] | Loss=0.00779 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.368 | L2-Norm(final)=9.511 | 4442.6 samples/s | 69.4 steps/s
[Step=47450 Epoch=92.8] | Loss=0.00778 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.369 | L2-Norm(final)=9.514 | 4440.8 samples/s | 69.4 steps/s
[Step=47500 Epoch=92.9] | Loss=0.00782 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.369 | L2-Norm(final)=9.518 | 4913.6 samples/s | 76.8 steps/s
[Step=47550 Epoch=93.0] | Loss=0.00777 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.369 | L2-Norm(final)=9.521 | 2567.8 samples/s | 40.1 steps/s
[Step=47600 Epoch=93.1] | Loss=0.00769 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.368 | L2-Norm(final)=9.524 | 4433.1 samples/s | 69.3 steps/s
[Step=47650 Epoch=93.2] | Loss=0.00753 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.368 | L2-Norm(final)=9.527 | 4451.9 samples/s | 69.6 steps/s
[Step=47700 Epoch=93.3] | Loss=0.00745 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.367 | L2-Norm(final)=9.530 | 4429.9 samples/s | 69.2 steps/s
[Step=47750 Epoch=93.4] | Loss=0.00744 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.366 | L2-Norm(final)=9.533 | 4463.9 samples/s | 69.7 steps/s
[Step=47800 Epoch=93.4] | Loss=0.00744 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.366 | L2-Norm(final)=9.536 | 4517.8 samples/s | 70.6 steps/s
[Step=47850 Epoch=93.5] | Loss=0.00742 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.365 | L2-Norm(final)=9.538 | 4396.7 samples/s | 68.7 steps/s
[Step=47900 Epoch=93.6] | Loss=0.00729 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.363 | L2-Norm(final)=9.541 | 4424.4 samples/s | 69.1 steps/s
[Step=47950 Epoch=93.7] | Loss=0.00739 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.362 | L2-Norm(final)=9.544 | 4504.6 samples/s | 70.4 steps/s
[Step=48000 Epoch=93.8] | Loss=0.00732 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.361 | L2-Norm(final)=9.546 | 4410.2 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step48000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=176.3] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=5.947 | 5403.8 samples/s | 84.4 steps/s
[Step=46050 Epoch=176.4] | Loss=0.00018 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.282 | L2-Norm(final)=5.962 | 4289.4 samples/s | 67.0 steps/s
[Step=46100 Epoch=176.6] | Loss=0.00011 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=5.974 | 4572.7 samples/s | 71.4 steps/s
[Step=46150 Epoch=176.8] | Loss=0.00009 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=5.983 | 4751.8 samples/s | 74.2 steps/s
[Step=46200 Epoch=177.0] | Loss=0.00007 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.300 | L2-Norm(final)=5.991 | 4763.1 samples/s | 74.4 steps/s
[Step=46250 Epoch=177.2] | Loss=0.00006 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.301 | L2-Norm(final)=5.997 | 6478.0 samples/s | 101.2 steps/s
[Step=46300 Epoch=177.4] | Loss=0.00006 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.302 | L2-Norm(final)=6.003 | 2403.9 samples/s | 37.6 steps/s
[Step=46350 Epoch=177.6] | Loss=0.00005 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=6.009 | 4790.7 samples/s | 74.9 steps/s
[Step=46400 Epoch=177.8] | Loss=0.00005 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=6.014 | 4796.6 samples/s | 74.9 steps/s
[Step=46450 Epoch=178.0] | Loss=0.00004 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=6.018 | 4623.1 samples/s | 72.2 steps/s
[Step=46500 Epoch=178.2] | Loss=0.00004 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=6.023 | 5404.6 samples/s | 84.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=178.2] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.300 | L2-Norm(final)=6.068 | 6681.6 samples/s | 104.4 steps/s
[Step=46550 Epoch=178.4] | Loss=0.00024 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=6.073 | 3670.9 samples/s | 57.4 steps/s
[Step=46600 Epoch=178.6] | Loss=0.00276 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.326 | L2-Norm(final)=6.071 | 4217.3 samples/s | 65.9 steps/s
[Step=46650 Epoch=178.7] | Loss=0.00218 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.361 | L2-Norm(final)=6.066 | 4243.0 samples/s | 66.3 steps/s
[Step=46700 Epoch=178.9] | Loss=0.00167 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.382 | L2-Norm(final)=6.065 | 4236.6 samples/s | 66.2 steps/s
[Step=46750 Epoch=179.1] | Loss=0.00134 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.394 | L2-Norm(final)=6.065 | 5648.0 samples/s | 88.3 steps/s
[Step=46800 Epoch=179.3] | Loss=0.00112 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.402 | L2-Norm(final)=6.065 | 2280.5 samples/s | 35.6 steps/s
[Step=46850 Epoch=179.5] | Loss=0.00101 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.407 | L2-Norm(final)=6.066 | 4152.3 samples/s | 64.9 steps/s
[Step=46900 Epoch=179.7] | Loss=0.00088 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=6.066 | 4281.9 samples/s | 66.9 steps/s
[Step=46950 Epoch=179.9] | Loss=0.00079 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.413 | L2-Norm(final)=6.067 | 4224.8 samples/s | 66.0 steps/s
[Step=47000 Epoch=180.1] | Loss=0.00071 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.415 | L2-Norm(final)=6.068 | 4724.9 samples/s | 73.8 steps/s
[Step=47050 Epoch=180.3] | Loss=0.00065 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.416 | L2-Norm(final)=6.068 | 2441.9 samples/s | 38.2 steps/s
[Step=47100 Epoch=180.5] | Loss=0.00060 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=6.069 | 4200.7 samples/s | 65.6 steps/s
[Step=47150 Epoch=180.7] | Loss=0.00055 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=6.069 | 4205.8 samples/s | 65.7 steps/s
[Step=47200 Epoch=180.9] | Loss=0.00051 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=6.070 | 4231.8 samples/s | 66.1 steps/s
[Step=47250 Epoch=181.0] | Loss=0.00048 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.416 | L2-Norm(final)=6.071 | 4258.9 samples/s | 66.5 steps/s
[Step=47300 Epoch=181.2] | Loss=0.00045 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.415 | L2-Norm(final)=6.071 | 2641.3 samples/s | 41.3 steps/s
[Step=47350 Epoch=181.4] | Loss=0.00042 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.414 | L2-Norm(final)=6.072 | 4161.0 samples/s | 65.0 steps/s
[Step=47400 Epoch=181.6] | Loss=0.00040 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.413 | L2-Norm(final)=6.072 | 4290.4 samples/s | 67.0 steps/s
[Step=47450 Epoch=181.8] | Loss=0.00038 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.412 | L2-Norm(final)=6.073 | 4180.8 samples/s | 65.3 steps/s
[Step=47500 Epoch=182.0] | Loss=0.00036 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=6.073 | 4205.1 samples/s | 65.7 steps/s
[Step=47550 Epoch=182.2] | Loss=0.00034 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.409 | L2-Norm(final)=6.074 | 2616.9 samples/s | 40.9 steps/s
[Step=47600 Epoch=182.4] | Loss=0.00033 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.408 | L2-Norm(final)=6.074 | 4307.1 samples/s | 67.3 steps/s
[Step=47650 Epoch=182.6] | Loss=0.00031 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.406 | L2-Norm(final)=6.075 | 4107.0 samples/s | 64.2 steps/s
[Step=47700 Epoch=182.8] | Loss=0.00030 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.404 | L2-Norm(final)=6.075 | 4235.7 samples/s | 66.2 steps/s
[Step=47750 Epoch=183.0] | Loss=0.00029 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.402 | L2-Norm(final)=6.076 | 4291.6 samples/s | 67.1 steps/s
[Step=47800 Epoch=183.2] | Loss=0.00028 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.401 | L2-Norm(final)=6.076 | 6100.4 samples/s | 95.3 steps/s
[Step=47850 Epoch=183.3] | Loss=0.00027 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.399 | L2-Norm(final)=6.077 | 2176.1 samples/s | 34.0 steps/s
[Step=47900 Epoch=183.5] | Loss=0.00026 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.397 | L2-Norm(final)=6.077 | 4252.5 samples/s | 66.4 steps/s
[Step=47950 Epoch=183.7] | Loss=0.00025 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.394 | L2-Norm(final)=6.077 | 4297.2 samples/s | 67.1 steps/s
[Step=48000 Epoch=183.9] | Loss=0.00024 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.392 | L2-Norm(final)=6.078 | 4195.9 samples/s | 65.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step48000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=177.1] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=6.341 | 5516.1 samples/s | 86.2 steps/s
[Step=46050 Epoch=177.3] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=6.360 | 4253.6 samples/s | 66.5 steps/s
[Step=46100 Epoch=177.5] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.203 | L2-Norm(final)=6.378 | 4688.2 samples/s | 73.3 steps/s
[Step=46150 Epoch=177.6] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.207 | L2-Norm(final)=6.396 | 4706.8 samples/s | 73.5 steps/s
[Step=46200 Epoch=177.8] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.413 | 4673.0 samples/s | 73.0 steps/s
[Step=46250 Epoch=178.0] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.215 | L2-Norm(final)=6.427 | 6703.1 samples/s | 104.7 steps/s
[Step=46300 Epoch=178.2] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.217 | L2-Norm(final)=6.439 | 2408.1 samples/s | 37.6 steps/s
[Step=46350 Epoch=178.4] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=6.450 | 4657.9 samples/s | 72.8 steps/s
[Step=46400 Epoch=178.6] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=6.460 | 4814.6 samples/s | 75.2 steps/s
[Step=46450 Epoch=178.8] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=6.470 | 4735.7 samples/s | 74.0 steps/s
[Step=46500 Epoch=179.0] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=6.479 | 5560.3 samples/s | 86.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=179.0] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.214 | L2-Norm(final)=6.568 | 6732.2 samples/s | 105.2 steps/s
[Step=46550 Epoch=179.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.576 | 3622.6 samples/s | 56.6 steps/s
[Step=46600 Epoch=179.4] | Loss=0.00048 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.161 | L2-Norm(final)=6.583 | 4238.1 samples/s | 66.2 steps/s
[Step=46650 Epoch=179.6] | Loss=0.00203 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.176 | L2-Norm(final)=6.581 | 4248.8 samples/s | 66.4 steps/s
[Step=46700 Epoch=179.8] | Loss=0.00166 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.198 | L2-Norm(final)=6.576 | 4182.5 samples/s | 65.4 steps/s
[Step=46750 Epoch=180.0] | Loss=0.00139 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.575 | 5814.8 samples/s | 90.9 steps/s
[Step=46800 Epoch=180.2] | Loss=0.00121 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.221 | L2-Norm(final)=6.574 | 2240.1 samples/s | 35.0 steps/s
[Step=46850 Epoch=180.3] | Loss=0.00105 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.228 | L2-Norm(final)=6.575 | 4257.5 samples/s | 66.5 steps/s
[Step=46900 Epoch=180.5] | Loss=0.00092 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.233 | L2-Norm(final)=6.575 | 4186.3 samples/s | 65.4 steps/s
[Step=46950 Epoch=180.7] | Loss=0.00083 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.237 | L2-Norm(final)=6.576 | 4237.5 samples/s | 66.2 steps/s
[Step=47000 Epoch=180.9] | Loss=0.00075 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.577 | 4900.4 samples/s | 76.6 steps/s
[Step=47050 Epoch=181.1] | Loss=0.00069 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.242 | L2-Norm(final)=6.577 | 2405.7 samples/s | 37.6 steps/s
[Step=47100 Epoch=181.3] | Loss=0.00063 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.243 | L2-Norm(final)=6.578 | 4249.8 samples/s | 66.4 steps/s
[Step=47150 Epoch=181.5] | Loss=0.00059 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.244 | L2-Norm(final)=6.579 | 4194.3 samples/s | 65.5 steps/s
[Step=47200 Epoch=181.7] | Loss=0.00054 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.580 | 4273.3 samples/s | 66.8 steps/s
[Step=47250 Epoch=181.9] | Loss=0.00051 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.581 | 4198.8 samples/s | 65.6 steps/s
[Step=47300 Epoch=182.1] | Loss=0.00048 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=6.581 | 2572.8 samples/s | 40.2 steps/s
[Step=47350 Epoch=182.3] | Loss=0.00045 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=6.582 | 4044.0 samples/s | 63.2 steps/s
[Step=47400 Epoch=182.5] | Loss=0.00043 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.583 | 4084.0 samples/s | 63.8 steps/s
[Step=47450 Epoch=182.7] | Loss=0.00040 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.583 | 4071.6 samples/s | 63.6 steps/s
[Step=47500 Epoch=182.8] | Loss=0.00039 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.584 | 4120.9 samples/s | 64.4 steps/s
[Step=47550 Epoch=183.0] | Loss=0.00037 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.244 | L2-Norm(final)=6.585 | 2556.3 samples/s | 39.9 steps/s
[Step=47600 Epoch=183.2] | Loss=0.00035 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.243 | L2-Norm(final)=6.585 | 4190.0 samples/s | 65.5 steps/s
[Step=47650 Epoch=183.4] | Loss=0.00034 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.242 | L2-Norm(final)=6.586 | 4075.5 samples/s | 63.7 steps/s
[Step=47700 Epoch=183.6] | Loss=0.00032 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.242 | L2-Norm(final)=6.586 | 4076.9 samples/s | 63.7 steps/s
[Step=47750 Epoch=183.8] | Loss=0.00031 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.587 | 4139.9 samples/s | 64.7 steps/s
[Step=47800 Epoch=184.0] | Loss=0.00030 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.587 | 6717.5 samples/s | 105.0 steps/s
[Step=47850 Epoch=184.2] | Loss=0.00029 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=6.588 | 2067.3 samples/s | 32.3 steps/s
[Step=47900 Epoch=184.4] | Loss=0.00028 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.237 | L2-Norm(final)=6.588 | 4076.5 samples/s | 63.7 steps/s
[Step=47950 Epoch=184.6] | Loss=0.00027 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=6.589 | 4139.9 samples/s | 64.7 steps/s
[Step=48000 Epoch=184.8] | Loss=0.00026 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.235 | L2-Norm(final)=6.589 | 4107.1 samples/s | 64.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07668 | acc=0.9675 | tpr=0.9741 | fpr=0.0468 | 4820.1 samples/s | 18.8 steps/s
Avg test loss: 0.07698, Avg test acc: 0.96767, Avg tpr: 0.97354, Avg fpr: 0.04525, total FA: 353

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07523 | acc=0.9673 | tpr=0.9744 | fpr=0.0481 | 4721.3 samples/s | 18.4 steps/s
Avg test loss: 0.07632, Avg test acc: 0.96682, Avg tpr: 0.97412, Avg fpr: 0.04922, total FA: 384

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.21738 | acc=0.2967 | tpr=0.0075 | fpr=0.0753 | 4629.7 samples/s | 18.1 steps/s
Avg test loss: 5.21750, Avg test acc: 0.29365, Avg tpr: 0.00892, Avg fpr: 0.08012, total FA: 625

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.89198 | acc=0.3057 | tpr=0.0162 | fpr=0.0657 | 4965.8 samples/s | 19.4 steps/s
Avg test loss: 5.87735, Avg test acc: 0.30239, Avg tpr: 0.01743, Avg fpr: 0.07089, total FA: 553

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.17334 | acc=0.1514 | tpr=0.5619 | fpr=0.8560 | 4684.6 samples/s | 18.3 steps/s
[Step= 100] | Loss=6.13307 | acc=0.1519 | tpr=0.5437 | fpr=0.8554 | 7515.0 samples/s | 29.4 steps/s
[Step= 150] | Loss=6.13908 | acc=0.1528 | tpr=0.5418 | fpr=0.8543 | 7864.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.13257 | acc=0.1527 | tpr=0.5377 | fpr=0.8543 | 7672.9 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.12397 | acc=0.1533 | tpr=0.5467 | fpr=0.8539 | 7604.9 samples/s | 29.7 steps/s
[Step= 300] | Loss=6.11604 | acc=0.1533 | tpr=0.5469 | fpr=0.8539 | 7464.0 samples/s | 29.2 steps/s
[Step= 350] | Loss=6.12223 | acc=0.1533 | tpr=0.5398 | fpr=0.8537 | 7961.1 samples/s | 31.1 steps/s
[Step= 400] | Loss=6.12375 | acc=0.1534 | tpr=0.5372 | fpr=0.8536 | 7973.0 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.12681 | acc=0.1529 | tpr=0.5336 | fpr=0.8540 | 7715.5 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.12836 | acc=0.1534 | tpr=0.5366 | fpr=0.8536 | 7725.0 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.13237 | acc=0.1535 | tpr=0.5352 | fpr=0.8534 | 13779.5 samples/s | 53.8 steps/s
Avg test loss: 6.13419, Avg test acc: 0.15339, Avg tpr: 0.53645, Avg fpr: 0.85357, total FA: 118517

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.90757 | acc=0.1327 | tpr=0.5796 | fpr=0.8754 | 5071.2 samples/s | 19.8 steps/s
[Step= 100] | Loss=6.88834 | acc=0.1334 | tpr=0.5352 | fpr=0.8741 | 6773.8 samples/s | 26.5 steps/s
[Step= 150] | Loss=6.88942 | acc=0.1336 | tpr=0.5447 | fpr=0.8739 | 7690.8 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.88850 | acc=0.1338 | tpr=0.5443 | fpr=0.8737 | 7770.1 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.88131 | acc=0.1342 | tpr=0.5397 | fpr=0.8732 | 7916.8 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.87416 | acc=0.1346 | tpr=0.5353 | fpr=0.8727 | 7854.5 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.87970 | acc=0.1344 | tpr=0.5329 | fpr=0.8728 | 7477.8 samples/s | 29.2 steps/s
[Step= 400] | Loss=6.87945 | acc=0.1345 | tpr=0.5284 | fpr=0.8726 | 8116.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=6.88474 | acc=0.1341 | tpr=0.5224 | fpr=0.8729 | 7871.3 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.88748 | acc=0.1345 | tpr=0.5269 | fpr=0.8726 | 7803.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.89353 | acc=0.1344 | tpr=0.5288 | fpr=0.8728 | 13531.3 samples/s | 52.9 steps/s
Avg test loss: 6.89589, Avg test acc: 0.13426, Avg tpr: 0.52932, Avg fpr: 0.87293, total FA: 121204

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13676 | acc=0.9785 | tpr=0.9425 | fpr=0.0208 | 4843.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.13900 | acc=0.9788 | tpr=0.9531 | fpr=0.0207 | 7352.7 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.14538 | acc=0.9779 | tpr=0.9510 | fpr=0.0216 | 7614.6 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.14930 | acc=0.9774 | tpr=0.9530 | fpr=0.0221 | 7692.7 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.14691 | acc=0.9777 | tpr=0.9528 | fpr=0.0218 | 7942.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.14914 | acc=0.9774 | tpr=0.9505 | fpr=0.0221 | 7795.7 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.14951 | acc=0.9773 | tpr=0.9518 | fpr=0.0223 | 7718.2 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.15085 | acc=0.9772 | tpr=0.9502 | fpr=0.0224 | 7802.1 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.15351 | acc=0.9768 | tpr=0.9489 | fpr=0.0227 | 7800.8 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.15300 | acc=0.9769 | tpr=0.9502 | fpr=0.0226 | 7941.4 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.15140 | acc=0.9772 | tpr=0.9511 | fpr=0.0223 | 13332.6 samples/s | 52.1 steps/s
Avg test loss: 0.15126, Avg test acc: 0.97719, Avg tpr: 0.95087, Avg fpr: 0.02233, total FA: 3101

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12584 | acc=0.9780 | tpr=0.9558 | fpr=0.0216 | 5026.3 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.12880 | acc=0.9780 | tpr=0.9616 | fpr=0.0217 | 7005.4 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.13448 | acc=0.9770 | tpr=0.9625 | fpr=0.0227 | 7817.4 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.13699 | acc=0.9772 | tpr=0.9607 | fpr=0.0225 | 7520.9 samples/s | 29.4 steps/s
[Step= 250] | Loss=0.13481 | acc=0.9775 | tpr=0.9555 | fpr=0.0221 | 7762.0 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.13740 | acc=0.9770 | tpr=0.9542 | fpr=0.0226 | 7888.4 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.13724 | acc=0.9771 | tpr=0.9549 | fpr=0.0225 | 7608.4 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.13835 | acc=0.9770 | tpr=0.9524 | fpr=0.0226 | 7638.0 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.14104 | acc=0.9766 | tpr=0.9499 | fpr=0.0229 | 7670.3 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.14044 | acc=0.9767 | tpr=0.9507 | fpr=0.0229 | 8034.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.13925 | acc=0.9769 | tpr=0.9507 | fpr=0.0226 | 13430.6 samples/s | 52.5 steps/s
Avg test loss: 0.13904, Avg test acc: 0.97690, Avg tpr: 0.95048, Avg fpr: 0.02261, total FA: 3140

server round 24/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=93.6] | Loss=0.00824 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.163 | L2-Norm(final)=9.482 | 6602.1 samples/s | 103.2 steps/s
[Step=48050 Epoch=93.7] | Loss=0.00606 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.163 | L2-Norm(final)=9.488 | 4692.2 samples/s | 73.3 steps/s
[Step=48100 Epoch=93.8] | Loss=0.00623 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.164 | L2-Norm(final)=9.495 | 5021.3 samples/s | 78.5 steps/s
[Step=48150 Epoch=93.9] | Loss=0.00614 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.164 | L2-Norm(final)=9.502 | 4906.9 samples/s | 76.7 steps/s
[Step=48200 Epoch=94.0] | Loss=0.00602 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.164 | L2-Norm(final)=9.509 | 5189.4 samples/s | 81.1 steps/s
[Step=48250 Epoch=94.1] | Loss=0.00581 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.163 | L2-Norm(final)=9.517 | 4858.4 samples/s | 75.9 steps/s
[Step=48300 Epoch=94.2] | Loss=0.00582 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.163 | L2-Norm(final)=9.524 | 4881.2 samples/s | 76.3 steps/s
[Step=48350 Epoch=94.3] | Loss=0.00565 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.163 | L2-Norm(final)=9.531 | 5068.6 samples/s | 79.2 steps/s
[Step=48400 Epoch=94.4] | Loss=0.00585 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.162 | L2-Norm(final)=9.537 | 5027.6 samples/s | 78.6 steps/s
[Step=48450 Epoch=94.5] | Loss=0.00582 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.161 | L2-Norm(final)=9.544 | 4915.8 samples/s | 76.8 steps/s
[Step=48500 Epoch=94.6] | Loss=0.00584 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.160 | L2-Norm(final)=9.550 | 6748.0 samples/s | 105.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=94.6] | Loss=0.00096 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.153 | L2-Norm(final)=9.616 | 6282.1 samples/s | 98.2 steps/s
[Step=48550 Epoch=94.7] | Loss=0.00668 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.152 | L2-Norm(final)=9.623 | 4014.3 samples/s | 62.7 steps/s
[Step=48600 Epoch=94.8] | Loss=0.00745 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.152 | L2-Norm(final)=9.626 | 4422.5 samples/s | 69.1 steps/s
[Step=48650 Epoch=94.9] | Loss=0.00750 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.154 | L2-Norm(final)=9.630 | 4431.1 samples/s | 69.2 steps/s
[Step=48700 Epoch=95.0] | Loss=0.00780 | Reg=0.00330 | acc=0.9688 | L2-Norm=18.157 | L2-Norm(final)=9.634 | 4511.1 samples/s | 70.5 steps/s
[Step=48750 Epoch=95.1] | Loss=0.00798 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.160 | L2-Norm(final)=9.639 | 4416.9 samples/s | 69.0 steps/s
[Step=48800 Epoch=95.2] | Loss=0.00810 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.164 | L2-Norm(final)=9.644 | 4335.7 samples/s | 67.7 steps/s
[Step=48850 Epoch=95.3] | Loss=0.00821 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.168 | L2-Norm(final)=9.649 | 4440.7 samples/s | 69.4 steps/s
[Step=48900 Epoch=95.4] | Loss=0.00849 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.170 | L2-Norm(final)=9.654 | 4495.7 samples/s | 70.2 steps/s
[Step=48950 Epoch=95.5] | Loss=0.00846 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.173 | L2-Norm(final)=9.658 | 4376.6 samples/s | 68.4 steps/s
[Step=49000 Epoch=95.6] | Loss=0.00845 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.176 | L2-Norm(final)=9.662 | 5730.2 samples/s | 89.5 steps/s
[Step=49050 Epoch=95.7] | Loss=0.00824 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.178 | L2-Norm(final)=9.667 | 2371.1 samples/s | 37.0 steps/s
[Step=49100 Epoch=95.8] | Loss=0.00805 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.179 | L2-Norm(final)=9.671 | 4423.7 samples/s | 69.1 steps/s
[Step=49150 Epoch=95.9] | Loss=0.00796 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.180 | L2-Norm(final)=9.675 | 4432.0 samples/s | 69.2 steps/s
[Step=49200 Epoch=96.0] | Loss=0.00778 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.180 | L2-Norm(final)=9.679 | 4389.3 samples/s | 68.6 steps/s
[Step=49250 Epoch=96.1] | Loss=0.00760 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.181 | L2-Norm(final)=9.683 | 4444.1 samples/s | 69.4 steps/s
[Step=49300 Epoch=96.2] | Loss=0.00752 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.181 | L2-Norm(final)=9.687 | 4495.8 samples/s | 70.2 steps/s
[Step=49350 Epoch=96.3] | Loss=0.00757 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.181 | L2-Norm(final)=9.690 | 4420.0 samples/s | 69.1 steps/s
[Step=49400 Epoch=96.3] | Loss=0.00749 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.181 | L2-Norm(final)=9.693 | 4357.4 samples/s | 68.1 steps/s
[Step=49450 Epoch=96.4] | Loss=0.00763 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.181 | L2-Norm(final)=9.697 | 4399.3 samples/s | 68.7 steps/s
[Step=49500 Epoch=96.5] | Loss=0.00766 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.181 | L2-Norm(final)=9.700 | 4793.0 samples/s | 74.9 steps/s
[Step=49550 Epoch=96.6] | Loss=0.00767 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.181 | L2-Norm(final)=9.703 | 2560.8 samples/s | 40.0 steps/s
[Step=49600 Epoch=96.7] | Loss=0.00756 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.181 | L2-Norm(final)=9.706 | 4454.7 samples/s | 69.6 steps/s
[Step=49650 Epoch=96.8] | Loss=0.00748 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.180 | L2-Norm(final)=9.709 | 4452.0 samples/s | 69.6 steps/s
[Step=49700 Epoch=96.9] | Loss=0.00738 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.180 | L2-Norm(final)=9.712 | 4405.5 samples/s | 68.8 steps/s
[Step=49750 Epoch=97.0] | Loss=0.00728 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.180 | L2-Norm(final)=9.715 | 4477.1 samples/s | 70.0 steps/s
[Step=49800 Epoch=97.1] | Loss=0.00725 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.179 | L2-Norm(final)=9.719 | 4370.6 samples/s | 68.3 steps/s
[Step=49850 Epoch=97.2] | Loss=0.00730 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.178 | L2-Norm(final)=9.722 | 4404.9 samples/s | 68.8 steps/s
[Step=49900 Epoch=97.3] | Loss=0.00721 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.178 | L2-Norm(final)=9.725 | 4432.8 samples/s | 69.3 steps/s
[Step=49950 Epoch=97.4] | Loss=0.00721 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.177 | L2-Norm(final)=9.728 | 4443.8 samples/s | 69.4 steps/s
[Step=50000 Epoch=97.5] | Loss=0.00721 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.176 | L2-Norm(final)=9.731 | 4417.3 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step50000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=93.8] | Loss=0.00323 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.222 | L2-Norm(final)=9.627 | 5839.9 samples/s | 91.2 steps/s
[Step=48050 Epoch=93.9] | Loss=0.00590 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.222 | L2-Norm(final)=9.633 | 4402.3 samples/s | 68.8 steps/s
[Step=48100 Epoch=94.0] | Loss=0.00638 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.223 | L2-Norm(final)=9.640 | 4918.9 samples/s | 76.9 steps/s
[Step=48150 Epoch=94.1] | Loss=0.00674 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.224 | L2-Norm(final)=9.646 | 5110.4 samples/s | 79.8 steps/s
[Step=48200 Epoch=94.2] | Loss=0.00638 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.225 | L2-Norm(final)=9.653 | 4908.9 samples/s | 76.7 steps/s
[Step=48250 Epoch=94.3] | Loss=0.00637 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.660 | 5069.1 samples/s | 79.2 steps/s
[Step=48300 Epoch=94.4] | Loss=0.00638 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.667 | 4958.9 samples/s | 77.5 steps/s
[Step=48350 Epoch=94.5] | Loss=0.00626 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.226 | L2-Norm(final)=9.674 | 5016.1 samples/s | 78.4 steps/s
[Step=48400 Epoch=94.6] | Loss=0.00626 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.226 | L2-Norm(final)=9.681 | 4879.5 samples/s | 76.2 steps/s
[Step=48450 Epoch=94.7] | Loss=0.00615 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.687 | 4981.6 samples/s | 77.8 steps/s
[Step=48500 Epoch=94.8] | Loss=0.00606 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.694 | 6889.3 samples/s | 107.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=94.8] | Loss=0.00083 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.764 | 5970.4 samples/s | 93.3 steps/s
[Step=48550 Epoch=94.9] | Loss=0.00495 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.771 | 4175.2 samples/s | 65.2 steps/s
[Step=48600 Epoch=95.0] | Loss=0.00608 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.226 | L2-Norm(final)=9.776 | 4458.4 samples/s | 69.7 steps/s
[Step=48650 Epoch=95.1] | Loss=0.00723 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.227 | L2-Norm(final)=9.780 | 4415.2 samples/s | 69.0 steps/s
[Step=48700 Epoch=95.2] | Loss=0.00779 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.228 | L2-Norm(final)=9.783 | 4448.2 samples/s | 69.5 steps/s
[Step=48750 Epoch=95.3] | Loss=0.00779 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.231 | L2-Norm(final)=9.787 | 4475.5 samples/s | 69.9 steps/s
[Step=48800 Epoch=95.4] | Loss=0.00774 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.234 | L2-Norm(final)=9.791 | 4346.9 samples/s | 67.9 steps/s
[Step=48850 Epoch=95.5] | Loss=0.00787 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.235 | L2-Norm(final)=9.794 | 4418.0 samples/s | 69.0 steps/s
[Step=48900 Epoch=95.6] | Loss=0.00786 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.237 | L2-Norm(final)=9.798 | 4428.2 samples/s | 69.2 steps/s
[Step=48950 Epoch=95.7] | Loss=0.00793 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.238 | L2-Norm(final)=9.801 | 4445.8 samples/s | 69.5 steps/s
[Step=49000 Epoch=95.8] | Loss=0.00794 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.239 | L2-Norm(final)=9.805 | 5855.8 samples/s | 91.5 steps/s
[Step=49050 Epoch=95.9] | Loss=0.00776 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.240 | L2-Norm(final)=9.809 | 2371.2 samples/s | 37.1 steps/s
[Step=49100 Epoch=96.0] | Loss=0.00764 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.241 | L2-Norm(final)=9.813 | 4371.4 samples/s | 68.3 steps/s
[Step=49150 Epoch=96.1] | Loss=0.00757 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.242 | L2-Norm(final)=9.817 | 4414.1 samples/s | 69.0 steps/s
[Step=49200 Epoch=96.2] | Loss=0.00748 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=9.820 | 4548.7 samples/s | 71.1 steps/s
[Step=49250 Epoch=96.3] | Loss=0.00754 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=9.824 | 4315.7 samples/s | 67.4 steps/s
[Step=49300 Epoch=96.4] | Loss=0.00755 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=9.827 | 4461.1 samples/s | 69.7 steps/s
[Step=49350 Epoch=96.5] | Loss=0.00755 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.242 | L2-Norm(final)=9.830 | 4514.4 samples/s | 70.5 steps/s
[Step=49400 Epoch=96.6] | Loss=0.00763 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=9.833 | 4366.1 samples/s | 68.2 steps/s
[Step=49450 Epoch=96.7] | Loss=0.00763 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=9.836 | 4415.6 samples/s | 69.0 steps/s
[Step=49500 Epoch=96.8] | Loss=0.00764 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.242 | L2-Norm(final)=9.839 | 4904.7 samples/s | 76.6 steps/s
[Step=49550 Epoch=96.9] | Loss=0.00762 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.241 | L2-Norm(final)=9.842 | 2565.5 samples/s | 40.1 steps/s
[Step=49600 Epoch=97.0] | Loss=0.00751 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.241 | L2-Norm(final)=9.844 | 4364.3 samples/s | 68.2 steps/s
[Step=49650 Epoch=97.1] | Loss=0.00742 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.240 | L2-Norm(final)=9.847 | 4470.1 samples/s | 69.8 steps/s
[Step=49700 Epoch=97.2] | Loss=0.00732 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.240 | L2-Norm(final)=9.850 | 4396.3 samples/s | 68.7 steps/s
[Step=49750 Epoch=97.3] | Loss=0.00731 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.239 | L2-Norm(final)=9.853 | 4429.9 samples/s | 69.2 steps/s
[Step=49800 Epoch=97.4] | Loss=0.00732 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.238 | L2-Norm(final)=9.855 | 4443.6 samples/s | 69.4 steps/s
[Step=49850 Epoch=97.5] | Loss=0.00727 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.237 | L2-Norm(final)=9.858 | 4418.8 samples/s | 69.0 steps/s
[Step=49900 Epoch=97.6] | Loss=0.00723 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.236 | L2-Norm(final)=9.861 | 4402.0 samples/s | 68.8 steps/s
[Step=49950 Epoch=97.7] | Loss=0.00718 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.234 | L2-Norm(final)=9.863 | 4477.0 samples/s | 70.0 steps/s
[Step=50000 Epoch=97.7] | Loss=0.00721 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.233 | L2-Norm(final)=9.866 | 4418.8 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step50000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=183.9] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.361 | L2-Norm(final)=6.092 | 6582.4 samples/s | 102.8 steps/s
[Step=48050 Epoch=184.1] | Loss=0.00006 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.364 | L2-Norm(final)=6.094 | 4318.3 samples/s | 67.5 steps/s
[Step=48100 Epoch=184.3] | Loss=0.00004 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=6.096 | 4690.3 samples/s | 73.3 steps/s
[Step=48150 Epoch=184.5] | Loss=0.00004 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=6.098 | 4723.5 samples/s | 73.8 steps/s
[Step=48200 Epoch=184.7] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=6.100 | 4561.4 samples/s | 71.3 steps/s
[Step=48250 Epoch=184.9] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=6.102 | 6541.1 samples/s | 102.2 steps/s
[Step=48300 Epoch=185.1] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=6.104 | 2379.3 samples/s | 37.2 steps/s
[Step=48350 Epoch=185.3] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=6.105 | 4673.5 samples/s | 73.0 steps/s
[Step=48400 Epoch=185.5] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=6.107 | 4850.6 samples/s | 75.8 steps/s
[Step=48450 Epoch=185.6] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=6.109 | 4569.9 samples/s | 71.4 steps/s
[Step=48500 Epoch=185.8] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=6.110 | 5397.3 samples/s | 84.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=185.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.363 | L2-Norm(final)=6.128 | 6450.8 samples/s | 100.8 steps/s
[Step=48550 Epoch=186.0] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.361 | L2-Norm(final)=6.130 | 3624.4 samples/s | 56.6 steps/s
[Step=48600 Epoch=186.2] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.131 | 4244.1 samples/s | 66.3 steps/s
[Step=48650 Epoch=186.4] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.352 | L2-Norm(final)=6.133 | 4170.1 samples/s | 65.2 steps/s
[Step=48700 Epoch=186.6] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.348 | L2-Norm(final)=6.134 | 4234.7 samples/s | 66.2 steps/s
[Step=48750 Epoch=186.8] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.344 | L2-Norm(final)=6.136 | 5550.2 samples/s | 86.7 steps/s
[Step=48800 Epoch=187.0] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.340 | L2-Norm(final)=6.137 | 2226.4 samples/s | 34.8 steps/s
[Step=48850 Epoch=187.2] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.335 | L2-Norm(final)=6.138 | 4049.4 samples/s | 63.3 steps/s
[Step=48900 Epoch=187.4] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=6.139 | 4118.1 samples/s | 64.3 steps/s
[Step=48950 Epoch=187.6] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.326 | L2-Norm(final)=6.141 | 4117.2 samples/s | 64.3 steps/s
[Step=49000 Epoch=187.8] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.321 | L2-Norm(final)=6.142 | 4464.5 samples/s | 69.8 steps/s
[Step=49050 Epoch=187.9] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.316 | L2-Norm(final)=6.143 | 2372.8 samples/s | 37.1 steps/s
[Step=49100 Epoch=188.1] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.312 | L2-Norm(final)=6.144 | 4165.6 samples/s | 65.1 steps/s
[Step=49150 Epoch=188.3] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.307 | L2-Norm(final)=6.145 | 4238.2 samples/s | 66.2 steps/s
[Step=49200 Epoch=188.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.302 | L2-Norm(final)=6.146 | 4187.0 samples/s | 65.4 steps/s
[Step=49250 Epoch=188.7] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=6.147 | 4218.1 samples/s | 65.9 steps/s
[Step=49300 Epoch=188.9] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.292 | L2-Norm(final)=6.148 | 2578.7 samples/s | 40.3 steps/s
[Step=49350 Epoch=189.1] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.149 | 4230.1 samples/s | 66.1 steps/s
[Step=49400 Epoch=189.3] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.281 | L2-Norm(final)=6.150 | 4091.9 samples/s | 63.9 steps/s
[Step=49450 Epoch=189.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.276 | L2-Norm(final)=6.150 | 4194.9 samples/s | 65.5 steps/s
[Step=49500 Epoch=189.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=6.151 | 4199.1 samples/s | 65.6 steps/s
[Step=49550 Epoch=189.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.265 | L2-Norm(final)=6.152 | 2637.2 samples/s | 41.2 steps/s
[Step=49600 Epoch=190.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.259 | L2-Norm(final)=6.153 | 4065.9 samples/s | 63.5 steps/s
[Step=49650 Epoch=190.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=6.154 | 4241.2 samples/s | 66.3 steps/s
[Step=49700 Epoch=190.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.248 | L2-Norm(final)=6.155 | 4158.8 samples/s | 65.0 steps/s
[Step=49750 Epoch=190.6] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.242 | L2-Norm(final)=6.156 | 4261.8 samples/s | 66.6 steps/s
[Step=49800 Epoch=190.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=6.157 | 6197.1 samples/s | 96.8 steps/s
[Step=49850 Epoch=191.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=6.158 | 2170.3 samples/s | 33.9 steps/s
[Step=49900 Epoch=191.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.225 | L2-Norm(final)=6.159 | 4247.8 samples/s | 66.4 steps/s
[Step=49950 Epoch=191.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=6.159 | 4258.3 samples/s | 66.5 steps/s
[Step=50000 Epoch=191.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.160 | 4198.1 samples/s | 65.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step50000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=184.8] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.281 | L2-Norm(final)=6.604 | 6308.5 samples/s | 98.6 steps/s
[Step=48050 Epoch=185.0] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.281 | L2-Norm(final)=6.605 | 4201.3 samples/s | 65.6 steps/s
[Step=48100 Epoch=185.2] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.281 | L2-Norm(final)=6.607 | 4694.3 samples/s | 73.3 steps/s
[Step=48150 Epoch=185.3] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.609 | 4629.6 samples/s | 72.3 steps/s
[Step=48200 Epoch=185.5] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.610 | 4756.0 samples/s | 74.3 steps/s
[Step=48250 Epoch=185.7] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.611 | 6273.1 samples/s | 98.0 steps/s
[Step=48300 Epoch=185.9] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.613 | 2266.2 samples/s | 35.4 steps/s
[Step=48350 Epoch=186.1] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.614 | 4510.5 samples/s | 70.5 steps/s
[Step=48400 Epoch=186.3] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.616 | 4574.1 samples/s | 71.5 steps/s
[Step=48450 Epoch=186.5] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.617 | 4492.0 samples/s | 70.2 steps/s
[Step=48500 Epoch=186.7] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.618 | 5408.4 samples/s | 84.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=186.7] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.279 | L2-Norm(final)=6.632 | 5511.1 samples/s | 86.1 steps/s
[Step=48550 Epoch=186.9] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.277 | L2-Norm(final)=6.634 | 3824.8 samples/s | 59.8 steps/s
[Step=48600 Epoch=187.1] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.275 | L2-Norm(final)=6.635 | 3975.7 samples/s | 62.1 steps/s
[Step=48650 Epoch=187.3] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=6.637 | 4177.8 samples/s | 65.3 steps/s
[Step=48700 Epoch=187.5] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.269 | L2-Norm(final)=6.638 | 4278.8 samples/s | 66.9 steps/s
[Step=48750 Epoch=187.7] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.267 | L2-Norm(final)=6.639 | 5573.3 samples/s | 87.1 steps/s
[Step=48800 Epoch=187.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.264 | L2-Norm(final)=6.640 | 2235.6 samples/s | 34.9 steps/s
[Step=48850 Epoch=188.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.261 | L2-Norm(final)=6.641 | 4205.1 samples/s | 65.7 steps/s
[Step=48900 Epoch=188.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=6.642 | 4221.0 samples/s | 66.0 steps/s
[Step=48950 Epoch=188.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.255 | L2-Norm(final)=6.642 | 4219.1 samples/s | 65.9 steps/s
[Step=49000 Epoch=188.6] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.251 | L2-Norm(final)=6.643 | 4918.1 samples/s | 76.8 steps/s
[Step=49050 Epoch=188.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.248 | L2-Norm(final)=6.644 | 2397.9 samples/s | 37.5 steps/s
[Step=49100 Epoch=189.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=6.645 | 4267.0 samples/s | 66.7 steps/s
[Step=49150 Epoch=189.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.646 | 4278.3 samples/s | 66.8 steps/s
[Step=49200 Epoch=189.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=6.646 | 4083.6 samples/s | 63.8 steps/s
[Step=49250 Epoch=189.6] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.234 | L2-Norm(final)=6.647 | 4339.4 samples/s | 67.8 steps/s
[Step=49300 Epoch=189.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=6.648 | 2631.3 samples/s | 41.1 steps/s
[Step=49350 Epoch=190.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.227 | L2-Norm(final)=6.649 | 4224.1 samples/s | 66.0 steps/s
[Step=49400 Epoch=190.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.223 | L2-Norm(final)=6.649 | 4192.1 samples/s | 65.5 steps/s
[Step=49450 Epoch=190.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.220 | L2-Norm(final)=6.650 | 4207.7 samples/s | 65.7 steps/s
[Step=49500 Epoch=190.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.216 | L2-Norm(final)=6.651 | 4206.2 samples/s | 65.7 steps/s
[Step=49550 Epoch=190.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.652 | 2626.1 samples/s | 41.0 steps/s
[Step=49600 Epoch=190.9] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.652 | 4251.2 samples/s | 66.4 steps/s
[Step=49650 Epoch=191.1] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.204 | L2-Norm(final)=6.653 | 4205.3 samples/s | 65.7 steps/s
[Step=49700 Epoch=191.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.200 | L2-Norm(final)=6.654 | 4234.2 samples/s | 66.2 steps/s
[Step=49750 Epoch=191.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.196 | L2-Norm(final)=6.654 | 4278.7 samples/s | 66.9 steps/s
[Step=49800 Epoch=191.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=6.655 | 6831.5 samples/s | 106.7 steps/s
[Step=49850 Epoch=191.9] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.187 | L2-Norm(final)=6.656 | 2101.3 samples/s | 32.8 steps/s
[Step=49900 Epoch=192.1] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.183 | L2-Norm(final)=6.657 | 4197.8 samples/s | 65.6 steps/s
[Step=49950 Epoch=192.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.178 | L2-Norm(final)=6.657 | 4255.1 samples/s | 66.5 steps/s
[Step=50000 Epoch=192.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.174 | L2-Norm(final)=6.658 | 4234.7 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08133 | acc=0.9654 | tpr=0.9757 | fpr=0.0570 | 5052.4 samples/s | 19.7 steps/s
Avg test loss: 0.08017, Avg test acc: 0.96630, Avg tpr: 0.97622, Avg fpr: 0.05551, total FA: 433

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07304 | acc=0.9655 | tpr=0.9685 | fpr=0.0411 | 4964.1 samples/s | 19.4 steps/s
Avg test loss: 0.07430, Avg test acc: 0.96538, Avg tpr: 0.96841, Avg fpr: 0.04128, total FA: 322

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.26126 | acc=0.2981 | tpr=0.0102 | fpr=0.0766 | 4808.9 samples/s | 18.8 steps/s
Avg test loss: 5.25924, Avg test acc: 0.29630, Avg tpr: 0.01218, Avg fpr: 0.07884, total FA: 615

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.64215 | acc=0.3088 | tpr=0.0238 | fpr=0.0723 | 5081.1 samples/s | 19.8 steps/s
Avg test loss: 5.62695, Avg test acc: 0.30539, Avg tpr: 0.02465, Avg fpr: 0.07717, total FA: 602

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.49083 | acc=0.1260 | tpr=0.6150 | fpr=0.8828 | 4852.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=7.44909 | acc=0.1269 | tpr=0.6055 | fpr=0.8821 | 7107.4 samples/s | 27.8 steps/s
[Step= 150] | Loss=7.45951 | acc=0.1272 | tpr=0.5922 | fpr=0.8814 | 7941.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=7.45309 | acc=0.1269 | tpr=0.5956 | fpr=0.8816 | 7636.2 samples/s | 29.8 steps/s
[Step= 250] | Loss=7.44598 | acc=0.1274 | tpr=0.5983 | fpr=0.8812 | 8311.4 samples/s | 32.5 steps/s
[Step= 300] | Loss=7.43795 | acc=0.1274 | tpr=0.5935 | fpr=0.8811 | 7675.1 samples/s | 30.0 steps/s
[Step= 350] | Loss=7.44499 | acc=0.1273 | tpr=0.5867 | fpr=0.8811 | 7839.2 samples/s | 30.6 steps/s
[Step= 400] | Loss=7.44729 | acc=0.1272 | tpr=0.5810 | fpr=0.8810 | 7873.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=7.45052 | acc=0.1270 | tpr=0.5837 | fpr=0.8813 | 7785.1 samples/s | 30.4 steps/s
[Step= 500] | Loss=7.45237 | acc=0.1270 | tpr=0.5828 | fpr=0.8813 | 7934.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=7.45648 | acc=0.1271 | tpr=0.5822 | fpr=0.8812 | 13607.3 samples/s | 53.2 steps/s
Avg test loss: 7.45804, Avg test acc: 0.12691, Avg tpr: 0.58320, Avg fpr: 0.88138, total FA: 122378

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.70356 | acc=0.1523 | tpr=0.5929 | fpr=0.8556 | 5117.2 samples/s | 20.0 steps/s
[Step= 100] | Loss=6.68444 | acc=0.1531 | tpr=0.5352 | fpr=0.8540 | 6907.6 samples/s | 27.0 steps/s
[Step= 150] | Loss=6.68725 | acc=0.1532 | tpr=0.5418 | fpr=0.8539 | 7698.7 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.68172 | acc=0.1535 | tpr=0.5377 | fpr=0.8535 | 7590.0 samples/s | 29.6 steps/s
[Step= 250] | Loss=6.67155 | acc=0.1537 | tpr=0.5310 | fpr=0.8531 | 8013.1 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.66356 | acc=0.1542 | tpr=0.5244 | fpr=0.8525 | 7756.9 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.66938 | acc=0.1540 | tpr=0.5166 | fpr=0.8526 | 8359.2 samples/s | 32.7 steps/s
[Step= 400] | Loss=6.66713 | acc=0.1540 | tpr=0.5082 | fpr=0.8524 | 7621.9 samples/s | 29.8 steps/s
[Step= 450] | Loss=6.67253 | acc=0.1539 | tpr=0.5068 | fpr=0.8525 | 7702.6 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.67423 | acc=0.1543 | tpr=0.5079 | fpr=0.8521 | 7890.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.67922 | acc=0.1542 | tpr=0.5082 | fpr=0.8522 | 13908.6 samples/s | 54.3 steps/s
Avg test loss: 6.68193, Avg test acc: 0.15411, Avg tpr: 0.50872, Avg fpr: 0.85233, total FA: 118345

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12908 | acc=0.9788 | tpr=0.9381 | fpr=0.0204 | 4963.3 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.13110 | acc=0.9794 | tpr=0.9424 | fpr=0.0199 | 7197.6 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.13667 | acc=0.9785 | tpr=0.9467 | fpr=0.0209 | 7700.4 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.14021 | acc=0.9785 | tpr=0.9475 | fpr=0.0210 | 7958.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.13760 | acc=0.9789 | tpr=0.9485 | fpr=0.0206 | 7622.8 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.13963 | acc=0.9785 | tpr=0.9455 | fpr=0.0209 | 7879.4 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.14006 | acc=0.9784 | tpr=0.9461 | fpr=0.0210 | 7913.5 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.14144 | acc=0.9784 | tpr=0.9464 | fpr=0.0210 | 8092.7 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14419 | acc=0.9780 | tpr=0.9445 | fpr=0.0214 | 7642.9 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.14325 | acc=0.9780 | tpr=0.9449 | fpr=0.0214 | 7781.7 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.14177 | acc=0.9783 | tpr=0.9459 | fpr=0.0211 | 14126.5 samples/s | 55.2 steps/s
Avg test loss: 0.14165, Avg test acc: 0.97833, Avg tpr: 0.94572, Avg fpr: 0.02107, total FA: 2926

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13206 | acc=0.9776 | tpr=0.9602 | fpr=0.0221 | 5032.8 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.13476 | acc=0.9775 | tpr=0.9680 | fpr=0.0223 | 7232.3 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.14138 | acc=0.9766 | tpr=0.9669 | fpr=0.0233 | 7479.1 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.14444 | acc=0.9762 | tpr=0.9650 | fpr=0.0236 | 7907.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14224 | acc=0.9765 | tpr=0.9607 | fpr=0.0232 | 7962.1 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.14490 | acc=0.9761 | tpr=0.9585 | fpr=0.0235 | 7570.2 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.14502 | acc=0.9761 | tpr=0.9587 | fpr=0.0236 | 7857.9 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.14611 | acc=0.9761 | tpr=0.9568 | fpr=0.0235 | 7964.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.14866 | acc=0.9758 | tpr=0.9542 | fpr=0.0238 | 7754.1 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.14776 | acc=0.9759 | tpr=0.9546 | fpr=0.0237 | 7784.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.14634 | acc=0.9762 | tpr=0.9554 | fpr=0.0234 | 14111.6 samples/s | 55.1 steps/s
Avg test loss: 0.14626, Avg test acc: 0.97624, Avg tpr: 0.95523, Avg fpr: 0.02338, total FA: 3246

server round 25/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=97.5] | Loss=0.00234 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.008 | L2-Norm(final)=9.818 | 6621.6 samples/s | 103.5 steps/s
[Step=50050 Epoch=97.6] | Loss=0.00506 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.010 | L2-Norm(final)=9.821 | 4558.0 samples/s | 71.2 steps/s
[Step=50100 Epoch=97.7] | Loss=0.00557 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.009 | L2-Norm(final)=9.825 | 4794.9 samples/s | 74.9 steps/s
[Step=50150 Epoch=97.8] | Loss=0.00559 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.006 | L2-Norm(final)=9.829 | 5022.0 samples/s | 78.5 steps/s
[Step=50200 Epoch=97.9] | Loss=0.00504 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.003 | L2-Norm(final)=9.833 | 5017.6 samples/s | 78.4 steps/s
[Step=50250 Epoch=98.0] | Loss=0.00509 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.000 | L2-Norm(final)=9.837 | 5046.7 samples/s | 78.9 steps/s
[Step=50300 Epoch=98.1] | Loss=0.00498 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.997 | L2-Norm(final)=9.842 | 5115.0 samples/s | 79.9 steps/s
[Step=50350 Epoch=98.2] | Loss=0.00500 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.995 | L2-Norm(final)=9.847 | 5117.7 samples/s | 80.0 steps/s
[Step=50400 Epoch=98.3] | Loss=0.00517 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.992 | L2-Norm(final)=9.852 | 4928.2 samples/s | 77.0 steps/s
[Step=50450 Epoch=98.4] | Loss=0.00509 | Reg=0.00324 | acc=0.9844 | L2-Norm=17.990 | L2-Norm(final)=9.856 | 4906.3 samples/s | 76.7 steps/s
[Step=50500 Epoch=98.5] | Loss=0.00498 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.987 | L2-Norm(final)=9.861 | 6712.0 samples/s | 104.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=98.5] | Loss=0.00042 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.960 | L2-Norm(final)=9.906 | 5966.2 samples/s | 93.2 steps/s
[Step=50550 Epoch=98.6] | Loss=0.00518 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.958 | L2-Norm(final)=9.910 | 4194.0 samples/s | 65.5 steps/s
[Step=50600 Epoch=98.7] | Loss=0.00509 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.957 | L2-Norm(final)=9.914 | 4505.2 samples/s | 70.4 steps/s
[Step=50650 Epoch=98.8] | Loss=0.00547 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.958 | L2-Norm(final)=9.919 | 4457.2 samples/s | 69.6 steps/s
[Step=50700 Epoch=98.9] | Loss=0.00567 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.959 | L2-Norm(final)=9.923 | 4496.9 samples/s | 70.3 steps/s
[Step=50750 Epoch=99.0] | Loss=0.00674 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.961 | L2-Norm(final)=9.927 | 4445.7 samples/s | 69.5 steps/s
[Step=50800 Epoch=99.1] | Loss=0.00700 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.963 | L2-Norm(final)=9.931 | 4422.7 samples/s | 69.1 steps/s
[Step=50850 Epoch=99.2] | Loss=0.00705 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.965 | L2-Norm(final)=9.935 | 4419.6 samples/s | 69.1 steps/s
[Step=50900 Epoch=99.3] | Loss=0.00730 | Reg=0.00323 | acc=0.9688 | L2-Norm=17.967 | L2-Norm(final)=9.939 | 4480.8 samples/s | 70.0 steps/s
[Step=50950 Epoch=99.4] | Loss=0.00741 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.968 | L2-Norm(final)=9.943 | 4489.9 samples/s | 70.2 steps/s
[Step=51000 Epoch=99.5] | Loss=0.00747 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.969 | L2-Norm(final)=9.947 | 5752.9 samples/s | 89.9 steps/s
[Step=51050 Epoch=99.6] | Loss=0.00731 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.971 | L2-Norm(final)=9.951 | 2403.6 samples/s | 37.6 steps/s
[Step=51100 Epoch=99.7] | Loss=0.00720 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.971 | L2-Norm(final)=9.955 | 4461.7 samples/s | 69.7 steps/s
[Step=51150 Epoch=99.8] | Loss=0.00713 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.972 | L2-Norm(final)=9.960 | 4525.8 samples/s | 70.7 steps/s
[Step=51200 Epoch=99.9] | Loss=0.00717 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.972 | L2-Norm(final)=9.963 | 4379.9 samples/s | 68.4 steps/s
[Step=51250 Epoch=100.0] | Loss=0.00720 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.972 | L2-Norm(final)=9.967 | 4540.2 samples/s | 70.9 steps/s
[Step=51300 Epoch=100.1] | Loss=0.00732 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.972 | L2-Norm(final)=9.970 | 4357.1 samples/s | 68.1 steps/s
[Step=51350 Epoch=100.2] | Loss=0.00734 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.972 | L2-Norm(final)=9.973 | 4459.2 samples/s | 69.7 steps/s
[Step=51400 Epoch=100.2] | Loss=0.00739 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.972 | L2-Norm(final)=9.976 | 4499.1 samples/s | 70.3 steps/s
[Step=51450 Epoch=100.3] | Loss=0.00737 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.971 | L2-Norm(final)=9.979 | 4504.3 samples/s | 70.4 steps/s
[Step=51500 Epoch=100.4] | Loss=0.00734 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.971 | L2-Norm(final)=9.982 | 4803.1 samples/s | 75.0 steps/s
[Step=51550 Epoch=100.5] | Loss=0.00736 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.971 | L2-Norm(final)=9.985 | 2619.5 samples/s | 40.9 steps/s
[Step=51600 Epoch=100.6] | Loss=0.00728 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.970 | L2-Norm(final)=9.988 | 4395.6 samples/s | 68.7 steps/s
[Step=51650 Epoch=100.7] | Loss=0.00728 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.969 | L2-Norm(final)=9.991 | 4484.3 samples/s | 70.1 steps/s
[Step=51700 Epoch=100.8] | Loss=0.00727 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.969 | L2-Norm(final)=9.994 | 4395.6 samples/s | 68.7 steps/s
[Step=51750 Epoch=100.9] | Loss=0.00726 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.968 | L2-Norm(final)=9.996 | 4538.7 samples/s | 70.9 steps/s
[Step=51800 Epoch=101.0] | Loss=0.00718 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.967 | L2-Norm(final)=9.999 | 4468.2 samples/s | 69.8 steps/s
[Step=51850 Epoch=101.1] | Loss=0.00713 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.966 | L2-Norm(final)=10.002 | 4511.1 samples/s | 70.5 steps/s
[Step=51900 Epoch=101.2] | Loss=0.00708 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.965 | L2-Norm(final)=10.005 | 4436.3 samples/s | 69.3 steps/s
[Step=51950 Epoch=101.3] | Loss=0.00704 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.964 | L2-Norm(final)=10.007 | 4527.6 samples/s | 70.7 steps/s
[Step=52000 Epoch=101.4] | Loss=0.00702 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.963 | L2-Norm(final)=10.010 | 4417.4 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step52000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=97.8] | Loss=0.00011 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.063 | L2-Norm(final)=9.939 | 6612.9 samples/s | 103.3 steps/s
[Step=50050 Epoch=97.8] | Loss=0.00543 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.061 | L2-Norm(final)=9.945 | 4291.3 samples/s | 67.1 steps/s
[Step=50100 Epoch=97.9] | Loss=0.00500 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.058 | L2-Norm(final)=9.951 | 5012.6 samples/s | 78.3 steps/s
[Step=50150 Epoch=98.0] | Loss=0.00455 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.056 | L2-Norm(final)=9.957 | 5083.7 samples/s | 79.4 steps/s
[Step=50200 Epoch=98.1] | Loss=0.00482 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.053 | L2-Norm(final)=9.962 | 5036.8 samples/s | 78.7 steps/s
[Step=50250 Epoch=98.2] | Loss=0.00454 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.051 | L2-Norm(final)=9.967 | 5027.5 samples/s | 78.6 steps/s
[Step=50300 Epoch=98.3] | Loss=0.00461 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.048 | L2-Norm(final)=9.972 | 5060.0 samples/s | 79.1 steps/s
[Step=50350 Epoch=98.4] | Loss=0.00467 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.045 | L2-Norm(final)=9.978 | 5017.3 samples/s | 78.4 steps/s
[Step=50400 Epoch=98.5] | Loss=0.00466 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.043 | L2-Norm(final)=9.982 | 5102.5 samples/s | 79.7 steps/s
[Step=50450 Epoch=98.6] | Loss=0.00482 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.040 | L2-Norm(final)=9.987 | 4871.5 samples/s | 76.1 steps/s
[Step=50500 Epoch=98.7] | Loss=0.00477 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.037 | L2-Norm(final)=9.992 | 6968.1 samples/s | 108.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=98.7] | Loss=0.00326 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.012 | L2-Norm(final)=10.040 | 6474.7 samples/s | 101.2 steps/s
[Step=50550 Epoch=98.8] | Loss=0.00439 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.010 | L2-Norm(final)=10.044 | 4017.7 samples/s | 62.8 steps/s
[Step=50600 Epoch=98.9] | Loss=0.00698 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.010 | L2-Norm(final)=10.048 | 4468.4 samples/s | 69.8 steps/s
[Step=50650 Epoch=99.0] | Loss=0.00746 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.011 | L2-Norm(final)=10.050 | 4457.1 samples/s | 69.6 steps/s
[Step=50700 Epoch=99.1] | Loss=0.00734 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.014 | L2-Norm(final)=10.052 | 4508.5 samples/s | 70.4 steps/s
[Step=50750 Epoch=99.2] | Loss=0.00765 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.016 | L2-Norm(final)=10.055 | 4496.2 samples/s | 70.3 steps/s
[Step=50800 Epoch=99.3] | Loss=0.00808 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.018 | L2-Norm(final)=10.058 | 4398.0 samples/s | 68.7 steps/s
[Step=50850 Epoch=99.4] | Loss=0.00816 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.020 | L2-Norm(final)=10.060 | 4456.7 samples/s | 69.6 steps/s
[Step=50900 Epoch=99.5] | Loss=0.00790 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.022 | L2-Norm(final)=10.063 | 4477.2 samples/s | 70.0 steps/s
[Step=50950 Epoch=99.6] | Loss=0.00785 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.023 | L2-Norm(final)=10.066 | 4563.0 samples/s | 71.3 steps/s
[Step=51000 Epoch=99.7] | Loss=0.00786 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.025 | L2-Norm(final)=10.069 | 5789.1 samples/s | 90.5 steps/s
[Step=51050 Epoch=99.8] | Loss=0.00755 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.026 | L2-Norm(final)=10.072 | 2385.9 samples/s | 37.3 steps/s
[Step=51100 Epoch=99.9] | Loss=0.00756 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.027 | L2-Norm(final)=10.076 | 4498.4 samples/s | 70.3 steps/s
[Step=51150 Epoch=100.0] | Loss=0.00734 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.027 | L2-Norm(final)=10.079 | 4500.1 samples/s | 70.3 steps/s
[Step=51200 Epoch=100.1] | Loss=0.00716 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.027 | L2-Norm(final)=10.082 | 4374.7 samples/s | 68.4 steps/s
[Step=51250 Epoch=100.2] | Loss=0.00727 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.027 | L2-Norm(final)=10.086 | 4441.8 samples/s | 69.4 steps/s
[Step=51300 Epoch=100.3] | Loss=0.00730 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.028 | L2-Norm(final)=10.089 | 4526.1 samples/s | 70.7 steps/s
[Step=51350 Epoch=100.4] | Loss=0.00733 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.028 | L2-Norm(final)=10.092 | 4474.2 samples/s | 69.9 steps/s
[Step=51400 Epoch=100.5] | Loss=0.00740 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=10.095 | 4464.1 samples/s | 69.8 steps/s
[Step=51450 Epoch=100.6] | Loss=0.00740 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=10.098 | 4511.0 samples/s | 70.5 steps/s
[Step=51500 Epoch=100.7] | Loss=0.00738 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.029 | L2-Norm(final)=10.101 | 4949.2 samples/s | 77.3 steps/s
[Step=51550 Epoch=100.8] | Loss=0.00726 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.029 | L2-Norm(final)=10.104 | 2608.7 samples/s | 40.8 steps/s
[Step=51600 Epoch=100.9] | Loss=0.00717 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=10.107 | 4373.1 samples/s | 68.3 steps/s
[Step=51650 Epoch=101.0] | Loss=0.00707 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=10.110 | 4386.6 samples/s | 68.5 steps/s
[Step=51700 Epoch=101.1] | Loss=0.00699 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.028 | L2-Norm(final)=10.114 | 4486.1 samples/s | 70.1 steps/s
[Step=51750 Epoch=101.2] | Loss=0.00695 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.028 | L2-Norm(final)=10.117 | 4486.7 samples/s | 70.1 steps/s
[Step=51800 Epoch=101.3] | Loss=0.00701 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.027 | L2-Norm(final)=10.120 | 4458.1 samples/s | 69.7 steps/s
[Step=51850 Epoch=101.4] | Loss=0.00700 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.026 | L2-Norm(final)=10.123 | 4499.3 samples/s | 70.3 steps/s
[Step=51900 Epoch=101.5] | Loss=0.00700 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.025 | L2-Norm(final)=10.125 | 4558.5 samples/s | 71.2 steps/s
[Step=51950 Epoch=101.6] | Loss=0.00697 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.024 | L2-Norm(final)=10.128 | 4414.2 samples/s | 69.0 steps/s
[Step=52000 Epoch=101.7] | Loss=0.00691 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.023 | L2-Norm(final)=10.131 | 4490.9 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step52000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=191.6] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.187 | 5966.3 samples/s | 93.2 steps/s
[Step=50050 Epoch=191.8] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.190 | 4296.6 samples/s | 67.1 steps/s
[Step=50100 Epoch=192.0] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.194 | 4677.4 samples/s | 73.1 steps/s
[Step=50150 Epoch=192.2] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=6.197 | 4749.0 samples/s | 74.2 steps/s
[Step=50200 Epoch=192.3] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=6.201 | 4732.6 samples/s | 73.9 steps/s
[Step=50250 Epoch=192.5] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=6.205 | 6608.5 samples/s | 103.3 steps/s
[Step=50300 Epoch=192.7] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=6.209 | 2429.7 samples/s | 38.0 steps/s
[Step=50350 Epoch=192.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.212 | 4683.3 samples/s | 73.2 steps/s
[Step=50400 Epoch=193.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.215 | 4619.5 samples/s | 72.2 steps/s
[Step=50450 Epoch=193.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.261 | L2-Norm(final)=6.218 | 4754.5 samples/s | 74.3 steps/s
[Step=50500 Epoch=193.5] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.261 | L2-Norm(final)=6.222 | 5452.6 samples/s | 85.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=193.5] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.257 | L2-Norm(final)=6.257 | 6573.3 samples/s | 102.7 steps/s
[Step=50550 Epoch=193.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=6.261 | 3649.4 samples/s | 57.0 steps/s
[Step=50600 Epoch=193.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.264 | 4276.7 samples/s | 66.8 steps/s
[Step=50650 Epoch=194.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.230 | L2-Norm(final)=6.267 | 4225.4 samples/s | 66.0 steps/s
[Step=50700 Epoch=194.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=6.270 | 4179.3 samples/s | 65.3 steps/s
[Step=50750 Epoch=194.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.209 | L2-Norm(final)=6.272 | 5608.1 samples/s | 87.6 steps/s
[Step=50800 Epoch=194.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.198 | L2-Norm(final)=6.275 | 2252.2 samples/s | 35.2 steps/s
[Step=50850 Epoch=194.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.187 | L2-Norm(final)=6.277 | 4223.5 samples/s | 66.0 steps/s
[Step=50900 Epoch=195.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.176 | L2-Norm(final)=6.279 | 4258.8 samples/s | 66.5 steps/s
[Step=50950 Epoch=195.2] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=6.281 | 4206.2 samples/s | 65.7 steps/s
[Step=51000 Epoch=195.4] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.153 | L2-Norm(final)=6.282 | 4803.6 samples/s | 75.1 steps/s
[Step=51050 Epoch=195.6] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.141 | L2-Norm(final)=6.284 | 2445.9 samples/s | 38.2 steps/s
[Step=51100 Epoch=195.8] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.130 | L2-Norm(final)=6.286 | 4146.0 samples/s | 64.8 steps/s
[Step=51150 Epoch=196.0] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=6.288 | 4237.7 samples/s | 66.2 steps/s
[Step=51200 Epoch=196.2] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=6.289 | 4227.6 samples/s | 66.1 steps/s
[Step=51250 Epoch=196.4] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.094 | L2-Norm(final)=6.291 | 4284.5 samples/s | 66.9 steps/s
[Step=51300 Epoch=196.6] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.081 | L2-Norm(final)=6.293 | 2652.0 samples/s | 41.4 steps/s
[Step=51350 Epoch=196.8] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=6.294 | 4183.5 samples/s | 65.4 steps/s
[Step=51400 Epoch=196.9] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.057 | L2-Norm(final)=6.296 | 4177.5 samples/s | 65.3 steps/s
[Step=51450 Epoch=197.1] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.044 | L2-Norm(final)=6.297 | 4233.1 samples/s | 66.1 steps/s
[Step=51500 Epoch=197.3] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.031 | L2-Norm(final)=6.299 | 4182.3 samples/s | 65.3 steps/s
[Step=51550 Epoch=197.5] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.018 | L2-Norm(final)=6.301 | 2634.5 samples/s | 41.2 steps/s
[Step=51600 Epoch=197.7] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.005 | L2-Norm(final)=6.302 | 4264.6 samples/s | 66.6 steps/s
[Step=51650 Epoch=197.9] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.992 | L2-Norm(final)=6.304 | 4278.3 samples/s | 66.8 steps/s
[Step=51700 Epoch=198.1] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=6.306 | 4192.7 samples/s | 65.5 steps/s
[Step=51750 Epoch=198.3] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.966 | L2-Norm(final)=6.307 | 4208.3 samples/s | 65.8 steps/s
[Step=51800 Epoch=198.5] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.952 | L2-Norm(final)=6.309 | 6372.6 samples/s | 99.6 steps/s
[Step=51850 Epoch=198.7] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.939 | L2-Norm(final)=6.311 | 2181.2 samples/s | 34.1 steps/s
[Step=51900 Epoch=198.9] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.925 | L2-Norm(final)=6.312 | 4283.1 samples/s | 66.9 steps/s
[Step=51950 Epoch=199.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.911 | L2-Norm(final)=6.314 | 4130.2 samples/s | 64.5 steps/s
[Step=52000 Epoch=199.2] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.897 | L2-Norm(final)=6.316 | 4215.2 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step52000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=192.5] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.194 | L2-Norm(final)=6.679 | 5666.5 samples/s | 88.5 steps/s
[Step=50050 Epoch=192.7] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=6.681 | 4330.3 samples/s | 67.7 steps/s
[Step=50100 Epoch=192.9] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=6.683 | 4786.7 samples/s | 74.8 steps/s
[Step=50150 Epoch=193.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.685 | 4682.0 samples/s | 73.2 steps/s
[Step=50200 Epoch=193.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.688 | 4814.2 samples/s | 75.2 steps/s
[Step=50250 Epoch=193.4] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.691 | 6583.3 samples/s | 102.9 steps/s
[Step=50300 Epoch=193.6] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=6.693 | 2387.4 samples/s | 37.3 steps/s
[Step=50350 Epoch=193.8] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=6.696 | 4751.0 samples/s | 74.2 steps/s
[Step=50400 Epoch=194.0] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=6.699 | 4701.4 samples/s | 73.5 steps/s
[Step=50450 Epoch=194.2] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=6.701 | 4733.5 samples/s | 74.0 steps/s
[Step=50500 Epoch=194.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.189 | L2-Norm(final)=6.704 | 5724.9 samples/s | 89.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=194.4] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.186 | L2-Norm(final)=6.730 | 6463.0 samples/s | 101.0 steps/s
[Step=50550 Epoch=194.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.182 | L2-Norm(final)=6.733 | 3624.8 samples/s | 56.6 steps/s
[Step=50600 Epoch=194.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.175 | L2-Norm(final)=6.735 | 4283.5 samples/s | 66.9 steps/s
[Step=50650 Epoch=195.0] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.168 | L2-Norm(final)=6.738 | 4070.4 samples/s | 63.6 steps/s
[Step=50700 Epoch=195.2] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.160 | L2-Norm(final)=6.740 | 4138.8 samples/s | 64.7 steps/s
[Step=50750 Epoch=195.4] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.153 | L2-Norm(final)=6.742 | 5599.8 samples/s | 87.5 steps/s
[Step=50800 Epoch=195.5] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.145 | L2-Norm(final)=6.744 | 2167.6 samples/s | 33.9 steps/s
[Step=50850 Epoch=195.7] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.137 | L2-Norm(final)=6.746 | 4214.3 samples/s | 65.8 steps/s
[Step=50900 Epoch=195.9] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.129 | L2-Norm(final)=6.747 | 4187.4 samples/s | 65.4 steps/s
[Step=50950 Epoch=196.1] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.121 | L2-Norm(final)=6.749 | 4149.6 samples/s | 64.8 steps/s
[Step=51000 Epoch=196.3] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.113 | L2-Norm(final)=6.750 | 4968.8 samples/s | 77.6 steps/s
[Step=51050 Epoch=196.5] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=6.752 | 2437.3 samples/s | 38.1 steps/s
[Step=51100 Epoch=196.7] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.096 | L2-Norm(final)=6.753 | 4142.3 samples/s | 64.7 steps/s
[Step=51150 Epoch=196.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.087 | L2-Norm(final)=6.754 | 4248.3 samples/s | 66.4 steps/s
[Step=51200 Epoch=197.1] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=6.756 | 4231.2 samples/s | 66.1 steps/s
[Step=51250 Epoch=197.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=6.757 | 4241.5 samples/s | 66.3 steps/s
[Step=51300 Epoch=197.5] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.060 | L2-Norm(final)=6.759 | 2596.6 samples/s | 40.6 steps/s
[Step=51350 Epoch=197.7] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.051 | L2-Norm(final)=6.760 | 4181.9 samples/s | 65.3 steps/s
[Step=51400 Epoch=197.9] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.042 | L2-Norm(final)=6.761 | 4284.1 samples/s | 66.9 steps/s
[Step=51450 Epoch=198.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.032 | L2-Norm(final)=6.763 | 4252.7 samples/s | 66.4 steps/s
[Step=51500 Epoch=198.2] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.023 | L2-Norm(final)=6.764 | 4172.6 samples/s | 65.2 steps/s
[Step=51550 Epoch=198.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.013 | L2-Norm(final)=6.765 | 2665.2 samples/s | 41.6 steps/s
[Step=51600 Epoch=198.6] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.003 | L2-Norm(final)=6.767 | 4173.9 samples/s | 65.2 steps/s
[Step=51650 Epoch=198.8] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.993 | L2-Norm(final)=6.768 | 4204.0 samples/s | 65.7 steps/s
[Step=51700 Epoch=199.0] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=6.770 | 4205.0 samples/s | 65.7 steps/s
[Step=51750 Epoch=199.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.973 | L2-Norm(final)=6.771 | 4237.2 samples/s | 66.2 steps/s
[Step=51800 Epoch=199.4] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.963 | L2-Norm(final)=6.772 | 6991.5 samples/s | 109.2 steps/s
[Step=51850 Epoch=199.6] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.952 | L2-Norm(final)=6.774 | 2148.4 samples/s | 33.6 steps/s
[Step=51900 Epoch=199.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.942 | L2-Norm(final)=6.775 | 4108.5 samples/s | 64.2 steps/s
[Step=51950 Epoch=200.0] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.931 | L2-Norm(final)=6.777 | 4190.4 samples/s | 65.5 steps/s
[Step=52000 Epoch=200.2] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.920 | L2-Norm(final)=6.779 | 4234.1 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08402 | acc=0.9688 | tpr=0.9772 | fpr=0.0496 | 4866.3 samples/s | 19.0 steps/s
Avg test loss: 0.08179, Avg test acc: 0.96859, Avg tpr: 0.97674, Avg fpr: 0.04935, total FA: 385

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07897 | acc=0.9672 | tpr=0.9728 | fpr=0.0451 | 4902.6 samples/s | 19.2 steps/s
Avg test loss: 0.08167, Avg test acc: 0.96658, Avg tpr: 0.97231, Avg fpr: 0.04602, total FA: 359

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.18330 | acc=0.2982 | tpr=0.0128 | fpr=0.0820 | 4763.8 samples/s | 18.6 steps/s
Avg test loss: 5.18003, Avg test acc: 0.29514, Avg tpr: 0.01376, Avg fpr: 0.08601, total FA: 671

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.62801 | acc=0.3109 | tpr=0.0224 | fpr=0.0627 | 5005.5 samples/s | 19.6 steps/s
Avg test loss: 5.61196, Avg test acc: 0.30900, Avg tpr: 0.02396, Avg fpr: 0.06409, total FA: 500

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.40466 | acc=0.1320 | tpr=0.5398 | fpr=0.8753 | 4821.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=7.35702 | acc=0.1323 | tpr=0.5160 | fpr=0.8749 | 7671.7 samples/s | 30.0 steps/s
[Step= 150] | Loss=7.36624 | acc=0.1327 | tpr=0.5086 | fpr=0.8742 | 7698.3 samples/s | 30.1 steps/s
[Step= 200] | Loss=7.35884 | acc=0.1325 | tpr=0.5137 | fpr=0.8744 | 7655.3 samples/s | 29.9 steps/s
[Step= 250] | Loss=7.34719 | acc=0.1331 | tpr=0.5258 | fpr=0.8740 | 8043.9 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.34069 | acc=0.1327 | tpr=0.5280 | fpr=0.8745 | 7904.0 samples/s | 30.9 steps/s
[Step= 350] | Loss=7.34551 | acc=0.1324 | tpr=0.5185 | fpr=0.8746 | 5672.9 samples/s | 22.2 steps/s
[Step= 400] | Loss=7.34673 | acc=0.1326 | tpr=0.5142 | fpr=0.8743 | 7997.4 samples/s | 31.2 steps/s
[Step= 450] | Loss=7.35007 | acc=0.1320 | tpr=0.5127 | fpr=0.8749 | 7632.4 samples/s | 29.8 steps/s
[Step= 500] | Loss=7.35281 | acc=0.1322 | tpr=0.5123 | fpr=0.8746 | 7810.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=7.35685 | acc=0.1325 | tpr=0.5165 | fpr=0.8745 | 14609.1 samples/s | 57.1 steps/s
Avg test loss: 7.35813, Avg test acc: 0.13237, Avg tpr: 0.51783, Avg fpr: 0.87464, total FA: 121442

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.18270 | acc=0.1478 | tpr=0.5664 | fpr=0.8597 | 4954.1 samples/s | 19.4 steps/s
[Step= 100] | Loss=7.15361 | acc=0.1481 | tpr=0.5267 | fpr=0.8590 | 7247.6 samples/s | 28.3 steps/s
[Step= 150] | Loss=7.14692 | acc=0.1486 | tpr=0.5231 | fpr=0.8583 | 7869.2 samples/s | 30.7 steps/s
[Step= 200] | Loss=7.14140 | acc=0.1487 | tpr=0.5191 | fpr=0.8580 | 7533.6 samples/s | 29.4 steps/s
[Step= 250] | Loss=7.13448 | acc=0.1495 | tpr=0.5135 | fpr=0.8571 | 7939.4 samples/s | 31.0 steps/s
[Step= 300] | Loss=7.12719 | acc=0.1501 | tpr=0.5135 | fpr=0.8566 | 7473.2 samples/s | 29.2 steps/s
[Step= 350] | Loss=7.13207 | acc=0.1498 | tpr=0.5059 | fpr=0.8567 | 5936.3 samples/s | 23.2 steps/s
[Step= 400] | Loss=7.12997 | acc=0.1496 | tpr=0.4989 | fpr=0.8567 | 7668.3 samples/s | 30.0 steps/s
[Step= 450] | Loss=7.13490 | acc=0.1495 | tpr=0.4971 | fpr=0.8568 | 7759.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=7.13648 | acc=0.1499 | tpr=0.5004 | fpr=0.8564 | 8397.1 samples/s | 32.8 steps/s
[Step= 550] | Loss=7.14194 | acc=0.1499 | tpr=0.5022 | fpr=0.8565 | 12791.7 samples/s | 50.0 steps/s
Avg test loss: 7.14510, Avg test acc: 0.14971, Avg tpr: 0.50277, Avg fpr: 0.85671, total FA: 118952

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13688 | acc=0.9772 | tpr=0.9425 | fpr=0.0222 | 4915.6 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13856 | acc=0.9780 | tpr=0.9467 | fpr=0.0214 | 7147.0 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.14463 | acc=0.9770 | tpr=0.9496 | fpr=0.0225 | 7646.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.14822 | acc=0.9769 | tpr=0.9497 | fpr=0.0226 | 8170.4 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.14546 | acc=0.9774 | tpr=0.9502 | fpr=0.0221 | 7722.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.14749 | acc=0.9771 | tpr=0.9491 | fpr=0.0224 | 5949.5 samples/s | 23.2 steps/s
[Step= 350] | Loss=0.14786 | acc=0.9770 | tpr=0.9499 | fpr=0.0225 | 7677.6 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.14928 | acc=0.9770 | tpr=0.9502 | fpr=0.0225 | 7521.1 samples/s | 29.4 steps/s
[Step= 450] | Loss=0.15215 | acc=0.9766 | tpr=0.9479 | fpr=0.0229 | 7702.9 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.15125 | acc=0.9767 | tpr=0.9489 | fpr=0.0228 | 8018.2 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.14966 | acc=0.9769 | tpr=0.9491 | fpr=0.0226 | 13680.2 samples/s | 53.4 steps/s
Avg test loss: 0.14954, Avg test acc: 0.97690, Avg tpr: 0.94889, Avg fpr: 0.02259, total FA: 3136

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13232 | acc=0.9779 | tpr=0.9558 | fpr=0.0217 | 5089.7 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.13475 | acc=0.9778 | tpr=0.9638 | fpr=0.0219 | 6937.3 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.14175 | acc=0.9768 | tpr=0.9640 | fpr=0.0230 | 7760.0 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.14486 | acc=0.9765 | tpr=0.9628 | fpr=0.0233 | 7641.2 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.14244 | acc=0.9767 | tpr=0.9581 | fpr=0.0229 | 7804.6 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.14500 | acc=0.9765 | tpr=0.9564 | fpr=0.0232 | 5609.3 samples/s | 21.9 steps/s
[Step= 350] | Loss=0.14519 | acc=0.9764 | tpr=0.9574 | fpr=0.0232 | 7871.0 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.14637 | acc=0.9765 | tpr=0.9551 | fpr=0.0231 | 7664.5 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.14906 | acc=0.9762 | tpr=0.9528 | fpr=0.0234 | 7915.5 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.14826 | acc=0.9763 | tpr=0.9533 | fpr=0.0233 | 7617.1 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.14677 | acc=0.9766 | tpr=0.9538 | fpr=0.0230 | 14346.7 samples/s | 56.0 steps/s
Avg test loss: 0.14667, Avg test acc: 0.97657, Avg tpr: 0.95365, Avg fpr: 0.02301, total FA: 3195

server round 26/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=101.4] | Loss=0.00712 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.691 | L2-Norm(final)=10.088 | 6193.7 samples/s | 96.8 steps/s
[Step=52050 Epoch=101.5] | Loss=0.00495 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.689 | L2-Norm(final)=10.091 | 4588.4 samples/s | 71.7 steps/s
[Step=52100 Epoch=101.6] | Loss=0.00534 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.687 | L2-Norm(final)=10.096 | 4997.9 samples/s | 78.1 steps/s
[Step=52150 Epoch=101.7] | Loss=0.00509 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.685 | L2-Norm(final)=10.102 | 5071.1 samples/s | 79.2 steps/s
[Step=52200 Epoch=101.8] | Loss=0.00557 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.683 | L2-Norm(final)=10.107 | 5036.9 samples/s | 78.7 steps/s
[Step=52250 Epoch=101.9] | Loss=0.00538 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.682 | L2-Norm(final)=10.113 | 5120.5 samples/s | 80.0 steps/s
[Step=52300 Epoch=102.0] | Loss=0.00506 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.680 | L2-Norm(final)=10.118 | 5029.4 samples/s | 78.6 steps/s
[Step=52350 Epoch=102.1] | Loss=0.00499 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.677 | L2-Norm(final)=10.122 | 4973.0 samples/s | 77.7 steps/s
[Step=52400 Epoch=102.2] | Loss=0.00493 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.675 | L2-Norm(final)=10.127 | 4982.3 samples/s | 77.8 steps/s
[Step=52450 Epoch=102.3] | Loss=0.00496 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.672 | L2-Norm(final)=10.132 | 5067.4 samples/s | 79.2 steps/s
[Step=52500 Epoch=102.4] | Loss=0.00495 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.669 | L2-Norm(final)=10.137 | 6770.1 samples/s | 105.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=102.4] | Loss=0.00057 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.645 | L2-Norm(final)=10.185 | 6264.0 samples/s | 97.9 steps/s
[Step=52550 Epoch=102.5] | Loss=0.00445 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.643 | L2-Norm(final)=10.189 | 4014.6 samples/s | 62.7 steps/s
[Step=52600 Epoch=102.6] | Loss=0.00549 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.642 | L2-Norm(final)=10.193 | 4461.4 samples/s | 69.7 steps/s
[Step=52650 Epoch=102.7] | Loss=0.00580 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.642 | L2-Norm(final)=10.197 | 4537.2 samples/s | 70.9 steps/s
[Step=52700 Epoch=102.8] | Loss=0.00584 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.643 | L2-Norm(final)=10.201 | 4385.6 samples/s | 68.5 steps/s
[Step=52750 Epoch=102.9] | Loss=0.00580 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.643 | L2-Norm(final)=10.205 | 4492.8 samples/s | 70.2 steps/s
[Step=52800 Epoch=103.0] | Loss=0.00639 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.644 | L2-Norm(final)=10.209 | 4442.4 samples/s | 69.4 steps/s
[Step=52850 Epoch=103.1] | Loss=0.00660 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.646 | L2-Norm(final)=10.214 | 4456.2 samples/s | 69.6 steps/s
[Step=52900 Epoch=103.2] | Loss=0.00665 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.648 | L2-Norm(final)=10.218 | 4532.0 samples/s | 70.8 steps/s
[Step=52950 Epoch=103.3] | Loss=0.00667 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.650 | L2-Norm(final)=10.223 | 4429.7 samples/s | 69.2 steps/s
[Step=53000 Epoch=103.4] | Loss=0.00678 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.652 | L2-Norm(final)=10.228 | 5801.5 samples/s | 90.6 steps/s
[Step=53050 Epoch=103.5] | Loss=0.00696 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.654 | L2-Norm(final)=10.233 | 2383.7 samples/s | 37.2 steps/s
[Step=53100 Epoch=103.6] | Loss=0.00695 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.656 | L2-Norm(final)=10.238 | 4453.5 samples/s | 69.6 steps/s
[Step=53150 Epoch=103.7] | Loss=0.00703 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.657 | L2-Norm(final)=10.242 | 4410.8 samples/s | 68.9 steps/s
[Step=53200 Epoch=103.8] | Loss=0.00695 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.659 | L2-Norm(final)=10.247 | 4445.9 samples/s | 69.5 steps/s
[Step=53250 Epoch=103.9] | Loss=0.00697 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.661 | L2-Norm(final)=10.251 | 4495.2 samples/s | 70.2 steps/s
[Step=53300 Epoch=104.0] | Loss=0.00699 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.662 | L2-Norm(final)=10.255 | 4470.2 samples/s | 69.8 steps/s
[Step=53350 Epoch=104.1] | Loss=0.00693 | Reg=0.00312 | acc=0.9688 | L2-Norm=17.663 | L2-Norm(final)=10.260 | 4584.6 samples/s | 71.6 steps/s
[Step=53400 Epoch=104.2] | Loss=0.00689 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.664 | L2-Norm(final)=10.264 | 4371.2 samples/s | 68.3 steps/s
[Step=53450 Epoch=104.2] | Loss=0.00687 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.665 | L2-Norm(final)=10.268 | 4481.8 samples/s | 70.0 steps/s
[Step=53500 Epoch=104.3] | Loss=0.00689 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.666 | L2-Norm(final)=10.271 | 4810.2 samples/s | 75.2 steps/s
[Step=53550 Epoch=104.4] | Loss=0.00691 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.666 | L2-Norm(final)=10.275 | 2580.2 samples/s | 40.3 steps/s
[Step=53600 Epoch=104.5] | Loss=0.00684 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.666 | L2-Norm(final)=10.278 | 4600.3 samples/s | 71.9 steps/s
[Step=53650 Epoch=104.6] | Loss=0.00683 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.666 | L2-Norm(final)=10.282 | 4426.5 samples/s | 69.2 steps/s
[Step=53700 Epoch=104.7] | Loss=0.00681 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.667 | L2-Norm(final)=10.285 | 4477.7 samples/s | 70.0 steps/s
[Step=53750 Epoch=104.8] | Loss=0.00691 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.667 | L2-Norm(final)=10.288 | 4444.5 samples/s | 69.4 steps/s
[Step=53800 Epoch=104.9] | Loss=0.00692 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.666 | L2-Norm(final)=10.291 | 4496.2 samples/s | 70.3 steps/s
[Step=53850 Epoch=105.0] | Loss=0.00688 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.666 | L2-Norm(final)=10.294 | 4457.8 samples/s | 69.7 steps/s
[Step=53900 Epoch=105.1] | Loss=0.00689 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.666 | L2-Norm(final)=10.297 | 4458.5 samples/s | 69.7 steps/s
[Step=53950 Epoch=105.2] | Loss=0.00681 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.666 | L2-Norm(final)=10.299 | 4418.4 samples/s | 69.0 steps/s
[Step=54000 Epoch=105.3] | Loss=0.00684 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.665 | L2-Norm(final)=10.302 | 4474.9 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step54000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=101.7] | Loss=0.00066 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.744 | L2-Norm(final)=10.211 | 6191.6 samples/s | 96.7 steps/s
[Step=52050 Epoch=101.8] | Loss=0.00480 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.742 | L2-Norm(final)=10.215 | 4410.1 samples/s | 68.9 steps/s
[Step=52100 Epoch=101.9] | Loss=0.00467 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.741 | L2-Norm(final)=10.221 | 5069.6 samples/s | 79.2 steps/s
[Step=52150 Epoch=102.0] | Loss=0.00450 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.739 | L2-Norm(final)=10.227 | 4873.7 samples/s | 76.2 steps/s
[Step=52200 Epoch=102.0] | Loss=0.00465 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.736 | L2-Norm(final)=10.232 | 5160.2 samples/s | 80.6 steps/s
[Step=52250 Epoch=102.1] | Loss=0.00482 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.734 | L2-Norm(final)=10.237 | 4976.8 samples/s | 77.8 steps/s
[Step=52300 Epoch=102.2] | Loss=0.00478 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.732 | L2-Norm(final)=10.242 | 5170.1 samples/s | 80.8 steps/s
[Step=52350 Epoch=102.3] | Loss=0.00484 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.730 | L2-Norm(final)=10.247 | 4781.1 samples/s | 74.7 steps/s
[Step=52400 Epoch=102.4] | Loss=0.00475 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.728 | L2-Norm(final)=10.251 | 5108.1 samples/s | 79.8 steps/s
[Step=52450 Epoch=102.5] | Loss=0.00467 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.726 | L2-Norm(final)=10.256 | 4979.9 samples/s | 77.8 steps/s
[Step=52500 Epoch=102.6] | Loss=0.00463 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.724 | L2-Norm(final)=10.261 | 6895.4 samples/s | 107.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=102.6] | Loss=0.00179 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.703 | L2-Norm(final)=10.312 | 6085.3 samples/s | 95.1 steps/s
[Step=52550 Epoch=102.7] | Loss=0.00545 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.702 | L2-Norm(final)=10.316 | 4141.1 samples/s | 64.7 steps/s
[Step=52600 Epoch=102.8] | Loss=0.00588 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.702 | L2-Norm(final)=10.320 | 4456.4 samples/s | 69.6 steps/s
[Step=52650 Epoch=102.9] | Loss=0.00612 | Reg=0.00313 | acc=0.9688 | L2-Norm=17.702 | L2-Norm(final)=10.325 | 4468.4 samples/s | 69.8 steps/s
[Step=52700 Epoch=103.0] | Loss=0.00671 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.704 | L2-Norm(final)=10.329 | 4447.9 samples/s | 69.5 steps/s
[Step=52750 Epoch=103.1] | Loss=0.00742 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.706 | L2-Norm(final)=10.333 | 4390.0 samples/s | 68.6 steps/s
[Step=52800 Epoch=103.2] | Loss=0.00748 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.709 | L2-Norm(final)=10.337 | 4467.6 samples/s | 69.8 steps/s
[Step=52850 Epoch=103.3] | Loss=0.00722 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.711 | L2-Norm(final)=10.341 | 4495.5 samples/s | 70.2 steps/s
[Step=52900 Epoch=103.4] | Loss=0.00746 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.714 | L2-Norm(final)=10.345 | 4526.8 samples/s | 70.7 steps/s
[Step=52950 Epoch=103.5] | Loss=0.00760 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.716 | L2-Norm(final)=10.349 | 4418.8 samples/s | 69.0 steps/s
[Step=53000 Epoch=103.6] | Loss=0.00748 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.719 | L2-Norm(final)=10.353 | 5892.7 samples/s | 92.1 steps/s
[Step=53050 Epoch=103.7] | Loss=0.00749 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.721 | L2-Norm(final)=10.357 | 2381.7 samples/s | 37.2 steps/s
[Step=53100 Epoch=103.8] | Loss=0.00738 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.723 | L2-Norm(final)=10.361 | 4519.2 samples/s | 70.6 steps/s
[Step=53150 Epoch=103.9] | Loss=0.00726 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.724 | L2-Norm(final)=10.365 | 4484.8 samples/s | 70.1 steps/s
[Step=53200 Epoch=104.0] | Loss=0.00720 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.725 | L2-Norm(final)=10.369 | 4276.4 samples/s | 66.8 steps/s
[Step=53250 Epoch=104.1] | Loss=0.00722 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.726 | L2-Norm(final)=10.373 | 4460.0 samples/s | 69.7 steps/s
[Step=53300 Epoch=104.2] | Loss=0.00720 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.726 | L2-Norm(final)=10.376 | 4538.2 samples/s | 70.9 steps/s
[Step=53350 Epoch=104.3] | Loss=0.00724 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.727 | L2-Norm(final)=10.380 | 4448.8 samples/s | 69.5 steps/s
[Step=53400 Epoch=104.4] | Loss=0.00728 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.728 | L2-Norm(final)=10.383 | 4462.7 samples/s | 69.7 steps/s
[Step=53450 Epoch=104.5] | Loss=0.00725 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.729 | L2-Norm(final)=10.387 | 4477.1 samples/s | 70.0 steps/s
[Step=53500 Epoch=104.6] | Loss=0.00721 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.730 | L2-Norm(final)=10.390 | 4959.7 samples/s | 77.5 steps/s
[Step=53550 Epoch=104.7] | Loss=0.00726 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.731 | L2-Norm(final)=10.394 | 2555.6 samples/s | 39.9 steps/s
[Step=53600 Epoch=104.8] | Loss=0.00719 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.732 | L2-Norm(final)=10.397 | 4527.7 samples/s | 70.7 steps/s
[Step=53650 Epoch=104.9] | Loss=0.00724 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.733 | L2-Norm(final)=10.401 | 4428.8 samples/s | 69.2 steps/s
[Step=53700 Epoch=105.0] | Loss=0.00727 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.734 | L2-Norm(final)=10.404 | 4472.9 samples/s | 69.9 steps/s
[Step=53750 Epoch=105.1] | Loss=0.00717 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.735 | L2-Norm(final)=10.408 | 4445.3 samples/s | 69.5 steps/s
[Step=53800 Epoch=105.2] | Loss=0.00715 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.737 | L2-Norm(final)=10.411 | 4505.0 samples/s | 70.4 steps/s
[Step=53850 Epoch=105.3] | Loss=0.00714 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.738 | L2-Norm(final)=10.414 | 4497.7 samples/s | 70.3 steps/s
[Step=53900 Epoch=105.4] | Loss=0.00716 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.739 | L2-Norm(final)=10.418 | 4440.7 samples/s | 69.4 steps/s
[Step=53950 Epoch=105.5] | Loss=0.00720 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.740 | L2-Norm(final)=10.421 | 4427.5 samples/s | 69.2 steps/s
[Step=54000 Epoch=105.6] | Loss=0.00716 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.741 | L2-Norm(final)=10.424 | 4490.6 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step54000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=199.2] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.924 | L2-Norm(final)=6.369 | 5865.8 samples/s | 91.7 steps/s
[Step=52050 Epoch=199.4] | Loss=0.00007 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.929 | L2-Norm(final)=6.382 | 4038.2 samples/s | 63.1 steps/s
[Step=52100 Epoch=199.6] | Loss=0.00004 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.938 | L2-Norm(final)=6.394 | 4705.7 samples/s | 73.5 steps/s
[Step=52150 Epoch=199.8] | Loss=0.00005 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.941 | L2-Norm(final)=6.405 | 4873.4 samples/s | 76.1 steps/s
[Step=52200 Epoch=200.0] | Loss=0.00004 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.946 | L2-Norm(final)=6.416 | 4627.0 samples/s | 72.3 steps/s
[Step=52250 Epoch=200.2] | Loss=0.00004 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.948 | L2-Norm(final)=6.425 | 6696.6 samples/s | 104.6 steps/s
[Step=52300 Epoch=200.4] | Loss=0.00003 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.950 | L2-Norm(final)=6.433 | 2414.5 samples/s | 37.7 steps/s
[Step=52350 Epoch=200.6] | Loss=0.00003 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=6.440 | 4720.4 samples/s | 73.8 steps/s
[Step=52400 Epoch=200.8] | Loss=0.00003 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=6.446 | 4580.7 samples/s | 71.6 steps/s
[Step=52450 Epoch=201.0] | Loss=0.00003 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=6.453 | 4746.6 samples/s | 74.2 steps/s
[Step=52500 Epoch=201.2] | Loss=0.00003 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=6.459 | 5515.2 samples/s | 86.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=201.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.949 | L2-Norm(final)=6.519 | 5509.8 samples/s | 86.1 steps/s
[Step=52550 Epoch=201.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.934 | L2-Norm(final)=6.524 | 4133.4 samples/s | 64.6 steps/s
[Step=52600 Epoch=201.5] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.911 | L2-Norm(final)=6.528 | 4352.8 samples/s | 68.0 steps/s
[Step=52650 Epoch=201.7] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.888 | L2-Norm(final)=6.532 | 4068.9 samples/s | 63.6 steps/s
[Step=52700 Epoch=201.9] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.864 | L2-Norm(final)=6.535 | 4270.8 samples/s | 66.7 steps/s
[Step=52750 Epoch=202.1] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.840 | L2-Norm(final)=6.538 | 5650.5 samples/s | 88.3 steps/s
[Step=52800 Epoch=202.3] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.816 | L2-Norm(final)=6.540 | 2292.3 samples/s | 35.8 steps/s
[Step=52850 Epoch=202.5] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.791 | L2-Norm(final)=6.543 | 4171.5 samples/s | 65.2 steps/s
[Step=52900 Epoch=202.7] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.766 | L2-Norm(final)=6.545 | 4211.8 samples/s | 65.8 steps/s
[Step=52950 Epoch=202.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.741 | L2-Norm(final)=6.547 | 4239.8 samples/s | 66.2 steps/s
[Step=53000 Epoch=203.1] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.716 | L2-Norm(final)=6.549 | 4828.0 samples/s | 75.4 steps/s
[Step=53050 Epoch=203.3] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=6.551 | 2428.3 samples/s | 37.9 steps/s
[Step=53100 Epoch=203.5] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=6.553 | 4181.4 samples/s | 65.3 steps/s
[Step=53150 Epoch=203.7] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.639 | L2-Norm(final)=6.555 | 4251.3 samples/s | 66.4 steps/s
[Step=53200 Epoch=203.8] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=6.556 | 4231.7 samples/s | 66.1 steps/s
[Step=53250 Epoch=204.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.587 | L2-Norm(final)=6.558 | 4339.5 samples/s | 67.8 steps/s
[Step=53300 Epoch=204.2] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.561 | L2-Norm(final)=6.561 | 2627.4 samples/s | 41.1 steps/s
[Step=53350 Epoch=204.4] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=6.563 | 4054.2 samples/s | 63.3 steps/s
[Step=53400 Epoch=204.6] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.509 | L2-Norm(final)=6.565 | 4171.4 samples/s | 65.2 steps/s
[Step=53450 Epoch=204.8] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.483 | L2-Norm(final)=6.567 | 4263.4 samples/s | 66.6 steps/s
[Step=53500 Epoch=205.0] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.456 | L2-Norm(final)=6.569 | 4253.3 samples/s | 66.5 steps/s
[Step=53550 Epoch=205.2] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=6.571 | 2608.3 samples/s | 40.8 steps/s
[Step=53600 Epoch=205.4] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.403 | L2-Norm(final)=6.573 | 4217.3 samples/s | 65.9 steps/s
[Step=53650 Epoch=205.6] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.376 | L2-Norm(final)=6.576 | 4265.4 samples/s | 66.6 steps/s
[Step=53700 Epoch=205.8] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.349 | L2-Norm(final)=6.578 | 4252.6 samples/s | 66.4 steps/s
[Step=53750 Epoch=206.0] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=6.581 | 4202.5 samples/s | 65.7 steps/s
[Step=53800 Epoch=206.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.295 | L2-Norm(final)=6.583 | 6205.3 samples/s | 97.0 steps/s
[Step=53850 Epoch=206.3] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.268 | L2-Norm(final)=6.586 | 2196.6 samples/s | 34.3 steps/s
[Step=53900 Epoch=206.5] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.240 | L2-Norm(final)=6.589 | 4220.8 samples/s | 65.9 steps/s
[Step=53950 Epoch=206.7] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.213 | L2-Norm(final)=6.591 | 4194.3 samples/s | 65.5 steps/s
[Step=54000 Epoch=206.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.185 | L2-Norm(final)=6.594 | 4241.8 samples/s | 66.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step54000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=200.2] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.874 | L2-Norm(final)=6.826 | 6413.6 samples/s | 100.2 steps/s
[Step=52050 Epoch=200.4] | Loss=0.00002 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.872 | L2-Norm(final)=6.832 | 4177.5 samples/s | 65.3 steps/s
[Step=52100 Epoch=200.6] | Loss=0.00002 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.874 | L2-Norm(final)=6.842 | 4759.6 samples/s | 74.4 steps/s
[Step=52150 Epoch=200.7] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.875 | L2-Norm(final)=6.851 | 4625.8 samples/s | 72.3 steps/s
[Step=52200 Epoch=200.9] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.876 | L2-Norm(final)=6.860 | 4753.4 samples/s | 74.3 steps/s
[Step=52250 Epoch=201.1] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.877 | L2-Norm(final)=6.868 | 6721.7 samples/s | 105.0 steps/s
[Step=52300 Epoch=201.3] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.877 | L2-Norm(final)=6.876 | 1826.2 samples/s | 28.5 steps/s
[Step=52350 Epoch=201.5] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.878 | L2-Norm(final)=6.884 | 4773.5 samples/s | 74.6 steps/s
[Step=52400 Epoch=201.7] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.878 | L2-Norm(final)=6.891 | 4867.3 samples/s | 76.1 steps/s
[Step=52450 Epoch=201.9] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.878 | L2-Norm(final)=6.898 | 4514.5 samples/s | 70.5 steps/s
[Step=52500 Epoch=202.1] | Loss=0.00002 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.878 | L2-Norm(final)=6.905 | 5621.7 samples/s | 87.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=202.1] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.879 | L2-Norm(final)=6.975 | 5819.5 samples/s | 90.9 steps/s
[Step=52550 Epoch=202.3] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.867 | L2-Norm(final)=6.980 | 4040.0 samples/s | 63.1 steps/s
[Step=52600 Epoch=202.5] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=6.985 | 4189.9 samples/s | 65.5 steps/s
[Step=52650 Epoch=202.7] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.833 | L2-Norm(final)=6.990 | 4131.6 samples/s | 64.6 steps/s
[Step=52700 Epoch=202.9] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.816 | L2-Norm(final)=6.994 | 4200.5 samples/s | 65.6 steps/s
[Step=52750 Epoch=203.1] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.798 | L2-Norm(final)=6.998 | 5835.9 samples/s | 91.2 steps/s
[Step=52800 Epoch=203.2] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.779 | L2-Norm(final)=7.002 | 2241.1 samples/s | 35.0 steps/s
[Step=52850 Epoch=203.4] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=7.006 | 4395.6 samples/s | 68.7 steps/s
[Step=52900 Epoch=203.6] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.742 | L2-Norm(final)=7.009 | 4180.2 samples/s | 65.3 steps/s
[Step=52950 Epoch=203.8] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.722 | L2-Norm(final)=7.012 | 4137.8 samples/s | 64.7 steps/s
[Step=53000 Epoch=204.0] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.703 | L2-Norm(final)=7.015 | 4954.0 samples/s | 77.4 steps/s
[Step=53050 Epoch=204.2] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.683 | L2-Norm(final)=7.018 | 2430.7 samples/s | 38.0 steps/s
[Step=53100 Epoch=204.4] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.663 | L2-Norm(final)=7.020 | 4174.1 samples/s | 65.2 steps/s
[Step=53150 Epoch=204.6] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.643 | L2-Norm(final)=7.023 | 4151.8 samples/s | 64.9 steps/s
[Step=53200 Epoch=204.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.622 | L2-Norm(final)=7.026 | 4388.1 samples/s | 68.6 steps/s
[Step=53250 Epoch=205.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.602 | L2-Norm(final)=7.029 | 4195.7 samples/s | 65.6 steps/s
[Step=53300 Epoch=205.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.581 | L2-Norm(final)=7.032 | 2568.1 samples/s | 40.1 steps/s
[Step=53350 Epoch=205.4] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.560 | L2-Norm(final)=7.035 | 4242.8 samples/s | 66.3 steps/s
[Step=53400 Epoch=205.6] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.539 | L2-Norm(final)=7.038 | 4262.4 samples/s | 66.6 steps/s
[Step=53450 Epoch=205.8] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.518 | L2-Norm(final)=7.041 | 4202.4 samples/s | 65.7 steps/s
[Step=53500 Epoch=205.9] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.496 | L2-Norm(final)=7.044 | 4319.9 samples/s | 67.5 steps/s
[Step=53550 Epoch=206.1] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.474 | L2-Norm(final)=7.047 | 2581.4 samples/s | 40.3 steps/s
[Step=53600 Epoch=206.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.453 | L2-Norm(final)=7.050 | 4244.3 samples/s | 66.3 steps/s
[Step=53650 Epoch=206.5] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.430 | L2-Norm(final)=7.053 | 4170.8 samples/s | 65.2 steps/s
[Step=53700 Epoch=206.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.409 | L2-Norm(final)=7.057 | 4230.5 samples/s | 66.1 steps/s
[Step=53750 Epoch=206.9] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=7.061 | 4222.1 samples/s | 66.0 steps/s
[Step=53800 Epoch=207.1] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.365 | L2-Norm(final)=7.065 | 6929.4 samples/s | 108.3 steps/s
[Step=53850 Epoch=207.3] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.343 | L2-Norm(final)=7.069 | 2098.7 samples/s | 32.8 steps/s
[Step=53900 Epoch=207.5] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.320 | L2-Norm(final)=7.072 | 4227.8 samples/s | 66.1 steps/s
[Step=53950 Epoch=207.7] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.298 | L2-Norm(final)=7.076 | 4211.3 samples/s | 65.8 steps/s
[Step=54000 Epoch=207.9] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.275 | L2-Norm(final)=7.080 | 4243.5 samples/s | 66.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07574 | acc=0.9686 | tpr=0.9759 | fpr=0.0473 | 5002.8 samples/s | 19.5 steps/s
Avg test loss: 0.07467, Avg test acc: 0.96819, Avg tpr: 0.97517, Avg fpr: 0.04717, total FA: 368

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07505 | acc=0.9661 | tpr=0.9743 | fpr=0.0518 | 4935.8 samples/s | 19.3 steps/s
Avg test loss: 0.07890, Avg test acc: 0.96546, Avg tpr: 0.97383, Avg fpr: 0.05294, total FA: 413

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.24224 | acc=0.3028 | tpr=0.0076 | fpr=0.0562 | 4924.3 samples/s | 19.2 steps/s
Avg test loss: 5.24001, Avg test acc: 0.29982, Avg tpr: 0.00857, Avg fpr: 0.05961, total FA: 465

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.48956 | acc=0.3139 | tpr=0.0175 | fpr=0.0424 | 5041.1 samples/s | 19.7 steps/s
Avg test loss: 5.47466, Avg test acc: 0.31092, Avg tpr: 0.01877, Avg fpr: 0.04653, total FA: 363

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.06055 | acc=0.1363 | tpr=0.5398 | fpr=0.8709 | 5112.1 samples/s | 20.0 steps/s
[Step= 100] | Loss=7.00573 | acc=0.1377 | tpr=0.5139 | fpr=0.8693 | 6833.6 samples/s | 26.7 steps/s
[Step= 150] | Loss=7.00815 | acc=0.1377 | tpr=0.5014 | fpr=0.8690 | 7427.1 samples/s | 29.0 steps/s
[Step= 200] | Loss=7.00067 | acc=0.1394 | tpr=0.5104 | fpr=0.8674 | 7959.2 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.99240 | acc=0.1399 | tpr=0.5188 | fpr=0.8670 | 8179.5 samples/s | 32.0 steps/s
[Step= 300] | Loss=6.98109 | acc=0.1399 | tpr=0.5156 | fpr=0.8670 | 7706.8 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.98386 | acc=0.1399 | tpr=0.5085 | fpr=0.8668 | 7843.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.98302 | acc=0.1401 | tpr=0.5060 | fpr=0.8665 | 7871.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.98704 | acc=0.1397 | tpr=0.5073 | fpr=0.8670 | 7808.8 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.98815 | acc=0.1401 | tpr=0.5097 | fpr=0.8665 | 7940.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=6.99283 | acc=0.1401 | tpr=0.5082 | fpr=0.8666 | 13490.7 samples/s | 52.7 steps/s
Avg test loss: 6.99508, Avg test acc: 0.14000, Avg tpr: 0.50951, Avg fpr: 0.86672, total FA: 120342

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.99147 | acc=0.1334 | tpr=0.6150 | fpr=0.8752 | 4845.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.97194 | acc=0.1337 | tpr=0.5693 | fpr=0.8744 | 7095.9 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.97633 | acc=0.1343 | tpr=0.5648 | fpr=0.8736 | 8138.8 samples/s | 31.8 steps/s
[Step= 200] | Loss=6.97316 | acc=0.1344 | tpr=0.5574 | fpr=0.8733 | 7743.2 samples/s | 30.2 steps/s
[Step= 250] | Loss=6.96490 | acc=0.1350 | tpr=0.5563 | fpr=0.8726 | 7741.5 samples/s | 30.2 steps/s
[Step= 300] | Loss=6.95928 | acc=0.1354 | tpr=0.5542 | fpr=0.8722 | 8122.9 samples/s | 31.7 steps/s
[Step= 350] | Loss=6.96200 | acc=0.1353 | tpr=0.5479 | fpr=0.8722 | 7636.1 samples/s | 29.8 steps/s
[Step= 400] | Loss=6.95959 | acc=0.1354 | tpr=0.5410 | fpr=0.8719 | 7595.0 samples/s | 29.7 steps/s
[Step= 450] | Loss=6.96382 | acc=0.1349 | tpr=0.5370 | fpr=0.8724 | 7776.2 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.96698 | acc=0.1354 | tpr=0.5410 | fpr=0.8719 | 8141.4 samples/s | 31.8 steps/s
[Step= 550] | Loss=6.97174 | acc=0.1353 | tpr=0.5404 | fpr=0.8720 | 13690.1 samples/s | 53.5 steps/s
Avg test loss: 6.97382, Avg test acc: 0.13516, Avg tpr: 0.54081, Avg fpr: 0.87221, total FA: 121105

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12508 | acc=0.9782 | tpr=0.9381 | fpr=0.0211 | 5022.1 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.12690 | acc=0.9789 | tpr=0.9424 | fpr=0.0205 | 7065.6 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.13269 | acc=0.9779 | tpr=0.9467 | fpr=0.0216 | 7638.9 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.13617 | acc=0.9778 | tpr=0.9519 | fpr=0.0217 | 7875.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.13362 | acc=0.9781 | tpr=0.9511 | fpr=0.0214 | 7737.9 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.13551 | acc=0.9777 | tpr=0.9484 | fpr=0.0218 | 7841.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.13558 | acc=0.9776 | tpr=0.9499 | fpr=0.0219 | 7778.0 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.13695 | acc=0.9776 | tpr=0.9491 | fpr=0.0219 | 7901.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13942 | acc=0.9772 | tpr=0.9469 | fpr=0.0223 | 7987.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.13869 | acc=0.9772 | tpr=0.9485 | fpr=0.0223 | 7432.8 samples/s | 29.0 steps/s
[Step= 550] | Loss=0.13733 | acc=0.9775 | tpr=0.9483 | fpr=0.0220 | 15019.9 samples/s | 58.7 steps/s
Avg test loss: 0.13717, Avg test acc: 0.97746, Avg tpr: 0.94810, Avg fpr: 0.02201, total FA: 3056

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12817 | acc=0.9780 | tpr=0.9558 | fpr=0.0216 | 5074.5 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.13116 | acc=0.9782 | tpr=0.9659 | fpr=0.0215 | 6830.4 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.13773 | acc=0.9770 | tpr=0.9640 | fpr=0.0228 | 7887.2 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.14102 | acc=0.9768 | tpr=0.9628 | fpr=0.0229 | 7820.2 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.13862 | acc=0.9770 | tpr=0.9607 | fpr=0.0227 | 7672.9 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.14096 | acc=0.9767 | tpr=0.9578 | fpr=0.0230 | 7844.2 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.14127 | acc=0.9766 | tpr=0.9593 | fpr=0.0231 | 7554.2 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.14242 | acc=0.9766 | tpr=0.9562 | fpr=0.0231 | 8119.4 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.14495 | acc=0.9762 | tpr=0.9537 | fpr=0.0234 | 7561.6 samples/s | 29.5 steps/s
[Step= 500] | Loss=0.14432 | acc=0.9763 | tpr=0.9542 | fpr=0.0233 | 7951.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.14285 | acc=0.9766 | tpr=0.9534 | fpr=0.0230 | 14028.9 samples/s | 54.8 steps/s
Avg test loss: 0.14273, Avg test acc: 0.97654, Avg tpr: 0.95325, Avg fpr: 0.02303, total FA: 3198

server round 27/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=105.3] | Loss=0.00497 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.202 | L2-Norm(final)=10.386 | 6404.9 samples/s | 100.1 steps/s
[Step=54050 Epoch=105.4] | Loss=0.00521 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.204 | L2-Norm(final)=10.393 | 4469.6 samples/s | 69.8 steps/s
[Step=54100 Epoch=105.5] | Loss=0.00497 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=10.402 | 5039.9 samples/s | 78.7 steps/s
[Step=54150 Epoch=105.6] | Loss=0.00527 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=10.410 | 5046.7 samples/s | 78.9 steps/s
[Step=54200 Epoch=105.7] | Loss=0.00596 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.206 | L2-Norm(final)=10.418 | 5024.9 samples/s | 78.5 steps/s
[Step=54250 Epoch=105.8] | Loss=0.00583 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.206 | L2-Norm(final)=10.425 | 5054.6 samples/s | 79.0 steps/s
[Step=54300 Epoch=105.9] | Loss=0.00587 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=10.433 | 5062.4 samples/s | 79.1 steps/s
[Step=54350 Epoch=106.0] | Loss=0.00576 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=10.439 | 5079.4 samples/s | 79.4 steps/s
[Step=54400 Epoch=106.1] | Loss=0.00571 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.206 | L2-Norm(final)=10.446 | 4860.4 samples/s | 75.9 steps/s
[Step=54450 Epoch=106.2] | Loss=0.00575 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=10.453 | 5109.8 samples/s | 79.8 steps/s
[Step=54500 Epoch=106.3] | Loss=0.00570 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.206 | L2-Norm(final)=10.460 | 6622.6 samples/s | 103.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=106.3] | Loss=0.00057 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.204 | L2-Norm(final)=10.531 | 6413.8 samples/s | 100.2 steps/s
[Step=54550 Epoch=106.4] | Loss=0.00518 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.205 | L2-Norm(final)=10.536 | 4012.1 samples/s | 62.7 steps/s
[Step=54600 Epoch=106.5] | Loss=0.00629 | Reg=0.00296 | acc=0.9531 | L2-Norm=17.208 | L2-Norm(final)=10.542 | 4459.4 samples/s | 69.7 steps/s
[Step=54650 Epoch=106.6] | Loss=0.00724 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.212 | L2-Norm(final)=10.549 | 4484.9 samples/s | 70.1 steps/s
[Step=54700 Epoch=106.7] | Loss=0.00771 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.217 | L2-Norm(final)=10.555 | 4458.5 samples/s | 69.7 steps/s
[Step=54750 Epoch=106.8] | Loss=0.00804 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.222 | L2-Norm(final)=10.561 | 4516.6 samples/s | 70.6 steps/s
[Step=54800 Epoch=106.9] | Loss=0.00850 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.228 | L2-Norm(final)=10.567 | 4361.8 samples/s | 68.2 steps/s
[Step=54850 Epoch=107.0] | Loss=0.00891 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.233 | L2-Norm(final)=10.573 | 4467.0 samples/s | 69.8 steps/s
[Step=54900 Epoch=107.1] | Loss=0.00899 | Reg=0.00297 | acc=0.9688 | L2-Norm=17.239 | L2-Norm(final)=10.579 | 4482.6 samples/s | 70.0 steps/s
[Step=54950 Epoch=107.2] | Loss=0.00881 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.244 | L2-Norm(final)=10.584 | 4454.1 samples/s | 69.6 steps/s
[Step=55000 Epoch=107.3] | Loss=0.00901 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.249 | L2-Norm(final)=10.589 | 5804.1 samples/s | 90.7 steps/s
[Step=55050 Epoch=107.4] | Loss=0.00914 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=10.594 | 2427.9 samples/s | 37.9 steps/s
[Step=55100 Epoch=107.5] | Loss=0.00900 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.259 | L2-Norm(final)=10.600 | 4395.9 samples/s | 68.7 steps/s
[Step=55150 Epoch=107.6] | Loss=0.00888 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.264 | L2-Norm(final)=10.606 | 4455.9 samples/s | 69.6 steps/s
[Step=55200 Epoch=107.7] | Loss=0.00876 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.268 | L2-Norm(final)=10.611 | 4450.5 samples/s | 69.5 steps/s
[Step=55250 Epoch=107.8] | Loss=0.00887 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.272 | L2-Norm(final)=10.616 | 4414.6 samples/s | 69.0 steps/s
[Step=55300 Epoch=107.9] | Loss=0.00872 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.275 | L2-Norm(final)=10.620 | 4477.9 samples/s | 70.0 steps/s
[Step=55350 Epoch=108.0] | Loss=0.00862 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.278 | L2-Norm(final)=10.625 | 4545.0 samples/s | 71.0 steps/s
[Step=55400 Epoch=108.1] | Loss=0.00851 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.281 | L2-Norm(final)=10.629 | 4430.9 samples/s | 69.2 steps/s
[Step=55450 Epoch=108.1] | Loss=0.00850 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.284 | L2-Norm(final)=10.634 | 4558.3 samples/s | 71.2 steps/s
[Step=55500 Epoch=108.2] | Loss=0.00846 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.286 | L2-Norm(final)=10.639 | 4717.0 samples/s | 73.7 steps/s
[Step=55550 Epoch=108.3] | Loss=0.00829 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.289 | L2-Norm(final)=10.643 | 2610.1 samples/s | 40.8 steps/s
[Step=55600 Epoch=108.4] | Loss=0.00818 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.290 | L2-Norm(final)=10.647 | 4452.5 samples/s | 69.6 steps/s
[Step=55650 Epoch=108.5] | Loss=0.00809 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.292 | L2-Norm(final)=10.652 | 4494.8 samples/s | 70.2 steps/s
[Step=55700 Epoch=108.6] | Loss=0.00796 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.294 | L2-Norm(final)=10.656 | 4418.3 samples/s | 69.0 steps/s
[Step=55750 Epoch=108.7] | Loss=0.00791 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.660 | 4474.3 samples/s | 69.9 steps/s
[Step=55800 Epoch=108.8] | Loss=0.00784 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.296 | L2-Norm(final)=10.664 | 4416.8 samples/s | 69.0 steps/s
[Step=55850 Epoch=108.9] | Loss=0.00773 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.297 | L2-Norm(final)=10.668 | 4542.2 samples/s | 71.0 steps/s
[Step=55900 Epoch=109.0] | Loss=0.00767 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.298 | L2-Norm(final)=10.672 | 4413.9 samples/s | 69.0 steps/s
[Step=55950 Epoch=109.1] | Loss=0.00763 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.298 | L2-Norm(final)=10.676 | 4498.4 samples/s | 70.3 steps/s
[Step=56000 Epoch=109.2] | Loss=0.00766 | Reg=0.00299 | acc=0.9688 | L2-Norm=17.299 | L2-Norm(final)=10.680 | 4425.9 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step56000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=105.6] | Loss=0.00844 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.522 | 5810.8 samples/s | 90.8 steps/s
[Step=54050 Epoch=105.7] | Loss=0.00604 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.294 | L2-Norm(final)=10.528 | 4807.1 samples/s | 75.1 steps/s
[Step=54100 Epoch=105.8] | Loss=0.00638 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.294 | L2-Norm(final)=10.534 | 5084.5 samples/s | 79.4 steps/s
[Step=54150 Epoch=105.9] | Loss=0.00584 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.294 | L2-Norm(final)=10.540 | 5079.1 samples/s | 79.4 steps/s
[Step=54200 Epoch=106.0] | Loss=0.00573 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.547 | 4938.8 samples/s | 77.2 steps/s
[Step=54250 Epoch=106.1] | Loss=0.00565 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.553 | 5068.0 samples/s | 79.2 steps/s
[Step=54300 Epoch=106.2] | Loss=0.00568 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.295 | L2-Norm(final)=10.560 | 4982.8 samples/s | 77.9 steps/s
[Step=54350 Epoch=106.3] | Loss=0.00568 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.566 | 5049.2 samples/s | 78.9 steps/s
[Step=54400 Epoch=106.4] | Loss=0.00569 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.573 | 4964.1 samples/s | 77.6 steps/s
[Step=54450 Epoch=106.4] | Loss=0.00571 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=10.579 | 4957.9 samples/s | 77.5 steps/s
[Step=54500 Epoch=106.5] | Loss=0.00580 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.296 | L2-Norm(final)=10.585 | 6907.5 samples/s | 107.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=106.5] | Loss=0.00579 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.297 | L2-Norm(final)=10.646 | 6718.0 samples/s | 105.0 steps/s
[Step=54550 Epoch=106.6] | Loss=0.00632 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.298 | L2-Norm(final)=10.653 | 3999.8 samples/s | 62.5 steps/s
[Step=54600 Epoch=106.7] | Loss=0.00759 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.303 | L2-Norm(final)=10.658 | 4491.4 samples/s | 70.2 steps/s
[Step=54650 Epoch=106.8] | Loss=0.00821 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.308 | L2-Norm(final)=10.665 | 4464.3 samples/s | 69.8 steps/s
[Step=54700 Epoch=106.9] | Loss=0.00735 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.314 | L2-Norm(final)=10.671 | 4454.6 samples/s | 69.6 steps/s
[Step=54750 Epoch=107.0] | Loss=0.00811 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=10.678 | 4510.0 samples/s | 70.5 steps/s
[Step=54800 Epoch=107.1] | Loss=0.00829 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.325 | L2-Norm(final)=10.684 | 4335.8 samples/s | 67.7 steps/s
[Step=54850 Epoch=107.2] | Loss=0.00843 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.331 | L2-Norm(final)=10.690 | 4479.0 samples/s | 70.0 steps/s
[Step=54900 Epoch=107.3] | Loss=0.00883 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.336 | L2-Norm(final)=10.695 | 4436.7 samples/s | 69.3 steps/s
[Step=54950 Epoch=107.4] | Loss=0.00873 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.341 | L2-Norm(final)=10.700 | 4588.7 samples/s | 71.7 steps/s
[Step=55000 Epoch=107.5] | Loss=0.00876 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.345 | L2-Norm(final)=10.705 | 5733.7 samples/s | 89.6 steps/s
[Step=55050 Epoch=107.6] | Loss=0.00852 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.350 | L2-Norm(final)=10.710 | 2393.8 samples/s | 37.4 steps/s
[Step=55100 Epoch=107.7] | Loss=0.00827 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.353 | L2-Norm(final)=10.716 | 4417.0 samples/s | 69.0 steps/s
[Step=55150 Epoch=107.8] | Loss=0.00818 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.356 | L2-Norm(final)=10.721 | 4550.2 samples/s | 71.1 steps/s
[Step=55200 Epoch=107.9] | Loss=0.00813 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.359 | L2-Norm(final)=10.726 | 4396.3 samples/s | 68.7 steps/s
[Step=55250 Epoch=108.0] | Loss=0.00820 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.362 | L2-Norm(final)=10.731 | 4413.9 samples/s | 69.0 steps/s
[Step=55300 Epoch=108.1] | Loss=0.00815 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.364 | L2-Norm(final)=10.735 | 4519.4 samples/s | 70.6 steps/s
[Step=55350 Epoch=108.2] | Loss=0.00815 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.366 | L2-Norm(final)=10.740 | 4424.4 samples/s | 69.1 steps/s
[Step=55400 Epoch=108.3] | Loss=0.00811 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.369 | L2-Norm(final)=10.744 | 4486.4 samples/s | 70.1 steps/s
[Step=55450 Epoch=108.4] | Loss=0.00803 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.371 | L2-Norm(final)=10.748 | 4522.3 samples/s | 70.7 steps/s
[Step=55500 Epoch=108.5] | Loss=0.00800 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.373 | L2-Norm(final)=10.753 | 4896.5 samples/s | 76.5 steps/s
[Step=55550 Epoch=108.6] | Loss=0.00785 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.374 | L2-Norm(final)=10.757 | 2588.1 samples/s | 40.4 steps/s
[Step=55600 Epoch=108.7] | Loss=0.00772 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.376 | L2-Norm(final)=10.762 | 4364.6 samples/s | 68.2 steps/s
[Step=55650 Epoch=108.8] | Loss=0.00759 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.377 | L2-Norm(final)=10.766 | 4444.8 samples/s | 69.4 steps/s
[Step=55700 Epoch=108.9] | Loss=0.00759 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.378 | L2-Norm(final)=10.770 | 4556.7 samples/s | 71.2 steps/s
[Step=55750 Epoch=109.0] | Loss=0.00762 | Reg=0.00302 | acc=0.9688 | L2-Norm=17.379 | L2-Norm(final)=10.774 | 4395.1 samples/s | 68.7 steps/s
[Step=55800 Epoch=109.1] | Loss=0.00757 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.380 | L2-Norm(final)=10.778 | 4473.8 samples/s | 69.9 steps/s
[Step=55850 Epoch=109.2] | Loss=0.00756 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.381 | L2-Norm(final)=10.782 | 4459.8 samples/s | 69.7 steps/s
[Step=55900 Epoch=109.3] | Loss=0.00755 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.381 | L2-Norm(final)=10.786 | 4503.6 samples/s | 70.4 steps/s
[Step=55950 Epoch=109.4] | Loss=0.00754 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.382 | L2-Norm(final)=10.789 | 4446.9 samples/s | 69.5 steps/s
[Step=56000 Epoch=109.5] | Loss=0.00748 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.383 | L2-Norm(final)=10.793 | 4409.1 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step56000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=206.9] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.230 | L2-Norm(final)=6.684 | 6141.5 samples/s | 96.0 steps/s
[Step=54050 Epoch=207.1] | Loss=0.00009 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.232 | L2-Norm(final)=6.703 | 4233.7 samples/s | 66.2 steps/s
[Step=54100 Epoch=207.3] | Loss=0.00007 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.244 | L2-Norm(final)=6.726 | 4705.1 samples/s | 73.5 steps/s
[Step=54150 Epoch=207.5] | Loss=0.00006 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.252 | L2-Norm(final)=6.744 | 4731.9 samples/s | 73.9 steps/s
[Step=54200 Epoch=207.7] | Loss=0.00010 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.258 | L2-Norm(final)=6.759 | 4704.0 samples/s | 73.5 steps/s
[Step=54250 Epoch=207.9] | Loss=0.00009 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.266 | L2-Norm(final)=6.772 | 6572.0 samples/s | 102.7 steps/s
[Step=54300 Epoch=208.1] | Loss=0.00007 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.272 | L2-Norm(final)=6.782 | 2404.6 samples/s | 37.6 steps/s
[Step=54350 Epoch=208.3] | Loss=0.00007 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.275 | L2-Norm(final)=6.790 | 4632.1 samples/s | 72.4 steps/s
[Step=54400 Epoch=208.4] | Loss=0.00006 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.278 | L2-Norm(final)=6.797 | 4660.8 samples/s | 72.8 steps/s
[Step=54450 Epoch=208.6] | Loss=0.00006 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.280 | L2-Norm(final)=6.803 | 4742.1 samples/s | 74.1 steps/s
[Step=54500 Epoch=208.8] | Loss=0.00005 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.282 | L2-Norm(final)=6.808 | 5474.4 samples/s | 85.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=208.8] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.301 | L2-Norm(final)=6.862 | 5599.3 samples/s | 87.5 steps/s
[Step=54550 Epoch=209.0] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.268 | L2-Norm(final)=6.864 | 4047.2 samples/s | 63.2 steps/s
[Step=54600 Epoch=209.2] | Loss=0.00135 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.264 | L2-Norm(final)=6.867 | 4427.1 samples/s | 69.2 steps/s
[Step=54650 Epoch=209.4] | Loss=0.00183 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.305 | L2-Norm(final)=6.864 | 4073.6 samples/s | 63.6 steps/s
[Step=54700 Epoch=209.6] | Loss=0.00191 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.332 | L2-Norm(final)=6.858 | 4270.8 samples/s | 66.7 steps/s
[Step=54750 Epoch=209.8] | Loss=0.00156 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.348 | L2-Norm(final)=6.855 | 5464.0 samples/s | 85.4 steps/s
[Step=54800 Epoch=210.0] | Loss=0.00137 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.359 | L2-Norm(final)=6.854 | 2264.6 samples/s | 35.4 steps/s
[Step=54850 Epoch=210.2] | Loss=0.00119 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.367 | L2-Norm(final)=6.853 | 4242.9 samples/s | 66.3 steps/s
[Step=54900 Epoch=210.4] | Loss=0.00106 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.372 | L2-Norm(final)=6.853 | 4226.6 samples/s | 66.0 steps/s
[Step=54950 Epoch=210.5] | Loss=0.00094 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.377 | L2-Norm(final)=6.853 | 4283.9 samples/s | 66.9 steps/s
[Step=55000 Epoch=210.7] | Loss=0.00085 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=6.853 | 4771.4 samples/s | 74.6 steps/s
[Step=55050 Epoch=210.9] | Loss=0.00078 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.382 | L2-Norm(final)=6.854 | 2426.7 samples/s | 37.9 steps/s
[Step=55100 Epoch=211.1] | Loss=0.00071 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.384 | L2-Norm(final)=6.854 | 4212.9 samples/s | 65.8 steps/s
[Step=55150 Epoch=211.3] | Loss=0.00066 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.385 | L2-Norm(final)=6.854 | 4213.7 samples/s | 65.8 steps/s
[Step=55200 Epoch=211.5] | Loss=0.00061 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.386 | L2-Norm(final)=6.855 | 4278.7 samples/s | 66.9 steps/s
[Step=55250 Epoch=211.7] | Loss=0.00057 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.855 | 4241.6 samples/s | 66.3 steps/s
[Step=55300 Epoch=211.9] | Loss=0.00054 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.856 | 2618.8 samples/s | 40.9 steps/s
[Step=55350 Epoch=212.1] | Loss=0.00050 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.856 | 4270.8 samples/s | 66.7 steps/s
[Step=55400 Epoch=212.3] | Loss=0.00048 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.856 | 4240.0 samples/s | 66.2 steps/s
[Step=55450 Epoch=212.5] | Loss=0.00045 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.857 | 4103.3 samples/s | 64.1 steps/s
[Step=55500 Epoch=212.7] | Loss=0.00043 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=6.857 | 4230.2 samples/s | 66.1 steps/s
[Step=55550 Epoch=212.8] | Loss=0.00041 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.386 | L2-Norm(final)=6.857 | 2646.8 samples/s | 41.4 steps/s
[Step=55600 Epoch=213.0] | Loss=0.00039 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.386 | L2-Norm(final)=6.858 | 4178.3 samples/s | 65.3 steps/s
[Step=55650 Epoch=213.2] | Loss=0.00037 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.385 | L2-Norm(final)=6.858 | 4230.2 samples/s | 66.1 steps/s
[Step=55700 Epoch=213.4] | Loss=0.00036 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.384 | L2-Norm(final)=6.859 | 4226.6 samples/s | 66.0 steps/s
[Step=55750 Epoch=213.6] | Loss=0.00035 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.383 | L2-Norm(final)=6.859 | 4297.3 samples/s | 67.1 steps/s
[Step=55800 Epoch=213.8] | Loss=0.00033 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.382 | L2-Norm(final)=6.859 | 6169.6 samples/s | 96.4 steps/s
[Step=55850 Epoch=214.0] | Loss=0.00032 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.381 | L2-Norm(final)=6.860 | 2205.8 samples/s | 34.5 steps/s
[Step=55900 Epoch=214.2] | Loss=0.00031 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=6.860 | 4114.3 samples/s | 64.3 steps/s
[Step=55950 Epoch=214.4] | Loss=0.00030 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.379 | L2-Norm(final)=6.860 | 4225.8 samples/s | 66.0 steps/s
[Step=56000 Epoch=214.6] | Loss=0.00029 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.378 | L2-Norm(final)=6.861 | 4249.1 samples/s | 66.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step56000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=207.9] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=7.199 | 6077.5 samples/s | 95.0 steps/s
[Step=54050 Epoch=208.1] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.176 | L2-Norm(final)=7.230 | 4204.5 samples/s | 65.7 steps/s
[Step=54100 Epoch=208.3] | Loss=0.00008 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.188 | L2-Norm(final)=7.258 | 4765.3 samples/s | 74.5 steps/s
[Step=54150 Epoch=208.4] | Loss=0.00007 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.199 | L2-Norm(final)=7.279 | 4604.4 samples/s | 71.9 steps/s
[Step=54200 Epoch=208.6] | Loss=0.00006 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.206 | L2-Norm(final)=7.295 | 4775.6 samples/s | 74.6 steps/s
[Step=54250 Epoch=208.8] | Loss=0.00005 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.211 | L2-Norm(final)=7.309 | 6651.7 samples/s | 103.9 steps/s
[Step=54300 Epoch=209.0] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.215 | L2-Norm(final)=7.320 | 2412.9 samples/s | 37.7 steps/s
[Step=54350 Epoch=209.2] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.217 | L2-Norm(final)=7.330 | 4749.0 samples/s | 74.2 steps/s
[Step=54400 Epoch=209.4] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.219 | L2-Norm(final)=7.339 | 4707.0 samples/s | 73.5 steps/s
[Step=54450 Epoch=209.6] | Loss=0.00003 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.220 | L2-Norm(final)=7.347 | 4726.1 samples/s | 73.8 steps/s
[Step=54500 Epoch=209.8] | Loss=0.00003 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.221 | L2-Norm(final)=7.354 | 5687.0 samples/s | 88.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=209.8] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.228 | L2-Norm(final)=7.429 | 6356.9 samples/s | 99.3 steps/s
[Step=54550 Epoch=210.0] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.203 | L2-Norm(final)=7.433 | 3737.7 samples/s | 58.4 steps/s
[Step=54600 Epoch=210.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.167 | L2-Norm(final)=7.437 | 4275.2 samples/s | 66.8 steps/s
[Step=54650 Epoch=210.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=7.439 | 4160.2 samples/s | 65.0 steps/s
[Step=54700 Epoch=210.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.091 | L2-Norm(final)=7.442 | 4262.8 samples/s | 66.6 steps/s
[Step=54750 Epoch=210.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=7.445 | 5796.3 samples/s | 90.6 steps/s
[Step=54800 Epoch=210.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.018 | L2-Norm(final)=7.448 | 2258.9 samples/s | 35.3 steps/s
[Step=54850 Epoch=211.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.981 | L2-Norm(final)=7.451 | 4210.7 samples/s | 65.8 steps/s
[Step=54900 Epoch=211.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=7.453 | 4171.8 samples/s | 65.2 steps/s
[Step=54950 Epoch=211.5] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.905 | L2-Norm(final)=7.455 | 4233.7 samples/s | 66.2 steps/s
[Step=55000 Epoch=211.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.867 | L2-Norm(final)=7.457 | 5004.3 samples/s | 78.2 steps/s
[Step=55050 Epoch=211.9] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.829 | L2-Norm(final)=7.459 | 2427.3 samples/s | 37.9 steps/s
[Step=55100 Epoch=212.1] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.790 | L2-Norm(final)=7.461 | 4173.2 samples/s | 65.2 steps/s
[Step=55150 Epoch=212.3] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.751 | L2-Norm(final)=7.463 | 4219.4 samples/s | 65.9 steps/s
[Step=55200 Epoch=212.5] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=7.465 | 4253.0 samples/s | 66.5 steps/s
[Step=55250 Epoch=212.7] | Loss=0.00012 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.676 | L2-Norm(final)=7.468 | 4245.8 samples/s | 66.3 steps/s
[Step=55300 Epoch=212.9] | Loss=0.00020 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.652 | L2-Norm(final)=7.469 | 2581.8 samples/s | 40.3 steps/s
[Step=55350 Epoch=213.1] | Loss=0.00046 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.633 | L2-Norm(final)=7.471 | 4234.0 samples/s | 66.2 steps/s
[Step=55400 Epoch=213.3] | Loss=0.00057 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.619 | L2-Norm(final)=7.472 | 4351.9 samples/s | 68.0 steps/s
[Step=55450 Epoch=213.4] | Loss=0.00057 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.607 | L2-Norm(final)=7.473 | 4133.4 samples/s | 64.6 steps/s
[Step=55500 Epoch=213.6] | Loss=0.00057 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.597 | L2-Norm(final)=7.474 | 4248.9 samples/s | 66.4 steps/s
[Step=55550 Epoch=213.8] | Loss=0.00054 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.588 | L2-Norm(final)=7.475 | 2646.3 samples/s | 41.3 steps/s
[Step=55600 Epoch=214.0] | Loss=0.00052 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.580 | L2-Norm(final)=7.477 | 4194.8 samples/s | 65.5 steps/s
[Step=55650 Epoch=214.2] | Loss=0.00050 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.572 | L2-Norm(final)=7.478 | 4118.9 samples/s | 64.4 steps/s
[Step=55700 Epoch=214.4] | Loss=0.00048 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.565 | L2-Norm(final)=7.480 | 4283.1 samples/s | 66.9 steps/s
[Step=55750 Epoch=214.6] | Loss=0.00046 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.559 | L2-Norm(final)=7.481 | 4193.0 samples/s | 65.5 steps/s
[Step=55800 Epoch=214.8] | Loss=0.00045 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.552 | L2-Norm(final)=7.482 | 6876.8 samples/s | 107.4 steps/s
[Step=55850 Epoch=215.0] | Loss=0.00043 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.547 | L2-Norm(final)=7.483 | 2077.4 samples/s | 32.5 steps/s
[Step=55900 Epoch=215.2] | Loss=0.00041 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.541 | L2-Norm(final)=7.485 | 4148.4 samples/s | 64.8 steps/s
[Step=55950 Epoch=215.4] | Loss=0.00040 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.536 | L2-Norm(final)=7.486 | 4148.0 samples/s | 64.8 steps/s
[Step=56000 Epoch=215.6] | Loss=0.00039 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.531 | L2-Norm(final)=7.487 | 4062.3 samples/s | 63.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08072 | acc=0.9655 | tpr=0.9774 | fpr=0.0602 | 4909.2 samples/s | 19.2 steps/s
Avg test loss: 0.07917, Avg test acc: 0.96610, Avg tpr: 0.97750, Avg fpr: 0.05897, total FA: 460

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07443 | acc=0.9672 | tpr=0.9750 | fpr=0.0498 | 4926.7 samples/s | 19.2 steps/s
Avg test loss: 0.07671, Avg test acc: 0.96666, Avg tpr: 0.97453, Avg fpr: 0.05063, total FA: 395

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.29906 | acc=0.3088 | tpr=0.0038 | fpr=0.0287 | 5042.4 samples/s | 19.7 steps/s
Avg test loss: 5.30681, Avg test acc: 0.30559, Avg tpr: 0.00495, Avg fpr: 0.03320, total FA: 259

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.04755 | acc=0.3110 | tpr=0.0094 | fpr=0.0339 | 5101.3 samples/s | 19.9 steps/s
Avg test loss: 5.04184, Avg test acc: 0.30800, Avg tpr: 0.01043, Avg fpr: 0.03756, total FA: 293

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.71851 | acc=0.1308 | tpr=0.5487 | fpr=0.8767 | 4980.9 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.66697 | acc=0.1309 | tpr=0.5330 | fpr=0.8766 | 6989.6 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.67186 | acc=0.1316 | tpr=0.5274 | fpr=0.8757 | 7767.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.66723 | acc=0.1318 | tpr=0.5377 | fpr=0.8756 | 7725.9 samples/s | 30.2 steps/s
[Step= 250] | Loss=6.65866 | acc=0.1318 | tpr=0.5476 | fpr=0.8757 | 7787.0 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.65070 | acc=0.1317 | tpr=0.5418 | fpr=0.8758 | 7850.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.65737 | acc=0.1316 | tpr=0.5329 | fpr=0.8757 | 7972.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=6.65776 | acc=0.1319 | tpr=0.5284 | fpr=0.8753 | 7629.1 samples/s | 29.8 steps/s
[Step= 450] | Loss=6.66046 | acc=0.1317 | tpr=0.5273 | fpr=0.8755 | 7883.2 samples/s | 30.8 steps/s
[Step= 500] | Loss=6.66060 | acc=0.1318 | tpr=0.5247 | fpr=0.8753 | 7720.0 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.66224 | acc=0.1318 | tpr=0.5249 | fpr=0.8753 | 14225.1 samples/s | 55.6 steps/s
Avg test loss: 6.66384, Avg test acc: 0.13169, Avg tpr: 0.52615, Avg fpr: 0.87548, total FA: 121559

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.92976 | acc=0.1261 | tpr=0.6372 | fpr=0.8831 | 4984.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.90690 | acc=0.1260 | tpr=0.5928 | fpr=0.8827 | 7008.9 samples/s | 27.4 steps/s
[Step= 150] | Loss=6.90650 | acc=0.1270 | tpr=0.5893 | fpr=0.8815 | 7705.6 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.90305 | acc=0.1273 | tpr=0.5836 | fpr=0.8810 | 7995.3 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.89241 | acc=0.1278 | tpr=0.5843 | fpr=0.8805 | 7506.1 samples/s | 29.3 steps/s
[Step= 300] | Loss=6.88577 | acc=0.1282 | tpr=0.5804 | fpr=0.8801 | 7930.5 samples/s | 31.0 steps/s
[Step= 350] | Loss=6.88878 | acc=0.1279 | tpr=0.5729 | fpr=0.8801 | 8151.0 samples/s | 31.8 steps/s
[Step= 400] | Loss=6.88701 | acc=0.1279 | tpr=0.5656 | fpr=0.8800 | 7758.7 samples/s | 30.3 steps/s
[Step= 450] | Loss=6.89324 | acc=0.1277 | tpr=0.5604 | fpr=0.8802 | 7642.8 samples/s | 29.9 steps/s
[Step= 500] | Loss=6.89625 | acc=0.1284 | tpr=0.5634 | fpr=0.8794 | 7756.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.90253 | acc=0.1282 | tpr=0.5639 | fpr=0.8798 | 14460.6 samples/s | 56.5 steps/s
Avg test loss: 6.90463, Avg test acc: 0.12800, Avg tpr: 0.56498, Avg fpr: 0.87994, total FA: 122178

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12132 | acc=0.9784 | tpr=0.9336 | fpr=0.0208 | 4845.5 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.12488 | acc=0.9786 | tpr=0.9488 | fpr=0.0209 | 7369.8 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.12967 | acc=0.9776 | tpr=0.9510 | fpr=0.0219 | 7741.6 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.13248 | acc=0.9777 | tpr=0.9519 | fpr=0.0218 | 7859.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.13079 | acc=0.9779 | tpr=0.9520 | fpr=0.0216 | 7619.0 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.13357 | acc=0.9774 | tpr=0.9491 | fpr=0.0221 | 7945.5 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.13395 | acc=0.9773 | tpr=0.9499 | fpr=0.0222 | 7775.8 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.13516 | acc=0.9773 | tpr=0.9497 | fpr=0.0222 | 8093.6 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.13741 | acc=0.9770 | tpr=0.9494 | fpr=0.0224 | 7922.0 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.13696 | acc=0.9770 | tpr=0.9502 | fpr=0.0225 | 7767.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.13592 | acc=0.9772 | tpr=0.9515 | fpr=0.0223 | 13275.0 samples/s | 51.9 steps/s
Avg test loss: 0.13580, Avg test acc: 0.97720, Avg tpr: 0.95087, Avg fpr: 0.02232, total FA: 3099

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10087 | acc=0.9785 | tpr=0.9513 | fpr=0.0210 | 5104.7 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.10151 | acc=0.9778 | tpr=0.9531 | fpr=0.0217 | 6762.5 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.10692 | acc=0.9767 | tpr=0.9568 | fpr=0.0229 | 7925.4 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10905 | acc=0.9767 | tpr=0.9596 | fpr=0.0229 | 7928.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.10701 | acc=0.9771 | tpr=0.9572 | fpr=0.0226 | 7686.0 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.10902 | acc=0.9765 | tpr=0.9542 | fpr=0.0230 | 7602.3 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.10913 | acc=0.9765 | tpr=0.9555 | fpr=0.0231 | 7782.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.11006 | acc=0.9764 | tpr=0.9524 | fpr=0.0231 | 8055.2 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.11201 | acc=0.9761 | tpr=0.9513 | fpr=0.0235 | 7611.2 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.11152 | acc=0.9762 | tpr=0.9524 | fpr=0.0234 | 7730.5 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.11051 | acc=0.9764 | tpr=0.9522 | fpr=0.0232 | 14756.9 samples/s | 57.6 steps/s
Avg test loss: 0.11033, Avg test acc: 0.97640, Avg tpr: 0.95206, Avg fpr: 0.02315, total FA: 3215

server round 28/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=109.2] | Loss=0.01090 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.082 | L2-Norm(final)=10.792 | 6358.8 samples/s | 99.4 steps/s
[Step=56050 Epoch=109.3] | Loss=0.01326 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.089 | L2-Norm(final)=10.795 | 4542.7 samples/s | 71.0 steps/s
[Step=56100 Epoch=109.4] | Loss=0.01133 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.096 | L2-Norm(final)=10.806 | 5014.4 samples/s | 78.4 steps/s
[Step=56150 Epoch=109.5] | Loss=0.01107 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.101 | L2-Norm(final)=10.818 | 4933.0 samples/s | 77.1 steps/s
[Step=56200 Epoch=109.6] | Loss=0.01080 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.106 | L2-Norm(final)=10.828 | 5024.9 samples/s | 78.5 steps/s
[Step=56250 Epoch=109.7] | Loss=0.00991 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.110 | L2-Norm(final)=10.839 | 5201.9 samples/s | 81.3 steps/s
[Step=56300 Epoch=109.8] | Loss=0.00951 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.114 | L2-Norm(final)=10.850 | 4922.5 samples/s | 76.9 steps/s
[Step=56350 Epoch=109.9] | Loss=0.00968 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.118 | L2-Norm(final)=10.861 | 5090.3 samples/s | 79.5 steps/s
[Step=56400 Epoch=110.0] | Loss=0.00949 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.122 | L2-Norm(final)=10.871 | 5102.0 samples/s | 79.7 steps/s
[Step=56450 Epoch=110.1] | Loss=0.00946 | Reg=0.00293 | acc=0.9688 | L2-Norm=17.126 | L2-Norm(final)=10.881 | 4951.1 samples/s | 77.4 steps/s
[Step=56500 Epoch=110.2] | Loss=0.00928 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.130 | L2-Norm(final)=10.892 | 6530.4 samples/s | 102.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=110.2] | Loss=0.01544 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.168 | L2-Norm(final)=10.994 | 6260.0 samples/s | 97.8 steps/s
[Step=56550 Epoch=110.3] | Loss=0.00725 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.172 | L2-Norm(final)=11.002 | 4138.4 samples/s | 64.7 steps/s
[Step=56600 Epoch=110.4] | Loss=0.00754 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.177 | L2-Norm(final)=11.011 | 4469.0 samples/s | 69.8 steps/s
[Step=56650 Epoch=110.5] | Loss=0.00773 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.182 | L2-Norm(final)=11.017 | 4491.3 samples/s | 70.2 steps/s
[Step=56700 Epoch=110.6] | Loss=0.00844 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.187 | L2-Norm(final)=11.023 | 4513.8 samples/s | 70.5 steps/s
[Step=56750 Epoch=110.7] | Loss=0.00921 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.192 | L2-Norm(final)=11.028 | 4394.1 samples/s | 68.7 steps/s
[Step=56800 Epoch=110.8] | Loss=0.00964 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.198 | L2-Norm(final)=11.032 | 4515.7 samples/s | 70.6 steps/s
[Step=56850 Epoch=110.9] | Loss=0.00978 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.203 | L2-Norm(final)=11.037 | 4457.1 samples/s | 69.6 steps/s
[Step=56900 Epoch=111.0] | Loss=0.00969 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.209 | L2-Norm(final)=11.042 | 4482.8 samples/s | 70.0 steps/s
[Step=56950 Epoch=111.1] | Loss=0.00966 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.213 | L2-Norm(final)=11.047 | 4413.8 samples/s | 69.0 steps/s
[Step=57000 Epoch=111.2] | Loss=0.00966 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.217 | L2-Norm(final)=11.051 | 5776.2 samples/s | 90.3 steps/s
[Step=57050 Epoch=111.3] | Loss=0.00955 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.221 | L2-Norm(final)=11.056 | 2387.7 samples/s | 37.3 steps/s
[Step=57100 Epoch=111.4] | Loss=0.00944 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.224 | L2-Norm(final)=11.060 | 4471.5 samples/s | 69.9 steps/s
[Step=57150 Epoch=111.5] | Loss=0.00922 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.227 | L2-Norm(final)=11.065 | 4525.0 samples/s | 70.7 steps/s
[Step=57200 Epoch=111.6] | Loss=0.00909 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.229 | L2-Norm(final)=11.069 | 4379.7 samples/s | 68.4 steps/s
[Step=57250 Epoch=111.7] | Loss=0.00898 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.232 | L2-Norm(final)=11.073 | 4452.8 samples/s | 69.6 steps/s
[Step=57300 Epoch=111.8] | Loss=0.00884 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.234 | L2-Norm(final)=11.077 | 4382.0 samples/s | 68.5 steps/s
[Step=57350 Epoch=111.9] | Loss=0.00879 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.235 | L2-Norm(final)=11.080 | 4465.0 samples/s | 69.8 steps/s
[Step=57400 Epoch=112.0] | Loss=0.00873 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.237 | L2-Norm(final)=11.084 | 4499.8 samples/s | 70.3 steps/s
[Step=57450 Epoch=112.0] | Loss=0.00864 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.239 | L2-Norm(final)=11.088 | 4500.7 samples/s | 70.3 steps/s
[Step=57500 Epoch=112.1] | Loss=0.00872 | Reg=0.00297 | acc=0.9688 | L2-Norm=17.240 | L2-Norm(final)=11.092 | 4771.9 samples/s | 74.6 steps/s
[Step=57550 Epoch=112.2] | Loss=0.00865 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.242 | L2-Norm(final)=11.095 | 2635.4 samples/s | 41.2 steps/s
[Step=57600 Epoch=112.3] | Loss=0.00854 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.243 | L2-Norm(final)=11.099 | 4402.2 samples/s | 68.8 steps/s
[Step=57650 Epoch=112.4] | Loss=0.00843 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.245 | L2-Norm(final)=11.103 | 4430.4 samples/s | 69.2 steps/s
[Step=57700 Epoch=112.5] | Loss=0.00836 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.246 | L2-Norm(final)=11.107 | 4439.0 samples/s | 69.4 steps/s
[Step=57750 Epoch=112.6] | Loss=0.00826 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.247 | L2-Norm(final)=11.110 | 4424.4 samples/s | 69.1 steps/s
[Step=57800 Epoch=112.7] | Loss=0.00820 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.247 | L2-Norm(final)=11.114 | 4486.0 samples/s | 70.1 steps/s
[Step=57850 Epoch=112.8] | Loss=0.00817 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.248 | L2-Norm(final)=11.117 | 4478.6 samples/s | 70.0 steps/s
[Step=57900 Epoch=112.9] | Loss=0.00811 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=11.121 | 4470.6 samples/s | 69.9 steps/s
[Step=57950 Epoch=113.0] | Loss=0.00806 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=11.124 | 4421.1 samples/s | 69.1 steps/s
[Step=58000 Epoch=113.1] | Loss=0.00804 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.250 | L2-Norm(final)=11.127 | 4459.0 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step58000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=109.5] | Loss=0.01018 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.166 | L2-Norm(final)=10.898 | 6853.1 samples/s | 107.1 steps/s
[Step=56050 Epoch=109.6] | Loss=0.01064 | Reg=0.00295 | acc=0.9688 | L2-Norm=17.172 | L2-Norm(final)=10.907 | 4325.8 samples/s | 67.6 steps/s
[Step=56100 Epoch=109.7] | Loss=0.00985 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=10.917 | 5040.2 samples/s | 78.8 steps/s
[Step=56150 Epoch=109.8] | Loss=0.00988 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.184 | L2-Norm(final)=10.929 | 5085.6 samples/s | 79.5 steps/s
[Step=56200 Epoch=109.9] | Loss=0.00960 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.189 | L2-Norm(final)=10.941 | 4920.0 samples/s | 76.9 steps/s
[Step=56250 Epoch=110.0] | Loss=0.00944 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.194 | L2-Norm(final)=10.953 | 5144.3 samples/s | 80.4 steps/s
[Step=56300 Epoch=110.1] | Loss=0.00940 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.199 | L2-Norm(final)=10.964 | 5125.1 samples/s | 80.1 steps/s
[Step=56350 Epoch=110.2] | Loss=0.00912 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.204 | L2-Norm(final)=10.975 | 4865.6 samples/s | 76.0 steps/s
[Step=56400 Epoch=110.3] | Loss=0.00895 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.208 | L2-Norm(final)=10.985 | 5053.1 samples/s | 79.0 steps/s
[Step=56450 Epoch=110.4] | Loss=0.00913 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.212 | L2-Norm(final)=10.995 | 4888.2 samples/s | 76.4 steps/s
[Step=56500 Epoch=110.5] | Loss=0.00898 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.217 | L2-Norm(final)=11.006 | 6923.7 samples/s | 108.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=110.5] | Loss=0.01680 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.262 | L2-Norm(final)=11.112 | 6348.6 samples/s | 99.2 steps/s
[Step=56550 Epoch=110.6] | Loss=0.00662 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.267 | L2-Norm(final)=11.121 | 4039.7 samples/s | 63.1 steps/s
[Step=56600 Epoch=110.7] | Loss=0.00703 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.272 | L2-Norm(final)=11.129 | 4461.2 samples/s | 69.7 steps/s
[Step=56650 Epoch=110.7] | Loss=0.00773 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.276 | L2-Norm(final)=11.136 | 4502.3 samples/s | 70.3 steps/s
[Step=56700 Epoch=110.8] | Loss=0.00831 | Reg=0.00299 | acc=0.9688 | L2-Norm=17.280 | L2-Norm(final)=11.142 | 4445.3 samples/s | 69.5 steps/s
[Step=56750 Epoch=110.9] | Loss=0.00828 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.285 | L2-Norm(final)=11.148 | 4501.3 samples/s | 70.3 steps/s
[Step=56800 Epoch=111.0] | Loss=0.00820 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.289 | L2-Norm(final)=11.154 | 4489.1 samples/s | 70.1 steps/s
[Step=56850 Epoch=111.1] | Loss=0.00847 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.293 | L2-Norm(final)=11.159 | 4344.8 samples/s | 67.9 steps/s
[Step=56900 Epoch=111.2] | Loss=0.00854 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.297 | L2-Norm(final)=11.164 | 4451.1 samples/s | 69.5 steps/s
[Step=56950 Epoch=111.3] | Loss=0.00852 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.301 | L2-Norm(final)=11.169 | 4516.0 samples/s | 70.6 steps/s
[Step=57000 Epoch=111.4] | Loss=0.00880 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.304 | L2-Norm(final)=11.174 | 5866.6 samples/s | 91.7 steps/s
[Step=57050 Epoch=111.5] | Loss=0.00856 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.308 | L2-Norm(final)=11.179 | 2366.0 samples/s | 37.0 steps/s
[Step=57100 Epoch=111.6] | Loss=0.00847 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.311 | L2-Norm(final)=11.184 | 4479.6 samples/s | 70.0 steps/s
[Step=57150 Epoch=111.7] | Loss=0.00837 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.313 | L2-Norm(final)=11.189 | 4485.9 samples/s | 70.1 steps/s
[Step=57200 Epoch=111.8] | Loss=0.00834 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.315 | L2-Norm(final)=11.193 | 4412.4 samples/s | 68.9 steps/s
[Step=57250 Epoch=111.9] | Loss=0.00833 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.317 | L2-Norm(final)=11.197 | 4389.4 samples/s | 68.6 steps/s
[Step=57300 Epoch=112.0] | Loss=0.00828 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=11.200 | 4494.4 samples/s | 70.2 steps/s
[Step=57350 Epoch=112.1] | Loss=0.00825 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.320 | L2-Norm(final)=11.204 | 4443.0 samples/s | 69.4 steps/s
[Step=57400 Epoch=112.2] | Loss=0.00813 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.321 | L2-Norm(final)=11.208 | 4517.4 samples/s | 70.6 steps/s
[Step=57450 Epoch=112.3] | Loss=0.00816 | Reg=0.00300 | acc=0.9688 | L2-Norm=17.322 | L2-Norm(final)=11.212 | 4518.6 samples/s | 70.6 steps/s
[Step=57500 Epoch=112.4] | Loss=0.00811 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.323 | L2-Norm(final)=11.215 | 4861.8 samples/s | 76.0 steps/s
[Step=57550 Epoch=112.5] | Loss=0.00799 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.324 | L2-Norm(final)=11.219 | 2578.0 samples/s | 40.3 steps/s
[Step=57600 Epoch=112.6] | Loss=0.00798 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.325 | L2-Norm(final)=11.223 | 4443.0 samples/s | 69.4 steps/s
[Step=57650 Epoch=112.7] | Loss=0.00789 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.326 | L2-Norm(final)=11.226 | 4495.0 samples/s | 70.2 steps/s
[Step=57700 Epoch=112.8] | Loss=0.00783 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.326 | L2-Norm(final)=11.230 | 4360.3 samples/s | 68.1 steps/s
[Step=57750 Epoch=112.9] | Loss=0.00783 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.326 | L2-Norm(final)=11.233 | 4488.1 samples/s | 70.1 steps/s
[Step=57800 Epoch=113.0] | Loss=0.00771 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.327 | L2-Norm(final)=11.236 | 4465.9 samples/s | 69.8 steps/s
[Step=57850 Epoch=113.1] | Loss=0.00764 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.327 | L2-Norm(final)=11.240 | 4482.0 samples/s | 70.0 steps/s
[Step=57900 Epoch=113.2] | Loss=0.00765 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.327 | L2-Norm(final)=11.244 | 4516.6 samples/s | 70.6 steps/s
[Step=57950 Epoch=113.3] | Loss=0.00761 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.327 | L2-Norm(final)=11.247 | 4418.9 samples/s | 69.0 steps/s
[Step=58000 Epoch=113.4] | Loss=0.00757 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.327 | L2-Norm(final)=11.251 | 4470.2 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step58000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=214.6] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.170 | L2-Norm(final)=6.873 | 5465.1 samples/s | 85.4 steps/s
[Step=56050 Epoch=214.8] | Loss=0.00013 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.176 | L2-Norm(final)=6.876 | 4294.2 samples/s | 67.1 steps/s
[Step=56100 Epoch=215.0] | Loss=0.00008 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.878 | 4702.2 samples/s | 73.5 steps/s
[Step=56150 Epoch=215.1] | Loss=0.00006 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.880 | 4615.8 samples/s | 72.1 steps/s
[Step=56200 Epoch=215.3] | Loss=0.00007 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.178 | L2-Norm(final)=6.882 | 4710.7 samples/s | 73.6 steps/s
[Step=56250 Epoch=215.5] | Loss=0.00007 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.178 | L2-Norm(final)=6.884 | 6636.3 samples/s | 103.7 steps/s
[Step=56300 Epoch=215.7] | Loss=0.00006 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.886 | 2417.5 samples/s | 37.8 steps/s
[Step=56350 Epoch=215.9] | Loss=0.00005 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.888 | 4812.2 samples/s | 75.2 steps/s
[Step=56400 Epoch=216.1] | Loss=0.00005 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.890 | 4665.2 samples/s | 72.9 steps/s
[Step=56450 Epoch=216.3] | Loss=0.00005 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.891 | 4628.5 samples/s | 72.3 steps/s
[Step=56500 Epoch=216.5] | Loss=0.00005 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=6.893 | 5497.8 samples/s | 85.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=216.5] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.178 | L2-Norm(final)=6.909 | 6144.4 samples/s | 96.0 steps/s
[Step=56550 Epoch=216.7] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.177 | L2-Norm(final)=6.911 | 3858.9 samples/s | 60.3 steps/s
[Step=56600 Epoch=216.9] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.175 | L2-Norm(final)=6.912 | 4262.1 samples/s | 66.6 steps/s
[Step=56650 Epoch=217.1] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.172 | L2-Norm(final)=6.913 | 4180.6 samples/s | 65.3 steps/s
[Step=56700 Epoch=217.3] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.169 | L2-Norm(final)=6.914 | 4258.2 samples/s | 66.5 steps/s
[Step=56750 Epoch=217.4] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.167 | L2-Norm(final)=6.916 | 5617.5 samples/s | 87.8 steps/s
[Step=56800 Epoch=217.6] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.164 | L2-Norm(final)=6.917 | 2257.1 samples/s | 35.3 steps/s
[Step=56850 Epoch=217.8] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.162 | L2-Norm(final)=6.918 | 4270.6 samples/s | 66.7 steps/s
[Step=56900 Epoch=218.0] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.159 | L2-Norm(final)=6.919 | 4183.2 samples/s | 65.4 steps/s
[Step=56950 Epoch=218.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.156 | L2-Norm(final)=6.920 | 4244.9 samples/s | 66.3 steps/s
[Step=57000 Epoch=218.4] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=6.921 | 4780.6 samples/s | 74.7 steps/s
[Step=57050 Epoch=218.6] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.151 | L2-Norm(final)=6.922 | 2446.1 samples/s | 38.2 steps/s
[Step=57100 Epoch=218.8] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=6.923 | 4170.9 samples/s | 65.2 steps/s
[Step=57150 Epoch=219.0] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.145 | L2-Norm(final)=6.924 | 4298.0 samples/s | 67.2 steps/s
[Step=57200 Epoch=219.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.142 | L2-Norm(final)=6.925 | 4156.1 samples/s | 64.9 steps/s
[Step=57250 Epoch=219.4] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.139 | L2-Norm(final)=6.926 | 4228.6 samples/s | 66.1 steps/s
[Step=57300 Epoch=219.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.136 | L2-Norm(final)=6.927 | 2623.3 samples/s | 41.0 steps/s
[Step=57350 Epoch=219.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.133 | L2-Norm(final)=6.928 | 4294.7 samples/s | 67.1 steps/s
[Step=57400 Epoch=219.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=6.929 | 4171.8 samples/s | 65.2 steps/s
[Step=57450 Epoch=220.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.127 | L2-Norm(final)=6.930 | 4245.3 samples/s | 66.3 steps/s
[Step=57500 Epoch=220.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.123 | L2-Norm(final)=6.931 | 4126.8 samples/s | 64.5 steps/s
[Step=57550 Epoch=220.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.120 | L2-Norm(final)=6.931 | 2643.5 samples/s | 41.3 steps/s
[Step=57600 Epoch=220.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.117 | L2-Norm(final)=6.932 | 4164.6 samples/s | 65.1 steps/s
[Step=57650 Epoch=220.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.113 | L2-Norm(final)=6.933 | 4233.5 samples/s | 66.1 steps/s
[Step=57700 Epoch=221.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.110 | L2-Norm(final)=6.934 | 4205.5 samples/s | 65.7 steps/s
[Step=57750 Epoch=221.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.106 | L2-Norm(final)=6.935 | 4281.2 samples/s | 66.9 steps/s
[Step=57800 Epoch=221.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.103 | L2-Norm(final)=6.935 | 6125.4 samples/s | 95.7 steps/s
[Step=57850 Epoch=221.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=6.936 | 2171.1 samples/s | 33.9 steps/s
[Step=57900 Epoch=221.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.095 | L2-Norm(final)=6.937 | 4215.6 samples/s | 65.9 steps/s
[Step=57950 Epoch=222.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.092 | L2-Norm(final)=6.938 | 4219.8 samples/s | 65.9 steps/s
[Step=58000 Epoch=222.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.088 | L2-Norm(final)=6.939 | 4222.4 samples/s | 66.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step58000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=215.6] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=7.522 | 6269.0 samples/s | 98.0 steps/s
[Step=56050 Epoch=215.8] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=7.522 | 4117.4 samples/s | 64.3 steps/s
[Step=56100 Epoch=216.0] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=7.523 | 4742.7 samples/s | 74.1 steps/s
[Step=56150 Epoch=216.1] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.524 | 4733.6 samples/s | 74.0 steps/s
[Step=56200 Epoch=216.3] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.526 | 4748.7 samples/s | 74.2 steps/s
[Step=56250 Epoch=216.5] | Loss=0.00005 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.528 | 6841.7 samples/s | 106.9 steps/s
[Step=56300 Epoch=216.7] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=7.530 | 2401.8 samples/s | 37.5 steps/s
[Step=56350 Epoch=216.9] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=7.531 | 4708.9 samples/s | 73.6 steps/s
[Step=56400 Epoch=217.1] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=7.533 | 4746.0 samples/s | 74.2 steps/s
[Step=56450 Epoch=217.3] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=7.534 | 4725.0 samples/s | 73.8 steps/s
[Step=56500 Epoch=217.5] | Loss=0.00004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.080 | L2-Norm(final)=7.536 | 5706.8 samples/s | 89.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=217.5] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.082 | L2-Norm(final)=7.552 | 6687.7 samples/s | 104.5 steps/s
[Step=56550 Epoch=217.7] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.081 | L2-Norm(final)=7.553 | 3685.7 samples/s | 57.6 steps/s
[Step=56600 Epoch=217.9] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.080 | L2-Norm(final)=7.555 | 4268.9 samples/s | 66.7 steps/s
[Step=56650 Epoch=218.1] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.556 | 4133.0 samples/s | 64.6 steps/s
[Step=56700 Epoch=218.3] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=7.557 | 4330.7 samples/s | 67.7 steps/s
[Step=56750 Epoch=218.5] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.075 | L2-Norm(final)=7.558 | 5582.6 samples/s | 87.2 steps/s
[Step=56800 Epoch=218.6] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.073 | L2-Norm(final)=7.559 | 2242.4 samples/s | 35.0 steps/s
[Step=56850 Epoch=218.8] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.072 | L2-Norm(final)=7.560 | 4227.3 samples/s | 66.1 steps/s
[Step=56900 Epoch=219.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.070 | L2-Norm(final)=7.561 | 4353.1 samples/s | 68.0 steps/s
[Step=56950 Epoch=219.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=7.562 | 4157.6 samples/s | 65.0 steps/s
[Step=57000 Epoch=219.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.066 | L2-Norm(final)=7.563 | 4968.4 samples/s | 77.6 steps/s
[Step=57050 Epoch=219.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.064 | L2-Norm(final)=7.564 | 2404.7 samples/s | 37.6 steps/s
[Step=57100 Epoch=219.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.062 | L2-Norm(final)=7.564 | 4228.3 samples/s | 66.1 steps/s
[Step=57150 Epoch=220.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.060 | L2-Norm(final)=7.565 | 4318.0 samples/s | 67.5 steps/s
[Step=57200 Epoch=220.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.058 | L2-Norm(final)=7.566 | 4226.3 samples/s | 66.0 steps/s
[Step=57250 Epoch=220.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.056 | L2-Norm(final)=7.567 | 4228.3 samples/s | 66.1 steps/s
[Step=57300 Epoch=220.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=7.567 | 2589.7 samples/s | 40.5 steps/s
[Step=57350 Epoch=220.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.052 | L2-Norm(final)=7.568 | 4292.5 samples/s | 67.1 steps/s
[Step=57400 Epoch=221.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.049 | L2-Norm(final)=7.569 | 4186.0 samples/s | 65.4 steps/s
[Step=57450 Epoch=221.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=7.569 | 4229.0 samples/s | 66.1 steps/s
[Step=57500 Epoch=221.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.045 | L2-Norm(final)=7.570 | 4237.0 samples/s | 66.2 steps/s
[Step=57550 Epoch=221.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.042 | L2-Norm(final)=7.570 | 2646.8 samples/s | 41.4 steps/s
[Step=57600 Epoch=221.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=7.571 | 4290.3 samples/s | 67.0 steps/s
[Step=57650 Epoch=221.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.037 | L2-Norm(final)=7.571 | 4137.5 samples/s | 64.6 steps/s
[Step=57700 Epoch=222.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.035 | L2-Norm(final)=7.572 | 4275.1 samples/s | 66.8 steps/s
[Step=57750 Epoch=222.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.032 | L2-Norm(final)=7.573 | 4165.2 samples/s | 65.1 steps/s
[Step=57800 Epoch=222.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.030 | L2-Norm(final)=7.573 | 7007.3 samples/s | 109.5 steps/s
[Step=57850 Epoch=222.7] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.027 | L2-Norm(final)=7.574 | 2092.3 samples/s | 32.7 steps/s
[Step=57900 Epoch=222.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.024 | L2-Norm(final)=7.574 | 4262.3 samples/s | 66.6 steps/s
[Step=57950 Epoch=223.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.022 | L2-Norm(final)=7.575 | 4167.6 samples/s | 65.1 steps/s
[Step=58000 Epoch=223.3] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.019 | L2-Norm(final)=7.575 | 4250.1 samples/s | 66.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07340 | acc=0.9675 | tpr=0.9720 | fpr=0.0424 | 5060.5 samples/s | 19.8 steps/s
Avg test loss: 0.07303, Avg test acc: 0.96698, Avg tpr: 0.97132, Avg fpr: 0.04256, total FA: 332

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07197 | acc=0.9676 | tpr=0.9736 | fpr=0.0456 | 4990.1 samples/s | 19.5 steps/s
Avg test loss: 0.07286, Avg test acc: 0.96674, Avg tpr: 0.97371, Avg fpr: 0.04858, total FA: 379

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.24063 | acc=0.3059 | tpr=0.0106 | fpr=0.0528 | 5028.4 samples/s | 19.6 steps/s
Avg test loss: 5.23864, Avg test acc: 0.30279, Avg tpr: 0.01166, Avg fpr: 0.05692, total FA: 444

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.77075 | acc=0.3101 | tpr=0.0197 | fpr=0.0595 | 4988.0 samples/s | 19.5 steps/s
Avg test loss: 5.75526, Avg test acc: 0.30599, Avg tpr: 0.02087, Avg fpr: 0.06691, total FA: 522

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.62375 | acc=0.1598 | tpr=0.4912 | fpr=0.8462 | 4756.4 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.59041 | acc=0.1597 | tpr=0.4733 | fpr=0.8461 | 7512.0 samples/s | 29.3 steps/s
[Step= 150] | Loss=5.59090 | acc=0.1605 | tpr=0.4697 | fpr=0.8452 | 7814.2 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.58487 | acc=0.1618 | tpr=0.4776 | fpr=0.8439 | 7862.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.57676 | acc=0.1624 | tpr=0.4847 | fpr=0.8435 | 8087.5 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.56779 | acc=0.1628 | tpr=0.4793 | fpr=0.8429 | 7659.8 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.56854 | acc=0.1626 | tpr=0.4715 | fpr=0.8430 | 7581.8 samples/s | 29.6 steps/s
[Step= 400] | Loss=5.56925 | acc=0.1627 | tpr=0.4683 | fpr=0.8429 | 8069.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.57125 | acc=0.1624 | tpr=0.4693 | fpr=0.8432 | 7906.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.57310 | acc=0.1629 | tpr=0.4683 | fpr=0.8427 | 7714.2 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.57794 | acc=0.1630 | tpr=0.4676 | fpr=0.8425 | 14079.3 samples/s | 55.0 steps/s
Avg test loss: 5.57939, Avg test acc: 0.16291, Avg tpr: 0.46910, Avg fpr: 0.84266, total FA: 117001

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.43579 | acc=0.1337 | tpr=0.5752 | fpr=0.8743 | 5049.3 samples/s | 19.7 steps/s
[Step= 100] | Loss=6.42822 | acc=0.1342 | tpr=0.5352 | fpr=0.8733 | 6909.9 samples/s | 27.0 steps/s
[Step= 150] | Loss=6.42599 | acc=0.1343 | tpr=0.5360 | fpr=0.8731 | 7807.0 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.42368 | acc=0.1349 | tpr=0.5322 | fpr=0.8723 | 7828.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.41319 | acc=0.1352 | tpr=0.5310 | fpr=0.8720 | 7898.0 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.40740 | acc=0.1358 | tpr=0.5287 | fpr=0.8713 | 7593.8 samples/s | 29.7 steps/s
[Step= 350] | Loss=6.41122 | acc=0.1354 | tpr=0.5191 | fpr=0.8716 | 7782.1 samples/s | 30.4 steps/s
[Step= 400] | Loss=6.40788 | acc=0.1352 | tpr=0.5098 | fpr=0.8716 | 8396.2 samples/s | 32.8 steps/s
[Step= 450] | Loss=6.41195 | acc=0.1350 | tpr=0.5078 | fpr=0.8718 | 7720.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.41455 | acc=0.1356 | tpr=0.5128 | fpr=0.8712 | 7812.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.41908 | acc=0.1355 | tpr=0.5133 | fpr=0.8713 | 13935.4 samples/s | 54.4 steps/s
Avg test loss: 6.42097, Avg test acc: 0.13538, Avg tpr: 0.51387, Avg fpr: 0.87150, total FA: 121006

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12411 | acc=0.9780 | tpr=0.9381 | fpr=0.0213 | 5092.4 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.12563 | acc=0.9784 | tpr=0.9467 | fpr=0.0210 | 6697.6 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.13115 | acc=0.9774 | tpr=0.9496 | fpr=0.0221 | 7885.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.13439 | acc=0.9774 | tpr=0.9519 | fpr=0.0221 | 8027.7 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.13192 | acc=0.9777 | tpr=0.9528 | fpr=0.0218 | 7386.2 samples/s | 28.9 steps/s
[Step= 300] | Loss=0.13387 | acc=0.9775 | tpr=0.9542 | fpr=0.0221 | 8271.7 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.13420 | acc=0.9775 | tpr=0.9549 | fpr=0.0221 | 7960.1 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.13557 | acc=0.9774 | tpr=0.9551 | fpr=0.0222 | 7699.0 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.13800 | acc=0.9772 | tpr=0.9537 | fpr=0.0224 | 8197.4 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.13729 | acc=0.9772 | tpr=0.9546 | fpr=0.0224 | 7543.9 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.13596 | acc=0.9774 | tpr=0.9554 | fpr=0.0222 | 14157.1 samples/s | 55.3 steps/s
Avg test loss: 0.13579, Avg test acc: 0.97741, Avg tpr: 0.95523, Avg fpr: 0.02219, total FA: 3081

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13219 | acc=0.9777 | tpr=0.9513 | fpr=0.0218 | 4856.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.13402 | acc=0.9776 | tpr=0.9574 | fpr=0.0220 | 7581.1 samples/s | 29.6 steps/s
[Step= 150] | Loss=0.14080 | acc=0.9766 | tpr=0.9582 | fpr=0.0231 | 7518.6 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.14328 | acc=0.9765 | tpr=0.9596 | fpr=0.0231 | 8022.3 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.14096 | acc=0.9769 | tpr=0.9572 | fpr=0.0228 | 7877.2 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.14318 | acc=0.9767 | tpr=0.9564 | fpr=0.0229 | 7525.9 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.14343 | acc=0.9767 | tpr=0.9574 | fpr=0.0230 | 7972.5 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14475 | acc=0.9766 | tpr=0.9546 | fpr=0.0230 | 7733.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.14748 | acc=0.9762 | tpr=0.9523 | fpr=0.0233 | 7943.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14687 | acc=0.9763 | tpr=0.9529 | fpr=0.0232 | 7823.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.14538 | acc=0.9766 | tpr=0.9538 | fpr=0.0229 | 14742.0 samples/s | 57.6 steps/s
Avg test loss: 0.14524, Avg test acc: 0.97664, Avg tpr: 0.95365, Avg fpr: 0.02294, total FA: 3185

server round 29/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=113.1] | Loss=0.01085 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.148 | L2-Norm(final)=11.231 | 6158.6 samples/s | 96.2 steps/s
[Step=58050 Epoch=113.2] | Loss=0.00484 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.147 | L2-Norm(final)=11.235 | 4607.1 samples/s | 72.0 steps/s
[Step=58100 Epoch=113.3] | Loss=0.00512 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.146 | L2-Norm(final)=11.241 | 5046.9 samples/s | 78.9 steps/s
[Step=58150 Epoch=113.4] | Loss=0.00570 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.145 | L2-Norm(final)=11.247 | 5010.7 samples/s | 78.3 steps/s
[Step=58200 Epoch=113.5] | Loss=0.00583 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.144 | L2-Norm(final)=11.252 | 5017.8 samples/s | 78.4 steps/s
[Step=58250 Epoch=113.6] | Loss=0.00582 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.143 | L2-Norm(final)=11.257 | 5168.1 samples/s | 80.8 steps/s
[Step=58300 Epoch=113.7] | Loss=0.00564 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.142 | L2-Norm(final)=11.263 | 5117.3 samples/s | 80.0 steps/s
[Step=58350 Epoch=113.8] | Loss=0.00594 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.142 | L2-Norm(final)=11.269 | 4943.5 samples/s | 77.2 steps/s
[Step=58400 Epoch=113.9] | Loss=0.00571 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.141 | L2-Norm(final)=11.275 | 4980.9 samples/s | 77.8 steps/s
[Step=58450 Epoch=114.0] | Loss=0.00569 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.140 | L2-Norm(final)=11.281 | 4989.6 samples/s | 78.0 steps/s
[Step=58500 Epoch=114.1] | Loss=0.00556 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.139 | L2-Norm(final)=11.287 | 6777.1 samples/s | 105.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=114.1] | Loss=0.00059 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.129 | L2-Norm(final)=11.348 | 6762.0 samples/s | 105.7 steps/s
[Step=58550 Epoch=114.2] | Loss=0.00461 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.129 | L2-Norm(final)=11.354 | 3974.2 samples/s | 62.1 steps/s
[Step=58600 Epoch=114.3] | Loss=0.00526 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.130 | L2-Norm(final)=11.359 | 4521.5 samples/s | 70.6 steps/s
[Step=58650 Epoch=114.4] | Loss=0.00583 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.131 | L2-Norm(final)=11.362 | 4393.2 samples/s | 68.6 steps/s
[Step=58700 Epoch=114.5] | Loss=0.00627 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.131 | L2-Norm(final)=11.366 | 4471.8 samples/s | 69.9 steps/s
[Step=58750 Epoch=114.6] | Loss=0.00693 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.133 | L2-Norm(final)=11.370 | 4533.2 samples/s | 70.8 steps/s
[Step=58800 Epoch=114.7] | Loss=0.00698 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.135 | L2-Norm(final)=11.375 | 4462.8 samples/s | 69.7 steps/s
[Step=58850 Epoch=114.8] | Loss=0.00715 | Reg=0.00294 | acc=0.9531 | L2-Norm=17.137 | L2-Norm(final)=11.380 | 4471.3 samples/s | 69.9 steps/s
[Step=58900 Epoch=114.9] | Loss=0.00751 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.139 | L2-Norm(final)=11.384 | 4541.9 samples/s | 71.0 steps/s
[Step=58950 Epoch=115.0] | Loss=0.00767 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.141 | L2-Norm(final)=11.388 | 4461.0 samples/s | 69.7 steps/s
[Step=59000 Epoch=115.1] | Loss=0.00756 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.143 | L2-Norm(final)=11.393 | 5628.4 samples/s | 87.9 steps/s
[Step=59050 Epoch=115.2] | Loss=0.00760 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.145 | L2-Norm(final)=11.397 | 2396.7 samples/s | 37.4 steps/s
[Step=59100 Epoch=115.3] | Loss=0.00751 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.147 | L2-Norm(final)=11.402 | 4422.0 samples/s | 69.1 steps/s
[Step=59150 Epoch=115.4] | Loss=0.00757 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.148 | L2-Norm(final)=11.406 | 4487.9 samples/s | 70.1 steps/s
[Step=59200 Epoch=115.5] | Loss=0.00754 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.150 | L2-Norm(final)=11.410 | 4441.7 samples/s | 69.4 steps/s
[Step=59250 Epoch=115.6] | Loss=0.00746 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.151 | L2-Norm(final)=11.415 | 4470.1 samples/s | 69.8 steps/s
[Step=59300 Epoch=115.7] | Loss=0.00757 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.152 | L2-Norm(final)=11.419 | 4483.9 samples/s | 70.1 steps/s
[Step=59350 Epoch=115.8] | Loss=0.00754 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.153 | L2-Norm(final)=11.423 | 4479.8 samples/s | 70.0 steps/s
[Step=59400 Epoch=115.9] | Loss=0.00753 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.154 | L2-Norm(final)=11.427 | 4503.4 samples/s | 70.4 steps/s
[Step=59450 Epoch=116.0] | Loss=0.00740 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.155 | L2-Norm(final)=11.432 | 4471.4 samples/s | 69.9 steps/s
[Step=59500 Epoch=116.0] | Loss=0.00746 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.156 | L2-Norm(final)=11.436 | 4824.3 samples/s | 75.4 steps/s
[Step=59550 Epoch=116.1] | Loss=0.00753 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.157 | L2-Norm(final)=11.440 | 2624.7 samples/s | 41.0 steps/s
[Step=59600 Epoch=116.2] | Loss=0.00743 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.157 | L2-Norm(final)=11.444 | 4494.2 samples/s | 70.2 steps/s
[Step=59650 Epoch=116.3] | Loss=0.00733 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.158 | L2-Norm(final)=11.448 | 4470.4 samples/s | 69.8 steps/s
[Step=59700 Epoch=116.4] | Loss=0.00737 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.159 | L2-Norm(final)=11.452 | 4481.0 samples/s | 70.0 steps/s
[Step=59750 Epoch=116.5] | Loss=0.00732 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.159 | L2-Norm(final)=11.456 | 4574.1 samples/s | 71.5 steps/s
[Step=59800 Epoch=116.6] | Loss=0.00731 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.159 | L2-Norm(final)=11.459 | 4409.8 samples/s | 68.9 steps/s
[Step=59850 Epoch=116.7] | Loss=0.00724 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.160 | L2-Norm(final)=11.463 | 4420.0 samples/s | 69.1 steps/s
[Step=59900 Epoch=116.8] | Loss=0.00719 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.160 | L2-Norm(final)=11.467 | 4537.2 samples/s | 70.9 steps/s
[Step=59950 Epoch=116.9] | Loss=0.00725 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.160 | L2-Norm(final)=11.471 | 4421.9 samples/s | 69.1 steps/s
[Step=60000 Epoch=117.0] | Loss=0.00727 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.160 | L2-Norm(final)=11.474 | 4515.3 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step60000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=113.4] | Loss=0.01293 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.211 | L2-Norm(final)=11.355 | 6623.9 samples/s | 103.5 steps/s
[Step=58050 Epoch=113.5] | Loss=0.00546 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.209 | L2-Norm(final)=11.362 | 4399.1 samples/s | 68.7 steps/s
[Step=58100 Epoch=113.6] | Loss=0.00552 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.208 | L2-Norm(final)=11.368 | 4993.2 samples/s | 78.0 steps/s
[Step=58150 Epoch=113.7] | Loss=0.00516 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=11.375 | 5004.7 samples/s | 78.2 steps/s
[Step=58200 Epoch=113.8] | Loss=0.00524 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.205 | L2-Norm(final)=11.381 | 5029.8 samples/s | 78.6 steps/s
[Step=58250 Epoch=113.9] | Loss=0.00522 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.204 | L2-Norm(final)=11.387 | 5041.9 samples/s | 78.8 steps/s
[Step=58300 Epoch=114.0] | Loss=0.00526 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.203 | L2-Norm(final)=11.393 | 5057.4 samples/s | 79.0 steps/s
[Step=58350 Epoch=114.1] | Loss=0.00527 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.201 | L2-Norm(final)=11.399 | 5013.4 samples/s | 78.3 steps/s
[Step=58400 Epoch=114.2] | Loss=0.00519 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.200 | L2-Norm(final)=11.405 | 5035.9 samples/s | 78.7 steps/s
[Step=58450 Epoch=114.3] | Loss=0.00517 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.200 | L2-Norm(final)=11.411 | 5061.0 samples/s | 79.1 steps/s
[Step=58500 Epoch=114.4] | Loss=0.00507 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.199 | L2-Norm(final)=11.418 | 6950.2 samples/s | 108.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=114.4] | Loss=0.00014 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.192 | L2-Norm(final)=11.482 | 6073.1 samples/s | 94.9 steps/s
[Step=58550 Epoch=114.5] | Loss=0.00667 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.193 | L2-Norm(final)=11.488 | 4229.0 samples/s | 66.1 steps/s
[Step=58600 Epoch=114.6] | Loss=0.00570 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.196 | L2-Norm(final)=11.495 | 4352.2 samples/s | 68.0 steps/s
[Step=58650 Epoch=114.7] | Loss=0.00753 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.200 | L2-Norm(final)=11.500 | 4454.8 samples/s | 69.6 steps/s
[Step=58700 Epoch=114.8] | Loss=0.00756 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.204 | L2-Norm(final)=11.505 | 4470.8 samples/s | 69.9 steps/s
[Step=58750 Epoch=114.9] | Loss=0.00817 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.209 | L2-Norm(final)=11.510 | 4469.0 samples/s | 69.8 steps/s
[Step=58800 Epoch=115.0] | Loss=0.00836 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.213 | L2-Norm(final)=11.514 | 4519.9 samples/s | 70.6 steps/s
[Step=58850 Epoch=115.1] | Loss=0.00881 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.218 | L2-Norm(final)=11.518 | 4450.5 samples/s | 69.5 steps/s
[Step=58900 Epoch=115.1] | Loss=0.00906 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.222 | L2-Norm(final)=11.523 | 4556.7 samples/s | 71.2 steps/s
[Step=58950 Epoch=115.2] | Loss=0.00874 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.226 | L2-Norm(final)=11.527 | 4521.6 samples/s | 70.7 steps/s
[Step=59000 Epoch=115.3] | Loss=0.00861 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.230 | L2-Norm(final)=11.532 | 5687.4 samples/s | 88.9 steps/s
[Step=59050 Epoch=115.4] | Loss=0.00845 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.234 | L2-Norm(final)=11.536 | 2381.7 samples/s | 37.2 steps/s
[Step=59100 Epoch=115.5] | Loss=0.00820 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.236 | L2-Norm(final)=11.541 | 4518.7 samples/s | 70.6 steps/s
[Step=59150 Epoch=115.6] | Loss=0.00808 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.239 | L2-Norm(final)=11.546 | 4410.7 samples/s | 68.9 steps/s
[Step=59200 Epoch=115.7] | Loss=0.00801 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.241 | L2-Norm(final)=11.550 | 4476.3 samples/s | 69.9 steps/s
[Step=59250 Epoch=115.8] | Loss=0.00805 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.242 | L2-Norm(final)=11.554 | 4474.2 samples/s | 69.9 steps/s
[Step=59300 Epoch=115.9] | Loss=0.00804 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.244 | L2-Norm(final)=11.558 | 4523.7 samples/s | 70.7 steps/s
[Step=59350 Epoch=116.0] | Loss=0.00787 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.246 | L2-Norm(final)=11.562 | 4500.6 samples/s | 70.3 steps/s
[Step=59400 Epoch=116.1] | Loss=0.00784 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.247 | L2-Norm(final)=11.565 | 4537.9 samples/s | 70.9 steps/s
[Step=59450 Epoch=116.2] | Loss=0.00782 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=11.569 | 4386.2 samples/s | 68.5 steps/s
[Step=59500 Epoch=116.3] | Loss=0.00781 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.250 | L2-Norm(final)=11.573 | 4948.9 samples/s | 77.3 steps/s
[Step=59550 Epoch=116.4] | Loss=0.00777 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.251 | L2-Norm(final)=11.577 | 2628.5 samples/s | 41.1 steps/s
[Step=59600 Epoch=116.5] | Loss=0.00768 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.252 | L2-Norm(final)=11.581 | 4441.6 samples/s | 69.4 steps/s
[Step=59650 Epoch=116.6] | Loss=0.00755 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.252 | L2-Norm(final)=11.584 | 4412.0 samples/s | 68.9 steps/s
[Step=59700 Epoch=116.7] | Loss=0.00746 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.253 | L2-Norm(final)=11.588 | 4438.0 samples/s | 69.3 steps/s
[Step=59750 Epoch=116.8] | Loss=0.00741 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.253 | L2-Norm(final)=11.592 | 4483.9 samples/s | 70.1 steps/s
[Step=59800 Epoch=116.9] | Loss=0.00738 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.253 | L2-Norm(final)=11.595 | 4489.1 samples/s | 70.1 steps/s
[Step=59850 Epoch=117.0] | Loss=0.00730 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=11.599 | 4531.9 samples/s | 70.8 steps/s
[Step=59900 Epoch=117.1] | Loss=0.00732 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=11.602 | 4420.1 samples/s | 69.1 steps/s
[Step=59950 Epoch=117.2] | Loss=0.00729 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.254 | L2-Norm(final)=11.605 | 4476.8 samples/s | 70.0 steps/s
[Step=60000 Epoch=117.3] | Loss=0.00720 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=11.609 | 4508.2 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step60000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=222.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.172 | L2-Norm(final)=6.962 | 6224.4 samples/s | 97.3 steps/s
[Step=58050 Epoch=222.4] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.964 | 4143.2 samples/s | 64.7 steps/s
[Step=58100 Epoch=222.6] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.967 | 4797.4 samples/s | 75.0 steps/s
[Step=58150 Epoch=222.8] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.170 | L2-Norm(final)=6.970 | 4706.9 samples/s | 73.5 steps/s
[Step=58200 Epoch=223.0] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.973 | 4715.0 samples/s | 73.7 steps/s
[Step=58250 Epoch=223.2] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.977 | 6648.5 samples/s | 103.9 steps/s
[Step=58300 Epoch=223.4] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.980 | 2410.0 samples/s | 37.7 steps/s
[Step=58350 Epoch=223.6] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.983 | 4778.7 samples/s | 74.7 steps/s
[Step=58400 Epoch=223.8] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.986 | 4702.0 samples/s | 73.5 steps/s
[Step=58450 Epoch=224.0] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=6.989 | 4767.1 samples/s | 74.5 steps/s
[Step=58500 Epoch=224.2] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.170 | L2-Norm(final)=6.992 | 5443.5 samples/s | 85.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=224.2] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.170 | L2-Norm(final)=7.024 | 6334.8 samples/s | 99.0 steps/s
[Step=58550 Epoch=224.3] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.167 | L2-Norm(final)=7.028 | 3749.8 samples/s | 58.6 steps/s
[Step=58600 Epoch=224.5] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.162 | L2-Norm(final)=7.031 | 4172.9 samples/s | 65.2 steps/s
[Step=58650 Epoch=224.7] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=7.034 | 4314.5 samples/s | 67.4 steps/s
[Step=58700 Epoch=224.9] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=7.036 | 4174.5 samples/s | 65.2 steps/s
[Step=58750 Epoch=225.1] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.142 | L2-Norm(final)=7.037 | 5706.0 samples/s | 89.2 steps/s
[Step=58800 Epoch=225.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.136 | L2-Norm(final)=7.039 | 2291.0 samples/s | 35.8 steps/s
[Step=58850 Epoch=225.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=7.041 | 4212.7 samples/s | 65.8 steps/s
[Step=58900 Epoch=225.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=7.042 | 4045.3 samples/s | 63.2 steps/s
[Step=58950 Epoch=225.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.115 | L2-Norm(final)=7.044 | 4338.3 samples/s | 67.8 steps/s
[Step=59000 Epoch=226.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.108 | L2-Norm(final)=7.045 | 4606.0 samples/s | 72.0 steps/s
[Step=59050 Epoch=226.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.100 | L2-Norm(final)=7.047 | 2426.9 samples/s | 37.9 steps/s
[Step=59100 Epoch=226.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.093 | L2-Norm(final)=7.048 | 4259.7 samples/s | 66.6 steps/s
[Step=59150 Epoch=226.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.049 | 4150.1 samples/s | 64.8 steps/s
[Step=59200 Epoch=226.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.051 | 3944.9 samples/s | 61.6 steps/s
[Step=59250 Epoch=227.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.070 | L2-Norm(final)=7.052 | 4113.4 samples/s | 64.3 steps/s
[Step=59300 Epoch=227.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.062 | L2-Norm(final)=7.053 | 2610.0 samples/s | 40.8 steps/s
[Step=59350 Epoch=227.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=7.054 | 4197.2 samples/s | 65.6 steps/s
[Step=59400 Epoch=227.6] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.046 | L2-Norm(final)=7.056 | 4210.6 samples/s | 65.8 steps/s
[Step=59450 Epoch=227.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.038 | L2-Norm(final)=7.057 | 4175.5 samples/s | 65.2 steps/s
[Step=59500 Epoch=228.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.030 | L2-Norm(final)=7.058 | 4236.7 samples/s | 66.2 steps/s
[Step=59550 Epoch=228.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.021 | L2-Norm(final)=7.059 | 2585.2 samples/s | 40.4 steps/s
[Step=59600 Epoch=228.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.013 | L2-Norm(final)=7.060 | 4177.8 samples/s | 65.3 steps/s
[Step=59650 Epoch=228.6] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.004 | L2-Norm(final)=7.062 | 4175.7 samples/s | 65.2 steps/s
[Step=59700 Epoch=228.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.063 | 4241.7 samples/s | 66.3 steps/s
[Step=59750 Epoch=228.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.987 | L2-Norm(final)=7.064 | 4141.0 samples/s | 64.7 steps/s
[Step=59800 Epoch=229.1] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.978 | L2-Norm(final)=7.065 | 6280.0 samples/s | 98.1 steps/s
[Step=59850 Epoch=229.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.969 | L2-Norm(final)=7.067 | 2168.1 samples/s | 33.9 steps/s
[Step=59900 Epoch=229.5] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.960 | L2-Norm(final)=7.068 | 4146.7 samples/s | 64.8 steps/s
[Step=59950 Epoch=229.7] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.951 | L2-Norm(final)=7.069 | 4269.3 samples/s | 66.7 steps/s
[Step=60000 Epoch=229.9] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.942 | L2-Norm(final)=7.070 | 4145.6 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step60000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=223.3] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.591 | 5925.7 samples/s | 92.6 steps/s
[Step=58050 Epoch=223.5] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.593 | 4210.3 samples/s | 65.8 steps/s
[Step=58100 Epoch=223.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.595 | 4675.7 samples/s | 73.1 steps/s
[Step=58150 Epoch=223.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.598 | 4775.2 samples/s | 74.6 steps/s
[Step=58200 Epoch=224.0] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.601 | 4644.0 samples/s | 72.6 steps/s
[Step=58250 Epoch=224.2] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.604 | 6664.5 samples/s | 104.1 steps/s
[Step=58300 Epoch=224.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.607 | 2369.8 samples/s | 37.0 steps/s
[Step=58350 Epoch=224.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=7.609 | 4805.8 samples/s | 75.1 steps/s
[Step=58400 Epoch=224.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=7.612 | 4584.7 samples/s | 71.6 steps/s
[Step=58450 Epoch=225.0] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=7.615 | 4770.2 samples/s | 74.5 steps/s
[Step=58500 Epoch=225.2] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=7.617 | 5478.0 samples/s | 85.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=225.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=7.646 | 6083.5 samples/s | 95.1 steps/s
[Step=58550 Epoch=225.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=7.648 | 3838.9 samples/s | 60.0 steps/s
[Step=58600 Epoch=225.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.083 | L2-Norm(final)=7.651 | 4165.7 samples/s | 65.1 steps/s
[Step=58650 Epoch=225.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=7.653 | 4223.3 samples/s | 66.0 steps/s
[Step=58700 Epoch=226.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.075 | L2-Norm(final)=7.655 | 4168.4 samples/s | 65.1 steps/s
[Step=58750 Epoch=226.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.071 | L2-Norm(final)=7.657 | 5659.1 samples/s | 88.4 steps/s
[Step=58800 Epoch=226.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.066 | L2-Norm(final)=7.659 | 2228.1 samples/s | 34.8 steps/s
[Step=58850 Epoch=226.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.061 | L2-Norm(final)=7.660 | 4193.4 samples/s | 65.5 steps/s
[Step=58900 Epoch=226.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.056 | L2-Norm(final)=7.662 | 4125.9 samples/s | 64.5 steps/s
[Step=58950 Epoch=226.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.051 | L2-Norm(final)=7.663 | 4185.8 samples/s | 65.4 steps/s
[Step=59000 Epoch=227.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.046 | L2-Norm(final)=7.664 | 4934.1 samples/s | 77.1 steps/s
[Step=59050 Epoch=227.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=7.665 | 2390.3 samples/s | 37.3 steps/s
[Step=59100 Epoch=227.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.035 | L2-Norm(final)=7.667 | 4132.7 samples/s | 64.6 steps/s
[Step=59150 Epoch=227.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.030 | L2-Norm(final)=7.668 | 4241.9 samples/s | 66.3 steps/s
[Step=59200 Epoch=227.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.024 | L2-Norm(final)=7.669 | 4183.2 samples/s | 65.4 steps/s
[Step=59250 Epoch=228.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.019 | L2-Norm(final)=7.670 | 4259.5 samples/s | 66.6 steps/s
[Step=59300 Epoch=228.3] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.013 | L2-Norm(final)=7.671 | 2563.9 samples/s | 40.1 steps/s
[Step=59350 Epoch=228.5] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=7.672 | 4262.6 samples/s | 66.6 steps/s
[Step=59400 Epoch=228.7] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=7.673 | 4161.4 samples/s | 65.0 steps/s
[Step=59450 Epoch=228.8] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.674 | 4167.0 samples/s | 65.1 steps/s
[Step=59500 Epoch=229.0] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.989 | L2-Norm(final)=7.675 | 4205.2 samples/s | 65.7 steps/s
[Step=59550 Epoch=229.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.983 | L2-Norm(final)=7.676 | 2613.9 samples/s | 40.8 steps/s
[Step=59600 Epoch=229.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.977 | L2-Norm(final)=7.678 | 4328.3 samples/s | 67.6 steps/s
[Step=59650 Epoch=229.6] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.970 | L2-Norm(final)=7.679 | 4098.8 samples/s | 64.0 steps/s
[Step=59700 Epoch=229.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.964 | L2-Norm(final)=7.680 | 4233.0 samples/s | 66.1 steps/s
[Step=59750 Epoch=230.0] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.958 | L2-Norm(final)=7.681 | 4160.3 samples/s | 65.0 steps/s
[Step=59800 Epoch=230.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.951 | L2-Norm(final)=7.682 | 6841.5 samples/s | 106.9 steps/s
[Step=59850 Epoch=230.4] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=7.683 | 2126.2 samples/s | 33.2 steps/s
[Step=59900 Epoch=230.6] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.938 | L2-Norm(final)=7.684 | 4115.0 samples/s | 64.3 steps/s
[Step=59950 Epoch=230.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.931 | L2-Norm(final)=7.685 | 4267.8 samples/s | 66.7 steps/s
[Step=60000 Epoch=231.0] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.924 | L2-Norm(final)=7.686 | 4144.1 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07820 | acc=0.9642 | tpr=0.9776 | fpr=0.0649 | 4662.1 samples/s | 18.2 steps/s
Avg test loss: 0.07716, Avg test acc: 0.96490, Avg tpr: 0.97704, Avg fpr: 0.06179, total FA: 482

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07517 | acc=0.9676 | tpr=0.9724 | fpr=0.0429 | 4859.7 samples/s | 19.0 steps/s
Avg test loss: 0.07883, Avg test acc: 0.96610, Avg tpr: 0.97196, Avg fpr: 0.04679, total FA: 365

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.45107 | acc=0.3059 | tpr=0.0108 | fpr=0.0533 | 5043.3 samples/s | 19.7 steps/s
Avg test loss: 5.44761, Avg test acc: 0.30223, Avg tpr: 0.01160, Avg fpr: 0.05858, total FA: 457

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.72430 | acc=0.3109 | tpr=0.0194 | fpr=0.0560 | 4791.7 samples/s | 18.7 steps/s
Avg test loss: 5.70867, Avg test acc: 0.30788, Avg tpr: 0.02104, Avg fpr: 0.06127, total FA: 478

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.35850 | acc=0.1323 | tpr=0.5619 | fpr=0.8755 | 4734.5 samples/s | 18.5 steps/s
[Step= 100] | Loss=6.33029 | acc=0.1306 | tpr=0.5288 | fpr=0.8768 | 7469.3 samples/s | 29.2 steps/s
[Step= 150] | Loss=6.33306 | acc=0.1309 | tpr=0.5173 | fpr=0.8763 | 7759.2 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.32479 | acc=0.1316 | tpr=0.5180 | fpr=0.8754 | 7799.1 samples/s | 30.5 steps/s
[Step= 250] | Loss=6.31481 | acc=0.1318 | tpr=0.5284 | fpr=0.8754 | 8042.7 samples/s | 31.4 steps/s
[Step= 300] | Loss=6.30580 | acc=0.1316 | tpr=0.5244 | fpr=0.8756 | 7805.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=6.31114 | acc=0.1312 | tpr=0.5172 | fpr=0.8758 | 7735.5 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.31307 | acc=0.1314 | tpr=0.5137 | fpr=0.8755 | 7921.7 samples/s | 30.9 steps/s
[Step= 450] | Loss=6.31678 | acc=0.1313 | tpr=0.5131 | fpr=0.8756 | 7436.1 samples/s | 29.0 steps/s
[Step= 500] | Loss=6.31790 | acc=0.1318 | tpr=0.5115 | fpr=0.8751 | 7778.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=6.32183 | acc=0.1319 | tpr=0.5097 | fpr=0.8749 | 14638.3 samples/s | 57.2 steps/s
Avg test loss: 6.32362, Avg test acc: 0.13186, Avg tpr: 0.51109, Avg fpr: 0.87504, total FA: 121497

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.33630 | acc=0.1280 | tpr=0.5177 | fpr=0.8790 | 4925.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=7.32043 | acc=0.1286 | tpr=0.4861 | fpr=0.8781 | 7120.6 samples/s | 27.8 steps/s
[Step= 150] | Loss=7.31422 | acc=0.1285 | tpr=0.4957 | fpr=0.8782 | 8179.0 samples/s | 31.9 steps/s
[Step= 200] | Loss=7.30898 | acc=0.1287 | tpr=0.4874 | fpr=0.8778 | 7493.5 samples/s | 29.3 steps/s
[Step= 250] | Loss=7.30053 | acc=0.1287 | tpr=0.4865 | fpr=0.8778 | 7675.6 samples/s | 30.0 steps/s
[Step= 300] | Loss=7.29343 | acc=0.1291 | tpr=0.4822 | fpr=0.8774 | 7906.2 samples/s | 30.9 steps/s
[Step= 350] | Loss=7.30006 | acc=0.1287 | tpr=0.4753 | fpr=0.8776 | 7771.2 samples/s | 30.4 steps/s
[Step= 400] | Loss=7.29954 | acc=0.1286 | tpr=0.4655 | fpr=0.8775 | 8166.8 samples/s | 31.9 steps/s
[Step= 450] | Loss=7.30358 | acc=0.1285 | tpr=0.4635 | fpr=0.8776 | 7940.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=7.30573 | acc=0.1289 | tpr=0.4661 | fpr=0.8772 | 7834.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=7.31143 | acc=0.1289 | tpr=0.4672 | fpr=0.8772 | 12888.7 samples/s | 50.3 steps/s
Avg test loss: 7.31358, Avg test acc: 0.12877, Avg tpr: 0.46830, Avg fpr: 0.87740, total FA: 121825

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12298 | acc=0.9788 | tpr=0.9336 | fpr=0.0204 | 4852.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.12474 | acc=0.9791 | tpr=0.9403 | fpr=0.0202 | 7053.9 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.13022 | acc=0.9782 | tpr=0.9438 | fpr=0.0212 | 7750.4 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.13362 | acc=0.9781 | tpr=0.9464 | fpr=0.0213 | 7259.7 samples/s | 28.4 steps/s
[Step= 250] | Loss=0.13111 | acc=0.9785 | tpr=0.9467 | fpr=0.0210 | 8045.1 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.13287 | acc=0.9782 | tpr=0.9469 | fpr=0.0212 | 7745.1 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.13297 | acc=0.9782 | tpr=0.9487 | fpr=0.0212 | 7631.2 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.13437 | acc=0.9781 | tpr=0.9480 | fpr=0.0213 | 7614.2 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.13683 | acc=0.9778 | tpr=0.9464 | fpr=0.0217 | 7864.5 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.13606 | acc=0.9778 | tpr=0.9480 | fpr=0.0217 | 7828.6 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.13473 | acc=0.9780 | tpr=0.9487 | fpr=0.0214 | 14579.3 samples/s | 57.0 steps/s
Avg test loss: 0.13459, Avg test acc: 0.97804, Avg tpr: 0.94849, Avg fpr: 0.02142, total FA: 2974

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12478 | acc=0.9780 | tpr=0.9513 | fpr=0.0215 | 4992.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.12662 | acc=0.9782 | tpr=0.9552 | fpr=0.0214 | 7211.5 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.13319 | acc=0.9772 | tpr=0.9568 | fpr=0.0224 | 7697.6 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.13588 | acc=0.9770 | tpr=0.9574 | fpr=0.0227 | 7588.8 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.13379 | acc=0.9772 | tpr=0.9537 | fpr=0.0224 | 7756.3 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.13584 | acc=0.9770 | tpr=0.9535 | fpr=0.0226 | 7918.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.13609 | acc=0.9770 | tpr=0.9549 | fpr=0.0226 | 7578.9 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.13733 | acc=0.9769 | tpr=0.9524 | fpr=0.0227 | 7654.3 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.13997 | acc=0.9765 | tpr=0.9499 | fpr=0.0230 | 8321.0 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.13938 | acc=0.9766 | tpr=0.9507 | fpr=0.0229 | 7531.2 samples/s | 29.4 steps/s
[Step= 550] | Loss=0.13791 | acc=0.9769 | tpr=0.9515 | fpr=0.0226 | 13867.9 samples/s | 54.2 steps/s
Avg test loss: 0.13777, Avg test acc: 0.97694, Avg tpr: 0.95127, Avg fpr: 0.02259, total FA: 3137

server round 30/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=117.0] | Loss=0.01025 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.990 | L2-Norm(final)=11.576 | 6883.8 samples/s | 107.6 steps/s
[Step=60050 Epoch=117.1] | Loss=0.00447 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.989 | L2-Norm(final)=11.579 | 4085.5 samples/s | 63.8 steps/s
[Step=60100 Epoch=117.2] | Loss=0.00487 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.989 | L2-Norm(final)=11.582 | 4883.6 samples/s | 76.3 steps/s
[Step=60150 Epoch=117.3] | Loss=0.00468 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.988 | L2-Norm(final)=11.586 | 4969.7 samples/s | 77.7 steps/s
[Step=60200 Epoch=117.4] | Loss=0.00484 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.987 | L2-Norm(final)=11.589 | 5019.0 samples/s | 78.4 steps/s
[Step=60250 Epoch=117.5] | Loss=0.00489 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.986 | L2-Norm(final)=11.592 | 5003.9 samples/s | 78.2 steps/s
[Step=60300 Epoch=117.6] | Loss=0.00463 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.985 | L2-Norm(final)=11.595 | 5102.9 samples/s | 79.7 steps/s
[Step=60350 Epoch=117.7] | Loss=0.00470 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.984 | L2-Norm(final)=11.598 | 4970.2 samples/s | 77.7 steps/s
[Step=60400 Epoch=117.8] | Loss=0.00480 | Reg=0.00288 | acc=0.9688 | L2-Norm=16.983 | L2-Norm(final)=11.601 | 5068.3 samples/s | 79.2 steps/s
[Step=60450 Epoch=117.9] | Loss=0.00482 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.982 | L2-Norm(final)=11.604 | 5059.8 samples/s | 79.1 steps/s
[Step=60500 Epoch=118.0] | Loss=0.00475 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.981 | L2-Norm(final)=11.607 | 6595.1 samples/s | 103.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=118.0] | Loss=0.00103 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.972 | L2-Norm(final)=11.635 | 6236.2 samples/s | 97.4 steps/s
[Step=60550 Epoch=118.1] | Loss=0.00368 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.971 | L2-Norm(final)=11.638 | 4067.6 samples/s | 63.6 steps/s
[Step=60600 Epoch=118.2] | Loss=0.00450 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.971 | L2-Norm(final)=11.641 | 4497.1 samples/s | 70.3 steps/s
[Step=60650 Epoch=118.3] | Loss=0.00455 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.970 | L2-Norm(final)=11.644 | 4437.5 samples/s | 69.3 steps/s
[Step=60700 Epoch=118.4] | Loss=0.00501 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.970 | L2-Norm(final)=11.646 | 4463.0 samples/s | 69.7 steps/s
[Step=60750 Epoch=118.5] | Loss=0.00515 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.969 | L2-Norm(final)=11.649 | 4459.5 samples/s | 69.7 steps/s
[Step=60800 Epoch=118.6] | Loss=0.00514 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=11.651 | 4517.9 samples/s | 70.6 steps/s
[Step=60850 Epoch=118.7] | Loss=0.00520 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=11.654 | 4466.9 samples/s | 69.8 steps/s
[Step=60900 Epoch=118.8] | Loss=0.00522 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=11.656 | 4324.9 samples/s | 67.6 steps/s
[Step=60950 Epoch=118.9] | Loss=0.00527 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.967 | L2-Norm(final)=11.659 | 4507.1 samples/s | 70.4 steps/s
[Step=61000 Epoch=119.0] | Loss=0.00535 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.967 | L2-Norm(final)=11.662 | 5765.4 samples/s | 90.1 steps/s
[Step=61050 Epoch=119.1] | Loss=0.00521 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.966 | L2-Norm(final)=11.664 | 2420.0 samples/s | 37.8 steps/s
[Step=61100 Epoch=119.2] | Loss=0.00509 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.965 | L2-Norm(final)=11.667 | 4334.4 samples/s | 67.7 steps/s
[Step=61150 Epoch=119.3] | Loss=0.00501 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.964 | L2-Norm(final)=11.669 | 4439.2 samples/s | 69.4 steps/s
[Step=61200 Epoch=119.4] | Loss=0.00499 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.964 | L2-Norm(final)=11.672 | 4467.6 samples/s | 69.8 steps/s
[Step=61250 Epoch=119.5] | Loss=0.00496 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.963 | L2-Norm(final)=11.675 | 4458.2 samples/s | 69.7 steps/s
[Step=61300 Epoch=119.6] | Loss=0.00494 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.962 | L2-Norm(final)=11.677 | 4385.1 samples/s | 68.5 steps/s
[Step=61350 Epoch=119.7] | Loss=0.00507 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.961 | L2-Norm(final)=11.679 | 4549.4 samples/s | 71.1 steps/s
[Step=61400 Epoch=119.8] | Loss=0.00513 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.960 | L2-Norm(final)=11.682 | 4375.0 samples/s | 68.4 steps/s
[Step=61450 Epoch=119.9] | Loss=0.00518 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.959 | L2-Norm(final)=11.684 | 4504.0 samples/s | 70.4 steps/s
[Step=61500 Epoch=119.9] | Loss=0.00517 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.958 | L2-Norm(final)=11.686 | 4780.0 samples/s | 74.7 steps/s
[Step=61550 Epoch=120.0] | Loss=0.00516 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.957 | L2-Norm(final)=11.689 | 2621.8 samples/s | 41.0 steps/s
[Step=61600 Epoch=120.1] | Loss=0.00511 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.956 | L2-Norm(final)=11.691 | 4462.8 samples/s | 69.7 steps/s
[Step=61650 Epoch=120.2] | Loss=0.00510 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.955 | L2-Norm(final)=11.693 | 4462.4 samples/s | 69.7 steps/s
[Step=61700 Epoch=120.3] | Loss=0.00507 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.954 | L2-Norm(final)=11.696 | 4320.8 samples/s | 67.5 steps/s
[Step=61750 Epoch=120.4] | Loss=0.00507 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.953 | L2-Norm(final)=11.698 | 4492.6 samples/s | 70.2 steps/s
[Step=61800 Epoch=120.5] | Loss=0.00508 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.952 | L2-Norm(final)=11.700 | 4495.3 samples/s | 70.2 steps/s
[Step=61850 Epoch=120.6] | Loss=0.00505 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.951 | L2-Norm(final)=11.703 | 4428.3 samples/s | 69.2 steps/s
[Step=61900 Epoch=120.7] | Loss=0.00504 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.950 | L2-Norm(final)=11.705 | 4441.3 samples/s | 69.4 steps/s
[Step=61950 Epoch=120.8] | Loss=0.00505 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.948 | L2-Norm(final)=11.707 | 4518.2 samples/s | 70.6 steps/s
[Step=62000 Epoch=120.9] | Loss=0.00499 | Reg=0.00287 | acc=0.9688 | L2-Norm=16.947 | L2-Norm(final)=11.710 | 4496.2 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step62000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=117.3] | Loss=0.00316 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.070 | L2-Norm(final)=11.710 | 5863.2 samples/s | 91.6 steps/s
[Step=60050 Epoch=117.4] | Loss=0.00433 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.069 | L2-Norm(final)=11.713 | 4438.0 samples/s | 69.3 steps/s
[Step=60100 Epoch=117.5] | Loss=0.00455 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.069 | L2-Norm(final)=11.715 | 4876.5 samples/s | 76.2 steps/s
[Step=60150 Epoch=117.6] | Loss=0.00453 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.068 | L2-Norm(final)=11.718 | 5091.4 samples/s | 79.6 steps/s
[Step=60200 Epoch=117.7] | Loss=0.00482 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.067 | L2-Norm(final)=11.721 | 4944.7 samples/s | 77.3 steps/s
[Step=60250 Epoch=117.8] | Loss=0.00479 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.067 | L2-Norm(final)=11.724 | 5078.8 samples/s | 79.4 steps/s
[Step=60300 Epoch=117.9] | Loss=0.00456 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.066 | L2-Norm(final)=11.727 | 5044.7 samples/s | 78.8 steps/s
[Step=60350 Epoch=118.0] | Loss=0.00461 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.065 | L2-Norm(final)=11.730 | 4976.5 samples/s | 77.8 steps/s
[Step=60400 Epoch=118.1] | Loss=0.00465 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.064 | L2-Norm(final)=11.733 | 5055.8 samples/s | 79.0 steps/s
[Step=60450 Epoch=118.2] | Loss=0.00466 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.063 | L2-Norm(final)=11.736 | 5015.7 samples/s | 78.4 steps/s
[Step=60500 Epoch=118.3] | Loss=0.00460 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.062 | L2-Norm(final)=11.739 | 6848.0 samples/s | 107.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=118.3] | Loss=0.00493 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.053 | L2-Norm(final)=11.772 | 6098.2 samples/s | 95.3 steps/s
[Step=60550 Epoch=118.4] | Loss=0.00446 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.053 | L2-Norm(final)=11.775 | 4097.4 samples/s | 64.0 steps/s
[Step=60600 Epoch=118.5] | Loss=0.00488 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.053 | L2-Norm(final)=11.778 | 4423.7 samples/s | 69.1 steps/s
[Step=60650 Epoch=118.6] | Loss=0.00447 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.053 | L2-Norm(final)=11.781 | 4534.6 samples/s | 70.9 steps/s
[Step=60700 Epoch=118.7] | Loss=0.00472 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.052 | L2-Norm(final)=11.783 | 4444.0 samples/s | 69.4 steps/s
[Step=60750 Epoch=118.8] | Loss=0.00515 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.052 | L2-Norm(final)=11.786 | 4444.1 samples/s | 69.4 steps/s
[Step=60800 Epoch=118.9] | Loss=0.00517 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.051 | L2-Norm(final)=11.789 | 4470.7 samples/s | 69.9 steps/s
[Step=60850 Epoch=119.0] | Loss=0.00534 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.051 | L2-Norm(final)=11.791 | 4495.0 samples/s | 70.2 steps/s
[Step=60900 Epoch=119.1] | Loss=0.00528 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.050 | L2-Norm(final)=11.794 | 4369.9 samples/s | 68.3 steps/s
[Step=60950 Epoch=119.2] | Loss=0.00533 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.050 | L2-Norm(final)=11.797 | 4474.8 samples/s | 69.9 steps/s
[Step=61000 Epoch=119.3] | Loss=0.00524 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.050 | L2-Norm(final)=11.800 | 5834.7 samples/s | 91.2 steps/s
[Step=61050 Epoch=119.4] | Loss=0.00516 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.049 | L2-Norm(final)=11.802 | 2423.1 samples/s | 37.9 steps/s
[Step=61100 Epoch=119.4] | Loss=0.00523 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.049 | L2-Norm(final)=11.805 | 4384.4 samples/s | 68.5 steps/s
[Step=61150 Epoch=119.5] | Loss=0.00516 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.048 | L2-Norm(final)=11.807 | 4417.9 samples/s | 69.0 steps/s
[Step=61200 Epoch=119.6] | Loss=0.00512 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.048 | L2-Norm(final)=11.810 | 4500.8 samples/s | 70.3 steps/s
[Step=61250 Epoch=119.7] | Loss=0.00505 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.047 | L2-Norm(final)=11.812 | 4418.2 samples/s | 69.0 steps/s
[Step=61300 Epoch=119.8] | Loss=0.00508 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.046 | L2-Norm(final)=11.815 | 4397.2 samples/s | 68.7 steps/s
[Step=61350 Epoch=119.9] | Loss=0.00500 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.045 | L2-Norm(final)=11.817 | 4490.4 samples/s | 70.2 steps/s
[Step=61400 Epoch=120.0] | Loss=0.00504 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.045 | L2-Norm(final)=11.820 | 4432.8 samples/s | 69.3 steps/s
[Step=61450 Epoch=120.1] | Loss=0.00503 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.044 | L2-Norm(final)=11.822 | 4448.2 samples/s | 69.5 steps/s
[Step=61500 Epoch=120.2] | Loss=0.00503 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.043 | L2-Norm(final)=11.824 | 4886.8 samples/s | 76.4 steps/s
[Step=61550 Epoch=120.3] | Loss=0.00500 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.042 | L2-Norm(final)=11.827 | 2582.0 samples/s | 40.3 steps/s
[Step=61600 Epoch=120.4] | Loss=0.00499 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.041 | L2-Norm(final)=11.829 | 4469.5 samples/s | 69.8 steps/s
[Step=61650 Epoch=120.5] | Loss=0.00489 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.040 | L2-Norm(final)=11.832 | 4469.7 samples/s | 69.8 steps/s
[Step=61700 Epoch=120.6] | Loss=0.00484 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.039 | L2-Norm(final)=11.834 | 4329.2 samples/s | 67.6 steps/s
[Step=61750 Epoch=120.7] | Loss=0.00489 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.038 | L2-Norm(final)=11.836 | 4448.7 samples/s | 69.5 steps/s
[Step=61800 Epoch=120.8] | Loss=0.00488 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.037 | L2-Norm(final)=11.839 | 4455.1 samples/s | 69.6 steps/s
[Step=61850 Epoch=120.9] | Loss=0.00484 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.037 | L2-Norm(final)=11.841 | 4509.1 samples/s | 70.5 steps/s
[Step=61900 Epoch=121.0] | Loss=0.00484 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.036 | L2-Norm(final)=11.843 | 4477.4 samples/s | 70.0 steps/s
[Step=61950 Epoch=121.1] | Loss=0.00483 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.035 | L2-Norm(final)=11.846 | 4409.9 samples/s | 68.9 steps/s
[Step=62000 Epoch=121.2] | Loss=0.00484 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.034 | L2-Norm(final)=11.848 | 4547.8 samples/s | 71.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step62000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=229.9] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.109 | 5473.9 samples/s | 85.5 steps/s
[Step=60050 Epoch=230.1] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.114 | 4205.8 samples/s | 65.7 steps/s
[Step=60100 Epoch=230.3] | Loss=0.00004 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.119 | 4670.5 samples/s | 73.0 steps/s
[Step=60150 Epoch=230.5] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.999 | L2-Norm(final)=7.124 | 4719.6 samples/s | 73.7 steps/s
[Step=60200 Epoch=230.7] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.000 | L2-Norm(final)=7.128 | 4755.5 samples/s | 74.3 steps/s
[Step=60250 Epoch=230.9] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.000 | L2-Norm(final)=7.132 | 6605.9 samples/s | 103.2 steps/s
[Step=60300 Epoch=231.0] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=7.136 | 2405.6 samples/s | 37.6 steps/s
[Step=60350 Epoch=231.2] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.002 | L2-Norm(final)=7.140 | 4708.6 samples/s | 73.6 steps/s
[Step=60400 Epoch=231.4] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.002 | L2-Norm(final)=7.144 | 4585.8 samples/s | 71.7 steps/s
[Step=60450 Epoch=231.6] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.003 | L2-Norm(final)=7.148 | 4716.4 samples/s | 73.7 steps/s
[Step=60500 Epoch=231.8] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.003 | L2-Norm(final)=7.152 | 5486.1 samples/s | 85.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=231.8] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.006 | L2-Norm(final)=7.190 | 6410.7 samples/s | 100.2 steps/s
[Step=60550 Epoch=232.0] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.002 | L2-Norm(final)=7.193 | 3706.1 samples/s | 57.9 steps/s
[Step=60600 Epoch=232.2] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.196 | 4216.8 samples/s | 65.9 steps/s
[Step=60650 Epoch=232.4] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.988 | L2-Norm(final)=7.199 | 4206.2 samples/s | 65.7 steps/s
[Step=60700 Epoch=232.6] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.980 | L2-Norm(final)=7.201 | 4243.1 samples/s | 66.3 steps/s
[Step=60750 Epoch=232.8] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.973 | L2-Norm(final)=7.204 | 5615.6 samples/s | 87.7 steps/s
[Step=60800 Epoch=233.0] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.965 | L2-Norm(final)=7.206 | 2284.8 samples/s | 35.7 steps/s
[Step=60850 Epoch=233.2] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.957 | L2-Norm(final)=7.208 | 4122.8 samples/s | 64.4 steps/s
[Step=60900 Epoch=233.3] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.949 | L2-Norm(final)=7.209 | 4277.5 samples/s | 66.8 steps/s
[Step=60950 Epoch=233.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.940 | L2-Norm(final)=7.211 | 4262.5 samples/s | 66.6 steps/s
[Step=61000 Epoch=233.7] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.932 | L2-Norm(final)=7.213 | 4714.3 samples/s | 73.7 steps/s
[Step=61050 Epoch=233.9] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.923 | L2-Norm(final)=7.214 | 2456.7 samples/s | 38.4 steps/s
[Step=61100 Epoch=234.1] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.914 | L2-Norm(final)=7.216 | 4182.4 samples/s | 65.3 steps/s
[Step=61150 Epoch=234.3] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.905 | L2-Norm(final)=7.217 | 4251.8 samples/s | 66.4 steps/s
[Step=61200 Epoch=234.5] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.896 | L2-Norm(final)=7.218 | 4238.2 samples/s | 66.2 steps/s
[Step=61250 Epoch=234.7] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.886 | L2-Norm(final)=7.220 | 4239.3 samples/s | 66.2 steps/s
[Step=61300 Epoch=234.9] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.877 | L2-Norm(final)=7.221 | 2655.6 samples/s | 41.5 steps/s
[Step=61350 Epoch=235.1] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.867 | L2-Norm(final)=7.222 | 4159.4 samples/s | 65.0 steps/s
[Step=61400 Epoch=235.3] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.858 | L2-Norm(final)=7.223 | 4235.7 samples/s | 66.2 steps/s
[Step=61450 Epoch=235.5] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.848 | L2-Norm(final)=7.225 | 4236.6 samples/s | 66.2 steps/s
[Step=61500 Epoch=235.6] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.838 | L2-Norm(final)=7.226 | 4126.6 samples/s | 64.5 steps/s
[Step=61550 Epoch=235.8] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.828 | L2-Norm(final)=7.227 | 2647.1 samples/s | 41.4 steps/s
[Step=61600 Epoch=236.0] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.818 | L2-Norm(final)=7.229 | 4188.5 samples/s | 65.4 steps/s
[Step=61650 Epoch=236.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.807 | L2-Norm(final)=7.230 | 4271.0 samples/s | 66.7 steps/s
[Step=61700 Epoch=236.4] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.797 | L2-Norm(final)=7.232 | 4192.6 samples/s | 65.5 steps/s
[Step=61750 Epoch=236.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.786 | L2-Norm(final)=7.233 | 4283.3 samples/s | 66.9 steps/s
[Step=61800 Epoch=236.8] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.776 | L2-Norm(final)=7.234 | 6173.3 samples/s | 96.5 steps/s
[Step=61850 Epoch=237.0] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.765 | L2-Norm(final)=7.236 | 2155.1 samples/s | 33.7 steps/s
[Step=61900 Epoch=237.2] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.754 | L2-Norm(final)=7.237 | 4258.6 samples/s | 66.5 steps/s
[Step=61950 Epoch=237.4] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.743 | L2-Norm(final)=7.238 | 4206.1 samples/s | 65.7 steps/s
[Step=62000 Epoch=237.6] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.732 | L2-Norm(final)=7.240 | 4209.0 samples/s | 65.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step62000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=231.0] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.938 | L2-Norm(final)=7.720 | 5842.2 samples/s | 91.3 steps/s
[Step=60050 Epoch=231.2] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.937 | L2-Norm(final)=7.723 | 4310.5 samples/s | 67.4 steps/s
[Step=60100 Epoch=231.3] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.938 | L2-Norm(final)=7.728 | 4700.3 samples/s | 73.4 steps/s
[Step=60150 Epoch=231.5] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.939 | L2-Norm(final)=7.732 | 4765.9 samples/s | 74.5 steps/s
[Step=60200 Epoch=231.7] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.940 | L2-Norm(final)=7.737 | 4585.1 samples/s | 71.6 steps/s
[Step=60250 Epoch=231.9] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.941 | L2-Norm(final)=7.741 | 6832.3 samples/s | 106.8 steps/s
[Step=60300 Epoch=232.1] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.942 | L2-Norm(final)=7.745 | 2402.5 samples/s | 37.5 steps/s
[Step=60350 Epoch=232.3] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=7.749 | 4737.7 samples/s | 74.0 steps/s
[Step=60400 Epoch=232.5] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=7.753 | 4741.2 samples/s | 74.1 steps/s
[Step=60450 Epoch=232.7] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=7.758 | 4754.9 samples/s | 74.3 steps/s
[Step=60500 Epoch=232.9] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=7.762 | 5508.1 samples/s | 86.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=232.9] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.950 | L2-Norm(final)=7.802 | 6067.3 samples/s | 94.8 steps/s
[Step=60550 Epoch=233.1] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.948 | L2-Norm(final)=7.806 | 3859.2 samples/s | 60.3 steps/s
[Step=60600 Epoch=233.3] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=7.810 | 4108.1 samples/s | 64.2 steps/s
[Step=60650 Epoch=233.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.939 | L2-Norm(final)=7.812 | 4283.4 samples/s | 66.9 steps/s
[Step=60700 Epoch=233.7] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.933 | L2-Norm(final)=7.814 | 4290.7 samples/s | 67.0 steps/s
[Step=60750 Epoch=233.9] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.928 | L2-Norm(final)=7.816 | 5665.9 samples/s | 88.5 steps/s
[Step=60800 Epoch=234.0] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.922 | L2-Norm(final)=7.818 | 2256.2 samples/s | 35.3 steps/s
[Step=60850 Epoch=234.2] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.916 | L2-Norm(final)=7.820 | 4192.3 samples/s | 65.5 steps/s
[Step=60900 Epoch=234.4] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.910 | L2-Norm(final)=7.822 | 4131.5 samples/s | 64.6 steps/s
[Step=60950 Epoch=234.6] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.903 | L2-Norm(final)=7.823 | 4222.4 samples/s | 66.0 steps/s
[Step=61000 Epoch=234.8] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.897 | L2-Norm(final)=7.825 | 4973.2 samples/s | 77.7 steps/s
[Step=61050 Epoch=235.0] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.890 | L2-Norm(final)=7.826 | 2431.8 samples/s | 38.0 steps/s
[Step=61100 Epoch=235.2] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.884 | L2-Norm(final)=7.827 | 4162.3 samples/s | 65.0 steps/s
[Step=61150 Epoch=235.4] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.877 | L2-Norm(final)=7.829 | 4353.2 samples/s | 68.0 steps/s
[Step=61200 Epoch=235.6] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.870 | L2-Norm(final)=7.830 | 4136.9 samples/s | 64.6 steps/s
[Step=61250 Epoch=235.8] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.863 | L2-Norm(final)=7.831 | 4296.5 samples/s | 67.1 steps/s
[Step=61300 Epoch=236.0] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.856 | L2-Norm(final)=7.833 | 2539.1 samples/s | 39.7 steps/s
[Step=61350 Epoch=236.2] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.849 | L2-Norm(final)=7.834 | 4249.1 samples/s | 66.4 steps/s
[Step=61400 Epoch=236.4] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.841 | L2-Norm(final)=7.836 | 4313.7 samples/s | 67.4 steps/s
[Step=61450 Epoch=236.5] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.834 | L2-Norm(final)=7.837 | 4230.2 samples/s | 66.1 steps/s
[Step=61500 Epoch=236.7] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.827 | L2-Norm(final)=7.838 | 4146.0 samples/s | 64.8 steps/s
[Step=61550 Epoch=236.9] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.819 | L2-Norm(final)=7.839 | 2663.8 samples/s | 41.6 steps/s
[Step=61600 Epoch=237.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=7.841 | 4128.6 samples/s | 64.5 steps/s
[Step=61650 Epoch=237.3] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.804 | L2-Norm(final)=7.842 | 4192.9 samples/s | 65.5 steps/s
[Step=61700 Epoch=237.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.796 | L2-Norm(final)=7.844 | 4193.7 samples/s | 65.5 steps/s
[Step=61750 Epoch=237.7] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.788 | L2-Norm(final)=7.845 | 4243.9 samples/s | 66.3 steps/s
[Step=61800 Epoch=237.9] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.780 | L2-Norm(final)=7.846 | 6925.0 samples/s | 108.2 steps/s
[Step=61850 Epoch=238.1] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.772 | L2-Norm(final)=7.848 | 2135.6 samples/s | 33.4 steps/s
[Step=61900 Epoch=238.3] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.763 | L2-Norm(final)=7.849 | 4259.4 samples/s | 66.6 steps/s
[Step=61950 Epoch=238.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.755 | L2-Norm(final)=7.850 | 4153.8 samples/s | 64.9 steps/s
[Step=62000 Epoch=238.7] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.747 | L2-Norm(final)=7.852 | 4146.7 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07942 | acc=0.9676 | tpr=0.9718 | fpr=0.0416 | 4764.5 samples/s | 18.6 steps/s
Avg test loss: 0.08096, Avg test acc: 0.96718, Avg tpr: 0.97191, Avg fpr: 0.04320, total FA: 337

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08109 | acc=0.9679 | tpr=0.9773 | fpr=0.0525 | 5017.8 samples/s | 19.6 steps/s
Avg test loss: 0.08313, Avg test acc: 0.96751, Avg tpr: 0.97727, Avg fpr: 0.05397, total FA: 421

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.32656 | acc=0.3045 | tpr=0.0121 | fpr=0.0605 | 5152.5 samples/s | 20.1 steps/s
Avg test loss: 5.32219, Avg test acc: 0.30107, Avg tpr: 0.01306, Avg fpr: 0.06550, total FA: 511

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.57478 | acc=0.3093 | tpr=0.0216 | fpr=0.0659 | 5081.2 samples/s | 19.8 steps/s
Avg test loss: 5.55896, Avg test acc: 0.30668, Avg tpr: 0.02366, Avg fpr: 0.07089, total FA: 553

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.69864 | acc=0.1526 | tpr=0.5000 | fpr=0.8537 | 4876.9 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.66304 | acc=0.1525 | tpr=0.4776 | fpr=0.8536 | 7237.6 samples/s | 28.3 steps/s
[Step= 150] | Loss=6.66437 | acc=0.1526 | tpr=0.4755 | fpr=0.8533 | 7694.3 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.65837 | acc=0.1537 | tpr=0.4765 | fpr=0.8522 | 8073.6 samples/s | 31.5 steps/s
[Step= 250] | Loss=6.64732 | acc=0.1542 | tpr=0.4795 | fpr=0.8517 | 7599.9 samples/s | 29.7 steps/s
[Step= 300] | Loss=6.63630 | acc=0.1546 | tpr=0.4785 | fpr=0.8513 | 8049.3 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.63913 | acc=0.1541 | tpr=0.4678 | fpr=0.8516 | 7720.2 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.63772 | acc=0.1541 | tpr=0.4655 | fpr=0.8516 | 7893.8 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.64117 | acc=0.1539 | tpr=0.4649 | fpr=0.8517 | 7925.9 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.64262 | acc=0.1544 | tpr=0.4656 | fpr=0.8512 | 7547.0 samples/s | 29.5 steps/s
[Step= 550] | Loss=6.64654 | acc=0.1547 | tpr=0.4648 | fpr=0.8510 | 14652.3 samples/s | 57.2 steps/s
Avg test loss: 6.64821, Avg test acc: 0.15459, Avg tpr: 0.46632, Avg fpr: 0.85107, total FA: 118170

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.94820 | acc=0.1206 | tpr=0.5885 | fpr=0.8878 | 4763.1 samples/s | 18.6 steps/s
[Step= 100] | Loss=7.93215 | acc=0.1214 | tpr=0.5480 | fpr=0.8865 | 7404.9 samples/s | 28.9 steps/s
[Step= 150] | Loss=7.92906 | acc=0.1220 | tpr=0.5418 | fpr=0.8858 | 7900.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=7.92430 | acc=0.1219 | tpr=0.5388 | fpr=0.8857 | 7675.7 samples/s | 30.0 steps/s
[Step= 250] | Loss=7.91168 | acc=0.1217 | tpr=0.5380 | fpr=0.8859 | 7661.4 samples/s | 29.9 steps/s
[Step= 300] | Loss=7.90305 | acc=0.1221 | tpr=0.5375 | fpr=0.8855 | 8097.2 samples/s | 31.6 steps/s
[Step= 350] | Loss=7.90886 | acc=0.1216 | tpr=0.5291 | fpr=0.8858 | 8074.0 samples/s | 31.5 steps/s
[Step= 400] | Loss=7.90700 | acc=0.1215 | tpr=0.5191 | fpr=0.8858 | 7771.6 samples/s | 30.4 steps/s
[Step= 450] | Loss=7.91184 | acc=0.1211 | tpr=0.5146 | fpr=0.8861 | 7674.3 samples/s | 30.0 steps/s
[Step= 500] | Loss=7.91533 | acc=0.1214 | tpr=0.5194 | fpr=0.8857 | 7742.5 samples/s | 30.2 steps/s
[Step= 550] | Loss=7.92034 | acc=0.1214 | tpr=0.5205 | fpr=0.8858 | 14237.7 samples/s | 55.6 steps/s
Avg test loss: 7.92284, Avg test acc: 0.12127, Avg tpr: 0.52179, Avg fpr: 0.88601, total FA: 123021

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12675 | acc=0.9777 | tpr=0.9425 | fpr=0.0217 | 4987.7 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.12799 | acc=0.9785 | tpr=0.9510 | fpr=0.0210 | 7185.4 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.13357 | acc=0.9776 | tpr=0.9510 | fpr=0.0219 | 7657.6 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.13708 | acc=0.9776 | tpr=0.9530 | fpr=0.0220 | 7823.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.13455 | acc=0.9778 | tpr=0.9528 | fpr=0.0217 | 7699.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.13630 | acc=0.9775 | tpr=0.9527 | fpr=0.0220 | 7631.3 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.13638 | acc=0.9774 | tpr=0.9543 | fpr=0.0221 | 8244.1 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.13780 | acc=0.9773 | tpr=0.9530 | fpr=0.0222 | 7652.2 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.14026 | acc=0.9770 | tpr=0.9508 | fpr=0.0225 | 7845.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.13947 | acc=0.9770 | tpr=0.9524 | fpr=0.0225 | 7813.8 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13811 | acc=0.9773 | tpr=0.9534 | fpr=0.0223 | 13907.8 samples/s | 54.3 steps/s
Avg test loss: 0.13795, Avg test acc: 0.97727, Avg tpr: 0.95325, Avg fpr: 0.02229, total FA: 3095

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12667 | acc=0.9770 | tpr=0.9469 | fpr=0.0225 | 4922.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.12829 | acc=0.9771 | tpr=0.9531 | fpr=0.0224 | 7018.0 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.13490 | acc=0.9764 | tpr=0.9568 | fpr=0.0233 | 7835.2 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.13786 | acc=0.9761 | tpr=0.9574 | fpr=0.0236 | 8014.4 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.13582 | acc=0.9763 | tpr=0.9546 | fpr=0.0233 | 7884.9 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.13788 | acc=0.9762 | tpr=0.9542 | fpr=0.0234 | 7671.7 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.13814 | acc=0.9761 | tpr=0.9562 | fpr=0.0235 | 7923.4 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.13935 | acc=0.9761 | tpr=0.9535 | fpr=0.0235 | 7749.8 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.14193 | acc=0.9758 | tpr=0.9508 | fpr=0.0237 | 8042.6 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.14133 | acc=0.9759 | tpr=0.9515 | fpr=0.0237 | 8101.4 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.13979 | acc=0.9762 | tpr=0.9522 | fpr=0.0234 | 12996.5 samples/s | 50.8 steps/s
Avg test loss: 0.13966, Avg test acc: 0.97619, Avg tpr: 0.95206, Avg fpr: 0.02337, total FA: 3245

server round 31/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=120.9] | Loss=0.00420 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.755 | L2-Norm(final)=11.779 | 6169.5 samples/s | 96.4 steps/s
[Step=62050 Epoch=121.0] | Loss=0.00505 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.755 | L2-Norm(final)=11.782 | 4521.0 samples/s | 70.6 steps/s
[Step=62100 Epoch=121.1] | Loss=0.00483 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.756 | L2-Norm(final)=11.786 | 4975.6 samples/s | 77.7 steps/s
[Step=62150 Epoch=121.2] | Loss=0.00504 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.755 | L2-Norm(final)=11.790 | 5026.4 samples/s | 78.5 steps/s
[Step=62200 Epoch=121.3] | Loss=0.00498 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.755 | L2-Norm(final)=11.794 | 5034.1 samples/s | 78.7 steps/s
[Step=62250 Epoch=121.4] | Loss=0.00476 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.755 | L2-Norm(final)=11.798 | 5018.1 samples/s | 78.4 steps/s
[Step=62300 Epoch=121.5] | Loss=0.00475 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.754 | L2-Norm(final)=11.802 | 5060.1 samples/s | 79.1 steps/s
[Step=62350 Epoch=121.6] | Loss=0.00469 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.753 | L2-Norm(final)=11.806 | 5025.5 samples/s | 78.5 steps/s
[Step=62400 Epoch=121.7] | Loss=0.00474 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.752 | L2-Norm(final)=11.810 | 5113.7 samples/s | 79.9 steps/s
[Step=62450 Epoch=121.8] | Loss=0.00487 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=11.814 | 5013.8 samples/s | 78.3 steps/s
[Step=62500 Epoch=121.9] | Loss=0.00473 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=11.819 | 6703.3 samples/s | 104.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=121.9] | Loss=0.00532 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.742 | L2-Norm(final)=11.862 | 5961.1 samples/s | 93.1 steps/s
[Step=62550 Epoch=122.0] | Loss=0.00438 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.742 | L2-Norm(final)=11.866 | 4157.1 samples/s | 65.0 steps/s
[Step=62600 Epoch=122.1] | Loss=0.00463 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.743 | L2-Norm(final)=11.870 | 4496.2 samples/s | 70.3 steps/s
[Step=62650 Epoch=122.2] | Loss=0.00566 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.743 | L2-Norm(final)=11.874 | 4460.4 samples/s | 69.7 steps/s
[Step=62700 Epoch=122.3] | Loss=0.00571 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=11.877 | 4462.3 samples/s | 69.7 steps/s
[Step=62750 Epoch=122.4] | Loss=0.00585 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.745 | L2-Norm(final)=11.881 | 4462.5 samples/s | 69.7 steps/s
[Step=62800 Epoch=122.5] | Loss=0.00580 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.746 | L2-Norm(final)=11.885 | 4508.4 samples/s | 70.4 steps/s
[Step=62850 Epoch=122.6] | Loss=0.00584 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=11.888 | 4451.7 samples/s | 69.6 steps/s
[Step=62900 Epoch=122.7] | Loss=0.00579 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=11.892 | 4483.8 samples/s | 70.1 steps/s
[Step=62950 Epoch=122.8] | Loss=0.00583 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=11.896 | 4425.4 samples/s | 69.1 steps/s
[Step=63000 Epoch=122.9] | Loss=0.00599 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=11.900 | 5667.4 samples/s | 88.6 steps/s
[Step=63050 Epoch=123.0] | Loss=0.00580 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=11.904 | 2415.8 samples/s | 37.7 steps/s
[Step=63100 Epoch=123.1] | Loss=0.00573 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=11.908 | 4527.9 samples/s | 70.7 steps/s
[Step=63150 Epoch=123.2] | Loss=0.00573 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=11.911 | 4380.0 samples/s | 68.4 steps/s
[Step=63200 Epoch=123.3] | Loss=0.00571 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=11.915 | 4432.3 samples/s | 69.3 steps/s
[Step=63250 Epoch=123.4] | Loss=0.00568 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.750 | L2-Norm(final)=11.918 | 4530.2 samples/s | 70.8 steps/s
[Step=63300 Epoch=123.5] | Loss=0.00569 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=11.921 | 4362.1 samples/s | 68.2 steps/s
[Step=63350 Epoch=123.6] | Loss=0.00560 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=11.925 | 4410.1 samples/s | 68.9 steps/s
[Step=63400 Epoch=123.7] | Loss=0.00560 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=11.928 | 4481.0 samples/s | 70.0 steps/s
[Step=63450 Epoch=123.8] | Loss=0.00573 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=11.931 | 4510.8 samples/s | 70.5 steps/s
[Step=63500 Epoch=123.8] | Loss=0.00563 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=11.934 | 4789.0 samples/s | 74.8 steps/s
[Step=63550 Epoch=123.9] | Loss=0.00558 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.748 | L2-Norm(final)=11.937 | 2615.4 samples/s | 40.9 steps/s
[Step=63600 Epoch=124.0] | Loss=0.00555 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=11.940 | 4505.1 samples/s | 70.4 steps/s
[Step=63650 Epoch=124.1] | Loss=0.00553 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=11.943 | 4430.0 samples/s | 69.2 steps/s
[Step=63700 Epoch=124.2] | Loss=0.00543 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.746 | L2-Norm(final)=11.946 | 4405.1 samples/s | 68.8 steps/s
[Step=63750 Epoch=124.3] | Loss=0.00543 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.746 | L2-Norm(final)=11.949 | 4413.6 samples/s | 69.0 steps/s
[Step=63800 Epoch=124.4] | Loss=0.00541 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.745 | L2-Norm(final)=11.952 | 4501.4 samples/s | 70.3 steps/s
[Step=63850 Epoch=124.5] | Loss=0.00535 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=11.955 | 4473.1 samples/s | 69.9 steps/s
[Step=63900 Epoch=124.6] | Loss=0.00533 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=11.958 | 4475.8 samples/s | 69.9 steps/s
[Step=63950 Epoch=124.7] | Loss=0.00534 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.743 | L2-Norm(final)=11.961 | 4506.7 samples/s | 70.4 steps/s
[Step=64000 Epoch=124.8] | Loss=0.00535 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.742 | L2-Norm(final)=11.964 | 4417.4 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step64000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=121.2] | Loss=0.00160 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.847 | L2-Norm(final)=11.920 | 5835.2 samples/s | 91.2 steps/s
[Step=62050 Epoch=121.3] | Loss=0.00587 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=11.923 | 4558.5 samples/s | 71.2 steps/s
[Step=62100 Epoch=121.4] | Loss=0.00463 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=11.926 | 5180.2 samples/s | 80.9 steps/s
[Step=62150 Epoch=121.5] | Loss=0.00463 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=11.929 | 4873.8 samples/s | 76.2 steps/s
[Step=62200 Epoch=121.6] | Loss=0.00466 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=11.932 | 4984.1 samples/s | 77.9 steps/s
[Step=62250 Epoch=121.7] | Loss=0.00476 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.844 | L2-Norm(final)=11.936 | 5030.7 samples/s | 78.6 steps/s
[Step=62300 Epoch=121.8] | Loss=0.00459 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.844 | L2-Norm(final)=11.940 | 5029.2 samples/s | 78.6 steps/s
[Step=62350 Epoch=121.9] | Loss=0.00458 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.843 | L2-Norm(final)=11.944 | 5059.1 samples/s | 79.0 steps/s
[Step=62400 Epoch=122.0] | Loss=0.00451 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.843 | L2-Norm(final)=11.949 | 5116.8 samples/s | 79.9 steps/s
[Step=62450 Epoch=122.1] | Loss=0.00463 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=11.953 | 4946.2 samples/s | 77.3 steps/s
[Step=62500 Epoch=122.2] | Loss=0.00473 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=11.957 | 6947.1 samples/s | 108.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=122.2] | Loss=0.00249 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.837 | L2-Norm(final)=12.001 | 5529.7 samples/s | 86.4 steps/s
[Step=62550 Epoch=122.3] | Loss=0.00485 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.837 | L2-Norm(final)=12.005 | 4412.4 samples/s | 68.9 steps/s
[Step=62600 Epoch=122.4] | Loss=0.00539 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.838 | L2-Norm(final)=12.008 | 4449.8 samples/s | 69.5 steps/s
[Step=62650 Epoch=122.5] | Loss=0.00553 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.839 | L2-Norm(final)=12.012 | 4633.4 samples/s | 72.4 steps/s
[Step=62700 Epoch=122.6] | Loss=0.00561 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.840 | L2-Norm(final)=12.015 | 4301.3 samples/s | 67.2 steps/s
[Step=62750 Epoch=122.7] | Loss=0.00601 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.841 | L2-Norm(final)=12.018 | 4471.8 samples/s | 69.9 steps/s
[Step=62800 Epoch=122.8] | Loss=0.00592 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=12.021 | 4488.8 samples/s | 70.1 steps/s
[Step=62850 Epoch=122.9] | Loss=0.00577 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=12.025 | 4491.6 samples/s | 70.2 steps/s
[Step=62900 Epoch=123.0] | Loss=0.00582 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.843 | L2-Norm(final)=12.029 | 4429.3 samples/s | 69.2 steps/s
[Step=62950 Epoch=123.1] | Loss=0.00585 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.844 | L2-Norm(final)=12.032 | 4437.8 samples/s | 69.3 steps/s
[Step=63000 Epoch=123.2] | Loss=0.00586 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.845 | L2-Norm(final)=12.036 | 5867.9 samples/s | 91.7 steps/s
[Step=63050 Epoch=123.3] | Loss=0.00579 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=12.039 | 2393.0 samples/s | 37.4 steps/s
[Step=63100 Epoch=123.4] | Loss=0.00572 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.846 | L2-Norm(final)=12.043 | 4437.7 samples/s | 69.3 steps/s
[Step=63150 Epoch=123.5] | Loss=0.00565 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=12.046 | 4503.0 samples/s | 70.4 steps/s
[Step=63200 Epoch=123.6] | Loss=0.00559 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=12.050 | 4427.5 samples/s | 69.2 steps/s
[Step=63250 Epoch=123.7] | Loss=0.00556 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=12.053 | 4493.9 samples/s | 70.2 steps/s
[Step=63300 Epoch=123.7] | Loss=0.00556 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=12.056 | 4379.1 samples/s | 68.4 steps/s
[Step=63350 Epoch=123.8] | Loss=0.00560 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=12.059 | 4493.9 samples/s | 70.2 steps/s
[Step=63400 Epoch=123.9] | Loss=0.00559 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=12.062 | 4410.9 samples/s | 68.9 steps/s
[Step=63450 Epoch=124.0] | Loss=0.00554 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=12.065 | 4498.9 samples/s | 70.3 steps/s
[Step=63500 Epoch=124.1] | Loss=0.00548 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=12.068 | 4954.0 samples/s | 77.4 steps/s
[Step=63550 Epoch=124.2] | Loss=0.00540 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.844 | L2-Norm(final)=12.071 | 2565.5 samples/s | 40.1 steps/s
[Step=63600 Epoch=124.3] | Loss=0.00533 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.844 | L2-Norm(final)=12.074 | 4517.6 samples/s | 70.6 steps/s
[Step=63650 Epoch=124.4] | Loss=0.00525 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.843 | L2-Norm(final)=12.077 | 4516.5 samples/s | 70.6 steps/s
[Step=63700 Epoch=124.5] | Loss=0.00522 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.842 | L2-Norm(final)=12.080 | 4269.6 samples/s | 66.7 steps/s
[Step=63750 Epoch=124.6] | Loss=0.00520 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=12.083 | 4466.9 samples/s | 69.8 steps/s
[Step=63800 Epoch=124.7] | Loss=0.00519 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.841 | L2-Norm(final)=12.085 | 4454.4 samples/s | 69.6 steps/s
[Step=63850 Epoch=124.8] | Loss=0.00521 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.840 | L2-Norm(final)=12.088 | 4426.1 samples/s | 69.2 steps/s
[Step=63900 Epoch=124.9] | Loss=0.00519 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.839 | L2-Norm(final)=12.091 | 4470.5 samples/s | 69.9 steps/s
[Step=63950 Epoch=125.0] | Loss=0.00513 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.839 | L2-Norm(final)=12.094 | 4498.8 samples/s | 70.3 steps/s
[Step=64000 Epoch=125.1] | Loss=0.00512 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.838 | L2-Norm(final)=12.096 | 4462.9 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step64000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=237.6] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.737 | L2-Norm(final)=7.283 | 5961.3 samples/s | 93.1 steps/s
[Step=62050 Epoch=237.8] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.733 | L2-Norm(final)=7.289 | 4055.8 samples/s | 63.4 steps/s
[Step=62100 Epoch=237.9] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.735 | L2-Norm(final)=7.298 | 4771.6 samples/s | 74.6 steps/s
[Step=62150 Epoch=238.1] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.737 | L2-Norm(final)=7.307 | 4750.1 samples/s | 74.2 steps/s
[Step=62200 Epoch=238.3] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.738 | L2-Norm(final)=7.315 | 4675.3 samples/s | 73.1 steps/s
[Step=62250 Epoch=238.5] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.739 | L2-Norm(final)=7.322 | 6692.9 samples/s | 104.6 steps/s
[Step=62300 Epoch=238.7] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.739 | L2-Norm(final)=7.328 | 2398.2 samples/s | 37.5 steps/s
[Step=62350 Epoch=238.9] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.740 | L2-Norm(final)=7.335 | 4731.9 samples/s | 73.9 steps/s
[Step=62400 Epoch=239.1] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.740 | L2-Norm(final)=7.341 | 4719.6 samples/s | 73.7 steps/s
[Step=62450 Epoch=239.3] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.740 | L2-Norm(final)=7.347 | 4753.6 samples/s | 74.3 steps/s
[Step=62500 Epoch=239.5] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.741 | L2-Norm(final)=7.354 | 5332.9 samples/s | 83.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=239.5] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.744 | L2-Norm(final)=7.417 | 6492.9 samples/s | 101.5 steps/s
[Step=62550 Epoch=239.7] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=7.424 | 3647.4 samples/s | 57.0 steps/s
[Step=62600 Epoch=239.9] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.719 | L2-Norm(final)=7.429 | 4337.4 samples/s | 67.8 steps/s
[Step=62650 Epoch=240.1] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.702 | L2-Norm(final)=7.434 | 4194.0 samples/s | 65.5 steps/s
[Step=62700 Epoch=240.2] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.684 | L2-Norm(final)=7.438 | 4345.9 samples/s | 67.9 steps/s
[Step=62750 Epoch=240.4] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.666 | L2-Norm(final)=7.441 | 5538.4 samples/s | 86.5 steps/s
[Step=62800 Epoch=240.6] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.649 | L2-Norm(final)=7.445 | 2236.2 samples/s | 34.9 steps/s
[Step=62850 Epoch=240.8] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.631 | L2-Norm(final)=7.448 | 4246.2 samples/s | 66.3 steps/s
[Step=62900 Epoch=241.0] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.613 | L2-Norm(final)=7.451 | 4251.5 samples/s | 66.4 steps/s
[Step=62950 Epoch=241.2] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.595 | L2-Norm(final)=7.454 | 4201.5 samples/s | 65.6 steps/s
[Step=63000 Epoch=241.4] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.576 | L2-Norm(final)=7.457 | 4834.7 samples/s | 75.5 steps/s
[Step=63050 Epoch=241.6] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.557 | L2-Norm(final)=7.460 | 2446.3 samples/s | 38.2 steps/s
[Step=63100 Epoch=241.8] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.538 | L2-Norm(final)=7.462 | 4309.0 samples/s | 67.3 steps/s
[Step=63150 Epoch=242.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.519 | L2-Norm(final)=7.464 | 4152.7 samples/s | 64.9 steps/s
[Step=63200 Epoch=242.2] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.499 | L2-Norm(final)=7.467 | 4165.9 samples/s | 65.1 steps/s
[Step=63250 Epoch=242.4] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.479 | L2-Norm(final)=7.469 | 4248.8 samples/s | 66.4 steps/s
[Step=63300 Epoch=242.5] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.459 | L2-Norm(final)=7.471 | 2620.6 samples/s | 40.9 steps/s
[Step=63350 Epoch=242.7] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.439 | L2-Norm(final)=7.474 | 4226.6 samples/s | 66.0 steps/s
[Step=63400 Epoch=242.9] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.419 | L2-Norm(final)=7.476 | 4239.7 samples/s | 66.2 steps/s
[Step=63450 Epoch=243.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.398 | L2-Norm(final)=7.479 | 4212.5 samples/s | 65.8 steps/s
[Step=63500 Epoch=243.3] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.378 | L2-Norm(final)=7.481 | 4200.4 samples/s | 65.6 steps/s
[Step=63550 Epoch=243.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.357 | L2-Norm(final)=7.484 | 2616.0 samples/s | 40.9 steps/s
[Step=63600 Epoch=243.7] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.336 | L2-Norm(final)=7.486 | 4154.6 samples/s | 64.9 steps/s
[Step=63650 Epoch=243.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.315 | L2-Norm(final)=7.489 | 4285.5 samples/s | 67.0 steps/s
[Step=63700 Epoch=244.1] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.294 | L2-Norm(final)=7.491 | 4197.9 samples/s | 65.6 steps/s
[Step=63750 Epoch=244.3] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.273 | L2-Norm(final)=7.494 | 4203.6 samples/s | 65.7 steps/s
[Step=63800 Epoch=244.5] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=7.497 | 6297.4 samples/s | 98.4 steps/s
[Step=63850 Epoch=244.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.230 | L2-Norm(final)=7.500 | 2134.1 samples/s | 33.3 steps/s
[Step=63900 Epoch=244.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.208 | L2-Norm(final)=7.503 | 4098.6 samples/s | 64.0 steps/s
[Step=63950 Epoch=245.0] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=7.506 | 4108.7 samples/s | 64.2 steps/s
[Step=64000 Epoch=245.2] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.165 | L2-Norm(final)=7.509 | 4126.6 samples/s | 64.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step64000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=238.7] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.694 | L2-Norm(final)=7.895 | 5243.4 samples/s | 81.9 steps/s
[Step=62050 Epoch=238.9] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.693 | L2-Norm(final)=7.902 | 4477.0 samples/s | 70.0 steps/s
[Step=62100 Epoch=239.0] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.694 | L2-Norm(final)=7.910 | 4694.2 samples/s | 73.3 steps/s
[Step=62150 Epoch=239.2] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.696 | L2-Norm(final)=7.918 | 4721.1 samples/s | 73.8 steps/s
[Step=62200 Epoch=239.4] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.697 | L2-Norm(final)=7.926 | 4714.3 samples/s | 73.7 steps/s
[Step=62250 Epoch=239.6] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.698 | L2-Norm(final)=7.935 | 6717.4 samples/s | 105.0 steps/s
[Step=62300 Epoch=239.8] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.700 | L2-Norm(final)=7.942 | 2402.8 samples/s | 37.5 steps/s
[Step=62350 Epoch=240.0] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.700 | L2-Norm(final)=7.949 | 4615.9 samples/s | 72.1 steps/s
[Step=62400 Epoch=240.2] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.701 | L2-Norm(final)=7.956 | 4807.4 samples/s | 75.1 steps/s
[Step=62450 Epoch=240.4] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.702 | L2-Norm(final)=7.963 | 4736.7 samples/s | 74.0 steps/s
[Step=62500 Epoch=240.6] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.702 | L2-Norm(final)=7.969 | 5654.3 samples/s | 88.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=240.6] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=8.035 | 6573.2 samples/s | 102.7 steps/s
[Step=62550 Epoch=240.8] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.700 | L2-Norm(final)=8.040 | 3659.1 samples/s | 57.2 steps/s
[Step=62600 Epoch=241.0] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.688 | L2-Norm(final)=8.045 | 4205.8 samples/s | 65.7 steps/s
[Step=62650 Epoch=241.2] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.675 | L2-Norm(final)=8.049 | 4264.8 samples/s | 66.6 steps/s
[Step=62700 Epoch=241.4] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.661 | L2-Norm(final)=8.052 | 4182.9 samples/s | 65.4 steps/s
[Step=62750 Epoch=241.5] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.647 | L2-Norm(final)=8.055 | 5848.2 samples/s | 91.4 steps/s
[Step=62800 Epoch=241.7] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.633 | L2-Norm(final)=8.058 | 2301.3 samples/s | 36.0 steps/s
[Step=62850 Epoch=241.9] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.619 | L2-Norm(final)=8.061 | 4160.4 samples/s | 65.0 steps/s
[Step=62900 Epoch=242.1] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.604 | L2-Norm(final)=8.064 | 4297.8 samples/s | 67.2 steps/s
[Step=62950 Epoch=242.3] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.589 | L2-Norm(final)=8.066 | 4186.5 samples/s | 65.4 steps/s
[Step=63000 Epoch=242.5] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.574 | L2-Norm(final)=8.069 | 4880.2 samples/s | 76.3 steps/s
[Step=63050 Epoch=242.7] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.559 | L2-Norm(final)=8.071 | 2407.4 samples/s | 37.6 steps/s
[Step=63100 Epoch=242.9] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.543 | L2-Norm(final)=8.073 | 4290.9 samples/s | 67.0 steps/s
[Step=63150 Epoch=243.1] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.528 | L2-Norm(final)=8.076 | 4260.7 samples/s | 66.6 steps/s
[Step=63200 Epoch=243.3] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.512 | L2-Norm(final)=8.078 | 4183.5 samples/s | 65.4 steps/s
[Step=63250 Epoch=243.5] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.496 | L2-Norm(final)=8.080 | 4326.7 samples/s | 67.6 steps/s
[Step=63300 Epoch=243.7] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.480 | L2-Norm(final)=8.083 | 2586.7 samples/s | 40.4 steps/s
[Step=63350 Epoch=243.9] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.464 | L2-Norm(final)=8.085 | 4177.1 samples/s | 65.3 steps/s
[Step=63400 Epoch=244.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.448 | L2-Norm(final)=8.087 | 4169.3 samples/s | 65.1 steps/s
[Step=63450 Epoch=244.2] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.431 | L2-Norm(final)=8.090 | 4320.0 samples/s | 67.5 steps/s
[Step=63500 Epoch=244.4] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.415 | L2-Norm(final)=8.092 | 4163.4 samples/s | 65.1 steps/s
[Step=63550 Epoch=244.6] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.398 | L2-Norm(final)=8.095 | 2630.3 samples/s | 41.1 steps/s
[Step=63600 Epoch=244.8] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.381 | L2-Norm(final)=8.098 | 4241.6 samples/s | 66.3 steps/s
[Step=63650 Epoch=245.0] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.364 | L2-Norm(final)=8.100 | 4276.1 samples/s | 66.8 steps/s
[Step=63700 Epoch=245.2] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.347 | L2-Norm(final)=8.103 | 4122.4 samples/s | 64.4 steps/s
[Step=63750 Epoch=245.4] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.330 | L2-Norm(final)=8.106 | 4253.3 samples/s | 66.5 steps/s
[Step=63800 Epoch=245.6] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.313 | L2-Norm(final)=8.109 | 6891.2 samples/s | 107.7 steps/s
[Step=63850 Epoch=245.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.295 | L2-Norm(final)=8.112 | 2118.6 samples/s | 33.1 steps/s
[Step=63900 Epoch=246.0] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.278 | L2-Norm(final)=8.115 | 4209.7 samples/s | 65.8 steps/s
[Step=63950 Epoch=246.2] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.260 | L2-Norm(final)=8.118 | 4205.8 samples/s | 65.7 steps/s
[Step=64000 Epoch=246.4] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.242 | L2-Norm(final)=8.121 | 4246.6 samples/s | 66.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07688 | acc=0.9678 | tpr=0.9748 | fpr=0.0473 | 4890.4 samples/s | 19.1 steps/s
Avg test loss: 0.07793, Avg test acc: 0.96779, Avg tpr: 0.97494, Avg fpr: 0.04794, total FA: 374

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07689 | acc=0.9670 | tpr=0.9771 | fpr=0.0548 | 4912.5 samples/s | 19.2 steps/s
Avg test loss: 0.07904, Avg test acc: 0.96682, Avg tpr: 0.97774, Avg fpr: 0.05717, total FA: 446

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.26660 | acc=0.3063 | tpr=0.0096 | fpr=0.0493 | 5133.1 samples/s | 20.1 steps/s
Avg test loss: 5.26522, Avg test acc: 0.30211, Avg tpr: 0.01003, Avg fpr: 0.05551, total FA: 433

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.60661 | acc=0.3119 | tpr=0.0153 | fpr=0.0441 | 4933.8 samples/s | 19.3 steps/s
Avg test loss: 5.59224, Avg test acc: 0.30844, Avg tpr: 0.01649, Avg fpr: 0.04948, total FA: 386

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.71927 | acc=0.1420 | tpr=0.5221 | fpr=0.8648 | 4947.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.68432 | acc=0.1427 | tpr=0.4989 | fpr=0.8640 | 7200.9 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.68642 | acc=0.1428 | tpr=0.5000 | fpr=0.8638 | 7341.1 samples/s | 28.7 steps/s
[Step= 200] | Loss=6.68161 | acc=0.1432 | tpr=0.5005 | fpr=0.8633 | 8027.8 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.66989 | acc=0.1436 | tpr=0.5144 | fpr=0.8632 | 7739.3 samples/s | 30.2 steps/s
[Step= 300] | Loss=6.65856 | acc=0.1435 | tpr=0.5098 | fpr=0.8632 | 7548.6 samples/s | 29.5 steps/s
[Step= 350] | Loss=6.66280 | acc=0.1429 | tpr=0.5003 | fpr=0.8636 | 8176.7 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.66136 | acc=0.1431 | tpr=0.4978 | fpr=0.8634 | 7927.8 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.66522 | acc=0.1426 | tpr=0.4961 | fpr=0.8638 | 7613.4 samples/s | 29.7 steps/s
[Step= 500] | Loss=6.66699 | acc=0.1431 | tpr=0.4965 | fpr=0.8633 | 8117.5 samples/s | 31.7 steps/s
[Step= 550] | Loss=6.67029 | acc=0.1432 | tpr=0.4970 | fpr=0.8633 | 13596.3 samples/s | 53.1 steps/s
Avg test loss: 6.67191, Avg test acc: 0.14304, Avg tpr: 0.49842, Avg fpr: 0.86342, total FA: 119884

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.41381 | acc=0.1263 | tpr=0.5708 | fpr=0.8817 | 5187.6 samples/s | 20.3 steps/s
[Step= 100] | Loss=7.39600 | acc=0.1275 | tpr=0.5416 | fpr=0.8802 | 6524.2 samples/s | 25.5 steps/s
[Step= 150] | Loss=7.39406 | acc=0.1273 | tpr=0.5346 | fpr=0.8802 | 8090.9 samples/s | 31.6 steps/s
[Step= 200] | Loss=7.39116 | acc=0.1274 | tpr=0.5246 | fpr=0.8798 | 7638.7 samples/s | 29.8 steps/s
[Step= 250] | Loss=7.37962 | acc=0.1278 | tpr=0.5231 | fpr=0.8794 | 7790.6 samples/s | 30.4 steps/s
[Step= 300] | Loss=7.37161 | acc=0.1281 | tpr=0.5222 | fpr=0.8791 | 7814.6 samples/s | 30.5 steps/s
[Step= 350] | Loss=7.37712 | acc=0.1278 | tpr=0.5160 | fpr=0.8793 | 7627.1 samples/s | 29.8 steps/s
[Step= 400] | Loss=7.37481 | acc=0.1276 | tpr=0.5093 | fpr=0.8794 | 8215.1 samples/s | 32.1 steps/s
[Step= 450] | Loss=7.37909 | acc=0.1274 | tpr=0.5058 | fpr=0.8795 | 7601.4 samples/s | 29.7 steps/s
[Step= 500] | Loss=7.38203 | acc=0.1279 | tpr=0.5101 | fpr=0.8790 | 7861.7 samples/s | 30.7 steps/s
[Step= 550] | Loss=7.38720 | acc=0.1280 | tpr=0.5109 | fpr=0.8789 | 13909.1 samples/s | 54.3 steps/s
Avg test loss: 7.38929, Avg test acc: 0.12785, Avg tpr: 0.51189, Avg fpr: 0.87913, total FA: 122065

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12216 | acc=0.9773 | tpr=0.9469 | fpr=0.0222 | 4886.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.12323 | acc=0.9782 | tpr=0.9552 | fpr=0.0214 | 7153.7 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.12867 | acc=0.9774 | tpr=0.9568 | fpr=0.0222 | 8367.7 samples/s | 32.7 steps/s
[Step= 200] | Loss=0.13216 | acc=0.9775 | tpr=0.9585 | fpr=0.0222 | 7493.8 samples/s | 29.3 steps/s
[Step= 250] | Loss=0.12967 | acc=0.9777 | tpr=0.9590 | fpr=0.0220 | 7810.5 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.13145 | acc=0.9773 | tpr=0.9585 | fpr=0.0224 | 7692.1 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.13156 | acc=0.9773 | tpr=0.9593 | fpr=0.0223 | 7824.0 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.13285 | acc=0.9773 | tpr=0.9579 | fpr=0.0224 | 7672.0 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.13520 | acc=0.9769 | tpr=0.9552 | fpr=0.0227 | 7722.1 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.13451 | acc=0.9769 | tpr=0.9564 | fpr=0.0227 | 7889.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.13324 | acc=0.9772 | tpr=0.9566 | fpr=0.0225 | 13574.1 samples/s | 53.0 steps/s
Avg test loss: 0.13305, Avg test acc: 0.97717, Avg tpr: 0.95642, Avg fpr: 0.02246, total FA: 3118

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11969 | acc=0.9779 | tpr=0.9513 | fpr=0.0216 | 4776.0 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.12204 | acc=0.9782 | tpr=0.9616 | fpr=0.0215 | 7446.7 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.12825 | acc=0.9774 | tpr=0.9625 | fpr=0.0223 | 7538.6 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.13128 | acc=0.9772 | tpr=0.9617 | fpr=0.0225 | 8143.4 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.12931 | acc=0.9774 | tpr=0.9607 | fpr=0.0223 | 7560.2 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.13130 | acc=0.9771 | tpr=0.9585 | fpr=0.0225 | 7755.7 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.13148 | acc=0.9770 | tpr=0.9593 | fpr=0.0227 | 7929.3 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.13267 | acc=0.9770 | tpr=0.9579 | fpr=0.0227 | 8057.5 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.13513 | acc=0.9766 | tpr=0.9552 | fpr=0.0230 | 7497.1 samples/s | 29.3 steps/s
[Step= 500] | Loss=0.13462 | acc=0.9767 | tpr=0.9555 | fpr=0.0229 | 8240.1 samples/s | 32.2 steps/s
[Step= 550] | Loss=0.13318 | acc=0.9769 | tpr=0.9554 | fpr=0.0227 | 13371.2 samples/s | 52.2 steps/s
Avg test loss: 0.13303, Avg test acc: 0.97693, Avg tpr: 0.95523, Avg fpr: 0.02268, total FA: 3149

server round 32/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=124.8] | Loss=0.00212 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.409 | L2-Norm(final)=12.049 | 6764.1 samples/s | 105.7 steps/s
[Step=64050 Epoch=124.9] | Loss=0.00590 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=12.052 | 4338.8 samples/s | 67.8 steps/s
[Step=64100 Epoch=125.0] | Loss=0.00604 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=12.058 | 4952.3 samples/s | 77.4 steps/s
[Step=64150 Epoch=125.1] | Loss=0.00642 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.417 | L2-Norm(final)=12.065 | 4949.1 samples/s | 77.3 steps/s
[Step=64200 Epoch=125.2] | Loss=0.00628 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.072 | 5147.0 samples/s | 80.4 steps/s
[Step=64250 Epoch=125.3] | Loss=0.00613 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.419 | L2-Norm(final)=12.078 | 4941.7 samples/s | 77.2 steps/s
[Step=64300 Epoch=125.4] | Loss=0.00609 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.421 | L2-Norm(final)=12.084 | 5080.1 samples/s | 79.4 steps/s
[Step=64350 Epoch=125.5] | Loss=0.00597 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=12.090 | 5013.5 samples/s | 78.3 steps/s
[Step=64400 Epoch=125.6] | Loss=0.00619 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=12.096 | 5088.9 samples/s | 79.5 steps/s
[Step=64450 Epoch=125.7] | Loss=0.00625 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.423 | L2-Norm(final)=12.102 | 5000.7 samples/s | 78.1 steps/s
[Step=64500 Epoch=125.8] | Loss=0.00642 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.424 | L2-Norm(final)=12.108 | 6826.9 samples/s | 106.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=125.8] | Loss=0.00138 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.436 | L2-Norm(final)=12.166 | 6109.1 samples/s | 95.5 steps/s
[Step=64550 Epoch=125.9] | Loss=0.00606 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.440 | L2-Norm(final)=12.172 | 4082.8 samples/s | 63.8 steps/s
[Step=64600 Epoch=126.0] | Loss=0.00775 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.443 | L2-Norm(final)=12.176 | 4404.0 samples/s | 68.8 steps/s
[Step=64650 Epoch=126.1] | Loss=0.00735 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.446 | L2-Norm(final)=12.181 | 4585.5 samples/s | 71.6 steps/s
[Step=64700 Epoch=126.2] | Loss=0.00763 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.449 | L2-Norm(final)=12.185 | 4436.3 samples/s | 69.3 steps/s
[Step=64750 Epoch=126.3] | Loss=0.00775 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.451 | L2-Norm(final)=12.189 | 4450.2 samples/s | 69.5 steps/s
[Step=64800 Epoch=126.4] | Loss=0.00743 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.454 | L2-Norm(final)=12.194 | 4453.9 samples/s | 69.6 steps/s
[Step=64850 Epoch=126.5] | Loss=0.00742 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.456 | L2-Norm(final)=12.199 | 4541.7 samples/s | 71.0 steps/s
[Step=64900 Epoch=126.6] | Loss=0.00744 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.459 | L2-Norm(final)=12.203 | 4428.4 samples/s | 69.2 steps/s
[Step=64950 Epoch=126.7] | Loss=0.00743 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.461 | L2-Norm(final)=12.208 | 4418.6 samples/s | 69.0 steps/s
[Step=65000 Epoch=126.8] | Loss=0.00722 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.463 | L2-Norm(final)=12.212 | 5652.1 samples/s | 88.3 steps/s
[Step=65050 Epoch=126.9] | Loss=0.00708 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.465 | L2-Norm(final)=12.217 | 2391.8 samples/s | 37.4 steps/s
[Step=65100 Epoch=127.0] | Loss=0.00701 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=12.221 | 4507.1 samples/s | 70.4 steps/s
[Step=65150 Epoch=127.1] | Loss=0.00691 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.468 | L2-Norm(final)=12.225 | 4369.9 samples/s | 68.3 steps/s
[Step=65200 Epoch=127.2] | Loss=0.00685 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.469 | L2-Norm(final)=12.229 | 4428.4 samples/s | 69.2 steps/s
[Step=65250 Epoch=127.3] | Loss=0.00673 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.470 | L2-Norm(final)=12.233 | 4471.7 samples/s | 69.9 steps/s
[Step=65300 Epoch=127.4] | Loss=0.00664 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.471 | L2-Norm(final)=12.237 | 4571.6 samples/s | 71.4 steps/s
[Step=65350 Epoch=127.5] | Loss=0.00660 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.472 | L2-Norm(final)=12.240 | 4364.5 samples/s | 68.2 steps/s
[Step=65400 Epoch=127.6] | Loss=0.00651 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.473 | L2-Norm(final)=12.244 | 4392.9 samples/s | 68.6 steps/s
[Step=65450 Epoch=127.7] | Loss=0.00647 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.473 | L2-Norm(final)=12.248 | 4469.8 samples/s | 69.8 steps/s
[Step=65500 Epoch=127.8] | Loss=0.00637 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.474 | L2-Norm(final)=12.252 | 4808.3 samples/s | 75.1 steps/s
[Step=65550 Epoch=127.8] | Loss=0.00636 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.475 | L2-Norm(final)=12.255 | 2621.1 samples/s | 41.0 steps/s
[Step=65600 Epoch=127.9] | Loss=0.00625 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.475 | L2-Norm(final)=12.259 | 4458.4 samples/s | 69.7 steps/s
[Step=65650 Epoch=128.0] | Loss=0.00618 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.475 | L2-Norm(final)=12.262 | 4495.2 samples/s | 70.2 steps/s
[Step=65700 Epoch=128.1] | Loss=0.00610 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.266 | 4450.5 samples/s | 69.5 steps/s
[Step=65750 Epoch=128.2] | Loss=0.00606 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.269 | 4418.0 samples/s | 69.0 steps/s
[Step=65800 Epoch=128.3] | Loss=0.00606 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.272 | 4487.6 samples/s | 70.1 steps/s
[Step=65850 Epoch=128.4] | Loss=0.00606 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.476 | L2-Norm(final)=12.275 | 4454.4 samples/s | 69.6 steps/s
[Step=65900 Epoch=128.5] | Loss=0.00604 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.476 | L2-Norm(final)=12.279 | 4478.9 samples/s | 70.0 steps/s
[Step=65950 Epoch=128.6] | Loss=0.00594 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.282 | 4574.6 samples/s | 71.5 steps/s
[Step=66000 Epoch=128.7] | Loss=0.00591 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.285 | 4419.2 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step66000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=125.1] | Loss=0.00597 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.505 | L2-Norm(final)=12.179 | 6513.6 samples/s | 101.8 steps/s
[Step=64050 Epoch=125.2] | Loss=0.00722 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.507 | L2-Norm(final)=12.183 | 4137.9 samples/s | 64.7 steps/s
[Step=64100 Epoch=125.3] | Loss=0.00725 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.510 | L2-Norm(final)=12.189 | 5076.1 samples/s | 79.3 steps/s
[Step=64150 Epoch=125.4] | Loss=0.00693 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.512 | L2-Norm(final)=12.195 | 4911.5 samples/s | 76.7 steps/s
[Step=64200 Epoch=125.5] | Loss=0.00696 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.514 | L2-Norm(final)=12.201 | 5055.5 samples/s | 79.0 steps/s
[Step=64250 Epoch=125.6] | Loss=0.00693 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.516 | L2-Norm(final)=12.206 | 4986.8 samples/s | 77.9 steps/s
[Step=64300 Epoch=125.7] | Loss=0.00669 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.517 | L2-Norm(final)=12.212 | 4972.5 samples/s | 77.7 steps/s
[Step=64350 Epoch=125.8] | Loss=0.00659 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.519 | L2-Norm(final)=12.218 | 5043.0 samples/s | 78.8 steps/s
[Step=64400 Epoch=125.9] | Loss=0.00646 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.521 | L2-Norm(final)=12.224 | 5061.5 samples/s | 79.1 steps/s
[Step=64450 Epoch=126.0] | Loss=0.00649 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=12.230 | 5205.8 samples/s | 81.3 steps/s
[Step=64500 Epoch=126.1] | Loss=0.00641 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=12.236 | 6642.6 samples/s | 103.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=126.1] | Loss=0.00120 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.537 | L2-Norm(final)=12.297 | 6001.3 samples/s | 93.8 steps/s
[Step=64550 Epoch=126.2] | Loss=0.00727 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.540 | L2-Norm(final)=12.303 | 4086.0 samples/s | 63.8 steps/s
[Step=64600 Epoch=126.3] | Loss=0.00718 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.545 | L2-Norm(final)=12.309 | 4486.3 samples/s | 70.1 steps/s
[Step=64650 Epoch=126.4] | Loss=0.00743 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.549 | L2-Norm(final)=12.315 | 4460.9 samples/s | 69.7 steps/s
[Step=64700 Epoch=126.5] | Loss=0.00729 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.553 | L2-Norm(final)=12.320 | 4465.5 samples/s | 69.8 steps/s
[Step=64750 Epoch=126.6] | Loss=0.00737 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.556 | L2-Norm(final)=12.324 | 4480.9 samples/s | 70.0 steps/s
[Step=64800 Epoch=126.7] | Loss=0.00748 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.559 | L2-Norm(final)=12.329 | 4450.1 samples/s | 69.5 steps/s
[Step=64850 Epoch=126.8] | Loss=0.00762 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.561 | L2-Norm(final)=12.334 | 4519.8 samples/s | 70.6 steps/s
[Step=64900 Epoch=126.9] | Loss=0.00760 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.564 | L2-Norm(final)=12.338 | 4532.9 samples/s | 70.8 steps/s
[Step=64950 Epoch=127.0] | Loss=0.00755 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.566 | L2-Norm(final)=12.343 | 4348.6 samples/s | 67.9 steps/s
[Step=65000 Epoch=127.1] | Loss=0.00756 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.568 | L2-Norm(final)=12.347 | 5833.9 samples/s | 91.2 steps/s
[Step=65050 Epoch=127.2] | Loss=0.00738 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.571 | L2-Norm(final)=12.352 | 2382.3 samples/s | 37.2 steps/s
[Step=65100 Epoch=127.3] | Loss=0.00704 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.573 | L2-Norm(final)=12.356 | 4521.0 samples/s | 70.6 steps/s
[Step=65150 Epoch=127.4] | Loss=0.00700 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.574 | L2-Norm(final)=12.360 | 4462.4 samples/s | 69.7 steps/s
[Step=65200 Epoch=127.5] | Loss=0.00689 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=12.364 | 4446.4 samples/s | 69.5 steps/s
[Step=65250 Epoch=127.6] | Loss=0.00681 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.577 | L2-Norm(final)=12.368 | 4450.3 samples/s | 69.5 steps/s
[Step=65300 Epoch=127.7] | Loss=0.00671 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=12.372 | 4542.3 samples/s | 71.0 steps/s
[Step=65350 Epoch=127.8] | Loss=0.00663 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=12.375 | 4430.4 samples/s | 69.2 steps/s
[Step=65400 Epoch=127.9] | Loss=0.00659 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.580 | L2-Norm(final)=12.379 | 4399.0 samples/s | 68.7 steps/s
[Step=65450 Epoch=128.0] | Loss=0.00659 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=12.383 | 4416.6 samples/s | 69.0 steps/s
[Step=65500 Epoch=128.1] | Loss=0.00649 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.582 | L2-Norm(final)=12.386 | 4984.0 samples/s | 77.9 steps/s
[Step=65550 Epoch=128.1] | Loss=0.00641 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=12.390 | 2569.2 samples/s | 40.1 steps/s
[Step=65600 Epoch=128.2] | Loss=0.00630 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.584 | L2-Norm(final)=12.393 | 4466.5 samples/s | 69.8 steps/s
[Step=65650 Epoch=128.3] | Loss=0.00624 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.584 | L2-Norm(final)=12.396 | 4488.9 samples/s | 70.1 steps/s
[Step=65700 Epoch=128.4] | Loss=0.00616 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.585 | L2-Norm(final)=12.400 | 4493.9 samples/s | 70.2 steps/s
[Step=65750 Epoch=128.5] | Loss=0.00615 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.585 | L2-Norm(final)=12.403 | 4413.7 samples/s | 69.0 steps/s
[Step=65800 Epoch=128.6] | Loss=0.00612 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=12.407 | 4447.0 samples/s | 69.5 steps/s
[Step=65850 Epoch=128.7] | Loss=0.00609 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=12.410 | 4375.1 samples/s | 68.4 steps/s
[Step=65900 Epoch=128.8] | Loss=0.00604 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=12.413 | 4467.0 samples/s | 69.8 steps/s
[Step=65950 Epoch=128.9] | Loss=0.00598 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=12.416 | 4530.0 samples/s | 70.8 steps/s
[Step=66000 Epoch=129.0] | Loss=0.00591 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=12.419 | 4459.3 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step66000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=245.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.174 | L2-Norm(final)=7.602 | 6611.9 samples/s | 103.3 steps/s
[Step=64050 Epoch=245.4] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.173 | L2-Norm(final)=7.621 | 3974.0 samples/s | 62.1 steps/s
[Step=64100 Epoch=245.6] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.178 | L2-Norm(final)=7.642 | 4678.3 samples/s | 73.1 steps/s
[Step=64150 Epoch=245.8] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.181 | L2-Norm(final)=7.658 | 4632.3 samples/s | 72.4 steps/s
[Step=64200 Epoch=246.0] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=7.674 | 4821.5 samples/s | 75.3 steps/s
[Step=64250 Epoch=246.2] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=7.688 | 6507.0 samples/s | 101.7 steps/s
[Step=64300 Epoch=246.4] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.189 | L2-Norm(final)=7.702 | 2392.5 samples/s | 37.4 steps/s
[Step=64350 Epoch=246.6] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.191 | L2-Norm(final)=7.714 | 4743.0 samples/s | 74.1 steps/s
[Step=64400 Epoch=246.8] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.192 | L2-Norm(final)=7.725 | 4751.3 samples/s | 74.2 steps/s
[Step=64450 Epoch=246.9] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.194 | L2-Norm(final)=7.735 | 4706.8 samples/s | 73.5 steps/s
[Step=64500 Epoch=247.1] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.195 | L2-Norm(final)=7.745 | 5436.7 samples/s | 84.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=247.1] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.203 | L2-Norm(final)=7.841 | 6511.7 samples/s | 101.7 steps/s
[Step=64550 Epoch=247.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=7.849 | 3786.5 samples/s | 59.2 steps/s
[Step=64600 Epoch=247.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.150 | L2-Norm(final)=7.856 | 4264.4 samples/s | 66.6 steps/s
[Step=64650 Epoch=247.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.118 | L2-Norm(final)=7.861 | 4242.1 samples/s | 66.3 steps/s
[Step=64700 Epoch=247.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.085 | L2-Norm(final)=7.866 | 4250.9 samples/s | 66.4 steps/s
[Step=64750 Epoch=248.1] | Loss=0.00007 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.061 | L2-Norm(final)=7.871 | 5704.8 samples/s | 89.1 steps/s
[Step=64800 Epoch=248.3] | Loss=0.00013 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.050 | L2-Norm(final)=7.876 | 2290.8 samples/s | 35.8 steps/s
[Step=64850 Epoch=248.5] | Loss=0.00012 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.043 | L2-Norm(final)=7.880 | 4171.7 samples/s | 65.2 steps/s
[Step=64900 Epoch=248.7] | Loss=0.00011 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.038 | L2-Norm(final)=7.884 | 4163.5 samples/s | 65.1 steps/s
[Step=64950 Epoch=248.9] | Loss=0.00010 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=7.886 | 4258.9 samples/s | 66.5 steps/s
[Step=65000 Epoch=249.1] | Loss=0.00009 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.031 | L2-Norm(final)=7.889 | 4808.4 samples/s | 75.1 steps/s
[Step=65050 Epoch=249.2] | Loss=0.00009 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.028 | L2-Norm(final)=7.891 | 2456.3 samples/s | 38.4 steps/s
[Step=65100 Epoch=249.4] | Loss=0.00008 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.025 | L2-Norm(final)=7.893 | 4185.0 samples/s | 65.4 steps/s
[Step=65150 Epoch=249.6] | Loss=0.00007 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.023 | L2-Norm(final)=7.894 | 4386.5 samples/s | 68.5 steps/s
[Step=65200 Epoch=249.8] | Loss=0.00007 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.021 | L2-Norm(final)=7.896 | 4145.2 samples/s | 64.8 steps/s
[Step=65250 Epoch=250.0] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.018 | L2-Norm(final)=7.897 | 4152.3 samples/s | 64.9 steps/s
[Step=65300 Epoch=250.2] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=7.898 | 2629.6 samples/s | 41.1 steps/s
[Step=65350 Epoch=250.4] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=7.899 | 4188.0 samples/s | 65.4 steps/s
[Step=65400 Epoch=250.6] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.012 | L2-Norm(final)=7.900 | 4168.5 samples/s | 65.1 steps/s
[Step=65450 Epoch=250.8] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.010 | L2-Norm(final)=7.901 | 4233.7 samples/s | 66.2 steps/s
[Step=65500 Epoch=251.0] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=7.902 | 4257.1 samples/s | 66.5 steps/s
[Step=65550 Epoch=251.2] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.006 | L2-Norm(final)=7.902 | 2666.9 samples/s | 41.7 steps/s
[Step=65600 Epoch=251.4] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=7.903 | 4065.9 samples/s | 63.5 steps/s
[Step=65650 Epoch=251.5] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.002 | L2-Norm(final)=7.904 | 4198.2 samples/s | 65.6 steps/s
[Step=65700 Epoch=251.7] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.000 | L2-Norm(final)=7.905 | 4238.2 samples/s | 66.2 steps/s
[Step=65750 Epoch=251.9] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.999 | L2-Norm(final)=7.905 | 4306.5 samples/s | 67.3 steps/s
[Step=65800 Epoch=252.1] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.997 | L2-Norm(final)=7.906 | 6248.4 samples/s | 97.6 steps/s
[Step=65850 Epoch=252.3] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.995 | L2-Norm(final)=7.907 | 2175.5 samples/s | 34.0 steps/s
[Step=65900 Epoch=252.5] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.993 | L2-Norm(final)=7.907 | 4276.6 samples/s | 66.8 steps/s
[Step=65950 Epoch=252.7] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.991 | L2-Norm(final)=7.908 | 4167.6 samples/s | 65.1 steps/s
[Step=66000 Epoch=252.9] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=7.908 | 4183.8 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step66000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=246.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=8.217 | 5743.9 samples/s | 89.7 steps/s
[Step=64050 Epoch=246.6] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.153 | L2-Norm(final)=8.236 | 4369.5 samples/s | 68.3 steps/s
[Step=64100 Epoch=246.7] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.160 | L2-Norm(final)=8.255 | 4760.9 samples/s | 74.4 steps/s
[Step=64150 Epoch=246.9] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.165 | L2-Norm(final)=8.270 | 4707.4 samples/s | 73.6 steps/s
[Step=64200 Epoch=247.1] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.168 | L2-Norm(final)=8.282 | 4831.6 samples/s | 75.5 steps/s
[Step=64250 Epoch=247.3] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.171 | L2-Norm(final)=8.291 | 6676.8 samples/s | 104.3 steps/s
[Step=64300 Epoch=247.5] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.173 | L2-Norm(final)=8.300 | 2372.4 samples/s | 37.1 steps/s
[Step=64350 Epoch=247.7] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.174 | L2-Norm(final)=8.308 | 4687.5 samples/s | 73.2 steps/s
[Step=64400 Epoch=247.9] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.175 | L2-Norm(final)=8.315 | 4739.3 samples/s | 74.1 steps/s
[Step=64450 Epoch=248.1] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.176 | L2-Norm(final)=8.322 | 4771.9 samples/s | 74.6 steps/s
[Step=64500 Epoch=248.3] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.177 | L2-Norm(final)=8.330 | 5651.0 samples/s | 88.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=248.3] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.186 | L2-Norm(final)=8.404 | 6387.0 samples/s | 99.8 steps/s
[Step=64550 Epoch=248.5] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.169 | L2-Norm(final)=8.409 | 3741.3 samples/s | 58.5 steps/s
[Step=64600 Epoch=248.7] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.151 | L2-Norm(final)=8.417 | 4243.7 samples/s | 66.3 steps/s
[Step=64650 Epoch=248.9] | Loss=0.00009 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.151 | L2-Norm(final)=8.428 | 4202.7 samples/s | 65.7 steps/s
[Step=64700 Epoch=249.1] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.156 | L2-Norm(final)=8.438 | 4203.9 samples/s | 65.7 steps/s
[Step=64750 Epoch=249.2] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.159 | L2-Norm(final)=8.446 | 5794.9 samples/s | 90.5 steps/s
[Step=64800 Epoch=249.4] | Loss=0.00006 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.160 | L2-Norm(final)=8.451 | 2280.5 samples/s | 35.6 steps/s
[Step=64850 Epoch=249.6] | Loss=0.00005 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.160 | L2-Norm(final)=8.456 | 4263.3 samples/s | 66.6 steps/s
[Step=64900 Epoch=249.8] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.158 | L2-Norm(final)=8.459 | 4122.0 samples/s | 64.4 steps/s
[Step=64950 Epoch=250.0] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.157 | L2-Norm(final)=8.462 | 4240.0 samples/s | 66.3 steps/s
[Step=65000 Epoch=250.2] | Loss=0.00004 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.154 | L2-Norm(final)=8.464 | 4958.4 samples/s | 77.5 steps/s
[Step=65050 Epoch=250.4] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=8.466 | 2382.6 samples/s | 37.2 steps/s
[Step=65100 Epoch=250.6] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=8.468 | 4367.0 samples/s | 68.2 steps/s
[Step=65150 Epoch=250.8] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.470 | 4131.4 samples/s | 64.6 steps/s
[Step=65200 Epoch=251.0] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.471 | 4234.3 samples/s | 66.2 steps/s
[Step=65250 Epoch=251.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.138 | L2-Norm(final)=8.472 | 4329.4 samples/s | 67.6 steps/s
[Step=65300 Epoch=251.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.134 | L2-Norm(final)=8.474 | 2599.8 samples/s | 40.6 steps/s
[Step=65350 Epoch=251.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.130 | L2-Norm(final)=8.475 | 4231.2 samples/s | 66.1 steps/s
[Step=65400 Epoch=251.8] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.126 | L2-Norm(final)=8.476 | 4132.7 samples/s | 64.6 steps/s
[Step=65450 Epoch=251.9] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.122 | L2-Norm(final)=8.477 | 4225.6 samples/s | 66.0 steps/s
[Step=65500 Epoch=252.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.117 | L2-Norm(final)=8.478 | 4205.6 samples/s | 65.7 steps/s
[Step=65550 Epoch=252.3] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=8.479 | 2629.0 samples/s | 41.1 steps/s
[Step=65600 Epoch=252.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=8.479 | 4231.0 samples/s | 66.1 steps/s
[Step=65650 Epoch=252.7] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=8.480 | 4233.7 samples/s | 66.2 steps/s
[Step=65700 Epoch=252.9] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.481 | 4214.8 samples/s | 65.9 steps/s
[Step=65750 Epoch=253.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=8.482 | 4188.0 samples/s | 65.4 steps/s
[Step=65800 Epoch=253.3] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.089 | L2-Norm(final)=8.483 | 6963.1 samples/s | 108.8 steps/s
[Step=65850 Epoch=253.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.483 | 2133.8 samples/s | 33.3 steps/s
[Step=65900 Epoch=253.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=8.484 | 4202.3 samples/s | 65.7 steps/s
[Step=65950 Epoch=253.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=8.485 | 4208.6 samples/s | 65.8 steps/s
[Step=66000 Epoch=254.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.068 | L2-Norm(final)=8.486 | 4295.4 samples/s | 67.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07660 | acc=0.9668 | tpr=0.9764 | fpr=0.0540 | 4812.7 samples/s | 18.8 steps/s
Avg test loss: 0.07779, Avg test acc: 0.96743, Avg tpr: 0.97680, Avg fpr: 0.05320, total FA: 415

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07205 | acc=0.9669 | tpr=0.9727 | fpr=0.0458 | 4940.1 samples/s | 19.3 steps/s
Avg test loss: 0.07476, Avg test acc: 0.96618, Avg tpr: 0.97278, Avg fpr: 0.04833, total FA: 377

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.20915 | acc=0.3048 | tpr=0.0104 | fpr=0.0557 | 4869.2 samples/s | 19.0 steps/s
Avg test loss: 5.20806, Avg test acc: 0.30119, Avg tpr: 0.01125, Avg fpr: 0.06115, total FA: 477

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=6.27350 | acc=0.3141 | tpr=0.0130 | fpr=0.0322 | 4962.4 samples/s | 19.4 steps/s
Avg test loss: 6.26659, Avg test acc: 0.31128, Avg tpr: 0.01434, Avg fpr: 0.03564, total FA: 278

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.31362 | acc=0.1441 | tpr=0.5265 | fpr=0.8628 | 4898.5 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.28433 | acc=0.1435 | tpr=0.4883 | fpr=0.8630 | 7326.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=6.28692 | acc=0.1430 | tpr=0.4899 | fpr=0.8634 | 7852.5 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.28462 | acc=0.1438 | tpr=0.4929 | fpr=0.8626 | 7887.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.27140 | acc=0.1440 | tpr=0.5031 | fpr=0.8626 | 7683.1 samples/s | 30.0 steps/s
[Step= 300] | Loss=6.26214 | acc=0.1442 | tpr=0.5062 | fpr=0.8624 | 7479.1 samples/s | 29.2 steps/s
[Step= 350] | Loss=6.26634 | acc=0.1437 | tpr=0.4947 | fpr=0.8627 | 7956.4 samples/s | 31.1 steps/s
[Step= 400] | Loss=6.26694 | acc=0.1442 | tpr=0.4934 | fpr=0.8622 | 8141.1 samples/s | 31.8 steps/s
[Step= 450] | Loss=6.27026 | acc=0.1440 | tpr=0.4912 | fpr=0.8623 | 7718.2 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.27209 | acc=0.1443 | tpr=0.4912 | fpr=0.8619 | 7866.0 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.27417 | acc=0.1445 | tpr=0.4899 | fpr=0.8618 | 14062.0 samples/s | 54.9 steps/s
Avg test loss: 6.27599, Avg test acc: 0.14438, Avg tpr: 0.49128, Avg fpr: 0.86193, total FA: 119677

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.68720 | acc=0.1325 | tpr=0.6150 | fpr=0.8762 | 4904.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.67738 | acc=0.1329 | tpr=0.5650 | fpr=0.8752 | 6972.3 samples/s | 27.2 steps/s
[Step= 150] | Loss=6.67499 | acc=0.1327 | tpr=0.5620 | fpr=0.8752 | 8018.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=6.67022 | acc=0.1329 | tpr=0.5552 | fpr=0.8747 | 8183.7 samples/s | 32.0 steps/s
[Step= 250] | Loss=6.65877 | acc=0.1332 | tpr=0.5546 | fpr=0.8745 | 7693.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=6.65212 | acc=0.1335 | tpr=0.5549 | fpr=0.8741 | 7440.0 samples/s | 29.1 steps/s
[Step= 350] | Loss=6.65674 | acc=0.1334 | tpr=0.5473 | fpr=0.8741 | 8245.5 samples/s | 32.2 steps/s
[Step= 400] | Loss=6.65393 | acc=0.1333 | tpr=0.5443 | fpr=0.8742 | 7775.5 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.65839 | acc=0.1328 | tpr=0.5385 | fpr=0.8746 | 7883.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=6.66092 | acc=0.1334 | tpr=0.5441 | fpr=0.8740 | 7864.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.66524 | acc=0.1335 | tpr=0.5452 | fpr=0.8740 | 13397.0 samples/s | 52.3 steps/s
Avg test loss: 6.66712, Avg test acc: 0.13339, Avg tpr: 0.54596, Avg fpr: 0.87411, total FA: 121368

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12984 | acc=0.9775 | tpr=0.9469 | fpr=0.0220 | 5065.1 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.13104 | acc=0.9779 | tpr=0.9595 | fpr=0.0218 | 6958.4 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.13732 | acc=0.9768 | tpr=0.9582 | fpr=0.0228 | 7466.9 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.14029 | acc=0.9768 | tpr=0.9596 | fpr=0.0229 | 8088.9 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.13730 | acc=0.9773 | tpr=0.9581 | fpr=0.0224 | 8122.7 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.13916 | acc=0.9770 | tpr=0.9564 | fpr=0.0226 | 7598.5 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.13942 | acc=0.9769 | tpr=0.9568 | fpr=0.0228 | 8048.7 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.14053 | acc=0.9769 | tpr=0.9551 | fpr=0.0227 | 7463.1 samples/s | 29.2 steps/s
[Step= 450] | Loss=0.14298 | acc=0.9765 | tpr=0.9523 | fpr=0.0231 | 7990.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.14228 | acc=0.9766 | tpr=0.9537 | fpr=0.0229 | 7325.7 samples/s | 28.6 steps/s
[Step= 550] | Loss=0.14095 | acc=0.9769 | tpr=0.9538 | fpr=0.0227 | 15608.5 samples/s | 61.0 steps/s
Avg test loss: 0.14077, Avg test acc: 0.97692, Avg tpr: 0.95365, Avg fpr: 0.02266, total FA: 3146

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12959 | acc=0.9779 | tpr=0.9425 | fpr=0.0215 | 4940.6 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.13100 | acc=0.9783 | tpr=0.9531 | fpr=0.0212 | 6848.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.13760 | acc=0.9774 | tpr=0.9568 | fpr=0.0222 | 8072.1 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.14012 | acc=0.9772 | tpr=0.9574 | fpr=0.0224 | 7665.9 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.13762 | acc=0.9774 | tpr=0.9572 | fpr=0.0222 | 7781.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.13943 | acc=0.9772 | tpr=0.9549 | fpr=0.0224 | 7886.5 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.13998 | acc=0.9771 | tpr=0.9555 | fpr=0.0225 | 7998.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.14117 | acc=0.9771 | tpr=0.9530 | fpr=0.0225 | 8021.6 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.14387 | acc=0.9766 | tpr=0.9503 | fpr=0.0229 | 7630.3 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.14320 | acc=0.9767 | tpr=0.9511 | fpr=0.0228 | 7863.5 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.14178 | acc=0.9770 | tpr=0.9519 | fpr=0.0225 | 13766.9 samples/s | 53.8 steps/s
Avg test loss: 0.14160, Avg test acc: 0.97703, Avg tpr: 0.95166, Avg fpr: 0.02251, total FA: 3125

server round 33/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=128.7] | Loss=0.00105 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.356 | L2-Norm(final)=12.379 | 6687.5 samples/s | 104.5 steps/s
[Step=66050 Epoch=128.8] | Loss=0.00646 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.359 | L2-Norm(final)=12.383 | 4346.1 samples/s | 67.9 steps/s
[Step=66100 Epoch=128.9] | Loss=0.00545 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.361 | L2-Norm(final)=12.389 | 5148.7 samples/s | 80.4 steps/s
[Step=66150 Epoch=129.0] | Loss=0.00576 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.363 | L2-Norm(final)=12.396 | 5090.9 samples/s | 79.5 steps/s
[Step=66200 Epoch=129.1] | Loss=0.00600 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.365 | L2-Norm(final)=12.403 | 4855.7 samples/s | 75.9 steps/s
[Step=66250 Epoch=129.2] | Loss=0.00602 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.367 | L2-Norm(final)=12.409 | 4906.0 samples/s | 76.7 steps/s
[Step=66300 Epoch=129.3] | Loss=0.00590 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.368 | L2-Norm(final)=12.416 | 5044.5 samples/s | 78.8 steps/s
[Step=66350 Epoch=129.4] | Loss=0.00585 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.369 | L2-Norm(final)=12.422 | 5188.3 samples/s | 81.1 steps/s
[Step=66400 Epoch=129.5] | Loss=0.00575 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.371 | L2-Norm(final)=12.428 | 5027.3 samples/s | 78.6 steps/s
[Step=66450 Epoch=129.6] | Loss=0.00583 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.372 | L2-Norm(final)=12.434 | 4982.9 samples/s | 77.9 steps/s
[Step=66500 Epoch=129.7] | Loss=0.00593 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.373 | L2-Norm(final)=12.440 | 6753.4 samples/s | 105.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=129.7] | Loss=0.00302 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.383 | L2-Norm(final)=12.498 | 6440.0 samples/s | 100.6 steps/s
[Step=66550 Epoch=129.8] | Loss=0.00600 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=12.503 | 3988.7 samples/s | 62.3 steps/s
[Step=66600 Epoch=129.9] | Loss=0.00701 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.388 | L2-Norm(final)=12.508 | 4428.1 samples/s | 69.2 steps/s
[Step=66650 Epoch=130.0] | Loss=0.00696 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.391 | L2-Norm(final)=12.513 | 4361.0 samples/s | 68.1 steps/s
[Step=66700 Epoch=130.1] | Loss=0.00733 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.394 | L2-Norm(final)=12.518 | 4471.1 samples/s | 69.9 steps/s
[Step=66750 Epoch=130.2] | Loss=0.00708 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.397 | L2-Norm(final)=12.522 | 4539.1 samples/s | 70.9 steps/s
[Step=66800 Epoch=130.3] | Loss=0.00737 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.399 | L2-Norm(final)=12.527 | 4506.2 samples/s | 70.4 steps/s
[Step=66850 Epoch=130.4] | Loss=0.00719 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.401 | L2-Norm(final)=12.531 | 4358.3 samples/s | 68.1 steps/s
[Step=66900 Epoch=130.5] | Loss=0.00718 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.403 | L2-Norm(final)=12.536 | 4490.1 samples/s | 70.2 steps/s
[Step=66950 Epoch=130.6] | Loss=0.00733 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=12.540 | 4411.9 samples/s | 68.9 steps/s
[Step=67000 Epoch=130.7] | Loss=0.00723 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.407 | L2-Norm(final)=12.545 | 5818.7 samples/s | 90.9 steps/s
[Step=67050 Epoch=130.8] | Loss=0.00695 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.409 | L2-Norm(final)=12.549 | 2359.4 samples/s | 36.9 steps/s
[Step=67100 Epoch=130.9] | Loss=0.00688 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.410 | L2-Norm(final)=12.553 | 4497.7 samples/s | 70.3 steps/s
[Step=67150 Epoch=131.0] | Loss=0.00672 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=12.558 | 4431.4 samples/s | 69.2 steps/s
[Step=67200 Epoch=131.1] | Loss=0.00668 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.413 | L2-Norm(final)=12.562 | 4480.4 samples/s | 70.0 steps/s
[Step=67250 Epoch=131.2] | Loss=0.00659 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.414 | L2-Norm(final)=12.565 | 4567.0 samples/s | 71.4 steps/s
[Step=67300 Epoch=131.3] | Loss=0.00659 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=12.569 | 4448.9 samples/s | 69.5 steps/s
[Step=67350 Epoch=131.4] | Loss=0.00652 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=12.573 | 4409.9 samples/s | 68.9 steps/s
[Step=67400 Epoch=131.5] | Loss=0.00641 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.416 | L2-Norm(final)=12.576 | 4450.7 samples/s | 69.5 steps/s
[Step=67450 Epoch=131.6] | Loss=0.00646 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.416 | L2-Norm(final)=12.580 | 4412.2 samples/s | 68.9 steps/s
[Step=67500 Epoch=131.7] | Loss=0.00640 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.417 | L2-Norm(final)=12.583 | 4793.5 samples/s | 74.9 steps/s
[Step=67550 Epoch=131.7] | Loss=0.00633 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.417 | L2-Norm(final)=12.587 | 2626.7 samples/s | 41.0 steps/s
[Step=67600 Epoch=131.8] | Loss=0.00622 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.418 | L2-Norm(final)=12.590 | 4478.5 samples/s | 70.0 steps/s
[Step=67650 Epoch=131.9] | Loss=0.00614 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.593 | 4429.5 samples/s | 69.2 steps/s
[Step=67700 Epoch=132.0] | Loss=0.00614 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.597 | 4481.7 samples/s | 70.0 steps/s
[Step=67750 Epoch=132.1] | Loss=0.00609 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.600 | 4506.0 samples/s | 70.4 steps/s
[Step=67800 Epoch=132.2] | Loss=0.00601 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.418 | L2-Norm(final)=12.603 | 4465.1 samples/s | 69.8 steps/s
[Step=67850 Epoch=132.3] | Loss=0.00598 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.606 | 4362.2 samples/s | 68.2 steps/s
[Step=67900 Epoch=132.4] | Loss=0.00595 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.610 | 4456.1 samples/s | 69.6 steps/s
[Step=67950 Epoch=132.5] | Loss=0.00593 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.418 | L2-Norm(final)=12.613 | 4449.0 samples/s | 69.5 steps/s
[Step=68000 Epoch=132.6] | Loss=0.00589 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.616 | 4504.9 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step68000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=129.0] | Loss=0.00321 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=12.514 | 6334.2 samples/s | 99.0 steps/s
[Step=66050 Epoch=129.1] | Loss=0.00656 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.470 | L2-Norm(final)=12.518 | 4353.0 samples/s | 68.0 steps/s
[Step=66100 Epoch=129.2] | Loss=0.00672 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.472 | L2-Norm(final)=12.523 | 5045.5 samples/s | 78.8 steps/s
[Step=66150 Epoch=129.3] | Loss=0.00610 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.474 | L2-Norm(final)=12.529 | 5049.0 samples/s | 78.9 steps/s
[Step=66200 Epoch=129.4] | Loss=0.00644 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=12.535 | 5036.9 samples/s | 78.7 steps/s
[Step=66250 Epoch=129.5] | Loss=0.00621 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.478 | L2-Norm(final)=12.541 | 4915.0 samples/s | 76.8 steps/s
[Step=66300 Epoch=129.6] | Loss=0.00622 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.480 | L2-Norm(final)=12.547 | 4982.1 samples/s | 77.8 steps/s
[Step=66350 Epoch=129.7] | Loss=0.00631 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.481 | L2-Norm(final)=12.553 | 5018.1 samples/s | 78.4 steps/s
[Step=66400 Epoch=129.8] | Loss=0.00616 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.483 | L2-Norm(final)=12.559 | 5082.4 samples/s | 79.4 steps/s
[Step=66450 Epoch=129.9] | Loss=0.00623 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.484 | L2-Norm(final)=12.565 | 5024.4 samples/s | 78.5 steps/s
[Step=66500 Epoch=130.0] | Loss=0.00611 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.486 | L2-Norm(final)=12.570 | 6908.5 samples/s | 107.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=130.0] | Loss=0.00329 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.499 | L2-Norm(final)=12.627 | 6733.4 samples/s | 105.2 steps/s
[Step=66550 Epoch=130.1] | Loss=0.00691 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.501 | L2-Norm(final)=12.632 | 4033.6 samples/s | 63.0 steps/s
[Step=66600 Epoch=130.2] | Loss=0.00700 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.505 | L2-Norm(final)=12.637 | 4466.0 samples/s | 69.8 steps/s
[Step=66650 Epoch=130.3] | Loss=0.00647 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=12.642 | 4458.1 samples/s | 69.7 steps/s
[Step=66700 Epoch=130.4] | Loss=0.00657 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.511 | L2-Norm(final)=12.647 | 4393.5 samples/s | 68.6 steps/s
[Step=66750 Epoch=130.5] | Loss=0.00677 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.514 | L2-Norm(final)=12.652 | 4460.8 samples/s | 69.7 steps/s
[Step=66800 Epoch=130.6] | Loss=0.00666 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.516 | L2-Norm(final)=12.656 | 4533.7 samples/s | 70.8 steps/s
[Step=66850 Epoch=130.7] | Loss=0.00676 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.519 | L2-Norm(final)=12.661 | 4431.3 samples/s | 69.2 steps/s
[Step=66900 Epoch=130.8] | Loss=0.00666 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.521 | L2-Norm(final)=12.665 | 4508.5 samples/s | 70.4 steps/s
[Step=66950 Epoch=130.9] | Loss=0.00673 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.523 | L2-Norm(final)=12.669 | 4431.8 samples/s | 69.2 steps/s
[Step=67000 Epoch=131.0] | Loss=0.00688 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.524 | L2-Norm(final)=12.673 | 5938.6 samples/s | 92.8 steps/s
[Step=67050 Epoch=131.1] | Loss=0.00685 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.526 | L2-Norm(final)=12.677 | 2375.8 samples/s | 37.1 steps/s
[Step=67100 Epoch=131.2] | Loss=0.00674 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.527 | L2-Norm(final)=12.681 | 4398.5 samples/s | 68.7 steps/s
[Step=67150 Epoch=131.3] | Loss=0.00661 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.528 | L2-Norm(final)=12.684 | 4451.9 samples/s | 69.6 steps/s
[Step=67200 Epoch=131.4] | Loss=0.00658 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.529 | L2-Norm(final)=12.688 | 4491.2 samples/s | 70.2 steps/s
[Step=67250 Epoch=131.5] | Loss=0.00649 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.530 | L2-Norm(final)=12.692 | 4491.3 samples/s | 70.2 steps/s
[Step=67300 Epoch=131.6] | Loss=0.00643 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.531 | L2-Norm(final)=12.695 | 4466.9 samples/s | 69.8 steps/s
[Step=67350 Epoch=131.7] | Loss=0.00633 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=12.699 | 4450.5 samples/s | 69.5 steps/s
[Step=67400 Epoch=131.8] | Loss=0.00630 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=12.702 | 4479.6 samples/s | 70.0 steps/s
[Step=67450 Epoch=131.9] | Loss=0.00626 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.533 | L2-Norm(final)=12.705 | 4444.7 samples/s | 69.4 steps/s
[Step=67500 Epoch=132.0] | Loss=0.00624 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.533 | L2-Norm(final)=12.708 | 4885.2 samples/s | 76.3 steps/s
[Step=67550 Epoch=132.1] | Loss=0.00615 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.533 | L2-Norm(final)=12.711 | 2576.3 samples/s | 40.3 steps/s
[Step=67600 Epoch=132.2] | Loss=0.00606 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.715 | 4463.6 samples/s | 69.7 steps/s
[Step=67650 Epoch=132.3] | Loss=0.00600 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.534 | L2-Norm(final)=12.718 | 4507.5 samples/s | 70.4 steps/s
[Step=67700 Epoch=132.4] | Loss=0.00596 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.721 | 4417.6 samples/s | 69.0 steps/s
[Step=67750 Epoch=132.4] | Loss=0.00592 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.724 | 4528.1 samples/s | 70.8 steps/s
[Step=67800 Epoch=132.5] | Loss=0.00588 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.727 | 4403.9 samples/s | 68.8 steps/s
[Step=67850 Epoch=132.6] | Loss=0.00587 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.730 | 4386.5 samples/s | 68.5 steps/s
[Step=67900 Epoch=132.7] | Loss=0.00588 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.733 | 4523.8 samples/s | 70.7 steps/s
[Step=67950 Epoch=132.8] | Loss=0.00586 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.735 | 4420.0 samples/s | 69.1 steps/s
[Step=68000 Epoch=132.9] | Loss=0.00579 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=12.738 | 4476.4 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step68000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=252.9] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.130 | L2-Norm(final)=7.925 | 6097.2 samples/s | 95.3 steps/s
[Step=66050 Epoch=253.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=7.927 | 4146.0 samples/s | 64.8 steps/s
[Step=66100 Epoch=253.3] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.928 | 4717.7 samples/s | 73.7 steps/s
[Step=66150 Epoch=253.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.929 | 4805.7 samples/s | 75.1 steps/s
[Step=66200 Epoch=253.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.930 | 4637.6 samples/s | 72.5 steps/s
[Step=66250 Epoch=253.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.931 | 6569.3 samples/s | 102.6 steps/s
[Step=66300 Epoch=254.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.932 | 2416.0 samples/s | 37.8 steps/s
[Step=66350 Epoch=254.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.933 | 4811.5 samples/s | 75.2 steps/s
[Step=66400 Epoch=254.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.934 | 4703.4 samples/s | 73.5 steps/s
[Step=66450 Epoch=254.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.935 | 4674.3 samples/s | 73.0 steps/s
[Step=66500 Epoch=254.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.936 | 5505.8 samples/s | 86.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=254.8] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.946 | 5639.3 samples/s | 88.1 steps/s
[Step=66550 Epoch=255.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=7.947 | 4049.4 samples/s | 63.3 steps/s
[Step=66600 Epoch=255.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.129 | L2-Norm(final)=7.948 | 4143.4 samples/s | 64.7 steps/s
[Step=66650 Epoch=255.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.126 | L2-Norm(final)=7.949 | 4230.5 samples/s | 66.1 steps/s
[Step=66700 Epoch=255.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.123 | L2-Norm(final)=7.950 | 4243.3 samples/s | 66.3 steps/s
[Step=66750 Epoch=255.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.120 | L2-Norm(final)=7.950 | 5692.6 samples/s | 88.9 steps/s
[Step=66800 Epoch=256.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.117 | L2-Norm(final)=7.951 | 2265.2 samples/s | 35.4 steps/s
[Step=66850 Epoch=256.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.114 | L2-Norm(final)=7.952 | 4373.4 samples/s | 68.3 steps/s
[Step=66900 Epoch=256.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.111 | L2-Norm(final)=7.953 | 4161.4 samples/s | 65.0 steps/s
[Step=66950 Epoch=256.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.107 | L2-Norm(final)=7.954 | 4235.8 samples/s | 66.2 steps/s
[Step=67000 Epoch=256.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=7.954 | 4687.1 samples/s | 73.2 steps/s
[Step=67050 Epoch=256.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.101 | L2-Norm(final)=7.955 | 2446.9 samples/s | 38.2 steps/s
[Step=67100 Epoch=257.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=7.956 | 4211.5 samples/s | 65.8 steps/s
[Step=67150 Epoch=257.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.093 | L2-Norm(final)=7.956 | 4226.7 samples/s | 66.0 steps/s
[Step=67200 Epoch=257.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.090 | L2-Norm(final)=7.957 | 4233.3 samples/s | 66.1 steps/s
[Step=67250 Epoch=257.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.086 | L2-Norm(final)=7.958 | 4244.8 samples/s | 66.3 steps/s
[Step=67300 Epoch=257.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=7.958 | 2598.3 samples/s | 40.6 steps/s
[Step=67350 Epoch=258.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=7.959 | 4289.9 samples/s | 67.0 steps/s
[Step=67400 Epoch=258.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=7.960 | 4162.6 samples/s | 65.0 steps/s
[Step=67450 Epoch=258.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.070 | L2-Norm(final)=7.960 | 4199.9 samples/s | 65.6 steps/s
[Step=67500 Epoch=258.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=7.961 | 4245.9 samples/s | 66.3 steps/s
[Step=67550 Epoch=258.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=7.962 | 2612.8 samples/s | 40.8 steps/s
[Step=67600 Epoch=259.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.058 | L2-Norm(final)=7.962 | 4201.1 samples/s | 65.6 steps/s
[Step=67650 Epoch=259.2] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.054 | L2-Norm(final)=7.963 | 4181.0 samples/s | 65.3 steps/s
[Step=67700 Epoch=259.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.050 | L2-Norm(final)=7.964 | 4290.8 samples/s | 67.0 steps/s
[Step=67750 Epoch=259.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.045 | L2-Norm(final)=7.964 | 4238.2 samples/s | 66.2 steps/s
[Step=67800 Epoch=259.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.041 | L2-Norm(final)=7.965 | 6133.6 samples/s | 95.8 steps/s
[Step=67850 Epoch=260.0] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.036 | L2-Norm(final)=7.966 | 2181.9 samples/s | 34.1 steps/s
[Step=67900 Epoch=260.2] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.032 | L2-Norm(final)=7.966 | 4226.1 samples/s | 66.0 steps/s
[Step=67950 Epoch=260.4] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.027 | L2-Norm(final)=7.967 | 4219.2 samples/s | 65.9 steps/s
[Step=68000 Epoch=260.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.022 | L2-Norm(final)=7.968 | 4217.4 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step68000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=254.1] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.508 | 5935.4 samples/s | 92.7 steps/s
[Step=66050 Epoch=254.3] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.098 | L2-Norm(final)=8.511 | 4113.9 samples/s | 64.3 steps/s
[Step=66100 Epoch=254.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.515 | 4783.8 samples/s | 74.7 steps/s
[Step=66150 Epoch=254.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.519 | 4695.2 samples/s | 73.4 steps/s
[Step=66200 Epoch=254.8] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.523 | 4698.2 samples/s | 73.4 steps/s
[Step=66250 Epoch=255.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.101 | L2-Norm(final)=8.527 | 6844.6 samples/s | 106.9 steps/s
[Step=66300 Epoch=255.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.102 | L2-Norm(final)=8.531 | 2398.0 samples/s | 37.5 steps/s
[Step=66350 Epoch=255.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.102 | L2-Norm(final)=8.535 | 4743.5 samples/s | 74.1 steps/s
[Step=66400 Epoch=255.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=8.540 | 4862.5 samples/s | 76.0 steps/s
[Step=66450 Epoch=255.8] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=8.544 | 4631.0 samples/s | 72.4 steps/s
[Step=66500 Epoch=256.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=8.548 | 5582.5 samples/s | 87.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=256.0] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=8.586 | 5861.5 samples/s | 91.6 steps/s
[Step=66550 Epoch=256.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=8.590 | 3967.6 samples/s | 62.0 steps/s
[Step=66600 Epoch=256.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.096 | L2-Norm(final)=8.593 | 4231.5 samples/s | 66.1 steps/s
[Step=66650 Epoch=256.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=8.596 | 4173.3 samples/s | 65.2 steps/s
[Step=66700 Epoch=256.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.079 | L2-Norm(final)=8.599 | 4294.2 samples/s | 67.1 steps/s
[Step=66750 Epoch=256.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=8.601 | 5671.6 samples/s | 88.6 steps/s
[Step=66800 Epoch=257.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=8.603 | 2232.4 samples/s | 34.9 steps/s
[Step=66850 Epoch=257.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.053 | L2-Norm(final)=8.605 | 4301.2 samples/s | 67.2 steps/s
[Step=66900 Epoch=257.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.044 | L2-Norm(final)=8.607 | 4169.5 samples/s | 65.1 steps/s
[Step=66950 Epoch=257.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=8.609 | 4221.1 samples/s | 66.0 steps/s
[Step=67000 Epoch=257.9] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.024 | L2-Norm(final)=8.610 | 5001.0 samples/s | 78.1 steps/s
[Step=67050 Epoch=258.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=8.612 | 2439.4 samples/s | 38.1 steps/s
[Step=67100 Epoch=258.3] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=8.614 | 4090.8 samples/s | 63.9 steps/s
[Step=67150 Epoch=258.5] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=8.616 | 4338.1 samples/s | 67.8 steps/s
[Step=67200 Epoch=258.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.983 | L2-Norm(final)=8.617 | 4159.7 samples/s | 65.0 steps/s
[Step=67250 Epoch=258.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=8.619 | 4338.3 samples/s | 67.8 steps/s
[Step=67300 Epoch=259.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.962 | L2-Norm(final)=8.621 | 2649.6 samples/s | 41.4 steps/s
[Step=67350 Epoch=259.3] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.951 | L2-Norm(final)=8.623 | 4083.5 samples/s | 63.8 steps/s
[Step=67400 Epoch=259.4] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.940 | L2-Norm(final)=8.624 | 4296.2 samples/s | 67.1 steps/s
[Step=67450 Epoch=259.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.929 | L2-Norm(final)=8.626 | 4259.4 samples/s | 66.6 steps/s
[Step=67500 Epoch=259.8] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.918 | L2-Norm(final)=8.628 | 4062.8 samples/s | 63.5 steps/s
[Step=67550 Epoch=260.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.907 | L2-Norm(final)=8.630 | 2649.9 samples/s | 41.4 steps/s
[Step=67600 Epoch=260.2] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.895 | L2-Norm(final)=8.632 | 4280.7 samples/s | 66.9 steps/s
[Step=67650 Epoch=260.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.884 | L2-Norm(final)=8.634 | 4163.6 samples/s | 65.1 steps/s
[Step=67700 Epoch=260.6] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.872 | L2-Norm(final)=8.636 | 4289.4 samples/s | 67.0 steps/s
[Step=67750 Epoch=260.8] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.860 | L2-Norm(final)=8.638 | 4188.2 samples/s | 65.4 steps/s
[Step=67800 Epoch=261.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.848 | L2-Norm(final)=8.640 | 7035.6 samples/s | 109.9 steps/s
[Step=67850 Epoch=261.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.836 | L2-Norm(final)=8.642 | 2088.6 samples/s | 32.6 steps/s
[Step=67900 Epoch=261.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=8.644 | 4272.4 samples/s | 66.8 steps/s
[Step=67950 Epoch=261.6] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.811 | L2-Norm(final)=8.646 | 4265.1 samples/s | 66.6 steps/s
[Step=68000 Epoch=261.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.799 | L2-Norm(final)=8.648 | 4161.9 samples/s | 65.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07396 | acc=0.9672 | tpr=0.9770 | fpr=0.0540 | 4798.1 samples/s | 18.7 steps/s
Avg test loss: 0.07467, Avg test acc: 0.96735, Avg tpr: 0.97715, Avg fpr: 0.05422, total FA: 423

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07516 | acc=0.9662 | tpr=0.9719 | fpr=0.0463 | 5061.2 samples/s | 19.8 steps/s
Avg test loss: 0.07641, Avg test acc: 0.96546, Avg tpr: 0.97103, Avg fpr: 0.04679, total FA: 365

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.23646 | acc=0.3042 | tpr=0.0111 | fpr=0.0592 | 4943.9 samples/s | 19.3 steps/s
Avg test loss: 5.23522, Avg test acc: 0.30030, Avg tpr: 0.01166, Avg fpr: 0.06486, total FA: 506

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.67528 | acc=0.3129 | tpr=0.0129 | fpr=0.0357 | 5117.5 samples/s | 20.0 steps/s
Avg test loss: 5.66575, Avg test acc: 0.30964, Avg tpr: 0.01463, Avg fpr: 0.04153, total FA: 324

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.43092 | acc=0.1358 | tpr=0.5664 | fpr=0.8720 | 4965.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=6.40022 | acc=0.1348 | tpr=0.5373 | fpr=0.8727 | 7035.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.40033 | acc=0.1351 | tpr=0.5375 | fpr=0.8723 | 7828.5 samples/s | 30.6 steps/s
[Step= 200] | Loss=6.39829 | acc=0.1355 | tpr=0.5355 | fpr=0.8718 | 7796.0 samples/s | 30.5 steps/s
[Step= 250] | Loss=6.38707 | acc=0.1361 | tpr=0.5502 | fpr=0.8715 | 8377.3 samples/s | 32.7 steps/s
[Step= 300] | Loss=6.38051 | acc=0.1358 | tpr=0.5455 | fpr=0.8716 | 7486.9 samples/s | 29.2 steps/s
[Step= 350] | Loss=6.38451 | acc=0.1354 | tpr=0.5316 | fpr=0.8718 | 7527.3 samples/s | 29.4 steps/s
[Step= 400] | Loss=6.38462 | acc=0.1355 | tpr=0.5306 | fpr=0.8717 | 8152.2 samples/s | 31.8 steps/s
[Step= 450] | Loss=6.38860 | acc=0.1352 | tpr=0.5287 | fpr=0.8720 | 7828.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.39098 | acc=0.1354 | tpr=0.5282 | fpr=0.8717 | 7626.8 samples/s | 29.8 steps/s
[Step= 550] | Loss=6.39340 | acc=0.1356 | tpr=0.5285 | fpr=0.8715 | 13780.5 samples/s | 53.8 steps/s
Avg test loss: 6.39495, Avg test acc: 0.13552, Avg tpr: 0.52971, Avg fpr: 0.87164, total FA: 121026

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.91369 | acc=0.1283 | tpr=0.5575 | fpr=0.8794 | 4944.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.90568 | acc=0.1287 | tpr=0.5245 | fpr=0.8787 | 6998.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.90050 | acc=0.1293 | tpr=0.5259 | fpr=0.8780 | 7867.2 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.89509 | acc=0.1294 | tpr=0.5235 | fpr=0.8778 | 7925.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.88158 | acc=0.1298 | tpr=0.5223 | fpr=0.8774 | 7865.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.87521 | acc=0.1299 | tpr=0.5164 | fpr=0.8771 | 7732.1 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.88055 | acc=0.1297 | tpr=0.5078 | fpr=0.8772 | 8057.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.87776 | acc=0.1295 | tpr=0.5033 | fpr=0.8773 | 7777.9 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.88135 | acc=0.1294 | tpr=0.5000 | fpr=0.8774 | 7484.0 samples/s | 29.2 steps/s
[Step= 500] | Loss=6.88284 | acc=0.1298 | tpr=0.5031 | fpr=0.8769 | 7967.1 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.88781 | acc=0.1298 | tpr=0.5018 | fpr=0.8770 | 14262.2 samples/s | 55.7 steps/s
Avg test loss: 6.88970, Avg test acc: 0.12964, Avg tpr: 0.50277, Avg fpr: 0.87715, total FA: 121790

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12261 | acc=0.9778 | tpr=0.9513 | fpr=0.0217 | 4912.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.12348 | acc=0.9786 | tpr=0.9595 | fpr=0.0211 | 7096.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.12906 | acc=0.9774 | tpr=0.9597 | fpr=0.0223 | 8139.9 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.13213 | acc=0.9775 | tpr=0.9607 | fpr=0.0222 | 7863.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12948 | acc=0.9779 | tpr=0.9616 | fpr=0.0218 | 7745.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.13108 | acc=0.9777 | tpr=0.9607 | fpr=0.0220 | 7772.4 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.13129 | acc=0.9777 | tpr=0.9612 | fpr=0.0220 | 8035.9 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.13264 | acc=0.9776 | tpr=0.9612 | fpr=0.0221 | 7905.3 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13506 | acc=0.9772 | tpr=0.9591 | fpr=0.0224 | 7915.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.13426 | acc=0.9774 | tpr=0.9599 | fpr=0.0223 | 7815.8 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13288 | acc=0.9776 | tpr=0.9602 | fpr=0.0221 | 13514.9 samples/s | 52.8 steps/s
Avg test loss: 0.13273, Avg test acc: 0.97759, Avg tpr: 0.95998, Avg fpr: 0.02209, total FA: 3067

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11790 | acc=0.9780 | tpr=0.9558 | fpr=0.0216 | 4989.6 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.11974 | acc=0.9786 | tpr=0.9659 | fpr=0.0212 | 7239.5 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.12578 | acc=0.9778 | tpr=0.9640 | fpr=0.0219 | 7395.8 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.12864 | acc=0.9775 | tpr=0.9628 | fpr=0.0222 | 7975.2 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.12657 | acc=0.9777 | tpr=0.9633 | fpr=0.0221 | 7942.6 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.12836 | acc=0.9775 | tpr=0.9607 | fpr=0.0222 | 7677.7 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.12865 | acc=0.9773 | tpr=0.9618 | fpr=0.0224 | 8495.2 samples/s | 33.2 steps/s
[Step= 400] | Loss=0.12987 | acc=0.9773 | tpr=0.9606 | fpr=0.0224 | 7365.0 samples/s | 28.8 steps/s
[Step= 450] | Loss=0.13233 | acc=0.9770 | tpr=0.9576 | fpr=0.0227 | 7863.9 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.13173 | acc=0.9771 | tpr=0.9577 | fpr=0.0225 | 8015.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.13039 | acc=0.9773 | tpr=0.9574 | fpr=0.0223 | 13846.6 samples/s | 54.1 steps/s
Avg test loss: 0.13027, Avg test acc: 0.97732, Avg tpr: 0.95721, Avg fpr: 0.02232, total FA: 3099

server round 34/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=132.6] | Loss=0.01229 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.269 | L2-Norm(final)=12.713 | 6172.6 samples/s | 96.4 steps/s
[Step=68050 Epoch=132.7] | Loss=0.00636 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.270 | L2-Norm(final)=12.717 | 4666.8 samples/s | 72.9 steps/s
[Step=68100 Epoch=132.8] | Loss=0.00574 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.271 | L2-Norm(final)=12.722 | 5070.8 samples/s | 79.2 steps/s
[Step=68150 Epoch=132.9] | Loss=0.00606 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.272 | L2-Norm(final)=12.727 | 4980.2 samples/s | 77.8 steps/s
[Step=68200 Epoch=133.0] | Loss=0.00587 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.273 | L2-Norm(final)=12.733 | 5013.9 samples/s | 78.3 steps/s
[Step=68250 Epoch=133.1] | Loss=0.00565 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.274 | L2-Norm(final)=12.740 | 5080.0 samples/s | 79.4 steps/s
[Step=68300 Epoch=133.2] | Loss=0.00552 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=12.746 | 5128.6 samples/s | 80.1 steps/s
[Step=68350 Epoch=133.3] | Loss=0.00551 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=12.752 | 5044.7 samples/s | 78.8 steps/s
[Step=68400 Epoch=133.4] | Loss=0.00564 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.276 | L2-Norm(final)=12.758 | 5031.5 samples/s | 78.6 steps/s
[Step=68450 Epoch=133.5] | Loss=0.00567 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.276 | L2-Norm(final)=12.763 | 4974.3 samples/s | 77.7 steps/s
[Step=68500 Epoch=133.6] | Loss=0.00558 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.277 | L2-Norm(final)=12.769 | 6754.6 samples/s | 105.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=133.6] | Loss=0.00306 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.284 | L2-Norm(final)=12.825 | 5787.3 samples/s | 90.4 steps/s
[Step=68550 Epoch=133.7] | Loss=0.00658 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.286 | L2-Norm(final)=12.830 | 4386.0 samples/s | 68.5 steps/s
[Step=68600 Epoch=133.8] | Loss=0.00774 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.289 | L2-Norm(final)=12.835 | 4553.3 samples/s | 71.1 steps/s
[Step=68650 Epoch=133.9] | Loss=0.00748 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.291 | L2-Norm(final)=12.839 | 4343.0 samples/s | 67.9 steps/s
[Step=68700 Epoch=134.0] | Loss=0.00760 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.294 | L2-Norm(final)=12.844 | 4462.1 samples/s | 69.7 steps/s
[Step=68750 Epoch=134.1] | Loss=0.00742 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.296 | L2-Norm(final)=12.848 | 4502.0 samples/s | 70.3 steps/s
[Step=68800 Epoch=134.2] | Loss=0.00720 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.297 | L2-Norm(final)=12.853 | 4475.0 samples/s | 69.9 steps/s
[Step=68850 Epoch=134.3] | Loss=0.00721 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.299 | L2-Norm(final)=12.858 | 4441.3 samples/s | 69.4 steps/s
[Step=68900 Epoch=134.4] | Loss=0.00707 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.301 | L2-Norm(final)=12.862 | 4471.1 samples/s | 69.9 steps/s
[Step=68950 Epoch=134.5] | Loss=0.00706 | Reg=0.00266 | acc=0.9531 | L2-Norm=16.302 | L2-Norm(final)=12.867 | 4505.6 samples/s | 70.4 steps/s
[Step=69000 Epoch=134.6] | Loss=0.00715 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=12.872 | 5737.6 samples/s | 89.7 steps/s
[Step=69050 Epoch=134.7] | Loss=0.00697 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.305 | L2-Norm(final)=12.876 | 2413.6 samples/s | 37.7 steps/s
[Step=69100 Epoch=134.8] | Loss=0.00696 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.306 | L2-Norm(final)=12.880 | 4474.8 samples/s | 69.9 steps/s
[Step=69150 Epoch=134.9] | Loss=0.00693 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=12.884 | 4366.8 samples/s | 68.2 steps/s
[Step=69200 Epoch=135.0] | Loss=0.00688 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.308 | L2-Norm(final)=12.888 | 4472.3 samples/s | 69.9 steps/s
[Step=69250 Epoch=135.1] | Loss=0.00676 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.309 | L2-Norm(final)=12.892 | 4452.9 samples/s | 69.6 steps/s
[Step=69300 Epoch=135.2] | Loss=0.00668 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.310 | L2-Norm(final)=12.896 | 4517.0 samples/s | 70.6 steps/s
[Step=69350 Epoch=135.3] | Loss=0.00660 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.310 | L2-Norm(final)=12.900 | 4445.8 samples/s | 69.5 steps/s
[Step=69400 Epoch=135.4] | Loss=0.00658 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=12.904 | 4499.6 samples/s | 70.3 steps/s
[Step=69450 Epoch=135.5] | Loss=0.00654 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=12.908 | 4482.3 samples/s | 70.0 steps/s
[Step=69500 Epoch=135.6] | Loss=0.00646 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.312 | L2-Norm(final)=12.912 | 4811.8 samples/s | 75.2 steps/s
[Step=69550 Epoch=135.6] | Loss=0.00635 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.312 | L2-Norm(final)=12.915 | 2648.2 samples/s | 41.4 steps/s
[Step=69600 Epoch=135.7] | Loss=0.00632 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.313 | L2-Norm(final)=12.919 | 4374.2 samples/s | 68.3 steps/s
[Step=69650 Epoch=135.8] | Loss=0.00624 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.313 | L2-Norm(final)=12.923 | 4451.7 samples/s | 69.6 steps/s
[Step=69700 Epoch=135.9] | Loss=0.00615 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.313 | L2-Norm(final)=12.926 | 4522.3 samples/s | 70.7 steps/s
[Step=69750 Epoch=136.0] | Loss=0.00609 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.313 | L2-Norm(final)=12.930 | 4566.0 samples/s | 71.3 steps/s
[Step=69800 Epoch=136.1] | Loss=0.00611 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=12.933 | 4351.3 samples/s | 68.0 steps/s
[Step=69850 Epoch=136.2] | Loss=0.00609 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.314 | L2-Norm(final)=12.937 | 4536.4 samples/s | 70.9 steps/s
[Step=69900 Epoch=136.3] | Loss=0.00606 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=12.940 | 4412.4 samples/s | 68.9 steps/s
[Step=69950 Epoch=136.4] | Loss=0.00606 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=12.944 | 4495.4 samples/s | 70.2 steps/s
[Step=70000 Epoch=136.5] | Loss=0.00600 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=12.947 | 4448.0 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step70000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=132.9] | Loss=0.00530 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.382 | L2-Norm(final)=12.826 | 6237.4 samples/s | 97.5 steps/s
[Step=68050 Epoch=133.0] | Loss=0.00510 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.384 | L2-Norm(final)=12.832 | 4504.9 samples/s | 70.4 steps/s
[Step=68100 Epoch=133.1] | Loss=0.00556 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=12.838 | 4894.1 samples/s | 76.5 steps/s
[Step=68150 Epoch=133.2] | Loss=0.00564 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.386 | L2-Norm(final)=12.844 | 5083.1 samples/s | 79.4 steps/s
[Step=68200 Epoch=133.3] | Loss=0.00568 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.387 | L2-Norm(final)=12.849 | 4994.3 samples/s | 78.0 steps/s
[Step=68250 Epoch=133.4] | Loss=0.00541 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.387 | L2-Norm(final)=12.854 | 5146.1 samples/s | 80.4 steps/s
[Step=68300 Epoch=133.5] | Loss=0.00551 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.388 | L2-Norm(final)=12.859 | 4973.5 samples/s | 77.7 steps/s
[Step=68350 Epoch=133.6] | Loss=0.00543 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.388 | L2-Norm(final)=12.865 | 5049.9 samples/s | 78.9 steps/s
[Step=68400 Epoch=133.7] | Loss=0.00537 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.389 | L2-Norm(final)=12.870 | 5000.8 samples/s | 78.1 steps/s
[Step=68450 Epoch=133.8] | Loss=0.00538 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.390 | L2-Norm(final)=12.876 | 5091.0 samples/s | 79.5 steps/s
[Step=68500 Epoch=133.9] | Loss=0.00531 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.390 | L2-Norm(final)=12.881 | 6912.3 samples/s | 108.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=133.9] | Loss=0.00701 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.397 | L2-Norm(final)=12.936 | 6368.9 samples/s | 99.5 steps/s
[Step=68550 Epoch=134.0] | Loss=0.00557 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.400 | L2-Norm(final)=12.942 | 4152.9 samples/s | 64.9 steps/s
[Step=68600 Epoch=134.1] | Loss=0.00673 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.402 | L2-Norm(final)=12.946 | 4333.2 samples/s | 67.7 steps/s
[Step=68650 Epoch=134.2] | Loss=0.00717 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=12.950 | 4480.4 samples/s | 70.0 steps/s
[Step=68700 Epoch=134.3] | Loss=0.00717 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.408 | L2-Norm(final)=12.954 | 4489.9 samples/s | 70.2 steps/s
[Step=68750 Epoch=134.4] | Loss=0.00732 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.411 | L2-Norm(final)=12.959 | 4460.9 samples/s | 69.7 steps/s
[Step=68800 Epoch=134.5] | Loss=0.00735 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.413 | L2-Norm(final)=12.964 | 4491.9 samples/s | 70.2 steps/s
[Step=68850 Epoch=134.6] | Loss=0.00738 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.416 | L2-Norm(final)=12.969 | 4502.9 samples/s | 70.4 steps/s
[Step=68900 Epoch=134.7] | Loss=0.00717 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=12.973 | 4568.5 samples/s | 71.4 steps/s
[Step=68950 Epoch=134.8] | Loss=0.00707 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.420 | L2-Norm(final)=12.978 | 4374.5 samples/s | 68.4 steps/s
[Step=69000 Epoch=134.9] | Loss=0.00688 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=12.982 | 5882.3 samples/s | 91.9 steps/s
[Step=69050 Epoch=135.0] | Loss=0.00683 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.424 | L2-Norm(final)=12.987 | 2377.8 samples/s | 37.2 steps/s
[Step=69100 Epoch=135.1] | Loss=0.00676 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.425 | L2-Norm(final)=12.991 | 4458.5 samples/s | 69.7 steps/s
[Step=69150 Epoch=135.2] | Loss=0.00662 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.426 | L2-Norm(final)=12.995 | 4468.5 samples/s | 69.8 steps/s
[Step=69200 Epoch=135.3] | Loss=0.00638 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.427 | L2-Norm(final)=12.999 | 4472.2 samples/s | 69.9 steps/s
[Step=69250 Epoch=135.4] | Loss=0.00627 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.428 | L2-Norm(final)=13.003 | 4476.6 samples/s | 69.9 steps/s
[Step=69300 Epoch=135.5] | Loss=0.00635 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.429 | L2-Norm(final)=13.006 | 4500.6 samples/s | 70.3 steps/s
[Step=69350 Epoch=135.6] | Loss=0.00622 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.430 | L2-Norm(final)=13.010 | 4412.9 samples/s | 69.0 steps/s
[Step=69400 Epoch=135.7] | Loss=0.00617 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.431 | L2-Norm(final)=13.014 | 4540.6 samples/s | 70.9 steps/s
[Step=69450 Epoch=135.8] | Loss=0.00623 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.431 | L2-Norm(final)=13.018 | 4427.2 samples/s | 69.2 steps/s
[Step=69500 Epoch=135.9] | Loss=0.00633 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.432 | L2-Norm(final)=13.021 | 4978.7 samples/s | 77.8 steps/s
[Step=69550 Epoch=136.0] | Loss=0.00627 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.433 | L2-Norm(final)=13.024 | 2579.2 samples/s | 40.3 steps/s
[Step=69600 Epoch=136.1] | Loss=0.00615 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.433 | L2-Norm(final)=13.028 | 4429.0 samples/s | 69.2 steps/s
[Step=69650 Epoch=136.2] | Loss=0.00611 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.433 | L2-Norm(final)=13.031 | 4479.4 samples/s | 70.0 steps/s
[Step=69700 Epoch=136.3] | Loss=0.00607 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.434 | L2-Norm(final)=13.034 | 4468.2 samples/s | 69.8 steps/s
[Step=69750 Epoch=136.4] | Loss=0.00601 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.434 | L2-Norm(final)=13.038 | 4499.4 samples/s | 70.3 steps/s
[Step=69800 Epoch=136.5] | Loss=0.00598 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.435 | L2-Norm(final)=13.041 | 4431.4 samples/s | 69.2 steps/s
[Step=69850 Epoch=136.6] | Loss=0.00596 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.435 | L2-Norm(final)=13.044 | 4533.3 samples/s | 70.8 steps/s
[Step=69900 Epoch=136.7] | Loss=0.00593 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.435 | L2-Norm(final)=13.047 | 4448.5 samples/s | 69.5 steps/s
[Step=69950 Epoch=136.8] | Loss=0.00591 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.435 | L2-Norm(final)=13.051 | 4458.0 samples/s | 69.7 steps/s
[Step=70000 Epoch=136.8] | Loss=0.00589 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.436 | L2-Norm(final)=13.054 | 4629.8 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step70000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=260.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.953 | L2-Norm(final)=7.988 | 6287.1 samples/s | 98.2 steps/s
[Step=68050 Epoch=260.7] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.953 | L2-Norm(final)=7.991 | 4208.6 samples/s | 65.8 steps/s
[Step=68100 Epoch=260.9] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.954 | L2-Norm(final)=7.994 | 4564.4 samples/s | 71.3 steps/s
[Step=68150 Epoch=261.1] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.955 | L2-Norm(final)=7.997 | 4783.4 samples/s | 74.7 steps/s
[Step=68200 Epoch=261.3] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.955 | L2-Norm(final)=8.000 | 4809.5 samples/s | 75.1 steps/s
[Step=68250 Epoch=261.5] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.956 | L2-Norm(final)=8.003 | 6437.8 samples/s | 100.6 steps/s
[Step=68300 Epoch=261.7] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.956 | L2-Norm(final)=8.006 | 2390.8 samples/s | 37.4 steps/s
[Step=68350 Epoch=261.9] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=8.009 | 4803.0 samples/s | 75.0 steps/s
[Step=68400 Epoch=262.1] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=8.012 | 4706.4 samples/s | 73.5 steps/s
[Step=68450 Epoch=262.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=8.015 | 4689.8 samples/s | 73.3 steps/s
[Step=68500 Epoch=262.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=8.018 | 5494.3 samples/s | 85.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=262.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.962 | L2-Norm(final)=8.048 | 5934.8 samples/s | 92.7 steps/s
[Step=68550 Epoch=262.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=8.050 | 3949.1 samples/s | 61.7 steps/s
[Step=68600 Epoch=262.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.951 | L2-Norm(final)=8.053 | 4233.9 samples/s | 66.2 steps/s
[Step=68650 Epoch=263.0] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=8.056 | 4239.5 samples/s | 66.2 steps/s
[Step=68700 Epoch=263.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.938 | L2-Norm(final)=8.058 | 4242.9 samples/s | 66.3 steps/s
[Step=68750 Epoch=263.4] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.930 | L2-Norm(final)=8.060 | 5729.2 samples/s | 89.5 steps/s
[Step=68800 Epoch=263.6] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=8.062 | 2276.7 samples/s | 35.6 steps/s
[Step=68850 Epoch=263.8] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.915 | L2-Norm(final)=8.064 | 4224.4 samples/s | 66.0 steps/s
[Step=68900 Epoch=264.0] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.907 | L2-Norm(final)=8.066 | 4237.6 samples/s | 66.2 steps/s
[Step=68950 Epoch=264.2] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.899 | L2-Norm(final)=8.067 | 4259.9 samples/s | 66.6 steps/s
[Step=69000 Epoch=264.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.890 | L2-Norm(final)=8.069 | 4799.8 samples/s | 75.0 steps/s
[Step=69050 Epoch=264.6] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.882 | L2-Norm(final)=8.070 | 2475.1 samples/s | 38.7 steps/s
[Step=69100 Epoch=264.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.873 | L2-Norm(final)=8.072 | 4250.7 samples/s | 66.4 steps/s
[Step=69150 Epoch=265.0] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.864 | L2-Norm(final)=8.073 | 4136.3 samples/s | 64.6 steps/s
[Step=69200 Epoch=265.1] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.855 | L2-Norm(final)=8.075 | 4319.5 samples/s | 67.5 steps/s
[Step=69250 Epoch=265.3] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.846 | L2-Norm(final)=8.076 | 4142.1 samples/s | 64.7 steps/s
[Step=69300 Epoch=265.5] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.837 | L2-Norm(final)=8.078 | 2630.2 samples/s | 41.1 steps/s
[Step=69350 Epoch=265.7] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.828 | L2-Norm(final)=8.079 | 4267.7 samples/s | 66.7 steps/s
[Step=69400 Epoch=265.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.818 | L2-Norm(final)=8.081 | 4342.6 samples/s | 67.9 steps/s
[Step=69450 Epoch=266.1] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.809 | L2-Norm(final)=8.082 | 4112.7 samples/s | 64.3 steps/s
[Step=69500 Epoch=266.3] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.799 | L2-Norm(final)=8.084 | 4225.5 samples/s | 66.0 steps/s
[Step=69550 Epoch=266.5] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.790 | L2-Norm(final)=8.085 | 2624.9 samples/s | 41.0 steps/s
[Step=69600 Epoch=266.7] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.780 | L2-Norm(final)=8.087 | 4175.0 samples/s | 65.2 steps/s
[Step=69650 Epoch=266.9] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=8.088 | 4225.9 samples/s | 66.0 steps/s
[Step=69700 Epoch=267.1] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.760 | L2-Norm(final)=8.090 | 4189.9 samples/s | 65.5 steps/s
[Step=69750 Epoch=267.3] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.750 | L2-Norm(final)=8.091 | 4179.4 samples/s | 65.3 steps/s
[Step=69800 Epoch=267.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.739 | L2-Norm(final)=8.093 | 6305.5 samples/s | 98.5 steps/s
[Step=69850 Epoch=267.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.729 | L2-Norm(final)=8.094 | 2193.5 samples/s | 34.3 steps/s
[Step=69900 Epoch=267.8] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.719 | L2-Norm(final)=8.096 | 4181.2 samples/s | 65.3 steps/s
[Step=69950 Epoch=268.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.708 | L2-Norm(final)=8.098 | 4233.3 samples/s | 66.1 steps/s
[Step=70000 Epoch=268.2] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.697 | L2-Norm(final)=8.099 | 4254.3 samples/s | 66.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step70000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=261.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.900 | L2-Norm(final)=8.716 | 6052.7 samples/s | 94.6 steps/s
[Step=68050 Epoch=262.0] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.899 | L2-Norm(final)=8.730 | 4129.8 samples/s | 64.5 steps/s
[Step=68100 Epoch=262.1] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.901 | L2-Norm(final)=8.741 | 4796.9 samples/s | 75.0 steps/s
[Step=68150 Epoch=262.3] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.904 | L2-Norm(final)=8.752 | 4818.9 samples/s | 75.3 steps/s
[Step=68200 Epoch=262.5] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.906 | L2-Norm(final)=8.763 | 4581.9 samples/s | 71.6 steps/s
[Step=68250 Epoch=262.7] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.908 | L2-Norm(final)=8.772 | 6832.6 samples/s | 106.8 steps/s
[Step=68300 Epoch=262.9] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.910 | L2-Norm(final)=8.781 | 2451.1 samples/s | 38.3 steps/s
[Step=68350 Epoch=263.1] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.912 | L2-Norm(final)=8.789 | 4549.8 samples/s | 71.1 steps/s
[Step=68400 Epoch=263.3] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.913 | L2-Norm(final)=8.797 | 4833.5 samples/s | 75.5 steps/s
[Step=68450 Epoch=263.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.914 | L2-Norm(final)=8.805 | 4703.6 samples/s | 73.5 steps/s
[Step=68500 Epoch=263.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.915 | L2-Norm(final)=8.813 | 5649.6 samples/s | 88.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=263.7] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.922 | L2-Norm(final)=8.886 | 5870.9 samples/s | 91.7 steps/s
[Step=68550 Epoch=263.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.909 | L2-Norm(final)=8.891 | 3952.8 samples/s | 61.8 steps/s
[Step=68600 Epoch=264.1] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.890 | L2-Norm(final)=8.896 | 4215.8 samples/s | 65.9 steps/s
[Step=68650 Epoch=264.3] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.870 | L2-Norm(final)=8.901 | 4261.5 samples/s | 66.6 steps/s
[Step=68700 Epoch=264.5] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.850 | L2-Norm(final)=8.905 | 4269.9 samples/s | 66.7 steps/s
[Step=68750 Epoch=264.6] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.829 | L2-Norm(final)=8.909 | 5758.4 samples/s | 90.0 steps/s
[Step=68800 Epoch=264.8] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.807 | L2-Norm(final)=8.912 | 2279.8 samples/s | 35.6 steps/s
[Step=68850 Epoch=265.0] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.785 | L2-Norm(final)=8.916 | 4158.8 samples/s | 65.0 steps/s
[Step=68900 Epoch=265.2] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.763 | L2-Norm(final)=8.918 | 4241.2 samples/s | 66.3 steps/s
[Step=68950 Epoch=265.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.741 | L2-Norm(final)=8.921 | 4254.3 samples/s | 66.5 steps/s
[Step=69000 Epoch=265.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.718 | L2-Norm(final)=8.924 | 4985.1 samples/s | 77.9 steps/s
[Step=69050 Epoch=265.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.695 | L2-Norm(final)=8.927 | 2409.0 samples/s | 37.6 steps/s
[Step=69100 Epoch=266.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.672 | L2-Norm(final)=8.930 | 4274.8 samples/s | 66.8 steps/s
[Step=69150 Epoch=266.2] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.649 | L2-Norm(final)=8.933 | 4250.1 samples/s | 66.4 steps/s
[Step=69200 Epoch=266.4] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.626 | L2-Norm(final)=8.936 | 4214.6 samples/s | 65.9 steps/s
[Step=69250 Epoch=266.6] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.603 | L2-Norm(final)=8.939 | 4354.2 samples/s | 68.0 steps/s
[Step=69300 Epoch=266.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.580 | L2-Norm(final)=8.942 | 2587.4 samples/s | 40.4 steps/s
[Step=69350 Epoch=267.0] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.556 | L2-Norm(final)=8.945 | 4231.1 samples/s | 66.1 steps/s
[Step=69400 Epoch=267.1] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.948 | 4251.8 samples/s | 66.4 steps/s
[Step=69450 Epoch=267.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.510 | L2-Norm(final)=8.951 | 4173.6 samples/s | 65.2 steps/s
[Step=69500 Epoch=267.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.486 | L2-Norm(final)=8.955 | 4231.2 samples/s | 66.1 steps/s
[Step=69550 Epoch=267.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.463 | L2-Norm(final)=8.958 | 2620.2 samples/s | 40.9 steps/s
[Step=69600 Epoch=267.9] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.440 | L2-Norm(final)=8.962 | 4278.6 samples/s | 66.9 steps/s
[Step=69650 Epoch=268.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.418 | L2-Norm(final)=8.967 | 4219.0 samples/s | 65.9 steps/s
[Step=69700 Epoch=268.3] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.395 | L2-Norm(final)=8.971 | 4245.8 samples/s | 66.3 steps/s
[Step=69750 Epoch=268.5] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.372 | L2-Norm(final)=8.975 | 4281.3 samples/s | 66.9 steps/s
[Step=69800 Epoch=268.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=8.979 | 6896.6 samples/s | 107.8 steps/s
[Step=69850 Epoch=268.9] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.327 | L2-Norm(final)=8.983 | 2111.8 samples/s | 33.0 steps/s
[Step=69900 Epoch=269.1] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=8.987 | 4220.6 samples/s | 65.9 steps/s
[Step=69950 Epoch=269.3] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.282 | L2-Norm(final)=8.991 | 4234.5 samples/s | 66.2 steps/s
[Step=70000 Epoch=269.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.259 | L2-Norm(final)=8.996 | 4229.0 samples/s | 66.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07365 | acc=0.9684 | tpr=0.9750 | fpr=0.0458 | 4978.0 samples/s | 19.4 steps/s
Avg test loss: 0.07467, Avg test acc: 0.96702, Avg tpr: 0.97360, Avg fpr: 0.04743, total FA: 370

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07172 | acc=0.9664 | tpr=0.9714 | fpr=0.0444 | 4904.8 samples/s | 19.2 steps/s
Avg test loss: 0.07424, Avg test acc: 0.96626, Avg tpr: 0.97127, Avg fpr: 0.04474, total FA: 349

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.24089 | acc=0.3058 | tpr=0.0092 | fpr=0.0503 | 4925.5 samples/s | 19.2 steps/s
Avg test loss: 5.24065, Avg test acc: 0.30163, Avg tpr: 0.00956, Avg fpr: 0.05602, total FA: 437

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.30743 | acc=0.3097 | tpr=0.0178 | fpr=0.0565 | 4866.6 samples/s | 19.0 steps/s
Avg test loss: 5.29567, Avg test acc: 0.30591, Avg tpr: 0.01871, Avg fpr: 0.06243, total FA: 487

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.25956 | acc=0.1500 | tpr=0.5088 | fpr=0.8564 | 4922.8 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.23427 | acc=0.1482 | tpr=0.4670 | fpr=0.8577 | 7143.8 samples/s | 27.9 steps/s
[Step= 150] | Loss=6.23445 | acc=0.1485 | tpr=0.4683 | fpr=0.8573 | 8061.9 samples/s | 31.5 steps/s
[Step= 200] | Loss=6.23268 | acc=0.1488 | tpr=0.4689 | fpr=0.8570 | 7672.5 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.21959 | acc=0.1497 | tpr=0.4812 | fpr=0.8564 | 7898.7 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.21197 | acc=0.1496 | tpr=0.4807 | fpr=0.8564 | 7976.4 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.21637 | acc=0.1493 | tpr=0.4684 | fpr=0.8565 | 7596.8 samples/s | 29.7 steps/s
[Step= 400] | Loss=6.21566 | acc=0.1497 | tpr=0.4672 | fpr=0.8560 | 7986.8 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.21847 | acc=0.1493 | tpr=0.4649 | fpr=0.8564 | 7834.4 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.22195 | acc=0.1496 | tpr=0.4652 | fpr=0.8561 | 7432.1 samples/s | 29.0 steps/s
[Step= 550] | Loss=6.22450 | acc=0.1497 | tpr=0.4652 | fpr=0.8561 | 13600.9 samples/s | 53.1 steps/s
Avg test loss: 6.22625, Avg test acc: 0.14957, Avg tpr: 0.46672, Avg fpr: 0.85620, total FA: 118881

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.29800 | acc=0.1458 | tpr=0.5442 | fpr=0.8614 | 4839.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.29321 | acc=0.1452 | tpr=0.5032 | fpr=0.8615 | 7216.2 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.28917 | acc=0.1450 | tpr=0.5043 | fpr=0.8616 | 7680.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.28605 | acc=0.1449 | tpr=0.4929 | fpr=0.8614 | 7862.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.27406 | acc=0.1454 | tpr=0.4926 | fpr=0.8609 | 7577.3 samples/s | 29.6 steps/s
[Step= 300] | Loss=6.26814 | acc=0.1458 | tpr=0.4909 | fpr=0.8605 | 7848.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.27353 | acc=0.1455 | tpr=0.4840 | fpr=0.8607 | 7823.1 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.27108 | acc=0.1454 | tpr=0.4787 | fpr=0.8607 | 8066.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.27489 | acc=0.1448 | tpr=0.4742 | fpr=0.8611 | 7742.9 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.27743 | acc=0.1453 | tpr=0.4775 | fpr=0.8607 | 7858.6 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.28208 | acc=0.1453 | tpr=0.4759 | fpr=0.8607 | 13727.8 samples/s | 53.6 steps/s
Avg test loss: 6.28431, Avg test acc: 0.14511, Avg tpr: 0.47662, Avg fpr: 0.86091, total FA: 119536

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12341 | acc=0.9779 | tpr=0.9558 | fpr=0.0217 | 4864.1 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.12450 | acc=0.9786 | tpr=0.9638 | fpr=0.0212 | 6768.8 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.13008 | acc=0.9775 | tpr=0.9611 | fpr=0.0222 | 8890.3 samples/s | 34.7 steps/s
[Step= 200] | Loss=0.13324 | acc=0.9774 | tpr=0.9617 | fpr=0.0223 | 7508.8 samples/s | 29.3 steps/s
[Step= 250] | Loss=0.13071 | acc=0.9777 | tpr=0.9607 | fpr=0.0220 | 7445.2 samples/s | 29.1 steps/s
[Step= 300] | Loss=0.13242 | acc=0.9774 | tpr=0.9578 | fpr=0.0223 | 7734.1 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.13259 | acc=0.9774 | tpr=0.9587 | fpr=0.0223 | 7741.4 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.13395 | acc=0.9774 | tpr=0.9579 | fpr=0.0223 | 8133.6 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.13645 | acc=0.9770 | tpr=0.9572 | fpr=0.0226 | 7562.4 samples/s | 29.5 steps/s
[Step= 500] | Loss=0.13566 | acc=0.9771 | tpr=0.9581 | fpr=0.0226 | 7390.7 samples/s | 28.9 steps/s
[Step= 550] | Loss=0.13431 | acc=0.9773 | tpr=0.9586 | fpr=0.0223 | 15121.6 samples/s | 59.1 steps/s
Avg test loss: 0.13412, Avg test acc: 0.97733, Avg tpr: 0.95840, Avg fpr: 0.02233, total FA: 3100

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12857 | acc=0.9756 | tpr=0.9558 | fpr=0.0240 | 4773.4 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.13071 | acc=0.9756 | tpr=0.9659 | fpr=0.0242 | 7528.4 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.13672 | acc=0.9746 | tpr=0.9683 | fpr=0.0252 | 7691.3 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13959 | acc=0.9746 | tpr=0.9694 | fpr=0.0253 | 7833.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.13745 | acc=0.9749 | tpr=0.9694 | fpr=0.0250 | 7572.1 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.13940 | acc=0.9747 | tpr=0.9687 | fpr=0.0252 | 7909.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.13989 | acc=0.9745 | tpr=0.9699 | fpr=0.0254 | 7719.0 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.14106 | acc=0.9745 | tpr=0.9694 | fpr=0.0254 | 8287.6 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.14351 | acc=0.9741 | tpr=0.9674 | fpr=0.0258 | 7572.2 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.14275 | acc=0.9743 | tpr=0.9674 | fpr=0.0256 | 8009.9 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.14137 | acc=0.9746 | tpr=0.9674 | fpr=0.0253 | 13153.0 samples/s | 51.4 steps/s
Avg test loss: 0.14125, Avg test acc: 0.97456, Avg tpr: 0.96712, Avg fpr: 0.02530, total FA: 3513

server round 35/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=136.5] | Loss=0.00211 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.050 | L2-Norm(final)=13.047 | 6340.0 samples/s | 99.1 steps/s
[Step=70050 Epoch=136.6] | Loss=0.00964 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.054 | L2-Norm(final)=13.052 | 4690.6 samples/s | 73.3 steps/s
[Step=70100 Epoch=136.7] | Loss=0.00829 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.057 | L2-Norm(final)=13.060 | 4970.3 samples/s | 77.7 steps/s
[Step=70150 Epoch=136.8] | Loss=0.00844 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.059 | L2-Norm(final)=13.068 | 4952.8 samples/s | 77.4 steps/s
[Step=70200 Epoch=136.9] | Loss=0.00848 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.061 | L2-Norm(final)=13.076 | 5094.6 samples/s | 79.6 steps/s
[Step=70250 Epoch=137.0] | Loss=0.00808 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.063 | L2-Norm(final)=13.082 | 4894.4 samples/s | 76.5 steps/s
[Step=70300 Epoch=137.1] | Loss=0.00819 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=13.089 | 4985.9 samples/s | 77.9 steps/s
[Step=70350 Epoch=137.2] | Loss=0.00789 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.068 | L2-Norm(final)=13.095 | 5151.8 samples/s | 80.5 steps/s
[Step=70400 Epoch=137.3] | Loss=0.00778 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=13.101 | 5031.1 samples/s | 78.6 steps/s
[Step=70450 Epoch=137.4] | Loss=0.00775 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=13.108 | 4809.8 samples/s | 75.2 steps/s
[Step=70500 Epoch=137.5] | Loss=0.00783 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.073 | L2-Norm(final)=13.114 | 6738.6 samples/s | 105.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=137.5] | Loss=0.00490 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=13.174 | 6797.6 samples/s | 106.2 steps/s
[Step=70550 Epoch=137.6] | Loss=0.00919 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=13.180 | 3927.5 samples/s | 61.4 steps/s
[Step=70600 Epoch=137.7] | Loss=0.00879 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.100 | L2-Norm(final)=13.185 | 4415.6 samples/s | 69.0 steps/s
[Step=70650 Epoch=137.8] | Loss=0.00837 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=13.191 | 4411.5 samples/s | 68.9 steps/s
[Step=70700 Epoch=137.9] | Loss=0.00853 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.108 | L2-Norm(final)=13.196 | 4449.1 samples/s | 69.5 steps/s
[Step=70750 Epoch=138.0] | Loss=0.00847 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.111 | L2-Norm(final)=13.201 | 4465.1 samples/s | 69.8 steps/s
[Step=70800 Epoch=138.1] | Loss=0.00885 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=13.206 | 4418.3 samples/s | 69.0 steps/s
[Step=70850 Epoch=138.2] | Loss=0.00886 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=13.210 | 4397.5 samples/s | 68.7 steps/s
[Step=70900 Epoch=138.3] | Loss=0.00886 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.120 | L2-Norm(final)=13.215 | 4439.1 samples/s | 69.4 steps/s
[Step=70950 Epoch=138.4] | Loss=0.00877 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=13.220 | 4432.7 samples/s | 69.3 steps/s
[Step=71000 Epoch=138.5] | Loss=0.00864 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.125 | L2-Norm(final)=13.225 | 5706.5 samples/s | 89.2 steps/s
[Step=71050 Epoch=138.6] | Loss=0.00841 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=13.229 | 2384.3 samples/s | 37.3 steps/s
[Step=71100 Epoch=138.7] | Loss=0.00821 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=13.234 | 4389.4 samples/s | 68.6 steps/s
[Step=71150 Epoch=138.8] | Loss=0.00814 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.132 | L2-Norm(final)=13.238 | 4434.3 samples/s | 69.3 steps/s
[Step=71200 Epoch=138.9] | Loss=0.00809 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=13.243 | 4437.6 samples/s | 69.3 steps/s
[Step=71250 Epoch=139.0] | Loss=0.00794 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=13.247 | 4390.3 samples/s | 68.6 steps/s
[Step=71300 Epoch=139.1] | Loss=0.00785 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.137 | L2-Norm(final)=13.251 | 4479.6 samples/s | 70.0 steps/s
[Step=71350 Epoch=139.2] | Loss=0.00783 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.139 | L2-Norm(final)=13.255 | 4406.3 samples/s | 68.8 steps/s
[Step=71400 Epoch=139.3] | Loss=0.00777 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=13.258 | 4397.3 samples/s | 68.7 steps/s
[Step=71450 Epoch=139.4] | Loss=0.00761 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=13.262 | 4442.5 samples/s | 69.4 steps/s
[Step=71500 Epoch=139.5] | Loss=0.00757 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=13.266 | 4782.0 samples/s | 74.7 steps/s
[Step=71550 Epoch=139.6] | Loss=0.00742 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.144 | L2-Norm(final)=13.270 | 2601.5 samples/s | 40.6 steps/s
[Step=71600 Epoch=139.6] | Loss=0.00725 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=13.274 | 4411.8 samples/s | 68.9 steps/s
[Step=71650 Epoch=139.7] | Loss=0.00722 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.146 | L2-Norm(final)=13.277 | 4420.5 samples/s | 69.1 steps/s
[Step=71700 Epoch=139.8] | Loss=0.00710 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.147 | L2-Norm(final)=13.281 | 4460.3 samples/s | 69.7 steps/s
[Step=71750 Epoch=139.9] | Loss=0.00703 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.147 | L2-Norm(final)=13.285 | 4376.6 samples/s | 68.4 steps/s
[Step=71800 Epoch=140.0] | Loss=0.00702 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.148 | L2-Norm(final)=13.288 | 4471.1 samples/s | 69.9 steps/s
[Step=71850 Epoch=140.1] | Loss=0.00697 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.149 | L2-Norm(final)=13.292 | 4389.9 samples/s | 68.6 steps/s
[Step=71900 Epoch=140.2] | Loss=0.00694 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.149 | L2-Norm(final)=13.295 | 4435.7 samples/s | 69.3 steps/s
[Step=71950 Epoch=140.3] | Loss=0.00689 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=13.298 | 4475.0 samples/s | 69.9 steps/s
[Step=72000 Epoch=140.4] | Loss=0.00684 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=13.302 | 4500.9 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step72000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=136.9] | Loss=0.01522 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.175 | L2-Norm(final)=13.148 | 7273.4 samples/s | 113.6 steps/s
[Step=70050 Epoch=136.9] | Loss=0.00934 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.177 | L2-Norm(final)=13.152 | 4275.0 samples/s | 66.8 steps/s
[Step=70100 Epoch=137.0] | Loss=0.00801 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.179 | L2-Norm(final)=13.158 | 4942.6 samples/s | 77.2 steps/s
[Step=70150 Epoch=137.1] | Loss=0.00828 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.182 | L2-Norm(final)=13.165 | 5066.6 samples/s | 79.2 steps/s
[Step=70200 Epoch=137.2] | Loss=0.00815 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.185 | L2-Norm(final)=13.171 | 4883.7 samples/s | 76.3 steps/s
[Step=70250 Epoch=137.3] | Loss=0.00852 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.188 | L2-Norm(final)=13.177 | 4977.5 samples/s | 77.8 steps/s
[Step=70300 Epoch=137.4] | Loss=0.00869 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.191 | L2-Norm(final)=13.183 | 4954.9 samples/s | 77.4 steps/s
[Step=70350 Epoch=137.5] | Loss=0.00852 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.193 | L2-Norm(final)=13.190 | 5047.3 samples/s | 78.9 steps/s
[Step=70400 Epoch=137.6] | Loss=0.00828 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=13.196 | 5070.3 samples/s | 79.2 steps/s
[Step=70450 Epoch=137.7] | Loss=0.00826 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.198 | L2-Norm(final)=13.203 | 4884.0 samples/s | 76.3 steps/s
[Step=70500 Epoch=137.8] | Loss=0.00816 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.201 | L2-Norm(final)=13.209 | 6819.7 samples/s | 106.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=137.8] | Loss=0.00446 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=13.270 | 6269.0 samples/s | 98.0 steps/s
[Step=70550 Epoch=137.9] | Loss=0.00808 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.227 | L2-Norm(final)=13.275 | 4109.9 samples/s | 64.2 steps/s
[Step=70600 Epoch=138.0] | Loss=0.00822 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.231 | L2-Norm(final)=13.280 | 4537.8 samples/s | 70.9 steps/s
[Step=70650 Epoch=138.1] | Loss=0.00785 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.235 | L2-Norm(final)=13.285 | 4348.1 samples/s | 67.9 steps/s
[Step=70700 Epoch=138.2] | Loss=0.00832 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.239 | L2-Norm(final)=13.290 | 4403.3 samples/s | 68.8 steps/s
[Step=70750 Epoch=138.3] | Loss=0.00854 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.243 | L2-Norm(final)=13.295 | 4473.8 samples/s | 69.9 steps/s
[Step=70800 Epoch=138.4] | Loss=0.00869 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.246 | L2-Norm(final)=13.299 | 4488.2 samples/s | 70.1 steps/s
[Step=70850 Epoch=138.5] | Loss=0.00838 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.249 | L2-Norm(final)=13.304 | 4396.1 samples/s | 68.7 steps/s
[Step=70900 Epoch=138.6] | Loss=0.00843 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.252 | L2-Norm(final)=13.309 | 4533.6 samples/s | 70.8 steps/s
[Step=70950 Epoch=138.7] | Loss=0.00830 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.255 | L2-Norm(final)=13.314 | 4506.7 samples/s | 70.4 steps/s
[Step=71000 Epoch=138.8] | Loss=0.00820 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.258 | L2-Norm(final)=13.319 | 5809.9 samples/s | 90.8 steps/s
[Step=71050 Epoch=138.9] | Loss=0.00795 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.260 | L2-Norm(final)=13.324 | 2404.9 samples/s | 37.6 steps/s
[Step=71100 Epoch=139.0] | Loss=0.00773 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.262 | L2-Norm(final)=13.329 | 4433.7 samples/s | 69.3 steps/s
[Step=71150 Epoch=139.1] | Loss=0.00763 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.264 | L2-Norm(final)=13.333 | 4477.7 samples/s | 70.0 steps/s
[Step=71200 Epoch=139.2] | Loss=0.00750 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.266 | L2-Norm(final)=13.337 | 4556.4 samples/s | 71.2 steps/s
[Step=71250 Epoch=139.3] | Loss=0.00743 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.267 | L2-Norm(final)=13.342 | 4339.4 samples/s | 67.8 steps/s
[Step=71300 Epoch=139.4] | Loss=0.00739 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.269 | L2-Norm(final)=13.346 | 4241.7 samples/s | 66.3 steps/s
[Step=71350 Epoch=139.5] | Loss=0.00731 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.270 | L2-Norm(final)=13.350 | 4282.7 samples/s | 66.9 steps/s
[Step=71400 Epoch=139.6] | Loss=0.00725 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.272 | L2-Norm(final)=13.354 | 4325.6 samples/s | 67.6 steps/s
[Step=71450 Epoch=139.7] | Loss=0.00714 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.273 | L2-Norm(final)=13.358 | 4146.4 samples/s | 64.8 steps/s
[Step=71500 Epoch=139.8] | Loss=0.00711 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.274 | L2-Norm(final)=13.361 | 4701.1 samples/s | 73.5 steps/s
[Step=71550 Epoch=139.9] | Loss=0.00703 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=13.365 | 2457.3 samples/s | 38.4 steps/s
[Step=71600 Epoch=140.0] | Loss=0.00694 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.277 | L2-Norm(final)=13.369 | 4178.0 samples/s | 65.3 steps/s
[Step=71650 Epoch=140.1] | Loss=0.00693 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=13.373 | 4266.4 samples/s | 66.7 steps/s
[Step=71700 Epoch=140.2] | Loss=0.00696 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.278 | L2-Norm(final)=13.376 | 4258.2 samples/s | 66.5 steps/s
[Step=71750 Epoch=140.3] | Loss=0.00688 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.279 | L2-Norm(final)=13.380 | 4238.4 samples/s | 66.2 steps/s
[Step=71800 Epoch=140.4] | Loss=0.00680 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.280 | L2-Norm(final)=13.383 | 4477.9 samples/s | 70.0 steps/s
[Step=71850 Epoch=140.5] | Loss=0.00675 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.281 | L2-Norm(final)=13.387 | 4404.2 samples/s | 68.8 steps/s
[Step=71900 Epoch=140.6] | Loss=0.00670 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.281 | L2-Norm(final)=13.390 | 4420.5 samples/s | 69.1 steps/s
[Step=71950 Epoch=140.7] | Loss=0.00669 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.282 | L2-Norm(final)=13.393 | 4447.5 samples/s | 69.5 steps/s
[Step=72000 Epoch=140.8] | Loss=0.00669 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.283 | L2-Norm(final)=13.397 | 4467.8 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step72000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=268.2] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.509 | L2-Norm(final)=8.149 | 5874.3 samples/s | 91.8 steps/s
[Step=70050 Epoch=268.4] | Loss=0.00010 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.512 | L2-Norm(final)=8.159 | 4061.1 samples/s | 63.5 steps/s
[Step=70100 Epoch=268.6] | Loss=0.00006 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.519 | L2-Norm(final)=8.168 | 4780.6 samples/s | 74.7 steps/s
[Step=70150 Epoch=268.8] | Loss=0.00005 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.522 | L2-Norm(final)=8.175 | 4931.0 samples/s | 77.0 steps/s
[Step=70200 Epoch=269.0] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.525 | L2-Norm(final)=8.182 | 4641.1 samples/s | 72.5 steps/s
[Step=70250 Epoch=269.2] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.527 | L2-Norm(final)=8.188 | 6546.8 samples/s | 102.3 steps/s
[Step=70300 Epoch=269.4] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.529 | L2-Norm(final)=8.193 | 2421.9 samples/s | 37.8 steps/s
[Step=70350 Epoch=269.6] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.530 | L2-Norm(final)=8.199 | 4782.5 samples/s | 74.7 steps/s
[Step=70400 Epoch=269.7] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=8.203 | 4594.7 samples/s | 71.8 steps/s
[Step=70450 Epoch=269.9] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.532 | L2-Norm(final)=8.208 | 4726.6 samples/s | 73.9 steps/s
[Step=70500 Epoch=270.1] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=8.213 | 5457.5 samples/s | 85.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=270.1] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.543 | L2-Norm(final)=8.261 | 6372.4 samples/s | 99.6 steps/s
[Step=70550 Epoch=270.3] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=8.264 | 3770.8 samples/s | 58.9 steps/s
[Step=70600 Epoch=270.5] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.523 | L2-Norm(final)=8.268 | 4256.0 samples/s | 66.5 steps/s
[Step=70650 Epoch=270.7] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.512 | L2-Norm(final)=8.271 | 4129.7 samples/s | 64.5 steps/s
[Step=70700 Epoch=270.9] | Loss=0.00014 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.508 | L2-Norm(final)=8.276 | 4278.9 samples/s | 66.9 steps/s
[Step=70750 Epoch=271.1] | Loss=0.00036 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=8.280 | 5624.5 samples/s | 87.9 steps/s
[Step=70800 Epoch=271.3] | Loss=0.00031 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.518 | L2-Norm(final)=8.284 | 2261.6 samples/s | 35.3 steps/s
[Step=70850 Epoch=271.5] | Loss=0.00027 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.523 | L2-Norm(final)=8.286 | 4275.2 samples/s | 66.8 steps/s
[Step=70900 Epoch=271.7] | Loss=0.00024 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.526 | L2-Norm(final)=8.289 | 4191.7 samples/s | 65.5 steps/s
[Step=70950 Epoch=271.9] | Loss=0.00021 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.528 | L2-Norm(final)=8.290 | 4229.2 samples/s | 66.1 steps/s
[Step=71000 Epoch=272.0] | Loss=0.00019 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.529 | L2-Norm(final)=8.292 | 4779.1 samples/s | 74.7 steps/s
[Step=71050 Epoch=272.2] | Loss=0.00018 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=8.293 | 2420.8 samples/s | 37.8 steps/s
[Step=71100 Epoch=272.4] | Loss=0.00016 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.532 | L2-Norm(final)=8.295 | 4233.3 samples/s | 66.1 steps/s
[Step=71150 Epoch=272.6] | Loss=0.00015 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.532 | L2-Norm(final)=8.296 | 4224.4 samples/s | 66.0 steps/s
[Step=71200 Epoch=272.8] | Loss=0.00014 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.297 | 4241.0 samples/s | 66.3 steps/s
[Step=71250 Epoch=273.0] | Loss=0.00013 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.297 | 4244.2 samples/s | 66.3 steps/s
[Step=71300 Epoch=273.2] | Loss=0.00013 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.298 | 2611.0 samples/s | 40.8 steps/s
[Step=71350 Epoch=273.4] | Loss=0.00012 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.299 | 4140.2 samples/s | 64.7 steps/s
[Step=71400 Epoch=273.6] | Loss=0.00011 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.300 | 4207.0 samples/s | 65.7 steps/s
[Step=71450 Epoch=273.8] | Loss=0.00011 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.300 | 4225.7 samples/s | 66.0 steps/s
[Step=71500 Epoch=274.0] | Loss=0.00010 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.301 | 4311.1 samples/s | 67.4 steps/s
[Step=71550 Epoch=274.2] | Loss=0.00010 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.533 | L2-Norm(final)=8.302 | 2624.7 samples/s | 41.0 steps/s
[Step=71600 Epoch=274.3] | Loss=0.00009 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.532 | L2-Norm(final)=8.302 | 4219.1 samples/s | 65.9 steps/s
[Step=71650 Epoch=274.5] | Loss=0.00009 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.532 | L2-Norm(final)=8.303 | 4266.0 samples/s | 66.7 steps/s
[Step=71700 Epoch=274.7] | Loss=0.00009 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=8.303 | 4162.2 samples/s | 65.0 steps/s
[Step=71750 Epoch=274.9] | Loss=0.00008 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=8.304 | 4191.0 samples/s | 65.5 steps/s
[Step=71800 Epoch=275.1] | Loss=0.00008 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.530 | L2-Norm(final)=8.304 | 6249.4 samples/s | 97.6 steps/s
[Step=71850 Epoch=275.3] | Loss=0.00008 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.530 | L2-Norm(final)=8.305 | 2195.6 samples/s | 34.3 steps/s
[Step=71900 Epoch=275.5] | Loss=0.00008 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.529 | L2-Norm(final)=8.305 | 4260.0 samples/s | 66.6 steps/s
[Step=71950 Epoch=275.7] | Loss=0.00007 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.529 | L2-Norm(final)=8.306 | 4249.0 samples/s | 66.4 steps/s
[Step=72000 Epoch=275.9] | Loss=0.00007 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.528 | L2-Norm(final)=8.306 | 4234.9 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step72000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=269.5] | Loss=0.00006 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.449 | L2-Norm(final)=9.125 | 6650.4 samples/s | 103.9 steps/s
[Step=70050 Epoch=269.6] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.449 | L2-Norm(final)=9.145 | 3835.2 samples/s | 59.9 steps/s
[Step=70100 Epoch=269.8] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.456 | L2-Norm(final)=9.166 | 4850.4 samples/s | 75.8 steps/s
[Step=70150 Epoch=270.0] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.461 | L2-Norm(final)=9.183 | 4666.6 samples/s | 72.9 steps/s
[Step=70200 Epoch=270.2] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.466 | L2-Norm(final)=9.199 | 4749.4 samples/s | 74.2 steps/s
[Step=70250 Epoch=270.4] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.468 | L2-Norm(final)=9.211 | 6792.4 samples/s | 106.1 steps/s
[Step=70300 Epoch=270.6] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.470 | L2-Norm(final)=9.222 | 2463.0 samples/s | 38.5 steps/s
[Step=70350 Epoch=270.8] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=9.233 | 4521.7 samples/s | 70.7 steps/s
[Step=70400 Epoch=271.0] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.473 | L2-Norm(final)=9.242 | 4825.6 samples/s | 75.4 steps/s
[Step=70450 Epoch=271.2] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.474 | L2-Norm(final)=9.251 | 4645.0 samples/s | 72.6 steps/s
[Step=70500 Epoch=271.4] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.475 | L2-Norm(final)=9.260 | 5538.0 samples/s | 86.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=271.4] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.483 | L2-Norm(final)=9.349 | 6033.3 samples/s | 94.3 steps/s
[Step=70550 Epoch=271.6] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.458 | L2-Norm(final)=9.355 | 3850.2 samples/s | 60.2 steps/s
[Step=70600 Epoch=271.8] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.422 | L2-Norm(final)=9.361 | 4326.8 samples/s | 67.6 steps/s
[Step=70650 Epoch=272.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=9.366 | 4254.0 samples/s | 66.5 steps/s
[Step=70700 Epoch=272.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=9.371 | 4158.7 samples/s | 65.0 steps/s
[Step=70750 Epoch=272.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=9.376 | 5805.7 samples/s | 90.7 steps/s
[Step=70800 Epoch=272.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.281 | L2-Norm(final)=9.381 | 2235.8 samples/s | 34.9 steps/s
[Step=70850 Epoch=272.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.247 | L2-Norm(final)=9.386 | 4194.4 samples/s | 65.5 steps/s
[Step=70900 Epoch=272.9] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.213 | L2-Norm(final)=9.390 | 4240.9 samples/s | 66.3 steps/s
[Step=70950 Epoch=273.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.179 | L2-Norm(final)=9.394 | 4267.1 samples/s | 66.7 steps/s
[Step=71000 Epoch=273.3] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.145 | L2-Norm(final)=9.399 | 4952.9 samples/s | 77.4 steps/s
[Step=71050 Epoch=273.5] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.114 | L2-Norm(final)=9.404 | 2419.5 samples/s | 37.8 steps/s
[Step=71100 Epoch=273.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=9.410 | 4162.7 samples/s | 65.0 steps/s
[Step=71150 Epoch=273.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.056 | L2-Norm(final)=9.415 | 4318.4 samples/s | 67.5 steps/s
[Step=71200 Epoch=274.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=9.420 | 4094.8 samples/s | 64.0 steps/s
[Step=71250 Epoch=274.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.998 | L2-Norm(final)=9.424 | 4338.5 samples/s | 67.8 steps/s
[Step=71300 Epoch=274.5] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.969 | L2-Norm(final)=9.429 | 2618.8 samples/s | 40.9 steps/s
[Step=71350 Epoch=274.7] | Loss=0.00010 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.945 | L2-Norm(final)=9.434 | 4159.4 samples/s | 65.0 steps/s
[Step=71400 Epoch=274.8] | Loss=0.00011 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.438 | 4212.9 samples/s | 65.8 steps/s
[Step=71450 Epoch=275.0] | Loss=0.00010 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.907 | L2-Norm(final)=9.442 | 4215.8 samples/s | 65.9 steps/s
[Step=71500 Epoch=275.2] | Loss=0.00010 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.891 | L2-Norm(final)=9.446 | 4280.0 samples/s | 66.9 steps/s
[Step=71550 Epoch=275.4] | Loss=0.00010 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=9.450 | 2583.9 samples/s | 40.4 steps/s
[Step=71600 Epoch=275.6] | Loss=0.00009 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.864 | L2-Norm(final)=9.453 | 4271.0 samples/s | 66.7 steps/s
[Step=71650 Epoch=275.8] | Loss=0.00009 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.852 | L2-Norm(final)=9.456 | 4239.2 samples/s | 66.2 steps/s
[Step=71700 Epoch=276.0] | Loss=0.00009 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=9.459 | 4273.4 samples/s | 66.8 steps/s
[Step=71750 Epoch=276.2] | Loss=0.00008 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.831 | L2-Norm(final)=9.462 | 4223.3 samples/s | 66.0 steps/s
[Step=71800 Epoch=276.4] | Loss=0.00008 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.821 | L2-Norm(final)=9.464 | 6977.9 samples/s | 109.0 steps/s
[Step=71850 Epoch=276.6] | Loss=0.00008 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.813 | L2-Norm(final)=9.466 | 2120.2 samples/s | 33.1 steps/s
[Step=71900 Epoch=276.8] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.804 | L2-Norm(final)=9.469 | 4162.3 samples/s | 65.0 steps/s
[Step=71950 Epoch=277.0] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=9.471 | 4221.1 samples/s | 66.0 steps/s
[Step=72000 Epoch=277.2] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.790 | L2-Norm(final)=9.473 | 4285.6 samples/s | 67.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06985 | acc=0.9672 | tpr=0.9762 | fpr=0.0523 | 4952.2 samples/s | 19.3 steps/s
Avg test loss: 0.07013, Avg test acc: 0.96694, Avg tpr: 0.97581, Avg fpr: 0.05256, total FA: 410

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06719 | acc=0.9676 | tpr=0.9751 | fpr=0.0488 | 4965.5 samples/s | 19.4 steps/s
Avg test loss: 0.06892, Avg test acc: 0.96670, Avg tpr: 0.97500, Avg fpr: 0.05153, total FA: 402

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.04462 | acc=0.3066 | tpr=0.0048 | fpr=0.0379 | 4854.2 samples/s | 19.0 steps/s
Avg test loss: 5.04834, Avg test acc: 0.30243, Avg tpr: 0.00530, Avg fpr: 0.04410, total FA: 344

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.04180 | acc=0.3095 | tpr=0.0120 | fpr=0.0446 | 4980.2 samples/s | 19.5 steps/s
Avg test loss: 5.03433, Avg test acc: 0.30627, Avg tpr: 0.01352, Avg fpr: 0.04987, total FA: 389

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.57490 | acc=0.1469 | tpr=0.5885 | fpr=0.8611 | 4855.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.54902 | acc=0.1477 | tpr=0.5416 | fpr=0.8597 | 7874.2 samples/s | 30.8 steps/s
[Step= 150] | Loss=5.54915 | acc=0.1476 | tpr=0.5461 | fpr=0.8598 | 7225.0 samples/s | 28.2 steps/s
[Step= 200] | Loss=5.54723 | acc=0.1485 | tpr=0.5454 | fpr=0.8587 | 7886.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.53719 | acc=0.1488 | tpr=0.5537 | fpr=0.8586 | 8115.9 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.53164 | acc=0.1487 | tpr=0.5513 | fpr=0.8587 | 7348.5 samples/s | 28.7 steps/s
[Step= 350] | Loss=5.53534 | acc=0.1483 | tpr=0.5385 | fpr=0.8588 | 7988.6 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.53373 | acc=0.1486 | tpr=0.5356 | fpr=0.8584 | 5556.5 samples/s | 21.7 steps/s
[Step= 450] | Loss=5.53688 | acc=0.1481 | tpr=0.5336 | fpr=0.8589 | 8873.3 samples/s | 34.7 steps/s
[Step= 500] | Loss=5.53925 | acc=0.1482 | tpr=0.5339 | fpr=0.8587 | 7517.0 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.54094 | acc=0.1484 | tpr=0.5336 | fpr=0.8586 | 13410.1 samples/s | 52.4 steps/s
Avg test loss: 5.54263, Avg test acc: 0.14830, Avg tpr: 0.53447, Avg fpr: 0.85872, total FA: 119231

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.53348 | acc=0.1248 | tpr=0.5929 | fpr=0.8836 | 5004.7 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.52276 | acc=0.1257 | tpr=0.5608 | fpr=0.8824 | 6911.6 samples/s | 27.0 steps/s
[Step= 150] | Loss=6.52026 | acc=0.1263 | tpr=0.5591 | fpr=0.8816 | 7996.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=6.51648 | acc=0.1263 | tpr=0.5464 | fpr=0.8814 | 7134.5 samples/s | 27.9 steps/s
[Step= 250] | Loss=6.50547 | acc=0.1269 | tpr=0.5502 | fpr=0.8808 | 8170.3 samples/s | 31.9 steps/s
[Step= 300] | Loss=6.50126 | acc=0.1271 | tpr=0.5498 | fpr=0.8806 | 7546.2 samples/s | 29.5 steps/s
[Step= 350] | Loss=6.50645 | acc=0.1266 | tpr=0.5429 | fpr=0.8810 | 7685.8 samples/s | 30.0 steps/s
[Step= 400] | Loss=6.50357 | acc=0.1265 | tpr=0.5394 | fpr=0.8811 | 6510.0 samples/s | 25.4 steps/s
[Step= 450] | Loss=6.50806 | acc=0.1259 | tpr=0.5326 | fpr=0.8815 | 7346.1 samples/s | 28.7 steps/s
[Step= 500] | Loss=6.50981 | acc=0.1263 | tpr=0.5357 | fpr=0.8811 | 7763.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.51356 | acc=0.1262 | tpr=0.5352 | fpr=0.8813 | 14543.2 samples/s | 56.8 steps/s
Avg test loss: 6.51551, Avg test acc: 0.12603, Avg tpr: 0.53605, Avg fpr: 0.88142, total FA: 122384

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11405 | acc=0.9780 | tpr=0.9469 | fpr=0.0215 | 4931.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11602 | acc=0.9781 | tpr=0.9531 | fpr=0.0214 | 7330.1 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.12043 | acc=0.9771 | tpr=0.9539 | fpr=0.0225 | 7782.5 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.12296 | acc=0.9772 | tpr=0.9574 | fpr=0.0224 | 7397.9 samples/s | 28.9 steps/s
[Step= 250] | Loss=0.12083 | acc=0.9774 | tpr=0.9572 | fpr=0.0223 | 8204.4 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.12211 | acc=0.9771 | tpr=0.9578 | fpr=0.0226 | 7442.1 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.12248 | acc=0.9770 | tpr=0.9587 | fpr=0.0226 | 7707.3 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.12379 | acc=0.9770 | tpr=0.9562 | fpr=0.0226 | 6180.6 samples/s | 24.1 steps/s
[Step= 450] | Loss=0.12591 | acc=0.9767 | tpr=0.9567 | fpr=0.0230 | 7930.7 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.12546 | acc=0.9767 | tpr=0.9573 | fpr=0.0230 | 7767.5 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.12430 | acc=0.9769 | tpr=0.9570 | fpr=0.0228 | 13406.9 samples/s | 52.4 steps/s
Avg test loss: 0.12424, Avg test acc: 0.97684, Avg tpr: 0.95681, Avg fpr: 0.02279, total FA: 3165

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09889 | acc=0.9779 | tpr=0.9469 | fpr=0.0216 | 4948.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.10133 | acc=0.9781 | tpr=0.9595 | fpr=0.0216 | 7088.0 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.10627 | acc=0.9773 | tpr=0.9625 | fpr=0.0225 | 7723.4 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10886 | acc=0.9770 | tpr=0.9628 | fpr=0.0227 | 7271.7 samples/s | 28.4 steps/s
[Step= 250] | Loss=0.10715 | acc=0.9773 | tpr=0.9616 | fpr=0.0224 | 7581.9 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.10897 | acc=0.9771 | tpr=0.9615 | fpr=0.0227 | 7543.7 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.10947 | acc=0.9769 | tpr=0.9624 | fpr=0.0228 | 6509.5 samples/s | 25.4 steps/s
[Step= 400] | Loss=0.11049 | acc=0.9769 | tpr=0.9617 | fpr=0.0228 | 7994.7 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.11253 | acc=0.9766 | tpr=0.9596 | fpr=0.0231 | 7677.4 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.11198 | acc=0.9766 | tpr=0.9595 | fpr=0.0230 | 7899.6 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.11086 | acc=0.9769 | tpr=0.9598 | fpr=0.0228 | 13863.6 samples/s | 54.2 steps/s
Avg test loss: 0.11074, Avg test acc: 0.97687, Avg tpr: 0.95959, Avg fpr: 0.02282, total FA: 3168

server round 36/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=140.4] | Loss=0.00801 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.002 | L2-Norm(final)=13.402 | 5703.6 samples/s | 89.1 steps/s
[Step=72050 Epoch=140.5] | Loss=0.01085 | Reg=0.00256 | acc=0.9688 | L2-Norm=16.007 | L2-Norm(final)=13.409 | 4860.1 samples/s | 75.9 steps/s
[Step=72100 Epoch=140.6] | Loss=0.00976 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.011 | L2-Norm(final)=13.418 | 5162.6 samples/s | 80.7 steps/s
[Step=72150 Epoch=140.7] | Loss=0.00927 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.015 | L2-Norm(final)=13.427 | 4901.8 samples/s | 76.6 steps/s
[Step=72200 Epoch=140.8] | Loss=0.00901 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.018 | L2-Norm(final)=13.435 | 5040.9 samples/s | 78.8 steps/s
[Step=72250 Epoch=140.9] | Loss=0.00876 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.021 | L2-Norm(final)=13.444 | 4869.0 samples/s | 76.1 steps/s
[Step=72300 Epoch=141.0] | Loss=0.00870 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=13.452 | 5076.1 samples/s | 79.3 steps/s
[Step=72350 Epoch=141.1] | Loss=0.00888 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.027 | L2-Norm(final)=13.461 | 5025.1 samples/s | 78.5 steps/s
[Step=72400 Epoch=141.2] | Loss=0.00867 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.031 | L2-Norm(final)=13.469 | 5143.1 samples/s | 80.4 steps/s
[Step=72450 Epoch=141.3] | Loss=0.00853 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.034 | L2-Norm(final)=13.477 | 5060.6 samples/s | 79.1 steps/s
[Step=72500 Epoch=141.4] | Loss=0.00858 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.036 | L2-Norm(final)=13.484 | 6562.6 samples/s | 102.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=141.4] | Loss=0.00408 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=13.562 | 6664.3 samples/s | 104.1 steps/s
[Step=72550 Epoch=141.5] | Loss=0.00997 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=13.568 | 3890.6 samples/s | 60.8 steps/s
[Step=72600 Epoch=141.6] | Loss=0.00987 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=13.574 | 4425.4 samples/s | 69.1 steps/s
[Step=72650 Epoch=141.7] | Loss=0.00970 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.081 | L2-Norm(final)=13.580 | 4356.5 samples/s | 68.1 steps/s
[Step=72700 Epoch=141.8] | Loss=0.00922 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.085 | L2-Norm(final)=13.586 | 4491.6 samples/s | 70.2 steps/s
[Step=72750 Epoch=141.9] | Loss=0.00934 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.088 | L2-Norm(final)=13.592 | 4450.5 samples/s | 69.5 steps/s
[Step=72800 Epoch=142.0] | Loss=0.00932 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=13.597 | 4461.6 samples/s | 69.7 steps/s
[Step=72850 Epoch=142.1] | Loss=0.00898 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=13.602 | 4506.6 samples/s | 70.4 steps/s
[Step=72900 Epoch=142.2] | Loss=0.00905 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.098 | L2-Norm(final)=13.608 | 4437.8 samples/s | 69.3 steps/s
[Step=72950 Epoch=142.3] | Loss=0.00900 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.100 | L2-Norm(final)=13.613 | 4504.2 samples/s | 70.4 steps/s
[Step=73000 Epoch=142.4] | Loss=0.00888 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.103 | L2-Norm(final)=13.618 | 5734.4 samples/s | 89.6 steps/s
[Step=73050 Epoch=142.5] | Loss=0.00880 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=13.622 | 2399.8 samples/s | 37.5 steps/s
[Step=73100 Epoch=142.6] | Loss=0.00863 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.108 | L2-Norm(final)=13.627 | 4404.9 samples/s | 68.8 steps/s
[Step=73150 Epoch=142.7] | Loss=0.00845 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.110 | L2-Norm(final)=13.632 | 4462.0 samples/s | 69.7 steps/s
[Step=73200 Epoch=142.8] | Loss=0.00830 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.111 | L2-Norm(final)=13.636 | 4500.6 samples/s | 70.3 steps/s
[Step=73250 Epoch=142.9] | Loss=0.00822 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.113 | L2-Norm(final)=13.640 | 4410.7 samples/s | 68.9 steps/s
[Step=73300 Epoch=143.0] | Loss=0.00825 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.114 | L2-Norm(final)=13.644 | 4556.4 samples/s | 71.2 steps/s
[Step=73350 Epoch=143.1] | Loss=0.00808 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.116 | L2-Norm(final)=13.648 | 4446.2 samples/s | 69.5 steps/s
[Step=73400 Epoch=143.2] | Loss=0.00793 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=13.652 | 4457.8 samples/s | 69.7 steps/s
[Step=73450 Epoch=143.3] | Loss=0.00784 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.118 | L2-Norm(final)=13.656 | 4423.5 samples/s | 69.1 steps/s
[Step=73500 Epoch=143.4] | Loss=0.00778 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.119 | L2-Norm(final)=13.660 | 4784.5 samples/s | 74.8 steps/s
[Step=73550 Epoch=143.5] | Loss=0.00762 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=13.664 | 2610.4 samples/s | 40.8 steps/s
[Step=73600 Epoch=143.5] | Loss=0.00751 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=13.668 | 4491.0 samples/s | 70.2 steps/s
[Step=73650 Epoch=143.6] | Loss=0.00739 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.122 | L2-Norm(final)=13.671 | 4465.0 samples/s | 69.8 steps/s
[Step=73700 Epoch=143.7] | Loss=0.00734 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=13.675 | 4538.2 samples/s | 70.9 steps/s
[Step=73750 Epoch=143.8] | Loss=0.00728 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=13.679 | 4393.1 samples/s | 68.6 steps/s
[Step=73800 Epoch=143.9] | Loss=0.00722 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=13.682 | 4460.7 samples/s | 69.7 steps/s
[Step=73850 Epoch=144.0] | Loss=0.00715 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=13.686 | 4370.4 samples/s | 68.3 steps/s
[Step=73900 Epoch=144.1] | Loss=0.00711 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=13.689 | 4482.7 samples/s | 70.0 steps/s
[Step=73950 Epoch=144.2] | Loss=0.00705 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=13.693 | 4489.8 samples/s | 70.2 steps/s
[Step=74000 Epoch=144.3] | Loss=0.00704 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=13.696 | 4540.8 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step74000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=140.8] | Loss=0.01147 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=13.495 | 5382.9 samples/s | 84.1 steps/s
[Step=72050 Epoch=140.9] | Loss=0.00847 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=13.500 | 4717.5 samples/s | 73.7 steps/s
[Step=72100 Epoch=141.0] | Loss=0.00896 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.142 | L2-Norm(final)=13.508 | 5043.5 samples/s | 78.8 steps/s
[Step=72150 Epoch=141.1] | Loss=0.00930 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=13.516 | 4991.4 samples/s | 78.0 steps/s
[Step=72200 Epoch=141.1] | Loss=0.00898 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=13.524 | 4965.3 samples/s | 77.6 steps/s
[Step=72250 Epoch=141.2] | Loss=0.00871 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.153 | L2-Norm(final)=13.532 | 4952.4 samples/s | 77.4 steps/s
[Step=72300 Epoch=141.3] | Loss=0.00858 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.156 | L2-Norm(final)=13.540 | 5062.5 samples/s | 79.1 steps/s
[Step=72350 Epoch=141.4] | Loss=0.00848 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.159 | L2-Norm(final)=13.548 | 5189.2 samples/s | 81.1 steps/s
[Step=72400 Epoch=141.5] | Loss=0.00857 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.163 | L2-Norm(final)=13.555 | 5014.8 samples/s | 78.4 steps/s
[Step=72450 Epoch=141.6] | Loss=0.00857 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=13.563 | 4979.3 samples/s | 77.8 steps/s
[Step=72500 Epoch=141.7] | Loss=0.00856 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=13.570 | 6911.8 samples/s | 108.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=141.7] | Loss=0.01228 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.198 | L2-Norm(final)=13.644 | 5722.9 samples/s | 89.4 steps/s
[Step=72550 Epoch=141.8] | Loss=0.00771 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.203 | L2-Norm(final)=13.651 | 4344.8 samples/s | 67.9 steps/s
[Step=72600 Epoch=141.9] | Loss=0.00848 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.208 | L2-Norm(final)=13.658 | 4464.6 samples/s | 69.8 steps/s
[Step=72650 Epoch=142.0] | Loss=0.00841 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.213 | L2-Norm(final)=13.664 | 4442.6 samples/s | 69.4 steps/s
[Step=72700 Epoch=142.1] | Loss=0.00880 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=13.670 | 4439.3 samples/s | 69.4 steps/s
[Step=72750 Epoch=142.2] | Loss=0.00942 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.221 | L2-Norm(final)=13.676 | 4461.2 samples/s | 69.7 steps/s
[Step=72800 Epoch=142.3] | Loss=0.00922 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.224 | L2-Norm(final)=13.681 | 4493.3 samples/s | 70.2 steps/s
[Step=72850 Epoch=142.4] | Loss=0.00906 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.227 | L2-Norm(final)=13.686 | 4516.3 samples/s | 70.6 steps/s
[Step=72900 Epoch=142.5] | Loss=0.00898 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.230 | L2-Norm(final)=13.691 | 4447.3 samples/s | 69.5 steps/s
[Step=72950 Epoch=142.6] | Loss=0.00885 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.233 | L2-Norm(final)=13.696 | 4477.1 samples/s | 70.0 steps/s
[Step=73000 Epoch=142.7] | Loss=0.00887 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.235 | L2-Norm(final)=13.700 | 5909.9 samples/s | 92.3 steps/s
[Step=73050 Epoch=142.8] | Loss=0.00884 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.238 | L2-Norm(final)=13.705 | 2365.5 samples/s | 37.0 steps/s
[Step=73100 Epoch=142.9] | Loss=0.00861 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=13.710 | 4494.4 samples/s | 70.2 steps/s
[Step=73150 Epoch=143.0] | Loss=0.00844 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.242 | L2-Norm(final)=13.714 | 4412.2 samples/s | 68.9 steps/s
[Step=73200 Epoch=143.1] | Loss=0.00834 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.244 | L2-Norm(final)=13.718 | 4476.1 samples/s | 69.9 steps/s
[Step=73250 Epoch=143.2] | Loss=0.00826 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.246 | L2-Norm(final)=13.722 | 4506.3 samples/s | 70.4 steps/s
[Step=73300 Epoch=143.3] | Loss=0.00815 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.247 | L2-Norm(final)=13.726 | 4456.3 samples/s | 69.6 steps/s
[Step=73350 Epoch=143.4] | Loss=0.00799 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.249 | L2-Norm(final)=13.730 | 4573.4 samples/s | 71.5 steps/s
[Step=73400 Epoch=143.5] | Loss=0.00789 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.250 | L2-Norm(final)=13.734 | 4472.8 samples/s | 69.9 steps/s
[Step=73450 Epoch=143.6] | Loss=0.00781 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.252 | L2-Norm(final)=13.738 | 4345.9 samples/s | 67.9 steps/s
[Step=73500 Epoch=143.7] | Loss=0.00772 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.253 | L2-Norm(final)=13.742 | 4930.8 samples/s | 77.0 steps/s
[Step=73550 Epoch=143.8] | Loss=0.00758 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.254 | L2-Norm(final)=13.746 | 2570.7 samples/s | 40.2 steps/s
[Step=73600 Epoch=143.9] | Loss=0.00752 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.255 | L2-Norm(final)=13.750 | 4557.8 samples/s | 71.2 steps/s
[Step=73650 Epoch=144.0] | Loss=0.00739 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.256 | L2-Norm(final)=13.753 | 4398.6 samples/s | 68.7 steps/s
[Step=73700 Epoch=144.1] | Loss=0.00729 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.257 | L2-Norm(final)=13.757 | 4458.7 samples/s | 69.7 steps/s
[Step=73750 Epoch=144.2] | Loss=0.00715 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.258 | L2-Norm(final)=13.760 | 4489.9 samples/s | 70.2 steps/s
[Step=73800 Epoch=144.3] | Loss=0.00712 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.258 | L2-Norm(final)=13.764 | 4466.8 samples/s | 69.8 steps/s
[Step=73850 Epoch=144.4] | Loss=0.00703 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=13.767 | 4429.7 samples/s | 69.2 steps/s
[Step=73900 Epoch=144.5] | Loss=0.00700 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.260 | L2-Norm(final)=13.771 | 4428.6 samples/s | 69.2 steps/s
[Step=73950 Epoch=144.6] | Loss=0.00695 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.260 | L2-Norm(final)=13.774 | 4495.3 samples/s | 70.2 steps/s
[Step=74000 Epoch=144.7] | Loss=0.00696 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.261 | L2-Norm(final)=13.778 | 4462.8 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step74000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=275.9] | Loss=0.00018 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.379 | L2-Norm(final)=8.320 | 5814.2 samples/s | 90.8 steps/s
[Step=72050 Epoch=276.1] | Loss=0.00010 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.382 | L2-Norm(final)=8.323 | 4229.9 samples/s | 66.1 steps/s
[Step=72100 Epoch=276.3] | Loss=0.00006 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.385 | L2-Norm(final)=8.325 | 4804.8 samples/s | 75.1 steps/s
[Step=72150 Epoch=276.5] | Loss=0.00005 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=8.326 | 4874.8 samples/s | 76.2 steps/s
[Step=72200 Epoch=276.6] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=8.327 | 4536.6 samples/s | 70.9 steps/s
[Step=72250 Epoch=276.8] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=8.329 | 6561.3 samples/s | 102.5 steps/s
[Step=72300 Epoch=277.0] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=8.330 | 2460.6 samples/s | 38.4 steps/s
[Step=72350 Epoch=277.2] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=8.331 | 4565.5 samples/s | 71.3 steps/s
[Step=72400 Epoch=277.4] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=8.333 | 4715.1 samples/s | 73.7 steps/s
[Step=72450 Epoch=277.6] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=8.334 | 4762.7 samples/s | 74.4 steps/s
[Step=72500 Epoch=277.8] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=8.335 | 5494.3 samples/s | 85.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=277.8] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=8.349 | 6023.3 samples/s | 94.1 steps/s
[Step=72550 Epoch=278.0] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=8.350 | 3851.2 samples/s | 60.2 steps/s
[Step=72600 Epoch=278.2] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=8.351 | 4256.3 samples/s | 66.5 steps/s
[Step=72650 Epoch=278.4] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=8.352 | 4173.8 samples/s | 65.2 steps/s
[Step=72700 Epoch=278.6] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=8.353 | 4241.2 samples/s | 66.3 steps/s
[Step=72750 Epoch=278.8] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=8.355 | 5716.1 samples/s | 89.3 steps/s
[Step=72800 Epoch=278.9] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.384 | L2-Norm(final)=8.356 | 2285.4 samples/s | 35.7 steps/s
[Step=72850 Epoch=279.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.383 | L2-Norm(final)=8.357 | 4226.2 samples/s | 66.0 steps/s
[Step=72900 Epoch=279.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.382 | L2-Norm(final)=8.358 | 4277.7 samples/s | 66.8 steps/s
[Step=72950 Epoch=279.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.380 | L2-Norm(final)=8.359 | 4051.5 samples/s | 63.3 steps/s
[Step=73000 Epoch=279.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.379 | L2-Norm(final)=8.360 | 4791.6 samples/s | 74.9 steps/s
[Step=73050 Epoch=279.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.377 | L2-Norm(final)=8.361 | 2447.8 samples/s | 38.2 steps/s
[Step=73100 Epoch=280.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.376 | L2-Norm(final)=8.361 | 4193.9 samples/s | 65.5 steps/s
[Step=73150 Epoch=280.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.374 | L2-Norm(final)=8.362 | 4250.1 samples/s | 66.4 steps/s
[Step=73200 Epoch=280.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.373 | L2-Norm(final)=8.363 | 4231.2 samples/s | 66.1 steps/s
[Step=73250 Epoch=280.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.371 | L2-Norm(final)=8.364 | 4242.5 samples/s | 66.3 steps/s
[Step=73300 Epoch=280.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.369 | L2-Norm(final)=8.365 | 2603.3 samples/s | 40.7 steps/s
[Step=73350 Epoch=281.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.368 | L2-Norm(final)=8.366 | 4252.0 samples/s | 66.4 steps/s
[Step=73400 Epoch=281.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.366 | L2-Norm(final)=8.367 | 4290.3 samples/s | 67.0 steps/s
[Step=73450 Epoch=281.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.364 | L2-Norm(final)=8.367 | 4187.2 samples/s | 65.4 steps/s
[Step=73500 Epoch=281.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.362 | L2-Norm(final)=8.368 | 4219.0 samples/s | 65.9 steps/s
[Step=73550 Epoch=281.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.360 | L2-Norm(final)=8.369 | 2630.8 samples/s | 41.1 steps/s
[Step=73600 Epoch=282.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.358 | L2-Norm(final)=8.370 | 4297.4 samples/s | 67.1 steps/s
[Step=73650 Epoch=282.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=8.370 | 4160.8 samples/s | 65.0 steps/s
[Step=73700 Epoch=282.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.354 | L2-Norm(final)=8.371 | 4186.0 samples/s | 65.4 steps/s
[Step=73750 Epoch=282.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.352 | L2-Norm(final)=8.372 | 4279.4 samples/s | 66.9 steps/s
[Step=73800 Epoch=282.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=8.373 | 6178.1 samples/s | 96.5 steps/s
[Step=73850 Epoch=283.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.347 | L2-Norm(final)=8.374 | 2181.0 samples/s | 34.1 steps/s
[Step=73900 Epoch=283.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.345 | L2-Norm(final)=8.374 | 4273.4 samples/s | 66.8 steps/s
[Step=73950 Epoch=283.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.343 | L2-Norm(final)=8.375 | 4292.4 samples/s | 67.1 steps/s
[Step=74000 Epoch=283.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.341 | L2-Norm(final)=8.376 | 4144.5 samples/s | 64.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step74000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=277.2] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=9.530 | 5934.8 samples/s | 92.7 steps/s
[Step=72050 Epoch=277.3] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=9.530 | 4351.7 samples/s | 68.0 steps/s
[Step=72100 Epoch=277.5] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=9.531 | 4558.5 samples/s | 71.2 steps/s
[Step=72150 Epoch=277.7] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=9.532 | 4699.7 samples/s | 73.4 steps/s
[Step=72200 Epoch=277.9] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=9.533 | 4778.1 samples/s | 74.7 steps/s
[Step=72250 Epoch=278.1] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=9.534 | 6723.1 samples/s | 105.0 steps/s
[Step=72300 Epoch=278.3] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=9.535 | 2393.4 samples/s | 37.4 steps/s
[Step=72350 Epoch=278.5] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.536 | 4748.9 samples/s | 74.2 steps/s
[Step=72400 Epoch=278.7] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.538 | 4655.5 samples/s | 72.7 steps/s
[Step=72450 Epoch=278.9] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.539 | 4738.9 samples/s | 74.0 steps/s
[Step=72500 Epoch=279.1] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=9.540 | 5658.3 samples/s | 88.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=279.1] | Loss=0.00007 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.294 | L2-Norm(final)=9.550 | 6155.4 samples/s | 96.2 steps/s
[Step=72550 Epoch=279.3] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.294 | L2-Norm(final)=9.551 | 3790.7 samples/s | 59.2 steps/s
[Step=72600 Epoch=279.5] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=9.552 | 4262.2 samples/s | 66.6 steps/s
[Step=72650 Epoch=279.7] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=9.553 | 4250.9 samples/s | 66.4 steps/s
[Step=72700 Epoch=279.9] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=9.554 | 4234.6 samples/s | 66.2 steps/s
[Step=72750 Epoch=280.0] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.555 | 5683.1 samples/s | 88.8 steps/s
[Step=72800 Epoch=280.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=9.556 | 2273.9 samples/s | 35.5 steps/s
[Step=72850 Epoch=280.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=9.557 | 4192.7 samples/s | 65.5 steps/s
[Step=72900 Epoch=280.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.288 | L2-Norm(final)=9.558 | 4204.6 samples/s | 65.7 steps/s
[Step=72950 Epoch=280.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.287 | L2-Norm(final)=9.559 | 4286.7 samples/s | 67.0 steps/s
[Step=73000 Epoch=281.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.286 | L2-Norm(final)=9.559 | 4896.1 samples/s | 76.5 steps/s
[Step=73050 Epoch=281.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.285 | L2-Norm(final)=9.560 | 2399.7 samples/s | 37.5 steps/s
[Step=73100 Epoch=281.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.284 | L2-Norm(final)=9.561 | 4194.3 samples/s | 65.5 steps/s
[Step=73150 Epoch=281.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.282 | L2-Norm(final)=9.561 | 4208.0 samples/s | 65.8 steps/s
[Step=73200 Epoch=281.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.281 | L2-Norm(final)=9.562 | 4237.3 samples/s | 66.2 steps/s
[Step=73250 Epoch=282.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.280 | L2-Norm(final)=9.563 | 4350.6 samples/s | 68.0 steps/s
[Step=73300 Epoch=282.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.279 | L2-Norm(final)=9.563 | 1947.3 samples/s | 30.4 steps/s
[Step=73350 Epoch=282.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.277 | L2-Norm(final)=9.564 | 4213.8 samples/s | 65.8 steps/s
[Step=73400 Epoch=282.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.276 | L2-Norm(final)=9.565 | 4119.6 samples/s | 64.4 steps/s
[Step=73450 Epoch=282.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.274 | L2-Norm(final)=9.565 | 4121.3 samples/s | 64.4 steps/s
[Step=73500 Epoch=282.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.273 | L2-Norm(final)=9.566 | 4283.6 samples/s | 66.9 steps/s
[Step=73550 Epoch=283.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.271 | L2-Norm(final)=9.566 | 2604.1 samples/s | 40.7 steps/s
[Step=73600 Epoch=283.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.270 | L2-Norm(final)=9.567 | 4148.7 samples/s | 64.8 steps/s
[Step=73650 Epoch=283.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=9.567 | 4167.0 samples/s | 65.1 steps/s
[Step=73700 Epoch=283.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=9.568 | 4267.8 samples/s | 66.7 steps/s
[Step=73750 Epoch=283.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.265 | L2-Norm(final)=9.568 | 4224.3 samples/s | 66.0 steps/s
[Step=73800 Epoch=284.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=9.569 | 6784.0 samples/s | 106.0 steps/s
[Step=73850 Epoch=284.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.262 | L2-Norm(final)=9.570 | 2124.0 samples/s | 33.2 steps/s
[Step=73900 Epoch=284.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=9.570 | 4219.3 samples/s | 65.9 steps/s
[Step=73950 Epoch=284.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.258 | L2-Norm(final)=9.571 | 4237.6 samples/s | 66.2 steps/s
[Step=74000 Epoch=284.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.256 | L2-Norm(final)=9.571 | 4249.8 samples/s | 66.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07184 | acc=0.9669 | tpr=0.9767 | fpr=0.0545 | 4820.7 samples/s | 18.8 steps/s
Avg test loss: 0.07142, Avg test acc: 0.96678, Avg tpr: 0.97657, Avg fpr: 0.05474, total FA: 427

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06638 | acc=0.9666 | tpr=0.9743 | fpr=0.0500 | 4776.6 samples/s | 18.7 steps/s
Avg test loss: 0.06943, Avg test acc: 0.96606, Avg tpr: 0.97366, Avg fpr: 0.05063, total FA: 395

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.99504 | acc=0.3052 | tpr=0.0089 | fpr=0.0515 | 4910.8 samples/s | 19.2 steps/s
Avg test loss: 4.99361, Avg test acc: 0.30179, Avg tpr: 0.00985, Avg fpr: 0.05615, total FA: 438

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.43547 | acc=0.3109 | tpr=0.0162 | fpr=0.0491 | 5010.8 samples/s | 19.6 steps/s
Avg test loss: 5.42807, Avg test acc: 0.30764, Avg tpr: 0.01719, Avg fpr: 0.05358, total FA: 418

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.05041 | acc=0.1268 | tpr=0.5354 | fpr=0.8805 | 4875.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.01898 | acc=0.1266 | tpr=0.5160 | fpr=0.8806 | 7394.1 samples/s | 28.9 steps/s
[Step= 150] | Loss=6.01947 | acc=0.1263 | tpr=0.5130 | fpr=0.8808 | 7699.8 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.01576 | acc=0.1268 | tpr=0.5191 | fpr=0.8803 | 7832.3 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.00625 | acc=0.1270 | tpr=0.5328 | fpr=0.8804 | 7639.1 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.00037 | acc=0.1268 | tpr=0.5287 | fpr=0.8806 | 8060.2 samples/s | 31.5 steps/s
[Step= 350] | Loss=6.00562 | acc=0.1264 | tpr=0.5141 | fpr=0.8806 | 7857.9 samples/s | 30.7 steps/s
[Step= 400] | Loss=6.00443 | acc=0.1267 | tpr=0.5109 | fpr=0.8803 | 7803.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.00705 | acc=0.1262 | tpr=0.5122 | fpr=0.8808 | 7843.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.00961 | acc=0.1264 | tpr=0.5132 | fpr=0.8806 | 7586.9 samples/s | 29.6 steps/s
[Step= 550] | Loss=6.01125 | acc=0.1267 | tpr=0.5141 | fpr=0.8804 | 14739.3 samples/s | 57.6 steps/s
Avg test loss: 6.01273, Avg test acc: 0.12655, Avg tpr: 0.51506, Avg fpr: 0.88051, total FA: 122257

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.11972 | acc=0.1334 | tpr=0.5973 | fpr=0.8750 | 5115.4 samples/s | 20.0 steps/s
[Step= 100] | Loss=6.11043 | acc=0.1345 | tpr=0.5608 | fpr=0.8734 | 6732.6 samples/s | 26.3 steps/s
[Step= 150] | Loss=6.10739 | acc=0.1351 | tpr=0.5663 | fpr=0.8729 | 7450.9 samples/s | 29.1 steps/s
[Step= 200] | Loss=6.10353 | acc=0.1350 | tpr=0.5552 | fpr=0.8727 | 8388.6 samples/s | 32.8 steps/s
[Step= 250] | Loss=6.09335 | acc=0.1359 | tpr=0.5546 | fpr=0.8717 | 7827.3 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.08866 | acc=0.1363 | tpr=0.5549 | fpr=0.8713 | 7849.1 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.09277 | acc=0.1360 | tpr=0.5460 | fpr=0.8714 | 7733.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.08865 | acc=0.1359 | tpr=0.5432 | fpr=0.8715 | 7933.0 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.09248 | acc=0.1355 | tpr=0.5394 | fpr=0.8719 | 7580.1 samples/s | 29.6 steps/s
[Step= 500] | Loss=6.09482 | acc=0.1361 | tpr=0.5441 | fpr=0.8713 | 8240.5 samples/s | 32.2 steps/s
[Step= 550] | Loss=6.09795 | acc=0.1362 | tpr=0.5428 | fpr=0.8712 | 13397.0 samples/s | 52.3 steps/s
Avg test loss: 6.09998, Avg test acc: 0.13605, Avg tpr: 0.54319, Avg fpr: 0.87136, total FA: 120986

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12072 | acc=0.9772 | tpr=0.9513 | fpr=0.0223 | 4927.4 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.12188 | acc=0.9777 | tpr=0.9574 | fpr=0.0219 | 7133.2 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.12723 | acc=0.9769 | tpr=0.9597 | fpr=0.0228 | 7899.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.13028 | acc=0.9769 | tpr=0.9607 | fpr=0.0228 | 7647.4 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.12792 | acc=0.9771 | tpr=0.9624 | fpr=0.0226 | 7836.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.12952 | acc=0.9767 | tpr=0.9615 | fpr=0.0230 | 7907.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.12981 | acc=0.9767 | tpr=0.9612 | fpr=0.0230 | 8113.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.13112 | acc=0.9767 | tpr=0.9601 | fpr=0.0230 | 7664.0 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.13352 | acc=0.9763 | tpr=0.9591 | fpr=0.0234 | 7750.4 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13275 | acc=0.9763 | tpr=0.9595 | fpr=0.0234 | 8029.2 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.13145 | acc=0.9765 | tpr=0.9598 | fpr=0.0232 | 13481.9 samples/s | 52.7 steps/s
Avg test loss: 0.13129, Avg test acc: 0.97655, Avg tpr: 0.95959, Avg fpr: 0.02314, total FA: 3213

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11556 | acc=0.9782 | tpr=0.9558 | fpr=0.0214 | 5040.5 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.11750 | acc=0.9784 | tpr=0.9680 | fpr=0.0214 | 6833.7 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.12327 | acc=0.9776 | tpr=0.9669 | fpr=0.0222 | 7830.8 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.12612 | acc=0.9772 | tpr=0.9650 | fpr=0.0225 | 7750.4 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.12411 | acc=0.9775 | tpr=0.9642 | fpr=0.0223 | 8064.1 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.12576 | acc=0.9772 | tpr=0.9622 | fpr=0.0225 | 7946.0 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.12612 | acc=0.9771 | tpr=0.9631 | fpr=0.0226 | 7956.8 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.12733 | acc=0.9771 | tpr=0.9606 | fpr=0.0226 | 7623.3 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.12976 | acc=0.9767 | tpr=0.9581 | fpr=0.0230 | 7750.9 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12914 | acc=0.9769 | tpr=0.9581 | fpr=0.0228 | 7851.0 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.12781 | acc=0.9771 | tpr=0.9582 | fpr=0.0225 | 13806.4 samples/s | 53.9 steps/s
Avg test loss: 0.12767, Avg test acc: 0.97715, Avg tpr: 0.95800, Avg fpr: 0.02251, total FA: 3125

server round 37/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=144.3] | Loss=0.01114 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.073 | L2-Norm(final)=13.798 | 6201.3 samples/s | 96.9 steps/s
[Step=74050 Epoch=144.4] | Loss=0.00633 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=13.802 | 4654.6 samples/s | 72.7 steps/s
[Step=74100 Epoch=144.5] | Loss=0.00606 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=13.808 | 4895.1 samples/s | 76.5 steps/s
[Step=74150 Epoch=144.6] | Loss=0.00579 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.078 | L2-Norm(final)=13.813 | 5125.6 samples/s | 80.1 steps/s
[Step=74200 Epoch=144.7] | Loss=0.00609 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=13.819 | 4942.0 samples/s | 77.2 steps/s
[Step=74250 Epoch=144.8] | Loss=0.00602 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=13.825 | 5020.9 samples/s | 78.5 steps/s
[Step=74300 Epoch=144.9] | Loss=0.00578 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.081 | L2-Norm(final)=13.830 | 5016.5 samples/s | 78.4 steps/s
[Step=74350 Epoch=145.0] | Loss=0.00581 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=13.836 | 4971.9 samples/s | 77.7 steps/s
[Step=74400 Epoch=145.1] | Loss=0.00584 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=13.842 | 5012.3 samples/s | 78.3 steps/s
[Step=74450 Epoch=145.2] | Loss=0.00580 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.085 | L2-Norm(final)=13.847 | 5046.4 samples/s | 78.8 steps/s
[Step=74500 Epoch=145.3] | Loss=0.00586 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.086 | L2-Norm(final)=13.852 | 6832.3 samples/s | 106.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=145.3] | Loss=0.00021 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=13.906 | 6779.8 samples/s | 105.9 steps/s
[Step=74550 Epoch=145.4] | Loss=0.00674 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.096 | L2-Norm(final)=13.911 | 4024.5 samples/s | 62.9 steps/s
[Step=74600 Epoch=145.5] | Loss=0.00777 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.099 | L2-Norm(final)=13.917 | 4451.4 samples/s | 69.6 steps/s
[Step=74650 Epoch=145.6] | Loss=0.00753 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.102 | L2-Norm(final)=13.922 | 4443.9 samples/s | 69.4 steps/s
[Step=74700 Epoch=145.7] | Loss=0.00779 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.104 | L2-Norm(final)=13.927 | 4400.0 samples/s | 68.7 steps/s
[Step=74750 Epoch=145.8] | Loss=0.00733 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.106 | L2-Norm(final)=13.932 | 4489.4 samples/s | 70.1 steps/s
[Step=74800 Epoch=145.9] | Loss=0.00745 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.108 | L2-Norm(final)=13.937 | 4550.9 samples/s | 71.1 steps/s
[Step=74850 Epoch=146.0] | Loss=0.00745 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.110 | L2-Norm(final)=13.943 | 4410.6 samples/s | 68.9 steps/s
[Step=74900 Epoch=146.1] | Loss=0.00778 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=13.947 | 4495.5 samples/s | 70.2 steps/s
[Step=74950 Epoch=146.2] | Loss=0.00766 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=13.952 | 4531.3 samples/s | 70.8 steps/s
[Step=75000 Epoch=146.3] | Loss=0.00748 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=13.956 | 5651.4 samples/s | 88.3 steps/s
[Step=75050 Epoch=146.4] | Loss=0.00718 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.116 | L2-Norm(final)=13.961 | 2388.0 samples/s | 37.3 steps/s
[Step=75100 Epoch=146.5] | Loss=0.00694 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=13.965 | 4389.5 samples/s | 68.6 steps/s
[Step=75150 Epoch=146.6] | Loss=0.00689 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.118 | L2-Norm(final)=13.970 | 4519.1 samples/s | 70.6 steps/s
[Step=75200 Epoch=146.7] | Loss=0.00679 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.119 | L2-Norm(final)=13.974 | 4474.0 samples/s | 69.9 steps/s
[Step=75250 Epoch=146.8] | Loss=0.00679 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=13.978 | 4486.7 samples/s | 70.1 steps/s
[Step=75300 Epoch=146.9] | Loss=0.00673 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=13.982 | 4414.6 samples/s | 69.0 steps/s
[Step=75350 Epoch=147.0] | Loss=0.00680 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=13.986 | 4492.3 samples/s | 70.2 steps/s
[Step=75400 Epoch=147.1] | Loss=0.00688 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=13.990 | 4521.4 samples/s | 70.6 steps/s
[Step=75450 Epoch=147.2] | Loss=0.00690 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=13.994 | 4430.4 samples/s | 69.2 steps/s
[Step=75500 Epoch=147.3] | Loss=0.00686 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=13.998 | 4731.9 samples/s | 73.9 steps/s
[Step=75550 Epoch=147.4] | Loss=0.00682 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=14.002 | 2626.5 samples/s | 41.0 steps/s
[Step=75600 Epoch=147.4] | Loss=0.00679 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=14.005 | 4454.2 samples/s | 69.6 steps/s
[Step=75650 Epoch=147.5] | Loss=0.00672 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=14.009 | 4449.6 samples/s | 69.5 steps/s
[Step=75700 Epoch=147.6] | Loss=0.00661 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=14.013 | 4486.1 samples/s | 70.1 steps/s
[Step=75750 Epoch=147.7] | Loss=0.00656 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.126 | L2-Norm(final)=14.016 | 4439.0 samples/s | 69.4 steps/s
[Step=75800 Epoch=147.8] | Loss=0.00656 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=14.020 | 4472.9 samples/s | 69.9 steps/s
[Step=75850 Epoch=147.9] | Loss=0.00654 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=14.023 | 4468.3 samples/s | 69.8 steps/s
[Step=75900 Epoch=148.0] | Loss=0.00651 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.127 | L2-Norm(final)=14.027 | 4371.6 samples/s | 68.3 steps/s
[Step=75950 Epoch=148.1] | Loss=0.00648 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.128 | L2-Norm(final)=14.030 | 4502.6 samples/s | 70.4 steps/s
[Step=76000 Epoch=148.2] | Loss=0.00642 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=14.034 | 4418.8 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step76000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=144.7] | Loss=0.01484 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.213 | L2-Norm(final)=13.880 | 6377.3 samples/s | 99.6 steps/s
[Step=74050 Epoch=144.8] | Loss=0.00741 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=13.883 | 4513.7 samples/s | 70.5 steps/s
[Step=74100 Epoch=144.9] | Loss=0.00714 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.220 | L2-Norm(final)=13.889 | 4980.9 samples/s | 77.8 steps/s
[Step=74150 Epoch=145.0] | Loss=0.00693 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.222 | L2-Norm(final)=13.894 | 5042.0 samples/s | 78.8 steps/s
[Step=74200 Epoch=145.1] | Loss=0.00723 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=13.899 | 5011.0 samples/s | 78.3 steps/s
[Step=74250 Epoch=145.2] | Loss=0.00729 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.226 | L2-Norm(final)=13.905 | 5032.4 samples/s | 78.6 steps/s
[Step=74300 Epoch=145.3] | Loss=0.00712 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.228 | L2-Norm(final)=13.911 | 5188.6 samples/s | 81.1 steps/s
[Step=74350 Epoch=145.4] | Loss=0.00707 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.230 | L2-Norm(final)=13.917 | 4875.8 samples/s | 76.2 steps/s
[Step=74400 Epoch=145.5] | Loss=0.00680 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.231 | L2-Norm(final)=13.923 | 4989.6 samples/s | 78.0 steps/s
[Step=74450 Epoch=145.5] | Loss=0.00658 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.232 | L2-Norm(final)=13.929 | 5116.1 samples/s | 79.9 steps/s
[Step=74500 Epoch=145.6] | Loss=0.00650 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=13.935 | 6848.6 samples/s | 107.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=145.6] | Loss=0.00432 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=13.995 | 6266.3 samples/s | 97.9 steps/s
[Step=74550 Epoch=145.7] | Loss=0.00710 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.249 | L2-Norm(final)=14.000 | 4081.0 samples/s | 63.8 steps/s
[Step=74600 Epoch=145.8] | Loss=0.00717 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.253 | L2-Norm(final)=14.005 | 4414.7 samples/s | 69.0 steps/s
[Step=74650 Epoch=145.9] | Loss=0.00744 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.256 | L2-Norm(final)=14.010 | 4447.0 samples/s | 69.5 steps/s
[Step=74700 Epoch=146.0] | Loss=0.00722 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=14.014 | 4394.6 samples/s | 68.7 steps/s
[Step=74750 Epoch=146.1] | Loss=0.00710 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.261 | L2-Norm(final)=14.019 | 4458.6 samples/s | 69.7 steps/s
[Step=74800 Epoch=146.2] | Loss=0.00717 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.263 | L2-Norm(final)=14.024 | 4466.8 samples/s | 69.8 steps/s
[Step=74850 Epoch=146.3] | Loss=0.00710 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.265 | L2-Norm(final)=14.029 | 4539.4 samples/s | 70.9 steps/s
[Step=74900 Epoch=146.4] | Loss=0.00721 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.267 | L2-Norm(final)=14.033 | 4476.1 samples/s | 69.9 steps/s
[Step=74950 Epoch=146.5] | Loss=0.00714 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.269 | L2-Norm(final)=14.038 | 4465.6 samples/s | 69.8 steps/s
[Step=75000 Epoch=146.6] | Loss=0.00737 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.271 | L2-Norm(final)=14.042 | 5938.8 samples/s | 92.8 steps/s
[Step=75050 Epoch=146.7] | Loss=0.00726 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.273 | L2-Norm(final)=14.047 | 2372.8 samples/s | 37.1 steps/s
[Step=75100 Epoch=146.8] | Loss=0.00717 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.274 | L2-Norm(final)=14.051 | 4437.3 samples/s | 69.3 steps/s
[Step=75150 Epoch=146.9] | Loss=0.00710 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=14.055 | 4453.9 samples/s | 69.6 steps/s
[Step=75200 Epoch=147.0] | Loss=0.00711 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.277 | L2-Norm(final)=14.059 | 4487.2 samples/s | 70.1 steps/s
[Step=75250 Epoch=147.1] | Loss=0.00714 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=14.063 | 4482.3 samples/s | 70.0 steps/s
[Step=75300 Epoch=147.2] | Loss=0.00707 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=14.066 | 4463.1 samples/s | 69.7 steps/s
[Step=75350 Epoch=147.3] | Loss=0.00702 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.280 | L2-Norm(final)=14.070 | 4518.9 samples/s | 70.6 steps/s
[Step=75400 Epoch=147.4] | Loss=0.00702 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.281 | L2-Norm(final)=14.074 | 4437.7 samples/s | 69.3 steps/s
[Step=75450 Epoch=147.5] | Loss=0.00702 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.282 | L2-Norm(final)=14.078 | 4478.8 samples/s | 70.0 steps/s
[Step=75500 Epoch=147.6] | Loss=0.00695 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.283 | L2-Norm(final)=14.081 | 4854.4 samples/s | 75.9 steps/s
[Step=75550 Epoch=147.7] | Loss=0.00687 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.284 | L2-Norm(final)=14.085 | 2582.4 samples/s | 40.3 steps/s
[Step=75600 Epoch=147.8] | Loss=0.00676 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.285 | L2-Norm(final)=14.088 | 4435.3 samples/s | 69.3 steps/s
[Step=75650 Epoch=147.9] | Loss=0.00670 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.285 | L2-Norm(final)=14.092 | 4493.0 samples/s | 70.2 steps/s
[Step=75700 Epoch=148.0] | Loss=0.00663 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.286 | L2-Norm(final)=14.095 | 4508.5 samples/s | 70.4 steps/s
[Step=75750 Epoch=148.1] | Loss=0.00653 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.286 | L2-Norm(final)=14.099 | 4389.4 samples/s | 68.6 steps/s
[Step=75800 Epoch=148.2] | Loss=0.00645 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.287 | L2-Norm(final)=14.102 | 4489.2 samples/s | 70.1 steps/s
[Step=75850 Epoch=148.3] | Loss=0.00650 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.287 | L2-Norm(final)=14.106 | 4469.5 samples/s | 69.8 steps/s
[Step=75900 Epoch=148.4] | Loss=0.00650 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.287 | L2-Norm(final)=14.109 | 4383.5 samples/s | 68.5 steps/s
[Step=75950 Epoch=148.5] | Loss=0.00647 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.288 | L2-Norm(final)=14.112 | 4542.1 samples/s | 71.0 steps/s
[Step=76000 Epoch=148.6] | Loss=0.00649 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.288 | L2-Norm(final)=14.116 | 4414.7 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step76000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=283.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=8.398 | 6062.9 samples/s | 94.7 steps/s
[Step=74050 Epoch=283.7] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=8.400 | 4278.3 samples/s | 66.8 steps/s
[Step=74100 Epoch=283.9] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.401 | L2-Norm(final)=8.403 | 4630.3 samples/s | 72.3 steps/s
[Step=74150 Epoch=284.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.401 | L2-Norm(final)=8.406 | 4762.3 samples/s | 74.4 steps/s
[Step=74200 Epoch=284.3] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.402 | L2-Norm(final)=8.409 | 4706.9 samples/s | 73.5 steps/s
[Step=74250 Epoch=284.5] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.403 | L2-Norm(final)=8.412 | 6576.3 samples/s | 102.8 steps/s
[Step=74300 Epoch=284.7] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.403 | L2-Norm(final)=8.415 | 2365.6 samples/s | 37.0 steps/s
[Step=74350 Epoch=284.9] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.404 | L2-Norm(final)=8.418 | 4771.2 samples/s | 74.6 steps/s
[Step=74400 Epoch=285.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.404 | L2-Norm(final)=8.421 | 4705.6 samples/s | 73.5 steps/s
[Step=74450 Epoch=285.3] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.405 | L2-Norm(final)=8.424 | 4732.2 samples/s | 73.9 steps/s
[Step=74500 Epoch=285.5] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.405 | L2-Norm(final)=8.427 | 5515.8 samples/s | 86.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=285.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.409 | L2-Norm(final)=8.457 | 6013.0 samples/s | 94.0 steps/s
[Step=74550 Epoch=285.6] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.408 | L2-Norm(final)=8.459 | 3910.8 samples/s | 61.1 steps/s
[Step=74600 Epoch=285.8] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.405 | L2-Norm(final)=8.462 | 4178.7 samples/s | 65.3 steps/s
[Step=74650 Epoch=286.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.402 | L2-Norm(final)=8.465 | 4209.8 samples/s | 65.8 steps/s
[Step=74700 Epoch=286.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=8.467 | 4264.8 samples/s | 66.6 steps/s
[Step=74750 Epoch=286.4] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.395 | L2-Norm(final)=8.469 | 5644.4 samples/s | 88.2 steps/s
[Step=74800 Epoch=286.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.392 | L2-Norm(final)=8.471 | 2287.7 samples/s | 35.7 steps/s
[Step=74850 Epoch=286.8] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=8.473 | 4179.9 samples/s | 65.3 steps/s
[Step=74900 Epoch=287.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.384 | L2-Norm(final)=8.475 | 4268.6 samples/s | 66.7 steps/s
[Step=74950 Epoch=287.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.379 | L2-Norm(final)=8.476 | 4256.6 samples/s | 66.5 steps/s
[Step=75000 Epoch=287.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.375 | L2-Norm(final)=8.478 | 4680.8 samples/s | 73.1 steps/s
[Step=75050 Epoch=287.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.370 | L2-Norm(final)=8.479 | 2493.4 samples/s | 39.0 steps/s
[Step=75100 Epoch=287.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.366 | L2-Norm(final)=8.480 | 4109.6 samples/s | 64.2 steps/s
[Step=75150 Epoch=287.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.361 | L2-Norm(final)=8.482 | 4225.5 samples/s | 66.0 steps/s
[Step=75200 Epoch=288.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=8.483 | 4231.6 samples/s | 66.1 steps/s
[Step=75250 Epoch=288.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.352 | L2-Norm(final)=8.485 | 4341.5 samples/s | 67.8 steps/s
[Step=75300 Epoch=288.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.347 | L2-Norm(final)=8.486 | 2587.4 samples/s | 40.4 steps/s
[Step=75350 Epoch=288.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.342 | L2-Norm(final)=8.487 | 4210.1 samples/s | 65.8 steps/s
[Step=75400 Epoch=288.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.336 | L2-Norm(final)=8.488 | 4183.4 samples/s | 65.4 steps/s
[Step=75450 Epoch=289.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.331 | L2-Norm(final)=8.490 | 4258.4 samples/s | 66.5 steps/s
[Step=75500 Epoch=289.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.326 | L2-Norm(final)=8.491 | 4235.5 samples/s | 66.2 steps/s
[Step=75550 Epoch=289.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.320 | L2-Norm(final)=8.492 | 2635.1 samples/s | 41.2 steps/s
[Step=75600 Epoch=289.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=8.493 | 4167.6 samples/s | 65.1 steps/s
[Step=75650 Epoch=289.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.309 | L2-Norm(final)=8.495 | 4248.0 samples/s | 66.4 steps/s
[Step=75700 Epoch=290.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=8.496 | 4109.8 samples/s | 64.2 steps/s
[Step=75750 Epoch=290.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=8.497 | 4265.4 samples/s | 66.6 steps/s
[Step=75800 Epoch=290.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=8.498 | 6100.2 samples/s | 95.3 steps/s
[Step=75850 Epoch=290.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.286 | L2-Norm(final)=8.500 | 2204.2 samples/s | 34.4 steps/s
[Step=75900 Epoch=290.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.280 | L2-Norm(final)=8.501 | 4120.5 samples/s | 64.4 steps/s
[Step=75950 Epoch=291.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.274 | L2-Norm(final)=8.502 | 4204.8 samples/s | 65.7 steps/s
[Step=76000 Epoch=291.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=8.504 | 4240.4 samples/s | 66.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step76000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=284.9] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.314 | L2-Norm(final)=9.587 | 6012.5 samples/s | 93.9 steps/s
[Step=74050 Epoch=285.0] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.313 | L2-Norm(final)=9.588 | 4095.7 samples/s | 64.0 steps/s
[Step=74100 Epoch=285.2] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.314 | L2-Norm(final)=9.590 | 4730.3 samples/s | 73.9 steps/s
[Step=74150 Epoch=285.4] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=9.593 | 4739.3 samples/s | 74.1 steps/s
[Step=74200 Epoch=285.6] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=9.595 | 4869.3 samples/s | 76.1 steps/s
[Step=74250 Epoch=285.8] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=9.597 | 6546.8 samples/s | 102.3 steps/s
[Step=74300 Epoch=286.0] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=9.600 | 2416.2 samples/s | 37.8 steps/s
[Step=74350 Epoch=286.2] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=9.603 | 4785.1 samples/s | 74.8 steps/s
[Step=74400 Epoch=286.4] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=9.605 | 4568.6 samples/s | 71.4 steps/s
[Step=74450 Epoch=286.6] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.318 | L2-Norm(final)=9.608 | 4742.7 samples/s | 74.1 steps/s
[Step=74500 Epoch=286.8] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.318 | L2-Norm(final)=9.610 | 5686.2 samples/s | 88.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=286.8] | Loss=0.00003 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.323 | L2-Norm(final)=9.635 | 6082.9 samples/s | 95.0 steps/s
[Step=74550 Epoch=287.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=9.638 | 3873.2 samples/s | 60.5 steps/s
[Step=74600 Epoch=287.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.320 | L2-Norm(final)=9.640 | 4379.4 samples/s | 68.4 steps/s
[Step=74650 Epoch=287.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.318 | L2-Norm(final)=9.641 | 4177.7 samples/s | 65.3 steps/s
[Step=74700 Epoch=287.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=9.643 | 4167.8 samples/s | 65.1 steps/s
[Step=74750 Epoch=287.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.312 | L2-Norm(final)=9.644 | 5816.7 samples/s | 90.9 steps/s
[Step=74800 Epoch=287.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.309 | L2-Norm(final)=9.646 | 2239.6 samples/s | 35.0 steps/s
[Step=74850 Epoch=288.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.306 | L2-Norm(final)=9.647 | 4224.7 samples/s | 66.0 steps/s
[Step=74900 Epoch=288.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.303 | L2-Norm(final)=9.648 | 4201.5 samples/s | 65.6 steps/s
[Step=74950 Epoch=288.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.299 | L2-Norm(final)=9.650 | 4263.5 samples/s | 66.6 steps/s
[Step=75000 Epoch=288.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=9.651 | 4955.3 samples/s | 77.4 steps/s
[Step=75050 Epoch=288.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=9.652 | 2429.6 samples/s | 38.0 steps/s
[Step=75100 Epoch=289.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.288 | L2-Norm(final)=9.653 | 4173.4 samples/s | 65.2 steps/s
[Step=75150 Epoch=289.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.284 | L2-Norm(final)=9.654 | 4204.2 samples/s | 65.7 steps/s
[Step=75200 Epoch=289.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.280 | L2-Norm(final)=9.655 | 4188.1 samples/s | 65.4 steps/s
[Step=75250 Epoch=289.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.276 | L2-Norm(final)=9.656 | 4354.0 samples/s | 68.0 steps/s
[Step=75300 Epoch=289.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.272 | L2-Norm(final)=9.657 | 2635.2 samples/s | 41.2 steps/s
[Step=75350 Epoch=290.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=9.658 | 4233.2 samples/s | 66.1 steps/s
[Step=75400 Epoch=290.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=9.659 | 4214.5 samples/s | 65.9 steps/s
[Step=75450 Epoch=290.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.259 | L2-Norm(final)=9.660 | 4225.6 samples/s | 66.0 steps/s
[Step=75500 Epoch=290.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.255 | L2-Norm(final)=9.661 | 4174.6 samples/s | 65.2 steps/s
[Step=75550 Epoch=290.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.250 | L2-Norm(final)=9.661 | 2664.5 samples/s | 41.6 steps/s
[Step=75600 Epoch=291.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.245 | L2-Norm(final)=9.662 | 4194.2 samples/s | 65.5 steps/s
[Step=75650 Epoch=291.2] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.241 | L2-Norm(final)=9.663 | 4291.2 samples/s | 67.1 steps/s
[Step=75700 Epoch=291.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.236 | L2-Norm(final)=9.664 | 4156.8 samples/s | 65.0 steps/s
[Step=75750 Epoch=291.6] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.231 | L2-Norm(final)=9.665 | 4233.1 samples/s | 66.1 steps/s
[Step=75800 Epoch=291.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=9.666 | 6990.9 samples/s | 109.2 steps/s
[Step=75850 Epoch=292.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.221 | L2-Norm(final)=9.667 | 2082.4 samples/s | 32.5 steps/s
[Step=75900 Epoch=292.2] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=9.668 | 4291.7 samples/s | 67.1 steps/s
[Step=75950 Epoch=292.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.211 | L2-Norm(final)=9.669 | 4158.2 samples/s | 65.0 steps/s
[Step=76000 Epoch=292.6] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.206 | L2-Norm(final)=9.670 | 4292.3 samples/s | 67.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07175 | acc=0.9668 | tpr=0.9726 | fpr=0.0458 | 5031.4 samples/s | 19.7 steps/s
Avg test loss: 0.07209, Avg test acc: 0.96654, Avg tpr: 0.97173, Avg fpr: 0.04487, total FA: 350

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06604 | acc=0.9676 | tpr=0.9740 | fpr=0.0463 | 5161.1 samples/s | 20.2 steps/s
Avg test loss: 0.06972, Avg test acc: 0.96706, Avg tpr: 0.97406, Avg fpr: 0.04833, total FA: 377

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.13060 | acc=0.3045 | tpr=0.0103 | fpr=0.0565 | 5095.4 samples/s | 19.9 steps/s
Avg test loss: 5.12976, Avg test acc: 0.30131, Avg tpr: 0.01154, Avg fpr: 0.06140, total FA: 479

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.41378 | acc=0.3108 | tpr=0.0161 | fpr=0.0493 | 5084.5 samples/s | 19.9 steps/s
Avg test loss: 5.40566, Avg test acc: 0.30812, Avg tpr: 0.01807, Avg fpr: 0.05397, total FA: 421

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.82499 | acc=0.1488 | tpr=0.4690 | fpr=0.8569 | 4971.9 samples/s | 19.4 steps/s
[Step= 100] | Loss=5.79355 | acc=0.1483 | tpr=0.4435 | fpr=0.8572 | 7038.2 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.79267 | acc=0.1484 | tpr=0.4524 | fpr=0.8572 | 7798.0 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.79065 | acc=0.1492 | tpr=0.4481 | fpr=0.8563 | 7902.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=5.77915 | acc=0.1499 | tpr=0.4559 | fpr=0.8557 | 7640.1 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.77273 | acc=0.1498 | tpr=0.4553 | fpr=0.8557 | 7710.3 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.77732 | acc=0.1496 | tpr=0.4440 | fpr=0.8557 | 7903.8 samples/s | 30.9 steps/s
[Step= 400] | Loss=5.77535 | acc=0.1501 | tpr=0.4398 | fpr=0.8551 | 7942.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.77864 | acc=0.1496 | tpr=0.4362 | fpr=0.8556 | 7698.8 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.78108 | acc=0.1497 | tpr=0.4352 | fpr=0.8554 | 7960.7 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.78318 | acc=0.1499 | tpr=0.4341 | fpr=0.8553 | 14077.4 samples/s | 55.0 steps/s
Avg test loss: 5.78509, Avg test acc: 0.14972, Avg tpr: 0.43542, Avg fpr: 0.85548, total FA: 118781

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.33333 | acc=0.1298 | tpr=0.5487 | fpr=0.8777 | 5016.6 samples/s | 19.6 steps/s
[Step= 100] | Loss=6.32197 | acc=0.1303 | tpr=0.5075 | fpr=0.8767 | 6954.8 samples/s | 27.2 steps/s
[Step= 150] | Loss=6.31903 | acc=0.1310 | tpr=0.5130 | fpr=0.8760 | 7593.7 samples/s | 29.7 steps/s
[Step= 200] | Loss=6.31574 | acc=0.1314 | tpr=0.5082 | fpr=0.8755 | 7921.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.30437 | acc=0.1322 | tpr=0.5083 | fpr=0.8747 | 7752.3 samples/s | 30.3 steps/s
[Step= 300] | Loss=6.29884 | acc=0.1325 | tpr=0.5105 | fpr=0.8744 | 8027.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.30295 | acc=0.1322 | tpr=0.5066 | fpr=0.8746 | 7526.2 samples/s | 29.4 steps/s
[Step= 400] | Loss=6.29909 | acc=0.1322 | tpr=0.5022 | fpr=0.8745 | 7765.8 samples/s | 30.3 steps/s
[Step= 450] | Loss=6.30342 | acc=0.1318 | tpr=0.4995 | fpr=0.8748 | 8046.4 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.30553 | acc=0.1323 | tpr=0.5048 | fpr=0.8745 | 7740.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.30882 | acc=0.1325 | tpr=0.5026 | fpr=0.8742 | 13885.2 samples/s | 54.2 steps/s
Avg test loss: 6.31080, Avg test acc: 0.13240, Avg tpr: 0.50317, Avg fpr: 0.87434, total FA: 121401

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12369 | acc=0.9772 | tpr=0.9602 | fpr=0.0225 | 5083.4 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.12482 | acc=0.9776 | tpr=0.9659 | fpr=0.0222 | 6770.0 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.13039 | acc=0.9766 | tpr=0.9654 | fpr=0.0232 | 8266.8 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.13356 | acc=0.9766 | tpr=0.9650 | fpr=0.0232 | 7698.9 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.13120 | acc=0.9768 | tpr=0.9651 | fpr=0.0230 | 7504.7 samples/s | 29.3 steps/s
[Step= 300] | Loss=0.13295 | acc=0.9764 | tpr=0.9636 | fpr=0.0234 | 8117.9 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.13313 | acc=0.9764 | tpr=0.9631 | fpr=0.0234 | 7880.1 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.13450 | acc=0.9764 | tpr=0.9617 | fpr=0.0234 | 7932.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.13695 | acc=0.9760 | tpr=0.9606 | fpr=0.0237 | 7866.9 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.13613 | acc=0.9761 | tpr=0.9612 | fpr=0.0236 | 7932.9 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.13482 | acc=0.9763 | tpr=0.9614 | fpr=0.0234 | 13087.2 samples/s | 51.1 steps/s
Avg test loss: 0.13464, Avg test acc: 0.97631, Avg tpr: 0.96117, Avg fpr: 0.02341, total FA: 3251

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11719 | acc=0.9776 | tpr=0.9558 | fpr=0.0220 | 5103.3 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.11921 | acc=0.9779 | tpr=0.9680 | fpr=0.0219 | 7004.7 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.12500 | acc=0.9772 | tpr=0.9669 | fpr=0.0226 | 7462.2 samples/s | 29.1 steps/s
[Step= 200] | Loss=0.12779 | acc=0.9769 | tpr=0.9650 | fpr=0.0229 | 7915.0 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.12582 | acc=0.9771 | tpr=0.9642 | fpr=0.0226 | 7882.0 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.12753 | acc=0.9769 | tpr=0.9622 | fpr=0.0229 | 7677.9 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.12787 | acc=0.9767 | tpr=0.9631 | fpr=0.0230 | 8010.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.12909 | acc=0.9767 | tpr=0.9617 | fpr=0.0230 | 7550.5 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.13156 | acc=0.9763 | tpr=0.9596 | fpr=0.0234 | 8225.3 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.13094 | acc=0.9765 | tpr=0.9595 | fpr=0.0232 | 7637.1 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.12956 | acc=0.9768 | tpr=0.9594 | fpr=0.0229 | 14143.5 samples/s | 55.2 steps/s
Avg test loss: 0.12943, Avg test acc: 0.97679, Avg tpr: 0.95919, Avg fpr: 0.02289, total FA: 3178

server round 38/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=148.2] | Loss=0.00468 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.037 | L2-Norm(final)=14.139 | 6273.6 samples/s | 98.0 steps/s
[Step=76050 Epoch=148.3] | Loss=0.00542 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.038 | L2-Norm(final)=14.144 | 4529.6 samples/s | 70.8 steps/s
[Step=76100 Epoch=148.4] | Loss=0.00522 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.038 | L2-Norm(final)=14.150 | 5041.6 samples/s | 78.8 steps/s
[Step=76150 Epoch=148.5] | Loss=0.00537 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.039 | L2-Norm(final)=14.156 | 4947.8 samples/s | 77.3 steps/s
[Step=76200 Epoch=148.6] | Loss=0.00519 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.040 | L2-Norm(final)=14.161 | 5009.2 samples/s | 78.3 steps/s
[Step=76250 Epoch=148.7] | Loss=0.00503 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.040 | L2-Norm(final)=14.167 | 5132.4 samples/s | 80.2 steps/s
[Step=76300 Epoch=148.8] | Loss=0.00516 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.041 | L2-Norm(final)=14.172 | 5019.7 samples/s | 78.4 steps/s
[Step=76350 Epoch=148.9] | Loss=0.00515 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.041 | L2-Norm(final)=14.177 | 4917.5 samples/s | 76.8 steps/s
[Step=76400 Epoch=149.0] | Loss=0.00527 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=14.182 | 5025.2 samples/s | 78.5 steps/s
[Step=76450 Epoch=149.1] | Loss=0.00542 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=14.187 | 5035.4 samples/s | 78.7 steps/s
[Step=76500 Epoch=149.2] | Loss=0.00558 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.043 | L2-Norm(final)=14.192 | 6691.0 samples/s | 104.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=149.2] | Loss=0.00394 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.050 | L2-Norm(final)=14.244 | 6153.7 samples/s | 96.2 steps/s
[Step=76550 Epoch=149.3] | Loss=0.00379 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.051 | L2-Norm(final)=14.250 | 4113.2 samples/s | 64.3 steps/s
[Step=76600 Epoch=149.4] | Loss=0.00561 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.053 | L2-Norm(final)=14.255 | 4464.4 samples/s | 69.8 steps/s
[Step=76650 Epoch=149.5] | Loss=0.00650 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.056 | L2-Norm(final)=14.261 | 4453.1 samples/s | 69.6 steps/s
[Step=76700 Epoch=149.6] | Loss=0.00654 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.058 | L2-Norm(final)=14.265 | 4457.6 samples/s | 69.6 steps/s
[Step=76750 Epoch=149.7] | Loss=0.00632 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=14.270 | 4416.2 samples/s | 69.0 steps/s
[Step=76800 Epoch=149.8] | Loss=0.00664 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.061 | L2-Norm(final)=14.275 | 4447.1 samples/s | 69.5 steps/s
[Step=76850 Epoch=149.9] | Loss=0.00686 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.064 | L2-Norm(final)=14.280 | 4556.4 samples/s | 71.2 steps/s
[Step=76900 Epoch=150.0] | Loss=0.00713 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=14.285 | 4413.0 samples/s | 69.0 steps/s
[Step=76950 Epoch=150.1] | Loss=0.00709 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.068 | L2-Norm(final)=14.290 | 4477.6 samples/s | 70.0 steps/s
[Step=77000 Epoch=150.2] | Loss=0.00738 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.070 | L2-Norm(final)=14.294 | 5783.8 samples/s | 90.4 steps/s
[Step=77050 Epoch=150.3] | Loss=0.00726 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.072 | L2-Norm(final)=14.299 | 2378.5 samples/s | 37.2 steps/s
[Step=77100 Epoch=150.4] | Loss=0.00709 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.074 | L2-Norm(final)=14.304 | 4438.4 samples/s | 69.3 steps/s
[Step=77150 Epoch=150.5] | Loss=0.00703 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=14.308 | 4347.6 samples/s | 67.9 steps/s
[Step=77200 Epoch=150.6] | Loss=0.00699 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=14.313 | 4533.1 samples/s | 70.8 steps/s
[Step=77250 Epoch=150.7] | Loss=0.00686 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.077 | L2-Norm(final)=14.317 | 4395.1 samples/s | 68.7 steps/s
[Step=77300 Epoch=150.8] | Loss=0.00674 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.078 | L2-Norm(final)=14.321 | 4476.2 samples/s | 69.9 steps/s
[Step=77350 Epoch=150.9] | Loss=0.00672 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.079 | L2-Norm(final)=14.326 | 4489.2 samples/s | 70.1 steps/s
[Step=77400 Epoch=151.0] | Loss=0.00672 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.080 | L2-Norm(final)=14.330 | 4474.5 samples/s | 69.9 steps/s
[Step=77450 Epoch=151.1] | Loss=0.00667 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.080 | L2-Norm(final)=14.334 | 4498.2 samples/s | 70.3 steps/s
[Step=77500 Epoch=151.2] | Loss=0.00667 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.081 | L2-Norm(final)=14.338 | 4784.6 samples/s | 74.8 steps/s
[Step=77550 Epoch=151.3] | Loss=0.00678 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.081 | L2-Norm(final)=14.341 | 2588.1 samples/s | 40.4 steps/s
[Step=77600 Epoch=151.4] | Loss=0.00674 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.082 | L2-Norm(final)=14.345 | 4426.4 samples/s | 69.2 steps/s
[Step=77650 Epoch=151.4] | Loss=0.00666 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=14.348 | 4484.1 samples/s | 70.1 steps/s
[Step=77700 Epoch=151.5] | Loss=0.00664 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.082 | L2-Norm(final)=14.352 | 4451.0 samples/s | 69.5 steps/s
[Step=77750 Epoch=151.6] | Loss=0.00657 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=14.355 | 4433.1 samples/s | 69.3 steps/s
[Step=77800 Epoch=151.7] | Loss=0.00649 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.083 | L2-Norm(final)=14.359 | 4446.0 samples/s | 69.5 steps/s
[Step=77850 Epoch=151.8] | Loss=0.00649 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=14.362 | 4513.8 samples/s | 70.5 steps/s
[Step=77900 Epoch=151.9] | Loss=0.00642 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=14.366 | 4430.2 samples/s | 69.2 steps/s
[Step=77950 Epoch=152.0] | Loss=0.00638 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=14.369 | 4426.7 samples/s | 69.2 steps/s
[Step=78000 Epoch=152.1] | Loss=0.00634 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=14.372 | 4443.2 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step78000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=148.6] | Loss=0.00913 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=14.213 | 5508.4 samples/s | 86.1 steps/s
[Step=76050 Epoch=148.7] | Loss=0.00670 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=14.218 | 4712.7 samples/s | 73.6 steps/s
[Step=76100 Epoch=148.8] | Loss=0.00622 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.197 | L2-Norm(final)=14.223 | 5047.8 samples/s | 78.9 steps/s
[Step=76150 Epoch=148.9] | Loss=0.00618 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=14.228 | 4942.0 samples/s | 77.2 steps/s
[Step=76200 Epoch=149.0] | Loss=0.00599 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.198 | L2-Norm(final)=14.234 | 5010.7 samples/s | 78.3 steps/s
[Step=76250 Epoch=149.1] | Loss=0.00594 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.198 | L2-Norm(final)=14.239 | 5058.7 samples/s | 79.0 steps/s
[Step=76300 Epoch=149.2] | Loss=0.00593 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.199 | L2-Norm(final)=14.244 | 5025.1 samples/s | 78.5 steps/s
[Step=76350 Epoch=149.3] | Loss=0.00574 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.200 | L2-Norm(final)=14.250 | 4973.9 samples/s | 77.7 steps/s
[Step=76400 Epoch=149.4] | Loss=0.00557 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.200 | L2-Norm(final)=14.255 | 4990.3 samples/s | 78.0 steps/s
[Step=76450 Epoch=149.5] | Loss=0.00567 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.201 | L2-Norm(final)=14.260 | 5171.7 samples/s | 80.8 steps/s
[Step=76500 Epoch=149.6] | Loss=0.00559 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.201 | L2-Norm(final)=14.265 | 6671.1 samples/s | 104.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=149.6] | Loss=0.00175 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.209 | L2-Norm(final)=14.319 | 6273.8 samples/s | 98.0 steps/s
[Step=76550 Epoch=149.7] | Loss=0.00641 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.212 | L2-Norm(final)=14.324 | 4099.6 samples/s | 64.1 steps/s
[Step=76600 Epoch=149.8] | Loss=0.00597 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.214 | L2-Norm(final)=14.331 | 4430.7 samples/s | 69.2 steps/s
[Step=76650 Epoch=149.8] | Loss=0.00708 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.217 | L2-Norm(final)=14.336 | 4523.9 samples/s | 70.7 steps/s
[Step=76700 Epoch=149.9] | Loss=0.00725 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.219 | L2-Norm(final)=14.341 | 4424.7 samples/s | 69.1 steps/s
[Step=76750 Epoch=150.0] | Loss=0.00745 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.222 | L2-Norm(final)=14.346 | 4400.0 samples/s | 68.8 steps/s
[Step=76800 Epoch=150.1] | Loss=0.00758 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=14.351 | 4417.0 samples/s | 69.0 steps/s
[Step=76850 Epoch=150.2] | Loss=0.00760 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.225 | L2-Norm(final)=14.355 | 4593.1 samples/s | 71.8 steps/s
[Step=76900 Epoch=150.3] | Loss=0.00744 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.227 | L2-Norm(final)=14.360 | 4367.3 samples/s | 68.2 steps/s
[Step=76950 Epoch=150.4] | Loss=0.00748 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.229 | L2-Norm(final)=14.364 | 4509.1 samples/s | 70.5 steps/s
[Step=77000 Epoch=150.5] | Loss=0.00719 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.231 | L2-Norm(final)=14.369 | 5913.5 samples/s | 92.4 steps/s
[Step=77050 Epoch=150.6] | Loss=0.00705 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.233 | L2-Norm(final)=14.374 | 2376.3 samples/s | 37.1 steps/s
[Step=77100 Epoch=150.7] | Loss=0.00702 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=14.378 | 4449.1 samples/s | 69.5 steps/s
[Step=77150 Epoch=150.8] | Loss=0.00686 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.235 | L2-Norm(final)=14.382 | 4397.4 samples/s | 68.7 steps/s
[Step=77200 Epoch=150.9] | Loss=0.00684 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=14.387 | 4428.2 samples/s | 69.2 steps/s
[Step=77250 Epoch=151.0] | Loss=0.00675 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.238 | L2-Norm(final)=14.391 | 4520.0 samples/s | 70.6 steps/s
[Step=77300 Epoch=151.1] | Loss=0.00673 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.239 | L2-Norm(final)=14.395 | 4504.5 samples/s | 70.4 steps/s
[Step=77350 Epoch=151.2] | Loss=0.00666 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.240 | L2-Norm(final)=14.399 | 4390.9 samples/s | 68.6 steps/s
[Step=77400 Epoch=151.3] | Loss=0.00670 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.241 | L2-Norm(final)=14.403 | 4444.6 samples/s | 69.4 steps/s
[Step=77450 Epoch=151.4] | Loss=0.00666 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.242 | L2-Norm(final)=14.407 | 4490.3 samples/s | 70.2 steps/s
[Step=77500 Epoch=151.5] | Loss=0.00663 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.243 | L2-Norm(final)=14.411 | 4995.7 samples/s | 78.1 steps/s
[Step=77550 Epoch=151.6] | Loss=0.00656 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.243 | L2-Norm(final)=14.415 | 2553.3 samples/s | 39.9 steps/s
[Step=77600 Epoch=151.7] | Loss=0.00648 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.244 | L2-Norm(final)=14.418 | 4398.9 samples/s | 68.7 steps/s
[Step=77650 Epoch=151.8] | Loss=0.00642 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=14.422 | 4430.5 samples/s | 69.2 steps/s
[Step=77700 Epoch=151.9] | Loss=0.00638 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=14.426 | 4509.6 samples/s | 70.5 steps/s
[Step=77750 Epoch=152.0] | Loss=0.00632 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=14.430 | 4486.6 samples/s | 70.1 steps/s
[Step=77800 Epoch=152.1] | Loss=0.00633 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.246 | L2-Norm(final)=14.433 | 4391.2 samples/s | 68.6 steps/s
[Step=77850 Epoch=152.2] | Loss=0.00635 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.246 | L2-Norm(final)=14.436 | 4492.1 samples/s | 70.2 steps/s
[Step=77900 Epoch=152.3] | Loss=0.00629 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.246 | L2-Norm(final)=14.440 | 4478.0 samples/s | 70.0 steps/s
[Step=77950 Epoch=152.4] | Loss=0.00623 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.246 | L2-Norm(final)=14.443 | 4377.7 samples/s | 68.4 steps/s
[Step=78000 Epoch=152.5] | Loss=0.00623 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.246 | L2-Norm(final)=14.446 | 4468.3 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step78000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=291.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=8.543 | 6447.8 samples/s | 100.7 steps/s
[Step=76050 Epoch=291.4] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.297 | L2-Norm(final)=8.551 | 4003.6 samples/s | 62.6 steps/s
[Step=76100 Epoch=291.6] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.299 | L2-Norm(final)=8.559 | 4719.2 samples/s | 73.7 steps/s
[Step=76150 Epoch=291.8] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.301 | L2-Norm(final)=8.566 | 4965.7 samples/s | 77.6 steps/s
[Step=76200 Epoch=292.0] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.303 | L2-Norm(final)=8.573 | 4456.4 samples/s | 69.6 steps/s
[Step=76250 Epoch=292.2] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.305 | L2-Norm(final)=8.580 | 6680.4 samples/s | 104.4 steps/s
[Step=76300 Epoch=292.4] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.306 | L2-Norm(final)=8.587 | 2386.1 samples/s | 37.3 steps/s
[Step=76350 Epoch=292.5] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.307 | L2-Norm(final)=8.594 | 4703.7 samples/s | 73.5 steps/s
[Step=76400 Epoch=292.7] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.308 | L2-Norm(final)=8.600 | 4746.9 samples/s | 74.2 steps/s
[Step=76450 Epoch=292.9] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.309 | L2-Norm(final)=8.607 | 4704.0 samples/s | 73.5 steps/s
[Step=76500 Epoch=293.1] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.310 | L2-Norm(final)=8.613 | 5428.7 samples/s | 84.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=293.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.319 | L2-Norm(final)=8.678 | 6216.3 samples/s | 97.1 steps/s
[Step=76550 Epoch=293.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.314 | L2-Norm(final)=8.683 | 3795.8 samples/s | 59.3 steps/s
[Step=76600 Epoch=293.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.307 | L2-Norm(final)=8.688 | 4206.9 samples/s | 65.7 steps/s
[Step=76650 Epoch=293.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=8.693 | 4215.2 samples/s | 65.9 steps/s
[Step=76700 Epoch=293.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.289 | L2-Norm(final)=8.697 | 4097.4 samples/s | 64.0 steps/s
[Step=76750 Epoch=294.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.280 | L2-Norm(final)=8.701 | 5694.8 samples/s | 89.0 steps/s
[Step=76800 Epoch=294.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.270 | L2-Norm(final)=8.704 | 2293.6 samples/s | 35.8 steps/s
[Step=76850 Epoch=294.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=8.707 | 4138.9 samples/s | 64.7 steps/s
[Step=76900 Epoch=294.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.249 | L2-Norm(final)=8.710 | 4267.0 samples/s | 66.7 steps/s
[Step=76950 Epoch=294.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.238 | L2-Norm(final)=8.712 | 4222.3 samples/s | 66.0 steps/s
[Step=77000 Epoch=295.0] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=8.715 | 4738.1 samples/s | 74.0 steps/s
[Step=77050 Epoch=295.2] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=8.717 | 2417.9 samples/s | 37.8 steps/s
[Step=77100 Epoch=295.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.204 | L2-Norm(final)=8.719 | 4228.4 samples/s | 66.1 steps/s
[Step=77150 Epoch=295.6] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.193 | L2-Norm(final)=8.722 | 4322.9 samples/s | 67.5 steps/s
[Step=77200 Epoch=295.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.181 | L2-Norm(final)=8.724 | 4153.6 samples/s | 64.9 steps/s
[Step=77250 Epoch=296.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=8.726 | 4294.9 samples/s | 67.1 steps/s
[Step=77300 Epoch=296.2] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=8.728 | 2665.7 samples/s | 41.7 steps/s
[Step=77350 Epoch=296.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.144 | L2-Norm(final)=8.730 | 4099.4 samples/s | 64.1 steps/s
[Step=77400 Epoch=296.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.132 | L2-Norm(final)=8.732 | 4177.9 samples/s | 65.3 steps/s
[Step=77450 Epoch=296.8] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.119 | L2-Norm(final)=8.734 | 4236.4 samples/s | 66.2 steps/s
[Step=77500 Epoch=297.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.107 | L2-Norm(final)=8.737 | 4317.8 samples/s | 67.5 steps/s
[Step=77550 Epoch=297.1] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.094 | L2-Norm(final)=8.739 | 2593.1 samples/s | 40.5 steps/s
[Step=77600 Epoch=297.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=8.741 | 4319.1 samples/s | 67.5 steps/s
[Step=77650 Epoch=297.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.068 | L2-Norm(final)=8.744 | 4145.2 samples/s | 64.8 steps/s
[Step=77700 Epoch=297.7] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.055 | L2-Norm(final)=8.746 | 4216.6 samples/s | 65.9 steps/s
[Step=77750 Epoch=297.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.042 | L2-Norm(final)=8.748 | 4264.2 samples/s | 66.6 steps/s
[Step=77800 Epoch=298.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.029 | L2-Norm(final)=8.751 | 6014.7 samples/s | 94.0 steps/s
[Step=77850 Epoch=298.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.015 | L2-Norm(final)=8.753 | 2173.9 samples/s | 34.0 steps/s
[Step=77900 Epoch=298.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.002 | L2-Norm(final)=8.756 | 4211.9 samples/s | 65.8 steps/s
[Step=77950 Epoch=298.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.988 | L2-Norm(final)=8.759 | 4260.1 samples/s | 66.6 steps/s
[Step=78000 Epoch=298.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.975 | L2-Norm(final)=8.762 | 4218.0 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step78000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=292.6] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=9.700 | 7034.4 samples/s | 109.9 steps/s
[Step=76050 Epoch=292.7] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=9.704 | 3958.0 samples/s | 61.8 steps/s
[Step=76100 Epoch=292.9] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.228 | L2-Norm(final)=9.711 | 4728.1 samples/s | 73.9 steps/s
[Step=76150 Epoch=293.1] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.230 | L2-Norm(final)=9.717 | 4604.9 samples/s | 72.0 steps/s
[Step=76200 Epoch=293.3] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.231 | L2-Norm(final)=9.723 | 4800.3 samples/s | 75.0 steps/s
[Step=76250 Epoch=293.5] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.233 | L2-Norm(final)=9.730 | 6687.4 samples/s | 104.5 steps/s
[Step=76300 Epoch=293.7] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.235 | L2-Norm(final)=9.736 | 2392.1 samples/s | 37.4 steps/s
[Step=76350 Epoch=293.9] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.236 | L2-Norm(final)=9.741 | 4705.4 samples/s | 73.5 steps/s
[Step=76400 Epoch=294.1] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.237 | L2-Norm(final)=9.747 | 4810.7 samples/s | 75.2 steps/s
[Step=76450 Epoch=294.3] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.238 | L2-Norm(final)=9.753 | 4691.8 samples/s | 73.3 steps/s
[Step=76500 Epoch=294.5] | Loss=0.00002 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.240 | L2-Norm(final)=9.758 | 5514.2 samples/s | 86.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=294.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.250 | L2-Norm(final)=9.813 | 6058.6 samples/s | 94.7 steps/s
[Step=76550 Epoch=294.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.246 | L2-Norm(final)=9.817 | 3785.8 samples/s | 59.2 steps/s
[Step=76600 Epoch=294.9] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.240 | L2-Norm(final)=9.821 | 4280.6 samples/s | 66.9 steps/s
[Step=76650 Epoch=295.1] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.233 | L2-Norm(final)=9.824 | 4241.0 samples/s | 66.3 steps/s
[Step=76700 Epoch=295.2] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.225 | L2-Norm(final)=9.827 | 4187.9 samples/s | 65.4 steps/s
[Step=76750 Epoch=295.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=9.830 | 5722.6 samples/s | 89.4 steps/s
[Step=76800 Epoch=295.6] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.207 | L2-Norm(final)=9.832 | 2250.9 samples/s | 35.2 steps/s
[Step=76850 Epoch=295.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.198 | L2-Norm(final)=9.835 | 4122.7 samples/s | 64.4 steps/s
[Step=76900 Epoch=296.0] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.189 | L2-Norm(final)=9.837 | 4245.1 samples/s | 66.3 steps/s
[Step=76950 Epoch=296.2] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.180 | L2-Norm(final)=9.838 | 4221.3 samples/s | 66.0 steps/s
[Step=77000 Epoch=296.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.840 | 4994.9 samples/s | 78.0 steps/s
[Step=77050 Epoch=296.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.160 | L2-Norm(final)=9.842 | 2418.1 samples/s | 37.8 steps/s
[Step=77100 Epoch=296.8] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.150 | L2-Norm(final)=9.844 | 4310.4 samples/s | 67.4 steps/s
[Step=77150 Epoch=297.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.140 | L2-Norm(final)=9.846 | 4199.3 samples/s | 65.6 steps/s
[Step=77200 Epoch=297.2] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.130 | L2-Norm(final)=9.847 | 4130.8 samples/s | 64.5 steps/s
[Step=77250 Epoch=297.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=9.849 | 4277.5 samples/s | 66.8 steps/s
[Step=77300 Epoch=297.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.109 | L2-Norm(final)=9.851 | 2599.7 samples/s | 40.6 steps/s
[Step=77350 Epoch=297.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=9.853 | 4266.6 samples/s | 66.7 steps/s
[Step=77400 Epoch=297.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=9.855 | 4257.7 samples/s | 66.5 steps/s
[Step=77450 Epoch=298.1] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=9.857 | 4165.8 samples/s | 65.1 steps/s
[Step=77500 Epoch=298.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.066 | L2-Norm(final)=9.858 | 4200.9 samples/s | 65.6 steps/s
[Step=77550 Epoch=298.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.056 | L2-Norm(final)=9.860 | 2669.6 samples/s | 41.7 steps/s
[Step=77600 Epoch=298.7] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=9.862 | 4149.2 samples/s | 64.8 steps/s
[Step=77650 Epoch=298.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=9.864 | 4188.8 samples/s | 65.4 steps/s
[Step=77700 Epoch=299.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.022 | L2-Norm(final)=9.866 | 4225.1 samples/s | 66.0 steps/s
[Step=77750 Epoch=299.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.011 | L2-Norm(final)=9.868 | 4266.8 samples/s | 66.7 steps/s
[Step=77800 Epoch=299.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.999 | L2-Norm(final)=9.870 | 6828.5 samples/s | 106.7 steps/s
[Step=77850 Epoch=299.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.988 | L2-Norm(final)=9.873 | 2116.6 samples/s | 33.1 steps/s
[Step=77900 Epoch=299.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.976 | L2-Norm(final)=9.875 | 4187.7 samples/s | 65.4 steps/s
[Step=77950 Epoch=300.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.965 | L2-Norm(final)=9.877 | 4207.4 samples/s | 65.7 steps/s
[Step=78000 Epoch=300.3] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.879 | 4261.5 samples/s | 66.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07184 | acc=0.9675 | tpr=0.9727 | fpr=0.0439 | 4822.7 samples/s | 18.8 steps/s
Avg test loss: 0.07363, Avg test acc: 0.96638, Avg tpr: 0.97185, Avg fpr: 0.04564, total FA: 356

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06949 | acc=0.9685 | tpr=0.9780 | fpr=0.0520 | 4887.8 samples/s | 19.1 steps/s
Avg test loss: 0.07276, Avg test acc: 0.96755, Avg tpr: 0.97756, Avg fpr: 0.05448, total FA: 425

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.33755 | acc=0.3087 | tpr=0.0062 | fpr=0.0344 | 4799.2 samples/s | 18.7 steps/s
Avg test loss: 5.33783, Avg test acc: 0.30475, Avg tpr: 0.00688, Avg fpr: 0.04012, total FA: 313

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.60180 | acc=0.3104 | tpr=0.0108 | fpr=0.0391 | 5069.1 samples/s | 19.8 steps/s
Avg test loss: 5.59036, Avg test acc: 0.30780, Avg tpr: 0.01276, Avg fpr: 0.04333, total FA: 338

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.63036 | acc=0.1580 | tpr=0.4690 | fpr=0.8475 | 4930.3 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.60691 | acc=0.1575 | tpr=0.4286 | fpr=0.8476 | 7062.0 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.60567 | acc=0.1586 | tpr=0.4337 | fpr=0.8465 | 8130.6 samples/s | 31.8 steps/s
[Step= 200] | Loss=5.60403 | acc=0.1593 | tpr=0.4361 | fpr=0.8457 | 7524.2 samples/s | 29.4 steps/s
[Step= 250] | Loss=5.59294 | acc=0.1598 | tpr=0.4393 | fpr=0.8452 | 7967.7 samples/s | 31.1 steps/s
[Step= 300] | Loss=5.58523 | acc=0.1599 | tpr=0.4385 | fpr=0.8452 | 7875.7 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.58935 | acc=0.1596 | tpr=0.4264 | fpr=0.8453 | 7739.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.58818 | acc=0.1598 | tpr=0.4245 | fpr=0.8451 | 7725.0 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.59161 | acc=0.1595 | tpr=0.4241 | fpr=0.8453 | 8160.3 samples/s | 31.9 steps/s
[Step= 500] | Loss=5.59469 | acc=0.1595 | tpr=0.4238 | fpr=0.8453 | 7646.6 samples/s | 29.9 steps/s
[Step= 550] | Loss=5.59669 | acc=0.1597 | tpr=0.4202 | fpr=0.8451 | 14101.5 samples/s | 55.1 steps/s
Avg test loss: 5.59848, Avg test acc: 0.15954, Avg tpr: 0.42155, Avg fpr: 0.84522, total FA: 117357

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.74958 | acc=0.1275 | tpr=0.5664 | fpr=0.8804 | 4902.0 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.73301 | acc=0.1282 | tpr=0.5309 | fpr=0.8794 | 7202.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.73094 | acc=0.1289 | tpr=0.5346 | fpr=0.8786 | 7381.2 samples/s | 28.8 steps/s
[Step= 200] | Loss=6.72777 | acc=0.1286 | tpr=0.5235 | fpr=0.8786 | 8031.4 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.71783 | acc=0.1291 | tpr=0.5249 | fpr=0.8781 | 7621.2 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.71242 | acc=0.1290 | tpr=0.5258 | fpr=0.8783 | 7519.2 samples/s | 29.4 steps/s
[Step= 350] | Loss=6.71700 | acc=0.1284 | tpr=0.5197 | fpr=0.8787 | 7889.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.71332 | acc=0.1285 | tpr=0.5142 | fpr=0.8785 | 7701.0 samples/s | 30.1 steps/s
[Step= 450] | Loss=6.71714 | acc=0.1280 | tpr=0.5117 | fpr=0.8789 | 7678.7 samples/s | 30.0 steps/s
[Step= 500] | Loss=6.71899 | acc=0.1286 | tpr=0.5172 | fpr=0.8784 | 7963.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.72245 | acc=0.1285 | tpr=0.5149 | fpr=0.8785 | 13912.4 samples/s | 54.3 steps/s
Avg test loss: 6.72460, Avg test acc: 0.12834, Avg tpr: 0.51545, Avg fpr: 0.87870, total FA: 122006

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11236 | acc=0.9787 | tpr=0.9469 | fpr=0.0208 | 4944.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11424 | acc=0.9793 | tpr=0.9552 | fpr=0.0203 | 7195.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.11934 | acc=0.9783 | tpr=0.9553 | fpr=0.0212 | 7498.7 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.12256 | acc=0.9783 | tpr=0.9563 | fpr=0.0213 | 7627.6 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.12042 | acc=0.9786 | tpr=0.9572 | fpr=0.0210 | 8439.0 samples/s | 33.0 steps/s
[Step= 300] | Loss=0.12213 | acc=0.9781 | tpr=0.9549 | fpr=0.0214 | 7818.4 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.12229 | acc=0.9781 | tpr=0.9555 | fpr=0.0214 | 7735.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.12371 | acc=0.9781 | tpr=0.9551 | fpr=0.0215 | 7935.8 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.12599 | acc=0.9777 | tpr=0.9533 | fpr=0.0218 | 7754.5 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12525 | acc=0.9778 | tpr=0.9542 | fpr=0.0218 | 7826.6 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12409 | acc=0.9780 | tpr=0.9550 | fpr=0.0215 | 14128.7 samples/s | 55.2 steps/s
Avg test loss: 0.12390, Avg test acc: 0.97806, Avg tpr: 0.95483, Avg fpr: 0.02152, total FA: 2988

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11050 | acc=0.9788 | tpr=0.9469 | fpr=0.0206 | 4870.8 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.11308 | acc=0.9790 | tpr=0.9595 | fpr=0.0206 | 7341.7 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.11838 | acc=0.9785 | tpr=0.9625 | fpr=0.0212 | 7661.7 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.12121 | acc=0.9782 | tpr=0.9617 | fpr=0.0215 | 8044.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.11926 | acc=0.9785 | tpr=0.9616 | fpr=0.0212 | 7765.6 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.12105 | acc=0.9782 | tpr=0.9593 | fpr=0.0214 | 7920.2 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.12139 | acc=0.9780 | tpr=0.9612 | fpr=0.0217 | 7787.8 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.12270 | acc=0.9779 | tpr=0.9590 | fpr=0.0218 | 7858.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.12501 | acc=0.9775 | tpr=0.9557 | fpr=0.0221 | 7981.3 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.12450 | acc=0.9777 | tpr=0.9559 | fpr=0.0220 | 7796.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.12324 | acc=0.9779 | tpr=0.9562 | fpr=0.0218 | 13865.6 samples/s | 54.2 steps/s
Avg test loss: 0.12312, Avg test acc: 0.97785, Avg tpr: 0.95602, Avg fpr: 0.02175, total FA: 3020

server round 39/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=152.1] | Loss=0.00440 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=14.472 | 6602.1 samples/s | 103.2 steps/s
[Step=78050 Epoch=152.2] | Loss=0.00780 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=14.477 | 4383.2 samples/s | 68.5 steps/s
[Step=78100 Epoch=152.3] | Loss=0.00793 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.908 | L2-Norm(final)=14.484 | 5057.3 samples/s | 79.0 steps/s
[Step=78150 Epoch=152.4] | Loss=0.00819 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=14.491 | 5044.2 samples/s | 78.8 steps/s
[Step=78200 Epoch=152.5] | Loss=0.00779 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.915 | L2-Norm(final)=14.498 | 5061.6 samples/s | 79.1 steps/s
[Step=78250 Epoch=152.6] | Loss=0.00760 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=14.504 | 4929.9 samples/s | 77.0 steps/s
[Step=78300 Epoch=152.7] | Loss=0.00752 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.919 | L2-Norm(final)=14.511 | 5030.2 samples/s | 78.6 steps/s
[Step=78350 Epoch=152.8] | Loss=0.00743 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.922 | L2-Norm(final)=14.518 | 5064.2 samples/s | 79.1 steps/s
[Step=78400 Epoch=152.9] | Loss=0.00728 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.924 | L2-Norm(final)=14.524 | 5055.9 samples/s | 79.0 steps/s
[Step=78450 Epoch=153.0] | Loss=0.00722 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.926 | L2-Norm(final)=14.531 | 5066.6 samples/s | 79.2 steps/s
[Step=78500 Epoch=153.1] | Loss=0.00737 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.928 | L2-Norm(final)=14.537 | 6544.4 samples/s | 102.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=153.1] | Loss=0.00586 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=14.600 | 5968.8 samples/s | 93.3 steps/s
[Step=78550 Epoch=153.2] | Loss=0.00642 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=14.606 | 4234.5 samples/s | 66.2 steps/s
[Step=78600 Epoch=153.3] | Loss=0.00787 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.954 | L2-Norm(final)=14.611 | 4463.2 samples/s | 69.7 steps/s
[Step=78650 Epoch=153.4] | Loss=0.00793 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.958 | L2-Norm(final)=14.617 | 4456.9 samples/s | 69.6 steps/s
[Step=78700 Epoch=153.5] | Loss=0.00786 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=14.622 | 4513.6 samples/s | 70.5 steps/s
[Step=78750 Epoch=153.6] | Loss=0.00811 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=14.627 | 4476.1 samples/s | 69.9 steps/s
[Step=78800 Epoch=153.7] | Loss=0.00870 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=14.632 | 4404.0 samples/s | 68.8 steps/s
[Step=78850 Epoch=153.8] | Loss=0.00885 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.970 | L2-Norm(final)=14.637 | 4365.1 samples/s | 68.2 steps/s
[Step=78900 Epoch=153.9] | Loss=0.00893 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.972 | L2-Norm(final)=14.642 | 4531.8 samples/s | 70.8 steps/s
[Step=78950 Epoch=154.0] | Loss=0.00879 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=14.647 | 4394.2 samples/s | 68.7 steps/s
[Step=79000 Epoch=154.1] | Loss=0.00878 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=14.652 | 5747.6 samples/s | 89.8 steps/s
[Step=79050 Epoch=154.2] | Loss=0.00860 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.980 | L2-Norm(final)=14.657 | 2399.8 samples/s | 37.5 steps/s
[Step=79100 Epoch=154.3] | Loss=0.00848 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.982 | L2-Norm(final)=14.661 | 4422.2 samples/s | 69.1 steps/s
[Step=79150 Epoch=154.4] | Loss=0.00827 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=14.666 | 4452.7 samples/s | 69.6 steps/s
[Step=79200 Epoch=154.5] | Loss=0.00817 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.986 | L2-Norm(final)=14.670 | 4502.4 samples/s | 70.4 steps/s
[Step=79250 Epoch=154.6] | Loss=0.00809 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.988 | L2-Norm(final)=14.675 | 4383.2 samples/s | 68.5 steps/s
[Step=79300 Epoch=154.7] | Loss=0.00801 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=14.679 | 4451.1 samples/s | 69.5 steps/s
[Step=79350 Epoch=154.8] | Loss=0.00786 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=14.683 | 4442.3 samples/s | 69.4 steps/s
[Step=79400 Epoch=154.9] | Loss=0.00773 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=14.687 | 4512.3 samples/s | 70.5 steps/s
[Step=79450 Epoch=155.0] | Loss=0.00761 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=14.691 | 4462.5 samples/s | 69.7 steps/s
[Step=79500 Epoch=155.1] | Loss=0.00752 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=14.695 | 4846.0 samples/s | 75.7 steps/s
[Step=79550 Epoch=155.2] | Loss=0.00754 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=14.699 | 2619.1 samples/s | 40.9 steps/s
[Step=79600 Epoch=155.3] | Loss=0.00752 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=14.702 | 4442.7 samples/s | 69.4 steps/s
[Step=79650 Epoch=155.3] | Loss=0.00748 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.997 | L2-Norm(final)=14.706 | 4437.2 samples/s | 69.3 steps/s
[Step=79700 Epoch=155.4] | Loss=0.00738 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=14.710 | 4473.8 samples/s | 69.9 steps/s
[Step=79750 Epoch=155.5] | Loss=0.00728 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=14.713 | 4468.2 samples/s | 69.8 steps/s
[Step=79800 Epoch=155.6] | Loss=0.00723 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=14.717 | 4374.1 samples/s | 68.3 steps/s
[Step=79850 Epoch=155.7] | Loss=0.00714 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.999 | L2-Norm(final)=14.720 | 4599.0 samples/s | 71.9 steps/s
[Step=79900 Epoch=155.8] | Loss=0.00713 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.000 | L2-Norm(final)=14.724 | 4378.6 samples/s | 68.4 steps/s
[Step=79950 Epoch=155.9] | Loss=0.00704 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.000 | L2-Norm(final)=14.727 | 4448.8 samples/s | 69.5 steps/s
[Step=80000 Epoch=156.0] | Loss=0.00703 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.001 | L2-Norm(final)=14.730 | 4469.3 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step80000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=152.5] | Loss=0.02294 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.066 | L2-Norm(final)=14.547 | 6583.1 samples/s | 102.9 steps/s
[Step=78050 Epoch=152.6] | Loss=0.00895 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=14.550 | 4292.7 samples/s | 67.1 steps/s
[Step=78100 Epoch=152.7] | Loss=0.00890 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.073 | L2-Norm(final)=14.556 | 5007.9 samples/s | 78.2 steps/s
[Step=78150 Epoch=152.8] | Loss=0.00867 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=14.563 | 5181.2 samples/s | 81.0 steps/s
[Step=78200 Epoch=152.9] | Loss=0.00820 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.079 | L2-Norm(final)=14.571 | 4872.7 samples/s | 76.1 steps/s
[Step=78250 Epoch=153.0] | Loss=0.00767 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=14.577 | 4994.3 samples/s | 78.0 steps/s
[Step=78300 Epoch=153.1] | Loss=0.00776 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=14.584 | 5111.0 samples/s | 79.9 steps/s
[Step=78350 Epoch=153.2] | Loss=0.00787 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.086 | L2-Norm(final)=14.591 | 5071.0 samples/s | 79.2 steps/s
[Step=78400 Epoch=153.3] | Loss=0.00768 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=14.597 | 4973.2 samples/s | 77.7 steps/s
[Step=78450 Epoch=153.4] | Loss=0.00773 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=14.604 | 5053.0 samples/s | 79.0 steps/s
[Step=78500 Epoch=153.5] | Loss=0.00757 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.093 | L2-Norm(final)=14.611 | 6647.3 samples/s | 103.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=153.5] | Loss=0.00163 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=14.676 | 5862.1 samples/s | 91.6 steps/s
[Step=78550 Epoch=153.6] | Loss=0.00766 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=14.682 | 4257.3 samples/s | 66.5 steps/s
[Step=78600 Epoch=153.7] | Loss=0.00917 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=14.688 | 4507.5 samples/s | 70.4 steps/s
[Step=78650 Epoch=153.8] | Loss=0.00954 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=14.694 | 4461.9 samples/s | 69.7 steps/s
[Step=78700 Epoch=153.9] | Loss=0.00955 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=14.699 | 4552.1 samples/s | 71.1 steps/s
[Step=78750 Epoch=154.0] | Loss=0.00935 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=14.705 | 4398.3 samples/s | 68.7 steps/s
[Step=78800 Epoch=154.1] | Loss=0.00933 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=14.710 | 4448.0 samples/s | 69.5 steps/s
[Step=78850 Epoch=154.1] | Loss=0.00906 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=14.716 | 4414.3 samples/s | 69.0 steps/s
[Step=78900 Epoch=154.2] | Loss=0.00872 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=14.721 | 4484.3 samples/s | 70.1 steps/s
[Step=78950 Epoch=154.3] | Loss=0.00856 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.147 | L2-Norm(final)=14.726 | 4610.6 samples/s | 72.0 steps/s
[Step=79000 Epoch=154.4] | Loss=0.00864 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.150 | L2-Norm(final)=14.731 | 5688.9 samples/s | 88.9 steps/s
[Step=79050 Epoch=154.5] | Loss=0.00840 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=14.736 | 2410.9 samples/s | 37.7 steps/s
[Step=79100 Epoch=154.6] | Loss=0.00829 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.154 | L2-Norm(final)=14.741 | 4394.4 samples/s | 68.7 steps/s
[Step=79150 Epoch=154.7] | Loss=0.00814 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.156 | L2-Norm(final)=14.745 | 4488.2 samples/s | 70.1 steps/s
[Step=79200 Epoch=154.8] | Loss=0.00796 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.158 | L2-Norm(final)=14.750 | 4527.5 samples/s | 70.7 steps/s
[Step=79250 Epoch=154.9] | Loss=0.00796 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.160 | L2-Norm(final)=14.754 | 4406.8 samples/s | 68.9 steps/s
[Step=79300 Epoch=155.0] | Loss=0.00788 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.161 | L2-Norm(final)=14.758 | 4488.5 samples/s | 70.1 steps/s
[Step=79350 Epoch=155.1] | Loss=0.00776 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.163 | L2-Norm(final)=14.762 | 4461.6 samples/s | 69.7 steps/s
[Step=79400 Epoch=155.2] | Loss=0.00767 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.164 | L2-Norm(final)=14.766 | 4525.1 samples/s | 70.7 steps/s
[Step=79450 Epoch=155.3] | Loss=0.00759 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.165 | L2-Norm(final)=14.770 | 4460.9 samples/s | 69.7 steps/s
[Step=79500 Epoch=155.4] | Loss=0.00751 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=14.774 | 4959.6 samples/s | 77.5 steps/s
[Step=79550 Epoch=155.5] | Loss=0.00746 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.168 | L2-Norm(final)=14.778 | 2582.2 samples/s | 40.3 steps/s
[Step=79600 Epoch=155.6] | Loss=0.00742 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=14.781 | 4512.5 samples/s | 70.5 steps/s
[Step=79650 Epoch=155.7] | Loss=0.00733 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=14.785 | 4445.7 samples/s | 69.5 steps/s
[Step=79700 Epoch=155.8] | Loss=0.00723 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=14.789 | 4422.8 samples/s | 69.1 steps/s
[Step=79750 Epoch=155.9] | Loss=0.00714 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=14.793 | 4445.9 samples/s | 69.5 steps/s
[Step=79800 Epoch=156.0] | Loss=0.00707 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=14.796 | 4696.7 samples/s | 73.4 steps/s
[Step=79850 Epoch=156.1] | Loss=0.00706 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.173 | L2-Norm(final)=14.800 | 4310.7 samples/s | 67.4 steps/s
[Step=79900 Epoch=156.2] | Loss=0.00697 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=14.803 | 4518.3 samples/s | 70.6 steps/s
[Step=79950 Epoch=156.3] | Loss=0.00690 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.174 | L2-Norm(final)=14.807 | 4456.5 samples/s | 69.6 steps/s
[Step=80000 Epoch=156.4] | Loss=0.00687 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.174 | L2-Norm(final)=14.810 | 4434.4 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step80000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=298.9] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.976 | L2-Norm(final)=8.844 | 6776.2 samples/s | 105.9 steps/s
[Step=78050 Epoch=299.1] | Loss=0.00014 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.982 | L2-Norm(final)=8.865 | 3969.5 samples/s | 62.0 steps/s
[Step=78100 Epoch=299.3] | Loss=0.00010 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.992 | L2-Norm(final)=8.880 | 4769.0 samples/s | 74.5 steps/s
[Step=78150 Epoch=299.4] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.996 | L2-Norm(final)=8.889 | 4801.9 samples/s | 75.0 steps/s
[Step=78200 Epoch=299.6] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.999 | L2-Norm(final)=8.896 | 4743.6 samples/s | 74.1 steps/s
[Step=78250 Epoch=299.8] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=8.901 | 6535.1 samples/s | 102.1 steps/s
[Step=78300 Epoch=300.0] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.002 | L2-Norm(final)=8.906 | 2441.3 samples/s | 38.1 steps/s
[Step=78350 Epoch=300.2] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.003 | L2-Norm(final)=8.911 | 4615.3 samples/s | 72.1 steps/s
[Step=78400 Epoch=300.4] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.005 | L2-Norm(final)=8.915 | 4719.0 samples/s | 73.7 steps/s
[Step=78450 Epoch=300.6] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.006 | L2-Norm(final)=8.920 | 4794.5 samples/s | 74.9 steps/s
[Step=78500 Epoch=300.8] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.007 | L2-Norm(final)=8.924 | 5418.1 samples/s | 84.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=300.8] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.016 | L2-Norm(final)=8.966 | 6089.3 samples/s | 95.1 steps/s
[Step=78550 Epoch=301.0] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.006 | L2-Norm(final)=8.969 | 3795.2 samples/s | 59.3 steps/s
[Step=78600 Epoch=301.2] | Loss=0.00133 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=8.971 | 4223.4 samples/s | 66.0 steps/s
[Step=78650 Epoch=301.4] | Loss=0.00113 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.023 | L2-Norm(final)=8.972 | 4302.1 samples/s | 67.2 steps/s
[Step=78700 Epoch=301.6] | Loss=0.00087 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=8.973 | 4171.3 samples/s | 65.2 steps/s
[Step=78750 Epoch=301.7] | Loss=0.00070 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.036 | L2-Norm(final)=8.974 | 5652.3 samples/s | 88.3 steps/s
[Step=78800 Epoch=301.9] | Loss=0.00059 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.039 | L2-Norm(final)=8.975 | 2256.4 samples/s | 35.3 steps/s
[Step=78850 Epoch=302.1] | Loss=0.00051 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.041 | L2-Norm(final)=8.976 | 4239.3 samples/s | 66.2 steps/s
[Step=78900 Epoch=302.3] | Loss=0.00045 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=8.976 | 4257.1 samples/s | 66.5 steps/s
[Step=78950 Epoch=302.5] | Loss=0.00040 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=8.977 | 4219.4 samples/s | 65.9 steps/s
[Step=79000 Epoch=302.7] | Loss=0.00036 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=8.978 | 4770.0 samples/s | 74.5 steps/s
[Step=79050 Epoch=302.9] | Loss=0.00033 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.978 | 2452.9 samples/s | 38.3 steps/s
[Step=79100 Epoch=303.1] | Loss=0.00030 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.979 | 4201.2 samples/s | 65.6 steps/s
[Step=79150 Epoch=303.3] | Loss=0.00028 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.979 | 4259.5 samples/s | 66.6 steps/s
[Step=79200 Epoch=303.5] | Loss=0.00026 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.980 | 4265.4 samples/s | 66.6 steps/s
[Step=79250 Epoch=303.7] | Loss=0.00025 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.981 | 4281.1 samples/s | 66.9 steps/s
[Step=79300 Epoch=303.8] | Loss=0.00023 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.981 | 2647.9 samples/s | 41.4 steps/s
[Step=79350 Epoch=304.0] | Loss=0.00022 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.982 | 4267.7 samples/s | 66.7 steps/s
[Step=79400 Epoch=304.2] | Loss=0.00021 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.982 | 4190.4 samples/s | 65.5 steps/s
[Step=79450 Epoch=304.4] | Loss=0.00020 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=8.983 | 4208.4 samples/s | 65.8 steps/s
[Step=79500 Epoch=304.6] | Loss=0.00019 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.983 | 4259.3 samples/s | 66.6 steps/s
[Step=79550 Epoch=304.8] | Loss=0.00018 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.984 | 2662.6 samples/s | 41.6 steps/s
[Step=79600 Epoch=305.0] | Loss=0.00017 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.984 | 4149.3 samples/s | 64.8 steps/s
[Step=79650 Epoch=305.2] | Loss=0.00016 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=8.984 | 4368.8 samples/s | 68.3 steps/s
[Step=79700 Epoch=305.4] | Loss=0.00016 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=8.985 | 4108.2 samples/s | 64.2 steps/s
[Step=79750 Epoch=305.6] | Loss=0.00015 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=8.985 | 4243.7 samples/s | 66.3 steps/s
[Step=79800 Epoch=305.8] | Loss=0.00015 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=8.986 | 6283.3 samples/s | 98.2 steps/s
[Step=79850 Epoch=306.0] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=8.986 | 2201.8 samples/s | 34.4 steps/s
[Step=79900 Epoch=306.1] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=8.987 | 4188.9 samples/s | 65.5 steps/s
[Step=79950 Epoch=306.3] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=8.987 | 4204.7 samples/s | 65.7 steps/s
[Step=80000 Epoch=306.5] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=8.988 | 4233.8 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step80000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=300.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.950 | 6184.4 samples/s | 96.6 steps/s
[Step=78050 Epoch=300.4] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.934 | L2-Norm(final)=9.966 | 4085.4 samples/s | 63.8 steps/s
[Step=78100 Epoch=300.6] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.941 | L2-Norm(final)=9.985 | 4736.7 samples/s | 74.0 steps/s
[Step=78150 Epoch=300.8] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=10.000 | 4698.3 samples/s | 73.4 steps/s
[Step=78200 Epoch=301.0] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=10.012 | 4852.6 samples/s | 75.8 steps/s
[Step=78250 Epoch=301.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=10.023 | 6582.4 samples/s | 102.9 steps/s
[Step=78300 Epoch=301.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.955 | L2-Norm(final)=10.032 | 2488.2 samples/s | 38.9 steps/s
[Step=78350 Epoch=301.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.957 | L2-Norm(final)=10.040 | 4428.5 samples/s | 69.2 steps/s
[Step=78400 Epoch=301.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.958 | L2-Norm(final)=10.048 | 4785.3 samples/s | 74.8 steps/s
[Step=78450 Epoch=302.0] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.960 | L2-Norm(final)=10.056 | 4844.1 samples/s | 75.7 steps/s
[Step=78500 Epoch=302.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.961 | L2-Norm(final)=10.063 | 5544.0 samples/s | 86.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=302.2] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.972 | L2-Norm(final)=10.139 | 6241.7 samples/s | 97.5 steps/s
[Step=78550 Epoch=302.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.963 | L2-Norm(final)=10.145 | 3775.1 samples/s | 59.0 steps/s
[Step=78600 Epoch=302.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=10.149 | 4288.2 samples/s | 67.0 steps/s
[Step=78650 Epoch=302.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=10.153 | 4209.0 samples/s | 65.8 steps/s
[Step=78700 Epoch=302.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=10.157 | 4289.9 samples/s | 67.0 steps/s
[Step=78750 Epoch=303.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.890 | L2-Norm(final)=10.160 | 5701.2 samples/s | 89.1 steps/s
[Step=78800 Epoch=303.3] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.870 | L2-Norm(final)=10.163 | 2254.3 samples/s | 35.2 steps/s
[Step=78850 Epoch=303.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.851 | L2-Norm(final)=10.166 | 4301.4 samples/s | 67.2 steps/s
[Step=78900 Epoch=303.7] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=10.169 | 4201.3 samples/s | 65.6 steps/s
[Step=78950 Epoch=303.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.810 | L2-Norm(final)=10.171 | 4271.2 samples/s | 66.7 steps/s
[Step=79000 Epoch=304.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.790 | L2-Norm(final)=10.174 | 4847.8 samples/s | 75.7 steps/s
[Step=79050 Epoch=304.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.769 | L2-Norm(final)=10.177 | 2417.1 samples/s | 37.8 steps/s
[Step=79100 Epoch=304.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.749 | L2-Norm(final)=10.179 | 4191.0 samples/s | 65.5 steps/s
[Step=79150 Epoch=304.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.728 | L2-Norm(final)=10.182 | 4316.4 samples/s | 67.4 steps/s
[Step=79200 Epoch=304.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.707 | L2-Norm(final)=10.184 | 4298.7 samples/s | 67.2 steps/s
[Step=79250 Epoch=305.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.687 | L2-Norm(final)=10.187 | 4225.7 samples/s | 66.0 steps/s
[Step=79300 Epoch=305.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.666 | L2-Norm(final)=10.190 | 2580.9 samples/s | 40.3 steps/s
[Step=79350 Epoch=305.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.646 | L2-Norm(final)=10.193 | 4290.7 samples/s | 67.0 steps/s
[Step=79400 Epoch=305.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.625 | L2-Norm(final)=10.196 | 4292.7 samples/s | 67.1 steps/s
[Step=79450 Epoch=305.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.605 | L2-Norm(final)=10.200 | 4174.2 samples/s | 65.2 steps/s
[Step=79500 Epoch=306.0] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.585 | L2-Norm(final)=10.203 | 4340.9 samples/s | 67.8 steps/s
[Step=79550 Epoch=306.2] | Loss=0.00005 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.568 | L2-Norm(final)=10.208 | 2596.8 samples/s | 40.6 steps/s
[Step=79600 Epoch=306.4] | Loss=0.00010 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.556 | L2-Norm(final)=10.213 | 4254.4 samples/s | 66.5 steps/s
[Step=79650 Epoch=306.6] | Loss=0.00011 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.545 | L2-Norm(final)=10.217 | 4218.7 samples/s | 65.9 steps/s
[Step=79700 Epoch=306.8] | Loss=0.00012 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.535 | L2-Norm(final)=10.222 | 4215.8 samples/s | 65.9 steps/s
[Step=79750 Epoch=307.0] | Loss=0.00011 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.527 | L2-Norm(final)=10.226 | 4231.7 samples/s | 66.1 steps/s
[Step=79800 Epoch=307.2] | Loss=0.00011 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.519 | L2-Norm(final)=10.230 | 7022.7 samples/s | 109.7 steps/s
[Step=79850 Epoch=307.4] | Loss=0.00011 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.512 | L2-Norm(final)=10.234 | 2140.2 samples/s | 33.4 steps/s
[Step=79900 Epoch=307.6] | Loss=0.00010 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.505 | L2-Norm(final)=10.237 | 4129.9 samples/s | 64.5 steps/s
[Step=79950 Epoch=307.8] | Loss=0.00010 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.499 | L2-Norm(final)=10.241 | 4265.9 samples/s | 66.7 steps/s
[Step=80000 Epoch=308.0] | Loss=0.00010 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=10.244 | 4166.2 samples/s | 65.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07050 | acc=0.9687 | tpr=0.9781 | fpr=0.0518 | 4824.8 samples/s | 18.8 steps/s
Avg test loss: 0.07157, Avg test acc: 0.96727, Avg tpr: 0.97692, Avg fpr: 0.05397, total FA: 421

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06736 | acc=0.9673 | tpr=0.9772 | fpr=0.0543 | 5036.1 samples/s | 19.7 steps/s
Avg test loss: 0.06982, Avg test acc: 0.96670, Avg tpr: 0.97692, Avg fpr: 0.05576, total FA: 435

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.75961 | acc=0.3083 | tpr=0.0082 | fpr=0.0401 | 4899.3 samples/s | 19.1 steps/s
Avg test loss: 4.75716, Avg test acc: 0.30475, Avg tpr: 0.00880, Avg fpr: 0.04435, total FA: 346

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.28183 | acc=0.3112 | tpr=0.0047 | fpr=0.0233 | 4803.6 samples/s | 18.8 steps/s
Avg test loss: 5.27820, Avg test acc: 0.30872, Avg tpr: 0.00571, Avg fpr: 0.02487, total FA: 194

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.50219 | acc=0.1509 | tpr=0.5088 | fpr=0.8555 | 4920.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.47548 | acc=0.1505 | tpr=0.4670 | fpr=0.8554 | 7066.9 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.47555 | acc=0.1512 | tpr=0.4640 | fpr=0.8545 | 8043.9 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.47578 | acc=0.1519 | tpr=0.4601 | fpr=0.8537 | 7754.5 samples/s | 30.3 steps/s
[Step= 250] | Loss=5.46506 | acc=0.1523 | tpr=0.4707 | fpr=0.8535 | 7910.8 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.45816 | acc=0.1525 | tpr=0.4705 | fpr=0.8533 | 7756.1 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.46224 | acc=0.1522 | tpr=0.4615 | fpr=0.8534 | 7757.6 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.46042 | acc=0.1525 | tpr=0.4562 | fpr=0.8530 | 7959.9 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.46377 | acc=0.1522 | tpr=0.4523 | fpr=0.8533 | 8105.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.46584 | acc=0.1521 | tpr=0.4515 | fpr=0.8533 | 7705.6 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.46703 | acc=0.1523 | tpr=0.4497 | fpr=0.8531 | 13772.9 samples/s | 53.8 steps/s
Avg test loss: 5.46880, Avg test acc: 0.15223, Avg tpr: 0.45087, Avg fpr: 0.85320, total FA: 118465

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.66311 | acc=0.1217 | tpr=0.6327 | fpr=0.8875 | 5121.5 samples/s | 20.0 steps/s
[Step= 100] | Loss=6.64856 | acc=0.1217 | tpr=0.5736 | fpr=0.8867 | 6864.5 samples/s | 26.8 steps/s
[Step= 150] | Loss=6.64691 | acc=0.1226 | tpr=0.5778 | fpr=0.8857 | 7621.9 samples/s | 29.8 steps/s
[Step= 200] | Loss=6.64359 | acc=0.1222 | tpr=0.5716 | fpr=0.8859 | 7726.3 samples/s | 30.2 steps/s
[Step= 250] | Loss=6.63399 | acc=0.1231 | tpr=0.5729 | fpr=0.8851 | 7948.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.62856 | acc=0.1229 | tpr=0.5724 | fpr=0.8853 | 7806.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=6.63359 | acc=0.1227 | tpr=0.5673 | fpr=0.8854 | 8022.2 samples/s | 31.3 steps/s
[Step= 400] | Loss=6.62982 | acc=0.1225 | tpr=0.5640 | fpr=0.8855 | 7636.0 samples/s | 29.8 steps/s
[Step= 450] | Loss=6.63412 | acc=0.1221 | tpr=0.5599 | fpr=0.8859 | 8259.4 samples/s | 32.3 steps/s
[Step= 500] | Loss=6.63557 | acc=0.1226 | tpr=0.5626 | fpr=0.8853 | 7674.4 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.63813 | acc=0.1226 | tpr=0.5591 | fpr=0.8854 | 13812.3 samples/s | 54.0 steps/s
Avg test loss: 6.64016, Avg test acc: 0.12240, Avg tpr: 0.55983, Avg fpr: 0.88555, total FA: 122957

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11115 | acc=0.9771 | tpr=0.9425 | fpr=0.0223 | 5082.9 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.11123 | acc=0.9781 | tpr=0.9574 | fpr=0.0215 | 6892.8 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.11678 | acc=0.9771 | tpr=0.9582 | fpr=0.0225 | 7762.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.11996 | acc=0.9770 | tpr=0.9585 | fpr=0.0226 | 7835.7 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.11772 | acc=0.9776 | tpr=0.9598 | fpr=0.0221 | 7783.6 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11988 | acc=0.9773 | tpr=0.9593 | fpr=0.0224 | 7823.3 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.12019 | acc=0.9772 | tpr=0.9593 | fpr=0.0225 | 8128.8 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.12128 | acc=0.9772 | tpr=0.9590 | fpr=0.0224 | 7743.5 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.12351 | acc=0.9768 | tpr=0.9576 | fpr=0.0228 | 7918.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.12289 | acc=0.9769 | tpr=0.9581 | fpr=0.0228 | 7603.8 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.12189 | acc=0.9771 | tpr=0.9578 | fpr=0.0226 | 14329.7 samples/s | 56.0 steps/s
Avg test loss: 0.12172, Avg test acc: 0.97710, Avg tpr: 0.95761, Avg fpr: 0.02255, total FA: 3131

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09307 | acc=0.9791 | tpr=0.9425 | fpr=0.0203 | 4833.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.09492 | acc=0.9789 | tpr=0.9531 | fpr=0.0206 | 7078.7 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.09924 | acc=0.9782 | tpr=0.9582 | fpr=0.0215 | 8078.2 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.10143 | acc=0.9779 | tpr=0.9596 | fpr=0.0217 | 7618.2 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.09982 | acc=0.9783 | tpr=0.9590 | fpr=0.0214 | 7741.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.10156 | acc=0.9780 | tpr=0.9578 | fpr=0.0217 | 7631.0 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.10178 | acc=0.9778 | tpr=0.9593 | fpr=0.0218 | 7787.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10289 | acc=0.9777 | tpr=0.9573 | fpr=0.0219 | 8034.3 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.10477 | acc=0.9774 | tpr=0.9562 | fpr=0.0222 | 7842.2 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10440 | acc=0.9775 | tpr=0.9564 | fpr=0.0222 | 7677.6 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.10329 | acc=0.9777 | tpr=0.9570 | fpr=0.0219 | 13975.7 samples/s | 54.6 steps/s
Avg test loss: 0.10322, Avg test acc: 0.97773, Avg tpr: 0.95681, Avg fpr: 0.02189, total FA: 3039

server round 40/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=156.0] | Loss=0.02072 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.892 | L2-Norm(final)=14.832 | 6194.5 samples/s | 96.8 steps/s
[Step=80050 Epoch=156.1] | Loss=0.01163 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.895 | L2-Norm(final)=14.833 | 4621.3 samples/s | 72.2 steps/s
[Step=80100 Epoch=156.2] | Loss=0.01104 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=14.837 | 4992.5 samples/s | 78.0 steps/s
[Step=80150 Epoch=156.3] | Loss=0.01086 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.901 | L2-Norm(final)=14.841 | 5038.9 samples/s | 78.7 steps/s
[Step=80200 Epoch=156.4] | Loss=0.01049 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=14.845 | 5004.4 samples/s | 78.2 steps/s
[Step=80250 Epoch=156.5] | Loss=0.00998 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=14.849 | 5055.4 samples/s | 79.0 steps/s
[Step=80300 Epoch=156.6] | Loss=0.00993 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.907 | L2-Norm(final)=14.853 | 5126.6 samples/s | 80.1 steps/s
[Step=80350 Epoch=156.7] | Loss=0.00985 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.909 | L2-Norm(final)=14.857 | 4971.1 samples/s | 77.7 steps/s
[Step=80400 Epoch=156.8] | Loss=0.00950 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.911 | L2-Norm(final)=14.861 | 5066.8 samples/s | 79.2 steps/s
[Step=80450 Epoch=156.9] | Loss=0.00933 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=14.865 | 5084.1 samples/s | 79.4 steps/s
[Step=80500 Epoch=157.0] | Loss=0.00916 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.914 | L2-Norm(final)=14.869 | 6667.4 samples/s | 104.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=157.0] | Loss=0.01157 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.932 | L2-Norm(final)=14.908 | 7566.0 samples/s | 118.2 steps/s
[Step=80550 Epoch=157.1] | Loss=0.00824 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.936 | L2-Norm(final)=14.912 | 4017.2 samples/s | 62.8 steps/s
[Step=80600 Epoch=157.2] | Loss=0.00815 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.938 | L2-Norm(final)=14.915 | 4504.4 samples/s | 70.4 steps/s
[Step=80650 Epoch=157.3] | Loss=0.00834 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.940 | L2-Norm(final)=14.918 | 4478.2 samples/s | 70.0 steps/s
[Step=80700 Epoch=157.4] | Loss=0.00832 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.942 | L2-Norm(final)=14.921 | 4458.0 samples/s | 69.7 steps/s
[Step=80750 Epoch=157.5] | Loss=0.00829 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=14.924 | 4421.2 samples/s | 69.1 steps/s
[Step=80800 Epoch=157.6] | Loss=0.00823 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=14.927 | 4561.7 samples/s | 71.3 steps/s
[Step=80850 Epoch=157.7] | Loss=0.00787 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.947 | L2-Norm(final)=14.930 | 4365.5 samples/s | 68.2 steps/s
[Step=80900 Epoch=157.8] | Loss=0.00774 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=14.933 | 4451.8 samples/s | 69.6 steps/s
[Step=80950 Epoch=157.9] | Loss=0.00756 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=14.936 | 4395.6 samples/s | 68.7 steps/s
[Step=81000 Epoch=158.0] | Loss=0.00734 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.950 | L2-Norm(final)=14.938 | 5518.5 samples/s | 86.2 steps/s
[Step=81050 Epoch=158.1] | Loss=0.00723 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=14.941 | 2323.1 samples/s | 36.3 steps/s
[Step=81100 Epoch=158.2] | Loss=0.00702 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.952 | L2-Norm(final)=14.944 | 4257.4 samples/s | 66.5 steps/s
[Step=81150 Epoch=158.3] | Loss=0.00685 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.953 | L2-Norm(final)=14.946 | 4439.7 samples/s | 69.4 steps/s
[Step=81200 Epoch=158.4] | Loss=0.00674 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=14.949 | 4413.0 samples/s | 69.0 steps/s
[Step=81250 Epoch=158.5] | Loss=0.00671 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=14.951 | 4464.7 samples/s | 69.8 steps/s
[Step=81300 Epoch=158.6] | Loss=0.00664 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=14.954 | 4418.3 samples/s | 69.0 steps/s
[Step=81350 Epoch=158.7] | Loss=0.00658 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.956 | L2-Norm(final)=14.956 | 4593.2 samples/s | 71.8 steps/s
[Step=81400 Epoch=158.8] | Loss=0.00661 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.956 | L2-Norm(final)=14.958 | 4367.7 samples/s | 68.2 steps/s
[Step=81450 Epoch=158.9] | Loss=0.00654 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=14.961 | 4499.5 samples/s | 70.3 steps/s
[Step=81500 Epoch=159.0] | Loss=0.00652 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=14.963 | 4833.1 samples/s | 75.5 steps/s
[Step=81550 Epoch=159.1] | Loss=0.00642 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=14.965 | 2615.7 samples/s | 40.9 steps/s
[Step=81600 Epoch=159.2] | Loss=0.00632 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=14.968 | 4520.1 samples/s | 70.6 steps/s
[Step=81650 Epoch=159.2] | Loss=0.00624 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.959 | L2-Norm(final)=14.970 | 4409.4 samples/s | 68.9 steps/s
[Step=81700 Epoch=159.3] | Loss=0.00618 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=14.972 | 4330.5 samples/s | 67.7 steps/s
[Step=81750 Epoch=159.4] | Loss=0.00610 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=14.974 | 4439.9 samples/s | 69.4 steps/s
[Step=81800 Epoch=159.5] | Loss=0.00606 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.960 | L2-Norm(final)=14.976 | 4402.4 samples/s | 68.8 steps/s
[Step=81850 Epoch=159.6] | Loss=0.00603 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=14.979 | 4400.8 samples/s | 68.8 steps/s
[Step=81900 Epoch=159.7] | Loss=0.00604 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=14.981 | 4430.6 samples/s | 69.2 steps/s
[Step=81950 Epoch=159.8] | Loss=0.00602 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=14.983 | 4372.1 samples/s | 68.3 steps/s
[Step=82000 Epoch=159.9] | Loss=0.00599 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=14.985 | 4482.5 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step82000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=156.4] | Loss=0.02481 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.063 | L2-Norm(final)=14.910 | 5651.2 samples/s | 88.3 steps/s
[Step=80050 Epoch=156.5] | Loss=0.01479 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.067 | L2-Norm(final)=14.909 | 4375.4 samples/s | 68.4 steps/s
[Step=80100 Epoch=156.6] | Loss=0.01265 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=14.912 | 4907.1 samples/s | 76.7 steps/s
[Step=80150 Epoch=156.7] | Loss=0.01165 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.073 | L2-Norm(final)=14.915 | 4962.1 samples/s | 77.5 steps/s
[Step=80200 Epoch=156.8] | Loss=0.01067 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.075 | L2-Norm(final)=14.919 | 5080.3 samples/s | 79.4 steps/s
[Step=80250 Epoch=156.9] | Loss=0.01054 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.077 | L2-Norm(final)=14.922 | 4893.2 samples/s | 76.5 steps/s
[Step=80300 Epoch=157.0] | Loss=0.01012 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=14.926 | 5145.2 samples/s | 80.4 steps/s
[Step=80350 Epoch=157.1] | Loss=0.00993 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.081 | L2-Norm(final)=14.929 | 5001.8 samples/s | 78.2 steps/s
[Step=80400 Epoch=157.2] | Loss=0.00976 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.083 | L2-Norm(final)=14.933 | 4806.3 samples/s | 75.1 steps/s
[Step=80450 Epoch=157.3] | Loss=0.00962 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.084 | L2-Norm(final)=14.936 | 5015.3 samples/s | 78.4 steps/s
[Step=80500 Epoch=157.4] | Loss=0.00945 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.086 | L2-Norm(final)=14.940 | 6746.7 samples/s | 105.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=157.4] | Loss=0.01211 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.102 | L2-Norm(final)=14.975 | 5828.3 samples/s | 91.1 steps/s
[Step=80550 Epoch=157.5] | Loss=0.00952 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.105 | L2-Norm(final)=14.978 | 4210.3 samples/s | 65.8 steps/s
[Step=80600 Epoch=157.6] | Loss=0.00893 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=14.982 | 4408.7 samples/s | 68.9 steps/s
[Step=80650 Epoch=157.7] | Loss=0.00911 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=14.984 | 4447.1 samples/s | 69.5 steps/s
[Step=80700 Epoch=157.8] | Loss=0.00831 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.111 | L2-Norm(final)=14.987 | 4426.5 samples/s | 69.2 steps/s
[Step=80750 Epoch=157.9] | Loss=0.00812 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.113 | L2-Norm(final)=14.990 | 4459.4 samples/s | 69.7 steps/s
[Step=80800 Epoch=158.0] | Loss=0.00797 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=14.993 | 4357.7 samples/s | 68.1 steps/s
[Step=80850 Epoch=158.1] | Loss=0.00788 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=14.996 | 4402.6 samples/s | 68.8 steps/s
[Step=80900 Epoch=158.2] | Loss=0.00777 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=14.998 | 4454.8 samples/s | 69.6 steps/s
[Step=80950 Epoch=158.3] | Loss=0.00758 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.118 | L2-Norm(final)=15.001 | 4441.9 samples/s | 69.4 steps/s
[Step=81000 Epoch=158.4] | Loss=0.00740 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.119 | L2-Norm(final)=15.004 | 5803.0 samples/s | 90.7 steps/s
[Step=81050 Epoch=158.5] | Loss=0.00727 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=15.006 | 2356.5 samples/s | 36.8 steps/s
[Step=81100 Epoch=158.5] | Loss=0.00706 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=15.009 | 4370.9 samples/s | 68.3 steps/s
[Step=81150 Epoch=158.6] | Loss=0.00690 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=15.011 | 4420.5 samples/s | 69.1 steps/s
[Step=81200 Epoch=158.7] | Loss=0.00677 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=15.014 | 4439.2 samples/s | 69.4 steps/s
[Step=81250 Epoch=158.8] | Loss=0.00670 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.123 | L2-Norm(final)=15.016 | 4397.1 samples/s | 68.7 steps/s
[Step=81300 Epoch=158.9] | Loss=0.00660 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.124 | L2-Norm(final)=15.019 | 4476.1 samples/s | 69.9 steps/s
[Step=81350 Epoch=159.0] | Loss=0.00660 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=15.021 | 4461.0 samples/s | 69.7 steps/s
[Step=81400 Epoch=159.1] | Loss=0.00656 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=15.023 | 4314.6 samples/s | 67.4 steps/s
[Step=81450 Epoch=159.2] | Loss=0.00652 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.126 | L2-Norm(final)=15.026 | 4452.5 samples/s | 69.6 steps/s
[Step=81500 Epoch=159.3] | Loss=0.00648 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=15.028 | 4915.7 samples/s | 76.8 steps/s
[Step=81550 Epoch=159.4] | Loss=0.00640 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.127 | L2-Norm(final)=15.030 | 2577.3 samples/s | 40.3 steps/s
[Step=81600 Epoch=159.5] | Loss=0.00634 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=15.033 | 4409.9 samples/s | 68.9 steps/s
[Step=81650 Epoch=159.6] | Loss=0.00628 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=15.035 | 4508.8 samples/s | 70.5 steps/s
[Step=81700 Epoch=159.7] | Loss=0.00617 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=15.037 | 4269.1 samples/s | 66.7 steps/s
[Step=81750 Epoch=159.8] | Loss=0.00617 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.129 | L2-Norm(final)=15.039 | 4406.7 samples/s | 68.9 steps/s
[Step=81800 Epoch=159.9] | Loss=0.00611 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.129 | L2-Norm(final)=15.042 | 4485.4 samples/s | 70.1 steps/s
[Step=81850 Epoch=160.0] | Loss=0.00603 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.044 | 4434.6 samples/s | 69.3 steps/s
[Step=81900 Epoch=160.1] | Loss=0.00598 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.046 | 4435.1 samples/s | 69.3 steps/s
[Step=81950 Epoch=160.2] | Loss=0.00598 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.048 | 4414.0 samples/s | 69.0 steps/s
[Step=82000 Epoch=160.3] | Loss=0.00593 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.131 | L2-Norm(final)=15.050 | 4509.1 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step82000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=306.5] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=9.000 | 5726.9 samples/s | 89.5 steps/s
[Step=80050 Epoch=306.7] | Loss=0.00007 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.001 | 4033.0 samples/s | 63.0 steps/s
[Step=80100 Epoch=306.9] | Loss=0.00007 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.002 | 4770.9 samples/s | 74.5 steps/s
[Step=80150 Epoch=307.1] | Loss=0.00006 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.003 | 4645.7 samples/s | 72.6 steps/s
[Step=80200 Epoch=307.3] | Loss=0.00006 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.004 | 4633.4 samples/s | 72.4 steps/s
[Step=80250 Epoch=307.5] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.005 | 6524.4 samples/s | 101.9 steps/s
[Step=80300 Epoch=307.7] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.006 | 2393.8 samples/s | 37.4 steps/s
[Step=80350 Epoch=307.9] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.006 | 4745.6 samples/s | 74.2 steps/s
[Step=80400 Epoch=308.1] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.007 | 4597.2 samples/s | 71.8 steps/s
[Step=80450 Epoch=308.3] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.008 | 4863.5 samples/s | 76.0 steps/s
[Step=80500 Epoch=308.4] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.009 | 5188.3 samples/s | 81.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=308.5] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.017 | 6251.2 samples/s | 97.7 steps/s
[Step=80550 Epoch=308.6] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.018 | 3750.2 samples/s | 58.6 steps/s
[Step=80600 Epoch=308.8] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.019 | 4255.3 samples/s | 66.5 steps/s
[Step=80650 Epoch=309.0] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.019 | 4192.1 samples/s | 65.5 steps/s
[Step=80700 Epoch=309.2] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.020 | 4147.4 samples/s | 64.8 steps/s
[Step=80750 Epoch=309.4] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.021 | 5619.6 samples/s | 87.8 steps/s
[Step=80800 Epoch=309.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.022 | 2245.6 samples/s | 35.1 steps/s
[Step=80850 Epoch=309.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.022 | 4193.2 samples/s | 65.5 steps/s
[Step=80900 Epoch=310.0] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.023 | 4171.4 samples/s | 65.2 steps/s
[Step=80950 Epoch=310.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.024 | 4175.5 samples/s | 65.2 steps/s
[Step=81000 Epoch=310.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.024 | 4751.0 samples/s | 74.2 steps/s
[Step=81050 Epoch=310.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.025 | 2426.7 samples/s | 37.9 steps/s
[Step=81100 Epoch=310.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.025 | 4172.9 samples/s | 65.2 steps/s
[Step=81150 Epoch=310.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.026 | 4144.0 samples/s | 64.8 steps/s
[Step=81200 Epoch=311.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.027 | 4157.2 samples/s | 65.0 steps/s
[Step=81250 Epoch=311.3] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.027 | 4256.9 samples/s | 66.5 steps/s
[Step=81300 Epoch=311.5] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.028 | 2602.6 samples/s | 40.7 steps/s
[Step=81350 Epoch=311.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.028 | 4202.0 samples/s | 65.7 steps/s
[Step=81400 Epoch=311.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.029 | 4224.9 samples/s | 66.0 steps/s
[Step=81450 Epoch=312.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.029 | 4151.4 samples/s | 64.9 steps/s
[Step=81500 Epoch=312.3] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.030 | 4223.5 samples/s | 66.0 steps/s
[Step=81550 Epoch=312.5] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.031 | 2652.1 samples/s | 41.4 steps/s
[Step=81600 Epoch=312.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.031 | 4018.4 samples/s | 62.8 steps/s
[Step=81650 Epoch=312.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.032 | 4252.9 samples/s | 66.5 steps/s
[Step=81700 Epoch=313.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.032 | 4164.9 samples/s | 65.1 steps/s
[Step=81750 Epoch=313.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.033 | 4146.8 samples/s | 64.8 steps/s
[Step=81800 Epoch=313.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.033 | 6286.6 samples/s | 98.2 steps/s
[Step=81850 Epoch=313.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=9.034 | 2166.8 samples/s | 33.9 steps/s
[Step=81900 Epoch=313.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.922 | L2-Norm(final)=9.034 | 4276.5 samples/s | 66.8 steps/s
[Step=81950 Epoch=314.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.921 | L2-Norm(final)=9.035 | 4133.8 samples/s | 64.6 steps/s
[Step=82000 Epoch=314.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.921 | L2-Norm(final)=9.035 | 4186.2 samples/s | 65.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step82000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=308.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.336 | 6005.8 samples/s | 93.8 steps/s
[Step=80050 Epoch=308.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.336 | 4213.7 samples/s | 65.8 steps/s
[Step=80100 Epoch=308.3] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.337 | 4731.6 samples/s | 73.9 steps/s
[Step=80150 Epoch=308.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.337 | 4728.0 samples/s | 73.9 steps/s
[Step=80200 Epoch=308.7] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.338 | 4734.9 samples/s | 74.0 steps/s
[Step=80250 Epoch=308.9] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.338 | 6547.5 samples/s | 102.3 steps/s
[Step=80300 Epoch=309.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.339 | 2394.3 samples/s | 37.4 steps/s
[Step=80350 Epoch=309.3] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.339 | 4635.8 samples/s | 72.4 steps/s
[Step=80400 Epoch=309.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.340 | 4694.5 samples/s | 73.4 steps/s
[Step=80450 Epoch=309.7] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.340 | 4759.5 samples/s | 74.4 steps/s
[Step=80500 Epoch=309.9] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.341 | 5519.8 samples/s | 86.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=309.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.346 | 6053.1 samples/s | 94.6 steps/s
[Step=80550 Epoch=310.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.346 | 3816.1 samples/s | 59.6 steps/s
[Step=80600 Epoch=310.3] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.347 | 4191.5 samples/s | 65.5 steps/s
[Step=80650 Epoch=310.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=10.347 | 4208.6 samples/s | 65.8 steps/s
[Step=80700 Epoch=310.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=10.348 | 4194.8 samples/s | 65.5 steps/s
[Step=80750 Epoch=310.8] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=10.348 | 5728.3 samples/s | 89.5 steps/s
[Step=80800 Epoch=311.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=10.348 | 2229.9 samples/s | 34.8 steps/s
[Step=80850 Epoch=311.2] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.349 | 4234.0 samples/s | 66.2 steps/s
[Step=80900 Epoch=311.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.349 | 4166.4 samples/s | 65.1 steps/s
[Step=80950 Epoch=311.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.349 | 4171.4 samples/s | 65.2 steps/s
[Step=81000 Epoch=311.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.350 | 4866.4 samples/s | 76.0 steps/s
[Step=81050 Epoch=312.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.350 | 2401.6 samples/s | 37.5 steps/s
[Step=81100 Epoch=312.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.350 | 4211.3 samples/s | 65.8 steps/s
[Step=81150 Epoch=312.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=10.351 | 4198.2 samples/s | 65.6 steps/s
[Step=81200 Epoch=312.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=10.351 | 4174.0 samples/s | 65.2 steps/s
[Step=81250 Epoch=312.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.351 | 4288.4 samples/s | 67.0 steps/s
[Step=81300 Epoch=313.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.352 | 2582.1 samples/s | 40.3 steps/s
[Step=81350 Epoch=313.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.352 | 4168.1 samples/s | 65.1 steps/s
[Step=81400 Epoch=313.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.857 | L2-Norm(final)=10.352 | 4178.0 samples/s | 65.3 steps/s
[Step=81450 Epoch=313.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.857 | L2-Norm(final)=10.353 | 4158.0 samples/s | 65.0 steps/s
[Step=81500 Epoch=313.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.856 | L2-Norm(final)=10.353 | 4198.2 samples/s | 65.6 steps/s
[Step=81550 Epoch=313.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.353 | 2653.1 samples/s | 41.5 steps/s
[Step=81600 Epoch=314.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.354 | 4106.4 samples/s | 64.2 steps/s
[Step=81650 Epoch=314.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.354 | 4188.4 samples/s | 65.4 steps/s
[Step=81700 Epoch=314.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.354 | 4202.5 samples/s | 65.7 steps/s
[Step=81750 Epoch=314.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.354 | 4193.7 samples/s | 65.5 steps/s
[Step=81800 Epoch=314.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.852 | L2-Norm(final)=10.355 | 6942.8 samples/s | 108.5 steps/s
[Step=81850 Epoch=315.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.852 | L2-Norm(final)=10.355 | 2119.5 samples/s | 33.1 steps/s
[Step=81900 Epoch=315.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.851 | L2-Norm(final)=10.355 | 4066.9 samples/s | 63.5 steps/s
[Step=81950 Epoch=315.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.850 | L2-Norm(final)=10.356 | 4263.7 samples/s | 66.6 steps/s
[Step=82000 Epoch=315.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.850 | L2-Norm(final)=10.356 | 4106.9 samples/s | 64.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06958 | acc=0.9659 | tpr=0.9700 | fpr=0.0429 | 4654.9 samples/s | 18.2 steps/s
Avg test loss: 0.07103, Avg test acc: 0.96494, Avg tpr: 0.96958, Avg fpr: 0.04525, total FA: 353

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06644 | acc=0.9672 | tpr=0.9751 | fpr=0.0500 | 4983.3 samples/s | 19.5 steps/s
Avg test loss: 0.06964, Avg test acc: 0.96646, Avg tpr: 0.97476, Avg fpr: 0.05179, total FA: 404

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.78413 | acc=0.3059 | tpr=0.0089 | fpr=0.0493 | 4821.2 samples/s | 18.8 steps/s
Avg test loss: 4.78131, Avg test acc: 0.30275, Avg tpr: 0.00997, Avg fpr: 0.05333, total FA: 416

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.40559 | acc=0.3075 | tpr=0.0147 | fpr=0.0567 | 4634.5 samples/s | 18.1 steps/s
Avg test loss: 5.39777, Avg test acc: 0.30531, Avg tpr: 0.01708, Avg fpr: 0.06076, total FA: 474

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.19362 | acc=0.1594 | tpr=0.4867 | fpr=0.8465 | 4940.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.17073 | acc=0.1594 | tpr=0.4478 | fpr=0.8460 | 7067.3 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.17053 | acc=0.1603 | tpr=0.4496 | fpr=0.8450 | 7786.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.16865 | acc=0.1611 | tpr=0.4470 | fpr=0.8441 | 7843.8 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.15892 | acc=0.1614 | tpr=0.4559 | fpr=0.8439 | 7754.7 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.15254 | acc=0.1612 | tpr=0.4509 | fpr=0.8441 | 7882.1 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.15633 | acc=0.1606 | tpr=0.4383 | fpr=0.8444 | 7871.0 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.15432 | acc=0.1611 | tpr=0.4354 | fpr=0.8439 | 8047.3 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.15719 | acc=0.1609 | tpr=0.4309 | fpr=0.8440 | 7695.7 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.15976 | acc=0.1610 | tpr=0.4295 | fpr=0.8438 | 7536.6 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.16162 | acc=0.1614 | tpr=0.4282 | fpr=0.8434 | 14461.8 samples/s | 56.5 steps/s
Avg test loss: 5.16304, Avg test acc: 0.16129, Avg tpr: 0.42948, Avg fpr: 0.84358, total FA: 117130

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.18053 | acc=0.1295 | tpr=0.5575 | fpr=0.8782 | 4986.3 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.17248 | acc=0.1303 | tpr=0.5203 | fpr=0.8770 | 6754.2 samples/s | 26.4 steps/s
[Step= 150] | Loss=6.17185 | acc=0.1311 | tpr=0.5259 | fpr=0.8762 | 8050.2 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.16595 | acc=0.1313 | tpr=0.5191 | fpr=0.8758 | 7970.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.15716 | acc=0.1323 | tpr=0.5179 | fpr=0.8748 | 8051.3 samples/s | 31.5 steps/s
[Step= 300] | Loss=6.15227 | acc=0.1326 | tpr=0.5207 | fpr=0.8745 | 7724.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.15610 | acc=0.1323 | tpr=0.5135 | fpr=0.8747 | 7635.9 samples/s | 29.8 steps/s
[Step= 400] | Loss=6.15309 | acc=0.1324 | tpr=0.5088 | fpr=0.8744 | 8099.7 samples/s | 31.6 steps/s
[Step= 450] | Loss=6.15758 | acc=0.1320 | tpr=0.5058 | fpr=0.8748 | 7655.9 samples/s | 29.9 steps/s
[Step= 500] | Loss=6.15985 | acc=0.1325 | tpr=0.5079 | fpr=0.8743 | 7768.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.16223 | acc=0.1326 | tpr=0.5046 | fpr=0.8741 | 14197.6 samples/s | 55.5 steps/s
Avg test loss: 6.16415, Avg test acc: 0.13249, Avg tpr: 0.50515, Avg fpr: 0.87428, total FA: 121392

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11267 | acc=0.9769 | tpr=0.9513 | fpr=0.0227 | 5014.6 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.11317 | acc=0.9777 | tpr=0.9616 | fpr=0.0220 | 6795.6 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.11809 | acc=0.9770 | tpr=0.9625 | fpr=0.0227 | 7969.3 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.12101 | acc=0.9770 | tpr=0.9628 | fpr=0.0227 | 7860.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.11885 | acc=0.9772 | tpr=0.9642 | fpr=0.0225 | 7861.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.12049 | acc=0.9769 | tpr=0.9644 | fpr=0.0229 | 7564.4 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.12068 | acc=0.9768 | tpr=0.9643 | fpr=0.0229 | 7875.9 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.12194 | acc=0.9768 | tpr=0.9633 | fpr=0.0229 | 8084.7 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.12421 | acc=0.9765 | tpr=0.9620 | fpr=0.0233 | 7768.6 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12355 | acc=0.9766 | tpr=0.9626 | fpr=0.0232 | 7606.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.12237 | acc=0.9768 | tpr=0.9626 | fpr=0.0229 | 14621.9 samples/s | 57.1 steps/s
Avg test loss: 0.12223, Avg test acc: 0.97683, Avg tpr: 0.96236, Avg fpr: 0.02291, total FA: 3181

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11743 | acc=0.9775 | tpr=0.9558 | fpr=0.0221 | 5080.3 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.11866 | acc=0.9777 | tpr=0.9680 | fpr=0.0221 | 6848.2 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.12410 | acc=0.9770 | tpr=0.9669 | fpr=0.0228 | 7904.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.12681 | acc=0.9768 | tpr=0.9650 | fpr=0.0230 | 7621.4 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.12480 | acc=0.9770 | tpr=0.9642 | fpr=0.0227 | 8023.5 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.12657 | acc=0.9768 | tpr=0.9629 | fpr=0.0229 | 7468.9 samples/s | 29.2 steps/s
[Step= 350] | Loss=0.12682 | acc=0.9767 | tpr=0.9643 | fpr=0.0231 | 8248.5 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.12807 | acc=0.9766 | tpr=0.9623 | fpr=0.0231 | 7518.7 samples/s | 29.4 steps/s
[Step= 450] | Loss=0.13054 | acc=0.9762 | tpr=0.9596 | fpr=0.0235 | 8019.9 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.12997 | acc=0.9764 | tpr=0.9599 | fpr=0.0233 | 7851.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.12857 | acc=0.9766 | tpr=0.9602 | fpr=0.0231 | 13654.9 samples/s | 53.3 steps/s
Avg test loss: 0.12846, Avg test acc: 0.97664, Avg tpr: 0.95998, Avg fpr: 0.02305, total FA: 3201

server round 41/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=159.9] | Loss=0.00084 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.942 | L2-Norm(final)=15.049 | 6089.3 samples/s | 95.1 steps/s
[Step=82050 Epoch=160.0] | Loss=0.00469 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.942 | L2-Norm(final)=15.052 | 4565.3 samples/s | 71.3 steps/s
[Step=82100 Epoch=160.1] | Loss=0.00523 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.943 | L2-Norm(final)=15.056 | 5221.4 samples/s | 81.6 steps/s
[Step=82150 Epoch=160.2] | Loss=0.00561 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=15.059 | 4914.2 samples/s | 76.8 steps/s
[Step=82200 Epoch=160.3] | Loss=0.00567 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=15.063 | 4955.1 samples/s | 77.4 steps/s
[Step=82250 Epoch=160.4] | Loss=0.00587 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=15.066 | 5147.8 samples/s | 80.4 steps/s
[Step=82300 Epoch=160.5] | Loss=0.00582 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=15.069 | 4965.1 samples/s | 77.6 steps/s
[Step=82350 Epoch=160.6] | Loss=0.00577 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=15.073 | 5049.2 samples/s | 78.9 steps/s
[Step=82400 Epoch=160.7] | Loss=0.00588 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=15.076 | 5011.9 samples/s | 78.3 steps/s
[Step=82450 Epoch=160.8] | Loss=0.00592 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=15.079 | 4994.9 samples/s | 78.0 steps/s
[Step=82500 Epoch=160.9] | Loss=0.00592 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=15.083 | 6659.3 samples/s | 104.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=160.9] | Loss=0.00301 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.953 | L2-Norm(final)=15.114 | 6195.7 samples/s | 96.8 steps/s
[Step=82550 Epoch=161.0] | Loss=0.00579 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=15.117 | 4116.0 samples/s | 64.3 steps/s
[Step=82600 Epoch=161.1] | Loss=0.00658 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=15.120 | 4562.0 samples/s | 71.3 steps/s
[Step=82650 Epoch=161.2] | Loss=0.00711 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.957 | L2-Norm(final)=15.123 | 4358.1 samples/s | 68.1 steps/s
[Step=82700 Epoch=161.3] | Loss=0.00687 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=15.126 | 4484.3 samples/s | 70.1 steps/s
[Step=82750 Epoch=161.4] | Loss=0.00656 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.959 | L2-Norm(final)=15.128 | 4452.1 samples/s | 69.6 steps/s
[Step=82800 Epoch=161.5] | Loss=0.00633 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.960 | L2-Norm(final)=15.131 | 4502.9 samples/s | 70.4 steps/s
[Step=82850 Epoch=161.6] | Loss=0.00636 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=15.134 | 4428.5 samples/s | 69.2 steps/s
[Step=82900 Epoch=161.7] | Loss=0.00615 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.962 | L2-Norm(final)=15.137 | 4475.9 samples/s | 69.9 steps/s
[Step=82950 Epoch=161.8] | Loss=0.00630 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.962 | L2-Norm(final)=15.140 | 4443.8 samples/s | 69.4 steps/s
[Step=83000 Epoch=161.9] | Loss=0.00631 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.963 | L2-Norm(final)=15.143 | 5821.7 samples/s | 91.0 steps/s
[Step=83050 Epoch=162.0] | Loss=0.00627 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=15.145 | 2406.0 samples/s | 37.6 steps/s
[Step=83100 Epoch=162.1] | Loss=0.00617 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=15.148 | 4525.8 samples/s | 70.7 steps/s
[Step=83150 Epoch=162.2] | Loss=0.00611 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=15.151 | 4503.8 samples/s | 70.4 steps/s
[Step=83200 Epoch=162.3] | Loss=0.00596 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=15.153 | 4407.9 samples/s | 68.9 steps/s
[Step=83250 Epoch=162.4] | Loss=0.00589 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=15.156 | 4400.1 samples/s | 68.8 steps/s
[Step=83300 Epoch=162.5] | Loss=0.00587 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=15.158 | 4480.8 samples/s | 70.0 steps/s
[Step=83350 Epoch=162.6] | Loss=0.00587 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.967 | L2-Norm(final)=15.161 | 4443.3 samples/s | 69.4 steps/s
[Step=83400 Epoch=162.7] | Loss=0.00584 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=15.163 | 4488.4 samples/s | 70.1 steps/s
[Step=83450 Epoch=162.8] | Loss=0.00583 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=15.165 | 4444.6 samples/s | 69.4 steps/s
[Step=83500 Epoch=162.9] | Loss=0.00581 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.168 | 4827.5 samples/s | 75.4 steps/s
[Step=83550 Epoch=163.0] | Loss=0.00582 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.170 | 2622.8 samples/s | 41.0 steps/s
[Step=83600 Epoch=163.1] | Loss=0.00571 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.172 | 4472.3 samples/s | 69.9 steps/s
[Step=83650 Epoch=163.1] | Loss=0.00568 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.175 | 4427.8 samples/s | 69.2 steps/s
[Step=83700 Epoch=163.2] | Loss=0.00559 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.177 | 4368.5 samples/s | 68.3 steps/s
[Step=83750 Epoch=163.3] | Loss=0.00555 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.179 | 4508.5 samples/s | 70.4 steps/s
[Step=83800 Epoch=163.4] | Loss=0.00553 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.969 | L2-Norm(final)=15.181 | 4442.7 samples/s | 69.4 steps/s
[Step=83850 Epoch=163.5] | Loss=0.00555 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.184 | 4628.7 samples/s | 72.3 steps/s
[Step=83900 Epoch=163.6] | Loss=0.00554 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.186 | 4335.7 samples/s | 67.7 steps/s
[Step=83950 Epoch=163.7] | Loss=0.00550 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.188 | 4514.5 samples/s | 70.5 steps/s
[Step=84000 Epoch=163.8] | Loss=0.00553 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.190 | 4462.6 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step84000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=160.3] | Loss=0.01007 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.113 | L2-Norm(final)=15.116 | 5988.8 samples/s | 93.6 steps/s
[Step=82050 Epoch=160.4] | Loss=0.00520 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=15.119 | 4542.8 samples/s | 71.0 steps/s
[Step=82100 Epoch=160.5] | Loss=0.00599 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=15.122 | 5039.0 samples/s | 78.7 steps/s
[Step=82150 Epoch=160.6] | Loss=0.00603 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.116 | L2-Norm(final)=15.125 | 5054.4 samples/s | 79.0 steps/s
[Step=82200 Epoch=160.7] | Loss=0.00641 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=15.129 | 5043.9 samples/s | 78.8 steps/s
[Step=82250 Epoch=160.8] | Loss=0.00625 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.118 | L2-Norm(final)=15.132 | 5057.0 samples/s | 79.0 steps/s
[Step=82300 Epoch=160.9] | Loss=0.00627 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.119 | L2-Norm(final)=15.135 | 5016.4 samples/s | 78.4 steps/s
[Step=82350 Epoch=161.0] | Loss=0.00621 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.120 | L2-Norm(final)=15.138 | 5016.6 samples/s | 78.4 steps/s
[Step=82400 Epoch=161.1] | Loss=0.00618 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=15.142 | 5111.4 samples/s | 79.9 steps/s
[Step=82450 Epoch=161.2] | Loss=0.00600 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=15.145 | 4994.7 samples/s | 78.0 steps/s
[Step=82500 Epoch=161.3] | Loss=0.00586 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=15.148 | 6775.9 samples/s | 105.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=161.3] | Loss=0.02010 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.128 | L2-Norm(final)=15.180 | 6810.5 samples/s | 106.4 steps/s
[Step=82550 Epoch=161.4] | Loss=0.00852 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.183 | 3956.4 samples/s | 61.8 steps/s
[Step=82600 Epoch=161.5] | Loss=0.00756 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=15.187 | 4371.8 samples/s | 68.3 steps/s
[Step=82650 Epoch=161.6] | Loss=0.00750 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.133 | L2-Norm(final)=15.190 | 4489.0 samples/s | 70.1 steps/s
[Step=82700 Epoch=161.7] | Loss=0.00720 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=15.193 | 4485.5 samples/s | 70.1 steps/s
[Step=82750 Epoch=161.8] | Loss=0.00677 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=15.196 | 4467.1 samples/s | 69.8 steps/s
[Step=82800 Epoch=161.9] | Loss=0.00661 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.136 | L2-Norm(final)=15.199 | 4532.0 samples/s | 70.8 steps/s
[Step=82850 Epoch=162.0] | Loss=0.00641 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=15.202 | 4423.1 samples/s | 69.1 steps/s
[Step=82900 Epoch=162.1] | Loss=0.00628 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=15.205 | 4370.2 samples/s | 68.3 steps/s
[Step=82950 Epoch=162.2] | Loss=0.00614 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.139 | L2-Norm(final)=15.208 | 4504.8 samples/s | 70.4 steps/s
[Step=83000 Epoch=162.3] | Loss=0.00614 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=15.211 | 5891.5 samples/s | 92.1 steps/s
[Step=83050 Epoch=162.4] | Loss=0.00606 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=15.214 | 2388.8 samples/s | 37.3 steps/s
[Step=83100 Epoch=162.5] | Loss=0.00585 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=15.216 | 4558.8 samples/s | 71.2 steps/s
[Step=83150 Epoch=162.6] | Loss=0.00584 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=15.219 | 4342.1 samples/s | 67.8 steps/s
[Step=83200 Epoch=162.7] | Loss=0.00585 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=15.222 | 4484.3 samples/s | 70.1 steps/s
[Step=83250 Epoch=162.8] | Loss=0.00574 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.143 | L2-Norm(final)=15.224 | 4501.8 samples/s | 70.3 steps/s
[Step=83300 Epoch=162.8] | Loss=0.00584 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=15.227 | 4357.1 samples/s | 68.1 steps/s
[Step=83350 Epoch=162.9] | Loss=0.00581 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=15.229 | 4466.5 samples/s | 69.8 steps/s
[Step=83400 Epoch=163.0] | Loss=0.00574 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=15.232 | 4508.6 samples/s | 70.4 steps/s
[Step=83450 Epoch=163.1] | Loss=0.00573 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=15.234 | 4488.5 samples/s | 70.1 steps/s
[Step=83500 Epoch=163.2] | Loss=0.00574 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=15.236 | 4944.6 samples/s | 77.3 steps/s
[Step=83550 Epoch=163.3] | Loss=0.00572 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=15.239 | 2583.5 samples/s | 40.4 steps/s
[Step=83600 Epoch=163.4] | Loss=0.00563 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=15.241 | 4468.1 samples/s | 69.8 steps/s
[Step=83650 Epoch=163.5] | Loss=0.00562 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=15.243 | 4498.0 samples/s | 70.3 steps/s
[Step=83700 Epoch=163.6] | Loss=0.00559 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=15.246 | 4360.8 samples/s | 68.1 steps/s
[Step=83750 Epoch=163.7] | Loss=0.00557 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=15.248 | 4430.2 samples/s | 69.2 steps/s
[Step=83800 Epoch=163.8] | Loss=0.00553 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.250 | 4488.1 samples/s | 70.1 steps/s
[Step=83850 Epoch=163.9] | Loss=0.00551 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.252 | 4479.5 samples/s | 70.0 steps/s
[Step=83900 Epoch=164.0] | Loss=0.00548 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.255 | 4459.7 samples/s | 69.7 steps/s
[Step=83950 Epoch=164.1] | Loss=0.00547 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.257 | 4495.5 samples/s | 70.2 steps/s
[Step=84000 Epoch=164.2] | Loss=0.00544 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.259 | 4459.0 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step84000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=314.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.952 | L2-Norm(final)=9.051 | 6527.2 samples/s | 102.0 steps/s
[Step=82050 Epoch=314.4] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.952 | L2-Norm(final)=9.053 | 3914.6 samples/s | 61.2 steps/s
[Step=82100 Epoch=314.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.054 | 4808.2 samples/s | 75.1 steps/s
[Step=82150 Epoch=314.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.055 | 4859.6 samples/s | 75.9 steps/s
[Step=82200 Epoch=315.0] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.057 | 4569.0 samples/s | 71.4 steps/s
[Step=82250 Epoch=315.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.058 | 6711.0 samples/s | 104.9 steps/s
[Step=82300 Epoch=315.3] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.059 | 2412.7 samples/s | 37.7 steps/s
[Step=82350 Epoch=315.5] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.061 | 4704.6 samples/s | 73.5 steps/s
[Step=82400 Epoch=315.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.062 | 4836.6 samples/s | 75.6 steps/s
[Step=82450 Epoch=315.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.064 | 4533.4 samples/s | 70.8 steps/s
[Step=82500 Epoch=316.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.065 | 5500.0 samples/s | 85.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=316.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.957 | L2-Norm(final)=9.079 | 5571.3 samples/s | 87.1 steps/s
[Step=82550 Epoch=316.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.956 | L2-Norm(final)=9.080 | 4000.5 samples/s | 62.5 steps/s
[Step=82600 Epoch=316.5] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.955 | L2-Norm(final)=9.081 | 4338.9 samples/s | 67.8 steps/s
[Step=82650 Epoch=316.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.083 | 4289.3 samples/s | 67.0 steps/s
[Step=82700 Epoch=316.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.953 | L2-Norm(final)=9.084 | 4184.7 samples/s | 65.4 steps/s
[Step=82750 Epoch=317.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.952 | L2-Norm(final)=9.085 | 5721.3 samples/s | 89.4 steps/s
[Step=82800 Epoch=317.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.951 | L2-Norm(final)=9.087 | 2243.3 samples/s | 35.1 steps/s
[Step=82850 Epoch=317.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=9.088 | 4225.7 samples/s | 66.0 steps/s
[Step=82900 Epoch=317.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.949 | L2-Norm(final)=9.089 | 4229.1 samples/s | 66.1 steps/s
[Step=82950 Epoch=317.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.948 | L2-Norm(final)=9.090 | 4206.0 samples/s | 65.7 steps/s
[Step=83000 Epoch=318.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=9.091 | 4817.7 samples/s | 75.3 steps/s
[Step=83050 Epoch=318.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.945 | L2-Norm(final)=9.092 | 2434.4 samples/s | 38.0 steps/s
[Step=83100 Epoch=318.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=9.093 | 4226.5 samples/s | 66.0 steps/s
[Step=83150 Epoch=318.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=9.094 | 4147.7 samples/s | 64.8 steps/s
[Step=83200 Epoch=318.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.940 | L2-Norm(final)=9.094 | 4353.8 samples/s | 68.0 steps/s
[Step=83250 Epoch=319.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=9.095 | 4085.2 samples/s | 63.8 steps/s
[Step=83300 Epoch=319.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.096 | 2619.3 samples/s | 40.9 steps/s
[Step=83350 Epoch=319.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=9.097 | 4338.3 samples/s | 67.8 steps/s
[Step=83400 Epoch=319.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.098 | 4155.9 samples/s | 64.9 steps/s
[Step=83450 Epoch=319.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.099 | 4315.0 samples/s | 67.4 steps/s
[Step=83500 Epoch=319.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.100 | 4089.8 samples/s | 63.9 steps/s
[Step=83550 Epoch=320.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.100 | 2619.2 samples/s | 40.9 steps/s
[Step=83600 Epoch=320.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.101 | 4265.8 samples/s | 66.7 steps/s
[Step=83650 Epoch=320.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.102 | 4186.9 samples/s | 65.4 steps/s
[Step=83700 Epoch=320.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.922 | L2-Norm(final)=9.103 | 4291.6 samples/s | 67.1 steps/s
[Step=83750 Epoch=320.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.920 | L2-Norm(final)=9.104 | 4184.0 samples/s | 65.4 steps/s
[Step=83800 Epoch=321.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.918 | L2-Norm(final)=9.105 | 6314.0 samples/s | 98.7 steps/s
[Step=83850 Epoch=321.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.915 | L2-Norm(final)=9.105 | 2164.5 samples/s | 33.8 steps/s
[Step=83900 Epoch=321.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.913 | L2-Norm(final)=9.106 | 4187.6 samples/s | 65.4 steps/s
[Step=83950 Epoch=321.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.911 | L2-Norm(final)=9.107 | 4290.7 samples/s | 67.0 steps/s
[Step=84000 Epoch=321.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=9.108 | 4259.2 samples/s | 66.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step84000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=315.7] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.364 | 5269.4 samples/s | 82.3 steps/s
[Step=82050 Epoch=315.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.881 | L2-Norm(final)=10.365 | 4470.9 samples/s | 69.9 steps/s
[Step=82100 Epoch=316.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.881 | L2-Norm(final)=10.366 | 4661.4 samples/s | 72.8 steps/s
[Step=82150 Epoch=316.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.367 | 4702.6 samples/s | 73.5 steps/s
[Step=82200 Epoch=316.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.367 | 4631.0 samples/s | 72.4 steps/s
[Step=82250 Epoch=316.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.368 | 6804.5 samples/s | 106.3 steps/s
[Step=82300 Epoch=316.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.369 | 2393.0 samples/s | 37.4 steps/s
[Step=82350 Epoch=317.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.370 | 4882.2 samples/s | 76.3 steps/s
[Step=82400 Epoch=317.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.370 | 4729.0 samples/s | 73.9 steps/s
[Step=82450 Epoch=317.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.371 | 4633.8 samples/s | 72.4 steps/s
[Step=82500 Epoch=317.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.372 | 5693.1 samples/s | 89.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=317.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=10.380 | 6563.1 samples/s | 102.5 steps/s
[Step=82550 Epoch=317.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.380 | 3555.5 samples/s | 55.6 steps/s
[Step=82600 Epoch=318.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.881 | L2-Norm(final)=10.381 | 4203.6 samples/s | 65.7 steps/s
[Step=82650 Epoch=318.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.880 | L2-Norm(final)=10.382 | 4206.0 samples/s | 65.7 steps/s
[Step=82700 Epoch=318.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.879 | L2-Norm(final)=10.383 | 4247.4 samples/s | 66.4 steps/s
[Step=82750 Epoch=318.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.878 | L2-Norm(final)=10.383 | 5777.8 samples/s | 90.3 steps/s
[Step=82800 Epoch=318.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=10.384 | 2258.7 samples/s | 35.3 steps/s
[Step=82850 Epoch=318.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.876 | L2-Norm(final)=10.385 | 4236.9 samples/s | 66.2 steps/s
[Step=82900 Epoch=319.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.875 | L2-Norm(final)=10.385 | 4144.4 samples/s | 64.8 steps/s
[Step=82950 Epoch=319.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.873 | L2-Norm(final)=10.386 | 4165.4 samples/s | 65.1 steps/s
[Step=83000 Epoch=319.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.872 | L2-Norm(final)=10.387 | 4940.2 samples/s | 77.2 steps/s
[Step=83050 Epoch=319.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.871 | L2-Norm(final)=10.387 | 2436.6 samples/s | 38.1 steps/s
[Step=83100 Epoch=319.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.869 | L2-Norm(final)=10.388 | 4136.7 samples/s | 64.6 steps/s
[Step=83150 Epoch=320.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=10.388 | 4306.1 samples/s | 67.3 steps/s
[Step=83200 Epoch=320.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.866 | L2-Norm(final)=10.389 | 4187.9 samples/s | 65.4 steps/s
[Step=83250 Epoch=320.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.865 | L2-Norm(final)=10.389 | 4322.2 samples/s | 67.5 steps/s
[Step=83300 Epoch=320.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.390 | 2589.0 samples/s | 40.5 steps/s
[Step=83350 Epoch=320.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.390 | 4269.0 samples/s | 66.7 steps/s
[Step=83400 Epoch=321.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.391 | 4229.4 samples/s | 66.1 steps/s
[Step=83450 Epoch=321.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.391 | 4286.9 samples/s | 67.0 steps/s
[Step=83500 Epoch=321.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.856 | L2-Norm(final)=10.392 | 4230.8 samples/s | 66.1 steps/s
[Step=83550 Epoch=321.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.392 | 2615.5 samples/s | 40.9 steps/s
[Step=83600 Epoch=321.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.393 | 4218.5 samples/s | 65.9 steps/s
[Step=83650 Epoch=322.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.851 | L2-Norm(final)=10.393 | 4156.6 samples/s | 64.9 steps/s
[Step=83700 Epoch=322.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.849 | L2-Norm(final)=10.394 | 4292.4 samples/s | 67.1 steps/s
[Step=83750 Epoch=322.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.847 | L2-Norm(final)=10.394 | 4173.7 samples/s | 65.2 steps/s
[Step=83800 Epoch=322.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.845 | L2-Norm(final)=10.395 | 7003.7 samples/s | 109.4 steps/s
[Step=83850 Epoch=322.8] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.843 | L2-Norm(final)=10.395 | 2110.7 samples/s | 33.0 steps/s
[Step=83900 Epoch=323.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=10.396 | 4256.2 samples/s | 66.5 steps/s
[Step=83950 Epoch=323.2] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.839 | L2-Norm(final)=10.396 | 4213.8 samples/s | 65.8 steps/s
[Step=84000 Epoch=323.3] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.837 | L2-Norm(final)=10.397 | 4216.8 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06995 | acc=0.9670 | tpr=0.9764 | fpr=0.0535 | 4677.3 samples/s | 18.3 steps/s
Avg test loss: 0.07170, Avg test acc: 0.96598, Avg tpr: 0.97523, Avg fpr: 0.05435, total FA: 424

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06830 | acc=0.9677 | tpr=0.9759 | fpr=0.0500 | 4891.8 samples/s | 19.1 steps/s
Avg test loss: 0.07106, Avg test acc: 0.96714, Avg tpr: 0.97546, Avg fpr: 0.05115, total FA: 399

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.12416 | acc=0.3049 | tpr=0.0095 | fpr=0.0535 | 4855.8 samples/s | 19.0 steps/s
Avg test loss: 5.12116, Avg test acc: 0.30195, Avg tpr: 0.01072, Avg fpr: 0.05756, total FA: 449

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.49243 | acc=0.3077 | tpr=0.0149 | fpr=0.0565 | 5046.8 samples/s | 19.7 steps/s
Avg test loss: 5.48369, Avg test acc: 0.30591, Avg tpr: 0.01789, Avg fpr: 0.06063, total FA: 473

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.73974 | acc=0.1441 | tpr=0.5177 | fpr=0.8626 | 5082.6 samples/s | 19.9 steps/s
[Step= 100] | Loss=5.71353 | acc=0.1441 | tpr=0.4819 | fpr=0.8622 | 6706.8 samples/s | 26.2 steps/s
[Step= 150] | Loss=5.71351 | acc=0.1449 | tpr=0.4798 | fpr=0.8613 | 7957.8 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.71201 | acc=0.1452 | tpr=0.4765 | fpr=0.8608 | 7718.2 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.70229 | acc=0.1455 | tpr=0.4908 | fpr=0.8608 | 8064.7 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.69613 | acc=0.1452 | tpr=0.4858 | fpr=0.8611 | 7831.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.70007 | acc=0.1448 | tpr=0.4790 | fpr=0.8613 | 8052.9 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.69782 | acc=0.1454 | tpr=0.4770 | fpr=0.8606 | 7705.3 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.70108 | acc=0.1451 | tpr=0.4737 | fpr=0.8609 | 7911.4 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.70409 | acc=0.1453 | tpr=0.4744 | fpr=0.8607 | 7452.0 samples/s | 29.1 steps/s
[Step= 550] | Loss=5.70538 | acc=0.1456 | tpr=0.4719 | fpr=0.8603 | 14507.2 samples/s | 56.7 steps/s
Avg test loss: 5.70680, Avg test acc: 0.14548, Avg tpr: 0.47306, Avg fpr: 0.86047, total FA: 119475

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.29621 | acc=0.1367 | tpr=0.5531 | fpr=0.8708 | 4810.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.29057 | acc=0.1373 | tpr=0.5117 | fpr=0.8697 | 7462.4 samples/s | 29.1 steps/s
[Step= 150] | Loss=6.29088 | acc=0.1378 | tpr=0.5130 | fpr=0.8691 | 7979.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=6.28675 | acc=0.1378 | tpr=0.5071 | fpr=0.8689 | 7704.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=6.27746 | acc=0.1386 | tpr=0.5092 | fpr=0.8682 | 7604.1 samples/s | 29.7 steps/s
[Step= 300] | Loss=6.27149 | acc=0.1388 | tpr=0.5120 | fpr=0.8680 | 8007.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=6.27597 | acc=0.1384 | tpr=0.5047 | fpr=0.8682 | 7587.3 samples/s | 29.6 steps/s
[Step= 400] | Loss=6.27246 | acc=0.1386 | tpr=0.5022 | fpr=0.8680 | 7948.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.27644 | acc=0.1382 | tpr=0.4981 | fpr=0.8683 | 8106.2 samples/s | 31.7 steps/s
[Step= 500] | Loss=6.27877 | acc=0.1385 | tpr=0.5009 | fpr=0.8680 | 7856.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.28081 | acc=0.1386 | tpr=0.4966 | fpr=0.8679 | 13418.9 samples/s | 52.4 steps/s
Avg test loss: 6.28280, Avg test acc: 0.13848, Avg tpr: 0.49762, Avg fpr: 0.86805, total FA: 120527

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11893 | acc=0.9773 | tpr=0.9558 | fpr=0.0223 | 5002.8 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.11952 | acc=0.9782 | tpr=0.9638 | fpr=0.0216 | 6822.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12480 | acc=0.9774 | tpr=0.9640 | fpr=0.0223 | 8142.5 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.12787 | acc=0.9774 | tpr=0.9639 | fpr=0.0223 | 7711.5 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.12553 | acc=0.9776 | tpr=0.9633 | fpr=0.0222 | 7581.0 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.12730 | acc=0.9772 | tpr=0.9636 | fpr=0.0226 | 8201.4 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.12749 | acc=0.9772 | tpr=0.9637 | fpr=0.0226 | 7757.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.12888 | acc=0.9772 | tpr=0.9628 | fpr=0.0226 | 7719.2 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.13139 | acc=0.9768 | tpr=0.9611 | fpr=0.0230 | 8043.2 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.13061 | acc=0.9769 | tpr=0.9617 | fpr=0.0229 | 7507.4 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.12938 | acc=0.9771 | tpr=0.9618 | fpr=0.0226 | 14435.7 samples/s | 56.4 steps/s
Avg test loss: 0.12922, Avg test acc: 0.97711, Avg tpr: 0.96157, Avg fpr: 0.02261, total FA: 3139

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11897 | acc=0.9776 | tpr=0.9558 | fpr=0.0220 | 5141.4 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.12051 | acc=0.9776 | tpr=0.9659 | fpr=0.0222 | 6882.4 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.12616 | acc=0.9769 | tpr=0.9654 | fpr=0.0229 | 7616.3 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.12894 | acc=0.9766 | tpr=0.9639 | fpr=0.0231 | 7926.0 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.12692 | acc=0.9768 | tpr=0.9633 | fpr=0.0229 | 7650.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.12872 | acc=0.9767 | tpr=0.9622 | fpr=0.0231 | 7997.0 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.12903 | acc=0.9765 | tpr=0.9637 | fpr=0.0232 | 7816.1 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.13031 | acc=0.9766 | tpr=0.9617 | fpr=0.0232 | 7927.7 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.13284 | acc=0.9762 | tpr=0.9591 | fpr=0.0235 | 7720.1 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.13223 | acc=0.9763 | tpr=0.9590 | fpr=0.0234 | 7837.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.13081 | acc=0.9766 | tpr=0.9594 | fpr=0.0231 | 14024.5 samples/s | 54.8 steps/s
Avg test loss: 0.13069, Avg test acc: 0.97661, Avg tpr: 0.95919, Avg fpr: 0.02307, total FA: 3203

server round 42/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=163.8] | Loss=0.00235 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.932 | L2-Norm(final)=15.254 | 5999.8 samples/s | 93.7 steps/s
[Step=84050 Epoch=163.9] | Loss=0.00608 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=15.256 | 4594.0 samples/s | 71.8 steps/s
[Step=84100 Epoch=164.0] | Loss=0.00535 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=15.260 | 5026.0 samples/s | 78.5 steps/s
[Step=84150 Epoch=164.1] | Loss=0.00530 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=15.263 | 5032.2 samples/s | 78.6 steps/s
[Step=84200 Epoch=164.2] | Loss=0.00511 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=15.266 | 5023.8 samples/s | 78.5 steps/s
[Step=84250 Epoch=164.3] | Loss=0.00518 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.934 | L2-Norm(final)=15.269 | 5013.0 samples/s | 78.3 steps/s
[Step=84300 Epoch=164.4] | Loss=0.00542 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.934 | L2-Norm(final)=15.273 | 5137.7 samples/s | 80.3 steps/s
[Step=84350 Epoch=164.5] | Loss=0.00535 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.934 | L2-Norm(final)=15.276 | 5045.5 samples/s | 78.8 steps/s
[Step=84400 Epoch=164.6] | Loss=0.00533 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=15.279 | 4943.8 samples/s | 77.2 steps/s
[Step=84450 Epoch=164.7] | Loss=0.00529 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=15.282 | 5127.6 samples/s | 80.1 steps/s
[Step=84500 Epoch=164.8] | Loss=0.00532 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=15.285 | 6607.3 samples/s | 103.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=164.8] | Loss=0.00435 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.938 | L2-Norm(final)=15.318 | 6657.9 samples/s | 104.0 steps/s
[Step=84550 Epoch=164.9] | Loss=0.00509 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.938 | L2-Norm(final)=15.321 | 3924.7 samples/s | 61.3 steps/s
[Step=84600 Epoch=165.0] | Loss=0.00583 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.940 | L2-Norm(final)=15.324 | 4436.6 samples/s | 69.3 steps/s
[Step=84650 Epoch=165.1] | Loss=0.00530 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.940 | L2-Norm(final)=15.327 | 4492.8 samples/s | 70.2 steps/s
[Step=84700 Epoch=165.2] | Loss=0.00545 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.941 | L2-Norm(final)=15.330 | 4478.7 samples/s | 70.0 steps/s
[Step=84750 Epoch=165.3] | Loss=0.00545 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.942 | L2-Norm(final)=15.333 | 4515.2 samples/s | 70.5 steps/s
[Step=84800 Epoch=165.4] | Loss=0.00559 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.943 | L2-Norm(final)=15.336 | 4481.2 samples/s | 70.0 steps/s
[Step=84850 Epoch=165.5] | Loss=0.00565 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=15.339 | 4422.1 samples/s | 69.1 steps/s
[Step=84900 Epoch=165.6] | Loss=0.00571 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=15.342 | 4395.7 samples/s | 68.7 steps/s
[Step=84950 Epoch=165.7] | Loss=0.00585 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.945 | L2-Norm(final)=15.345 | 4455.3 samples/s | 69.6 steps/s
[Step=85000 Epoch=165.8] | Loss=0.00590 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.946 | L2-Norm(final)=15.348 | 5810.6 samples/s | 90.8 steps/s
[Step=85050 Epoch=165.9] | Loss=0.00586 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.947 | L2-Norm(final)=15.351 | 2392.5 samples/s | 37.4 steps/s
[Step=85100 Epoch=166.0] | Loss=0.00575 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=15.353 | 4463.6 samples/s | 69.7 steps/s
[Step=85150 Epoch=166.1] | Loss=0.00561 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=15.356 | 4526.3 samples/s | 70.7 steps/s
[Step=85200 Epoch=166.2] | Loss=0.00554 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=15.359 | 4501.7 samples/s | 70.3 steps/s
[Step=85250 Epoch=166.3] | Loss=0.00554 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=15.361 | 4395.4 samples/s | 68.7 steps/s
[Step=85300 Epoch=166.4] | Loss=0.00553 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=15.364 | 4373.2 samples/s | 68.3 steps/s
[Step=85350 Epoch=166.5] | Loss=0.00554 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=15.366 | 4485.3 samples/s | 70.1 steps/s
[Step=85400 Epoch=166.6] | Loss=0.00555 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=15.369 | 4499.6 samples/s | 70.3 steps/s
[Step=85450 Epoch=166.7] | Loss=0.00561 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=15.371 | 4436.2 samples/s | 69.3 steps/s
[Step=85500 Epoch=166.8] | Loss=0.00559 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=15.374 | 4843.9 samples/s | 75.7 steps/s
[Step=85550 Epoch=166.9] | Loss=0.00553 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.376 | 2619.0 samples/s | 40.9 steps/s
[Step=85600 Epoch=167.0] | Loss=0.00546 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.379 | 4512.2 samples/s | 70.5 steps/s
[Step=85650 Epoch=167.1] | Loss=0.00542 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.381 | 4450.3 samples/s | 69.5 steps/s
[Step=85700 Epoch=167.1] | Loss=0.00540 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.383 | 4343.1 samples/s | 67.9 steps/s
[Step=85750 Epoch=167.2] | Loss=0.00537 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.386 | 4534.7 samples/s | 70.9 steps/s
[Step=85800 Epoch=167.3] | Loss=0.00540 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.950 | L2-Norm(final)=15.388 | 4467.1 samples/s | 69.8 steps/s
[Step=85850 Epoch=167.4] | Loss=0.00543 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.391 | 4472.1 samples/s | 69.9 steps/s
[Step=85900 Epoch=167.5] | Loss=0.00541 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=15.393 | 4446.6 samples/s | 69.5 steps/s
[Step=85950 Epoch=167.6] | Loss=0.00539 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=15.395 | 4477.2 samples/s | 70.0 steps/s
[Step=86000 Epoch=167.7] | Loss=0.00539 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=15.397 | 4488.4 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step86000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=164.2] | Loss=0.00507 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.108 | L2-Norm(final)=15.325 | 5954.9 samples/s | 93.0 steps/s
[Step=84050 Epoch=164.3] | Loss=0.00555 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=15.328 | 4634.4 samples/s | 72.4 steps/s
[Step=84100 Epoch=164.4] | Loss=0.00545 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=15.331 | 4925.8 samples/s | 77.0 steps/s
[Step=84150 Epoch=164.5] | Loss=0.00520 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.110 | L2-Norm(final)=15.334 | 5022.2 samples/s | 78.5 steps/s
[Step=84200 Epoch=164.6] | Loss=0.00530 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.110 | L2-Norm(final)=15.337 | 5241.9 samples/s | 81.9 steps/s
[Step=84250 Epoch=164.7] | Loss=0.00563 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.110 | L2-Norm(final)=15.340 | 4907.8 samples/s | 76.7 steps/s
[Step=84300 Epoch=164.8] | Loss=0.00521 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.111 | L2-Norm(final)=15.344 | 5059.0 samples/s | 79.0 steps/s
[Step=84350 Epoch=164.9] | Loss=0.00558 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.111 | L2-Norm(final)=15.347 | 5021.4 samples/s | 78.5 steps/s
[Step=84400 Epoch=165.0] | Loss=0.00568 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=15.350 | 5063.1 samples/s | 79.1 steps/s
[Step=84450 Epoch=165.1] | Loss=0.00552 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.112 | L2-Norm(final)=15.353 | 4972.6 samples/s | 77.7 steps/s
[Step=84500 Epoch=165.2] | Loss=0.00545 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.112 | L2-Norm(final)=15.356 | 6980.5 samples/s | 109.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=165.2] | Loss=0.00099 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.116 | L2-Norm(final)=15.389 | 6455.6 samples/s | 100.9 steps/s
[Step=84550 Epoch=165.3] | Loss=0.00571 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=15.392 | 3994.9 samples/s | 62.4 steps/s
[Step=84600 Epoch=165.4] | Loss=0.00541 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.119 | L2-Norm(final)=15.395 | 4415.5 samples/s | 69.0 steps/s
[Step=84650 Epoch=165.5] | Loss=0.00544 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=15.399 | 4525.3 samples/s | 70.7 steps/s
[Step=84700 Epoch=165.6] | Loss=0.00576 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=15.402 | 4407.1 samples/s | 68.9 steps/s
[Step=84750 Epoch=165.7] | Loss=0.00596 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=15.405 | 4546.6 samples/s | 71.0 steps/s
[Step=84800 Epoch=165.8] | Loss=0.00590 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=15.408 | 4527.7 samples/s | 70.7 steps/s
[Step=84850 Epoch=165.9] | Loss=0.00605 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=15.410 | 4407.3 samples/s | 68.9 steps/s
[Step=84900 Epoch=166.0] | Loss=0.00603 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=15.413 | 4405.0 samples/s | 68.8 steps/s
[Step=84950 Epoch=166.1] | Loss=0.00597 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=15.416 | 4439.4 samples/s | 69.4 steps/s
[Step=85000 Epoch=166.2] | Loss=0.00598 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.125 | L2-Norm(final)=15.418 | 5860.5 samples/s | 91.6 steps/s
[Step=85050 Epoch=166.3] | Loss=0.00579 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=15.421 | 2383.1 samples/s | 37.2 steps/s
[Step=85100 Epoch=166.4] | Loss=0.00569 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=15.424 | 4476.7 samples/s | 69.9 steps/s
[Step=85150 Epoch=166.5] | Loss=0.00569 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.127 | L2-Norm(final)=15.426 | 4469.1 samples/s | 69.8 steps/s
[Step=85200 Epoch=166.6] | Loss=0.00562 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=15.429 | 4438.1 samples/s | 69.3 steps/s
[Step=85250 Epoch=166.7] | Loss=0.00562 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=15.431 | 4591.2 samples/s | 71.7 steps/s
[Step=85300 Epoch=166.8] | Loss=0.00557 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.128 | L2-Norm(final)=15.434 | 4275.6 samples/s | 66.8 steps/s
[Step=85350 Epoch=166.9] | Loss=0.00548 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=15.436 | 4518.8 samples/s | 70.6 steps/s
[Step=85400 Epoch=167.0] | Loss=0.00549 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=15.439 | 4430.5 samples/s | 69.2 steps/s
[Step=85450 Epoch=167.1] | Loss=0.00552 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.441 | 4494.1 samples/s | 70.2 steps/s
[Step=85500 Epoch=167.2] | Loss=0.00553 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.443 | 4931.4 samples/s | 77.1 steps/s
[Step=85550 Epoch=167.2] | Loss=0.00546 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.446 | 2592.7 samples/s | 40.5 steps/s
[Step=85600 Epoch=167.3] | Loss=0.00542 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.448 | 4416.2 samples/s | 69.0 steps/s
[Step=85650 Epoch=167.4] | Loss=0.00539 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=15.450 | 4474.7 samples/s | 69.9 steps/s
[Step=85700 Epoch=167.5] | Loss=0.00533 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.453 | 4494.4 samples/s | 70.2 steps/s
[Step=85750 Epoch=167.6] | Loss=0.00529 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.455 | 4308.6 samples/s | 67.3 steps/s
[Step=85800 Epoch=167.7] | Loss=0.00528 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.130 | L2-Norm(final)=15.457 | 4490.6 samples/s | 70.2 steps/s
[Step=85850 Epoch=167.8] | Loss=0.00525 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.459 | 4579.8 samples/s | 71.6 steps/s
[Step=85900 Epoch=167.9] | Loss=0.00524 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.462 | 4383.1 samples/s | 68.5 steps/s
[Step=85950 Epoch=168.0] | Loss=0.00519 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.464 | 4458.2 samples/s | 69.7 steps/s
[Step=86000 Epoch=168.1] | Loss=0.00517 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.466 | 4573.1 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step86000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=321.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.132 | 5446.8 samples/s | 85.1 steps/s
[Step=84050 Epoch=322.0] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=9.134 | 4222.0 samples/s | 66.0 steps/s
[Step=84100 Epoch=322.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=9.137 | 4734.7 samples/s | 74.0 steps/s
[Step=84150 Epoch=322.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.140 | 4687.8 samples/s | 73.2 steps/s
[Step=84200 Epoch=322.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.143 | 4730.6 samples/s | 73.9 steps/s
[Step=84250 Epoch=322.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.145 | 6618.3 samples/s | 103.4 steps/s
[Step=84300 Epoch=323.0] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=9.148 | 2411.0 samples/s | 37.7 steps/s
[Step=84350 Epoch=323.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.151 | 4695.7 samples/s | 73.4 steps/s
[Step=84400 Epoch=323.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.154 | 4788.5 samples/s | 74.8 steps/s
[Step=84450 Epoch=323.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.157 | 4639.0 samples/s | 72.5 steps/s
[Step=84500 Epoch=323.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.159 | 5406.0 samples/s | 84.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=323.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.188 | 6149.4 samples/s | 96.1 steps/s
[Step=84550 Epoch=324.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=9.191 | 3816.7 samples/s | 59.6 steps/s
[Step=84600 Epoch=324.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.927 | L2-Norm(final)=9.194 | 4230.8 samples/s | 66.1 steps/s
[Step=84650 Epoch=324.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=9.196 | 4234.0 samples/s | 66.2 steps/s
[Step=84700 Epoch=324.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.921 | L2-Norm(final)=9.198 | 4216.1 samples/s | 65.9 steps/s
[Step=84750 Epoch=324.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.918 | L2-Norm(final)=9.200 | 5694.0 samples/s | 89.0 steps/s
[Step=84800 Epoch=324.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.915 | L2-Norm(final)=9.202 | 2253.0 samples/s | 35.2 steps/s
[Step=84850 Epoch=325.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.911 | L2-Norm(final)=9.204 | 4261.2 samples/s | 66.6 steps/s
[Step=84900 Epoch=325.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.907 | L2-Norm(final)=9.206 | 4297.7 samples/s | 67.2 steps/s
[Step=84950 Epoch=325.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.903 | L2-Norm(final)=9.207 | 4124.2 samples/s | 64.4 steps/s
[Step=85000 Epoch=325.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.899 | L2-Norm(final)=9.209 | 4820.6 samples/s | 75.3 steps/s
[Step=85050 Epoch=325.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.895 | L2-Norm(final)=9.210 | 2447.2 samples/s | 38.2 steps/s
[Step=85100 Epoch=326.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.891 | L2-Norm(final)=9.212 | 4305.7 samples/s | 67.3 steps/s
[Step=85150 Epoch=326.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=9.213 | 4122.9 samples/s | 64.4 steps/s
[Step=85200 Epoch=326.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=9.215 | 4189.6 samples/s | 65.5 steps/s
[Step=85250 Epoch=326.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.878 | L2-Norm(final)=9.216 | 4168.5 samples/s | 65.1 steps/s
[Step=85300 Epoch=326.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.873 | L2-Norm(final)=9.217 | 2635.4 samples/s | 41.2 steps/s
[Step=85350 Epoch=327.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=9.219 | 4220.5 samples/s | 65.9 steps/s
[Step=85400 Epoch=327.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=9.220 | 4271.8 samples/s | 66.7 steps/s
[Step=85450 Epoch=327.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=9.221 | 4216.5 samples/s | 65.9 steps/s
[Step=85500 Epoch=327.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=9.223 | 4290.4 samples/s | 67.0 steps/s
[Step=85550 Epoch=327.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.849 | L2-Norm(final)=9.224 | 2618.7 samples/s | 40.9 steps/s
[Step=85600 Epoch=328.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.844 | L2-Norm(final)=9.225 | 4145.8 samples/s | 64.8 steps/s
[Step=85650 Epoch=328.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.838 | L2-Norm(final)=9.226 | 4296.9 samples/s | 67.1 steps/s
[Step=85700 Epoch=328.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.833 | L2-Norm(final)=9.228 | 4246.6 samples/s | 66.4 steps/s
[Step=85750 Epoch=328.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.828 | L2-Norm(final)=9.229 | 4275.8 samples/s | 66.8 steps/s
[Step=85800 Epoch=328.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.822 | L2-Norm(final)=9.230 | 6283.3 samples/s | 98.2 steps/s
[Step=85850 Epoch=328.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.817 | L2-Norm(final)=9.232 | 2198.1 samples/s | 34.3 steps/s
[Step=85900 Epoch=329.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.811 | L2-Norm(final)=9.233 | 4094.2 samples/s | 64.0 steps/s
[Step=85950 Epoch=329.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=9.234 | 4209.7 samples/s | 65.8 steps/s
[Step=86000 Epoch=329.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.800 | L2-Norm(final)=9.236 | 4233.7 samples/s | 66.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step86000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=323.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.413 | 6668.7 samples/s | 104.2 steps/s
[Step=84050 Epoch=323.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.415 | 4193.7 samples/s | 65.5 steps/s
[Step=84100 Epoch=323.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.416 | 4718.5 samples/s | 73.7 steps/s
[Step=84150 Epoch=323.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.418 | 4784.7 samples/s | 74.8 steps/s
[Step=84200 Epoch=324.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.420 | 4766.9 samples/s | 74.5 steps/s
[Step=84250 Epoch=324.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.422 | 6511.7 samples/s | 101.7 steps/s
[Step=84300 Epoch=324.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.424 | 2390.1 samples/s | 37.3 steps/s
[Step=84350 Epoch=324.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.425 | 4746.5 samples/s | 74.2 steps/s
[Step=84400 Epoch=324.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.427 | 4725.2 samples/s | 73.8 steps/s
[Step=84450 Epoch=325.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.429 | 4735.7 samples/s | 74.0 steps/s
[Step=84500 Epoch=325.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.431 | 5693.9 samples/s | 89.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=325.3] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.857 | L2-Norm(final)=10.449 | 6202.1 samples/s | 96.9 steps/s
[Step=84550 Epoch=325.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.451 | 3829.2 samples/s | 59.8 steps/s
[Step=84600 Epoch=325.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.453 | 4088.9 samples/s | 63.9 steps/s
[Step=84650 Epoch=325.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.850 | L2-Norm(final)=10.454 | 4260.7 samples/s | 66.6 steps/s
[Step=84700 Epoch=326.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.847 | L2-Norm(final)=10.456 | 4229.3 samples/s | 66.1 steps/s
[Step=84750 Epoch=326.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.844 | L2-Norm(final)=10.457 | 5733.5 samples/s | 89.6 steps/s
[Step=84800 Epoch=326.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=10.458 | 2258.5 samples/s | 35.3 steps/s
[Step=84850 Epoch=326.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.838 | L2-Norm(final)=10.460 | 4276.5 samples/s | 66.8 steps/s
[Step=84900 Epoch=326.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=10.461 | 4303.7 samples/s | 67.2 steps/s
[Step=84950 Epoch=327.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=10.462 | 4143.1 samples/s | 64.7 steps/s
[Step=85000 Epoch=327.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.827 | L2-Norm(final)=10.463 | 4926.9 samples/s | 77.0 steps/s
[Step=85050 Epoch=327.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.823 | L2-Norm(final)=10.464 | 2423.1 samples/s | 37.9 steps/s
[Step=85100 Epoch=327.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.819 | L2-Norm(final)=10.465 | 4321.8 samples/s | 67.5 steps/s
[Step=85150 Epoch=327.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.815 | L2-Norm(final)=10.466 | 4117.0 samples/s | 64.3 steps/s
[Step=85200 Epoch=328.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.811 | L2-Norm(final)=10.467 | 4376.5 samples/s | 68.4 steps/s
[Step=85250 Epoch=328.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.807 | L2-Norm(final)=10.468 | 4206.3 samples/s | 65.7 steps/s
[Step=85300 Epoch=328.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.803 | L2-Norm(final)=10.469 | 2574.8 samples/s | 40.2 steps/s
[Step=85350 Epoch=328.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.799 | L2-Norm(final)=10.470 | 4242.6 samples/s | 66.3 steps/s
[Step=85400 Epoch=328.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.794 | L2-Norm(final)=10.471 | 4171.3 samples/s | 65.2 steps/s
[Step=85450 Epoch=328.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.790 | L2-Norm(final)=10.472 | 4242.4 samples/s | 66.3 steps/s
[Step=85500 Epoch=329.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.786 | L2-Norm(final)=10.473 | 4309.9 samples/s | 67.3 steps/s
[Step=85550 Epoch=329.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.781 | L2-Norm(final)=10.474 | 2631.0 samples/s | 41.1 steps/s
[Step=85600 Epoch=329.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.777 | L2-Norm(final)=10.476 | 4207.8 samples/s | 65.7 steps/s
[Step=85650 Epoch=329.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.772 | L2-Norm(final)=10.477 | 4172.1 samples/s | 65.2 steps/s
[Step=85700 Epoch=329.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.767 | L2-Norm(final)=10.478 | 4165.8 samples/s | 65.1 steps/s
[Step=85750 Epoch=330.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.479 | 4204.4 samples/s | 65.7 steps/s
[Step=85800 Epoch=330.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.758 | L2-Norm(final)=10.480 | 7043.1 samples/s | 110.0 steps/s
[Step=85850 Epoch=330.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.753 | L2-Norm(final)=10.481 | 2121.5 samples/s | 33.1 steps/s
[Step=85900 Epoch=330.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.748 | L2-Norm(final)=10.482 | 4209.6 samples/s | 65.8 steps/s
[Step=85950 Epoch=330.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.743 | L2-Norm(final)=10.483 | 4215.2 samples/s | 65.9 steps/s
[Step=86000 Epoch=331.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.738 | L2-Norm(final)=10.484 | 4359.7 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07125 | acc=0.9657 | tpr=0.9702 | fpr=0.0441 | 4863.2 samples/s | 19.0 steps/s
Avg test loss: 0.07270, Avg test acc: 0.96470, Avg tpr: 0.96940, Avg fpr: 0.04564, total FA: 356

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06958 | acc=0.9667 | tpr=0.9726 | fpr=0.0461 | 5044.4 samples/s | 19.7 steps/s
Avg test loss: 0.07300, Avg test acc: 0.96582, Avg tpr: 0.97208, Avg fpr: 0.04794, total FA: 374

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.23230 | acc=0.3053 | tpr=0.0096 | fpr=0.0525 | 5054.5 samples/s | 19.7 steps/s
Avg test loss: 5.22932, Avg test acc: 0.30263, Avg tpr: 0.01084, Avg fpr: 0.05563, total FA: 434

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.47350 | acc=0.3082 | tpr=0.0145 | fpr=0.0540 | 4983.4 samples/s | 19.5 steps/s
Avg test loss: 5.46300, Avg test acc: 0.30647, Avg tpr: 0.01743, Avg fpr: 0.05781, total FA: 451

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.49957 | acc=0.1579 | tpr=0.4779 | fpr=0.8479 | 4849.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.47608 | acc=0.1580 | tpr=0.4414 | fpr=0.8472 | 7106.2 samples/s | 27.8 steps/s
[Step= 150] | Loss=5.47588 | acc=0.1591 | tpr=0.4395 | fpr=0.8461 | 8177.1 samples/s | 31.9 steps/s
[Step= 200] | Loss=5.47394 | acc=0.1597 | tpr=0.4372 | fpr=0.8453 | 7617.2 samples/s | 29.8 steps/s
[Step= 250] | Loss=5.46505 | acc=0.1601 | tpr=0.4463 | fpr=0.8452 | 7836.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=5.45942 | acc=0.1596 | tpr=0.4415 | fpr=0.8456 | 7869.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.46297 | acc=0.1594 | tpr=0.4321 | fpr=0.8456 | 7765.4 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.46101 | acc=0.1598 | tpr=0.4267 | fpr=0.8450 | 7869.3 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.46422 | acc=0.1595 | tpr=0.4216 | fpr=0.8453 | 7550.9 samples/s | 29.5 steps/s
[Step= 500] | Loss=5.46719 | acc=0.1597 | tpr=0.4229 | fpr=0.8451 | 8385.5 samples/s | 32.8 steps/s
[Step= 550] | Loss=5.46885 | acc=0.1600 | tpr=0.4210 | fpr=0.8448 | 13544.6 samples/s | 52.9 steps/s
Avg test loss: 5.47036, Avg test acc: 0.15981, Avg tpr: 0.42235, Avg fpr: 0.84497, total FA: 117322

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.33336 | acc=0.1391 | tpr=0.5531 | fpr=0.8683 | 5033.9 samples/s | 19.7 steps/s
[Step= 100] | Loss=6.32493 | acc=0.1393 | tpr=0.5075 | fpr=0.8675 | 6931.1 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.32387 | acc=0.1397 | tpr=0.5058 | fpr=0.8670 | 7917.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.31970 | acc=0.1398 | tpr=0.5038 | fpr=0.8668 | 7760.9 samples/s | 30.3 steps/s
[Step= 250] | Loss=6.31117 | acc=0.1407 | tpr=0.5057 | fpr=0.8660 | 7489.7 samples/s | 29.3 steps/s
[Step= 300] | Loss=6.30576 | acc=0.1410 | tpr=0.5062 | fpr=0.8656 | 8133.6 samples/s | 31.8 steps/s
[Step= 350] | Loss=6.31033 | acc=0.1408 | tpr=0.4997 | fpr=0.8657 | 7944.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=6.30650 | acc=0.1408 | tpr=0.4956 | fpr=0.8657 | 7724.2 samples/s | 30.2 steps/s
[Step= 450] | Loss=6.31101 | acc=0.1405 | tpr=0.4912 | fpr=0.8658 | 7578.0 samples/s | 29.6 steps/s
[Step= 500] | Loss=6.31329 | acc=0.1410 | tpr=0.4956 | fpr=0.8654 | 8153.6 samples/s | 31.9 steps/s
[Step= 550] | Loss=6.31573 | acc=0.1410 | tpr=0.4922 | fpr=0.8654 | 13583.3 samples/s | 53.1 steps/s
Avg test loss: 6.31761, Avg test acc: 0.14085, Avg tpr: 0.49287, Avg fpr: 0.86555, total FA: 120180

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12032 | acc=0.9772 | tpr=0.9602 | fpr=0.0225 | 4993.8 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.12105 | acc=0.9779 | tpr=0.9680 | fpr=0.0219 | 6809.4 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12645 | acc=0.9772 | tpr=0.9669 | fpr=0.0226 | 8148.4 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.12958 | acc=0.9771 | tpr=0.9650 | fpr=0.0227 | 7559.8 samples/s | 29.5 steps/s
[Step= 250] | Loss=0.12726 | acc=0.9773 | tpr=0.9651 | fpr=0.0224 | 8114.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.12910 | acc=0.9770 | tpr=0.9651 | fpr=0.0228 | 7627.9 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.12930 | acc=0.9769 | tpr=0.9649 | fpr=0.0229 | 7874.9 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.13073 | acc=0.9769 | tpr=0.9639 | fpr=0.0228 | 7846.4 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.13329 | acc=0.9766 | tpr=0.9615 | fpr=0.0232 | 7848.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.13250 | acc=0.9767 | tpr=0.9621 | fpr=0.0230 | 7809.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13127 | acc=0.9769 | tpr=0.9622 | fpr=0.0228 | 13963.9 samples/s | 54.5 steps/s
Avg test loss: 0.13110, Avg test acc: 0.97695, Avg tpr: 0.96197, Avg fpr: 0.02277, total FA: 3162

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11805 | acc=0.9772 | tpr=0.9513 | fpr=0.0223 | 4864.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.12000 | acc=0.9774 | tpr=0.9638 | fpr=0.0224 | 6972.8 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.12566 | acc=0.9768 | tpr=0.9654 | fpr=0.0230 | 8071.6 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.12847 | acc=0.9764 | tpr=0.9639 | fpr=0.0234 | 8198.8 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.12644 | acc=0.9767 | tpr=0.9642 | fpr=0.0231 | 7546.4 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.12828 | acc=0.9764 | tpr=0.9622 | fpr=0.0233 | 8073.1 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.12865 | acc=0.9762 | tpr=0.9637 | fpr=0.0235 | 7647.9 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.12990 | acc=0.9763 | tpr=0.9628 | fpr=0.0235 | 8003.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.13238 | acc=0.9759 | tpr=0.9606 | fpr=0.0239 | 7753.0 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13177 | acc=0.9760 | tpr=0.9604 | fpr=0.0237 | 7713.2 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.13039 | acc=0.9763 | tpr=0.9606 | fpr=0.0234 | 13786.9 samples/s | 53.9 steps/s
Avg test loss: 0.13028, Avg test acc: 0.97635, Avg tpr: 0.96038, Avg fpr: 0.02336, total FA: 3243

server round 43/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=167.7] | Loss=0.00180 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.879 | L2-Norm(final)=15.465 | 6202.5 samples/s | 96.9 steps/s
[Step=86050 Epoch=167.8] | Loss=0.00554 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=15.468 | 4614.4 samples/s | 72.1 steps/s
[Step=86100 Epoch=167.9] | Loss=0.00554 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=15.472 | 4950.7 samples/s | 77.4 steps/s
[Step=86150 Epoch=168.0] | Loss=0.00587 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.879 | L2-Norm(final)=15.475 | 4981.6 samples/s | 77.8 steps/s
[Step=86200 Epoch=168.1] | Loss=0.00599 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=15.479 | 5090.9 samples/s | 79.5 steps/s
[Step=86250 Epoch=168.2] | Loss=0.00607 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.880 | L2-Norm(final)=15.483 | 4897.8 samples/s | 76.5 steps/s
[Step=86300 Epoch=168.3] | Loss=0.00609 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=15.487 | 5164.5 samples/s | 80.7 steps/s
[Step=86350 Epoch=168.4] | Loss=0.00590 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=15.490 | 4942.9 samples/s | 77.2 steps/s
[Step=86400 Epoch=168.5] | Loss=0.00603 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=15.494 | 4959.8 samples/s | 77.5 steps/s
[Step=86450 Epoch=168.6] | Loss=0.00609 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.883 | L2-Norm(final)=15.497 | 5046.4 samples/s | 78.8 steps/s
[Step=86500 Epoch=168.7] | Loss=0.00598 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.883 | L2-Norm(final)=15.500 | 6733.6 samples/s | 105.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=168.7] | Loss=0.00749 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.888 | L2-Norm(final)=15.535 | 6220.3 samples/s | 97.2 steps/s
[Step=86550 Epoch=168.8] | Loss=0.00604 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.889 | L2-Norm(final)=15.539 | 4081.6 samples/s | 63.8 steps/s
[Step=86600 Epoch=168.9] | Loss=0.00666 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.891 | L2-Norm(final)=15.542 | 4384.8 samples/s | 68.5 steps/s
[Step=86650 Epoch=169.0] | Loss=0.00670 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=15.545 | 4483.3 samples/s | 70.1 steps/s
[Step=86700 Epoch=169.1] | Loss=0.00651 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.893 | L2-Norm(final)=15.548 | 4434.9 samples/s | 69.3 steps/s
[Step=86750 Epoch=169.2] | Loss=0.00664 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=15.551 | 4521.6 samples/s | 70.7 steps/s
[Step=86800 Epoch=169.3] | Loss=0.00662 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.895 | L2-Norm(final)=15.554 | 4450.1 samples/s | 69.5 steps/s
[Step=86850 Epoch=169.4] | Loss=0.00650 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.896 | L2-Norm(final)=15.557 | 4439.4 samples/s | 69.4 steps/s
[Step=86900 Epoch=169.5] | Loss=0.00640 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.897 | L2-Norm(final)=15.559 | 4492.0 samples/s | 70.2 steps/s
[Step=86950 Epoch=169.6] | Loss=0.00632 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=15.562 | 4434.2 samples/s | 69.3 steps/s
[Step=87000 Epoch=169.7] | Loss=0.00635 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.899 | L2-Norm(final)=15.565 | 5681.9 samples/s | 88.8 steps/s
[Step=87050 Epoch=169.8] | Loss=0.00627 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.900 | L2-Norm(final)=15.568 | 2403.8 samples/s | 37.6 steps/s
[Step=87100 Epoch=169.9] | Loss=0.00609 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.901 | L2-Norm(final)=15.570 | 4440.2 samples/s | 69.4 steps/s
[Step=87150 Epoch=170.0] | Loss=0.00595 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.901 | L2-Norm(final)=15.573 | 4465.1 samples/s | 69.8 steps/s
[Step=87200 Epoch=170.1] | Loss=0.00594 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=15.575 | 4450.3 samples/s | 69.5 steps/s
[Step=87250 Epoch=170.2] | Loss=0.00587 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=15.578 | 4553.9 samples/s | 71.2 steps/s
[Step=87300 Epoch=170.3] | Loss=0.00592 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=15.580 | 4419.5 samples/s | 69.1 steps/s
[Step=87350 Epoch=170.4] | Loss=0.00588 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=15.583 | 4393.1 samples/s | 68.6 steps/s
[Step=87400 Epoch=170.5] | Loss=0.00577 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=15.585 | 4442.9 samples/s | 69.4 steps/s
[Step=87450 Epoch=170.6] | Loss=0.00581 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=15.588 | 4451.6 samples/s | 69.6 steps/s
[Step=87500 Epoch=170.7] | Loss=0.00578 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=15.590 | 4823.4 samples/s | 75.4 steps/s
[Step=87550 Epoch=170.8] | Loss=0.00578 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=15.593 | 2617.6 samples/s | 40.9 steps/s
[Step=87600 Epoch=170.9] | Loss=0.00573 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=15.595 | 4444.5 samples/s | 69.4 steps/s
[Step=87650 Epoch=171.0] | Loss=0.00569 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.905 | L2-Norm(final)=15.597 | 4602.5 samples/s | 71.9 steps/s
[Step=87700 Epoch=171.0] | Loss=0.00565 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=15.600 | 4332.1 samples/s | 67.7 steps/s
[Step=87750 Epoch=171.1] | Loss=0.00564 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=15.602 | 4522.3 samples/s | 70.7 steps/s
[Step=87800 Epoch=171.2] | Loss=0.00556 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=15.604 | 4330.2 samples/s | 67.7 steps/s
[Step=87850 Epoch=171.3] | Loss=0.00558 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=15.606 | 4475.4 samples/s | 69.9 steps/s
[Step=87900 Epoch=171.4] | Loss=0.00550 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=15.608 | 4506.6 samples/s | 70.4 steps/s
[Step=87950 Epoch=171.5] | Loss=0.00551 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=15.611 | 4440.8 samples/s | 69.4 steps/s
[Step=88000 Epoch=171.6] | Loss=0.00552 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.906 | L2-Norm(final)=15.613 | 4484.6 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step88000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=168.1] | Loss=0.00579 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.057 | L2-Norm(final)=15.533 | 5241.7 samples/s | 81.9 steps/s
[Step=86050 Epoch=168.2] | Loss=0.00604 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.058 | L2-Norm(final)=15.536 | 4773.8 samples/s | 74.6 steps/s
[Step=86100 Epoch=168.3] | Loss=0.00570 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=15.540 | 5103.2 samples/s | 79.7 steps/s
[Step=86150 Epoch=168.4] | Loss=0.00557 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.061 | L2-Norm(final)=15.544 | 4937.8 samples/s | 77.2 steps/s
[Step=86200 Epoch=168.5] | Loss=0.00553 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=15.547 | 4938.4 samples/s | 77.2 steps/s
[Step=86250 Epoch=168.6] | Loss=0.00569 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.063 | L2-Norm(final)=15.551 | 5130.7 samples/s | 80.2 steps/s
[Step=86300 Epoch=168.7] | Loss=0.00564 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.064 | L2-Norm(final)=15.555 | 4994.5 samples/s | 78.0 steps/s
[Step=86350 Epoch=168.8] | Loss=0.00568 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.065 | L2-Norm(final)=15.558 | 4956.2 samples/s | 77.4 steps/s
[Step=86400 Epoch=168.9] | Loss=0.00569 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=15.562 | 5090.8 samples/s | 79.5 steps/s
[Step=86450 Epoch=169.0] | Loss=0.00572 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=15.565 | 5146.1 samples/s | 80.4 steps/s
[Step=86500 Epoch=169.1] | Loss=0.00583 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.067 | L2-Norm(final)=15.568 | 6625.9 samples/s | 103.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=169.1] | Loss=0.01616 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.073 | L2-Norm(final)=15.601 | 6147.8 samples/s | 96.1 steps/s
[Step=86550 Epoch=169.2] | Loss=0.00563 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=15.605 | 4339.5 samples/s | 67.8 steps/s
[Step=86600 Epoch=169.3] | Loss=0.00543 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.077 | L2-Norm(final)=15.609 | 4412.4 samples/s | 68.9 steps/s
[Step=86650 Epoch=169.4] | Loss=0.00554 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=15.612 | 4580.4 samples/s | 71.6 steps/s
[Step=86700 Epoch=169.5] | Loss=0.00593 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=15.615 | 4383.0 samples/s | 68.5 steps/s
[Step=86750 Epoch=169.6] | Loss=0.00608 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.081 | L2-Norm(final)=15.618 | 4450.0 samples/s | 69.5 steps/s
[Step=86800 Epoch=169.7] | Loss=0.00623 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=15.621 | 4529.1 samples/s | 70.8 steps/s
[Step=86850 Epoch=169.8] | Loss=0.00619 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=15.623 | 4446.2 samples/s | 69.5 steps/s
[Step=86900 Epoch=169.9] | Loss=0.00621 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=15.626 | 4545.2 samples/s | 71.0 steps/s
[Step=86950 Epoch=170.0] | Loss=0.00616 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.085 | L2-Norm(final)=15.629 | 4401.2 samples/s | 68.8 steps/s
[Step=87000 Epoch=170.1] | Loss=0.00615 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.086 | L2-Norm(final)=15.632 | 5754.9 samples/s | 89.9 steps/s
[Step=87050 Epoch=170.2] | Loss=0.00611 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.087 | L2-Norm(final)=15.635 | 2378.2 samples/s | 37.2 steps/s
[Step=87100 Epoch=170.3] | Loss=0.00598 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.088 | L2-Norm(final)=15.637 | 4434.7 samples/s | 69.3 steps/s
[Step=87150 Epoch=170.4] | Loss=0.00602 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.088 | L2-Norm(final)=15.640 | 4492.3 samples/s | 70.2 steps/s
[Step=87200 Epoch=170.5] | Loss=0.00590 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=15.643 | 4482.0 samples/s | 70.0 steps/s
[Step=87250 Epoch=170.6] | Loss=0.00585 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.089 | L2-Norm(final)=15.645 | 4553.6 samples/s | 71.1 steps/s
[Step=87300 Epoch=170.7] | Loss=0.00586 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.090 | L2-Norm(final)=15.648 | 4455.7 samples/s | 69.6 steps/s
[Step=87350 Epoch=170.8] | Loss=0.00581 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.090 | L2-Norm(final)=15.650 | 4378.0 samples/s | 68.4 steps/s
[Step=87400 Epoch=170.9] | Loss=0.00578 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=15.652 | 4383.3 samples/s | 68.5 steps/s
[Step=87450 Epoch=171.0] | Loss=0.00573 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=15.655 | 4494.0 samples/s | 70.2 steps/s
[Step=87500 Epoch=171.1] | Loss=0.00562 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.092 | L2-Norm(final)=15.657 | 4936.2 samples/s | 77.1 steps/s
[Step=87550 Epoch=171.2] | Loss=0.00557 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.092 | L2-Norm(final)=15.660 | 2592.7 samples/s | 40.5 steps/s
[Step=87600 Epoch=171.3] | Loss=0.00548 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.092 | L2-Norm(final)=15.662 | 4408.3 samples/s | 68.9 steps/s
[Step=87650 Epoch=171.4] | Loss=0.00547 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.093 | L2-Norm(final)=15.664 | 4458.2 samples/s | 69.7 steps/s
[Step=87700 Epoch=171.5] | Loss=0.00549 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=15.667 | 4558.3 samples/s | 71.2 steps/s
[Step=87750 Epoch=171.5] | Loss=0.00546 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=15.669 | 4355.0 samples/s | 68.0 steps/s
[Step=87800 Epoch=171.6] | Loss=0.00541 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=15.671 | 4452.1 samples/s | 69.6 steps/s
[Step=87850 Epoch=171.7] | Loss=0.00539 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=15.673 | 4501.3 samples/s | 70.3 steps/s
[Step=87900 Epoch=171.8] | Loss=0.00537 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=15.676 | 4461.6 samples/s | 69.7 steps/s
[Step=87950 Epoch=171.9] | Loss=0.00538 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=15.678 | 4530.4 samples/s | 70.8 steps/s
[Step=88000 Epoch=172.0] | Loss=0.00537 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=15.680 | 4452.2 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step88000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=329.5] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.794 | L2-Norm(final)=9.276 | 6494.7 samples/s | 101.5 steps/s
[Step=86050 Epoch=329.7] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.793 | L2-Norm(final)=9.282 | 3937.9 samples/s | 61.5 steps/s
[Step=86100 Epoch=329.9] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.795 | L2-Norm(final)=9.288 | 4713.5 samples/s | 73.6 steps/s
[Step=86150 Epoch=330.1] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=9.295 | 4638.9 samples/s | 72.5 steps/s
[Step=86200 Epoch=330.3] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.798 | L2-Norm(final)=9.301 | 4723.1 samples/s | 73.8 steps/s
[Step=86250 Epoch=330.5] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.800 | L2-Norm(final)=9.307 | 6558.2 samples/s | 102.5 steps/s
[Step=86300 Epoch=330.7] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.801 | L2-Norm(final)=9.313 | 2440.3 samples/s | 38.1 steps/s
[Step=86350 Epoch=330.9] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.802 | L2-Norm(final)=9.318 | 4575.2 samples/s | 71.5 steps/s
[Step=86400 Epoch=331.1] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.803 | L2-Norm(final)=9.324 | 4774.7 samples/s | 74.6 steps/s
[Step=86450 Epoch=331.2] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.804 | L2-Norm(final)=9.329 | 4904.2 samples/s | 76.6 steps/s
[Step=86500 Epoch=331.4] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.805 | L2-Norm(final)=9.335 | 5240.8 samples/s | 81.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=331.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.814 | L2-Norm(final)=9.388 | 5935.5 samples/s | 92.7 steps/s
[Step=86550 Epoch=331.6] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.809 | L2-Norm(final)=9.393 | 3874.5 samples/s | 60.5 steps/s
[Step=86600 Epoch=331.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.803 | L2-Norm(final)=9.396 | 4170.0 samples/s | 65.2 steps/s
[Step=86650 Epoch=332.0] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.796 | L2-Norm(final)=9.400 | 4175.2 samples/s | 65.2 steps/s
[Step=86700 Epoch=332.2] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.788 | L2-Norm(final)=9.403 | 4232.4 samples/s | 66.1 steps/s
[Step=86750 Epoch=332.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.781 | L2-Norm(final)=9.406 | 5704.0 samples/s | 89.1 steps/s
[Step=86800 Epoch=332.6] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.772 | L2-Norm(final)=9.408 | 2300.5 samples/s | 35.9 steps/s
[Step=86850 Epoch=332.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.764 | L2-Norm(final)=9.410 | 4164.7 samples/s | 65.1 steps/s
[Step=86900 Epoch=333.0] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.755 | L2-Norm(final)=9.412 | 4161.8 samples/s | 65.0 steps/s
[Step=86950 Epoch=333.2] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.745 | L2-Norm(final)=9.414 | 4241.0 samples/s | 66.3 steps/s
[Step=87000 Epoch=333.4] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.736 | L2-Norm(final)=9.416 | 4818.3 samples/s | 75.3 steps/s
[Step=87050 Epoch=333.5] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.727 | L2-Norm(final)=9.418 | 2465.2 samples/s | 38.5 steps/s
[Step=87100 Epoch=333.7] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.717 | L2-Norm(final)=9.420 | 4294.5 samples/s | 67.1 steps/s
[Step=87150 Epoch=333.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.707 | L2-Norm(final)=9.422 | 4146.7 samples/s | 64.8 steps/s
[Step=87200 Epoch=334.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.697 | L2-Norm(final)=9.423 | 4238.8 samples/s | 66.2 steps/s
[Step=87250 Epoch=334.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.687 | L2-Norm(final)=9.425 | 4163.5 samples/s | 65.1 steps/s
[Step=87300 Epoch=334.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.677 | L2-Norm(final)=9.427 | 2670.3 samples/s | 41.7 steps/s
[Step=87350 Epoch=334.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.667 | L2-Norm(final)=9.429 | 4160.1 samples/s | 65.0 steps/s
[Step=87400 Epoch=334.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.656 | L2-Norm(final)=9.431 | 4176.1 samples/s | 65.3 steps/s
[Step=87450 Epoch=335.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.646 | L2-Norm(final)=9.432 | 4265.9 samples/s | 66.7 steps/s
[Step=87500 Epoch=335.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.635 | L2-Norm(final)=9.434 | 4145.9 samples/s | 64.8 steps/s
[Step=87550 Epoch=335.5] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.625 | L2-Norm(final)=9.436 | 2638.3 samples/s | 41.2 steps/s
[Step=87600 Epoch=335.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.614 | L2-Norm(final)=9.438 | 4158.2 samples/s | 65.0 steps/s
[Step=87650 Epoch=335.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.603 | L2-Norm(final)=9.440 | 4300.4 samples/s | 67.2 steps/s
[Step=87700 Epoch=336.0] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.592 | L2-Norm(final)=9.442 | 4225.6 samples/s | 66.0 steps/s
[Step=87750 Epoch=336.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.581 | L2-Norm(final)=9.444 | 4286.4 samples/s | 67.0 steps/s
[Step=87800 Epoch=336.4] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.570 | L2-Norm(final)=9.446 | 6151.3 samples/s | 96.1 steps/s
[Step=87850 Epoch=336.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.559 | L2-Norm(final)=9.448 | 2169.7 samples/s | 33.9 steps/s
[Step=87900 Epoch=336.8] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.548 | L2-Norm(final)=9.450 | 4289.8 samples/s | 67.0 steps/s
[Step=87950 Epoch=337.0] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.536 | L2-Norm(final)=9.452 | 4227.1 samples/s | 66.0 steps/s
[Step=88000 Epoch=337.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.525 | L2-Norm(final)=9.455 | 4093.8 samples/s | 64.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step88000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=331.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.732 | L2-Norm(final)=10.517 | 6133.4 samples/s | 95.8 steps/s
[Step=86050 Epoch=331.2] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.731 | L2-Norm(final)=10.521 | 3923.8 samples/s | 61.3 steps/s
[Step=86100 Epoch=331.4] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.732 | L2-Norm(final)=10.527 | 4924.3 samples/s | 76.9 steps/s
[Step=86150 Epoch=331.6] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.733 | L2-Norm(final)=10.532 | 4482.5 samples/s | 70.0 steps/s
[Step=86200 Epoch=331.8] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.734 | L2-Norm(final)=10.536 | 4718.8 samples/s | 73.7 steps/s
[Step=86250 Epoch=332.0] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.735 | L2-Norm(final)=10.541 | 6808.1 samples/s | 106.4 steps/s
[Step=86300 Epoch=332.2] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.736 | L2-Norm(final)=10.546 | 2372.4 samples/s | 37.1 steps/s
[Step=86350 Epoch=332.4] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.737 | L2-Norm(final)=10.550 | 4715.8 samples/s | 73.7 steps/s
[Step=86400 Epoch=332.6] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.738 | L2-Norm(final)=10.555 | 4727.9 samples/s | 73.9 steps/s
[Step=86450 Epoch=332.8] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.739 | L2-Norm(final)=10.559 | 4742.2 samples/s | 74.1 steps/s
[Step=86500 Epoch=333.0] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.740 | L2-Norm(final)=10.563 | 5635.2 samples/s | 88.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=333.0] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.746 | L2-Norm(final)=10.604 | 6233.1 samples/s | 97.4 steps/s
[Step=86550 Epoch=333.2] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.741 | L2-Norm(final)=10.607 | 3777.5 samples/s | 59.0 steps/s
[Step=86600 Epoch=333.4] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.734 | L2-Norm(final)=10.610 | 4203.0 samples/s | 65.7 steps/s
[Step=86650 Epoch=333.5] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.727 | L2-Norm(final)=10.613 | 4166.8 samples/s | 65.1 steps/s
[Step=86700 Epoch=333.7] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=10.615 | 4208.3 samples/s | 65.8 steps/s
[Step=86750 Epoch=333.9] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.712 | L2-Norm(final)=10.618 | 5839.4 samples/s | 91.2 steps/s
[Step=86800 Epoch=334.1] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.704 | L2-Norm(final)=10.620 | 2252.2 samples/s | 35.2 steps/s
[Step=86850 Epoch=334.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.696 | L2-Norm(final)=10.622 | 4244.5 samples/s | 66.3 steps/s
[Step=86900 Epoch=334.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.688 | L2-Norm(final)=10.624 | 4259.7 samples/s | 66.6 steps/s
[Step=86950 Epoch=334.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.679 | L2-Norm(final)=10.626 | 4216.4 samples/s | 65.9 steps/s
[Step=87000 Epoch=334.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.671 | L2-Norm(final)=10.628 | 4937.5 samples/s | 77.1 steps/s
[Step=87050 Epoch=335.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.662 | L2-Norm(final)=10.630 | 2389.5 samples/s | 37.3 steps/s
[Step=87100 Epoch=335.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.653 | L2-Norm(final)=10.632 | 4281.8 samples/s | 66.9 steps/s
[Step=87150 Epoch=335.5] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.644 | L2-Norm(final)=10.634 | 4184.0 samples/s | 65.4 steps/s
[Step=87200 Epoch=335.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.635 | L2-Norm(final)=10.635 | 4228.1 samples/s | 66.1 steps/s
[Step=87250 Epoch=335.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.625 | L2-Norm(final)=10.637 | 4326.0 samples/s | 67.6 steps/s
[Step=87300 Epoch=336.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.616 | L2-Norm(final)=10.639 | 2617.9 samples/s | 40.9 steps/s
[Step=87350 Epoch=336.2] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.607 | L2-Norm(final)=10.641 | 4238.6 samples/s | 66.2 steps/s
[Step=87400 Epoch=336.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.597 | L2-Norm(final)=10.643 | 4128.9 samples/s | 64.5 steps/s
[Step=87450 Epoch=336.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.587 | L2-Norm(final)=10.645 | 4270.4 samples/s | 66.7 steps/s
[Step=87500 Epoch=336.8] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.578 | L2-Norm(final)=10.646 | 4164.6 samples/s | 65.1 steps/s
[Step=87550 Epoch=337.0] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.568 | L2-Norm(final)=10.648 | 2666.1 samples/s | 41.7 steps/s
[Step=87600 Epoch=337.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.558 | L2-Norm(final)=10.650 | 4303.1 samples/s | 67.2 steps/s
[Step=87650 Epoch=337.4] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.548 | L2-Norm(final)=10.652 | 4104.6 samples/s | 64.1 steps/s
[Step=87700 Epoch=337.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.539 | L2-Norm(final)=10.655 | 4229.7 samples/s | 66.1 steps/s
[Step=87750 Epoch=337.8] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.529 | L2-Norm(final)=10.657 | 4250.5 samples/s | 66.4 steps/s
[Step=87800 Epoch=338.0] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.518 | L2-Norm(final)=10.659 | 6627.1 samples/s | 103.5 steps/s
[Step=87850 Epoch=338.2] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.508 | L2-Norm(final)=10.661 | 2134.2 samples/s | 33.3 steps/s
[Step=87900 Epoch=338.4] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.498 | L2-Norm(final)=10.663 | 4209.3 samples/s | 65.8 steps/s
[Step=87950 Epoch=338.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.488 | L2-Norm(final)=10.665 | 4228.5 samples/s | 66.1 steps/s
[Step=88000 Epoch=338.7] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.477 | L2-Norm(final)=10.668 | 4254.5 samples/s | 66.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07492 | acc=0.9669 | tpr=0.9784 | fpr=0.0582 | 4791.7 samples/s | 18.7 steps/s
Avg test loss: 0.07588, Avg test acc: 0.96618, Avg tpr: 0.97768, Avg fpr: 0.05909, total FA: 461

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06960 | acc=0.9660 | tpr=0.9712 | fpr=0.0453 | 5076.3 samples/s | 19.8 steps/s
Avg test loss: 0.07297, Avg test acc: 0.96590, Avg tpr: 0.97144, Avg fpr: 0.04628, total FA: 361

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.20342 | acc=0.3063 | tpr=0.0092 | fpr=0.0488 | 5076.9 samples/s | 19.8 steps/s
Avg test loss: 5.20062, Avg test acc: 0.30331, Avg tpr: 0.00985, Avg fpr: 0.05128, total FA: 400

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.58920 | acc=0.3093 | tpr=0.0108 | fpr=0.0426 | 4785.2 samples/s | 18.7 steps/s
Avg test loss: 5.57787, Avg test acc: 0.30664, Avg tpr: 0.01294, Avg fpr: 0.04743, total FA: 370

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.33358 | acc=0.1370 | tpr=0.5310 | fpr=0.8700 | 5035.3 samples/s | 19.7 steps/s
[Step= 100] | Loss=6.30806 | acc=0.1362 | tpr=0.4883 | fpr=0.8704 | 6954.8 samples/s | 27.2 steps/s
[Step= 150] | Loss=6.30637 | acc=0.1367 | tpr=0.4870 | fpr=0.8697 | 7930.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=6.30421 | acc=0.1371 | tpr=0.4831 | fpr=0.8692 | 7633.4 samples/s | 29.8 steps/s
[Step= 250] | Loss=6.29542 | acc=0.1378 | tpr=0.4952 | fpr=0.8688 | 7937.0 samples/s | 31.0 steps/s
[Step= 300] | Loss=6.28935 | acc=0.1372 | tpr=0.4909 | fpr=0.8692 | 7536.8 samples/s | 29.4 steps/s
[Step= 350] | Loss=6.29409 | acc=0.1368 | tpr=0.4828 | fpr=0.8695 | 8153.5 samples/s | 31.8 steps/s
[Step= 400] | Loss=6.29194 | acc=0.1372 | tpr=0.4819 | fpr=0.8691 | 7867.6 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.29528 | acc=0.1368 | tpr=0.4766 | fpr=0.8694 | 7732.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.29878 | acc=0.1372 | tpr=0.4771 | fpr=0.8690 | 7881.9 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.30009 | acc=0.1375 | tpr=0.4739 | fpr=0.8686 | 14057.8 samples/s | 54.9 steps/s
Avg test loss: 6.30154, Avg test acc: 0.13740, Avg tpr: 0.47504, Avg fpr: 0.86873, total FA: 120622

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.62395 | acc=0.1309 | tpr=0.5442 | fpr=0.8765 | 4901.4 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.61617 | acc=0.1312 | tpr=0.5053 | fpr=0.8758 | 6945.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.61568 | acc=0.1318 | tpr=0.5072 | fpr=0.8751 | 8128.7 samples/s | 31.8 steps/s
[Step= 200] | Loss=6.61116 | acc=0.1322 | tpr=0.5049 | fpr=0.8746 | 7967.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.60307 | acc=0.1330 | tpr=0.5066 | fpr=0.8738 | 7920.6 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.59842 | acc=0.1332 | tpr=0.5076 | fpr=0.8736 | 7977.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.60327 | acc=0.1329 | tpr=0.5022 | fpr=0.8738 | 7557.3 samples/s | 29.5 steps/s
[Step= 400] | Loss=6.59886 | acc=0.1330 | tpr=0.4989 | fpr=0.8737 | 7946.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.60351 | acc=0.1326 | tpr=0.4956 | fpr=0.8740 | 7826.2 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.60603 | acc=0.1331 | tpr=0.4991 | fpr=0.8735 | 7986.7 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.60780 | acc=0.1331 | tpr=0.4946 | fpr=0.8735 | 13543.1 samples/s | 52.9 steps/s
Avg test loss: 6.60978, Avg test acc: 0.13294, Avg tpr: 0.49564, Avg fpr: 0.87365, total FA: 121305

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11836 | acc=0.9766 | tpr=0.9602 | fpr=0.0231 | 4938.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11965 | acc=0.9775 | tpr=0.9680 | fpr=0.0223 | 6803.6 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12496 | acc=0.9767 | tpr=0.9669 | fpr=0.0231 | 8134.3 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.12806 | acc=0.9767 | tpr=0.9661 | fpr=0.0231 | 7838.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.12574 | acc=0.9770 | tpr=0.9659 | fpr=0.0228 | 8102.4 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.12764 | acc=0.9766 | tpr=0.9644 | fpr=0.0231 | 7658.9 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.12786 | acc=0.9766 | tpr=0.9643 | fpr=0.0232 | 7658.9 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.12927 | acc=0.9765 | tpr=0.9628 | fpr=0.0232 | 8097.5 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.13166 | acc=0.9762 | tpr=0.9611 | fpr=0.0235 | 7991.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.13092 | acc=0.9763 | tpr=0.9617 | fpr=0.0234 | 7703.6 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.12973 | acc=0.9765 | tpr=0.9622 | fpr=0.0232 | 13564.2 samples/s | 53.0 steps/s
Avg test loss: 0.12953, Avg test acc: 0.97656, Avg tpr: 0.96197, Avg fpr: 0.02318, total FA: 3218

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11256 | acc=0.9779 | tpr=0.9469 | fpr=0.0216 | 5071.8 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.11539 | acc=0.9778 | tpr=0.9595 | fpr=0.0218 | 7026.7 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.12086 | acc=0.9774 | tpr=0.9625 | fpr=0.0223 | 7640.5 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.12378 | acc=0.9771 | tpr=0.9607 | fpr=0.0226 | 7649.7 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.12171 | acc=0.9775 | tpr=0.9624 | fpr=0.0222 | 7957.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.12366 | acc=0.9773 | tpr=0.9600 | fpr=0.0224 | 7802.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.12410 | acc=0.9770 | tpr=0.9618 | fpr=0.0227 | 7758.6 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.12539 | acc=0.9770 | tpr=0.9601 | fpr=0.0227 | 7869.4 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.12772 | acc=0.9766 | tpr=0.9572 | fpr=0.0231 | 7876.8 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.12717 | acc=0.9767 | tpr=0.9577 | fpr=0.0229 | 7934.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.12593 | acc=0.9770 | tpr=0.9582 | fpr=0.0227 | 13644.2 samples/s | 53.3 steps/s
Avg test loss: 0.12581, Avg test acc: 0.97699, Avg tpr: 0.95800, Avg fpr: 0.02267, total FA: 3147

server round 44/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=171.6] | Loss=0.01213 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.773 | L2-Norm(final)=15.681 | 7554.7 samples/s | 118.0 steps/s
[Step=88050 Epoch=171.7] | Loss=0.01077 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=15.682 | 4065.7 samples/s | 63.5 steps/s
[Step=88100 Epoch=171.8] | Loss=0.00989 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.779 | L2-Norm(final)=15.685 | 5084.9 samples/s | 79.5 steps/s
[Step=88150 Epoch=171.9] | Loss=0.00914 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.781 | L2-Norm(final)=15.689 | 4966.7 samples/s | 77.6 steps/s
[Step=88200 Epoch=172.0] | Loss=0.00939 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.783 | L2-Norm(final)=15.693 | 4930.8 samples/s | 77.0 steps/s
[Step=88250 Epoch=172.1] | Loss=0.00939 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=15.696 | 5002.6 samples/s | 78.2 steps/s
[Step=88300 Epoch=172.2] | Loss=0.00947 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.786 | L2-Norm(final)=15.700 | 5052.8 samples/s | 78.9 steps/s
[Step=88350 Epoch=172.3] | Loss=0.00938 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.788 | L2-Norm(final)=15.703 | 5132.7 samples/s | 80.2 steps/s
[Step=88400 Epoch=172.4] | Loss=0.00925 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.789 | L2-Norm(final)=15.707 | 4971.6 samples/s | 77.7 steps/s
[Step=88450 Epoch=172.5] | Loss=0.00937 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.791 | L2-Norm(final)=15.710 | 5152.6 samples/s | 80.5 steps/s
[Step=88500 Epoch=172.6] | Loss=0.00934 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=15.713 | 6602.5 samples/s | 103.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=172.6] | Loss=0.02292 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.804 | L2-Norm(final)=15.746 | 6627.3 samples/s | 103.6 steps/s
[Step=88550 Epoch=172.7] | Loss=0.01088 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.806 | L2-Norm(final)=15.749 | 3940.2 samples/s | 61.6 steps/s
[Step=88600 Epoch=172.8] | Loss=0.00910 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.809 | L2-Norm(final)=15.752 | 4434.2 samples/s | 69.3 steps/s
[Step=88650 Epoch=172.9] | Loss=0.00891 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.811 | L2-Norm(final)=15.755 | 4407.5 samples/s | 68.9 steps/s
[Step=88700 Epoch=173.0] | Loss=0.00858 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=15.758 | 4549.4 samples/s | 71.1 steps/s
[Step=88750 Epoch=173.1] | Loss=0.00829 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=15.761 | 4396.6 samples/s | 68.7 steps/s
[Step=88800 Epoch=173.2] | Loss=0.00810 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=15.764 | 4485.7 samples/s | 70.1 steps/s
[Step=88850 Epoch=173.3] | Loss=0.00813 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=15.766 | 4480.3 samples/s | 70.0 steps/s
[Step=88900 Epoch=173.4] | Loss=0.00801 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=15.769 | 4461.9 samples/s | 69.7 steps/s
[Step=88950 Epoch=173.5] | Loss=0.00799 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.820 | L2-Norm(final)=15.771 | 4514.9 samples/s | 70.5 steps/s
[Step=89000 Epoch=173.6] | Loss=0.00801 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.822 | L2-Norm(final)=15.774 | 5812.9 samples/s | 90.8 steps/s
[Step=89050 Epoch=173.7] | Loss=0.00780 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.823 | L2-Norm(final)=15.777 | 2394.0 samples/s | 37.4 steps/s
[Step=89100 Epoch=173.8] | Loss=0.00761 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.824 | L2-Norm(final)=15.779 | 4438.0 samples/s | 69.3 steps/s
[Step=89150 Epoch=173.9] | Loss=0.00740 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=15.782 | 4502.2 samples/s | 70.3 steps/s
[Step=89200 Epoch=174.0] | Loss=0.00735 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.826 | L2-Norm(final)=15.784 | 4379.5 samples/s | 68.4 steps/s
[Step=89250 Epoch=174.1] | Loss=0.00730 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.827 | L2-Norm(final)=15.787 | 4449.6 samples/s | 69.5 steps/s
[Step=89300 Epoch=174.2] | Loss=0.00712 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.828 | L2-Norm(final)=15.789 | 4470.2 samples/s | 69.8 steps/s
[Step=89350 Epoch=174.3] | Loss=0.00701 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.828 | L2-Norm(final)=15.791 | 4539.7 samples/s | 70.9 steps/s
[Step=89400 Epoch=174.4] | Loss=0.00702 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.829 | L2-Norm(final)=15.794 | 4399.2 samples/s | 68.7 steps/s
[Step=89450 Epoch=174.5] | Loss=0.00701 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.830 | L2-Norm(final)=15.796 | 4443.4 samples/s | 69.4 steps/s
[Step=89500 Epoch=174.6] | Loss=0.00694 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.830 | L2-Norm(final)=15.798 | 4744.3 samples/s | 74.1 steps/s
[Step=89550 Epoch=174.7] | Loss=0.00690 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.831 | L2-Norm(final)=15.800 | 2629.8 samples/s | 41.1 steps/s
[Step=89600 Epoch=174.8] | Loss=0.00675 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.832 | L2-Norm(final)=15.803 | 4424.3 samples/s | 69.1 steps/s
[Step=89650 Epoch=174.9] | Loss=0.00668 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.832 | L2-Norm(final)=15.805 | 4478.8 samples/s | 70.0 steps/s
[Step=89700 Epoch=174.9] | Loss=0.00666 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.833 | L2-Norm(final)=15.807 | 4468.7 samples/s | 69.8 steps/s
[Step=89750 Epoch=175.0] | Loss=0.00656 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.833 | L2-Norm(final)=15.809 | 4461.2 samples/s | 69.7 steps/s
[Step=89800 Epoch=175.1] | Loss=0.00657 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.834 | L2-Norm(final)=15.811 | 4532.0 samples/s | 70.8 steps/s
[Step=89850 Epoch=175.2] | Loss=0.00655 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.834 | L2-Norm(final)=15.814 | 4351.4 samples/s | 68.0 steps/s
[Step=89900 Epoch=175.3] | Loss=0.00646 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.835 | L2-Norm(final)=15.816 | 4384.5 samples/s | 68.5 steps/s
[Step=89950 Epoch=175.4] | Loss=0.00644 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.835 | L2-Norm(final)=15.818 | 4557.1 samples/s | 71.2 steps/s
[Step=90000 Epoch=175.5] | Loss=0.00641 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.835 | L2-Norm(final)=15.820 | 4436.4 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step90000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=172.0] | Loss=0.00925 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=15.747 | 6233.4 samples/s | 97.4 steps/s
[Step=88050 Epoch=172.1] | Loss=0.01077 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.962 | L2-Norm(final)=15.748 | 4692.9 samples/s | 73.3 steps/s
[Step=88100 Epoch=172.2] | Loss=0.00963 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.964 | L2-Norm(final)=15.752 | 4862.8 samples/s | 76.0 steps/s
[Step=88150 Epoch=172.3] | Loss=0.00978 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=15.756 | 5017.2 samples/s | 78.4 steps/s
[Step=88200 Epoch=172.4] | Loss=0.00904 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=15.759 | 4974.6 samples/s | 77.7 steps/s
[Step=88250 Epoch=172.5] | Loss=0.00875 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=15.763 | 4921.3 samples/s | 76.9 steps/s
[Step=88300 Epoch=172.6] | Loss=0.00875 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=15.767 | 5033.1 samples/s | 78.6 steps/s
[Step=88350 Epoch=172.7] | Loss=0.00877 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.972 | L2-Norm(final)=15.771 | 5195.2 samples/s | 81.2 steps/s
[Step=88400 Epoch=172.8] | Loss=0.00884 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.974 | L2-Norm(final)=15.774 | 4874.2 samples/s | 76.2 steps/s
[Step=88450 Epoch=172.9] | Loss=0.00899 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=15.778 | 5118.6 samples/s | 80.0 steps/s
[Step=88500 Epoch=173.0] | Loss=0.00921 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.977 | L2-Norm(final)=15.781 | 6863.0 samples/s | 107.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=173.0] | Loss=0.00428 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=15.815 | 6257.9 samples/s | 97.8 steps/s
[Step=88550 Epoch=173.1] | Loss=0.00628 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=15.818 | 4130.2 samples/s | 64.5 steps/s
[Step=88600 Epoch=173.2] | Loss=0.00794 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.997 | L2-Norm(final)=15.822 | 4412.7 samples/s | 68.9 steps/s
[Step=88650 Epoch=173.3] | Loss=0.00859 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.999 | L2-Norm(final)=15.824 | 4370.8 samples/s | 68.3 steps/s
[Step=88700 Epoch=173.4] | Loss=0.00848 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.001 | L2-Norm(final)=15.827 | 4568.1 samples/s | 71.4 steps/s
[Step=88750 Epoch=173.5] | Loss=0.00825 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.003 | L2-Norm(final)=15.830 | 4398.6 samples/s | 68.7 steps/s
[Step=88800 Epoch=173.6] | Loss=0.00831 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.005 | L2-Norm(final)=15.833 | 4514.2 samples/s | 70.5 steps/s
[Step=88850 Epoch=173.7] | Loss=0.00824 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=15.836 | 4486.0 samples/s | 70.1 steps/s
[Step=88900 Epoch=173.8] | Loss=0.00818 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.008 | L2-Norm(final)=15.839 | 4458.0 samples/s | 69.7 steps/s
[Step=88950 Epoch=173.9] | Loss=0.00811 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=15.841 | 4454.6 samples/s | 69.6 steps/s
[Step=89000 Epoch=174.0] | Loss=0.00793 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=15.844 | 5818.5 samples/s | 90.9 steps/s
[Step=89050 Epoch=174.1] | Loss=0.00772 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.012 | L2-Norm(final)=15.847 | 2358.0 samples/s | 36.8 steps/s
[Step=89100 Epoch=174.2] | Loss=0.00758 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.013 | L2-Norm(final)=15.849 | 4468.4 samples/s | 69.8 steps/s
[Step=89150 Epoch=174.3] | Loss=0.00746 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.014 | L2-Norm(final)=15.852 | 4548.3 samples/s | 71.1 steps/s
[Step=89200 Epoch=174.4] | Loss=0.00732 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.015 | L2-Norm(final)=15.854 | 4503.8 samples/s | 70.4 steps/s
[Step=89250 Epoch=174.5] | Loss=0.00713 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.015 | L2-Norm(final)=15.857 | 4344.5 samples/s | 67.9 steps/s
[Step=89300 Epoch=174.6] | Loss=0.00699 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.016 | L2-Norm(final)=15.859 | 4491.9 samples/s | 70.2 steps/s
[Step=89350 Epoch=174.7] | Loss=0.00690 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.017 | L2-Norm(final)=15.861 | 4469.9 samples/s | 69.8 steps/s
[Step=89400 Epoch=174.8] | Loss=0.00696 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.018 | L2-Norm(final)=15.864 | 4520.6 samples/s | 70.6 steps/s
[Step=89450 Epoch=174.9] | Loss=0.00686 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.019 | L2-Norm(final)=15.866 | 4435.6 samples/s | 69.3 steps/s
[Step=89500 Epoch=175.0] | Loss=0.00683 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.019 | L2-Norm(final)=15.868 | 4901.4 samples/s | 76.6 steps/s
[Step=89550 Epoch=175.1] | Loss=0.00677 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.020 | L2-Norm(final)=15.871 | 2586.2 samples/s | 40.4 steps/s
[Step=89600 Epoch=175.2] | Loss=0.00669 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.021 | L2-Norm(final)=15.873 | 4548.0 samples/s | 71.1 steps/s
[Step=89650 Epoch=175.3] | Loss=0.00666 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.022 | L2-Norm(final)=15.875 | 4390.5 samples/s | 68.6 steps/s
[Step=89700 Epoch=175.4] | Loss=0.00660 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.022 | L2-Norm(final)=15.878 | 4484.7 samples/s | 70.1 steps/s
[Step=89750 Epoch=175.5] | Loss=0.00653 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.023 | L2-Norm(final)=15.880 | 4436.2 samples/s | 69.3 steps/s
[Step=89800 Epoch=175.6] | Loss=0.00648 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.023 | L2-Norm(final)=15.882 | 4432.0 samples/s | 69.2 steps/s
[Step=89850 Epoch=175.7] | Loss=0.00644 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=15.884 | 4490.4 samples/s | 70.2 steps/s
[Step=89900 Epoch=175.8] | Loss=0.00638 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=15.887 | 4366.8 samples/s | 68.2 steps/s
[Step=89950 Epoch=175.8] | Loss=0.00635 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.025 | L2-Norm(final)=15.889 | 4452.2 samples/s | 69.6 steps/s
[Step=90000 Epoch=175.9] | Loss=0.00626 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.025 | L2-Norm(final)=15.891 | 4502.9 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step90000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=337.2] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.506 | L2-Norm(final)=9.522 | 6211.4 samples/s | 97.1 steps/s
[Step=88050 Epoch=337.4] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.506 | L2-Norm(final)=9.534 | 4016.4 samples/s | 62.8 steps/s
[Step=88100 Epoch=337.6] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.510 | L2-Norm(final)=9.546 | 4647.7 samples/s | 72.6 steps/s
[Step=88150 Epoch=337.8] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.513 | L2-Norm(final)=9.557 | 4771.2 samples/s | 74.5 steps/s
[Step=88200 Epoch=338.0] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.516 | L2-Norm(final)=9.566 | 4632.8 samples/s | 72.4 steps/s
[Step=88250 Epoch=338.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.519 | L2-Norm(final)=9.575 | 6603.3 samples/s | 103.2 steps/s
[Step=88300 Epoch=338.3] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.520 | L2-Norm(final)=9.583 | 2429.8 samples/s | 38.0 steps/s
[Step=88350 Epoch=338.5] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.522 | L2-Norm(final)=9.590 | 4875.9 samples/s | 76.2 steps/s
[Step=88400 Epoch=338.7] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.524 | L2-Norm(final)=9.598 | 4603.1 samples/s | 71.9 steps/s
[Step=88450 Epoch=338.9] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.525 | L2-Norm(final)=9.604 | 4832.3 samples/s | 75.5 steps/s
[Step=88500 Epoch=339.1] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.526 | L2-Norm(final)=9.611 | 5403.0 samples/s | 84.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=339.1] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.537 | L2-Norm(final)=9.675 | 6174.2 samples/s | 96.5 steps/s
[Step=88550 Epoch=339.3] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.532 | L2-Norm(final)=9.681 | 3779.8 samples/s | 59.1 steps/s
[Step=88600 Epoch=339.5] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.523 | L2-Norm(final)=9.686 | 4227.2 samples/s | 66.1 steps/s
[Step=88650 Epoch=339.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.513 | L2-Norm(final)=9.690 | 4333.4 samples/s | 67.7 steps/s
[Step=88700 Epoch=339.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.502 | L2-Norm(final)=9.693 | 4189.1 samples/s | 65.5 steps/s
[Step=88750 Epoch=340.1] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.491 | L2-Norm(final)=9.696 | 5660.2 samples/s | 88.4 steps/s
[Step=88800 Epoch=340.3] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.480 | L2-Norm(final)=9.699 | 2296.0 samples/s | 35.9 steps/s
[Step=88850 Epoch=340.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.469 | L2-Norm(final)=9.701 | 4272.7 samples/s | 66.8 steps/s
[Step=88900 Epoch=340.6] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.457 | L2-Norm(final)=9.703 | 4125.4 samples/s | 64.5 steps/s
[Step=88950 Epoch=340.8] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.446 | L2-Norm(final)=9.706 | 4265.6 samples/s | 66.6 steps/s
[Step=89000 Epoch=341.0] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.434 | L2-Norm(final)=9.708 | 4627.1 samples/s | 72.3 steps/s
[Step=89050 Epoch=341.2] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.423 | L2-Norm(final)=9.710 | 2472.0 samples/s | 38.6 steps/s
[Step=89100 Epoch=341.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.411 | L2-Norm(final)=9.712 | 4145.0 samples/s | 64.8 steps/s
[Step=89150 Epoch=341.6] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.399 | L2-Norm(final)=9.714 | 4243.3 samples/s | 66.3 steps/s
[Step=89200 Epoch=341.8] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.386 | L2-Norm(final)=9.715 | 4241.1 samples/s | 66.3 steps/s
[Step=89250 Epoch=342.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.374 | L2-Norm(final)=9.717 | 4228.0 samples/s | 66.1 steps/s
[Step=89300 Epoch=342.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.361 | L2-Norm(final)=9.719 | 2619.5 samples/s | 40.9 steps/s
[Step=89350 Epoch=342.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.349 | L2-Norm(final)=9.720 | 4255.7 samples/s | 66.5 steps/s
[Step=89400 Epoch=342.5] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.336 | L2-Norm(final)=9.722 | 4237.0 samples/s | 66.2 steps/s
[Step=89450 Epoch=342.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.323 | L2-Norm(final)=9.724 | 4253.9 samples/s | 66.5 steps/s
[Step=89500 Epoch=342.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.311 | L2-Norm(final)=9.726 | 4198.5 samples/s | 65.6 steps/s
[Step=89550 Epoch=343.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.298 | L2-Norm(final)=9.728 | 2648.8 samples/s | 41.4 steps/s
[Step=89600 Epoch=343.3] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.285 | L2-Norm(final)=9.729 | 4142.1 samples/s | 64.7 steps/s
[Step=89650 Epoch=343.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=9.731 | 4146.4 samples/s | 64.8 steps/s
[Step=89700 Epoch=343.7] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=9.733 | 4207.2 samples/s | 65.7 steps/s
[Step=89750 Epoch=343.9] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.246 | L2-Norm(final)=9.735 | 4279.0 samples/s | 66.9 steps/s
[Step=89800 Epoch=344.1] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.233 | L2-Norm(final)=9.737 | 6231.2 samples/s | 97.4 steps/s
[Step=89850 Epoch=344.3] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.220 | L2-Norm(final)=9.740 | 2177.7 samples/s | 34.0 steps/s
[Step=89900 Epoch=344.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.207 | L2-Norm(final)=9.742 | 4264.1 samples/s | 66.6 steps/s
[Step=89950 Epoch=344.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.193 | L2-Norm(final)=9.744 | 4193.8 samples/s | 65.5 steps/s
[Step=90000 Epoch=344.8] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.180 | L2-Norm(final)=9.746 | 4189.6 samples/s | 65.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step90000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=338.8] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.738 | 6243.7 samples/s | 97.6 steps/s
[Step=88050 Epoch=338.9] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.452 | L2-Norm(final)=10.748 | 4174.8 samples/s | 65.2 steps/s
[Step=88100 Epoch=339.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.456 | L2-Norm(final)=10.758 | 4860.5 samples/s | 75.9 steps/s
[Step=88150 Epoch=339.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.459 | L2-Norm(final)=10.766 | 4689.6 samples/s | 73.3 steps/s
[Step=88200 Epoch=339.5] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=10.773 | 4781.3 samples/s | 74.7 steps/s
[Step=88250 Epoch=339.7] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.463 | L2-Norm(final)=10.779 | 6707.4 samples/s | 104.8 steps/s
[Step=88300 Epoch=339.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.465 | L2-Norm(final)=10.784 | 2409.1 samples/s | 37.6 steps/s
[Step=88350 Epoch=340.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.466 | L2-Norm(final)=10.789 | 4677.6 samples/s | 73.1 steps/s
[Step=88400 Epoch=340.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.467 | L2-Norm(final)=10.794 | 4621.1 samples/s | 72.2 steps/s
[Step=88450 Epoch=340.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.469 | L2-Norm(final)=10.799 | 4869.3 samples/s | 76.1 steps/s
[Step=88500 Epoch=340.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.469 | L2-Norm(final)=10.803 | 5541.0 samples/s | 86.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=340.7] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.479 | L2-Norm(final)=10.850 | 6234.2 samples/s | 97.4 steps/s
[Step=88550 Epoch=340.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.472 | L2-Norm(final)=10.854 | 3838.7 samples/s | 60.0 steps/s
[Step=88600 Epoch=341.1] | Loss=0.00013 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.465 | L2-Norm(final)=10.859 | 4176.6 samples/s | 65.3 steps/s
[Step=88650 Epoch=341.2] | Loss=0.00013 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.862 | 4229.2 samples/s | 66.1 steps/s
[Step=88700 Epoch=341.4] | Loss=0.00010 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.864 | 4254.0 samples/s | 66.5 steps/s
[Step=88750 Epoch=341.6] | Loss=0.00008 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.865 | 5631.9 samples/s | 88.0 steps/s
[Step=88800 Epoch=341.8] | Loss=0.00007 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.463 | L2-Norm(final)=10.867 | 2243.1 samples/s | 35.0 steps/s
[Step=88850 Epoch=342.0] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.463 | L2-Norm(final)=10.867 | 4202.5 samples/s | 65.7 steps/s
[Step=88900 Epoch=342.2] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.463 | L2-Norm(final)=10.868 | 4233.8 samples/s | 66.2 steps/s
[Step=88950 Epoch=342.4] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.462 | L2-Norm(final)=10.869 | 4345.1 samples/s | 67.9 steps/s
[Step=89000 Epoch=342.6] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.462 | L2-Norm(final)=10.869 | 4830.3 samples/s | 75.5 steps/s
[Step=89050 Epoch=342.8] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=10.870 | 2391.8 samples/s | 37.4 steps/s
[Step=89100 Epoch=343.0] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=10.870 | 4171.4 samples/s | 65.2 steps/s
[Step=89150 Epoch=343.2] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.460 | L2-Norm(final)=10.870 | 4298.7 samples/s | 67.2 steps/s
[Step=89200 Epoch=343.4] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.460 | L2-Norm(final)=10.871 | 4244.9 samples/s | 66.3 steps/s
[Step=89250 Epoch=343.6] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.459 | L2-Norm(final)=10.871 | 4278.1 samples/s | 66.8 steps/s
[Step=89300 Epoch=343.8] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.458 | L2-Norm(final)=10.871 | 2650.9 samples/s | 41.4 steps/s
[Step=89350 Epoch=343.9] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.458 | L2-Norm(final)=10.871 | 4080.9 samples/s | 63.8 steps/s
[Step=89400 Epoch=344.1] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.457 | L2-Norm(final)=10.872 | 4220.5 samples/s | 65.9 steps/s
[Step=89450 Epoch=344.3] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.456 | L2-Norm(final)=10.872 | 4257.2 samples/s | 66.5 steps/s
[Step=89500 Epoch=344.5] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.456 | L2-Norm(final)=10.872 | 4119.1 samples/s | 64.4 steps/s
[Step=89550 Epoch=344.7] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.455 | L2-Norm(final)=10.872 | 2635.6 samples/s | 41.2 steps/s
[Step=89600 Epoch=344.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.454 | L2-Norm(final)=10.873 | 4275.1 samples/s | 66.8 steps/s
[Step=89650 Epoch=345.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.873 | 4198.3 samples/s | 65.6 steps/s
[Step=89700 Epoch=345.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.452 | L2-Norm(final)=10.873 | 4276.6 samples/s | 66.8 steps/s
[Step=89750 Epoch=345.5] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.452 | L2-Norm(final)=10.873 | 4272.4 samples/s | 66.8 steps/s
[Step=89800 Epoch=345.7] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.451 | L2-Norm(final)=10.874 | 6843.9 samples/s | 106.9 steps/s
[Step=89850 Epoch=345.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.450 | L2-Norm(final)=10.874 | 2094.7 samples/s | 32.7 steps/s
[Step=89900 Epoch=346.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.449 | L2-Norm(final)=10.874 | 4246.5 samples/s | 66.4 steps/s
[Step=89950 Epoch=346.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.448 | L2-Norm(final)=10.874 | 4283.8 samples/s | 66.9 steps/s
[Step=90000 Epoch=346.4] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.447 | L2-Norm(final)=10.874 | 4262.3 samples/s | 66.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07012 | acc=0.9670 | tpr=0.9764 | fpr=0.0535 | 4713.9 samples/s | 18.4 steps/s
Avg test loss: 0.07097, Avg test acc: 0.96614, Avg tpr: 0.97546, Avg fpr: 0.05435, total FA: 424

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06549 | acc=0.9673 | tpr=0.9730 | fpr=0.0451 | 4857.0 samples/s | 19.0 steps/s
Avg test loss: 0.06821, Avg test acc: 0.96634, Avg tpr: 0.97261, Avg fpr: 0.04743, total FA: 370

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.37263 | acc=0.3094 | tpr=0.0052 | fpr=0.0302 | 4966.8 samples/s | 19.4 steps/s
Avg test loss: 5.37240, Avg test acc: 0.30631, Avg tpr: 0.00583, Avg fpr: 0.03282, total FA: 256

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.59396 | acc=0.3109 | tpr=0.0131 | fpr=0.0426 | 5009.3 samples/s | 19.6 steps/s
Avg test loss: 5.58698, Avg test acc: 0.30792, Avg tpr: 0.01463, Avg fpr: 0.04705, total FA: 367

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.68891 | acc=0.1457 | tpr=0.4823 | fpr=0.8603 | 5012.0 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.66438 | acc=0.1457 | tpr=0.4542 | fpr=0.8601 | 7154.6 samples/s | 27.9 steps/s
[Step= 150] | Loss=5.66327 | acc=0.1462 | tpr=0.4539 | fpr=0.8594 | 7730.6 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.66248 | acc=0.1463 | tpr=0.4503 | fpr=0.8592 | 7675.4 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.65401 | acc=0.1466 | tpr=0.4585 | fpr=0.8591 | 7906.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.64750 | acc=0.1463 | tpr=0.4560 | fpr=0.8594 | 7738.0 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.65178 | acc=0.1457 | tpr=0.4458 | fpr=0.8597 | 7707.9 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.64993 | acc=0.1462 | tpr=0.4447 | fpr=0.8592 | 8254.4 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.65309 | acc=0.1460 | tpr=0.4416 | fpr=0.8594 | 7947.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.65605 | acc=0.1462 | tpr=0.4427 | fpr=0.8591 | 7845.5 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.65687 | acc=0.1465 | tpr=0.4429 | fpr=0.8589 | 14247.8 samples/s | 55.7 steps/s
Avg test loss: 5.65842, Avg test acc: 0.14638, Avg tpr: 0.44414, Avg fpr: 0.85903, total FA: 119275

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.03975 | acc=0.1346 | tpr=0.5354 | fpr=0.8726 | 4950.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.03188 | acc=0.1352 | tpr=0.4904 | fpr=0.8714 | 7086.2 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.03041 | acc=0.1351 | tpr=0.4784 | fpr=0.8713 | 7747.4 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.02925 | acc=0.1353 | tpr=0.4743 | fpr=0.8709 | 8087.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=6.02078 | acc=0.1359 | tpr=0.4751 | fpr=0.8702 | 8016.7 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.01596 | acc=0.1361 | tpr=0.4771 | fpr=0.8701 | 7379.7 samples/s | 28.8 steps/s
[Step= 350] | Loss=6.02072 | acc=0.1357 | tpr=0.4721 | fpr=0.8704 | 7998.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.01703 | acc=0.1359 | tpr=0.4699 | fpr=0.8701 | 8123.7 samples/s | 31.7 steps/s
[Step= 450] | Loss=6.02097 | acc=0.1356 | tpr=0.4654 | fpr=0.8704 | 7829.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.02298 | acc=0.1360 | tpr=0.4705 | fpr=0.8700 | 7640.6 samples/s | 29.8 steps/s
[Step= 550] | Loss=6.02475 | acc=0.1360 | tpr=0.4660 | fpr=0.8700 | 14185.7 samples/s | 55.4 steps/s
Avg test loss: 6.02667, Avg test acc: 0.13585, Avg tpr: 0.46672, Avg fpr: 0.87017, total FA: 120821

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10864 | acc=0.9778 | tpr=0.9469 | fpr=0.0216 | 4891.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.11052 | acc=0.9785 | tpr=0.9574 | fpr=0.0211 | 7547.2 samples/s | 29.5 steps/s
[Step= 150] | Loss=0.11541 | acc=0.9776 | tpr=0.9582 | fpr=0.0220 | 7449.9 samples/s | 29.1 steps/s
[Step= 200] | Loss=0.11846 | acc=0.9776 | tpr=0.9585 | fpr=0.0221 | 7759.2 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.11636 | acc=0.9778 | tpr=0.9598 | fpr=0.0218 | 8205.9 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.11817 | acc=0.9774 | tpr=0.9571 | fpr=0.0222 | 7753.1 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.11834 | acc=0.9775 | tpr=0.9580 | fpr=0.0221 | 7900.3 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.11968 | acc=0.9775 | tpr=0.9573 | fpr=0.0221 | 6947.9 samples/s | 27.1 steps/s
[Step= 450] | Loss=0.12184 | acc=0.9772 | tpr=0.9552 | fpr=0.0224 | 9143.9 samples/s | 35.7 steps/s
[Step= 500] | Loss=0.12118 | acc=0.9772 | tpr=0.9559 | fpr=0.0224 | 7357.1 samples/s | 28.7 steps/s
[Step= 550] | Loss=0.12013 | acc=0.9775 | tpr=0.9570 | fpr=0.0221 | 13667.3 samples/s | 53.4 steps/s
Avg test loss: 0.11992, Avg test acc: 0.97756, Avg tpr: 0.95681, Avg fpr: 0.02207, total FA: 3064

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11600 | acc=0.9779 | tpr=0.9469 | fpr=0.0216 | 4966.9 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.11896 | acc=0.9778 | tpr=0.9595 | fpr=0.0218 | 7442.9 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.12495 | acc=0.9771 | tpr=0.9625 | fpr=0.0226 | 7210.8 samples/s | 28.2 steps/s
[Step= 200] | Loss=0.12760 | acc=0.9768 | tpr=0.9617 | fpr=0.0229 | 8000.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.12548 | acc=0.9771 | tpr=0.9624 | fpr=0.0227 | 7930.1 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.12749 | acc=0.9769 | tpr=0.9607 | fpr=0.0228 | 8026.5 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.12795 | acc=0.9767 | tpr=0.9624 | fpr=0.0231 | 7714.1 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.12916 | acc=0.9767 | tpr=0.9612 | fpr=0.0230 | 7172.8 samples/s | 28.0 steps/s
[Step= 450] | Loss=0.13157 | acc=0.9762 | tpr=0.9586 | fpr=0.0234 | 7671.7 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.13096 | acc=0.9764 | tpr=0.9586 | fpr=0.0233 | 7740.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.12967 | acc=0.9767 | tpr=0.9590 | fpr=0.0230 | 14322.9 samples/s | 55.9 steps/s
Avg test loss: 0.12952, Avg test acc: 0.97666, Avg tpr: 0.95880, Avg fpr: 0.02302, total FA: 3196

server round 45/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=175.5] | Loss=0.01439 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.745 | L2-Norm(final)=15.882 | 6059.5 samples/s | 94.7 steps/s
[Step=90050 Epoch=175.6] | Loss=0.01018 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.748 | L2-Norm(final)=15.885 | 4670.9 samples/s | 73.0 steps/s
[Step=90100 Epoch=175.7] | Loss=0.00986 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.751 | L2-Norm(final)=15.888 | 5026.0 samples/s | 78.5 steps/s
[Step=90150 Epoch=175.8] | Loss=0.01011 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.753 | L2-Norm(final)=15.891 | 5120.3 samples/s | 80.0 steps/s
[Step=90200 Epoch=175.9] | Loss=0.01008 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.755 | L2-Norm(final)=15.895 | 4922.4 samples/s | 76.9 steps/s
[Step=90250 Epoch=176.0] | Loss=0.01036 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.757 | L2-Norm(final)=15.899 | 5011.2 samples/s | 78.3 steps/s
[Step=90300 Epoch=176.1] | Loss=0.01001 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.759 | L2-Norm(final)=15.902 | 5119.5 samples/s | 80.0 steps/s
[Step=90350 Epoch=176.2] | Loss=0.00971 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=15.906 | 4950.2 samples/s | 77.3 steps/s
[Step=90400 Epoch=176.3] | Loss=0.00986 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.762 | L2-Norm(final)=15.910 | 5060.2 samples/s | 79.1 steps/s
[Step=90450 Epoch=176.4] | Loss=0.00968 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=15.913 | 5050.5 samples/s | 78.9 steps/s
[Step=90500 Epoch=176.5] | Loss=0.00953 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=15.917 | 6783.0 samples/s | 106.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=176.5] | Loss=0.01710 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=15.952 | 6884.5 samples/s | 107.6 steps/s
[Step=90550 Epoch=176.6] | Loss=0.00855 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=15.956 | 3850.4 samples/s | 60.2 steps/s
[Step=90600 Epoch=176.7] | Loss=0.00973 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.787 | L2-Norm(final)=15.959 | 4502.1 samples/s | 70.3 steps/s
[Step=90650 Epoch=176.8] | Loss=0.00918 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.790 | L2-Norm(final)=15.962 | 4413.5 samples/s | 69.0 steps/s
[Step=90700 Epoch=176.9] | Loss=0.00902 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.792 | L2-Norm(final)=15.965 | 4482.3 samples/s | 70.0 steps/s
[Step=90750 Epoch=177.0] | Loss=0.00890 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.794 | L2-Norm(final)=15.968 | 4445.6 samples/s | 69.5 steps/s
[Step=90800 Epoch=177.1] | Loss=0.00869 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.795 | L2-Norm(final)=15.971 | 4543.8 samples/s | 71.0 steps/s
[Step=90850 Epoch=177.2] | Loss=0.00869 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.797 | L2-Norm(final)=15.974 | 4450.5 samples/s | 69.5 steps/s
[Step=90900 Epoch=177.3] | Loss=0.00878 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.798 | L2-Norm(final)=15.977 | 4445.6 samples/s | 69.5 steps/s
[Step=90950 Epoch=177.4] | Loss=0.00873 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.800 | L2-Norm(final)=15.980 | 4496.5 samples/s | 70.3 steps/s
[Step=91000 Epoch=177.5] | Loss=0.00860 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=15.983 | 5792.0 samples/s | 90.5 steps/s
[Step=91050 Epoch=177.6] | Loss=0.00833 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.802 | L2-Norm(final)=15.985 | 2399.0 samples/s | 37.5 steps/s
[Step=91100 Epoch=177.7] | Loss=0.00807 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.804 | L2-Norm(final)=15.988 | 4475.3 samples/s | 69.9 steps/s
[Step=91150 Epoch=177.8] | Loss=0.00787 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.805 | L2-Norm(final)=15.991 | 4478.5 samples/s | 70.0 steps/s
[Step=91200 Epoch=177.9] | Loss=0.00778 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.806 | L2-Norm(final)=15.993 | 4484.4 samples/s | 70.1 steps/s
[Step=91250 Epoch=178.0] | Loss=0.00775 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.807 | L2-Norm(final)=15.996 | 4464.7 samples/s | 69.8 steps/s
[Step=91300 Epoch=178.1] | Loss=0.00773 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.808 | L2-Norm(final)=15.998 | 4446.3 samples/s | 69.5 steps/s
[Step=91350 Epoch=178.2] | Loss=0.00763 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.809 | L2-Norm(final)=16.001 | 4490.0 samples/s | 70.2 steps/s
[Step=91400 Epoch=178.3] | Loss=0.00755 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=16.003 | 4503.9 samples/s | 70.4 steps/s
[Step=91450 Epoch=178.4] | Loss=0.00747 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=16.006 | 4502.3 samples/s | 70.3 steps/s
[Step=91500 Epoch=178.5] | Loss=0.00743 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.811 | L2-Norm(final)=16.008 | 4764.5 samples/s | 74.4 steps/s
[Step=91550 Epoch=178.6] | Loss=0.00734 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.812 | L2-Norm(final)=16.011 | 2625.0 samples/s | 41.0 steps/s
[Step=91600 Epoch=178.7] | Loss=0.00727 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=16.013 | 4423.6 samples/s | 69.1 steps/s
[Step=91650 Epoch=178.8] | Loss=0.00712 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=16.016 | 4489.8 samples/s | 70.2 steps/s
[Step=91700 Epoch=178.9] | Loss=0.00701 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=16.018 | 4461.0 samples/s | 69.7 steps/s
[Step=91750 Epoch=178.9] | Loss=0.00697 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.815 | L2-Norm(final)=16.020 | 4457.8 samples/s | 69.7 steps/s
[Step=91800 Epoch=179.0] | Loss=0.00693 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.816 | L2-Norm(final)=16.023 | 4484.4 samples/s | 70.1 steps/s
[Step=91850 Epoch=179.1] | Loss=0.00686 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=16.025 | 4462.3 samples/s | 69.7 steps/s
[Step=91900 Epoch=179.2] | Loss=0.00685 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.817 | L2-Norm(final)=16.028 | 4469.7 samples/s | 69.8 steps/s
[Step=91950 Epoch=179.3] | Loss=0.00682 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.817 | L2-Norm(final)=16.030 | 4475.4 samples/s | 69.9 steps/s
[Step=92000 Epoch=179.4] | Loss=0.00681 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=16.032 | 4468.0 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step92000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=175.9] | Loss=0.01888 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.936 | L2-Norm(final)=15.957 | 6143.2 samples/s | 96.0 steps/s
[Step=90050 Epoch=176.0] | Loss=0.00974 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.937 | L2-Norm(final)=15.960 | 4282.8 samples/s | 66.9 steps/s
[Step=90100 Epoch=176.1] | Loss=0.00955 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.940 | L2-Norm(final)=15.963 | 5081.8 samples/s | 79.4 steps/s
[Step=90150 Epoch=176.2] | Loss=0.00925 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.942 | L2-Norm(final)=15.967 | 5086.6 samples/s | 79.5 steps/s
[Step=90200 Epoch=176.3] | Loss=0.00903 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.944 | L2-Norm(final)=15.971 | 4911.5 samples/s | 76.7 steps/s
[Step=90250 Epoch=176.4] | Loss=0.00893 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.945 | L2-Norm(final)=15.975 | 5107.7 samples/s | 79.8 steps/s
[Step=90300 Epoch=176.5] | Loss=0.00930 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.947 | L2-Norm(final)=15.979 | 4981.6 samples/s | 77.8 steps/s
[Step=90350 Epoch=176.6] | Loss=0.00943 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=15.983 | 5163.7 samples/s | 80.7 steps/s
[Step=90400 Epoch=176.7] | Loss=0.00943 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=15.986 | 4916.8 samples/s | 76.8 steps/s
[Step=90450 Epoch=176.8] | Loss=0.00945 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.952 | L2-Norm(final)=15.990 | 5035.3 samples/s | 78.7 steps/s
[Step=90500 Epoch=176.9] | Loss=0.00938 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=15.994 | 6974.7 samples/s | 109.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=176.9] | Loss=0.00260 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=16.031 | 5978.9 samples/s | 93.4 steps/s
[Step=90550 Epoch=177.0] | Loss=0.00904 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.973 | L2-Norm(final)=16.034 | 4307.4 samples/s | 67.3 steps/s
[Step=90600 Epoch=177.1] | Loss=0.00865 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.976 | L2-Norm(final)=16.038 | 4335.1 samples/s | 67.7 steps/s
[Step=90650 Epoch=177.2] | Loss=0.00876 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.978 | L2-Norm(final)=16.041 | 4489.3 samples/s | 70.1 steps/s
[Step=90700 Epoch=177.3] | Loss=0.00902 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.980 | L2-Norm(final)=16.045 | 4454.3 samples/s | 69.6 steps/s
[Step=90750 Epoch=177.4] | Loss=0.00884 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=16.048 | 4486.8 samples/s | 70.1 steps/s
[Step=90800 Epoch=177.5] | Loss=0.00888 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=16.051 | 4597.6 samples/s | 71.8 steps/s
[Step=90850 Epoch=177.6] | Loss=0.00898 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.986 | L2-Norm(final)=16.054 | 4350.0 samples/s | 68.0 steps/s
[Step=90900 Epoch=177.7] | Loss=0.00893 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.988 | L2-Norm(final)=16.057 | 4468.5 samples/s | 69.8 steps/s
[Step=90950 Epoch=177.8] | Loss=0.00878 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=16.060 | 4487.1 samples/s | 70.1 steps/s
[Step=91000 Epoch=177.9] | Loss=0.00871 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=16.062 | 5924.7 samples/s | 92.6 steps/s
[Step=91050 Epoch=178.0] | Loss=0.00857 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=16.065 | 2393.6 samples/s | 37.4 steps/s
[Step=91100 Epoch=178.1] | Loss=0.00836 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=16.068 | 4495.3 samples/s | 70.2 steps/s
[Step=91150 Epoch=178.2] | Loss=0.00818 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=16.071 | 4437.3 samples/s | 69.3 steps/s
[Step=91200 Epoch=178.3] | Loss=0.00793 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.997 | L2-Norm(final)=16.073 | 4451.4 samples/s | 69.6 steps/s
[Step=91250 Epoch=178.4] | Loss=0.00791 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=16.076 | 4485.9 samples/s | 70.1 steps/s
[Step=91300 Epoch=178.5] | Loss=0.00793 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=16.079 | 4511.1 samples/s | 70.5 steps/s
[Step=91350 Epoch=178.6] | Loss=0.00778 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.000 | L2-Norm(final)=16.081 | 4444.2 samples/s | 69.4 steps/s
[Step=91400 Epoch=178.7] | Loss=0.00764 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.001 | L2-Norm(final)=16.084 | 4460.7 samples/s | 69.7 steps/s
[Step=91450 Epoch=178.8] | Loss=0.00751 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.001 | L2-Norm(final)=16.086 | 4473.1 samples/s | 69.9 steps/s
[Step=91500 Epoch=178.9] | Loss=0.00747 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.002 | L2-Norm(final)=16.089 | 4963.8 samples/s | 77.6 steps/s
[Step=91550 Epoch=179.0] | Loss=0.00735 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.003 | L2-Norm(final)=16.091 | 2572.3 samples/s | 40.2 steps/s
[Step=91600 Epoch=179.1] | Loss=0.00725 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.004 | L2-Norm(final)=16.094 | 4484.3 samples/s | 70.1 steps/s
[Step=91650 Epoch=179.2] | Loss=0.00718 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.005 | L2-Norm(final)=16.096 | 4430.9 samples/s | 69.2 steps/s
[Step=91700 Epoch=179.3] | Loss=0.00712 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.005 | L2-Norm(final)=16.099 | 4467.7 samples/s | 69.8 steps/s
[Step=91750 Epoch=179.4] | Loss=0.00703 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=16.101 | 4495.7 samples/s | 70.2 steps/s
[Step=91800 Epoch=179.5] | Loss=0.00697 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.007 | L2-Norm(final)=16.103 | 4549.2 samples/s | 71.1 steps/s
[Step=91850 Epoch=179.6] | Loss=0.00691 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.007 | L2-Norm(final)=16.106 | 4438.6 samples/s | 69.4 steps/s
[Step=91900 Epoch=179.7] | Loss=0.00688 | Reg=0.00256 | acc=0.9688 | L2-Norm=16.008 | L2-Norm(final)=16.108 | 4448.1 samples/s | 69.5 steps/s
[Step=91950 Epoch=179.8] | Loss=0.00685 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=16.110 | 4515.6 samples/s | 70.6 steps/s
[Step=92000 Epoch=179.9] | Loss=0.00679 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=16.113 | 4521.8 samples/s | 70.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step92000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=344.9] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=9.814 | 5512.4 samples/s | 86.1 steps/s
[Step=90050 Epoch=345.0] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.330 | L2-Norm(final)=9.827 | 4248.7 samples/s | 66.4 steps/s
[Step=90100 Epoch=345.2] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.335 | L2-Norm(final)=9.839 | 4787.0 samples/s | 74.8 steps/s
[Step=90150 Epoch=345.4] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.341 | L2-Norm(final)=9.847 | 4761.3 samples/s | 74.4 steps/s
[Step=90200 Epoch=345.6] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=9.852 | 4770.3 samples/s | 74.5 steps/s
[Step=90250 Epoch=345.8] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.347 | L2-Norm(final)=9.856 | 6532.1 samples/s | 102.1 steps/s
[Step=90300 Epoch=346.0] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.349 | L2-Norm(final)=9.859 | 2433.9 samples/s | 38.0 steps/s
[Step=90350 Epoch=346.2] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.350 | L2-Norm(final)=9.862 | 4853.3 samples/s | 75.8 steps/s
[Step=90400 Epoch=346.4] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.352 | L2-Norm(final)=9.864 | 4696.8 samples/s | 73.4 steps/s
[Step=90450 Epoch=346.6] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.353 | L2-Norm(final)=9.867 | 4671.8 samples/s | 73.0 steps/s
[Step=90500 Epoch=346.8] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.354 | L2-Norm(final)=9.869 | 5461.3 samples/s | 85.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=346.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.362 | L2-Norm(final)=9.893 | 6189.8 samples/s | 96.7 steps/s
[Step=90550 Epoch=347.0] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.360 | L2-Norm(final)=9.896 | 3817.7 samples/s | 59.7 steps/s
[Step=90600 Epoch=347.1] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.359 | L2-Norm(final)=9.900 | 4226.6 samples/s | 66.0 steps/s
[Step=90650 Epoch=347.3] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.354 | L2-Norm(final)=9.902 | 4249.3 samples/s | 66.4 steps/s
[Step=90700 Epoch=347.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.349 | L2-Norm(final)=9.903 | 4257.1 samples/s | 66.5 steps/s
[Step=90750 Epoch=347.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.342 | L2-Norm(final)=9.904 | 5638.8 samples/s | 88.1 steps/s
[Step=90800 Epoch=347.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.336 | L2-Norm(final)=9.905 | 2270.5 samples/s | 35.5 steps/s
[Step=90850 Epoch=348.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=9.906 | 4207.3 samples/s | 65.7 steps/s
[Step=90900 Epoch=348.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.321 | L2-Norm(final)=9.907 | 4270.6 samples/s | 66.7 steps/s
[Step=90950 Epoch=348.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.314 | L2-Norm(final)=9.908 | 4291.5 samples/s | 67.1 steps/s
[Step=91000 Epoch=348.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.306 | L2-Norm(final)=9.909 | 4710.6 samples/s | 73.6 steps/s
[Step=91050 Epoch=348.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.298 | L2-Norm(final)=9.909 | 2440.8 samples/s | 38.1 steps/s
[Step=91100 Epoch=349.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.290 | L2-Norm(final)=9.910 | 4287.4 samples/s | 67.0 steps/s
[Step=91150 Epoch=349.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.282 | L2-Norm(final)=9.911 | 4176.5 samples/s | 65.3 steps/s
[Step=91200 Epoch=349.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.273 | L2-Norm(final)=9.911 | 4299.7 samples/s | 67.2 steps/s
[Step=91250 Epoch=349.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=9.912 | 4297.1 samples/s | 67.1 steps/s
[Step=91300 Epoch=349.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.256 | L2-Norm(final)=9.913 | 2609.7 samples/s | 40.8 steps/s
[Step=91350 Epoch=350.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.248 | L2-Norm(final)=9.913 | 4145.9 samples/s | 64.8 steps/s
[Step=91400 Epoch=350.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.239 | L2-Norm(final)=9.914 | 4246.6 samples/s | 66.4 steps/s
[Step=91450 Epoch=350.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.230 | L2-Norm(final)=9.915 | 4285.4 samples/s | 67.0 steps/s
[Step=91500 Epoch=350.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=9.915 | 4211.0 samples/s | 65.8 steps/s
[Step=91550 Epoch=350.8] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.213 | L2-Norm(final)=9.916 | 2642.6 samples/s | 41.3 steps/s
[Step=91600 Epoch=351.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.204 | L2-Norm(final)=9.917 | 4101.3 samples/s | 64.1 steps/s
[Step=91650 Epoch=351.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.194 | L2-Norm(final)=9.917 | 4226.3 samples/s | 66.0 steps/s
[Step=91700 Epoch=351.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.185 | L2-Norm(final)=9.918 | 4273.7 samples/s | 66.8 steps/s
[Step=91750 Epoch=351.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=9.919 | 4198.6 samples/s | 65.6 steps/s
[Step=91800 Epoch=351.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=9.920 | 6340.7 samples/s | 99.1 steps/s
[Step=91850 Epoch=351.9] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=9.920 | 2182.5 samples/s | 34.1 steps/s
[Step=91900 Epoch=352.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.148 | L2-Norm(final)=9.921 | 4131.8 samples/s | 64.6 steps/s
[Step=91950 Epoch=352.3] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=9.922 | 4250.6 samples/s | 66.4 steps/s
[Step=92000 Epoch=352.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=9.923 | 4241.6 samples/s | 66.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step92000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=346.4] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=10.881 | 5678.2 samples/s | 88.7 steps/s
[Step=90050 Epoch=346.6] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=10.881 | 4165.8 samples/s | 65.1 steps/s
[Step=90100 Epoch=346.8] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=10.882 | 4840.0 samples/s | 75.6 steps/s
[Step=90150 Epoch=347.0] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=10.883 | 4638.3 samples/s | 72.5 steps/s
[Step=90200 Epoch=347.2] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=10.884 | 4760.5 samples/s | 74.4 steps/s
[Step=90250 Epoch=347.4] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=10.884 | 6862.9 samples/s | 107.2 steps/s
[Step=90300 Epoch=347.6] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=10.885 | 2421.3 samples/s | 37.8 steps/s
[Step=90350 Epoch=347.8] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.886 | 4771.5 samples/s | 74.6 steps/s
[Step=90400 Epoch=348.0] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.887 | 4656.5 samples/s | 72.8 steps/s
[Step=90450 Epoch=348.2] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.888 | 4840.0 samples/s | 75.6 steps/s
[Step=90500 Epoch=348.4] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.889 | 5580.0 samples/s | 87.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=348.4] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=10.899 | 6168.7 samples/s | 96.4 steps/s
[Step=90550 Epoch=348.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.331 | L2-Norm(final)=10.899 | 3833.3 samples/s | 59.9 steps/s
[Step=90600 Epoch=348.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.331 | L2-Norm(final)=10.900 | 4271.3 samples/s | 66.7 steps/s
[Step=90650 Epoch=348.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.330 | L2-Norm(final)=10.901 | 4218.2 samples/s | 65.9 steps/s
[Step=90700 Epoch=349.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.902 | 4210.4 samples/s | 65.8 steps/s
[Step=90750 Epoch=349.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=10.903 | 5847.0 samples/s | 91.4 steps/s
[Step=90800 Epoch=349.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.326 | L2-Norm(final)=10.903 | 2238.3 samples/s | 35.0 steps/s
[Step=90850 Epoch=349.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.325 | L2-Norm(final)=10.904 | 4343.4 samples/s | 67.9 steps/s
[Step=90900 Epoch=349.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.324 | L2-Norm(final)=10.905 | 4147.7 samples/s | 64.8 steps/s
[Step=90950 Epoch=350.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.323 | L2-Norm(final)=10.906 | 4259.4 samples/s | 66.6 steps/s
[Step=91000 Epoch=350.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.321 | L2-Norm(final)=10.906 | 4962.8 samples/s | 77.5 steps/s
[Step=91050 Epoch=350.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.320 | L2-Norm(final)=10.907 | 2417.9 samples/s | 37.8 steps/s
[Step=91100 Epoch=350.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=10.907 | 4203.5 samples/s | 65.7 steps/s
[Step=91150 Epoch=350.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.317 | L2-Norm(final)=10.908 | 4236.9 samples/s | 66.2 steps/s
[Step=91200 Epoch=351.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.315 | L2-Norm(final)=10.909 | 4045.8 samples/s | 63.2 steps/s
[Step=91250 Epoch=351.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.314 | L2-Norm(final)=10.909 | 4251.5 samples/s | 66.4 steps/s
[Step=91300 Epoch=351.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.312 | L2-Norm(final)=10.910 | 2547.4 samples/s | 39.8 steps/s
[Step=91350 Epoch=351.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.311 | L2-Norm(final)=10.910 | 4244.8 samples/s | 66.3 steps/s
[Step=91400 Epoch=351.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.309 | L2-Norm(final)=10.911 | 4330.6 samples/s | 67.7 steps/s
[Step=91450 Epoch=352.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.307 | L2-Norm(final)=10.912 | 4252.8 samples/s | 66.4 steps/s
[Step=91500 Epoch=352.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.305 | L2-Norm(final)=10.912 | 4280.6 samples/s | 66.9 steps/s
[Step=91550 Epoch=352.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.303 | L2-Norm(final)=10.913 | 2624.2 samples/s | 41.0 steps/s
[Step=91600 Epoch=352.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.302 | L2-Norm(final)=10.913 | 4132.2 samples/s | 64.6 steps/s
[Step=91650 Epoch=352.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.300 | L2-Norm(final)=10.914 | 4046.3 samples/s | 63.2 steps/s
[Step=91700 Epoch=353.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.298 | L2-Norm(final)=10.914 | 4115.4 samples/s | 64.3 steps/s
[Step=91750 Epoch=353.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.296 | L2-Norm(final)=10.915 | 4212.3 samples/s | 65.8 steps/s
[Step=91800 Epoch=353.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.294 | L2-Norm(final)=10.916 | 6720.1 samples/s | 105.0 steps/s
[Step=91850 Epoch=353.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.291 | L2-Norm(final)=10.916 | 2126.4 samples/s | 33.2 steps/s
[Step=91900 Epoch=353.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.289 | L2-Norm(final)=10.917 | 4054.2 samples/s | 63.3 steps/s
[Step=91950 Epoch=354.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.287 | L2-Norm(final)=10.917 | 4208.7 samples/s | 65.8 steps/s
[Step=92000 Epoch=354.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.285 | L2-Norm(final)=10.918 | 4211.2 samples/s | 65.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06799 | acc=0.9657 | tpr=0.9770 | fpr=0.0587 | 4765.6 samples/s | 18.6 steps/s
Avg test loss: 0.06935, Avg test acc: 0.96546, Avg tpr: 0.97616, Avg fpr: 0.05807, total FA: 453

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06342 | acc=0.9658 | tpr=0.9733 | fpr=0.0505 | 4811.8 samples/s | 18.8 steps/s
Avg test loss: 0.06636, Avg test acc: 0.96538, Avg tpr: 0.97290, Avg fpr: 0.05115, total FA: 399

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.28086 | acc=0.3071 | tpr=0.0073 | fpr=0.0419 | 4942.2 samples/s | 19.3 steps/s
Avg test loss: 5.27764, Avg test acc: 0.30455, Avg tpr: 0.00804, Avg fpr: 0.04333, total FA: 338

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.46334 | acc=0.3096 | tpr=0.0147 | fpr=0.0500 | 5015.3 samples/s | 19.6 steps/s
Avg test loss: 5.45501, Avg test acc: 0.30752, Avg tpr: 0.01743, Avg fpr: 0.05448, total FA: 425

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.49926 | acc=0.1395 | tpr=0.5088 | fpr=0.8672 | 5158.7 samples/s | 20.2 steps/s
[Step= 100] | Loss=5.47630 | acc=0.1400 | tpr=0.4819 | fpr=0.8664 | 5071.0 samples/s | 19.8 steps/s
[Step= 150] | Loss=5.47372 | acc=0.1404 | tpr=0.4813 | fpr=0.8659 | 8470.5 samples/s | 33.1 steps/s
[Step= 200] | Loss=5.47269 | acc=0.1411 | tpr=0.4776 | fpr=0.8651 | 7338.2 samples/s | 28.7 steps/s
[Step= 250] | Loss=5.46408 | acc=0.1418 | tpr=0.4882 | fpr=0.8645 | 7800.8 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.45871 | acc=0.1414 | tpr=0.4858 | fpr=0.8648 | 7734.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.46302 | acc=0.1408 | tpr=0.4753 | fpr=0.8652 | 7769.4 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.46090 | acc=0.1415 | tpr=0.4754 | fpr=0.8646 | 7398.4 samples/s | 28.9 steps/s
[Step= 450] | Loss=5.46382 | acc=0.1413 | tpr=0.4737 | fpr=0.8647 | 8042.9 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.46664 | acc=0.1417 | tpr=0.4758 | fpr=0.8643 | 7846.5 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.46732 | acc=0.1420 | tpr=0.4739 | fpr=0.8640 | 13932.3 samples/s | 54.4 steps/s
Avg test loss: 5.46886, Avg test acc: 0.14191, Avg tpr: 0.47504, Avg fpr: 0.86415, total FA: 119985

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.78736 | acc=0.1341 | tpr=0.5708 | fpr=0.8738 | 4865.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.78079 | acc=0.1350 | tpr=0.5373 | fpr=0.8725 | 5259.8 samples/s | 20.5 steps/s
[Step= 150] | Loss=5.77964 | acc=0.1352 | tpr=0.5389 | fpr=0.8722 | 8257.9 samples/s | 32.3 steps/s
[Step= 200] | Loss=5.77726 | acc=0.1358 | tpr=0.5355 | fpr=0.8715 | 7380.4 samples/s | 28.8 steps/s
[Step= 250] | Loss=5.76854 | acc=0.1367 | tpr=0.5362 | fpr=0.8706 | 7966.8 samples/s | 31.1 steps/s
[Step= 300] | Loss=5.76415 | acc=0.1369 | tpr=0.5396 | fpr=0.8705 | 7691.3 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.76938 | acc=0.1363 | tpr=0.5335 | fpr=0.8709 | 7679.3 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.76571 | acc=0.1364 | tpr=0.5290 | fpr=0.8707 | 7962.9 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.76925 | acc=0.1362 | tpr=0.5263 | fpr=0.8708 | 7671.7 samples/s | 30.0 steps/s
[Step= 500] | Loss=5.77144 | acc=0.1366 | tpr=0.5291 | fpr=0.8705 | 7922.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.77272 | acc=0.1367 | tpr=0.5233 | fpr=0.8704 | 13512.4 samples/s | 52.8 steps/s
Avg test loss: 5.77444, Avg test acc: 0.13655, Avg tpr: 0.52417, Avg fpr: 0.87049, total FA: 120866

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11338 | acc=0.9777 | tpr=0.9558 | fpr=0.0220 | 4908.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.11537 | acc=0.9783 | tpr=0.9659 | fpr=0.0214 | 5124.7 samples/s | 20.0 steps/s
[Step= 150] | Loss=0.12054 | acc=0.9775 | tpr=0.9654 | fpr=0.0223 | 8029.7 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.12364 | acc=0.9774 | tpr=0.9650 | fpr=0.0224 | 7804.5 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.12149 | acc=0.9778 | tpr=0.9651 | fpr=0.0220 | 7872.8 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.12340 | acc=0.9773 | tpr=0.9615 | fpr=0.0224 | 7785.0 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.12368 | acc=0.9773 | tpr=0.9624 | fpr=0.0225 | 7812.1 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.12508 | acc=0.9772 | tpr=0.9617 | fpr=0.0225 | 7691.6 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.12733 | acc=0.9769 | tpr=0.9601 | fpr=0.0228 | 7520.5 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.12660 | acc=0.9770 | tpr=0.9608 | fpr=0.0227 | 7829.6 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12553 | acc=0.9773 | tpr=0.9618 | fpr=0.0224 | 14557.2 samples/s | 56.9 steps/s
Avg test loss: 0.12534, Avg test acc: 0.97729, Avg tpr: 0.96157, Avg fpr: 0.02243, total FA: 3114

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11494 | acc=0.9776 | tpr=0.9558 | fpr=0.0220 | 4595.1 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.11758 | acc=0.9774 | tpr=0.9659 | fpr=0.0224 | 6388.8 samples/s | 25.0 steps/s
[Step= 150] | Loss=0.12333 | acc=0.9768 | tpr=0.9669 | fpr=0.0230 | 6922.0 samples/s | 27.0 steps/s
[Step= 200] | Loss=0.12597 | acc=0.9766 | tpr=0.9650 | fpr=0.0231 | 7714.1 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.12394 | acc=0.9769 | tpr=0.9651 | fpr=0.0229 | 7708.4 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.12589 | acc=0.9767 | tpr=0.9629 | fpr=0.0230 | 7805.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.12634 | acc=0.9765 | tpr=0.9643 | fpr=0.0233 | 7560.2 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.12759 | acc=0.9765 | tpr=0.9633 | fpr=0.0232 | 8016.0 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.13002 | acc=0.9761 | tpr=0.9615 | fpr=0.0236 | 7566.0 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.12939 | acc=0.9763 | tpr=0.9612 | fpr=0.0234 | 7597.5 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.12806 | acc=0.9766 | tpr=0.9614 | fpr=0.0232 | 14910.3 samples/s | 58.2 steps/s
Avg test loss: 0.12795, Avg test acc: 0.97657, Avg tpr: 0.96117, Avg fpr: 0.02315, total FA: 3215

server round 46/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=179.4] | Loss=0.04059 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.752 | L2-Norm(final)=16.102 | 6247.0 samples/s | 97.6 steps/s
[Step=92050 Epoch=179.5] | Loss=0.01095 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.755 | L2-Norm(final)=16.104 | 4551.0 samples/s | 71.1 steps/s
[Step=92100 Epoch=179.6] | Loss=0.01015 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.756 | L2-Norm(final)=16.108 | 5048.8 samples/s | 78.9 steps/s
[Step=92150 Epoch=179.7] | Loss=0.00985 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.758 | L2-Norm(final)=16.112 | 5006.5 samples/s | 78.2 steps/s
[Step=92200 Epoch=179.8] | Loss=0.00930 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.760 | L2-Norm(final)=16.116 | 5090.1 samples/s | 79.5 steps/s
[Step=92250 Epoch=179.9] | Loss=0.00974 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=16.119 | 4948.4 samples/s | 77.3 steps/s
[Step=92300 Epoch=180.0] | Loss=0.00959 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=16.123 | 5006.4 samples/s | 78.2 steps/s
[Step=92350 Epoch=180.1] | Loss=0.00960 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=16.127 | 5136.0 samples/s | 80.2 steps/s
[Step=92400 Epoch=180.2] | Loss=0.00965 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=16.131 | 4930.2 samples/s | 77.0 steps/s
[Step=92450 Epoch=180.3] | Loss=0.00961 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.767 | L2-Norm(final)=16.134 | 5014.1 samples/s | 78.3 steps/s
[Step=92500 Epoch=180.4] | Loss=0.00963 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=16.138 | 6705.4 samples/s | 104.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=180.4] | Loss=0.01137 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=16.175 | 6459.9 samples/s | 100.9 steps/s
[Step=92550 Epoch=180.5] | Loss=0.00978 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.786 | L2-Norm(final)=16.178 | 3710.2 samples/s | 58.0 steps/s
[Step=92600 Epoch=180.6] | Loss=0.00936 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.789 | L2-Norm(final)=16.181 | 4283.3 samples/s | 66.9 steps/s
[Step=92650 Epoch=180.7] | Loss=0.00925 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.790 | L2-Norm(final)=16.184 | 4243.4 samples/s | 66.3 steps/s
[Step=92700 Epoch=180.8] | Loss=0.00945 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=16.187 | 4210.8 samples/s | 65.8 steps/s
[Step=92750 Epoch=180.9] | Loss=0.00966 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.794 | L2-Norm(final)=16.190 | 4244.8 samples/s | 66.3 steps/s
[Step=92800 Epoch=181.0] | Loss=0.00953 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.796 | L2-Norm(final)=16.193 | 4241.4 samples/s | 66.3 steps/s
[Step=92850 Epoch=181.1] | Loss=0.00941 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.797 | L2-Norm(final)=16.196 | 4284.7 samples/s | 66.9 steps/s
[Step=92900 Epoch=181.2] | Loss=0.00930 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.799 | L2-Norm(final)=16.199 | 4201.4 samples/s | 65.6 steps/s
[Step=92950 Epoch=181.3] | Loss=0.00912 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.800 | L2-Norm(final)=16.202 | 4232.3 samples/s | 66.1 steps/s
[Step=93000 Epoch=181.4] | Loss=0.00896 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.802 | L2-Norm(final)=16.205 | 5473.3 samples/s | 85.5 steps/s
[Step=93050 Epoch=181.5] | Loss=0.00883 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.803 | L2-Norm(final)=16.208 | 2028.0 samples/s | 31.7 steps/s
[Step=93100 Epoch=181.6] | Loss=0.00846 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.804 | L2-Norm(final)=16.210 | 4456.3 samples/s | 69.6 steps/s
[Step=93150 Epoch=181.7] | Loss=0.00838 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.805 | L2-Norm(final)=16.213 | 4196.9 samples/s | 65.6 steps/s
[Step=93200 Epoch=181.8] | Loss=0.00824 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.806 | L2-Norm(final)=16.216 | 4476.6 samples/s | 69.9 steps/s
[Step=93250 Epoch=181.9] | Loss=0.00821 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.807 | L2-Norm(final)=16.218 | 4488.0 samples/s | 70.1 steps/s
[Step=93300 Epoch=182.0] | Loss=0.00816 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.808 | L2-Norm(final)=16.221 | 4497.7 samples/s | 70.3 steps/s
[Step=93350 Epoch=182.1] | Loss=0.00803 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.809 | L2-Norm(final)=16.223 | 4523.7 samples/s | 70.7 steps/s
[Step=93400 Epoch=182.2] | Loss=0.00795 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=16.226 | 4429.6 samples/s | 69.2 steps/s
[Step=93450 Epoch=182.3] | Loss=0.00788 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=16.228 | 4311.4 samples/s | 67.4 steps/s
[Step=93500 Epoch=182.4] | Loss=0.00772 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.811 | L2-Norm(final)=16.231 | 4839.7 samples/s | 75.6 steps/s
[Step=93550 Epoch=182.5] | Loss=0.00769 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.812 | L2-Norm(final)=16.233 | 2566.5 samples/s | 40.1 steps/s
[Step=93600 Epoch=182.6] | Loss=0.00759 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=16.236 | 4400.5 samples/s | 68.8 steps/s
[Step=93650 Epoch=182.7] | Loss=0.00752 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=16.238 | 4450.5 samples/s | 69.5 steps/s
[Step=93700 Epoch=182.8] | Loss=0.00750 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=16.240 | 4494.1 samples/s | 70.2 steps/s
[Step=93750 Epoch=182.8] | Loss=0.00743 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.815 | L2-Norm(final)=16.243 | 4471.7 samples/s | 69.9 steps/s
[Step=93800 Epoch=182.9] | Loss=0.00733 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.815 | L2-Norm(final)=16.245 | 4489.4 samples/s | 70.1 steps/s
[Step=93850 Epoch=183.0] | Loss=0.00725 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=16.247 | 4414.9 samples/s | 69.0 steps/s
[Step=93900 Epoch=183.1] | Loss=0.00727 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=16.250 | 4468.2 samples/s | 69.8 steps/s
[Step=93950 Epoch=183.2] | Loss=0.00721 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.817 | L2-Norm(final)=16.252 | 4427.4 samples/s | 69.2 steps/s
[Step=94000 Epoch=183.3] | Loss=0.00715 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=16.254 | 4481.0 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step94000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=179.9] | Loss=0.02384 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.943 | L2-Norm(final)=16.183 | 6596.9 samples/s | 103.1 steps/s
[Step=92050 Epoch=180.0] | Loss=0.01071 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=16.186 | 4394.4 samples/s | 68.7 steps/s
[Step=92100 Epoch=180.1] | Loss=0.01016 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.949 | L2-Norm(final)=16.189 | 5004.1 samples/s | 78.2 steps/s
[Step=92150 Epoch=180.2] | Loss=0.00982 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=16.192 | 5089.5 samples/s | 79.5 steps/s
[Step=92200 Epoch=180.2] | Loss=0.00970 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.952 | L2-Norm(final)=16.196 | 5057.1 samples/s | 79.0 steps/s
[Step=92250 Epoch=180.3] | Loss=0.00957 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=16.200 | 4972.3 samples/s | 77.7 steps/s
[Step=92300 Epoch=180.4] | Loss=0.00958 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.956 | L2-Norm(final)=16.203 | 5104.2 samples/s | 79.8 steps/s
[Step=92350 Epoch=180.5] | Loss=0.00996 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.957 | L2-Norm(final)=16.207 | 4899.2 samples/s | 76.6 steps/s
[Step=92400 Epoch=180.6] | Loss=0.00990 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.959 | L2-Norm(final)=16.211 | 5078.4 samples/s | 79.3 steps/s
[Step=92450 Epoch=180.7] | Loss=0.00978 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=16.214 | 5016.3 samples/s | 78.4 steps/s
[Step=92500 Epoch=180.8] | Loss=0.00988 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.962 | L2-Norm(final)=16.218 | 6978.4 samples/s | 109.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=180.8] | Loss=0.01164 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.979 | L2-Norm(final)=16.254 | 6356.2 samples/s | 99.3 steps/s
[Step=92550 Epoch=180.9] | Loss=0.00967 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.980 | L2-Norm(final)=16.257 | 4052.0 samples/s | 63.3 steps/s
[Step=92600 Epoch=181.0] | Loss=0.00910 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.983 | L2-Norm(final)=16.261 | 4444.5 samples/s | 69.4 steps/s
[Step=92650 Epoch=181.1] | Loss=0.00914 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.985 | L2-Norm(final)=16.264 | 4504.9 samples/s | 70.4 steps/s
[Step=92700 Epoch=181.2] | Loss=0.00894 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=16.267 | 4460.3 samples/s | 69.7 steps/s
[Step=92750 Epoch=181.3] | Loss=0.00893 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=16.271 | 4364.9 samples/s | 68.2 steps/s
[Step=92800 Epoch=181.4] | Loss=0.00895 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=16.274 | 4494.6 samples/s | 70.2 steps/s
[Step=92850 Epoch=181.5] | Loss=0.00914 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=16.277 | 4482.8 samples/s | 70.0 steps/s
[Step=92900 Epoch=181.6] | Loss=0.00908 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=16.280 | 4478.0 samples/s | 70.0 steps/s
[Step=92950 Epoch=181.7] | Loss=0.00898 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=16.283 | 4502.4 samples/s | 70.3 steps/s
[Step=93000 Epoch=181.8] | Loss=0.00875 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=16.286 | 5892.6 samples/s | 92.1 steps/s
[Step=93050 Epoch=181.9] | Loss=0.00842 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=16.288 | 2405.2 samples/s | 37.6 steps/s
[Step=93100 Epoch=182.0] | Loss=0.00822 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.000 | L2-Norm(final)=16.291 | 4355.8 samples/s | 68.1 steps/s
[Step=93150 Epoch=182.1] | Loss=0.00804 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.002 | L2-Norm(final)=16.294 | 4489.4 samples/s | 70.1 steps/s
[Step=93200 Epoch=182.2] | Loss=0.00782 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.003 | L2-Norm(final)=16.297 | 4411.0 samples/s | 68.9 steps/s
[Step=93250 Epoch=182.3] | Loss=0.00782 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.004 | L2-Norm(final)=16.299 | 4476.0 samples/s | 69.9 steps/s
[Step=93300 Epoch=182.4] | Loss=0.00761 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.005 | L2-Norm(final)=16.302 | 4487.5 samples/s | 70.1 steps/s
[Step=93350 Epoch=182.5] | Loss=0.00756 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.005 | L2-Norm(final)=16.304 | 4452.4 samples/s | 69.6 steps/s
[Step=93400 Epoch=182.6] | Loss=0.00754 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=16.307 | 4492.2 samples/s | 70.2 steps/s
[Step=93450 Epoch=182.7] | Loss=0.00756 | Reg=0.00256 | acc=0.9531 | L2-Norm=16.007 | L2-Norm(final)=16.309 | 4558.2 samples/s | 71.2 steps/s
[Step=93500 Epoch=182.8] | Loss=0.00752 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.008 | L2-Norm(final)=16.312 | 4888.2 samples/s | 76.4 steps/s
[Step=93550 Epoch=182.9] | Loss=0.00747 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=16.314 | 2599.0 samples/s | 40.6 steps/s
[Step=93600 Epoch=183.0] | Loss=0.00739 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=16.317 | 4457.9 samples/s | 69.7 steps/s
[Step=93650 Epoch=183.1] | Loss=0.00736 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=16.319 | 4437.3 samples/s | 69.3 steps/s
[Step=93700 Epoch=183.2] | Loss=0.00728 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.011 | L2-Norm(final)=16.322 | 4447.6 samples/s | 69.5 steps/s
[Step=93750 Epoch=183.3] | Loss=0.00725 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.012 | L2-Norm(final)=16.324 | 4484.3 samples/s | 70.1 steps/s
[Step=93800 Epoch=183.4] | Loss=0.00719 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.013 | L2-Norm(final)=16.327 | 4467.3 samples/s | 69.8 steps/s
[Step=93850 Epoch=183.5] | Loss=0.00715 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.013 | L2-Norm(final)=16.329 | 4500.9 samples/s | 70.3 steps/s
[Step=93900 Epoch=183.6] | Loss=0.00708 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.014 | L2-Norm(final)=16.331 | 4570.6 samples/s | 71.4 steps/s
[Step=93950 Epoch=183.7] | Loss=0.00704 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.014 | L2-Norm(final)=16.334 | 4340.6 samples/s | 67.8 steps/s
[Step=94000 Epoch=183.8] | Loss=0.00697 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.015 | L2-Norm(final)=16.336 | 4420.7 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step94000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=352.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.221 | L2-Norm(final)=9.949 | 5774.7 samples/s | 90.2 steps/s
[Step=92050 Epoch=352.7] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.221 | L2-Norm(final)=9.955 | 4249.5 samples/s | 66.4 steps/s
[Step=92100 Epoch=352.9] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.223 | L2-Norm(final)=9.961 | 4743.8 samples/s | 74.1 steps/s
[Step=92150 Epoch=353.1] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.225 | L2-Norm(final)=9.967 | 4752.2 samples/s | 74.3 steps/s
[Step=92200 Epoch=353.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.226 | L2-Norm(final)=9.971 | 4890.3 samples/s | 76.4 steps/s
[Step=92250 Epoch=353.5] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.227 | L2-Norm(final)=9.976 | 6423.4 samples/s | 100.4 steps/s
[Step=92300 Epoch=353.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.228 | L2-Norm(final)=9.980 | 2469.6 samples/s | 38.6 steps/s
[Step=92350 Epoch=353.9] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.229 | L2-Norm(final)=9.984 | 4513.0 samples/s | 70.5 steps/s
[Step=92400 Epoch=354.0] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.230 | L2-Norm(final)=9.988 | 4721.1 samples/s | 73.8 steps/s
[Step=92450 Epoch=354.2] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.231 | L2-Norm(final)=9.992 | 4807.2 samples/s | 75.1 steps/s
[Step=92500 Epoch=354.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=9.997 | 5407.3 samples/s | 84.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=354.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.240 | L2-Norm(final)=10.039 | 6686.0 samples/s | 104.5 steps/s
[Step=92550 Epoch=354.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.233 | L2-Norm(final)=10.043 | 3760.9 samples/s | 58.8 steps/s
[Step=92600 Epoch=354.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.223 | L2-Norm(final)=10.046 | 4218.9 samples/s | 65.9 steps/s
[Step=92650 Epoch=355.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.212 | L2-Norm(final)=10.048 | 4186.5 samples/s | 65.4 steps/s
[Step=92700 Epoch=355.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.200 | L2-Norm(final)=10.051 | 4248.7 samples/s | 66.4 steps/s
[Step=92750 Epoch=355.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.188 | L2-Norm(final)=10.053 | 5648.6 samples/s | 88.3 steps/s
[Step=92800 Epoch=355.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=10.055 | 2279.8 samples/s | 35.6 steps/s
[Step=92850 Epoch=355.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.163 | L2-Norm(final)=10.057 | 4273.5 samples/s | 66.8 steps/s
[Step=92900 Epoch=356.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.150 | L2-Norm(final)=10.059 | 4337.1 samples/s | 67.8 steps/s
[Step=92950 Epoch=356.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=10.060 | 4234.1 samples/s | 66.2 steps/s
[Step=93000 Epoch=356.3] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.124 | L2-Norm(final)=10.062 | 4678.6 samples/s | 73.1 steps/s
[Step=93050 Epoch=356.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=10.063 | 2436.8 samples/s | 38.1 steps/s
[Step=93100 Epoch=356.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.097 | L2-Norm(final)=10.065 | 4226.4 samples/s | 66.0 steps/s
[Step=93150 Epoch=356.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=10.066 | 4237.9 samples/s | 66.2 steps/s
[Step=93200 Epoch=357.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.069 | L2-Norm(final)=10.068 | 4230.2 samples/s | 66.1 steps/s
[Step=93250 Epoch=357.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.055 | L2-Norm(final)=10.069 | 4210.0 samples/s | 65.8 steps/s
[Step=93300 Epoch=357.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.041 | L2-Norm(final)=10.070 | 2630.2 samples/s | 41.1 steps/s
[Step=93350 Epoch=357.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.027 | L2-Norm(final)=10.072 | 4214.4 samples/s | 65.9 steps/s
[Step=93400 Epoch=357.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.013 | L2-Norm(final)=10.073 | 4205.0 samples/s | 65.7 steps/s
[Step=93450 Epoch=358.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.999 | L2-Norm(final)=10.075 | 4209.6 samples/s | 65.8 steps/s
[Step=93500 Epoch=358.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.985 | L2-Norm(final)=10.076 | 4293.1 samples/s | 67.1 steps/s
[Step=93550 Epoch=358.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.971 | L2-Norm(final)=10.078 | 2569.0 samples/s | 40.1 steps/s
[Step=93600 Epoch=358.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.957 | L2-Norm(final)=10.080 | 4217.4 samples/s | 65.9 steps/s
[Step=93650 Epoch=358.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.943 | L2-Norm(final)=10.082 | 4292.2 samples/s | 67.1 steps/s
[Step=93700 Epoch=359.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.929 | L2-Norm(final)=10.083 | 4203.6 samples/s | 65.7 steps/s
[Step=93750 Epoch=359.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.915 | L2-Norm(final)=10.085 | 4170.3 samples/s | 65.2 steps/s
[Step=93800 Epoch=359.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.902 | L2-Norm(final)=10.087 | 6309.2 samples/s | 98.6 steps/s
[Step=93850 Epoch=359.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.888 | L2-Norm(final)=10.089 | 2219.7 samples/s | 34.7 steps/s
[Step=93900 Epoch=359.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=10.091 | 4133.9 samples/s | 64.6 steps/s
[Step=93950 Epoch=360.0] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.860 | L2-Norm(final)=10.093 | 4229.0 samples/s | 66.1 steps/s
[Step=94000 Epoch=360.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.846 | L2-Norm(final)=10.095 | 4279.3 samples/s | 66.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step94000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=354.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.215 | L2-Norm(final)=10.935 | 6423.2 samples/s | 100.4 steps/s
[Step=92050 Epoch=354.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.215 | L2-Norm(final)=10.937 | 4025.3 samples/s | 62.9 steps/s
[Step=92100 Epoch=354.5] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.216 | L2-Norm(final)=10.939 | 4646.2 samples/s | 72.6 steps/s
[Step=92150 Epoch=354.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.217 | L2-Norm(final)=10.942 | 4749.2 samples/s | 74.2 steps/s
[Step=92200 Epoch=354.9] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.218 | L2-Norm(final)=10.945 | 5050.2 samples/s | 78.9 steps/s
[Step=92250 Epoch=355.1] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.218 | L2-Norm(final)=10.948 | 6326.2 samples/s | 98.8 steps/s
[Step=92300 Epoch=355.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=10.950 | 2399.4 samples/s | 37.5 steps/s
[Step=92350 Epoch=355.5] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.220 | L2-Norm(final)=10.953 | 4800.0 samples/s | 75.0 steps/s
[Step=92400 Epoch=355.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.221 | L2-Norm(final)=10.956 | 4790.6 samples/s | 74.9 steps/s
[Step=92450 Epoch=355.9] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=10.959 | 4631.1 samples/s | 72.4 steps/s
[Step=92500 Epoch=356.1] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=10.961 | 5639.0 samples/s | 88.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=356.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.229 | L2-Norm(final)=10.988 | 6273.6 samples/s | 98.0 steps/s
[Step=92550 Epoch=356.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.228 | L2-Norm(final)=10.991 | 3781.4 samples/s | 59.1 steps/s
[Step=92600 Epoch=356.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.226 | L2-Norm(final)=10.993 | 4243.9 samples/s | 66.3 steps/s
[Step=92650 Epoch=356.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.224 | L2-Norm(final)=10.995 | 4246.6 samples/s | 66.4 steps/s
[Step=92700 Epoch=356.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=10.996 | 4227.0 samples/s | 66.0 steps/s
[Step=92750 Epoch=357.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=10.998 | 5830.1 samples/s | 91.1 steps/s
[Step=92800 Epoch=357.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.216 | L2-Norm(final)=11.000 | 2253.1 samples/s | 35.2 steps/s
[Step=92850 Epoch=357.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.213 | L2-Norm(final)=11.001 | 4164.8 samples/s | 65.1 steps/s
[Step=92900 Epoch=357.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.209 | L2-Norm(final)=11.002 | 4263.9 samples/s | 66.6 steps/s
[Step=92950 Epoch=357.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.206 | L2-Norm(final)=11.004 | 4385.6 samples/s | 68.5 steps/s
[Step=93000 Epoch=358.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.202 | L2-Norm(final)=11.005 | 4808.9 samples/s | 75.1 steps/s
[Step=93050 Epoch=358.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.198 | L2-Norm(final)=11.006 | 2443.3 samples/s | 38.2 steps/s
[Step=93100 Epoch=358.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.194 | L2-Norm(final)=11.007 | 4203.6 samples/s | 65.7 steps/s
[Step=93150 Epoch=358.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.190 | L2-Norm(final)=11.008 | 4328.2 samples/s | 67.6 steps/s
[Step=93200 Epoch=358.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.186 | L2-Norm(final)=11.009 | 4135.2 samples/s | 64.6 steps/s
[Step=93250 Epoch=359.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.182 | L2-Norm(final)=11.010 | 4273.2 samples/s | 66.8 steps/s
[Step=93300 Epoch=359.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.178 | L2-Norm(final)=11.012 | 2607.3 samples/s | 40.7 steps/s
[Step=93350 Epoch=359.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.174 | L2-Norm(final)=11.013 | 4211.1 samples/s | 65.8 steps/s
[Step=93400 Epoch=359.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.169 | L2-Norm(final)=11.014 | 4257.0 samples/s | 66.5 steps/s
[Step=93450 Epoch=359.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.165 | L2-Norm(final)=11.015 | 4207.1 samples/s | 65.7 steps/s
[Step=93500 Epoch=359.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=11.016 | 4236.3 samples/s | 66.2 steps/s
[Step=93550 Epoch=360.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=11.017 | 2640.3 samples/s | 41.3 steps/s
[Step=93600 Epoch=360.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.151 | L2-Norm(final)=11.018 | 4158.8 samples/s | 65.0 steps/s
[Step=93650 Epoch=360.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.146 | L2-Norm(final)=11.019 | 4251.9 samples/s | 66.4 steps/s
[Step=93700 Epoch=360.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.142 | L2-Norm(final)=11.020 | 4240.1 samples/s | 66.3 steps/s
[Step=93750 Epoch=360.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=11.021 | 4260.6 samples/s | 66.6 steps/s
[Step=93800 Epoch=361.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.132 | L2-Norm(final)=11.022 | 6895.0 samples/s | 107.7 steps/s
[Step=93850 Epoch=361.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=11.024 | 2102.9 samples/s | 32.9 steps/s
[Step=93900 Epoch=361.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.025 | 4168.8 samples/s | 65.1 steps/s
[Step=93950 Epoch=361.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.026 | 4296.9 samples/s | 67.1 steps/s
[Step=94000 Epoch=361.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.027 | 4140.8 samples/s | 64.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06678 | acc=0.9668 | tpr=0.9732 | fpr=0.0471 | 4995.2 samples/s | 19.5 steps/s
Avg test loss: 0.06802, Avg test acc: 0.96570, Avg tpr: 0.97220, Avg fpr: 0.04858, total FA: 379

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06351 | acc=0.9664 | tpr=0.9739 | fpr=0.0498 | 4951.0 samples/s | 19.3 steps/s
Avg test loss: 0.06614, Avg test acc: 0.96558, Avg tpr: 0.97319, Avg fpr: 0.05115, total FA: 399

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.41318 | acc=0.3092 | tpr=0.0041 | fpr=0.0282 | 4998.9 samples/s | 19.5 steps/s
Avg test loss: 5.41269, Avg test acc: 0.30656, Avg tpr: 0.00478, Avg fpr: 0.02974, total FA: 232

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.64637 | acc=0.3109 | tpr=0.0120 | fpr=0.0401 | 4799.0 samples/s | 18.7 steps/s
Avg test loss: 5.63637, Avg test acc: 0.30824, Avg tpr: 0.01422, Avg fpr: 0.04512, total FA: 352

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.19726 | acc=0.1505 | tpr=0.4646 | fpr=0.8552 | 4975.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=5.17617 | acc=0.1510 | tpr=0.4414 | fpr=0.8544 | 6912.8 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.17426 | acc=0.1520 | tpr=0.4496 | fpr=0.8535 | 7719.1 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.17480 | acc=0.1522 | tpr=0.4426 | fpr=0.8531 | 8060.9 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.16637 | acc=0.1526 | tpr=0.4463 | fpr=0.8527 | 7696.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.16000 | acc=0.1523 | tpr=0.4436 | fpr=0.8531 | 8104.4 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.16414 | acc=0.1518 | tpr=0.4346 | fpr=0.8534 | 7569.4 samples/s | 29.6 steps/s
[Step= 400] | Loss=5.16260 | acc=0.1523 | tpr=0.4316 | fpr=0.8528 | 7902.0 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.16552 | acc=0.1519 | tpr=0.4279 | fpr=0.8531 | 7998.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.16792 | acc=0.1522 | tpr=0.4295 | fpr=0.8528 | 7884.5 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.16882 | acc=0.1525 | tpr=0.4290 | fpr=0.8526 | 13130.9 samples/s | 51.3 steps/s
Avg test loss: 5.17024, Avg test acc: 0.15231, Avg tpr: 0.43027, Avg fpr: 0.85274, total FA: 118401

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.86154 | acc=0.1337 | tpr=0.5398 | fpr=0.8736 | 4703.4 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.85607 | acc=0.1343 | tpr=0.5224 | fpr=0.8729 | 7393.1 samples/s | 28.9 steps/s
[Step= 150] | Loss=5.85618 | acc=0.1339 | tpr=0.5115 | fpr=0.8730 | 8018.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.85329 | acc=0.1341 | tpr=0.5082 | fpr=0.8727 | 7669.2 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.84497 | acc=0.1352 | tpr=0.5100 | fpr=0.8717 | 8019.8 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.84081 | acc=0.1354 | tpr=0.5127 | fpr=0.8715 | 7692.3 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.84621 | acc=0.1348 | tpr=0.5047 | fpr=0.8719 | 7692.7 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.84301 | acc=0.1350 | tpr=0.5011 | fpr=0.8716 | 8021.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.84633 | acc=0.1348 | tpr=0.4981 | fpr=0.8718 | 7609.1 samples/s | 29.7 steps/s
[Step= 500] | Loss=5.84865 | acc=0.1353 | tpr=0.5018 | fpr=0.8713 | 7830.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.84986 | acc=0.1354 | tpr=0.4962 | fpr=0.8711 | 14166.0 samples/s | 55.3 steps/s
Avg test loss: 5.85155, Avg test acc: 0.13530, Avg tpr: 0.49723, Avg fpr: 0.87128, total FA: 120976

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10777 | acc=0.9784 | tpr=0.9513 | fpr=0.0212 | 4705.6 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.11009 | acc=0.9788 | tpr=0.9616 | fpr=0.0209 | 7890.5 samples/s | 30.8 steps/s
[Step= 150] | Loss=0.11499 | acc=0.9778 | tpr=0.9597 | fpr=0.0219 | 7994.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.11788 | acc=0.9779 | tpr=0.9607 | fpr=0.0217 | 7659.9 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.11587 | acc=0.9783 | tpr=0.9616 | fpr=0.0214 | 7593.9 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.11772 | acc=0.9778 | tpr=0.9593 | fpr=0.0219 | 8343.2 samples/s | 32.6 steps/s
[Step= 350] | Loss=0.11797 | acc=0.9776 | tpr=0.9599 | fpr=0.0220 | 7641.7 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.11926 | acc=0.9776 | tpr=0.9584 | fpr=0.0220 | 7775.6 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.12137 | acc=0.9773 | tpr=0.9567 | fpr=0.0223 | 7898.5 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.12070 | acc=0.9774 | tpr=0.9568 | fpr=0.0223 | 8064.9 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.11969 | acc=0.9776 | tpr=0.9578 | fpr=0.0220 | 13576.9 samples/s | 53.0 steps/s
Avg test loss: 0.11947, Avg test acc: 0.97765, Avg tpr: 0.95761, Avg fpr: 0.02199, total FA: 3053

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11144 | acc=0.9781 | tpr=0.9469 | fpr=0.0213 | 4943.9 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11460 | acc=0.9779 | tpr=0.9616 | fpr=0.0218 | 7121.5 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.12021 | acc=0.9774 | tpr=0.9640 | fpr=0.0223 | 7637.4 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.12286 | acc=0.9772 | tpr=0.9617 | fpr=0.0225 | 7853.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12085 | acc=0.9776 | tpr=0.9624 | fpr=0.0221 | 7842.2 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.12291 | acc=0.9775 | tpr=0.9607 | fpr=0.0222 | 7768.4 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.12339 | acc=0.9773 | tpr=0.9624 | fpr=0.0225 | 7916.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.12470 | acc=0.9772 | tpr=0.9612 | fpr=0.0225 | 8186.6 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.12708 | acc=0.9768 | tpr=0.9586 | fpr=0.0229 | 7489.5 samples/s | 29.3 steps/s
[Step= 500] | Loss=0.12645 | acc=0.9770 | tpr=0.9590 | fpr=0.0227 | 7950.2 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12520 | acc=0.9772 | tpr=0.9594 | fpr=0.0225 | 14264.1 samples/s | 55.7 steps/s
Avg test loss: 0.12509, Avg test acc: 0.97721, Avg tpr: 0.95919, Avg fpr: 0.02246, total FA: 3119

server round 47/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=183.3] | Loss=0.01293 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=16.323 | 6113.5 samples/s | 95.5 steps/s
[Step=94050 Epoch=183.4] | Loss=0.01141 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.715 | L2-Norm(final)=16.326 | 4699.5 samples/s | 73.4 steps/s
[Step=94100 Epoch=183.5] | Loss=0.01305 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.718 | L2-Norm(final)=16.329 | 5095.9 samples/s | 79.6 steps/s
[Step=94150 Epoch=183.6] | Loss=0.01373 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.721 | L2-Norm(final)=16.333 | 4895.3 samples/s | 76.5 steps/s
[Step=94200 Epoch=183.7] | Loss=0.01369 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.723 | L2-Norm(final)=16.337 | 5026.5 samples/s | 78.5 steps/s
[Step=94250 Epoch=183.8] | Loss=0.01340 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=16.340 | 5022.0 samples/s | 78.5 steps/s
[Step=94300 Epoch=183.9] | Loss=0.01367 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.728 | L2-Norm(final)=16.344 | 5123.1 samples/s | 80.0 steps/s
[Step=94350 Epoch=184.0] | Loss=0.01360 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.730 | L2-Norm(final)=16.348 | 5130.0 samples/s | 80.2 steps/s
[Step=94400 Epoch=184.1] | Loss=0.01333 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.732 | L2-Norm(final)=16.351 | 4942.2 samples/s | 77.2 steps/s
[Step=94450 Epoch=184.2] | Loss=0.01294 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.734 | L2-Norm(final)=16.355 | 4955.6 samples/s | 77.4 steps/s
[Step=94500 Epoch=184.3] | Loss=0.01292 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=16.359 | 6746.6 samples/s | 105.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=184.3] | Loss=0.01872 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.755 | L2-Norm(final)=16.394 | 6823.1 samples/s | 106.6 steps/s
[Step=94550 Epoch=184.4] | Loss=0.01374 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=16.397 | 3878.2 samples/s | 60.6 steps/s
[Step=94600 Epoch=184.5] | Loss=0.01252 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.761 | L2-Norm(final)=16.400 | 4451.1 samples/s | 69.5 steps/s
[Step=94650 Epoch=184.6] | Loss=0.01174 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=16.404 | 4465.0 samples/s | 69.8 steps/s
[Step=94700 Epoch=184.7] | Loss=0.01172 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=16.407 | 4450.0 samples/s | 69.5 steps/s
[Step=94750 Epoch=184.8] | Loss=0.01161 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.768 | L2-Norm(final)=16.410 | 4474.1 samples/s | 69.9 steps/s
[Step=94800 Epoch=184.9] | Loss=0.01148 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.770 | L2-Norm(final)=16.413 | 4425.2 samples/s | 69.1 steps/s
[Step=94850 Epoch=185.0] | Loss=0.01125 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.772 | L2-Norm(final)=16.416 | 4475.1 samples/s | 69.9 steps/s
[Step=94900 Epoch=185.1] | Loss=0.01113 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.774 | L2-Norm(final)=16.418 | 4440.2 samples/s | 69.4 steps/s
[Step=94950 Epoch=185.2] | Loss=0.01095 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=16.421 | 4527.4 samples/s | 70.7 steps/s
[Step=95000 Epoch=185.3] | Loss=0.01079 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.777 | L2-Norm(final)=16.424 | 5789.8 samples/s | 90.5 steps/s
[Step=95050 Epoch=185.4] | Loss=0.01038 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=16.427 | 2401.1 samples/s | 37.5 steps/s
[Step=95100 Epoch=185.5] | Loss=0.01013 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.780 | L2-Norm(final)=16.430 | 4475.9 samples/s | 69.9 steps/s
[Step=95150 Epoch=185.6] | Loss=0.00983 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=16.432 | 4492.2 samples/s | 70.2 steps/s
[Step=95200 Epoch=185.7] | Loss=0.00964 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=16.435 | 4410.4 samples/s | 68.9 steps/s
[Step=95250 Epoch=185.8] | Loss=0.00953 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.784 | L2-Norm(final)=16.438 | 4421.8 samples/s | 69.1 steps/s
[Step=95300 Epoch=185.9] | Loss=0.00947 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=16.440 | 4506.1 samples/s | 70.4 steps/s
[Step=95350 Epoch=186.0] | Loss=0.00934 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.786 | L2-Norm(final)=16.443 | 4499.8 samples/s | 70.3 steps/s
[Step=95400 Epoch=186.1] | Loss=0.00918 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.787 | L2-Norm(final)=16.445 | 4391.7 samples/s | 68.6 steps/s
[Step=95450 Epoch=186.2] | Loss=0.00911 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.788 | L2-Norm(final)=16.448 | 4486.0 samples/s | 70.1 steps/s
[Step=95500 Epoch=186.3] | Loss=0.00898 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.789 | L2-Norm(final)=16.450 | 4814.6 samples/s | 75.2 steps/s
[Step=95550 Epoch=186.4] | Loss=0.00885 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.790 | L2-Norm(final)=16.453 | 2623.5 samples/s | 41.0 steps/s
[Step=95600 Epoch=186.5] | Loss=0.00872 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.791 | L2-Norm(final)=16.455 | 4367.6 samples/s | 68.2 steps/s
[Step=95650 Epoch=186.6] | Loss=0.00860 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=16.458 | 4456.2 samples/s | 69.6 steps/s
[Step=95700 Epoch=186.7] | Loss=0.00853 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.793 | L2-Norm(final)=16.460 | 4420.8 samples/s | 69.1 steps/s
[Step=95750 Epoch=186.7] | Loss=0.00845 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.793 | L2-Norm(final)=16.462 | 4528.7 samples/s | 70.8 steps/s
[Step=95800 Epoch=186.8] | Loss=0.00840 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.794 | L2-Norm(final)=16.465 | 4374.6 samples/s | 68.4 steps/s
[Step=95850 Epoch=186.9] | Loss=0.00828 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.795 | L2-Norm(final)=16.467 | 4526.3 samples/s | 70.7 steps/s
[Step=95900 Epoch=187.0] | Loss=0.00826 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.796 | L2-Norm(final)=16.469 | 4435.7 samples/s | 69.3 steps/s
[Step=95950 Epoch=187.1] | Loss=0.00820 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.796 | L2-Norm(final)=16.472 | 4550.9 samples/s | 71.1 steps/s
[Step=96000 Epoch=187.2] | Loss=0.00813 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.797 | L2-Norm(final)=16.474 | 4495.1 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step96000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=183.8] | Loss=0.00952 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.908 | L2-Norm(final)=16.406 | 5736.5 samples/s | 89.6 steps/s
[Step=94050 Epoch=183.9] | Loss=0.01646 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.912 | L2-Norm(final)=16.408 | 4543.1 samples/s | 71.0 steps/s
[Step=94100 Epoch=184.0] | Loss=0.01466 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.915 | L2-Norm(final)=16.412 | 5108.5 samples/s | 79.8 steps/s
[Step=94150 Epoch=184.1] | Loss=0.01370 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=16.415 | 5031.3 samples/s | 78.6 steps/s
[Step=94200 Epoch=184.2] | Loss=0.01374 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.919 | L2-Norm(final)=16.418 | 4987.8 samples/s | 77.9 steps/s
[Step=94250 Epoch=184.3] | Loss=0.01357 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.922 | L2-Norm(final)=16.422 | 4997.0 samples/s | 78.1 steps/s
[Step=94300 Epoch=184.4] | Loss=0.01380 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.924 | L2-Norm(final)=16.425 | 5156.3 samples/s | 80.6 steps/s
[Step=94350 Epoch=184.5] | Loss=0.01349 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.926 | L2-Norm(final)=16.429 | 4966.3 samples/s | 77.6 steps/s
[Step=94400 Epoch=184.5] | Loss=0.01332 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.928 | L2-Norm(final)=16.433 | 4957.3 samples/s | 77.5 steps/s
[Step=94450 Epoch=184.6] | Loss=0.01341 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.930 | L2-Norm(final)=16.436 | 5146.9 samples/s | 80.4 steps/s
[Step=94500 Epoch=184.7] | Loss=0.01329 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.932 | L2-Norm(final)=16.440 | 6595.8 samples/s | 103.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=184.7] | Loss=0.02047 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.951 | L2-Norm(final)=16.475 | 5959.2 samples/s | 93.1 steps/s
[Step=94550 Epoch=184.8] | Loss=0.01228 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=16.479 | 4378.2 samples/s | 68.4 steps/s
[Step=94600 Epoch=184.9] | Loss=0.01153 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.957 | L2-Norm(final)=16.482 | 4502.0 samples/s | 70.3 steps/s
[Step=94650 Epoch=185.0] | Loss=0.01185 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.959 | L2-Norm(final)=16.485 | 4444.9 samples/s | 69.5 steps/s
[Step=94700 Epoch=185.1] | Loss=0.01173 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.962 | L2-Norm(final)=16.489 | 4479.8 samples/s | 70.0 steps/s
[Step=94750 Epoch=185.2] | Loss=0.01151 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=16.492 | 4456.0 samples/s | 69.6 steps/s
[Step=94800 Epoch=185.3] | Loss=0.01137 | Reg=0.00255 | acc=0.9531 | L2-Norm=15.966 | L2-Norm(final)=16.495 | 4444.9 samples/s | 69.5 steps/s
[Step=94850 Epoch=185.4] | Loss=0.01112 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=16.498 | 4430.0 samples/s | 69.2 steps/s
[Step=94900 Epoch=185.5] | Loss=0.01107 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.970 | L2-Norm(final)=16.500 | 4531.5 samples/s | 70.8 steps/s
[Step=94950 Epoch=185.6] | Loss=0.01091 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=16.503 | 4434.7 samples/s | 69.3 steps/s
[Step=95000 Epoch=185.7] | Loss=0.01081 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.973 | L2-Norm(final)=16.506 | 5883.7 samples/s | 91.9 steps/s
[Step=95050 Epoch=185.8] | Loss=0.01059 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=16.509 | 2423.0 samples/s | 37.9 steps/s
[Step=95100 Epoch=185.9] | Loss=0.01031 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.976 | L2-Norm(final)=16.512 | 4439.8 samples/s | 69.4 steps/s
[Step=95150 Epoch=186.0] | Loss=0.01007 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.978 | L2-Norm(final)=16.515 | 4401.7 samples/s | 68.8 steps/s
[Step=95200 Epoch=186.1] | Loss=0.00990 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.979 | L2-Norm(final)=16.517 | 4397.1 samples/s | 68.7 steps/s
[Step=95250 Epoch=186.2] | Loss=0.00972 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.980 | L2-Norm(final)=16.520 | 4455.1 samples/s | 69.6 steps/s
[Step=95300 Epoch=186.3] | Loss=0.00954 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=16.523 | 4461.8 samples/s | 69.7 steps/s
[Step=95350 Epoch=186.4] | Loss=0.00928 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.983 | L2-Norm(final)=16.525 | 4482.7 samples/s | 70.0 steps/s
[Step=95400 Epoch=186.5] | Loss=0.00918 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=16.528 | 4486.2 samples/s | 70.1 steps/s
[Step=95450 Epoch=186.6] | Loss=0.00920 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=16.530 | 4488.7 samples/s | 70.1 steps/s
[Step=95500 Epoch=186.7] | Loss=0.00909 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=16.533 | 4976.6 samples/s | 77.8 steps/s
[Step=95550 Epoch=186.8] | Loss=0.00896 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=16.535 | 2586.1 samples/s | 40.4 steps/s
[Step=95600 Epoch=186.9] | Loss=0.00885 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.988 | L2-Norm(final)=16.538 | 4360.2 samples/s | 68.1 steps/s
[Step=95650 Epoch=187.0] | Loss=0.00874 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=16.540 | 4498.5 samples/s | 70.3 steps/s
[Step=95700 Epoch=187.1] | Loss=0.00866 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=16.542 | 4420.8 samples/s | 69.1 steps/s
[Step=95750 Epoch=187.2] | Loss=0.00857 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=16.545 | 4556.0 samples/s | 71.2 steps/s
[Step=95800 Epoch=187.3] | Loss=0.00849 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=16.547 | 4362.8 samples/s | 68.2 steps/s
[Step=95850 Epoch=187.4] | Loss=0.00845 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=16.550 | 4516.2 samples/s | 70.6 steps/s
[Step=95900 Epoch=187.5] | Loss=0.00835 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=16.552 | 4459.8 samples/s | 69.7 steps/s
[Step=95950 Epoch=187.6] | Loss=0.00826 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=16.554 | 4458.0 samples/s | 69.7 steps/s
[Step=96000 Epoch=187.7] | Loss=0.00820 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=16.557 | 4466.5 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step96000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=360.2] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.974 | L2-Norm(final)=10.156 | 5490.2 samples/s | 85.8 steps/s
[Step=94050 Epoch=360.4] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.974 | L2-Norm(final)=10.165 | 4554.9 samples/s | 71.2 steps/s
[Step=94100 Epoch=360.6] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.978 | L2-Norm(final)=10.175 | 4750.6 samples/s | 74.2 steps/s
[Step=94150 Epoch=360.7] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.980 | L2-Norm(final)=10.184 | 4708.8 samples/s | 73.6 steps/s
[Step=94200 Epoch=360.9] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.983 | L2-Norm(final)=10.193 | 4764.1 samples/s | 74.4 steps/s
[Step=94250 Epoch=361.1] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.985 | L2-Norm(final)=10.201 | 6637.4 samples/s | 103.7 steps/s
[Step=94300 Epoch=361.3] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.987 | L2-Norm(final)=10.209 | 2423.0 samples/s | 37.9 steps/s
[Step=94350 Epoch=361.5] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.989 | L2-Norm(final)=10.216 | 4686.9 samples/s | 73.2 steps/s
[Step=94400 Epoch=361.7] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.991 | L2-Norm(final)=10.223 | 4705.3 samples/s | 73.5 steps/s
[Step=94450 Epoch=361.9] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.992 | L2-Norm(final)=10.229 | 4846.1 samples/s | 75.7 steps/s
[Step=94500 Epoch=362.1] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.993 | L2-Norm(final)=10.235 | 5355.5 samples/s | 83.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=362.1] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.005 | L2-Norm(final)=10.297 | 6251.1 samples/s | 97.7 steps/s
[Step=94550 Epoch=362.3] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.004 | L2-Norm(final)=10.304 | 3799.8 samples/s | 59.4 steps/s
[Step=94600 Epoch=362.5] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.995 | L2-Norm(final)=10.309 | 4304.4 samples/s | 67.3 steps/s
[Step=94650 Epoch=362.7] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.984 | L2-Norm(final)=10.313 | 4238.0 samples/s | 66.2 steps/s
[Step=94700 Epoch=362.9] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.972 | L2-Norm(final)=10.316 | 4268.7 samples/s | 66.7 steps/s
[Step=94750 Epoch=363.0] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.959 | L2-Norm(final)=10.319 | 5543.7 samples/s | 86.6 steps/s
[Step=94800 Epoch=363.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.945 | L2-Norm(final)=10.321 | 2252.7 samples/s | 35.2 steps/s
[Step=94850 Epoch=363.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.931 | L2-Norm(final)=10.323 | 4281.1 samples/s | 66.9 steps/s
[Step=94900 Epoch=363.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.917 | L2-Norm(final)=10.325 | 4176.6 samples/s | 65.3 steps/s
[Step=94950 Epoch=363.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.902 | L2-Norm(final)=10.326 | 4285.0 samples/s | 67.0 steps/s
[Step=95000 Epoch=364.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.888 | L2-Norm(final)=10.328 | 4767.9 samples/s | 74.5 steps/s
[Step=95050 Epoch=364.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.873 | L2-Norm(final)=10.330 | 2447.9 samples/s | 38.2 steps/s
[Step=95100 Epoch=364.4] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.858 | L2-Norm(final)=10.332 | 4189.6 samples/s | 65.5 steps/s
[Step=95150 Epoch=364.6] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.844 | L2-Norm(final)=10.334 | 4232.0 samples/s | 66.1 steps/s
[Step=95200 Epoch=364.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.829 | L2-Norm(final)=10.335 | 4305.3 samples/s | 67.3 steps/s
[Step=95250 Epoch=365.0] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.814 | L2-Norm(final)=10.337 | 4246.2 samples/s | 66.3 steps/s
[Step=95300 Epoch=365.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.799 | L2-Norm(final)=10.339 | 2611.0 samples/s | 40.8 steps/s
[Step=95350 Epoch=365.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=10.341 | 4266.5 samples/s | 66.7 steps/s
[Step=95400 Epoch=365.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.769 | L2-Norm(final)=10.343 | 4200.0 samples/s | 65.6 steps/s
[Step=95450 Epoch=365.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.754 | L2-Norm(final)=10.345 | 4162.3 samples/s | 65.0 steps/s
[Step=95500 Epoch=365.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.739 | L2-Norm(final)=10.347 | 4270.6 samples/s | 66.7 steps/s
[Step=95550 Epoch=366.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.724 | L2-Norm(final)=10.350 | 2637.2 samples/s | 41.2 steps/s
[Step=95600 Epoch=366.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.710 | L2-Norm(final)=10.352 | 4202.3 samples/s | 65.7 steps/s
[Step=95650 Epoch=366.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.695 | L2-Norm(final)=10.354 | 4206.1 samples/s | 65.7 steps/s
[Step=95700 Epoch=366.7] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.680 | L2-Norm(final)=10.357 | 4259.6 samples/s | 66.6 steps/s
[Step=95750 Epoch=366.9] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.666 | L2-Norm(final)=10.359 | 4268.9 samples/s | 66.7 steps/s
[Step=95800 Epoch=367.1] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.652 | L2-Norm(final)=10.362 | 6247.4 samples/s | 97.6 steps/s
[Step=95850 Epoch=367.3] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.638 | L2-Norm(final)=10.364 | 2164.1 samples/s | 33.8 steps/s
[Step=95900 Epoch=367.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.624 | L2-Norm(final)=10.367 | 4240.1 samples/s | 66.3 steps/s
[Step=95950 Epoch=367.6] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.610 | L2-Norm(final)=10.369 | 4299.4 samples/s | 67.2 steps/s
[Step=96000 Epoch=367.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.596 | L2-Norm(final)=10.372 | 4201.4 samples/s | 65.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step96000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=361.8] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.987 | L2-Norm(final)=11.061 | 6576.1 samples/s | 102.8 steps/s
[Step=94050 Epoch=362.0] | Loss=0.00006 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.989 | L2-Norm(final)=11.069 | 4163.3 samples/s | 65.1 steps/s
[Step=94100 Epoch=362.2] | Loss=0.00004 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.993 | L2-Norm(final)=11.078 | 4708.3 samples/s | 73.6 steps/s
[Step=94150 Epoch=362.4] | Loss=0.00004 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.996 | L2-Norm(final)=11.084 | 4597.0 samples/s | 71.8 steps/s
[Step=94200 Epoch=362.6] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=11.090 | 4681.6 samples/s | 73.2 steps/s
[Step=94250 Epoch=362.8] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.000 | L2-Norm(final)=11.095 | 6838.0 samples/s | 106.8 steps/s
[Step=94300 Epoch=363.0] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.002 | L2-Norm(final)=11.099 | 2407.9 samples/s | 37.6 steps/s
[Step=94350 Epoch=363.2] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.004 | L2-Norm(final)=11.104 | 4696.8 samples/s | 73.4 steps/s
[Step=94400 Epoch=363.4] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.005 | L2-Norm(final)=11.108 | 4789.0 samples/s | 74.8 steps/s
[Step=94450 Epoch=363.6] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.006 | L2-Norm(final)=11.112 | 4698.1 samples/s | 73.4 steps/s
[Step=94500 Epoch=363.8] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.008 | L2-Norm(final)=11.117 | 5622.3 samples/s | 87.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=363.8] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.020 | L2-Norm(final)=11.157 | 7294.8 samples/s | 114.0 steps/s
[Step=94550 Epoch=364.0] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.017 | L2-Norm(final)=11.159 | 3561.2 samples/s | 55.6 steps/s
[Step=94600 Epoch=364.2] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.015 | L2-Norm(final)=11.163 | 4236.8 samples/s | 66.2 steps/s
[Step=94650 Epoch=364.3] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.012 | L2-Norm(final)=11.166 | 4258.8 samples/s | 66.5 steps/s
[Step=94700 Epoch=364.5] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.009 | L2-Norm(final)=11.169 | 4267.5 samples/s | 66.7 steps/s
[Step=94750 Epoch=364.7] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.006 | L2-Norm(final)=11.172 | 5757.5 samples/s | 90.0 steps/s
[Step=94800 Epoch=364.9] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.002 | L2-Norm(final)=11.174 | 2262.1 samples/s | 35.3 steps/s
[Step=94850 Epoch=365.1] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=11.176 | 4193.4 samples/s | 65.5 steps/s
[Step=94900 Epoch=365.3] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.993 | L2-Norm(final)=11.178 | 4301.0 samples/s | 67.2 steps/s
[Step=94950 Epoch=365.5] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.988 | L2-Norm(final)=11.179 | 4105.8 samples/s | 64.2 steps/s
[Step=95000 Epoch=365.7] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.983 | L2-Norm(final)=11.181 | 4988.4 samples/s | 77.9 steps/s
[Step=95050 Epoch=365.9] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.978 | L2-Norm(final)=11.182 | 2437.3 samples/s | 38.1 steps/s
[Step=95100 Epoch=366.1] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.972 | L2-Norm(final)=11.183 | 4256.0 samples/s | 66.5 steps/s
[Step=95150 Epoch=366.3] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.966 | L2-Norm(final)=11.185 | 4201.7 samples/s | 65.7 steps/s
[Step=95200 Epoch=366.5] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.961 | L2-Norm(final)=11.186 | 4296.2 samples/s | 67.1 steps/s
[Step=95250 Epoch=366.7] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.955 | L2-Norm(final)=11.187 | 4212.7 samples/s | 65.8 steps/s
[Step=95300 Epoch=366.8] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.948 | L2-Norm(final)=11.188 | 2571.4 samples/s | 40.2 steps/s
[Step=95350 Epoch=367.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.942 | L2-Norm(final)=11.189 | 4236.0 samples/s | 66.2 steps/s
[Step=95400 Epoch=367.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.936 | L2-Norm(final)=11.190 | 4240.4 samples/s | 66.3 steps/s
[Step=95450 Epoch=367.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.929 | L2-Norm(final)=11.191 | 4238.9 samples/s | 66.2 steps/s
[Step=95500 Epoch=367.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.923 | L2-Norm(final)=11.192 | 4221.7 samples/s | 66.0 steps/s
[Step=95550 Epoch=367.8] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.916 | L2-Norm(final)=11.193 | 2684.9 samples/s | 42.0 steps/s
[Step=95600 Epoch=368.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.909 | L2-Norm(final)=11.194 | 4035.1 samples/s | 63.0 steps/s
[Step=95650 Epoch=368.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.903 | L2-Norm(final)=11.195 | 4299.8 samples/s | 67.2 steps/s
[Step=95700 Epoch=368.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=11.196 | 4209.3 samples/s | 65.8 steps/s
[Step=95750 Epoch=368.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.889 | L2-Norm(final)=11.197 | 4294.8 samples/s | 67.1 steps/s
[Step=95800 Epoch=368.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.199 | 6792.0 samples/s | 106.1 steps/s
[Step=95850 Epoch=369.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.200 | 2117.8 samples/s | 33.1 steps/s
[Step=95900 Epoch=369.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=11.201 | 4186.9 samples/s | 65.4 steps/s
[Step=95950 Epoch=369.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.860 | L2-Norm(final)=11.202 | 4225.0 samples/s | 66.0 steps/s
[Step=96000 Epoch=369.5] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.853 | L2-Norm(final)=11.203 | 4212.4 samples/s | 65.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06764 | acc=0.9643 | tpr=0.9677 | fpr=0.0431 | 4748.3 samples/s | 18.5 steps/s
Avg test loss: 0.06931, Avg test acc: 0.96334, Avg tpr: 0.96689, Avg fpr: 0.04448, total FA: 347

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06126 | acc=0.9661 | tpr=0.9720 | fpr=0.0468 | 4919.8 samples/s | 19.2 steps/s
Avg test loss: 0.06428, Avg test acc: 0.96462, Avg tpr: 0.97074, Avg fpr: 0.04884, total FA: 381

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.18066 | acc=0.3077 | tpr=0.0076 | fpr=0.0406 | 5111.7 samples/s | 20.0 steps/s
Avg test loss: 5.17811, Avg test acc: 0.30499, Avg tpr: 0.00799, Avg fpr: 0.04179, total FA: 326

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.75830 | acc=0.3112 | tpr=0.0106 | fpr=0.0362 | 4988.8 samples/s | 19.5 steps/s
Avg test loss: 5.74720, Avg test acc: 0.30856, Avg tpr: 0.01207, Avg fpr: 0.03935, total FA: 307

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.96961 | acc=0.1523 | tpr=0.4735 | fpr=0.8534 | 5103.1 samples/s | 19.9 steps/s
[Step= 100] | Loss=4.94741 | acc=0.1529 | tpr=0.4520 | fpr=0.8527 | 6564.2 samples/s | 25.6 steps/s
[Step= 150] | Loss=4.94746 | acc=0.1531 | tpr=0.4481 | fpr=0.8523 | 8417.2 samples/s | 32.9 steps/s
[Step= 200] | Loss=4.94927 | acc=0.1533 | tpr=0.4404 | fpr=0.8520 | 7701.4 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.94033 | acc=0.1541 | tpr=0.4454 | fpr=0.8512 | 7694.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=4.93578 | acc=0.1541 | tpr=0.4436 | fpr=0.8512 | 7930.8 samples/s | 31.0 steps/s
[Step= 350] | Loss=4.94020 | acc=0.1536 | tpr=0.4339 | fpr=0.8515 | 8110.1 samples/s | 31.7 steps/s
[Step= 400] | Loss=4.93870 | acc=0.1539 | tpr=0.4289 | fpr=0.8511 | 7562.4 samples/s | 29.5 steps/s
[Step= 450] | Loss=4.94070 | acc=0.1535 | tpr=0.4236 | fpr=0.8514 | 7686.6 samples/s | 30.0 steps/s
[Step= 500] | Loss=4.94291 | acc=0.1538 | tpr=0.4256 | fpr=0.8511 | 7956.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=4.94323 | acc=0.1540 | tpr=0.4226 | fpr=0.8509 | 14428.0 samples/s | 56.4 steps/s
Avg test loss: 4.94461, Avg test acc: 0.15381, Avg tpr: 0.42353, Avg fpr: 0.85109, total FA: 118172

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.28627 | acc=0.1412 | tpr=0.5575 | fpr=0.8662 | 4839.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.28311 | acc=0.1427 | tpr=0.5288 | fpr=0.8645 | 7571.9 samples/s | 29.6 steps/s
[Step= 150] | Loss=5.28429 | acc=0.1422 | tpr=0.5202 | fpr=0.8647 | 7748.2 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.28251 | acc=0.1419 | tpr=0.5126 | fpr=0.8649 | 7576.1 samples/s | 29.6 steps/s
[Step= 250] | Loss=5.27507 | acc=0.1431 | tpr=0.5127 | fpr=0.8637 | 7798.7 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.27166 | acc=0.1432 | tpr=0.5156 | fpr=0.8636 | 8047.4 samples/s | 31.4 steps/s
[Step= 350] | Loss=5.27675 | acc=0.1427 | tpr=0.5085 | fpr=0.8640 | 7532.3 samples/s | 29.4 steps/s
[Step= 400] | Loss=5.27410 | acc=0.1427 | tpr=0.5049 | fpr=0.8639 | 8038.1 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.27750 | acc=0.1423 | tpr=0.5015 | fpr=0.8642 | 7550.1 samples/s | 29.5 steps/s
[Step= 500] | Loss=5.27952 | acc=0.1428 | tpr=0.5057 | fpr=0.8638 | 7963.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.28027 | acc=0.1428 | tpr=0.5010 | fpr=0.8637 | 14381.3 samples/s | 56.2 steps/s
Avg test loss: 5.28181, Avg test acc: 0.14264, Avg tpr: 0.50158, Avg fpr: 0.86388, total FA: 119948

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11540 | acc=0.9759 | tpr=0.9602 | fpr=0.0238 | 4952.1 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11737 | acc=0.9764 | tpr=0.9723 | fpr=0.0236 | 7004.9 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.12248 | acc=0.9753 | tpr=0.9683 | fpr=0.0246 | 7754.9 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.12534 | acc=0.9750 | tpr=0.9683 | fpr=0.0249 | 7710.4 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.12324 | acc=0.9754 | tpr=0.9677 | fpr=0.0244 | 7978.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.12518 | acc=0.9751 | tpr=0.9673 | fpr=0.0247 | 7764.6 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.12552 | acc=0.9751 | tpr=0.9674 | fpr=0.0248 | 8314.6 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.12673 | acc=0.9750 | tpr=0.9666 | fpr=0.0248 | 7465.6 samples/s | 29.2 steps/s
[Step= 450] | Loss=0.12883 | acc=0.9748 | tpr=0.9654 | fpr=0.0250 | 8251.2 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.12820 | acc=0.9749 | tpr=0.9661 | fpr=0.0250 | 7649.7 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.12700 | acc=0.9752 | tpr=0.9666 | fpr=0.0247 | 13988.3 samples/s | 54.6 steps/s
Avg test loss: 0.12677, Avg test acc: 0.97519, Avg tpr: 0.96632, Avg fpr: 0.02465, total FA: 3422

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10796 | acc=0.9788 | tpr=0.9513 | fpr=0.0207 | 5091.4 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.11134 | acc=0.9784 | tpr=0.9595 | fpr=0.0212 | 6527.2 samples/s | 25.5 steps/s
[Step= 150] | Loss=0.11683 | acc=0.9777 | tpr=0.9611 | fpr=0.0220 | 8263.5 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.11957 | acc=0.9776 | tpr=0.9607 | fpr=0.0221 | 7642.6 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.11763 | acc=0.9780 | tpr=0.9607 | fpr=0.0217 | 7880.8 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.11966 | acc=0.9779 | tpr=0.9585 | fpr=0.0218 | 7615.3 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.12017 | acc=0.9776 | tpr=0.9606 | fpr=0.0220 | 8186.5 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.12146 | acc=0.9776 | tpr=0.9595 | fpr=0.0221 | 7835.3 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.12374 | acc=0.9771 | tpr=0.9576 | fpr=0.0225 | 7758.3 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12314 | acc=0.9772 | tpr=0.9577 | fpr=0.0224 | 8079.3 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.12199 | acc=0.9775 | tpr=0.9582 | fpr=0.0222 | 13629.1 samples/s | 53.2 steps/s
Avg test loss: 0.12189, Avg test acc: 0.97748, Avg tpr: 0.95800, Avg fpr: 0.02217, total FA: 3078

server round 48/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=187.2] | Loss=0.00851 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=16.544 | 6234.0 samples/s | 97.4 steps/s
[Step=96050 Epoch=187.3] | Loss=0.02039 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.691 | L2-Norm(final)=16.545 | 4632.6 samples/s | 72.4 steps/s
[Step=96100 Epoch=187.4] | Loss=0.01915 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.694 | L2-Norm(final)=16.548 | 4855.0 samples/s | 75.9 steps/s
[Step=96150 Epoch=187.5] | Loss=0.01898 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.697 | L2-Norm(final)=16.552 | 5030.0 samples/s | 78.6 steps/s
[Step=96200 Epoch=187.6] | Loss=0.01835 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.700 | L2-Norm(final)=16.555 | 5066.9 samples/s | 79.2 steps/s
[Step=96250 Epoch=187.7] | Loss=0.01814 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.702 | L2-Norm(final)=16.559 | 5022.5 samples/s | 78.5 steps/s
[Step=96300 Epoch=187.8] | Loss=0.01806 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.705 | L2-Norm(final)=16.563 | 4989.3 samples/s | 78.0 steps/s
[Step=96350 Epoch=187.9] | Loss=0.01783 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.708 | L2-Norm(final)=16.566 | 5069.3 samples/s | 79.2 steps/s
[Step=96400 Epoch=188.0] | Loss=0.01765 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.710 | L2-Norm(final)=16.570 | 5001.0 samples/s | 78.1 steps/s
[Step=96450 Epoch=188.1] | Loss=0.01745 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=16.574 | 5024.5 samples/s | 78.5 steps/s
[Step=96500 Epoch=188.2] | Loss=0.01752 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=16.577 | 6755.2 samples/s | 105.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=188.2] | Loss=0.02602 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.736 | L2-Norm(final)=16.613 | 6161.4 samples/s | 96.3 steps/s
[Step=96550 Epoch=188.3] | Loss=0.01549 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.740 | L2-Norm(final)=16.616 | 4129.9 samples/s | 64.5 steps/s
[Step=96600 Epoch=188.4] | Loss=0.01472 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.743 | L2-Norm(final)=16.619 | 4446.5 samples/s | 69.5 steps/s
[Step=96650 Epoch=188.5] | Loss=0.01479 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.746 | L2-Norm(final)=16.623 | 4490.9 samples/s | 70.2 steps/s
[Step=96700 Epoch=188.6] | Loss=0.01476 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.748 | L2-Norm(final)=16.626 | 4446.6 samples/s | 69.5 steps/s
[Step=96750 Epoch=188.7] | Loss=0.01453 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.751 | L2-Norm(final)=16.629 | 4514.5 samples/s | 70.5 steps/s
[Step=96800 Epoch=188.8] | Loss=0.01460 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.753 | L2-Norm(final)=16.632 | 4435.2 samples/s | 69.3 steps/s
[Step=96850 Epoch=188.9] | Loss=0.01405 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.755 | L2-Norm(final)=16.635 | 4494.5 samples/s | 70.2 steps/s
[Step=96900 Epoch=189.0] | Loss=0.01360 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.757 | L2-Norm(final)=16.638 | 4408.7 samples/s | 68.9 steps/s
[Step=96950 Epoch=189.1] | Loss=0.01345 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.759 | L2-Norm(final)=16.641 | 4468.4 samples/s | 69.8 steps/s
[Step=97000 Epoch=189.2] | Loss=0.01308 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.761 | L2-Norm(final)=16.644 | 5832.8 samples/s | 91.1 steps/s
[Step=97050 Epoch=189.3] | Loss=0.01275 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.763 | L2-Norm(final)=16.647 | 2390.9 samples/s | 37.4 steps/s
[Step=97100 Epoch=189.4] | Loss=0.01237 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.764 | L2-Norm(final)=16.650 | 4489.9 samples/s | 70.2 steps/s
[Step=97150 Epoch=189.5] | Loss=0.01206 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=16.652 | 4491.6 samples/s | 70.2 steps/s
[Step=97200 Epoch=189.6] | Loss=0.01172 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.767 | L2-Norm(final)=16.655 | 4481.1 samples/s | 70.0 steps/s
[Step=97250 Epoch=189.7] | Loss=0.01167 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=16.658 | 4508.8 samples/s | 70.4 steps/s
[Step=97300 Epoch=189.8] | Loss=0.01144 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.770 | L2-Norm(final)=16.661 | 4344.1 samples/s | 67.9 steps/s
[Step=97350 Epoch=189.9] | Loss=0.01127 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.771 | L2-Norm(final)=16.663 | 4487.6 samples/s | 70.1 steps/s
[Step=97400 Epoch=190.0] | Loss=0.01117 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.773 | L2-Norm(final)=16.666 | 4474.7 samples/s | 69.9 steps/s
[Step=97450 Epoch=190.1] | Loss=0.01105 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.774 | L2-Norm(final)=16.668 | 4488.1 samples/s | 70.1 steps/s
[Step=97500 Epoch=190.2] | Loss=0.01090 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=16.671 | 4814.1 samples/s | 75.2 steps/s
[Step=97550 Epoch=190.3] | Loss=0.01073 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.776 | L2-Norm(final)=16.673 | 2632.3 samples/s | 41.1 steps/s
[Step=97600 Epoch=190.4] | Loss=0.01056 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=16.676 | 4438.0 samples/s | 69.3 steps/s
[Step=97650 Epoch=190.5] | Loss=0.01043 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=16.678 | 4526.9 samples/s | 70.7 steps/s
[Step=97700 Epoch=190.6] | Loss=0.01026 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.779 | L2-Norm(final)=16.681 | 4340.3 samples/s | 67.8 steps/s
[Step=97750 Epoch=190.7] | Loss=0.01010 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.780 | L2-Norm(final)=16.683 | 4454.1 samples/s | 69.6 steps/s
[Step=97800 Epoch=190.7] | Loss=0.01004 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=16.686 | 4475.2 samples/s | 69.9 steps/s
[Step=97850 Epoch=190.8] | Loss=0.00999 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=16.688 | 4492.9 samples/s | 70.2 steps/s
[Step=97900 Epoch=190.9] | Loss=0.00984 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=16.690 | 4477.6 samples/s | 70.0 steps/s
[Step=97950 Epoch=191.0] | Loss=0.00974 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.784 | L2-Norm(final)=16.693 | 4521.1 samples/s | 70.6 steps/s
[Step=98000 Epoch=191.1] | Loss=0.00971 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.785 | L2-Norm(final)=16.695 | 4534.0 samples/s | 70.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step98000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=187.7] | Loss=0.01993 | Reg=0.00252 | acc=0.9688 | L2-Norm=15.884 | L2-Norm(final)=16.628 | 5497.0 samples/s | 85.9 steps/s
[Step=96050 Epoch=187.8] | Loss=0.01991 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.888 | L2-Norm(final)=16.629 | 4577.4 samples/s | 71.5 steps/s
[Step=96100 Epoch=187.9] | Loss=0.01937 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.891 | L2-Norm(final)=16.632 | 4957.0 samples/s | 77.5 steps/s
[Step=96150 Epoch=188.0] | Loss=0.01858 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=16.635 | 5021.0 samples/s | 78.5 steps/s
[Step=96200 Epoch=188.1] | Loss=0.01880 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.896 | L2-Norm(final)=16.638 | 5059.5 samples/s | 79.1 steps/s
[Step=96250 Epoch=188.2] | Loss=0.01902 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=16.641 | 5048.2 samples/s | 78.9 steps/s
[Step=96300 Epoch=188.3] | Loss=0.01849 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.900 | L2-Norm(final)=16.644 | 5084.5 samples/s | 79.4 steps/s
[Step=96350 Epoch=188.4] | Loss=0.01834 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=16.647 | 4990.2 samples/s | 78.0 steps/s
[Step=96400 Epoch=188.5] | Loss=0.01856 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.650 | 5118.7 samples/s | 80.0 steps/s
[Step=96450 Epoch=188.6] | Loss=0.01841 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.906 | L2-Norm(final)=16.654 | 4962.2 samples/s | 77.5 steps/s
[Step=96500 Epoch=188.7] | Loss=0.01824 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.908 | L2-Norm(final)=16.657 | 6828.4 samples/s | 106.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=188.7] | Loss=0.03229 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.926 | L2-Norm(final)=16.690 | 5739.6 samples/s | 89.7 steps/s
[Step=96550 Epoch=188.8] | Loss=0.01778 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.929 | L2-Norm(final)=16.692 | 4299.0 samples/s | 67.2 steps/s
[Step=96600 Epoch=188.9] | Loss=0.01545 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.932 | L2-Norm(final)=16.695 | 4456.0 samples/s | 69.6 steps/s
[Step=96650 Epoch=188.9] | Loss=0.01539 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=16.698 | 4472.5 samples/s | 69.9 steps/s
[Step=96700 Epoch=189.0] | Loss=0.01503 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.937 | L2-Norm(final)=16.701 | 4480.4 samples/s | 70.0 steps/s
[Step=96750 Epoch=189.1] | Loss=0.01520 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.940 | L2-Norm(final)=16.704 | 4468.8 samples/s | 69.8 steps/s
[Step=96800 Epoch=189.2] | Loss=0.01451 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.942 | L2-Norm(final)=16.707 | 4481.5 samples/s | 70.0 steps/s
[Step=96850 Epoch=189.3] | Loss=0.01409 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.944 | L2-Norm(final)=16.710 | 4483.1 samples/s | 70.0 steps/s
[Step=96900 Epoch=189.4] | Loss=0.01382 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=16.713 | 4406.1 samples/s | 68.8 steps/s
[Step=96950 Epoch=189.5] | Loss=0.01336 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=16.716 | 4441.5 samples/s | 69.4 steps/s
[Step=97000 Epoch=189.6] | Loss=0.01323 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=16.719 | 5875.2 samples/s | 91.8 steps/s
[Step=97050 Epoch=189.7] | Loss=0.01286 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=16.722 | 2395.4 samples/s | 37.4 steps/s
[Step=97100 Epoch=189.8] | Loss=0.01251 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.953 | L2-Norm(final)=16.725 | 4460.6 samples/s | 69.7 steps/s
[Step=97150 Epoch=189.9] | Loss=0.01221 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=16.727 | 4513.6 samples/s | 70.5 steps/s
[Step=97200 Epoch=190.0] | Loss=0.01204 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=16.730 | 4560.9 samples/s | 71.3 steps/s
[Step=97250 Epoch=190.1] | Loss=0.01181 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=16.733 | 4357.0 samples/s | 68.1 steps/s
[Step=97300 Epoch=190.2] | Loss=0.01161 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=16.735 | 4372.7 samples/s | 68.3 steps/s
[Step=97350 Epoch=190.3] | Loss=0.01144 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.960 | L2-Norm(final)=16.738 | 4472.6 samples/s | 69.9 steps/s
[Step=97400 Epoch=190.4] | Loss=0.01121 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=16.741 | 4610.2 samples/s | 72.0 steps/s
[Step=97450 Epoch=190.5] | Loss=0.01113 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=16.743 | 4383.0 samples/s | 68.5 steps/s
[Step=97500 Epoch=190.6] | Loss=0.01097 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=16.746 | 4997.7 samples/s | 78.1 steps/s
[Step=97550 Epoch=190.7] | Loss=0.01086 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.965 | L2-Norm(final)=16.748 | 2576.3 samples/s | 40.3 steps/s
[Step=97600 Epoch=190.8] | Loss=0.01061 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=16.751 | 4456.7 samples/s | 69.6 steps/s
[Step=97650 Epoch=190.9] | Loss=0.01046 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=16.753 | 4566.9 samples/s | 71.4 steps/s
[Step=97700 Epoch=191.0] | Loss=0.01029 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=16.756 | 4277.5 samples/s | 66.8 steps/s
[Step=97750 Epoch=191.1] | Loss=0.01015 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=16.758 | 4443.0 samples/s | 69.4 steps/s
[Step=97800 Epoch=191.2] | Loss=0.01006 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.970 | L2-Norm(final)=16.761 | 4444.0 samples/s | 69.4 steps/s
[Step=97850 Epoch=191.3] | Loss=0.00998 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=16.763 | 4528.6 samples/s | 70.8 steps/s
[Step=97900 Epoch=191.4] | Loss=0.00984 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.972 | L2-Norm(final)=16.766 | 4432.5 samples/s | 69.3 steps/s
[Step=97950 Epoch=191.5] | Loss=0.00977 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=16.768 | 4518.0 samples/s | 70.6 steps/s
[Step=98000 Epoch=191.6] | Loss=0.00974 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.974 | L2-Norm(final)=16.771 | 4488.9 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step98000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=367.8] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.709 | L2-Norm(final)=10.452 | 6417.7 samples/s | 100.3 steps/s
[Step=96050 Epoch=368.0] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.708 | L2-Norm(final)=10.463 | 4010.6 samples/s | 62.7 steps/s
[Step=96100 Epoch=368.2] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.714 | L2-Norm(final)=10.477 | 4748.8 samples/s | 74.2 steps/s
[Step=96150 Epoch=368.4] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.719 | L2-Norm(final)=10.489 | 4738.2 samples/s | 74.0 steps/s
[Step=96200 Epoch=368.6] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.723 | L2-Norm(final)=10.498 | 4684.8 samples/s | 73.2 steps/s
[Step=96250 Epoch=368.8] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.726 | L2-Norm(final)=10.504 | 6558.3 samples/s | 102.5 steps/s
[Step=96300 Epoch=369.0] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.728 | L2-Norm(final)=10.510 | 2394.6 samples/s | 37.4 steps/s
[Step=96350 Epoch=369.2] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.729 | L2-Norm(final)=10.516 | 4757.4 samples/s | 74.3 steps/s
[Step=96400 Epoch=369.4] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.731 | L2-Norm(final)=10.521 | 4807.9 samples/s | 75.1 steps/s
[Step=96450 Epoch=369.6] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.732 | L2-Norm(final)=10.525 | 4550.4 samples/s | 71.1 steps/s
[Step=96500 Epoch=369.8] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.734 | L2-Norm(final)=10.530 | 5488.2 samples/s | 85.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=369.8] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.747 | L2-Norm(final)=10.576 | 6450.4 samples/s | 100.8 steps/s
[Step=96550 Epoch=369.9] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.740 | L2-Norm(final)=10.579 | 3706.4 samples/s | 57.9 steps/s
[Step=96600 Epoch=370.1] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.730 | L2-Norm(final)=10.582 | 4245.8 samples/s | 66.3 steps/s
[Step=96650 Epoch=370.3] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.719 | L2-Norm(final)=10.585 | 4317.3 samples/s | 67.5 steps/s
[Step=96700 Epoch=370.5] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.710 | L2-Norm(final)=10.588 | 4183.8 samples/s | 65.4 steps/s
[Step=96750 Epoch=370.7] | Loss=0.00028 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.709 | L2-Norm(final)=10.591 | 5737.0 samples/s | 89.6 steps/s
[Step=96800 Epoch=370.9] | Loss=0.00023 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.710 | L2-Norm(final)=10.594 | 2267.2 samples/s | 35.4 steps/s
[Step=96850 Epoch=371.1] | Loss=0.00020 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.711 | L2-Norm(final)=10.597 | 4319.7 samples/s | 67.5 steps/s
[Step=96900 Epoch=371.3] | Loss=0.00018 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=10.598 | 4187.1 samples/s | 65.4 steps/s
[Step=96950 Epoch=371.5] | Loss=0.00016 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.600 | 4259.5 samples/s | 66.6 steps/s
[Step=97000 Epoch=371.7] | Loss=0.00014 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.601 | 4806.2 samples/s | 75.1 steps/s
[Step=97050 Epoch=371.9] | Loss=0.00013 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.602 | 2445.2 samples/s | 38.2 steps/s
[Step=97100 Epoch=372.1] | Loss=0.00012 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.603 | 4286.4 samples/s | 67.0 steps/s
[Step=97150 Epoch=372.2] | Loss=0.00011 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.603 | 4119.8 samples/s | 64.4 steps/s
[Step=97200 Epoch=372.4] | Loss=0.00011 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.714 | L2-Norm(final)=10.604 | 4199.4 samples/s | 65.6 steps/s
[Step=97250 Epoch=372.6] | Loss=0.00010 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.714 | L2-Norm(final)=10.605 | 4241.1 samples/s | 66.3 steps/s
[Step=97300 Epoch=372.8] | Loss=0.00009 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.714 | L2-Norm(final)=10.605 | 2636.2 samples/s | 41.2 steps/s
[Step=97350 Epoch=373.0] | Loss=0.00009 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.714 | L2-Norm(final)=10.606 | 4193.9 samples/s | 65.5 steps/s
[Step=97400 Epoch=373.2] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.606 | 4246.8 samples/s | 66.4 steps/s
[Step=97450 Epoch=373.4] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.607 | 4300.5 samples/s | 67.2 steps/s
[Step=97500 Epoch=373.6] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.607 | 4096.1 samples/s | 64.0 steps/s
[Step=97550 Epoch=373.8] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.607 | 2576.5 samples/s | 40.3 steps/s
[Step=97600 Epoch=374.0] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.608 | 4274.1 samples/s | 66.8 steps/s
[Step=97650 Epoch=374.2] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.608 | 4333.1 samples/s | 67.7 steps/s
[Step=97700 Epoch=374.4] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.608 | 4101.4 samples/s | 64.1 steps/s
[Step=97750 Epoch=374.5] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.713 | L2-Norm(final)=10.609 | 4278.3 samples/s | 66.8 steps/s
[Step=97800 Epoch=374.7] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=10.609 | 6248.7 samples/s | 97.6 steps/s
[Step=97850 Epoch=374.9] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=10.609 | 2180.0 samples/s | 34.1 steps/s
[Step=97900 Epoch=375.1] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=10.610 | 4169.6 samples/s | 65.1 steps/s
[Step=97950 Epoch=375.3] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=10.610 | 4271.9 samples/s | 66.7 steps/s
[Step=98000 Epoch=375.5] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.711 | L2-Norm(final)=10.610 | 4209.5 samples/s | 65.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step98000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=369.5] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.740 | L2-Norm(final)=11.239 | 5768.1 samples/s | 90.1 steps/s
[Step=96050 Epoch=369.7] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.743 | L2-Norm(final)=11.249 | 4462.7 samples/s | 69.7 steps/s
[Step=96100 Epoch=369.9] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.748 | L2-Norm(final)=11.259 | 4703.2 samples/s | 73.5 steps/s
[Step=96150 Epoch=370.1] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.751 | L2-Norm(final)=11.267 | 4681.1 samples/s | 73.1 steps/s
[Step=96200 Epoch=370.3] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.755 | L2-Norm(final)=11.274 | 4723.1 samples/s | 73.8 steps/s
[Step=96250 Epoch=370.5] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.757 | L2-Norm(final)=11.281 | 6694.1 samples/s | 104.6 steps/s
[Step=96300 Epoch=370.7] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.760 | L2-Norm(final)=11.288 | 2405.7 samples/s | 37.6 steps/s
[Step=96350 Epoch=370.9] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.763 | L2-Norm(final)=11.295 | 4731.3 samples/s | 73.9 steps/s
[Step=96400 Epoch=371.1] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.765 | L2-Norm(final)=11.301 | 4753.8 samples/s | 74.3 steps/s
[Step=96450 Epoch=371.3] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.767 | L2-Norm(final)=11.306 | 4747.7 samples/s | 74.2 steps/s
[Step=96500 Epoch=371.5] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.769 | L2-Norm(final)=11.312 | 5602.6 samples/s | 87.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=371.5] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.788 | L2-Norm(final)=11.364 | 5908.8 samples/s | 92.3 steps/s
[Step=96550 Epoch=371.7] | Loss=0.00019 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.792 | L2-Norm(final)=11.370 | 3936.9 samples/s | 61.5 steps/s
[Step=96600 Epoch=371.9] | Loss=0.00012 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.802 | L2-Norm(final)=11.376 | 4169.6 samples/s | 65.1 steps/s
[Step=96650 Epoch=372.0] | Loss=0.00009 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.806 | L2-Norm(final)=11.379 | 4251.1 samples/s | 66.4 steps/s
[Step=96700 Epoch=372.2] | Loss=0.00007 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.807 | L2-Norm(final)=11.381 | 4220.9 samples/s | 66.0 steps/s
[Step=96750 Epoch=372.4] | Loss=0.00006 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.383 | 5848.6 samples/s | 91.4 steps/s
[Step=96800 Epoch=372.6] | Loss=0.00005 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.384 | 2296.7 samples/s | 35.9 steps/s
[Step=96850 Epoch=372.8] | Loss=0.00004 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.385 | 4167.7 samples/s | 65.1 steps/s
[Step=96900 Epoch=373.0] | Loss=0.00004 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.386 | 4265.2 samples/s | 66.6 steps/s
[Step=96950 Epoch=373.2] | Loss=0.00004 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.387 | 4131.0 samples/s | 64.5 steps/s
[Step=97000 Epoch=373.4] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.807 | L2-Norm(final)=11.388 | 4903.6 samples/s | 76.6 steps/s
[Step=97050 Epoch=373.6] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.806 | L2-Norm(final)=11.389 | 2429.3 samples/s | 38.0 steps/s
[Step=97100 Epoch=373.8] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.806 | L2-Norm(final)=11.390 | 4213.4 samples/s | 65.8 steps/s
[Step=97150 Epoch=374.0] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.805 | L2-Norm(final)=11.390 | 4278.4 samples/s | 66.9 steps/s
[Step=97200 Epoch=374.2] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.804 | L2-Norm(final)=11.391 | 4178.4 samples/s | 65.3 steps/s
[Step=97250 Epoch=374.4] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.803 | L2-Norm(final)=11.392 | 4350.5 samples/s | 68.0 steps/s
[Step=97300 Epoch=374.5] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.802 | L2-Norm(final)=11.392 | 2576.0 samples/s | 40.3 steps/s
[Step=97350 Epoch=374.7] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.801 | L2-Norm(final)=11.393 | 4232.3 samples/s | 66.1 steps/s
[Step=97400 Epoch=374.9] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.799 | L2-Norm(final)=11.393 | 4271.6 samples/s | 66.7 steps/s
[Step=97450 Epoch=375.1] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.798 | L2-Norm(final)=11.394 | 4159.4 samples/s | 65.0 steps/s
[Step=97500 Epoch=375.3] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.797 | L2-Norm(final)=11.395 | 4277.7 samples/s | 66.8 steps/s
[Step=97550 Epoch=375.5] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.796 | L2-Norm(final)=11.395 | 2634.1 samples/s | 41.2 steps/s
[Step=97600 Epoch=375.7] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.795 | L2-Norm(final)=11.396 | 4283.1 samples/s | 66.9 steps/s
[Step=97650 Epoch=375.9] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.793 | L2-Norm(final)=11.396 | 4165.3 samples/s | 65.1 steps/s
[Step=97700 Epoch=376.1] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.792 | L2-Norm(final)=11.397 | 4183.6 samples/s | 65.4 steps/s
[Step=97750 Epoch=376.3] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.790 | L2-Norm(final)=11.397 | 4239.1 samples/s | 66.2 steps/s
[Step=97800 Epoch=376.5] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.789 | L2-Norm(final)=11.398 | 6995.8 samples/s | 109.3 steps/s
[Step=97850 Epoch=376.7] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.787 | L2-Norm(final)=11.398 | 2110.9 samples/s | 33.0 steps/s
[Step=97900 Epoch=376.9] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.786 | L2-Norm(final)=11.399 | 4251.1 samples/s | 66.4 steps/s
[Step=97950 Epoch=377.0] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=11.400 | 4233.9 samples/s | 66.2 steps/s
[Step=98000 Epoch=377.2] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.783 | L2-Norm(final)=11.400 | 4215.2 samples/s | 65.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06175 | acc=0.9655 | tpr=0.9723 | fpr=0.0491 | 4678.4 samples/s | 18.3 steps/s
Avg test loss: 0.06334, Avg test acc: 0.96458, Avg tpr: 0.97132, Avg fpr: 0.05025, total FA: 392

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.05859 | acc=0.9657 | tpr=0.9702 | fpr=0.0441 | 4717.2 samples/s | 18.4 steps/s
Avg test loss: 0.06175, Avg test acc: 0.96426, Avg tpr: 0.96911, Avg fpr: 0.04640, total FA: 362

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.99015 | acc=0.3105 | tpr=0.0051 | fpr=0.0265 | 5025.0 samples/s | 19.6 steps/s
Avg test loss: 4.99462, Avg test acc: 0.30732, Avg tpr: 0.00542, Avg fpr: 0.02871, total FA: 224

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.87555 | acc=0.3090 | tpr=0.0140 | fpr=0.0505 | 5050.7 samples/s | 19.7 steps/s
Avg test loss: 5.86851, Avg test acc: 0.30668, Avg tpr: 0.01615, Avg fpr: 0.05435, total FA: 424

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.59430 | acc=0.1523 | tpr=0.4690 | fpr=0.8534 | 4820.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=4.57591 | acc=0.1534 | tpr=0.4371 | fpr=0.8519 | 7390.1 samples/s | 28.9 steps/s
[Step= 150] | Loss=4.57529 | acc=0.1535 | tpr=0.4308 | fpr=0.8516 | 7900.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=4.57742 | acc=0.1533 | tpr=0.4251 | fpr=0.8517 | 7589.2 samples/s | 29.6 steps/s
[Step= 250] | Loss=4.56878 | acc=0.1538 | tpr=0.4314 | fpr=0.8512 | 7967.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=4.56414 | acc=0.1538 | tpr=0.4313 | fpr=0.8513 | 7620.2 samples/s | 29.8 steps/s
[Step= 350] | Loss=4.56799 | acc=0.1530 | tpr=0.4239 | fpr=0.8519 | 7986.9 samples/s | 31.2 steps/s
[Step= 400] | Loss=4.56634 | acc=0.1536 | tpr=0.4218 | fpr=0.8513 | 7704.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=4.56803 | acc=0.1531 | tpr=0.4182 | fpr=0.8517 | 7742.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=4.57004 | acc=0.1536 | tpr=0.4211 | fpr=0.8513 | 8018.2 samples/s | 31.3 steps/s
[Step= 550] | Loss=4.57041 | acc=0.1537 | tpr=0.4198 | fpr=0.8511 | 14207.2 samples/s | 55.5 steps/s
Avg test loss: 4.57167, Avg test acc: 0.15357, Avg tpr: 0.42116, Avg fpr: 0.85130, total FA: 118201

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.78133 | acc=0.1424 | tpr=0.5398 | fpr=0.8647 | 4907.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=4.77844 | acc=0.1436 | tpr=0.5181 | fpr=0.8634 | 7153.0 samples/s | 27.9 steps/s
[Step= 150] | Loss=4.77890 | acc=0.1432 | tpr=0.5014 | fpr=0.8634 | 7816.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=4.77926 | acc=0.1426 | tpr=0.4962 | fpr=0.8638 | 7902.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=4.77209 | acc=0.1438 | tpr=0.4969 | fpr=0.8627 | 7600.8 samples/s | 29.7 steps/s
[Step= 300] | Loss=4.76885 | acc=0.1442 | tpr=0.4996 | fpr=0.8623 | 7913.4 samples/s | 30.9 steps/s
[Step= 350] | Loss=4.77362 | acc=0.1437 | tpr=0.4941 | fpr=0.8626 | 8116.2 samples/s | 31.7 steps/s
[Step= 400] | Loss=4.77149 | acc=0.1437 | tpr=0.4934 | fpr=0.8626 | 7622.0 samples/s | 29.8 steps/s
[Step= 450] | Loss=4.77401 | acc=0.1435 | tpr=0.4893 | fpr=0.8628 | 8077.4 samples/s | 31.6 steps/s
[Step= 500] | Loss=4.77534 | acc=0.1439 | tpr=0.4934 | fpr=0.8624 | 7626.2 samples/s | 29.8 steps/s
[Step= 550] | Loss=4.77628 | acc=0.1438 | tpr=0.4887 | fpr=0.8624 | 14086.8 samples/s | 55.0 steps/s
Avg test loss: 4.77782, Avg test acc: 0.14371, Avg tpr: 0.48930, Avg fpr: 0.86257, total FA: 119766

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11040 | acc=0.9762 | tpr=0.9558 | fpr=0.0235 | 4753.0 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.11164 | acc=0.9768 | tpr=0.9680 | fpr=0.0231 | 7333.1 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.11694 | acc=0.9758 | tpr=0.9669 | fpr=0.0240 | 8389.8 samples/s | 32.8 steps/s
[Step= 200] | Loss=0.11999 | acc=0.9758 | tpr=0.9672 | fpr=0.0240 | 7683.6 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.11794 | acc=0.9761 | tpr=0.9659 | fpr=0.0237 | 7785.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11991 | acc=0.9757 | tpr=0.9644 | fpr=0.0241 | 7805.5 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.12031 | acc=0.9757 | tpr=0.9649 | fpr=0.0241 | 8067.9 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.12153 | acc=0.9757 | tpr=0.9644 | fpr=0.0241 | 7562.7 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.12360 | acc=0.9754 | tpr=0.9635 | fpr=0.0244 | 7885.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.12299 | acc=0.9755 | tpr=0.9643 | fpr=0.0243 | 7733.5 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.12197 | acc=0.9758 | tpr=0.9646 | fpr=0.0240 | 14251.4 samples/s | 55.7 steps/s
Avg test loss: 0.12177, Avg test acc: 0.97577, Avg tpr: 0.96434, Avg fpr: 0.02402, total FA: 3335

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11239 | acc=0.9784 | tpr=0.9602 | fpr=0.0212 | 4870.1 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.11568 | acc=0.9784 | tpr=0.9638 | fpr=0.0214 | 7316.3 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.12155 | acc=0.9778 | tpr=0.9654 | fpr=0.0220 | 7485.2 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.12437 | acc=0.9774 | tpr=0.9639 | fpr=0.0223 | 8038.5 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.12222 | acc=0.9778 | tpr=0.9633 | fpr=0.0219 | 7702.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.12426 | acc=0.9775 | tpr=0.9607 | fpr=0.0222 | 8003.8 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.12478 | acc=0.9773 | tpr=0.9624 | fpr=0.0224 | 7986.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.12598 | acc=0.9773 | tpr=0.9612 | fpr=0.0224 | 7827.8 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.12850 | acc=0.9768 | tpr=0.9591 | fpr=0.0228 | 7768.1 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12787 | acc=0.9771 | tpr=0.9595 | fpr=0.0226 | 7836.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12660 | acc=0.9773 | tpr=0.9602 | fpr=0.0224 | 13504.4 samples/s | 52.8 steps/s
Avg test loss: 0.12647, Avg test acc: 0.97729, Avg tpr: 0.95998, Avg fpr: 0.02240, total FA: 3110

server round 49/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=191.1] | Loss=0.00365 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=16.765 | 6873.7 samples/s | 107.4 steps/s
[Step=98050 Epoch=191.2] | Loss=0.01251 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.780 | L2-Norm(final)=16.767 | 4297.7 samples/s | 67.2 steps/s
[Step=98100 Epoch=191.3] | Loss=0.01318 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=16.771 | 4960.1 samples/s | 77.5 steps/s
[Step=98150 Epoch=191.4] | Loss=0.01281 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=16.775 | 4989.7 samples/s | 78.0 steps/s
[Step=98200 Epoch=191.5] | Loss=0.01232 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.787 | L2-Norm(final)=16.778 | 5142.8 samples/s | 80.4 steps/s
[Step=98250 Epoch=191.6] | Loss=0.01229 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.789 | L2-Norm(final)=16.782 | 4922.4 samples/s | 76.9 steps/s
[Step=98300 Epoch=191.7] | Loss=0.01227 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=16.786 | 5090.3 samples/s | 79.5 steps/s
[Step=98350 Epoch=191.8] | Loss=0.01221 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.794 | L2-Norm(final)=16.790 | 5101.7 samples/s | 79.7 steps/s
[Step=98400 Epoch=191.9] | Loss=0.01215 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.796 | L2-Norm(final)=16.794 | 5020.2 samples/s | 78.4 steps/s
[Step=98450 Epoch=192.0] | Loss=0.01218 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.798 | L2-Norm(final)=16.798 | 5148.6 samples/s | 80.4 steps/s
[Step=98500 Epoch=192.1] | Loss=0.01212 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.800 | L2-Norm(final)=16.802 | 6627.3 samples/s | 103.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_0/client_state-step98500.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=191.6] | Loss=0.00588 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=16.843 | 6086.8 samples/s | 95.1 steps/s
[Step=98050 Epoch=191.7] | Loss=0.01408 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.970 | L2-Norm(final)=16.845 | 4615.5 samples/s | 72.1 steps/s
[Step=98100 Epoch=191.8] | Loss=0.01396 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.973 | L2-Norm(final)=16.848 | 4959.4 samples/s | 77.5 steps/s
[Step=98150 Epoch=191.9] | Loss=0.01377 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=16.852 | 5206.4 samples/s | 81.4 steps/s
[Step=98200 Epoch=192.0] | Loss=0.01388 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=16.855 | 4923.5 samples/s | 76.9 steps/s
[Step=98250 Epoch=192.1] | Loss=0.01370 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.980 | L2-Norm(final)=16.859 | 5021.9 samples/s | 78.5 steps/s
[Step=98300 Epoch=192.2] | Loss=0.01313 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=16.862 | 5005.5 samples/s | 78.2 steps/s
[Step=98350 Epoch=192.3] | Loss=0.01291 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=16.866 | 5064.1 samples/s | 79.1 steps/s
[Step=98400 Epoch=192.4] | Loss=0.01270 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.986 | L2-Norm(final)=16.870 | 5036.8 samples/s | 78.7 steps/s
[Step=98450 Epoch=192.5] | Loss=0.01271 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.987 | L2-Norm(final)=16.873 | 5068.7 samples/s | 79.2 steps/s
[Step=98500 Epoch=192.6] | Loss=0.01267 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=16.877 | 6678.6 samples/s | 104.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_asml1_1/client_state-step98500.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=375.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=10.618 | 5885.7 samples/s | 92.0 steps/s
[Step=98050 Epoch=375.7] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=10.619 | 4403.6 samples/s | 68.8 steps/s
[Step=98100 Epoch=375.9] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=10.619 | 4651.9 samples/s | 72.7 steps/s
[Step=98150 Epoch=376.1] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.620 | 4816.2 samples/s | 75.3 steps/s
[Step=98200 Epoch=376.3] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.620 | 4661.6 samples/s | 72.8 steps/s
[Step=98250 Epoch=376.5] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.621 | 6662.0 samples/s | 104.1 steps/s
[Step=98300 Epoch=376.7] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.621 | 2421.2 samples/s | 37.8 steps/s
[Step=98350 Epoch=376.8] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.622 | 4672.0 samples/s | 73.0 steps/s
[Step=98400 Epoch=377.0] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.622 | 4745.9 samples/s | 74.2 steps/s
[Step=98450 Epoch=377.2] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.623 | 4692.8 samples/s | 73.3 steps/s
[Step=98500 Epoch=377.4] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.623 | 5456.3 samples/s | 85.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_0/client_state-step98500.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=377.2] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.806 | L2-Norm(final)=11.417 | 5584.4 samples/s | 87.3 steps/s
[Step=98050 Epoch=377.4] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.419 | 4192.2 samples/s | 65.5 steps/s
[Step=98100 Epoch=377.6] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.809 | L2-Norm(final)=11.421 | 4834.7 samples/s | 75.5 steps/s
[Step=98150 Epoch=377.8] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.810 | L2-Norm(final)=11.424 | 4740.3 samples/s | 74.1 steps/s
[Step=98200 Epoch=378.0] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.811 | L2-Norm(final)=11.427 | 4727.7 samples/s | 73.9 steps/s
[Step=98250 Epoch=378.2] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.812 | L2-Norm(final)=11.430 | 6580.1 samples/s | 102.8 steps/s
[Step=98300 Epoch=378.4] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.813 | L2-Norm(final)=11.433 | 2417.9 samples/s | 37.8 steps/s
[Step=98350 Epoch=378.6] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.814 | L2-Norm(final)=11.436 | 4663.2 samples/s | 72.9 steps/s
[Step=98400 Epoch=378.8] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.815 | L2-Norm(final)=11.438 | 4815.2 samples/s | 75.2 steps/s
[Step=98450 Epoch=379.0] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.816 | L2-Norm(final)=11.441 | 4686.4 samples/s | 73.2 steps/s
[Step=98500 Epoch=379.2] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.817 | L2-Norm(final)=11.444 | 5721.2 samples/s | 89.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a2i2-sel1.0-ch32/client_iccad2012_1/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06408 | acc=0.9611 | tpr=0.9650 | fpr=0.0473 | 4919.0 samples/s | 19.2 steps/s
Avg test loss: 0.06587, Avg test acc: 0.95945, Avg tpr: 0.96322, Avg fpr: 0.04884, total FA: 381

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.05959 | acc=0.9644 | tpr=0.9700 | fpr=0.0478 | 4861.3 samples/s | 19.0 steps/s
Avg test loss: 0.06172, Avg test acc: 0.96158, Avg tpr: 0.96742, Avg fpr: 0.05128, total FA: 400

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.62002 | acc=0.3081 | tpr=0.0089 | fpr=0.0421 | 5147.3 samples/s | 20.1 steps/s
Avg test loss: 4.61856, Avg test acc: 0.30511, Avg tpr: 0.00991, Avg fpr: 0.04564, total FA: 356

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.14019 | acc=0.3080 | tpr=0.0148 | fpr=0.0555 | 4943.5 samples/s | 19.3 steps/s
Avg test loss: 5.13406, Avg test acc: 0.30627, Avg tpr: 0.01784, Avg fpr: 0.05935, total FA: 463

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.88282 | acc=0.1638 | tpr=0.3850 | fpr=0.8402 | 4871.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=3.87365 | acc=0.1658 | tpr=0.3710 | fpr=0.8380 | 7207.9 samples/s | 28.2 steps/s
[Step= 150] | Loss=3.87185 | acc=0.1668 | tpr=0.3689 | fpr=0.8369 | 7899.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=3.87255 | acc=0.1680 | tpr=0.3683 | fpr=0.8357 | 7801.4 samples/s | 30.5 steps/s
[Step= 250] | Loss=3.86619 | acc=0.1684 | tpr=0.3712 | fpr=0.8353 | 7996.7 samples/s | 31.2 steps/s
[Step= 300] | Loss=3.86293 | acc=0.1680 | tpr=0.3724 | fpr=0.8357 | 7385.7 samples/s | 28.9 steps/s
[Step= 350] | Loss=3.86626 | acc=0.1673 | tpr=0.3663 | fpr=0.8363 | 7819.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=3.86510 | acc=0.1675 | tpr=0.3605 | fpr=0.8360 | 8002.4 samples/s | 31.3 steps/s
[Step= 450] | Loss=3.86571 | acc=0.1671 | tpr=0.3588 | fpr=0.8364 | 8227.4 samples/s | 32.1 steps/s
[Step= 500] | Loss=3.86748 | acc=0.1674 | tpr=0.3604 | fpr=0.8361 | 7627.0 samples/s | 29.8 steps/s
[Step= 550] | Loss=3.86835 | acc=0.1675 | tpr=0.3589 | fpr=0.8359 | 13841.0 samples/s | 54.1 steps/s
Avg test loss: 3.86936, Avg test acc: 0.16737, Avg tpr: 0.36014, Avg fpr: 0.83614, total FA: 116096

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.23873 | acc=0.1477 | tpr=0.5133 | fpr=0.8589 | 4971.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=4.23852 | acc=0.1496 | tpr=0.4797 | fpr=0.8566 | 7222.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=4.23762 | acc=0.1501 | tpr=0.4697 | fpr=0.8558 | 7647.3 samples/s | 29.9 steps/s
[Step= 200] | Loss=4.23753 | acc=0.1501 | tpr=0.4689 | fpr=0.8557 | 7955.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=4.23097 | acc=0.1510 | tpr=0.4681 | fpr=0.8548 | 7443.7 samples/s | 29.1 steps/s
[Step= 300] | Loss=4.22911 | acc=0.1511 | tpr=0.4691 | fpr=0.8547 | 8042.9 samples/s | 31.4 steps/s
[Step= 350] | Loss=4.23280 | acc=0.1505 | tpr=0.4652 | fpr=0.8552 | 7943.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=4.23177 | acc=0.1506 | tpr=0.4639 | fpr=0.8551 | 7791.7 samples/s | 30.4 steps/s
[Step= 450] | Loss=4.23322 | acc=0.1501 | tpr=0.4625 | fpr=0.8555 | 8009.2 samples/s | 31.3 steps/s
[Step= 500] | Loss=4.23424 | acc=0.1505 | tpr=0.4661 | fpr=0.8552 | 7668.3 samples/s | 30.0 steps/s
[Step= 550] | Loss=4.23507 | acc=0.1506 | tpr=0.4608 | fpr=0.8550 | 13815.6 samples/s | 54.0 steps/s
Avg test loss: 4.23627, Avg test acc: 0.15048, Avg tpr: 0.46197, Avg fpr: 0.85519, total FA: 118741

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10461 | acc=0.9762 | tpr=0.9513 | fpr=0.0233 | 4871.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10539 | acc=0.9770 | tpr=0.9638 | fpr=0.0227 | 7174.5 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.11019 | acc=0.9761 | tpr=0.9640 | fpr=0.0237 | 7937.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.11273 | acc=0.9760 | tpr=0.9661 | fpr=0.0238 | 8172.5 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.11081 | acc=0.9762 | tpr=0.9659 | fpr=0.0236 | 7357.8 samples/s | 28.7 steps/s
[Step= 300] | Loss=0.11249 | acc=0.9758 | tpr=0.9658 | fpr=0.0240 | 8218.2 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.11280 | acc=0.9758 | tpr=0.9668 | fpr=0.0240 | 7675.2 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.11400 | acc=0.9758 | tpr=0.9655 | fpr=0.0240 | 8222.2 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.11601 | acc=0.9755 | tpr=0.9640 | fpr=0.0242 | 7614.5 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.11537 | acc=0.9756 | tpr=0.9643 | fpr=0.0241 | 7950.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.11432 | acc=0.9758 | tpr=0.9646 | fpr=0.0240 | 13238.8 samples/s | 51.7 steps/s
Avg test loss: 0.11417, Avg test acc: 0.97586, Avg tpr: 0.96434, Avg fpr: 0.02393, total FA: 3323

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10630 | acc=0.9759 | tpr=0.9558 | fpr=0.0238 | 4894.1 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.10844 | acc=0.9757 | tpr=0.9680 | fpr=0.0241 | 7187.7 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.11356 | acc=0.9753 | tpr=0.9683 | fpr=0.0246 | 7836.0 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.11605 | acc=0.9749 | tpr=0.9661 | fpr=0.0249 | 7994.7 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.11402 | acc=0.9754 | tpr=0.9659 | fpr=0.0244 | 7835.9 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.11582 | acc=0.9752 | tpr=0.9651 | fpr=0.0246 | 7741.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.11624 | acc=0.9751 | tpr=0.9662 | fpr=0.0248 | 7681.4 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.11730 | acc=0.9751 | tpr=0.9650 | fpr=0.0247 | 7973.2 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.11944 | acc=0.9748 | tpr=0.9635 | fpr=0.0250 | 7740.2 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.11885 | acc=0.9750 | tpr=0.9634 | fpr=0.0248 | 7719.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.11764 | acc=0.9753 | tpr=0.9630 | fpr=0.0245 | 14555.4 samples/s | 56.9 steps/s
Avg test loss: 0.11750, Avg test acc: 0.97527, Avg tpr: 0.96276, Avg fpr: 0.02450, total FA: 3402
