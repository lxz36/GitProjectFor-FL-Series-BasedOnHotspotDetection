#clients of iccad2012: 5
#clients of asml1: 5
select ratio: 1.0
Total num clients: 10
client model path: ['models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3', 'models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (9983, 144, 32)
Resampled dataset to size (13125, 144, 32)
Using transform option: train
#pos = 6841, #neg = 6284
Allocated dataset with size (9983, 144, 32)
Resampled dataset to size (13116, 144, 32)
Using transform option: train
#pos = 6850, #neg = 6266
Allocated dataset with size (9983, 144, 32)
Resampled dataset to size (13135, 144, 32)
Using transform option: train
#pos = 6831, #neg = 6304
Allocated dataset with size (9983, 144, 32)
Resampled dataset to size (13124, 144, 32)
Using transform option: train
#pos = 6842, #neg = 6282
Allocated dataset with size (9984, 144, 32)
Resampled dataset to size (13051, 144, 32)
Using transform option: train
#pos = 6917, #neg = 6134
loading data into the main memory...
Allocated dataset with size (3660, 144, 32)
Resampled dataset to size (6754, 144, 32)
Using transform option: train
#pos = 3332, #neg = 3422
Allocated dataset with size (3660, 144, 32)
Resampled dataset to size (6728, 144, 32)
Using transform option: train
#pos = 3304, #neg = 3424
Allocated dataset with size (3660, 144, 32)
Resampled dataset to size (6702, 144, 32)
Using transform option: train
#pos = 3276, #neg = 3426
Allocated dataset with size (3660, 144, 32)
Resampled dataset to size (6792, 144, 32)
Using transform option: train
#pos = 3393, #neg = 3399
Allocated dataset with size (3660, 144, 32)
Resampled dataset to size (6715, 144, 32)
Using transform option: train
#pos = 3290, #neg = 3425
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 32)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.35001 | Reg=0.00356 | acc=0.4375 | L2-Norm=18.862 | L2-Norm(final)=1.947 | 3712.7 samples/s | 58.0 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.32216 | Reg=0.00341 | acc=0.6250 | L2-Norm=18.469 | L2-Norm(final)=1.945 | 5794.9 samples/s | 90.5 steps/s
[Step= 100 Epoch= 0.5] | Loss=0.31039 | Reg=0.00334 | acc=0.6719 | L2-Norm=18.273 | L2-Norm(final)=1.950 | 5834.1 samples/s | 91.2 steps/s
[Step= 150 Epoch= 0.7] | Loss=0.30085 | Reg=0.00330 | acc=0.6719 | L2-Norm=18.160 | L2-Norm(final)=1.961 | 5262.2 samples/s | 82.2 steps/s
[Step= 200 Epoch= 1.0] | Loss=0.29494 | Reg=0.00327 | acc=0.7500 | L2-Norm=18.092 | L2-Norm(final)=1.971 | 8976.8 samples/s | 140.3 steps/s
[Step= 250 Epoch= 1.2] | Loss=0.28955 | Reg=0.00326 | acc=0.7344 | L2-Norm=18.053 | L2-Norm(final)=1.984 | 2387.0 samples/s | 37.3 steps/s
[Step= 300 Epoch= 1.5] | Loss=0.28629 | Reg=0.00325 | acc=0.7188 | L2-Norm=18.031 | L2-Norm(final)=1.996 | 5615.3 samples/s | 87.7 steps/s
[Step= 350 Epoch= 1.7] | Loss=0.28280 | Reg=0.00325 | acc=0.7188 | L2-Norm=18.022 | L2-Norm(final)=2.010 | 5230.9 samples/s | 81.7 steps/s
[Step= 400 Epoch= 2.0] | Loss=0.28038 | Reg=0.00325 | acc=0.6094 | L2-Norm=18.022 | L2-Norm(final)=2.024 | 7844.5 samples/s | 122.6 steps/s
[Step= 450 Epoch= 2.2] | Loss=0.27693 | Reg=0.00325 | acc=0.6719 | L2-Norm=18.029 | L2-Norm(final)=2.039 | 2466.6 samples/s | 38.5 steps/s
[Step= 500 Epoch= 2.4] | Loss=0.27432 | Reg=0.00326 | acc=0.7812 | L2-Norm=18.044 | L2-Norm(final)=2.057 | 5433.4 samples/s | 84.9 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 2.4] | Loss=0.24460 | Reg=0.00332 | acc=0.7656 | L2-Norm=18.228 | L2-Norm(final)=2.235 | 5221.9 samples/s | 81.6 steps/s
[Step= 550 Epoch= 2.7] | Loss=0.24112 | Reg=0.00333 | acc=0.8594 | L2-Norm=18.236 | L2-Norm(final)=2.236 | 4160.0 samples/s | 65.0 steps/s
[Step= 600 Epoch= 2.9] | Loss=0.21100 | Reg=0.00333 | acc=0.8750 | L2-Norm=18.256 | L2-Norm(final)=2.248 | 4548.8 samples/s | 71.1 steps/s
[Step= 650 Epoch= 3.2] | Loss=0.19375 | Reg=0.00334 | acc=0.7969 | L2-Norm=18.269 | L2-Norm(final)=2.258 | 4456.4 samples/s | 69.6 steps/s
[Step= 700 Epoch= 3.4] | Loss=0.18012 | Reg=0.00334 | acc=0.9219 | L2-Norm=18.286 | L2-Norm(final)=2.268 | 6515.2 samples/s | 101.8 steps/s
[Step= 750 Epoch= 3.7] | Loss=0.16488 | Reg=0.00335 | acc=0.9062 | L2-Norm=18.310 | L2-Norm(final)=2.278 | 2093.0 samples/s | 32.7 steps/s
[Step= 800 Epoch= 3.9] | Loss=0.15270 | Reg=0.00336 | acc=0.8906 | L2-Norm=18.335 | L2-Norm(final)=2.289 | 4581.8 samples/s | 71.6 steps/s
[Step= 850 Epoch= 4.1] | Loss=0.14524 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.361 | L2-Norm(final)=2.299 | 4462.4 samples/s | 69.7 steps/s
[Step= 900 Epoch= 4.4] | Loss=0.13744 | Reg=0.00338 | acc=0.9375 | L2-Norm=18.388 | L2-Norm(final)=2.309 | 6006.9 samples/s | 93.9 steps/s
[Step= 950 Epoch= 4.6] | Loss=0.12879 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.411 | L2-Norm(final)=2.320 | 2204.4 samples/s | 34.4 steps/s
[Step=1000 Epoch= 4.9] | Loss=0.12142 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.436 | L2-Norm(final)=2.331 | 4521.2 samples/s | 70.6 steps/s
[Step=1050 Epoch= 5.1] | Loss=0.11535 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.459 | L2-Norm(final)=2.341 | 4396.5 samples/s | 68.7 steps/s
[Step=1100 Epoch= 5.4] | Loss=0.11113 | Reg=0.00342 | acc=0.9219 | L2-Norm=18.481 | L2-Norm(final)=2.351 | 5444.0 samples/s | 85.1 steps/s
[Step=1150 Epoch= 5.6] | Loss=0.10624 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.499 | L2-Norm(final)=2.360 | 2272.9 samples/s | 35.5 steps/s
[Step=1200 Epoch= 5.9] | Loss=0.10130 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.517 | L2-Norm(final)=2.369 | 4448.1 samples/s | 69.5 steps/s
[Step=1250 Epoch= 6.1] | Loss=0.09741 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.534 | L2-Norm(final)=2.378 | 4518.0 samples/s | 70.6 steps/s
[Step=1300 Epoch= 6.3] | Loss=0.09486 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.551 | L2-Norm(final)=2.386 | 5005.8 samples/s | 78.2 steps/s
[Step=1350 Epoch= 6.6] | Loss=0.09288 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.567 | L2-Norm(final)=2.392 | 2352.6 samples/s | 36.8 steps/s
[Step=1400 Epoch= 6.8] | Loss=0.08985 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.584 | L2-Norm(final)=2.398 | 4442.0 samples/s | 69.4 steps/s
[Step=1450 Epoch= 7.1] | Loss=0.08739 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.599 | L2-Norm(final)=2.404 | 4499.6 samples/s | 70.3 steps/s
[Step=1500 Epoch= 7.3] | Loss=0.08485 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.614 | L2-Norm(final)=2.410 | 4658.9 samples/s | 72.8 steps/s
[Step=1550 Epoch= 7.6] | Loss=0.08246 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.627 | L2-Norm(final)=2.416 | 2468.8 samples/s | 38.6 steps/s
[Step=1600 Epoch= 7.8] | Loss=0.07972 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.640 | L2-Norm(final)=2.422 | 4627.0 samples/s | 72.3 steps/s
[Step=1650 Epoch= 8.0] | Loss=0.07750 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.651 | L2-Norm(final)=2.427 | 4389.0 samples/s | 68.6 steps/s
[Step=1700 Epoch= 8.3] | Loss=0.07519 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.662 | L2-Norm(final)=2.433 | 4635.5 samples/s | 72.4 steps/s
[Step=1750 Epoch= 8.5] | Loss=0.07354 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.673 | L2-Norm(final)=2.439 | 2430.4 samples/s | 38.0 steps/s
[Step=1800 Epoch= 8.8] | Loss=0.07171 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.684 | L2-Norm(final)=2.444 | 4548.9 samples/s | 71.1 steps/s
[Step=1850 Epoch= 9.0] | Loss=0.07008 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.694 | L2-Norm(final)=2.449 | 4471.0 samples/s | 69.9 steps/s
[Step=1900 Epoch= 9.3] | Loss=0.06845 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.704 | L2-Norm(final)=2.454 | 4449.3 samples/s | 69.5 steps/s
[Step=1950 Epoch= 9.5] | Loss=0.06724 | Reg=0.00350 | acc=0.8594 | L2-Norm=18.714 | L2-Norm(final)=2.459 | 2513.1 samples/s | 39.3 steps/s
[Step=2000 Epoch= 9.8] | Loss=0.06668 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.727 | L2-Norm(final)=2.463 | 4577.4 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step2000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.35309 | Reg=0.00360 | acc=0.6250 | L2-Norm=18.969 | L2-Norm(final)=2.043 | 5635.6 samples/s | 88.1 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.33205 | Reg=0.00341 | acc=0.6875 | L2-Norm=18.478 | L2-Norm(final)=2.027 | 4513.1 samples/s | 70.5 steps/s
[Step= 100 Epoch= 0.5] | Loss=0.31292 | Reg=0.00333 | acc=0.6562 | L2-Norm=18.260 | L2-Norm(final)=2.031 | 5537.4 samples/s | 86.5 steps/s
[Step= 150 Epoch= 0.7] | Loss=0.30415 | Reg=0.00329 | acc=0.6250 | L2-Norm=18.131 | L2-Norm(final)=2.045 | 5496.1 samples/s | 85.9 steps/s
[Step= 200 Epoch= 1.0] | Loss=0.29879 | Reg=0.00326 | acc=0.7656 | L2-Norm=18.046 | L2-Norm(final)=2.059 | 9189.6 samples/s | 143.6 steps/s
[Step= 250 Epoch= 1.2] | Loss=0.29245 | Reg=0.00324 | acc=0.7188 | L2-Norm=17.989 | L2-Norm(final)=2.073 | 2332.0 samples/s | 36.4 steps/s
[Step= 300 Epoch= 1.5] | Loss=0.28885 | Reg=0.00322 | acc=0.7344 | L2-Norm=17.951 | L2-Norm(final)=2.090 | 5589.9 samples/s | 87.3 steps/s
[Step= 350 Epoch= 1.7] | Loss=0.28360 | Reg=0.00321 | acc=0.7812 | L2-Norm=17.926 | L2-Norm(final)=2.109 | 5408.2 samples/s | 84.5 steps/s
[Step= 400 Epoch= 2.0] | Loss=0.28040 | Reg=0.00321 | acc=0.7500 | L2-Norm=17.912 | L2-Norm(final)=2.131 | 8125.6 samples/s | 127.0 steps/s
[Step= 450 Epoch= 2.2] | Loss=0.27629 | Reg=0.00321 | acc=0.8125 | L2-Norm=17.907 | L2-Norm(final)=2.154 | 2410.9 samples/s | 37.7 steps/s
[Step= 500 Epoch= 2.4] | Loss=0.27368 | Reg=0.00321 | acc=0.7188 | L2-Norm=17.910 | L2-Norm(final)=2.178 | 5263.7 samples/s | 82.2 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 2.4] | Loss=0.22804 | Reg=0.00323 | acc=0.8594 | L2-Norm=17.963 | L2-Norm(final)=2.419 | 5806.9 samples/s | 90.7 steps/s
[Step= 550 Epoch= 2.7] | Loss=0.22149 | Reg=0.00323 | acc=0.8281 | L2-Norm=17.979 | L2-Norm(final)=2.429 | 4090.9 samples/s | 63.9 steps/s
[Step= 600 Epoch= 2.9] | Loss=0.19680 | Reg=0.00324 | acc=0.7969 | L2-Norm=18.000 | L2-Norm(final)=2.447 | 4466.0 samples/s | 69.8 steps/s
[Step= 650 Epoch= 3.2] | Loss=0.18060 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.012 | L2-Norm(final)=2.460 | 4518.6 samples/s | 70.6 steps/s
[Step= 700 Epoch= 3.4] | Loss=0.17213 | Reg=0.00325 | acc=0.8750 | L2-Norm=18.024 | L2-Norm(final)=2.469 | 6641.7 samples/s | 103.8 steps/s
[Step= 750 Epoch= 3.7] | Loss=0.15688 | Reg=0.00326 | acc=0.9375 | L2-Norm=18.046 | L2-Norm(final)=2.479 | 2091.5 samples/s | 32.7 steps/s
[Step= 800 Epoch= 3.9] | Loss=0.14657 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.075 | L2-Norm(final)=2.491 | 4458.4 samples/s | 69.7 steps/s
[Step= 850 Epoch= 4.1] | Loss=0.13979 | Reg=0.00328 | acc=0.9062 | L2-Norm=18.103 | L2-Norm(final)=2.501 | 4434.0 samples/s | 69.3 steps/s
[Step= 900 Epoch= 4.4] | Loss=0.13333 | Reg=0.00329 | acc=0.9375 | L2-Norm=18.128 | L2-Norm(final)=2.509 | 6120.3 samples/s | 95.6 steps/s
[Step= 950 Epoch= 4.6] | Loss=0.12485 | Reg=0.00330 | acc=0.9375 | L2-Norm=18.152 | L2-Norm(final)=2.517 | 2165.1 samples/s | 33.8 steps/s
[Step=1000 Epoch= 4.9] | Loss=0.11775 | Reg=0.00330 | acc=0.9062 | L2-Norm=18.177 | L2-Norm(final)=2.527 | 4549.4 samples/s | 71.1 steps/s
[Step=1050 Epoch= 5.1] | Loss=0.11258 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.199 | L2-Norm(final)=2.536 | 4466.1 samples/s | 69.8 steps/s
[Step=1100 Epoch= 5.4] | Loss=0.10883 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.221 | L2-Norm(final)=2.545 | 5660.9 samples/s | 88.5 steps/s
[Step=1150 Epoch= 5.6] | Loss=0.10335 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.244 | L2-Norm(final)=2.555 | 2241.1 samples/s | 35.0 steps/s
[Step=1200 Epoch= 5.9] | Loss=0.09844 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.267 | L2-Norm(final)=2.565 | 4515.0 samples/s | 70.5 steps/s
[Step=1250 Epoch= 6.1] | Loss=0.09464 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.289 | L2-Norm(final)=2.575 | 4479.3 samples/s | 70.0 steps/s
[Step=1300 Epoch= 6.3] | Loss=0.09197 | Reg=0.00335 | acc=0.9531 | L2-Norm=18.311 | L2-Norm(final)=2.584 | 5236.9 samples/s | 81.8 steps/s
[Step=1350 Epoch= 6.6] | Loss=0.08857 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.330 | L2-Norm(final)=2.592 | 2276.6 samples/s | 35.6 steps/s
[Step=1400 Epoch= 6.8] | Loss=0.08494 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.349 | L2-Norm(final)=2.600 | 4529.5 samples/s | 70.8 steps/s
[Step=1450 Epoch= 7.1] | Loss=0.08227 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.367 | L2-Norm(final)=2.608 | 4492.6 samples/s | 70.2 steps/s
[Step=1500 Epoch= 7.3] | Loss=0.07959 | Reg=0.00338 | acc=1.0000 | L2-Norm=18.382 | L2-Norm(final)=2.615 | 4867.0 samples/s | 76.0 steps/s
[Step=1550 Epoch= 7.6] | Loss=0.07737 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.396 | L2-Norm(final)=2.622 | 2369.2 samples/s | 37.0 steps/s
[Step=1600 Epoch= 7.8] | Loss=0.07491 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.410 | L2-Norm(final)=2.629 | 4505.5 samples/s | 70.4 steps/s
[Step=1650 Epoch= 8.1] | Loss=0.07287 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.424 | L2-Norm(final)=2.636 | 4497.3 samples/s | 70.3 steps/s
[Step=1700 Epoch= 8.3] | Loss=0.07112 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.437 | L2-Norm(final)=2.642 | 4624.1 samples/s | 72.3 steps/s
[Step=1750 Epoch= 8.5] | Loss=0.06936 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.450 | L2-Norm(final)=2.648 | 2509.0 samples/s | 39.2 steps/s
[Step=1800 Epoch= 8.8] | Loss=0.06746 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.462 | L2-Norm(final)=2.653 | 4433.5 samples/s | 69.3 steps/s
[Step=1850 Epoch= 9.0] | Loss=0.06587 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.475 | L2-Norm(final)=2.659 | 4497.7 samples/s | 70.3 steps/s
[Step=1900 Epoch= 9.3] | Loss=0.06479 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.486 | L2-Norm(final)=2.664 | 4498.1 samples/s | 70.3 steps/s
[Step=1950 Epoch= 9.5] | Loss=0.06347 | Reg=0.00342 | acc=0.9531 | L2-Norm=18.498 | L2-Norm(final)=2.669 | 2495.1 samples/s | 39.0 steps/s
[Step=2000 Epoch= 9.8] | Loss=0.06211 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.509 | L2-Norm(final)=2.673 | 4671.3 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step2000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.42081 | Reg=0.00357 | acc=0.4844 | L2-Norm=18.900 | L2-Norm(final)=1.871 | 5278.2 samples/s | 82.5 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.33367 | Reg=0.00341 | acc=0.7656 | L2-Norm=18.468 | L2-Norm(final)=1.851 | 4678.6 samples/s | 73.1 steps/s
[Step= 100 Epoch= 0.5] | Loss=0.32078 | Reg=0.00333 | acc=0.6250 | L2-Norm=18.251 | L2-Norm(final)=1.855 | 5552.4 samples/s | 86.8 steps/s
[Step= 150 Epoch= 0.7] | Loss=0.31362 | Reg=0.00328 | acc=0.7031 | L2-Norm=18.119 | L2-Norm(final)=1.860 | 5528.4 samples/s | 86.4 steps/s
[Step= 200 Epoch= 1.0] | Loss=0.30509 | Reg=0.00325 | acc=0.8281 | L2-Norm=18.032 | L2-Norm(final)=1.871 | 8897.1 samples/s | 139.0 steps/s
[Step= 250 Epoch= 1.2] | Loss=0.29789 | Reg=0.00323 | acc=0.8125 | L2-Norm=17.975 | L2-Norm(final)=1.887 | 2329.2 samples/s | 36.4 steps/s
[Step= 300 Epoch= 1.5] | Loss=0.29506 | Reg=0.00322 | acc=0.7188 | L2-Norm=17.941 | L2-Norm(final)=1.904 | 5397.1 samples/s | 84.3 steps/s
[Step= 350 Epoch= 1.7] | Loss=0.29024 | Reg=0.00321 | acc=0.7812 | L2-Norm=17.922 | L2-Norm(final)=1.921 | 5633.3 samples/s | 88.0 steps/s
[Step= 400 Epoch= 1.9] | Loss=0.28639 | Reg=0.00321 | acc=0.7656 | L2-Norm=17.918 | L2-Norm(final)=1.940 | 7794.6 samples/s | 121.8 steps/s
[Step= 450 Epoch= 2.2] | Loss=0.28395 | Reg=0.00321 | acc=0.7969 | L2-Norm=17.925 | L2-Norm(final)=1.961 | 2433.3 samples/s | 38.0 steps/s
[Step= 500 Epoch= 2.4] | Loss=0.28189 | Reg=0.00322 | acc=0.6875 | L2-Norm=17.941 | L2-Norm(final)=1.980 | 5375.8 samples/s | 84.0 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 2.4] | Loss=0.22271 | Reg=0.00328 | acc=0.7969 | L2-Norm=18.124 | L2-Norm(final)=2.176 | 5178.9 samples/s | 80.9 steps/s
[Step= 550 Epoch= 2.7] | Loss=0.26797 | Reg=0.00330 | acc=0.7031 | L2-Norm=18.159 | L2-Norm(final)=2.168 | 4187.4 samples/s | 65.4 steps/s
[Step= 600 Epoch= 2.9] | Loss=0.23131 | Reg=0.00331 | acc=0.8906 | L2-Norm=18.198 | L2-Norm(final)=2.180 | 4546.4 samples/s | 71.0 steps/s
[Step= 650 Epoch= 3.2] | Loss=0.20984 | Reg=0.00332 | acc=0.8281 | L2-Norm=18.231 | L2-Norm(final)=2.193 | 4485.4 samples/s | 70.1 steps/s
[Step= 700 Epoch= 3.4] | Loss=0.19466 | Reg=0.00334 | acc=0.8906 | L2-Norm=18.263 | L2-Norm(final)=2.204 | 6572.9 samples/s | 102.7 steps/s
[Step= 750 Epoch= 3.7] | Loss=0.17897 | Reg=0.00335 | acc=0.8438 | L2-Norm=18.293 | L2-Norm(final)=2.214 | 2130.8 samples/s | 33.3 steps/s
[Step= 800 Epoch= 3.9] | Loss=0.16707 | Reg=0.00336 | acc=0.9062 | L2-Norm=18.324 | L2-Norm(final)=2.225 | 4580.8 samples/s | 71.6 steps/s
[Step= 850 Epoch= 4.1] | Loss=0.15582 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.352 | L2-Norm(final)=2.236 | 4435.0 samples/s | 69.3 steps/s
[Step= 900 Epoch= 4.4] | Loss=0.14840 | Reg=0.00338 | acc=0.9375 | L2-Norm=18.377 | L2-Norm(final)=2.246 | 5978.9 samples/s | 93.4 steps/s
[Step= 950 Epoch= 4.6] | Loss=0.13897 | Reg=0.00339 | acc=0.9688 | L2-Norm=18.402 | L2-Norm(final)=2.257 | 2224.1 samples/s | 34.8 steps/s
[Step=1000 Epoch= 4.9] | Loss=0.13092 | Reg=0.00339 | acc=0.8594 | L2-Norm=18.425 | L2-Norm(final)=2.268 | 4465.6 samples/s | 69.8 steps/s
[Step=1050 Epoch= 5.1] | Loss=0.12499 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.445 | L2-Norm(final)=2.279 | 4494.6 samples/s | 70.2 steps/s
[Step=1100 Epoch= 5.4] | Loss=0.11899 | Reg=0.00341 | acc=0.9531 | L2-Norm=18.464 | L2-Norm(final)=2.289 | 5431.4 samples/s | 84.9 steps/s
[Step=1150 Epoch= 5.6] | Loss=0.11352 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.483 | L2-Norm(final)=2.300 | 2284.8 samples/s | 35.7 steps/s
[Step=1200 Epoch= 5.8] | Loss=0.10812 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.502 | L2-Norm(final)=2.310 | 4513.6 samples/s | 70.5 steps/s
[Step=1250 Epoch= 6.1] | Loss=0.10382 | Reg=0.00343 | acc=0.9531 | L2-Norm=18.520 | L2-Norm(final)=2.320 | 4483.7 samples/s | 70.1 steps/s
[Step=1300 Epoch= 6.3] | Loss=0.10058 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.536 | L2-Norm(final)=2.329 | 5040.0 samples/s | 78.8 steps/s
[Step=1350 Epoch= 6.6] | Loss=0.09709 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.551 | L2-Norm(final)=2.337 | 2359.4 samples/s | 36.9 steps/s
[Step=1400 Epoch= 6.8] | Loss=0.09334 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.566 | L2-Norm(final)=2.345 | 4493.6 samples/s | 70.2 steps/s
[Step=1450 Epoch= 7.1] | Loss=0.09043 | Reg=0.00345 | acc=0.9531 | L2-Norm=18.580 | L2-Norm(final)=2.352 | 4537.0 samples/s | 70.9 steps/s
[Step=1500 Epoch= 7.3] | Loss=0.08750 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.594 | L2-Norm(final)=2.359 | 4628.9 samples/s | 72.3 steps/s
[Step=1550 Epoch= 7.6] | Loss=0.08477 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.607 | L2-Norm(final)=2.366 | 2467.4 samples/s | 38.6 steps/s
[Step=1600 Epoch= 7.8] | Loss=0.08222 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.618 | L2-Norm(final)=2.373 | 4470.0 samples/s | 69.8 steps/s
[Step=1650 Epoch= 8.0] | Loss=0.07989 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.629 | L2-Norm(final)=2.379 | 4507.2 samples/s | 70.4 steps/s
[Step=1700 Epoch= 8.3] | Loss=0.07769 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.640 | L2-Norm(final)=2.385 | 4538.5 samples/s | 70.9 steps/s
[Step=1750 Epoch= 8.5] | Loss=0.07605 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.651 | L2-Norm(final)=2.391 | 2521.6 samples/s | 39.4 steps/s
[Step=1800 Epoch= 8.8] | Loss=0.07399 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.662 | L2-Norm(final)=2.396 | 4395.6 samples/s | 68.7 steps/s
[Step=1850 Epoch= 9.0] | Loss=0.07220 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.671 | L2-Norm(final)=2.402 | 4518.2 samples/s | 70.6 steps/s
[Step=1900 Epoch= 9.3] | Loss=0.07054 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.679 | L2-Norm(final)=2.407 | 4545.2 samples/s | 71.0 steps/s
[Step=1950 Epoch= 9.5] | Loss=0.06902 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.687 | L2-Norm(final)=2.412 | 2513.8 samples/s | 39.3 steps/s
[Step=2000 Epoch= 9.7] | Loss=0.06740 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.694 | L2-Norm(final)=2.416 | 4482.1 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step2000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.36030 | Reg=0.00359 | acc=0.4688 | L2-Norm=18.948 | L2-Norm(final)=2.108 | 5436.4 samples/s | 84.9 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.31834 | Reg=0.00341 | acc=0.7500 | L2-Norm=18.466 | L2-Norm(final)=2.100 | 4811.7 samples/s | 75.2 steps/s
[Step= 100 Epoch= 0.5] | Loss=0.30949 | Reg=0.00333 | acc=0.5156 | L2-Norm=18.249 | L2-Norm(final)=2.112 | 5388.4 samples/s | 84.2 steps/s
[Step= 150 Epoch= 0.7] | Loss=0.30651 | Reg=0.00329 | acc=0.7188 | L2-Norm=18.128 | L2-Norm(final)=2.119 | 5498.8 samples/s | 85.9 steps/s
[Step= 200 Epoch= 1.0] | Loss=0.29778 | Reg=0.00326 | acc=0.8125 | L2-Norm=18.044 | L2-Norm(final)=2.128 | 9092.3 samples/s | 142.1 steps/s
[Step= 250 Epoch= 1.2] | Loss=0.29176 | Reg=0.00324 | acc=0.7500 | L2-Norm=17.986 | L2-Norm(final)=2.143 | 2332.5 samples/s | 36.4 steps/s
[Step= 300 Epoch= 1.5] | Loss=0.28857 | Reg=0.00322 | acc=0.7656 | L2-Norm=17.951 | L2-Norm(final)=2.158 | 5547.3 samples/s | 86.7 steps/s
[Step= 350 Epoch= 1.7] | Loss=0.28518 | Reg=0.00322 | acc=0.6875 | L2-Norm=17.929 | L2-Norm(final)=2.174 | 5623.5 samples/s | 87.9 steps/s
[Step= 400 Epoch= 2.0] | Loss=0.28172 | Reg=0.00321 | acc=0.6719 | L2-Norm=17.915 | L2-Norm(final)=2.191 | 7565.8 samples/s | 118.2 steps/s
[Step= 450 Epoch= 2.2] | Loss=0.27865 | Reg=0.00321 | acc=0.7031 | L2-Norm=17.911 | L2-Norm(final)=2.209 | 2437.7 samples/s | 38.1 steps/s
[Step= 500 Epoch= 2.4] | Loss=0.27516 | Reg=0.00321 | acc=0.6719 | L2-Norm=17.915 | L2-Norm(final)=2.229 | 5401.7 samples/s | 84.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 2.4] | Loss=0.21684 | Reg=0.00324 | acc=0.8750 | L2-Norm=17.995 | L2-Norm(final)=2.442 | 5455.3 samples/s | 85.2 steps/s
[Step= 550 Epoch= 2.7] | Loss=0.23190 | Reg=0.00325 | acc=0.8750 | L2-Norm=18.032 | L2-Norm(final)=2.448 | 4009.9 samples/s | 62.7 steps/s
[Step= 600 Epoch= 2.9] | Loss=0.20852 | Reg=0.00326 | acc=0.8594 | L2-Norm=18.060 | L2-Norm(final)=2.460 | 4582.8 samples/s | 71.6 steps/s
[Step= 650 Epoch= 3.2] | Loss=0.19215 | Reg=0.00327 | acc=0.9062 | L2-Norm=18.089 | L2-Norm(final)=2.472 | 4476.1 samples/s | 69.9 steps/s
[Step= 700 Epoch= 3.4] | Loss=0.17791 | Reg=0.00328 | acc=0.8906 | L2-Norm=18.119 | L2-Norm(final)=2.483 | 6497.8 samples/s | 101.5 steps/s
[Step= 750 Epoch= 3.7] | Loss=0.16252 | Reg=0.00329 | acc=0.8906 | L2-Norm=18.148 | L2-Norm(final)=2.492 | 2089.4 samples/s | 32.6 steps/s
[Step= 800 Epoch= 3.9] | Loss=0.15194 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.174 | L2-Norm(final)=2.502 | 4545.1 samples/s | 71.0 steps/s
[Step= 850 Epoch= 4.1] | Loss=0.14266 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.198 | L2-Norm(final)=2.511 | 4467.7 samples/s | 69.8 steps/s
[Step= 900 Epoch= 4.4] | Loss=0.13568 | Reg=0.00332 | acc=0.9062 | L2-Norm=18.220 | L2-Norm(final)=2.520 | 5943.9 samples/s | 92.9 steps/s
[Step= 950 Epoch= 4.6] | Loss=0.12738 | Reg=0.00333 | acc=0.9219 | L2-Norm=18.239 | L2-Norm(final)=2.528 | 2218.4 samples/s | 34.7 steps/s
[Step=1000 Epoch= 4.9] | Loss=0.12052 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.259 | L2-Norm(final)=2.537 | 4531.6 samples/s | 70.8 steps/s
[Step=1050 Epoch= 5.1] | Loss=0.11473 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.278 | L2-Norm(final)=2.545 | 4454.2 samples/s | 69.6 steps/s
[Step=1100 Epoch= 5.4] | Loss=0.10992 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.297 | L2-Norm(final)=2.553 | 5433.5 samples/s | 84.9 steps/s
[Step=1150 Epoch= 5.6] | Loss=0.10736 | Reg=0.00335 | acc=0.9375 | L2-Norm=18.314 | L2-Norm(final)=2.561 | 2287.9 samples/s | 35.7 steps/s
[Step=1200 Epoch= 5.9] | Loss=0.10344 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.331 | L2-Norm(final)=2.567 | 4539.0 samples/s | 70.9 steps/s
[Step=1250 Epoch= 6.1] | Loss=0.10114 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.349 | L2-Norm(final)=2.572 | 4520.7 samples/s | 70.6 steps/s
[Step=1300 Epoch= 6.3] | Loss=0.09803 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.365 | L2-Norm(final)=2.578 | 4887.7 samples/s | 76.4 steps/s
[Step=1350 Epoch= 6.6] | Loss=0.09532 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.382 | L2-Norm(final)=2.583 | 2347.0 samples/s | 36.7 steps/s
[Step=1400 Epoch= 6.8] | Loss=0.09172 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.399 | L2-Norm(final)=2.588 | 4509.8 samples/s | 70.5 steps/s
[Step=1450 Epoch= 7.1] | Loss=0.08829 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.415 | L2-Norm(final)=2.594 | 4605.6 samples/s | 72.0 steps/s
[Step=1500 Epoch= 7.3] | Loss=0.08559 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.430 | L2-Norm(final)=2.599 | 4541.6 samples/s | 71.0 steps/s
[Step=1550 Epoch= 7.6] | Loss=0.08543 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.444 | L2-Norm(final)=2.604 | 2477.3 samples/s | 38.7 steps/s
[Step=1600 Epoch= 7.8] | Loss=0.08399 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.460 | L2-Norm(final)=2.606 | 4463.9 samples/s | 69.7 steps/s
[Step=1650 Epoch= 8.0] | Loss=0.08226 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.476 | L2-Norm(final)=2.609 | 4452.5 samples/s | 69.6 steps/s
[Step=1700 Epoch= 8.3] | Loss=0.08040 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.490 | L2-Norm(final)=2.611 | 4495.8 samples/s | 70.2 steps/s
[Step=1750 Epoch= 8.5] | Loss=0.07841 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.504 | L2-Norm(final)=2.614 | 2477.4 samples/s | 38.7 steps/s
[Step=1800 Epoch= 8.8] | Loss=0.07609 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.516 | L2-Norm(final)=2.617 | 4625.9 samples/s | 72.3 steps/s
[Step=1850 Epoch= 9.0] | Loss=0.07419 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.527 | L2-Norm(final)=2.620 | 4396.3 samples/s | 68.7 steps/s
[Step=1900 Epoch= 9.3] | Loss=0.07235 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.537 | L2-Norm(final)=2.622 | 4523.6 samples/s | 70.7 steps/s
[Step=1950 Epoch= 9.5] | Loss=0.07061 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.546 | L2-Norm(final)=2.625 | 2488.6 samples/s | 38.9 steps/s
[Step=2000 Epoch= 9.8] | Loss=0.06881 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.555 | L2-Norm(final)=2.628 | 4495.1 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step2000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.38656 | Reg=0.00357 | acc=0.4531 | L2-Norm=18.905 | L2-Norm(final)=1.935 | 5576.0 samples/s | 87.1 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.32978 | Reg=0.00336 | acc=0.6094 | L2-Norm=18.337 | L2-Norm(final)=1.919 | 4679.2 samples/s | 73.1 steps/s
[Step= 100 Epoch= 0.5] | Loss=0.32026 | Reg=0.00326 | acc=0.6406 | L2-Norm=18.052 | L2-Norm(final)=1.920 | 5622.7 samples/s | 87.9 steps/s
[Step= 150 Epoch= 0.7] | Loss=0.30961 | Reg=0.00320 | acc=0.7344 | L2-Norm=17.885 | L2-Norm(final)=1.927 | 5420.1 samples/s | 84.7 steps/s
[Step= 200 Epoch= 1.0] | Loss=0.30048 | Reg=0.00316 | acc=0.7031 | L2-Norm=17.780 | L2-Norm(final)=1.943 | 9326.1 samples/s | 145.7 steps/s
[Step= 250 Epoch= 1.2] | Loss=0.29459 | Reg=0.00314 | acc=0.8750 | L2-Norm=17.712 | L2-Norm(final)=1.961 | 2289.4 samples/s | 35.8 steps/s
[Step= 300 Epoch= 1.5] | Loss=0.29052 | Reg=0.00312 | acc=0.6562 | L2-Norm=17.667 | L2-Norm(final)=1.980 | 5479.3 samples/s | 85.6 steps/s
[Step= 350 Epoch= 1.7] | Loss=0.28510 | Reg=0.00311 | acc=0.7188 | L2-Norm=17.643 | L2-Norm(final)=2.001 | 5707.7 samples/s | 89.2 steps/s
[Step= 400 Epoch= 2.0] | Loss=0.28198 | Reg=0.00311 | acc=0.7812 | L2-Norm=17.632 | L2-Norm(final)=2.023 | 8191.8 samples/s | 128.0 steps/s
[Step= 450 Epoch= 2.2] | Loss=0.27782 | Reg=0.00311 | acc=0.8438 | L2-Norm=17.630 | L2-Norm(final)=2.046 | 2395.4 samples/s | 37.4 steps/s
[Step= 500 Epoch= 2.5] | Loss=0.27488 | Reg=0.00311 | acc=0.8125 | L2-Norm=17.638 | L2-Norm(final)=2.070 | 5390.6 samples/s | 84.2 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 2.5] | Loss=0.27379 | Reg=0.00315 | acc=0.7812 | L2-Norm=17.751 | L2-Norm(final)=2.323 | 5668.0 samples/s | 88.6 steps/s
[Step= 550 Epoch= 2.7] | Loss=0.24385 | Reg=0.00316 | acc=0.8750 | L2-Norm=17.782 | L2-Norm(final)=2.320 | 3929.0 samples/s | 61.4 steps/s
[Step= 600 Epoch= 2.9] | Loss=0.20928 | Reg=0.00318 | acc=0.8906 | L2-Norm=17.832 | L2-Norm(final)=2.336 | 4518.3 samples/s | 70.6 steps/s
[Step= 650 Epoch= 3.2] | Loss=0.19335 | Reg=0.00319 | acc=0.9062 | L2-Norm=17.869 | L2-Norm(final)=2.347 | 4514.4 samples/s | 70.5 steps/s
[Step= 700 Epoch= 3.4] | Loss=0.18145 | Reg=0.00320 | acc=0.8281 | L2-Norm=17.902 | L2-Norm(final)=2.358 | 6778.5 samples/s | 105.9 steps/s
[Step= 750 Epoch= 3.7] | Loss=0.16537 | Reg=0.00322 | acc=0.9531 | L2-Norm=17.933 | L2-Norm(final)=2.369 | 2095.6 samples/s | 32.7 steps/s
[Step= 800 Epoch= 3.9] | Loss=0.15158 | Reg=0.00323 | acc=0.9375 | L2-Norm=17.967 | L2-Norm(final)=2.382 | 4463.5 samples/s | 69.7 steps/s
[Step= 850 Epoch= 4.2] | Loss=0.14284 | Reg=0.00324 | acc=0.9531 | L2-Norm=17.998 | L2-Norm(final)=2.394 | 4550.4 samples/s | 71.1 steps/s
[Step= 900 Epoch= 4.4] | Loss=0.13501 | Reg=0.00325 | acc=0.9375 | L2-Norm=18.026 | L2-Norm(final)=2.406 | 6219.4 samples/s | 97.2 steps/s
[Step= 950 Epoch= 4.7] | Loss=0.12692 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.053 | L2-Norm(final)=2.418 | 2135.2 samples/s | 33.4 steps/s
[Step=1000 Epoch= 4.9] | Loss=0.11874 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.081 | L2-Norm(final)=2.431 | 4499.0 samples/s | 70.3 steps/s
[Step=1050 Epoch= 5.1] | Loss=0.11352 | Reg=0.00328 | acc=0.9375 | L2-Norm=18.106 | L2-Norm(final)=2.443 | 4529.9 samples/s | 70.8 steps/s
[Step=1100 Epoch= 5.4] | Loss=0.10890 | Reg=0.00329 | acc=0.9531 | L2-Norm=18.130 | L2-Norm(final)=2.454 | 5899.7 samples/s | 92.2 steps/s
[Step=1150 Epoch= 5.6] | Loss=0.10421 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.153 | L2-Norm(final)=2.464 | 2178.7 samples/s | 34.0 steps/s
[Step=1200 Epoch= 5.9] | Loss=0.09974 | Reg=0.00330 | acc=0.9062 | L2-Norm=18.176 | L2-Norm(final)=2.474 | 4542.8 samples/s | 71.0 steps/s
[Step=1250 Epoch= 6.1] | Loss=0.09564 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.198 | L2-Norm(final)=2.484 | 4446.7 samples/s | 69.5 steps/s
[Step=1300 Epoch= 6.4] | Loss=0.09233 | Reg=0.00332 | acc=0.9219 | L2-Norm=18.220 | L2-Norm(final)=2.494 | 5564.4 samples/s | 86.9 steps/s
[Step=1350 Epoch= 6.6] | Loss=0.08928 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.241 | L2-Norm(final)=2.503 | 2258.5 samples/s | 35.3 steps/s
[Step=1400 Epoch= 6.9] | Loss=0.08597 | Reg=0.00334 | acc=0.9531 | L2-Norm=18.262 | L2-Norm(final)=2.512 | 4553.6 samples/s | 71.2 steps/s
[Step=1450 Epoch= 7.1] | Loss=0.08285 | Reg=0.00334 | acc=0.9844 | L2-Norm=18.281 | L2-Norm(final)=2.521 | 4597.6 samples/s | 71.8 steps/s
[Step=1500 Epoch= 7.4] | Loss=0.08070 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.299 | L2-Norm(final)=2.529 | 5060.9 samples/s | 79.1 steps/s
[Step=1550 Epoch= 7.6] | Loss=0.07814 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.316 | L2-Norm(final)=2.537 | 2299.4 samples/s | 35.9 steps/s
[Step=1600 Epoch= 7.8] | Loss=0.07572 | Reg=0.00336 | acc=0.9375 | L2-Norm=18.332 | L2-Norm(final)=2.544 | 4475.9 samples/s | 69.9 steps/s
[Step=1650 Epoch= 8.1] | Loss=0.07357 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.347 | L2-Norm(final)=2.552 | 4452.4 samples/s | 69.6 steps/s
[Step=1700 Epoch= 8.3] | Loss=0.07138 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.362 | L2-Norm(final)=2.559 | 4939.9 samples/s | 77.2 steps/s
[Step=1750 Epoch= 8.6] | Loss=0.06952 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.376 | L2-Norm(final)=2.566 | 2360.9 samples/s | 36.9 steps/s
[Step=1800 Epoch= 8.8] | Loss=0.06790 | Reg=0.00338 | acc=1.0000 | L2-Norm=18.390 | L2-Norm(final)=2.573 | 4513.2 samples/s | 70.5 steps/s
[Step=1850 Epoch= 9.1] | Loss=0.06663 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.404 | L2-Norm(final)=2.579 | 4541.6 samples/s | 71.0 steps/s
[Step=1900 Epoch= 9.3] | Loss=0.06536 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.417 | L2-Norm(final)=2.584 | 4660.2 samples/s | 72.8 steps/s
[Step=1950 Epoch= 9.6] | Loss=0.06407 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.431 | L2-Norm(final)=2.590 | 2398.9 samples/s | 37.5 steps/s
[Step=2000 Epoch= 9.8] | Loss=0.06243 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.444 | L2-Norm(final)=2.596 | 4468.2 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step2000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.41375 | Reg=0.00175 | acc=0.4844 | L2-Norm=13.215 | L2-Norm(final)=1.856 | 5763.8 samples/s | 90.1 steps/s
[Step=  50 Epoch= 0.5] | Loss=0.28307 | Reg=0.00170 | acc=0.7969 | L2-Norm=13.055 | L2-Norm(final)=1.855 | 4219.4 samples/s | 65.9 steps/s
[Step= 100 Epoch= 0.9] | Loss=0.23809 | Reg=0.00169 | acc=0.8906 | L2-Norm=13.019 | L2-Norm(final)=1.888 | 8482.5 samples/s | 132.5 steps/s
[Step= 150 Epoch= 1.4] | Loss=0.20575 | Reg=0.00170 | acc=0.8906 | L2-Norm=13.040 | L2-Norm(final)=1.928 | 2245.2 samples/s | 35.1 steps/s
[Step= 200 Epoch= 1.9] | Loss=0.18449 | Reg=0.00171 | acc=0.9531 | L2-Norm=13.079 | L2-Norm(final)=1.964 | 7233.1 samples/s | 113.0 steps/s
[Step= 250 Epoch= 2.4] | Loss=0.16889 | Reg=0.00172 | acc=0.9531 | L2-Norm=13.122 | L2-Norm(final)=1.996 | 2306.1 samples/s | 36.0 steps/s
[Step= 300 Epoch= 2.8] | Loss=0.15735 | Reg=0.00173 | acc=0.9375 | L2-Norm=13.166 | L2-Norm(final)=2.026 | 6589.9 samples/s | 103.0 steps/s
[Step= 350 Epoch= 3.3] | Loss=0.14738 | Reg=0.00174 | acc=0.9531 | L2-Norm=13.209 | L2-Norm(final)=2.052 | 2406.8 samples/s | 37.6 steps/s
[Step= 400 Epoch= 3.8] | Loss=0.13852 | Reg=0.00176 | acc=0.9531 | L2-Norm=13.251 | L2-Norm(final)=2.077 | 5923.7 samples/s | 92.6 steps/s
[Step= 450 Epoch= 4.3] | Loss=0.13210 | Reg=0.00177 | acc=0.9531 | L2-Norm=13.291 | L2-Norm(final)=2.100 | 2511.6 samples/s | 39.2 steps/s
[Step= 500 Epoch= 4.7] | Loss=0.12636 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.331 | L2-Norm(final)=2.122 | 5337.7 samples/s | 83.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 4.7] | Loss=0.07613 | Reg=0.00188 | acc=0.9531 | L2-Norm=13.713 | L2-Norm(final)=2.333 | 5678.9 samples/s | 88.7 steps/s
[Step= 550 Epoch= 5.2] | Loss=0.10878 | Reg=0.00187 | acc=0.9688 | L2-Norm=13.670 | L2-Norm(final)=2.318 | 3653.7 samples/s | 57.1 steps/s
[Step= 600 Epoch= 5.7] | Loss=0.07084 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.682 | L2-Norm(final)=2.330 | 6224.0 samples/s | 97.2 steps/s
[Step= 650 Epoch= 6.2] | Loss=0.05014 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.699 | L2-Norm(final)=2.342 | 2037.6 samples/s | 31.8 steps/s
[Step= 700 Epoch= 6.6] | Loss=0.03878 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.714 | L2-Norm(final)=2.351 | 5665.3 samples/s | 88.5 steps/s
[Step= 750 Epoch= 7.1] | Loss=0.03169 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=2.359 | 2100.8 samples/s | 32.8 steps/s
[Step= 800 Epoch= 7.6] | Loss=0.02658 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.737 | L2-Norm(final)=2.365 | 5183.4 samples/s | 81.0 steps/s
[Step= 850 Epoch= 8.1] | Loss=0.02286 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.743 | L2-Norm(final)=2.370 | 2180.2 samples/s | 34.1 steps/s
[Step= 900 Epoch= 8.5] | Loss=0.02004 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.745 | L2-Norm(final)=2.375 | 4767.6 samples/s | 74.5 steps/s
[Step= 950 Epoch= 9.0] | Loss=0.01784 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.744 | L2-Norm(final)=2.378 | 2296.2 samples/s | 35.9 steps/s
[Step=1000 Epoch= 9.5] | Loss=0.01608 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.742 | L2-Norm(final)=2.382 | 4387.7 samples/s | 68.6 steps/s
[Step=1050 Epoch= 9.9] | Loss=0.01463 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.738 | L2-Norm(final)=2.385 | 2394.0 samples/s | 37.4 steps/s
[Step=1100 Epoch=10.4] | Loss=0.01342 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.733 | L2-Norm(final)=2.387 | 4207.5 samples/s | 65.7 steps/s
[Step=1150 Epoch=10.9] | Loss=0.01240 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=2.390 | 2475.7 samples/s | 38.7 steps/s
[Step=1200 Epoch=11.4] | Loss=0.01152 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.719 | L2-Norm(final)=2.392 | 4062.9 samples/s | 63.5 steps/s
[Step=1250 Epoch=11.8] | Loss=0.01076 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.710 | L2-Norm(final)=2.394 | 2444.1 samples/s | 38.2 steps/s
[Step=1300 Epoch=12.3] | Loss=0.01009 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.701 | L2-Norm(final)=2.396 | 4227.7 samples/s | 66.1 steps/s
[Step=1350 Epoch=12.8] | Loss=0.00950 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.691 | L2-Norm(final)=2.398 | 2561.0 samples/s | 40.0 steps/s
[Step=1400 Epoch=13.3] | Loss=0.00897 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=2.399 | 3971.9 samples/s | 62.1 steps/s
[Step=1450 Epoch=13.7] | Loss=0.00850 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.670 | L2-Norm(final)=2.401 | 6509.6 samples/s | 101.7 steps/s
[Step=1500 Epoch=14.2] | Loss=0.00808 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.659 | L2-Norm(final)=2.402 | 2011.0 samples/s | 31.4 steps/s
[Step=1550 Epoch=14.7] | Loss=0.00770 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.648 | L2-Norm(final)=2.403 | 5867.2 samples/s | 91.7 steps/s
[Step=1600 Epoch=15.2] | Loss=0.00735 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.636 | L2-Norm(final)=2.405 | 2073.6 samples/s | 32.4 steps/s
[Step=1650 Epoch=15.6] | Loss=0.00703 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.624 | L2-Norm(final)=2.406 | 5333.2 samples/s | 83.3 steps/s
[Step=1700 Epoch=16.1] | Loss=0.00674 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.612 | L2-Norm(final)=2.407 | 2152.3 samples/s | 33.6 steps/s
[Step=1750 Epoch=16.6] | Loss=0.00647 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.599 | L2-Norm(final)=2.408 | 4885.9 samples/s | 76.3 steps/s
[Step=1800 Epoch=17.1] | Loss=0.00622 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.586 | L2-Norm(final)=2.409 | 2284.2 samples/s | 35.7 steps/s
[Step=1850 Epoch=17.5] | Loss=0.00599 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.573 | L2-Norm(final)=2.411 | 4464.1 samples/s | 69.8 steps/s
[Step=1900 Epoch=18.0] | Loss=0.00578 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=2.412 | 2313.6 samples/s | 36.2 steps/s
[Step=1950 Epoch=18.5] | Loss=0.00558 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.547 | L2-Norm(final)=2.413 | 4260.2 samples/s | 66.6 steps/s
[Step=2000 Epoch=19.0] | Loss=0.00540 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.533 | L2-Norm(final)=2.413 | 2400.6 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step2000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.38877 | Reg=0.00173 | acc=0.4688 | L2-Norm=13.135 | L2-Norm(final)=1.878 | 5987.3 samples/s | 93.6 steps/s
[Step=  50 Epoch= 0.5] | Loss=0.28570 | Reg=0.00169 | acc=0.7969 | L2-Norm=12.985 | L2-Norm(final)=1.871 | 4393.0 samples/s | 68.6 steps/s
[Step= 100 Epoch= 1.0] | Loss=0.23992 | Reg=0.00168 | acc=0.9062 | L2-Norm=12.972 | L2-Norm(final)=1.900 | 7643.8 samples/s | 119.4 steps/s
[Step= 150 Epoch= 1.4] | Loss=0.20579 | Reg=0.00169 | acc=0.9219 | L2-Norm=13.005 | L2-Norm(final)=1.935 | 2233.9 samples/s | 34.9 steps/s
[Step= 200 Epoch= 1.9] | Loss=0.18504 | Reg=0.00170 | acc=0.9531 | L2-Norm=13.043 | L2-Norm(final)=1.969 | 7470.6 samples/s | 116.7 steps/s
[Step= 250 Epoch= 2.4] | Loss=0.17122 | Reg=0.00171 | acc=0.9531 | L2-Norm=13.081 | L2-Norm(final)=1.999 | 2345.6 samples/s | 36.7 steps/s
[Step= 300 Epoch= 2.9] | Loss=0.15949 | Reg=0.00172 | acc=0.8906 | L2-Norm=13.117 | L2-Norm(final)=2.025 | 6384.9 samples/s | 99.8 steps/s
[Step= 350 Epoch= 3.3] | Loss=0.14948 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.152 | L2-Norm(final)=2.049 | 2439.6 samples/s | 38.1 steps/s
[Step= 400 Epoch= 3.8] | Loss=0.14152 | Reg=0.00174 | acc=0.9531 | L2-Norm=13.184 | L2-Norm(final)=2.071 | 5761.2 samples/s | 90.0 steps/s
[Step= 450 Epoch= 4.3] | Loss=0.13588 | Reg=0.00175 | acc=0.9062 | L2-Norm=13.216 | L2-Norm(final)=2.092 | 2590.2 samples/s | 40.5 steps/s
[Step= 500 Epoch= 4.8] | Loss=0.13007 | Reg=0.00176 | acc=0.9531 | L2-Norm=13.248 | L2-Norm(final)=2.112 | 5204.5 samples/s | 81.3 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 4.8] | Loss=0.03978 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.563 | L2-Norm(final)=2.302 | 5226.2 samples/s | 81.7 steps/s
[Step= 550 Epoch= 5.2] | Loss=0.05411 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.563 | L2-Norm(final)=2.310 | 3848.0 samples/s | 60.1 steps/s
[Step= 600 Epoch= 5.7] | Loss=0.03499 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.580 | L2-Norm(final)=2.321 | 6332.6 samples/s | 98.9 steps/s
[Step= 650 Epoch= 6.2] | Loss=0.02479 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.596 | L2-Norm(final)=2.329 | 2037.6 samples/s | 31.8 steps/s
[Step= 700 Epoch= 6.7] | Loss=0.01896 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.603 | L2-Norm(final)=2.335 | 5712.0 samples/s | 89.2 steps/s
[Step= 750 Epoch= 7.1] | Loss=0.01527 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.604 | L2-Norm(final)=2.340 | 2119.3 samples/s | 33.1 steps/s
[Step= 800 Epoch= 7.6] | Loss=0.01277 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.600 | L2-Norm(final)=2.343 | 5193.9 samples/s | 81.2 steps/s
[Step= 850 Epoch= 8.1] | Loss=0.01097 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.593 | L2-Norm(final)=2.346 | 2189.5 samples/s | 34.2 steps/s
[Step= 900 Epoch= 8.6] | Loss=0.00962 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.584 | L2-Norm(final)=2.348 | 4745.0 samples/s | 74.1 steps/s
[Step= 950 Epoch= 9.0] | Loss=0.00856 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.573 | L2-Norm(final)=2.350 | 2286.9 samples/s | 35.7 steps/s
[Step=1000 Epoch= 9.5] | Loss=0.00772 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.561 | L2-Norm(final)=2.351 | 4396.9 samples/s | 68.7 steps/s
[Step=1050 Epoch=10.0] | Loss=0.00702 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.548 | L2-Norm(final)=2.353 | 2394.9 samples/s | 37.4 steps/s
[Step=1100 Epoch=10.5] | Loss=0.00644 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.534 | L2-Norm(final)=2.354 | 4229.8 samples/s | 66.1 steps/s
[Step=1150 Epoch=10.9] | Loss=0.00595 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.520 | L2-Norm(final)=2.355 | 2471.1 samples/s | 38.6 steps/s
[Step=1200 Epoch=11.4] | Loss=0.00553 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.506 | L2-Norm(final)=2.356 | 4094.8 samples/s | 64.0 steps/s
[Step=1250 Epoch=11.9] | Loss=0.00517 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.491 | L2-Norm(final)=2.357 | 2438.2 samples/s | 38.1 steps/s
[Step=1300 Epoch=12.4] | Loss=0.00485 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.476 | L2-Norm(final)=2.358 | 4327.8 samples/s | 67.6 steps/s
[Step=1350 Epoch=12.8] | Loss=0.00456 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.461 | L2-Norm(final)=2.359 | 2550.7 samples/s | 39.9 steps/s
[Step=1400 Epoch=13.3] | Loss=0.00431 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.446 | L2-Norm(final)=2.360 | 3891.2 samples/s | 60.8 steps/s
[Step=1450 Epoch=13.8] | Loss=0.00409 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.430 | L2-Norm(final)=2.360 | 6518.8 samples/s | 101.9 steps/s
[Step=1500 Epoch=14.3] | Loss=0.00389 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.414 | L2-Norm(final)=2.361 | 2018.5 samples/s | 31.5 steps/s
[Step=1550 Epoch=14.7] | Loss=0.00370 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.398 | L2-Norm(final)=2.361 | 5930.1 samples/s | 92.7 steps/s
[Step=1600 Epoch=15.2] | Loss=0.00354 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.382 | L2-Norm(final)=2.362 | 2083.3 samples/s | 32.6 steps/s
[Step=1650 Epoch=15.7] | Loss=0.00338 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.366 | L2-Norm(final)=2.363 | 5252.9 samples/s | 82.1 steps/s
[Step=1700 Epoch=16.2] | Loss=0.00324 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.350 | L2-Norm(final)=2.363 | 2154.8 samples/s | 33.7 steps/s
[Step=1750 Epoch=16.6] | Loss=0.00311 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.334 | L2-Norm(final)=2.364 | 4918.8 samples/s | 76.9 steps/s
[Step=1800 Epoch=17.1] | Loss=0.00300 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.318 | L2-Norm(final)=2.364 | 2288.7 samples/s | 35.8 steps/s
[Step=1850 Epoch=17.6] | Loss=0.00288 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.301 | L2-Norm(final)=2.365 | 4316.9 samples/s | 67.5 steps/s
[Step=1900 Epoch=18.1] | Loss=0.00278 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.285 | L2-Norm(final)=2.365 | 2334.0 samples/s | 36.5 steps/s
[Step=1950 Epoch=18.5] | Loss=0.00269 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.269 | L2-Norm(final)=2.366 | 4225.6 samples/s | 66.0 steps/s
[Step=2000 Epoch=19.0] | Loss=0.00260 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.252 | L2-Norm(final)=2.366 | 2410.2 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step2000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.33891 | Reg=0.00175 | acc=0.5312 | L2-Norm=13.236 | L2-Norm(final)=1.928 | 5196.6 samples/s | 81.2 steps/s
[Step=  50 Epoch= 0.5] | Loss=0.27140 | Reg=0.00171 | acc=0.8594 | L2-Norm=13.086 | L2-Norm(final)=1.948 | 4321.7 samples/s | 67.5 steps/s
[Step= 100 Epoch= 1.0] | Loss=0.22106 | Reg=0.00171 | acc=0.9219 | L2-Norm=13.080 | L2-Norm(final)=1.988 | 8548.7 samples/s | 133.6 steps/s
[Step= 150 Epoch= 1.4] | Loss=0.18774 | Reg=0.00172 | acc=0.9531 | L2-Norm=13.115 | L2-Norm(final)=2.032 | 2224.7 samples/s | 34.8 steps/s
[Step= 200 Epoch= 1.9] | Loss=0.16727 | Reg=0.00173 | acc=0.9688 | L2-Norm=13.162 | L2-Norm(final)=2.075 | 6954.0 samples/s | 108.7 steps/s
[Step= 250 Epoch= 2.4] | Loss=0.15311 | Reg=0.00175 | acc=0.9531 | L2-Norm=13.211 | L2-Norm(final)=2.112 | 2207.5 samples/s | 34.5 steps/s
[Step= 300 Epoch= 2.9] | Loss=0.14141 | Reg=0.00176 | acc=0.9688 | L2-Norm=13.263 | L2-Norm(final)=2.147 | 6922.0 samples/s | 108.2 steps/s
[Step= 350 Epoch= 3.3] | Loss=0.13277 | Reg=0.00177 | acc=0.9531 | L2-Norm=13.315 | L2-Norm(final)=2.179 | 2261.9 samples/s | 35.3 steps/s
[Step= 400 Epoch= 3.8] | Loss=0.12469 | Reg=0.00179 | acc=0.9688 | L2-Norm=13.365 | L2-Norm(final)=2.209 | 6262.1 samples/s | 97.8 steps/s
[Step= 450 Epoch= 4.3] | Loss=0.11853 | Reg=0.00180 | acc=0.9375 | L2-Norm=13.416 | L2-Norm(final)=2.238 | 2389.5 samples/s | 37.3 steps/s
[Step= 500 Epoch= 4.8] | Loss=0.11275 | Reg=0.00181 | acc=0.9688 | L2-Norm=13.466 | L2-Norm(final)=2.266 | 5709.6 samples/s | 89.2 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 4.8] | Loss=0.03017 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.970 | L2-Norm(final)=2.540 | 5168.0 samples/s | 80.8 steps/s
[Step= 550 Epoch= 5.3] | Loss=0.04648 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.992 | L2-Norm(final)=2.552 | 3838.2 samples/s | 60.0 steps/s
[Step= 600 Epoch= 5.7] | Loss=0.02995 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.001 | L2-Norm(final)=2.561 | 6253.1 samples/s | 97.7 steps/s
[Step= 650 Epoch= 6.2] | Loss=0.02150 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.004 | L2-Norm(final)=2.569 | 1985.4 samples/s | 31.0 steps/s
[Step= 700 Epoch= 6.7] | Loss=0.01647 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.005 | L2-Norm(final)=2.574 | 5685.4 samples/s | 88.8 steps/s
[Step= 750 Epoch= 7.2] | Loss=0.01325 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.003 | L2-Norm(final)=2.579 | 2075.0 samples/s | 32.4 steps/s
[Step= 800 Epoch= 7.6] | Loss=0.01108 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.999 | L2-Norm(final)=2.582 | 5271.7 samples/s | 82.4 steps/s
[Step= 850 Epoch= 8.1] | Loss=0.00952 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.994 | L2-Norm(final)=2.585 | 2142.9 samples/s | 33.5 steps/s
[Step= 900 Epoch= 8.6] | Loss=0.00834 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.986 | L2-Norm(final)=2.588 | 4837.7 samples/s | 75.6 steps/s
[Step= 950 Epoch= 9.1] | Loss=0.00742 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.978 | L2-Norm(final)=2.590 | 2196.1 samples/s | 34.3 steps/s
[Step=1000 Epoch= 9.5] | Loss=0.00669 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.968 | L2-Norm(final)=2.592 | 4609.7 samples/s | 72.0 steps/s
[Step=1050 Epoch=10.0] | Loss=0.00608 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=2.594 | 2252.7 samples/s | 35.2 steps/s
[Step=1100 Epoch=10.5] | Loss=0.00558 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.946 | L2-Norm(final)=2.596 | 4242.9 samples/s | 66.3 steps/s
[Step=1150 Epoch=11.0] | Loss=0.00516 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.935 | L2-Norm(final)=2.597 | 2330.2 samples/s | 36.4 steps/s
[Step=1200 Epoch=11.5] | Loss=0.00479 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.923 | L2-Norm(final)=2.599 | 4284.5 samples/s | 66.9 steps/s
[Step=1250 Epoch=11.9] | Loss=0.00447 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.910 | L2-Norm(final)=2.600 | 2328.8 samples/s | 36.4 steps/s
[Step=1300 Epoch=12.4] | Loss=0.00420 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.897 | L2-Norm(final)=2.601 | 4178.8 samples/s | 65.3 steps/s
[Step=1350 Epoch=12.9] | Loss=0.00395 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.884 | L2-Norm(final)=2.603 | 2353.7 samples/s | 36.8 steps/s
[Step=1400 Epoch=13.4] | Loss=0.00373 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.871 | L2-Norm(final)=2.604 | 4191.3 samples/s | 65.5 steps/s
[Step=1450 Epoch=13.8] | Loss=0.00354 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.857 | L2-Norm(final)=2.605 | 2340.6 samples/s | 36.6 steps/s
[Step=1500 Epoch=14.3] | Loss=0.00336 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.843 | L2-Norm(final)=2.606 | 4167.9 samples/s | 65.1 steps/s
[Step=1550 Epoch=14.8] | Loss=0.00320 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.829 | L2-Norm(final)=2.607 | 7008.1 samples/s | 109.5 steps/s
[Step=1600 Epoch=15.3] | Loss=0.00306 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.815 | L2-Norm(final)=2.608 | 1947.9 samples/s | 30.4 steps/s
[Step=1650 Epoch=15.8] | Loss=0.00293 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.800 | L2-Norm(final)=2.609 | 6287.8 samples/s | 98.2 steps/s
[Step=1700 Epoch=16.2] | Loss=0.00281 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.786 | L2-Norm(final)=2.610 | 1986.6 samples/s | 31.0 steps/s
[Step=1750 Epoch=16.7] | Loss=0.00269 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.771 | L2-Norm(final)=2.611 | 5767.4 samples/s | 90.1 steps/s
[Step=1800 Epoch=17.2] | Loss=0.00259 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=2.612 | 2053.8 samples/s | 32.1 steps/s
[Step=1850 Epoch=17.7] | Loss=0.00250 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.741 | L2-Norm(final)=2.613 | 5285.3 samples/s | 82.6 steps/s
[Step=1900 Epoch=18.1] | Loss=0.00241 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=2.614 | 2107.0 samples/s | 32.9 steps/s
[Step=1950 Epoch=18.6] | Loss=0.00232 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.711 | L2-Norm(final)=2.615 | 4923.0 samples/s | 76.9 steps/s
[Step=2000 Epoch=19.1] | Loss=0.00225 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.696 | L2-Norm(final)=2.616 | 2155.2 samples/s | 33.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step2000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.42270 | Reg=0.00173 | acc=0.5781 | L2-Norm=13.151 | L2-Norm(final)=1.656 | 5098.4 samples/s | 79.7 steps/s
[Step=  50 Epoch= 0.5] | Loss=0.27923 | Reg=0.00171 | acc=0.7969 | L2-Norm=13.068 | L2-Norm(final)=1.668 | 4351.4 samples/s | 68.0 steps/s
[Step= 100 Epoch= 0.9] | Loss=0.23037 | Reg=0.00172 | acc=0.8750 | L2-Norm=13.112 | L2-Norm(final)=1.711 | 8078.7 samples/s | 126.2 steps/s
[Step= 150 Epoch= 1.4] | Loss=0.20050 | Reg=0.00174 | acc=0.9375 | L2-Norm=13.177 | L2-Norm(final)=1.753 | 2212.7 samples/s | 34.6 steps/s
[Step= 200 Epoch= 1.9] | Loss=0.18211 | Reg=0.00175 | acc=0.8906 | L2-Norm=13.240 | L2-Norm(final)=1.791 | 6878.1 samples/s | 107.5 steps/s
[Step= 250 Epoch= 2.4] | Loss=0.16960 | Reg=0.00177 | acc=0.9219 | L2-Norm=13.301 | L2-Norm(final)=1.823 | 2310.7 samples/s | 36.1 steps/s
[Step= 300 Epoch= 2.8] | Loss=0.15861 | Reg=0.00178 | acc=0.9688 | L2-Norm=13.358 | L2-Norm(final)=1.853 | 6194.2 samples/s | 96.8 steps/s
[Step= 350 Epoch= 3.3] | Loss=0.14953 | Reg=0.00180 | acc=0.9531 | L2-Norm=13.412 | L2-Norm(final)=1.881 | 2424.6 samples/s | 37.9 steps/s
[Step= 400 Epoch= 3.8] | Loss=0.14197 | Reg=0.00181 | acc=0.9375 | L2-Norm=13.464 | L2-Norm(final)=1.907 | 5447.5 samples/s | 85.1 steps/s
[Step= 450 Epoch= 4.2] | Loss=0.13641 | Reg=0.00183 | acc=0.9531 | L2-Norm=13.517 | L2-Norm(final)=1.933 | 2552.9 samples/s | 39.9 steps/s
[Step= 500 Epoch= 4.7] | Loss=0.13054 | Reg=0.00184 | acc=0.9375 | L2-Norm=13.568 | L2-Norm(final)=1.957 | 5129.7 samples/s | 80.2 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 4.7] | Loss=0.13521 | Reg=0.00198 | acc=0.9219 | L2-Norm=14.089 | L2-Norm(final)=2.206 | 5517.9 samples/s | 86.2 steps/s
[Step= 550 Epoch= 5.2] | Loss=0.06510 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.099 | L2-Norm(final)=2.219 | 3679.5 samples/s | 57.5 steps/s
[Step= 600 Epoch= 5.7] | Loss=0.04002 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.111 | L2-Norm(final)=2.230 | 6012.8 samples/s | 94.0 steps/s
[Step= 650 Epoch= 6.1] | Loss=0.02762 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.126 | L2-Norm(final)=2.240 | 2033.1 samples/s | 31.8 steps/s
[Step= 700 Epoch= 6.6] | Loss=0.02113 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.134 | L2-Norm(final)=2.248 | 5438.4 samples/s | 85.0 steps/s
[Step= 750 Epoch= 7.1] | Loss=0.01704 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.139 | L2-Norm(final)=2.254 | 2122.8 samples/s | 33.2 steps/s
[Step= 800 Epoch= 7.5] | Loss=0.01427 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.139 | L2-Norm(final)=2.259 | 4874.6 samples/s | 76.2 steps/s
[Step= 850 Epoch= 8.0] | Loss=0.01227 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.137 | L2-Norm(final)=2.263 | 2174.4 samples/s | 34.0 steps/s
[Step= 900 Epoch= 8.5] | Loss=0.01076 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.132 | L2-Norm(final)=2.266 | 4471.2 samples/s | 69.9 steps/s
[Step= 950 Epoch= 9.0] | Loss=0.00958 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=2.269 | 2288.6 samples/s | 35.8 steps/s
[Step=1000 Epoch= 9.4] | Loss=0.00863 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.118 | L2-Norm(final)=2.271 | 4227.7 samples/s | 66.1 steps/s
[Step=1050 Epoch= 9.9] | Loss=0.00786 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=2.273 | 2363.0 samples/s | 36.9 steps/s
[Step=1100 Epoch=10.4] | Loss=0.00721 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=2.275 | 4245.7 samples/s | 66.3 steps/s
[Step=1150 Epoch=10.8] | Loss=0.00666 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.089 | L2-Norm(final)=2.277 | 2416.3 samples/s | 37.8 steps/s
[Step=1200 Epoch=11.3] | Loss=0.00619 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.078 | L2-Norm(final)=2.279 | 4146.6 samples/s | 64.8 steps/s
[Step=1250 Epoch=11.8] | Loss=0.00578 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.066 | L2-Norm(final)=2.280 | 2729.7 samples/s | 42.7 steps/s
[Step=1300 Epoch=12.2] | Loss=0.00542 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.054 | L2-Norm(final)=2.281 | 3387.6 samples/s | 52.9 steps/s
[Step=1350 Epoch=12.7] | Loss=0.00511 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.041 | L2-Norm(final)=2.283 | 6310.4 samples/s | 98.6 steps/s
[Step=1400 Epoch=13.2] | Loss=0.00483 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.028 | L2-Norm(final)=2.284 | 1997.1 samples/s | 31.2 steps/s
[Step=1450 Epoch=13.7] | Loss=0.00457 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.015 | L2-Norm(final)=2.285 | 5601.4 samples/s | 87.5 steps/s
[Step=1500 Epoch=14.1] | Loss=0.00435 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.001 | L2-Norm(final)=2.286 | 2076.4 samples/s | 32.4 steps/s
[Step=1550 Epoch=14.6] | Loss=0.00414 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.987 | L2-Norm(final)=2.287 | 5000.4 samples/s | 78.1 steps/s
[Step=1600 Epoch=15.1] | Loss=0.00396 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.973 | L2-Norm(final)=2.288 | 2182.7 samples/s | 34.1 steps/s
[Step=1650 Epoch=15.5] | Loss=0.00378 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=2.289 | 4546.2 samples/s | 71.0 steps/s
[Step=1700 Epoch=16.0] | Loss=0.00363 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.944 | L2-Norm(final)=2.289 | 2294.7 samples/s | 35.9 steps/s
[Step=1750 Epoch=16.5] | Loss=0.00348 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.929 | L2-Norm(final)=2.290 | 4235.2 samples/s | 66.2 steps/s
[Step=1800 Epoch=17.0] | Loss=0.00335 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.913 | L2-Norm(final)=2.291 | 2383.9 samples/s | 37.2 steps/s
[Step=1850 Epoch=17.4] | Loss=0.00323 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.898 | L2-Norm(final)=2.292 | 4224.3 samples/s | 66.0 steps/s
[Step=1900 Epoch=17.9] | Loss=0.00311 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.882 | L2-Norm(final)=2.292 | 2344.7 samples/s | 36.6 steps/s
[Step=1950 Epoch=18.4] | Loss=0.00301 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=2.293 | 4217.2 samples/s | 65.9 steps/s
[Step=2000 Epoch=18.8] | Loss=0.00291 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.851 | L2-Norm(final)=2.294 | 2450.6 samples/s | 38.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step2000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.51037 | Reg=0.00176 | acc=0.5312 | L2-Norm=13.251 | L2-Norm(final)=2.147 | 5202.4 samples/s | 81.3 steps/s
[Step=  50 Epoch= 0.5] | Loss=0.28467 | Reg=0.00173 | acc=0.8594 | L2-Norm=13.134 | L2-Norm(final)=2.142 | 4183.9 samples/s | 65.4 steps/s
[Step= 100 Epoch= 1.0] | Loss=0.23490 | Reg=0.00172 | acc=0.9062 | L2-Norm=13.126 | L2-Norm(final)=2.173 | 8422.0 samples/s | 131.6 steps/s
[Step= 150 Epoch= 1.4] | Loss=0.20444 | Reg=0.00173 | acc=0.9219 | L2-Norm=13.152 | L2-Norm(final)=2.211 | 2173.1 samples/s | 34.0 steps/s
[Step= 200 Epoch= 1.9] | Loss=0.18519 | Reg=0.00174 | acc=0.9375 | L2-Norm=13.185 | L2-Norm(final)=2.247 | 7560.6 samples/s | 118.1 steps/s
[Step= 250 Epoch= 2.4] | Loss=0.16848 | Reg=0.00175 | acc=0.9844 | L2-Norm=13.221 | L2-Norm(final)=2.279 | 2297.0 samples/s | 35.9 steps/s
[Step= 300 Epoch= 2.9] | Loss=0.15762 | Reg=0.00176 | acc=0.9844 | L2-Norm=13.258 | L2-Norm(final)=2.309 | 6295.9 samples/s | 98.4 steps/s
[Step= 350 Epoch= 3.3] | Loss=0.14965 | Reg=0.00177 | acc=0.9531 | L2-Norm=13.294 | L2-Norm(final)=2.336 | 2321.3 samples/s | 36.3 steps/s
[Step= 400 Epoch= 3.8] | Loss=0.14135 | Reg=0.00178 | acc=0.9375 | L2-Norm=13.332 | L2-Norm(final)=2.364 | 6165.1 samples/s | 96.3 steps/s
[Step= 450 Epoch= 4.3] | Loss=0.13418 | Reg=0.00179 | acc=0.9062 | L2-Norm=13.371 | L2-Norm(final)=2.391 | 2443.6 samples/s | 38.2 steps/s
[Step= 500 Epoch= 4.8] | Loss=0.12926 | Reg=0.00180 | acc=0.9531 | L2-Norm=13.411 | L2-Norm(final)=2.417 | 5453.9 samples/s | 85.2 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 4.8] | Loss=0.08363 | Reg=0.00191 | acc=0.9688 | L2-Norm=13.828 | L2-Norm(final)=2.668 | 5232.0 samples/s | 81.8 steps/s
[Step= 550 Epoch= 5.2] | Loss=0.05887 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.845 | L2-Norm(final)=2.678 | 3760.0 samples/s | 58.7 steps/s
[Step= 600 Epoch= 5.7] | Loss=0.03778 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.866 | L2-Norm(final)=2.691 | 6346.6 samples/s | 99.2 steps/s
[Step= 650 Epoch= 6.2] | Loss=0.02649 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.875 | L2-Norm(final)=2.700 | 1985.9 samples/s | 31.0 steps/s
[Step= 700 Epoch= 6.7] | Loss=0.02043 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.880 | L2-Norm(final)=2.708 | 5767.4 samples/s | 90.1 steps/s
[Step= 750 Epoch= 7.1] | Loss=0.01646 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.880 | L2-Norm(final)=2.713 | 2055.2 samples/s | 32.1 steps/s
[Step= 800 Epoch= 7.6] | Loss=0.01377 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.876 | L2-Norm(final)=2.718 | 5285.1 samples/s | 82.6 steps/s
[Step= 850 Epoch= 8.1] | Loss=0.01183 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.869 | L2-Norm(final)=2.721 | 2110.9 samples/s | 33.0 steps/s
[Step= 900 Epoch= 8.6] | Loss=0.01037 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.861 | L2-Norm(final)=2.724 | 4928.8 samples/s | 77.0 steps/s
[Step= 950 Epoch= 9.1] | Loss=0.00923 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.851 | L2-Norm(final)=2.726 | 2189.4 samples/s | 34.2 steps/s
[Step=1000 Epoch= 9.5] | Loss=0.00832 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.840 | L2-Norm(final)=2.728 | 4457.4 samples/s | 69.6 steps/s
[Step=1050 Epoch=10.0] | Loss=0.00757 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.829 | L2-Norm(final)=2.730 | 2270.2 samples/s | 35.5 steps/s
[Step=1100 Epoch=10.5] | Loss=0.00694 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.817 | L2-Norm(final)=2.732 | 4344.3 samples/s | 67.9 steps/s
[Step=1150 Epoch=11.0] | Loss=0.00641 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.806 | L2-Norm(final)=2.735 | 2384.4 samples/s | 37.3 steps/s
[Step=1200 Epoch=11.4] | Loss=0.00596 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.794 | L2-Norm(final)=2.740 | 4406.2 samples/s | 68.8 steps/s
[Step=1250 Epoch=11.9] | Loss=0.00556 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.781 | L2-Norm(final)=2.746 | 2315.0 samples/s | 36.2 steps/s
[Step=1300 Epoch=12.4] | Loss=0.00522 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.769 | L2-Norm(final)=2.752 | 4272.3 samples/s | 66.8 steps/s
[Step=1350 Epoch=12.9] | Loss=0.00491 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=2.759 | 2382.1 samples/s | 37.2 steps/s
[Step=1400 Epoch=13.3] | Loss=0.00464 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.742 | L2-Norm(final)=2.767 | 4130.1 samples/s | 64.5 steps/s
[Step=1450 Epoch=13.8] | Loss=0.00440 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.729 | L2-Norm(final)=2.775 | 2234.0 samples/s | 34.9 steps/s
[Step=1500 Epoch=14.3] | Loss=0.00418 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.715 | L2-Norm(final)=2.783 | 4015.3 samples/s | 62.7 steps/s
[Step=1550 Epoch=14.8] | Loss=0.00398 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.701 | L2-Norm(final)=2.791 | 6556.1 samples/s | 102.4 steps/s
[Step=1600 Epoch=15.2] | Loss=0.00380 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.686 | L2-Norm(final)=2.800 | 1820.4 samples/s | 28.4 steps/s
[Step=1650 Epoch=15.7] | Loss=0.00364 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.672 | L2-Norm(final)=2.808 | 5997.5 samples/s | 93.7 steps/s
[Step=1700 Epoch=16.2] | Loss=0.00348 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.657 | L2-Norm(final)=2.817 | 1899.0 samples/s | 29.7 steps/s
[Step=1750 Epoch=16.7] | Loss=0.00335 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.642 | L2-Norm(final)=2.825 | 5496.0 samples/s | 85.9 steps/s
[Step=1800 Epoch=17.2] | Loss=0.00322 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=2.834 | 2017.1 samples/s | 31.5 steps/s
[Step=1850 Epoch=17.6] | Loss=0.00310 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.612 | L2-Norm(final)=2.843 | 5421.4 samples/s | 84.7 steps/s
[Step=1900 Epoch=18.1] | Loss=0.00299 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.596 | L2-Norm(final)=2.852 | 2140.4 samples/s | 33.4 steps/s
[Step=1950 Epoch=18.6] | Loss=0.00289 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.581 | L2-Norm(final)=2.861 | 4886.5 samples/s | 76.4 steps/s
[Step=2000 Epoch=19.1] | Loss=0.00279 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=2.870 | 2192.5 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.14878 | acc=0.9076 | tpr=0.9088 | fpr=0.0951 | 4669.5 samples/s | 18.2 steps/s
Avg test loss: 0.15416, Avg test acc: 0.90316, Avg tpr: 0.90529, Avg fpr: 0.10153, total FA: 792

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.14463 | acc=0.9205 | tpr=0.9321 | fpr=0.1046 | 5060.7 samples/s | 19.8 steps/s
Avg test loss: 0.14770, Avg test acc: 0.91995, Avg tpr: 0.93029, Avg fpr: 0.10281, total FA: 802

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.19562 | acc=0.8969 | tpr=0.8820 | fpr=0.0709 | 4684.6 samples/s | 18.3 steps/s
Avg test loss: 0.19949, Avg test acc: 0.89410, Avg tpr: 0.87824, Avg fpr: 0.07102, total FA: 554

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14692 | acc=0.9277 | tpr=0.9565 | fpr=0.1348 | 4945.1 samples/s | 19.3 steps/s
Avg test loss: 0.15093, Avg test acc: 0.92628, Avg tpr: 0.95757, Avg fpr: 0.14255, total FA: 1112

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.15247 | acc=0.9272 | tpr=0.9456 | fpr=0.1127 | 4927.0 samples/s | 19.2 steps/s
Avg test loss: 0.15584, Avg test acc: 0.92564, Avg tpr: 0.94236, Avg fpr: 0.11114, total FA: 867

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.77156 | acc=0.3184 | tpr=0.0396 | fpr=0.0761 | 4861.0 samples/s | 19.0 steps/s
Avg test loss: 3.79253, Avg test acc: 0.31601, Avg tpr: 0.03730, Avg fpr: 0.07102, total FA: 554

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=3.80403 | acc=0.3147 | tpr=0.0350 | fpr=0.0780 | 4844.7 samples/s | 18.9 steps/s
Avg test loss: 3.81506, Avg test acc: 0.31353, Avg tpr: 0.03474, Avg fpr: 0.07332, total FA: 572

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.16059 | acc=0.3170 | tpr=0.0261 | fpr=0.0515 | 4856.2 samples/s | 19.0 steps/s
Avg test loss: 4.20615, Avg test acc: 0.31253, Avg tpr: 0.02378, Avg fpr: 0.05243, total FA: 409

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=3.90540 | acc=0.3124 | tpr=0.0366 | fpr=0.0887 | 4660.9 samples/s | 18.2 steps/s
Avg test loss: 3.92845, Avg test acc: 0.31064, Avg tpr: 0.03567, Avg fpr: 0.08460, total FA: 660

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=3.91664 | acc=0.3220 | tpr=0.0314 | fpr=0.0468 | 5066.0 samples/s | 19.8 steps/s
Avg test loss: 3.93858, Avg test acc: 0.32058, Avg tpr: 0.03182, Avg fpr: 0.04435, total FA: 346

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=1.88077 | acc=0.1980 | tpr=0.7168 | fpr=0.8113 | 4967.7 samples/s | 19.4 steps/s
[Step= 100] | Loss=1.88004 | acc=0.1978 | tpr=0.7249 | fpr=0.8121 | 7073.9 samples/s | 27.6 steps/s
[Step= 150] | Loss=1.87218 | acc=0.1989 | tpr=0.7089 | fpr=0.8105 | 7870.3 samples/s | 30.7 steps/s
[Step= 200] | Loss=1.86449 | acc=0.2003 | tpr=0.7115 | fpr=0.8090 | 7744.3 samples/s | 30.3 steps/s
[Step= 250] | Loss=1.86964 | acc=0.2002 | tpr=0.7048 | fpr=0.8090 | 7795.3 samples/s | 30.5 steps/s
[Step= 300] | Loss=1.87004 | acc=0.1994 | tpr=0.7098 | fpr=0.8099 | 7781.8 samples/s | 30.4 steps/s
[Step= 350] | Loss=1.86909 | acc=0.1989 | tpr=0.7101 | fpr=0.8104 | 7920.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=1.87120 | acc=0.1986 | tpr=0.7144 | fpr=0.8108 | 7728.7 samples/s | 30.2 steps/s
[Step= 450] | Loss=1.87065 | acc=0.1985 | tpr=0.7157 | fpr=0.8109 | 7949.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=1.87095 | acc=0.1982 | tpr=0.7167 | fpr=0.8111 | 7853.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=1.87026 | acc=0.1984 | tpr=0.7187 | fpr=0.8111 | 14307.1 samples/s | 55.9 steps/s
Avg test loss: 1.87073, Avg test acc: 0.19835, Avg tpr: 0.71791, Avg fpr: 0.81110, total FA: 112619

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=2.53425 | acc=0.1930 | tpr=0.6106 | fpr=0.8145 | 4912.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=2.52927 | acc=0.1904 | tpr=0.6119 | fpr=0.8175 | 7010.6 samples/s | 27.4 steps/s
[Step= 150] | Loss=2.51681 | acc=0.1911 | tpr=0.6023 | fpr=0.8164 | 7579.5 samples/s | 29.6 steps/s
[Step= 200] | Loss=2.51099 | acc=0.1912 | tpr=0.6066 | fpr=0.8163 | 8022.7 samples/s | 31.3 steps/s
[Step= 250] | Loss=2.51119 | acc=0.1910 | tpr=0.6131 | fpr=0.8167 | 7983.3 samples/s | 31.2 steps/s
[Step= 300] | Loss=2.51549 | acc=0.1896 | tpr=0.6160 | fpr=0.8182 | 7698.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=2.51527 | acc=0.1887 | tpr=0.6155 | fpr=0.8190 | 7776.5 samples/s | 30.4 steps/s
[Step= 400] | Loss=2.51625 | acc=0.1891 | tpr=0.6220 | fpr=0.8188 | 8575.2 samples/s | 33.5 steps/s
[Step= 450] | Loss=2.51950 | acc=0.1888 | tpr=0.6246 | fpr=0.8191 | 7624.9 samples/s | 29.8 steps/s
[Step= 500] | Loss=2.52072 | acc=0.1885 | tpr=0.6181 | fpr=0.8192 | 8081.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=2.52010 | acc=0.1890 | tpr=0.6184 | fpr=0.8188 | 13700.8 samples/s | 53.5 steps/s
Avg test loss: 2.52041, Avg test acc: 0.18889, Avg tpr: 0.61846, Avg fpr: 0.81892, total FA: 113705

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=2.68836 | acc=0.1966 | tpr=0.5885 | fpr=0.8104 | 4796.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=2.66723 | acc=0.1972 | tpr=0.6247 | fpr=0.8108 | 7205.5 samples/s | 28.1 steps/s
[Step= 150] | Loss=2.66648 | acc=0.1972 | tpr=0.6297 | fpr=0.8107 | 7504.7 samples/s | 29.3 steps/s
[Step= 200] | Loss=2.66419 | acc=0.1970 | tpr=0.6262 | fpr=0.8109 | 7861.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=2.67063 | acc=0.1968 | tpr=0.6157 | fpr=0.8109 | 8236.7 samples/s | 32.2 steps/s
[Step= 300] | Loss=2.67358 | acc=0.1967 | tpr=0.6145 | fpr=0.8109 | 7687.8 samples/s | 30.0 steps/s
[Step= 350] | Loss=2.67121 | acc=0.1974 | tpr=0.6193 | fpr=0.8103 | 8020.2 samples/s | 31.3 steps/s
[Step= 400] | Loss=2.66952 | acc=0.1975 | tpr=0.6149 | fpr=0.8101 | 8127.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=2.67107 | acc=0.1969 | tpr=0.6183 | fpr=0.8108 | 7691.5 samples/s | 30.0 steps/s
[Step= 500] | Loss=2.67287 | acc=0.1967 | tpr=0.6123 | fpr=0.8108 | 8028.0 samples/s | 31.4 steps/s
[Step= 550] | Loss=2.67294 | acc=0.1966 | tpr=0.6116 | fpr=0.8110 | 13632.2 samples/s | 53.3 steps/s
Avg test loss: 2.67332, Avg test acc: 0.19650, Avg tpr: 0.61212, Avg fpr: 0.81105, total FA: 112613

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=3.26106 | acc=0.1259 | tpr=0.8407 | fpr=0.8870 | 4756.2 samples/s | 18.6 steps/s
[Step= 100] | Loss=3.25444 | acc=0.1270 | tpr=0.8230 | fpr=0.8860 | 7086.5 samples/s | 27.7 steps/s
[Step= 150] | Loss=3.24302 | acc=0.1272 | tpr=0.8300 | fpr=0.8857 | 8169.8 samples/s | 31.9 steps/s
[Step= 200] | Loss=3.23469 | acc=0.1268 | tpr=0.8208 | fpr=0.8858 | 7582.0 samples/s | 29.6 steps/s
[Step= 250] | Loss=3.23495 | acc=0.1270 | tpr=0.8245 | fpr=0.8857 | 7941.2 samples/s | 31.0 steps/s
[Step= 300] | Loss=3.23537 | acc=0.1263 | tpr=0.8204 | fpr=0.8864 | 7991.1 samples/s | 31.2 steps/s
[Step= 350] | Loss=3.23285 | acc=0.1259 | tpr=0.8203 | fpr=0.8867 | 7704.3 samples/s | 30.1 steps/s
[Step= 400] | Loss=3.23032 | acc=0.1260 | tpr=0.8200 | fpr=0.8866 | 8180.3 samples/s | 32.0 steps/s
[Step= 450] | Loss=3.23258 | acc=0.1260 | tpr=0.8233 | fpr=0.8867 | 7789.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=3.23315 | acc=0.1260 | tpr=0.8233 | fpr=0.8866 | 7947.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=3.23236 | acc=0.1261 | tpr=0.8265 | fpr=0.8867 | 13967.1 samples/s | 54.6 steps/s
Avg test loss: 3.23300, Avg test acc: 0.12604, Avg tpr: 0.82647, Avg fpr: 0.88670, total FA: 123116

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=3.41612 | acc=0.1314 | tpr=0.6947 | fpr=0.8787 | 4955.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=3.42859 | acc=0.1315 | tpr=0.7036 | fpr=0.8792 | 6999.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=3.42061 | acc=0.1329 | tpr=0.6931 | fpr=0.8774 | 7410.3 samples/s | 28.9 steps/s
[Step= 200] | Loss=3.41023 | acc=0.1337 | tpr=0.7027 | fpr=0.8766 | 8163.0 samples/s | 31.9 steps/s
[Step= 250] | Loss=3.41950 | acc=0.1327 | tpr=0.7074 | fpr=0.8778 | 7594.5 samples/s | 29.7 steps/s
[Step= 300] | Loss=3.41803 | acc=0.1324 | tpr=0.7069 | fpr=0.8780 | 8130.3 samples/s | 31.8 steps/s
[Step= 350] | Loss=3.41573 | acc=0.1326 | tpr=0.7038 | fpr=0.8778 | 8085.7 samples/s | 31.6 steps/s
[Step= 400] | Loss=3.41239 | acc=0.1327 | tpr=0.7057 | fpr=0.8777 | 7531.1 samples/s | 29.4 steps/s
[Step= 450] | Loss=3.41477 | acc=0.1321 | tpr=0.7030 | fpr=0.8782 | 7783.4 samples/s | 30.4 steps/s
[Step= 500] | Loss=3.41509 | acc=0.1321 | tpr=0.7070 | fpr=0.8782 | 8393.8 samples/s | 32.8 steps/s
[Step= 550] | Loss=3.41482 | acc=0.1323 | tpr=0.7047 | fpr=0.8781 | 13357.9 samples/s | 52.2 steps/s
Avg test loss: 3.41527, Avg test acc: 0.13221, Avg tpr: 0.70404, Avg fpr: 0.87818, total FA: 121934

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.05220 | acc=0.9801 | tpr=0.8319 | fpr=0.0173 | 4784.9 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.05098 | acc=0.9804 | tpr=0.8465 | fpr=0.0172 | 7222.3 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.05218 | acc=0.9795 | tpr=0.8429 | fpr=0.0180 | 7823.5 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.05302 | acc=0.9793 | tpr=0.8481 | fpr=0.0183 | 7689.0 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.05309 | acc=0.9794 | tpr=0.8428 | fpr=0.0181 | 8159.3 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.05412 | acc=0.9791 | tpr=0.8415 | fpr=0.0184 | 8028.2 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.05496 | acc=0.9790 | tpr=0.8422 | fpr=0.0185 | 7579.0 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.05556 | acc=0.9787 | tpr=0.8397 | fpr=0.0188 | 7993.1 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.05631 | acc=0.9785 | tpr=0.8442 | fpr=0.0191 | 8148.6 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.05576 | acc=0.9786 | tpr=0.8480 | fpr=0.0191 | 7805.7 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.05535 | acc=0.9788 | tpr=0.8508 | fpr=0.0189 | 13831.9 samples/s | 54.0 steps/s
Avg test loss: 0.05526, Avg test acc: 0.97877, Avg tpr: 0.85103, Avg fpr: 0.01891, total FA: 2626

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.04629 | acc=0.9815 | tpr=0.8053 | fpr=0.0153 | 4861.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.04706 | acc=0.9816 | tpr=0.8337 | fpr=0.0156 | 6976.2 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.04699 | acc=0.9814 | tpr=0.8401 | fpr=0.0160 | 7622.3 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.04718 | acc=0.9811 | tpr=0.8361 | fpr=0.0163 | 8407.3 samples/s | 32.8 steps/s
[Step= 250] | Loss=0.04697 | acc=0.9811 | tpr=0.8279 | fpr=0.0161 | 7901.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.04751 | acc=0.9809 | tpr=0.8269 | fpr=0.0163 | 7902.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.04728 | acc=0.9808 | tpr=0.8297 | fpr=0.0164 | 7655.2 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.04752 | acc=0.9806 | tpr=0.8304 | fpr=0.0166 | 8052.5 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.04861 | acc=0.9803 | tpr=0.8272 | fpr=0.0169 | 7979.7 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.04827 | acc=0.9804 | tpr=0.8295 | fpr=0.0168 | 8174.5 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.04805 | acc=0.9804 | tpr=0.8269 | fpr=0.0168 | 13543.5 samples/s | 52.9 steps/s
Avg test loss: 0.04796, Avg test acc: 0.98042, Avg tpr: 0.82726, Avg fpr: 0.01680, total FA: 2332

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.04811 | acc=0.9798 | tpr=0.8717 | fpr=0.0183 | 4836.2 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.04930 | acc=0.9796 | tpr=0.8614 | fpr=0.0182 | 7278.4 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.05178 | acc=0.9785 | tpr=0.8473 | fpr=0.0191 | 7704.5 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.05259 | acc=0.9782 | tpr=0.8448 | fpr=0.0193 | 7660.2 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.05149 | acc=0.9787 | tpr=0.8437 | fpr=0.0189 | 7961.4 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.05282 | acc=0.9784 | tpr=0.8385 | fpr=0.0191 | 7878.4 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.05280 | acc=0.9783 | tpr=0.8441 | fpr=0.0192 | 7890.5 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.05360 | acc=0.9780 | tpr=0.8414 | fpr=0.0195 | 7750.0 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.05366 | acc=0.9780 | tpr=0.8457 | fpr=0.0196 | 8298.8 samples/s | 32.4 steps/s
[Step= 500] | Loss=0.05346 | acc=0.9780 | tpr=0.8449 | fpr=0.0196 | 7274.6 samples/s | 28.4 steps/s
[Step= 550] | Loss=0.05326 | acc=0.9782 | tpr=0.8472 | fpr=0.0194 | 15051.8 samples/s | 58.8 steps/s
Avg test loss: 0.05316, Avg test acc: 0.97821, Avg tpr: 0.84707, Avg fpr: 0.01941, total FA: 2695

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.05660 | acc=0.9785 | tpr=0.8540 | fpr=0.0192 | 4840.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.05808 | acc=0.9782 | tpr=0.8721 | fpr=0.0199 | 7186.2 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.05975 | acc=0.9772 | tpr=0.8718 | fpr=0.0209 | 7765.4 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.06071 | acc=0.9772 | tpr=0.8776 | fpr=0.0210 | 7766.4 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.05984 | acc=0.9776 | tpr=0.8760 | fpr=0.0206 | 8009.9 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.06085 | acc=0.9771 | tpr=0.8720 | fpr=0.0210 | 7782.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.06145 | acc=0.9770 | tpr=0.8754 | fpr=0.0211 | 7994.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.06227 | acc=0.9766 | tpr=0.8714 | fpr=0.0214 | 7771.9 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.06298 | acc=0.9763 | tpr=0.8715 | fpr=0.0218 | 8094.7 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.06262 | acc=0.9763 | tpr=0.8722 | fpr=0.0219 | 7837.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.06197 | acc=0.9765 | tpr=0.8719 | fpr=0.0216 | 13476.0 samples/s | 52.6 steps/s
Avg test loss: 0.06191, Avg test acc: 0.97653, Avg tpr: 0.87242, Avg fpr: 0.02158, total FA: 2996

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.06333 | acc=0.9802 | tpr=0.7876 | fpr=0.0164 | 5012.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.06487 | acc=0.9791 | tpr=0.7996 | fpr=0.0175 | 6446.5 samples/s | 25.2 steps/s
[Step= 150] | Loss=0.06428 | acc=0.9788 | tpr=0.8141 | fpr=0.0182 | 7992.2 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.06575 | acc=0.9784 | tpr=0.8175 | fpr=0.0187 | 8161.2 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.06484 | acc=0.9787 | tpr=0.8122 | fpr=0.0182 | 7927.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.06552 | acc=0.9788 | tpr=0.8095 | fpr=0.0182 | 7755.2 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.06633 | acc=0.9786 | tpr=0.8128 | fpr=0.0184 | 7799.2 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.06681 | acc=0.9783 | tpr=0.8113 | fpr=0.0187 | 8054.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.06814 | acc=0.9779 | tpr=0.8087 | fpr=0.0190 | 7621.0 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.06739 | acc=0.9781 | tpr=0.8084 | fpr=0.0188 | 8157.0 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.06706 | acc=0.9782 | tpr=0.8094 | fpr=0.0187 | 13912.6 samples/s | 54.3 steps/s
Avg test loss: 0.06687, Avg test acc: 0.97824, Avg tpr: 0.80943, Avg fpr: 0.01869, total FA: 2595

server round 1/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 9.8] | Loss=0.18702 | Reg=0.00338 | acc=0.8594 | L2-Norm=18.397 | L2-Norm(final)=2.566 | 5361.2 samples/s | 83.8 steps/s
[Step=2050 Epoch=10.0] | Loss=0.15314 | Reg=0.00340 | acc=0.8125 | L2-Norm=18.436 | L2-Norm(final)=2.539 | 4501.2 samples/s | 70.3 steps/s
[Step=2100 Epoch=10.2] | Loss=0.13851 | Reg=0.00342 | acc=0.8750 | L2-Norm=18.485 | L2-Norm(final)=2.540 | 5067.9 samples/s | 79.2 steps/s
[Step=2150 Epoch=10.5] | Loss=0.13395 | Reg=0.00343 | acc=0.8750 | L2-Norm=18.524 | L2-Norm(final)=2.549 | 5062.3 samples/s | 79.1 steps/s
[Step=2200 Epoch=10.7] | Loss=0.13052 | Reg=0.00344 | acc=0.8281 | L2-Norm=18.558 | L2-Norm(final)=2.561 | 7931.7 samples/s | 123.9 steps/s
[Step=2250 Epoch=11.0] | Loss=0.13079 | Reg=0.00346 | acc=0.8750 | L2-Norm=18.598 | L2-Norm(final)=2.573 | 2186.3 samples/s | 34.2 steps/s
[Step=2300 Epoch=11.2] | Loss=0.12854 | Reg=0.00348 | acc=0.8750 | L2-Norm=18.645 | L2-Norm(final)=2.588 | 5078.6 samples/s | 79.4 steps/s
[Step=2350 Epoch=11.5] | Loss=0.12553 | Reg=0.00349 | acc=0.9219 | L2-Norm=18.691 | L2-Norm(final)=2.605 | 4974.5 samples/s | 77.7 steps/s
[Step=2400 Epoch=11.7] | Loss=0.12365 | Reg=0.00351 | acc=0.8750 | L2-Norm=18.736 | L2-Norm(final)=2.621 | 7042.0 samples/s | 110.0 steps/s
[Step=2450 Epoch=11.9] | Loss=0.12179 | Reg=0.00353 | acc=0.9531 | L2-Norm=18.781 | L2-Norm(final)=2.639 | 2322.9 samples/s | 36.3 steps/s
[Step=2500 Epoch=12.2] | Loss=0.12036 | Reg=0.00355 | acc=0.9375 | L2-Norm=18.826 | L2-Norm(final)=2.658 | 5057.0 samples/s | 79.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=12.2] | Loss=0.07123 | Reg=0.00372 | acc=0.9062 | L2-Norm=19.286 | L2-Norm(final)=2.854 | 5969.3 samples/s | 93.3 steps/s
[Step=2550 Epoch=12.4] | Loss=0.12839 | Reg=0.00374 | acc=0.8750 | L2-Norm=19.332 | L2-Norm(final)=2.857 | 3817.8 samples/s | 59.7 steps/s
[Step=2600 Epoch=12.7] | Loss=0.11879 | Reg=0.00375 | acc=0.9062 | L2-Norm=19.364 | L2-Norm(final)=2.861 | 4382.3 samples/s | 68.5 steps/s
[Step=2650 Epoch=12.9] | Loss=0.11028 | Reg=0.00376 | acc=0.9219 | L2-Norm=19.396 | L2-Norm(final)=2.866 | 4493.4 samples/s | 70.2 steps/s
[Step=2700 Epoch=13.2] | Loss=0.10429 | Reg=0.00377 | acc=0.9375 | L2-Norm=19.422 | L2-Norm(final)=2.872 | 6572.2 samples/s | 102.7 steps/s
[Step=2750 Epoch=13.4] | Loss=0.09446 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.444 | L2-Norm(final)=2.878 | 2093.2 samples/s | 32.7 steps/s
[Step=2800 Epoch=13.7] | Loss=0.08723 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.463 | L2-Norm(final)=2.885 | 4531.3 samples/s | 70.8 steps/s
[Step=2850 Epoch=13.9] | Loss=0.08260 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.478 | L2-Norm(final)=2.892 | 4443.0 samples/s | 69.4 steps/s
[Step=2900 Epoch=14.1] | Loss=0.08003 | Reg=0.00380 | acc=0.9219 | L2-Norm=19.493 | L2-Norm(final)=2.897 | 5947.2 samples/s | 92.9 steps/s
[Step=2950 Epoch=14.4] | Loss=0.07475 | Reg=0.00381 | acc=0.9688 | L2-Norm=19.508 | L2-Norm(final)=2.904 | 2140.8 samples/s | 33.5 steps/s
[Step=3000 Epoch=14.6] | Loss=0.07066 | Reg=0.00381 | acc=0.9688 | L2-Norm=19.521 | L2-Norm(final)=2.911 | 4519.9 samples/s | 70.6 steps/s
[Step=3050 Epoch=14.9] | Loss=0.06808 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.533 | L2-Norm(final)=2.917 | 4465.6 samples/s | 69.8 steps/s
[Step=3100 Epoch=15.1] | Loss=0.06520 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.544 | L2-Norm(final)=2.923 | 5450.9 samples/s | 85.2 steps/s
[Step=3150 Epoch=15.4] | Loss=0.06236 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.555 | L2-Norm(final)=2.928 | 2253.9 samples/s | 35.2 steps/s
[Step=3200 Epoch=15.6] | Loss=0.06070 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.565 | L2-Norm(final)=2.933 | 4526.1 samples/s | 70.7 steps/s
[Step=3250 Epoch=15.8] | Loss=0.05853 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.575 | L2-Norm(final)=2.938 | 4464.4 samples/s | 69.8 steps/s
[Step=3300 Epoch=16.1] | Loss=0.05621 | Reg=0.00384 | acc=0.9531 | L2-Norm=19.585 | L2-Norm(final)=2.943 | 4938.6 samples/s | 77.2 steps/s
[Step=3350 Epoch=16.3] | Loss=0.05423 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.593 | L2-Norm(final)=2.948 | 2245.7 samples/s | 35.1 steps/s
[Step=3400 Epoch=16.6] | Loss=0.05240 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.601 | L2-Norm(final)=2.953 | 4483.3 samples/s | 70.1 steps/s
[Step=3450 Epoch=16.8] | Loss=0.05080 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.608 | L2-Norm(final)=2.958 | 4491.8 samples/s | 70.2 steps/s
[Step=3500 Epoch=17.1] | Loss=0.04926 | Reg=0.00385 | acc=0.9375 | L2-Norm=19.614 | L2-Norm(final)=2.963 | 4619.2 samples/s | 72.2 steps/s
[Step=3550 Epoch=17.3] | Loss=0.04790 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.620 | L2-Norm(final)=2.967 | 2450.2 samples/s | 38.3 steps/s
[Step=3600 Epoch=17.6] | Loss=0.04651 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.625 | L2-Norm(final)=2.972 | 4431.5 samples/s | 69.2 steps/s
[Step=3650 Epoch=17.8] | Loss=0.04509 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.630 | L2-Norm(final)=2.977 | 4363.1 samples/s | 68.2 steps/s
[Step=3700 Epoch=18.0] | Loss=0.04437 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.635 | L2-Norm(final)=2.981 | 4435.4 samples/s | 69.3 steps/s
[Step=3750 Epoch=18.3] | Loss=0.04332 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.640 | L2-Norm(final)=2.985 | 2512.7 samples/s | 39.3 steps/s
[Step=3800 Epoch=18.5] | Loss=0.04232 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.644 | L2-Norm(final)=2.990 | 4376.0 samples/s | 68.4 steps/s
[Step=3850 Epoch=18.8] | Loss=0.04182 | Reg=0.00386 | acc=0.9219 | L2-Norm=19.648 | L2-Norm(final)=2.993 | 4460.1 samples/s | 69.7 steps/s
[Step=3900 Epoch=19.0] | Loss=0.04120 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.653 | L2-Norm(final)=2.997 | 4577.9 samples/s | 71.5 steps/s
[Step=3950 Epoch=19.3] | Loss=0.04048 | Reg=0.00386 | acc=0.9688 | L2-Norm=19.658 | L2-Norm(final)=3.000 | 2449.7 samples/s | 38.3 steps/s
[Step=4000 Epoch=19.5] | Loss=0.03971 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.663 | L2-Norm(final)=3.003 | 4423.7 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step4000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 9.8] | Loss=0.10182 | Reg=0.00330 | acc=0.9062 | L2-Norm=18.164 | L2-Norm(final)=2.798 | 5464.4 samples/s | 85.4 steps/s
[Step=2050 Epoch=10.0] | Loss=0.13528 | Reg=0.00330 | acc=0.8750 | L2-Norm=18.179 | L2-Norm(final)=2.774 | 4646.1 samples/s | 72.6 steps/s
[Step=2100 Epoch=10.2] | Loss=0.12872 | Reg=0.00331 | acc=0.8438 | L2-Norm=18.206 | L2-Norm(final)=2.774 | 5024.1 samples/s | 78.5 steps/s
[Step=2150 Epoch=10.5] | Loss=0.12979 | Reg=0.00332 | acc=0.8750 | L2-Norm=18.229 | L2-Norm(final)=2.778 | 5105.3 samples/s | 79.8 steps/s
[Step=2200 Epoch=10.7] | Loss=0.12756 | Reg=0.00333 | acc=0.9531 | L2-Norm=18.261 | L2-Norm(final)=2.783 | 7822.6 samples/s | 122.2 steps/s
[Step=2250 Epoch=11.0] | Loss=0.12443 | Reg=0.00335 | acc=0.8750 | L2-Norm=18.291 | L2-Norm(final)=2.791 | 2208.9 samples/s | 34.5 steps/s
[Step=2300 Epoch=11.2] | Loss=0.12289 | Reg=0.00336 | acc=0.8438 | L2-Norm=18.322 | L2-Norm(final)=2.802 | 5049.1 samples/s | 78.9 steps/s
[Step=2350 Epoch=11.5] | Loss=0.12174 | Reg=0.00337 | acc=0.8438 | L2-Norm=18.355 | L2-Norm(final)=2.813 | 5058.1 samples/s | 79.0 steps/s
[Step=2400 Epoch=11.7] | Loss=0.12005 | Reg=0.00338 | acc=0.8906 | L2-Norm=18.389 | L2-Norm(final)=2.826 | 6894.4 samples/s | 107.7 steps/s
[Step=2450 Epoch=12.0] | Loss=0.11765 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.422 | L2-Norm(final)=2.841 | 2293.3 samples/s | 35.8 steps/s
[Step=2500 Epoch=12.2] | Loss=0.11679 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.456 | L2-Norm(final)=2.857 | 4964.5 samples/s | 77.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=12.2] | Loss=0.16983 | Reg=0.00354 | acc=0.9219 | L2-Norm=18.806 | L2-Norm(final)=3.017 | 5438.1 samples/s | 85.0 steps/s
[Step=2550 Epoch=12.4] | Loss=0.12935 | Reg=0.00355 | acc=0.8906 | L2-Norm=18.850 | L2-Norm(final)=3.017 | 4184.8 samples/s | 65.4 steps/s
[Step=2600 Epoch=12.7] | Loss=0.12131 | Reg=0.00357 | acc=0.9375 | L2-Norm=18.898 | L2-Norm(final)=3.016 | 4528.7 samples/s | 70.8 steps/s
[Step=2650 Epoch=12.9] | Loss=0.11569 | Reg=0.00359 | acc=0.8906 | L2-Norm=18.938 | L2-Norm(final)=3.014 | 4446.8 samples/s | 69.5 steps/s
[Step=2700 Epoch=13.2] | Loss=0.11017 | Reg=0.00360 | acc=0.9062 | L2-Norm=18.966 | L2-Norm(final)=3.014 | 6459.4 samples/s | 100.9 steps/s
[Step=2750 Epoch=13.4] | Loss=0.09892 | Reg=0.00361 | acc=0.9688 | L2-Norm=18.990 | L2-Norm(final)=3.014 | 2084.0 samples/s | 32.6 steps/s
[Step=2800 Epoch=13.7] | Loss=0.09330 | Reg=0.00362 | acc=0.9531 | L2-Norm=19.014 | L2-Norm(final)=3.017 | 4515.0 samples/s | 70.5 steps/s
[Step=2850 Epoch=13.9] | Loss=0.08767 | Reg=0.00362 | acc=0.9062 | L2-Norm=19.037 | L2-Norm(final)=3.021 | 4356.5 samples/s | 68.1 steps/s
[Step=2900 Epoch=14.2] | Loss=0.08321 | Reg=0.00363 | acc=0.9375 | L2-Norm=19.061 | L2-Norm(final)=3.025 | 6030.4 samples/s | 94.2 steps/s
[Step=2950 Epoch=14.4] | Loss=0.07881 | Reg=0.00364 | acc=0.9688 | L2-Norm=19.085 | L2-Norm(final)=3.031 | 2173.6 samples/s | 34.0 steps/s
[Step=3000 Epoch=14.6] | Loss=0.07448 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.108 | L2-Norm(final)=3.037 | 4480.5 samples/s | 70.0 steps/s
[Step=3050 Epoch=14.9] | Loss=0.07208 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.129 | L2-Norm(final)=3.041 | 4403.3 samples/s | 68.8 steps/s
[Step=3100 Epoch=15.1] | Loss=0.06987 | Reg=0.00367 | acc=0.9219 | L2-Norm=19.151 | L2-Norm(final)=3.046 | 5472.5 samples/s | 85.5 steps/s
[Step=3150 Epoch=15.4] | Loss=0.06678 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.173 | L2-Norm(final)=3.050 | 2239.4 samples/s | 35.0 steps/s
[Step=3200 Epoch=15.6] | Loss=0.06440 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.192 | L2-Norm(final)=3.054 | 4540.8 samples/s | 70.9 steps/s
[Step=3250 Epoch=15.9] | Loss=0.06159 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.209 | L2-Norm(final)=3.057 | 4481.7 samples/s | 70.0 steps/s
[Step=3300 Epoch=16.1] | Loss=0.05929 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.223 | L2-Norm(final)=3.061 | 5137.6 samples/s | 80.3 steps/s
[Step=3350 Epoch=16.3] | Loss=0.05702 | Reg=0.00370 | acc=0.9688 | L2-Norm=19.236 | L2-Norm(final)=3.065 | 2293.0 samples/s | 35.8 steps/s
[Step=3400 Epoch=16.6] | Loss=0.05517 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.247 | L2-Norm(final)=3.068 | 4380.0 samples/s | 68.4 steps/s
[Step=3450 Epoch=16.8] | Loss=0.05328 | Reg=0.00371 | acc=0.9844 | L2-Norm=19.258 | L2-Norm(final)=3.072 | 4556.8 samples/s | 71.2 steps/s
[Step=3500 Epoch=17.1] | Loss=0.05188 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.269 | L2-Norm(final)=3.076 | 4818.1 samples/s | 75.3 steps/s
[Step=3550 Epoch=17.3] | Loss=0.05043 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.279 | L2-Norm(final)=3.080 | 2341.4 samples/s | 36.6 steps/s
[Step=3600 Epoch=17.6] | Loss=0.04909 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.289 | L2-Norm(final)=3.083 | 4545.4 samples/s | 71.0 steps/s
[Step=3650 Epoch=17.8] | Loss=0.04794 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.298 | L2-Norm(final)=3.087 | 4543.7 samples/s | 71.0 steps/s
[Step=3700 Epoch=18.1] | Loss=0.04681 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.306 | L2-Norm(final)=3.090 | 4473.0 samples/s | 69.9 steps/s
[Step=3750 Epoch=18.3] | Loss=0.04573 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.315 | L2-Norm(final)=3.093 | 2430.5 samples/s | 38.0 steps/s
[Step=3800 Epoch=18.5] | Loss=0.04473 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.323 | L2-Norm(final)=3.097 | 4493.3 samples/s | 70.2 steps/s
[Step=3850 Epoch=18.8] | Loss=0.04366 | Reg=0.00374 | acc=0.9688 | L2-Norm=19.330 | L2-Norm(final)=3.100 | 4519.6 samples/s | 70.6 steps/s
[Step=3900 Epoch=19.0] | Loss=0.04258 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.337 | L2-Norm(final)=3.104 | 4440.5 samples/s | 69.4 steps/s
[Step=3950 Epoch=19.3] | Loss=0.04191 | Reg=0.00374 | acc=0.9688 | L2-Norm=19.344 | L2-Norm(final)=3.107 | 2472.6 samples/s | 38.6 steps/s
[Step=4000 Epoch=19.5] | Loss=0.04112 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.350 | L2-Norm(final)=3.110 | 4469.8 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step4000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 9.7] | Loss=0.29865 | Reg=0.00328 | acc=0.7656 | L2-Norm=18.118 | L2-Norm(final)=2.551 | 5128.5 samples/s | 80.1 steps/s
[Step=2050 Epoch=10.0] | Loss=0.14710 | Reg=0.00328 | acc=0.8594 | L2-Norm=18.118 | L2-Norm(final)=2.527 | 4432.4 samples/s | 69.3 steps/s
[Step=2100 Epoch=10.2] | Loss=0.14442 | Reg=0.00329 | acc=0.8750 | L2-Norm=18.149 | L2-Norm(final)=2.534 | 5213.9 samples/s | 81.5 steps/s
[Step=2150 Epoch=10.5] | Loss=0.13774 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.184 | L2-Norm(final)=2.546 | 4918.3 samples/s | 76.8 steps/s
[Step=2200 Epoch=10.7] | Loss=0.13436 | Reg=0.00332 | acc=0.9219 | L2-Norm=18.218 | L2-Norm(final)=2.560 | 7838.0 samples/s | 122.5 steps/s
[Step=2250 Epoch=11.0] | Loss=0.13253 | Reg=0.00333 | acc=0.9375 | L2-Norm=18.256 | L2-Norm(final)=2.578 | 2258.8 samples/s | 35.3 steps/s
[Step=2300 Epoch=11.2] | Loss=0.13156 | Reg=0.00335 | acc=0.9062 | L2-Norm=18.298 | L2-Norm(final)=2.596 | 5015.0 samples/s | 78.4 steps/s
[Step=2350 Epoch=11.5] | Loss=0.12896 | Reg=0.00336 | acc=0.9062 | L2-Norm=18.342 | L2-Norm(final)=2.615 | 4991.6 samples/s | 78.0 steps/s
[Step=2400 Epoch=11.7] | Loss=0.12797 | Reg=0.00338 | acc=0.9375 | L2-Norm=18.385 | L2-Norm(final)=2.634 | 7010.8 samples/s | 109.5 steps/s
[Step=2450 Epoch=11.9] | Loss=0.12699 | Reg=0.00340 | acc=0.9219 | L2-Norm=18.429 | L2-Norm(final)=2.654 | 2306.5 samples/s | 36.0 steps/s
[Step=2500 Epoch=12.2] | Loss=0.12590 | Reg=0.00341 | acc=0.9062 | L2-Norm=18.475 | L2-Norm(final)=2.675 | 5062.4 samples/s | 79.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=12.2] | Loss=0.13165 | Reg=0.00358 | acc=0.8750 | L2-Norm=18.932 | L2-Norm(final)=2.880 | 5330.3 samples/s | 83.3 steps/s
[Step=2550 Epoch=12.4] | Loss=0.13226 | Reg=0.00360 | acc=0.8750 | L2-Norm=18.986 | L2-Norm(final)=2.892 | 4102.7 samples/s | 64.1 steps/s
[Step=2600 Epoch=12.7] | Loss=0.12859 | Reg=0.00362 | acc=0.9062 | L2-Norm=19.032 | L2-Norm(final)=2.895 | 4419.5 samples/s | 69.1 steps/s
[Step=2650 Epoch=12.9] | Loss=0.12190 | Reg=0.00364 | acc=0.8750 | L2-Norm=19.066 | L2-Norm(final)=2.895 | 4508.8 samples/s | 70.4 steps/s
[Step=2700 Epoch=13.2] | Loss=0.11327 | Reg=0.00364 | acc=0.9375 | L2-Norm=19.089 | L2-Norm(final)=2.896 | 6576.1 samples/s | 102.8 steps/s
[Step=2750 Epoch=13.4] | Loss=0.10408 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.112 | L2-Norm(final)=2.898 | 2100.2 samples/s | 32.8 steps/s
[Step=2800 Epoch=13.6] | Loss=0.09742 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.135 | L2-Norm(final)=2.902 | 4416.6 samples/s | 69.0 steps/s
[Step=2850 Epoch=13.9] | Loss=0.09191 | Reg=0.00367 | acc=0.9688 | L2-Norm=19.156 | L2-Norm(final)=2.906 | 4500.0 samples/s | 70.3 steps/s
[Step=2900 Epoch=14.1] | Loss=0.08744 | Reg=0.00368 | acc=0.9375 | L2-Norm=19.175 | L2-Norm(final)=2.910 | 5905.7 samples/s | 92.3 steps/s
[Step=2950 Epoch=14.4] | Loss=0.08233 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.195 | L2-Norm(final)=2.916 | 2189.8 samples/s | 34.2 steps/s
[Step=3000 Epoch=14.6] | Loss=0.07850 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.214 | L2-Norm(final)=2.922 | 4531.3 samples/s | 70.8 steps/s
[Step=3050 Epoch=14.9] | Loss=0.07456 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.232 | L2-Norm(final)=2.928 | 4431.9 samples/s | 69.2 steps/s
[Step=3100 Epoch=15.1] | Loss=0.07171 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.248 | L2-Norm(final)=2.933 | 5442.5 samples/s | 85.0 steps/s
[Step=3150 Epoch=15.3] | Loss=0.06856 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.263 | L2-Norm(final)=2.939 | 2242.0 samples/s | 35.0 steps/s
[Step=3200 Epoch=15.6] | Loss=0.06597 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.277 | L2-Norm(final)=2.945 | 4582.3 samples/s | 71.6 steps/s
[Step=3250 Epoch=15.8] | Loss=0.06344 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.291 | L2-Norm(final)=2.950 | 4446.6 samples/s | 69.5 steps/s
[Step=3300 Epoch=16.1] | Loss=0.06119 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.303 | L2-Norm(final)=2.956 | 4877.1 samples/s | 76.2 steps/s
[Step=3350 Epoch=16.3] | Loss=0.05916 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.314 | L2-Norm(final)=2.961 | 2321.7 samples/s | 36.3 steps/s
[Step=3400 Epoch=16.6] | Loss=0.05692 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.325 | L2-Norm(final)=2.967 | 4460.8 samples/s | 69.7 steps/s
[Step=3450 Epoch=16.8] | Loss=0.05519 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.334 | L2-Norm(final)=2.973 | 4512.4 samples/s | 70.5 steps/s
[Step=3500 Epoch=17.1] | Loss=0.05396 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.343 | L2-Norm(final)=2.978 | 4496.9 samples/s | 70.3 steps/s
[Step=3550 Epoch=17.3] | Loss=0.05237 | Reg=0.00374 | acc=0.9688 | L2-Norm=19.351 | L2-Norm(final)=2.983 | 2458.6 samples/s | 38.4 steps/s
[Step=3600 Epoch=17.5] | Loss=0.05123 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.359 | L2-Norm(final)=2.988 | 4475.6 samples/s | 69.9 steps/s
[Step=3650 Epoch=17.8] | Loss=0.04984 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.368 | L2-Norm(final)=2.993 | 4496.7 samples/s | 70.3 steps/s
[Step=3700 Epoch=18.0] | Loss=0.04884 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.376 | L2-Norm(final)=2.998 | 4511.2 samples/s | 70.5 steps/s
[Step=3750 Epoch=18.3] | Loss=0.04793 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.385 | L2-Norm(final)=3.002 | 2454.4 samples/s | 38.4 steps/s
[Step=3800 Epoch=18.5] | Loss=0.04706 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.394 | L2-Norm(final)=3.006 | 4510.6 samples/s | 70.5 steps/s
[Step=3850 Epoch=18.8] | Loss=0.04611 | Reg=0.00376 | acc=0.9688 | L2-Norm=19.402 | L2-Norm(final)=3.010 | 4374.4 samples/s | 68.4 steps/s
[Step=3900 Epoch=19.0] | Loss=0.04556 | Reg=0.00377 | acc=0.9688 | L2-Norm=19.411 | L2-Norm(final)=3.014 | 4474.9 samples/s | 69.9 steps/s
[Step=3950 Epoch=19.2] | Loss=0.04451 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.419 | L2-Norm(final)=3.017 | 2491.1 samples/s | 38.9 steps/s
[Step=4000 Epoch=19.5] | Loss=0.04376 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.427 | L2-Norm(final)=3.020 | 4525.3 samples/s | 70.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step4000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 9.8] | Loss=0.14405 | Reg=0.00328 | acc=0.8906 | L2-Norm=18.113 | L2-Norm(final)=2.716 | 5233.8 samples/s | 81.8 steps/s
[Step=2050 Epoch=10.0] | Loss=0.14134 | Reg=0.00328 | acc=0.8906 | L2-Norm=18.113 | L2-Norm(final)=2.701 | 4393.5 samples/s | 68.6 steps/s
[Step=2100 Epoch=10.2] | Loss=0.13556 | Reg=0.00329 | acc=0.8906 | L2-Norm=18.125 | L2-Norm(final)=2.704 | 5122.3 samples/s | 80.0 steps/s
[Step=2150 Epoch=10.5] | Loss=0.13063 | Reg=0.00329 | acc=0.8125 | L2-Norm=18.145 | L2-Norm(final)=2.718 | 4848.6 samples/s | 75.8 steps/s
[Step=2200 Epoch=10.7] | Loss=0.12568 | Reg=0.00330 | acc=0.9219 | L2-Norm=18.166 | L2-Norm(final)=2.734 | 7785.6 samples/s | 121.6 steps/s
[Step=2250 Epoch=11.0] | Loss=0.12322 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.192 | L2-Norm(final)=2.750 | 2240.7 samples/s | 35.0 steps/s
[Step=2300 Epoch=11.2] | Loss=0.12106 | Reg=0.00332 | acc=0.8750 | L2-Norm=18.222 | L2-Norm(final)=2.767 | 5194.4 samples/s | 81.2 steps/s
[Step=2350 Epoch=11.5] | Loss=0.11949 | Reg=0.00333 | acc=0.8750 | L2-Norm=18.249 | L2-Norm(final)=2.784 | 5185.8 samples/s | 81.0 steps/s
[Step=2400 Epoch=11.7] | Loss=0.11828 | Reg=0.00334 | acc=0.9375 | L2-Norm=18.278 | L2-Norm(final)=2.802 | 6598.2 samples/s | 103.1 steps/s
[Step=2450 Epoch=11.9] | Loss=0.11666 | Reg=0.00335 | acc=0.9062 | L2-Norm=18.308 | L2-Norm(final)=2.819 | 2307.7 samples/s | 36.1 steps/s
[Step=2500 Epoch=12.2] | Loss=0.11604 | Reg=0.00336 | acc=0.9375 | L2-Norm=18.340 | L2-Norm(final)=2.837 | 5067.4 samples/s | 79.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=12.2] | Loss=0.06904 | Reg=0.00349 | acc=0.9531 | L2-Norm=18.674 | L2-Norm(final)=3.019 | 5203.0 samples/s | 81.3 steps/s
[Step=2550 Epoch=12.4] | Loss=0.11891 | Reg=0.00351 | acc=0.8750 | L2-Norm=18.722 | L2-Norm(final)=3.032 | 4185.1 samples/s | 65.4 steps/s
[Step=2600 Epoch=12.7] | Loss=0.11619 | Reg=0.00352 | acc=0.9062 | L2-Norm=18.761 | L2-Norm(final)=3.029 | 4426.9 samples/s | 69.2 steps/s
[Step=2650 Epoch=12.9] | Loss=0.11088 | Reg=0.00353 | acc=0.9375 | L2-Norm=18.798 | L2-Norm(final)=3.027 | 4540.1 samples/s | 70.9 steps/s
[Step=2700 Epoch=13.2] | Loss=0.10637 | Reg=0.00355 | acc=0.9062 | L2-Norm=18.832 | L2-Norm(final)=3.028 | 6498.8 samples/s | 101.5 steps/s
[Step=2750 Epoch=13.4] | Loss=0.09934 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.868 | L2-Norm(final)=3.030 | 2097.1 samples/s | 32.8 steps/s
[Step=2800 Epoch=13.7] | Loss=0.09311 | Reg=0.00357 | acc=0.9375 | L2-Norm=18.900 | L2-Norm(final)=3.033 | 4540.4 samples/s | 70.9 steps/s
[Step=2850 Epoch=13.9] | Loss=0.08833 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.927 | L2-Norm(final)=3.037 | 4398.8 samples/s | 68.7 steps/s
[Step=2900 Epoch=14.1] | Loss=0.08344 | Reg=0.00359 | acc=0.9375 | L2-Norm=18.952 | L2-Norm(final)=3.041 | 5853.7 samples/s | 91.5 steps/s
[Step=2950 Epoch=14.4] | Loss=0.07848 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.975 | L2-Norm(final)=3.046 | 2202.2 samples/s | 34.4 steps/s
[Step=3000 Epoch=14.6] | Loss=0.07390 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.997 | L2-Norm(final)=3.051 | 4557.1 samples/s | 71.2 steps/s
[Step=3050 Epoch=14.9] | Loss=0.07023 | Reg=0.00362 | acc=0.9688 | L2-Norm=19.017 | L2-Norm(final)=3.057 | 4339.1 samples/s | 67.8 steps/s
[Step=3100 Epoch=15.1] | Loss=0.06753 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.035 | L2-Norm(final)=3.062 | 5443.5 samples/s | 85.1 steps/s
[Step=3150 Epoch=15.4] | Loss=0.06446 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.053 | L2-Norm(final)=3.066 | 2254.3 samples/s | 35.2 steps/s
[Step=3200 Epoch=15.6] | Loss=0.06132 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.070 | L2-Norm(final)=3.072 | 4414.7 samples/s | 69.0 steps/s
[Step=3250 Epoch=15.8] | Loss=0.05883 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.085 | L2-Norm(final)=3.076 | 4421.1 samples/s | 69.1 steps/s
[Step=3300 Epoch=16.1] | Loss=0.05692 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.099 | L2-Norm(final)=3.081 | 4971.4 samples/s | 77.7 steps/s
[Step=3350 Epoch=16.3] | Loss=0.05515 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.112 | L2-Norm(final)=3.085 | 2374.3 samples/s | 37.1 steps/s
[Step=3400 Epoch=16.6] | Loss=0.05367 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.125 | L2-Norm(final)=3.089 | 4469.6 samples/s | 69.8 steps/s
[Step=3450 Epoch=16.8] | Loss=0.05271 | Reg=0.00366 | acc=0.9531 | L2-Norm=19.138 | L2-Norm(final)=3.092 | 4476.3 samples/s | 69.9 steps/s
[Step=3500 Epoch=17.1] | Loss=0.05163 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.152 | L2-Norm(final)=3.095 | 4661.7 samples/s | 72.8 steps/s
[Step=3550 Epoch=17.3] | Loss=0.05014 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.166 | L2-Norm(final)=3.098 | 2420.3 samples/s | 37.8 steps/s
[Step=3600 Epoch=17.6] | Loss=0.04895 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.178 | L2-Norm(final)=3.101 | 4432.9 samples/s | 69.3 steps/s
[Step=3650 Epoch=17.8] | Loss=0.04796 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.189 | L2-Norm(final)=3.104 | 4494.9 samples/s | 70.2 steps/s
[Step=3700 Epoch=18.0] | Loss=0.04688 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.200 | L2-Norm(final)=3.106 | 4469.7 samples/s | 69.8 steps/s
[Step=3750 Epoch=18.3] | Loss=0.04594 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.212 | L2-Norm(final)=3.109 | 2476.6 samples/s | 38.7 steps/s
[Step=3800 Epoch=18.5] | Loss=0.04482 | Reg=0.00370 | acc=0.9688 | L2-Norm=19.223 | L2-Norm(final)=3.112 | 4454.6 samples/s | 69.6 steps/s
[Step=3850 Epoch=18.8] | Loss=0.04369 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.233 | L2-Norm(final)=3.114 | 4495.5 samples/s | 70.2 steps/s
[Step=3900 Epoch=19.0] | Loss=0.04278 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.243 | L2-Norm(final)=3.117 | 4458.1 samples/s | 69.7 steps/s
[Step=3950 Epoch=19.3] | Loss=0.04197 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.252 | L2-Norm(final)=3.120 | 2386.0 samples/s | 37.3 steps/s
[Step=4000 Epoch=19.5] | Loss=0.04110 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.260 | L2-Norm(final)=3.122 | 4499.7 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step4000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 9.8] | Loss=0.22063 | Reg=0.00328 | acc=0.8438 | L2-Norm=18.118 | L2-Norm(final)=2.760 | 5766.6 samples/s | 90.1 steps/s
[Step=2050 Epoch=10.1] | Loss=0.12417 | Reg=0.00329 | acc=0.9219 | L2-Norm=18.132 | L2-Norm(final)=2.736 | 4251.7 samples/s | 66.4 steps/s
[Step=2100 Epoch=10.3] | Loss=0.12259 | Reg=0.00330 | acc=0.8750 | L2-Norm=18.164 | L2-Norm(final)=2.743 | 5071.7 samples/s | 79.2 steps/s
[Step=2150 Epoch=10.5] | Loss=0.11984 | Reg=0.00331 | acc=0.9062 | L2-Norm=18.195 | L2-Norm(final)=2.755 | 5094.1 samples/s | 79.6 steps/s
[Step=2200 Epoch=10.8] | Loss=0.12184 | Reg=0.00332 | acc=0.8906 | L2-Norm=18.223 | L2-Norm(final)=2.767 | 8062.6 samples/s | 126.0 steps/s
[Step=2250 Epoch=11.0] | Loss=0.11849 | Reg=0.00333 | acc=0.9531 | L2-Norm=18.251 | L2-Norm(final)=2.780 | 2182.8 samples/s | 34.1 steps/s
[Step=2300 Epoch=11.3] | Loss=0.11701 | Reg=0.00334 | acc=0.8750 | L2-Norm=18.282 | L2-Norm(final)=2.796 | 5029.9 samples/s | 78.6 steps/s
[Step=2350 Epoch=11.5] | Loss=0.11633 | Reg=0.00335 | acc=0.9062 | L2-Norm=18.312 | L2-Norm(final)=2.814 | 5067.5 samples/s | 79.2 steps/s
[Step=2400 Epoch=11.8] | Loss=0.11522 | Reg=0.00337 | acc=0.8438 | L2-Norm=18.345 | L2-Norm(final)=2.832 | 7517.7 samples/s | 117.5 steps/s
[Step=2450 Epoch=12.0] | Loss=0.11370 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.383 | L2-Norm(final)=2.851 | 2245.1 samples/s | 35.1 steps/s
[Step=2500 Epoch=12.3] | Loss=0.11126 | Reg=0.00339 | acc=0.8750 | L2-Norm=18.422 | L2-Norm(final)=2.873 | 5060.3 samples/s | 79.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=12.3] | Loss=0.11251 | Reg=0.00354 | acc=0.9062 | L2-Norm=18.824 | L2-Norm(final)=3.097 | 5604.5 samples/s | 87.6 steps/s
[Step=2550 Epoch=12.5] | Loss=0.11915 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.888 | L2-Norm(final)=3.114 | 3925.5 samples/s | 61.3 steps/s
[Step=2600 Epoch=12.7] | Loss=0.11635 | Reg=0.00359 | acc=0.8906 | L2-Norm=18.941 | L2-Norm(final)=3.110 | 4409.3 samples/s | 68.9 steps/s
[Step=2650 Epoch=13.0] | Loss=0.10814 | Reg=0.00360 | acc=0.9375 | L2-Norm=18.979 | L2-Norm(final)=3.108 | 4472.1 samples/s | 69.9 steps/s
[Step=2700 Epoch=13.2] | Loss=0.10330 | Reg=0.00361 | acc=0.9688 | L2-Norm=19.009 | L2-Norm(final)=3.107 | 6692.7 samples/s | 104.6 steps/s
[Step=2750 Epoch=13.5] | Loss=0.09403 | Reg=0.00362 | acc=0.9531 | L2-Norm=19.036 | L2-Norm(final)=3.108 | 2072.5 samples/s | 32.4 steps/s
[Step=2800 Epoch=13.7] | Loss=0.08750 | Reg=0.00363 | acc=0.8906 | L2-Norm=19.061 | L2-Norm(final)=3.112 | 4486.1 samples/s | 70.1 steps/s
[Step=2850 Epoch=14.0] | Loss=0.08220 | Reg=0.00364 | acc=0.9688 | L2-Norm=19.084 | L2-Norm(final)=3.116 | 4502.1 samples/s | 70.3 steps/s
[Step=2900 Epoch=14.2] | Loss=0.07757 | Reg=0.00365 | acc=0.9375 | L2-Norm=19.106 | L2-Norm(final)=3.122 | 6266.1 samples/s | 97.9 steps/s
[Step=2950 Epoch=14.5] | Loss=0.07339 | Reg=0.00366 | acc=0.9531 | L2-Norm=19.126 | L2-Norm(final)=3.127 | 2146.0 samples/s | 33.5 steps/s
[Step=3000 Epoch=14.7] | Loss=0.06936 | Reg=0.00367 | acc=0.9375 | L2-Norm=19.145 | L2-Norm(final)=3.133 | 4358.4 samples/s | 68.1 steps/s
[Step=3050 Epoch=15.0] | Loss=0.06688 | Reg=0.00367 | acc=0.8438 | L2-Norm=19.163 | L2-Norm(final)=3.139 | 4490.5 samples/s | 70.2 steps/s
[Step=3100 Epoch=15.2] | Loss=0.06460 | Reg=0.00368 | acc=0.9375 | L2-Norm=19.180 | L2-Norm(final)=3.143 | 5854.1 samples/s | 91.5 steps/s
[Step=3150 Epoch=15.4] | Loss=0.06168 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.196 | L2-Norm(final)=3.147 | 2168.8 samples/s | 33.9 steps/s
[Step=3200 Epoch=15.7] | Loss=0.05910 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.210 | L2-Norm(final)=3.151 | 4527.6 samples/s | 70.7 steps/s
[Step=3250 Epoch=15.9] | Loss=0.05702 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.224 | L2-Norm(final)=3.156 | 4460.5 samples/s | 69.7 steps/s
[Step=3300 Epoch=16.2] | Loss=0.05487 | Reg=0.00370 | acc=0.9688 | L2-Norm=19.237 | L2-Norm(final)=3.160 | 5523.0 samples/s | 86.3 steps/s
[Step=3350 Epoch=16.4] | Loss=0.05270 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.248 | L2-Norm(final)=3.164 | 2165.8 samples/s | 33.8 steps/s
[Step=3400 Epoch=16.7] | Loss=0.05093 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.259 | L2-Norm(final)=3.169 | 4470.8 samples/s | 69.9 steps/s
[Step=3450 Epoch=16.9] | Loss=0.04954 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.270 | L2-Norm(final)=3.173 | 4497.9 samples/s | 70.3 steps/s
[Step=3500 Epoch=17.2] | Loss=0.04839 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.280 | L2-Norm(final)=3.177 | 5214.6 samples/s | 81.5 steps/s
[Step=3550 Epoch=17.4] | Loss=0.04705 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.290 | L2-Norm(final)=3.181 | 2291.5 samples/s | 35.8 steps/s
[Step=3600 Epoch=17.7] | Loss=0.04576 | Reg=0.00373 | acc=0.9531 | L2-Norm=19.300 | L2-Norm(final)=3.185 | 4482.9 samples/s | 70.0 steps/s
[Step=3650 Epoch=17.9] | Loss=0.04505 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.309 | L2-Norm(final)=3.188 | 4443.2 samples/s | 69.4 steps/s
[Step=3700 Epoch=18.1] | Loss=0.04430 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.320 | L2-Norm(final)=3.192 | 4884.5 samples/s | 76.3 steps/s
[Step=3750 Epoch=18.4] | Loss=0.04317 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.330 | L2-Norm(final)=3.195 | 2325.4 samples/s | 36.3 steps/s
[Step=3800 Epoch=18.6] | Loss=0.04207 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.340 | L2-Norm(final)=3.198 | 4518.3 samples/s | 70.6 steps/s
[Step=3850 Epoch=18.9] | Loss=0.04123 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.348 | L2-Norm(final)=3.201 | 4543.0 samples/s | 71.0 steps/s
[Step=3900 Epoch=19.1] | Loss=0.04026 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.356 | L2-Norm(final)=3.204 | 4587.8 samples/s | 71.7 steps/s
[Step=3950 Epoch=19.4] | Loss=0.03925 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.363 | L2-Norm(final)=3.208 | 2400.5 samples/s | 37.5 steps/s
[Step=4000 Epoch=19.6] | Loss=0.03835 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.369 | L2-Norm(final)=3.211 | 4375.6 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step4000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch=19.0] | Loss=0.05468 | Reg=0.00176 | acc=0.9531 | L2-Norm=13.249 | L2-Norm(final)=2.442 | 4987.1 samples/s | 77.9 steps/s
[Step=2050 Epoch=19.4] | Loss=0.04710 | Reg=0.00176 | acc=0.9531 | L2-Norm=13.267 | L2-Norm(final)=2.444 | 2742.4 samples/s | 42.8 steps/s
[Step=2100 Epoch=19.9] | Loss=0.04217 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.326 | L2-Norm(final)=2.458 | 7463.6 samples/s | 116.6 steps/s
[Step=2150 Epoch=20.4] | Loss=0.03826 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.383 | L2-Norm(final)=2.475 | 2132.7 samples/s | 33.3 steps/s
[Step=2200 Epoch=20.8] | Loss=0.03620 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.439 | L2-Norm(final)=2.493 | 6529.3 samples/s | 102.0 steps/s
[Step=2250 Epoch=21.3] | Loss=0.03464 | Reg=0.00182 | acc=0.9844 | L2-Norm=13.495 | L2-Norm(final)=2.512 | 2200.0 samples/s | 34.4 steps/s
[Step=2300 Epoch=21.8] | Loss=0.03219 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.547 | L2-Norm(final)=2.530 | 5841.7 samples/s | 91.3 steps/s
[Step=2350 Epoch=22.3] | Loss=0.03113 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.597 | L2-Norm(final)=2.549 | 2305.5 samples/s | 36.0 steps/s
[Step=2400 Epoch=22.7] | Loss=0.02963 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.644 | L2-Norm(final)=2.568 | 5340.7 samples/s | 83.4 steps/s
[Step=2450 Epoch=23.2] | Loss=0.02824 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.688 | L2-Norm(final)=2.587 | 2445.8 samples/s | 38.2 steps/s
[Step=2500 Epoch=23.7] | Loss=0.02719 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.731 | L2-Norm(final)=2.606 | 4824.8 samples/s | 75.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=23.7] | Loss=0.01397 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.150 | L2-Norm(final)=2.794 | 5462.9 samples/s | 85.4 steps/s
[Step=2550 Epoch=24.2] | Loss=0.06403 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.292 | L2-Norm(final)=2.770 | 3683.4 samples/s | 57.6 steps/s
[Step=2600 Epoch=24.6] | Loss=0.03507 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.360 | L2-Norm(final)=2.770 | 6131.5 samples/s | 95.8 steps/s
[Step=2650 Epoch=25.1] | Loss=0.02402 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.389 | L2-Norm(final)=2.773 | 2018.8 samples/s | 31.5 steps/s
[Step=2700 Epoch=25.6] | Loss=0.01836 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.400 | L2-Norm(final)=2.777 | 5666.5 samples/s | 88.5 steps/s
[Step=2750 Epoch=26.1] | Loss=0.01475 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.404 | L2-Norm(final)=2.780 | 2092.7 samples/s | 32.7 steps/s
[Step=2800 Epoch=26.5] | Loss=0.01231 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.402 | L2-Norm(final)=2.782 | 5150.5 samples/s | 80.5 steps/s
[Step=2850 Epoch=27.0] | Loss=0.01057 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.397 | L2-Norm(final)=2.784 | 2172.7 samples/s | 33.9 steps/s
[Step=2900 Epoch=27.5] | Loss=0.00926 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.391 | L2-Norm(final)=2.785 | 4723.2 samples/s | 73.8 steps/s
[Step=2950 Epoch=28.0] | Loss=0.00823 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.382 | L2-Norm(final)=2.787 | 2269.5 samples/s | 35.5 steps/s
[Step=3000 Epoch=28.4] | Loss=0.00742 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.373 | L2-Norm(final)=2.788 | 4359.1 samples/s | 68.1 steps/s
[Step=3050 Epoch=28.9] | Loss=0.00674 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.364 | L2-Norm(final)=2.790 | 2359.8 samples/s | 36.9 steps/s
[Step=3100 Epoch=29.4] | Loss=0.00619 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.354 | L2-Norm(final)=2.791 | 4244.6 samples/s | 66.3 steps/s
[Step=3150 Epoch=29.8] | Loss=0.00571 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.343 | L2-Norm(final)=2.793 | 2412.8 samples/s | 37.7 steps/s
[Step=3200 Epoch=30.3] | Loss=0.00531 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.333 | L2-Norm(final)=2.796 | 4059.3 samples/s | 63.4 steps/s
[Step=3250 Epoch=30.8] | Loss=0.00495 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.321 | L2-Norm(final)=2.798 | 2425.9 samples/s | 37.9 steps/s
[Step=3300 Epoch=31.3] | Loss=0.00465 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.310 | L2-Norm(final)=2.800 | 4296.3 samples/s | 67.1 steps/s
[Step=3350 Epoch=31.7] | Loss=0.00437 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.298 | L2-Norm(final)=2.802 | 2502.3 samples/s | 39.1 steps/s
[Step=3400 Epoch=32.2] | Loss=0.00413 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.286 | L2-Norm(final)=2.805 | 3868.1 samples/s | 60.4 steps/s
[Step=3450 Epoch=32.7] | Loss=0.00391 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.274 | L2-Norm(final)=2.807 | 6482.1 samples/s | 101.3 steps/s
[Step=3500 Epoch=33.2] | Loss=0.00372 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.261 | L2-Norm(final)=2.809 | 2000.8 samples/s | 31.3 steps/s
[Step=3550 Epoch=33.6] | Loss=0.00354 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.249 | L2-Norm(final)=2.812 | 5726.6 samples/s | 89.5 steps/s
[Step=3600 Epoch=34.1] | Loss=0.00338 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.236 | L2-Norm(final)=2.814 | 2094.8 samples/s | 32.7 steps/s
[Step=3650 Epoch=34.6] | Loss=0.00324 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.223 | L2-Norm(final)=2.816 | 5168.5 samples/s | 80.8 steps/s
[Step=3700 Epoch=35.1] | Loss=0.00310 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.210 | L2-Norm(final)=2.818 | 2156.2 samples/s | 33.7 steps/s
[Step=3750 Epoch=35.5] | Loss=0.00298 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.197 | L2-Norm(final)=2.821 | 4663.3 samples/s | 72.9 steps/s
[Step=3800 Epoch=36.0] | Loss=0.00286 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.184 | L2-Norm(final)=2.823 | 2222.8 samples/s | 34.7 steps/s
[Step=3850 Epoch=36.5] | Loss=0.00276 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.170 | L2-Norm(final)=2.825 | 4482.1 samples/s | 70.0 steps/s
[Step=3900 Epoch=37.0] | Loss=0.00266 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.157 | L2-Norm(final)=2.827 | 2331.2 samples/s | 36.4 steps/s
[Step=3950 Epoch=37.4] | Loss=0.00257 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.143 | L2-Norm(final)=2.830 | 4285.4 samples/s | 67.0 steps/s
[Step=4000 Epoch=37.9] | Loss=0.00248 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.129 | L2-Norm(final)=2.832 | 2368.7 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step4000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch=19.0] | Loss=0.08445 | Reg=0.00168 | acc=0.9219 | L2-Norm=12.962 | L2-Norm(final)=2.378 | 5406.5 samples/s | 84.5 steps/s
[Step=2050 Epoch=19.5] | Loss=0.05558 | Reg=0.00169 | acc=0.9844 | L2-Norm=13.007 | L2-Norm(final)=2.366 | 4178.6 samples/s | 65.3 steps/s
[Step=2100 Epoch=20.0] | Loss=0.04743 | Reg=0.00171 | acc=0.9844 | L2-Norm=13.083 | L2-Norm(final)=2.376 | 7207.8 samples/s | 112.6 steps/s
[Step=2150 Epoch=20.5] | Loss=0.04320 | Reg=0.00173 | acc=0.9688 | L2-Norm=13.164 | L2-Norm(final)=2.394 | 2152.5 samples/s | 33.6 steps/s
[Step=2200 Epoch=20.9] | Loss=0.03988 | Reg=0.00175 | acc=0.9844 | L2-Norm=13.244 | L2-Norm(final)=2.418 | 6688.4 samples/s | 104.5 steps/s
[Step=2250 Epoch=21.4] | Loss=0.03702 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.319 | L2-Norm(final)=2.440 | 2242.5 samples/s | 35.0 steps/s
[Step=2300 Epoch=21.9] | Loss=0.03498 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.392 | L2-Norm(final)=2.462 | 5820.8 samples/s | 91.0 steps/s
[Step=2350 Epoch=22.4] | Loss=0.03310 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.458 | L2-Norm(final)=2.486 | 2234.0 samples/s | 34.9 steps/s
[Step=2400 Epoch=22.8] | Loss=0.03180 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.522 | L2-Norm(final)=2.508 | 5400.6 samples/s | 84.4 steps/s
[Step=2450 Epoch=23.3] | Loss=0.03080 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.582 | L2-Norm(final)=2.531 | 2427.6 samples/s | 37.9 steps/s
[Step=2500 Epoch=23.8] | Loss=0.02988 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.639 | L2-Norm(final)=2.554 | 4938.0 samples/s | 77.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=23.8] | Loss=0.00789 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.214 | L2-Norm(final)=2.779 | 5642.0 samples/s | 88.2 steps/s
[Step=2550 Epoch=24.3] | Loss=0.08925 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.429 | L2-Norm(final)=2.740 | 3651.1 samples/s | 57.0 steps/s
[Step=2600 Epoch=24.7] | Loss=0.04682 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=2.740 | 6210.6 samples/s | 97.0 steps/s
[Step=2650 Epoch=25.2] | Loss=0.03159 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.565 | L2-Norm(final)=2.742 | 2015.0 samples/s | 31.5 steps/s
[Step=2700 Epoch=25.7] | Loss=0.02377 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=2.745 | 5538.2 samples/s | 86.5 steps/s
[Step=2750 Epoch=26.2] | Loss=0.01904 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=2.746 | 2110.3 samples/s | 33.0 steps/s
[Step=2800 Epoch=26.6] | Loss=0.01589 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.580 | L2-Norm(final)=2.748 | 5135.2 samples/s | 80.2 steps/s
[Step=2850 Epoch=27.1] | Loss=0.01363 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=2.749 | 2208.8 samples/s | 34.5 steps/s
[Step=2900 Epoch=27.6] | Loss=0.01193 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.569 | L2-Norm(final)=2.750 | 4581.1 samples/s | 71.6 steps/s
[Step=2950 Epoch=28.1] | Loss=0.01061 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=2.751 | 2264.7 samples/s | 35.4 steps/s
[Step=3000 Epoch=28.5] | Loss=0.00955 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=2.751 | 4403.5 samples/s | 68.8 steps/s
[Step=3050 Epoch=29.0] | Loss=0.00869 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=2.752 | 2340.7 samples/s | 36.6 steps/s
[Step=3100 Epoch=29.5] | Loss=0.00797 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=2.753 | 4276.3 samples/s | 66.8 steps/s
[Step=3150 Epoch=30.0] | Loss=0.00736 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.521 | L2-Norm(final)=2.753 | 2391.3 samples/s | 37.4 steps/s
[Step=3200 Epoch=30.4] | Loss=0.00683 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=2.754 | 4200.0 samples/s | 65.6 steps/s
[Step=3250 Epoch=30.9] | Loss=0.00638 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.498 | L2-Norm(final)=2.754 | 2433.9 samples/s | 38.0 steps/s
[Step=3300 Epoch=31.4] | Loss=0.00598 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.487 | L2-Norm(final)=2.755 | 4206.4 samples/s | 65.7 steps/s
[Step=3350 Epoch=31.9] | Loss=0.00563 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.475 | L2-Norm(final)=2.755 | 2614.9 samples/s | 40.9 steps/s
[Step=3400 Epoch=32.3] | Loss=0.00532 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.463 | L2-Norm(final)=2.756 | 3705.6 samples/s | 57.9 steps/s
[Step=3450 Epoch=32.8] | Loss=0.00504 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.451 | L2-Norm(final)=2.757 | 6592.0 samples/s | 103.0 steps/s
[Step=3500 Epoch=33.3] | Loss=0.00479 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.438 | L2-Norm(final)=2.758 | 1966.1 samples/s | 30.7 steps/s
[Step=3550 Epoch=33.8] | Loss=0.00456 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.426 | L2-Norm(final)=2.759 | 5932.9 samples/s | 92.7 steps/s
[Step=3600 Epoch=34.2] | Loss=0.00436 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.413 | L2-Norm(final)=2.760 | 2055.4 samples/s | 32.1 steps/s
[Step=3650 Epoch=34.7] | Loss=0.00417 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.401 | L2-Norm(final)=2.761 | 5381.5 samples/s | 84.1 steps/s
[Step=3700 Epoch=35.2] | Loss=0.00400 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.388 | L2-Norm(final)=2.763 | 2196.5 samples/s | 34.3 steps/s
[Step=3750 Epoch=35.7] | Loss=0.00384 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=2.765 | 4733.5 samples/s | 74.0 steps/s
[Step=3800 Epoch=36.1] | Loss=0.00369 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=2.767 | 2214.1 samples/s | 34.6 steps/s
[Step=3850 Epoch=36.6] | Loss=0.00355 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.349 | L2-Norm(final)=2.769 | 4502.1 samples/s | 70.3 steps/s
[Step=3900 Epoch=37.1] | Loss=0.00343 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.336 | L2-Norm(final)=2.771 | 2349.0 samples/s | 36.7 steps/s
[Step=3950 Epoch=37.6] | Loss=0.00331 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.322 | L2-Norm(final)=2.773 | 4270.7 samples/s | 66.7 steps/s
[Step=4000 Epoch=38.0] | Loss=0.00320 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.309 | L2-Norm(final)=2.776 | 2444.7 samples/s | 38.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step4000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch=19.1] | Loss=0.09971 | Reg=0.00181 | acc=0.9219 | L2-Norm=13.446 | L2-Norm(final)=2.644 | 5453.7 samples/s | 85.2 steps/s
[Step=2050 Epoch=19.6] | Loss=0.05261 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.525 | L2-Norm(final)=2.636 | 4068.8 samples/s | 63.6 steps/s
[Step=2100 Epoch=20.1] | Loss=0.04533 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.635 | L2-Norm(final)=2.646 | 7342.5 samples/s | 114.7 steps/s
[Step=2150 Epoch=20.5] | Loss=0.04043 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.726 | L2-Norm(final)=2.665 | 2133.6 samples/s | 33.3 steps/s
[Step=2200 Epoch=21.0] | Loss=0.03576 | Reg=0.00191 | acc=0.9844 | L2-Norm=13.806 | L2-Norm(final)=2.688 | 6888.7 samples/s | 107.6 steps/s
[Step=2250 Epoch=21.5] | Loss=0.03267 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.875 | L2-Norm(final)=2.714 | 2191.5 samples/s | 34.2 steps/s
[Step=2300 Epoch=22.0] | Loss=0.03070 | Reg=0.00194 | acc=0.9688 | L2-Norm=13.939 | L2-Norm(final)=2.741 | 6214.7 samples/s | 97.1 steps/s
[Step=2350 Epoch=22.4] | Loss=0.02899 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.002 | L2-Norm(final)=2.768 | 2285.9 samples/s | 35.7 steps/s
[Step=2400 Epoch=22.9] | Loss=0.02729 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=2.796 | 5428.7 samples/s | 84.8 steps/s
[Step=2450 Epoch=23.4] | Loss=0.02619 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.118 | L2-Norm(final)=2.823 | 2370.7 samples/s | 37.0 steps/s
[Step=2500 Epoch=23.9] | Loss=0.02506 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.171 | L2-Norm(final)=2.850 | 5166.1 samples/s | 80.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=23.9] | Loss=0.00658 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=3.121 | 5382.3 samples/s | 84.1 steps/s
[Step=2550 Epoch=24.4] | Loss=0.20823 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.884 | L2-Norm(final)=2.987 | 3728.4 samples/s | 58.3 steps/s
[Step=2600 Epoch=24.8] | Loss=0.11582 | Reg=0.00225 | acc=0.9688 | L2-Norm=14.989 | L2-Norm(final)=2.969 | 6465.1 samples/s | 101.0 steps/s
[Step=2650 Epoch=25.3] | Loss=0.07986 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=2.968 | 2036.2 samples/s | 31.8 steps/s
[Step=2700 Epoch=25.8] | Loss=0.06051 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=2.969 | 5612.7 samples/s | 87.7 steps/s
[Step=2750 Epoch=26.3] | Loss=0.04864 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=2.972 | 2087.6 samples/s | 32.6 steps/s
[Step=2800 Epoch=26.7] | Loss=0.04058 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=2.974 | 5395.7 samples/s | 84.3 steps/s
[Step=2850 Epoch=27.2] | Loss=0.03482 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.118 | L2-Norm(final)=2.975 | 2083.9 samples/s | 32.6 steps/s
[Step=2900 Epoch=27.7] | Loss=0.03050 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=2.977 | 4998.4 samples/s | 78.1 steps/s
[Step=2950 Epoch=28.2] | Loss=0.02712 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=2.978 | 2193.4 samples/s | 34.3 steps/s
[Step=3000 Epoch=28.6] | Loss=0.02442 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=2.980 | 4655.9 samples/s | 72.7 steps/s
[Step=3050 Epoch=29.1] | Loss=0.02221 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=2.981 | 2279.0 samples/s | 35.6 steps/s
[Step=3100 Epoch=29.6] | Loss=0.02037 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=2.982 | 4405.4 samples/s | 68.8 steps/s
[Step=3150 Epoch=30.1] | Loss=0.01881 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=2.983 | 2319.4 samples/s | 36.2 steps/s
[Step=3200 Epoch=30.6] | Loss=0.01747 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.103 | L2-Norm(final)=2.984 | 4230.6 samples/s | 66.1 steps/s
[Step=3250 Epoch=31.0] | Loss=0.01631 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.097 | L2-Norm(final)=2.985 | 2332.5 samples/s | 36.4 steps/s
[Step=3300 Epoch=31.5] | Loss=0.01530 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=2.985 | 4136.9 samples/s | 64.6 steps/s
[Step=3350 Epoch=32.0] | Loss=0.01440 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.085 | L2-Norm(final)=2.986 | 2397.5 samples/s | 37.5 steps/s
[Step=3400 Epoch=32.5] | Loss=0.01360 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=2.987 | 4233.4 samples/s | 66.1 steps/s
[Step=3450 Epoch=32.9] | Loss=0.01289 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=2.988 | 2420.6 samples/s | 37.8 steps/s
[Step=3500 Epoch=33.4] | Loss=0.01225 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=2.988 | 4149.9 samples/s | 64.8 steps/s
[Step=3550 Epoch=33.9] | Loss=0.01166 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=2.989 | 6873.9 samples/s | 107.4 steps/s
[Step=3600 Epoch=34.4] | Loss=0.01114 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=2.989 | 1962.7 samples/s | 30.7 steps/s
[Step=3650 Epoch=34.9] | Loss=0.01065 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=2.990 | 6412.6 samples/s | 100.2 steps/s
[Step=3700 Epoch=35.3] | Loss=0.01021 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=2.991 | 2026.7 samples/s | 31.7 steps/s
[Step=3750 Epoch=35.8] | Loss=0.00980 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=2.991 | 5847.7 samples/s | 91.4 steps/s
[Step=3800 Epoch=36.3] | Loss=0.00943 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=2.992 | 2055.1 samples/s | 32.1 steps/s
[Step=3850 Epoch=36.8] | Loss=0.00908 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=2.992 | 5263.2 samples/s | 82.2 steps/s
[Step=3900 Epoch=37.2] | Loss=0.00876 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=2.993 | 2104.9 samples/s | 32.9 steps/s
[Step=3950 Epoch=37.7] | Loss=0.00845 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=2.993 | 5002.6 samples/s | 78.2 steps/s
[Step=4000 Epoch=38.2] | Loss=0.00817 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=2.993 | 2212.9 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step4000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch=18.9] | Loss=0.34812 | Reg=0.00183 | acc=0.7031 | L2-Norm=13.509 | L2-Norm(final)=2.308 | 5661.0 samples/s | 88.5 steps/s
[Step=2050 Epoch=19.3] | Loss=0.09215 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.652 | L2-Norm(final)=2.246 | 4021.1 samples/s | 62.8 steps/s
[Step=2100 Epoch=19.8] | Loss=0.06700 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.755 | L2-Norm(final)=2.247 | 7193.8 samples/s | 112.4 steps/s
[Step=2150 Epoch=20.3] | Loss=0.05697 | Reg=0.00191 | acc=0.9688 | L2-Norm=13.829 | L2-Norm(final)=2.264 | 2143.3 samples/s | 33.5 steps/s
[Step=2200 Epoch=20.7] | Loss=0.04988 | Reg=0.00193 | acc=0.9844 | L2-Norm=13.897 | L2-Norm(final)=2.286 | 6475.4 samples/s | 101.2 steps/s
[Step=2250 Epoch=21.2] | Loss=0.04710 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.955 | L2-Norm(final)=2.307 | 2230.8 samples/s | 34.9 steps/s
[Step=2300 Epoch=21.7] | Loss=0.04403 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.011 | L2-Norm(final)=2.329 | 5701.1 samples/s | 89.1 steps/s
[Step=2350 Epoch=22.1] | Loss=0.04134 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=2.352 | 2385.4 samples/s | 37.3 steps/s
[Step=2400 Epoch=22.6] | Loss=0.03890 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=2.375 | 4931.4 samples/s | 77.1 steps/s
[Step=2450 Epoch=23.1] | Loss=0.03705 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.154 | L2-Norm(final)=2.398 | 2430.0 samples/s | 38.0 steps/s
[Step=2500 Epoch=23.6] | Loss=0.03487 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.197 | L2-Norm(final)=2.422 | 4770.0 samples/s | 74.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=23.6] | Loss=0.01405 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.609 | L2-Norm(final)=2.656 | 5335.5 samples/s | 83.4 steps/s
[Step=2550 Epoch=24.0] | Loss=0.18811 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.782 | L2-Norm(final)=2.555 | 3782.4 samples/s | 59.1 steps/s
[Step=2600 Epoch=24.5] | Loss=0.10602 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.890 | L2-Norm(final)=2.549 | 6208.8 samples/s | 97.0 steps/s
[Step=2650 Epoch=25.0] | Loss=0.07486 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=2.556 | 2029.8 samples/s | 31.7 steps/s
[Step=2700 Epoch=25.4] | Loss=0.05732 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=2.563 | 5368.3 samples/s | 83.9 steps/s
[Step=2750 Epoch=25.9] | Loss=0.04622 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=2.570 | 2135.8 samples/s | 33.4 steps/s
[Step=2800 Epoch=26.4] | Loss=0.03864 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=2.576 | 4827.2 samples/s | 75.4 steps/s
[Step=2850 Epoch=26.9] | Loss=0.03320 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=2.582 | 2216.1 samples/s | 34.6 steps/s
[Step=2900 Epoch=27.3] | Loss=0.02909 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.035 | L2-Norm(final)=2.586 | 4494.2 samples/s | 70.2 steps/s
[Step=2950 Epoch=27.8] | Loss=0.02589 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=2.590 | 2320.0 samples/s | 36.2 steps/s
[Step=3000 Epoch=28.3] | Loss=0.02332 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=2.593 | 4253.1 samples/s | 66.5 steps/s
[Step=3050 Epoch=28.7] | Loss=0.02121 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=2.596 | 2382.6 samples/s | 37.2 steps/s
[Step=3100 Epoch=29.2] | Loss=0.01946 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=2.599 | 4258.1 samples/s | 66.5 steps/s
[Step=3150 Epoch=29.7] | Loss=0.01797 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=2.601 | 2392.5 samples/s | 37.4 steps/s
[Step=3200 Epoch=30.2] | Loss=0.01669 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=2.603 | 4238.8 samples/s | 66.2 steps/s
[Step=3250 Epoch=30.6] | Loss=0.01559 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=2.605 | 2557.4 samples/s | 40.0 steps/s
[Step=3300 Epoch=31.1] | Loss=0.01462 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=2.607 | 3982.1 samples/s | 62.2 steps/s
[Step=3350 Epoch=31.6] | Loss=0.01376 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=2.609 | 6138.4 samples/s | 95.9 steps/s
[Step=3400 Epoch=32.0] | Loss=0.01300 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=2.610 | 2039.2 samples/s | 31.9 steps/s
[Step=3450 Epoch=32.5] | Loss=0.01232 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=2.612 | 5645.8 samples/s | 88.2 steps/s
[Step=3500 Epoch=33.0] | Loss=0.01170 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=2.613 | 2100.0 samples/s | 32.8 steps/s
[Step=3550 Epoch=33.5] | Loss=0.01115 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=2.614 | 5040.1 samples/s | 78.8 steps/s
[Step=3600 Epoch=33.9] | Loss=0.01064 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=2.616 | 2131.3 samples/s | 33.3 steps/s
[Step=3650 Epoch=34.4] | Loss=0.01018 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=2.617 | 4545.0 samples/s | 71.0 steps/s
[Step=3700 Epoch=34.9] | Loss=0.00976 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.988 | L2-Norm(final)=2.618 | 2325.6 samples/s | 36.3 steps/s
[Step=3750 Epoch=35.3] | Loss=0.00937 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=2.619 | 4074.4 samples/s | 63.7 steps/s
[Step=3800 Epoch=35.8] | Loss=0.00901 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=2.620 | 2274.6 samples/s | 35.5 steps/s
[Step=3850 Epoch=36.3] | Loss=0.00868 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=2.621 | 4196.1 samples/s | 65.6 steps/s
[Step=3900 Epoch=36.7] | Loss=0.00837 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=2.622 | 2419.5 samples/s | 37.8 steps/s
[Step=3950 Epoch=37.2] | Loss=0.00808 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=2.623 | 4137.9 samples/s | 64.7 steps/s
[Step=4000 Epoch=37.7] | Loss=0.00781 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.941 | L2-Norm(final)=2.623 | 2607.9 samples/s | 40.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step4000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch=19.1] | Loss=0.14894 | Reg=0.00177 | acc=0.8906 | L2-Norm=13.289 | L2-Norm(final)=3.140 | 5007.6 samples/s | 78.2 steps/s
[Step=2050 Epoch=19.5] | Loss=0.06973 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.353 | L2-Norm(final)=3.098 | 4104.8 samples/s | 64.1 steps/s
[Step=2100 Epoch=20.0] | Loss=0.05923 | Reg=0.00180 | acc=0.9844 | L2-Norm=13.411 | L2-Norm(final)=3.092 | 7436.3 samples/s | 116.2 steps/s
[Step=2150 Epoch=20.5] | Loss=0.05345 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.483 | L2-Norm(final)=3.100 | 2102.7 samples/s | 32.9 steps/s
[Step=2200 Epoch=21.0] | Loss=0.04757 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.553 | L2-Norm(final)=3.116 | 6738.0 samples/s | 105.3 steps/s
[Step=2250 Epoch=21.4] | Loss=0.04395 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.614 | L2-Norm(final)=3.134 | 2216.6 samples/s | 34.6 steps/s
[Step=2300 Epoch=21.9] | Loss=0.04075 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.671 | L2-Norm(final)=3.154 | 6048.6 samples/s | 94.5 steps/s
[Step=2350 Epoch=22.4] | Loss=0.03854 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.727 | L2-Norm(final)=3.175 | 2256.0 samples/s | 35.2 steps/s
[Step=2400 Epoch=22.9] | Loss=0.03659 | Reg=0.00190 | acc=0.9844 | L2-Norm=13.780 | L2-Norm(final)=3.198 | 5606.7 samples/s | 87.6 steps/s
[Step=2450 Epoch=23.4] | Loss=0.03461 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.830 | L2-Norm(final)=3.220 | 2296.4 samples/s | 35.9 steps/s
[Step=2500 Epoch=23.8] | Loss=0.03323 | Reg=0.00193 | acc=0.9688 | L2-Norm=13.878 | L2-Norm(final)=3.243 | 5284.4 samples/s | 82.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch=23.8] | Loss=0.02266 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.349 | L2-Norm(final)=3.476 | 5644.0 samples/s | 88.2 steps/s
[Step=2550 Epoch=24.3] | Loss=0.13604 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.590 | L2-Norm(final)=3.386 | 3591.6 samples/s | 56.1 steps/s
[Step=2600 Epoch=24.8] | Loss=0.07493 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=3.380 | 6397.8 samples/s | 100.0 steps/s
[Step=2650 Epoch=25.3] | Loss=0.05111 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=3.383 | 2057.1 samples/s | 32.1 steps/s
[Step=2700 Epoch=25.7] | Loss=0.03855 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.765 | L2-Norm(final)=3.387 | 5438.3 samples/s | 85.0 steps/s
[Step=2750 Epoch=26.2] | Loss=0.03097 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=3.391 | 2095.3 samples/s | 32.7 steps/s
[Step=2800 Epoch=26.7] | Loss=0.02585 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=3.394 | 5329.1 samples/s | 83.3 steps/s
[Step=2850 Epoch=27.2] | Loss=0.02218 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=3.396 | 2160.9 samples/s | 33.8 steps/s
[Step=2900 Epoch=27.6] | Loss=0.01941 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=3.398 | 4898.6 samples/s | 76.5 steps/s
[Step=2950 Epoch=28.1] | Loss=0.01727 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.780 | L2-Norm(final)=3.399 | 2197.0 samples/s | 34.3 steps/s
[Step=3000 Epoch=28.6] | Loss=0.01554 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.775 | L2-Norm(final)=3.401 | 4578.5 samples/s | 71.5 steps/s
[Step=3050 Epoch=29.1] | Loss=0.01414 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=3.402 | 2271.0 samples/s | 35.5 steps/s
[Step=3100 Epoch=29.5] | Loss=0.01296 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.761 | L2-Norm(final)=3.403 | 4344.7 samples/s | 67.9 steps/s
[Step=3150 Epoch=30.0] | Loss=0.01197 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=3.404 | 2364.3 samples/s | 36.9 steps/s
[Step=3200 Epoch=30.5] | Loss=0.01112 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.745 | L2-Norm(final)=3.405 | 4324.6 samples/s | 67.6 steps/s
[Step=3250 Epoch=31.0] | Loss=0.01038 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=3.406 | 2359.5 samples/s | 36.9 steps/s
[Step=3300 Epoch=31.5] | Loss=0.00973 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.726 | L2-Norm(final)=3.406 | 4217.2 samples/s | 65.9 steps/s
[Step=3350 Epoch=31.9] | Loss=0.00916 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=3.407 | 2436.6 samples/s | 38.1 steps/s
[Step=3400 Epoch=32.4] | Loss=0.00865 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=3.408 | 4200.9 samples/s | 65.6 steps/s
[Step=3450 Epoch=32.9] | Loss=0.00820 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=3.408 | 2370.8 samples/s | 37.0 steps/s
[Step=3500 Epoch=33.4] | Loss=0.00779 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=3.409 | 4322.6 samples/s | 67.5 steps/s
[Step=3550 Epoch=33.8] | Loss=0.00742 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=3.409 | 6810.1 samples/s | 106.4 steps/s
[Step=3600 Epoch=34.3] | Loss=0.00708 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=3.410 | 1948.8 samples/s | 30.5 steps/s
[Step=3650 Epoch=34.8] | Loss=0.00678 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.653 | L2-Norm(final)=3.410 | 6312.9 samples/s | 98.6 steps/s
[Step=3700 Epoch=35.3] | Loss=0.00650 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=3.411 | 2038.9 samples/s | 31.9 steps/s
[Step=3750 Epoch=35.7] | Loss=0.00624 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=3.411 | 5650.9 samples/s | 88.3 steps/s
[Step=3800 Epoch=36.2] | Loss=0.00600 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=3.412 | 2052.2 samples/s | 32.1 steps/s
[Step=3850 Epoch=36.7] | Loss=0.00578 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=3.412 | 5356.8 samples/s | 83.7 steps/s
[Step=3900 Epoch=37.2] | Loss=0.00557 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=3.413 | 2117.6 samples/s | 33.1 steps/s
[Step=3950 Epoch=37.6] | Loss=0.00538 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.584 | L2-Norm(final)=3.413 | 4986.7 samples/s | 77.9 steps/s
[Step=4000 Epoch=38.1] | Loss=0.00520 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=3.413 | 2196.1 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.15589 | acc=0.9165 | tpr=0.9111 | fpr=0.0719 | 4956.7 samples/s | 19.4 steps/s
Avg test loss: 0.16504, Avg test acc: 0.91522, Avg tpr: 0.91077, Avg fpr: 0.07499, total FA: 585

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.15744 | acc=0.9278 | tpr=0.9509 | fpr=0.1224 | 4787.6 samples/s | 18.7 steps/s
Avg test loss: 0.15733, Avg test acc: 0.92792, Avg tpr: 0.95197, Avg fpr: 0.12498, total FA: 975

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14617 | acc=0.9300 | tpr=0.9553 | fpr=0.1249 | 4747.7 samples/s | 18.5 steps/s
Avg test loss: 0.14755, Avg test acc: 0.92812, Avg tpr: 0.95296, Avg fpr: 0.12652, total FA: 987

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.16428 | acc=0.9168 | tpr=0.9087 | fpr=0.0657 | 4901.8 samples/s | 19.1 steps/s
Avg test loss: 0.16825, Avg test acc: 0.91337, Avg tpr: 0.90430, Avg fpr: 0.06666, total FA: 520

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.13978 | acc=0.9292 | tpr=0.9409 | fpr=0.0961 | 4824.2 samples/s | 18.8 steps/s
Avg test loss: 0.13970, Avg test acc: 0.92924, Avg tpr: 0.93979, Avg fpr: 0.09396, total FA: 733

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.64977 | acc=0.3137 | tpr=0.0144 | fpr=0.0362 | 4889.2 samples/s | 19.1 steps/s
Avg test loss: 4.66664, Avg test acc: 0.31172, Avg tpr: 0.01445, Avg fpr: 0.03448, total FA: 269

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.85269 | acc=0.3043 | tpr=0.0256 | fpr=0.0904 | 4884.6 samples/s | 19.1 steps/s
Avg test loss: 4.87567, Avg test acc: 0.30239, Avg tpr: 0.02530, Avg fpr: 0.08819, total FA: 688

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=3.66531 | acc=0.2922 | tpr=0.0403 | fpr=0.1608 | 4970.1 samples/s | 19.4 steps/s
Avg test loss: 3.68673, Avg test acc: 0.29085, Avg tpr: 0.03841, Avg fpr: 0.15395, total FA: 1201

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=3.91157 | acc=0.2991 | tpr=0.0354 | fpr=0.1283 | 4966.7 samples/s | 19.4 steps/s
Avg test loss: 3.92001, Avg test acc: 0.29866, Avg tpr: 0.03515, Avg fpr: 0.12178, total FA: 950

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.40842 | acc=0.3078 | tpr=0.0226 | fpr=0.0728 | 4805.2 samples/s | 18.8 steps/s
Avg test loss: 4.41583, Avg test acc: 0.30864, Avg tpr: 0.02407, Avg fpr: 0.06550, total FA: 511

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.36262 | acc=0.1648 | tpr=0.6726 | fpr=0.8444 | 4868.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=3.35075 | acc=0.1677 | tpr=0.6652 | fpr=0.8416 | 7205.6 samples/s | 28.1 steps/s
[Step= 150] | Loss=3.35414 | acc=0.1670 | tpr=0.6585 | fpr=0.8421 | 7694.3 samples/s | 30.1 steps/s
[Step= 200] | Loss=3.34637 | acc=0.1671 | tpr=0.6579 | fpr=0.8418 | 7838.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=3.35082 | acc=0.1677 | tpr=0.6611 | fpr=0.8413 | 7760.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=3.35154 | acc=0.1666 | tpr=0.6589 | fpr=0.8424 | 7688.1 samples/s | 30.0 steps/s
[Step= 350] | Loss=3.34807 | acc=0.1667 | tpr=0.6631 | fpr=0.8424 | 8234.9 samples/s | 32.2 steps/s
[Step= 400] | Loss=3.34883 | acc=0.1670 | tpr=0.6586 | fpr=0.8420 | 7664.4 samples/s | 29.9 steps/s
[Step= 450] | Loss=3.35000 | acc=0.1664 | tpr=0.6558 | fpr=0.8425 | 8084.1 samples/s | 31.6 steps/s
[Step= 500] | Loss=3.35118 | acc=0.1666 | tpr=0.6555 | fpr=0.8422 | 7607.3 samples/s | 29.7 steps/s
[Step= 550] | Loss=3.35247 | acc=0.1670 | tpr=0.6514 | fpr=0.8419 | 14345.3 samples/s | 56.0 steps/s
Avg test loss: 3.35338, Avg test acc: 0.16682, Avg tpr: 0.64976, Avg fpr: 0.84196, total FA: 116905

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.52394 | acc=0.1170 | tpr=0.6018 | fpr=0.8917 | 4846.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=3.52419 | acc=0.1182 | tpr=0.6034 | fpr=0.8908 | 7510.9 samples/s | 29.3 steps/s
[Step= 150] | Loss=3.51562 | acc=0.1196 | tpr=0.6182 | fpr=0.8895 | 7107.8 samples/s | 27.8 steps/s
[Step= 200] | Loss=3.50072 | acc=0.1208 | tpr=0.6164 | fpr=0.8882 | 7696.6 samples/s | 30.1 steps/s
[Step= 250] | Loss=3.50598 | acc=0.1207 | tpr=0.6227 | fpr=0.8884 | 8237.7 samples/s | 32.2 steps/s
[Step= 300] | Loss=3.51037 | acc=0.1196 | tpr=0.6225 | fpr=0.8895 | 7995.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=3.50465 | acc=0.1200 | tpr=0.6218 | fpr=0.8891 | 7982.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=3.50407 | acc=0.1205 | tpr=0.6286 | fpr=0.8887 | 7640.0 samples/s | 29.8 steps/s
[Step= 450] | Loss=3.50778 | acc=0.1202 | tpr=0.6329 | fpr=0.8891 | 7739.3 samples/s | 30.2 steps/s
[Step= 500] | Loss=3.50974 | acc=0.1201 | tpr=0.6308 | fpr=0.8891 | 8025.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=3.51128 | acc=0.1200 | tpr=0.6283 | fpr=0.8892 | 13671.5 samples/s | 53.4 steps/s
Avg test loss: 3.51261, Avg test acc: 0.11995, Avg tpr: 0.62837, Avg fpr: 0.88930, total FA: 123477

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=4.27247 | acc=0.0904 | tpr=0.7655 | fpr=0.9217 | 5016.9 samples/s | 19.6 steps/s
[Step= 100] | Loss=4.25028 | acc=0.0912 | tpr=0.7676 | fpr=0.9214 | 6778.6 samples/s | 26.5 steps/s
[Step= 150] | Loss=4.24760 | acc=0.0913 | tpr=0.7839 | fpr=0.9214 | 7618.0 samples/s | 29.8 steps/s
[Step= 200] | Loss=4.24792 | acc=0.0911 | tpr=0.7869 | fpr=0.9216 | 7976.3 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.25596 | acc=0.0913 | tpr=0.7930 | fpr=0.9214 | 7669.6 samples/s | 30.0 steps/s
[Step= 300] | Loss=4.25528 | acc=0.0919 | tpr=0.7956 | fpr=0.9210 | 8173.8 samples/s | 31.9 steps/s
[Step= 350] | Loss=4.25176 | acc=0.0918 | tpr=0.7915 | fpr=0.9209 | 7694.3 samples/s | 30.1 steps/s
[Step= 400] | Loss=4.25355 | acc=0.0918 | tpr=0.7949 | fpr=0.9210 | 7812.8 samples/s | 30.5 steps/s
[Step= 450] | Loss=4.25150 | acc=0.0919 | tpr=0.7960 | fpr=0.9208 | 7859.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=4.25212 | acc=0.0917 | tpr=0.7947 | fpr=0.9210 | 7939.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=4.25199 | acc=0.0921 | tpr=0.7943 | fpr=0.9207 | 14320.1 samples/s | 55.9 steps/s
Avg test loss: 4.25243, Avg test acc: 0.09203, Avg tpr: 0.79358, Avg fpr: 0.92073, total FA: 127841

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=2.97867 | acc=0.2165 | tpr=0.6416 | fpr=0.7912 | 4931.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=2.96769 | acc=0.2168 | tpr=0.6077 | fpr=0.7905 | 6847.4 samples/s | 26.7 steps/s
[Step= 150] | Loss=2.96561 | acc=0.2205 | tpr=0.6167 | fpr=0.7868 | 8218.4 samples/s | 32.1 steps/s
[Step= 200] | Loss=2.95545 | acc=0.2218 | tpr=0.6175 | fpr=0.7854 | 7536.7 samples/s | 29.4 steps/s
[Step= 250] | Loss=2.96224 | acc=0.2218 | tpr=0.6114 | fpr=0.7853 | 8131.6 samples/s | 31.8 steps/s
[Step= 300] | Loss=2.96603 | acc=0.2209 | tpr=0.6087 | fpr=0.7862 | 7821.2 samples/s | 30.6 steps/s
[Step= 350] | Loss=2.95913 | acc=0.2214 | tpr=0.6124 | fpr=0.7857 | 7752.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=2.95562 | acc=0.2216 | tpr=0.6050 | fpr=0.7853 | 7770.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=2.95712 | acc=0.2211 | tpr=0.6061 | fpr=0.7859 | 7610.0 samples/s | 29.7 steps/s
[Step= 500] | Loss=2.95870 | acc=0.2211 | tpr=0.6026 | fpr=0.7858 | 8935.9 samples/s | 34.9 steps/s
[Step= 550] | Loss=2.95792 | acc=0.2211 | tpr=0.5973 | fpr=0.7857 | 11936.9 samples/s | 46.6 steps/s
Avg test loss: 2.95888, Avg test acc: 0.22101, Avg tpr: 0.59707, Avg fpr: 0.78582, total FA: 109110

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=3.36310 | acc=0.1493 | tpr=0.6239 | fpr=0.8592 | 4920.5 samples/s | 19.2 steps/s
[Step= 100] | Loss=3.35206 | acc=0.1518 | tpr=0.6247 | fpr=0.8571 | 7254.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=3.34895 | acc=0.1533 | tpr=0.6196 | fpr=0.8553 | 7540.0 samples/s | 29.5 steps/s
[Step= 200] | Loss=3.33917 | acc=0.1538 | tpr=0.6230 | fpr=0.8547 | 7989.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=3.34980 | acc=0.1534 | tpr=0.6218 | fpr=0.8551 | 7717.0 samples/s | 30.1 steps/s
[Step= 300] | Loss=3.35098 | acc=0.1533 | tpr=0.6225 | fpr=0.8553 | 7727.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=3.35266 | acc=0.1528 | tpr=0.6187 | fpr=0.8557 | 7853.4 samples/s | 30.7 steps/s
[Step= 400] | Loss=3.35338 | acc=0.1528 | tpr=0.6253 | fpr=0.8558 | 8007.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=3.35701 | acc=0.1523 | tpr=0.6198 | fpr=0.8562 | 7883.5 samples/s | 30.8 steps/s
[Step= 500] | Loss=3.35819 | acc=0.1521 | tpr=0.6132 | fpr=0.8562 | 7787.2 samples/s | 30.4 steps/s
[Step= 550] | Loss=3.35669 | acc=0.1519 | tpr=0.6120 | fpr=0.8565 | 14280.8 samples/s | 55.8 steps/s
Avg test loss: 3.35735, Avg test acc: 0.15178, Avg tpr: 0.61252, Avg fpr: 0.85659, total FA: 118936

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.07789 | acc=0.9809 | tpr=0.8673 | fpr=0.0171 | 4786.4 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.08012 | acc=0.9805 | tpr=0.8977 | fpr=0.0179 | 7121.8 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.08358 | acc=0.9796 | tpr=0.8963 | fpr=0.0189 | 8245.4 samples/s | 32.2 steps/s
[Step= 200] | Loss=0.08420 | acc=0.9796 | tpr=0.9005 | fpr=0.0190 | 7207.9 samples/s | 28.2 steps/s
[Step= 250] | Loss=0.08311 | acc=0.9800 | tpr=0.8978 | fpr=0.0186 | 8285.6 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.08438 | acc=0.9799 | tpr=0.8960 | fpr=0.0186 | 7790.7 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.08621 | acc=0.9794 | tpr=0.8936 | fpr=0.0190 | 7997.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.08699 | acc=0.9791 | tpr=0.8933 | fpr=0.0193 | 7821.7 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.08844 | acc=0.9788 | tpr=0.8929 | fpr=0.0196 | 7796.1 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.08785 | acc=0.9789 | tpr=0.8943 | fpr=0.0196 | 8124.3 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.08677 | acc=0.9792 | tpr=0.8953 | fpr=0.0193 | 13677.7 samples/s | 53.4 steps/s
Avg test loss: 0.08663, Avg test acc: 0.97914, Avg tpr: 0.89461, Avg fpr: 0.01932, total FA: 2683

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.05422 | acc=0.9829 | tpr=0.8142 | fpr=0.0141 | 4867.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.05540 | acc=0.9827 | tpr=0.8294 | fpr=0.0144 | 7052.6 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.05708 | acc=0.9826 | tpr=0.8329 | fpr=0.0146 | 7983.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.05780 | acc=0.9826 | tpr=0.8415 | fpr=0.0148 | 7635.3 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.05704 | acc=0.9830 | tpr=0.8410 | fpr=0.0144 | 7817.8 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.05768 | acc=0.9827 | tpr=0.8364 | fpr=0.0146 | 7703.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.05810 | acc=0.9827 | tpr=0.8372 | fpr=0.0147 | 8150.1 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.05825 | acc=0.9825 | tpr=0.8353 | fpr=0.0148 | 7873.1 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.05947 | acc=0.9822 | tpr=0.8354 | fpr=0.0151 | 8108.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.05909 | acc=0.9823 | tpr=0.8357 | fpr=0.0150 | 7556.4 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.05853 | acc=0.9825 | tpr=0.8372 | fpr=0.0148 | 14701.0 samples/s | 57.4 steps/s
Avg test loss: 0.05840, Avg test acc: 0.98254, Avg tpr: 0.83796, Avg fpr: 0.01483, total FA: 2059

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.05170 | acc=0.9823 | tpr=0.9159 | fpr=0.0165 | 4804.0 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.05183 | acc=0.9819 | tpr=0.9147 | fpr=0.0168 | 7065.4 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.05324 | acc=0.9811 | tpr=0.9135 | fpr=0.0177 | 7996.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.05447 | acc=0.9812 | tpr=0.9180 | fpr=0.0177 | 7819.7 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.05389 | acc=0.9813 | tpr=0.9109 | fpr=0.0174 | 7794.2 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.05429 | acc=0.9810 | tpr=0.9062 | fpr=0.0176 | 8084.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.05417 | acc=0.9810 | tpr=0.9054 | fpr=0.0176 | 7767.1 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.05494 | acc=0.9807 | tpr=0.8977 | fpr=0.0178 | 7960.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.05570 | acc=0.9805 | tpr=0.8963 | fpr=0.0179 | 7744.1 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.05516 | acc=0.9806 | tpr=0.9000 | fpr=0.0179 | 7770.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.05488 | acc=0.9808 | tpr=0.9013 | fpr=0.0177 | 14463.7 samples/s | 56.5 steps/s
Avg test loss: 0.05487, Avg test acc: 0.98083, Avg tpr: 0.90135, Avg fpr: 0.01772, total FA: 2461

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.06361 | acc=0.9824 | tpr=0.8805 | fpr=0.0157 | 4783.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.06110 | acc=0.9829 | tpr=0.8891 | fpr=0.0154 | 7149.6 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.06343 | acc=0.9821 | tpr=0.8890 | fpr=0.0162 | 8077.8 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.06412 | acc=0.9819 | tpr=0.8929 | fpr=0.0165 | 7703.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.06259 | acc=0.9821 | tpr=0.8830 | fpr=0.0161 | 7671.5 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.06355 | acc=0.9818 | tpr=0.8764 | fpr=0.0163 | 8201.5 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.06364 | acc=0.9818 | tpr=0.8804 | fpr=0.0164 | 7751.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.06459 | acc=0.9816 | tpr=0.8736 | fpr=0.0165 | 7731.7 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.06567 | acc=0.9812 | tpr=0.8724 | fpr=0.0168 | 8063.3 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.06548 | acc=0.9812 | tpr=0.8740 | fpr=0.0168 | 7914.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.06505 | acc=0.9813 | tpr=0.8747 | fpr=0.0168 | 13459.2 samples/s | 52.6 steps/s
Avg test loss: 0.06496, Avg test acc: 0.98130, Avg tpr: 0.87520, Avg fpr: 0.01677, total FA: 2329

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.07492 | acc=0.9811 | tpr=0.8496 | fpr=0.0165 | 4951.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.07318 | acc=0.9809 | tpr=0.8699 | fpr=0.0170 | 6856.1 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.07456 | acc=0.9806 | tpr=0.8818 | fpr=0.0176 | 7573.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.07647 | acc=0.9803 | tpr=0.8809 | fpr=0.0179 | 8009.4 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.07445 | acc=0.9807 | tpr=0.8751 | fpr=0.0174 | 8186.7 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.07588 | acc=0.9804 | tpr=0.8684 | fpr=0.0175 | 7489.4 samples/s | 29.3 steps/s
[Step= 350] | Loss=0.07713 | acc=0.9801 | tpr=0.8685 | fpr=0.0179 | 8201.2 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.07783 | acc=0.9797 | tpr=0.8616 | fpr=0.0182 | 7803.7 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.07890 | acc=0.9796 | tpr=0.8608 | fpr=0.0183 | 7866.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.07863 | acc=0.9795 | tpr=0.8626 | fpr=0.0184 | 7861.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.07802 | acc=0.9795 | tpr=0.8615 | fpr=0.0183 | 13938.4 samples/s | 54.4 steps/s
Avg test loss: 0.07793, Avg test acc: 0.97955, Avg tpr: 0.86173, Avg fpr: 0.01831, total FA: 2542

server round 2/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=19.5] | Loss=0.13778 | Reg=0.00369 | acc=0.8906 | L2-Norm=19.201 | L2-Norm(final)=3.105 | 5025.4 samples/s | 78.5 steps/s
[Step=4050 Epoch=19.7] | Loss=0.14113 | Reg=0.00371 | acc=0.8594 | L2-Norm=19.255 | L2-Norm(final)=3.125 | 4740.2 samples/s | 74.1 steps/s
[Step=4100 Epoch=20.0] | Loss=0.13452 | Reg=0.00373 | acc=0.9219 | L2-Norm=19.310 | L2-Norm(final)=3.152 | 5035.5 samples/s | 78.7 steps/s
[Step=4150 Epoch=20.2] | Loss=0.12812 | Reg=0.00375 | acc=0.9219 | L2-Norm=19.359 | L2-Norm(final)=3.185 | 5026.2 samples/s | 78.5 steps/s
[Step=4200 Epoch=20.5] | Loss=0.12539 | Reg=0.00377 | acc=0.9062 | L2-Norm=19.406 | L2-Norm(final)=3.219 | 7681.9 samples/s | 120.0 steps/s
[Step=4250 Epoch=20.7] | Loss=0.12302 | Reg=0.00378 | acc=0.8438 | L2-Norm=19.452 | L2-Norm(final)=3.251 | 2231.9 samples/s | 34.9 steps/s
[Step=4300 Epoch=21.0] | Loss=0.12071 | Reg=0.00380 | acc=0.9062 | L2-Norm=19.498 | L2-Norm(final)=3.283 | 5075.3 samples/s | 79.3 steps/s
[Step=4350 Epoch=21.2] | Loss=0.11903 | Reg=0.00382 | acc=0.9531 | L2-Norm=19.544 | L2-Norm(final)=3.316 | 4885.0 samples/s | 76.3 steps/s
[Step=4400 Epoch=21.5] | Loss=0.11796 | Reg=0.00384 | acc=0.8906 | L2-Norm=19.588 | L2-Norm(final)=3.348 | 6879.9 samples/s | 107.5 steps/s
[Step=4450 Epoch=21.7] | Loss=0.11729 | Reg=0.00386 | acc=0.9062 | L2-Norm=19.634 | L2-Norm(final)=3.380 | 2286.2 samples/s | 35.7 steps/s
[Step=4500 Epoch=21.9] | Loss=0.11525 | Reg=0.00387 | acc=0.8906 | L2-Norm=19.681 | L2-Norm(final)=3.413 | 5034.1 samples/s | 78.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=21.9] | Loss=0.09715 | Reg=0.00406 | acc=0.9531 | L2-Norm=20.150 | L2-Norm(final)=3.758 | 5394.7 samples/s | 84.3 steps/s
[Step=4550 Epoch=22.2] | Loss=0.10759 | Reg=0.00408 | acc=0.8438 | L2-Norm=20.200 | L2-Norm(final)=3.758 | 4016.9 samples/s | 62.8 steps/s
[Step=4600 Epoch=22.4] | Loss=0.10357 | Reg=0.00410 | acc=0.9531 | L2-Norm=20.250 | L2-Norm(final)=3.742 | 4409.1 samples/s | 68.9 steps/s
[Step=4650 Epoch=22.7] | Loss=0.09753 | Reg=0.00412 | acc=0.9375 | L2-Norm=20.288 | L2-Norm(final)=3.733 | 4469.5 samples/s | 69.8 steps/s
[Step=4700 Epoch=22.9] | Loss=0.09011 | Reg=0.00413 | acc=0.9531 | L2-Norm=20.315 | L2-Norm(final)=3.730 | 6531.1 samples/s | 102.0 steps/s
[Step=4750 Epoch=23.2] | Loss=0.08535 | Reg=0.00414 | acc=0.9531 | L2-Norm=20.340 | L2-Norm(final)=3.724 | 2076.9 samples/s | 32.5 steps/s
[Step=4800 Epoch=23.4] | Loss=0.08092 | Reg=0.00415 | acc=0.9531 | L2-Norm=20.368 | L2-Norm(final)=3.720 | 4509.0 samples/s | 70.5 steps/s
[Step=4850 Epoch=23.6] | Loss=0.07614 | Reg=0.00416 | acc=0.9375 | L2-Norm=20.393 | L2-Norm(final)=3.716 | 4418.9 samples/s | 69.0 steps/s
[Step=4900 Epoch=23.9] | Loss=0.07282 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.416 | L2-Norm(final)=3.714 | 5799.6 samples/s | 90.6 steps/s
[Step=4950 Epoch=24.1] | Loss=0.06851 | Reg=0.00418 | acc=0.9375 | L2-Norm=20.439 | L2-Norm(final)=3.712 | 2171.6 samples/s | 33.9 steps/s
[Step=5000 Epoch=24.4] | Loss=0.06488 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.460 | L2-Norm(final)=3.711 | 4489.1 samples/s | 70.1 steps/s
[Step=5050 Epoch=24.6] | Loss=0.06183 | Reg=0.00419 | acc=0.9531 | L2-Norm=20.478 | L2-Norm(final)=3.711 | 4393.9 samples/s | 68.7 steps/s
[Step=5100 Epoch=24.9] | Loss=0.05947 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.493 | L2-Norm(final)=3.711 | 5351.7 samples/s | 83.6 steps/s
[Step=5150 Epoch=25.1] | Loss=0.05692 | Reg=0.00421 | acc=0.9844 | L2-Norm=20.507 | L2-Norm(final)=3.711 | 2258.7 samples/s | 35.3 steps/s
[Step=5200 Epoch=25.4] | Loss=0.05468 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.519 | L2-Norm(final)=3.711 | 4431.8 samples/s | 69.2 steps/s
[Step=5250 Epoch=25.6] | Loss=0.05243 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.530 | L2-Norm(final)=3.712 | 4404.1 samples/s | 68.8 steps/s
[Step=5300 Epoch=25.8] | Loss=0.05087 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.540 | L2-Norm(final)=3.713 | 4955.4 samples/s | 77.4 steps/s
[Step=5350 Epoch=26.1] | Loss=0.04953 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.551 | L2-Norm(final)=3.714 | 2347.8 samples/s | 36.7 steps/s
[Step=5400 Epoch=26.3] | Loss=0.04815 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.562 | L2-Norm(final)=3.715 | 4396.6 samples/s | 68.7 steps/s
[Step=5450 Epoch=26.6] | Loss=0.04694 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.572 | L2-Norm(final)=3.716 | 4446.1 samples/s | 69.5 steps/s
[Step=5500 Epoch=26.8] | Loss=0.04555 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.580 | L2-Norm(final)=3.717 | 4618.1 samples/s | 72.2 steps/s
[Step=5550 Epoch=27.1] | Loss=0.04418 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.588 | L2-Norm(final)=3.718 | 2463.7 samples/s | 38.5 steps/s
[Step=5600 Epoch=27.3] | Loss=0.04291 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.594 | L2-Norm(final)=3.720 | 4410.6 samples/s | 68.9 steps/s
[Step=5650 Epoch=27.6] | Loss=0.04182 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.599 | L2-Norm(final)=3.721 | 4455.3 samples/s | 69.6 steps/s
[Step=5700 Epoch=27.8] | Loss=0.04070 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.604 | L2-Norm(final)=3.722 | 4551.1 samples/s | 71.1 steps/s
[Step=5750 Epoch=28.0] | Loss=0.03945 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.608 | L2-Norm(final)=3.724 | 2413.9 samples/s | 37.7 steps/s
[Step=5800 Epoch=28.3] | Loss=0.03842 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.611 | L2-Norm(final)=3.726 | 4468.5 samples/s | 69.8 steps/s
[Step=5850 Epoch=28.5] | Loss=0.03744 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.613 | L2-Norm(final)=3.728 | 4476.4 samples/s | 69.9 steps/s
[Step=5900 Epoch=28.8] | Loss=0.03649 | Reg=0.00425 | acc=0.9688 | L2-Norm=20.615 | L2-Norm(final)=3.730 | 4473.9 samples/s | 69.9 steps/s
[Step=5950 Epoch=29.0] | Loss=0.03587 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.616 | L2-Norm(final)=3.732 | 2445.8 samples/s | 38.2 steps/s
[Step=6000 Epoch=29.3] | Loss=0.03517 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.618 | L2-Norm(final)=3.734 | 4502.1 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step6000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=19.5] | Loss=0.16500 | Reg=0.00357 | acc=0.8750 | L2-Norm=18.887 | L2-Norm(final)=3.200 | 5348.5 samples/s | 83.6 steps/s
[Step=4050 Epoch=19.8] | Loss=0.13526 | Reg=0.00359 | acc=0.8438 | L2-Norm=18.947 | L2-Norm(final)=3.234 | 4210.5 samples/s | 65.8 steps/s
[Step=4100 Epoch=20.0] | Loss=0.13080 | Reg=0.00361 | acc=0.8750 | L2-Norm=19.009 | L2-Norm(final)=3.269 | 5035.4 samples/s | 78.7 steps/s
[Step=4150 Epoch=20.3] | Loss=0.12897 | Reg=0.00363 | acc=0.9062 | L2-Norm=19.060 | L2-Norm(final)=3.296 | 5020.3 samples/s | 78.4 steps/s
[Step=4200 Epoch=20.5] | Loss=0.12664 | Reg=0.00365 | acc=0.9062 | L2-Norm=19.106 | L2-Norm(final)=3.323 | 7892.7 samples/s | 123.3 steps/s
[Step=4250 Epoch=20.7] | Loss=0.12344 | Reg=0.00367 | acc=0.9219 | L2-Norm=19.147 | L2-Norm(final)=3.353 | 2221.1 samples/s | 34.7 steps/s
[Step=4300 Epoch=21.0] | Loss=0.12227 | Reg=0.00368 | acc=0.8750 | L2-Norm=19.187 | L2-Norm(final)=3.382 | 5003.7 samples/s | 78.2 steps/s
[Step=4350 Epoch=21.2] | Loss=0.12031 | Reg=0.00370 | acc=0.9219 | L2-Norm=19.227 | L2-Norm(final)=3.412 | 5083.9 samples/s | 79.4 steps/s
[Step=4400 Epoch=21.5] | Loss=0.11880 | Reg=0.00371 | acc=0.9219 | L2-Norm=19.267 | L2-Norm(final)=3.442 | 6934.1 samples/s | 108.3 steps/s
[Step=4450 Epoch=21.7] | Loss=0.11712 | Reg=0.00373 | acc=0.9375 | L2-Norm=19.308 | L2-Norm(final)=3.472 | 2249.2 samples/s | 35.1 steps/s
[Step=4500 Epoch=22.0] | Loss=0.11628 | Reg=0.00374 | acc=0.9375 | L2-Norm=19.350 | L2-Norm(final)=3.503 | 5115.2 samples/s | 79.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=22.0] | Loss=0.11152 | Reg=0.00391 | acc=0.9375 | L2-Norm=19.769 | L2-Norm(final)=3.806 | 5260.4 samples/s | 82.2 steps/s
[Step=4550 Epoch=22.2] | Loss=0.10281 | Reg=0.00393 | acc=0.8594 | L2-Norm=19.821 | L2-Norm(final)=3.816 | 4058.2 samples/s | 63.4 steps/s
[Step=4600 Epoch=22.4] | Loss=0.09994 | Reg=0.00394 | acc=0.9219 | L2-Norm=19.859 | L2-Norm(final)=3.806 | 4485.7 samples/s | 70.1 steps/s
[Step=4650 Epoch=22.7] | Loss=0.09341 | Reg=0.00396 | acc=0.9531 | L2-Norm=19.888 | L2-Norm(final)=3.799 | 4540.1 samples/s | 70.9 steps/s
[Step=4700 Epoch=22.9] | Loss=0.08803 | Reg=0.00397 | acc=0.8906 | L2-Norm=19.912 | L2-Norm(final)=3.795 | 6365.7 samples/s | 99.5 steps/s
[Step=4750 Epoch=23.2] | Loss=0.07988 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.935 | L2-Norm(final)=3.793 | 2093.6 samples/s | 32.7 steps/s
[Step=4800 Epoch=23.4] | Loss=0.07451 | Reg=0.00398 | acc=0.9531 | L2-Norm=19.956 | L2-Norm(final)=3.793 | 4422.8 samples/s | 69.1 steps/s
[Step=4850 Epoch=23.7] | Loss=0.07017 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.976 | L2-Norm(final)=3.794 | 4529.1 samples/s | 70.8 steps/s
[Step=4900 Epoch=23.9] | Loss=0.06770 | Reg=0.00400 | acc=0.9531 | L2-Norm=19.996 | L2-Norm(final)=3.794 | 5914.4 samples/s | 92.4 steps/s
[Step=4950 Epoch=24.2] | Loss=0.06381 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.015 | L2-Norm(final)=3.795 | 2143.8 samples/s | 33.5 steps/s
[Step=5000 Epoch=24.4] | Loss=0.06042 | Reg=0.00401 | acc=0.9688 | L2-Norm=20.032 | L2-Norm(final)=3.797 | 4480.3 samples/s | 70.0 steps/s
[Step=5050 Epoch=24.6] | Loss=0.05765 | Reg=0.00402 | acc=0.9688 | L2-Norm=20.047 | L2-Norm(final)=3.799 | 4461.6 samples/s | 69.7 steps/s
[Step=5100 Epoch=24.9] | Loss=0.05563 | Reg=0.00402 | acc=0.9531 | L2-Norm=20.062 | L2-Norm(final)=3.800 | 5576.5 samples/s | 87.1 steps/s
[Step=5150 Epoch=25.1] | Loss=0.05349 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.076 | L2-Norm(final)=3.801 | 2225.3 samples/s | 34.8 steps/s
[Step=5200 Epoch=25.4] | Loss=0.05060 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.089 | L2-Norm(final)=3.803 | 4429.6 samples/s | 69.2 steps/s
[Step=5250 Epoch=25.6] | Loss=0.04921 | Reg=0.00404 | acc=0.9375 | L2-Norm=20.101 | L2-Norm(final)=3.805 | 4504.4 samples/s | 70.4 steps/s
[Step=5300 Epoch=25.9] | Loss=0.04813 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.112 | L2-Norm(final)=3.807 | 5085.2 samples/s | 79.5 steps/s
[Step=5350 Epoch=26.1] | Loss=0.04660 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.123 | L2-Norm(final)=3.808 | 2259.4 samples/s | 35.3 steps/s
[Step=5400 Epoch=26.3] | Loss=0.04517 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.134 | L2-Norm(final)=3.810 | 4486.3 samples/s | 70.1 steps/s
[Step=5450 Epoch=26.6] | Loss=0.04397 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.143 | L2-Norm(final)=3.811 | 4465.3 samples/s | 69.8 steps/s
[Step=5500 Epoch=26.8] | Loss=0.04281 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.152 | L2-Norm(final)=3.813 | 4786.3 samples/s | 74.8 steps/s
[Step=5550 Epoch=27.1] | Loss=0.04166 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.161 | L2-Norm(final)=3.814 | 2332.2 samples/s | 36.4 steps/s
[Step=5600 Epoch=27.3] | Loss=0.04068 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.168 | L2-Norm(final)=3.815 | 4558.3 samples/s | 71.2 steps/s
[Step=5650 Epoch=27.6] | Loss=0.03953 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.174 | L2-Norm(final)=3.817 | 4353.7 samples/s | 68.0 steps/s
[Step=5700 Epoch=27.8] | Loss=0.03861 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.179 | L2-Norm(final)=3.818 | 4539.0 samples/s | 70.9 steps/s
[Step=5750 Epoch=28.1] | Loss=0.03749 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.184 | L2-Norm(final)=3.819 | 2449.8 samples/s | 38.3 steps/s
[Step=5800 Epoch=28.3] | Loss=0.03648 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.188 | L2-Norm(final)=3.821 | 4441.3 samples/s | 69.4 steps/s
[Step=5850 Epoch=28.5] | Loss=0.03558 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.191 | L2-Norm(final)=3.823 | 4476.0 samples/s | 69.9 steps/s
[Step=5900 Epoch=28.8] | Loss=0.03490 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.193 | L2-Norm(final)=3.825 | 4408.6 samples/s | 68.9 steps/s
[Step=5950 Epoch=29.0] | Loss=0.03405 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.195 | L2-Norm(final)=3.827 | 2461.4 samples/s | 38.5 steps/s
[Step=6000 Epoch=29.3] | Loss=0.03321 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.197 | L2-Norm(final)=3.829 | 4424.3 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step6000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=19.5] | Loss=0.12330 | Reg=0.00360 | acc=0.8906 | L2-Norm=18.962 | L2-Norm(final)=3.115 | 5580.1 samples/s | 87.2 steps/s
[Step=4050 Epoch=19.7] | Loss=0.13480 | Reg=0.00361 | acc=0.8906 | L2-Norm=19.008 | L2-Norm(final)=3.155 | 4385.1 samples/s | 68.5 steps/s
[Step=4100 Epoch=20.0] | Loss=0.12832 | Reg=0.00364 | acc=0.9219 | L2-Norm=19.070 | L2-Norm(final)=3.199 | 4996.0 samples/s | 78.1 steps/s
[Step=4150 Epoch=20.2] | Loss=0.12723 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.129 | L2-Norm(final)=3.239 | 5155.8 samples/s | 80.6 steps/s
[Step=4200 Epoch=20.5] | Loss=0.12725 | Reg=0.00368 | acc=0.9062 | L2-Norm=19.186 | L2-Norm(final)=3.272 | 7552.4 samples/s | 118.0 steps/s
[Step=4250 Epoch=20.7] | Loss=0.12587 | Reg=0.00370 | acc=0.8750 | L2-Norm=19.239 | L2-Norm(final)=3.301 | 2206.9 samples/s | 34.5 steps/s
[Step=4300 Epoch=21.0] | Loss=0.12397 | Reg=0.00372 | acc=0.8594 | L2-Norm=19.292 | L2-Norm(final)=3.333 | 4987.2 samples/s | 77.9 steps/s
[Step=4350 Epoch=21.2] | Loss=0.12181 | Reg=0.00374 | acc=0.9375 | L2-Norm=19.348 | L2-Norm(final)=3.367 | 5075.6 samples/s | 79.3 steps/s
[Step=4400 Epoch=21.4] | Loss=0.12111 | Reg=0.00377 | acc=0.9531 | L2-Norm=19.403 | L2-Norm(final)=3.401 | 6855.4 samples/s | 107.1 steps/s
[Step=4450 Epoch=21.7] | Loss=0.11966 | Reg=0.00379 | acc=0.9375 | L2-Norm=19.455 | L2-Norm(final)=3.433 | 2317.4 samples/s | 36.2 steps/s
[Step=4500 Epoch=21.9] | Loss=0.11784 | Reg=0.00381 | acc=0.9688 | L2-Norm=19.508 | L2-Norm(final)=3.467 | 4978.5 samples/s | 77.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=21.9] | Loss=0.10662 | Reg=0.00402 | acc=0.9219 | L2-Norm=20.049 | L2-Norm(final)=3.813 | 5614.8 samples/s | 87.7 steps/s
[Step=4550 Epoch=22.2] | Loss=0.09936 | Reg=0.00404 | acc=0.9375 | L2-Norm=20.101 | L2-Norm(final)=3.832 | 3879.0 samples/s | 60.6 steps/s
[Step=4600 Epoch=22.4] | Loss=0.10170 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.122 | L2-Norm(final)=3.824 | 4464.5 samples/s | 69.8 steps/s
[Step=4650 Epoch=22.7] | Loss=0.09537 | Reg=0.00406 | acc=0.8906 | L2-Norm=20.140 | L2-Norm(final)=3.817 | 4465.7 samples/s | 69.8 steps/s
[Step=4700 Epoch=22.9] | Loss=0.09338 | Reg=0.00406 | acc=0.9062 | L2-Norm=20.158 | L2-Norm(final)=3.810 | 6507.9 samples/s | 101.7 steps/s
[Step=4750 Epoch=23.1] | Loss=0.08698 | Reg=0.00407 | acc=0.9688 | L2-Norm=20.181 | L2-Norm(final)=3.804 | 2106.5 samples/s | 32.9 steps/s
[Step=4800 Epoch=23.4] | Loss=0.08033 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.205 | L2-Norm(final)=3.802 | 4477.5 samples/s | 70.0 steps/s
[Step=4850 Epoch=23.6] | Loss=0.07585 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.226 | L2-Norm(final)=3.801 | 4467.6 samples/s | 69.8 steps/s
[Step=4900 Epoch=23.9] | Loss=0.07227 | Reg=0.00410 | acc=0.9688 | L2-Norm=20.246 | L2-Norm(final)=3.801 | 5832.5 samples/s | 91.1 steps/s
[Step=4950 Epoch=24.1] | Loss=0.06807 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.265 | L2-Norm(final)=3.802 | 2117.8 samples/s | 33.1 steps/s
[Step=5000 Epoch=24.4] | Loss=0.06477 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.281 | L2-Norm(final)=3.803 | 4464.7 samples/s | 69.8 steps/s
[Step=5050 Epoch=24.6] | Loss=0.06200 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.296 | L2-Norm(final)=3.806 | 4460.3 samples/s | 69.7 steps/s
[Step=5100 Epoch=24.8] | Loss=0.05901 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.312 | L2-Norm(final)=3.809 | 5356.9 samples/s | 83.7 steps/s
[Step=5150 Epoch=25.1] | Loss=0.05670 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.327 | L2-Norm(final)=3.812 | 2272.6 samples/s | 35.5 steps/s
[Step=5200 Epoch=25.3] | Loss=0.05392 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.341 | L2-Norm(final)=3.816 | 4367.0 samples/s | 68.2 steps/s
[Step=5250 Epoch=25.6] | Loss=0.05240 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.354 | L2-Norm(final)=3.819 | 4409.5 samples/s | 68.9 steps/s
[Step=5300 Epoch=25.8] | Loss=0.05055 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.365 | L2-Norm(final)=3.822 | 4928.4 samples/s | 77.0 steps/s
[Step=5350 Epoch=26.1] | Loss=0.04887 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.375 | L2-Norm(final)=3.825 | 2354.5 samples/s | 36.8 steps/s
[Step=5400 Epoch=26.3] | Loss=0.04702 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.384 | L2-Norm(final)=3.829 | 4391.9 samples/s | 68.6 steps/s
[Step=5450 Epoch=26.6] | Loss=0.04573 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.392 | L2-Norm(final)=3.832 | 4452.2 samples/s | 69.6 steps/s
[Step=5500 Epoch=26.8] | Loss=0.04483 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.399 | L2-Norm(final)=3.835 | 4609.6 samples/s | 72.0 steps/s
[Step=5550 Epoch=27.0] | Loss=0.04345 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.407 | L2-Norm(final)=3.837 | 2434.9 samples/s | 38.0 steps/s
[Step=5600 Epoch=27.3] | Loss=0.04213 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.414 | L2-Norm(final)=3.841 | 4420.3 samples/s | 69.1 steps/s
[Step=5650 Epoch=27.5] | Loss=0.04104 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.420 | L2-Norm(final)=3.844 | 4434.7 samples/s | 69.3 steps/s
[Step=5700 Epoch=27.8] | Loss=0.04001 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.425 | L2-Norm(final)=3.847 | 4455.4 samples/s | 69.6 steps/s
[Step=5750 Epoch=28.0] | Loss=0.03947 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.429 | L2-Norm(final)=3.849 | 2464.0 samples/s | 38.5 steps/s
[Step=5800 Epoch=28.3] | Loss=0.03861 | Reg=0.00418 | acc=0.9688 | L2-Norm=20.434 | L2-Norm(final)=3.851 | 4512.3 samples/s | 70.5 steps/s
[Step=5850 Epoch=28.5] | Loss=0.03809 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.439 | L2-Norm(final)=3.854 | 4426.1 samples/s | 69.2 steps/s
[Step=5900 Epoch=28.7] | Loss=0.03730 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.445 | L2-Norm(final)=3.856 | 4503.9 samples/s | 70.4 steps/s
[Step=5950 Epoch=29.0] | Loss=0.03663 | Reg=0.00418 | acc=0.9531 | L2-Norm=20.450 | L2-Norm(final)=3.858 | 2499.1 samples/s | 39.0 steps/s
[Step=6000 Epoch=29.2] | Loss=0.03596 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.455 | L2-Norm(final)=3.860 | 4351.1 samples/s | 68.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step6000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=19.5] | Loss=0.10944 | Reg=0.00356 | acc=0.9375 | L2-Norm=18.856 | L2-Norm(final)=3.191 | 5209.2 samples/s | 81.4 steps/s
[Step=4050 Epoch=19.8] | Loss=0.14254 | Reg=0.00357 | acc=0.8750 | L2-Norm=18.892 | L2-Norm(final)=3.227 | 4669.1 samples/s | 73.0 steps/s
[Step=4100 Epoch=20.0] | Loss=0.13893 | Reg=0.00358 | acc=0.9062 | L2-Norm=18.930 | L2-Norm(final)=3.258 | 4980.2 samples/s | 77.8 steps/s
[Step=4150 Epoch=20.2] | Loss=0.13716 | Reg=0.00360 | acc=0.9219 | L2-Norm=18.966 | L2-Norm(final)=3.288 | 4972.8 samples/s | 77.7 steps/s
[Step=4200 Epoch=20.5] | Loss=0.13603 | Reg=0.00361 | acc=0.9062 | L2-Norm=19.001 | L2-Norm(final)=3.315 | 7922.5 samples/s | 123.8 steps/s
[Step=4250 Epoch=20.7] | Loss=0.13347 | Reg=0.00362 | acc=0.8750 | L2-Norm=19.035 | L2-Norm(final)=3.341 | 2240.6 samples/s | 35.0 steps/s
[Step=4300 Epoch=21.0] | Loss=0.13197 | Reg=0.00364 | acc=0.9219 | L2-Norm=19.067 | L2-Norm(final)=3.368 | 5041.3 samples/s | 78.8 steps/s
[Step=4350 Epoch=21.2] | Loss=0.12978 | Reg=0.00365 | acc=0.9219 | L2-Norm=19.097 | L2-Norm(final)=3.393 | 4833.5 samples/s | 75.5 steps/s
[Step=4400 Epoch=21.5] | Loss=0.12854 | Reg=0.00366 | acc=0.9531 | L2-Norm=19.129 | L2-Norm(final)=3.419 | 6973.3 samples/s | 109.0 steps/s
[Step=4450 Epoch=21.7] | Loss=0.12628 | Reg=0.00367 | acc=0.9531 | L2-Norm=19.163 | L2-Norm(final)=3.446 | 2314.6 samples/s | 36.2 steps/s
[Step=4500 Epoch=21.9] | Loss=0.12481 | Reg=0.00369 | acc=0.9219 | L2-Norm=19.197 | L2-Norm(final)=3.475 | 5219.4 samples/s | 81.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=21.9] | Loss=0.09734 | Reg=0.00382 | acc=0.9219 | L2-Norm=19.546 | L2-Norm(final)=3.772 | 5771.8 samples/s | 90.2 steps/s
[Step=4550 Epoch=22.2] | Loss=0.10641 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.586 | L2-Norm(final)=3.777 | 3870.0 samples/s | 60.5 steps/s
[Step=4600 Epoch=22.4] | Loss=0.10334 | Reg=0.00385 | acc=0.8906 | L2-Norm=19.622 | L2-Norm(final)=3.764 | 4513.3 samples/s | 70.5 steps/s
[Step=4650 Epoch=22.7] | Loss=0.09570 | Reg=0.00386 | acc=0.8594 | L2-Norm=19.651 | L2-Norm(final)=3.758 | 4479.4 samples/s | 70.0 steps/s
[Step=4700 Epoch=22.9] | Loss=0.09008 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.677 | L2-Norm(final)=3.753 | 6330.2 samples/s | 98.9 steps/s
[Step=4750 Epoch=23.2] | Loss=0.08062 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.699 | L2-Norm(final)=3.749 | 2090.9 samples/s | 32.7 steps/s
[Step=4800 Epoch=23.4] | Loss=0.07406 | Reg=0.00389 | acc=0.9531 | L2-Norm=19.720 | L2-Norm(final)=3.749 | 4464.1 samples/s | 69.8 steps/s
[Step=4850 Epoch=23.7] | Loss=0.06990 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.740 | L2-Norm(final)=3.750 | 4466.9 samples/s | 69.8 steps/s
[Step=4900 Epoch=23.9] | Loss=0.06674 | Reg=0.00390 | acc=0.9375 | L2-Norm=19.759 | L2-Norm(final)=3.751 | 5917.7 samples/s | 92.5 steps/s
[Step=4950 Epoch=24.1] | Loss=0.06367 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.777 | L2-Norm(final)=3.750 | 2162.1 samples/s | 33.8 steps/s
[Step=5000 Epoch=24.4] | Loss=0.06034 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.793 | L2-Norm(final)=3.751 | 4429.6 samples/s | 69.2 steps/s
[Step=5050 Epoch=24.6] | Loss=0.05735 | Reg=0.00392 | acc=0.9531 | L2-Norm=19.807 | L2-Norm(final)=3.752 | 4452.8 samples/s | 69.6 steps/s
[Step=5100 Epoch=24.9] | Loss=0.05538 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.820 | L2-Norm(final)=3.753 | 5370.5 samples/s | 83.9 steps/s
[Step=5150 Epoch=25.1] | Loss=0.05314 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.833 | L2-Norm(final)=3.754 | 2277.1 samples/s | 35.6 steps/s
[Step=5200 Epoch=25.4] | Loss=0.05073 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.845 | L2-Norm(final)=3.755 | 4406.0 samples/s | 68.8 steps/s
[Step=5250 Epoch=25.6] | Loss=0.04924 | Reg=0.00394 | acc=0.9531 | L2-Norm=19.856 | L2-Norm(final)=3.757 | 4517.4 samples/s | 70.6 steps/s
[Step=5300 Epoch=25.8] | Loss=0.04762 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.866 | L2-Norm(final)=3.758 | 4914.6 samples/s | 76.8 steps/s
[Step=5350 Epoch=26.1] | Loss=0.04613 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.877 | L2-Norm(final)=3.760 | 2359.6 samples/s | 36.9 steps/s
[Step=5400 Epoch=26.3] | Loss=0.04480 | Reg=0.00396 | acc=0.9688 | L2-Norm=19.888 | L2-Norm(final)=3.762 | 4358.8 samples/s | 68.1 steps/s
[Step=5450 Epoch=26.6] | Loss=0.04334 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.898 | L2-Norm(final)=3.764 | 4427.2 samples/s | 69.2 steps/s
[Step=5500 Epoch=26.8] | Loss=0.04248 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.909 | L2-Norm(final)=3.766 | 4617.7 samples/s | 72.2 steps/s
[Step=5550 Epoch=27.1] | Loss=0.04136 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.919 | L2-Norm(final)=3.768 | 2423.5 samples/s | 37.9 steps/s
[Step=5600 Epoch=27.3] | Loss=0.04037 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.928 | L2-Norm(final)=3.770 | 4500.6 samples/s | 70.3 steps/s
[Step=5650 Epoch=27.6] | Loss=0.03929 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.936 | L2-Norm(final)=3.772 | 4448.2 samples/s | 69.5 steps/s
[Step=5700 Epoch=27.8] | Loss=0.03850 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.944 | L2-Norm(final)=3.774 | 4450.3 samples/s | 69.5 steps/s
[Step=5750 Epoch=28.0] | Loss=0.03781 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.952 | L2-Norm(final)=3.776 | 2417.4 samples/s | 37.8 steps/s
[Step=5800 Epoch=28.3] | Loss=0.03712 | Reg=0.00398 | acc=0.9688 | L2-Norm=19.961 | L2-Norm(final)=3.778 | 4466.3 samples/s | 69.8 steps/s
[Step=5850 Epoch=28.5] | Loss=0.03628 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.971 | L2-Norm(final)=3.780 | 4540.0 samples/s | 70.9 steps/s
[Step=5900 Epoch=28.8] | Loss=0.03550 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.980 | L2-Norm(final)=3.783 | 4421.9 samples/s | 69.1 steps/s
[Step=5950 Epoch=29.0] | Loss=0.03492 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.988 | L2-Norm(final)=3.785 | 2458.8 samples/s | 38.4 steps/s
[Step=6000 Epoch=29.3] | Loss=0.03449 | Reg=0.00400 | acc=0.9844 | L2-Norm=19.997 | L2-Norm(final)=3.787 | 4457.8 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step6000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=19.6] | Loss=0.12448 | Reg=0.00358 | acc=0.9062 | L2-Norm=18.919 | L2-Norm(final)=3.310 | 5111.1 samples/s | 79.9 steps/s
[Step=4050 Epoch=19.9] | Loss=0.13662 | Reg=0.00359 | acc=0.9062 | L2-Norm=18.957 | L2-Norm(final)=3.357 | 4470.1 samples/s | 69.8 steps/s
[Step=4100 Epoch=20.1] | Loss=0.12976 | Reg=0.00361 | acc=0.8594 | L2-Norm=19.011 | L2-Norm(final)=3.404 | 5034.0 samples/s | 78.7 steps/s
[Step=4150 Epoch=20.4] | Loss=0.12832 | Reg=0.00363 | acc=0.9219 | L2-Norm=19.055 | L2-Norm(final)=3.442 | 5078.1 samples/s | 79.3 steps/s
[Step=4200 Epoch=20.6] | Loss=0.12686 | Reg=0.00365 | acc=0.9062 | L2-Norm=19.100 | L2-Norm(final)=3.479 | 7938.9 samples/s | 124.0 steps/s
[Step=4250 Epoch=20.8] | Loss=0.12488 | Reg=0.00367 | acc=0.9531 | L2-Norm=19.146 | L2-Norm(final)=3.515 | 2183.8 samples/s | 34.1 steps/s
[Step=4300 Epoch=21.1] | Loss=0.12289 | Reg=0.00368 | acc=0.8906 | L2-Norm=19.193 | L2-Norm(final)=3.552 | 5130.3 samples/s | 80.2 steps/s
[Step=4350 Epoch=21.3] | Loss=0.12081 | Reg=0.00370 | acc=0.9688 | L2-Norm=19.245 | L2-Norm(final)=3.589 | 4967.5 samples/s | 77.6 steps/s
[Step=4400 Epoch=21.6] | Loss=0.11931 | Reg=0.00372 | acc=0.9219 | L2-Norm=19.295 | L2-Norm(final)=3.627 | 7442.8 samples/s | 116.3 steps/s
[Step=4450 Epoch=21.8] | Loss=0.11797 | Reg=0.00374 | acc=0.9219 | L2-Norm=19.345 | L2-Norm(final)=3.664 | 2231.7 samples/s | 34.9 steps/s
[Step=4500 Epoch=22.1] | Loss=0.11681 | Reg=0.00376 | acc=0.9062 | L2-Norm=19.394 | L2-Norm(final)=3.702 | 4985.0 samples/s | 77.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=22.1] | Loss=0.08653 | Reg=0.00396 | acc=0.9688 | L2-Norm=19.888 | L2-Norm(final)=4.081 | 5364.7 samples/s | 83.8 steps/s
[Step=4550 Epoch=22.3] | Loss=0.10420 | Reg=0.00398 | acc=0.9219 | L2-Norm=19.953 | L2-Norm(final)=4.088 | 4062.0 samples/s | 63.5 steps/s
[Step=4600 Epoch=22.6] | Loss=0.09348 | Reg=0.00400 | acc=0.9688 | L2-Norm=19.998 | L2-Norm(final)=4.077 | 4448.2 samples/s | 69.5 steps/s
[Step=4650 Epoch=22.8] | Loss=0.09160 | Reg=0.00401 | acc=0.9531 | L2-Norm=20.033 | L2-Norm(final)=4.071 | 4522.8 samples/s | 70.7 steps/s
[Step=4700 Epoch=23.0] | Loss=0.08727 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.065 | L2-Norm(final)=4.065 | 6612.6 samples/s | 103.3 steps/s
[Step=4750 Epoch=23.3] | Loss=0.07977 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.094 | L2-Norm(final)=4.061 | 2058.8 samples/s | 32.2 steps/s
[Step=4800 Epoch=23.5] | Loss=0.07410 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.123 | L2-Norm(final)=4.063 | 4394.1 samples/s | 68.7 steps/s
[Step=4850 Epoch=23.8] | Loss=0.07050 | Reg=0.00406 | acc=0.9531 | L2-Norm=20.149 | L2-Norm(final)=4.063 | 4476.5 samples/s | 69.9 steps/s
[Step=4900 Epoch=24.0] | Loss=0.06714 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.172 | L2-Norm(final)=4.063 | 6216.1 samples/s | 97.1 steps/s
[Step=4950 Epoch=24.3] | Loss=0.06302 | Reg=0.00408 | acc=0.9531 | L2-Norm=20.193 | L2-Norm(final)=4.063 | 2124.8 samples/s | 33.2 steps/s
[Step=5000 Epoch=24.5] | Loss=0.05968 | Reg=0.00409 | acc=0.9531 | L2-Norm=20.211 | L2-Norm(final)=4.066 | 4465.6 samples/s | 69.8 steps/s
[Step=5050 Epoch=24.8] | Loss=0.05692 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.228 | L2-Norm(final)=4.068 | 4473.6 samples/s | 69.9 steps/s
[Step=5100 Epoch=25.0] | Loss=0.05461 | Reg=0.00410 | acc=0.9219 | L2-Norm=20.245 | L2-Norm(final)=4.071 | 5861.0 samples/s | 91.6 steps/s
[Step=5150 Epoch=25.3] | Loss=0.05181 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.260 | L2-Norm(final)=4.074 | 2132.6 samples/s | 33.3 steps/s
[Step=5200 Epoch=25.5] | Loss=0.04938 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.274 | L2-Norm(final)=4.078 | 4464.7 samples/s | 69.8 steps/s
[Step=5250 Epoch=25.7] | Loss=0.04764 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.287 | L2-Norm(final)=4.082 | 4476.2 samples/s | 69.9 steps/s
[Step=5300 Epoch=26.0] | Loss=0.04592 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.298 | L2-Norm(final)=4.087 | 5491.8 samples/s | 85.8 steps/s
[Step=5350 Epoch=26.2] | Loss=0.04431 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.308 | L2-Norm(final)=4.091 | 2230.3 samples/s | 34.8 steps/s
[Step=5400 Epoch=26.5] | Loss=0.04251 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.319 | L2-Norm(final)=4.096 | 4469.8 samples/s | 69.8 steps/s
[Step=5450 Epoch=26.7] | Loss=0.04113 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.328 | L2-Norm(final)=4.100 | 4469.3 samples/s | 69.8 steps/s
[Step=5500 Epoch=27.0] | Loss=0.04038 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.338 | L2-Norm(final)=4.104 | 5108.9 samples/s | 79.8 steps/s
[Step=5550 Epoch=27.2] | Loss=0.03946 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.347 | L2-Norm(final)=4.107 | 2259.7 samples/s | 35.3 steps/s
[Step=5600 Epoch=27.5] | Loss=0.03835 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.355 | L2-Norm(final)=4.111 | 4418.2 samples/s | 69.0 steps/s
[Step=5650 Epoch=27.7] | Loss=0.03737 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.363 | L2-Norm(final)=4.114 | 4478.5 samples/s | 70.0 steps/s
[Step=5700 Epoch=28.0] | Loss=0.03656 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.371 | L2-Norm(final)=4.118 | 4950.7 samples/s | 77.4 steps/s
[Step=5750 Epoch=28.2] | Loss=0.03565 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.378 | L2-Norm(final)=4.121 | 2307.2 samples/s | 36.0 steps/s
[Step=5800 Epoch=28.4] | Loss=0.03483 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.385 | L2-Norm(final)=4.124 | 4442.4 samples/s | 69.4 steps/s
[Step=5850 Epoch=28.7] | Loss=0.03419 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.392 | L2-Norm(final)=4.127 | 4412.2 samples/s | 68.9 steps/s
[Step=5900 Epoch=28.9] | Loss=0.03369 | Reg=0.00416 | acc=0.9688 | L2-Norm=20.399 | L2-Norm(final)=4.130 | 4694.8 samples/s | 73.4 steps/s
[Step=5950 Epoch=29.2] | Loss=0.03316 | Reg=0.00416 | acc=0.9688 | L2-Norm=20.405 | L2-Norm(final)=4.133 | 2437.0 samples/s | 38.1 steps/s
[Step=6000 Epoch=29.4] | Loss=0.03235 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.412 | L2-Norm(final)=4.136 | 4377.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step6000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=37.9] | Loss=0.01022 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.682 | L2-Norm(final)=2.898 | 5001.6 samples/s | 78.2 steps/s
[Step=4050 Epoch=38.4] | Loss=0.04272 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.746 | L2-Norm(final)=2.954 | 4284.0 samples/s | 66.9 steps/s
[Step=4100 Epoch=38.9] | Loss=0.03663 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.817 | L2-Norm(final)=2.997 | 7119.2 samples/s | 111.2 steps/s
[Step=4150 Epoch=39.3] | Loss=0.03292 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.876 | L2-Norm(final)=3.030 | 2107.2 samples/s | 32.9 steps/s
[Step=4200 Epoch=39.8] | Loss=0.03055 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.932 | L2-Norm(final)=3.061 | 6643.3 samples/s | 103.8 steps/s
[Step=4250 Epoch=40.3] | Loss=0.02882 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.982 | L2-Norm(final)=3.092 | 2197.5 samples/s | 34.3 steps/s
[Step=4300 Epoch=40.7] | Loss=0.02724 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.029 | L2-Norm(final)=3.122 | 5860.7 samples/s | 91.6 steps/s
[Step=4350 Epoch=41.2] | Loss=0.02609 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.075 | L2-Norm(final)=3.150 | 2324.5 samples/s | 36.3 steps/s
[Step=4400 Epoch=41.7] | Loss=0.02491 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.121 | L2-Norm(final)=3.178 | 5308.7 samples/s | 82.9 steps/s
[Step=4450 Epoch=42.2] | Loss=0.02411 | Reg=0.00201 | acc=0.9688 | L2-Norm=14.165 | L2-Norm(final)=3.205 | 2402.2 samples/s | 37.5 steps/s
[Step=4500 Epoch=42.6] | Loss=0.02322 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.208 | L2-Norm(final)=3.232 | 4994.9 samples/s | 78.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=42.7] | Loss=0.00286 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=3.497 | 5250.2 samples/s | 82.0 steps/s
[Step=4550 Epoch=43.1] | Loss=0.03922 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.783 | L2-Norm(final)=3.488 | 3876.8 samples/s | 60.6 steps/s
[Step=4600 Epoch=43.6] | Loss=0.02635 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.904 | L2-Norm(final)=3.458 | 6029.1 samples/s | 94.2 steps/s
[Step=4650 Epoch=44.1] | Loss=0.01803 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=3.449 | 2017.6 samples/s | 31.5 steps/s
[Step=4700 Epoch=44.5] | Loss=0.01373 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=3.445 | 5668.9 samples/s | 88.6 steps/s
[Step=4750 Epoch=45.0] | Loss=0.01100 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=3.444 | 2068.3 samples/s | 32.3 steps/s
[Step=4800 Epoch=45.5] | Loss=0.00919 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=3.443 | 5145.5 samples/s | 80.4 steps/s
[Step=4850 Epoch=46.0] | Loss=0.00788 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=3.443 | 2199.0 samples/s | 34.4 steps/s
[Step=4900 Epoch=46.4] | Loss=0.00690 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=3.443 | 4579.0 samples/s | 71.5 steps/s
[Step=4950 Epoch=46.9] | Loss=0.00613 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=3.443 | 2255.5 samples/s | 35.2 steps/s
[Step=5000 Epoch=47.4] | Loss=0.00552 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=3.443 | 4349.1 samples/s | 68.0 steps/s
[Step=5050 Epoch=47.9] | Loss=0.00502 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.910 | L2-Norm(final)=3.443 | 2330.6 samples/s | 36.4 steps/s
[Step=5100 Epoch=48.3] | Loss=0.00461 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.897 | L2-Norm(final)=3.443 | 4369.2 samples/s | 68.3 steps/s
[Step=5150 Epoch=48.8] | Loss=0.00425 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=3.444 | 2368.0 samples/s | 37.0 steps/s
[Step=5200 Epoch=49.3] | Loss=0.00395 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.869 | L2-Norm(final)=3.444 | 4321.6 samples/s | 67.5 steps/s
[Step=5250 Epoch=49.7] | Loss=0.00369 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.854 | L2-Norm(final)=3.444 | 2325.2 samples/s | 36.3 steps/s
[Step=5300 Epoch=50.2] | Loss=0.00346 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=3.444 | 4350.5 samples/s | 68.0 steps/s
[Step=5350 Epoch=50.7] | Loss=0.00326 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.824 | L2-Norm(final)=3.445 | 2563.4 samples/s | 40.1 steps/s
[Step=5400 Epoch=51.2] | Loss=0.00308 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=3.445 | 3691.6 samples/s | 57.7 steps/s
[Step=5450 Epoch=51.6] | Loss=0.00291 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=3.445 | 6273.3 samples/s | 98.0 steps/s
[Step=5500 Epoch=52.1] | Loss=0.00277 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=3.445 | 1991.8 samples/s | 31.1 steps/s
[Step=5550 Epoch=52.6] | Loss=0.00264 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=3.446 | 5820.5 samples/s | 90.9 steps/s
[Step=5600 Epoch=53.1] | Loss=0.00252 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=3.446 | 2093.7 samples/s | 32.7 steps/s
[Step=5650 Epoch=53.5] | Loss=0.00241 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=3.446 | 5171.2 samples/s | 80.8 steps/s
[Step=5700 Epoch=54.0] | Loss=0.00231 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.713 | L2-Norm(final)=3.446 | 2167.7 samples/s | 33.9 steps/s
[Step=5750 Epoch=54.5] | Loss=0.00222 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.697 | L2-Norm(final)=3.447 | 4836.4 samples/s | 75.6 steps/s
[Step=5800 Epoch=55.0] | Loss=0.00213 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=3.447 | 2234.0 samples/s | 34.9 steps/s
[Step=5850 Epoch=55.4] | Loss=0.00205 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=3.447 | 4454.2 samples/s | 69.6 steps/s
[Step=5900 Epoch=55.9] | Loss=0.00198 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=3.448 | 2341.2 samples/s | 36.6 steps/s
[Step=5950 Epoch=56.4] | Loss=0.00191 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.630 | L2-Norm(final)=3.448 | 4265.8 samples/s | 66.7 steps/s
[Step=6000 Epoch=56.9] | Loss=0.00185 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=3.448 | 2349.1 samples/s | 36.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step6000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=38.1] | Loss=0.06014 | Reg=0.00191 | acc=0.9688 | L2-Norm=13.834 | L2-Norm(final)=2.854 | 5748.0 samples/s | 89.8 steps/s
[Step=4050 Epoch=38.5] | Loss=0.04702 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.898 | L2-Norm(final)=2.893 | 3966.3 samples/s | 62.0 steps/s
[Step=4100 Epoch=39.0] | Loss=0.04200 | Reg=0.00195 | acc=0.9531 | L2-Norm=13.960 | L2-Norm(final)=2.934 | 7481.0 samples/s | 116.9 steps/s
[Step=4150 Epoch=39.5] | Loss=0.03798 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.015 | L2-Norm(final)=2.970 | 2150.3 samples/s | 33.6 steps/s
[Step=4200 Epoch=40.0] | Loss=0.03491 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.070 | L2-Norm(final)=3.009 | 6374.6 samples/s | 99.6 steps/s
[Step=4250 Epoch=40.4] | Loss=0.03208 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.128 | L2-Norm(final)=3.050 | 2150.7 samples/s | 33.6 steps/s
[Step=4300 Epoch=40.9] | Loss=0.03038 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.186 | L2-Norm(final)=3.090 | 5780.3 samples/s | 90.3 steps/s
[Step=4350 Epoch=41.4] | Loss=0.02866 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.244 | L2-Norm(final)=3.129 | 2337.1 samples/s | 36.5 steps/s
[Step=4400 Epoch=41.9] | Loss=0.02713 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.297 | L2-Norm(final)=3.167 | 5340.6 samples/s | 83.4 steps/s
[Step=4450 Epoch=42.3] | Loss=0.02572 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.349 | L2-Norm(final)=3.204 | 2362.8 samples/s | 36.9 steps/s
[Step=4500 Epoch=42.8] | Loss=0.02455 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.398 | L2-Norm(final)=3.240 | 4675.8 samples/s | 73.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=42.8] | Loss=0.00888 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.873 | L2-Norm(final)=3.601 | 5403.5 samples/s | 84.4 steps/s
[Step=4550 Epoch=43.3] | Loss=0.03805 | Reg=0.00226 | acc=0.9375 | L2-Norm=15.030 | L2-Norm(final)=3.602 | 3656.1 samples/s | 57.1 steps/s
[Step=4600 Epoch=43.8] | Loss=0.02452 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=3.588 | 6254.1 samples/s | 97.7 steps/s
[Step=4650 Epoch=44.2] | Loss=0.01655 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=3.586 | 1989.4 samples/s | 31.1 steps/s
[Step=4700 Epoch=44.7] | Loss=0.01247 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=3.586 | 5634.0 samples/s | 88.0 steps/s
[Step=4750 Epoch=45.2] | Loss=0.01010 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.232 | L2-Norm(final)=3.587 | 2071.6 samples/s | 32.4 steps/s
[Step=4800 Epoch=45.7] | Loss=0.00845 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=3.588 | 5078.6 samples/s | 79.4 steps/s
[Step=4850 Epoch=46.1] | Loss=0.00725 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=3.589 | 2137.1 samples/s | 33.4 steps/s
[Step=4900 Epoch=46.6] | Loss=0.00635 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.219 | L2-Norm(final)=3.590 | 4619.7 samples/s | 72.2 steps/s
[Step=4950 Epoch=47.1] | Loss=0.00565 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.209 | L2-Norm(final)=3.591 | 2241.3 samples/s | 35.0 steps/s
[Step=5000 Epoch=47.6] | Loss=0.00508 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=3.592 | 4342.2 samples/s | 67.8 steps/s
[Step=5050 Epoch=48.0] | Loss=0.00462 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=3.593 | 2317.5 samples/s | 36.2 steps/s
[Step=5100 Epoch=48.5] | Loss=0.00424 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=3.593 | 4165.1 samples/s | 65.1 steps/s
[Step=5150 Epoch=49.0] | Loss=0.00392 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=3.594 | 2371.1 samples/s | 37.0 steps/s
[Step=5200 Epoch=49.5] | Loss=0.00364 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=3.595 | 4257.4 samples/s | 66.5 steps/s
[Step=5250 Epoch=49.9] | Loss=0.00340 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=3.595 | 2338.1 samples/s | 36.5 steps/s
[Step=5300 Epoch=50.4] | Loss=0.00319 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=3.596 | 4190.2 samples/s | 65.5 steps/s
[Step=5350 Epoch=50.9] | Loss=0.00300 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=3.596 | 2458.0 samples/s | 38.4 steps/s
[Step=5400 Epoch=51.4] | Loss=0.00283 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.080 | L2-Norm(final)=3.597 | 4008.5 samples/s | 62.6 steps/s
[Step=5450 Epoch=51.8] | Loss=0.00268 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=3.597 | 6378.0 samples/s | 99.7 steps/s
[Step=5500 Epoch=52.3] | Loss=0.00255 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=3.598 | 1980.8 samples/s | 30.9 steps/s
[Step=5550 Epoch=52.8] | Loss=0.00243 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=3.598 | 5848.8 samples/s | 91.4 steps/s
[Step=5600 Epoch=53.3] | Loss=0.00232 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=3.599 | 2035.8 samples/s | 31.8 steps/s
[Step=5650 Epoch=53.7] | Loss=0.00222 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=3.599 | 5254.9 samples/s | 82.1 steps/s
[Step=5700 Epoch=54.2] | Loss=0.00213 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=3.600 | 2093.7 samples/s | 32.7 steps/s
[Step=5750 Epoch=54.7] | Loss=0.00204 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=3.600 | 4827.6 samples/s | 75.4 steps/s
[Step=5800 Epoch=55.2] | Loss=0.00196 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=3.600 | 2181.6 samples/s | 34.1 steps/s
[Step=5850 Epoch=55.6] | Loss=0.00189 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=3.601 | 4429.9 samples/s | 69.2 steps/s
[Step=5900 Epoch=56.1] | Loss=0.00182 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.906 | L2-Norm(final)=3.601 | 2268.1 samples/s | 35.4 steps/s
[Step=5950 Epoch=56.6] | Loss=0.00176 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.888 | L2-Norm(final)=3.601 | 4139.5 samples/s | 64.7 steps/s
[Step=6000 Epoch=57.1] | Loss=0.00170 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=3.602 | 2333.0 samples/s | 36.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step6000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=38.2] | Loss=0.07090 | Reg=0.00211 | acc=0.9531 | L2-Norm=14.510 | L2-Norm(final)=3.007 | 5572.8 samples/s | 87.1 steps/s
[Step=4050 Epoch=38.7] | Loss=0.05607 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=3.049 | 3894.4 samples/s | 60.9 steps/s
[Step=4100 Epoch=39.2] | Loss=0.04991 | Reg=0.00216 | acc=0.9531 | L2-Norm=14.698 | L2-Norm(final)=3.090 | 7567.3 samples/s | 118.2 steps/s
[Step=4150 Epoch=39.6] | Loss=0.04463 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=3.125 | 2104.6 samples/s | 32.9 steps/s
[Step=4200 Epoch=40.1] | Loss=0.04197 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.868 | L2-Norm(final)=3.158 | 6707.1 samples/s | 104.8 steps/s
[Step=4250 Epoch=40.6] | Loss=0.03891 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.942 | L2-Norm(final)=3.189 | 2135.7 samples/s | 33.4 steps/s
[Step=4300 Epoch=41.1] | Loss=0.03649 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.011 | L2-Norm(final)=3.218 | 6176.7 samples/s | 96.5 steps/s
[Step=4350 Epoch=41.5] | Loss=0.03465 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.076 | L2-Norm(final)=3.246 | 2223.6 samples/s | 34.7 steps/s
[Step=4400 Epoch=42.0] | Loss=0.03318 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=3.273 | 5632.4 samples/s | 88.0 steps/s
[Step=4450 Epoch=42.5] | Loss=0.03155 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=3.299 | 2327.4 samples/s | 36.4 steps/s
[Step=4500 Epoch=43.0] | Loss=0.03033 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.248 | L2-Norm(final)=3.324 | 5088.8 samples/s | 79.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=43.0] | Loss=0.00753 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.774 | L2-Norm(final)=3.571 | 5368.9 samples/s | 83.9 steps/s
[Step=4550 Epoch=43.4] | Loss=0.02352 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.830 | L2-Norm(final)=3.574 | 3652.0 samples/s | 57.1 steps/s
[Step=4600 Epoch=43.9] | Loss=0.01652 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.870 | L2-Norm(final)=3.577 | 6271.4 samples/s | 98.0 steps/s
[Step=4650 Epoch=44.4] | Loss=0.01143 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=3.578 | 1964.9 samples/s | 30.7 steps/s
[Step=4700 Epoch=44.9] | Loss=0.00861 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.908 | L2-Norm(final)=3.579 | 5759.4 samples/s | 90.0 steps/s
[Step=4750 Epoch=45.4] | Loss=0.00690 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.907 | L2-Norm(final)=3.580 | 2048.3 samples/s | 32.0 steps/s
[Step=4800 Epoch=45.8] | Loss=0.00576 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.901 | L2-Norm(final)=3.581 | 5336.9 samples/s | 83.4 steps/s
[Step=4850 Epoch=46.3] | Loss=0.00494 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=3.582 | 2081.8 samples/s | 32.5 steps/s
[Step=4900 Epoch=46.8] | Loss=0.00433 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=3.583 | 4927.7 samples/s | 77.0 steps/s
[Step=4950 Epoch=47.3] | Loss=0.00385 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.868 | L2-Norm(final)=3.584 | 2173.7 samples/s | 34.0 steps/s
[Step=5000 Epoch=47.7] | Loss=0.00347 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.855 | L2-Norm(final)=3.584 | 4606.5 samples/s | 72.0 steps/s
[Step=5050 Epoch=48.2] | Loss=0.00316 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.840 | L2-Norm(final)=3.585 | 2240.1 samples/s | 35.0 steps/s
[Step=5100 Epoch=48.7] | Loss=0.00290 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=3.585 | 4285.8 samples/s | 67.0 steps/s
[Step=5150 Epoch=49.2] | Loss=0.00267 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=3.586 | 2296.1 samples/s | 35.9 steps/s
[Step=5200 Epoch=49.7] | Loss=0.00248 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.794 | L2-Norm(final)=3.586 | 4217.4 samples/s | 65.9 steps/s
[Step=5250 Epoch=50.1] | Loss=0.00232 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=3.587 | 2347.9 samples/s | 36.7 steps/s
[Step=5300 Epoch=50.6] | Loss=0.00218 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=3.587 | 4190.9 samples/s | 65.5 steps/s
[Step=5350 Epoch=51.1] | Loss=0.00205 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.744 | L2-Norm(final)=3.588 | 2356.4 samples/s | 36.8 steps/s
[Step=5400 Epoch=51.6] | Loss=0.00194 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=3.588 | 4115.9 samples/s | 64.3 steps/s
[Step=5450 Epoch=52.0] | Loss=0.00183 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.709 | L2-Norm(final)=3.588 | 2336.0 samples/s | 36.5 steps/s
[Step=5500 Epoch=52.5] | Loss=0.00174 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.692 | L2-Norm(final)=3.589 | 4194.8 samples/s | 65.5 steps/s
[Step=5550 Epoch=53.0] | Loss=0.00166 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=3.589 | 6878.1 samples/s | 107.5 steps/s
[Step=5600 Epoch=53.5] | Loss=0.00159 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.656 | L2-Norm(final)=3.590 | 1927.7 samples/s | 30.1 steps/s
[Step=5650 Epoch=54.0] | Loss=0.00152 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.638 | L2-Norm(final)=3.590 | 6185.7 samples/s | 96.7 steps/s
[Step=5700 Epoch=54.4] | Loss=0.00146 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.619 | L2-Norm(final)=3.590 | 1972.4 samples/s | 30.8 steps/s
[Step=5750 Epoch=54.9] | Loss=0.00140 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=3.590 | 5747.7 samples/s | 89.8 steps/s
[Step=5800 Epoch=55.4] | Loss=0.00134 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=3.591 | 2046.9 samples/s | 32.0 steps/s
[Step=5850 Epoch=55.9] | Loss=0.00129 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=3.591 | 5218.9 samples/s | 81.5 steps/s
[Step=5900 Epoch=56.3] | Loss=0.00125 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.544 | L2-Norm(final)=3.591 | 2109.0 samples/s | 33.0 steps/s
[Step=5950 Epoch=56.8] | Loss=0.00121 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=3.592 | 4945.0 samples/s | 77.3 steps/s
[Step=6000 Epoch=57.3] | Loss=0.00117 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=3.592 | 2186.9 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step6000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=37.7] | Loss=0.07731 | Reg=0.00210 | acc=0.9531 | L2-Norm=14.487 | L2-Norm(final)=2.648 | 5239.1 samples/s | 81.9 steps/s
[Step=4050 Epoch=38.2] | Loss=0.06547 | Reg=0.00211 | acc=0.9531 | L2-Norm=14.522 | L2-Norm(final)=2.673 | 4144.4 samples/s | 64.8 steps/s
[Step=4100 Epoch=38.6] | Loss=0.05721 | Reg=0.00213 | acc=0.9531 | L2-Norm=14.583 | L2-Norm(final)=2.703 | 7337.8 samples/s | 114.7 steps/s
[Step=4150 Epoch=39.1] | Loss=0.05268 | Reg=0.00214 | acc=0.9531 | L2-Norm=14.634 | L2-Norm(final)=2.735 | 2132.6 samples/s | 33.3 steps/s
[Step=4200 Epoch=39.6] | Loss=0.04874 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.682 | L2-Norm(final)=2.763 | 6254.8 samples/s | 97.7 steps/s
[Step=4250 Epoch=40.0] | Loss=0.04587 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.732 | L2-Norm(final)=2.794 | 2217.3 samples/s | 34.6 steps/s
[Step=4300 Epoch=40.5] | Loss=0.04284 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.782 | L2-Norm(final)=2.825 | 5498.4 samples/s | 85.9 steps/s
[Step=4350 Epoch=41.0] | Loss=0.04060 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.832 | L2-Norm(final)=2.856 | 2308.2 samples/s | 36.1 steps/s
[Step=4400 Epoch=41.5] | Loss=0.03909 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.881 | L2-Norm(final)=2.888 | 5028.2 samples/s | 78.6 steps/s
[Step=4450 Epoch=41.9] | Loss=0.03736 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.929 | L2-Norm(final)=2.918 | 2425.3 samples/s | 37.9 steps/s
[Step=4500 Epoch=42.4] | Loss=0.03572 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=2.949 | 4724.8 samples/s | 73.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=42.4] | Loss=0.00898 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=3.250 | 5350.6 samples/s | 83.6 steps/s
[Step=4550 Epoch=42.9] | Loss=0.03293 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=3.255 | 3662.9 samples/s | 57.2 steps/s
[Step=4600 Epoch=43.3] | Loss=0.02057 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.614 | L2-Norm(final)=3.254 | 6135.8 samples/s | 95.9 steps/s
[Step=4650 Epoch=43.8] | Loss=0.01501 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=3.257 | 1995.4 samples/s | 31.2 steps/s
[Step=4700 Epoch=44.3] | Loss=0.01139 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=3.260 | 5438.7 samples/s | 85.0 steps/s
[Step=4750 Epoch=44.8] | Loss=0.00913 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.691 | L2-Norm(final)=3.262 | 2086.8 samples/s | 32.6 steps/s
[Step=4800 Epoch=45.2] | Loss=0.00762 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.692 | L2-Norm(final)=3.264 | 4897.1 samples/s | 76.5 steps/s
[Step=4850 Epoch=45.7] | Loss=0.00654 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.689 | L2-Norm(final)=3.266 | 2193.9 samples/s | 34.3 steps/s
[Step=4900 Epoch=46.2] | Loss=0.00572 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=3.267 | 4482.6 samples/s | 70.0 steps/s
[Step=4950 Epoch=46.6] | Loss=0.00509 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=3.268 | 2293.8 samples/s | 35.8 steps/s
[Step=5000 Epoch=47.1] | Loss=0.00458 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=3.269 | 4236.4 samples/s | 66.2 steps/s
[Step=5050 Epoch=47.6] | Loss=0.00417 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.652 | L2-Norm(final)=3.270 | 2337.4 samples/s | 36.5 steps/s
[Step=5100 Epoch=48.1] | Loss=0.00382 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.640 | L2-Norm(final)=3.271 | 4196.3 samples/s | 65.6 steps/s
[Step=5150 Epoch=48.5] | Loss=0.00353 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.628 | L2-Norm(final)=3.272 | 2375.7 samples/s | 37.1 steps/s
[Step=5200 Epoch=49.0] | Loss=0.00328 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.614 | L2-Norm(final)=3.273 | 4261.9 samples/s | 66.6 steps/s
[Step=5250 Epoch=49.5] | Loss=0.00306 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=3.273 | 2720.5 samples/s | 42.5 steps/s
[Step=5300 Epoch=49.9] | Loss=0.00287 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=3.274 | 3592.1 samples/s | 56.1 steps/s
[Step=5350 Epoch=50.4] | Loss=0.00270 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.572 | L2-Norm(final)=3.274 | 6254.7 samples/s | 97.7 steps/s
[Step=5400 Epoch=50.9] | Loss=0.00255 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.557 | L2-Norm(final)=3.275 | 2007.1 samples/s | 31.4 steps/s
[Step=5450 Epoch=51.4] | Loss=0.00242 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=3.276 | 5564.5 samples/s | 86.9 steps/s
[Step=5500 Epoch=51.8] | Loss=0.00230 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.526 | L2-Norm(final)=3.276 | 1991.9 samples/s | 31.1 steps/s
[Step=5550 Epoch=52.3] | Loss=0.00219 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=3.277 | 4808.9 samples/s | 75.1 steps/s
[Step=5600 Epoch=52.8] | Loss=0.00209 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=3.277 | 2087.9 samples/s | 32.6 steps/s
[Step=5650 Epoch=53.2] | Loss=0.00200 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=3.277 | 4363.0 samples/s | 68.2 steps/s
[Step=5700 Epoch=53.7] | Loss=0.00192 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=3.278 | 2153.7 samples/s | 33.7 steps/s
[Step=5750 Epoch=54.2] | Loss=0.00184 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.446 | L2-Norm(final)=3.278 | 4063.2 samples/s | 63.5 steps/s
[Step=5800 Epoch=54.7] | Loss=0.00177 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=3.279 | 2230.9 samples/s | 34.9 steps/s
[Step=5850 Epoch=55.1] | Loss=0.00171 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.412 | L2-Norm(final)=3.279 | 4125.4 samples/s | 64.5 steps/s
[Step=5900 Epoch=55.6] | Loss=0.00165 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=3.280 | 2416.5 samples/s | 37.8 steps/s
[Step=5950 Epoch=56.1] | Loss=0.00159 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=3.280 | 4298.6 samples/s | 67.2 steps/s
[Step=6000 Epoch=56.5] | Loss=0.00154 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=3.280 | 2599.2 samples/s | 40.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step6000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=38.1] | Loss=0.06757 | Reg=0.00197 | acc=0.9531 | L2-Norm=14.019 | L2-Norm(final)=3.425 | 5525.8 samples/s | 86.3 steps/s
[Step=4050 Epoch=38.6] | Loss=0.06076 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.039 | L2-Norm(final)=3.442 | 3908.0 samples/s | 61.1 steps/s
[Step=4100 Epoch=39.1] | Loss=0.05250 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.081 | L2-Norm(final)=3.467 | 7502.6 samples/s | 117.2 steps/s
[Step=4150 Epoch=39.6] | Loss=0.04784 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.122 | L2-Norm(final)=3.499 | 2126.4 samples/s | 33.2 steps/s
[Step=4200 Epoch=40.0] | Loss=0.04473 | Reg=0.00201 | acc=0.9688 | L2-Norm=14.161 | L2-Norm(final)=3.531 | 6701.8 samples/s | 104.7 steps/s
[Step=4250 Epoch=40.5] | Loss=0.04231 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.201 | L2-Norm(final)=3.562 | 2170.7 samples/s | 33.9 steps/s
[Step=4300 Epoch=41.0] | Loss=0.04040 | Reg=0.00203 | acc=0.9688 | L2-Norm=14.242 | L2-Norm(final)=3.593 | 6064.3 samples/s | 94.8 steps/s
[Step=4350 Epoch=41.5] | Loss=0.03867 | Reg=0.00204 | acc=0.9688 | L2-Norm=14.280 | L2-Norm(final)=3.625 | 2225.7 samples/s | 34.8 steps/s
[Step=4400 Epoch=41.9] | Loss=0.03687 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.319 | L2-Norm(final)=3.657 | 5657.1 samples/s | 88.4 steps/s
[Step=4450 Epoch=42.4] | Loss=0.03556 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.354 | L2-Norm(final)=3.688 | 2366.3 samples/s | 37.0 steps/s
[Step=4500 Epoch=42.9] | Loss=0.03405 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.388 | L2-Norm(final)=3.720 | 5142.0 samples/s | 80.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=42.9] | Loss=0.01869 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.729 | L2-Norm(final)=4.037 | 5405.2 samples/s | 84.5 steps/s
[Step=4550 Epoch=43.4] | Loss=0.02610 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.845 | L2-Norm(final)=4.050 | 3875.4 samples/s | 60.6 steps/s
[Step=4600 Epoch=43.8] | Loss=0.02300 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=4.048 | 6097.2 samples/s | 95.3 steps/s
[Step=4650 Epoch=44.3] | Loss=0.01576 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=4.048 | 2034.8 samples/s | 31.8 steps/s
[Step=4700 Epoch=44.8] | Loss=0.01204 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=4.050 | 5615.9 samples/s | 87.7 steps/s
[Step=4750 Epoch=45.3] | Loss=0.00965 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=4.052 | 2068.9 samples/s | 32.3 steps/s
[Step=4800 Epoch=45.7] | Loss=0.00806 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.012 | L2-Norm(final)=4.054 | 5324.6 samples/s | 83.2 steps/s
[Step=4850 Epoch=46.2] | Loss=0.00692 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=4.055 | 2127.3 samples/s | 33.2 steps/s
[Step=4900 Epoch=46.7] | Loss=0.00606 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=4.057 | 4885.5 samples/s | 76.3 steps/s
[Step=4950 Epoch=47.2] | Loss=0.00539 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=4.058 | 2215.4 samples/s | 34.6 steps/s
[Step=5000 Epoch=47.7] | Loss=0.00485 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=4.059 | 4611.2 samples/s | 72.1 steps/s
[Step=5050 Epoch=48.1] | Loss=0.00442 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=4.060 | 2302.6 samples/s | 36.0 steps/s
[Step=5100 Epoch=48.6] | Loss=0.00405 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=4.061 | 4241.8 samples/s | 66.3 steps/s
[Step=5150 Epoch=49.1] | Loss=0.00374 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=4.062 | 2322.3 samples/s | 36.3 steps/s
[Step=5200 Epoch=49.6] | Loss=0.00347 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=4.062 | 4173.2 samples/s | 65.2 steps/s
[Step=5250 Epoch=50.0] | Loss=0.00324 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=4.063 | 2425.9 samples/s | 37.9 steps/s
[Step=5300 Epoch=50.5] | Loss=0.00304 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.918 | L2-Norm(final)=4.064 | 4136.7 samples/s | 64.6 steps/s
[Step=5350 Epoch=51.0] | Loss=0.00287 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.905 | L2-Norm(final)=4.065 | 2408.1 samples/s | 37.6 steps/s
[Step=5400 Epoch=51.5] | Loss=0.00271 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.892 | L2-Norm(final)=4.065 | 4233.8 samples/s | 66.2 steps/s
[Step=5450 Epoch=51.9] | Loss=0.00257 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=4.066 | 2350.3 samples/s | 36.7 steps/s
[Step=5500 Epoch=52.4] | Loss=0.00244 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.865 | L2-Norm(final)=4.066 | 4202.3 samples/s | 65.7 steps/s
[Step=5550 Epoch=52.9] | Loss=0.00232 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.851 | L2-Norm(final)=4.067 | 6932.3 samples/s | 108.3 steps/s
[Step=5600 Epoch=53.4] | Loss=0.00222 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=4.068 | 1964.8 samples/s | 30.7 steps/s
[Step=5650 Epoch=53.8] | Loss=0.00212 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.823 | L2-Norm(final)=4.068 | 6364.2 samples/s | 99.4 steps/s
[Step=5700 Epoch=54.3] | Loss=0.00203 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=4.069 | 2023.0 samples/s | 31.6 steps/s
[Step=5750 Epoch=54.8] | Loss=0.00195 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.794 | L2-Norm(final)=4.069 | 5749.1 samples/s | 89.8 steps/s
[Step=5800 Epoch=55.3] | Loss=0.00188 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=4.070 | 2017.5 samples/s | 31.5 steps/s
[Step=5850 Epoch=55.8] | Loss=0.00181 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=4.070 | 5303.7 samples/s | 82.9 steps/s
[Step=5900 Epoch=56.2] | Loss=0.00175 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=4.071 | 2134.9 samples/s | 33.4 steps/s
[Step=5950 Epoch=56.7] | Loss=0.00169 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=4.071 | 4945.1 samples/s | 77.3 steps/s
[Step=6000 Epoch=57.2] | Loss=0.00163 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.718 | L2-Norm(final)=4.072 | 2220.9 samples/s | 34.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.13656 | acc=0.9368 | tpr=0.9649 | fpr=0.1241 | 4879.2 samples/s | 19.1 steps/s
Avg test loss: 0.14149, Avg test acc: 0.93441, Avg tpr: 0.96252, Avg fpr: 0.12742, total FA: 994

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.15414 | acc=0.9366 | tpr=0.9660 | fpr=0.1274 | 4852.8 samples/s | 19.0 steps/s
Avg test loss: 0.15494, Avg test acc: 0.93537, Avg tpr: 0.96602, Avg fpr: 0.13203, total FA: 1030

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14296 | acc=0.9252 | tpr=0.9197 | fpr=0.0629 | 4702.4 samples/s | 18.4 steps/s
Avg test loss: 0.14390, Avg test acc: 0.92499, Avg tpr: 0.91968, Avg fpr: 0.06333, total FA: 494

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13808 | acc=0.9306 | tpr=0.9414 | fpr=0.0927 | 5118.4 samples/s | 20.0 steps/s
Avg test loss: 0.14026, Avg test acc: 0.92944, Avg tpr: 0.94224, Avg fpr: 0.09871, total FA: 770

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.15374 | acc=0.9340 | tpr=0.9580 | fpr=0.1182 | 4774.2 samples/s | 18.6 steps/s
Avg test loss: 0.15592, Avg test acc: 0.93317, Avg tpr: 0.95751, Avg fpr: 0.12037, total FA: 939

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.12068 | acc=0.3135 | tpr=0.0110 | fpr=0.0295 | 4951.0 samples/s | 19.3 steps/s
Avg test loss: 4.14496, Avg test acc: 0.31164, Avg tpr: 0.01142, Avg fpr: 0.02807, total FA: 219

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.30395 | acc=0.3109 | tpr=0.0102 | fpr=0.0362 | 5151.1 samples/s | 20.1 steps/s
Avg test loss: 4.32172, Avg test acc: 0.30912, Avg tpr: 0.00973, Avg fpr: 0.03243, total FA: 253

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.13390 | acc=0.3052 | tpr=0.0129 | fpr=0.0600 | 4943.0 samples/s | 19.3 steps/s
Avg test loss: 4.15199, Avg test acc: 0.30483, Avg tpr: 0.01422, Avg fpr: 0.05602, total FA: 437

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=3.85202 | acc=0.3114 | tpr=0.0156 | fpr=0.0463 | 4755.0 samples/s | 18.6 steps/s
Avg test loss: 3.85544, Avg test acc: 0.30888, Avg tpr: 0.01457, Avg fpr: 0.04384, total FA: 342

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.01938 | acc=0.3100 | tpr=0.0180 | fpr=0.0560 | 5014.2 samples/s | 19.6 steps/s
Avg test loss: 4.03512, Avg test acc: 0.30884, Avg tpr: 0.01801, Avg fpr: 0.05153, total FA: 402

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.26896 | acc=0.0966 | tpr=0.7788 | fpr=0.9157 | 5047.2 samples/s | 19.7 steps/s
[Step= 100] | Loss=4.25755 | acc=0.0982 | tpr=0.7612 | fpr=0.9142 | 6798.8 samples/s | 26.6 steps/s
[Step= 150] | Loss=4.25107 | acc=0.0988 | tpr=0.7608 | fpr=0.9134 | 7497.2 samples/s | 29.3 steps/s
[Step= 200] | Loss=4.25159 | acc=0.0987 | tpr=0.7552 | fpr=0.9132 | 7848.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=4.25834 | acc=0.0990 | tpr=0.7511 | fpr=0.9129 | 8244.0 samples/s | 32.2 steps/s
[Step= 300] | Loss=4.26146 | acc=0.0982 | tpr=0.7484 | fpr=0.9136 | 7790.6 samples/s | 30.4 steps/s
[Step= 350] | Loss=4.25722 | acc=0.0978 | tpr=0.7514 | fpr=0.9141 | 7909.0 samples/s | 30.9 steps/s
[Step= 400] | Loss=4.25696 | acc=0.0977 | tpr=0.7467 | fpr=0.9141 | 7872.9 samples/s | 30.8 steps/s
[Step= 450] | Loss=4.25856 | acc=0.0975 | tpr=0.7439 | fpr=0.9142 | 7728.1 samples/s | 30.2 steps/s
[Step= 500] | Loss=4.26242 | acc=0.0970 | tpr=0.7352 | fpr=0.9145 | 7884.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=4.26294 | acc=0.0969 | tpr=0.7322 | fpr=0.9146 | 13750.9 samples/s | 53.7 steps/s
Avg test loss: 4.26428, Avg test acc: 0.09682, Avg tpr: 0.73257, Avg fpr: 0.91474, total FA: 127010

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.33081 | acc=0.1120 | tpr=0.6903 | fpr=0.8984 | 4946.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=4.33461 | acc=0.1106 | tpr=0.6844 | fpr=0.9001 | 6857.3 samples/s | 26.8 steps/s
[Step= 150] | Loss=4.32674 | acc=0.1121 | tpr=0.6744 | fpr=0.8983 | 7902.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=4.32008 | acc=0.1118 | tpr=0.6754 | fpr=0.8985 | 7638.6 samples/s | 29.8 steps/s
[Step= 250] | Loss=4.32510 | acc=0.1120 | tpr=0.6803 | fpr=0.8984 | 8062.7 samples/s | 31.5 steps/s
[Step= 300] | Loss=4.32087 | acc=0.1115 | tpr=0.6742 | fpr=0.8988 | 7940.6 samples/s | 31.0 steps/s
[Step= 350] | Loss=4.31530 | acc=0.1117 | tpr=0.6719 | fpr=0.8984 | 7582.7 samples/s | 29.6 steps/s
[Step= 400] | Loss=4.31206 | acc=0.1122 | tpr=0.6761 | fpr=0.8980 | 8260.2 samples/s | 32.3 steps/s
[Step= 450] | Loss=4.31507 | acc=0.1120 | tpr=0.6767 | fpr=0.8983 | 7899.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=4.31668 | acc=0.1119 | tpr=0.6762 | fpr=0.8983 | 7801.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=4.31835 | acc=0.1115 | tpr=0.6745 | fpr=0.8987 | 13649.1 samples/s | 53.3 steps/s
Avg test loss: 4.31870, Avg test acc: 0.11155, Avg tpr: 0.67472, Avg fpr: 0.89869, total FA: 124781

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=3.33489 | acc=0.1644 | tpr=0.4735 | fpr=0.8412 | 4909.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=3.32069 | acc=0.1636 | tpr=0.4648 | fpr=0.8421 | 6659.3 samples/s | 26.0 steps/s
[Step= 150] | Loss=3.31207 | acc=0.1659 | tpr=0.4755 | fpr=0.8398 | 8172.1 samples/s | 31.9 steps/s
[Step= 200] | Loss=3.30789 | acc=0.1659 | tpr=0.4699 | fpr=0.8396 | 7976.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=3.31119 | acc=0.1662 | tpr=0.4716 | fpr=0.8394 | 7776.3 samples/s | 30.4 steps/s
[Step= 300] | Loss=3.31255 | acc=0.1650 | tpr=0.4684 | fpr=0.8405 | 7744.6 samples/s | 30.3 steps/s
[Step= 350] | Loss=3.30643 | acc=0.1656 | tpr=0.4771 | fpr=0.8401 | 7950.3 samples/s | 31.1 steps/s
[Step= 400] | Loss=3.30559 | acc=0.1658 | tpr=0.4743 | fpr=0.8398 | 7898.1 samples/s | 30.9 steps/s
[Step= 450] | Loss=3.30893 | acc=0.1655 | tpr=0.4757 | fpr=0.8401 | 7632.8 samples/s | 29.8 steps/s
[Step= 500] | Loss=3.30935 | acc=0.1651 | tpr=0.4705 | fpr=0.8404 | 7989.0 samples/s | 31.2 steps/s
[Step= 550] | Loss=3.31101 | acc=0.1651 | tpr=0.4712 | fpr=0.8404 | 14167.1 samples/s | 55.3 steps/s
Avg test loss: 3.31111, Avg test acc: 0.16502, Avg tpr: 0.47108, Avg fpr: 0.84055, total FA: 116708

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=3.45754 | acc=0.1655 | tpr=0.6681 | fpr=0.8436 | 4954.0 samples/s | 19.4 steps/s
[Step= 100] | Loss=3.44787 | acc=0.1629 | tpr=0.6461 | fpr=0.8461 | 6528.4 samples/s | 25.5 steps/s
[Step= 150] | Loss=3.43239 | acc=0.1636 | tpr=0.6686 | fpr=0.8457 | 8300.6 samples/s | 32.4 steps/s
[Step= 200] | Loss=3.42921 | acc=0.1642 | tpr=0.6656 | fpr=0.8449 | 7744.9 samples/s | 30.3 steps/s
[Step= 250] | Loss=3.43388 | acc=0.1649 | tpr=0.6734 | fpr=0.8444 | 7981.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=3.43453 | acc=0.1648 | tpr=0.6742 | fpr=0.8445 | 7811.0 samples/s | 30.5 steps/s
[Step= 350] | Loss=3.43072 | acc=0.1652 | tpr=0.6713 | fpr=0.8440 | 7835.6 samples/s | 30.6 steps/s
[Step= 400] | Loss=3.43265 | acc=0.1649 | tpr=0.6679 | fpr=0.8442 | 7695.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=3.43713 | acc=0.1642 | tpr=0.6685 | fpr=0.8449 | 8044.9 samples/s | 31.4 steps/s
[Step= 500] | Loss=3.43515 | acc=0.1646 | tpr=0.6678 | fpr=0.8445 | 7588.5 samples/s | 29.6 steps/s
[Step= 550] | Loss=3.43266 | acc=0.1648 | tpr=0.6645 | fpr=0.8443 | 14892.5 samples/s | 58.2 steps/s
Avg test loss: 3.43318, Avg test acc: 0.16466, Avg tpr: 0.66521, Avg fpr: 0.84443, total FA: 117248

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.44191 | acc=0.1194 | tpr=0.5310 | fpr=0.8880 | 4811.9 samples/s | 18.8 steps/s
[Step= 100] | Loss=4.42950 | acc=0.1178 | tpr=0.5480 | fpr=0.8902 | 6874.2 samples/s | 26.9 steps/s
[Step= 150] | Loss=4.42337 | acc=0.1178 | tpr=0.5591 | fpr=0.8903 | 7812.5 samples/s | 30.5 steps/s
[Step= 200] | Loss=4.42277 | acc=0.1174 | tpr=0.5530 | fpr=0.8905 | 8052.0 samples/s | 31.5 steps/s
[Step= 250] | Loss=4.43227 | acc=0.1165 | tpr=0.5555 | fpr=0.8915 | 7739.0 samples/s | 30.2 steps/s
[Step= 300] | Loss=4.43260 | acc=0.1163 | tpr=0.5571 | fpr=0.8917 | 8049.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=4.43169 | acc=0.1164 | tpr=0.5579 | fpr=0.8916 | 8216.7 samples/s | 32.1 steps/s
[Step= 400] | Loss=4.43146 | acc=0.1173 | tpr=0.5596 | fpr=0.8908 | 7421.9 samples/s | 29.0 steps/s
[Step= 450] | Loss=4.43529 | acc=0.1174 | tpr=0.5638 | fpr=0.8907 | 7924.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=4.44010 | acc=0.1175 | tpr=0.5581 | fpr=0.8904 | 7805.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=4.43886 | acc=0.1176 | tpr=0.5619 | fpr=0.8905 | 14522.0 samples/s | 56.7 steps/s
Avg test loss: 4.44009, Avg test acc: 0.11752, Avg tpr: 0.56260, Avg fpr: 0.89057, total FA: 123654

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10753 | acc=0.9780 | tpr=0.8540 | fpr=0.0197 | 4939.7 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.10860 | acc=0.9786 | tpr=0.8806 | fpr=0.0196 | 6872.2 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.11421 | acc=0.9777 | tpr=0.8876 | fpr=0.0206 | 7522.4 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.11718 | acc=0.9777 | tpr=0.8929 | fpr=0.0207 | 8235.6 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.11476 | acc=0.9782 | tpr=0.8891 | fpr=0.0202 | 7962.7 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11669 | acc=0.9780 | tpr=0.8851 | fpr=0.0203 | 7714.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.11822 | acc=0.9776 | tpr=0.8854 | fpr=0.0207 | 7804.8 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.11917 | acc=0.9774 | tpr=0.8829 | fpr=0.0209 | 8038.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.12191 | acc=0.9771 | tpr=0.8822 | fpr=0.0212 | 7815.1 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.12082 | acc=0.9771 | tpr=0.8841 | fpr=0.0212 | 7854.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.12013 | acc=0.9773 | tpr=0.8834 | fpr=0.0210 | 14145.1 samples/s | 55.3 steps/s
Avg test loss: 0.12002, Avg test acc: 0.97730, Avg tpr: 0.88312, Avg fpr: 0.02099, total FA: 2914

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07565 | acc=0.9826 | tpr=0.8540 | fpr=0.0151 | 5024.0 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.07552 | acc=0.9830 | tpr=0.8742 | fpr=0.0150 | 6617.9 samples/s | 25.9 steps/s
[Step= 150] | Loss=0.07787 | acc=0.9821 | tpr=0.8761 | fpr=0.0159 | 7966.1 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.07779 | acc=0.9821 | tpr=0.8798 | fpr=0.0160 | 7771.8 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.07618 | acc=0.9825 | tpr=0.8760 | fpr=0.0155 | 7911.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.07754 | acc=0.9821 | tpr=0.8720 | fpr=0.0159 | 7801.6 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.07874 | acc=0.9819 | tpr=0.8735 | fpr=0.0162 | 7701.0 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.07940 | acc=0.9816 | tpr=0.8704 | fpr=0.0164 | 8084.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.08068 | acc=0.9813 | tpr=0.8671 | fpr=0.0167 | 7699.7 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.08021 | acc=0.9813 | tpr=0.8678 | fpr=0.0166 | 8039.2 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.08006 | acc=0.9815 | tpr=0.8671 | fpr=0.0164 | 13740.7 samples/s | 53.7 steps/s
Avg test loss: 0.07991, Avg test acc: 0.98154, Avg tpr: 0.86727, Avg fpr: 0.01638, total FA: 2275

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.07357 | acc=0.9808 | tpr=0.8938 | fpr=0.0177 | 4891.5 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.07323 | acc=0.9802 | tpr=0.9041 | fpr=0.0184 | 6700.9 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.07736 | acc=0.9792 | tpr=0.8991 | fpr=0.0193 | 7878.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.07931 | acc=0.9792 | tpr=0.9060 | fpr=0.0195 | 8037.1 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.07777 | acc=0.9797 | tpr=0.9039 | fpr=0.0190 | 7833.6 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.07948 | acc=0.9794 | tpr=0.8945 | fpr=0.0191 | 8001.5 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.08034 | acc=0.9791 | tpr=0.8929 | fpr=0.0193 | 7539.1 samples/s | 29.4 steps/s
[Step= 400] | Loss=0.08114 | acc=0.9789 | tpr=0.8906 | fpr=0.0195 | 7981.7 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.08232 | acc=0.9789 | tpr=0.8919 | fpr=0.0195 | 7944.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.08155 | acc=0.9791 | tpr=0.8956 | fpr=0.0194 | 7859.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.08119 | acc=0.9792 | tpr=0.8965 | fpr=0.0193 | 14236.1 samples/s | 55.6 steps/s
Avg test loss: 0.08110, Avg test acc: 0.97919, Avg tpr: 0.89699, Avg fpr: 0.01932, total FA: 2682

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.06295 | acc=0.9836 | tpr=0.8451 | fpr=0.0139 | 4859.8 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.06662 | acc=0.9833 | tpr=0.8721 | fpr=0.0146 | 6818.5 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.06854 | acc=0.9828 | tpr=0.8775 | fpr=0.0152 | 7921.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.06944 | acc=0.9826 | tpr=0.8842 | fpr=0.0156 | 7860.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.06859 | acc=0.9829 | tpr=0.8856 | fpr=0.0154 | 7972.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.06993 | acc=0.9826 | tpr=0.8793 | fpr=0.0155 | 7975.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.07039 | acc=0.9825 | tpr=0.8817 | fpr=0.0157 | 7837.2 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.07134 | acc=0.9823 | tpr=0.8786 | fpr=0.0158 | 7671.6 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.07279 | acc=0.9820 | tpr=0.8788 | fpr=0.0161 | 8136.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.07256 | acc=0.9821 | tpr=0.8828 | fpr=0.0161 | 7548.5 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.07223 | acc=0.9822 | tpr=0.8822 | fpr=0.0160 | 14837.3 samples/s | 58.0 steps/s
Avg test loss: 0.07215, Avg test acc: 0.98222, Avg tpr: 0.88233, Avg fpr: 0.01596, total FA: 2216

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.07060 | acc=0.9819 | tpr=0.8761 | fpr=0.0162 | 4686.3 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.07137 | acc=0.9821 | tpr=0.8913 | fpr=0.0162 | 7190.3 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.07458 | acc=0.9811 | tpr=0.8977 | fpr=0.0173 | 7745.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.07636 | acc=0.9808 | tpr=0.8951 | fpr=0.0176 | 8288.0 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.07553 | acc=0.9809 | tpr=0.8873 | fpr=0.0174 | 7955.6 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.07691 | acc=0.9807 | tpr=0.8822 | fpr=0.0175 | 7618.7 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.07822 | acc=0.9805 | tpr=0.8829 | fpr=0.0177 | 7877.8 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.07890 | acc=0.9803 | tpr=0.8829 | fpr=0.0179 | 7799.5 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.08034 | acc=0.9800 | tpr=0.8793 | fpr=0.0182 | 7814.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.07972 | acc=0.9801 | tpr=0.8815 | fpr=0.0181 | 7706.1 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.07926 | acc=0.9802 | tpr=0.8818 | fpr=0.0180 | 14615.6 samples/s | 57.1 steps/s
Avg test loss: 0.07910, Avg test acc: 0.98022, Avg tpr: 0.88154, Avg fpr: 0.01799, total FA: 2498

server round 3/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=29.3] | Loss=0.10862 | Reg=0.00400 | acc=0.8750 | L2-Norm=20.010 | L2-Norm(final)=3.783 | 5448.7 samples/s | 85.1 steps/s
[Step=6050 Epoch=29.5] | Loss=0.07533 | Reg=0.00402 | acc=0.9219 | L2-Norm=20.052 | L2-Norm(final)=3.792 | 4289.7 samples/s | 67.0 steps/s
[Step=6100 Epoch=29.7] | Loss=0.07806 | Reg=0.00403 | acc=0.9375 | L2-Norm=20.081 | L2-Norm(final)=3.812 | 5136.6 samples/s | 80.3 steps/s
[Step=6150 Epoch=30.0] | Loss=0.07553 | Reg=0.00405 | acc=0.9062 | L2-Norm=20.112 | L2-Norm(final)=3.835 | 4945.9 samples/s | 77.3 steps/s
[Step=6200 Epoch=30.2] | Loss=0.07477 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.143 | L2-Norm(final)=3.859 | 7795.4 samples/s | 121.8 steps/s
[Step=6250 Epoch=30.5] | Loss=0.07249 | Reg=0.00407 | acc=0.9531 | L2-Norm=20.179 | L2-Norm(final)=3.885 | 2214.2 samples/s | 34.6 steps/s
[Step=6300 Epoch=30.7] | Loss=0.07120 | Reg=0.00409 | acc=0.9531 | L2-Norm=20.215 | L2-Norm(final)=3.914 | 4996.7 samples/s | 78.1 steps/s
[Step=6350 Epoch=31.0] | Loss=0.07044 | Reg=0.00410 | acc=0.9219 | L2-Norm=20.255 | L2-Norm(final)=3.946 | 5269.7 samples/s | 82.3 steps/s
[Step=6400 Epoch=31.2] | Loss=0.06919 | Reg=0.00412 | acc=0.9375 | L2-Norm=20.294 | L2-Norm(final)=3.978 | 6505.2 samples/s | 101.6 steps/s
[Step=6450 Epoch=31.5] | Loss=0.06745 | Reg=0.00414 | acc=0.9219 | L2-Norm=20.334 | L2-Norm(final)=4.013 | 2309.5 samples/s | 36.1 steps/s
[Step=6500 Epoch=31.7] | Loss=0.06667 | Reg=0.00415 | acc=0.9688 | L2-Norm=20.375 | L2-Norm(final)=4.048 | 4955.3 samples/s | 77.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=31.7] | Loss=0.04744 | Reg=0.00433 | acc=0.9531 | L2-Norm=20.809 | L2-Norm(final)=4.411 | 5573.1 samples/s | 87.1 steps/s
[Step=6550 Epoch=31.9] | Loss=0.06754 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.866 | L2-Norm(final)=4.437 | 3916.2 samples/s | 61.2 steps/s
[Step=6600 Epoch=32.2] | Loss=0.07253 | Reg=0.00438 | acc=0.9062 | L2-Norm=20.922 | L2-Norm(final)=4.432 | 4432.4 samples/s | 69.3 steps/s
[Step=6650 Epoch=32.4] | Loss=0.07255 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.965 | L2-Norm(final)=4.418 | 4430.3 samples/s | 69.2 steps/s
[Step=6700 Epoch=32.7] | Loss=0.07064 | Reg=0.00441 | acc=0.9062 | L2-Norm=20.999 | L2-Norm(final)=4.407 | 6559.9 samples/s | 102.5 steps/s
[Step=6750 Epoch=32.9] | Loss=0.06464 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.029 | L2-Norm(final)=4.399 | 2087.1 samples/s | 32.6 steps/s
[Step=6800 Epoch=33.2] | Loss=0.05960 | Reg=0.00443 | acc=0.9531 | L2-Norm=21.054 | L2-Norm(final)=4.394 | 4543.9 samples/s | 71.0 steps/s
[Step=6850 Epoch=33.4] | Loss=0.05703 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.076 | L2-Norm(final)=4.391 | 4504.3 samples/s | 70.4 steps/s
[Step=6900 Epoch=33.6] | Loss=0.05440 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.097 | L2-Norm(final)=4.389 | 5700.1 samples/s | 89.1 steps/s
[Step=6950 Epoch=33.9] | Loss=0.05157 | Reg=0.00446 | acc=0.9844 | L2-Norm=21.115 | L2-Norm(final)=4.387 | 2164.8 samples/s | 33.8 steps/s
[Step=7000 Epoch=34.1] | Loss=0.04823 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.130 | L2-Norm(final)=4.387 | 4494.3 samples/s | 70.2 steps/s
[Step=7050 Epoch=34.4] | Loss=0.04626 | Reg=0.00447 | acc=0.9844 | L2-Norm=21.144 | L2-Norm(final)=4.388 | 4498.0 samples/s | 70.3 steps/s
[Step=7100 Epoch=34.6] | Loss=0.04521 | Reg=0.00448 | acc=0.9531 | L2-Norm=21.158 | L2-Norm(final)=4.388 | 5265.7 samples/s | 82.3 steps/s
[Step=7150 Epoch=34.9] | Loss=0.04362 | Reg=0.00448 | acc=0.9688 | L2-Norm=21.171 | L2-Norm(final)=4.388 | 2190.3 samples/s | 34.2 steps/s
[Step=7200 Epoch=35.1] | Loss=0.04222 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.183 | L2-Norm(final)=4.387 | 4420.3 samples/s | 69.1 steps/s
[Step=7250 Epoch=35.4] | Loss=0.04063 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.194 | L2-Norm(final)=4.388 | 4569.9 samples/s | 71.4 steps/s
[Step=7300 Epoch=35.6] | Loss=0.03975 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.205 | L2-Norm(final)=4.388 | 4822.8 samples/s | 75.4 steps/s
[Step=7350 Epoch=35.8] | Loss=0.03828 | Reg=0.00450 | acc=0.9844 | L2-Norm=21.215 | L2-Norm(final)=4.388 | 2301.6 samples/s | 36.0 steps/s
[Step=7400 Epoch=36.1] | Loss=0.03704 | Reg=0.00450 | acc=0.9688 | L2-Norm=21.224 | L2-Norm(final)=4.390 | 4468.4 samples/s | 69.8 steps/s
[Step=7450 Epoch=36.3] | Loss=0.03591 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.231 | L2-Norm(final)=4.391 | 4412.6 samples/s | 68.9 steps/s
[Step=7500 Epoch=36.6] | Loss=0.03515 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.237 | L2-Norm(final)=4.392 | 4590.5 samples/s | 71.7 steps/s
[Step=7550 Epoch=36.8] | Loss=0.03436 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.244 | L2-Norm(final)=4.393 | 2425.4 samples/s | 37.9 steps/s
[Step=7600 Epoch=37.1] | Loss=0.03366 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.250 | L2-Norm(final)=4.393 | 4427.2 samples/s | 69.2 steps/s
[Step=7650 Epoch=37.3] | Loss=0.03298 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.256 | L2-Norm(final)=4.393 | 4428.7 samples/s | 69.2 steps/s
[Step=7700 Epoch=37.5] | Loss=0.03243 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.262 | L2-Norm(final)=4.393 | 4409.2 samples/s | 68.9 steps/s
[Step=7750 Epoch=37.8] | Loss=0.03217 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.268 | L2-Norm(final)=4.392 | 2452.1 samples/s | 38.3 steps/s
[Step=7800 Epoch=38.0] | Loss=0.03163 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.273 | L2-Norm(final)=4.392 | 4405.2 samples/s | 68.8 steps/s
[Step=7850 Epoch=38.3] | Loss=0.03100 | Reg=0.00453 | acc=0.9688 | L2-Norm=21.279 | L2-Norm(final)=4.392 | 4471.6 samples/s | 69.9 steps/s
[Step=7900 Epoch=38.5] | Loss=0.03039 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.285 | L2-Norm(final)=4.392 | 4451.8 samples/s | 69.6 steps/s
[Step=7950 Epoch=38.8] | Loss=0.02997 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.290 | L2-Norm(final)=4.392 | 2462.7 samples/s | 38.5 steps/s
[Step=8000 Epoch=39.0] | Loss=0.02940 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.296 | L2-Norm(final)=4.392 | 4396.1 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step8000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=29.3] | Loss=0.06853 | Reg=0.00384 | acc=0.9219 | L2-Norm=19.588 | L2-Norm(final)=3.885 | 4730.8 samples/s | 73.9 steps/s
[Step=6050 Epoch=29.5] | Loss=0.08490 | Reg=0.00386 | acc=0.9531 | L2-Norm=19.644 | L2-Norm(final)=3.869 | 5003.8 samples/s | 78.2 steps/s
[Step=6100 Epoch=29.8] | Loss=0.07970 | Reg=0.00388 | acc=0.9531 | L2-Norm=19.689 | L2-Norm(final)=3.883 | 4979.1 samples/s | 77.8 steps/s
[Step=6150 Epoch=30.0] | Loss=0.07577 | Reg=0.00389 | acc=0.9531 | L2-Norm=19.726 | L2-Norm(final)=3.906 | 4952.0 samples/s | 77.4 steps/s
[Step=6200 Epoch=30.3] | Loss=0.07352 | Reg=0.00391 | acc=0.9531 | L2-Norm=19.763 | L2-Norm(final)=3.930 | 7920.2 samples/s | 123.8 steps/s
[Step=6250 Epoch=30.5] | Loss=0.07058 | Reg=0.00392 | acc=0.9688 | L2-Norm=19.799 | L2-Norm(final)=3.956 | 2221.4 samples/s | 34.7 steps/s
[Step=6300 Epoch=30.7] | Loss=0.06898 | Reg=0.00394 | acc=0.9062 | L2-Norm=19.838 | L2-Norm(final)=3.986 | 4935.7 samples/s | 77.1 steps/s
[Step=6350 Epoch=31.0] | Loss=0.06828 | Reg=0.00395 | acc=0.9375 | L2-Norm=19.880 | L2-Norm(final)=4.015 | 5032.9 samples/s | 78.6 steps/s
[Step=6400 Epoch=31.2] | Loss=0.06678 | Reg=0.00397 | acc=0.9531 | L2-Norm=19.922 | L2-Norm(final)=4.045 | 6895.0 samples/s | 107.7 steps/s
[Step=6450 Epoch=31.5] | Loss=0.06525 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.965 | L2-Norm(final)=4.076 | 2275.8 samples/s | 35.6 steps/s
[Step=6500 Epoch=31.7] | Loss=0.06378 | Reg=0.00400 | acc=0.9688 | L2-Norm=20.008 | L2-Norm(final)=4.109 | 5021.6 samples/s | 78.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=31.7] | Loss=0.01723 | Reg=0.00418 | acc=1.0000 | L2-Norm=20.445 | L2-Norm(final)=4.448 | 5373.1 samples/s | 84.0 steps/s
[Step=6550 Epoch=32.0] | Loss=0.07690 | Reg=0.00421 | acc=0.8906 | L2-Norm=20.516 | L2-Norm(final)=4.469 | 4054.9 samples/s | 63.4 steps/s
[Step=6600 Epoch=32.2] | Loss=0.08665 | Reg=0.00424 | acc=0.9375 | L2-Norm=20.584 | L2-Norm(final)=4.439 | 4522.4 samples/s | 70.7 steps/s
[Step=6650 Epoch=32.4] | Loss=0.08287 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.637 | L2-Norm(final)=4.419 | 4418.7 samples/s | 69.0 steps/s
[Step=6700 Epoch=32.7] | Loss=0.07816 | Reg=0.00428 | acc=0.9062 | L2-Norm=20.680 | L2-Norm(final)=4.408 | 6392.3 samples/s | 99.9 steps/s
[Step=6750 Epoch=32.9] | Loss=0.07190 | Reg=0.00429 | acc=0.9688 | L2-Norm=20.716 | L2-Norm(final)=4.401 | 2075.9 samples/s | 32.4 steps/s
[Step=6800 Epoch=33.2] | Loss=0.06644 | Reg=0.00431 | acc=1.0000 | L2-Norm=20.749 | L2-Norm(final)=4.397 | 4463.1 samples/s | 69.7 steps/s
[Step=6850 Epoch=33.4] | Loss=0.06192 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.777 | L2-Norm(final)=4.398 | 4424.3 samples/s | 69.1 steps/s
[Step=6900 Epoch=33.7] | Loss=0.05972 | Reg=0.00433 | acc=0.9531 | L2-Norm=20.801 | L2-Norm(final)=4.397 | 5916.5 samples/s | 92.4 steps/s
[Step=6950 Epoch=33.9] | Loss=0.05617 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.825 | L2-Norm(final)=4.398 | 2137.4 samples/s | 33.4 steps/s
[Step=7000 Epoch=34.2] | Loss=0.05298 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.848 | L2-Norm(final)=4.400 | 4512.3 samples/s | 70.5 steps/s
[Step=7050 Epoch=34.4] | Loss=0.05059 | Reg=0.00436 | acc=0.9688 | L2-Norm=20.869 | L2-Norm(final)=4.401 | 4372.0 samples/s | 68.3 steps/s
[Step=7100 Epoch=34.6] | Loss=0.04877 | Reg=0.00436 | acc=1.0000 | L2-Norm=20.888 | L2-Norm(final)=4.402 | 5464.7 samples/s | 85.4 steps/s
[Step=7150 Epoch=34.9] | Loss=0.04628 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.906 | L2-Norm(final)=4.403 | 2212.7 samples/s | 34.6 steps/s
[Step=7200 Epoch=35.1] | Loss=0.04408 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.922 | L2-Norm(final)=4.406 | 4367.4 samples/s | 68.2 steps/s
[Step=7250 Epoch=35.4] | Loss=0.04285 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.936 | L2-Norm(final)=4.407 | 4469.5 samples/s | 69.8 steps/s
[Step=7300 Epoch=35.6] | Loss=0.04212 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.949 | L2-Norm(final)=4.407 | 5205.9 samples/s | 81.3 steps/s
[Step=7350 Epoch=35.9] | Loss=0.04057 | Reg=0.00439 | acc=0.9688 | L2-Norm=20.962 | L2-Norm(final)=4.406 | 2313.0 samples/s | 36.1 steps/s
[Step=7400 Epoch=36.1] | Loss=0.03932 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.973 | L2-Norm(final)=4.406 | 4368.1 samples/s | 68.3 steps/s
[Step=7450 Epoch=36.4] | Loss=0.03817 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.983 | L2-Norm(final)=4.406 | 4498.3 samples/s | 70.3 steps/s
[Step=7500 Epoch=36.6] | Loss=0.03718 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.992 | L2-Norm(final)=4.406 | 4839.5 samples/s | 75.6 steps/s
[Step=7550 Epoch=36.8] | Loss=0.03596 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.000 | L2-Norm(final)=4.406 | 2315.8 samples/s | 36.2 steps/s
[Step=7600 Epoch=37.1] | Loss=0.03488 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.006 | L2-Norm(final)=4.407 | 4452.4 samples/s | 69.6 steps/s
[Step=7650 Epoch=37.3] | Loss=0.03378 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.011 | L2-Norm(final)=4.407 | 4526.2 samples/s | 70.7 steps/s
[Step=7700 Epoch=37.6] | Loss=0.03318 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.016 | L2-Norm(final)=4.408 | 4512.5 samples/s | 70.5 steps/s
[Step=7750 Epoch=37.8] | Loss=0.03250 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.021 | L2-Norm(final)=4.409 | 2419.2 samples/s | 37.8 steps/s
[Step=7800 Epoch=38.1] | Loss=0.03170 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.025 | L2-Norm(final)=4.410 | 4470.7 samples/s | 69.9 steps/s
[Step=7850 Epoch=38.3] | Loss=0.03087 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.027 | L2-Norm(final)=4.411 | 4580.5 samples/s | 71.6 steps/s
[Step=7900 Epoch=38.5] | Loss=0.03024 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.029 | L2-Norm(final)=4.412 | 4299.0 samples/s | 67.2 steps/s
[Step=7950 Epoch=38.8] | Loss=0.02962 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.031 | L2-Norm(final)=4.413 | 2511.8 samples/s | 39.2 steps/s
[Step=8000 Epoch=39.0] | Loss=0.02901 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.032 | L2-Norm(final)=4.414 | 4374.9 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step8000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=29.2] | Loss=0.10538 | Reg=0.00396 | acc=0.9219 | L2-Norm=19.900 | L2-Norm(final)=3.914 | 5633.2 samples/s | 88.0 steps/s
[Step=6050 Epoch=29.5] | Loss=0.08082 | Reg=0.00397 | acc=0.9531 | L2-Norm=19.919 | L2-Norm(final)=3.934 | 4313.0 samples/s | 67.4 steps/s
[Step=6100 Epoch=29.7] | Loss=0.07540 | Reg=0.00398 | acc=0.8906 | L2-Norm=19.947 | L2-Norm(final)=3.966 | 5026.3 samples/s | 78.5 steps/s
[Step=6150 Epoch=30.0] | Loss=0.07409 | Reg=0.00399 | acc=0.9375 | L2-Norm=19.976 | L2-Norm(final)=3.996 | 5080.3 samples/s | 79.4 steps/s
[Step=6200 Epoch=30.2] | Loss=0.07337 | Reg=0.00400 | acc=0.9062 | L2-Norm=20.002 | L2-Norm(final)=4.020 | 7691.2 samples/s | 120.2 steps/s
[Step=6250 Epoch=30.5] | Loss=0.07206 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.033 | L2-Norm(final)=4.045 | 2213.2 samples/s | 34.6 steps/s
[Step=6300 Epoch=30.7] | Loss=0.07052 | Reg=0.00403 | acc=0.9375 | L2-Norm=20.069 | L2-Norm(final)=4.074 | 5027.2 samples/s | 78.6 steps/s
[Step=6350 Epoch=30.9] | Loss=0.06998 | Reg=0.00404 | acc=0.9219 | L2-Norm=20.102 | L2-Norm(final)=4.103 | 4935.6 samples/s | 77.1 steps/s
[Step=6400 Epoch=31.2] | Loss=0.06852 | Reg=0.00406 | acc=0.9531 | L2-Norm=20.137 | L2-Norm(final)=4.134 | 6980.8 samples/s | 109.1 steps/s
[Step=6450 Epoch=31.4] | Loss=0.06768 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.173 | L2-Norm(final)=4.166 | 2307.8 samples/s | 36.1 steps/s
[Step=6500 Epoch=31.7] | Loss=0.06597 | Reg=0.00409 | acc=0.9531 | L2-Norm=20.213 | L2-Norm(final)=4.201 | 5040.9 samples/s | 78.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=31.7] | Loss=0.02184 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.610 | L2-Norm(final)=4.556 | 5209.9 samples/s | 81.4 steps/s
[Step=6550 Epoch=31.9] | Loss=0.06394 | Reg=0.00427 | acc=0.9688 | L2-Norm=20.664 | L2-Norm(final)=4.575 | 4065.0 samples/s | 63.5 steps/s
[Step=6600 Epoch=32.2] | Loss=0.07074 | Reg=0.00429 | acc=0.9375 | L2-Norm=20.717 | L2-Norm(final)=4.569 | 4564.7 samples/s | 71.3 steps/s
[Step=6650 Epoch=32.4] | Loss=0.07067 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.757 | L2-Norm(final)=4.562 | 4426.6 samples/s | 69.2 steps/s
[Step=6700 Epoch=32.6] | Loss=0.06777 | Reg=0.00432 | acc=0.9219 | L2-Norm=20.791 | L2-Norm(final)=4.556 | 6425.8 samples/s | 100.4 steps/s
[Step=6750 Epoch=32.9] | Loss=0.06278 | Reg=0.00433 | acc=0.9375 | L2-Norm=20.819 | L2-Norm(final)=4.553 | 2091.3 samples/s | 32.7 steps/s
[Step=6800 Epoch=33.1] | Loss=0.05847 | Reg=0.00434 | acc=0.9531 | L2-Norm=20.843 | L2-Norm(final)=4.552 | 4450.6 samples/s | 69.5 steps/s
[Step=6850 Epoch=33.4] | Loss=0.05527 | Reg=0.00435 | acc=0.9531 | L2-Norm=20.862 | L2-Norm(final)=4.552 | 4495.2 samples/s | 70.2 steps/s
[Step=6900 Epoch=33.6] | Loss=0.05358 | Reg=0.00436 | acc=0.9844 | L2-Norm=20.880 | L2-Norm(final)=4.552 | 5882.1 samples/s | 91.9 steps/s
[Step=6950 Epoch=33.9] | Loss=0.05173 | Reg=0.00437 | acc=0.9375 | L2-Norm=20.900 | L2-Norm(final)=4.551 | 2144.9 samples/s | 33.5 steps/s
[Step=7000 Epoch=34.1] | Loss=0.04932 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.919 | L2-Norm(final)=4.552 | 4482.3 samples/s | 70.0 steps/s
[Step=7050 Epoch=34.4] | Loss=0.04755 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.937 | L2-Norm(final)=4.552 | 4466.0 samples/s | 69.8 steps/s
[Step=7100 Epoch=34.6] | Loss=0.04572 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.954 | L2-Norm(final)=4.552 | 5388.3 samples/s | 84.2 steps/s
[Step=7150 Epoch=34.8] | Loss=0.04373 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.970 | L2-Norm(final)=4.553 | 2286.1 samples/s | 35.7 steps/s
[Step=7200 Epoch=35.1] | Loss=0.04205 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.984 | L2-Norm(final)=4.555 | 4363.3 samples/s | 68.2 steps/s
[Step=7250 Epoch=35.3] | Loss=0.04058 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.997 | L2-Norm(final)=4.557 | 4462.4 samples/s | 69.7 steps/s
[Step=7300 Epoch=35.6] | Loss=0.03926 | Reg=0.00441 | acc=0.9688 | L2-Norm=21.007 | L2-Norm(final)=4.560 | 4872.9 samples/s | 76.1 steps/s
[Step=7350 Epoch=35.8] | Loss=0.03785 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.017 | L2-Norm(final)=4.562 | 2328.6 samples/s | 36.4 steps/s
[Step=7400 Epoch=36.1] | Loss=0.03660 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.026 | L2-Norm(final)=4.565 | 4402.5 samples/s | 68.8 steps/s
[Step=7450 Epoch=36.3] | Loss=0.03579 | Reg=0.00442 | acc=0.9688 | L2-Norm=21.035 | L2-Norm(final)=4.567 | 4473.0 samples/s | 69.9 steps/s
[Step=7500 Epoch=36.5] | Loss=0.03467 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.043 | L2-Norm(final)=4.570 | 4579.3 samples/s | 71.6 steps/s
[Step=7550 Epoch=36.8] | Loss=0.03349 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.049 | L2-Norm(final)=4.572 | 2440.9 samples/s | 38.1 steps/s
[Step=7600 Epoch=37.0] | Loss=0.03270 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.055 | L2-Norm(final)=4.575 | 4396.7 samples/s | 68.7 steps/s
[Step=7650 Epoch=37.3] | Loss=0.03211 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.061 | L2-Norm(final)=4.577 | 4449.9 samples/s | 69.5 steps/s
[Step=7700 Epoch=37.5] | Loss=0.03148 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.067 | L2-Norm(final)=4.579 | 4518.1 samples/s | 70.6 steps/s
[Step=7750 Epoch=37.8] | Loss=0.03125 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.073 | L2-Norm(final)=4.581 | 2458.3 samples/s | 38.4 steps/s
[Step=7800 Epoch=38.0] | Loss=0.03072 | Reg=0.00444 | acc=0.9531 | L2-Norm=21.079 | L2-Norm(final)=4.582 | 4515.6 samples/s | 70.6 steps/s
[Step=7850 Epoch=38.2] | Loss=0.03030 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.085 | L2-Norm(final)=4.583 | 4520.1 samples/s | 70.6 steps/s
[Step=7900 Epoch=38.5] | Loss=0.03004 | Reg=0.00445 | acc=0.9844 | L2-Norm=21.092 | L2-Norm(final)=4.584 | 4326.6 samples/s | 67.6 steps/s
[Step=7950 Epoch=38.7] | Loss=0.02960 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.098 | L2-Norm(final)=4.585 | 2449.7 samples/s | 38.3 steps/s
[Step=8000 Epoch=39.0] | Loss=0.02907 | Reg=0.00445 | acc=0.9844 | L2-Norm=21.105 | L2-Norm(final)=4.586 | 4488.1 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step8000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=29.3] | Loss=0.06801 | Reg=0.00383 | acc=0.9531 | L2-Norm=19.562 | L2-Norm(final)=3.842 | 5664.6 samples/s | 88.5 steps/s
[Step=6050 Epoch=29.5] | Loss=0.08583 | Reg=0.00384 | acc=0.9375 | L2-Norm=19.588 | L2-Norm(final)=3.843 | 4377.7 samples/s | 68.4 steps/s
[Step=6100 Epoch=29.7] | Loss=0.07889 | Reg=0.00385 | acc=0.8906 | L2-Norm=19.627 | L2-Norm(final)=3.864 | 5029.0 samples/s | 78.6 steps/s
[Step=6150 Epoch=30.0] | Loss=0.07472 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.662 | L2-Norm(final)=3.884 | 4882.8 samples/s | 76.3 steps/s
[Step=6200 Epoch=30.2] | Loss=0.07378 | Reg=0.00388 | acc=0.9375 | L2-Norm=19.695 | L2-Norm(final)=3.909 | 7894.0 samples/s | 123.3 steps/s
[Step=6250 Epoch=30.5] | Loss=0.07150 | Reg=0.00389 | acc=0.9375 | L2-Norm=19.725 | L2-Norm(final)=3.930 | 2226.3 samples/s | 34.8 steps/s
[Step=6300 Epoch=30.7] | Loss=0.07064 | Reg=0.00390 | acc=0.9531 | L2-Norm=19.757 | L2-Norm(final)=3.954 | 4923.8 samples/s | 76.9 steps/s
[Step=6350 Epoch=31.0] | Loss=0.06875 | Reg=0.00392 | acc=0.9375 | L2-Norm=19.791 | L2-Norm(final)=3.980 | 5175.5 samples/s | 80.9 steps/s
[Step=6400 Epoch=31.2] | Loss=0.06797 | Reg=0.00393 | acc=0.9688 | L2-Norm=19.825 | L2-Norm(final)=4.008 | 6722.0 samples/s | 105.0 steps/s
[Step=6450 Epoch=31.5] | Loss=0.06684 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.862 | L2-Norm(final)=4.036 | 2308.6 samples/s | 36.1 steps/s
[Step=6500 Epoch=31.7] | Loss=0.06572 | Reg=0.00396 | acc=0.9531 | L2-Norm=19.901 | L2-Norm(final)=4.066 | 5002.0 samples/s | 78.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=31.7] | Loss=0.02426 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.297 | L2-Norm(final)=4.363 | 5591.7 samples/s | 87.4 steps/s
[Step=6550 Epoch=31.9] | Loss=0.06923 | Reg=0.00414 | acc=0.9219 | L2-Norm=20.351 | L2-Norm(final)=4.380 | 3909.3 samples/s | 61.1 steps/s
[Step=6600 Epoch=32.2] | Loss=0.07245 | Reg=0.00416 | acc=0.9531 | L2-Norm=20.396 | L2-Norm(final)=4.373 | 4385.9 samples/s | 68.5 steps/s
[Step=6650 Epoch=32.4] | Loss=0.07167 | Reg=0.00418 | acc=0.9375 | L2-Norm=20.436 | L2-Norm(final)=4.365 | 4421.8 samples/s | 69.1 steps/s
[Step=6700 Epoch=32.7] | Loss=0.06804 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.475 | L2-Norm(final)=4.358 | 6444.4 samples/s | 100.7 steps/s
[Step=6750 Epoch=32.9] | Loss=0.06750 | Reg=0.00421 | acc=0.9375 | L2-Norm=20.529 | L2-Norm(final)=4.350 | 2104.0 samples/s | 32.9 steps/s
[Step=6800 Epoch=33.2] | Loss=0.06433 | Reg=0.00424 | acc=0.9688 | L2-Norm=20.582 | L2-Norm(final)=4.343 | 4489.2 samples/s | 70.1 steps/s
[Step=6850 Epoch=33.4] | Loss=0.06230 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.626 | L2-Norm(final)=4.337 | 4471.0 samples/s | 69.9 steps/s
[Step=6900 Epoch=33.6] | Loss=0.05994 | Reg=0.00427 | acc=0.9531 | L2-Norm=20.664 | L2-Norm(final)=4.332 | 5860.3 samples/s | 91.6 steps/s
[Step=6950 Epoch=33.9] | Loss=0.05644 | Reg=0.00428 | acc=0.9688 | L2-Norm=20.698 | L2-Norm(final)=4.328 | 1654.3 samples/s | 25.8 steps/s
[Step=7000 Epoch=34.1] | Loss=0.05288 | Reg=0.00430 | acc=0.9531 | L2-Norm=20.726 | L2-Norm(final)=4.327 | 4496.3 samples/s | 70.3 steps/s
[Step=7050 Epoch=34.4] | Loss=0.05001 | Reg=0.00431 | acc=1.0000 | L2-Norm=20.750 | L2-Norm(final)=4.327 | 4334.2 samples/s | 67.7 steps/s
[Step=7100 Epoch=34.6] | Loss=0.04887 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.771 | L2-Norm(final)=4.326 | 5264.3 samples/s | 82.3 steps/s
[Step=7150 Epoch=34.9] | Loss=0.04801 | Reg=0.00432 | acc=0.9688 | L2-Norm=20.792 | L2-Norm(final)=4.324 | 2234.5 samples/s | 34.9 steps/s
[Step=7200 Epoch=35.1] | Loss=0.04626 | Reg=0.00433 | acc=0.9688 | L2-Norm=20.812 | L2-Norm(final)=4.322 | 4409.0 samples/s | 68.9 steps/s
[Step=7250 Epoch=35.4] | Loss=0.04465 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.831 | L2-Norm(final)=4.322 | 4468.6 samples/s | 69.8 steps/s
[Step=7300 Epoch=35.6] | Loss=0.04343 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.849 | L2-Norm(final)=4.322 | 4964.1 samples/s | 77.6 steps/s
[Step=7350 Epoch=35.8] | Loss=0.04182 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.865 | L2-Norm(final)=4.322 | 2327.2 samples/s | 36.4 steps/s
[Step=7400 Epoch=36.1] | Loss=0.04049 | Reg=0.00436 | acc=0.9531 | L2-Norm=20.878 | L2-Norm(final)=4.322 | 4392.4 samples/s | 68.6 steps/s
[Step=7450 Epoch=36.3] | Loss=0.03925 | Reg=0.00436 | acc=0.9688 | L2-Norm=20.891 | L2-Norm(final)=4.322 | 4556.1 samples/s | 71.2 steps/s
[Step=7500 Epoch=36.6] | Loss=0.03816 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.903 | L2-Norm(final)=4.323 | 4571.6 samples/s | 71.4 steps/s
[Step=7550 Epoch=36.8] | Loss=0.03734 | Reg=0.00437 | acc=0.9531 | L2-Norm=20.913 | L2-Norm(final)=4.323 | 2432.7 samples/s | 38.0 steps/s
[Step=7600 Epoch=37.1] | Loss=0.03633 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.922 | L2-Norm(final)=4.323 | 4395.9 samples/s | 68.7 steps/s
[Step=7650 Epoch=37.3] | Loss=0.03536 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.930 | L2-Norm(final)=4.323 | 4465.8 samples/s | 69.8 steps/s
[Step=7700 Epoch=37.5] | Loss=0.03445 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.938 | L2-Norm(final)=4.324 | 4406.5 samples/s | 68.9 steps/s
[Step=7750 Epoch=37.8] | Loss=0.03366 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.945 | L2-Norm(final)=4.325 | 2484.9 samples/s | 38.8 steps/s
[Step=7800 Epoch=38.0] | Loss=0.03285 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.951 | L2-Norm(final)=4.326 | 4431.7 samples/s | 69.2 steps/s
[Step=7850 Epoch=38.3] | Loss=0.03201 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.957 | L2-Norm(final)=4.327 | 4504.3 samples/s | 70.4 steps/s
[Step=7900 Epoch=38.5] | Loss=0.03127 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.961 | L2-Norm(final)=4.328 | 4525.8 samples/s | 70.7 steps/s
[Step=7950 Epoch=38.8] | Loss=0.03052 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.964 | L2-Norm(final)=4.329 | 2439.3 samples/s | 38.1 steps/s
[Step=8000 Epoch=39.0] | Loss=0.02971 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.966 | L2-Norm(final)=4.330 | 4518.3 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step8000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=29.4] | Loss=0.11476 | Reg=0.00397 | acc=0.9219 | L2-Norm=19.920 | L2-Norm(final)=4.225 | 5819.5 samples/s | 90.9 steps/s
[Step=6050 Epoch=29.7] | Loss=0.07354 | Reg=0.00398 | acc=0.9219 | L2-Norm=19.938 | L2-Norm(final)=4.248 | 4303.9 samples/s | 67.2 steps/s
[Step=6100 Epoch=29.9] | Loss=0.06776 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.958 | L2-Norm(final)=4.269 | 4920.4 samples/s | 76.9 steps/s
[Step=6150 Epoch=30.2] | Loss=0.06522 | Reg=0.00399 | acc=0.9531 | L2-Norm=19.979 | L2-Norm(final)=4.294 | 5073.9 samples/s | 79.3 steps/s
[Step=6200 Epoch=30.4] | Loss=0.06463 | Reg=0.00400 | acc=0.9219 | L2-Norm=20.005 | L2-Norm(final)=4.318 | 7978.5 samples/s | 124.7 steps/s
[Step=6250 Epoch=30.6] | Loss=0.06259 | Reg=0.00401 | acc=0.9062 | L2-Norm=20.030 | L2-Norm(final)=4.343 | 2188.8 samples/s | 34.2 steps/s
[Step=6300 Epoch=30.9] | Loss=0.06161 | Reg=0.00402 | acc=0.9688 | L2-Norm=20.059 | L2-Norm(final)=4.371 | 5139.6 samples/s | 80.3 steps/s
[Step=6350 Epoch=31.1] | Loss=0.06126 | Reg=0.00404 | acc=0.9531 | L2-Norm=20.088 | L2-Norm(final)=4.400 | 4910.3 samples/s | 76.7 steps/s
[Step=6400 Epoch=31.4] | Loss=0.05965 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.120 | L2-Norm(final)=4.430 | 7238.1 samples/s | 113.1 steps/s
[Step=6450 Epoch=31.6] | Loss=0.05871 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.155 | L2-Norm(final)=4.463 | 2270.5 samples/s | 35.5 steps/s
[Step=6500 Epoch=31.9] | Loss=0.05748 | Reg=0.00408 | acc=0.9375 | L2-Norm=20.192 | L2-Norm(final)=4.497 | 5163.8 samples/s | 80.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=31.9] | Loss=0.05663 | Reg=0.00423 | acc=0.9219 | L2-Norm=20.576 | L2-Norm(final)=4.852 | 5232.0 samples/s | 81.8 steps/s
[Step=6550 Epoch=32.1] | Loss=0.06819 | Reg=0.00426 | acc=0.9375 | L2-Norm=20.633 | L2-Norm(final)=4.867 | 4112.6 samples/s | 64.3 steps/s
[Step=6600 Epoch=32.4] | Loss=0.07667 | Reg=0.00428 | acc=0.9844 | L2-Norm=20.699 | L2-Norm(final)=4.853 | 4469.8 samples/s | 69.8 steps/s
[Step=6650 Epoch=32.6] | Loss=0.07244 | Reg=0.00431 | acc=0.9844 | L2-Norm=20.751 | L2-Norm(final)=4.839 | 4432.2 samples/s | 69.3 steps/s
[Step=6700 Epoch=32.9] | Loss=0.07137 | Reg=0.00432 | acc=0.9531 | L2-Norm=20.796 | L2-Norm(final)=4.826 | 6659.2 samples/s | 104.0 steps/s
[Step=6750 Epoch=33.1] | Loss=0.06511 | Reg=0.00434 | acc=0.9688 | L2-Norm=20.834 | L2-Norm(final)=4.820 | 2079.1 samples/s | 32.5 steps/s
[Step=6800 Epoch=33.3] | Loss=0.05922 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.863 | L2-Norm(final)=4.818 | 4326.9 samples/s | 67.6 steps/s
[Step=6850 Epoch=33.6] | Loss=0.05557 | Reg=0.00436 | acc=0.9219 | L2-Norm=20.887 | L2-Norm(final)=4.817 | 4448.9 samples/s | 69.5 steps/s
[Step=6900 Epoch=33.8] | Loss=0.05388 | Reg=0.00437 | acc=0.9844 | L2-Norm=20.911 | L2-Norm(final)=4.816 | 6256.0 samples/s | 97.8 steps/s
[Step=6950 Epoch=34.1] | Loss=0.05127 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.936 | L2-Norm(final)=4.814 | 2127.4 samples/s | 33.2 steps/s
[Step=7000 Epoch=34.3] | Loss=0.04897 | Reg=0.00439 | acc=0.9688 | L2-Norm=20.959 | L2-Norm(final)=4.813 | 4479.6 samples/s | 70.0 steps/s
[Step=7050 Epoch=34.6] | Loss=0.04724 | Reg=0.00440 | acc=0.9531 | L2-Norm=20.980 | L2-Norm(final)=4.813 | 4409.7 samples/s | 68.9 steps/s
[Step=7100 Epoch=34.8] | Loss=0.04547 | Reg=0.00441 | acc=0.9688 | L2-Norm=20.999 | L2-Norm(final)=4.812 | 5769.4 samples/s | 90.1 steps/s
[Step=7150 Epoch=35.1] | Loss=0.04331 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.016 | L2-Norm(final)=4.813 | 2175.6 samples/s | 34.0 steps/s
[Step=7200 Epoch=35.3] | Loss=0.04124 | Reg=0.00442 | acc=0.9844 | L2-Norm=21.032 | L2-Norm(final)=4.814 | 4447.2 samples/s | 69.5 steps/s
[Step=7250 Epoch=35.6] | Loss=0.03931 | Reg=0.00443 | acc=0.9531 | L2-Norm=21.045 | L2-Norm(final)=4.817 | 4461.3 samples/s | 69.7 steps/s
[Step=7300 Epoch=35.8] | Loss=0.03801 | Reg=0.00443 | acc=0.9531 | L2-Norm=21.057 | L2-Norm(final)=4.820 | 5502.3 samples/s | 86.0 steps/s
[Step=7350 Epoch=36.0] | Loss=0.03667 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.070 | L2-Norm(final)=4.822 | 2208.6 samples/s | 34.5 steps/s
[Step=7400 Epoch=36.3] | Loss=0.03536 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.082 | L2-Norm(final)=4.825 | 4421.4 samples/s | 69.1 steps/s
[Step=7450 Epoch=36.5] | Loss=0.03429 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.092 | L2-Norm(final)=4.829 | 4435.6 samples/s | 69.3 steps/s
[Step=7500 Epoch=36.8] | Loss=0.03347 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.102 | L2-Norm(final)=4.832 | 5184.9 samples/s | 81.0 steps/s
[Step=7550 Epoch=37.0] | Loss=0.03248 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.111 | L2-Norm(final)=4.835 | 2298.3 samples/s | 35.9 steps/s
[Step=7600 Epoch=37.3] | Loss=0.03154 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.120 | L2-Norm(final)=4.839 | 4483.7 samples/s | 70.1 steps/s
[Step=7650 Epoch=37.5] | Loss=0.03081 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.127 | L2-Norm(final)=4.842 | 4438.5 samples/s | 69.4 steps/s
[Step=7700 Epoch=37.8] | Loss=0.03027 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.134 | L2-Norm(final)=4.846 | 4935.0 samples/s | 77.1 steps/s
[Step=7750 Epoch=38.0] | Loss=0.02962 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.142 | L2-Norm(final)=4.849 | 2304.4 samples/s | 36.0 steps/s
[Step=7800 Epoch=38.2] | Loss=0.02908 | Reg=0.00447 | acc=0.9688 | L2-Norm=21.150 | L2-Norm(final)=4.852 | 4470.7 samples/s | 69.9 steps/s
[Step=7850 Epoch=38.5] | Loss=0.02862 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.158 | L2-Norm(final)=4.855 | 4484.0 samples/s | 70.1 steps/s
[Step=7900 Epoch=38.7] | Loss=0.02836 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.166 | L2-Norm(final)=4.858 | 4703.5 samples/s | 73.5 steps/s
[Step=7950 Epoch=39.0] | Loss=0.02799 | Reg=0.00448 | acc=0.9844 | L2-Norm=21.175 | L2-Norm(final)=4.860 | 2407.1 samples/s | 37.6 steps/s
[Step=8000 Epoch=39.2] | Loss=0.02757 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.184 | L2-Norm(final)=4.862 | 4500.8 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step8000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=56.9] | Loss=0.08478 | Reg=0.00194 | acc=0.8906 | L2-Norm=13.940 | L2-Norm(final)=3.455 | 5408.5 samples/s | 84.5 steps/s
[Step=6050 Epoch=57.3] | Loss=0.01790 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.982 | L2-Norm(final)=3.447 | 4100.2 samples/s | 64.1 steps/s
[Step=6100 Epoch=57.8] | Loss=0.01308 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.026 | L2-Norm(final)=3.460 | 7199.6 samples/s | 112.5 steps/s
[Step=6150 Epoch=58.3] | Loss=0.01089 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.058 | L2-Norm(final)=3.480 | 2207.0 samples/s | 34.5 steps/s
[Step=6200 Epoch=58.8] | Loss=0.00948 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.086 | L2-Norm(final)=3.502 | 6054.3 samples/s | 94.6 steps/s
[Step=6250 Epoch=59.2] | Loss=0.00861 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.110 | L2-Norm(final)=3.523 | 2216.8 samples/s | 34.6 steps/s
[Step=6300 Epoch=59.7] | Loss=0.00818 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.133 | L2-Norm(final)=3.546 | 5847.4 samples/s | 91.4 steps/s
[Step=6350 Epoch=60.2] | Loss=0.00759 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.154 | L2-Norm(final)=3.567 | 2293.5 samples/s | 35.8 steps/s
[Step=6400 Epoch=60.6] | Loss=0.00697 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.175 | L2-Norm(final)=3.589 | 5268.8 samples/s | 82.3 steps/s
[Step=6450 Epoch=61.1] | Loss=0.00658 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.194 | L2-Norm(final)=3.610 | 2390.5 samples/s | 37.4 steps/s
[Step=6500 Epoch=61.6] | Loss=0.00628 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.211 | L2-Norm(final)=3.630 | 4864.5 samples/s | 76.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=61.6] | Loss=0.00150 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.388 | L2-Norm(final)=3.836 | 5477.1 samples/s | 85.6 steps/s
[Step=6550 Epoch=62.1] | Loss=0.03089 | Reg=0.00210 | acc=0.9375 | L2-Norm=14.494 | L2-Norm(final)=3.826 | 3681.9 samples/s | 57.5 steps/s
[Step=6600 Epoch=62.5] | Loss=0.02436 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.617 | L2-Norm(final)=3.782 | 6244.4 samples/s | 97.6 steps/s
[Step=6650 Epoch=63.0] | Loss=0.01661 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=3.769 | 2020.8 samples/s | 31.6 steps/s
[Step=6700 Epoch=63.5] | Loss=0.01324 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=3.764 | 5467.3 samples/s | 85.4 steps/s
[Step=6750 Epoch=64.0] | Loss=0.01072 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=3.762 | 2097.6 samples/s | 32.8 steps/s
[Step=6800 Epoch=64.4] | Loss=0.00897 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=3.761 | 5075.7 samples/s | 79.3 steps/s
[Step=6850 Epoch=64.9] | Loss=0.00770 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=3.761 | 2172.3 samples/s | 33.9 steps/s
[Step=6900 Epoch=65.4] | Loss=0.00674 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=3.762 | 4617.4 samples/s | 72.1 steps/s
[Step=6950 Epoch=65.9] | Loss=0.00600 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=3.762 | 2241.9 samples/s | 35.0 steps/s
[Step=7000 Epoch=66.3] | Loss=0.00540 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=3.763 | 4287.3 samples/s | 67.0 steps/s
[Step=7050 Epoch=66.8] | Loss=0.00491 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=3.763 | 2376.8 samples/s | 37.1 steps/s
[Step=7100 Epoch=67.3] | Loss=0.00450 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=3.764 | 4173.1 samples/s | 65.2 steps/s
[Step=7150 Epoch=67.8] | Loss=0.00416 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=3.765 | 2408.1 samples/s | 37.6 steps/s
[Step=7200 Epoch=68.2] | Loss=0.00386 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=3.765 | 4160.8 samples/s | 65.0 steps/s
[Step=7250 Epoch=68.7] | Loss=0.00361 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=3.766 | 2351.2 samples/s | 36.7 steps/s
[Step=7300 Epoch=69.2] | Loss=0.00338 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=3.766 | 4276.1 samples/s | 66.8 steps/s
[Step=7350 Epoch=69.6] | Loss=0.00318 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=3.767 | 2703.8 samples/s | 42.2 steps/s
[Step=7400 Epoch=70.1] | Loss=0.00301 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=3.767 | 3663.6 samples/s | 57.2 steps/s
[Step=7450 Epoch=70.6] | Loss=0.00285 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=3.768 | 6536.3 samples/s | 102.1 steps/s
[Step=7500 Epoch=71.1] | Loss=0.00271 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.590 | L2-Norm(final)=3.768 | 2003.7 samples/s | 31.3 steps/s
[Step=7550 Epoch=71.5] | Loss=0.00258 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=3.769 | 5781.4 samples/s | 90.3 steps/s
[Step=7600 Epoch=72.0] | Loss=0.00246 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.562 | L2-Norm(final)=3.769 | 2050.4 samples/s | 32.0 steps/s
[Step=7650 Epoch=72.5] | Loss=0.00236 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=3.770 | 5188.0 samples/s | 81.1 steps/s
[Step=7700 Epoch=73.0] | Loss=0.00226 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.533 | L2-Norm(final)=3.770 | 2160.7 samples/s | 33.8 steps/s
[Step=7750 Epoch=73.4] | Loss=0.00217 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.518 | L2-Norm(final)=3.771 | 4864.8 samples/s | 76.0 steps/s
[Step=7800 Epoch=73.9] | Loss=0.00208 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=3.772 | 2271.0 samples/s | 35.5 steps/s
[Step=7850 Epoch=74.4] | Loss=0.00201 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.487 | L2-Norm(final)=3.773 | 4285.7 samples/s | 67.0 steps/s
[Step=7900 Epoch=74.9] | Loss=0.00194 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.471 | L2-Norm(final)=3.775 | 2299.8 samples/s | 35.9 steps/s
[Step=7950 Epoch=75.3] | Loss=0.00187 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.456 | L2-Norm(final)=3.776 | 4261.9 samples/s | 66.6 steps/s
[Step=8000 Epoch=75.8] | Loss=0.00181 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.440 | L2-Norm(final)=3.778 | 2381.1 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step8000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=57.1] | Loss=0.17935 | Reg=0.00201 | acc=0.8750 | L2-Norm=14.161 | L2-Norm(final)=3.612 | 5288.6 samples/s | 82.6 steps/s
[Step=6050 Epoch=57.6] | Loss=0.02329 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.280 | L2-Norm(final)=3.610 | 4148.5 samples/s | 64.8 steps/s
[Step=6100 Epoch=58.0] | Loss=0.01578 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.336 | L2-Norm(final)=3.632 | 7508.6 samples/s | 117.3 steps/s
[Step=6150 Epoch=58.5] | Loss=0.01240 | Reg=0.00207 | acc=0.9688 | L2-Norm=14.373 | L2-Norm(final)=3.656 | 2140.3 samples/s | 33.4 steps/s
[Step=6200 Epoch=59.0] | Loss=0.01055 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.405 | L2-Norm(final)=3.681 | 6473.7 samples/s | 101.2 steps/s
[Step=6250 Epoch=59.5] | Loss=0.00909 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.431 | L2-Norm(final)=3.704 | 2228.6 samples/s | 34.8 steps/s
[Step=6300 Epoch=59.9] | Loss=0.00826 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.454 | L2-Norm(final)=3.726 | 5843.8 samples/s | 91.3 steps/s
[Step=6350 Epoch=60.4] | Loss=0.00754 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=3.749 | 2307.8 samples/s | 36.1 steps/s
[Step=6400 Epoch=60.9] | Loss=0.00693 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=3.770 | 5348.0 samples/s | 83.6 steps/s
[Step=6450 Epoch=61.4] | Loss=0.00645 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.517 | L2-Norm(final)=3.791 | 2354.1 samples/s | 36.8 steps/s
[Step=6500 Epoch=61.8] | Loss=0.00606 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.537 | L2-Norm(final)=3.812 | 4890.0 samples/s | 76.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=61.8] | Loss=0.00266 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=4.020 | 5653.5 samples/s | 88.3 steps/s
[Step=6550 Epoch=62.3] | Loss=0.02857 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.875 | L2-Norm(final)=4.008 | 3604.5 samples/s | 56.3 steps/s
[Step=6600 Epoch=62.8] | Loss=0.02136 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=3.981 | 6260.1 samples/s | 97.8 steps/s
[Step=6650 Epoch=63.3] | Loss=0.01462 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=3.972 | 2039.3 samples/s | 31.9 steps/s
[Step=6700 Epoch=63.7] | Loss=0.01115 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=3.969 | 5675.4 samples/s | 88.7 steps/s
[Step=6750 Epoch=64.2] | Loss=0.00897 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=3.968 | 2049.4 samples/s | 32.0 steps/s
[Step=6800 Epoch=64.7] | Loss=0.00749 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=3.967 | 5101.0 samples/s | 79.7 steps/s
[Step=6850 Epoch=65.2] | Loss=0.00643 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=3.968 | 2200.9 samples/s | 34.4 steps/s
[Step=6900 Epoch=65.6] | Loss=0.00563 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=3.968 | 4666.5 samples/s | 72.9 steps/s
[Step=6950 Epoch=66.1] | Loss=0.00501 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=3.968 | 2259.5 samples/s | 35.3 steps/s
[Step=7000 Epoch=66.6] | Loss=0.00451 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=3.969 | 4267.6 samples/s | 66.7 steps/s
[Step=7050 Epoch=67.1] | Loss=0.00410 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=3.969 | 2342.8 samples/s | 36.6 steps/s
[Step=7100 Epoch=67.5] | Loss=0.00376 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=3.970 | 4316.9 samples/s | 67.5 steps/s
[Step=7150 Epoch=68.0] | Loss=0.00347 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=3.971 | 2375.1 samples/s | 37.1 steps/s
[Step=7200 Epoch=68.5] | Loss=0.00322 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=3.972 | 4258.5 samples/s | 66.5 steps/s
[Step=7250 Epoch=69.0] | Loss=0.00301 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=3.973 | 2404.1 samples/s | 37.6 steps/s
[Step=7300 Epoch=69.4] | Loss=0.00282 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=3.974 | 4167.6 samples/s | 65.1 steps/s
[Step=7350 Epoch=69.9] | Loss=0.00266 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=3.976 | 2574.9 samples/s | 40.2 steps/s
[Step=7400 Epoch=70.4] | Loss=0.00251 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=3.978 | 3818.3 samples/s | 59.7 steps/s
[Step=7450 Epoch=70.9] | Loss=0.00238 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=3.980 | 6576.1 samples/s | 102.8 steps/s
[Step=7500 Epoch=71.3] | Loss=0.00226 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.051 | L2-Norm(final)=3.983 | 1994.0 samples/s | 31.2 steps/s
[Step=7550 Epoch=71.8] | Loss=0.00215 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=3.986 | 5879.6 samples/s | 91.9 steps/s
[Step=7600 Epoch=72.3] | Loss=0.00206 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=3.989 | 2060.0 samples/s | 32.2 steps/s
[Step=7650 Epoch=72.8] | Loss=0.00197 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=3.992 | 5312.8 samples/s | 83.0 steps/s
[Step=7700 Epoch=73.2] | Loss=0.00189 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=3.995 | 2162.2 samples/s | 33.8 steps/s
[Step=7750 Epoch=73.7] | Loss=0.00181 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=3.999 | 4758.0 samples/s | 74.3 steps/s
[Step=7800 Epoch=74.2] | Loss=0.00174 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=4.003 | 2228.6 samples/s | 34.8 steps/s
[Step=7850 Epoch=74.7] | Loss=0.00168 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=4.007 | 4501.3 samples/s | 70.3 steps/s
[Step=7900 Epoch=75.1] | Loss=0.00162 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=4.012 | 2278.9 samples/s | 35.6 steps/s
[Step=7950 Epoch=75.6] | Loss=0.00156 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.906 | L2-Norm(final)=4.016 | 4294.2 samples/s | 67.1 steps/s
[Step=8000 Epoch=76.1] | Loss=0.00151 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.889 | L2-Norm(final)=4.021 | 2394.4 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step8000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=57.3] | Loss=0.11062 | Reg=0.00224 | acc=0.9219 | L2-Norm=14.974 | L2-Norm(final)=3.599 | 5328.4 samples/s | 83.3 steps/s
[Step=6050 Epoch=57.8] | Loss=0.01930 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=3.591 | 4182.4 samples/s | 65.3 steps/s
[Step=6100 Epoch=58.3] | Loss=0.01429 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=3.606 | 7509.8 samples/s | 117.3 steps/s
[Step=6150 Epoch=58.7] | Loss=0.01227 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=3.626 | 2072.0 samples/s | 32.4 steps/s
[Step=6200 Epoch=59.2] | Loss=0.01076 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.122 | L2-Norm(final)=3.645 | 6867.6 samples/s | 107.3 steps/s
[Step=6250 Epoch=59.7] | Loss=0.00958 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=3.666 | 2213.9 samples/s | 34.6 steps/s
[Step=6300 Epoch=60.2] | Loss=0.00890 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=3.686 | 6128.1 samples/s | 95.8 steps/s
[Step=6350 Epoch=60.6] | Loss=0.00830 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=3.706 | 2282.3 samples/s | 35.7 steps/s
[Step=6400 Epoch=61.1] | Loss=0.00786 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=3.725 | 5416.3 samples/s | 84.6 steps/s
[Step=6450 Epoch=61.6] | Loss=0.00738 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=3.745 | 2154.6 samples/s | 33.7 steps/s
[Step=6500 Epoch=62.1] | Loss=0.00696 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=3.764 | 5203.6 samples/s | 81.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=62.1] | Loss=0.01292 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.508 | L2-Norm(final)=3.955 | 5205.6 samples/s | 81.3 steps/s
[Step=6550 Epoch=62.5] | Loss=0.03113 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.685 | L2-Norm(final)=3.935 | 3803.5 samples/s | 59.4 steps/s
[Step=6600 Epoch=63.0] | Loss=0.02381 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.799 | L2-Norm(final)=3.906 | 6179.0 samples/s | 96.5 steps/s
[Step=6650 Epoch=63.5] | Loss=0.01665 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.845 | L2-Norm(final)=3.891 | 2012.4 samples/s | 31.4 steps/s
[Step=6700 Epoch=64.0] | Loss=0.01253 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=3.885 | 5688.3 samples/s | 88.9 steps/s
[Step=6750 Epoch=64.5] | Loss=0.01005 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=3.882 | 2039.4 samples/s | 31.9 steps/s
[Step=6800 Epoch=64.9] | Loss=0.00838 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.864 | L2-Norm(final)=3.880 | 5274.1 samples/s | 82.4 steps/s
[Step=6850 Epoch=65.4] | Loss=0.00719 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.857 | L2-Norm(final)=3.879 | 2117.2 samples/s | 33.1 steps/s
[Step=6900 Epoch=65.9] | Loss=0.00629 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=3.878 | 4846.9 samples/s | 75.7 steps/s
[Step=6950 Epoch=66.4] | Loss=0.00559 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=3.878 | 2164.9 samples/s | 33.8 steps/s
[Step=7000 Epoch=66.8] | Loss=0.00504 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=3.877 | 4581.6 samples/s | 71.6 steps/s
[Step=7050 Epoch=67.3] | Loss=0.00458 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.812 | L2-Norm(final)=3.877 | 2211.9 samples/s | 34.6 steps/s
[Step=7100 Epoch=67.8] | Loss=0.00420 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.798 | L2-Norm(final)=3.877 | 4323.6 samples/s | 67.6 steps/s
[Step=7150 Epoch=68.3] | Loss=0.00388 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=3.877 | 2323.6 samples/s | 36.3 steps/s
[Step=7200 Epoch=68.8] | Loss=0.00360 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=3.877 | 4204.5 samples/s | 65.7 steps/s
[Step=7250 Epoch=69.2] | Loss=0.00336 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.753 | L2-Norm(final)=3.877 | 2386.0 samples/s | 37.3 steps/s
[Step=7300 Epoch=69.7] | Loss=0.00315 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=3.877 | 4216.0 samples/s | 65.9 steps/s
[Step=7350 Epoch=70.2] | Loss=0.00297 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=3.877 | 2283.2 samples/s | 35.7 steps/s
[Step=7400 Epoch=70.7] | Loss=0.00280 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.705 | L2-Norm(final)=3.877 | 4270.5 samples/s | 66.7 steps/s
[Step=7450 Epoch=71.1] | Loss=0.00266 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=3.878 | 2338.0 samples/s | 36.5 steps/s
[Step=7500 Epoch=71.6] | Loss=0.00252 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.672 | L2-Norm(final)=3.878 | 4145.4 samples/s | 64.8 steps/s
[Step=7550 Epoch=72.1] | Loss=0.00241 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.655 | L2-Norm(final)=3.878 | 6940.3 samples/s | 108.4 steps/s
[Step=7600 Epoch=72.6] | Loss=0.00230 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.638 | L2-Norm(final)=3.878 | 1931.3 samples/s | 30.2 steps/s
[Step=7650 Epoch=73.1] | Loss=0.00220 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.620 | L2-Norm(final)=3.878 | 6273.7 samples/s | 98.0 steps/s
[Step=7700 Epoch=73.5] | Loss=0.00211 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.603 | L2-Norm(final)=3.879 | 1987.1 samples/s | 31.0 steps/s
[Step=7750 Epoch=74.0] | Loss=0.00202 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=3.879 | 5682.6 samples/s | 88.8 steps/s
[Step=7800 Epoch=74.5] | Loss=0.00194 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.567 | L2-Norm(final)=3.879 | 2045.6 samples/s | 32.0 steps/s
[Step=7850 Epoch=75.0] | Loss=0.00187 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=3.879 | 5257.8 samples/s | 82.2 steps/s
[Step=7900 Epoch=75.4] | Loss=0.00181 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.530 | L2-Norm(final)=3.879 | 2117.1 samples/s | 33.1 steps/s
[Step=7950 Epoch=75.9] | Loss=0.00174 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.512 | L2-Norm(final)=3.880 | 4891.6 samples/s | 76.4 steps/s
[Step=8000 Epoch=76.4] | Loss=0.00169 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=3.880 | 2180.4 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step8000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=56.5] | Loss=0.06008 | Reg=0.00219 | acc=0.9375 | L2-Norm=14.799 | L2-Norm(final)=3.291 | 5454.9 samples/s | 85.2 steps/s
[Step=6050 Epoch=57.0] | Loss=0.02446 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.852 | L2-Norm(final)=3.270 | 3981.1 samples/s | 62.2 steps/s
[Step=6100 Epoch=57.5] | Loss=0.01837 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.889 | L2-Norm(final)=3.285 | 7312.8 samples/s | 114.3 steps/s
[Step=6150 Epoch=58.0] | Loss=0.01553 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=3.309 | 2147.7 samples/s | 33.6 steps/s
[Step=6200 Epoch=58.4] | Loss=0.01408 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=3.333 | 6137.0 samples/s | 95.9 steps/s
[Step=6250 Epoch=58.9] | Loss=0.01278 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=3.358 | 2207.5 samples/s | 34.5 steps/s
[Step=6300 Epoch=59.4] | Loss=0.01162 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=3.382 | 5582.7 samples/s | 87.2 steps/s
[Step=6350 Epoch=59.8] | Loss=0.01041 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.049 | L2-Norm(final)=3.407 | 2339.0 samples/s | 36.5 steps/s
[Step=6400 Epoch=60.3] | Loss=0.00963 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=3.431 | 4998.6 samples/s | 78.1 steps/s
[Step=6450 Epoch=60.8] | Loss=0.00930 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=3.455 | 2462.2 samples/s | 38.5 steps/s
[Step=6500 Epoch=61.2] | Loss=0.00873 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=3.479 | 4659.7 samples/s | 72.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=61.3] | Loss=0.00121 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=3.723 | 5103.7 samples/s | 79.7 steps/s
[Step=6550 Epoch=61.7] | Loss=0.04184 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.471 | L2-Norm(final)=3.686 | 3901.5 samples/s | 61.0 steps/s
[Step=6600 Epoch=62.2] | Loss=0.02635 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.611 | L2-Norm(final)=3.655 | 6158.9 samples/s | 96.2 steps/s
[Step=6650 Epoch=62.7] | Loss=0.01816 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=3.649 | 2013.0 samples/s | 31.5 steps/s
[Step=6700 Epoch=63.1] | Loss=0.01377 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=3.647 | 5441.8 samples/s | 85.0 steps/s
[Step=6750 Epoch=63.6] | Loss=0.01113 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.692 | L2-Norm(final)=3.648 | 2099.3 samples/s | 32.8 steps/s
[Step=6800 Epoch=64.1] | Loss=0.00930 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.692 | L2-Norm(final)=3.649 | 4859.3 samples/s | 75.9 steps/s
[Step=6850 Epoch=64.5] | Loss=0.00798 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=3.651 | 2190.9 samples/s | 34.2 steps/s
[Step=6900 Epoch=65.0] | Loss=0.00699 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=3.652 | 4444.0 samples/s | 69.4 steps/s
[Step=6950 Epoch=65.5] | Loss=0.00622 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.673 | L2-Norm(final)=3.653 | 2309.7 samples/s | 36.1 steps/s
[Step=7000 Epoch=66.0] | Loss=0.00560 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=3.654 | 4142.5 samples/s | 64.7 steps/s
[Step=7050 Epoch=66.4] | Loss=0.00509 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.651 | L2-Norm(final)=3.655 | 2305.8 samples/s | 36.0 steps/s
[Step=7100 Epoch=66.9] | Loss=0.00467 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.638 | L2-Norm(final)=3.656 | 4187.8 samples/s | 65.4 steps/s
[Step=7150 Epoch=67.4] | Loss=0.00431 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.625 | L2-Norm(final)=3.657 | 2367.0 samples/s | 37.0 steps/s
[Step=7200 Epoch=67.8] | Loss=0.00401 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.611 | L2-Norm(final)=3.658 | 4156.8 samples/s | 65.0 steps/s
[Step=7250 Epoch=68.3] | Loss=0.00374 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=3.659 | 2570.9 samples/s | 40.2 steps/s
[Step=7300 Epoch=68.8] | Loss=0.00351 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=3.660 | 3706.0 samples/s | 57.9 steps/s
[Step=7350 Epoch=69.3] | Loss=0.00330 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=3.661 | 6116.9 samples/s | 95.6 steps/s
[Step=7400 Epoch=69.7] | Loss=0.00312 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=3.662 | 1999.6 samples/s | 31.2 steps/s
[Step=7450 Epoch=70.2] | Loss=0.00296 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.535 | L2-Norm(final)=3.663 | 5489.3 samples/s | 85.8 steps/s
[Step=7500 Epoch=70.7] | Loss=0.00281 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.518 | L2-Norm(final)=3.663 | 2093.2 samples/s | 32.7 steps/s
[Step=7550 Epoch=71.1] | Loss=0.00268 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=3.664 | 4909.3 samples/s | 76.7 steps/s
[Step=7600 Epoch=71.6] | Loss=0.00256 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=3.665 | 2159.1 samples/s | 33.7 steps/s
[Step=7650 Epoch=72.1] | Loss=0.00245 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.467 | L2-Norm(final)=3.665 | 4436.6 samples/s | 69.3 steps/s
[Step=7700 Epoch=72.6] | Loss=0.00234 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.450 | L2-Norm(final)=3.666 | 2290.6 samples/s | 35.8 steps/s
[Step=7750 Epoch=73.0] | Loss=0.00225 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.432 | L2-Norm(final)=3.667 | 4220.7 samples/s | 65.9 steps/s
[Step=7800 Epoch=73.5] | Loss=0.00216 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=3.667 | 2403.1 samples/s | 37.5 steps/s
[Step=7850 Epoch=74.0] | Loss=0.00208 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=3.668 | 4089.6 samples/s | 63.9 steps/s
[Step=7900 Epoch=74.4] | Loss=0.00201 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=3.669 | 2402.1 samples/s | 37.5 steps/s
[Step=7950 Epoch=74.9] | Loss=0.00194 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=3.669 | 4113.2 samples/s | 64.3 steps/s
[Step=8000 Epoch=75.4] | Loss=0.00188 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.340 | L2-Norm(final)=3.670 | 2505.6 samples/s | 39.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step8000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=57.2] | Loss=0.04451 | Reg=0.00201 | acc=0.9688 | L2-Norm=14.170 | L2-Norm(final)=4.084 | 5417.1 samples/s | 84.6 steps/s
[Step=6050 Epoch=57.7] | Loss=0.02143 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.241 | L2-Norm(final)=4.077 | 4026.6 samples/s | 62.9 steps/s
[Step=6100 Epoch=58.1] | Loss=0.01659 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.298 | L2-Norm(final)=4.103 | 7448.3 samples/s | 116.4 steps/s
[Step=6150 Epoch=58.6] | Loss=0.01435 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.340 | L2-Norm(final)=4.131 | 2067.1 samples/s | 32.3 steps/s
[Step=6200 Epoch=59.1] | Loss=0.01237 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.377 | L2-Norm(final)=4.161 | 6669.6 samples/s | 104.2 steps/s
[Step=6250 Epoch=59.6] | Loss=0.01105 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.410 | L2-Norm(final)=4.190 | 2190.3 samples/s | 34.2 steps/s
[Step=6300 Epoch=60.0] | Loss=0.00997 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.442 | L2-Norm(final)=4.220 | 5963.1 samples/s | 93.2 steps/s
[Step=6350 Epoch=60.5] | Loss=0.00915 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.470 | L2-Norm(final)=4.249 | 2245.0 samples/s | 35.1 steps/s
[Step=6400 Epoch=61.0] | Loss=0.00856 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.496 | L2-Norm(final)=4.277 | 5589.1 samples/s | 87.3 steps/s
[Step=6450 Epoch=61.5] | Loss=0.00789 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=4.305 | 2316.6 samples/s | 36.2 steps/s
[Step=6500 Epoch=62.0] | Loss=0.00738 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.543 | L2-Norm(final)=4.332 | 5134.2 samples/s | 80.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=62.0] | Loss=0.00192 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.763 | L2-Norm(final)=4.601 | 5380.4 samples/s | 84.1 steps/s
[Step=6550 Epoch=62.4] | Loss=0.03940 | Reg=0.00222 | acc=0.9531 | L2-Norm=14.901 | L2-Norm(final)=4.585 | 3653.5 samples/s | 57.1 steps/s
[Step=6600 Epoch=62.9] | Loss=0.02951 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=4.532 | 6277.7 samples/s | 98.1 steps/s
[Step=6650 Epoch=63.4] | Loss=0.02026 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=4.517 | 1975.7 samples/s | 30.9 steps/s
[Step=6700 Epoch=63.9] | Loss=0.01583 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.190 | L2-Norm(final)=4.511 | 5749.6 samples/s | 89.8 steps/s
[Step=6750 Epoch=64.3] | Loss=0.01277 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=4.509 | 2053.2 samples/s | 32.1 steps/s
[Step=6800 Epoch=64.8] | Loss=0.01066 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.215 | L2-Norm(final)=4.508 | 5286.3 samples/s | 82.6 steps/s
[Step=6850 Epoch=65.3] | Loss=0.00914 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.216 | L2-Norm(final)=4.508 | 2107.5 samples/s | 32.9 steps/s
[Step=6900 Epoch=65.8] | Loss=0.00800 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.214 | L2-Norm(final)=4.508 | 4927.9 samples/s | 77.0 steps/s
[Step=6950 Epoch=66.2] | Loss=0.00712 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=4.508 | 2199.6 samples/s | 34.4 steps/s
[Step=7000 Epoch=66.7] | Loss=0.00641 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=4.509 | 4535.2 samples/s | 70.9 steps/s
[Step=7050 Epoch=67.2] | Loss=0.00583 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=4.509 | 2233.1 samples/s | 34.9 steps/s
[Step=7100 Epoch=67.7] | Loss=0.00534 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=4.510 | 4321.8 samples/s | 67.5 steps/s
[Step=7150 Epoch=68.1] | Loss=0.00494 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=4.510 | 2355.5 samples/s | 36.8 steps/s
[Step=7200 Epoch=68.6] | Loss=0.00458 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=4.511 | 4295.9 samples/s | 67.1 steps/s
[Step=7250 Epoch=69.1] | Loss=0.00428 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=4.511 | 2375.4 samples/s | 37.1 steps/s
[Step=7300 Epoch=69.6] | Loss=0.00401 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=4.512 | 4129.2 samples/s | 64.5 steps/s
[Step=7350 Epoch=70.1] | Loss=0.00378 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=4.512 | 2355.1 samples/s | 36.8 steps/s
[Step=7400 Epoch=70.5] | Loss=0.00357 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=4.513 | 4167.4 samples/s | 65.1 steps/s
[Step=7450 Epoch=71.0] | Loss=0.00338 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=4.513 | 2210.1 samples/s | 34.5 steps/s
[Step=7500 Epoch=71.5] | Loss=0.00321 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=4.514 | 4107.1 samples/s | 64.2 steps/s
[Step=7550 Epoch=72.0] | Loss=0.00306 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=4.514 | 6593.8 samples/s | 103.0 steps/s
[Step=7600 Epoch=72.4] | Loss=0.00292 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=4.515 | 1866.3 samples/s | 29.2 steps/s
[Step=7650 Epoch=72.9] | Loss=0.00280 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=4.515 | 5845.2 samples/s | 91.3 steps/s
[Step=7700 Epoch=73.4] | Loss=0.00268 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=4.516 | 1904.9 samples/s | 29.8 steps/s
[Step=7750 Epoch=73.9] | Loss=0.00257 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=4.516 | 5547.5 samples/s | 86.7 steps/s
[Step=7800 Epoch=74.3] | Loss=0.00247 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=4.516 | 1968.3 samples/s | 30.8 steps/s
[Step=7850 Epoch=74.8] | Loss=0.00238 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=4.517 | 5369.5 samples/s | 83.9 steps/s
[Step=7900 Epoch=75.3] | Loss=0.00230 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=4.517 | 2112.2 samples/s | 33.0 steps/s
[Step=7950 Epoch=75.8] | Loss=0.00222 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=4.518 | 4900.7 samples/s | 76.6 steps/s
[Step=8000 Epoch=76.2] | Loss=0.00215 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=4.518 | 2200.0 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.14104 | acc=0.9369 | tpr=0.9514 | fpr=0.0946 | 4847.8 samples/s | 18.9 steps/s
Avg test loss: 0.15000, Avg test acc: 0.93365, Avg tpr: 0.94789, Avg fpr: 0.09768, total FA: 762

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.17269 | acc=0.9345 | tpr=0.9707 | fpr=0.1442 | 5038.7 samples/s | 19.7 steps/s
Avg test loss: 0.17033, Avg test acc: 0.93353, Avg tpr: 0.96829, Avg fpr: 0.14293, total FA: 1115

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14697 | acc=0.9396 | tpr=0.9618 | fpr=0.1085 | 5023.3 samples/s | 19.6 steps/s
Avg test loss: 0.14814, Avg test acc: 0.93830, Avg tpr: 0.96037, Avg fpr: 0.11024, total FA: 860

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.15157 | acc=0.9422 | tpr=0.9589 | fpr=0.0942 | 5110.2 samples/s | 20.0 steps/s
Avg test loss: 0.15846, Avg test acc: 0.94098, Avg tpr: 0.95932, Avg fpr: 0.09935, total FA: 775

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.15341 | acc=0.9359 | tpr=0.9466 | fpr=0.0872 | 4938.9 samples/s | 19.3 steps/s
Avg test loss: 0.15529, Avg test acc: 0.93429, Avg tpr: 0.94568, Avg fpr: 0.09076, total FA: 708

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.36672 | acc=0.3064 | tpr=0.0163 | fpr=0.0637 | 4677.0 samples/s | 18.3 steps/s
Avg test loss: 4.37829, Avg test acc: 0.30455, Avg tpr: 0.01702, Avg fpr: 0.06307, total FA: 492

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.16503 | acc=0.3133 | tpr=0.0138 | fpr=0.0364 | 5029.7 samples/s | 19.6 steps/s
Avg test loss: 4.17442, Avg test acc: 0.31128, Avg tpr: 0.01486, Avg fpr: 0.03679, total FA: 287

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.29968 | acc=0.3011 | tpr=0.0223 | fpr=0.0934 | 4870.9 samples/s | 19.0 steps/s
Avg test loss: 4.31363, Avg test acc: 0.30147, Avg tpr: 0.02279, Avg fpr: 0.08563, total FA: 668

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=4.08913 | acc=0.3066 | tpr=0.0092 | fpr=0.0476 | 4956.9 samples/s | 19.4 steps/s
Avg test loss: 4.10386, Avg test acc: 0.30539, Avg tpr: 0.01020, Avg fpr: 0.04538, total FA: 354

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.49512 | acc=0.3115 | tpr=0.0089 | fpr=0.0315 | 4713.4 samples/s | 18.4 steps/s
Avg test loss: 4.50549, Avg test acc: 0.30860, Avg tpr: 0.00833, Avg fpr: 0.03102, total FA: 242

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.02526 | acc=0.1103 | tpr=0.7257 | fpr=0.9007 | 4895.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.00164 | acc=0.1141 | tpr=0.6908 | fpr=0.8967 | 7495.0 samples/s | 29.3 steps/s
[Step= 150] | Loss=4.98937 | acc=0.1143 | tpr=0.7046 | fpr=0.8966 | 7167.3 samples/s | 28.0 steps/s
[Step= 200] | Loss=4.98137 | acc=0.1153 | tpr=0.6940 | fpr=0.8953 | 7867.9 samples/s | 30.7 steps/s
[Step= 250] | Loss=4.99793 | acc=0.1148 | tpr=0.6987 | fpr=0.8959 | 7619.8 samples/s | 29.8 steps/s
[Step= 300] | Loss=4.99862 | acc=0.1141 | tpr=0.6967 | fpr=0.8965 | 8432.0 samples/s | 32.9 steps/s
[Step= 350] | Loss=4.99677 | acc=0.1138 | tpr=0.6900 | fpr=0.8966 | 7598.5 samples/s | 29.7 steps/s
[Step= 400] | Loss=4.99819 | acc=0.1143 | tpr=0.6953 | fpr=0.8962 | 7812.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=4.99477 | acc=0.1145 | tpr=0.6981 | fpr=0.8961 | 7839.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.99578 | acc=0.1142 | tpr=0.6916 | fpr=0.8962 | 7872.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=4.99348 | acc=0.1146 | tpr=0.6904 | fpr=0.8959 | 13959.4 samples/s | 54.5 steps/s
Avg test loss: 4.99347, Avg test acc: 0.11445, Avg tpr: 0.69136, Avg fpr: 0.89604, total FA: 124413

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.14605 | acc=0.1209 | tpr=0.6947 | fpr=0.8894 | 4934.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=4.14497 | acc=0.1209 | tpr=0.7100 | fpr=0.8901 | 6955.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=4.13529 | acc=0.1209 | tpr=0.6974 | fpr=0.8897 | 7720.9 samples/s | 30.2 steps/s
[Step= 200] | Loss=4.13154 | acc=0.1214 | tpr=0.6852 | fpr=0.8889 | 7715.6 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.13898 | acc=0.1212 | tpr=0.6978 | fpr=0.8893 | 8057.3 samples/s | 31.5 steps/s
[Step= 300] | Loss=4.13420 | acc=0.1202 | tpr=0.7047 | fpr=0.8904 | 7672.2 samples/s | 30.0 steps/s
[Step= 350] | Loss=4.12475 | acc=0.1204 | tpr=0.7044 | fpr=0.8902 | 8201.1 samples/s | 32.0 steps/s
[Step= 400] | Loss=4.12433 | acc=0.1208 | tpr=0.7101 | fpr=0.8899 | 7621.8 samples/s | 29.8 steps/s
[Step= 450] | Loss=4.12699 | acc=0.1206 | tpr=0.7113 | fpr=0.8901 | 8104.4 samples/s | 31.7 steps/s
[Step= 500] | Loss=4.13367 | acc=0.1202 | tpr=0.7026 | fpr=0.8903 | 7638.1 samples/s | 29.8 steps/s
[Step= 550] | Loss=4.13422 | acc=0.1203 | tpr=0.7047 | fpr=0.8903 | 14081.6 samples/s | 55.0 steps/s
Avg test loss: 4.13563, Avg test acc: 0.12026, Avg tpr: 0.70563, Avg fpr: 0.89038, total FA: 123628

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.83558 | acc=0.0738 | tpr=0.6903 | fpr=0.9373 | 4837.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.81172 | acc=0.0734 | tpr=0.6780 | fpr=0.9378 | 7080.4 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.80570 | acc=0.0749 | tpr=0.6729 | fpr=0.9361 | 7563.3 samples/s | 29.5 steps/s
[Step= 200] | Loss=5.80252 | acc=0.0753 | tpr=0.6754 | fpr=0.9356 | 8264.6 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.81119 | acc=0.0756 | tpr=0.6821 | fpr=0.9354 | 7865.4 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.81055 | acc=0.0753 | tpr=0.6858 | fpr=0.9359 | 8109.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.80559 | acc=0.0754 | tpr=0.6800 | fpr=0.9356 | 7550.3 samples/s | 29.5 steps/s
[Step= 400] | Loss=5.80246 | acc=0.0754 | tpr=0.6772 | fpr=0.9355 | 7721.8 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.80329 | acc=0.0754 | tpr=0.6835 | fpr=0.9357 | 8241.9 samples/s | 32.2 steps/s
[Step= 500] | Loss=5.80818 | acc=0.0753 | tpr=0.6806 | fpr=0.9356 | 8045.3 samples/s | 31.4 steps/s
[Step= 550] | Loss=5.81081 | acc=0.0754 | tpr=0.6805 | fpr=0.9355 | 13097.7 samples/s | 51.2 steps/s
Avg test loss: 5.81230, Avg test acc: 0.07542, Avg tpr: 0.68027, Avg fpr: 0.93558, total FA: 129903

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.36499 | acc=0.1291 | tpr=0.8097 | fpr=0.8832 | 5024.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.34053 | acc=0.1287 | tpr=0.7889 | fpr=0.8836 | 6639.8 samples/s | 25.9 steps/s
[Step= 150] | Loss=5.32658 | acc=0.1285 | tpr=0.7867 | fpr=0.8836 | 8018.5 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.32214 | acc=0.1292 | tpr=0.7913 | fpr=0.8828 | 7574.6 samples/s | 29.6 steps/s
[Step= 250] | Loss=5.32989 | acc=0.1290 | tpr=0.7956 | fpr=0.8832 | 8120.9 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.33252 | acc=0.1287 | tpr=0.7949 | fpr=0.8834 | 7844.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.32410 | acc=0.1290 | tpr=0.7934 | fpr=0.8831 | 7775.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.31803 | acc=0.1296 | tpr=0.7905 | fpr=0.8824 | 8032.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.32436 | acc=0.1298 | tpr=0.7945 | fpr=0.8822 | 7661.2 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.32933 | acc=0.1294 | tpr=0.7925 | fpr=0.8825 | 7862.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.32983 | acc=0.1294 | tpr=0.7939 | fpr=0.8827 | 14176.8 samples/s | 55.4 steps/s
Avg test loss: 5.33108, Avg test acc: 0.12922, Avg tpr: 0.79477, Avg fpr: 0.88288, total FA: 122586

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.61215 | acc=0.1459 | tpr=0.4867 | fpr=0.8603 | 4813.5 samples/s | 18.8 steps/s
[Step= 100] | Loss=4.57531 | acc=0.1465 | tpr=0.4840 | fpr=0.8598 | 7092.0 samples/s | 27.7 steps/s
[Step= 150] | Loss=4.56355 | acc=0.1478 | tpr=0.4755 | fpr=0.8582 | 7901.7 samples/s | 30.9 steps/s
[Step= 200] | Loss=4.55259 | acc=0.1489 | tpr=0.4721 | fpr=0.8570 | 7697.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.55674 | acc=0.1492 | tpr=0.4760 | fpr=0.8568 | 7865.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=4.55576 | acc=0.1488 | tpr=0.4785 | fpr=0.8572 | 8084.0 samples/s | 31.6 steps/s
[Step= 350] | Loss=4.55132 | acc=0.1489 | tpr=0.4771 | fpr=0.8571 | 7553.9 samples/s | 29.5 steps/s
[Step= 400] | Loss=4.55016 | acc=0.1489 | tpr=0.4809 | fpr=0.8571 | 7571.8 samples/s | 29.6 steps/s
[Step= 450] | Loss=4.55181 | acc=0.1487 | tpr=0.4878 | fpr=0.8574 | 8430.0 samples/s | 32.9 steps/s
[Step= 500] | Loss=4.55433 | acc=0.1487 | tpr=0.4797 | fpr=0.8572 | 7957.9 samples/s | 31.1 steps/s
[Step= 550] | Loss=4.55642 | acc=0.1486 | tpr=0.4791 | fpr=0.8575 | 13330.9 samples/s | 52.1 steps/s
Avg test loss: 4.55791, Avg test acc: 0.14840, Avg tpr: 0.47861, Avg fpr: 0.85760, total FA: 119076

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09859 | acc=0.9807 | tpr=0.8805 | fpr=0.0175 | 4715.1 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.09711 | acc=0.9812 | tpr=0.9083 | fpr=0.0175 | 7342.4 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.10153 | acc=0.9799 | tpr=0.9107 | fpr=0.0188 | 7697.3 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.10390 | acc=0.9796 | tpr=0.9126 | fpr=0.0192 | 7950.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.10263 | acc=0.9796 | tpr=0.9039 | fpr=0.0190 | 7639.2 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.10481 | acc=0.9792 | tpr=0.9004 | fpr=0.0194 | 8028.3 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.10583 | acc=0.9790 | tpr=0.9036 | fpr=0.0196 | 7991.9 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.10683 | acc=0.9787 | tpr=0.9032 | fpr=0.0199 | 7752.9 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10886 | acc=0.9786 | tpr=0.9026 | fpr=0.0201 | 7841.9 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10819 | acc=0.9787 | tpr=0.9044 | fpr=0.0200 | 8031.0 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.10741 | acc=0.9789 | tpr=0.9041 | fpr=0.0198 | 13389.7 samples/s | 52.3 steps/s
Avg test loss: 0.10721, Avg test acc: 0.97889, Avg tpr: 0.90412, Avg fpr: 0.01976, total FA: 2743

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09056 | acc=0.9824 | tpr=0.8584 | fpr=0.0153 | 4937.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.08966 | acc=0.9827 | tpr=0.8827 | fpr=0.0154 | 6835.6 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.09360 | acc=0.9822 | tpr=0.8847 | fpr=0.0160 | 7785.0 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.09583 | acc=0.9821 | tpr=0.8852 | fpr=0.0162 | 7914.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.09442 | acc=0.9821 | tpr=0.8760 | fpr=0.0159 | 7881.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.09560 | acc=0.9820 | tpr=0.8785 | fpr=0.0161 | 7998.7 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09601 | acc=0.9820 | tpr=0.8791 | fpr=0.0161 | 7950.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09728 | acc=0.9818 | tpr=0.8786 | fpr=0.0163 | 7552.8 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.09949 | acc=0.9814 | tpr=0.8749 | fpr=0.0166 | 8113.0 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.09885 | acc=0.9814 | tpr=0.8753 | fpr=0.0166 | 8361.2 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.09858 | acc=0.9815 | tpr=0.8703 | fpr=0.0165 | 13501.2 samples/s | 52.7 steps/s
Avg test loss: 0.09852, Avg test acc: 0.98144, Avg tpr: 0.86965, Avg fpr: 0.01653, total FA: 2295

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09082 | acc=0.9802 | tpr=0.9159 | fpr=0.0187 | 4773.5 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.09171 | acc=0.9796 | tpr=0.9126 | fpr=0.0192 | 7217.5 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.09620 | acc=0.9784 | tpr=0.9150 | fpr=0.0204 | 7886.7 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.09801 | acc=0.9782 | tpr=0.9158 | fpr=0.0206 | 7672.6 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.09696 | acc=0.9784 | tpr=0.9162 | fpr=0.0205 | 7839.5 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09890 | acc=0.9782 | tpr=0.9113 | fpr=0.0206 | 7958.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.10121 | acc=0.9776 | tpr=0.9098 | fpr=0.0212 | 7760.9 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.10223 | acc=0.9774 | tpr=0.9075 | fpr=0.0214 | 7865.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.10408 | acc=0.9773 | tpr=0.9075 | fpr=0.0215 | 7999.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10326 | acc=0.9774 | tpr=0.9119 | fpr=0.0214 | 7705.3 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.10293 | acc=0.9775 | tpr=0.9109 | fpr=0.0213 | 13969.5 samples/s | 54.6 steps/s
Avg test loss: 0.10272, Avg test acc: 0.97749, Avg tpr: 0.91125, Avg fpr: 0.02130, total FA: 2958

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.07751 | acc=0.9820 | tpr=0.8982 | fpr=0.0165 | 4836.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.08058 | acc=0.9811 | tpr=0.9062 | fpr=0.0175 | 7097.3 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.08345 | acc=0.9801 | tpr=0.9049 | fpr=0.0185 | 7787.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.08497 | acc=0.9800 | tpr=0.9082 | fpr=0.0187 | 7584.4 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.08328 | acc=0.9804 | tpr=0.8996 | fpr=0.0181 | 8084.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.08453 | acc=0.9802 | tpr=0.8996 | fpr=0.0183 | 7878.5 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.08512 | acc=0.9799 | tpr=0.9023 | fpr=0.0187 | 8047.7 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.08608 | acc=0.9799 | tpr=0.8993 | fpr=0.0186 | 7835.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.08832 | acc=0.9795 | tpr=0.8968 | fpr=0.0190 | 8163.8 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.08775 | acc=0.9797 | tpr=0.8978 | fpr=0.0188 | 7273.8 samples/s | 28.4 steps/s
[Step= 550] | Loss=0.08717 | acc=0.9799 | tpr=0.8981 | fpr=0.0186 | 15120.8 samples/s | 59.1 steps/s
Avg test loss: 0.08704, Avg test acc: 0.97990, Avg tpr: 0.89778, Avg fpr: 0.01860, total FA: 2583

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09932 | acc=0.9800 | tpr=0.8938 | fpr=0.0185 | 4826.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.10329 | acc=0.9800 | tpr=0.9041 | fpr=0.0185 | 6936.2 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.10669 | acc=0.9794 | tpr=0.9049 | fpr=0.0192 | 8090.1 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.10899 | acc=0.9791 | tpr=0.9115 | fpr=0.0197 | 7579.7 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.10781 | acc=0.9791 | tpr=0.9048 | fpr=0.0196 | 8243.7 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.10997 | acc=0.9787 | tpr=0.8967 | fpr=0.0198 | 7621.1 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.11094 | acc=0.9786 | tpr=0.8992 | fpr=0.0200 | 8110.3 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.11232 | acc=0.9783 | tpr=0.8873 | fpr=0.0200 | 7932.5 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.11432 | acc=0.9780 | tpr=0.8851 | fpr=0.0203 | 7973.1 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.11432 | acc=0.9779 | tpr=0.8863 | fpr=0.0205 | 7698.6 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.11340 | acc=0.9780 | tpr=0.8854 | fpr=0.0203 | 14122.5 samples/s | 55.2 steps/s
Avg test loss: 0.11319, Avg test acc: 0.97804, Avg tpr: 0.88471, Avg fpr: 0.02027, total FA: 2814

server round 4/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=39.0] | Loss=0.08247 | Reg=0.00431 | acc=0.9375 | L2-Norm=20.771 | L2-Norm(final)=4.396 | 6101.7 samples/s | 95.3 steps/s
[Step=8050 Epoch=39.3] | Loss=0.06691 | Reg=0.00433 | acc=0.9219 | L2-Norm=20.805 | L2-Norm(final)=4.440 | 4108.4 samples/s | 64.2 steps/s
[Step=8100 Epoch=39.5] | Loss=0.06295 | Reg=0.00435 | acc=0.9219 | L2-Norm=20.852 | L2-Norm(final)=4.479 | 5003.5 samples/s | 78.2 steps/s
[Step=8150 Epoch=39.7] | Loss=0.06177 | Reg=0.00437 | acc=0.9688 | L2-Norm=20.893 | L2-Norm(final)=4.516 | 5139.4 samples/s | 80.3 steps/s
[Step=8200 Epoch=40.0] | Loss=0.06085 | Reg=0.00438 | acc=0.9531 | L2-Norm=20.932 | L2-Norm(final)=4.548 | 7680.2 samples/s | 120.0 steps/s
[Step=8250 Epoch=40.2] | Loss=0.05876 | Reg=0.00440 | acc=0.9531 | L2-Norm=20.972 | L2-Norm(final)=4.581 | 2226.6 samples/s | 34.8 steps/s
[Step=8300 Epoch=40.5] | Loss=0.05692 | Reg=0.00442 | acc=0.9219 | L2-Norm=21.014 | L2-Norm(final)=4.621 | 4956.4 samples/s | 77.4 steps/s
[Step=8350 Epoch=40.7] | Loss=0.05586 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.057 | L2-Norm(final)=4.659 | 5121.1 samples/s | 80.0 steps/s
[Step=8400 Epoch=41.0] | Loss=0.05438 | Reg=0.00445 | acc=0.9219 | L2-Norm=21.100 | L2-Norm(final)=4.697 | 6876.2 samples/s | 107.4 steps/s
[Step=8450 Epoch=41.2] | Loss=0.05356 | Reg=0.00447 | acc=0.9844 | L2-Norm=21.144 | L2-Norm(final)=4.736 | 2276.8 samples/s | 35.6 steps/s
[Step=8500 Epoch=41.4] | Loss=0.05236 | Reg=0.00449 | acc=0.9531 | L2-Norm=21.188 | L2-Norm(final)=4.777 | 5023.8 samples/s | 78.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=41.5] | Loss=0.00442 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.641 | L2-Norm(final)=5.196 | 5295.3 samples/s | 82.7 steps/s
[Step=8550 Epoch=41.7] | Loss=0.05532 | Reg=0.00471 | acc=0.9062 | L2-Norm=21.708 | L2-Norm(final)=5.217 | 4150.6 samples/s | 64.9 steps/s
[Step=8600 Epoch=41.9] | Loss=0.06010 | Reg=0.00474 | acc=0.9375 | L2-Norm=21.780 | L2-Norm(final)=5.205 | 4489.5 samples/s | 70.1 steps/s
[Step=8650 Epoch=42.2] | Loss=0.06249 | Reg=0.00477 | acc=0.9531 | L2-Norm=21.834 | L2-Norm(final)=5.191 | 4370.3 samples/s | 68.3 steps/s
[Step=8700 Epoch=42.4] | Loss=0.06074 | Reg=0.00479 | acc=0.9531 | L2-Norm=21.875 | L2-Norm(final)=5.175 | 6523.7 samples/s | 101.9 steps/s
[Step=8750 Epoch=42.7] | Loss=0.05569 | Reg=0.00480 | acc=0.9688 | L2-Norm=21.906 | L2-Norm(final)=5.165 | 2107.2 samples/s | 32.9 steps/s
[Step=8800 Epoch=42.9] | Loss=0.05235 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.930 | L2-Norm(final)=5.157 | 4480.6 samples/s | 70.0 steps/s
[Step=8850 Epoch=43.2] | Loss=0.04925 | Reg=0.00482 | acc=0.9531 | L2-Norm=21.950 | L2-Norm(final)=5.151 | 4395.9 samples/s | 68.7 steps/s
[Step=8900 Epoch=43.4] | Loss=0.04743 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.968 | L2-Norm(final)=5.146 | 5930.1 samples/s | 92.7 steps/s
[Step=8950 Epoch=43.6] | Loss=0.04443 | Reg=0.00483 | acc=0.9688 | L2-Norm=21.987 | L2-Norm(final)=5.143 | 2172.0 samples/s | 33.9 steps/s
[Step=9000 Epoch=43.9] | Loss=0.04276 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.002 | L2-Norm(final)=5.140 | 4479.3 samples/s | 70.0 steps/s
[Step=9050 Epoch=44.1] | Loss=0.04089 | Reg=0.00485 | acc=0.9375 | L2-Norm=22.015 | L2-Norm(final)=5.138 | 4506.8 samples/s | 70.4 steps/s
[Step=9100 Epoch=44.4] | Loss=0.04019 | Reg=0.00485 | acc=0.9688 | L2-Norm=22.028 | L2-Norm(final)=5.136 | 5395.0 samples/s | 84.3 steps/s
[Step=9150 Epoch=44.6] | Loss=0.03936 | Reg=0.00486 | acc=1.0000 | L2-Norm=22.041 | L2-Norm(final)=5.134 | 2235.6 samples/s | 34.9 steps/s
[Step=9200 Epoch=44.9] | Loss=0.03785 | Reg=0.00486 | acc=0.9688 | L2-Norm=22.053 | L2-Norm(final)=5.132 | 4508.2 samples/s | 70.4 steps/s
[Step=9250 Epoch=45.1] | Loss=0.03721 | Reg=0.00487 | acc=1.0000 | L2-Norm=22.064 | L2-Norm(final)=5.131 | 4444.9 samples/s | 69.5 steps/s
[Step=9300 Epoch=45.3] | Loss=0.03617 | Reg=0.00487 | acc=1.0000 | L2-Norm=22.075 | L2-Norm(final)=5.130 | 4986.4 samples/s | 77.9 steps/s
[Step=9350 Epoch=45.6] | Loss=0.03494 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.084 | L2-Norm(final)=5.129 | 2352.3 samples/s | 36.8 steps/s
[Step=9400 Epoch=45.8] | Loss=0.03357 | Reg=0.00488 | acc=0.9688 | L2-Norm=22.091 | L2-Norm(final)=5.129 | 4451.4 samples/s | 69.6 steps/s
[Step=9450 Epoch=46.1] | Loss=0.03238 | Reg=0.00488 | acc=1.0000 | L2-Norm=22.096 | L2-Norm(final)=5.129 | 4567.9 samples/s | 71.4 steps/s
[Step=9500 Epoch=46.3] | Loss=0.03164 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.100 | L2-Norm(final)=5.129 | 4530.8 samples/s | 70.8 steps/s
[Step=9550 Epoch=46.6] | Loss=0.03066 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.103 | L2-Norm(final)=5.130 | 2418.4 samples/s | 37.8 steps/s
[Step=9600 Epoch=46.8] | Loss=0.02968 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.105 | L2-Norm(final)=5.131 | 4491.5 samples/s | 70.2 steps/s
[Step=9650 Epoch=47.1] | Loss=0.02882 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.105 | L2-Norm(final)=5.131 | 4449.4 samples/s | 69.5 steps/s
[Step=9700 Epoch=47.3] | Loss=0.02810 | Reg=0.00489 | acc=0.9844 | L2-Norm=22.104 | L2-Norm(final)=5.132 | 4531.4 samples/s | 70.8 steps/s
[Step=9750 Epoch=47.5] | Loss=0.02737 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.102 | L2-Norm(final)=5.132 | 2460.1 samples/s | 38.4 steps/s
[Step=9800 Epoch=47.8] | Loss=0.02660 | Reg=0.00488 | acc=1.0000 | L2-Norm=22.099 | L2-Norm(final)=5.133 | 4475.0 samples/s | 69.9 steps/s
[Step=9850 Epoch=48.0] | Loss=0.02597 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.095 | L2-Norm(final)=5.134 | 4513.1 samples/s | 70.5 steps/s
[Step=9900 Epoch=48.3] | Loss=0.02536 | Reg=0.00488 | acc=1.0000 | L2-Norm=22.091 | L2-Norm(final)=5.135 | 4538.8 samples/s | 70.9 steps/s
[Step=9950 Epoch=48.5] | Loss=0.02504 | Reg=0.00488 | acc=0.9531 | L2-Norm=22.086 | L2-Norm(final)=5.136 | 2456.5 samples/s | 38.4 steps/s
[Step=10000 Epoch=48.8] | Loss=0.02456 | Reg=0.00488 | acc=1.0000 | L2-Norm=22.082 | L2-Norm(final)=5.137 | 4480.8 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step10000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=39.0] | Loss=0.08583 | Reg=0.00417 | acc=0.9219 | L2-Norm=20.412 | L2-Norm(final)=4.452 | 4694.4 samples/s | 73.3 steps/s
[Step=8050 Epoch=39.3] | Loss=0.06659 | Reg=0.00418 | acc=0.9219 | L2-Norm=20.442 | L2-Norm(final)=4.476 | 4809.8 samples/s | 75.2 steps/s
[Step=8100 Epoch=39.5] | Loss=0.06366 | Reg=0.00419 | acc=0.9688 | L2-Norm=20.481 | L2-Norm(final)=4.499 | 4966.6 samples/s | 77.6 steps/s
[Step=8150 Epoch=39.8] | Loss=0.06208 | Reg=0.00421 | acc=0.9375 | L2-Norm=20.513 | L2-Norm(final)=4.526 | 5098.4 samples/s | 79.7 steps/s
[Step=8200 Epoch=40.0] | Loss=0.06021 | Reg=0.00422 | acc=0.9688 | L2-Norm=20.549 | L2-Norm(final)=4.556 | 7802.4 samples/s | 121.9 steps/s
[Step=8250 Epoch=40.3] | Loss=0.05847 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.589 | L2-Norm(final)=4.588 | 2191.6 samples/s | 34.2 steps/s
[Step=8300 Epoch=40.5] | Loss=0.05665 | Reg=0.00426 | acc=0.9375 | L2-Norm=20.631 | L2-Norm(final)=4.625 | 5148.8 samples/s | 80.5 steps/s
[Step=8350 Epoch=40.7] | Loss=0.05499 | Reg=0.00427 | acc=0.9375 | L2-Norm=20.675 | L2-Norm(final)=4.666 | 4924.4 samples/s | 76.9 steps/s
[Step=8400 Epoch=41.0] | Loss=0.05426 | Reg=0.00429 | acc=0.9844 | L2-Norm=20.718 | L2-Norm(final)=4.707 | 7202.9 samples/s | 112.5 steps/s
[Step=8450 Epoch=41.2] | Loss=0.05302 | Reg=0.00431 | acc=0.9531 | L2-Norm=20.764 | L2-Norm(final)=4.748 | 2290.6 samples/s | 35.8 steps/s
[Step=8500 Epoch=41.5] | Loss=0.05199 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.811 | L2-Norm(final)=4.790 | 5032.9 samples/s | 78.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=41.5] | Loss=0.07022 | Reg=0.00453 | acc=0.9688 | L2-Norm=21.291 | L2-Norm(final)=5.222 | 5585.3 samples/s | 87.3 steps/s
[Step=8550 Epoch=41.7] | Loss=0.05433 | Reg=0.00456 | acc=0.9375 | L2-Norm=21.346 | L2-Norm(final)=5.250 | 3936.7 samples/s | 61.5 steps/s
[Step=8600 Epoch=42.0] | Loss=0.06605 | Reg=0.00459 | acc=0.9688 | L2-Norm=21.414 | L2-Norm(final)=5.240 | 4456.7 samples/s | 69.6 steps/s
[Step=8650 Epoch=42.2] | Loss=0.06666 | Reg=0.00461 | acc=0.9688 | L2-Norm=21.476 | L2-Norm(final)=5.222 | 4460.9 samples/s | 69.7 steps/s
[Step=8700 Epoch=42.5] | Loss=0.06709 | Reg=0.00464 | acc=0.9531 | L2-Norm=21.533 | L2-Norm(final)=5.205 | 6586.8 samples/s | 102.9 steps/s
[Step=8750 Epoch=42.7] | Loss=0.06134 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.580 | L2-Norm(final)=5.195 | 2102.3 samples/s | 32.8 steps/s
[Step=8800 Epoch=42.9] | Loss=0.05718 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.618 | L2-Norm(final)=5.188 | 4438.5 samples/s | 69.4 steps/s
[Step=8850 Epoch=43.2] | Loss=0.05394 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.650 | L2-Norm(final)=5.184 | 4488.7 samples/s | 70.1 steps/s
[Step=8900 Epoch=43.4] | Loss=0.05147 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.678 | L2-Norm(final)=5.177 | 5993.4 samples/s | 93.6 steps/s
[Step=8950 Epoch=43.7] | Loss=0.04840 | Reg=0.00471 | acc=0.9688 | L2-Norm=21.702 | L2-Norm(final)=5.174 | 2139.0 samples/s | 33.4 steps/s
[Step=9000 Epoch=43.9] | Loss=0.04578 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.725 | L2-Norm(final)=5.172 | 4512.4 samples/s | 70.5 steps/s
[Step=9050 Epoch=44.2] | Loss=0.04439 | Reg=0.00473 | acc=0.9688 | L2-Norm=21.745 | L2-Norm(final)=5.169 | 4398.5 samples/s | 68.7 steps/s
[Step=9100 Epoch=44.4] | Loss=0.04270 | Reg=0.00474 | acc=0.9688 | L2-Norm=21.764 | L2-Norm(final)=5.167 | 5596.5 samples/s | 87.4 steps/s
[Step=9150 Epoch=44.6] | Loss=0.04105 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.781 | L2-Norm(final)=5.166 | 2218.3 samples/s | 34.7 steps/s
[Step=9200 Epoch=44.9] | Loss=0.03913 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.797 | L2-Norm(final)=5.165 | 4384.4 samples/s | 68.5 steps/s
[Step=9250 Epoch=45.1] | Loss=0.03759 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.810 | L2-Norm(final)=5.164 | 4483.4 samples/s | 70.1 steps/s
[Step=9300 Epoch=45.4] | Loss=0.03607 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.821 | L2-Norm(final)=5.164 | 5179.4 samples/s | 80.9 steps/s
[Step=9350 Epoch=45.6] | Loss=0.03493 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.832 | L2-Norm(final)=5.164 | 2293.2 samples/s | 35.8 steps/s
[Step=9400 Epoch=45.9] | Loss=0.03381 | Reg=0.00477 | acc=0.9688 | L2-Norm=21.840 | L2-Norm(final)=5.164 | 4350.9 samples/s | 68.0 steps/s
[Step=9450 Epoch=46.1] | Loss=0.03277 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.846 | L2-Norm(final)=5.164 | 4479.1 samples/s | 70.0 steps/s
[Step=9500 Epoch=46.4] | Loss=0.03185 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.851 | L2-Norm(final)=5.164 | 4899.6 samples/s | 76.6 steps/s
[Step=9550 Epoch=46.6] | Loss=0.03101 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.854 | L2-Norm(final)=5.165 | 2350.0 samples/s | 36.7 steps/s
[Step=9600 Epoch=46.8] | Loss=0.03006 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.856 | L2-Norm(final)=5.165 | 4449.2 samples/s | 69.5 steps/s
[Step=9650 Epoch=47.1] | Loss=0.02917 | Reg=0.00478 | acc=0.9531 | L2-Norm=21.856 | L2-Norm(final)=5.165 | 4517.7 samples/s | 70.6 steps/s
[Step=9700 Epoch=47.3] | Loss=0.02842 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.856 | L2-Norm(final)=5.166 | 4525.1 samples/s | 70.7 steps/s
[Step=9750 Epoch=47.6] | Loss=0.02756 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.856 | L2-Norm(final)=5.167 | 2422.0 samples/s | 37.8 steps/s
[Step=9800 Epoch=47.8] | Loss=0.02681 | Reg=0.00478 | acc=0.9844 | L2-Norm=21.854 | L2-Norm(final)=5.168 | 4487.3 samples/s | 70.1 steps/s
[Step=9850 Epoch=48.1] | Loss=0.02610 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.851 | L2-Norm(final)=5.169 | 4512.1 samples/s | 70.5 steps/s
[Step=9900 Epoch=48.3] | Loss=0.02550 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.847 | L2-Norm(final)=5.170 | 4552.4 samples/s | 71.1 steps/s
[Step=9950 Epoch=48.6] | Loss=0.02496 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.843 | L2-Norm(final)=5.171 | 2416.3 samples/s | 37.8 steps/s
[Step=10000 Epoch=48.8] | Loss=0.02437 | Reg=0.00477 | acc=0.9688 | L2-Norm=21.838 | L2-Norm(final)=5.172 | 4508.6 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step10000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=39.0] | Loss=0.12696 | Reg=0.00425 | acc=0.9062 | L2-Norm=20.627 | L2-Norm(final)=4.613 | 5482.1 samples/s | 85.7 steps/s
[Step=8050 Epoch=39.2] | Loss=0.07333 | Reg=0.00426 | acc=0.9375 | L2-Norm=20.647 | L2-Norm(final)=4.623 | 4497.7 samples/s | 70.3 steps/s
[Step=8100 Epoch=39.5] | Loss=0.06432 | Reg=0.00428 | acc=0.9688 | L2-Norm=20.687 | L2-Norm(final)=4.667 | 4949.9 samples/s | 77.3 steps/s
[Step=8150 Epoch=39.7] | Loss=0.06189 | Reg=0.00430 | acc=0.9688 | L2-Norm=20.725 | L2-Norm(final)=4.706 | 5068.1 samples/s | 79.2 steps/s
[Step=8200 Epoch=40.0] | Loss=0.06131 | Reg=0.00431 | acc=0.9219 | L2-Norm=20.763 | L2-Norm(final)=4.743 | 7642.6 samples/s | 119.4 steps/s
[Step=8250 Epoch=40.2] | Loss=0.05913 | Reg=0.00433 | acc=0.9688 | L2-Norm=20.804 | L2-Norm(final)=4.783 | 2215.3 samples/s | 34.6 steps/s
[Step=8300 Epoch=40.4] | Loss=0.05709 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.847 | L2-Norm(final)=4.828 | 5050.3 samples/s | 78.9 steps/s
[Step=8350 Epoch=40.7] | Loss=0.05665 | Reg=0.00436 | acc=0.9219 | L2-Norm=20.890 | L2-Norm(final)=4.873 | 5113.3 samples/s | 79.9 steps/s
[Step=8400 Epoch=40.9] | Loss=0.05565 | Reg=0.00438 | acc=0.9531 | L2-Norm=20.935 | L2-Norm(final)=4.919 | 6850.2 samples/s | 107.0 steps/s
[Step=8450 Epoch=41.2] | Loss=0.05442 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.982 | L2-Norm(final)=4.965 | 2292.2 samples/s | 35.8 steps/s
[Step=8500 Epoch=41.4] | Loss=0.05263 | Reg=0.00442 | acc=0.9688 | L2-Norm=21.029 | L2-Norm(final)=5.013 | 5128.2 samples/s | 80.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=41.4] | Loss=0.03466 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.505 | L2-Norm(final)=5.499 | 5583.4 samples/s | 87.2 steps/s
[Step=8550 Epoch=41.7] | Loss=0.06790 | Reg=0.00465 | acc=0.9219 | L2-Norm=21.568 | L2-Norm(final)=5.510 | 4079.3 samples/s | 63.7 steps/s
[Step=8600 Epoch=41.9] | Loss=0.06876 | Reg=0.00468 | acc=0.9219 | L2-Norm=21.644 | L2-Norm(final)=5.495 | 4465.4 samples/s | 69.8 steps/s
[Step=8650 Epoch=42.1] | Loss=0.06914 | Reg=0.00471 | acc=0.8906 | L2-Norm=21.706 | L2-Norm(final)=5.478 | 4565.3 samples/s | 71.3 steps/s
[Step=8700 Epoch=42.4] | Loss=0.06976 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.756 | L2-Norm(final)=5.461 | 6398.4 samples/s | 100.0 steps/s
[Step=8750 Epoch=42.6] | Loss=0.06382 | Reg=0.00475 | acc=0.9375 | L2-Norm=21.798 | L2-Norm(final)=5.450 | 2102.2 samples/s | 32.8 steps/s
[Step=8800 Epoch=42.9] | Loss=0.05952 | Reg=0.00477 | acc=0.9375 | L2-Norm=21.831 | L2-Norm(final)=5.445 | 4458.0 samples/s | 69.7 steps/s
[Step=8850 Epoch=43.1] | Loss=0.05499 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.858 | L2-Norm(final)=5.441 | 4395.6 samples/s | 68.7 steps/s
[Step=8900 Epoch=43.4] | Loss=0.05319 | Reg=0.00479 | acc=0.9688 | L2-Norm=21.880 | L2-Norm(final)=5.438 | 5943.7 samples/s | 92.9 steps/s
[Step=8950 Epoch=43.6] | Loss=0.05114 | Reg=0.00480 | acc=0.9688 | L2-Norm=21.901 | L2-Norm(final)=5.435 | 2185.1 samples/s | 34.1 steps/s
[Step=9000 Epoch=43.9] | Loss=0.04822 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.921 | L2-Norm(final)=5.432 | 4484.8 samples/s | 70.1 steps/s
[Step=9050 Epoch=44.1] | Loss=0.04605 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.936 | L2-Norm(final)=5.431 | 4503.1 samples/s | 70.4 steps/s
[Step=9100 Epoch=44.3] | Loss=0.04437 | Reg=0.00482 | acc=0.9688 | L2-Norm=21.950 | L2-Norm(final)=5.430 | 5401.9 samples/s | 84.4 steps/s
[Step=9150 Epoch=44.6] | Loss=0.04278 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.963 | L2-Norm(final)=5.428 | 2238.5 samples/s | 35.0 steps/s
[Step=9200 Epoch=44.8] | Loss=0.04105 | Reg=0.00483 | acc=0.9844 | L2-Norm=21.974 | L2-Norm(final)=5.428 | 4472.6 samples/s | 69.9 steps/s
[Step=9250 Epoch=45.1] | Loss=0.03975 | Reg=0.00483 | acc=0.9844 | L2-Norm=21.985 | L2-Norm(final)=5.428 | 4526.2 samples/s | 70.7 steps/s
[Step=9300 Epoch=45.3] | Loss=0.03827 | Reg=0.00484 | acc=0.9688 | L2-Norm=21.994 | L2-Norm(final)=5.427 | 4923.1 samples/s | 76.9 steps/s
[Step=9350 Epoch=45.6] | Loss=0.03676 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.001 | L2-Norm(final)=5.428 | 2316.7 samples/s | 36.2 steps/s
[Step=9400 Epoch=45.8] | Loss=0.03538 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.007 | L2-Norm(final)=5.429 | 4497.0 samples/s | 70.3 steps/s
[Step=9450 Epoch=46.0] | Loss=0.03440 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.012 | L2-Norm(final)=5.430 | 4455.8 samples/s | 69.6 steps/s
[Step=9500 Epoch=46.3] | Loss=0.03343 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.016 | L2-Norm(final)=5.431 | 4594.2 samples/s | 71.8 steps/s
[Step=9550 Epoch=46.5] | Loss=0.03238 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.018 | L2-Norm(final)=5.432 | 2406.3 samples/s | 37.6 steps/s
[Step=9600 Epoch=46.8] | Loss=0.03140 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.019 | L2-Norm(final)=5.433 | 4462.8 samples/s | 69.7 steps/s
[Step=9650 Epoch=47.0] | Loss=0.03045 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.019 | L2-Norm(final)=5.435 | 4494.2 samples/s | 70.2 steps/s
[Step=9700 Epoch=47.3] | Loss=0.02983 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.018 | L2-Norm(final)=5.436 | 4485.5 samples/s | 70.1 steps/s
[Step=9750 Epoch=47.5] | Loss=0.02913 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.017 | L2-Norm(final)=5.437 | 2487.3 samples/s | 38.9 steps/s
[Step=9800 Epoch=47.8] | Loss=0.02836 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.016 | L2-Norm(final)=5.439 | 4454.2 samples/s | 69.6 steps/s
[Step=9850 Epoch=48.0] | Loss=0.02774 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.014 | L2-Norm(final)=5.440 | 4474.4 samples/s | 69.9 steps/s
[Step=9900 Epoch=48.2] | Loss=0.02713 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.012 | L2-Norm(final)=5.442 | 4494.4 samples/s | 70.2 steps/s
[Step=9950 Epoch=48.5] | Loss=0.02659 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.010 | L2-Norm(final)=5.443 | 2464.0 samples/s | 38.5 steps/s
[Step=10000 Epoch=48.7] | Loss=0.02601 | Reg=0.00484 | acc=1.0000 | L2-Norm=22.006 | L2-Norm(final)=5.445 | 4513.3 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step10000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=39.0] | Loss=0.11954 | Reg=0.00416 | acc=0.9062 | L2-Norm=20.385 | L2-Norm(final)=4.370 | 5249.5 samples/s | 82.0 steps/s
[Step=8050 Epoch=39.3] | Loss=0.07064 | Reg=0.00417 | acc=0.9375 | L2-Norm=20.417 | L2-Norm(final)=4.387 | 4486.0 samples/s | 70.1 steps/s
[Step=8100 Epoch=39.5] | Loss=0.06499 | Reg=0.00418 | acc=0.9375 | L2-Norm=20.455 | L2-Norm(final)=4.428 | 5071.5 samples/s | 79.2 steps/s
[Step=8150 Epoch=39.7] | Loss=0.06505 | Reg=0.00420 | acc=0.9531 | L2-Norm=20.488 | L2-Norm(final)=4.464 | 5027.1 samples/s | 78.5 steps/s
[Step=8200 Epoch=40.0] | Loss=0.06269 | Reg=0.00421 | acc=0.9531 | L2-Norm=20.525 | L2-Norm(final)=4.501 | 7856.4 samples/s | 122.8 steps/s
[Step=8250 Epoch=40.2] | Loss=0.06009 | Reg=0.00423 | acc=0.9531 | L2-Norm=20.565 | L2-Norm(final)=4.542 | 2219.7 samples/s | 34.7 steps/s
[Step=8300 Epoch=40.5] | Loss=0.05853 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.608 | L2-Norm(final)=4.586 | 5041.8 samples/s | 78.8 steps/s
[Step=8350 Epoch=40.7] | Loss=0.05743 | Reg=0.00426 | acc=0.9531 | L2-Norm=20.651 | L2-Norm(final)=4.630 | 4991.3 samples/s | 78.0 steps/s
[Step=8400 Epoch=41.0] | Loss=0.05685 | Reg=0.00428 | acc=0.9531 | L2-Norm=20.695 | L2-Norm(final)=4.674 | 6999.0 samples/s | 109.4 steps/s
[Step=8450 Epoch=41.2] | Loss=0.05581 | Reg=0.00430 | acc=0.9219 | L2-Norm=20.740 | L2-Norm(final)=4.718 | 2315.8 samples/s | 36.2 steps/s
[Step=8500 Epoch=41.5] | Loss=0.05448 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.786 | L2-Norm(final)=4.764 | 5082.1 samples/s | 79.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=41.5] | Loss=0.03349 | Reg=0.00452 | acc=0.9688 | L2-Norm=21.264 | L2-Norm(final)=5.235 | 5647.3 samples/s | 88.2 steps/s
[Step=8550 Epoch=41.7] | Loss=0.05680 | Reg=0.00455 | acc=0.9375 | L2-Norm=21.334 | L2-Norm(final)=5.262 | 3983.2 samples/s | 62.2 steps/s
[Step=8600 Epoch=41.9] | Loss=0.06517 | Reg=0.00458 | acc=0.9688 | L2-Norm=21.398 | L2-Norm(final)=5.253 | 4505.2 samples/s | 70.4 steps/s
[Step=8650 Epoch=42.2] | Loss=0.06342 | Reg=0.00460 | acc=0.9062 | L2-Norm=21.448 | L2-Norm(final)=5.240 | 4502.8 samples/s | 70.4 steps/s
[Step=8700 Epoch=42.4] | Loss=0.06378 | Reg=0.00462 | acc=0.9844 | L2-Norm=21.492 | L2-Norm(final)=5.230 | 6463.0 samples/s | 101.0 steps/s
[Step=8750 Epoch=42.7] | Loss=0.05903 | Reg=0.00464 | acc=0.9688 | L2-Norm=21.534 | L2-Norm(final)=5.220 | 2098.7 samples/s | 32.8 steps/s
[Step=8800 Epoch=42.9] | Loss=0.05513 | Reg=0.00465 | acc=0.9844 | L2-Norm=21.569 | L2-Norm(final)=5.214 | 4483.5 samples/s | 70.1 steps/s
[Step=8850 Epoch=43.2] | Loss=0.05147 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.596 | L2-Norm(final)=5.209 | 4445.6 samples/s | 69.5 steps/s
[Step=8900 Epoch=43.4] | Loss=0.04924 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.618 | L2-Norm(final)=5.205 | 5949.5 samples/s | 93.0 steps/s
[Step=8950 Epoch=43.6] | Loss=0.04711 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.639 | L2-Norm(final)=5.202 | 2194.3 samples/s | 34.3 steps/s
[Step=9000 Epoch=43.9] | Loss=0.04500 | Reg=0.00469 | acc=0.9531 | L2-Norm=21.660 | L2-Norm(final)=5.199 | 4458.0 samples/s | 69.7 steps/s
[Step=9050 Epoch=44.1] | Loss=0.04294 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.679 | L2-Norm(final)=5.198 | 4490.6 samples/s | 70.2 steps/s
[Step=9100 Epoch=44.4] | Loss=0.04168 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.696 | L2-Norm(final)=5.197 | 5414.0 samples/s | 84.6 steps/s
[Step=9150 Epoch=44.6] | Loss=0.04015 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.712 | L2-Norm(final)=5.196 | 2243.0 samples/s | 35.0 steps/s
[Step=9200 Epoch=44.9] | Loss=0.03855 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.727 | L2-Norm(final)=5.195 | 4424.7 samples/s | 69.1 steps/s
[Step=9250 Epoch=45.1] | Loss=0.03748 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.741 | L2-Norm(final)=5.195 | 4461.3 samples/s | 69.7 steps/s
[Step=9300 Epoch=45.4] | Loss=0.03610 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.753 | L2-Norm(final)=5.195 | 5000.2 samples/s | 78.1 steps/s
[Step=9350 Epoch=45.6] | Loss=0.03484 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.765 | L2-Norm(final)=5.196 | 2384.2 samples/s | 37.3 steps/s
[Step=9400 Epoch=45.8] | Loss=0.03410 | Reg=0.00474 | acc=0.9844 | L2-Norm=21.776 | L2-Norm(final)=5.197 | 4391.8 samples/s | 68.6 steps/s
[Step=9450 Epoch=46.1] | Loss=0.03312 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.786 | L2-Norm(final)=5.198 | 4496.4 samples/s | 70.3 steps/s
[Step=9500 Epoch=46.3] | Loss=0.03203 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.795 | L2-Norm(final)=5.199 | 4505.1 samples/s | 70.4 steps/s
[Step=9550 Epoch=46.6] | Loss=0.03117 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.803 | L2-Norm(final)=5.201 | 2402.3 samples/s | 37.5 steps/s
[Step=9600 Epoch=46.8] | Loss=0.03022 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.810 | L2-Norm(final)=5.203 | 4481.0 samples/s | 70.0 steps/s
[Step=9650 Epoch=47.1] | Loss=0.02952 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.816 | L2-Norm(final)=5.205 | 4538.7 samples/s | 70.9 steps/s
[Step=9700 Epoch=47.3] | Loss=0.02905 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.822 | L2-Norm(final)=5.207 | 4444.8 samples/s | 69.5 steps/s
[Step=9750 Epoch=47.5] | Loss=0.02859 | Reg=0.00476 | acc=0.9531 | L2-Norm=21.827 | L2-Norm(final)=5.208 | 2474.2 samples/s | 38.7 steps/s
[Step=9800 Epoch=47.8] | Loss=0.02813 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.834 | L2-Norm(final)=5.209 | 4570.0 samples/s | 71.4 steps/s
[Step=9850 Epoch=48.0] | Loss=0.02752 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.840 | L2-Norm(final)=5.210 | 4375.6 samples/s | 68.4 steps/s
[Step=9900 Epoch=48.3] | Loss=0.02695 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.845 | L2-Norm(final)=5.212 | 4487.1 samples/s | 70.1 steps/s
[Step=9950 Epoch=48.5] | Loss=0.02630 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.850 | L2-Norm(final)=5.214 | 2454.5 samples/s | 38.4 steps/s
[Step=10000 Epoch=48.8] | Loss=0.02584 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.854 | L2-Norm(final)=5.216 | 4480.5 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step10000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=39.2] | Loss=0.04022 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.779 | L2-Norm(final)=4.930 | 5313.6 samples/s | 83.0 steps/s
[Step=8050 Epoch=39.5] | Loss=0.06316 | Reg=0.00433 | acc=0.9219 | L2-Norm=20.813 | L2-Norm(final)=4.973 | 4241.1 samples/s | 66.3 steps/s
[Step=8100 Epoch=39.7] | Loss=0.06501 | Reg=0.00435 | acc=0.8906 | L2-Norm=20.845 | L2-Norm(final)=5.008 | 5047.3 samples/s | 78.9 steps/s
[Step=8150 Epoch=40.0] | Loss=0.06371 | Reg=0.00436 | acc=0.9531 | L2-Norm=20.881 | L2-Norm(final)=5.044 | 5094.2 samples/s | 79.6 steps/s
[Step=8200 Epoch=40.2] | Loss=0.06315 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.921 | L2-Norm(final)=5.080 | 7853.3 samples/s | 122.7 steps/s
[Step=8250 Epoch=40.5] | Loss=0.06099 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.962 | L2-Norm(final)=5.117 | 2247.6 samples/s | 35.1 steps/s
[Step=8300 Epoch=40.7] | Loss=0.05944 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.004 | L2-Norm(final)=5.156 | 5021.6 samples/s | 78.5 steps/s
[Step=8350 Epoch=40.9] | Loss=0.05819 | Reg=0.00443 | acc=0.9375 | L2-Norm=21.046 | L2-Norm(final)=5.197 | 4852.7 samples/s | 75.8 steps/s
[Step=8400 Epoch=41.2] | Loss=0.05721 | Reg=0.00445 | acc=0.9844 | L2-Norm=21.089 | L2-Norm(final)=5.240 | 7502.1 samples/s | 117.2 steps/s
[Step=8450 Epoch=41.4] | Loss=0.05570 | Reg=0.00447 | acc=0.9375 | L2-Norm=21.133 | L2-Norm(final)=5.285 | 2249.2 samples/s | 35.1 steps/s
[Step=8500 Epoch=41.7] | Loss=0.05439 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.178 | L2-Norm(final)=5.331 | 5093.0 samples/s | 79.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=41.7] | Loss=0.02021 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.629 | L2-Norm(final)=5.802 | 5180.6 samples/s | 80.9 steps/s
[Step=8550 Epoch=41.9] | Loss=0.05496 | Reg=0.00470 | acc=0.9531 | L2-Norm=21.678 | L2-Norm(final)=5.826 | 4210.7 samples/s | 65.8 steps/s
[Step=8600 Epoch=42.2] | Loss=0.06056 | Reg=0.00472 | acc=0.9688 | L2-Norm=21.730 | L2-Norm(final)=5.819 | 4453.9 samples/s | 69.6 steps/s
[Step=8650 Epoch=42.4] | Loss=0.06290 | Reg=0.00474 | acc=0.9844 | L2-Norm=21.779 | L2-Norm(final)=5.807 | 4524.8 samples/s | 70.7 steps/s
[Step=8700 Epoch=42.7] | Loss=0.06036 | Reg=0.00476 | acc=0.8750 | L2-Norm=21.823 | L2-Norm(final)=5.796 | 6648.3 samples/s | 103.9 steps/s
[Step=8750 Epoch=42.9] | Loss=0.05507 | Reg=0.00478 | acc=0.9375 | L2-Norm=21.858 | L2-Norm(final)=5.789 | 2089.3 samples/s | 32.6 steps/s
[Step=8800 Epoch=43.2] | Loss=0.05148 | Reg=0.00479 | acc=0.9844 | L2-Norm=21.888 | L2-Norm(final)=5.786 | 4410.5 samples/s | 68.9 steps/s
[Step=8850 Epoch=43.4] | Loss=0.04877 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.914 | L2-Norm(final)=5.782 | 4470.5 samples/s | 69.9 steps/s
[Step=8900 Epoch=43.6] | Loss=0.04676 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.939 | L2-Norm(final)=5.781 | 6178.3 samples/s | 96.5 steps/s
[Step=8950 Epoch=43.9] | Loss=0.04280 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.960 | L2-Norm(final)=5.781 | 2130.6 samples/s | 33.3 steps/s
[Step=9000 Epoch=44.1] | Loss=0.04041 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.975 | L2-Norm(final)=5.783 | 4418.9 samples/s | 69.0 steps/s
[Step=9050 Epoch=44.4] | Loss=0.03927 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.987 | L2-Norm(final)=5.784 | 4449.7 samples/s | 69.5 steps/s
[Step=9100 Epoch=44.6] | Loss=0.03776 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.999 | L2-Norm(final)=5.785 | 5908.3 samples/s | 92.3 steps/s
[Step=9150 Epoch=44.9] | Loss=0.03598 | Reg=0.00484 | acc=0.9844 | L2-Norm=22.010 | L2-Norm(final)=5.787 | 2168.4 samples/s | 33.9 steps/s
[Step=9200 Epoch=45.1] | Loss=0.03469 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.018 | L2-Norm(final)=5.789 | 4451.7 samples/s | 69.6 steps/s
[Step=9250 Epoch=45.4] | Loss=0.03339 | Reg=0.00485 | acc=0.9844 | L2-Norm=22.026 | L2-Norm(final)=5.791 | 4490.7 samples/s | 70.2 steps/s
[Step=9300 Epoch=45.6] | Loss=0.03237 | Reg=0.00485 | acc=0.9688 | L2-Norm=22.033 | L2-Norm(final)=5.792 | 5482.4 samples/s | 85.7 steps/s
[Step=9350 Epoch=45.9] | Loss=0.03119 | Reg=0.00486 | acc=0.9688 | L2-Norm=22.038 | L2-Norm(final)=5.794 | 2229.6 samples/s | 34.8 steps/s
[Step=9400 Epoch=46.1] | Loss=0.03016 | Reg=0.00486 | acc=0.9844 | L2-Norm=22.042 | L2-Norm(final)=5.796 | 4551.6 samples/s | 71.1 steps/s
[Step=9450 Epoch=46.3] | Loss=0.02909 | Reg=0.00486 | acc=0.9844 | L2-Norm=22.046 | L2-Norm(final)=5.797 | 4382.9 samples/s | 68.5 steps/s
[Step=9500 Epoch=46.6] | Loss=0.02820 | Reg=0.00486 | acc=0.9844 | L2-Norm=22.049 | L2-Norm(final)=5.799 | 5219.3 samples/s | 81.6 steps/s
[Step=9550 Epoch=46.8] | Loss=0.02768 | Reg=0.00486 | acc=0.9844 | L2-Norm=22.052 | L2-Norm(final)=5.801 | 2285.8 samples/s | 35.7 steps/s
[Step=9600 Epoch=47.1] | Loss=0.02747 | Reg=0.00487 | acc=0.9844 | L2-Norm=22.057 | L2-Norm(final)=5.801 | 4486.5 samples/s | 70.1 steps/s
[Step=9650 Epoch=47.3] | Loss=0.02705 | Reg=0.00487 | acc=0.9844 | L2-Norm=22.063 | L2-Norm(final)=5.802 | 4436.0 samples/s | 69.3 steps/s
[Step=9700 Epoch=47.6] | Loss=0.02658 | Reg=0.00487 | acc=0.9688 | L2-Norm=22.069 | L2-Norm(final)=5.802 | 4935.7 samples/s | 77.1 steps/s
[Step=9750 Epoch=47.8] | Loss=0.02630 | Reg=0.00487 | acc=0.9844 | L2-Norm=22.076 | L2-Norm(final)=5.803 | 2315.5 samples/s | 36.2 steps/s
[Step=9800 Epoch=48.1] | Loss=0.02591 | Reg=0.00488 | acc=0.9375 | L2-Norm=22.084 | L2-Norm(final)=5.804 | 4457.6 samples/s | 69.6 steps/s
[Step=9850 Epoch=48.3] | Loss=0.02555 | Reg=0.00488 | acc=0.9688 | L2-Norm=22.091 | L2-Norm(final)=5.805 | 4447.8 samples/s | 69.5 steps/s
[Step=9900 Epoch=48.5] | Loss=0.02508 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.097 | L2-Norm(final)=5.806 | 4700.5 samples/s | 73.4 steps/s
[Step=9950 Epoch=48.8] | Loss=0.02460 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.103 | L2-Norm(final)=5.807 | 2381.2 samples/s | 37.2 steps/s
[Step=10000 Epoch=49.0] | Loss=0.02414 | Reg=0.00489 | acc=1.0000 | L2-Norm=22.109 | L2-Norm(final)=5.808 | 4613.3 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step10000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=75.8] | Loss=0.02668 | Reg=0.00192 | acc=0.9688 | L2-Norm=13.846 | L2-Norm(final)=3.833 | 5402.8 samples/s | 84.4 steps/s
[Step=8050 Epoch=76.3] | Loss=0.01363 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.986 | L2-Norm(final)=3.819 | 3926.9 samples/s | 61.4 steps/s
[Step=8100 Epoch=76.8] | Loss=0.01001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.060 | L2-Norm(final)=3.831 | 7436.3 samples/s | 116.2 steps/s
[Step=8150 Epoch=77.2] | Loss=0.00805 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.113 | L2-Norm(final)=3.851 | 2145.9 samples/s | 33.5 steps/s
[Step=8200 Epoch=77.7] | Loss=0.00672 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.155 | L2-Norm(final)=3.871 | 6407.9 samples/s | 100.1 steps/s
[Step=8250 Epoch=78.2] | Loss=0.00605 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.191 | L2-Norm(final)=3.894 | 2126.2 samples/s | 33.2 steps/s
[Step=8300 Epoch=78.6] | Loss=0.00531 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.222 | L2-Norm(final)=3.915 | 5862.4 samples/s | 91.6 steps/s
[Step=8350 Epoch=79.1] | Loss=0.00483 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.250 | L2-Norm(final)=3.938 | 2257.8 samples/s | 35.3 steps/s
[Step=8400 Epoch=79.6] | Loss=0.00442 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.275 | L2-Norm(final)=3.960 | 5343.5 samples/s | 83.5 steps/s
[Step=8450 Epoch=80.1] | Loss=0.00410 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.298 | L2-Norm(final)=3.982 | 2344.5 samples/s | 36.6 steps/s
[Step=8500 Epoch=80.5] | Loss=0.00379 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.319 | L2-Norm(final)=4.004 | 4702.5 samples/s | 73.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=80.6] | Loss=0.00084 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=4.215 | 5091.5 samples/s | 79.6 steps/s
[Step=8550 Epoch=81.0] | Loss=0.02904 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=4.204 | 3837.2 samples/s | 60.0 steps/s
[Step=8600 Epoch=81.5] | Loss=0.02603 | Reg=0.00218 | acc=0.9531 | L2-Norm=14.755 | L2-Norm(final)=4.133 | 6169.8 samples/s | 96.4 steps/s
[Step=8650 Epoch=82.0] | Loss=0.02105 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=4.092 | 2006.4 samples/s | 31.4 steps/s
[Step=8700 Epoch=82.4] | Loss=0.01621 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=4.073 | 5548.8 samples/s | 86.7 steps/s
[Step=8750 Epoch=82.9] | Loss=0.01302 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=4.064 | 2070.3 samples/s | 32.3 steps/s
[Step=8800 Epoch=83.4] | Loss=0.01087 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=4.058 | 5089.1 samples/s | 79.5 steps/s
[Step=8850 Epoch=83.9] | Loss=0.00932 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=4.054 | 2185.0 samples/s | 34.1 steps/s
[Step=8900 Epoch=84.3] | Loss=0.00817 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=4.052 | 4620.6 samples/s | 72.2 steps/s
[Step=8950 Epoch=84.8] | Loss=0.00726 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=4.050 | 2222.9 samples/s | 34.7 steps/s
[Step=9000 Epoch=85.3] | Loss=0.00654 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=4.049 | 4260.5 samples/s | 66.6 steps/s
[Step=9050 Epoch=85.8] | Loss=0.00595 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=4.048 | 2346.0 samples/s | 36.7 steps/s
[Step=9100 Epoch=86.2] | Loss=0.00546 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=4.048 | 4200.3 samples/s | 65.6 steps/s
[Step=9150 Epoch=86.7] | Loss=0.00504 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.957 | L2-Norm(final)=4.048 | 2369.7 samples/s | 37.0 steps/s
[Step=9200 Epoch=87.2] | Loss=0.00468 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=4.048 | 4156.6 samples/s | 64.9 steps/s
[Step=9250 Epoch=87.7] | Loss=0.00437 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=4.047 | 2400.3 samples/s | 37.5 steps/s
[Step=9300 Epoch=88.1] | Loss=0.00410 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=4.048 | 4165.6 samples/s | 65.1 steps/s
[Step=9350 Epoch=88.6] | Loss=0.00386 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=4.048 | 2427.1 samples/s | 37.9 steps/s
[Step=9400 Epoch=89.1] | Loss=0.00364 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=4.048 | 4029.0 samples/s | 63.0 steps/s
[Step=9450 Epoch=89.5] | Loss=0.00345 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.890 | L2-Norm(final)=4.048 | 6404.6 samples/s | 100.1 steps/s
[Step=9500 Epoch=90.0] | Loss=0.00328 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.877 | L2-Norm(final)=4.049 | 1982.3 samples/s | 31.0 steps/s
[Step=9550 Epoch=90.5] | Loss=0.00312 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=4.050 | 5755.7 samples/s | 89.9 steps/s
[Step=9600 Epoch=91.0] | Loss=0.00298 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.851 | L2-Norm(final)=4.051 | 2045.4 samples/s | 32.0 steps/s
[Step=9650 Epoch=91.4] | Loss=0.00285 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=4.052 | 5273.5 samples/s | 82.4 steps/s
[Step=9700 Epoch=91.9] | Loss=0.00274 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.822 | L2-Norm(final)=4.053 | 2119.3 samples/s | 33.1 steps/s
[Step=9750 Epoch=92.4] | Loss=0.00263 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.808 | L2-Norm(final)=4.055 | 4803.3 samples/s | 75.1 steps/s
[Step=9800 Epoch=92.9] | Loss=0.00253 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=4.057 | 2214.3 samples/s | 34.6 steps/s
[Step=9850 Epoch=93.3] | Loss=0.00243 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=4.058 | 4457.1 samples/s | 69.6 steps/s
[Step=9900 Epoch=93.8] | Loss=0.00235 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.763 | L2-Norm(final)=4.060 | 2276.2 samples/s | 35.6 steps/s
[Step=9950 Epoch=94.3] | Loss=0.00227 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.747 | L2-Norm(final)=4.062 | 4289.7 samples/s | 67.0 steps/s
[Step=10000 Epoch=94.8] | Loss=0.00219 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.732 | L2-Norm(final)=4.064 | 2348.9 samples/s | 36.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step10000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=76.1] | Loss=0.01182 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.177 | L2-Norm(final)=4.170 | 5235.0 samples/s | 81.8 steps/s
[Step=8050 Epoch=76.6] | Loss=0.01096 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.283 | L2-Norm(final)=4.178 | 4171.0 samples/s | 65.2 steps/s
[Step=8100 Epoch=77.1] | Loss=0.00817 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.347 | L2-Norm(final)=4.189 | 7435.6 samples/s | 116.2 steps/s
[Step=8150 Epoch=77.5] | Loss=0.00634 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.385 | L2-Norm(final)=4.208 | 2127.7 samples/s | 33.2 steps/s
[Step=8200 Epoch=78.0] | Loss=0.00539 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.414 | L2-Norm(final)=4.229 | 6551.8 samples/s | 102.4 steps/s
[Step=8250 Epoch=78.5] | Loss=0.00474 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.439 | L2-Norm(final)=4.249 | 2187.6 samples/s | 34.2 steps/s
[Step=8300 Epoch=79.0] | Loss=0.00425 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.459 | L2-Norm(final)=4.269 | 5871.9 samples/s | 91.7 steps/s
[Step=8350 Epoch=79.4] | Loss=0.00381 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.479 | L2-Norm(final)=4.289 | 2287.6 samples/s | 35.7 steps/s
[Step=8400 Epoch=79.9] | Loss=0.00352 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=4.308 | 5315.6 samples/s | 83.1 steps/s
[Step=8450 Epoch=80.4] | Loss=0.00325 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=4.328 | 2362.2 samples/s | 36.9 steps/s
[Step=8500 Epoch=80.9] | Loss=0.00300 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=4.347 | 4878.1 samples/s | 76.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=80.9] | Loss=0.00017 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=4.537 | 5346.3 samples/s | 83.5 steps/s
[Step=8550 Epoch=81.3] | Loss=0.00359 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.660 | L2-Norm(final)=4.547 | 3749.9 samples/s | 58.6 steps/s
[Step=8600 Epoch=81.8] | Loss=0.01780 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.846 | L2-Norm(final)=4.517 | 6082.4 samples/s | 95.0 steps/s
[Step=8650 Epoch=82.3] | Loss=0.01415 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=4.479 | 1987.6 samples/s | 31.1 steps/s
[Step=8700 Epoch=82.8] | Loss=0.01210 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=4.458 | 5642.0 samples/s | 88.2 steps/s
[Step=8750 Epoch=83.2] | Loss=0.00985 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=4.444 | 2084.0 samples/s | 32.6 steps/s
[Step=8800 Epoch=83.7] | Loss=0.00830 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.203 | L2-Norm(final)=4.436 | 5012.9 samples/s | 78.3 steps/s
[Step=8850 Epoch=84.2] | Loss=0.00713 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=4.430 | 2134.8 samples/s | 33.4 steps/s
[Step=8900 Epoch=84.7] | Loss=0.00624 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=4.426 | 4681.0 samples/s | 73.1 steps/s
[Step=8950 Epoch=85.1] | Loss=0.00555 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.248 | L2-Norm(final)=4.423 | 2250.7 samples/s | 35.2 steps/s
[Step=9000 Epoch=85.6] | Loss=0.00500 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=4.421 | 4340.4 samples/s | 67.8 steps/s
[Step=9050 Epoch=86.1] | Loss=0.00455 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=4.419 | 2323.2 samples/s | 36.3 steps/s
[Step=9100 Epoch=86.6] | Loss=0.00417 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.249 | L2-Norm(final)=4.418 | 4226.5 samples/s | 66.0 steps/s
[Step=9150 Epoch=87.0] | Loss=0.00385 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.244 | L2-Norm(final)=4.417 | 2371.1 samples/s | 37.0 steps/s
[Step=9200 Epoch=87.5] | Loss=0.00357 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=4.416 | 4176.3 samples/s | 65.3 steps/s
[Step=9250 Epoch=88.0] | Loss=0.00334 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=4.415 | 2407.1 samples/s | 37.6 steps/s
[Step=9300 Epoch=88.5] | Loss=0.00313 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=4.415 | 4179.5 samples/s | 65.3 steps/s
[Step=9350 Epoch=88.9] | Loss=0.00295 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.213 | L2-Norm(final)=4.414 | 2461.9 samples/s | 38.5 steps/s
[Step=9400 Epoch=89.4] | Loss=0.00278 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=4.414 | 3868.7 samples/s | 60.4 steps/s
[Step=9450 Epoch=89.9] | Loss=0.00264 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=4.414 | 6443.4 samples/s | 100.7 steps/s
[Step=9500 Epoch=90.4] | Loss=0.00251 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=4.413 | 1966.1 samples/s | 30.7 steps/s
[Step=9550 Epoch=90.8] | Loss=0.00239 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=4.413 | 5842.5 samples/s | 91.3 steps/s
[Step=9600 Epoch=91.3] | Loss=0.00228 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=4.413 | 2027.8 samples/s | 31.7 steps/s
[Step=9650 Epoch=91.8] | Loss=0.00218 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=4.413 | 5268.7 samples/s | 82.3 steps/s
[Step=9700 Epoch=92.3] | Loss=0.00209 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=4.413 | 2116.1 samples/s | 33.1 steps/s
[Step=9750 Epoch=92.7] | Loss=0.00201 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=4.413 | 4766.7 samples/s | 74.5 steps/s
[Step=9800 Epoch=93.2] | Loss=0.00193 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=4.413 | 2221.6 samples/s | 34.7 steps/s
[Step=9850 Epoch=93.7] | Loss=0.00186 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=4.413 | 4464.0 samples/s | 69.8 steps/s
[Step=9900 Epoch=94.2] | Loss=0.00179 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.073 | L2-Norm(final)=4.414 | 2329.9 samples/s | 36.4 steps/s
[Step=9950 Epoch=94.6] | Loss=0.00173 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.058 | L2-Norm(final)=4.414 | 4051.7 samples/s | 63.3 steps/s
[Step=10000 Epoch=95.1] | Loss=0.00167 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=4.414 | 2374.5 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step10000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=76.4] | Loss=0.05065 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.717 | L2-Norm(final)=3.886 | 5072.2 samples/s | 79.3 steps/s
[Step=8050 Epoch=76.9] | Loss=0.01822 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=3.856 | 4161.0 samples/s | 65.0 steps/s
[Step=8100 Epoch=77.4] | Loss=0.01214 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=3.869 | 7516.8 samples/s | 117.5 steps/s
[Step=8150 Epoch=77.8] | Loss=0.00931 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.979 | L2-Norm(final)=3.889 | 2083.4 samples/s | 32.6 steps/s
[Step=8200 Epoch=78.3] | Loss=0.00811 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=3.912 | 6783.7 samples/s | 106.0 steps/s
[Step=8250 Epoch=78.8] | Loss=0.00719 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=3.935 | 2156.4 samples/s | 33.7 steps/s
[Step=8300 Epoch=79.3] | Loss=0.00639 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=3.960 | 6113.9 samples/s | 95.5 steps/s
[Step=8350 Epoch=79.7] | Loss=0.00570 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=3.982 | 2229.1 samples/s | 34.8 steps/s
[Step=8400 Epoch=80.2] | Loss=0.00530 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.110 | L2-Norm(final)=4.005 | 5686.0 samples/s | 88.8 steps/s
[Step=8450 Epoch=80.7] | Loss=0.00490 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=4.028 | 2292.9 samples/s | 35.8 steps/s
[Step=8500 Epoch=81.2] | Loss=0.00457 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=4.050 | 5238.7 samples/s | 81.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=81.2] | Loss=0.00128 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=4.274 | 5426.5 samples/s | 84.8 steps/s
[Step=8550 Epoch=81.6] | Loss=0.01203 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.346 | L2-Norm(final)=4.283 | 3711.9 samples/s | 58.0 steps/s
[Step=8600 Epoch=82.1] | Loss=0.01568 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.459 | L2-Norm(final)=4.264 | 6143.2 samples/s | 96.0 steps/s
[Step=8650 Epoch=82.6] | Loss=0.01183 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.539 | L2-Norm(final)=4.248 | 1978.4 samples/s | 30.9 steps/s
[Step=8700 Epoch=83.1] | Loss=0.00923 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.578 | L2-Norm(final)=4.242 | 5804.1 samples/s | 90.7 steps/s
[Step=8750 Epoch=83.6] | Loss=0.00746 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=4.240 | 2067.2 samples/s | 32.3 steps/s
[Step=8800 Epoch=84.0] | Loss=0.00622 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.603 | L2-Norm(final)=4.240 | 5256.1 samples/s | 82.1 steps/s
[Step=8850 Epoch=84.5] | Loss=0.00534 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=4.239 | 2091.1 samples/s | 32.7 steps/s
[Step=8900 Epoch=85.0] | Loss=0.00467 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=4.240 | 4952.8 samples/s | 77.4 steps/s
[Step=8950 Epoch=85.5] | Loss=0.00416 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=4.240 | 2180.3 samples/s | 34.1 steps/s
[Step=9000 Epoch=85.9] | Loss=0.00374 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.577 | L2-Norm(final)=4.240 | 4517.7 samples/s | 70.6 steps/s
[Step=9050 Epoch=86.4] | Loss=0.00340 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=4.240 | 2264.9 samples/s | 35.4 steps/s
[Step=9100 Epoch=86.9] | Loss=0.00312 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=4.240 | 4267.0 samples/s | 66.7 steps/s
[Step=9150 Epoch=87.4] | Loss=0.00288 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=4.241 | 2384.0 samples/s | 37.3 steps/s
[Step=9200 Epoch=87.9] | Loss=0.00268 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.518 | L2-Norm(final)=4.241 | 4208.9 samples/s | 65.8 steps/s
[Step=9250 Epoch=88.3] | Loss=0.00250 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.501 | L2-Norm(final)=4.241 | 2398.6 samples/s | 37.5 steps/s
[Step=9300 Epoch=88.8] | Loss=0.00234 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.483 | L2-Norm(final)=4.242 | 4313.5 samples/s | 67.4 steps/s
[Step=9350 Epoch=89.3] | Loss=0.00221 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=4.242 | 2348.1 samples/s | 36.7 steps/s
[Step=9400 Epoch=89.8] | Loss=0.00208 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.447 | L2-Norm(final)=4.243 | 4224.5 samples/s | 66.0 steps/s
[Step=9450 Epoch=90.2] | Loss=0.00197 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=4.243 | 2396.5 samples/s | 37.4 steps/s
[Step=9500 Epoch=90.7] | Loss=0.00188 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.408 | L2-Norm(final)=4.243 | 4103.1 samples/s | 64.1 steps/s
[Step=9550 Epoch=91.2] | Loss=0.00179 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=4.244 | 6605.1 samples/s | 103.2 steps/s
[Step=9600 Epoch=91.7] | Loss=0.00171 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=4.244 | 1835.6 samples/s | 28.7 steps/s
[Step=9650 Epoch=92.2] | Loss=0.00163 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=4.244 | 5993.6 samples/s | 93.6 steps/s
[Step=9700 Epoch=92.6] | Loss=0.00156 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=4.245 | 1863.2 samples/s | 29.1 steps/s
[Step=9750 Epoch=93.1] | Loss=0.00150 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=4.245 | 5540.6 samples/s | 86.6 steps/s
[Step=9800 Epoch=93.6] | Loss=0.00144 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=4.245 | 1925.2 samples/s | 30.1 steps/s
[Step=9850 Epoch=94.1] | Loss=0.00139 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=4.246 | 5050.1 samples/s | 78.9 steps/s
[Step=9900 Epoch=94.5] | Loss=0.00134 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=4.246 | 2137.0 samples/s | 33.4 steps/s
[Step=9950 Epoch=95.0] | Loss=0.00130 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=4.246 | 4930.7 samples/s | 77.0 steps/s
[Step=10000 Epoch=95.5] | Loss=0.00125 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=4.247 | 2196.2 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step10000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=75.4] | Loss=0.04827 | Reg=0.00215 | acc=0.9531 | L2-Norm=14.672 | L2-Norm(final)=3.686 | 5025.0 samples/s | 78.5 steps/s
[Step=8050 Epoch=75.9] | Loss=0.01041 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.736 | L2-Norm(final)=3.691 | 4428.7 samples/s | 69.2 steps/s
[Step=8100 Epoch=76.3] | Loss=0.00743 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.789 | L2-Norm(final)=3.724 | 7254.7 samples/s | 113.4 steps/s
[Step=8150 Epoch=76.8] | Loss=0.00593 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.830 | L2-Norm(final)=3.759 | 2158.0 samples/s | 33.7 steps/s
[Step=8200 Epoch=77.3] | Loss=0.00528 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.860 | L2-Norm(final)=3.790 | 6462.0 samples/s | 101.0 steps/s
[Step=8250 Epoch=77.7] | Loss=0.00458 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.888 | L2-Norm(final)=3.821 | 2265.4 samples/s | 35.4 steps/s
[Step=8300 Epoch=78.2] | Loss=0.00406 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.910 | L2-Norm(final)=3.851 | 5418.5 samples/s | 84.7 steps/s
[Step=8350 Epoch=78.7] | Loss=0.00383 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=3.879 | 2382.5 samples/s | 37.2 steps/s
[Step=8400 Epoch=79.2] | Loss=0.00358 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=3.906 | 4974.0 samples/s | 77.7 steps/s
[Step=8450 Epoch=79.6] | Loss=0.00329 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=3.933 | 2496.3 samples/s | 39.0 steps/s
[Step=8500 Epoch=80.1] | Loss=0.00309 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=3.958 | 4933.2 samples/s | 77.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=80.1] | Loss=0.00656 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.101 | L2-Norm(final)=4.208 | 5593.7 samples/s | 87.4 steps/s
[Step=8550 Epoch=80.6] | Loss=0.03382 | Reg=0.00233 | acc=0.9531 | L2-Norm=15.278 | L2-Norm(final)=4.160 | 3763.0 samples/s | 58.8 steps/s
[Step=8600 Epoch=81.0] | Loss=0.02291 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=4.102 | 6045.5 samples/s | 94.5 steps/s
[Step=8650 Epoch=81.5] | Loss=0.01573 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=4.080 | 2019.3 samples/s | 31.6 steps/s
[Step=8700 Epoch=82.0] | Loss=0.01203 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=4.072 | 5507.3 samples/s | 86.1 steps/s
[Step=8750 Epoch=82.4] | Loss=0.00967 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.521 | L2-Norm(final)=4.069 | 2137.9 samples/s | 33.4 steps/s
[Step=8800 Epoch=82.9] | Loss=0.00807 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.524 | L2-Norm(final)=4.068 | 4957.2 samples/s | 77.5 steps/s
[Step=8850 Epoch=83.4] | Loss=0.00693 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.521 | L2-Norm(final)=4.067 | 2198.6 samples/s | 34.4 steps/s
[Step=8900 Epoch=83.9] | Loss=0.00606 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=4.067 | 4399.4 samples/s | 68.7 steps/s
[Step=8950 Epoch=84.3] | Loss=0.00539 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=4.067 | 2309.9 samples/s | 36.1 steps/s
[Step=9000 Epoch=84.8] | Loss=0.00485 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.494 | L2-Norm(final)=4.068 | 4256.5 samples/s | 66.5 steps/s
[Step=9050 Epoch=85.3] | Loss=0.00442 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=4.068 | 2423.7 samples/s | 37.9 steps/s
[Step=9100 Epoch=85.7] | Loss=0.00405 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.469 | L2-Norm(final)=4.068 | 4217.1 samples/s | 65.9 steps/s
[Step=9150 Epoch=86.2] | Loss=0.00374 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.455 | L2-Norm(final)=4.069 | 2383.6 samples/s | 37.2 steps/s
[Step=9200 Epoch=86.7] | Loss=0.00347 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=4.069 | 4256.0 samples/s | 66.5 steps/s
[Step=9250 Epoch=87.2] | Loss=0.00324 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=4.069 | 2613.2 samples/s | 40.8 steps/s
[Step=9300 Epoch=87.6] | Loss=0.00304 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.409 | L2-Norm(final)=4.070 | 3694.8 samples/s | 57.7 steps/s
[Step=9350 Epoch=88.1] | Loss=0.00286 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=4.070 | 6378.1 samples/s | 99.7 steps/s
[Step=9400 Epoch=88.6] | Loss=0.00270 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=4.071 | 2026.1 samples/s | 31.7 steps/s
[Step=9450 Epoch=89.0] | Loss=0.00256 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=4.071 | 5587.6 samples/s | 87.3 steps/s
[Step=9500 Epoch=89.5] | Loss=0.00243 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=4.072 | 2090.8 samples/s | 32.7 steps/s
[Step=9550 Epoch=90.0] | Loss=0.00232 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=4.072 | 5004.5 samples/s | 78.2 steps/s
[Step=9600 Epoch=90.5] | Loss=0.00221 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.306 | L2-Norm(final)=4.073 | 2224.2 samples/s | 34.8 steps/s
[Step=9650 Epoch=90.9] | Loss=0.00212 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=4.073 | 4477.1 samples/s | 70.0 steps/s
[Step=9700 Epoch=91.4] | Loss=0.00203 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=4.074 | 2299.2 samples/s | 35.9 steps/s
[Step=9750 Epoch=91.9] | Loss=0.00195 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=4.074 | 4207.0 samples/s | 65.7 steps/s
[Step=9800 Epoch=92.3] | Loss=0.00187 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=4.075 | 2397.3 samples/s | 37.5 steps/s
[Step=9850 Epoch=92.8] | Loss=0.00181 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=4.075 | 4344.8 samples/s | 67.9 steps/s
[Step=9900 Epoch=93.3] | Loss=0.00174 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=4.076 | 2390.2 samples/s | 37.3 steps/s
[Step=9950 Epoch=93.8] | Loss=0.00168 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=4.076 | 4198.3 samples/s | 65.6 steps/s
[Step=10000 Epoch=94.2] | Loss=0.00163 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=4.077 | 2592.5 samples/s | 40.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step10000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=76.3] | Loss=0.03597 | Reg=0.00200 | acc=0.9531 | L2-Norm=14.156 | L2-Norm(final)=4.530 | 5535.9 samples/s | 86.5 steps/s
[Step=8050 Epoch=76.7] | Loss=0.01243 | Reg=0.00203 | acc=0.9844 | L2-Norm=14.264 | L2-Norm(final)=4.527 | 3940.0 samples/s | 61.6 steps/s
[Step=8100 Epoch=77.2] | Loss=0.00868 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.324 | L2-Norm(final)=4.556 | 7589.9 samples/s | 118.6 steps/s
[Step=8150 Epoch=77.7] | Loss=0.00739 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.366 | L2-Norm(final)=4.589 | 2117.6 samples/s | 33.1 steps/s
[Step=8200 Epoch=78.2] | Loss=0.00651 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.401 | L2-Norm(final)=4.621 | 6869.8 samples/s | 107.3 steps/s
[Step=8250 Epoch=78.6] | Loss=0.00564 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.428 | L2-Norm(final)=4.651 | 2189.8 samples/s | 34.2 steps/s
[Step=8300 Epoch=79.1] | Loss=0.00506 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.454 | L2-Norm(final)=4.681 | 6251.2 samples/s | 97.7 steps/s
[Step=8350 Epoch=79.6] | Loss=0.00461 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=4.709 | 2270.5 samples/s | 35.5 steps/s
[Step=8400 Epoch=80.1] | Loss=0.00431 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.495 | L2-Norm(final)=4.737 | 5570.0 samples/s | 87.0 steps/s
[Step=8450 Epoch=80.5] | Loss=0.00399 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=4.763 | 2333.6 samples/s | 36.5 steps/s
[Step=8500 Epoch=81.0] | Loss=0.00368 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.526 | L2-Norm(final)=4.788 | 5262.1 samples/s | 82.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=81.0] | Loss=0.00031 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=5.030 | 5587.9 samples/s | 87.3 steps/s
[Step=8550 Epoch=81.5] | Loss=0.01448 | Reg=0.00216 | acc=0.9219 | L2-Norm=14.705 | L2-Norm(final)=5.045 | 3640.1 samples/s | 56.9 steps/s
[Step=8600 Epoch=82.0] | Loss=0.01978 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=5.013 | 6385.3 samples/s | 99.8 steps/s
[Step=8650 Epoch=82.4] | Loss=0.01431 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=4.992 | 2015.0 samples/s | 31.5 steps/s
[Step=8700 Epoch=82.9] | Loss=0.01084 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=4.984 | 5673.9 samples/s | 88.7 steps/s
[Step=8750 Epoch=83.4] | Loss=0.00868 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=4.982 | 2089.5 samples/s | 32.6 steps/s
[Step=8800 Epoch=83.9] | Loss=0.00724 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.035 | L2-Norm(final)=4.981 | 5236.2 samples/s | 81.8 steps/s
[Step=8850 Epoch=84.3] | Loss=0.00621 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=4.980 | 2133.5 samples/s | 33.3 steps/s
[Step=8900 Epoch=84.8] | Loss=0.00544 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=4.980 | 4997.3 samples/s | 78.1 steps/s
[Step=8950 Epoch=85.3] | Loss=0.00483 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=4.980 | 2145.8 samples/s | 33.5 steps/s
[Step=9000 Epoch=85.8] | Loss=0.00435 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=4.981 | 4637.3 samples/s | 72.5 steps/s
[Step=9050 Epoch=86.3] | Loss=0.00396 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=4.981 | 2298.8 samples/s | 35.9 steps/s
[Step=9100 Epoch=86.7] | Loss=0.00363 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=4.982 | 4414.9 samples/s | 69.0 steps/s
[Step=9150 Epoch=87.2] | Loss=0.00335 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=4.982 | 2345.2 samples/s | 36.6 steps/s
[Step=9200 Epoch=87.7] | Loss=0.00311 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=4.983 | 4255.9 samples/s | 66.5 steps/s
[Step=9250 Epoch=88.2] | Loss=0.00291 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=4.983 | 2350.3 samples/s | 36.7 steps/s
[Step=9300 Epoch=88.6] | Loss=0.00272 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=4.984 | 4232.9 samples/s | 66.1 steps/s
[Step=9350 Epoch=89.1] | Loss=0.00256 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=4.984 | 2418.4 samples/s | 37.8 steps/s
[Step=9400 Epoch=89.6] | Loss=0.00242 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.907 | L2-Norm(final)=4.985 | 4155.8 samples/s | 64.9 steps/s
[Step=9450 Epoch=90.1] | Loss=0.00230 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=4.985 | 2412.2 samples/s | 37.7 steps/s
[Step=9500 Epoch=90.5] | Loss=0.00218 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.874 | L2-Norm(final)=4.986 | 4100.5 samples/s | 64.1 steps/s
[Step=9550 Epoch=91.0] | Loss=0.00208 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.857 | L2-Norm(final)=4.987 | 6993.7 samples/s | 109.3 steps/s
[Step=9600 Epoch=91.5] | Loss=0.00198 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=4.987 | 1964.8 samples/s | 30.7 steps/s
[Step=9650 Epoch=92.0] | Loss=0.00190 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.822 | L2-Norm(final)=4.988 | 6258.5 samples/s | 97.8 steps/s
[Step=9700 Epoch=92.4] | Loss=0.00182 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.804 | L2-Norm(final)=4.988 | 2007.5 samples/s | 31.4 steps/s
[Step=9750 Epoch=92.9] | Loss=0.00175 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=4.989 | 5873.3 samples/s | 91.8 steps/s
[Step=9800 Epoch=93.4] | Loss=0.00168 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.767 | L2-Norm(final)=4.990 | 2060.4 samples/s | 32.2 steps/s
[Step=9850 Epoch=93.9] | Loss=0.00162 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=4.990 | 5382.4 samples/s | 84.1 steps/s
[Step=9900 Epoch=94.4] | Loss=0.00156 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=4.991 | 2151.8 samples/s | 33.6 steps/s
[Step=9950 Epoch=94.8] | Loss=0.00151 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=4.992 | 5012.4 samples/s | 78.3 steps/s
[Step=10000 Epoch=95.3] | Loss=0.00146 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=4.992 | 2197.3 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.14897 | acc=0.9323 | tpr=0.9334 | fpr=0.0699 | 4652.6 samples/s | 18.2 steps/s
Avg test loss: 0.14935, Avg test acc: 0.93185, Avg tpr: 0.93350, Avg fpr: 0.07179, total FA: 560

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12880 | acc=0.9435 | tpr=0.9606 | fpr=0.0937 | 5029.6 samples/s | 19.6 steps/s
Avg test loss: 0.12885, Avg test acc: 0.94326, Avg tpr: 0.96089, Avg fpr: 0.09550, total FA: 745

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.16334 | acc=0.9412 | tpr=0.9686 | fpr=0.1184 | 4846.6 samples/s | 18.9 steps/s
Avg test loss: 0.16408, Avg test acc: 0.94074, Avg tpr: 0.96923, Avg fpr: 0.12191, total FA: 951

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.15944 | acc=0.9381 | tpr=0.9718 | fpr=0.1350 | 4863.2 samples/s | 19.0 steps/s
Avg test loss: 0.16130, Avg test acc: 0.93830, Avg tpr: 0.97255, Avg fpr: 0.13703, total FA: 1069

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.15434 | acc=0.9423 | tpr=0.9662 | fpr=0.1095 | 4745.7 samples/s | 18.5 steps/s
Avg test loss: 0.15780, Avg test acc: 0.94178, Avg tpr: 0.96555, Avg fpr: 0.11050, total FA: 862

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.15702 | acc=0.3086 | tpr=0.0154 | fpr=0.0548 | 4964.8 samples/s | 19.4 steps/s
Avg test loss: 4.17091, Avg test acc: 0.30740, Avg tpr: 0.01626, Avg fpr: 0.05230, total FA: 408

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=3.99354 | acc=0.3116 | tpr=0.0017 | fpr=0.0156 | 4671.9 samples/s | 18.2 steps/s
Avg test loss: 4.01111, Avg test acc: 0.30912, Avg tpr: 0.00169, Avg fpr: 0.01474, total FA: 115

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.68582 | acc=0.3031 | tpr=0.0126 | fpr=0.0659 | 4828.5 samples/s | 18.9 steps/s
Avg test loss: 4.70194, Avg test acc: 0.30151, Avg tpr: 0.01276, Avg fpr: 0.06345, total FA: 495

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=4.07978 | acc=0.3095 | tpr=0.0137 | fpr=0.0483 | 4678.2 samples/s | 18.3 steps/s
Avg test loss: 4.07759, Avg test acc: 0.30756, Avg tpr: 0.01440, Avg fpr: 0.04769, total FA: 372

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.85923 | acc=0.3108 | tpr=0.0223 | fpr=0.0627 | 4925.1 samples/s | 19.2 steps/s
Avg test loss: 4.87318, Avg test acc: 0.30736, Avg tpr: 0.02133, Avg fpr: 0.06358, total FA: 496

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.19816 | acc=0.1489 | tpr=0.5442 | fpr=0.8582 | 4874.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=4.19237 | acc=0.1486 | tpr=0.5437 | fpr=0.8588 | 6866.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=4.19155 | acc=0.1491 | tpr=0.5360 | fpr=0.8580 | 7979.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=4.19038 | acc=0.1480 | tpr=0.5410 | fpr=0.8591 | 7974.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.20454 | acc=0.1481 | tpr=0.5406 | fpr=0.8591 | 8104.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=4.20140 | acc=0.1477 | tpr=0.5425 | fpr=0.8594 | 7238.9 samples/s | 28.3 steps/s
[Step= 350] | Loss=4.19617 | acc=0.1482 | tpr=0.5454 | fpr=0.8590 | 8168.3 samples/s | 31.9 steps/s
[Step= 400] | Loss=4.19183 | acc=0.1483 | tpr=0.5454 | fpr=0.8589 | 8025.7 samples/s | 31.4 steps/s
[Step= 450] | Loss=4.19282 | acc=0.1484 | tpr=0.5472 | fpr=0.8588 | 7765.1 samples/s | 30.3 steps/s
[Step= 500] | Loss=4.19629 | acc=0.1489 | tpr=0.5515 | fpr=0.8584 | 7927.6 samples/s | 31.0 steps/s
[Step= 550] | Loss=4.19501 | acc=0.1489 | tpr=0.5551 | fpr=0.8585 | 8375.4 samples/s | 32.7 steps/s
Avg test loss: 4.19646, Avg test acc: 0.14881, Avg tpr: 0.55586, Avg fpr: 0.85859, total FA: 119214

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.36768 | acc=0.1288 | tpr=0.6770 | fpr=0.8811 | 4759.3 samples/s | 18.6 steps/s
[Step= 100] | Loss=4.34386 | acc=0.1298 | tpr=0.6482 | fpr=0.8798 | 7131.4 samples/s | 27.9 steps/s
[Step= 150] | Loss=4.34006 | acc=0.1310 | tpr=0.6470 | fpr=0.8785 | 7890.9 samples/s | 30.8 steps/s
[Step= 200] | Loss=4.33079 | acc=0.1321 | tpr=0.6481 | fpr=0.8773 | 7663.2 samples/s | 29.9 steps/s
[Step= 250] | Loss=4.33666 | acc=0.1325 | tpr=0.6507 | fpr=0.8769 | 8215.3 samples/s | 32.1 steps/s
[Step= 300] | Loss=4.32801 | acc=0.1324 | tpr=0.6509 | fpr=0.8770 | 7891.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=4.32422 | acc=0.1326 | tpr=0.6518 | fpr=0.8768 | 8002.4 samples/s | 31.3 steps/s
[Step= 400] | Loss=4.31892 | acc=0.1328 | tpr=0.6592 | fpr=0.8768 | 7715.5 samples/s | 30.1 steps/s
[Step= 450] | Loss=4.32492 | acc=0.1320 | tpr=0.6631 | fpr=0.8776 | 7937.8 samples/s | 31.0 steps/s
[Step= 500] | Loss=4.32718 | acc=0.1316 | tpr=0.6564 | fpr=0.8779 | 5979.0 samples/s | 23.4 steps/s
[Step= 550] | Loss=4.32755 | acc=0.1314 | tpr=0.6534 | fpr=0.8780 | 12665.7 samples/s | 49.5 steps/s
Avg test loss: 4.32981, Avg test acc: 0.13129, Avg tpr: 0.65372, Avg fpr: 0.87820, total FA: 121937

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.86961 | acc=0.0749 | tpr=0.6814 | fpr=0.9360 | 4747.4 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.83932 | acc=0.0766 | tpr=0.6908 | fpr=0.9348 | 7296.5 samples/s | 28.5 steps/s
[Step= 150] | Loss=5.83412 | acc=0.0774 | tpr=0.7118 | fpr=0.9343 | 7867.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.83392 | acc=0.0767 | tpr=0.7060 | fpr=0.9348 | 7799.8 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.85175 | acc=0.0761 | tpr=0.7153 | fpr=0.9356 | 7575.5 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.85205 | acc=0.0763 | tpr=0.7207 | fpr=0.9355 | 7987.7 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.84633 | acc=0.0765 | tpr=0.7201 | fpr=0.9352 | 8397.4 samples/s | 32.8 steps/s
[Step= 400] | Loss=5.84146 | acc=0.0770 | tpr=0.7243 | fpr=0.9348 | 7722.5 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.84515 | acc=0.0766 | tpr=0.7278 | fpr=0.9353 | 7924.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.85142 | acc=0.0765 | tpr=0.7269 | fpr=0.9353 | 5802.2 samples/s | 22.7 steps/s
[Step= 550] | Loss=5.85154 | acc=0.0763 | tpr=0.7262 | fpr=0.9355 | 13305.8 samples/s | 52.0 steps/s
Avg test loss: 5.85271, Avg test acc: 0.07624, Avg tpr: 0.72662, Avg fpr: 0.93558, total FA: 129904

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.40727 | acc=0.1197 | tpr=0.7434 | fpr=0.8915 | 4787.6 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.39472 | acc=0.1215 | tpr=0.7548 | fpr=0.8903 | 7083.7 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.40071 | acc=0.1219 | tpr=0.7464 | fpr=0.8896 | 7898.7 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.39555 | acc=0.1214 | tpr=0.7541 | fpr=0.8901 | 7959.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.40592 | acc=0.1222 | tpr=0.7703 | fpr=0.8897 | 7790.0 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.40600 | acc=0.1212 | tpr=0.7724 | fpr=0.8907 | 7869.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.39763 | acc=0.1212 | tpr=0.7683 | fpr=0.8905 | 7724.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.39423 | acc=0.1212 | tpr=0.7631 | fpr=0.8905 | 7884.1 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.40290 | acc=0.1210 | tpr=0.7692 | fpr=0.8907 | 7939.6 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.40818 | acc=0.1205 | tpr=0.7639 | fpr=0.8911 | 5696.1 samples/s | 22.3 steps/s
[Step= 550] | Loss=5.41048 | acc=0.1205 | tpr=0.7636 | fpr=0.8911 | 14241.5 samples/s | 55.6 steps/s
Avg test loss: 5.41138, Avg test acc: 0.12046, Avg tpr: 0.76466, Avg fpr: 0.89126, total FA: 123749

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.22709 | acc=0.1166 | tpr=0.8142 | fpr=0.8959 | 4721.7 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.22567 | acc=0.1170 | tpr=0.7953 | fpr=0.8956 | 7268.8 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.23462 | acc=0.1178 | tpr=0.7867 | fpr=0.8945 | 7847.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.23377 | acc=0.1184 | tpr=0.7825 | fpr=0.8937 | 7970.8 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.25448 | acc=0.1176 | tpr=0.7817 | fpr=0.8945 | 7918.6 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.25245 | acc=0.1172 | tpr=0.7775 | fpr=0.8948 | 7524.0 samples/s | 29.4 steps/s
[Step= 350] | Loss=5.25870 | acc=0.1161 | tpr=0.7765 | fpr=0.8959 | 8071.2 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.25626 | acc=0.1158 | tpr=0.7746 | fpr=0.8962 | 8072.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.26140 | acc=0.1155 | tpr=0.7736 | fpr=0.8964 | 6656.2 samples/s | 26.0 steps/s
[Step= 500] | Loss=5.26753 | acc=0.1155 | tpr=0.7727 | fpr=0.8964 | 6799.3 samples/s | 26.6 steps/s
[Step= 550] | Loss=5.27065 | acc=0.1157 | tpr=0.7720 | fpr=0.8962 | 12922.4 samples/s | 50.5 steps/s
Avg test loss: 5.27164, Avg test acc: 0.11560, Avg tpr: 0.77179, Avg fpr: 0.89633, total FA: 124454

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09975 | acc=0.9805 | tpr=0.9071 | fpr=0.0182 | 4768.4 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10113 | acc=0.9796 | tpr=0.9062 | fpr=0.0190 | 6915.6 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.10600 | acc=0.9785 | tpr=0.9078 | fpr=0.0202 | 8316.0 samples/s | 32.5 steps/s
[Step= 200] | Loss=0.10882 | acc=0.9784 | tpr=0.9169 | fpr=0.0205 | 7554.7 samples/s | 29.5 steps/s
[Step= 250] | Loss=0.10694 | acc=0.9787 | tpr=0.9135 | fpr=0.0202 | 7775.1 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.10875 | acc=0.9784 | tpr=0.9113 | fpr=0.0204 | 7914.5 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.11032 | acc=0.9781 | tpr=0.9105 | fpr=0.0207 | 8113.3 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.11151 | acc=0.9779 | tpr=0.9108 | fpr=0.0209 | 7668.5 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.11371 | acc=0.9774 | tpr=0.9094 | fpr=0.0214 | 5860.7 samples/s | 22.9 steps/s
[Step= 500] | Loss=0.11287 | acc=0.9774 | tpr=0.9119 | fpr=0.0214 | 7878.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.11225 | acc=0.9776 | tpr=0.9097 | fpr=0.0212 | 13585.2 samples/s | 53.1 steps/s
Avg test loss: 0.11217, Avg test acc: 0.97761, Avg tpr: 0.90967, Avg fpr: 0.02115, total FA: 2937

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11437 | acc=0.9817 | tpr=0.8407 | fpr=0.0157 | 4889.2 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.11807 | acc=0.9823 | tpr=0.8614 | fpr=0.0154 | 6856.2 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.12348 | acc=0.9812 | tpr=0.8646 | fpr=0.0167 | 7940.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.12458 | acc=0.9813 | tpr=0.8721 | fpr=0.0167 | 8119.2 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.12197 | acc=0.9815 | tpr=0.8681 | fpr=0.0164 | 7615.5 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.12432 | acc=0.9812 | tpr=0.8713 | fpr=0.0168 | 7444.4 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.12592 | acc=0.9811 | tpr=0.8754 | fpr=0.0170 | 8422.1 samples/s | 32.9 steps/s
[Step= 400] | Loss=0.12781 | acc=0.9809 | tpr=0.8753 | fpr=0.0172 | 7664.7 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.13088 | acc=0.9804 | tpr=0.8720 | fpr=0.0176 | 5739.5 samples/s | 22.4 steps/s
[Step= 500] | Loss=0.12944 | acc=0.9804 | tpr=0.8727 | fpr=0.0176 | 7839.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12910 | acc=0.9805 | tpr=0.8711 | fpr=0.0175 | 14590.0 samples/s | 57.0 steps/s
Avg test loss: 0.12890, Avg test acc: 0.98053, Avg tpr: 0.87044, Avg fpr: 0.01747, total FA: 2426

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10941 | acc=0.9786 | tpr=0.9159 | fpr=0.0203 | 4816.1 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.11126 | acc=0.9782 | tpr=0.9254 | fpr=0.0208 | 6905.5 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.11950 | acc=0.9764 | tpr=0.9193 | fpr=0.0225 | 7993.9 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.12142 | acc=0.9766 | tpr=0.9235 | fpr=0.0225 | 7967.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.11831 | acc=0.9769 | tpr=0.9231 | fpr=0.0222 | 7995.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.12003 | acc=0.9767 | tpr=0.9178 | fpr=0.0222 | 7816.3 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.12093 | acc=0.9765 | tpr=0.9161 | fpr=0.0224 | 7649.1 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.12265 | acc=0.9763 | tpr=0.9147 | fpr=0.0226 | 7677.9 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.12526 | acc=0.9759 | tpr=0.9138 | fpr=0.0230 | 6367.5 samples/s | 24.9 steps/s
[Step= 500] | Loss=0.12445 | acc=0.9759 | tpr=0.9163 | fpr=0.0231 | 8071.6 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.12397 | acc=0.9761 | tpr=0.9160 | fpr=0.0228 | 13800.8 samples/s | 53.9 steps/s
Avg test loss: 0.12380, Avg test acc: 0.97612, Avg tpr: 0.91640, Avg fpr: 0.02279, total FA: 3165

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09149 | acc=0.9819 | tpr=0.8717 | fpr=0.0161 | 4782.3 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09275 | acc=0.9815 | tpr=0.8827 | fpr=0.0167 | 6979.2 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.09607 | acc=0.9812 | tpr=0.8876 | fpr=0.0171 | 7961.8 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09780 | acc=0.9812 | tpr=0.8973 | fpr=0.0173 | 8149.3 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.09544 | acc=0.9813 | tpr=0.8908 | fpr=0.0171 | 7578.0 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.09821 | acc=0.9809 | tpr=0.8887 | fpr=0.0174 | 8146.9 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.09932 | acc=0.9809 | tpr=0.8936 | fpr=0.0175 | 8057.8 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.10020 | acc=0.9807 | tpr=0.8884 | fpr=0.0176 | 5905.1 samples/s | 23.1 steps/s
[Step= 450] | Loss=0.10241 | acc=0.9803 | tpr=0.8870 | fpr=0.0180 | 7397.3 samples/s | 28.9 steps/s
[Step= 500] | Loss=0.10204 | acc=0.9804 | tpr=0.8877 | fpr=0.0179 | 7933.2 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.10143 | acc=0.9806 | tpr=0.8870 | fpr=0.0177 | 14128.3 samples/s | 55.2 steps/s
Avg test loss: 0.10126, Avg test acc: 0.98059, Avg tpr: 0.88708, Avg fpr: 0.01771, total FA: 2459

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09877 | acc=0.9802 | tpr=0.8938 | fpr=0.0182 | 4709.3 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.09902 | acc=0.9807 | tpr=0.9126 | fpr=0.0180 | 7111.8 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.10173 | acc=0.9805 | tpr=0.9207 | fpr=0.0184 | 7839.7 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.10410 | acc=0.9804 | tpr=0.9279 | fpr=0.0186 | 7379.8 samples/s | 28.8 steps/s
[Step= 250] | Loss=0.10314 | acc=0.9802 | tpr=0.9214 | fpr=0.0187 | 7849.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.10531 | acc=0.9798 | tpr=0.9171 | fpr=0.0190 | 7641.7 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.10686 | acc=0.9796 | tpr=0.9173 | fpr=0.0193 | 7769.1 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.10790 | acc=0.9793 | tpr=0.9168 | fpr=0.0196 | 6428.9 samples/s | 25.1 steps/s
[Step= 450] | Loss=0.11019 | acc=0.9789 | tpr=0.9114 | fpr=0.0199 | 7769.2 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.10945 | acc=0.9790 | tpr=0.9128 | fpr=0.0198 | 8128.2 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.10902 | acc=0.9792 | tpr=0.9125 | fpr=0.0196 | 13485.7 samples/s | 52.7 steps/s
Avg test loss: 0.10881, Avg test acc: 0.97918, Avg tpr: 0.91244, Avg fpr: 0.01960, total FA: 2722

server round 5/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=48.8] | Loss=0.02925 | Reg=0.00458 | acc=0.9844 | L2-Norm=21.408 | L2-Norm(final)=5.175 | 5496.5 samples/s | 85.9 steps/s
[Step=10050 Epoch=49.0] | Loss=0.05311 | Reg=0.00460 | acc=1.0000 | L2-Norm=21.443 | L2-Norm(final)=5.236 | 4809.5 samples/s | 75.1 steps/s
[Step=10100 Epoch=49.2] | Loss=0.04955 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.498 | L2-Norm(final)=5.287 | 5083.8 samples/s | 79.4 steps/s
[Step=10150 Epoch=49.5] | Loss=0.05020 | Reg=0.00464 | acc=0.9375 | L2-Norm=21.550 | L2-Norm(final)=5.327 | 5009.6 samples/s | 78.3 steps/s
[Step=10200 Epoch=49.7] | Loss=0.05042 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.600 | L2-Norm(final)=5.365 | 7808.1 samples/s | 122.0 steps/s
[Step=10250 Epoch=50.0] | Loss=0.04800 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.653 | L2-Norm(final)=5.407 | 2237.3 samples/s | 35.0 steps/s
[Step=10300 Epoch=50.2] | Loss=0.04685 | Reg=0.00471 | acc=0.9688 | L2-Norm=21.705 | L2-Norm(final)=5.452 | 5092.2 samples/s | 79.6 steps/s
[Step=10350 Epoch=50.5] | Loss=0.04534 | Reg=0.00473 | acc=0.9375 | L2-Norm=21.756 | L2-Norm(final)=5.503 | 5041.3 samples/s | 78.8 steps/s
[Step=10400 Epoch=50.7] | Loss=0.04421 | Reg=0.00476 | acc=0.9531 | L2-Norm=21.807 | L2-Norm(final)=5.554 | 6965.0 samples/s | 108.8 steps/s
[Step=10450 Epoch=51.0] | Loss=0.04274 | Reg=0.00478 | acc=0.9844 | L2-Norm=21.858 | L2-Norm(final)=5.605 | 2292.4 samples/s | 35.8 steps/s
[Step=10500 Epoch=51.2] | Loss=0.04144 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.908 | L2-Norm(final)=5.657 | 5078.1 samples/s | 79.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=51.2] | Loss=0.05268 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.409 | L2-Norm(final)=6.188 | 5806.5 samples/s | 90.7 steps/s
[Step=10550 Epoch=51.4] | Loss=0.05533 | Reg=0.00505 | acc=0.9688 | L2-Norm=22.468 | L2-Norm(final)=6.207 | 3953.5 samples/s | 61.8 steps/s
[Step=10600 Epoch=51.7] | Loss=0.06045 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.539 | L2-Norm(final)=6.185 | 4514.8 samples/s | 70.5 steps/s
[Step=10650 Epoch=51.9] | Loss=0.05996 | Reg=0.00511 | acc=0.9688 | L2-Norm=22.599 | L2-Norm(final)=6.159 | 4489.5 samples/s | 70.1 steps/s
[Step=10700 Epoch=52.2] | Loss=0.05939 | Reg=0.00513 | acc=0.9062 | L2-Norm=22.652 | L2-Norm(final)=6.135 | 6425.2 samples/s | 100.4 steps/s
[Step=10750 Epoch=52.4] | Loss=0.06280 | Reg=0.00516 | acc=0.9062 | L2-Norm=22.713 | L2-Norm(final)=6.111 | 2084.4 samples/s | 32.6 steps/s
[Step=10800 Epoch=52.7] | Loss=0.06033 | Reg=0.00519 | acc=0.9844 | L2-Norm=22.773 | L2-Norm(final)=6.090 | 4414.7 samples/s | 69.0 steps/s
[Step=10850 Epoch=52.9] | Loss=0.05811 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.821 | L2-Norm(final)=6.072 | 4479.5 samples/s | 70.0 steps/s
[Step=10900 Epoch=53.2] | Loss=0.05603 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.861 | L2-Norm(final)=6.058 | 5891.5 samples/s | 92.1 steps/s
[Step=10950 Epoch=53.4] | Loss=0.05241 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.894 | L2-Norm(final)=6.046 | 2174.5 samples/s | 34.0 steps/s
[Step=11000 Epoch=53.6] | Loss=0.04918 | Reg=0.00525 | acc=0.9375 | L2-Norm=22.919 | L2-Norm(final)=6.037 | 4569.6 samples/s | 71.4 steps/s
[Step=11050 Epoch=53.9] | Loss=0.04638 | Reg=0.00526 | acc=0.9844 | L2-Norm=22.937 | L2-Norm(final)=6.030 | 4366.0 samples/s | 68.2 steps/s
[Step=11100 Epoch=54.1] | Loss=0.04420 | Reg=0.00527 | acc=0.9531 | L2-Norm=22.952 | L2-Norm(final)=6.024 | 5397.9 samples/s | 84.3 steps/s
[Step=11150 Epoch=54.4] | Loss=0.04225 | Reg=0.00527 | acc=0.9844 | L2-Norm=22.965 | L2-Norm(final)=6.020 | 2236.5 samples/s | 34.9 steps/s
[Step=11200 Epoch=54.6] | Loss=0.04050 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.976 | L2-Norm(final)=6.016 | 4473.5 samples/s | 69.9 steps/s
[Step=11250 Epoch=54.9] | Loss=0.03909 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.983 | L2-Norm(final)=6.012 | 4488.9 samples/s | 70.1 steps/s
[Step=11300 Epoch=55.1] | Loss=0.03774 | Reg=0.00529 | acc=1.0000 | L2-Norm=22.990 | L2-Norm(final)=6.008 | 4989.7 samples/s | 78.0 steps/s
[Step=11350 Epoch=55.3] | Loss=0.03702 | Reg=0.00529 | acc=0.9844 | L2-Norm=22.997 | L2-Norm(final)=6.005 | 2335.9 samples/s | 36.5 steps/s
[Step=11400 Epoch=55.6] | Loss=0.03618 | Reg=0.00529 | acc=0.9688 | L2-Norm=23.006 | L2-Norm(final)=6.001 | 4509.7 samples/s | 70.5 steps/s
[Step=11450 Epoch=55.8] | Loss=0.03505 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.015 | L2-Norm(final)=5.998 | 4507.4 samples/s | 70.4 steps/s
[Step=11500 Epoch=56.1] | Loss=0.03417 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.022 | L2-Norm(final)=5.995 | 4496.8 samples/s | 70.3 steps/s
[Step=11550 Epoch=56.3] | Loss=0.03307 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.027 | L2-Norm(final)=5.993 | 2419.7 samples/s | 37.8 steps/s
[Step=11600 Epoch=56.6] | Loss=0.03203 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.031 | L2-Norm(final)=5.991 | 4446.7 samples/s | 69.5 steps/s
[Step=11650 Epoch=56.8] | Loss=0.03119 | Reg=0.00531 | acc=0.9531 | L2-Norm=23.034 | L2-Norm(final)=5.990 | 4496.9 samples/s | 70.3 steps/s
[Step=11700 Epoch=57.1] | Loss=0.03029 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.036 | L2-Norm(final)=5.989 | 4532.5 samples/s | 70.8 steps/s
[Step=11750 Epoch=57.3] | Loss=0.02957 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.036 | L2-Norm(final)=5.987 | 2438.0 samples/s | 38.1 steps/s
[Step=11800 Epoch=57.5] | Loss=0.02874 | Reg=0.00531 | acc=0.9844 | L2-Norm=23.036 | L2-Norm(final)=5.987 | 4491.0 samples/s | 70.2 steps/s
[Step=11850 Epoch=57.8] | Loss=0.02803 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.035 | L2-Norm(final)=5.986 | 4363.8 samples/s | 68.2 steps/s
[Step=11900 Epoch=58.0] | Loss=0.02745 | Reg=0.00531 | acc=0.9844 | L2-Norm=23.034 | L2-Norm(final)=5.986 | 4478.7 samples/s | 70.0 steps/s
[Step=11950 Epoch=58.3] | Loss=0.02692 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.032 | L2-Norm(final)=5.986 | 2446.7 samples/s | 38.2 steps/s
[Step=12000 Epoch=58.5] | Loss=0.02627 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.031 | L2-Norm(final)=5.986 | 4462.9 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step12000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=48.8] | Loss=0.06034 | Reg=0.00445 | acc=0.9375 | L2-Norm=21.098 | L2-Norm(final)=5.211 | 5132.8 samples/s | 80.2 steps/s
[Step=10050 Epoch=49.0] | Loss=0.05339 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.124 | L2-Norm(final)=5.252 | 4374.4 samples/s | 68.3 steps/s
[Step=10100 Epoch=49.3] | Loss=0.05159 | Reg=0.00448 | acc=0.9688 | L2-Norm=21.165 | L2-Norm(final)=5.298 | 5049.5 samples/s | 78.9 steps/s
[Step=10150 Epoch=49.5] | Loss=0.05044 | Reg=0.00450 | acc=0.9219 | L2-Norm=21.210 | L2-Norm(final)=5.339 | 4972.8 samples/s | 77.7 steps/s
[Step=10200 Epoch=49.8] | Loss=0.04889 | Reg=0.00452 | acc=0.9688 | L2-Norm=21.259 | L2-Norm(final)=5.383 | 7790.6 samples/s | 121.7 steps/s
[Step=10250 Epoch=50.0] | Loss=0.04726 | Reg=0.00454 | acc=0.9531 | L2-Norm=21.311 | L2-Norm(final)=5.429 | 2222.0 samples/s | 34.7 steps/s
[Step=10300 Epoch=50.3] | Loss=0.04571 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.363 | L2-Norm(final)=5.480 | 4928.9 samples/s | 77.0 steps/s
[Step=10350 Epoch=50.5] | Loss=0.04434 | Reg=0.00459 | acc=0.9844 | L2-Norm=21.414 | L2-Norm(final)=5.529 | 5196.5 samples/s | 81.2 steps/s
[Step=10400 Epoch=50.7] | Loss=0.04338 | Reg=0.00461 | acc=0.9844 | L2-Norm=21.464 | L2-Norm(final)=5.580 | 6903.6 samples/s | 107.9 steps/s
[Step=10450 Epoch=51.0] | Loss=0.04215 | Reg=0.00463 | acc=0.9688 | L2-Norm=21.514 | L2-Norm(final)=5.630 | 2262.0 samples/s | 35.3 steps/s
[Step=10500 Epoch=51.2] | Loss=0.04099 | Reg=0.00465 | acc=0.9844 | L2-Norm=21.565 | L2-Norm(final)=5.683 | 5129.9 samples/s | 80.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=51.2] | Loss=0.01048 | Reg=0.00487 | acc=1.0000 | L2-Norm=22.074 | L2-Norm(final)=6.218 | 4921.4 samples/s | 76.9 steps/s
[Step=10550 Epoch=51.5] | Loss=0.05424 | Reg=0.00491 | acc=0.9531 | L2-Norm=22.154 | L2-Norm(final)=6.240 | 4345.3 samples/s | 67.9 steps/s
[Step=10600 Epoch=51.7] | Loss=0.06807 | Reg=0.00495 | acc=0.9531 | L2-Norm=22.250 | L2-Norm(final)=6.217 | 4460.6 samples/s | 69.7 steps/s
[Step=10650 Epoch=52.0] | Loss=0.06600 | Reg=0.00499 | acc=0.8750 | L2-Norm=22.334 | L2-Norm(final)=6.192 | 4481.6 samples/s | 70.0 steps/s
[Step=10700 Epoch=52.2] | Loss=0.06416 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.395 | L2-Norm(final)=6.169 | 6580.4 samples/s | 102.8 steps/s
[Step=10750 Epoch=52.5] | Loss=0.05908 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.445 | L2-Norm(final)=6.156 | 2074.2 samples/s | 32.4 steps/s
[Step=10800 Epoch=52.7] | Loss=0.05528 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.484 | L2-Norm(final)=6.145 | 4424.8 samples/s | 69.1 steps/s
[Step=10850 Epoch=52.9] | Loss=0.05244 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.516 | L2-Norm(final)=6.137 | 4391.2 samples/s | 68.6 steps/s
[Step=10900 Epoch=53.2] | Loss=0.04912 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.545 | L2-Norm(final)=6.131 | 5999.9 samples/s | 93.7 steps/s
[Step=10950 Epoch=53.4] | Loss=0.04564 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.570 | L2-Norm(final)=6.128 | 2125.7 samples/s | 33.2 steps/s
[Step=11000 Epoch=53.7] | Loss=0.04331 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.590 | L2-Norm(final)=6.125 | 4477.8 samples/s | 70.0 steps/s
[Step=11050 Epoch=53.9] | Loss=0.04141 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.609 | L2-Norm(final)=6.122 | 4475.4 samples/s | 69.9 steps/s
[Step=11100 Epoch=54.2] | Loss=0.04006 | Reg=0.00512 | acc=0.9844 | L2-Norm=22.626 | L2-Norm(final)=6.120 | 5606.6 samples/s | 87.6 steps/s
[Step=11150 Epoch=54.4] | Loss=0.03847 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.640 | L2-Norm(final)=6.117 | 2189.3 samples/s | 34.2 steps/s
[Step=11200 Epoch=54.7] | Loss=0.03669 | Reg=0.00513 | acc=0.9688 | L2-Norm=22.653 | L2-Norm(final)=6.116 | 4383.0 samples/s | 68.5 steps/s
[Step=11250 Epoch=54.9] | Loss=0.03527 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.663 | L2-Norm(final)=6.114 | 4513.7 samples/s | 70.5 steps/s
[Step=11300 Epoch=55.1] | Loss=0.03388 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.672 | L2-Norm(final)=6.114 | 5139.0 samples/s | 80.3 steps/s
[Step=11350 Epoch=55.4] | Loss=0.03260 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.679 | L2-Norm(final)=6.114 | 2311.3 samples/s | 36.1 steps/s
[Step=11400 Epoch=55.6] | Loss=0.03145 | Reg=0.00515 | acc=0.9688 | L2-Norm=22.684 | L2-Norm(final)=6.114 | 4444.8 samples/s | 69.5 steps/s
[Step=11450 Epoch=55.9] | Loss=0.03057 | Reg=0.00515 | acc=1.0000 | L2-Norm=22.689 | L2-Norm(final)=6.113 | 4464.3 samples/s | 69.8 steps/s
[Step=11500 Epoch=56.1] | Loss=0.02992 | Reg=0.00515 | acc=0.9844 | L2-Norm=22.692 | L2-Norm(final)=6.113 | 4804.1 samples/s | 75.1 steps/s
[Step=11550 Epoch=56.4] | Loss=0.02931 | Reg=0.00515 | acc=1.0000 | L2-Norm=22.696 | L2-Norm(final)=6.112 | 2334.5 samples/s | 36.5 steps/s
[Step=11600 Epoch=56.6] | Loss=0.02860 | Reg=0.00515 | acc=1.0000 | L2-Norm=22.701 | L2-Norm(final)=6.111 | 4570.0 samples/s | 71.4 steps/s
[Step=11650 Epoch=56.8] | Loss=0.02778 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.705 | L2-Norm(final)=6.111 | 4403.4 samples/s | 68.8 steps/s
[Step=11700 Epoch=57.1] | Loss=0.02718 | Reg=0.00516 | acc=0.9844 | L2-Norm=22.709 | L2-Norm(final)=6.111 | 4552.5 samples/s | 71.1 steps/s
[Step=11750 Epoch=57.3] | Loss=0.02667 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.712 | L2-Norm(final)=6.111 | 2409.5 samples/s | 37.6 steps/s
[Step=11800 Epoch=57.6] | Loss=0.02608 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.716 | L2-Norm(final)=6.111 | 4516.2 samples/s | 70.6 steps/s
[Step=11850 Epoch=57.8] | Loss=0.02562 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.719 | L2-Norm(final)=6.112 | 4449.4 samples/s | 69.5 steps/s
[Step=11900 Epoch=58.1] | Loss=0.02516 | Reg=0.00516 | acc=0.9688 | L2-Norm=22.723 | L2-Norm(final)=6.112 | 4395.2 samples/s | 68.7 steps/s
[Step=11950 Epoch=58.3] | Loss=0.02471 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.726 | L2-Norm(final)=6.113 | 2452.7 samples/s | 38.3 steps/s
[Step=12000 Epoch=58.6] | Loss=0.02426 | Reg=0.00517 | acc=1.0000 | L2-Norm=22.728 | L2-Norm(final)=6.113 | 4473.0 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step12000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=48.7] | Loss=0.06950 | Reg=0.00455 | acc=0.9375 | L2-Norm=21.336 | L2-Norm(final)=5.495 | 5228.7 samples/s | 81.7 steps/s
[Step=10050 Epoch=49.0] | Loss=0.05386 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.355 | L2-Norm(final)=5.524 | 2805.3 samples/s | 43.8 steps/s
[Step=10100 Epoch=49.2] | Loss=0.05136 | Reg=0.00458 | acc=0.9531 | L2-Norm=21.390 | L2-Norm(final)=5.563 | 5022.0 samples/s | 78.5 steps/s
[Step=10150 Epoch=49.5] | Loss=0.05031 | Reg=0.00460 | acc=0.9688 | L2-Norm=21.436 | L2-Norm(final)=5.603 | 4895.7 samples/s | 76.5 steps/s
[Step=10200 Epoch=49.7] | Loss=0.04978 | Reg=0.00462 | acc=1.0000 | L2-Norm=21.486 | L2-Norm(final)=5.643 | 7370.8 samples/s | 115.2 steps/s
[Step=10250 Epoch=49.9] | Loss=0.04864 | Reg=0.00464 | acc=0.9531 | L2-Norm=21.536 | L2-Norm(final)=5.686 | 2151.9 samples/s | 33.6 steps/s
[Step=10300 Epoch=50.2] | Loss=0.04732 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.587 | L2-Norm(final)=5.729 | 4941.8 samples/s | 77.2 steps/s
[Step=10350 Epoch=50.4] | Loss=0.04644 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.636 | L2-Norm(final)=5.775 | 5052.4 samples/s | 78.9 steps/s
[Step=10400 Epoch=50.7] | Loss=0.04516 | Reg=0.00470 | acc=0.9531 | L2-Norm=21.685 | L2-Norm(final)=5.822 | 7028.1 samples/s | 109.8 steps/s
[Step=10450 Epoch=50.9] | Loss=0.04422 | Reg=0.00473 | acc=0.9688 | L2-Norm=21.736 | L2-Norm(final)=5.872 | 2313.2 samples/s | 36.1 steps/s
[Step=10500 Epoch=51.2] | Loss=0.04280 | Reg=0.00475 | acc=0.9531 | L2-Norm=21.787 | L2-Norm(final)=5.923 | 5032.3 samples/s | 78.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=51.2] | Loss=0.01189 | Reg=0.00497 | acc=1.0000 | L2-Norm=22.286 | L2-Norm(final)=6.448 | 5267.6 samples/s | 82.3 steps/s
[Step=10550 Epoch=51.4] | Loss=0.06221 | Reg=0.00500 | acc=0.9062 | L2-Norm=22.358 | L2-Norm(final)=6.461 | 4105.4 samples/s | 64.1 steps/s
[Step=10600 Epoch=51.6] | Loss=0.06429 | Reg=0.00504 | acc=0.9375 | L2-Norm=22.459 | L2-Norm(final)=6.440 | 4395.7 samples/s | 68.7 steps/s
[Step=10650 Epoch=51.9] | Loss=0.06122 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.533 | L2-Norm(final)=6.419 | 4476.7 samples/s | 69.9 steps/s
[Step=10700 Epoch=52.1] | Loss=0.06270 | Reg=0.00510 | acc=0.9688 | L2-Norm=22.594 | L2-Norm(final)=6.401 | 6591.7 samples/s | 103.0 steps/s
[Step=10750 Epoch=52.4] | Loss=0.05787 | Reg=0.00513 | acc=0.9844 | L2-Norm=22.645 | L2-Norm(final)=6.386 | 2123.1 samples/s | 33.2 steps/s
[Step=10800 Epoch=52.6] | Loss=0.05351 | Reg=0.00515 | acc=0.9688 | L2-Norm=22.685 | L2-Norm(final)=6.374 | 4504.8 samples/s | 70.4 steps/s
[Step=10850 Epoch=52.9] | Loss=0.05190 | Reg=0.00516 | acc=0.9688 | L2-Norm=22.717 | L2-Norm(final)=6.365 | 4484.8 samples/s | 70.1 steps/s
[Step=10900 Epoch=53.1] | Loss=0.04973 | Reg=0.00517 | acc=0.9688 | L2-Norm=22.744 | L2-Norm(final)=6.358 | 5820.7 samples/s | 90.9 steps/s
[Step=10950 Epoch=53.4] | Loss=0.04650 | Reg=0.00518 | acc=0.9844 | L2-Norm=22.767 | L2-Norm(final)=6.352 | 2107.8 samples/s | 32.9 steps/s
[Step=11000 Epoch=53.6] | Loss=0.04417 | Reg=0.00519 | acc=0.9844 | L2-Norm=22.786 | L2-Norm(final)=6.348 | 4594.7 samples/s | 71.8 steps/s
[Step=11050 Epoch=53.8] | Loss=0.04242 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.803 | L2-Norm(final)=6.345 | 4470.4 samples/s | 69.8 steps/s
[Step=11100 Epoch=54.1] | Loss=0.04138 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.817 | L2-Norm(final)=6.342 | 5299.9 samples/s | 82.8 steps/s
[Step=11150 Epoch=54.3] | Loss=0.03967 | Reg=0.00521 | acc=1.0000 | L2-Norm=22.831 | L2-Norm(final)=6.340 | 2246.9 samples/s | 35.1 steps/s
[Step=11200 Epoch=54.6] | Loss=0.03802 | Reg=0.00522 | acc=0.9531 | L2-Norm=22.843 | L2-Norm(final)=6.338 | 4494.0 samples/s | 70.2 steps/s
[Step=11250 Epoch=54.8] | Loss=0.03682 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.854 | L2-Norm(final)=6.337 | 4369.5 samples/s | 68.3 steps/s
[Step=11300 Epoch=55.1] | Loss=0.03542 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.864 | L2-Norm(final)=6.336 | 4999.2 samples/s | 78.1 steps/s
[Step=11350 Epoch=55.3] | Loss=0.03425 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.871 | L2-Norm(final)=6.335 | 2361.2 samples/s | 36.9 steps/s
[Step=11400 Epoch=55.5] | Loss=0.03332 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.877 | L2-Norm(final)=6.333 | 4490.2 samples/s | 70.2 steps/s
[Step=11450 Epoch=55.8] | Loss=0.03236 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.883 | L2-Norm(final)=6.332 | 4513.9 samples/s | 70.5 steps/s
[Step=11500 Epoch=56.0] | Loss=0.03158 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.887 | L2-Norm(final)=6.332 | 4585.3 samples/s | 71.6 steps/s
[Step=11550 Epoch=56.3] | Loss=0.03060 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.890 | L2-Norm(final)=6.331 | 2455.0 samples/s | 38.4 steps/s
[Step=11600 Epoch=56.5] | Loss=0.02971 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.893 | L2-Norm(final)=6.331 | 4408.3 samples/s | 68.9 steps/s
[Step=11650 Epoch=56.8] | Loss=0.02894 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.894 | L2-Norm(final)=6.332 | 4429.4 samples/s | 69.2 steps/s
[Step=11700 Epoch=57.0] | Loss=0.02833 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.895 | L2-Norm(final)=6.332 | 4489.1 samples/s | 70.1 steps/s
[Step=11750 Epoch=57.3] | Loss=0.02789 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.896 | L2-Norm(final)=6.332 | 2489.7 samples/s | 38.9 steps/s
[Step=11800 Epoch=57.5] | Loss=0.02720 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.897 | L2-Norm(final)=6.332 | 4484.3 samples/s | 70.1 steps/s
[Step=11850 Epoch=57.7] | Loss=0.02654 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.896 | L2-Norm(final)=6.332 | 4496.5 samples/s | 70.3 steps/s
[Step=11900 Epoch=58.0] | Loss=0.02610 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.895 | L2-Norm(final)=6.332 | 4500.3 samples/s | 70.3 steps/s
[Step=11950 Epoch=58.2] | Loss=0.02550 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.894 | L2-Norm(final)=6.332 | 2416.4 samples/s | 37.8 steps/s
[Step=12000 Epoch=58.5] | Loss=0.02480 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.892 | L2-Norm(final)=6.333 | 4462.3 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step12000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=48.8] | Loss=0.06187 | Reg=0.00453 | acc=0.9688 | L2-Norm=21.292 | L2-Norm(final)=5.275 | 4825.5 samples/s | 75.4 steps/s
[Step=10050 Epoch=49.0] | Loss=0.05184 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.312 | L2-Norm(final)=5.300 | 4693.4 samples/s | 73.3 steps/s
[Step=10100 Epoch=49.3] | Loss=0.04789 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.344 | L2-Norm(final)=5.337 | 5040.4 samples/s | 78.8 steps/s
[Step=10150 Epoch=49.5] | Loss=0.04879 | Reg=0.00457 | acc=0.9688 | L2-Norm=21.379 | L2-Norm(final)=5.375 | 5080.7 samples/s | 79.4 steps/s
[Step=10200 Epoch=49.7] | Loss=0.04818 | Reg=0.00459 | acc=0.9531 | L2-Norm=21.418 | L2-Norm(final)=5.416 | 7743.8 samples/s | 121.0 steps/s
[Step=10250 Epoch=50.0] | Loss=0.04621 | Reg=0.00460 | acc=0.9688 | L2-Norm=21.458 | L2-Norm(final)=5.460 | 2212.0 samples/s | 34.6 steps/s
[Step=10300 Epoch=50.2] | Loss=0.04446 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.499 | L2-Norm(final)=5.507 | 5232.3 samples/s | 81.8 steps/s
[Step=10350 Epoch=50.5] | Loss=0.04396 | Reg=0.00464 | acc=0.9688 | L2-Norm=21.541 | L2-Norm(final)=5.553 | 4869.3 samples/s | 76.1 steps/s
[Step=10400 Epoch=50.7] | Loss=0.04309 | Reg=0.00466 | acc=0.9688 | L2-Norm=21.583 | L2-Norm(final)=5.600 | 7000.4 samples/s | 109.4 steps/s
[Step=10450 Epoch=51.0] | Loss=0.04158 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.626 | L2-Norm(final)=5.650 | 2321.0 samples/s | 36.3 steps/s
[Step=10500 Epoch=51.2] | Loss=0.04037 | Reg=0.00470 | acc=0.9375 | L2-Norm=21.667 | L2-Norm(final)=5.701 | 4982.3 samples/s | 77.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=51.2] | Loss=0.01449 | Reg=0.00487 | acc=1.0000 | L2-Norm=22.079 | L2-Norm(final)=6.220 | 5691.8 samples/s | 88.9 steps/s
[Step=10550 Epoch=51.4] | Loss=0.04533 | Reg=0.00490 | acc=0.9062 | L2-Norm=22.132 | L2-Norm(final)=6.249 | 3835.6 samples/s | 59.9 steps/s
[Step=10600 Epoch=51.7] | Loss=0.05373 | Reg=0.00493 | acc=0.9844 | L2-Norm=22.195 | L2-Norm(final)=6.231 | 4395.8 samples/s | 68.7 steps/s
[Step=10650 Epoch=51.9] | Loss=0.05583 | Reg=0.00495 | acc=0.9375 | L2-Norm=22.254 | L2-Norm(final)=6.212 | 4449.3 samples/s | 69.5 steps/s
[Step=10700 Epoch=52.2] | Loss=0.05549 | Reg=0.00498 | acc=0.9688 | L2-Norm=22.305 | L2-Norm(final)=6.195 | 6586.8 samples/s | 102.9 steps/s
[Step=10750 Epoch=52.4] | Loss=0.05158 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.349 | L2-Norm(final)=6.183 | 2104.7 samples/s | 32.9 steps/s
[Step=10800 Epoch=52.7] | Loss=0.04842 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.383 | L2-Norm(final)=6.174 | 4642.2 samples/s | 72.5 steps/s
[Step=10850 Epoch=52.9] | Loss=0.04535 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.410 | L2-Norm(final)=6.167 | 4334.2 samples/s | 67.7 steps/s
[Step=10900 Epoch=53.2] | Loss=0.04476 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.433 | L2-Norm(final)=6.159 | 5940.3 samples/s | 92.8 steps/s
[Step=10950 Epoch=53.4] | Loss=0.04173 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.454 | L2-Norm(final)=6.152 | 2135.1 samples/s | 33.4 steps/s
[Step=11000 Epoch=53.6] | Loss=0.04008 | Reg=0.00505 | acc=0.9375 | L2-Norm=22.471 | L2-Norm(final)=6.148 | 4486.5 samples/s | 70.1 steps/s
[Step=11050 Epoch=53.9] | Loss=0.03834 | Reg=0.00506 | acc=0.9375 | L2-Norm=22.488 | L2-Norm(final)=6.145 | 4527.5 samples/s | 70.7 steps/s
[Step=11100 Epoch=54.1] | Loss=0.03686 | Reg=0.00506 | acc=0.9688 | L2-Norm=22.502 | L2-Norm(final)=6.142 | 5364.1 samples/s | 83.8 steps/s
[Step=11150 Epoch=54.4] | Loss=0.03502 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.514 | L2-Norm(final)=6.140 | 2263.9 samples/s | 35.4 steps/s
[Step=11200 Epoch=54.6] | Loss=0.03337 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.523 | L2-Norm(final)=6.139 | 4494.8 samples/s | 70.2 steps/s
[Step=11250 Epoch=54.9] | Loss=0.03200 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.530 | L2-Norm(final)=6.139 | 4467.5 samples/s | 69.8 steps/s
[Step=11300 Epoch=55.1] | Loss=0.03063 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.534 | L2-Norm(final)=6.138 | 4850.0 samples/s | 75.8 steps/s
[Step=11350 Epoch=55.3] | Loss=0.02953 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.536 | L2-Norm(final)=6.139 | 2271.7 samples/s | 35.5 steps/s
[Step=11400 Epoch=55.6] | Loss=0.02839 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.536 | L2-Norm(final)=6.139 | 4584.5 samples/s | 71.6 steps/s
[Step=11450 Epoch=55.8] | Loss=0.02746 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.535 | L2-Norm(final)=6.139 | 4388.1 samples/s | 68.6 steps/s
[Step=11500 Epoch=56.1] | Loss=0.02663 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.533 | L2-Norm(final)=6.139 | 4610.3 samples/s | 72.0 steps/s
[Step=11550 Epoch=56.3] | Loss=0.02583 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.530 | L2-Norm(final)=6.139 | 2441.8 samples/s | 38.2 steps/s
[Step=11600 Epoch=56.6] | Loss=0.02523 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.527 | L2-Norm(final)=6.140 | 4507.4 samples/s | 70.4 steps/s
[Step=11650 Epoch=56.8] | Loss=0.02456 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.524 | L2-Norm(final)=6.141 | 4430.3 samples/s | 69.2 steps/s
[Step=11700 Epoch=57.1] | Loss=0.02412 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.521 | L2-Norm(final)=6.142 | 4412.6 samples/s | 68.9 steps/s
[Step=11750 Epoch=57.3] | Loss=0.02408 | Reg=0.00507 | acc=0.9688 | L2-Norm=22.520 | L2-Norm(final)=6.142 | 2467.8 samples/s | 38.6 steps/s
[Step=11800 Epoch=57.5] | Loss=0.02377 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.522 | L2-Norm(final)=6.142 | 4523.0 samples/s | 70.7 steps/s
[Step=11850 Epoch=57.8] | Loss=0.02349 | Reg=0.00507 | acc=0.9688 | L2-Norm=22.524 | L2-Norm(final)=6.142 | 4519.9 samples/s | 70.6 steps/s
[Step=11900 Epoch=58.0] | Loss=0.02332 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.528 | L2-Norm(final)=6.143 | 4456.0 samples/s | 69.6 steps/s
[Step=11950 Epoch=58.3] | Loss=0.02326 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.532 | L2-Norm(final)=6.143 | 2485.7 samples/s | 38.8 steps/s
[Step=12000 Epoch=58.5] | Loss=0.02312 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.536 | L2-Norm(final)=6.143 | 4381.6 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step12000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=49.0] | Loss=0.04527 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.610 | L2-Norm(final)=5.854 | 5414.5 samples/s | 84.6 steps/s
[Step=10050 Epoch=49.3] | Loss=0.05173 | Reg=0.00468 | acc=0.9375 | L2-Norm=21.636 | L2-Norm(final)=5.892 | 4427.9 samples/s | 69.2 steps/s
[Step=10100 Epoch=49.5] | Loss=0.04911 | Reg=0.00470 | acc=0.9531 | L2-Norm=21.674 | L2-Norm(final)=5.931 | 5041.6 samples/s | 78.8 steps/s
[Step=10150 Epoch=49.8] | Loss=0.04740 | Reg=0.00471 | acc=0.9375 | L2-Norm=21.710 | L2-Norm(final)=5.967 | 5073.0 samples/s | 79.3 steps/s
[Step=10200 Epoch=50.0] | Loss=0.04709 | Reg=0.00473 | acc=0.9531 | L2-Norm=21.747 | L2-Norm(final)=5.997 | 8092.7 samples/s | 126.4 steps/s
[Step=10250 Epoch=50.3] | Loss=0.04527 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.785 | L2-Norm(final)=6.029 | 2207.2 samples/s | 34.5 steps/s
[Step=10300 Epoch=50.5] | Loss=0.04423 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.823 | L2-Norm(final)=6.066 | 5185.6 samples/s | 81.0 steps/s
[Step=10350 Epoch=50.8] | Loss=0.04270 | Reg=0.00478 | acc=0.9688 | L2-Norm=21.862 | L2-Norm(final)=6.107 | 4752.6 samples/s | 74.3 steps/s
[Step=10400 Epoch=51.0] | Loss=0.04161 | Reg=0.00480 | acc=0.9688 | L2-Norm=21.899 | L2-Norm(final)=6.150 | 7387.5 samples/s | 115.4 steps/s
[Step=10450 Epoch=51.2] | Loss=0.04034 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.937 | L2-Norm(final)=6.194 | 2257.9 samples/s | 35.3 steps/s
[Step=10500 Epoch=51.5] | Loss=0.03911 | Reg=0.00483 | acc=1.0000 | L2-Norm=21.975 | L2-Norm(final)=6.241 | 5081.5 samples/s | 79.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=51.5] | Loss=0.01716 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.365 | L2-Norm(final)=6.710 | 5723.5 samples/s | 89.4 steps/s
[Step=10550 Epoch=51.7] | Loss=0.04967 | Reg=0.00503 | acc=0.9688 | L2-Norm=22.429 | L2-Norm(final)=6.723 | 4008.8 samples/s | 62.6 steps/s
[Step=10600 Epoch=52.0] | Loss=0.05928 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.503 | L2-Norm(final)=6.691 | 4460.8 samples/s | 69.7 steps/s
[Step=10650 Epoch=52.2] | Loss=0.05885 | Reg=0.00509 | acc=0.9219 | L2-Norm=22.569 | L2-Norm(final)=6.668 | 4562.3 samples/s | 71.3 steps/s
[Step=10700 Epoch=52.5] | Loss=0.05858 | Reg=0.00512 | acc=0.9844 | L2-Norm=22.626 | L2-Norm(final)=6.652 | 6518.2 samples/s | 101.8 steps/s
[Step=10750 Epoch=52.7] | Loss=0.05296 | Reg=0.00514 | acc=0.9844 | L2-Norm=22.674 | L2-Norm(final)=6.640 | 2036.3 samples/s | 31.8 steps/s
[Step=10800 Epoch=53.0] | Loss=0.04858 | Reg=0.00516 | acc=0.9844 | L2-Norm=22.710 | L2-Norm(final)=6.633 | 4483.7 samples/s | 70.1 steps/s
[Step=10850 Epoch=53.2] | Loss=0.04544 | Reg=0.00517 | acc=0.9844 | L2-Norm=22.740 | L2-Norm(final)=6.628 | 4500.9 samples/s | 70.3 steps/s
[Step=10900 Epoch=53.5] | Loss=0.04433 | Reg=0.00518 | acc=0.9844 | L2-Norm=22.766 | L2-Norm(final)=6.623 | 6224.3 samples/s | 97.3 steps/s
[Step=10950 Epoch=53.7] | Loss=0.04222 | Reg=0.00519 | acc=0.9375 | L2-Norm=22.788 | L2-Norm(final)=6.619 | 2114.2 samples/s | 33.0 steps/s
[Step=11000 Epoch=53.9] | Loss=0.04087 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.808 | L2-Norm(final)=6.615 | 4422.8 samples/s | 69.1 steps/s
[Step=11050 Epoch=54.2] | Loss=0.03862 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.825 | L2-Norm(final)=6.611 | 4397.1 samples/s | 68.7 steps/s
[Step=11100 Epoch=54.4] | Loss=0.03704 | Reg=0.00522 | acc=0.9688 | L2-Norm=22.840 | L2-Norm(final)=6.609 | 5858.6 samples/s | 91.5 steps/s
[Step=11150 Epoch=54.7] | Loss=0.03533 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.853 | L2-Norm(final)=6.607 | 2180.8 samples/s | 34.1 steps/s
[Step=11200 Epoch=54.9] | Loss=0.03356 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.863 | L2-Norm(final)=6.606 | 4497.7 samples/s | 70.3 steps/s
[Step=11250 Epoch=55.2] | Loss=0.03234 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.871 | L2-Norm(final)=6.605 | 4514.0 samples/s | 70.5 steps/s
[Step=11300 Epoch=55.4] | Loss=0.03126 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.877 | L2-Norm(final)=6.605 | 5483.1 samples/s | 85.7 steps/s
[Step=11350 Epoch=55.7] | Loss=0.02999 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.883 | L2-Norm(final)=6.605 | 2227.2 samples/s | 34.8 steps/s
[Step=11400 Epoch=55.9] | Loss=0.02887 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.887 | L2-Norm(final)=6.606 | 4493.0 samples/s | 70.2 steps/s
[Step=11450 Epoch=56.1] | Loss=0.02804 | Reg=0.00524 | acc=0.9688 | L2-Norm=22.889 | L2-Norm(final)=6.607 | 4459.1 samples/s | 69.7 steps/s
[Step=11500 Epoch=56.4] | Loss=0.02708 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.890 | L2-Norm(final)=6.608 | 5145.7 samples/s | 80.4 steps/s
[Step=11550 Epoch=56.6] | Loss=0.02611 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.889 | L2-Norm(final)=6.609 | 2273.4 samples/s | 35.5 steps/s
[Step=11600 Epoch=56.9] | Loss=0.02532 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.887 | L2-Norm(final)=6.611 | 4529.9 samples/s | 70.8 steps/s
[Step=11650 Epoch=57.1] | Loss=0.02479 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.884 | L2-Norm(final)=6.612 | 4478.7 samples/s | 70.0 steps/s
[Step=11700 Epoch=57.4] | Loss=0.02420 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.882 | L2-Norm(final)=6.613 | 4901.7 samples/s | 76.6 steps/s
[Step=11750 Epoch=57.6] | Loss=0.02363 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.879 | L2-Norm(final)=6.614 | 2306.4 samples/s | 36.0 steps/s
[Step=11800 Epoch=57.9] | Loss=0.02298 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.876 | L2-Norm(final)=6.615 | 4461.6 samples/s | 69.7 steps/s
[Step=11850 Epoch=58.1] | Loss=0.02257 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.873 | L2-Norm(final)=6.617 | 4610.5 samples/s | 72.0 steps/s
[Step=11900 Epoch=58.4] | Loss=0.02231 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.870 | L2-Norm(final)=6.618 | 4533.7 samples/s | 70.8 steps/s
[Step=11950 Epoch=58.6] | Loss=0.02199 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.868 | L2-Norm(final)=6.619 | 2386.2 samples/s | 37.3 steps/s
[Step=12000 Epoch=58.8] | Loss=0.02167 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.867 | L2-Norm(final)=6.620 | 4467.3 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step12000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=94.8] | Loss=0.05225 | Reg=0.00195 | acc=0.9531 | L2-Norm=13.964 | L2-Norm(final)=4.125 | 5344.4 samples/s | 83.5 steps/s
[Step=10050 Epoch=95.2] | Loss=0.00690 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.060 | L2-Norm(final)=4.149 | 3948.4 samples/s | 61.7 steps/s
[Step=10100 Epoch=95.7] | Loss=0.00475 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.113 | L2-Norm(final)=4.178 | 7481.7 samples/s | 116.9 steps/s
[Step=10150 Epoch=96.2] | Loss=0.00405 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.151 | L2-Norm(final)=4.204 | 2137.2 samples/s | 33.4 steps/s
[Step=10200 Epoch=96.7] | Loss=0.00341 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.181 | L2-Norm(final)=4.228 | 6609.2 samples/s | 103.3 steps/s
[Step=10250 Epoch=97.1] | Loss=0.00292 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=4.250 | 2210.5 samples/s | 34.5 steps/s
[Step=10300 Epoch=97.6] | Loss=0.00261 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.225 | L2-Norm(final)=4.271 | 5948.2 samples/s | 92.9 steps/s
[Step=10350 Epoch=98.1] | Loss=0.00240 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.241 | L2-Norm(final)=4.292 | 2271.1 samples/s | 35.5 steps/s
[Step=10400 Epoch=98.5] | Loss=0.00218 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.254 | L2-Norm(final)=4.311 | 5401.7 samples/s | 84.4 steps/s
[Step=10450 Epoch=99.0] | Loss=0.00206 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.265 | L2-Norm(final)=4.330 | 2408.4 samples/s | 37.6 steps/s
[Step=10500 Epoch=99.5] | Loss=0.00190 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.274 | L2-Norm(final)=4.348 | 4880.1 samples/s | 76.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=99.5] | Loss=0.00020 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.353 | L2-Norm(final)=4.524 | 5539.5 samples/s | 86.6 steps/s
[Step=10550 Epoch=100.0] | Loss=0.00874 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=4.536 | 3699.4 samples/s | 57.8 steps/s
[Step=10600 Epoch=100.4] | Loss=0.01727 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=4.472 | 6150.4 samples/s | 96.1 steps/s
[Step=10650 Epoch=100.9] | Loss=0.01245 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.736 | L2-Norm(final)=4.435 | 2017.2 samples/s | 31.5 steps/s
[Step=10700 Epoch=101.4] | Loss=0.00946 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=4.419 | 5652.4 samples/s | 88.3 steps/s
[Step=10750 Epoch=101.9] | Loss=0.00791 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=4.410 | 2092.8 samples/s | 32.7 steps/s
[Step=10800 Epoch=102.3] | Loss=0.00660 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.888 | L2-Norm(final)=4.404 | 5077.8 samples/s | 79.3 steps/s
[Step=10850 Epoch=102.8] | Loss=0.00566 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=4.401 | 2179.0 samples/s | 34.0 steps/s
[Step=10900 Epoch=103.3] | Loss=0.00496 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.911 | L2-Norm(final)=4.398 | 4738.0 samples/s | 74.0 steps/s
[Step=10950 Epoch=103.8] | Loss=0.00441 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.913 | L2-Norm(final)=4.397 | 2215.7 samples/s | 34.6 steps/s
[Step=11000 Epoch=104.2] | Loss=0.00397 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.912 | L2-Norm(final)=4.395 | 4377.9 samples/s | 68.4 steps/s
[Step=11050 Epoch=104.7] | Loss=0.00361 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.908 | L2-Norm(final)=4.394 | 2351.5 samples/s | 36.7 steps/s
[Step=11100 Epoch=105.2] | Loss=0.00331 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=4.394 | 4295.9 samples/s | 67.1 steps/s
[Step=11150 Epoch=105.7] | Loss=0.00305 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.894 | L2-Norm(final)=4.393 | 2371.0 samples/s | 37.0 steps/s
[Step=11200 Epoch=106.1] | Loss=0.00284 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.885 | L2-Norm(final)=4.393 | 4262.5 samples/s | 66.6 steps/s
[Step=11250 Epoch=106.6] | Loss=0.00265 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.875 | L2-Norm(final)=4.393 | 2313.9 samples/s | 36.2 steps/s
[Step=11300 Epoch=107.1] | Loss=0.00248 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=4.392 | 4281.2 samples/s | 66.9 steps/s
[Step=11350 Epoch=107.6] | Loss=0.00234 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.853 | L2-Norm(final)=4.392 | 2520.2 samples/s | 39.4 steps/s
[Step=11400 Epoch=108.0] | Loss=0.00221 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=4.392 | 3866.9 samples/s | 60.4 steps/s
[Step=11450 Epoch=108.5] | Loss=0.00209 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=4.392 | 6480.7 samples/s | 101.3 steps/s
[Step=11500 Epoch=109.0] | Loss=0.00199 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.814 | L2-Norm(final)=4.392 | 1983.0 samples/s | 31.0 steps/s
[Step=11550 Epoch=109.4] | Loss=0.00189 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.801 | L2-Norm(final)=4.392 | 5799.0 samples/s | 90.6 steps/s
[Step=11600 Epoch=109.9] | Loss=0.00181 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=4.393 | 2076.8 samples/s | 32.4 steps/s
[Step=11650 Epoch=110.4] | Loss=0.00173 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.772 | L2-Norm(final)=4.393 | 5308.9 samples/s | 83.0 steps/s
[Step=11700 Epoch=110.9] | Loss=0.00166 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.757 | L2-Norm(final)=4.393 | 2133.6 samples/s | 33.3 steps/s
[Step=11750 Epoch=111.3] | Loss=0.00159 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.742 | L2-Norm(final)=4.394 | 4835.0 samples/s | 75.5 steps/s
[Step=11800 Epoch=111.8] | Loss=0.00153 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=4.394 | 2229.4 samples/s | 34.8 steps/s
[Step=11850 Epoch=112.3] | Loss=0.00147 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=4.395 | 4401.1 samples/s | 68.8 steps/s
[Step=11900 Epoch=112.8] | Loss=0.00142 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=4.396 | 2337.8 samples/s | 36.5 steps/s
[Step=11950 Epoch=113.2] | Loss=0.00137 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=4.397 | 4217.0 samples/s | 65.9 steps/s
[Step=12000 Epoch=113.7] | Loss=0.00133 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=4.398 | 2396.7 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step12000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=95.1] | Loss=0.00698 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.130 | L2-Norm(final)=4.419 | 5689.5 samples/s | 88.9 steps/s
[Step=10050 Epoch=95.6] | Loss=0.00489 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.175 | L2-Norm(final)=4.435 | 3956.1 samples/s | 61.8 steps/s
[Step=10100 Epoch=96.1] | Loss=0.00342 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.211 | L2-Norm(final)=4.453 | 7345.7 samples/s | 114.8 steps/s
[Step=10150 Epoch=96.6] | Loss=0.00266 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.235 | L2-Norm(final)=4.472 | 2198.4 samples/s | 34.4 steps/s
[Step=10200 Epoch=97.0] | Loss=0.00217 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.250 | L2-Norm(final)=4.491 | 6271.9 samples/s | 98.0 steps/s
[Step=10250 Epoch=97.5] | Loss=0.00187 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.262 | L2-Norm(final)=4.508 | 2218.3 samples/s | 34.7 steps/s
[Step=10300 Epoch=98.0] | Loss=0.00166 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.270 | L2-Norm(final)=4.524 | 5934.3 samples/s | 92.7 steps/s
[Step=10350 Epoch=98.5] | Loss=0.00149 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.276 | L2-Norm(final)=4.540 | 2307.9 samples/s | 36.1 steps/s
[Step=10400 Epoch=98.9] | Loss=0.00137 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.280 | L2-Norm(final)=4.555 | 5319.3 samples/s | 83.1 steps/s
[Step=10450 Epoch=99.4] | Loss=0.00126 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.283 | L2-Norm(final)=4.569 | 2415.9 samples/s | 37.7 steps/s
[Step=10500 Epoch=99.9] | Loss=0.00117 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.284 | L2-Norm(final)=4.582 | 4907.8 samples/s | 76.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=99.9] | Loss=0.00048 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.289 | L2-Norm(final)=4.714 | 5703.7 samples/s | 89.1 steps/s
[Step=10550 Epoch=100.4] | Loss=0.00026 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.279 | L2-Norm(final)=4.724 | 3597.3 samples/s | 56.2 steps/s
[Step=10600 Epoch=100.8] | Loss=0.00020 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.263 | L2-Norm(final)=4.729 | 6288.9 samples/s | 98.3 steps/s
[Step=10650 Epoch=101.3] | Loss=0.00014 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.244 | L2-Norm(final)=4.733 | 2000.5 samples/s | 31.3 steps/s
[Step=10700 Epoch=101.8] | Loss=0.00011 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.223 | L2-Norm(final)=4.736 | 5599.6 samples/s | 87.5 steps/s
[Step=10750 Epoch=102.3] | Loss=0.00009 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.200 | L2-Norm(final)=4.738 | 2095.4 samples/s | 32.7 steps/s
[Step=10800 Epoch=102.7] | Loss=0.00008 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.176 | L2-Norm(final)=4.739 | 5167.6 samples/s | 80.7 steps/s
[Step=10850 Epoch=103.2] | Loss=0.00007 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.152 | L2-Norm(final)=4.741 | 2171.6 samples/s | 33.9 steps/s
[Step=10900 Epoch=103.7] | Loss=0.00006 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.127 | L2-Norm(final)=4.742 | 4751.9 samples/s | 74.2 steps/s
[Step=10950 Epoch=104.2] | Loss=0.00005 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.102 | L2-Norm(final)=4.743 | 2235.2 samples/s | 34.9 steps/s
[Step=11000 Epoch=104.6] | Loss=0.00005 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.077 | L2-Norm(final)=4.744 | 4409.4 samples/s | 68.9 steps/s
[Step=11050 Epoch=105.1] | Loss=0.00005 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.051 | L2-Norm(final)=4.745 | 2395.7 samples/s | 37.4 steps/s
[Step=11100 Epoch=105.6] | Loss=0.00004 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.026 | L2-Norm(final)=4.745 | 4173.8 samples/s | 65.2 steps/s
[Step=11150 Epoch=106.1] | Loss=0.00004 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.000 | L2-Norm(final)=4.746 | 2384.9 samples/s | 37.3 steps/s
[Step=11200 Epoch=106.5] | Loss=0.00004 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.974 | L2-Norm(final)=4.747 | 4225.9 samples/s | 66.0 steps/s
[Step=11250 Epoch=107.0] | Loss=0.00004 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.948 | L2-Norm(final)=4.748 | 2377.6 samples/s | 37.1 steps/s
[Step=11300 Epoch=107.5] | Loss=0.00003 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.922 | L2-Norm(final)=4.748 | 4306.7 samples/s | 67.3 steps/s
[Step=11350 Epoch=108.0] | Loss=0.00003 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.896 | L2-Norm(final)=4.749 | 2529.5 samples/s | 39.5 steps/s
[Step=11400 Epoch=108.4] | Loss=0.00003 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.869 | L2-Norm(final)=4.750 | 3867.3 samples/s | 60.4 steps/s
[Step=11450 Epoch=108.9] | Loss=0.00003 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.843 | L2-Norm(final)=4.750 | 6532.1 samples/s | 102.1 steps/s
[Step=11500 Epoch=109.4] | Loss=0.00003 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.816 | L2-Norm(final)=4.751 | 2018.7 samples/s | 31.5 steps/s
[Step=11550 Epoch=109.9] | Loss=0.00003 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.789 | L2-Norm(final)=4.752 | 5799.7 samples/s | 90.6 steps/s
[Step=11600 Epoch=110.3] | Loss=0.00003 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.763 | L2-Norm(final)=4.753 | 2018.6 samples/s | 31.5 steps/s
[Step=11650 Epoch=110.8] | Loss=0.00003 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.736 | L2-Norm(final)=4.753 | 5366.8 samples/s | 83.9 steps/s
[Step=11700 Epoch=111.3] | Loss=0.00002 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.708 | L2-Norm(final)=4.754 | 2174.1 samples/s | 34.0 steps/s
[Step=11750 Epoch=111.8] | Loss=0.00002 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=4.754 | 4884.2 samples/s | 76.3 steps/s
[Step=11800 Epoch=112.2] | Loss=0.00002 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.654 | L2-Norm(final)=4.755 | 2274.8 samples/s | 35.5 steps/s
[Step=11850 Epoch=112.7] | Loss=0.00002 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.626 | L2-Norm(final)=4.756 | 4304.7 samples/s | 67.3 steps/s
[Step=11900 Epoch=113.2] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.599 | L2-Norm(final)=4.756 | 2250.4 samples/s | 35.2 steps/s
[Step=11950 Epoch=113.7] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.571 | L2-Norm(final)=4.757 | 4285.8 samples/s | 67.0 steps/s
[Step=12000 Epoch=114.1] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.543 | L2-Norm(final)=4.758 | 2422.2 samples/s | 37.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step12000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=95.5] | Loss=0.06927 | Reg=0.00208 | acc=0.9531 | L2-Norm=14.434 | L2-Norm(final)=4.254 | 5260.9 samples/s | 82.2 steps/s
[Step=10050 Epoch=96.0] | Loss=0.00698 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=4.239 | 3945.9 samples/s | 61.7 steps/s
[Step=10100 Epoch=96.4] | Loss=0.00512 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=4.269 | 7413.5 samples/s | 115.8 steps/s
[Step=10150 Epoch=96.9] | Loss=0.00381 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=4.295 | 2130.1 samples/s | 33.3 steps/s
[Step=10200 Epoch=97.4] | Loss=0.00318 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=4.320 | 6915.2 samples/s | 108.1 steps/s
[Step=10250 Epoch=97.9] | Loss=0.00280 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=4.344 | 2202.6 samples/s | 34.4 steps/s
[Step=10300 Epoch=98.4] | Loss=0.00243 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.708 | L2-Norm(final)=4.368 | 6188.8 samples/s | 96.7 steps/s
[Step=10350 Epoch=98.8] | Loss=0.00215 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.718 | L2-Norm(final)=4.389 | 2258.8 samples/s | 35.3 steps/s
[Step=10400 Epoch=99.3] | Loss=0.00196 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.726 | L2-Norm(final)=4.409 | 5543.5 samples/s | 86.6 steps/s
[Step=10450 Epoch=99.8] | Loss=0.00182 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.731 | L2-Norm(final)=4.428 | 2359.9 samples/s | 36.9 steps/s
[Step=10500 Epoch=100.3] | Loss=0.00167 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=4.447 | 5197.3 samples/s | 81.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=100.3] | Loss=0.00013 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.758 | L2-Norm(final)=4.629 | 5416.0 samples/s | 84.6 steps/s
[Step=10550 Epoch=100.7] | Loss=0.00022 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=4.641 | 3874.7 samples/s | 60.5 steps/s
[Step=10600 Epoch=101.2] | Loss=0.00019 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=4.647 | 6328.0 samples/s | 98.9 steps/s
[Step=10650 Epoch=101.7] | Loss=0.00013 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.693 | L2-Norm(final)=4.652 | 2013.9 samples/s | 31.5 steps/s
[Step=10700 Epoch=102.2] | Loss=0.00010 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=4.655 | 5763.5 samples/s | 90.1 steps/s
[Step=10750 Epoch=102.7] | Loss=0.00008 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.634 | L2-Norm(final)=4.657 | 2108.1 samples/s | 32.9 steps/s
[Step=10800 Epoch=103.1] | Loss=0.00007 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.602 | L2-Norm(final)=4.658 | 5243.4 samples/s | 81.9 steps/s
[Step=10850 Epoch=103.6] | Loss=0.00006 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=4.659 | 2138.0 samples/s | 33.4 steps/s
[Step=10900 Epoch=104.1] | Loss=0.00005 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=4.660 | 5001.8 samples/s | 78.2 steps/s
[Step=10950 Epoch=104.6] | Loss=0.00005 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.505 | L2-Norm(final)=4.661 | 2188.7 samples/s | 34.2 steps/s
[Step=11000 Epoch=105.0] | Loss=0.00004 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.472 | L2-Norm(final)=4.662 | 4596.1 samples/s | 71.8 steps/s
[Step=11050 Epoch=105.5] | Loss=0.00004 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.439 | L2-Norm(final)=4.662 | 2266.2 samples/s | 35.4 steps/s
[Step=11100 Epoch=106.0] | Loss=0.00004 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.406 | L2-Norm(final)=4.663 | 4287.2 samples/s | 67.0 steps/s
[Step=11150 Epoch=106.5] | Loss=0.00003 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.372 | L2-Norm(final)=4.663 | 2355.3 samples/s | 36.8 steps/s
[Step=11200 Epoch=107.0] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.339 | L2-Norm(final)=4.664 | 4348.4 samples/s | 67.9 steps/s
[Step=11250 Epoch=107.4] | Loss=0.00003 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.305 | L2-Norm(final)=4.664 | 2343.2 samples/s | 36.6 steps/s
[Step=11300 Epoch=107.9] | Loss=0.00003 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.271 | L2-Norm(final)=4.665 | 4288.3 samples/s | 67.0 steps/s
[Step=11350 Epoch=108.4] | Loss=0.00003 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.238 | L2-Norm(final)=4.665 | 2378.1 samples/s | 37.2 steps/s
[Step=11400 Epoch=108.9] | Loss=0.00002 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.204 | L2-Norm(final)=4.666 | 4268.2 samples/s | 66.7 steps/s
[Step=11450 Epoch=109.3] | Loss=0.00002 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.169 | L2-Norm(final)=4.666 | 2394.5 samples/s | 37.4 steps/s
[Step=11500 Epoch=109.8] | Loss=0.00002 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.135 | L2-Norm(final)=4.667 | 4281.2 samples/s | 66.9 steps/s
[Step=11550 Epoch=110.3] | Loss=0.00002 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.101 | L2-Norm(final)=4.667 | 6910.3 samples/s | 108.0 steps/s
[Step=11600 Epoch=110.8] | Loss=0.00002 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.066 | L2-Norm(final)=4.667 | 1922.4 samples/s | 30.0 steps/s
[Step=11650 Epoch=111.3] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.032 | L2-Norm(final)=4.668 | 6400.8 samples/s | 100.0 steps/s
[Step=11700 Epoch=111.7] | Loss=0.00002 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.997 | L2-Norm(final)=4.668 | 2022.0 samples/s | 31.6 steps/s
[Step=11750 Epoch=112.2] | Loss=0.00002 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.962 | L2-Norm(final)=4.669 | 5725.3 samples/s | 89.5 steps/s
[Step=11800 Epoch=112.7] | Loss=0.00002 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.927 | L2-Norm(final)=4.669 | 2079.1 samples/s | 32.5 steps/s
[Step=11850 Epoch=113.2] | Loss=0.00002 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.892 | L2-Norm(final)=4.669 | 5270.3 samples/s | 82.3 steps/s
[Step=11900 Epoch=113.6] | Loss=0.00002 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.857 | L2-Norm(final)=4.670 | 2091.4 samples/s | 32.7 steps/s
[Step=11950 Epoch=114.1] | Loss=0.00002 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.822 | L2-Norm(final)=4.670 | 4938.9 samples/s | 77.2 steps/s
[Step=12000 Epoch=114.6] | Loss=0.00002 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.787 | L2-Norm(final)=4.671 | 2251.2 samples/s | 35.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step12000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=94.2] | Loss=0.00794 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.383 | L2-Norm(final)=4.091 | 5592.4 samples/s | 87.4 steps/s
[Step=10050 Epoch=94.7] | Loss=0.00535 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.444 | L2-Norm(final)=4.122 | 3962.8 samples/s | 61.9 steps/s
[Step=10100 Epoch=95.2] | Loss=0.00386 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.492 | L2-Norm(final)=4.153 | 7344.8 samples/s | 114.8 steps/s
[Step=10150 Epoch=95.6] | Loss=0.00289 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.521 | L2-Norm(final)=4.181 | 2110.1 samples/s | 33.0 steps/s
[Step=10200 Epoch=96.1] | Loss=0.00252 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=4.208 | 6472.3 samples/s | 101.1 steps/s
[Step=10250 Epoch=96.6] | Loss=0.00217 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.553 | L2-Norm(final)=4.235 | 2268.2 samples/s | 35.4 steps/s
[Step=10300 Epoch=97.1] | Loss=0.00191 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.564 | L2-Norm(final)=4.259 | 5408.9 samples/s | 84.5 steps/s
[Step=10350 Epoch=97.5] | Loss=0.00176 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=4.282 | 2394.1 samples/s | 37.4 steps/s
[Step=10400 Epoch=98.0] | Loss=0.00159 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.580 | L2-Norm(final)=4.305 | 4980.0 samples/s | 77.8 steps/s
[Step=10450 Epoch=98.5] | Loss=0.00146 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=4.326 | 2428.2 samples/s | 37.9 steps/s
[Step=10500 Epoch=98.9] | Loss=0.00134 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.587 | L2-Norm(final)=4.345 | 4720.7 samples/s | 73.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=98.9] | Loss=0.00015 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=4.533 | 5698.5 samples/s | 89.0 steps/s
[Step=10550 Epoch=99.4] | Loss=0.01535 | Reg=0.00214 | acc=0.9375 | L2-Norm=14.645 | L2-Norm(final)=4.538 | 3589.5 samples/s | 56.1 steps/s
[Step=10600 Epoch=99.9] | Loss=0.02051 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=4.472 | 6258.8 samples/s | 97.8 steps/s
[Step=10650 Epoch=100.4] | Loss=0.01473 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=4.440 | 2024.6 samples/s | 31.6 steps/s
[Step=10700 Epoch=100.8] | Loss=0.01120 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=4.427 | 5477.4 samples/s | 85.6 steps/s
[Step=10750 Epoch=101.3] | Loss=0.00898 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=4.421 | 2063.9 samples/s | 32.2 steps/s
[Step=10800 Epoch=101.8] | Loss=0.00749 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.118 | L2-Norm(final)=4.418 | 4984.9 samples/s | 77.9 steps/s
[Step=10850 Epoch=102.2] | Loss=0.00642 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=4.416 | 2220.5 samples/s | 34.7 steps/s
[Step=10900 Epoch=102.7] | Loss=0.00562 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=4.415 | 4493.0 samples/s | 70.2 steps/s
[Step=10950 Epoch=103.2] | Loss=0.00500 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=4.414 | 2292.2 samples/s | 35.8 steps/s
[Step=11000 Epoch=103.7] | Loss=0.00450 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=4.413 | 4195.2 samples/s | 65.6 steps/s
[Step=11050 Epoch=104.1] | Loss=0.00409 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.107 | L2-Norm(final)=4.413 | 2396.7 samples/s | 37.4 steps/s
[Step=11100 Epoch=104.6] | Loss=0.00375 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.097 | L2-Norm(final)=4.413 | 4253.2 samples/s | 66.5 steps/s
[Step=11150 Epoch=105.1] | Loss=0.00347 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=4.413 | 2401.7 samples/s | 37.5 steps/s
[Step=11200 Epoch=105.5] | Loss=0.00322 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.073 | L2-Norm(final)=4.413 | 4360.4 samples/s | 68.1 steps/s
[Step=11250 Epoch=106.0] | Loss=0.00301 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=4.413 | 2692.0 samples/s | 42.1 steps/s
[Step=11300 Epoch=106.5] | Loss=0.00282 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=4.414 | 3468.3 samples/s | 54.2 steps/s
[Step=11350 Epoch=106.9] | Loss=0.00265 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=4.414 | 6276.2 samples/s | 98.1 steps/s
[Step=11400 Epoch=107.4] | Loss=0.00251 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=4.414 | 2017.1 samples/s | 31.5 steps/s
[Step=11450 Epoch=107.9] | Loss=0.00238 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=4.415 | 5634.6 samples/s | 88.0 steps/s
[Step=11500 Epoch=108.4] | Loss=0.00226 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=4.415 | 2122.9 samples/s | 33.2 steps/s
[Step=11550 Epoch=108.8] | Loss=0.00215 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=4.415 | 5027.5 samples/s | 78.6 steps/s
[Step=11600 Epoch=109.3] | Loss=0.00205 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=4.416 | 2168.3 samples/s | 33.9 steps/s
[Step=11650 Epoch=109.8] | Loss=0.00196 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=4.416 | 4554.6 samples/s | 71.2 steps/s
[Step=11700 Epoch=110.2] | Loss=0.00188 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.918 | L2-Norm(final)=4.417 | 2300.4 samples/s | 35.9 steps/s
[Step=11750 Epoch=110.7] | Loss=0.00181 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=4.417 | 4353.1 samples/s | 68.0 steps/s
[Step=11800 Epoch=111.2] | Loss=0.00174 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=4.417 | 2369.2 samples/s | 37.0 steps/s
[Step=11850 Epoch=111.7] | Loss=0.00167 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.865 | L2-Norm(final)=4.418 | 4269.9 samples/s | 66.7 steps/s
[Step=11900 Epoch=112.1] | Loss=0.00161 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.846 | L2-Norm(final)=4.418 | 2363.6 samples/s | 36.9 steps/s
[Step=11950 Epoch=112.6] | Loss=0.00156 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=4.419 | 4219.7 samples/s | 65.9 steps/s
[Step=12000 Epoch=113.1] | Loss=0.00151 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=4.419 | 2512.7 samples/s | 39.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step12000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=95.3] | Loss=0.01948 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.960 | L2-Norm(final)=5.011 | 5621.6 samples/s | 87.8 steps/s
[Step=10050 Epoch=95.8] | Loss=0.01147 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.110 | L2-Norm(final)=5.019 | 3978.0 samples/s | 62.2 steps/s
[Step=10100 Epoch=96.3] | Loss=0.00684 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.205 | L2-Norm(final)=5.045 | 7628.0 samples/s | 119.2 steps/s
[Step=10150 Epoch=96.7] | Loss=0.00509 | Reg=0.00203 | acc=0.9844 | L2-Norm=14.252 | L2-Norm(final)=5.073 | 2155.7 samples/s | 33.7 steps/s
[Step=10200 Epoch=97.2] | Loss=0.00421 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.281 | L2-Norm(final)=5.100 | 6458.9 samples/s | 100.9 steps/s
[Step=10250 Epoch=97.7] | Loss=0.00360 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.308 | L2-Norm(final)=5.127 | 2237.9 samples/s | 35.0 steps/s
[Step=10300 Epoch=98.2] | Loss=0.00310 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.329 | L2-Norm(final)=5.153 | 5779.8 samples/s | 90.3 steps/s
[Step=10350 Epoch=98.6] | Loss=0.00276 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.344 | L2-Norm(final)=5.177 | 2305.3 samples/s | 36.0 steps/s
[Step=10400 Epoch=99.1] | Loss=0.00249 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.356 | L2-Norm(final)=5.199 | 5455.5 samples/s | 85.2 steps/s
[Step=10450 Epoch=99.6] | Loss=0.00229 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=5.221 | 2312.8 samples/s | 36.1 steps/s
[Step=10500 Epoch=100.1] | Loss=0.00211 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.373 | L2-Norm(final)=5.241 | 5240.1 samples/s | 81.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=100.1] | Loss=0.00069 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.437 | L2-Norm(final)=5.445 | 5738.5 samples/s | 89.7 steps/s
[Step=10550 Epoch=100.6] | Loss=0.00041 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.435 | L2-Norm(final)=5.460 | 3701.8 samples/s | 57.8 steps/s
[Step=10600 Epoch=101.0] | Loss=0.01129 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.437 | L2-Norm(final)=5.465 | 6072.4 samples/s | 94.9 steps/s
[Step=10650 Epoch=101.5] | Loss=0.02298 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.587 | L2-Norm(final)=5.406 | 2026.3 samples/s | 31.7 steps/s
[Step=10700 Epoch=102.0] | Loss=0.01883 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=5.363 | 5712.1 samples/s | 89.3 steps/s
[Step=10750 Epoch=102.5] | Loss=0.01537 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=5.339 | 2050.7 samples/s | 32.0 steps/s
[Step=10800 Epoch=102.9] | Loss=0.01290 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.813 | L2-Norm(final)=5.324 | 5358.9 samples/s | 83.7 steps/s
[Step=10850 Epoch=103.4] | Loss=0.01108 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=5.314 | 2158.1 samples/s | 33.7 steps/s
[Step=10900 Epoch=103.9] | Loss=0.00971 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.859 | L2-Norm(final)=5.306 | 4929.7 samples/s | 77.0 steps/s
[Step=10950 Epoch=104.4] | Loss=0.00863 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=5.301 | 2203.1 samples/s | 34.4 steps/s
[Step=11000 Epoch=104.8] | Loss=0.00777 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=5.297 | 4655.0 samples/s | 72.7 steps/s
[Step=11050 Epoch=105.3] | Loss=0.00707 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=5.294 | 2275.5 samples/s | 35.6 steps/s
[Step=11100 Epoch=105.8] | Loss=0.00648 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=5.291 | 4316.7 samples/s | 67.4 steps/s
[Step=11150 Epoch=106.3] | Loss=0.00599 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=5.289 | 2375.1 samples/s | 37.1 steps/s
[Step=11200 Epoch=106.7] | Loss=0.00556 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.872 | L2-Norm(final)=5.287 | 4270.9 samples/s | 66.7 steps/s
[Step=11250 Epoch=107.2] | Loss=0.00519 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.867 | L2-Norm(final)=5.286 | 2374.0 samples/s | 37.1 steps/s
[Step=11300 Epoch=107.7] | Loss=0.00487 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=5.285 | 4293.9 samples/s | 67.1 steps/s
[Step=11350 Epoch=108.2] | Loss=0.00458 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.853 | L2-Norm(final)=5.284 | 2311.2 samples/s | 36.1 steps/s
[Step=11400 Epoch=108.7] | Loss=0.00433 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.845 | L2-Norm(final)=5.283 | 4232.2 samples/s | 66.1 steps/s
[Step=11450 Epoch=109.1] | Loss=0.00410 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.836 | L2-Norm(final)=5.282 | 2380.8 samples/s | 37.2 steps/s
[Step=11500 Epoch=109.6] | Loss=0.00390 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=5.281 | 4350.7 samples/s | 68.0 steps/s
[Step=11550 Epoch=110.1] | Loss=0.00371 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=5.281 | 6811.5 samples/s | 106.4 steps/s
[Step=11600 Epoch=110.6] | Loss=0.00355 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.806 | L2-Norm(final)=5.280 | 1954.2 samples/s | 30.5 steps/s
[Step=11650 Epoch=111.0] | Loss=0.00339 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.795 | L2-Norm(final)=5.280 | 6218.7 samples/s | 97.2 steps/s
[Step=11700 Epoch=111.5] | Loss=0.00325 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=5.280 | 2016.3 samples/s | 31.5 steps/s
[Step=11750 Epoch=112.0] | Loss=0.00312 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.772 | L2-Norm(final)=5.280 | 5800.9 samples/s | 90.6 steps/s
[Step=11800 Epoch=112.5] | Loss=0.00300 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=5.279 | 2098.2 samples/s | 32.8 steps/s
[Step=11850 Epoch=112.9] | Loss=0.00289 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=5.279 | 5286.8 samples/s | 82.6 steps/s
[Step=11900 Epoch=113.4] | Loss=0.00279 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=5.279 | 2156.8 samples/s | 33.7 steps/s
[Step=11950 Epoch=113.9] | Loss=0.00269 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=5.279 | 4859.6 samples/s | 75.9 steps/s
[Step=12000 Epoch=114.4] | Loss=0.00260 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=5.279 | 2238.3 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.15150 | acc=0.9390 | tpr=0.9450 | fpr=0.0741 | 4863.9 samples/s | 19.0 steps/s
Avg test loss: 0.15409, Avg test acc: 0.94006, Avg tpr: 0.94620, Avg fpr: 0.07345, total FA: 573

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.14306 | acc=0.9417 | tpr=0.9595 | fpr=0.0969 | 4781.7 samples/s | 18.7 steps/s
Avg test loss: 0.14712, Avg test acc: 0.94086, Avg tpr: 0.95803, Avg fpr: 0.09691, total FA: 756

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.15802 | acc=0.9395 | tpr=0.9487 | fpr=0.0805 | 4778.3 samples/s | 18.7 steps/s
Avg test loss: 0.15823, Avg test acc: 0.93926, Avg tpr: 0.94883, Avg fpr: 0.08178, total FA: 638

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14158 | acc=0.9423 | tpr=0.9606 | fpr=0.0974 | 4999.9 samples/s | 19.5 steps/s
Avg test loss: 0.14675, Avg test acc: 0.94046, Avg tpr: 0.96147, Avg fpr: 0.10576, total FA: 825

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.13685 | acc=0.9408 | tpr=0.9514 | fpr=0.0823 | 4921.0 samples/s | 19.2 steps/s
Avg test loss: 0.14238, Avg test acc: 0.94090, Avg tpr: 0.95186, Avg fpr: 0.08319, total FA: 649

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.27809 | acc=0.3116 | tpr=0.0224 | fpr=0.0605 | 4770.7 samples/s | 18.6 steps/s
Avg test loss: 4.29684, Avg test acc: 0.31036, Avg tpr: 0.02308, Avg fpr: 0.05781, total FA: 451

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.56124 | acc=0.2901 | tpr=0.0081 | fpr=0.0976 | 5047.2 samples/s | 19.7 steps/s
Avg test loss: 4.57180, Avg test acc: 0.28792, Avg tpr: 0.00822, Avg fpr: 0.09691, total FA: 756

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.27830 | acc=0.2767 | tpr=0.0176 | fpr=0.1606 | 4783.8 samples/s | 18.7 steps/s
Avg test loss: 5.27570, Avg test acc: 0.27502, Avg tpr: 0.01906, Avg fpr: 0.16203, total FA: 1264

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=4.39343 | acc=0.3015 | tpr=0.0098 | fpr=0.0652 | 4823.4 samples/s | 18.8 steps/s
Avg test loss: 4.40615, Avg test acc: 0.30050, Avg tpr: 0.01008, Avg fpr: 0.06076, total FA: 474

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.54972 | acc=0.3153 | tpr=0.0041 | fpr=0.0089 | 4986.6 samples/s | 19.5 steps/s
Avg test loss: 4.56850, Avg test acc: 0.31253, Avg tpr: 0.00437, Avg fpr: 0.00974, total FA: 76

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.14173 | acc=0.1131 | tpr=0.5398 | fpr=0.8945 | 4837.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.11419 | acc=0.1154 | tpr=0.5693 | fpr=0.8930 | 7064.3 samples/s | 27.6 steps/s
[Step= 150] | Loss=6.10202 | acc=0.1174 | tpr=0.5533 | fpr=0.8907 | 7898.2 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.09798 | acc=0.1177 | tpr=0.5508 | fpr=0.8901 | 7446.1 samples/s | 29.1 steps/s
[Step= 250] | Loss=6.11240 | acc=0.1175 | tpr=0.5563 | fpr=0.8905 | 8280.8 samples/s | 32.3 steps/s
[Step= 300] | Loss=6.11186 | acc=0.1175 | tpr=0.5673 | fpr=0.8907 | 8049.4 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.10779 | acc=0.1174 | tpr=0.5673 | fpr=0.8908 | 7684.1 samples/s | 30.0 steps/s
[Step= 400] | Loss=6.10099 | acc=0.1176 | tpr=0.5689 | fpr=0.8906 | 8070.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.10218 | acc=0.1171 | tpr=0.5706 | fpr=0.8911 | 7475.3 samples/s | 29.2 steps/s
[Step= 500] | Loss=6.10825 | acc=0.1170 | tpr=0.5665 | fpr=0.8911 | 7981.2 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.11323 | acc=0.1172 | tpr=0.5671 | fpr=0.8910 | 14074.8 samples/s | 55.0 steps/s
Avg test loss: 6.11508, Avg test acc: 0.11714, Avg tpr: 0.56815, Avg fpr: 0.89106, total FA: 123722

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.09030 | acc=0.1023 | tpr=0.5442 | fpr=0.9057 | 4916.4 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.06840 | acc=0.1009 | tpr=0.5352 | fpr=0.9072 | 7056.4 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.05830 | acc=0.1015 | tpr=0.5216 | fpr=0.9062 | 7787.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.04903 | acc=0.1014 | tpr=0.5191 | fpr=0.9062 | 7738.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.05107 | acc=0.1019 | tpr=0.5197 | fpr=0.9058 | 7637.8 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.04652 | acc=0.1016 | tpr=0.5222 | fpr=0.9061 | 8156.1 samples/s | 31.9 steps/s
[Step= 350] | Loss=5.03900 | acc=0.1015 | tpr=0.5166 | fpr=0.9060 | 7621.1 samples/s | 29.8 steps/s
[Step= 400] | Loss=5.03842 | acc=0.1020 | tpr=0.5175 | fpr=0.9055 | 8095.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.04643 | acc=0.1018 | tpr=0.5156 | fpr=0.9058 | 8005.8 samples/s | 31.3 steps/s
[Step= 500] | Loss=5.04925 | acc=0.1009 | tpr=0.5088 | fpr=0.9065 | 7654.1 samples/s | 29.9 steps/s
[Step= 550] | Loss=5.05104 | acc=0.1007 | tpr=0.5082 | fpr=0.9068 | 14174.6 samples/s | 55.4 steps/s
Avg test loss: 5.05163, Avg test acc: 0.10064, Avg tpr: 0.50872, Avg fpr: 0.90678, total FA: 125904

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.61692 | acc=0.0988 | tpr=0.4248 | fpr=0.9071 | 4675.5 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.60663 | acc=0.1013 | tpr=0.4499 | fpr=0.9053 | 7660.7 samples/s | 29.9 steps/s
[Step= 150] | Loss=5.61259 | acc=0.1021 | tpr=0.4251 | fpr=0.9039 | 7760.5 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.61080 | acc=0.1023 | tpr=0.4219 | fpr=0.9035 | 7517.3 samples/s | 29.4 steps/s
[Step= 250] | Loss=5.62161 | acc=0.1021 | tpr=0.4376 | fpr=0.9040 | 8138.4 samples/s | 31.8 steps/s
[Step= 300] | Loss=5.62435 | acc=0.1020 | tpr=0.4444 | fpr=0.9042 | 8015.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.61355 | acc=0.1024 | tpr=0.4433 | fpr=0.9037 | 7718.1 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.61156 | acc=0.1026 | tpr=0.4415 | fpr=0.9036 | 7953.2 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.61217 | acc=0.1026 | tpr=0.4426 | fpr=0.9035 | 7646.6 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.61454 | acc=0.1029 | tpr=0.4410 | fpr=0.9032 | 8000.7 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.61682 | acc=0.1032 | tpr=0.4465 | fpr=0.9030 | 14061.8 samples/s | 54.9 steps/s
Avg test loss: 5.61790, Avg test acc: 0.10305, Avg tpr: 0.44651, Avg fpr: 0.90319, total FA: 125406

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.23555 | acc=0.1295 | tpr=0.6593 | fpr=0.8801 | 4613.5 samples/s | 18.0 steps/s
[Step= 100] | Loss=5.22144 | acc=0.1299 | tpr=0.6588 | fpr=0.8800 | 7690.0 samples/s | 30.0 steps/s
[Step= 150] | Loss=5.22229 | acc=0.1313 | tpr=0.6671 | fpr=0.8786 | 7760.6 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.21617 | acc=0.1312 | tpr=0.6634 | fpr=0.8785 | 7757.9 samples/s | 30.3 steps/s
[Step= 250] | Loss=5.22514 | acc=0.1320 | tpr=0.6664 | fpr=0.8778 | 8258.2 samples/s | 32.3 steps/s
[Step= 300] | Loss=5.22881 | acc=0.1310 | tpr=0.6662 | fpr=0.8788 | 7859.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.21982 | acc=0.1314 | tpr=0.6706 | fpr=0.8784 | 8026.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.21200 | acc=0.1320 | tpr=0.6701 | fpr=0.8778 | 7690.9 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.21875 | acc=0.1319 | tpr=0.6801 | fpr=0.8781 | 7937.7 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.22048 | acc=0.1315 | tpr=0.6740 | fpr=0.8783 | 7924.2 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.21778 | acc=0.1318 | tpr=0.6749 | fpr=0.8781 | 13738.9 samples/s | 53.7 steps/s
Avg test loss: 5.21793, Avg test acc: 0.13163, Avg tpr: 0.67472, Avg fpr: 0.87824, total FA: 121942

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.75301 | acc=0.1422 | tpr=0.7080 | fpr=0.8680 | 4775.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=4.74672 | acc=0.1437 | tpr=0.6780 | fpr=0.8663 | 7294.8 samples/s | 28.5 steps/s
[Step= 150] | Loss=4.74185 | acc=0.1449 | tpr=0.6614 | fpr=0.8646 | 7972.8 samples/s | 31.1 steps/s
[Step= 200] | Loss=4.74473 | acc=0.1444 | tpr=0.6590 | fpr=0.8649 | 7594.1 samples/s | 29.7 steps/s
[Step= 250] | Loss=4.76186 | acc=0.1441 | tpr=0.6559 | fpr=0.8652 | 8368.1 samples/s | 32.7 steps/s
[Step= 300] | Loss=4.76328 | acc=0.1441 | tpr=0.6604 | fpr=0.8653 | 7795.3 samples/s | 30.5 steps/s
[Step= 350] | Loss=4.75554 | acc=0.1437 | tpr=0.6531 | fpr=0.8656 | 7698.5 samples/s | 30.1 steps/s
[Step= 400] | Loss=4.75121 | acc=0.1439 | tpr=0.6526 | fpr=0.8653 | 7835.6 samples/s | 30.6 steps/s
[Step= 450] | Loss=4.75484 | acc=0.1435 | tpr=0.6514 | fpr=0.8658 | 8078.0 samples/s | 31.6 steps/s
[Step= 500] | Loss=4.75547 | acc=0.1433 | tpr=0.6498 | fpr=0.8658 | 7511.0 samples/s | 29.3 steps/s
[Step= 550] | Loss=4.75702 | acc=0.1434 | tpr=0.6498 | fpr=0.8658 | 14526.5 samples/s | 56.7 steps/s
Avg test loss: 4.75809, Avg test acc: 0.14327, Avg tpr: 0.65016, Avg fpr: 0.86594, total FA: 120234

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12179 | acc=0.9791 | tpr=0.9115 | fpr=0.0196 | 4661.2 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.12575 | acc=0.9793 | tpr=0.9254 | fpr=0.0197 | 6912.7 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.13184 | acc=0.9786 | tpr=0.9308 | fpr=0.0206 | 8294.2 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.13412 | acc=0.9789 | tpr=0.9366 | fpr=0.0203 | 7661.2 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.13190 | acc=0.9791 | tpr=0.9310 | fpr=0.0201 | 8229.5 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.13444 | acc=0.9787 | tpr=0.9287 | fpr=0.0204 | 7653.7 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.13684 | acc=0.9783 | tpr=0.9292 | fpr=0.0208 | 7968.4 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.13760 | acc=0.9782 | tpr=0.9256 | fpr=0.0208 | 7916.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13979 | acc=0.9779 | tpr=0.9221 | fpr=0.0211 | 7742.4 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.13832 | acc=0.9780 | tpr=0.9229 | fpr=0.0210 | 8102.6 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.13785 | acc=0.9782 | tpr=0.9216 | fpr=0.0208 | 13746.6 samples/s | 53.7 steps/s
Avg test loss: 0.13755, Avg test acc: 0.97822, Avg tpr: 0.92195, Avg fpr: 0.02076, total FA: 2882

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09342 | acc=0.9826 | tpr=0.8850 | fpr=0.0157 | 4796.9 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09501 | acc=0.9824 | tpr=0.8891 | fpr=0.0158 | 7106.2 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09923 | acc=0.9818 | tpr=0.8847 | fpr=0.0164 | 7986.8 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.10156 | acc=0.9815 | tpr=0.8907 | fpr=0.0169 | 7886.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.09867 | acc=0.9819 | tpr=0.8873 | fpr=0.0164 | 7779.9 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.10073 | acc=0.9817 | tpr=0.8858 | fpr=0.0166 | 7951.4 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.10141 | acc=0.9815 | tpr=0.8892 | fpr=0.0169 | 7780.8 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10271 | acc=0.9812 | tpr=0.8846 | fpr=0.0171 | 8191.0 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.10442 | acc=0.9810 | tpr=0.8841 | fpr=0.0172 | 7999.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10352 | acc=0.9811 | tpr=0.8859 | fpr=0.0171 | 8323.7 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.10282 | acc=0.9813 | tpr=0.8850 | fpr=0.0169 | 12080.0 samples/s | 47.2 steps/s
Avg test loss: 0.10270, Avg test acc: 0.98133, Avg tpr: 0.88431, Avg fpr: 0.01691, total FA: 2348

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08399 | acc=0.9807 | tpr=0.9558 | fpr=0.0188 | 4697.2 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.08554 | acc=0.9805 | tpr=0.9360 | fpr=0.0187 | 7272.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.09053 | acc=0.9799 | tpr=0.9380 | fpr=0.0193 | 8016.5 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.09279 | acc=0.9800 | tpr=0.9454 | fpr=0.0194 | 8063.0 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.09109 | acc=0.9801 | tpr=0.9397 | fpr=0.0191 | 7949.2 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.09321 | acc=0.9800 | tpr=0.9360 | fpr=0.0192 | 7831.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.09432 | acc=0.9799 | tpr=0.9361 | fpr=0.0193 | 7738.3 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09577 | acc=0.9797 | tpr=0.9322 | fpr=0.0194 | 7928.0 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.09724 | acc=0.9795 | tpr=0.9309 | fpr=0.0196 | 7894.8 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.09656 | acc=0.9796 | tpr=0.9322 | fpr=0.0196 | 8118.4 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.09625 | acc=0.9797 | tpr=0.9320 | fpr=0.0194 | 13778.5 samples/s | 53.8 steps/s
Avg test loss: 0.09618, Avg test acc: 0.97971, Avg tpr: 0.93185, Avg fpr: 0.01942, total FA: 2697

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09566 | acc=0.9832 | tpr=0.9027 | fpr=0.0153 | 4747.3 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.09969 | acc=0.9823 | tpr=0.8998 | fpr=0.0162 | 7116.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.10500 | acc=0.9812 | tpr=0.9063 | fpr=0.0174 | 8006.8 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.10681 | acc=0.9811 | tpr=0.9082 | fpr=0.0176 | 7478.0 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.10476 | acc=0.9813 | tpr=0.9048 | fpr=0.0173 | 7997.0 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.10623 | acc=0.9810 | tpr=0.9040 | fpr=0.0176 | 8104.0 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.10634 | acc=0.9807 | tpr=0.9073 | fpr=0.0180 | 8001.6 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.10675 | acc=0.9806 | tpr=0.9048 | fpr=0.0181 | 7914.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10884 | acc=0.9801 | tpr=0.9007 | fpr=0.0184 | 7866.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10848 | acc=0.9802 | tpr=0.9026 | fpr=0.0184 | 7849.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10801 | acc=0.9805 | tpr=0.9037 | fpr=0.0181 | 14154.8 samples/s | 55.3 steps/s
Avg test loss: 0.10785, Avg test acc: 0.98049, Avg tpr: 0.90412, Avg fpr: 0.01812, total FA: 2516

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12228 | acc=0.9776 | tpr=0.8717 | fpr=0.0205 | 4805.5 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.12527 | acc=0.9777 | tpr=0.9019 | fpr=0.0209 | 7157.7 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.13073 | acc=0.9767 | tpr=0.9020 | fpr=0.0220 | 7960.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.13475 | acc=0.9765 | tpr=0.9082 | fpr=0.0223 | 7782.5 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.13223 | acc=0.9768 | tpr=0.9066 | fpr=0.0219 | 7889.2 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.13446 | acc=0.9765 | tpr=0.9040 | fpr=0.0222 | 7870.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.13577 | acc=0.9761 | tpr=0.9036 | fpr=0.0226 | 7889.0 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.13726 | acc=0.9759 | tpr=0.8999 | fpr=0.0227 | 7908.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13990 | acc=0.9754 | tpr=0.8968 | fpr=0.0232 | 7627.4 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.13819 | acc=0.9756 | tpr=0.9004 | fpr=0.0231 | 8072.5 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.13771 | acc=0.9756 | tpr=0.8989 | fpr=0.0230 | 14056.1 samples/s | 54.9 steps/s
Avg test loss: 0.13750, Avg test acc: 0.97565, Avg tpr: 0.89857, Avg fpr: 0.02295, total FA: 3187

server round 6/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=58.5] | Loss=0.09560 | Reg=0.00497 | acc=0.9219 | L2-Norm=22.284 | L2-Norm(final)=6.007 | 5608.8 samples/s | 87.6 steps/s
[Step=12050 Epoch=58.8] | Loss=0.03621 | Reg=0.00497 | acc=0.9688 | L2-Norm=22.299 | L2-Norm(final)=6.024 | 4615.5 samples/s | 72.1 steps/s
[Step=12100 Epoch=59.0] | Loss=0.03578 | Reg=0.00498 | acc=0.9688 | L2-Norm=22.325 | L2-Norm(final)=6.052 | 5061.5 samples/s | 79.1 steps/s
[Step=12150 Epoch=59.2] | Loss=0.03491 | Reg=0.00500 | acc=0.9688 | L2-Norm=22.357 | L2-Norm(final)=6.080 | 4936.5 samples/s | 77.1 steps/s
[Step=12200 Epoch=59.5] | Loss=0.03476 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.390 | L2-Norm(final)=6.110 | 7756.7 samples/s | 121.2 steps/s
[Step=12250 Epoch=59.7] | Loss=0.03252 | Reg=0.00503 | acc=0.9531 | L2-Norm=22.428 | L2-Norm(final)=6.146 | 2271.7 samples/s | 35.5 steps/s
[Step=12300 Epoch=60.0] | Loss=0.03147 | Reg=0.00505 | acc=0.9844 | L2-Norm=22.463 | L2-Norm(final)=6.184 | 4919.4 samples/s | 76.9 steps/s
[Step=12350 Epoch=60.2] | Loss=0.03079 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.496 | L2-Norm(final)=6.222 | 4947.5 samples/s | 77.3 steps/s
[Step=12400 Epoch=60.5] | Loss=0.02959 | Reg=0.00508 | acc=0.9688 | L2-Norm=22.528 | L2-Norm(final)=6.261 | 7038.0 samples/s | 110.0 steps/s
[Step=12450 Epoch=60.7] | Loss=0.02855 | Reg=0.00509 | acc=0.9688 | L2-Norm=22.560 | L2-Norm(final)=6.301 | 2313.4 samples/s | 36.1 steps/s
[Step=12500 Epoch=61.0] | Loss=0.02749 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.592 | L2-Norm(final)=6.342 | 5107.2 samples/s | 79.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=61.0] | Loss=0.02700 | Reg=0.00525 | acc=0.9844 | L2-Norm=22.904 | L2-Norm(final)=6.766 | 5474.4 samples/s | 85.5 steps/s
[Step=12550 Epoch=61.2] | Loss=0.02842 | Reg=0.00526 | acc=0.9219 | L2-Norm=22.942 | L2-Norm(final)=6.797 | 4024.2 samples/s | 62.9 steps/s
[Step=12600 Epoch=61.4] | Loss=0.05302 | Reg=0.00530 | acc=0.9062 | L2-Norm=23.029 | L2-Norm(final)=6.772 | 4565.8 samples/s | 71.3 steps/s
[Step=12650 Epoch=61.7] | Loss=0.05293 | Reg=0.00534 | acc=0.9688 | L2-Norm=23.100 | L2-Norm(final)=6.745 | 4466.4 samples/s | 69.8 steps/s
[Step=12700 Epoch=61.9] | Loss=0.05309 | Reg=0.00536 | acc=0.9531 | L2-Norm=23.155 | L2-Norm(final)=6.724 | 6341.3 samples/s | 99.1 steps/s
[Step=12750 Epoch=62.2] | Loss=0.04793 | Reg=0.00538 | acc=0.9688 | L2-Norm=23.199 | L2-Norm(final)=6.715 | 2082.1 samples/s | 32.5 steps/s
[Step=12800 Epoch=62.4] | Loss=0.04476 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.233 | L2-Norm(final)=6.708 | 4493.5 samples/s | 70.2 steps/s
[Step=12850 Epoch=62.7] | Loss=0.04328 | Reg=0.00541 | acc=0.9531 | L2-Norm=23.261 | L2-Norm(final)=6.703 | 4493.7 samples/s | 70.2 steps/s
[Step=12900 Epoch=62.9] | Loss=0.04221 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.287 | L2-Norm(final)=6.696 | 5851.9 samples/s | 91.4 steps/s
[Step=12950 Epoch=63.1] | Loss=0.03960 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.309 | L2-Norm(final)=6.690 | 2159.4 samples/s | 33.7 steps/s
[Step=13000 Epoch=63.4] | Loss=0.03771 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.327 | L2-Norm(final)=6.685 | 4518.0 samples/s | 70.6 steps/s
[Step=13050 Epoch=63.6] | Loss=0.03622 | Reg=0.00545 | acc=0.9688 | L2-Norm=23.343 | L2-Norm(final)=6.680 | 4489.4 samples/s | 70.1 steps/s
[Step=13100 Epoch=63.9] | Loss=0.03513 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.357 | L2-Norm(final)=6.677 | 5372.4 samples/s | 83.9 steps/s
[Step=13150 Epoch=64.1] | Loss=0.03349 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.370 | L2-Norm(final)=6.674 | 2287.9 samples/s | 35.7 steps/s
[Step=13200 Epoch=64.4] | Loss=0.03207 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.379 | L2-Norm(final)=6.672 | 4360.4 samples/s | 68.1 steps/s
[Step=13250 Epoch=64.6] | Loss=0.03078 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.387 | L2-Norm(final)=6.671 | 4483.3 samples/s | 70.1 steps/s
[Step=13300 Epoch=64.9] | Loss=0.02990 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.393 | L2-Norm(final)=6.669 | 4979.4 samples/s | 77.8 steps/s
[Step=13350 Epoch=65.1] | Loss=0.02876 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.397 | L2-Norm(final)=6.669 | 2340.3 samples/s | 36.6 steps/s
[Step=13400 Epoch=65.3] | Loss=0.02787 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.399 | L2-Norm(final)=6.668 | 4551.9 samples/s | 71.1 steps/s
[Step=13450 Epoch=65.6] | Loss=0.02700 | Reg=0.00548 | acc=0.9531 | L2-Norm=23.401 | L2-Norm(final)=6.667 | 4465.3 samples/s | 69.8 steps/s
[Step=13500 Epoch=65.8] | Loss=0.02626 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.402 | L2-Norm(final)=6.668 | 4558.9 samples/s | 71.2 steps/s
[Step=13550 Epoch=66.1] | Loss=0.02578 | Reg=0.00548 | acc=0.9844 | L2-Norm=23.403 | L2-Norm(final)=6.667 | 2414.8 samples/s | 37.7 steps/s
[Step=13600 Epoch=66.3] | Loss=0.02493 | Reg=0.00548 | acc=0.9844 | L2-Norm=23.403 | L2-Norm(final)=6.667 | 4444.3 samples/s | 69.4 steps/s
[Step=13650 Epoch=66.6] | Loss=0.02413 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.401 | L2-Norm(final)=6.667 | 4485.9 samples/s | 70.1 steps/s
[Step=13700 Epoch=66.8] | Loss=0.02369 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.398 | L2-Norm(final)=6.668 | 4510.3 samples/s | 70.5 steps/s
[Step=13750 Epoch=67.0] | Loss=0.02315 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.396 | L2-Norm(final)=6.668 | 2462.3 samples/s | 38.5 steps/s
[Step=13800 Epoch=67.3] | Loss=0.02262 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.393 | L2-Norm(final)=6.669 | 4481.4 samples/s | 70.0 steps/s
[Step=13850 Epoch=67.5] | Loss=0.02206 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.389 | L2-Norm(final)=6.669 | 4511.0 samples/s | 70.5 steps/s
[Step=13900 Epoch=67.8] | Loss=0.02156 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.384 | L2-Norm(final)=6.670 | 4528.1 samples/s | 70.8 steps/s
[Step=13950 Epoch=68.0] | Loss=0.02112 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.379 | L2-Norm(final)=6.671 | 2436.6 samples/s | 38.1 steps/s
[Step=14000 Epoch=68.3] | Loss=0.02081 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.374 | L2-Norm(final)=6.671 | 4454.1 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step14000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=58.6] | Loss=0.07186 | Reg=0.00486 | acc=0.9219 | L2-Norm=22.051 | L2-Norm(final)=6.107 | 5375.4 samples/s | 84.0 steps/s
[Step=12050 Epoch=58.8] | Loss=0.03721 | Reg=0.00487 | acc=1.0000 | L2-Norm=22.072 | L2-Norm(final)=6.124 | 4194.5 samples/s | 65.5 steps/s
[Step=12100 Epoch=59.0] | Loss=0.03400 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.099 | L2-Norm(final)=6.163 | 5112.6 samples/s | 79.9 steps/s
[Step=12150 Epoch=59.3] | Loss=0.03245 | Reg=0.00490 | acc=1.0000 | L2-Norm=22.130 | L2-Norm(final)=6.204 | 4975.1 samples/s | 77.7 steps/s
[Step=12200 Epoch=59.5] | Loss=0.03174 | Reg=0.00491 | acc=1.0000 | L2-Norm=22.161 | L2-Norm(final)=6.240 | 7877.7 samples/s | 123.1 steps/s
[Step=12250 Epoch=59.8] | Loss=0.02997 | Reg=0.00492 | acc=0.9531 | L2-Norm=22.192 | L2-Norm(final)=6.277 | 2234.1 samples/s | 34.9 steps/s
[Step=12300 Epoch=60.0] | Loss=0.02874 | Reg=0.00494 | acc=1.0000 | L2-Norm=22.222 | L2-Norm(final)=6.315 | 4973.7 samples/s | 77.7 steps/s
[Step=12350 Epoch=60.3] | Loss=0.02806 | Reg=0.00495 | acc=0.9688 | L2-Norm=22.255 | L2-Norm(final)=6.355 | 5069.4 samples/s | 79.2 steps/s
[Step=12400 Epoch=60.5] | Loss=0.02693 | Reg=0.00497 | acc=0.9844 | L2-Norm=22.288 | L2-Norm(final)=6.397 | 7029.6 samples/s | 109.8 steps/s
[Step=12450 Epoch=60.8] | Loss=0.02585 | Reg=0.00498 | acc=0.9844 | L2-Norm=22.321 | L2-Norm(final)=6.438 | 2272.6 samples/s | 35.5 steps/s
[Step=12500 Epoch=61.0] | Loss=0.02485 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.354 | L2-Norm(final)=6.481 | 5022.8 samples/s | 78.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=61.0] | Loss=0.02212 | Reg=0.00514 | acc=0.9844 | L2-Norm=22.664 | L2-Norm(final)=6.914 | 5270.4 samples/s | 82.4 steps/s
[Step=12550 Epoch=61.2] | Loss=0.02576 | Reg=0.00515 | acc=0.9688 | L2-Norm=22.691 | L2-Norm(final)=6.941 | 4083.9 samples/s | 63.8 steps/s
[Step=12600 Epoch=61.5] | Loss=0.04229 | Reg=0.00518 | acc=0.9375 | L2-Norm=22.762 | L2-Norm(final)=6.923 | 4479.4 samples/s | 70.0 steps/s
[Step=12650 Epoch=61.7] | Loss=0.04619 | Reg=0.00522 | acc=0.9844 | L2-Norm=22.840 | L2-Norm(final)=6.898 | 4406.6 samples/s | 68.9 steps/s
[Step=12700 Epoch=62.0] | Loss=0.04557 | Reg=0.00525 | acc=0.9688 | L2-Norm=22.905 | L2-Norm(final)=6.879 | 6491.0 samples/s | 101.4 steps/s
[Step=12750 Epoch=62.2] | Loss=0.04196 | Reg=0.00527 | acc=0.9531 | L2-Norm=22.955 | L2-Norm(final)=6.865 | 2077.3 samples/s | 32.5 steps/s
[Step=12800 Epoch=62.5] | Loss=0.03977 | Reg=0.00529 | acc=0.9688 | L2-Norm=22.996 | L2-Norm(final)=6.855 | 4530.4 samples/s | 70.8 steps/s
[Step=12850 Epoch=62.7] | Loss=0.03990 | Reg=0.00531 | acc=0.9531 | L2-Norm=23.032 | L2-Norm(final)=6.844 | 4406.0 samples/s | 68.8 steps/s
[Step=12900 Epoch=62.9] | Loss=0.03892 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.066 | L2-Norm(final)=6.834 | 6053.9 samples/s | 94.6 steps/s
[Step=12950 Epoch=63.2] | Loss=0.03694 | Reg=0.00534 | acc=0.9688 | L2-Norm=23.098 | L2-Norm(final)=6.826 | 2167.9 samples/s | 33.9 steps/s
[Step=13000 Epoch=63.4] | Loss=0.03551 | Reg=0.00535 | acc=0.9531 | L2-Norm=23.126 | L2-Norm(final)=6.820 | 4468.3 samples/s | 69.8 steps/s
[Step=13050 Epoch=63.7] | Loss=0.03499 | Reg=0.00536 | acc=0.9844 | L2-Norm=23.153 | L2-Norm(final)=6.812 | 4481.1 samples/s | 70.0 steps/s
[Step=13100 Epoch=63.9] | Loss=0.03396 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.178 | L2-Norm(final)=6.806 | 5586.0 samples/s | 87.3 steps/s
[Step=13150 Epoch=64.2] | Loss=0.03234 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.201 | L2-Norm(final)=6.801 | 2246.8 samples/s | 35.1 steps/s
[Step=13200 Epoch=64.4] | Loss=0.03097 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.221 | L2-Norm(final)=6.797 | 4365.4 samples/s | 68.2 steps/s
[Step=13250 Epoch=64.7] | Loss=0.02993 | Reg=0.00540 | acc=0.9844 | L2-Norm=23.237 | L2-Norm(final)=6.794 | 4470.7 samples/s | 69.9 steps/s
[Step=13300 Epoch=64.9] | Loss=0.02915 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.251 | L2-Norm(final)=6.790 | 5191.7 samples/s | 81.1 steps/s
[Step=13350 Epoch=65.1] | Loss=0.02824 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=6.787 | 2270.5 samples/s | 35.5 steps/s
[Step=13400 Epoch=65.4] | Loss=0.02724 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.271 | L2-Norm(final)=6.785 | 4480.1 samples/s | 70.0 steps/s
[Step=13450 Epoch=65.6] | Loss=0.02630 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.278 | L2-Norm(final)=6.784 | 4433.8 samples/s | 69.3 steps/s
[Step=13500 Epoch=65.9] | Loss=0.02581 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.284 | L2-Norm(final)=6.782 | 4906.3 samples/s | 76.7 steps/s
[Step=13550 Epoch=66.1] | Loss=0.02496 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.288 | L2-Norm(final)=6.780 | 2372.7 samples/s | 37.1 steps/s
[Step=13600 Epoch=66.4] | Loss=0.02431 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.292 | L2-Norm(final)=6.779 | 4365.7 samples/s | 68.2 steps/s
[Step=13650 Epoch=66.6] | Loss=0.02369 | Reg=0.00543 | acc=0.9688 | L2-Norm=23.296 | L2-Norm(final)=6.778 | 4459.8 samples/s | 69.7 steps/s
[Step=13700 Epoch=66.8] | Loss=0.02316 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.299 | L2-Norm(final)=6.778 | 4560.7 samples/s | 71.3 steps/s
[Step=13750 Epoch=67.1] | Loss=0.02270 | Reg=0.00543 | acc=0.9844 | L2-Norm=23.301 | L2-Norm(final)=6.778 | 2448.1 samples/s | 38.3 steps/s
[Step=13800 Epoch=67.3] | Loss=0.02220 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.302 | L2-Norm(final)=6.777 | 4546.3 samples/s | 71.0 steps/s
[Step=13850 Epoch=67.6] | Loss=0.02159 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.303 | L2-Norm(final)=6.777 | 4420.3 samples/s | 69.1 steps/s
[Step=13900 Epoch=67.8] | Loss=0.02119 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.303 | L2-Norm(final)=6.777 | 4466.2 samples/s | 69.8 steps/s
[Step=13950 Epoch=68.1] | Loss=0.02098 | Reg=0.00543 | acc=0.9688 | L2-Norm=23.303 | L2-Norm(final)=6.776 | 2514.7 samples/s | 39.3 steps/s
[Step=14000 Epoch=68.3] | Loss=0.02075 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.305 | L2-Norm(final)=6.775 | 4359.0 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step14000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=58.5] | Loss=0.06852 | Reg=0.00489 | acc=0.9375 | L2-Norm=22.122 | L2-Norm(final)=6.362 | 5317.0 samples/s | 83.1 steps/s
[Step=12050 Epoch=58.7] | Loss=0.03112 | Reg=0.00490 | acc=0.9844 | L2-Norm=22.136 | L2-Norm(final)=6.382 | 4360.0 samples/s | 68.1 steps/s
[Step=12100 Epoch=59.0] | Loss=0.02943 | Reg=0.00491 | acc=0.9531 | L2-Norm=22.163 | L2-Norm(final)=6.420 | 4988.8 samples/s | 77.9 steps/s
[Step=12150 Epoch=59.2] | Loss=0.02977 | Reg=0.00493 | acc=0.9844 | L2-Norm=22.193 | L2-Norm(final)=6.459 | 5168.0 samples/s | 80.8 steps/s
[Step=12200 Epoch=59.4] | Loss=0.02971 | Reg=0.00494 | acc=0.9531 | L2-Norm=22.226 | L2-Norm(final)=6.497 | 7652.0 samples/s | 119.6 steps/s
[Step=12250 Epoch=59.7] | Loss=0.02854 | Reg=0.00495 | acc=0.9688 | L2-Norm=22.260 | L2-Norm(final)=6.539 | 2217.3 samples/s | 34.6 steps/s
[Step=12300 Epoch=59.9] | Loss=0.02754 | Reg=0.00497 | acc=1.0000 | L2-Norm=22.292 | L2-Norm(final)=6.583 | 5053.8 samples/s | 79.0 steps/s
[Step=12350 Epoch=60.2] | Loss=0.02674 | Reg=0.00498 | acc=0.9844 | L2-Norm=22.324 | L2-Norm(final)=6.629 | 5070.4 samples/s | 79.2 steps/s
[Step=12400 Epoch=60.4] | Loss=0.02596 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.356 | L2-Norm(final)=6.675 | 7001.9 samples/s | 109.4 steps/s
[Step=12450 Epoch=60.7] | Loss=0.02499 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.389 | L2-Norm(final)=6.720 | 2310.9 samples/s | 36.1 steps/s
[Step=12500 Epoch=60.9] | Loss=0.02422 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.420 | L2-Norm(final)=6.766 | 5083.1 samples/s | 79.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=60.9] | Loss=0.01168 | Reg=0.00517 | acc=1.0000 | L2-Norm=22.737 | L2-Norm(final)=7.228 | 5414.3 samples/s | 84.6 steps/s
[Step=12550 Epoch=61.1] | Loss=0.03111 | Reg=0.00519 | acc=0.9531 | L2-Norm=22.786 | L2-Norm(final)=7.253 | 3955.6 samples/s | 61.8 steps/s
[Step=12600 Epoch=61.4] | Loss=0.04172 | Reg=0.00523 | acc=0.9531 | L2-Norm=22.862 | L2-Norm(final)=7.243 | 4567.9 samples/s | 71.4 steps/s
[Step=12650 Epoch=61.6] | Loss=0.04684 | Reg=0.00527 | acc=0.9219 | L2-Norm=22.947 | L2-Norm(final)=7.227 | 4402.3 samples/s | 68.8 steps/s
[Step=12700 Epoch=61.9] | Loss=0.04815 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.019 | L2-Norm(final)=7.208 | 6605.2 samples/s | 103.2 steps/s
[Step=12750 Epoch=62.1] | Loss=0.04654 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.080 | L2-Norm(final)=7.194 | 2119.7 samples/s | 33.1 steps/s
[Step=12800 Epoch=62.4] | Loss=0.04360 | Reg=0.00535 | acc=0.9688 | L2-Norm=23.129 | L2-Norm(final)=7.187 | 4474.7 samples/s | 69.9 steps/s
[Step=12850 Epoch=62.6] | Loss=0.04162 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.170 | L2-Norm(final)=7.180 | 4528.2 samples/s | 70.8 steps/s
[Step=12900 Epoch=62.9] | Loss=0.04025 | Reg=0.00539 | acc=0.9531 | L2-Norm=23.207 | L2-Norm(final)=7.174 | 5850.2 samples/s | 91.4 steps/s
[Step=12950 Epoch=63.1] | Loss=0.03821 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.239 | L2-Norm(final)=7.169 | 2179.8 samples/s | 34.1 steps/s
[Step=13000 Epoch=63.3] | Loss=0.03618 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.265 | L2-Norm(final)=7.166 | 4443.9 samples/s | 69.4 steps/s
[Step=13050 Epoch=63.6] | Loss=0.03484 | Reg=0.00542 | acc=0.9688 | L2-Norm=23.286 | L2-Norm(final)=7.164 | 4491.3 samples/s | 70.2 steps/s
[Step=13100 Epoch=63.8] | Loss=0.03343 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.306 | L2-Norm(final)=7.162 | 5418.5 samples/s | 84.7 steps/s
[Step=13150 Epoch=64.1] | Loss=0.03227 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.324 | L2-Norm(final)=7.160 | 2274.1 samples/s | 35.5 steps/s
[Step=13200 Epoch=64.3] | Loss=0.03119 | Reg=0.00545 | acc=0.9844 | L2-Norm=23.341 | L2-Norm(final)=7.159 | 4514.2 samples/s | 70.5 steps/s
[Step=13250 Epoch=64.6] | Loss=0.03020 | Reg=0.00546 | acc=0.9688 | L2-Norm=23.355 | L2-Norm(final)=7.158 | 4559.4 samples/s | 71.2 steps/s
[Step=13300 Epoch=64.8] | Loss=0.02927 | Reg=0.00546 | acc=0.9844 | L2-Norm=23.369 | L2-Norm(final)=7.157 | 4860.2 samples/s | 75.9 steps/s
[Step=13350 Epoch=65.0] | Loss=0.02814 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.381 | L2-Norm(final)=7.157 | 2314.9 samples/s | 36.2 steps/s
[Step=13400 Epoch=65.3] | Loss=0.02767 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.390 | L2-Norm(final)=7.157 | 4479.9 samples/s | 70.0 steps/s
[Step=13450 Epoch=65.5] | Loss=0.02717 | Reg=0.00548 | acc=0.9688 | L2-Norm=23.400 | L2-Norm(final)=7.156 | 4474.8 samples/s | 69.9 steps/s
[Step=13500 Epoch=65.8] | Loss=0.02664 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.409 | L2-Norm(final)=7.155 | 4616.1 samples/s | 72.1 steps/s
[Step=13550 Epoch=66.0] | Loss=0.02599 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.417 | L2-Norm(final)=7.155 | 2423.0 samples/s | 37.9 steps/s
[Step=13600 Epoch=66.3] | Loss=0.02533 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.424 | L2-Norm(final)=7.154 | 4510.6 samples/s | 70.5 steps/s
[Step=13650 Epoch=66.5] | Loss=0.02478 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.430 | L2-Norm(final)=7.154 | 4510.5 samples/s | 70.5 steps/s
[Step=13700 Epoch=66.8] | Loss=0.02441 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.435 | L2-Norm(final)=7.153 | 4427.1 samples/s | 69.2 steps/s
[Step=13750 Epoch=67.0] | Loss=0.02410 | Reg=0.00549 | acc=0.9688 | L2-Norm=23.440 | L2-Norm(final)=7.152 | 2464.1 samples/s | 38.5 steps/s
[Step=13800 Epoch=67.2] | Loss=0.02362 | Reg=0.00550 | acc=0.9688 | L2-Norm=23.444 | L2-Norm(final)=7.151 | 4595.1 samples/s | 71.8 steps/s
[Step=13850 Epoch=67.5] | Loss=0.02309 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.447 | L2-Norm(final)=7.150 | 4453.0 samples/s | 69.6 steps/s
[Step=13900 Epoch=67.7] | Loss=0.02272 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.450 | L2-Norm(final)=7.149 | 4517.5 samples/s | 70.6 steps/s
[Step=13950 Epoch=68.0] | Loss=0.02273 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.454 | L2-Norm(final)=7.148 | 2417.2 samples/s | 37.8 steps/s
[Step=14000 Epoch=68.2] | Loss=0.02267 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.459 | L2-Norm(final)=7.147 | 4483.5 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step14000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=58.5] | Loss=0.06568 | Reg=0.00483 | acc=0.9375 | L2-Norm=21.973 | L2-Norm(final)=6.136 | 4743.6 samples/s | 74.1 steps/s
[Step=12050 Epoch=58.8] | Loss=0.04450 | Reg=0.00484 | acc=0.9844 | L2-Norm=21.995 | L2-Norm(final)=6.163 | 4727.7 samples/s | 73.9 steps/s
[Step=12100 Epoch=59.0] | Loss=0.04167 | Reg=0.00485 | acc=1.0000 | L2-Norm=22.027 | L2-Norm(final)=6.203 | 5088.7 samples/s | 79.5 steps/s
[Step=12150 Epoch=59.3] | Loss=0.03759 | Reg=0.00487 | acc=0.9688 | L2-Norm=22.063 | L2-Norm(final)=6.242 | 5058.6 samples/s | 79.0 steps/s
[Step=12200 Epoch=59.5] | Loss=0.03592 | Reg=0.00488 | acc=0.9844 | L2-Norm=22.100 | L2-Norm(final)=6.279 | 7864.5 samples/s | 122.9 steps/s
[Step=12250 Epoch=59.7] | Loss=0.03369 | Reg=0.00490 | acc=0.9844 | L2-Norm=22.137 | L2-Norm(final)=6.317 | 2245.0 samples/s | 35.1 steps/s
[Step=12300 Epoch=60.0] | Loss=0.03239 | Reg=0.00492 | acc=0.9688 | L2-Norm=22.176 | L2-Norm(final)=6.357 | 5221.4 samples/s | 81.6 steps/s
[Step=12350 Epoch=60.2] | Loss=0.03146 | Reg=0.00493 | acc=0.9688 | L2-Norm=22.212 | L2-Norm(final)=6.397 | 4827.5 samples/s | 75.4 steps/s
[Step=12400 Epoch=60.5] | Loss=0.03077 | Reg=0.00495 | acc=0.9844 | L2-Norm=22.247 | L2-Norm(final)=6.437 | 7025.1 samples/s | 109.8 steps/s
[Step=12450 Epoch=60.7] | Loss=0.02945 | Reg=0.00496 | acc=1.0000 | L2-Norm=22.281 | L2-Norm(final)=6.479 | 2279.7 samples/s | 35.6 steps/s
[Step=12500 Epoch=61.0] | Loss=0.02859 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.314 | L2-Norm(final)=6.523 | 5180.1 samples/s | 80.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=61.0] | Loss=0.01630 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.646 | L2-Norm(final)=6.969 | 5375.2 samples/s | 84.0 steps/s
[Step=12550 Epoch=61.2] | Loss=0.03457 | Reg=0.00515 | acc=1.0000 | L2-Norm=22.697 | L2-Norm(final)=6.995 | 3997.6 samples/s | 62.5 steps/s
[Step=12600 Epoch=61.4] | Loss=0.03813 | Reg=0.00518 | acc=0.9688 | L2-Norm=22.770 | L2-Norm(final)=6.991 | 4471.5 samples/s | 69.9 steps/s
[Step=12650 Epoch=61.7] | Loss=0.04374 | Reg=0.00522 | acc=0.9375 | L2-Norm=22.842 | L2-Norm(final)=6.974 | 4456.6 samples/s | 69.6 steps/s
[Step=12700 Epoch=61.9] | Loss=0.04689 | Reg=0.00525 | acc=0.9844 | L2-Norm=22.909 | L2-Norm(final)=6.952 | 6594.9 samples/s | 103.0 steps/s
[Step=12750 Epoch=62.2] | Loss=0.04420 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.967 | L2-Norm(final)=6.934 | 2108.8 samples/s | 33.0 steps/s
[Step=12800 Epoch=62.4] | Loss=0.04178 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.012 | L2-Norm(final)=6.922 | 4424.2 samples/s | 69.1 steps/s
[Step=12850 Epoch=62.7] | Loss=0.04023 | Reg=0.00531 | acc=0.9688 | L2-Norm=23.048 | L2-Norm(final)=6.914 | 4540.2 samples/s | 70.9 steps/s
[Step=12900 Epoch=62.9] | Loss=0.03887 | Reg=0.00533 | acc=0.9844 | L2-Norm=23.078 | L2-Norm(final)=6.906 | 5851.7 samples/s | 91.4 steps/s
[Step=12950 Epoch=63.2] | Loss=0.03692 | Reg=0.00534 | acc=0.9688 | L2-Norm=23.105 | L2-Norm(final)=6.899 | 2178.3 samples/s | 34.0 steps/s
[Step=13000 Epoch=63.4] | Loss=0.03535 | Reg=0.00535 | acc=0.9844 | L2-Norm=23.128 | L2-Norm(final)=6.893 | 4488.6 samples/s | 70.1 steps/s
[Step=13050 Epoch=63.6] | Loss=0.03440 | Reg=0.00536 | acc=0.9688 | L2-Norm=23.147 | L2-Norm(final)=6.887 | 4502.6 samples/s | 70.4 steps/s
[Step=13100 Epoch=63.9] | Loss=0.03328 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.166 | L2-Norm(final)=6.882 | 5411.8 samples/s | 84.6 steps/s
[Step=13150 Epoch=64.1] | Loss=0.03181 | Reg=0.00538 | acc=0.9531 | L2-Norm=23.183 | L2-Norm(final)=6.877 | 2244.2 samples/s | 35.1 steps/s
[Step=13200 Epoch=64.4] | Loss=0.03076 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.199 | L2-Norm(final)=6.873 | 4522.2 samples/s | 70.7 steps/s
[Step=13250 Epoch=64.6] | Loss=0.02975 | Reg=0.00539 | acc=0.9688 | L2-Norm=23.213 | L2-Norm(final)=6.869 | 4347.6 samples/s | 67.9 steps/s
[Step=13300 Epoch=64.9] | Loss=0.02890 | Reg=0.00539 | acc=0.9688 | L2-Norm=23.223 | L2-Norm(final)=6.866 | 5020.8 samples/s | 78.4 steps/s
[Step=13350 Epoch=65.1] | Loss=0.02830 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.233 | L2-Norm(final)=6.862 | 2336.5 samples/s | 36.5 steps/s
[Step=13400 Epoch=65.3] | Loss=0.02730 | Reg=0.00540 | acc=0.9844 | L2-Norm=23.243 | L2-Norm(final)=6.859 | 4308.1 samples/s | 67.3 steps/s
[Step=13450 Epoch=65.6] | Loss=0.02663 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.251 | L2-Norm(final)=6.857 | 4401.5 samples/s | 68.8 steps/s
[Step=13500 Epoch=65.8] | Loss=0.02594 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.258 | L2-Norm(final)=6.855 | 4551.8 samples/s | 71.1 steps/s
[Step=13550 Epoch=66.1] | Loss=0.02574 | Reg=0.00541 | acc=0.9688 | L2-Norm=23.266 | L2-Norm(final)=6.853 | 2376.2 samples/s | 37.1 steps/s
[Step=13600 Epoch=66.3] | Loss=0.02634 | Reg=0.00542 | acc=0.9688 | L2-Norm=23.279 | L2-Norm(final)=6.850 | 4549.0 samples/s | 71.1 steps/s
[Step=13650 Epoch=66.6] | Loss=0.02640 | Reg=0.00543 | acc=0.9844 | L2-Norm=23.293 | L2-Norm(final)=6.847 | 4174.5 samples/s | 65.2 steps/s
[Step=13700 Epoch=66.8] | Loss=0.02629 | Reg=0.00543 | acc=0.9844 | L2-Norm=23.308 | L2-Norm(final)=6.843 | 4224.0 samples/s | 66.0 steps/s
[Step=13750 Epoch=67.1] | Loss=0.02605 | Reg=0.00544 | acc=0.9844 | L2-Norm=23.321 | L2-Norm(final)=6.839 | 2421.7 samples/s | 37.8 steps/s
[Step=13800 Epoch=67.3] | Loss=0.02564 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.335 | L2-Norm(final)=6.835 | 4465.7 samples/s | 69.8 steps/s
[Step=13850 Epoch=67.5] | Loss=0.02536 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.347 | L2-Norm(final)=6.832 | 4370.8 samples/s | 68.3 steps/s
[Step=13900 Epoch=67.8] | Loss=0.02497 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.359 | L2-Norm(final)=6.829 | 4427.4 samples/s | 69.2 steps/s
[Step=13950 Epoch=68.0] | Loss=0.02447 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.370 | L2-Norm(final)=6.826 | 2421.7 samples/s | 37.8 steps/s
[Step=14000 Epoch=68.3] | Loss=0.02397 | Reg=0.00547 | acc=0.9688 | L2-Norm=23.380 | L2-Norm(final)=6.824 | 4412.0 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step14000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=58.9] | Loss=0.05333 | Reg=0.00494 | acc=0.9375 | L2-Norm=22.230 | L2-Norm(final)=6.657 | 5035.1 samples/s | 78.7 steps/s
[Step=12050 Epoch=59.1] | Loss=0.03779 | Reg=0.00495 | acc=0.9375 | L2-Norm=22.252 | L2-Norm(final)=6.680 | 4647.4 samples/s | 72.6 steps/s
[Step=12100 Epoch=59.3] | Loss=0.03223 | Reg=0.00497 | acc=0.9531 | L2-Norm=22.286 | L2-Norm(final)=6.718 | 5161.2 samples/s | 80.6 steps/s
[Step=12150 Epoch=59.6] | Loss=0.03107 | Reg=0.00498 | acc=0.9844 | L2-Norm=22.317 | L2-Norm(final)=6.755 | 4841.0 samples/s | 75.6 steps/s
[Step=12200 Epoch=59.8] | Loss=0.02916 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.349 | L2-Norm(final)=6.790 | 8066.9 samples/s | 126.0 steps/s
[Step=12250 Epoch=60.1] | Loss=0.02729 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.377 | L2-Norm(final)=6.827 | 2158.8 samples/s | 33.7 steps/s
[Step=12300 Epoch=60.3] | Loss=0.02580 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.407 | L2-Norm(final)=6.866 | 5031.1 samples/s | 78.6 steps/s
[Step=12350 Epoch=60.6] | Loss=0.02472 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.436 | L2-Norm(final)=6.906 | 5041.1 samples/s | 78.8 steps/s
[Step=12400 Epoch=60.8] | Loss=0.02414 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.464 | L2-Norm(final)=6.946 | 7163.6 samples/s | 111.9 steps/s
[Step=12450 Epoch=61.1] | Loss=0.02324 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.492 | L2-Norm(final)=6.986 | 2249.2 samples/s | 35.1 steps/s
[Step=12500 Epoch=61.3] | Loss=0.02235 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.520 | L2-Norm(final)=7.026 | 4970.1 samples/s | 77.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=61.3] | Loss=0.01556 | Reg=0.00519 | acc=1.0000 | L2-Norm=22.790 | L2-Norm(final)=7.438 | 5962.2 samples/s | 93.2 steps/s
[Step=12550 Epoch=61.5] | Loss=0.02648 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.831 | L2-Norm(final)=7.465 | 3701.6 samples/s | 57.8 steps/s
[Step=12600 Epoch=61.8] | Loss=0.04838 | Reg=0.00525 | acc=0.9688 | L2-Norm=22.921 | L2-Norm(final)=7.444 | 4470.2 samples/s | 69.8 steps/s
[Step=12650 Epoch=62.0] | Loss=0.05181 | Reg=0.00529 | acc=0.9531 | L2-Norm=23.006 | L2-Norm(final)=7.413 | 4387.5 samples/s | 68.6 steps/s
[Step=12700 Epoch=62.3] | Loss=0.05090 | Reg=0.00532 | acc=0.9688 | L2-Norm=23.070 | L2-Norm(final)=7.391 | 6651.5 samples/s | 103.9 steps/s
[Step=12750 Epoch=62.5] | Loss=0.04720 | Reg=0.00535 | acc=0.9531 | L2-Norm=23.123 | L2-Norm(final)=7.376 | 2058.0 samples/s | 32.2 steps/s
[Step=12800 Epoch=62.8] | Loss=0.04390 | Reg=0.00537 | acc=0.9531 | L2-Norm=23.165 | L2-Norm(final)=7.364 | 4407.0 samples/s | 68.9 steps/s
[Step=12850 Epoch=63.0] | Loss=0.04175 | Reg=0.00538 | acc=0.9375 | L2-Norm=23.199 | L2-Norm(final)=7.356 | 4400.5 samples/s | 68.8 steps/s
[Step=12900 Epoch=63.3] | Loss=0.03962 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.228 | L2-Norm(final)=7.349 | 6235.6 samples/s | 97.4 steps/s
[Step=12950 Epoch=63.5] | Loss=0.03673 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.251 | L2-Norm(final)=7.343 | 2110.4 samples/s | 33.0 steps/s
[Step=13000 Epoch=63.7] | Loss=0.03472 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.271 | L2-Norm(final)=7.341 | 4298.5 samples/s | 67.2 steps/s
[Step=13050 Epoch=64.0] | Loss=0.03323 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.289 | L2-Norm(final)=7.339 | 4426.4 samples/s | 69.2 steps/s
[Step=13100 Epoch=64.2] | Loss=0.03171 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.303 | L2-Norm(final)=7.336 | 5783.8 samples/s | 90.4 steps/s
[Step=13150 Epoch=64.5] | Loss=0.03115 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.317 | L2-Norm(final)=7.333 | 2148.0 samples/s | 33.6 steps/s
[Step=13200 Epoch=64.7] | Loss=0.02984 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.328 | L2-Norm(final)=7.330 | 4485.2 samples/s | 70.1 steps/s
[Step=13250 Epoch=65.0] | Loss=0.02859 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.338 | L2-Norm(final)=7.328 | 4402.9 samples/s | 68.8 steps/s
[Step=13300 Epoch=65.2] | Loss=0.02792 | Reg=0.00545 | acc=0.9844 | L2-Norm=23.346 | L2-Norm(final)=7.326 | 5436.5 samples/s | 84.9 steps/s
[Step=13350 Epoch=65.5] | Loss=0.02705 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.353 | L2-Norm(final)=7.324 | 2162.5 samples/s | 33.8 steps/s
[Step=13400 Epoch=65.7] | Loss=0.02630 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.359 | L2-Norm(final)=7.323 | 4451.9 samples/s | 69.6 steps/s
[Step=13450 Epoch=66.0] | Loss=0.02559 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.364 | L2-Norm(final)=7.321 | 4421.8 samples/s | 69.1 steps/s
[Step=13500 Epoch=66.2] | Loss=0.02509 | Reg=0.00546 | acc=0.9844 | L2-Norm=23.369 | L2-Norm(final)=7.320 | 5152.3 samples/s | 80.5 steps/s
[Step=13550 Epoch=66.4] | Loss=0.02465 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.375 | L2-Norm(final)=7.319 | 2259.7 samples/s | 35.3 steps/s
[Step=13600 Epoch=66.7] | Loss=0.02405 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.380 | L2-Norm(final)=7.318 | 4487.2 samples/s | 70.1 steps/s
[Step=13650 Epoch=66.9] | Loss=0.02364 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.386 | L2-Norm(final)=7.318 | 4353.8 samples/s | 68.0 steps/s
[Step=13700 Epoch=67.2] | Loss=0.02336 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.392 | L2-Norm(final)=7.317 | 4907.5 samples/s | 76.7 steps/s
[Step=13750 Epoch=67.4] | Loss=0.02331 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.399 | L2-Norm(final)=7.316 | 2312.4 samples/s | 36.1 steps/s
[Step=13800 Epoch=67.7] | Loss=0.02308 | Reg=0.00548 | acc=0.9844 | L2-Norm=23.406 | L2-Norm(final)=7.315 | 4413.9 samples/s | 69.0 steps/s
[Step=13850 Epoch=67.9] | Loss=0.02286 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.415 | L2-Norm(final)=7.313 | 4414.7 samples/s | 69.0 steps/s
[Step=13900 Epoch=68.2] | Loss=0.02260 | Reg=0.00549 | acc=0.9688 | L2-Norm=23.423 | L2-Norm(final)=7.312 | 4663.0 samples/s | 72.9 steps/s
[Step=13950 Epoch=68.4] | Loss=0.02216 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.431 | L2-Norm(final)=7.311 | 2304.1 samples/s | 36.0 steps/s
[Step=14000 Epoch=68.7] | Loss=0.02182 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.438 | L2-Norm(final)=7.310 | 4420.0 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step14000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=113.7] | Loss=0.01193 | Reg=0.00191 | acc=0.9844 | L2-Norm=13.826 | L2-Norm(final)=4.442 | 4902.4 samples/s | 76.6 steps/s
[Step=12050 Epoch=114.2] | Loss=0.00308 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.894 | L2-Norm(final)=4.449 | 4184.5 samples/s | 65.4 steps/s
[Step=12100 Epoch=114.7] | Loss=0.00199 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.920 | L2-Norm(final)=4.469 | 7363.2 samples/s | 115.1 steps/s
[Step=12150 Epoch=115.1] | Loss=0.00147 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=4.489 | 2108.1 samples/s | 32.9 steps/s
[Step=12200 Epoch=115.6] | Loss=0.00125 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.949 | L2-Norm(final)=4.508 | 6575.5 samples/s | 102.7 steps/s
[Step=12250 Epoch=116.1] | Loss=0.00104 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=4.525 | 2165.8 samples/s | 33.8 steps/s
[Step=12300 Epoch=116.6] | Loss=0.00093 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.963 | L2-Norm(final)=4.541 | 5897.2 samples/s | 92.1 steps/s
[Step=12350 Epoch=117.0] | Loss=0.00085 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.967 | L2-Norm(final)=4.556 | 2280.5 samples/s | 35.6 steps/s
[Step=12400 Epoch=117.5] | Loss=0.00077 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.969 | L2-Norm(final)=4.571 | 5337.3 samples/s | 83.4 steps/s
[Step=12450 Epoch=118.0] | Loss=0.00071 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.969 | L2-Norm(final)=4.584 | 2363.1 samples/s | 36.9 steps/s
[Step=12500 Epoch=118.4] | Loss=0.00066 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.969 | L2-Norm(final)=4.598 | 5022.5 samples/s | 78.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=118.5] | Loss=0.00065 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=4.727 | 5226.6 samples/s | 81.7 steps/s
[Step=12550 Epoch=118.9] | Loss=0.00335 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.958 | L2-Norm(final)=4.735 | 3720.8 samples/s | 58.1 steps/s
[Step=12600 Epoch=119.4] | Loss=0.01725 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.165 | L2-Norm(final)=4.678 | 6148.0 samples/s | 96.1 steps/s
[Step=12650 Epoch=119.9] | Loss=0.01235 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.325 | L2-Norm(final)=4.629 | 1998.9 samples/s | 31.2 steps/s
[Step=12700 Epoch=120.3] | Loss=0.00948 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.408 | L2-Norm(final)=4.608 | 5526.2 samples/s | 86.3 steps/s
[Step=12750 Epoch=120.8] | Loss=0.00763 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.455 | L2-Norm(final)=4.597 | 2079.7 samples/s | 32.5 steps/s
[Step=12800 Epoch=121.3] | Loss=0.00654 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.483 | L2-Norm(final)=4.591 | 5120.5 samples/s | 80.0 steps/s
[Step=12850 Epoch=121.8] | Loss=0.00562 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.500 | L2-Norm(final)=4.586 | 2146.8 samples/s | 33.5 steps/s
[Step=12900 Epoch=122.2] | Loss=0.00493 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=4.583 | 4665.3 samples/s | 72.9 steps/s
[Step=12950 Epoch=122.7] | Loss=0.00438 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.514 | L2-Norm(final)=4.581 | 2251.2 samples/s | 35.2 steps/s
[Step=13000 Epoch=123.2] | Loss=0.00395 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.514 | L2-Norm(final)=4.580 | 4234.9 samples/s | 66.2 steps/s
[Step=13050 Epoch=123.7] | Loss=0.00359 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.512 | L2-Norm(final)=4.579 | 2324.9 samples/s | 36.3 steps/s
[Step=13100 Epoch=124.1] | Loss=0.00329 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.508 | L2-Norm(final)=4.578 | 4194.1 samples/s | 65.5 steps/s
[Step=13150 Epoch=124.6] | Loss=0.00304 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.501 | L2-Norm(final)=4.578 | 2391.9 samples/s | 37.4 steps/s
[Step=13200 Epoch=125.1] | Loss=0.00282 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=4.578 | 4129.8 samples/s | 64.5 steps/s
[Step=13250 Epoch=125.6] | Loss=0.00263 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.485 | L2-Norm(final)=4.578 | 2378.2 samples/s | 37.2 steps/s
[Step=13300 Epoch=126.0] | Loss=0.00247 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=4.577 | 4094.5 samples/s | 64.0 steps/s
[Step=13350 Epoch=126.5] | Loss=0.00233 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.466 | L2-Norm(final)=4.577 | 2519.6 samples/s | 39.4 steps/s
[Step=13400 Epoch=127.0] | Loss=0.00220 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.455 | L2-Norm(final)=4.577 | 3849.2 samples/s | 60.1 steps/s
[Step=13450 Epoch=127.5] | Loss=0.00208 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.443 | L2-Norm(final)=4.577 | 6334.9 samples/s | 99.0 steps/s
[Step=13500 Epoch=127.9] | Loss=0.00198 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.431 | L2-Norm(final)=4.578 | 1995.2 samples/s | 31.2 steps/s
[Step=13550 Epoch=128.4] | Loss=0.00188 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.419 | L2-Norm(final)=4.578 | 5785.7 samples/s | 90.4 steps/s
[Step=13600 Epoch=128.9] | Loss=0.00180 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.406 | L2-Norm(final)=4.578 | 2054.7 samples/s | 32.1 steps/s
[Step=13650 Epoch=129.3] | Loss=0.00172 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.392 | L2-Norm(final)=4.578 | 5216.9 samples/s | 81.5 steps/s
[Step=13700 Epoch=129.8] | Loss=0.00165 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.379 | L2-Norm(final)=4.578 | 2149.1 samples/s | 33.6 steps/s
[Step=13750 Epoch=130.3] | Loss=0.00158 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=4.579 | 4787.4 samples/s | 74.8 steps/s
[Step=13800 Epoch=130.8] | Loss=0.00152 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.351 | L2-Norm(final)=4.579 | 2231.3 samples/s | 34.9 steps/s
[Step=13850 Epoch=131.2] | Loss=0.00147 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.336 | L2-Norm(final)=4.579 | 4379.7 samples/s | 68.4 steps/s
[Step=13900 Epoch=131.7] | Loss=0.00141 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.321 | L2-Norm(final)=4.579 | 2314.9 samples/s | 36.2 steps/s
[Step=13950 Epoch=132.2] | Loss=0.00137 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.306 | L2-Norm(final)=4.580 | 4157.6 samples/s | 65.0 steps/s
[Step=14000 Epoch=132.7] | Loss=0.00132 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.291 | L2-Norm(final)=4.580 | 2397.2 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step14000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=114.2] | Loss=0.01775 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.351 | L2-Norm(final)=4.777 | 5378.7 samples/s | 84.0 steps/s
[Step=12050 Epoch=114.6] | Loss=0.00373 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.416 | L2-Norm(final)=4.797 | 4072.5 samples/s | 63.6 steps/s
[Step=12100 Epoch=115.1] | Loss=0.00266 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.521 | L2-Norm(final)=4.812 | 7398.3 samples/s | 115.6 steps/s
[Step=12150 Epoch=115.6] | Loss=0.00203 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.591 | L2-Norm(final)=4.836 | 2120.5 samples/s | 33.1 steps/s
[Step=12200 Epoch=116.1] | Loss=0.00160 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.631 | L2-Norm(final)=4.856 | 6427.0 samples/s | 100.4 steps/s
[Step=12250 Epoch=116.5] | Loss=0.00133 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.655 | L2-Norm(final)=4.875 | 2209.7 samples/s | 34.5 steps/s
[Step=12300 Epoch=117.0] | Loss=0.00115 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.669 | L2-Norm(final)=4.892 | 5767.5 samples/s | 90.1 steps/s
[Step=12350 Epoch=117.5] | Loss=0.00101 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.677 | L2-Norm(final)=4.908 | 2265.9 samples/s | 35.4 steps/s
[Step=12400 Epoch=118.0] | Loss=0.00091 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.682 | L2-Norm(final)=4.923 | 5367.7 samples/s | 83.9 steps/s
[Step=12450 Epoch=118.4] | Loss=0.00083 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.684 | L2-Norm(final)=4.937 | 2356.7 samples/s | 36.8 steps/s
[Step=12500 Epoch=118.9] | Loss=0.00077 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.685 | L2-Norm(final)=4.951 | 4850.2 samples/s | 75.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=118.9] | Loss=0.00008 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=5.089 | 5286.6 samples/s | 82.6 steps/s
[Step=12550 Epoch=119.4] | Loss=0.00009 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.663 | L2-Norm(final)=5.097 | 3957.7 samples/s | 61.8 steps/s
[Step=12600 Epoch=119.9] | Loss=0.00006 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.630 | L2-Norm(final)=5.102 | 6069.2 samples/s | 94.8 steps/s
[Step=12650 Epoch=120.3] | Loss=0.00004 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=5.105 | 2015.7 samples/s | 31.5 steps/s
[Step=12700 Epoch=120.8] | Loss=0.00003 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.557 | L2-Norm(final)=5.106 | 5593.9 samples/s | 87.4 steps/s
[Step=12750 Epoch=121.3] | Loss=0.00003 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.519 | L2-Norm(final)=5.108 | 2080.8 samples/s | 32.5 steps/s
[Step=12800 Epoch=121.8] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.481 | L2-Norm(final)=5.109 | 5193.9 samples/s | 81.2 steps/s
[Step=12850 Epoch=122.2] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.443 | L2-Norm(final)=5.110 | 2185.6 samples/s | 34.1 steps/s
[Step=12900 Epoch=122.7] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.405 | L2-Norm(final)=5.111 | 4695.8 samples/s | 73.4 steps/s
[Step=12950 Epoch=123.2] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.367 | L2-Norm(final)=5.112 | 2202.6 samples/s | 34.4 steps/s
[Step=13000 Epoch=123.7] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.329 | L2-Norm(final)=5.112 | 4260.5 samples/s | 66.6 steps/s
[Step=13050 Epoch=124.1] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.291 | L2-Norm(final)=5.113 | 2252.3 samples/s | 35.2 steps/s
[Step=13100 Epoch=124.6] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.253 | L2-Norm(final)=5.114 | 4051.1 samples/s | 63.3 steps/s
[Step=13150 Epoch=125.1] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.214 | L2-Norm(final)=5.115 | 2234.4 samples/s | 34.9 steps/s
[Step=13200 Epoch=125.6] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.176 | L2-Norm(final)=5.115 | 4048.2 samples/s | 63.3 steps/s
[Step=13250 Epoch=126.0] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.138 | L2-Norm(final)=5.116 | 2280.9 samples/s | 35.6 steps/s
[Step=13300 Epoch=126.5] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.099 | L2-Norm(final)=5.117 | 3839.1 samples/s | 60.0 steps/s
[Step=13350 Epoch=127.0] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.061 | L2-Norm(final)=5.117 | 2287.0 samples/s | 35.7 steps/s
[Step=13400 Epoch=127.5] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.023 | L2-Norm(final)=5.118 | 3818.8 samples/s | 59.7 steps/s
[Step=13450 Epoch=127.9] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.984 | L2-Norm(final)=5.119 | 6242.7 samples/s | 97.5 steps/s
[Step=13500 Epoch=128.4] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.946 | L2-Norm(final)=5.120 | 2001.4 samples/s | 31.3 steps/s
[Step=13550 Epoch=128.9] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.907 | L2-Norm(final)=5.120 | 5855.8 samples/s | 91.5 steps/s
[Step=13600 Epoch=129.4] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.868 | L2-Norm(final)=5.121 | 2047.0 samples/s | 32.0 steps/s
[Step=13650 Epoch=129.8] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.830 | L2-Norm(final)=5.122 | 5274.5 samples/s | 82.4 steps/s
[Step=13700 Epoch=130.3] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.791 | L2-Norm(final)=5.123 | 2165.5 samples/s | 33.8 steps/s
[Step=13750 Epoch=130.8] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.752 | L2-Norm(final)=5.123 | 4880.8 samples/s | 76.3 steps/s
[Step=13800 Epoch=131.3] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.713 | L2-Norm(final)=5.124 | 2235.8 samples/s | 34.9 steps/s
[Step=13850 Epoch=131.7] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.674 | L2-Norm(final)=5.125 | 4411.2 samples/s | 68.9 steps/s
[Step=13900 Epoch=132.2] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.635 | L2-Norm(final)=5.126 | 2319.9 samples/s | 36.2 steps/s
[Step=13950 Epoch=132.7] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.596 | L2-Norm(final)=5.127 | 4269.5 samples/s | 66.7 steps/s
[Step=14000 Epoch=133.2] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.557 | L2-Norm(final)=5.127 | 2409.4 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step14000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=114.6] | Loss=0.00730 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.468 | L2-Norm(final)=4.683 | 5392.0 samples/s | 84.3 steps/s
[Step=12050 Epoch=115.1] | Loss=0.00267 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.590 | L2-Norm(final)=4.693 | 4101.2 samples/s | 64.1 steps/s
[Step=12100 Epoch=115.5] | Loss=0.00270 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.678 | L2-Norm(final)=4.729 | 7496.2 samples/s | 117.1 steps/s
[Step=12150 Epoch=116.0] | Loss=0.00195 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.741 | L2-Norm(final)=4.757 | 2072.3 samples/s | 32.4 steps/s
[Step=12200 Epoch=116.5] | Loss=0.00155 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.776 | L2-Norm(final)=4.782 | 6821.0 samples/s | 106.6 steps/s
[Step=12250 Epoch=117.0] | Loss=0.00131 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.799 | L2-Norm(final)=4.805 | 2214.7 samples/s | 34.6 steps/s
[Step=12300 Epoch=117.5] | Loss=0.00112 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.812 | L2-Norm(final)=4.826 | 6154.7 samples/s | 96.2 steps/s
[Step=12350 Epoch=117.9] | Loss=0.00098 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.819 | L2-Norm(final)=4.845 | 2252.2 samples/s | 35.2 steps/s
[Step=12400 Epoch=118.4] | Loss=0.00087 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.822 | L2-Norm(final)=4.863 | 5674.7 samples/s | 88.7 steps/s
[Step=12450 Epoch=118.9] | Loss=0.00079 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.821 | L2-Norm(final)=4.880 | 2289.0 samples/s | 35.8 steps/s
[Step=12500 Epoch=119.4] | Loss=0.00073 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.818 | L2-Norm(final)=4.896 | 5262.7 samples/s | 82.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=119.4] | Loss=0.00004 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.785 | L2-Norm(final)=5.057 | 4966.2 samples/s | 77.6 steps/s
[Step=12550 Epoch=119.8] | Loss=0.00005 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=5.065 | 4006.4 samples/s | 62.6 steps/s
[Step=12600 Epoch=120.3] | Loss=0.01765 | Reg=0.00190 | acc=0.9844 | L2-Norm=13.786 | L2-Norm(final)=5.050 | 6269.8 samples/s | 98.0 steps/s
[Step=12650 Epoch=120.8] | Loss=0.01661 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.040 | L2-Norm(final)=4.965 | 2017.1 samples/s | 31.5 steps/s
[Step=12700 Epoch=121.3] | Loss=0.01308 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.185 | L2-Norm(final)=4.921 | 5781.7 samples/s | 90.3 steps/s
[Step=12750 Epoch=121.8] | Loss=0.01051 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.270 | L2-Norm(final)=4.897 | 2008.2 samples/s | 31.4 steps/s
[Step=12800 Epoch=122.2] | Loss=0.00878 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.322 | L2-Norm(final)=4.882 | 5424.0 samples/s | 84.8 steps/s
[Step=12850 Epoch=122.7] | Loss=0.00754 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.354 | L2-Norm(final)=4.873 | 2147.0 samples/s | 33.5 steps/s
[Step=12900 Epoch=123.2] | Loss=0.00660 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.374 | L2-Norm(final)=4.866 | 4970.1 samples/s | 77.7 steps/s
[Step=12950 Epoch=123.7] | Loss=0.00587 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.385 | L2-Norm(final)=4.861 | 2227.0 samples/s | 34.8 steps/s
[Step=13000 Epoch=124.1] | Loss=0.00529 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.391 | L2-Norm(final)=4.857 | 4547.8 samples/s | 71.1 steps/s
[Step=13050 Epoch=124.6] | Loss=0.00481 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.392 | L2-Norm(final)=4.855 | 2281.8 samples/s | 35.7 steps/s
[Step=13100 Epoch=125.1] | Loss=0.00441 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.390 | L2-Norm(final)=4.853 | 4307.3 samples/s | 67.3 steps/s
[Step=13150 Epoch=125.6] | Loss=0.00407 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.386 | L2-Norm(final)=4.851 | 2374.9 samples/s | 37.1 steps/s
[Step=13200 Epoch=126.1] | Loss=0.00378 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.379 | L2-Norm(final)=4.850 | 4293.8 samples/s | 67.1 steps/s
[Step=13250 Epoch=126.5] | Loss=0.00353 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.371 | L2-Norm(final)=4.849 | 2343.1 samples/s | 36.6 steps/s
[Step=13300 Epoch=127.0] | Loss=0.00331 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=4.849 | 4167.0 samples/s | 65.1 steps/s
[Step=13350 Epoch=127.5] | Loss=0.00312 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.351 | L2-Norm(final)=4.848 | 2442.9 samples/s | 38.2 steps/s
[Step=13400 Epoch=128.0] | Loss=0.00295 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.340 | L2-Norm(final)=4.848 | 4070.9 samples/s | 63.6 steps/s
[Step=13450 Epoch=128.4] | Loss=0.00279 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.328 | L2-Norm(final)=4.848 | 2389.3 samples/s | 37.3 steps/s
[Step=13500 Epoch=128.9] | Loss=0.00265 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.315 | L2-Norm(final)=4.848 | 4253.2 samples/s | 66.5 steps/s
[Step=13550 Epoch=129.4] | Loss=0.00253 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.301 | L2-Norm(final)=4.848 | 7059.7 samples/s | 110.3 steps/s
[Step=13600 Epoch=129.9] | Loss=0.00241 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.287 | L2-Norm(final)=4.848 | 1939.5 samples/s | 30.3 steps/s
[Step=13650 Epoch=130.3] | Loss=0.00231 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.273 | L2-Norm(final)=4.848 | 6441.9 samples/s | 100.7 steps/s
[Step=13700 Epoch=130.8] | Loss=0.00221 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.258 | L2-Norm(final)=4.849 | 2011.7 samples/s | 31.4 steps/s
[Step=13750 Epoch=131.3] | Loss=0.00213 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.242 | L2-Norm(final)=4.849 | 5837.2 samples/s | 91.2 steps/s
[Step=13800 Epoch=131.8] | Loss=0.00204 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.227 | L2-Norm(final)=4.849 | 2077.3 samples/s | 32.5 steps/s
[Step=13850 Epoch=132.3] | Loss=0.00197 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.211 | L2-Norm(final)=4.850 | 5298.8 samples/s | 82.8 steps/s
[Step=13900 Epoch=132.7] | Loss=0.00190 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.194 | L2-Norm(final)=4.850 | 2099.7 samples/s | 32.8 steps/s
[Step=13950 Epoch=133.2] | Loss=0.00183 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.178 | L2-Norm(final)=4.850 | 4983.1 samples/s | 77.9 steps/s
[Step=14000 Epoch=133.7] | Loss=0.00177 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.161 | L2-Norm(final)=4.851 | 2213.3 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step14000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=113.1] | Loss=0.00282 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.960 | L2-Norm(final)=4.433 | 5204.1 samples/s | 81.3 steps/s
[Step=12050 Epoch=113.5] | Loss=0.00160 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.006 | L2-Norm(final)=4.451 | 4141.4 samples/s | 64.7 steps/s
[Step=12100 Epoch=114.0] | Loss=0.00122 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.024 | L2-Norm(final)=4.474 | 7402.8 samples/s | 115.7 steps/s
[Step=12150 Epoch=114.5] | Loss=0.00139 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=4.499 | 2116.1 samples/s | 33.1 steps/s
[Step=12200 Epoch=115.0] | Loss=0.00115 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.082 | L2-Norm(final)=4.522 | 6379.6 samples/s | 99.7 steps/s
[Step=12250 Epoch=115.4] | Loss=0.00095 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.096 | L2-Norm(final)=4.541 | 2260.5 samples/s | 35.3 steps/s
[Step=12300 Epoch=115.9] | Loss=0.00082 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.102 | L2-Norm(final)=4.556 | 5633.3 samples/s | 88.0 steps/s
[Step=12350 Epoch=116.4] | Loss=0.00072 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.104 | L2-Norm(final)=4.569 | 2372.4 samples/s | 37.1 steps/s
[Step=12400 Epoch=116.8] | Loss=0.00065 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.102 | L2-Norm(final)=4.581 | 4963.8 samples/s | 77.6 steps/s
[Step=12450 Epoch=117.3] | Loss=0.00059 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=4.592 | 2471.1 samples/s | 38.6 steps/s
[Step=12500 Epoch=117.8] | Loss=0.00054 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.094 | L2-Norm(final)=4.602 | 4627.7 samples/s | 72.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=117.8] | Loss=0.00020 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.036 | L2-Norm(final)=4.699 | 5442.2 samples/s | 85.0 steps/s
[Step=12550 Epoch=118.3] | Loss=0.00009 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.020 | L2-Norm(final)=4.707 | 3685.4 samples/s | 57.6 steps/s
[Step=12600 Epoch=118.7] | Loss=0.00006 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.997 | L2-Norm(final)=4.711 | 6118.4 samples/s | 95.6 steps/s
[Step=12650 Epoch=119.2] | Loss=0.00005 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.974 | L2-Norm(final)=4.715 | 2025.1 samples/s | 31.6 steps/s
[Step=12700 Epoch=119.7] | Loss=0.00004 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.950 | L2-Norm(final)=4.717 | 5523.5 samples/s | 86.3 steps/s
[Step=12750 Epoch=120.1] | Loss=0.00003 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.925 | L2-Norm(final)=4.719 | 2104.3 samples/s | 32.9 steps/s
[Step=12800 Epoch=120.6] | Loss=0.00003 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.900 | L2-Norm(final)=4.720 | 4969.9 samples/s | 77.7 steps/s
[Step=12850 Epoch=121.1] | Loss=0.00002 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.874 | L2-Norm(final)=4.721 | 2238.9 samples/s | 35.0 steps/s
[Step=12900 Epoch=121.6] | Loss=0.00002 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.849 | L2-Norm(final)=4.722 | 4459.6 samples/s | 69.7 steps/s
[Step=12950 Epoch=122.0] | Loss=0.00002 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.823 | L2-Norm(final)=4.723 | 2337.0 samples/s | 36.5 steps/s
[Step=13000 Epoch=122.5] | Loss=0.00002 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.797 | L2-Norm(final)=4.724 | 4242.7 samples/s | 66.3 steps/s
[Step=13050 Epoch=123.0] | Loss=0.00002 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.771 | L2-Norm(final)=4.725 | 2357.4 samples/s | 36.8 steps/s
[Step=13100 Epoch=123.4] | Loss=0.00002 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.745 | L2-Norm(final)=4.726 | 4174.1 samples/s | 65.2 steps/s
[Step=13150 Epoch=123.9] | Loss=0.00002 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.718 | L2-Norm(final)=4.727 | 2410.8 samples/s | 37.7 steps/s
[Step=13200 Epoch=124.4] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.691 | L2-Norm(final)=4.728 | 4321.7 samples/s | 67.5 steps/s
[Step=13250 Epoch=124.9] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.665 | L2-Norm(final)=4.728 | 2725.3 samples/s | 42.6 steps/s
[Step=13300 Epoch=125.3] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.638 | L2-Norm(final)=4.729 | 3618.7 samples/s | 56.5 steps/s
[Step=13350 Epoch=125.8] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.611 | L2-Norm(final)=4.730 | 6214.4 samples/s | 97.1 steps/s
[Step=13400 Epoch=126.3] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.584 | L2-Norm(final)=4.730 | 2056.7 samples/s | 32.1 steps/s
[Step=13450 Epoch=126.7] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.557 | L2-Norm(final)=4.731 | 5387.0 samples/s | 84.2 steps/s
[Step=13500 Epoch=127.2] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.529 | L2-Norm(final)=4.732 | 2114.2 samples/s | 33.0 steps/s
[Step=13550 Epoch=127.7] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.502 | L2-Norm(final)=4.732 | 5018.5 samples/s | 78.4 steps/s
[Step=13600 Epoch=128.2] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.474 | L2-Norm(final)=4.733 | 2192.0 samples/s | 34.2 steps/s
[Step=13650 Epoch=128.6] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.446 | L2-Norm(final)=4.734 | 4535.9 samples/s | 70.9 steps/s
[Step=13700 Epoch=129.1] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.419 | L2-Norm(final)=4.735 | 2309.6 samples/s | 36.1 steps/s
[Step=13750 Epoch=129.6] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.391 | L2-Norm(final)=4.735 | 4250.7 samples/s | 66.4 steps/s
[Step=13800 Epoch=130.0] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.362 | L2-Norm(final)=4.736 | 2428.9 samples/s | 38.0 steps/s
[Step=13850 Epoch=130.5] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.334 | L2-Norm(final)=4.737 | 4328.6 samples/s | 67.6 steps/s
[Step=13900 Epoch=131.0] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.306 | L2-Norm(final)=4.737 | 2376.1 samples/s | 37.1 steps/s
[Step=13950 Epoch=131.4] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.277 | L2-Norm(final)=4.738 | 4257.0 samples/s | 66.5 steps/s
[Step=14000 Epoch=131.9] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.249 | L2-Norm(final)=4.739 | 2477.2 samples/s | 38.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step14000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=114.4] | Loss=0.00062 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.939 | L2-Norm(final)=5.278 | 4976.8 samples/s | 77.8 steps/s
[Step=12050 Epoch=114.8] | Loss=0.00475 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.006 | L2-Norm(final)=5.290 | 4312.4 samples/s | 67.4 steps/s
[Step=12100 Epoch=115.3] | Loss=0.00345 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.068 | L2-Norm(final)=5.309 | 7637.5 samples/s | 119.3 steps/s
[Step=12150 Epoch=115.8] | Loss=0.00268 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=5.326 | 2123.5 samples/s | 33.2 steps/s
[Step=12200 Epoch=116.3] | Loss=0.00222 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.135 | L2-Norm(final)=5.341 | 6503.9 samples/s | 101.6 steps/s
[Step=12250 Epoch=116.8] | Loss=0.00187 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.154 | L2-Norm(final)=5.354 | 2205.9 samples/s | 34.5 steps/s
[Step=12300 Epoch=117.2] | Loss=0.00166 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=5.367 | 6003.9 samples/s | 93.8 steps/s
[Step=12350 Epoch=117.7] | Loss=0.00150 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.179 | L2-Norm(final)=5.379 | 2263.4 samples/s | 35.4 steps/s
[Step=12400 Epoch=118.2] | Loss=0.00137 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.191 | L2-Norm(final)=5.391 | 5629.6 samples/s | 88.0 steps/s
[Step=12450 Epoch=118.7] | Loss=0.00125 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.199 | L2-Norm(final)=5.402 | 2357.7 samples/s | 36.8 steps/s
[Step=12500 Epoch=119.1] | Loss=0.00116 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=5.413 | 5085.4 samples/s | 79.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=119.1] | Loss=0.00004 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.264 | L2-Norm(final)=5.520 | 5715.3 samples/s | 89.3 steps/s
[Step=12550 Epoch=119.6] | Loss=0.00017 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.253 | L2-Norm(final)=5.528 | 3733.1 samples/s | 58.3 steps/s
[Step=12600 Epoch=120.1] | Loss=0.00017 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.236 | L2-Norm(final)=5.532 | 6263.4 samples/s | 97.9 steps/s
[Step=12650 Epoch=120.6] | Loss=0.00014 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.223 | L2-Norm(final)=5.536 | 2010.2 samples/s | 31.4 steps/s
[Step=12700 Epoch=121.0] | Loss=0.00011 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=5.539 | 5662.2 samples/s | 88.5 steps/s
[Step=12750 Epoch=121.5] | Loss=0.00009 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.187 | L2-Norm(final)=5.541 | 2055.6 samples/s | 32.1 steps/s
[Step=12800 Epoch=122.0] | Loss=0.00008 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.165 | L2-Norm(final)=5.542 | 5304.7 samples/s | 82.9 steps/s
[Step=12850 Epoch=122.5] | Loss=0.00007 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.144 | L2-Norm(final)=5.544 | 2118.5 samples/s | 33.1 steps/s
[Step=12900 Epoch=122.9] | Loss=0.00006 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.121 | L2-Norm(final)=5.544 | 4995.1 samples/s | 78.0 steps/s
[Step=12950 Epoch=123.4] | Loss=0.00005 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=5.545 | 2228.3 samples/s | 34.8 steps/s
[Step=13000 Epoch=123.9] | Loss=0.00005 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.076 | L2-Norm(final)=5.546 | 4520.5 samples/s | 70.6 steps/s
[Step=13050 Epoch=124.4] | Loss=0.00004 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.053 | L2-Norm(final)=5.546 | 2248.8 samples/s | 35.1 steps/s
[Step=13100 Epoch=124.9] | Loss=0.00004 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.029 | L2-Norm(final)=5.547 | 4351.2 samples/s | 68.0 steps/s
[Step=13150 Epoch=125.3] | Loss=0.00004 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.006 | L2-Norm(final)=5.548 | 2374.2 samples/s | 37.1 steps/s
[Step=13200 Epoch=125.8] | Loss=0.00003 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.983 | L2-Norm(final)=5.548 | 4265.0 samples/s | 66.6 steps/s
[Step=13250 Epoch=126.3] | Loss=0.00003 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.959 | L2-Norm(final)=5.548 | 2393.9 samples/s | 37.4 steps/s
[Step=13300 Epoch=126.8] | Loss=0.00003 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.935 | L2-Norm(final)=5.549 | 4214.2 samples/s | 65.8 steps/s
[Step=13350 Epoch=127.2] | Loss=0.00003 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.911 | L2-Norm(final)=5.549 | 2342.5 samples/s | 36.6 steps/s
[Step=13400 Epoch=127.7] | Loss=0.00003 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.887 | L2-Norm(final)=5.550 | 4247.0 samples/s | 66.4 steps/s
[Step=13450 Epoch=128.2] | Loss=0.00003 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.863 | L2-Norm(final)=5.550 | 2416.9 samples/s | 37.8 steps/s
[Step=13500 Epoch=128.7] | Loss=0.00003 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.839 | L2-Norm(final)=5.550 | 4136.7 samples/s | 64.6 steps/s
[Step=13550 Epoch=129.1] | Loss=0.00002 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.815 | L2-Norm(final)=5.551 | 7024.2 samples/s | 109.8 steps/s
[Step=13600 Epoch=129.6] | Loss=0.00002 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.791 | L2-Norm(final)=5.551 | 1958.9 samples/s | 30.6 steps/s
[Step=13650 Epoch=130.1] | Loss=0.00002 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.766 | L2-Norm(final)=5.551 | 6320.1 samples/s | 98.8 steps/s
[Step=13700 Epoch=130.6] | Loss=0.00002 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.742 | L2-Norm(final)=5.552 | 1962.1 samples/s | 30.7 steps/s
[Step=13750 Epoch=131.0] | Loss=0.00002 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=5.552 | 5850.5 samples/s | 91.4 steps/s
[Step=13800 Epoch=131.5] | Loss=0.00002 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.693 | L2-Norm(final)=5.552 | 2064.4 samples/s | 32.3 steps/s
[Step=13850 Epoch=132.0] | Loss=0.00002 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.668 | L2-Norm(final)=5.553 | 5363.4 samples/s | 83.8 steps/s
[Step=13900 Epoch=132.5] | Loss=0.00002 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.643 | L2-Norm(final)=5.553 | 2146.6 samples/s | 33.5 steps/s
[Step=13950 Epoch=133.0] | Loss=0.00002 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=5.553 | 4879.5 samples/s | 76.2 steps/s
[Step=14000 Epoch=133.4] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.593 | L2-Norm(final)=5.554 | 2203.9 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.13355 | acc=0.9407 | tpr=0.9449 | fpr=0.0684 | 4757.2 samples/s | 18.6 steps/s
Avg test loss: 0.13338, Avg test acc: 0.93978, Avg tpr: 0.94428, Avg fpr: 0.07012, total FA: 547

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.17593 | acc=0.9413 | tpr=0.9709 | fpr=0.1229 | 4826.7 samples/s | 18.9 steps/s
Avg test loss: 0.16979, Avg test acc: 0.94146, Avg tpr: 0.96998, Avg fpr: 0.12127, total FA: 946

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.15155 | acc=0.9286 | tpr=0.9262 | fpr=0.0662 | 4746.8 samples/s | 18.5 steps/s
Avg test loss: 0.15161, Avg test acc: 0.92656, Avg tpr: 0.92429, Avg fpr: 0.06845, total FA: 534

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14815 | acc=0.9458 | tpr=0.9622 | fpr=0.0899 | 4804.7 samples/s | 18.8 steps/s
Avg test loss: 0.15252, Avg test acc: 0.94423, Avg tpr: 0.96206, Avg fpr: 0.09499, total FA: 741

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.14850 | acc=0.9375 | tpr=0.9447 | fpr=0.0780 | 4788.5 samples/s | 18.7 steps/s
Avg test loss: 0.14867, Avg test acc: 0.93745, Avg tpr: 0.94463, Avg fpr: 0.07832, total FA: 611

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.68592 | acc=0.3064 | tpr=0.0128 | fpr=0.0560 | 4911.4 samples/s | 19.2 steps/s
Avg test loss: 4.69997, Avg test acc: 0.30475, Avg tpr: 0.01341, Avg fpr: 0.05448, total FA: 425

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.83497 | acc=0.2807 | tpr=0.0075 | fpr=0.1261 | 4757.0 samples/s | 18.6 steps/s
Avg test loss: 4.84645, Avg test acc: 0.27827, Avg tpr: 0.00752, Avg fpr: 0.12627, total FA: 985

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.34920 | acc=0.3059 | tpr=0.0056 | fpr=0.0419 | 4691.2 samples/s | 18.3 steps/s
Avg test loss: 4.36511, Avg test acc: 0.30395, Avg tpr: 0.00664, Avg fpr: 0.04217, total FA: 329

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.27372 | acc=0.2931 | tpr=0.0267 | fpr=0.1283 | 4581.5 samples/s | 17.9 steps/s
Avg test loss: 5.27714, Avg test acc: 0.29105, Avg tpr: 0.02594, Avg fpr: 0.12588, total FA: 982

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.19191 | acc=0.3004 | tpr=0.0237 | fpr=0.0989 | 4684.3 samples/s | 18.3 steps/s
Avg test loss: 5.19571, Avg test acc: 0.29962, Avg tpr: 0.02401, Avg fpr: 0.09422, total FA: 735

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.63937 | acc=0.1396 | tpr=0.5354 | fpr=0.8675 | 4830.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=4.60784 | acc=0.1431 | tpr=0.5416 | fpr=0.8643 | 6490.3 samples/s | 25.4 steps/s
[Step= 150] | Loss=4.61375 | acc=0.1425 | tpr=0.5389 | fpr=0.8648 | 7202.7 samples/s | 28.1 steps/s
[Step= 200] | Loss=4.62306 | acc=0.1417 | tpr=0.5279 | fpr=0.8653 | 7564.4 samples/s | 29.5 steps/s
[Step= 250] | Loss=4.63666 | acc=0.1415 | tpr=0.5275 | fpr=0.8655 | 6900.1 samples/s | 27.0 steps/s
[Step= 300] | Loss=4.63636 | acc=0.1415 | tpr=0.5222 | fpr=0.8654 | 8440.2 samples/s | 33.0 steps/s
[Step= 350] | Loss=4.63322 | acc=0.1417 | tpr=0.5222 | fpr=0.8652 | 7532.7 samples/s | 29.4 steps/s
[Step= 400] | Loss=4.62922 | acc=0.1420 | tpr=0.5170 | fpr=0.8648 | 7700.7 samples/s | 30.1 steps/s
[Step= 450] | Loss=4.63376 | acc=0.1420 | tpr=0.5170 | fpr=0.8648 | 8019.6 samples/s | 31.3 steps/s
[Step= 500] | Loss=4.64112 | acc=0.1417 | tpr=0.5137 | fpr=0.8650 | 7788.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=4.64267 | acc=0.1415 | tpr=0.5097 | fpr=0.8652 | 13890.7 samples/s | 54.3 steps/s
Avg test loss: 4.64402, Avg test acc: 0.14136, Avg tpr: 0.50951, Avg fpr: 0.86533, total FA: 120149

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.69878 | acc=0.0775 | tpr=0.6593 | fpr=0.9330 | 4283.5 samples/s | 16.7 steps/s
[Step= 100] | Loss=5.70464 | acc=0.0770 | tpr=0.6631 | fpr=0.9340 | 8031.3 samples/s | 31.4 steps/s
[Step= 150] | Loss=5.70327 | acc=0.0782 | tpr=0.6643 | fpr=0.9326 | 7030.6 samples/s | 27.5 steps/s
[Step= 200] | Loss=5.68816 | acc=0.0788 | tpr=0.6634 | fpr=0.9318 | 7993.2 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.69447 | acc=0.0785 | tpr=0.6672 | fpr=0.9322 | 6597.1 samples/s | 25.8 steps/s
[Step= 300] | Loss=5.68603 | acc=0.0781 | tpr=0.6655 | fpr=0.9326 | 7865.3 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.68249 | acc=0.0783 | tpr=0.6612 | fpr=0.9323 | 7718.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.68052 | acc=0.0783 | tpr=0.6619 | fpr=0.9323 | 7979.3 samples/s | 31.2 steps/s
[Step= 450] | Loss=5.68191 | acc=0.0786 | tpr=0.6641 | fpr=0.9321 | 7880.2 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.68688 | acc=0.0782 | tpr=0.6559 | fpr=0.9323 | 7987.1 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.68806 | acc=0.0783 | tpr=0.6606 | fpr=0.9323 | 13481.9 samples/s | 52.7 steps/s
Avg test loss: 5.68898, Avg test acc: 0.07823, Avg tpr: 0.66006, Avg fpr: 0.93235, total FA: 129455

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=4.02989 | acc=0.1410 | tpr=0.3894 | fpr=0.8634 | 4845.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=4.00252 | acc=0.1421 | tpr=0.4072 | fpr=0.8628 | 7313.4 samples/s | 28.6 steps/s
[Step= 150] | Loss=4.00627 | acc=0.1436 | tpr=0.4236 | fpr=0.8615 | 7678.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=3.99697 | acc=0.1439 | tpr=0.4197 | fpr=0.8612 | 6248.4 samples/s | 24.4 steps/s
[Step= 250] | Loss=4.00263 | acc=0.1447 | tpr=0.4218 | fpr=0.8604 | 7236.1 samples/s | 28.3 steps/s
[Step= 300] | Loss=3.99908 | acc=0.1443 | tpr=0.4335 | fpr=0.8610 | 7955.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=3.99008 | acc=0.1443 | tpr=0.4296 | fpr=0.8609 | 7602.1 samples/s | 29.7 steps/s
[Step= 400] | Loss=3.98745 | acc=0.1445 | tpr=0.4267 | fpr=0.8607 | 7897.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=3.98905 | acc=0.1450 | tpr=0.4343 | fpr=0.8603 | 7910.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=3.99357 | acc=0.1448 | tpr=0.4322 | fpr=0.8604 | 7929.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=3.99516 | acc=0.1444 | tpr=0.4286 | fpr=0.8607 | 13699.5 samples/s | 53.5 steps/s
Avg test loss: 3.99642, Avg test acc: 0.14434, Avg tpr: 0.42948, Avg fpr: 0.86085, total FA: 119527

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.65613 | acc=0.1369 | tpr=0.5752 | fpr=0.8710 | 4999.5 samples/s | 19.5 steps/s
[Step= 100] | Loss=5.64244 | acc=0.1343 | tpr=0.5693 | fpr=0.8738 | 6915.0 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.64762 | acc=0.1352 | tpr=0.5533 | fpr=0.8725 | 7358.1 samples/s | 28.7 steps/s
[Step= 200] | Loss=5.65071 | acc=0.1357 | tpr=0.5421 | fpr=0.8717 | 6021.7 samples/s | 23.5 steps/s
[Step= 250] | Loss=5.65630 | acc=0.1354 | tpr=0.5345 | fpr=0.8719 | 7925.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.64029 | acc=0.1357 | tpr=0.5389 | fpr=0.8716 | 8420.9 samples/s | 32.9 steps/s
[Step= 350] | Loss=5.62431 | acc=0.1365 | tpr=0.5385 | fpr=0.8708 | 7126.5 samples/s | 27.8 steps/s
[Step= 400] | Loss=5.62297 | acc=0.1370 | tpr=0.5416 | fpr=0.8704 | 7893.0 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.62921 | acc=0.1365 | tpr=0.5428 | fpr=0.8708 | 7809.5 samples/s | 30.5 steps/s
[Step= 500] | Loss=5.63649 | acc=0.1362 | tpr=0.5401 | fpr=0.8711 | 7862.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.63820 | acc=0.1365 | tpr=0.5384 | fpr=0.8708 | 14033.7 samples/s | 54.8 steps/s
Avg test loss: 5.64112, Avg test acc: 0.13634, Avg tpr: 0.53883, Avg fpr: 0.87098, total FA: 120934

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.34115 | acc=0.1845 | tpr=0.4646 | fpr=0.8206 | 4660.2 samples/s | 18.2 steps/s
[Step= 100] | Loss=4.34216 | acc=0.1831 | tpr=0.4627 | fpr=0.8221 | 7442.2 samples/s | 29.1 steps/s
[Step= 150] | Loss=4.34967 | acc=0.1832 | tpr=0.4640 | fpr=0.8220 | 7883.2 samples/s | 30.8 steps/s
[Step= 200] | Loss=4.34379 | acc=0.1843 | tpr=0.4601 | fpr=0.8208 | 5828.8 samples/s | 22.8 steps/s
[Step= 250] | Loss=4.35088 | acc=0.1841 | tpr=0.4646 | fpr=0.8210 | 7882.5 samples/s | 30.8 steps/s
[Step= 300] | Loss=4.34633 | acc=0.1837 | tpr=0.4705 | fpr=0.8215 | 7840.9 samples/s | 30.6 steps/s
[Step= 350] | Loss=4.33960 | acc=0.1839 | tpr=0.4690 | fpr=0.8213 | 7635.2 samples/s | 29.8 steps/s
[Step= 400] | Loss=4.33790 | acc=0.1838 | tpr=0.4710 | fpr=0.8214 | 8186.6 samples/s | 32.0 steps/s
[Step= 450] | Loss=4.33698 | acc=0.1835 | tpr=0.4703 | fpr=0.8217 | 7692.0 samples/s | 30.0 steps/s
[Step= 500] | Loss=4.34252 | acc=0.1829 | tpr=0.4714 | fpr=0.8223 | 7806.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=4.34242 | acc=0.1829 | tpr=0.4696 | fpr=0.8223 | 14349.6 samples/s | 56.1 steps/s
Avg test loss: 4.34401, Avg test acc: 0.18280, Avg tpr: 0.47029, Avg fpr: 0.82242, total FA: 114192

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08320 | acc=0.9816 | tpr=0.8805 | fpr=0.0166 | 4910.0 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.08626 | acc=0.9809 | tpr=0.9041 | fpr=0.0176 | 6943.7 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.08835 | acc=0.9805 | tpr=0.9121 | fpr=0.0182 | 6584.3 samples/s | 25.7 steps/s
[Step= 200] | Loss=0.08970 | acc=0.9807 | tpr=0.9169 | fpr=0.0181 | 6807.1 samples/s | 26.6 steps/s
[Step= 250] | Loss=0.08940 | acc=0.9809 | tpr=0.9153 | fpr=0.0179 | 8096.4 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.09102 | acc=0.9808 | tpr=0.9149 | fpr=0.0180 | 7629.6 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.09175 | acc=0.9806 | tpr=0.9167 | fpr=0.0182 | 8013.9 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09281 | acc=0.9805 | tpr=0.9130 | fpr=0.0183 | 7831.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.09451 | acc=0.9803 | tpr=0.9114 | fpr=0.0184 | 7953.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09415 | acc=0.9803 | tpr=0.9132 | fpr=0.0185 | 7764.5 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.09379 | acc=0.9806 | tpr=0.9144 | fpr=0.0182 | 14164.9 samples/s | 55.3 steps/s
Avg test loss: 0.09375, Avg test acc: 0.98056, Avg tpr: 0.91403, Avg fpr: 0.01823, total FA: 2531

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09176 | acc=0.9827 | tpr=0.8805 | fpr=0.0154 | 4916.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09406 | acc=0.9826 | tpr=0.8827 | fpr=0.0155 | 6941.7 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.09852 | acc=0.9818 | tpr=0.8847 | fpr=0.0164 | 5531.8 samples/s | 21.6 steps/s
[Step= 200] | Loss=0.10166 | acc=0.9816 | tpr=0.8907 | fpr=0.0168 | 8370.7 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.09912 | acc=0.9819 | tpr=0.8891 | fpr=0.0164 | 8068.2 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.10135 | acc=0.9817 | tpr=0.8887 | fpr=0.0166 | 7920.7 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.10160 | acc=0.9817 | tpr=0.8948 | fpr=0.0168 | 7388.0 samples/s | 28.9 steps/s
[Step= 400] | Loss=0.10266 | acc=0.9814 | tpr=0.8922 | fpr=0.0170 | 8122.8 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.10433 | acc=0.9813 | tpr=0.8914 | fpr=0.0171 | 7520.4 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.10350 | acc=0.9814 | tpr=0.8943 | fpr=0.0171 | 8371.8 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.10296 | acc=0.9815 | tpr=0.8930 | fpr=0.0169 | 13955.4 samples/s | 54.5 steps/s
Avg test loss: 0.10284, Avg test acc: 0.98149, Avg tpr: 0.89303, Avg fpr: 0.01690, total FA: 2347

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09852 | acc=0.9781 | tpr=0.9292 | fpr=0.0210 | 4912.0 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09838 | acc=0.9784 | tpr=0.9296 | fpr=0.0207 | 6794.7 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.10294 | acc=0.9772 | tpr=0.9308 | fpr=0.0219 | 5783.4 samples/s | 22.6 steps/s
[Step= 200] | Loss=0.10466 | acc=0.9773 | tpr=0.9366 | fpr=0.0219 | 8558.5 samples/s | 33.4 steps/s
[Step= 250] | Loss=0.10274 | acc=0.9777 | tpr=0.9301 | fpr=0.0215 | 7258.7 samples/s | 28.4 steps/s
[Step= 300] | Loss=0.10479 | acc=0.9774 | tpr=0.9265 | fpr=0.0217 | 7708.4 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.10612 | acc=0.9771 | tpr=0.9230 | fpr=0.0220 | 8197.9 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.10742 | acc=0.9768 | tpr=0.9223 | fpr=0.0222 | 7936.9 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.10877 | acc=0.9764 | tpr=0.9197 | fpr=0.0226 | 7824.8 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10812 | acc=0.9765 | tpr=0.9216 | fpr=0.0225 | 7715.8 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.10733 | acc=0.9767 | tpr=0.9216 | fpr=0.0223 | 14383.4 samples/s | 56.2 steps/s
Avg test loss: 0.10720, Avg test acc: 0.97669, Avg tpr: 0.92155, Avg fpr: 0.02230, total FA: 3097

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10312 | acc=0.9806 | tpr=0.9027 | fpr=0.0180 | 4855.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10881 | acc=0.9802 | tpr=0.9126 | fpr=0.0185 | 5559.4 samples/s | 21.7 steps/s
[Step= 150] | Loss=0.11325 | acc=0.9793 | tpr=0.9150 | fpr=0.0195 | 7323.0 samples/s | 28.6 steps/s
[Step= 200] | Loss=0.11708 | acc=0.9791 | tpr=0.9213 | fpr=0.0198 | 7970.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.11443 | acc=0.9796 | tpr=0.9240 | fpr=0.0194 | 7838.5 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.11762 | acc=0.9792 | tpr=0.9236 | fpr=0.0198 | 7530.0 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.11852 | acc=0.9791 | tpr=0.9274 | fpr=0.0200 | 7749.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.11969 | acc=0.9788 | tpr=0.9251 | fpr=0.0202 | 8122.4 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.12176 | acc=0.9785 | tpr=0.9226 | fpr=0.0205 | 7626.2 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.12105 | acc=0.9787 | tpr=0.9242 | fpr=0.0204 | 7807.5 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.12044 | acc=0.9789 | tpr=0.9248 | fpr=0.0202 | 14291.3 samples/s | 55.8 steps/s
Avg test loss: 0.12038, Avg test acc: 0.97887, Avg tpr: 0.92512, Avg fpr: 0.02015, total FA: 2798

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.11395 | acc=0.9802 | tpr=0.8938 | fpr=0.0183 | 4897.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.11845 | acc=0.9800 | tpr=0.9126 | fpr=0.0187 | 5065.5 samples/s | 19.8 steps/s
[Step= 150] | Loss=0.12304 | acc=0.9791 | tpr=0.9164 | fpr=0.0198 | 8506.7 samples/s | 33.2 steps/s
[Step= 200] | Loss=0.12610 | acc=0.9789 | tpr=0.9202 | fpr=0.0200 | 7528.8 samples/s | 29.4 steps/s
[Step= 250] | Loss=0.12402 | acc=0.9791 | tpr=0.9162 | fpr=0.0197 | 7834.1 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.12582 | acc=0.9789 | tpr=0.9127 | fpr=0.0199 | 7878.1 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.12630 | acc=0.9788 | tpr=0.9161 | fpr=0.0201 | 7845.4 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.12788 | acc=0.9786 | tpr=0.9125 | fpr=0.0202 | 7909.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13061 | acc=0.9784 | tpr=0.9119 | fpr=0.0204 | 7792.1 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.12996 | acc=0.9785 | tpr=0.9132 | fpr=0.0203 | 7821.3 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12924 | acc=0.9788 | tpr=0.9129 | fpr=0.0200 | 14433.3 samples/s | 56.4 steps/s
Avg test loss: 0.12909, Avg test acc: 0.97876, Avg tpr: 0.91244, Avg fpr: 0.02004, total FA: 2782

server round 7/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=68.3] | Loss=0.03189 | Reg=0.00509 | acc=0.9531 | L2-Norm=22.560 | L2-Norm(final)=6.683 | 5541.9 samples/s | 86.6 steps/s
[Step=14050 Epoch=68.5] | Loss=0.03369 | Reg=0.00510 | acc=0.9688 | L2-Norm=22.577 | L2-Norm(final)=6.705 | 4352.9 samples/s | 68.0 steps/s
[Step=14100 Epoch=68.8] | Loss=0.02949 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.608 | L2-Norm(final)=6.746 | 5129.7 samples/s | 80.2 steps/s
[Step=14150 Epoch=69.0] | Loss=0.02699 | Reg=0.00512 | acc=0.9531 | L2-Norm=22.637 | L2-Norm(final)=6.785 | 4918.9 samples/s | 76.9 steps/s
[Step=14200 Epoch=69.2] | Loss=0.02579 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.665 | L2-Norm(final)=6.823 | 7883.9 samples/s | 123.2 steps/s
[Step=14250 Epoch=69.5] | Loss=0.02403 | Reg=0.00515 | acc=0.9844 | L2-Norm=22.691 | L2-Norm(final)=6.860 | 2180.8 samples/s | 34.1 steps/s
[Step=14300 Epoch=69.7] | Loss=0.02312 | Reg=0.00516 | acc=1.0000 | L2-Norm=22.718 | L2-Norm(final)=6.898 | 4970.3 samples/s | 77.7 steps/s
[Step=14350 Epoch=70.0] | Loss=0.02230 | Reg=0.00517 | acc=0.9844 | L2-Norm=22.743 | L2-Norm(final)=6.935 | 4999.2 samples/s | 78.1 steps/s
[Step=14400 Epoch=70.2] | Loss=0.02149 | Reg=0.00518 | acc=1.0000 | L2-Norm=22.769 | L2-Norm(final)=6.973 | 7040.7 samples/s | 110.0 steps/s
[Step=14450 Epoch=70.5] | Loss=0.02090 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.794 | L2-Norm(final)=7.012 | 2309.9 samples/s | 36.1 steps/s
[Step=14500 Epoch=70.7] | Loss=0.02037 | Reg=0.00521 | acc=0.9844 | L2-Norm=22.819 | L2-Norm(final)=7.051 | 5041.0 samples/s | 78.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=70.7] | Loss=0.01167 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.070 | L2-Norm(final)=7.441 | 5243.9 samples/s | 81.9 steps/s
[Step=14550 Epoch=70.9] | Loss=0.02201 | Reg=0.00534 | acc=0.9688 | L2-Norm=23.099 | L2-Norm(final)=7.471 | 4033.5 samples/s | 63.0 steps/s
[Step=14600 Epoch=71.2] | Loss=0.03807 | Reg=0.00537 | acc=0.9531 | L2-Norm=23.168 | L2-Norm(final)=7.459 | 4488.7 samples/s | 70.1 steps/s
[Step=14650 Epoch=71.4] | Loss=0.04015 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.249 | L2-Norm(final)=7.436 | 4614.6 samples/s | 72.1 steps/s
[Step=14700 Epoch=71.7] | Loss=0.04365 | Reg=0.00544 | acc=0.9531 | L2-Norm=23.318 | L2-Norm(final)=7.415 | 6311.8 samples/s | 98.6 steps/s
[Step=14750 Epoch=71.9] | Loss=0.04218 | Reg=0.00546 | acc=0.9844 | L2-Norm=23.376 | L2-Norm(final)=7.394 | 2109.4 samples/s | 33.0 steps/s
[Step=14800 Epoch=72.2] | Loss=0.04024 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.423 | L2-Norm(final)=7.379 | 4543.1 samples/s | 71.0 steps/s
[Step=14850 Epoch=72.4] | Loss=0.03934 | Reg=0.00551 | acc=0.9531 | L2-Norm=23.462 | L2-Norm(final)=7.366 | 4449.2 samples/s | 69.5 steps/s
[Step=14900 Epoch=72.7] | Loss=0.03746 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.495 | L2-Norm(final)=7.356 | 5842.1 samples/s | 91.3 steps/s
[Step=14950 Epoch=72.9] | Loss=0.03558 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.523 | L2-Norm(final)=7.349 | 1642.5 samples/s | 25.7 steps/s
[Step=15000 Epoch=73.1] | Loss=0.03337 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.547 | L2-Norm(final)=7.344 | 4476.2 samples/s | 69.9 steps/s
[Step=15050 Epoch=73.4] | Loss=0.03150 | Reg=0.00555 | acc=0.9844 | L2-Norm=23.565 | L2-Norm(final)=7.341 | 4329.7 samples/s | 67.7 steps/s
[Step=15100 Epoch=73.6] | Loss=0.03080 | Reg=0.00556 | acc=0.9844 | L2-Norm=23.579 | L2-Norm(final)=7.337 | 5345.3 samples/s | 83.5 steps/s
[Step=15150 Epoch=73.9] | Loss=0.02934 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.592 | L2-Norm(final)=7.333 | 2208.9 samples/s | 34.5 steps/s
[Step=15200 Epoch=74.1] | Loss=0.02811 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.603 | L2-Norm(final)=7.330 | 4473.1 samples/s | 69.9 steps/s
[Step=15250 Epoch=74.4] | Loss=0.02722 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.613 | L2-Norm(final)=7.328 | 4385.2 samples/s | 68.5 steps/s
[Step=15300 Epoch=74.6] | Loss=0.02669 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.622 | L2-Norm(final)=7.325 | 5020.4 samples/s | 78.4 steps/s
[Step=15350 Epoch=74.8] | Loss=0.02788 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.635 | L2-Norm(final)=7.321 | 2353.6 samples/s | 36.8 steps/s
[Step=15400 Epoch=75.1] | Loss=0.02849 | Reg=0.00560 | acc=0.9844 | L2-Norm=23.657 | L2-Norm(final)=7.316 | 4516.5 samples/s | 70.6 steps/s
[Step=15450 Epoch=75.3] | Loss=0.02882 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.681 | L2-Norm(final)=7.310 | 4455.6 samples/s | 69.6 steps/s
[Step=15500 Epoch=75.6] | Loss=0.02862 | Reg=0.00562 | acc=0.9844 | L2-Norm=23.704 | L2-Norm(final)=7.305 | 4584.9 samples/s | 71.6 steps/s
[Step=15550 Epoch=75.8] | Loss=0.02800 | Reg=0.00563 | acc=1.0000 | L2-Norm=23.726 | L2-Norm(final)=7.299 | 2423.4 samples/s | 37.9 steps/s
[Step=15600 Epoch=76.1] | Loss=0.02724 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.745 | L2-Norm(final)=7.295 | 4412.0 samples/s | 68.9 steps/s
[Step=15650 Epoch=76.3] | Loss=0.02666 | Reg=0.00565 | acc=1.0000 | L2-Norm=23.762 | L2-Norm(final)=7.291 | 4459.4 samples/s | 69.7 steps/s
[Step=15700 Epoch=76.6] | Loss=0.02609 | Reg=0.00565 | acc=1.0000 | L2-Norm=23.778 | L2-Norm(final)=7.287 | 4502.5 samples/s | 70.4 steps/s
[Step=15750 Epoch=76.8] | Loss=0.02542 | Reg=0.00566 | acc=0.9844 | L2-Norm=23.791 | L2-Norm(final)=7.284 | 2512.2 samples/s | 39.3 steps/s
[Step=15800 Epoch=77.0] | Loss=0.02476 | Reg=0.00567 | acc=1.0000 | L2-Norm=23.802 | L2-Norm(final)=7.281 | 4313.8 samples/s | 67.4 steps/s
[Step=15850 Epoch=77.3] | Loss=0.02413 | Reg=0.00567 | acc=1.0000 | L2-Norm=23.812 | L2-Norm(final)=7.279 | 4508.7 samples/s | 70.4 steps/s
[Step=15900 Epoch=77.5] | Loss=0.02353 | Reg=0.00567 | acc=1.0000 | L2-Norm=23.820 | L2-Norm(final)=7.276 | 4431.9 samples/s | 69.2 steps/s
[Step=15950 Epoch=77.8] | Loss=0.02304 | Reg=0.00568 | acc=1.0000 | L2-Norm=23.826 | L2-Norm(final)=7.274 | 2394.4 samples/s | 37.4 steps/s
[Step=16000 Epoch=78.0] | Loss=0.02247 | Reg=0.00568 | acc=0.9688 | L2-Norm=23.830 | L2-Norm(final)=7.272 | 4470.7 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step16000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=68.3] | Loss=0.05478 | Reg=0.00513 | acc=0.9531 | L2-Norm=22.643 | L2-Norm(final)=6.748 | 5602.2 samples/s | 87.5 steps/s
[Step=14050 Epoch=68.6] | Loss=0.02426 | Reg=0.00513 | acc=0.9688 | L2-Norm=22.650 | L2-Norm(final)=6.770 | 4308.2 samples/s | 67.3 steps/s
[Step=14100 Epoch=68.8] | Loss=0.02297 | Reg=0.00514 | acc=0.9688 | L2-Norm=22.665 | L2-Norm(final)=6.800 | 5050.1 samples/s | 78.9 steps/s
[Step=14150 Epoch=69.0] | Loss=0.02204 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.682 | L2-Norm(final)=6.833 | 5054.7 samples/s | 79.0 steps/s
[Step=14200 Epoch=69.3] | Loss=0.02099 | Reg=0.00515 | acc=0.9688 | L2-Norm=22.700 | L2-Norm(final)=6.868 | 7901.5 samples/s | 123.5 steps/s
[Step=14250 Epoch=69.5] | Loss=0.01973 | Reg=0.00516 | acc=0.9688 | L2-Norm=22.720 | L2-Norm(final)=6.902 | 2183.4 samples/s | 34.1 steps/s
[Step=14300 Epoch=69.8] | Loss=0.01877 | Reg=0.00517 | acc=0.9844 | L2-Norm=22.739 | L2-Norm(final)=6.939 | 5088.1 samples/s | 79.5 steps/s
[Step=14350 Epoch=70.0] | Loss=0.01819 | Reg=0.00518 | acc=0.9844 | L2-Norm=22.757 | L2-Norm(final)=6.975 | 4945.0 samples/s | 77.3 steps/s
[Step=14400 Epoch=70.3] | Loss=0.01738 | Reg=0.00519 | acc=0.9688 | L2-Norm=22.773 | L2-Norm(final)=7.010 | 7067.9 samples/s | 110.4 steps/s
[Step=14450 Epoch=70.5] | Loss=0.01668 | Reg=0.00519 | acc=1.0000 | L2-Norm=22.786 | L2-Norm(final)=7.046 | 2261.3 samples/s | 35.3 steps/s
[Step=14500 Epoch=70.8] | Loss=0.01604 | Reg=0.00520 | acc=1.0000 | L2-Norm=22.800 | L2-Norm(final)=7.082 | 5031.0 samples/s | 78.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=70.8] | Loss=0.00997 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.942 | L2-Norm(final)=7.449 | 5364.6 samples/s | 83.8 steps/s
[Step=14550 Epoch=71.0] | Loss=0.02435 | Reg=0.00527 | acc=0.9844 | L2-Norm=22.963 | L2-Norm(final)=7.468 | 4050.2 samples/s | 63.3 steps/s
[Step=14600 Epoch=71.2] | Loss=0.02915 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.025 | L2-Norm(final)=7.462 | 4367.7 samples/s | 68.2 steps/s
[Step=14650 Epoch=71.5] | Loss=0.03676 | Reg=0.00533 | acc=0.9688 | L2-Norm=23.095 | L2-Norm(final)=7.453 | 4443.4 samples/s | 69.4 steps/s
[Step=14700 Epoch=71.7] | Loss=0.03977 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.169 | L2-Norm(final)=7.436 | 6580.0 samples/s | 102.8 steps/s
[Step=14750 Epoch=72.0] | Loss=0.03674 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.226 | L2-Norm(final)=7.420 | 2084.9 samples/s | 32.6 steps/s
[Step=14800 Epoch=72.2] | Loss=0.03598 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.272 | L2-Norm(final)=7.409 | 4325.7 samples/s | 67.6 steps/s
[Step=14850 Epoch=72.5] | Loss=0.03485 | Reg=0.00544 | acc=0.9844 | L2-Norm=23.315 | L2-Norm(final)=7.399 | 4270.3 samples/s | 66.7 steps/s
[Step=14900 Epoch=72.7] | Loss=0.03347 | Reg=0.00545 | acc=0.9688 | L2-Norm=23.353 | L2-Norm(final)=7.392 | 6008.7 samples/s | 93.9 steps/s
[Step=14950 Epoch=72.9] | Loss=0.03214 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.384 | L2-Norm(final)=7.387 | 2137.7 samples/s | 33.4 steps/s
[Step=15000 Epoch=73.2] | Loss=0.03157 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.413 | L2-Norm(final)=7.380 | 4503.2 samples/s | 70.4 steps/s
[Step=15050 Epoch=73.4] | Loss=0.03042 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.440 | L2-Norm(final)=7.374 | 4529.3 samples/s | 70.8 steps/s
[Step=15100 Epoch=73.7] | Loss=0.02955 | Reg=0.00551 | acc=0.9688 | L2-Norm=23.463 | L2-Norm(final)=7.369 | 5500.4 samples/s | 85.9 steps/s
[Step=15150 Epoch=73.9] | Loss=0.02843 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.485 | L2-Norm(final)=7.365 | 2229.7 samples/s | 34.8 steps/s
[Step=15200 Epoch=74.2] | Loss=0.02751 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.505 | L2-Norm(final)=7.361 | 4490.5 samples/s | 70.2 steps/s
[Step=15250 Epoch=74.4] | Loss=0.02653 | Reg=0.00553 | acc=0.9688 | L2-Norm=23.524 | L2-Norm(final)=7.358 | 4444.9 samples/s | 69.5 steps/s
[Step=15300 Epoch=74.7] | Loss=0.02565 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.540 | L2-Norm(final)=7.356 | 5178.1 samples/s | 80.9 steps/s
[Step=15350 Epoch=74.9] | Loss=0.02498 | Reg=0.00555 | acc=0.9844 | L2-Norm=23.554 | L2-Norm(final)=7.354 | 2223.0 samples/s | 34.7 steps/s
[Step=15400 Epoch=75.1] | Loss=0.02414 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.565 | L2-Norm(final)=7.352 | 4489.4 samples/s | 70.1 steps/s
[Step=15450 Epoch=75.4] | Loss=0.02351 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.575 | L2-Norm(final)=7.350 | 4543.5 samples/s | 71.0 steps/s
[Step=15500 Epoch=75.6] | Loss=0.02320 | Reg=0.00556 | acc=0.9844 | L2-Norm=23.584 | L2-Norm(final)=7.347 | 4826.5 samples/s | 75.4 steps/s
[Step=15550 Epoch=75.9] | Loss=0.02257 | Reg=0.00557 | acc=0.9688 | L2-Norm=23.593 | L2-Norm(final)=7.345 | 2371.8 samples/s | 37.1 steps/s
[Step=15600 Epoch=76.1] | Loss=0.02191 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.601 | L2-Norm(final)=7.343 | 4407.3 samples/s | 68.9 steps/s
[Step=15650 Epoch=76.4] | Loss=0.02146 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.608 | L2-Norm(final)=7.342 | 4470.8 samples/s | 69.9 steps/s
[Step=15700 Epoch=76.6] | Loss=0.02108 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.614 | L2-Norm(final)=7.341 | 4513.5 samples/s | 70.5 steps/s
[Step=15750 Epoch=76.9] | Loss=0.02068 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.620 | L2-Norm(final)=7.340 | 2429.8 samples/s | 38.0 steps/s
[Step=15800 Epoch=77.1] | Loss=0.02023 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.625 | L2-Norm(final)=7.339 | 4503.8 samples/s | 70.4 steps/s
[Step=15850 Epoch=77.3] | Loss=0.01997 | Reg=0.00558 | acc=0.9844 | L2-Norm=23.629 | L2-Norm(final)=7.338 | 4510.6 samples/s | 70.5 steps/s
[Step=15900 Epoch=77.6] | Loss=0.01956 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.633 | L2-Norm(final)=7.337 | 4541.6 samples/s | 71.0 steps/s
[Step=15950 Epoch=77.8] | Loss=0.01927 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.637 | L2-Norm(final)=7.336 | 2488.2 samples/s | 38.9 steps/s
[Step=16000 Epoch=78.1] | Loss=0.01893 | Reg=0.00559 | acc=0.9688 | L2-Norm=23.639 | L2-Norm(final)=7.336 | 4303.1 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step16000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=68.2] | Loss=0.02175 | Reg=0.00520 | acc=0.9844 | L2-Norm=22.813 | L2-Norm(final)=7.083 | 6333.0 samples/s | 99.0 steps/s
[Step=14050 Epoch=68.5] | Loss=0.02410 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.822 | L2-Norm(final)=7.111 | 4037.9 samples/s | 63.1 steps/s
[Step=14100 Epoch=68.7] | Loss=0.02505 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.829 | L2-Norm(final)=7.146 | 4973.2 samples/s | 77.7 steps/s
[Step=14150 Epoch=68.9] | Loss=0.02341 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.841 | L2-Norm(final)=7.182 | 5092.6 samples/s | 79.6 steps/s
[Step=14200 Epoch=69.2] | Loss=0.02352 | Reg=0.00522 | acc=0.9531 | L2-Norm=22.856 | L2-Norm(final)=7.216 | 7832.2 samples/s | 122.4 steps/s
[Step=14250 Epoch=69.4] | Loss=0.02248 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.875 | L2-Norm(final)=7.249 | 2228.9 samples/s | 34.8 steps/s
[Step=14300 Epoch=69.7] | Loss=0.02122 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.891 | L2-Norm(final)=7.285 | 5011.0 samples/s | 78.3 steps/s
[Step=14350 Epoch=69.9] | Loss=0.02073 | Reg=0.00525 | acc=1.0000 | L2-Norm=22.907 | L2-Norm(final)=7.320 | 4995.9 samples/s | 78.1 steps/s
[Step=14400 Epoch=70.2] | Loss=0.02020 | Reg=0.00526 | acc=0.9844 | L2-Norm=22.924 | L2-Norm(final)=7.356 | 6869.2 samples/s | 107.3 steps/s
[Step=14450 Epoch=70.4] | Loss=0.01936 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.941 | L2-Norm(final)=7.393 | 2290.8 samples/s | 35.8 steps/s
[Step=14500 Epoch=70.7] | Loss=0.01850 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.957 | L2-Norm(final)=7.431 | 5147.8 samples/s | 80.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=70.7] | Loss=0.00888 | Reg=0.00534 | acc=0.9844 | L2-Norm=23.117 | L2-Norm(final)=7.802 | 5634.4 samples/s | 88.0 steps/s
[Step=14550 Epoch=70.9] | Loss=0.02209 | Reg=0.00535 | acc=0.9844 | L2-Norm=23.138 | L2-Norm(final)=7.825 | 3994.8 samples/s | 62.4 steps/s
[Step=14600 Epoch=71.1] | Loss=0.03025 | Reg=0.00537 | acc=0.9688 | L2-Norm=23.179 | L2-Norm(final)=7.824 | 4406.7 samples/s | 68.9 steps/s
[Step=14650 Epoch=71.4] | Loss=0.03253 | Reg=0.00539 | acc=0.9844 | L2-Norm=23.223 | L2-Norm(final)=7.816 | 4593.5 samples/s | 71.8 steps/s
[Step=14700 Epoch=71.6] | Loss=0.03329 | Reg=0.00541 | acc=0.9688 | L2-Norm=23.269 | L2-Norm(final)=7.812 | 6169.7 samples/s | 96.4 steps/s
[Step=14750 Epoch=71.9] | Loss=0.03440 | Reg=0.00544 | acc=0.9375 | L2-Norm=23.320 | L2-Norm(final)=7.806 | 2068.2 samples/s | 32.3 steps/s
[Step=14800 Epoch=72.1] | Loss=0.03485 | Reg=0.00546 | acc=0.9531 | L2-Norm=23.370 | L2-Norm(final)=7.799 | 4505.3 samples/s | 70.4 steps/s
[Step=14850 Epoch=72.4] | Loss=0.03502 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.416 | L2-Norm(final)=7.787 | 4456.8 samples/s | 69.6 steps/s
[Step=14900 Epoch=72.6] | Loss=0.03403 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.458 | L2-Norm(final)=7.777 | 5930.6 samples/s | 92.7 steps/s
[Step=14950 Epoch=72.8] | Loss=0.03362 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.495 | L2-Norm(final)=7.768 | 2186.3 samples/s | 34.2 steps/s
[Step=15000 Epoch=73.1] | Loss=0.03247 | Reg=0.00554 | acc=0.9844 | L2-Norm=23.530 | L2-Norm(final)=7.762 | 4440.0 samples/s | 69.4 steps/s
[Step=15050 Epoch=73.3] | Loss=0.03138 | Reg=0.00555 | acc=0.9688 | L2-Norm=23.559 | L2-Norm(final)=7.756 | 4438.1 samples/s | 69.3 steps/s
[Step=15100 Epoch=73.6] | Loss=0.03067 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.584 | L2-Norm(final)=7.752 | 5323.1 samples/s | 83.2 steps/s
[Step=15150 Epoch=73.8] | Loss=0.02951 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.607 | L2-Norm(final)=7.748 | 2292.7 samples/s | 35.8 steps/s
[Step=15200 Epoch=74.1] | Loss=0.02850 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.627 | L2-Norm(final)=7.745 | 4395.0 samples/s | 68.7 steps/s
[Step=15250 Epoch=74.3] | Loss=0.02750 | Reg=0.00559 | acc=0.9375 | L2-Norm=23.645 | L2-Norm(final)=7.742 | 4477.3 samples/s | 70.0 steps/s
[Step=15300 Epoch=74.5] | Loss=0.02701 | Reg=0.00560 | acc=1.0000 | L2-Norm=23.662 | L2-Norm(final)=7.739 | 5010.3 samples/s | 78.3 steps/s
[Step=15350 Epoch=74.8] | Loss=0.02612 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.676 | L2-Norm(final)=7.737 | 2345.4 samples/s | 36.6 steps/s
[Step=15400 Epoch=75.0] | Loss=0.02535 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.689 | L2-Norm(final)=7.736 | 4425.5 samples/s | 69.1 steps/s
[Step=15450 Epoch=75.3] | Loss=0.02463 | Reg=0.00562 | acc=0.9844 | L2-Norm=23.700 | L2-Norm(final)=7.735 | 4499.0 samples/s | 70.3 steps/s
[Step=15500 Epoch=75.5] | Loss=0.02411 | Reg=0.00562 | acc=1.0000 | L2-Norm=23.709 | L2-Norm(final)=7.734 | 4580.0 samples/s | 71.6 steps/s
[Step=15550 Epoch=75.8] | Loss=0.02370 | Reg=0.00563 | acc=1.0000 | L2-Norm=23.719 | L2-Norm(final)=7.734 | 2423.4 samples/s | 37.9 steps/s
[Step=15600 Epoch=76.0] | Loss=0.02336 | Reg=0.00563 | acc=0.9688 | L2-Norm=23.728 | L2-Norm(final)=7.733 | 4525.0 samples/s | 70.7 steps/s
[Step=15650 Epoch=76.3] | Loss=0.02304 | Reg=0.00563 | acc=1.0000 | L2-Norm=23.736 | L2-Norm(final)=7.731 | 4444.1 samples/s | 69.4 steps/s
[Step=15700 Epoch=76.5] | Loss=0.02260 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.744 | L2-Norm(final)=7.730 | 4479.9 samples/s | 70.0 steps/s
[Step=15750 Epoch=76.7] | Loss=0.02205 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.751 | L2-Norm(final)=7.729 | 2476.6 samples/s | 38.7 steps/s
[Step=15800 Epoch=77.0] | Loss=0.02144 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.757 | L2-Norm(final)=7.728 | 4313.3 samples/s | 67.4 steps/s
[Step=15850 Epoch=77.2] | Loss=0.02092 | Reg=0.00565 | acc=0.9688 | L2-Norm=23.762 | L2-Norm(final)=7.728 | 4480.1 samples/s | 70.0 steps/s
[Step=15900 Epoch=77.5] | Loss=0.02067 | Reg=0.00565 | acc=1.0000 | L2-Norm=23.767 | L2-Norm(final)=7.728 | 4525.7 samples/s | 70.7 steps/s
[Step=15950 Epoch=77.7] | Loss=0.02039 | Reg=0.00565 | acc=1.0000 | L2-Norm=23.771 | L2-Norm(final)=7.728 | 2467.9 samples/s | 38.6 steps/s
[Step=16000 Epoch=78.0] | Loss=0.02010 | Reg=0.00565 | acc=1.0000 | L2-Norm=23.776 | L2-Norm(final)=7.727 | 4453.5 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step16000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=68.3] | Loss=0.06518 | Reg=0.00521 | acc=0.9219 | L2-Norm=22.817 | L2-Norm(final)=6.756 | 4923.0 samples/s | 76.9 steps/s
[Step=14050 Epoch=68.5] | Loss=0.02474 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.817 | L2-Norm(final)=6.786 | 4638.6 samples/s | 72.5 steps/s
[Step=14100 Epoch=68.8] | Loss=0.02506 | Reg=0.00521 | acc=0.9688 | L2-Norm=22.825 | L2-Norm(final)=6.826 | 5087.3 samples/s | 79.5 steps/s
[Step=14150 Epoch=69.0] | Loss=0.02427 | Reg=0.00522 | acc=0.9688 | L2-Norm=22.842 | L2-Norm(final)=6.861 | 5048.6 samples/s | 78.9 steps/s
[Step=14200 Epoch=69.2] | Loss=0.02394 | Reg=0.00523 | acc=1.0000 | L2-Norm=22.862 | L2-Norm(final)=6.894 | 7867.0 samples/s | 122.9 steps/s
[Step=14250 Epoch=69.5] | Loss=0.02261 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.884 | L2-Norm(final)=6.927 | 2207.4 samples/s | 34.5 steps/s
[Step=14300 Epoch=69.7] | Loss=0.02177 | Reg=0.00525 | acc=1.0000 | L2-Norm=22.905 | L2-Norm(final)=6.962 | 5104.6 samples/s | 79.8 steps/s
[Step=14350 Epoch=70.0] | Loss=0.02101 | Reg=0.00526 | acc=0.9844 | L2-Norm=22.925 | L2-Norm(final)=6.999 | 5013.1 samples/s | 78.3 steps/s
[Step=14400 Epoch=70.2] | Loss=0.02033 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.945 | L2-Norm(final)=7.035 | 6994.4 samples/s | 109.3 steps/s
[Step=14450 Epoch=70.5] | Loss=0.01960 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.966 | L2-Norm(final)=7.072 | 2283.3 samples/s | 35.7 steps/s
[Step=14500 Epoch=70.7] | Loss=0.01932 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.989 | L2-Norm(final)=7.108 | 5114.0 samples/s | 79.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=70.7] | Loss=0.01550 | Reg=0.00539 | acc=0.9844 | L2-Norm=23.212 | L2-Norm(final)=7.473 | 5720.0 samples/s | 89.4 steps/s
[Step=14550 Epoch=71.0] | Loss=0.01580 | Reg=0.00540 | acc=0.9844 | L2-Norm=23.233 | L2-Norm(final)=7.499 | 3870.5 samples/s | 60.5 steps/s
[Step=14600 Epoch=71.2] | Loss=0.02102 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.258 | L2-Norm(final)=7.511 | 4528.4 samples/s | 70.8 steps/s
[Step=14650 Epoch=71.4] | Loss=0.02346 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.290 | L2-Norm(final)=7.511 | 4432.2 samples/s | 69.3 steps/s
[Step=14700 Epoch=71.7] | Loss=0.02724 | Reg=0.00544 | acc=0.9688 | L2-Norm=23.324 | L2-Norm(final)=7.508 | 6569.4 samples/s | 102.6 steps/s
[Step=14750 Epoch=71.9] | Loss=0.02752 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.361 | L2-Norm(final)=7.503 | 2083.9 samples/s | 32.6 steps/s
[Step=14800 Epoch=72.2] | Loss=0.02646 | Reg=0.00547 | acc=0.9531 | L2-Norm=23.396 | L2-Norm(final)=7.500 | 4450.6 samples/s | 69.5 steps/s
[Step=14850 Epoch=72.4] | Loss=0.02702 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.427 | L2-Norm(final)=7.495 | 4549.2 samples/s | 71.1 steps/s
[Step=14900 Epoch=72.7] | Loss=0.02718 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.458 | L2-Norm(final)=7.491 | 5689.6 samples/s | 88.9 steps/s
[Step=14950 Epoch=72.9] | Loss=0.02589 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.485 | L2-Norm(final)=7.486 | 2198.0 samples/s | 34.3 steps/s
[Step=15000 Epoch=73.1] | Loss=0.02555 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.509 | L2-Norm(final)=7.482 | 4494.9 samples/s | 70.2 steps/s
[Step=15050 Epoch=73.4] | Loss=0.02605 | Reg=0.00554 | acc=0.9531 | L2-Norm=23.531 | L2-Norm(final)=7.477 | 4519.0 samples/s | 70.6 steps/s
[Step=15100 Epoch=73.6] | Loss=0.02535 | Reg=0.00555 | acc=0.9688 | L2-Norm=23.552 | L2-Norm(final)=7.472 | 5364.4 samples/s | 83.8 steps/s
[Step=15150 Epoch=73.9] | Loss=0.02499 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.571 | L2-Norm(final)=7.468 | 2216.8 samples/s | 34.6 steps/s
[Step=15200 Epoch=74.1] | Loss=0.02407 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.590 | L2-Norm(final)=7.464 | 4483.0 samples/s | 70.0 steps/s
[Step=15250 Epoch=74.4] | Loss=0.02369 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.608 | L2-Norm(final)=7.462 | 4495.2 samples/s | 70.2 steps/s
[Step=15300 Epoch=74.6] | Loss=0.02361 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.624 | L2-Norm(final)=7.460 | 4991.0 samples/s | 78.0 steps/s
[Step=15350 Epoch=74.9] | Loss=0.02293 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.640 | L2-Norm(final)=7.457 | 2334.5 samples/s | 36.5 steps/s
[Step=15400 Epoch=75.1] | Loss=0.02219 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.652 | L2-Norm(final)=7.456 | 4475.3 samples/s | 69.9 steps/s
[Step=15450 Epoch=75.3] | Loss=0.02168 | Reg=0.00560 | acc=1.0000 | L2-Norm=23.663 | L2-Norm(final)=7.455 | 4576.0 samples/s | 71.5 steps/s
[Step=15500 Epoch=75.6] | Loss=0.02110 | Reg=0.00560 | acc=0.9688 | L2-Norm=23.671 | L2-Norm(final)=7.453 | 4454.8 samples/s | 69.6 steps/s
[Step=15550 Epoch=75.8] | Loss=0.02051 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.678 | L2-Norm(final)=7.452 | 2432.1 samples/s | 38.0 steps/s
[Step=15600 Epoch=76.1] | Loss=0.01981 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.683 | L2-Norm(final)=7.452 | 4521.5 samples/s | 70.6 steps/s
[Step=15650 Epoch=76.3] | Loss=0.01931 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.686 | L2-Norm(final)=7.451 | 4427.1 samples/s | 69.2 steps/s
[Step=15700 Epoch=76.6] | Loss=0.01881 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.688 | L2-Norm(final)=7.451 | 4465.1 samples/s | 69.8 steps/s
[Step=15750 Epoch=76.8] | Loss=0.01860 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.688 | L2-Norm(final)=7.451 | 2485.4 samples/s | 38.8 steps/s
[Step=15800 Epoch=77.0] | Loss=0.01826 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.688 | L2-Norm(final)=7.450 | 4379.0 samples/s | 68.4 steps/s
[Step=15850 Epoch=77.3] | Loss=0.01803 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.688 | L2-Norm(final)=7.450 | 4457.3 samples/s | 69.6 steps/s
[Step=15900 Epoch=77.5] | Loss=0.01762 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.687 | L2-Norm(final)=7.449 | 4383.2 samples/s | 68.5 steps/s
[Step=15950 Epoch=77.8] | Loss=0.01731 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.686 | L2-Norm(final)=7.449 | 2486.4 samples/s | 38.8 steps/s
[Step=16000 Epoch=78.0] | Loss=0.01713 | Reg=0.00561 | acc=0.9688 | L2-Norm=23.685 | L2-Norm(final)=7.449 | 4532.8 samples/s | 70.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step16000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=68.7] | Loss=0.00842 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.847 | L2-Norm(final)=7.279 | 5670.1 samples/s | 88.6 steps/s
[Step=14050 Epoch=68.9] | Loss=0.02184 | Reg=0.00522 | acc=1.0000 | L2-Norm=22.854 | L2-Norm(final)=7.311 | 4340.3 samples/s | 67.8 steps/s
[Step=14100 Epoch=69.1] | Loss=0.02161 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.864 | L2-Norm(final)=7.348 | 5089.3 samples/s | 79.5 steps/s
[Step=14150 Epoch=69.4] | Loss=0.02030 | Reg=0.00523 | acc=0.9844 | L2-Norm=22.875 | L2-Norm(final)=7.379 | 5072.8 samples/s | 79.3 steps/s
[Step=14200 Epoch=69.6] | Loss=0.01978 | Reg=0.00524 | acc=1.0000 | L2-Norm=22.887 | L2-Norm(final)=7.409 | 7564.5 samples/s | 118.2 steps/s
[Step=14250 Epoch=69.9] | Loss=0.01887 | Reg=0.00524 | acc=0.9844 | L2-Norm=22.898 | L2-Norm(final)=7.438 | 2184.0 samples/s | 34.1 steps/s
[Step=14300 Epoch=70.1] | Loss=0.01779 | Reg=0.00525 | acc=0.9844 | L2-Norm=22.909 | L2-Norm(final)=7.470 | 5034.4 samples/s | 78.7 steps/s
[Step=14350 Epoch=70.4] | Loss=0.01691 | Reg=0.00525 | acc=1.0000 | L2-Norm=22.920 | L2-Norm(final)=7.503 | 5065.6 samples/s | 79.1 steps/s
[Step=14400 Epoch=70.6] | Loss=0.01642 | Reg=0.00526 | acc=0.9688 | L2-Norm=22.931 | L2-Norm(final)=7.537 | 7405.1 samples/s | 115.7 steps/s
[Step=14450 Epoch=70.9] | Loss=0.01577 | Reg=0.00526 | acc=0.9844 | L2-Norm=22.943 | L2-Norm(final)=7.569 | 2243.2 samples/s | 35.1 steps/s
[Step=14500 Epoch=71.1] | Loss=0.01519 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.954 | L2-Norm(final)=7.603 | 5176.2 samples/s | 80.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=71.1] | Loss=0.03700 | Reg=0.00532 | acc=0.9531 | L2-Norm=23.063 | L2-Norm(final)=7.938 | 5281.2 samples/s | 82.5 steps/s
[Step=14550 Epoch=71.4] | Loss=0.01625 | Reg=0.00532 | acc=0.9844 | L2-Norm=23.074 | L2-Norm(final)=7.954 | 4053.5 samples/s | 63.3 steps/s
[Step=14600 Epoch=71.6] | Loss=0.02807 | Reg=0.00534 | acc=0.9844 | L2-Norm=23.116 | L2-Norm(final)=7.942 | 4503.4 samples/s | 70.4 steps/s
[Step=14650 Epoch=71.8] | Loss=0.04026 | Reg=0.00537 | acc=0.9375 | L2-Norm=23.182 | L2-Norm(final)=7.916 | 4541.1 samples/s | 71.0 steps/s
[Step=14700 Epoch=72.1] | Loss=0.04262 | Reg=0.00541 | acc=0.9688 | L2-Norm=23.254 | L2-Norm(final)=7.888 | 6497.5 samples/s | 101.5 steps/s
[Step=14750 Epoch=72.3] | Loss=0.03867 | Reg=0.00543 | acc=0.9844 | L2-Norm=23.308 | L2-Norm(final)=7.872 | 2065.1 samples/s | 32.3 steps/s
[Step=14800 Epoch=72.6] | Loss=0.03708 | Reg=0.00545 | acc=0.9375 | L2-Norm=23.349 | L2-Norm(final)=7.861 | 4474.5 samples/s | 69.9 steps/s
[Step=14850 Epoch=72.8] | Loss=0.03593 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.387 | L2-Norm(final)=7.851 | 4429.7 samples/s | 69.2 steps/s
[Step=14900 Epoch=73.1] | Loss=0.03410 | Reg=0.00548 | acc=0.9688 | L2-Norm=23.418 | L2-Norm(final)=7.843 | 6151.2 samples/s | 96.1 steps/s
[Step=14950 Epoch=73.3] | Loss=0.03202 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.444 | L2-Norm(final)=7.838 | 2139.3 samples/s | 33.4 steps/s
[Step=15000 Epoch=73.6] | Loss=0.03047 | Reg=0.00551 | acc=0.9844 | L2-Norm=23.465 | L2-Norm(final)=7.834 | 4488.3 samples/s | 70.1 steps/s
[Step=15050 Epoch=73.8] | Loss=0.02924 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.483 | L2-Norm(final)=7.830 | 4516.5 samples/s | 70.6 steps/s
[Step=15100 Epoch=74.0] | Loss=0.02818 | Reg=0.00552 | acc=0.9688 | L2-Norm=23.497 | L2-Norm(final)=7.826 | 5848.7 samples/s | 91.4 steps/s
[Step=15150 Epoch=74.3] | Loss=0.02693 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.511 | L2-Norm(final)=7.823 | 2176.6 samples/s | 34.0 steps/s
[Step=15200 Epoch=74.5] | Loss=0.02598 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.522 | L2-Norm(final)=7.822 | 4402.4 samples/s | 68.8 steps/s
[Step=15250 Epoch=74.8] | Loss=0.02529 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.532 | L2-Norm(final)=7.820 | 4423.9 samples/s | 69.1 steps/s
[Step=15300 Epoch=75.0] | Loss=0.02449 | Reg=0.00554 | acc=0.9688 | L2-Norm=23.541 | L2-Norm(final)=7.818 | 5497.3 samples/s | 85.9 steps/s
[Step=15350 Epoch=75.3] | Loss=0.02369 | Reg=0.00555 | acc=0.9844 | L2-Norm=23.549 | L2-Norm(final)=7.817 | 2219.9 samples/s | 34.7 steps/s
[Step=15400 Epoch=75.5] | Loss=0.02286 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.555 | L2-Norm(final)=7.817 | 4569.5 samples/s | 71.4 steps/s
[Step=15450 Epoch=75.8] | Loss=0.02222 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.560 | L2-Norm(final)=7.816 | 4403.2 samples/s | 68.8 steps/s
[Step=15500 Epoch=76.0] | Loss=0.02176 | Reg=0.00555 | acc=0.9688 | L2-Norm=23.563 | L2-Norm(final)=7.815 | 5206.8 samples/s | 81.4 steps/s
[Step=15550 Epoch=76.3] | Loss=0.02141 | Reg=0.00555 | acc=0.9688 | L2-Norm=23.566 | L2-Norm(final)=7.814 | 2269.1 samples/s | 35.5 steps/s
[Step=15600 Epoch=76.5] | Loss=0.02076 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.567 | L2-Norm(final)=7.813 | 4546.7 samples/s | 71.0 steps/s
[Step=15650 Epoch=76.7] | Loss=0.02024 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.568 | L2-Norm(final)=7.812 | 4357.2 samples/s | 68.1 steps/s
[Step=15700 Epoch=77.0] | Loss=0.01983 | Reg=0.00556 | acc=0.9844 | L2-Norm=23.569 | L2-Norm(final)=7.812 | 4880.2 samples/s | 76.3 steps/s
[Step=15750 Epoch=77.2] | Loss=0.01963 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.568 | L2-Norm(final)=7.811 | 2370.9 samples/s | 37.0 steps/s
[Step=15800 Epoch=77.5] | Loss=0.01914 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.568 | L2-Norm(final)=7.810 | 4417.7 samples/s | 69.0 steps/s
[Step=15850 Epoch=77.7] | Loss=0.01892 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.566 | L2-Norm(final)=7.809 | 4439.1 samples/s | 69.4 steps/s
[Step=15900 Epoch=78.0] | Loss=0.01867 | Reg=0.00555 | acc=0.9688 | L2-Norm=23.566 | L2-Norm(final)=7.809 | 4676.0 samples/s | 73.1 steps/s
[Step=15950 Epoch=78.2] | Loss=0.01840 | Reg=0.00555 | acc=0.9844 | L2-Norm=23.565 | L2-Norm(final)=7.808 | 2320.1 samples/s | 36.3 steps/s
[Step=16000 Epoch=78.5] | Loss=0.01824 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.565 | L2-Norm(final)=7.808 | 4482.6 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step16000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=132.7] | Loss=0.03049 | Reg=0.00180 | acc=0.9844 | L2-Norm=13.402 | L2-Norm(final)=4.587 | 4818.5 samples/s | 75.3 steps/s
[Step=14050 Epoch=133.1] | Loss=0.00293 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.466 | L2-Norm(final)=4.599 | 4465.5 samples/s | 69.8 steps/s
[Step=14100 Epoch=133.6] | Loss=0.00203 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.511 | L2-Norm(final)=4.627 | 7401.1 samples/s | 115.6 steps/s
[Step=14150 Epoch=134.1] | Loss=0.00149 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.538 | L2-Norm(final)=4.647 | 2143.9 samples/s | 33.5 steps/s
[Step=14200 Epoch=134.6] | Loss=0.00121 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.554 | L2-Norm(final)=4.663 | 6596.9 samples/s | 103.1 steps/s
[Step=14250 Epoch=135.0] | Loss=0.00100 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.563 | L2-Norm(final)=4.678 | 2180.3 samples/s | 34.1 steps/s
[Step=14300 Epoch=135.5] | Loss=0.00086 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.567 | L2-Norm(final)=4.690 | 5778.7 samples/s | 90.3 steps/s
[Step=14350 Epoch=136.0] | Loss=0.00076 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.568 | L2-Norm(final)=4.703 | 2311.3 samples/s | 36.1 steps/s
[Step=14400 Epoch=136.5] | Loss=0.00069 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.567 | L2-Norm(final)=4.714 | 5267.7 samples/s | 82.3 steps/s
[Step=14450 Epoch=136.9] | Loss=0.00063 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=4.726 | 2427.3 samples/s | 37.9 steps/s
[Step=14500 Epoch=137.4] | Loss=0.00057 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=4.736 | 4853.3 samples/s | 75.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=137.4] | Loss=0.00014 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.525 | L2-Norm(final)=4.841 | 5579.7 samples/s | 87.2 steps/s
[Step=14550 Epoch=137.9] | Loss=0.00263 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.527 | L2-Norm(final)=4.849 | 3688.5 samples/s | 57.6 steps/s
[Step=14600 Epoch=138.3] | Loss=0.00824 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.694 | L2-Norm(final)=4.813 | 6249.6 samples/s | 97.6 steps/s
[Step=14650 Epoch=138.8] | Loss=0.00815 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.845 | L2-Norm(final)=4.779 | 2018.1 samples/s | 31.5 steps/s
[Step=14700 Epoch=139.3] | Loss=0.00921 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=4.749 | 5642.3 samples/s | 88.2 steps/s
[Step=14750 Epoch=139.8] | Loss=0.00753 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.027 | L2-Norm(final)=4.731 | 2086.5 samples/s | 32.6 steps/s
[Step=14800 Epoch=140.2] | Loss=0.00641 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.073 | L2-Norm(final)=4.719 | 5051.8 samples/s | 78.9 steps/s
[Step=14850 Epoch=140.7] | Loss=0.00550 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.103 | L2-Norm(final)=4.712 | 2160.2 samples/s | 33.8 steps/s
[Step=14900 Epoch=141.2] | Loss=0.00482 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.122 | L2-Norm(final)=4.707 | 4718.5 samples/s | 73.7 steps/s
[Step=14950 Epoch=141.7] | Loss=0.00429 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.134 | L2-Norm(final)=4.703 | 2282.5 samples/s | 35.7 steps/s
[Step=15000 Epoch=142.1] | Loss=0.00386 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.141 | L2-Norm(final)=4.700 | 4335.1 samples/s | 67.7 steps/s
[Step=15050 Epoch=142.6] | Loss=0.00351 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.144 | L2-Norm(final)=4.698 | 2363.0 samples/s | 36.9 steps/s
[Step=15100 Epoch=143.1] | Loss=0.00322 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.144 | L2-Norm(final)=4.697 | 4256.3 samples/s | 66.5 steps/s
[Step=15150 Epoch=143.6] | Loss=0.00297 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.142 | L2-Norm(final)=4.696 | 2338.1 samples/s | 36.5 steps/s
[Step=15200 Epoch=144.0] | Loss=0.00276 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.137 | L2-Norm(final)=4.696 | 4227.2 samples/s | 66.0 steps/s
[Step=15250 Epoch=144.5] | Loss=0.00258 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.132 | L2-Norm(final)=4.696 | 2515.0 samples/s | 39.3 steps/s
[Step=15300 Epoch=145.0] | Loss=0.00242 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=4.697 | 3928.3 samples/s | 61.4 steps/s
[Step=15350 Epoch=145.5] | Loss=0.00228 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.117 | L2-Norm(final)=4.698 | 2468.1 samples/s | 38.6 steps/s
[Step=15400 Epoch=145.9] | Loss=0.00215 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=4.699 | 4047.7 samples/s | 63.2 steps/s
[Step=15450 Epoch=146.4] | Loss=0.00204 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=4.700 | 6452.1 samples/s | 100.8 steps/s
[Step=15500 Epoch=146.9] | Loss=0.00194 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.089 | L2-Norm(final)=4.702 | 1985.3 samples/s | 31.0 steps/s
[Step=15550 Epoch=147.3] | Loss=0.00184 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.078 | L2-Norm(final)=4.704 | 5834.3 samples/s | 91.2 steps/s
[Step=15600 Epoch=147.8] | Loss=0.00176 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.067 | L2-Norm(final)=4.706 | 2056.4 samples/s | 32.1 steps/s
[Step=15650 Epoch=148.3] | Loss=0.00168 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.055 | L2-Norm(final)=4.708 | 5327.9 samples/s | 83.2 steps/s
[Step=15700 Epoch=148.8] | Loss=0.00161 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.043 | L2-Norm(final)=4.710 | 2116.6 samples/s | 33.1 steps/s
[Step=15750 Epoch=149.2] | Loss=0.00155 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.031 | L2-Norm(final)=4.713 | 4869.7 samples/s | 76.1 steps/s
[Step=15800 Epoch=149.7] | Loss=0.00149 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.018 | L2-Norm(final)=4.715 | 2256.6 samples/s | 35.3 steps/s
[Step=15850 Epoch=150.2] | Loss=0.00144 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.005 | L2-Norm(final)=4.717 | 4428.7 samples/s | 69.2 steps/s
[Step=15900 Epoch=150.7] | Loss=0.00138 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.991 | L2-Norm(final)=4.720 | 2358.3 samples/s | 36.8 steps/s
[Step=15950 Epoch=151.1] | Loss=0.00134 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.977 | L2-Norm(final)=4.723 | 4186.5 samples/s | 65.4 steps/s
[Step=16000 Epoch=151.6] | Loss=0.00129 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.963 | L2-Norm(final)=4.725 | 2357.6 samples/s | 36.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step16000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=133.2] | Loss=0.00816 | Reg=0.00159 | acc=0.9844 | L2-Norm=12.619 | L2-Norm(final)=5.154 | 5225.4 samples/s | 81.6 steps/s
[Step=14050 Epoch=133.7] | Loss=0.00267 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.791 | L2-Norm(final)=5.187 | 4390.3 samples/s | 68.6 steps/s
[Step=14100 Epoch=134.1] | Loss=0.00274 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.943 | L2-Norm(final)=5.212 | 7349.2 samples/s | 114.8 steps/s
[Step=14150 Epoch=134.6] | Loss=0.00213 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.030 | L2-Norm(final)=5.232 | 2126.2 samples/s | 33.2 steps/s
[Step=14200 Epoch=135.1] | Loss=0.00168 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.086 | L2-Norm(final)=5.251 | 6467.1 samples/s | 101.0 steps/s
[Step=14250 Epoch=135.6] | Loss=0.00138 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.118 | L2-Norm(final)=5.269 | 2202.6 samples/s | 34.4 steps/s
[Step=14300 Epoch=136.0] | Loss=0.00117 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.137 | L2-Norm(final)=5.284 | 5961.3 samples/s | 93.1 steps/s
[Step=14350 Epoch=136.5] | Loss=0.00102 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.148 | L2-Norm(final)=5.297 | 2308.5 samples/s | 36.1 steps/s
[Step=14400 Epoch=137.0] | Loss=0.00091 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.154 | L2-Norm(final)=5.310 | 5366.3 samples/s | 83.8 steps/s
[Step=14450 Epoch=137.5] | Loss=0.00082 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.156 | L2-Norm(final)=5.322 | 2374.6 samples/s | 37.1 steps/s
[Step=14500 Epoch=137.9] | Loss=0.00075 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.156 | L2-Norm(final)=5.333 | 4928.6 samples/s | 77.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=137.9] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.149 | L2-Norm(final)=5.443 | 5327.0 samples/s | 83.2 steps/s
[Step=14550 Epoch=138.4] | Loss=0.03252 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.301 | L2-Norm(final)=5.421 | 3668.7 samples/s | 57.3 steps/s
[Step=14600 Epoch=138.9] | Loss=0.02316 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.712 | L2-Norm(final)=5.309 | 6268.4 samples/s | 97.9 steps/s
[Step=14650 Epoch=139.4] | Loss=0.01596 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.890 | L2-Norm(final)=5.270 | 2014.6 samples/s | 31.5 steps/s
[Step=14700 Epoch=139.8] | Loss=0.01207 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.977 | L2-Norm(final)=5.254 | 5720.3 samples/s | 89.4 steps/s
[Step=14750 Epoch=140.3] | Loss=0.01136 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.037 | L2-Norm(final)=5.243 | 2083.0 samples/s | 32.5 steps/s
[Step=14800 Epoch=140.8] | Loss=0.00966 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.089 | L2-Norm(final)=5.235 | 5165.2 samples/s | 80.7 steps/s
[Step=14850 Epoch=141.3] | Loss=0.00831 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=5.230 | 2146.2 samples/s | 33.5 steps/s
[Step=14900 Epoch=141.7] | Loss=0.00728 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.149 | L2-Norm(final)=5.228 | 4663.4 samples/s | 72.9 steps/s
[Step=14950 Epoch=142.2] | Loss=0.00648 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.165 | L2-Norm(final)=5.226 | 2281.3 samples/s | 35.6 steps/s
[Step=15000 Epoch=142.7] | Loss=0.00584 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.175 | L2-Norm(final)=5.225 | 4332.4 samples/s | 67.7 steps/s
[Step=15050 Epoch=143.2] | Loss=0.00531 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.180 | L2-Norm(final)=5.224 | 2374.8 samples/s | 37.1 steps/s
[Step=15100 Epoch=143.6] | Loss=0.00487 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.182 | L2-Norm(final)=5.224 | 4127.3 samples/s | 64.5 steps/s
[Step=15150 Epoch=144.1] | Loss=0.00450 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.182 | L2-Norm(final)=5.224 | 2415.8 samples/s | 37.7 steps/s
[Step=15200 Epoch=144.6] | Loss=0.00418 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.179 | L2-Norm(final)=5.224 | 4179.2 samples/s | 65.3 steps/s
[Step=15250 Epoch=145.1] | Loss=0.00390 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.175 | L2-Norm(final)=5.224 | 2384.4 samples/s | 37.3 steps/s
[Step=15300 Epoch=145.5] | Loss=0.00366 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.170 | L2-Norm(final)=5.224 | 4242.1 samples/s | 66.3 steps/s
[Step=15350 Epoch=146.0] | Loss=0.00344 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.163 | L2-Norm(final)=5.225 | 2504.5 samples/s | 39.1 steps/s
[Step=15400 Epoch=146.5] | Loss=0.00325 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.156 | L2-Norm(final)=5.225 | 3937.7 samples/s | 61.5 steps/s
[Step=15450 Epoch=147.0] | Loss=0.00308 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.148 | L2-Norm(final)=5.226 | 6448.5 samples/s | 100.8 steps/s
[Step=15500 Epoch=147.4] | Loss=0.00293 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.139 | L2-Norm(final)=5.226 | 1995.3 samples/s | 31.2 steps/s
[Step=15550 Epoch=147.9] | Loss=0.00279 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.130 | L2-Norm(final)=5.227 | 5867.7 samples/s | 91.7 steps/s
[Step=15600 Epoch=148.4] | Loss=0.00267 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.120 | L2-Norm(final)=5.227 | 2060.8 samples/s | 32.2 steps/s
[Step=15650 Epoch=148.9] | Loss=0.00255 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=5.228 | 5347.2 samples/s | 83.5 steps/s
[Step=15700 Epoch=149.3] | Loss=0.00244 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.098 | L2-Norm(final)=5.228 | 2149.7 samples/s | 33.6 steps/s
[Step=15750 Epoch=149.8] | Loss=0.00235 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.087 | L2-Norm(final)=5.229 | 4734.4 samples/s | 74.0 steps/s
[Step=15800 Epoch=150.3] | Loss=0.00226 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.076 | L2-Norm(final)=5.230 | 2200.2 samples/s | 34.4 steps/s
[Step=15850 Epoch=150.8] | Loss=0.00217 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=5.231 | 4533.0 samples/s | 70.8 steps/s
[Step=15900 Epoch=151.2] | Loss=0.00210 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.052 | L2-Norm(final)=5.233 | 2324.2 samples/s | 36.3 steps/s
[Step=15950 Epoch=151.7] | Loss=0.00202 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.040 | L2-Norm(final)=5.236 | 4254.7 samples/s | 66.5 steps/s
[Step=16000 Epoch=152.2] | Loss=0.00196 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.027 | L2-Norm(final)=5.238 | 2432.6 samples/s | 38.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step16000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=133.7] | Loss=0.00632 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.223 | L2-Norm(final)=4.864 | 5180.1 samples/s | 80.9 steps/s
[Step=14050 Epoch=134.2] | Loss=0.00352 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.323 | L2-Norm(final)=4.902 | 4221.3 samples/s | 66.0 steps/s
[Step=14100 Epoch=134.6] | Loss=0.00226 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.397 | L2-Norm(final)=4.938 | 7523.4 samples/s | 117.6 steps/s
[Step=14150 Epoch=135.1] | Loss=0.00165 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.435 | L2-Norm(final)=4.965 | 2182.7 samples/s | 34.1 steps/s
[Step=14200 Epoch=135.6] | Loss=0.00132 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.457 | L2-Norm(final)=4.988 | 6299.4 samples/s | 98.4 steps/s
[Step=14250 Epoch=136.1] | Loss=0.00110 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.471 | L2-Norm(final)=5.009 | 2185.7 samples/s | 34.2 steps/s
[Step=14300 Epoch=136.6] | Loss=0.00095 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.480 | L2-Norm(final)=5.028 | 6158.8 samples/s | 96.2 steps/s
[Step=14350 Epoch=137.0] | Loss=0.00083 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.485 | L2-Norm(final)=5.045 | 2263.2 samples/s | 35.4 steps/s
[Step=14400 Epoch=137.5] | Loss=0.00075 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.488 | L2-Norm(final)=5.061 | 5560.0 samples/s | 86.9 steps/s
[Step=14450 Epoch=138.0] | Loss=0.00068 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.489 | L2-Norm(final)=5.077 | 2391.9 samples/s | 37.4 steps/s
[Step=14500 Epoch=138.5] | Loss=0.00062 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.488 | L2-Norm(final)=5.091 | 4921.3 samples/s | 76.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=138.5] | Loss=0.00011 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.475 | L2-Norm(final)=5.235 | 4783.4 samples/s | 74.7 steps/s
[Step=14550 Epoch=138.9] | Loss=0.00009 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.459 | L2-Norm(final)=5.247 | 4073.8 samples/s | 63.7 steps/s
[Step=14600 Epoch=139.4] | Loss=0.00006 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.437 | L2-Norm(final)=5.254 | 6198.4 samples/s | 96.9 steps/s
[Step=14650 Epoch=139.9] | Loss=0.00004 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.412 | L2-Norm(final)=5.259 | 2025.8 samples/s | 31.7 steps/s
[Step=14700 Epoch=140.4] | Loss=0.00003 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.385 | L2-Norm(final)=5.261 | 5683.8 samples/s | 88.8 steps/s
[Step=14750 Epoch=140.9] | Loss=0.00003 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.357 | L2-Norm(final)=5.263 | 2074.1 samples/s | 32.4 steps/s
[Step=14800 Epoch=141.3] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.329 | L2-Norm(final)=5.265 | 5315.4 samples/s | 83.1 steps/s
[Step=14850 Epoch=141.8] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.301 | L2-Norm(final)=5.266 | 2108.1 samples/s | 32.9 steps/s
[Step=14900 Epoch=142.3] | Loss=0.00002 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.273 | L2-Norm(final)=5.267 | 5010.6 samples/s | 78.3 steps/s
[Step=14950 Epoch=142.8] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.245 | L2-Norm(final)=5.269 | 2219.2 samples/s | 34.7 steps/s
[Step=15000 Epoch=143.2] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.216 | L2-Norm(final)=5.270 | 4632.8 samples/s | 72.4 steps/s
[Step=15050 Epoch=143.7] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.188 | L2-Norm(final)=5.271 | 2288.3 samples/s | 35.8 steps/s
[Step=15100 Epoch=144.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.160 | L2-Norm(final)=5.271 | 4428.2 samples/s | 69.2 steps/s
[Step=15150 Epoch=144.7] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.132 | L2-Norm(final)=5.272 | 2302.7 samples/s | 36.0 steps/s
[Step=15200 Epoch=145.2] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.103 | L2-Norm(final)=5.273 | 4244.1 samples/s | 66.3 steps/s
[Step=15250 Epoch=145.6] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.075 | L2-Norm(final)=5.274 | 2428.4 samples/s | 37.9 steps/s
[Step=15300 Epoch=146.1] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.047 | L2-Norm(final)=5.275 | 4163.5 samples/s | 65.1 steps/s
[Step=15350 Epoch=146.6] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.019 | L2-Norm(final)=5.276 | 2371.1 samples/s | 37.0 steps/s
[Step=15400 Epoch=147.1] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.991 | L2-Norm(final)=5.276 | 4400.6 samples/s | 68.8 steps/s
[Step=15450 Epoch=147.5] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.962 | L2-Norm(final)=5.277 | 2321.5 samples/s | 36.3 steps/s
[Step=15500 Epoch=148.0] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.934 | L2-Norm(final)=5.278 | 4209.6 samples/s | 65.8 steps/s
[Step=15550 Epoch=148.5] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.906 | L2-Norm(final)=5.279 | 6934.6 samples/s | 108.4 steps/s
[Step=15600 Epoch=149.0] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.878 | L2-Norm(final)=5.279 | 1966.4 samples/s | 30.7 steps/s
[Step=15650 Epoch=149.4] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.850 | L2-Norm(final)=5.280 | 6411.9 samples/s | 100.2 steps/s
[Step=15700 Epoch=149.9] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.822 | L2-Norm(final)=5.281 | 2016.6 samples/s | 31.5 steps/s
[Step=15750 Epoch=150.4] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.793 | L2-Norm(final)=5.282 | 5602.6 samples/s | 87.5 steps/s
[Step=15800 Epoch=150.9] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.765 | L2-Norm(final)=5.282 | 2063.4 samples/s | 32.2 steps/s
[Step=15850 Epoch=151.4] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.737 | L2-Norm(final)=5.283 | 5362.9 samples/s | 83.8 steps/s
[Step=15900 Epoch=151.8] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.709 | L2-Norm(final)=5.284 | 2142.9 samples/s | 33.5 steps/s
[Step=15950 Epoch=152.3] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.680 | L2-Norm(final)=5.285 | 4954.2 samples/s | 77.4 steps/s
[Step=16000 Epoch=152.8] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.652 | L2-Norm(final)=5.285 | 2238.0 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step16000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=131.9] | Loss=0.00053 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.055 | L2-Norm(final)=4.759 | 5780.1 samples/s | 90.3 steps/s
[Step=14050 Epoch=132.4] | Loss=0.00524 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.231 | L2-Norm(final)=4.749 | 3941.9 samples/s | 61.6 steps/s
[Step=14100 Epoch=132.9] | Loss=0.00334 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.340 | L2-Norm(final)=4.772 | 7177.5 samples/s | 112.1 steps/s
[Step=14150 Epoch=133.3] | Loss=0.00234 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.406 | L2-Norm(final)=4.796 | 2153.7 samples/s | 33.7 steps/s
[Step=14200 Epoch=133.8] | Loss=0.00181 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.438 | L2-Norm(final)=4.817 | 6389.9 samples/s | 99.8 steps/s
[Step=14250 Epoch=134.3] | Loss=0.00147 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.455 | L2-Norm(final)=4.834 | 2257.7 samples/s | 35.3 steps/s
[Step=14300 Epoch=134.7] | Loss=0.00125 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.462 | L2-Norm(final)=4.849 | 5643.8 samples/s | 88.2 steps/s
[Step=14350 Epoch=135.2] | Loss=0.00109 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.464 | L2-Norm(final)=4.863 | 2315.3 samples/s | 36.2 steps/s
[Step=14400 Epoch=135.7] | Loss=0.00096 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.463 | L2-Norm(final)=4.876 | 5098.1 samples/s | 79.7 steps/s
[Step=14450 Epoch=136.2] | Loss=0.00087 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.460 | L2-Norm(final)=4.888 | 2468.3 samples/s | 38.6 steps/s
[Step=14500 Epoch=136.6] | Loss=0.00079 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.456 | L2-Norm(final)=4.900 | 4842.4 samples/s | 75.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=136.6] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.404 | L2-Norm(final)=5.017 | 5729.0 samples/s | 89.5 steps/s
[Step=14550 Epoch=137.1] | Loss=0.00006 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.381 | L2-Norm(final)=5.025 | 3603.6 samples/s | 56.3 steps/s
[Step=14600 Epoch=137.6] | Loss=0.00198 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.354 | L2-Norm(final)=5.030 | 6135.4 samples/s | 95.9 steps/s
[Step=14650 Epoch=138.0] | Loss=0.01884 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.549 | L2-Norm(final)=4.955 | 1975.7 samples/s | 30.9 steps/s
[Step=14700 Epoch=138.5] | Loss=0.01667 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.745 | L2-Norm(final)=4.882 | 5514.2 samples/s | 86.2 steps/s
[Step=14750 Epoch=139.0] | Loss=0.01351 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=4.838 | 2153.0 samples/s | 33.6 steps/s
[Step=14800 Epoch=139.5] | Loss=0.01128 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.947 | L2-Norm(final)=4.810 | 4867.4 samples/s | 76.1 steps/s
[Step=14850 Epoch=139.9] | Loss=0.00968 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.001 | L2-Norm(final)=4.791 | 2237.2 samples/s | 35.0 steps/s
[Step=14900 Epoch=140.4] | Loss=0.00848 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.038 | L2-Norm(final)=4.777 | 4315.2 samples/s | 67.4 steps/s
[Step=14950 Epoch=140.9] | Loss=0.00754 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=4.766 | 2340.4 samples/s | 36.6 steps/s
[Step=15000 Epoch=141.3] | Loss=0.00679 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.083 | L2-Norm(final)=4.757 | 4258.1 samples/s | 66.5 steps/s
[Step=15050 Epoch=141.8] | Loss=0.00618 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.096 | L2-Norm(final)=4.751 | 2385.1 samples/s | 37.3 steps/s
[Step=15100 Epoch=142.3] | Loss=0.00566 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.105 | L2-Norm(final)=4.745 | 4244.3 samples/s | 66.3 steps/s
[Step=15150 Epoch=142.8] | Loss=0.00523 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.110 | L2-Norm(final)=4.741 | 2376.0 samples/s | 37.1 steps/s
[Step=15200 Epoch=143.2] | Loss=0.00486 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.113 | L2-Norm(final)=4.737 | 4156.0 samples/s | 64.9 steps/s
[Step=15250 Epoch=143.7] | Loss=0.00453 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.113 | L2-Norm(final)=4.734 | 2567.2 samples/s | 40.1 steps/s
[Step=15300 Epoch=144.2] | Loss=0.00425 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.112 | L2-Norm(final)=4.732 | 3779.0 samples/s | 59.0 steps/s
[Step=15350 Epoch=144.6] | Loss=0.00400 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=4.731 | 6344.6 samples/s | 99.1 steps/s
[Step=15400 Epoch=145.1] | Loss=0.00378 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.106 | L2-Norm(final)=4.730 | 2045.7 samples/s | 32.0 steps/s
[Step=15450 Epoch=145.6] | Loss=0.00358 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.101 | L2-Norm(final)=4.729 | 5473.6 samples/s | 85.5 steps/s
[Step=15500 Epoch=146.1] | Loss=0.00340 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.095 | L2-Norm(final)=4.729 | 2116.2 samples/s | 33.1 steps/s
[Step=15550 Epoch=146.5] | Loss=0.00324 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.088 | L2-Norm(final)=4.729 | 4961.0 samples/s | 77.5 steps/s
[Step=15600 Epoch=147.0] | Loss=0.00309 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.081 | L2-Norm(final)=4.730 | 2238.3 samples/s | 35.0 steps/s
[Step=15650 Epoch=147.5] | Loss=0.00296 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.073 | L2-Norm(final)=4.730 | 4419.4 samples/s | 69.1 steps/s
[Step=15700 Epoch=147.9] | Loss=0.00284 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=4.731 | 2326.9 samples/s | 36.4 steps/s
[Step=15750 Epoch=148.4] | Loss=0.00272 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.055 | L2-Norm(final)=4.732 | 4177.5 samples/s | 65.3 steps/s
[Step=15800 Epoch=148.9] | Loss=0.00262 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.045 | L2-Norm(final)=4.733 | 2364.8 samples/s | 37.0 steps/s
[Step=15850 Epoch=149.4] | Loss=0.00252 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.035 | L2-Norm(final)=4.734 | 4259.6 samples/s | 66.6 steps/s
[Step=15900 Epoch=149.8] | Loss=0.00243 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.025 | L2-Norm(final)=4.735 | 2406.0 samples/s | 37.6 steps/s
[Step=15950 Epoch=150.3] | Loss=0.00235 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.014 | L2-Norm(final)=4.736 | 4238.7 samples/s | 66.2 steps/s
[Step=16000 Epoch=150.8] | Loss=0.00227 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.003 | L2-Norm(final)=4.738 | 2441.4 samples/s | 38.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step16000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=133.4] | Loss=0.00430 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.359 | L2-Norm(final)=5.563 | 5275.7 samples/s | 82.4 steps/s
[Step=14050 Epoch=133.9] | Loss=0.00642 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.535 | L2-Norm(final)=5.571 | 4107.0 samples/s | 64.2 steps/s
[Step=14100 Epoch=134.4] | Loss=0.00443 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.668 | L2-Norm(final)=5.588 | 7684.7 samples/s | 120.1 steps/s
[Step=14150 Epoch=134.9] | Loss=0.00316 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.740 | L2-Norm(final)=5.607 | 2128.9 samples/s | 33.3 steps/s
[Step=14200 Epoch=135.3] | Loss=0.00255 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.783 | L2-Norm(final)=5.625 | 6742.3 samples/s | 105.3 steps/s
[Step=14250 Epoch=135.8] | Loss=0.00211 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.813 | L2-Norm(final)=5.642 | 2218.4 samples/s | 34.7 steps/s
[Step=14300 Epoch=136.3] | Loss=0.00181 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.832 | L2-Norm(final)=5.658 | 6141.1 samples/s | 96.0 steps/s
[Step=14350 Epoch=136.8] | Loss=0.00159 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.844 | L2-Norm(final)=5.672 | 2248.2 samples/s | 35.1 steps/s
[Step=14400 Epoch=137.2] | Loss=0.00142 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.852 | L2-Norm(final)=5.685 | 5652.4 samples/s | 88.3 steps/s
[Step=14450 Epoch=137.7] | Loss=0.00128 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.857 | L2-Norm(final)=5.697 | 2378.3 samples/s | 37.2 steps/s
[Step=14500 Epoch=138.2] | Loss=0.00117 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.859 | L2-Norm(final)=5.708 | 5024.4 samples/s | 78.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=138.2] | Loss=0.00015 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.873 | L2-Norm(final)=5.820 | 5467.5 samples/s | 85.4 steps/s
[Step=14550 Epoch=138.7] | Loss=0.04224 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.020 | L2-Norm(final)=5.785 | 3700.4 samples/s | 57.8 steps/s
[Step=14600 Epoch=139.2] | Loss=0.03108 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.373 | L2-Norm(final)=5.680 | 6397.8 samples/s | 100.0 steps/s
[Step=14650 Epoch=139.6] | Loss=0.02119 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.521 | L2-Norm(final)=5.643 | 2000.8 samples/s | 31.3 steps/s
[Step=14700 Epoch=140.1] | Loss=0.01604 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=5.627 | 5802.4 samples/s | 90.7 steps/s
[Step=14750 Epoch=140.6] | Loss=0.01285 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=5.618 | 2075.6 samples/s | 32.4 steps/s
[Step=14800 Epoch=141.1] | Loss=0.01072 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=5.613 | 5360.4 samples/s | 83.8 steps/s
[Step=14850 Epoch=141.5] | Loss=0.00920 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=5.610 | 2176.2 samples/s | 34.0 steps/s
[Step=14900 Epoch=142.0] | Loss=0.00806 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=5.608 | 4874.1 samples/s | 76.2 steps/s
[Step=14950 Epoch=142.5] | Loss=0.00716 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=5.606 | 2192.4 samples/s | 34.3 steps/s
[Step=15000 Epoch=143.0] | Loss=0.00645 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=5.605 | 4614.4 samples/s | 72.1 steps/s
[Step=15050 Epoch=143.4] | Loss=0.00587 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=5.605 | 2262.4 samples/s | 35.3 steps/s
[Step=15100 Epoch=143.9] | Loss=0.00538 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=5.604 | 4351.3 samples/s | 68.0 steps/s
[Step=15150 Epoch=144.4] | Loss=0.00497 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=5.604 | 2362.3 samples/s | 36.9 steps/s
[Step=15200 Epoch=144.9] | Loss=0.00461 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.640 | L2-Norm(final)=5.604 | 4318.1 samples/s | 67.5 steps/s
[Step=15250 Epoch=145.3] | Loss=0.00431 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.630 | L2-Norm(final)=5.604 | 2353.8 samples/s | 36.8 steps/s
[Step=15300 Epoch=145.8] | Loss=0.00404 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=5.604 | 4172.2 samples/s | 65.2 steps/s
[Step=15350 Epoch=146.3] | Loss=0.00380 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=5.604 | 2394.4 samples/s | 37.4 steps/s
[Step=15400 Epoch=146.8] | Loss=0.00359 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=5.604 | 4314.4 samples/s | 67.4 steps/s
[Step=15450 Epoch=147.3] | Loss=0.00340 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.584 | L2-Norm(final)=5.604 | 2323.5 samples/s | 36.3 steps/s
[Step=15500 Epoch=147.7] | Loss=0.00323 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.572 | L2-Norm(final)=5.604 | 4294.9 samples/s | 67.1 steps/s
[Step=15550 Epoch=148.2] | Loss=0.00308 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.559 | L2-Norm(final)=5.605 | 6763.0 samples/s | 105.7 steps/s
[Step=15600 Epoch=148.7] | Loss=0.00294 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.545 | L2-Norm(final)=5.605 | 1967.7 samples/s | 30.7 steps/s
[Step=15650 Epoch=149.2] | Loss=0.00281 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=5.605 | 6130.6 samples/s | 95.8 steps/s
[Step=15700 Epoch=149.6] | Loss=0.00270 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.518 | L2-Norm(final)=5.605 | 2041.9 samples/s | 31.9 steps/s
[Step=15750 Epoch=150.1] | Loss=0.00259 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.504 | L2-Norm(final)=5.606 | 5638.5 samples/s | 88.1 steps/s
[Step=15800 Epoch=150.6] | Loss=0.00249 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.489 | L2-Norm(final)=5.606 | 2061.7 samples/s | 32.2 steps/s
[Step=15850 Epoch=151.1] | Loss=0.00240 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.475 | L2-Norm(final)=5.606 | 5247.9 samples/s | 82.0 steps/s
[Step=15900 Epoch=151.5] | Loss=0.00231 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.460 | L2-Norm(final)=5.607 | 2151.4 samples/s | 33.6 steps/s
[Step=15950 Epoch=152.0] | Loss=0.00223 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.445 | L2-Norm(final)=5.608 | 4864.6 samples/s | 76.0 steps/s
[Step=16000 Epoch=152.5] | Loss=0.00216 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.430 | L2-Norm(final)=5.608 | 2199.6 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.13351 | acc=0.9495 | tpr=0.9688 | fpr=0.0924 | 4743.1 samples/s | 18.5 steps/s
Avg test loss: 0.13753, Avg test acc: 0.94755, Avg tpr: 0.96695, Avg fpr: 0.09512, total FA: 742

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.16767 | acc=0.9406 | tpr=0.9754 | fpr=0.1348 | 4672.8 samples/s | 18.3 steps/s
Avg test loss: 0.16474, Avg test acc: 0.94014, Avg tpr: 0.97476, Avg fpr: 0.13601, total FA: 1061

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14514 | acc=0.9421 | tpr=0.9560 | fpr=0.0880 | 4809.8 samples/s | 18.8 steps/s
Avg test loss: 0.14376, Avg test acc: 0.94166, Avg tpr: 0.95564, Avg fpr: 0.08909, total FA: 695

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14145 | acc=0.9457 | tpr=0.9682 | fpr=0.1031 | 4806.9 samples/s | 18.8 steps/s
Avg test loss: 0.14619, Avg test acc: 0.94467, Avg tpr: 0.96923, Avg fpr: 0.10934, total FA: 853

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.12281 | acc=0.9410 | tpr=0.9542 | fpr=0.0877 | 4841.1 samples/s | 18.9 steps/s
Avg test loss: 0.12336, Avg test acc: 0.94198, Avg tpr: 0.95430, Avg fpr: 0.08512, total FA: 664

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.43520 | acc=0.3098 | tpr=0.0228 | fpr=0.0669 | 4719.6 samples/s | 18.4 steps/s
Avg test loss: 4.44436, Avg test acc: 0.30696, Avg tpr: 0.02256, Avg fpr: 0.06756, total FA: 527

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=3.98746 | acc=0.3086 | tpr=0.0034 | fpr=0.0287 | 4669.2 samples/s | 18.2 steps/s
Avg test loss: 4.00334, Avg test acc: 0.30539, Avg tpr: 0.00350, Avg fpr: 0.03064, total FA: 239

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.70216 | acc=0.2573 | tpr=0.0266 | fpr=0.2418 | 4794.7 samples/s | 18.7 steps/s
Avg test loss: 5.70486, Avg test acc: 0.25599, Avg tpr: 0.02774, Avg fpr: 0.24202, total FA: 1888

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.05888 | acc=0.3043 | tpr=0.0249 | fpr=0.0889 | 4708.8 samples/s | 18.4 steps/s
Avg test loss: 5.08029, Avg test acc: 0.30331, Avg tpr: 0.02489, Avg fpr: 0.08435, total FA: 658

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.17911 | acc=0.3127 | tpr=0.0084 | fpr=0.0268 | 4575.0 samples/s | 17.9 steps/s
Avg test loss: 5.19503, Avg test acc: 0.31072, Avg tpr: 0.00799, Avg fpr: 0.02346, total FA: 183

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.02708 | acc=0.1073 | tpr=0.7035 | fpr=0.9035 | 4785.9 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.99003 | acc=0.1074 | tpr=0.6780 | fpr=0.9032 | 7017.0 samples/s | 27.4 steps/s
[Step= 150] | Loss=5.99529 | acc=0.1072 | tpr=0.6772 | fpr=0.9033 | 7981.7 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.98365 | acc=0.1076 | tpr=0.6787 | fpr=0.9028 | 8199.8 samples/s | 32.0 steps/s
[Step= 250] | Loss=5.99339 | acc=0.1086 | tpr=0.6821 | fpr=0.9018 | 7357.5 samples/s | 28.7 steps/s
[Step= 300] | Loss=5.99808 | acc=0.1080 | tpr=0.6807 | fpr=0.9025 | 8280.1 samples/s | 32.3 steps/s
[Step= 350] | Loss=5.99803 | acc=0.1079 | tpr=0.6863 | fpr=0.9026 | 8124.0 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.99535 | acc=0.1081 | tpr=0.6849 | fpr=0.9023 | 7385.5 samples/s | 28.8 steps/s
[Step= 450] | Loss=5.99459 | acc=0.1080 | tpr=0.6870 | fpr=0.9025 | 8667.0 samples/s | 33.9 steps/s
[Step= 500] | Loss=5.99706 | acc=0.1083 | tpr=0.6837 | fpr=0.9021 | 7475.1 samples/s | 29.2 steps/s
[Step= 550] | Loss=5.99630 | acc=0.1083 | tpr=0.6825 | fpr=0.9022 | 13730.7 samples/s | 53.6 steps/s
Avg test loss: 5.99850, Avg test acc: 0.10819, Avg tpr: 0.68304, Avg fpr: 0.90226, total FA: 125277

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.34752 | acc=0.0719 | tpr=0.6726 | fpr=0.9389 | 5010.5 samples/s | 19.6 steps/s
[Step= 100] | Loss=6.34266 | acc=0.0720 | tpr=0.6930 | fpr=0.9396 | 6803.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=6.34257 | acc=0.0720 | tpr=0.6686 | fpr=0.9390 | 7592.3 samples/s | 29.7 steps/s
[Step= 200] | Loss=6.33322 | acc=0.0721 | tpr=0.6678 | fpr=0.9387 | 7626.0 samples/s | 29.8 steps/s
[Step= 250] | Loss=6.34393 | acc=0.0721 | tpr=0.6681 | fpr=0.9388 | 8143.2 samples/s | 31.8 steps/s
[Step= 300] | Loss=6.33488 | acc=0.0719 | tpr=0.6713 | fpr=0.9390 | 7909.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.32880 | acc=0.0717 | tpr=0.6619 | fpr=0.9390 | 7997.7 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.32607 | acc=0.0717 | tpr=0.6586 | fpr=0.9390 | 7564.4 samples/s | 29.5 steps/s
[Step= 450] | Loss=6.33164 | acc=0.0720 | tpr=0.6665 | fpr=0.9387 | 8153.4 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.33847 | acc=0.0714 | tpr=0.6577 | fpr=0.9391 | 8055.2 samples/s | 31.5 steps/s
[Step= 550] | Loss=6.33983 | acc=0.0717 | tpr=0.6590 | fpr=0.9390 | 13340.2 samples/s | 52.1 steps/s
Avg test loss: 6.34163, Avg test acc: 0.07163, Avg tpr: 0.65808, Avg fpr: 0.93903, total FA: 130382

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.82111 | acc=0.0991 | tpr=0.6062 | fpr=0.9101 | 4645.1 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.79417 | acc=0.0992 | tpr=0.6141 | fpr=0.9104 | 7387.8 samples/s | 28.9 steps/s
[Step= 150] | Loss=5.79530 | acc=0.1000 | tpr=0.5980 | fpr=0.9092 | 7931.9 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.78720 | acc=0.0997 | tpr=0.6066 | fpr=0.9095 | 7854.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.79271 | acc=0.0995 | tpr=0.6105 | fpr=0.9099 | 7857.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.79009 | acc=0.0994 | tpr=0.6109 | fpr=0.9099 | 7966.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.78159 | acc=0.0999 | tpr=0.6099 | fpr=0.9093 | 7862.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.77271 | acc=0.1000 | tpr=0.6105 | fpr=0.9092 | 7860.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.77384 | acc=0.0998 | tpr=0.6110 | fpr=0.9094 | 7703.3 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.77333 | acc=0.0997 | tpr=0.6119 | fpr=0.9095 | 8207.8 samples/s | 32.1 steps/s
[Step= 550] | Loss=5.77162 | acc=0.0994 | tpr=0.6080 | fpr=0.9098 | 13536.1 samples/s | 52.9 steps/s
Avg test loss: 5.77465, Avg test acc: 0.09933, Avg tpr: 0.60935, Avg fpr: 0.90994, total FA: 126343

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.03276 | acc=0.1276 | tpr=0.6637 | fpr=0.8821 | 4917.4 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.03053 | acc=0.1275 | tpr=0.6525 | fpr=0.8823 | 6822.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.02349 | acc=0.1287 | tpr=0.6585 | fpr=0.8810 | 7973.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.01502 | acc=0.1297 | tpr=0.6765 | fpr=0.8803 | 7670.9 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.02406 | acc=0.1295 | tpr=0.6760 | fpr=0.8804 | 8302.2 samples/s | 32.4 steps/s
[Step= 300] | Loss=5.01932 | acc=0.1293 | tpr=0.6778 | fpr=0.8807 | 7442.2 samples/s | 29.1 steps/s
[Step= 350] | Loss=5.01061 | acc=0.1296 | tpr=0.6844 | fpr=0.8805 | 7978.4 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.00780 | acc=0.1295 | tpr=0.6876 | fpr=0.8807 | 7933.1 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.01179 | acc=0.1296 | tpr=0.6952 | fpr=0.8807 | 8110.9 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.01167 | acc=0.1292 | tpr=0.6899 | fpr=0.8809 | 7744.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.01230 | acc=0.1295 | tpr=0.6904 | fpr=0.8807 | 14144.7 samples/s | 55.3 steps/s
Avg test loss: 5.01303, Avg test acc: 0.12940, Avg tpr: 0.69057, Avg fpr: 0.88080, total FA: 122297

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.82553 | acc=0.0961 | tpr=0.6947 | fpr=0.9147 | 4952.6 samples/s | 19.3 steps/s
[Step= 100] | Loss=4.81407 | acc=0.0973 | tpr=0.6631 | fpr=0.9133 | 6929.6 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.81852 | acc=0.0980 | tpr=0.6571 | fpr=0.9123 | 7578.4 samples/s | 29.6 steps/s
[Step= 200] | Loss=4.82047 | acc=0.0982 | tpr=0.6568 | fpr=0.9120 | 8058.3 samples/s | 31.5 steps/s
[Step= 250] | Loss=4.83203 | acc=0.0981 | tpr=0.6524 | fpr=0.9120 | 7918.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=4.83410 | acc=0.0974 | tpr=0.6516 | fpr=0.9127 | 7998.3 samples/s | 31.2 steps/s
[Step= 350] | Loss=4.82687 | acc=0.0970 | tpr=0.6512 | fpr=0.9130 | 7836.1 samples/s | 30.6 steps/s
[Step= 400] | Loss=4.82285 | acc=0.0974 | tpr=0.6554 | fpr=0.9128 | 7820.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=4.82242 | acc=0.0977 | tpr=0.6573 | fpr=0.9125 | 7788.3 samples/s | 30.4 steps/s
[Step= 500] | Loss=4.82930 | acc=0.0976 | tpr=0.6559 | fpr=0.9125 | 8203.8 samples/s | 32.0 steps/s
[Step= 550] | Loss=4.82887 | acc=0.0978 | tpr=0.6574 | fpr=0.9124 | 13634.8 samples/s | 53.3 steps/s
Avg test loss: 4.83014, Avg test acc: 0.09766, Avg tpr: 0.65729, Avg fpr: 0.91251, total FA: 126700

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09546 | acc=0.9819 | tpr=0.9159 | fpr=0.0169 | 4943.4 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.09697 | acc=0.9815 | tpr=0.9232 | fpr=0.0174 | 6624.9 samples/s | 25.9 steps/s
[Step= 150] | Loss=0.10136 | acc=0.9805 | tpr=0.9265 | fpr=0.0185 | 7984.8 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.10272 | acc=0.9804 | tpr=0.9290 | fpr=0.0187 | 8124.6 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.10064 | acc=0.9808 | tpr=0.9240 | fpr=0.0182 | 7837.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.10235 | acc=0.9806 | tpr=0.9215 | fpr=0.0183 | 7866.2 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10444 | acc=0.9803 | tpr=0.9211 | fpr=0.0187 | 7952.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.10543 | acc=0.9799 | tpr=0.9152 | fpr=0.0190 | 7938.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.10717 | acc=0.9796 | tpr=0.9129 | fpr=0.0192 | 7803.0 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.10624 | acc=0.9797 | tpr=0.9145 | fpr=0.0191 | 7965.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.10546 | acc=0.9800 | tpr=0.9144 | fpr=0.0189 | 13910.9 samples/s | 54.3 steps/s
Avg test loss: 0.10522, Avg test acc: 0.97997, Avg tpr: 0.91442, Avg fpr: 0.01884, total FA: 2616

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09880 | acc=0.9826 | tpr=0.8628 | fpr=0.0153 | 4714.9 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10460 | acc=0.9818 | tpr=0.8699 | fpr=0.0161 | 7369.5 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.10856 | acc=0.9810 | tpr=0.8674 | fpr=0.0169 | 7792.0 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.11146 | acc=0.9808 | tpr=0.8699 | fpr=0.0172 | 7823.8 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.10937 | acc=0.9810 | tpr=0.8664 | fpr=0.0169 | 7927.0 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.11102 | acc=0.9808 | tpr=0.8655 | fpr=0.0171 | 8246.9 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.11188 | acc=0.9806 | tpr=0.8679 | fpr=0.0174 | 7663.4 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.11291 | acc=0.9804 | tpr=0.8643 | fpr=0.0175 | 7795.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.11503 | acc=0.9801 | tpr=0.8617 | fpr=0.0178 | 7829.4 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.11411 | acc=0.9800 | tpr=0.8630 | fpr=0.0179 | 8056.1 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.11330 | acc=0.9802 | tpr=0.8619 | fpr=0.0176 | 13625.4 samples/s | 53.2 steps/s
Avg test loss: 0.11302, Avg test acc: 0.98021, Avg tpr: 0.86173, Avg fpr: 0.01764, total FA: 2449

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09471 | acc=0.9796 | tpr=0.9513 | fpr=0.0199 | 4863.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09664 | acc=0.9793 | tpr=0.9467 | fpr=0.0201 | 7223.1 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.10101 | acc=0.9786 | tpr=0.9481 | fpr=0.0208 | 7615.1 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.10278 | acc=0.9786 | tpr=0.9475 | fpr=0.0208 | 7509.0 samples/s | 29.3 steps/s
[Step= 250] | Loss=0.10094 | acc=0.9791 | tpr=0.9476 | fpr=0.0204 | 8352.3 samples/s | 32.6 steps/s
[Step= 300] | Loss=0.10326 | acc=0.9789 | tpr=0.9425 | fpr=0.0205 | 7940.8 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.10386 | acc=0.9789 | tpr=0.9424 | fpr=0.0204 | 7980.8 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.10514 | acc=0.9787 | tpr=0.9415 | fpr=0.0206 | 7854.3 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.10633 | acc=0.9786 | tpr=0.9411 | fpr=0.0207 | 7668.8 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.10557 | acc=0.9786 | tpr=0.9423 | fpr=0.0207 | 7998.2 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.10518 | acc=0.9788 | tpr=0.9423 | fpr=0.0206 | 14299.0 samples/s | 55.9 steps/s
Avg test loss: 0.10524, Avg test acc: 0.97879, Avg tpr: 0.94255, Avg fpr: 0.02055, total FA: 2853

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.13268 | acc=0.9798 | tpr=0.9159 | fpr=0.0191 | 4904.7 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13401 | acc=0.9802 | tpr=0.9339 | fpr=0.0189 | 6588.4 samples/s | 25.7 steps/s
[Step= 150] | Loss=0.14036 | acc=0.9797 | tpr=0.9380 | fpr=0.0195 | 8538.9 samples/s | 33.4 steps/s
[Step= 200] | Loss=0.14326 | acc=0.9796 | tpr=0.9421 | fpr=0.0197 | 7632.3 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.13991 | acc=0.9797 | tpr=0.9345 | fpr=0.0195 | 7944.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.14271 | acc=0.9794 | tpr=0.9265 | fpr=0.0196 | 7856.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.14403 | acc=0.9792 | tpr=0.9292 | fpr=0.0199 | 7754.4 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.14517 | acc=0.9790 | tpr=0.9283 | fpr=0.0201 | 8163.9 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.14759 | acc=0.9786 | tpr=0.9255 | fpr=0.0205 | 7789.9 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.14657 | acc=0.9787 | tpr=0.9278 | fpr=0.0204 | 7874.1 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.14633 | acc=0.9789 | tpr=0.9292 | fpr=0.0202 | 14121.4 samples/s | 55.2 steps/s
Avg test loss: 0.14622, Avg test acc: 0.97887, Avg tpr: 0.92908, Avg fpr: 0.02022, total FA: 2808

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10763 | acc=0.9808 | tpr=0.8761 | fpr=0.0173 | 4814.9 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.11058 | acc=0.9811 | tpr=0.8977 | fpr=0.0174 | 7343.0 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.11549 | acc=0.9801 | tpr=0.9063 | fpr=0.0186 | 7844.8 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.11677 | acc=0.9803 | tpr=0.9137 | fpr=0.0185 | 7864.0 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.11561 | acc=0.9805 | tpr=0.9109 | fpr=0.0182 | 7752.7 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.11745 | acc=0.9802 | tpr=0.9113 | fpr=0.0185 | 7679.4 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.11960 | acc=0.9798 | tpr=0.9105 | fpr=0.0189 | 8346.2 samples/s | 32.6 steps/s
[Step= 400] | Loss=0.12063 | acc=0.9797 | tpr=0.9026 | fpr=0.0189 | 7872.1 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.12344 | acc=0.9793 | tpr=0.9002 | fpr=0.0193 | 7649.3 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.12278 | acc=0.9794 | tpr=0.9031 | fpr=0.0193 | 7884.9 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.12252 | acc=0.9795 | tpr=0.9025 | fpr=0.0191 | 14196.8 samples/s | 55.5 steps/s
Avg test loss: 0.12228, Avg test acc: 0.97948, Avg tpr: 0.90214, Avg fpr: 0.01911, total FA: 2654

server round 8/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=78.0] | Loss=0.05499 | Reg=0.00539 | acc=0.9531 | L2-Norm=23.215 | L2-Norm(final)=7.211 | 5144.6 samples/s | 80.4 steps/s
[Step=16050 Epoch=78.3] | Loss=0.03510 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.226 | L2-Norm(final)=7.243 | 4634.5 samples/s | 72.4 steps/s
[Step=16100 Epoch=78.5] | Loss=0.03054 | Reg=0.00541 | acc=0.9688 | L2-Norm=23.250 | L2-Norm(final)=7.296 | 5062.7 samples/s | 79.1 steps/s
[Step=16150 Epoch=78.8] | Loss=0.02791 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.276 | L2-Norm(final)=7.351 | 5122.5 samples/s | 80.0 steps/s
[Step=16200 Epoch=79.0] | Loss=0.02662 | Reg=0.00543 | acc=0.9688 | L2-Norm=23.302 | L2-Norm(final)=7.398 | 7744.4 samples/s | 121.0 steps/s
[Step=16250 Epoch=79.2] | Loss=0.02505 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.331 | L2-Norm(final)=7.444 | 2261.3 samples/s | 35.3 steps/s
[Step=16300 Epoch=79.5] | Loss=0.02384 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.358 | L2-Norm(final)=7.493 | 5005.6 samples/s | 78.2 steps/s
[Step=16350 Epoch=79.7] | Loss=0.02279 | Reg=0.00547 | acc=0.9688 | L2-Norm=23.385 | L2-Norm(final)=7.542 | 5005.4 samples/s | 78.2 steps/s
[Step=16400 Epoch=80.0] | Loss=0.02239 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.412 | L2-Norm(final)=7.590 | 6999.4 samples/s | 109.4 steps/s
[Step=16450 Epoch=80.2] | Loss=0.02162 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.437 | L2-Norm(final)=7.637 | 2328.5 samples/s | 36.4 steps/s
[Step=16500 Epoch=80.5] | Loss=0.02087 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.461 | L2-Norm(final)=7.684 | 4867.9 samples/s | 76.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=80.5] | Loss=0.00826 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.691 | L2-Norm(final)=8.159 | 5333.9 samples/s | 83.3 steps/s
[Step=16550 Epoch=80.7] | Loss=0.01514 | Reg=0.00562 | acc=1.0000 | L2-Norm=23.707 | L2-Norm(final)=8.196 | 4063.5 samples/s | 63.5 steps/s
[Step=16600 Epoch=80.9] | Loss=0.02513 | Reg=0.00564 | acc=0.9531 | L2-Norm=23.745 | L2-Norm(final)=8.203 | 4546.0 samples/s | 71.0 steps/s
[Step=16650 Epoch=81.2] | Loss=0.02944 | Reg=0.00567 | acc=0.9844 | L2-Norm=23.801 | L2-Norm(final)=8.190 | 4516.9 samples/s | 70.6 steps/s
[Step=16700 Epoch=81.4] | Loss=0.03371 | Reg=0.00569 | acc=0.9844 | L2-Norm=23.861 | L2-Norm(final)=8.178 | 6425.6 samples/s | 100.4 steps/s
[Step=16750 Epoch=81.7] | Loss=0.03560 | Reg=0.00572 | acc=0.9688 | L2-Norm=23.916 | L2-Norm(final)=8.159 | 2083.9 samples/s | 32.6 steps/s
[Step=16800 Epoch=81.9] | Loss=0.03413 | Reg=0.00574 | acc=0.9844 | L2-Norm=23.961 | L2-Norm(final)=8.143 | 4505.3 samples/s | 70.4 steps/s
[Step=16850 Epoch=82.2] | Loss=0.03336 | Reg=0.00576 | acc=0.9844 | L2-Norm=24.000 | L2-Norm(final)=8.130 | 4511.7 samples/s | 70.5 steps/s
[Step=16900 Epoch=82.4] | Loss=0.03271 | Reg=0.00578 | acc=0.9531 | L2-Norm=24.034 | L2-Norm(final)=8.120 | 5877.3 samples/s | 91.8 steps/s
[Step=16950 Epoch=82.7] | Loss=0.03189 | Reg=0.00579 | acc=0.9844 | L2-Norm=24.065 | L2-Norm(final)=8.111 | 2169.4 samples/s | 33.9 steps/s
[Step=17000 Epoch=82.9] | Loss=0.03093 | Reg=0.00581 | acc=1.0000 | L2-Norm=24.094 | L2-Norm(final)=8.104 | 4478.4 samples/s | 70.0 steps/s
[Step=17050 Epoch=83.1] | Loss=0.02970 | Reg=0.00582 | acc=1.0000 | L2-Norm=24.119 | L2-Norm(final)=8.097 | 4494.1 samples/s | 70.2 steps/s
[Step=17100 Epoch=83.4] | Loss=0.02835 | Reg=0.00583 | acc=1.0000 | L2-Norm=24.141 | L2-Norm(final)=8.092 | 5429.6 samples/s | 84.8 steps/s
[Step=17150 Epoch=83.6] | Loss=0.02755 | Reg=0.00584 | acc=1.0000 | L2-Norm=24.159 | L2-Norm(final)=8.087 | 2248.0 samples/s | 35.1 steps/s
[Step=17200 Epoch=83.9] | Loss=0.02668 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.177 | L2-Norm(final)=8.083 | 4492.7 samples/s | 70.2 steps/s
[Step=17250 Epoch=84.1] | Loss=0.02553 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.192 | L2-Norm(final)=8.080 | 4490.4 samples/s | 70.2 steps/s
[Step=17300 Epoch=84.4] | Loss=0.02482 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.203 | L2-Norm(final)=8.076 | 4939.4 samples/s | 77.2 steps/s
[Step=17350 Epoch=84.6] | Loss=0.02396 | Reg=0.00586 | acc=1.0000 | L2-Norm=24.213 | L2-Norm(final)=8.074 | 2356.3 samples/s | 36.8 steps/s
[Step=17400 Epoch=84.8] | Loss=0.02309 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.221 | L2-Norm(final)=8.072 | 4425.7 samples/s | 69.2 steps/s
[Step=17450 Epoch=85.1] | Loss=0.02252 | Reg=0.00587 | acc=0.9531 | L2-Norm=24.228 | L2-Norm(final)=8.071 | 4508.1 samples/s | 70.4 steps/s
[Step=17500 Epoch=85.3] | Loss=0.02213 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.234 | L2-Norm(final)=8.070 | 4634.3 samples/s | 72.4 steps/s
[Step=17550 Epoch=85.6] | Loss=0.02178 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.239 | L2-Norm(final)=8.068 | 2406.1 samples/s | 37.6 steps/s
[Step=17600 Epoch=85.8] | Loss=0.02111 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.243 | L2-Norm(final)=8.067 | 4479.8 samples/s | 70.0 steps/s
[Step=17650 Epoch=86.1] | Loss=0.02059 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.246 | L2-Norm(final)=8.066 | 4502.1 samples/s | 70.3 steps/s
[Step=17700 Epoch=86.3] | Loss=0.02054 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.249 | L2-Norm(final)=8.065 | 4483.5 samples/s | 70.1 steps/s
[Step=17750 Epoch=86.6] | Loss=0.02012 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.253 | L2-Norm(final)=8.064 | 2440.0 samples/s | 38.1 steps/s
[Step=17800 Epoch=86.8] | Loss=0.01987 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.256 | L2-Norm(final)=8.062 | 4508.3 samples/s | 70.4 steps/s
[Step=17850 Epoch=87.0] | Loss=0.01951 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.260 | L2-Norm(final)=8.061 | 4431.2 samples/s | 69.2 steps/s
[Step=17900 Epoch=87.3] | Loss=0.01923 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.263 | L2-Norm(final)=8.059 | 4496.9 samples/s | 70.3 steps/s
[Step=17950 Epoch=87.5] | Loss=0.01927 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.267 | L2-Norm(final)=8.057 | 2452.3 samples/s | 38.3 steps/s
[Step=18000 Epoch=87.8] | Loss=0.01916 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.272 | L2-Norm(final)=8.054 | 4457.3 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step18000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=78.1] | Loss=0.03311 | Reg=0.00533 | acc=0.9688 | L2-Norm=23.078 | L2-Norm(final)=7.314 | 5922.0 samples/s | 92.5 steps/s
[Step=16050 Epoch=78.3] | Loss=0.03494 | Reg=0.00535 | acc=0.9219 | L2-Norm=23.125 | L2-Norm(final)=7.336 | 4215.6 samples/s | 65.9 steps/s
[Step=16100 Epoch=78.6] | Loss=0.03288 | Reg=0.00536 | acc=0.9844 | L2-Norm=23.158 | L2-Norm(final)=7.381 | 5169.8 samples/s | 80.8 steps/s
[Step=16150 Epoch=78.8] | Loss=0.03079 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.188 | L2-Norm(final)=7.425 | 4940.6 samples/s | 77.2 steps/s
[Step=16200 Epoch=79.0] | Loss=0.03055 | Reg=0.00539 | acc=0.9688 | L2-Norm=23.216 | L2-Norm(final)=7.469 | 7984.2 samples/s | 124.8 steps/s
[Step=16250 Epoch=79.3] | Loss=0.02842 | Reg=0.00540 | acc=0.9844 | L2-Norm=23.244 | L2-Norm(final)=7.511 | 2196.0 samples/s | 34.3 steps/s
[Step=16300 Epoch=79.5] | Loss=0.02692 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.271 | L2-Norm(final)=7.556 | 4950.7 samples/s | 77.4 steps/s
[Step=16350 Epoch=79.8] | Loss=0.02606 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.298 | L2-Norm(final)=7.600 | 5105.7 samples/s | 79.8 steps/s
[Step=16400 Epoch=80.0] | Loss=0.02524 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.327 | L2-Norm(final)=7.647 | 7044.7 samples/s | 110.1 steps/s
[Step=16450 Epoch=80.3] | Loss=0.02421 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.357 | L2-Norm(final)=7.693 | 2318.8 samples/s | 36.2 steps/s
[Step=16500 Epoch=80.5] | Loss=0.02337 | Reg=0.00547 | acc=0.9688 | L2-Norm=23.384 | L2-Norm(final)=7.740 | 4771.3 samples/s | 74.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=80.5] | Loss=0.00763 | Reg=0.00560 | acc=1.0000 | L2-Norm=23.657 | L2-Norm(final)=8.222 | 4940.9 samples/s | 77.2 steps/s
[Step=16550 Epoch=80.8] | Loss=0.02106 | Reg=0.00562 | acc=1.0000 | L2-Norm=23.700 | L2-Norm(final)=8.254 | 4350.2 samples/s | 68.0 steps/s
[Step=16600 Epoch=81.0] | Loss=0.03068 | Reg=0.00564 | acc=0.9531 | L2-Norm=23.755 | L2-Norm(final)=8.253 | 4436.1 samples/s | 69.3 steps/s
[Step=16650 Epoch=81.2] | Loss=0.03369 | Reg=0.00567 | acc=0.9531 | L2-Norm=23.816 | L2-Norm(final)=8.241 | 4482.6 samples/s | 70.0 steps/s
[Step=16700 Epoch=81.5] | Loss=0.03470 | Reg=0.00570 | acc=0.9531 | L2-Norm=23.878 | L2-Norm(final)=8.228 | 6616.1 samples/s | 103.4 steps/s
[Step=16750 Epoch=81.7] | Loss=0.03274 | Reg=0.00573 | acc=1.0000 | L2-Norm=23.935 | L2-Norm(final)=8.219 | 2106.4 samples/s | 32.9 steps/s
[Step=16800 Epoch=82.0] | Loss=0.03281 | Reg=0.00575 | acc=0.9844 | L2-Norm=23.985 | L2-Norm(final)=8.212 | 4440.1 samples/s | 69.4 steps/s
[Step=16850 Epoch=82.2] | Loss=0.03214 | Reg=0.00578 | acc=0.9688 | L2-Norm=24.031 | L2-Norm(final)=8.206 | 4492.6 samples/s | 70.2 steps/s
[Step=16900 Epoch=82.5] | Loss=0.03153 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.070 | L2-Norm(final)=8.199 | 6053.6 samples/s | 94.6 steps/s
[Step=16950 Epoch=82.7] | Loss=0.03030 | Reg=0.00581 | acc=0.9688 | L2-Norm=24.102 | L2-Norm(final)=8.193 | 2164.8 samples/s | 33.8 steps/s
[Step=17000 Epoch=83.0] | Loss=0.02928 | Reg=0.00582 | acc=1.0000 | L2-Norm=24.130 | L2-Norm(final)=8.187 | 4516.6 samples/s | 70.6 steps/s
[Step=17050 Epoch=83.2] | Loss=0.02779 | Reg=0.00583 | acc=1.0000 | L2-Norm=24.154 | L2-Norm(final)=8.183 | 4395.1 samples/s | 68.7 steps/s
[Step=17100 Epoch=83.4] | Loss=0.02692 | Reg=0.00584 | acc=1.0000 | L2-Norm=24.173 | L2-Norm(final)=8.179 | 5582.9 samples/s | 87.2 steps/s
[Step=17150 Epoch=83.7] | Loss=0.02611 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.189 | L2-Norm(final)=8.175 | 2204.6 samples/s | 34.4 steps/s
[Step=17200 Epoch=83.9] | Loss=0.02527 | Reg=0.00586 | acc=1.0000 | L2-Norm=24.204 | L2-Norm(final)=8.173 | 4476.7 samples/s | 69.9 steps/s
[Step=17250 Epoch=84.2] | Loss=0.02459 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.218 | L2-Norm(final)=8.170 | 4485.7 samples/s | 70.1 steps/s
[Step=17300 Epoch=84.4] | Loss=0.02418 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.233 | L2-Norm(final)=8.167 | 5173.2 samples/s | 80.8 steps/s
[Step=17350 Epoch=84.7] | Loss=0.02353 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.247 | L2-Norm(final)=8.164 | 2271.1 samples/s | 35.5 steps/s
[Step=17400 Epoch=84.9] | Loss=0.02292 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.259 | L2-Norm(final)=8.161 | 4504.2 samples/s | 70.4 steps/s
[Step=17450 Epoch=85.1] | Loss=0.02264 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.268 | L2-Norm(final)=8.159 | 4472.5 samples/s | 69.9 steps/s
[Step=17500 Epoch=85.4] | Loss=0.02199 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.277 | L2-Norm(final)=8.156 | 4878.7 samples/s | 76.2 steps/s
[Step=17550 Epoch=85.6] | Loss=0.02138 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.284 | L2-Norm(final)=8.153 | 2380.5 samples/s | 37.2 steps/s
[Step=17600 Epoch=85.9] | Loss=0.02088 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.289 | L2-Norm(final)=8.150 | 4421.6 samples/s | 69.1 steps/s
[Step=17650 Epoch=86.1] | Loss=0.02044 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.293 | L2-Norm(final)=8.148 | 4522.6 samples/s | 70.7 steps/s
[Step=17700 Epoch=86.4] | Loss=0.02000 | Reg=0.00590 | acc=0.9688 | L2-Norm=24.296 | L2-Norm(final)=8.146 | 4534.5 samples/s | 70.9 steps/s
[Step=17750 Epoch=86.6] | Loss=0.01960 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.299 | L2-Norm(final)=8.144 | 2456.7 samples/s | 38.4 steps/s
[Step=17800 Epoch=86.9] | Loss=0.01920 | Reg=0.00591 | acc=0.9844 | L2-Norm=24.302 | L2-Norm(final)=8.143 | 4559.7 samples/s | 71.2 steps/s
[Step=17850 Epoch=87.1] | Loss=0.01881 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.304 | L2-Norm(final)=8.142 | 4368.0 samples/s | 68.3 steps/s
[Step=17900 Epoch=87.3] | Loss=0.01842 | Reg=0.00591 | acc=0.9844 | L2-Norm=24.305 | L2-Norm(final)=8.141 | 4481.6 samples/s | 70.0 steps/s
[Step=17950 Epoch=87.6] | Loss=0.01813 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.305 | L2-Norm(final)=8.140 | 2495.2 samples/s | 39.0 steps/s
[Step=18000 Epoch=87.8] | Loss=0.01774 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.304 | L2-Norm(final)=8.139 | 4438.1 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step18000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=78.0] | Loss=0.03293 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.270 | L2-Norm(final)=7.715 | 5248.3 samples/s | 82.0 steps/s
[Step=16050 Epoch=78.2] | Loss=0.03010 | Reg=0.00543 | acc=0.9688 | L2-Norm=23.297 | L2-Norm(final)=7.749 | 4644.4 samples/s | 72.6 steps/s
[Step=16100 Epoch=78.4] | Loss=0.02828 | Reg=0.00544 | acc=0.9844 | L2-Norm=23.325 | L2-Norm(final)=7.787 | 5138.5 samples/s | 80.3 steps/s
[Step=16150 Epoch=78.7] | Loss=0.02772 | Reg=0.00545 | acc=0.9531 | L2-Norm=23.353 | L2-Norm(final)=7.828 | 4935.5 samples/s | 77.1 steps/s
[Step=16200 Epoch=78.9] | Loss=0.02683 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.380 | L2-Norm(final)=7.872 | 7793.5 samples/s | 121.8 steps/s
[Step=16250 Epoch=79.2] | Loss=0.02556 | Reg=0.00548 | acc=0.9688 | L2-Norm=23.406 | L2-Norm(final)=7.915 | 2212.9 samples/s | 34.6 steps/s
[Step=16300 Epoch=79.4] | Loss=0.02460 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.432 | L2-Norm(final)=7.957 | 5043.9 samples/s | 78.8 steps/s
[Step=16350 Epoch=79.7] | Loss=0.02346 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.457 | L2-Norm(final)=7.998 | 5057.9 samples/s | 79.0 steps/s
[Step=16400 Epoch=79.9] | Loss=0.02301 | Reg=0.00551 | acc=0.9844 | L2-Norm=23.483 | L2-Norm(final)=8.042 | 6950.9 samples/s | 108.6 steps/s
[Step=16450 Epoch=80.2] | Loss=0.02222 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.506 | L2-Norm(final)=8.086 | 2302.1 samples/s | 36.0 steps/s
[Step=16500 Epoch=80.4] | Loss=0.02125 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.528 | L2-Norm(final)=8.129 | 5059.1 samples/s | 79.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=80.4] | Loss=0.00388 | Reg=0.00563 | acc=1.0000 | L2-Norm=23.738 | L2-Norm(final)=8.564 | 5000.7 samples/s | 78.1 steps/s
[Step=16550 Epoch=80.6] | Loss=0.01911 | Reg=0.00564 | acc=0.9688 | L2-Norm=23.759 | L2-Norm(final)=8.596 | 4275.2 samples/s | 66.8 steps/s
[Step=16600 Epoch=80.9] | Loss=0.03180 | Reg=0.00568 | acc=0.9531 | L2-Norm=23.823 | L2-Norm(final)=8.593 | 4450.1 samples/s | 69.5 steps/s
[Step=16650 Epoch=81.1] | Loss=0.03721 | Reg=0.00571 | acc=0.9688 | L2-Norm=23.899 | L2-Norm(final)=8.574 | 4394.4 samples/s | 68.7 steps/s
[Step=16700 Epoch=81.4] | Loss=0.03841 | Reg=0.00574 | acc=0.9688 | L2-Norm=23.959 | L2-Norm(final)=8.560 | 6404.3 samples/s | 100.1 steps/s
[Step=16750 Epoch=81.6] | Loss=0.03659 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.012 | L2-Norm(final)=8.552 | 2072.3 samples/s | 32.4 steps/s
[Step=16800 Epoch=81.9] | Loss=0.03486 | Reg=0.00579 | acc=0.9844 | L2-Norm=24.057 | L2-Norm(final)=8.546 | 4483.3 samples/s | 70.1 steps/s
[Step=16850 Epoch=82.1] | Loss=0.03400 | Reg=0.00581 | acc=0.9688 | L2-Norm=24.095 | L2-Norm(final)=8.540 | 4482.4 samples/s | 70.0 steps/s
[Step=16900 Epoch=82.3] | Loss=0.03368 | Reg=0.00582 | acc=1.0000 | L2-Norm=24.128 | L2-Norm(final)=8.535 | 5679.0 samples/s | 88.7 steps/s
[Step=16950 Epoch=82.6] | Loss=0.03223 | Reg=0.00584 | acc=1.0000 | L2-Norm=24.157 | L2-Norm(final)=8.530 | 2081.6 samples/s | 32.5 steps/s
[Step=17000 Epoch=82.8] | Loss=0.03090 | Reg=0.00585 | acc=0.9531 | L2-Norm=24.182 | L2-Norm(final)=8.527 | 4331.2 samples/s | 67.7 steps/s
[Step=17050 Epoch=83.1] | Loss=0.03020 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.204 | L2-Norm(final)=8.523 | 4457.2 samples/s | 69.6 steps/s
[Step=17100 Epoch=83.3] | Loss=0.02937 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.225 | L2-Norm(final)=8.520 | 5332.6 samples/s | 83.3 steps/s
[Step=17150 Epoch=83.6] | Loss=0.02844 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.245 | L2-Norm(final)=8.517 | 2255.7 samples/s | 35.2 steps/s
[Step=17200 Epoch=83.8] | Loss=0.02710 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.261 | L2-Norm(final)=8.515 | 4514.2 samples/s | 70.5 steps/s
[Step=17250 Epoch=84.1] | Loss=0.02628 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.274 | L2-Norm(final)=8.513 | 4340.5 samples/s | 67.8 steps/s
[Step=17300 Epoch=84.3] | Loss=0.02555 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.284 | L2-Norm(final)=8.511 | 4931.1 samples/s | 77.0 steps/s
[Step=17350 Epoch=84.5] | Loss=0.02476 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.293 | L2-Norm(final)=8.510 | 2335.3 samples/s | 36.5 steps/s
[Step=17400 Epoch=84.8] | Loss=0.02417 | Reg=0.00591 | acc=0.9688 | L2-Norm=24.302 | L2-Norm(final)=8.508 | 4383.4 samples/s | 68.5 steps/s
[Step=17450 Epoch=85.0] | Loss=0.02361 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.310 | L2-Norm(final)=8.507 | 4445.9 samples/s | 69.5 steps/s
[Step=17500 Epoch=85.3] | Loss=0.02319 | Reg=0.00591 | acc=0.9844 | L2-Norm=24.317 | L2-Norm(final)=8.505 | 4556.5 samples/s | 71.2 steps/s
[Step=17550 Epoch=85.5] | Loss=0.02259 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.323 | L2-Norm(final)=8.504 | 2390.6 samples/s | 37.4 steps/s
[Step=17600 Epoch=85.8] | Loss=0.02201 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.328 | L2-Norm(final)=8.503 | 4486.0 samples/s | 70.1 steps/s
[Step=17650 Epoch=86.0] | Loss=0.02137 | Reg=0.00592 | acc=0.9844 | L2-Norm=24.331 | L2-Norm(final)=8.503 | 4420.5 samples/s | 69.1 steps/s
[Step=17700 Epoch=86.2] | Loss=0.02087 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.333 | L2-Norm(final)=8.503 | 4529.1 samples/s | 70.8 steps/s
[Step=17750 Epoch=86.5] | Loss=0.02056 | Reg=0.00592 | acc=0.9844 | L2-Norm=24.335 | L2-Norm(final)=8.502 | 2417.0 samples/s | 37.8 steps/s
[Step=17800 Epoch=86.7] | Loss=0.02022 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.337 | L2-Norm(final)=8.502 | 4448.6 samples/s | 69.5 steps/s
[Step=17850 Epoch=87.0] | Loss=0.01979 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.338 | L2-Norm(final)=8.501 | 4454.2 samples/s | 69.6 steps/s
[Step=17900 Epoch=87.2] | Loss=0.01944 | Reg=0.00592 | acc=0.9688 | L2-Norm=24.338 | L2-Norm(final)=8.501 | 4421.7 samples/s | 69.1 steps/s
[Step=17950 Epoch=87.5] | Loss=0.01906 | Reg=0.00592 | acc=0.9844 | L2-Norm=24.338 | L2-Norm(final)=8.500 | 2451.5 samples/s | 38.3 steps/s
[Step=18000 Epoch=87.7] | Loss=0.01865 | Reg=0.00592 | acc=0.9844 | L2-Norm=24.337 | L2-Norm(final)=8.500 | 4421.1 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step18000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=78.0] | Loss=0.02205 | Reg=0.00535 | acc=1.0000 | L2-Norm=23.136 | L2-Norm(final)=7.450 | 5411.8 samples/s | 84.6 steps/s
[Step=16050 Epoch=78.3] | Loss=0.03261 | Reg=0.00537 | acc=0.9844 | L2-Norm=23.167 | L2-Norm(final)=7.487 | 4364.2 samples/s | 68.2 steps/s
[Step=16100 Epoch=78.5] | Loss=0.03005 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.190 | L2-Norm(final)=7.538 | 4950.1 samples/s | 77.3 steps/s
[Step=16150 Epoch=78.8] | Loss=0.03022 | Reg=0.00539 | acc=0.9531 | L2-Norm=23.211 | L2-Norm(final)=7.580 | 4977.0 samples/s | 77.8 steps/s
[Step=16200 Epoch=79.0] | Loss=0.02968 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.239 | L2-Norm(final)=7.623 | 7862.8 samples/s | 122.9 steps/s
[Step=16250 Epoch=79.2] | Loss=0.02768 | Reg=0.00541 | acc=0.9688 | L2-Norm=23.268 | L2-Norm(final)=7.671 | 2185.8 samples/s | 34.2 steps/s
[Step=16300 Epoch=79.5] | Loss=0.02635 | Reg=0.00543 | acc=0.9688 | L2-Norm=23.297 | L2-Norm(final)=7.721 | 4926.7 samples/s | 77.0 steps/s
[Step=16350 Epoch=79.7] | Loss=0.02530 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.324 | L2-Norm(final)=7.771 | 4985.6 samples/s | 77.9 steps/s
[Step=16400 Epoch=80.0] | Loss=0.02462 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.351 | L2-Norm(final)=7.821 | 6962.8 samples/s | 108.8 steps/s
[Step=16450 Epoch=80.2] | Loss=0.02362 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.378 | L2-Norm(final)=7.870 | 2270.8 samples/s | 35.5 steps/s
[Step=16500 Epoch=80.5] | Loss=0.02274 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.402 | L2-Norm(final)=7.919 | 4957.3 samples/s | 77.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=80.5] | Loss=0.02289 | Reg=0.00559 | acc=0.9688 | L2-Norm=23.648 | L2-Norm(final)=8.406 | 5412.0 samples/s | 84.6 steps/s
[Step=16550 Epoch=80.7] | Loss=0.02256 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.694 | L2-Norm(final)=8.445 | 3940.5 samples/s | 61.6 steps/s
[Step=16600 Epoch=81.0] | Loss=0.02680 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.756 | L2-Norm(final)=8.447 | 4424.5 samples/s | 69.1 steps/s
[Step=16650 Epoch=81.2] | Loss=0.03200 | Reg=0.00568 | acc=0.9844 | L2-Norm=23.826 | L2-Norm(final)=8.432 | 4438.9 samples/s | 69.4 steps/s
[Step=16700 Epoch=81.4] | Loss=0.03738 | Reg=0.00571 | acc=0.9844 | L2-Norm=23.892 | L2-Norm(final)=8.411 | 6503.5 samples/s | 101.6 steps/s
[Step=16750 Epoch=81.7] | Loss=0.03537 | Reg=0.00574 | acc=0.9844 | L2-Norm=23.950 | L2-Norm(final)=8.391 | 2054.1 samples/s | 32.1 steps/s
[Step=16800 Epoch=81.9] | Loss=0.03438 | Reg=0.00576 | acc=1.0000 | L2-Norm=23.995 | L2-Norm(final)=8.377 | 4435.4 samples/s | 69.3 steps/s
[Step=16850 Epoch=82.2] | Loss=0.03317 | Reg=0.00578 | acc=1.0000 | L2-Norm=24.033 | L2-Norm(final)=8.365 | 4451.2 samples/s | 69.5 steps/s
[Step=16900 Epoch=82.4] | Loss=0.03197 | Reg=0.00579 | acc=0.9688 | L2-Norm=24.064 | L2-Norm(final)=8.356 | 5851.2 samples/s | 91.4 steps/s
[Step=16950 Epoch=82.7] | Loss=0.03066 | Reg=0.00580 | acc=1.0000 | L2-Norm=24.092 | L2-Norm(final)=8.349 | 2131.3 samples/s | 33.3 steps/s
[Step=17000 Epoch=82.9] | Loss=0.02944 | Reg=0.00582 | acc=0.9688 | L2-Norm=24.116 | L2-Norm(final)=8.345 | 4443.1 samples/s | 69.4 steps/s
[Step=17050 Epoch=83.1] | Loss=0.02871 | Reg=0.00583 | acc=0.9688 | L2-Norm=24.138 | L2-Norm(final)=8.340 | 4399.6 samples/s | 68.7 steps/s
[Step=17100 Epoch=83.4] | Loss=0.02793 | Reg=0.00584 | acc=0.9844 | L2-Norm=24.157 | L2-Norm(final)=8.335 | 5374.8 samples/s | 84.0 steps/s
[Step=17150 Epoch=83.6] | Loss=0.02734 | Reg=0.00584 | acc=0.9688 | L2-Norm=24.174 | L2-Norm(final)=8.330 | 2247.9 samples/s | 35.1 steps/s
[Step=17200 Epoch=83.9] | Loss=0.02677 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.191 | L2-Norm(final)=8.326 | 4440.3 samples/s | 69.4 steps/s
[Step=17250 Epoch=84.1] | Loss=0.02583 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.206 | L2-Norm(final)=8.321 | 4397.4 samples/s | 68.7 steps/s
[Step=17300 Epoch=84.4] | Loss=0.02565 | Reg=0.00587 | acc=0.9688 | L2-Norm=24.219 | L2-Norm(final)=8.317 | 4942.8 samples/s | 77.2 steps/s
[Step=17350 Epoch=84.6] | Loss=0.02520 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.233 | L2-Norm(final)=8.312 | 2306.7 samples/s | 36.0 steps/s
[Step=17400 Epoch=84.9] | Loss=0.02456 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.246 | L2-Norm(final)=8.308 | 4435.9 samples/s | 69.3 steps/s
[Step=17450 Epoch=85.1] | Loss=0.02397 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.258 | L2-Norm(final)=8.305 | 4451.9 samples/s | 69.6 steps/s
[Step=17500 Epoch=85.3] | Loss=0.02344 | Reg=0.00589 | acc=0.9688 | L2-Norm=24.269 | L2-Norm(final)=8.302 | 4584.3 samples/s | 71.6 steps/s
[Step=17550 Epoch=85.6] | Loss=0.02291 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.278 | L2-Norm(final)=8.299 | 2398.0 samples/s | 37.5 steps/s
[Step=17600 Epoch=85.8] | Loss=0.02254 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.287 | L2-Norm(final)=8.296 | 4447.1 samples/s | 69.5 steps/s
[Step=17650 Epoch=86.1] | Loss=0.02201 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.295 | L2-Norm(final)=8.293 | 4447.7 samples/s | 69.5 steps/s
[Step=17700 Epoch=86.3] | Loss=0.02155 | Reg=0.00591 | acc=0.9844 | L2-Norm=24.301 | L2-Norm(final)=8.290 | 4377.4 samples/s | 68.4 steps/s
[Step=17750 Epoch=86.6] | Loss=0.02103 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.307 | L2-Norm(final)=8.288 | 2448.6 samples/s | 38.3 steps/s
[Step=17800 Epoch=86.8] | Loss=0.02055 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.311 | L2-Norm(final)=8.286 | 4320.9 samples/s | 67.5 steps/s
[Step=17850 Epoch=87.0] | Loss=0.02012 | Reg=0.00591 | acc=0.9688 | L2-Norm=24.314 | L2-Norm(final)=8.285 | 4450.9 samples/s | 69.5 steps/s
[Step=17900 Epoch=87.3] | Loss=0.01971 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.316 | L2-Norm(final)=8.283 | 4382.9 samples/s | 68.5 steps/s
[Step=17950 Epoch=87.5] | Loss=0.01934 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.316 | L2-Norm(final)=8.281 | 2434.9 samples/s | 38.0 steps/s
[Step=18000 Epoch=87.8] | Loss=0.01911 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.316 | L2-Norm(final)=8.279 | 4541.4 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step18000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=78.5] | Loss=0.02007 | Reg=0.00528 | acc=0.9844 | L2-Norm=22.978 | L2-Norm(final)=7.787 | 5651.8 samples/s | 88.3 steps/s
[Step=16050 Epoch=78.7] | Loss=0.03087 | Reg=0.00529 | acc=0.9844 | L2-Norm=23.000 | L2-Norm(final)=7.824 | 4299.0 samples/s | 67.2 steps/s
[Step=16100 Epoch=79.0] | Loss=0.02666 | Reg=0.00530 | acc=0.9844 | L2-Norm=23.025 | L2-Norm(final)=7.862 | 5034.7 samples/s | 78.7 steps/s
[Step=16150 Epoch=79.2] | Loss=0.02620 | Reg=0.00531 | acc=0.9844 | L2-Norm=23.046 | L2-Norm(final)=7.900 | 5093.0 samples/s | 79.6 steps/s
[Step=16200 Epoch=79.4] | Loss=0.02537 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.068 | L2-Norm(final)=7.938 | 7713.6 samples/s | 120.5 steps/s
[Step=16250 Epoch=79.7] | Loss=0.02371 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.090 | L2-Norm(final)=7.978 | 2181.8 samples/s | 34.1 steps/s
[Step=16300 Epoch=79.9] | Loss=0.02230 | Reg=0.00534 | acc=1.0000 | L2-Norm=23.111 | L2-Norm(final)=8.020 | 5096.0 samples/s | 79.6 steps/s
[Step=16350 Epoch=80.2] | Loss=0.02142 | Reg=0.00535 | acc=0.9688 | L2-Norm=23.132 | L2-Norm(final)=8.064 | 4859.6 samples/s | 75.9 steps/s
[Step=16400 Epoch=80.4] | Loss=0.02098 | Reg=0.00536 | acc=0.9688 | L2-Norm=23.153 | L2-Norm(final)=8.107 | 7392.1 samples/s | 115.5 steps/s
[Step=16450 Epoch=80.7] | Loss=0.02002 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.174 | L2-Norm(final)=8.150 | 2205.6 samples/s | 34.5 steps/s
[Step=16500 Epoch=80.9] | Loss=0.01935 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.194 | L2-Norm(final)=8.195 | 5161.5 samples/s | 80.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=80.9] | Loss=0.01223 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.405 | L2-Norm(final)=8.644 | 5703.0 samples/s | 89.1 steps/s
[Step=16550 Epoch=81.2] | Loss=0.01718 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.423 | L2-Norm(final)=8.677 | 3902.7 samples/s | 61.0 steps/s
[Step=16600 Epoch=81.4] | Loss=0.03209 | Reg=0.00552 | acc=0.9062 | L2-Norm=23.489 | L2-Norm(final)=8.670 | 4413.5 samples/s | 69.0 steps/s
[Step=16650 Epoch=81.6] | Loss=0.03669 | Reg=0.00556 | acc=0.9219 | L2-Norm=23.575 | L2-Norm(final)=8.648 | 4413.2 samples/s | 69.0 steps/s
[Step=16700 Epoch=81.9] | Loss=0.04002 | Reg=0.00559 | acc=0.9531 | L2-Norm=23.646 | L2-Norm(final)=8.629 | 6682.0 samples/s | 104.4 steps/s
[Step=16750 Epoch=82.1] | Loss=0.03716 | Reg=0.00562 | acc=0.9062 | L2-Norm=23.703 | L2-Norm(final)=8.616 | 2058.3 samples/s | 32.2 steps/s
[Step=16800 Epoch=82.4] | Loss=0.03562 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.752 | L2-Norm(final)=8.607 | 4376.9 samples/s | 68.4 steps/s
[Step=16850 Epoch=82.6] | Loss=0.03398 | Reg=0.00566 | acc=0.9844 | L2-Norm=23.792 | L2-Norm(final)=8.600 | 4487.9 samples/s | 70.1 steps/s
[Step=16900 Epoch=82.9] | Loss=0.03294 | Reg=0.00568 | acc=0.9844 | L2-Norm=23.826 | L2-Norm(final)=8.594 | 6117.1 samples/s | 95.6 steps/s
[Step=16950 Epoch=83.1] | Loss=0.03105 | Reg=0.00569 | acc=0.9844 | L2-Norm=23.854 | L2-Norm(final)=8.589 | 2104.3 samples/s | 32.9 steps/s
[Step=17000 Epoch=83.4] | Loss=0.02943 | Reg=0.00570 | acc=0.9844 | L2-Norm=23.877 | L2-Norm(final)=8.584 | 4418.6 samples/s | 69.0 steps/s
[Step=17050 Epoch=83.6] | Loss=0.02825 | Reg=0.00571 | acc=1.0000 | L2-Norm=23.897 | L2-Norm(final)=8.581 | 4438.0 samples/s | 69.3 steps/s
[Step=17100 Epoch=83.9] | Loss=0.02762 | Reg=0.00572 | acc=0.9688 | L2-Norm=23.916 | L2-Norm(final)=8.577 | 5838.9 samples/s | 91.2 steps/s
[Step=17150 Epoch=84.1] | Loss=0.02702 | Reg=0.00573 | acc=1.0000 | L2-Norm=23.935 | L2-Norm(final)=8.574 | 2141.6 samples/s | 33.5 steps/s
[Step=17200 Epoch=84.3] | Loss=0.02612 | Reg=0.00574 | acc=1.0000 | L2-Norm=23.952 | L2-Norm(final)=8.570 | 4408.6 samples/s | 68.9 steps/s
[Step=17250 Epoch=84.6] | Loss=0.02541 | Reg=0.00574 | acc=1.0000 | L2-Norm=23.967 | L2-Norm(final)=8.567 | 4412.5 samples/s | 68.9 steps/s
[Step=17300 Epoch=84.8] | Loss=0.02479 | Reg=0.00575 | acc=1.0000 | L2-Norm=23.980 | L2-Norm(final)=8.564 | 5467.9 samples/s | 85.4 steps/s
[Step=17350 Epoch=85.1] | Loss=0.02409 | Reg=0.00576 | acc=1.0000 | L2-Norm=23.990 | L2-Norm(final)=8.561 | 2196.7 samples/s | 34.3 steps/s
[Step=17400 Epoch=85.3] | Loss=0.02320 | Reg=0.00576 | acc=1.0000 | L2-Norm=24.000 | L2-Norm(final)=8.558 | 4511.4 samples/s | 70.5 steps/s
[Step=17450 Epoch=85.6] | Loss=0.02249 | Reg=0.00576 | acc=1.0000 | L2-Norm=24.008 | L2-Norm(final)=8.557 | 4369.1 samples/s | 68.3 steps/s
[Step=17500 Epoch=85.8] | Loss=0.02185 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.015 | L2-Norm(final)=8.555 | 5194.2 samples/s | 81.2 steps/s
[Step=17550 Epoch=86.1] | Loss=0.02119 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.020 | L2-Norm(final)=8.554 | 2229.6 samples/s | 34.8 steps/s
[Step=17600 Epoch=86.3] | Loss=0.02057 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.024 | L2-Norm(final)=8.553 | 4460.6 samples/s | 69.7 steps/s
[Step=17650 Epoch=86.6] | Loss=0.01995 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.027 | L2-Norm(final)=8.553 | 4464.3 samples/s | 69.8 steps/s
[Step=17700 Epoch=86.8] | Loss=0.01949 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.028 | L2-Norm(final)=8.552 | 4846.0 samples/s | 75.7 steps/s
[Step=17750 Epoch=87.0] | Loss=0.01902 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.029 | L2-Norm(final)=8.552 | 2296.8 samples/s | 35.9 steps/s
[Step=17800 Epoch=87.3] | Loss=0.01849 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.029 | L2-Norm(final)=8.552 | 4531.2 samples/s | 70.8 steps/s
[Step=17850 Epoch=87.5] | Loss=0.01806 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.027 | L2-Norm(final)=8.552 | 4303.7 samples/s | 67.2 steps/s
[Step=17900 Epoch=87.8] | Loss=0.01775 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.025 | L2-Norm(final)=8.551 | 4665.5 samples/s | 72.9 steps/s
[Step=17950 Epoch=88.0] | Loss=0.01742 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.022 | L2-Norm(final)=8.551 | 2321.1 samples/s | 36.3 steps/s
[Step=18000 Epoch=88.3] | Loss=0.01697 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.018 | L2-Norm(final)=8.551 | 4314.8 samples/s | 67.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step18000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=151.6] | Loss=0.12817 | Reg=0.00176 | acc=0.8906 | L2-Norm=13.258 | L2-Norm(final)=4.803 | 5112.7 samples/s | 79.9 steps/s
[Step=16050 Epoch=152.1] | Loss=0.00874 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.466 | L2-Norm(final)=4.804 | 4189.8 samples/s | 65.5 steps/s
[Step=16100 Epoch=152.6] | Loss=0.00529 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.526 | L2-Norm(final)=4.825 | 7425.0 samples/s | 116.0 steps/s
[Step=16150 Epoch=153.0] | Loss=0.00401 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.566 | L2-Norm(final)=4.846 | 2115.5 samples/s | 33.1 steps/s
[Step=16200 Epoch=153.5] | Loss=0.00318 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=4.864 | 6465.0 samples/s | 101.0 steps/s
[Step=16250 Epoch=154.0] | Loss=0.00260 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.611 | L2-Norm(final)=4.880 | 2189.7 samples/s | 34.2 steps/s
[Step=16300 Epoch=154.5] | Loss=0.00222 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.622 | L2-Norm(final)=4.894 | 5854.3 samples/s | 91.5 steps/s
[Step=16350 Epoch=154.9] | Loss=0.00194 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.629 | L2-Norm(final)=4.907 | 2264.1 samples/s | 35.4 steps/s
[Step=16400 Epoch=155.4] | Loss=0.00173 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.634 | L2-Norm(final)=4.919 | 5325.7 samples/s | 83.2 steps/s
[Step=16450 Epoch=155.9] | Loss=0.00156 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.637 | L2-Norm(final)=4.930 | 2417.2 samples/s | 37.8 steps/s
[Step=16500 Epoch=156.4] | Loss=0.00142 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.639 | L2-Norm(final)=4.940 | 4836.3 samples/s | 75.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=156.4] | Loss=0.00004 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.647 | L2-Norm(final)=5.041 | 5443.9 samples/s | 85.1 steps/s
[Step=16550 Epoch=156.8] | Loss=0.00021 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.642 | L2-Norm(final)=5.051 | 3709.8 samples/s | 58.0 steps/s
[Step=16600 Epoch=157.3] | Loss=0.00012 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=5.056 | 6131.4 samples/s | 95.8 steps/s
[Step=16650 Epoch=157.8] | Loss=0.00008 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.607 | L2-Norm(final)=5.058 | 2017.6 samples/s | 31.5 steps/s
[Step=16700 Epoch=158.2] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.586 | L2-Norm(final)=5.060 | 5612.3 samples/s | 87.7 steps/s
[Step=16750 Epoch=158.7] | Loss=0.00005 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.564 | L2-Norm(final)=5.061 | 2099.1 samples/s | 32.8 steps/s
[Step=16800 Epoch=159.2] | Loss=0.00004 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.542 | L2-Norm(final)=5.062 | 5113.7 samples/s | 79.9 steps/s
[Step=16850 Epoch=159.7] | Loss=0.00004 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.519 | L2-Norm(final)=5.063 | 2089.4 samples/s | 32.6 steps/s
[Step=16900 Epoch=160.1] | Loss=0.00003 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.497 | L2-Norm(final)=5.064 | 4272.2 samples/s | 66.8 steps/s
[Step=16950 Epoch=160.6] | Loss=0.00003 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.474 | L2-Norm(final)=5.065 | 2086.2 samples/s | 32.6 steps/s
[Step=17000 Epoch=161.1] | Loss=0.00003 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.450 | L2-Norm(final)=5.066 | 4163.6 samples/s | 65.1 steps/s
[Step=17050 Epoch=161.6] | Loss=0.00003 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.427 | L2-Norm(final)=5.066 | 2169.5 samples/s | 33.9 steps/s
[Step=17100 Epoch=162.0] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.403 | L2-Norm(final)=5.067 | 4078.9 samples/s | 63.7 steps/s
[Step=17150 Epoch=162.5] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.380 | L2-Norm(final)=5.067 | 2192.9 samples/s | 34.3 steps/s
[Step=17200 Epoch=163.0] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.356 | L2-Norm(final)=5.068 | 4275.6 samples/s | 66.8 steps/s
[Step=17250 Epoch=163.5] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.332 | L2-Norm(final)=5.068 | 2385.3 samples/s | 37.3 steps/s
[Step=17300 Epoch=163.9] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.308 | L2-Norm(final)=5.069 | 4167.3 samples/s | 65.1 steps/s
[Step=17350 Epoch=164.4] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.284 | L2-Norm(final)=5.069 | 2543.8 samples/s | 39.7 steps/s
[Step=17400 Epoch=164.9] | Loss=0.00002 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.259 | L2-Norm(final)=5.070 | 3899.2 samples/s | 60.9 steps/s
[Step=17450 Epoch=165.4] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.235 | L2-Norm(final)=5.070 | 6377.5 samples/s | 99.6 steps/s
[Step=17500 Epoch=165.8] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.210 | L2-Norm(final)=5.071 | 1993.9 samples/s | 31.2 steps/s
[Step=17550 Epoch=166.3] | Loss=0.00002 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.185 | L2-Norm(final)=5.071 | 5827.3 samples/s | 91.1 steps/s
[Step=17600 Epoch=166.8] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.160 | L2-Norm(final)=5.072 | 2054.7 samples/s | 32.1 steps/s
[Step=17650 Epoch=167.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.135 | L2-Norm(final)=5.073 | 5300.5 samples/s | 82.8 steps/s
[Step=17700 Epoch=167.7] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.110 | L2-Norm(final)=5.073 | 2181.9 samples/s | 34.1 steps/s
[Step=17750 Epoch=168.2] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.085 | L2-Norm(final)=5.074 | 4739.7 samples/s | 74.1 steps/s
[Step=17800 Epoch=168.7] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.059 | L2-Norm(final)=5.075 | 2261.3 samples/s | 35.3 steps/s
[Step=17850 Epoch=169.1] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.033 | L2-Norm(final)=5.076 | 4380.7 samples/s | 68.4 steps/s
[Step=17900 Epoch=169.6] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.008 | L2-Norm(final)=5.078 | 2254.9 samples/s | 35.2 steps/s
[Step=17950 Epoch=170.1] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.982 | L2-Norm(final)=5.079 | 4208.6 samples/s | 65.8 steps/s
[Step=18000 Epoch=170.6] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.956 | L2-Norm(final)=5.080 | 2423.3 samples/s | 37.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step18000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=152.2] | Loss=0.05652 | Reg=0.00170 | acc=0.9688 | L2-Norm=13.039 | L2-Norm(final)=5.324 | 4916.5 samples/s | 76.8 steps/s
[Step=16050 Epoch=152.7] | Loss=0.00435 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.137 | L2-Norm(final)=5.337 | 4385.1 samples/s | 68.5 steps/s
[Step=16100 Epoch=153.2] | Loss=0.00272 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.189 | L2-Norm(final)=5.360 | 7336.1 samples/s | 114.6 steps/s
[Step=16150 Epoch=153.6] | Loss=0.00211 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.223 | L2-Norm(final)=5.379 | 2101.9 samples/s | 32.8 steps/s
[Step=16200 Epoch=154.1] | Loss=0.00169 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.245 | L2-Norm(final)=5.395 | 6499.5 samples/s | 101.6 steps/s
[Step=16250 Epoch=154.6] | Loss=0.00140 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.260 | L2-Norm(final)=5.410 | 2211.7 samples/s | 34.6 steps/s
[Step=16300 Epoch=155.1] | Loss=0.00121 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.269 | L2-Norm(final)=5.423 | 5853.6 samples/s | 91.5 steps/s
[Step=16350 Epoch=155.5] | Loss=0.00107 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.277 | L2-Norm(final)=5.435 | 2284.6 samples/s | 35.7 steps/s
[Step=16400 Epoch=156.0] | Loss=0.00096 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.282 | L2-Norm(final)=5.447 | 5395.2 samples/s | 84.3 steps/s
[Step=16450 Epoch=156.5] | Loss=0.00087 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.285 | L2-Norm(final)=5.458 | 2383.3 samples/s | 37.2 steps/s
[Step=16500 Epoch=157.0] | Loss=0.00080 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.287 | L2-Norm(final)=5.468 | 4857.1 samples/s | 75.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=157.0] | Loss=0.00006 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.307 | L2-Norm(final)=5.572 | 5139.5 samples/s | 80.3 steps/s
[Step=16550 Epoch=157.4] | Loss=0.00013 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.294 | L2-Norm(final)=5.579 | 3807.8 samples/s | 59.5 steps/s
[Step=16600 Epoch=157.9] | Loss=0.00008 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.276 | L2-Norm(final)=5.584 | 6379.8 samples/s | 99.7 steps/s
[Step=16650 Epoch=158.4] | Loss=0.00006 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.254 | L2-Norm(final)=5.587 | 2032.2 samples/s | 31.8 steps/s
[Step=16700 Epoch=158.9] | Loss=0.00005 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.232 | L2-Norm(final)=5.589 | 5583.9 samples/s | 87.2 steps/s
[Step=16750 Epoch=159.3] | Loss=0.00004 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.209 | L2-Norm(final)=5.591 | 2093.8 samples/s | 32.7 steps/s
[Step=16800 Epoch=159.8] | Loss=0.00003 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.185 | L2-Norm(final)=5.592 | 5141.5 samples/s | 80.3 steps/s
[Step=16850 Epoch=160.3] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.162 | L2-Norm(final)=5.594 | 2183.4 samples/s | 34.1 steps/s
[Step=16900 Epoch=160.8] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.138 | L2-Norm(final)=5.595 | 4653.2 samples/s | 72.7 steps/s
[Step=16950 Epoch=161.2] | Loss=0.00002 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.115 | L2-Norm(final)=5.596 | 2241.7 samples/s | 35.0 steps/s
[Step=17000 Epoch=161.7] | Loss=0.00002 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.092 | L2-Norm(final)=5.597 | 4368.0 samples/s | 68.3 steps/s
[Step=17050 Epoch=162.2] | Loss=0.00002 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.068 | L2-Norm(final)=5.598 | 2276.7 samples/s | 35.6 steps/s
[Step=17100 Epoch=162.7] | Loss=0.00002 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.045 | L2-Norm(final)=5.598 | 4257.3 samples/s | 66.5 steps/s
[Step=17150 Epoch=163.1] | Loss=0.00002 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.022 | L2-Norm(final)=5.599 | 2414.1 samples/s | 37.7 steps/s
[Step=17200 Epoch=163.6] | Loss=0.00002 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.999 | L2-Norm(final)=5.600 | 4259.3 samples/s | 66.6 steps/s
[Step=17250 Epoch=164.1] | Loss=0.00002 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.975 | L2-Norm(final)=5.601 | 2396.5 samples/s | 37.4 steps/s
[Step=17300 Epoch=164.6] | Loss=0.00002 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.952 | L2-Norm(final)=5.601 | 4166.5 samples/s | 65.1 steps/s
[Step=17350 Epoch=165.0] | Loss=0.00002 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.929 | L2-Norm(final)=5.602 | 2480.4 samples/s | 38.8 steps/s
[Step=17400 Epoch=165.5] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.906 | L2-Norm(final)=5.603 | 4024.5 samples/s | 62.9 steps/s
[Step=17450 Epoch=166.0] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.882 | L2-Norm(final)=5.603 | 6597.1 samples/s | 103.1 steps/s
[Step=17500 Epoch=166.5] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.859 | L2-Norm(final)=5.604 | 1999.2 samples/s | 31.2 steps/s
[Step=17550 Epoch=166.9] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.836 | L2-Norm(final)=5.605 | 5888.2 samples/s | 92.0 steps/s
[Step=17600 Epoch=167.4] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.813 | L2-Norm(final)=5.605 | 2048.3 samples/s | 32.0 steps/s
[Step=17650 Epoch=167.9] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.789 | L2-Norm(final)=5.606 | 5306.2 samples/s | 82.9 steps/s
[Step=17700 Epoch=168.4] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.766 | L2-Norm(final)=5.607 | 2135.1 samples/s | 33.4 steps/s
[Step=17750 Epoch=168.8] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.743 | L2-Norm(final)=5.607 | 4898.2 samples/s | 76.5 steps/s
[Step=17800 Epoch=169.3] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.720 | L2-Norm(final)=5.608 | 2273.3 samples/s | 35.5 steps/s
[Step=17850 Epoch=169.8] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.696 | L2-Norm(final)=5.609 | 4367.0 samples/s | 68.2 steps/s
[Step=17900 Epoch=170.3] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.673 | L2-Norm(final)=5.609 | 2339.2 samples/s | 36.5 steps/s
[Step=17950 Epoch=170.7] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.649 | L2-Norm(final)=5.610 | 4116.0 samples/s | 64.3 steps/s
[Step=18000 Epoch=171.2] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.626 | L2-Norm(final)=5.611 | 2391.9 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step18000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=152.8] | Loss=0.05135 | Reg=0.00162 | acc=0.9531 | L2-Norm=12.742 | L2-Norm(final)=5.301 | 5129.0 samples/s | 80.1 steps/s
[Step=16050 Epoch=153.3] | Loss=0.01151 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.124 | L2-Norm(final)=5.226 | 4200.8 samples/s | 65.6 steps/s
[Step=16100 Epoch=153.7] | Loss=0.00726 | Reg=0.00176 | acc=0.9844 | L2-Norm=13.255 | L2-Norm(final)=5.230 | 7659.5 samples/s | 119.7 steps/s
[Step=16150 Epoch=154.2] | Loss=0.00507 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.319 | L2-Norm(final)=5.241 | 2084.5 samples/s | 32.6 steps/s
[Step=16200 Epoch=154.7] | Loss=0.00420 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.359 | L2-Norm(final)=5.254 | 6786.8 samples/s | 106.0 steps/s
[Step=16250 Epoch=155.2] | Loss=0.00350 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.387 | L2-Norm(final)=5.268 | 2209.2 samples/s | 34.5 steps/s
[Step=16300 Epoch=155.7] | Loss=0.00298 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.410 | L2-Norm(final)=5.283 | 6174.5 samples/s | 96.5 steps/s
[Step=16350 Epoch=156.1] | Loss=0.00268 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.427 | L2-Norm(final)=5.297 | 2301.5 samples/s | 36.0 steps/s
[Step=16400 Epoch=156.6] | Loss=0.00238 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.442 | L2-Norm(final)=5.310 | 5329.5 samples/s | 83.3 steps/s
[Step=16450 Epoch=157.1] | Loss=0.00216 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.454 | L2-Norm(final)=5.324 | 2332.3 samples/s | 36.4 steps/s
[Step=16500 Epoch=157.6] | Loss=0.00197 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.465 | L2-Norm(final)=5.337 | 5155.3 samples/s | 80.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=157.6] | Loss=0.00086 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.556 | L2-Norm(final)=5.466 | 5212.6 samples/s | 81.4 steps/s
[Step=16550 Epoch=158.0] | Loss=0.03308 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.921 | L2-Norm(final)=5.402 | 3827.7 samples/s | 59.8 steps/s
[Step=16600 Epoch=158.5] | Loss=0.01921 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.223 | L2-Norm(final)=5.342 | 6400.3 samples/s | 100.0 steps/s
[Step=16650 Epoch=159.0] | Loss=0.01289 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.341 | L2-Norm(final)=5.323 | 2011.3 samples/s | 31.4 steps/s
[Step=16700 Epoch=159.5] | Loss=0.00969 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.396 | L2-Norm(final)=5.315 | 5825.0 samples/s | 91.0 steps/s
[Step=16750 Epoch=160.0] | Loss=0.00776 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.424 | L2-Norm(final)=5.311 | 2057.7 samples/s | 32.2 steps/s
[Step=16800 Epoch=160.4] | Loss=0.00647 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.438 | L2-Norm(final)=5.308 | 5293.2 samples/s | 82.7 steps/s
[Step=16850 Epoch=160.9] | Loss=0.00555 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.445 | L2-Norm(final)=5.306 | 2127.2 samples/s | 33.2 steps/s
[Step=16900 Epoch=161.4] | Loss=0.00486 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.446 | L2-Norm(final)=5.305 | 5025.5 samples/s | 78.5 steps/s
[Step=16950 Epoch=161.9] | Loss=0.00432 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.444 | L2-Norm(final)=5.304 | 2206.2 samples/s | 34.5 steps/s
[Step=17000 Epoch=162.3] | Loss=0.00389 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.440 | L2-Norm(final)=5.304 | 4575.1 samples/s | 71.5 steps/s
[Step=17050 Epoch=162.8] | Loss=0.00353 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.434 | L2-Norm(final)=5.303 | 2245.1 samples/s | 35.1 steps/s
[Step=17100 Epoch=163.3] | Loss=0.00324 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.426 | L2-Norm(final)=5.303 | 4308.3 samples/s | 67.3 steps/s
[Step=17150 Epoch=163.8] | Loss=0.00299 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.418 | L2-Norm(final)=5.303 | 2347.2 samples/s | 36.7 steps/s
[Step=17200 Epoch=164.2] | Loss=0.00278 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.409 | L2-Norm(final)=5.303 | 4244.0 samples/s | 66.3 steps/s
[Step=17250 Epoch=164.7] | Loss=0.00259 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.399 | L2-Norm(final)=5.303 | 2373.0 samples/s | 37.1 steps/s
[Step=17300 Epoch=165.2] | Loss=0.00243 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.388 | L2-Norm(final)=5.303 | 4276.1 samples/s | 66.8 steps/s
[Step=17350 Epoch=165.7] | Loss=0.00229 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.377 | L2-Norm(final)=5.303 | 2313.8 samples/s | 36.2 steps/s
[Step=17400 Epoch=166.2] | Loss=0.00216 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.365 | L2-Norm(final)=5.304 | 4231.9 samples/s | 66.1 steps/s
[Step=17450 Epoch=166.6] | Loss=0.00205 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.354 | L2-Norm(final)=5.304 | 2398.4 samples/s | 37.5 steps/s
[Step=17500 Epoch=167.1] | Loss=0.00194 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.341 | L2-Norm(final)=5.305 | 4238.6 samples/s | 66.2 steps/s
[Step=17550 Epoch=167.6] | Loss=0.00185 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.329 | L2-Norm(final)=5.307 | 7048.3 samples/s | 110.1 steps/s
[Step=17600 Epoch=168.1] | Loss=0.00177 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.316 | L2-Norm(final)=5.308 | 1949.7 samples/s | 30.5 steps/s
[Step=17650 Epoch=168.5] | Loss=0.00169 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.303 | L2-Norm(final)=5.310 | 6258.6 samples/s | 97.8 steps/s
[Step=17700 Epoch=169.0] | Loss=0.00162 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.290 | L2-Norm(final)=5.312 | 2024.4 samples/s | 31.6 steps/s
[Step=17750 Epoch=169.5] | Loss=0.00156 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.277 | L2-Norm(final)=5.314 | 5680.8 samples/s | 88.8 steps/s
[Step=17800 Epoch=170.0] | Loss=0.00150 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.263 | L2-Norm(final)=5.317 | 2086.5 samples/s | 32.6 steps/s
[Step=17850 Epoch=170.5] | Loss=0.00144 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.249 | L2-Norm(final)=5.320 | 5298.7 samples/s | 82.8 steps/s
[Step=17900 Epoch=170.9] | Loss=0.00139 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.235 | L2-Norm(final)=5.322 | 2144.0 samples/s | 33.5 steps/s
[Step=17950 Epoch=171.4] | Loss=0.00134 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.221 | L2-Norm(final)=5.325 | 4913.0 samples/s | 76.8 steps/s
[Step=18000 Epoch=171.9] | Loss=0.00130 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.207 | L2-Norm(final)=5.328 | 2228.5 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step18000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=150.8] | Loss=0.00355 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.239 | L2-Norm(final)=4.781 | 5236.9 samples/s | 81.8 steps/s
[Step=16050 Epoch=151.2] | Loss=0.00388 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.317 | L2-Norm(final)=4.818 | 4152.4 samples/s | 64.9 steps/s
[Step=16100 Epoch=151.7] | Loss=0.00375 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.386 | L2-Norm(final)=4.847 | 7459.4 samples/s | 116.6 steps/s
[Step=16150 Epoch=152.2] | Loss=0.00274 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.440 | L2-Norm(final)=4.873 | 2164.4 samples/s | 33.8 steps/s
[Step=16200 Epoch=152.7] | Loss=0.00221 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.471 | L2-Norm(final)=4.897 | 6258.7 samples/s | 97.8 steps/s
[Step=16250 Epoch=153.1] | Loss=0.00193 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.496 | L2-Norm(final)=4.920 | 2206.8 samples/s | 34.5 steps/s
[Step=16300 Epoch=153.6] | Loss=0.00168 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.515 | L2-Norm(final)=4.942 | 5621.5 samples/s | 87.8 steps/s
[Step=16350 Epoch=154.1] | Loss=0.00149 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.530 | L2-Norm(final)=4.962 | 2354.9 samples/s | 36.8 steps/s
[Step=16400 Epoch=154.5] | Loss=0.00133 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.541 | L2-Norm(final)=4.981 | 5095.6 samples/s | 79.6 steps/s
[Step=16450 Epoch=155.0] | Loss=0.00122 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.549 | L2-Norm(final)=4.999 | 2478.6 samples/s | 38.7 steps/s
[Step=16500 Epoch=155.5] | Loss=0.00112 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.556 | L2-Norm(final)=5.016 | 4718.6 samples/s | 73.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=155.5] | Loss=0.00008 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=5.184 | 5013.6 samples/s | 78.3 steps/s
[Step=16550 Epoch=155.9] | Loss=0.00015 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.612 | L2-Norm(final)=5.194 | 3926.2 samples/s | 61.3 steps/s
[Step=16600 Epoch=156.4] | Loss=0.00017 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.599 | L2-Norm(final)=5.201 | 6187.2 samples/s | 96.7 steps/s
[Step=16650 Epoch=156.9] | Loss=0.00092 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.606 | L2-Norm(final)=5.207 | 2046.4 samples/s | 32.0 steps/s
[Step=16700 Epoch=157.4] | Loss=0.00672 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.713 | L2-Norm(final)=5.183 | 5422.2 samples/s | 84.7 steps/s
[Step=16750 Epoch=157.8] | Loss=0.00588 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.843 | L2-Norm(final)=5.155 | 2131.9 samples/s | 33.3 steps/s
[Step=16800 Epoch=158.3] | Loss=0.00523 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.931 | L2-Norm(final)=5.138 | 4846.8 samples/s | 75.7 steps/s
[Step=16850 Epoch=158.8] | Loss=0.00482 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.996 | L2-Norm(final)=5.126 | 2220.0 samples/s | 34.7 steps/s
[Step=16900 Epoch=159.2] | Loss=0.00425 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.046 | L2-Norm(final)=5.117 | 4451.8 samples/s | 69.6 steps/s
[Step=16950 Epoch=159.7] | Loss=0.00381 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.082 | L2-Norm(final)=5.111 | 2317.3 samples/s | 36.2 steps/s
[Step=17000 Epoch=160.2] | Loss=0.00344 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=5.107 | 4304.4 samples/s | 67.3 steps/s
[Step=17050 Epoch=160.7] | Loss=0.00313 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.129 | L2-Norm(final)=5.103 | 2381.4 samples/s | 37.2 steps/s
[Step=17100 Epoch=161.1] | Loss=0.00287 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.144 | L2-Norm(final)=5.101 | 4163.5 samples/s | 65.1 steps/s
[Step=17150 Epoch=161.6] | Loss=0.00265 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.155 | L2-Norm(final)=5.099 | 2375.9 samples/s | 37.1 steps/s
[Step=17200 Epoch=162.1] | Loss=0.00246 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.162 | L2-Norm(final)=5.097 | 4273.8 samples/s | 66.8 steps/s
[Step=17250 Epoch=162.5] | Loss=0.00230 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.166 | L2-Norm(final)=5.096 | 2538.6 samples/s | 39.7 steps/s
[Step=17300 Epoch=163.0] | Loss=0.00216 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=5.095 | 3881.5 samples/s | 60.6 steps/s
[Step=17350 Epoch=163.5] | Loss=0.00203 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=5.094 | 6183.4 samples/s | 96.6 steps/s
[Step=17400 Epoch=164.0] | Loss=0.00192 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.165 | L2-Norm(final)=5.093 | 2022.3 samples/s | 31.6 steps/s
[Step=17450 Epoch=164.4] | Loss=0.00182 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.162 | L2-Norm(final)=5.093 | 5574.1 samples/s | 87.1 steps/s
[Step=17500 Epoch=164.9] | Loss=0.00173 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.158 | L2-Norm(final)=5.093 | 2098.7 samples/s | 32.8 steps/s
[Step=17550 Epoch=165.4] | Loss=0.00164 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.152 | L2-Norm(final)=5.092 | 5048.4 samples/s | 78.9 steps/s
[Step=17600 Epoch=165.8] | Loss=0.00157 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.146 | L2-Norm(final)=5.092 | 2202.8 samples/s | 34.4 steps/s
[Step=17650 Epoch=166.3] | Loss=0.00150 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.139 | L2-Norm(final)=5.092 | 4563.2 samples/s | 71.3 steps/s
[Step=17700 Epoch=166.8] | Loss=0.00144 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.131 | L2-Norm(final)=5.092 | 2261.7 samples/s | 35.3 steps/s
[Step=17750 Epoch=167.3] | Loss=0.00138 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.123 | L2-Norm(final)=5.092 | 4224.2 samples/s | 66.0 steps/s
[Step=17800 Epoch=167.7] | Loss=0.00133 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.113 | L2-Norm(final)=5.092 | 2370.0 samples/s | 37.0 steps/s
[Step=17850 Epoch=168.2] | Loss=0.00128 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.104 | L2-Norm(final)=5.092 | 4249.7 samples/s | 66.4 steps/s
[Step=17900 Epoch=168.7] | Loss=0.00123 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.094 | L2-Norm(final)=5.092 | 2382.2 samples/s | 37.2 steps/s
[Step=17950 Epoch=169.1] | Loss=0.00119 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.083 | L2-Norm(final)=5.092 | 4291.6 samples/s | 67.1 steps/s
[Step=18000 Epoch=169.6] | Loss=0.00115 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.072 | L2-Norm(final)=5.092 | 2495.8 samples/s | 39.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step18000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=152.5] | Loss=0.07523 | Reg=0.00183 | acc=0.9531 | L2-Norm=13.543 | L2-Norm(final)=5.630 | 5279.8 samples/s | 82.5 steps/s
[Step=16050 Epoch=153.0] | Loss=0.01034 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.699 | L2-Norm(final)=5.617 | 4273.7 samples/s | 66.8 steps/s
[Step=16100 Epoch=153.4] | Loss=0.00655 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.779 | L2-Norm(final)=5.635 | 7552.1 samples/s | 118.0 steps/s
[Step=16150 Epoch=153.9] | Loss=0.00479 | Reg=0.00191 | acc=0.9844 | L2-Norm=13.828 | L2-Norm(final)=5.657 | 2155.3 samples/s | 33.7 steps/s
[Step=16200 Epoch=154.4] | Loss=0.00390 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.861 | L2-Norm(final)=5.678 | 6557.0 samples/s | 102.5 steps/s
[Step=16250 Epoch=154.9] | Loss=0.00324 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.884 | L2-Norm(final)=5.696 | 1655.9 samples/s | 25.9 steps/s
[Step=16300 Epoch=155.4] | Loss=0.00278 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.903 | L2-Norm(final)=5.713 | 6122.2 samples/s | 95.7 steps/s
[Step=16350 Epoch=155.8] | Loss=0.00251 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.918 | L2-Norm(final)=5.729 | 2248.8 samples/s | 35.1 steps/s
[Step=16400 Epoch=156.3] | Loss=0.00226 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.930 | L2-Norm(final)=5.744 | 5605.8 samples/s | 87.6 steps/s
[Step=16450 Epoch=156.8] | Loss=0.00205 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.945 | L2-Norm(final)=5.760 | 2332.4 samples/s | 36.4 steps/s
[Step=16500 Epoch=157.3] | Loss=0.00188 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.956 | L2-Norm(final)=5.775 | 5184.2 samples/s | 81.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=157.3] | Loss=0.00032 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.065 | L2-Norm(final)=5.922 | 5478.9 samples/s | 85.6 steps/s
[Step=16550 Epoch=157.7] | Loss=0.00030 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=5.933 | 3685.7 samples/s | 57.6 steps/s
[Step=16600 Epoch=158.2] | Loss=0.00024 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.052 | L2-Norm(final)=5.942 | 6298.5 samples/s | 98.4 steps/s
[Step=16650 Epoch=158.7] | Loss=0.00016 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.036 | L2-Norm(final)=5.947 | 2052.0 samples/s | 32.1 steps/s
[Step=16700 Epoch=159.2] | Loss=0.00013 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.015 | L2-Norm(final)=5.951 | 5680.5 samples/s | 88.8 steps/s
[Step=16750 Epoch=159.6] | Loss=0.00010 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.992 | L2-Norm(final)=5.953 | 2066.7 samples/s | 32.3 steps/s
[Step=16800 Epoch=160.1] | Loss=0.00009 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.968 | L2-Norm(final)=5.954 | 5321.2 samples/s | 83.1 steps/s
[Step=16850 Epoch=160.6] | Loss=0.00007 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.943 | L2-Norm(final)=5.955 | 2104.2 samples/s | 32.9 steps/s
[Step=16900 Epoch=161.1] | Loss=0.00007 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.918 | L2-Norm(final)=5.956 | 4932.6 samples/s | 77.1 steps/s
[Step=16950 Epoch=161.5] | Loss=0.00006 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.893 | L2-Norm(final)=5.957 | 2219.1 samples/s | 34.7 steps/s
[Step=17000 Epoch=162.0] | Loss=0.00005 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=5.958 | 4658.1 samples/s | 72.8 steps/s
[Step=17050 Epoch=162.5] | Loss=0.00005 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.843 | L2-Norm(final)=5.959 | 2302.2 samples/s | 36.0 steps/s
[Step=17100 Epoch=163.0] | Loss=0.00004 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.817 | L2-Norm(final)=5.959 | 4195.6 samples/s | 65.6 steps/s
[Step=17150 Epoch=163.5] | Loss=0.00004 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.792 | L2-Norm(final)=5.960 | 2359.6 samples/s | 36.9 steps/s
[Step=17200 Epoch=163.9] | Loss=0.00004 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.766 | L2-Norm(final)=5.960 | 4291.1 samples/s | 67.0 steps/s
[Step=17250 Epoch=164.4] | Loss=0.00004 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.741 | L2-Norm(final)=5.961 | 2386.6 samples/s | 37.3 steps/s
[Step=17300 Epoch=164.9] | Loss=0.00003 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.715 | L2-Norm(final)=5.961 | 4129.8 samples/s | 64.5 steps/s
[Step=17350 Epoch=165.4] | Loss=0.00003 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.690 | L2-Norm(final)=5.962 | 2368.3 samples/s | 37.0 steps/s
[Step=17400 Epoch=165.8] | Loss=0.00003 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.664 | L2-Norm(final)=5.962 | 4203.2 samples/s | 65.7 steps/s
[Step=17450 Epoch=166.3] | Loss=0.00003 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.638 | L2-Norm(final)=5.963 | 2408.3 samples/s | 37.6 steps/s
[Step=17500 Epoch=166.8] | Loss=0.00003 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.612 | L2-Norm(final)=5.963 | 4219.8 samples/s | 65.9 steps/s
[Step=17550 Epoch=167.3] | Loss=0.00003 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.586 | L2-Norm(final)=5.963 | 7058.7 samples/s | 110.3 steps/s
[Step=17600 Epoch=167.7] | Loss=0.00003 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.561 | L2-Norm(final)=5.964 | 1954.4 samples/s | 30.5 steps/s
[Step=17650 Epoch=168.2] | Loss=0.00002 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.535 | L2-Norm(final)=5.964 | 6338.9 samples/s | 99.0 steps/s
[Step=17700 Epoch=168.7] | Loss=0.00002 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.508 | L2-Norm(final)=5.965 | 1988.3 samples/s | 31.1 steps/s
[Step=17750 Epoch=169.2] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.482 | L2-Norm(final)=5.965 | 5748.3 samples/s | 89.8 steps/s
[Step=17800 Epoch=169.7] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.456 | L2-Norm(final)=5.965 | 2054.5 samples/s | 32.1 steps/s
[Step=17850 Epoch=170.1] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.430 | L2-Norm(final)=5.966 | 5394.0 samples/s | 84.3 steps/s
[Step=17900 Epoch=170.6] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.403 | L2-Norm(final)=5.966 | 2120.5 samples/s | 33.1 steps/s
[Step=17950 Epoch=171.1] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.377 | L2-Norm(final)=5.967 | 4987.0 samples/s | 77.9 steps/s
[Step=18000 Epoch=171.6] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.350 | L2-Norm(final)=5.967 | 2199.7 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.13899 | acc=0.9401 | tpr=0.9555 | fpr=0.0934 | 4719.8 samples/s | 18.4 steps/s
Avg test loss: 0.14340, Avg test acc: 0.93802, Avg tpr: 0.95442, Avg fpr: 0.09806, total FA: 765

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.14886 | acc=0.9443 | tpr=0.9561 | fpr=0.0813 | 4962.9 samples/s | 19.4 steps/s
Avg test loss: 0.14839, Avg test acc: 0.94443, Avg tpr: 0.95623, Avg fpr: 0.08153, total FA: 636

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14565 | acc=0.9468 | tpr=0.9660 | fpr=0.0949 | 4940.4 samples/s | 19.3 steps/s
Avg test loss: 0.14544, Avg test acc: 0.94491, Avg tpr: 0.96357, Avg fpr: 0.09614, total FA: 750

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14196 | acc=0.9493 | tpr=0.9728 | fpr=0.1018 | 4945.6 samples/s | 19.3 steps/s
Avg test loss: 0.14602, Avg test acc: 0.94739, Avg tpr: 0.97226, Avg fpr: 0.10729, total FA: 837

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.16185 | acc=0.9463 | tpr=0.9635 | fpr=0.0912 | 4769.5 samples/s | 18.6 steps/s
Avg test loss: 0.16557, Avg test acc: 0.94663, Avg tpr: 0.96480, Avg fpr: 0.09332, total FA: 728

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.09499 | acc=0.2885 | tpr=0.0195 | fpr=0.1274 | 5150.8 samples/s | 20.1 steps/s
Avg test loss: 5.11169, Avg test acc: 0.28612, Avg tpr: 0.02063, Avg fpr: 0.12998, total FA: 1014

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.87312 | acc=0.2858 | tpr=0.0052 | fpr=0.1051 | 4866.7 samples/s | 19.0 steps/s
Avg test loss: 4.88579, Avg test acc: 0.28412, Avg tpr: 0.00589, Avg fpr: 0.10396, total FA: 811

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.26293 | acc=0.2963 | tpr=0.0102 | fpr=0.0823 | 4705.0 samples/s | 18.4 steps/s
Avg test loss: 5.28163, Avg test acc: 0.29429, Avg tpr: 0.01084, Avg fpr: 0.08230, total FA: 642

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.16621 | acc=0.3019 | tpr=0.0193 | fpr=0.0845 | 4907.6 samples/s | 19.2 steps/s
Avg test loss: 5.16668, Avg test acc: 0.30034, Avg tpr: 0.01918, Avg fpr: 0.08127, total FA: 634

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.39886 | acc=0.2954 | tpr=0.0241 | fpr=0.1155 | 4868.8 samples/s | 19.0 steps/s
Avg test loss: 5.40638, Avg test acc: 0.29518, Avg tpr: 0.02489, Avg fpr: 0.11037, total FA: 861

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.68659 | acc=0.1171 | tpr=0.5664 | fpr=0.8910 | 4761.6 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.67020 | acc=0.1185 | tpr=0.5458 | fpr=0.8895 | 7505.6 samples/s | 29.3 steps/s
[Step= 150] | Loss=5.67191 | acc=0.1179 | tpr=0.5331 | fpr=0.8897 | 7463.1 samples/s | 29.2 steps/s
[Step= 200] | Loss=5.67593 | acc=0.1183 | tpr=0.5399 | fpr=0.8893 | 8047.1 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.69533 | acc=0.1179 | tpr=0.5380 | fpr=0.8897 | 7730.8 samples/s | 30.2 steps/s
[Step= 300] | Loss=5.69368 | acc=0.1177 | tpr=0.5440 | fpr=0.8901 | 7851.5 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.68720 | acc=0.1177 | tpr=0.5441 | fpr=0.8900 | 7577.2 samples/s | 29.6 steps/s
[Step= 400] | Loss=5.68221 | acc=0.1179 | tpr=0.5476 | fpr=0.8899 | 7809.5 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.68395 | acc=0.1182 | tpr=0.5482 | fpr=0.8896 | 7913.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.69189 | acc=0.1179 | tpr=0.5480 | fpr=0.8899 | 8058.8 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.69635 | acc=0.1178 | tpr=0.5480 | fpr=0.8900 | 13912.8 samples/s | 54.3 steps/s
Avg test loss: 5.69911, Avg test acc: 0.11775, Avg tpr: 0.54913, Avg fpr: 0.89010, total FA: 123588

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.96857 | acc=0.1104 | tpr=0.5752 | fpr=0.8980 | 4848.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=4.97158 | acc=0.1111 | tpr=0.5736 | fpr=0.8976 | 6887.0 samples/s | 26.9 steps/s
[Step= 150] | Loss=4.96702 | acc=0.1113 | tpr=0.5576 | fpr=0.8969 | 8080.7 samples/s | 31.6 steps/s
[Step= 200] | Loss=4.95728 | acc=0.1112 | tpr=0.5508 | fpr=0.8968 | 7704.1 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.96611 | acc=0.1109 | tpr=0.5528 | fpr=0.8971 | 7740.5 samples/s | 30.2 steps/s
[Step= 300] | Loss=4.95514 | acc=0.1108 | tpr=0.5556 | fpr=0.8973 | 8271.3 samples/s | 32.3 steps/s
[Step= 350] | Loss=4.95085 | acc=0.1109 | tpr=0.5510 | fpr=0.8971 | 7607.2 samples/s | 29.7 steps/s
[Step= 400] | Loss=4.94541 | acc=0.1113 | tpr=0.5547 | fpr=0.8968 | 8016.9 samples/s | 31.3 steps/s
[Step= 450] | Loss=4.94742 | acc=0.1116 | tpr=0.5516 | fpr=0.8964 | 8164.9 samples/s | 31.9 steps/s
[Step= 500] | Loss=4.95164 | acc=0.1111 | tpr=0.5502 | fpr=0.8968 | 7570.6 samples/s | 29.6 steps/s
[Step= 550] | Loss=4.95245 | acc=0.1111 | tpr=0.5491 | fpr=0.8969 | 13360.9 samples/s | 52.2 steps/s
Avg test loss: 4.95346, Avg test acc: 0.11096, Avg tpr: 0.54992, Avg fpr: 0.89702, total FA: 124550

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.34979 | acc=0.0723 | tpr=0.6504 | fpr=0.9381 | 4749.6 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.29591 | acc=0.0773 | tpr=0.6354 | fpr=0.9332 | 7259.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=6.29944 | acc=0.0778 | tpr=0.6427 | fpr=0.9326 | 7632.9 samples/s | 29.8 steps/s
[Step= 200] | Loss=6.28891 | acc=0.0784 | tpr=0.6404 | fpr=0.9319 | 7869.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.29947 | acc=0.0780 | tpr=0.6419 | fpr=0.9323 | 8015.9 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.29857 | acc=0.0780 | tpr=0.6473 | fpr=0.9324 | 7938.4 samples/s | 31.0 steps/s
[Step= 350] | Loss=6.28871 | acc=0.0779 | tpr=0.6456 | fpr=0.9324 | 7896.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.28481 | acc=0.0781 | tpr=0.6422 | fpr=0.9322 | 7968.4 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.28913 | acc=0.0782 | tpr=0.6441 | fpr=0.9321 | 7725.6 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.29032 | acc=0.0779 | tpr=0.6427 | fpr=0.9323 | 7917.4 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.29143 | acc=0.0778 | tpr=0.6419 | fpr=0.9325 | 13963.4 samples/s | 54.5 steps/s
Avg test loss: 6.29293, Avg test acc: 0.07769, Avg tpr: 0.64263, Avg fpr: 0.93258, total FA: 129487

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.23966 | acc=0.0976 | tpr=0.7611 | fpr=0.9143 | 4657.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=6.22580 | acc=0.0971 | tpr=0.7527 | fpr=0.9152 | 7402.4 samples/s | 28.9 steps/s
[Step= 150] | Loss=6.22392 | acc=0.0972 | tpr=0.7680 | fpr=0.9152 | 7698.5 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.21916 | acc=0.0972 | tpr=0.7672 | fpr=0.9149 | 8091.3 samples/s | 31.6 steps/s
[Step= 250] | Loss=6.22497 | acc=0.0971 | tpr=0.7686 | fpr=0.9151 | 7864.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.21798 | acc=0.0972 | tpr=0.7585 | fpr=0.9148 | 7648.0 samples/s | 29.9 steps/s
[Step= 350] | Loss=6.20830 | acc=0.0971 | tpr=0.7621 | fpr=0.9150 | 7895.4 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.20244 | acc=0.0973 | tpr=0.7615 | fpr=0.9147 | 7941.5 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.20928 | acc=0.0972 | tpr=0.7634 | fpr=0.9149 | 8114.3 samples/s | 31.7 steps/s
[Step= 500] | Loss=6.21015 | acc=0.0970 | tpr=0.7648 | fpr=0.9151 | 7784.8 samples/s | 30.4 steps/s
[Step= 550] | Loss=6.21100 | acc=0.0970 | tpr=0.7652 | fpr=0.9152 | 13849.3 samples/s | 54.1 steps/s
Avg test loss: 6.21263, Avg test acc: 0.09685, Avg tpr: 0.76585, Avg fpr: 0.91531, total FA: 127089

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.60022 | acc=0.1052 | tpr=0.7168 | fpr=0.9058 | 4740.1 samples/s | 18.5 steps/s
[Step= 100] | Loss=6.57294 | acc=0.1067 | tpr=0.6887 | fpr=0.9042 | 7209.4 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.57671 | acc=0.1076 | tpr=0.6945 | fpr=0.9032 | 7917.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.57585 | acc=0.1085 | tpr=0.6885 | fpr=0.9021 | 8005.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.58091 | acc=0.1084 | tpr=0.6856 | fpr=0.9021 | 7977.4 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.58081 | acc=0.1083 | tpr=0.6858 | fpr=0.9022 | 7792.7 samples/s | 30.4 steps/s
[Step= 350] | Loss=6.57479 | acc=0.1082 | tpr=0.6869 | fpr=0.9023 | 7757.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.56948 | acc=0.1089 | tpr=0.6860 | fpr=0.9016 | 7964.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.56985 | acc=0.1094 | tpr=0.6899 | fpr=0.9011 | 7880.1 samples/s | 30.8 steps/s
[Step= 500] | Loss=6.57472 | acc=0.1090 | tpr=0.6877 | fpr=0.9014 | 7815.4 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.57475 | acc=0.1091 | tpr=0.6908 | fpr=0.9015 | 13933.3 samples/s | 54.4 steps/s
Avg test loss: 6.57622, Avg test acc: 0.10900, Avg tpr: 0.69057, Avg fpr: 0.90158, total FA: 125182

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09968 | acc=0.9811 | tpr=0.9159 | fpr=0.0177 | 4760.7 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10467 | acc=0.9811 | tpr=0.9254 | fpr=0.0179 | 7239.9 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.10807 | acc=0.9806 | tpr=0.9251 | fpr=0.0184 | 7668.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.11106 | acc=0.9806 | tpr=0.9333 | fpr=0.0186 | 7991.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.10894 | acc=0.9808 | tpr=0.9284 | fpr=0.0183 | 8307.1 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.11120 | acc=0.9805 | tpr=0.9265 | fpr=0.0185 | 7426.5 samples/s | 29.0 steps/s
[Step= 350] | Loss=0.11214 | acc=0.9804 | tpr=0.9286 | fpr=0.0187 | 8238.3 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.11342 | acc=0.9801 | tpr=0.9256 | fpr=0.0189 | 7718.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.11548 | acc=0.9799 | tpr=0.9231 | fpr=0.0191 | 7970.9 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.11474 | acc=0.9800 | tpr=0.9260 | fpr=0.0190 | 7805.6 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.11409 | acc=0.9802 | tpr=0.9252 | fpr=0.0188 | 13937.7 samples/s | 54.4 steps/s
Avg test loss: 0.11399, Avg test acc: 0.98017, Avg tpr: 0.92552, Avg fpr: 0.01884, total FA: 2616

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11329 | acc=0.9821 | tpr=0.8894 | fpr=0.0162 | 4995.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.11770 | acc=0.9817 | tpr=0.8870 | fpr=0.0166 | 6974.9 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.12140 | acc=0.9812 | tpr=0.8934 | fpr=0.0172 | 7586.6 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.12437 | acc=0.9810 | tpr=0.8995 | fpr=0.0175 | 7452.0 samples/s | 29.1 steps/s
[Step= 250] | Loss=0.12143 | acc=0.9813 | tpr=0.8987 | fpr=0.0172 | 8238.0 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.12454 | acc=0.9810 | tpr=0.8982 | fpr=0.0175 | 7666.4 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.12487 | acc=0.9809 | tpr=0.8992 | fpr=0.0177 | 8244.6 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.12598 | acc=0.9806 | tpr=0.8944 | fpr=0.0178 | 7728.4 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.12840 | acc=0.9804 | tpr=0.8944 | fpr=0.0181 | 7894.8 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.12756 | acc=0.9804 | tpr=0.8982 | fpr=0.0181 | 7775.5 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.12712 | acc=0.9806 | tpr=0.8977 | fpr=0.0179 | 14474.7 samples/s | 56.5 steps/s
Avg test loss: 0.12695, Avg test acc: 0.98058, Avg tpr: 0.89739, Avg fpr: 0.01791, total FA: 2487

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09830 | acc=0.9827 | tpr=0.9425 | fpr=0.0166 | 4817.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.10124 | acc=0.9815 | tpr=0.9403 | fpr=0.0177 | 7209.3 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.10667 | acc=0.9807 | tpr=0.9352 | fpr=0.0185 | 7476.1 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.10870 | acc=0.9807 | tpr=0.9355 | fpr=0.0185 | 8200.7 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.10697 | acc=0.9808 | tpr=0.9284 | fpr=0.0182 | 7824.5 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.10907 | acc=0.9805 | tpr=0.9229 | fpr=0.0184 | 7871.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.11012 | acc=0.9803 | tpr=0.9205 | fpr=0.0186 | 7785.0 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.11174 | acc=0.9802 | tpr=0.9163 | fpr=0.0187 | 7563.6 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.11379 | acc=0.9798 | tpr=0.9143 | fpr=0.0190 | 8447.4 samples/s | 33.0 steps/s
[Step= 500] | Loss=0.11321 | acc=0.9799 | tpr=0.9163 | fpr=0.0189 | 7786.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.11254 | acc=0.9800 | tpr=0.9160 | fpr=0.0188 | 13460.5 samples/s | 52.6 steps/s
Avg test loss: 0.11236, Avg test acc: 0.98007, Avg tpr: 0.91640, Avg fpr: 0.01878, total FA: 2607

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10294 | acc=0.9801 | tpr=0.8982 | fpr=0.0185 | 4736.6 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.10559 | acc=0.9797 | tpr=0.9041 | fpr=0.0189 | 7329.7 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.11168 | acc=0.9794 | tpr=0.9107 | fpr=0.0193 | 7778.1 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.11517 | acc=0.9790 | tpr=0.9148 | fpr=0.0198 | 8061.9 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.11218 | acc=0.9793 | tpr=0.9109 | fpr=0.0194 | 7972.6 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11415 | acc=0.9790 | tpr=0.9091 | fpr=0.0197 | 7777.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.11401 | acc=0.9789 | tpr=0.9105 | fpr=0.0199 | 7552.7 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.11420 | acc=0.9789 | tpr=0.9081 | fpr=0.0198 | 8003.9 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.11698 | acc=0.9785 | tpr=0.9051 | fpr=0.0201 | 8095.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11586 | acc=0.9786 | tpr=0.9075 | fpr=0.0201 | 7745.3 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.11563 | acc=0.9788 | tpr=0.9097 | fpr=0.0200 | 14276.8 samples/s | 55.8 steps/s
Avg test loss: 0.11551, Avg test acc: 0.97880, Avg tpr: 0.90967, Avg fpr: 0.01994, total FA: 2769

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12533 | acc=0.9798 | tpr=0.9027 | fpr=0.0188 | 4985.8 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.13054 | acc=0.9791 | tpr=0.9168 | fpr=0.0198 | 6886.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.13474 | acc=0.9784 | tpr=0.9251 | fpr=0.0206 | 7649.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.13751 | acc=0.9782 | tpr=0.9290 | fpr=0.0209 | 7834.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.13551 | acc=0.9784 | tpr=0.9258 | fpr=0.0207 | 7853.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.13824 | acc=0.9781 | tpr=0.9193 | fpr=0.0208 | 7580.6 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.13906 | acc=0.9779 | tpr=0.9198 | fpr=0.0210 | 8185.8 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.14079 | acc=0.9777 | tpr=0.9168 | fpr=0.0212 | 7684.0 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.14364 | acc=0.9774 | tpr=0.9153 | fpr=0.0214 | 7852.0 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.14264 | acc=0.9776 | tpr=0.9163 | fpr=0.0213 | 7892.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.14205 | acc=0.9776 | tpr=0.9148 | fpr=0.0212 | 14553.2 samples/s | 56.8 steps/s
Avg test loss: 0.14179, Avg test acc: 0.97765, Avg tpr: 0.91442, Avg fpr: 0.02120, total FA: 2944

server round 9/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=87.8] | Loss=0.01991 | Reg=0.00563 | acc=0.9844 | L2-Norm=23.723 | L2-Norm(final)=7.979 | 5639.4 samples/s | 88.1 steps/s
[Step=18050 Epoch=88.0] | Loss=0.01807 | Reg=0.00563 | acc=0.9844 | L2-Norm=23.732 | L2-Norm(final)=7.997 | 4309.6 samples/s | 67.3 steps/s
[Step=18100 Epoch=88.3] | Loss=0.01675 | Reg=0.00563 | acc=0.9844 | L2-Norm=23.738 | L2-Norm(final)=8.022 | 5079.8 samples/s | 79.4 steps/s
[Step=18150 Epoch=88.5] | Loss=0.01554 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.740 | L2-Norm(final)=8.046 | 4997.1 samples/s | 78.1 steps/s
[Step=18200 Epoch=88.7] | Loss=0.01470 | Reg=0.00564 | acc=0.9688 | L2-Norm=23.741 | L2-Norm(final)=8.070 | 7793.5 samples/s | 121.8 steps/s
[Step=18250 Epoch=89.0] | Loss=0.01328 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.741 | L2-Norm(final)=8.094 | 2195.8 samples/s | 34.3 steps/s
[Step=18300 Epoch=89.2] | Loss=0.01282 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.740 | L2-Norm(final)=8.120 | 5129.0 samples/s | 80.1 steps/s
[Step=18350 Epoch=89.5] | Loss=0.01233 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.742 | L2-Norm(final)=8.145 | 4972.7 samples/s | 77.7 steps/s
[Step=18400 Epoch=89.7] | Loss=0.01192 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.744 | L2-Norm(final)=8.170 | 6631.9 samples/s | 103.6 steps/s
[Step=18450 Epoch=90.0] | Loss=0.01150 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.745 | L2-Norm(final)=8.194 | 2316.0 samples/s | 36.2 steps/s
[Step=18500 Epoch=90.2] | Loss=0.01112 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.745 | L2-Norm(final)=8.219 | 5145.2 samples/s | 80.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=90.2] | Loss=0.00500 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.745 | L2-Norm(final)=8.472 | 5412.8 samples/s | 84.6 steps/s
[Step=18550 Epoch=90.5] | Loss=0.01201 | Reg=0.00564 | acc=1.0000 | L2-Norm=23.743 | L2-Norm(final)=8.491 | 4093.4 samples/s | 64.0 steps/s
[Step=18600 Epoch=90.7] | Loss=0.02204 | Reg=0.00566 | acc=0.9531 | L2-Norm=23.782 | L2-Norm(final)=8.487 | 4423.9 samples/s | 69.1 steps/s
[Step=18650 Epoch=90.9] | Loss=0.02512 | Reg=0.00569 | acc=0.9844 | L2-Norm=23.844 | L2-Norm(final)=8.477 | 4451.0 samples/s | 69.5 steps/s
[Step=18700 Epoch=91.2] | Loss=0.02953 | Reg=0.00571 | acc=0.9688 | L2-Norm=23.904 | L2-Norm(final)=8.464 | 6379.9 samples/s | 99.7 steps/s
[Step=18750 Epoch=91.4] | Loss=0.03027 | Reg=0.00574 | acc=0.9688 | L2-Norm=23.962 | L2-Norm(final)=8.453 | 2086.6 samples/s | 32.6 steps/s
[Step=18800 Epoch=91.7] | Loss=0.03064 | Reg=0.00577 | acc=0.9688 | L2-Norm=24.014 | L2-Norm(final)=8.442 | 4482.5 samples/s | 70.0 steps/s
[Step=18850 Epoch=91.9] | Loss=0.03004 | Reg=0.00579 | acc=0.9688 | L2-Norm=24.057 | L2-Norm(final)=8.433 | 4423.8 samples/s | 69.1 steps/s
[Step=18900 Epoch=92.2] | Loss=0.02909 | Reg=0.00581 | acc=0.9844 | L2-Norm=24.093 | L2-Norm(final)=8.425 | 5934.7 samples/s | 92.7 steps/s
[Step=18950 Epoch=92.4] | Loss=0.02817 | Reg=0.00582 | acc=0.9688 | L2-Norm=24.124 | L2-Norm(final)=8.419 | 2179.4 samples/s | 34.1 steps/s
[Step=19000 Epoch=92.6] | Loss=0.02719 | Reg=0.00583 | acc=1.0000 | L2-Norm=24.150 | L2-Norm(final)=8.413 | 4371.1 samples/s | 68.3 steps/s
[Step=19050 Epoch=92.9] | Loss=0.02616 | Reg=0.00584 | acc=0.9688 | L2-Norm=24.172 | L2-Norm(final)=8.408 | 4388.2 samples/s | 68.6 steps/s
[Step=19100 Epoch=93.1] | Loss=0.02583 | Reg=0.00585 | acc=0.9844 | L2-Norm=24.194 | L2-Norm(final)=8.402 | 5401.4 samples/s | 84.4 steps/s
[Step=19150 Epoch=93.4] | Loss=0.02501 | Reg=0.00586 | acc=1.0000 | L2-Norm=24.214 | L2-Norm(final)=8.397 | 2261.9 samples/s | 35.3 steps/s
[Step=19200 Epoch=93.6] | Loss=0.02391 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.230 | L2-Norm(final)=8.394 | 4525.3 samples/s | 70.7 steps/s
[Step=19250 Epoch=93.9] | Loss=0.02326 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.243 | L2-Norm(final)=8.391 | 4403.6 samples/s | 68.8 steps/s
[Step=19300 Epoch=94.1] | Loss=0.02264 | Reg=0.00588 | acc=1.0000 | L2-Norm=24.255 | L2-Norm(final)=8.388 | 4996.6 samples/s | 78.1 steps/s
[Step=19350 Epoch=94.4] | Loss=0.02188 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.265 | L2-Norm(final)=8.385 | 2310.7 samples/s | 36.1 steps/s
[Step=19400 Epoch=94.6] | Loss=0.02114 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.273 | L2-Norm(final)=8.383 | 4443.3 samples/s | 69.4 steps/s
[Step=19450 Epoch=94.8] | Loss=0.02052 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.280 | L2-Norm(final)=8.381 | 4520.9 samples/s | 70.6 steps/s
[Step=19500 Epoch=95.1] | Loss=0.02009 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.284 | L2-Norm(final)=8.379 | 4584.2 samples/s | 71.6 steps/s
[Step=19550 Epoch=95.3] | Loss=0.01959 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.288 | L2-Norm(final)=8.377 | 2450.0 samples/s | 38.3 steps/s
[Step=19600 Epoch=95.6] | Loss=0.01898 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.290 | L2-Norm(final)=8.375 | 4472.8 samples/s | 69.9 steps/s
[Step=19650 Epoch=95.8] | Loss=0.01856 | Reg=0.00590 | acc=0.9688 | L2-Norm=24.290 | L2-Norm(final)=8.374 | 4534.9 samples/s | 70.9 steps/s
[Step=19700 Epoch=96.1] | Loss=0.01813 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.289 | L2-Norm(final)=8.373 | 4392.2 samples/s | 68.6 steps/s
[Step=19750 Epoch=96.3] | Loss=0.01767 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.287 | L2-Norm(final)=8.372 | 2446.7 samples/s | 38.2 steps/s
[Step=19800 Epoch=96.5] | Loss=0.01729 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.284 | L2-Norm(final)=8.371 | 4445.5 samples/s | 69.5 steps/s
[Step=19850 Epoch=96.8] | Loss=0.01690 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.280 | L2-Norm(final)=8.370 | 4370.1 samples/s | 68.3 steps/s
[Step=19900 Epoch=97.0] | Loss=0.01651 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.275 | L2-Norm(final)=8.370 | 4474.1 samples/s | 69.9 steps/s
[Step=19950 Epoch=97.3] | Loss=0.01617 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.269 | L2-Norm(final)=8.369 | 2455.2 samples/s | 38.4 steps/s
[Step=20000 Epoch=97.5] | Loss=0.01582 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.263 | L2-Norm(final)=8.368 | 4537.2 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step20000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=87.8] | Loss=0.01309 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.595 | L2-Norm(final)=8.121 | 4961.0 samples/s | 77.5 steps/s
[Step=18050 Epoch=88.1] | Loss=0.01684 | Reg=0.00557 | acc=0.9531 | L2-Norm=23.591 | L2-Norm(final)=8.144 | 4707.5 samples/s | 73.6 steps/s
[Step=18100 Epoch=88.3] | Loss=0.01506 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.592 | L2-Norm(final)=8.175 | 5030.1 samples/s | 78.6 steps/s
[Step=18150 Epoch=88.6] | Loss=0.01378 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.594 | L2-Norm(final)=8.201 | 5010.3 samples/s | 78.3 steps/s
[Step=18200 Epoch=88.8] | Loss=0.01298 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.597 | L2-Norm(final)=8.227 | 7945.0 samples/s | 124.1 steps/s
[Step=18250 Epoch=89.1] | Loss=0.01240 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.598 | L2-Norm(final)=8.254 | 2219.1 samples/s | 34.7 steps/s
[Step=18300 Epoch=89.3] | Loss=0.01172 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.600 | L2-Norm(final)=8.281 | 4955.7 samples/s | 77.4 steps/s
[Step=18350 Epoch=89.5] | Loss=0.01105 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.601 | L2-Norm(final)=8.308 | 5081.7 samples/s | 79.4 steps/s
[Step=18400 Epoch=89.8] | Loss=0.01068 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.602 | L2-Norm(final)=8.335 | 6977.8 samples/s | 109.0 steps/s
[Step=18450 Epoch=90.0] | Loss=0.01013 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.603 | L2-Norm(final)=8.361 | 2243.3 samples/s | 35.1 steps/s
[Step=18500 Epoch=90.3] | Loss=0.00976 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.603 | L2-Norm(final)=8.388 | 5088.2 samples/s | 79.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=90.3] | Loss=0.00438 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.600 | L2-Norm(final)=8.650 | 5698.5 samples/s | 89.0 steps/s
[Step=18550 Epoch=90.5] | Loss=0.01147 | Reg=0.00557 | acc=0.9219 | L2-Norm=23.597 | L2-Norm(final)=8.669 | 4024.2 samples/s | 62.9 steps/s
[Step=18600 Epoch=90.8] | Loss=0.01986 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.617 | L2-Norm(final)=8.664 | 4407.9 samples/s | 68.9 steps/s
[Step=18650 Epoch=91.0] | Loss=0.02573 | Reg=0.00560 | acc=0.9688 | L2-Norm=23.674 | L2-Norm(final)=8.649 | 4541.6 samples/s | 71.0 steps/s
[Step=18700 Epoch=91.2] | Loss=0.02892 | Reg=0.00564 | acc=0.9844 | L2-Norm=23.741 | L2-Norm(final)=8.634 | 6471.4 samples/s | 101.1 steps/s
[Step=18750 Epoch=91.5] | Loss=0.03009 | Reg=0.00567 | acc=0.9844 | L2-Norm=23.807 | L2-Norm(final)=8.620 | 2080.3 samples/s | 32.5 steps/s
[Step=18800 Epoch=91.7] | Loss=0.02903 | Reg=0.00570 | acc=0.9844 | L2-Norm=23.865 | L2-Norm(final)=8.608 | 4541.3 samples/s | 71.0 steps/s
[Step=18850 Epoch=92.0] | Loss=0.02792 | Reg=0.00572 | acc=0.9844 | L2-Norm=23.912 | L2-Norm(final)=8.600 | 4534.6 samples/s | 70.9 steps/s
[Step=18900 Epoch=92.2] | Loss=0.02774 | Reg=0.00574 | acc=0.9844 | L2-Norm=23.953 | L2-Norm(final)=8.592 | 5866.2 samples/s | 91.7 steps/s
[Step=18950 Epoch=92.5] | Loss=0.02699 | Reg=0.00576 | acc=1.0000 | L2-Norm=23.989 | L2-Norm(final)=8.585 | 2151.8 samples/s | 33.6 steps/s
[Step=19000 Epoch=92.7] | Loss=0.02664 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.023 | L2-Norm(final)=8.578 | 4535.1 samples/s | 70.9 steps/s
[Step=19050 Epoch=93.0] | Loss=0.02583 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.054 | L2-Norm(final)=8.570 | 4420.9 samples/s | 69.1 steps/s
[Step=19100 Epoch=93.2] | Loss=0.02517 | Reg=0.00580 | acc=1.0000 | L2-Norm=24.082 | L2-Norm(final)=8.564 | 5514.0 samples/s | 86.2 steps/s
[Step=19150 Epoch=93.4] | Loss=0.02447 | Reg=0.00581 | acc=1.0000 | L2-Norm=24.106 | L2-Norm(final)=8.558 | 2169.2 samples/s | 33.9 steps/s
[Step=19200 Epoch=93.7] | Loss=0.02375 | Reg=0.00582 | acc=0.9844 | L2-Norm=24.127 | L2-Norm(final)=8.553 | 4426.7 samples/s | 69.2 steps/s
[Step=19250 Epoch=93.9] | Loss=0.02290 | Reg=0.00583 | acc=0.9844 | L2-Norm=24.146 | L2-Norm(final)=8.549 | 4566.2 samples/s | 71.3 steps/s
[Step=19300 Epoch=94.2] | Loss=0.02229 | Reg=0.00584 | acc=1.0000 | L2-Norm=24.162 | L2-Norm(final)=8.545 | 5065.5 samples/s | 79.1 steps/s
[Step=19350 Epoch=94.4] | Loss=0.02162 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.175 | L2-Norm(final)=8.542 | 2290.3 samples/s | 35.8 steps/s
[Step=19400 Epoch=94.7] | Loss=0.02086 | Reg=0.00585 | acc=1.0000 | L2-Norm=24.186 | L2-Norm(final)=8.539 | 4612.7 samples/s | 72.1 steps/s
[Step=19450 Epoch=94.9] | Loss=0.02025 | Reg=0.00585 | acc=0.9844 | L2-Norm=24.195 | L2-Norm(final)=8.537 | 4278.4 samples/s | 66.9 steps/s
[Step=19500 Epoch=95.2] | Loss=0.01960 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.201 | L2-Norm(final)=8.536 | 4832.3 samples/s | 75.5 steps/s
[Step=19550 Epoch=95.4] | Loss=0.01899 | Reg=0.00586 | acc=1.0000 | L2-Norm=24.206 | L2-Norm(final)=8.534 | 2360.1 samples/s | 36.9 steps/s
[Step=19600 Epoch=95.6] | Loss=0.01846 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.210 | L2-Norm(final)=8.534 | 4383.2 samples/s | 68.5 steps/s
[Step=19650 Epoch=95.9] | Loss=0.01802 | Reg=0.00586 | acc=0.9688 | L2-Norm=24.213 | L2-Norm(final)=8.533 | 4574.6 samples/s | 71.5 steps/s
[Step=19700 Epoch=96.1] | Loss=0.01772 | Reg=0.00586 | acc=1.0000 | L2-Norm=24.216 | L2-Norm(final)=8.533 | 4464.2 samples/s | 69.8 steps/s
[Step=19750 Epoch=96.4] | Loss=0.01723 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.217 | L2-Norm(final)=8.532 | 2391.3 samples/s | 37.4 steps/s
[Step=19800 Epoch=96.6] | Loss=0.01683 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.218 | L2-Norm(final)=8.531 | 4407.4 samples/s | 68.9 steps/s
[Step=19850 Epoch=96.9] | Loss=0.01660 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.218 | L2-Norm(final)=8.531 | 4468.3 samples/s | 69.8 steps/s
[Step=19900 Epoch=97.1] | Loss=0.01688 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.220 | L2-Norm(final)=8.529 | 4511.7 samples/s | 70.5 steps/s
[Step=19950 Epoch=97.3] | Loss=0.01716 | Reg=0.00587 | acc=0.9688 | L2-Norm=24.225 | L2-Norm(final)=8.526 | 2463.8 samples/s | 38.5 steps/s
[Step=20000 Epoch=97.6] | Loss=0.01729 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.232 | L2-Norm(final)=8.523 | 4489.9 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step20000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=87.7] | Loss=0.01591 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.630 | L2-Norm(final)=8.493 | 5319.5 samples/s | 83.1 steps/s
[Step=18050 Epoch=87.9] | Loss=0.01396 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.624 | L2-Norm(final)=8.517 | 4545.6 samples/s | 71.0 steps/s
[Step=18100 Epoch=88.2] | Loss=0.01406 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.626 | L2-Norm(final)=8.548 | 4967.4 samples/s | 77.6 steps/s
[Step=18150 Epoch=88.4] | Loss=0.01300 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.630 | L2-Norm(final)=8.578 | 4940.2 samples/s | 77.2 steps/s
[Step=18200 Epoch=88.7] | Loss=0.01241 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.635 | L2-Norm(final)=8.606 | 7810.0 samples/s | 122.0 steps/s
[Step=18250 Epoch=88.9] | Loss=0.01143 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.636 | L2-Norm(final)=8.634 | 2216.1 samples/s | 34.6 steps/s
[Step=18300 Epoch=89.2] | Loss=0.01084 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.636 | L2-Norm(final)=8.661 | 5125.5 samples/s | 80.1 steps/s
[Step=18350 Epoch=89.4] | Loss=0.01083 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.636 | L2-Norm(final)=8.687 | 4933.3 samples/s | 77.1 steps/s
[Step=18400 Epoch=89.7] | Loss=0.01053 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.635 | L2-Norm(final)=8.712 | 7025.6 samples/s | 109.8 steps/s
[Step=18450 Epoch=89.9] | Loss=0.01005 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.634 | L2-Norm(final)=8.738 | 2314.6 samples/s | 36.2 steps/s
[Step=18500 Epoch=90.1] | Loss=0.00978 | Reg=0.00558 | acc=0.9844 | L2-Norm=23.632 | L2-Norm(final)=8.763 | 4802.0 samples/s | 75.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=90.1] | Loss=0.00811 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.611 | L2-Norm(final)=9.013 | 5665.7 samples/s | 88.5 steps/s
[Step=18550 Epoch=90.4] | Loss=0.01298 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.619 | L2-Norm(final)=9.028 | 4033.0 samples/s | 63.0 steps/s
[Step=18600 Epoch=90.6] | Loss=0.02009 | Reg=0.00559 | acc=0.9688 | L2-Norm=23.644 | L2-Norm(final)=9.029 | 4503.1 samples/s | 70.4 steps/s
[Step=18650 Epoch=90.9] | Loss=0.02450 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.691 | L2-Norm(final)=9.021 | 4495.3 samples/s | 70.2 steps/s
[Step=18700 Epoch=91.1] | Loss=0.02882 | Reg=0.00564 | acc=0.9531 | L2-Norm=23.747 | L2-Norm(final)=9.011 | 6545.7 samples/s | 102.3 steps/s
[Step=18750 Epoch=91.4] | Loss=0.03018 | Reg=0.00567 | acc=0.9844 | L2-Norm=23.808 | L2-Norm(final)=8.997 | 2111.8 samples/s | 33.0 steps/s
[Step=18800 Epoch=91.6] | Loss=0.02984 | Reg=0.00570 | acc=0.9844 | L2-Norm=23.864 | L2-Norm(final)=8.985 | 4468.8 samples/s | 69.8 steps/s
[Step=18850 Epoch=91.8] | Loss=0.03150 | Reg=0.00572 | acc=0.9688 | L2-Norm=23.915 | L2-Norm(final)=8.974 | 4404.8 samples/s | 68.8 steps/s
[Step=18900 Epoch=92.1] | Loss=0.03250 | Reg=0.00575 | acc=0.9844 | L2-Norm=23.970 | L2-Norm(final)=8.959 | 5851.9 samples/s | 91.4 steps/s
[Step=18950 Epoch=92.3] | Loss=0.03215 | Reg=0.00577 | acc=0.9688 | L2-Norm=24.020 | L2-Norm(final)=8.945 | 2173.2 samples/s | 34.0 steps/s
[Step=19000 Epoch=92.6] | Loss=0.03084 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.062 | L2-Norm(final)=8.934 | 4516.8 samples/s | 70.6 steps/s
[Step=19050 Epoch=92.8] | Loss=0.02917 | Reg=0.00581 | acc=1.0000 | L2-Norm=24.097 | L2-Norm(final)=8.926 | 4454.9 samples/s | 69.6 steps/s
[Step=19100 Epoch=93.1] | Loss=0.02819 | Reg=0.00582 | acc=0.9531 | L2-Norm=24.126 | L2-Norm(final)=8.919 | 5400.7 samples/s | 84.4 steps/s
[Step=19150 Epoch=93.3] | Loss=0.02687 | Reg=0.00583 | acc=1.0000 | L2-Norm=24.150 | L2-Norm(final)=8.914 | 2229.0 samples/s | 34.8 steps/s
[Step=19200 Epoch=93.6] | Loss=0.02569 | Reg=0.00584 | acc=0.9844 | L2-Norm=24.170 | L2-Norm(final)=8.911 | 4412.6 samples/s | 68.9 steps/s
[Step=19250 Epoch=93.8] | Loss=0.02460 | Reg=0.00585 | acc=0.9844 | L2-Norm=24.186 | L2-Norm(final)=8.908 | 4531.5 samples/s | 70.8 steps/s
[Step=19300 Epoch=94.0] | Loss=0.02408 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.201 | L2-Norm(final)=8.905 | 4938.0 samples/s | 77.2 steps/s
[Step=19350 Epoch=94.3] | Loss=0.02349 | Reg=0.00586 | acc=0.9844 | L2-Norm=24.216 | L2-Norm(final)=8.903 | 2337.9 samples/s | 36.5 steps/s
[Step=19400 Epoch=94.5] | Loss=0.02300 | Reg=0.00587 | acc=0.9844 | L2-Norm=24.230 | L2-Norm(final)=8.900 | 4512.3 samples/s | 70.5 steps/s
[Step=19450 Epoch=94.8] | Loss=0.02268 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.244 | L2-Norm(final)=8.898 | 4487.4 samples/s | 70.1 steps/s
[Step=19500 Epoch=95.0] | Loss=0.02244 | Reg=0.00589 | acc=0.9844 | L2-Norm=24.257 | L2-Norm(final)=8.895 | 4573.4 samples/s | 71.5 steps/s
[Step=19550 Epoch=95.3] | Loss=0.02207 | Reg=0.00589 | acc=1.0000 | L2-Norm=24.270 | L2-Norm(final)=8.892 | 2415.3 samples/s | 37.7 steps/s
[Step=19600 Epoch=95.5] | Loss=0.02169 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.282 | L2-Norm(final)=8.890 | 4508.6 samples/s | 70.4 steps/s
[Step=19650 Epoch=95.7] | Loss=0.02145 | Reg=0.00590 | acc=0.9844 | L2-Norm=24.293 | L2-Norm(final)=8.887 | 4401.9 samples/s | 68.8 steps/s
[Step=19700 Epoch=96.0] | Loss=0.02122 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.305 | L2-Norm(final)=8.885 | 4534.8 samples/s | 70.9 steps/s
[Step=19750 Epoch=96.2] | Loss=0.02068 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.315 | L2-Norm(final)=8.882 | 2483.3 samples/s | 38.8 steps/s
[Step=19800 Epoch=96.5] | Loss=0.02026 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.324 | L2-Norm(final)=8.880 | 4423.2 samples/s | 69.1 steps/s
[Step=19850 Epoch=96.7] | Loss=0.01992 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.332 | L2-Norm(final)=8.878 | 4464.2 samples/s | 69.8 steps/s
[Step=19900 Epoch=97.0] | Loss=0.01953 | Reg=0.00592 | acc=0.9844 | L2-Norm=24.338 | L2-Norm(final)=8.877 | 4362.3 samples/s | 68.2 steps/s
[Step=19950 Epoch=97.2] | Loss=0.01923 | Reg=0.00593 | acc=1.0000 | L2-Norm=24.344 | L2-Norm(final)=8.876 | 2486.9 samples/s | 38.9 steps/s
[Step=20000 Epoch=97.4] | Loss=0.01885 | Reg=0.00593 | acc=0.9844 | L2-Norm=24.348 | L2-Norm(final)=8.875 | 4471.0 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step20000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=87.8] | Loss=0.00992 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.646 | L2-Norm(final)=8.225 | 5466.9 samples/s | 85.4 steps/s
[Step=18050 Epoch=88.0] | Loss=0.01480 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.652 | L2-Norm(final)=8.260 | 4468.2 samples/s | 69.8 steps/s
[Step=18100 Epoch=88.3] | Loss=0.01432 | Reg=0.00560 | acc=0.9531 | L2-Norm=23.657 | L2-Norm(final)=8.292 | 5042.0 samples/s | 78.8 steps/s
[Step=18150 Epoch=88.5] | Loss=0.01411 | Reg=0.00560 | acc=1.0000 | L2-Norm=23.662 | L2-Norm(final)=8.323 | 5077.1 samples/s | 79.3 steps/s
[Step=18200 Epoch=88.8] | Loss=0.01331 | Reg=0.00560 | acc=0.9688 | L2-Norm=23.667 | L2-Norm(final)=8.352 | 7753.4 samples/s | 121.1 steps/s
[Step=18250 Epoch=89.0] | Loss=0.01253 | Reg=0.00560 | acc=1.0000 | L2-Norm=23.672 | L2-Norm(final)=8.382 | 2215.0 samples/s | 34.6 steps/s
[Step=18300 Epoch=89.2] | Loss=0.01169 | Reg=0.00560 | acc=0.9844 | L2-Norm=23.674 | L2-Norm(final)=8.411 | 5232.6 samples/s | 81.8 steps/s
[Step=18350 Epoch=89.5] | Loss=0.01142 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.676 | L2-Norm(final)=8.439 | 4839.8 samples/s | 75.6 steps/s
[Step=18400 Epoch=89.7] | Loss=0.01109 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.678 | L2-Norm(final)=8.467 | 6979.0 samples/s | 109.0 steps/s
[Step=18450 Epoch=90.0] | Loss=0.01058 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.680 | L2-Norm(final)=8.494 | 2296.7 samples/s | 35.9 steps/s
[Step=18500 Epoch=90.2] | Loss=0.01030 | Reg=0.00561 | acc=0.9844 | L2-Norm=23.681 | L2-Norm(final)=8.521 | 5045.2 samples/s | 78.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=90.2] | Loss=0.00247 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.684 | L2-Norm(final)=8.792 | 5282.8 samples/s | 82.5 steps/s
[Step=18550 Epoch=90.5] | Loss=0.01086 | Reg=0.00561 | acc=1.0000 | L2-Norm=23.689 | L2-Norm(final)=8.818 | 4130.2 samples/s | 64.5 steps/s
[Step=18600 Epoch=90.7] | Loss=0.01825 | Reg=0.00562 | acc=0.9844 | L2-Norm=23.715 | L2-Norm(final)=8.824 | 4335.0 samples/s | 67.7 steps/s
[Step=18650 Epoch=90.9] | Loss=0.02628 | Reg=0.00565 | acc=0.9844 | L2-Norm=23.776 | L2-Norm(final)=8.810 | 4464.7 samples/s | 69.8 steps/s
[Step=18700 Epoch=91.2] | Loss=0.03053 | Reg=0.00569 | acc=0.9688 | L2-Norm=23.847 | L2-Norm(final)=8.796 | 6600.5 samples/s | 103.1 steps/s
[Step=18750 Epoch=91.4] | Loss=0.03101 | Reg=0.00572 | acc=0.9688 | L2-Norm=23.914 | L2-Norm(final)=8.780 | 2116.2 samples/s | 33.1 steps/s
[Step=18800 Epoch=91.7] | Loss=0.03029 | Reg=0.00575 | acc=0.9844 | L2-Norm=23.972 | L2-Norm(final)=8.769 | 4467.2 samples/s | 69.8 steps/s
[Step=18850 Epoch=91.9] | Loss=0.03015 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.018 | L2-Norm(final)=8.760 | 4494.0 samples/s | 70.2 steps/s
[Step=18900 Epoch=92.2] | Loss=0.02987 | Reg=0.00579 | acc=0.9531 | L2-Norm=24.058 | L2-Norm(final)=8.752 | 5925.5 samples/s | 92.6 steps/s
[Step=18950 Epoch=92.4] | Loss=0.03109 | Reg=0.00581 | acc=0.9531 | L2-Norm=24.098 | L2-Norm(final)=8.742 | 2155.9 samples/s | 33.7 steps/s
[Step=19000 Epoch=92.7] | Loss=0.03034 | Reg=0.00583 | acc=0.9844 | L2-Norm=24.142 | L2-Norm(final)=8.732 | 4550.9 samples/s | 71.1 steps/s
[Step=19050 Epoch=92.9] | Loss=0.02948 | Reg=0.00585 | acc=0.9844 | L2-Norm=24.182 | L2-Norm(final)=8.724 | 4446.6 samples/s | 69.5 steps/s
[Step=19100 Epoch=93.1] | Loss=0.02934 | Reg=0.00587 | acc=1.0000 | L2-Norm=24.218 | L2-Norm(final)=8.716 | 5395.7 samples/s | 84.3 steps/s
[Step=19150 Epoch=93.4] | Loss=0.02871 | Reg=0.00588 | acc=0.9844 | L2-Norm=24.252 | L2-Norm(final)=8.708 | 2251.5 samples/s | 35.2 steps/s
[Step=19200 Epoch=93.6] | Loss=0.02752 | Reg=0.00590 | acc=1.0000 | L2-Norm=24.282 | L2-Norm(final)=8.701 | 4487.7 samples/s | 70.1 steps/s
[Step=19250 Epoch=93.9] | Loss=0.02681 | Reg=0.00591 | acc=1.0000 | L2-Norm=24.308 | L2-Norm(final)=8.696 | 4433.9 samples/s | 69.3 steps/s
[Step=19300 Epoch=94.1] | Loss=0.02643 | Reg=0.00592 | acc=1.0000 | L2-Norm=24.332 | L2-Norm(final)=8.690 | 4916.3 samples/s | 76.8 steps/s
[Step=19350 Epoch=94.4] | Loss=0.02572 | Reg=0.00593 | acc=1.0000 | L2-Norm=24.354 | L2-Norm(final)=8.685 | 2382.0 samples/s | 37.2 steps/s
[Step=19400 Epoch=94.6] | Loss=0.02484 | Reg=0.00594 | acc=1.0000 | L2-Norm=24.372 | L2-Norm(final)=8.680 | 4381.5 samples/s | 68.5 steps/s
[Step=19450 Epoch=94.8] | Loss=0.02435 | Reg=0.00595 | acc=0.9844 | L2-Norm=24.387 | L2-Norm(final)=8.676 | 4525.3 samples/s | 70.7 steps/s
[Step=19500 Epoch=95.1] | Loss=0.02374 | Reg=0.00595 | acc=0.9844 | L2-Norm=24.400 | L2-Norm(final)=8.672 | 4579.3 samples/s | 71.6 steps/s
[Step=19550 Epoch=95.3] | Loss=0.02296 | Reg=0.00596 | acc=1.0000 | L2-Norm=24.411 | L2-Norm(final)=8.668 | 2420.1 samples/s | 37.8 steps/s
[Step=19600 Epoch=95.6] | Loss=0.02231 | Reg=0.00596 | acc=1.0000 | L2-Norm=24.419 | L2-Norm(final)=8.665 | 4450.5 samples/s | 69.5 steps/s
[Step=19650 Epoch=95.8] | Loss=0.02171 | Reg=0.00597 | acc=1.0000 | L2-Norm=24.427 | L2-Norm(final)=8.662 | 4411.1 samples/s | 68.9 steps/s
[Step=19700 Epoch=96.1] | Loss=0.02120 | Reg=0.00597 | acc=1.0000 | L2-Norm=24.433 | L2-Norm(final)=8.660 | 4457.3 samples/s | 69.6 steps/s
[Step=19750 Epoch=96.3] | Loss=0.02067 | Reg=0.00597 | acc=1.0000 | L2-Norm=24.438 | L2-Norm(final)=8.657 | 2474.0 samples/s | 38.7 steps/s
[Step=19800 Epoch=96.6] | Loss=0.02009 | Reg=0.00597 | acc=1.0000 | L2-Norm=24.442 | L2-Norm(final)=8.656 | 4473.9 samples/s | 69.9 steps/s
[Step=19850 Epoch=96.8] | Loss=0.01957 | Reg=0.00598 | acc=1.0000 | L2-Norm=24.444 | L2-Norm(final)=8.654 | 4512.4 samples/s | 70.5 steps/s
[Step=19900 Epoch=97.0] | Loss=0.01914 | Reg=0.00598 | acc=1.0000 | L2-Norm=24.445 | L2-Norm(final)=8.653 | 4432.1 samples/s | 69.3 steps/s
[Step=19950 Epoch=97.3] | Loss=0.01877 | Reg=0.00598 | acc=1.0000 | L2-Norm=24.445 | L2-Norm(final)=8.652 | 2459.7 samples/s | 38.4 steps/s
[Step=20000 Epoch=97.5] | Loss=0.01848 | Reg=0.00598 | acc=0.9844 | L2-Norm=24.445 | L2-Norm(final)=8.651 | 4382.9 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step20000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=88.3] | Loss=0.01080 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=8.550 | 5162.7 samples/s | 80.7 steps/s
[Step=18050 Epoch=88.5] | Loss=0.01424 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.259 | L2-Norm(final)=8.578 | 4845.7 samples/s | 75.7 steps/s
[Step=18100 Epoch=88.8] | Loss=0.01309 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=8.607 | 5131.4 samples/s | 80.2 steps/s
[Step=18150 Epoch=89.0] | Loss=0.01228 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=8.632 | 4958.7 samples/s | 77.5 steps/s
[Step=18200 Epoch=89.2] | Loss=0.01152 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=8.658 | 8105.9 samples/s | 126.7 steps/s
[Step=18250 Epoch=89.5] | Loss=0.01059 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.262 | L2-Norm(final)=8.685 | 2199.9 samples/s | 34.4 steps/s
[Step=18300 Epoch=89.7] | Loss=0.01009 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.263 | L2-Norm(final)=8.712 | 5026.4 samples/s | 78.5 steps/s
[Step=18350 Epoch=90.0] | Loss=0.01007 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.264 | L2-Norm(final)=8.739 | 4965.5 samples/s | 77.6 steps/s
[Step=18400 Epoch=90.2] | Loss=0.00964 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.264 | L2-Norm(final)=8.766 | 7386.0 samples/s | 115.4 steps/s
[Step=18450 Epoch=90.5] | Loss=0.00924 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.263 | L2-Norm(final)=8.793 | 2273.5 samples/s | 35.5 steps/s
[Step=18500 Epoch=90.7] | Loss=0.00904 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.261 | L2-Norm(final)=8.819 | 4980.4 samples/s | 77.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=90.7] | Loss=0.00423 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.237 | L2-Norm(final)=9.077 | 5693.2 samples/s | 89.0 steps/s
[Step=18550 Epoch=91.0] | Loss=0.01174 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.233 | L2-Norm(final)=9.087 | 3863.9 samples/s | 60.4 steps/s
[Step=18600 Epoch=91.2] | Loss=0.01788 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.264 | L2-Norm(final)=9.086 | 4491.3 samples/s | 70.2 steps/s
[Step=18650 Epoch=91.5] | Loss=0.02646 | Reg=0.00544 | acc=0.9219 | L2-Norm=23.330 | L2-Norm(final)=9.073 | 4457.5 samples/s | 69.6 steps/s
[Step=18700 Epoch=91.7] | Loss=0.03196 | Reg=0.00548 | acc=0.9688 | L2-Norm=23.407 | L2-Norm(final)=9.052 | 6486.5 samples/s | 101.4 steps/s
[Step=18750 Epoch=91.9] | Loss=0.03381 | Reg=0.00552 | acc=0.9688 | L2-Norm=23.485 | L2-Norm(final)=9.031 | 2080.4 samples/s | 32.5 steps/s
[Step=18800 Epoch=92.2] | Loss=0.03308 | Reg=0.00555 | acc=0.9844 | L2-Norm=23.556 | L2-Norm(final)=9.015 | 4452.7 samples/s | 69.6 steps/s
[Step=18850 Epoch=92.4] | Loss=0.03231 | Reg=0.00558 | acc=0.9844 | L2-Norm=23.617 | L2-Norm(final)=9.001 | 4430.7 samples/s | 69.2 steps/s
[Step=18900 Epoch=92.7] | Loss=0.03226 | Reg=0.00560 | acc=0.9844 | L2-Norm=23.670 | L2-Norm(final)=8.988 | 6320.4 samples/s | 98.8 steps/s
[Step=18950 Epoch=92.9] | Loss=0.03117 | Reg=0.00563 | acc=0.9688 | L2-Norm=23.718 | L2-Norm(final)=8.975 | 2135.8 samples/s | 33.4 steps/s
[Step=19000 Epoch=93.2] | Loss=0.03031 | Reg=0.00565 | acc=0.9844 | L2-Norm=23.762 | L2-Norm(final)=8.966 | 4472.1 samples/s | 69.9 steps/s
[Step=19050 Epoch=93.4] | Loss=0.02934 | Reg=0.00567 | acc=1.0000 | L2-Norm=23.802 | L2-Norm(final)=8.957 | 4369.5 samples/s | 68.3 steps/s
[Step=19100 Epoch=93.7] | Loss=0.02893 | Reg=0.00568 | acc=0.9844 | L2-Norm=23.837 | L2-Norm(final)=8.950 | 5904.7 samples/s | 92.3 steps/s
[Step=19150 Epoch=93.9] | Loss=0.02773 | Reg=0.00570 | acc=1.0000 | L2-Norm=23.870 | L2-Norm(final)=8.942 | 2214.3 samples/s | 34.6 steps/s
[Step=19200 Epoch=94.2] | Loss=0.02666 | Reg=0.00571 | acc=1.0000 | L2-Norm=23.898 | L2-Norm(final)=8.935 | 4461.7 samples/s | 69.7 steps/s
[Step=19250 Epoch=94.4] | Loss=0.02580 | Reg=0.00572 | acc=0.9531 | L2-Norm=23.923 | L2-Norm(final)=8.930 | 4397.3 samples/s | 68.7 steps/s
[Step=19300 Epoch=94.6] | Loss=0.02484 | Reg=0.00573 | acc=1.0000 | L2-Norm=23.945 | L2-Norm(final)=8.925 | 5508.1 samples/s | 86.1 steps/s
[Step=19350 Epoch=94.9] | Loss=0.02382 | Reg=0.00574 | acc=1.0000 | L2-Norm=23.963 | L2-Norm(final)=8.921 | 2210.2 samples/s | 34.5 steps/s
[Step=19400 Epoch=95.1] | Loss=0.02289 | Reg=0.00575 | acc=0.9844 | L2-Norm=23.978 | L2-Norm(final)=8.917 | 4464.2 samples/s | 69.8 steps/s
[Step=19450 Epoch=95.4] | Loss=0.02207 | Reg=0.00576 | acc=0.9844 | L2-Norm=23.990 | L2-Norm(final)=8.915 | 4510.4 samples/s | 70.5 steps/s
[Step=19500 Epoch=95.6] | Loss=0.02139 | Reg=0.00576 | acc=0.9844 | L2-Norm=24.001 | L2-Norm(final)=8.912 | 5123.3 samples/s | 80.1 steps/s
[Step=19550 Epoch=95.9] | Loss=0.02084 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.009 | L2-Norm(final)=8.910 | 2276.3 samples/s | 35.6 steps/s
[Step=19600 Epoch=96.1] | Loss=0.02025 | Reg=0.00577 | acc=1.0000 | L2-Norm=24.016 | L2-Norm(final)=8.908 | 4497.8 samples/s | 70.3 steps/s
[Step=19650 Epoch=96.4] | Loss=0.02000 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.022 | L2-Norm(final)=8.905 | 4482.0 samples/s | 70.0 steps/s
[Step=19700 Epoch=96.6] | Loss=0.01970 | Reg=0.00577 | acc=0.9844 | L2-Norm=24.029 | L2-Norm(final)=8.903 | 4915.4 samples/s | 76.8 steps/s
[Step=19750 Epoch=96.9] | Loss=0.01932 | Reg=0.00578 | acc=1.0000 | L2-Norm=24.036 | L2-Norm(final)=8.900 | 2287.3 samples/s | 35.7 steps/s
[Step=19800 Epoch=97.1] | Loss=0.01898 | Reg=0.00578 | acc=0.9531 | L2-Norm=24.042 | L2-Norm(final)=8.898 | 4482.1 samples/s | 70.0 steps/s
[Step=19850 Epoch=97.3] | Loss=0.01874 | Reg=0.00578 | acc=1.0000 | L2-Norm=24.048 | L2-Norm(final)=8.896 | 4500.0 samples/s | 70.3 steps/s
[Step=19900 Epoch=97.6] | Loss=0.01863 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.053 | L2-Norm(final)=8.893 | 4660.7 samples/s | 72.8 steps/s
[Step=19950 Epoch=97.8] | Loss=0.01833 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.059 | L2-Norm(final)=8.890 | 2392.2 samples/s | 37.4 steps/s
[Step=20000 Epoch=98.1] | Loss=0.01801 | Reg=0.00579 | acc=1.0000 | L2-Norm=24.065 | L2-Norm(final)=8.887 | 4486.3 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step20000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=170.6] | Loss=0.00090 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.953 | L2-Norm(final)=5.123 | 5041.4 samples/s | 78.8 steps/s
[Step=18050 Epoch=171.0] | Loss=0.00055 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.990 | L2-Norm(final)=5.142 | 4354.5 samples/s | 68.0 steps/s
[Step=18100 Epoch=171.5] | Loss=0.00041 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.030 | L2-Norm(final)=5.164 | 7034.4 samples/s | 109.9 steps/s
[Step=18150 Epoch=172.0] | Loss=0.00035 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.053 | L2-Norm(final)=5.184 | 2174.0 samples/s | 34.0 steps/s
[Step=18200 Epoch=172.5] | Loss=0.00029 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.065 | L2-Norm(final)=5.201 | 6438.6 samples/s | 100.6 steps/s
[Step=18250 Epoch=172.9] | Loss=0.00025 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.069 | L2-Norm(final)=5.215 | 2216.8 samples/s | 34.6 steps/s
[Step=18300 Epoch=173.4] | Loss=0.00022 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.070 | L2-Norm(final)=5.227 | 5789.2 samples/s | 90.5 steps/s
[Step=18350 Epoch=173.9] | Loss=0.00020 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.068 | L2-Norm(final)=5.238 | 2335.6 samples/s | 36.5 steps/s
[Step=18400 Epoch=174.4] | Loss=0.00018 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.065 | L2-Norm(final)=5.248 | 5199.4 samples/s | 81.2 steps/s
[Step=18450 Epoch=174.8] | Loss=0.00017 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.060 | L2-Norm(final)=5.258 | 2399.8 samples/s | 37.5 steps/s
[Step=18500 Epoch=175.3] | Loss=0.00016 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.055 | L2-Norm(final)=5.267 | 4889.2 samples/s | 76.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=175.3] | Loss=0.00004 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.994 | L2-Norm(final)=5.357 | 5804.7 samples/s | 90.7 steps/s
[Step=18550 Epoch=175.8] | Loss=0.00052 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.972 | L2-Norm(final)=5.365 | 3552.6 samples/s | 55.5 steps/s
[Step=18600 Epoch=176.3] | Loss=0.02278 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.321 | L2-Norm(final)=5.294 | 6305.1 samples/s | 98.5 steps/s
[Step=18650 Epoch=176.7] | Loss=0.01613 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.600 | L2-Norm(final)=5.254 | 2013.8 samples/s | 31.5 steps/s
[Step=18700 Epoch=177.2] | Loss=0.01233 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.742 | L2-Norm(final)=5.237 | 5508.4 samples/s | 86.1 steps/s
[Step=18750 Epoch=177.7] | Loss=0.01029 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.825 | L2-Norm(final)=5.227 | 2100.8 samples/s | 32.8 steps/s
[Step=18800 Epoch=178.1] | Loss=0.00859 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.878 | L2-Norm(final)=5.221 | 5123.5 samples/s | 80.1 steps/s
[Step=18850 Epoch=178.6] | Loss=0.00738 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.912 | L2-Norm(final)=5.218 | 2172.8 samples/s | 34.0 steps/s
[Step=18900 Epoch=179.1] | Loss=0.00646 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.935 | L2-Norm(final)=5.216 | 4742.8 samples/s | 74.1 steps/s
[Step=18950 Epoch=179.6] | Loss=0.00574 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.950 | L2-Norm(final)=5.215 | 2229.0 samples/s | 34.8 steps/s
[Step=19000 Epoch=180.0] | Loss=0.00517 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.959 | L2-Norm(final)=5.214 | 4335.8 samples/s | 67.7 steps/s
[Step=19050 Epoch=180.5] | Loss=0.00470 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.965 | L2-Norm(final)=5.214 | 2348.7 samples/s | 36.7 steps/s
[Step=19100 Epoch=181.0] | Loss=0.00431 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.967 | L2-Norm(final)=5.214 | 4277.5 samples/s | 66.8 steps/s
[Step=19150 Epoch=181.5] | Loss=0.00398 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.967 | L2-Norm(final)=5.214 | 2371.6 samples/s | 37.1 steps/s
[Step=19200 Epoch=181.9] | Loss=0.00370 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.964 | L2-Norm(final)=5.214 | 4215.2 samples/s | 65.9 steps/s
[Step=19250 Epoch=182.4] | Loss=0.00345 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.961 | L2-Norm(final)=5.215 | 2383.2 samples/s | 37.2 steps/s
[Step=19300 Epoch=182.9] | Loss=0.00324 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.956 | L2-Norm(final)=5.215 | 4100.4 samples/s | 64.1 steps/s
[Step=19350 Epoch=183.4] | Loss=0.00305 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.950 | L2-Norm(final)=5.216 | 2514.1 samples/s | 39.3 steps/s
[Step=19400 Epoch=183.8] | Loss=0.00288 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.943 | L2-Norm(final)=5.216 | 3878.8 samples/s | 60.6 steps/s
[Step=19450 Epoch=184.3] | Loss=0.00273 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.936 | L2-Norm(final)=5.217 | 6414.2 samples/s | 100.2 steps/s
[Step=19500 Epoch=184.8] | Loss=0.00259 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.927 | L2-Norm(final)=5.218 | 1954.7 samples/s | 30.5 steps/s
[Step=19550 Epoch=185.3] | Loss=0.00247 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.918 | L2-Norm(final)=5.218 | 5646.5 samples/s | 88.2 steps/s
[Step=19600 Epoch=185.7] | Loss=0.00236 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.909 | L2-Norm(final)=5.219 | 2030.3 samples/s | 31.7 steps/s
[Step=19650 Epoch=186.2] | Loss=0.00225 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.899 | L2-Norm(final)=5.220 | 5259.9 samples/s | 82.2 steps/s
[Step=19700 Epoch=186.7] | Loss=0.00216 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.889 | L2-Norm(final)=5.220 | 2119.8 samples/s | 33.1 steps/s
[Step=19750 Epoch=187.1] | Loss=0.00207 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.878 | L2-Norm(final)=5.221 | 4795.6 samples/s | 74.9 steps/s
[Step=19800 Epoch=187.6] | Loss=0.00200 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=5.222 | 2195.1 samples/s | 34.3 steps/s
[Step=19850 Epoch=188.1] | Loss=0.00192 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.856 | L2-Norm(final)=5.223 | 4503.2 samples/s | 70.4 steps/s
[Step=19900 Epoch=188.6] | Loss=0.00185 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.845 | L2-Norm(final)=5.223 | 2338.9 samples/s | 36.5 steps/s
[Step=19950 Epoch=189.0] | Loss=0.00179 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.833 | L2-Norm(final)=5.224 | 4219.3 samples/s | 65.9 steps/s
[Step=20000 Epoch=189.5] | Loss=0.00173 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.821 | L2-Norm(final)=5.225 | 2427.1 samples/s | 37.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step20000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=171.2] | Loss=0.00138 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.714 | L2-Norm(final)=5.631 | 5591.7 samples/s | 87.4 steps/s
[Step=18050 Epoch=171.7] | Loss=0.00158 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.784 | L2-Norm(final)=5.655 | 3962.2 samples/s | 61.9 steps/s
[Step=18100 Epoch=172.2] | Loss=0.00106 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.859 | L2-Norm(final)=5.677 | 7391.4 samples/s | 115.5 steps/s
[Step=18150 Epoch=172.7] | Loss=0.00076 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.897 | L2-Norm(final)=5.698 | 2133.3 samples/s | 33.3 steps/s
[Step=18200 Epoch=173.1] | Loss=0.00060 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.915 | L2-Norm(final)=5.714 | 6622.9 samples/s | 103.5 steps/s
[Step=18250 Epoch=173.6] | Loss=0.00051 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=5.728 | 2214.7 samples/s | 34.6 steps/s
[Step=18300 Epoch=174.1] | Loss=0.00044 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.934 | L2-Norm(final)=5.741 | 5991.1 samples/s | 93.6 steps/s
[Step=18350 Epoch=174.6] | Loss=0.00039 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.937 | L2-Norm(final)=5.753 | 2315.4 samples/s | 36.2 steps/s
[Step=18400 Epoch=175.0] | Loss=0.00034 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.939 | L2-Norm(final)=5.763 | 5299.9 samples/s | 82.8 steps/s
[Step=18450 Epoch=175.5] | Loss=0.00031 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.938 | L2-Norm(final)=5.773 | 2409.9 samples/s | 37.7 steps/s
[Step=18500 Epoch=176.0] | Loss=0.00029 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.936 | L2-Norm(final)=5.783 | 4928.3 samples/s | 77.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=176.0] | Loss=0.00007 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.910 | L2-Norm(final)=5.876 | 5451.4 samples/s | 85.2 steps/s
[Step=18550 Epoch=176.5] | Loss=0.00003 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.880 | L2-Norm(final)=5.882 | 3700.4 samples/s | 57.8 steps/s
[Step=18600 Epoch=176.9] | Loss=0.00002 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.840 | L2-Norm(final)=5.886 | 6284.7 samples/s | 98.2 steps/s
[Step=18650 Epoch=177.4] | Loss=0.00002 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.798 | L2-Norm(final)=5.888 | 2028.5 samples/s | 31.7 steps/s
[Step=18700 Epoch=177.9] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.757 | L2-Norm(final)=5.889 | 5608.0 samples/s | 87.6 steps/s
[Step=18750 Epoch=178.4] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.715 | L2-Norm(final)=5.890 | 2076.8 samples/s | 32.4 steps/s
[Step=18800 Epoch=178.8] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.674 | L2-Norm(final)=5.891 | 5194.3 samples/s | 81.2 steps/s
[Step=18850 Epoch=179.3] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.634 | L2-Norm(final)=5.892 | 2173.7 samples/s | 34.0 steps/s
[Step=18900 Epoch=179.8] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.594 | L2-Norm(final)=5.893 | 4724.9 samples/s | 73.8 steps/s
[Step=18950 Epoch=180.3] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=5.893 | 2219.8 samples/s | 34.7 steps/s
[Step=19000 Epoch=180.7] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.515 | L2-Norm(final)=5.894 | 4378.1 samples/s | 68.4 steps/s
[Step=19050 Epoch=181.2] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.477 | L2-Norm(final)=5.895 | 2366.4 samples/s | 37.0 steps/s
[Step=19100 Epoch=181.7] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.438 | L2-Norm(final)=5.895 | 4306.1 samples/s | 67.3 steps/s
[Step=19150 Epoch=182.2] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.400 | L2-Norm(final)=5.896 | 2385.4 samples/s | 37.3 steps/s
[Step=19200 Epoch=182.6] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.362 | L2-Norm(final)=5.897 | 4231.7 samples/s | 66.1 steps/s
[Step=19250 Epoch=183.1] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.325 | L2-Norm(final)=5.897 | 2380.4 samples/s | 37.2 steps/s
[Step=19300 Epoch=183.6] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.287 | L2-Norm(final)=5.898 | 4225.4 samples/s | 66.0 steps/s
[Step=19350 Epoch=184.1] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.250 | L2-Norm(final)=5.898 | 2533.7 samples/s | 39.6 steps/s
[Step=19400 Epoch=184.5] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.213 | L2-Norm(final)=5.899 | 3917.3 samples/s | 61.2 steps/s
[Step=19450 Epoch=185.0] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.176 | L2-Norm(final)=5.900 | 6623.9 samples/s | 103.5 steps/s
[Step=19500 Epoch=185.5] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.140 | L2-Norm(final)=5.900 | 1998.7 samples/s | 31.2 steps/s
[Step=19550 Epoch=186.0] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.103 | L2-Norm(final)=5.901 | 5782.8 samples/s | 90.4 steps/s
[Step=19600 Epoch=186.4] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.067 | L2-Norm(final)=5.902 | 2028.9 samples/s | 31.7 steps/s
[Step=19650 Epoch=186.9] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.030 | L2-Norm(final)=5.902 | 5238.6 samples/s | 81.9 steps/s
[Step=19700 Epoch=187.4] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.994 | L2-Norm(final)=5.903 | 2153.6 samples/s | 33.7 steps/s
[Step=19750 Epoch=187.9] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.958 | L2-Norm(final)=5.904 | 4914.1 samples/s | 76.8 steps/s
[Step=19800 Epoch=188.3] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.922 | L2-Norm(final)=5.904 | 2238.0 samples/s | 35.0 steps/s
[Step=19850 Epoch=188.8] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.886 | L2-Norm(final)=5.905 | 4305.0 samples/s | 67.3 steps/s
[Step=19900 Epoch=189.3] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.850 | L2-Norm(final)=5.906 | 2382.4 samples/s | 37.2 steps/s
[Step=19950 Epoch=189.8] | Loss=0.00000 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.814 | L2-Norm(final)=5.907 | 4042.5 samples/s | 63.2 steps/s
[Step=20000 Epoch=190.2] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.778 | L2-Norm(final)=5.907 | 2398.3 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step20000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=171.9] | Loss=0.00231 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.164 | L2-Norm(final)=5.426 | 5164.6 samples/s | 80.7 steps/s
[Step=18050 Epoch=172.4] | Loss=0.00291 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.237 | L2-Norm(final)=5.441 | 4163.3 samples/s | 65.1 steps/s
[Step=18100 Epoch=172.8] | Loss=0.00182 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.283 | L2-Norm(final)=5.456 | 7558.1 samples/s | 118.1 steps/s
[Step=18150 Epoch=173.3] | Loss=0.00136 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=5.471 | 2082.2 samples/s | 32.5 steps/s
[Step=18200 Epoch=173.8] | Loss=0.00107 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.327 | L2-Norm(final)=5.485 | 6753.7 samples/s | 105.5 steps/s
[Step=18250 Epoch=174.3] | Loss=0.00088 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.336 | L2-Norm(final)=5.497 | 2198.8 samples/s | 34.4 steps/s
[Step=18300 Epoch=174.8] | Loss=0.00076 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.341 | L2-Norm(final)=5.508 | 6070.5 samples/s | 94.9 steps/s
[Step=18350 Epoch=175.2] | Loss=0.00067 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.344 | L2-Norm(final)=5.518 | 2279.6 samples/s | 35.6 steps/s
[Step=18400 Epoch=175.7] | Loss=0.00060 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.344 | L2-Norm(final)=5.527 | 5573.2 samples/s | 87.1 steps/s
[Step=18450 Epoch=176.2] | Loss=0.00054 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.343 | L2-Norm(final)=5.536 | 2244.2 samples/s | 35.1 steps/s
[Step=18500 Epoch=176.7] | Loss=0.00050 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.341 | L2-Norm(final)=5.545 | 5279.1 samples/s | 82.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=176.7] | Loss=0.00004 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.320 | L2-Norm(final)=5.633 | 5556.5 samples/s | 86.8 steps/s
[Step=18550 Epoch=177.1] | Loss=0.00007 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.307 | L2-Norm(final)=5.639 | 3749.3 samples/s | 58.6 steps/s
[Step=18600 Epoch=177.6] | Loss=0.00005 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.289 | L2-Norm(final)=5.644 | 6409.4 samples/s | 100.1 steps/s
[Step=18650 Epoch=178.1] | Loss=0.00004 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.269 | L2-Norm(final)=5.647 | 2025.1 samples/s | 31.6 steps/s
[Step=18700 Epoch=178.6] | Loss=0.00003 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.248 | L2-Norm(final)=5.650 | 5757.5 samples/s | 90.0 steps/s
[Step=18750 Epoch=179.1] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.226 | L2-Norm(final)=5.651 | 2033.4 samples/s | 31.8 steps/s
[Step=18800 Epoch=179.5] | Loss=0.00002 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.204 | L2-Norm(final)=5.653 | 5203.7 samples/s | 81.3 steps/s
[Step=18850 Epoch=180.0] | Loss=0.00002 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.182 | L2-Norm(final)=5.654 | 2144.2 samples/s | 33.5 steps/s
[Step=18900 Epoch=180.5] | Loss=0.00002 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.159 | L2-Norm(final)=5.655 | 4882.8 samples/s | 76.3 steps/s
[Step=18950 Epoch=181.0] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.136 | L2-Norm(final)=5.656 | 2208.6 samples/s | 34.5 steps/s
[Step=19000 Epoch=181.4] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.113 | L2-Norm(final)=5.656 | 4528.4 samples/s | 70.8 steps/s
[Step=19050 Epoch=181.9] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.090 | L2-Norm(final)=5.657 | 2285.7 samples/s | 35.7 steps/s
[Step=19100 Epoch=182.4] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.067 | L2-Norm(final)=5.658 | 4326.5 samples/s | 67.6 steps/s
[Step=19150 Epoch=182.9] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.043 | L2-Norm(final)=5.659 | 2376.6 samples/s | 37.1 steps/s
[Step=19200 Epoch=183.3] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.020 | L2-Norm(final)=5.659 | 4235.7 samples/s | 66.2 steps/s
[Step=19250 Epoch=183.8] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.997 | L2-Norm(final)=5.660 | 2369.1 samples/s | 37.0 steps/s
[Step=19300 Epoch=184.3] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.973 | L2-Norm(final)=5.661 | 4222.5 samples/s | 66.0 steps/s
[Step=19350 Epoch=184.8] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.950 | L2-Norm(final)=5.661 | 2410.6 samples/s | 37.7 steps/s
[Step=19400 Epoch=185.3] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=5.662 | 4108.6 samples/s | 64.2 steps/s
[Step=19450 Epoch=185.7] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.902 | L2-Norm(final)=5.662 | 2395.2 samples/s | 37.4 steps/s
[Step=19500 Epoch=186.2] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.878 | L2-Norm(final)=5.663 | 4283.0 samples/s | 66.9 steps/s
[Step=19550 Epoch=186.7] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.854 | L2-Norm(final)=5.663 | 6925.8 samples/s | 108.2 steps/s
[Step=19600 Epoch=187.2] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.830 | L2-Norm(final)=5.664 | 1930.7 samples/s | 30.2 steps/s
[Step=19650 Epoch=187.6] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.806 | L2-Norm(final)=5.665 | 6340.3 samples/s | 99.1 steps/s
[Step=19700 Epoch=188.1] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.782 | L2-Norm(final)=5.665 | 2019.4 samples/s | 31.6 steps/s
[Step=19750 Epoch=188.6] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.758 | L2-Norm(final)=5.666 | 5873.4 samples/s | 91.8 steps/s
[Step=19800 Epoch=189.1] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.733 | L2-Norm(final)=5.666 | 2061.2 samples/s | 32.2 steps/s
[Step=19850 Epoch=189.6] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.709 | L2-Norm(final)=5.667 | 5383.4 samples/s | 84.1 steps/s
[Step=19900 Epoch=190.0] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.684 | L2-Norm(final)=5.667 | 2116.2 samples/s | 33.1 steps/s
[Step=19950 Epoch=190.5] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.659 | L2-Norm(final)=5.668 | 4816.3 samples/s | 75.3 steps/s
[Step=20000 Epoch=191.0] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.635 | L2-Norm(final)=5.669 | 2203.9 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step20000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=169.6] | Loss=0.01179 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.327 | L2-Norm(final)=5.095 | 5292.8 samples/s | 82.7 steps/s
[Step=18050 Epoch=170.1] | Loss=0.00157 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.383 | L2-Norm(final)=5.109 | 4121.5 samples/s | 64.4 steps/s
[Step=18100 Epoch=170.6] | Loss=0.00110 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.410 | L2-Norm(final)=5.135 | 7346.5 samples/s | 114.8 steps/s
[Step=18150 Epoch=171.0] | Loss=0.00083 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.427 | L2-Norm(final)=5.156 | 2142.1 samples/s | 33.5 steps/s
[Step=18200 Epoch=171.5] | Loss=0.00066 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.437 | L2-Norm(final)=5.172 | 6244.2 samples/s | 97.6 steps/s
[Step=18250 Epoch=172.0] | Loss=0.00055 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.441 | L2-Norm(final)=5.185 | 2254.5 samples/s | 35.2 steps/s
[Step=18300 Epoch=172.4] | Loss=0.00047 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.441 | L2-Norm(final)=5.196 | 5646.8 samples/s | 88.2 steps/s
[Step=18350 Epoch=172.9] | Loss=0.00042 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.440 | L2-Norm(final)=5.206 | 2328.8 samples/s | 36.4 steps/s
[Step=18400 Epoch=173.4] | Loss=0.00037 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.437 | L2-Norm(final)=5.216 | 5143.8 samples/s | 80.4 steps/s
[Step=18450 Epoch=173.9] | Loss=0.00034 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.433 | L2-Norm(final)=5.225 | 2454.4 samples/s | 38.3 steps/s
[Step=18500 Epoch=174.3] | Loss=0.00031 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.429 | L2-Norm(final)=5.234 | 4776.4 samples/s | 74.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=174.3] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.383 | L2-Norm(final)=5.317 | 5464.8 samples/s | 85.4 steps/s
[Step=18550 Epoch=174.8] | Loss=0.00006 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.370 | L2-Norm(final)=5.324 | 3830.8 samples/s | 59.9 steps/s
[Step=18600 Epoch=175.3] | Loss=0.00004 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=5.329 | 6199.8 samples/s | 96.9 steps/s
[Step=18650 Epoch=175.7] | Loss=0.00003 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.331 | L2-Norm(final)=5.332 | 2030.4 samples/s | 31.7 steps/s
[Step=18700 Epoch=176.2] | Loss=0.00003 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=5.334 | 5521.9 samples/s | 86.3 steps/s
[Step=18750 Epoch=176.7] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.288 | L2-Norm(final)=5.336 | 2096.4 samples/s | 32.8 steps/s
[Step=18800 Epoch=177.1] | Loss=0.00002 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.266 | L2-Norm(final)=5.338 | 4958.5 samples/s | 77.5 steps/s
[Step=18850 Epoch=177.6] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.244 | L2-Norm(final)=5.339 | 2198.9 samples/s | 34.4 steps/s
[Step=18900 Epoch=178.1] | Loss=0.00002 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.222 | L2-Norm(final)=5.340 | 4461.9 samples/s | 69.7 steps/s
[Step=18950 Epoch=178.6] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.200 | L2-Norm(final)=5.341 | 2331.0 samples/s | 36.4 steps/s
[Step=19000 Epoch=179.0] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.178 | L2-Norm(final)=5.342 | 4201.7 samples/s | 65.7 steps/s
[Step=19050 Epoch=179.5] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.155 | L2-Norm(final)=5.343 | 2329.9 samples/s | 36.4 steps/s
[Step=19100 Epoch=180.0] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.133 | L2-Norm(final)=5.344 | 4275.2 samples/s | 66.8 steps/s
[Step=19150 Epoch=180.4] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.110 | L2-Norm(final)=5.345 | 2395.6 samples/s | 37.4 steps/s
[Step=19200 Epoch=180.9] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.087 | L2-Norm(final)=5.346 | 4212.0 samples/s | 65.8 steps/s
[Step=19250 Epoch=181.4] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.064 | L2-Norm(final)=5.347 | 2612.0 samples/s | 40.8 steps/s
[Step=19300 Epoch=181.9] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.041 | L2-Norm(final)=5.348 | 3608.2 samples/s | 56.4 steps/s
[Step=19350 Epoch=182.3] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.018 | L2-Norm(final)=5.349 | 6293.5 samples/s | 98.3 steps/s
[Step=19400 Epoch=182.8] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.995 | L2-Norm(final)=5.350 | 2021.2 samples/s | 31.6 steps/s
[Step=19450 Epoch=183.3] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.971 | L2-Norm(final)=5.351 | 5629.8 samples/s | 88.0 steps/s
[Step=19500 Epoch=183.7] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.948 | L2-Norm(final)=5.352 | 2121.7 samples/s | 33.2 steps/s
[Step=19550 Epoch=184.2] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.924 | L2-Norm(final)=5.353 | 5034.9 samples/s | 78.7 steps/s
[Step=19600 Epoch=184.7] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.901 | L2-Norm(final)=5.354 | 2188.1 samples/s | 34.2 steps/s
[Step=19650 Epoch=185.2] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.877 | L2-Norm(final)=5.354 | 4509.5 samples/s | 70.5 steps/s
[Step=19700 Epoch=185.6] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.853 | L2-Norm(final)=5.355 | 2309.6 samples/s | 36.1 steps/s
[Step=19750 Epoch=186.1] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.829 | L2-Norm(final)=5.356 | 4224.5 samples/s | 66.0 steps/s
[Step=19800 Epoch=186.6] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.805 | L2-Norm(final)=5.357 | 2367.5 samples/s | 37.0 steps/s
[Step=19850 Epoch=187.0] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.780 | L2-Norm(final)=5.358 | 4293.0 samples/s | 67.1 steps/s
[Step=19900 Epoch=187.5] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.756 | L2-Norm(final)=5.359 | 2366.8 samples/s | 37.0 steps/s
[Step=19950 Epoch=188.0] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.731 | L2-Norm(final)=5.360 | 4260.1 samples/s | 66.6 steps/s
[Step=20000 Epoch=188.5] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.707 | L2-Norm(final)=5.361 | 2584.0 samples/s | 40.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step20000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=171.6] | Loss=0.00081 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.204 | L2-Norm(final)=5.978 | 5585.6 samples/s | 87.3 steps/s
[Step=18050 Epoch=172.0] | Loss=0.00377 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.313 | L2-Norm(final)=6.001 | 3954.3 samples/s | 61.8 steps/s
[Step=18100 Epoch=172.5] | Loss=0.00312 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.452 | L2-Norm(final)=6.033 | 7652.3 samples/s | 119.6 steps/s
[Step=18150 Epoch=173.0] | Loss=0.00221 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.526 | L2-Norm(final)=6.060 | 2089.8 samples/s | 32.7 steps/s
[Step=18200 Epoch=173.5] | Loss=0.00175 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=6.080 | 6880.3 samples/s | 107.5 steps/s
[Step=18250 Epoch=173.9] | Loss=0.00143 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=6.097 | 2204.6 samples/s | 34.4 steps/s
[Step=18300 Epoch=174.4] | Loss=0.00122 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.602 | L2-Norm(final)=6.111 | 6045.0 samples/s | 94.5 steps/s
[Step=18350 Epoch=174.9] | Loss=0.00106 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.610 | L2-Norm(final)=6.124 | 2260.0 samples/s | 35.3 steps/s
[Step=18400 Epoch=175.4] | Loss=0.00095 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.614 | L2-Norm(final)=6.136 | 5678.1 samples/s | 88.7 steps/s
[Step=18450 Epoch=175.8] | Loss=0.00085 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.616 | L2-Norm(final)=6.146 | 2371.8 samples/s | 37.1 steps/s
[Step=18500 Epoch=176.3] | Loss=0.00078 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.616 | L2-Norm(final)=6.157 | 4942.8 samples/s | 77.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=176.3] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.608 | L2-Norm(final)=6.256 | 5474.9 samples/s | 85.5 steps/s
[Step=18550 Epoch=176.8] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=6.262 | 3833.3 samples/s | 59.9 steps/s
[Step=18600 Epoch=177.3] | Loss=0.00004 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.556 | L2-Norm(final)=6.266 | 6287.7 samples/s | 98.2 steps/s
[Step=18650 Epoch=177.8] | Loss=0.00003 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.522 | L2-Norm(final)=6.268 | 2011.1 samples/s | 31.4 steps/s
[Step=18700 Epoch=178.2] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.486 | L2-Norm(final)=6.269 | 5818.5 samples/s | 90.9 steps/s
[Step=18750 Epoch=178.7] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.450 | L2-Norm(final)=6.270 | 2026.4 samples/s | 31.7 steps/s
[Step=18800 Epoch=179.2] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.413 | L2-Norm(final)=6.271 | 5390.3 samples/s | 84.2 steps/s
[Step=18850 Epoch=179.7] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.377 | L2-Norm(final)=6.273 | 2145.6 samples/s | 33.5 steps/s
[Step=18900 Epoch=180.1] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.340 | L2-Norm(final)=6.275 | 4871.5 samples/s | 76.1 steps/s
[Step=18950 Epoch=180.6] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.304 | L2-Norm(final)=6.277 | 2215.2 samples/s | 34.6 steps/s
[Step=19000 Epoch=181.1] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.267 | L2-Norm(final)=6.279 | 4536.2 samples/s | 70.9 steps/s
[Step=19050 Epoch=181.6] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.230 | L2-Norm(final)=6.281 | 2293.7 samples/s | 35.8 steps/s
[Step=19100 Epoch=182.0] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.194 | L2-Norm(final)=6.284 | 4247.6 samples/s | 66.4 steps/s
[Step=19150 Epoch=182.5] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.157 | L2-Norm(final)=6.287 | 2365.8 samples/s | 37.0 steps/s
[Step=19200 Epoch=183.0] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.120 | L2-Norm(final)=6.289 | 4253.8 samples/s | 66.5 steps/s
[Step=19250 Epoch=183.5] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.084 | L2-Norm(final)=6.292 | 2377.1 samples/s | 37.1 steps/s
[Step=19300 Epoch=183.9] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.047 | L2-Norm(final)=6.295 | 4291.4 samples/s | 67.1 steps/s
[Step=19350 Epoch=184.4] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.010 | L2-Norm(final)=6.299 | 2346.9 samples/s | 36.7 steps/s
[Step=19400 Epoch=184.9] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.973 | L2-Norm(final)=6.302 | 4313.8 samples/s | 67.4 steps/s
[Step=19450 Epoch=185.4] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.936 | L2-Norm(final)=6.305 | 2504.7 samples/s | 39.1 steps/s
[Step=19500 Epoch=185.9] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.899 | L2-Norm(final)=6.309 | 3800.0 samples/s | 59.4 steps/s
[Step=19550 Epoch=186.3] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.862 | L2-Norm(final)=6.312 | 6973.9 samples/s | 109.0 steps/s
[Step=19600 Epoch=186.8] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.825 | L2-Norm(final)=6.316 | 1951.6 samples/s | 30.5 steps/s
[Step=19650 Epoch=187.3] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.788 | L2-Norm(final)=6.319 | 6146.6 samples/s | 96.0 steps/s
[Step=19700 Epoch=187.8] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.751 | L2-Norm(final)=6.323 | 2002.6 samples/s | 31.3 steps/s
[Step=19750 Epoch=188.2] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.714 | L2-Norm(final)=6.327 | 5847.1 samples/s | 91.4 steps/s
[Step=19800 Epoch=188.7] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.677 | L2-Norm(final)=6.330 | 2065.8 samples/s | 32.3 steps/s
[Step=19850 Epoch=189.2] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.639 | L2-Norm(final)=6.334 | 5338.2 samples/s | 83.4 steps/s
[Step=19900 Epoch=189.7] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.602 | L2-Norm(final)=6.338 | 2107.9 samples/s | 32.9 steps/s
[Step=19950 Epoch=190.1] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.564 | L2-Norm(final)=6.342 | 4898.7 samples/s | 76.5 steps/s
[Step=20000 Epoch=190.6] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.526 | L2-Norm(final)=6.346 | 2215.0 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.14136 | acc=0.9520 | tpr=0.9704 | fpr=0.0880 | 4845.3 samples/s | 18.9 steps/s
Avg test loss: 0.14699, Avg test acc: 0.95000, Avg tpr: 0.96864, Avg fpr: 0.09101, total FA: 710

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13125 | acc=0.9381 | tpr=0.9469 | fpr=0.0810 | 4898.1 samples/s | 19.1 steps/s
Avg test loss: 0.12740, Avg test acc: 0.93862, Avg tpr: 0.94789, Avg fpr: 0.08178, total FA: 638

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.14774 | acc=0.9487 | tpr=0.9647 | fpr=0.0860 | 4796.0 samples/s | 18.7 steps/s
Avg test loss: 0.14685, Avg test acc: 0.94615, Avg tpr: 0.96340, Avg fpr: 0.09178, total FA: 716

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.14475 | acc=0.9461 | tpr=0.9593 | fpr=0.0825 | 4596.7 samples/s | 18.0 steps/s
Avg test loss: 0.14663, Avg test acc: 0.94475, Avg tpr: 0.95908, Avg fpr: 0.08678, total FA: 677

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.15680 | acc=0.9448 | tpr=0.9645 | fpr=0.0979 | 4828.5 samples/s | 18.9 steps/s
Avg test loss: 0.16353, Avg test acc: 0.94411, Avg tpr: 0.96474, Avg fpr: 0.10127, total FA: 790

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.27616 | acc=0.3084 | tpr=0.0103 | fpr=0.0444 | 4756.6 samples/s | 18.6 steps/s
Avg test loss: 4.29365, Avg test acc: 0.30583, Avg tpr: 0.01020, Avg fpr: 0.04397, total FA: 343

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.11472 | acc=0.2787 | tpr=0.0074 | fpr=0.1321 | 4909.4 samples/s | 19.2 steps/s
Avg test loss: 5.12723, Avg test acc: 0.27614, Avg tpr: 0.00746, Avg fpr: 0.13293, total FA: 1037

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.60101 | acc=0.2571 | tpr=0.0223 | fpr=0.2329 | 4957.2 samples/s | 19.4 steps/s
Avg test loss: 5.60962, Avg test acc: 0.25463, Avg tpr: 0.02308, Avg fpr: 0.23612, total FA: 1842

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.64440 | acc=0.2814 | tpr=0.0305 | fpr=0.1737 | 4687.4 samples/s | 18.3 steps/s
Avg test loss: 5.64405, Avg test acc: 0.27867, Avg tpr: 0.03008, Avg fpr: 0.17459, total FA: 1362

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.68621 | acc=0.2981 | tpr=0.0270 | fpr=0.1132 | 4804.2 samples/s | 18.8 steps/s
Avg test loss: 5.69303, Avg test acc: 0.29786, Avg tpr: 0.02763, Avg fpr: 0.10781, total FA: 841

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.24435 | acc=0.0859 | tpr=0.7434 | fpr=0.9260 | 4945.6 samples/s | 19.3 steps/s
[Step= 100] | Loss=7.23730 | acc=0.0877 | tpr=0.7228 | fpr=0.9242 | 6892.0 samples/s | 26.9 steps/s
[Step= 150] | Loss=7.25264 | acc=0.0882 | tpr=0.7233 | fpr=0.9235 | 7864.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=7.24800 | acc=0.0880 | tpr=0.7148 | fpr=0.9234 | 7744.3 samples/s | 30.3 steps/s
[Step= 250] | Loss=7.26062 | acc=0.0878 | tpr=0.7214 | fpr=0.9237 | 7579.0 samples/s | 29.6 steps/s
[Step= 300] | Loss=7.24885 | acc=0.0880 | tpr=0.7273 | fpr=0.9236 | 8269.6 samples/s | 32.3 steps/s
[Step= 350] | Loss=7.24836 | acc=0.0880 | tpr=0.7239 | fpr=0.9236 | 7859.8 samples/s | 30.7 steps/s
[Step= 400] | Loss=7.24190 | acc=0.0881 | tpr=0.7270 | fpr=0.9235 | 7860.2 samples/s | 30.7 steps/s
[Step= 450] | Loss=7.24607 | acc=0.0880 | tpr=0.7332 | fpr=0.9237 | 7737.4 samples/s | 30.2 steps/s
[Step= 500] | Loss=7.25116 | acc=0.0880 | tpr=0.7335 | fpr=0.9237 | 7939.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=7.25610 | acc=0.0877 | tpr=0.7350 | fpr=0.9240 | 14385.2 samples/s | 56.2 steps/s
Avg test loss: 7.25876, Avg test acc: 0.08772, Avg tpr: 0.73494, Avg fpr: 0.92405, total FA: 128302

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.42554 | acc=0.1225 | tpr=0.5752 | fpr=0.8856 | 5033.9 samples/s | 19.7 steps/s
[Step= 100] | Loss=4.39577 | acc=0.1240 | tpr=0.5608 | fpr=0.8842 | 7090.2 samples/s | 27.7 steps/s
[Step= 150] | Loss=4.39334 | acc=0.1241 | tpr=0.5461 | fpr=0.8837 | 7316.5 samples/s | 28.6 steps/s
[Step= 200] | Loss=4.38157 | acc=0.1247 | tpr=0.5432 | fpr=0.8829 | 7955.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=4.38400 | acc=0.1245 | tpr=0.5441 | fpr=0.8831 | 7621.0 samples/s | 29.8 steps/s
[Step= 300] | Loss=4.37636 | acc=0.1245 | tpr=0.5491 | fpr=0.8832 | 8010.0 samples/s | 31.3 steps/s
[Step= 350] | Loss=4.36755 | acc=0.1245 | tpr=0.5523 | fpr=0.8833 | 7778.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=4.36488 | acc=0.1248 | tpr=0.5531 | fpr=0.8830 | 7972.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=4.36432 | acc=0.1249 | tpr=0.5492 | fpr=0.8828 | 7781.3 samples/s | 30.4 steps/s
[Step= 500] | Loss=4.36651 | acc=0.1250 | tpr=0.5458 | fpr=0.8826 | 8061.3 samples/s | 31.5 steps/s
[Step= 550] | Loss=4.36650 | acc=0.1247 | tpr=0.5499 | fpr=0.8830 | 14216.4 samples/s | 55.5 steps/s
Avg test loss: 4.36917, Avg test acc: 0.12469, Avg tpr: 0.55071, Avg fpr: 0.88306, total FA: 122611

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.78564 | acc=0.0725 | tpr=0.5929 | fpr=0.9369 | 4854.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.77419 | acc=0.0743 | tpr=0.5608 | fpr=0.9348 | 6982.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.77417 | acc=0.0753 | tpr=0.5749 | fpr=0.9339 | 7919.1 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.76239 | acc=0.0753 | tpr=0.5760 | fpr=0.9339 | 7713.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=6.77329 | acc=0.0758 | tpr=0.5799 | fpr=0.9334 | 8213.3 samples/s | 32.1 steps/s
[Step= 300] | Loss=6.77490 | acc=0.0764 | tpr=0.5869 | fpr=0.9329 | 7868.6 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.76945 | acc=0.0765 | tpr=0.5848 | fpr=0.9328 | 8318.4 samples/s | 32.5 steps/s
[Step= 400] | Loss=6.76488 | acc=0.0769 | tpr=0.5832 | fpr=0.9323 | 7327.9 samples/s | 28.6 steps/s
[Step= 450] | Loss=6.76572 | acc=0.0771 | tpr=0.5833 | fpr=0.9321 | 7945.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.76935 | acc=0.0770 | tpr=0.5841 | fpr=0.9321 | 8221.4 samples/s | 32.1 steps/s
[Step= 550] | Loss=6.77282 | acc=0.0768 | tpr=0.5798 | fpr=0.9324 | 13927.6 samples/s | 54.4 steps/s
Avg test loss: 6.77461, Avg test acc: 0.07675, Avg tpr: 0.58043, Avg fpr: 0.93240, total FA: 129462

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.52845 | acc=0.1037 | tpr=0.7035 | fpr=0.9070 | 4936.8 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.48447 | acc=0.1063 | tpr=0.7079 | fpr=0.9049 | 7410.9 samples/s | 28.9 steps/s
[Step= 150] | Loss=6.48283 | acc=0.1067 | tpr=0.7104 | fpr=0.9044 | 7386.4 samples/s | 28.9 steps/s
[Step= 200] | Loss=6.48171 | acc=0.1071 | tpr=0.7049 | fpr=0.9038 | 7838.0 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.49525 | acc=0.1068 | tpr=0.7031 | fpr=0.9041 | 8017.5 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.49130 | acc=0.1071 | tpr=0.7105 | fpr=0.9039 | 7707.2 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.49011 | acc=0.1071 | tpr=0.7095 | fpr=0.9038 | 7803.0 samples/s | 30.5 steps/s
[Step= 400] | Loss=6.49199 | acc=0.1073 | tpr=0.7155 | fpr=0.9038 | 8074.7 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.49613 | acc=0.1073 | tpr=0.7171 | fpr=0.9038 | 7420.4 samples/s | 29.0 steps/s
[Step= 500] | Loss=6.49846 | acc=0.1068 | tpr=0.7123 | fpr=0.9041 | 8125.0 samples/s | 31.7 steps/s
[Step= 550] | Loss=6.49692 | acc=0.1068 | tpr=0.7131 | fpr=0.9042 | 14471.0 samples/s | 56.5 steps/s
Avg test loss: 6.49864, Avg test acc: 0.10667, Avg tpr: 0.71276, Avg fpr: 0.90435, total FA: 125567

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.61314 | acc=0.0907 | tpr=0.6903 | fpr=0.9201 | 4912.8 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.60325 | acc=0.0898 | tpr=0.6780 | fpr=0.9212 | 6829.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.60921 | acc=0.0901 | tpr=0.6585 | fpr=0.9204 | 7769.4 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.60632 | acc=0.0903 | tpr=0.6514 | fpr=0.9199 | 8046.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.61198 | acc=0.0902 | tpr=0.6568 | fpr=0.9201 | 7913.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.61274 | acc=0.0901 | tpr=0.6604 | fpr=0.9203 | 7908.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.60678 | acc=0.0901 | tpr=0.6662 | fpr=0.9204 | 7599.8 samples/s | 29.7 steps/s
[Step= 400] | Loss=6.60518 | acc=0.0903 | tpr=0.6707 | fpr=0.9203 | 8044.1 samples/s | 31.4 steps/s
[Step= 450] | Loss=6.60524 | acc=0.0903 | tpr=0.6753 | fpr=0.9203 | 8038.9 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.60817 | acc=0.0898 | tpr=0.6696 | fpr=0.9207 | 7674.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.61022 | acc=0.0897 | tpr=0.6721 | fpr=0.9209 | 14250.3 samples/s | 55.7 steps/s
Avg test loss: 6.61168, Avg test acc: 0.08961, Avg tpr: 0.67195, Avg fpr: 0.92097, total FA: 127875

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10867 | acc=0.9795 | tpr=0.8894 | fpr=0.0188 | 4851.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10967 | acc=0.9798 | tpr=0.9147 | fpr=0.0190 | 6895.7 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.11431 | acc=0.9791 | tpr=0.9164 | fpr=0.0197 | 7879.3 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.11645 | acc=0.9791 | tpr=0.9213 | fpr=0.0199 | 7978.3 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.11443 | acc=0.9792 | tpr=0.9153 | fpr=0.0197 | 7555.7 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.11697 | acc=0.9787 | tpr=0.9105 | fpr=0.0201 | 8222.9 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.11811 | acc=0.9787 | tpr=0.9136 | fpr=0.0202 | 7999.1 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.11965 | acc=0.9784 | tpr=0.9086 | fpr=0.0203 | 7583.2 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.12192 | acc=0.9780 | tpr=0.9046 | fpr=0.0206 | 8058.8 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.12081 | acc=0.9782 | tpr=0.9075 | fpr=0.0206 | 7933.2 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.12017 | acc=0.9783 | tpr=0.9077 | fpr=0.0204 | 14265.0 samples/s | 55.7 steps/s
Avg test loss: 0.11988, Avg test acc: 0.97835, Avg tpr: 0.90808, Avg fpr: 0.02037, total FA: 2828

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10913 | acc=0.9824 | tpr=0.8982 | fpr=0.0161 | 5000.9 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.11227 | acc=0.9821 | tpr=0.8955 | fpr=0.0163 | 6862.6 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.11554 | acc=0.9815 | tpr=0.8991 | fpr=0.0170 | 7603.3 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.11918 | acc=0.9813 | tpr=0.9049 | fpr=0.0173 | 7944.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.11696 | acc=0.9814 | tpr=0.9004 | fpr=0.0171 | 7686.6 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.12004 | acc=0.9810 | tpr=0.8975 | fpr=0.0174 | 8008.9 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.12006 | acc=0.9810 | tpr=0.9004 | fpr=0.0175 | 7864.0 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.12151 | acc=0.9807 | tpr=0.8950 | fpr=0.0178 | 7772.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.12395 | acc=0.9804 | tpr=0.8944 | fpr=0.0180 | 7967.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12311 | acc=0.9805 | tpr=0.8965 | fpr=0.0180 | 7840.4 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12260 | acc=0.9807 | tpr=0.8953 | fpr=0.0178 | 14468.3 samples/s | 56.5 steps/s
Avg test loss: 0.12244, Avg test acc: 0.98070, Avg tpr: 0.89540, Avg fpr: 0.01775, total FA: 2465

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10566 | acc=0.9799 | tpr=0.9602 | fpr=0.0197 | 4679.7 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10723 | acc=0.9795 | tpr=0.9467 | fpr=0.0199 | 7908.1 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.11125 | acc=0.9789 | tpr=0.9496 | fpr=0.0206 | 7567.9 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.11359 | acc=0.9790 | tpr=0.9519 | fpr=0.0205 | 7639.0 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.11168 | acc=0.9789 | tpr=0.9520 | fpr=0.0206 | 7584.5 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.11379 | acc=0.9786 | tpr=0.9469 | fpr=0.0208 | 8345.8 samples/s | 32.6 steps/s
[Step= 350] | Loss=0.11414 | acc=0.9786 | tpr=0.9487 | fpr=0.0209 | 7772.0 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.11553 | acc=0.9784 | tpr=0.9458 | fpr=0.0210 | 7800.1 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.11737 | acc=0.9783 | tpr=0.9430 | fpr=0.0211 | 8098.9 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11656 | acc=0.9783 | tpr=0.9445 | fpr=0.0211 | 7676.3 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.11615 | acc=0.9784 | tpr=0.9447 | fpr=0.0210 | 14592.8 samples/s | 57.0 steps/s
Avg test loss: 0.11618, Avg test acc: 0.97843, Avg tpr: 0.94453, Avg fpr: 0.02096, total FA: 2910

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10178 | acc=0.9819 | tpr=0.9336 | fpr=0.0173 | 4859.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10787 | acc=0.9805 | tpr=0.9275 | fpr=0.0185 | 7232.9 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.11176 | acc=0.9798 | tpr=0.9323 | fpr=0.0193 | 7517.3 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.11452 | acc=0.9799 | tpr=0.9366 | fpr=0.0193 | 7812.1 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.11257 | acc=0.9802 | tpr=0.9354 | fpr=0.0190 | 7959.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11525 | acc=0.9798 | tpr=0.9324 | fpr=0.0193 | 8003.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.11594 | acc=0.9796 | tpr=0.9349 | fpr=0.0196 | 7963.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.11674 | acc=0.9795 | tpr=0.9322 | fpr=0.0196 | 7728.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.11897 | acc=0.9792 | tpr=0.9304 | fpr=0.0199 | 8438.5 samples/s | 33.0 steps/s
[Step= 500] | Loss=0.11817 | acc=0.9793 | tpr=0.9330 | fpr=0.0198 | 7332.3 samples/s | 28.6 steps/s
[Step= 550] | Loss=0.11763 | acc=0.9795 | tpr=0.9331 | fpr=0.0196 | 14605.4 samples/s | 57.1 steps/s
Avg test loss: 0.11760, Avg test acc: 0.97953, Avg tpr: 0.93304, Avg fpr: 0.01963, total FA: 2725

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12047 | acc=0.9808 | tpr=0.9027 | fpr=0.0178 | 4523.6 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.12633 | acc=0.9798 | tpr=0.9126 | fpr=0.0189 | 8168.3 samples/s | 31.9 steps/s
[Step= 150] | Loss=0.12948 | acc=0.9792 | tpr=0.9179 | fpr=0.0197 | 7527.0 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.13307 | acc=0.9788 | tpr=0.9224 | fpr=0.0202 | 8243.6 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.13132 | acc=0.9789 | tpr=0.9170 | fpr=0.0199 | 7752.4 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.13331 | acc=0.9787 | tpr=0.9135 | fpr=0.0201 | 7740.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.13336 | acc=0.9786 | tpr=0.9167 | fpr=0.0202 | 8099.1 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.13506 | acc=0.9785 | tpr=0.9136 | fpr=0.0203 | 7610.1 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.13814 | acc=0.9782 | tpr=0.9109 | fpr=0.0205 | 7892.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.13744 | acc=0.9782 | tpr=0.9106 | fpr=0.0205 | 7915.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.13676 | acc=0.9784 | tpr=0.9093 | fpr=0.0204 | 14088.5 samples/s | 55.0 steps/s
Avg test loss: 0.13651, Avg test acc: 0.97837, Avg tpr: 0.90927, Avg fpr: 0.02037, total FA: 2829

server round 10/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=97.5] | Loss=0.00557 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.402 | L2-Norm(final)=8.353 | 5767.2 samples/s | 90.1 steps/s
[Step=20050 Epoch=97.8] | Loss=0.01022 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.394 | L2-Norm(final)=8.362 | 4278.7 samples/s | 66.9 steps/s
[Step=20100 Epoch=98.0] | Loss=0.01010 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.389 | L2-Norm(final)=8.375 | 4993.7 samples/s | 78.0 steps/s
[Step=20150 Epoch=98.3] | Loss=0.00976 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.385 | L2-Norm(final)=8.388 | 5100.2 samples/s | 79.7 steps/s
[Step=20200 Epoch=98.5] | Loss=0.00924 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.380 | L2-Norm(final)=8.401 | 7742.9 samples/s | 121.0 steps/s
[Step=20250 Epoch=98.7] | Loss=0.00870 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.375 | L2-Norm(final)=8.414 | 2254.4 samples/s | 35.2 steps/s
[Step=20300 Epoch=99.0] | Loss=0.00819 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.370 | L2-Norm(final)=8.427 | 4997.7 samples/s | 78.1 steps/s
[Step=20350 Epoch=99.2] | Loss=0.00814 | Reg=0.00546 | acc=0.9688 | L2-Norm=23.364 | L2-Norm(final)=8.440 | 4906.4 samples/s | 76.7 steps/s
[Step=20400 Epoch=99.5] | Loss=0.00796 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.358 | L2-Norm(final)=8.452 | 7026.9 samples/s | 109.8 steps/s
[Step=20450 Epoch=99.7] | Loss=0.00792 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.353 | L2-Norm(final)=8.464 | 2319.1 samples/s | 36.2 steps/s
[Step=20500 Epoch=100.0] | Loss=0.00769 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.348 | L2-Norm(final)=8.477 | 4932.3 samples/s | 77.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=100.0] | Loss=0.00155 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.300 | L2-Norm(final)=8.600 | 5307.2 samples/s | 82.9 steps/s
[Step=20550 Epoch=100.2] | Loss=0.00640 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.296 | L2-Norm(final)=8.612 | 4051.6 samples/s | 63.3 steps/s
[Step=20600 Epoch=100.4] | Loss=0.00784 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.294 | L2-Norm(final)=8.619 | 4452.6 samples/s | 69.6 steps/s
[Step=20650 Epoch=100.7] | Loss=0.00842 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.291 | L2-Norm(final)=8.624 | 4457.0 samples/s | 69.6 steps/s
[Step=20700 Epoch=100.9] | Loss=0.00932 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.289 | L2-Norm(final)=8.627 | 6576.6 samples/s | 102.8 steps/s
[Step=20750 Epoch=101.2] | Loss=0.00911 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.287 | L2-Norm(final)=8.632 | 2094.5 samples/s | 32.7 steps/s
[Step=20800 Epoch=101.4] | Loss=0.00904 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.284 | L2-Norm(final)=8.635 | 4619.6 samples/s | 72.2 steps/s
[Step=20850 Epoch=101.7] | Loss=0.00886 | Reg=0.00542 | acc=0.9844 | L2-Norm=23.281 | L2-Norm(final)=8.639 | 4292.4 samples/s | 67.1 steps/s
[Step=20900 Epoch=101.9] | Loss=0.00904 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.276 | L2-Norm(final)=8.642 | 5933.2 samples/s | 92.7 steps/s
[Step=20950 Epoch=102.2] | Loss=0.00852 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.271 | L2-Norm(final)=8.645 | 2188.6 samples/s | 34.2 steps/s
[Step=21000 Epoch=102.4] | Loss=0.00811 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.265 | L2-Norm(final)=8.649 | 4411.3 samples/s | 68.9 steps/s
[Step=21050 Epoch=102.6] | Loss=0.00795 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.258 | L2-Norm(final)=8.652 | 4464.9 samples/s | 69.8 steps/s
[Step=21100 Epoch=102.9] | Loss=0.00762 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.250 | L2-Norm(final)=8.656 | 5436.4 samples/s | 84.9 steps/s
[Step=21150 Epoch=103.1] | Loss=0.00738 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.241 | L2-Norm(final)=8.659 | 2267.1 samples/s | 35.4 steps/s
[Step=21200 Epoch=103.4] | Loss=0.00712 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.232 | L2-Norm(final)=8.662 | 4503.3 samples/s | 70.4 steps/s
[Step=21250 Epoch=103.6] | Loss=0.00686 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.223 | L2-Norm(final)=8.665 | 4428.7 samples/s | 69.2 steps/s
[Step=21300 Epoch=103.9] | Loss=0.00687 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.212 | L2-Norm(final)=8.667 | 5008.8 samples/s | 78.3 steps/s
[Step=21350 Epoch=104.1] | Loss=0.00673 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.201 | L2-Norm(final)=8.669 | 2338.6 samples/s | 36.5 steps/s
[Step=21400 Epoch=104.4] | Loss=0.00663 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.190 | L2-Norm(final)=8.671 | 4550.2 samples/s | 71.1 steps/s
[Step=21450 Epoch=104.6] | Loss=0.00655 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.178 | L2-Norm(final)=8.673 | 4554.4 samples/s | 71.2 steps/s
[Step=21500 Epoch=104.8] | Loss=0.00639 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.166 | L2-Norm(final)=8.674 | 4501.2 samples/s | 70.3 steps/s
[Step=21550 Epoch=105.1] | Loss=0.00622 | Reg=0.00536 | acc=1.0000 | L2-Norm=23.153 | L2-Norm(final)=8.676 | 2436.7 samples/s | 38.1 steps/s
[Step=21600 Epoch=105.3] | Loss=0.00605 | Reg=0.00535 | acc=1.0000 | L2-Norm=23.140 | L2-Norm(final)=8.678 | 4521.3 samples/s | 70.6 steps/s
[Step=21650 Epoch=105.6] | Loss=0.00593 | Reg=0.00535 | acc=1.0000 | L2-Norm=23.127 | L2-Norm(final)=8.680 | 4370.4 samples/s | 68.3 steps/s
[Step=21700 Epoch=105.8] | Loss=0.00587 | Reg=0.00534 | acc=1.0000 | L2-Norm=23.113 | L2-Norm(final)=8.682 | 4507.1 samples/s | 70.4 steps/s
[Step=21750 Epoch=106.1] | Loss=0.00585 | Reg=0.00534 | acc=1.0000 | L2-Norm=23.100 | L2-Norm(final)=8.684 | 2441.8 samples/s | 38.2 steps/s
[Step=21800 Epoch=106.3] | Loss=0.00577 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.086 | L2-Norm(final)=8.685 | 4393.1 samples/s | 68.6 steps/s
[Step=21850 Epoch=106.5] | Loss=0.00566 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.072 | L2-Norm(final)=8.687 | 4505.7 samples/s | 70.4 steps/s
[Step=21900 Epoch=106.8] | Loss=0.00562 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.058 | L2-Norm(final)=8.689 | 4444.9 samples/s | 69.5 steps/s
[Step=21950 Epoch=107.0] | Loss=0.00554 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.044 | L2-Norm(final)=8.690 | 2491.2 samples/s | 38.9 steps/s
[Step=22000 Epoch=107.3] | Loss=0.00548 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.030 | L2-Norm(final)=8.692 | 4390.7 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step22000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=97.6] | Loss=0.04502 | Reg=0.00558 | acc=0.9688 | L2-Norm=23.624 | L2-Norm(final)=8.427 | 4992.3 samples/s | 78.0 steps/s
[Step=20050 Epoch=97.8] | Loss=0.01101 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.624 | L2-Norm(final)=8.436 | 4861.9 samples/s | 76.0 steps/s
[Step=20100 Epoch=98.1] | Loss=0.00997 | Reg=0.00558 | acc=0.9844 | L2-Norm=23.620 | L2-Norm(final)=8.447 | 4997.4 samples/s | 78.1 steps/s
[Step=20150 Epoch=98.3] | Loss=0.01024 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.615 | L2-Norm(final)=8.459 | 5058.0 samples/s | 79.0 steps/s
[Step=20200 Epoch=98.6] | Loss=0.00960 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.610 | L2-Norm(final)=8.473 | 7862.2 samples/s | 122.8 steps/s
[Step=20250 Epoch=98.8] | Loss=0.00914 | Reg=0.00557 | acc=0.9844 | L2-Norm=23.605 | L2-Norm(final)=8.485 | 2224.9 samples/s | 34.8 steps/s
[Step=20300 Epoch=99.1] | Loss=0.00856 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.599 | L2-Norm(final)=8.498 | 4981.2 samples/s | 77.8 steps/s
[Step=20350 Epoch=99.3] | Loss=0.00827 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.594 | L2-Norm(final)=8.510 | 5069.4 samples/s | 79.2 steps/s
[Step=20400 Epoch=99.5] | Loss=0.00816 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.588 | L2-Norm(final)=8.522 | 6815.7 samples/s | 106.5 steps/s
[Step=20450 Epoch=99.8] | Loss=0.00783 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.583 | L2-Norm(final)=8.534 | 2247.6 samples/s | 35.1 steps/s
[Step=20500 Epoch=100.0] | Loss=0.00766 | Reg=0.00556 | acc=0.9844 | L2-Norm=23.578 | L2-Norm(final)=8.546 | 4885.1 samples/s | 76.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=100.0] | Loss=0.02569 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.525 | L2-Norm(final)=8.665 | 5790.6 samples/s | 90.5 steps/s
[Step=20550 Epoch=100.3] | Loss=0.00531 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.520 | L2-Norm(final)=8.677 | 3767.5 samples/s | 58.9 steps/s
[Step=20600 Epoch=100.5] | Loss=0.00697 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.516 | L2-Norm(final)=8.685 | 4396.3 samples/s | 68.7 steps/s
[Step=20650 Epoch=100.8] | Loss=0.00823 | Reg=0.00553 | acc=0.9688 | L2-Norm=23.513 | L2-Norm(final)=8.691 | 4228.0 samples/s | 66.1 steps/s
[Step=20700 Epoch=101.0] | Loss=0.00783 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.509 | L2-Norm(final)=8.696 | 6298.8 samples/s | 98.4 steps/s
[Step=20750 Epoch=101.3] | Loss=0.00815 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.505 | L2-Norm(final)=8.699 | 2059.9 samples/s | 32.2 steps/s
[Step=20800 Epoch=101.5] | Loss=0.00785 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.500 | L2-Norm(final)=8.703 | 4456.8 samples/s | 69.6 steps/s
[Step=20850 Epoch=101.7] | Loss=0.00743 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.494 | L2-Norm(final)=8.707 | 4381.9 samples/s | 68.5 steps/s
[Step=20900 Epoch=102.0] | Loss=0.00716 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.487 | L2-Norm(final)=8.711 | 6026.3 samples/s | 94.2 steps/s
[Step=20950 Epoch=102.2] | Loss=0.00684 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.479 | L2-Norm(final)=8.714 | 2131.2 samples/s | 33.3 steps/s
[Step=21000 Epoch=102.5] | Loss=0.00682 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.470 | L2-Norm(final)=8.718 | 4433.3 samples/s | 69.3 steps/s
[Step=21050 Epoch=102.7] | Loss=0.00669 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.461 | L2-Norm(final)=8.721 | 4484.2 samples/s | 70.1 steps/s
[Step=21100 Epoch=103.0] | Loss=0.00656 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.451 | L2-Norm(final)=8.723 | 5490.8 samples/s | 85.8 steps/s
[Step=21150 Epoch=103.2] | Loss=0.00651 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.441 | L2-Norm(final)=8.726 | 2173.3 samples/s | 34.0 steps/s
[Step=21200 Epoch=103.4] | Loss=0.00635 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.431 | L2-Norm(final)=8.728 | 4569.8 samples/s | 71.4 steps/s
[Step=21250 Epoch=103.7] | Loss=0.00631 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.421 | L2-Norm(final)=8.731 | 4337.7 samples/s | 67.8 steps/s
[Step=21300 Epoch=103.9] | Loss=0.00620 | Reg=0.00548 | acc=0.9844 | L2-Norm=23.410 | L2-Norm(final)=8.733 | 5159.3 samples/s | 80.6 steps/s
[Step=21350 Epoch=104.2] | Loss=0.00605 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.399 | L2-Norm(final)=8.735 | 2266.6 samples/s | 35.4 steps/s
[Step=21400 Epoch=104.4] | Loss=0.00605 | Reg=0.00547 | acc=0.9844 | L2-Norm=23.388 | L2-Norm(final)=8.738 | 4349.7 samples/s | 68.0 steps/s
[Step=21450 Epoch=104.7] | Loss=0.00596 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.376 | L2-Norm(final)=8.740 | 4499.8 samples/s | 70.3 steps/s
[Step=21500 Epoch=104.9] | Loss=0.00575 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.364 | L2-Norm(final)=8.742 | 4727.6 samples/s | 73.9 steps/s
[Step=21550 Epoch=105.2] | Loss=0.00566 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.352 | L2-Norm(final)=8.744 | 2319.4 samples/s | 36.2 steps/s
[Step=21600 Epoch=105.4] | Loss=0.00559 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.340 | L2-Norm(final)=8.746 | 4445.4 samples/s | 69.5 steps/s
[Step=21650 Epoch=105.6] | Loss=0.00544 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.327 | L2-Norm(final)=8.748 | 4504.2 samples/s | 70.4 steps/s
[Step=21700 Epoch=105.9] | Loss=0.00535 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.315 | L2-Norm(final)=8.750 | 4474.0 samples/s | 69.9 steps/s
[Step=21750 Epoch=106.1] | Loss=0.00529 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.302 | L2-Norm(final)=8.752 | 2431.7 samples/s | 38.0 steps/s
[Step=21800 Epoch=106.4] | Loss=0.00528 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.288 | L2-Norm(final)=8.754 | 4345.7 samples/s | 67.9 steps/s
[Step=21850 Epoch=106.6] | Loss=0.00523 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.275 | L2-Norm(final)=8.755 | 4500.8 samples/s | 70.3 steps/s
[Step=21900 Epoch=106.9] | Loss=0.00518 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.261 | L2-Norm(final)=8.757 | 4340.9 samples/s | 67.8 steps/s
[Step=21950 Epoch=107.1] | Loss=0.00510 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.247 | L2-Norm(final)=8.759 | 2467.4 samples/s | 38.6 steps/s
[Step=22000 Epoch=107.3] | Loss=0.00500 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.233 | L2-Norm(final)=8.761 | 4472.8 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step22000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=97.5] | Loss=0.00756 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.652 | L2-Norm(final)=8.854 | 5448.8 samples/s | 85.1 steps/s
[Step=20050 Epoch=97.7] | Loss=0.01221 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.647 | L2-Norm(final)=8.863 | 4251.3 samples/s | 66.4 steps/s
[Step=20100 Epoch=97.9] | Loss=0.01160 | Reg=0.00559 | acc=1.0000 | L2-Norm=23.643 | L2-Norm(final)=8.875 | 4978.3 samples/s | 77.8 steps/s
[Step=20150 Epoch=98.2] | Loss=0.01102 | Reg=0.00559 | acc=0.9844 | L2-Norm=23.638 | L2-Norm(final)=8.888 | 5025.4 samples/s | 78.5 steps/s
[Step=20200 Epoch=98.4] | Loss=0.01067 | Reg=0.00559 | acc=0.9688 | L2-Norm=23.634 | L2-Norm(final)=8.901 | 7644.9 samples/s | 119.5 steps/s
[Step=20250 Epoch=98.7] | Loss=0.01047 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.629 | L2-Norm(final)=8.913 | 2181.0 samples/s | 34.1 steps/s
[Step=20300 Epoch=98.9] | Loss=0.01004 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.625 | L2-Norm(final)=8.926 | 5054.1 samples/s | 79.0 steps/s
[Step=20350 Epoch=99.2] | Loss=0.00951 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.620 | L2-Norm(final)=8.938 | 4927.7 samples/s | 77.0 steps/s
[Step=20400 Epoch=99.4] | Loss=0.00934 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.615 | L2-Norm(final)=8.950 | 6872.9 samples/s | 107.4 steps/s
[Step=20450 Epoch=99.6] | Loss=0.00887 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.610 | L2-Norm(final)=8.962 | 2278.9 samples/s | 35.6 steps/s
[Step=20500 Epoch=99.9] | Loss=0.00860 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.605 | L2-Norm(final)=8.974 | 4978.2 samples/s | 77.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=99.9] | Loss=0.00253 | Reg=0.00555 | acc=1.0000 | L2-Norm=23.553 | L2-Norm(final)=9.096 | 5240.3 samples/s | 81.9 steps/s
[Step=20550 Epoch=100.1] | Loss=0.00759 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.547 | L2-Norm(final)=9.106 | 4004.5 samples/s | 62.6 steps/s
[Step=20600 Epoch=100.4] | Loss=0.00806 | Reg=0.00554 | acc=0.9844 | L2-Norm=23.543 | L2-Norm(final)=9.114 | 4436.6 samples/s | 69.3 steps/s
[Step=20650 Epoch=100.6] | Loss=0.00885 | Reg=0.00554 | acc=0.9844 | L2-Norm=23.539 | L2-Norm(final)=9.121 | 4444.6 samples/s | 69.4 steps/s
[Step=20700 Epoch=100.9] | Loss=0.00920 | Reg=0.00554 | acc=0.9688 | L2-Norm=23.534 | L2-Norm(final)=9.126 | 6388.1 samples/s | 99.8 steps/s
[Step=20750 Epoch=101.1] | Loss=0.00833 | Reg=0.00554 | acc=1.0000 | L2-Norm=23.529 | L2-Norm(final)=9.131 | 2082.3 samples/s | 32.5 steps/s
[Step=20800 Epoch=101.3] | Loss=0.00790 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.522 | L2-Norm(final)=9.136 | 4401.3 samples/s | 68.8 steps/s
[Step=20850 Epoch=101.6] | Loss=0.00789 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.515 | L2-Norm(final)=9.139 | 4366.5 samples/s | 68.2 steps/s
[Step=20900 Epoch=101.8] | Loss=0.00780 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.507 | L2-Norm(final)=9.143 | 5832.5 samples/s | 91.1 steps/s
[Step=20950 Epoch=102.1] | Loss=0.00746 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.499 | L2-Norm(final)=9.146 | 2142.4 samples/s | 33.5 steps/s
[Step=21000 Epoch=102.3] | Loss=0.00720 | Reg=0.00552 | acc=0.9844 | L2-Norm=23.490 | L2-Norm(final)=9.149 | 4436.5 samples/s | 69.3 steps/s
[Step=21050 Epoch=102.6] | Loss=0.00708 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.480 | L2-Norm(final)=9.152 | 4415.9 samples/s | 69.0 steps/s
[Step=21100 Epoch=102.8] | Loss=0.00699 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.470 | L2-Norm(final)=9.155 | 5343.3 samples/s | 83.5 steps/s
[Step=21150 Epoch=103.1] | Loss=0.00695 | Reg=0.00550 | acc=0.9844 | L2-Norm=23.460 | L2-Norm(final)=9.157 | 2240.7 samples/s | 35.0 steps/s
[Step=21200 Epoch=103.3] | Loss=0.00680 | Reg=0.00550 | acc=0.9531 | L2-Norm=23.450 | L2-Norm(final)=9.159 | 4386.4 samples/s | 68.5 steps/s
[Step=21250 Epoch=103.5] | Loss=0.00664 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.439 | L2-Norm(final)=9.162 | 4520.8 samples/s | 70.6 steps/s
[Step=21300 Epoch=103.8] | Loss=0.00652 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.428 | L2-Norm(final)=9.164 | 4809.1 samples/s | 75.1 steps/s
[Step=21350 Epoch=104.0] | Loss=0.00632 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.418 | L2-Norm(final)=9.167 | 2275.1 samples/s | 35.5 steps/s
[Step=21400 Epoch=104.3] | Loss=0.00617 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.406 | L2-Norm(final)=9.169 | 4521.7 samples/s | 70.7 steps/s
[Step=21450 Epoch=104.5] | Loss=0.00602 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.395 | L2-Norm(final)=9.171 | 4396.6 samples/s | 68.7 steps/s
[Step=21500 Epoch=104.8] | Loss=0.00606 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.383 | L2-Norm(final)=9.174 | 4432.7 samples/s | 69.3 steps/s
[Step=21550 Epoch=105.0] | Loss=0.00608 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.371 | L2-Norm(final)=9.176 | 2384.2 samples/s | 37.3 steps/s
[Step=21600 Epoch=105.2] | Loss=0.00600 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.359 | L2-Norm(final)=9.178 | 4424.8 samples/s | 69.1 steps/s
[Step=21650 Epoch=105.5] | Loss=0.00589 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.347 | L2-Norm(final)=9.180 | 4416.3 samples/s | 69.0 steps/s
[Step=21700 Epoch=105.7] | Loss=0.00587 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.334 | L2-Norm(final)=9.182 | 4433.6 samples/s | 69.3 steps/s
[Step=21750 Epoch=106.0] | Loss=0.00575 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.322 | L2-Norm(final)=9.184 | 2399.6 samples/s | 37.5 steps/s
[Step=21800 Epoch=106.2] | Loss=0.00566 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.309 | L2-Norm(final)=9.186 | 4495.2 samples/s | 70.2 steps/s
[Step=21850 Epoch=106.5] | Loss=0.00559 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.296 | L2-Norm(final)=9.188 | 4385.5 samples/s | 68.5 steps/s
[Step=21900 Epoch=106.7] | Loss=0.00555 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.283 | L2-Norm(final)=9.191 | 4468.0 samples/s | 69.8 steps/s
[Step=21950 Epoch=107.0] | Loss=0.00545 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.269 | L2-Norm(final)=9.193 | 2441.2 samples/s | 38.1 steps/s
[Step=22000 Epoch=107.2] | Loss=0.00535 | Reg=0.00541 | acc=0.9844 | L2-Norm=23.255 | L2-Norm(final)=9.195 | 4467.3 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step22000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=97.5] | Loss=0.01963 | Reg=0.00558 | acc=0.9844 | L2-Norm=23.627 | L2-Norm(final)=8.608 | 5356.7 samples/s | 83.7 steps/s
[Step=20050 Epoch=97.8] | Loss=0.01095 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.622 | L2-Norm(final)=8.618 | 4596.5 samples/s | 71.8 steps/s
[Step=20100 Epoch=98.0] | Loss=0.01072 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.617 | L2-Norm(final)=8.631 | 4978.5 samples/s | 77.8 steps/s
[Step=20150 Epoch=98.3] | Loss=0.00985 | Reg=0.00558 | acc=1.0000 | L2-Norm=23.613 | L2-Norm(final)=8.644 | 4957.6 samples/s | 77.5 steps/s
[Step=20200 Epoch=98.5] | Loss=0.00991 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.608 | L2-Norm(final)=8.658 | 7777.0 samples/s | 121.5 steps/s
[Step=20250 Epoch=98.8] | Loss=0.00934 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.603 | L2-Norm(final)=8.670 | 2186.4 samples/s | 34.2 steps/s
[Step=20300 Epoch=99.0] | Loss=0.00878 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.598 | L2-Norm(final)=8.683 | 4994.0 samples/s | 78.0 steps/s
[Step=20350 Epoch=99.2] | Loss=0.00857 | Reg=0.00557 | acc=1.0000 | L2-Norm=23.592 | L2-Norm(final)=8.696 | 4991.7 samples/s | 78.0 steps/s
[Step=20400 Epoch=99.5] | Loss=0.00840 | Reg=0.00556 | acc=0.9844 | L2-Norm=23.587 | L2-Norm(final)=8.708 | 6946.9 samples/s | 108.5 steps/s
[Step=20450 Epoch=99.7] | Loss=0.00808 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.582 | L2-Norm(final)=8.721 | 2243.3 samples/s | 35.1 steps/s
[Step=20500 Epoch=100.0] | Loss=0.00787 | Reg=0.00556 | acc=1.0000 | L2-Norm=23.577 | L2-Norm(final)=8.733 | 4927.2 samples/s | 77.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=100.0] | Loss=0.00391 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.525 | L2-Norm(final)=8.860 | 5565.4 samples/s | 87.0 steps/s
[Step=20550 Epoch=100.2] | Loss=0.00597 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.521 | L2-Norm(final)=8.870 | 3873.5 samples/s | 60.5 steps/s
[Step=20600 Epoch=100.5] | Loss=0.00603 | Reg=0.00553 | acc=0.9844 | L2-Norm=23.515 | L2-Norm(final)=8.878 | 4423.5 samples/s | 69.1 steps/s
[Step=20650 Epoch=100.7] | Loss=0.00688 | Reg=0.00553 | acc=1.0000 | L2-Norm=23.510 | L2-Norm(final)=8.886 | 4426.5 samples/s | 69.2 steps/s
[Step=20700 Epoch=100.9] | Loss=0.00704 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.504 | L2-Norm(final)=8.891 | 6500.2 samples/s | 101.6 steps/s
[Step=20750 Epoch=101.2] | Loss=0.00652 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.498 | L2-Norm(final)=8.896 | 2082.5 samples/s | 32.5 steps/s
[Step=20800 Epoch=101.4] | Loss=0.00633 | Reg=0.00552 | acc=1.0000 | L2-Norm=23.491 | L2-Norm(final)=8.900 | 4439.2 samples/s | 69.4 steps/s
[Step=20850 Epoch=101.7] | Loss=0.00670 | Reg=0.00551 | acc=0.9844 | L2-Norm=23.483 | L2-Norm(final)=8.903 | 4310.8 samples/s | 67.4 steps/s
[Step=20900 Epoch=101.9] | Loss=0.00701 | Reg=0.00551 | acc=0.9844 | L2-Norm=23.475 | L2-Norm(final)=8.905 | 5889.2 samples/s | 92.0 steps/s
[Step=20950 Epoch=102.2] | Loss=0.00682 | Reg=0.00551 | acc=1.0000 | L2-Norm=23.467 | L2-Norm(final)=8.907 | 2143.6 samples/s | 33.5 steps/s
[Step=21000 Epoch=102.4] | Loss=0.00664 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.459 | L2-Norm(final)=8.910 | 4444.6 samples/s | 69.4 steps/s
[Step=21050 Epoch=102.7] | Loss=0.00649 | Reg=0.00550 | acc=1.0000 | L2-Norm=23.450 | L2-Norm(final)=8.912 | 4417.8 samples/s | 69.0 steps/s
[Step=21100 Epoch=102.9] | Loss=0.00636 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.440 | L2-Norm(final)=8.915 | 5388.9 samples/s | 84.2 steps/s
[Step=21150 Epoch=103.1] | Loss=0.00634 | Reg=0.00549 | acc=1.0000 | L2-Norm=23.430 | L2-Norm(final)=8.917 | 2201.5 samples/s | 34.4 steps/s
[Step=21200 Epoch=103.4] | Loss=0.00619 | Reg=0.00549 | acc=0.9844 | L2-Norm=23.420 | L2-Norm(final)=8.919 | 4430.4 samples/s | 69.2 steps/s
[Step=21250 Epoch=103.6] | Loss=0.00606 | Reg=0.00548 | acc=1.0000 | L2-Norm=23.410 | L2-Norm(final)=8.921 | 4424.0 samples/s | 69.1 steps/s
[Step=21300 Epoch=103.9] | Loss=0.00606 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.398 | L2-Norm(final)=8.923 | 4915.6 samples/s | 76.8 steps/s
[Step=21350 Epoch=104.1] | Loss=0.00591 | Reg=0.00547 | acc=1.0000 | L2-Norm=23.387 | L2-Norm(final)=8.925 | 2315.2 samples/s | 36.2 steps/s
[Step=21400 Epoch=104.4] | Loss=0.00572 | Reg=0.00546 | acc=1.0000 | L2-Norm=23.375 | L2-Norm(final)=8.927 | 4392.5 samples/s | 68.6 steps/s
[Step=21450 Epoch=104.6] | Loss=0.00556 | Reg=0.00546 | acc=0.9844 | L2-Norm=23.363 | L2-Norm(final)=8.929 | 4375.3 samples/s | 68.4 steps/s
[Step=21500 Epoch=104.8] | Loss=0.00547 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.351 | L2-Norm(final)=8.931 | 4587.4 samples/s | 71.7 steps/s
[Step=21550 Epoch=105.1] | Loss=0.00539 | Reg=0.00545 | acc=1.0000 | L2-Norm=23.339 | L2-Norm(final)=8.933 | 2399.9 samples/s | 37.5 steps/s
[Step=21600 Epoch=105.3] | Loss=0.00525 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.326 | L2-Norm(final)=8.935 | 4403.9 samples/s | 68.8 steps/s
[Step=21650 Epoch=105.6] | Loss=0.00526 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.313 | L2-Norm(final)=8.937 | 4446.1 samples/s | 69.5 steps/s
[Step=21700 Epoch=105.8] | Loss=0.00524 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.300 | L2-Norm(final)=8.939 | 4423.5 samples/s | 69.1 steps/s
[Step=21750 Epoch=106.1] | Loss=0.00516 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.287 | L2-Norm(final)=8.941 | 2419.1 samples/s | 37.8 steps/s
[Step=21800 Epoch=106.3] | Loss=0.00524 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.274 | L2-Norm(final)=8.943 | 4424.6 samples/s | 69.1 steps/s
[Step=21850 Epoch=106.6] | Loss=0.00514 | Reg=0.00541 | acc=1.0000 | L2-Norm=23.260 | L2-Norm(final)=8.944 | 4451.6 samples/s | 69.6 steps/s
[Step=21900 Epoch=106.8] | Loss=0.00512 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.247 | L2-Norm(final)=8.946 | 4389.6 samples/s | 68.6 steps/s
[Step=21950 Epoch=107.0] | Loss=0.00511 | Reg=0.00540 | acc=1.0000 | L2-Norm=23.234 | L2-Norm(final)=8.947 | 2408.7 samples/s | 37.6 steps/s
[Step=22000 Epoch=107.3] | Loss=0.00510 | Reg=0.00539 | acc=0.9844 | L2-Norm=23.221 | L2-Norm(final)=8.949 | 4462.5 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step22000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=98.1] | Loss=0.01405 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.330 | L2-Norm(final)=8.816 | 5303.5 samples/s | 82.9 steps/s
[Step=20050 Epoch=98.3] | Loss=0.01194 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.326 | L2-Norm(final)=8.824 | 4454.5 samples/s | 69.6 steps/s
[Step=20100 Epoch=98.6] | Loss=0.01103 | Reg=0.00544 | acc=1.0000 | L2-Norm=23.320 | L2-Norm(final)=8.834 | 4997.0 samples/s | 78.1 steps/s
[Step=20150 Epoch=98.8] | Loss=0.00971 | Reg=0.00544 | acc=0.9844 | L2-Norm=23.313 | L2-Norm(final)=8.845 | 4942.8 samples/s | 77.2 steps/s
[Step=20200 Epoch=99.1] | Loss=0.00918 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.308 | L2-Norm(final)=8.856 | 7967.2 samples/s | 124.5 steps/s
[Step=20250 Epoch=99.3] | Loss=0.00855 | Reg=0.00543 | acc=0.9844 | L2-Norm=23.301 | L2-Norm(final)=8.868 | 2179.6 samples/s | 34.1 steps/s
[Step=20300 Epoch=99.5] | Loss=0.00828 | Reg=0.00543 | acc=1.0000 | L2-Norm=23.295 | L2-Norm(final)=8.879 | 4918.1 samples/s | 76.8 steps/s
[Step=20350 Epoch=99.8] | Loss=0.00806 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.289 | L2-Norm(final)=8.890 | 5054.5 samples/s | 79.0 steps/s
[Step=20400 Epoch=100.0] | Loss=0.00788 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.283 | L2-Norm(final)=8.901 | 7391.1 samples/s | 115.5 steps/s
[Step=20450 Epoch=100.3] | Loss=0.00758 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.277 | L2-Norm(final)=8.912 | 2223.2 samples/s | 34.7 steps/s
[Step=20500 Epoch=100.5] | Loss=0.00739 | Reg=0.00542 | acc=1.0000 | L2-Norm=23.271 | L2-Norm(final)=8.922 | 5065.4 samples/s | 79.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=100.5] | Loss=0.00117 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.212 | L2-Norm(final)=9.027 | 5149.3 samples/s | 80.5 steps/s
[Step=20550 Epoch=100.8] | Loss=0.00537 | Reg=0.00539 | acc=1.0000 | L2-Norm=23.206 | L2-Norm(final)=9.036 | 4164.0 samples/s | 65.1 steps/s
[Step=20600 Epoch=101.0] | Loss=0.00648 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.202 | L2-Norm(final)=9.042 | 4489.1 samples/s | 70.1 steps/s
[Step=20650 Epoch=101.3] | Loss=0.00671 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.198 | L2-Norm(final)=9.047 | 4232.0 samples/s | 66.1 steps/s
[Step=20700 Epoch=101.5] | Loss=0.00768 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.194 | L2-Norm(final)=9.051 | 6295.1 samples/s | 98.4 steps/s
[Step=20750 Epoch=101.8] | Loss=0.00743 | Reg=0.00538 | acc=1.0000 | L2-Norm=23.189 | L2-Norm(final)=9.054 | 1933.5 samples/s | 30.2 steps/s
[Step=20800 Epoch=102.0] | Loss=0.00686 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.183 | L2-Norm(final)=9.057 | 4239.8 samples/s | 66.2 steps/s
[Step=20850 Epoch=102.2] | Loss=0.00660 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.176 | L2-Norm(final)=9.061 | 4323.0 samples/s | 67.5 steps/s
[Step=20900 Epoch=102.5] | Loss=0.00666 | Reg=0.00537 | acc=1.0000 | L2-Norm=23.168 | L2-Norm(final)=9.064 | 5802.2 samples/s | 90.7 steps/s
[Step=20950 Epoch=102.7] | Loss=0.00664 | Reg=0.00536 | acc=1.0000 | L2-Norm=23.161 | L2-Norm(final)=9.067 | 1966.5 samples/s | 30.7 steps/s
[Step=21000 Epoch=103.0] | Loss=0.00640 | Reg=0.00536 | acc=1.0000 | L2-Norm=23.153 | L2-Norm(final)=9.069 | 4228.5 samples/s | 66.1 steps/s
[Step=21050 Epoch=103.2] | Loss=0.00628 | Reg=0.00536 | acc=1.0000 | L2-Norm=23.144 | L2-Norm(final)=9.072 | 4280.7 samples/s | 66.9 steps/s
[Step=21100 Epoch=103.5] | Loss=0.00621 | Reg=0.00535 | acc=1.0000 | L2-Norm=23.135 | L2-Norm(final)=9.074 | 5844.0 samples/s | 91.3 steps/s
[Step=21150 Epoch=103.7] | Loss=0.00613 | Reg=0.00535 | acc=0.9844 | L2-Norm=23.127 | L2-Norm(final)=9.077 | 2165.3 samples/s | 33.8 steps/s
[Step=21200 Epoch=104.0] | Loss=0.00601 | Reg=0.00534 | acc=1.0000 | L2-Norm=23.117 | L2-Norm(final)=9.079 | 4454.8 samples/s | 69.6 steps/s
[Step=21250 Epoch=104.2] | Loss=0.00593 | Reg=0.00534 | acc=1.0000 | L2-Norm=23.108 | L2-Norm(final)=9.082 | 4576.1 samples/s | 71.5 steps/s
[Step=21300 Epoch=104.5] | Loss=0.00585 | Reg=0.00534 | acc=0.9844 | L2-Norm=23.098 | L2-Norm(final)=9.084 | 5387.2 samples/s | 84.2 steps/s
[Step=21350 Epoch=104.7] | Loss=0.00577 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.088 | L2-Norm(final)=9.086 | 2234.6 samples/s | 34.9 steps/s
[Step=21400 Epoch=104.9] | Loss=0.00568 | Reg=0.00533 | acc=1.0000 | L2-Norm=23.077 | L2-Norm(final)=9.088 | 4470.7 samples/s | 69.9 steps/s
[Step=21450 Epoch=105.2] | Loss=0.00555 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.066 | L2-Norm(final)=9.090 | 4489.1 samples/s | 70.1 steps/s
[Step=21500 Epoch=105.4] | Loss=0.00548 | Reg=0.00532 | acc=1.0000 | L2-Norm=23.055 | L2-Norm(final)=9.092 | 5157.7 samples/s | 80.6 steps/s
[Step=21550 Epoch=105.7] | Loss=0.00538 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.044 | L2-Norm(final)=9.094 | 2266.8 samples/s | 35.4 steps/s
[Step=21600 Epoch=105.9] | Loss=0.00531 | Reg=0.00531 | acc=1.0000 | L2-Norm=23.033 | L2-Norm(final)=9.096 | 4491.5 samples/s | 70.2 steps/s
[Step=21650 Epoch=106.2] | Loss=0.00528 | Reg=0.00530 | acc=1.0000 | L2-Norm=23.021 | L2-Norm(final)=9.098 | 4459.6 samples/s | 69.7 steps/s
[Step=21700 Epoch=106.4] | Loss=0.00521 | Reg=0.00529 | acc=1.0000 | L2-Norm=23.010 | L2-Norm(final)=9.100 | 4822.5 samples/s | 75.4 steps/s
[Step=21750 Epoch=106.7] | Loss=0.00510 | Reg=0.00529 | acc=0.9844 | L2-Norm=22.998 | L2-Norm(final)=9.103 | 2366.7 samples/s | 37.0 steps/s
[Step=21800 Epoch=106.9] | Loss=0.00506 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.986 | L2-Norm(final)=9.105 | 4422.9 samples/s | 69.1 steps/s
[Step=21850 Epoch=107.1] | Loss=0.00506 | Reg=0.00528 | acc=1.0000 | L2-Norm=22.974 | L2-Norm(final)=9.107 | 4498.2 samples/s | 70.3 steps/s
[Step=21900 Epoch=107.4] | Loss=0.00498 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.962 | L2-Norm(final)=9.108 | 4656.0 samples/s | 72.8 steps/s
[Step=21950 Epoch=107.6] | Loss=0.00494 | Reg=0.00527 | acc=1.0000 | L2-Norm=22.949 | L2-Norm(final)=9.110 | 2383.1 samples/s | 37.2 steps/s
[Step=22000 Epoch=107.9] | Loss=0.00491 | Reg=0.00526 | acc=1.0000 | L2-Norm=22.937 | L2-Norm(final)=9.112 | 4538.1 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step22000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=189.5] | Loss=0.00025 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.711 | L2-Norm(final)=5.248 | 5323.5 samples/s | 83.2 steps/s
[Step=20050 Epoch=190.0] | Loss=0.00189 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.723 | L2-Norm(final)=5.249 | 4171.6 samples/s | 65.2 steps/s
[Step=20100 Epoch=190.5] | Loss=0.00116 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.733 | L2-Norm(final)=5.256 | 7376.1 samples/s | 115.3 steps/s
[Step=20150 Epoch=190.9] | Loss=0.00088 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.739 | L2-Norm(final)=5.263 | 2137.1 samples/s | 33.4 steps/s
[Step=20200 Epoch=191.4] | Loss=0.00071 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.742 | L2-Norm(final)=5.269 | 6512.6 samples/s | 101.8 steps/s
[Step=20250 Epoch=191.9] | Loss=0.00060 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.744 | L2-Norm(final)=5.275 | 2200.9 samples/s | 34.4 steps/s
[Step=20300 Epoch=192.4] | Loss=0.00052 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.746 | L2-Norm(final)=5.280 | 5909.8 samples/s | 92.3 steps/s
[Step=20350 Epoch=192.8] | Loss=0.00048 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.747 | L2-Norm(final)=5.284 | 2283.0 samples/s | 35.7 steps/s
[Step=20400 Epoch=193.3] | Loss=0.00043 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.747 | L2-Norm(final)=5.289 | 5091.9 samples/s | 79.6 steps/s
[Step=20450 Epoch=193.8] | Loss=0.00040 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.747 | L2-Norm(final)=5.293 | 2405.6 samples/s | 37.6 steps/s
[Step=20500 Epoch=194.3] | Loss=0.00037 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.747 | L2-Norm(final)=5.298 | 4929.8 samples/s | 77.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=194.3] | Loss=0.00027 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.742 | L2-Norm(final)=5.338 | 5456.6 samples/s | 85.3 steps/s
[Step=20550 Epoch=194.7] | Loss=0.00010 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.738 | L2-Norm(final)=5.342 | 3833.0 samples/s | 59.9 steps/s
[Step=20600 Epoch=195.2] | Loss=0.00007 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.731 | L2-Norm(final)=5.344 | 6206.8 samples/s | 97.0 steps/s
[Step=20650 Epoch=195.7] | Loss=0.00006 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.722 | L2-Norm(final)=5.346 | 1978.0 samples/s | 30.9 steps/s
[Step=20700 Epoch=196.2] | Loss=0.00004 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.713 | L2-Norm(final)=5.347 | 5630.5 samples/s | 88.0 steps/s
[Step=20750 Epoch=196.6] | Loss=0.00004 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.704 | L2-Norm(final)=5.348 | 2119.6 samples/s | 33.1 steps/s
[Step=20800 Epoch=197.1] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.694 | L2-Norm(final)=5.349 | 5106.0 samples/s | 79.8 steps/s
[Step=20850 Epoch=197.6] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.684 | L2-Norm(final)=5.350 | 2165.4 samples/s | 33.8 steps/s
[Step=20900 Epoch=198.0] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.674 | L2-Norm(final)=5.351 | 4637.9 samples/s | 72.5 steps/s
[Step=20950 Epoch=198.5] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.663 | L2-Norm(final)=5.351 | 2248.1 samples/s | 35.1 steps/s
[Step=21000 Epoch=199.0] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.653 | L2-Norm(final)=5.352 | 4439.5 samples/s | 69.4 steps/s
[Step=21050 Epoch=199.5] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.642 | L2-Norm(final)=5.352 | 2338.5 samples/s | 36.5 steps/s
[Step=21100 Epoch=199.9] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.631 | L2-Norm(final)=5.353 | 4276.6 samples/s | 66.8 steps/s
[Step=21150 Epoch=200.4] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.620 | L2-Norm(final)=5.353 | 2385.5 samples/s | 37.3 steps/s
[Step=21200 Epoch=200.9] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.609 | L2-Norm(final)=5.354 | 4267.1 samples/s | 66.7 steps/s
[Step=21250 Epoch=201.4] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.598 | L2-Norm(final)=5.354 | 2417.2 samples/s | 37.8 steps/s
[Step=21300 Epoch=201.8] | Loss=0.00002 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.587 | L2-Norm(final)=5.355 | 4093.4 samples/s | 64.0 steps/s
[Step=21350 Epoch=202.3] | Loss=0.00002 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.355 | 2445.8 samples/s | 38.2 steps/s
[Step=21400 Epoch=202.8] | Loss=0.00002 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.564 | L2-Norm(final)=5.356 | 4162.8 samples/s | 65.0 steps/s
[Step=21450 Epoch=203.3] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.553 | L2-Norm(final)=5.356 | 6519.8 samples/s | 101.9 steps/s
[Step=21500 Epoch=203.7] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.541 | L2-Norm(final)=5.357 | 2015.8 samples/s | 31.5 steps/s
[Step=21550 Epoch=204.2] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.529 | L2-Norm(final)=5.357 | 5685.4 samples/s | 88.8 steps/s
[Step=21600 Epoch=204.7] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.517 | L2-Norm(final)=5.357 | 2073.1 samples/s | 32.4 steps/s
[Step=21650 Epoch=205.2] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.505 | L2-Norm(final)=5.358 | 5214.4 samples/s | 81.5 steps/s
[Step=21700 Epoch=205.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.493 | L2-Norm(final)=5.358 | 2185.4 samples/s | 34.1 steps/s
[Step=21750 Epoch=206.1] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.481 | L2-Norm(final)=5.359 | 4844.6 samples/s | 75.7 steps/s
[Step=21800 Epoch=206.6] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.468 | L2-Norm(final)=5.359 | 2223.0 samples/s | 34.7 steps/s
[Step=21850 Epoch=207.0] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.456 | L2-Norm(final)=5.359 | 4352.2 samples/s | 68.0 steps/s
[Step=21900 Epoch=207.5] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.443 | L2-Norm(final)=5.360 | 2338.3 samples/s | 36.5 steps/s
[Step=21950 Epoch=208.0] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.430 | L2-Norm(final)=5.360 | 4315.7 samples/s | 67.4 steps/s
[Step=22000 Epoch=208.5] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.417 | L2-Norm(final)=5.361 | 2412.7 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step22000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=190.3] | Loss=0.01856 | Reg=0.00145 | acc=0.9844 | L2-Norm=12.055 | L2-Norm(final)=5.929 | 5599.3 samples/s | 87.5 steps/s
[Step=20050 Epoch=190.7] | Loss=0.00243 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.129 | L2-Norm(final)=5.929 | 3980.8 samples/s | 62.2 steps/s
[Step=20100 Epoch=191.2] | Loss=0.00149 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.183 | L2-Norm(final)=5.940 | 7410.4 samples/s | 115.8 steps/s
[Step=20150 Epoch=191.7] | Loss=0.00105 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.209 | L2-Norm(final)=5.951 | 2117.4 samples/s | 33.1 steps/s
[Step=20200 Epoch=192.2] | Loss=0.00083 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.222 | L2-Norm(final)=5.960 | 6609.7 samples/s | 103.3 steps/s
[Step=20250 Epoch=192.6] | Loss=0.00070 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.232 | L2-Norm(final)=5.968 | 2227.1 samples/s | 34.8 steps/s
[Step=20300 Epoch=193.1] | Loss=0.00060 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.238 | L2-Norm(final)=5.976 | 5880.9 samples/s | 91.9 steps/s
[Step=20350 Epoch=193.6] | Loss=0.00052 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.242 | L2-Norm(final)=5.983 | 2312.4 samples/s | 36.1 steps/s
[Step=20400 Epoch=194.1] | Loss=0.00047 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.246 | L2-Norm(final)=5.990 | 5311.0 samples/s | 83.0 steps/s
[Step=20450 Epoch=194.5] | Loss=0.00043 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.248 | L2-Norm(final)=5.996 | 2419.1 samples/s | 37.8 steps/s
[Step=20500 Epoch=195.0] | Loss=0.00039 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.250 | L2-Norm(final)=6.002 | 4806.5 samples/s | 75.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=195.0] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.265 | L2-Norm(final)=6.060 | 5516.6 samples/s | 86.2 steps/s
[Step=20550 Epoch=195.5] | Loss=0.00425 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.283 | L2-Norm(final)=6.061 | 3683.2 samples/s | 57.5 steps/s
[Step=20600 Epoch=196.0] | Loss=0.00918 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.414 | L2-Norm(final)=6.040 | 6304.1 samples/s | 98.5 steps/s
[Step=20650 Epoch=196.4] | Loss=0.00627 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.491 | L2-Norm(final)=6.018 | 2015.5 samples/s | 31.5 steps/s
[Step=20700 Epoch=196.9] | Loss=0.00472 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.529 | L2-Norm(final)=6.007 | 5695.1 samples/s | 89.0 steps/s
[Step=20750 Epoch=197.4] | Loss=0.00379 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.550 | L2-Norm(final)=6.001 | 2094.6 samples/s | 32.7 steps/s
[Step=20800 Epoch=197.9] | Loss=0.00316 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.562 | L2-Norm(final)=5.998 | 5157.1 samples/s | 80.6 steps/s
[Step=20850 Epoch=198.3] | Loss=0.00271 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.569 | L2-Norm(final)=5.995 | 2231.1 samples/s | 34.9 steps/s
[Step=20900 Epoch=198.8] | Loss=0.00237 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.573 | L2-Norm(final)=5.994 | 4539.7 samples/s | 70.9 steps/s
[Step=20950 Epoch=199.3] | Loss=0.00211 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.575 | L2-Norm(final)=5.992 | 2268.5 samples/s | 35.4 steps/s
[Step=21000 Epoch=199.8] | Loss=0.00190 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.992 | 4315.6 samples/s | 67.4 steps/s
[Step=21050 Epoch=200.2] | Loss=0.00173 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.575 | L2-Norm(final)=5.991 | 2349.4 samples/s | 36.7 steps/s
[Step=21100 Epoch=200.7] | Loss=0.00159 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.574 | L2-Norm(final)=5.990 | 4238.8 samples/s | 66.2 steps/s
[Step=21150 Epoch=201.2] | Loss=0.00147 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.572 | L2-Norm(final)=5.990 | 2440.3 samples/s | 38.1 steps/s
[Step=21200 Epoch=201.7] | Loss=0.00136 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.569 | L2-Norm(final)=5.990 | 4148.5 samples/s | 64.8 steps/s
[Step=21250 Epoch=202.1] | Loss=0.00127 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.566 | L2-Norm(final)=5.990 | 2318.5 samples/s | 36.2 steps/s
[Step=21300 Epoch=202.6] | Loss=0.00119 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.563 | L2-Norm(final)=5.990 | 4296.2 samples/s | 67.1 steps/s
[Step=21350 Epoch=203.1] | Loss=0.00112 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.559 | L2-Norm(final)=5.990 | 2562.8 samples/s | 40.0 steps/s
[Step=21400 Epoch=203.6] | Loss=0.00106 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.555 | L2-Norm(final)=5.990 | 3801.6 samples/s | 59.4 steps/s
[Step=21450 Epoch=204.0] | Loss=0.00101 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.551 | L2-Norm(final)=5.990 | 6610.2 samples/s | 103.3 steps/s
[Step=21500 Epoch=204.5] | Loss=0.00096 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.547 | L2-Norm(final)=5.990 | 1990.3 samples/s | 31.1 steps/s
[Step=21550 Epoch=205.0] | Loss=0.00091 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.542 | L2-Norm(final)=5.990 | 5835.6 samples/s | 91.2 steps/s
[Step=21600 Epoch=205.5] | Loss=0.00087 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.537 | L2-Norm(final)=5.990 | 2062.2 samples/s | 32.2 steps/s
[Step=21650 Epoch=205.9] | Loss=0.00083 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.532 | L2-Norm(final)=5.990 | 5368.0 samples/s | 83.9 steps/s
[Step=21700 Epoch=206.4] | Loss=0.00080 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.527 | L2-Norm(final)=5.990 | 2174.4 samples/s | 34.0 steps/s
[Step=21750 Epoch=206.9] | Loss=0.00077 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.522 | L2-Norm(final)=5.990 | 4866.3 samples/s | 76.0 steps/s
[Step=21800 Epoch=207.4] | Loss=0.00074 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.517 | L2-Norm(final)=5.990 | 2198.7 samples/s | 34.4 steps/s
[Step=21850 Epoch=207.8] | Loss=0.00071 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.511 | L2-Norm(final)=5.991 | 4468.1 samples/s | 69.8 steps/s
[Step=21900 Epoch=208.3] | Loss=0.00068 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.506 | L2-Norm(final)=5.991 | 2346.6 samples/s | 36.7 steps/s
[Step=21950 Epoch=208.8] | Loss=0.00066 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.500 | L2-Norm(final)=5.991 | 4244.8 samples/s | 66.3 steps/s
[Step=22000 Epoch=209.3] | Loss=0.00064 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.494 | L2-Norm(final)=5.991 | 2462.1 samples/s | 38.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step22000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=191.0] | Loss=0.00055 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.425 | L2-Norm(final)=5.686 | 5619.3 samples/s | 87.8 steps/s
[Step=20050 Epoch=191.5] | Loss=0.00141 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.474 | L2-Norm(final)=5.695 | 3959.5 samples/s | 61.9 steps/s
[Step=20100 Epoch=191.9] | Loss=0.00090 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.501 | L2-Norm(final)=5.710 | 7404.3 samples/s | 115.7 steps/s
[Step=20150 Epoch=192.4] | Loss=0.00068 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.517 | L2-Norm(final)=5.724 | 2116.6 samples/s | 33.1 steps/s
[Step=20200 Epoch=192.9] | Loss=0.00055 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.528 | L2-Norm(final)=5.737 | 6814.5 samples/s | 106.5 steps/s
[Step=20250 Epoch=193.4] | Loss=0.00046 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.536 | L2-Norm(final)=5.749 | 2189.1 samples/s | 34.2 steps/s
[Step=20300 Epoch=193.9] | Loss=0.00040 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.541 | L2-Norm(final)=5.759 | 6221.7 samples/s | 97.2 steps/s
[Step=20350 Epoch=194.3] | Loss=0.00036 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.546 | L2-Norm(final)=5.769 | 2260.0 samples/s | 35.3 steps/s
[Step=20400 Epoch=194.8] | Loss=0.00033 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=5.779 | 5558.1 samples/s | 86.8 steps/s
[Step=20450 Epoch=195.3] | Loss=0.00030 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.552 | L2-Norm(final)=5.788 | 2344.3 samples/s | 36.6 steps/s
[Step=20500 Epoch=195.8] | Loss=0.00028 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=5.797 | 5275.8 samples/s | 82.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=195.8] | Loss=0.00007 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.570 | L2-Norm(final)=5.885 | 5182.8 samples/s | 81.0 steps/s
[Step=20550 Epoch=196.2] | Loss=0.00004 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.559 | L2-Norm(final)=5.890 | 3864.3 samples/s | 60.4 steps/s
[Step=20600 Epoch=196.7] | Loss=0.00003 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.542 | L2-Norm(final)=5.895 | 6321.7 samples/s | 98.8 steps/s
[Step=20650 Epoch=197.2] | Loss=0.00002 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.525 | L2-Norm(final)=5.897 | 2017.8 samples/s | 31.5 steps/s
[Step=20700 Epoch=197.7] | Loss=0.00002 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.506 | L2-Norm(final)=5.899 | 5524.1 samples/s | 86.3 steps/s
[Step=20750 Epoch=198.1] | Loss=0.00002 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.487 | L2-Norm(final)=5.900 | 2071.3 samples/s | 32.4 steps/s
[Step=20800 Epoch=198.6] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.468 | L2-Norm(final)=5.901 | 5407.6 samples/s | 84.5 steps/s
[Step=20850 Epoch=199.1] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.448 | L2-Norm(final)=5.902 | 2139.0 samples/s | 33.4 steps/s
[Step=20900 Epoch=199.6] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.428 | L2-Norm(final)=5.903 | 4975.2 samples/s | 77.7 steps/s
[Step=20950 Epoch=200.1] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.409 | L2-Norm(final)=5.904 | 2193.9 samples/s | 34.3 steps/s
[Step=21000 Epoch=200.5] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.388 | L2-Norm(final)=5.905 | 4591.0 samples/s | 71.7 steps/s
[Step=21050 Epoch=201.0] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.368 | L2-Norm(final)=5.906 | 2272.8 samples/s | 35.5 steps/s
[Step=21100 Epoch=201.5] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.348 | L2-Norm(final)=5.906 | 4310.3 samples/s | 67.3 steps/s
[Step=21150 Epoch=202.0] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.327 | L2-Norm(final)=5.907 | 2437.7 samples/s | 38.1 steps/s
[Step=21200 Epoch=202.4] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.307 | L2-Norm(final)=5.908 | 4092.4 samples/s | 63.9 steps/s
[Step=21250 Epoch=202.9] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.286 | L2-Norm(final)=5.908 | 2349.8 samples/s | 36.7 steps/s
[Step=21300 Epoch=203.4] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.265 | L2-Norm(final)=5.909 | 4229.6 samples/s | 66.1 steps/s
[Step=21350 Epoch=203.9] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.244 | L2-Norm(final)=5.909 | 2388.5 samples/s | 37.3 steps/s
[Step=21400 Epoch=204.4] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.223 | L2-Norm(final)=5.910 | 4310.6 samples/s | 67.4 steps/s
[Step=21450 Epoch=204.8] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.202 | L2-Norm(final)=5.911 | 2369.4 samples/s | 37.0 steps/s
[Step=21500 Epoch=205.3] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.180 | L2-Norm(final)=5.911 | 4284.2 samples/s | 66.9 steps/s
[Step=21550 Epoch=205.8] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.158 | L2-Norm(final)=5.912 | 7000.4 samples/s | 109.4 steps/s
[Step=21600 Epoch=206.3] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.137 | L2-Norm(final)=5.912 | 1944.2 samples/s | 30.4 steps/s
[Step=21650 Epoch=206.7] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.115 | L2-Norm(final)=5.913 | 6200.4 samples/s | 96.9 steps/s
[Step=21700 Epoch=207.2] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.093 | L2-Norm(final)=5.914 | 2017.8 samples/s | 31.5 steps/s
[Step=21750 Epoch=207.7] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.070 | L2-Norm(final)=5.914 | 5836.8 samples/s | 91.2 steps/s
[Step=21800 Epoch=208.2] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.048 | L2-Norm(final)=5.915 | 2060.8 samples/s | 32.2 steps/s
[Step=21850 Epoch=208.7] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.025 | L2-Norm(final)=5.915 | 5344.9 samples/s | 83.5 steps/s
[Step=21900 Epoch=209.1] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.003 | L2-Norm(final)=5.916 | 2086.7 samples/s | 32.6 steps/s
[Step=21950 Epoch=209.6] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.980 | L2-Norm(final)=5.916 | 4987.4 samples/s | 77.9 steps/s
[Step=22000 Epoch=210.1] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.957 | L2-Norm(final)=5.917 | 2216.8 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step22000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=188.5] | Loss=0.00096 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.500 | L2-Norm(final)=5.388 | 5428.3 samples/s | 84.8 steps/s
[Step=20050 Epoch=188.9] | Loss=0.00151 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.536 | L2-Norm(final)=5.403 | 4251.8 samples/s | 66.4 steps/s
[Step=20100 Epoch=189.4] | Loss=0.00190 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.573 | L2-Norm(final)=5.417 | 6996.2 samples/s | 109.3 steps/s
[Step=20150 Epoch=189.9] | Loss=0.00135 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.599 | L2-Norm(final)=5.427 | 2127.3 samples/s | 33.2 steps/s
[Step=20200 Epoch=190.3] | Loss=0.00107 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.612 | L2-Norm(final)=5.436 | 6452.5 samples/s | 100.8 steps/s
[Step=20250 Epoch=190.8] | Loss=0.00088 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.621 | L2-Norm(final)=5.445 | 2268.5 samples/s | 35.4 steps/s
[Step=20300 Epoch=191.3] | Loss=0.00076 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.626 | L2-Norm(final)=5.452 | 5606.0 samples/s | 87.6 steps/s
[Step=20350 Epoch=191.8] | Loss=0.00067 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.630 | L2-Norm(final)=5.460 | 2359.1 samples/s | 36.9 steps/s
[Step=20400 Epoch=192.2] | Loss=0.00060 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.634 | L2-Norm(final)=5.467 | 5060.7 samples/s | 79.1 steps/s
[Step=20450 Epoch=192.7] | Loss=0.00054 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.636 | L2-Norm(final)=5.474 | 1845.7 samples/s | 28.8 steps/s
[Step=20500 Epoch=193.2] | Loss=0.00050 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.637 | L2-Norm(final)=5.481 | 4610.4 samples/s | 72.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=193.2] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.649 | L2-Norm(final)=5.544 | 5660.5 samples/s | 88.4 steps/s
[Step=20550 Epoch=193.6] | Loss=0.00006 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.639 | L2-Norm(final)=5.549 | 3686.1 samples/s | 57.6 steps/s
[Step=20600 Epoch=194.1] | Loss=0.00004 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.625 | L2-Norm(final)=5.552 | 6228.3 samples/s | 97.3 steps/s
[Step=20650 Epoch=194.6] | Loss=0.00003 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.610 | L2-Norm(final)=5.554 | 2063.0 samples/s | 32.2 steps/s
[Step=20700 Epoch=195.1] | Loss=0.00003 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.593 | L2-Norm(final)=5.555 | 5224.9 samples/s | 81.6 steps/s
[Step=20750 Epoch=195.5] | Loss=0.00002 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.577 | L2-Norm(final)=5.557 | 2132.3 samples/s | 33.3 steps/s
[Step=20800 Epoch=196.0] | Loss=0.00002 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.560 | L2-Norm(final)=5.558 | 4912.1 samples/s | 76.8 steps/s
[Step=20850 Epoch=196.5] | Loss=0.00002 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.542 | L2-Norm(final)=5.558 | 2205.2 samples/s | 34.5 steps/s
[Step=20900 Epoch=196.9] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.525 | L2-Norm(final)=5.559 | 4508.0 samples/s | 70.4 steps/s
[Step=20950 Epoch=197.4] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.507 | L2-Norm(final)=5.560 | 2328.3 samples/s | 36.4 steps/s
[Step=21000 Epoch=197.9] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.489 | L2-Norm(final)=5.560 | 4187.9 samples/s | 65.4 steps/s
[Step=21050 Epoch=198.4] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.471 | L2-Norm(final)=5.561 | 2399.6 samples/s | 37.5 steps/s
[Step=21100 Epoch=198.8] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.453 | L2-Norm(final)=5.561 | 4255.5 samples/s | 66.5 steps/s
[Step=21150 Epoch=199.3] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.435 | L2-Norm(final)=5.562 | 2404.2 samples/s | 37.6 steps/s
[Step=21200 Epoch=199.8] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.416 | L2-Norm(final)=5.562 | 4207.1 samples/s | 65.7 steps/s
[Step=21250 Epoch=200.2] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.398 | L2-Norm(final)=5.563 | 2623.2 samples/s | 41.0 steps/s
[Step=21300 Epoch=200.7] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.379 | L2-Norm(final)=5.563 | 3689.9 samples/s | 57.7 steps/s
[Step=21350 Epoch=201.2] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.360 | L2-Norm(final)=5.564 | 6275.1 samples/s | 98.0 steps/s
[Step=21400 Epoch=201.6] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.341 | L2-Norm(final)=5.564 | 2061.4 samples/s | 32.2 steps/s
[Step=21450 Epoch=202.1] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.322 | L2-Norm(final)=5.565 | 5399.4 samples/s | 84.4 steps/s
[Step=21500 Epoch=202.6] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.303 | L2-Norm(final)=5.565 | 2106.2 samples/s | 32.9 steps/s
[Step=21550 Epoch=203.1] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.283 | L2-Norm(final)=5.566 | 4943.6 samples/s | 77.2 steps/s
[Step=21600 Epoch=203.5] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.264 | L2-Norm(final)=5.566 | 2212.0 samples/s | 34.6 steps/s
[Step=21650 Epoch=204.0] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.244 | L2-Norm(final)=5.567 | 4439.0 samples/s | 69.4 steps/s
[Step=21700 Epoch=204.5] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.224 | L2-Norm(final)=5.567 | 2329.7 samples/s | 36.4 steps/s
[Step=21750 Epoch=204.9] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.204 | L2-Norm(final)=5.567 | 4248.1 samples/s | 66.4 steps/s
[Step=21800 Epoch=205.4] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.183 | L2-Norm(final)=5.568 | 2418.1 samples/s | 37.8 steps/s
[Step=21850 Epoch=205.9] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.163 | L2-Norm(final)=5.568 | 4158.4 samples/s | 65.0 steps/s
[Step=21900 Epoch=206.4] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.142 | L2-Norm(final)=5.569 | 2385.1 samples/s | 37.3 steps/s
[Step=21950 Epoch=206.8] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.121 | L2-Norm(final)=5.569 | 4150.7 samples/s | 64.9 steps/s
[Step=22000 Epoch=207.3] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=5.570 | 2524.4 samples/s | 39.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step22000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=190.6] | Loss=0.00209 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.597 | L2-Norm(final)=6.463 | 5512.3 samples/s | 86.1 steps/s
[Step=20050 Epoch=191.1] | Loss=0.00378 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.653 | L2-Norm(final)=6.477 | 4236.1 samples/s | 66.2 steps/s
[Step=20100 Epoch=191.6] | Loss=0.00250 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.714 | L2-Norm(final)=6.497 | 7435.8 samples/s | 116.2 steps/s
[Step=20150 Epoch=192.0] | Loss=0.00183 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.745 | L2-Norm(final)=6.513 | 2101.4 samples/s | 32.8 steps/s
[Step=20200 Epoch=192.5] | Loss=0.00145 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.764 | L2-Norm(final)=6.527 | 6825.5 samples/s | 106.6 steps/s
[Step=20250 Epoch=193.0] | Loss=0.00121 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.777 | L2-Norm(final)=6.539 | 2211.2 samples/s | 34.5 steps/s
[Step=20300 Epoch=193.5] | Loss=0.00105 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.786 | L2-Norm(final)=6.549 | 6057.3 samples/s | 94.6 steps/s
[Step=20350 Epoch=194.0] | Loss=0.00093 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.793 | L2-Norm(final)=6.559 | 2272.8 samples/s | 35.5 steps/s
[Step=20400 Epoch=194.4] | Loss=0.00083 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.799 | L2-Norm(final)=6.568 | 5546.8 samples/s | 86.7 steps/s
[Step=20450 Epoch=194.9] | Loss=0.00076 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.803 | L2-Norm(final)=6.577 | 2322.3 samples/s | 36.3 steps/s
[Step=20500 Epoch=195.4] | Loss=0.00070 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.807 | L2-Norm(final)=6.585 | 5283.9 samples/s | 82.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=195.4] | Loss=0.00005 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.841 | L2-Norm(final)=6.667 | 4999.0 samples/s | 78.1 steps/s
[Step=20550 Epoch=195.9] | Loss=0.00844 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.848 | L2-Norm(final)=6.672 | 3966.4 samples/s | 62.0 steps/s
[Step=20600 Epoch=196.3] | Loss=0.01176 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.963 | L2-Norm(final)=6.647 | 6244.3 samples/s | 97.6 steps/s
[Step=20650 Epoch=196.8] | Loss=0.00859 | Reg=0.00170 | acc=0.9844 | L2-Norm=13.030 | L2-Norm(final)=6.630 | 2038.8 samples/s | 31.9 steps/s
[Step=20700 Epoch=197.3] | Loss=0.00720 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.066 | L2-Norm(final)=6.621 | 5629.7 samples/s | 88.0 steps/s
[Step=20750 Epoch=197.8] | Loss=0.00620 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.089 | L2-Norm(final)=6.614 | 2053.8 samples/s | 32.1 steps/s
[Step=20800 Epoch=198.2] | Loss=0.00519 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.104 | L2-Norm(final)=6.610 | 5379.8 samples/s | 84.1 steps/s
[Step=20850 Epoch=198.7] | Loss=0.00445 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.114 | L2-Norm(final)=6.607 | 2140.0 samples/s | 33.4 steps/s
[Step=20900 Epoch=199.2] | Loss=0.00390 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.120 | L2-Norm(final)=6.604 | 4973.1 samples/s | 77.7 steps/s
[Step=20950 Epoch=199.7] | Loss=0.00347 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.123 | L2-Norm(final)=6.603 | 2215.3 samples/s | 34.6 steps/s
[Step=21000 Epoch=200.1] | Loss=0.00312 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.125 | L2-Norm(final)=6.601 | 4584.4 samples/s | 71.6 steps/s
[Step=21050 Epoch=200.6] | Loss=0.00284 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.126 | L2-Norm(final)=6.600 | 2247.7 samples/s | 35.1 steps/s
[Step=21100 Epoch=201.1] | Loss=0.00260 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.125 | L2-Norm(final)=6.600 | 4284.5 samples/s | 66.9 steps/s
[Step=21150 Epoch=201.6] | Loss=0.00240 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.124 | L2-Norm(final)=6.599 | 2404.6 samples/s | 37.6 steps/s
[Step=21200 Epoch=202.1] | Loss=0.00223 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.123 | L2-Norm(final)=6.598 | 4220.7 samples/s | 65.9 steps/s
[Step=21250 Epoch=202.5] | Loss=0.00208 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.120 | L2-Norm(final)=6.598 | 2389.7 samples/s | 37.3 steps/s
[Step=21300 Epoch=203.0] | Loss=0.00195 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.118 | L2-Norm(final)=6.597 | 4100.0 samples/s | 64.1 steps/s
[Step=21350 Epoch=203.5] | Loss=0.00184 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.115 | L2-Norm(final)=6.597 | 2325.7 samples/s | 36.3 steps/s
[Step=21400 Epoch=204.0] | Loss=0.00174 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.112 | L2-Norm(final)=6.597 | 4344.8 samples/s | 67.9 steps/s
[Step=21450 Epoch=204.4] | Loss=0.00165 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.108 | L2-Norm(final)=6.597 | 2367.0 samples/s | 37.0 steps/s
[Step=21500 Epoch=204.9] | Loss=0.00156 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.105 | L2-Norm(final)=6.597 | 4269.0 samples/s | 66.7 steps/s
[Step=21550 Epoch=205.4] | Loss=0.00149 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.101 | L2-Norm(final)=6.596 | 7037.1 samples/s | 110.0 steps/s
[Step=21600 Epoch=205.9] | Loss=0.00142 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.097 | L2-Norm(final)=6.596 | 1951.0 samples/s | 30.5 steps/s
[Step=21650 Epoch=206.3] | Loss=0.00136 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.093 | L2-Norm(final)=6.596 | 6357.5 samples/s | 99.3 steps/s
[Step=21700 Epoch=206.8] | Loss=0.00130 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.088 | L2-Norm(final)=6.596 | 2020.6 samples/s | 31.6 steps/s
[Step=21750 Epoch=207.3] | Loss=0.00125 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.084 | L2-Norm(final)=6.596 | 5829.0 samples/s | 91.1 steps/s
[Step=21800 Epoch=207.8] | Loss=0.00120 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.079 | L2-Norm(final)=6.596 | 2080.8 samples/s | 32.5 steps/s
[Step=21850 Epoch=208.3] | Loss=0.00116 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.074 | L2-Norm(final)=6.596 | 5398.1 samples/s | 84.3 steps/s
[Step=21900 Epoch=208.7] | Loss=0.00112 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.069 | L2-Norm(final)=6.596 | 2091.9 samples/s | 32.7 steps/s
[Step=21950 Epoch=209.2] | Loss=0.00108 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.064 | L2-Norm(final)=6.596 | 4996.9 samples/s | 78.1 steps/s
[Step=22000 Epoch=209.7] | Loss=0.00104 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.059 | L2-Norm(final)=6.596 | 2239.0 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11176 | acc=0.9552 | tpr=0.9645 | fpr=0.0649 | 4996.0 samples/s | 19.5 steps/s
Avg test loss: 0.11820, Avg test acc: 0.95392, Avg tpr: 0.96433, Avg fpr: 0.06897, total FA: 538

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11593 | acc=0.9566 | tpr=0.9694 | fpr=0.0714 | 4855.0 samples/s | 19.0 steps/s
Avg test loss: 0.11951, Avg test acc: 0.95541, Avg tpr: 0.96963, Avg fpr: 0.07589, total FA: 592

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11926 | acc=0.9588 | tpr=0.9742 | fpr=0.0746 | 4830.5 samples/s | 18.9 steps/s
Avg test loss: 0.11919, Avg test acc: 0.95785, Avg tpr: 0.97237, Avg fpr: 0.07409, total FA: 578

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10827 | acc=0.9580 | tpr=0.9698 | fpr=0.0674 | 4737.4 samples/s | 18.5 steps/s
Avg test loss: 0.11173, Avg test acc: 0.95709, Avg tpr: 0.97010, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11298 | acc=0.9575 | tpr=0.9725 | fpr=0.0751 | 4899.5 samples/s | 19.1 steps/s
Avg test loss: 0.11563, Avg test acc: 0.95761, Avg tpr: 0.97325, Avg fpr: 0.07679, total FA: 599

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.71385 | acc=0.2687 | tpr=0.0323 | fpr=0.2178 | 4738.2 samples/s | 18.5 steps/s
Avg test loss: 5.72460, Avg test acc: 0.26737, Avg tpr: 0.03200, Avg fpr: 0.21497, total FA: 1677

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.22308 | acc=0.2859 | tpr=0.0092 | fpr=0.1135 | 4884.7 samples/s | 19.1 steps/s
Avg test loss: 5.24162, Avg test acc: 0.28247, Avg tpr: 0.00921, Avg fpr: 0.11652, total FA: 909

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.72549 | acc=0.2585 | tpr=0.0264 | fpr=0.2374 | 4775.5 samples/s | 18.7 steps/s
Avg test loss: 5.73151, Avg test acc: 0.25683, Avg tpr: 0.02640, Avg fpr: 0.23638, total FA: 1844

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.98219 | acc=0.2824 | tpr=0.0283 | fpr=0.1658 | 4911.5 samples/s | 19.2 steps/s
Avg test loss: 5.98202, Avg test acc: 0.27995, Avg tpr: 0.02774, Avg fpr: 0.16536, total FA: 1290

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.79952 | acc=0.3053 | tpr=0.0259 | fpr=0.0880 | 4798.5 samples/s | 18.7 steps/s
Avg test loss: 5.81272, Avg test acc: 0.30311, Avg tpr: 0.02570, Avg fpr: 0.08678, total FA: 677

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.44619 | acc=0.0982 | tpr=0.7168 | fpr=0.9129 | 4638.1 samples/s | 18.1 steps/s
[Step= 100] | Loss=6.40244 | acc=0.1000 | tpr=0.6994 | fpr=0.9111 | 7750.8 samples/s | 30.3 steps/s
[Step= 150] | Loss=6.41644 | acc=0.1016 | tpr=0.6772 | fpr=0.9090 | 7680.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.41503 | acc=0.1016 | tpr=0.6776 | fpr=0.9089 | 7861.8 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.42553 | acc=0.1015 | tpr=0.6681 | fpr=0.9088 | 7834.0 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.42117 | acc=0.1014 | tpr=0.6705 | fpr=0.9090 | 7860.1 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.41809 | acc=0.1017 | tpr=0.6744 | fpr=0.9087 | 7504.3 samples/s | 29.3 steps/s
[Step= 400] | Loss=6.41094 | acc=0.1017 | tpr=0.6772 | fpr=0.9088 | 7989.8 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.41578 | acc=0.1015 | tpr=0.6782 | fpr=0.9089 | 8275.1 samples/s | 32.3 steps/s
[Step= 500] | Loss=6.42226 | acc=0.1012 | tpr=0.6758 | fpr=0.9092 | 7912.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.42314 | acc=0.1015 | tpr=0.6721 | fpr=0.9088 | 13179.4 samples/s | 51.5 steps/s
Avg test loss: 6.42462, Avg test acc: 0.10144, Avg tpr: 0.67235, Avg fpr: 0.90894, total FA: 126204

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.78356 | acc=0.0927 | tpr=0.6327 | fpr=0.9170 | 4580.4 samples/s | 17.9 steps/s
[Step= 100] | Loss=5.75009 | acc=0.0930 | tpr=0.6226 | fpr=0.9169 | 7567.8 samples/s | 29.6 steps/s
[Step= 150] | Loss=5.75803 | acc=0.0937 | tpr=0.6225 | fpr=0.9160 | 7784.1 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.74412 | acc=0.0944 | tpr=0.6186 | fpr=0.9151 | 7980.3 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.75636 | acc=0.0947 | tpr=0.6227 | fpr=0.9149 | 7759.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.74624 | acc=0.0946 | tpr=0.6240 | fpr=0.9150 | 8088.1 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.73987 | acc=0.0951 | tpr=0.6293 | fpr=0.9145 | 7715.0 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.73611 | acc=0.0954 | tpr=0.6291 | fpr=0.9143 | 8201.4 samples/s | 32.0 steps/s
[Step= 450] | Loss=5.73958 | acc=0.0953 | tpr=0.6290 | fpr=0.9144 | 7523.1 samples/s | 29.4 steps/s
[Step= 500] | Loss=5.74304 | acc=0.0948 | tpr=0.6300 | fpr=0.9149 | 7847.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.74455 | acc=0.0945 | tpr=0.6279 | fpr=0.9152 | 14331.7 samples/s | 56.0 steps/s
Avg test loss: 5.74595, Avg test acc: 0.09435, Avg tpr: 0.62797, Avg fpr: 0.91535, total FA: 127094

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=7.15619 | acc=0.0777 | tpr=0.5442 | fpr=0.9307 | 4972.6 samples/s | 19.4 steps/s
[Step= 100] | Loss=7.11041 | acc=0.0786 | tpr=0.5416 | fpr=0.9301 | 6712.5 samples/s | 26.2 steps/s
[Step= 150] | Loss=7.12780 | acc=0.0788 | tpr=0.5562 | fpr=0.9300 | 8070.7 samples/s | 31.5 steps/s
[Step= 200] | Loss=7.11649 | acc=0.0790 | tpr=0.5607 | fpr=0.9298 | 7362.5 samples/s | 28.8 steps/s
[Step= 250] | Loss=7.12646 | acc=0.0794 | tpr=0.5607 | fpr=0.9294 | 8049.7 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.11930 | acc=0.0790 | tpr=0.5615 | fpr=0.9298 | 7991.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=7.11021 | acc=0.0793 | tpr=0.5654 | fpr=0.9296 | 7904.5 samples/s | 30.9 steps/s
[Step= 400] | Loss=7.10205 | acc=0.0796 | tpr=0.5635 | fpr=0.9292 | 7868.8 samples/s | 30.7 steps/s
[Step= 450] | Loss=7.10403 | acc=0.0797 | tpr=0.5657 | fpr=0.9291 | 7767.2 samples/s | 30.3 steps/s
[Step= 500] | Loss=7.10839 | acc=0.0794 | tpr=0.5639 | fpr=0.9294 | 7946.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=7.11054 | acc=0.0793 | tpr=0.5611 | fpr=0.9295 | 14202.0 samples/s | 55.5 steps/s
Avg test loss: 7.11162, Avg test acc: 0.07919, Avg tpr: 0.56220, Avg fpr: 0.92959, total FA: 129072

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.49395 | acc=0.1071 | tpr=0.6726 | fpr=0.9031 | 4946.9 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.47253 | acc=0.1075 | tpr=0.6610 | fpr=0.9028 | 6995.8 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.47332 | acc=0.1076 | tpr=0.6671 | fpr=0.9027 | 7604.1 samples/s | 29.7 steps/s
[Step= 200] | Loss=5.46570 | acc=0.1074 | tpr=0.6656 | fpr=0.9028 | 7737.0 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.47878 | acc=0.1070 | tpr=0.6524 | fpr=0.9029 | 7919.7 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.47404 | acc=0.1065 | tpr=0.6538 | fpr=0.9034 | 8189.9 samples/s | 32.0 steps/s
[Step= 350] | Loss=5.46399 | acc=0.1069 | tpr=0.6550 | fpr=0.9031 | 7639.6 samples/s | 29.8 steps/s
[Step= 400] | Loss=5.46151 | acc=0.1068 | tpr=0.6493 | fpr=0.9031 | 8044.7 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.46466 | acc=0.1070 | tpr=0.6504 | fpr=0.9029 | 7711.3 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.46787 | acc=0.1066 | tpr=0.6507 | fpr=0.9032 | 8035.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=5.46914 | acc=0.1064 | tpr=0.6490 | fpr=0.9035 | 13521.0 samples/s | 52.8 steps/s
Avg test loss: 5.47002, Avg test acc: 0.10625, Avg tpr: 0.64897, Avg fpr: 0.90361, total FA: 125465

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.89280 | acc=0.0961 | tpr=0.7035 | fpr=0.9148 | 4713.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.88561 | acc=0.0971 | tpr=0.6738 | fpr=0.9137 | 7660.4 samples/s | 29.9 steps/s
[Step= 150] | Loss=5.89396 | acc=0.0964 | tpr=0.6599 | fpr=0.9140 | 7497.4 samples/s | 29.3 steps/s
[Step= 200] | Loss=5.88884 | acc=0.0957 | tpr=0.6536 | fpr=0.9144 | 7720.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.90290 | acc=0.0958 | tpr=0.6533 | fpr=0.9144 | 7890.8 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.89874 | acc=0.0964 | tpr=0.6509 | fpr=0.9137 | 7709.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.89368 | acc=0.0964 | tpr=0.6569 | fpr=0.9138 | 7968.1 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.89181 | acc=0.0969 | tpr=0.6608 | fpr=0.9133 | 8025.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.89551 | acc=0.0968 | tpr=0.6602 | fpr=0.9135 | 7862.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.89827 | acc=0.0965 | tpr=0.6568 | fpr=0.9136 | 7952.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.90073 | acc=0.0964 | tpr=0.6586 | fpr=0.9138 | 13674.7 samples/s | 53.4 steps/s
Avg test loss: 5.90184, Avg test acc: 0.09632, Avg tpr: 0.65887, Avg fpr: 0.91391, total FA: 126894

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10097 | acc=0.9819 | tpr=0.9204 | fpr=0.0170 | 4960.6 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.10519 | acc=0.9809 | tpr=0.9232 | fpr=0.0180 | 6670.1 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.10803 | acc=0.9803 | tpr=0.9280 | fpr=0.0187 | 7710.1 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.11034 | acc=0.9801 | tpr=0.9355 | fpr=0.0191 | 7918.8 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.10886 | acc=0.9803 | tpr=0.9310 | fpr=0.0188 | 8032.7 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.11133 | acc=0.9800 | tpr=0.9295 | fpr=0.0191 | 7950.3 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.11200 | acc=0.9798 | tpr=0.9330 | fpr=0.0193 | 7766.0 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.11344 | acc=0.9796 | tpr=0.9294 | fpr=0.0195 | 7836.4 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.11526 | acc=0.9793 | tpr=0.9270 | fpr=0.0197 | 7851.5 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.11443 | acc=0.9795 | tpr=0.9295 | fpr=0.0196 | 7739.8 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.11398 | acc=0.9796 | tpr=0.9288 | fpr=0.0195 | 14370.6 samples/s | 56.1 steps/s
Avg test loss: 0.11397, Avg test acc: 0.97961, Avg tpr: 0.92868, Avg fpr: 0.01947, total FA: 2703

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08404 | acc=0.9827 | tpr=0.8894 | fpr=0.0157 | 4894.2 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08611 | acc=0.9829 | tpr=0.8849 | fpr=0.0153 | 7079.0 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.08673 | acc=0.9825 | tpr=0.8905 | fpr=0.0158 | 7288.9 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.08848 | acc=0.9825 | tpr=0.8940 | fpr=0.0159 | 8144.9 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.08640 | acc=0.9828 | tpr=0.8952 | fpr=0.0156 | 8229.1 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.08840 | acc=0.9824 | tpr=0.8902 | fpr=0.0159 | 7633.5 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.08882 | acc=0.9823 | tpr=0.8961 | fpr=0.0161 | 7665.0 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.08910 | acc=0.9822 | tpr=0.8939 | fpr=0.0162 | 7980.3 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.09092 | acc=0.9819 | tpr=0.8900 | fpr=0.0164 | 7793.2 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.08989 | acc=0.9820 | tpr=0.8952 | fpr=0.0164 | 7718.4 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.09003 | acc=0.9821 | tpr=0.8945 | fpr=0.0163 | 14714.6 samples/s | 57.5 steps/s
Avg test loss: 0.09000, Avg test acc: 0.98211, Avg tpr: 0.89422, Avg fpr: 0.01629, total FA: 2262

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10826 | acc=0.9797 | tpr=0.9558 | fpr=0.0199 | 4740.9 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.11122 | acc=0.9791 | tpr=0.9510 | fpr=0.0204 | 7306.3 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.11502 | acc=0.9782 | tpr=0.9510 | fpr=0.0213 | 7906.9 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.11741 | acc=0.9781 | tpr=0.9541 | fpr=0.0215 | 7855.5 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.11605 | acc=0.9782 | tpr=0.9520 | fpr=0.0213 | 7767.7 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.11860 | acc=0.9780 | tpr=0.9469 | fpr=0.0214 | 7735.0 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.11871 | acc=0.9780 | tpr=0.9474 | fpr=0.0214 | 8367.4 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.11995 | acc=0.9779 | tpr=0.9453 | fpr=0.0215 | 7855.9 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.12163 | acc=0.9778 | tpr=0.9435 | fpr=0.0215 | 7605.2 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.12100 | acc=0.9778 | tpr=0.9445 | fpr=0.0216 | 7949.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12066 | acc=0.9780 | tpr=0.9447 | fpr=0.0214 | 13794.9 samples/s | 53.9 steps/s
Avg test loss: 0.12070, Avg test acc: 0.97800, Avg tpr: 0.94493, Avg fpr: 0.02140, total FA: 2971

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10521 | acc=0.9803 | tpr=0.9115 | fpr=0.0185 | 4868.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.11089 | acc=0.9795 | tpr=0.9104 | fpr=0.0192 | 6715.7 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.11463 | acc=0.9793 | tpr=0.9164 | fpr=0.0196 | 8061.3 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.11704 | acc=0.9795 | tpr=0.9224 | fpr=0.0194 | 7959.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.11544 | acc=0.9798 | tpr=0.9223 | fpr=0.0192 | 7863.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.11811 | acc=0.9794 | tpr=0.9200 | fpr=0.0195 | 7841.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.11853 | acc=0.9793 | tpr=0.9255 | fpr=0.0197 | 7718.4 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.11943 | acc=0.9792 | tpr=0.9234 | fpr=0.0198 | 7835.4 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.12136 | acc=0.9790 | tpr=0.9211 | fpr=0.0199 | 8031.3 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.12047 | acc=0.9791 | tpr=0.9242 | fpr=0.0199 | 7726.8 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.12011 | acc=0.9792 | tpr=0.9232 | fpr=0.0198 | 14086.4 samples/s | 55.0 steps/s
Avg test loss: 0.12002, Avg test acc: 0.97923, Avg tpr: 0.92314, Avg fpr: 0.01975, total FA: 2742

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.15244 | acc=0.9780 | tpr=0.9292 | fpr=0.0212 | 5043.8 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.15731 | acc=0.9771 | tpr=0.9360 | fpr=0.0222 | 6774.6 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.16391 | acc=0.9763 | tpr=0.9380 | fpr=0.0230 | 7657.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.16771 | acc=0.9761 | tpr=0.9377 | fpr=0.0232 | 7949.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.16511 | acc=0.9765 | tpr=0.9328 | fpr=0.0228 | 7859.4 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.16900 | acc=0.9761 | tpr=0.9273 | fpr=0.0230 | 7657.2 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.16951 | acc=0.9758 | tpr=0.9274 | fpr=0.0233 | 7899.6 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.17097 | acc=0.9757 | tpr=0.9223 | fpr=0.0233 | 7977.4 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.17424 | acc=0.9753 | tpr=0.9202 | fpr=0.0237 | 7457.1 samples/s | 29.1 steps/s
[Step= 500] | Loss=0.17344 | acc=0.9753 | tpr=0.9216 | fpr=0.0237 | 8184.7 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.17224 | acc=0.9755 | tpr=0.9216 | fpr=0.0235 | 13907.7 samples/s | 54.3 steps/s
Avg test loss: 0.17191, Avg test acc: 0.97551, Avg tpr: 0.92195, Avg fpr: 0.02351, total FA: 3265

server round 11/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=107.3] | Loss=0.00562 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.396 | L2-Norm(final)=8.740 | 5156.0 samples/s | 80.6 steps/s
[Step=22050 Epoch=107.5] | Loss=0.00610 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.390 | L2-Norm(final)=8.747 | 4644.1 samples/s | 72.6 steps/s
[Step=22100 Epoch=107.8] | Loss=0.00724 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.386 | L2-Norm(final)=8.760 | 5113.6 samples/s | 79.9 steps/s
[Step=22150 Epoch=108.0] | Loss=0.00603 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.381 | L2-Norm(final)=8.773 | 4994.4 samples/s | 78.0 steps/s
[Step=22200 Epoch=108.3] | Loss=0.00595 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.374 | L2-Norm(final)=8.786 | 7697.3 samples/s | 120.3 steps/s
[Step=22250 Epoch=108.5] | Loss=0.00540 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.366 | L2-Norm(final)=8.800 | 2212.9 samples/s | 34.6 steps/s
[Step=22300 Epoch=108.7] | Loss=0.00544 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.358 | L2-Norm(final)=8.813 | 5020.4 samples/s | 78.4 steps/s
[Step=22350 Epoch=109.0] | Loss=0.00522 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.350 | L2-Norm(final)=8.827 | 5062.8 samples/s | 79.1 steps/s
[Step=22400 Epoch=109.2] | Loss=0.00530 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.342 | L2-Norm(final)=8.841 | 6983.5 samples/s | 109.1 steps/s
[Step=22450 Epoch=109.5] | Loss=0.00519 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.334 | L2-Norm(final)=8.854 | 2319.7 samples/s | 36.2 steps/s
[Step=22500 Epoch=109.7] | Loss=0.00507 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.325 | L2-Norm(final)=8.868 | 5096.1 samples/s | 79.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=109.7] | Loss=0.00058 | Reg=0.00495 | acc=1.0000 | L2-Norm=22.242 | L2-Norm(final)=9.005 | 5496.0 samples/s | 85.9 steps/s
[Step=22550 Epoch=110.0] | Loss=0.01000 | Reg=0.00495 | acc=0.9844 | L2-Norm=22.247 | L2-Norm(final)=9.014 | 4157.2 samples/s | 65.0 steps/s
[Step=22600 Epoch=110.2] | Loss=0.01361 | Reg=0.00496 | acc=0.9844 | L2-Norm=22.271 | L2-Norm(final)=9.021 | 4299.2 samples/s | 67.2 steps/s
[Step=22650 Epoch=110.4] | Loss=0.01640 | Reg=0.00497 | acc=1.0000 | L2-Norm=22.301 | L2-Norm(final)=9.022 | 4533.6 samples/s | 70.8 steps/s
[Step=22700 Epoch=110.7] | Loss=0.01753 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.329 | L2-Norm(final)=9.021 | 6462.0 samples/s | 101.0 steps/s
[Step=22750 Epoch=110.9] | Loss=0.01597 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.353 | L2-Norm(final)=9.021 | 2106.2 samples/s | 32.9 steps/s
[Step=22800 Epoch=111.2] | Loss=0.01651 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.373 | L2-Norm(final)=9.021 | 4400.0 samples/s | 68.8 steps/s
[Step=22850 Epoch=111.4] | Loss=0.01622 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.391 | L2-Norm(final)=9.021 | 4526.4 samples/s | 70.7 steps/s
[Step=22900 Epoch=111.7] | Loss=0.01598 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.409 | L2-Norm(final)=9.023 | 5866.1 samples/s | 91.7 steps/s
[Step=22950 Epoch=111.9] | Loss=0.01530 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.423 | L2-Norm(final)=9.025 | 2134.4 samples/s | 33.3 steps/s
[Step=23000 Epoch=112.2] | Loss=0.01459 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.434 | L2-Norm(final)=9.026 | 4444.1 samples/s | 69.4 steps/s
[Step=23050 Epoch=112.4] | Loss=0.01415 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.442 | L2-Norm(final)=9.027 | 4524.3 samples/s | 70.7 steps/s
[Step=23100 Epoch=112.6] | Loss=0.01359 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.448 | L2-Norm(final)=9.029 | 5378.2 samples/s | 84.0 steps/s
[Step=23150 Epoch=112.9] | Loss=0.01287 | Reg=0.00504 | acc=0.9688 | L2-Norm=22.452 | L2-Norm(final)=9.031 | 2255.2 samples/s | 35.2 steps/s
[Step=23200 Epoch=113.1] | Loss=0.01246 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.454 | L2-Norm(final)=9.033 | 4450.2 samples/s | 69.5 steps/s
[Step=23250 Epoch=113.4] | Loss=0.01196 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.456 | L2-Norm(final)=9.035 | 4411.2 samples/s | 68.9 steps/s
[Step=23300 Epoch=113.6] | Loss=0.01161 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.456 | L2-Norm(final)=9.037 | 4933.5 samples/s | 77.1 steps/s
[Step=23350 Epoch=113.9] | Loss=0.01119 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.454 | L2-Norm(final)=9.039 | 2355.7 samples/s | 36.8 steps/s
[Step=23400 Epoch=114.1] | Loss=0.01082 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.452 | L2-Norm(final)=9.041 | 4468.6 samples/s | 69.8 steps/s
[Step=23450 Epoch=114.3] | Loss=0.01043 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.449 | L2-Norm(final)=9.043 | 4479.1 samples/s | 70.0 steps/s
[Step=23500 Epoch=114.6] | Loss=0.01013 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.445 | L2-Norm(final)=9.045 | 4617.5 samples/s | 72.1 steps/s
[Step=23550 Epoch=114.8] | Loss=0.00992 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.441 | L2-Norm(final)=9.046 | 2451.7 samples/s | 38.3 steps/s
[Step=23600 Epoch=115.1] | Loss=0.00960 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.436 | L2-Norm(final)=9.048 | 4389.0 samples/s | 68.6 steps/s
[Step=23650 Epoch=115.3] | Loss=0.00936 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.430 | L2-Norm(final)=9.050 | 4457.7 samples/s | 69.7 steps/s
[Step=23700 Epoch=115.6] | Loss=0.00913 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.424 | L2-Norm(final)=9.051 | 4470.6 samples/s | 69.9 steps/s
[Step=23750 Epoch=115.8] | Loss=0.00886 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.417 | L2-Norm(final)=9.053 | 2496.6 samples/s | 39.0 steps/s
[Step=23800 Epoch=116.1] | Loss=0.00870 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.409 | L2-Norm(final)=9.055 | 4379.2 samples/s | 68.4 steps/s
[Step=23850 Epoch=116.3] | Loss=0.00847 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.402 | L2-Norm(final)=9.056 | 4445.2 samples/s | 69.5 steps/s
[Step=23900 Epoch=116.5] | Loss=0.00834 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.393 | L2-Norm(final)=9.058 | 4449.8 samples/s | 69.5 steps/s
[Step=23950 Epoch=116.8] | Loss=0.00818 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.385 | L2-Norm(final)=9.059 | 2462.4 samples/s | 38.5 steps/s
[Step=24000 Epoch=117.0] | Loss=0.00800 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.376 | L2-Norm(final)=9.060 | 4373.5 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step24000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=107.4] | Loss=0.00218 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.627 | L2-Norm(final)=8.816 | 4897.2 samples/s | 76.5 steps/s
[Step=22050 Epoch=107.6] | Loss=0.00376 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.616 | L2-Norm(final)=8.828 | 4862.7 samples/s | 76.0 steps/s
[Step=22100 Epoch=107.8] | Loss=0.00478 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.606 | L2-Norm(final)=8.841 | 5038.2 samples/s | 78.7 steps/s
[Step=22150 Epoch=108.1] | Loss=0.00459 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.599 | L2-Norm(final)=8.854 | 5289.2 samples/s | 82.6 steps/s
[Step=22200 Epoch=108.3] | Loss=0.00469 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.590 | L2-Norm(final)=8.867 | 7406.7 samples/s | 115.7 steps/s
[Step=22250 Epoch=108.6] | Loss=0.00437 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.581 | L2-Norm(final)=8.880 | 2206.0 samples/s | 34.5 steps/s
[Step=22300 Epoch=108.8] | Loss=0.00429 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.571 | L2-Norm(final)=8.893 | 5041.8 samples/s | 78.8 steps/s
[Step=22350 Epoch=109.1] | Loss=0.00423 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.561 | L2-Norm(final)=8.906 | 4947.5 samples/s | 77.3 steps/s
[Step=22400 Epoch=109.3] | Loss=0.00433 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.551 | L2-Norm(final)=8.918 | 7150.8 samples/s | 111.7 steps/s
[Step=22450 Epoch=109.5] | Loss=0.00421 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.542 | L2-Norm(final)=8.930 | 2282.9 samples/s | 35.7 steps/s
[Step=22500 Epoch=109.8] | Loss=0.00410 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.532 | L2-Norm(final)=8.943 | 4995.5 samples/s | 78.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=109.8] | Loss=0.00693 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.427 | L2-Norm(final)=9.066 | 5149.8 samples/s | 80.5 steps/s
[Step=22550 Epoch=110.0] | Loss=0.00610 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.420 | L2-Norm(final)=9.075 | 4259.4 samples/s | 66.6 steps/s
[Step=22600 Epoch=110.3] | Loss=0.00819 | Reg=0.00503 | acc=1.0000 | L2-Norm=22.417 | L2-Norm(final)=9.076 | 4486.0 samples/s | 70.1 steps/s
[Step=22650 Epoch=110.5] | Loss=0.00987 | Reg=0.00503 | acc=0.9688 | L2-Norm=22.418 | L2-Norm(final)=9.079 | 4388.7 samples/s | 68.6 steps/s
[Step=22700 Epoch=110.8] | Loss=0.01145 | Reg=0.00503 | acc=0.9844 | L2-Norm=22.426 | L2-Norm(final)=9.078 | 6544.6 samples/s | 102.3 steps/s
[Step=22750 Epoch=111.0] | Loss=0.01130 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.439 | L2-Norm(final)=9.080 | 2085.2 samples/s | 32.6 steps/s
[Step=22800 Epoch=111.3] | Loss=0.01156 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.452 | L2-Norm(final)=9.083 | 4526.3 samples/s | 70.7 steps/s
[Step=22850 Epoch=111.5] | Loss=0.01174 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.464 | L2-Norm(final)=9.087 | 4459.8 samples/s | 69.7 steps/s
[Step=22900 Epoch=111.7] | Loss=0.01208 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.476 | L2-Norm(final)=9.089 | 5991.9 samples/s | 93.6 steps/s
[Step=22950 Epoch=112.0] | Loss=0.01216 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.488 | L2-Norm(final)=9.090 | 2146.1 samples/s | 33.5 steps/s
[Step=23000 Epoch=112.2] | Loss=0.01194 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.499 | L2-Norm(final)=9.092 | 4391.3 samples/s | 68.6 steps/s
[Step=23050 Epoch=112.5] | Loss=0.01208 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.510 | L2-Norm(final)=9.094 | 4456.3 samples/s | 69.6 steps/s
[Step=23100 Epoch=112.7] | Loss=0.01171 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.519 | L2-Norm(final)=9.096 | 5618.9 samples/s | 87.8 steps/s
[Step=23150 Epoch=113.0] | Loss=0.01136 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.527 | L2-Norm(final)=9.099 | 2229.0 samples/s | 34.8 steps/s
[Step=23200 Epoch=113.2] | Loss=0.01090 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.533 | L2-Norm(final)=9.102 | 4383.5 samples/s | 68.5 steps/s
[Step=23250 Epoch=113.4] | Loss=0.01056 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.537 | L2-Norm(final)=9.105 | 4449.7 samples/s | 69.5 steps/s
[Step=23300 Epoch=113.7] | Loss=0.01036 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.539 | L2-Norm(final)=9.108 | 5207.9 samples/s | 81.4 steps/s
[Step=23350 Epoch=113.9] | Loss=0.01019 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.541 | L2-Norm(final)=9.110 | 2289.1 samples/s | 35.8 steps/s
[Step=23400 Epoch=114.2] | Loss=0.00988 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.541 | L2-Norm(final)=9.112 | 4354.2 samples/s | 68.0 steps/s
[Step=23450 Epoch=114.4] | Loss=0.00962 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.541 | L2-Norm(final)=9.114 | 4453.3 samples/s | 69.6 steps/s
[Step=23500 Epoch=114.7] | Loss=0.00935 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.539 | L2-Norm(final)=9.116 | 4888.8 samples/s | 76.4 steps/s
[Step=23550 Epoch=114.9] | Loss=0.00915 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.536 | L2-Norm(final)=9.117 | 2357.5 samples/s | 36.8 steps/s
[Step=23600 Epoch=115.2] | Loss=0.00892 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.533 | L2-Norm(final)=9.119 | 4448.6 samples/s | 69.5 steps/s
[Step=23650 Epoch=115.4] | Loss=0.00873 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.529 | L2-Norm(final)=9.121 | 4446.3 samples/s | 69.5 steps/s
[Step=23700 Epoch=115.6] | Loss=0.00854 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.524 | L2-Norm(final)=9.122 | 4526.1 samples/s | 70.7 steps/s
[Step=23750 Epoch=115.9] | Loss=0.00828 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.518 | L2-Norm(final)=9.124 | 2428.2 samples/s | 37.9 steps/s
[Step=23800 Epoch=116.1] | Loss=0.00809 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.512 | L2-Norm(final)=9.126 | 4500.2 samples/s | 70.3 steps/s
[Step=23850 Epoch=116.4] | Loss=0.00796 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.505 | L2-Norm(final)=9.127 | 4393.1 samples/s | 68.6 steps/s
[Step=23900 Epoch=116.6] | Loss=0.00783 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.498 | L2-Norm(final)=9.129 | 4469.0 samples/s | 69.8 steps/s
[Step=23950 Epoch=116.9] | Loss=0.00763 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.490 | L2-Norm(final)=9.130 | 2448.7 samples/s | 38.3 steps/s
[Step=24000 Epoch=117.1] | Loss=0.00746 | Reg=0.00505 | acc=0.9844 | L2-Norm=22.482 | L2-Norm(final)=9.132 | 4503.8 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step24000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=107.2] | Loss=0.00563 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.668 | L2-Norm(final)=9.269 | 5426.6 samples/s | 84.8 steps/s
[Step=22050 Epoch=107.4] | Loss=0.00573 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.660 | L2-Norm(final)=9.279 | 4334.4 samples/s | 67.7 steps/s
[Step=22100 Epoch=107.7] | Loss=0.00551 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.652 | L2-Norm(final)=9.292 | 5109.8 samples/s | 79.8 steps/s
[Step=22150 Epoch=107.9] | Loss=0.00554 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.646 | L2-Norm(final)=9.305 | 4935.9 samples/s | 77.1 steps/s
[Step=22200 Epoch=108.2] | Loss=0.00611 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.639 | L2-Norm(final)=9.317 | 7713.7 samples/s | 120.5 steps/s
[Step=22250 Epoch=108.4] | Loss=0.00605 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.633 | L2-Norm(final)=9.329 | 2246.8 samples/s | 35.1 steps/s
[Step=22300 Epoch=108.7] | Loss=0.00572 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.626 | L2-Norm(final)=9.342 | 4990.9 samples/s | 78.0 steps/s
[Step=22350 Epoch=108.9] | Loss=0.00563 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.618 | L2-Norm(final)=9.355 | 5040.9 samples/s | 78.8 steps/s
[Step=22400 Epoch=109.1] | Loss=0.00548 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.610 | L2-Norm(final)=9.368 | 6866.4 samples/s | 107.3 steps/s
[Step=22450 Epoch=109.4] | Loss=0.00527 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.602 | L2-Norm(final)=9.381 | 2255.6 samples/s | 35.2 steps/s
[Step=22500 Epoch=109.6] | Loss=0.00521 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.594 | L2-Norm(final)=9.394 | 5158.2 samples/s | 80.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=109.6] | Loss=0.00049 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.510 | L2-Norm(final)=9.526 | 5205.8 samples/s | 81.3 steps/s
[Step=22550 Epoch=109.9] | Loss=0.00774 | Reg=0.00506 | acc=0.9844 | L2-Norm=22.503 | L2-Norm(final)=9.536 | 4163.7 samples/s | 65.1 steps/s
[Step=22600 Epoch=110.1] | Loss=0.01140 | Reg=0.00507 | acc=0.9844 | L2-Norm=22.510 | L2-Norm(final)=9.537 | 4453.8 samples/s | 69.6 steps/s
[Step=22650 Epoch=110.4] | Loss=0.01336 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.531 | L2-Norm(final)=9.538 | 4475.6 samples/s | 69.9 steps/s
[Step=22700 Epoch=110.6] | Loss=0.01601 | Reg=0.00509 | acc=0.9688 | L2-Norm=22.554 | L2-Norm(final)=9.540 | 6516.8 samples/s | 101.8 steps/s
[Step=22750 Epoch=110.8] | Loss=0.01662 | Reg=0.00510 | acc=0.9844 | L2-Norm=22.580 | L2-Norm(final)=9.540 | 2066.8 samples/s | 32.3 steps/s
[Step=22800 Epoch=111.1] | Loss=0.01588 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.601 | L2-Norm(final)=9.541 | 4536.0 samples/s | 70.9 steps/s
[Step=22850 Epoch=111.3] | Loss=0.01523 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.616 | L2-Norm(final)=9.545 | 4393.0 samples/s | 68.6 steps/s
[Step=22900 Epoch=111.6] | Loss=0.01483 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.627 | L2-Norm(final)=9.548 | 5938.1 samples/s | 92.8 steps/s
[Step=22950 Epoch=111.8] | Loss=0.01443 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.637 | L2-Norm(final)=9.551 | 2152.2 samples/s | 33.6 steps/s
[Step=23000 Epoch=112.1] | Loss=0.01404 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.646 | L2-Norm(final)=9.554 | 4507.5 samples/s | 70.4 steps/s
[Step=23050 Epoch=112.3] | Loss=0.01368 | Reg=0.00513 | acc=0.9844 | L2-Norm=22.653 | L2-Norm(final)=9.556 | 4497.1 samples/s | 70.3 steps/s
[Step=23100 Epoch=112.6] | Loss=0.01318 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.659 | L2-Norm(final)=9.559 | 5174.1 samples/s | 80.8 steps/s
[Step=23150 Epoch=112.8] | Loss=0.01266 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.664 | L2-Norm(final)=9.562 | 2244.7 samples/s | 35.1 steps/s
[Step=23200 Epoch=113.0] | Loss=0.01212 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.666 | L2-Norm(final)=9.565 | 4504.0 samples/s | 70.4 steps/s
[Step=23250 Epoch=113.3] | Loss=0.01176 | Reg=0.00514 | acc=0.9688 | L2-Norm=22.668 | L2-Norm(final)=9.568 | 4598.0 samples/s | 71.8 steps/s
[Step=23300 Epoch=113.5] | Loss=0.01149 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.668 | L2-Norm(final)=9.571 | 4789.7 samples/s | 74.8 steps/s
[Step=23350 Epoch=113.8] | Loss=0.01115 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.668 | L2-Norm(final)=9.574 | 2349.1 samples/s | 36.7 steps/s
[Step=23400 Epoch=114.0] | Loss=0.01079 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.667 | L2-Norm(final)=9.577 | 4473.7 samples/s | 69.9 steps/s
[Step=23450 Epoch=114.3] | Loss=0.01043 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.664 | L2-Norm(final)=9.580 | 4410.5 samples/s | 68.9 steps/s
[Step=23500 Epoch=114.5] | Loss=0.01017 | Reg=0.00514 | acc=1.0000 | L2-Norm=22.661 | L2-Norm(final)=9.582 | 4550.0 samples/s | 71.1 steps/s
[Step=23550 Epoch=114.7] | Loss=0.00993 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.657 | L2-Norm(final)=9.584 | 2414.6 samples/s | 37.7 steps/s
[Step=23600 Epoch=115.0] | Loss=0.00964 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.653 | L2-Norm(final)=9.587 | 4517.3 samples/s | 70.6 steps/s
[Step=23650 Epoch=115.2] | Loss=0.00939 | Reg=0.00513 | acc=1.0000 | L2-Norm=22.647 | L2-Norm(final)=9.589 | 4450.4 samples/s | 69.5 steps/s
[Step=23700 Epoch=115.5] | Loss=0.00930 | Reg=0.00513 | acc=0.9844 | L2-Norm=22.641 | L2-Norm(final)=9.591 | 4507.8 samples/s | 70.4 steps/s
[Step=23750 Epoch=115.7] | Loss=0.00914 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.635 | L2-Norm(final)=9.593 | 2426.7 samples/s | 37.9 steps/s
[Step=23800 Epoch=116.0] | Loss=0.00891 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.628 | L2-Norm(final)=9.595 | 4518.3 samples/s | 70.6 steps/s
[Step=23850 Epoch=116.2] | Loss=0.00879 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.621 | L2-Norm(final)=9.596 | 4369.6 samples/s | 68.3 steps/s
[Step=23900 Epoch=116.5] | Loss=0.00866 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.613 | L2-Norm(final)=9.598 | 4482.7 samples/s | 70.0 steps/s
[Step=23950 Epoch=116.7] | Loss=0.00849 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.605 | L2-Norm(final)=9.600 | 2460.9 samples/s | 38.5 steps/s
[Step=24000 Epoch=116.9] | Loss=0.00829 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.597 | L2-Norm(final)=9.602 | 4451.1 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step24000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=107.3] | Loss=0.00234 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.632 | L2-Norm(final)=9.001 | 5398.6 samples/s | 84.4 steps/s
[Step=22050 Epoch=107.5] | Loss=0.00404 | Reg=0.00512 | acc=1.0000 | L2-Norm=22.624 | L2-Norm(final)=9.013 | 4413.0 samples/s | 69.0 steps/s
[Step=22100 Epoch=107.8] | Loss=0.00491 | Reg=0.00512 | acc=0.9844 | L2-Norm=22.618 | L2-Norm(final)=9.025 | 4962.7 samples/s | 77.5 steps/s
[Step=22150 Epoch=108.0] | Loss=0.00513 | Reg=0.00511 | acc=1.0000 | L2-Norm=22.611 | L2-Norm(final)=9.037 | 4995.7 samples/s | 78.1 steps/s
[Step=22200 Epoch=108.3] | Loss=0.00526 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.604 | L2-Norm(final)=9.049 | 7830.3 samples/s | 122.3 steps/s
[Step=22250 Epoch=108.5] | Loss=0.00512 | Reg=0.00511 | acc=0.9844 | L2-Norm=22.598 | L2-Norm(final)=9.062 | 2225.5 samples/s | 34.8 steps/s
[Step=22300 Epoch=108.7] | Loss=0.00498 | Reg=0.00510 | acc=0.9688 | L2-Norm=22.591 | L2-Norm(final)=9.075 | 5066.3 samples/s | 79.2 steps/s
[Step=22350 Epoch=109.0] | Loss=0.00487 | Reg=0.00510 | acc=0.9844 | L2-Norm=22.583 | L2-Norm(final)=9.088 | 4987.0 samples/s | 77.9 steps/s
[Step=22400 Epoch=109.2] | Loss=0.00476 | Reg=0.00510 | acc=1.0000 | L2-Norm=22.575 | L2-Norm(final)=9.101 | 6859.0 samples/s | 107.2 steps/s
[Step=22450 Epoch=109.5] | Loss=0.00463 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.566 | L2-Norm(final)=9.114 | 2291.2 samples/s | 35.8 steps/s
[Step=22500 Epoch=109.7] | Loss=0.00458 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.558 | L2-Norm(final)=9.126 | 4983.5 samples/s | 77.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=109.7] | Loss=0.01119 | Reg=0.00505 | acc=0.9844 | L2-Norm=22.465 | L2-Norm(final)=9.251 | 5798.2 samples/s | 90.6 steps/s
[Step=22550 Epoch=110.0] | Loss=0.00598 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.457 | L2-Norm(final)=9.261 | 3803.0 samples/s | 59.4 steps/s
[Step=22600 Epoch=110.2] | Loss=0.00784 | Reg=0.00504 | acc=1.0000 | L2-Norm=22.451 | L2-Norm(final)=9.263 | 4506.1 samples/s | 70.4 steps/s
[Step=22650 Epoch=110.5] | Loss=0.00968 | Reg=0.00504 | acc=0.9844 | L2-Norm=22.451 | L2-Norm(final)=9.265 | 4422.3 samples/s | 69.1 steps/s
[Step=22700 Epoch=110.7] | Loss=0.01098 | Reg=0.00505 | acc=1.0000 | L2-Norm=22.461 | L2-Norm(final)=9.266 | 6552.0 samples/s | 102.4 steps/s
[Step=22750 Epoch=110.9] | Loss=0.01083 | Reg=0.00505 | acc=0.9688 | L2-Norm=22.472 | L2-Norm(final)=9.269 | 2104.6 samples/s | 32.9 steps/s
[Step=22800 Epoch=111.2] | Loss=0.01096 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.484 | L2-Norm(final)=9.272 | 4309.8 samples/s | 67.3 steps/s
[Step=22850 Epoch=111.4] | Loss=0.01088 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.495 | L2-Norm(final)=9.277 | 4482.5 samples/s | 70.0 steps/s
[Step=22900 Epoch=111.7] | Loss=0.01170 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.507 | L2-Norm(final)=9.279 | 5907.2 samples/s | 92.3 steps/s
[Step=22950 Epoch=111.9] | Loss=0.01186 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.519 | L2-Norm(final)=9.282 | 2166.6 samples/s | 33.9 steps/s
[Step=23000 Epoch=112.2] | Loss=0.01154 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.530 | L2-Norm(final)=9.285 | 4484.0 samples/s | 70.1 steps/s
[Step=23050 Epoch=112.4] | Loss=0.01111 | Reg=0.00508 | acc=0.9844 | L2-Norm=22.539 | L2-Norm(final)=9.289 | 4503.2 samples/s | 70.4 steps/s
[Step=23100 Epoch=112.6] | Loss=0.01088 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.546 | L2-Norm(final)=9.293 | 5384.6 samples/s | 84.1 steps/s
[Step=23150 Epoch=112.9] | Loss=0.01061 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.553 | L2-Norm(final)=9.296 | 2274.4 samples/s | 35.5 steps/s
[Step=23200 Epoch=113.1] | Loss=0.01013 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.558 | L2-Norm(final)=9.300 | 4333.5 samples/s | 67.7 steps/s
[Step=23250 Epoch=113.4] | Loss=0.00988 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.561 | L2-Norm(final)=9.303 | 4453.5 samples/s | 69.6 steps/s
[Step=23300 Epoch=113.6] | Loss=0.00953 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.563 | L2-Norm(final)=9.306 | 4950.6 samples/s | 77.4 steps/s
[Step=23350 Epoch=113.9] | Loss=0.00929 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.563 | L2-Norm(final)=9.310 | 2317.7 samples/s | 36.2 steps/s
[Step=23400 Epoch=114.1] | Loss=0.00912 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.563 | L2-Norm(final)=9.313 | 4507.8 samples/s | 70.4 steps/s
[Step=23450 Epoch=114.4] | Loss=0.00882 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.561 | L2-Norm(final)=9.316 | 4507.8 samples/s | 70.4 steps/s
[Step=23500 Epoch=114.6] | Loss=0.00862 | Reg=0.00509 | acc=0.9688 | L2-Norm=22.559 | L2-Norm(final)=9.319 | 4550.3 samples/s | 71.1 steps/s
[Step=23550 Epoch=114.8] | Loss=0.00837 | Reg=0.00509 | acc=0.9844 | L2-Norm=22.555 | L2-Norm(final)=9.322 | 2352.8 samples/s | 36.8 steps/s
[Step=23600 Epoch=115.1] | Loss=0.00814 | Reg=0.00509 | acc=1.0000 | L2-Norm=22.551 | L2-Norm(final)=9.325 | 4514.5 samples/s | 70.5 steps/s
[Step=23650 Epoch=115.3] | Loss=0.00790 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.546 | L2-Norm(final)=9.328 | 4408.8 samples/s | 68.9 steps/s
[Step=23700 Epoch=115.6] | Loss=0.00769 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.540 | L2-Norm(final)=9.331 | 4446.4 samples/s | 69.5 steps/s
[Step=23750 Epoch=115.8] | Loss=0.00747 | Reg=0.00508 | acc=1.0000 | L2-Norm=22.533 | L2-Norm(final)=9.334 | 2472.0 samples/s | 38.6 steps/s
[Step=23800 Epoch=116.1] | Loss=0.00731 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.526 | L2-Norm(final)=9.337 | 4592.3 samples/s | 71.8 steps/s
[Step=23850 Epoch=116.3] | Loss=0.00715 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.518 | L2-Norm(final)=9.339 | 4359.4 samples/s | 68.1 steps/s
[Step=23900 Epoch=116.5] | Loss=0.00705 | Reg=0.00507 | acc=1.0000 | L2-Norm=22.510 | L2-Norm(final)=9.341 | 4428.3 samples/s | 69.2 steps/s
[Step=23950 Epoch=116.8] | Loss=0.00693 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.502 | L2-Norm(final)=9.344 | 2430.6 samples/s | 38.0 steps/s
[Step=24000 Epoch=117.0] | Loss=0.00675 | Reg=0.00506 | acc=1.0000 | L2-Norm=22.493 | L2-Norm(final)=9.346 | 4493.1 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step24000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=107.9] | Loss=0.02944 | Reg=0.00501 | acc=0.9531 | L2-Norm=22.372 | L2-Norm(final)=9.169 | 5556.9 samples/s | 86.8 steps/s
[Step=22050 Epoch=108.1] | Loss=0.00528 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.364 | L2-Norm(final)=9.180 | 4251.7 samples/s | 66.4 steps/s
[Step=22100 Epoch=108.4] | Loss=0.00486 | Reg=0.00500 | acc=0.9688 | L2-Norm=22.359 | L2-Norm(final)=9.193 | 4954.0 samples/s | 77.4 steps/s
[Step=22150 Epoch=108.6] | Loss=0.00500 | Reg=0.00500 | acc=0.9844 | L2-Norm=22.352 | L2-Norm(final)=9.202 | 5041.2 samples/s | 78.8 steps/s
[Step=22200 Epoch=108.9] | Loss=0.00496 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.346 | L2-Norm(final)=9.212 | 7990.1 samples/s | 124.8 steps/s
[Step=22250 Epoch=109.1] | Loss=0.00467 | Reg=0.00499 | acc=0.9844 | L2-Norm=22.340 | L2-Norm(final)=9.223 | 2139.4 samples/s | 33.4 steps/s
[Step=22300 Epoch=109.4] | Loss=0.00466 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.332 | L2-Norm(final)=9.234 | 5047.3 samples/s | 78.9 steps/s
[Step=22350 Epoch=109.6] | Loss=0.00461 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.324 | L2-Norm(final)=9.246 | 5027.5 samples/s | 78.6 steps/s
[Step=22400 Epoch=109.8] | Loss=0.00443 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.316 | L2-Norm(final)=9.258 | 7460.5 samples/s | 116.6 steps/s
[Step=22450 Epoch=110.1] | Loss=0.00426 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.306 | L2-Norm(final)=9.269 | 2255.6 samples/s | 35.2 steps/s
[Step=22500 Epoch=110.3] | Loss=0.00421 | Reg=0.00497 | acc=0.9844 | L2-Norm=22.297 | L2-Norm(final)=9.280 | 5067.3 samples/s | 79.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=110.3] | Loss=0.00901 | Reg=0.00493 | acc=0.9844 | L2-Norm=22.196 | L2-Norm(final)=9.391 | 5255.6 samples/s | 82.1 steps/s
[Step=22550 Epoch=110.6] | Loss=0.00599 | Reg=0.00492 | acc=0.9844 | L2-Norm=22.190 | L2-Norm(final)=9.399 | 4014.8 samples/s | 62.7 steps/s
[Step=22600 Epoch=110.8] | Loss=0.01450 | Reg=0.00493 | acc=0.9844 | L2-Norm=22.212 | L2-Norm(final)=9.400 | 4493.9 samples/s | 70.2 steps/s
[Step=22650 Epoch=111.1] | Loss=0.01913 | Reg=0.00495 | acc=0.9844 | L2-Norm=22.259 | L2-Norm(final)=9.395 | 4469.7 samples/s | 69.8 steps/s
[Step=22700 Epoch=111.3] | Loss=0.02183 | Reg=0.00497 | acc=0.9844 | L2-Norm=22.304 | L2-Norm(final)=9.388 | 6758.3 samples/s | 105.6 steps/s
[Step=22750 Epoch=111.6] | Loss=0.02045 | Reg=0.00499 | acc=0.9844 | L2-Norm=22.338 | L2-Norm(final)=9.383 | 2074.5 samples/s | 32.4 steps/s
[Step=22800 Epoch=111.8] | Loss=0.01927 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.361 | L2-Norm(final)=9.381 | 4506.9 samples/s | 70.4 steps/s
[Step=22850 Epoch=112.1] | Loss=0.01810 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.378 | L2-Norm(final)=9.381 | 4399.2 samples/s | 68.7 steps/s
[Step=22900 Epoch=112.3] | Loss=0.01729 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.390 | L2-Norm(final)=9.382 | 6170.0 samples/s | 96.4 steps/s
[Step=22950 Epoch=112.5] | Loss=0.01614 | Reg=0.00502 | acc=0.9688 | L2-Norm=22.399 | L2-Norm(final)=9.383 | 2076.3 samples/s | 32.4 steps/s
[Step=23000 Epoch=112.8] | Loss=0.01509 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.405 | L2-Norm(final)=9.385 | 4482.0 samples/s | 70.0 steps/s
[Step=23050 Epoch=113.0] | Loss=0.01422 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.408 | L2-Norm(final)=9.387 | 4554.8 samples/s | 71.2 steps/s
[Step=23100 Epoch=113.3] | Loss=0.01344 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.410 | L2-Norm(final)=9.389 | 5754.0 samples/s | 89.9 steps/s
[Step=23150 Epoch=113.5] | Loss=0.01273 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.410 | L2-Norm(final)=9.391 | 2167.3 samples/s | 33.9 steps/s
[Step=23200 Epoch=113.8] | Loss=0.01216 | Reg=0.00502 | acc=0.9844 | L2-Norm=22.408 | L2-Norm(final)=9.394 | 4438.6 samples/s | 69.4 steps/s
[Step=23250 Epoch=114.0] | Loss=0.01174 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.405 | L2-Norm(final)=9.396 | 4359.4 samples/s | 68.1 steps/s
[Step=23300 Epoch=114.3] | Loss=0.01131 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.402 | L2-Norm(final)=9.398 | 5519.9 samples/s | 86.2 steps/s
[Step=23350 Epoch=114.5] | Loss=0.01095 | Reg=0.00502 | acc=1.0000 | L2-Norm=22.397 | L2-Norm(final)=9.400 | 2211.9 samples/s | 34.6 steps/s
[Step=23400 Epoch=114.7] | Loss=0.01066 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.392 | L2-Norm(final)=9.402 | 4548.9 samples/s | 71.1 steps/s
[Step=23450 Epoch=115.0] | Loss=0.01030 | Reg=0.00501 | acc=0.9844 | L2-Norm=22.387 | L2-Norm(final)=9.404 | 4429.1 samples/s | 69.2 steps/s
[Step=23500 Epoch=115.2] | Loss=0.00995 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.381 | L2-Norm(final)=9.406 | 5179.1 samples/s | 80.9 steps/s
[Step=23550 Epoch=115.5] | Loss=0.00961 | Reg=0.00501 | acc=1.0000 | L2-Norm=22.374 | L2-Norm(final)=9.408 | 2312.4 samples/s | 36.1 steps/s
[Step=23600 Epoch=115.7] | Loss=0.00932 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.367 | L2-Norm(final)=9.410 | 4331.3 samples/s | 67.7 steps/s
[Step=23650 Epoch=116.0] | Loss=0.00908 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.360 | L2-Norm(final)=9.412 | 4438.0 samples/s | 69.3 steps/s
[Step=23700 Epoch=116.2] | Loss=0.00890 | Reg=0.00500 | acc=1.0000 | L2-Norm=22.352 | L2-Norm(final)=9.413 | 4923.8 samples/s | 76.9 steps/s
[Step=23750 Epoch=116.5] | Loss=0.00873 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.344 | L2-Norm(final)=9.415 | 2362.0 samples/s | 36.9 steps/s
[Step=23800 Epoch=116.7] | Loss=0.00852 | Reg=0.00499 | acc=1.0000 | L2-Norm=22.335 | L2-Norm(final)=9.417 | 4467.3 samples/s | 69.8 steps/s
[Step=23850 Epoch=117.0] | Loss=0.00827 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.326 | L2-Norm(final)=9.419 | 4430.9 samples/s | 69.2 steps/s
[Step=23900 Epoch=117.2] | Loss=0.00803 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.317 | L2-Norm(final)=9.420 | 4699.5 samples/s | 73.4 steps/s
[Step=23950 Epoch=117.4] | Loss=0.00792 | Reg=0.00498 | acc=1.0000 | L2-Norm=22.307 | L2-Norm(final)=9.422 | 2381.6 samples/s | 37.2 steps/s
[Step=24000 Epoch=117.7] | Loss=0.00771 | Reg=0.00497 | acc=1.0000 | L2-Norm=22.298 | L2-Norm(final)=9.424 | 4391.8 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step24000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=208.5] | Loss=0.00328 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.226 | L2-Norm(final)=5.372 | 5966.0 samples/s | 93.2 steps/s
[Step=22050 Epoch=208.9] | Loss=0.00017 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.231 | L2-Norm(final)=5.380 | 3910.4 samples/s | 61.1 steps/s
[Step=22100 Epoch=209.4] | Loss=0.00012 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.231 | L2-Norm(final)=5.385 | 7345.8 samples/s | 114.8 steps/s
[Step=22150 Epoch=209.9] | Loss=0.00009 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.229 | L2-Norm(final)=5.389 | 2115.7 samples/s | 33.1 steps/s
[Step=22200 Epoch=210.4] | Loss=0.00008 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.227 | L2-Norm(final)=5.393 | 6482.4 samples/s | 101.3 steps/s
[Step=22250 Epoch=210.8] | Loss=0.00008 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.224 | L2-Norm(final)=5.396 | 2190.3 samples/s | 34.2 steps/s
[Step=22300 Epoch=211.3] | Loss=0.00007 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.221 | L2-Norm(final)=5.400 | 5870.2 samples/s | 91.7 steps/s
[Step=22350 Epoch=211.8] | Loss=0.00007 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.219 | L2-Norm(final)=5.404 | 2360.6 samples/s | 36.9 steps/s
[Step=22400 Epoch=212.3] | Loss=0.00006 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.215 | L2-Norm(final)=5.407 | 5126.1 samples/s | 80.1 steps/s
[Step=22450 Epoch=212.7] | Loss=0.00006 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.212 | L2-Norm(final)=5.411 | 2457.2 samples/s | 38.4 steps/s
[Step=22500 Epoch=213.2] | Loss=0.00006 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.208 | L2-Norm(final)=5.414 | 4813.6 samples/s | 75.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=213.2] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.172 | L2-Norm(final)=5.448 | 5336.0 samples/s | 83.4 steps/s
[Step=22550 Epoch=213.7] | Loss=0.00003 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.159 | L2-Norm(final)=5.452 | 3700.9 samples/s | 57.8 steps/s
[Step=22600 Epoch=214.2] | Loss=0.00002 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.141 | L2-Norm(final)=5.454 | 6163.4 samples/s | 96.3 steps/s
[Step=22650 Epoch=214.6] | Loss=0.00002 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.122 | L2-Norm(final)=5.456 | 2016.4 samples/s | 31.5 steps/s
[Step=22700 Epoch=215.1] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.102 | L2-Norm(final)=5.457 | 5635.0 samples/s | 88.0 steps/s
[Step=22750 Epoch=215.6] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.081 | L2-Norm(final)=5.458 | 2103.3 samples/s | 32.9 steps/s
[Step=22800 Epoch=216.0] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.060 | L2-Norm(final)=5.459 | 5142.3 samples/s | 80.3 steps/s
[Step=22850 Epoch=216.5] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.039 | L2-Norm(final)=5.459 | 2135.2 samples/s | 33.4 steps/s
[Step=22900 Epoch=217.0] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.018 | L2-Norm(final)=5.460 | 4754.1 samples/s | 74.3 steps/s
[Step=22950 Epoch=217.5] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.997 | L2-Norm(final)=5.461 | 2290.1 samples/s | 35.8 steps/s
[Step=23000 Epoch=217.9] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.976 | L2-Norm(final)=5.461 | 4266.5 samples/s | 66.7 steps/s
[Step=23050 Epoch=218.4] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=5.462 | 2345.5 samples/s | 36.6 steps/s
[Step=23100 Epoch=218.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.933 | L2-Norm(final)=5.462 | 4224.8 samples/s | 66.0 steps/s
[Step=23150 Epoch=219.4] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.912 | L2-Norm(final)=5.463 | 2347.3 samples/s | 36.7 steps/s
[Step=23200 Epoch=219.8] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.890 | L2-Norm(final)=5.464 | 4233.9 samples/s | 66.2 steps/s
[Step=23250 Epoch=220.3] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.868 | L2-Norm(final)=5.464 | 2381.4 samples/s | 37.2 steps/s
[Step=23300 Epoch=220.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.846 | L2-Norm(final)=5.465 | 4219.2 samples/s | 65.9 steps/s
[Step=23350 Epoch=221.3] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.824 | L2-Norm(final)=5.465 | 2514.3 samples/s | 39.3 steps/s
[Step=23400 Epoch=221.7] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.802 | L2-Norm(final)=5.466 | 3904.2 samples/s | 61.0 steps/s
[Step=23450 Epoch=222.2] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.780 | L2-Norm(final)=5.466 | 6355.4 samples/s | 99.3 steps/s
[Step=23500 Epoch=222.7] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.758 | L2-Norm(final)=5.467 | 1993.0 samples/s | 31.1 steps/s
[Step=23550 Epoch=223.2] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.736 | L2-Norm(final)=5.468 | 5783.0 samples/s | 90.4 steps/s
[Step=23600 Epoch=223.6] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.713 | L2-Norm(final)=5.468 | 2053.0 samples/s | 32.1 steps/s
[Step=23650 Epoch=224.1] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.690 | L2-Norm(final)=5.469 | 5329.6 samples/s | 83.3 steps/s
[Step=23700 Epoch=224.6] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.668 | L2-Norm(final)=5.469 | 2112.6 samples/s | 33.0 steps/s
[Step=23750 Epoch=225.1] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.645 | L2-Norm(final)=5.470 | 4805.4 samples/s | 75.1 steps/s
[Step=23800 Epoch=225.5] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.622 | L2-Norm(final)=5.471 | 2238.7 samples/s | 35.0 steps/s
[Step=23850 Epoch=226.0] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.599 | L2-Norm(final)=5.471 | 4481.1 samples/s | 70.0 steps/s
[Step=23900 Epoch=226.5] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.575 | L2-Norm(final)=5.472 | 2332.7 samples/s | 36.4 steps/s
[Step=23950 Epoch=226.9] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.552 | L2-Norm(final)=5.472 | 4204.0 samples/s | 65.7 steps/s
[Step=24000 Epoch=227.4] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.529 | L2-Norm(final)=5.473 | 2384.9 samples/s | 37.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step24000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=209.3] | Loss=0.00018 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.003 | L2-Norm(final)=5.997 | 5774.0 samples/s | 90.2 steps/s
[Step=22050 Epoch=209.8] | Loss=0.00016 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.005 | L2-Norm(final)=6.000 | 3884.7 samples/s | 60.7 steps/s
[Step=22100 Epoch=210.2] | Loss=0.00011 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.004 | L2-Norm(final)=6.002 | 7500.3 samples/s | 117.2 steps/s
[Step=22150 Epoch=210.7] | Loss=0.00009 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.003 | L2-Norm(final)=6.005 | 2116.9 samples/s | 33.1 steps/s
[Step=22200 Epoch=211.2] | Loss=0.00008 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.002 | L2-Norm(final)=6.007 | 6646.4 samples/s | 103.8 steps/s
[Step=22250 Epoch=211.7] | Loss=0.00007 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.001 | L2-Norm(final)=6.010 | 2204.4 samples/s | 34.4 steps/s
[Step=22300 Epoch=212.1] | Loss=0.00007 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.000 | L2-Norm(final)=6.012 | 5858.0 samples/s | 91.5 steps/s
[Step=22350 Epoch=212.6] | Loss=0.00006 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.998 | L2-Norm(final)=6.014 | 2314.6 samples/s | 36.2 steps/s
[Step=22400 Epoch=213.1] | Loss=0.00006 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.997 | L2-Norm(final)=6.016 | 5253.4 samples/s | 82.1 steps/s
[Step=22450 Epoch=213.6] | Loss=0.00006 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.995 | L2-Norm(final)=6.018 | 2391.3 samples/s | 37.4 steps/s
[Step=22500 Epoch=214.0] | Loss=0.00005 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.994 | L2-Norm(final)=6.020 | 4917.0 samples/s | 76.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=214.0] | Loss=0.00002 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.977 | L2-Norm(final)=6.038 | 5629.4 samples/s | 88.0 steps/s
[Step=22550 Epoch=214.5] | Loss=0.00003 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.970 | L2-Norm(final)=6.040 | 3596.8 samples/s | 56.2 steps/s
[Step=22600 Epoch=215.0] | Loss=0.00002 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=6.041 | 6208.7 samples/s | 97.0 steps/s
[Step=22650 Epoch=215.5] | Loss=0.00002 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.951 | L2-Norm(final)=6.043 | 2056.1 samples/s | 32.1 steps/s
[Step=22700 Epoch=215.9] | Loss=0.00002 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.942 | L2-Norm(final)=6.044 | 5467.8 samples/s | 85.4 steps/s
[Step=22750 Epoch=216.4] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.932 | L2-Norm(final)=6.045 | 2115.1 samples/s | 33.0 steps/s
[Step=22800 Epoch=216.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.923 | L2-Norm(final)=6.046 | 5115.0 samples/s | 79.9 steps/s
[Step=22850 Epoch=217.4] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.913 | L2-Norm(final)=6.046 | 2170.0 samples/s | 33.9 steps/s
[Step=22900 Epoch=217.8] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.903 | L2-Norm(final)=6.047 | 4701.5 samples/s | 73.5 steps/s
[Step=22950 Epoch=218.3] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.893 | L2-Norm(final)=6.048 | 2256.6 samples/s | 35.3 steps/s
[Step=23000 Epoch=218.8] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.883 | L2-Norm(final)=6.048 | 4385.4 samples/s | 68.5 steps/s
[Step=23050 Epoch=219.3] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.873 | L2-Norm(final)=6.049 | 2347.8 samples/s | 36.7 steps/s
[Step=23100 Epoch=219.7] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.863 | L2-Norm(final)=6.049 | 4275.2 samples/s | 66.8 steps/s
[Step=23150 Epoch=220.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.853 | L2-Norm(final)=6.050 | 2381.9 samples/s | 37.2 steps/s
[Step=23200 Epoch=220.7] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.842 | L2-Norm(final)=6.050 | 4205.9 samples/s | 65.7 steps/s
[Step=23250 Epoch=221.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.832 | L2-Norm(final)=6.051 | 2411.9 samples/s | 37.7 steps/s
[Step=23300 Epoch=221.6] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.821 | L2-Norm(final)=6.051 | 4453.2 samples/s | 69.6 steps/s
[Step=23350 Epoch=222.1] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.810 | L2-Norm(final)=6.051 | 2600.7 samples/s | 40.6 steps/s
[Step=23400 Epoch=222.6] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.799 | L2-Norm(final)=6.052 | 3856.5 samples/s | 60.3 steps/s
[Step=23450 Epoch=223.1] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.788 | L2-Norm(final)=6.052 | 6441.0 samples/s | 100.6 steps/s
[Step=23500 Epoch=223.5] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.777 | L2-Norm(final)=6.052 | 1944.8 samples/s | 30.4 steps/s
[Step=23550 Epoch=224.0] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.766 | L2-Norm(final)=6.053 | 5853.3 samples/s | 91.5 steps/s
[Step=23600 Epoch=224.5] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.755 | L2-Norm(final)=6.053 | 2069.8 samples/s | 32.3 steps/s
[Step=23650 Epoch=225.0] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.744 | L2-Norm(final)=6.054 | 5320.0 samples/s | 83.1 steps/s
[Step=23700 Epoch=225.4] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.732 | L2-Norm(final)=6.054 | 2161.9 samples/s | 33.8 steps/s
[Step=23750 Epoch=225.9] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.721 | L2-Norm(final)=6.054 | 4783.6 samples/s | 74.7 steps/s
[Step=23800 Epoch=226.4] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.709 | L2-Norm(final)=6.055 | 2230.4 samples/s | 34.8 steps/s
[Step=23850 Epoch=226.9] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.697 | L2-Norm(final)=6.055 | 4475.4 samples/s | 69.9 steps/s
[Step=23900 Epoch=227.3] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.686 | L2-Norm(final)=6.055 | 2364.5 samples/s | 36.9 steps/s
[Step=23950 Epoch=227.8] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.674 | L2-Norm(final)=6.056 | 4216.0 samples/s | 65.9 steps/s
[Step=24000 Epoch=228.3] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.662 | L2-Norm(final)=6.056 | 2363.1 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step24000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=210.1] | Loss=0.00035 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.905 | L2-Norm(final)=5.935 | 5009.2 samples/s | 78.3 steps/s
[Step=22050 Epoch=210.6] | Loss=0.00027 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.922 | L2-Norm(final)=5.949 | 4301.8 samples/s | 67.2 steps/s
[Step=22100 Epoch=211.0] | Loss=0.00021 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.940 | L2-Norm(final)=5.968 | 7586.8 samples/s | 118.5 steps/s
[Step=22150 Epoch=211.5] | Loss=0.00016 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.950 | L2-Norm(final)=5.982 | 2120.4 samples/s | 33.1 steps/s
[Step=22200 Epoch=212.0] | Loss=0.00013 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=5.995 | 6818.0 samples/s | 106.5 steps/s
[Step=22250 Epoch=212.5] | Loss=0.00011 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.958 | L2-Norm(final)=6.006 | 2195.1 samples/s | 34.3 steps/s
[Step=22300 Epoch=213.0] | Loss=0.00010 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.958 | L2-Norm(final)=6.016 | 6090.9 samples/s | 95.2 steps/s
[Step=22350 Epoch=213.4] | Loss=0.00009 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.958 | L2-Norm(final)=6.025 | 2227.0 samples/s | 34.8 steps/s
[Step=22400 Epoch=213.9] | Loss=0.00008 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.957 | L2-Norm(final)=6.033 | 5672.0 samples/s | 88.6 steps/s
[Step=22450 Epoch=214.4] | Loss=0.00008 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=6.042 | 2365.3 samples/s | 37.0 steps/s
[Step=22500 Epoch=214.9] | Loss=0.00007 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.952 | L2-Norm(final)=6.050 | 4980.6 samples/s | 77.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=214.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.926 | L2-Norm(final)=6.131 | 5678.6 samples/s | 88.7 steps/s
[Step=22550 Epoch=215.3] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.901 | L2-Norm(final)=6.137 | 3742.1 samples/s | 58.5 steps/s
[Step=22600 Epoch=215.8] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.868 | L2-Norm(final)=6.141 | 6170.4 samples/s | 96.4 steps/s
[Step=22650 Epoch=216.3] | Loss=0.00684 | Reg=0.00142 | acc=0.9688 | L2-Norm=11.895 | L2-Norm(final)=6.131 | 1977.3 samples/s | 30.9 steps/s
[Step=22700 Epoch=216.8] | Loss=0.00654 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.985 | L2-Norm(final)=6.104 | 5852.0 samples/s | 91.4 steps/s
[Step=22750 Epoch=217.2] | Loss=0.00528 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.046 | L2-Norm(final)=6.087 | 2056.0 samples/s | 32.1 steps/s
[Step=22800 Epoch=217.7] | Loss=0.00440 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.086 | L2-Norm(final)=6.076 | 5367.5 samples/s | 83.9 steps/s
[Step=22850 Epoch=218.2] | Loss=0.00378 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.114 | L2-Norm(final)=6.069 | 2147.1 samples/s | 33.5 steps/s
[Step=22900 Epoch=218.7] | Loss=0.00331 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.133 | L2-Norm(final)=6.063 | 4854.9 samples/s | 75.9 steps/s
[Step=22950 Epoch=219.2] | Loss=0.00294 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.147 | L2-Norm(final)=6.059 | 2215.8 samples/s | 34.6 steps/s
[Step=23000 Epoch=219.6] | Loss=0.00265 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.158 | L2-Norm(final)=6.056 | 4526.6 samples/s | 70.7 steps/s
[Step=23050 Epoch=220.1] | Loss=0.00241 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.166 | L2-Norm(final)=6.053 | 2286.2 samples/s | 35.7 steps/s
[Step=23100 Epoch=220.6] | Loss=0.00221 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.172 | L2-Norm(final)=6.051 | 4317.0 samples/s | 67.5 steps/s
[Step=23150 Epoch=221.1] | Loss=0.00204 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.176 | L2-Norm(final)=6.049 | 2325.4 samples/s | 36.3 steps/s
[Step=23200 Epoch=221.5] | Loss=0.00189 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.179 | L2-Norm(final)=6.048 | 4133.5 samples/s | 64.6 steps/s
[Step=23250 Epoch=222.0] | Loss=0.00177 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.181 | L2-Norm(final)=6.046 | 2384.7 samples/s | 37.3 steps/s
[Step=23300 Epoch=222.5] | Loss=0.00166 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.182 | L2-Norm(final)=6.045 | 4252.2 samples/s | 66.4 steps/s
[Step=23350 Epoch=223.0] | Loss=0.00156 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.183 | L2-Norm(final)=6.044 | 2362.3 samples/s | 36.9 steps/s
[Step=23400 Epoch=223.5] | Loss=0.00147 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.183 | L2-Norm(final)=6.044 | 4389.6 samples/s | 68.6 steps/s
[Step=23450 Epoch=223.9] | Loss=0.00140 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.182 | L2-Norm(final)=6.043 | 2325.8 samples/s | 36.3 steps/s
[Step=23500 Epoch=224.4] | Loss=0.00133 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.181 | L2-Norm(final)=6.042 | 4170.1 samples/s | 65.2 steps/s
[Step=23550 Epoch=224.9] | Loss=0.00126 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.180 | L2-Norm(final)=6.042 | 7012.5 samples/s | 109.6 steps/s
[Step=23600 Epoch=225.4] | Loss=0.00121 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.178 | L2-Norm(final)=6.042 | 1968.4 samples/s | 30.8 steps/s
[Step=23650 Epoch=225.8] | Loss=0.00115 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.176 | L2-Norm(final)=6.041 | 6299.2 samples/s | 98.4 steps/s
[Step=23700 Epoch=226.3] | Loss=0.00111 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.174 | L2-Norm(final)=6.041 | 2023.1 samples/s | 31.6 steps/s
[Step=23750 Epoch=226.8] | Loss=0.00106 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.171 | L2-Norm(final)=6.041 | 5705.5 samples/s | 89.1 steps/s
[Step=23800 Epoch=227.3] | Loss=0.00102 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.168 | L2-Norm(final)=6.040 | 2038.0 samples/s | 31.8 steps/s
[Step=23850 Epoch=227.8] | Loss=0.00098 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.165 | L2-Norm(final)=6.040 | 5388.2 samples/s | 84.2 steps/s
[Step=23900 Epoch=228.2] | Loss=0.00095 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.162 | L2-Norm(final)=6.040 | 2132.6 samples/s | 33.3 steps/s
[Step=23950 Epoch=228.7] | Loss=0.00092 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.159 | L2-Norm(final)=6.040 | 4929.7 samples/s | 77.0 steps/s
[Step=24000 Epoch=229.2] | Loss=0.00089 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.156 | L2-Norm(final)=6.040 | 2193.8 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step24000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=207.3] | Loss=0.00017 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.090 | L2-Norm(final)=5.584 | 4977.0 samples/s | 77.8 steps/s
[Step=22050 Epoch=207.8] | Loss=0.00012 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.086 | L2-Norm(final)=5.594 | 4419.0 samples/s | 69.0 steps/s
[Step=22100 Epoch=208.2] | Loss=0.00013 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.090 | L2-Norm(final)=5.605 | 7019.6 samples/s | 109.7 steps/s
[Step=22150 Epoch=208.7] | Loss=0.00011 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.097 | L2-Norm(final)=5.618 | 2160.8 samples/s | 33.8 steps/s
[Step=22200 Epoch=209.2] | Loss=0.00010 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.101 | L2-Norm(final)=5.629 | 6440.9 samples/s | 100.6 steps/s
[Step=22250 Epoch=209.7] | Loss=0.00009 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.102 | L2-Norm(final)=5.638 | 2241.6 samples/s | 35.0 steps/s
[Step=22300 Epoch=210.1] | Loss=0.00008 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.102 | L2-Norm(final)=5.647 | 5624.3 samples/s | 87.9 steps/s
[Step=22350 Epoch=210.6] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.101 | L2-Norm(final)=5.655 | 2351.1 samples/s | 36.7 steps/s
[Step=22400 Epoch=211.1] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.099 | L2-Norm(final)=5.662 | 4978.4 samples/s | 77.8 steps/s
[Step=22450 Epoch=211.5] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.096 | L2-Norm(final)=5.669 | 2467.4 samples/s | 38.6 steps/s
[Step=22500 Epoch=212.0] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.093 | L2-Norm(final)=5.676 | 4846.1 samples/s | 75.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=212.0] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.064 | L2-Norm(final)=5.744 | 5554.0 samples/s | 86.8 steps/s
[Step=22550 Epoch=212.5] | Loss=0.00002 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.041 | L2-Norm(final)=5.750 | 3722.3 samples/s | 58.2 steps/s
[Step=22600 Epoch=213.0] | Loss=0.00002 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.008 | L2-Norm(final)=5.754 | 6158.2 samples/s | 96.2 steps/s
[Step=22650 Epoch=213.4] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.973 | L2-Norm(final)=5.756 | 2031.2 samples/s | 31.7 steps/s
[Step=22700 Epoch=213.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.936 | L2-Norm(final)=5.758 | 5409.0 samples/s | 84.5 steps/s
[Step=22750 Epoch=214.4] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.899 | L2-Norm(final)=5.759 | 2120.0 samples/s | 33.1 steps/s
[Step=22800 Epoch=214.8] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.862 | L2-Norm(final)=5.760 | 4941.2 samples/s | 77.2 steps/s
[Step=22850 Epoch=215.3] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.825 | L2-Norm(final)=5.761 | 2210.6 samples/s | 34.5 steps/s
[Step=22900 Epoch=215.8] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.788 | L2-Norm(final)=5.762 | 4513.3 samples/s | 70.5 steps/s
[Step=22950 Epoch=216.3] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.751 | L2-Norm(final)=5.762 | 2284.0 samples/s | 35.7 steps/s
[Step=23000 Epoch=216.7] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.713 | L2-Norm(final)=5.763 | 4174.0 samples/s | 65.2 steps/s
[Step=23050 Epoch=217.2] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.676 | L2-Norm(final)=5.764 | 2366.3 samples/s | 37.0 steps/s
[Step=23100 Epoch=217.7] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.639 | L2-Norm(final)=5.765 | 4243.0 samples/s | 66.3 steps/s
[Step=23150 Epoch=218.1] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.601 | L2-Norm(final)=5.765 | 2381.3 samples/s | 37.2 steps/s
[Step=23200 Epoch=218.6] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.564 | L2-Norm(final)=5.766 | 4186.5 samples/s | 65.4 steps/s
[Step=23250 Epoch=219.1] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.526 | L2-Norm(final)=5.767 | 2630.8 samples/s | 41.1 steps/s
[Step=23300 Epoch=219.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.489 | L2-Norm(final)=5.767 | 3717.4 samples/s | 58.1 steps/s
[Step=23350 Epoch=220.0] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.451 | L2-Norm(final)=5.768 | 6362.8 samples/s | 99.4 steps/s
[Step=23400 Epoch=220.5] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.414 | L2-Norm(final)=5.769 | 2033.2 samples/s | 31.8 steps/s
[Step=23450 Epoch=221.0] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.376 | L2-Norm(final)=5.770 | 5595.0 samples/s | 87.4 steps/s
[Step=23500 Epoch=221.4] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.338 | L2-Norm(final)=5.770 | 2092.6 samples/s | 32.7 steps/s
[Step=23550 Epoch=221.9] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=5.771 | 5029.2 samples/s | 78.6 steps/s
[Step=23600 Epoch=222.4] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.262 | L2-Norm(final)=5.772 | 2202.2 samples/s | 34.4 steps/s
[Step=23650 Epoch=222.9] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.224 | L2-Norm(final)=5.773 | 4581.5 samples/s | 71.6 steps/s
[Step=23700 Epoch=223.3] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.186 | L2-Norm(final)=5.774 | 2320.2 samples/s | 36.3 steps/s
[Step=23750 Epoch=223.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.148 | L2-Norm(final)=5.774 | 4272.8 samples/s | 66.8 steps/s
[Step=23800 Epoch=224.3] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.110 | L2-Norm(final)=5.775 | 2399.2 samples/s | 37.5 steps/s
[Step=23850 Epoch=224.7] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.071 | L2-Norm(final)=5.776 | 4189.9 samples/s | 65.5 steps/s
[Step=23900 Epoch=225.2] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.033 | L2-Norm(final)=5.777 | 2409.9 samples/s | 37.7 steps/s
[Step=23950 Epoch=225.7] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.994 | L2-Norm(final)=5.778 | 4267.0 samples/s | 66.7 steps/s
[Step=24000 Epoch=226.1] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.956 | L2-Norm(final)=5.779 | 2546.5 samples/s | 39.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step24000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=209.7] | Loss=0.00287 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.509 | L2-Norm(final)=6.596 | 5043.7 samples/s | 78.8 steps/s
[Step=22050 Epoch=210.2] | Loss=0.00031 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.511 | L2-Norm(final)=6.597 | 4170.7 samples/s | 65.2 steps/s
[Step=22100 Epoch=210.6] | Loss=0.00021 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.511 | L2-Norm(final)=6.600 | 7573.2 samples/s | 118.3 steps/s
[Step=22150 Epoch=211.1] | Loss=0.00017 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.510 | L2-Norm(final)=6.603 | 2105.2 samples/s | 32.9 steps/s
[Step=22200 Epoch=211.6] | Loss=0.00015 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.509 | L2-Norm(final)=6.606 | 6857.9 samples/s | 107.2 steps/s
[Step=22250 Epoch=212.1] | Loss=0.00013 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.508 | L2-Norm(final)=6.608 | 2190.6 samples/s | 34.2 steps/s
[Step=22300 Epoch=212.5] | Loss=0.00012 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.506 | L2-Norm(final)=6.611 | 6091.6 samples/s | 95.2 steps/s
[Step=22350 Epoch=213.0] | Loss=0.00012 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.505 | L2-Norm(final)=6.613 | 2251.4 samples/s | 35.2 steps/s
[Step=22400 Epoch=213.5] | Loss=0.00011 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.503 | L2-Norm(final)=6.615 | 5418.3 samples/s | 84.7 steps/s
[Step=22450 Epoch=214.0] | Loss=0.00010 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.501 | L2-Norm(final)=6.618 | 2363.1 samples/s | 36.9 steps/s
[Step=22500 Epoch=214.4] | Loss=0.00010 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.499 | L2-Norm(final)=6.620 | 5183.8 samples/s | 81.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=214.5] | Loss=0.00005 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.480 | L2-Norm(final)=6.641 | 5859.7 samples/s | 91.6 steps/s
[Step=22550 Epoch=214.9] | Loss=0.00004 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.475 | L2-Norm(final)=6.643 | 3571.5 samples/s | 55.8 steps/s
[Step=22600 Epoch=215.4] | Loss=0.00004 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.468 | L2-Norm(final)=6.645 | 6264.3 samples/s | 97.9 steps/s
[Step=22650 Epoch=215.9] | Loss=0.00003 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.461 | L2-Norm(final)=6.646 | 2018.3 samples/s | 31.5 steps/s
[Step=22700 Epoch=216.4] | Loss=0.00003 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.453 | L2-Norm(final)=6.647 | 5651.7 samples/s | 88.3 steps/s
[Step=22750 Epoch=216.8] | Loss=0.00002 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.445 | L2-Norm(final)=6.648 | 2089.4 samples/s | 32.6 steps/s
[Step=22800 Epoch=217.3] | Loss=0.00002 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.436 | L2-Norm(final)=6.649 | 5192.9 samples/s | 81.1 steps/s
[Step=22850 Epoch=217.8] | Loss=0.00002 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.428 | L2-Norm(final)=6.650 | 2168.7 samples/s | 33.9 steps/s
[Step=22900 Epoch=218.3] | Loss=0.00002 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.419 | L2-Norm(final)=6.650 | 4855.1 samples/s | 75.9 steps/s
[Step=22950 Epoch=218.7] | Loss=0.00002 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.410 | L2-Norm(final)=6.651 | 2189.0 samples/s | 34.2 steps/s
[Step=23000 Epoch=219.2] | Loss=0.00002 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.402 | L2-Norm(final)=6.651 | 4630.7 samples/s | 72.4 steps/s
[Step=23050 Epoch=219.7] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.393 | L2-Norm(final)=6.652 | 2281.4 samples/s | 35.6 steps/s
[Step=23100 Epoch=220.2] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.383 | L2-Norm(final)=6.652 | 4343.5 samples/s | 67.9 steps/s
[Step=23150 Epoch=220.6] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.374 | L2-Norm(final)=6.653 | 2358.5 samples/s | 36.9 steps/s
[Step=23200 Epoch=221.1] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.365 | L2-Norm(final)=6.653 | 4280.1 samples/s | 66.9 steps/s
[Step=23250 Epoch=221.6] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.356 | L2-Norm(final)=6.654 | 2399.6 samples/s | 37.5 steps/s
[Step=23300 Epoch=222.1] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.346 | L2-Norm(final)=6.654 | 4133.1 samples/s | 64.6 steps/s
[Step=23350 Epoch=222.5] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.336 | L2-Norm(final)=6.655 | 2431.4 samples/s | 38.0 steps/s
[Step=23400 Epoch=223.0] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.327 | L2-Norm(final)=6.655 | 4146.2 samples/s | 64.8 steps/s
[Step=23450 Epoch=223.5] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.317 | L2-Norm(final)=6.656 | 2415.1 samples/s | 37.7 steps/s
[Step=23500 Epoch=224.0] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.307 | L2-Norm(final)=6.656 | 4244.9 samples/s | 66.3 steps/s
[Step=23550 Epoch=224.5] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.297 | L2-Norm(final)=6.656 | 6821.8 samples/s | 106.6 steps/s
[Step=23600 Epoch=224.9] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.287 | L2-Norm(final)=6.657 | 1922.7 samples/s | 30.0 steps/s
[Step=23650 Epoch=225.4] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.277 | L2-Norm(final)=6.657 | 6382.8 samples/s | 99.7 steps/s
[Step=23700 Epoch=225.9] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.267 | L2-Norm(final)=6.658 | 2007.4 samples/s | 31.4 steps/s
[Step=23750 Epoch=226.4] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=6.658 | 5847.6 samples/s | 91.4 steps/s
[Step=23800 Epoch=226.8] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.246 | L2-Norm(final)=6.659 | 2059.9 samples/s | 32.2 steps/s
[Step=23850 Epoch=227.3] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.235 | L2-Norm(final)=6.659 | 5239.8 samples/s | 81.9 steps/s
[Step=23900 Epoch=227.8] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.224 | L2-Norm(final)=6.659 | 2135.1 samples/s | 33.4 steps/s
[Step=23950 Epoch=228.3] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.214 | L2-Norm(final)=6.660 | 5016.2 samples/s | 78.4 steps/s
[Step=24000 Epoch=228.7] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.203 | L2-Norm(final)=6.660 | 2208.4 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12370 | acc=0.9552 | tpr=0.9694 | fpr=0.0756 | 4770.5 samples/s | 18.6 steps/s
Avg test loss: 0.12549, Avg test acc: 0.95344, Avg tpr: 0.96794, Avg fpr: 0.07845, total FA: 612

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13305 | acc=0.9550 | tpr=0.9707 | fpr=0.0790 | 4779.8 samples/s | 18.7 steps/s
Avg test loss: 0.13756, Avg test acc: 0.95332, Avg tpr: 0.96870, Avg fpr: 0.08050, total FA: 628

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.13465 | acc=0.9537 | tpr=0.9666 | fpr=0.0743 | 4985.9 samples/s | 19.5 steps/s
Avg test loss: 0.13651, Avg test acc: 0.95292, Avg tpr: 0.96643, Avg fpr: 0.07679, total FA: 599

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13218 | acc=0.9567 | tpr=0.9704 | fpr=0.0731 | 4835.8 samples/s | 18.9 steps/s
Avg test loss: 0.13300, Avg test acc: 0.95516, Avg tpr: 0.96981, Avg fpr: 0.07704, total FA: 601

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.12311 | acc=0.9542 | tpr=0.9662 | fpr=0.0719 | 4735.5 samples/s | 18.5 steps/s
Avg test loss: 0.12905, Avg test acc: 0.95416, Avg tpr: 0.96596, Avg fpr: 0.07179, total FA: 560

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.65389 | acc=0.2799 | tpr=0.0245 | fpr=0.1655 | 4767.8 samples/s | 18.6 steps/s
Avg test loss: 5.66359, Avg test acc: 0.27995, Avg tpr: 0.02605, Avg fpr: 0.16165, total FA: 1261

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.67491 | acc=0.2769 | tpr=0.0090 | fpr=0.1415 | 4636.8 samples/s | 18.1 steps/s
Avg test loss: 5.69217, Avg test acc: 0.27534, Avg tpr: 0.00938, Avg fpr: 0.13973, total FA: 1090

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.30093 | acc=0.2888 | tpr=0.0183 | fpr=0.1239 | 4834.4 samples/s | 18.9 steps/s
Avg test loss: 5.30035, Avg test acc: 0.28748, Avg tpr: 0.01923, Avg fpr: 0.12255, total FA: 956

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.60280 | acc=0.2827 | tpr=0.0259 | fpr=0.1598 | 4696.9 samples/s | 18.3 steps/s
Avg test loss: 5.59746, Avg test acc: 0.28179, Avg tpr: 0.02658, Avg fpr: 0.15690, total FA: 1224

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=6.00849 | acc=0.2998 | tpr=0.0307 | fpr=0.1157 | 4992.6 samples/s | 19.5 steps/s
Avg test loss: 6.01599, Avg test acc: 0.29890, Avg tpr: 0.03235, Avg fpr: 0.11486, total FA: 896

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.36920 | acc=0.0958 | tpr=0.6903 | fpr=0.9149 | 4854.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.34624 | acc=0.0979 | tpr=0.6482 | fpr=0.9124 | 7233.1 samples/s | 28.3 steps/s
[Step= 150] | Loss=6.36594 | acc=0.0980 | tpr=0.6628 | fpr=0.9124 | 7544.0 samples/s | 29.5 steps/s
[Step= 200] | Loss=6.36762 | acc=0.0984 | tpr=0.6557 | fpr=0.9118 | 8024.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.38148 | acc=0.0988 | tpr=0.6498 | fpr=0.9112 | 7550.2 samples/s | 29.5 steps/s
[Step= 300] | Loss=6.37448 | acc=0.0987 | tpr=0.6531 | fpr=0.9114 | 8082.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.36900 | acc=0.0987 | tpr=0.6550 | fpr=0.9114 | 8058.7 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.36501 | acc=0.0990 | tpr=0.6526 | fpr=0.9111 | 7587.9 samples/s | 29.6 steps/s
[Step= 450] | Loss=6.36974 | acc=0.0991 | tpr=0.6509 | fpr=0.9110 | 8090.3 samples/s | 31.6 steps/s
[Step= 500] | Loss=6.37763 | acc=0.0985 | tpr=0.6493 | fpr=0.9114 | 8141.1 samples/s | 31.8 steps/s
[Step= 550] | Loss=6.37886 | acc=0.0984 | tpr=0.6470 | fpr=0.9116 | 13540.0 samples/s | 52.9 steps/s
Avg test loss: 6.38025, Avg test acc: 0.09831, Avg tpr: 0.64699, Avg fpr: 0.91167, total FA: 126583

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.78264 | acc=0.0963 | tpr=0.6106 | fpr=0.9130 | 4927.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.76156 | acc=0.0975 | tpr=0.6205 | fpr=0.9123 | 7016.8 samples/s | 27.4 steps/s
[Step= 150] | Loss=5.78152 | acc=0.0975 | tpr=0.6167 | fpr=0.9120 | 7652.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.77080 | acc=0.0974 | tpr=0.6077 | fpr=0.9118 | 7839.1 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.77639 | acc=0.0975 | tpr=0.6122 | fpr=0.9119 | 7898.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.76638 | acc=0.0973 | tpr=0.6102 | fpr=0.9121 | 7999.9 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.75854 | acc=0.0974 | tpr=0.6093 | fpr=0.9119 | 7515.1 samples/s | 29.4 steps/s
[Step= 400] | Loss=5.75528 | acc=0.0978 | tpr=0.6067 | fpr=0.9114 | 8358.4 samples/s | 32.6 steps/s
[Step= 450] | Loss=5.75783 | acc=0.0975 | tpr=0.6095 | fpr=0.9118 | 7993.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.76149 | acc=0.0968 | tpr=0.6066 | fpr=0.9124 | 7842.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.75986 | acc=0.0969 | tpr=0.6072 | fpr=0.9124 | 13570.7 samples/s | 53.0 steps/s
Avg test loss: 5.76145, Avg test acc: 0.09686, Avg tpr: 0.60737, Avg fpr: 0.91242, total FA: 126688

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.64904 | acc=0.0925 | tpr=0.5575 | fpr=0.9159 | 4777.5 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.61738 | acc=0.0914 | tpr=0.5522 | fpr=0.9172 | 7281.2 samples/s | 28.4 steps/s
[Step= 150] | Loss=6.62571 | acc=0.0913 | tpr=0.5519 | fpr=0.9172 | 7755.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.61343 | acc=0.0910 | tpr=0.5519 | fpr=0.9174 | 8049.0 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.62226 | acc=0.0914 | tpr=0.5467 | fpr=0.9169 | 8143.1 samples/s | 31.8 steps/s
[Step= 300] | Loss=6.61622 | acc=0.0910 | tpr=0.5476 | fpr=0.9173 | 7674.4 samples/s | 30.0 steps/s
[Step= 350] | Loss=6.60743 | acc=0.0912 | tpr=0.5510 | fpr=0.9171 | 7895.7 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.60125 | acc=0.0916 | tpr=0.5449 | fpr=0.9166 | 8134.0 samples/s | 31.8 steps/s
[Step= 450] | Loss=6.60075 | acc=0.0919 | tpr=0.5428 | fpr=0.9163 | 7699.8 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.60472 | acc=0.0916 | tpr=0.5361 | fpr=0.9164 | 7944.6 samples/s | 31.0 steps/s
[Step= 550] | Loss=6.60780 | acc=0.0913 | tpr=0.5316 | fpr=0.9167 | 14408.3 samples/s | 56.3 steps/s
Avg test loss: 6.60873, Avg test acc: 0.09126, Avg tpr: 0.53209, Avg fpr: 0.91675, total FA: 127289

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.45051 | acc=0.1052 | tpr=0.6460 | fpr=0.9045 | 4788.7 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.40336 | acc=0.1050 | tpr=0.6418 | fpr=0.9050 | 7215.0 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.40785 | acc=0.1045 | tpr=0.6311 | fpr=0.9052 | 7672.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.39969 | acc=0.1046 | tpr=0.6306 | fpr=0.9050 | 7795.0 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.41574 | acc=0.1048 | tpr=0.6262 | fpr=0.9047 | 8340.1 samples/s | 32.6 steps/s
[Step= 300] | Loss=6.40988 | acc=0.1048 | tpr=0.6240 | fpr=0.9047 | 7664.5 samples/s | 29.9 steps/s
[Step= 350] | Loss=6.40061 | acc=0.1051 | tpr=0.6243 | fpr=0.9044 | 8170.6 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.39916 | acc=0.1050 | tpr=0.6258 | fpr=0.9045 | 7730.6 samples/s | 30.2 steps/s
[Step= 450] | Loss=6.40274 | acc=0.1049 | tpr=0.6295 | fpr=0.9046 | 7641.1 samples/s | 29.8 steps/s
[Step= 500] | Loss=6.40605 | acc=0.1044 | tpr=0.6278 | fpr=0.9050 | 7991.8 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.40828 | acc=0.1044 | tpr=0.6279 | fpr=0.9051 | 14243.9 samples/s | 55.6 steps/s
Avg test loss: 6.40974, Avg test acc: 0.10434, Avg tpr: 0.62837, Avg fpr: 0.90518, total FA: 125683

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.11733 | acc=0.1146 | tpr=0.5531 | fpr=0.8933 | 4905.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.09887 | acc=0.1157 | tpr=0.5480 | fpr=0.8923 | 6986.8 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.10188 | acc=0.1149 | tpr=0.5331 | fpr=0.8928 | 7799.8 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.10043 | acc=0.1139 | tpr=0.5235 | fpr=0.8935 | 7808.4 samples/s | 30.5 steps/s
[Step= 250] | Loss=6.11355 | acc=0.1134 | tpr=0.5249 | fpr=0.8941 | 7788.2 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.11114 | acc=0.1133 | tpr=0.5316 | fpr=0.8943 | 8103.5 samples/s | 31.7 steps/s
[Step= 350] | Loss=6.10165 | acc=0.1132 | tpr=0.5329 | fpr=0.8944 | 7508.1 samples/s | 29.3 steps/s
[Step= 400] | Loss=6.10137 | acc=0.1135 | tpr=0.5334 | fpr=0.8941 | 8091.5 samples/s | 31.6 steps/s
[Step= 450] | Loss=6.10739 | acc=0.1135 | tpr=0.5331 | fpr=0.8941 | 7913.7 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.11010 | acc=0.1135 | tpr=0.5344 | fpr=0.8941 | 7895.1 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.11445 | acc=0.1134 | tpr=0.5364 | fpr=0.8943 | 14113.4 samples/s | 55.1 steps/s
Avg test loss: 6.11588, Avg test acc: 0.11327, Avg tpr: 0.53685, Avg fpr: 0.89443, total FA: 124190

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10392 | acc=0.9805 | tpr=0.9248 | fpr=0.0185 | 4674.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10753 | acc=0.9801 | tpr=0.9339 | fpr=0.0190 | 7472.4 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.11046 | acc=0.9797 | tpr=0.9366 | fpr=0.0195 | 7945.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.11305 | acc=0.9796 | tpr=0.9454 | fpr=0.0197 | 7842.3 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.11145 | acc=0.9799 | tpr=0.9415 | fpr=0.0194 | 7606.5 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.11412 | acc=0.9795 | tpr=0.9389 | fpr=0.0197 | 8495.5 samples/s | 33.2 steps/s
[Step= 350] | Loss=0.11477 | acc=0.9794 | tpr=0.9424 | fpr=0.0199 | 7796.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.11611 | acc=0.9792 | tpr=0.9398 | fpr=0.0201 | 7842.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.11810 | acc=0.9790 | tpr=0.9387 | fpr=0.0203 | 7678.0 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.11712 | acc=0.9791 | tpr=0.9401 | fpr=0.0201 | 8313.2 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.11655 | acc=0.9793 | tpr=0.9391 | fpr=0.0199 | 13397.5 samples/s | 52.3 steps/s
Avg test loss: 0.11654, Avg test acc: 0.97934, Avg tpr: 0.93899, Avg fpr: 0.01993, total FA: 2767

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12089 | acc=0.9818 | tpr=0.9115 | fpr=0.0169 | 4988.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.12457 | acc=0.9815 | tpr=0.9104 | fpr=0.0172 | 6790.2 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.12789 | acc=0.9811 | tpr=0.9092 | fpr=0.0175 | 7751.9 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.13140 | acc=0.9806 | tpr=0.9137 | fpr=0.0182 | 7716.3 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.12930 | acc=0.9807 | tpr=0.9092 | fpr=0.0180 | 7939.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.13281 | acc=0.9803 | tpr=0.9062 | fpr=0.0184 | 8111.7 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.13309 | acc=0.9801 | tpr=0.9067 | fpr=0.0186 | 8012.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.13440 | acc=0.9798 | tpr=0.9037 | fpr=0.0188 | 7730.4 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.13699 | acc=0.9796 | tpr=0.9031 | fpr=0.0191 | 7763.5 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13605 | acc=0.9797 | tpr=0.9057 | fpr=0.0190 | 7969.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.13552 | acc=0.9799 | tpr=0.9045 | fpr=0.0187 | 14030.3 samples/s | 54.8 steps/s
Avg test loss: 0.13536, Avg test acc: 0.97991, Avg tpr: 0.90452, Avg fpr: 0.01872, total FA: 2599

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10362 | acc=0.9830 | tpr=0.9381 | fpr=0.0161 | 4630.3 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.10860 | acc=0.9820 | tpr=0.9339 | fpr=0.0171 | 7375.9 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.11352 | acc=0.9814 | tpr=0.9337 | fpr=0.0177 | 7898.7 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.11483 | acc=0.9814 | tpr=0.9377 | fpr=0.0178 | 7990.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.11283 | acc=0.9815 | tpr=0.9328 | fpr=0.0176 | 7830.0 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.11511 | acc=0.9811 | tpr=0.9244 | fpr=0.0179 | 7723.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.11611 | acc=0.9811 | tpr=0.9286 | fpr=0.0180 | 8319.2 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.11638 | acc=0.9811 | tpr=0.9294 | fpr=0.0180 | 7874.3 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11789 | acc=0.9809 | tpr=0.9284 | fpr=0.0182 | 8034.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.11691 | acc=0.9810 | tpr=0.9300 | fpr=0.0181 | 7491.8 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.11646 | acc=0.9810 | tpr=0.9284 | fpr=0.0180 | 14711.1 samples/s | 57.5 steps/s
Avg test loss: 0.11625, Avg test acc: 0.98105, Avg tpr: 0.92829, Avg fpr: 0.01799, total FA: 2498

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10455 | acc=0.9802 | tpr=0.9425 | fpr=0.0192 | 5120.8 samples/s | 20.0 steps/s
[Step= 100] | Loss=0.10969 | acc=0.9796 | tpr=0.9360 | fpr=0.0196 | 6474.9 samples/s | 25.3 steps/s
[Step= 150] | Loss=0.11377 | acc=0.9792 | tpr=0.9366 | fpr=0.0200 | 7829.4 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.11650 | acc=0.9795 | tpr=0.9443 | fpr=0.0199 | 8059.9 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.11459 | acc=0.9799 | tpr=0.9424 | fpr=0.0195 | 7845.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.11716 | acc=0.9795 | tpr=0.9389 | fpr=0.0198 | 7666.1 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.11741 | acc=0.9794 | tpr=0.9411 | fpr=0.0200 | 8268.4 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.11807 | acc=0.9791 | tpr=0.9387 | fpr=0.0202 | 7689.8 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.12019 | acc=0.9789 | tpr=0.9367 | fpr=0.0203 | 7915.5 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.11922 | acc=0.9790 | tpr=0.9388 | fpr=0.0202 | 8120.1 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.11885 | acc=0.9791 | tpr=0.9387 | fpr=0.0201 | 13441.8 samples/s | 52.5 steps/s
Avg test loss: 0.11879, Avg test acc: 0.97915, Avg tpr: 0.93859, Avg fpr: 0.02012, total FA: 2793

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12788 | acc=0.9802 | tpr=0.9381 | fpr=0.0191 | 4987.5 samples/s | 19.5 steps/s
[Step= 100] | Loss=0.13376 | acc=0.9792 | tpr=0.9318 | fpr=0.0199 | 6878.0 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.13759 | acc=0.9787 | tpr=0.9380 | fpr=0.0206 | 7558.3 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.13974 | acc=0.9783 | tpr=0.9399 | fpr=0.0210 | 7673.4 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.13752 | acc=0.9785 | tpr=0.9371 | fpr=0.0208 | 8254.5 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.13969 | acc=0.9783 | tpr=0.9316 | fpr=0.0209 | 8025.0 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.13999 | acc=0.9781 | tpr=0.9343 | fpr=0.0211 | 7674.0 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.14166 | acc=0.9778 | tpr=0.9283 | fpr=0.0213 | 8059.6 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.14464 | acc=0.9776 | tpr=0.9270 | fpr=0.0214 | 7981.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.14372 | acc=0.9777 | tpr=0.9269 | fpr=0.0213 | 7702.9 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.14301 | acc=0.9778 | tpr=0.9252 | fpr=0.0212 | 13927.5 samples/s | 54.4 steps/s
Avg test loss: 0.14276, Avg test acc: 0.97786, Avg tpr: 0.92552, Avg fpr: 0.02119, total FA: 2942

server round 12/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=117.0] | Loss=0.00681 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.720 | L2-Norm(final)=9.102 | 5486.9 samples/s | 85.7 steps/s
[Step=24050 Epoch=117.3] | Loss=0.00670 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.712 | L2-Norm(final)=9.106 | 4468.5 samples/s | 69.8 steps/s
[Step=24100 Epoch=117.5] | Loss=0.00585 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.705 | L2-Norm(final)=9.113 | 5019.5 samples/s | 78.4 steps/s
[Step=24150 Epoch=117.8] | Loss=0.00541 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.698 | L2-Norm(final)=9.122 | 4864.6 samples/s | 76.0 steps/s
[Step=24200 Epoch=118.0] | Loss=0.00477 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.691 | L2-Norm(final)=9.133 | 7756.5 samples/s | 121.2 steps/s
[Step=24250 Epoch=118.2] | Loss=0.00450 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.683 | L2-Norm(final)=9.144 | 2170.7 samples/s | 33.9 steps/s
[Step=24300 Epoch=118.5] | Loss=0.00444 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.675 | L2-Norm(final)=9.154 | 4968.8 samples/s | 77.6 steps/s
[Step=24350 Epoch=118.7] | Loss=0.00441 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.666 | L2-Norm(final)=9.164 | 5090.2 samples/s | 79.5 steps/s
[Step=24400 Epoch=119.0] | Loss=0.00440 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.657 | L2-Norm(final)=9.174 | 6697.4 samples/s | 104.6 steps/s
[Step=24450 Epoch=119.2] | Loss=0.00418 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.647 | L2-Norm(final)=9.183 | 2282.7 samples/s | 35.7 steps/s
[Step=24500 Epoch=119.5] | Loss=0.00408 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.637 | L2-Norm(final)=9.192 | 4708.2 samples/s | 73.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=119.5] | Loss=0.00144 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.538 | L2-Norm(final)=9.284 | 4952.7 samples/s | 77.4 steps/s
[Step=24550 Epoch=119.7] | Loss=0.00538 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.532 | L2-Norm(final)=9.291 | 4229.6 samples/s | 66.1 steps/s
[Step=24600 Epoch=120.0] | Loss=0.00667 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.530 | L2-Norm(final)=9.294 | 4452.2 samples/s | 69.6 steps/s
[Step=24650 Epoch=120.2] | Loss=0.00770 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.531 | L2-Norm(final)=9.296 | 4495.9 samples/s | 70.2 steps/s
[Step=24700 Epoch=120.4] | Loss=0.00979 | Reg=0.00464 | acc=0.9531 | L2-Norm=21.539 | L2-Norm(final)=9.299 | 6339.3 samples/s | 99.1 steps/s
[Step=24750 Epoch=120.7] | Loss=0.01122 | Reg=0.00465 | acc=0.9688 | L2-Norm=21.555 | L2-Norm(final)=9.301 | 2094.9 samples/s | 32.7 steps/s
[Step=24800 Epoch=120.9] | Loss=0.01252 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.579 | L2-Norm(final)=9.302 | 4376.3 samples/s | 68.4 steps/s
[Step=24850 Epoch=121.2] | Loss=0.01307 | Reg=0.00467 | acc=1.0000 | L2-Norm=21.603 | L2-Norm(final)=9.304 | 4478.6 samples/s | 70.0 steps/s
[Step=24900 Epoch=121.4] | Loss=0.01323 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.625 | L2-Norm(final)=9.306 | 5785.4 samples/s | 90.4 steps/s
[Step=24950 Epoch=121.7] | Loss=0.01253 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.643 | L2-Norm(final)=9.310 | 2154.0 samples/s | 33.7 steps/s
[Step=25000 Epoch=121.9] | Loss=0.01188 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.657 | L2-Norm(final)=9.315 | 4382.4 samples/s | 68.5 steps/s
[Step=25050 Epoch=122.1] | Loss=0.01155 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.668 | L2-Norm(final)=9.319 | 4488.0 samples/s | 70.1 steps/s
[Step=25100 Epoch=122.4] | Loss=0.01157 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.678 | L2-Norm(final)=9.323 | 5316.3 samples/s | 83.1 steps/s
[Step=25150 Epoch=122.6] | Loss=0.01120 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.687 | L2-Norm(final)=9.328 | 2226.7 samples/s | 34.8 steps/s
[Step=25200 Epoch=122.9] | Loss=0.01069 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.695 | L2-Norm(final)=9.332 | 4425.7 samples/s | 69.2 steps/s
[Step=25250 Epoch=123.1] | Loss=0.01033 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.701 | L2-Norm(final)=9.336 | 4366.7 samples/s | 68.2 steps/s
[Step=25300 Epoch=123.4] | Loss=0.01012 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.704 | L2-Norm(final)=9.340 | 4931.9 samples/s | 77.1 steps/s
[Step=25350 Epoch=123.6] | Loss=0.00991 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.707 | L2-Norm(final)=9.343 | 2286.0 samples/s | 35.7 steps/s
[Step=25400 Epoch=123.9] | Loss=0.00960 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.708 | L2-Norm(final)=9.346 | 4433.5 samples/s | 69.3 steps/s
[Step=25450 Epoch=124.1] | Loss=0.00941 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.708 | L2-Norm(final)=9.349 | 4456.0 samples/s | 69.6 steps/s
[Step=25500 Epoch=124.3] | Loss=0.00912 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.707 | L2-Norm(final)=9.352 | 4538.0 samples/s | 70.9 steps/s
[Step=25550 Epoch=124.6] | Loss=0.00890 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.704 | L2-Norm(final)=9.355 | 2395.0 samples/s | 37.4 steps/s
[Step=25600 Epoch=124.8] | Loss=0.00864 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.701 | L2-Norm(final)=9.358 | 4398.4 samples/s | 68.7 steps/s
[Step=25650 Epoch=125.1] | Loss=0.00839 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.698 | L2-Norm(final)=9.360 | 4430.8 samples/s | 69.2 steps/s
[Step=25700 Epoch=125.3] | Loss=0.00824 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.693 | L2-Norm(final)=9.363 | 4485.2 samples/s | 70.1 steps/s
[Step=25750 Epoch=125.6] | Loss=0.00805 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.688 | L2-Norm(final)=9.365 | 2420.9 samples/s | 37.8 steps/s
[Step=25800 Epoch=125.8] | Loss=0.00788 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.683 | L2-Norm(final)=9.367 | 4418.0 samples/s | 69.0 steps/s
[Step=25850 Epoch=126.0] | Loss=0.00769 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.677 | L2-Norm(final)=9.370 | 4442.5 samples/s | 69.4 steps/s
[Step=25900 Epoch=126.3] | Loss=0.00759 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.670 | L2-Norm(final)=9.372 | 4433.4 samples/s | 69.3 steps/s
[Step=25950 Epoch=126.5] | Loss=0.00744 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.663 | L2-Norm(final)=9.373 | 2423.3 samples/s | 37.9 steps/s
[Step=26000 Epoch=126.8] | Loss=0.00729 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.656 | L2-Norm(final)=9.375 | 4514.2 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step26000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=117.1] | Loss=0.00162 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.846 | L2-Norm(final)=9.177 | 5261.2 samples/s | 82.2 steps/s
[Step=24050 Epoch=117.4] | Loss=0.00426 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.839 | L2-Norm(final)=9.186 | 4532.4 samples/s | 70.8 steps/s
[Step=24100 Epoch=117.6] | Loss=0.00418 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.832 | L2-Norm(final)=9.197 | 5167.1 samples/s | 80.7 steps/s
[Step=24150 Epoch=117.8] | Loss=0.00412 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.824 | L2-Norm(final)=9.207 | 4762.7 samples/s | 74.4 steps/s
[Step=24200 Epoch=118.1] | Loss=0.00400 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.815 | L2-Norm(final)=9.218 | 7851.3 samples/s | 122.7 steps/s
[Step=24250 Epoch=118.3] | Loss=0.00392 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.807 | L2-Norm(final)=9.229 | 2181.4 samples/s | 34.1 steps/s
[Step=24300 Epoch=118.6] | Loss=0.00386 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.797 | L2-Norm(final)=9.239 | 4915.1 samples/s | 76.8 steps/s
[Step=24350 Epoch=118.8] | Loss=0.00374 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.788 | L2-Norm(final)=9.249 | 4954.2 samples/s | 77.4 steps/s
[Step=24400 Epoch=119.1] | Loss=0.00368 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.778 | L2-Norm(final)=9.259 | 7129.2 samples/s | 111.4 steps/s
[Step=24450 Epoch=119.3] | Loss=0.00365 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.768 | L2-Norm(final)=9.268 | 2240.8 samples/s | 35.0 steps/s
[Step=24500 Epoch=119.5] | Loss=0.00357 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.758 | L2-Norm(final)=9.278 | 5072.6 samples/s | 79.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=119.6] | Loss=0.00003 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.652 | L2-Norm(final)=9.370 | 5146.8 samples/s | 80.4 steps/s
[Step=24550 Epoch=119.8] | Loss=0.00528 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.645 | L2-Norm(final)=9.374 | 4158.6 samples/s | 65.0 steps/s
[Step=24600 Epoch=120.0] | Loss=0.00681 | Reg=0.00468 | acc=0.9688 | L2-Norm=21.639 | L2-Norm(final)=9.374 | 4370.4 samples/s | 68.3 steps/s
[Step=24650 Epoch=120.3] | Loss=0.00810 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.640 | L2-Norm(final)=9.373 | 4438.0 samples/s | 69.3 steps/s
[Step=24700 Epoch=120.5] | Loss=0.00926 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.646 | L2-Norm(final)=9.376 | 6547.7 samples/s | 102.3 steps/s
[Step=24750 Epoch=120.8] | Loss=0.00989 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.655 | L2-Norm(final)=9.380 | 2065.0 samples/s | 32.3 steps/s
[Step=24800 Epoch=121.0] | Loss=0.01013 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.665 | L2-Norm(final)=9.384 | 4402.8 samples/s | 68.8 steps/s
[Step=24850 Epoch=121.3] | Loss=0.01013 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.675 | L2-Norm(final)=9.388 | 4454.5 samples/s | 69.6 steps/s
[Step=24900 Epoch=121.5] | Loss=0.01016 | Reg=0.00470 | acc=1.0000 | L2-Norm=21.685 | L2-Norm(final)=9.393 | 6015.5 samples/s | 94.0 steps/s
[Step=24950 Epoch=121.7] | Loss=0.00995 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.696 | L2-Norm(final)=9.398 | 2119.3 samples/s | 33.1 steps/s
[Step=25000 Epoch=122.0] | Loss=0.01021 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.708 | L2-Norm(final)=9.402 | 4425.3 samples/s | 69.1 steps/s
[Step=25050 Epoch=122.2] | Loss=0.01010 | Reg=0.00472 | acc=1.0000 | L2-Norm=21.720 | L2-Norm(final)=9.406 | 4401.1 samples/s | 68.8 steps/s
[Step=25100 Epoch=122.5] | Loss=0.01044 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.731 | L2-Norm(final)=9.410 | 5562.4 samples/s | 86.9 steps/s
[Step=25150 Epoch=122.7] | Loss=0.01037 | Reg=0.00473 | acc=0.9844 | L2-Norm=21.744 | L2-Norm(final)=9.414 | 2182.3 samples/s | 34.1 steps/s
[Step=25200 Epoch=123.0] | Loss=0.01006 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.754 | L2-Norm(final)=9.418 | 4481.8 samples/s | 70.0 steps/s
[Step=25250 Epoch=123.2] | Loss=0.00992 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.763 | L2-Norm(final)=9.422 | 4405.1 samples/s | 68.8 steps/s
[Step=25300 Epoch=123.5] | Loss=0.00958 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.770 | L2-Norm(final)=9.426 | 5097.6 samples/s | 79.6 steps/s
[Step=25350 Epoch=123.7] | Loss=0.00934 | Reg=0.00474 | acc=0.9844 | L2-Norm=21.775 | L2-Norm(final)=9.430 | 2243.4 samples/s | 35.1 steps/s
[Step=25400 Epoch=123.9] | Loss=0.00909 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.779 | L2-Norm(final)=9.433 | 4417.3 samples/s | 69.0 steps/s
[Step=25450 Epoch=124.2] | Loss=0.00889 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.782 | L2-Norm(final)=9.437 | 4450.9 samples/s | 69.5 steps/s
[Step=25500 Epoch=124.4] | Loss=0.00863 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.784 | L2-Norm(final)=9.440 | 4776.9 samples/s | 74.6 steps/s
[Step=25550 Epoch=124.7] | Loss=0.00834 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.785 | L2-Norm(final)=9.443 | 2318.7 samples/s | 36.2 steps/s
[Step=25600 Epoch=124.9] | Loss=0.00813 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.785 | L2-Norm(final)=9.446 | 4426.2 samples/s | 69.2 steps/s
[Step=25650 Epoch=125.2] | Loss=0.00793 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.783 | L2-Norm(final)=9.449 | 4431.1 samples/s | 69.2 steps/s
[Step=25700 Epoch=125.4] | Loss=0.00781 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.781 | L2-Norm(final)=9.452 | 4533.0 samples/s | 70.8 steps/s
[Step=25750 Epoch=125.6] | Loss=0.00773 | Reg=0.00474 | acc=0.9844 | L2-Norm=21.778 | L2-Norm(final)=9.454 | 2373.1 samples/s | 37.1 steps/s
[Step=25800 Epoch=125.9] | Loss=0.00762 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.775 | L2-Norm(final)=9.457 | 4441.4 samples/s | 69.4 steps/s
[Step=25850 Epoch=126.1] | Loss=0.00746 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.771 | L2-Norm(final)=9.459 | 4407.8 samples/s | 68.9 steps/s
[Step=25900 Epoch=126.4] | Loss=0.00729 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.767 | L2-Norm(final)=9.461 | 4458.8 samples/s | 69.7 steps/s
[Step=25950 Epoch=126.6] | Loss=0.00711 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.762 | L2-Norm(final)=9.464 | 2450.1 samples/s | 38.3 steps/s
[Step=26000 Epoch=126.9] | Loss=0.00698 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.756 | L2-Norm(final)=9.466 | 4364.3 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step26000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=116.9] | Loss=0.02912 | Reg=0.00482 | acc=0.9844 | L2-Norm=21.947 | L2-Norm(final)=9.655 | 5606.2 samples/s | 87.6 steps/s
[Step=24050 Epoch=117.2] | Loss=0.00606 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.946 | L2-Norm(final)=9.665 | 4201.4 samples/s | 65.6 steps/s
[Step=24100 Epoch=117.4] | Loss=0.00571 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.940 | L2-Norm(final)=9.677 | 5193.7 samples/s | 81.2 steps/s
[Step=24150 Epoch=117.7] | Loss=0.00528 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.934 | L2-Norm(final)=9.689 | 4798.6 samples/s | 75.0 steps/s
[Step=24200 Epoch=117.9] | Loss=0.00511 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.926 | L2-Norm(final)=9.701 | 7847.1 samples/s | 122.6 steps/s
[Step=24250 Epoch=118.2] | Loss=0.00471 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.917 | L2-Norm(final)=9.712 | 2206.7 samples/s | 34.5 steps/s
[Step=24300 Epoch=118.4] | Loss=0.00448 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.909 | L2-Norm(final)=9.722 | 4954.2 samples/s | 77.4 steps/s
[Step=24350 Epoch=118.6] | Loss=0.00457 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.900 | L2-Norm(final)=9.733 | 5059.4 samples/s | 79.1 steps/s
[Step=24400 Epoch=118.9] | Loss=0.00453 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.891 | L2-Norm(final)=9.743 | 6729.2 samples/s | 105.1 steps/s
[Step=24450 Epoch=119.1] | Loss=0.00436 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.881 | L2-Norm(final)=9.754 | 2282.8 samples/s | 35.7 steps/s
[Step=24500 Epoch=119.4] | Loss=0.00422 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.872 | L2-Norm(final)=9.764 | 4828.3 samples/s | 75.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=119.4] | Loss=0.00084 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.775 | L2-Norm(final)=9.868 | 5783.2 samples/s | 90.4 steps/s
[Step=24550 Epoch=119.6] | Loss=0.00488 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.768 | L2-Norm(final)=9.875 | 3861.7 samples/s | 60.3 steps/s
[Step=24600 Epoch=119.9] | Loss=0.00694 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.765 | L2-Norm(final)=9.881 | 4412.9 samples/s | 69.0 steps/s
[Step=24650 Epoch=120.1] | Loss=0.00958 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.770 | L2-Norm(final)=9.882 | 4463.9 samples/s | 69.7 steps/s
[Step=24700 Epoch=120.4] | Loss=0.01311 | Reg=0.00475 | acc=0.9688 | L2-Norm=21.788 | L2-Norm(final)=9.881 | 6435.7 samples/s | 100.6 steps/s
[Step=24750 Epoch=120.6] | Loss=0.01408 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.816 | L2-Norm(final)=9.880 | 2079.8 samples/s | 32.5 steps/s
[Step=24800 Epoch=120.8] | Loss=0.01456 | Reg=0.00477 | acc=0.9844 | L2-Norm=21.842 | L2-Norm(final)=9.880 | 4423.8 samples/s | 69.1 steps/s
[Step=24850 Epoch=121.1] | Loss=0.01476 | Reg=0.00478 | acc=0.9844 | L2-Norm=21.865 | L2-Norm(final)=9.880 | 4519.1 samples/s | 70.6 steps/s
[Step=24900 Epoch=121.3] | Loss=0.01497 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.884 | L2-Norm(final)=9.880 | 5676.4 samples/s | 88.7 steps/s
[Step=24950 Epoch=121.6] | Loss=0.01438 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.900 | L2-Norm(final)=9.881 | 2139.4 samples/s | 33.4 steps/s
[Step=25000 Epoch=121.8] | Loss=0.01379 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.913 | L2-Norm(final)=9.882 | 4422.3 samples/s | 69.1 steps/s
[Step=25050 Epoch=122.1] | Loss=0.01326 | Reg=0.00481 | acc=0.9688 | L2-Norm=21.923 | L2-Norm(final)=9.883 | 4526.5 samples/s | 70.7 steps/s
[Step=25100 Epoch=122.3] | Loss=0.01271 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.930 | L2-Norm(final)=9.885 | 5226.6 samples/s | 81.7 steps/s
[Step=25150 Epoch=122.5] | Loss=0.01231 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.936 | L2-Norm(final)=9.887 | 2197.3 samples/s | 34.3 steps/s
[Step=25200 Epoch=122.8] | Loss=0.01209 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.941 | L2-Norm(final)=9.889 | 4439.0 samples/s | 69.4 steps/s
[Step=25250 Epoch=123.0] | Loss=0.01159 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.944 | L2-Norm(final)=9.891 | 4522.1 samples/s | 70.7 steps/s
[Step=25300 Epoch=123.3] | Loss=0.01115 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.945 | L2-Norm(final)=9.893 | 4779.7 samples/s | 74.7 steps/s
[Step=25350 Epoch=123.5] | Loss=0.01077 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.946 | L2-Norm(final)=9.896 | 2323.8 samples/s | 36.3 steps/s
[Step=25400 Epoch=123.8] | Loss=0.01049 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.945 | L2-Norm(final)=9.898 | 4425.8 samples/s | 69.2 steps/s
[Step=25450 Epoch=124.0] | Loss=0.01021 | Reg=0.00482 | acc=1.0000 | L2-Norm=21.943 | L2-Norm(final)=9.900 | 4488.0 samples/s | 70.1 steps/s
[Step=25500 Epoch=124.2] | Loss=0.00992 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.941 | L2-Norm(final)=9.902 | 4505.1 samples/s | 70.4 steps/s
[Step=25550 Epoch=124.5] | Loss=0.00961 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.938 | L2-Norm(final)=9.904 | 2367.7 samples/s | 37.0 steps/s
[Step=25600 Epoch=124.7] | Loss=0.00942 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.934 | L2-Norm(final)=9.906 | 4446.4 samples/s | 69.5 steps/s
[Step=25650 Epoch=125.0] | Loss=0.00924 | Reg=0.00481 | acc=0.9844 | L2-Norm=21.929 | L2-Norm(final)=9.908 | 4428.0 samples/s | 69.2 steps/s
[Step=25700 Epoch=125.2] | Loss=0.00896 | Reg=0.00481 | acc=1.0000 | L2-Norm=21.925 | L2-Norm(final)=9.909 | 4481.6 samples/s | 70.0 steps/s
[Step=25750 Epoch=125.5] | Loss=0.00877 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.919 | L2-Norm(final)=9.911 | 2408.9 samples/s | 37.6 steps/s
[Step=25800 Epoch=125.7] | Loss=0.00859 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.913 | L2-Norm(final)=9.913 | 4395.8 samples/s | 68.7 steps/s
[Step=25850 Epoch=126.0] | Loss=0.00841 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.906 | L2-Norm(final)=9.914 | 4457.4 samples/s | 69.6 steps/s
[Step=25900 Epoch=126.2] | Loss=0.00822 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.899 | L2-Norm(final)=9.916 | 4472.5 samples/s | 69.9 steps/s
[Step=25950 Epoch=126.4] | Loss=0.00805 | Reg=0.00479 | acc=0.9844 | L2-Norm=21.892 | L2-Norm(final)=9.918 | 2459.6 samples/s | 38.4 steps/s
[Step=26000 Epoch=126.7] | Loss=0.00794 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.884 | L2-Norm(final)=9.919 | 4306.9 samples/s | 67.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step26000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=117.0] | Loss=0.01228 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.843 | L2-Norm(final)=9.415 | 4895.1 samples/s | 76.5 steps/s
[Step=24050 Epoch=117.3] | Loss=0.00429 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.838 | L2-Norm(final)=9.426 | 4659.4 samples/s | 72.8 steps/s
[Step=24100 Epoch=117.5] | Loss=0.00440 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.833 | L2-Norm(final)=9.439 | 4978.7 samples/s | 77.8 steps/s
[Step=24150 Epoch=117.8] | Loss=0.00417 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.825 | L2-Norm(final)=9.451 | 4891.9 samples/s | 76.4 steps/s
[Step=24200 Epoch=118.0] | Loss=0.00423 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.816 | L2-Norm(final)=9.462 | 7466.8 samples/s | 116.7 steps/s
[Step=24250 Epoch=118.3] | Loss=0.00400 | Reg=0.00476 | acc=0.9844 | L2-Norm=21.806 | L2-Norm(final)=9.473 | 2086.3 samples/s | 32.6 steps/s
[Step=24300 Epoch=118.5] | Loss=0.00390 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.796 | L2-Norm(final)=9.483 | 4721.4 samples/s | 73.8 steps/s
[Step=24350 Epoch=118.7] | Loss=0.00378 | Reg=0.00475 | acc=1.0000 | L2-Norm=21.786 | L2-Norm(final)=9.493 | 4840.5 samples/s | 75.6 steps/s
[Step=24400 Epoch=119.0] | Loss=0.00380 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.776 | L2-Norm(final)=9.504 | 6526.4 samples/s | 102.0 steps/s
[Step=24450 Epoch=119.2] | Loss=0.00378 | Reg=0.00474 | acc=1.0000 | L2-Norm=21.766 | L2-Norm(final)=9.514 | 2163.4 samples/s | 33.8 steps/s
[Step=24500 Epoch=119.5] | Loss=0.00368 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.756 | L2-Norm(final)=9.524 | 4887.3 samples/s | 76.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=119.5] | Loss=0.00025 | Reg=0.00469 | acc=1.0000 | L2-Norm=21.653 | L2-Norm(final)=9.629 | 5036.4 samples/s | 78.7 steps/s
[Step=24550 Epoch=119.7] | Loss=0.00418 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.643 | L2-Norm(final)=9.638 | 3947.4 samples/s | 61.7 steps/s
[Step=24600 Epoch=120.0] | Loss=0.00591 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.640 | L2-Norm(final)=9.644 | 4356.2 samples/s | 68.1 steps/s
[Step=24650 Epoch=120.2] | Loss=0.01129 | Reg=0.00469 | acc=0.9688 | L2-Norm=21.657 | L2-Norm(final)=9.649 | 4448.0 samples/s | 69.5 steps/s
[Step=24700 Epoch=120.5] | Loss=0.01319 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.693 | L2-Norm(final)=9.650 | 6546.8 samples/s | 102.3 steps/s
[Step=24750 Epoch=120.7] | Loss=0.01429 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.728 | L2-Norm(final)=9.652 | 2091.7 samples/s | 32.7 steps/s
[Step=24800 Epoch=120.9] | Loss=0.01549 | Reg=0.00473 | acc=1.0000 | L2-Norm=21.759 | L2-Norm(final)=9.654 | 4498.5 samples/s | 70.3 steps/s
[Step=24850 Epoch=121.2] | Loss=0.01519 | Reg=0.00475 | acc=0.9844 | L2-Norm=21.787 | L2-Norm(final)=9.653 | 4453.9 samples/s | 69.6 steps/s
[Step=24900 Epoch=121.4] | Loss=0.01553 | Reg=0.00476 | acc=1.0000 | L2-Norm=21.811 | L2-Norm(final)=9.654 | 5875.3 samples/s | 91.8 steps/s
[Step=24950 Epoch=121.7] | Loss=0.01494 | Reg=0.00477 | acc=1.0000 | L2-Norm=21.834 | L2-Norm(final)=9.654 | 2164.4 samples/s | 33.8 steps/s
[Step=25000 Epoch=121.9] | Loss=0.01444 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.853 | L2-Norm(final)=9.655 | 4492.4 samples/s | 70.2 steps/s
[Step=25050 Epoch=122.2] | Loss=0.01383 | Reg=0.00478 | acc=1.0000 | L2-Norm=21.869 | L2-Norm(final)=9.657 | 4432.2 samples/s | 69.3 steps/s
[Step=25100 Epoch=122.4] | Loss=0.01322 | Reg=0.00479 | acc=0.9844 | L2-Norm=21.881 | L2-Norm(final)=9.659 | 5354.1 samples/s | 83.7 steps/s
[Step=25150 Epoch=122.6] | Loss=0.01273 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.891 | L2-Norm(final)=9.662 | 2250.5 samples/s | 35.2 steps/s
[Step=25200 Epoch=122.9] | Loss=0.01212 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.899 | L2-Norm(final)=9.664 | 4433.3 samples/s | 69.3 steps/s
[Step=25250 Epoch=123.1] | Loss=0.01148 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.906 | L2-Norm(final)=9.666 | 4489.1 samples/s | 70.1 steps/s
[Step=25300 Epoch=123.4] | Loss=0.01120 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.910 | L2-Norm(final)=9.669 | 4987.7 samples/s | 77.9 steps/s
[Step=25350 Epoch=123.6] | Loss=0.01082 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.913 | L2-Norm(final)=9.670 | 2353.5 samples/s | 36.8 steps/s
[Step=25400 Epoch=123.9] | Loss=0.01043 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.915 | L2-Norm(final)=9.672 | 4481.0 samples/s | 70.0 steps/s
[Step=25450 Epoch=124.1] | Loss=0.01008 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.916 | L2-Norm(final)=9.674 | 4372.0 samples/s | 68.3 steps/s
[Step=25500 Epoch=124.4] | Loss=0.00980 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.916 | L2-Norm(final)=9.677 | 4617.4 samples/s | 72.1 steps/s
[Step=25550 Epoch=124.6] | Loss=0.00950 | Reg=0.00480 | acc=0.9844 | L2-Norm=21.915 | L2-Norm(final)=9.679 | 2439.4 samples/s | 38.1 steps/s
[Step=25600 Epoch=124.8] | Loss=0.00923 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.913 | L2-Norm(final)=9.681 | 4538.5 samples/s | 70.9 steps/s
[Step=25650 Epoch=125.1] | Loss=0.00892 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.911 | L2-Norm(final)=9.683 | 4445.2 samples/s | 69.5 steps/s
[Step=25700 Epoch=125.3] | Loss=0.00873 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.908 | L2-Norm(final)=9.685 | 4658.5 samples/s | 72.8 steps/s
[Step=25750 Epoch=125.6] | Loss=0.00850 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.904 | L2-Norm(final)=9.687 | 2392.4 samples/s | 37.4 steps/s
[Step=25800 Epoch=125.8] | Loss=0.00832 | Reg=0.00480 | acc=1.0000 | L2-Norm=21.900 | L2-Norm(final)=9.689 | 4512.3 samples/s | 70.5 steps/s
[Step=25850 Epoch=126.1] | Loss=0.00812 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.895 | L2-Norm(final)=9.690 | 4413.4 samples/s | 69.0 steps/s
[Step=25900 Epoch=126.3] | Loss=0.00797 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.890 | L2-Norm(final)=9.692 | 4522.1 samples/s | 70.7 steps/s
[Step=25950 Epoch=126.5] | Loss=0.00780 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.885 | L2-Norm(final)=9.693 | 2447.5 samples/s | 38.2 steps/s
[Step=26000 Epoch=126.8] | Loss=0.00760 | Reg=0.00479 | acc=1.0000 | L2-Norm=21.879 | L2-Norm(final)=9.695 | 4424.1 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step26000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=117.7] | Loss=0.00888 | Reg=0.00468 | acc=1.0000 | L2-Norm=21.628 | L2-Norm(final)=9.480 | 5710.0 samples/s | 89.2 steps/s
[Step=24050 Epoch=117.9] | Loss=0.00391 | Reg=0.00467 | acc=0.9844 | L2-Norm=21.617 | L2-Norm(final)=9.489 | 4206.4 samples/s | 65.7 steps/s
[Step=24100 Epoch=118.2] | Loss=0.00367 | Reg=0.00467 | acc=1.0000 | L2-Norm=21.609 | L2-Norm(final)=9.500 | 4915.4 samples/s | 76.8 steps/s
[Step=24150 Epoch=118.4] | Loss=0.00370 | Reg=0.00467 | acc=1.0000 | L2-Norm=21.601 | L2-Norm(final)=9.511 | 5048.0 samples/s | 78.9 steps/s
[Step=24200 Epoch=118.7] | Loss=0.00397 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.593 | L2-Norm(final)=9.522 | 8063.8 samples/s | 126.0 steps/s
[Step=24250 Epoch=118.9] | Loss=0.00387 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.585 | L2-Norm(final)=9.532 | 2204.8 samples/s | 34.4 steps/s
[Step=24300 Epoch=119.2] | Loss=0.00367 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.577 | L2-Norm(final)=9.543 | 5099.0 samples/s | 79.7 steps/s
[Step=24350 Epoch=119.4] | Loss=0.00361 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.567 | L2-Norm(final)=9.554 | 5051.6 samples/s | 78.9 steps/s
[Step=24400 Epoch=119.7] | Loss=0.00358 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.558 | L2-Norm(final)=9.565 | 7430.4 samples/s | 116.1 steps/s
[Step=24450 Epoch=119.9] | Loss=0.00356 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.549 | L2-Norm(final)=9.575 | 2257.8 samples/s | 35.3 steps/s
[Step=24500 Epoch=120.1] | Loss=0.00353 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.539 | L2-Norm(final)=9.585 | 4780.4 samples/s | 74.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=120.1] | Loss=0.00044 | Reg=0.00460 | acc=1.0000 | L2-Norm=21.444 | L2-Norm(final)=9.685 | 5083.4 samples/s | 79.4 steps/s
[Step=24550 Epoch=120.4] | Loss=0.00461 | Reg=0.00460 | acc=1.0000 | L2-Norm=21.437 | L2-Norm(final)=9.688 | 4196.9 samples/s | 65.6 steps/s
[Step=24600 Epoch=120.6] | Loss=0.00791 | Reg=0.00460 | acc=1.0000 | L2-Norm=21.436 | L2-Norm(final)=9.693 | 4510.7 samples/s | 70.5 steps/s
[Step=24650 Epoch=120.9] | Loss=0.01130 | Reg=0.00460 | acc=1.0000 | L2-Norm=21.449 | L2-Norm(final)=9.693 | 4495.6 samples/s | 70.2 steps/s
[Step=24700 Epoch=121.1] | Loss=0.01350 | Reg=0.00461 | acc=0.9688 | L2-Norm=21.470 | L2-Norm(final)=9.692 | 6735.1 samples/s | 105.2 steps/s
[Step=24750 Epoch=121.4] | Loss=0.01320 | Reg=0.00462 | acc=0.9844 | L2-Norm=21.497 | L2-Norm(final)=9.692 | 2062.6 samples/s | 32.2 steps/s
[Step=24800 Epoch=121.6] | Loss=0.01360 | Reg=0.00463 | acc=1.0000 | L2-Norm=21.517 | L2-Norm(final)=9.693 | 4394.9 samples/s | 68.7 steps/s
[Step=24850 Epoch=121.9] | Loss=0.01288 | Reg=0.00464 | acc=0.9844 | L2-Norm=21.534 | L2-Norm(final)=9.694 | 4471.1 samples/s | 69.9 steps/s
[Step=24900 Epoch=122.1] | Loss=0.01239 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.549 | L2-Norm(final)=9.696 | 6205.4 samples/s | 97.0 steps/s
[Step=24950 Epoch=122.4] | Loss=0.01198 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.560 | L2-Norm(final)=9.699 | 2146.9 samples/s | 33.5 steps/s
[Step=25000 Epoch=122.6] | Loss=0.01152 | Reg=0.00465 | acc=0.9844 | L2-Norm=21.569 | L2-Norm(final)=9.701 | 4450.1 samples/s | 69.5 steps/s
[Step=25050 Epoch=122.8] | Loss=0.01128 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.577 | L2-Norm(final)=9.704 | 4444.3 samples/s | 69.4 steps/s
[Step=25100 Epoch=123.1] | Loss=0.01092 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.584 | L2-Norm(final)=9.707 | 5880.2 samples/s | 91.9 steps/s
[Step=25150 Epoch=123.3] | Loss=0.01049 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.589 | L2-Norm(final)=9.710 | 2161.7 samples/s | 33.8 steps/s
[Step=25200 Epoch=123.6] | Loss=0.01004 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.593 | L2-Norm(final)=9.713 | 4369.8 samples/s | 68.3 steps/s
[Step=25250 Epoch=123.8] | Loss=0.00963 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.595 | L2-Norm(final)=9.716 | 4508.3 samples/s | 70.4 steps/s
[Step=25300 Epoch=124.1] | Loss=0.00944 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.596 | L2-Norm(final)=9.719 | 5471.4 samples/s | 85.5 steps/s
[Step=25350 Epoch=124.3] | Loss=0.00927 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.595 | L2-Norm(final)=9.722 | 2225.3 samples/s | 34.8 steps/s
[Step=25400 Epoch=124.6] | Loss=0.00901 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.595 | L2-Norm(final)=9.724 | 4442.1 samples/s | 69.4 steps/s
[Step=25450 Epoch=124.8] | Loss=0.00874 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.593 | L2-Norm(final)=9.727 | 4532.7 samples/s | 70.8 steps/s
[Step=25500 Epoch=125.0] | Loss=0.00844 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.590 | L2-Norm(final)=9.730 | 5141.0 samples/s | 80.3 steps/s
[Step=25550 Epoch=125.3] | Loss=0.00835 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.587 | L2-Norm(final)=9.733 | 2257.8 samples/s | 35.3 steps/s
[Step=25600 Epoch=125.5] | Loss=0.00810 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.584 | L2-Norm(final)=9.735 | 4570.1 samples/s | 71.4 steps/s
[Step=25650 Epoch=125.8] | Loss=0.00794 | Reg=0.00466 | acc=1.0000 | L2-Norm=21.579 | L2-Norm(final)=9.737 | 4365.3 samples/s | 68.2 steps/s
[Step=25700 Epoch=126.0] | Loss=0.00780 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.574 | L2-Norm(final)=9.739 | 4890.3 samples/s | 76.4 steps/s
[Step=25750 Epoch=126.3] | Loss=0.00765 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.569 | L2-Norm(final)=9.742 | 2350.1 samples/s | 36.7 steps/s
[Step=25800 Epoch=126.5] | Loss=0.00751 | Reg=0.00465 | acc=0.9844 | L2-Norm=21.563 | L2-Norm(final)=9.744 | 4449.2 samples/s | 69.5 steps/s
[Step=25850 Epoch=126.8] | Loss=0.00732 | Reg=0.00465 | acc=1.0000 | L2-Norm=21.557 | L2-Norm(final)=9.746 | 4418.4 samples/s | 69.0 steps/s
[Step=25900 Epoch=127.0] | Loss=0.00717 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.550 | L2-Norm(final)=9.748 | 4680.6 samples/s | 73.1 steps/s
[Step=25950 Epoch=127.3] | Loss=0.00713 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.543 | L2-Norm(final)=9.750 | 2383.5 samples/s | 37.2 steps/s
[Step=26000 Epoch=127.5] | Loss=0.00705 | Reg=0.00464 | acc=1.0000 | L2-Norm=21.536 | L2-Norm(final)=9.751 | 4478.1 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step26000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=227.4] | Loss=0.00010 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.469 | L2-Norm(final)=5.493 | 5448.2 samples/s | 85.1 steps/s
[Step=24050 Epoch=227.9] | Loss=0.00043 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.503 | L2-Norm(final)=5.508 | 4265.3 samples/s | 66.6 steps/s
[Step=24100 Epoch=228.4] | Loss=0.00036 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.534 | L2-Norm(final)=5.526 | 7542.0 samples/s | 117.8 steps/s
[Step=24150 Epoch=228.8] | Loss=0.00027 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.561 | L2-Norm(final)=5.542 | 2152.8 samples/s | 33.6 steps/s
[Step=24200 Epoch=229.3] | Loss=0.00021 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.575 | L2-Norm(final)=5.555 | 6246.7 samples/s | 97.6 steps/s
[Step=24250 Epoch=229.8] | Loss=0.00019 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.583 | L2-Norm(final)=5.565 | 2217.0 samples/s | 34.6 steps/s
[Step=24300 Epoch=230.3] | Loss=0.00016 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.588 | L2-Norm(final)=5.574 | 5957.4 samples/s | 93.1 steps/s
[Step=24350 Epoch=230.7] | Loss=0.00014 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.590 | L2-Norm(final)=5.582 | 2292.2 samples/s | 35.8 steps/s
[Step=24400 Epoch=231.2] | Loss=0.00013 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.590 | L2-Norm(final)=5.589 | 5390.1 samples/s | 84.2 steps/s
[Step=24450 Epoch=231.7] | Loss=0.00012 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.589 | L2-Norm(final)=5.596 | 2423.6 samples/s | 37.9 steps/s
[Step=24500 Epoch=232.2] | Loss=0.00011 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.588 | L2-Norm(final)=5.602 | 4778.9 samples/s | 74.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=232.2] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.573 | L2-Norm(final)=5.664 | 5069.3 samples/s | 79.2 steps/s
[Step=24550 Epoch=232.6] | Loss=0.00216 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.587 | L2-Norm(final)=5.673 | 3871.7 samples/s | 60.5 steps/s
[Step=24600 Epoch=233.1] | Loss=0.00623 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.747 | L2-Norm(final)=5.654 | 6316.3 samples/s | 98.7 steps/s
[Step=24650 Epoch=233.6] | Loss=0.00457 | Reg=0.00140 | acc=0.9844 | L2-Norm=11.844 | L2-Norm(final)=5.643 | 2005.6 samples/s | 31.3 steps/s
[Step=24700 Epoch=234.1] | Loss=0.00350 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=5.640 | 5669.1 samples/s | 88.6 steps/s
[Step=24750 Epoch=234.5] | Loss=0.00282 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.925 | L2-Norm(final)=5.640 | 2071.5 samples/s | 32.4 steps/s
[Step=24800 Epoch=235.0] | Loss=0.00236 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.943 | L2-Norm(final)=5.640 | 5170.9 samples/s | 80.8 steps/s
[Step=24850 Epoch=235.5] | Loss=0.00202 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.954 | L2-Norm(final)=5.640 | 2167.3 samples/s | 33.9 steps/s
[Step=24900 Epoch=235.9] | Loss=0.00177 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=5.641 | 4741.7 samples/s | 74.1 steps/s
[Step=24950 Epoch=236.4] | Loss=0.00158 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.964 | L2-Norm(final)=5.641 | 2273.8 samples/s | 35.5 steps/s
[Step=25000 Epoch=236.9] | Loss=0.00142 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.965 | L2-Norm(final)=5.642 | 4330.3 samples/s | 67.7 steps/s
[Step=25050 Epoch=237.4] | Loss=0.00129 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.965 | L2-Norm(final)=5.642 | 2324.1 samples/s | 36.3 steps/s
[Step=25100 Epoch=237.8] | Loss=0.00118 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.964 | L2-Norm(final)=5.643 | 4233.7 samples/s | 66.2 steps/s
[Step=25150 Epoch=238.3] | Loss=0.00109 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=5.644 | 2383.9 samples/s | 37.2 steps/s
[Step=25200 Epoch=238.8] | Loss=0.00102 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.958 | L2-Norm(final)=5.644 | 4262.4 samples/s | 66.6 steps/s
[Step=25250 Epoch=239.3] | Loss=0.00095 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.954 | L2-Norm(final)=5.645 | 2400.4 samples/s | 37.5 steps/s
[Step=25300 Epoch=239.7] | Loss=0.00089 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.950 | L2-Norm(final)=5.645 | 4209.2 samples/s | 65.8 steps/s
[Step=25350 Epoch=240.2] | Loss=0.00084 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.945 | L2-Norm(final)=5.646 | 2357.7 samples/s | 36.8 steps/s
[Step=25400 Epoch=240.7] | Loss=0.00079 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.940 | L2-Norm(final)=5.646 | 4178.8 samples/s | 65.3 steps/s
[Step=25450 Epoch=241.2] | Loss=0.00075 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.935 | L2-Norm(final)=5.647 | 6466.2 samples/s | 101.0 steps/s
[Step=25500 Epoch=241.6] | Loss=0.00071 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.929 | L2-Norm(final)=5.647 | 1992.8 samples/s | 31.1 steps/s
[Step=25550 Epoch=242.1] | Loss=0.00068 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.923 | L2-Norm(final)=5.648 | 5791.8 samples/s | 90.5 steps/s
[Step=25600 Epoch=242.6] | Loss=0.00065 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.917 | L2-Norm(final)=5.648 | 2041.7 samples/s | 31.9 steps/s
[Step=25650 Epoch=243.1] | Loss=0.00062 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.910 | L2-Norm(final)=5.648 | 5189.5 samples/s | 81.1 steps/s
[Step=25700 Epoch=243.5] | Loss=0.00059 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.903 | L2-Norm(final)=5.649 | 2175.2 samples/s | 34.0 steps/s
[Step=25750 Epoch=244.0] | Loss=0.00057 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.897 | L2-Norm(final)=5.649 | 4772.8 samples/s | 74.6 steps/s
[Step=25800 Epoch=244.5] | Loss=0.00055 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.889 | L2-Norm(final)=5.650 | 2232.7 samples/s | 34.9 steps/s
[Step=25850 Epoch=245.0] | Loss=0.00053 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.882 | L2-Norm(final)=5.650 | 4447.0 samples/s | 69.5 steps/s
[Step=25900 Epoch=245.4] | Loss=0.00051 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.875 | L2-Norm(final)=5.651 | 2333.9 samples/s | 36.5 steps/s
[Step=25950 Epoch=245.9] | Loss=0.00049 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.867 | L2-Norm(final)=5.651 | 4192.3 samples/s | 65.5 steps/s
[Step=26000 Epoch=246.4] | Loss=0.00048 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.860 | L2-Norm(final)=5.651 | 2372.5 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step26000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=228.3] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.491 | L2-Norm(final)=6.066 | 5425.0 samples/s | 84.8 steps/s
[Step=24050 Epoch=228.8] | Loss=0.00009 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.491 | L2-Norm(final)=6.073 | 4083.0 samples/s | 63.8 steps/s
[Step=24100 Epoch=229.3] | Loss=0.00010 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.497 | L2-Norm(final)=6.082 | 7498.3 samples/s | 117.2 steps/s
[Step=24150 Epoch=229.7] | Loss=0.00008 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=6.090 | 2147.4 samples/s | 33.6 steps/s
[Step=24200 Epoch=230.2] | Loss=0.00007 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.503 | L2-Norm(final)=6.096 | 6341.6 samples/s | 99.1 steps/s
[Step=24250 Epoch=230.7] | Loss=0.00006 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.504 | L2-Norm(final)=6.102 | 2202.3 samples/s | 34.4 steps/s
[Step=24300 Epoch=231.2] | Loss=0.00006 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.503 | L2-Norm(final)=6.107 | 5874.0 samples/s | 91.8 steps/s
[Step=24350 Epoch=231.6] | Loss=0.00005 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=6.112 | 2324.1 samples/s | 36.3 steps/s
[Step=24400 Epoch=232.1] | Loss=0.00005 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.501 | L2-Norm(final)=6.117 | 5312.9 samples/s | 83.0 steps/s
[Step=24450 Epoch=232.6] | Loss=0.00005 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.499 | L2-Norm(final)=6.122 | 2413.7 samples/s | 37.7 steps/s
[Step=24500 Epoch=233.1] | Loss=0.00004 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.497 | L2-Norm(final)=6.126 | 4875.2 samples/s | 76.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=233.1] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.479 | L2-Norm(final)=6.171 | 5653.2 samples/s | 88.3 steps/s
[Step=24550 Epoch=233.5] | Loss=0.00002 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.465 | L2-Norm(final)=6.175 | 3580.9 samples/s | 56.0 steps/s
[Step=24600 Epoch=234.0] | Loss=0.00002 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.447 | L2-Norm(final)=6.178 | 6342.8 samples/s | 99.1 steps/s
[Step=24650 Epoch=234.5] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=6.181 | 2022.2 samples/s | 31.6 steps/s
[Step=24700 Epoch=235.0] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.409 | L2-Norm(final)=6.183 | 5692.4 samples/s | 88.9 steps/s
[Step=24750 Epoch=235.4] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.389 | L2-Norm(final)=6.185 | 2088.7 samples/s | 32.6 steps/s
[Step=24800 Epoch=235.9] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.369 | L2-Norm(final)=6.186 | 5076.1 samples/s | 79.3 steps/s
[Step=24850 Epoch=236.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.349 | L2-Norm(final)=6.187 | 2158.1 samples/s | 33.7 steps/s
[Step=24900 Epoch=236.9] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.328 | L2-Norm(final)=6.189 | 4773.0 samples/s | 74.6 steps/s
[Step=24950 Epoch=237.3] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.307 | L2-Norm(final)=6.190 | 2252.8 samples/s | 35.2 steps/s
[Step=25000 Epoch=237.8] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.287 | L2-Norm(final)=6.191 | 4366.2 samples/s | 68.2 steps/s
[Step=25050 Epoch=238.3] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.266 | L2-Norm(final)=6.192 | 2333.4 samples/s | 36.5 steps/s
[Step=25100 Epoch=238.8] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.245 | L2-Norm(final)=6.193 | 4206.1 samples/s | 65.7 steps/s
[Step=25150 Epoch=239.2] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.225 | L2-Norm(final)=6.194 | 2356.1 samples/s | 36.8 steps/s
[Step=25200 Epoch=239.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.204 | L2-Norm(final)=6.195 | 4323.6 samples/s | 67.6 steps/s
[Step=25250 Epoch=240.2] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.183 | L2-Norm(final)=6.195 | 2378.6 samples/s | 37.2 steps/s
[Step=25300 Epoch=240.7] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.162 | L2-Norm(final)=6.196 | 4250.3 samples/s | 66.4 steps/s
[Step=25350 Epoch=241.1] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.141 | L2-Norm(final)=6.197 | 2566.2 samples/s | 40.1 steps/s
[Step=25400 Epoch=241.6] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.120 | L2-Norm(final)=6.198 | 3776.9 samples/s | 59.0 steps/s
[Step=25450 Epoch=242.1] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.098 | L2-Norm(final)=6.199 | 6465.7 samples/s | 101.0 steps/s
[Step=25500 Epoch=242.6] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.077 | L2-Norm(final)=6.200 | 1990.9 samples/s | 31.1 steps/s
[Step=25550 Epoch=243.0] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.056 | L2-Norm(final)=6.201 | 5793.2 samples/s | 90.5 steps/s
[Step=25600 Epoch=243.5] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.034 | L2-Norm(final)=6.202 | 2084.2 samples/s | 32.6 steps/s
[Step=25650 Epoch=244.0] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.013 | L2-Norm(final)=6.203 | 5331.9 samples/s | 83.3 steps/s
[Step=25700 Epoch=244.5] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.991 | L2-Norm(final)=6.203 | 2121.4 samples/s | 33.1 steps/s
[Step=25750 Epoch=244.9] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.970 | L2-Norm(final)=6.204 | 4700.1 samples/s | 73.4 steps/s
[Step=25800 Epoch=245.4] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.948 | L2-Norm(final)=6.205 | 2238.7 samples/s | 35.0 steps/s
[Step=25850 Epoch=245.9] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.926 | L2-Norm(final)=6.206 | 4494.0 samples/s | 70.2 steps/s
[Step=25900 Epoch=246.4] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.904 | L2-Norm(final)=6.207 | 2320.2 samples/s | 36.3 steps/s
[Step=25950 Epoch=246.8] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.882 | L2-Norm(final)=6.208 | 4176.9 samples/s | 65.3 steps/s
[Step=26000 Epoch=247.3] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.860 | L2-Norm(final)=6.209 | 2381.5 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step26000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=229.2] | Loss=0.00061 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.648 | L2-Norm(final)=6.037 | 5197.3 samples/s | 81.2 steps/s
[Step=24050 Epoch=229.7] | Loss=0.00030 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.658 | L2-Norm(final)=6.045 | 4336.9 samples/s | 67.8 steps/s
[Step=24100 Epoch=230.1] | Loss=0.00026 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.665 | L2-Norm(final)=6.051 | 7694.6 samples/s | 120.2 steps/s
[Step=24150 Epoch=230.6] | Loss=0.00021 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.671 | L2-Norm(final)=6.056 | 2130.9 samples/s | 33.3 steps/s
[Step=24200 Epoch=231.1] | Loss=0.00017 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.675 | L2-Norm(final)=6.060 | 6822.1 samples/s | 106.6 steps/s
[Step=24250 Epoch=231.6] | Loss=0.00015 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.678 | L2-Norm(final)=6.064 | 2148.6 samples/s | 33.6 steps/s
[Step=24300 Epoch=232.1] | Loss=0.00013 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.679 | L2-Norm(final)=6.068 | 6242.3 samples/s | 97.5 steps/s
[Step=24350 Epoch=232.5] | Loss=0.00012 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.680 | L2-Norm(final)=6.072 | 2317.0 samples/s | 36.2 steps/s
[Step=24400 Epoch=233.0] | Loss=0.00011 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.681 | L2-Norm(final)=6.075 | 5482.5 samples/s | 85.7 steps/s
[Step=24450 Epoch=233.5] | Loss=0.00010 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.681 | L2-Norm(final)=6.078 | 2347.4 samples/s | 36.7 steps/s
[Step=24500 Epoch=234.0] | Loss=0.00010 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.681 | L2-Norm(final)=6.082 | 5224.2 samples/s | 81.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=234.0] | Loss=0.00011 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.678 | L2-Norm(final)=6.114 | 5210.7 samples/s | 81.4 steps/s
[Step=24550 Epoch=234.4] | Loss=0.00003 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.675 | L2-Norm(final)=6.117 | 3761.4 samples/s | 58.8 steps/s
[Step=24600 Epoch=234.9] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.669 | L2-Norm(final)=6.119 | 6362.0 samples/s | 99.4 steps/s
[Step=24650 Epoch=235.4] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.663 | L2-Norm(final)=6.121 | 2025.2 samples/s | 31.6 steps/s
[Step=24700 Epoch=235.9] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.656 | L2-Norm(final)=6.122 | 5883.7 samples/s | 91.9 steps/s
[Step=24750 Epoch=236.3] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.649 | L2-Norm(final)=6.123 | 1602.8 samples/s | 25.0 steps/s
[Step=24800 Epoch=236.8] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.641 | L2-Norm(final)=6.123 | 5245.5 samples/s | 82.0 steps/s
[Step=24850 Epoch=237.3] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.633 | L2-Norm(final)=6.124 | 2074.3 samples/s | 32.4 steps/s
[Step=24900 Epoch=237.8] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.624 | L2-Norm(final)=6.125 | 5019.9 samples/s | 78.4 steps/s
[Step=24950 Epoch=238.3] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.616 | L2-Norm(final)=6.125 | 2250.9 samples/s | 35.2 steps/s
[Step=25000 Epoch=238.7] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.608 | L2-Norm(final)=6.126 | 4526.4 samples/s | 70.7 steps/s
[Step=25050 Epoch=239.2] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.599 | L2-Norm(final)=6.126 | 2335.6 samples/s | 36.5 steps/s
[Step=25100 Epoch=239.7] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.591 | L2-Norm(final)=6.127 | 4154.5 samples/s | 64.9 steps/s
[Step=25150 Epoch=240.2] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.582 | L2-Norm(final)=6.127 | 2321.8 samples/s | 36.3 steps/s
[Step=25200 Epoch=240.6] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.573 | L2-Norm(final)=6.127 | 4269.7 samples/s | 66.7 steps/s
[Step=25250 Epoch=241.1] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.565 | L2-Norm(final)=6.128 | 2388.4 samples/s | 37.3 steps/s
[Step=25300 Epoch=241.6] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.556 | L2-Norm(final)=6.128 | 4208.2 samples/s | 65.8 steps/s
[Step=25350 Epoch=242.1] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.547 | L2-Norm(final)=6.129 | 2386.3 samples/s | 37.3 steps/s
[Step=25400 Epoch=242.6] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=6.129 | 4156.3 samples/s | 64.9 steps/s
[Step=25450 Epoch=243.0] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.529 | L2-Norm(final)=6.129 | 2360.7 samples/s | 36.9 steps/s
[Step=25500 Epoch=243.5] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.520 | L2-Norm(final)=6.130 | 4332.4 samples/s | 67.7 steps/s
[Step=25550 Epoch=244.0] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.511 | L2-Norm(final)=6.130 | 6843.8 samples/s | 106.9 steps/s
[Step=25600 Epoch=244.5] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=6.131 | 1959.1 samples/s | 30.6 steps/s
[Step=25650 Epoch=244.9] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.492 | L2-Norm(final)=6.131 | 6412.4 samples/s | 100.2 steps/s
[Step=25700 Epoch=245.4] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.483 | L2-Norm(final)=6.131 | 2003.2 samples/s | 31.3 steps/s
[Step=25750 Epoch=245.9] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.474 | L2-Norm(final)=6.132 | 5850.6 samples/s | 91.4 steps/s
[Step=25800 Epoch=246.4] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=6.132 | 2059.2 samples/s | 32.2 steps/s
[Step=25850 Epoch=246.9] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=6.132 | 5357.8 samples/s | 83.7 steps/s
[Step=25900 Epoch=247.3] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.445 | L2-Norm(final)=6.133 | 2123.5 samples/s | 33.2 steps/s
[Step=25950 Epoch=247.8] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.435 | L2-Norm(final)=6.133 | 4991.0 samples/s | 78.0 steps/s
[Step=26000 Epoch=248.3] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.425 | L2-Norm(final)=6.134 | 2161.1 samples/s | 33.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step26000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=226.2] | Loss=0.00032 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.316 | L2-Norm(final)=5.809 | 5803.1 samples/s | 90.7 steps/s
[Step=24050 Epoch=226.6] | Loss=0.00027 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.341 | L2-Norm(final)=5.841 | 4056.8 samples/s | 63.4 steps/s
[Step=24100 Epoch=227.1] | Loss=0.00130 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.403 | L2-Norm(final)=5.874 | 7160.6 samples/s | 111.9 steps/s
[Step=24150 Epoch=227.6] | Loss=0.00095 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.458 | L2-Norm(final)=5.893 | 2142.9 samples/s | 33.5 steps/s
[Step=24200 Epoch=228.0] | Loss=0.00074 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.488 | L2-Norm(final)=5.907 | 6431.0 samples/s | 100.5 steps/s
[Step=24250 Epoch=228.5] | Loss=0.00060 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.506 | L2-Norm(final)=5.916 | 2213.4 samples/s | 34.6 steps/s
[Step=24300 Epoch=229.0] | Loss=0.00051 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.517 | L2-Norm(final)=5.924 | 5559.5 samples/s | 86.9 steps/s
[Step=24350 Epoch=229.4] | Loss=0.00044 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.525 | L2-Norm(final)=5.931 | 2349.6 samples/s | 36.7 steps/s
[Step=24400 Epoch=229.9] | Loss=0.00039 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.531 | L2-Norm(final)=5.937 | 5044.7 samples/s | 78.8 steps/s
[Step=24450 Epoch=230.4] | Loss=0.00035 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=5.942 | 2468.9 samples/s | 38.6 steps/s
[Step=24500 Epoch=230.9] | Loss=0.00032 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=5.947 | 4754.1 samples/s | 74.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=230.9] | Loss=0.00002 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=5.997 | 5451.8 samples/s | 85.2 steps/s
[Step=24550 Epoch=231.3] | Loss=0.00530 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.545 | L2-Norm(final)=5.998 | 3629.3 samples/s | 56.7 steps/s
[Step=24600 Epoch=231.8] | Loss=0.00773 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.674 | L2-Norm(final)=5.970 | 6238.4 samples/s | 97.5 steps/s
[Step=24650 Epoch=232.3] | Loss=0.00612 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.755 | L2-Norm(final)=5.952 | 2055.0 samples/s | 32.1 steps/s
[Step=24700 Epoch=232.7] | Loss=0.00483 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.802 | L2-Norm(final)=5.944 | 5426.9 samples/s | 84.8 steps/s
[Step=24750 Epoch=233.2] | Loss=0.00389 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.830 | L2-Norm(final)=5.939 | 2135.9 samples/s | 33.4 steps/s
[Step=24800 Epoch=233.7] | Loss=0.00325 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.847 | L2-Norm(final)=5.937 | 4978.2 samples/s | 77.8 steps/s
[Step=24850 Epoch=234.2] | Loss=0.00279 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.859 | L2-Norm(final)=5.936 | 2202.5 samples/s | 34.4 steps/s
[Step=24900 Epoch=234.6] | Loss=0.00244 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.866 | L2-Norm(final)=5.935 | 4492.0 samples/s | 70.2 steps/s
[Step=24950 Epoch=235.1] | Loss=0.00217 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.870 | L2-Norm(final)=5.935 | 2342.6 samples/s | 36.6 steps/s
[Step=25000 Epoch=235.6] | Loss=0.00196 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.873 | L2-Norm(final)=5.935 | 4230.5 samples/s | 66.1 steps/s
[Step=25050 Epoch=236.0] | Loss=0.00178 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.874 | L2-Norm(final)=5.935 | 2399.5 samples/s | 37.5 steps/s
[Step=25100 Epoch=236.5] | Loss=0.00163 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.874 | L2-Norm(final)=5.935 | 4257.1 samples/s | 66.5 steps/s
[Step=25150 Epoch=237.0] | Loss=0.00151 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.873 | L2-Norm(final)=5.935 | 2345.4 samples/s | 36.6 steps/s
[Step=25200 Epoch=237.5] | Loss=0.00140 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.872 | L2-Norm(final)=5.935 | 4254.6 samples/s | 66.5 steps/s
[Step=25250 Epoch=237.9] | Loss=0.00131 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.870 | L2-Norm(final)=5.935 | 2596.8 samples/s | 40.6 steps/s
[Step=25300 Epoch=238.4] | Loss=0.00123 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.868 | L2-Norm(final)=5.935 | 3765.7 samples/s | 58.8 steps/s
[Step=25350 Epoch=238.9] | Loss=0.00115 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=5.935 | 6304.5 samples/s | 98.5 steps/s
[Step=25400 Epoch=239.3] | Loss=0.00109 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.862 | L2-Norm(final)=5.936 | 2031.4 samples/s | 31.7 steps/s
[Step=25450 Epoch=239.8] | Loss=0.00103 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.858 | L2-Norm(final)=5.936 | 5318.0 samples/s | 83.1 steps/s
[Step=25500 Epoch=240.3] | Loss=0.00098 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.855 | L2-Norm(final)=5.936 | 2117.7 samples/s | 33.1 steps/s
[Step=25550 Epoch=240.8] | Loss=0.00093 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.851 | L2-Norm(final)=5.936 | 5012.8 samples/s | 78.3 steps/s
[Step=25600 Epoch=241.2] | Loss=0.00089 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.847 | L2-Norm(final)=5.937 | 2202.4 samples/s | 34.4 steps/s
[Step=25650 Epoch=241.7] | Loss=0.00085 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.843 | L2-Norm(final)=5.937 | 4467.2 samples/s | 69.8 steps/s
[Step=25700 Epoch=242.2] | Loss=0.00082 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.838 | L2-Norm(final)=5.937 | 2337.3 samples/s | 36.5 steps/s
[Step=25750 Epoch=242.6] | Loss=0.00079 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.833 | L2-Norm(final)=5.937 | 4078.0 samples/s | 63.7 steps/s
[Step=25800 Epoch=243.1] | Loss=0.00076 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.829 | L2-Norm(final)=5.938 | 2385.0 samples/s | 37.3 steps/s
[Step=25850 Epoch=243.6] | Loss=0.00073 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.824 | L2-Norm(final)=5.938 | 4286.1 samples/s | 67.0 steps/s
[Step=25900 Epoch=244.1] | Loss=0.00070 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.819 | L2-Norm(final)=5.938 | 2404.5 samples/s | 37.6 steps/s
[Step=25950 Epoch=244.5] | Loss=0.00068 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.814 | L2-Norm(final)=5.939 | 4284.0 samples/s | 66.9 steps/s
[Step=26000 Epoch=245.0] | Loss=0.00066 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.808 | L2-Norm(final)=5.939 | 2532.3 samples/s | 39.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step26000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=228.8] | Loss=0.00053 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.924 | L2-Norm(final)=6.672 | 5840.6 samples/s | 91.3 steps/s
[Step=24050 Epoch=229.2] | Loss=0.00016 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.925 | L2-Norm(final)=6.679 | 3826.3 samples/s | 59.8 steps/s
[Step=24100 Epoch=229.7] | Loss=0.00024 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.931 | L2-Norm(final)=6.689 | 7636.7 samples/s | 119.3 steps/s
[Step=24150 Epoch=230.2] | Loss=0.00022 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.944 | L2-Norm(final)=6.701 | 2131.7 samples/s | 33.3 steps/s
[Step=24200 Epoch=230.6] | Loss=0.00018 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.952 | L2-Norm(final)=6.710 | 6703.8 samples/s | 104.7 steps/s
[Step=24250 Epoch=231.1] | Loss=0.00016 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=6.718 | 2203.6 samples/s | 34.4 steps/s
[Step=24300 Epoch=231.6] | Loss=0.00014 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.957 | L2-Norm(final)=6.725 | 5960.6 samples/s | 93.1 steps/s
[Step=24350 Epoch=232.1] | Loss=0.00012 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.957 | L2-Norm(final)=6.730 | 2271.9 samples/s | 35.5 steps/s
[Step=24400 Epoch=232.6] | Loss=0.00011 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.956 | L2-Norm(final)=6.736 | 5597.6 samples/s | 87.5 steps/s
[Step=24450 Epoch=233.0] | Loss=0.00010 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.954 | L2-Norm(final)=6.741 | 2396.4 samples/s | 37.4 steps/s
[Step=24500 Epoch=233.5] | Loss=0.00010 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.952 | L2-Norm(final)=6.745 | 5070.9 samples/s | 79.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=233.5] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.931 | L2-Norm(final)=6.792 | 5149.7 samples/s | 80.5 steps/s
[Step=24550 Epoch=234.0] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.921 | L2-Norm(final)=6.796 | 3835.1 samples/s | 59.9 steps/s
[Step=24600 Epoch=234.5] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.908 | L2-Norm(final)=6.799 | 6220.6 samples/s | 97.2 steps/s
[Step=24650 Epoch=234.9] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.893 | L2-Norm(final)=6.801 | 2016.3 samples/s | 31.5 steps/s
[Step=24700 Epoch=235.4] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.877 | L2-Norm(final)=6.802 | 5801.8 samples/s | 90.7 steps/s
[Step=24750 Epoch=235.9] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.860 | L2-Norm(final)=6.803 | 2090.0 samples/s | 32.7 steps/s
[Step=24800 Epoch=236.4] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.843 | L2-Norm(final)=6.804 | 5341.6 samples/s | 83.5 steps/s
[Step=24850 Epoch=236.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.826 | L2-Norm(final)=6.805 | 2095.4 samples/s | 32.7 steps/s
[Step=24900 Epoch=237.3] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.808 | L2-Norm(final)=6.806 | 4906.5 samples/s | 76.7 steps/s
[Step=24950 Epoch=237.8] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.791 | L2-Norm(final)=6.806 | 2208.8 samples/s | 34.5 steps/s
[Step=25000 Epoch=238.3] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.773 | L2-Norm(final)=6.807 | 4651.0 samples/s | 72.7 steps/s
[Step=25050 Epoch=238.7] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.756 | L2-Norm(final)=6.808 | 2293.5 samples/s | 35.8 steps/s
[Step=25100 Epoch=239.2] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.738 | L2-Norm(final)=6.808 | 4314.5 samples/s | 67.4 steps/s
[Step=25150 Epoch=239.7] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.720 | L2-Norm(final)=6.809 | 2361.4 samples/s | 36.9 steps/s
[Step=25200 Epoch=240.2] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.702 | L2-Norm(final)=6.809 | 4184.4 samples/s | 65.4 steps/s
[Step=25250 Epoch=240.7] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.684 | L2-Norm(final)=6.810 | 2405.5 samples/s | 37.6 steps/s
[Step=25300 Epoch=241.1] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.665 | L2-Norm(final)=6.810 | 4249.0 samples/s | 66.4 steps/s
[Step=25350 Epoch=241.6] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.647 | L2-Norm(final)=6.811 | 2406.3 samples/s | 37.6 steps/s
[Step=25400 Epoch=242.1] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.629 | L2-Norm(final)=6.812 | 4335.3 samples/s | 67.7 steps/s
[Step=25450 Epoch=242.6] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.610 | L2-Norm(final)=6.812 | 2351.3 samples/s | 36.7 steps/s
[Step=25500 Epoch=243.0] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.591 | L2-Norm(final)=6.813 | 4188.6 samples/s | 65.4 steps/s
[Step=25550 Epoch=243.5] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.573 | L2-Norm(final)=6.813 | 7056.8 samples/s | 110.3 steps/s
[Step=25600 Epoch=244.0] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.554 | L2-Norm(final)=6.814 | 1959.9 samples/s | 30.6 steps/s
[Step=25650 Epoch=244.5] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=6.814 | 6290.7 samples/s | 98.3 steps/s
[Step=25700 Epoch=244.9] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.516 | L2-Norm(final)=6.815 | 2012.2 samples/s | 31.4 steps/s
[Step=25750 Epoch=245.4] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.496 | L2-Norm(final)=6.816 | 5733.5 samples/s | 89.6 steps/s
[Step=25800 Epoch=245.9] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.477 | L2-Norm(final)=6.816 | 2023.8 samples/s | 31.6 steps/s
[Step=25850 Epoch=246.4] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.457 | L2-Norm(final)=6.817 | 5305.8 samples/s | 82.9 steps/s
[Step=25900 Epoch=246.9] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.438 | L2-Norm(final)=6.817 | 2132.6 samples/s | 33.3 steps/s
[Step=25950 Epoch=247.3] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.418 | L2-Norm(final)=6.818 | 4994.3 samples/s | 78.0 steps/s
[Step=26000 Epoch=247.8] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.398 | L2-Norm(final)=6.819 | 2196.7 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12976 | acc=0.9558 | tpr=0.9728 | fpr=0.0813 | 4638.9 samples/s | 18.1 steps/s
Avg test loss: 0.13091, Avg test acc: 0.95444, Avg tpr: 0.97097, Avg fpr: 0.08191, total FA: 639

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13708 | acc=0.9523 | tpr=0.9717 | fpr=0.0897 | 4732.9 samples/s | 18.5 steps/s
Avg test loss: 0.13620, Avg test acc: 0.95224, Avg tpr: 0.97132, Avg fpr: 0.08973, total FA: 700

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.12942 | acc=0.9568 | tpr=0.9738 | fpr=0.0800 | 5135.8 samples/s | 20.1 steps/s
Avg test loss: 0.12809, Avg test acc: 0.95512, Avg tpr: 0.97167, Avg fpr: 0.08127, total FA: 634

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13762 | acc=0.9574 | tpr=0.9734 | fpr=0.0773 | 4809.8 samples/s | 18.8 steps/s
Avg test loss: 0.14042, Avg test acc: 0.95524, Avg tpr: 0.97214, Avg fpr: 0.08191, total FA: 639

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11400 | acc=0.9561 | tpr=0.9662 | fpr=0.0659 | 4974.6 samples/s | 19.4 steps/s
Avg test loss: 0.12069, Avg test acc: 0.95508, Avg tpr: 0.96555, Avg fpr: 0.06794, total FA: 530

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.66215 | acc=0.3063 | tpr=0.0189 | fpr=0.0696 | 4852.2 samples/s | 19.0 steps/s
Avg test loss: 5.67126, Avg test acc: 0.30535, Avg tpr: 0.01883, Avg fpr: 0.06448, total FA: 503

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.31839 | acc=0.2777 | tpr=0.0082 | fpr=0.1370 | 4815.6 samples/s | 18.8 steps/s
Avg test loss: 5.33689, Avg test acc: 0.27574, Avg tpr: 0.00833, Avg fpr: 0.13614, total FA: 1062

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=6.65664 | acc=0.2641 | tpr=0.0260 | fpr=0.2188 | 4722.7 samples/s | 18.4 steps/s
Avg test loss: 6.66356, Avg test acc: 0.26332, Avg tpr: 0.02664, Avg fpr: 0.21613, total FA: 1686

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.70722 | acc=0.2917 | tpr=0.0326 | fpr=0.1457 | 4807.5 samples/s | 18.8 steps/s
Avg test loss: 5.71658, Avg test acc: 0.29165, Avg tpr: 0.03270, Avg fpr: 0.13883, total FA: 1083

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.56522 | acc=0.3067 | tpr=0.0312 | fpr=0.0949 | 4821.6 samples/s | 18.8 steps/s
Avg test loss: 5.57813, Avg test acc: 0.30459, Avg tpr: 0.03246, Avg fpr: 0.09691, total FA: 756

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.33729 | acc=0.0902 | tpr=0.5973 | fpr=0.9190 | 4728.2 samples/s | 18.5 steps/s
[Step= 100] | Loss=6.30508 | acc=0.0902 | tpr=0.5885 | fpr=0.9191 | 7291.5 samples/s | 28.5 steps/s
[Step= 150] | Loss=6.31581 | acc=0.0913 | tpr=0.5893 | fpr=0.9179 | 8053.8 samples/s | 31.5 steps/s
[Step= 200] | Loss=6.30952 | acc=0.0920 | tpr=0.5967 | fpr=0.9172 | 7539.3 samples/s | 29.5 steps/s
[Step= 250] | Loss=6.32261 | acc=0.0916 | tpr=0.5930 | fpr=0.9176 | 8036.0 samples/s | 31.4 steps/s
[Step= 300] | Loss=6.31151 | acc=0.0915 | tpr=0.6036 | fpr=0.9178 | 7738.0 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.31086 | acc=0.0917 | tpr=0.6011 | fpr=0.9176 | 8044.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.30407 | acc=0.0916 | tpr=0.6018 | fpr=0.9176 | 7855.1 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.30964 | acc=0.0917 | tpr=0.6022 | fpr=0.9176 | 8080.1 samples/s | 31.6 steps/s
[Step= 500] | Loss=6.31661 | acc=0.0914 | tpr=0.5974 | fpr=0.9177 | 7690.9 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.31748 | acc=0.0915 | tpr=0.5945 | fpr=0.9177 | 14125.8 samples/s | 55.2 steps/s
Avg test loss: 6.31962, Avg test acc: 0.09140, Avg tpr: 0.59469, Avg fpr: 0.91775, total FA: 127428

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.61035 | acc=0.0939 | tpr=0.5354 | fpr=0.9140 | 4868.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.58581 | acc=0.0941 | tpr=0.5352 | fpr=0.9141 | 6867.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=5.59196 | acc=0.0939 | tpr=0.5202 | fpr=0.9139 | 7723.2 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.58666 | acc=0.0933 | tpr=0.5137 | fpr=0.9143 | 8173.7 samples/s | 31.9 steps/s
[Step= 250] | Loss=5.58684 | acc=0.0938 | tpr=0.5144 | fpr=0.9139 | 7888.5 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.57985 | acc=0.0934 | tpr=0.5156 | fpr=0.9143 | 8356.5 samples/s | 32.6 steps/s
[Step= 350] | Loss=5.57041 | acc=0.0937 | tpr=0.5166 | fpr=0.9140 | 7439.6 samples/s | 29.1 steps/s
[Step= 400] | Loss=5.56560 | acc=0.0941 | tpr=0.5175 | fpr=0.9136 | 7908.1 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.56742 | acc=0.0940 | tpr=0.5156 | fpr=0.9136 | 8131.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.57209 | acc=0.0931 | tpr=0.5141 | fpr=0.9145 | 7969.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.57296 | acc=0.0929 | tpr=0.5157 | fpr=0.9148 | 13393.1 samples/s | 52.3 steps/s
Avg test loss: 5.57482, Avg test acc: 0.09283, Avg tpr: 0.51585, Avg fpr: 0.91486, total FA: 127027

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.97134 | acc=0.0759 | tpr=0.5088 | fpr=0.9318 | 5004.2 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.92997 | acc=0.0776 | tpr=0.5267 | fpr=0.9308 | 6544.3 samples/s | 25.6 steps/s
[Step= 150] | Loss=6.94598 | acc=0.0770 | tpr=0.5245 | fpr=0.9313 | 8044.0 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.93544 | acc=0.0773 | tpr=0.5388 | fpr=0.9311 | 7824.0 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.94019 | acc=0.0773 | tpr=0.5389 | fpr=0.9311 | 7558.7 samples/s | 29.5 steps/s
[Step= 300] | Loss=6.93481 | acc=0.0777 | tpr=0.5447 | fpr=0.9308 | 8407.8 samples/s | 32.8 steps/s
[Step= 350] | Loss=6.92951 | acc=0.0779 | tpr=0.5454 | fpr=0.9305 | 8029.7 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.92441 | acc=0.0782 | tpr=0.5383 | fpr=0.9302 | 7901.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=6.92542 | acc=0.0783 | tpr=0.5399 | fpr=0.9300 | 7725.1 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.92707 | acc=0.0783 | tpr=0.5300 | fpr=0.9299 | 7884.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.92964 | acc=0.0781 | tpr=0.5269 | fpr=0.9300 | 13813.6 samples/s | 54.0 steps/s
Avg test loss: 6.93060, Avg test acc: 0.07801, Avg tpr: 0.52694, Avg fpr: 0.93015, total FA: 129150

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.86389 | acc=0.0974 | tpr=0.7080 | fpr=0.9136 | 4936.4 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.82194 | acc=0.0961 | tpr=0.6908 | fpr=0.9150 | 6843.9 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.82684 | acc=0.0958 | tpr=0.6974 | fpr=0.9153 | 7751.1 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.82073 | acc=0.0960 | tpr=0.7049 | fpr=0.9150 | 7692.9 samples/s | 30.1 steps/s
[Step= 250] | Loss=6.83635 | acc=0.0965 | tpr=0.7031 | fpr=0.9146 | 8218.7 samples/s | 32.1 steps/s
[Step= 300] | Loss=6.82743 | acc=0.0964 | tpr=0.7055 | fpr=0.9147 | 7695.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.81869 | acc=0.0967 | tpr=0.7095 | fpr=0.9144 | 7935.3 samples/s | 31.0 steps/s
[Step= 400] | Loss=6.81465 | acc=0.0967 | tpr=0.7101 | fpr=0.9144 | 8024.7 samples/s | 31.3 steps/s
[Step= 450] | Loss=6.81956 | acc=0.0965 | tpr=0.7103 | fpr=0.9146 | 7779.8 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.81997 | acc=0.0962 | tpr=0.7088 | fpr=0.9148 | 7882.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.82140 | acc=0.0967 | tpr=0.7103 | fpr=0.9145 | 13972.6 samples/s | 54.6 steps/s
Avg test loss: 6.82237, Avg test acc: 0.09661, Avg tpr: 0.71078, Avg fpr: 0.91455, total FA: 126984

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.80640 | acc=0.1036 | tpr=0.6549 | fpr=0.9063 | 4703.4 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.79152 | acc=0.1054 | tpr=0.6333 | fpr=0.9044 | 7335.8 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.79863 | acc=0.1067 | tpr=0.6225 | fpr=0.9028 | 7688.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.79841 | acc=0.1060 | tpr=0.6044 | fpr=0.9030 | 7951.7 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.80336 | acc=0.1054 | tpr=0.6009 | fpr=0.9037 | 7788.8 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.80462 | acc=0.1056 | tpr=0.6058 | fpr=0.9035 | 7875.0 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.79592 | acc=0.1058 | tpr=0.6086 | fpr=0.9033 | 8048.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.79520 | acc=0.1060 | tpr=0.6078 | fpr=0.9031 | 7443.0 samples/s | 29.1 steps/s
[Step= 450] | Loss=5.79786 | acc=0.1062 | tpr=0.6115 | fpr=0.9030 | 8374.8 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.80096 | acc=0.1057 | tpr=0.6079 | fpr=0.9033 | 7501.1 samples/s | 29.3 steps/s
[Step= 550] | Loss=5.80440 | acc=0.1057 | tpr=0.6100 | fpr=0.9035 | 14908.2 samples/s | 58.2 steps/s
Avg test loss: 5.80632, Avg test acc: 0.10561, Avg tpr: 0.60975, Avg fpr: 0.90356, total FA: 125457

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10344 | acc=0.9806 | tpr=0.9204 | fpr=0.0183 | 5047.2 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.10586 | acc=0.9811 | tpr=0.9403 | fpr=0.0181 | 6628.6 samples/s | 25.9 steps/s
[Step= 150] | Loss=0.11117 | acc=0.9800 | tpr=0.9409 | fpr=0.0193 | 7913.6 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.11320 | acc=0.9798 | tpr=0.9464 | fpr=0.0196 | 7834.6 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.11089 | acc=0.9801 | tpr=0.9415 | fpr=0.0192 | 7956.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11317 | acc=0.9797 | tpr=0.9367 | fpr=0.0195 | 7779.0 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.11375 | acc=0.9796 | tpr=0.9374 | fpr=0.0197 | 8181.5 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.11477 | acc=0.9794 | tpr=0.9338 | fpr=0.0198 | 7824.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.11636 | acc=0.9791 | tpr=0.9299 | fpr=0.0200 | 8090.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11538 | acc=0.9792 | tpr=0.9317 | fpr=0.0199 | 7486.6 samples/s | 29.2 steps/s
[Step= 550] | Loss=0.11481 | acc=0.9794 | tpr=0.9312 | fpr=0.0197 | 14436.9 samples/s | 56.4 steps/s
Avg test loss: 0.11458, Avg test acc: 0.97944, Avg tpr: 0.93106, Avg fpr: 0.01968, total FA: 2733

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11215 | acc=0.9821 | tpr=0.9336 | fpr=0.0170 | 4623.5 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.11632 | acc=0.9815 | tpr=0.9147 | fpr=0.0172 | 7845.3 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.11889 | acc=0.9812 | tpr=0.9164 | fpr=0.0176 | 7659.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.12223 | acc=0.9809 | tpr=0.9191 | fpr=0.0180 | 7797.1 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.12040 | acc=0.9811 | tpr=0.9144 | fpr=0.0177 | 7748.6 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.12350 | acc=0.9806 | tpr=0.9098 | fpr=0.0181 | 7834.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.12403 | acc=0.9805 | tpr=0.9123 | fpr=0.0183 | 8119.7 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.12529 | acc=0.9802 | tpr=0.9070 | fpr=0.0185 | 7439.9 samples/s | 29.1 steps/s
[Step= 450] | Loss=0.12773 | acc=0.9799 | tpr=0.9056 | fpr=0.0187 | 8117.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.12680 | acc=0.9801 | tpr=0.9075 | fpr=0.0186 | 7937.2 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.12628 | acc=0.9803 | tpr=0.9065 | fpr=0.0184 | 13864.3 samples/s | 54.2 steps/s
Avg test loss: 0.12614, Avg test acc: 0.98029, Avg tpr: 0.90689, Avg fpr: 0.01837, total FA: 2551

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.11325 | acc=0.9809 | tpr=0.9513 | fpr=0.0186 | 4832.8 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.11698 | acc=0.9803 | tpr=0.9403 | fpr=0.0190 | 6899.5 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.12041 | acc=0.9797 | tpr=0.9438 | fpr=0.0197 | 7944.3 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.12305 | acc=0.9796 | tpr=0.9497 | fpr=0.0199 | 7527.7 samples/s | 29.4 steps/s
[Step= 250] | Loss=0.12132 | acc=0.9797 | tpr=0.9502 | fpr=0.0197 | 8169.6 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.12439 | acc=0.9794 | tpr=0.9411 | fpr=0.0199 | 8183.9 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.12454 | acc=0.9794 | tpr=0.9436 | fpr=0.0199 | 7835.6 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.12596 | acc=0.9792 | tpr=0.9409 | fpr=0.0201 | 7562.0 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.12791 | acc=0.9791 | tpr=0.9401 | fpr=0.0202 | 7807.3 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.12735 | acc=0.9790 | tpr=0.9414 | fpr=0.0203 | 8055.7 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.12687 | acc=0.9792 | tpr=0.9403 | fpr=0.0201 | 14147.5 samples/s | 55.3 steps/s
Avg test loss: 0.12690, Avg test acc: 0.97920, Avg tpr: 0.94057, Avg fpr: 0.02010, total FA: 2791

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10946 | acc=0.9802 | tpr=0.9115 | fpr=0.0186 | 4846.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.11271 | acc=0.9805 | tpr=0.9083 | fpr=0.0181 | 7118.8 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.11815 | acc=0.9798 | tpr=0.9150 | fpr=0.0190 | 7730.2 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.12095 | acc=0.9796 | tpr=0.9191 | fpr=0.0193 | 7768.8 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.11961 | acc=0.9800 | tpr=0.9118 | fpr=0.0188 | 7897.5 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.12222 | acc=0.9797 | tpr=0.9120 | fpr=0.0191 | 8160.0 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.12227 | acc=0.9796 | tpr=0.9167 | fpr=0.0192 | 7699.7 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.12185 | acc=0.9795 | tpr=0.9130 | fpr=0.0193 | 7940.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.12455 | acc=0.9793 | tpr=0.9119 | fpr=0.0195 | 7764.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.12369 | acc=0.9794 | tpr=0.9141 | fpr=0.0194 | 8326.1 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.12336 | acc=0.9796 | tpr=0.9148 | fpr=0.0192 | 13187.2 samples/s | 51.5 steps/s
Avg test loss: 0.12330, Avg test acc: 0.97963, Avg tpr: 0.91482, Avg fpr: 0.01919, total FA: 2665

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.11939 | acc=0.9797 | tpr=0.9204 | fpr=0.0192 | 4768.5 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.12570 | acc=0.9788 | tpr=0.9168 | fpr=0.0200 | 7553.0 samples/s | 29.5 steps/s
[Step= 150] | Loss=0.12910 | acc=0.9784 | tpr=0.9222 | fpr=0.0206 | 7263.3 samples/s | 28.4 steps/s
[Step= 200] | Loss=0.13070 | acc=0.9782 | tpr=0.9279 | fpr=0.0208 | 8143.3 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.12899 | acc=0.9786 | tpr=0.9258 | fpr=0.0205 | 7983.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.13124 | acc=0.9784 | tpr=0.9222 | fpr=0.0206 | 7516.7 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.13133 | acc=0.9784 | tpr=0.9255 | fpr=0.0206 | 8137.6 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.13283 | acc=0.9781 | tpr=0.9218 | fpr=0.0208 | 7958.5 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.13571 | acc=0.9779 | tpr=0.9192 | fpr=0.0210 | 7745.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13490 | acc=0.9781 | tpr=0.9207 | fpr=0.0209 | 7768.2 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.13427 | acc=0.9782 | tpr=0.9180 | fpr=0.0207 | 14684.9 samples/s | 57.4 steps/s
Avg test loss: 0.13406, Avg test acc: 0.97819, Avg tpr: 0.91838, Avg fpr: 0.02072, total FA: 2877

server round 13/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=126.8] | Loss=0.00520 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.122 | L2-Norm(final)=9.432 | 5242.6 samples/s | 81.9 steps/s
[Step=26050 Epoch=127.0] | Loss=0.00385 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.113 | L2-Norm(final)=9.443 | 4472.6 samples/s | 69.9 steps/s
[Step=26100 Epoch=127.3] | Loss=0.00403 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.106 | L2-Norm(final)=9.455 | 5050.5 samples/s | 78.9 steps/s
[Step=26150 Epoch=127.5] | Loss=0.00405 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.101 | L2-Norm(final)=9.468 | 4962.9 samples/s | 77.5 steps/s
[Step=26200 Epoch=127.8] | Loss=0.00426 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.095 | L2-Norm(final)=9.479 | 7938.4 samples/s | 124.0 steps/s
[Step=26250 Epoch=128.0] | Loss=0.00421 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.088 | L2-Norm(final)=9.490 | 2242.1 samples/s | 35.0 steps/s
[Step=26300 Epoch=128.2] | Loss=0.00405 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.082 | L2-Norm(final)=9.502 | 5080.7 samples/s | 79.4 steps/s
[Step=26350 Epoch=128.5] | Loss=0.00397 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.074 | L2-Norm(final)=9.513 | 5001.4 samples/s | 78.1 steps/s
[Step=26400 Epoch=128.7] | Loss=0.00397 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.066 | L2-Norm(final)=9.524 | 6830.9 samples/s | 106.7 steps/s
[Step=26450 Epoch=129.0] | Loss=0.00376 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.058 | L2-Norm(final)=9.535 | 2296.0 samples/s | 35.9 steps/s
[Step=26500 Epoch=129.2] | Loss=0.00372 | Reg=0.00443 | acc=0.9844 | L2-Norm=21.050 | L2-Norm(final)=9.545 | 4954.2 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=129.2] | Loss=0.00208 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.966 | L2-Norm(final)=9.653 | 5323.8 samples/s | 83.2 steps/s
[Step=26550 Epoch=129.5] | Loss=0.00346 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.957 | L2-Norm(final)=9.662 | 4065.7 samples/s | 63.5 steps/s
[Step=26600 Epoch=129.7] | Loss=0.00446 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.951 | L2-Norm(final)=9.667 | 4470.5 samples/s | 69.9 steps/s
[Step=26650 Epoch=130.0] | Loss=0.00836 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.952 | L2-Norm(final)=9.669 | 4548.5 samples/s | 71.1 steps/s
[Step=26700 Epoch=130.2] | Loss=0.01072 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.967 | L2-Norm(final)=9.670 | 6417.4 samples/s | 100.3 steps/s
[Step=26750 Epoch=130.4] | Loss=0.01325 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.991 | L2-Norm(final)=9.671 | 2069.0 samples/s | 32.3 steps/s
[Step=26800 Epoch=130.7] | Loss=0.01358 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.021 | L2-Norm(final)=9.670 | 4525.1 samples/s | 70.7 steps/s
[Step=26850 Epoch=130.9] | Loss=0.01348 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.047 | L2-Norm(final)=9.672 | 4450.6 samples/s | 69.5 steps/s
[Step=26900 Epoch=131.2] | Loss=0.01331 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.070 | L2-Norm(final)=9.673 | 5836.7 samples/s | 91.2 steps/s
[Step=26950 Epoch=131.4] | Loss=0.01299 | Reg=0.00445 | acc=0.9844 | L2-Norm=21.089 | L2-Norm(final)=9.676 | 2173.3 samples/s | 34.0 steps/s
[Step=27000 Epoch=131.7] | Loss=0.01284 | Reg=0.00445 | acc=0.9688 | L2-Norm=21.105 | L2-Norm(final)=9.678 | 4540.1 samples/s | 70.9 steps/s
[Step=27050 Epoch=131.9] | Loss=0.01230 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.119 | L2-Norm(final)=9.682 | 4432.4 samples/s | 69.3 steps/s
[Step=27100 Epoch=132.1] | Loss=0.01186 | Reg=0.00447 | acc=0.9844 | L2-Norm=21.131 | L2-Norm(final)=9.685 | 5387.0 samples/s | 84.2 steps/s
[Step=27150 Epoch=132.4] | Loss=0.01150 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.143 | L2-Norm(final)=9.689 | 2208.6 samples/s | 34.5 steps/s
[Step=27200 Epoch=132.6] | Loss=0.01124 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.154 | L2-Norm(final)=9.693 | 4397.9 samples/s | 68.7 steps/s
[Step=27250 Epoch=132.9] | Loss=0.01096 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.164 | L2-Norm(final)=9.696 | 4464.7 samples/s | 69.8 steps/s
[Step=27300 Epoch=133.1] | Loss=0.01065 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.172 | L2-Norm(final)=9.700 | 4991.9 samples/s | 78.0 steps/s
[Step=27350 Epoch=133.4] | Loss=0.01047 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.179 | L2-Norm(final)=9.703 | 2359.9 samples/s | 36.9 steps/s
[Step=27400 Epoch=133.6] | Loss=0.01010 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.184 | L2-Norm(final)=9.706 | 4472.5 samples/s | 69.9 steps/s
[Step=27450 Epoch=133.9] | Loss=0.00985 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.189 | L2-Norm(final)=9.709 | 4436.8 samples/s | 69.3 steps/s
[Step=27500 Epoch=134.1] | Loss=0.00965 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.192 | L2-Norm(final)=9.712 | 4588.7 samples/s | 71.7 steps/s
[Step=27550 Epoch=134.3] | Loss=0.00939 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.194 | L2-Norm(final)=9.714 | 2424.4 samples/s | 37.9 steps/s
[Step=27600 Epoch=134.6] | Loss=0.00914 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.195 | L2-Norm(final)=9.716 | 4512.9 samples/s | 70.5 steps/s
[Step=27650 Epoch=134.8] | Loss=0.00888 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.195 | L2-Norm(final)=9.719 | 4389.7 samples/s | 68.6 steps/s
[Step=27700 Epoch=135.1] | Loss=0.00872 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.194 | L2-Norm(final)=9.721 | 4500.8 samples/s | 70.3 steps/s
[Step=27750 Epoch=135.3] | Loss=0.00853 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.193 | L2-Norm(final)=9.723 | 2474.8 samples/s | 38.7 steps/s
[Step=27800 Epoch=135.6] | Loss=0.00831 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.191 | L2-Norm(final)=9.725 | 4395.9 samples/s | 68.7 steps/s
[Step=27850 Epoch=135.8] | Loss=0.00819 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.188 | L2-Norm(final)=9.727 | 4514.9 samples/s | 70.5 steps/s
[Step=27900 Epoch=136.0] | Loss=0.00797 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.185 | L2-Norm(final)=9.729 | 4456.4 samples/s | 69.6 steps/s
[Step=27950 Epoch=136.3] | Loss=0.00782 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.182 | L2-Norm(final)=9.731 | 2444.7 samples/s | 38.2 steps/s
[Step=28000 Epoch=136.5] | Loss=0.00766 | Reg=0.00449 | acc=1.0000 | L2-Norm=21.178 | L2-Norm(final)=9.733 | 4492.2 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step28000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=126.9] | Loss=0.00100 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.266 | L2-Norm(final)=9.538 | 5232.1 samples/s | 81.8 steps/s
[Step=26050 Epoch=127.1] | Loss=0.00451 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.260 | L2-Norm(final)=9.544 | 4491.7 samples/s | 70.2 steps/s
[Step=26100 Epoch=127.4] | Loss=0.00402 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.256 | L2-Norm(final)=9.554 | 5204.4 samples/s | 81.3 steps/s
[Step=26150 Epoch=127.6] | Loss=0.00403 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.253 | L2-Norm(final)=9.564 | 4748.7 samples/s | 74.2 steps/s
[Step=26200 Epoch=127.8] | Loss=0.00399 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.248 | L2-Norm(final)=9.575 | 7923.1 samples/s | 123.8 steps/s
[Step=26250 Epoch=128.1] | Loss=0.00382 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.242 | L2-Norm(final)=9.586 | 2207.1 samples/s | 34.5 steps/s
[Step=26300 Epoch=128.3] | Loss=0.00380 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.236 | L2-Norm(final)=9.596 | 4993.2 samples/s | 78.0 steps/s
[Step=26350 Epoch=128.6] | Loss=0.00374 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.228 | L2-Norm(final)=9.606 | 5105.9 samples/s | 79.8 steps/s
[Step=26400 Epoch=128.8] | Loss=0.00364 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.221 | L2-Norm(final)=9.616 | 7027.3 samples/s | 109.8 steps/s
[Step=26450 Epoch=129.1] | Loss=0.00352 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.213 | L2-Norm(final)=9.625 | 2290.2 samples/s | 35.8 steps/s
[Step=26500 Epoch=129.3] | Loss=0.00348 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.205 | L2-Norm(final)=9.635 | 5064.0 samples/s | 79.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=129.3] | Loss=0.00067 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.123 | L2-Norm(final)=9.730 | 5477.0 samples/s | 85.6 steps/s
[Step=26550 Epoch=129.6] | Loss=0.00491 | Reg=0.00446 | acc=0.9844 | L2-Norm=21.113 | L2-Norm(final)=9.736 | 3976.6 samples/s | 62.1 steps/s
[Step=26600 Epoch=129.8] | Loss=0.00643 | Reg=0.00446 | acc=0.9844 | L2-Norm=21.108 | L2-Norm(final)=9.733 | 4536.9 samples/s | 70.9 steps/s
[Step=26650 Epoch=130.0] | Loss=0.00626 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.109 | L2-Norm(final)=9.736 | 4480.4 samples/s | 70.0 steps/s
[Step=26700 Epoch=130.3] | Loss=0.00754 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.114 | L2-Norm(final)=9.741 | 6585.1 samples/s | 102.9 steps/s
[Step=26750 Epoch=130.5] | Loss=0.00835 | Reg=0.00446 | acc=1.0000 | L2-Norm=21.125 | L2-Norm(final)=9.746 | 2084.6 samples/s | 32.6 steps/s
[Step=26800 Epoch=130.8] | Loss=0.00892 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.136 | L2-Norm(final)=9.751 | 4487.6 samples/s | 70.1 steps/s
[Step=26850 Epoch=131.0] | Loss=0.00922 | Reg=0.00447 | acc=1.0000 | L2-Norm=21.149 | L2-Norm(final)=9.755 | 4400.5 samples/s | 68.8 steps/s
[Step=26900 Epoch=131.3] | Loss=0.00914 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.162 | L2-Norm(final)=9.761 | 6083.7 samples/s | 95.1 steps/s
[Step=26950 Epoch=131.5] | Loss=0.00886 | Reg=0.00448 | acc=1.0000 | L2-Norm=21.175 | L2-Norm(final)=9.766 | 2158.8 samples/s | 33.7 steps/s
[Step=27000 Epoch=131.7] | Loss=0.00904 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.186 | L2-Norm(final)=9.771 | 4405.8 samples/s | 68.8 steps/s
[Step=27050 Epoch=132.0] | Loss=0.00941 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.197 | L2-Norm(final)=9.775 | 4541.6 samples/s | 71.0 steps/s
[Step=27100 Epoch=132.2] | Loss=0.00922 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.208 | L2-Norm(final)=9.780 | 5489.0 samples/s | 85.8 steps/s
[Step=27150 Epoch=132.5] | Loss=0.00903 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.217 | L2-Norm(final)=9.785 | 2210.0 samples/s | 34.5 steps/s
[Step=27200 Epoch=132.7] | Loss=0.00877 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.224 | L2-Norm(final)=9.789 | 4374.1 samples/s | 68.3 steps/s
[Step=27250 Epoch=133.0] | Loss=0.00856 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.230 | L2-Norm(final)=9.794 | 4468.3 samples/s | 69.8 steps/s
[Step=27300 Epoch=133.2] | Loss=0.00827 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.235 | L2-Norm(final)=9.799 | 5229.6 samples/s | 81.7 steps/s
[Step=27350 Epoch=133.5] | Loss=0.00813 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.239 | L2-Norm(final)=9.803 | 2288.2 samples/s | 35.8 steps/s
[Step=27400 Epoch=133.7] | Loss=0.00805 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.242 | L2-Norm(final)=9.807 | 4415.6 samples/s | 69.0 steps/s
[Step=27450 Epoch=133.9] | Loss=0.00797 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.244 | L2-Norm(final)=9.811 | 4474.6 samples/s | 69.9 steps/s
[Step=27500 Epoch=134.2] | Loss=0.00781 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.245 | L2-Norm(final)=9.814 | 4868.9 samples/s | 76.1 steps/s
[Step=27550 Epoch=134.4] | Loss=0.00762 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.245 | L2-Norm(final)=9.818 | 2336.6 samples/s | 36.5 steps/s
[Step=27600 Epoch=134.7] | Loss=0.00746 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.245 | L2-Norm(final)=9.821 | 4544.7 samples/s | 71.0 steps/s
[Step=27650 Epoch=134.9] | Loss=0.00729 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.244 | L2-Norm(final)=9.825 | 4423.2 samples/s | 69.1 steps/s
[Step=27700 Epoch=135.2] | Loss=0.00717 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.242 | L2-Norm(final)=9.828 | 4574.9 samples/s | 71.5 steps/s
[Step=27750 Epoch=135.4] | Loss=0.00700 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.240 | L2-Norm(final)=9.831 | 2424.5 samples/s | 37.9 steps/s
[Step=27800 Epoch=135.7] | Loss=0.00684 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.236 | L2-Norm(final)=9.834 | 4426.2 samples/s | 69.2 steps/s
[Step=27850 Epoch=135.9] | Loss=0.00672 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.233 | L2-Norm(final)=9.837 | 4620.1 samples/s | 72.2 steps/s
[Step=27900 Epoch=136.1] | Loss=0.00663 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.228 | L2-Norm(final)=9.840 | 4277.4 samples/s | 66.8 steps/s
[Step=27950 Epoch=136.4] | Loss=0.00650 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.224 | L2-Norm(final)=9.842 | 2444.0 samples/s | 38.2 steps/s
[Step=28000 Epoch=136.6] | Loss=0.00640 | Reg=0.00450 | acc=0.9844 | L2-Norm=21.219 | L2-Norm(final)=9.845 | 4481.1 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step28000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=126.7] | Loss=0.00693 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.360 | L2-Norm(final)=9.965 | 5489.7 samples/s | 85.8 steps/s
[Step=26050 Epoch=126.9] | Loss=0.00418 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.360 | L2-Norm(final)=9.976 | 4372.6 samples/s | 68.3 steps/s
[Step=26100 Epoch=127.2] | Loss=0.00471 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.357 | L2-Norm(final)=9.987 | 5169.3 samples/s | 80.8 steps/s
[Step=26150 Epoch=127.4] | Loss=0.00476 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.354 | L2-Norm(final)=10.001 | 4918.0 samples/s | 76.8 steps/s
[Step=26200 Epoch=127.7] | Loss=0.00488 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.349 | L2-Norm(final)=10.013 | 7834.0 samples/s | 122.4 steps/s
[Step=26250 Epoch=127.9] | Loss=0.00469 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.342 | L2-Norm(final)=10.025 | 2227.7 samples/s | 34.8 steps/s
[Step=26300 Epoch=128.1] | Loss=0.00436 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.336 | L2-Norm(final)=10.036 | 4964.3 samples/s | 77.6 steps/s
[Step=26350 Epoch=128.4] | Loss=0.00444 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.329 | L2-Norm(final)=10.048 | 5113.3 samples/s | 79.9 steps/s
[Step=26400 Epoch=128.6] | Loss=0.00437 | Reg=0.00455 | acc=0.9844 | L2-Norm=21.322 | L2-Norm(final)=10.059 | 6880.7 samples/s | 107.5 steps/s
[Step=26450 Epoch=128.9] | Loss=0.00424 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.314 | L2-Norm(final)=10.071 | 2302.7 samples/s | 36.0 steps/s
[Step=26500 Epoch=129.1] | Loss=0.00423 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.307 | L2-Norm(final)=10.082 | 4955.1 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=129.1] | Loss=0.00108 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.228 | L2-Norm(final)=10.194 | 5476.0 samples/s | 85.6 steps/s
[Step=26550 Epoch=129.4] | Loss=0.00639 | Reg=0.00450 | acc=0.9844 | L2-Norm=21.223 | L2-Norm(final)=10.202 | 4121.4 samples/s | 64.4 steps/s
[Step=26600 Epoch=129.6] | Loss=0.00912 | Reg=0.00451 | acc=0.9844 | L2-Norm=21.226 | L2-Norm(final)=10.207 | 4442.5 samples/s | 69.4 steps/s
[Step=26650 Epoch=129.9] | Loss=0.01000 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.240 | L2-Norm(final)=10.212 | 4435.6 samples/s | 69.3 steps/s
[Step=26700 Epoch=130.1] | Loss=0.01243 | Reg=0.00452 | acc=0.9531 | L2-Norm=21.259 | L2-Norm(final)=10.214 | 6581.5 samples/s | 102.8 steps/s
[Step=26750 Epoch=130.3] | Loss=0.01500 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.281 | L2-Norm(final)=10.213 | 2091.1 samples/s | 32.7 steps/s
[Step=26800 Epoch=130.6] | Loss=0.01471 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.303 | L2-Norm(final)=10.213 | 4584.4 samples/s | 71.6 steps/s
[Step=26850 Epoch=130.8] | Loss=0.01511 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.324 | L2-Norm(final)=10.214 | 4403.3 samples/s | 68.8 steps/s
[Step=26900 Epoch=131.1] | Loss=0.01444 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.342 | L2-Norm(final)=10.216 | 5911.2 samples/s | 92.4 steps/s
[Step=26950 Epoch=131.3] | Loss=0.01388 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.358 | L2-Norm(final)=10.219 | 2137.3 samples/s | 33.4 steps/s
[Step=27000 Epoch=131.6] | Loss=0.01330 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.370 | L2-Norm(final)=10.223 | 4489.0 samples/s | 70.1 steps/s
[Step=27050 Epoch=131.8] | Loss=0.01268 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.380 | L2-Norm(final)=10.227 | 4489.4 samples/s | 70.1 steps/s
[Step=27100 Epoch=132.0] | Loss=0.01212 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.387 | L2-Norm(final)=10.230 | 5397.7 samples/s | 84.3 steps/s
[Step=27150 Epoch=132.3] | Loss=0.01150 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.393 | L2-Norm(final)=10.234 | 2297.7 samples/s | 35.9 steps/s
[Step=27200 Epoch=132.5] | Loss=0.01133 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.397 | L2-Norm(final)=10.237 | 4378.6 samples/s | 68.4 steps/s
[Step=27250 Epoch=132.8] | Loss=0.01089 | Reg=0.00458 | acc=0.9844 | L2-Norm=21.400 | L2-Norm(final)=10.240 | 4439.2 samples/s | 69.4 steps/s
[Step=27300 Epoch=133.0] | Loss=0.01051 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.403 | L2-Norm(final)=10.244 | 4907.5 samples/s | 76.7 steps/s
[Step=27350 Epoch=133.3] | Loss=0.01026 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.404 | L2-Norm(final)=10.247 | 2346.1 samples/s | 36.7 steps/s
[Step=27400 Epoch=133.5] | Loss=0.01009 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.404 | L2-Norm(final)=10.249 | 4402.6 samples/s | 68.8 steps/s
[Step=27450 Epoch=133.7] | Loss=0.00982 | Reg=0.00458 | acc=0.9844 | L2-Norm=21.404 | L2-Norm(final)=10.252 | 4522.9 samples/s | 70.7 steps/s
[Step=27500 Epoch=134.0] | Loss=0.00956 | Reg=0.00458 | acc=0.9844 | L2-Norm=21.402 | L2-Norm(final)=10.255 | 4569.9 samples/s | 71.4 steps/s
[Step=27550 Epoch=134.2] | Loss=0.00938 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.401 | L2-Norm(final)=10.258 | 2428.1 samples/s | 37.9 steps/s
[Step=27600 Epoch=134.5] | Loss=0.00915 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.398 | L2-Norm(final)=10.260 | 4454.4 samples/s | 69.6 steps/s
[Step=27650 Epoch=134.7] | Loss=0.00893 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.396 | L2-Norm(final)=10.263 | 4406.3 samples/s | 68.8 steps/s
[Step=27700 Epoch=135.0] | Loss=0.00878 | Reg=0.00458 | acc=0.9531 | L2-Norm=21.392 | L2-Norm(final)=10.265 | 4495.5 samples/s | 70.2 steps/s
[Step=27750 Epoch=135.2] | Loss=0.00856 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.389 | L2-Norm(final)=10.268 | 2468.1 samples/s | 38.6 steps/s
[Step=27800 Epoch=135.5] | Loss=0.00836 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.384 | L2-Norm(final)=10.270 | 4386.6 samples/s | 68.5 steps/s
[Step=27850 Epoch=135.7] | Loss=0.00815 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.379 | L2-Norm(final)=10.272 | 4438.8 samples/s | 69.4 steps/s
[Step=27900 Epoch=135.9] | Loss=0.00798 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.374 | L2-Norm(final)=10.275 | 4456.8 samples/s | 69.6 steps/s
[Step=27950 Epoch=136.2] | Loss=0.00789 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.369 | L2-Norm(final)=10.277 | 2454.4 samples/s | 38.3 steps/s
[Step=28000 Epoch=136.4] | Loss=0.00775 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.363 | L2-Norm(final)=10.279 | 4485.0 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step28000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=126.8] | Loss=0.00146 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.363 | L2-Norm(final)=9.745 | 5375.3 samples/s | 84.0 steps/s
[Step=26050 Epoch=127.0] | Loss=0.00351 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.358 | L2-Norm(final)=9.753 | 4445.6 samples/s | 69.5 steps/s
[Step=26100 Epoch=127.3] | Loss=0.00339 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.350 | L2-Norm(final)=9.764 | 5079.3 samples/s | 79.4 steps/s
[Step=26150 Epoch=127.5] | Loss=0.00364 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.343 | L2-Norm(final)=9.776 | 5013.0 samples/s | 78.3 steps/s
[Step=26200 Epoch=127.8] | Loss=0.00395 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.337 | L2-Norm(final)=9.788 | 7972.1 samples/s | 124.6 steps/s
[Step=26250 Epoch=128.0] | Loss=0.00380 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.331 | L2-Norm(final)=9.799 | 2242.0 samples/s | 35.0 steps/s
[Step=26300 Epoch=128.3] | Loss=0.00369 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.324 | L2-Norm(final)=9.811 | 5026.4 samples/s | 78.5 steps/s
[Step=26350 Epoch=128.5] | Loss=0.00368 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.317 | L2-Norm(final)=9.822 | 4846.9 samples/s | 75.7 steps/s
[Step=26400 Epoch=128.7] | Loss=0.00354 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.310 | L2-Norm(final)=9.834 | 7032.9 samples/s | 109.9 steps/s
[Step=26450 Epoch=129.0] | Loss=0.00350 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.302 | L2-Norm(final)=9.845 | 2301.2 samples/s | 36.0 steps/s
[Step=26500 Epoch=129.2] | Loss=0.00341 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.294 | L2-Norm(final)=9.856 | 4955.5 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=129.2] | Loss=0.00225 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.213 | L2-Norm(final)=9.965 | 5629.9 samples/s | 88.0 steps/s
[Step=26550 Epoch=129.5] | Loss=0.00304 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.207 | L2-Norm(final)=9.975 | 3876.8 samples/s | 60.6 steps/s
[Step=26600 Epoch=129.7] | Loss=0.00436 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.206 | L2-Norm(final)=9.981 | 4494.0 samples/s | 70.2 steps/s
[Step=26650 Epoch=130.0] | Loss=0.00590 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.208 | L2-Norm(final)=9.985 | 4493.9 samples/s | 70.2 steps/s
[Step=26700 Epoch=130.2] | Loss=0.00793 | Reg=0.00450 | acc=0.9844 | L2-Norm=21.213 | L2-Norm(final)=9.986 | 6392.4 samples/s | 99.9 steps/s
[Step=26750 Epoch=130.4] | Loss=0.00896 | Reg=0.00450 | acc=0.9375 | L2-Norm=21.222 | L2-Norm(final)=9.986 | 2089.1 samples/s | 32.6 steps/s
[Step=26800 Epoch=130.7] | Loss=0.00919 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.232 | L2-Norm(final)=9.988 | 4604.3 samples/s | 71.9 steps/s
[Step=26850 Epoch=130.9] | Loss=0.01035 | Reg=0.00451 | acc=1.0000 | L2-Norm=21.244 | L2-Norm(final)=9.989 | 4395.9 samples/s | 68.7 steps/s
[Step=26900 Epoch=131.2] | Loss=0.01025 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.257 | L2-Norm(final)=9.991 | 5911.4 samples/s | 92.4 steps/s
[Step=26950 Epoch=131.4] | Loss=0.01006 | Reg=0.00452 | acc=1.0000 | L2-Norm=21.270 | L2-Norm(final)=9.993 | 2184.9 samples/s | 34.1 steps/s
[Step=27000 Epoch=131.7] | Loss=0.00975 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.282 | L2-Norm(final)=9.996 | 4359.2 samples/s | 68.1 steps/s
[Step=27050 Epoch=131.9] | Loss=0.00961 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.291 | L2-Norm(final)=10.000 | 4489.6 samples/s | 70.2 steps/s
[Step=27100 Epoch=132.2] | Loss=0.00970 | Reg=0.00454 | acc=0.9688 | L2-Norm=21.300 | L2-Norm(final)=10.003 | 5414.6 samples/s | 84.6 steps/s
[Step=27150 Epoch=132.4] | Loss=0.00935 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.308 | L2-Norm(final)=10.006 | 2253.9 samples/s | 35.2 steps/s
[Step=27200 Epoch=132.6] | Loss=0.00903 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.315 | L2-Norm(final)=10.010 | 4511.3 samples/s | 70.5 steps/s
[Step=27250 Epoch=132.9] | Loss=0.00879 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.320 | L2-Norm(final)=10.014 | 4437.5 samples/s | 69.3 steps/s
[Step=27300 Epoch=133.1] | Loss=0.00853 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.324 | L2-Norm(final)=10.017 | 4998.7 samples/s | 78.1 steps/s
[Step=27350 Epoch=133.4] | Loss=0.00830 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.326 | L2-Norm(final)=10.021 | 2333.2 samples/s | 36.5 steps/s
[Step=27400 Epoch=133.6] | Loss=0.00797 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.328 | L2-Norm(final)=10.024 | 4408.0 samples/s | 68.9 steps/s
[Step=27450 Epoch=133.9] | Loss=0.00778 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.329 | L2-Norm(final)=10.028 | 4480.1 samples/s | 70.0 steps/s
[Step=27500 Epoch=134.1] | Loss=0.00761 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.328 | L2-Norm(final)=10.031 | 4648.6 samples/s | 72.6 steps/s
[Step=27550 Epoch=134.3] | Loss=0.00754 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.327 | L2-Norm(final)=10.034 | 2440.2 samples/s | 38.1 steps/s
[Step=27600 Epoch=134.6] | Loss=0.00735 | Reg=0.00455 | acc=0.9844 | L2-Norm=21.326 | L2-Norm(final)=10.036 | 4435.0 samples/s | 69.3 steps/s
[Step=27650 Epoch=134.8] | Loss=0.00717 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.323 | L2-Norm(final)=10.039 | 4492.4 samples/s | 70.2 steps/s
[Step=27700 Epoch=135.1] | Loss=0.00697 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.320 | L2-Norm(final)=10.042 | 4416.0 samples/s | 69.0 steps/s
[Step=27750 Epoch=135.3] | Loss=0.00687 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.316 | L2-Norm(final)=10.045 | 2455.0 samples/s | 38.4 steps/s
[Step=27800 Epoch=135.6] | Loss=0.00672 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.312 | L2-Norm(final)=10.047 | 4358.5 samples/s | 68.1 steps/s
[Step=27850 Epoch=135.8] | Loss=0.00659 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.307 | L2-Norm(final)=10.049 | 4485.1 samples/s | 70.1 steps/s
[Step=27900 Epoch=136.1] | Loss=0.00644 | Reg=0.00454 | acc=0.9844 | L2-Norm=21.302 | L2-Norm(final)=10.052 | 4468.8 samples/s | 69.8 steps/s
[Step=27950 Epoch=136.3] | Loss=0.00635 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.296 | L2-Norm(final)=10.054 | 2467.5 samples/s | 38.6 steps/s
[Step=28000 Epoch=136.5] | Loss=0.00622 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.290 | L2-Norm(final)=10.056 | 4518.8 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step28000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=127.5] | Loss=0.00475 | Reg=0.00441 | acc=1.0000 | L2-Norm=21.007 | L2-Norm(final)=9.801 | 5048.6 samples/s | 78.9 steps/s
[Step=26050 Epoch=127.7] | Loss=0.00377 | Reg=0.00441 | acc=0.9688 | L2-Norm=21.000 | L2-Norm(final)=9.808 | 4791.4 samples/s | 74.9 steps/s
[Step=26100 Epoch=128.0] | Loss=0.00410 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.995 | L2-Norm(final)=9.817 | 4957.8 samples/s | 77.5 steps/s
[Step=26150 Epoch=128.2] | Loss=0.00420 | Reg=0.00441 | acc=1.0000 | L2-Norm=20.989 | L2-Norm(final)=9.827 | 5086.1 samples/s | 79.5 steps/s
[Step=26200 Epoch=128.5] | Loss=0.00410 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.982 | L2-Norm(final)=9.838 | 7996.3 samples/s | 124.9 steps/s
[Step=26250 Epoch=128.7] | Loss=0.00396 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.976 | L2-Norm(final)=9.850 | 2196.4 samples/s | 34.3 steps/s
[Step=26300 Epoch=129.0] | Loss=0.00386 | Reg=0.00440 | acc=1.0000 | L2-Norm=20.969 | L2-Norm(final)=9.862 | 5079.2 samples/s | 79.4 steps/s
[Step=26350 Epoch=129.2] | Loss=0.00378 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.962 | L2-Norm(final)=9.874 | 5006.1 samples/s | 78.2 steps/s
[Step=26400 Epoch=129.5] | Loss=0.00370 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.954 | L2-Norm(final)=9.886 | 7463.5 samples/s | 116.6 steps/s
[Step=26450 Epoch=129.7] | Loss=0.00354 | Reg=0.00439 | acc=1.0000 | L2-Norm=20.947 | L2-Norm(final)=9.898 | 2250.8 samples/s | 35.2 steps/s
[Step=26500 Epoch=130.0] | Loss=0.00351 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.939 | L2-Norm(final)=9.909 | 4991.2 samples/s | 78.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=130.0] | Loss=0.00477 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.856 | L2-Norm(final)=10.022 | 5494.8 samples/s | 85.9 steps/s
[Step=26550 Epoch=130.2] | Loss=0.00297 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.847 | L2-Norm(final)=10.032 | 3959.9 samples/s | 61.9 steps/s
[Step=26600 Epoch=130.4] | Loss=0.00513 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.843 | L2-Norm(final)=10.037 | 4516.7 samples/s | 70.6 steps/s
[Step=26650 Epoch=130.7] | Loss=0.00740 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.846 | L2-Norm(final)=10.039 | 4415.9 samples/s | 69.0 steps/s
[Step=26700 Epoch=130.9] | Loss=0.00848 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.858 | L2-Norm(final)=10.043 | 6672.1 samples/s | 104.3 steps/s
[Step=26750 Epoch=131.2] | Loss=0.01119 | Reg=0.00436 | acc=0.9688 | L2-Norm=20.881 | L2-Norm(final)=10.045 | 2073.8 samples/s | 32.4 steps/s
[Step=26800 Epoch=131.4] | Loss=0.01264 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.910 | L2-Norm(final)=10.048 | 4384.4 samples/s | 68.5 steps/s
[Step=26850 Epoch=131.7] | Loss=0.01290 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.939 | L2-Norm(final)=10.050 | 4496.5 samples/s | 70.3 steps/s
[Step=26900 Epoch=131.9] | Loss=0.01351 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.964 | L2-Norm(final)=10.052 | 6233.2 samples/s | 97.4 steps/s
[Step=26950 Epoch=132.2] | Loss=0.01313 | Reg=0.00440 | acc=0.9844 | L2-Norm=20.986 | L2-Norm(final)=10.054 | 2149.1 samples/s | 33.6 steps/s
[Step=27000 Epoch=132.4] | Loss=0.01303 | Reg=0.00441 | acc=0.9844 | L2-Norm=21.006 | L2-Norm(final)=10.056 | 4408.3 samples/s | 68.9 steps/s
[Step=27050 Epoch=132.6] | Loss=0.01273 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.022 | L2-Norm(final)=10.058 | 4462.3 samples/s | 69.7 steps/s
[Step=27100 Epoch=132.9] | Loss=0.01216 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.036 | L2-Norm(final)=10.060 | 5764.5 samples/s | 90.1 steps/s
[Step=27150 Epoch=133.1] | Loss=0.01179 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.047 | L2-Norm(final)=10.063 | 2146.1 samples/s | 33.5 steps/s
[Step=27200 Epoch=133.4] | Loss=0.01142 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.056 | L2-Norm(final)=10.065 | 4409.0 samples/s | 68.9 steps/s
[Step=27250 Epoch=133.6] | Loss=0.01099 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.063 | L2-Norm(final)=10.068 | 4538.9 samples/s | 70.9 steps/s
[Step=27300 Epoch=133.9] | Loss=0.01058 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.069 | L2-Norm(final)=10.070 | 5457.2 samples/s | 85.3 steps/s
[Step=27350 Epoch=134.1] | Loss=0.01022 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.073 | L2-Norm(final)=10.073 | 2208.6 samples/s | 34.5 steps/s
[Step=27400 Epoch=134.4] | Loss=0.00983 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.076 | L2-Norm(final)=10.075 | 4399.7 samples/s | 68.7 steps/s
[Step=27450 Epoch=134.6] | Loss=0.00943 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.078 | L2-Norm(final)=10.078 | 4348.7 samples/s | 67.9 steps/s
[Step=27500 Epoch=134.9] | Loss=0.00918 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.079 | L2-Norm(final)=10.081 | 5182.9 samples/s | 81.0 steps/s
[Step=27550 Epoch=135.1] | Loss=0.00895 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.079 | L2-Norm(final)=10.083 | 2256.5 samples/s | 35.3 steps/s
[Step=27600 Epoch=135.3] | Loss=0.00871 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.078 | L2-Norm(final)=10.086 | 4511.8 samples/s | 70.5 steps/s
[Step=27650 Epoch=135.6] | Loss=0.00856 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.076 | L2-Norm(final)=10.088 | 4442.5 samples/s | 69.4 steps/s
[Step=27700 Epoch=135.8] | Loss=0.00838 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.074 | L2-Norm(final)=10.090 | 4954.6 samples/s | 77.4 steps/s
[Step=27750 Epoch=136.1] | Loss=0.00815 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.071 | L2-Norm(final)=10.092 | 2329.3 samples/s | 36.4 steps/s
[Step=27800 Epoch=136.3] | Loss=0.00802 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.068 | L2-Norm(final)=10.094 | 4386.4 samples/s | 68.5 steps/s
[Step=27850 Epoch=136.6] | Loss=0.00785 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.065 | L2-Norm(final)=10.096 | 4535.2 samples/s | 70.9 steps/s
[Step=27900 Epoch=136.8] | Loss=0.00769 | Reg=0.00444 | acc=1.0000 | L2-Norm=21.061 | L2-Norm(final)=10.098 | 4625.9 samples/s | 72.3 steps/s
[Step=27950 Epoch=137.1] | Loss=0.00755 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.056 | L2-Norm(final)=10.099 | 2399.0 samples/s | 37.5 steps/s
[Step=28000 Epoch=137.3] | Loss=0.00739 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.051 | L2-Norm(final)=10.101 | 4546.7 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step28000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=246.4] | Loss=0.00024 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.426 | L2-Norm(final)=5.664 | 5736.9 samples/s | 89.6 steps/s
[Step=26050 Epoch=246.8] | Loss=0.00028 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.433 | L2-Norm(final)=5.672 | 3956.9 samples/s | 61.8 steps/s
[Step=26100 Epoch=247.3] | Loss=0.00019 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.438 | L2-Norm(final)=5.682 | 7245.5 samples/s | 113.2 steps/s
[Step=26150 Epoch=247.8] | Loss=0.00014 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.440 | L2-Norm(final)=5.688 | 2109.7 samples/s | 33.0 steps/s
[Step=26200 Epoch=248.3] | Loss=0.00012 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.441 | L2-Norm(final)=5.694 | 6464.5 samples/s | 101.0 steps/s
[Step=26250 Epoch=248.7] | Loss=0.00010 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.440 | L2-Norm(final)=5.699 | 2228.6 samples/s | 34.8 steps/s
[Step=26300 Epoch=249.2] | Loss=0.00009 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.440 | L2-Norm(final)=5.703 | 5964.3 samples/s | 93.2 steps/s
[Step=26350 Epoch=249.7] | Loss=0.00008 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.439 | L2-Norm(final)=5.707 | 2314.1 samples/s | 36.2 steps/s
[Step=26400 Epoch=250.2] | Loss=0.00008 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.438 | L2-Norm(final)=5.711 | 5372.6 samples/s | 83.9 steps/s
[Step=26450 Epoch=250.6] | Loss=0.00007 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.436 | L2-Norm(final)=5.715 | 2403.2 samples/s | 37.5 steps/s
[Step=26500 Epoch=251.1] | Loss=0.00007 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.434 | L2-Norm(final)=5.719 | 4713.7 samples/s | 73.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=251.1] | Loss=0.00005 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.418 | L2-Norm(final)=5.755 | 6015.2 samples/s | 94.0 steps/s
[Step=26550 Epoch=251.6] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.409 | L2-Norm(final)=5.758 | 3486.1 samples/s | 54.5 steps/s
[Step=26600 Epoch=252.1] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.398 | L2-Norm(final)=5.761 | 6278.6 samples/s | 98.1 steps/s
[Step=26650 Epoch=252.5] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.386 | L2-Norm(final)=5.763 | 2016.3 samples/s | 31.5 steps/s
[Step=26700 Epoch=253.0] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.373 | L2-Norm(final)=5.764 | 5538.0 samples/s | 86.5 steps/s
[Step=26750 Epoch=253.5] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=5.765 | 2095.6 samples/s | 32.7 steps/s
[Step=26800 Epoch=254.0] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.347 | L2-Norm(final)=5.767 | 5053.5 samples/s | 79.0 steps/s
[Step=26850 Epoch=254.4] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.333 | L2-Norm(final)=5.768 | 2192.4 samples/s | 34.3 steps/s
[Step=26900 Epoch=254.9] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=5.769 | 4742.5 samples/s | 74.1 steps/s
[Step=26950 Epoch=255.4] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.307 | L2-Norm(final)=5.770 | 2249.3 samples/s | 35.1 steps/s
[Step=27000 Epoch=255.8] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.293 | L2-Norm(final)=5.770 | 4248.4 samples/s | 66.4 steps/s
[Step=27050 Epoch=256.3] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.279 | L2-Norm(final)=5.771 | 2343.5 samples/s | 36.6 steps/s
[Step=27100 Epoch=256.8] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.265 | L2-Norm(final)=5.772 | 4319.2 samples/s | 67.5 steps/s
[Step=27150 Epoch=257.3] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.251 | L2-Norm(final)=5.773 | 2375.2 samples/s | 37.1 steps/s
[Step=27200 Epoch=257.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.237 | L2-Norm(final)=5.774 | 4197.6 samples/s | 65.6 steps/s
[Step=27250 Epoch=258.2] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.223 | L2-Norm(final)=5.775 | 2381.0 samples/s | 37.2 steps/s
[Step=27300 Epoch=258.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.209 | L2-Norm(final)=5.775 | 4204.3 samples/s | 65.7 steps/s
[Step=27350 Epoch=259.2] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.195 | L2-Norm(final)=5.776 | 2457.2 samples/s | 38.4 steps/s
[Step=27400 Epoch=259.6] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.180 | L2-Norm(final)=5.777 | 4170.6 samples/s | 65.2 steps/s
[Step=27450 Epoch=260.1] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.166 | L2-Norm(final)=5.778 | 6327.9 samples/s | 98.9 steps/s
[Step=27500 Epoch=260.6] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.151 | L2-Norm(final)=5.778 | 1994.8 samples/s | 31.2 steps/s
[Step=27550 Epoch=261.1] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.137 | L2-Norm(final)=5.779 | 5853.0 samples/s | 91.5 steps/s
[Step=27600 Epoch=261.5] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.122 | L2-Norm(final)=5.780 | 2090.0 samples/s | 32.7 steps/s
[Step=27650 Epoch=262.0] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.107 | L2-Norm(final)=5.780 | 5114.6 samples/s | 79.9 steps/s
[Step=27700 Epoch=262.5] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.092 | L2-Norm(final)=5.781 | 2142.1 samples/s | 33.5 steps/s
[Step=27750 Epoch=263.0] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.077 | L2-Norm(final)=5.782 | 4852.8 samples/s | 75.8 steps/s
[Step=27800 Epoch=263.4] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.062 | L2-Norm(final)=5.783 | 2240.9 samples/s | 35.0 steps/s
[Step=27850 Epoch=263.9] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.047 | L2-Norm(final)=5.783 | 4314.9 samples/s | 67.4 steps/s
[Step=27900 Epoch=264.4] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.031 | L2-Norm(final)=5.784 | 2259.3 samples/s | 35.3 steps/s
[Step=27950 Epoch=264.9] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.016 | L2-Norm(final)=5.785 | 4227.9 samples/s | 66.1 steps/s
[Step=28000 Epoch=265.3] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.000 | L2-Norm(final)=5.785 | 2393.0 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step28000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=247.3] | Loss=0.00024 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.044 | L2-Norm(final)=6.237 | 5332.6 samples/s | 83.3 steps/s
[Step=26050 Epoch=247.8] | Loss=0.00029 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.066 | L2-Norm(final)=6.260 | 4166.5 samples/s | 65.1 steps/s
[Step=26100 Epoch=248.3] | Loss=0.00047 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.110 | L2-Norm(final)=6.288 | 7596.5 samples/s | 118.7 steps/s
[Step=26150 Epoch=248.8] | Loss=0.00044 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.156 | L2-Norm(final)=6.311 | 2138.7 samples/s | 33.4 steps/s
[Step=26200 Epoch=249.2] | Loss=0.00035 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.183 | L2-Norm(final)=6.327 | 6630.8 samples/s | 103.6 steps/s
[Step=26250 Epoch=249.7] | Loss=0.00028 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.200 | L2-Norm(final)=6.340 | 2248.1 samples/s | 35.1 steps/s
[Step=26300 Epoch=250.2] | Loss=0.00024 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.211 | L2-Norm(final)=6.350 | 5839.7 samples/s | 91.2 steps/s
[Step=26350 Epoch=250.7] | Loss=0.00021 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.218 | L2-Norm(final)=6.359 | 2403.7 samples/s | 37.6 steps/s
[Step=26400 Epoch=251.1] | Loss=0.00019 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.222 | L2-Norm(final)=6.366 | 4979.7 samples/s | 77.8 steps/s
[Step=26450 Epoch=251.6] | Loss=0.00017 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.225 | L2-Norm(final)=6.373 | 2385.7 samples/s | 37.3 steps/s
[Step=26500 Epoch=252.1] | Loss=0.00015 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.226 | L2-Norm(final)=6.379 | 4929.6 samples/s | 77.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=252.1] | Loss=0.00017 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.238 | L2-Norm(final)=6.439 | 5379.8 samples/s | 84.1 steps/s
[Step=26550 Epoch=252.6] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.212 | L2-Norm(final)=6.444 | 3749.7 samples/s | 58.6 steps/s
[Step=26600 Epoch=253.0] | Loss=0.00002 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.176 | L2-Norm(final)=6.447 | 6314.8 samples/s | 98.7 steps/s
[Step=26650 Epoch=253.5] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.138 | L2-Norm(final)=6.449 | 2016.1 samples/s | 31.5 steps/s
[Step=26700 Epoch=254.0] | Loss=0.00001 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.098 | L2-Norm(final)=6.450 | 5699.3 samples/s | 89.1 steps/s
[Step=26750 Epoch=254.5] | Loss=0.00001 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.058 | L2-Norm(final)=6.451 | 2060.4 samples/s | 32.2 steps/s
[Step=26800 Epoch=254.9] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.019 | L2-Norm(final)=6.452 | 5184.5 samples/s | 81.0 steps/s
[Step=26850 Epoch=255.4] | Loss=0.00001 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.980 | L2-Norm(final)=6.453 | 2198.1 samples/s | 34.3 steps/s
[Step=26900 Epoch=255.9] | Loss=0.00001 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.941 | L2-Norm(final)=6.453 | 4688.0 samples/s | 73.3 steps/s
[Step=26950 Epoch=256.4] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.902 | L2-Norm(final)=6.454 | 2252.5 samples/s | 35.2 steps/s
[Step=27000 Epoch=256.8] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.864 | L2-Norm(final)=6.454 | 4370.2 samples/s | 68.3 steps/s
[Step=27050 Epoch=257.3] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.825 | L2-Norm(final)=6.455 | 2293.3 samples/s | 35.8 steps/s
[Step=27100 Epoch=257.8] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.787 | L2-Norm(final)=6.456 | 4218.9 samples/s | 65.9 steps/s
[Step=27150 Epoch=258.3] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.749 | L2-Norm(final)=6.456 | 2418.2 samples/s | 37.8 steps/s
[Step=27200 Epoch=258.7] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.711 | L2-Norm(final)=6.457 | 4118.0 samples/s | 64.3 steps/s
[Step=27250 Epoch=259.2] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.674 | L2-Norm(final)=6.457 | 2413.1 samples/s | 37.7 steps/s
[Step=27300 Epoch=259.7] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.636 | L2-Norm(final)=6.458 | 4157.7 samples/s | 65.0 steps/s
[Step=27350 Epoch=260.2] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.598 | L2-Norm(final)=6.458 | 2480.3 samples/s | 38.8 steps/s
[Step=27400 Epoch=260.6] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.561 | L2-Norm(final)=6.459 | 4108.1 samples/s | 64.2 steps/s
[Step=27450 Epoch=261.1] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.523 | L2-Norm(final)=6.459 | 6507.3 samples/s | 101.7 steps/s
[Step=27500 Epoch=261.6] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.486 | L2-Norm(final)=6.460 | 2005.6 samples/s | 31.3 steps/s
[Step=27550 Epoch=262.1] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.449 | L2-Norm(final)=6.461 | 5830.0 samples/s | 91.1 steps/s
[Step=27600 Epoch=262.5] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=6.461 | 2069.4 samples/s | 32.3 steps/s
[Step=27650 Epoch=263.0] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.374 | L2-Norm(final)=6.462 | 5207.0 samples/s | 81.4 steps/s
[Step=27700 Epoch=263.5] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.336 | L2-Norm(final)=6.462 | 2147.7 samples/s | 33.6 steps/s
[Step=27750 Epoch=264.0] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.299 | L2-Norm(final)=6.463 | 4867.9 samples/s | 76.1 steps/s
[Step=27800 Epoch=264.4] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.464 | 2237.0 samples/s | 35.0 steps/s
[Step=27850 Epoch=264.9] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.224 | L2-Norm(final)=6.464 | 4524.1 samples/s | 70.7 steps/s
[Step=27900 Epoch=265.4] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.187 | L2-Norm(final)=6.465 | 2312.1 samples/s | 36.1 steps/s
[Step=27950 Epoch=265.9] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.150 | L2-Norm(final)=6.466 | 4297.4 samples/s | 67.1 steps/s
[Step=28000 Epoch=266.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=6.467 | 2394.2 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step28000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=248.3] | Loss=0.00029 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.324 | L2-Norm(final)=6.145 | 5020.6 samples/s | 78.4 steps/s
[Step=26050 Epoch=248.8] | Loss=0.00017 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=6.154 | 4353.7 samples/s | 68.0 steps/s
[Step=26100 Epoch=249.2] | Loss=0.00014 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.343 | L2-Norm(final)=6.167 | 7414.8 samples/s | 115.9 steps/s
[Step=26150 Epoch=249.7] | Loss=0.00011 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.351 | L2-Norm(final)=6.177 | 2132.8 samples/s | 33.3 steps/s
[Step=26200 Epoch=250.2] | Loss=0.00010 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=6.187 | 6567.7 samples/s | 102.6 steps/s
[Step=26250 Epoch=250.7] | Loss=0.00008 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.358 | L2-Norm(final)=6.196 | 2244.8 samples/s | 35.1 steps/s
[Step=26300 Epoch=251.1] | Loss=0.00008 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=6.205 | 5859.9 samples/s | 91.6 steps/s
[Step=26350 Epoch=251.6] | Loss=0.00007 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=6.214 | 2297.2 samples/s | 35.9 steps/s
[Step=26400 Epoch=252.1] | Loss=0.00006 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=6.223 | 5569.0 samples/s | 87.0 steps/s
[Step=26450 Epoch=252.6] | Loss=0.00006 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=6.232 | 2353.3 samples/s | 36.8 steps/s
[Step=26500 Epoch=253.1] | Loss=0.00006 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=6.241 | 5048.2 samples/s | 78.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=253.1] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.353 | L2-Norm(final)=6.328 | 5547.0 samples/s | 86.7 steps/s
[Step=26550 Epoch=253.5] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.342 | L2-Norm(final)=6.335 | 3655.9 samples/s | 57.1 steps/s
[Step=26600 Epoch=254.0] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.328 | L2-Norm(final)=6.341 | 6379.9 samples/s | 99.7 steps/s
[Step=26650 Epoch=254.5] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.313 | L2-Norm(final)=6.345 | 2002.1 samples/s | 31.3 steps/s
[Step=26700 Epoch=255.0] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.296 | L2-Norm(final)=6.349 | 5728.0 samples/s | 89.5 steps/s
[Step=26750 Epoch=255.4] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.280 | L2-Norm(final)=6.351 | 2054.8 samples/s | 32.1 steps/s
[Step=26800 Epoch=255.9] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.263 | L2-Norm(final)=6.353 | 5303.2 samples/s | 82.9 steps/s
[Step=26850 Epoch=256.4] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.246 | L2-Norm(final)=6.355 | 2147.7 samples/s | 33.6 steps/s
[Step=26900 Epoch=256.9] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.228 | L2-Norm(final)=6.356 | 4993.5 samples/s | 78.0 steps/s
[Step=26950 Epoch=257.4] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.211 | L2-Norm(final)=6.358 | 2224.1 samples/s | 34.8 steps/s
[Step=27000 Epoch=257.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.194 | L2-Norm(final)=6.359 | 4588.6 samples/s | 71.7 steps/s
[Step=27050 Epoch=258.3] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.176 | L2-Norm(final)=6.361 | 2281.3 samples/s | 35.6 steps/s
[Step=27100 Epoch=258.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.159 | L2-Norm(final)=6.362 | 4290.8 samples/s | 67.0 steps/s
[Step=27150 Epoch=259.3] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.141 | L2-Norm(final)=6.363 | 2344.8 samples/s | 36.6 steps/s
[Step=27200 Epoch=259.7] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.123 | L2-Norm(final)=6.364 | 4425.6 samples/s | 69.2 steps/s
[Step=27250 Epoch=260.2] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.105 | L2-Norm(final)=6.365 | 2344.5 samples/s | 36.6 steps/s
[Step=27300 Epoch=260.7] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.087 | L2-Norm(final)=6.366 | 4247.5 samples/s | 66.4 steps/s
[Step=27350 Epoch=261.2] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.069 | L2-Norm(final)=6.367 | 2351.0 samples/s | 36.7 steps/s
[Step=27400 Epoch=261.7] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.051 | L2-Norm(final)=6.368 | 4269.2 samples/s | 66.7 steps/s
[Step=27450 Epoch=262.1] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.033 | L2-Norm(final)=6.369 | 2517.0 samples/s | 39.3 steps/s
[Step=27500 Epoch=262.6] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.015 | L2-Norm(final)=6.370 | 3936.5 samples/s | 61.5 steps/s
[Step=27550 Epoch=263.1] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.997 | L2-Norm(final)=6.371 | 6994.7 samples/s | 109.3 steps/s
[Step=27600 Epoch=263.6] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.978 | L2-Norm(final)=6.372 | 1988.8 samples/s | 31.1 steps/s
[Step=27650 Epoch=264.0] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.959 | L2-Norm(final)=6.373 | 6109.6 samples/s | 95.5 steps/s
[Step=27700 Epoch=264.5] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.941 | L2-Norm(final)=6.375 | 1989.1 samples/s | 31.1 steps/s
[Step=27750 Epoch=265.0] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.922 | L2-Norm(final)=6.376 | 5837.2 samples/s | 91.2 steps/s
[Step=27800 Epoch=265.5] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.903 | L2-Norm(final)=6.377 | 2091.6 samples/s | 32.7 steps/s
[Step=27850 Epoch=266.0] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.884 | L2-Norm(final)=6.378 | 5243.1 samples/s | 81.9 steps/s
[Step=27900 Epoch=266.4] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.865 | L2-Norm(final)=6.379 | 2166.8 samples/s | 33.9 steps/s
[Step=27950 Epoch=266.9] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.846 | L2-Norm(final)=6.380 | 4763.3 samples/s | 74.4 steps/s
[Step=28000 Epoch=267.4] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.826 | L2-Norm(final)=6.381 | 2241.7 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step28000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=245.0] | Loss=0.00944 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.395 | L2-Norm(final)=5.948 | 5533.5 samples/s | 86.5 steps/s
[Step=26050 Epoch=245.5] | Loss=0.00062 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.419 | L2-Norm(final)=5.948 | 4013.5 samples/s | 62.7 steps/s
[Step=26100 Epoch=245.9] | Loss=0.00037 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.425 | L2-Norm(final)=5.954 | 7365.3 samples/s | 115.1 steps/s
[Step=26150 Epoch=246.4] | Loss=0.00027 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=5.960 | 2154.4 samples/s | 33.7 steps/s
[Step=26200 Epoch=246.9] | Loss=0.00022 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=5.965 | 6314.5 samples/s | 98.7 steps/s
[Step=26250 Epoch=247.3] | Loss=0.00018 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.430 | L2-Norm(final)=5.970 | 2233.7 samples/s | 34.9 steps/s
[Step=26300 Epoch=247.8] | Loss=0.00016 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=5.974 | 5586.3 samples/s | 87.3 steps/s
[Step=26350 Epoch=248.3] | Loss=0.00014 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=5.978 | 2363.6 samples/s | 36.9 steps/s
[Step=26400 Epoch=248.8] | Loss=0.00013 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.428 | L2-Norm(final)=5.981 | 5171.6 samples/s | 80.8 steps/s
[Step=26450 Epoch=249.2] | Loss=0.00012 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.427 | L2-Norm(final)=5.985 | 2461.4 samples/s | 38.5 steps/s
[Step=26500 Epoch=249.7] | Loss=0.00011 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.426 | L2-Norm(final)=5.988 | 4758.6 samples/s | 74.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=249.7] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.414 | L2-Norm(final)=6.024 | 5573.5 samples/s | 87.1 steps/s
[Step=26550 Epoch=250.2] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.408 | L2-Norm(final)=6.027 | 3556.7 samples/s | 55.6 steps/s
[Step=26600 Epoch=250.6] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.401 | L2-Norm(final)=6.030 | 6268.9 samples/s | 98.0 steps/s
[Step=26650 Epoch=251.1] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.393 | L2-Norm(final)=6.032 | 2031.1 samples/s | 31.7 steps/s
[Step=26700 Epoch=251.6] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.384 | L2-Norm(final)=6.034 | 5534.3 samples/s | 86.5 steps/s
[Step=26750 Epoch=252.1] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.375 | L2-Norm(final)=6.035 | 2142.7 samples/s | 33.5 steps/s
[Step=26800 Epoch=252.5] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.366 | L2-Norm(final)=6.037 | 4782.8 samples/s | 74.7 steps/s
[Step=26850 Epoch=253.0] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.357 | L2-Norm(final)=6.038 | 2192.4 samples/s | 34.3 steps/s
[Step=26900 Epoch=253.5] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.348 | L2-Norm(final)=6.039 | 4386.6 samples/s | 68.5 steps/s
[Step=26950 Epoch=253.9] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.338 | L2-Norm(final)=6.040 | 2361.0 samples/s | 36.9 steps/s
[Step=27000 Epoch=254.4] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.329 | L2-Norm(final)=6.041 | 4242.5 samples/s | 66.3 steps/s
[Step=27050 Epoch=254.9] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.319 | L2-Norm(final)=6.042 | 2388.1 samples/s | 37.3 steps/s
[Step=27100 Epoch=255.4] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.310 | L2-Norm(final)=6.042 | 4155.4 samples/s | 64.9 steps/s
[Step=27150 Epoch=255.8] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=6.043 | 2387.3 samples/s | 37.3 steps/s
[Step=27200 Epoch=256.3] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.290 | L2-Norm(final)=6.044 | 4230.0 samples/s | 66.1 steps/s
[Step=27250 Epoch=256.8] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.280 | L2-Norm(final)=6.045 | 2681.6 samples/s | 41.9 steps/s
[Step=27300 Epoch=257.2] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.270 | L2-Norm(final)=6.046 | 3547.3 samples/s | 55.4 steps/s
[Step=27350 Epoch=257.7] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.260 | L2-Norm(final)=6.046 | 6363.5 samples/s | 99.4 steps/s
[Step=27400 Epoch=258.2] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.249 | L2-Norm(final)=6.047 | 2011.9 samples/s | 31.4 steps/s
[Step=27450 Epoch=258.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.239 | L2-Norm(final)=6.048 | 5575.6 samples/s | 87.1 steps/s
[Step=27500 Epoch=259.1] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.229 | L2-Norm(final)=6.049 | 2121.7 samples/s | 33.2 steps/s
[Step=27550 Epoch=259.6] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.218 | L2-Norm(final)=6.049 | 5054.5 samples/s | 79.0 steps/s
[Step=27600 Epoch=260.1] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.207 | L2-Norm(final)=6.050 | 2224.4 samples/s | 34.8 steps/s
[Step=27650 Epoch=260.5] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.197 | L2-Norm(final)=6.051 | 4518.4 samples/s | 70.6 steps/s
[Step=27700 Epoch=261.0] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.186 | L2-Norm(final)=6.051 | 2266.2 samples/s | 35.4 steps/s
[Step=27750 Epoch=261.5] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.175 | L2-Norm(final)=6.052 | 4229.4 samples/s | 66.1 steps/s
[Step=27800 Epoch=262.0] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.164 | L2-Norm(final)=6.053 | 2395.7 samples/s | 37.4 steps/s
[Step=27850 Epoch=262.4] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.153 | L2-Norm(final)=6.054 | 4374.1 samples/s | 68.3 steps/s
[Step=27900 Epoch=262.9] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.141 | L2-Norm(final)=6.054 | 2385.4 samples/s | 37.3 steps/s
[Step=27950 Epoch=263.4] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.130 | L2-Norm(final)=6.055 | 4189.1 samples/s | 65.5 steps/s
[Step=28000 Epoch=263.8] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.118 | L2-Norm(final)=6.056 | 2493.6 samples/s | 39.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step28000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=247.8] | Loss=0.00024 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.370 | L2-Norm(final)=6.837 | 5443.3 samples/s | 85.1 steps/s
[Step=26050 Epoch=248.3] | Loss=0.00056 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.419 | L2-Norm(final)=6.868 | 4116.9 samples/s | 64.3 steps/s
[Step=26100 Epoch=248.8] | Loss=0.00043 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.463 | L2-Norm(final)=6.902 | 7345.5 samples/s | 114.8 steps/s
[Step=26150 Epoch=249.2] | Loss=0.00032 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.488 | L2-Norm(final)=6.926 | 2130.8 samples/s | 33.3 steps/s
[Step=26200 Epoch=249.7] | Loss=0.00026 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=6.944 | 6893.5 samples/s | 107.7 steps/s
[Step=26250 Epoch=250.2] | Loss=0.00022 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.509 | L2-Norm(final)=6.958 | 2174.0 samples/s | 34.0 steps/s
[Step=26300 Epoch=250.7] | Loss=0.00019 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.514 | L2-Norm(final)=6.970 | 6115.8 samples/s | 95.6 steps/s
[Step=26350 Epoch=251.1] | Loss=0.00017 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.517 | L2-Norm(final)=6.981 | 2269.8 samples/s | 35.5 steps/s
[Step=26400 Epoch=251.6] | Loss=0.00016 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.518 | L2-Norm(final)=6.991 | 5628.7 samples/s | 87.9 steps/s
[Step=26450 Epoch=252.1] | Loss=0.00014 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.519 | L2-Norm(final)=7.001 | 2347.3 samples/s | 36.7 steps/s
[Step=26500 Epoch=252.6] | Loss=0.00013 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.519 | L2-Norm(final)=7.010 | 5234.2 samples/s | 81.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=252.6] | Loss=0.00002 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.515 | L2-Norm(final)=7.098 | 5660.3 samples/s | 88.4 steps/s
[Step=26550 Epoch=253.0] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.497 | L2-Norm(final)=7.105 | 3623.8 samples/s | 56.6 steps/s
[Step=26600 Epoch=253.5] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.471 | L2-Norm(final)=7.110 | 6358.5 samples/s | 99.4 steps/s
[Step=26650 Epoch=254.0] | Loss=0.00002 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.442 | L2-Norm(final)=7.113 | 2029.3 samples/s | 31.7 steps/s
[Step=26700 Epoch=254.5] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.411 | L2-Norm(final)=7.115 | 5695.2 samples/s | 89.0 steps/s
[Step=26750 Epoch=255.0] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.380 | L2-Norm(final)=7.116 | 2092.3 samples/s | 32.7 steps/s
[Step=26800 Epoch=255.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.348 | L2-Norm(final)=7.117 | 5153.9 samples/s | 80.5 steps/s
[Step=26850 Epoch=255.9] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.316 | L2-Norm(final)=7.118 | 2117.4 samples/s | 33.1 steps/s
[Step=26900 Epoch=256.4] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.283 | L2-Norm(final)=7.119 | 4962.5 samples/s | 77.5 steps/s
[Step=26950 Epoch=256.9] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.251 | L2-Norm(final)=7.120 | 2218.1 samples/s | 34.7 steps/s
[Step=27000 Epoch=257.3] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.219 | L2-Norm(final)=7.121 | 4637.8 samples/s | 72.5 steps/s
[Step=27050 Epoch=257.8] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.186 | L2-Norm(final)=7.121 | 2286.2 samples/s | 35.7 steps/s
[Step=27100 Epoch=258.3] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.154 | L2-Norm(final)=7.122 | 4292.5 samples/s | 67.1 steps/s
[Step=27150 Epoch=258.8] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.121 | L2-Norm(final)=7.122 | 2310.4 samples/s | 36.1 steps/s
[Step=27200 Epoch=259.2] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.089 | L2-Norm(final)=7.123 | 4134.9 samples/s | 64.6 steps/s
[Step=27250 Epoch=259.7] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.056 | L2-Norm(final)=7.124 | 2414.4 samples/s | 37.7 steps/s
[Step=27300 Epoch=260.2] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.024 | L2-Norm(final)=7.124 | 4204.9 samples/s | 65.7 steps/s
[Step=27350 Epoch=260.7] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.991 | L2-Norm(final)=7.125 | 2380.6 samples/s | 37.2 steps/s
[Step=27400 Epoch=261.1] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.958 | L2-Norm(final)=7.125 | 4245.3 samples/s | 66.3 steps/s
[Step=27450 Epoch=261.6] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.925 | L2-Norm(final)=7.126 | 2421.5 samples/s | 37.8 steps/s
[Step=27500 Epoch=262.1] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.892 | L2-Norm(final)=7.126 | 4244.8 samples/s | 66.3 steps/s
[Step=27550 Epoch=262.6] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.859 | L2-Norm(final)=7.127 | 6929.1 samples/s | 108.3 steps/s
[Step=27600 Epoch=263.1] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.826 | L2-Norm(final)=7.128 | 1971.7 samples/s | 30.8 steps/s
[Step=27650 Epoch=263.5] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.793 | L2-Norm(final)=7.128 | 6195.0 samples/s | 96.8 steps/s
[Step=27700 Epoch=264.0] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.760 | L2-Norm(final)=7.129 | 2032.8 samples/s | 31.8 steps/s
[Step=27750 Epoch=264.5] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.726 | L2-Norm(final)=7.129 | 5621.7 samples/s | 87.8 steps/s
[Step=27800 Epoch=265.0] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.693 | L2-Norm(final)=7.130 | 2059.4 samples/s | 32.2 steps/s
[Step=27850 Epoch=265.4] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.659 | L2-Norm(final)=7.131 | 5387.9 samples/s | 84.2 steps/s
[Step=27900 Epoch=265.9] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.626 | L2-Norm(final)=7.131 | 2138.9 samples/s | 33.4 steps/s
[Step=27950 Epoch=266.4] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.592 | L2-Norm(final)=7.132 | 4995.5 samples/s | 78.1 steps/s
[Step=28000 Epoch=266.9] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.558 | L2-Norm(final)=7.133 | 2229.9 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11730 | acc=0.9562 | tpr=0.9692 | fpr=0.0721 | 4827.4 samples/s | 18.9 steps/s
Avg test loss: 0.12267, Avg test acc: 0.95388, Avg tpr: 0.96649, Avg fpr: 0.07384, total FA: 576

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13493 | acc=0.9530 | tpr=0.9754 | fpr=0.0956 | 5005.1 samples/s | 19.6 steps/s
Avg test loss: 0.13605, Avg test acc: 0.95300, Avg tpr: 0.97395, Avg fpr: 0.09306, total FA: 726

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.12718 | acc=0.9567 | tpr=0.9735 | fpr=0.0798 | 4830.0 samples/s | 18.9 steps/s
Avg test loss: 0.12683, Avg test acc: 0.95460, Avg tpr: 0.97173, Avg fpr: 0.08307, total FA: 648

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13272 | acc=0.9531 | tpr=0.9686 | fpr=0.0805 | 5036.1 samples/s | 19.7 steps/s
Avg test loss: 0.13713, Avg test acc: 0.95320, Avg tpr: 0.96952, Avg fpr: 0.08268, total FA: 645

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.12145 | acc=0.9574 | tpr=0.9724 | fpr=0.0751 | 4952.4 samples/s | 19.3 steps/s
Avg test loss: 0.12824, Avg test acc: 0.95629, Avg tpr: 0.97208, Avg fpr: 0.07845, total FA: 612

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.00291 | acc=0.2799 | tpr=0.0224 | fpr=0.1608 | 4907.2 samples/s | 19.2 steps/s
Avg test loss: 6.01268, Avg test acc: 0.27927, Avg tpr: 0.02273, Avg fpr: 0.15652, total FA: 1221

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.92160 | acc=0.2816 | tpr=0.0062 | fpr=0.1202 | 4797.8 samples/s | 18.7 steps/s
Avg test loss: 4.94255, Avg test acc: 0.27923, Avg tpr: 0.00694, Avg fpr: 0.12191, total FA: 951

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=6.07315 | acc=0.2633 | tpr=0.0221 | fpr=0.2131 | 4824.5 samples/s | 18.8 steps/s
Avg test loss: 6.07884, Avg test acc: 0.26200, Avg tpr: 0.02238, Avg fpr: 0.21100, total FA: 1646

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=6.16490 | acc=0.2735 | tpr=0.0332 | fpr=0.2047 | 5038.1 samples/s | 19.7 steps/s
Avg test loss: 6.16337, Avg test acc: 0.27262, Avg tpr: 0.03322, Avg fpr: 0.20087, total FA: 1567

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.15191 | acc=0.2999 | tpr=0.0363 | fpr=0.1276 | 4901.2 samples/s | 19.1 steps/s
Avg test loss: 5.15696, Avg test acc: 0.29826, Avg tpr: 0.03719, Avg fpr: 0.12755, total FA: 995

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.82909 | acc=0.1026 | tpr=0.6372 | fpr=0.9070 | 4610.4 samples/s | 18.0 steps/s
[Step= 100] | Loss=5.81396 | acc=0.1028 | tpr=0.6290 | fpr=0.9070 | 7537.0 samples/s | 29.4 steps/s
[Step= 150] | Loss=5.84026 | acc=0.1048 | tpr=0.6225 | fpr=0.9047 | 7940.8 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.83517 | acc=0.1046 | tpr=0.6208 | fpr=0.9047 | 7885.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.84614 | acc=0.1044 | tpr=0.6210 | fpr=0.9050 | 7770.1 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.83810 | acc=0.1050 | tpr=0.6305 | fpr=0.9046 | 7777.2 samples/s | 30.4 steps/s
[Step= 350] | Loss=5.83532 | acc=0.1050 | tpr=0.6312 | fpr=0.9045 | 7979.1 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.82786 | acc=0.1053 | tpr=0.6313 | fpr=0.9043 | 7932.5 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.83313 | acc=0.1049 | tpr=0.6280 | fpr=0.9046 | 7847.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.84129 | acc=0.1047 | tpr=0.6273 | fpr=0.9047 | 7771.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=5.84089 | acc=0.1048 | tpr=0.6251 | fpr=0.9046 | 14830.3 samples/s | 57.9 steps/s
Avg test loss: 5.84240, Avg test acc: 0.10473, Avg tpr: 0.62559, Avg fpr: 0.90474, total FA: 125621

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.94334 | acc=0.0832 | tpr=0.6858 | fpr=0.9276 | 4912.6 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.91322 | acc=0.0837 | tpr=0.6588 | fpr=0.9271 | 6779.8 samples/s | 26.5 steps/s
[Step= 150] | Loss=5.91704 | acc=0.0852 | tpr=0.6599 | fpr=0.9254 | 8143.2 samples/s | 31.8 steps/s
[Step= 200] | Loss=5.90710 | acc=0.0854 | tpr=0.6503 | fpr=0.9248 | 7842.7 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.91331 | acc=0.0852 | tpr=0.6463 | fpr=0.9250 | 7927.5 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.90792 | acc=0.0848 | tpr=0.6516 | fpr=0.9255 | 7932.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.90434 | acc=0.0853 | tpr=0.6462 | fpr=0.9249 | 7984.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.89925 | acc=0.0856 | tpr=0.6439 | fpr=0.9245 | 7602.6 samples/s | 29.7 steps/s
[Step= 450] | Loss=5.90198 | acc=0.0852 | tpr=0.6441 | fpr=0.9249 | 7901.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.90492 | acc=0.0845 | tpr=0.6458 | fpr=0.9256 | 8099.0 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.90677 | acc=0.0842 | tpr=0.6442 | fpr=0.9260 | 14050.2 samples/s | 54.9 steps/s
Avg test loss: 5.90868, Avg test acc: 0.08409, Avg tpr: 0.64422, Avg fpr: 0.92609, total FA: 128586

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.83881 | acc=0.0748 | tpr=0.6062 | fpr=0.9347 | 4839.4 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.80884 | acc=0.0746 | tpr=0.5991 | fpr=0.9352 | 7296.9 samples/s | 28.5 steps/s
[Step= 150] | Loss=6.81868 | acc=0.0753 | tpr=0.6023 | fpr=0.9344 | 7638.6 samples/s | 29.8 steps/s
[Step= 200] | Loss=6.81056 | acc=0.0752 | tpr=0.6109 | fpr=0.9346 | 7884.8 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.81478 | acc=0.0752 | tpr=0.6070 | fpr=0.9345 | 7821.9 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.81458 | acc=0.0753 | tpr=0.6029 | fpr=0.9343 | 7827.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=6.80667 | acc=0.0754 | tpr=0.6024 | fpr=0.9341 | 8039.9 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.79955 | acc=0.0755 | tpr=0.6012 | fpr=0.9340 | 7698.6 samples/s | 30.1 steps/s
[Step= 450] | Loss=6.79979 | acc=0.0754 | tpr=0.5983 | fpr=0.9341 | 7919.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.80108 | acc=0.0752 | tpr=0.5916 | fpr=0.9341 | 8071.8 samples/s | 31.5 steps/s
[Step= 550] | Loss=6.80470 | acc=0.0753 | tpr=0.5901 | fpr=0.9341 | 13742.5 samples/s | 53.7 steps/s
Avg test loss: 6.80542, Avg test acc: 0.07523, Avg tpr: 0.59113, Avg fpr: 0.93415, total FA: 129705

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.74847 | acc=0.1159 | tpr=0.7257 | fpr=0.8950 | 4935.0 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.71351 | acc=0.1145 | tpr=0.7228 | fpr=0.8969 | 7081.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.72122 | acc=0.1151 | tpr=0.7305 | fpr=0.8963 | 7564.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=5.71704 | acc=0.1153 | tpr=0.7301 | fpr=0.8959 | 8048.9 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.72481 | acc=0.1157 | tpr=0.7249 | fpr=0.8954 | 7903.8 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.72199 | acc=0.1157 | tpr=0.7244 | fpr=0.8954 | 7627.2 samples/s | 29.8 steps/s
[Step= 350] | Loss=5.71475 | acc=0.1159 | tpr=0.7270 | fpr=0.8952 | 8010.7 samples/s | 31.3 steps/s
[Step= 400] | Loss=5.71267 | acc=0.1160 | tpr=0.7254 | fpr=0.8951 | 7775.7 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.71928 | acc=0.1158 | tpr=0.7288 | fpr=0.8953 | 8058.8 samples/s | 31.5 steps/s
[Step= 500] | Loss=5.72234 | acc=0.1155 | tpr=0.7317 | fpr=0.8957 | 7846.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.72379 | acc=0.1153 | tpr=0.7282 | fpr=0.8958 | 14271.9 samples/s | 55.7 steps/s
Avg test loss: 5.72510, Avg test acc: 0.11523, Avg tpr: 0.72861, Avg fpr: 0.89592, total FA: 124397

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.43816 | acc=0.0975 | tpr=0.7212 | fpr=0.9137 | 4790.8 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.42781 | acc=0.1002 | tpr=0.6994 | fpr=0.9109 | 7204.2 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.44233 | acc=0.1007 | tpr=0.6960 | fpr=0.9103 | 8071.9 samples/s | 31.5 steps/s
[Step= 200] | Loss=6.43383 | acc=0.1003 | tpr=0.6929 | fpr=0.9105 | 7416.4 samples/s | 29.0 steps/s
[Step= 250] | Loss=6.44580 | acc=0.1002 | tpr=0.6934 | fpr=0.9106 | 7962.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.44295 | acc=0.1001 | tpr=0.6953 | fpr=0.9107 | 7991.4 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.43847 | acc=0.0999 | tpr=0.6969 | fpr=0.9109 | 7894.0 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.43777 | acc=0.1004 | tpr=0.6997 | fpr=0.9105 | 7797.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.43989 | acc=0.1004 | tpr=0.7006 | fpr=0.9105 | 8212.6 samples/s | 32.1 steps/s
[Step= 500] | Loss=6.44298 | acc=0.1004 | tpr=0.6996 | fpr=0.9104 | 7396.6 samples/s | 28.9 steps/s
[Step= 550] | Loss=6.44527 | acc=0.1004 | tpr=0.7012 | fpr=0.9105 | 14889.2 samples/s | 58.2 steps/s
Avg test loss: 6.44731, Avg test acc: 0.10037, Avg tpr: 0.70166, Avg fpr: 0.91056, total FA: 126430

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10030 | acc=0.9816 | tpr=0.9381 | fpr=0.0176 | 4638.0 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.10410 | acc=0.9811 | tpr=0.9446 | fpr=0.0183 | 7348.0 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.10731 | acc=0.9806 | tpr=0.9424 | fpr=0.0187 | 7843.9 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.10931 | acc=0.9805 | tpr=0.9486 | fpr=0.0189 | 8168.7 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.10804 | acc=0.9807 | tpr=0.9432 | fpr=0.0187 | 7359.4 samples/s | 28.7 steps/s
[Step= 300] | Loss=0.11053 | acc=0.9802 | tpr=0.9396 | fpr=0.0191 | 8200.4 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.11103 | acc=0.9802 | tpr=0.9430 | fpr=0.0191 | 8118.2 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.11222 | acc=0.9799 | tpr=0.9393 | fpr=0.0194 | 7878.6 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11421 | acc=0.9797 | tpr=0.9372 | fpr=0.0196 | 7588.3 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.11331 | acc=0.9797 | tpr=0.9388 | fpr=0.0195 | 7831.3 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.11276 | acc=0.9799 | tpr=0.9379 | fpr=0.0193 | 15073.0 samples/s | 58.9 steps/s
Avg test loss: 0.11270, Avg test acc: 0.97990, Avg tpr: 0.93780, Avg fpr: 0.01933, total FA: 2684

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10140 | acc=0.9813 | tpr=0.9381 | fpr=0.0179 | 4853.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10483 | acc=0.9811 | tpr=0.9232 | fpr=0.0178 | 7141.6 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.10755 | acc=0.9807 | tpr=0.9251 | fpr=0.0183 | 8020.5 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.11018 | acc=0.9804 | tpr=0.9301 | fpr=0.0186 | 7750.3 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.10858 | acc=0.9807 | tpr=0.9249 | fpr=0.0183 | 7632.3 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.11099 | acc=0.9805 | tpr=0.9229 | fpr=0.0185 | 8198.6 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.11144 | acc=0.9805 | tpr=0.9267 | fpr=0.0186 | 8165.6 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.11255 | acc=0.9802 | tpr=0.9218 | fpr=0.0187 | 7709.2 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.11497 | acc=0.9799 | tpr=0.9192 | fpr=0.0190 | 7660.7 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.11398 | acc=0.9800 | tpr=0.9207 | fpr=0.0189 | 8071.8 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.11362 | acc=0.9801 | tpr=0.9200 | fpr=0.0188 | 14163.4 samples/s | 55.3 steps/s
Avg test loss: 0.11352, Avg test acc: 0.98012, Avg tpr: 0.92036, Avg fpr: 0.01880, total FA: 2610

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10777 | acc=0.9801 | tpr=0.9558 | fpr=0.0195 | 4842.4 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.11060 | acc=0.9798 | tpr=0.9510 | fpr=0.0197 | 6959.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.11451 | acc=0.9791 | tpr=0.9524 | fpr=0.0204 | 8257.9 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.11731 | acc=0.9792 | tpr=0.9574 | fpr=0.0204 | 7463.1 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.11566 | acc=0.9794 | tpr=0.9572 | fpr=0.0202 | 8075.1 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.11850 | acc=0.9790 | tpr=0.9491 | fpr=0.0204 | 8239.7 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.11895 | acc=0.9789 | tpr=0.9499 | fpr=0.0206 | 7651.0 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.12017 | acc=0.9786 | tpr=0.9480 | fpr=0.0208 | 7857.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.12208 | acc=0.9786 | tpr=0.9469 | fpr=0.0209 | 7404.9 samples/s | 28.9 steps/s
[Step= 500] | Loss=0.12145 | acc=0.9785 | tpr=0.9480 | fpr=0.0209 | 8019.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.12101 | acc=0.9787 | tpr=0.9467 | fpr=0.0208 | 13287.7 samples/s | 51.9 steps/s
Avg test loss: 0.12101, Avg test acc: 0.97867, Avg tpr: 0.94691, Avg fpr: 0.02076, total FA: 2882

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.11525 | acc=0.9791 | tpr=0.9336 | fpr=0.0201 | 4595.6 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.12018 | acc=0.9786 | tpr=0.9296 | fpr=0.0205 | 7202.0 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.12492 | acc=0.9785 | tpr=0.9337 | fpr=0.0207 | 7769.9 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.12779 | acc=0.9786 | tpr=0.9421 | fpr=0.0207 | 7978.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.12617 | acc=0.9790 | tpr=0.9397 | fpr=0.0203 | 7618.6 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.12947 | acc=0.9788 | tpr=0.9367 | fpr=0.0205 | 7697.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.12981 | acc=0.9787 | tpr=0.9399 | fpr=0.0206 | 8100.8 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.13030 | acc=0.9786 | tpr=0.9371 | fpr=0.0206 | 7830.4 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.13263 | acc=0.9783 | tpr=0.9343 | fpr=0.0209 | 7810.0 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.13170 | acc=0.9785 | tpr=0.9361 | fpr=0.0207 | 7733.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.13119 | acc=0.9787 | tpr=0.9351 | fpr=0.0205 | 14144.6 samples/s | 55.3 steps/s
Avg test loss: 0.13105, Avg test acc: 0.97869, Avg tpr: 0.93502, Avg fpr: 0.02052, total FA: 2849

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12268 | acc=0.9788 | tpr=0.9381 | fpr=0.0205 | 4683.9 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.12748 | acc=0.9780 | tpr=0.9382 | fpr=0.0212 | 7512.2 samples/s | 29.3 steps/s
[Step= 150] | Loss=0.13207 | acc=0.9771 | tpr=0.9409 | fpr=0.0222 | 7681.7 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13418 | acc=0.9769 | tpr=0.9475 | fpr=0.0225 | 7825.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.13259 | acc=0.9772 | tpr=0.9467 | fpr=0.0223 | 7483.1 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.13490 | acc=0.9768 | tpr=0.9440 | fpr=0.0226 | 8148.1 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.13513 | acc=0.9766 | tpr=0.9468 | fpr=0.0228 | 7741.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.13655 | acc=0.9765 | tpr=0.9431 | fpr=0.0229 | 8061.1 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.13938 | acc=0.9763 | tpr=0.9416 | fpr=0.0231 | 7817.8 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.13858 | acc=0.9763 | tpr=0.9414 | fpr=0.0230 | 7925.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.13775 | acc=0.9766 | tpr=0.9411 | fpr=0.0228 | 13684.3 samples/s | 53.5 steps/s
Avg test loss: 0.13754, Avg test acc: 0.97660, Avg tpr: 0.94136, Avg fpr: 0.02276, total FA: 3160

server round 14/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=136.5] | Loss=0.00137 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.554 | L2-Norm(final)=9.788 | 5058.7 samples/s | 79.0 steps/s
[Step=28050 Epoch=136.8] | Loss=0.00348 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.544 | L2-Norm(final)=9.795 | 4583.3 samples/s | 71.6 steps/s
[Step=28100 Epoch=137.0] | Loss=0.00357 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.535 | L2-Norm(final)=9.803 | 5196.4 samples/s | 81.2 steps/s
[Step=28150 Epoch=137.3] | Loss=0.00378 | Reg=0.00421 | acc=0.9688 | L2-Norm=20.527 | L2-Norm(final)=9.810 | 4804.2 samples/s | 75.1 steps/s
[Step=28200 Epoch=137.5] | Loss=0.00386 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.520 | L2-Norm(final)=9.818 | 7854.4 samples/s | 122.7 steps/s
[Step=28250 Epoch=137.8] | Loss=0.00348 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.514 | L2-Norm(final)=9.827 | 2189.9 samples/s | 34.2 steps/s
[Step=28300 Epoch=138.0] | Loss=0.00351 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.507 | L2-Norm(final)=9.835 | 4976.1 samples/s | 77.8 steps/s
[Step=28350 Epoch=138.2] | Loss=0.00362 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.499 | L2-Norm(final)=9.843 | 5021.2 samples/s | 78.5 steps/s
[Step=28400 Epoch=138.5] | Loss=0.00347 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.491 | L2-Norm(final)=9.851 | 6855.4 samples/s | 107.1 steps/s
[Step=28450 Epoch=138.7] | Loss=0.00349 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.483 | L2-Norm(final)=9.858 | 2259.6 samples/s | 35.3 steps/s
[Step=28500 Epoch=139.0] | Loss=0.00349 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.474 | L2-Norm(final)=9.866 | 4928.0 samples/s | 77.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=139.0] | Loss=0.00055 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.387 | L2-Norm(final)=9.941 | 5580.9 samples/s | 87.2 steps/s
[Step=28550 Epoch=139.2] | Loss=0.00615 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.382 | L2-Norm(final)=9.945 | 3849.8 samples/s | 60.2 steps/s
[Step=28600 Epoch=139.5] | Loss=0.00848 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.392 | L2-Norm(final)=9.948 | 4433.4 samples/s | 69.3 steps/s
[Step=28650 Epoch=139.7] | Loss=0.01081 | Reg=0.00417 | acc=0.9688 | L2-Norm=20.413 | L2-Norm(final)=9.953 | 4438.5 samples/s | 69.4 steps/s
[Step=28700 Epoch=139.9] | Loss=0.01130 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.436 | L2-Norm(final)=9.957 | 6548.4 samples/s | 102.3 steps/s
[Step=28750 Epoch=140.2] | Loss=0.01086 | Reg=0.00418 | acc=1.0000 | L2-Norm=20.457 | L2-Norm(final)=9.963 | 2083.6 samples/s | 32.6 steps/s
[Step=28800 Epoch=140.4] | Loss=0.01109 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.473 | L2-Norm(final)=9.968 | 4393.0 samples/s | 68.6 steps/s
[Step=28850 Epoch=140.7] | Loss=0.01075 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.486 | L2-Norm(final)=9.974 | 4418.7 samples/s | 69.0 steps/s
[Step=28900 Epoch=140.9] | Loss=0.01079 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.498 | L2-Norm(final)=9.980 | 5917.3 samples/s | 92.5 steps/s
[Step=28950 Epoch=141.2] | Loss=0.01017 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.509 | L2-Norm(final)=9.987 | 2148.8 samples/s | 33.6 steps/s
[Step=29000 Epoch=141.4] | Loss=0.01027 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.519 | L2-Norm(final)=9.993 | 4357.0 samples/s | 68.1 steps/s
[Step=29050 Epoch=141.7] | Loss=0.01004 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.527 | L2-Norm(final)=9.998 | 4543.7 samples/s | 71.0 steps/s
[Step=29100 Epoch=141.9] | Loss=0.00988 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.535 | L2-Norm(final)=10.004 | 5209.4 samples/s | 81.4 steps/s
[Step=29150 Epoch=142.1] | Loss=0.00964 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.542 | L2-Norm(final)=10.009 | 2219.2 samples/s | 34.7 steps/s
[Step=29200 Epoch=142.4] | Loss=0.00935 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.548 | L2-Norm(final)=10.014 | 4431.7 samples/s | 69.2 steps/s
[Step=29250 Epoch=142.6] | Loss=0.00915 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.552 | L2-Norm(final)=10.019 | 4463.3 samples/s | 69.7 steps/s
[Step=29300 Epoch=142.9] | Loss=0.00886 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.555 | L2-Norm(final)=10.024 | 4902.6 samples/s | 76.6 steps/s
[Step=29350 Epoch=143.1] | Loss=0.00865 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.557 | L2-Norm(final)=10.029 | 2295.0 samples/s | 35.9 steps/s
[Step=29400 Epoch=143.4] | Loss=0.00831 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.558 | L2-Norm(final)=10.033 | 4474.1 samples/s | 69.9 steps/s
[Step=29450 Epoch=143.6] | Loss=0.00810 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.557 | L2-Norm(final)=10.037 | 4382.0 samples/s | 68.5 steps/s
[Step=29500 Epoch=143.8] | Loss=0.00784 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.556 | L2-Norm(final)=10.041 | 4569.7 samples/s | 71.4 steps/s
[Step=29550 Epoch=144.1] | Loss=0.00773 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.554 | L2-Norm(final)=10.045 | 2363.0 samples/s | 36.9 steps/s
[Step=29600 Epoch=144.3] | Loss=0.00760 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.552 | L2-Norm(final)=10.048 | 4456.2 samples/s | 69.6 steps/s
[Step=29650 Epoch=144.6] | Loss=0.00742 | Reg=0.00422 | acc=0.9688 | L2-Norm=20.548 | L2-Norm(final)=10.051 | 4451.6 samples/s | 69.6 steps/s
[Step=29700 Epoch=144.8] | Loss=0.00723 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.544 | L2-Norm(final)=10.054 | 4447.6 samples/s | 69.5 steps/s
[Step=29750 Epoch=145.1] | Loss=0.00706 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.540 | L2-Norm(final)=10.057 | 2407.5 samples/s | 37.6 steps/s
[Step=29800 Epoch=145.3] | Loss=0.00690 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.535 | L2-Norm(final)=10.060 | 4353.3 samples/s | 68.0 steps/s
[Step=29850 Epoch=145.6] | Loss=0.00685 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.530 | L2-Norm(final)=10.063 | 4456.6 samples/s | 69.6 steps/s
[Step=29900 Epoch=145.8] | Loss=0.00673 | Reg=0.00421 | acc=0.9844 | L2-Norm=20.524 | L2-Norm(final)=10.066 | 4483.3 samples/s | 70.1 steps/s
[Step=29950 Epoch=146.0] | Loss=0.00661 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.518 | L2-Norm(final)=10.068 | 2404.8 samples/s | 37.6 steps/s
[Step=30000 Epoch=146.3] | Loss=0.00649 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.511 | L2-Norm(final)=10.071 | 4481.9 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step30000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=136.6] | Loss=0.00280 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.582 | L2-Norm(final)=9.922 | 5365.7 samples/s | 83.8 steps/s
[Step=28050 Epoch=136.9] | Loss=0.00389 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.578 | L2-Norm(final)=9.929 | 4367.7 samples/s | 68.2 steps/s
[Step=28100 Epoch=137.1] | Loss=0.00366 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.572 | L2-Norm(final)=9.939 | 5020.2 samples/s | 78.4 steps/s
[Step=28150 Epoch=137.4] | Loss=0.00332 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.567 | L2-Norm(final)=9.949 | 5011.9 samples/s | 78.3 steps/s
[Step=28200 Epoch=137.6] | Loss=0.00346 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.561 | L2-Norm(final)=9.959 | 7637.9 samples/s | 119.3 steps/s
[Step=28250 Epoch=137.8] | Loss=0.00330 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.552 | L2-Norm(final)=9.967 | 2162.8 samples/s | 33.8 steps/s
[Step=28300 Epoch=138.1] | Loss=0.00317 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.544 | L2-Norm(final)=9.976 | 5046.8 samples/s | 78.9 steps/s
[Step=28350 Epoch=138.3] | Loss=0.00320 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.535 | L2-Norm(final)=9.984 | 4871.6 samples/s | 76.1 steps/s
[Step=28400 Epoch=138.6] | Loss=0.00307 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.528 | L2-Norm(final)=9.992 | 7104.7 samples/s | 111.0 steps/s
[Step=28450 Epoch=138.8] | Loss=0.00307 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.520 | L2-Norm(final)=10.001 | 2218.8 samples/s | 34.7 steps/s
[Step=28500 Epoch=139.1] | Loss=0.00299 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.511 | L2-Norm(final)=10.009 | 4955.1 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=139.1] | Loss=0.00647 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.427 | L2-Norm(final)=10.094 | 5770.0 samples/s | 90.2 steps/s
[Step=28550 Epoch=139.3] | Loss=0.00387 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.424 | L2-Norm(final)=10.100 | 3893.5 samples/s | 60.8 steps/s
[Step=28600 Epoch=139.6] | Loss=0.00522 | Reg=0.00417 | acc=1.0000 | L2-Norm=20.424 | L2-Norm(final)=10.105 | 4373.1 samples/s | 68.3 steps/s
[Step=28650 Epoch=139.8] | Loss=0.00634 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.429 | L2-Norm(final)=10.110 | 4489.6 samples/s | 70.1 steps/s
[Step=28700 Epoch=140.0] | Loss=0.00838 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.443 | L2-Norm(final)=10.117 | 6419.4 samples/s | 100.3 steps/s
[Step=28750 Epoch=140.3] | Loss=0.00906 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.459 | L2-Norm(final)=10.122 | 2079.3 samples/s | 32.5 steps/s
[Step=28800 Epoch=140.5] | Loss=0.01088 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.480 | L2-Norm(final)=10.127 | 4375.7 samples/s | 68.4 steps/s
[Step=28850 Epoch=140.8] | Loss=0.01179 | Reg=0.00421 | acc=0.9531 | L2-Norm=20.508 | L2-Norm(final)=10.130 | 4425.2 samples/s | 69.1 steps/s
[Step=28900 Epoch=141.0] | Loss=0.01226 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.534 | L2-Norm(final)=10.133 | 5944.7 samples/s | 92.9 steps/s
[Step=28950 Epoch=141.3] | Loss=0.01225 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.556 | L2-Norm(final)=10.137 | 2112.9 samples/s | 33.0 steps/s
[Step=29000 Epoch=141.5] | Loss=0.01175 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.577 | L2-Norm(final)=10.141 | 4395.3 samples/s | 68.7 steps/s
[Step=29050 Epoch=141.8] | Loss=0.01130 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.594 | L2-Norm(final)=10.146 | 4503.5 samples/s | 70.4 steps/s
[Step=29100 Epoch=142.0] | Loss=0.01109 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.608 | L2-Norm(final)=10.151 | 5448.6 samples/s | 85.1 steps/s
[Step=29150 Epoch=142.2] | Loss=0.01061 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.620 | L2-Norm(final)=10.155 | 2172.9 samples/s | 34.0 steps/s
[Step=29200 Epoch=142.5] | Loss=0.01016 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.630 | L2-Norm(final)=10.160 | 4361.4 samples/s | 68.1 steps/s
[Step=29250 Epoch=142.7] | Loss=0.00976 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.637 | L2-Norm(final)=10.165 | 4430.1 samples/s | 69.2 steps/s
[Step=29300 Epoch=143.0] | Loss=0.00949 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.643 | L2-Norm(final)=10.169 | 5154.3 samples/s | 80.5 steps/s
[Step=29350 Epoch=143.2] | Loss=0.00919 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.647 | L2-Norm(final)=10.173 | 2231.6 samples/s | 34.9 steps/s
[Step=29400 Epoch=143.5] | Loss=0.00898 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.650 | L2-Norm(final)=10.176 | 4448.9 samples/s | 69.5 steps/s
[Step=29450 Epoch=143.7] | Loss=0.00869 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.651 | L2-Norm(final)=10.180 | 4464.4 samples/s | 69.8 steps/s
[Step=29500 Epoch=143.9] | Loss=0.00843 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.651 | L2-Norm(final)=10.183 | 4845.8 samples/s | 75.7 steps/s
[Step=29550 Epoch=144.2] | Loss=0.00821 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.651 | L2-Norm(final)=10.186 | 2335.8 samples/s | 36.5 steps/s
[Step=29600 Epoch=144.4] | Loss=0.00806 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.649 | L2-Norm(final)=10.189 | 4521.8 samples/s | 70.7 steps/s
[Step=29650 Epoch=144.7] | Loss=0.00786 | Reg=0.00426 | acc=0.9844 | L2-Norm=20.647 | L2-Norm(final)=10.192 | 4439.7 samples/s | 69.4 steps/s
[Step=29700 Epoch=144.9] | Loss=0.00764 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.645 | L2-Norm(final)=10.195 | 4580.7 samples/s | 71.6 steps/s
[Step=29750 Epoch=145.2] | Loss=0.00747 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.641 | L2-Norm(final)=10.197 | 2429.2 samples/s | 38.0 steps/s
[Step=29800 Epoch=145.4] | Loss=0.00732 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.638 | L2-Norm(final)=10.200 | 4467.7 samples/s | 69.8 steps/s
[Step=29850 Epoch=145.7] | Loss=0.00717 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.634 | L2-Norm(final)=10.203 | 4451.2 samples/s | 69.5 steps/s
[Step=29900 Epoch=145.9] | Loss=0.00701 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.630 | L2-Norm(final)=10.205 | 4306.2 samples/s | 67.3 steps/s
[Step=29950 Epoch=146.1] | Loss=0.00688 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.626 | L2-Norm(final)=10.208 | 2257.1 samples/s | 35.3 steps/s
[Step=30000 Epoch=146.4] | Loss=0.00678 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.621 | L2-Norm(final)=10.211 | 4299.5 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step30000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=136.4] | Loss=0.00142 | Reg=0.00429 | acc=1.0000 | L2-Norm=20.707 | L2-Norm(final)=10.340 | 5415.0 samples/s | 84.6 steps/s
[Step=28050 Epoch=136.7] | Loss=0.00474 | Reg=0.00429 | acc=0.9688 | L2-Norm=20.702 | L2-Norm(final)=10.351 | 4056.1 samples/s | 63.4 steps/s
[Step=28100 Epoch=136.9] | Loss=0.00461 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.699 | L2-Norm(final)=10.361 | 4785.5 samples/s | 74.8 steps/s
[Step=28150 Epoch=137.2] | Loss=0.00430 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.698 | L2-Norm(final)=10.371 | 4807.7 samples/s | 75.1 steps/s
[Step=28200 Epoch=137.4] | Loss=0.00444 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.695 | L2-Norm(final)=10.379 | 7529.9 samples/s | 117.7 steps/s
[Step=28250 Epoch=137.6] | Loss=0.00416 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.690 | L2-Norm(final)=10.388 | 2052.1 samples/s | 32.1 steps/s
[Step=28300 Epoch=137.9] | Loss=0.00408 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.683 | L2-Norm(final)=10.397 | 4934.8 samples/s | 77.1 steps/s
[Step=28350 Epoch=138.1] | Loss=0.00413 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.676 | L2-Norm(final)=10.405 | 4995.6 samples/s | 78.1 steps/s
[Step=28400 Epoch=138.4] | Loss=0.00397 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.670 | L2-Norm(final)=10.413 | 7001.6 samples/s | 109.4 steps/s
[Step=28450 Epoch=138.6] | Loss=0.00386 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.663 | L2-Norm(final)=10.422 | 2281.1 samples/s | 35.6 steps/s
[Step=28500 Epoch=138.9] | Loss=0.00376 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.656 | L2-Norm(final)=10.430 | 4882.4 samples/s | 76.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=138.9] | Loss=0.00027 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.579 | L2-Norm(final)=10.514 | 5751.7 samples/s | 89.9 steps/s
[Step=28550 Epoch=139.1] | Loss=0.00566 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.576 | L2-Norm(final)=10.524 | 3830.2 samples/s | 59.8 steps/s
[Step=28600 Epoch=139.4] | Loss=0.00913 | Reg=0.00424 | acc=0.9531 | L2-Norm=20.582 | L2-Norm(final)=10.525 | 4513.1 samples/s | 70.5 steps/s
[Step=28650 Epoch=139.6] | Loss=0.01202 | Reg=0.00424 | acc=0.9531 | L2-Norm=20.600 | L2-Norm(final)=10.525 | 4508.0 samples/s | 70.4 steps/s
[Step=28700 Epoch=139.8] | Loss=0.01296 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.626 | L2-Norm(final)=10.526 | 6543.6 samples/s | 102.2 steps/s
[Step=28750 Epoch=140.1] | Loss=0.01386 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.651 | L2-Norm(final)=10.529 | 2065.3 samples/s | 32.3 steps/s
[Step=28800 Epoch=140.3] | Loss=0.01388 | Reg=0.00427 | acc=0.9844 | L2-Norm=20.675 | L2-Norm(final)=10.532 | 4513.6 samples/s | 70.5 steps/s
[Step=28850 Epoch=140.6] | Loss=0.01467 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.699 | L2-Norm(final)=10.534 | 4444.4 samples/s | 69.4 steps/s
[Step=28900 Epoch=140.8] | Loss=0.01399 | Reg=0.00429 | acc=1.0000 | L2-Norm=20.720 | L2-Norm(final)=10.538 | 5944.2 samples/s | 92.9 steps/s
[Step=28950 Epoch=141.1] | Loss=0.01308 | Reg=0.00430 | acc=0.9844 | L2-Norm=20.738 | L2-Norm(final)=10.543 | 2170.1 samples/s | 33.9 steps/s
[Step=29000 Epoch=141.3] | Loss=0.01268 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.751 | L2-Norm(final)=10.547 | 4471.6 samples/s | 69.9 steps/s
[Step=29050 Epoch=141.5] | Loss=0.01221 | Reg=0.00431 | acc=0.9688 | L2-Norm=20.763 | L2-Norm(final)=10.552 | 4486.3 samples/s | 70.1 steps/s
[Step=29100 Epoch=141.8] | Loss=0.01207 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.773 | L2-Norm(final)=10.556 | 5387.0 samples/s | 84.2 steps/s
[Step=29150 Epoch=142.0] | Loss=0.01166 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.783 | L2-Norm(final)=10.560 | 2206.1 samples/s | 34.5 steps/s
[Step=29200 Epoch=142.3] | Loss=0.01124 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.790 | L2-Norm(final)=10.563 | 4546.5 samples/s | 71.0 steps/s
[Step=29250 Epoch=142.5] | Loss=0.01091 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.797 | L2-Norm(final)=10.567 | 4436.8 samples/s | 69.3 steps/s
[Step=29300 Epoch=142.8] | Loss=0.01063 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.802 | L2-Norm(final)=10.571 | 5000.8 samples/s | 78.1 steps/s
[Step=29350 Epoch=143.0] | Loss=0.01019 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.805 | L2-Norm(final)=10.575 | 2340.8 samples/s | 36.6 steps/s
[Step=29400 Epoch=143.3] | Loss=0.00982 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.807 | L2-Norm(final)=10.578 | 4538.7 samples/s | 70.9 steps/s
[Step=29450 Epoch=143.5] | Loss=0.00967 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.809 | L2-Norm(final)=10.582 | 4306.7 samples/s | 67.3 steps/s
[Step=29500 Epoch=143.7] | Loss=0.00938 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.809 | L2-Norm(final)=10.585 | 4615.3 samples/s | 72.1 steps/s
[Step=29550 Epoch=144.0] | Loss=0.00920 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.809 | L2-Norm(final)=10.588 | 2459.1 samples/s | 38.4 steps/s
[Step=29600 Epoch=144.2] | Loss=0.00890 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.808 | L2-Norm(final)=10.591 | 4472.6 samples/s | 69.9 steps/s
[Step=29650 Epoch=144.5] | Loss=0.00874 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.806 | L2-Norm(final)=10.593 | 4516.5 samples/s | 70.6 steps/s
[Step=29700 Epoch=144.7] | Loss=0.00854 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.803 | L2-Norm(final)=10.596 | 4481.3 samples/s | 70.0 steps/s
[Step=29750 Epoch=145.0] | Loss=0.00837 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.800 | L2-Norm(final)=10.599 | 2440.4 samples/s | 38.1 steps/s
[Step=29800 Epoch=145.2] | Loss=0.00814 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.797 | L2-Norm(final)=10.601 | 4347.0 samples/s | 67.9 steps/s
[Step=29850 Epoch=145.4] | Loss=0.00808 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.794 | L2-Norm(final)=10.604 | 4512.4 samples/s | 70.5 steps/s
[Step=29900 Epoch=145.7] | Loss=0.00794 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.790 | L2-Norm(final)=10.606 | 4424.8 samples/s | 69.1 steps/s
[Step=29950 Epoch=145.9] | Loss=0.00781 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.785 | L2-Norm(final)=10.608 | 2508.8 samples/s | 39.2 steps/s
[Step=30000 Epoch=146.2] | Loss=0.00762 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.780 | L2-Norm(final)=10.611 | 4523.7 samples/s | 70.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step30000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=136.5] | Loss=0.00041 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.647 | L2-Norm(final)=10.130 | 5246.1 samples/s | 82.0 steps/s
[Step=28050 Epoch=136.8] | Loss=0.00371 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.643 | L2-Norm(final)=10.139 | 4600.3 samples/s | 71.9 steps/s
[Step=28100 Epoch=137.0] | Loss=0.00356 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.638 | L2-Norm(final)=10.149 | 4944.6 samples/s | 77.3 steps/s
[Step=28150 Epoch=137.3] | Loss=0.00356 | Reg=0.00426 | acc=1.0000 | L2-Norm=20.631 | L2-Norm(final)=10.159 | 5017.6 samples/s | 78.4 steps/s
[Step=28200 Epoch=137.5] | Loss=0.00366 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.624 | L2-Norm(final)=10.168 | 7753.3 samples/s | 121.1 steps/s
[Step=28250 Epoch=137.8] | Loss=0.00344 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.617 | L2-Norm(final)=10.177 | 2222.9 samples/s | 34.7 steps/s
[Step=28300 Epoch=138.0] | Loss=0.00327 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.610 | L2-Norm(final)=10.187 | 5039.6 samples/s | 78.7 steps/s
[Step=28350 Epoch=138.3] | Loss=0.00318 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.602 | L2-Norm(final)=10.197 | 5108.9 samples/s | 79.8 steps/s
[Step=28400 Epoch=138.5] | Loss=0.00316 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.594 | L2-Norm(final)=10.206 | 6864.7 samples/s | 107.3 steps/s
[Step=28450 Epoch=138.7] | Loss=0.00319 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.585 | L2-Norm(final)=10.215 | 2305.4 samples/s | 36.0 steps/s
[Step=28500 Epoch=139.0] | Loss=0.00306 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.576 | L2-Norm(final)=10.224 | 4924.4 samples/s | 76.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=139.0] | Loss=0.00079 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.487 | L2-Norm(final)=10.314 | 5634.1 samples/s | 88.0 steps/s
[Step=28550 Epoch=139.2] | Loss=0.00470 | Reg=0.00419 | acc=0.9531 | L2-Norm=20.480 | L2-Norm(final)=10.324 | 4194.8 samples/s | 65.5 steps/s
[Step=28600 Epoch=139.5] | Loss=0.00789 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.483 | L2-Norm(final)=10.326 | 4466.3 samples/s | 69.8 steps/s
[Step=28650 Epoch=139.7] | Loss=0.01059 | Reg=0.00421 | acc=0.9844 | L2-Norm=20.506 | L2-Norm(final)=10.330 | 4487.1 samples/s | 70.1 steps/s
[Step=28700 Epoch=140.0] | Loss=0.01148 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.536 | L2-Norm(final)=10.339 | 6509.2 samples/s | 101.7 steps/s
[Step=28750 Epoch=140.2] | Loss=0.01218 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.567 | L2-Norm(final)=10.346 | 2132.2 samples/s | 33.3 steps/s
[Step=28800 Epoch=140.4] | Loss=0.01249 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.597 | L2-Norm(final)=10.353 | 4340.9 samples/s | 67.8 steps/s
[Step=28850 Epoch=140.7] | Loss=0.01247 | Reg=0.00425 | acc=1.0000 | L2-Norm=20.623 | L2-Norm(final)=10.358 | 4431.6 samples/s | 69.2 steps/s
[Step=28900 Epoch=140.9] | Loss=0.01238 | Reg=0.00426 | acc=0.9844 | L2-Norm=20.645 | L2-Norm(final)=10.363 | 5894.7 samples/s | 92.1 steps/s
[Step=28950 Epoch=141.2] | Loss=0.01197 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.665 | L2-Norm(final)=10.367 | 2169.4 samples/s | 33.9 steps/s
[Step=29000 Epoch=141.4] | Loss=0.01145 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.680 | L2-Norm(final)=10.372 | 4503.3 samples/s | 70.4 steps/s
[Step=29050 Epoch=141.7] | Loss=0.01108 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.693 | L2-Norm(final)=10.376 | 4437.7 samples/s | 69.3 steps/s
[Step=29100 Epoch=141.9] | Loss=0.01075 | Reg=0.00429 | acc=1.0000 | L2-Norm=20.704 | L2-Norm(final)=10.380 | 5415.2 samples/s | 84.6 steps/s
[Step=29150 Epoch=142.2] | Loss=0.01047 | Reg=0.00429 | acc=1.0000 | L2-Norm=20.714 | L2-Norm(final)=10.385 | 2252.2 samples/s | 35.2 steps/s
[Step=29200 Epoch=142.4] | Loss=0.01017 | Reg=0.00429 | acc=0.9688 | L2-Norm=20.722 | L2-Norm(final)=10.389 | 4433.0 samples/s | 69.3 steps/s
[Step=29250 Epoch=142.6] | Loss=0.00978 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.728 | L2-Norm(final)=10.393 | 4429.8 samples/s | 69.2 steps/s
[Step=29300 Epoch=142.9] | Loss=0.00942 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.732 | L2-Norm(final)=10.396 | 5023.6 samples/s | 78.5 steps/s
[Step=29350 Epoch=143.1] | Loss=0.00913 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.735 | L2-Norm(final)=10.399 | 2329.2 samples/s | 36.4 steps/s
[Step=29400 Epoch=143.4] | Loss=0.00881 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.738 | L2-Norm(final)=10.403 | 4500.2 samples/s | 70.3 steps/s
[Step=29450 Epoch=143.6] | Loss=0.00860 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.739 | L2-Norm(final)=10.406 | 4469.0 samples/s | 69.8 steps/s
[Step=29500 Epoch=143.9] | Loss=0.00832 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.739 | L2-Norm(final)=10.408 | 4531.6 samples/s | 70.8 steps/s
[Step=29550 Epoch=144.1] | Loss=0.00815 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.738 | L2-Norm(final)=10.411 | 2409.5 samples/s | 37.6 steps/s
[Step=29600 Epoch=144.3] | Loss=0.00789 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.737 | L2-Norm(final)=10.414 | 4395.0 samples/s | 68.7 steps/s
[Step=29650 Epoch=144.6] | Loss=0.00778 | Reg=0.00430 | acc=0.9844 | L2-Norm=20.736 | L2-Norm(final)=10.417 | 4535.5 samples/s | 70.9 steps/s
[Step=29700 Epoch=144.8] | Loss=0.00772 | Reg=0.00430 | acc=0.9844 | L2-Norm=20.735 | L2-Norm(final)=10.420 | 4433.2 samples/s | 69.3 steps/s
[Step=29750 Epoch=145.1] | Loss=0.00766 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.734 | L2-Norm(final)=10.422 | 2473.2 samples/s | 38.6 steps/s
[Step=29800 Epoch=145.3] | Loss=0.00748 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.733 | L2-Norm(final)=10.425 | 4487.4 samples/s | 70.1 steps/s
[Step=29850 Epoch=145.6] | Loss=0.00731 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.731 | L2-Norm(final)=10.427 | 4482.8 samples/s | 70.0 steps/s
[Step=29900 Epoch=145.8] | Loss=0.00720 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.729 | L2-Norm(final)=10.430 | 4373.5 samples/s | 68.3 steps/s
[Step=29950 Epoch=146.1] | Loss=0.00712 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.727 | L2-Norm(final)=10.433 | 2475.3 samples/s | 38.7 steps/s
[Step=30000 Epoch=146.3] | Loss=0.00701 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.724 | L2-Norm(final)=10.435 | 4461.7 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step30000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=137.3] | Loss=0.00151 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.402 | L2-Norm(final)=10.157 | 5608.6 samples/s | 87.6 steps/s
[Step=28050 Epoch=137.6] | Loss=0.00465 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.401 | L2-Norm(final)=10.163 | 4205.8 samples/s | 65.7 steps/s
[Step=28100 Epoch=137.8] | Loss=0.00411 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.397 | L2-Norm(final)=10.173 | 5040.9 samples/s | 78.8 steps/s
[Step=28150 Epoch=138.0] | Loss=0.00416 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.391 | L2-Norm(final)=10.183 | 5049.6 samples/s | 78.9 steps/s
[Step=28200 Epoch=138.3] | Loss=0.00383 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.384 | L2-Norm(final)=10.193 | 8069.7 samples/s | 126.1 steps/s
[Step=28250 Epoch=138.5] | Loss=0.00349 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.377 | L2-Norm(final)=10.203 | 2151.7 samples/s | 33.6 steps/s
[Step=28300 Epoch=138.8] | Loss=0.00326 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.370 | L2-Norm(final)=10.213 | 5014.2 samples/s | 78.3 steps/s
[Step=28350 Epoch=139.0] | Loss=0.00342 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.362 | L2-Norm(final)=10.223 | 5056.6 samples/s | 79.0 steps/s
[Step=28400 Epoch=139.3] | Loss=0.00333 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.355 | L2-Norm(final)=10.232 | 7521.8 samples/s | 117.5 steps/s
[Step=28450 Epoch=139.5] | Loss=0.00331 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.347 | L2-Norm(final)=10.241 | 2254.1 samples/s | 35.2 steps/s
[Step=28500 Epoch=139.8] | Loss=0.00319 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.338 | L2-Norm(final)=10.250 | 5104.6 samples/s | 79.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=139.8] | Loss=0.01504 | Reg=0.00410 | acc=0.9844 | L2-Norm=20.259 | L2-Norm(final)=10.340 | 5565.4 samples/s | 87.0 steps/s
[Step=28550 Epoch=140.0] | Loss=0.00396 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.254 | L2-Norm(final)=10.347 | 3827.3 samples/s | 59.8 steps/s
[Step=28600 Epoch=140.2] | Loss=0.00625 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.256 | L2-Norm(final)=10.350 | 4532.7 samples/s | 70.8 steps/s
[Step=28650 Epoch=140.5] | Loss=0.00925 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.270 | L2-Norm(final)=10.353 | 4436.8 samples/s | 69.3 steps/s
[Step=28700 Epoch=140.7] | Loss=0.01002 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.289 | L2-Norm(final)=10.357 | 6648.1 samples/s | 103.9 steps/s
[Step=28750 Epoch=141.0] | Loss=0.01007 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.312 | L2-Norm(final)=10.364 | 2087.6 samples/s | 32.6 steps/s
[Step=28800 Epoch=141.2] | Loss=0.01068 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.336 | L2-Norm(final)=10.370 | 4442.7 samples/s | 69.4 steps/s
[Step=28850 Epoch=141.5] | Loss=0.01072 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.360 | L2-Norm(final)=10.376 | 4580.7 samples/s | 71.6 steps/s
[Step=28900 Epoch=141.7] | Loss=0.01078 | Reg=0.00415 | acc=0.9844 | L2-Norm=20.382 | L2-Norm(final)=10.382 | 6083.2 samples/s | 95.1 steps/s
[Step=28950 Epoch=142.0] | Loss=0.01026 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.401 | L2-Norm(final)=10.388 | 2071.8 samples/s | 32.4 steps/s
[Step=29000 Epoch=142.2] | Loss=0.00994 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.417 | L2-Norm(final)=10.394 | 4475.4 samples/s | 69.9 steps/s
[Step=29050 Epoch=142.5] | Loss=0.00991 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.431 | L2-Norm(final)=10.400 | 4538.4 samples/s | 70.9 steps/s
[Step=29100 Epoch=142.7] | Loss=0.01017 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.442 | L2-Norm(final)=10.404 | 5743.9 samples/s | 89.7 steps/s
[Step=29150 Epoch=142.9] | Loss=0.00984 | Reg=0.00418 | acc=1.0000 | L2-Norm=20.453 | L2-Norm(final)=10.408 | 2189.7 samples/s | 34.2 steps/s
[Step=29200 Epoch=143.2] | Loss=0.00963 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.463 | L2-Norm(final)=10.412 | 4484.3 samples/s | 70.1 steps/s
[Step=29250 Epoch=143.4] | Loss=0.00941 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.471 | L2-Norm(final)=10.416 | 4385.8 samples/s | 68.5 steps/s
[Step=29300 Epoch=143.7] | Loss=0.00917 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.478 | L2-Norm(final)=10.420 | 5457.5 samples/s | 85.3 steps/s
[Step=29350 Epoch=143.9] | Loss=0.00895 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.484 | L2-Norm(final)=10.424 | 2245.1 samples/s | 35.1 steps/s
[Step=29400 Epoch=144.2] | Loss=0.00862 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.488 | L2-Norm(final)=10.427 | 4416.5 samples/s | 69.0 steps/s
[Step=29450 Epoch=144.4] | Loss=0.00848 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.491 | L2-Norm(final)=10.431 | 4498.1 samples/s | 70.3 steps/s
[Step=29500 Epoch=144.7] | Loss=0.00826 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.493 | L2-Norm(final)=10.434 | 5140.1 samples/s | 80.3 steps/s
[Step=29550 Epoch=144.9] | Loss=0.00796 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.495 | L2-Norm(final)=10.437 | 2295.7 samples/s | 35.9 steps/s
[Step=29600 Epoch=145.2] | Loss=0.00772 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.495 | L2-Norm(final)=10.441 | 4401.7 samples/s | 68.8 steps/s
[Step=29650 Epoch=145.4] | Loss=0.00751 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.495 | L2-Norm(final)=10.444 | 4370.9 samples/s | 68.3 steps/s
[Step=29700 Epoch=145.6] | Loss=0.00735 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.493 | L2-Norm(final)=10.447 | 4922.7 samples/s | 76.9 steps/s
[Step=29750 Epoch=145.9] | Loss=0.00716 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.491 | L2-Norm(final)=10.450 | 2332.7 samples/s | 36.4 steps/s
[Step=29800 Epoch=146.1] | Loss=0.00698 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.489 | L2-Norm(final)=10.453 | 4512.1 samples/s | 70.5 steps/s
[Step=29850 Epoch=146.4] | Loss=0.00686 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.486 | L2-Norm(final)=10.456 | 4415.2 samples/s | 69.0 steps/s
[Step=29900 Epoch=146.6] | Loss=0.00673 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.482 | L2-Norm(final)=10.458 | 4671.2 samples/s | 73.0 steps/s
[Step=29950 Epoch=146.9] | Loss=0.00658 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.478 | L2-Norm(final)=10.461 | 2353.5 samples/s | 36.8 steps/s
[Step=30000 Epoch=147.1] | Loss=0.00644 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.473 | L2-Norm(final)=10.463 | 4477.2 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step30000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=265.3] | Loss=0.00016 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.722 | L2-Norm(final)=5.807 | 5526.0 samples/s | 86.3 steps/s
[Step=28050 Epoch=265.8] | Loss=0.00013 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.730 | L2-Norm(final)=5.824 | 4018.9 samples/s | 62.8 steps/s
[Step=28100 Epoch=266.3] | Loss=0.00011 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.740 | L2-Norm(final)=5.842 | 7466.5 samples/s | 116.7 steps/s
[Step=28150 Epoch=266.7] | Loss=0.00009 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.747 | L2-Norm(final)=5.857 | 2119.1 samples/s | 33.1 steps/s
[Step=28200 Epoch=267.2] | Loss=0.00007 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.751 | L2-Norm(final)=5.868 | 6648.5 samples/s | 103.9 steps/s
[Step=28250 Epoch=267.7] | Loss=0.00006 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.753 | L2-Norm(final)=5.878 | 2195.0 samples/s | 34.3 steps/s
[Step=28300 Epoch=268.2] | Loss=0.00006 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.753 | L2-Norm(final)=5.888 | 5845.1 samples/s | 91.3 steps/s
[Step=28350 Epoch=268.6] | Loss=0.00005 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.753 | L2-Norm(final)=5.896 | 2331.0 samples/s | 36.4 steps/s
[Step=28400 Epoch=269.1] | Loss=0.00005 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.752 | L2-Norm(final)=5.905 | 5266.1 samples/s | 82.3 steps/s
[Step=28450 Epoch=269.6] | Loss=0.00005 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.751 | L2-Norm(final)=5.913 | 2395.8 samples/s | 37.4 steps/s
[Step=28500 Epoch=270.1] | Loss=0.00004 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.750 | L2-Norm(final)=5.921 | 4929.5 samples/s | 77.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=270.1] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.734 | L2-Norm(final)=6.000 | 5196.3 samples/s | 81.2 steps/s
[Step=28550 Epoch=270.5] | Loss=0.00002 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.718 | L2-Norm(final)=6.006 | 3751.8 samples/s | 58.6 steps/s
[Step=28600 Epoch=271.0] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.697 | L2-Norm(final)=6.012 | 6333.0 samples/s | 99.0 steps/s
[Step=28650 Epoch=271.5] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=6.016 | 2013.8 samples/s | 31.5 steps/s
[Step=28700 Epoch=272.0] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=6.019 | 5712.5 samples/s | 89.3 steps/s
[Step=28750 Epoch=272.4] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.623 | L2-Norm(final)=6.022 | 2101.6 samples/s | 32.8 steps/s
[Step=28800 Epoch=272.9] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.597 | L2-Norm(final)=6.023 | 5179.4 samples/s | 80.9 steps/s
[Step=28850 Epoch=273.4] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.570 | L2-Norm(final)=6.025 | 2154.7 samples/s | 33.7 steps/s
[Step=28900 Epoch=273.9] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.544 | L2-Norm(final)=6.027 | 4715.7 samples/s | 73.7 steps/s
[Step=28950 Epoch=274.3] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.518 | L2-Norm(final)=6.028 | 1707.1 samples/s | 26.7 steps/s
[Step=29000 Epoch=274.8] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.491 | L2-Norm(final)=6.029 | 4341.1 samples/s | 67.8 steps/s
[Step=29050 Epoch=275.3] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=6.031 | 2344.0 samples/s | 36.6 steps/s
[Step=29100 Epoch=275.7] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.438 | L2-Norm(final)=6.032 | 4147.7 samples/s | 64.8 steps/s
[Step=29150 Epoch=276.2] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.412 | L2-Norm(final)=6.033 | 2370.4 samples/s | 37.0 steps/s
[Step=29200 Epoch=276.7] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.385 | L2-Norm(final)=6.034 | 4298.9 samples/s | 67.2 steps/s
[Step=29250 Epoch=277.2] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.358 | L2-Norm(final)=6.036 | 2396.3 samples/s | 37.4 steps/s
[Step=29300 Epoch=277.6] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.332 | L2-Norm(final)=6.037 | 4359.1 samples/s | 68.1 steps/s
[Step=29350 Epoch=278.1] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.305 | L2-Norm(final)=6.038 | 2432.0 samples/s | 38.0 steps/s
[Step=29400 Epoch=278.6] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.278 | L2-Norm(final)=6.040 | 4019.3 samples/s | 62.8 steps/s
[Step=29450 Epoch=279.1] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=6.041 | 6460.0 samples/s | 100.9 steps/s
[Step=29500 Epoch=279.5] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.225 | L2-Norm(final)=6.042 | 1998.1 samples/s | 31.2 steps/s
[Step=29550 Epoch=280.0] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.198 | L2-Norm(final)=6.044 | 5843.1 samples/s | 91.3 steps/s
[Step=29600 Epoch=280.5] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.171 | L2-Norm(final)=6.045 | 2056.7 samples/s | 32.1 steps/s
[Step=29650 Epoch=281.0] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=6.046 | 5325.4 samples/s | 83.2 steps/s
[Step=29700 Epoch=281.4] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.117 | L2-Norm(final)=6.048 | 2158.4 samples/s | 33.7 steps/s
[Step=29750 Epoch=281.9] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.090 | L2-Norm(final)=6.049 | 4749.5 samples/s | 74.2 steps/s
[Step=29800 Epoch=282.4] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.063 | L2-Norm(final)=6.051 | 2246.5 samples/s | 35.1 steps/s
[Step=29850 Epoch=282.9] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.036 | L2-Norm(final)=6.053 | 4381.0 samples/s | 68.5 steps/s
[Step=29900 Epoch=283.3] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.009 | L2-Norm(final)=6.054 | 2330.1 samples/s | 36.4 steps/s
[Step=29950 Epoch=283.8] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.981 | L2-Norm(final)=6.056 | 4342.1 samples/s | 67.8 steps/s
[Step=30000 Epoch=284.3] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.954 | L2-Norm(final)=6.058 | 2300.7 samples/s | 35.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step30000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=266.4] | Loss=0.00194 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.525 | L2-Norm(final)=6.490 | 5092.0 samples/s | 79.6 steps/s
[Step=28050 Epoch=266.8] | Loss=0.00116 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.585 | L2-Norm(final)=6.494 | 4234.2 samples/s | 66.2 steps/s
[Step=28100 Epoch=267.3] | Loss=0.00071 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.616 | L2-Norm(final)=6.508 | 7496.3 samples/s | 117.1 steps/s
[Step=28150 Epoch=267.8] | Loss=0.00049 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.634 | L2-Norm(final)=6.521 | 2136.8 samples/s | 33.4 steps/s
[Step=28200 Epoch=268.3] | Loss=0.00039 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.643 | L2-Norm(final)=6.530 | 6472.5 samples/s | 101.1 steps/s
[Step=28250 Epoch=268.7] | Loss=0.00033 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=6.539 | 2211.8 samples/s | 34.6 steps/s
[Step=28300 Epoch=269.2] | Loss=0.00028 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.653 | L2-Norm(final)=6.548 | 5956.1 samples/s | 93.1 steps/s
[Step=28350 Epoch=269.7] | Loss=0.00025 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.656 | L2-Norm(final)=6.555 | 2298.8 samples/s | 35.9 steps/s
[Step=28400 Epoch=270.2] | Loss=0.00022 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.658 | L2-Norm(final)=6.562 | 5411.9 samples/s | 84.6 steps/s
[Step=28450 Epoch=270.6] | Loss=0.00020 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.659 | L2-Norm(final)=6.568 | 2423.1 samples/s | 37.9 steps/s
[Step=28500 Epoch=271.1] | Loss=0.00018 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.660 | L2-Norm(final)=6.574 | 4889.7 samples/s | 76.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=271.1] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.669 | L2-Norm(final)=6.635 | 5276.9 samples/s | 82.5 steps/s
[Step=28550 Epoch=271.6] | Loss=0.00813 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.761 | L2-Norm(final)=6.630 | 3739.7 samples/s | 58.4 steps/s
[Step=28600 Epoch=272.1] | Loss=0.00846 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.917 | L2-Norm(final)=6.590 | 6257.7 samples/s | 97.8 steps/s
[Step=28650 Epoch=272.5] | Loss=0.00598 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.987 | L2-Norm(final)=6.569 | 2031.3 samples/s | 31.7 steps/s
[Step=28700 Epoch=273.0] | Loss=0.00464 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.025 | L2-Norm(final)=6.559 | 5651.0 samples/s | 88.3 steps/s
[Step=28750 Epoch=273.5] | Loss=0.00376 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.049 | L2-Norm(final)=6.555 | 2101.2 samples/s | 32.8 steps/s
[Step=28800 Epoch=274.0] | Loss=0.00313 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.064 | L2-Norm(final)=6.552 | 5129.7 samples/s | 80.2 steps/s
[Step=28850 Epoch=274.4] | Loss=0.00269 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.074 | L2-Norm(final)=6.550 | 2164.4 samples/s | 33.8 steps/s
[Step=28900 Epoch=274.9] | Loss=0.00235 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.080 | L2-Norm(final)=6.549 | 4751.2 samples/s | 74.2 steps/s
[Step=28950 Epoch=275.4] | Loss=0.00209 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.084 | L2-Norm(final)=6.549 | 2270.5 samples/s | 35.5 steps/s
[Step=29000 Epoch=275.9] | Loss=0.00189 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.087 | L2-Norm(final)=6.548 | 4397.9 samples/s | 68.7 steps/s
[Step=29050 Epoch=276.3] | Loss=0.00172 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.088 | L2-Norm(final)=6.548 | 2365.3 samples/s | 37.0 steps/s
[Step=29100 Epoch=276.8] | Loss=0.00157 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.089 | L2-Norm(final)=6.548 | 4270.7 samples/s | 66.7 steps/s
[Step=29150 Epoch=277.3] | Loss=0.00145 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.088 | L2-Norm(final)=6.548 | 2340.8 samples/s | 36.6 steps/s
[Step=29200 Epoch=277.8] | Loss=0.00135 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.087 | L2-Norm(final)=6.548 | 4269.4 samples/s | 66.7 steps/s
[Step=29250 Epoch=278.2] | Loss=0.00126 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.086 | L2-Norm(final)=6.549 | 2414.2 samples/s | 37.7 steps/s
[Step=29300 Epoch=278.7] | Loss=0.00118 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.085 | L2-Norm(final)=6.549 | 4262.4 samples/s | 66.6 steps/s
[Step=29350 Epoch=279.2] | Loss=0.00111 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.083 | L2-Norm(final)=6.549 | 2495.1 samples/s | 39.0 steps/s
[Step=29400 Epoch=279.7] | Loss=0.00105 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.080 | L2-Norm(final)=6.550 | 4007.3 samples/s | 62.6 steps/s
[Step=29450 Epoch=280.1] | Loss=0.00100 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.078 | L2-Norm(final)=6.550 | 6415.4 samples/s | 100.2 steps/s
[Step=29500 Epoch=280.6] | Loss=0.00095 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.075 | L2-Norm(final)=6.550 | 1989.2 samples/s | 31.1 steps/s
[Step=29550 Epoch=281.1] | Loss=0.00090 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.073 | L2-Norm(final)=6.551 | 5867.2 samples/s | 91.7 steps/s
[Step=29600 Epoch=281.6] | Loss=0.00086 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.070 | L2-Norm(final)=6.551 | 2068.4 samples/s | 32.3 steps/s
[Step=29650 Epoch=282.0] | Loss=0.00082 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.066 | L2-Norm(final)=6.552 | 5327.6 samples/s | 83.2 steps/s
[Step=29700 Epoch=282.5] | Loss=0.00079 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.063 | L2-Norm(final)=6.552 | 2150.3 samples/s | 33.6 steps/s
[Step=29750 Epoch=283.0] | Loss=0.00076 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.060 | L2-Norm(final)=6.553 | 4728.9 samples/s | 73.9 steps/s
[Step=29800 Epoch=283.5] | Loss=0.00073 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.056 | L2-Norm(final)=6.553 | 2253.5 samples/s | 35.2 steps/s
[Step=29850 Epoch=283.9] | Loss=0.00070 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.053 | L2-Norm(final)=6.554 | 4497.4 samples/s | 70.3 steps/s
[Step=29900 Epoch=284.4] | Loss=0.00068 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.049 | L2-Norm(final)=6.554 | 2335.6 samples/s | 36.5 steps/s
[Step=29950 Epoch=284.9] | Loss=0.00066 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.045 | L2-Norm(final)=6.555 | 4243.7 samples/s | 66.3 steps/s
[Step=30000 Epoch=285.4] | Loss=0.00063 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.041 | L2-Norm(final)=6.555 | 2358.7 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step30000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=267.4] | Loss=0.00012 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.582 | L2-Norm(final)=6.415 | 5127.5 samples/s | 80.1 steps/s
[Step=28050 Epoch=267.9] | Loss=0.00107 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.653 | L2-Norm(final)=6.434 | 4254.2 samples/s | 66.5 steps/s
[Step=28100 Epoch=268.3] | Loss=0.00082 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.721 | L2-Norm(final)=6.458 | 7382.5 samples/s | 115.4 steps/s
[Step=28150 Epoch=268.8] | Loss=0.00058 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.753 | L2-Norm(final)=6.474 | 2116.8 samples/s | 33.1 steps/s
[Step=28200 Epoch=269.3] | Loss=0.00045 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.769 | L2-Norm(final)=6.485 | 6824.3 samples/s | 106.6 steps/s
[Step=28250 Epoch=269.8] | Loss=0.00037 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.778 | L2-Norm(final)=6.494 | 2190.2 samples/s | 34.2 steps/s
[Step=28300 Epoch=270.2] | Loss=0.00032 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.784 | L2-Norm(final)=6.502 | 6086.4 samples/s | 95.1 steps/s
[Step=28350 Epoch=270.7] | Loss=0.00028 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.788 | L2-Norm(final)=6.508 | 2212.4 samples/s | 34.6 steps/s
[Step=28400 Epoch=271.2] | Loss=0.00025 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.791 | L2-Norm(final)=6.514 | 5707.4 samples/s | 89.2 steps/s
[Step=28450 Epoch=271.7] | Loss=0.00022 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.792 | L2-Norm(final)=6.520 | 2337.2 samples/s | 36.5 steps/s
[Step=28500 Epoch=272.2] | Loss=0.00020 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.793 | L2-Norm(final)=6.525 | 5244.6 samples/s | 81.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=272.2] | Loss=0.00003 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.800 | L2-Norm(final)=6.575 | 5680.0 samples/s | 88.8 steps/s
[Step=28550 Epoch=272.6] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.785 | L2-Norm(final)=6.579 | 3629.0 samples/s | 56.7 steps/s
[Step=28600 Epoch=273.1] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.763 | L2-Norm(final)=6.581 | 6236.8 samples/s | 97.5 steps/s
[Step=28650 Epoch=273.6] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.736 | L2-Norm(final)=6.582 | 1998.2 samples/s | 31.2 steps/s
[Step=28700 Epoch=274.1] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.709 | L2-Norm(final)=6.583 | 5826.1 samples/s | 91.0 steps/s
[Step=28750 Epoch=274.5] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.680 | L2-Norm(final)=6.583 | 2078.9 samples/s | 32.5 steps/s
[Step=28800 Epoch=275.0] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.652 | L2-Norm(final)=6.584 | 5361.9 samples/s | 83.8 steps/s
[Step=28850 Epoch=275.5] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.623 | L2-Norm(final)=6.584 | 2180.9 samples/s | 34.1 steps/s
[Step=28900 Epoch=276.0] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.594 | L2-Norm(final)=6.585 | 4689.7 samples/s | 73.3 steps/s
[Step=28950 Epoch=276.5] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.564 | L2-Norm(final)=6.585 | 2202.5 samples/s | 34.4 steps/s
[Step=29000 Epoch=276.9] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.535 | L2-Norm(final)=6.585 | 4643.0 samples/s | 72.5 steps/s
[Step=29050 Epoch=277.4] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.506 | L2-Norm(final)=6.585 | 2269.6 samples/s | 35.5 steps/s
[Step=29100 Epoch=277.9] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.476 | L2-Norm(final)=6.586 | 4329.5 samples/s | 67.6 steps/s
[Step=29150 Epoch=278.4] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.447 | L2-Norm(final)=6.586 | 2376.0 samples/s | 37.1 steps/s
[Step=29200 Epoch=278.8] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=6.586 | 4075.7 samples/s | 63.7 steps/s
[Step=29250 Epoch=279.3] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.387 | L2-Norm(final)=6.587 | 2393.9 samples/s | 37.4 steps/s
[Step=29300 Epoch=279.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.587 | 4187.3 samples/s | 65.4 steps/s
[Step=29350 Epoch=280.3] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.327 | L2-Norm(final)=6.587 | 2397.9 samples/s | 37.5 steps/s
[Step=29400 Epoch=280.8] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=6.587 | 4143.7 samples/s | 64.7 steps/s
[Step=29450 Epoch=281.2] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.266 | L2-Norm(final)=6.588 | 2373.7 samples/s | 37.1 steps/s
[Step=29500 Epoch=281.7] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=6.588 | 4232.9 samples/s | 66.1 steps/s
[Step=29550 Epoch=282.2] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.205 | L2-Norm(final)=6.588 | 7018.6 samples/s | 109.7 steps/s
[Step=29600 Epoch=282.7] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.174 | L2-Norm(final)=6.589 | 1954.4 samples/s | 30.5 steps/s
[Step=29650 Epoch=283.1] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=6.589 | 6367.3 samples/s | 99.5 steps/s
[Step=29700 Epoch=283.6] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=6.589 | 2005.5 samples/s | 31.3 steps/s
[Step=29750 Epoch=284.1] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.081 | L2-Norm(final)=6.590 | 5718.2 samples/s | 89.3 steps/s
[Step=29800 Epoch=284.6] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.050 | L2-Norm(final)=6.590 | 2075.7 samples/s | 32.4 steps/s
[Step=29850 Epoch=285.0] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.018 | L2-Norm(final)=6.590 | 5182.4 samples/s | 81.0 steps/s
[Step=29900 Epoch=285.5] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.987 | L2-Norm(final)=6.591 | 2139.8 samples/s | 33.4 steps/s
[Step=29950 Epoch=286.0] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.955 | L2-Norm(final)=6.591 | 4981.4 samples/s | 77.8 steps/s
[Step=30000 Epoch=286.5] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.923 | L2-Norm(final)=6.591 | 2200.5 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step30000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=263.8] | Loss=0.00009 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.775 | L2-Norm(final)=6.077 | 5224.6 samples/s | 81.6 steps/s
[Step=28050 Epoch=264.3] | Loss=0.00019 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.795 | L2-Norm(final)=6.097 | 4139.3 samples/s | 64.7 steps/s
[Step=28100 Epoch=264.8] | Loss=0.00014 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.806 | L2-Norm(final)=6.112 | 7305.2 samples/s | 114.1 steps/s
[Step=28150 Epoch=265.3] | Loss=0.00012 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.813 | L2-Norm(final)=6.125 | 2182.3 samples/s | 34.1 steps/s
[Step=28200 Epoch=265.7] | Loss=0.00010 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.816 | L2-Norm(final)=6.136 | 6342.1 samples/s | 99.1 steps/s
[Step=28250 Epoch=266.2] | Loss=0.00009 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.817 | L2-Norm(final)=6.146 | 2271.1 samples/s | 35.5 steps/s
[Step=28300 Epoch=266.7] | Loss=0.00008 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.818 | L2-Norm(final)=6.155 | 5567.0 samples/s | 87.0 steps/s
[Step=28350 Epoch=267.1] | Loss=0.00007 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.818 | L2-Norm(final)=6.163 | 2352.8 samples/s | 36.8 steps/s
[Step=28400 Epoch=267.6] | Loss=0.00006 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.817 | L2-Norm(final)=6.171 | 4984.7 samples/s | 77.9 steps/s
[Step=28450 Epoch=268.1] | Loss=0.00006 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.816 | L2-Norm(final)=6.179 | 2490.8 samples/s | 38.9 steps/s
[Step=28500 Epoch=268.6] | Loss=0.00006 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.815 | L2-Norm(final)=6.186 | 4812.6 samples/s | 75.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=268.6] | Loss=0.00001 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.803 | L2-Norm(final)=6.258 | 5335.5 samples/s | 83.4 steps/s
[Step=28550 Epoch=269.0] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.792 | L2-Norm(final)=6.264 | 3791.3 samples/s | 59.2 steps/s
[Step=28600 Epoch=269.5] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.777 | L2-Norm(final)=6.268 | 6124.7 samples/s | 95.7 steps/s
[Step=28650 Epoch=270.0] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.761 | L2-Norm(final)=6.273 | 1991.0 samples/s | 31.1 steps/s
[Step=28700 Epoch=270.4] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.743 | L2-Norm(final)=6.275 | 5522.3 samples/s | 86.3 steps/s
[Step=28750 Epoch=270.9] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.725 | L2-Norm(final)=6.278 | 2133.0 samples/s | 33.3 steps/s
[Step=28800 Epoch=271.4] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.706 | L2-Norm(final)=6.279 | 4924.5 samples/s | 76.9 steps/s
[Step=28850 Epoch=271.8] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.687 | L2-Norm(final)=6.281 | 2205.4 samples/s | 34.5 steps/s
[Step=28900 Epoch=272.3] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.668 | L2-Norm(final)=6.282 | 4455.9 samples/s | 69.6 steps/s
[Step=28950 Epoch=272.8] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=6.284 | 2272.4 samples/s | 35.5 steps/s
[Step=29000 Epoch=273.3] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.629 | L2-Norm(final)=6.285 | 4265.9 samples/s | 66.7 steps/s
[Step=29050 Epoch=273.7] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.610 | L2-Norm(final)=6.286 | 2397.8 samples/s | 37.5 steps/s
[Step=29100 Epoch=274.2] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.590 | L2-Norm(final)=6.288 | 4228.3 samples/s | 66.1 steps/s
[Step=29150 Epoch=274.7] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.571 | L2-Norm(final)=6.289 | 2398.1 samples/s | 37.5 steps/s
[Step=29200 Epoch=275.1] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=6.290 | 4130.6 samples/s | 64.5 steps/s
[Step=29250 Epoch=275.6] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.531 | L2-Norm(final)=6.291 | 2608.4 samples/s | 40.8 steps/s
[Step=29300 Epoch=276.1] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.511 | L2-Norm(final)=6.293 | 3750.2 samples/s | 58.6 steps/s
[Step=29350 Epoch=276.6] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.491 | L2-Norm(final)=6.294 | 6328.0 samples/s | 98.9 steps/s
[Step=29400 Epoch=277.0] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=6.295 | 2010.0 samples/s | 31.4 steps/s
[Step=29450 Epoch=277.5] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.451 | L2-Norm(final)=6.296 | 5597.8 samples/s | 87.5 steps/s
[Step=29500 Epoch=278.0] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.430 | L2-Norm(final)=6.298 | 2097.3 samples/s | 32.8 steps/s
[Step=29550 Epoch=278.4] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.410 | L2-Norm(final)=6.299 | 4991.3 samples/s | 78.0 steps/s
[Step=29600 Epoch=278.9] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.389 | L2-Norm(final)=6.300 | 2196.5 samples/s | 34.3 steps/s
[Step=29650 Epoch=279.4] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.368 | L2-Norm(final)=6.301 | 4556.0 samples/s | 71.2 steps/s
[Step=29700 Epoch=279.9] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.347 | L2-Norm(final)=6.303 | 2298.5 samples/s | 35.9 steps/s
[Step=29750 Epoch=280.3] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.326 | L2-Norm(final)=6.304 | 4274.8 samples/s | 66.8 steps/s
[Step=29800 Epoch=280.8] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.305 | L2-Norm(final)=6.305 | 2383.7 samples/s | 37.2 steps/s
[Step=29850 Epoch=281.3] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.284 | L2-Norm(final)=6.307 | 4217.9 samples/s | 65.9 steps/s
[Step=29900 Epoch=281.7] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=6.308 | 2372.6 samples/s | 37.1 steps/s
[Step=29950 Epoch=282.2] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.310 | 4278.6 samples/s | 66.9 steps/s
[Step=30000 Epoch=282.7] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=6.311 | 2472.0 samples/s | 38.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step30000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=266.9] | Loss=0.00036 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.609 | L2-Norm(final)=7.155 | 5171.1 samples/s | 80.8 steps/s
[Step=28050 Epoch=267.3] | Loss=0.00067 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.670 | L2-Norm(final)=7.197 | 4142.6 samples/s | 64.7 steps/s
[Step=28100 Epoch=267.8] | Loss=0.00056 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.723 | L2-Norm(final)=7.233 | 7485.5 samples/s | 117.0 steps/s
[Step=28150 Epoch=268.3] | Loss=0.00041 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.755 | L2-Norm(final)=7.257 | 2123.8 samples/s | 33.2 steps/s
[Step=28200 Epoch=268.8] | Loss=0.00034 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.772 | L2-Norm(final)=7.274 | 6724.9 samples/s | 105.1 steps/s
[Step=28250 Epoch=269.2] | Loss=0.00028 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.784 | L2-Norm(final)=7.289 | 2196.3 samples/s | 34.3 steps/s
[Step=28300 Epoch=269.7] | Loss=0.00024 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.792 | L2-Norm(final)=7.301 | 6051.8 samples/s | 94.6 steps/s
[Step=28350 Epoch=270.2] | Loss=0.00021 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.797 | L2-Norm(final)=7.311 | 2241.5 samples/s | 35.0 steps/s
[Step=28400 Epoch=270.7] | Loss=0.00019 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.801 | L2-Norm(final)=7.320 | 5652.9 samples/s | 88.3 steps/s
[Step=28450 Epoch=271.2] | Loss=0.00018 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.803 | L2-Norm(final)=7.329 | 2318.1 samples/s | 36.2 steps/s
[Step=28500 Epoch=271.6] | Loss=0.00016 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.805 | L2-Norm(final)=7.337 | 5251.2 samples/s | 82.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=271.6] | Loss=0.00003 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.817 | L2-Norm(final)=7.414 | 5055.2 samples/s | 79.0 steps/s
[Step=28550 Epoch=272.1] | Loss=0.00773 | Reg=0.00117 | acc=0.9531 | L2-Norm=10.795 | L2-Norm(final)=7.419 | 3926.8 samples/s | 61.4 steps/s
[Step=28600 Epoch=272.6] | Loss=0.01196 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.914 | L2-Norm(final)=7.392 | 6276.4 samples/s | 98.1 steps/s
[Step=28650 Epoch=273.1] | Loss=0.00814 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.988 | L2-Norm(final)=7.381 | 2001.5 samples/s | 31.3 steps/s
[Step=28700 Epoch=273.5] | Loss=0.00613 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.025 | L2-Norm(final)=7.376 | 5853.1 samples/s | 91.5 steps/s
[Step=28750 Epoch=274.0] | Loss=0.00515 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.047 | L2-Norm(final)=7.373 | 2050.3 samples/s | 32.0 steps/s
[Step=28800 Epoch=274.5] | Loss=0.00430 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.060 | L2-Norm(final)=7.372 | 5381.9 samples/s | 84.1 steps/s
[Step=28850 Epoch=275.0] | Loss=0.00369 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.070 | L2-Norm(final)=7.371 | 2185.8 samples/s | 34.2 steps/s
[Step=28900 Epoch=275.4] | Loss=0.00323 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.076 | L2-Norm(final)=7.370 | 4795.4 samples/s | 74.9 steps/s
[Step=28950 Epoch=275.9] | Loss=0.00288 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.080 | L2-Norm(final)=7.370 | 2185.8 samples/s | 34.2 steps/s
[Step=29000 Epoch=276.4] | Loss=0.00259 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.083 | L2-Norm(final)=7.370 | 4619.3 samples/s | 72.2 steps/s
[Step=29050 Epoch=276.9] | Loss=0.00236 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.084 | L2-Norm(final)=7.370 | 2269.2 samples/s | 35.5 steps/s
[Step=29100 Epoch=277.3] | Loss=0.00216 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.085 | L2-Norm(final)=7.370 | 4335.0 samples/s | 67.7 steps/s
[Step=29150 Epoch=277.8] | Loss=0.00200 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.085 | L2-Norm(final)=7.370 | 2358.8 samples/s | 36.9 steps/s
[Step=29200 Epoch=278.3] | Loss=0.00186 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.085 | L2-Norm(final)=7.370 | 4358.9 samples/s | 68.1 steps/s
[Step=29250 Epoch=278.8] | Loss=0.00173 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.084 | L2-Norm(final)=7.370 | 2346.6 samples/s | 36.7 steps/s
[Step=29300 Epoch=279.3] | Loss=0.00163 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.083 | L2-Norm(final)=7.371 | 4185.2 samples/s | 65.4 steps/s
[Step=29350 Epoch=279.7] | Loss=0.00153 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.081 | L2-Norm(final)=7.371 | 2382.8 samples/s | 37.2 steps/s
[Step=29400 Epoch=280.2] | Loss=0.00145 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.080 | L2-Norm(final)=7.371 | 4285.8 samples/s | 67.0 steps/s
[Step=29450 Epoch=280.7] | Loss=0.00137 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.078 | L2-Norm(final)=7.372 | 2379.5 samples/s | 37.2 steps/s
[Step=29500 Epoch=281.2] | Loss=0.00130 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.076 | L2-Norm(final)=7.372 | 4221.3 samples/s | 66.0 steps/s
[Step=29550 Epoch=281.6] | Loss=0.00124 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.073 | L2-Norm(final)=7.373 | 6908.0 samples/s | 107.9 steps/s
[Step=29600 Epoch=282.1] | Loss=0.00118 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.071 | L2-Norm(final)=7.373 | 1933.4 samples/s | 30.2 steps/s
[Step=29650 Epoch=282.6] | Loss=0.00113 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.068 | L2-Norm(final)=7.374 | 6388.9 samples/s | 99.8 steps/s
[Step=29700 Epoch=283.1] | Loss=0.00109 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.065 | L2-Norm(final)=7.375 | 2023.6 samples/s | 31.6 steps/s
[Step=29750 Epoch=283.5] | Loss=0.00104 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.063 | L2-Norm(final)=7.375 | 5627.5 samples/s | 87.9 steps/s
[Step=29800 Epoch=284.0] | Loss=0.00100 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.060 | L2-Norm(final)=7.376 | 2066.7 samples/s | 32.3 steps/s
[Step=29850 Epoch=284.5] | Loss=0.00097 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.056 | L2-Norm(final)=7.377 | 5318.9 samples/s | 83.1 steps/s
[Step=29900 Epoch=285.0] | Loss=0.00093 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.053 | L2-Norm(final)=7.377 | 2138.5 samples/s | 33.4 steps/s
[Step=29950 Epoch=285.5] | Loss=0.00090 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.050 | L2-Norm(final)=7.378 | 4981.7 samples/s | 77.8 steps/s
[Step=30000 Epoch=285.9] | Loss=0.00087 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.046 | L2-Norm(final)=7.379 | 2196.6 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12576 | acc=0.9572 | tpr=0.9764 | fpr=0.0845 | 4915.0 samples/s | 19.2 steps/s
Avg test loss: 0.13206, Avg test acc: 0.95512, Avg tpr: 0.97470, Avg fpr: 0.08794, total FA: 686

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13359 | acc=0.9540 | tpr=0.9767 | fpr=0.0954 | 4914.8 samples/s | 19.2 steps/s
Avg test loss: 0.13204, Avg test acc: 0.95360, Avg tpr: 0.97575, Avg fpr: 0.09512, total FA: 742

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.13089 | acc=0.9551 | tpr=0.9706 | fpr=0.0785 | 4837.6 samples/s | 18.9 steps/s
Avg test loss: 0.12998, Avg test acc: 0.95384, Avg tpr: 0.96987, Avg fpr: 0.08140, total FA: 635

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.12653 | acc=0.9517 | tpr=0.9596 | fpr=0.0654 | 4670.2 samples/s | 18.2 steps/s
Avg test loss: 0.12823, Avg test acc: 0.95128, Avg tpr: 0.96054, Avg fpr: 0.06909, total FA: 539

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11907 | acc=0.9556 | tpr=0.9700 | fpr=0.0756 | 4947.6 samples/s | 19.3 steps/s
Avg test loss: 0.12726, Avg test acc: 0.95444, Avg tpr: 0.96841, Avg fpr: 0.07627, total FA: 595

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.12947 | acc=0.2843 | tpr=0.0235 | fpr=0.1494 | 4789.8 samples/s | 18.7 steps/s
Avg test loss: 5.13154, Avg test acc: 0.28243, Avg tpr: 0.02384, Avg fpr: 0.14883, total FA: 1161

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.69285 | acc=0.3095 | tpr=0.0025 | fpr=0.0240 | 4835.2 samples/s | 18.9 steps/s
Avg test loss: 4.71636, Avg test acc: 0.30676, Avg tpr: 0.00268, Avg fpr: 0.02448, total FA: 191

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.55737 | acc=0.2781 | tpr=0.0183 | fpr=0.1576 | 4902.4 samples/s | 19.1 steps/s
Avg test loss: 5.55849, Avg test acc: 0.27614, Avg tpr: 0.01848, Avg fpr: 0.15716, total FA: 1226

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.74717 | acc=0.2833 | tpr=0.0286 | fpr=0.1638 | 4878.9 samples/s | 19.1 steps/s
Avg test loss: 5.74349, Avg test acc: 0.28271, Avg tpr: 0.02850, Avg fpr: 0.15818, total FA: 1234

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.69663 | acc=0.2988 | tpr=0.0172 | fpr=0.0899 | 4808.1 samples/s | 18.8 steps/s
Avg test loss: 5.71796, Avg test acc: 0.29702, Avg tpr: 0.01661, Avg fpr: 0.08627, total FA: 673

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.42172 | acc=0.0765 | tpr=0.6770 | fpr=0.9343 | 4904.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.39935 | acc=0.0771 | tpr=0.6503 | fpr=0.9336 | 6929.0 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.42015 | acc=0.0782 | tpr=0.6412 | fpr=0.9322 | 7441.5 samples/s | 29.1 steps/s
[Step= 200] | Loss=6.42117 | acc=0.0776 | tpr=0.6448 | fpr=0.9327 | 8241.4 samples/s | 32.2 steps/s
[Step= 250] | Loss=6.43104 | acc=0.0779 | tpr=0.6428 | fpr=0.9324 | 8094.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=6.43149 | acc=0.0777 | tpr=0.6444 | fpr=0.9326 | 7449.4 samples/s | 29.1 steps/s
[Step= 350] | Loss=6.43156 | acc=0.0774 | tpr=0.6481 | fpr=0.9329 | 8152.0 samples/s | 31.8 steps/s
[Step= 400] | Loss=6.42513 | acc=0.0778 | tpr=0.6488 | fpr=0.9326 | 7787.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.43013 | acc=0.0779 | tpr=0.6451 | fpr=0.9324 | 7945.0 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.43612 | acc=0.0777 | tpr=0.6441 | fpr=0.9325 | 7724.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.43962 | acc=0.0777 | tpr=0.6431 | fpr=0.9326 | 13960.4 samples/s | 54.5 steps/s
Avg test loss: 6.44126, Avg test acc: 0.07768, Avg tpr: 0.64342, Avg fpr: 0.93260, total FA: 129490

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.61458 | acc=0.0824 | tpr=0.6283 | fpr=0.9274 | 4704.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.59956 | acc=0.0813 | tpr=0.6311 | fpr=0.9289 | 7356.1 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.60083 | acc=0.0830 | tpr=0.6412 | fpr=0.9273 | 7739.9 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.59717 | acc=0.0825 | tpr=0.6350 | fpr=0.9275 | 8041.6 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.60849 | acc=0.0823 | tpr=0.6288 | fpr=0.9276 | 7715.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.60119 | acc=0.0817 | tpr=0.6262 | fpr=0.9283 | 8231.3 samples/s | 32.2 steps/s
[Step= 350] | Loss=5.59188 | acc=0.0820 | tpr=0.6318 | fpr=0.9280 | 7650.2 samples/s | 29.9 steps/s
[Step= 400] | Loss=5.58747 | acc=0.0825 | tpr=0.6307 | fpr=0.9275 | 7807.4 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.59160 | acc=0.0822 | tpr=0.6290 | fpr=0.9277 | 7994.3 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.59802 | acc=0.0817 | tpr=0.6300 | fpr=0.9282 | 7859.7 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.60008 | acc=0.0817 | tpr=0.6303 | fpr=0.9283 | 13709.3 samples/s | 53.6 steps/s
Avg test loss: 5.60181, Avg test acc: 0.08161, Avg tpr: 0.63074, Avg fpr: 0.92837, total FA: 128903

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.32054 | acc=0.0830 | tpr=0.5752 | fpr=0.9258 | 4844.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.27922 | acc=0.0843 | tpr=0.5906 | fpr=0.9251 | 7071.9 samples/s | 27.6 steps/s
[Step= 150] | Loss=6.29152 | acc=0.0845 | tpr=0.5980 | fpr=0.9250 | 7532.7 samples/s | 29.4 steps/s
[Step= 200] | Loss=6.28180 | acc=0.0847 | tpr=0.6000 | fpr=0.9247 | 8022.8 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.28393 | acc=0.0845 | tpr=0.5965 | fpr=0.9248 | 7423.9 samples/s | 29.0 steps/s
[Step= 300] | Loss=6.28469 | acc=0.0847 | tpr=0.6029 | fpr=0.9247 | 8095.0 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.27700 | acc=0.0851 | tpr=0.6043 | fpr=0.9243 | 8155.0 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.27053 | acc=0.0852 | tpr=0.5963 | fpr=0.9241 | 7801.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.27096 | acc=0.0853 | tpr=0.5983 | fpr=0.9240 | 7926.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.27314 | acc=0.0856 | tpr=0.5969 | fpr=0.9237 | 7689.4 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.27605 | acc=0.0856 | tpr=0.5953 | fpr=0.9237 | 14105.0 samples/s | 55.1 steps/s
Avg test loss: 6.27760, Avg test acc: 0.08548, Avg tpr: 0.59628, Avg fpr: 0.92381, total FA: 128269

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.12701 | acc=0.1255 | tpr=0.6327 | fpr=0.8836 | 4820.5 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.10636 | acc=0.1269 | tpr=0.6247 | fpr=0.8824 | 6978.7 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.11259 | acc=0.1278 | tpr=0.6340 | fpr=0.8815 | 7907.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.10372 | acc=0.1279 | tpr=0.6295 | fpr=0.8813 | 7923.5 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.10962 | acc=0.1278 | tpr=0.6227 | fpr=0.8812 | 7774.4 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.10438 | acc=0.1275 | tpr=0.6196 | fpr=0.8814 | 7839.0 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.09505 | acc=0.1274 | tpr=0.6218 | fpr=0.8815 | 8056.0 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.09715 | acc=0.1274 | tpr=0.6138 | fpr=0.8814 | 7740.4 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.10116 | acc=0.1273 | tpr=0.6164 | fpr=0.8816 | 8112.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.10346 | acc=0.1266 | tpr=0.6159 | fpr=0.8822 | 7563.0 samples/s | 29.5 steps/s
[Step= 550] | Loss=5.10349 | acc=0.1266 | tpr=0.6188 | fpr=0.8823 | 14645.8 samples/s | 57.2 steps/s
Avg test loss: 5.10504, Avg test acc: 0.12652, Avg tpr: 0.61926, Avg fpr: 0.88244, total FA: 122525

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.08047 | acc=0.1023 | tpr=0.6239 | fpr=0.9071 | 4537.8 samples/s | 17.7 steps/s
[Step= 100] | Loss=6.05385 | acc=0.1041 | tpr=0.6098 | fpr=0.9054 | 7699.6 samples/s | 30.1 steps/s
[Step= 150] | Loss=6.05652 | acc=0.1054 | tpr=0.6153 | fpr=0.9040 | 7813.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.06277 | acc=0.1045 | tpr=0.6120 | fpr=0.9048 | 7870.0 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.07387 | acc=0.1041 | tpr=0.6079 | fpr=0.9050 | 7717.8 samples/s | 30.1 steps/s
[Step= 300] | Loss=6.06770 | acc=0.1041 | tpr=0.6138 | fpr=0.9052 | 8094.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.06150 | acc=0.1042 | tpr=0.6124 | fpr=0.9050 | 7728.7 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.05982 | acc=0.1044 | tpr=0.6176 | fpr=0.9049 | 7911.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=6.06156 | acc=0.1041 | tpr=0.6168 | fpr=0.9052 | 8020.0 samples/s | 31.3 steps/s
[Step= 500] | Loss=6.06490 | acc=0.1040 | tpr=0.6128 | fpr=0.9052 | 7382.2 samples/s | 28.8 steps/s
[Step= 550] | Loss=6.06798 | acc=0.1036 | tpr=0.6140 | fpr=0.9056 | 15522.3 samples/s | 60.6 steps/s
Avg test loss: 6.06922, Avg test acc: 0.10356, Avg tpr: 0.61450, Avg fpr: 0.90573, total FA: 125759

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10152 | acc=0.9796 | tpr=0.9602 | fpr=0.0200 | 4699.0 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10371 | acc=0.9796 | tpr=0.9616 | fpr=0.0201 | 7187.5 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.10690 | acc=0.9792 | tpr=0.9597 | fpr=0.0205 | 7945.2 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10928 | acc=0.9789 | tpr=0.9628 | fpr=0.0208 | 7943.0 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.10812 | acc=0.9791 | tpr=0.9563 | fpr=0.0205 | 7770.9 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11058 | acc=0.9787 | tpr=0.9535 | fpr=0.0209 | 7870.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.11132 | acc=0.9785 | tpr=0.9549 | fpr=0.0211 | 7999.8 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.11244 | acc=0.9783 | tpr=0.9508 | fpr=0.0212 | 7818.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.11466 | acc=0.9780 | tpr=0.9484 | fpr=0.0215 | 7875.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.11384 | acc=0.9780 | tpr=0.9498 | fpr=0.0214 | 7845.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.11317 | acc=0.9783 | tpr=0.9487 | fpr=0.0212 | 14479.6 samples/s | 56.6 steps/s
Avg test loss: 0.11312, Avg test acc: 0.97829, Avg tpr: 0.94849, Avg fpr: 0.02117, total FA: 2939

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08603 | acc=0.9833 | tpr=0.8628 | fpr=0.0146 | 4694.8 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.08754 | acc=0.9832 | tpr=0.8827 | fpr=0.0149 | 7420.7 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.09098 | acc=0.9827 | tpr=0.8862 | fpr=0.0155 | 7744.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.09151 | acc=0.9829 | tpr=0.8940 | fpr=0.0154 | 7810.2 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09043 | acc=0.9829 | tpr=0.8900 | fpr=0.0154 | 8142.5 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.09268 | acc=0.9826 | tpr=0.8865 | fpr=0.0157 | 7290.6 samples/s | 28.5 steps/s
[Step= 350] | Loss=0.09316 | acc=0.9825 | tpr=0.8904 | fpr=0.0158 | 8045.8 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.09472 | acc=0.9822 | tpr=0.8835 | fpr=0.0160 | 8121.5 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.09657 | acc=0.9819 | tpr=0.8812 | fpr=0.0163 | 7917.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.09547 | acc=0.9820 | tpr=0.8824 | fpr=0.0162 | 7758.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.09530 | acc=0.9822 | tpr=0.8818 | fpr=0.0160 | 14008.1 samples/s | 54.7 steps/s
Avg test loss: 0.09523, Avg test acc: 0.98221, Avg tpr: 0.88193, Avg fpr: 0.01597, total FA: 2217

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10023 | acc=0.9795 | tpr=0.9558 | fpr=0.0201 | 4835.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.10191 | acc=0.9796 | tpr=0.9510 | fpr=0.0199 | 6989.5 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.10530 | acc=0.9790 | tpr=0.9510 | fpr=0.0205 | 8085.3 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.10782 | acc=0.9791 | tpr=0.9519 | fpr=0.0204 | 7602.8 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.10653 | acc=0.9793 | tpr=0.9528 | fpr=0.0202 | 7862.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.10896 | acc=0.9790 | tpr=0.9462 | fpr=0.0204 | 7805.0 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.10927 | acc=0.9790 | tpr=0.9480 | fpr=0.0204 | 7817.3 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.11042 | acc=0.9787 | tpr=0.9458 | fpr=0.0207 | 7840.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.11224 | acc=0.9786 | tpr=0.9455 | fpr=0.0208 | 7714.5 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.11158 | acc=0.9786 | tpr=0.9458 | fpr=0.0208 | 8287.6 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.11107 | acc=0.9788 | tpr=0.9455 | fpr=0.0206 | 14363.8 samples/s | 56.1 steps/s
Avg test loss: 0.11102, Avg test acc: 0.97879, Avg tpr: 0.94572, Avg fpr: 0.02061, total FA: 2862

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10731 | acc=0.9803 | tpr=0.9336 | fpr=0.0188 | 4929.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.11219 | acc=0.9797 | tpr=0.9275 | fpr=0.0193 | 6958.3 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.11706 | acc=0.9791 | tpr=0.9337 | fpr=0.0200 | 7674.5 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.11972 | acc=0.9792 | tpr=0.9421 | fpr=0.0201 | 7798.3 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.11827 | acc=0.9795 | tpr=0.9389 | fpr=0.0197 | 7980.2 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.12141 | acc=0.9792 | tpr=0.9360 | fpr=0.0200 | 7722.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.12176 | acc=0.9791 | tpr=0.9368 | fpr=0.0201 | 7937.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.12229 | acc=0.9789 | tpr=0.9344 | fpr=0.0202 | 7986.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.12468 | acc=0.9788 | tpr=0.9328 | fpr=0.0204 | 8024.4 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.12360 | acc=0.9789 | tpr=0.9357 | fpr=0.0203 | 7382.6 samples/s | 28.8 steps/s
[Step= 550] | Loss=0.12320 | acc=0.9790 | tpr=0.9351 | fpr=0.0202 | 15569.0 samples/s | 60.8 steps/s
Avg test loss: 0.12308, Avg test acc: 0.97903, Avg tpr: 0.93502, Avg fpr: 0.02017, total FA: 2801

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.13388 | acc=0.9791 | tpr=0.9248 | fpr=0.0199 | 4813.9 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.14032 | acc=0.9789 | tpr=0.9318 | fpr=0.0202 | 6808.8 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.14600 | acc=0.9784 | tpr=0.9380 | fpr=0.0209 | 8024.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.14877 | acc=0.9785 | tpr=0.9454 | fpr=0.0209 | 7907.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14622 | acc=0.9787 | tpr=0.9389 | fpr=0.0206 | 7676.5 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.14888 | acc=0.9785 | tpr=0.9316 | fpr=0.0207 | 7906.7 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.15009 | acc=0.9782 | tpr=0.9305 | fpr=0.0210 | 7882.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.15172 | acc=0.9779 | tpr=0.9289 | fpr=0.0212 | 7943.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.15431 | acc=0.9777 | tpr=0.9255 | fpr=0.0214 | 7935.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15330 | acc=0.9777 | tpr=0.9251 | fpr=0.0214 | 7578.3 samples/s | 29.6 steps/s
[Step= 550] | Loss=0.15238 | acc=0.9778 | tpr=0.9244 | fpr=0.0212 | 14378.5 samples/s | 56.2 steps/s
Avg test loss: 0.15209, Avg test acc: 0.97781, Avg tpr: 0.92393, Avg fpr: 0.02121, total FA: 2945

server round 15/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=146.3] | Loss=0.01194 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.928 | L2-Norm(final)=10.151 | 5807.3 samples/s | 90.7 steps/s
[Step=30050 Epoch=146.5] | Loss=0.00390 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.925 | L2-Norm(final)=10.163 | 4112.9 samples/s | 64.3 steps/s
[Step=30100 Epoch=146.8] | Loss=0.00384 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.925 | L2-Norm(final)=10.176 | 4931.5 samples/s | 77.1 steps/s
[Step=30150 Epoch=147.0] | Loss=0.00386 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.924 | L2-Norm(final)=10.190 | 5108.7 samples/s | 79.8 steps/s
[Step=30200 Epoch=147.3] | Loss=0.00432 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.922 | L2-Norm(final)=10.204 | 7746.0 samples/s | 121.0 steps/s
[Step=30250 Epoch=147.5] | Loss=0.00416 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.919 | L2-Norm(final)=10.217 | 2219.0 samples/s | 34.7 steps/s
[Step=30300 Epoch=147.7] | Loss=0.00405 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.915 | L2-Norm(final)=10.231 | 4943.6 samples/s | 77.2 steps/s
[Step=30350 Epoch=148.0] | Loss=0.00405 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.911 | L2-Norm(final)=10.244 | 5038.9 samples/s | 78.7 steps/s
[Step=30400 Epoch=148.2] | Loss=0.00392 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.906 | L2-Norm(final)=10.257 | 6978.5 samples/s | 109.0 steps/s
[Step=30450 Epoch=148.5] | Loss=0.00382 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.901 | L2-Norm(final)=10.270 | 2286.5 samples/s | 35.7 steps/s
[Step=30500 Epoch=148.7] | Loss=0.00370 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.896 | L2-Norm(final)=10.283 | 4988.8 samples/s | 77.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=148.7] | Loss=0.01190 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.842 | L2-Norm(final)=10.414 | 5493.2 samples/s | 85.8 steps/s
[Step=30550 Epoch=149.0] | Loss=0.00641 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.839 | L2-Norm(final)=10.424 | 4046.7 samples/s | 63.2 steps/s
[Step=30600 Epoch=149.2] | Loss=0.00933 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.854 | L2-Norm(final)=10.428 | 4466.3 samples/s | 69.8 steps/s
[Step=30650 Epoch=149.5] | Loss=0.01138 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.892 | L2-Norm(final)=10.434 | 4458.6 samples/s | 69.7 steps/s
[Step=30700 Epoch=149.7] | Loss=0.01351 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.938 | L2-Norm(final)=10.439 | 6598.0 samples/s | 103.1 steps/s
[Step=30750 Epoch=149.9] | Loss=0.01494 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.980 | L2-Norm(final)=10.443 | 2102.9 samples/s | 32.9 steps/s
[Step=30800 Epoch=150.2] | Loss=0.01539 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.019 | L2-Norm(final)=10.447 | 4259.0 samples/s | 66.5 steps/s
[Step=30850 Epoch=150.4] | Loss=0.01542 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.053 | L2-Norm(final)=10.450 | 4470.3 samples/s | 69.8 steps/s
[Step=30900 Epoch=150.7] | Loss=0.01520 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.082 | L2-Norm(final)=10.453 | 5887.5 samples/s | 92.0 steps/s
[Step=30950 Epoch=150.9] | Loss=0.01482 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.107 | L2-Norm(final)=10.456 | 2171.6 samples/s | 33.9 steps/s
[Step=31000 Epoch=151.2] | Loss=0.01414 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.129 | L2-Norm(final)=10.459 | 4528.3 samples/s | 70.8 steps/s
[Step=31050 Epoch=151.4] | Loss=0.01365 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.148 | L2-Norm(final)=10.463 | 4521.5 samples/s | 70.6 steps/s
[Step=31100 Epoch=151.6] | Loss=0.01329 | Reg=0.00407 | acc=0.9688 | L2-Norm=20.164 | L2-Norm(final)=10.466 | 5263.7 samples/s | 82.2 steps/s
[Step=31150 Epoch=151.9] | Loss=0.01267 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.177 | L2-Norm(final)=10.469 | 2230.0 samples/s | 34.8 steps/s
[Step=31200 Epoch=152.1] | Loss=0.01212 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.188 | L2-Norm(final)=10.473 | 4497.6 samples/s | 70.3 steps/s
[Step=31250 Epoch=152.4] | Loss=0.01155 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.197 | L2-Norm(final)=10.476 | 4438.1 samples/s | 69.3 steps/s
[Step=31300 Epoch=152.6] | Loss=0.01129 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.203 | L2-Norm(final)=10.480 | 4925.1 samples/s | 77.0 steps/s
[Step=31350 Epoch=152.9] | Loss=0.01089 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.209 | L2-Norm(final)=10.483 | 2345.7 samples/s | 36.7 steps/s
[Step=31400 Epoch=153.1] | Loss=0.01050 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.213 | L2-Norm(final)=10.486 | 4370.4 samples/s | 68.3 steps/s
[Step=31450 Epoch=153.4] | Loss=0.01009 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.217 | L2-Norm(final)=10.489 | 4530.7 samples/s | 70.8 steps/s
[Step=31500 Epoch=153.6] | Loss=0.00986 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.219 | L2-Norm(final)=10.492 | 4526.1 samples/s | 70.7 steps/s
[Step=31550 Epoch=153.8] | Loss=0.00959 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.220 | L2-Norm(final)=10.495 | 2422.5 samples/s | 37.9 steps/s
[Step=31600 Epoch=154.1] | Loss=0.00930 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.221 | L2-Norm(final)=10.498 | 4356.0 samples/s | 68.1 steps/s
[Step=31650 Epoch=154.3] | Loss=0.00907 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.221 | L2-Norm(final)=10.500 | 4460.6 samples/s | 69.7 steps/s
[Step=31700 Epoch=154.6] | Loss=0.00883 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.220 | L2-Norm(final)=10.503 | 4446.9 samples/s | 69.5 steps/s
[Step=31750 Epoch=154.8] | Loss=0.00858 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.218 | L2-Norm(final)=10.506 | 2472.9 samples/s | 38.6 steps/s
[Step=31800 Epoch=155.1] | Loss=0.00839 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.216 | L2-Norm(final)=10.508 | 4458.4 samples/s | 69.7 steps/s
[Step=31850 Epoch=155.3] | Loss=0.00821 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.213 | L2-Norm(final)=10.511 | 4414.3 samples/s | 69.0 steps/s
[Step=31900 Epoch=155.6] | Loss=0.00811 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.210 | L2-Norm(final)=10.513 | 4455.8 samples/s | 69.6 steps/s
[Step=31950 Epoch=155.8] | Loss=0.00796 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.206 | L2-Norm(final)=10.515 | 2467.9 samples/s | 38.6 steps/s
[Step=32000 Epoch=156.0] | Loss=0.00779 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.202 | L2-Norm(final)=10.516 | 4505.0 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step32000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=146.4] | Loss=0.00449 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.059 | L2-Norm(final)=10.286 | 5298.4 samples/s | 82.8 steps/s
[Step=30050 Epoch=146.6] | Loss=0.00401 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.057 | L2-Norm(final)=10.296 | 4536.4 samples/s | 70.9 steps/s
[Step=30100 Epoch=146.9] | Loss=0.00441 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.054 | L2-Norm(final)=10.309 | 5016.6 samples/s | 78.4 steps/s
[Step=30150 Epoch=147.1] | Loss=0.00402 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.053 | L2-Norm(final)=10.323 | 5141.9 samples/s | 80.3 steps/s
[Step=30200 Epoch=147.4] | Loss=0.00397 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.050 | L2-Norm(final)=10.336 | 7386.0 samples/s | 115.4 steps/s
[Step=30250 Epoch=147.6] | Loss=0.00367 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.045 | L2-Norm(final)=10.348 | 2172.4 samples/s | 33.9 steps/s
[Step=30300 Epoch=147.8] | Loss=0.00370 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.041 | L2-Norm(final)=10.360 | 5122.8 samples/s | 80.0 steps/s
[Step=30350 Epoch=148.1] | Loss=0.00367 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.037 | L2-Norm(final)=10.373 | 5119.1 samples/s | 80.0 steps/s
[Step=30400 Epoch=148.3] | Loss=0.00363 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.032 | L2-Norm(final)=10.384 | 6826.1 samples/s | 106.7 steps/s
[Step=30450 Epoch=148.6] | Loss=0.00349 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.026 | L2-Norm(final)=10.396 | 2290.1 samples/s | 35.8 steps/s
[Step=30500 Epoch=148.8] | Loss=0.00341 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.021 | L2-Norm(final)=10.407 | 4963.8 samples/s | 77.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=148.8] | Loss=0.00414 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.960 | L2-Norm(final)=10.522 | 5091.4 samples/s | 79.6 steps/s
[Step=30550 Epoch=149.1] | Loss=0.00458 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.956 | L2-Norm(final)=10.530 | 4094.2 samples/s | 64.0 steps/s
[Step=30600 Epoch=149.3] | Loss=0.00768 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.969 | L2-Norm(final)=10.538 | 4500.0 samples/s | 70.3 steps/s
[Step=30650 Epoch=149.6] | Loss=0.01129 | Reg=0.00400 | acc=0.9844 | L2-Norm=20.006 | L2-Norm(final)=10.544 | 4480.6 samples/s | 70.0 steps/s
[Step=30700 Epoch=149.8] | Loss=0.01476 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.046 | L2-Norm(final)=10.547 | 6585.6 samples/s | 102.9 steps/s
[Step=30750 Epoch=150.0] | Loss=0.01492 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.080 | L2-Norm(final)=10.547 | 2065.4 samples/s | 32.3 steps/s
[Step=30800 Epoch=150.3] | Loss=0.01393 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.107 | L2-Norm(final)=10.550 | 4474.3 samples/s | 69.9 steps/s
[Step=30850 Epoch=150.5] | Loss=0.01362 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.128 | L2-Norm(final)=10.554 | 4580.4 samples/s | 71.6 steps/s
[Step=30900 Epoch=150.8] | Loss=0.01312 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.146 | L2-Norm(final)=10.558 | 5719.9 samples/s | 89.4 steps/s
[Step=30950 Epoch=151.0] | Loss=0.01271 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.161 | L2-Norm(final)=10.562 | 2139.8 samples/s | 33.4 steps/s
[Step=31000 Epoch=151.3] | Loss=0.01188 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.175 | L2-Norm(final)=10.567 | 4472.6 samples/s | 69.9 steps/s
[Step=31050 Epoch=151.5] | Loss=0.01155 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.186 | L2-Norm(final)=10.571 | 4477.6 samples/s | 70.0 steps/s
[Step=31100 Epoch=151.8] | Loss=0.01119 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.197 | L2-Norm(final)=10.576 | 5602.9 samples/s | 87.5 steps/s
[Step=31150 Epoch=152.0] | Loss=0.01106 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.206 | L2-Norm(final)=10.580 | 2222.7 samples/s | 34.7 steps/s
[Step=31200 Epoch=152.2] | Loss=0.01061 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.214 | L2-Norm(final)=10.583 | 4470.8 samples/s | 69.9 steps/s
[Step=31250 Epoch=152.5] | Loss=0.01038 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.220 | L2-Norm(final)=10.587 | 4409.5 samples/s | 68.9 steps/s
[Step=31300 Epoch=152.7] | Loss=0.01000 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.225 | L2-Norm(final)=10.590 | 5215.4 samples/s | 81.5 steps/s
[Step=31350 Epoch=153.0] | Loss=0.00965 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.228 | L2-Norm(final)=10.593 | 2294.2 samples/s | 35.8 steps/s
[Step=31400 Epoch=153.2] | Loss=0.00933 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.230 | L2-Norm(final)=10.596 | 4464.7 samples/s | 69.8 steps/s
[Step=31450 Epoch=153.5] | Loss=0.00915 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.231 | L2-Norm(final)=10.599 | 4443.2 samples/s | 69.4 steps/s
[Step=31500 Epoch=153.7] | Loss=0.00885 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.231 | L2-Norm(final)=10.601 | 4830.3 samples/s | 75.5 steps/s
[Step=31550 Epoch=153.9] | Loss=0.00858 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.231 | L2-Norm(final)=10.604 | 2314.6 samples/s | 36.2 steps/s
[Step=31600 Epoch=154.2] | Loss=0.00835 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.229 | L2-Norm(final)=10.607 | 4519.2 samples/s | 70.6 steps/s
[Step=31650 Epoch=154.4] | Loss=0.00812 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.227 | L2-Norm(final)=10.609 | 4408.7 samples/s | 68.9 steps/s
[Step=31700 Epoch=154.7] | Loss=0.00789 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.224 | L2-Norm(final)=10.612 | 4565.5 samples/s | 71.3 steps/s
[Step=31750 Epoch=154.9] | Loss=0.00765 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.221 | L2-Norm(final)=10.614 | 2435.5 samples/s | 38.1 steps/s
[Step=31800 Epoch=155.2] | Loss=0.00744 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.217 | L2-Norm(final)=10.617 | 4519.9 samples/s | 70.6 steps/s
[Step=31850 Epoch=155.4] | Loss=0.00728 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.212 | L2-Norm(final)=10.619 | 4483.0 samples/s | 70.0 steps/s
[Step=31900 Epoch=155.7] | Loss=0.00714 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.207 | L2-Norm(final)=10.621 | 4405.4 samples/s | 68.8 steps/s
[Step=31950 Epoch=155.9] | Loss=0.00700 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.202 | L2-Norm(final)=10.623 | 2393.6 samples/s | 37.4 steps/s
[Step=32000 Epoch=156.1] | Loss=0.00685 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.196 | L2-Norm(final)=10.626 | 4436.7 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step32000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=146.2] | Loss=0.00089 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.237 | L2-Norm(final)=10.682 | 5473.6 samples/s | 85.5 steps/s
[Step=30050 Epoch=146.4] | Loss=0.00548 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.235 | L2-Norm(final)=10.694 | 4263.2 samples/s | 66.6 steps/s
[Step=30100 Epoch=146.7] | Loss=0.00503 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.236 | L2-Norm(final)=10.707 | 5047.4 samples/s | 78.9 steps/s
[Step=30150 Epoch=146.9] | Loss=0.00489 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.236 | L2-Norm(final)=10.720 | 5066.7 samples/s | 79.2 steps/s
[Step=30200 Epoch=147.1] | Loss=0.00488 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.234 | L2-Norm(final)=10.733 | 7821.2 samples/s | 122.2 steps/s
[Step=30250 Epoch=147.4] | Loss=0.00473 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.231 | L2-Norm(final)=10.745 | 2187.7 samples/s | 34.2 steps/s
[Step=30300 Epoch=147.6] | Loss=0.00445 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.229 | L2-Norm(final)=10.758 | 5130.2 samples/s | 80.2 steps/s
[Step=30350 Epoch=147.9] | Loss=0.00458 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.225 | L2-Norm(final)=10.771 | 5040.5 samples/s | 78.8 steps/s
[Step=30400 Epoch=148.1] | Loss=0.00442 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.221 | L2-Norm(final)=10.783 | 6848.3 samples/s | 107.0 steps/s
[Step=30450 Epoch=148.4] | Loss=0.00428 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.217 | L2-Norm(final)=10.795 | 2358.5 samples/s | 36.9 steps/s
[Step=30500 Epoch=148.6] | Loss=0.00421 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.213 | L2-Norm(final)=10.807 | 4808.2 samples/s | 75.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=148.6] | Loss=0.00176 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.170 | L2-Norm(final)=10.926 | 5052.3 samples/s | 78.9 steps/s
[Step=30550 Epoch=148.9] | Loss=0.00354 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.166 | L2-Norm(final)=10.937 | 4245.4 samples/s | 66.3 steps/s
[Step=30600 Epoch=149.1] | Loss=0.00491 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.167 | L2-Norm(final)=10.946 | 4374.2 samples/s | 68.3 steps/s
[Step=30650 Epoch=149.3] | Loss=0.00747 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.171 | L2-Norm(final)=10.952 | 4498.5 samples/s | 70.3 steps/s
[Step=30700 Epoch=149.6] | Loss=0.00840 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.181 | L2-Norm(final)=10.958 | 6556.5 samples/s | 102.4 steps/s
[Step=30750 Epoch=149.8] | Loss=0.00942 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.195 | L2-Norm(final)=10.964 | 2115.4 samples/s | 33.1 steps/s
[Step=30800 Epoch=150.1] | Loss=0.01084 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.213 | L2-Norm(final)=10.970 | 4482.9 samples/s | 70.0 steps/s
[Step=30850 Epoch=150.3] | Loss=0.01103 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.234 | L2-Norm(final)=10.975 | 4471.4 samples/s | 69.9 steps/s
[Step=30900 Epoch=150.6] | Loss=0.01148 | Reg=0.00410 | acc=0.9844 | L2-Norm=20.255 | L2-Norm(final)=10.981 | 5888.9 samples/s | 92.0 steps/s
[Step=30950 Epoch=150.8] | Loss=0.01139 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.275 | L2-Norm(final)=10.988 | 2158.6 samples/s | 33.7 steps/s
[Step=31000 Epoch=151.0] | Loss=0.01111 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.292 | L2-Norm(final)=10.994 | 4505.3 samples/s | 70.4 steps/s
[Step=31050 Epoch=151.3] | Loss=0.01087 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.306 | L2-Norm(final)=11.000 | 4475.4 samples/s | 69.9 steps/s
[Step=31100 Epoch=151.5] | Loss=0.01062 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.318 | L2-Norm(final)=11.005 | 5397.0 samples/s | 84.3 steps/s
[Step=31150 Epoch=151.8] | Loss=0.01016 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.327 | L2-Norm(final)=11.011 | 2239.7 samples/s | 35.0 steps/s
[Step=31200 Epoch=152.0] | Loss=0.00976 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.335 | L2-Norm(final)=11.016 | 4471.4 samples/s | 69.9 steps/s
[Step=31250 Epoch=152.3] | Loss=0.00958 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.340 | L2-Norm(final)=11.020 | 4496.7 samples/s | 70.3 steps/s
[Step=31300 Epoch=152.5] | Loss=0.00942 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.345 | L2-Norm(final)=11.024 | 4824.8 samples/s | 75.4 steps/s
[Step=31350 Epoch=152.8] | Loss=0.00906 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.348 | L2-Norm(final)=11.028 | 2263.3 samples/s | 35.4 steps/s
[Step=31400 Epoch=153.0] | Loss=0.00876 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.350 | L2-Norm(final)=11.032 | 4447.5 samples/s | 69.5 steps/s
[Step=31450 Epoch=153.2] | Loss=0.00858 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.351 | L2-Norm(final)=11.036 | 4530.5 samples/s | 70.8 steps/s
[Step=31500 Epoch=153.5] | Loss=0.00838 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.351 | L2-Norm(final)=11.039 | 4566.6 samples/s | 71.4 steps/s
[Step=31550 Epoch=153.7] | Loss=0.00812 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.350 | L2-Norm(final)=11.043 | 2439.3 samples/s | 38.1 steps/s
[Step=31600 Epoch=154.0] | Loss=0.00791 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.349 | L2-Norm(final)=11.046 | 4507.3 samples/s | 70.4 steps/s
[Step=31650 Epoch=154.2] | Loss=0.00769 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.346 | L2-Norm(final)=11.049 | 4424.5 samples/s | 69.1 steps/s
[Step=31700 Epoch=154.5] | Loss=0.00759 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.343 | L2-Norm(final)=11.053 | 4439.5 samples/s | 69.4 steps/s
[Step=31750 Epoch=154.7] | Loss=0.00739 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.340 | L2-Norm(final)=11.055 | 2463.0 samples/s | 38.5 steps/s
[Step=31800 Epoch=154.9] | Loss=0.00721 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.336 | L2-Norm(final)=11.058 | 4476.9 samples/s | 70.0 steps/s
[Step=31850 Epoch=155.2] | Loss=0.00707 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.332 | L2-Norm(final)=11.061 | 4548.0 samples/s | 71.1 steps/s
[Step=31900 Epoch=155.4] | Loss=0.00699 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.327 | L2-Norm(final)=11.064 | 4394.5 samples/s | 68.7 steps/s
[Step=31950 Epoch=155.7] | Loss=0.00688 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.322 | L2-Norm(final)=11.067 | 2509.8 samples/s | 39.2 steps/s
[Step=32000 Epoch=155.9] | Loss=0.00678 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.317 | L2-Norm(final)=11.070 | 4283.1 samples/s | 66.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step32000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=146.3] | Loss=0.00515 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.205 | L2-Norm(final)=10.508 | 4963.2 samples/s | 77.6 steps/s
[Step=30050 Epoch=146.5] | Loss=0.00362 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.203 | L2-Norm(final)=10.520 | 4532.7 samples/s | 70.8 steps/s
[Step=30100 Epoch=146.8] | Loss=0.00364 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.200 | L2-Norm(final)=10.533 | 5086.7 samples/s | 79.5 steps/s
[Step=30150 Epoch=147.0] | Loss=0.00398 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.198 | L2-Norm(final)=10.545 | 5101.4 samples/s | 79.7 steps/s
[Step=30200 Epoch=147.3] | Loss=0.00377 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.196 | L2-Norm(final)=10.558 | 7636.4 samples/s | 119.3 steps/s
[Step=30250 Epoch=147.5] | Loss=0.00367 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.192 | L2-Norm(final)=10.570 | 2211.1 samples/s | 34.5 steps/s
[Step=30300 Epoch=147.8] | Loss=0.00361 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.189 | L2-Norm(final)=10.583 | 4975.2 samples/s | 77.7 steps/s
[Step=30350 Epoch=148.0] | Loss=0.00360 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.185 | L2-Norm(final)=10.595 | 4985.4 samples/s | 77.9 steps/s
[Step=30400 Epoch=148.2] | Loss=0.00349 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.180 | L2-Norm(final)=10.607 | 6890.2 samples/s | 107.7 steps/s
[Step=30450 Epoch=148.5] | Loss=0.00335 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.175 | L2-Norm(final)=10.619 | 2311.0 samples/s | 36.1 steps/s
[Step=30500 Epoch=148.7] | Loss=0.00341 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.171 | L2-Norm(final)=10.630 | 4888.7 samples/s | 76.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=148.7] | Loss=0.00005 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.120 | L2-Norm(final)=10.744 | 5444.3 samples/s | 85.1 steps/s
[Step=30550 Epoch=149.0] | Loss=0.00465 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.117 | L2-Norm(final)=10.753 | 4109.1 samples/s | 64.2 steps/s
[Step=30600 Epoch=149.2] | Loss=0.00607 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.126 | L2-Norm(final)=10.760 | 4454.3 samples/s | 69.6 steps/s
[Step=30650 Epoch=149.5] | Loss=0.00853 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.138 | L2-Norm(final)=10.766 | 4463.1 samples/s | 69.7 steps/s
[Step=30700 Epoch=149.7] | Loss=0.00934 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.156 | L2-Norm(final)=10.774 | 6423.5 samples/s | 100.4 steps/s
[Step=30750 Epoch=150.0] | Loss=0.00919 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.176 | L2-Norm(final)=10.782 | 2100.2 samples/s | 32.8 steps/s
[Step=30800 Epoch=150.2] | Loss=0.00908 | Reg=0.00408 | acc=0.9844 | L2-Norm=20.193 | L2-Norm(final)=10.791 | 4457.3 samples/s | 69.6 steps/s
[Step=30850 Epoch=150.4] | Loss=0.00965 | Reg=0.00408 | acc=1.0000 | L2-Norm=20.211 | L2-Norm(final)=10.799 | 4530.7 samples/s | 70.8 steps/s
[Step=30900 Epoch=150.7] | Loss=0.00982 | Reg=0.00409 | acc=1.0000 | L2-Norm=20.232 | L2-Norm(final)=10.806 | 5836.1 samples/s | 91.2 steps/s
[Step=30950 Epoch=150.9] | Loss=0.00988 | Reg=0.00410 | acc=1.0000 | L2-Norm=20.252 | L2-Norm(final)=10.813 | 2192.0 samples/s | 34.2 steps/s
[Step=31000 Epoch=151.2] | Loss=0.00979 | Reg=0.00411 | acc=1.0000 | L2-Norm=20.270 | L2-Norm(final)=10.820 | 4358.0 samples/s | 68.1 steps/s
[Step=31050 Epoch=151.4] | Loss=0.01012 | Reg=0.00412 | acc=1.0000 | L2-Norm=20.287 | L2-Norm(final)=10.826 | 4441.9 samples/s | 69.4 steps/s
[Step=31100 Epoch=151.7] | Loss=0.01022 | Reg=0.00412 | acc=0.9688 | L2-Norm=20.304 | L2-Norm(final)=10.831 | 5366.7 samples/s | 83.9 steps/s
[Step=31150 Epoch=151.9] | Loss=0.01006 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.320 | L2-Norm(final)=10.836 | 2266.5 samples/s | 35.4 steps/s
[Step=31200 Epoch=152.1] | Loss=0.00994 | Reg=0.00413 | acc=0.9844 | L2-Norm=20.333 | L2-Norm(final)=10.841 | 4495.4 samples/s | 70.2 steps/s
[Step=31250 Epoch=152.4] | Loss=0.00979 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.345 | L2-Norm(final)=10.846 | 4452.2 samples/s | 69.6 steps/s
[Step=31300 Epoch=152.6] | Loss=0.00961 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.357 | L2-Norm(final)=10.850 | 4975.8 samples/s | 77.7 steps/s
[Step=31350 Epoch=152.9] | Loss=0.00939 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.367 | L2-Norm(final)=10.854 | 2295.8 samples/s | 35.9 steps/s
[Step=31400 Epoch=153.1] | Loss=0.00903 | Reg=0.00415 | acc=0.9688 | L2-Norm=20.375 | L2-Norm(final)=10.858 | 4462.6 samples/s | 69.7 steps/s
[Step=31450 Epoch=153.4] | Loss=0.00878 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.382 | L2-Norm(final)=10.862 | 4490.8 samples/s | 70.2 steps/s
[Step=31500 Epoch=153.6] | Loss=0.00856 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.388 | L2-Norm(final)=10.866 | 4633.2 samples/s | 72.4 steps/s
[Step=31550 Epoch=153.9] | Loss=0.00845 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.393 | L2-Norm(final)=10.869 | 2429.2 samples/s | 38.0 steps/s
[Step=31600 Epoch=154.1] | Loss=0.00826 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.397 | L2-Norm(final)=10.873 | 4440.3 samples/s | 69.4 steps/s
[Step=31650 Epoch=154.3] | Loss=0.00803 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.400 | L2-Norm(final)=10.876 | 4495.7 samples/s | 70.2 steps/s
[Step=31700 Epoch=154.6] | Loss=0.00782 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.402 | L2-Norm(final)=10.879 | 4462.8 samples/s | 69.7 steps/s
[Step=31750 Epoch=154.8] | Loss=0.00760 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.403 | L2-Norm(final)=10.882 | 2425.3 samples/s | 37.9 steps/s
[Step=31800 Epoch=155.1] | Loss=0.00751 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.403 | L2-Norm(final)=10.885 | 4476.8 samples/s | 69.9 steps/s
[Step=31850 Epoch=155.3] | Loss=0.00734 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.403 | L2-Norm(final)=10.888 | 4476.1 samples/s | 69.9 steps/s
[Step=31900 Epoch=155.6] | Loss=0.00719 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.402 | L2-Norm(final)=10.891 | 4476.8 samples/s | 69.9 steps/s
[Step=31950 Epoch=155.8] | Loss=0.00703 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.401 | L2-Norm(final)=10.893 | 2519.1 samples/s | 39.4 steps/s
[Step=32000 Epoch=156.0] | Loss=0.00688 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.399 | L2-Norm(final)=10.896 | 4307.9 samples/s | 67.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step32000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=147.1] | Loss=0.00235 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.920 | L2-Norm(final)=10.537 | 5081.6 samples/s | 79.4 steps/s
[Step=30050 Epoch=147.4] | Loss=0.00397 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.919 | L2-Norm(final)=10.548 | 4560.5 samples/s | 71.3 steps/s
[Step=30100 Epoch=147.6] | Loss=0.00372 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.915 | L2-Norm(final)=10.562 | 5054.4 samples/s | 79.0 steps/s
[Step=30150 Epoch=147.9] | Loss=0.00359 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.911 | L2-Norm(final)=10.575 | 4972.5 samples/s | 77.7 steps/s
[Step=30200 Epoch=148.1] | Loss=0.00355 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.906 | L2-Norm(final)=10.587 | 8039.6 samples/s | 125.6 steps/s
[Step=30250 Epoch=148.3] | Loss=0.00340 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.902 | L2-Norm(final)=10.601 | 2199.4 samples/s | 34.4 steps/s
[Step=30300 Epoch=148.6] | Loss=0.00346 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.897 | L2-Norm(final)=10.613 | 5018.8 samples/s | 78.4 steps/s
[Step=30350 Epoch=148.8] | Loss=0.00333 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.891 | L2-Norm(final)=10.626 | 5060.6 samples/s | 79.1 steps/s
[Step=30400 Epoch=149.1] | Loss=0.00323 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.886 | L2-Norm(final)=10.638 | 7274.7 samples/s | 113.7 steps/s
[Step=30450 Epoch=149.3] | Loss=0.00317 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.880 | L2-Norm(final)=10.650 | 2208.8 samples/s | 34.5 steps/s
[Step=30500 Epoch=149.6] | Loss=0.00308 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.874 | L2-Norm(final)=10.662 | 5052.2 samples/s | 78.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=149.6] | Loss=0.00065 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.820 | L2-Norm(final)=10.779 | 5427.3 samples/s | 84.8 steps/s
[Step=30550 Epoch=149.8] | Loss=0.00347 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.819 | L2-Norm(final)=10.792 | 4084.7 samples/s | 63.8 steps/s
[Step=30600 Epoch=150.1] | Loss=0.00991 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.840 | L2-Norm(final)=10.798 | 4411.2 samples/s | 68.9 steps/s
[Step=30650 Epoch=150.3] | Loss=0.01175 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.873 | L2-Norm(final)=10.804 | 4490.2 samples/s | 70.2 steps/s
[Step=30700 Epoch=150.5] | Loss=0.01290 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.908 | L2-Norm(final)=10.809 | 6572.9 samples/s | 102.7 steps/s
[Step=30750 Epoch=150.8] | Loss=0.01250 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.938 | L2-Norm(final)=10.812 | 2051.4 samples/s | 32.1 steps/s
[Step=30800 Epoch=151.0] | Loss=0.01215 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.962 | L2-Norm(final)=10.816 | 4529.4 samples/s | 70.8 steps/s
[Step=30850 Epoch=151.3] | Loss=0.01221 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.982 | L2-Norm(final)=10.821 | 4379.4 samples/s | 68.4 steps/s
[Step=30900 Epoch=151.5] | Loss=0.01201 | Reg=0.00400 | acc=1.0000 | L2-Norm=20.001 | L2-Norm(final)=10.826 | 6253.1 samples/s | 97.7 steps/s
[Step=30950 Epoch=151.8] | Loss=0.01204 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.019 | L2-Norm(final)=10.830 | 2132.9 samples/s | 33.3 steps/s
[Step=31000 Epoch=152.0] | Loss=0.01201 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.036 | L2-Norm(final)=10.835 | 4379.7 samples/s | 68.4 steps/s
[Step=31050 Epoch=152.3] | Loss=0.01138 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.051 | L2-Norm(final)=10.839 | 4456.5 samples/s | 69.6 steps/s
[Step=31100 Epoch=152.5] | Loss=0.01131 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.064 | L2-Norm(final)=10.844 | 5891.3 samples/s | 92.1 steps/s
[Step=31150 Epoch=152.8] | Loss=0.01089 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.076 | L2-Norm(final)=10.848 | 2148.8 samples/s | 33.6 steps/s
[Step=31200 Epoch=153.0] | Loss=0.01049 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.086 | L2-Norm(final)=10.852 | 4363.9 samples/s | 68.2 steps/s
[Step=31250 Epoch=153.2] | Loss=0.01022 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.095 | L2-Norm(final)=10.856 | 4528.2 samples/s | 70.8 steps/s
[Step=31300 Epoch=153.5] | Loss=0.00993 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.102 | L2-Norm(final)=10.860 | 5429.9 samples/s | 84.8 steps/s
[Step=31350 Epoch=153.7] | Loss=0.00962 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.108 | L2-Norm(final)=10.864 | 2217.0 samples/s | 34.6 steps/s
[Step=31400 Epoch=154.0] | Loss=0.00948 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.112 | L2-Norm(final)=10.868 | 4527.1 samples/s | 70.7 steps/s
[Step=31450 Epoch=154.2] | Loss=0.00920 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.116 | L2-Norm(final)=10.871 | 4451.1 samples/s | 69.5 steps/s
[Step=31500 Epoch=154.5] | Loss=0.00900 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.119 | L2-Norm(final)=10.874 | 5053.5 samples/s | 79.0 steps/s
[Step=31550 Epoch=154.7] | Loss=0.00879 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.121 | L2-Norm(final)=10.877 | 2275.1 samples/s | 35.5 steps/s
[Step=31600 Epoch=155.0] | Loss=0.00861 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.122 | L2-Norm(final)=10.880 | 4488.4 samples/s | 70.1 steps/s
[Step=31650 Epoch=155.2] | Loss=0.00842 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.122 | L2-Norm(final)=10.882 | 4466.3 samples/s | 69.8 steps/s
[Step=31700 Epoch=155.5] | Loss=0.00818 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.122 | L2-Norm(final)=10.885 | 4860.5 samples/s | 75.9 steps/s
[Step=31750 Epoch=155.7] | Loss=0.00791 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.121 | L2-Norm(final)=10.887 | 2343.3 samples/s | 36.6 steps/s
[Step=31800 Epoch=155.9] | Loss=0.00770 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.119 | L2-Norm(final)=10.890 | 4370.8 samples/s | 68.3 steps/s
[Step=31850 Epoch=156.2] | Loss=0.00756 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.117 | L2-Norm(final)=10.892 | 4484.6 samples/s | 70.1 steps/s
[Step=31900 Epoch=156.4] | Loss=0.00746 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.114 | L2-Norm(final)=10.894 | 4654.5 samples/s | 72.7 steps/s
[Step=31950 Epoch=156.7] | Loss=0.00731 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.111 | L2-Norm(final)=10.896 | 2386.5 samples/s | 37.3 steps/s
[Step=32000 Epoch=156.9] | Loss=0.00724 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.107 | L2-Norm(final)=10.898 | 4481.5 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step32000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=284.3] | Loss=0.00040 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.120 | L2-Norm(final)=6.112 | 5573.2 samples/s | 87.1 steps/s
[Step=30050 Epoch=284.7] | Loss=0.00034 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=6.163 | 4023.7 samples/s | 62.9 steps/s
[Step=30100 Epoch=285.2] | Loss=0.00081 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.235 | L2-Norm(final)=6.195 | 7329.5 samples/s | 114.5 steps/s
[Step=30150 Epoch=285.7] | Loss=0.00058 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.279 | L2-Norm(final)=6.217 | 2139.9 samples/s | 33.4 steps/s
[Step=30200 Epoch=286.2] | Loss=0.00045 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.302 | L2-Norm(final)=6.230 | 6247.0 samples/s | 97.6 steps/s
[Step=30250 Epoch=286.6] | Loss=0.00037 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.315 | L2-Norm(final)=6.241 | 2252.9 samples/s | 35.2 steps/s
[Step=30300 Epoch=287.1] | Loss=0.00031 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.323 | L2-Norm(final)=6.249 | 5569.6 samples/s | 87.0 steps/s
[Step=30350 Epoch=287.6] | Loss=0.00027 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.328 | L2-Norm(final)=6.256 | 2322.2 samples/s | 36.3 steps/s
[Step=30400 Epoch=288.1] | Loss=0.00024 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=6.262 | 5357.2 samples/s | 83.7 steps/s
[Step=30450 Epoch=288.5] | Loss=0.00021 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.333 | L2-Norm(final)=6.267 | 2402.9 samples/s | 37.5 steps/s
[Step=30500 Epoch=289.0] | Loss=0.00019 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.335 | L2-Norm(final)=6.272 | 4842.6 samples/s | 75.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=289.0] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.342 | L2-Norm(final)=6.318 | 5106.7 samples/s | 79.8 steps/s
[Step=30550 Epoch=289.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.308 | L2-Norm(final)=6.321 | 3902.6 samples/s | 61.0 steps/s
[Step=30600 Epoch=290.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.264 | L2-Norm(final)=6.324 | 6204.3 samples/s | 96.9 steps/s
[Step=30650 Epoch=290.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=6.325 | 2028.2 samples/s | 31.7 steps/s
[Step=30700 Epoch=290.9] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.172 | L2-Norm(final)=6.326 | 5491.7 samples/s | 85.8 steps/s
[Step=30750 Epoch=291.4] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.125 | L2-Norm(final)=6.327 | 2058.3 samples/s | 32.2 steps/s
[Step=30800 Epoch=291.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=6.328 | 5082.8 samples/s | 79.4 steps/s
[Step=30850 Epoch=292.3] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.031 | L2-Norm(final)=6.328 | 2196.7 samples/s | 34.3 steps/s
[Step=30900 Epoch=292.8] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.984 | L2-Norm(final)=6.328 | 4716.7 samples/s | 73.7 steps/s
[Step=30950 Epoch=293.3] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.938 | L2-Norm(final)=6.329 | 2290.0 samples/s | 35.8 steps/s
[Step=31000 Epoch=293.8] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.891 | L2-Norm(final)=6.329 | 4214.8 samples/s | 65.9 steps/s
[Step=31050 Epoch=294.2] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.845 | L2-Norm(final)=6.330 | 2369.1 samples/s | 37.0 steps/s
[Step=31100 Epoch=294.7] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.800 | L2-Norm(final)=6.330 | 4146.3 samples/s | 64.8 steps/s
[Step=31150 Epoch=295.2] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.754 | L2-Norm(final)=6.330 | 2395.2 samples/s | 37.4 steps/s
[Step=31200 Epoch=295.6] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.709 | L2-Norm(final)=6.331 | 4314.0 samples/s | 67.4 steps/s
[Step=31250 Epoch=296.1] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.664 | L2-Norm(final)=6.331 | 2348.7 samples/s | 36.7 steps/s
[Step=31300 Epoch=296.6] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.619 | L2-Norm(final)=6.332 | 4115.6 samples/s | 64.3 steps/s
[Step=31350 Epoch=297.1] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.574 | L2-Norm(final)=6.332 | 2481.5 samples/s | 38.8 steps/s
[Step=31400 Epoch=297.5] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.529 | L2-Norm(final)=6.332 | 3918.7 samples/s | 61.2 steps/s
[Step=31450 Epoch=298.0] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.485 | L2-Norm(final)=6.333 | 6490.4 samples/s | 101.4 steps/s
[Step=31500 Epoch=298.5] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=6.333 | 2002.9 samples/s | 31.3 steps/s
[Step=31550 Epoch=299.0] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.396 | L2-Norm(final)=6.334 | 5858.1 samples/s | 91.5 steps/s
[Step=31600 Epoch=299.4] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.352 | L2-Norm(final)=6.335 | 2075.5 samples/s | 32.4 steps/s
[Step=31650 Epoch=299.9] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.308 | L2-Norm(final)=6.335 | 5228.1 samples/s | 81.7 steps/s
[Step=31700 Epoch=300.4] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.264 | L2-Norm(final)=6.336 | 2135.3 samples/s | 33.4 steps/s
[Step=31750 Epoch=300.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.220 | L2-Norm(final)=6.336 | 4848.0 samples/s | 75.8 steps/s
[Step=31800 Epoch=301.3] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.176 | L2-Norm(final)=6.337 | 2219.3 samples/s | 34.7 steps/s
[Step=31850 Epoch=301.8] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.132 | L2-Norm(final)=6.338 | 4461.6 samples/s | 69.7 steps/s
[Step=31900 Epoch=302.3] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=6.338 | 2274.4 samples/s | 35.5 steps/s
[Step=31950 Epoch=302.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.045 | L2-Norm(final)=6.339 | 4198.2 samples/s | 65.6 steps/s
[Step=32000 Epoch=303.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=6.340 | 2413.0 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step32000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=285.4] | Loss=0.00619 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.418 | L2-Norm(final)=6.570 | 5199.0 samples/s | 81.2 steps/s
[Step=30050 Epoch=285.9] | Loss=0.00066 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.436 | L2-Norm(final)=6.578 | 4184.6 samples/s | 65.4 steps/s
[Step=30100 Epoch=286.3] | Loss=0.00043 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.444 | L2-Norm(final)=6.585 | 7325.1 samples/s | 114.5 steps/s
[Step=30150 Epoch=286.8] | Loss=0.00031 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.448 | L2-Norm(final)=6.590 | 2126.8 samples/s | 33.2 steps/s
[Step=30200 Epoch=287.3] | Loss=0.00026 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.450 | L2-Norm(final)=6.595 | 6573.5 samples/s | 102.7 steps/s
[Step=30250 Epoch=287.8] | Loss=0.00022 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.451 | L2-Norm(final)=6.600 | 2225.9 samples/s | 34.8 steps/s
[Step=30300 Epoch=288.2] | Loss=0.00019 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.452 | L2-Norm(final)=6.604 | 5996.6 samples/s | 93.7 steps/s
[Step=30350 Epoch=288.7] | Loss=0.00017 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=6.608 | 2292.2 samples/s | 35.8 steps/s
[Step=30400 Epoch=289.2] | Loss=0.00016 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=6.612 | 5314.1 samples/s | 83.0 steps/s
[Step=30450 Epoch=289.7] | Loss=0.00014 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=6.616 | 2370.2 samples/s | 37.0 steps/s
[Step=30500 Epoch=290.1] | Loss=0.00013 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=6.620 | 5032.0 samples/s | 78.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=290.1] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.452 | L2-Norm(final)=6.655 | 5665.8 samples/s | 88.5 steps/s
[Step=30550 Epoch=290.6] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.448 | L2-Norm(final)=6.658 | 3624.7 samples/s | 56.6 steps/s
[Step=30600 Epoch=291.1] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.443 | L2-Norm(final)=6.660 | 6343.0 samples/s | 99.1 steps/s
[Step=30650 Epoch=291.6] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.438 | L2-Norm(final)=6.663 | 2039.8 samples/s | 31.9 steps/s
[Step=30700 Epoch=292.0] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.431 | L2-Norm(final)=6.664 | 5601.6 samples/s | 87.5 steps/s
[Step=30750 Epoch=292.5] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.425 | L2-Norm(final)=6.666 | 2087.8 samples/s | 32.6 steps/s
[Step=30800 Epoch=293.0] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.418 | L2-Norm(final)=6.667 | 5066.7 samples/s | 79.2 steps/s
[Step=30850 Epoch=293.5] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=6.668 | 2161.0 samples/s | 33.8 steps/s
[Step=30900 Epoch=293.9] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.405 | L2-Norm(final)=6.670 | 4748.3 samples/s | 74.2 steps/s
[Step=30950 Epoch=294.4] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.398 | L2-Norm(final)=6.671 | 2294.2 samples/s | 35.8 steps/s
[Step=31000 Epoch=294.9] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.391 | L2-Norm(final)=6.672 | 4326.5 samples/s | 67.6 steps/s
[Step=31050 Epoch=295.4] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.383 | L2-Norm(final)=6.673 | 2333.4 samples/s | 36.5 steps/s
[Step=31100 Epoch=295.8] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=6.673 | 4295.7 samples/s | 67.1 steps/s
[Step=31150 Epoch=296.3] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.369 | L2-Norm(final)=6.674 | 2416.0 samples/s | 37.8 steps/s
[Step=31200 Epoch=296.8] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.362 | L2-Norm(final)=6.675 | 4231.2 samples/s | 66.1 steps/s
[Step=31250 Epoch=297.3] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.354 | L2-Norm(final)=6.676 | 2364.2 samples/s | 36.9 steps/s
[Step=31300 Epoch=297.7] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.346 | L2-Norm(final)=6.677 | 4204.7 samples/s | 65.7 steps/s
[Step=31350 Epoch=298.2] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.339 | L2-Norm(final)=6.678 | 2549.7 samples/s | 39.8 steps/s
[Step=31400 Epoch=298.7] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=6.679 | 3959.9 samples/s | 61.9 steps/s
[Step=31450 Epoch=299.2] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.323 | L2-Norm(final)=6.679 | 6561.8 samples/s | 102.5 steps/s
[Step=31500 Epoch=299.6] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.315 | L2-Norm(final)=6.680 | 2007.2 samples/s | 31.4 steps/s
[Step=31550 Epoch=300.1] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.307 | L2-Norm(final)=6.681 | 5703.8 samples/s | 89.1 steps/s
[Step=31600 Epoch=300.6] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.299 | L2-Norm(final)=6.682 | 2061.4 samples/s | 32.2 steps/s
[Step=31650 Epoch=301.1] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.291 | L2-Norm(final)=6.682 | 5267.8 samples/s | 82.3 steps/s
[Step=31700 Epoch=301.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.283 | L2-Norm(final)=6.683 | 2135.3 samples/s | 33.4 steps/s
[Step=31750 Epoch=302.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.275 | L2-Norm(final)=6.684 | 4890.6 samples/s | 76.4 steps/s
[Step=31800 Epoch=302.5] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.266 | L2-Norm(final)=6.685 | 2221.8 samples/s | 34.7 steps/s
[Step=31850 Epoch=303.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=6.685 | 4507.9 samples/s | 70.4 steps/s
[Step=31900 Epoch=303.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.249 | L2-Norm(final)=6.686 | 2326.4 samples/s | 36.3 steps/s
[Step=31950 Epoch=303.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.687 | 4179.4 samples/s | 65.3 steps/s
[Step=32000 Epoch=304.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=6.688 | 2438.8 samples/s | 38.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step32000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=286.5] | Loss=0.00038 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.273 | L2-Norm(final)=6.603 | 5201.9 samples/s | 81.3 steps/s
[Step=30050 Epoch=287.0] | Loss=0.00041 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.298 | L2-Norm(final)=6.621 | 4114.4 samples/s | 64.3 steps/s
[Step=30100 Epoch=287.4] | Loss=0.00065 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.344 | L2-Norm(final)=6.648 | 7515.7 samples/s | 117.4 steps/s
[Step=30150 Epoch=287.9] | Loss=0.00047 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.383 | L2-Norm(final)=6.668 | 2100.8 samples/s | 32.8 steps/s
[Step=30200 Epoch=288.4] | Loss=0.00038 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.404 | L2-Norm(final)=6.682 | 6741.5 samples/s | 105.3 steps/s
[Step=30250 Epoch=288.9] | Loss=0.00031 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.419 | L2-Norm(final)=6.694 | 2181.8 samples/s | 34.1 steps/s
[Step=30300 Epoch=289.3] | Loss=0.00027 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.428 | L2-Norm(final)=6.704 | 5907.5 samples/s | 92.3 steps/s
[Step=30350 Epoch=289.8] | Loss=0.00023 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.434 | L2-Norm(final)=6.712 | 2227.6 samples/s | 34.8 steps/s
[Step=30400 Epoch=290.3] | Loss=0.00021 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.438 | L2-Norm(final)=6.719 | 5744.0 samples/s | 89.7 steps/s
[Step=30450 Epoch=290.8] | Loss=0.00019 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.441 | L2-Norm(final)=6.726 | 2337.6 samples/s | 36.5 steps/s
[Step=30500 Epoch=291.3] | Loss=0.00017 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.443 | L2-Norm(final)=6.733 | 5079.8 samples/s | 79.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=291.3] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.459 | L2-Norm(final)=6.804 | 5383.0 samples/s | 84.1 steps/s
[Step=30550 Epoch=291.7] | Loss=0.00483 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.466 | L2-Norm(final)=6.807 | 3850.4 samples/s | 60.2 steps/s
[Step=30600 Epoch=292.2] | Loss=0.01057 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.630 | L2-Norm(final)=6.767 | 6205.8 samples/s | 97.0 steps/s
[Step=30650 Epoch=292.7] | Loss=0.00759 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.724 | L2-Norm(final)=6.740 | 2017.0 samples/s | 31.5 steps/s
[Step=30700 Epoch=293.2] | Loss=0.00574 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.773 | L2-Norm(final)=6.728 | 5771.5 samples/s | 90.2 steps/s
[Step=30750 Epoch=293.6] | Loss=0.00460 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.802 | L2-Norm(final)=6.721 | 2040.3 samples/s | 31.9 steps/s
[Step=30800 Epoch=294.1] | Loss=0.00384 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.820 | L2-Norm(final)=6.717 | 5259.0 samples/s | 82.2 steps/s
[Step=30850 Epoch=294.6] | Loss=0.00329 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.832 | L2-Norm(final)=6.714 | 2161.4 samples/s | 33.8 steps/s
[Step=30900 Epoch=295.1] | Loss=0.00288 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.840 | L2-Norm(final)=6.712 | 4936.9 samples/s | 77.1 steps/s
[Step=30950 Epoch=295.6] | Loss=0.00257 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.846 | L2-Norm(final)=6.710 | 2218.8 samples/s | 34.7 steps/s
[Step=31000 Epoch=296.0] | Loss=0.00231 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.850 | L2-Norm(final)=6.709 | 4517.9 samples/s | 70.6 steps/s
[Step=31050 Epoch=296.5] | Loss=0.00210 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.852 | L2-Norm(final)=6.708 | 2257.3 samples/s | 35.3 steps/s
[Step=31100 Epoch=297.0] | Loss=0.00193 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.854 | L2-Norm(final)=6.708 | 4316.1 samples/s | 67.4 steps/s
[Step=31150 Epoch=297.5] | Loss=0.00178 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.855 | L2-Norm(final)=6.707 | 2369.5 samples/s | 37.0 steps/s
[Step=31200 Epoch=297.9] | Loss=0.00165 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.855 | L2-Norm(final)=6.707 | 4187.5 samples/s | 65.4 steps/s
[Step=31250 Epoch=298.4] | Loss=0.00154 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.855 | L2-Norm(final)=6.707 | 2418.4 samples/s | 37.8 steps/s
[Step=31300 Epoch=298.9] | Loss=0.00145 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.854 | L2-Norm(final)=6.707 | 4242.8 samples/s | 66.3 steps/s
[Step=31350 Epoch=299.4] | Loss=0.00136 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.853 | L2-Norm(final)=6.706 | 2355.5 samples/s | 36.8 steps/s
[Step=31400 Epoch=299.9] | Loss=0.00129 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.852 | L2-Norm(final)=6.706 | 4191.4 samples/s | 65.5 steps/s
[Step=31450 Epoch=300.3] | Loss=0.00122 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.850 | L2-Norm(final)=6.706 | 2383.0 samples/s | 37.2 steps/s
[Step=31500 Epoch=300.8] | Loss=0.00116 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.848 | L2-Norm(final)=6.706 | 4175.1 samples/s | 65.2 steps/s
[Step=31550 Epoch=301.3] | Loss=0.00110 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.846 | L2-Norm(final)=6.706 | 7048.1 samples/s | 110.1 steps/s
[Step=31600 Epoch=301.8] | Loss=0.00105 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.844 | L2-Norm(final)=6.706 | 1947.2 samples/s | 30.4 steps/s
[Step=31650 Epoch=302.2] | Loss=0.00101 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.842 | L2-Norm(final)=6.706 | 6344.2 samples/s | 99.1 steps/s
[Step=31700 Epoch=302.7] | Loss=0.00096 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.839 | L2-Norm(final)=6.706 | 1971.7 samples/s | 30.8 steps/s
[Step=31750 Epoch=303.2] | Loss=0.00093 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.836 | L2-Norm(final)=6.706 | 5877.0 samples/s | 91.8 steps/s
[Step=31800 Epoch=303.7] | Loss=0.00089 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.833 | L2-Norm(final)=6.706 | 2047.1 samples/s | 32.0 steps/s
[Step=31850 Epoch=304.1] | Loss=0.00086 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.830 | L2-Norm(final)=6.706 | 5378.8 samples/s | 84.0 steps/s
[Step=31900 Epoch=304.6] | Loss=0.00083 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.827 | L2-Norm(final)=6.706 | 2140.2 samples/s | 33.4 steps/s
[Step=31950 Epoch=305.1] | Loss=0.00080 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.824 | L2-Norm(final)=6.706 | 4815.5 samples/s | 75.2 steps/s
[Step=32000 Epoch=305.6] | Loss=0.00077 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.820 | L2-Norm(final)=6.706 | 2191.2 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step32000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=282.7] | Loss=0.00006 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.225 | L2-Norm(final)=6.356 | 4831.6 samples/s | 75.5 steps/s
[Step=30050 Epoch=283.2] | Loss=0.00172 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.275 | L2-Norm(final)=6.389 | 4588.9 samples/s | 71.7 steps/s
[Step=30100 Epoch=283.6] | Loss=0.00243 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.373 | L2-Norm(final)=6.402 | 7264.2 samples/s | 113.5 steps/s
[Step=30150 Epoch=284.1] | Loss=0.00185 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.431 | L2-Norm(final)=6.408 | 2147.6 samples/s | 33.6 steps/s
[Step=30200 Epoch=284.6] | Loss=0.00148 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.464 | L2-Norm(final)=6.415 | 6326.0 samples/s | 98.8 steps/s
[Step=30250 Epoch=285.0] | Loss=0.00121 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.486 | L2-Norm(final)=6.422 | 2180.6 samples/s | 34.1 steps/s
[Step=30300 Epoch=285.5] | Loss=0.00102 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.501 | L2-Norm(final)=6.428 | 5646.9 samples/s | 88.2 steps/s
[Step=30350 Epoch=286.0] | Loss=0.00088 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.512 | L2-Norm(final)=6.433 | 2336.9 samples/s | 36.5 steps/s
[Step=30400 Epoch=286.5] | Loss=0.00078 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.519 | L2-Norm(final)=6.437 | 5056.7 samples/s | 79.0 steps/s
[Step=30450 Epoch=286.9] | Loss=0.00070 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.525 | L2-Norm(final)=6.442 | 2512.3 samples/s | 39.3 steps/s
[Step=30500 Epoch=287.4] | Loss=0.00063 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.529 | L2-Norm(final)=6.446 | 4758.6 samples/s | 74.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=287.4] | Loss=0.00004 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.567 | L2-Norm(final)=6.484 | 5535.5 samples/s | 86.5 steps/s
[Step=30550 Epoch=287.9] | Loss=0.00927 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.652 | L2-Norm(final)=6.470 | 3665.7 samples/s | 57.3 steps/s
[Step=30600 Epoch=288.3] | Loss=0.00685 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.783 | L2-Norm(final)=6.457 | 6139.1 samples/s | 95.9 steps/s
[Step=30650 Epoch=288.8] | Loss=0.00532 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.843 | L2-Norm(final)=6.452 | 2031.7 samples/s | 31.7 steps/s
[Step=30700 Epoch=289.3] | Loss=0.00412 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.874 | L2-Norm(final)=6.451 | 5520.3 samples/s | 86.3 steps/s
[Step=30750 Epoch=289.8] | Loss=0.00331 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.892 | L2-Norm(final)=6.451 | 2138.6 samples/s | 33.4 steps/s
[Step=30800 Epoch=290.2] | Loss=0.00276 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.903 | L2-Norm(final)=6.452 | 4736.5 samples/s | 74.0 steps/s
[Step=30850 Epoch=290.7] | Loss=0.00237 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.909 | L2-Norm(final)=6.453 | 2237.7 samples/s | 35.0 steps/s
[Step=30900 Epoch=291.2] | Loss=0.00208 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.913 | L2-Norm(final)=6.454 | 4352.9 samples/s | 68.0 steps/s
[Step=30950 Epoch=291.6] | Loss=0.00185 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.915 | L2-Norm(final)=6.454 | 2350.9 samples/s | 36.7 steps/s
[Step=31000 Epoch=292.1] | Loss=0.00166 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.916 | L2-Norm(final)=6.455 | 4254.0 samples/s | 66.5 steps/s
[Step=31050 Epoch=292.6] | Loss=0.00151 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.916 | L2-Norm(final)=6.456 | 2388.4 samples/s | 37.3 steps/s
[Step=31100 Epoch=293.1] | Loss=0.00139 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.915 | L2-Norm(final)=6.457 | 4209.4 samples/s | 65.8 steps/s
[Step=31150 Epoch=293.5] | Loss=0.00128 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.914 | L2-Norm(final)=6.458 | 2377.0 samples/s | 37.1 steps/s
[Step=31200 Epoch=294.0] | Loss=0.00119 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.912 | L2-Norm(final)=6.459 | 4329.6 samples/s | 67.7 steps/s
[Step=31250 Epoch=294.5] | Loss=0.00111 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.910 | L2-Norm(final)=6.460 | 2630.8 samples/s | 41.1 steps/s
[Step=31300 Epoch=294.9] | Loss=0.00104 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.907 | L2-Norm(final)=6.461 | 3669.2 samples/s | 57.3 steps/s
[Step=31350 Epoch=295.4] | Loss=0.00098 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.904 | L2-Norm(final)=6.462 | 6295.7 samples/s | 98.4 steps/s
[Step=31400 Epoch=295.9] | Loss=0.00093 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.901 | L2-Norm(final)=6.463 | 2033.6 samples/s | 31.8 steps/s
[Step=31450 Epoch=296.3] | Loss=0.00088 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.898 | L2-Norm(final)=6.464 | 5388.3 samples/s | 84.2 steps/s
[Step=31500 Epoch=296.8] | Loss=0.00084 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.894 | L2-Norm(final)=6.465 | 2120.9 samples/s | 33.1 steps/s
[Step=31550 Epoch=297.3] | Loss=0.00080 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.890 | L2-Norm(final)=6.466 | 4950.8 samples/s | 77.4 steps/s
[Step=31600 Epoch=297.8] | Loss=0.00076 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.886 | L2-Norm(final)=6.467 | 2196.1 samples/s | 34.3 steps/s
[Step=31650 Epoch=298.2] | Loss=0.00073 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.882 | L2-Norm(final)=6.468 | 4566.3 samples/s | 71.3 steps/s
[Step=31700 Epoch=298.7] | Loss=0.00070 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.878 | L2-Norm(final)=6.469 | 2290.1 samples/s | 35.8 steps/s
[Step=31750 Epoch=299.2] | Loss=0.00067 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.874 | L2-Norm(final)=6.470 | 4255.3 samples/s | 66.5 steps/s
[Step=31800 Epoch=299.6] | Loss=0.00064 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.870 | L2-Norm(final)=6.471 | 2433.3 samples/s | 38.0 steps/s
[Step=31850 Epoch=300.1] | Loss=0.00062 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.865 | L2-Norm(final)=6.472 | 4194.1 samples/s | 65.5 steps/s
[Step=31900 Epoch=300.6] | Loss=0.00060 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.861 | L2-Norm(final)=6.473 | 2346.6 samples/s | 36.7 steps/s
[Step=31950 Epoch=301.1] | Loss=0.00058 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.856 | L2-Norm(final)=6.474 | 4243.2 samples/s | 66.3 steps/s
[Step=32000 Epoch=301.5] | Loss=0.00056 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.852 | L2-Norm(final)=6.475 | 2510.2 samples/s | 39.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step32000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=285.9] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.544 | L2-Norm(final)=7.401 | 5175.2 samples/s | 80.9 steps/s
[Step=30050 Epoch=286.4] | Loss=0.00046 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.556 | L2-Norm(final)=7.403 | 4170.5 samples/s | 65.2 steps/s
[Step=30100 Epoch=286.9] | Loss=0.00033 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.569 | L2-Norm(final)=7.407 | 7541.7 samples/s | 117.8 steps/s
[Step=30150 Epoch=287.4] | Loss=0.00025 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.575 | L2-Norm(final)=7.411 | 2112.6 samples/s | 33.0 steps/s
[Step=30200 Epoch=287.8] | Loss=0.00021 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.577 | L2-Norm(final)=7.414 | 6807.0 samples/s | 106.4 steps/s
[Step=30250 Epoch=288.3] | Loss=0.00018 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.579 | L2-Norm(final)=7.417 | 2184.0 samples/s | 34.1 steps/s
[Step=30300 Epoch=288.8] | Loss=0.00017 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.581 | L2-Norm(final)=7.420 | 6160.5 samples/s | 96.3 steps/s
[Step=30350 Epoch=289.3] | Loss=0.00015 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.582 | L2-Norm(final)=7.423 | 2265.8 samples/s | 35.4 steps/s
[Step=30400 Epoch=289.7] | Loss=0.00014 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.583 | L2-Norm(final)=7.426 | 5656.9 samples/s | 88.4 steps/s
[Step=30450 Epoch=290.2] | Loss=0.00013 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.583 | L2-Norm(final)=7.429 | 2377.3 samples/s | 37.1 steps/s
[Step=30500 Epoch=290.7] | Loss=0.00012 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.584 | L2-Norm(final)=7.431 | 5136.0 samples/s | 80.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=290.7] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.587 | L2-Norm(final)=7.456 | 5264.1 samples/s | 82.3 steps/s
[Step=30550 Epoch=291.2] | Loss=0.00004 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.584 | L2-Norm(final)=7.459 | 3806.6 samples/s | 59.5 steps/s
[Step=30600 Epoch=291.6] | Loss=0.00004 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.580 | L2-Norm(final)=7.461 | 6323.4 samples/s | 98.8 steps/s
[Step=30650 Epoch=292.1] | Loss=0.00003 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.575 | L2-Norm(final)=7.462 | 2007.0 samples/s | 31.4 steps/s
[Step=30700 Epoch=292.6] | Loss=0.00002 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.569 | L2-Norm(final)=7.463 | 5813.7 samples/s | 90.8 steps/s
[Step=30750 Epoch=293.1] | Loss=0.00002 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.563 | L2-Norm(final)=7.464 | 2058.3 samples/s | 32.2 steps/s
[Step=30800 Epoch=293.6] | Loss=0.00002 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.557 | L2-Norm(final)=7.465 | 5383.0 samples/s | 84.1 steps/s
[Step=30850 Epoch=294.0] | Loss=0.00002 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=7.465 | 2116.5 samples/s | 33.1 steps/s
[Step=30900 Epoch=294.5] | Loss=0.00002 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.544 | L2-Norm(final)=7.466 | 4972.1 samples/s | 77.7 steps/s
[Step=30950 Epoch=295.0] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.537 | L2-Norm(final)=7.467 | 2206.6 samples/s | 34.5 steps/s
[Step=31000 Epoch=295.5] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.531 | L2-Norm(final)=7.467 | 4591.4 samples/s | 71.7 steps/s
[Step=31050 Epoch=295.9] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.524 | L2-Norm(final)=7.468 | 2321.2 samples/s | 36.3 steps/s
[Step=31100 Epoch=296.4] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.517 | L2-Norm(final)=7.468 | 4216.6 samples/s | 65.9 steps/s
[Step=31150 Epoch=296.9] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.511 | L2-Norm(final)=7.469 | 2352.3 samples/s | 36.8 steps/s
[Step=31200 Epoch=297.4] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.504 | L2-Norm(final)=7.469 | 4253.3 samples/s | 66.5 steps/s
[Step=31250 Epoch=297.8] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.497 | L2-Norm(final)=7.470 | 2389.4 samples/s | 37.3 steps/s
[Step=31300 Epoch=298.3] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.489 | L2-Norm(final)=7.470 | 4208.9 samples/s | 65.8 steps/s
[Step=31350 Epoch=298.8] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.482 | L2-Norm(final)=7.470 | 2394.5 samples/s | 37.4 steps/s
[Step=31400 Epoch=299.3] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.475 | L2-Norm(final)=7.471 | 4269.6 samples/s | 66.7 steps/s
[Step=31450 Epoch=299.7] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.468 | L2-Norm(final)=7.471 | 2394.8 samples/s | 37.4 steps/s
[Step=31500 Epoch=300.2] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.460 | L2-Norm(final)=7.472 | 4281.4 samples/s | 66.9 steps/s
[Step=31550 Epoch=300.7] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=7.472 | 6847.1 samples/s | 107.0 steps/s
[Step=31600 Epoch=301.2] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.445 | L2-Norm(final)=7.472 | 1961.4 samples/s | 30.6 steps/s
[Step=31650 Epoch=301.7] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.437 | L2-Norm(final)=7.473 | 6337.1 samples/s | 99.0 steps/s
[Step=31700 Epoch=302.1] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.430 | L2-Norm(final)=7.473 | 2009.4 samples/s | 31.4 steps/s
[Step=31750 Epoch=302.6] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.422 | L2-Norm(final)=7.474 | 5750.1 samples/s | 89.8 steps/s
[Step=31800 Epoch=303.1] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.414 | L2-Norm(final)=7.474 | 2062.8 samples/s | 32.2 steps/s
[Step=31850 Epoch=303.6] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.406 | L2-Norm(final)=7.475 | 5377.8 samples/s | 84.0 steps/s
[Step=31900 Epoch=304.0] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.398 | L2-Norm(final)=7.476 | 2129.9 samples/s | 33.3 steps/s
[Step=31950 Epoch=304.5] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.390 | L2-Norm(final)=7.476 | 4974.2 samples/s | 77.7 steps/s
[Step=32000 Epoch=305.0] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.381 | L2-Norm(final)=7.477 | 2202.5 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11612 | acc=0.9543 | tpr=0.9650 | fpr=0.0689 | 4618.7 samples/s | 18.0 steps/s
Avg test loss: 0.12001, Avg test acc: 0.95272, Avg tpr: 0.96386, Avg fpr: 0.07179, total FA: 560

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12674 | acc=0.9547 | tpr=0.9772 | fpr=0.0942 | 4775.5 samples/s | 18.7 steps/s
Avg test loss: 0.13067, Avg test acc: 0.95404, Avg tpr: 0.97610, Avg fpr: 0.09448, total FA: 737

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11812 | acc=0.9560 | tpr=0.9702 | fpr=0.0748 | 4907.2 samples/s | 19.2 steps/s
Avg test loss: 0.12216, Avg test acc: 0.95420, Avg tpr: 0.96847, Avg fpr: 0.07717, total FA: 602

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13363 | acc=0.9556 | tpr=0.9716 | fpr=0.0790 | 4901.6 samples/s | 19.1 steps/s
Avg test loss: 0.13605, Avg test acc: 0.95456, Avg tpr: 0.97103, Avg fpr: 0.08166, total FA: 637

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11005 | acc=0.9558 | tpr=0.9654 | fpr=0.0652 | 4864.8 samples/s | 19.0 steps/s
Avg test loss: 0.11410, Avg test acc: 0.95516, Avg tpr: 0.96550, Avg fpr: 0.06756, total FA: 527

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.20841 | acc=0.2991 | tpr=0.0063 | fpr=0.0649 | 4868.8 samples/s | 19.0 steps/s
Avg test loss: 5.21698, Avg test acc: 0.29770, Avg tpr: 0.00810, Avg fpr: 0.06538, total FA: 510

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.88793 | acc=0.2890 | tpr=0.0073 | fpr=0.0994 | 4912.6 samples/s | 19.2 steps/s
Avg test loss: 4.90671, Avg test acc: 0.28656, Avg tpr: 0.00711, Avg fpr: 0.09883, total FA: 771

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.88012 | acc=0.2968 | tpr=0.0122 | fpr=0.0852 | 4981.4 samples/s | 19.5 steps/s
Avg test loss: 5.89953, Avg test acc: 0.29377, Avg tpr: 0.01230, Avg fpr: 0.08717, total FA: 680

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.75907 | acc=0.3017 | tpr=0.0094 | fpr=0.0634 | 4634.7 samples/s | 18.1 steps/s
Avg test loss: 5.76812, Avg test acc: 0.29946, Avg tpr: 0.00903, Avg fpr: 0.06179, total FA: 482

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.67279 | acc=0.2986 | tpr=0.0327 | fpr=0.1241 | 4815.1 samples/s | 18.8 steps/s
Avg test loss: 5.68868, Avg test acc: 0.29522, Avg tpr: 0.03229, Avg fpr: 0.12652, total FA: 987

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.52612 | acc=0.0924 | tpr=0.6239 | fpr=0.9171 | 4780.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.51719 | acc=0.0929 | tpr=0.6098 | fpr=0.9167 | 7346.2 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.53792 | acc=0.0934 | tpr=0.6009 | fpr=0.9160 | 7750.0 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.54223 | acc=0.0932 | tpr=0.6044 | fpr=0.9161 | 7645.7 samples/s | 29.9 steps/s
[Step= 250] | Loss=5.54998 | acc=0.0936 | tpr=0.6044 | fpr=0.9157 | 8065.6 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.54944 | acc=0.0934 | tpr=0.6102 | fpr=0.9160 | 7914.5 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.54643 | acc=0.0936 | tpr=0.6111 | fpr=0.9158 | 7774.6 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.54377 | acc=0.0938 | tpr=0.6154 | fpr=0.9157 | 8108.7 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.54900 | acc=0.0939 | tpr=0.6154 | fpr=0.9156 | 7587.8 samples/s | 29.6 steps/s
[Step= 500] | Loss=5.55428 | acc=0.0937 | tpr=0.6163 | fpr=0.9157 | 8006.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.55607 | acc=0.0939 | tpr=0.6128 | fpr=0.9155 | 14155.6 samples/s | 55.3 steps/s
Avg test loss: 5.55736, Avg test acc: 0.09387, Avg tpr: 0.61331, Avg fpr: 0.91557, total FA: 127125

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.93030 | acc=0.0712 | tpr=0.5841 | fpr=0.9380 | 4880.2 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.90074 | acc=0.0737 | tpr=0.5842 | fpr=0.9359 | 6948.3 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.90601 | acc=0.0740 | tpr=0.5793 | fpr=0.9353 | 7573.6 samples/s | 29.6 steps/s
[Step= 200] | Loss=5.89494 | acc=0.0740 | tpr=0.5792 | fpr=0.9352 | 8101.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=5.90516 | acc=0.0744 | tpr=0.5773 | fpr=0.9348 | 8121.4 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.89822 | acc=0.0739 | tpr=0.5804 | fpr=0.9354 | 7845.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.89046 | acc=0.0745 | tpr=0.5848 | fpr=0.9347 | 7709.3 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.88453 | acc=0.0749 | tpr=0.5799 | fpr=0.9343 | 8251.1 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.88755 | acc=0.0749 | tpr=0.5769 | fpr=0.9342 | 7657.1 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.89191 | acc=0.0745 | tpr=0.5744 | fpr=0.9345 | 7579.2 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.89319 | acc=0.0743 | tpr=0.5734 | fpr=0.9348 | 15141.3 samples/s | 59.1 steps/s
Avg test loss: 5.89536, Avg test acc: 0.07419, Avg tpr: 0.57330, Avg fpr: 0.93489, total FA: 129807

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.05803 | acc=0.0773 | tpr=0.5487 | fpr=0.9312 | 4800.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.03558 | acc=0.0775 | tpr=0.5416 | fpr=0.9312 | 7314.1 samples/s | 28.6 steps/s
[Step= 150] | Loss=6.04161 | acc=0.0784 | tpr=0.5288 | fpr=0.9299 | 8128.2 samples/s | 31.8 steps/s
[Step= 200] | Loss=6.04056 | acc=0.0784 | tpr=0.5202 | fpr=0.9296 | 7529.7 samples/s | 29.4 steps/s
[Step= 250] | Loss=6.04662 | acc=0.0785 | tpr=0.5127 | fpr=0.9294 | 7995.7 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.04705 | acc=0.0780 | tpr=0.5149 | fpr=0.9299 | 7994.3 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.04067 | acc=0.0784 | tpr=0.5210 | fpr=0.9297 | 7536.5 samples/s | 29.4 steps/s
[Step= 400] | Loss=6.03536 | acc=0.0786 | tpr=0.5170 | fpr=0.9294 | 7849.4 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.03694 | acc=0.0786 | tpr=0.5204 | fpr=0.9295 | 8023.9 samples/s | 31.3 steps/s
[Step= 500] | Loss=6.03863 | acc=0.0783 | tpr=0.5194 | fpr=0.9297 | 7600.4 samples/s | 29.7 steps/s
[Step= 550] | Loss=6.03817 | acc=0.0784 | tpr=0.5169 | fpr=0.9296 | 15251.2 samples/s | 59.6 steps/s
Avg test loss: 6.03857, Avg test acc: 0.07831, Avg tpr: 0.51704, Avg fpr: 0.92966, total FA: 129082

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.92987 | acc=0.1027 | tpr=0.7035 | fpr=0.9081 | 4903.4 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.92292 | acc=0.1022 | tpr=0.6908 | fpr=0.9088 | 7040.3 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.92411 | acc=0.1034 | tpr=0.6873 | fpr=0.9074 | 7674.2 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.91179 | acc=0.1040 | tpr=0.6820 | fpr=0.9065 | 7933.9 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.92032 | acc=0.1042 | tpr=0.6803 | fpr=0.9063 | 7777.3 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.91611 | acc=0.1043 | tpr=0.6815 | fpr=0.9062 | 8035.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=5.90836 | acc=0.1048 | tpr=0.6800 | fpr=0.9057 | 7434.5 samples/s | 29.0 steps/s
[Step= 400] | Loss=5.90823 | acc=0.1051 | tpr=0.6822 | fpr=0.9054 | 7822.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.91275 | acc=0.1048 | tpr=0.6845 | fpr=0.9058 | 8063.4 samples/s | 31.5 steps/s
[Step= 500] | Loss=5.91551 | acc=0.1044 | tpr=0.6850 | fpr=0.9060 | 8097.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.91720 | acc=0.1044 | tpr=0.6860 | fpr=0.9062 | 14069.3 samples/s | 55.0 steps/s
Avg test loss: 5.91801, Avg test acc: 0.10431, Avg tpr: 0.68661, Avg fpr: 0.90628, total FA: 125835

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.22654 | acc=0.1136 | tpr=0.5664 | fpr=0.8945 | 4722.6 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.20403 | acc=0.1135 | tpr=0.5629 | fpr=0.8949 | 7239.1 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.19963 | acc=0.1147 | tpr=0.5605 | fpr=0.8935 | 7978.7 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.20095 | acc=0.1141 | tpr=0.5464 | fpr=0.8937 | 7862.3 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.21276 | acc=0.1140 | tpr=0.5450 | fpr=0.8939 | 7991.2 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.20965 | acc=0.1146 | tpr=0.5527 | fpr=0.8934 | 7936.6 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.19981 | acc=0.1149 | tpr=0.5617 | fpr=0.8932 | 7815.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.19892 | acc=0.1154 | tpr=0.5618 | fpr=0.8927 | 7835.2 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.20036 | acc=0.1153 | tpr=0.5628 | fpr=0.8928 | 8294.9 samples/s | 32.4 steps/s
[Step= 500] | Loss=5.20184 | acc=0.1151 | tpr=0.5634 | fpr=0.8930 | 7538.4 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.20524 | acc=0.1150 | tpr=0.5631 | fpr=0.8931 | 14568.8 samples/s | 56.9 steps/s
Avg test loss: 5.20677, Avg test acc: 0.11493, Avg tpr: 0.56300, Avg fpr: 0.89321, total FA: 124021

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08238 | acc=0.9834 | tpr=0.9336 | fpr=0.0157 | 5045.5 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.08434 | acc=0.9834 | tpr=0.9467 | fpr=0.0159 | 6860.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.08753 | acc=0.9827 | tpr=0.9467 | fpr=0.0167 | 7575.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.08956 | acc=0.9826 | tpr=0.9497 | fpr=0.0168 | 7957.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.08848 | acc=0.9827 | tpr=0.9432 | fpr=0.0165 | 7829.8 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09037 | acc=0.9823 | tpr=0.9411 | fpr=0.0169 | 7560.1 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.09109 | acc=0.9821 | tpr=0.9430 | fpr=0.0171 | 7911.3 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.09212 | acc=0.9819 | tpr=0.9376 | fpr=0.0173 | 7601.4 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.09400 | acc=0.9816 | tpr=0.9357 | fpr=0.0176 | 7504.4 samples/s | 29.3 steps/s
[Step= 500] | Loss=0.09323 | acc=0.9817 | tpr=0.9366 | fpr=0.0175 | 8204.6 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.09296 | acc=0.9818 | tpr=0.9347 | fpr=0.0173 | 13631.5 samples/s | 53.2 steps/s
Avg test loss: 0.09290, Avg test acc: 0.98180, Avg tpr: 0.93463, Avg fpr: 0.01734, total FA: 2408

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10321 | acc=0.9822 | tpr=0.8894 | fpr=0.0161 | 4727.2 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.10858 | acc=0.9818 | tpr=0.8870 | fpr=0.0164 | 7103.0 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.11153 | acc=0.9812 | tpr=0.8919 | fpr=0.0171 | 7822.8 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.11414 | acc=0.9812 | tpr=0.8973 | fpr=0.0173 | 7780.7 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.11226 | acc=0.9813 | tpr=0.8961 | fpr=0.0171 | 7481.6 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.11526 | acc=0.9810 | tpr=0.8953 | fpr=0.0175 | 8231.5 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.11557 | acc=0.9809 | tpr=0.8986 | fpr=0.0176 | 7823.3 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.11667 | acc=0.9806 | tpr=0.8928 | fpr=0.0178 | 7969.3 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.11920 | acc=0.9803 | tpr=0.8919 | fpr=0.0181 | 7837.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.11834 | acc=0.9804 | tpr=0.8947 | fpr=0.0180 | 7501.2 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.11812 | acc=0.9806 | tpr=0.8938 | fpr=0.0178 | 14380.0 samples/s | 56.2 steps/s
Avg test loss: 0.11799, Avg test acc: 0.98061, Avg tpr: 0.89422, Avg fpr: 0.01782, total FA: 2474

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10159 | acc=0.9805 | tpr=0.9248 | fpr=0.0185 | 4686.0 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10306 | acc=0.9806 | tpr=0.9275 | fpr=0.0184 | 7058.2 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.10842 | acc=0.9799 | tpr=0.9337 | fpr=0.0193 | 7872.2 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.11038 | acc=0.9801 | tpr=0.9355 | fpr=0.0191 | 8087.9 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.10770 | acc=0.9805 | tpr=0.9345 | fpr=0.0187 | 7738.3 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.10976 | acc=0.9802 | tpr=0.9287 | fpr=0.0188 | 7804.6 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.11077 | acc=0.9801 | tpr=0.9280 | fpr=0.0189 | 7864.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.11217 | acc=0.9800 | tpr=0.9234 | fpr=0.0190 | 7856.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.11401 | acc=0.9797 | tpr=0.9221 | fpr=0.0192 | 7575.7 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.11295 | acc=0.9798 | tpr=0.9256 | fpr=0.0193 | 8096.4 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.11240 | acc=0.9799 | tpr=0.9268 | fpr=0.0191 | 13761.5 samples/s | 53.8 steps/s
Avg test loss: 0.11229, Avg test acc: 0.97993, Avg tpr: 0.92710, Avg fpr: 0.01911, total FA: 2654

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10837 | acc=0.9831 | tpr=0.9115 | fpr=0.0156 | 4658.1 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.11439 | acc=0.9826 | tpr=0.9041 | fpr=0.0160 | 7452.6 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.11911 | acc=0.9821 | tpr=0.9063 | fpr=0.0165 | 7497.8 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.12101 | acc=0.9820 | tpr=0.9158 | fpr=0.0168 | 7893.1 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.11897 | acc=0.9823 | tpr=0.9135 | fpr=0.0165 | 7561.3 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.12163 | acc=0.9819 | tpr=0.9120 | fpr=0.0168 | 8384.0 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.12195 | acc=0.9818 | tpr=0.9148 | fpr=0.0170 | 7485.9 samples/s | 29.2 steps/s
[Step= 400] | Loss=0.12235 | acc=0.9816 | tpr=0.9136 | fpr=0.0172 | 7859.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.12469 | acc=0.9814 | tpr=0.9124 | fpr=0.0173 | 7633.3 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.12411 | acc=0.9815 | tpr=0.9141 | fpr=0.0173 | 7959.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12384 | acc=0.9816 | tpr=0.9125 | fpr=0.0172 | 14119.5 samples/s | 55.2 steps/s
Avg test loss: 0.12367, Avg test acc: 0.98159, Avg tpr: 0.91244, Avg fpr: 0.01716, total FA: 2382

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.12464 | acc=0.9796 | tpr=0.9115 | fpr=0.0192 | 4835.5 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.13213 | acc=0.9789 | tpr=0.9211 | fpr=0.0200 | 6843.9 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.13657 | acc=0.9779 | tpr=0.9280 | fpr=0.0211 | 7899.5 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.13897 | acc=0.9778 | tpr=0.9344 | fpr=0.0214 | 7920.0 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.13709 | acc=0.9781 | tpr=0.9328 | fpr=0.0210 | 7702.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.13956 | acc=0.9779 | tpr=0.9287 | fpr=0.0212 | 7641.6 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.13986 | acc=0.9778 | tpr=0.9324 | fpr=0.0214 | 7951.4 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14142 | acc=0.9776 | tpr=0.9283 | fpr=0.0215 | 7780.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.14424 | acc=0.9774 | tpr=0.9265 | fpr=0.0217 | 7900.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.14339 | acc=0.9775 | tpr=0.9278 | fpr=0.0216 | 7707.8 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.14270 | acc=0.9777 | tpr=0.9272 | fpr=0.0214 | 14258.3 samples/s | 55.7 steps/s
Avg test loss: 0.14248, Avg test acc: 0.97774, Avg tpr: 0.92750, Avg fpr: 0.02135, total FA: 2964

server round 16/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=156.0] | Loss=0.00234 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.672 | L2-Norm(final)=10.575 | 5437.6 samples/s | 85.0 steps/s
[Step=32050 Epoch=156.3] | Loss=0.00390 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.668 | L2-Norm(final)=10.585 | 4399.0 samples/s | 68.7 steps/s
[Step=32100 Epoch=156.5] | Loss=0.00405 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.666 | L2-Norm(final)=10.600 | 4975.2 samples/s | 77.7 steps/s
[Step=32150 Epoch=156.8] | Loss=0.00423 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.665 | L2-Norm(final)=10.614 | 4991.4 samples/s | 78.0 steps/s
[Step=32200 Epoch=157.0] | Loss=0.00426 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.663 | L2-Norm(final)=10.628 | 7565.4 samples/s | 118.2 steps/s
[Step=32250 Epoch=157.3] | Loss=0.00407 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.660 | L2-Norm(final)=10.641 | 2192.5 samples/s | 34.3 steps/s
[Step=32300 Epoch=157.5] | Loss=0.00408 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.656 | L2-Norm(final)=10.654 | 4883.0 samples/s | 76.3 steps/s
[Step=32350 Epoch=157.7] | Loss=0.00391 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.653 | L2-Norm(final)=10.667 | 5007.3 samples/s | 78.2 steps/s
[Step=32400 Epoch=158.0] | Loss=0.00378 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.649 | L2-Norm(final)=10.679 | 6877.0 samples/s | 107.5 steps/s
[Step=32450 Epoch=158.2] | Loss=0.00361 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.644 | L2-Norm(final)=10.691 | 2273.9 samples/s | 35.5 steps/s
[Step=32500 Epoch=158.5] | Loss=0.00353 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.639 | L2-Norm(final)=10.703 | 4955.6 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=158.5] | Loss=0.00654 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.592 | L2-Norm(final)=10.824 | 5549.1 samples/s | 86.7 steps/s
[Step=32550 Epoch=158.7] | Loss=0.00349 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.590 | L2-Norm(final)=10.835 | 3877.2 samples/s | 60.6 steps/s
[Step=32600 Epoch=159.0] | Loss=0.00461 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.589 | L2-Norm(final)=10.843 | 4401.9 samples/s | 68.8 steps/s
[Step=32650 Epoch=159.2] | Loss=0.00649 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.593 | L2-Norm(final)=10.847 | 4418.7 samples/s | 69.0 steps/s
[Step=32700 Epoch=159.5] | Loss=0.00792 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.602 | L2-Norm(final)=10.851 | 6404.5 samples/s | 100.1 steps/s
[Step=32750 Epoch=159.7] | Loss=0.00841 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.616 | L2-Norm(final)=10.856 | 2081.8 samples/s | 32.5 steps/s
[Step=32800 Epoch=159.9] | Loss=0.00847 | Reg=0.00385 | acc=0.9531 | L2-Norm=19.629 | L2-Norm(final)=10.863 | 4452.2 samples/s | 69.6 steps/s
[Step=32850 Epoch=160.2] | Loss=0.00874 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.644 | L2-Norm(final)=10.871 | 4443.3 samples/s | 69.4 steps/s
[Step=32900 Epoch=160.4] | Loss=0.00886 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.658 | L2-Norm(final)=10.880 | 5829.1 samples/s | 91.1 steps/s
[Step=32950 Epoch=160.7] | Loss=0.00883 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.673 | L2-Norm(final)=10.888 | 2141.4 samples/s | 33.5 steps/s
[Step=33000 Epoch=160.9] | Loss=0.00883 | Reg=0.00388 | acc=0.9844 | L2-Norm=19.686 | L2-Norm(final)=10.896 | 4473.3 samples/s | 69.9 steps/s
[Step=33050 Epoch=161.2] | Loss=0.00896 | Reg=0.00388 | acc=0.9844 | L2-Norm=19.700 | L2-Norm(final)=10.903 | 4383.2 samples/s | 68.5 steps/s
[Step=33100 Epoch=161.4] | Loss=0.00889 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.714 | L2-Norm(final)=10.911 | 5444.6 samples/s | 85.1 steps/s
[Step=33150 Epoch=161.6] | Loss=0.00857 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.727 | L2-Norm(final)=10.918 | 2257.9 samples/s | 35.3 steps/s
[Step=33200 Epoch=161.9] | Loss=0.00845 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.739 | L2-Norm(final)=10.926 | 4403.3 samples/s | 68.8 steps/s
[Step=33250 Epoch=162.1] | Loss=0.00836 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.749 | L2-Norm(final)=10.932 | 4433.1 samples/s | 69.3 steps/s
[Step=33300 Epoch=162.4] | Loss=0.00808 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.757 | L2-Norm(final)=10.938 | 4988.4 samples/s | 77.9 steps/s
[Step=33350 Epoch=162.6] | Loss=0.00782 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.764 | L2-Norm(final)=10.945 | 2311.3 samples/s | 36.1 steps/s
[Step=33400 Epoch=162.9] | Loss=0.00773 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.770 | L2-Norm(final)=10.950 | 4508.3 samples/s | 70.4 steps/s
[Step=33450 Epoch=163.1] | Loss=0.00751 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.775 | L2-Norm(final)=10.956 | 4391.9 samples/s | 68.6 steps/s
[Step=33500 Epoch=163.4] | Loss=0.00741 | Reg=0.00391 | acc=0.9688 | L2-Norm=19.778 | L2-Norm(final)=10.961 | 4341.3 samples/s | 67.8 steps/s
[Step=33550 Epoch=163.6] | Loss=0.00722 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.781 | L2-Norm(final)=10.965 | 2227.3 samples/s | 34.8 steps/s
[Step=33600 Epoch=163.8] | Loss=0.00710 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.782 | L2-Norm(final)=10.970 | 4242.0 samples/s | 66.3 steps/s
[Step=33650 Epoch=164.1] | Loss=0.00700 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.783 | L2-Norm(final)=10.974 | 4289.0 samples/s | 67.0 steps/s
[Step=33700 Epoch=164.3] | Loss=0.00683 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.783 | L2-Norm(final)=10.978 | 4218.7 samples/s | 65.9 steps/s
[Step=33750 Epoch=164.6] | Loss=0.00669 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.782 | L2-Norm(final)=10.982 | 2274.7 samples/s | 35.5 steps/s
[Step=33800 Epoch=164.8] | Loss=0.00658 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.780 | L2-Norm(final)=10.985 | 4195.9 samples/s | 65.6 steps/s
[Step=33850 Epoch=165.1] | Loss=0.00641 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.778 | L2-Norm(final)=10.989 | 4261.0 samples/s | 66.6 steps/s
[Step=33900 Epoch=165.3] | Loss=0.00632 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.775 | L2-Norm(final)=10.992 | 4399.8 samples/s | 68.7 steps/s
[Step=33950 Epoch=165.5] | Loss=0.00628 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.772 | L2-Norm(final)=10.995 | 2456.1 samples/s | 38.4 steps/s
[Step=34000 Epoch=165.8] | Loss=0.00623 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.768 | L2-Norm(final)=10.998 | 4459.9 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step34000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=156.2] | Loss=0.00513 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.666 | L2-Norm(final)=10.691 | 5282.4 samples/s | 82.5 steps/s
[Step=32050 Epoch=156.4] | Loss=0.00462 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.664 | L2-Norm(final)=10.701 | 4435.0 samples/s | 69.3 steps/s
[Step=32100 Epoch=156.6] | Loss=0.00441 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.662 | L2-Norm(final)=10.714 | 4960.7 samples/s | 77.5 steps/s
[Step=32150 Epoch=156.9] | Loss=0.00406 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.659 | L2-Norm(final)=10.728 | 5026.7 samples/s | 78.5 steps/s
[Step=32200 Epoch=157.1] | Loss=0.00397 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.656 | L2-Norm(final)=10.741 | 7867.9 samples/s | 122.9 steps/s
[Step=32250 Epoch=157.4] | Loss=0.00380 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.653 | L2-Norm(final)=10.755 | 2196.0 samples/s | 34.3 steps/s
[Step=32300 Epoch=157.6] | Loss=0.00385 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.649 | L2-Norm(final)=10.768 | 5070.1 samples/s | 79.2 steps/s
[Step=32350 Epoch=157.9] | Loss=0.00379 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.646 | L2-Norm(final)=10.781 | 5065.1 samples/s | 79.1 steps/s
[Step=32400 Epoch=158.1] | Loss=0.00359 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.643 | L2-Norm(final)=10.794 | 7125.4 samples/s | 111.3 steps/s
[Step=32450 Epoch=158.3] | Loss=0.00350 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.639 | L2-Norm(final)=10.806 | 2275.4 samples/s | 35.6 steps/s
[Step=32500 Epoch=158.6] | Loss=0.00345 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.634 | L2-Norm(final)=10.819 | 4937.1 samples/s | 77.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=158.6] | Loss=0.00046 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.582 | L2-Norm(final)=10.942 | 5766.0 samples/s | 90.1 steps/s
[Step=32550 Epoch=158.8] | Loss=0.00444 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.582 | L2-Norm(final)=10.952 | 3802.0 samples/s | 59.4 steps/s
[Step=32600 Epoch=159.1] | Loss=0.00645 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.590 | L2-Norm(final)=10.958 | 4491.9 samples/s | 70.2 steps/s
[Step=32650 Epoch=159.3] | Loss=0.00889 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.608 | L2-Norm(final)=10.963 | 4464.8 samples/s | 69.8 steps/s
[Step=32700 Epoch=159.6] | Loss=0.01200 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.636 | L2-Norm(final)=10.965 | 6621.1 samples/s | 103.5 steps/s
[Step=32750 Epoch=159.8] | Loss=0.01245 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.670 | L2-Norm(final)=10.968 | 2097.1 samples/s | 32.8 steps/s
[Step=32800 Epoch=160.0] | Loss=0.01286 | Reg=0.00388 | acc=0.9844 | L2-Norm=19.702 | L2-Norm(final)=10.971 | 4475.2 samples/s | 69.9 steps/s
[Step=32850 Epoch=160.3] | Loss=0.01285 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.730 | L2-Norm(final)=10.975 | 4341.5 samples/s | 67.8 steps/s
[Step=32900 Epoch=160.5] | Loss=0.01275 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.754 | L2-Norm(final)=10.979 | 6042.0 samples/s | 94.4 steps/s
[Step=32950 Epoch=160.8] | Loss=0.01215 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.774 | L2-Norm(final)=10.984 | 2172.5 samples/s | 33.9 steps/s
[Step=33000 Epoch=161.0] | Loss=0.01147 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.791 | L2-Norm(final)=10.989 | 4492.2 samples/s | 70.2 steps/s
[Step=33050 Epoch=161.3] | Loss=0.01095 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.803 | L2-Norm(final)=10.995 | 4472.3 samples/s | 69.9 steps/s
[Step=33100 Epoch=161.5] | Loss=0.01058 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.813 | L2-Norm(final)=10.999 | 5513.5 samples/s | 86.1 steps/s
[Step=33150 Epoch=161.8] | Loss=0.01016 | Reg=0.00393 | acc=0.9688 | L2-Norm=19.821 | L2-Norm(final)=11.004 | 2204.9 samples/s | 34.5 steps/s
[Step=33200 Epoch=162.0] | Loss=0.00981 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.827 | L2-Norm(final)=11.007 | 4502.6 samples/s | 70.4 steps/s
[Step=33250 Epoch=162.2] | Loss=0.00939 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.831 | L2-Norm(final)=11.011 | 4398.7 samples/s | 68.7 steps/s
[Step=33300 Epoch=162.5] | Loss=0.00900 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.834 | L2-Norm(final)=11.015 | 5204.3 samples/s | 81.3 steps/s
[Step=33350 Epoch=162.7] | Loss=0.00874 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.836 | L2-Norm(final)=11.018 | 2279.6 samples/s | 35.6 steps/s
[Step=33400 Epoch=163.0] | Loss=0.00845 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.837 | L2-Norm(final)=11.022 | 4438.3 samples/s | 69.3 steps/s
[Step=33450 Epoch=163.2] | Loss=0.00823 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.836 | L2-Norm(final)=11.026 | 4448.2 samples/s | 69.5 steps/s
[Step=33500 Epoch=163.5] | Loss=0.00798 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.836 | L2-Norm(final)=11.029 | 4825.4 samples/s | 75.4 steps/s
[Step=33550 Epoch=163.7] | Loss=0.00786 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.834 | L2-Norm(final)=11.033 | 2316.2 samples/s | 36.2 steps/s
[Step=33600 Epoch=164.0] | Loss=0.00776 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.833 | L2-Norm(final)=11.036 | 4523.1 samples/s | 70.7 steps/s
[Step=33650 Epoch=164.2] | Loss=0.00772 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.831 | L2-Norm(final)=11.039 | 4425.0 samples/s | 69.1 steps/s
[Step=33700 Epoch=164.4] | Loss=0.00760 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.829 | L2-Norm(final)=11.042 | 4571.7 samples/s | 71.4 steps/s
[Step=33750 Epoch=164.7] | Loss=0.00748 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.826 | L2-Norm(final)=11.044 | 2428.6 samples/s | 37.9 steps/s
[Step=33800 Epoch=164.9] | Loss=0.00732 | Reg=0.00393 | acc=0.9688 | L2-Norm=19.823 | L2-Norm(final)=11.047 | 4490.8 samples/s | 70.2 steps/s
[Step=33850 Epoch=165.2] | Loss=0.00717 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.820 | L2-Norm(final)=11.050 | 4594.2 samples/s | 71.8 steps/s
[Step=33900 Epoch=165.4] | Loss=0.00701 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.817 | L2-Norm(final)=11.052 | 4304.1 samples/s | 67.3 steps/s
[Step=33950 Epoch=165.7] | Loss=0.00687 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.813 | L2-Norm(final)=11.055 | 2469.2 samples/s | 38.6 steps/s
[Step=34000 Epoch=165.9] | Loss=0.00673 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.808 | L2-Norm(final)=11.058 | 4503.1 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step34000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=155.9] | Loss=0.00562 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.808 | L2-Norm(final)=11.156 | 5351.6 samples/s | 83.6 steps/s
[Step=32050 Epoch=156.2] | Loss=0.00593 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.807 | L2-Norm(final)=11.169 | 4499.8 samples/s | 70.3 steps/s
[Step=32100 Epoch=156.4] | Loss=0.00524 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.810 | L2-Norm(final)=11.184 | 5012.5 samples/s | 78.3 steps/s
[Step=32150 Epoch=156.7] | Loss=0.00511 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.810 | L2-Norm(final)=11.200 | 5006.4 samples/s | 78.2 steps/s
[Step=32200 Epoch=156.9] | Loss=0.00509 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.812 | L2-Norm(final)=11.215 | 7887.4 samples/s | 123.2 steps/s
[Step=32250 Epoch=157.1] | Loss=0.00485 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.812 | L2-Norm(final)=11.230 | 2217.8 samples/s | 34.7 steps/s
[Step=32300 Epoch=157.4] | Loss=0.00463 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.812 | L2-Norm(final)=11.245 | 4769.8 samples/s | 74.5 steps/s
[Step=32350 Epoch=157.6] | Loss=0.00443 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.811 | L2-Norm(final)=11.260 | 5080.9 samples/s | 79.4 steps/s
[Step=32400 Epoch=157.9] | Loss=0.00442 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.810 | L2-Norm(final)=11.274 | 6961.0 samples/s | 108.8 steps/s
[Step=32450 Epoch=158.1] | Loss=0.00430 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.808 | L2-Norm(final)=11.289 | 2284.7 samples/s | 35.7 steps/s
[Step=32500 Epoch=158.4] | Loss=0.00421 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.806 | L2-Norm(final)=11.304 | 5022.8 samples/s | 78.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=158.4] | Loss=0.00769 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.777 | L2-Norm(final)=11.452 | 5481.3 samples/s | 85.6 steps/s
[Step=32550 Epoch=158.6] | Loss=0.00504 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.780 | L2-Norm(final)=11.467 | 3837.5 samples/s | 60.0 steps/s
[Step=32600 Epoch=158.8] | Loss=0.00883 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.798 | L2-Norm(final)=11.476 | 4540.0 samples/s | 70.9 steps/s
[Step=32650 Epoch=159.1] | Loss=0.01319 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.834 | L2-Norm(final)=11.483 | 4418.8 samples/s | 69.0 steps/s
[Step=32700 Epoch=159.3] | Loss=0.01431 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.873 | L2-Norm(final)=11.488 | 6545.6 samples/s | 102.3 steps/s
[Step=32750 Epoch=159.6] | Loss=0.01621 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.914 | L2-Norm(final)=11.491 | 2091.0 samples/s | 32.7 steps/s
[Step=32800 Epoch=159.8] | Loss=0.01678 | Reg=0.00398 | acc=0.9688 | L2-Norm=19.951 | L2-Norm(final)=11.493 | 4468.9 samples/s | 69.8 steps/s
[Step=32850 Epoch=160.1] | Loss=0.01708 | Reg=0.00399 | acc=0.9688 | L2-Norm=19.983 | L2-Norm(final)=11.495 | 4526.1 samples/s | 70.7 steps/s
[Step=32900 Epoch=160.3] | Loss=0.01675 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.012 | L2-Norm(final)=11.497 | 5828.6 samples/s | 91.1 steps/s
[Step=32950 Epoch=160.5] | Loss=0.01606 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.037 | L2-Norm(final)=11.500 | 2140.0 samples/s | 33.4 steps/s
[Step=33000 Epoch=160.8] | Loss=0.01529 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.058 | L2-Norm(final)=11.503 | 4459.9 samples/s | 69.7 steps/s
[Step=33050 Epoch=161.0] | Loss=0.01457 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.075 | L2-Norm(final)=11.507 | 4476.0 samples/s | 69.9 steps/s
[Step=33100 Epoch=161.3] | Loss=0.01378 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.089 | L2-Norm(final)=11.511 | 5412.5 samples/s | 84.6 steps/s
[Step=33150 Epoch=161.5] | Loss=0.01320 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.100 | L2-Norm(final)=11.515 | 2250.1 samples/s | 35.2 steps/s
[Step=33200 Epoch=161.8] | Loss=0.01250 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.110 | L2-Norm(final)=11.519 | 4492.3 samples/s | 70.2 steps/s
[Step=33250 Epoch=162.0] | Loss=0.01199 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.117 | L2-Norm(final)=11.522 | 4414.1 samples/s | 69.0 steps/s
[Step=33300 Epoch=162.3] | Loss=0.01149 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.123 | L2-Norm(final)=11.526 | 4916.2 samples/s | 76.8 steps/s
[Step=33350 Epoch=162.5] | Loss=0.01112 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.127 | L2-Norm(final)=11.529 | 2333.2 samples/s | 36.5 steps/s
[Step=33400 Epoch=162.7] | Loss=0.01077 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.131 | L2-Norm(final)=11.532 | 4541.0 samples/s | 71.0 steps/s
[Step=33450 Epoch=163.0] | Loss=0.01045 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.133 | L2-Norm(final)=11.535 | 4449.1 samples/s | 69.5 steps/s
[Step=33500 Epoch=163.2] | Loss=0.01019 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.135 | L2-Norm(final)=11.538 | 4609.6 samples/s | 72.0 steps/s
[Step=33550 Epoch=163.5] | Loss=0.00996 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.136 | L2-Norm(final)=11.540 | 2401.9 samples/s | 37.5 steps/s
[Step=33600 Epoch=163.7] | Loss=0.00966 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.136 | L2-Norm(final)=11.543 | 4474.4 samples/s | 69.9 steps/s
[Step=33650 Epoch=164.0] | Loss=0.00944 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.136 | L2-Norm(final)=11.546 | 4413.5 samples/s | 69.0 steps/s
[Step=33700 Epoch=164.2] | Loss=0.00924 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.135 | L2-Norm(final)=11.548 | 4503.8 samples/s | 70.4 steps/s
[Step=33750 Epoch=164.4] | Loss=0.00900 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.134 | L2-Norm(final)=11.551 | 2519.4 samples/s | 39.4 steps/s
[Step=33800 Epoch=164.7] | Loss=0.00878 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.132 | L2-Norm(final)=11.553 | 4413.0 samples/s | 69.0 steps/s
[Step=33850 Epoch=164.9] | Loss=0.00855 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.130 | L2-Norm(final)=11.556 | 4458.8 samples/s | 69.7 steps/s
[Step=33900 Epoch=165.2] | Loss=0.00839 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.127 | L2-Norm(final)=11.559 | 4486.9 samples/s | 70.1 steps/s
[Step=33950 Epoch=165.4] | Loss=0.00818 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.124 | L2-Norm(final)=11.561 | 2446.7 samples/s | 38.2 steps/s
[Step=34000 Epoch=165.7] | Loss=0.00801 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.121 | L2-Norm(final)=11.564 | 4466.2 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step34000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=156.1] | Loss=0.00135 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.941 | L2-Norm(final)=10.969 | 4577.1 samples/s | 71.5 steps/s
[Step=32050 Epoch=156.3] | Loss=0.00463 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.936 | L2-Norm(final)=10.979 | 2967.1 samples/s | 46.4 steps/s
[Step=32100 Epoch=156.5] | Loss=0.00412 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.932 | L2-Norm(final)=10.992 | 5005.4 samples/s | 78.2 steps/s
[Step=32150 Epoch=156.8] | Loss=0.00410 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.929 | L2-Norm(final)=11.006 | 5023.8 samples/s | 78.5 steps/s
[Step=32200 Epoch=157.0] | Loss=0.00373 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.926 | L2-Norm(final)=11.019 | 7349.0 samples/s | 114.8 steps/s
[Step=32250 Epoch=157.3] | Loss=0.00363 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.923 | L2-Norm(final)=11.033 | 2152.6 samples/s | 33.6 steps/s
[Step=32300 Epoch=157.5] | Loss=0.00352 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.919 | L2-Norm(final)=11.046 | 5104.3 samples/s | 79.8 steps/s
[Step=32350 Epoch=157.8] | Loss=0.00344 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.915 | L2-Norm(final)=11.058 | 4909.3 samples/s | 76.7 steps/s
[Step=32400 Epoch=158.0] | Loss=0.00338 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.911 | L2-Norm(final)=11.069 | 7037.9 samples/s | 110.0 steps/s
[Step=32450 Epoch=158.2] | Loss=0.00331 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.906 | L2-Norm(final)=11.082 | 2284.9 samples/s | 35.7 steps/s
[Step=32500 Epoch=158.5] | Loss=0.00332 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.902 | L2-Norm(final)=11.094 | 5057.8 samples/s | 79.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=158.5] | Loss=0.01028 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.858 | L2-Norm(final)=11.215 | 5657.1 samples/s | 88.4 steps/s
[Step=32550 Epoch=158.7] | Loss=0.00291 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.858 | L2-Norm(final)=11.224 | 3858.6 samples/s | 60.3 steps/s
[Step=32600 Epoch=159.0] | Loss=0.00539 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.859 | L2-Norm(final)=11.233 | 4440.1 samples/s | 69.4 steps/s
[Step=32650 Epoch=159.2] | Loss=0.00674 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.863 | L2-Norm(final)=11.237 | 4454.6 samples/s | 69.6 steps/s
[Step=32700 Epoch=159.5] | Loss=0.00831 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.870 | L2-Norm(final)=11.243 | 6522.1 samples/s | 101.9 steps/s
[Step=32750 Epoch=159.7] | Loss=0.00905 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.883 | L2-Norm(final)=11.247 | 2102.2 samples/s | 32.8 steps/s
[Step=32800 Epoch=160.0] | Loss=0.00945 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.901 | L2-Norm(final)=11.252 | 4490.5 samples/s | 70.2 steps/s
[Step=32850 Epoch=160.2] | Loss=0.00963 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.920 | L2-Norm(final)=11.258 | 4512.6 samples/s | 70.5 steps/s
[Step=32900 Epoch=160.4] | Loss=0.01070 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.941 | L2-Norm(final)=11.263 | 5883.6 samples/s | 91.9 steps/s
[Step=32950 Epoch=160.7] | Loss=0.01044 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.960 | L2-Norm(final)=11.267 | 2152.1 samples/s | 33.6 steps/s
[Step=33000 Epoch=160.9] | Loss=0.00998 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.977 | L2-Norm(final)=11.273 | 4477.1 samples/s | 70.0 steps/s
[Step=33050 Epoch=161.2] | Loss=0.00981 | Reg=0.00400 | acc=1.0000 | L2-Norm=19.990 | L2-Norm(final)=11.278 | 4512.6 samples/s | 70.5 steps/s
[Step=33100 Epoch=161.4] | Loss=0.00972 | Reg=0.00400 | acc=1.0000 | L2-Norm=20.002 | L2-Norm(final)=11.282 | 5408.6 samples/s | 84.5 steps/s
[Step=33150 Epoch=161.7] | Loss=0.00926 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.013 | L2-Norm(final)=11.287 | 2245.9 samples/s | 35.1 steps/s
[Step=33200 Epoch=161.9] | Loss=0.00899 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.022 | L2-Norm(final)=11.291 | 4500.4 samples/s | 70.3 steps/s
[Step=33250 Epoch=162.1] | Loss=0.00879 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.030 | L2-Norm(final)=11.295 | 4472.2 samples/s | 69.9 steps/s
[Step=33300 Epoch=162.4] | Loss=0.00852 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.036 | L2-Norm(final)=11.299 | 4972.0 samples/s | 77.7 steps/s
[Step=33350 Epoch=162.6] | Loss=0.00828 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.041 | L2-Norm(final)=11.303 | 2320.9 samples/s | 36.3 steps/s
[Step=33400 Epoch=162.9] | Loss=0.00799 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.045 | L2-Norm(final)=11.307 | 4568.7 samples/s | 71.4 steps/s
[Step=33450 Epoch=163.1] | Loss=0.00778 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.047 | L2-Norm(final)=11.311 | 4343.4 samples/s | 67.9 steps/s
[Step=33500 Epoch=163.4] | Loss=0.00757 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.048 | L2-Norm(final)=11.314 | 4613.9 samples/s | 72.1 steps/s
[Step=33550 Epoch=163.6] | Loss=0.00746 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.049 | L2-Norm(final)=11.318 | 2438.2 samples/s | 38.1 steps/s
[Step=33600 Epoch=163.9] | Loss=0.00726 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.049 | L2-Norm(final)=11.321 | 4561.1 samples/s | 71.3 steps/s
[Step=33650 Epoch=164.1] | Loss=0.00706 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.048 | L2-Norm(final)=11.324 | 4430.4 samples/s | 69.2 steps/s
[Step=33700 Epoch=164.3] | Loss=0.00690 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.046 | L2-Norm(final)=11.327 | 4333.6 samples/s | 67.7 steps/s
[Step=33750 Epoch=164.6] | Loss=0.00678 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.044 | L2-Norm(final)=11.330 | 2463.9 samples/s | 38.5 steps/s
[Step=33800 Epoch=164.8] | Loss=0.00661 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.042 | L2-Norm(final)=11.333 | 4551.5 samples/s | 71.1 steps/s
[Step=33850 Epoch=165.1] | Loss=0.00644 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.039 | L2-Norm(final)=11.336 | 4375.0 samples/s | 68.4 steps/s
[Step=33900 Epoch=165.3] | Loss=0.00635 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.035 | L2-Norm(final)=11.339 | 4466.7 samples/s | 69.8 steps/s
[Step=33950 Epoch=165.6] | Loss=0.00624 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.031 | L2-Norm(final)=11.341 | 2469.5 samples/s | 38.6 steps/s
[Step=34000 Epoch=165.8] | Loss=0.00614 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.027 | L2-Norm(final)=11.344 | 4442.0 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step34000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=156.9] | Loss=0.00050 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.612 | L2-Norm(final)=10.955 | 5296.3 samples/s | 82.8 steps/s
[Step=32050 Epoch=157.2] | Loss=0.00486 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.608 | L2-Norm(final)=10.967 | 4442.1 samples/s | 69.4 steps/s
[Step=32100 Epoch=157.4] | Loss=0.00446 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.608 | L2-Norm(final)=10.980 | 5100.5 samples/s | 79.7 steps/s
[Step=32150 Epoch=157.7] | Loss=0.00436 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.606 | L2-Norm(final)=10.993 | 5118.2 samples/s | 80.0 steps/s
[Step=32200 Epoch=157.9] | Loss=0.00422 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.605 | L2-Norm(final)=11.006 | 7733.4 samples/s | 120.8 steps/s
[Step=32250 Epoch=158.1] | Loss=0.00388 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.603 | L2-Norm(final)=11.019 | 2191.1 samples/s | 34.2 steps/s
[Step=32300 Epoch=158.4] | Loss=0.00382 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.600 | L2-Norm(final)=11.032 | 5040.9 samples/s | 78.8 steps/s
[Step=32350 Epoch=158.6] | Loss=0.00364 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.597 | L2-Norm(final)=11.046 | 5055.8 samples/s | 79.0 steps/s
[Step=32400 Epoch=158.9] | Loss=0.00368 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.594 | L2-Norm(final)=11.059 | 7224.2 samples/s | 112.9 steps/s
[Step=32450 Epoch=159.1] | Loss=0.00359 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.590 | L2-Norm(final)=11.072 | 2227.5 samples/s | 34.8 steps/s
[Step=32500 Epoch=159.4] | Loss=0.00351 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.586 | L2-Norm(final)=11.084 | 5030.5 samples/s | 78.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=159.4] | Loss=0.00511 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.543 | L2-Norm(final)=11.210 | 5719.9 samples/s | 89.4 steps/s
[Step=32550 Epoch=159.6] | Loss=0.00450 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.542 | L2-Norm(final)=11.218 | 3928.0 samples/s | 61.4 steps/s
[Step=32600 Epoch=159.9] | Loss=0.00450 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.543 | L2-Norm(final)=11.226 | 4460.3 samples/s | 69.7 steps/s
[Step=32650 Epoch=160.1] | Loss=0.00583 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.547 | L2-Norm(final)=11.233 | 4589.8 samples/s | 71.7 steps/s
[Step=32700 Epoch=160.4] | Loss=0.00717 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.555 | L2-Norm(final)=11.239 | 6392.9 samples/s | 99.9 steps/s
[Step=32750 Epoch=160.6] | Loss=0.00778 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.568 | L2-Norm(final)=11.247 | 2049.0 samples/s | 32.0 steps/s
[Step=32800 Epoch=160.8] | Loss=0.00855 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.586 | L2-Norm(final)=11.254 | 4485.5 samples/s | 70.1 steps/s
[Step=32850 Epoch=161.1] | Loss=0.00962 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.608 | L2-Norm(final)=11.259 | 4430.2 samples/s | 69.2 steps/s
[Step=32900 Epoch=161.3] | Loss=0.01017 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.630 | L2-Norm(final)=11.264 | 6273.2 samples/s | 98.0 steps/s
[Step=32950 Epoch=161.6] | Loss=0.01023 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.651 | L2-Norm(final)=11.268 | 2114.1 samples/s | 33.0 steps/s
[Step=33000 Epoch=161.8] | Loss=0.01039 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.671 | L2-Norm(final)=11.273 | 4553.5 samples/s | 71.1 steps/s
[Step=33050 Epoch=162.1] | Loss=0.01069 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.690 | L2-Norm(final)=11.277 | 4331.8 samples/s | 67.7 steps/s
[Step=33100 Epoch=162.3] | Loss=0.01094 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.707 | L2-Norm(final)=11.281 | 5865.9 samples/s | 91.7 steps/s
[Step=33150 Epoch=162.6] | Loss=0.01087 | Reg=0.00389 | acc=0.9688 | L2-Norm=19.723 | L2-Norm(final)=11.285 | 2174.0 samples/s | 34.0 steps/s
[Step=33200 Epoch=162.8] | Loss=0.01056 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.738 | L2-Norm(final)=11.288 | 4429.5 samples/s | 69.2 steps/s
[Step=33250 Epoch=163.1] | Loss=0.01038 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.750 | L2-Norm(final)=11.292 | 4479.8 samples/s | 70.0 steps/s
[Step=33300 Epoch=163.3] | Loss=0.01019 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.762 | L2-Norm(final)=11.295 | 5529.0 samples/s | 86.4 steps/s
[Step=33350 Epoch=163.5] | Loss=0.00989 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.771 | L2-Norm(final)=11.298 | 2220.9 samples/s | 34.7 steps/s
[Step=33400 Epoch=163.8] | Loss=0.00958 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.779 | L2-Norm(final)=11.300 | 4369.3 samples/s | 68.3 steps/s
[Step=33450 Epoch=164.0] | Loss=0.00945 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.786 | L2-Norm(final)=11.303 | 4539.5 samples/s | 70.9 steps/s
[Step=33500 Epoch=164.3] | Loss=0.00916 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.792 | L2-Norm(final)=11.306 | 5121.6 samples/s | 80.0 steps/s
[Step=33550 Epoch=164.5] | Loss=0.00890 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.797 | L2-Norm(final)=11.309 | 2267.8 samples/s | 35.4 steps/s
[Step=33600 Epoch=164.8] | Loss=0.00861 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.800 | L2-Norm(final)=11.312 | 4545.7 samples/s | 71.0 steps/s
[Step=33650 Epoch=165.0] | Loss=0.00842 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.803 | L2-Norm(final)=11.315 | 4431.2 samples/s | 69.2 steps/s
[Step=33700 Epoch=165.3] | Loss=0.00824 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.805 | L2-Norm(final)=11.317 | 4913.4 samples/s | 76.8 steps/s
[Step=33750 Epoch=165.5] | Loss=0.00808 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.806 | L2-Norm(final)=11.320 | 2329.8 samples/s | 36.4 steps/s
[Step=33800 Epoch=165.7] | Loss=0.00792 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.807 | L2-Norm(final)=11.322 | 4473.8 samples/s | 69.9 steps/s
[Step=33850 Epoch=166.0] | Loss=0.00770 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.807 | L2-Norm(final)=11.325 | 4548.5 samples/s | 71.1 steps/s
[Step=33900 Epoch=166.2] | Loss=0.00753 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.806 | L2-Norm(final)=11.327 | 4597.0 samples/s | 71.8 steps/s
[Step=33950 Epoch=166.5] | Loss=0.00736 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.805 | L2-Norm(final)=11.329 | 2407.4 samples/s | 37.6 steps/s
[Step=34000 Epoch=166.7] | Loss=0.00722 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.804 | L2-Norm(final)=11.332 | 4542.7 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step34000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=303.2] | Loss=0.00034 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.940 | L2-Norm(final)=6.365 | 5400.6 samples/s | 84.4 steps/s
[Step=32050 Epoch=303.7] | Loss=0.00015 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.956 | L2-Norm(final)=6.388 | 4057.4 samples/s | 63.4 steps/s
[Step=32100 Epoch=304.2] | Loss=0.00036 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=6.413 | 7542.2 samples/s | 117.8 steps/s
[Step=32150 Epoch=304.6] | Loss=0.00028 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.012 | L2-Norm(final)=6.437 | 2129.7 samples/s | 33.3 steps/s
[Step=32200 Epoch=305.1] | Loss=0.00025 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.031 | L2-Norm(final)=6.455 | 6497.3 samples/s | 101.5 steps/s
[Step=32250 Epoch=305.6] | Loss=0.00021 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.044 | L2-Norm(final)=6.469 | 2211.5 samples/s | 34.6 steps/s
[Step=32300 Epoch=306.1] | Loss=0.00018 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.052 | L2-Norm(final)=6.480 | 5936.7 samples/s | 92.8 steps/s
[Step=32350 Epoch=306.5] | Loss=0.00016 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.058 | L2-Norm(final)=6.489 | 2300.5 samples/s | 35.9 steps/s
[Step=32400 Epoch=307.0] | Loss=0.00014 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.061 | L2-Norm(final)=6.496 | 5168.0 samples/s | 80.7 steps/s
[Step=32450 Epoch=307.5] | Loss=0.00013 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.064 | L2-Norm(final)=6.503 | 2376.6 samples/s | 37.1 steps/s
[Step=32500 Epoch=308.0] | Loss=0.00012 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.065 | L2-Norm(final)=6.509 | 4916.1 samples/s | 76.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=308.0] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=6.568 | 5065.0 samples/s | 79.1 steps/s
[Step=32550 Epoch=308.4] | Loss=0.01204 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.137 | L2-Norm(final)=6.549 | 3938.8 samples/s | 61.5 steps/s
[Step=32600 Epoch=308.9] | Loss=0.00789 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.274 | L2-Norm(final)=6.522 | 6254.4 samples/s | 97.7 steps/s
[Step=32650 Epoch=309.4] | Loss=0.00529 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.334 | L2-Norm(final)=6.513 | 2000.0 samples/s | 31.2 steps/s
[Step=32700 Epoch=309.9] | Loss=0.00399 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.363 | L2-Norm(final)=6.510 | 5626.4 samples/s | 87.9 steps/s
[Step=32750 Epoch=310.3] | Loss=0.00320 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.380 | L2-Norm(final)=6.509 | 2096.2 samples/s | 32.8 steps/s
[Step=32800 Epoch=310.8] | Loss=0.00267 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.391 | L2-Norm(final)=6.508 | 5119.7 samples/s | 80.0 steps/s
[Step=32850 Epoch=311.3] | Loss=0.00229 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.397 | L2-Norm(final)=6.508 | 2188.3 samples/s | 34.2 steps/s
[Step=32900 Epoch=311.8] | Loss=0.00200 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.401 | L2-Norm(final)=6.508 | 4697.2 samples/s | 73.4 steps/s
[Step=32950 Epoch=312.2] | Loss=0.00178 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.403 | L2-Norm(final)=6.508 | 2260.3 samples/s | 35.3 steps/s
[Step=33000 Epoch=312.7] | Loss=0.00160 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.405 | L2-Norm(final)=6.509 | 4283.2 samples/s | 66.9 steps/s
[Step=33050 Epoch=313.2] | Loss=0.00146 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.405 | L2-Norm(final)=6.509 | 2352.7 samples/s | 36.8 steps/s
[Step=33100 Epoch=313.7] | Loss=0.00134 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.405 | L2-Norm(final)=6.509 | 4429.3 samples/s | 69.2 steps/s
[Step=33150 Epoch=314.1] | Loss=0.00124 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.404 | L2-Norm(final)=6.510 | 2330.8 samples/s | 36.4 steps/s
[Step=33200 Epoch=314.6] | Loss=0.00115 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.403 | L2-Norm(final)=6.510 | 4267.9 samples/s | 66.7 steps/s
[Step=33250 Epoch=315.1] | Loss=0.00107 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.401 | L2-Norm(final)=6.511 | 2330.6 samples/s | 36.4 steps/s
[Step=33300 Epoch=315.5] | Loss=0.00101 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.400 | L2-Norm(final)=6.512 | 4249.0 samples/s | 66.4 steps/s
[Step=33350 Epoch=316.0] | Loss=0.00095 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.398 | L2-Norm(final)=6.513 | 2582.2 samples/s | 40.3 steps/s
[Step=33400 Epoch=316.5] | Loss=0.00089 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.396 | L2-Norm(final)=6.514 | 3801.4 samples/s | 59.4 steps/s
[Step=33450 Epoch=317.0] | Loss=0.00085 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.393 | L2-Norm(final)=6.516 | 6353.2 samples/s | 99.3 steps/s
[Step=33500 Epoch=317.4] | Loss=0.00081 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.391 | L2-Norm(final)=6.517 | 1984.4 samples/s | 31.0 steps/s
[Step=33550 Epoch=317.9] | Loss=0.00077 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.388 | L2-Norm(final)=6.519 | 5749.0 samples/s | 89.8 steps/s
[Step=33600 Epoch=318.4] | Loss=0.00073 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.386 | L2-Norm(final)=6.521 | 2040.5 samples/s | 31.9 steps/s
[Step=33650 Epoch=318.9] | Loss=0.00070 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.383 | L2-Norm(final)=6.522 | 5299.8 samples/s | 82.8 steps/s
[Step=33700 Epoch=319.3] | Loss=0.00067 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.380 | L2-Norm(final)=6.524 | 2139.5 samples/s | 33.4 steps/s
[Step=33750 Epoch=319.8] | Loss=0.00065 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.377 | L2-Norm(final)=6.526 | 4861.9 samples/s | 76.0 steps/s
[Step=33800 Epoch=320.3] | Loss=0.00062 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.374 | L2-Norm(final)=6.528 | 2216.5 samples/s | 34.6 steps/s
[Step=33850 Epoch=320.8] | Loss=0.00060 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.370 | L2-Norm(final)=6.530 | 4371.3 samples/s | 68.3 steps/s
[Step=33900 Epoch=321.2] | Loss=0.00058 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=6.531 | 2307.0 samples/s | 36.0 steps/s
[Step=33950 Epoch=321.7] | Loss=0.00056 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.364 | L2-Norm(final)=6.533 | 4264.9 samples/s | 66.6 steps/s
[Step=34000 Epoch=322.2] | Loss=0.00054 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.360 | L2-Norm(final)=6.535 | 2383.4 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step34000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=304.4] | Loss=0.00014 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.124 | L2-Norm(final)=6.712 | 5471.8 samples/s | 85.5 steps/s
[Step=32050 Epoch=304.9] | Loss=0.00017 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.134 | L2-Norm(final)=6.723 | 4053.1 samples/s | 63.3 steps/s
[Step=32100 Epoch=305.4] | Loss=0.00012 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.142 | L2-Norm(final)=6.736 | 7232.8 samples/s | 113.0 steps/s
[Step=32150 Epoch=305.8] | Loss=0.00010 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.146 | L2-Norm(final)=6.748 | 2095.4 samples/s | 32.7 steps/s
[Step=32200 Epoch=306.3] | Loss=0.00009 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.149 | L2-Norm(final)=6.758 | 6661.4 samples/s | 104.1 steps/s
[Step=32250 Epoch=306.8] | Loss=0.00008 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.151 | L2-Norm(final)=6.769 | 2227.9 samples/s | 34.8 steps/s
[Step=32300 Epoch=307.3] | Loss=0.00007 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.153 | L2-Norm(final)=6.778 | 5935.9 samples/s | 92.7 steps/s
[Step=32350 Epoch=307.7] | Loss=0.00007 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.154 | L2-Norm(final)=6.788 | 2307.8 samples/s | 36.1 steps/s
[Step=32400 Epoch=308.2] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.155 | L2-Norm(final)=6.797 | 5303.3 samples/s | 82.9 steps/s
[Step=32450 Epoch=308.7] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.155 | L2-Norm(final)=6.806 | 2328.2 samples/s | 36.4 steps/s
[Step=32500 Epoch=309.2] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.156 | L2-Norm(final)=6.815 | 4857.1 samples/s | 75.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=309.2] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.159 | L2-Norm(final)=6.903 | 5685.2 samples/s | 88.8 steps/s
[Step=32550 Epoch=309.6] | Loss=0.00003 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.151 | L2-Norm(final)=6.910 | 3568.1 samples/s | 55.8 steps/s
[Step=32600 Epoch=310.1] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=6.916 | 6390.2 samples/s | 99.8 steps/s
[Step=32650 Epoch=310.6] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.127 | L2-Norm(final)=6.921 | 2031.5 samples/s | 31.7 steps/s
[Step=32700 Epoch=311.1] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=6.923 | 5470.9 samples/s | 85.5 steps/s
[Step=32750 Epoch=311.5] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.096 | L2-Norm(final)=6.926 | 2074.2 samples/s | 32.4 steps/s
[Step=32800 Epoch=312.0] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.080 | L2-Norm(final)=6.928 | 5127.3 samples/s | 80.1 steps/s
[Step=32850 Epoch=312.5] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.065 | L2-Norm(final)=6.930 | 2214.2 samples/s | 34.6 steps/s
[Step=32900 Epoch=313.0] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.048 | L2-Norm(final)=6.931 | 4596.8 samples/s | 71.8 steps/s
[Step=32950 Epoch=313.4] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.032 | L2-Norm(final)=6.933 | 2259.3 samples/s | 35.3 steps/s
[Step=33000 Epoch=313.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.016 | L2-Norm(final)=6.934 | 4311.9 samples/s | 67.4 steps/s
[Step=33050 Epoch=314.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.000 | L2-Norm(final)=6.936 | 2350.9 samples/s | 36.7 steps/s
[Step=33100 Epoch=314.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=6.937 | 4198.6 samples/s | 65.6 steps/s
[Step=33150 Epoch=315.3] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.966 | L2-Norm(final)=6.938 | 2404.3 samples/s | 37.6 steps/s
[Step=33200 Epoch=315.8] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.950 | L2-Norm(final)=6.940 | 4270.0 samples/s | 66.7 steps/s
[Step=33250 Epoch=316.3] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.933 | L2-Norm(final)=6.941 | 2364.0 samples/s | 36.9 steps/s
[Step=33300 Epoch=316.8] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.916 | L2-Norm(final)=6.942 | 4263.5 samples/s | 66.6 steps/s
[Step=33350 Epoch=317.2] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.899 | L2-Norm(final)=6.944 | 2449.5 samples/s | 38.3 steps/s
[Step=33400 Epoch=317.7] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.882 | L2-Norm(final)=6.945 | 4174.2 samples/s | 65.2 steps/s
[Step=33450 Epoch=318.2] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.864 | L2-Norm(final)=6.946 | 6377.8 samples/s | 99.7 steps/s
[Step=33500 Epoch=318.7] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.847 | L2-Norm(final)=6.947 | 1986.6 samples/s | 31.0 steps/s
[Step=33550 Epoch=319.1] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.829 | L2-Norm(final)=6.948 | 5907.3 samples/s | 92.3 steps/s
[Step=33600 Epoch=319.6] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=6.950 | 2047.1 samples/s | 32.0 steps/s
[Step=33650 Epoch=320.1] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.794 | L2-Norm(final)=6.951 | 5254.3 samples/s | 82.1 steps/s
[Step=33700 Epoch=320.6] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.776 | L2-Norm(final)=6.952 | 2122.1 samples/s | 33.2 steps/s
[Step=33750 Epoch=321.0] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.758 | L2-Norm(final)=6.953 | 4888.4 samples/s | 76.4 steps/s
[Step=33800 Epoch=321.5] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=6.955 | 2222.7 samples/s | 34.7 steps/s
[Step=33850 Epoch=322.0] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.721 | L2-Norm(final)=6.956 | 4448.4 samples/s | 69.5 steps/s
[Step=33900 Epoch=322.5] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.703 | L2-Norm(final)=6.957 | 2282.5 samples/s | 35.7 steps/s
[Step=33950 Epoch=322.9] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=6.958 | 4230.8 samples/s | 66.1 steps/s
[Step=34000 Epoch=323.4] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.666 | L2-Norm(final)=6.960 | 2411.1 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step34000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=305.6] | Loss=0.00181 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.268 | L2-Norm(final)=6.707 | 5175.7 samples/s | 80.9 steps/s
[Step=32050 Epoch=306.1] | Loss=0.00026 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.282 | L2-Norm(final)=6.710 | 4127.0 samples/s | 64.5 steps/s
[Step=32100 Epoch=306.5] | Loss=0.00019 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.284 | L2-Norm(final)=6.715 | 7546.5 samples/s | 117.9 steps/s
[Step=32150 Epoch=307.0] | Loss=0.00014 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=6.719 | 2089.9 samples/s | 32.7 steps/s
[Step=32200 Epoch=307.5] | Loss=0.00013 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.723 | 6734.4 samples/s | 105.2 steps/s
[Step=32250 Epoch=308.0] | Loss=0.00011 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.726 | 2164.6 samples/s | 33.8 steps/s
[Step=32300 Epoch=308.4] | Loss=0.00010 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.729 | 6224.4 samples/s | 97.3 steps/s
[Step=32350 Epoch=308.9] | Loss=0.00009 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.732 | 2260.6 samples/s | 35.3 steps/s
[Step=32400 Epoch=309.4] | Loss=0.00008 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.735 | 5638.4 samples/s | 88.1 steps/s
[Step=32450 Epoch=309.9] | Loss=0.00008 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.286 | L2-Norm(final)=6.738 | 2380.2 samples/s | 37.2 steps/s
[Step=32500 Epoch=310.4] | Loss=0.00007 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=6.741 | 5053.5 samples/s | 79.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=310.4] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=6.767 | 5640.5 samples/s | 88.1 steps/s
[Step=32550 Epoch=310.8] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.279 | L2-Norm(final)=6.770 | 3702.2 samples/s | 57.8 steps/s
[Step=32600 Epoch=311.3] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.274 | L2-Norm(final)=6.771 | 6149.8 samples/s | 96.1 steps/s
[Step=32650 Epoch=311.8] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=6.773 | 2015.5 samples/s | 31.5 steps/s
[Step=32700 Epoch=312.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.264 | L2-Norm(final)=6.774 | 5821.9 samples/s | 91.0 steps/s
[Step=32750 Epoch=312.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=6.774 | 2023.3 samples/s | 31.6 steps/s
[Step=32800 Epoch=313.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=6.775 | 5376.5 samples/s | 84.0 steps/s
[Step=32850 Epoch=313.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=6.776 | 2136.3 samples/s | 33.4 steps/s
[Step=32900 Epoch=314.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.239 | L2-Norm(final)=6.776 | 4937.4 samples/s | 77.1 steps/s
[Step=32950 Epoch=314.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.232 | L2-Norm(final)=6.777 | 2203.2 samples/s | 34.4 steps/s
[Step=33000 Epoch=315.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.226 | L2-Norm(final)=6.777 | 4572.9 samples/s | 71.5 steps/s
[Step=33050 Epoch=315.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=6.777 | 2254.9 samples/s | 35.2 steps/s
[Step=33100 Epoch=316.1] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.778 | 4365.5 samples/s | 68.2 steps/s
[Step=33150 Epoch=316.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.205 | L2-Norm(final)=6.778 | 2337.7 samples/s | 36.5 steps/s
[Step=33200 Epoch=317.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.198 | L2-Norm(final)=6.779 | 4385.6 samples/s | 68.5 steps/s
[Step=33250 Epoch=317.5] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.779 | 2345.1 samples/s | 36.6 steps/s
[Step=33300 Epoch=318.0] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.184 | L2-Norm(final)=6.779 | 4204.3 samples/s | 65.7 steps/s
[Step=33350 Epoch=318.5] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.177 | L2-Norm(final)=6.780 | 2370.1 samples/s | 37.0 steps/s
[Step=33400 Epoch=318.9] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.169 | L2-Norm(final)=6.780 | 4221.1 samples/s | 66.0 steps/s
[Step=33450 Epoch=319.4] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.162 | L2-Norm(final)=6.780 | 2385.3 samples/s | 37.3 steps/s
[Step=33500 Epoch=319.9] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.155 | L2-Norm(final)=6.781 | 4165.0 samples/s | 65.1 steps/s
[Step=33550 Epoch=320.4] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.147 | L2-Norm(final)=6.781 | 7076.3 samples/s | 110.6 steps/s
[Step=33600 Epoch=320.9] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=6.781 | 1932.7 samples/s | 30.2 steps/s
[Step=33650 Epoch=321.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=6.782 | 6368.9 samples/s | 99.5 steps/s
[Step=33700 Epoch=321.8] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.124 | L2-Norm(final)=6.782 | 2015.3 samples/s | 31.5 steps/s
[Step=33750 Epoch=322.3] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.116 | L2-Norm(final)=6.782 | 5737.1 samples/s | 89.6 steps/s
[Step=33800 Epoch=322.8] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.109 | L2-Norm(final)=6.783 | 2082.1 samples/s | 32.5 steps/s
[Step=33850 Epoch=323.2] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=6.783 | 5214.3 samples/s | 81.5 steps/s
[Step=33900 Epoch=323.7] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.093 | L2-Norm(final)=6.783 | 2104.9 samples/s | 32.9 steps/s
[Step=33950 Epoch=324.2] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.085 | L2-Norm(final)=6.784 | 4984.6 samples/s | 77.9 steps/s
[Step=34000 Epoch=324.7] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.077 | L2-Norm(final)=6.784 | 2205.0 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step34000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=301.5] | Loss=0.00060 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.329 | L2-Norm(final)=6.502 | 5127.1 samples/s | 80.1 steps/s
[Step=32050 Epoch=302.0] | Loss=0.00031 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.339 | L2-Norm(final)=6.509 | 4387.5 samples/s | 68.6 steps/s
[Step=32100 Epoch=302.5] | Loss=0.00022 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.349 | L2-Norm(final)=6.516 | 6881.4 samples/s | 107.5 steps/s
[Step=32150 Epoch=302.9] | Loss=0.00017 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.353 | L2-Norm(final)=6.522 | 2138.9 samples/s | 33.4 steps/s
[Step=32200 Epoch=303.4] | Loss=0.00014 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.355 | L2-Norm(final)=6.528 | 6357.3 samples/s | 99.3 steps/s
[Step=32250 Epoch=303.9] | Loss=0.00013 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.356 | L2-Norm(final)=6.534 | 2265.0 samples/s | 35.4 steps/s
[Step=32300 Epoch=304.4] | Loss=0.00011 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.539 | 5587.5 samples/s | 87.3 steps/s
[Step=32350 Epoch=304.8] | Loss=0.00010 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.544 | 2450.2 samples/s | 38.3 steps/s
[Step=32400 Epoch=305.3] | Loss=0.00010 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.550 | 4785.5 samples/s | 74.8 steps/s
[Step=32450 Epoch=305.8] | Loss=0.00009 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=6.555 | 2438.7 samples/s | 38.1 steps/s
[Step=32500 Epoch=306.2] | Loss=0.00008 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.356 | L2-Norm(final)=6.559 | 4818.8 samples/s | 75.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=306.3] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.350 | L2-Norm(final)=6.607 | 4866.6 samples/s | 76.0 steps/s
[Step=32550 Epoch=306.7] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.349 | L2-Norm(final)=6.612 | 4017.2 samples/s | 62.8 steps/s
[Step=32600 Epoch=307.2] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.343 | L2-Norm(final)=6.615 | 6261.7 samples/s | 97.8 steps/s
[Step=32650 Epoch=307.7] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.336 | L2-Norm(final)=6.617 | 2025.1 samples/s | 31.6 steps/s
[Step=32700 Epoch=308.1] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.327 | L2-Norm(final)=6.619 | 5532.8 samples/s | 86.5 steps/s
[Step=32750 Epoch=308.6] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.319 | L2-Norm(final)=6.621 | 2114.2 samples/s | 33.0 steps/s
[Step=32800 Epoch=309.1] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.311 | L2-Norm(final)=6.622 | 4857.5 samples/s | 75.9 steps/s
[Step=32850 Epoch=309.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.302 | L2-Norm(final)=6.624 | 2271.8 samples/s | 35.5 steps/s
[Step=32900 Epoch=310.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=6.625 | 4351.2 samples/s | 68.0 steps/s
[Step=32950 Epoch=310.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=6.626 | 2315.5 samples/s | 36.2 steps/s
[Step=33000 Epoch=311.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.276 | L2-Norm(final)=6.627 | 4322.2 samples/s | 67.5 steps/s
[Step=33050 Epoch=311.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.267 | L2-Norm(final)=6.628 | 2351.4 samples/s | 36.7 steps/s
[Step=33100 Epoch=311.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=6.629 | 4193.9 samples/s | 65.5 steps/s
[Step=33150 Epoch=312.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.249 | L2-Norm(final)=6.630 | 2396.3 samples/s | 37.4 steps/s
[Step=33200 Epoch=312.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.239 | L2-Norm(final)=6.631 | 4204.4 samples/s | 65.7 steps/s
[Step=33250 Epoch=313.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.230 | L2-Norm(final)=6.632 | 2687.8 samples/s | 42.0 steps/s
[Step=33300 Epoch=313.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.221 | L2-Norm(final)=6.633 | 3476.1 samples/s | 54.3 steps/s
[Step=33350 Epoch=314.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=6.634 | 6206.8 samples/s | 97.0 steps/s
[Step=33400 Epoch=314.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.202 | L2-Norm(final)=6.635 | 1996.6 samples/s | 31.2 steps/s
[Step=33450 Epoch=315.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=6.636 | 5593.5 samples/s | 87.4 steps/s
[Step=33500 Epoch=315.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.182 | L2-Norm(final)=6.637 | 2113.2 samples/s | 33.0 steps/s
[Step=33550 Epoch=316.1] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.173 | L2-Norm(final)=6.638 | 5049.4 samples/s | 78.9 steps/s
[Step=33600 Epoch=316.6] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.163 | L2-Norm(final)=6.639 | 2217.5 samples/s | 34.6 steps/s
[Step=33650 Epoch=317.1] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.153 | L2-Norm(final)=6.640 | 4437.4 samples/s | 69.3 steps/s
[Step=33700 Epoch=317.6] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=6.641 | 2300.5 samples/s | 35.9 steps/s
[Step=33750 Epoch=318.0] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.133 | L2-Norm(final)=6.642 | 4323.2 samples/s | 67.5 steps/s
[Step=33800 Epoch=318.5] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.122 | L2-Norm(final)=6.643 | 2377.9 samples/s | 37.2 steps/s
[Step=33850 Epoch=319.0] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=6.644 | 4411.4 samples/s | 68.9 steps/s
[Step=33900 Epoch=319.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=6.645 | 2322.4 samples/s | 36.3 steps/s
[Step=33950 Epoch=319.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.091 | L2-Norm(final)=6.646 | 4207.5 samples/s | 65.7 steps/s
[Step=34000 Epoch=320.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.080 | L2-Norm(final)=6.647 | 2578.9 samples/s | 40.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step34000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=305.0] | Loss=0.00016 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=7.497 | 4886.9 samples/s | 76.4 steps/s
[Step=32050 Epoch=305.5] | Loss=0.00030 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=7.509 | 4237.4 samples/s | 66.2 steps/s
[Step=32100 Epoch=305.9] | Loss=0.00024 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.279 | L2-Norm(final)=7.522 | 7454.4 samples/s | 116.5 steps/s
[Step=32150 Epoch=306.4] | Loss=0.00020 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.289 | L2-Norm(final)=7.533 | 2130.8 samples/s | 33.3 steps/s
[Step=32200 Epoch=306.9] | Loss=0.00018 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.296 | L2-Norm(final)=7.544 | 6690.0 samples/s | 104.5 steps/s
[Step=32250 Epoch=307.4] | Loss=0.00016 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.302 | L2-Norm(final)=7.553 | 2168.9 samples/s | 33.9 steps/s
[Step=32300 Epoch=307.8] | Loss=0.00014 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.306 | L2-Norm(final)=7.562 | 6227.7 samples/s | 97.3 steps/s
[Step=32350 Epoch=308.3] | Loss=0.00013 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.310 | L2-Norm(final)=7.571 | 2260.8 samples/s | 35.3 steps/s
[Step=32400 Epoch=308.8] | Loss=0.00012 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.313 | L2-Norm(final)=7.579 | 5602.7 samples/s | 87.5 steps/s
[Step=32450 Epoch=309.3] | Loss=0.00012 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.315 | L2-Norm(final)=7.587 | 2347.7 samples/s | 36.7 steps/s
[Step=32500 Epoch=309.8] | Loss=0.00011 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.317 | L2-Norm(final)=7.595 | 5173.9 samples/s | 80.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=309.8] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.336 | L2-Norm(final)=7.671 | 5221.9 samples/s | 81.6 steps/s
[Step=32550 Epoch=310.2] | Loss=0.00004 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.333 | L2-Norm(final)=7.676 | 3818.0 samples/s | 59.7 steps/s
[Step=32600 Epoch=310.7] | Loss=0.00869 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.402 | L2-Norm(final)=7.672 | 6256.4 samples/s | 97.8 steps/s
[Step=32650 Epoch=311.2] | Loss=0.00705 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.524 | L2-Norm(final)=7.655 | 1989.3 samples/s | 31.1 steps/s
[Step=32700 Epoch=311.7] | Loss=0.00539 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.590 | L2-Norm(final)=7.647 | 5871.4 samples/s | 91.7 steps/s
[Step=32750 Epoch=312.1] | Loss=0.00433 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.629 | L2-Norm(final)=7.643 | 2050.0 samples/s | 32.0 steps/s
[Step=32800 Epoch=312.6] | Loss=0.00361 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.655 | L2-Norm(final)=7.640 | 5314.9 samples/s | 83.0 steps/s
[Step=32850 Epoch=313.1] | Loss=0.00310 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.672 | L2-Norm(final)=7.638 | 2136.6 samples/s | 33.4 steps/s
[Step=32900 Epoch=313.6] | Loss=0.00272 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.685 | L2-Norm(final)=7.637 | 4996.1 samples/s | 78.1 steps/s
[Step=32950 Epoch=314.0] | Loss=0.00242 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.694 | L2-Norm(final)=7.637 | 2201.4 samples/s | 34.4 steps/s
[Step=33000 Epoch=314.5] | Loss=0.00218 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.701 | L2-Norm(final)=7.636 | 4626.3 samples/s | 72.3 steps/s
[Step=33050 Epoch=315.0] | Loss=0.00198 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.706 | L2-Norm(final)=7.636 | 2307.3 samples/s | 36.1 steps/s
[Step=33100 Epoch=315.5] | Loss=0.00182 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.710 | L2-Norm(final)=7.636 | 4175.3 samples/s | 65.2 steps/s
[Step=33150 Epoch=315.9] | Loss=0.00168 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.712 | L2-Norm(final)=7.636 | 2330.3 samples/s | 36.4 steps/s
[Step=33200 Epoch=316.4] | Loss=0.00156 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.714 | L2-Norm(final)=7.636 | 4230.6 samples/s | 66.1 steps/s
[Step=33250 Epoch=316.9] | Loss=0.00146 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.715 | L2-Norm(final)=7.636 | 2400.3 samples/s | 37.5 steps/s
[Step=33300 Epoch=317.4] | Loss=0.00137 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.716 | L2-Norm(final)=7.636 | 4224.0 samples/s | 66.0 steps/s
[Step=33350 Epoch=317.9] | Loss=0.00129 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.716 | L2-Norm(final)=7.636 | 2377.7 samples/s | 37.2 steps/s
[Step=33400 Epoch=318.3] | Loss=0.00121 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.716 | L2-Norm(final)=7.636 | 4242.0 samples/s | 66.3 steps/s
[Step=33450 Epoch=318.8] | Loss=0.00115 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.716 | L2-Norm(final)=7.636 | 2401.5 samples/s | 37.5 steps/s
[Step=33500 Epoch=319.3] | Loss=0.00109 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.715 | L2-Norm(final)=7.636 | 4207.9 samples/s | 65.7 steps/s
[Step=33550 Epoch=319.8] | Loss=0.00104 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.714 | L2-Norm(final)=7.636 | 6981.7 samples/s | 109.1 steps/s
[Step=33600 Epoch=320.2] | Loss=0.00100 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.712 | L2-Norm(final)=7.637 | 1949.3 samples/s | 30.5 steps/s
[Step=33650 Epoch=320.7] | Loss=0.00095 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.711 | L2-Norm(final)=7.637 | 6397.0 samples/s | 100.0 steps/s
[Step=33700 Epoch=321.2] | Loss=0.00091 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.709 | L2-Norm(final)=7.637 | 1974.7 samples/s | 30.9 steps/s
[Step=33750 Epoch=321.7] | Loss=0.00088 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.707 | L2-Norm(final)=7.637 | 5816.0 samples/s | 90.9 steps/s
[Step=33800 Epoch=322.1] | Loss=0.00084 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.706 | L2-Norm(final)=7.638 | 2072.0 samples/s | 32.4 steps/s
[Step=33850 Epoch=322.6] | Loss=0.00081 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.703 | L2-Norm(final)=7.638 | 5416.5 samples/s | 84.6 steps/s
[Step=33900 Epoch=323.1] | Loss=0.00078 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.701 | L2-Norm(final)=7.638 | 2144.4 samples/s | 33.5 steps/s
[Step=33950 Epoch=323.6] | Loss=0.00076 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.699 | L2-Norm(final)=7.638 | 4859.5 samples/s | 75.9 steps/s
[Step=34000 Epoch=324.1] | Loss=0.00073 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.696 | L2-Norm(final)=7.638 | 2180.1 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11475 | acc=0.9517 | tpr=0.9555 | fpr=0.0565 | 4887.6 samples/s | 19.1 steps/s
Avg test loss: 0.12190, Avg test acc: 0.94976, Avg tpr: 0.95401, Avg fpr: 0.05961, total FA: 465

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13163 | acc=0.9554 | tpr=0.9783 | fpr=0.0944 | 4843.1 samples/s | 18.9 steps/s
Avg test loss: 0.13455, Avg test acc: 0.95408, Avg tpr: 0.97680, Avg fpr: 0.09589, total FA: 748

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.12430 | acc=0.9539 | tpr=0.9716 | fpr=0.0845 | 4833.7 samples/s | 18.9 steps/s
Avg test loss: 0.12621, Avg test acc: 0.95260, Avg tpr: 0.97074, Avg fpr: 0.08730, total FA: 681

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.13469 | acc=0.9555 | tpr=0.9783 | fpr=0.0942 | 5119.3 samples/s | 20.0 steps/s
Avg test loss: 0.13792, Avg test acc: 0.95432, Avg tpr: 0.97803, Avg fpr: 0.09781, total FA: 763

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11579 | acc=0.9552 | tpr=0.9718 | fpr=0.0810 | 4682.9 samples/s | 18.3 steps/s
Avg test loss: 0.12076, Avg test acc: 0.95528, Avg tpr: 0.97278, Avg fpr: 0.08319, total FA: 649

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.91105 | acc=0.2977 | tpr=0.0165 | fpr=0.0919 | 4675.6 samples/s | 18.3 steps/s
Avg test loss: 4.91994, Avg test acc: 0.29662, Avg tpr: 0.01778, Avg fpr: 0.09012, total FA: 703

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.79702 | acc=0.2901 | tpr=0.0063 | fpr=0.0937 | 4835.7 samples/s | 18.9 steps/s
Avg test loss: 4.81760, Avg test acc: 0.28768, Avg tpr: 0.00618, Avg fpr: 0.09319, total FA: 727

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.97106 | acc=0.2688 | tpr=0.0251 | fpr=0.2019 | 4775.9 samples/s | 18.7 steps/s
Avg test loss: 5.97391, Avg test acc: 0.26693, Avg tpr: 0.02506, Avg fpr: 0.20113, total FA: 1569

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=6.12542 | acc=0.2848 | tpr=0.0185 | fpr=0.1368 | 4654.2 samples/s | 18.2 steps/s
Avg test loss: 6.12316, Avg test acc: 0.28292, Avg tpr: 0.01900, Avg fpr: 0.13665, total FA: 1066

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.09443 | acc=0.3039 | tpr=0.0264 | fpr=0.0934 | 4845.1 samples/s | 18.9 steps/s
Avg test loss: 5.10036, Avg test acc: 0.30299, Avg tpr: 0.02838, Avg fpr: 0.09306, total FA: 726

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.15617 | acc=0.1211 | tpr=0.5841 | fpr=0.8872 | 4735.0 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.13591 | acc=0.1233 | tpr=0.5501 | fpr=0.8846 | 6904.7 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.14403 | acc=0.1243 | tpr=0.5504 | fpr=0.8836 | 8400.2 samples/s | 32.8 steps/s
[Step= 200] | Loss=5.14308 | acc=0.1245 | tpr=0.5475 | fpr=0.8832 | 7696.1 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.15020 | acc=0.1253 | tpr=0.5406 | fpr=0.8822 | 7885.3 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.14688 | acc=0.1255 | tpr=0.5425 | fpr=0.8821 | 7658.0 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.14475 | acc=0.1257 | tpr=0.5479 | fpr=0.8819 | 8198.2 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.14015 | acc=0.1265 | tpr=0.5470 | fpr=0.8811 | 7775.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.14393 | acc=0.1265 | tpr=0.5501 | fpr=0.8812 | 7769.1 samples/s | 30.3 steps/s
[Step= 500] | Loss=5.14618 | acc=0.1261 | tpr=0.5502 | fpr=0.8816 | 7856.8 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.14897 | acc=0.1259 | tpr=0.5464 | fpr=0.8817 | 14368.5 samples/s | 56.1 steps/s
Avg test loss: 5.15026, Avg test acc: 0.12584, Avg tpr: 0.54675, Avg fpr: 0.88181, total FA: 122438

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.90431 | acc=0.0830 | tpr=0.6150 | fpr=0.9266 | 4717.0 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.87821 | acc=0.0829 | tpr=0.6205 | fpr=0.9271 | 7237.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.88936 | acc=0.0849 | tpr=0.6427 | fpr=0.9254 | 8005.3 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.87691 | acc=0.0848 | tpr=0.6306 | fpr=0.9251 | 7927.7 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.88465 | acc=0.0848 | tpr=0.6297 | fpr=0.9251 | 7750.0 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.87913 | acc=0.0847 | tpr=0.6269 | fpr=0.9252 | 7769.2 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.87059 | acc=0.0850 | tpr=0.6249 | fpr=0.9248 | 8028.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.86590 | acc=0.0854 | tpr=0.6286 | fpr=0.9245 | 7719.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.86898 | acc=0.0855 | tpr=0.6285 | fpr=0.9244 | 7852.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.87288 | acc=0.0850 | tpr=0.6220 | fpr=0.9247 | 8069.1 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.87395 | acc=0.0851 | tpr=0.6232 | fpr=0.9247 | 14239.2 samples/s | 55.6 steps/s
Avg test loss: 5.87651, Avg test acc: 0.08500, Avg tpr: 0.62361, Avg fpr: 0.92479, total FA: 128405

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.10659 | acc=0.0751 | tpr=0.5088 | fpr=0.9327 | 4855.8 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.09189 | acc=0.0761 | tpr=0.4968 | fpr=0.9318 | 6844.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.09443 | acc=0.0768 | tpr=0.4928 | fpr=0.9309 | 8005.1 samples/s | 31.3 steps/s
[Step= 200] | Loss=6.09212 | acc=0.0761 | tpr=0.4863 | fpr=0.9314 | 7906.7 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.09651 | acc=0.0766 | tpr=0.4821 | fpr=0.9308 | 7750.3 samples/s | 30.3 steps/s
[Step= 300] | Loss=6.09469 | acc=0.0761 | tpr=0.4916 | fpr=0.9315 | 8233.7 samples/s | 32.2 steps/s
[Step= 350] | Loss=6.08772 | acc=0.0764 | tpr=0.4922 | fpr=0.9312 | 7658.8 samples/s | 29.9 steps/s
[Step= 400] | Loss=6.08084 | acc=0.0764 | tpr=0.4852 | fpr=0.9310 | 7815.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.08214 | acc=0.0771 | tpr=0.4888 | fpr=0.9304 | 7810.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.08233 | acc=0.0767 | tpr=0.4850 | fpr=0.9306 | 7902.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.08649 | acc=0.0763 | tpr=0.4807 | fpr=0.9311 | 14028.7 samples/s | 54.8 steps/s
Avg test loss: 6.08770, Avg test acc: 0.07620, Avg tpr: 0.48177, Avg fpr: 0.93117, total FA: 129291

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.25036 | acc=0.0977 | tpr=0.6726 | fpr=0.9127 | 4720.9 samples/s | 18.4 steps/s
[Step= 100] | Loss=6.24875 | acc=0.0975 | tpr=0.6525 | fpr=0.9128 | 7171.0 samples/s | 28.0 steps/s
[Step= 150] | Loss=6.25582 | acc=0.0975 | tpr=0.6556 | fpr=0.9128 | 7770.5 samples/s | 30.4 steps/s
[Step= 200] | Loss=6.24628 | acc=0.0963 | tpr=0.6481 | fpr=0.9137 | 7956.5 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.25182 | acc=0.0970 | tpr=0.6463 | fpr=0.9130 | 7910.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.24408 | acc=0.0970 | tpr=0.6436 | fpr=0.9130 | 8047.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.23752 | acc=0.0970 | tpr=0.6450 | fpr=0.9129 | 7714.6 samples/s | 30.1 steps/s
[Step= 400] | Loss=6.23333 | acc=0.0975 | tpr=0.6433 | fpr=0.9125 | 7916.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=6.23998 | acc=0.0974 | tpr=0.6422 | fpr=0.9125 | 7772.7 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.24281 | acc=0.0969 | tpr=0.6396 | fpr=0.9129 | 7897.7 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.24474 | acc=0.0967 | tpr=0.6363 | fpr=0.9132 | 13878.8 samples/s | 54.2 steps/s
Avg test loss: 6.24550, Avg test acc: 0.09660, Avg tpr: 0.63629, Avg fpr: 0.91321, total FA: 126798

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.83391 | acc=0.1174 | tpr=0.6062 | fpr=0.8914 | 4737.9 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.82476 | acc=0.1175 | tpr=0.5928 | fpr=0.8914 | 7104.6 samples/s | 27.8 steps/s
[Step= 150] | Loss=5.82693 | acc=0.1172 | tpr=0.5850 | fpr=0.8914 | 7817.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.82518 | acc=0.1166 | tpr=0.5770 | fpr=0.8917 | 7969.0 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.83481 | acc=0.1168 | tpr=0.5686 | fpr=0.8914 | 7866.3 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.83398 | acc=0.1167 | tpr=0.5753 | fpr=0.8916 | 7736.1 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.82757 | acc=0.1165 | tpr=0.5773 | fpr=0.8919 | 7951.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.82478 | acc=0.1169 | tpr=0.5755 | fpr=0.8915 | 8042.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.82882 | acc=0.1168 | tpr=0.5740 | fpr=0.8915 | 7955.1 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.83376 | acc=0.1167 | tpr=0.5727 | fpr=0.8916 | 7834.3 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.83655 | acc=0.1166 | tpr=0.5754 | fpr=0.8917 | 14132.1 samples/s | 55.2 steps/s
Avg test loss: 5.83869, Avg test acc: 0.11656, Avg tpr: 0.57528, Avg fpr: 0.89177, total FA: 123821

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11355 | acc=0.9795 | tpr=0.9425 | fpr=0.0198 | 4788.3 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.11692 | acc=0.9795 | tpr=0.9446 | fpr=0.0199 | 7209.7 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.12353 | acc=0.9781 | tpr=0.9424 | fpr=0.0212 | 7613.3 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.12493 | acc=0.9784 | tpr=0.9475 | fpr=0.0210 | 7903.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.12259 | acc=0.9786 | tpr=0.9450 | fpr=0.0208 | 8014.9 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.12531 | acc=0.9784 | tpr=0.9425 | fpr=0.0209 | 7922.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.12668 | acc=0.9781 | tpr=0.9443 | fpr=0.0213 | 7734.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.12769 | acc=0.9778 | tpr=0.9387 | fpr=0.0215 | 7937.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.13014 | acc=0.9774 | tpr=0.9367 | fpr=0.0219 | 7776.4 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.12887 | acc=0.9776 | tpr=0.9383 | fpr=0.0217 | 7990.9 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.12852 | acc=0.9777 | tpr=0.9367 | fpr=0.0215 | 13819.3 samples/s | 54.0 steps/s
Avg test loss: 0.12830, Avg test acc: 0.97775, Avg tpr: 0.93661, Avg fpr: 0.02151, total FA: 2986

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09879 | acc=0.9827 | tpr=0.9159 | fpr=0.0161 | 4735.0 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.10367 | acc=0.9821 | tpr=0.9062 | fpr=0.0165 | 7093.7 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.10742 | acc=0.9815 | tpr=0.9063 | fpr=0.0171 | 8172.3 samples/s | 31.9 steps/s
[Step= 200] | Loss=0.11022 | acc=0.9813 | tpr=0.9082 | fpr=0.0173 | 7707.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.10842 | acc=0.9815 | tpr=0.9048 | fpr=0.0171 | 7730.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.11115 | acc=0.9811 | tpr=0.9040 | fpr=0.0175 | 8086.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.11152 | acc=0.9810 | tpr=0.9080 | fpr=0.0176 | 7829.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.11273 | acc=0.9808 | tpr=0.9026 | fpr=0.0178 | 7765.7 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.11519 | acc=0.9804 | tpr=0.9012 | fpr=0.0181 | 8082.6 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11438 | acc=0.9806 | tpr=0.9040 | fpr=0.0180 | 7751.7 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.11422 | acc=0.9807 | tpr=0.9025 | fpr=0.0178 | 14140.0 samples/s | 55.2 steps/s
Avg test loss: 0.11410, Avg test acc: 0.98077, Avg tpr: 0.90293, Avg fpr: 0.01782, total FA: 2474

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10878 | acc=0.9799 | tpr=0.9558 | fpr=0.0196 | 4842.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.11277 | acc=0.9795 | tpr=0.9552 | fpr=0.0201 | 7387.8 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.11711 | acc=0.9786 | tpr=0.9553 | fpr=0.0210 | 7375.1 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.11958 | acc=0.9788 | tpr=0.9574 | fpr=0.0209 | 7898.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.11803 | acc=0.9787 | tpr=0.9563 | fpr=0.0209 | 7663.2 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.12073 | acc=0.9785 | tpr=0.9498 | fpr=0.0210 | 8116.8 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.12151 | acc=0.9783 | tpr=0.9505 | fpr=0.0212 | 7714.7 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.12278 | acc=0.9781 | tpr=0.9491 | fpr=0.0214 | 8056.5 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.12466 | acc=0.9780 | tpr=0.9479 | fpr=0.0214 | 7971.1 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12401 | acc=0.9781 | tpr=0.9498 | fpr=0.0214 | 7814.8 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.12357 | acc=0.9783 | tpr=0.9491 | fpr=0.0212 | 13761.1 samples/s | 53.8 steps/s
Avg test loss: 0.12351, Avg test acc: 0.97827, Avg tpr: 0.94929, Avg fpr: 0.02120, total FA: 2944

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10446 | acc=0.9818 | tpr=0.9381 | fpr=0.0174 | 4726.4 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.11011 | acc=0.9810 | tpr=0.9318 | fpr=0.0181 | 7247.3 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.11508 | acc=0.9799 | tpr=0.9337 | fpr=0.0193 | 7896.3 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.11699 | acc=0.9801 | tpr=0.9410 | fpr=0.0192 | 7355.6 samples/s | 28.7 steps/s
[Step= 250] | Loss=0.11528 | acc=0.9805 | tpr=0.9389 | fpr=0.0188 | 8626.8 samples/s | 33.7 steps/s
[Step= 300] | Loss=0.11813 | acc=0.9801 | tpr=0.9360 | fpr=0.0191 | 7672.8 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.11857 | acc=0.9801 | tpr=0.9386 | fpr=0.0191 | 7854.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.11918 | acc=0.9800 | tpr=0.9354 | fpr=0.0192 | 7957.9 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.12144 | acc=0.9797 | tpr=0.9348 | fpr=0.0195 | 8216.6 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.12048 | acc=0.9799 | tpr=0.9374 | fpr=0.0193 | 7679.6 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.12020 | acc=0.9800 | tpr=0.9367 | fpr=0.0192 | 13838.4 samples/s | 54.1 steps/s
Avg test loss: 0.12008, Avg test acc: 0.97997, Avg tpr: 0.93661, Avg fpr: 0.01924, total FA: 2671

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10443 | acc=0.9779 | tpr=0.9204 | fpr=0.0211 | 4800.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.10724 | acc=0.9782 | tpr=0.9254 | fpr=0.0209 | 7140.3 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.11185 | acc=0.9773 | tpr=0.9337 | fpr=0.0219 | 7765.1 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.11362 | acc=0.9771 | tpr=0.9388 | fpr=0.0222 | 7716.0 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.11260 | acc=0.9774 | tpr=0.9328 | fpr=0.0218 | 8130.6 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.11426 | acc=0.9773 | tpr=0.9280 | fpr=0.0218 | 7782.7 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.11577 | acc=0.9769 | tpr=0.9267 | fpr=0.0221 | 7983.1 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.11717 | acc=0.9767 | tpr=0.9234 | fpr=0.0224 | 7668.2 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.11959 | acc=0.9763 | tpr=0.9216 | fpr=0.0227 | 7940.7 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.11866 | acc=0.9764 | tpr=0.9229 | fpr=0.0226 | 7966.2 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.11818 | acc=0.9765 | tpr=0.9212 | fpr=0.0225 | 13539.1 samples/s | 52.9 steps/s
Avg test loss: 0.11795, Avg test acc: 0.97654, Avg tpr: 0.92155, Avg fpr: 0.02246, total FA: 3118

server round 17/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=165.8] | Loss=0.00805 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.409 | L2-Norm(final)=11.088 | 5146.7 samples/s | 80.4 steps/s
[Step=34050 Epoch=166.0] | Loss=0.00656 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.413 | L2-Norm(final)=11.095 | 4580.2 samples/s | 71.6 steps/s
[Step=34100 Epoch=166.3] | Loss=0.00506 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.417 | L2-Norm(final)=11.110 | 5030.3 samples/s | 78.6 steps/s
[Step=34150 Epoch=166.5] | Loss=0.00483 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.418 | L2-Norm(final)=11.125 | 5048.8 samples/s | 78.9 steps/s
[Step=34200 Epoch=166.8] | Loss=0.00470 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.417 | L2-Norm(final)=11.139 | 7837.3 samples/s | 122.5 steps/s
[Step=34250 Epoch=167.0] | Loss=0.00447 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.415 | L2-Norm(final)=11.153 | 2191.0 samples/s | 34.2 steps/s
[Step=34300 Epoch=167.3] | Loss=0.00432 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.411 | L2-Norm(final)=11.166 | 4985.0 samples/s | 77.9 steps/s
[Step=34350 Epoch=167.5] | Loss=0.00424 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.407 | L2-Norm(final)=11.179 | 4974.3 samples/s | 77.7 steps/s
[Step=34400 Epoch=167.7] | Loss=0.00408 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.404 | L2-Norm(final)=11.191 | 7012.1 samples/s | 109.6 steps/s
[Step=34450 Epoch=168.0] | Loss=0.00394 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.400 | L2-Norm(final)=11.204 | 2296.3 samples/s | 35.9 steps/s
[Step=34500 Epoch=168.2] | Loss=0.00381 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.395 | L2-Norm(final)=11.216 | 5098.2 samples/s | 79.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=168.2] | Loss=0.01034 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.350 | L2-Norm(final)=11.337 | 5715.1 samples/s | 89.3 steps/s
[Step=34550 Epoch=168.5] | Loss=0.00758 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.349 | L2-Norm(final)=11.345 | 3895.6 samples/s | 60.9 steps/s
[Step=34600 Epoch=168.7] | Loss=0.00771 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.360 | L2-Norm(final)=11.347 | 4475.2 samples/s | 69.9 steps/s
[Step=34650 Epoch=169.0] | Loss=0.01022 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.384 | L2-Norm(final)=11.352 | 4342.8 samples/s | 67.9 steps/s
[Step=34700 Epoch=169.2] | Loss=0.01250 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.421 | L2-Norm(final)=11.356 | 6494.2 samples/s | 101.5 steps/s
[Step=34750 Epoch=169.4] | Loss=0.01389 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.457 | L2-Norm(final)=11.360 | 2117.1 samples/s | 33.1 steps/s
[Step=34800 Epoch=169.7] | Loss=0.01489 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.491 | L2-Norm(final)=11.364 | 4542.9 samples/s | 71.0 steps/s
[Step=34850 Epoch=169.9] | Loss=0.01512 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.523 | L2-Norm(final)=11.368 | 4357.0 samples/s | 68.1 steps/s
[Step=34900 Epoch=170.2] | Loss=0.01504 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.552 | L2-Norm(final)=11.373 | 5901.3 samples/s | 92.2 steps/s
[Step=34950 Epoch=170.4] | Loss=0.01413 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.578 | L2-Norm(final)=11.379 | 2159.2 samples/s | 33.7 steps/s
[Step=35000 Epoch=170.7] | Loss=0.01361 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.600 | L2-Norm(final)=11.384 | 4450.8 samples/s | 69.5 steps/s
[Step=35050 Epoch=170.9] | Loss=0.01314 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.619 | L2-Norm(final)=11.389 | 4436.6 samples/s | 69.3 steps/s
[Step=35100 Epoch=171.2] | Loss=0.01284 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.635 | L2-Norm(final)=11.394 | 5375.7 samples/s | 84.0 steps/s
[Step=35150 Epoch=171.4] | Loss=0.01248 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.650 | L2-Norm(final)=11.399 | 2245.6 samples/s | 35.1 steps/s
[Step=35200 Epoch=171.6] | Loss=0.01180 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.663 | L2-Norm(final)=11.403 | 4473.2 samples/s | 69.9 steps/s
[Step=35250 Epoch=171.9] | Loss=0.01146 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.674 | L2-Norm(final)=11.407 | 4431.0 samples/s | 69.2 steps/s
[Step=35300 Epoch=172.1] | Loss=0.01126 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.684 | L2-Norm(final)=11.411 | 4980.8 samples/s | 77.8 steps/s
[Step=35350 Epoch=172.4] | Loss=0.01093 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.693 | L2-Norm(final)=11.415 | 2323.5 samples/s | 36.3 steps/s
[Step=35400 Epoch=172.6] | Loss=0.01053 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.700 | L2-Norm(final)=11.418 | 4483.8 samples/s | 70.1 steps/s
[Step=35450 Epoch=172.9] | Loss=0.01016 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.706 | L2-Norm(final)=11.422 | 4483.8 samples/s | 70.1 steps/s
[Step=35500 Epoch=173.1] | Loss=0.00988 | Reg=0.00389 | acc=0.9844 | L2-Norm=19.712 | L2-Norm(final)=11.425 | 4568.8 samples/s | 71.4 steps/s
[Step=35550 Epoch=173.3] | Loss=0.00964 | Reg=0.00389 | acc=0.9844 | L2-Norm=19.716 | L2-Norm(final)=11.428 | 2423.6 samples/s | 37.9 steps/s
[Step=35600 Epoch=173.6] | Loss=0.00932 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.719 | L2-Norm(final)=11.432 | 4562.9 samples/s | 71.3 steps/s
[Step=35650 Epoch=173.8] | Loss=0.00905 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.721 | L2-Norm(final)=11.435 | 4394.3 samples/s | 68.7 steps/s
[Step=35700 Epoch=174.1] | Loss=0.00878 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.722 | L2-Norm(final)=11.437 | 4424.9 samples/s | 69.1 steps/s
[Step=35750 Epoch=174.3] | Loss=0.00860 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.722 | L2-Norm(final)=11.440 | 2478.0 samples/s | 38.7 steps/s
[Step=35800 Epoch=174.6] | Loss=0.00835 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.722 | L2-Norm(final)=11.443 | 4449.9 samples/s | 69.5 steps/s
[Step=35850 Epoch=174.8] | Loss=0.00814 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.721 | L2-Norm(final)=11.445 | 4502.4 samples/s | 70.3 steps/s
[Step=35900 Epoch=175.1] | Loss=0.00796 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.719 | L2-Norm(final)=11.448 | 4448.0 samples/s | 69.5 steps/s
[Step=35950 Epoch=175.3] | Loss=0.00782 | Reg=0.00389 | acc=0.9844 | L2-Norm=19.717 | L2-Norm(final)=11.450 | 2455.9 samples/s | 38.4 steps/s
[Step=36000 Epoch=175.5] | Loss=0.00761 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.714 | L2-Norm(final)=11.452 | 4444.3 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step36000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=165.9] | Loss=0.00379 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=11.136 | 5038.7 samples/s | 78.7 steps/s
[Step=34050 Epoch=166.1] | Loss=0.00344 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=11.150 | 4573.4 samples/s | 71.5 steps/s
[Step=34100 Epoch=166.4] | Loss=0.00304 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.400 | L2-Norm(final)=11.165 | 5087.4 samples/s | 79.5 steps/s
[Step=34150 Epoch=166.6] | Loss=0.00335 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.396 | L2-Norm(final)=11.178 | 5052.6 samples/s | 78.9 steps/s
[Step=34200 Epoch=166.9] | Loss=0.00352 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.391 | L2-Norm(final)=11.189 | 7862.1 samples/s | 122.8 steps/s
[Step=34250 Epoch=167.1] | Loss=0.00327 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.386 | L2-Norm(final)=11.201 | 2214.1 samples/s | 34.6 steps/s
[Step=34300 Epoch=167.4] | Loss=0.00316 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.380 | L2-Norm(final)=11.214 | 5049.8 samples/s | 78.9 steps/s
[Step=34350 Epoch=167.6] | Loss=0.00311 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.375 | L2-Norm(final)=11.226 | 5084.8 samples/s | 79.4 steps/s
[Step=34400 Epoch=167.9] | Loss=0.00321 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.369 | L2-Norm(final)=11.238 | 6996.1 samples/s | 109.3 steps/s
[Step=34450 Epoch=168.1] | Loss=0.00312 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.365 | L2-Norm(final)=11.249 | 2232.8 samples/s | 34.9 steps/s
[Step=34500 Epoch=168.3] | Loss=0.00311 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.359 | L2-Norm(final)=11.261 | 5047.5 samples/s | 78.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=168.3] | Loss=0.00137 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.306 | L2-Norm(final)=11.378 | 5506.8 samples/s | 86.0 steps/s
[Step=34550 Epoch=168.6] | Loss=0.00341 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.302 | L2-Norm(final)=11.385 | 4160.8 samples/s | 65.0 steps/s
[Step=34600 Epoch=168.8] | Loss=0.00482 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.303 | L2-Norm(final)=11.390 | 4552.4 samples/s | 71.1 steps/s
[Step=34650 Epoch=169.1] | Loss=0.00639 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.308 | L2-Norm(final)=11.396 | 4396.4 samples/s | 68.7 steps/s
[Step=34700 Epoch=169.3] | Loss=0.00898 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.328 | L2-Norm(final)=11.401 | 6578.1 samples/s | 102.8 steps/s
[Step=34750 Epoch=169.6] | Loss=0.01141 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.361 | L2-Norm(final)=11.407 | 2058.4 samples/s | 32.2 steps/s
[Step=34800 Epoch=169.8] | Loss=0.01210 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.396 | L2-Norm(final)=11.413 | 4454.7 samples/s | 69.6 steps/s
[Step=34850 Epoch=170.1] | Loss=0.01241 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.432 | L2-Norm(final)=11.419 | 4466.5 samples/s | 69.8 steps/s
[Step=34900 Epoch=170.3] | Loss=0.01290 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.466 | L2-Norm(final)=11.425 | 6072.1 samples/s | 94.9 steps/s
[Step=34950 Epoch=170.5] | Loss=0.01255 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.496 | L2-Norm(final)=11.430 | 2151.1 samples/s | 33.6 steps/s
[Step=35000 Epoch=170.8] | Loss=0.01219 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.523 | L2-Norm(final)=11.435 | 4472.5 samples/s | 69.9 steps/s
[Step=35050 Epoch=171.0] | Loss=0.01174 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.544 | L2-Norm(final)=11.440 | 4440.8 samples/s | 69.4 steps/s
[Step=35100 Epoch=171.3] | Loss=0.01133 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.563 | L2-Norm(final)=11.445 | 5495.2 samples/s | 85.9 steps/s
[Step=35150 Epoch=171.5] | Loss=0.01103 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.578 | L2-Norm(final)=11.450 | 2175.2 samples/s | 34.0 steps/s
[Step=35200 Epoch=171.8] | Loss=0.01063 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.591 | L2-Norm(final)=11.454 | 4467.4 samples/s | 69.8 steps/s
[Step=35250 Epoch=172.0] | Loss=0.01018 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.601 | L2-Norm(final)=11.459 | 4471.0 samples/s | 69.9 steps/s
[Step=35300 Epoch=172.2] | Loss=0.00981 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.610 | L2-Norm(final)=11.463 | 5238.6 samples/s | 81.9 steps/s
[Step=35350 Epoch=172.5] | Loss=0.00935 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.617 | L2-Norm(final)=11.467 | 2255.3 samples/s | 35.2 steps/s
[Step=35400 Epoch=172.7] | Loss=0.00903 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.622 | L2-Norm(final)=11.471 | 4465.9 samples/s | 69.8 steps/s
[Step=35450 Epoch=173.0] | Loss=0.00876 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.625 | L2-Norm(final)=11.474 | 4371.6 samples/s | 68.3 steps/s
[Step=35500 Epoch=173.2] | Loss=0.00849 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.628 | L2-Norm(final)=11.477 | 4882.3 samples/s | 76.3 steps/s
[Step=35550 Epoch=173.5] | Loss=0.00827 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.630 | L2-Norm(final)=11.481 | 2347.2 samples/s | 36.7 steps/s
[Step=35600 Epoch=173.7] | Loss=0.00801 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.630 | L2-Norm(final)=11.484 | 4510.3 samples/s | 70.5 steps/s
[Step=35650 Epoch=174.0] | Loss=0.00782 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.630 | L2-Norm(final)=11.487 | 4470.8 samples/s | 69.9 steps/s
[Step=35700 Epoch=174.2] | Loss=0.00764 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.629 | L2-Norm(final)=11.489 | 4596.7 samples/s | 71.8 steps/s
[Step=35750 Epoch=174.4] | Loss=0.00742 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.628 | L2-Norm(final)=11.492 | 2442.9 samples/s | 38.2 steps/s
[Step=35800 Epoch=174.7] | Loss=0.00732 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.626 | L2-Norm(final)=11.495 | 4357.1 samples/s | 68.1 steps/s
[Step=35850 Epoch=174.9] | Loss=0.00715 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.624 | L2-Norm(final)=11.497 | 4534.5 samples/s | 70.9 steps/s
[Step=35900 Epoch=175.2] | Loss=0.00704 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.621 | L2-Norm(final)=11.500 | 4442.8 samples/s | 69.4 steps/s
[Step=35950 Epoch=175.4] | Loss=0.00687 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.618 | L2-Norm(final)=11.502 | 2470.0 samples/s | 38.6 steps/s
[Step=36000 Epoch=175.7] | Loss=0.00673 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.614 | L2-Norm(final)=11.504 | 4429.2 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step36000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=165.7] | Loss=0.00381 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.705 | L2-Norm(final)=11.635 | 5261.2 samples/s | 82.2 steps/s
[Step=34050 Epoch=165.9] | Loss=0.00479 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.706 | L2-Norm(final)=11.645 | 4491.0 samples/s | 70.2 steps/s
[Step=34100 Epoch=166.2] | Loss=0.00438 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.702 | L2-Norm(final)=11.658 | 4940.4 samples/s | 77.2 steps/s
[Step=34150 Epoch=166.4] | Loss=0.00421 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.699 | L2-Norm(final)=11.670 | 5063.5 samples/s | 79.1 steps/s
[Step=34200 Epoch=166.6] | Loss=0.00412 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.696 | L2-Norm(final)=11.682 | 7577.1 samples/s | 118.4 steps/s
[Step=34250 Epoch=166.9] | Loss=0.00394 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.693 | L2-Norm(final)=11.695 | 2241.4 samples/s | 35.0 steps/s
[Step=34300 Epoch=167.1] | Loss=0.00382 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.690 | L2-Norm(final)=11.707 | 5027.1 samples/s | 78.5 steps/s
[Step=34350 Epoch=167.4] | Loss=0.00383 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.687 | L2-Norm(final)=11.719 | 5180.7 samples/s | 80.9 steps/s
[Step=34400 Epoch=167.6] | Loss=0.00381 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.683 | L2-Norm(final)=11.731 | 6713.0 samples/s | 104.9 steps/s
[Step=34450 Epoch=167.9] | Loss=0.00377 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.678 | L2-Norm(final)=11.743 | 2293.8 samples/s | 35.8 steps/s
[Step=34500 Epoch=168.1] | Loss=0.00377 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.674 | L2-Norm(final)=11.754 | 4935.8 samples/s | 77.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=168.1] | Loss=0.00019 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.628 | L2-Norm(final)=11.870 | 5498.3 samples/s | 85.9 steps/s
[Step=34550 Epoch=168.3] | Loss=0.00443 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.626 | L2-Norm(final)=11.880 | 4103.7 samples/s | 64.1 steps/s
[Step=34600 Epoch=168.6] | Loss=0.00699 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.633 | L2-Norm(final)=11.888 | 4507.4 samples/s | 70.4 steps/s
[Step=34650 Epoch=168.8] | Loss=0.00841 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.657 | L2-Norm(final)=11.897 | 4499.4 samples/s | 70.3 steps/s
[Step=34700 Epoch=169.1] | Loss=0.01042 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.683 | L2-Norm(final)=11.905 | 6537.5 samples/s | 102.1 steps/s
[Step=34750 Epoch=169.3] | Loss=0.01201 | Reg=0.00388 | acc=0.9531 | L2-Norm=19.709 | L2-Norm(final)=11.909 | 2086.6 samples/s | 32.6 steps/s
[Step=34800 Epoch=169.6] | Loss=0.01239 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.736 | L2-Norm(final)=11.911 | 4423.3 samples/s | 69.1 steps/s
[Step=34850 Epoch=169.8] | Loss=0.01250 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.760 | L2-Norm(final)=11.915 | 4470.4 samples/s | 69.8 steps/s
[Step=34900 Epoch=170.0] | Loss=0.01237 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.781 | L2-Norm(final)=11.919 | 5905.0 samples/s | 92.3 steps/s
[Step=34950 Epoch=170.3] | Loss=0.01182 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.799 | L2-Norm(final)=11.924 | 2153.4 samples/s | 33.6 steps/s
[Step=35000 Epoch=170.5] | Loss=0.01168 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.815 | L2-Norm(final)=11.928 | 4581.9 samples/s | 71.6 steps/s
[Step=35050 Epoch=170.8] | Loss=0.01131 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.828 | L2-Norm(final)=11.932 | 4395.0 samples/s | 68.7 steps/s
[Step=35100 Epoch=171.0] | Loss=0.01113 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.840 | L2-Norm(final)=11.936 | 5404.9 samples/s | 84.5 steps/s
[Step=35150 Epoch=171.3] | Loss=0.01062 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.850 | L2-Norm(final)=11.941 | 2232.0 samples/s | 34.9 steps/s
[Step=35200 Epoch=171.5] | Loss=0.01020 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.859 | L2-Norm(final)=11.945 | 4455.2 samples/s | 69.6 steps/s
[Step=35250 Epoch=171.8] | Loss=0.00991 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.867 | L2-Norm(final)=11.949 | 4471.1 samples/s | 69.9 steps/s
[Step=35300 Epoch=172.0] | Loss=0.00972 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.873 | L2-Norm(final)=11.954 | 4987.0 samples/s | 77.9 steps/s
[Step=35350 Epoch=172.2] | Loss=0.00952 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.880 | L2-Norm(final)=11.958 | 2325.1 samples/s | 36.3 steps/s
[Step=35400 Epoch=172.5] | Loss=0.00921 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.885 | L2-Norm(final)=11.962 | 4511.6 samples/s | 70.5 steps/s
[Step=35450 Epoch=172.7] | Loss=0.00896 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.889 | L2-Norm(final)=11.965 | 4467.7 samples/s | 69.8 steps/s
[Step=35500 Epoch=173.0] | Loss=0.00877 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.893 | L2-Norm(final)=11.969 | 4617.7 samples/s | 72.2 steps/s
[Step=35550 Epoch=173.2] | Loss=0.00858 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.895 | L2-Norm(final)=11.972 | 2353.6 samples/s | 36.8 steps/s
[Step=35600 Epoch=173.5] | Loss=0.00834 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.897 | L2-Norm(final)=11.975 | 4460.0 samples/s | 69.7 steps/s
[Step=35650 Epoch=173.7] | Loss=0.00818 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.897 | L2-Norm(final)=11.978 | 4501.3 samples/s | 70.3 steps/s
[Step=35700 Epoch=173.9] | Loss=0.00805 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.897 | L2-Norm(final)=11.981 | 4533.1 samples/s | 70.8 steps/s
[Step=35750 Epoch=174.2] | Loss=0.00788 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.897 | L2-Norm(final)=11.984 | 2448.2 samples/s | 38.3 steps/s
[Step=35800 Epoch=174.4] | Loss=0.00770 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.896 | L2-Norm(final)=11.987 | 4436.7 samples/s | 69.3 steps/s
[Step=35850 Epoch=174.7] | Loss=0.00755 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.894 | L2-Norm(final)=11.989 | 4468.1 samples/s | 69.8 steps/s
[Step=35900 Epoch=174.9] | Loss=0.00738 | Reg=0.00396 | acc=0.9844 | L2-Norm=19.892 | L2-Norm(final)=11.992 | 4394.4 samples/s | 68.7 steps/s
[Step=35950 Epoch=175.2] | Loss=0.00722 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.890 | L2-Norm(final)=11.994 | 2456.2 samples/s | 38.4 steps/s
[Step=36000 Epoch=175.4] | Loss=0.00710 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.887 | L2-Norm(final)=11.997 | 4518.0 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step36000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=165.8] | Loss=0.00293 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.647 | L2-Norm(final)=11.428 | 5255.4 samples/s | 82.1 steps/s
[Step=34050 Epoch=166.0] | Loss=0.00375 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.646 | L2-Norm(final)=11.439 | 4479.0 samples/s | 70.0 steps/s
[Step=34100 Epoch=166.3] | Loss=0.00366 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.644 | L2-Norm(final)=11.454 | 5089.2 samples/s | 79.5 steps/s
[Step=34150 Epoch=166.5] | Loss=0.00346 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.641 | L2-Norm(final)=11.468 | 5149.6 samples/s | 80.5 steps/s
[Step=34200 Epoch=166.8] | Loss=0.00347 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.638 | L2-Norm(final)=11.481 | 7550.5 samples/s | 118.0 steps/s
[Step=34250 Epoch=167.0] | Loss=0.00341 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.635 | L2-Norm(final)=11.495 | 2190.8 samples/s | 34.2 steps/s
[Step=34300 Epoch=167.3] | Loss=0.00330 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.631 | L2-Norm(final)=11.509 | 4949.6 samples/s | 77.3 steps/s
[Step=34350 Epoch=167.5] | Loss=0.00320 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.625 | L2-Norm(final)=11.521 | 5084.2 samples/s | 79.4 steps/s
[Step=34400 Epoch=167.8] | Loss=0.00316 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.621 | L2-Norm(final)=11.534 | 6982.7 samples/s | 109.1 steps/s
[Step=34450 Epoch=168.0] | Loss=0.00306 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.616 | L2-Norm(final)=11.548 | 2284.5 samples/s | 35.7 steps/s
[Step=34500 Epoch=168.2] | Loss=0.00304 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.610 | L2-Norm(final)=11.561 | 5027.9 samples/s | 78.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=168.2] | Loss=0.00048 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.557 | L2-Norm(final)=11.693 | 5507.3 samples/s | 86.1 steps/s
[Step=34550 Epoch=168.5] | Loss=0.00300 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.553 | L2-Norm(final)=11.704 | 3990.8 samples/s | 62.4 steps/s
[Step=34600 Epoch=168.7] | Loss=0.00480 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.555 | L2-Norm(final)=11.712 | 4487.1 samples/s | 70.1 steps/s
[Step=34650 Epoch=169.0] | Loss=0.00623 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.567 | L2-Norm(final)=11.718 | 4411.8 samples/s | 68.9 steps/s
[Step=34700 Epoch=169.2] | Loss=0.00764 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.584 | L2-Norm(final)=11.727 | 6480.0 samples/s | 101.2 steps/s
[Step=34750 Epoch=169.5] | Loss=0.00812 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.602 | L2-Norm(final)=11.734 | 2090.4 samples/s | 32.7 steps/s
[Step=34800 Epoch=169.7] | Loss=0.00909 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.622 | L2-Norm(final)=11.741 | 4520.1 samples/s | 70.6 steps/s
[Step=34850 Epoch=169.9] | Loss=0.01000 | Reg=0.00386 | acc=0.9688 | L2-Norm=19.647 | L2-Norm(final)=11.746 | 4467.6 samples/s | 69.8 steps/s
[Step=34900 Epoch=170.2] | Loss=0.01090 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.671 | L2-Norm(final)=11.751 | 5885.0 samples/s | 92.0 steps/s
[Step=34950 Epoch=170.4] | Loss=0.01167 | Reg=0.00388 | acc=0.9844 | L2-Norm=19.697 | L2-Norm(final)=11.755 | 2110.6 samples/s | 33.0 steps/s
[Step=35000 Epoch=170.7] | Loss=0.01114 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.720 | L2-Norm(final)=11.760 | 4525.3 samples/s | 70.7 steps/s
[Step=35050 Epoch=170.9] | Loss=0.01114 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.740 | L2-Norm(final)=11.764 | 4441.2 samples/s | 69.4 steps/s
[Step=35100 Epoch=171.2] | Loss=0.01079 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.758 | L2-Norm(final)=11.769 | 5424.7 samples/s | 84.8 steps/s
[Step=35150 Epoch=171.4] | Loss=0.01033 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.774 | L2-Norm(final)=11.775 | 2258.1 samples/s | 35.3 steps/s
[Step=35200 Epoch=171.7] | Loss=0.01019 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.788 | L2-Norm(final)=11.780 | 4447.4 samples/s | 69.5 steps/s
[Step=35250 Epoch=171.9] | Loss=0.00991 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.800 | L2-Norm(final)=11.784 | 4422.4 samples/s | 69.1 steps/s
[Step=35300 Epoch=172.1] | Loss=0.00953 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.811 | L2-Norm(final)=11.788 | 4874.4 samples/s | 76.2 steps/s
[Step=35350 Epoch=172.4] | Loss=0.00918 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.820 | L2-Norm(final)=11.793 | 2340.0 samples/s | 36.6 steps/s
[Step=35400 Epoch=172.6] | Loss=0.00896 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.827 | L2-Norm(final)=11.797 | 4345.1 samples/s | 67.9 steps/s
[Step=35450 Epoch=172.9] | Loss=0.00871 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.833 | L2-Norm(final)=11.801 | 4495.2 samples/s | 70.2 steps/s
[Step=35500 Epoch=173.1] | Loss=0.00846 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.838 | L2-Norm(final)=11.804 | 4623.0 samples/s | 72.2 steps/s
[Step=35550 Epoch=173.4] | Loss=0.00824 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.842 | L2-Norm(final)=11.807 | 2424.5 samples/s | 37.9 steps/s
[Step=35600 Epoch=173.6] | Loss=0.00799 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.844 | L2-Norm(final)=11.811 | 4446.4 samples/s | 69.5 steps/s
[Step=35650 Epoch=173.8] | Loss=0.00783 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.846 | L2-Norm(final)=11.814 | 4433.2 samples/s | 69.3 steps/s
[Step=35700 Epoch=174.1] | Loss=0.00772 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.847 | L2-Norm(final)=11.817 | 4484.4 samples/s | 70.1 steps/s
[Step=35750 Epoch=174.3] | Loss=0.00752 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.847 | L2-Norm(final)=11.819 | 2485.2 samples/s | 38.8 steps/s
[Step=35800 Epoch=174.6] | Loss=0.00738 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.847 | L2-Norm(final)=11.822 | 4455.2 samples/s | 69.6 steps/s
[Step=35850 Epoch=174.8] | Loss=0.00721 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.846 | L2-Norm(final)=11.825 | 4486.8 samples/s | 70.1 steps/s
[Step=35900 Epoch=175.1] | Loss=0.00706 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.844 | L2-Norm(final)=11.828 | 4484.0 samples/s | 70.1 steps/s
[Step=35950 Epoch=175.3] | Loss=0.00690 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.842 | L2-Norm(final)=11.830 | 2456.6 samples/s | 38.4 steps/s
[Step=36000 Epoch=175.6] | Loss=0.00674 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.840 | L2-Norm(final)=11.833 | 4456.1 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step36000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=166.7] | Loss=0.00422 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.456 | L2-Norm(final)=11.398 | 5514.0 samples/s | 86.2 steps/s
[Step=34050 Epoch=167.0] | Loss=0.00462 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.453 | L2-Norm(final)=11.407 | 4386.7 samples/s | 68.5 steps/s
[Step=34100 Epoch=167.2] | Loss=0.00428 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.450 | L2-Norm(final)=11.420 | 5072.7 samples/s | 79.3 steps/s
[Step=34150 Epoch=167.5] | Loss=0.00412 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.447 | L2-Norm(final)=11.434 | 5083.5 samples/s | 79.4 steps/s
[Step=34200 Epoch=167.7] | Loss=0.00402 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.446 | L2-Norm(final)=11.448 | 7911.4 samples/s | 123.6 steps/s
[Step=34250 Epoch=168.0] | Loss=0.00377 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.444 | L2-Norm(final)=11.462 | 2182.9 samples/s | 34.1 steps/s
[Step=34300 Epoch=168.2] | Loss=0.00360 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.441 | L2-Norm(final)=11.476 | 4948.7 samples/s | 77.3 steps/s
[Step=34350 Epoch=168.4] | Loss=0.00345 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.437 | L2-Norm(final)=11.489 | 4995.6 samples/s | 78.1 steps/s
[Step=34400 Epoch=168.7] | Loss=0.00355 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.433 | L2-Norm(final)=11.502 | 7472.7 samples/s | 116.8 steps/s
[Step=34450 Epoch=168.9] | Loss=0.00344 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=11.515 | 2241.9 samples/s | 35.0 steps/s
[Step=34500 Epoch=169.2] | Loss=0.00343 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.426 | L2-Norm(final)=11.529 | 4966.0 samples/s | 77.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=169.2] | Loss=0.00036 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.387 | L2-Norm(final)=11.663 | 5544.7 samples/s | 86.6 steps/s
[Step=34550 Epoch=169.4] | Loss=0.00224 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.384 | L2-Norm(final)=11.674 | 4075.9 samples/s | 63.7 steps/s
[Step=34600 Epoch=169.7] | Loss=0.00297 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.380 | L2-Norm(final)=11.683 | 4492.1 samples/s | 70.2 steps/s
[Step=34650 Epoch=169.9] | Loss=0.00561 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.386 | L2-Norm(final)=11.690 | 4399.0 samples/s | 68.7 steps/s
[Step=34700 Epoch=170.2] | Loss=0.00769 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=11.694 | 6664.7 samples/s | 104.1 steps/s
[Step=34750 Epoch=170.4] | Loss=0.00827 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.422 | L2-Norm(final)=11.698 | 2082.6 samples/s | 32.5 steps/s
[Step=34800 Epoch=170.7] | Loss=0.00823 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.439 | L2-Norm(final)=11.704 | 4466.1 samples/s | 69.8 steps/s
[Step=34850 Epoch=170.9] | Loss=0.00886 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.454 | L2-Norm(final)=11.710 | 4483.1 samples/s | 70.0 steps/s
[Step=34900 Epoch=171.1] | Loss=0.00962 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.471 | L2-Norm(final)=11.714 | 6262.4 samples/s | 97.9 steps/s
[Step=34950 Epoch=171.4] | Loss=0.00926 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.486 | L2-Norm(final)=11.719 | 2117.8 samples/s | 33.1 steps/s
[Step=35000 Epoch=171.6] | Loss=0.00904 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.500 | L2-Norm(final)=11.723 | 4381.1 samples/s | 68.5 steps/s
[Step=35050 Epoch=171.9] | Loss=0.00910 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.511 | L2-Norm(final)=11.728 | 4486.6 samples/s | 70.1 steps/s
[Step=35100 Epoch=172.1] | Loss=0.00922 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.522 | L2-Norm(final)=11.732 | 5776.0 samples/s | 90.3 steps/s
[Step=35150 Epoch=172.4] | Loss=0.00927 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.532 | L2-Norm(final)=11.735 | 2160.9 samples/s | 33.8 steps/s
[Step=35200 Epoch=172.6] | Loss=0.00902 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.543 | L2-Norm(final)=11.739 | 4465.2 samples/s | 69.8 steps/s
[Step=35250 Epoch=172.9] | Loss=0.00878 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.551 | L2-Norm(final)=11.743 | 4483.8 samples/s | 70.1 steps/s
[Step=35300 Epoch=173.1] | Loss=0.00856 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.559 | L2-Norm(final)=11.747 | 5511.2 samples/s | 86.1 steps/s
[Step=35350 Epoch=173.4] | Loss=0.00842 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.566 | L2-Norm(final)=11.751 | 2196.4 samples/s | 34.3 steps/s
[Step=35400 Epoch=173.6] | Loss=0.00842 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.573 | L2-Norm(final)=11.754 | 4475.0 samples/s | 69.9 steps/s
[Step=35450 Epoch=173.8] | Loss=0.00832 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.578 | L2-Norm(final)=11.757 | 4460.1 samples/s | 69.7 steps/s
[Step=35500 Epoch=174.1] | Loss=0.00813 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.583 | L2-Norm(final)=11.760 | 5217.3 samples/s | 81.5 steps/s
[Step=35550 Epoch=174.3] | Loss=0.00810 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.587 | L2-Norm(final)=11.763 | 2292.4 samples/s | 35.8 steps/s
[Step=35600 Epoch=174.6] | Loss=0.00803 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.592 | L2-Norm(final)=11.766 | 4613.0 samples/s | 72.1 steps/s
[Step=35650 Epoch=174.8] | Loss=0.00781 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.595 | L2-Norm(final)=11.769 | 4413.1 samples/s | 69.0 steps/s
[Step=35700 Epoch=175.1] | Loss=0.00779 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.598 | L2-Norm(final)=11.772 | 4772.4 samples/s | 74.6 steps/s
[Step=35750 Epoch=175.3] | Loss=0.00759 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.600 | L2-Norm(final)=11.775 | 2340.5 samples/s | 36.6 steps/s
[Step=35800 Epoch=175.6] | Loss=0.00743 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.602 | L2-Norm(final)=11.778 | 4482.9 samples/s | 70.0 steps/s
[Step=35850 Epoch=175.8] | Loss=0.00731 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.603 | L2-Norm(final)=11.781 | 4451.7 samples/s | 69.6 steps/s
[Step=35900 Epoch=176.0] | Loss=0.00715 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.604 | L2-Norm(final)=11.784 | 4708.9 samples/s | 73.6 steps/s
[Step=35950 Epoch=176.3] | Loss=0.00704 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.604 | L2-Norm(final)=11.787 | 2376.9 samples/s | 37.1 steps/s
[Step=36000 Epoch=176.5] | Loss=0.00692 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.603 | L2-Norm(final)=11.790 | 4512.5 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step36000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=322.2] | Loss=0.00009 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.113 | L2-Norm(final)=6.593 | 4832.4 samples/s | 75.5 steps/s
[Step=34050 Epoch=322.7] | Loss=0.00006 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=6.600 | 4408.1 samples/s | 68.9 steps/s
[Step=34100 Epoch=323.1] | Loss=0.00012 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.126 | L2-Norm(final)=6.604 | 7404.3 samples/s | 115.7 steps/s
[Step=34150 Epoch=323.6] | Loss=0.00009 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.138 | L2-Norm(final)=6.609 | 2133.4 samples/s | 33.3 steps/s
[Step=34200 Epoch=324.1] | Loss=0.00008 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.142 | L2-Norm(final)=6.612 | 6514.0 samples/s | 101.8 steps/s
[Step=34250 Epoch=324.5] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=6.615 | 2220.8 samples/s | 34.7 steps/s
[Step=34300 Epoch=325.0] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=6.618 | 5959.5 samples/s | 93.1 steps/s
[Step=34350 Epoch=325.5] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=6.620 | 2316.3 samples/s | 36.2 steps/s
[Step=34400 Epoch=326.0] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=6.622 | 5192.9 samples/s | 81.1 steps/s
[Step=34450 Epoch=326.4] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.142 | L2-Norm(final)=6.624 | 2399.8 samples/s | 37.5 steps/s
[Step=34500 Epoch=326.9] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.141 | L2-Norm(final)=6.626 | 4834.2 samples/s | 75.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=326.9] | Loss=0.00009 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.129 | L2-Norm(final)=6.647 | 5130.6 samples/s | 80.2 steps/s
[Step=34550 Epoch=327.4] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.125 | L2-Norm(final)=6.649 | 3919.2 samples/s | 61.2 steps/s
[Step=34600 Epoch=327.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.119 | L2-Norm(final)=6.651 | 6159.5 samples/s | 96.2 steps/s
[Step=34650 Epoch=328.3] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=6.652 | 1983.3 samples/s | 31.0 steps/s
[Step=34700 Epoch=328.8] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=6.653 | 5603.5 samples/s | 87.6 steps/s
[Step=34750 Epoch=329.3] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.098 | L2-Norm(final)=6.654 | 2101.7 samples/s | 32.8 steps/s
[Step=34800 Epoch=329.8] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.092 | L2-Norm(final)=6.655 | 5036.8 samples/s | 78.7 steps/s
[Step=34850 Epoch=330.2] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.085 | L2-Norm(final)=6.656 | 2192.3 samples/s | 34.3 steps/s
[Step=34900 Epoch=330.7] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=6.656 | 4624.4 samples/s | 72.3 steps/s
[Step=34950 Epoch=331.2] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.071 | L2-Norm(final)=6.657 | 2225.8 samples/s | 34.8 steps/s
[Step=35000 Epoch=331.7] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.064 | L2-Norm(final)=6.658 | 4367.6 samples/s | 68.2 steps/s
[Step=35050 Epoch=332.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.057 | L2-Norm(final)=6.659 | 2356.8 samples/s | 36.8 steps/s
[Step=35100 Epoch=332.6] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.050 | L2-Norm(final)=6.659 | 4327.5 samples/s | 67.6 steps/s
[Step=35150 Epoch=333.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.043 | L2-Norm(final)=6.660 | 2356.1 samples/s | 36.8 steps/s
[Step=35200 Epoch=333.6] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.036 | L2-Norm(final)=6.661 | 4223.9 samples/s | 66.0 steps/s
[Step=35250 Epoch=334.0] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=6.661 | 2352.5 samples/s | 36.8 steps/s
[Step=35300 Epoch=334.5] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.022 | L2-Norm(final)=6.662 | 4305.1 samples/s | 67.3 steps/s
[Step=35350 Epoch=335.0] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.014 | L2-Norm(final)=6.662 | 2451.5 samples/s | 38.3 steps/s
[Step=35400 Epoch=335.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.007 | L2-Norm(final)=6.663 | 4089.8 samples/s | 63.9 steps/s
[Step=35450 Epoch=335.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.000 | L2-Norm(final)=6.664 | 6475.8 samples/s | 101.2 steps/s
[Step=35500 Epoch=336.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.992 | L2-Norm(final)=6.664 | 1985.0 samples/s | 31.0 steps/s
[Step=35550 Epoch=336.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.985 | L2-Norm(final)=6.665 | 5751.2 samples/s | 89.9 steps/s
[Step=35600 Epoch=337.3] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.977 | L2-Norm(final)=6.665 | 2097.4 samples/s | 32.8 steps/s
[Step=35650 Epoch=337.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.969 | L2-Norm(final)=6.666 | 5218.5 samples/s | 81.5 steps/s
[Step=35700 Epoch=338.3] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.961 | L2-Norm(final)=6.666 | 2143.0 samples/s | 33.5 steps/s
[Step=35750 Epoch=338.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.954 | L2-Norm(final)=6.667 | 4845.9 samples/s | 75.7 steps/s
[Step=35800 Epoch=339.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.946 | L2-Norm(final)=6.667 | 2228.4 samples/s | 34.8 steps/s
[Step=35850 Epoch=339.7] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.938 | L2-Norm(final)=6.668 | 4460.1 samples/s | 69.7 steps/s
[Step=35900 Epoch=340.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.930 | L2-Norm(final)=6.669 | 2314.4 samples/s | 36.2 steps/s
[Step=35950 Epoch=340.7] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.921 | L2-Norm(final)=6.669 | 4327.7 samples/s | 67.6 steps/s
[Step=36000 Epoch=341.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.913 | L2-Norm(final)=6.670 | 2397.4 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step36000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=323.4] | Loss=0.00059 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.922 | L2-Norm(final)=7.001 | 5197.9 samples/s | 81.2 steps/s
[Step=34050 Epoch=323.9] | Loss=0.00029 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.957 | L2-Norm(final)=7.040 | 4098.0 samples/s | 64.0 steps/s
[Step=34100 Epoch=324.4] | Loss=0.00023 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.994 | L2-Norm(final)=7.084 | 7557.2 samples/s | 118.1 steps/s
[Step=34150 Epoch=324.9] | Loss=0.00019 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.019 | L2-Norm(final)=7.117 | 2136.1 samples/s | 33.4 steps/s
[Step=34200 Epoch=325.3] | Loss=0.00015 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.034 | L2-Norm(final)=7.142 | 6645.3 samples/s | 103.8 steps/s
[Step=34250 Epoch=325.8] | Loss=0.00013 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.042 | L2-Norm(final)=7.161 | 2208.8 samples/s | 34.5 steps/s
[Step=34300 Epoch=326.3] | Loss=0.00011 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.047 | L2-Norm(final)=7.177 | 5923.8 samples/s | 92.6 steps/s
[Step=34350 Epoch=326.8] | Loss=0.00010 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.050 | L2-Norm(final)=7.191 | 2284.2 samples/s | 35.7 steps/s
[Step=34400 Epoch=327.2] | Loss=0.00009 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.052 | L2-Norm(final)=7.204 | 5350.9 samples/s | 83.6 steps/s
[Step=34450 Epoch=327.7] | Loss=0.00008 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.053 | L2-Norm(final)=7.217 | 2391.1 samples/s | 37.4 steps/s
[Step=34500 Epoch=328.2] | Loss=0.00008 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.053 | L2-Norm(final)=7.228 | 4953.0 samples/s | 77.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=328.2] | Loss=0.00004 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.055 | L2-Norm(final)=7.343 | 5477.5 samples/s | 85.6 steps/s
[Step=34550 Epoch=328.7] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.033 | L2-Norm(final)=7.352 | 3835.3 samples/s | 59.9 steps/s
[Step=34600 Epoch=329.1] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.000 | L2-Norm(final)=7.358 | 6262.7 samples/s | 97.9 steps/s
[Step=34650 Epoch=329.6] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.966 | L2-Norm(final)=7.361 | 1997.1 samples/s | 31.2 steps/s
[Step=34700 Epoch=330.1] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.931 | L2-Norm(final)=7.364 | 5585.6 samples/s | 87.3 steps/s
[Step=34750 Epoch=330.6] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.896 | L2-Norm(final)=7.366 | 2092.6 samples/s | 32.7 steps/s
[Step=34800 Epoch=331.0] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.860 | L2-Norm(final)=7.368 | 5126.6 samples/s | 80.1 steps/s
[Step=34850 Epoch=331.5] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.824 | L2-Norm(final)=7.370 | 2170.0 samples/s | 33.9 steps/s
[Step=34900 Epoch=332.0] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.788 | L2-Norm(final)=7.371 | 4760.7 samples/s | 74.4 steps/s
[Step=34950 Epoch=332.5] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.753 | L2-Norm(final)=7.373 | 2222.9 samples/s | 34.7 steps/s
[Step=35000 Epoch=332.9] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.717 | L2-Norm(final)=7.374 | 4391.6 samples/s | 68.6 steps/s
[Step=35050 Epoch=333.4] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.681 | L2-Norm(final)=7.375 | 2375.9 samples/s | 37.1 steps/s
[Step=35100 Epoch=333.9] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.645 | L2-Norm(final)=7.377 | 4254.7 samples/s | 66.5 steps/s
[Step=35150 Epoch=334.4] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.610 | L2-Norm(final)=7.378 | 2339.0 samples/s | 36.5 steps/s
[Step=35200 Epoch=334.8] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.574 | L2-Norm(final)=7.380 | 4248.6 samples/s | 66.4 steps/s
[Step=35250 Epoch=335.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.538 | L2-Norm(final)=7.381 | 2338.9 samples/s | 36.5 steps/s
[Step=35300 Epoch=335.8] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.502 | L2-Norm(final)=7.383 | 4309.8 samples/s | 67.3 steps/s
[Step=35350 Epoch=336.3] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.466 | L2-Norm(final)=7.384 | 2499.6 samples/s | 39.1 steps/s
[Step=35400 Epoch=336.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.430 | L2-Norm(final)=7.386 | 3915.3 samples/s | 61.2 steps/s
[Step=35450 Epoch=337.2] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.394 | L2-Norm(final)=7.388 | 6556.5 samples/s | 102.4 steps/s
[Step=35500 Epoch=337.7] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.358 | L2-Norm(final)=7.389 | 2002.3 samples/s | 31.3 steps/s
[Step=35550 Epoch=338.2] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=7.391 | 5680.2 samples/s | 88.8 steps/s
[Step=35600 Epoch=338.6] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.286 | L2-Norm(final)=7.393 | 2062.1 samples/s | 32.2 steps/s
[Step=35650 Epoch=339.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.250 | L2-Norm(final)=7.395 | 5340.2 samples/s | 83.4 steps/s
[Step=35700 Epoch=339.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.213 | L2-Norm(final)=7.397 | 2146.2 samples/s | 33.5 steps/s
[Step=35750 Epoch=340.1] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.177 | L2-Norm(final)=7.399 | 4916.2 samples/s | 76.8 steps/s
[Step=35800 Epoch=340.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.141 | L2-Norm(final)=7.401 | 2219.1 samples/s | 34.7 steps/s
[Step=35850 Epoch=341.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.104 | L2-Norm(final)=7.403 | 4457.0 samples/s | 69.6 steps/s
[Step=35900 Epoch=341.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=7.405 | 2340.4 samples/s | 36.6 steps/s
[Step=35950 Epoch=342.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.032 | L2-Norm(final)=7.407 | 4189.8 samples/s | 65.5 steps/s
[Step=36000 Epoch=342.4] | Loss=0.00030 | Reg=0.00081 | acc=0.9531 | L2-Norm=8.998 | L2-Norm(final)=7.410 | 2414.8 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step36000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=324.7] | Loss=0.00010 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.116 | L2-Norm(final)=6.794 | 5389.8 samples/s | 84.2 steps/s
[Step=34050 Epoch=325.2] | Loss=0.00009 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.121 | L2-Norm(final)=6.802 | 4219.0 samples/s | 65.9 steps/s
[Step=34100 Epoch=325.6] | Loss=0.00008 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.125 | L2-Norm(final)=6.812 | 6955.5 samples/s | 108.7 steps/s
[Step=34150 Epoch=326.1] | Loss=0.00007 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.129 | L2-Norm(final)=6.822 | 2084.8 samples/s | 32.6 steps/s
[Step=34200 Epoch=326.6] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.131 | L2-Norm(final)=6.831 | 6813.6 samples/s | 106.5 steps/s
[Step=34250 Epoch=327.1] | Loss=0.00006 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.133 | L2-Norm(final)=6.839 | 2213.0 samples/s | 34.6 steps/s
[Step=34300 Epoch=327.5] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.134 | L2-Norm(final)=6.847 | 6151.8 samples/s | 96.1 steps/s
[Step=34350 Epoch=328.0] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.135 | L2-Norm(final)=6.855 | 2257.5 samples/s | 35.3 steps/s
[Step=34400 Epoch=328.5] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.135 | L2-Norm(final)=6.863 | 5602.4 samples/s | 87.5 steps/s
[Step=34450 Epoch=329.0] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.136 | L2-Norm(final)=6.870 | 2286.6 samples/s | 35.7 steps/s
[Step=34500 Epoch=329.5] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.136 | L2-Norm(final)=6.877 | 5233.9 samples/s | 81.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=329.5] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.137 | L2-Norm(final)=6.950 | 5828.8 samples/s | 91.1 steps/s
[Step=34550 Epoch=329.9] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.128 | L2-Norm(final)=6.954 | 3668.0 samples/s | 57.3 steps/s
[Step=34600 Epoch=330.4] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.115 | L2-Norm(final)=6.959 | 6288.1 samples/s | 98.3 steps/s
[Step=34650 Epoch=330.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.103 | L2-Norm(final)=6.963 | 2031.3 samples/s | 31.7 steps/s
[Step=34700 Epoch=331.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.089 | L2-Norm(final)=6.966 | 5586.4 samples/s | 87.3 steps/s
[Step=34750 Epoch=331.8] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.075 | L2-Norm(final)=6.969 | 2059.2 samples/s | 32.2 steps/s
[Step=34800 Epoch=332.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.061 | L2-Norm(final)=6.971 | 5416.7 samples/s | 84.6 steps/s
[Step=34850 Epoch=332.8] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.046 | L2-Norm(final)=6.972 | 2152.7 samples/s | 33.6 steps/s
[Step=34900 Epoch=333.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.032 | L2-Norm(final)=6.974 | 4946.5 samples/s | 77.3 steps/s
[Step=34950 Epoch=333.8] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.017 | L2-Norm(final)=6.975 | 2198.6 samples/s | 34.4 steps/s
[Step=35000 Epoch=334.2] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.003 | L2-Norm(final)=6.977 | 4579.6 samples/s | 71.6 steps/s
[Step=35050 Epoch=334.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.988 | L2-Norm(final)=6.978 | 2285.6 samples/s | 35.7 steps/s
[Step=35100 Epoch=335.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.973 | L2-Norm(final)=6.979 | 4380.9 samples/s | 68.5 steps/s
[Step=35150 Epoch=335.7] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.958 | L2-Norm(final)=6.980 | 2358.2 samples/s | 36.8 steps/s
[Step=35200 Epoch=336.1] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.943 | L2-Norm(final)=6.981 | 4249.7 samples/s | 66.4 steps/s
[Step=35250 Epoch=336.6] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.928 | L2-Norm(final)=6.982 | 2387.2 samples/s | 37.3 steps/s
[Step=35300 Epoch=337.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.913 | L2-Norm(final)=6.983 | 4100.7 samples/s | 64.1 steps/s
[Step=35350 Epoch=337.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.898 | L2-Norm(final)=6.984 | 2395.8 samples/s | 37.4 steps/s
[Step=35400 Epoch=338.0] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.883 | L2-Norm(final)=6.985 | 4271.7 samples/s | 66.7 steps/s
[Step=35450 Epoch=338.5] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.867 | L2-Norm(final)=6.986 | 2413.1 samples/s | 37.7 steps/s
[Step=35500 Epoch=339.0] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=6.987 | 4222.8 samples/s | 66.0 steps/s
[Step=35550 Epoch=339.5] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.836 | L2-Norm(final)=6.988 | 7062.1 samples/s | 110.3 steps/s
[Step=35600 Epoch=340.0] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.820 | L2-Norm(final)=6.989 | 1953.5 samples/s | 30.5 steps/s
[Step=35650 Epoch=340.4] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.804 | L2-Norm(final)=6.990 | 6297.9 samples/s | 98.4 steps/s
[Step=35700 Epoch=340.9] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.788 | L2-Norm(final)=6.991 | 2011.6 samples/s | 31.4 steps/s
[Step=35750 Epoch=341.4] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.772 | L2-Norm(final)=6.992 | 5875.3 samples/s | 91.8 steps/s
[Step=35800 Epoch=341.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.756 | L2-Norm(final)=6.993 | 2093.4 samples/s | 32.7 steps/s
[Step=35850 Epoch=342.3] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=6.994 | 5384.0 samples/s | 84.1 steps/s
[Step=35900 Epoch=342.8] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.723 | L2-Norm(final)=6.995 | 2136.4 samples/s | 33.4 steps/s
[Step=35950 Epoch=343.3] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.707 | L2-Norm(final)=6.996 | 4963.7 samples/s | 77.6 steps/s
[Step=36000 Epoch=343.8] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=6.997 | 2216.5 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step36000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=320.4] | Loss=0.00011 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.151 | L2-Norm(final)=6.675 | 5151.5 samples/s | 80.5 steps/s
[Step=34050 Epoch=320.8] | Loss=0.00027 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.179 | L2-Norm(final)=6.698 | 4213.3 samples/s | 65.8 steps/s
[Step=34100 Epoch=321.3] | Loss=0.00018 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.194 | L2-Norm(final)=6.716 | 7346.0 samples/s | 114.8 steps/s
[Step=34150 Epoch=321.8] | Loss=0.00014 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.201 | L2-Norm(final)=6.731 | 2145.8 samples/s | 33.5 steps/s
[Step=34200 Epoch=322.3] | Loss=0.00011 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.205 | L2-Norm(final)=6.744 | 6445.5 samples/s | 100.7 steps/s
[Step=34250 Epoch=322.7] | Loss=0.00010 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.207 | L2-Norm(final)=6.755 | 2247.4 samples/s | 35.1 steps/s
[Step=34300 Epoch=323.2] | Loss=0.00009 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.764 | 5681.4 samples/s | 88.8 steps/s
[Step=34350 Epoch=323.7] | Loss=0.00008 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.774 | 2354.5 samples/s | 36.8 steps/s
[Step=34400 Epoch=324.1] | Loss=0.00007 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.783 | 5093.2 samples/s | 79.6 steps/s
[Step=34450 Epoch=324.6] | Loss=0.00007 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.792 | 2451.6 samples/s | 38.3 steps/s
[Step=34500 Epoch=325.1] | Loss=0.00006 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.207 | L2-Norm(final)=6.800 | 4760.4 samples/s | 74.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=325.1] | Loss=0.00005 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.201 | L2-Norm(final)=6.883 | 5626.0 samples/s | 87.9 steps/s
[Step=34550 Epoch=325.6] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=6.890 | 3774.2 samples/s | 59.0 steps/s
[Step=34600 Epoch=326.0] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.176 | L2-Norm(final)=6.895 | 6180.8 samples/s | 96.6 steps/s
[Step=34650 Epoch=326.5] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.159 | L2-Norm(final)=6.899 | 2034.8 samples/s | 31.8 steps/s
[Step=34700 Epoch=327.0] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.142 | L2-Norm(final)=6.903 | 5470.3 samples/s | 85.5 steps/s
[Step=34750 Epoch=327.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.123 | L2-Norm(final)=6.905 | 2107.7 samples/s | 32.9 steps/s
[Step=34800 Epoch=327.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.104 | L2-Norm(final)=6.908 | 4999.8 samples/s | 78.1 steps/s
[Step=34850 Epoch=328.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.085 | L2-Norm(final)=6.910 | 2233.1 samples/s | 34.9 steps/s
[Step=34900 Epoch=328.9] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.066 | L2-Norm(final)=6.911 | 4427.4 samples/s | 69.2 steps/s
[Step=34950 Epoch=329.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.047 | L2-Norm(final)=6.913 | 2290.9 samples/s | 35.8 steps/s
[Step=35000 Epoch=329.8] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.027 | L2-Norm(final)=6.914 | 4220.2 samples/s | 65.9 steps/s
[Step=35050 Epoch=330.3] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.007 | L2-Norm(final)=6.916 | 2388.4 samples/s | 37.3 steps/s
[Step=35100 Epoch=330.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.988 | L2-Norm(final)=6.917 | 4241.1 samples/s | 66.3 steps/s
[Step=35150 Epoch=331.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.968 | L2-Norm(final)=6.919 | 2373.9 samples/s | 37.1 steps/s
[Step=35200 Epoch=331.7] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.948 | L2-Norm(final)=6.920 | 4251.7 samples/s | 66.4 steps/s
[Step=35250 Epoch=332.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.927 | L2-Norm(final)=6.921 | 2684.4 samples/s | 41.9 steps/s
[Step=35300 Epoch=332.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.907 | L2-Norm(final)=6.923 | 3766.4 samples/s | 58.9 steps/s
[Step=35350 Epoch=333.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.887 | L2-Norm(final)=6.924 | 6230.0 samples/s | 97.3 steps/s
[Step=35400 Epoch=333.6] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.866 | L2-Norm(final)=6.925 | 2049.7 samples/s | 32.0 steps/s
[Step=35450 Epoch=334.0] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.845 | L2-Norm(final)=6.927 | 5449.0 samples/s | 85.1 steps/s
[Step=35500 Epoch=334.5] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.825 | L2-Norm(final)=6.928 | 2136.4 samples/s | 33.4 steps/s
[Step=35550 Epoch=335.0] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.804 | L2-Norm(final)=6.930 | 4903.9 samples/s | 76.6 steps/s
[Step=35600 Epoch=335.5] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.783 | L2-Norm(final)=6.931 | 2212.7 samples/s | 34.6 steps/s
[Step=35650 Epoch=335.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.932 | 4541.0 samples/s | 71.0 steps/s
[Step=35700 Epoch=336.4] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=6.934 | 2296.8 samples/s | 35.9 steps/s
[Step=35750 Epoch=336.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.719 | L2-Norm(final)=6.935 | 4250.0 samples/s | 66.4 steps/s
[Step=35800 Epoch=337.3] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.697 | L2-Norm(final)=6.937 | 2387.6 samples/s | 37.3 steps/s
[Step=35850 Epoch=337.8] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.675 | L2-Norm(final)=6.939 | 4242.3 samples/s | 66.3 steps/s
[Step=35900 Epoch=338.3] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.654 | L2-Norm(final)=6.940 | 2390.0 samples/s | 37.3 steps/s
[Step=35950 Epoch=338.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.632 | L2-Norm(final)=6.942 | 4254.6 samples/s | 66.5 steps/s
[Step=36000 Epoch=339.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.609 | L2-Norm(final)=6.944 | 2533.8 samples/s | 39.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step36000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=324.1] | Loss=0.00063 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.361 | L2-Norm(final)=7.646 | 5669.7 samples/s | 88.6 steps/s
[Step=34050 Epoch=324.5] | Loss=0.00019 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.368 | L2-Norm(final)=7.649 | 3927.7 samples/s | 61.4 steps/s
[Step=34100 Epoch=325.0] | Loss=0.00023 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.370 | L2-Norm(final)=7.654 | 7527.9 samples/s | 117.6 steps/s
[Step=34150 Epoch=325.5] | Loss=0.00019 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.374 | L2-Norm(final)=7.660 | 2119.0 samples/s | 33.1 steps/s
[Step=34200 Epoch=326.0] | Loss=0.00016 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.375 | L2-Norm(final)=7.664 | 6757.9 samples/s | 105.6 steps/s
[Step=34250 Epoch=326.4] | Loss=0.00014 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.667 | 2214.2 samples/s | 34.6 steps/s
[Step=34300 Epoch=326.9] | Loss=0.00013 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.670 | 6093.3 samples/s | 95.2 steps/s
[Step=34350 Epoch=327.4] | Loss=0.00012 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.674 | 2256.3 samples/s | 35.3 steps/s
[Step=34400 Epoch=327.9] | Loss=0.00011 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.677 | 5654.6 samples/s | 88.4 steps/s
[Step=34450 Epoch=328.3] | Loss=0.00010 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.680 | 2355.7 samples/s | 36.8 steps/s
[Step=34500 Epoch=328.8] | Loss=0.00010 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.376 | L2-Norm(final)=7.683 | 5237.2 samples/s | 81.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=328.8] | Loss=0.00004 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.373 | L2-Norm(final)=7.711 | 5577.5 samples/s | 87.1 steps/s
[Step=34550 Epoch=329.3] | Loss=0.00004 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.370 | L2-Norm(final)=7.713 | 3693.1 samples/s | 57.7 steps/s
[Step=34600 Epoch=329.8] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=7.715 | 6236.4 samples/s | 97.4 steps/s
[Step=34650 Epoch=330.2] | Loss=0.00003 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.362 | L2-Norm(final)=7.717 | 1999.2 samples/s | 31.2 steps/s
[Step=34700 Epoch=330.7] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=7.718 | 5824.5 samples/s | 91.0 steps/s
[Step=34750 Epoch=331.2] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.352 | L2-Norm(final)=7.719 | 2052.1 samples/s | 32.1 steps/s
[Step=34800 Epoch=331.7] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.347 | L2-Norm(final)=7.720 | 5337.1 samples/s | 83.4 steps/s
[Step=34850 Epoch=332.2] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.342 | L2-Norm(final)=7.721 | 2138.7 samples/s | 33.4 steps/s
[Step=34900 Epoch=332.6] | Loss=0.00002 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.337 | L2-Norm(final)=7.722 | 4886.3 samples/s | 76.3 steps/s
[Step=34950 Epoch=333.1] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=7.723 | 2199.9 samples/s | 34.4 steps/s
[Step=35000 Epoch=333.6] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.326 | L2-Norm(final)=7.724 | 4635.2 samples/s | 72.4 steps/s
[Step=35050 Epoch=334.1] | Loss=0.00001 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.320 | L2-Norm(final)=7.724 | 2290.4 samples/s | 35.8 steps/s
[Step=35100 Epoch=334.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.314 | L2-Norm(final)=7.725 | 4263.5 samples/s | 66.6 steps/s
[Step=35150 Epoch=335.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.308 | L2-Norm(final)=7.726 | 2338.4 samples/s | 36.5 steps/s
[Step=35200 Epoch=335.5] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=7.726 | 4240.5 samples/s | 66.3 steps/s
[Step=35250 Epoch=336.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=7.727 | 2366.0 samples/s | 37.0 steps/s
[Step=35300 Epoch=336.4] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=7.727 | 4313.0 samples/s | 67.4 steps/s
[Step=35350 Epoch=336.9] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.284 | L2-Norm(final)=7.728 | 2375.3 samples/s | 37.1 steps/s
[Step=35400 Epoch=337.4] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.278 | L2-Norm(final)=7.729 | 4168.8 samples/s | 65.1 steps/s
[Step=35450 Epoch=337.9] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=7.729 | 2402.3 samples/s | 37.5 steps/s
[Step=35500 Epoch=338.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.265 | L2-Norm(final)=7.730 | 4242.1 samples/s | 66.3 steps/s
[Step=35550 Epoch=338.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.259 | L2-Norm(final)=7.730 | 7055.2 samples/s | 110.2 steps/s
[Step=35600 Epoch=339.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=7.731 | 1944.6 samples/s | 30.4 steps/s
[Step=35650 Epoch=339.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=7.731 | 6367.6 samples/s | 99.5 steps/s
[Step=35700 Epoch=340.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.239 | L2-Norm(final)=7.732 | 2012.8 samples/s | 31.4 steps/s
[Step=35750 Epoch=340.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.232 | L2-Norm(final)=7.733 | 5839.2 samples/s | 91.2 steps/s
[Step=35800 Epoch=341.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.225 | L2-Norm(final)=7.733 | 2100.9 samples/s | 32.8 steps/s
[Step=35850 Epoch=341.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=7.734 | 5336.9 samples/s | 83.4 steps/s
[Step=35900 Epoch=342.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=7.734 | 2141.0 samples/s | 33.5 steps/s
[Step=35950 Epoch=342.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.204 | L2-Norm(final)=7.735 | 4940.4 samples/s | 77.2 steps/s
[Step=36000 Epoch=343.1] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.197 | L2-Norm(final)=7.736 | 2205.8 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12805 | acc=0.9573 | tpr=0.9728 | fpr=0.0763 | 4702.7 samples/s | 18.4 steps/s
Avg test loss: 0.13184, Avg test acc: 0.95601, Avg tpr: 0.97313, Avg fpr: 0.08166, total FA: 637

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12952 | acc=0.9544 | tpr=0.9642 | fpr=0.0669 | 4901.3 samples/s | 19.1 steps/s
Avg test loss: 0.13132, Avg test acc: 0.95228, Avg tpr: 0.96165, Avg fpr: 0.06832, total FA: 533

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.12625 | acc=0.9573 | tpr=0.9734 | fpr=0.0778 | 4847.4 samples/s | 18.9 steps/s
Avg test loss: 0.12847, Avg test acc: 0.95537, Avg tpr: 0.97132, Avg fpr: 0.07973, total FA: 622

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.12725 | acc=0.9565 | tpr=0.9675 | fpr=0.0674 | 4946.6 samples/s | 19.3 steps/s
Avg test loss: 0.13360, Avg test acc: 0.95520, Avg tpr: 0.96736, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.12585 | acc=0.9583 | tpr=0.9720 | fpr=0.0716 | 4820.8 samples/s | 18.8 steps/s
Avg test loss: 0.12955, Avg test acc: 0.95745, Avg tpr: 0.97167, Avg fpr: 0.07384, total FA: 576

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.69084 | acc=0.2798 | tpr=0.0248 | fpr=0.1663 | 4830.2 samples/s | 18.9 steps/s
Avg test loss: 5.69316, Avg test acc: 0.28035, Avg tpr: 0.02675, Avg fpr: 0.16190, total FA: 1263

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=3.42901 | acc=0.3124 | tpr=0.0013 | fpr=0.0119 | 4698.9 samples/s | 18.4 steps/s
Avg test loss: 3.44200, Avg test acc: 0.30940, Avg tpr: 0.00152, Avg fpr: 0.01346, total FA: 105

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.54447 | acc=0.2710 | tpr=0.0209 | fpr=0.1858 | 4807.0 samples/s | 18.8 steps/s
Avg test loss: 5.54539, Avg test acc: 0.26877, Avg tpr: 0.02075, Avg fpr: 0.18575, total FA: 1449

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.63528 | acc=0.2907 | tpr=0.0195 | fpr=0.1204 | 4858.7 samples/s | 19.0 steps/s
Avg test loss: 5.63497, Avg test acc: 0.28844, Avg tpr: 0.01935, Avg fpr: 0.11973, total FA: 934

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.24663 | acc=0.2936 | tpr=0.0301 | fpr=0.1343 | 4549.8 samples/s | 17.8 steps/s
Avg test loss: 5.25825, Avg test acc: 0.29297, Avg tpr: 0.03147, Avg fpr: 0.13191, total FA: 1029

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.69931 | acc=0.0859 | tpr=0.6150 | fpr=0.9236 | 4769.6 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.68690 | acc=0.0885 | tpr=0.5885 | fpr=0.9208 | 7133.1 samples/s | 27.9 steps/s
[Step= 150] | Loss=6.68942 | acc=0.0901 | tpr=0.5735 | fpr=0.9188 | 7769.5 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.68988 | acc=0.0900 | tpr=0.5650 | fpr=0.9187 | 7685.3 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.70147 | acc=0.0900 | tpr=0.5633 | fpr=0.9186 | 7663.0 samples/s | 29.9 steps/s
[Step= 300] | Loss=6.69156 | acc=0.0899 | tpr=0.5680 | fpr=0.9188 | 8010.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=6.69470 | acc=0.0902 | tpr=0.5723 | fpr=0.9185 | 7596.7 samples/s | 29.7 steps/s
[Step= 400] | Loss=6.68601 | acc=0.0906 | tpr=0.5684 | fpr=0.9180 | 6202.0 samples/s | 24.2 steps/s
[Step= 450] | Loss=6.69045 | acc=0.0904 | tpr=0.5667 | fpr=0.9182 | 7726.4 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.69559 | acc=0.0904 | tpr=0.5626 | fpr=0.9181 | 8011.2 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.69966 | acc=0.0904 | tpr=0.5623 | fpr=0.9182 | 13813.1 samples/s | 54.0 steps/s
Avg test loss: 6.70108, Avg test acc: 0.09035, Avg tpr: 0.56300, Avg fpr: 0.91824, total FA: 127496

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.07983 | acc=0.1114 | tpr=0.5442 | fpr=0.8964 | 4760.9 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.05708 | acc=0.1119 | tpr=0.5437 | fpr=0.8962 | 7069.6 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.06716 | acc=0.1122 | tpr=0.5375 | fpr=0.8957 | 7726.9 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.06017 | acc=0.1124 | tpr=0.5213 | fpr=0.8950 | 7138.7 samples/s | 27.9 steps/s
[Step= 250] | Loss=5.07098 | acc=0.1122 | tpr=0.5153 | fpr=0.8952 | 7820.3 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.06615 | acc=0.1124 | tpr=0.5207 | fpr=0.8950 | 7671.8 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.05880 | acc=0.1129 | tpr=0.5229 | fpr=0.8945 | 8127.4 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.05601 | acc=0.1134 | tpr=0.5202 | fpr=0.8940 | 6656.7 samples/s | 26.0 steps/s
[Step= 450] | Loss=5.05981 | acc=0.1132 | tpr=0.5185 | fpr=0.8942 | 7579.0 samples/s | 29.6 steps/s
[Step= 500] | Loss=5.06028 | acc=0.1127 | tpr=0.5181 | fpr=0.8946 | 7961.4 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.06055 | acc=0.1126 | tpr=0.5185 | fpr=0.8948 | 13932.9 samples/s | 54.4 steps/s
Avg test loss: 5.06251, Avg test acc: 0.11248, Avg tpr: 0.51862, Avg fpr: 0.89490, total FA: 124255

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.09636 | acc=0.0918 | tpr=0.4646 | fpr=0.9149 | 4709.1 samples/s | 18.4 steps/s
[Step= 100] | Loss=6.06191 | acc=0.0923 | tpr=0.4670 | fpr=0.9146 | 7445.0 samples/s | 29.1 steps/s
[Step= 150] | Loss=6.06564 | acc=0.0923 | tpr=0.4597 | fpr=0.9144 | 8134.1 samples/s | 31.8 steps/s
[Step= 200] | Loss=6.06134 | acc=0.0928 | tpr=0.4557 | fpr=0.9138 | 7341.2 samples/s | 28.7 steps/s
[Step= 250] | Loss=6.06518 | acc=0.0930 | tpr=0.4541 | fpr=0.9136 | 7450.0 samples/s | 29.1 steps/s
[Step= 300] | Loss=6.06603 | acc=0.0933 | tpr=0.4589 | fpr=0.9133 | 7493.3 samples/s | 29.3 steps/s
[Step= 350] | Loss=6.05991 | acc=0.0931 | tpr=0.4571 | fpr=0.9135 | 6622.4 samples/s | 25.9 steps/s
[Step= 400] | Loss=6.05324 | acc=0.0934 | tpr=0.4546 | fpr=0.9132 | 7867.3 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.05484 | acc=0.0934 | tpr=0.4508 | fpr=0.9131 | 7862.6 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.05482 | acc=0.0932 | tpr=0.4480 | fpr=0.9132 | 7806.8 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.05771 | acc=0.0931 | tpr=0.4429 | fpr=0.9132 | 14244.1 samples/s | 55.6 steps/s
Avg test loss: 6.05945, Avg test acc: 0.09300, Avg tpr: 0.44414, Avg fpr: 0.91339, total FA: 126822

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.29903 | acc=0.1230 | tpr=0.5354 | fpr=0.8844 | 4858.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.26554 | acc=0.1236 | tpr=0.5139 | fpr=0.8837 | 7129.8 samples/s | 27.9 steps/s
[Step= 150] | Loss=5.26983 | acc=0.1237 | tpr=0.5072 | fpr=0.8834 | 6620.9 samples/s | 25.9 steps/s
[Step= 200] | Loss=5.26721 | acc=0.1238 | tpr=0.5038 | fpr=0.8831 | 7703.6 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.27341 | acc=0.1240 | tpr=0.5074 | fpr=0.8830 | 7581.1 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.26804 | acc=0.1240 | tpr=0.5120 | fpr=0.8830 | 7551.3 samples/s | 29.5 steps/s
[Step= 350] | Loss=5.25840 | acc=0.1237 | tpr=0.5153 | fpr=0.8834 | 6903.9 samples/s | 27.0 steps/s
[Step= 400] | Loss=5.25322 | acc=0.1237 | tpr=0.5164 | fpr=0.8834 | 7671.5 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.25487 | acc=0.1241 | tpr=0.5219 | fpr=0.8832 | 7695.8 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.25296 | acc=0.1238 | tpr=0.5185 | fpr=0.8833 | 8265.6 samples/s | 32.3 steps/s
[Step= 550] | Loss=5.25598 | acc=0.1236 | tpr=0.5213 | fpr=0.8836 | 13264.9 samples/s | 51.8 steps/s
Avg test loss: 5.25673, Avg test acc: 0.12358, Avg tpr: 0.52179, Avg fpr: 0.88366, total FA: 122694

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.11892 | acc=0.0866 | tpr=0.6327 | fpr=0.9232 | 4579.9 samples/s | 17.9 steps/s
[Step= 100] | Loss=6.09405 | acc=0.0884 | tpr=0.6461 | fpr=0.9220 | 7601.4 samples/s | 29.7 steps/s
[Step= 150] | Loss=6.10596 | acc=0.0889 | tpr=0.6455 | fpr=0.9214 | 6914.6 samples/s | 27.0 steps/s
[Step= 200] | Loss=6.10918 | acc=0.0876 | tpr=0.6175 | fpr=0.9220 | 7671.2 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.11809 | acc=0.0877 | tpr=0.6253 | fpr=0.9221 | 7987.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.11530 | acc=0.0879 | tpr=0.6313 | fpr=0.9220 | 7788.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=6.11041 | acc=0.0879 | tpr=0.6337 | fpr=0.9220 | 6296.4 samples/s | 24.6 steps/s
[Step= 400] | Loss=6.11065 | acc=0.0883 | tpr=0.6379 | fpr=0.9217 | 8020.7 samples/s | 31.3 steps/s
[Step= 450] | Loss=6.11234 | acc=0.0882 | tpr=0.6422 | fpr=0.9218 | 7830.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.11505 | acc=0.0882 | tpr=0.6441 | fpr=0.9218 | 7726.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.11835 | acc=0.0882 | tpr=0.6506 | fpr=0.9221 | 13622.1 samples/s | 53.2 steps/s
Avg test loss: 6.11967, Avg test acc: 0.08815, Avg tpr: 0.65095, Avg fpr: 0.92208, total FA: 128029

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10193 | acc=0.9806 | tpr=0.9248 | fpr=0.0184 | 4653.7 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.10619 | acc=0.9805 | tpr=0.9360 | fpr=0.0186 | 7412.9 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.11001 | acc=0.9798 | tpr=0.9366 | fpr=0.0194 | 7175.9 samples/s | 28.0 steps/s
[Step= 200] | Loss=0.11175 | acc=0.9798 | tpr=0.9432 | fpr=0.0196 | 7333.8 samples/s | 28.6 steps/s
[Step= 250] | Loss=0.11004 | acc=0.9800 | tpr=0.9397 | fpr=0.0193 | 8379.8 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.11263 | acc=0.9795 | tpr=0.9382 | fpr=0.0197 | 5983.2 samples/s | 23.4 steps/s
[Step= 350] | Loss=0.11380 | acc=0.9794 | tpr=0.9411 | fpr=0.0199 | 7881.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.11497 | acc=0.9791 | tpr=0.9365 | fpr=0.0201 | 7624.5 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.11724 | acc=0.9787 | tpr=0.9352 | fpr=0.0205 | 7956.5 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.11625 | acc=0.9789 | tpr=0.9370 | fpr=0.0203 | 7798.2 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.11577 | acc=0.9791 | tpr=0.9355 | fpr=0.0201 | 14016.8 samples/s | 54.8 steps/s
Avg test loss: 0.11571, Avg test acc: 0.97909, Avg tpr: 0.93582, Avg fpr: 0.02012, total FA: 2794

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12584 | acc=0.9747 | tpr=0.6947 | fpr=0.0203 | 4732.8 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.12903 | acc=0.9751 | tpr=0.7292 | fpr=0.0203 | 6374.7 samples/s | 24.9 steps/s
[Step= 150] | Loss=0.13451 | acc=0.9744 | tpr=0.7406 | fpr=0.0213 | 7901.2 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.13644 | acc=0.9742 | tpr=0.7410 | fpr=0.0216 | 7577.0 samples/s | 29.6 steps/s
[Step= 250] | Loss=0.13435 | acc=0.9742 | tpr=0.7310 | fpr=0.0214 | 7709.4 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.13720 | acc=0.9737 | tpr=0.7251 | fpr=0.0218 | 6646.0 samples/s | 26.0 steps/s
[Step= 350] | Loss=0.13817 | acc=0.9735 | tpr=0.7351 | fpr=0.0221 | 7742.4 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.13933 | acc=0.9734 | tpr=0.7330 | fpr=0.0222 | 7929.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.14224 | acc=0.9729 | tpr=0.7278 | fpr=0.0226 | 7834.6 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.14105 | acc=0.9731 | tpr=0.7330 | fpr=0.0226 | 7792.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.14011 | acc=0.9734 | tpr=0.7358 | fpr=0.0223 | 13494.9 samples/s | 52.7 steps/s
Avg test loss: 0.13983, Avg test acc: 0.97338, Avg tpr: 0.73574, Avg fpr: 0.02230, total FA: 3097

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10270 | acc=0.9801 | tpr=0.9513 | fpr=0.0194 | 4617.8 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.10617 | acc=0.9802 | tpr=0.9510 | fpr=0.0192 | 6691.8 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.11060 | acc=0.9795 | tpr=0.9524 | fpr=0.0200 | 7792.9 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.11271 | acc=0.9796 | tpr=0.9563 | fpr=0.0200 | 7906.7 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.11095 | acc=0.9798 | tpr=0.9563 | fpr=0.0198 | 7553.5 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.11359 | acc=0.9795 | tpr=0.9498 | fpr=0.0199 | 6395.5 samples/s | 25.0 steps/s
[Step= 350] | Loss=0.11436 | acc=0.9792 | tpr=0.9512 | fpr=0.0203 | 7748.0 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.11555 | acc=0.9790 | tpr=0.9491 | fpr=0.0205 | 7882.9 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11748 | acc=0.9788 | tpr=0.9489 | fpr=0.0206 | 7601.5 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.11681 | acc=0.9789 | tpr=0.9507 | fpr=0.0206 | 7795.2 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.11641 | acc=0.9790 | tpr=0.9507 | fpr=0.0205 | 14035.1 samples/s | 54.8 steps/s
Avg test loss: 0.11634, Avg test acc: 0.97903, Avg tpr: 0.95087, Avg fpr: 0.02046, total FA: 2841

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09702 | acc=0.9814 | tpr=0.9336 | fpr=0.0177 | 4748.9 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10184 | acc=0.9811 | tpr=0.9318 | fpr=0.0180 | 6721.0 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.10651 | acc=0.9803 | tpr=0.9323 | fpr=0.0189 | 7742.9 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10831 | acc=0.9804 | tpr=0.9399 | fpr=0.0188 | 7885.8 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.10670 | acc=0.9807 | tpr=0.9371 | fpr=0.0185 | 6080.8 samples/s | 23.8 steps/s
[Step= 300] | Loss=0.10924 | acc=0.9804 | tpr=0.9324 | fpr=0.0187 | 7796.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.10978 | acc=0.9803 | tpr=0.9343 | fpr=0.0189 | 7688.8 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.11016 | acc=0.9802 | tpr=0.9322 | fpr=0.0189 | 7912.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.11243 | acc=0.9799 | tpr=0.9309 | fpr=0.0192 | 7881.7 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.11156 | acc=0.9801 | tpr=0.9335 | fpr=0.0191 | 7930.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.11126 | acc=0.9802 | tpr=0.9335 | fpr=0.0189 | 13378.8 samples/s | 52.3 steps/s
Avg test loss: 0.11116, Avg test acc: 0.98024, Avg tpr: 0.93384, Avg fpr: 0.01891, total FA: 2626

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10990 | acc=0.9795 | tpr=0.9292 | fpr=0.0196 | 4129.9 samples/s | 16.1 steps/s
[Step= 100] | Loss=0.11546 | acc=0.9792 | tpr=0.9318 | fpr=0.0199 | 7606.6 samples/s | 29.7 steps/s
[Step= 150] | Loss=0.11963 | acc=0.9783 | tpr=0.9395 | fpr=0.0210 | 7512.5 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.12153 | acc=0.9781 | tpr=0.9432 | fpr=0.0213 | 7706.2 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.11990 | acc=0.9784 | tpr=0.9397 | fpr=0.0209 | 6340.2 samples/s | 24.8 steps/s
[Step= 300] | Loss=0.12243 | acc=0.9782 | tpr=0.9360 | fpr=0.0210 | 7857.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.12322 | acc=0.9781 | tpr=0.9386 | fpr=0.0212 | 8062.7 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.12441 | acc=0.9779 | tpr=0.9327 | fpr=0.0213 | 7898.3 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.12702 | acc=0.9776 | tpr=0.9314 | fpr=0.0216 | 7686.4 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.12619 | acc=0.9777 | tpr=0.9317 | fpr=0.0214 | 7638.0 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.12576 | acc=0.9779 | tpr=0.9300 | fpr=0.0212 | 14595.9 samples/s | 57.0 steps/s
Avg test loss: 0.12564, Avg test acc: 0.97792, Avg tpr: 0.93027, Avg fpr: 0.02122, total FA: 2946

server round 18/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=175.5] | Loss=0.00079 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.185 | L2-Norm(final)=11.518 | 5387.9 samples/s | 84.2 steps/s
[Step=36050 Epoch=175.8] | Loss=0.00393 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.183 | L2-Norm(final)=11.526 | 4537.6 samples/s | 70.9 steps/s
[Step=36100 Epoch=176.0] | Loss=0.00347 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.180 | L2-Norm(final)=11.534 | 4890.3 samples/s | 76.4 steps/s
[Step=36150 Epoch=176.3] | Loss=0.00350 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.175 | L2-Norm(final)=11.543 | 4948.7 samples/s | 77.3 steps/s
[Step=36200 Epoch=176.5] | Loss=0.00364 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.169 | L2-Norm(final)=11.553 | 7848.9 samples/s | 122.6 steps/s
[Step=36250 Epoch=176.8] | Loss=0.00330 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.164 | L2-Norm(final)=11.562 | 2204.7 samples/s | 34.4 steps/s
[Step=36300 Epoch=177.0] | Loss=0.00324 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.158 | L2-Norm(final)=11.572 | 5054.2 samples/s | 79.0 steps/s
[Step=36350 Epoch=177.2] | Loss=0.00320 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.153 | L2-Norm(final)=11.582 | 4985.5 samples/s | 77.9 steps/s
[Step=36400 Epoch=177.5] | Loss=0.00323 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.147 | L2-Norm(final)=11.591 | 7016.5 samples/s | 109.6 steps/s
[Step=36450 Epoch=177.7] | Loss=0.00324 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.141 | L2-Norm(final)=11.600 | 2292.3 samples/s | 35.8 steps/s
[Step=36500 Epoch=178.0] | Loss=0.00318 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.135 | L2-Norm(final)=11.609 | 4956.8 samples/s | 77.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=178.0] | Loss=0.00040 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.077 | L2-Norm(final)=11.701 | 5437.8 samples/s | 85.0 steps/s
[Step=36550 Epoch=178.2] | Loss=0.00306 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.070 | L2-Norm(final)=11.710 | 4060.3 samples/s | 63.4 steps/s
[Step=36600 Epoch=178.5] | Loss=0.00443 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.066 | L2-Norm(final)=11.714 | 4521.7 samples/s | 70.7 steps/s
[Step=36650 Epoch=178.7] | Loss=0.00635 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.072 | L2-Norm(final)=11.719 | 4356.2 samples/s | 68.1 steps/s
[Step=36700 Epoch=179.0] | Loss=0.00741 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.085 | L2-Norm(final)=11.724 | 6593.2 samples/s | 103.0 steps/s
[Step=36750 Epoch=179.2] | Loss=0.00866 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.103 | L2-Norm(final)=11.728 | 2074.7 samples/s | 32.4 steps/s
[Step=36800 Epoch=179.4] | Loss=0.00918 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.123 | L2-Norm(final)=11.733 | 4416.6 samples/s | 69.0 steps/s
[Step=36850 Epoch=179.7] | Loss=0.00903 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.141 | L2-Norm(final)=11.739 | 4425.5 samples/s | 69.1 steps/s
[Step=36900 Epoch=179.9] | Loss=0.00959 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.160 | L2-Norm(final)=11.745 | 5877.5 samples/s | 91.8 steps/s
[Step=36950 Epoch=180.2] | Loss=0.00957 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.177 | L2-Norm(final)=11.751 | 2175.0 samples/s | 34.0 steps/s
[Step=37000 Epoch=180.4] | Loss=0.00934 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.193 | L2-Norm(final)=11.757 | 4422.0 samples/s | 69.1 steps/s
[Step=37050 Epoch=180.7] | Loss=0.00949 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.208 | L2-Norm(final)=11.763 | 4477.9 samples/s | 70.0 steps/s
[Step=37100 Epoch=180.9] | Loss=0.00944 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.221 | L2-Norm(final)=11.768 | 5410.5 samples/s | 84.5 steps/s
[Step=37150 Epoch=181.2] | Loss=0.00917 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.233 | L2-Norm(final)=11.773 | 2231.5 samples/s | 34.9 steps/s
[Step=37200 Epoch=181.4] | Loss=0.00885 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.244 | L2-Norm(final)=11.778 | 4484.0 samples/s | 70.1 steps/s
[Step=37250 Epoch=181.6] | Loss=0.00869 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.252 | L2-Norm(final)=11.784 | 4486.5 samples/s | 70.1 steps/s
[Step=37300 Epoch=181.9] | Loss=0.00880 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.260 | L2-Norm(final)=11.788 | 4878.9 samples/s | 76.2 steps/s
[Step=37350 Epoch=182.1] | Loss=0.00863 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.268 | L2-Norm(final)=11.792 | 2337.0 samples/s | 36.5 steps/s
[Step=37400 Epoch=182.4] | Loss=0.00844 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.275 | L2-Norm(final)=11.797 | 4423.4 samples/s | 69.1 steps/s
[Step=37450 Epoch=182.6] | Loss=0.00825 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.282 | L2-Norm(final)=11.801 | 4475.1 samples/s | 69.9 steps/s
[Step=37500 Epoch=182.9] | Loss=0.00827 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.288 | L2-Norm(final)=11.805 | 4605.8 samples/s | 72.0 steps/s
[Step=37550 Epoch=183.1] | Loss=0.00809 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.294 | L2-Norm(final)=11.809 | 2371.6 samples/s | 37.1 steps/s
[Step=37600 Epoch=183.3] | Loss=0.00796 | Reg=0.00372 | acc=0.9688 | L2-Norm=19.298 | L2-Norm(final)=11.813 | 4480.0 samples/s | 70.0 steps/s
[Step=37650 Epoch=183.6] | Loss=0.00773 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.302 | L2-Norm(final)=11.817 | 4481.6 samples/s | 70.0 steps/s
[Step=37700 Epoch=183.8] | Loss=0.00763 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.305 | L2-Norm(final)=11.821 | 4524.0 samples/s | 70.7 steps/s
[Step=37750 Epoch=184.1] | Loss=0.00746 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.307 | L2-Norm(final)=11.824 | 2432.7 samples/s | 38.0 steps/s
[Step=37800 Epoch=184.3] | Loss=0.00725 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.309 | L2-Norm(final)=11.828 | 4453.1 samples/s | 69.6 steps/s
[Step=37850 Epoch=184.6] | Loss=0.00709 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.309 | L2-Norm(final)=11.832 | 4469.1 samples/s | 69.8 steps/s
[Step=37900 Epoch=184.8] | Loss=0.00697 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.309 | L2-Norm(final)=11.835 | 4372.0 samples/s | 68.3 steps/s
[Step=37950 Epoch=185.1] | Loss=0.00684 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.309 | L2-Norm(final)=11.839 | 2434.3 samples/s | 38.0 steps/s
[Step=38000 Epoch=185.3] | Loss=0.00670 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.308 | L2-Norm(final)=11.842 | 4515.1 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step38000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=175.7] | Loss=0.00056 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.085 | L2-Norm(final)=11.568 | 5386.2 samples/s | 84.2 steps/s
[Step=36050 Epoch=175.9] | Loss=0.00312 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.078 | L2-Norm(final)=11.576 | 4484.3 samples/s | 70.1 steps/s
[Step=36100 Epoch=176.2] | Loss=0.00367 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.073 | L2-Norm(final)=11.586 | 4979.9 samples/s | 77.8 steps/s
[Step=36150 Epoch=176.4] | Loss=0.00347 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.069 | L2-Norm(final)=11.596 | 5143.7 samples/s | 80.4 steps/s
[Step=36200 Epoch=176.6] | Loss=0.00325 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.064 | L2-Norm(final)=11.606 | 7619.2 samples/s | 119.0 steps/s
[Step=36250 Epoch=176.9] | Loss=0.00297 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=11.617 | 2187.7 samples/s | 34.2 steps/s
[Step=36300 Epoch=177.1] | Loss=0.00294 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.054 | L2-Norm(final)=11.627 | 4884.7 samples/s | 76.3 steps/s
[Step=36350 Epoch=177.4] | Loss=0.00289 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.048 | L2-Norm(final)=11.637 | 5126.6 samples/s | 80.1 steps/s
[Step=36400 Epoch=177.6] | Loss=0.00290 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.042 | L2-Norm(final)=11.648 | 7004.2 samples/s | 109.4 steps/s
[Step=36450 Epoch=177.9] | Loss=0.00291 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.036 | L2-Norm(final)=11.657 | 2259.4 samples/s | 35.3 steps/s
[Step=36500 Epoch=178.1] | Loss=0.00278 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.029 | L2-Norm(final)=11.667 | 4981.7 samples/s | 77.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=178.1] | Loss=0.00168 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.963 | L2-Norm(final)=11.764 | 5080.7 samples/s | 79.4 steps/s
[Step=36550 Epoch=178.3] | Loss=0.00280 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.957 | L2-Norm(final)=11.774 | 2565.4 samples/s | 40.1 steps/s
[Step=36600 Epoch=178.6] | Loss=0.00378 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.955 | L2-Norm(final)=11.780 | 4491.3 samples/s | 70.2 steps/s
[Step=36650 Epoch=178.8] | Loss=0.00588 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.960 | L2-Norm(final)=11.784 | 4293.6 samples/s | 67.1 steps/s
[Step=36700 Epoch=179.1] | Loss=0.00815 | Reg=0.00360 | acc=0.9531 | L2-Norm=18.977 | L2-Norm(final)=11.789 | 6568.1 samples/s | 102.6 steps/s
[Step=36750 Epoch=179.3] | Loss=0.00927 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.005 | L2-Norm(final)=11.794 | 2085.1 samples/s | 32.6 steps/s
[Step=36800 Epoch=179.6] | Loss=0.01009 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.033 | L2-Norm(final)=11.800 | 4406.6 samples/s | 68.9 steps/s
[Step=36850 Epoch=179.8] | Loss=0.01123 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.062 | L2-Norm(final)=11.806 | 4419.6 samples/s | 69.1 steps/s
[Step=36900 Epoch=180.1] | Loss=0.01191 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.091 | L2-Norm(final)=11.811 | 5928.5 samples/s | 92.6 steps/s
[Step=36950 Epoch=180.3] | Loss=0.01217 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.119 | L2-Norm(final)=11.816 | 2144.5 samples/s | 33.5 steps/s
[Step=37000 Epoch=180.5] | Loss=0.01171 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.142 | L2-Norm(final)=11.821 | 4506.2 samples/s | 70.4 steps/s
[Step=37050 Epoch=180.8] | Loss=0.01114 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.162 | L2-Norm(final)=11.826 | 4509.9 samples/s | 70.5 steps/s
[Step=37100 Epoch=181.0] | Loss=0.01088 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.179 | L2-Norm(final)=11.832 | 5543.4 samples/s | 86.6 steps/s
[Step=37150 Epoch=181.3] | Loss=0.01051 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.194 | L2-Norm(final)=11.837 | 2224.8 samples/s | 34.8 steps/s
[Step=37200 Epoch=181.5] | Loss=0.01026 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.207 | L2-Norm(final)=11.842 | 4441.4 samples/s | 69.4 steps/s
[Step=37250 Epoch=181.8] | Loss=0.00985 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.217 | L2-Norm(final)=11.846 | 4391.1 samples/s | 68.6 steps/s
[Step=37300 Epoch=182.0] | Loss=0.00954 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.226 | L2-Norm(final)=11.850 | 5168.6 samples/s | 80.8 steps/s
[Step=37350 Epoch=182.3] | Loss=0.00919 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.233 | L2-Norm(final)=11.854 | 2321.1 samples/s | 36.3 steps/s
[Step=37400 Epoch=182.5] | Loss=0.00896 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.238 | L2-Norm(final)=11.858 | 4357.6 samples/s | 68.1 steps/s
[Step=37450 Epoch=182.7] | Loss=0.00867 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.243 | L2-Norm(final)=11.862 | 4524.5 samples/s | 70.7 steps/s
[Step=37500 Epoch=183.0] | Loss=0.00845 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.246 | L2-Norm(final)=11.865 | 4830.9 samples/s | 75.5 steps/s
[Step=37550 Epoch=183.2] | Loss=0.00817 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.248 | L2-Norm(final)=11.869 | 2343.6 samples/s | 36.6 steps/s
[Step=37600 Epoch=183.5] | Loss=0.00799 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.249 | L2-Norm(final)=11.872 | 4374.0 samples/s | 68.3 steps/s
[Step=37650 Epoch=183.7] | Loss=0.00774 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.250 | L2-Norm(final)=11.875 | 4477.2 samples/s | 70.0 steps/s
[Step=37700 Epoch=184.0] | Loss=0.00754 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.250 | L2-Norm(final)=11.879 | 4520.5 samples/s | 70.6 steps/s
[Step=37750 Epoch=184.2] | Loss=0.00733 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.249 | L2-Norm(final)=11.882 | 2410.2 samples/s | 37.7 steps/s
[Step=37800 Epoch=184.4] | Loss=0.00716 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.247 | L2-Norm(final)=11.885 | 4462.0 samples/s | 69.7 steps/s
[Step=37850 Epoch=184.7] | Loss=0.00703 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.245 | L2-Norm(final)=11.887 | 4454.6 samples/s | 69.6 steps/s
[Step=37900 Epoch=184.9] | Loss=0.00692 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.243 | L2-Norm(final)=11.890 | 4436.2 samples/s | 69.3 steps/s
[Step=37950 Epoch=185.2] | Loss=0.00681 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.241 | L2-Norm(final)=11.893 | 2381.6 samples/s | 37.2 steps/s
[Step=38000 Epoch=185.4] | Loss=0.00671 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.239 | L2-Norm(final)=11.896 | 4575.7 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step38000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=175.4] | Loss=0.00195 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.397 | L2-Norm(final)=12.066 | 5163.3 samples/s | 80.7 steps/s
[Step=36050 Epoch=175.7] | Loss=0.00324 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.392 | L2-Norm(final)=12.075 | 4633.8 samples/s | 72.4 steps/s
[Step=36100 Epoch=175.9] | Loss=0.00403 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.389 | L2-Norm(final)=12.086 | 5009.1 samples/s | 78.3 steps/s
[Step=36150 Epoch=176.1] | Loss=0.00375 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.386 | L2-Norm(final)=12.097 | 4995.0 samples/s | 78.0 steps/s
[Step=36200 Epoch=176.4] | Loss=0.00369 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.381 | L2-Norm(final)=12.108 | 7892.9 samples/s | 123.3 steps/s
[Step=36250 Epoch=176.6] | Loss=0.00359 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.376 | L2-Norm(final)=12.119 | 2215.6 samples/s | 34.6 steps/s
[Step=36300 Epoch=176.9] | Loss=0.00359 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.371 | L2-Norm(final)=12.130 | 4929.9 samples/s | 77.0 steps/s
[Step=36350 Epoch=177.1] | Loss=0.00341 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.366 | L2-Norm(final)=12.140 | 5101.0 samples/s | 79.7 steps/s
[Step=36400 Epoch=177.4] | Loss=0.00341 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.361 | L2-Norm(final)=12.151 | 6868.6 samples/s | 107.3 steps/s
[Step=36450 Epoch=177.6] | Loss=0.00333 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.355 | L2-Norm(final)=12.162 | 2304.7 samples/s | 36.0 steps/s
[Step=36500 Epoch=177.8] | Loss=0.00334 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.350 | L2-Norm(final)=12.172 | 5032.9 samples/s | 78.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=177.9] | Loss=0.01342 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.295 | L2-Norm(final)=12.278 | 5131.4 samples/s | 80.2 steps/s
[Step=36550 Epoch=178.1] | Loss=0.00582 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.294 | L2-Norm(final)=12.286 | 4137.3 samples/s | 64.6 steps/s
[Step=36600 Epoch=178.3] | Loss=0.00790 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.302 | L2-Norm(final)=12.292 | 4456.3 samples/s | 69.6 steps/s
[Step=36650 Epoch=178.6] | Loss=0.01065 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.324 | L2-Norm(final)=12.299 | 4443.7 samples/s | 69.4 steps/s
[Step=36700 Epoch=178.8] | Loss=0.01098 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.349 | L2-Norm(final)=12.305 | 6535.9 samples/s | 102.1 steps/s
[Step=36750 Epoch=179.1] | Loss=0.01169 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.373 | L2-Norm(final)=12.311 | 2116.2 samples/s | 33.1 steps/s
[Step=36800 Epoch=179.3] | Loss=0.01300 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.404 | L2-Norm(final)=12.316 | 4431.2 samples/s | 69.2 steps/s
[Step=36850 Epoch=179.6] | Loss=0.01395 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.434 | L2-Norm(final)=12.321 | 4412.4 samples/s | 68.9 steps/s
[Step=36900 Epoch=179.8] | Loss=0.01499 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.466 | L2-Norm(final)=12.324 | 5862.8 samples/s | 91.6 steps/s
[Step=36950 Epoch=180.0] | Loss=0.01459 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.493 | L2-Norm(final)=12.328 | 2152.7 samples/s | 33.6 steps/s
[Step=37000 Epoch=180.3] | Loss=0.01393 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.516 | L2-Norm(final)=12.331 | 4513.7 samples/s | 70.5 steps/s
[Step=37050 Epoch=180.5] | Loss=0.01354 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.536 | L2-Norm(final)=12.335 | 4389.8 samples/s | 68.6 steps/s
[Step=37100 Epoch=180.8] | Loss=0.01309 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.554 | L2-Norm(final)=12.338 | 5430.3 samples/s | 84.8 steps/s
[Step=37150 Epoch=181.0] | Loss=0.01249 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.569 | L2-Norm(final)=12.343 | 2247.3 samples/s | 35.1 steps/s
[Step=37200 Epoch=181.3] | Loss=0.01191 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.582 | L2-Norm(final)=12.347 | 4543.2 samples/s | 71.0 steps/s
[Step=37250 Epoch=181.5] | Loss=0.01145 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.593 | L2-Norm(final)=12.351 | 4476.0 samples/s | 69.9 steps/s
[Step=37300 Epoch=181.7] | Loss=0.01096 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.601 | L2-Norm(final)=12.355 | 4790.4 samples/s | 74.8 steps/s
[Step=37350 Epoch=182.0] | Loss=0.01054 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.608 | L2-Norm(final)=12.358 | 2323.4 samples/s | 36.3 steps/s
[Step=37400 Epoch=182.2] | Loss=0.01018 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.613 | L2-Norm(final)=12.362 | 4454.3 samples/s | 69.6 steps/s
[Step=37450 Epoch=182.5] | Loss=0.00977 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.617 | L2-Norm(final)=12.365 | 4463.4 samples/s | 69.7 steps/s
[Step=37500 Epoch=182.7] | Loss=0.00945 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.620 | L2-Norm(final)=12.369 | 4612.8 samples/s | 72.1 steps/s
[Step=37550 Epoch=183.0] | Loss=0.00919 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.622 | L2-Norm(final)=12.372 | 2419.8 samples/s | 37.8 steps/s
[Step=37600 Epoch=183.2] | Loss=0.00895 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.623 | L2-Norm(final)=12.375 | 4446.8 samples/s | 69.5 steps/s
[Step=37650 Epoch=183.4] | Loss=0.00873 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.624 | L2-Norm(final)=12.378 | 4405.7 samples/s | 68.8 steps/s
[Step=37700 Epoch=183.7] | Loss=0.00850 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.623 | L2-Norm(final)=12.380 | 4486.1 samples/s | 70.1 steps/s
[Step=37750 Epoch=183.9] | Loss=0.00835 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.623 | L2-Norm(final)=12.383 | 2438.5 samples/s | 38.1 steps/s
[Step=37800 Epoch=184.2] | Loss=0.00812 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.622 | L2-Norm(final)=12.385 | 4514.5 samples/s | 70.5 steps/s
[Step=37850 Epoch=184.4] | Loss=0.00795 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.620 | L2-Norm(final)=12.388 | 4436.7 samples/s | 69.3 steps/s
[Step=37900 Epoch=184.7] | Loss=0.00780 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.618 | L2-Norm(final)=12.390 | 4472.7 samples/s | 69.9 steps/s
[Step=37950 Epoch=184.9] | Loss=0.00763 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.615 | L2-Norm(final)=12.392 | 2466.7 samples/s | 38.5 steps/s
[Step=38000 Epoch=185.2] | Loss=0.00748 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.612 | L2-Norm(final)=12.394 | 4411.8 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step38000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=175.6] | Loss=0.00600 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.342 | L2-Norm(final)=11.911 | 5517.6 samples/s | 86.2 steps/s
[Step=36050 Epoch=175.8] | Loss=0.00322 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.335 | L2-Norm(final)=11.919 | 4454.1 samples/s | 69.6 steps/s
[Step=36100 Epoch=176.0] | Loss=0.00266 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.329 | L2-Norm(final)=11.929 | 5074.3 samples/s | 79.3 steps/s
[Step=36150 Epoch=176.3] | Loss=0.00307 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.325 | L2-Norm(final)=11.941 | 5064.1 samples/s | 79.1 steps/s
[Step=36200 Epoch=176.5] | Loss=0.00285 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.322 | L2-Norm(final)=11.952 | 7683.4 samples/s | 120.1 steps/s
[Step=36250 Epoch=176.8] | Loss=0.00278 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.318 | L2-Norm(final)=11.963 | 2197.8 samples/s | 34.3 steps/s
[Step=36300 Epoch=177.0] | Loss=0.00278 | Reg=0.00373 | acc=0.9688 | L2-Norm=19.312 | L2-Norm(final)=11.973 | 5013.7 samples/s | 78.3 steps/s
[Step=36350 Epoch=177.3] | Loss=0.00269 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.306 | L2-Norm(final)=11.984 | 4961.2 samples/s | 77.5 steps/s
[Step=36400 Epoch=177.5] | Loss=0.00271 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.301 | L2-Norm(final)=11.994 | 6947.7 samples/s | 108.6 steps/s
[Step=36450 Epoch=177.8] | Loss=0.00264 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.295 | L2-Norm(final)=12.004 | 2298.6 samples/s | 35.9 steps/s
[Step=36500 Epoch=178.0] | Loss=0.00257 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.290 | L2-Norm(final)=12.015 | 5051.1 samples/s | 78.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=178.0] | Loss=0.00046 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.231 | L2-Norm(final)=12.119 | 5488.7 samples/s | 85.8 steps/s
[Step=36550 Epoch=178.2] | Loss=0.00208 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.228 | L2-Norm(final)=12.127 | 3965.1 samples/s | 62.0 steps/s
[Step=36600 Epoch=178.5] | Loss=0.00487 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.225 | L2-Norm(final)=12.134 | 4524.8 samples/s | 70.7 steps/s
[Step=36650 Epoch=178.7] | Loss=0.00594 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.227 | L2-Norm(final)=12.137 | 4400.2 samples/s | 68.8 steps/s
[Step=36700 Epoch=179.0] | Loss=0.00652 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.233 | L2-Norm(final)=12.144 | 6413.2 samples/s | 100.2 steps/s
[Step=36750 Epoch=179.2] | Loss=0.00870 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.247 | L2-Norm(final)=12.150 | 2101.7 samples/s | 32.8 steps/s
[Step=36800 Epoch=179.5] | Loss=0.01099 | Reg=0.00372 | acc=0.9531 | L2-Norm=19.277 | L2-Norm(final)=12.155 | 4399.7 samples/s | 68.7 steps/s
[Step=36850 Epoch=179.7] | Loss=0.01202 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.309 | L2-Norm(final)=12.159 | 4470.3 samples/s | 69.8 steps/s
[Step=36900 Epoch=179.9] | Loss=0.01201 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.339 | L2-Norm(final)=12.162 | 5962.9 samples/s | 93.2 steps/s
[Step=36950 Epoch=180.2] | Loss=0.01150 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.365 | L2-Norm(final)=12.167 | 2139.6 samples/s | 33.4 steps/s
[Step=37000 Epoch=180.4] | Loss=0.01090 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.386 | L2-Norm(final)=12.171 | 4548.3 samples/s | 71.1 steps/s
[Step=37050 Epoch=180.7] | Loss=0.01053 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=12.176 | 4312.0 samples/s | 67.4 steps/s
[Step=37100 Epoch=180.9] | Loss=0.01059 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.418 | L2-Norm(final)=12.180 | 5435.8 samples/s | 84.9 steps/s
[Step=37150 Epoch=181.2] | Loss=0.01023 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=12.184 | 2254.2 samples/s | 35.2 steps/s
[Step=37200 Epoch=181.4] | Loss=0.00988 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.442 | L2-Norm(final)=12.188 | 4477.7 samples/s | 70.0 steps/s
[Step=37250 Epoch=181.7] | Loss=0.00950 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.451 | L2-Norm(final)=12.193 | 4451.1 samples/s | 69.5 steps/s
[Step=37300 Epoch=181.9] | Loss=0.00927 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.460 | L2-Norm(final)=12.197 | 4997.6 samples/s | 78.1 steps/s
[Step=37350 Epoch=182.1] | Loss=0.00897 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.467 | L2-Norm(final)=12.201 | 2352.9 samples/s | 36.8 steps/s
[Step=37400 Epoch=182.4] | Loss=0.00874 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.473 | L2-Norm(final)=12.206 | 4370.1 samples/s | 68.3 steps/s
[Step=37450 Epoch=182.6] | Loss=0.00863 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.478 | L2-Norm(final)=12.209 | 4491.6 samples/s | 70.2 steps/s
[Step=37500 Epoch=182.9] | Loss=0.00867 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.484 | L2-Norm(final)=12.213 | 4618.8 samples/s | 72.2 steps/s
[Step=37550 Epoch=183.1] | Loss=0.00863 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.490 | L2-Norm(final)=12.217 | 2435.1 samples/s | 38.0 steps/s
[Step=37600 Epoch=183.4] | Loss=0.00849 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.496 | L2-Norm(final)=12.220 | 4415.9 samples/s | 69.0 steps/s
[Step=37650 Epoch=183.6] | Loss=0.00835 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.501 | L2-Norm(final)=12.223 | 4463.4 samples/s | 69.7 steps/s
[Step=37700 Epoch=183.8] | Loss=0.00820 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.506 | L2-Norm(final)=12.227 | 4551.8 samples/s | 71.1 steps/s
[Step=37750 Epoch=184.1] | Loss=0.00800 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.510 | L2-Norm(final)=12.230 | 2395.5 samples/s | 37.4 steps/s
[Step=37800 Epoch=184.3] | Loss=0.00784 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.514 | L2-Norm(final)=12.233 | 4477.4 samples/s | 70.0 steps/s
[Step=37850 Epoch=184.6] | Loss=0.00768 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.517 | L2-Norm(final)=12.237 | 4500.0 samples/s | 70.3 steps/s
[Step=37900 Epoch=184.8] | Loss=0.00753 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.519 | L2-Norm(final)=12.240 | 4470.6 samples/s | 69.9 steps/s
[Step=37950 Epoch=185.1] | Loss=0.00741 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.521 | L2-Norm(final)=12.243 | 2445.6 samples/s | 38.2 steps/s
[Step=38000 Epoch=185.3] | Loss=0.00727 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.521 | L2-Norm(final)=12.246 | 4510.0 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step38000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=176.5] | Loss=0.00169 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.161 | L2-Norm(final)=11.873 | 5243.6 samples/s | 81.9 steps/s
[Step=36050 Epoch=176.8] | Loss=0.00389 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.160 | L2-Norm(final)=11.882 | 4439.6 samples/s | 69.4 steps/s
[Step=36100 Epoch=177.0] | Loss=0.00321 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.157 | L2-Norm(final)=11.892 | 4975.6 samples/s | 77.7 steps/s
[Step=36150 Epoch=177.3] | Loss=0.00331 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.152 | L2-Norm(final)=11.901 | 5030.9 samples/s | 78.6 steps/s
[Step=36200 Epoch=177.5] | Loss=0.00324 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.149 | L2-Norm(final)=11.911 | 8058.3 samples/s | 125.9 steps/s
[Step=36250 Epoch=177.8] | Loss=0.00304 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.145 | L2-Norm(final)=11.921 | 2191.8 samples/s | 34.2 steps/s
[Step=36300 Epoch=178.0] | Loss=0.00296 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.140 | L2-Norm(final)=11.932 | 5160.6 samples/s | 80.6 steps/s
[Step=36350 Epoch=178.3] | Loss=0.00291 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.134 | L2-Norm(final)=11.942 | 4842.6 samples/s | 75.7 steps/s
[Step=36400 Epoch=178.5] | Loss=0.00291 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.129 | L2-Norm(final)=11.952 | 7421.3 samples/s | 116.0 steps/s
[Step=36450 Epoch=178.7] | Loss=0.00287 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.123 | L2-Norm(final)=11.962 | 2220.9 samples/s | 34.7 steps/s
[Step=36500 Epoch=179.0] | Loss=0.00278 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.118 | L2-Norm(final)=11.972 | 5138.1 samples/s | 80.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=179.0] | Loss=0.00168 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=12.071 | 5533.6 samples/s | 86.5 steps/s
[Step=36550 Epoch=179.2] | Loss=0.00340 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.056 | L2-Norm(final)=12.079 | 3901.5 samples/s | 61.0 steps/s
[Step=36600 Epoch=179.5] | Loss=0.00337 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.055 | L2-Norm(final)=12.086 | 4488.2 samples/s | 70.1 steps/s
[Step=36650 Epoch=179.7] | Loss=0.00449 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.058 | L2-Norm(final)=12.094 | 4468.8 samples/s | 69.8 steps/s
[Step=36700 Epoch=180.0] | Loss=0.00549 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.063 | L2-Norm(final)=12.101 | 6691.1 samples/s | 104.5 steps/s
[Step=36750 Epoch=180.2] | Loss=0.00613 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.072 | L2-Norm(final)=12.108 | 2065.6 samples/s | 32.3 steps/s
[Step=36800 Epoch=180.5] | Loss=0.00673 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.082 | L2-Norm(final)=12.114 | 4416.3 samples/s | 69.0 steps/s
[Step=36850 Epoch=180.7] | Loss=0.00688 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.092 | L2-Norm(final)=12.119 | 4462.5 samples/s | 69.7 steps/s
[Step=36900 Epoch=181.0] | Loss=0.00713 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.101 | L2-Norm(final)=12.125 | 6261.2 samples/s | 97.8 steps/s
[Step=36950 Epoch=181.2] | Loss=0.00697 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.110 | L2-Norm(final)=12.131 | 2135.7 samples/s | 33.4 steps/s
[Step=37000 Epoch=181.4] | Loss=0.00711 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.118 | L2-Norm(final)=12.137 | 4392.6 samples/s | 68.6 steps/s
[Step=37050 Epoch=181.7] | Loss=0.00727 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.126 | L2-Norm(final)=12.142 | 4444.8 samples/s | 69.4 steps/s
[Step=37100 Epoch=181.9] | Loss=0.00738 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.135 | L2-Norm(final)=12.147 | 5844.4 samples/s | 91.3 steps/s
[Step=37150 Epoch=182.2] | Loss=0.00747 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.146 | L2-Norm(final)=12.153 | 2094.4 samples/s | 32.7 steps/s
[Step=37200 Epoch=182.4] | Loss=0.00766 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.158 | L2-Norm(final)=12.158 | 4471.9 samples/s | 69.9 steps/s
[Step=37250 Epoch=182.7] | Loss=0.00789 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.169 | L2-Norm(final)=12.163 | 4496.4 samples/s | 70.3 steps/s
[Step=37300 Epoch=182.9] | Loss=0.00777 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.180 | L2-Norm(final)=12.168 | 5524.3 samples/s | 86.3 steps/s
[Step=37350 Epoch=183.2] | Loss=0.00781 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.191 | L2-Norm(final)=12.173 | 2201.7 samples/s | 34.4 steps/s
[Step=37400 Epoch=183.4] | Loss=0.00776 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.202 | L2-Norm(final)=12.178 | 4505.2 samples/s | 70.4 steps/s
[Step=37450 Epoch=183.6] | Loss=0.00786 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.213 | L2-Norm(final)=12.183 | 4523.8 samples/s | 70.7 steps/s
[Step=37500 Epoch=183.9] | Loss=0.00788 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.224 | L2-Norm(final)=12.188 | 4972.7 samples/s | 77.7 steps/s
[Step=37550 Epoch=184.1] | Loss=0.00788 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.235 | L2-Norm(final)=12.193 | 2262.6 samples/s | 35.4 steps/s
[Step=37600 Epoch=184.4] | Loss=0.00784 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.246 | L2-Norm(final)=12.197 | 4517.2 samples/s | 70.6 steps/s
[Step=37650 Epoch=184.6] | Loss=0.00778 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.256 | L2-Norm(final)=12.201 | 4436.0 samples/s | 69.3 steps/s
[Step=37700 Epoch=184.9] | Loss=0.00767 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.264 | L2-Norm(final)=12.205 | 4921.1 samples/s | 76.9 steps/s
[Step=37750 Epoch=185.1] | Loss=0.00752 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.272 | L2-Norm(final)=12.209 | 2330.4 samples/s | 36.4 steps/s
[Step=37800 Epoch=185.4] | Loss=0.00739 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.279 | L2-Norm(final)=12.213 | 4468.9 samples/s | 69.8 steps/s
[Step=37850 Epoch=185.6] | Loss=0.00728 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.285 | L2-Norm(final)=12.217 | 4420.7 samples/s | 69.1 steps/s
[Step=37900 Epoch=185.9] | Loss=0.00713 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.290 | L2-Norm(final)=12.220 | 4656.2 samples/s | 72.8 steps/s
[Step=37950 Epoch=186.1] | Loss=0.00694 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.295 | L2-Norm(final)=12.224 | 2391.9 samples/s | 37.4 steps/s
[Step=38000 Epoch=186.3] | Loss=0.00681 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.299 | L2-Norm(final)=12.227 | 4479.6 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step38000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=341.1] | Loss=0.00011 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.743 | L2-Norm(final)=6.686 | 5310.1 samples/s | 83.0 steps/s
[Step=36050 Epoch=341.6] | Loss=0.00008 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.749 | L2-Norm(final)=6.693 | 4142.4 samples/s | 64.7 steps/s
[Step=36100 Epoch=342.1] | Loss=0.00006 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.756 | L2-Norm(final)=6.701 | 7163.1 samples/s | 111.9 steps/s
[Step=36150 Epoch=342.6] | Loss=0.00005 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.758 | L2-Norm(final)=6.707 | 2077.0 samples/s | 32.5 steps/s
[Step=36200 Epoch=343.0] | Loss=0.00004 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.760 | L2-Norm(final)=6.714 | 6536.6 samples/s | 102.1 steps/s
[Step=36250 Epoch=343.5] | Loss=0.00004 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.720 | 2227.1 samples/s | 34.8 steps/s
[Step=36300 Epoch=344.0] | Loss=0.00004 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.726 | 5774.2 samples/s | 90.2 steps/s
[Step=36350 Epoch=344.4] | Loss=0.00003 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.731 | 2354.6 samples/s | 36.8 steps/s
[Step=36400 Epoch=344.9] | Loss=0.00003 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.737 | 4963.1 samples/s | 77.5 steps/s
[Step=36450 Epoch=345.4] | Loss=0.00003 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.743 | 2343.5 samples/s | 36.6 steps/s
[Step=36500 Epoch=345.9] | Loss=0.00003 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=6.748 | 4870.7 samples/s | 76.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=345.9] | Loss=0.00003 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.756 | L2-Norm(final)=6.801 | 5363.3 samples/s | 83.8 steps/s
[Step=36550 Epoch=346.3] | Loss=0.00002 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.747 | L2-Norm(final)=6.806 | 3995.6 samples/s | 62.4 steps/s
[Step=36600 Epoch=346.8] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.735 | L2-Norm(final)=6.810 | 6283.7 samples/s | 98.2 steps/s
[Step=36650 Epoch=347.3] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.722 | L2-Norm(final)=6.813 | 2031.0 samples/s | 31.7 steps/s
[Step=36700 Epoch=347.8] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.708 | L2-Norm(final)=6.815 | 5370.5 samples/s | 83.9 steps/s
[Step=36750 Epoch=348.2] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.694 | L2-Norm(final)=6.817 | 2099.6 samples/s | 32.8 steps/s
[Step=36800 Epoch=348.7] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.679 | L2-Norm(final)=6.818 | 5132.9 samples/s | 80.2 steps/s
[Step=36850 Epoch=349.2] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=6.820 | 2181.0 samples/s | 34.1 steps/s
[Step=36900 Epoch=349.7] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.651 | L2-Norm(final)=6.821 | 4708.5 samples/s | 73.6 steps/s
[Step=36950 Epoch=350.1] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=6.823 | 2267.8 samples/s | 35.4 steps/s
[Step=37000 Epoch=350.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.621 | L2-Norm(final)=6.824 | 4318.9 samples/s | 67.5 steps/s
[Step=37050 Epoch=351.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.607 | L2-Norm(final)=6.825 | 2348.9 samples/s | 36.7 steps/s
[Step=37100 Epoch=351.6] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.592 | L2-Norm(final)=6.827 | 4270.0 samples/s | 66.7 steps/s
[Step=37150 Epoch=352.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.577 | L2-Norm(final)=6.828 | 2430.8 samples/s | 38.0 steps/s
[Step=37200 Epoch=352.5] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.562 | L2-Norm(final)=6.829 | 4128.7 samples/s | 64.5 steps/s
[Step=37250 Epoch=353.0] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.547 | L2-Norm(final)=6.830 | 2390.0 samples/s | 37.3 steps/s
[Step=37300 Epoch=353.4] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.532 | L2-Norm(final)=6.831 | 4152.9 samples/s | 64.9 steps/s
[Step=37350 Epoch=353.9] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.516 | L2-Norm(final)=6.832 | 2531.5 samples/s | 39.6 steps/s
[Step=37400 Epoch=354.4] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.501 | L2-Norm(final)=6.834 | 3903.8 samples/s | 61.0 steps/s
[Step=37450 Epoch=354.9] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.485 | L2-Norm(final)=6.835 | 6562.4 samples/s | 102.5 steps/s
[Step=37500 Epoch=355.3] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.470 | L2-Norm(final)=6.836 | 1988.3 samples/s | 31.1 steps/s
[Step=37550 Epoch=355.8] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.454 | L2-Norm(final)=6.837 | 5836.2 samples/s | 91.2 steps/s
[Step=37600 Epoch=356.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=6.838 | 2065.5 samples/s | 32.3 steps/s
[Step=37650 Epoch=356.8] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.422 | L2-Norm(final)=6.839 | 5279.7 samples/s | 82.5 steps/s
[Step=37700 Epoch=357.2] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.406 | L2-Norm(final)=6.841 | 2147.6 samples/s | 33.6 steps/s
[Step=37750 Epoch=357.7] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.390 | L2-Norm(final)=6.842 | 4816.2 samples/s | 75.3 steps/s
[Step=37800 Epoch=358.2] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.374 | L2-Norm(final)=6.843 | 2222.3 samples/s | 34.7 steps/s
[Step=37850 Epoch=358.7] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.357 | L2-Norm(final)=6.844 | 4416.4 samples/s | 69.0 steps/s
[Step=37900 Epoch=359.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.341 | L2-Norm(final)=6.846 | 2278.1 samples/s | 35.6 steps/s
[Step=37950 Epoch=359.6] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.324 | L2-Norm(final)=6.847 | 4245.5 samples/s | 66.3 steps/s
[Step=38000 Epoch=360.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.307 | L2-Norm(final)=6.848 | 2374.5 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step38000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=342.5] | Loss=0.00040 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.547 | L2-Norm(final)=7.473 | 5806.7 samples/s | 90.7 steps/s
[Step=36050 Epoch=342.9] | Loss=0.02463 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.752 | L2-Norm(final)=7.430 | 3911.3 samples/s | 61.1 steps/s
[Step=36100 Epoch=343.4] | Loss=0.02018 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.837 | L2-Norm(final)=7.437 | 7405.7 samples/s | 115.7 steps/s
[Step=36150 Epoch=343.9] | Loss=0.01635 | Reg=0.00098 | acc=0.9688 | L2-Norm=9.900 | L2-Norm(final)=7.456 | 2117.0 samples/s | 33.1 steps/s
[Step=36200 Epoch=344.4] | Loss=0.01433 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.952 | L2-Norm(final)=7.479 | 6664.7 samples/s | 104.1 steps/s
[Step=36250 Epoch=344.8] | Loss=0.01242 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.996 | L2-Norm(final)=7.502 | 2282.2 samples/s | 35.7 steps/s
[Step=36300 Epoch=345.3] | Loss=0.01132 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.035 | L2-Norm(final)=7.526 | 5591.8 samples/s | 87.4 steps/s
[Step=36350 Epoch=345.8] | Loss=0.01054 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.070 | L2-Norm(final)=7.549 | 2279.1 samples/s | 35.6 steps/s
[Step=36400 Epoch=346.3] | Loss=0.00974 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.102 | L2-Norm(final)=7.571 | 5403.7 samples/s | 84.4 steps/s
[Step=36450 Epoch=346.7] | Loss=0.00908 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=7.593 | 2385.7 samples/s | 37.3 steps/s
[Step=36500 Epoch=347.2] | Loss=0.00843 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.158 | L2-Norm(final)=7.615 | 4945.9 samples/s | 77.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=347.2] | Loss=0.00177 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=7.826 | 5738.2 samples/s | 89.7 steps/s
[Step=36550 Epoch=347.7] | Loss=0.00441 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.466 | L2-Norm(final)=7.841 | 3563.8 samples/s | 55.7 steps/s
[Step=36600 Epoch=348.2] | Loss=0.00311 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.511 | L2-Norm(final)=7.844 | 6275.2 samples/s | 98.0 steps/s
[Step=36650 Epoch=348.6] | Loss=0.00211 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.529 | L2-Norm(final)=7.846 | 2006.2 samples/s | 31.3 steps/s
[Step=36700 Epoch=349.1] | Loss=0.00163 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=7.848 | 5708.4 samples/s | 89.2 steps/s
[Step=36750 Epoch=349.6] | Loss=0.00132 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.538 | L2-Norm(final)=7.850 | 2078.9 samples/s | 32.5 steps/s
[Step=36800 Epoch=350.1] | Loss=0.00111 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.538 | L2-Norm(final)=7.852 | 5140.8 samples/s | 80.3 steps/s
[Step=36850 Epoch=350.5] | Loss=0.00095 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=7.854 | 2190.1 samples/s | 34.2 steps/s
[Step=36900 Epoch=351.0] | Loss=0.00084 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.533 | L2-Norm(final)=7.855 | 4720.3 samples/s | 73.8 steps/s
[Step=36950 Epoch=351.5] | Loss=0.00074 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.530 | L2-Norm(final)=7.857 | 2289.1 samples/s | 35.8 steps/s
[Step=37000 Epoch=352.0] | Loss=0.00067 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.525 | L2-Norm(final)=7.858 | 4361.4 samples/s | 68.1 steps/s
[Step=37050 Epoch=352.4] | Loss=0.00061 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.521 | L2-Norm(final)=7.859 | 2280.1 samples/s | 35.6 steps/s
[Step=37100 Epoch=352.9] | Loss=0.00056 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.516 | L2-Norm(final)=7.860 | 4266.1 samples/s | 66.7 steps/s
[Step=37150 Epoch=353.4] | Loss=0.00052 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.511 | L2-Norm(final)=7.862 | 2436.5 samples/s | 38.1 steps/s
[Step=37200 Epoch=353.9] | Loss=0.00048 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.506 | L2-Norm(final)=7.863 | 4163.7 samples/s | 65.1 steps/s
[Step=37250 Epoch=354.3] | Loss=0.00045 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.500 | L2-Norm(final)=7.864 | 2389.3 samples/s | 37.3 steps/s
[Step=37300 Epoch=354.8] | Loss=0.00042 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.495 | L2-Norm(final)=7.866 | 4235.6 samples/s | 66.2 steps/s
[Step=37350 Epoch=355.3] | Loss=0.00040 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.489 | L2-Norm(final)=7.868 | 2516.3 samples/s | 39.3 steps/s
[Step=37400 Epoch=355.8] | Loss=0.00038 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.483 | L2-Norm(final)=7.869 | 3913.7 samples/s | 61.2 steps/s
[Step=37450 Epoch=356.2] | Loss=0.00036 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.478 | L2-Norm(final)=7.871 | 6589.2 samples/s | 103.0 steps/s
[Step=37500 Epoch=356.7] | Loss=0.00034 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.472 | L2-Norm(final)=7.872 | 2015.2 samples/s | 31.5 steps/s
[Step=37550 Epoch=357.2] | Loss=0.00033 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.466 | L2-Norm(final)=7.874 | 5905.0 samples/s | 92.3 steps/s
[Step=37600 Epoch=357.7] | Loss=0.00031 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.460 | L2-Norm(final)=7.876 | 2058.0 samples/s | 32.2 steps/s
[Step=37650 Epoch=358.1] | Loss=0.00030 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.453 | L2-Norm(final)=7.877 | 5323.9 samples/s | 83.2 steps/s
[Step=37700 Epoch=358.6] | Loss=0.00029 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.447 | L2-Norm(final)=7.879 | 2152.1 samples/s | 33.6 steps/s
[Step=37750 Epoch=359.1] | Loss=0.00027 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.441 | L2-Norm(final)=7.881 | 4892.8 samples/s | 76.4 steps/s
[Step=37800 Epoch=359.6] | Loss=0.00026 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.435 | L2-Norm(final)=7.882 | 2230.4 samples/s | 34.8 steps/s
[Step=37850 Epoch=360.0] | Loss=0.00025 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.428 | L2-Norm(final)=7.884 | 4507.9 samples/s | 70.4 steps/s
[Step=37900 Epoch=360.5] | Loss=0.00025 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.422 | L2-Norm(final)=7.886 | 2309.5 samples/s | 36.1 steps/s
[Step=37950 Epoch=361.0] | Loss=0.00024 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.415 | L2-Norm(final)=7.887 | 4238.5 samples/s | 66.2 steps/s
[Step=38000 Epoch=361.5] | Loss=0.00023 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.409 | L2-Norm(final)=7.889 | 2435.5 samples/s | 38.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step38000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=343.8] | Loss=0.00032 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.640 | L2-Norm(final)=7.028 | 5602.3 samples/s | 87.5 steps/s
[Step=36050 Epoch=344.3] | Loss=0.00080 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.709 | L2-Norm(final)=7.057 | 3938.4 samples/s | 61.5 steps/s
[Step=36100 Epoch=344.7] | Loss=0.00046 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.757 | L2-Norm(final)=7.080 | 7692.3 samples/s | 120.2 steps/s
[Step=36150 Epoch=345.2] | Loss=0.00033 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.779 | L2-Norm(final)=7.098 | 2104.9 samples/s | 32.9 steps/s
[Step=36200 Epoch=345.7] | Loss=0.00026 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.791 | L2-Norm(final)=7.112 | 6561.8 samples/s | 102.5 steps/s
[Step=36250 Epoch=346.2] | Loss=0.00022 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.798 | L2-Norm(final)=7.124 | 2178.6 samples/s | 34.0 steps/s
[Step=36300 Epoch=346.6] | Loss=0.00019 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.803 | L2-Norm(final)=7.134 | 6274.7 samples/s | 98.0 steps/s
[Step=36350 Epoch=347.1] | Loss=0.00017 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.807 | L2-Norm(final)=7.144 | 2296.0 samples/s | 35.9 steps/s
[Step=36400 Epoch=347.6] | Loss=0.00015 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.809 | L2-Norm(final)=7.152 | 5606.4 samples/s | 87.6 steps/s
[Step=36450 Epoch=348.1] | Loss=0.00014 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.811 | L2-Norm(final)=7.161 | 2356.9 samples/s | 36.8 steps/s
[Step=36500 Epoch=348.6] | Loss=0.00013 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=7.168 | 5096.6 samples/s | 79.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=348.6] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.821 | L2-Norm(final)=7.246 | 5062.0 samples/s | 79.1 steps/s
[Step=36550 Epoch=349.0] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.804 | L2-Norm(final)=7.252 | 3894.1 samples/s | 60.8 steps/s
[Step=36600 Epoch=349.5] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.779 | L2-Norm(final)=7.255 | 6377.6 samples/s | 99.7 steps/s
[Step=36650 Epoch=350.0] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.753 | L2-Norm(final)=7.258 | 2021.4 samples/s | 31.6 steps/s
[Step=36700 Epoch=350.5] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.725 | L2-Norm(final)=7.260 | 5543.6 samples/s | 86.6 steps/s
[Step=36750 Epoch=350.9] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.697 | L2-Norm(final)=7.261 | 2062.3 samples/s | 32.2 steps/s
[Step=36800 Epoch=351.4] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.668 | L2-Norm(final)=7.262 | 5324.8 samples/s | 83.2 steps/s
[Step=36850 Epoch=351.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.640 | L2-Norm(final)=7.263 | 2126.2 samples/s | 33.2 steps/s
[Step=36900 Epoch=352.4] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.611 | L2-Norm(final)=7.264 | 5015.0 samples/s | 78.4 steps/s
[Step=36950 Epoch=352.8] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.583 | L2-Norm(final)=7.265 | 2237.9 samples/s | 35.0 steps/s
[Step=37000 Epoch=353.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.554 | L2-Norm(final)=7.265 | 4506.0 samples/s | 70.4 steps/s
[Step=37050 Epoch=353.8] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.525 | L2-Norm(final)=7.266 | 2248.8 samples/s | 35.1 steps/s
[Step=37100 Epoch=354.3] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.496 | L2-Norm(final)=7.267 | 4337.2 samples/s | 67.8 steps/s
[Step=37150 Epoch=354.8] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.467 | L2-Norm(final)=7.267 | 2356.3 samples/s | 36.8 steps/s
[Step=37200 Epoch=355.2] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=7.268 | 4174.7 samples/s | 65.2 steps/s
[Step=37250 Epoch=355.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.409 | L2-Norm(final)=7.269 | 2386.5 samples/s | 37.3 steps/s
[Step=37300 Epoch=356.2] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=7.269 | 4257.4 samples/s | 66.5 steps/s
[Step=37350 Epoch=356.7] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.351 | L2-Norm(final)=7.270 | 2346.9 samples/s | 36.7 steps/s
[Step=37400 Epoch=357.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=7.271 | 4294.6 samples/s | 67.1 steps/s
[Step=37450 Epoch=357.6] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.293 | L2-Norm(final)=7.272 | 2358.5 samples/s | 36.9 steps/s
[Step=37500 Epoch=358.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.263 | L2-Norm(final)=7.272 | 4225.3 samples/s | 66.0 steps/s
[Step=37550 Epoch=358.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.234 | L2-Norm(final)=7.273 | 6847.6 samples/s | 107.0 steps/s
[Step=37600 Epoch=359.1] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.204 | L2-Norm(final)=7.274 | 1964.8 samples/s | 30.7 steps/s
[Step=37650 Epoch=359.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=7.275 | 6152.5 samples/s | 96.1 steps/s
[Step=37700 Epoch=360.0] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.144 | L2-Norm(final)=7.276 | 1962.3 samples/s | 30.7 steps/s
[Step=37750 Epoch=360.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.114 | L2-Norm(final)=7.276 | 5752.0 samples/s | 89.9 steps/s
[Step=37800 Epoch=361.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.277 | 2070.1 samples/s | 32.3 steps/s
[Step=37850 Epoch=361.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=7.278 | 5395.2 samples/s | 84.3 steps/s
[Step=37900 Epoch=361.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.024 | L2-Norm(final)=7.279 | 2120.8 samples/s | 33.1 steps/s
[Step=37950 Epoch=362.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.994 | L2-Norm(final)=7.280 | 4941.9 samples/s | 77.2 steps/s
[Step=38000 Epoch=362.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.963 | L2-Norm(final)=7.281 | 2206.9 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step38000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=339.2] | Loss=0.00023 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.666 | L2-Norm(final)=6.996 | 5103.4 samples/s | 79.7 steps/s
[Step=36050 Epoch=339.7] | Loss=0.00101 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.707 | L2-Norm(final)=7.032 | 4299.4 samples/s | 67.2 steps/s
[Step=36100 Epoch=340.2] | Loss=0.00075 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.785 | L2-Norm(final)=7.061 | 7116.3 samples/s | 111.2 steps/s
[Step=36150 Epoch=340.6] | Loss=0.00054 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.821 | L2-Norm(final)=7.080 | 2133.4 samples/s | 33.3 steps/s
[Step=36200 Epoch=341.1] | Loss=0.00042 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.840 | L2-Norm(final)=7.095 | 6356.0 samples/s | 99.3 steps/s
[Step=36250 Epoch=341.6] | Loss=0.00035 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.852 | L2-Norm(final)=7.106 | 2179.5 samples/s | 34.1 steps/s
[Step=36300 Epoch=342.0] | Loss=0.00030 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.860 | L2-Norm(final)=7.116 | 5688.2 samples/s | 88.9 steps/s
[Step=36350 Epoch=342.5] | Loss=0.00026 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.865 | L2-Norm(final)=7.125 | 2365.7 samples/s | 37.0 steps/s
[Step=36400 Epoch=343.0] | Loss=0.00023 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.869 | L2-Norm(final)=7.133 | 5065.3 samples/s | 79.1 steps/s
[Step=36450 Epoch=343.5] | Loss=0.00021 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.872 | L2-Norm(final)=7.140 | 2456.4 samples/s | 38.4 steps/s
[Step=36500 Epoch=343.9] | Loss=0.00019 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.874 | L2-Norm(final)=7.148 | 4746.8 samples/s | 74.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=343.9] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.893 | L2-Norm(final)=7.222 | 5194.2 samples/s | 81.2 steps/s
[Step=36550 Epoch=344.4] | Loss=0.01524 | Reg=0.00099 | acc=0.9531 | L2-Norm=9.974 | L2-Norm(final)=7.202 | 3988.7 samples/s | 62.3 steps/s
[Step=36600 Epoch=344.9] | Loss=0.01173 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.152 | L2-Norm(final)=7.147 | 6209.8 samples/s | 97.0 steps/s
[Step=36650 Epoch=345.3] | Loss=0.00820 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.227 | L2-Norm(final)=7.126 | 2015.6 samples/s | 31.5 steps/s
[Step=36700 Epoch=345.8] | Loss=0.00641 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.266 | L2-Norm(final)=7.116 | 5515.5 samples/s | 86.2 steps/s
[Step=36750 Epoch=346.3] | Loss=0.00544 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=7.111 | 2143.1 samples/s | 33.5 steps/s
[Step=36800 Epoch=346.8] | Loss=0.00458 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.314 | L2-Norm(final)=7.109 | 4753.2 samples/s | 74.3 steps/s
[Step=36850 Epoch=347.2] | Loss=0.00396 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.328 | L2-Norm(final)=7.108 | 2212.7 samples/s | 34.6 steps/s
[Step=36900 Epoch=347.7] | Loss=0.00347 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.339 | L2-Norm(final)=7.109 | 4475.7 samples/s | 69.9 steps/s
[Step=36950 Epoch=348.2] | Loss=0.00309 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.348 | L2-Norm(final)=7.109 | 2314.6 samples/s | 36.2 steps/s
[Step=37000 Epoch=348.6] | Loss=0.00278 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.354 | L2-Norm(final)=7.109 | 4265.6 samples/s | 66.7 steps/s
[Step=37050 Epoch=349.1] | Loss=0.00253 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.359 | L2-Norm(final)=7.109 | 2366.4 samples/s | 37.0 steps/s
[Step=37100 Epoch=349.6] | Loss=0.00232 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.363 | L2-Norm(final)=7.109 | 4211.1 samples/s | 65.8 steps/s
[Step=37150 Epoch=350.1] | Loss=0.00214 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.365 | L2-Norm(final)=7.110 | 2392.4 samples/s | 37.4 steps/s
[Step=37200 Epoch=350.5] | Loss=0.00199 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=7.110 | 4262.3 samples/s | 66.6 steps/s
[Step=37250 Epoch=351.0] | Loss=0.00185 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=7.110 | 2672.1 samples/s | 41.8 steps/s
[Step=37300 Epoch=351.5] | Loss=0.00174 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.368 | L2-Norm(final)=7.110 | 3744.5 samples/s | 58.5 steps/s
[Step=37350 Epoch=351.9] | Loss=0.00164 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.368 | L2-Norm(final)=7.110 | 6205.4 samples/s | 97.0 steps/s
[Step=37400 Epoch=352.4] | Loss=0.00155 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.367 | L2-Norm(final)=7.111 | 2000.1 samples/s | 31.3 steps/s
[Step=37450 Epoch=352.9] | Loss=0.00146 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.366 | L2-Norm(final)=7.111 | 5606.7 samples/s | 87.6 steps/s
[Step=37500 Epoch=353.4] | Loss=0.00139 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.365 | L2-Norm(final)=7.111 | 2138.3 samples/s | 33.4 steps/s
[Step=37550 Epoch=353.8] | Loss=0.00133 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.363 | L2-Norm(final)=7.111 | 4820.2 samples/s | 75.3 steps/s
[Step=37600 Epoch=354.3] | Loss=0.00127 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.362 | L2-Norm(final)=7.111 | 2198.8 samples/s | 34.4 steps/s
[Step=37650 Epoch=354.8] | Loss=0.00121 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.360 | L2-Norm(final)=7.111 | 4528.2 samples/s | 70.8 steps/s
[Step=37700 Epoch=355.2] | Loss=0.00116 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.358 | L2-Norm(final)=7.112 | 2232.6 samples/s | 34.9 steps/s
[Step=37750 Epoch=355.7] | Loss=0.00111 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.355 | L2-Norm(final)=7.112 | 4256.2 samples/s | 66.5 steps/s
[Step=37800 Epoch=356.2] | Loss=0.00107 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.353 | L2-Norm(final)=7.112 | 2413.3 samples/s | 37.7 steps/s
[Step=37850 Epoch=356.7] | Loss=0.00103 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.351 | L2-Norm(final)=7.112 | 4233.7 samples/s | 66.2 steps/s
[Step=37900 Epoch=357.1] | Loss=0.00099 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.348 | L2-Norm(final)=7.112 | 2410.5 samples/s | 37.7 steps/s
[Step=37950 Epoch=357.6] | Loss=0.00096 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.345 | L2-Norm(final)=7.113 | 4259.3 samples/s | 66.6 steps/s
[Step=38000 Epoch=358.1] | Loss=0.00093 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.342 | L2-Norm(final)=7.113 | 2491.8 samples/s | 38.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step38000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=343.1] | Loss=0.00011 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.967 | L2-Norm(final)=7.758 | 4947.6 samples/s | 77.3 steps/s
[Step=36050 Epoch=343.6] | Loss=0.00007 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.975 | L2-Norm(final)=7.765 | 4484.4 samples/s | 70.1 steps/s
[Step=36100 Epoch=344.1] | Loss=0.00008 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=7.773 | 7447.5 samples/s | 116.4 steps/s
[Step=36150 Epoch=344.5] | Loss=0.00007 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=7.781 | 2127.4 samples/s | 33.2 steps/s
[Step=36200 Epoch=345.0] | Loss=0.00007 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.986 | L2-Norm(final)=7.788 | 6655.1 samples/s | 104.0 steps/s
[Step=36250 Epoch=345.5] | Loss=0.00006 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.987 | L2-Norm(final)=7.795 | 2196.8 samples/s | 34.3 steps/s
[Step=36300 Epoch=346.0] | Loss=0.00006 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.988 | L2-Norm(final)=7.802 | 6097.7 samples/s | 95.3 steps/s
[Step=36350 Epoch=346.4] | Loss=0.00006 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.989 | L2-Norm(final)=7.808 | 2287.9 samples/s | 35.7 steps/s
[Step=36400 Epoch=346.9] | Loss=0.00006 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.989 | L2-Norm(final)=7.815 | 5672.2 samples/s | 88.6 steps/s
[Step=36450 Epoch=347.4] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.989 | L2-Norm(final)=7.821 | 2316.3 samples/s | 36.2 steps/s
[Step=36500 Epoch=347.9] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.989 | L2-Norm(final)=7.827 | 5245.0 samples/s | 82.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=347.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.987 | L2-Norm(final)=7.887 | 4919.0 samples/s | 76.9 steps/s
[Step=36550 Epoch=348.4] | Loss=0.00003 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.981 | L2-Norm(final)=7.892 | 3973.4 samples/s | 62.1 steps/s
[Step=36600 Epoch=348.8] | Loss=0.00002 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.973 | L2-Norm(final)=7.897 | 6263.4 samples/s | 97.9 steps/s
[Step=36650 Epoch=349.3] | Loss=0.00002 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.963 | L2-Norm(final)=7.900 | 1992.6 samples/s | 31.1 steps/s
[Step=36700 Epoch=349.8] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=7.902 | 5816.6 samples/s | 90.9 steps/s
[Step=36750 Epoch=350.3] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.939 | L2-Norm(final)=7.904 | 2055.6 samples/s | 32.1 steps/s
[Step=36800 Epoch=350.7] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.927 | L2-Norm(final)=7.905 | 5379.1 samples/s | 84.0 steps/s
[Step=36850 Epoch=351.2] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.914 | L2-Norm(final)=7.907 | 2115.4 samples/s | 33.1 steps/s
[Step=36900 Epoch=351.7] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.902 | L2-Norm(final)=7.908 | 4880.8 samples/s | 76.3 steps/s
[Step=36950 Epoch=352.2] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.889 | L2-Norm(final)=7.909 | 2223.2 samples/s | 34.7 steps/s
[Step=37000 Epoch=352.6] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.876 | L2-Norm(final)=7.910 | 4531.4 samples/s | 70.8 steps/s
[Step=37050 Epoch=353.1] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.863 | L2-Norm(final)=7.911 | 2276.3 samples/s | 35.6 steps/s
[Step=37100 Epoch=353.6] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.850 | L2-Norm(final)=7.912 | 4267.6 samples/s | 66.7 steps/s
[Step=37150 Epoch=354.1] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.837 | L2-Norm(final)=7.913 | 2343.2 samples/s | 36.6 steps/s
[Step=37200 Epoch=354.5] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.824 | L2-Norm(final)=7.914 | 4195.2 samples/s | 65.5 steps/s
[Step=37250 Epoch=355.0] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.810 | L2-Norm(final)=7.915 | 2394.4 samples/s | 37.4 steps/s
[Step=37300 Epoch=355.5] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.797 | L2-Norm(final)=7.916 | 4221.1 samples/s | 66.0 steps/s
[Step=37350 Epoch=356.0] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.783 | L2-Norm(final)=7.917 | 2412.0 samples/s | 37.7 steps/s
[Step=37400 Epoch=356.5] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.770 | L2-Norm(final)=7.918 | 4175.0 samples/s | 65.2 steps/s
[Step=37450 Epoch=356.9] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.756 | L2-Norm(final)=7.918 | 2386.5 samples/s | 37.3 steps/s
[Step=37500 Epoch=357.4] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.742 | L2-Norm(final)=7.919 | 4220.8 samples/s | 65.9 steps/s
[Step=37550 Epoch=357.9] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.728 | L2-Norm(final)=7.920 | 7015.3 samples/s | 109.6 steps/s
[Step=37600 Epoch=358.4] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.714 | L2-Norm(final)=7.921 | 1964.0 samples/s | 30.7 steps/s
[Step=37650 Epoch=358.8] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.699 | L2-Norm(final)=7.922 | 6310.1 samples/s | 98.6 steps/s
[Step=37700 Epoch=359.3] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.685 | L2-Norm(final)=7.923 | 1979.0 samples/s | 30.9 steps/s
[Step=37750 Epoch=359.8] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.670 | L2-Norm(final)=7.924 | 5801.8 samples/s | 90.7 steps/s
[Step=37800 Epoch=360.3] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=7.924 | 2097.7 samples/s | 32.8 steps/s
[Step=37850 Epoch=360.7] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=7.925 | 5213.6 samples/s | 81.5 steps/s
[Step=37900 Epoch=361.2] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.626 | L2-Norm(final)=7.926 | 2141.2 samples/s | 33.5 steps/s
[Step=37950 Epoch=361.7] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.611 | L2-Norm(final)=7.927 | 4936.3 samples/s | 77.1 steps/s
[Step=38000 Epoch=362.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.595 | L2-Norm(final)=7.928 | 2192.1 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12875 | acc=0.9572 | tpr=0.9771 | fpr=0.0860 | 4554.2 samples/s | 17.8 steps/s
Avg test loss: 0.13274, Avg test acc: 0.95557, Avg tpr: 0.97540, Avg fpr: 0.08807, total FA: 687

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.14143 | acc=0.9498 | tpr=0.9555 | fpr=0.0627 | 4691.8 samples/s | 18.3 steps/s
Avg test loss: 0.14435, Avg test acc: 0.94883, Avg tpr: 0.95460, Avg fpr: 0.06384, total FA: 498

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.12336 | acc=0.9557 | tpr=0.9717 | fpr=0.0790 | 4984.7 samples/s | 19.5 steps/s
Avg test loss: 0.12403, Avg test acc: 0.95537, Avg tpr: 0.97103, Avg fpr: 0.07909, total FA: 617

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.12829 | acc=0.9560 | tpr=0.9628 | fpr=0.0587 | 4825.2 samples/s | 18.8 steps/s
Avg test loss: 0.13386, Avg test acc: 0.95464, Avg tpr: 0.96182, Avg fpr: 0.06115, total FA: 477

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.12155 | acc=0.9569 | tpr=0.9718 | fpr=0.0756 | 4796.0 samples/s | 18.7 steps/s
Avg test loss: 0.12755, Avg test acc: 0.95549, Avg tpr: 0.97086, Avg fpr: 0.07832, total FA: 611

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.24884 | acc=0.2865 | tpr=0.0185 | fpr=0.1316 | 4972.9 samples/s | 19.4 steps/s
Avg test loss: 5.25270, Avg test acc: 0.28584, Avg tpr: 0.02011, Avg fpr: 0.12973, total FA: 1012

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.48807 | acc=0.3008 | tpr=0.0052 | fpr=0.0575 | 5088.9 samples/s | 19.9 steps/s
Avg test loss: 4.49667, Avg test acc: 0.29854, Avg tpr: 0.00583, Avg fpr: 0.05768, total FA: 450

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.23185 | acc=0.2737 | tpr=0.0165 | fpr=0.1677 | 4759.7 samples/s | 18.6 steps/s
Avg test loss: 5.23220, Avg test acc: 0.27246, Avg tpr: 0.01725, Avg fpr: 0.16626, total FA: 1297

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.34172 | acc=0.2909 | tpr=0.0136 | fpr=0.1070 | 4924.5 samples/s | 19.2 steps/s
Avg test loss: 5.35721, Avg test acc: 0.28929, Avg tpr: 0.01346, Avg fpr: 0.10409, total FA: 812

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.03959 | acc=0.3002 | tpr=0.0291 | fpr=0.1110 | 4700.0 samples/s | 18.4 steps/s
Avg test loss: 5.04676, Avg test acc: 0.29874, Avg tpr: 0.03008, Avg fpr: 0.11037, total FA: 861

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.10361 | acc=0.0794 | tpr=0.7168 | fpr=0.9321 | 4690.5 samples/s | 18.3 steps/s
[Step= 100] | Loss=6.09697 | acc=0.0798 | tpr=0.6866 | fpr=0.9316 | 7208.0 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.10766 | acc=0.0804 | tpr=0.6830 | fpr=0.9306 | 7960.1 samples/s | 31.1 steps/s
[Step= 200] | Loss=6.10914 | acc=0.0803 | tpr=0.6874 | fpr=0.9308 | 7901.0 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.11728 | acc=0.0809 | tpr=0.6856 | fpr=0.9302 | 7861.8 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.11379 | acc=0.0811 | tpr=0.6851 | fpr=0.9299 | 7661.1 samples/s | 29.9 steps/s
[Step= 350] | Loss=6.10990 | acc=0.0816 | tpr=0.6857 | fpr=0.9294 | 8071.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.10510 | acc=0.0818 | tpr=0.6805 | fpr=0.9291 | 7595.9 samples/s | 29.7 steps/s
[Step= 450] | Loss=6.11015 | acc=0.0818 | tpr=0.6787 | fpr=0.9290 | 8148.7 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.11489 | acc=0.0816 | tpr=0.6753 | fpr=0.9291 | 7938.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=6.11582 | acc=0.0817 | tpr=0.6753 | fpr=0.9291 | 14116.3 samples/s | 55.1 steps/s
Avg test loss: 6.11757, Avg test acc: 0.08161, Avg tpr: 0.67512, Avg fpr: 0.92917, total FA: 129014

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.14624 | acc=0.1199 | tpr=0.5619 | fpr=0.8880 | 5056.0 samples/s | 19.7 steps/s
[Step= 100] | Loss=5.11180 | acc=0.1232 | tpr=0.5736 | fpr=0.8852 | 6680.2 samples/s | 26.1 steps/s
[Step= 150] | Loss=5.12113 | acc=0.1221 | tpr=0.5663 | fpr=0.8861 | 7668.8 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.11218 | acc=0.1223 | tpr=0.5628 | fpr=0.8858 | 7786.2 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.11446 | acc=0.1224 | tpr=0.5581 | fpr=0.8855 | 7940.8 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.10983 | acc=0.1225 | tpr=0.5607 | fpr=0.8855 | 8012.9 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.10488 | acc=0.1222 | tpr=0.5629 | fpr=0.8858 | 7683.0 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.09885 | acc=0.1223 | tpr=0.5607 | fpr=0.8857 | 8163.2 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.10126 | acc=0.1222 | tpr=0.5604 | fpr=0.8857 | 7891.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.10587 | acc=0.1217 | tpr=0.5586 | fpr=0.8862 | 7486.1 samples/s | 29.2 steps/s
[Step= 550] | Loss=5.10819 | acc=0.1216 | tpr=0.5555 | fpr=0.8863 | 14699.2 samples/s | 57.4 steps/s
Avg test loss: 5.11022, Avg test acc: 0.12147, Avg tpr: 0.55507, Avg fpr: 0.88642, total FA: 123077

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.33015 | acc=0.0887 | tpr=0.5531 | fpr=0.9197 | 4767.5 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.30245 | acc=0.0886 | tpr=0.5458 | fpr=0.9199 | 7130.4 samples/s | 27.9 steps/s
[Step= 150] | Loss=6.30300 | acc=0.0882 | tpr=0.5389 | fpr=0.9201 | 7851.0 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.29923 | acc=0.0891 | tpr=0.5344 | fpr=0.9190 | 7953.9 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.30217 | acc=0.0898 | tpr=0.5301 | fpr=0.9182 | 7651.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=6.30014 | acc=0.0900 | tpr=0.5353 | fpr=0.9181 | 8107.5 samples/s | 31.7 steps/s
[Step= 350] | Loss=6.29127 | acc=0.0898 | tpr=0.5310 | fpr=0.9182 | 7672.9 samples/s | 30.0 steps/s
[Step= 400] | Loss=6.28689 | acc=0.0896 | tpr=0.5246 | fpr=0.9183 | 8027.0 samples/s | 31.4 steps/s
[Step= 450] | Loss=6.28706 | acc=0.0896 | tpr=0.5248 | fpr=0.9183 | 8042.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.29001 | acc=0.0893 | tpr=0.5203 | fpr=0.9185 | 7730.6 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.29240 | acc=0.0894 | tpr=0.5221 | fpr=0.9185 | 13938.8 samples/s | 54.4 steps/s
Avg test loss: 6.29390, Avg test acc: 0.08925, Avg tpr: 0.52219, Avg fpr: 0.91862, total FA: 127549

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.53775 | acc=0.1333 | tpr=0.5619 | fpr=0.8744 | 4666.3 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.53689 | acc=0.1322 | tpr=0.5352 | fpr=0.8753 | 7516.0 samples/s | 29.4 steps/s
[Step= 150] | Loss=5.54084 | acc=0.1326 | tpr=0.5403 | fpr=0.8750 | 7664.2 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.53423 | acc=0.1324 | tpr=0.5355 | fpr=0.8750 | 7938.6 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.54004 | acc=0.1320 | tpr=0.5249 | fpr=0.8752 | 7920.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.53293 | acc=0.1324 | tpr=0.5331 | fpr=0.8749 | 7840.0 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.52458 | acc=0.1325 | tpr=0.5316 | fpr=0.8747 | 7709.9 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.51964 | acc=0.1328 | tpr=0.5317 | fpr=0.8745 | 8061.3 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.52515 | acc=0.1323 | tpr=0.5316 | fpr=0.8749 | 8035.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.52760 | acc=0.1319 | tpr=0.5295 | fpr=0.8753 | 7743.2 samples/s | 30.2 steps/s
[Step= 550] | Loss=5.53102 | acc=0.1317 | tpr=0.5253 | fpr=0.8755 | 13813.1 samples/s | 54.0 steps/s
Avg test loss: 5.53200, Avg test acc: 0.13155, Avg tpr: 0.52536, Avg fpr: 0.87561, total FA: 121577

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.19845 | acc=0.0864 | tpr=0.4867 | fpr=0.9208 | 4962.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=6.20137 | acc=0.0904 | tpr=0.5160 | fpr=0.9176 | 6771.5 samples/s | 26.5 steps/s
[Step= 150] | Loss=6.19556 | acc=0.0913 | tpr=0.5072 | fpr=0.9164 | 7773.9 samples/s | 30.4 steps/s
[Step= 200] | Loss=6.20553 | acc=0.0914 | tpr=0.4907 | fpr=0.9158 | 7885.8 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.21410 | acc=0.0911 | tpr=0.4934 | fpr=0.9162 | 7478.6 samples/s | 29.2 steps/s
[Step= 300] | Loss=6.20904 | acc=0.0914 | tpr=0.4989 | fpr=0.9160 | 8174.7 samples/s | 31.9 steps/s
[Step= 350] | Loss=6.20221 | acc=0.0916 | tpr=0.5009 | fpr=0.9158 | 8152.4 samples/s | 31.8 steps/s
[Step= 400] | Loss=6.20011 | acc=0.0920 | tpr=0.5000 | fpr=0.9154 | 7590.7 samples/s | 29.7 steps/s
[Step= 450] | Loss=6.20182 | acc=0.0922 | tpr=0.4985 | fpr=0.9152 | 7781.7 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.20431 | acc=0.0919 | tpr=0.4912 | fpr=0.9153 | 8075.0 samples/s | 31.5 steps/s
[Step= 550] | Loss=6.20859 | acc=0.0915 | tpr=0.4938 | fpr=0.9158 | 14008.2 samples/s | 54.7 steps/s
Avg test loss: 6.21126, Avg test acc: 0.09138, Avg tpr: 0.49366, Avg fpr: 0.91593, total FA: 127175

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09577 | acc=0.9812 | tpr=0.9381 | fpr=0.0181 | 4624.2 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.09954 | acc=0.9811 | tpr=0.9403 | fpr=0.0181 | 7490.8 samples/s | 29.3 steps/s
[Step= 150] | Loss=0.10310 | acc=0.9804 | tpr=0.9409 | fpr=0.0189 | 7887.6 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.10488 | acc=0.9803 | tpr=0.9464 | fpr=0.0191 | 7849.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.10323 | acc=0.9806 | tpr=0.9432 | fpr=0.0188 | 7533.6 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.10582 | acc=0.9800 | tpr=0.9411 | fpr=0.0193 | 7955.6 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.10707 | acc=0.9799 | tpr=0.9424 | fpr=0.0194 | 8173.4 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.10817 | acc=0.9797 | tpr=0.9382 | fpr=0.0196 | 7680.6 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.11039 | acc=0.9793 | tpr=0.9372 | fpr=0.0199 | 7968.5 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.10951 | acc=0.9795 | tpr=0.9392 | fpr=0.0198 | 7921.6 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.10901 | acc=0.9796 | tpr=0.9387 | fpr=0.0196 | 13621.3 samples/s | 53.2 steps/s
Avg test loss: 0.10896, Avg test acc: 0.97964, Avg tpr: 0.93899, Avg fpr: 0.01963, total FA: 2725

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08581 | acc=0.9834 | tpr=0.8982 | fpr=0.0151 | 4674.1 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.08915 | acc=0.9830 | tpr=0.8934 | fpr=0.0153 | 7455.7 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.09252 | acc=0.9823 | tpr=0.8948 | fpr=0.0161 | 7668.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.09453 | acc=0.9821 | tpr=0.9016 | fpr=0.0165 | 8126.0 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.09244 | acc=0.9822 | tpr=0.8996 | fpr=0.0163 | 7661.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.09501 | acc=0.9818 | tpr=0.8953 | fpr=0.0167 | 7796.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.09549 | acc=0.9816 | tpr=0.9011 | fpr=0.0169 | 8176.0 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.09605 | acc=0.9814 | tpr=0.8955 | fpr=0.0171 | 7871.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.09813 | acc=0.9810 | tpr=0.8924 | fpr=0.0174 | 7663.5 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.09716 | acc=0.9811 | tpr=0.8943 | fpr=0.0173 | 7952.1 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.09712 | acc=0.9812 | tpr=0.8934 | fpr=0.0172 | 13605.4 samples/s | 53.1 steps/s
Avg test loss: 0.09699, Avg test acc: 0.98121, Avg tpr: 0.89342, Avg fpr: 0.01720, total FA: 2388

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09305 | acc=0.9811 | tpr=0.9558 | fpr=0.0185 | 4822.8 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09535 | acc=0.9809 | tpr=0.9574 | fpr=0.0187 | 7105.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09919 | acc=0.9802 | tpr=0.9582 | fpr=0.0194 | 7547.0 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.10094 | acc=0.9803 | tpr=0.9596 | fpr=0.0193 | 8093.0 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.09944 | acc=0.9805 | tpr=0.9581 | fpr=0.0190 | 7907.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.10151 | acc=0.9802 | tpr=0.9513 | fpr=0.0193 | 7845.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.10235 | acc=0.9800 | tpr=0.9524 | fpr=0.0195 | 7734.2 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.10357 | acc=0.9797 | tpr=0.9502 | fpr=0.0198 | 7666.5 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.10554 | acc=0.9795 | tpr=0.9489 | fpr=0.0199 | 7970.9 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.10499 | acc=0.9795 | tpr=0.9498 | fpr=0.0200 | 7923.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.10458 | acc=0.9796 | tpr=0.9487 | fpr=0.0199 | 14172.9 samples/s | 55.4 steps/s
Avg test loss: 0.10449, Avg test acc: 0.97960, Avg tpr: 0.94889, Avg fpr: 0.01984, total FA: 2755

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.07511 | acc=0.9848 | tpr=0.9115 | fpr=0.0139 | 4869.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.08052 | acc=0.9841 | tpr=0.8955 | fpr=0.0142 | 6899.1 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.08449 | acc=0.9836 | tpr=0.9049 | fpr=0.0150 | 7673.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.08604 | acc=0.9833 | tpr=0.9104 | fpr=0.0154 | 8200.4 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.08504 | acc=0.9836 | tpr=0.9092 | fpr=0.0151 | 7877.7 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.08765 | acc=0.9832 | tpr=0.9047 | fpr=0.0154 | 7904.3 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.08773 | acc=0.9831 | tpr=0.9080 | fpr=0.0155 | 7848.5 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.08811 | acc=0.9830 | tpr=0.9054 | fpr=0.0156 | 7388.1 samples/s | 28.9 steps/s
[Step= 450] | Loss=0.09034 | acc=0.9826 | tpr=0.9026 | fpr=0.0159 | 8348.5 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.08946 | acc=0.9827 | tpr=0.9053 | fpr=0.0159 | 7729.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.08928 | acc=0.9829 | tpr=0.9049 | fpr=0.0157 | 13874.2 samples/s | 54.2 steps/s
Avg test loss: 0.08916, Avg test acc: 0.98292, Avg tpr: 0.90531, Avg fpr: 0.01566, total FA: 2175

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10589 | acc=0.9811 | tpr=0.9248 | fpr=0.0179 | 4788.5 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.11175 | acc=0.9802 | tpr=0.9232 | fpr=0.0187 | 7149.0 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.11548 | acc=0.9793 | tpr=0.9280 | fpr=0.0198 | 7766.7 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.11754 | acc=0.9790 | tpr=0.9344 | fpr=0.0202 | 8207.7 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.11590 | acc=0.9794 | tpr=0.9336 | fpr=0.0198 | 7760.7 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.11836 | acc=0.9791 | tpr=0.9295 | fpr=0.0200 | 7802.0 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.11906 | acc=0.9789 | tpr=0.9317 | fpr=0.0203 | 8034.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.12037 | acc=0.9787 | tpr=0.9267 | fpr=0.0204 | 7651.5 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.12309 | acc=0.9783 | tpr=0.9245 | fpr=0.0207 | 8041.3 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.12241 | acc=0.9784 | tpr=0.9251 | fpr=0.0206 | 7688.3 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.12187 | acc=0.9786 | tpr=0.9240 | fpr=0.0204 | 14335.1 samples/s | 56.0 steps/s
Avg test loss: 0.12173, Avg test acc: 0.97864, Avg tpr: 0.92433, Avg fpr: 0.02037, total FA: 2829

server round 19/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=185.3] | Loss=0.00428 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.917 | L2-Norm(final)=11.939 | 5538.7 samples/s | 86.5 steps/s
[Step=38050 Epoch=185.5] | Loss=0.00348 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.915 | L2-Norm(final)=11.947 | 4377.2 samples/s | 68.4 steps/s
[Step=38100 Epoch=185.8] | Loss=0.00383 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.911 | L2-Norm(final)=11.959 | 5064.4 samples/s | 79.1 steps/s
[Step=38150 Epoch=186.0] | Loss=0.00380 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.909 | L2-Norm(final)=11.970 | 5006.5 samples/s | 78.2 steps/s
[Step=38200 Epoch=186.3] | Loss=0.00365 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.907 | L2-Norm(final)=11.982 | 7826.6 samples/s | 122.3 steps/s
[Step=38250 Epoch=186.5] | Loss=0.00364 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.904 | L2-Norm(final)=11.993 | 2247.4 samples/s | 35.1 steps/s
[Step=38300 Epoch=186.8] | Loss=0.00359 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.901 | L2-Norm(final)=12.004 | 4895.6 samples/s | 76.5 steps/s
[Step=38350 Epoch=187.0] | Loss=0.00351 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.897 | L2-Norm(final)=12.016 | 4947.6 samples/s | 77.3 steps/s
[Step=38400 Epoch=187.2] | Loss=0.00344 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.892 | L2-Norm(final)=12.026 | 6954.2 samples/s | 108.7 steps/s
[Step=38450 Epoch=187.5] | Loss=0.00333 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.887 | L2-Norm(final)=12.037 | 2333.9 samples/s | 36.5 steps/s
[Step=38500 Epoch=187.7] | Loss=0.00329 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.882 | L2-Norm(final)=12.048 | 5051.0 samples/s | 78.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=187.7] | Loss=0.00119 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.827 | L2-Norm(final)=12.153 | 5503.9 samples/s | 86.0 steps/s
[Step=38550 Epoch=188.0] | Loss=0.00485 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.826 | L2-Norm(final)=12.163 | 3934.0 samples/s | 61.5 steps/s
[Step=38600 Epoch=188.2] | Loss=0.00610 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.832 | L2-Norm(final)=12.171 | 4489.7 samples/s | 70.2 steps/s
[Step=38650 Epoch=188.5] | Loss=0.00692 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.850 | L2-Norm(final)=12.178 | 4367.9 samples/s | 68.2 steps/s
[Step=38700 Epoch=188.7] | Loss=0.00956 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.881 | L2-Norm(final)=12.184 | 6519.1 samples/s | 101.9 steps/s
[Step=38750 Epoch=189.0] | Loss=0.01069 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.913 | L2-Norm(final)=12.192 | 2097.9 samples/s | 32.8 steps/s
[Step=38800 Epoch=189.2] | Loss=0.01113 | Reg=0.00359 | acc=0.9531 | L2-Norm=18.945 | L2-Norm(final)=12.197 | 4519.6 samples/s | 70.6 steps/s
[Step=38850 Epoch=189.4] | Loss=0.01178 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.974 | L2-Norm(final)=12.202 | 4316.7 samples/s | 67.4 steps/s
[Step=38900 Epoch=189.7] | Loss=0.01187 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.003 | L2-Norm(final)=12.207 | 5899.1 samples/s | 92.2 steps/s
[Step=38950 Epoch=189.9] | Loss=0.01216 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.030 | L2-Norm(final)=12.211 | 2150.6 samples/s | 33.6 steps/s
[Step=39000 Epoch=190.2] | Loss=0.01187 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.054 | L2-Norm(final)=12.215 | 4362.3 samples/s | 68.2 steps/s
[Step=39050 Epoch=190.4] | Loss=0.01144 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.075 | L2-Norm(final)=12.219 | 4514.2 samples/s | 70.5 steps/s
[Step=39100 Epoch=190.7] | Loss=0.01130 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.093 | L2-Norm(final)=12.224 | 5373.5 samples/s | 84.0 steps/s
[Step=39150 Epoch=190.9] | Loss=0.01093 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.109 | L2-Norm(final)=12.229 | 2267.6 samples/s | 35.4 steps/s
[Step=39200 Epoch=191.1] | Loss=0.01048 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.123 | L2-Norm(final)=12.234 | 4421.6 samples/s | 69.1 steps/s
[Step=39250 Epoch=191.4] | Loss=0.01018 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.133 | L2-Norm(final)=12.238 | 4386.3 samples/s | 68.5 steps/s
[Step=39300 Epoch=191.6] | Loss=0.01002 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.142 | L2-Norm(final)=12.242 | 4982.1 samples/s | 77.8 steps/s
[Step=39350 Epoch=191.9] | Loss=0.00969 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.150 | L2-Norm(final)=12.245 | 2368.5 samples/s | 37.0 steps/s
[Step=39400 Epoch=192.1] | Loss=0.00943 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.157 | L2-Norm(final)=12.248 | 4352.2 samples/s | 68.0 steps/s
[Step=39450 Epoch=192.4] | Loss=0.00910 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.162 | L2-Norm(final)=12.252 | 4446.2 samples/s | 69.5 steps/s
[Step=39500 Epoch=192.6] | Loss=0.00896 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.166 | L2-Norm(final)=12.255 | 4624.6 samples/s | 72.3 steps/s
[Step=39550 Epoch=192.9] | Loss=0.00871 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.169 | L2-Norm(final)=12.257 | 2436.4 samples/s | 38.1 steps/s
[Step=39600 Epoch=193.1] | Loss=0.00844 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.171 | L2-Norm(final)=12.260 | 4526.7 samples/s | 70.7 steps/s
[Step=39650 Epoch=193.3] | Loss=0.00822 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=12.263 | 4440.7 samples/s | 69.4 steps/s
[Step=39700 Epoch=193.6] | Loss=0.00801 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=12.266 | 4490.4 samples/s | 70.2 steps/s
[Step=39750 Epoch=193.8] | Loss=0.00782 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=12.268 | 2440.2 samples/s | 38.1 steps/s
[Step=39800 Epoch=194.1] | Loss=0.00768 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.171 | L2-Norm(final)=12.271 | 4491.7 samples/s | 70.2 steps/s
[Step=39850 Epoch=194.3] | Loss=0.00748 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.170 | L2-Norm(final)=12.273 | 4481.9 samples/s | 70.0 steps/s
[Step=39900 Epoch=194.6] | Loss=0.00739 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.168 | L2-Norm(final)=12.276 | 4486.6 samples/s | 70.1 steps/s
[Step=39950 Epoch=194.8] | Loss=0.00722 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.166 | L2-Norm(final)=12.278 | 2489.5 samples/s | 38.9 steps/s
[Step=40000 Epoch=195.0] | Loss=0.00709 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.163 | L2-Norm(final)=12.280 | 4353.0 samples/s | 68.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step40000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=185.4] | Loss=0.00908 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.833 | L2-Norm(final)=11.982 | 5033.9 samples/s | 78.7 steps/s
[Step=38050 Epoch=185.7] | Loss=0.00422 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.838 | L2-Norm(final)=11.993 | 4676.7 samples/s | 73.1 steps/s
[Step=38100 Epoch=185.9] | Loss=0.00387 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.840 | L2-Norm(final)=12.007 | 4983.7 samples/s | 77.9 steps/s
[Step=38150 Epoch=186.2] | Loss=0.00421 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.839 | L2-Norm(final)=12.021 | 5005.6 samples/s | 78.2 steps/s
[Step=38200 Epoch=186.4] | Loss=0.00429 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.839 | L2-Norm(final)=12.033 | 7907.1 samples/s | 123.5 steps/s
[Step=38250 Epoch=186.6] | Loss=0.00401 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.840 | L2-Norm(final)=12.046 | 2189.6 samples/s | 34.2 steps/s
[Step=38300 Epoch=186.9] | Loss=0.00376 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.839 | L2-Norm(final)=12.059 | 5029.7 samples/s | 78.6 steps/s
[Step=38350 Epoch=187.1] | Loss=0.00364 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.836 | L2-Norm(final)=12.071 | 5086.6 samples/s | 79.5 steps/s
[Step=38400 Epoch=187.4] | Loss=0.00365 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.833 | L2-Norm(final)=12.084 | 6949.0 samples/s | 108.6 steps/s
[Step=38450 Epoch=187.6] | Loss=0.00350 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.829 | L2-Norm(final)=12.096 | 2212.0 samples/s | 34.6 steps/s
[Step=38500 Epoch=187.9] | Loss=0.00342 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.825 | L2-Norm(final)=12.107 | 5061.1 samples/s | 79.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=187.9] | Loss=0.00502 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.782 | L2-Norm(final)=12.221 | 5397.4 samples/s | 84.3 steps/s
[Step=38550 Epoch=188.1] | Loss=0.00416 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.781 | L2-Norm(final)=12.230 | 4134.5 samples/s | 64.6 steps/s
[Step=38600 Epoch=188.4] | Loss=0.00687 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.786 | L2-Norm(final)=12.235 | 4506.8 samples/s | 70.4 steps/s
[Step=38650 Epoch=188.6] | Loss=0.00761 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.798 | L2-Norm(final)=12.240 | 4474.7 samples/s | 69.9 steps/s
[Step=38700 Epoch=188.8] | Loss=0.00782 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.818 | L2-Norm(final)=12.248 | 6485.0 samples/s | 101.3 steps/s
[Step=38750 Epoch=189.1] | Loss=0.00811 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.838 | L2-Norm(final)=12.257 | 2060.9 samples/s | 32.2 steps/s
[Step=38800 Epoch=189.3] | Loss=0.00841 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.856 | L2-Norm(final)=12.266 | 4531.5 samples/s | 70.8 steps/s
[Step=38850 Epoch=189.6] | Loss=0.00847 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.875 | L2-Norm(final)=12.275 | 4440.7 samples/s | 69.4 steps/s
[Step=38900 Epoch=189.8] | Loss=0.00885 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.895 | L2-Norm(final)=12.283 | 6054.9 samples/s | 94.6 steps/s
[Step=38950 Epoch=190.1] | Loss=0.00930 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.916 | L2-Norm(final)=12.290 | 2132.0 samples/s | 33.3 steps/s
[Step=39000 Epoch=190.3] | Loss=0.00903 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.935 | L2-Norm(final)=12.296 | 4414.1 samples/s | 69.0 steps/s
[Step=39050 Epoch=190.5] | Loss=0.00913 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.952 | L2-Norm(final)=12.303 | 4492.8 samples/s | 70.2 steps/s
[Step=39100 Epoch=190.8] | Loss=0.00908 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.968 | L2-Norm(final)=12.310 | 5416.4 samples/s | 84.6 steps/s
[Step=39150 Epoch=191.0] | Loss=0.00906 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.982 | L2-Norm(final)=12.316 | 2189.6 samples/s | 34.2 steps/s
[Step=39200 Epoch=191.3] | Loss=0.00879 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.994 | L2-Norm(final)=12.321 | 4537.3 samples/s | 70.9 steps/s
[Step=39250 Epoch=191.5] | Loss=0.00859 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.004 | L2-Norm(final)=12.326 | 4475.4 samples/s | 69.9 steps/s
[Step=39300 Epoch=191.8] | Loss=0.00848 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.014 | L2-Norm(final)=12.332 | 5142.6 samples/s | 80.4 steps/s
[Step=39350 Epoch=192.0] | Loss=0.00815 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.021 | L2-Norm(final)=12.337 | 2258.4 samples/s | 35.3 steps/s
[Step=39400 Epoch=192.3] | Loss=0.00794 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.027 | L2-Norm(final)=12.341 | 4440.2 samples/s | 69.4 steps/s
[Step=39450 Epoch=192.5] | Loss=0.00777 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.032 | L2-Norm(final)=12.346 | 4535.4 samples/s | 70.9 steps/s
[Step=39500 Epoch=192.7] | Loss=0.00752 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.036 | L2-Norm(final)=12.350 | 4751.2 samples/s | 74.2 steps/s
[Step=39550 Epoch=193.0] | Loss=0.00736 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.039 | L2-Norm(final)=12.355 | 2370.6 samples/s | 37.0 steps/s
[Step=39600 Epoch=193.2] | Loss=0.00721 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.041 | L2-Norm(final)=12.359 | 4371.6 samples/s | 68.3 steps/s
[Step=39650 Epoch=193.5] | Loss=0.00706 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.042 | L2-Norm(final)=12.363 | 4493.4 samples/s | 70.2 steps/s
[Step=39700 Epoch=193.7] | Loss=0.00695 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.043 | L2-Norm(final)=12.366 | 4601.4 samples/s | 71.9 steps/s
[Step=39750 Epoch=194.0] | Loss=0.00677 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.042 | L2-Norm(final)=12.370 | 2410.2 samples/s | 37.7 steps/s
[Step=39800 Epoch=194.2] | Loss=0.00665 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.042 | L2-Norm(final)=12.373 | 4467.6 samples/s | 69.8 steps/s
[Step=39850 Epoch=194.4] | Loss=0.00653 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.041 | L2-Norm(final)=12.377 | 4473.0 samples/s | 69.9 steps/s
[Step=39900 Epoch=194.7] | Loss=0.00641 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.040 | L2-Norm(final)=12.380 | 4477.8 samples/s | 70.0 steps/s
[Step=39950 Epoch=194.9] | Loss=0.00631 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.038 | L2-Norm(final)=12.383 | 2432.7 samples/s | 38.0 steps/s
[Step=40000 Epoch=195.2] | Loss=0.00632 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.037 | L2-Norm(final)=12.386 | 4486.0 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step40000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=185.2] | Loss=0.02918 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.180 | L2-Norm(final)=12.461 | 5142.7 samples/s | 80.4 steps/s
[Step=38050 Epoch=185.4] | Loss=0.00407 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.181 | L2-Norm(final)=12.473 | 4579.2 samples/s | 71.5 steps/s
[Step=38100 Epoch=185.6] | Loss=0.00491 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.182 | L2-Norm(final)=12.486 | 5013.7 samples/s | 78.3 steps/s
[Step=38150 Epoch=185.9] | Loss=0.00454 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.182 | L2-Norm(final)=12.498 | 4989.8 samples/s | 78.0 steps/s
[Step=38200 Epoch=186.1] | Loss=0.00449 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.182 | L2-Norm(final)=12.511 | 7787.4 samples/s | 121.7 steps/s
[Step=38250 Epoch=186.4] | Loss=0.00430 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.181 | L2-Norm(final)=12.524 | 2228.8 samples/s | 34.8 steps/s
[Step=38300 Epoch=186.6] | Loss=0.00429 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.179 | L2-Norm(final)=12.537 | 5051.5 samples/s | 78.9 steps/s
[Step=38350 Epoch=186.9] | Loss=0.00415 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.176 | L2-Norm(final)=12.549 | 4905.5 samples/s | 76.6 steps/s
[Step=38400 Epoch=187.1] | Loss=0.00410 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.173 | L2-Norm(final)=12.561 | 6909.5 samples/s | 108.0 steps/s
[Step=38450 Epoch=187.3] | Loss=0.00395 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.170 | L2-Norm(final)=12.574 | 2289.2 samples/s | 35.8 steps/s
[Step=38500 Epoch=187.6] | Loss=0.00384 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.167 | L2-Norm(final)=12.586 | 5015.8 samples/s | 78.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=187.6] | Loss=0.00425 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.136 | L2-Norm(final)=12.710 | 5447.5 samples/s | 85.1 steps/s
[Step=38550 Epoch=187.8] | Loss=0.00416 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.135 | L2-Norm(final)=12.719 | 3922.6 samples/s | 61.3 steps/s
[Step=38600 Epoch=188.1] | Loss=0.00588 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.134 | L2-Norm(final)=12.725 | 4496.4 samples/s | 70.3 steps/s
[Step=38650 Epoch=188.3] | Loss=0.00738 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.140 | L2-Norm(final)=12.731 | 4505.3 samples/s | 70.4 steps/s
[Step=38700 Epoch=188.6] | Loss=0.00885 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.152 | L2-Norm(final)=12.735 | 6492.6 samples/s | 101.4 steps/s
[Step=38750 Epoch=188.8] | Loss=0.00918 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.167 | L2-Norm(final)=12.741 | 2086.3 samples/s | 32.6 steps/s
[Step=38800 Epoch=189.1] | Loss=0.01084 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.185 | L2-Norm(final)=12.746 | 4323.7 samples/s | 67.6 steps/s
[Step=38850 Epoch=189.3] | Loss=0.01138 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.209 | L2-Norm(final)=12.752 | 4494.4 samples/s | 70.2 steps/s
[Step=38900 Epoch=189.5] | Loss=0.01135 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.232 | L2-Norm(final)=12.757 | 5913.3 samples/s | 92.4 steps/s
[Step=38950 Epoch=189.8] | Loss=0.01123 | Reg=0.00371 | acc=0.9531 | L2-Norm=19.253 | L2-Norm(final)=12.763 | 2166.2 samples/s | 33.8 steps/s
[Step=39000 Epoch=190.0] | Loss=0.01116 | Reg=0.00371 | acc=0.9844 | L2-Norm=19.272 | L2-Norm(final)=12.769 | 4535.9 samples/s | 70.9 steps/s
[Step=39050 Epoch=190.3] | Loss=0.01127 | Reg=0.00372 | acc=1.0000 | L2-Norm=19.289 | L2-Norm(final)=12.773 | 4389.7 samples/s | 68.6 steps/s
[Step=39100 Epoch=190.5] | Loss=0.01127 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.304 | L2-Norm(final)=12.777 | 5388.2 samples/s | 84.2 steps/s
[Step=39150 Epoch=190.8] | Loss=0.01102 | Reg=0.00373 | acc=1.0000 | L2-Norm=19.319 | L2-Norm(final)=12.782 | 2232.0 samples/s | 34.9 steps/s
[Step=39200 Epoch=191.0] | Loss=0.01056 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.332 | L2-Norm(final)=12.786 | 4451.4 samples/s | 69.6 steps/s
[Step=39250 Epoch=191.2] | Loss=0.01026 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.343 | L2-Norm(final)=12.791 | 4469.6 samples/s | 69.8 steps/s
[Step=39300 Epoch=191.5] | Loss=0.01005 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.352 | L2-Norm(final)=12.795 | 4923.6 samples/s | 76.9 steps/s
[Step=39350 Epoch=191.7] | Loss=0.01006 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.361 | L2-Norm(final)=12.799 | 2359.5 samples/s | 36.9 steps/s
[Step=39400 Epoch=192.0] | Loss=0.00970 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.369 | L2-Norm(final)=12.803 | 4435.8 samples/s | 69.3 steps/s
[Step=39450 Epoch=192.2] | Loss=0.00953 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.376 | L2-Norm(final)=12.807 | 4389.7 samples/s | 68.6 steps/s
[Step=39500 Epoch=192.5] | Loss=0.00932 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.382 | L2-Norm(final)=12.810 | 4549.2 samples/s | 71.1 steps/s
[Step=39550 Epoch=192.7] | Loss=0.00905 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.386 | L2-Norm(final)=12.814 | 2418.8 samples/s | 37.8 steps/s
[Step=39600 Epoch=193.0] | Loss=0.00881 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.390 | L2-Norm(final)=12.817 | 4426.1 samples/s | 69.2 steps/s
[Step=39650 Epoch=193.2] | Loss=0.00870 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.393 | L2-Norm(final)=12.820 | 4465.3 samples/s | 69.8 steps/s
[Step=39700 Epoch=193.4] | Loss=0.00850 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.396 | L2-Norm(final)=12.824 | 4484.6 samples/s | 70.1 steps/s
[Step=39750 Epoch=193.7] | Loss=0.00841 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.398 | L2-Norm(final)=12.827 | 2507.8 samples/s | 39.2 steps/s
[Step=39800 Epoch=193.9] | Loss=0.00826 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.400 | L2-Norm(final)=12.829 | 4417.4 samples/s | 69.0 steps/s
[Step=39850 Epoch=194.2] | Loss=0.00809 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.401 | L2-Norm(final)=12.832 | 4305.1 samples/s | 67.3 steps/s
[Step=39900 Epoch=194.4] | Loss=0.00801 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.402 | L2-Norm(final)=12.835 | 4524.6 samples/s | 70.7 steps/s
[Step=39950 Epoch=194.7] | Loss=0.00791 | Reg=0.00376 | acc=0.9844 | L2-Norm=19.403 | L2-Norm(final)=12.838 | 2389.7 samples/s | 37.3 steps/s
[Step=40000 Epoch=194.9] | Loss=0.00772 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.403 | L2-Norm(final)=12.840 | 4502.6 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step40000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=185.3] | Loss=0.00646 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.155 | L2-Norm(final)=12.328 | 4988.8 samples/s | 78.0 steps/s
[Step=38050 Epoch=185.6] | Loss=0.00374 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.156 | L2-Norm(final)=12.338 | 4827.2 samples/s | 75.4 steps/s
[Step=38100 Epoch=185.8] | Loss=0.00351 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.155 | L2-Norm(final)=12.350 | 4929.5 samples/s | 77.0 steps/s
[Step=38150 Epoch=186.0] | Loss=0.00377 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.152 | L2-Norm(final)=12.361 | 5053.6 samples/s | 79.0 steps/s
[Step=38200 Epoch=186.3] | Loss=0.00364 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.149 | L2-Norm(final)=12.373 | 7698.7 samples/s | 120.3 steps/s
[Step=38250 Epoch=186.5] | Loss=0.00341 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.145 | L2-Norm(final)=12.384 | 2197.7 samples/s | 34.3 steps/s
[Step=38300 Epoch=186.8] | Loss=0.00328 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.142 | L2-Norm(final)=12.396 | 5045.0 samples/s | 78.8 steps/s
[Step=38350 Epoch=187.0] | Loss=0.00326 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.138 | L2-Norm(final)=12.408 | 5041.4 samples/s | 78.8 steps/s
[Step=38400 Epoch=187.3] | Loss=0.00321 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.134 | L2-Norm(final)=12.419 | 7032.0 samples/s | 109.9 steps/s
[Step=38450 Epoch=187.5] | Loss=0.00318 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.131 | L2-Norm(final)=12.430 | 2326.6 samples/s | 36.4 steps/s
[Step=38500 Epoch=187.7] | Loss=0.00301 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.127 | L2-Norm(final)=12.440 | 5060.2 samples/s | 79.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=187.8] | Loss=0.00313 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.086 | L2-Norm(final)=12.549 | 5521.9 samples/s | 86.3 steps/s
[Step=38550 Epoch=188.0] | Loss=0.00320 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.084 | L2-Norm(final)=12.558 | 3881.2 samples/s | 60.6 steps/s
[Step=38600 Epoch=188.2] | Loss=0.00489 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.084 | L2-Norm(final)=12.563 | 4441.0 samples/s | 69.4 steps/s
[Step=38650 Epoch=188.5] | Loss=0.00508 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.090 | L2-Norm(final)=12.569 | 4495.7 samples/s | 70.2 steps/s
[Step=38700 Epoch=188.7] | Loss=0.00608 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.097 | L2-Norm(final)=12.575 | 6558.1 samples/s | 102.5 steps/s
[Step=38750 Epoch=189.0] | Loss=0.00676 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.107 | L2-Norm(final)=12.581 | 2093.6 samples/s | 32.7 steps/s
[Step=38800 Epoch=189.2] | Loss=0.00893 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.123 | L2-Norm(final)=12.585 | 4532.2 samples/s | 70.8 steps/s
[Step=38850 Epoch=189.5] | Loss=0.00980 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.147 | L2-Norm(final)=12.588 | 4464.5 samples/s | 69.8 steps/s
[Step=38900 Epoch=189.7] | Loss=0.01050 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.169 | L2-Norm(final)=12.592 | 5725.5 samples/s | 89.5 steps/s
[Step=38950 Epoch=189.9] | Loss=0.00998 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.189 | L2-Norm(final)=12.596 | 2151.9 samples/s | 33.6 steps/s
[Step=39000 Epoch=190.2] | Loss=0.00937 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.205 | L2-Norm(final)=12.602 | 4464.0 samples/s | 69.7 steps/s
[Step=39050 Epoch=190.4] | Loss=0.00913 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.218 | L2-Norm(final)=12.607 | 4560.0 samples/s | 71.2 steps/s
[Step=39100 Epoch=190.7] | Loss=0.00882 | Reg=0.00370 | acc=0.9844 | L2-Norm=19.229 | L2-Norm(final)=12.612 | 5280.9 samples/s | 82.5 steps/s
[Step=39150 Epoch=190.9] | Loss=0.00850 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.238 | L2-Norm(final)=12.617 | 2251.2 samples/s | 35.2 steps/s
[Step=39200 Epoch=191.2] | Loss=0.00829 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.246 | L2-Norm(final)=12.622 | 4506.3 samples/s | 70.4 steps/s
[Step=39250 Epoch=191.4] | Loss=0.00821 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.252 | L2-Norm(final)=12.627 | 4491.3 samples/s | 70.2 steps/s
[Step=39300 Epoch=191.6] | Loss=0.00790 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.258 | L2-Norm(final)=12.631 | 4862.3 samples/s | 76.0 steps/s
[Step=39350 Epoch=191.9] | Loss=0.00770 | Reg=0.00371 | acc=0.9844 | L2-Norm=19.262 | L2-Norm(final)=12.635 | 2322.9 samples/s | 36.3 steps/s
[Step=39400 Epoch=192.1] | Loss=0.00746 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.264 | L2-Norm(final)=12.639 | 4500.6 samples/s | 70.3 steps/s
[Step=39450 Epoch=192.4] | Loss=0.00726 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.266 | L2-Norm(final)=12.642 | 4463.3 samples/s | 69.7 steps/s
[Step=39500 Epoch=192.6] | Loss=0.00703 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.267 | L2-Norm(final)=12.646 | 4631.9 samples/s | 72.4 steps/s
[Step=39550 Epoch=192.9] | Loss=0.00684 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.267 | L2-Norm(final)=12.650 | 2440.4 samples/s | 38.1 steps/s
[Step=39600 Epoch=193.1] | Loss=0.00662 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.266 | L2-Norm(final)=12.653 | 4318.9 samples/s | 67.5 steps/s
[Step=39650 Epoch=193.4] | Loss=0.00648 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.265 | L2-Norm(final)=12.656 | 4498.9 samples/s | 70.3 steps/s
[Step=39700 Epoch=193.6] | Loss=0.00635 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.262 | L2-Norm(final)=12.659 | 4479.9 samples/s | 70.0 steps/s
[Step=39750 Epoch=193.8] | Loss=0.00619 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.260 | L2-Norm(final)=12.662 | 2451.9 samples/s | 38.3 steps/s
[Step=39800 Epoch=194.1] | Loss=0.00603 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.257 | L2-Norm(final)=12.665 | 4487.9 samples/s | 70.1 steps/s
[Step=39850 Epoch=194.3] | Loss=0.00593 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.253 | L2-Norm(final)=12.668 | 4428.0 samples/s | 69.2 steps/s
[Step=39900 Epoch=194.6] | Loss=0.00580 | Reg=0.00371 | acc=0.9844 | L2-Norm=19.249 | L2-Norm(final)=12.671 | 4485.9 samples/s | 70.1 steps/s
[Step=39950 Epoch=194.8] | Loss=0.00569 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.245 | L2-Norm(final)=12.674 | 2404.7 samples/s | 37.6 steps/s
[Step=40000 Epoch=195.1] | Loss=0.00559 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.240 | L2-Norm(final)=12.677 | 4476.3 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step40000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=186.4] | Loss=0.00050 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.007 | L2-Norm(final)=12.327 | 5207.9 samples/s | 81.4 steps/s
[Step=38050 Epoch=186.6] | Loss=0.00425 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.003 | L2-Norm(final)=12.334 | 4430.4 samples/s | 69.2 steps/s
[Step=38100 Epoch=186.8] | Loss=0.00381 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.999 | L2-Norm(final)=12.344 | 5008.6 samples/s | 78.3 steps/s
[Step=38150 Epoch=187.1] | Loss=0.00352 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.995 | L2-Norm(final)=12.353 | 5041.2 samples/s | 78.8 steps/s
[Step=38200 Epoch=187.3] | Loss=0.00334 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.991 | L2-Norm(final)=12.363 | 8043.6 samples/s | 125.7 steps/s
[Step=38250 Epoch=187.6] | Loss=0.00312 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.987 | L2-Norm(final)=12.373 | 2188.6 samples/s | 34.2 steps/s
[Step=38300 Epoch=187.8] | Loss=0.00305 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.983 | L2-Norm(final)=12.383 | 5157.6 samples/s | 80.6 steps/s
[Step=38350 Epoch=188.1] | Loss=0.00308 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.979 | L2-Norm(final)=12.393 | 4803.9 samples/s | 75.1 steps/s
[Step=38400 Epoch=188.3] | Loss=0.00303 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.975 | L2-Norm(final)=12.403 | 7492.1 samples/s | 117.1 steps/s
[Step=38450 Epoch=188.6] | Loss=0.00296 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.970 | L2-Norm(final)=12.412 | 2240.3 samples/s | 35.0 steps/s
[Step=38500 Epoch=188.8] | Loss=0.00284 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.965 | L2-Norm(final)=12.422 | 5129.4 samples/s | 80.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=188.8] | Loss=0.00298 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.915 | L2-Norm(final)=12.516 | 4903.9 samples/s | 76.6 steps/s
[Step=38550 Epoch=189.0] | Loss=0.00236 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.911 | L2-Norm(final)=12.525 | 4324.4 samples/s | 67.6 steps/s
[Step=38600 Epoch=189.3] | Loss=0.00406 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.908 | L2-Norm(final)=12.532 | 4431.1 samples/s | 69.2 steps/s
[Step=38650 Epoch=189.5] | Loss=0.00532 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.910 | L2-Norm(final)=12.536 | 4462.6 samples/s | 69.7 steps/s
[Step=38700 Epoch=189.8] | Loss=0.00574 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.915 | L2-Norm(final)=12.542 | 6670.1 samples/s | 104.2 steps/s
[Step=38750 Epoch=190.0] | Loss=0.00659 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.922 | L2-Norm(final)=12.547 | 2065.4 samples/s | 32.3 steps/s
[Step=38800 Epoch=190.3] | Loss=0.00665 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.933 | L2-Norm(final)=12.552 | 4423.4 samples/s | 69.1 steps/s
[Step=38850 Epoch=190.5] | Loss=0.00746 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.944 | L2-Norm(final)=12.558 | 4521.9 samples/s | 70.7 steps/s
[Step=38900 Epoch=190.8] | Loss=0.00802 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.956 | L2-Norm(final)=12.563 | 6207.4 samples/s | 97.0 steps/s
[Step=38950 Epoch=191.0] | Loss=0.00805 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.969 | L2-Norm(final)=12.569 | 2107.3 samples/s | 32.9 steps/s
[Step=39000 Epoch=191.2] | Loss=0.00782 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.980 | L2-Norm(final)=12.574 | 4463.9 samples/s | 69.7 steps/s
[Step=39050 Epoch=191.5] | Loss=0.00757 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.991 | L2-Norm(final)=12.580 | 4498.6 samples/s | 70.3 steps/s
[Step=39100 Epoch=191.7] | Loss=0.00742 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.999 | L2-Norm(final)=12.586 | 5838.7 samples/s | 91.2 steps/s
[Step=39150 Epoch=192.0] | Loss=0.00721 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.006 | L2-Norm(final)=12.592 | 2168.9 samples/s | 33.9 steps/s
[Step=39200 Epoch=192.2] | Loss=0.00702 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.012 | L2-Norm(final)=12.597 | 4516.6 samples/s | 70.6 steps/s
[Step=39250 Epoch=192.5] | Loss=0.00695 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.017 | L2-Norm(final)=12.603 | 4446.6 samples/s | 69.5 steps/s
[Step=39300 Epoch=192.7] | Loss=0.00668 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.020 | L2-Norm(final)=12.608 | 5464.6 samples/s | 85.4 steps/s
[Step=39350 Epoch=193.0] | Loss=0.00651 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.023 | L2-Norm(final)=12.613 | 2198.6 samples/s | 34.4 steps/s
[Step=39400 Epoch=193.2] | Loss=0.00632 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.025 | L2-Norm(final)=12.619 | 4477.9 samples/s | 70.0 steps/s
[Step=39450 Epoch=193.5] | Loss=0.00616 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.026 | L2-Norm(final)=12.624 | 4420.8 samples/s | 69.1 steps/s
[Step=39500 Epoch=193.7] | Loss=0.00606 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.026 | L2-Norm(final)=12.628 | 5206.7 samples/s | 81.4 steps/s
[Step=39550 Epoch=193.9] | Loss=0.00594 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.026 | L2-Norm(final)=12.633 | 2263.2 samples/s | 35.4 steps/s
[Step=39600 Epoch=194.2] | Loss=0.00585 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.025 | L2-Norm(final)=12.638 | 4482.5 samples/s | 70.0 steps/s
[Step=39650 Epoch=194.4] | Loss=0.00578 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.025 | L2-Norm(final)=12.642 | 4418.0 samples/s | 69.0 steps/s
[Step=39700 Epoch=194.7] | Loss=0.00563 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.023 | L2-Norm(final)=12.646 | 4882.1 samples/s | 76.3 steps/s
[Step=39750 Epoch=194.9] | Loss=0.00549 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.021 | L2-Norm(final)=12.650 | 2346.8 samples/s | 36.7 steps/s
[Step=39800 Epoch=195.2] | Loss=0.00538 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.019 | L2-Norm(final)=12.655 | 4408.4 samples/s | 68.9 steps/s
[Step=39850 Epoch=195.4] | Loss=0.00534 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.016 | L2-Norm(final)=12.658 | 4513.8 samples/s | 70.5 steps/s
[Step=39900 Epoch=195.7] | Loss=0.00529 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.013 | L2-Norm(final)=12.662 | 4646.4 samples/s | 72.6 steps/s
[Step=39950 Epoch=195.9] | Loss=0.00522 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.010 | L2-Norm(final)=12.665 | 2382.2 samples/s | 37.2 steps/s
[Step=40000 Epoch=196.2] | Loss=0.00514 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.006 | L2-Norm(final)=12.669 | 4427.4 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step40000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=360.1] | Loss=0.00044 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=6.888 | 5200.9 samples/s | 81.3 steps/s
[Step=38050 Epoch=360.6] | Loss=0.00104 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.499 | L2-Norm(final)=6.902 | 4083.5 samples/s | 63.8 steps/s
[Step=38100 Epoch=361.0] | Loss=0.00111 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.567 | L2-Norm(final)=6.919 | 7500.3 samples/s | 117.2 steps/s
[Step=38150 Epoch=361.5] | Loss=0.00078 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.609 | L2-Norm(final)=6.932 | 2170.7 samples/s | 33.9 steps/s
[Step=38200 Epoch=362.0] | Loss=0.00060 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.630 | L2-Norm(final)=6.941 | 6411.7 samples/s | 100.2 steps/s
[Step=38250 Epoch=362.5] | Loss=0.00049 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.643 | L2-Norm(final)=6.948 | 2206.9 samples/s | 34.5 steps/s
[Step=38300 Epoch=362.9] | Loss=0.00041 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.650 | L2-Norm(final)=6.954 | 5789.5 samples/s | 90.5 steps/s
[Step=38350 Epoch=363.4] | Loss=0.00036 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.656 | L2-Norm(final)=6.958 | 2351.4 samples/s | 36.7 steps/s
[Step=38400 Epoch=363.9] | Loss=0.00032 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.660 | L2-Norm(final)=6.962 | 5030.9 samples/s | 78.6 steps/s
[Step=38450 Epoch=364.3] | Loss=0.00029 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.662 | L2-Norm(final)=6.966 | 2405.8 samples/s | 37.6 steps/s
[Step=38500 Epoch=364.8] | Loss=0.00026 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.664 | L2-Norm(final)=6.970 | 4798.3 samples/s | 75.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=364.8] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.681 | L2-Norm(final)=7.004 | 5496.4 samples/s | 85.9 steps/s
[Step=38550 Epoch=365.3] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=7.006 | 3773.4 samples/s | 59.0 steps/s
[Step=38600 Epoch=365.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.640 | L2-Norm(final)=7.007 | 6127.8 samples/s | 95.7 steps/s
[Step=38650 Epoch=366.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=7.008 | 2028.5 samples/s | 31.7 steps/s
[Step=38700 Epoch=366.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.584 | L2-Norm(final)=7.009 | 5514.5 samples/s | 86.2 steps/s
[Step=38750 Epoch=367.2] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.555 | L2-Norm(final)=7.009 | 2112.4 samples/s | 33.0 steps/s
[Step=38800 Epoch=367.7] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.527 | L2-Norm(final)=7.010 | 5060.9 samples/s | 79.1 steps/s
[Step=38850 Epoch=368.1] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.498 | L2-Norm(final)=7.010 | 2176.6 samples/s | 34.0 steps/s
[Step=38900 Epoch=368.6] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.469 | L2-Norm(final)=7.010 | 4610.5 samples/s | 72.0 steps/s
[Step=38950 Epoch=369.1] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=7.010 | 2249.2 samples/s | 35.1 steps/s
[Step=39000 Epoch=369.6] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.410 | L2-Norm(final)=7.011 | 4338.1 samples/s | 67.8 steps/s
[Step=39050 Epoch=370.0] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.381 | L2-Norm(final)=7.011 | 2346.0 samples/s | 36.7 steps/s
[Step=39100 Epoch=370.5] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.352 | L2-Norm(final)=7.011 | 4268.2 samples/s | 66.7 steps/s
[Step=39150 Epoch=371.0] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.323 | L2-Norm(final)=7.011 | 2361.2 samples/s | 36.9 steps/s
[Step=39200 Epoch=371.5] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.293 | L2-Norm(final)=7.012 | 4208.2 samples/s | 65.8 steps/s
[Step=39250 Epoch=371.9] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.264 | L2-Norm(final)=7.012 | 2393.8 samples/s | 37.4 steps/s
[Step=39300 Epoch=372.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.234 | L2-Norm(final)=7.012 | 4255.9 samples/s | 66.5 steps/s
[Step=39350 Epoch=372.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.205 | L2-Norm(final)=7.012 | 2494.7 samples/s | 39.0 steps/s
[Step=39400 Epoch=373.3] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.175 | L2-Norm(final)=7.013 | 3966.4 samples/s | 62.0 steps/s
[Step=39450 Epoch=373.8] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.145 | L2-Norm(final)=7.013 | 6347.0 samples/s | 99.2 steps/s
[Step=39500 Epoch=374.3] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.115 | L2-Norm(final)=7.013 | 1989.6 samples/s | 31.1 steps/s
[Step=39550 Epoch=374.8] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.013 | 5776.0 samples/s | 90.3 steps/s
[Step=39600 Epoch=375.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.055 | L2-Norm(final)=7.014 | 2083.6 samples/s | 32.6 steps/s
[Step=39650 Epoch=375.7] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.025 | L2-Norm(final)=7.014 | 5247.1 samples/s | 82.0 steps/s
[Step=39700 Epoch=376.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.014 | 2135.8 samples/s | 33.4 steps/s
[Step=39750 Epoch=376.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.964 | L2-Norm(final)=7.015 | 4807.1 samples/s | 75.1 steps/s
[Step=39800 Epoch=377.1] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.933 | L2-Norm(final)=7.015 | 2169.8 samples/s | 33.9 steps/s
[Step=39850 Epoch=377.6] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.903 | L2-Norm(final)=7.015 | 4450.5 samples/s | 69.5 steps/s
[Step=39900 Epoch=378.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.872 | L2-Norm(final)=7.015 | 2305.9 samples/s | 36.0 steps/s
[Step=39950 Epoch=378.6] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.841 | L2-Norm(final)=7.016 | 4296.1 samples/s | 67.1 steps/s
[Step=40000 Epoch=379.0] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.810 | L2-Norm(final)=7.016 | 2391.2 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step40000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=361.5] | Loss=0.04727 | Reg=0.00100 | acc=0.9844 | L2-Norm=9.987 | L2-Norm(final)=7.937 | 5243.1 samples/s | 81.9 steps/s
[Step=38050 Epoch=362.0] | Loss=0.00487 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.007 | L2-Norm(final)=7.913 | 4054.7 samples/s | 63.4 steps/s
[Step=38100 Epoch=362.4] | Loss=0.00273 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.020 | L2-Norm(final)=7.911 | 7588.4 samples/s | 118.6 steps/s
[Step=38150 Epoch=362.9] | Loss=0.00190 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.024 | L2-Norm(final)=7.914 | 2138.6 samples/s | 33.4 steps/s
[Step=38200 Epoch=363.4] | Loss=0.00145 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.028 | L2-Norm(final)=7.918 | 6551.1 samples/s | 102.4 steps/s
[Step=38250 Epoch=363.9] | Loss=0.00117 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=7.921 | 2237.5 samples/s | 35.0 steps/s
[Step=38300 Epoch=364.3] | Loss=0.00099 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.030 | L2-Norm(final)=7.924 | 5903.4 samples/s | 92.2 steps/s
[Step=38350 Epoch=364.8] | Loss=0.00085 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.030 | L2-Norm(final)=7.928 | 2305.6 samples/s | 36.0 steps/s
[Step=38400 Epoch=365.3] | Loss=0.00075 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=7.931 | 5296.0 samples/s | 82.7 steps/s
[Step=38450 Epoch=365.8] | Loss=0.00067 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=7.933 | 2415.5 samples/s | 37.7 steps/s
[Step=38500 Epoch=366.2] | Loss=0.00061 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.028 | L2-Norm(final)=7.936 | 4848.2 samples/s | 75.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=366.2] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.017 | L2-Norm(final)=7.964 | 4977.0 samples/s | 77.8 steps/s
[Step=38550 Epoch=366.7] | Loss=0.00239 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.046 | L2-Norm(final)=7.964 | 3945.2 samples/s | 61.6 steps/s
[Step=38600 Epoch=367.2] | Loss=0.00375 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.131 | L2-Norm(final)=7.964 | 6294.9 samples/s | 98.4 steps/s
[Step=38650 Epoch=367.7] | Loss=0.00366 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=7.954 | 2012.8 samples/s | 31.5 steps/s
[Step=38700 Epoch=368.1] | Loss=0.00293 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.228 | L2-Norm(final)=7.948 | 5548.2 samples/s | 86.7 steps/s
[Step=38750 Epoch=368.6] | Loss=0.00236 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.249 | L2-Norm(final)=7.946 | 2119.0 samples/s | 33.1 steps/s
[Step=38800 Epoch=369.1] | Loss=0.00197 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.261 | L2-Norm(final)=7.944 | 5005.4 samples/s | 78.2 steps/s
[Step=38850 Epoch=369.6] | Loss=0.00170 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.269 | L2-Norm(final)=7.944 | 2200.8 samples/s | 34.4 steps/s
[Step=38900 Epoch=370.0] | Loss=0.00149 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.274 | L2-Norm(final)=7.944 | 4655.9 samples/s | 72.7 steps/s
[Step=38950 Epoch=370.5] | Loss=0.00132 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.277 | L2-Norm(final)=7.944 | 2192.9 samples/s | 34.3 steps/s
[Step=39000 Epoch=371.0] | Loss=0.00119 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.278 | L2-Norm(final)=7.944 | 4371.7 samples/s | 68.3 steps/s
[Step=39050 Epoch=371.5] | Loss=0.00108 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.278 | L2-Norm(final)=7.944 | 2361.0 samples/s | 36.9 steps/s
[Step=39100 Epoch=371.9] | Loss=0.00099 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.277 | L2-Norm(final)=7.944 | 4228.8 samples/s | 66.1 steps/s
[Step=39150 Epoch=372.4] | Loss=0.00092 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.276 | L2-Norm(final)=7.945 | 2380.7 samples/s | 37.2 steps/s
[Step=39200 Epoch=372.9] | Loss=0.00085 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.274 | L2-Norm(final)=7.945 | 4241.6 samples/s | 66.3 steps/s
[Step=39250 Epoch=373.4] | Loss=0.00080 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=7.945 | 2392.3 samples/s | 37.4 steps/s
[Step=39300 Epoch=373.8] | Loss=0.00075 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.269 | L2-Norm(final)=7.946 | 4276.7 samples/s | 66.8 steps/s
[Step=39350 Epoch=374.3] | Loss=0.00070 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.266 | L2-Norm(final)=7.946 | 2531.1 samples/s | 39.5 steps/s
[Step=39400 Epoch=374.8] | Loss=0.00067 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=7.946 | 3934.2 samples/s | 61.5 steps/s
[Step=39450 Epoch=375.3] | Loss=0.00063 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.260 | L2-Norm(final)=7.947 | 6572.4 samples/s | 102.7 steps/s
[Step=39500 Epoch=375.7] | Loss=0.00060 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.256 | L2-Norm(final)=7.947 | 1997.1 samples/s | 31.2 steps/s
[Step=39550 Epoch=376.2] | Loss=0.00057 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=7.948 | 5856.7 samples/s | 91.5 steps/s
[Step=39600 Epoch=376.7] | Loss=0.00055 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.248 | L2-Norm(final)=7.948 | 2066.4 samples/s | 32.3 steps/s
[Step=39650 Epoch=377.2] | Loss=0.00052 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.244 | L2-Norm(final)=7.948 | 5347.1 samples/s | 83.5 steps/s
[Step=39700 Epoch=377.6] | Loss=0.00050 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=7.949 | 2140.4 samples/s | 33.4 steps/s
[Step=39750 Epoch=378.1] | Loss=0.00048 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=7.949 | 4872.4 samples/s | 76.1 steps/s
[Step=39800 Epoch=378.6] | Loss=0.00046 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=7.950 | 2219.9 samples/s | 34.7 steps/s
[Step=39850 Epoch=379.1] | Loss=0.00045 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.227 | L2-Norm(final)=7.950 | 4489.4 samples/s | 70.1 steps/s
[Step=39900 Epoch=379.5] | Loss=0.00043 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.222 | L2-Norm(final)=7.950 | 2317.6 samples/s | 36.2 steps/s
[Step=39950 Epoch=380.0] | Loss=0.00041 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.218 | L2-Norm(final)=7.951 | 4159.7 samples/s | 65.0 steps/s
[Step=40000 Epoch=380.5] | Loss=0.00040 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.213 | L2-Norm(final)=7.951 | 2382.9 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step40000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=362.9] | Loss=0.00136 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.436 | L2-Norm(final)=7.311 | 5137.6 samples/s | 80.3 steps/s
[Step=38050 Epoch=363.4] | Loss=0.00154 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.508 | L2-Norm(final)=7.347 | 4280.7 samples/s | 66.9 steps/s
[Step=38100 Epoch=363.8] | Loss=0.00106 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.581 | L2-Norm(final)=7.360 | 7351.4 samples/s | 114.9 steps/s
[Step=38150 Epoch=364.3] | Loss=0.00074 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.620 | L2-Norm(final)=7.373 | 2132.2 samples/s | 33.3 steps/s
[Step=38200 Epoch=364.8] | Loss=0.00057 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=7.383 | 6854.1 samples/s | 107.1 steps/s
[Step=38250 Epoch=365.3] | Loss=0.00047 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.653 | L2-Norm(final)=7.391 | 2188.7 samples/s | 34.2 steps/s
[Step=38300 Epoch=365.7] | Loss=0.00039 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.660 | L2-Norm(final)=7.399 | 6257.0 samples/s | 97.8 steps/s
[Step=38350 Epoch=366.2] | Loss=0.00034 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.666 | L2-Norm(final)=7.405 | 2258.2 samples/s | 35.3 steps/s
[Step=38400 Epoch=366.7] | Loss=0.00031 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.670 | L2-Norm(final)=7.412 | 5673.6 samples/s | 88.7 steps/s
[Step=38450 Epoch=367.2] | Loss=0.00028 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.672 | L2-Norm(final)=7.418 | 2318.8 samples/s | 36.2 steps/s
[Step=38500 Epoch=367.7] | Loss=0.00025 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.675 | L2-Norm(final)=7.424 | 5205.5 samples/s | 81.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=367.7] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.692 | L2-Norm(final)=7.481 | 5918.2 samples/s | 92.5 steps/s
[Step=38550 Epoch=368.1] | Loss=0.01299 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=7.463 | 3531.8 samples/s | 55.2 steps/s
[Step=38600 Epoch=368.6] | Loss=0.00896 | Reg=0.00099 | acc=0.9844 | L2-Norm=9.925 | L2-Norm(final)=7.424 | 6383.2 samples/s | 99.7 steps/s
[Step=38650 Epoch=369.1] | Loss=0.00640 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=7.409 | 2016.8 samples/s | 31.5 steps/s
[Step=38700 Epoch=369.6] | Loss=0.00532 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.038 | L2-Norm(final)=7.402 | 5830.5 samples/s | 91.1 steps/s
[Step=38750 Epoch=370.0] | Loss=0.00432 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.062 | L2-Norm(final)=7.398 | 2082.2 samples/s | 32.5 steps/s
[Step=38800 Epoch=370.5] | Loss=0.00361 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.077 | L2-Norm(final)=7.396 | 5313.2 samples/s | 83.0 steps/s
[Step=38850 Epoch=371.0] | Loss=0.00310 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.087 | L2-Norm(final)=7.394 | 2134.3 samples/s | 33.3 steps/s
[Step=38900 Epoch=371.5] | Loss=0.00271 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.094 | L2-Norm(final)=7.393 | 5014.9 samples/s | 78.4 steps/s
[Step=38950 Epoch=371.9] | Loss=0.00241 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.099 | L2-Norm(final)=7.393 | 2184.6 samples/s | 34.1 steps/s
[Step=39000 Epoch=372.4] | Loss=0.00217 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.102 | L2-Norm(final)=7.393 | 4651.9 samples/s | 72.7 steps/s
[Step=39050 Epoch=372.9] | Loss=0.00197 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=7.393 | 2248.9 samples/s | 35.1 steps/s
[Step=39100 Epoch=373.4] | Loss=0.00181 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=7.393 | 4378.8 samples/s | 68.4 steps/s
[Step=39150 Epoch=373.9] | Loss=0.00167 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=7.394 | 2391.2 samples/s | 37.4 steps/s
[Step=39200 Epoch=374.3] | Loss=0.00155 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.107 | L2-Norm(final)=7.395 | 4155.0 samples/s | 64.9 steps/s
[Step=39250 Epoch=374.8] | Loss=0.00145 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=7.395 | 2394.9 samples/s | 37.4 steps/s
[Step=39300 Epoch=375.3] | Loss=0.00136 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=7.396 | 4211.4 samples/s | 65.8 steps/s
[Step=39350 Epoch=375.8] | Loss=0.00128 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.104 | L2-Norm(final)=7.397 | 2438.1 samples/s | 38.1 steps/s
[Step=39400 Epoch=376.2] | Loss=0.00121 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.102 | L2-Norm(final)=7.398 | 4131.9 samples/s | 64.6 steps/s
[Step=39450 Epoch=376.7] | Loss=0.00115 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=7.399 | 2382.2 samples/s | 37.2 steps/s
[Step=39500 Epoch=377.2] | Loss=0.00109 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.099 | L2-Norm(final)=7.399 | 4274.0 samples/s | 66.8 steps/s
[Step=39550 Epoch=377.7] | Loss=0.00104 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.097 | L2-Norm(final)=7.400 | 6939.1 samples/s | 108.4 steps/s
[Step=39600 Epoch=378.2] | Loss=0.00099 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.095 | L2-Norm(final)=7.401 | 1950.8 samples/s | 30.5 steps/s
[Step=39650 Epoch=378.6] | Loss=0.00095 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.092 | L2-Norm(final)=7.402 | 6432.8 samples/s | 100.5 steps/s
[Step=39700 Epoch=379.1] | Loss=0.00091 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.090 | L2-Norm(final)=7.403 | 2019.1 samples/s | 31.5 steps/s
[Step=39750 Epoch=379.6] | Loss=0.00087 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.087 | L2-Norm(final)=7.404 | 5728.4 samples/s | 89.5 steps/s
[Step=39800 Epoch=380.1] | Loss=0.00084 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.084 | L2-Norm(final)=7.405 | 2067.1 samples/s | 32.3 steps/s
[Step=39850 Epoch=380.5] | Loss=0.00081 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.081 | L2-Norm(final)=7.406 | 5326.1 samples/s | 83.2 steps/s
[Step=39900 Epoch=381.0] | Loss=0.00078 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=7.407 | 2141.7 samples/s | 33.5 steps/s
[Step=39950 Epoch=381.5] | Loss=0.00075 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.075 | L2-Norm(final)=7.408 | 4999.1 samples/s | 78.1 steps/s
[Step=40000 Epoch=382.0] | Loss=0.00073 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.072 | L2-Norm(final)=7.409 | 2195.6 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step40000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=358.1] | Loss=0.00009 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.820 | L2-Norm(final)=7.118 | 5117.2 samples/s | 80.0 steps/s
[Step=38050 Epoch=358.5] | Loss=0.00046 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.824 | L2-Norm(final)=7.127 | 4222.2 samples/s | 66.0 steps/s
[Step=38100 Epoch=359.0] | Loss=0.00035 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.830 | L2-Norm(final)=7.138 | 7331.9 samples/s | 114.6 steps/s
[Step=38150 Epoch=359.5] | Loss=0.00029 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.835 | L2-Norm(final)=7.147 | 2149.6 samples/s | 33.6 steps/s
[Step=38200 Epoch=360.0] | Loss=0.00024 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.838 | L2-Norm(final)=7.156 | 6281.6 samples/s | 98.2 steps/s
[Step=38250 Epoch=360.4] | Loss=0.00021 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.840 | L2-Norm(final)=7.164 | 2276.8 samples/s | 35.6 steps/s
[Step=38300 Epoch=360.9] | Loss=0.00019 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.842 | L2-Norm(final)=7.171 | 5497.7 samples/s | 85.9 steps/s
[Step=38350 Epoch=361.4] | Loss=0.00017 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.843 | L2-Norm(final)=7.178 | 2362.1 samples/s | 36.9 steps/s
[Step=38400 Epoch=361.8] | Loss=0.00016 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.845 | L2-Norm(final)=7.184 | 5086.3 samples/s | 79.5 steps/s
[Step=38450 Epoch=362.3] | Loss=0.00015 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.846 | L2-Norm(final)=7.191 | 2441.6 samples/s | 38.2 steps/s
[Step=38500 Epoch=362.8] | Loss=0.00014 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.847 | L2-Norm(final)=7.197 | 4793.9 samples/s | 74.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=362.8] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.855 | L2-Norm(final)=7.259 | 5099.2 samples/s | 79.7 steps/s
[Step=38550 Epoch=363.3] | Loss=0.00006 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.854 | L2-Norm(final)=7.264 | 3871.0 samples/s | 60.5 steps/s
[Step=38600 Epoch=363.7] | Loss=0.00005 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=7.270 | 6115.5 samples/s | 95.6 steps/s
[Step=38650 Epoch=364.2] | Loss=0.00004 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.848 | L2-Norm(final)=7.273 | 2036.9 samples/s | 31.8 steps/s
[Step=38700 Epoch=364.7] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.843 | L2-Norm(final)=7.276 | 5389.4 samples/s | 84.2 steps/s
[Step=38750 Epoch=365.1] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.838 | L2-Norm(final)=7.278 | 2121.7 samples/s | 33.2 steps/s
[Step=38800 Epoch=365.6] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.833 | L2-Norm(final)=7.280 | 4993.4 samples/s | 78.0 steps/s
[Step=38850 Epoch=366.1] | Loss=0.00002 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.828 | L2-Norm(final)=7.282 | 2228.1 samples/s | 34.8 steps/s
[Step=38900 Epoch=366.5] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.822 | L2-Norm(final)=7.283 | 4463.1 samples/s | 69.7 steps/s
[Step=38950 Epoch=367.0] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.816 | L2-Norm(final)=7.285 | 2330.6 samples/s | 36.4 steps/s
[Step=39000 Epoch=367.5] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.810 | L2-Norm(final)=7.286 | 4282.5 samples/s | 66.9 steps/s
[Step=39050 Epoch=368.0] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.805 | L2-Norm(final)=7.287 | 2387.6 samples/s | 37.3 steps/s
[Step=39100 Epoch=368.4] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.798 | L2-Norm(final)=7.288 | 4276.4 samples/s | 66.8 steps/s
[Step=39150 Epoch=368.9] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.792 | L2-Norm(final)=7.290 | 2388.9 samples/s | 37.3 steps/s
[Step=39200 Epoch=369.4] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.786 | L2-Norm(final)=7.291 | 4242.4 samples/s | 66.3 steps/s
[Step=39250 Epoch=369.8] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.780 | L2-Norm(final)=7.292 | 2664.0 samples/s | 41.6 steps/s
[Step=39300 Epoch=370.3] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.774 | L2-Norm(final)=7.293 | 3684.5 samples/s | 57.6 steps/s
[Step=39350 Epoch=370.8] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.767 | L2-Norm(final)=7.294 | 6298.6 samples/s | 98.4 steps/s
[Step=39400 Epoch=371.3] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=7.295 | 2038.3 samples/s | 31.8 steps/s
[Step=39450 Epoch=371.7] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.754 | L2-Norm(final)=7.296 | 5566.8 samples/s | 87.0 steps/s
[Step=39500 Epoch=372.2] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.747 | L2-Norm(final)=7.297 | 2121.4 samples/s | 33.1 steps/s
[Step=39550 Epoch=372.7] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.741 | L2-Norm(final)=7.298 | 4867.7 samples/s | 76.1 steps/s
[Step=39600 Epoch=373.1] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.734 | L2-Norm(final)=7.299 | 2207.5 samples/s | 34.5 steps/s
[Step=39650 Epoch=373.6] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.727 | L2-Norm(final)=7.300 | 4507.7 samples/s | 70.4 steps/s
[Step=39700 Epoch=374.1] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.720 | L2-Norm(final)=7.301 | 2293.5 samples/s | 35.8 steps/s
[Step=39750 Epoch=374.6] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.713 | L2-Norm(final)=7.302 | 4271.8 samples/s | 66.7 steps/s
[Step=39800 Epoch=375.0] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.706 | L2-Norm(final)=7.303 | 2411.0 samples/s | 37.7 steps/s
[Step=39850 Epoch=375.5] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.699 | L2-Norm(final)=7.303 | 4237.0 samples/s | 66.2 steps/s
[Step=39900 Epoch=376.0] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.692 | L2-Norm(final)=7.304 | 2414.2 samples/s | 37.7 steps/s
[Step=39950 Epoch=376.4] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=7.305 | 4283.2 samples/s | 66.9 steps/s
[Step=40000 Epoch=376.9] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.677 | L2-Norm(final)=7.306 | 2389.8 samples/s | 37.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step40000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=362.2] | Loss=0.00005 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.595 | L2-Norm(final)=7.955 | 5374.0 samples/s | 84.0 steps/s
[Step=38050 Epoch=362.7] | Loss=0.00092 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.671 | L2-Norm(final)=7.978 | 4248.1 samples/s | 66.4 steps/s
[Step=38100 Epoch=363.1] | Loss=0.00081 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.726 | L2-Norm(final)=8.005 | 7563.4 samples/s | 118.2 steps/s
[Step=38150 Epoch=363.6] | Loss=0.00077 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.771 | L2-Norm(final)=8.027 | 2135.5 samples/s | 33.4 steps/s
[Step=38200 Epoch=364.1] | Loss=0.00060 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.800 | L2-Norm(final)=8.044 | 6716.1 samples/s | 104.9 steps/s
[Step=38250 Epoch=364.6] | Loss=0.00049 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.817 | L2-Norm(final)=8.056 | 2175.4 samples/s | 34.0 steps/s
[Step=38300 Epoch=365.0] | Loss=0.00042 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.828 | L2-Norm(final)=8.065 | 6253.1 samples/s | 97.7 steps/s
[Step=38350 Epoch=365.5] | Loss=0.00037 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.836 | L2-Norm(final)=8.073 | 2276.9 samples/s | 35.6 steps/s
[Step=38400 Epoch=366.0] | Loss=0.00032 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.841 | L2-Norm(final)=8.080 | 5511.3 samples/s | 86.1 steps/s
[Step=38450 Epoch=366.5] | Loss=0.00029 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.845 | L2-Norm(final)=8.086 | 2340.8 samples/s | 36.6 steps/s
[Step=38500 Epoch=366.9] | Loss=0.00027 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.848 | L2-Norm(final)=8.092 | 5135.4 samples/s | 80.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=366.9] | Loss=0.00002 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.873 | L2-Norm(final)=8.146 | 5294.3 samples/s | 82.7 steps/s
[Step=38550 Epoch=367.4] | Loss=0.00004 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.862 | L2-Norm(final)=8.150 | 3761.7 samples/s | 58.8 steps/s
[Step=38600 Epoch=367.9] | Loss=0.00784 | Reg=0.00098 | acc=0.9688 | L2-Norm=9.882 | L2-Norm(final)=8.150 | 6374.6 samples/s | 99.6 steps/s
[Step=38650 Epoch=368.4] | Loss=0.00664 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=8.131 | 2011.6 samples/s | 31.4 steps/s
[Step=38700 Epoch=368.8] | Loss=0.00541 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.071 | L2-Norm(final)=8.123 | 5768.1 samples/s | 90.1 steps/s
[Step=38750 Epoch=369.3] | Loss=0.00436 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.115 | L2-Norm(final)=8.119 | 2057.3 samples/s | 32.1 steps/s
[Step=38800 Epoch=369.8] | Loss=0.00365 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=8.117 | 5353.1 samples/s | 83.6 steps/s
[Step=38850 Epoch=370.3] | Loss=0.00313 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.164 | L2-Norm(final)=8.116 | 2143.0 samples/s | 33.5 steps/s
[Step=38900 Epoch=370.8] | Loss=0.00274 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.178 | L2-Norm(final)=8.115 | 4931.4 samples/s | 77.1 steps/s
[Step=38950 Epoch=371.2] | Loss=0.00244 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.189 | L2-Norm(final)=8.114 | 2224.7 samples/s | 34.8 steps/s
[Step=39000 Epoch=371.7] | Loss=0.00220 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.196 | L2-Norm(final)=8.114 | 4557.0 samples/s | 71.2 steps/s
[Step=39050 Epoch=372.2] | Loss=0.00200 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.202 | L2-Norm(final)=8.114 | 2284.9 samples/s | 35.7 steps/s
[Step=39100 Epoch=372.7] | Loss=0.00183 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.206 | L2-Norm(final)=8.114 | 4336.7 samples/s | 67.8 steps/s
[Step=39150 Epoch=373.1] | Loss=0.00169 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=8.114 | 2385.7 samples/s | 37.3 steps/s
[Step=39200 Epoch=373.6] | Loss=0.00157 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.210 | L2-Norm(final)=8.114 | 4200.6 samples/s | 65.6 steps/s
[Step=39250 Epoch=374.1] | Loss=0.00147 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=8.114 | 2369.3 samples/s | 37.0 steps/s
[Step=39300 Epoch=374.6] | Loss=0.00138 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=8.114 | 4226.8 samples/s | 66.0 steps/s
[Step=39350 Epoch=375.0] | Loss=0.00130 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=8.115 | 2371.3 samples/s | 37.1 steps/s
[Step=39400 Epoch=375.5] | Loss=0.00122 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=8.115 | 4335.4 samples/s | 67.7 steps/s
[Step=39450 Epoch=376.0] | Loss=0.00116 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.210 | L2-Norm(final)=8.115 | 2366.3 samples/s | 37.0 steps/s
[Step=39500 Epoch=376.5] | Loss=0.00110 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.209 | L2-Norm(final)=8.115 | 4202.6 samples/s | 65.7 steps/s
[Step=39550 Epoch=376.9] | Loss=0.00105 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.207 | L2-Norm(final)=8.116 | 7055.8 samples/s | 110.2 steps/s
[Step=39600 Epoch=377.4] | Loss=0.00100 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.206 | L2-Norm(final)=8.116 | 1966.3 samples/s | 30.7 steps/s
[Step=39650 Epoch=377.9] | Loss=0.00096 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.204 | L2-Norm(final)=8.117 | 6282.3 samples/s | 98.2 steps/s
[Step=39700 Epoch=378.4] | Loss=0.00092 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.201 | L2-Norm(final)=8.117 | 1998.4 samples/s | 31.2 steps/s
[Step=39750 Epoch=378.9] | Loss=0.00088 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=8.118 | 5850.9 samples/s | 91.4 steps/s
[Step=39800 Epoch=379.3] | Loss=0.00085 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.196 | L2-Norm(final)=8.119 | 2112.8 samples/s | 33.0 steps/s
[Step=39850 Epoch=379.8] | Loss=0.00082 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.193 | L2-Norm(final)=8.119 | 5141.3 samples/s | 80.3 steps/s
[Step=39900 Epoch=380.3] | Loss=0.00079 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=8.120 | 2125.5 samples/s | 33.2 steps/s
[Step=39950 Epoch=380.8] | Loss=0.00076 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.188 | L2-Norm(final)=8.121 | 5019.4 samples/s | 78.4 steps/s
[Step=40000 Epoch=381.2] | Loss=0.00074 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.184 | L2-Norm(final)=8.121 | 2180.4 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.12013 | acc=0.9514 | tpr=0.9573 | fpr=0.0614 | 5071.7 samples/s | 19.8 steps/s
Avg test loss: 0.12409, Avg test acc: 0.95032, Avg tpr: 0.95675, Avg fpr: 0.06384, total FA: 498

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.13225 | acc=0.9497 | tpr=0.9809 | fpr=0.1182 | 4867.3 samples/s | 19.0 steps/s
Avg test loss: 0.13158, Avg test acc: 0.95004, Avg tpr: 0.98100, Avg fpr: 0.11806, total FA: 921

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11774 | acc=0.9564 | tpr=0.9698 | fpr=0.0726 | 5047.6 samples/s | 19.7 steps/s
Avg test loss: 0.12017, Avg test acc: 0.95569, Avg tpr: 0.96928, Avg fpr: 0.07422, total FA: 579

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.11962 | acc=0.9582 | tpr=0.9715 | fpr=0.0706 | 4959.2 samples/s | 19.4 steps/s
Avg test loss: 0.12527, Avg test acc: 0.95625, Avg tpr: 0.97092, Avg fpr: 0.07602, total FA: 593

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11732 | acc=0.9584 | tpr=0.9749 | fpr=0.0776 | 4869.0 samples/s | 19.0 steps/s
Avg test loss: 0.12284, Avg test acc: 0.95781, Avg tpr: 0.97470, Avg fpr: 0.07935, total FA: 619

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.42032 | acc=0.2958 | tpr=0.0105 | fpr=0.0847 | 4920.6 samples/s | 19.2 steps/s
Avg test loss: 5.42591, Avg test acc: 0.29441, Avg tpr: 0.01177, Avg fpr: 0.08396, total FA: 655

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.90537 | acc=0.2940 | tpr=0.0137 | fpr=0.0974 | 4820.1 samples/s | 18.8 steps/s
Avg test loss: 4.92211, Avg test acc: 0.29181, Avg tpr: 0.01440, Avg fpr: 0.09806, total FA: 765

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.05187 | acc=0.2991 | tpr=0.0111 | fpr=0.0756 | 5058.0 samples/s | 19.8 steps/s
Avg test loss: 5.06683, Avg test acc: 0.29682, Avg tpr: 0.01096, Avg fpr: 0.07448, total FA: 581

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.75865 | acc=0.2834 | tpr=0.0217 | fpr=0.1484 | 4641.6 samples/s | 18.1 steps/s
Avg test loss: 5.74752, Avg test acc: 0.28223, Avg tpr: 0.02238, Avg fpr: 0.14626, total FA: 1141

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.78186 | acc=0.3046 | tpr=0.0097 | fpr=0.0550 | 4888.9 samples/s | 19.1 steps/s
Avg test loss: 5.79521, Avg test acc: 0.30219, Avg tpr: 0.00956, Avg fpr: 0.05422, total FA: 423

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.10617 | acc=0.1270 | tpr=0.5664 | fpr=0.8809 | 4742.9 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.07806 | acc=0.1288 | tpr=0.5544 | fpr=0.8791 | 5496.0 samples/s | 21.5 steps/s
[Step= 150] | Loss=5.09270 | acc=0.1287 | tpr=0.5375 | fpr=0.8789 | 7860.2 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.08677 | acc=0.1289 | tpr=0.5443 | fpr=0.8787 | 7742.5 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.09215 | acc=0.1288 | tpr=0.5389 | fpr=0.8787 | 7821.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=5.08861 | acc=0.1291 | tpr=0.5484 | fpr=0.8786 | 8000.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.08485 | acc=0.1289 | tpr=0.5567 | fpr=0.8788 | 7386.8 samples/s | 28.9 steps/s
[Step= 400] | Loss=5.07878 | acc=0.1293 | tpr=0.5536 | fpr=0.8784 | 7824.1 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.08273 | acc=0.1294 | tpr=0.5516 | fpr=0.8783 | 8065.2 samples/s | 31.5 steps/s
[Step= 500] | Loss=5.08612 | acc=0.1295 | tpr=0.5480 | fpr=0.8780 | 7586.3 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.08755 | acc=0.1295 | tpr=0.5448 | fpr=0.8781 | 13930.4 samples/s | 54.4 steps/s
Avg test loss: 5.08883, Avg test acc: 0.12932, Avg tpr: 0.54477, Avg fpr: 0.87823, total FA: 121941

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.76140 | acc=0.0641 | tpr=0.6770 | fpr=0.9469 | 4866.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.75091 | acc=0.0638 | tpr=0.6482 | fpr=0.9471 | 5998.0 samples/s | 23.4 steps/s
[Step= 150] | Loss=5.75778 | acc=0.0643 | tpr=0.6571 | fpr=0.9466 | 7182.7 samples/s | 28.1 steps/s
[Step= 200] | Loss=5.75437 | acc=0.0643 | tpr=0.6514 | fpr=0.9464 | 7556.6 samples/s | 29.5 steps/s
[Step= 250] | Loss=5.76348 | acc=0.0642 | tpr=0.6533 | fpr=0.9465 | 7372.9 samples/s | 28.8 steps/s
[Step= 300] | Loss=5.75282 | acc=0.0646 | tpr=0.6589 | fpr=0.9463 | 8402.6 samples/s | 32.8 steps/s
[Step= 350] | Loss=5.74722 | acc=0.0648 | tpr=0.6612 | fpr=0.9460 | 7736.7 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.74148 | acc=0.0650 | tpr=0.6608 | fpr=0.9458 | 7580.6 samples/s | 29.6 steps/s
[Step= 450] | Loss=5.74439 | acc=0.0648 | tpr=0.6587 | fpr=0.9460 | 7743.4 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.74826 | acc=0.0645 | tpr=0.6564 | fpr=0.9462 | 8101.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.75025 | acc=0.0646 | tpr=0.6550 | fpr=0.9461 | 13258.6 samples/s | 51.8 steps/s
Avg test loss: 5.75295, Avg test acc: 0.06448, Avg tpr: 0.65452, Avg fpr: 0.94625, total FA: 131385

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.57335 | acc=0.0961 | tpr=0.5177 | fpr=0.9115 | 4322.1 samples/s | 16.9 steps/s
[Step= 100] | Loss=5.53996 | acc=0.0963 | tpr=0.5117 | fpr=0.9115 | 7017.3 samples/s | 27.4 steps/s
[Step= 150] | Loss=5.54801 | acc=0.0971 | tpr=0.5159 | fpr=0.9106 | 7320.3 samples/s | 28.6 steps/s
[Step= 200] | Loss=5.54351 | acc=0.0964 | tpr=0.5104 | fpr=0.9111 | 6607.8 samples/s | 25.8 steps/s
[Step= 250] | Loss=5.54761 | acc=0.0969 | tpr=0.5022 | fpr=0.9104 | 8175.7 samples/s | 31.9 steps/s
[Step= 300] | Loss=5.54346 | acc=0.0971 | tpr=0.5105 | fpr=0.9105 | 7872.5 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.53822 | acc=0.0972 | tpr=0.5128 | fpr=0.9103 | 8057.2 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.53289 | acc=0.0974 | tpr=0.5071 | fpr=0.9101 | 7493.9 samples/s | 29.3 steps/s
[Step= 450] | Loss=5.53307 | acc=0.0975 | tpr=0.5049 | fpr=0.9099 | 7912.7 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.53431 | acc=0.0972 | tpr=0.5031 | fpr=0.9101 | 7960.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.53436 | acc=0.0971 | tpr=0.4970 | fpr=0.9102 | 14406.7 samples/s | 56.3 steps/s
Avg test loss: 5.53556, Avg test acc: 0.09700, Avg tpr: 0.49802, Avg fpr: 0.91029, total FA: 126392

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.86067 | acc=0.1016 | tpr=0.6770 | fpr=0.9088 | 4942.7 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.83793 | acc=0.1029 | tpr=0.6695 | fpr=0.9076 | 6613.4 samples/s | 25.8 steps/s
[Step= 150] | Loss=5.84347 | acc=0.1025 | tpr=0.6614 | fpr=0.9078 | 8041.3 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.84352 | acc=0.1020 | tpr=0.6546 | fpr=0.9081 | 6211.9 samples/s | 24.3 steps/s
[Step= 250] | Loss=5.85283 | acc=0.1020 | tpr=0.6507 | fpr=0.9080 | 7071.6 samples/s | 27.6 steps/s
[Step= 300] | Loss=5.85172 | acc=0.1021 | tpr=0.6553 | fpr=0.9080 | 7546.4 samples/s | 29.5 steps/s
[Step= 350] | Loss=5.84498 | acc=0.1021 | tpr=0.6525 | fpr=0.9079 | 8069.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.84004 | acc=0.1023 | tpr=0.6504 | fpr=0.9076 | 7384.9 samples/s | 28.8 steps/s
[Step= 450] | Loss=5.84494 | acc=0.1023 | tpr=0.6538 | fpr=0.9077 | 8369.5 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.84820 | acc=0.1019 | tpr=0.6551 | fpr=0.9081 | 7707.4 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.85091 | acc=0.1020 | tpr=0.6550 | fpr=0.9081 | 13412.5 samples/s | 52.4 steps/s
Avg test loss: 5.85153, Avg test acc: 0.10187, Avg tpr: 0.65452, Avg fpr: 0.90817, total FA: 126098

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.16970 | acc=0.0932 | tpr=0.6372 | fpr=0.9166 | 4633.8 samples/s | 18.1 steps/s
[Step= 100] | Loss=6.14329 | acc=0.0939 | tpr=0.6333 | fpr=0.9162 | 7128.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=6.14945 | acc=0.0928 | tpr=0.6153 | fpr=0.9168 | 7913.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.15044 | acc=0.0921 | tpr=0.5934 | fpr=0.9171 | 5703.9 samples/s | 22.3 steps/s
[Step= 250] | Loss=6.15926 | acc=0.0931 | tpr=0.5965 | fpr=0.9161 | 7983.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.15946 | acc=0.0932 | tpr=0.5993 | fpr=0.9160 | 7913.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.15145 | acc=0.0931 | tpr=0.5999 | fpr=0.9160 | 8057.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.14959 | acc=0.0934 | tpr=0.5974 | fpr=0.9158 | 7325.0 samples/s | 28.6 steps/s
[Step= 450] | Loss=6.15080 | acc=0.0936 | tpr=0.6008 | fpr=0.9156 | 7711.2 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.15402 | acc=0.0935 | tpr=0.5996 | fpr=0.9156 | 7458.7 samples/s | 29.1 steps/s
[Step= 550] | Loss=6.15671 | acc=0.0935 | tpr=0.6033 | fpr=0.9158 | 15626.0 samples/s | 61.0 steps/s
Avg test loss: 6.15847, Avg test acc: 0.09336, Avg tpr: 0.60301, Avg fpr: 0.91590, total FA: 127171

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09486 | acc=0.9820 | tpr=0.9558 | fpr=0.0176 | 4610.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.09787 | acc=0.9819 | tpr=0.9552 | fpr=0.0176 | 7118.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.10131 | acc=0.9811 | tpr=0.9553 | fpr=0.0185 | 7956.2 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.10339 | acc=0.9809 | tpr=0.9585 | fpr=0.0187 | 5876.6 samples/s | 23.0 steps/s
[Step= 250] | Loss=0.10192 | acc=0.9812 | tpr=0.9528 | fpr=0.0182 | 7561.9 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.10429 | acc=0.9808 | tpr=0.9505 | fpr=0.0187 | 7713.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.10546 | acc=0.9805 | tpr=0.9505 | fpr=0.0190 | 7856.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10673 | acc=0.9802 | tpr=0.9458 | fpr=0.0192 | 7906.0 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10887 | acc=0.9798 | tpr=0.9445 | fpr=0.0196 | 7895.6 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10818 | acc=0.9799 | tpr=0.9449 | fpr=0.0195 | 7790.7 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.10777 | acc=0.9801 | tpr=0.9439 | fpr=0.0193 | 13786.6 samples/s | 53.9 steps/s
Avg test loss: 0.10768, Avg test acc: 0.98007, Avg tpr: 0.94414, Avg fpr: 0.01928, total FA: 2677

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08550 | acc=0.9825 | tpr=0.9159 | fpr=0.0163 | 4734.0 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.08684 | acc=0.9826 | tpr=0.9211 | fpr=0.0163 | 7209.0 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.09019 | acc=0.9818 | tpr=0.9207 | fpr=0.0171 | 6130.9 samples/s | 23.9 steps/s
[Step= 200] | Loss=0.09181 | acc=0.9817 | tpr=0.9224 | fpr=0.0172 | 7258.2 samples/s | 28.4 steps/s
[Step= 250] | Loss=0.09055 | acc=0.9819 | tpr=0.9223 | fpr=0.0170 | 7531.5 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.09327 | acc=0.9815 | tpr=0.9164 | fpr=0.0173 | 7757.6 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.09414 | acc=0.9812 | tpr=0.9192 | fpr=0.0176 | 7831.6 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.09519 | acc=0.9810 | tpr=0.9114 | fpr=0.0177 | 7575.6 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.09736 | acc=0.9807 | tpr=0.9070 | fpr=0.0180 | 7542.9 samples/s | 29.5 steps/s
[Step= 500] | Loss=0.09646 | acc=0.9808 | tpr=0.9106 | fpr=0.0179 | 8292.2 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.09618 | acc=0.9809 | tpr=0.9089 | fpr=0.0178 | 13301.6 samples/s | 52.0 steps/s
Avg test loss: 0.09600, Avg test acc: 0.98094, Avg tpr: 0.90927, Avg fpr: 0.01775, total FA: 2465

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08676 | acc=0.9832 | tpr=0.9469 | fpr=0.0161 | 4832.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.08803 | acc=0.9830 | tpr=0.9382 | fpr=0.0162 | 6773.8 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.09227 | acc=0.9822 | tpr=0.9395 | fpr=0.0170 | 5930.6 samples/s | 23.2 steps/s
[Step= 200] | Loss=0.09452 | acc=0.9821 | tpr=0.9443 | fpr=0.0172 | 7898.6 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.09307 | acc=0.9821 | tpr=0.9406 | fpr=0.0171 | 7639.5 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.09530 | acc=0.9818 | tpr=0.9353 | fpr=0.0174 | 8003.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.09647 | acc=0.9817 | tpr=0.9361 | fpr=0.0175 | 7829.4 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.09728 | acc=0.9814 | tpr=0.9344 | fpr=0.0177 | 7734.1 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.09907 | acc=0.9811 | tpr=0.9343 | fpr=0.0180 | 8054.4 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.09822 | acc=0.9812 | tpr=0.9361 | fpr=0.0180 | 7568.0 samples/s | 29.6 steps/s
[Step= 550] | Loss=0.09848 | acc=0.9812 | tpr=0.9359 | fpr=0.0180 | 14115.9 samples/s | 55.1 steps/s
Avg test loss: 0.09826, Avg test acc: 0.98122, Avg tpr: 0.93582, Avg fpr: 0.01795, total FA: 2493

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09520 | acc=0.9817 | tpr=0.9292 | fpr=0.0173 | 5024.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.10060 | acc=0.9812 | tpr=0.9232 | fpr=0.0177 | 6647.9 samples/s | 26.0 steps/s
[Step= 150] | Loss=0.10463 | acc=0.9807 | tpr=0.9294 | fpr=0.0184 | 5695.8 samples/s | 22.2 steps/s
[Step= 200] | Loss=0.10615 | acc=0.9809 | tpr=0.9366 | fpr=0.0183 | 8109.9 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.10443 | acc=0.9813 | tpr=0.9354 | fpr=0.0179 | 7824.6 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.10726 | acc=0.9808 | tpr=0.9302 | fpr=0.0182 | 7818.1 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.10772 | acc=0.9807 | tpr=0.9324 | fpr=0.0184 | 7965.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.10809 | acc=0.9806 | tpr=0.9294 | fpr=0.0185 | 7871.4 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.11045 | acc=0.9803 | tpr=0.9265 | fpr=0.0187 | 7623.8 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.10947 | acc=0.9805 | tpr=0.9291 | fpr=0.0186 | 8065.5 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.10915 | acc=0.9806 | tpr=0.9288 | fpr=0.0184 | 13653.2 samples/s | 53.3 steps/s
Avg test loss: 0.10905, Avg test acc: 0.98064, Avg tpr: 0.92868, Avg fpr: 0.01842, total FA: 2557

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10326 | acc=0.9810 | tpr=0.9204 | fpr=0.0179 | 4717.2 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10629 | acc=0.9809 | tpr=0.9190 | fpr=0.0179 | 5531.5 samples/s | 21.6 steps/s
[Step= 150] | Loss=0.11135 | acc=0.9798 | tpr=0.9265 | fpr=0.0192 | 7221.7 samples/s | 28.2 steps/s
[Step= 200] | Loss=0.11380 | acc=0.9799 | tpr=0.9355 | fpr=0.0193 | 8202.0 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.11173 | acc=0.9801 | tpr=0.9310 | fpr=0.0190 | 8215.4 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.11425 | acc=0.9798 | tpr=0.9229 | fpr=0.0191 | 7536.2 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.11498 | acc=0.9796 | tpr=0.9242 | fpr=0.0194 | 7767.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.11609 | acc=0.9794 | tpr=0.9201 | fpr=0.0195 | 8010.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.11814 | acc=0.9791 | tpr=0.9197 | fpr=0.0198 | 7528.2 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.11715 | acc=0.9792 | tpr=0.9207 | fpr=0.0197 | 8043.6 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.11688 | acc=0.9794 | tpr=0.9184 | fpr=0.0195 | 14025.3 samples/s | 54.8 steps/s
Avg test loss: 0.11670, Avg test acc: 0.97936, Avg tpr: 0.91759, Avg fpr: 0.01952, total FA: 2710

server round 20/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=195.1] | Loss=0.01430 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.756 | L2-Norm(final)=12.346 | 5393.7 samples/s | 84.3 steps/s
[Step=40050 Epoch=195.3] | Loss=0.00466 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.758 | L2-Norm(final)=12.351 | 4408.4 samples/s | 68.9 steps/s
[Step=40100 Epoch=195.5] | Loss=0.00464 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.757 | L2-Norm(final)=12.359 | 5066.1 samples/s | 79.2 steps/s
[Step=40150 Epoch=195.8] | Loss=0.00438 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.757 | L2-Norm(final)=12.367 | 4994.7 samples/s | 78.0 steps/s
[Step=40200 Epoch=196.0] | Loss=0.00436 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.756 | L2-Norm(final)=12.375 | 7872.5 samples/s | 123.0 steps/s
[Step=40250 Epoch=196.3] | Loss=0.00426 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.755 | L2-Norm(final)=12.382 | 2186.2 samples/s | 34.2 steps/s
[Step=40300 Epoch=196.5] | Loss=0.00413 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.754 | L2-Norm(final)=12.390 | 5033.8 samples/s | 78.7 steps/s
[Step=40350 Epoch=196.8] | Loss=0.00409 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.752 | L2-Norm(final)=12.398 | 4997.6 samples/s | 78.1 steps/s
[Step=40400 Epoch=197.0] | Loss=0.00393 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.751 | L2-Norm(final)=12.405 | 7012.1 samples/s | 109.6 steps/s
[Step=40450 Epoch=197.2] | Loss=0.00378 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.750 | L2-Norm(final)=12.413 | 2288.8 samples/s | 35.8 steps/s
[Step=40500 Epoch=197.5] | Loss=0.00374 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.748 | L2-Norm(final)=12.420 | 5043.6 samples/s | 78.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=197.5] | Loss=0.00082 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.733 | L2-Norm(final)=12.495 | 5312.2 samples/s | 83.0 steps/s
[Step=40550 Epoch=197.7] | Loss=0.00330 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.732 | L2-Norm(final)=12.501 | 3975.4 samples/s | 62.1 steps/s
[Step=40600 Epoch=198.0] | Loss=0.00365 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.731 | L2-Norm(final)=12.505 | 4423.0 samples/s | 69.1 steps/s
[Step=40650 Epoch=198.2] | Loss=0.00359 | Reg=0.00351 | acc=0.9531 | L2-Norm=18.730 | L2-Norm(final)=12.510 | 4468.3 samples/s | 69.8 steps/s
[Step=40700 Epoch=198.5] | Loss=0.00391 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.727 | L2-Norm(final)=12.513 | 6576.3 samples/s | 102.8 steps/s
[Step=40750 Epoch=198.7] | Loss=0.00402 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.724 | L2-Norm(final)=12.516 | 2115.8 samples/s | 33.1 steps/s
[Step=40800 Epoch=198.9] | Loss=0.00392 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.721 | L2-Norm(final)=12.519 | 4360.5 samples/s | 68.1 steps/s
[Step=40850 Epoch=199.2] | Loss=0.00375 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.717 | L2-Norm(final)=12.522 | 4502.9 samples/s | 70.4 steps/s
[Step=40900 Epoch=199.4] | Loss=0.00366 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.713 | L2-Norm(final)=12.524 | 5871.0 samples/s | 91.7 steps/s
[Step=40950 Epoch=199.7] | Loss=0.00366 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.709 | L2-Norm(final)=12.527 | 1664.3 samples/s | 26.0 steps/s
[Step=41000 Epoch=199.9] | Loss=0.00356 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.704 | L2-Norm(final)=12.529 | 4405.5 samples/s | 68.8 steps/s
[Step=41050 Epoch=200.2] | Loss=0.00352 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.700 | L2-Norm(final)=12.531 | 4444.4 samples/s | 69.4 steps/s
[Step=41100 Epoch=200.4] | Loss=0.00351 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.695 | L2-Norm(final)=12.533 | 5208.3 samples/s | 81.4 steps/s
[Step=41150 Epoch=200.7] | Loss=0.00345 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.690 | L2-Norm(final)=12.536 | 2231.8 samples/s | 34.9 steps/s
[Step=41200 Epoch=200.9] | Loss=0.00340 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.685 | L2-Norm(final)=12.538 | 4411.2 samples/s | 68.9 steps/s
[Step=41250 Epoch=201.1] | Loss=0.00338 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=12.540 | 4426.0 samples/s | 69.2 steps/s
[Step=41300 Epoch=201.4] | Loss=0.00337 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.675 | L2-Norm(final)=12.542 | 4966.1 samples/s | 77.6 steps/s
[Step=41350 Epoch=201.6] | Loss=0.00331 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.670 | L2-Norm(final)=12.544 | 2343.5 samples/s | 36.6 steps/s
[Step=41400 Epoch=201.9] | Loss=0.00326 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.665 | L2-Norm(final)=12.546 | 4542.2 samples/s | 71.0 steps/s
[Step=41450 Epoch=202.1] | Loss=0.00321 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.659 | L2-Norm(final)=12.548 | 4423.8 samples/s | 69.1 steps/s
[Step=41500 Epoch=202.4] | Loss=0.00314 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.653 | L2-Norm(final)=12.550 | 4602.4 samples/s | 71.9 steps/s
[Step=41550 Epoch=202.6] | Loss=0.00321 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.648 | L2-Norm(final)=12.552 | 2402.3 samples/s | 37.5 steps/s
[Step=41600 Epoch=202.8] | Loss=0.00321 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.642 | L2-Norm(final)=12.554 | 4416.7 samples/s | 69.0 steps/s
[Step=41650 Epoch=203.1] | Loss=0.00320 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.636 | L2-Norm(final)=12.556 | 4494.3 samples/s | 70.2 steps/s
[Step=41700 Epoch=203.3] | Loss=0.00319 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.630 | L2-Norm(final)=12.558 | 4424.9 samples/s | 69.1 steps/s
[Step=41750 Epoch=203.6] | Loss=0.00322 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.624 | L2-Norm(final)=12.559 | 2435.6 samples/s | 38.1 steps/s
[Step=41800 Epoch=203.8] | Loss=0.00320 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.618 | L2-Norm(final)=12.561 | 4435.8 samples/s | 69.3 steps/s
[Step=41850 Epoch=204.1] | Loss=0.00314 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.612 | L2-Norm(final)=12.563 | 4495.2 samples/s | 70.2 steps/s
[Step=41900 Epoch=204.3] | Loss=0.00313 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.606 | L2-Norm(final)=12.565 | 4461.6 samples/s | 69.7 steps/s
[Step=41950 Epoch=204.6] | Loss=0.00315 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.600 | L2-Norm(final)=12.567 | 2386.8 samples/s | 37.3 steps/s
[Step=42000 Epoch=204.8] | Loss=0.00314 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.594 | L2-Norm(final)=12.569 | 4433.1 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step42000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=195.2] | Loss=0.00279 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.682 | L2-Norm(final)=12.480 | 5133.5 samples/s | 80.2 steps/s
[Step=40050 Epoch=195.4] | Loss=0.00399 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.684 | L2-Norm(final)=12.488 | 4552.3 samples/s | 71.1 steps/s
[Step=40100 Epoch=195.7] | Loss=0.00397 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.684 | L2-Norm(final)=12.498 | 5200.6 samples/s | 81.3 steps/s
[Step=40150 Epoch=195.9] | Loss=0.00371 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.684 | L2-Norm(final)=12.509 | 4997.9 samples/s | 78.1 steps/s
[Step=40200 Epoch=196.2] | Loss=0.00407 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.684 | L2-Norm(final)=12.518 | 7699.7 samples/s | 120.3 steps/s
[Step=40250 Epoch=196.4] | Loss=0.00395 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.683 | L2-Norm(final)=12.528 | 2181.9 samples/s | 34.1 steps/s
[Step=40300 Epoch=196.6] | Loss=0.00387 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.682 | L2-Norm(final)=12.537 | 5074.9 samples/s | 79.3 steps/s
[Step=40350 Epoch=196.9] | Loss=0.00375 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.682 | L2-Norm(final)=12.546 | 4943.6 samples/s | 77.2 steps/s
[Step=40400 Epoch=197.1] | Loss=0.00372 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.681 | L2-Norm(final)=12.555 | 7199.4 samples/s | 112.5 steps/s
[Step=40450 Epoch=197.4] | Loss=0.00358 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=12.563 | 2247.9 samples/s | 35.1 steps/s
[Step=40500 Epoch=197.6] | Loss=0.00346 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.678 | L2-Norm(final)=12.572 | 5065.9 samples/s | 79.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=197.6] | Loss=0.00179 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.664 | L2-Norm(final)=12.658 | 5270.8 samples/s | 82.4 steps/s
[Step=40550 Epoch=197.9] | Loss=0.00239 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.662 | L2-Norm(final)=12.666 | 4070.1 samples/s | 63.6 steps/s
[Step=40600 Epoch=198.1] | Loss=0.00316 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.662 | L2-Norm(final)=12.672 | 4416.2 samples/s | 69.0 steps/s
[Step=40650 Epoch=198.4] | Loss=0.00336 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.661 | L2-Norm(final)=12.677 | 4553.2 samples/s | 71.1 steps/s
[Step=40700 Epoch=198.6] | Loss=0.00351 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.659 | L2-Norm(final)=12.682 | 6376.5 samples/s | 99.6 steps/s
[Step=40750 Epoch=198.8] | Loss=0.00343 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.657 | L2-Norm(final)=12.685 | 2094.9 samples/s | 32.7 steps/s
[Step=40800 Epoch=199.1] | Loss=0.00323 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.654 | L2-Norm(final)=12.689 | 4449.0 samples/s | 69.5 steps/s
[Step=40850 Epoch=199.3] | Loss=0.00329 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.650 | L2-Norm(final)=12.692 | 4481.8 samples/s | 70.0 steps/s
[Step=40900 Epoch=199.6] | Loss=0.00315 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.646 | L2-Norm(final)=12.695 | 6027.1 samples/s | 94.2 steps/s
[Step=40950 Epoch=199.8] | Loss=0.00301 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.642 | L2-Norm(final)=12.699 | 2095.9 samples/s | 32.7 steps/s
[Step=41000 Epoch=200.1] | Loss=0.00293 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.637 | L2-Norm(final)=12.702 | 4499.8 samples/s | 70.3 steps/s
[Step=41050 Epoch=200.3] | Loss=0.00286 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.633 | L2-Norm(final)=12.705 | 4436.8 samples/s | 69.3 steps/s
[Step=41100 Epoch=200.5] | Loss=0.00295 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.628 | L2-Norm(final)=12.708 | 5638.1 samples/s | 88.1 steps/s
[Step=41150 Epoch=200.8] | Loss=0.00293 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.623 | L2-Norm(final)=12.711 | 2212.0 samples/s | 34.6 steps/s
[Step=41200 Epoch=201.0] | Loss=0.00291 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.618 | L2-Norm(final)=12.713 | 4456.2 samples/s | 69.6 steps/s
[Step=41250 Epoch=201.3] | Loss=0.00289 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.613 | L2-Norm(final)=12.716 | 4494.7 samples/s | 70.2 steps/s
[Step=41300 Epoch=201.5] | Loss=0.00291 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.608 | L2-Norm(final)=12.718 | 5155.8 samples/s | 80.6 steps/s
[Step=41350 Epoch=201.8] | Loss=0.00290 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.603 | L2-Norm(final)=12.721 | 2189.3 samples/s | 34.2 steps/s
[Step=41400 Epoch=202.0] | Loss=0.00287 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.598 | L2-Norm(final)=12.723 | 4419.7 samples/s | 69.1 steps/s
[Step=41450 Epoch=202.3] | Loss=0.00282 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.593 | L2-Norm(final)=12.726 | 4481.4 samples/s | 70.0 steps/s
[Step=41500 Epoch=202.5] | Loss=0.00279 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.588 | L2-Norm(final)=12.729 | 4868.7 samples/s | 76.1 steps/s
[Step=41550 Epoch=202.7] | Loss=0.00273 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.582 | L2-Norm(final)=12.731 | 2342.2 samples/s | 36.6 steps/s
[Step=41600 Epoch=203.0] | Loss=0.00275 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.576 | L2-Norm(final)=12.734 | 4456.4 samples/s | 69.6 steps/s
[Step=41650 Epoch=203.2] | Loss=0.00274 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.571 | L2-Norm(final)=12.737 | 4398.3 samples/s | 68.7 steps/s
[Step=41700 Epoch=203.5] | Loss=0.00274 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.565 | L2-Norm(final)=12.739 | 4588.3 samples/s | 71.7 steps/s
[Step=41750 Epoch=203.7] | Loss=0.00276 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.559 | L2-Norm(final)=12.742 | 2434.2 samples/s | 38.0 steps/s
[Step=41800 Epoch=204.0] | Loss=0.00272 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.553 | L2-Norm(final)=12.744 | 4514.5 samples/s | 70.5 steps/s
[Step=41850 Epoch=204.2] | Loss=0.00273 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.547 | L2-Norm(final)=12.746 | 4379.1 samples/s | 68.4 steps/s
[Step=41900 Epoch=204.5] | Loss=0.00272 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.542 | L2-Norm(final)=12.749 | 4481.7 samples/s | 70.0 steps/s
[Step=41950 Epoch=204.7] | Loss=0.00267 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.536 | L2-Norm(final)=12.751 | 2484.6 samples/s | 38.8 steps/s
[Step=42000 Epoch=204.9] | Loss=0.00266 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.529 | L2-Norm(final)=12.754 | 4209.2 samples/s | 65.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step42000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=194.9] | Loss=0.00855 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.075 | L2-Norm(final)=12.925 | 5467.4 samples/s | 85.4 steps/s
[Step=40050 Epoch=195.1] | Loss=0.00511 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.082 | L2-Norm(final)=12.931 | 4446.2 samples/s | 69.5 steps/s
[Step=40100 Epoch=195.4] | Loss=0.00470 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.082 | L2-Norm(final)=12.939 | 5067.2 samples/s | 79.2 steps/s
[Step=40150 Epoch=195.6] | Loss=0.00503 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.081 | L2-Norm(final)=12.946 | 5089.1 samples/s | 79.5 steps/s
[Step=40200 Epoch=195.9] | Loss=0.00494 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.081 | L2-Norm(final)=12.953 | 7498.2 samples/s | 117.2 steps/s
[Step=40250 Epoch=196.1] | Loss=0.00455 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.080 | L2-Norm(final)=12.961 | 2229.1 samples/s | 34.8 steps/s
[Step=40300 Epoch=196.4] | Loss=0.00453 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.079 | L2-Norm(final)=12.968 | 5039.9 samples/s | 78.7 steps/s
[Step=40350 Epoch=196.6] | Loss=0.00448 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.078 | L2-Norm(final)=12.976 | 4823.7 samples/s | 75.4 steps/s
[Step=40400 Epoch=196.8] | Loss=0.00444 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.076 | L2-Norm(final)=12.983 | 6878.8 samples/s | 107.5 steps/s
[Step=40450 Epoch=197.1] | Loss=0.00434 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.075 | L2-Norm(final)=12.990 | 2314.2 samples/s | 36.2 steps/s
[Step=40500 Epoch=197.3] | Loss=0.00427 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.073 | L2-Norm(final)=12.998 | 4983.2 samples/s | 77.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=197.3] | Loss=0.00577 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=13.071 | 5242.6 samples/s | 81.9 steps/s
[Step=40550 Epoch=197.6] | Loss=0.00411 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=13.078 | 4098.2 samples/s | 64.0 steps/s
[Step=40600 Epoch=197.8] | Loss=0.00460 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=13.083 | 4501.1 samples/s | 70.3 steps/s
[Step=40650 Epoch=198.1] | Loss=0.00447 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.058 | L2-Norm(final)=13.088 | 4431.9 samples/s | 69.2 steps/s
[Step=40700 Epoch=198.3] | Loss=0.00412 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.056 | L2-Norm(final)=13.092 | 6344.1 samples/s | 99.1 steps/s
[Step=40750 Epoch=198.6] | Loss=0.00401 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.054 | L2-Norm(final)=13.096 | 2080.3 samples/s | 32.5 steps/s
[Step=40800 Epoch=198.8] | Loss=0.00406 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.051 | L2-Norm(final)=13.100 | 4517.2 samples/s | 70.6 steps/s
[Step=40850 Epoch=199.0] | Loss=0.00396 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.048 | L2-Norm(final)=13.103 | 4479.2 samples/s | 70.0 steps/s
[Step=40900 Epoch=199.3] | Loss=0.00380 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.045 | L2-Norm(final)=13.106 | 5861.0 samples/s | 91.6 steps/s
[Step=40950 Epoch=199.5] | Loss=0.00381 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.041 | L2-Norm(final)=13.109 | 2153.6 samples/s | 33.6 steps/s
[Step=41000 Epoch=199.8] | Loss=0.00379 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.037 | L2-Norm(final)=13.112 | 4473.3 samples/s | 69.9 steps/s
[Step=41050 Epoch=200.0] | Loss=0.00365 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.033 | L2-Norm(final)=13.115 | 4395.5 samples/s | 68.7 steps/s
[Step=41100 Epoch=200.3] | Loss=0.00358 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.029 | L2-Norm(final)=13.117 | 5331.9 samples/s | 83.3 steps/s
[Step=41150 Epoch=200.5] | Loss=0.00344 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.024 | L2-Norm(final)=13.120 | 2281.4 samples/s | 35.6 steps/s
[Step=41200 Epoch=200.7] | Loss=0.00340 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.020 | L2-Norm(final)=13.123 | 4407.3 samples/s | 68.9 steps/s
[Step=41250 Epoch=201.0] | Loss=0.00342 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.016 | L2-Norm(final)=13.126 | 4478.5 samples/s | 70.0 steps/s
[Step=41300 Epoch=201.2] | Loss=0.00338 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.011 | L2-Norm(final)=13.128 | 4971.0 samples/s | 77.7 steps/s
[Step=41350 Epoch=201.5] | Loss=0.00333 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.006 | L2-Norm(final)=13.131 | 2307.9 samples/s | 36.1 steps/s
[Step=41400 Epoch=201.7] | Loss=0.00339 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.002 | L2-Norm(final)=13.133 | 4521.6 samples/s | 70.6 steps/s
[Step=41450 Epoch=202.0] | Loss=0.00332 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.997 | L2-Norm(final)=13.136 | 4453.2 samples/s | 69.6 steps/s
[Step=41500 Epoch=202.2] | Loss=0.00328 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.992 | L2-Norm(final)=13.138 | 4532.9 samples/s | 70.8 steps/s
[Step=41550 Epoch=202.5] | Loss=0.00327 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.987 | L2-Norm(final)=13.141 | 2387.2 samples/s | 37.3 steps/s
[Step=41600 Epoch=202.7] | Loss=0.00320 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.982 | L2-Norm(final)=13.143 | 4509.7 samples/s | 70.5 steps/s
[Step=41650 Epoch=202.9] | Loss=0.00316 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.976 | L2-Norm(final)=13.145 | 4480.6 samples/s | 70.0 steps/s
[Step=41700 Epoch=203.2] | Loss=0.00314 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.971 | L2-Norm(final)=13.148 | 4388.3 samples/s | 68.6 steps/s
[Step=41750 Epoch=203.4] | Loss=0.00314 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.966 | L2-Norm(final)=13.150 | 2441.5 samples/s | 38.1 steps/s
[Step=41800 Epoch=203.7] | Loss=0.00313 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.960 | L2-Norm(final)=13.152 | 4397.2 samples/s | 68.7 steps/s
[Step=41850 Epoch=203.9] | Loss=0.00313 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.954 | L2-Norm(final)=13.154 | 4513.5 samples/s | 70.5 steps/s
[Step=41900 Epoch=204.2] | Loss=0.00314 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.949 | L2-Norm(final)=13.156 | 4544.6 samples/s | 71.0 steps/s
[Step=41950 Epoch=204.4] | Loss=0.00313 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.943 | L2-Norm(final)=13.159 | 2439.7 samples/s | 38.1 steps/s
[Step=42000 Epoch=204.6] | Loss=0.00311 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.938 | L2-Norm(final)=13.161 | 4520.3 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step42000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=195.1] | Loss=0.00159 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.838 | L2-Norm(final)=12.756 | 5363.7 samples/s | 83.8 steps/s
[Step=40050 Epoch=195.3] | Loss=0.00475 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.838 | L2-Norm(final)=12.764 | 4445.5 samples/s | 69.5 steps/s
[Step=40100 Epoch=195.6] | Loss=0.00426 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.838 | L2-Norm(final)=12.772 | 5010.6 samples/s | 78.3 steps/s
[Step=40150 Epoch=195.8] | Loss=0.00397 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.838 | L2-Norm(final)=12.781 | 4995.3 samples/s | 78.1 steps/s
[Step=40200 Epoch=196.0] | Loss=0.00369 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.837 | L2-Norm(final)=12.789 | 7842.5 samples/s | 122.5 steps/s
[Step=40250 Epoch=196.3] | Loss=0.00360 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.837 | L2-Norm(final)=12.798 | 2193.6 samples/s | 34.3 steps/s
[Step=40300 Epoch=196.5] | Loss=0.00356 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.835 | L2-Norm(final)=12.806 | 5144.9 samples/s | 80.4 steps/s
[Step=40350 Epoch=196.8] | Loss=0.00342 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.834 | L2-Norm(final)=12.815 | 4944.1 samples/s | 77.3 steps/s
[Step=40400 Epoch=197.0] | Loss=0.00335 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.833 | L2-Norm(final)=12.823 | 6934.4 samples/s | 108.4 steps/s
[Step=40450 Epoch=197.3] | Loss=0.00319 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.831 | L2-Norm(final)=12.832 | 2280.2 samples/s | 35.6 steps/s
[Step=40500 Epoch=197.5] | Loss=0.00316 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.830 | L2-Norm(final)=12.841 | 4992.5 samples/s | 78.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=197.5] | Loss=0.00018 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.817 | L2-Norm(final)=12.927 | 5462.6 samples/s | 85.4 steps/s
[Step=40550 Epoch=197.7] | Loss=0.00337 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.815 | L2-Norm(final)=12.935 | 4009.3 samples/s | 62.6 steps/s
[Step=40600 Epoch=198.0] | Loss=0.00334 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.814 | L2-Norm(final)=12.940 | 4437.9 samples/s | 69.3 steps/s
[Step=40650 Epoch=198.2] | Loss=0.00299 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.812 | L2-Norm(final)=12.946 | 4503.2 samples/s | 70.4 steps/s
[Step=40700 Epoch=198.5] | Loss=0.00345 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.810 | L2-Norm(final)=12.951 | 6577.2 samples/s | 102.8 steps/s
[Step=40750 Epoch=198.7] | Loss=0.00330 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.808 | L2-Norm(final)=12.954 | 2068.3 samples/s | 32.3 steps/s
[Step=40800 Epoch=199.0] | Loss=0.00315 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.806 | L2-Norm(final)=12.959 | 4458.0 samples/s | 69.7 steps/s
[Step=40850 Epoch=199.2] | Loss=0.00325 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.803 | L2-Norm(final)=12.963 | 4480.9 samples/s | 70.0 steps/s
[Step=40900 Epoch=199.5] | Loss=0.00339 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.800 | L2-Norm(final)=12.966 | 5892.1 samples/s | 92.1 steps/s
[Step=40950 Epoch=199.7] | Loss=0.00337 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.797 | L2-Norm(final)=12.970 | 2209.3 samples/s | 34.5 steps/s
[Step=41000 Epoch=199.9] | Loss=0.00333 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.794 | L2-Norm(final)=12.973 | 4415.9 samples/s | 69.0 steps/s
[Step=41050 Epoch=200.2] | Loss=0.00335 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.790 | L2-Norm(final)=12.976 | 4536.2 samples/s | 70.9 steps/s
[Step=41100 Epoch=200.4] | Loss=0.00315 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.786 | L2-Norm(final)=12.979 | 5273.7 samples/s | 82.4 steps/s
[Step=41150 Epoch=200.7] | Loss=0.00306 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.782 | L2-Norm(final)=12.982 | 2203.0 samples/s | 34.4 steps/s
[Step=41200 Epoch=200.9] | Loss=0.00305 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.777 | L2-Norm(final)=12.985 | 4458.8 samples/s | 69.7 steps/s
[Step=41250 Epoch=201.2] | Loss=0.00298 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.772 | L2-Norm(final)=12.988 | 4476.4 samples/s | 69.9 steps/s
[Step=41300 Epoch=201.4] | Loss=0.00294 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.767 | L2-Norm(final)=12.991 | 4981.0 samples/s | 77.8 steps/s
[Step=41350 Epoch=201.6] | Loss=0.00288 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.761 | L2-Norm(final)=12.993 | 2325.9 samples/s | 36.3 steps/s
[Step=41400 Epoch=201.9] | Loss=0.00288 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.756 | L2-Norm(final)=12.996 | 4481.9 samples/s | 70.0 steps/s
[Step=41450 Epoch=202.1] | Loss=0.00286 | Reg=0.00352 | acc=1.0000 | L2-Norm=18.750 | L2-Norm(final)=12.998 | 4397.3 samples/s | 68.7 steps/s
[Step=41500 Epoch=202.4] | Loss=0.00281 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.745 | L2-Norm(final)=13.001 | 4583.8 samples/s | 71.6 steps/s
[Step=41550 Epoch=202.6] | Loss=0.00277 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.739 | L2-Norm(final)=13.003 | 2411.9 samples/s | 37.7 steps/s
[Step=41600 Epoch=202.9] | Loss=0.00273 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.733 | L2-Norm(final)=13.006 | 4467.9 samples/s | 69.8 steps/s
[Step=41650 Epoch=203.1] | Loss=0.00268 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.727 | L2-Norm(final)=13.009 | 4482.5 samples/s | 70.0 steps/s
[Step=41700 Epoch=203.4] | Loss=0.00264 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.720 | L2-Norm(final)=13.011 | 4500.1 samples/s | 70.3 steps/s
[Step=41750 Epoch=203.6] | Loss=0.00267 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.714 | L2-Norm(final)=13.013 | 2441.2 samples/s | 38.1 steps/s
[Step=41800 Epoch=203.8] | Loss=0.00263 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.707 | L2-Norm(final)=13.015 | 4389.7 samples/s | 68.6 steps/s
[Step=41850 Epoch=204.1] | Loss=0.00262 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.701 | L2-Norm(final)=13.017 | 4477.9 samples/s | 70.0 steps/s
[Step=41900 Epoch=204.3] | Loss=0.00256 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.694 | L2-Norm(final)=13.019 | 4441.2 samples/s | 69.4 steps/s
[Step=41950 Epoch=204.6] | Loss=0.00254 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.687 | L2-Norm(final)=13.022 | 2473.6 samples/s | 38.6 steps/s
[Step=42000 Epoch=204.8] | Loss=0.00250 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=13.024 | 4452.8 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step42000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=196.2] | Loss=0.00194 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.655 | L2-Norm(final)=12.767 | 5365.0 samples/s | 83.8 steps/s
[Step=40050 Epoch=196.4] | Loss=0.00428 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.657 | L2-Norm(final)=12.775 | 4480.9 samples/s | 70.0 steps/s
[Step=40100 Epoch=196.6] | Loss=0.00403 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.656 | L2-Norm(final)=12.785 | 4920.8 samples/s | 76.9 steps/s
[Step=40150 Epoch=196.9] | Loss=0.00361 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.655 | L2-Norm(final)=12.794 | 5067.7 samples/s | 79.2 steps/s
[Step=40200 Epoch=197.1] | Loss=0.00367 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.653 | L2-Norm(final)=12.803 | 7826.0 samples/s | 122.3 steps/s
[Step=40250 Epoch=197.4] | Loss=0.00353 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.652 | L2-Norm(final)=12.812 | 2171.4 samples/s | 33.9 steps/s
[Step=40300 Epoch=197.6] | Loss=0.00335 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.650 | L2-Norm(final)=12.821 | 5086.1 samples/s | 79.5 steps/s
[Step=40350 Epoch=197.9] | Loss=0.00334 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.648 | L2-Norm(final)=12.830 | 4981.4 samples/s | 77.8 steps/s
[Step=40400 Epoch=198.1] | Loss=0.00334 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.647 | L2-Norm(final)=12.839 | 7460.1 samples/s | 116.6 steps/s
[Step=40450 Epoch=198.4] | Loss=0.00328 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.645 | L2-Norm(final)=12.848 | 2254.9 samples/s | 35.2 steps/s
[Step=40500 Epoch=198.6] | Loss=0.00317 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.643 | L2-Norm(final)=12.856 | 5107.3 samples/s | 79.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=198.6] | Loss=0.00177 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.623 | L2-Norm(final)=12.944 | 5466.8 samples/s | 85.4 steps/s
[Step=40550 Epoch=198.9] | Loss=0.00222 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.622 | L2-Norm(final)=12.952 | 3999.9 samples/s | 62.5 steps/s
[Step=40600 Epoch=199.1] | Loss=0.00308 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.621 | L2-Norm(final)=12.958 | 4440.6 samples/s | 69.4 steps/s
[Step=40650 Epoch=199.3] | Loss=0.00303 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.619 | L2-Norm(final)=12.964 | 4547.3 samples/s | 71.1 steps/s
[Step=40700 Epoch=199.6] | Loss=0.00346 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.617 | L2-Norm(final)=12.970 | 6549.7 samples/s | 102.3 steps/s
[Step=40750 Epoch=199.8] | Loss=0.00338 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.615 | L2-Norm(final)=12.974 | 2057.3 samples/s | 32.1 steps/s
[Step=40800 Epoch=200.1] | Loss=0.00336 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.612 | L2-Norm(final)=12.977 | 4454.5 samples/s | 69.6 steps/s
[Step=40850 Epoch=200.3] | Loss=0.00361 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.609 | L2-Norm(final)=12.981 | 4403.9 samples/s | 68.8 steps/s
[Step=40900 Epoch=200.6] | Loss=0.00357 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.606 | L2-Norm(final)=12.985 | 6249.0 samples/s | 97.6 steps/s
[Step=40950 Epoch=200.8] | Loss=0.00346 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.603 | L2-Norm(final)=12.988 | 2144.5 samples/s | 33.5 steps/s
[Step=41000 Epoch=201.1] | Loss=0.00345 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.599 | L2-Norm(final)=12.991 | 4442.9 samples/s | 69.4 steps/s
[Step=41050 Epoch=201.3] | Loss=0.00346 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.596 | L2-Norm(final)=12.994 | 4498.8 samples/s | 70.3 steps/s
[Step=41100 Epoch=201.5] | Loss=0.00340 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.592 | L2-Norm(final)=12.997 | 5814.6 samples/s | 90.9 steps/s
[Step=41150 Epoch=201.8] | Loss=0.00331 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.588 | L2-Norm(final)=13.000 | 2189.3 samples/s | 34.2 steps/s
[Step=41200 Epoch=202.0] | Loss=0.00320 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.584 | L2-Norm(final)=13.003 | 4308.8 samples/s | 67.3 steps/s
[Step=41250 Epoch=202.3] | Loss=0.00318 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.579 | L2-Norm(final)=13.006 | 4422.9 samples/s | 69.1 steps/s
[Step=41300 Epoch=202.5] | Loss=0.00316 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.574 | L2-Norm(final)=13.009 | 5533.0 samples/s | 86.5 steps/s
[Step=41350 Epoch=202.8] | Loss=0.00309 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.569 | L2-Norm(final)=13.012 | 2221.6 samples/s | 34.7 steps/s
[Step=41400 Epoch=203.0] | Loss=0.00300 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.564 | L2-Norm(final)=13.015 | 4486.8 samples/s | 70.1 steps/s
[Step=41450 Epoch=203.3] | Loss=0.00296 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.558 | L2-Norm(final)=13.017 | 4474.8 samples/s | 69.9 steps/s
[Step=41500 Epoch=203.5] | Loss=0.00295 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.553 | L2-Norm(final)=13.020 | 5208.0 samples/s | 81.4 steps/s
[Step=41550 Epoch=203.8] | Loss=0.00288 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.547 | L2-Norm(final)=13.023 | 2262.3 samples/s | 35.3 steps/s
[Step=41600 Epoch=204.0] | Loss=0.00295 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.541 | L2-Norm(final)=13.025 | 4517.1 samples/s | 70.6 steps/s
[Step=41650 Epoch=204.2] | Loss=0.00291 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.535 | L2-Norm(final)=13.028 | 4474.0 samples/s | 69.9 steps/s
[Step=41700 Epoch=204.5] | Loss=0.00286 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.530 | L2-Norm(final)=13.030 | 4902.4 samples/s | 76.6 steps/s
[Step=41750 Epoch=204.7] | Loss=0.00284 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.524 | L2-Norm(final)=13.033 | 2350.4 samples/s | 36.7 steps/s
[Step=41800 Epoch=205.0] | Loss=0.00279 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.518 | L2-Norm(final)=13.035 | 4526.9 samples/s | 70.7 steps/s
[Step=41850 Epoch=205.2] | Loss=0.00275 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.512 | L2-Norm(final)=13.038 | 4360.7 samples/s | 68.1 steps/s
[Step=41900 Epoch=205.5] | Loss=0.00275 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.505 | L2-Norm(final)=13.040 | 4587.7 samples/s | 71.7 steps/s
[Step=41950 Epoch=205.7] | Loss=0.00272 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.499 | L2-Norm(final)=13.043 | 2414.6 samples/s | 37.7 steps/s
[Step=42000 Epoch=206.0] | Loss=0.00269 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.492 | L2-Norm(final)=13.045 | 4442.0 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step42000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=379.0] | Loss=0.00010 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.469 | L2-Norm(final)=7.026 | 5264.3 samples/s | 82.3 steps/s
[Step=40050 Epoch=379.5] | Loss=0.00010 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.467 | L2-Norm(final)=7.031 | 4253.0 samples/s | 66.5 steps/s
[Step=40100 Epoch=380.0] | Loss=0.00008 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.469 | L2-Norm(final)=7.037 | 7134.1 samples/s | 111.5 steps/s
[Step=40150 Epoch=380.5] | Loss=0.00007 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.471 | L2-Norm(final)=7.042 | 2109.6 samples/s | 33.0 steps/s
[Step=40200 Epoch=380.9] | Loss=0.00007 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=7.047 | 6484.2 samples/s | 101.3 steps/s
[Step=40250 Epoch=381.4] | Loss=0.00006 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.474 | L2-Norm(final)=7.053 | 2221.8 samples/s | 34.7 steps/s
[Step=40300 Epoch=381.9] | Loss=0.00006 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.476 | L2-Norm(final)=7.059 | 5773.0 samples/s | 90.2 steps/s
[Step=40350 Epoch=382.4] | Loss=0.00005 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=7.064 | 2331.0 samples/s | 36.4 steps/s
[Step=40400 Epoch=382.8] | Loss=0.00005 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.478 | L2-Norm(final)=7.069 | 5215.0 samples/s | 81.5 steps/s
[Step=40450 Epoch=383.3] | Loss=0.00005 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.480 | L2-Norm(final)=7.075 | 2426.9 samples/s | 37.9 steps/s
[Step=40500 Epoch=383.8] | Loss=0.00005 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.480 | L2-Norm(final)=7.080 | 4798.1 samples/s | 75.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=383.8] | Loss=0.00009 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.489 | L2-Norm(final)=7.132 | 5593.1 samples/s | 87.4 steps/s
[Step=40550 Epoch=384.2] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.467 | L2-Norm(final)=7.135 | 3554.6 samples/s | 55.5 steps/s
[Step=40600 Epoch=384.7] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.434 | L2-Norm(final)=7.137 | 6332.1 samples/s | 98.9 steps/s
[Step=40650 Epoch=385.2] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.401 | L2-Norm(final)=7.139 | 2013.5 samples/s | 31.5 steps/s
[Step=40700 Epoch=385.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.366 | L2-Norm(final)=7.140 | 5633.8 samples/s | 88.0 steps/s
[Step=40750 Epoch=386.1] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.331 | L2-Norm(final)=7.141 | 2084.2 samples/s | 32.6 steps/s
[Step=40800 Epoch=386.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.296 | L2-Norm(final)=7.141 | 5059.7 samples/s | 79.1 steps/s
[Step=40850 Epoch=387.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.261 | L2-Norm(final)=7.142 | 2141.3 samples/s | 33.5 steps/s
[Step=40900 Epoch=387.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.226 | L2-Norm(final)=7.142 | 4704.5 samples/s | 73.5 steps/s
[Step=40950 Epoch=388.0] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.190 | L2-Norm(final)=7.143 | 2258.0 samples/s | 35.3 steps/s
[Step=41000 Epoch=388.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=7.143 | 4391.2 samples/s | 68.6 steps/s
[Step=41050 Epoch=389.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.120 | L2-Norm(final)=7.144 | 2376.9 samples/s | 37.1 steps/s
[Step=41100 Epoch=389.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.144 | 4136.7 samples/s | 64.6 steps/s
[Step=41150 Epoch=389.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.049 | L2-Norm(final)=7.144 | 2442.8 samples/s | 38.2 steps/s
[Step=41200 Epoch=390.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.014 | L2-Norm(final)=7.145 | 4220.3 samples/s | 65.9 steps/s
[Step=41250 Epoch=390.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.979 | L2-Norm(final)=7.145 | 2351.3 samples/s | 36.7 steps/s
[Step=41300 Epoch=391.4] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=7.146 | 4243.4 samples/s | 66.3 steps/s
[Step=41350 Epoch=391.8] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.908 | L2-Norm(final)=7.146 | 2449.0 samples/s | 38.3 steps/s
[Step=41400 Epoch=392.3] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.872 | L2-Norm(final)=7.147 | 4027.1 samples/s | 62.9 steps/s
[Step=41450 Epoch=392.8] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.837 | L2-Norm(final)=7.147 | 6532.2 samples/s | 102.1 steps/s
[Step=41500 Epoch=393.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.801 | L2-Norm(final)=7.147 | 2025.7 samples/s | 31.7 steps/s
[Step=41550 Epoch=393.7] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.766 | L2-Norm(final)=7.148 | 5698.1 samples/s | 89.0 steps/s
[Step=41600 Epoch=394.2] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.730 | L2-Norm(final)=7.148 | 2046.8 samples/s | 32.0 steps/s
[Step=41650 Epoch=394.7] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.694 | L2-Norm(final)=7.149 | 5240.3 samples/s | 81.9 steps/s
[Step=41700 Epoch=395.1] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.658 | L2-Norm(final)=7.149 | 2105.2 samples/s | 32.9 steps/s
[Step=41750 Epoch=395.6] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.622 | L2-Norm(final)=7.150 | 4761.7 samples/s | 74.4 steps/s
[Step=41800 Epoch=396.1] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.587 | L2-Norm(final)=7.150 | 2244.7 samples/s | 35.1 steps/s
[Step=41850 Epoch=396.6] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.551 | L2-Norm(final)=7.151 | 4377.7 samples/s | 68.4 steps/s
[Step=41900 Epoch=397.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.515 | L2-Norm(final)=7.151 | 2337.6 samples/s | 36.5 steps/s
[Step=41950 Epoch=397.5] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.478 | L2-Norm(final)=7.152 | 4161.0 samples/s | 65.0 steps/s
[Step=42000 Epoch=398.0] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.442 | L2-Norm(final)=7.153 | 2380.6 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step42000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=380.5] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.847 | L2-Norm(final)=7.963 | 5339.0 samples/s | 83.4 steps/s
[Step=40050 Epoch=381.0] | Loss=0.00012 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.849 | L2-Norm(final)=7.965 | 4171.4 samples/s | 65.2 steps/s
[Step=40100 Epoch=381.5] | Loss=0.00010 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=7.968 | 7587.9 samples/s | 118.6 steps/s
[Step=40150 Epoch=381.9] | Loss=0.00008 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=7.970 | 2155.9 samples/s | 33.7 steps/s
[Step=40200 Epoch=382.4] | Loss=0.00007 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.851 | L2-Norm(final)=7.972 | 6414.4 samples/s | 100.2 steps/s
[Step=40250 Epoch=382.9] | Loss=0.00007 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.850 | L2-Norm(final)=7.974 | 2168.7 samples/s | 33.9 steps/s
[Step=40300 Epoch=383.4] | Loss=0.00007 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.850 | L2-Norm(final)=7.976 | 5881.4 samples/s | 91.9 steps/s
[Step=40350 Epoch=383.8] | Loss=0.00006 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.849 | L2-Norm(final)=7.978 | 2328.3 samples/s | 36.4 steps/s
[Step=40400 Epoch=384.3] | Loss=0.00006 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.848 | L2-Norm(final)=7.979 | 5199.6 samples/s | 81.2 steps/s
[Step=40450 Epoch=384.8] | Loss=0.00006 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.847 | L2-Norm(final)=7.981 | 2403.2 samples/s | 37.6 steps/s
[Step=40500 Epoch=385.3] | Loss=0.00006 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.846 | L2-Norm(final)=7.983 | 4849.8 samples/s | 75.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=385.3] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.837 | L2-Norm(final)=8.000 | 4765.6 samples/s | 74.5 steps/s
[Step=40550 Epoch=385.7] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.835 | L2-Norm(final)=8.001 | 4013.7 samples/s | 62.7 steps/s
[Step=40600 Epoch=386.2] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.831 | L2-Norm(final)=8.003 | 6368.9 samples/s | 99.5 steps/s
[Step=40650 Epoch=386.7] | Loss=0.00003 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.827 | L2-Norm(final)=8.004 | 2027.8 samples/s | 31.7 steps/s
[Step=40700 Epoch=387.2] | Loss=0.00002 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.824 | L2-Norm(final)=8.005 | 5681.8 samples/s | 88.8 steps/s
[Step=40750 Epoch=387.6] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.820 | L2-Norm(final)=8.006 | 2089.9 samples/s | 32.7 steps/s
[Step=40800 Epoch=388.1] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.816 | L2-Norm(final)=8.007 | 5101.7 samples/s | 79.7 steps/s
[Step=40850 Epoch=388.6] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=8.008 | 2151.9 samples/s | 33.6 steps/s
[Step=40900 Epoch=389.1] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.808 | L2-Norm(final)=8.009 | 4681.5 samples/s | 73.1 steps/s
[Step=40950 Epoch=389.5] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.804 | L2-Norm(final)=8.010 | 2244.6 samples/s | 35.1 steps/s
[Step=41000 Epoch=390.0] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.799 | L2-Norm(final)=8.010 | 4399.3 samples/s | 68.7 steps/s
[Step=41050 Epoch=390.5] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.795 | L2-Norm(final)=8.011 | 2358.9 samples/s | 36.9 steps/s
[Step=41100 Epoch=391.0] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.791 | L2-Norm(final)=8.012 | 4161.5 samples/s | 65.0 steps/s
[Step=41150 Epoch=391.4] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.786 | L2-Norm(final)=8.012 | 2396.7 samples/s | 37.4 steps/s
[Step=41200 Epoch=391.9] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.782 | L2-Norm(final)=8.013 | 4294.2 samples/s | 67.1 steps/s
[Step=41250 Epoch=392.4] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.778 | L2-Norm(final)=8.014 | 2348.2 samples/s | 36.7 steps/s
[Step=41300 Epoch=392.9] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.773 | L2-Norm(final)=8.014 | 4225.2 samples/s | 66.0 steps/s
[Step=41350 Epoch=393.3] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.768 | L2-Norm(final)=8.015 | 2476.5 samples/s | 38.7 steps/s
[Step=41400 Epoch=393.8] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.764 | L2-Norm(final)=8.015 | 4041.3 samples/s | 63.1 steps/s
[Step=41450 Epoch=394.3] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.759 | L2-Norm(final)=8.016 | 6543.9 samples/s | 102.2 steps/s
[Step=41500 Epoch=394.8] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.754 | L2-Norm(final)=8.017 | 2008.6 samples/s | 31.4 steps/s
[Step=41550 Epoch=395.2] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.749 | L2-Norm(final)=8.017 | 5873.3 samples/s | 91.8 steps/s
[Step=41600 Epoch=395.7] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.745 | L2-Norm(final)=8.018 | 2064.0 samples/s | 32.2 steps/s
[Step=41650 Epoch=396.2] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=8.018 | 5329.3 samples/s | 83.3 steps/s
[Step=41700 Epoch=396.7] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.735 | L2-Norm(final)=8.019 | 2131.9 samples/s | 33.3 steps/s
[Step=41750 Epoch=397.1] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.729 | L2-Norm(final)=8.019 | 4803.9 samples/s | 75.1 steps/s
[Step=41800 Epoch=397.6] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.724 | L2-Norm(final)=8.020 | 2220.4 samples/s | 34.7 steps/s
[Step=41850 Epoch=398.1] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.719 | L2-Norm(final)=8.020 | 4483.4 samples/s | 70.1 steps/s
[Step=41900 Epoch=398.6] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.714 | L2-Norm(final)=8.021 | 2326.1 samples/s | 36.3 steps/s
[Step=41950 Epoch=399.0] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.709 | L2-Norm(final)=8.022 | 4205.1 samples/s | 65.7 steps/s
[Step=42000 Epoch=399.5] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.703 | L2-Norm(final)=8.022 | 2316.8 samples/s | 36.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step42000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=382.0] | Loss=0.00040 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.633 | L2-Norm(final)=7.439 | 5294.7 samples/s | 82.7 steps/s
[Step=40050 Epoch=382.5] | Loss=0.00043 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.643 | L2-Norm(final)=7.444 | 4208.6 samples/s | 65.8 steps/s
[Step=40100 Epoch=382.9] | Loss=0.00028 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=7.447 | 7453.8 samples/s | 116.5 steps/s
[Step=40150 Epoch=383.4] | Loss=0.00021 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.650 | L2-Norm(final)=7.450 | 2109.0 samples/s | 33.0 steps/s
[Step=40200 Epoch=383.9] | Loss=0.00019 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.651 | L2-Norm(final)=7.453 | 6920.2 samples/s | 108.1 steps/s
[Step=40250 Epoch=384.4] | Loss=0.00017 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.652 | L2-Norm(final)=7.456 | 2149.0 samples/s | 33.6 steps/s
[Step=40300 Epoch=384.8] | Loss=0.00015 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.654 | L2-Norm(final)=7.458 | 6190.3 samples/s | 96.7 steps/s
[Step=40350 Epoch=385.3] | Loss=0.00014 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=7.461 | 2253.9 samples/s | 35.2 steps/s
[Step=40400 Epoch=385.8] | Loss=0.00013 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.656 | L2-Norm(final)=7.464 | 5662.7 samples/s | 88.5 steps/s
[Step=40450 Epoch=386.3] | Loss=0.00012 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.657 | L2-Norm(final)=7.467 | 2319.2 samples/s | 36.2 steps/s
[Step=40500 Epoch=386.8] | Loss=0.00012 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.657 | L2-Norm(final)=7.469 | 5306.1 samples/s | 82.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=386.8] | Loss=0.00010 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=7.496 | 5322.2 samples/s | 83.2 steps/s
[Step=40550 Epoch=387.2] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.664 | L2-Norm(final)=7.498 | 3663.3 samples/s | 57.2 steps/s
[Step=40600 Epoch=387.7] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.662 | L2-Norm(final)=7.500 | 6409.2 samples/s | 100.1 steps/s
[Step=40650 Epoch=388.2] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.660 | L2-Norm(final)=7.502 | 2003.4 samples/s | 31.3 steps/s
[Step=40700 Epoch=388.7] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.658 | L2-Norm(final)=7.503 | 5686.4 samples/s | 88.8 steps/s
[Step=40750 Epoch=389.1] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.656 | L2-Norm(final)=7.504 | 2056.9 samples/s | 32.1 steps/s
[Step=40800 Epoch=389.6] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.653 | L2-Norm(final)=7.505 | 5359.9 samples/s | 83.7 steps/s
[Step=40850 Epoch=390.1] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.650 | L2-Norm(final)=7.506 | 2115.9 samples/s | 33.1 steps/s
[Step=40900 Epoch=390.6] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=7.507 | 4998.1 samples/s | 78.1 steps/s
[Step=40950 Epoch=391.0] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.645 | L2-Norm(final)=7.507 | 2228.9 samples/s | 34.8 steps/s
[Step=41000 Epoch=391.5] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.642 | L2-Norm(final)=7.508 | 4516.6 samples/s | 70.6 steps/s
[Step=41050 Epoch=392.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.639 | L2-Norm(final)=7.509 | 2280.4 samples/s | 35.6 steps/s
[Step=41100 Epoch=392.5] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=7.509 | 4357.2 samples/s | 68.1 steps/s
[Step=41150 Epoch=393.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.632 | L2-Norm(final)=7.510 | 2296.2 samples/s | 35.9 steps/s
[Step=41200 Epoch=393.4] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.629 | L2-Norm(final)=7.511 | 4267.1 samples/s | 66.7 steps/s
[Step=41250 Epoch=393.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.626 | L2-Norm(final)=7.511 | 2390.7 samples/s | 37.4 steps/s
[Step=41300 Epoch=394.4] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.623 | L2-Norm(final)=7.512 | 4277.4 samples/s | 66.8 steps/s
[Step=41350 Epoch=394.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.619 | L2-Norm(final)=7.512 | 2391.5 samples/s | 37.4 steps/s
[Step=41400 Epoch=395.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.616 | L2-Norm(final)=7.513 | 4255.2 samples/s | 66.5 steps/s
[Step=41450 Epoch=395.8] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=7.513 | 2371.2 samples/s | 37.1 steps/s
[Step=41500 Epoch=396.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.609 | L2-Norm(final)=7.514 | 4256.4 samples/s | 66.5 steps/s
[Step=41550 Epoch=396.8] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.606 | L2-Norm(final)=7.514 | 7071.3 samples/s | 110.5 steps/s
[Step=41600 Epoch=397.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.602 | L2-Norm(final)=7.515 | 1964.3 samples/s | 30.7 steps/s
[Step=41650 Epoch=397.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.599 | L2-Norm(final)=7.515 | 6365.9 samples/s | 99.5 steps/s
[Step=41700 Epoch=398.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.595 | L2-Norm(final)=7.516 | 1984.8 samples/s | 31.0 steps/s
[Step=41750 Epoch=398.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.591 | L2-Norm(final)=7.516 | 5822.3 samples/s | 91.0 steps/s
[Step=41800 Epoch=399.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.588 | L2-Norm(final)=7.517 | 2051.8 samples/s | 32.1 steps/s
[Step=41850 Epoch=399.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.584 | L2-Norm(final)=7.517 | 5390.9 samples/s | 84.2 steps/s
[Step=41900 Epoch=400.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.580 | L2-Norm(final)=7.518 | 2140.5 samples/s | 33.4 steps/s
[Step=41950 Epoch=400.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.576 | L2-Norm(final)=7.518 | 4897.7 samples/s | 76.5 steps/s
[Step=42000 Epoch=401.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.572 | L2-Norm(final)=7.519 | 2215.5 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step42000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=376.9] | Loss=0.00021 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=7.333 | 5433.0 samples/s | 84.9 steps/s
[Step=40050 Epoch=377.4] | Loss=0.00041 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=7.335 | 4067.0 samples/s | 63.5 steps/s
[Step=40100 Epoch=377.9] | Loss=0.00037 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.654 | L2-Norm(final)=7.345 | 7128.0 samples/s | 111.4 steps/s
[Step=40150 Epoch=378.3] | Loss=0.00029 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.661 | L2-Norm(final)=7.354 | 2173.5 samples/s | 34.0 steps/s
[Step=40200 Epoch=378.8] | Loss=0.00026 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=7.361 | 6106.3 samples/s | 95.4 steps/s
[Step=40250 Epoch=379.3] | Loss=0.00023 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.669 | L2-Norm(final)=7.368 | 2235.7 samples/s | 34.9 steps/s
[Step=40300 Epoch=379.7] | Loss=0.00020 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.672 | L2-Norm(final)=7.374 | 5572.1 samples/s | 87.1 steps/s
[Step=40350 Epoch=380.2] | Loss=0.00019 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.675 | L2-Norm(final)=7.380 | 2317.1 samples/s | 36.2 steps/s
[Step=40400 Epoch=380.7] | Loss=0.00017 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.677 | L2-Norm(final)=7.386 | 5083.1 samples/s | 79.4 steps/s
[Step=40450 Epoch=381.2] | Loss=0.00016 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.679 | L2-Norm(final)=7.391 | 2472.6 samples/s | 38.6 steps/s
[Step=40500 Epoch=381.6] | Loss=0.00015 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.681 | L2-Norm(final)=7.396 | 4768.9 samples/s | 74.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=381.6] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.696 | L2-Norm(final)=7.447 | 5161.1 samples/s | 80.6 steps/s
[Step=40550 Epoch=382.1] | Loss=0.00008 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.696 | L2-Norm(final)=7.452 | 3772.5 samples/s | 58.9 steps/s
[Step=40600 Epoch=382.6] | Loss=0.00005 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.693 | L2-Norm(final)=7.455 | 6118.1 samples/s | 95.6 steps/s
[Step=40650 Epoch=383.0] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=7.458 | 2033.6 samples/s | 31.8 steps/s
[Step=40700 Epoch=383.5] | Loss=0.00003 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=7.460 | 5495.9 samples/s | 85.9 steps/s
[Step=40750 Epoch=384.0] | Loss=0.00003 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.678 | L2-Norm(final)=7.461 | 2118.2 samples/s | 33.1 steps/s
[Step=40800 Epoch=384.5] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.673 | L2-Norm(final)=7.463 | 4965.6 samples/s | 77.6 steps/s
[Step=40850 Epoch=384.9] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.667 | L2-Norm(final)=7.464 | 2197.3 samples/s | 34.3 steps/s
[Step=40900 Epoch=385.4] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.661 | L2-Norm(final)=7.465 | 4477.5 samples/s | 70.0 steps/s
[Step=40950 Epoch=385.9] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.654 | L2-Norm(final)=7.466 | 2317.8 samples/s | 36.2 steps/s
[Step=41000 Epoch=386.3] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=7.467 | 4228.5 samples/s | 66.1 steps/s
[Step=41050 Epoch=386.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=7.468 | 2411.5 samples/s | 37.7 steps/s
[Step=41100 Epoch=387.3] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=7.469 | 4242.6 samples/s | 66.3 steps/s
[Step=41150 Epoch=387.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.628 | L2-Norm(final)=7.470 | 2377.0 samples/s | 37.1 steps/s
[Step=41200 Epoch=388.2] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.621 | L2-Norm(final)=7.470 | 4184.6 samples/s | 65.4 steps/s
[Step=41250 Epoch=388.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.614 | L2-Norm(final)=7.471 | 2676.5 samples/s | 41.8 steps/s
[Step=41300 Epoch=389.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.607 | L2-Norm(final)=7.472 | 3790.8 samples/s | 59.2 steps/s
[Step=41350 Epoch=389.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.600 | L2-Norm(final)=7.473 | 6270.1 samples/s | 98.0 steps/s
[Step=41400 Epoch=390.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.592 | L2-Norm(final)=7.474 | 2022.3 samples/s | 31.6 steps/s
[Step=41450 Epoch=390.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.585 | L2-Norm(final)=7.474 | 5510.3 samples/s | 86.1 steps/s
[Step=41500 Epoch=391.0] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.578 | L2-Norm(final)=7.475 | 2051.9 samples/s | 32.1 steps/s
[Step=41550 Epoch=391.5] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.570 | L2-Norm(final)=7.476 | 4969.8 samples/s | 77.7 steps/s
[Step=41600 Epoch=392.0] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.562 | L2-Norm(final)=7.477 | 2196.1 samples/s | 34.3 steps/s
[Step=41650 Epoch=392.5] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.555 | L2-Norm(final)=7.477 | 4591.2 samples/s | 71.7 steps/s
[Step=41700 Epoch=392.9] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.547 | L2-Norm(final)=7.478 | 2298.0 samples/s | 35.9 steps/s
[Step=41750 Epoch=393.4] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.539 | L2-Norm(final)=7.479 | 4170.0 samples/s | 65.2 steps/s
[Step=41800 Epoch=393.9] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.531 | L2-Norm(final)=7.479 | 2405.4 samples/s | 37.6 steps/s
[Step=41850 Epoch=394.3] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.523 | L2-Norm(final)=7.480 | 4213.1 samples/s | 65.8 steps/s
[Step=41900 Epoch=394.8] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.514 | L2-Norm(final)=7.481 | 2395.3 samples/s | 37.4 steps/s
[Step=41950 Epoch=395.3] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.506 | L2-Norm(final)=7.482 | 4227.9 samples/s | 66.1 steps/s
[Step=42000 Epoch=395.8] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.497 | L2-Norm(final)=7.482 | 2518.4 samples/s | 39.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step42000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=381.2] | Loss=0.00091 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.800 | L2-Norm(final)=8.144 | 5648.7 samples/s | 88.3 steps/s
[Step=40050 Epoch=381.7] | Loss=0.00022 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.809 | L2-Norm(final)=8.147 | 4016.0 samples/s | 62.7 steps/s
[Step=40100 Epoch=382.2] | Loss=0.00016 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=8.149 | 7562.9 samples/s | 118.2 steps/s
[Step=40150 Epoch=382.7] | Loss=0.00013 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.813 | L2-Norm(final)=8.151 | 2139.6 samples/s | 33.4 steps/s
[Step=40200 Epoch=383.1] | Loss=0.00012 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.153 | 6794.0 samples/s | 106.2 steps/s
[Step=40250 Epoch=383.6] | Loss=0.00011 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.155 | 2181.6 samples/s | 34.1 steps/s
[Step=40300 Epoch=384.1] | Loss=0.00010 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.157 | 6206.8 samples/s | 97.0 steps/s
[Step=40350 Epoch=384.6] | Loss=0.00009 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.159 | 2240.9 samples/s | 35.0 steps/s
[Step=40400 Epoch=385.0] | Loss=0.00009 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.160 | 5513.0 samples/s | 86.1 steps/s
[Step=40450 Epoch=385.5] | Loss=0.00008 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.162 | 2343.6 samples/s | 36.6 steps/s
[Step=40500 Epoch=386.0] | Loss=0.00008 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.164 | 5268.0 samples/s | 82.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=386.0] | Loss=0.00012 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.814 | L2-Norm(final)=8.180 | 5555.9 samples/s | 86.8 steps/s
[Step=40550 Epoch=386.5] | Loss=0.00004 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.813 | L2-Norm(final)=8.182 | 3643.1 samples/s | 56.9 steps/s
[Step=40600 Epoch=387.0] | Loss=0.00004 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.811 | L2-Norm(final)=8.183 | 6338.8 samples/s | 99.0 steps/s
[Step=40650 Epoch=387.4] | Loss=0.00003 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.808 | L2-Norm(final)=8.184 | 1976.8 samples/s | 30.9 steps/s
[Step=40700 Epoch=387.9] | Loss=0.00003 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.805 | L2-Norm(final)=8.185 | 5811.5 samples/s | 90.8 steps/s
[Step=40750 Epoch=388.4] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.802 | L2-Norm(final)=8.186 | 2057.8 samples/s | 32.2 steps/s
[Step=40800 Epoch=388.9] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.799 | L2-Norm(final)=8.187 | 5266.6 samples/s | 82.3 steps/s
[Step=40850 Epoch=389.3] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.796 | L2-Norm(final)=8.187 | 2128.4 samples/s | 33.3 steps/s
[Step=40900 Epoch=389.8] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.793 | L2-Norm(final)=8.188 | 4814.4 samples/s | 75.2 steps/s
[Step=40950 Epoch=390.3] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.790 | L2-Norm(final)=8.189 | 2206.1 samples/s | 34.5 steps/s
[Step=41000 Epoch=390.8] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.786 | L2-Norm(final)=8.189 | 4510.9 samples/s | 70.5 steps/s
[Step=41050 Epoch=391.2] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.783 | L2-Norm(final)=8.190 | 2272.3 samples/s | 35.5 steps/s
[Step=41100 Epoch=391.7] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.780 | L2-Norm(final)=8.191 | 4336.4 samples/s | 67.8 steps/s
[Step=41150 Epoch=392.2] | Loss=0.00002 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.776 | L2-Norm(final)=8.191 | 2329.3 samples/s | 36.4 steps/s
[Step=41200 Epoch=392.7] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.772 | L2-Norm(final)=8.192 | 4206.7 samples/s | 65.7 steps/s
[Step=41250 Epoch=393.1] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=8.192 | 2412.4 samples/s | 37.7 steps/s
[Step=41300 Epoch=393.6] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.765 | L2-Norm(final)=8.193 | 4334.3 samples/s | 67.7 steps/s
[Step=41350 Epoch=394.1] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=8.193 | 2367.4 samples/s | 37.0 steps/s
[Step=41400 Epoch=394.6] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.757 | L2-Norm(final)=8.194 | 4277.4 samples/s | 66.8 steps/s
[Step=41450 Epoch=395.1] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.753 | L2-Norm(final)=8.194 | 2327.3 samples/s | 36.4 steps/s
[Step=41500 Epoch=395.5] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.749 | L2-Norm(final)=8.195 | 4290.2 samples/s | 67.0 steps/s
[Step=41550 Epoch=396.0] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.745 | L2-Norm(final)=8.195 | 6955.3 samples/s | 108.7 steps/s
[Step=41600 Epoch=396.5] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.741 | L2-Norm(final)=8.196 | 1944.5 samples/s | 30.4 steps/s
[Step=41650 Epoch=397.0] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.737 | L2-Norm(final)=8.196 | 6387.8 samples/s | 99.8 steps/s
[Step=41700 Epoch=397.4] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.733 | L2-Norm(final)=8.197 | 2021.0 samples/s | 31.6 steps/s
[Step=41750 Epoch=397.9] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.729 | L2-Norm(final)=8.197 | 5819.0 samples/s | 90.9 steps/s
[Step=41800 Epoch=398.4] | Loss=0.00001 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.724 | L2-Norm(final)=8.198 | 2048.9 samples/s | 32.0 steps/s
[Step=41850 Epoch=398.9] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.720 | L2-Norm(final)=8.198 | 5370.5 samples/s | 83.9 steps/s
[Step=41900 Epoch=399.3] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.716 | L2-Norm(final)=8.198 | 2145.2 samples/s | 33.5 steps/s
[Step=41950 Epoch=399.8] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.711 | L2-Norm(final)=8.199 | 4965.8 samples/s | 77.6 steps/s
[Step=42000 Epoch=400.3] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.706 | L2-Norm(final)=8.199 | 2221.5 samples/s | 34.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10714 | acc=0.9609 | tpr=0.9766 | fpr=0.0731 | 4780.6 samples/s | 18.7 steps/s
Avg test loss: 0.11261, Avg test acc: 0.95881, Avg tpr: 0.97604, Avg fpr: 0.07909, total FA: 617

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10623 | acc=0.9595 | tpr=0.9715 | fpr=0.0667 | 4920.6 samples/s | 19.2 steps/s
Avg test loss: 0.10998, Avg test acc: 0.95789, Avg tpr: 0.96917, Avg fpr: 0.06691, total FA: 522

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10432 | acc=0.9609 | tpr=0.9754 | fpr=0.0706 | 4681.1 samples/s | 18.3 steps/s
Avg test loss: 0.10927, Avg test acc: 0.95953, Avg tpr: 0.97400, Avg fpr: 0.07230, total FA: 564

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.11276 | acc=0.9624 | tpr=0.9760 | fpr=0.0671 | 4821.8 samples/s | 18.8 steps/s
Avg test loss: 0.11984, Avg test acc: 0.96134, Avg tpr: 0.97558, Avg fpr: 0.06999, total FA: 546

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10500 | acc=0.9612 | tpr=0.9731 | fpr=0.0647 | 4567.5 samples/s | 17.8 steps/s
Avg test loss: 0.11364, Avg test acc: 0.96025, Avg tpr: 0.97284, Avg fpr: 0.06743, total FA: 526

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.25771 | acc=0.3014 | tpr=0.0078 | fpr=0.0610 | 4730.3 samples/s | 18.5 steps/s
Avg test loss: 5.26359, Avg test acc: 0.30083, Avg tpr: 0.00968, Avg fpr: 0.05884, total FA: 459

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.03975 | acc=0.2848 | tpr=0.0151 | fpr=0.1296 | 4844.5 samples/s | 18.9 steps/s
Avg test loss: 5.05384, Avg test acc: 0.28215, Avg tpr: 0.01533, Avg fpr: 0.13101, total FA: 1022

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.50344 | acc=0.2678 | tpr=0.0240 | fpr=0.2027 | 4810.1 samples/s | 18.8 steps/s
Avg test loss: 5.50413, Avg test acc: 0.26621, Avg tpr: 0.02401, Avg fpr: 0.20113, total FA: 1569

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.67711 | acc=0.2862 | tpr=0.0216 | fpr=0.1392 | 4690.3 samples/s | 18.3 steps/s
Avg test loss: 5.66532, Avg test acc: 0.28476, Avg tpr: 0.02314, Avg fpr: 0.13985, total FA: 1091

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.48471 | acc=0.2912 | tpr=0.0209 | fpr=0.1219 | 4750.9 samples/s | 18.6 steps/s
Avg test loss: 5.49796, Avg test acc: 0.28965, Avg tpr: 0.02215, Avg fpr: 0.12204, total FA: 952

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.13750 | acc=0.0812 | tpr=0.6327 | fpr=0.9287 | 4790.4 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.11051 | acc=0.0819 | tpr=0.6013 | fpr=0.9278 | 7226.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.12804 | acc=0.0831 | tpr=0.6037 | fpr=0.9265 | 7470.3 samples/s | 29.2 steps/s
[Step= 200] | Loss=6.12637 | acc=0.0827 | tpr=0.5989 | fpr=0.9267 | 7750.1 samples/s | 30.3 steps/s
[Step= 250] | Loss=6.13253 | acc=0.0830 | tpr=0.5991 | fpr=0.9264 | 8058.9 samples/s | 31.5 steps/s
[Step= 300] | Loss=6.12870 | acc=0.0834 | tpr=0.6058 | fpr=0.9261 | 7885.2 samples/s | 30.8 steps/s
[Step= 350] | Loss=6.12674 | acc=0.0839 | tpr=0.6093 | fpr=0.9256 | 7877.1 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.12100 | acc=0.0845 | tpr=0.6116 | fpr=0.9251 | 8064.6 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.12571 | acc=0.0845 | tpr=0.6095 | fpr=0.9251 | 7819.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.13133 | acc=0.0842 | tpr=0.6066 | fpr=0.9252 | 7800.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.13290 | acc=0.0841 | tpr=0.6033 | fpr=0.9253 | 13937.2 samples/s | 54.4 steps/s
Avg test loss: 6.13428, Avg test acc: 0.08409, Avg tpr: 0.60380, Avg fpr: 0.92536, total FA: 128484

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.20894 | acc=0.0926 | tpr=0.6195 | fpr=0.9169 | 4961.2 samples/s | 19.4 steps/s
[Step= 100] | Loss=5.19198 | acc=0.0940 | tpr=0.6098 | fpr=0.9156 | 6946.0 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.19006 | acc=0.0942 | tpr=0.6023 | fpr=0.9152 | 7502.3 samples/s | 29.3 steps/s
[Step= 200] | Loss=5.18834 | acc=0.0949 | tpr=0.5978 | fpr=0.9142 | 8115.8 samples/s | 31.7 steps/s
[Step= 250] | Loss=5.19867 | acc=0.0950 | tpr=0.5878 | fpr=0.9140 | 7655.0 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.19286 | acc=0.0950 | tpr=0.5891 | fpr=0.9140 | 7720.3 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.18672 | acc=0.0953 | tpr=0.5917 | fpr=0.9137 | 8216.3 samples/s | 32.1 steps/s
[Step= 400] | Loss=5.18369 | acc=0.0959 | tpr=0.5842 | fpr=0.9130 | 7873.9 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.18629 | acc=0.0954 | tpr=0.5808 | fpr=0.9134 | 7857.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.18813 | acc=0.0950 | tpr=0.5828 | fpr=0.9138 | 7572.6 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.18971 | acc=0.0950 | tpr=0.5790 | fpr=0.9138 | 14442.2 samples/s | 56.4 steps/s
Avg test loss: 5.19218, Avg test acc: 0.09489, Avg tpr: 0.57884, Avg fpr: 0.91391, total FA: 126894

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.13866 | acc=0.0813 | tpr=0.4735 | fpr=0.9258 | 4794.3 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.10517 | acc=0.0833 | tpr=0.4627 | fpr=0.9238 | 7159.8 samples/s | 28.0 steps/s
[Step= 150] | Loss=6.11629 | acc=0.0840 | tpr=0.4654 | fpr=0.9230 | 7658.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=6.11654 | acc=0.0837 | tpr=0.4612 | fpr=0.9232 | 8143.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=6.11650 | acc=0.0840 | tpr=0.4594 | fpr=0.9228 | 7683.5 samples/s | 30.0 steps/s
[Step= 300] | Loss=6.11410 | acc=0.0840 | tpr=0.4662 | fpr=0.9230 | 7917.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.10667 | acc=0.0845 | tpr=0.4671 | fpr=0.9225 | 7944.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=6.10229 | acc=0.0849 | tpr=0.4666 | fpr=0.9220 | 8087.8 samples/s | 31.6 steps/s
[Step= 450] | Loss=6.10355 | acc=0.0851 | tpr=0.4640 | fpr=0.9218 | 7616.3 samples/s | 29.8 steps/s
[Step= 500] | Loss=6.10814 | acc=0.0848 | tpr=0.4639 | fpr=0.9221 | 7890.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.11046 | acc=0.0847 | tpr=0.4588 | fpr=0.9221 | 13789.7 samples/s | 53.9 steps/s
Avg test loss: 6.11208, Avg test acc: 0.08457, Avg tpr: 0.45959, Avg fpr: 0.92225, total FA: 128052

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.19300 | acc=0.1084 | tpr=0.6372 | fpr=0.9011 | 4815.9 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.18211 | acc=0.1071 | tpr=0.6375 | fpr=0.9028 | 6924.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.19578 | acc=0.1067 | tpr=0.6354 | fpr=0.9030 | 7543.5 samples/s | 29.5 steps/s
[Step= 200] | Loss=6.18574 | acc=0.1059 | tpr=0.6273 | fpr=0.9036 | 8104.8 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.19468 | acc=0.1062 | tpr=0.6245 | fpr=0.9032 | 7770.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.18965 | acc=0.1061 | tpr=0.6233 | fpr=0.9033 | 7662.5 samples/s | 29.9 steps/s
[Step= 350] | Loss=6.18315 | acc=0.1067 | tpr=0.6255 | fpr=0.9027 | 8433.3 samples/s | 32.9 steps/s
[Step= 400] | Loss=6.17424 | acc=0.1073 | tpr=0.6247 | fpr=0.9021 | 7898.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=6.17973 | acc=0.1072 | tpr=0.6227 | fpr=0.9022 | 7634.5 samples/s | 29.8 steps/s
[Step= 500] | Loss=6.18280 | acc=0.1070 | tpr=0.6216 | fpr=0.9023 | 7925.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=6.18682 | acc=0.1070 | tpr=0.6212 | fpr=0.9024 | 13736.5 samples/s | 53.7 steps/s
Avg test loss: 6.18738, Avg test acc: 0.10686, Avg tpr: 0.62163, Avg fpr: 0.90250, total FA: 125310

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.18918 | acc=0.1015 | tpr=0.5398 | fpr=0.9064 | 4681.6 samples/s | 18.3 steps/s
[Step= 100] | Loss=6.16886 | acc=0.1036 | tpr=0.5373 | fpr=0.9045 | 7292.2 samples/s | 28.5 steps/s
[Step= 150] | Loss=6.17390 | acc=0.1037 | tpr=0.5303 | fpr=0.9041 | 7986.8 samples/s | 31.2 steps/s
[Step= 200] | Loss=6.17443 | acc=0.1028 | tpr=0.5093 | fpr=0.9046 | 7486.8 samples/s | 29.2 steps/s
[Step= 250] | Loss=6.18418 | acc=0.1030 | tpr=0.5109 | fpr=0.9044 | 8037.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=6.18498 | acc=0.1028 | tpr=0.5164 | fpr=0.9048 | 8041.6 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.17826 | acc=0.1028 | tpr=0.5191 | fpr=0.9048 | 7624.3 samples/s | 29.8 steps/s
[Step= 400] | Loss=6.17349 | acc=0.1031 | tpr=0.5219 | fpr=0.9046 | 8240.3 samples/s | 32.2 steps/s
[Step= 450] | Loss=6.17630 | acc=0.1031 | tpr=0.5239 | fpr=0.9045 | 7500.2 samples/s | 29.3 steps/s
[Step= 500] | Loss=6.17907 | acc=0.1029 | tpr=0.5220 | fpr=0.9046 | 8077.9 samples/s | 31.6 steps/s
[Step= 550] | Loss=6.18157 | acc=0.1029 | tpr=0.5269 | fpr=0.9048 | 14193.5 samples/s | 55.4 steps/s
Avg test loss: 6.18347, Avg test acc: 0.10284, Avg tpr: 0.52655, Avg fpr: 0.90486, total FA: 125638

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09125 | acc=0.9823 | tpr=0.9469 | fpr=0.0171 | 4526.1 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.09410 | acc=0.9823 | tpr=0.9552 | fpr=0.0172 | 7580.4 samples/s | 29.6 steps/s
[Step= 150] | Loss=0.09772 | acc=0.9816 | tpr=0.9553 | fpr=0.0179 | 7969.2 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09955 | acc=0.9815 | tpr=0.9596 | fpr=0.0181 | 7899.4 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.09805 | acc=0.9818 | tpr=0.9546 | fpr=0.0177 | 7639.0 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.10052 | acc=0.9813 | tpr=0.9520 | fpr=0.0182 | 8075.7 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.10159 | acc=0.9810 | tpr=0.9524 | fpr=0.0185 | 7844.8 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.10274 | acc=0.9806 | tpr=0.9469 | fpr=0.0187 | 7569.4 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.10480 | acc=0.9803 | tpr=0.9450 | fpr=0.0190 | 8154.0 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.10405 | acc=0.9805 | tpr=0.9454 | fpr=0.0189 | 8049.2 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.10365 | acc=0.9806 | tpr=0.9439 | fpr=0.0187 | 13681.6 samples/s | 53.4 steps/s
Avg test loss: 0.10355, Avg test acc: 0.98060, Avg tpr: 0.94414, Avg fpr: 0.01873, total FA: 2601

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10377 | acc=0.9823 | tpr=0.9336 | fpr=0.0168 | 4670.4 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.10728 | acc=0.9820 | tpr=0.9275 | fpr=0.0170 | 7331.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.11111 | acc=0.9812 | tpr=0.9236 | fpr=0.0177 | 7889.5 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.11335 | acc=0.9810 | tpr=0.9257 | fpr=0.0180 | 7950.2 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.11132 | acc=0.9813 | tpr=0.9258 | fpr=0.0177 | 7794.5 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11446 | acc=0.9809 | tpr=0.9207 | fpr=0.0180 | 7512.7 samples/s | 29.3 steps/s
[Step= 350] | Loss=0.11524 | acc=0.9807 | tpr=0.9236 | fpr=0.0182 | 8149.2 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.11646 | acc=0.9805 | tpr=0.9163 | fpr=0.0184 | 7889.2 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11897 | acc=0.9802 | tpr=0.9153 | fpr=0.0186 | 7857.5 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.11783 | acc=0.9804 | tpr=0.9167 | fpr=0.0185 | 7718.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.11752 | acc=0.9805 | tpr=0.9164 | fpr=0.0183 | 14313.1 samples/s | 55.9 steps/s
Avg test loss: 0.11739, Avg test acc: 0.98054, Avg tpr: 0.91680, Avg fpr: 0.01830, total FA: 2541

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10105 | acc=0.9787 | tpr=0.9513 | fpr=0.0208 | 4850.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.10495 | acc=0.9790 | tpr=0.9488 | fpr=0.0204 | 7099.3 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.10936 | acc=0.9785 | tpr=0.9510 | fpr=0.0210 | 7635.7 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.11120 | acc=0.9787 | tpr=0.9541 | fpr=0.0208 | 7621.3 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.10974 | acc=0.9791 | tpr=0.9555 | fpr=0.0205 | 8210.6 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.11282 | acc=0.9788 | tpr=0.9484 | fpr=0.0207 | 7571.8 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.11344 | acc=0.9786 | tpr=0.9487 | fpr=0.0208 | 7978.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.11454 | acc=0.9784 | tpr=0.9469 | fpr=0.0210 | 7863.9 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.11642 | acc=0.9783 | tpr=0.9469 | fpr=0.0212 | 7789.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.11567 | acc=0.9784 | tpr=0.9489 | fpr=0.0211 | 8172.7 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.11520 | acc=0.9785 | tpr=0.9475 | fpr=0.0210 | 13330.4 samples/s | 52.1 steps/s
Avg test loss: 0.11510, Avg test acc: 0.97848, Avg tpr: 0.94770, Avg fpr: 0.02096, total FA: 2910

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10180 | acc=0.9813 | tpr=0.9469 | fpr=0.0181 | 4584.2 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.10696 | acc=0.9812 | tpr=0.9403 | fpr=0.0181 | 7390.7 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.11197 | acc=0.9801 | tpr=0.9380 | fpr=0.0191 | 8351.2 samples/s | 32.6 steps/s
[Step= 200] | Loss=0.11350 | acc=0.9802 | tpr=0.9443 | fpr=0.0191 | 7406.2 samples/s | 28.9 steps/s
[Step= 250] | Loss=0.11171 | acc=0.9805 | tpr=0.9441 | fpr=0.0189 | 7993.7 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.11456 | acc=0.9801 | tpr=0.9382 | fpr=0.0192 | 7690.0 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.11509 | acc=0.9800 | tpr=0.9393 | fpr=0.0192 | 8026.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.11549 | acc=0.9799 | tpr=0.9354 | fpr=0.0193 | 7912.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.11773 | acc=0.9796 | tpr=0.9323 | fpr=0.0195 | 7884.1 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.11681 | acc=0.9798 | tpr=0.9348 | fpr=0.0194 | 8019.5 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.11649 | acc=0.9799 | tpr=0.9343 | fpr=0.0192 | 13600.4 samples/s | 53.1 steps/s
Avg test loss: 0.11639, Avg test acc: 0.97994, Avg tpr: 0.93463, Avg fpr: 0.01924, total FA: 2671

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.11052 | acc=0.9812 | tpr=0.9381 | fpr=0.0180 | 4661.6 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.11519 | acc=0.9804 | tpr=0.9318 | fpr=0.0187 | 7388.6 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.11960 | acc=0.9791 | tpr=0.9323 | fpr=0.0200 | 7808.7 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.12154 | acc=0.9791 | tpr=0.9377 | fpr=0.0202 | 7842.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.12006 | acc=0.9794 | tpr=0.9336 | fpr=0.0198 | 8161.7 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.12294 | acc=0.9791 | tpr=0.9287 | fpr=0.0200 | 8068.3 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.12360 | acc=0.9790 | tpr=0.9311 | fpr=0.0201 | 7473.7 samples/s | 29.2 steps/s
[Step= 400] | Loss=0.12485 | acc=0.9788 | tpr=0.9261 | fpr=0.0203 | 7832.4 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.12753 | acc=0.9785 | tpr=0.9250 | fpr=0.0206 | 7963.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12652 | acc=0.9786 | tpr=0.9247 | fpr=0.0204 | 7832.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.12614 | acc=0.9788 | tpr=0.9232 | fpr=0.0202 | 14036.8 samples/s | 54.8 steps/s
Avg test loss: 0.12596, Avg test acc: 0.97878, Avg tpr: 0.92314, Avg fpr: 0.02021, total FA: 2806

server round 21/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=204.8] | Loss=0.00577 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.230 | L2-Norm(final)=12.627 | 5083.1 samples/s | 79.4 steps/s
[Step=42050 Epoch=205.0] | Loss=0.00311 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.227 | L2-Norm(final)=12.633 | 4797.9 samples/s | 75.0 steps/s
[Step=42100 Epoch=205.3] | Loss=0.00294 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.224 | L2-Norm(final)=12.640 | 4768.8 samples/s | 74.5 steps/s
[Step=42150 Epoch=205.5] | Loss=0.00294 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.220 | L2-Norm(final)=12.647 | 5095.0 samples/s | 79.6 steps/s
[Step=42200 Epoch=205.8] | Loss=0.00286 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.216 | L2-Norm(final)=12.653 | 7814.9 samples/s | 122.1 steps/s
[Step=42250 Epoch=206.0] | Loss=0.00274 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.212 | L2-Norm(final)=12.660 | 2216.9 samples/s | 34.6 steps/s
[Step=42300 Epoch=206.3] | Loss=0.00274 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.207 | L2-Norm(final)=12.666 | 4966.8 samples/s | 77.6 steps/s
[Step=42350 Epoch=206.5] | Loss=0.00275 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.202 | L2-Norm(final)=12.673 | 5161.1 samples/s | 80.6 steps/s
[Step=42400 Epoch=206.8] | Loss=0.00269 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.197 | L2-Norm(final)=12.680 | 6724.2 samples/s | 105.1 steps/s
[Step=42450 Epoch=207.0] | Loss=0.00257 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.193 | L2-Norm(final)=12.687 | 2236.3 samples/s | 34.9 steps/s
[Step=42500 Epoch=207.2] | Loss=0.00257 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.188 | L2-Norm(final)=12.694 | 5010.2 samples/s | 78.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=207.2] | Loss=0.00196 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.136 | L2-Norm(final)=12.765 | 5229.1 samples/s | 81.7 steps/s
[Step=42550 Epoch=207.5] | Loss=0.00364 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.131 | L2-Norm(final)=12.770 | 4113.9 samples/s | 64.3 steps/s
[Step=42600 Epoch=207.7] | Loss=0.00353 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.129 | L2-Norm(final)=12.774 | 4478.2 samples/s | 70.0 steps/s
[Step=42650 Epoch=208.0] | Loss=0.00399 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.128 | L2-Norm(final)=12.778 | 4463.9 samples/s | 69.7 steps/s
[Step=42700 Epoch=208.2] | Loss=0.00457 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.127 | L2-Norm(final)=12.783 | 6600.1 samples/s | 103.1 steps/s
[Step=42750 Epoch=208.5] | Loss=0.00451 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.126 | L2-Norm(final)=12.788 | 2068.1 samples/s | 32.3 steps/s
[Step=42800 Epoch=208.7] | Loss=0.00486 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.123 | L2-Norm(final)=12.792 | 4481.5 samples/s | 70.0 steps/s
[Step=42850 Epoch=208.9] | Loss=0.00484 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.122 | L2-Norm(final)=12.795 | 4496.6 samples/s | 70.3 steps/s
[Step=42900 Epoch=209.2] | Loss=0.00468 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.120 | L2-Norm(final)=12.800 | 5868.0 samples/s | 91.7 steps/s
[Step=42950 Epoch=209.4] | Loss=0.00473 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.119 | L2-Norm(final)=12.804 | 2184.2 samples/s | 34.1 steps/s
[Step=43000 Epoch=209.7] | Loss=0.00469 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.116 | L2-Norm(final)=12.808 | 4452.6 samples/s | 69.6 steps/s
[Step=43050 Epoch=209.9] | Loss=0.00457 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.114 | L2-Norm(final)=12.812 | 4470.0 samples/s | 69.8 steps/s
[Step=43100 Epoch=210.2] | Loss=0.00446 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.111 | L2-Norm(final)=12.816 | 5363.4 samples/s | 83.8 steps/s
[Step=43150 Epoch=210.4] | Loss=0.00445 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.108 | L2-Norm(final)=12.820 | 2231.4 samples/s | 34.9 steps/s
[Step=43200 Epoch=210.7] | Loss=0.00431 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.104 | L2-Norm(final)=12.823 | 4453.4 samples/s | 69.6 steps/s
[Step=43250 Epoch=210.9] | Loss=0.00426 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.100 | L2-Norm(final)=12.827 | 4469.2 samples/s | 69.8 steps/s
[Step=43300 Epoch=211.1] | Loss=0.00417 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.096 | L2-Norm(final)=12.831 | 4952.0 samples/s | 77.4 steps/s
[Step=43350 Epoch=211.4] | Loss=0.00409 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.091 | L2-Norm(final)=12.834 | 2356.2 samples/s | 36.8 steps/s
[Step=43400 Epoch=211.6] | Loss=0.00403 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.086 | L2-Norm(final)=12.837 | 4461.9 samples/s | 69.7 steps/s
[Step=43450 Epoch=211.9] | Loss=0.00394 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.081 | L2-Norm(final)=12.840 | 4393.1 samples/s | 68.6 steps/s
[Step=43500 Epoch=212.1] | Loss=0.00391 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.076 | L2-Norm(final)=12.844 | 4565.6 samples/s | 71.3 steps/s
[Step=43550 Epoch=212.4] | Loss=0.00389 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.070 | L2-Norm(final)=12.847 | 2426.5 samples/s | 37.9 steps/s
[Step=43600 Epoch=212.6] | Loss=0.00391 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.064 | L2-Norm(final)=12.849 | 4461.1 samples/s | 69.7 steps/s
[Step=43650 Epoch=212.8] | Loss=0.00386 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.058 | L2-Norm(final)=12.852 | 4582.2 samples/s | 71.6 steps/s
[Step=43700 Epoch=213.1] | Loss=0.00382 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.052 | L2-Norm(final)=12.855 | 4424.1 samples/s | 69.1 steps/s
[Step=43750 Epoch=213.3] | Loss=0.00372 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.046 | L2-Norm(final)=12.857 | 2451.2 samples/s | 38.3 steps/s
[Step=43800 Epoch=213.6] | Loss=0.00364 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.040 | L2-Norm(final)=12.860 | 4347.8 samples/s | 67.9 steps/s
[Step=43850 Epoch=213.8] | Loss=0.00360 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.033 | L2-Norm(final)=12.863 | 4552.5 samples/s | 71.1 steps/s
[Step=43900 Epoch=214.1] | Loss=0.00357 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.027 | L2-Norm(final)=12.865 | 4397.1 samples/s | 68.7 steps/s
[Step=43950 Epoch=214.3] | Loss=0.00355 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.020 | L2-Norm(final)=12.868 | 2504.2 samples/s | 39.1 steps/s
[Step=44000 Epoch=214.6] | Loss=0.00352 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.013 | L2-Norm(final)=12.870 | 4504.2 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step44000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=204.9] | Loss=0.00038 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.159 | L2-Norm(final)=12.829 | 5494.7 samples/s | 85.9 steps/s
[Step=42050 Epoch=205.2] | Loss=0.00224 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.155 | L2-Norm(final)=12.834 | 4266.1 samples/s | 66.7 steps/s
[Step=42100 Epoch=205.4] | Loss=0.00241 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.150 | L2-Norm(final)=12.841 | 4926.1 samples/s | 77.0 steps/s
[Step=42150 Epoch=205.7] | Loss=0.00257 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.145 | L2-Norm(final)=12.848 | 5102.7 samples/s | 79.7 steps/s
[Step=42200 Epoch=205.9] | Loss=0.00260 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.140 | L2-Norm(final)=12.855 | 7702.5 samples/s | 120.4 steps/s
[Step=42250 Epoch=206.2] | Loss=0.00250 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.136 | L2-Norm(final)=12.862 | 2218.7 samples/s | 34.7 steps/s
[Step=42300 Epoch=206.4] | Loss=0.00262 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.131 | L2-Norm(final)=12.870 | 4908.0 samples/s | 76.7 steps/s
[Step=42350 Epoch=206.6] | Loss=0.00252 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.126 | L2-Norm(final)=12.877 | 5213.2 samples/s | 81.5 steps/s
[Step=42400 Epoch=206.9] | Loss=0.00245 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.121 | L2-Norm(final)=12.884 | 6877.1 samples/s | 107.5 steps/s
[Step=42450 Epoch=207.1] | Loss=0.00248 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.116 | L2-Norm(final)=12.892 | 2278.8 samples/s | 35.6 steps/s
[Step=42500 Epoch=207.4] | Loss=0.00241 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.111 | L2-Norm(final)=12.900 | 4956.0 samples/s | 77.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=207.4] | Loss=0.00027 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.059 | L2-Norm(final)=12.976 | 5570.5 samples/s | 87.0 steps/s
[Step=42550 Epoch=207.6] | Loss=0.00499 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.055 | L2-Norm(final)=12.981 | 4023.8 samples/s | 62.9 steps/s
[Step=42600 Epoch=207.9] | Loss=0.00525 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.059 | L2-Norm(final)=12.986 | 4482.9 samples/s | 70.0 steps/s
[Step=42650 Epoch=208.1] | Loss=0.00437 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.064 | L2-Norm(final)=12.994 | 4610.7 samples/s | 72.0 steps/s
[Step=42700 Epoch=208.4] | Loss=0.00482 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.067 | L2-Norm(final)=13.001 | 6408.4 samples/s | 100.1 steps/s
[Step=42750 Epoch=208.6] | Loss=0.00451 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.069 | L2-Norm(final)=13.007 | 2064.0 samples/s | 32.2 steps/s
[Step=42800 Epoch=208.8] | Loss=0.00476 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.070 | L2-Norm(final)=13.012 | 4459.3 samples/s | 69.7 steps/s
[Step=42850 Epoch=209.1] | Loss=0.00527 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.072 | L2-Norm(final)=13.018 | 4336.1 samples/s | 67.8 steps/s
[Step=42900 Epoch=209.3] | Loss=0.00516 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.072 | L2-Norm(final)=13.022 | 6059.0 samples/s | 94.7 steps/s
[Step=42950 Epoch=209.6] | Loss=0.00503 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.073 | L2-Norm(final)=13.026 | 2159.6 samples/s | 33.7 steps/s
[Step=43000 Epoch=209.8] | Loss=0.00482 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.072 | L2-Norm(final)=13.030 | 4464.8 samples/s | 69.8 steps/s
[Step=43050 Epoch=210.1] | Loss=0.00469 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.071 | L2-Norm(final)=13.034 | 4477.2 samples/s | 70.0 steps/s
[Step=43100 Epoch=210.3] | Loss=0.00458 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.069 | L2-Norm(final)=13.038 | 5567.3 samples/s | 87.0 steps/s
[Step=43150 Epoch=210.6] | Loss=0.00443 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.067 | L2-Norm(final)=13.041 | 2206.7 samples/s | 34.5 steps/s
[Step=43200 Epoch=210.8] | Loss=0.00431 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.064 | L2-Norm(final)=13.045 | 4415.6 samples/s | 69.0 steps/s
[Step=43250 Epoch=211.0] | Loss=0.00414 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.061 | L2-Norm(final)=13.049 | 4468.4 samples/s | 69.8 steps/s
[Step=43300 Epoch=211.3] | Loss=0.00414 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.057 | L2-Norm(final)=13.052 | 5150.9 samples/s | 80.5 steps/s
[Step=43350 Epoch=211.5] | Loss=0.00401 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.053 | L2-Norm(final)=13.055 | 2261.3 samples/s | 35.3 steps/s
[Step=43400 Epoch=211.8] | Loss=0.00392 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.049 | L2-Norm(final)=13.058 | 4504.7 samples/s | 70.4 steps/s
[Step=43450 Epoch=212.0] | Loss=0.00379 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.045 | L2-Norm(final)=13.061 | 4464.4 samples/s | 69.8 steps/s
[Step=43500 Epoch=212.3] | Loss=0.00373 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.040 | L2-Norm(final)=13.064 | 4874.8 samples/s | 76.2 steps/s
[Step=43550 Epoch=212.5] | Loss=0.00363 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.035 | L2-Norm(final)=13.067 | 2333.5 samples/s | 36.5 steps/s
[Step=43600 Epoch=212.7] | Loss=0.00355 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=13.070 | 4476.7 samples/s | 69.9 steps/s
[Step=43650 Epoch=213.0] | Loss=0.00348 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.023 | L2-Norm(final)=13.073 | 4572.2 samples/s | 71.4 steps/s
[Step=43700 Epoch=213.2] | Loss=0.00340 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.018 | L2-Norm(final)=13.076 | 4513.7 samples/s | 70.5 steps/s
[Step=43750 Epoch=213.5] | Loss=0.00332 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.012 | L2-Norm(final)=13.079 | 2437.1 samples/s | 38.1 steps/s
[Step=43800 Epoch=213.7] | Loss=0.00324 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.005 | L2-Norm(final)=13.081 | 4478.3 samples/s | 70.0 steps/s
[Step=43850 Epoch=214.0] | Loss=0.00317 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.999 | L2-Norm(final)=13.084 | 4454.8 samples/s | 69.6 steps/s
[Step=43900 Epoch=214.2] | Loss=0.00314 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.992 | L2-Norm(final)=13.087 | 4384.4 samples/s | 68.5 steps/s
[Step=43950 Epoch=214.5] | Loss=0.00311 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.985 | L2-Norm(final)=13.089 | 2461.1 samples/s | 38.5 steps/s
[Step=44000 Epoch=214.7] | Loss=0.00308 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.978 | L2-Norm(final)=13.092 | 4540.4 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step44000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=204.6] | Loss=0.01374 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.587 | L2-Norm(final)=13.232 | 5023.8 samples/s | 78.5 steps/s
[Step=42050 Epoch=204.9] | Loss=0.00378 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.585 | L2-Norm(final)=13.238 | 4682.2 samples/s | 73.2 steps/s
[Step=42100 Epoch=205.1] | Loss=0.00384 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.583 | L2-Norm(final)=13.244 | 5118.5 samples/s | 80.0 steps/s
[Step=42150 Epoch=205.4] | Loss=0.00364 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.581 | L2-Norm(final)=13.251 | 4871.4 samples/s | 76.1 steps/s
[Step=42200 Epoch=205.6] | Loss=0.00350 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.578 | L2-Norm(final)=13.259 | 7741.6 samples/s | 121.0 steps/s
[Step=42250 Epoch=205.9] | Loss=0.00338 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.575 | L2-Norm(final)=13.267 | 2191.0 samples/s | 34.2 steps/s
[Step=42300 Epoch=206.1] | Loss=0.00318 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.571 | L2-Norm(final)=13.275 | 4970.6 samples/s | 77.7 steps/s
[Step=42350 Epoch=206.3] | Loss=0.00315 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.567 | L2-Norm(final)=13.284 | 5076.9 samples/s | 79.3 steps/s
[Step=42400 Epoch=206.6] | Loss=0.00312 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.564 | L2-Norm(final)=13.292 | 6843.5 samples/s | 106.9 steps/s
[Step=42450 Epoch=206.8] | Loss=0.00318 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.560 | L2-Norm(final)=13.300 | 2300.6 samples/s | 35.9 steps/s
[Step=42500 Epoch=207.1] | Loss=0.00317 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.556 | L2-Norm(final)=13.309 | 5036.3 samples/s | 78.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=207.1] | Loss=0.00029 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.517 | L2-Norm(final)=13.393 | 5409.9 samples/s | 84.5 steps/s
[Step=42550 Epoch=207.3] | Loss=0.00242 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.513 | L2-Norm(final)=13.400 | 3958.6 samples/s | 61.9 steps/s
[Step=42600 Epoch=207.6] | Loss=0.00349 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.509 | L2-Norm(final)=13.406 | 4415.1 samples/s | 69.0 steps/s
[Step=42650 Epoch=207.8] | Loss=0.00362 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.508 | L2-Norm(final)=13.413 | 4506.1 samples/s | 70.4 steps/s
[Step=42700 Epoch=208.1] | Loss=0.00463 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.509 | L2-Norm(final)=13.419 | 6507.7 samples/s | 101.7 steps/s
[Step=42750 Epoch=208.3] | Loss=0.00505 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.512 | L2-Norm(final)=13.425 | 2104.5 samples/s | 32.9 steps/s
[Step=42800 Epoch=208.5] | Loss=0.00489 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.515 | L2-Norm(final)=13.431 | 4567.9 samples/s | 71.4 steps/s
[Step=42850 Epoch=208.8] | Loss=0.00497 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.518 | L2-Norm(final)=13.437 | 4411.2 samples/s | 68.9 steps/s
[Step=42900 Epoch=209.0] | Loss=0.00548 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.519 | L2-Norm(final)=13.442 | 5891.6 samples/s | 92.1 steps/s
[Step=42950 Epoch=209.3] | Loss=0.00538 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.521 | L2-Norm(final)=13.447 | 2177.8 samples/s | 34.0 steps/s
[Step=43000 Epoch=209.5] | Loss=0.00526 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=13.452 | 4436.8 samples/s | 69.3 steps/s
[Step=43050 Epoch=209.8] | Loss=0.00534 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=13.457 | 4477.7 samples/s | 70.0 steps/s
[Step=43100 Epoch=210.0] | Loss=0.00526 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=13.461 | 5442.8 samples/s | 85.0 steps/s
[Step=43150 Epoch=210.2] | Loss=0.00546 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=13.465 | 2270.9 samples/s | 35.5 steps/s
[Step=43200 Epoch=210.5] | Loss=0.00539 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=13.469 | 4377.7 samples/s | 68.4 steps/s
[Step=43250 Epoch=210.7] | Loss=0.00536 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.521 | L2-Norm(final)=13.473 | 4507.8 samples/s | 70.4 steps/s
[Step=43300 Epoch=211.0] | Loss=0.00524 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.519 | L2-Norm(final)=13.476 | 4819.7 samples/s | 75.3 steps/s
[Step=43350 Epoch=211.2] | Loss=0.00512 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.517 | L2-Norm(final)=13.480 | 2317.6 samples/s | 36.2 steps/s
[Step=43400 Epoch=211.5] | Loss=0.00499 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.515 | L2-Norm(final)=13.483 | 4460.6 samples/s | 69.7 steps/s
[Step=43450 Epoch=211.7] | Loss=0.00486 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.513 | L2-Norm(final)=13.487 | 4606.7 samples/s | 72.0 steps/s
[Step=43500 Epoch=212.0] | Loss=0.00480 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.510 | L2-Norm(final)=13.490 | 4456.6 samples/s | 69.6 steps/s
[Step=43550 Epoch=212.2] | Loss=0.00467 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.507 | L2-Norm(final)=13.493 | 2410.5 samples/s | 37.7 steps/s
[Step=43600 Epoch=212.4] | Loss=0.00462 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.504 | L2-Norm(final)=13.496 | 4486.0 samples/s | 70.1 steps/s
[Step=43650 Epoch=212.7] | Loss=0.00452 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.500 | L2-Norm(final)=13.499 | 4383.1 samples/s | 68.5 steps/s
[Step=43700 Epoch=212.9] | Loss=0.00444 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.496 | L2-Norm(final)=13.502 | 4495.7 samples/s | 70.2 steps/s
[Step=43750 Epoch=213.2] | Loss=0.00439 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.492 | L2-Norm(final)=13.504 | 2490.0 samples/s | 38.9 steps/s
[Step=43800 Epoch=213.4] | Loss=0.00429 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.488 | L2-Norm(final)=13.507 | 4372.6 samples/s | 68.3 steps/s
[Step=43850 Epoch=213.7] | Loss=0.00422 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.483 | L2-Norm(final)=13.510 | 4584.4 samples/s | 71.6 steps/s
[Step=43900 Epoch=213.9] | Loss=0.00418 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.478 | L2-Norm(final)=13.513 | 4343.1 samples/s | 67.9 steps/s
[Step=43950 Epoch=214.1] | Loss=0.00411 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.474 | L2-Norm(final)=13.515 | 2442.7 samples/s | 38.2 steps/s
[Step=44000 Epoch=214.4] | Loss=0.00407 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.469 | L2-Norm(final)=13.518 | 4437.9 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step44000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=204.8] | Loss=0.00059 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.278 | L2-Norm(final)=13.093 | 5064.9 samples/s | 79.1 steps/s
[Step=42050 Epoch=205.1] | Loss=0.00147 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.274 | L2-Norm(final)=13.099 | 4439.4 samples/s | 69.4 steps/s
[Step=42100 Epoch=205.3] | Loss=0.00213 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.269 | L2-Norm(final)=13.107 | 5019.6 samples/s | 78.4 steps/s
[Step=42150 Epoch=205.5] | Loss=0.00231 | Reg=0.00334 | acc=0.9844 | L2-Norm=18.264 | L2-Norm(final)=13.115 | 5044.6 samples/s | 78.8 steps/s
[Step=42200 Epoch=205.8] | Loss=0.00230 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.261 | L2-Norm(final)=13.123 | 7829.0 samples/s | 122.3 steps/s
[Step=42250 Epoch=206.0] | Loss=0.00222 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.257 | L2-Norm(final)=13.132 | 2241.8 samples/s | 35.0 steps/s
[Step=42300 Epoch=206.3] | Loss=0.00220 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.252 | L2-Norm(final)=13.141 | 4924.0 samples/s | 76.9 steps/s
[Step=42350 Epoch=206.5] | Loss=0.00217 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.247 | L2-Norm(final)=13.150 | 4941.3 samples/s | 77.2 steps/s
[Step=42400 Epoch=206.8] | Loss=0.00217 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.242 | L2-Norm(final)=13.158 | 6898.2 samples/s | 107.8 steps/s
[Step=42450 Epoch=207.0] | Loss=0.00208 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.237 | L2-Norm(final)=13.167 | 2308.3 samples/s | 36.1 steps/s
[Step=42500 Epoch=207.3] | Loss=0.00212 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.232 | L2-Norm(final)=13.175 | 5172.6 samples/s | 80.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=207.3] | Loss=0.00004 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.177 | L2-Norm(final)=13.257 | 5556.1 samples/s | 86.8 steps/s
[Step=42550 Epoch=207.5] | Loss=0.00193 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.173 | L2-Norm(final)=13.266 | 3979.7 samples/s | 62.2 steps/s
[Step=42600 Epoch=207.7] | Loss=0.00274 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.170 | L2-Norm(final)=13.272 | 4434.4 samples/s | 69.3 steps/s
[Step=42650 Epoch=208.0] | Loss=0.00419 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.167 | L2-Norm(final)=13.277 | 4426.5 samples/s | 69.2 steps/s
[Step=42700 Epoch=208.2] | Loss=0.00475 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.168 | L2-Norm(final)=13.281 | 6472.6 samples/s | 101.1 steps/s
[Step=42750 Epoch=208.5] | Loss=0.00491 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.171 | L2-Norm(final)=13.288 | 2085.3 samples/s | 32.6 steps/s
[Step=42800 Epoch=208.7] | Loss=0.00492 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.173 | L2-Norm(final)=13.293 | 4498.5 samples/s | 70.3 steps/s
[Step=42850 Epoch=209.0] | Loss=0.00495 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.176 | L2-Norm(final)=13.299 | 4562.8 samples/s | 71.3 steps/s
[Step=42900 Epoch=209.2] | Loss=0.00502 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.179 | L2-Norm(final)=13.305 | 5792.4 samples/s | 90.5 steps/s
[Step=42950 Epoch=209.4] | Loss=0.00477 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.181 | L2-Norm(final)=13.311 | 2138.3 samples/s | 33.4 steps/s
[Step=43000 Epoch=209.7] | Loss=0.00490 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.183 | L2-Norm(final)=13.316 | 4404.1 samples/s | 68.8 steps/s
[Step=43050 Epoch=209.9] | Loss=0.00474 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.183 | L2-Norm(final)=13.321 | 4446.2 samples/s | 69.5 steps/s
[Step=43100 Epoch=210.2] | Loss=0.00459 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.183 | L2-Norm(final)=13.326 | 5430.1 samples/s | 84.8 steps/s
[Step=43150 Epoch=210.4] | Loss=0.00454 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.183 | L2-Norm(final)=13.331 | 2243.9 samples/s | 35.1 steps/s
[Step=43200 Epoch=210.7] | Loss=0.00436 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.182 | L2-Norm(final)=13.335 | 4465.4 samples/s | 69.8 steps/s
[Step=43250 Epoch=210.9] | Loss=0.00423 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.181 | L2-Norm(final)=13.340 | 4476.3 samples/s | 69.9 steps/s
[Step=43300 Epoch=211.2] | Loss=0.00409 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.179 | L2-Norm(final)=13.344 | 4976.6 samples/s | 77.8 steps/s
[Step=43350 Epoch=211.4] | Loss=0.00410 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.176 | L2-Norm(final)=13.348 | 2314.1 samples/s | 36.2 steps/s
[Step=43400 Epoch=211.6] | Loss=0.00404 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.173 | L2-Norm(final)=13.351 | 4438.1 samples/s | 69.3 steps/s
[Step=43450 Epoch=211.9] | Loss=0.00391 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.170 | L2-Norm(final)=13.355 | 4518.9 samples/s | 70.6 steps/s
[Step=43500 Epoch=212.1] | Loss=0.00385 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.167 | L2-Norm(final)=13.359 | 4568.7 samples/s | 71.4 steps/s
[Step=43550 Epoch=212.4] | Loss=0.00375 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.164 | L2-Norm(final)=13.362 | 2426.7 samples/s | 37.9 steps/s
[Step=43600 Epoch=212.6] | Loss=0.00365 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.160 | L2-Norm(final)=13.366 | 4441.8 samples/s | 69.4 steps/s
[Step=43650 Epoch=212.9] | Loss=0.00353 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.156 | L2-Norm(final)=13.369 | 4485.1 samples/s | 70.1 steps/s
[Step=43700 Epoch=213.1] | Loss=0.00346 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.151 | L2-Norm(final)=13.373 | 4399.4 samples/s | 68.7 steps/s
[Step=43750 Epoch=213.3] | Loss=0.00340 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.146 | L2-Norm(final)=13.376 | 2404.7 samples/s | 37.6 steps/s
[Step=43800 Epoch=213.6] | Loss=0.00332 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.141 | L2-Norm(final)=13.379 | 4461.0 samples/s | 69.7 steps/s
[Step=43850 Epoch=213.8] | Loss=0.00323 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.136 | L2-Norm(final)=13.382 | 4432.9 samples/s | 69.3 steps/s
[Step=43900 Epoch=214.1] | Loss=0.00314 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.130 | L2-Norm(final)=13.385 | 4495.7 samples/s | 70.2 steps/s
[Step=43950 Epoch=214.3] | Loss=0.00314 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.124 | L2-Norm(final)=13.388 | 2459.6 samples/s | 38.4 steps/s
[Step=44000 Epoch=214.6] | Loss=0.00307 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.119 | L2-Norm(final)=13.391 | 4493.6 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step44000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=206.0] | Loss=0.00109 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.103 | L2-Norm(final)=13.122 | 5330.6 samples/s | 83.3 steps/s
[Step=42050 Epoch=206.2] | Loss=0.00250 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.098 | L2-Norm(final)=13.127 | 4434.1 samples/s | 69.3 steps/s
[Step=42100 Epoch=206.5] | Loss=0.00219 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=13.135 | 5033.2 samples/s | 78.6 steps/s
[Step=42150 Epoch=206.7] | Loss=0.00239 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.091 | L2-Norm(final)=13.143 | 5176.5 samples/s | 80.9 steps/s
[Step=42200 Epoch=206.9] | Loss=0.00236 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.087 | L2-Norm(final)=13.152 | 7772.1 samples/s | 121.4 steps/s
[Step=42250 Epoch=207.2] | Loss=0.00237 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.083 | L2-Norm(final)=13.161 | 2192.8 samples/s | 34.3 steps/s
[Step=42300 Epoch=207.4] | Loss=0.00231 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.079 | L2-Norm(final)=13.170 | 5083.3 samples/s | 79.4 steps/s
[Step=42350 Epoch=207.7] | Loss=0.00219 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.074 | L2-Norm(final)=13.179 | 4975.5 samples/s | 77.7 steps/s
[Step=42400 Epoch=207.9] | Loss=0.00221 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.069 | L2-Norm(final)=13.188 | 7331.2 samples/s | 114.6 steps/s
[Step=42450 Epoch=208.2] | Loss=0.00220 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.064 | L2-Norm(final)=13.196 | 2181.0 samples/s | 34.1 steps/s
[Step=42500 Epoch=208.4] | Loss=0.00217 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.059 | L2-Norm(final)=13.205 | 4986.8 samples/s | 77.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=208.4] | Loss=0.00114 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.007 | L2-Norm(final)=13.294 | 5673.0 samples/s | 88.6 steps/s
[Step=42550 Epoch=208.7] | Loss=0.00213 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.005 | L2-Norm(final)=13.302 | 4056.0 samples/s | 63.4 steps/s
[Step=42600 Epoch=208.9] | Loss=0.00178 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.002 | L2-Norm(final)=13.311 | 4477.2 samples/s | 70.0 steps/s
[Step=42650 Epoch=209.1] | Loss=0.00257 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.001 | L2-Norm(final)=13.318 | 4504.3 samples/s | 70.4 steps/s
[Step=42700 Epoch=209.4] | Loss=0.00346 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.003 | L2-Norm(final)=13.326 | 6711.2 samples/s | 104.9 steps/s
[Step=42750 Epoch=209.6] | Loss=0.00427 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.008 | L2-Norm(final)=13.334 | 2056.6 samples/s | 32.1 steps/s
[Step=42800 Epoch=209.9] | Loss=0.00494 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.013 | L2-Norm(final)=13.340 | 4470.9 samples/s | 69.9 steps/s
[Step=42850 Epoch=210.1] | Loss=0.00488 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.018 | L2-Norm(final)=13.346 | 4497.5 samples/s | 70.3 steps/s
[Step=42900 Epoch=210.4] | Loss=0.00499 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.023 | L2-Norm(final)=13.352 | 6277.3 samples/s | 98.1 steps/s
[Step=42950 Epoch=210.6] | Loss=0.00479 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.026 | L2-Norm(final)=13.358 | 2136.7 samples/s | 33.4 steps/s
[Step=43000 Epoch=210.9] | Loss=0.00460 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=13.365 | 4472.5 samples/s | 69.9 steps/s
[Step=43050 Epoch=211.1] | Loss=0.00457 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.030 | L2-Norm(final)=13.370 | 4512.6 samples/s | 70.5 steps/s
[Step=43100 Epoch=211.4] | Loss=0.00449 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.031 | L2-Norm(final)=13.375 | 5634.1 samples/s | 88.0 steps/s
[Step=43150 Epoch=211.6] | Loss=0.00430 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.031 | L2-Norm(final)=13.380 | 2162.9 samples/s | 33.8 steps/s
[Step=43200 Epoch=211.8] | Loss=0.00421 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.030 | L2-Norm(final)=13.385 | 4440.1 samples/s | 69.4 steps/s
[Step=43250 Epoch=212.1] | Loss=0.00414 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.029 | L2-Norm(final)=13.389 | 4448.0 samples/s | 69.5 steps/s
[Step=43300 Epoch=212.3] | Loss=0.00413 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.027 | L2-Norm(final)=13.394 | 5541.4 samples/s | 86.6 steps/s
[Step=43350 Epoch=212.6] | Loss=0.00399 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.025 | L2-Norm(final)=13.398 | 2234.7 samples/s | 34.9 steps/s
[Step=43400 Epoch=212.8] | Loss=0.00389 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.022 | L2-Norm(final)=13.402 | 4479.4 samples/s | 70.0 steps/s
[Step=43450 Epoch=213.1] | Loss=0.00381 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.020 | L2-Norm(final)=13.406 | 4320.6 samples/s | 67.5 steps/s
[Step=43500 Epoch=213.3] | Loss=0.00372 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.016 | L2-Norm(final)=13.409 | 5235.9 samples/s | 81.8 steps/s
[Step=43550 Epoch=213.6] | Loss=0.00369 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.013 | L2-Norm(final)=13.413 | 2278.9 samples/s | 35.6 steps/s
[Step=43600 Epoch=213.8] | Loss=0.00363 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.010 | L2-Norm(final)=13.417 | 4386.2 samples/s | 68.5 steps/s
[Step=43650 Epoch=214.1] | Loss=0.00360 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.006 | L2-Norm(final)=13.420 | 4450.4 samples/s | 69.5 steps/s
[Step=43700 Epoch=214.3] | Loss=0.00353 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.002 | L2-Norm(final)=13.423 | 4951.6 samples/s | 77.4 steps/s
[Step=43750 Epoch=214.5] | Loss=0.00345 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.998 | L2-Norm(final)=13.427 | 2313.8 samples/s | 36.2 steps/s
[Step=43800 Epoch=214.8] | Loss=0.00342 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.994 | L2-Norm(final)=13.430 | 4437.8 samples/s | 69.3 steps/s
[Step=43850 Epoch=215.0] | Loss=0.00341 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.989 | L2-Norm(final)=13.433 | 4531.8 samples/s | 70.8 steps/s
[Step=43900 Epoch=215.3] | Loss=0.00333 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.985 | L2-Norm(final)=13.436 | 4597.9 samples/s | 71.8 steps/s
[Step=43950 Epoch=215.5] | Loss=0.00331 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.980 | L2-Norm(final)=13.439 | 2417.0 samples/s | 37.8 steps/s
[Step=44000 Epoch=215.8] | Loss=0.00331 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.976 | L2-Norm(final)=13.441 | 4439.1 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step44000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=398.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.107 | L2-Norm(final)=7.170 | 4859.1 samples/s | 75.9 steps/s
[Step=42050 Epoch=398.5] | Loss=0.00003 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=7.177 | 4391.7 samples/s | 68.6 steps/s
[Step=42100 Epoch=398.9] | Loss=0.00003 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=7.185 | 7343.2 samples/s | 114.7 steps/s
[Step=42150 Epoch=399.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.098 | L2-Norm(final)=7.192 | 2101.6 samples/s | 32.8 steps/s
[Step=42200 Epoch=399.9] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.098 | L2-Norm(final)=7.199 | 6660.0 samples/s | 104.1 steps/s
[Step=42250 Epoch=400.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.206 | 2216.8 samples/s | 34.6 steps/s
[Step=42300 Epoch=400.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.212 | 5898.7 samples/s | 92.2 steps/s
[Step=42350 Epoch=401.3] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.219 | 2319.5 samples/s | 36.2 steps/s
[Step=42400 Epoch=401.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.225 | 5159.3 samples/s | 80.6 steps/s
[Step=42450 Epoch=402.3] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.232 | 2351.5 samples/s | 36.7 steps/s
[Step=42500 Epoch=402.7] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.238 | 4912.3 samples/s | 76.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=402.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=7.301 | 5670.1 samples/s | 88.6 steps/s
[Step=42550 Epoch=403.2] | Loss=0.00266 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.072 | L2-Norm(final)=7.304 | 3707.5 samples/s | 57.9 steps/s
[Step=42600 Epoch=403.7] | Loss=0.00202 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.120 | L2-Norm(final)=7.302 | 6053.7 samples/s | 94.6 steps/s
[Step=42650 Epoch=404.1] | Loss=0.00148 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=7.305 | 2016.8 samples/s | 31.5 steps/s
[Step=42700 Epoch=404.6] | Loss=0.00112 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.165 | L2-Norm(final)=7.308 | 5482.5 samples/s | 85.7 steps/s
[Step=42750 Epoch=405.1] | Loss=0.00090 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.173 | L2-Norm(final)=7.310 | 2110.2 samples/s | 33.0 steps/s
[Step=42800 Epoch=405.6] | Loss=0.00075 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=7.311 | 5131.3 samples/s | 80.2 steps/s
[Step=42850 Epoch=406.0] | Loss=0.00064 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=7.312 | 2185.9 samples/s | 34.2 steps/s
[Step=42900 Epoch=406.5] | Loss=0.00056 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.184 | L2-Norm(final)=7.313 | 4660.9 samples/s | 72.8 steps/s
[Step=42950 Epoch=407.0] | Loss=0.00050 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.185 | L2-Norm(final)=7.314 | 2254.2 samples/s | 35.2 steps/s
[Step=43000 Epoch=407.5] | Loss=0.00045 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=7.315 | 4350.9 samples/s | 68.0 steps/s
[Step=43050 Epoch=407.9] | Loss=0.00041 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=7.315 | 2376.6 samples/s | 37.1 steps/s
[Step=43100 Epoch=408.4] | Loss=0.00038 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=7.316 | 4273.8 samples/s | 66.8 steps/s
[Step=43150 Epoch=408.9] | Loss=0.00035 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.185 | L2-Norm(final)=7.317 | 2367.9 samples/s | 37.0 steps/s
[Step=43200 Epoch=409.4] | Loss=0.00033 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.185 | L2-Norm(final)=7.317 | 4284.3 samples/s | 66.9 steps/s
[Step=43250 Epoch=409.8] | Loss=0.00030 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.184 | L2-Norm(final)=7.318 | 2398.6 samples/s | 37.5 steps/s
[Step=43300 Epoch=410.3] | Loss=0.00029 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.183 | L2-Norm(final)=7.318 | 4218.3 samples/s | 65.9 steps/s
[Step=43350 Epoch=410.8] | Loss=0.00027 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=7.319 | 2471.5 samples/s | 38.6 steps/s
[Step=43400 Epoch=411.3] | Loss=0.00025 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.180 | L2-Norm(final)=7.319 | 4044.7 samples/s | 63.2 steps/s
[Step=43450 Epoch=411.7] | Loss=0.00024 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=7.319 | 6403.8 samples/s | 100.1 steps/s
[Step=43500 Epoch=412.2] | Loss=0.00023 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.177 | L2-Norm(final)=7.320 | 1989.6 samples/s | 31.1 steps/s
[Step=43550 Epoch=412.7] | Loss=0.00022 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.176 | L2-Norm(final)=7.320 | 5804.7 samples/s | 90.7 steps/s
[Step=43600 Epoch=413.1] | Loss=0.00021 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=7.321 | 2089.0 samples/s | 32.6 steps/s
[Step=43650 Epoch=413.6] | Loss=0.00020 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.173 | L2-Norm(final)=7.321 | 5265.7 samples/s | 82.3 steps/s
[Step=43700 Epoch=414.1] | Loss=0.00019 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=7.321 | 2147.4 samples/s | 33.6 steps/s
[Step=43750 Epoch=414.6] | Loss=0.00018 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.169 | L2-Norm(final)=7.322 | 4852.6 samples/s | 75.8 steps/s
[Step=43800 Epoch=415.0] | Loss=0.00018 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.167 | L2-Norm(final)=7.322 | 2235.0 samples/s | 34.9 steps/s
[Step=43850 Epoch=415.5] | Loss=0.00017 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.165 | L2-Norm(final)=7.322 | 4483.0 samples/s | 70.0 steps/s
[Step=43900 Epoch=416.0] | Loss=0.00017 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.163 | L2-Norm(final)=7.323 | 2308.7 samples/s | 36.1 steps/s
[Step=43950 Epoch=416.5] | Loss=0.00016 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.161 | L2-Norm(final)=7.323 | 4211.1 samples/s | 65.8 steps/s
[Step=44000 Epoch=416.9] | Loss=0.00015 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.159 | L2-Norm(final)=7.323 | 2393.9 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step44000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=399.5] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.466 | L2-Norm(final)=8.037 | 5295.6 samples/s | 82.7 steps/s
[Step=42050 Epoch=400.0] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.464 | L2-Norm(final)=8.039 | 4353.0 samples/s | 68.0 steps/s
[Step=42100 Epoch=400.5] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.462 | L2-Norm(final)=8.041 | 7255.3 samples/s | 113.4 steps/s
[Step=42150 Epoch=401.0] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.460 | L2-Norm(final)=8.043 | 2149.6 samples/s | 33.6 steps/s
[Step=42200 Epoch=401.4] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.459 | L2-Norm(final)=8.045 | 6406.3 samples/s | 100.1 steps/s
[Step=42250 Epoch=401.9] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.457 | L2-Norm(final)=8.047 | 2226.7 samples/s | 34.8 steps/s
[Step=42300 Epoch=402.4] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.455 | L2-Norm(final)=8.049 | 5858.3 samples/s | 91.5 steps/s
[Step=42350 Epoch=402.9] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.454 | L2-Norm(final)=8.051 | 2305.3 samples/s | 36.0 steps/s
[Step=42400 Epoch=403.3] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.452 | L2-Norm(final)=8.053 | 5430.0 samples/s | 84.8 steps/s
[Step=42450 Epoch=403.8] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.450 | L2-Norm(final)=8.055 | 2431.3 samples/s | 38.0 steps/s
[Step=42500 Epoch=404.3] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.448 | L2-Norm(final)=8.057 | 4854.4 samples/s | 75.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=404.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.430 | L2-Norm(final)=8.077 | 5727.9 samples/s | 89.5 steps/s
[Step=42550 Epoch=404.8] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.425 | L2-Norm(final)=8.079 | 3640.6 samples/s | 56.9 steps/s
[Step=42600 Epoch=405.2] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.417 | L2-Norm(final)=8.080 | 6289.4 samples/s | 98.3 steps/s
[Step=42650 Epoch=405.7] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.409 | L2-Norm(final)=8.082 | 2015.6 samples/s | 31.5 steps/s
[Step=42700 Epoch=406.2] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.401 | L2-Norm(final)=8.083 | 5704.8 samples/s | 89.1 steps/s
[Step=42750 Epoch=406.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.393 | L2-Norm(final)=8.084 | 2103.4 samples/s | 32.9 steps/s
[Step=42800 Epoch=407.1] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.384 | L2-Norm(final)=8.085 | 5026.5 samples/s | 78.5 steps/s
[Step=42850 Epoch=407.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.376 | L2-Norm(final)=8.086 | 2172.1 samples/s | 33.9 steps/s
[Step=42900 Epoch=408.1] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.367 | L2-Norm(final)=8.087 | 4724.4 samples/s | 73.8 steps/s
[Step=42950 Epoch=408.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.358 | L2-Norm(final)=8.088 | 2273.8 samples/s | 35.5 steps/s
[Step=43000 Epoch=409.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.349 | L2-Norm(final)=8.089 | 4351.1 samples/s | 68.0 steps/s
[Step=43050 Epoch=409.5] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.340 | L2-Norm(final)=8.090 | 2374.1 samples/s | 37.1 steps/s
[Step=43100 Epoch=410.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.331 | L2-Norm(final)=8.090 | 4167.7 samples/s | 65.1 steps/s
[Step=43150 Epoch=410.5] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=8.091 | 2409.7 samples/s | 37.7 steps/s
[Step=43200 Epoch=410.9] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.313 | L2-Norm(final)=8.092 | 4205.0 samples/s | 65.7 steps/s
[Step=43250 Epoch=411.4] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.303 | L2-Norm(final)=8.093 | 2381.6 samples/s | 37.2 steps/s
[Step=43300 Epoch=411.9] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.294 | L2-Norm(final)=8.093 | 4299.1 samples/s | 67.2 steps/s
[Step=43350 Epoch=412.4] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.284 | L2-Norm(final)=8.094 | 2416.2 samples/s | 37.8 steps/s
[Step=43400 Epoch=412.8] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.274 | L2-Norm(final)=8.095 | 4087.2 samples/s | 63.9 steps/s
[Step=43450 Epoch=413.3] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.264 | L2-Norm(final)=8.096 | 6543.1 samples/s | 102.2 steps/s
[Step=43500 Epoch=413.8] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.254 | L2-Norm(final)=8.097 | 1976.1 samples/s | 30.9 steps/s
[Step=43550 Epoch=414.3] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.244 | L2-Norm(final)=8.097 | 5899.1 samples/s | 92.2 steps/s
[Step=43600 Epoch=414.7] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.234 | L2-Norm(final)=8.098 | 2066.0 samples/s | 32.3 steps/s
[Step=43650 Epoch=415.2] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.224 | L2-Norm(final)=8.099 | 5328.0 samples/s | 83.2 steps/s
[Step=43700 Epoch=415.7] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.214 | L2-Norm(final)=8.100 | 2134.7 samples/s | 33.4 steps/s
[Step=43750 Epoch=416.2] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.203 | L2-Norm(final)=8.101 | 4871.6 samples/s | 76.1 steps/s
[Step=43800 Epoch=416.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.192 | L2-Norm(final)=8.101 | 2228.0 samples/s | 34.8 steps/s
[Step=43850 Epoch=417.1] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=8.102 | 4427.5 samples/s | 69.2 steps/s
[Step=43900 Epoch=417.6] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=8.103 | 2328.4 samples/s | 36.4 steps/s
[Step=43950 Epoch=418.1] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.160 | L2-Norm(final)=8.104 | 4261.7 samples/s | 66.6 steps/s
[Step=44000 Epoch=418.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=8.105 | 2373.8 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step44000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=401.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.332 | L2-Norm(final)=7.535 | 4980.6 samples/s | 77.8 steps/s
[Step=42050 Epoch=401.6] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.330 | L2-Norm(final)=7.537 | 4240.2 samples/s | 66.3 steps/s
[Step=42100 Epoch=402.0] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.330 | L2-Norm(final)=7.539 | 7273.0 samples/s | 113.6 steps/s
[Step=42150 Epoch=402.5] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.329 | L2-Norm(final)=7.542 | 2166.7 samples/s | 33.9 steps/s
[Step=42200 Epoch=403.0] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.329 | L2-Norm(final)=7.544 | 6426.5 samples/s | 100.4 steps/s
[Step=42250 Epoch=403.5] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.328 | L2-Norm(final)=7.547 | 2172.2 samples/s | 33.9 steps/s
[Step=42300 Epoch=403.9] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.328 | L2-Norm(final)=7.549 | 6152.1 samples/s | 96.1 steps/s
[Step=42350 Epoch=404.4] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.327 | L2-Norm(final)=7.552 | 2279.1 samples/s | 35.6 steps/s
[Step=42400 Epoch=404.9] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.326 | L2-Norm(final)=7.554 | 5645.3 samples/s | 88.2 steps/s
[Step=42450 Epoch=405.4] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.325 | L2-Norm(final)=7.556 | 2365.3 samples/s | 37.0 steps/s
[Step=42500 Epoch=405.8] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.324 | L2-Norm(final)=7.559 | 5146.0 samples/s | 80.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=405.9] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.315 | L2-Norm(final)=7.584 | 5345.5 samples/s | 83.5 steps/s
[Step=42550 Epoch=406.3] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.311 | L2-Norm(final)=7.586 | 4041.3 samples/s | 63.1 steps/s
[Step=42600 Epoch=406.8] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.306 | L2-Norm(final)=7.588 | 6225.9 samples/s | 97.3 steps/s
[Step=42650 Epoch=407.3] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.300 | L2-Norm(final)=7.590 | 2001.0 samples/s | 31.3 steps/s
[Step=42700 Epoch=407.8] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.294 | L2-Norm(final)=7.592 | 5820.3 samples/s | 90.9 steps/s
[Step=42750 Epoch=408.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.288 | L2-Norm(final)=7.593 | 2078.2 samples/s | 32.5 steps/s
[Step=42800 Epoch=408.7] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.282 | L2-Norm(final)=7.594 | 5378.6 samples/s | 84.0 steps/s
[Step=42850 Epoch=409.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.275 | L2-Norm(final)=7.595 | 2141.6 samples/s | 33.5 steps/s
[Step=42900 Epoch=409.7] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.269 | L2-Norm(final)=7.596 | 4933.6 samples/s | 77.1 steps/s
[Step=42950 Epoch=410.1] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.262 | L2-Norm(final)=7.597 | 2189.7 samples/s | 34.2 steps/s
[Step=43000 Epoch=410.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.256 | L2-Norm(final)=7.598 | 4644.1 samples/s | 72.6 steps/s
[Step=43050 Epoch=411.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.249 | L2-Norm(final)=7.599 | 2276.5 samples/s | 35.6 steps/s
[Step=43100 Epoch=411.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.242 | L2-Norm(final)=7.600 | 4330.3 samples/s | 67.7 steps/s
[Step=43150 Epoch=412.1] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.235 | L2-Norm(final)=7.601 | 2373.8 samples/s | 37.1 steps/s
[Step=43200 Epoch=412.5] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.228 | L2-Norm(final)=7.602 | 4241.5 samples/s | 66.3 steps/s
[Step=43250 Epoch=413.0] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.222 | L2-Norm(final)=7.603 | 2371.2 samples/s | 37.0 steps/s
[Step=43300 Epoch=413.5] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.215 | L2-Norm(final)=7.603 | 4266.4 samples/s | 66.7 steps/s
[Step=43350 Epoch=414.0] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.207 | L2-Norm(final)=7.604 | 2408.7 samples/s | 37.6 steps/s
[Step=43400 Epoch=414.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.200 | L2-Norm(final)=7.605 | 4182.5 samples/s | 65.4 steps/s
[Step=43450 Epoch=414.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.193 | L2-Norm(final)=7.606 | 2380.3 samples/s | 37.2 steps/s
[Step=43500 Epoch=415.4] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=7.607 | 4268.4 samples/s | 66.7 steps/s
[Step=43550 Epoch=415.9] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.178 | L2-Norm(final)=7.607 | 6980.5 samples/s | 109.1 steps/s
[Step=43600 Epoch=416.4] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.171 | L2-Norm(final)=7.608 | 1959.3 samples/s | 30.6 steps/s
[Step=43650 Epoch=416.8] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.163 | L2-Norm(final)=7.609 | 6242.5 samples/s | 97.5 steps/s
[Step=43700 Epoch=417.3] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.156 | L2-Norm(final)=7.610 | 2021.5 samples/s | 31.6 steps/s
[Step=43750 Epoch=417.8] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=7.610 | 5824.4 samples/s | 91.0 steps/s
[Step=43800 Epoch=418.3] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.140 | L2-Norm(final)=7.611 | 2076.2 samples/s | 32.4 steps/s
[Step=43850 Epoch=418.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.133 | L2-Norm(final)=7.612 | 5340.8 samples/s | 83.5 steps/s
[Step=43900 Epoch=419.2] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.125 | L2-Norm(final)=7.613 | 2137.5 samples/s | 33.4 steps/s
[Step=43950 Epoch=419.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.117 | L2-Norm(final)=7.613 | 4866.6 samples/s | 76.0 steps/s
[Step=44000 Epoch=420.2] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.109 | L2-Norm(final)=7.614 | 2236.8 samples/s | 34.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step44000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=395.8] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.310 | L2-Norm(final)=7.503 | 5276.4 samples/s | 82.4 steps/s
[Step=42050 Epoch=396.2] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.307 | L2-Norm(final)=7.508 | 4051.6 samples/s | 63.3 steps/s
[Step=42100 Epoch=396.7] | Loss=0.00004 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.308 | L2-Norm(final)=7.514 | 7398.7 samples/s | 115.6 steps/s
[Step=42150 Epoch=397.2] | Loss=0.00004 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.521 | 2136.0 samples/s | 33.4 steps/s
[Step=42200 Epoch=397.6] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.526 | 6438.9 samples/s | 100.6 steps/s
[Step=42250 Epoch=398.1] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.532 | 2252.0 samples/s | 35.2 steps/s
[Step=42300 Epoch=398.6] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.538 | 5634.1 samples/s | 88.0 steps/s
[Step=42350 Epoch=399.1] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.543 | 2366.9 samples/s | 37.0 steps/s
[Step=42400 Epoch=399.5] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.548 | 5062.3 samples/s | 79.1 steps/s
[Step=42450 Epoch=400.0] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.308 | L2-Norm(final)=7.553 | 2496.5 samples/s | 39.0 steps/s
[Step=42500 Epoch=400.5] | Loss=0.00003 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.308 | L2-Norm(final)=7.558 | 4737.2 samples/s | 74.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=400.5] | Loss=0.00006 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.301 | L2-Norm(final)=7.609 | 5576.9 samples/s | 87.1 steps/s
[Step=42550 Epoch=400.9] | Loss=0.00002 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.294 | L2-Norm(final)=7.614 | 3699.7 samples/s | 57.8 steps/s
[Step=42600 Epoch=401.4] | Loss=0.00002 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.283 | L2-Norm(final)=7.618 | 6162.5 samples/s | 96.3 steps/s
[Step=42650 Epoch=401.9] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.272 | L2-Norm(final)=7.621 | 2018.5 samples/s | 31.5 steps/s
[Step=42700 Epoch=402.4] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.259 | L2-Norm(final)=7.624 | 5555.6 samples/s | 86.8 steps/s
[Step=42750 Epoch=402.8] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.246 | L2-Norm(final)=7.626 | 2120.1 samples/s | 33.1 steps/s
[Step=42800 Epoch=403.3] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.232 | L2-Norm(final)=7.628 | 4913.4 samples/s | 76.8 steps/s
[Step=42850 Epoch=403.8] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.218 | L2-Norm(final)=7.629 | 2230.4 samples/s | 34.8 steps/s
[Step=42900 Epoch=404.2] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.204 | L2-Norm(final)=7.631 | 4489.1 samples/s | 70.1 steps/s
[Step=42950 Epoch=404.7] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.190 | L2-Norm(final)=7.632 | 2317.6 samples/s | 36.2 steps/s
[Step=43000 Epoch=405.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.175 | L2-Norm(final)=7.633 | 4229.4 samples/s | 66.1 steps/s
[Step=43050 Epoch=405.7] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.160 | L2-Norm(final)=7.634 | 2370.9 samples/s | 37.0 steps/s
[Step=43100 Epoch=406.1] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.146 | L2-Norm(final)=7.636 | 4231.4 samples/s | 66.1 steps/s
[Step=43150 Epoch=406.6] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.131 | L2-Norm(final)=7.637 | 2355.7 samples/s | 36.8 steps/s
[Step=43200 Epoch=407.1] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.116 | L2-Norm(final)=7.638 | 4269.3 samples/s | 66.7 steps/s
[Step=43250 Epoch=407.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.101 | L2-Norm(final)=7.639 | 2664.9 samples/s | 41.6 steps/s
[Step=43300 Epoch=408.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=7.640 | 3610.9 samples/s | 56.4 steps/s
[Step=43350 Epoch=408.5] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.070 | L2-Norm(final)=7.642 | 6319.3 samples/s | 98.7 steps/s
[Step=43400 Epoch=409.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=7.643 | 2027.3 samples/s | 31.7 steps/s
[Step=43450 Epoch=409.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.039 | L2-Norm(final)=7.644 | 5562.3 samples/s | 86.9 steps/s
[Step=43500 Epoch=409.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.023 | L2-Norm(final)=7.645 | 2120.8 samples/s | 33.1 steps/s
[Step=43550 Epoch=410.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=7.646 | 5025.2 samples/s | 78.5 steps/s
[Step=43600 Epoch=410.8] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.991 | L2-Norm(final)=7.648 | 2225.9 samples/s | 34.8 steps/s
[Step=43650 Epoch=411.3] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.975 | L2-Norm(final)=7.649 | 4508.3 samples/s | 70.4 steps/s
[Step=43700 Epoch=411.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=7.650 | 2323.6 samples/s | 36.3 steps/s
[Step=43750 Epoch=412.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.942 | L2-Norm(final)=7.652 | 4184.9 samples/s | 65.4 steps/s
[Step=43800 Epoch=412.7] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.926 | L2-Norm(final)=7.653 | 2380.3 samples/s | 37.2 steps/s
[Step=43850 Epoch=413.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.909 | L2-Norm(final)=7.654 | 4207.3 samples/s | 65.7 steps/s
[Step=43900 Epoch=413.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.892 | L2-Norm(final)=7.656 | 2417.7 samples/s | 37.8 steps/s
[Step=43950 Epoch=414.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.875 | L2-Norm(final)=7.657 | 4209.5 samples/s | 65.8 steps/s
[Step=44000 Epoch=414.6] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.858 | L2-Norm(final)=7.658 | 2552.1 samples/s | 39.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step44000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=400.3] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.465 | L2-Norm(final)=8.212 | 6354.8 samples/s | 99.3 steps/s
[Step=42050 Epoch=400.8] | Loss=0.00004 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.464 | L2-Norm(final)=8.215 | 3680.6 samples/s | 57.5 steps/s
[Step=42100 Epoch=401.3] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.463 | L2-Norm(final)=8.217 | 7676.5 samples/s | 119.9 steps/s
[Step=42150 Epoch=401.7] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.463 | L2-Norm(final)=8.220 | 2118.5 samples/s | 33.1 steps/s
[Step=42200 Epoch=402.2] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.462 | L2-Norm(final)=8.222 | 6871.7 samples/s | 107.4 steps/s
[Step=42250 Epoch=402.7] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.461 | L2-Norm(final)=8.224 | 2171.6 samples/s | 33.9 steps/s
[Step=42300 Epoch=403.2] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.460 | L2-Norm(final)=8.226 | 6239.8 samples/s | 97.5 steps/s
[Step=42350 Epoch=403.6] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.459 | L2-Norm(final)=8.229 | 2268.7 samples/s | 35.4 steps/s
[Step=42400 Epoch=404.1] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.458 | L2-Norm(final)=8.231 | 5649.6 samples/s | 88.3 steps/s
[Step=42450 Epoch=404.6] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.457 | L2-Norm(final)=8.233 | 2328.4 samples/s | 36.4 steps/s
[Step=42500 Epoch=405.1] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.456 | L2-Norm(final)=8.235 | 5227.6 samples/s | 81.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=405.1] | Loss=0.00004 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.445 | L2-Norm(final)=8.257 | 5524.5 samples/s | 86.3 steps/s
[Step=42550 Epoch=405.5] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.441 | L2-Norm(final)=8.260 | 3734.7 samples/s | 58.4 steps/s
[Step=42600 Epoch=406.0] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.436 | L2-Norm(final)=8.262 | 6384.8 samples/s | 99.8 steps/s
[Step=42650 Epoch=406.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=8.263 | 2016.3 samples/s | 31.5 steps/s
[Step=42700 Epoch=407.0] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.422 | L2-Norm(final)=8.264 | 5692.9 samples/s | 89.0 steps/s
[Step=42750 Epoch=407.4] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.415 | L2-Norm(final)=8.265 | 2039.8 samples/s | 31.9 steps/s
[Step=42800 Epoch=407.9] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.408 | L2-Norm(final)=8.266 | 5378.1 samples/s | 84.0 steps/s
[Step=42850 Epoch=408.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.401 | L2-Norm(final)=8.267 | 2141.7 samples/s | 33.5 steps/s
[Step=42900 Epoch=408.9] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.393 | L2-Norm(final)=8.268 | 4929.2 samples/s | 77.0 steps/s
[Step=42950 Epoch=409.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.386 | L2-Norm(final)=8.269 | 2195.1 samples/s | 34.3 steps/s
[Step=43000 Epoch=409.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.378 | L2-Norm(final)=8.270 | 4573.1 samples/s | 71.5 steps/s
[Step=43050 Epoch=410.3] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.370 | L2-Norm(final)=8.271 | 2262.5 samples/s | 35.4 steps/s
[Step=43100 Epoch=410.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.363 | L2-Norm(final)=8.271 | 4288.5 samples/s | 67.0 steps/s
[Step=43150 Epoch=411.3] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.355 | L2-Norm(final)=8.272 | 2340.2 samples/s | 36.6 steps/s
[Step=43200 Epoch=411.7] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.347 | L2-Norm(final)=8.273 | 4274.9 samples/s | 66.8 steps/s
[Step=43250 Epoch=412.2] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.338 | L2-Norm(final)=8.273 | 2403.8 samples/s | 37.6 steps/s
[Step=43300 Epoch=412.7] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.330 | L2-Norm(final)=8.274 | 4220.1 samples/s | 65.9 steps/s
[Step=43350 Epoch=413.2] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=8.275 | 2404.9 samples/s | 37.6 steps/s
[Step=43400 Epoch=413.6] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.313 | L2-Norm(final)=8.275 | 4163.7 samples/s | 65.1 steps/s
[Step=43450 Epoch=414.1] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.305 | L2-Norm(final)=8.276 | 2413.6 samples/s | 37.7 steps/s
[Step=43500 Epoch=414.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.296 | L2-Norm(final)=8.277 | 4196.6 samples/s | 65.6 steps/s
[Step=43550 Epoch=415.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.288 | L2-Norm(final)=8.277 | 6984.6 samples/s | 109.1 steps/s
[Step=43600 Epoch=415.5] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.279 | L2-Norm(final)=8.278 | 1961.7 samples/s | 30.7 steps/s
[Step=43650 Epoch=416.0] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.270 | L2-Norm(final)=8.279 | 6369.3 samples/s | 99.5 steps/s
[Step=43700 Epoch=416.5] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.261 | L2-Norm(final)=8.279 | 2028.9 samples/s | 31.7 steps/s
[Step=43750 Epoch=417.0] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.252 | L2-Norm(final)=8.280 | 5767.3 samples/s | 90.1 steps/s
[Step=43800 Epoch=417.5] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.242 | L2-Norm(final)=8.280 | 2097.2 samples/s | 32.8 steps/s
[Step=43850 Epoch=417.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.233 | L2-Norm(final)=8.281 | 5264.0 samples/s | 82.3 steps/s
[Step=43900 Epoch=418.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.224 | L2-Norm(final)=8.282 | 2135.3 samples/s | 33.4 steps/s
[Step=43950 Epoch=418.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.214 | L2-Norm(final)=8.282 | 4988.2 samples/s | 77.9 steps/s
[Step=44000 Epoch=419.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.205 | L2-Norm(final)=8.283 | 2187.6 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11028 | acc=0.9611 | tpr=0.9750 | fpr=0.0691 | 4579.9 samples/s | 17.9 steps/s
Avg test loss: 0.11607, Avg test acc: 0.95853, Avg tpr: 0.97336, Avg fpr: 0.07409, total FA: 578

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11912 | acc=0.9597 | tpr=0.9725 | fpr=0.0681 | 4554.2 samples/s | 17.8 steps/s
Avg test loss: 0.12119, Avg test acc: 0.95821, Avg tpr: 0.97057, Avg fpr: 0.06897, total FA: 538

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10409 | acc=0.9590 | tpr=0.9732 | fpr=0.0719 | 4788.2 samples/s | 18.7 steps/s
Avg test loss: 0.10759, Avg test acc: 0.95845, Avg tpr: 0.97220, Avg fpr: 0.07179, total FA: 560

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.12358 | acc=0.9586 | tpr=0.9741 | fpr=0.0751 | 4745.6 samples/s | 18.5 steps/s
Avg test loss: 0.12914, Avg test acc: 0.95845, Avg tpr: 0.97441, Avg fpr: 0.07666, total FA: 598

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10951 | acc=0.9579 | tpr=0.9695 | fpr=0.0674 | 4815.5 samples/s | 18.8 steps/s
Avg test loss: 0.11745, Avg test acc: 0.95761, Avg tpr: 0.96952, Avg fpr: 0.06858, total FA: 535

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.32562 | acc=0.2885 | tpr=0.0202 | fpr=0.1288 | 4708.3 samples/s | 18.4 steps/s
Avg test loss: 5.32881, Avg test acc: 0.28792, Avg tpr: 0.02145, Avg fpr: 0.12601, total FA: 983

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.05858 | acc=0.2859 | tpr=0.0149 | fpr=0.1256 | 4718.8 samples/s | 18.4 steps/s
Avg test loss: 5.07254, Avg test acc: 0.28332, Avg tpr: 0.01527, Avg fpr: 0.12716, total FA: 992

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.64777 | acc=0.2711 | tpr=0.0197 | fpr=0.1831 | 4865.7 samples/s | 19.0 steps/s
Avg test loss: 5.64874, Avg test acc: 0.26873, Avg tpr: 0.02063, Avg fpr: 0.18562, total FA: 1448

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.58622 | acc=0.2905 | tpr=0.0201 | fpr=0.1222 | 3861.9 samples/s | 15.1 steps/s
Avg test loss: 5.57738, Avg test acc: 0.28788, Avg tpr: 0.02110, Avg fpr: 0.12537, total FA: 978

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.44021 | acc=0.2944 | tpr=0.0216 | fpr=0.1132 | 4434.4 samples/s | 17.3 steps/s
Avg test loss: 5.45115, Avg test acc: 0.29309, Avg tpr: 0.02261, Avg fpr: 0.11204, total FA: 874

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.09749 | acc=0.0954 | tpr=0.6416 | fpr=0.9144 | 3974.9 samples/s | 15.5 steps/s
[Step= 100] | Loss=6.07958 | acc=0.0968 | tpr=0.6162 | fpr=0.9129 | 7028.0 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.10223 | acc=0.0975 | tpr=0.6066 | fpr=0.9119 | 7529.8 samples/s | 29.4 steps/s
[Step= 200] | Loss=6.09995 | acc=0.0974 | tpr=0.6098 | fpr=0.9119 | 7927.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.10946 | acc=0.0979 | tpr=0.6096 | fpr=0.9114 | 7725.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=6.10540 | acc=0.0982 | tpr=0.6145 | fpr=0.9112 | 7746.6 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.10303 | acc=0.0986 | tpr=0.6193 | fpr=0.9108 | 8218.8 samples/s | 32.1 steps/s
[Step= 400] | Loss=6.09809 | acc=0.0992 | tpr=0.6193 | fpr=0.9102 | 7654.3 samples/s | 29.9 steps/s
[Step= 450] | Loss=6.10380 | acc=0.0993 | tpr=0.6217 | fpr=0.9102 | 7656.6 samples/s | 29.9 steps/s
[Step= 500] | Loss=6.10801 | acc=0.0991 | tpr=0.6194 | fpr=0.9103 | 8004.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.11112 | acc=0.0988 | tpr=0.6164 | fpr=0.9106 | 13851.6 samples/s | 54.1 steps/s
Avg test loss: 6.11296, Avg test acc: 0.09871, Avg tpr: 0.61648, Avg fpr: 0.91070, total FA: 126449

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.77246 | acc=0.1002 | tpr=0.4912 | fpr=0.9069 | 4157.9 samples/s | 16.2 steps/s
[Step= 100] | Loss=5.73840 | acc=0.1011 | tpr=0.5053 | fpr=0.9065 | 6575.0 samples/s | 25.7 steps/s
[Step= 150] | Loss=5.74052 | acc=0.1022 | tpr=0.5101 | fpr=0.9053 | 7666.7 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.73752 | acc=0.1022 | tpr=0.5027 | fpr=0.9051 | 7710.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.74860 | acc=0.1023 | tpr=0.4961 | fpr=0.9048 | 7940.5 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.74157 | acc=0.1021 | tpr=0.5025 | fpr=0.9052 | 7947.3 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.73740 | acc=0.1020 | tpr=0.5009 | fpr=0.9052 | 7455.3 samples/s | 29.1 steps/s
[Step= 400] | Loss=5.73187 | acc=0.1024 | tpr=0.5011 | fpr=0.9048 | 7778.2 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.73466 | acc=0.1022 | tpr=0.4961 | fpr=0.9049 | 8169.7 samples/s | 31.9 steps/s
[Step= 500] | Loss=5.74029 | acc=0.1020 | tpr=0.4934 | fpr=0.9051 | 7379.2 samples/s | 28.8 steps/s
[Step= 550] | Loss=5.74459 | acc=0.1019 | tpr=0.4899 | fpr=0.9052 | 14769.5 samples/s | 57.7 steps/s
Avg test loss: 5.74747, Avg test acc: 0.10175, Avg tpr: 0.48970, Avg fpr: 0.90530, total FA: 125699

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.05380 | acc=0.0837 | tpr=0.4558 | fpr=0.9230 | 3943.0 samples/s | 15.4 steps/s
[Step= 100] | Loss=6.02491 | acc=0.0848 | tpr=0.4499 | fpr=0.9220 | 7148.2 samples/s | 27.9 steps/s
[Step= 150] | Loss=6.03773 | acc=0.0852 | tpr=0.4481 | fpr=0.9215 | 7680.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.03521 | acc=0.0849 | tpr=0.4470 | fpr=0.9217 | 7457.0 samples/s | 29.1 steps/s
[Step= 250] | Loss=6.03487 | acc=0.0856 | tpr=0.4480 | fpr=0.9210 | 7911.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.03149 | acc=0.0859 | tpr=0.4538 | fpr=0.9208 | 7993.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.02464 | acc=0.0865 | tpr=0.4571 | fpr=0.9203 | 7897.1 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.01781 | acc=0.0871 | tpr=0.4584 | fpr=0.9197 | 7779.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.01981 | acc=0.0870 | tpr=0.4547 | fpr=0.9196 | 7846.2 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.02247 | acc=0.0869 | tpr=0.4515 | fpr=0.9197 | 7573.6 samples/s | 29.6 steps/s
[Step= 550] | Loss=6.02400 | acc=0.0868 | tpr=0.4481 | fpr=0.9198 | 14790.3 samples/s | 57.8 steps/s
Avg test loss: 6.02529, Avg test acc: 0.08668, Avg tpr: 0.44889, Avg fpr: 0.91991, total FA: 127727

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.44704 | acc=0.0978 | tpr=0.6637 | fpr=0.9124 | 4748.2 samples/s | 18.5 steps/s
[Step= 100] | Loss=6.42537 | acc=0.0990 | tpr=0.6418 | fpr=0.9111 | 7092.5 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.43239 | acc=0.0999 | tpr=0.6441 | fpr=0.9101 | 7879.1 samples/s | 30.8 steps/s
[Step= 200] | Loss=6.42287 | acc=0.0998 | tpr=0.6372 | fpr=0.9100 | 7875.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.42798 | acc=0.1003 | tpr=0.6358 | fpr=0.9095 | 7837.3 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.42378 | acc=0.1002 | tpr=0.6364 | fpr=0.9096 | 7962.9 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.41555 | acc=0.1004 | tpr=0.6381 | fpr=0.9093 | 7765.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.40743 | acc=0.1008 | tpr=0.6329 | fpr=0.9089 | 7654.5 samples/s | 29.9 steps/s
[Step= 450] | Loss=6.41388 | acc=0.1007 | tpr=0.6295 | fpr=0.9089 | 7916.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.41618 | acc=0.1004 | tpr=0.6286 | fpr=0.9092 | 8228.5 samples/s | 32.1 steps/s
[Step= 550] | Loss=6.41923 | acc=0.1002 | tpr=0.6271 | fpr=0.9093 | 12964.8 samples/s | 50.6 steps/s
Avg test loss: 6.42036, Avg test acc: 0.10015, Avg tpr: 0.62718, Avg fpr: 0.90943, total FA: 126272

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.95687 | acc=0.0904 | tpr=0.5177 | fpr=0.9173 | 4554.1 samples/s | 17.8 steps/s
[Step= 100] | Loss=5.93616 | acc=0.0925 | tpr=0.5224 | fpr=0.9156 | 7184.3 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.93820 | acc=0.0921 | tpr=0.5159 | fpr=0.9157 | 7682.3 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.94015 | acc=0.0916 | tpr=0.4951 | fpr=0.9157 | 7971.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.95017 | acc=0.0917 | tpr=0.4926 | fpr=0.9156 | 7658.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.95147 | acc=0.0918 | tpr=0.4975 | fpr=0.9156 | 7749.8 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.94204 | acc=0.0924 | tpr=0.5028 | fpr=0.9150 | 7711.4 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.93794 | acc=0.0931 | tpr=0.5027 | fpr=0.9143 | 8014.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.93942 | acc=0.0932 | tpr=0.5049 | fpr=0.9143 | 7853.9 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.93875 | acc=0.0931 | tpr=0.5026 | fpr=0.9143 | 7957.1 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.94265 | acc=0.0932 | tpr=0.5070 | fpr=0.9143 | 13665.0 samples/s | 53.4 steps/s
Avg test loss: 5.94464, Avg test acc: 0.09313, Avg tpr: 0.50674, Avg fpr: 0.91439, total FA: 126961

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10212 | acc=0.9814 | tpr=0.9381 | fpr=0.0178 | 4805.0 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.10381 | acc=0.9816 | tpr=0.9424 | fpr=0.0176 | 7228.1 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.10752 | acc=0.9810 | tpr=0.9424 | fpr=0.0183 | 7653.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.10928 | acc=0.9811 | tpr=0.9464 | fpr=0.0182 | 8042.0 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.10671 | acc=0.9814 | tpr=0.9415 | fpr=0.0179 | 7620.0 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.10951 | acc=0.9810 | tpr=0.9389 | fpr=0.0182 | 7631.8 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.11092 | acc=0.9807 | tpr=0.9399 | fpr=0.0185 | 8346.5 samples/s | 32.6 steps/s
[Step= 400] | Loss=0.11190 | acc=0.9805 | tpr=0.9360 | fpr=0.0187 | 7551.7 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.11379 | acc=0.9801 | tpr=0.9338 | fpr=0.0190 | 8010.6 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.11275 | acc=0.9802 | tpr=0.9344 | fpr=0.0189 | 7990.2 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.11239 | acc=0.9804 | tpr=0.9324 | fpr=0.0187 | 13592.8 samples/s | 53.1 steps/s
Avg test loss: 0.11228, Avg test acc: 0.98042, Avg tpr: 0.93265, Avg fpr: 0.01871, total FA: 2598

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10558 | acc=0.9817 | tpr=0.9248 | fpr=0.0173 | 4832.4 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.10926 | acc=0.9814 | tpr=0.9211 | fpr=0.0175 | 6961.3 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.11279 | acc=0.9809 | tpr=0.9207 | fpr=0.0180 | 7794.5 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.11529 | acc=0.9807 | tpr=0.9224 | fpr=0.0182 | 7978.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.11329 | acc=0.9810 | tpr=0.9240 | fpr=0.0180 | 7751.4 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.11637 | acc=0.9806 | tpr=0.9207 | fpr=0.0183 | 7814.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.11709 | acc=0.9804 | tpr=0.9249 | fpr=0.0186 | 8118.5 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.11835 | acc=0.9803 | tpr=0.9190 | fpr=0.0186 | 7650.7 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.12099 | acc=0.9801 | tpr=0.9187 | fpr=0.0188 | 7994.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.11985 | acc=0.9802 | tpr=0.9207 | fpr=0.0187 | 7669.2 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.11961 | acc=0.9804 | tpr=0.9204 | fpr=0.0185 | 14311.9 samples/s | 55.9 steps/s
Avg test loss: 0.11947, Avg test acc: 0.98045, Avg tpr: 0.92076, Avg fpr: 0.01847, total FA: 2564

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10072 | acc=0.9799 | tpr=0.9513 | fpr=0.0196 | 4741.1 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.10409 | acc=0.9802 | tpr=0.9531 | fpr=0.0193 | 7193.2 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.10822 | acc=0.9795 | tpr=0.9539 | fpr=0.0200 | 7627.9 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.10998 | acc=0.9797 | tpr=0.9563 | fpr=0.0199 | 8138.2 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.10852 | acc=0.9798 | tpr=0.9563 | fpr=0.0198 | 7779.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11149 | acc=0.9794 | tpr=0.9498 | fpr=0.0200 | 8218.7 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.11224 | acc=0.9793 | tpr=0.9505 | fpr=0.0201 | 7436.4 samples/s | 29.0 steps/s
[Step= 400] | Loss=0.11331 | acc=0.9792 | tpr=0.9502 | fpr=0.0202 | 7895.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11520 | acc=0.9791 | tpr=0.9503 | fpr=0.0204 | 8123.6 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.11445 | acc=0.9791 | tpr=0.9524 | fpr=0.0204 | 7796.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.11397 | acc=0.9792 | tpr=0.9507 | fpr=0.0202 | 14497.1 samples/s | 56.6 steps/s
Avg test loss: 0.11386, Avg test acc: 0.97925, Avg tpr: 0.95087, Avg fpr: 0.02023, total FA: 2809

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09795 | acc=0.9815 | tpr=0.9425 | fpr=0.0178 | 4358.0 samples/s | 17.0 steps/s
[Step= 100] | Loss=0.10233 | acc=0.9809 | tpr=0.9382 | fpr=0.0183 | 9067.4 samples/s | 35.4 steps/s
[Step= 150] | Loss=0.10704 | acc=0.9799 | tpr=0.9395 | fpr=0.0194 | 6930.6 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.10841 | acc=0.9800 | tpr=0.9475 | fpr=0.0194 | 8004.7 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.10677 | acc=0.9805 | tpr=0.9476 | fpr=0.0189 | 8282.3 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.10940 | acc=0.9802 | tpr=0.9433 | fpr=0.0192 | 7787.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.11010 | acc=0.9800 | tpr=0.9436 | fpr=0.0193 | 7922.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.11060 | acc=0.9799 | tpr=0.9415 | fpr=0.0194 | 7770.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.11280 | acc=0.9797 | tpr=0.9396 | fpr=0.0196 | 8072.1 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.11193 | acc=0.9797 | tpr=0.9414 | fpr=0.0196 | 7488.7 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.11160 | acc=0.9799 | tpr=0.9415 | fpr=0.0194 | 15395.7 samples/s | 60.1 steps/s
Avg test loss: 0.11151, Avg test acc: 0.97989, Avg tpr: 0.94176, Avg fpr: 0.01942, total FA: 2696

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.11156 | acc=0.9812 | tpr=0.9381 | fpr=0.0181 | 4665.4 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.11663 | acc=0.9803 | tpr=0.9318 | fpr=0.0188 | 7456.0 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.12067 | acc=0.9791 | tpr=0.9323 | fpr=0.0200 | 7796.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.12290 | acc=0.9789 | tpr=0.9377 | fpr=0.0204 | 7860.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12155 | acc=0.9793 | tpr=0.9336 | fpr=0.0198 | 7883.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.12437 | acc=0.9790 | tpr=0.9280 | fpr=0.0200 | 7865.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.12510 | acc=0.9789 | tpr=0.9305 | fpr=0.0202 | 7989.9 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.12641 | acc=0.9786 | tpr=0.9278 | fpr=0.0204 | 7726.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.12908 | acc=0.9784 | tpr=0.9270 | fpr=0.0206 | 7847.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.12813 | acc=0.9786 | tpr=0.9278 | fpr=0.0205 | 8179.9 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.12769 | acc=0.9787 | tpr=0.9264 | fpr=0.0204 | 13350.6 samples/s | 52.2 steps/s
Avg test loss: 0.12749, Avg test acc: 0.97872, Avg tpr: 0.92670, Avg fpr: 0.02034, total FA: 2824

server round 22/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=214.6] | Loss=0.00641 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.649 | L2-Norm(final)=12.946 | 5242.0 samples/s | 81.9 steps/s
[Step=44050 Epoch=214.8] | Loss=0.00263 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.644 | L2-Norm(final)=12.952 | 4566.8 samples/s | 71.4 steps/s
[Step=44100 Epoch=215.0] | Loss=0.00327 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.642 | L2-Norm(final)=12.960 | 4883.6 samples/s | 76.3 steps/s
[Step=44150 Epoch=215.3] | Loss=0.00278 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.640 | L2-Norm(final)=12.970 | 5127.6 samples/s | 80.1 steps/s
[Step=44200 Epoch=215.5] | Loss=0.00289 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.637 | L2-Norm(final)=12.979 | 7763.1 samples/s | 121.3 steps/s
[Step=44250 Epoch=215.8] | Loss=0.00288 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.634 | L2-Norm(final)=12.989 | 2232.9 samples/s | 34.9 steps/s
[Step=44300 Epoch=216.0] | Loss=0.00273 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.630 | L2-Norm(final)=12.997 | 4880.6 samples/s | 76.3 steps/s
[Step=44350 Epoch=216.3] | Loss=0.00267 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.626 | L2-Norm(final)=13.006 | 5087.6 samples/s | 79.5 steps/s
[Step=44400 Epoch=216.5] | Loss=0.00267 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.623 | L2-Norm(final)=13.015 | 6642.4 samples/s | 103.8 steps/s
[Step=44450 Epoch=216.7] | Loss=0.00261 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=13.024 | 2237.5 samples/s | 35.0 steps/s
[Step=44500 Epoch=217.0] | Loss=0.00257 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=13.033 | 5014.7 samples/s | 78.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=217.0] | Loss=0.00018 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.571 | L2-Norm(final)=13.121 | 5776.0 samples/s | 90.2 steps/s
[Step=44550 Epoch=217.2] | Loss=0.00340 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.569 | L2-Norm(final)=13.129 | 3832.8 samples/s | 59.9 steps/s
[Step=44600 Epoch=217.5] | Loss=0.00424 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.567 | L2-Norm(final)=13.134 | 4457.7 samples/s | 69.7 steps/s
[Step=44650 Epoch=217.7] | Loss=0.00459 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.567 | L2-Norm(final)=13.139 | 4481.5 samples/s | 70.0 steps/s
[Step=44700 Epoch=218.0] | Loss=0.00513 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.568 | L2-Norm(final)=13.144 | 6530.6 samples/s | 102.0 steps/s
[Step=44750 Epoch=218.2] | Loss=0.00576 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.572 | L2-Norm(final)=13.149 | 2081.7 samples/s | 32.5 steps/s
[Step=44800 Epoch=218.5] | Loss=0.00599 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.581 | L2-Norm(final)=13.155 | 4568.5 samples/s | 71.4 steps/s
[Step=44850 Epoch=218.7] | Loss=0.00659 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.591 | L2-Norm(final)=13.161 | 4344.3 samples/s | 67.9 steps/s
[Step=44900 Epoch=218.9] | Loss=0.00662 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.601 | L2-Norm(final)=13.167 | 5896.3 samples/s | 92.1 steps/s
[Step=44950 Epoch=219.2] | Loss=0.00668 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.611 | L2-Norm(final)=13.174 | 2157.5 samples/s | 33.7 steps/s
[Step=45000 Epoch=219.4] | Loss=0.00648 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.620 | L2-Norm(final)=13.179 | 4470.8 samples/s | 69.9 steps/s
[Step=45050 Epoch=219.7] | Loss=0.00623 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.627 | L2-Norm(final)=13.185 | 4512.4 samples/s | 70.5 steps/s
[Step=45100 Epoch=219.9] | Loss=0.00603 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.632 | L2-Norm(final)=13.190 | 5266.5 samples/s | 82.3 steps/s
[Step=45150 Epoch=220.2] | Loss=0.00587 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.637 | L2-Norm(final)=13.196 | 2257.1 samples/s | 35.3 steps/s
[Step=45200 Epoch=220.4] | Loss=0.00569 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.641 | L2-Norm(final)=13.201 | 4446.8 samples/s | 69.5 steps/s
[Step=45250 Epoch=220.6] | Loss=0.00549 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.643 | L2-Norm(final)=13.205 | 4530.8 samples/s | 70.8 steps/s
[Step=45300 Epoch=220.9] | Loss=0.00530 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.645 | L2-Norm(final)=13.210 | 4926.3 samples/s | 77.0 steps/s
[Step=45350 Epoch=221.1] | Loss=0.00511 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.646 | L2-Norm(final)=13.214 | 2305.3 samples/s | 36.0 steps/s
[Step=45400 Epoch=221.4] | Loss=0.00497 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.647 | L2-Norm(final)=13.218 | 4444.2 samples/s | 69.4 steps/s
[Step=45450 Epoch=221.6] | Loss=0.00483 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.647 | L2-Norm(final)=13.221 | 4389.9 samples/s | 68.6 steps/s
[Step=45500 Epoch=221.9] | Loss=0.00470 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.647 | L2-Norm(final)=13.225 | 4635.0 samples/s | 72.4 steps/s
[Step=45550 Epoch=222.1] | Loss=0.00464 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.646 | L2-Norm(final)=13.228 | 2416.9 samples/s | 37.8 steps/s
[Step=45600 Epoch=222.4] | Loss=0.00449 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.645 | L2-Norm(final)=13.232 | 4401.1 samples/s | 68.8 steps/s
[Step=45650 Epoch=222.6] | Loss=0.00438 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.643 | L2-Norm(final)=13.235 | 4540.1 samples/s | 70.9 steps/s
[Step=45700 Epoch=222.8] | Loss=0.00432 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.642 | L2-Norm(final)=13.238 | 4366.1 samples/s | 68.2 steps/s
[Step=45750 Epoch=223.1] | Loss=0.00427 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.639 | L2-Norm(final)=13.241 | 2422.7 samples/s | 37.9 steps/s
[Step=45800 Epoch=223.3] | Loss=0.00421 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.637 | L2-Norm(final)=13.244 | 4456.0 samples/s | 69.6 steps/s
[Step=45850 Epoch=223.6] | Loss=0.00416 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.634 | L2-Norm(final)=13.247 | 4483.2 samples/s | 70.0 steps/s
[Step=45900 Epoch=223.8] | Loss=0.00408 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.631 | L2-Norm(final)=13.249 | 4477.1 samples/s | 70.0 steps/s
[Step=45950 Epoch=224.1] | Loss=0.00401 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.628 | L2-Norm(final)=13.252 | 2478.2 samples/s | 38.7 steps/s
[Step=46000 Epoch=224.3] | Loss=0.00394 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.625 | L2-Norm(final)=13.254 | 4503.7 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step46000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=214.7] | Loss=0.00046 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=13.170 | 4963.9 samples/s | 77.6 steps/s
[Step=44050 Epoch=214.9] | Loss=0.00283 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.610 | L2-Norm(final)=13.177 | 4609.9 samples/s | 72.0 steps/s
[Step=44100 Epoch=215.2] | Loss=0.00212 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.604 | L2-Norm(final)=13.184 | 4885.9 samples/s | 76.3 steps/s
[Step=44150 Epoch=215.4] | Loss=0.00227 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.599 | L2-Norm(final)=13.191 | 5138.3 samples/s | 80.3 steps/s
[Step=44200 Epoch=215.7] | Loss=0.00233 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.594 | L2-Norm(final)=13.198 | 7679.4 samples/s | 120.0 steps/s
[Step=44250 Epoch=215.9] | Loss=0.00226 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.590 | L2-Norm(final)=13.206 | 2195.9 samples/s | 34.3 steps/s
[Step=44300 Epoch=216.2] | Loss=0.00222 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.585 | L2-Norm(final)=13.214 | 5118.7 samples/s | 80.0 steps/s
[Step=44350 Epoch=216.4] | Loss=0.00212 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.580 | L2-Norm(final)=13.222 | 5009.3 samples/s | 78.3 steps/s
[Step=44400 Epoch=216.7] | Loss=0.00216 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.574 | L2-Norm(final)=13.230 | 6979.8 samples/s | 109.1 steps/s
[Step=44450 Epoch=216.9] | Loss=0.00215 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.568 | L2-Norm(final)=13.237 | 2269.6 samples/s | 35.5 steps/s
[Step=44500 Epoch=217.1] | Loss=0.00212 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.563 | L2-Norm(final)=13.245 | 4971.5 samples/s | 77.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=217.1] | Loss=0.00025 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.503 | L2-Norm(final)=13.321 | 5577.8 samples/s | 87.2 steps/s
[Step=44550 Epoch=217.4] | Loss=0.00352 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.499 | L2-Norm(final)=13.327 | 3919.2 samples/s | 61.2 steps/s
[Step=44600 Epoch=217.6] | Loss=0.00292 | Reg=0.00306 | acc=0.9844 | L2-Norm=17.498 | L2-Norm(final)=13.334 | 4455.4 samples/s | 69.6 steps/s
[Step=44650 Epoch=217.9] | Loss=0.00298 | Reg=0.00306 | acc=0.9844 | L2-Norm=17.496 | L2-Norm(final)=13.341 | 4486.9 samples/s | 70.1 steps/s
[Step=44700 Epoch=218.1] | Loss=0.00436 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.497 | L2-Norm(final)=13.347 | 6559.5 samples/s | 102.5 steps/s
[Step=44750 Epoch=218.4] | Loss=0.00464 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.503 | L2-Norm(final)=13.352 | 2095.2 samples/s | 32.7 steps/s
[Step=44800 Epoch=218.6] | Loss=0.00505 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.507 | L2-Norm(final)=13.358 | 4466.9 samples/s | 69.8 steps/s
[Step=44850 Epoch=218.8] | Loss=0.00553 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.511 | L2-Norm(final)=13.363 | 4449.3 samples/s | 69.5 steps/s
[Step=44900 Epoch=219.1] | Loss=0.00538 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.516 | L2-Norm(final)=13.369 | 5961.1 samples/s | 93.1 steps/s
[Step=44950 Epoch=219.3] | Loss=0.00523 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.521 | L2-Norm(final)=13.374 | 2158.8 samples/s | 33.7 steps/s
[Step=45000 Epoch=219.6] | Loss=0.00527 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.526 | L2-Norm(final)=13.380 | 4466.4 samples/s | 69.8 steps/s
[Step=45050 Epoch=219.8] | Loss=0.00508 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.530 | L2-Norm(final)=13.386 | 4498.1 samples/s | 70.3 steps/s
[Step=45100 Epoch=220.1] | Loss=0.00490 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.533 | L2-Norm(final)=13.392 | 5588.6 samples/s | 87.3 steps/s
[Step=45150 Epoch=220.3] | Loss=0.00488 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.535 | L2-Norm(final)=13.398 | 2187.3 samples/s | 34.2 steps/s
[Step=45200 Epoch=220.6] | Loss=0.00481 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.537 | L2-Norm(final)=13.403 | 4476.9 samples/s | 70.0 steps/s
[Step=45250 Epoch=220.8] | Loss=0.00459 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.539 | L2-Norm(final)=13.408 | 4448.6 samples/s | 69.5 steps/s
[Step=45300 Epoch=221.0] | Loss=0.00444 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.540 | L2-Norm(final)=13.413 | 5214.0 samples/s | 81.5 steps/s
[Step=45350 Epoch=221.3] | Loss=0.00435 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.540 | L2-Norm(final)=13.418 | 2281.5 samples/s | 35.6 steps/s
[Step=45400 Epoch=221.5] | Loss=0.00424 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.539 | L2-Norm(final)=13.422 | 4457.9 samples/s | 69.7 steps/s
[Step=45450 Epoch=221.8] | Loss=0.00412 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.539 | L2-Norm(final)=13.426 | 4457.3 samples/s | 69.6 steps/s
[Step=45500 Epoch=222.0] | Loss=0.00405 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.537 | L2-Norm(final)=13.431 | 4781.6 samples/s | 74.7 steps/s
[Step=45550 Epoch=222.3] | Loss=0.00396 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.536 | L2-Norm(final)=13.434 | 2328.5 samples/s | 36.4 steps/s
[Step=45600 Epoch=222.5] | Loss=0.00392 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.534 | L2-Norm(final)=13.438 | 4489.8 samples/s | 70.2 steps/s
[Step=45650 Epoch=222.8] | Loss=0.00386 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.531 | L2-Norm(final)=13.442 | 4447.8 samples/s | 69.5 steps/s
[Step=45700 Epoch=223.0] | Loss=0.00376 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.529 | L2-Norm(final)=13.445 | 4548.3 samples/s | 71.1 steps/s
[Step=45750 Epoch=223.2] | Loss=0.00366 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.526 | L2-Norm(final)=13.449 | 2404.1 samples/s | 37.6 steps/s
[Step=45800 Epoch=223.5] | Loss=0.00357 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.522 | L2-Norm(final)=13.452 | 4483.8 samples/s | 70.1 steps/s
[Step=45850 Epoch=223.7] | Loss=0.00354 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.519 | L2-Norm(final)=13.455 | 4402.2 samples/s | 68.8 steps/s
[Step=45900 Epoch=224.0] | Loss=0.00346 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.515 | L2-Norm(final)=13.458 | 4433.5 samples/s | 69.3 steps/s
[Step=45950 Epoch=224.2] | Loss=0.00340 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.511 | L2-Norm(final)=13.461 | 2452.3 samples/s | 38.3 steps/s
[Step=46000 Epoch=224.5] | Loss=0.00333 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.507 | L2-Norm(final)=13.464 | 4458.5 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step46000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=214.4] | Loss=0.00278 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.150 | L2-Norm(final)=13.598 | 5659.3 samples/s | 88.4 steps/s
[Step=44050 Epoch=214.6] | Loss=0.00202 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.145 | L2-Norm(final)=13.603 | 4242.3 samples/s | 66.3 steps/s
[Step=44100 Epoch=214.9] | Loss=0.00247 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.140 | L2-Norm(final)=13.610 | 4996.4 samples/s | 78.1 steps/s
[Step=44150 Epoch=215.1] | Loss=0.00285 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.136 | L2-Norm(final)=13.616 | 5019.1 samples/s | 78.4 steps/s
[Step=44200 Epoch=215.4] | Loss=0.00276 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.132 | L2-Norm(final)=13.623 | 7717.8 samples/s | 120.6 steps/s
[Step=44250 Epoch=215.6] | Loss=0.00261 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.128 | L2-Norm(final)=13.630 | 2172.9 samples/s | 34.0 steps/s
[Step=44300 Epoch=215.9] | Loss=0.00270 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=13.638 | 5104.6 samples/s | 79.8 steps/s
[Step=44350 Epoch=216.1] | Loss=0.00267 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.120 | L2-Norm(final)=13.645 | 5169.2 samples/s | 80.8 steps/s
[Step=44400 Epoch=216.3] | Loss=0.00269 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.115 | L2-Norm(final)=13.652 | 6642.0 samples/s | 103.8 steps/s
[Step=44450 Epoch=216.6] | Loss=0.00263 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.111 | L2-Norm(final)=13.660 | 2305.2 samples/s | 36.0 steps/s
[Step=44500 Epoch=216.8] | Loss=0.00261 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.106 | L2-Norm(final)=13.667 | 4982.2 samples/s | 77.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=216.8] | Loss=0.01465 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.061 | L2-Norm(final)=13.741 | 5560.1 samples/s | 86.9 steps/s
[Step=44550 Epoch=217.1] | Loss=0.00319 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.058 | L2-Norm(final)=13.748 | 3871.3 samples/s | 60.5 steps/s
[Step=44600 Epoch=217.3] | Loss=0.00376 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.057 | L2-Norm(final)=13.755 | 4482.1 samples/s | 70.0 steps/s
[Step=44650 Epoch=217.6] | Loss=0.00488 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.056 | L2-Norm(final)=13.759 | 4492.4 samples/s | 70.2 steps/s
[Step=44700 Epoch=217.8] | Loss=0.00568 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.062 | L2-Norm(final)=13.766 | 6543.0 samples/s | 102.2 steps/s
[Step=44750 Epoch=218.0] | Loss=0.00612 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.069 | L2-Norm(final)=13.772 | 2092.7 samples/s | 32.7 steps/s
[Step=44800 Epoch=218.3] | Loss=0.00598 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.076 | L2-Norm(final)=13.779 | 4504.4 samples/s | 70.4 steps/s
[Step=44850 Epoch=218.5] | Loss=0.00593 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.083 | L2-Norm(final)=13.785 | 4447.7 samples/s | 69.5 steps/s
[Step=44900 Epoch=218.8] | Loss=0.00590 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.089 | L2-Norm(final)=13.792 | 5777.7 samples/s | 90.3 steps/s
[Step=44950 Epoch=219.0] | Loss=0.00556 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.093 | L2-Norm(final)=13.798 | 2145.8 samples/s | 33.5 steps/s
[Step=45000 Epoch=219.3] | Loss=0.00520 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.096 | L2-Norm(final)=13.804 | 4464.9 samples/s | 69.8 steps/s
[Step=45050 Epoch=219.5] | Loss=0.00503 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.098 | L2-Norm(final)=13.810 | 4428.8 samples/s | 69.2 steps/s
[Step=45100 Epoch=219.7] | Loss=0.00497 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.099 | L2-Norm(final)=13.815 | 5389.6 samples/s | 84.2 steps/s
[Step=45150 Epoch=220.0] | Loss=0.00497 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.101 | L2-Norm(final)=13.820 | 2243.6 samples/s | 35.1 steps/s
[Step=45200 Epoch=220.2] | Loss=0.00511 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.102 | L2-Norm(final)=13.825 | 4422.8 samples/s | 69.1 steps/s
[Step=45250 Epoch=220.5] | Loss=0.00502 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.103 | L2-Norm(final)=13.829 | 4387.7 samples/s | 68.6 steps/s
[Step=45300 Epoch=220.7] | Loss=0.00488 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.104 | L2-Norm(final)=13.833 | 4991.2 samples/s | 78.0 steps/s
[Step=45350 Epoch=221.0] | Loss=0.00478 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.104 | L2-Norm(final)=13.837 | 2331.4 samples/s | 36.4 steps/s
[Step=45400 Epoch=221.2] | Loss=0.00464 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.104 | L2-Norm(final)=13.841 | 4472.8 samples/s | 69.9 steps/s
[Step=45450 Epoch=221.5] | Loss=0.00455 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.103 | L2-Norm(final)=13.845 | 4504.2 samples/s | 70.4 steps/s
[Step=45500 Epoch=221.7] | Loss=0.00444 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.102 | L2-Norm(final)=13.849 | 4600.0 samples/s | 71.9 steps/s
[Step=45550 Epoch=221.9] | Loss=0.00439 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.101 | L2-Norm(final)=13.853 | 2388.9 samples/s | 37.3 steps/s
[Step=45600 Epoch=222.2] | Loss=0.00426 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.099 | L2-Norm(final)=13.856 | 4451.4 samples/s | 69.6 steps/s
[Step=45650 Epoch=222.4] | Loss=0.00426 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.097 | L2-Norm(final)=13.859 | 4573.2 samples/s | 71.5 steps/s
[Step=45700 Epoch=222.7] | Loss=0.00419 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=13.863 | 4447.0 samples/s | 69.5 steps/s
[Step=45750 Epoch=222.9] | Loss=0.00413 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.093 | L2-Norm(final)=13.866 | 2510.6 samples/s | 39.2 steps/s
[Step=45800 Epoch=223.2] | Loss=0.00404 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.090 | L2-Norm(final)=13.869 | 4380.2 samples/s | 68.4 steps/s
[Step=45850 Epoch=223.4] | Loss=0.00398 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.087 | L2-Norm(final)=13.872 | 4421.4 samples/s | 69.1 steps/s
[Step=45900 Epoch=223.6] | Loss=0.00393 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.084 | L2-Norm(final)=13.875 | 4503.3 samples/s | 70.4 steps/s
[Step=45950 Epoch=223.9] | Loss=0.00387 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.081 | L2-Norm(final)=13.878 | 2362.6 samples/s | 36.9 steps/s
[Step=46000 Epoch=224.1] | Loss=0.00379 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.077 | L2-Norm(final)=13.881 | 4500.1 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step46000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=214.6] | Loss=0.00340 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.768 | L2-Norm(final)=13.481 | 5206.2 samples/s | 81.3 steps/s
[Step=44050 Epoch=214.8] | Loss=0.00206 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.763 | L2-Norm(final)=13.488 | 4676.1 samples/s | 73.1 steps/s
[Step=44100 Epoch=215.1] | Loss=0.00218 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.760 | L2-Norm(final)=13.497 | 4895.7 samples/s | 76.5 steps/s
[Step=44150 Epoch=215.3] | Loss=0.00215 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.757 | L2-Norm(final)=13.506 | 5138.4 samples/s | 80.3 steps/s
[Step=44200 Epoch=215.5] | Loss=0.00218 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.754 | L2-Norm(final)=13.514 | 7661.0 samples/s | 119.7 steps/s
[Step=44250 Epoch=215.8] | Loss=0.00210 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.750 | L2-Norm(final)=13.523 | 2197.9 samples/s | 34.3 steps/s
[Step=44300 Epoch=216.0] | Loss=0.00208 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.746 | L2-Norm(final)=13.531 | 5116.4 samples/s | 79.9 steps/s
[Step=44350 Epoch=216.3] | Loss=0.00205 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.742 | L2-Norm(final)=13.540 | 4990.7 samples/s | 78.0 steps/s
[Step=44400 Epoch=216.5] | Loss=0.00207 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.738 | L2-Norm(final)=13.549 | 6975.3 samples/s | 109.0 steps/s
[Step=44450 Epoch=216.8] | Loss=0.00207 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.733 | L2-Norm(final)=13.557 | 2304.5 samples/s | 36.0 steps/s
[Step=44500 Epoch=217.0] | Loss=0.00206 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.728 | L2-Norm(final)=13.565 | 5012.7 samples/s | 78.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=217.0] | Loss=0.00036 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.679 | L2-Norm(final)=13.651 | 5694.5 samples/s | 89.0 steps/s
[Step=44550 Epoch=217.3] | Loss=0.00253 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.675 | L2-Norm(final)=13.658 | 3879.0 samples/s | 60.6 steps/s
[Step=44600 Epoch=217.5] | Loss=0.00362 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.675 | L2-Norm(final)=13.665 | 4382.3 samples/s | 68.5 steps/s
[Step=44650 Epoch=217.7] | Loss=0.00495 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.682 | L2-Norm(final)=13.672 | 4486.5 samples/s | 70.1 steps/s
[Step=44700 Epoch=218.0] | Loss=0.00590 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.692 | L2-Norm(final)=13.679 | 6521.7 samples/s | 101.9 steps/s
[Step=44750 Epoch=218.2] | Loss=0.00904 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.709 | L2-Norm(final)=13.685 | 2122.1 samples/s | 33.2 steps/s
[Step=44800 Epoch=218.5] | Loss=0.00907 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.727 | L2-Norm(final)=13.691 | 4344.4 samples/s | 67.9 steps/s
[Step=44850 Epoch=218.7] | Loss=0.00898 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.742 | L2-Norm(final)=13.697 | 4508.6 samples/s | 70.4 steps/s
[Step=44900 Epoch=219.0] | Loss=0.00850 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.754 | L2-Norm(final)=13.703 | 5886.0 samples/s | 92.0 steps/s
[Step=44950 Epoch=219.2] | Loss=0.00792 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.764 | L2-Norm(final)=13.709 | 2151.5 samples/s | 33.6 steps/s
[Step=45000 Epoch=219.4] | Loss=0.00737 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.772 | L2-Norm(final)=13.714 | 4464.0 samples/s | 69.7 steps/s
[Step=45050 Epoch=219.7] | Loss=0.00700 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.777 | L2-Norm(final)=13.720 | 4460.2 samples/s | 69.7 steps/s
[Step=45100 Epoch=219.9] | Loss=0.00674 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.781 | L2-Norm(final)=13.724 | 5377.1 samples/s | 84.0 steps/s
[Step=45150 Epoch=220.2] | Loss=0.00636 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.785 | L2-Norm(final)=13.729 | 2235.5 samples/s | 34.9 steps/s
[Step=45200 Epoch=220.4] | Loss=0.00601 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.787 | L2-Norm(final)=13.733 | 4466.7 samples/s | 69.8 steps/s
[Step=45250 Epoch=220.7] | Loss=0.00579 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.788 | L2-Norm(final)=13.738 | 4526.0 samples/s | 70.7 steps/s
[Step=45300 Epoch=220.9] | Loss=0.00555 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.789 | L2-Norm(final)=13.742 | 4901.6 samples/s | 76.6 steps/s
[Step=45350 Epoch=221.2] | Loss=0.00538 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.789 | L2-Norm(final)=13.745 | 2303.8 samples/s | 36.0 steps/s
[Step=45400 Epoch=221.4] | Loss=0.00520 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.789 | L2-Norm(final)=13.749 | 4348.2 samples/s | 67.9 steps/s
[Step=45450 Epoch=221.6] | Loss=0.00503 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.788 | L2-Norm(final)=13.752 | 4515.2 samples/s | 70.5 steps/s
[Step=45500 Epoch=221.9] | Loss=0.00487 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.787 | L2-Norm(final)=13.755 | 4623.2 samples/s | 72.2 steps/s
[Step=45550 Epoch=222.1] | Loss=0.00475 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.786 | L2-Norm(final)=13.758 | 2436.4 samples/s | 38.1 steps/s
[Step=45600 Epoch=222.4] | Loss=0.00459 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.784 | L2-Norm(final)=13.761 | 4478.8 samples/s | 70.0 steps/s
[Step=45650 Epoch=222.6] | Loss=0.00448 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.782 | L2-Norm(final)=13.764 | 4449.1 samples/s | 69.5 steps/s
[Step=45700 Epoch=222.9] | Loss=0.00440 | Reg=0.00316 | acc=0.9844 | L2-Norm=17.780 | L2-Norm(final)=13.767 | 4435.7 samples/s | 69.3 steps/s
[Step=45750 Epoch=223.1] | Loss=0.00426 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.778 | L2-Norm(final)=13.770 | 2504.7 samples/s | 39.1 steps/s
[Step=45800 Epoch=223.3] | Loss=0.00414 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.775 | L2-Norm(final)=13.772 | 4376.2 samples/s | 68.4 steps/s
[Step=45850 Epoch=223.6] | Loss=0.00409 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.773 | L2-Norm(final)=13.775 | 4443.3 samples/s | 69.4 steps/s
[Step=45900 Epoch=223.8] | Loss=0.00401 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.770 | L2-Norm(final)=13.777 | 4462.0 samples/s | 69.7 steps/s
[Step=45950 Epoch=224.1] | Loss=0.00394 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.767 | L2-Norm(final)=13.779 | 2465.5 samples/s | 38.5 steps/s
[Step=46000 Epoch=224.3] | Loss=0.00387 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.764 | L2-Norm(final)=13.782 | 4428.0 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step46000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=215.8] | Loss=0.00496 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.659 | L2-Norm(final)=13.528 | 5314.8 samples/s | 83.0 steps/s
[Step=44050 Epoch=216.0] | Loss=0.00220 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.657 | L2-Norm(final)=13.535 | 4520.8 samples/s | 70.6 steps/s
[Step=44100 Epoch=216.3] | Loss=0.00238 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.655 | L2-Norm(final)=13.542 | 4989.0 samples/s | 78.0 steps/s
[Step=44150 Epoch=216.5] | Loss=0.00224 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.652 | L2-Norm(final)=13.548 | 5060.9 samples/s | 79.1 steps/s
[Step=44200 Epoch=216.7] | Loss=0.00227 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.649 | L2-Norm(final)=13.556 | 7941.6 samples/s | 124.1 steps/s
[Step=44250 Epoch=217.0] | Loss=0.00215 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.646 | L2-Norm(final)=13.563 | 2196.1 samples/s | 34.3 steps/s
[Step=44300 Epoch=217.2] | Loss=0.00205 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.642 | L2-Norm(final)=13.570 | 5094.5 samples/s | 79.6 steps/s
[Step=44350 Epoch=217.5] | Loss=0.00208 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.638 | L2-Norm(final)=13.578 | 5088.9 samples/s | 79.5 steps/s
[Step=44400 Epoch=217.7] | Loss=0.00209 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.634 | L2-Norm(final)=13.585 | 7004.3 samples/s | 109.4 steps/s
[Step=44450 Epoch=218.0] | Loss=0.00205 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.629 | L2-Norm(final)=13.592 | 2237.8 samples/s | 35.0 steps/s
[Step=44500 Epoch=218.2] | Loss=0.00210 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=13.600 | 5001.0 samples/s | 78.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=218.2] | Loss=0.00133 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.578 | L2-Norm(final)=13.672 | 5749.3 samples/s | 89.8 steps/s
[Step=44550 Epoch=218.5] | Loss=0.00258 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.576 | L2-Norm(final)=13.680 | 4116.1 samples/s | 64.3 steps/s
[Step=44600 Epoch=218.7] | Loss=0.00389 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.579 | L2-Norm(final)=13.686 | 4481.9 samples/s | 70.0 steps/s
[Step=44650 Epoch=219.0] | Loss=0.00427 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.582 | L2-Norm(final)=13.692 | 4468.5 samples/s | 69.8 steps/s
[Step=44700 Epoch=219.2] | Loss=0.00453 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.588 | L2-Norm(final)=13.699 | 6625.1 samples/s | 103.5 steps/s
[Step=44750 Epoch=219.4] | Loss=0.00463 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.594 | L2-Norm(final)=13.705 | 2033.2 samples/s | 31.8 steps/s
[Step=44800 Epoch=219.7] | Loss=0.00493 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.600 | L2-Norm(final)=13.710 | 4365.9 samples/s | 68.2 steps/s
[Step=44850 Epoch=219.9] | Loss=0.00490 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.604 | L2-Norm(final)=13.716 | 4520.7 samples/s | 70.6 steps/s
[Step=44900 Epoch=220.2] | Loss=0.00483 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.608 | L2-Norm(final)=13.721 | 6175.4 samples/s | 96.5 steps/s
[Step=44950 Epoch=220.4] | Loss=0.00458 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.610 | L2-Norm(final)=13.726 | 2111.6 samples/s | 33.0 steps/s
[Step=45000 Epoch=220.7] | Loss=0.00444 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.611 | L2-Norm(final)=13.731 | 4509.8 samples/s | 70.5 steps/s
[Step=45050 Epoch=220.9] | Loss=0.00430 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.611 | L2-Norm(final)=13.735 | 4328.5 samples/s | 67.6 steps/s
[Step=45100 Epoch=221.2] | Loss=0.00426 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.611 | L2-Norm(final)=13.740 | 5908.6 samples/s | 92.3 steps/s
[Step=45150 Epoch=221.4] | Loss=0.00410 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.610 | L2-Norm(final)=13.744 | 2172.9 samples/s | 34.0 steps/s
[Step=45200 Epoch=221.7] | Loss=0.00398 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.609 | L2-Norm(final)=13.748 | 4467.9 samples/s | 69.8 steps/s
[Step=45250 Epoch=221.9] | Loss=0.00390 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.607 | L2-Norm(final)=13.752 | 4455.5 samples/s | 69.6 steps/s
[Step=45300 Epoch=222.1] | Loss=0.00384 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.606 | L2-Norm(final)=13.756 | 5542.0 samples/s | 86.6 steps/s
[Step=45350 Epoch=222.4] | Loss=0.00379 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.603 | L2-Norm(final)=13.759 | 2200.9 samples/s | 34.4 steps/s
[Step=45400 Epoch=222.6] | Loss=0.00369 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.601 | L2-Norm(final)=13.762 | 4417.2 samples/s | 69.0 steps/s
[Step=45450 Epoch=222.9] | Loss=0.00362 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.598 | L2-Norm(final)=13.766 | 4526.4 samples/s | 70.7 steps/s
[Step=45500 Epoch=223.1] | Loss=0.00359 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.596 | L2-Norm(final)=13.769 | 5173.1 samples/s | 80.8 steps/s
[Step=45550 Epoch=223.4] | Loss=0.00350 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.593 | L2-Norm(final)=13.772 | 2250.1 samples/s | 35.2 steps/s
[Step=45600 Epoch=223.6] | Loss=0.00342 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.589 | L2-Norm(final)=13.775 | 4495.0 samples/s | 70.2 steps/s
[Step=45650 Epoch=223.9] | Loss=0.00338 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.586 | L2-Norm(final)=13.778 | 4527.2 samples/s | 70.7 steps/s
[Step=45700 Epoch=224.1] | Loss=0.00330 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.582 | L2-Norm(final)=13.781 | 4876.4 samples/s | 76.2 steps/s
[Step=45750 Epoch=224.4] | Loss=0.00327 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.578 | L2-Norm(final)=13.784 | 2330.7 samples/s | 36.4 steps/s
[Step=45800 Epoch=224.6] | Loss=0.00324 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.574 | L2-Norm(final)=13.787 | 4491.5 samples/s | 70.2 steps/s
[Step=45850 Epoch=224.8] | Loss=0.00323 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.570 | L2-Norm(final)=13.789 | 4481.3 samples/s | 70.0 steps/s
[Step=45900 Epoch=225.1] | Loss=0.00318 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.565 | L2-Norm(final)=13.792 | 4632.4 samples/s | 72.4 steps/s
[Step=45950 Epoch=225.3] | Loss=0.00313 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.561 | L2-Norm(final)=13.794 | 2420.0 samples/s | 37.8 steps/s
[Step=46000 Epoch=225.6] | Loss=0.00309 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.556 | L2-Norm(final)=13.797 | 4478.6 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step46000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=416.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.334 | 5577.4 samples/s | 87.1 steps/s
[Step=44050 Epoch=417.4] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.335 | 4016.2 samples/s | 62.8 steps/s
[Step=44100 Epoch=417.9] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.336 | 7434.8 samples/s | 116.2 steps/s
[Step=44150 Epoch=418.4] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.337 | 2127.1 samples/s | 33.2 steps/s
[Step=44200 Epoch=418.8] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.339 | 6568.4 samples/s | 102.6 steps/s
[Step=44250 Epoch=419.3] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.340 | 2211.5 samples/s | 34.6 steps/s
[Step=44300 Epoch=419.8] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.341 | 5923.3 samples/s | 92.6 steps/s
[Step=44350 Epoch=420.3] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.342 | 2314.8 samples/s | 36.2 steps/s
[Step=44400 Epoch=420.7] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.996 | L2-Norm(final)=7.344 | 5290.6 samples/s | 82.7 steps/s
[Step=44450 Epoch=421.2] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.345 | 2413.3 samples/s | 37.7 steps/s
[Step=44500 Epoch=421.7] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.346 | 4975.4 samples/s | 77.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=421.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.992 | L2-Norm(final)=7.359 | 5174.8 samples/s | 80.9 steps/s
[Step=44550 Epoch=422.1] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.990 | L2-Norm(final)=7.360 | 3867.8 samples/s | 60.4 steps/s
[Step=44600 Epoch=422.6] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.987 | L2-Norm(final)=7.362 | 6209.2 samples/s | 97.0 steps/s
[Step=44650 Epoch=423.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.984 | L2-Norm(final)=7.363 | 2009.7 samples/s | 31.4 steps/s
[Step=44700 Epoch=423.6] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.980 | L2-Norm(final)=7.364 | 5534.3 samples/s | 86.5 steps/s
[Step=44750 Epoch=424.0] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.976 | L2-Norm(final)=7.364 | 2110.1 samples/s | 33.0 steps/s
[Step=44800 Epoch=424.5] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.973 | L2-Norm(final)=7.365 | 5095.4 samples/s | 79.6 steps/s
[Step=44850 Epoch=425.0] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.969 | L2-Norm(final)=7.366 | 2174.4 samples/s | 34.0 steps/s
[Step=44900 Epoch=425.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.965 | L2-Norm(final)=7.367 | 4733.2 samples/s | 74.0 steps/s
[Step=44950 Epoch=425.9] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.961 | L2-Norm(final)=7.367 | 2267.8 samples/s | 35.4 steps/s
[Step=45000 Epoch=426.4] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.957 | L2-Norm(final)=7.368 | 4292.4 samples/s | 67.1 steps/s
[Step=45050 Epoch=426.9] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.953 | L2-Norm(final)=7.369 | 2355.9 samples/s | 36.8 steps/s
[Step=45100 Epoch=427.4] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.949 | L2-Norm(final)=7.369 | 4250.4 samples/s | 66.4 steps/s
[Step=45150 Epoch=427.8] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.945 | L2-Norm(final)=7.370 | 2375.0 samples/s | 37.1 steps/s
[Step=45200 Epoch=428.3] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.941 | L2-Norm(final)=7.370 | 4335.9 samples/s | 67.7 steps/s
[Step=45250 Epoch=428.8] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.936 | L2-Norm(final)=7.371 | 2266.1 samples/s | 35.4 steps/s
[Step=45300 Epoch=429.3] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.932 | L2-Norm(final)=7.372 | 4287.3 samples/s | 67.0 steps/s
[Step=45350 Epoch=429.7] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.928 | L2-Norm(final)=7.372 | 2558.2 samples/s | 40.0 steps/s
[Step=45400 Epoch=430.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.923 | L2-Norm(final)=7.373 | 3883.2 samples/s | 60.7 steps/s
[Step=45450 Epoch=430.7] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.919 | L2-Norm(final)=7.373 | 6420.1 samples/s | 100.3 steps/s
[Step=45500 Epoch=431.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.914 | L2-Norm(final)=7.374 | 1993.4 samples/s | 31.1 steps/s
[Step=45550 Epoch=431.6] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.910 | L2-Norm(final)=7.374 | 5760.4 samples/s | 90.0 steps/s
[Step=45600 Epoch=432.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.905 | L2-Norm(final)=7.375 | 2050.2 samples/s | 32.0 steps/s
[Step=45650 Epoch=432.6] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.900 | L2-Norm(final)=7.376 | 5236.9 samples/s | 81.8 steps/s
[Step=45700 Epoch=433.0] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.895 | L2-Norm(final)=7.376 | 2163.2 samples/s | 33.8 steps/s
[Step=45750 Epoch=433.5] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.891 | L2-Norm(final)=7.377 | 4781.0 samples/s | 74.7 steps/s
[Step=45800 Epoch=434.0] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.886 | L2-Norm(final)=7.377 | 2239.4 samples/s | 35.0 steps/s
[Step=45850 Epoch=434.5] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.881 | L2-Norm(final)=7.378 | 4433.8 samples/s | 69.3 steps/s
[Step=45900 Epoch=434.9] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.876 | L2-Norm(final)=7.378 | 2364.4 samples/s | 36.9 steps/s
[Step=45950 Epoch=435.4] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.870 | L2-Norm(final)=7.379 | 4172.8 samples/s | 65.2 steps/s
[Step=46000 Epoch=435.9] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.865 | L2-Norm(final)=7.379 | 2359.8 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step46000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=418.6] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.110 | L2-Norm(final)=8.130 | 4817.3 samples/s | 75.3 steps/s
[Step=44050 Epoch=419.0] | Loss=0.00003 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.107 | L2-Norm(final)=8.134 | 4266.0 samples/s | 66.7 steps/s
[Step=44100 Epoch=419.5] | Loss=0.00003 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.107 | L2-Norm(final)=8.140 | 7292.8 samples/s | 113.9 steps/s
[Step=44150 Epoch=420.0] | Loss=0.00003 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.107 | L2-Norm(final)=8.147 | 2129.0 samples/s | 33.3 steps/s
[Step=44200 Epoch=420.5] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.107 | L2-Norm(final)=8.153 | 6629.8 samples/s | 103.6 steps/s
[Step=44250 Epoch=420.9] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.106 | L2-Norm(final)=8.159 | 2239.4 samples/s | 35.0 steps/s
[Step=44300 Epoch=421.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.105 | L2-Norm(final)=8.165 | 5851.1 samples/s | 91.4 steps/s
[Step=44350 Epoch=421.9] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.104 | L2-Norm(final)=8.171 | 2345.7 samples/s | 36.7 steps/s
[Step=44400 Epoch=422.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.103 | L2-Norm(final)=8.177 | 5090.8 samples/s | 79.5 steps/s
[Step=44450 Epoch=422.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.102 | L2-Norm(final)=8.182 | 2399.6 samples/s | 37.5 steps/s
[Step=44500 Epoch=423.3] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.100 | L2-Norm(final)=8.188 | 4926.6 samples/s | 77.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=423.3] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=8.244 | 4893.8 samples/s | 76.5 steps/s
[Step=44550 Epoch=423.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.073 | L2-Norm(final)=8.250 | 3969.5 samples/s | 62.0 steps/s
[Step=44600 Epoch=424.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.057 | L2-Norm(final)=8.254 | 6368.1 samples/s | 99.5 steps/s
[Step=44650 Epoch=424.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=8.257 | 2011.3 samples/s | 31.4 steps/s
[Step=44700 Epoch=425.2] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.022 | L2-Norm(final)=8.260 | 5548.3 samples/s | 86.7 steps/s
[Step=44750 Epoch=425.7] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.004 | L2-Norm(final)=8.262 | 2107.7 samples/s | 32.9 steps/s
[Step=44800 Epoch=426.2] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.986 | L2-Norm(final)=8.264 | 5127.2 samples/s | 80.1 steps/s
[Step=44850 Epoch=426.6] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.967 | L2-Norm(final)=8.266 | 2183.6 samples/s | 34.1 steps/s
[Step=44900 Epoch=427.1] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.949 | L2-Norm(final)=8.268 | 4680.0 samples/s | 73.1 steps/s
[Step=44950 Epoch=427.6] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.930 | L2-Norm(final)=8.270 | 2268.5 samples/s | 35.4 steps/s
[Step=45000 Epoch=428.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.911 | L2-Norm(final)=8.271 | 4228.2 samples/s | 66.1 steps/s
[Step=45050 Epoch=428.5] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.892 | L2-Norm(final)=8.273 | 2322.9 samples/s | 36.3 steps/s
[Step=45100 Epoch=429.0] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.873 | L2-Norm(final)=8.275 | 4358.7 samples/s | 68.1 steps/s
[Step=45150 Epoch=429.5] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.853 | L2-Norm(final)=8.276 | 2375.7 samples/s | 37.1 steps/s
[Step=45200 Epoch=430.0] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.834 | L2-Norm(final)=8.278 | 4198.9 samples/s | 65.6 steps/s
[Step=45250 Epoch=430.4] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.814 | L2-Norm(final)=8.279 | 2382.5 samples/s | 37.2 steps/s
[Step=45300 Epoch=430.9] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.794 | L2-Norm(final)=8.281 | 4261.5 samples/s | 66.6 steps/s
[Step=45350 Epoch=431.4] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.775 | L2-Norm(final)=8.282 | 2530.7 samples/s | 39.5 steps/s
[Step=45400 Epoch=431.9] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.755 | L2-Norm(final)=8.284 | 3917.9 samples/s | 61.2 steps/s
[Step=45450 Epoch=432.3] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=8.285 | 6563.6 samples/s | 102.6 steps/s
[Step=45500 Epoch=432.8] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.287 | 2009.0 samples/s | 31.4 steps/s
[Step=45550 Epoch=433.3] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.694 | L2-Norm(final)=8.288 | 5714.7 samples/s | 89.3 steps/s
[Step=45600 Epoch=433.8] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.673 | L2-Norm(final)=8.290 | 2040.1 samples/s | 31.9 steps/s
[Step=45650 Epoch=434.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.653 | L2-Norm(final)=8.292 | 5361.2 samples/s | 83.8 steps/s
[Step=45700 Epoch=434.7] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.632 | L2-Norm(final)=8.293 | 2152.5 samples/s | 33.6 steps/s
[Step=45750 Epoch=435.2] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.611 | L2-Norm(final)=8.295 | 4823.5 samples/s | 75.4 steps/s
[Step=45800 Epoch=435.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.590 | L2-Norm(final)=8.297 | 2217.7 samples/s | 34.7 steps/s
[Step=45850 Epoch=436.1] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.569 | L2-Norm(final)=8.299 | 4425.8 samples/s | 69.2 steps/s
[Step=45900 Epoch=436.6] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.548 | L2-Norm(final)=8.300 | 2291.2 samples/s | 35.8 steps/s
[Step=45950 Epoch=437.1] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.526 | L2-Norm(final)=8.302 | 4234.0 samples/s | 66.2 steps/s
[Step=46000 Epoch=437.6] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.505 | L2-Norm(final)=8.304 | 2403.6 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step46000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=420.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.045 | L2-Norm(final)=7.637 | 5767.6 samples/s | 90.1 steps/s
[Step=44050 Epoch=420.7] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.046 | L2-Norm(final)=7.642 | 3809.2 samples/s | 59.5 steps/s
[Step=44100 Epoch=421.1] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=7.648 | 7562.5 samples/s | 118.2 steps/s
[Step=44150 Epoch=421.6] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=7.654 | 2080.4 samples/s | 32.5 steps/s
[Step=44200 Epoch=422.1] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.049 | L2-Norm(final)=7.661 | 6705.2 samples/s | 104.8 steps/s
[Step=44250 Epoch=422.6] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.666 | 2180.8 samples/s | 34.1 steps/s
[Step=44300 Epoch=423.0] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.671 | 6240.4 samples/s | 97.5 steps/s
[Step=44350 Epoch=423.5] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.676 | 2254.4 samples/s | 35.2 steps/s
[Step=44400 Epoch=424.0] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.682 | 5695.1 samples/s | 89.0 steps/s
[Step=44450 Epoch=424.5] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.687 | 2299.0 samples/s | 35.9 steps/s
[Step=44500 Epoch=424.9] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.692 | 5153.1 samples/s | 80.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=425.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.046 | L2-Norm(final)=7.745 | 5270.7 samples/s | 82.4 steps/s
[Step=44550 Epoch=425.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.038 | L2-Norm(final)=7.750 | 3824.0 samples/s | 59.8 steps/s
[Step=44600 Epoch=425.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.027 | L2-Norm(final)=7.755 | 6259.6 samples/s | 97.8 steps/s
[Step=44650 Epoch=426.4] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.014 | L2-Norm(final)=7.759 | 2014.9 samples/s | 31.5 steps/s
[Step=44700 Epoch=426.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=7.761 | 5789.1 samples/s | 90.5 steps/s
[Step=44750 Epoch=427.3] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.987 | L2-Norm(final)=7.763 | 2013.7 samples/s | 31.5 steps/s
[Step=44800 Epoch=427.8] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.974 | L2-Norm(final)=7.765 | 5424.6 samples/s | 84.8 steps/s
[Step=44850 Epoch=428.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.960 | L2-Norm(final)=7.767 | 2145.1 samples/s | 33.5 steps/s
[Step=44900 Epoch=428.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.945 | L2-Norm(final)=7.769 | 4914.3 samples/s | 76.8 steps/s
[Step=44950 Epoch=429.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.931 | L2-Norm(final)=7.771 | 2187.6 samples/s | 34.2 steps/s
[Step=45000 Epoch=429.7] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.917 | L2-Norm(final)=7.772 | 4574.0 samples/s | 71.5 steps/s
[Step=45050 Epoch=430.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.903 | L2-Norm(final)=7.774 | 2296.3 samples/s | 35.9 steps/s
[Step=45100 Epoch=430.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.888 | L2-Norm(final)=7.775 | 4307.5 samples/s | 67.3 steps/s
[Step=45150 Epoch=431.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.874 | L2-Norm(final)=7.777 | 2347.9 samples/s | 36.7 steps/s
[Step=45200 Epoch=431.6] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.859 | L2-Norm(final)=7.778 | 4224.1 samples/s | 66.0 steps/s
[Step=45250 Epoch=432.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.844 | L2-Norm(final)=7.780 | 2352.3 samples/s | 36.8 steps/s
[Step=45300 Epoch=432.6] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.830 | L2-Norm(final)=7.781 | 4144.1 samples/s | 64.8 steps/s
[Step=45350 Epoch=433.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.815 | L2-Norm(final)=7.783 | 2426.7 samples/s | 37.9 steps/s
[Step=45400 Epoch=433.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.800 | L2-Norm(final)=7.784 | 4271.9 samples/s | 66.7 steps/s
[Step=45450 Epoch=434.0] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.785 | L2-Norm(final)=7.786 | 2442.5 samples/s | 38.2 steps/s
[Step=45500 Epoch=434.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.770 | L2-Norm(final)=7.787 | 4006.7 samples/s | 62.6 steps/s
[Step=45550 Epoch=435.0] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.754 | L2-Norm(final)=7.789 | 6926.7 samples/s | 108.2 steps/s
[Step=45600 Epoch=435.5] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.739 | L2-Norm(final)=7.790 | 1945.4 samples/s | 30.4 steps/s
[Step=45650 Epoch=435.9] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.724 | L2-Norm(final)=7.792 | 6287.6 samples/s | 98.2 steps/s
[Step=45700 Epoch=436.4] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=7.794 | 2005.1 samples/s | 31.3 steps/s
[Step=45750 Epoch=436.9] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.692 | L2-Norm(final)=7.795 | 5834.0 samples/s | 91.2 steps/s
[Step=45800 Epoch=437.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.677 | L2-Norm(final)=7.797 | 2086.9 samples/s | 32.6 steps/s
[Step=45850 Epoch=437.8] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.661 | L2-Norm(final)=7.798 | 5328.4 samples/s | 83.3 steps/s
[Step=45900 Epoch=438.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.645 | L2-Norm(final)=7.800 | 2124.2 samples/s | 33.2 steps/s
[Step=45950 Epoch=438.8] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.629 | L2-Norm(final)=7.802 | 4946.5 samples/s | 77.3 steps/s
[Step=46000 Epoch=439.3] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.613 | L2-Norm(final)=7.804 | 2214.0 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step46000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=414.6] | Loss=0.00018 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.964 | L2-Norm(final)=7.703 | 5535.8 samples/s | 86.5 steps/s
[Step=44050 Epoch=415.1] | Loss=0.00030 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.988 | L2-Norm(final)=7.723 | 3997.7 samples/s | 62.5 steps/s
[Step=44100 Epoch=415.5] | Loss=0.00034 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.013 | L2-Norm(final)=7.739 | 7422.6 samples/s | 116.0 steps/s
[Step=44150 Epoch=416.0] | Loss=0.00026 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.032 | L2-Norm(final)=7.750 | 2124.8 samples/s | 33.2 steps/s
[Step=44200 Epoch=416.5] | Loss=0.00020 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.042 | L2-Norm(final)=7.758 | 6383.9 samples/s | 99.7 steps/s
[Step=44250 Epoch=417.0] | Loss=0.00017 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=7.764 | 2260.7 samples/s | 35.3 steps/s
[Step=44300 Epoch=417.4] | Loss=0.00015 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.053 | L2-Norm(final)=7.770 | 5534.1 samples/s | 86.5 steps/s
[Step=44350 Epoch=417.9] | Loss=0.00013 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.056 | L2-Norm(final)=7.774 | 2370.8 samples/s | 37.0 steps/s
[Step=44400 Epoch=418.4] | Loss=0.00011 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.058 | L2-Norm(final)=7.779 | 5087.0 samples/s | 79.5 steps/s
[Step=44450 Epoch=418.8] | Loss=0.00010 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.059 | L2-Norm(final)=7.783 | 2480.5 samples/s | 38.8 steps/s
[Step=44500 Epoch=419.3] | Loss=0.00010 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.060 | L2-Norm(final)=7.787 | 4587.1 samples/s | 71.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=419.3] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.070 | L2-Norm(final)=7.825 | 5542.5 samples/s | 86.6 steps/s
[Step=44550 Epoch=419.8] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.057 | L2-Norm(final)=7.828 | 3834.9 samples/s | 59.9 steps/s
[Step=44600 Epoch=420.3] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=7.832 | 6114.7 samples/s | 95.5 steps/s
[Step=44650 Epoch=420.7] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.024 | L2-Norm(final)=7.834 | 2027.7 samples/s | 31.7 steps/s
[Step=44700 Epoch=421.2] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.004 | L2-Norm(final)=7.836 | 5425.0 samples/s | 84.8 steps/s
[Step=44750 Epoch=421.7] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.982 | L2-Norm(final)=7.838 | 2103.7 samples/s | 32.9 steps/s
[Step=44800 Epoch=422.1] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=7.839 | 4947.3 samples/s | 77.3 steps/s
[Step=44850 Epoch=422.6] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.936 | L2-Norm(final)=7.839 | 2212.2 samples/s | 34.6 steps/s
[Step=44900 Epoch=423.1] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.912 | L2-Norm(final)=7.840 | 4526.0 samples/s | 70.7 steps/s
[Step=44950 Epoch=423.6] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.888 | L2-Norm(final)=7.841 | 2307.0 samples/s | 36.0 steps/s
[Step=45000 Epoch=424.0] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.863 | L2-Norm(final)=7.841 | 4249.7 samples/s | 66.4 steps/s
[Step=45050 Epoch=424.5] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.838 | L2-Norm(final)=7.842 | 2353.1 samples/s | 36.8 steps/s
[Step=45100 Epoch=425.0] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.813 | L2-Norm(final)=7.842 | 4133.3 samples/s | 64.6 steps/s
[Step=45150 Epoch=425.4] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.788 | L2-Norm(final)=7.842 | 2394.5 samples/s | 37.4 steps/s
[Step=45200 Epoch=425.9] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.762 | L2-Norm(final)=7.843 | 4382.9 samples/s | 68.5 steps/s
[Step=45250 Epoch=426.4] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.737 | L2-Norm(final)=7.843 | 2664.7 samples/s | 41.6 steps/s
[Step=45300 Epoch=426.9] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=7.844 | 3570.0 samples/s | 55.8 steps/s
[Step=45350 Epoch=427.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.685 | L2-Norm(final)=7.844 | 6140.0 samples/s | 95.9 steps/s
[Step=45400 Epoch=427.8] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.659 | L2-Norm(final)=7.844 | 2014.2 samples/s | 31.5 steps/s
[Step=45450 Epoch=428.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.633 | L2-Norm(final)=7.845 | 5664.1 samples/s | 88.5 steps/s
[Step=45500 Epoch=428.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.606 | L2-Norm(final)=7.845 | 2114.0 samples/s | 33.0 steps/s
[Step=45550 Epoch=429.2] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.579 | L2-Norm(final)=7.845 | 5013.7 samples/s | 78.3 steps/s
[Step=45600 Epoch=429.7] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.553 | L2-Norm(final)=7.846 | 2192.8 samples/s | 34.3 steps/s
[Step=45650 Epoch=430.2] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.526 | L2-Norm(final)=7.846 | 4496.8 samples/s | 70.3 steps/s
[Step=45700 Epoch=430.6] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.499 | L2-Norm(final)=7.847 | 2309.3 samples/s | 36.1 steps/s
[Step=45750 Epoch=431.1] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.472 | L2-Norm(final)=7.847 | 4260.5 samples/s | 66.6 steps/s
[Step=45800 Epoch=431.6] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.444 | L2-Norm(final)=7.848 | 2407.0 samples/s | 37.6 steps/s
[Step=45850 Epoch=432.0] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.417 | L2-Norm(final)=7.848 | 4231.9 samples/s | 66.1 steps/s
[Step=45900 Epoch=432.5] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.389 | L2-Norm(final)=7.849 | 2364.0 samples/s | 36.9 steps/s
[Step=45950 Epoch=433.0] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.362 | L2-Norm(final)=7.849 | 4244.2 samples/s | 66.3 steps/s
[Step=46000 Epoch=433.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.334 | L2-Norm(final)=7.850 | 2499.2 samples/s | 39.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step46000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=419.4] | Loss=0.00033 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.139 | L2-Norm(final)=8.302 | 5283.8 samples/s | 82.6 steps/s
[Step=44050 Epoch=419.8] | Loss=0.00007 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.141 | L2-Norm(final)=8.310 | 4164.2 samples/s | 65.1 steps/s
[Step=44100 Epoch=420.3] | Loss=0.00005 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.144 | L2-Norm(final)=8.319 | 7462.5 samples/s | 116.6 steps/s
[Step=44150 Epoch=420.8] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.146 | L2-Norm(final)=8.327 | 2094.6 samples/s | 32.7 steps/s
[Step=44200 Epoch=421.3] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.147 | L2-Norm(final)=8.334 | 6667.0 samples/s | 104.2 steps/s
[Step=44250 Epoch=421.7] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=8.341 | 2193.1 samples/s | 34.3 steps/s
[Step=44300 Epoch=422.2] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=8.347 | 6239.0 samples/s | 97.5 steps/s
[Step=44350 Epoch=422.7] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=8.354 | 2290.2 samples/s | 35.8 steps/s
[Step=44400 Epoch=423.2] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=8.360 | 5619.3 samples/s | 87.8 steps/s
[Step=44450 Epoch=423.6] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.149 | L2-Norm(final)=8.366 | 2339.8 samples/s | 36.6 steps/s
[Step=44500 Epoch=424.1] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=8.372 | 5076.3 samples/s | 79.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=424.1] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.145 | L2-Norm(final)=8.433 | 5613.0 samples/s | 87.7 steps/s
[Step=44550 Epoch=424.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.137 | L2-Norm(final)=8.439 | 3672.6 samples/s | 57.4 steps/s
[Step=44600 Epoch=425.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.124 | L2-Norm(final)=8.443 | 6239.7 samples/s | 97.5 steps/s
[Step=44650 Epoch=425.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.111 | L2-Norm(final)=8.447 | 2021.1 samples/s | 31.6 steps/s
[Step=44700 Epoch=426.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=8.449 | 5644.3 samples/s | 88.2 steps/s
[Step=44750 Epoch=426.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.081 | L2-Norm(final)=8.451 | 2035.7 samples/s | 31.8 steps/s
[Step=44800 Epoch=427.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.065 | L2-Norm(final)=8.453 | 5341.5 samples/s | 83.5 steps/s
[Step=44850 Epoch=427.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=8.454 | 2126.7 samples/s | 33.2 steps/s
[Step=44900 Epoch=427.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.032 | L2-Norm(final)=8.455 | 5016.3 samples/s | 78.4 steps/s
[Step=44950 Epoch=428.4] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.015 | L2-Norm(final)=8.457 | 2225.2 samples/s | 34.8 steps/s
[Step=45000 Epoch=428.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.998 | L2-Norm(final)=8.458 | 4595.5 samples/s | 71.8 steps/s
[Step=45050 Epoch=429.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.982 | L2-Norm(final)=8.459 | 2247.4 samples/s | 35.1 steps/s
[Step=45100 Epoch=429.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.965 | L2-Norm(final)=8.460 | 4347.1 samples/s | 67.9 steps/s
[Step=45150 Epoch=430.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.947 | L2-Norm(final)=8.461 | 2358.1 samples/s | 36.8 steps/s
[Step=45200 Epoch=430.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.930 | L2-Norm(final)=8.462 | 4293.1 samples/s | 67.1 steps/s
[Step=45250 Epoch=431.3] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.913 | L2-Norm(final)=8.463 | 2375.5 samples/s | 37.1 steps/s
[Step=45300 Epoch=431.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.895 | L2-Norm(final)=8.464 | 4219.2 samples/s | 65.9 steps/s
[Step=45350 Epoch=432.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.878 | L2-Norm(final)=8.465 | 2378.7 samples/s | 37.2 steps/s
[Step=45400 Epoch=432.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.860 | L2-Norm(final)=8.466 | 4288.8 samples/s | 67.0 steps/s
[Step=45450 Epoch=433.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.842 | L2-Norm(final)=8.467 | 2545.0 samples/s | 39.8 steps/s
[Step=45500 Epoch=433.7] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.824 | L2-Norm(final)=8.469 | 3894.1 samples/s | 60.8 steps/s
[Step=45550 Epoch=434.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.806 | L2-Norm(final)=8.470 | 6740.1 samples/s | 105.3 steps/s
[Step=45600 Epoch=434.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.788 | L2-Norm(final)=8.471 | 1966.5 samples/s | 30.7 steps/s
[Step=45650 Epoch=435.1] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.770 | L2-Norm(final)=8.472 | 6213.6 samples/s | 97.1 steps/s
[Step=45700 Epoch=435.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.751 | L2-Norm(final)=8.473 | 1981.0 samples/s | 31.0 steps/s
[Step=45750 Epoch=436.0] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.733 | L2-Norm(final)=8.474 | 5815.1 samples/s | 90.9 steps/s
[Step=45800 Epoch=436.5] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.475 | 2081.4 samples/s | 32.5 steps/s
[Step=45850 Epoch=437.0] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.695 | L2-Norm(final)=8.477 | 5273.0 samples/s | 82.4 steps/s
[Step=45900 Epoch=437.5] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.676 | L2-Norm(final)=8.478 | 2146.5 samples/s | 33.5 steps/s
[Step=45950 Epoch=437.9] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.657 | L2-Norm(final)=8.479 | 4825.1 samples/s | 75.4 steps/s
[Step=46000 Epoch=438.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.638 | L2-Norm(final)=8.480 | 2194.5 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11723 | acc=0.9586 | tpr=0.9734 | fpr=0.0736 | 4807.0 samples/s | 18.8 steps/s
Avg test loss: 0.12222, Avg test acc: 0.95681, Avg tpr: 0.97202, Avg fpr: 0.07666, total FA: 598

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12409 | acc=0.9574 | tpr=0.9747 | fpr=0.0800 | 4697.4 samples/s | 18.3 steps/s
Avg test loss: 0.12500, Avg test acc: 0.95713, Avg tpr: 0.97342, Avg fpr: 0.07871, total FA: 614

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11089 | acc=0.9600 | tpr=0.9738 | fpr=0.0699 | 4652.8 samples/s | 18.2 steps/s
Avg test loss: 0.11511, Avg test acc: 0.95825, Avg tpr: 0.97202, Avg fpr: 0.07204, total FA: 562

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.11546 | acc=0.9593 | tpr=0.9726 | fpr=0.0696 | 4700.0 samples/s | 18.4 steps/s
Avg test loss: 0.12062, Avg test acc: 0.95841, Avg tpr: 0.97342, Avg fpr: 0.07461, total FA: 582

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10639 | acc=0.9599 | tpr=0.9712 | fpr=0.0647 | 4909.1 samples/s | 19.2 steps/s
Avg test loss: 0.11484, Avg test acc: 0.95925, Avg tpr: 0.97127, Avg fpr: 0.06717, total FA: 524

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.66768 | acc=0.2866 | tpr=0.0189 | fpr=0.1323 | 4809.2 samples/s | 18.8 steps/s
Avg test loss: 5.67071, Avg test acc: 0.28584, Avg tpr: 0.02081, Avg fpr: 0.13127, total FA: 1024

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.89949 | acc=0.2940 | tpr=0.0071 | fpr=0.0830 | 4720.9 samples/s | 18.4 steps/s
Avg test loss: 4.91471, Avg test acc: 0.29137, Avg tpr: 0.00752, Avg fpr: 0.08435, total FA: 658

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.33033 | acc=0.2796 | tpr=0.0163 | fpr=0.1487 | 4703.9 samples/s | 18.4 steps/s
Avg test loss: 5.33209, Avg test acc: 0.27554, Avg tpr: 0.01597, Avg fpr: 0.15357, total FA: 1198

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.64730 | acc=0.2916 | tpr=0.0149 | fpr=0.1078 | 4697.0 samples/s | 18.3 steps/s
Avg test loss: 5.64493, Avg test acc: 0.28989, Avg tpr: 0.01597, Avg fpr: 0.10768, total FA: 840

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.02102 | acc=0.2976 | tpr=0.0167 | fpr=0.0924 | 4715.4 samples/s | 18.4 steps/s
Avg test loss: 5.02701, Avg test acc: 0.29622, Avg tpr: 0.01749, Avg fpr: 0.09076, total FA: 708

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.17568 | acc=0.0839 | tpr=0.6416 | fpr=0.9261 | 4856.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.14882 | acc=0.0857 | tpr=0.5928 | fpr=0.9238 | 7040.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.17042 | acc=0.0858 | tpr=0.5865 | fpr=0.9235 | 7857.7 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.16866 | acc=0.0862 | tpr=0.5869 | fpr=0.9230 | 7377.6 samples/s | 28.8 steps/s
[Step= 250] | Loss=6.17462 | acc=0.0862 | tpr=0.5834 | fpr=0.9229 | 8233.7 samples/s | 32.2 steps/s
[Step= 300] | Loss=6.17005 | acc=0.0865 | tpr=0.5942 | fpr=0.9227 | 7769.7 samples/s | 30.4 steps/s
[Step= 350] | Loss=6.16657 | acc=0.0869 | tpr=0.5974 | fpr=0.9224 | 7940.4 samples/s | 31.0 steps/s
[Step= 400] | Loss=6.16132 | acc=0.0874 | tpr=0.5946 | fpr=0.9218 | 7482.3 samples/s | 29.2 steps/s
[Step= 450] | Loss=6.16750 | acc=0.0876 | tpr=0.5949 | fpr=0.9216 | 8119.6 samples/s | 31.7 steps/s
[Step= 500] | Loss=6.17500 | acc=0.0875 | tpr=0.5925 | fpr=0.9216 | 8170.0 samples/s | 31.9 steps/s
[Step= 550] | Loss=6.17788 | acc=0.0877 | tpr=0.5933 | fpr=0.9215 | 13838.8 samples/s | 54.1 steps/s
Avg test loss: 6.17958, Avg test acc: 0.08757, Avg tpr: 0.59350, Avg fpr: 0.92163, total FA: 127966

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.05008 | acc=0.0848 | tpr=0.5531 | fpr=0.9236 | 4845.8 samples/s | 18.9 steps/s
[Step= 100] | Loss=6.02291 | acc=0.0860 | tpr=0.5458 | fpr=0.9226 | 6976.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.02441 | acc=0.0865 | tpr=0.5490 | fpr=0.9220 | 7903.5 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.01954 | acc=0.0870 | tpr=0.5290 | fpr=0.9211 | 7695.6 samples/s | 30.1 steps/s
[Step= 250] | Loss=6.02931 | acc=0.0872 | tpr=0.5319 | fpr=0.9209 | 7805.1 samples/s | 30.5 steps/s
[Step= 300] | Loss=6.02156 | acc=0.0870 | tpr=0.5411 | fpr=0.9212 | 8196.4 samples/s | 32.0 steps/s
[Step= 350] | Loss=6.01558 | acc=0.0876 | tpr=0.5404 | fpr=0.9206 | 8008.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=6.00932 | acc=0.0883 | tpr=0.5377 | fpr=0.9199 | 7682.7 samples/s | 30.0 steps/s
[Step= 450] | Loss=6.01235 | acc=0.0878 | tpr=0.5365 | fpr=0.9203 | 7871.2 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.01857 | acc=0.0874 | tpr=0.5348 | fpr=0.9207 | 7445.6 samples/s | 29.1 steps/s
[Step= 550] | Loss=6.02179 | acc=0.0875 | tpr=0.5328 | fpr=0.9206 | 15572.2 samples/s | 60.8 steps/s
Avg test loss: 6.02417, Avg test acc: 0.08739, Avg tpr: 0.53249, Avg fpr: 0.92070, total FA: 127838

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.52882 | acc=0.0838 | tpr=0.4292 | fpr=0.9225 | 4901.5 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.50065 | acc=0.0841 | tpr=0.4371 | fpr=0.9225 | 6852.6 samples/s | 26.8 steps/s
[Step= 150] | Loss=6.51014 | acc=0.0846 | tpr=0.4294 | fpr=0.9218 | 7883.1 samples/s | 30.8 steps/s
[Step= 200] | Loss=6.50786 | acc=0.0849 | tpr=0.4208 | fpr=0.9212 | 7916.5 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.51036 | acc=0.0852 | tpr=0.4210 | fpr=0.9210 | 7916.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.51019 | acc=0.0850 | tpr=0.4247 | fpr=0.9212 | 8300.5 samples/s | 32.4 steps/s
[Step= 350] | Loss=6.50416 | acc=0.0852 | tpr=0.4214 | fpr=0.9209 | 7555.6 samples/s | 29.5 steps/s
[Step= 400] | Loss=6.49718 | acc=0.0858 | tpr=0.4261 | fpr=0.9203 | 7563.7 samples/s | 29.5 steps/s
[Step= 450] | Loss=6.49955 | acc=0.0858 | tpr=0.4216 | fpr=0.9203 | 8156.8 samples/s | 31.9 steps/s
[Step= 500] | Loss=6.50345 | acc=0.0857 | tpr=0.4189 | fpr=0.9203 | 7907.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.50601 | acc=0.0858 | tpr=0.4198 | fpr=0.9203 | 14020.2 samples/s | 54.8 steps/s
Avg test loss: 6.50803, Avg test acc: 0.08573, Avg tpr: 0.42076, Avg fpr: 0.92036, total FA: 127790

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.07637 | acc=0.1058 | tpr=0.5752 | fpr=0.9027 | 4812.2 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.06099 | acc=0.1063 | tpr=0.5672 | fpr=0.9023 | 7216.1 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.06944 | acc=0.1060 | tpr=0.5720 | fpr=0.9026 | 7689.2 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.06078 | acc=0.1058 | tpr=0.5716 | fpr=0.9027 | 7938.2 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.06833 | acc=0.1063 | tpr=0.5651 | fpr=0.9021 | 7836.4 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.06533 | acc=0.1062 | tpr=0.5673 | fpr=0.9022 | 8002.4 samples/s | 31.3 steps/s
[Step= 350] | Loss=6.05966 | acc=0.1066 | tpr=0.5648 | fpr=0.9017 | 7766.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.05367 | acc=0.1070 | tpr=0.5640 | fpr=0.9014 | 7570.9 samples/s | 29.6 steps/s
[Step= 450] | Loss=6.05732 | acc=0.1068 | tpr=0.5652 | fpr=0.9015 | 7869.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.05939 | acc=0.1065 | tpr=0.5626 | fpr=0.9017 | 8187.6 samples/s | 32.0 steps/s
[Step= 550] | Loss=6.06254 | acc=0.1064 | tpr=0.5599 | fpr=0.9018 | 13707.7 samples/s | 53.5 steps/s
Avg test loss: 6.06351, Avg test acc: 0.10636, Avg tpr: 0.56022, Avg fpr: 0.90189, total FA: 125226

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.66359 | acc=0.1089 | tpr=0.5398 | fpr=0.8988 | 4831.6 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.64080 | acc=0.1114 | tpr=0.5501 | fpr=0.8968 | 6992.5 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.64353 | acc=0.1114 | tpr=0.5375 | fpr=0.8964 | 7976.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.64525 | acc=0.1110 | tpr=0.5290 | fpr=0.8966 | 7614.9 samples/s | 29.7 steps/s
[Step= 250] | Loss=5.65170 | acc=0.1113 | tpr=0.5328 | fpr=0.8963 | 7861.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.65019 | acc=0.1114 | tpr=0.5382 | fpr=0.8964 | 8206.7 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.64266 | acc=0.1118 | tpr=0.5429 | fpr=0.8960 | 7682.5 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.63944 | acc=0.1123 | tpr=0.5454 | fpr=0.8956 | 8155.8 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.64303 | acc=0.1126 | tpr=0.5511 | fpr=0.8953 | 7659.2 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.64559 | acc=0.1123 | tpr=0.5485 | fpr=0.8955 | 7938.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.64916 | acc=0.1122 | tpr=0.5511 | fpr=0.8957 | 13563.6 samples/s | 53.0 steps/s
Avg test loss: 5.65080, Avg test acc: 0.11212, Avg tpr: 0.55071, Avg fpr: 0.89586, total FA: 124388

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09911 | acc=0.9816 | tpr=0.9602 | fpr=0.0181 | 4761.8 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10250 | acc=0.9816 | tpr=0.9595 | fpr=0.0180 | 7325.4 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.10593 | acc=0.9807 | tpr=0.9524 | fpr=0.0188 | 7727.5 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10762 | acc=0.9806 | tpr=0.9563 | fpr=0.0189 | 7801.5 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.10573 | acc=0.9808 | tpr=0.9511 | fpr=0.0187 | 7831.0 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.10865 | acc=0.9803 | tpr=0.9476 | fpr=0.0191 | 7829.3 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.10972 | acc=0.9801 | tpr=0.9493 | fpr=0.0194 | 7817.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.11080 | acc=0.9799 | tpr=0.9442 | fpr=0.0195 | 7988.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.11281 | acc=0.9795 | tpr=0.9435 | fpr=0.0198 | 8112.3 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.11196 | acc=0.9797 | tpr=0.9445 | fpr=0.0197 | 7672.5 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.11150 | acc=0.9798 | tpr=0.9419 | fpr=0.0195 | 14029.7 samples/s | 54.8 steps/s
Avg test loss: 0.11142, Avg test acc: 0.97986, Avg tpr: 0.94216, Avg fpr: 0.01945, total FA: 2701

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08589 | acc=0.9841 | tpr=0.9204 | fpr=0.0147 | 4706.6 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.08960 | acc=0.9836 | tpr=0.9168 | fpr=0.0151 | 7013.6 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.09246 | acc=0.9830 | tpr=0.9164 | fpr=0.0157 | 7836.3 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.09476 | acc=0.9829 | tpr=0.9180 | fpr=0.0159 | 8239.7 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.09300 | acc=0.9830 | tpr=0.9162 | fpr=0.0157 | 7731.4 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.09558 | acc=0.9826 | tpr=0.9135 | fpr=0.0162 | 8258.8 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.09591 | acc=0.9826 | tpr=0.9186 | fpr=0.0163 | 7852.0 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.09717 | acc=0.9823 | tpr=0.9108 | fpr=0.0164 | 7791.6 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.09946 | acc=0.9820 | tpr=0.9075 | fpr=0.0167 | 8135.1 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.09843 | acc=0.9821 | tpr=0.9106 | fpr=0.0166 | 7829.2 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09835 | acc=0.9822 | tpr=0.9093 | fpr=0.0165 | 13404.0 samples/s | 52.4 steps/s
Avg test loss: 0.09822, Avg test acc: 0.98218, Avg tpr: 0.90967, Avg fpr: 0.01650, total FA: 2291

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09051 | acc=0.9808 | tpr=0.9602 | fpr=0.0188 | 4762.5 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.09295 | acc=0.9811 | tpr=0.9574 | fpr=0.0185 | 7247.4 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.09664 | acc=0.9805 | tpr=0.9582 | fpr=0.0191 | 7981.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.09824 | acc=0.9807 | tpr=0.9607 | fpr=0.0190 | 7764.4 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.09663 | acc=0.9810 | tpr=0.9598 | fpr=0.0186 | 7776.4 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.09914 | acc=0.9807 | tpr=0.9535 | fpr=0.0189 | 8054.3 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.09989 | acc=0.9804 | tpr=0.9543 | fpr=0.0191 | 7969.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.10090 | acc=0.9802 | tpr=0.9535 | fpr=0.0193 | 7911.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10269 | acc=0.9800 | tpr=0.9528 | fpr=0.0195 | 7799.4 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.10199 | acc=0.9800 | tpr=0.9537 | fpr=0.0195 | 7787.5 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.10154 | acc=0.9801 | tpr=0.9526 | fpr=0.0194 | 14090.6 samples/s | 55.0 steps/s
Avg test loss: 0.10143, Avg test acc: 0.98015, Avg tpr: 0.95285, Avg fpr: 0.01935, total FA: 2687

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09311 | acc=0.9820 | tpr=0.9425 | fpr=0.0173 | 4852.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09678 | acc=0.9813 | tpr=0.9424 | fpr=0.0179 | 6937.1 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.10146 | acc=0.9805 | tpr=0.9424 | fpr=0.0188 | 7950.0 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.10307 | acc=0.9805 | tpr=0.9508 | fpr=0.0190 | 7470.0 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.10171 | acc=0.9810 | tpr=0.9502 | fpr=0.0184 | 8216.5 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.10412 | acc=0.9807 | tpr=0.9462 | fpr=0.0186 | 7736.5 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.10485 | acc=0.9806 | tpr=0.9461 | fpr=0.0188 | 7884.5 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.10555 | acc=0.9804 | tpr=0.9415 | fpr=0.0189 | 8011.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.10772 | acc=0.9802 | tpr=0.9396 | fpr=0.0191 | 7932.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.10689 | acc=0.9802 | tpr=0.9405 | fpr=0.0190 | 7592.0 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.10658 | acc=0.9804 | tpr=0.9403 | fpr=0.0189 | 14704.1 samples/s | 57.4 steps/s
Avg test loss: 0.10646, Avg test acc: 0.98041, Avg tpr: 0.94057, Avg fpr: 0.01887, total FA: 2620

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09899 | acc=0.9817 | tpr=0.9159 | fpr=0.0171 | 4938.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.10359 | acc=0.9812 | tpr=0.9211 | fpr=0.0177 | 6807.7 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.10715 | acc=0.9803 | tpr=0.9236 | fpr=0.0186 | 7922.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.10923 | acc=0.9802 | tpr=0.9311 | fpr=0.0189 | 7648.8 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.10813 | acc=0.9806 | tpr=0.9284 | fpr=0.0184 | 7881.1 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.11072 | acc=0.9804 | tpr=0.9229 | fpr=0.0186 | 7959.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.11125 | acc=0.9802 | tpr=0.9261 | fpr=0.0188 | 7612.6 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.11258 | acc=0.9800 | tpr=0.9229 | fpr=0.0190 | 8314.7 samples/s | 32.5 steps/s
[Step= 450] | Loss=0.11503 | acc=0.9797 | tpr=0.9202 | fpr=0.0193 | 7353.9 samples/s | 28.7 steps/s
[Step= 500] | Loss=0.11424 | acc=0.9797 | tpr=0.9211 | fpr=0.0192 | 7891.3 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.11395 | acc=0.9799 | tpr=0.9200 | fpr=0.0190 | 14778.0 samples/s | 57.7 steps/s
Avg test loss: 0.11374, Avg test acc: 0.97993, Avg tpr: 0.91997, Avg fpr: 0.01898, total FA: 2636

server round 23/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=224.3] | Loss=0.00482 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.211 | L2-Norm(final)=13.329 | 5532.8 samples/s | 86.5 steps/s
[Step=46050 Epoch=224.5] | Loss=0.00353 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.211 | L2-Norm(final)=13.334 | 4372.9 samples/s | 68.3 steps/s
[Step=46100 Epoch=224.8] | Loss=0.00351 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.210 | L2-Norm(final)=13.341 | 5063.2 samples/s | 79.1 steps/s
[Step=46150 Epoch=225.0] | Loss=0.00328 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.209 | L2-Norm(final)=13.349 | 4976.2 samples/s | 77.8 steps/s
[Step=46200 Epoch=225.3] | Loss=0.00301 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.209 | L2-Norm(final)=13.356 | 7866.4 samples/s | 122.9 steps/s
[Step=46250 Epoch=225.5] | Loss=0.00286 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=13.364 | 2210.0 samples/s | 34.5 steps/s
[Step=46300 Epoch=225.8] | Loss=0.00275 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.205 | L2-Norm(final)=13.372 | 5250.9 samples/s | 82.0 steps/s
[Step=46350 Epoch=226.0] | Loss=0.00273 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.203 | L2-Norm(final)=13.380 | 4795.5 samples/s | 74.9 steps/s
[Step=46400 Epoch=226.3] | Loss=0.00279 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.200 | L2-Norm(final)=13.387 | 6956.3 samples/s | 108.7 steps/s
[Step=46450 Epoch=226.5] | Loss=0.00270 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.198 | L2-Norm(final)=13.395 | 2311.8 samples/s | 36.1 steps/s
[Step=46500 Epoch=226.7] | Loss=0.00271 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.195 | L2-Norm(final)=13.402 | 5096.8 samples/s | 79.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=226.7] | Loss=0.00023 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.167 | L2-Norm(final)=13.475 | 5519.0 samples/s | 86.2 steps/s
[Step=46550 Epoch=227.0] | Loss=0.00330 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.166 | L2-Norm(final)=13.481 | 4016.4 samples/s | 62.8 steps/s
[Step=46600 Epoch=227.2] | Loss=0.00416 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.168 | L2-Norm(final)=13.487 | 4379.5 samples/s | 68.4 steps/s
[Step=46650 Epoch=227.5] | Loss=0.00534 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=13.493 | 4467.5 samples/s | 69.8 steps/s
[Step=46700 Epoch=227.7] | Loss=0.00625 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.183 | L2-Norm(final)=13.499 | 6533.2 samples/s | 102.1 steps/s
[Step=46750 Epoch=228.0] | Loss=0.00695 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.194 | L2-Norm(final)=13.505 | 2097.2 samples/s | 32.8 steps/s
[Step=46800 Epoch=228.2] | Loss=0.00686 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.205 | L2-Norm(final)=13.511 | 4388.1 samples/s | 68.6 steps/s
[Step=46850 Epoch=228.4] | Loss=0.00678 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.215 | L2-Norm(final)=13.517 | 4488.6 samples/s | 70.1 steps/s
[Step=46900 Epoch=228.7] | Loss=0.00656 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.224 | L2-Norm(final)=13.523 | 5931.5 samples/s | 92.7 steps/s
[Step=46950 Epoch=228.9] | Loss=0.00635 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.231 | L2-Norm(final)=13.529 | 2133.0 samples/s | 33.3 steps/s
[Step=47000 Epoch=229.2] | Loss=0.00608 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.237 | L2-Norm(final)=13.535 | 4558.2 samples/s | 71.2 steps/s
[Step=47050 Epoch=229.4] | Loss=0.00580 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.241 | L2-Norm(final)=13.541 | 4432.1 samples/s | 69.3 steps/s
[Step=47100 Epoch=229.7] | Loss=0.00554 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.245 | L2-Norm(final)=13.547 | 5403.3 samples/s | 84.4 steps/s
[Step=47150 Epoch=229.9] | Loss=0.00527 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.247 | L2-Norm(final)=13.552 | 2246.4 samples/s | 35.1 steps/s
[Step=47200 Epoch=230.2] | Loss=0.00515 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.248 | L2-Norm(final)=13.557 | 4466.7 samples/s | 69.8 steps/s
[Step=47250 Epoch=230.4] | Loss=0.00497 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=13.561 | 4563.5 samples/s | 71.3 steps/s
[Step=47300 Epoch=230.6] | Loss=0.00493 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.250 | L2-Norm(final)=13.565 | 4774.8 samples/s | 74.6 steps/s
[Step=47350 Epoch=230.9] | Loss=0.00477 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=13.569 | 2330.6 samples/s | 36.4 steps/s
[Step=47400 Epoch=231.1] | Loss=0.00470 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.249 | L2-Norm(final)=13.573 | 4468.3 samples/s | 69.8 steps/s
[Step=47450 Epoch=231.4] | Loss=0.00459 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.248 | L2-Norm(final)=13.576 | 4534.5 samples/s | 70.9 steps/s
[Step=47500 Epoch=231.6] | Loss=0.00450 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.246 | L2-Norm(final)=13.580 | 4541.4 samples/s | 71.0 steps/s
[Step=47550 Epoch=231.9] | Loss=0.00439 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.244 | L2-Norm(final)=13.583 | 2368.9 samples/s | 37.0 steps/s
[Step=47600 Epoch=232.1] | Loss=0.00432 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.242 | L2-Norm(final)=13.586 | 4586.8 samples/s | 71.7 steps/s
[Step=47650 Epoch=232.4] | Loss=0.00419 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.240 | L2-Norm(final)=13.590 | 4270.1 samples/s | 66.7 steps/s
[Step=47700 Epoch=232.6] | Loss=0.00408 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.238 | L2-Norm(final)=13.593 | 4461.4 samples/s | 69.7 steps/s
[Step=47750 Epoch=232.8] | Loss=0.00401 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.235 | L2-Norm(final)=13.596 | 2480.1 samples/s | 38.8 steps/s
[Step=47800 Epoch=233.1] | Loss=0.00393 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.232 | L2-Norm(final)=13.599 | 4490.8 samples/s | 70.2 steps/s
[Step=47850 Epoch=233.3] | Loss=0.00390 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.229 | L2-Norm(final)=13.602 | 4403.4 samples/s | 68.8 steps/s
[Step=47900 Epoch=233.6] | Loss=0.00386 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.226 | L2-Norm(final)=13.604 | 4446.9 samples/s | 69.5 steps/s
[Step=47950 Epoch=233.8] | Loss=0.00382 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.222 | L2-Norm(final)=13.607 | 2475.0 samples/s | 38.7 steps/s
[Step=48000 Epoch=234.1] | Loss=0.00374 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.219 | L2-Norm(final)=13.610 | 4335.9 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step48000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=224.5] | Loss=0.00061 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.069 | L2-Norm(final)=13.553 | 5301.2 samples/s | 82.8 steps/s
[Step=46050 Epoch=224.7] | Loss=0.00276 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.067 | L2-Norm(final)=13.560 | 4331.5 samples/s | 67.7 steps/s
[Step=46100 Epoch=224.9] | Loss=0.00286 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.066 | L2-Norm(final)=13.570 | 5049.9 samples/s | 78.9 steps/s
[Step=46150 Epoch=225.2] | Loss=0.00260 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.065 | L2-Norm(final)=13.579 | 5069.6 samples/s | 79.2 steps/s
[Step=46200 Epoch=225.4] | Loss=0.00244 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.064 | L2-Norm(final)=13.587 | 7893.1 samples/s | 123.3 steps/s
[Step=46250 Epoch=225.7] | Loss=0.00233 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.061 | L2-Norm(final)=13.596 | 2215.4 samples/s | 34.6 steps/s
[Step=46300 Epoch=225.9] | Loss=0.00229 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.059 | L2-Norm(final)=13.604 | 5019.2 samples/s | 78.4 steps/s
[Step=46350 Epoch=226.2] | Loss=0.00237 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.056 | L2-Norm(final)=13.612 | 4890.0 samples/s | 76.4 steps/s
[Step=46400 Epoch=226.4] | Loss=0.00225 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.053 | L2-Norm(final)=13.620 | 7057.6 samples/s | 110.3 steps/s
[Step=46450 Epoch=226.7] | Loss=0.00222 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.049 | L2-Norm(final)=13.628 | 2277.5 samples/s | 35.6 steps/s
[Step=46500 Epoch=226.9] | Loss=0.00212 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.046 | L2-Norm(final)=13.637 | 4934.6 samples/s | 77.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=226.9] | Loss=0.00030 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.011 | L2-Norm(final)=13.720 | 5464.1 samples/s | 85.4 steps/s
[Step=46550 Epoch=227.1] | Loss=0.00563 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.011 | L2-Norm(final)=13.725 | 4098.0 samples/s | 64.0 steps/s
[Step=46600 Epoch=227.4] | Loss=0.00547 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.023 | L2-Norm(final)=13.732 | 4473.0 samples/s | 69.9 steps/s
[Step=46650 Epoch=227.6] | Loss=0.00565 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.035 | L2-Norm(final)=13.740 | 4491.9 samples/s | 70.2 steps/s
[Step=46700 Epoch=227.9] | Loss=0.00545 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.045 | L2-Norm(final)=13.749 | 6332.4 samples/s | 98.9 steps/s
[Step=46750 Epoch=228.1] | Loss=0.00523 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.054 | L2-Norm(final)=13.757 | 2097.5 samples/s | 32.8 steps/s
[Step=46800 Epoch=228.4] | Loss=0.00508 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.060 | L2-Norm(final)=13.765 | 4451.8 samples/s | 69.6 steps/s
[Step=46850 Epoch=228.6] | Loss=0.00523 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.066 | L2-Norm(final)=13.773 | 4431.9 samples/s | 69.2 steps/s
[Step=46900 Epoch=228.9] | Loss=0.00547 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.071 | L2-Norm(final)=13.780 | 6018.5 samples/s | 94.0 steps/s
[Step=46950 Epoch=229.1] | Loss=0.00542 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.076 | L2-Norm(final)=13.787 | 2137.7 samples/s | 33.4 steps/s
[Step=47000 Epoch=229.3] | Loss=0.00539 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.080 | L2-Norm(final)=13.793 | 4343.8 samples/s | 67.9 steps/s
[Step=47050 Epoch=229.6] | Loss=0.00535 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.084 | L2-Norm(final)=13.799 | 4485.2 samples/s | 70.1 steps/s
[Step=47100 Epoch=229.8] | Loss=0.00529 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.087 | L2-Norm(final)=13.804 | 5564.6 samples/s | 86.9 steps/s
[Step=47150 Epoch=230.1] | Loss=0.00515 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.091 | L2-Norm(final)=13.810 | 2198.5 samples/s | 34.4 steps/s
[Step=47200 Epoch=230.3] | Loss=0.00494 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.093 | L2-Norm(final)=13.815 | 4444.7 samples/s | 69.4 steps/s
[Step=47250 Epoch=230.6] | Loss=0.00477 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.095 | L2-Norm(final)=13.821 | 4475.0 samples/s | 69.9 steps/s
[Step=47300 Epoch=230.8] | Loss=0.00468 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.096 | L2-Norm(final)=13.826 | 5230.5 samples/s | 81.7 steps/s
[Step=47350 Epoch=231.0] | Loss=0.00455 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.097 | L2-Norm(final)=13.831 | 2269.3 samples/s | 35.5 steps/s
[Step=47400 Epoch=231.3] | Loss=0.00447 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.097 | L2-Norm(final)=13.835 | 4384.5 samples/s | 68.5 steps/s
[Step=47450 Epoch=231.5] | Loss=0.00434 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.097 | L2-Norm(final)=13.840 | 4459.8 samples/s | 69.7 steps/s
[Step=47500 Epoch=231.8] | Loss=0.00422 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.096 | L2-Norm(final)=13.844 | 4891.7 samples/s | 76.4 steps/s
[Step=47550 Epoch=232.0] | Loss=0.00409 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.095 | L2-Norm(final)=13.849 | 2336.3 samples/s | 36.5 steps/s
[Step=47600 Epoch=232.3] | Loss=0.00398 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.093 | L2-Norm(final)=13.853 | 4505.6 samples/s | 70.4 steps/s
[Step=47650 Epoch=232.5] | Loss=0.00392 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.091 | L2-Norm(final)=13.857 | 4469.9 samples/s | 69.8 steps/s
[Step=47700 Epoch=232.8] | Loss=0.00383 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.089 | L2-Norm(final)=13.860 | 4532.5 samples/s | 70.8 steps/s
[Step=47750 Epoch=233.0] | Loss=0.00374 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.087 | L2-Norm(final)=13.864 | 2340.2 samples/s | 36.6 steps/s
[Step=47800 Epoch=233.2] | Loss=0.00365 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.084 | L2-Norm(final)=13.868 | 4565.5 samples/s | 71.3 steps/s
[Step=47850 Epoch=233.5] | Loss=0.00360 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.082 | L2-Norm(final)=13.871 | 4487.3 samples/s | 70.1 steps/s
[Step=47900 Epoch=233.7] | Loss=0.00355 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.079 | L2-Norm(final)=13.874 | 4392.0 samples/s | 68.6 steps/s
[Step=47950 Epoch=234.0] | Loss=0.00352 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.076 | L2-Norm(final)=13.878 | 2453.0 samples/s | 38.3 steps/s
[Step=48000 Epoch=234.2] | Loss=0.00343 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.072 | L2-Norm(final)=13.881 | 4574.1 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step48000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=224.1] | Loss=0.00447 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.673 | L2-Norm(final)=13.967 | 5445.0 samples/s | 85.1 steps/s
[Step=46050 Epoch=224.4] | Loss=0.00343 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.670 | L2-Norm(final)=13.974 | 4376.9 samples/s | 68.4 steps/s
[Step=46100 Epoch=224.6] | Loss=0.00326 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.671 | L2-Norm(final)=13.982 | 4962.6 samples/s | 77.5 steps/s
[Step=46150 Epoch=224.9] | Loss=0.00297 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.670 | L2-Norm(final)=13.991 | 5053.0 samples/s | 79.0 steps/s
[Step=46200 Epoch=225.1] | Loss=0.00298 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.669 | L2-Norm(final)=14.000 | 7903.8 samples/s | 123.5 steps/s
[Step=46250 Epoch=225.4] | Loss=0.00283 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.667 | L2-Norm(final)=14.008 | 2211.4 samples/s | 34.6 steps/s
[Step=46300 Epoch=225.6] | Loss=0.00282 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.666 | L2-Norm(final)=14.017 | 5040.4 samples/s | 78.8 steps/s
[Step=46350 Epoch=225.8] | Loss=0.00281 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.664 | L2-Norm(final)=14.025 | 5120.7 samples/s | 80.0 steps/s
[Step=46400 Epoch=226.1] | Loss=0.00271 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.661 | L2-Norm(final)=14.033 | 6800.1 samples/s | 106.3 steps/s
[Step=46450 Epoch=226.3] | Loss=0.00278 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.659 | L2-Norm(final)=14.042 | 2294.3 samples/s | 35.8 steps/s
[Step=46500 Epoch=226.6] | Loss=0.00275 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.656 | L2-Norm(final)=14.050 | 4908.4 samples/s | 76.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=226.6] | Loss=0.00086 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.631 | L2-Norm(final)=14.128 | 5253.2 samples/s | 82.1 steps/s
[Step=46550 Epoch=226.8] | Loss=0.00393 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.632 | L2-Norm(final)=14.135 | 4064.5 samples/s | 63.5 steps/s
[Step=46600 Epoch=227.1] | Loss=0.00583 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.644 | L2-Norm(final)=14.142 | 4519.8 samples/s | 70.6 steps/s
[Step=46650 Epoch=227.3] | Loss=0.00740 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.657 | L2-Norm(final)=14.150 | 4456.1 samples/s | 69.6 steps/s
[Step=46700 Epoch=227.5] | Loss=0.00727 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.669 | L2-Norm(final)=14.158 | 6539.0 samples/s | 102.2 steps/s
[Step=46750 Epoch=227.8] | Loss=0.00678 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.679 | L2-Norm(final)=14.166 | 2088.2 samples/s | 32.6 steps/s
[Step=46800 Epoch=228.0] | Loss=0.00665 | Reg=0.00313 | acc=0.9688 | L2-Norm=17.685 | L2-Norm(final)=14.172 | 4524.5 samples/s | 70.7 steps/s
[Step=46850 Epoch=228.3] | Loss=0.00646 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.689 | L2-Norm(final)=14.178 | 4460.1 samples/s | 69.7 steps/s
[Step=46900 Epoch=228.5] | Loss=0.00611 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.693 | L2-Norm(final)=14.184 | 5911.2 samples/s | 92.4 steps/s
[Step=46950 Epoch=228.8] | Loss=0.00581 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.696 | L2-Norm(final)=14.190 | 2149.4 samples/s | 33.6 steps/s
[Step=47000 Epoch=229.0] | Loss=0.00557 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.698 | L2-Norm(final)=14.195 | 4479.9 samples/s | 70.0 steps/s
[Step=47050 Epoch=229.3] | Loss=0.00542 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.699 | L2-Norm(final)=14.201 | 4524.4 samples/s | 70.7 steps/s
[Step=47100 Epoch=229.5] | Loss=0.00530 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.700 | L2-Norm(final)=14.205 | 5267.6 samples/s | 82.3 steps/s
[Step=47150 Epoch=229.7] | Loss=0.00520 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.700 | L2-Norm(final)=14.210 | 2192.6 samples/s | 34.3 steps/s
[Step=47200 Epoch=230.0] | Loss=0.00507 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.701 | L2-Norm(final)=14.215 | 4454.4 samples/s | 69.6 steps/s
[Step=47250 Epoch=230.2] | Loss=0.00500 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.701 | L2-Norm(final)=14.219 | 4492.9 samples/s | 70.2 steps/s
[Step=47300 Epoch=230.5] | Loss=0.00494 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.701 | L2-Norm(final)=14.223 | 4981.0 samples/s | 77.8 steps/s
[Step=47350 Epoch=230.7] | Loss=0.00479 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.700 | L2-Norm(final)=14.227 | 2320.8 samples/s | 36.3 steps/s
[Step=47400 Epoch=231.0] | Loss=0.00473 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.699 | L2-Norm(final)=14.231 | 4467.3 samples/s | 69.8 steps/s
[Step=47450 Epoch=231.2] | Loss=0.00467 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.698 | L2-Norm(final)=14.234 | 4493.1 samples/s | 70.2 steps/s
[Step=47500 Epoch=231.4] | Loss=0.00463 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.696 | L2-Norm(final)=14.238 | 4491.6 samples/s | 70.2 steps/s
[Step=47550 Epoch=231.7] | Loss=0.00455 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.695 | L2-Norm(final)=14.241 | 2448.1 samples/s | 38.3 steps/s
[Step=47600 Epoch=231.9] | Loss=0.00456 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.693 | L2-Norm(final)=14.244 | 4459.6 samples/s | 69.7 steps/s
[Step=47650 Epoch=232.2] | Loss=0.00448 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.691 | L2-Norm(final)=14.248 | 4474.4 samples/s | 69.9 steps/s
[Step=47700 Epoch=232.4] | Loss=0.00446 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.689 | L2-Norm(final)=14.251 | 4462.0 samples/s | 69.7 steps/s
[Step=47750 Epoch=232.7] | Loss=0.00439 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.686 | L2-Norm(final)=14.254 | 2438.0 samples/s | 38.1 steps/s
[Step=47800 Epoch=232.9] | Loss=0.00432 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.684 | L2-Norm(final)=14.257 | 4345.5 samples/s | 67.9 steps/s
[Step=47850 Epoch=233.1] | Loss=0.00424 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.682 | L2-Norm(final)=14.260 | 4476.0 samples/s | 69.9 steps/s
[Step=47900 Epoch=233.4] | Loss=0.00423 | Reg=0.00313 | acc=0.9688 | L2-Norm=17.679 | L2-Norm(final)=14.263 | 4449.8 samples/s | 69.5 steps/s
[Step=47950 Epoch=233.6] | Loss=0.00419 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.676 | L2-Norm(final)=14.266 | 2481.3 samples/s | 38.8 steps/s
[Step=48000 Epoch=233.9] | Loss=0.00412 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.674 | L2-Norm(final)=14.269 | 4404.9 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step48000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=224.3] | Loss=0.00066 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.359 | L2-Norm(final)=13.852 | 5590.4 samples/s | 87.3 steps/s
[Step=46050 Epoch=224.6] | Loss=0.00288 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.359 | L2-Norm(final)=13.858 | 4402.4 samples/s | 68.8 steps/s
[Step=46100 Epoch=224.8] | Loss=0.00296 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.360 | L2-Norm(final)=13.866 | 4971.0 samples/s | 77.7 steps/s
[Step=46150 Epoch=225.1] | Loss=0.00272 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.360 | L2-Norm(final)=13.873 | 5056.2 samples/s | 79.0 steps/s
[Step=46200 Epoch=225.3] | Loss=0.00275 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.359 | L2-Norm(final)=13.880 | 7821.0 samples/s | 122.2 steps/s
[Step=46250 Epoch=225.5] | Loss=0.00254 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.357 | L2-Norm(final)=13.888 | 2250.0 samples/s | 35.2 steps/s
[Step=46300 Epoch=225.8] | Loss=0.00252 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.355 | L2-Norm(final)=13.895 | 5087.0 samples/s | 79.5 steps/s
[Step=46350 Epoch=226.0] | Loss=0.00256 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.353 | L2-Norm(final)=13.902 | 5040.9 samples/s | 78.8 steps/s
[Step=46400 Epoch=226.3] | Loss=0.00244 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.351 | L2-Norm(final)=13.910 | 6806.9 samples/s | 106.4 steps/s
[Step=46450 Epoch=226.5] | Loss=0.00244 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.349 | L2-Norm(final)=13.917 | 2308.1 samples/s | 36.1 steps/s
[Step=46500 Epoch=226.8] | Loss=0.00243 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.346 | L2-Norm(final)=13.924 | 4891.0 samples/s | 76.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=226.8] | Loss=0.00072 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.322 | L2-Norm(final)=13.999 | 5732.6 samples/s | 89.6 steps/s
[Step=46550 Epoch=227.0] | Loss=0.00212 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.320 | L2-Norm(final)=14.006 | 3958.3 samples/s | 61.8 steps/s
[Step=46600 Epoch=227.2] | Loss=0.00242 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=14.013 | 4486.1 samples/s | 70.1 steps/s
[Step=46650 Epoch=227.5] | Loss=0.00374 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.321 | L2-Norm(final)=14.019 | 4457.3 samples/s | 69.6 steps/s
[Step=46700 Epoch=227.7] | Loss=0.00432 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.327 | L2-Norm(final)=14.026 | 6589.8 samples/s | 103.0 steps/s
[Step=46750 Epoch=228.0] | Loss=0.00515 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.333 | L2-Norm(final)=14.034 | 2084.3 samples/s | 32.6 steps/s
[Step=46800 Epoch=228.2] | Loss=0.00499 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.338 | L2-Norm(final)=14.041 | 4447.8 samples/s | 69.5 steps/s
[Step=46850 Epoch=228.5] | Loss=0.00490 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.343 | L2-Norm(final)=14.048 | 4347.3 samples/s | 67.9 steps/s
[Step=46900 Epoch=228.7] | Loss=0.00478 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.347 | L2-Norm(final)=14.054 | 5932.6 samples/s | 92.7 steps/s
[Step=46950 Epoch=229.0] | Loss=0.00459 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.350 | L2-Norm(final)=14.060 | 2156.4 samples/s | 33.7 steps/s
[Step=47000 Epoch=229.2] | Loss=0.00439 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.352 | L2-Norm(final)=14.066 | 4479.4 samples/s | 70.0 steps/s
[Step=47050 Epoch=229.4] | Loss=0.00449 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.353 | L2-Norm(final)=14.071 | 4503.3 samples/s | 70.4 steps/s
[Step=47100 Epoch=229.7] | Loss=0.00429 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.353 | L2-Norm(final)=14.075 | 5404.4 samples/s | 84.4 steps/s
[Step=47150 Epoch=229.9] | Loss=0.00411 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.353 | L2-Norm(final)=14.080 | 2243.1 samples/s | 35.0 steps/s
[Step=47200 Epoch=230.2] | Loss=0.00400 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.353 | L2-Norm(final)=14.085 | 4388.8 samples/s | 68.6 steps/s
[Step=47250 Epoch=230.4] | Loss=0.00384 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.351 | L2-Norm(final)=14.089 | 4502.7 samples/s | 70.4 steps/s
[Step=47300 Epoch=230.7] | Loss=0.00375 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.350 | L2-Norm(final)=14.093 | 4971.9 samples/s | 77.7 steps/s
[Step=47350 Epoch=230.9] | Loss=0.00369 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.348 | L2-Norm(final)=14.097 | 2350.5 samples/s | 36.7 steps/s
[Step=47400 Epoch=231.1] | Loss=0.00363 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.346 | L2-Norm(final)=14.100 | 4470.2 samples/s | 69.8 steps/s
[Step=47450 Epoch=231.4] | Loss=0.00358 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.343 | L2-Norm(final)=14.103 | 4445.1 samples/s | 69.5 steps/s
[Step=47500 Epoch=231.6] | Loss=0.00351 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.341 | L2-Norm(final)=14.107 | 4619.3 samples/s | 72.2 steps/s
[Step=47550 Epoch=231.9] | Loss=0.00344 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.338 | L2-Norm(final)=14.110 | 2356.1 samples/s | 36.8 steps/s
[Step=47600 Epoch=232.1] | Loss=0.00336 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.335 | L2-Norm(final)=14.113 | 4490.2 samples/s | 70.2 steps/s
[Step=47650 Epoch=232.4] | Loss=0.00325 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.332 | L2-Norm(final)=14.117 | 4482.2 samples/s | 70.0 steps/s
[Step=47700 Epoch=232.6] | Loss=0.00322 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.328 | L2-Norm(final)=14.120 | 4439.3 samples/s | 69.4 steps/s
[Step=47750 Epoch=232.9] | Loss=0.00325 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.324 | L2-Norm(final)=14.123 | 2467.7 samples/s | 38.6 steps/s
[Step=47800 Epoch=233.1] | Loss=0.00321 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.321 | L2-Norm(final)=14.126 | 4513.1 samples/s | 70.5 steps/s
[Step=47850 Epoch=233.3] | Loss=0.00319 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.317 | L2-Norm(final)=14.129 | 4453.6 samples/s | 69.6 steps/s
[Step=47900 Epoch=233.6] | Loss=0.00311 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.312 | L2-Norm(final)=14.132 | 4386.2 samples/s | 68.5 steps/s
[Step=47950 Epoch=233.8] | Loss=0.00306 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.308 | L2-Norm(final)=14.135 | 2440.1 samples/s | 38.1 steps/s
[Step=48000 Epoch=234.1] | Loss=0.00315 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.303 | L2-Norm(final)=14.138 | 4508.9 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step48000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=225.6] | Loss=0.00016 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.126 | L2-Norm(final)=13.873 | 5428.9 samples/s | 84.8 steps/s
[Step=46050 Epoch=225.8] | Loss=0.00224 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.125 | L2-Norm(final)=13.879 | 4391.7 samples/s | 68.6 steps/s
[Step=46100 Epoch=226.1] | Loss=0.00247 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=13.888 | 5173.6 samples/s | 80.8 steps/s
[Step=46150 Epoch=226.3] | Loss=0.00253 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.122 | L2-Norm(final)=13.898 | 4933.8 samples/s | 77.1 steps/s
[Step=46200 Epoch=226.6] | Loss=0.00241 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.121 | L2-Norm(final)=13.907 | 8114.5 samples/s | 126.8 steps/s
[Step=46250 Epoch=226.8] | Loss=0.00236 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.120 | L2-Norm(final)=13.916 | 2172.5 samples/s | 33.9 steps/s
[Step=46300 Epoch=227.0] | Loss=0.00221 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.118 | L2-Norm(final)=13.926 | 4872.3 samples/s | 76.1 steps/s
[Step=46350 Epoch=227.3] | Loss=0.00222 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.116 | L2-Norm(final)=13.935 | 4980.7 samples/s | 77.8 steps/s
[Step=46400 Epoch=227.5] | Loss=0.00232 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.114 | L2-Norm(final)=13.944 | 7465.9 samples/s | 116.7 steps/s
[Step=46450 Epoch=227.8] | Loss=0.00224 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.112 | L2-Norm(final)=13.953 | 2229.2 samples/s | 34.8 steps/s
[Step=46500 Epoch=228.0] | Loss=0.00223 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.109 | L2-Norm(final)=13.962 | 5142.1 samples/s | 80.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=228.0] | Loss=0.00071 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.083 | L2-Norm(final)=14.052 | 5757.5 samples/s | 90.0 steps/s
[Step=46550 Epoch=228.3] | Loss=0.00358 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.083 | L2-Norm(final)=14.062 | 3958.1 samples/s | 61.8 steps/s
[Step=46600 Epoch=228.5] | Loss=0.00506 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.094 | L2-Norm(final)=14.070 | 4302.9 samples/s | 67.2 steps/s
[Step=46650 Epoch=228.8] | Loss=0.00510 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.108 | L2-Norm(final)=14.081 | 4506.8 samples/s | 70.4 steps/s
[Step=46700 Epoch=229.0] | Loss=0.00595 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.121 | L2-Norm(final)=14.091 | 6608.2 samples/s | 103.3 steps/s
[Step=46750 Epoch=229.3] | Loss=0.00649 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.135 | L2-Norm(final)=14.100 | 2089.5 samples/s | 32.6 steps/s
[Step=46800 Epoch=229.5] | Loss=0.00648 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.148 | L2-Norm(final)=14.108 | 4480.1 samples/s | 70.0 steps/s
[Step=46850 Epoch=229.7] | Loss=0.00642 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.158 | L2-Norm(final)=14.116 | 4513.2 samples/s | 70.5 steps/s
[Step=46900 Epoch=230.0] | Loss=0.00634 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.167 | L2-Norm(final)=14.123 | 6136.2 samples/s | 95.9 steps/s
[Step=46950 Epoch=230.2] | Loss=0.00607 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.175 | L2-Norm(final)=14.130 | 2122.0 samples/s | 33.2 steps/s
[Step=47000 Epoch=230.5] | Loss=0.00582 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.181 | L2-Norm(final)=14.137 | 4509.4 samples/s | 70.5 steps/s
[Step=47050 Epoch=230.7] | Loss=0.00563 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.186 | L2-Norm(final)=14.143 | 4482.6 samples/s | 70.0 steps/s
[Step=47100 Epoch=231.0] | Loss=0.00540 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.189 | L2-Norm(final)=14.149 | 5794.7 samples/s | 90.5 steps/s
[Step=47150 Epoch=231.2] | Loss=0.00516 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.192 | L2-Norm(final)=14.155 | 2180.1 samples/s | 34.1 steps/s
[Step=47200 Epoch=231.5] | Loss=0.00493 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.194 | L2-Norm(final)=14.160 | 4358.8 samples/s | 68.1 steps/s
[Step=47250 Epoch=231.7] | Loss=0.00477 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.195 | L2-Norm(final)=14.165 | 4436.2 samples/s | 69.3 steps/s
[Step=47300 Epoch=232.0] | Loss=0.00463 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.196 | L2-Norm(final)=14.169 | 5536.9 samples/s | 86.5 steps/s
[Step=47350 Epoch=232.2] | Loss=0.00444 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.196 | L2-Norm(final)=14.174 | 2237.3 samples/s | 35.0 steps/s
[Step=47400 Epoch=232.4] | Loss=0.00431 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.196 | L2-Norm(final)=14.178 | 4409.0 samples/s | 68.9 steps/s
[Step=47450 Epoch=232.7] | Loss=0.00421 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.195 | L2-Norm(final)=14.182 | 4509.2 samples/s | 70.5 steps/s
[Step=47500 Epoch=232.9] | Loss=0.00409 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.194 | L2-Norm(final)=14.186 | 5211.2 samples/s | 81.4 steps/s
[Step=47550 Epoch=233.2] | Loss=0.00400 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.193 | L2-Norm(final)=14.190 | 2282.8 samples/s | 35.7 steps/s
[Step=47600 Epoch=233.4] | Loss=0.00392 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.191 | L2-Norm(final)=14.194 | 4529.7 samples/s | 70.8 steps/s
[Step=47650 Epoch=233.7] | Loss=0.00390 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.189 | L2-Norm(final)=14.197 | 4382.8 samples/s | 68.5 steps/s
[Step=47700 Epoch=233.9] | Loss=0.00381 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.187 | L2-Norm(final)=14.201 | 4931.2 samples/s | 77.0 steps/s
[Step=47750 Epoch=234.2] | Loss=0.00372 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.185 | L2-Norm(final)=14.204 | 2313.3 samples/s | 36.1 steps/s
[Step=47800 Epoch=234.4] | Loss=0.00363 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.183 | L2-Norm(final)=14.207 | 4456.1 samples/s | 69.6 steps/s
[Step=47850 Epoch=234.6] | Loss=0.00356 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.180 | L2-Norm(final)=14.211 | 4501.3 samples/s | 70.3 steps/s
[Step=47900 Epoch=234.9] | Loss=0.00349 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=14.214 | 4680.5 samples/s | 73.1 steps/s
[Step=47950 Epoch=235.1] | Loss=0.00342 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.175 | L2-Norm(final)=14.217 | 2422.3 samples/s | 37.8 steps/s
[Step=48000 Epoch=235.4] | Loss=0.00335 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.172 | L2-Norm(final)=14.220 | 4392.0 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step48000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=435.9] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.564 | L2-Norm(final)=7.396 | 5822.4 samples/s | 91.0 steps/s
[Step=46050 Epoch=436.4] | Loss=0.00006 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.570 | L2-Norm(final)=7.401 | 3794.1 samples/s | 59.3 steps/s
[Step=46100 Epoch=436.8] | Loss=0.00004 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.573 | L2-Norm(final)=7.407 | 7464.6 samples/s | 116.6 steps/s
[Step=46150 Epoch=437.3] | Loss=0.00004 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.575 | L2-Norm(final)=7.412 | 2138.4 samples/s | 33.4 steps/s
[Step=46200 Epoch=437.8] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.576 | L2-Norm(final)=7.417 | 6527.8 samples/s | 102.0 steps/s
[Step=46250 Epoch=438.3] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.577 | L2-Norm(final)=7.421 | 2222.9 samples/s | 34.7 steps/s
[Step=46300 Epoch=438.7] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.577 | L2-Norm(final)=7.426 | 5970.5 samples/s | 93.3 steps/s
[Step=46350 Epoch=439.2] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.578 | L2-Norm(final)=7.430 | 2297.6 samples/s | 35.9 steps/s
[Step=46400 Epoch=439.7] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.578 | L2-Norm(final)=7.435 | 5352.9 samples/s | 83.6 steps/s
[Step=46450 Epoch=440.2] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.579 | L2-Norm(final)=7.439 | 2402.5 samples/s | 37.5 steps/s
[Step=46500 Epoch=440.6] | Loss=0.00002 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.579 | L2-Norm(final)=7.443 | 4919.2 samples/s | 76.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=440.6] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.582 | L2-Norm(final)=7.484 | 5297.3 samples/s | 82.8 steps/s
[Step=46550 Epoch=441.1] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.577 | L2-Norm(final)=7.488 | 3905.5 samples/s | 61.0 steps/s
[Step=46600 Epoch=441.6] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.571 | L2-Norm(final)=7.491 | 6343.9 samples/s | 99.1 steps/s
[Step=46650 Epoch=442.0] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.563 | L2-Norm(final)=7.494 | 2015.9 samples/s | 31.5 steps/s
[Step=46700 Epoch=442.5] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.556 | L2-Norm(final)=7.496 | 5621.7 samples/s | 87.8 steps/s
[Step=46750 Epoch=443.0] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.547 | L2-Norm(final)=7.497 | 2088.0 samples/s | 32.6 steps/s
[Step=46800 Epoch=443.5] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=7.499 | 5140.1 samples/s | 80.3 steps/s
[Step=46850 Epoch=443.9] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.530 | L2-Norm(final)=7.500 | 2157.9 samples/s | 33.7 steps/s
[Step=46900 Epoch=444.4] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.521 | L2-Norm(final)=7.502 | 4748.7 samples/s | 74.2 steps/s
[Step=46950 Epoch=444.9] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.512 | L2-Norm(final)=7.503 | 2290.8 samples/s | 35.8 steps/s
[Step=47000 Epoch=445.4] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.503 | L2-Norm(final)=7.504 | 4325.2 samples/s | 67.6 steps/s
[Step=47050 Epoch=445.8] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.494 | L2-Norm(final)=7.505 | 2403.0 samples/s | 37.5 steps/s
[Step=47100 Epoch=446.3] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.485 | L2-Norm(final)=7.506 | 4146.8 samples/s | 64.8 steps/s
[Step=47150 Epoch=446.8] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.475 | L2-Norm(final)=7.508 | 2386.1 samples/s | 37.3 steps/s
[Step=47200 Epoch=447.3] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.466 | L2-Norm(final)=7.509 | 4243.0 samples/s | 66.3 steps/s
[Step=47250 Epoch=447.7] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.456 | L2-Norm(final)=7.510 | 2406.4 samples/s | 37.6 steps/s
[Step=47300 Epoch=448.2] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.446 | L2-Norm(final)=7.511 | 4304.2 samples/s | 67.3 steps/s
[Step=47350 Epoch=448.7] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.437 | L2-Norm(final)=7.512 | 2415.6 samples/s | 37.7 steps/s
[Step=47400 Epoch=449.2] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.427 | L2-Norm(final)=7.513 | 4093.1 samples/s | 64.0 steps/s
[Step=47450 Epoch=449.6] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.417 | L2-Norm(final)=7.514 | 6504.6 samples/s | 101.6 steps/s
[Step=47500 Epoch=450.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.407 | L2-Norm(final)=7.515 | 1986.5 samples/s | 31.0 steps/s
[Step=47550 Epoch=450.6] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.396 | L2-Norm(final)=7.517 | 5833.2 samples/s | 91.1 steps/s
[Step=47600 Epoch=451.1] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.386 | L2-Norm(final)=7.518 | 2059.4 samples/s | 32.2 steps/s
[Step=47650 Epoch=451.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.376 | L2-Norm(final)=7.519 | 5331.4 samples/s | 83.3 steps/s
[Step=47700 Epoch=452.0] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.365 | L2-Norm(final)=7.520 | 2150.3 samples/s | 33.6 steps/s
[Step=47750 Epoch=452.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.355 | L2-Norm(final)=7.521 | 4857.8 samples/s | 75.9 steps/s
[Step=47800 Epoch=452.9] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.344 | L2-Norm(final)=7.522 | 2232.9 samples/s | 34.9 steps/s
[Step=47850 Epoch=453.4] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.333 | L2-Norm(final)=7.524 | 4445.3 samples/s | 69.5 steps/s
[Step=47900 Epoch=453.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.322 | L2-Norm(final)=7.525 | 2359.9 samples/s | 36.9 steps/s
[Step=47950 Epoch=454.4] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.311 | L2-Norm(final)=7.526 | 4175.0 samples/s | 65.2 steps/s
[Step=48000 Epoch=454.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.300 | L2-Norm(final)=7.527 | 2330.2 samples/s | 36.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step48000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=437.6] | Loss=0.00002 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.493 | L2-Norm(final)=8.361 | 5631.8 samples/s | 88.0 steps/s
[Step=46050 Epoch=438.0] | Loss=0.00008 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.502 | L2-Norm(final)=8.380 | 4024.0 samples/s | 62.9 steps/s
[Step=46100 Epoch=438.5] | Loss=0.00007 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.516 | L2-Norm(final)=8.405 | 7458.2 samples/s | 116.5 steps/s
[Step=46150 Epoch=439.0] | Loss=0.00006 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.528 | L2-Norm(final)=8.428 | 2146.3 samples/s | 33.5 steps/s
[Step=46200 Epoch=439.5] | Loss=0.00005 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.536 | L2-Norm(final)=8.446 | 6485.2 samples/s | 101.3 steps/s
[Step=46250 Epoch=440.0] | Loss=0.00005 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.541 | L2-Norm(final)=8.461 | 2215.3 samples/s | 34.6 steps/s
[Step=46300 Epoch=440.4] | Loss=0.00004 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.544 | L2-Norm(final)=8.473 | 5924.7 samples/s | 92.6 steps/s
[Step=46350 Epoch=440.9] | Loss=0.00004 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.546 | L2-Norm(final)=8.485 | 2301.2 samples/s | 36.0 steps/s
[Step=46400 Epoch=441.4] | Loss=0.00003 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.547 | L2-Norm(final)=8.495 | 5359.3 samples/s | 83.7 steps/s
[Step=46450 Epoch=441.9] | Loss=0.00003 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.547 | L2-Norm(final)=8.505 | 2414.1 samples/s | 37.7 steps/s
[Step=46500 Epoch=442.3] | Loss=0.00003 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.548 | L2-Norm(final)=8.514 | 5016.0 samples/s | 78.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=442.3] | Loss=0.00003 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.547 | L2-Norm(final)=8.603 | 5793.4 samples/s | 90.5 steps/s
[Step=46550 Epoch=442.8] | Loss=0.00088 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.565 | L2-Norm(final)=8.614 | 3682.4 samples/s | 57.5 steps/s
[Step=46600 Epoch=443.3] | Loss=0.00277 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.628 | L2-Norm(final)=8.612 | 6375.7 samples/s | 99.6 steps/s
[Step=46650 Epoch=443.8] | Loss=0.00231 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.665 | L2-Norm(final)=8.604 | 2022.8 samples/s | 31.6 steps/s
[Step=46700 Epoch=444.2] | Loss=0.00178 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.690 | L2-Norm(final)=8.600 | 5658.0 samples/s | 88.4 steps/s
[Step=46750 Epoch=444.7] | Loss=0.00146 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.705 | L2-Norm(final)=8.598 | 2097.2 samples/s | 32.8 steps/s
[Step=46800 Epoch=445.2] | Loss=0.00122 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.598 | 5072.6 samples/s | 79.3 steps/s
[Step=46850 Epoch=445.7] | Loss=0.00105 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.721 | L2-Norm(final)=8.597 | 2182.8 samples/s | 34.1 steps/s
[Step=46900 Epoch=446.1] | Loss=0.00092 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.726 | L2-Norm(final)=8.597 | 4721.7 samples/s | 73.8 steps/s
[Step=46950 Epoch=446.6] | Loss=0.00082 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.729 | L2-Norm(final)=8.597 | 2257.2 samples/s | 35.3 steps/s
[Step=47000 Epoch=447.1] | Loss=0.00074 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.731 | L2-Norm(final)=8.597 | 4364.4 samples/s | 68.2 steps/s
[Step=47050 Epoch=447.6] | Loss=0.00067 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.733 | L2-Norm(final)=8.598 | 2351.0 samples/s | 36.7 steps/s
[Step=47100 Epoch=448.0] | Loss=0.00062 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=8.598 | 4224.9 samples/s | 66.0 steps/s
[Step=47150 Epoch=448.5] | Loss=0.00057 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.735 | L2-Norm(final)=8.598 | 2393.6 samples/s | 37.4 steps/s
[Step=47200 Epoch=449.0] | Loss=0.00053 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.735 | L2-Norm(final)=8.599 | 4224.9 samples/s | 66.0 steps/s
[Step=47250 Epoch=449.5] | Loss=0.00050 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.736 | L2-Norm(final)=8.599 | 2383.6 samples/s | 37.2 steps/s
[Step=47300 Epoch=449.9] | Loss=0.00046 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.736 | L2-Norm(final)=8.599 | 4288.4 samples/s | 67.0 steps/s
[Step=47350 Epoch=450.4] | Loss=0.00044 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.735 | L2-Norm(final)=8.600 | 2544.0 samples/s | 39.8 steps/s
[Step=47400 Epoch=450.9] | Loss=0.00041 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.735 | L2-Norm(final)=8.600 | 3846.0 samples/s | 60.1 steps/s
[Step=47450 Epoch=451.4] | Loss=0.00039 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=8.600 | 6562.1 samples/s | 102.5 steps/s
[Step=47500 Epoch=451.8] | Loss=0.00037 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=8.601 | 1989.8 samples/s | 31.1 steps/s
[Step=47550 Epoch=452.3] | Loss=0.00036 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.733 | L2-Norm(final)=8.601 | 5774.8 samples/s | 90.2 steps/s
[Step=47600 Epoch=452.8] | Loss=0.00034 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.732 | L2-Norm(final)=8.602 | 2073.9 samples/s | 32.4 steps/s
[Step=47650 Epoch=453.3] | Loss=0.00033 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.731 | L2-Norm(final)=8.602 | 5381.7 samples/s | 84.1 steps/s
[Step=47700 Epoch=453.7] | Loss=0.00031 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.730 | L2-Norm(final)=8.602 | 2151.4 samples/s | 33.6 steps/s
[Step=47750 Epoch=454.2] | Loss=0.00030 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.729 | L2-Norm(final)=8.603 | 4893.0 samples/s | 76.5 steps/s
[Step=47800 Epoch=454.7] | Loss=0.00029 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.728 | L2-Norm(final)=8.603 | 2242.7 samples/s | 35.0 steps/s
[Step=47850 Epoch=455.2] | Loss=0.00028 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.727 | L2-Norm(final)=8.604 | 4439.6 samples/s | 69.4 steps/s
[Step=47900 Epoch=455.6] | Loss=0.00027 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.725 | L2-Norm(final)=8.604 | 2378.1 samples/s | 37.2 steps/s
[Step=47950 Epoch=456.1] | Loss=0.00026 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.724 | L2-Norm(final)=8.604 | 4187.2 samples/s | 65.4 steps/s
[Step=48000 Epoch=456.6] | Loss=0.00025 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.723 | L2-Norm(final)=8.605 | 2365.5 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step48000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=439.3] | Loss=0.00074 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.489 | L2-Norm(final)=7.856 | 5513.1 samples/s | 86.1 steps/s
[Step=46050 Epoch=439.7] | Loss=0.00022 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.515 | L2-Norm(final)=7.881 | 4107.1 samples/s | 64.2 steps/s
[Step=46100 Epoch=440.2] | Loss=0.00017 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=7.904 | 7597.3 samples/s | 118.7 steps/s
[Step=46150 Epoch=440.7] | Loss=0.00013 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.553 | L2-Norm(final)=7.921 | 2112.1 samples/s | 33.0 steps/s
[Step=46200 Epoch=441.2] | Loss=0.00010 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.561 | L2-Norm(final)=7.933 | 6829.0 samples/s | 106.7 steps/s
[Step=46250 Epoch=441.7] | Loss=0.00009 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.566 | L2-Norm(final)=7.943 | 2224.7 samples/s | 34.8 steps/s
[Step=46300 Epoch=442.1] | Loss=0.00008 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.569 | L2-Norm(final)=7.952 | 6050.0 samples/s | 94.5 steps/s
[Step=46350 Epoch=442.6] | Loss=0.00007 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.572 | L2-Norm(final)=7.960 | 2248.9 samples/s | 35.1 steps/s
[Step=46400 Epoch=443.1] | Loss=0.00006 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.574 | L2-Norm(final)=7.967 | 5732.8 samples/s | 89.6 steps/s
[Step=46450 Epoch=443.6] | Loss=0.00006 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.575 | L2-Norm(final)=7.974 | 2357.6 samples/s | 36.8 steps/s
[Step=46500 Epoch=444.0] | Loss=0.00005 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.576 | L2-Norm(final)=7.980 | 5151.8 samples/s | 80.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=444.1] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.584 | L2-Norm(final)=8.044 | 5475.3 samples/s | 85.6 steps/s
[Step=46550 Epoch=444.5] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.570 | L2-Norm(final)=8.050 | 3693.3 samples/s | 57.7 steps/s
[Step=46600 Epoch=445.0] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.546 | L2-Norm(final)=8.053 | 6338.2 samples/s | 99.0 steps/s
[Step=46650 Epoch=445.5] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.521 | L2-Norm(final)=8.055 | 1994.6 samples/s | 31.2 steps/s
[Step=46700 Epoch=446.0] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.495 | L2-Norm(final)=8.057 | 5881.7 samples/s | 91.9 steps/s
[Step=46750 Epoch=446.4] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.469 | L2-Norm(final)=8.058 | 2087.7 samples/s | 32.6 steps/s
[Step=46800 Epoch=446.9] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.442 | L2-Norm(final)=8.059 | 5384.0 samples/s | 84.1 steps/s
[Step=46850 Epoch=447.4] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.415 | L2-Norm(final)=8.060 | 2133.8 samples/s | 33.3 steps/s
[Step=46900 Epoch=447.9] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.388 | L2-Norm(final)=8.061 | 4902.2 samples/s | 76.6 steps/s
[Step=46950 Epoch=448.3] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.361 | L2-Norm(final)=8.062 | 2202.4 samples/s | 34.4 steps/s
[Step=47000 Epoch=448.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.334 | L2-Norm(final)=8.063 | 4637.0 samples/s | 72.5 steps/s
[Step=47050 Epoch=449.3] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.306 | L2-Norm(final)=8.064 | 2262.0 samples/s | 35.3 steps/s
[Step=47100 Epoch=449.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.279 | L2-Norm(final)=8.064 | 4365.0 samples/s | 68.2 steps/s
[Step=47150 Epoch=450.3] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.251 | L2-Norm(final)=8.065 | 2408.7 samples/s | 37.6 steps/s
[Step=47200 Epoch=450.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.224 | L2-Norm(final)=8.066 | 4113.7 samples/s | 64.3 steps/s
[Step=47250 Epoch=451.2] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.196 | L2-Norm(final)=8.067 | 2395.5 samples/s | 37.4 steps/s
[Step=47300 Epoch=451.7] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.169 | L2-Norm(final)=8.068 | 4210.9 samples/s | 65.8 steps/s
[Step=47350 Epoch=452.2] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.069 | 2383.7 samples/s | 37.2 steps/s
[Step=47400 Epoch=452.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=8.070 | 4319.9 samples/s | 67.5 steps/s
[Step=47450 Epoch=453.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.085 | L2-Norm(final)=8.071 | 2350.0 samples/s | 36.7 steps/s
[Step=47500 Epoch=453.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=8.073 | 4328.6 samples/s | 67.6 steps/s
[Step=47550 Epoch=454.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.029 | L2-Norm(final)=8.074 | 6829.4 samples/s | 106.7 steps/s
[Step=47600 Epoch=454.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=8.075 | 1950.6 samples/s | 30.5 steps/s
[Step=47650 Epoch=455.0] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=8.076 | 6393.8 samples/s | 99.9 steps/s
[Step=47700 Epoch=455.5] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.944 | L2-Norm(final)=8.078 | 2001.9 samples/s | 31.3 steps/s
[Step=47750 Epoch=456.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.916 | L2-Norm(final)=8.079 | 5866.0 samples/s | 91.7 steps/s
[Step=47800 Epoch=456.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.887 | L2-Norm(final)=8.080 | 2070.2 samples/s | 32.3 steps/s
[Step=47850 Epoch=456.9] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.859 | L2-Norm(final)=8.082 | 5328.4 samples/s | 83.3 steps/s
[Step=47900 Epoch=457.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.830 | L2-Norm(final)=8.083 | 2116.8 samples/s | 33.1 steps/s
[Step=47950 Epoch=457.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.801 | L2-Norm(final)=8.085 | 4967.0 samples/s | 77.6 steps/s
[Step=48000 Epoch=458.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.772 | L2-Norm(final)=8.087 | 2200.8 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step48000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=433.5] | Loss=0.00002 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.601 | L2-Norm(final)=7.866 | 4851.5 samples/s | 75.8 steps/s
[Step=46050 Epoch=433.9] | Loss=0.00006 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.599 | L2-Norm(final)=7.875 | 4271.3 samples/s | 66.7 steps/s
[Step=46100 Epoch=434.4] | Loss=0.00005 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.604 | L2-Norm(final)=7.888 | 7422.0 samples/s | 116.0 steps/s
[Step=46150 Epoch=434.9] | Loss=0.00005 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.610 | L2-Norm(final)=7.899 | 2146.6 samples/s | 33.5 steps/s
[Step=46200 Epoch=435.3] | Loss=0.00004 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.614 | L2-Norm(final)=7.910 | 6313.9 samples/s | 98.7 steps/s
[Step=46250 Epoch=435.8] | Loss=0.00004 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.617 | L2-Norm(final)=7.918 | 2279.9 samples/s | 35.6 steps/s
[Step=46300 Epoch=436.3] | Loss=0.00004 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.619 | L2-Norm(final)=7.926 | 5684.2 samples/s | 88.8 steps/s
[Step=46350 Epoch=436.7] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.620 | L2-Norm(final)=7.934 | 2364.1 samples/s | 36.9 steps/s
[Step=46400 Epoch=437.2] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.621 | L2-Norm(final)=7.941 | 5057.5 samples/s | 79.0 steps/s
[Step=46450 Epoch=437.7] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.622 | L2-Norm(final)=7.949 | 2458.4 samples/s | 38.4 steps/s
[Step=46500 Epoch=438.2] | Loss=0.00003 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.623 | L2-Norm(final)=7.956 | 4749.7 samples/s | 74.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=438.2] | Loss=0.00002 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.630 | L2-Norm(final)=8.029 | 5421.3 samples/s | 84.7 steps/s
[Step=46550 Epoch=438.6] | Loss=0.00002 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.598 | L2-Norm(final)=8.034 | 3676.8 samples/s | 57.5 steps/s
[Step=46600 Epoch=439.1] | Loss=0.00438 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.615 | L2-Norm(final)=8.038 | 6189.0 samples/s | 96.7 steps/s
[Step=46650 Epoch=439.6] | Loss=0.00320 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.654 | L2-Norm(final)=8.032 | 2027.5 samples/s | 31.7 steps/s
[Step=46700 Epoch=440.0] | Loss=0.00246 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.674 | L2-Norm(final)=8.030 | 5456.9 samples/s | 85.3 steps/s
[Step=46750 Epoch=440.5] | Loss=0.00202 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.687 | L2-Norm(final)=8.030 | 1658.8 samples/s | 25.9 steps/s
[Step=46800 Epoch=441.0] | Loss=0.00169 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.695 | L2-Norm(final)=8.030 | 4927.2 samples/s | 77.0 steps/s
[Step=46850 Epoch=441.5] | Loss=0.00146 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.701 | L2-Norm(final)=8.030 | 2175.7 samples/s | 34.0 steps/s
[Step=46900 Epoch=441.9] | Loss=0.00128 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.705 | L2-Norm(final)=8.030 | 4464.4 samples/s | 69.8 steps/s
[Step=46950 Epoch=442.4] | Loss=0.00114 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=8.031 | 2317.5 samples/s | 36.2 steps/s
[Step=47000 Epoch=442.9] | Loss=0.00103 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=8.031 | 4242.5 samples/s | 66.3 steps/s
[Step=47050 Epoch=443.3] | Loss=0.00094 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=8.031 | 2402.7 samples/s | 37.5 steps/s
[Step=47100 Epoch=443.8] | Loss=0.00086 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.032 | 4300.3 samples/s | 67.2 steps/s
[Step=47150 Epoch=444.3] | Loss=0.00080 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.032 | 2340.2 samples/s | 36.6 steps/s
[Step=47200 Epoch=444.8] | Loss=0.00074 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.033 | 4238.1 samples/s | 66.2 steps/s
[Step=47250 Epoch=445.2] | Loss=0.00070 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.033 | 2632.9 samples/s | 41.1 steps/s
[Step=47300 Epoch=445.7] | Loss=0.00065 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.716 | L2-Norm(final)=8.034 | 3652.7 samples/s | 57.1 steps/s
[Step=47350 Epoch=446.2] | Loss=0.00062 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.716 | L2-Norm(final)=8.034 | 6365.4 samples/s | 99.5 steps/s
[Step=47400 Epoch=446.6] | Loss=0.00058 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.716 | L2-Norm(final)=8.034 | 2038.1 samples/s | 31.8 steps/s
[Step=47450 Epoch=447.1] | Loss=0.00055 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.035 | 5590.4 samples/s | 87.3 steps/s
[Step=47500 Epoch=447.6] | Loss=0.00053 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.035 | 2087.4 samples/s | 32.6 steps/s
[Step=47550 Epoch=448.1] | Loss=0.00050 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.036 | 5029.5 samples/s | 78.6 steps/s
[Step=47600 Epoch=448.5] | Loss=0.00048 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.036 | 2195.5 samples/s | 34.3 steps/s
[Step=47650 Epoch=449.0] | Loss=0.00046 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=8.036 | 4540.3 samples/s | 70.9 steps/s
[Step=47700 Epoch=449.5] | Loss=0.00044 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.713 | L2-Norm(final)=8.037 | 2282.0 samples/s | 35.7 steps/s
[Step=47750 Epoch=449.9] | Loss=0.00042 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=8.037 | 4244.7 samples/s | 66.3 steps/s
[Step=47800 Epoch=450.4] | Loss=0.00041 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=8.037 | 2420.0 samples/s | 37.8 steps/s
[Step=47850 Epoch=450.9] | Loss=0.00039 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=8.038 | 4149.1 samples/s | 64.8 steps/s
[Step=47900 Epoch=451.4] | Loss=0.00038 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.710 | L2-Norm(final)=8.038 | 2395.2 samples/s | 37.4 steps/s
[Step=47950 Epoch=451.8] | Loss=0.00037 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.709 | L2-Norm(final)=8.038 | 4281.2 samples/s | 66.9 steps/s
[Step=48000 Epoch=452.3] | Loss=0.00035 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=8.039 | 2551.8 samples/s | 39.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step48000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=438.4] | Loss=0.00025 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.540 | L2-Norm(final)=8.520 | 5287.2 samples/s | 82.6 steps/s
[Step=46050 Epoch=438.9] | Loss=0.00059 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.564 | L2-Norm(final)=8.548 | 3953.2 samples/s | 61.8 steps/s
[Step=46100 Epoch=439.4] | Loss=0.00039 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.590 | L2-Norm(final)=8.568 | 7400.8 samples/s | 115.6 steps/s
[Step=46150 Epoch=439.9] | Loss=0.00031 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.603 | L2-Norm(final)=8.580 | 2081.9 samples/s | 32.5 steps/s
[Step=46200 Epoch=440.3] | Loss=0.00024 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.610 | L2-Norm(final)=8.589 | 6697.3 samples/s | 104.6 steps/s
[Step=46250 Epoch=440.8] | Loss=0.00020 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.616 | L2-Norm(final)=8.595 | 2160.8 samples/s | 33.8 steps/s
[Step=46300 Epoch=441.3] | Loss=0.00017 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.619 | L2-Norm(final)=8.601 | 5894.4 samples/s | 92.1 steps/s
[Step=46350 Epoch=441.8] | Loss=0.00015 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.622 | L2-Norm(final)=8.606 | 2108.6 samples/s | 32.9 steps/s
[Step=46400 Epoch=442.2] | Loss=0.00014 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.624 | L2-Norm(final)=8.610 | 5647.7 samples/s | 88.2 steps/s
[Step=46450 Epoch=442.7] | Loss=0.00013 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.625 | L2-Norm(final)=8.614 | 2296.3 samples/s | 35.9 steps/s
[Step=46500 Epoch=443.2] | Loss=0.00012 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.627 | L2-Norm(final)=8.618 | 5174.5 samples/s | 80.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=443.2] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.639 | L2-Norm(final)=8.657 | 5348.0 samples/s | 83.6 steps/s
[Step=46550 Epoch=443.7] | Loss=0.00002 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.625 | L2-Norm(final)=8.659 | 3755.2 samples/s | 58.7 steps/s
[Step=46600 Epoch=444.1] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.603 | L2-Norm(final)=8.661 | 6142.5 samples/s | 96.0 steps/s
[Step=46650 Epoch=444.6] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.578 | L2-Norm(final)=8.662 | 1984.0 samples/s | 31.0 steps/s
[Step=46700 Epoch=445.1] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.552 | L2-Norm(final)=8.663 | 5768.4 samples/s | 90.1 steps/s
[Step=46750 Epoch=445.6] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.524 | L2-Norm(final)=8.663 | 2069.2 samples/s | 32.3 steps/s
[Step=46800 Epoch=446.0] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.497 | L2-Norm(final)=8.663 | 5116.1 samples/s | 79.9 steps/s
[Step=46850 Epoch=446.5] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.469 | L2-Norm(final)=8.664 | 2093.8 samples/s | 32.7 steps/s
[Step=46900 Epoch=447.0] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.441 | L2-Norm(final)=8.664 | 4949.4 samples/s | 77.3 steps/s
[Step=46950 Epoch=447.5] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.412 | L2-Norm(final)=8.664 | 2198.4 samples/s | 34.3 steps/s
[Step=47000 Epoch=448.0] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.384 | L2-Norm(final)=8.665 | 4523.5 samples/s | 70.7 steps/s
[Step=47050 Epoch=448.4] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.355 | L2-Norm(final)=8.665 | 2270.2 samples/s | 35.5 steps/s
[Step=47100 Epoch=448.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.327 | L2-Norm(final)=8.665 | 4206.9 samples/s | 65.7 steps/s
[Step=47150 Epoch=449.4] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.298 | L2-Norm(final)=8.665 | 2318.7 samples/s | 36.2 steps/s
[Step=47200 Epoch=449.9] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.269 | L2-Norm(final)=8.666 | 4252.7 samples/s | 66.4 steps/s
[Step=47250 Epoch=450.3] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.240 | L2-Norm(final)=8.666 | 2359.4 samples/s | 36.9 steps/s
[Step=47300 Epoch=450.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.211 | L2-Norm(final)=8.666 | 4145.9 samples/s | 64.8 steps/s
[Step=47350 Epoch=451.3] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.182 | L2-Norm(final)=8.667 | 2328.4 samples/s | 36.4 steps/s
[Step=47400 Epoch=451.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=8.667 | 4215.1 samples/s | 65.9 steps/s
[Step=47450 Epoch=452.2] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.123 | L2-Norm(final)=8.667 | 2333.9 samples/s | 36.5 steps/s
[Step=47500 Epoch=452.7] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.093 | L2-Norm(final)=8.668 | 4207.7 samples/s | 65.7 steps/s
[Step=47550 Epoch=453.2] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=8.668 | 6914.9 samples/s | 108.0 steps/s
[Step=47600 Epoch=453.7] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=8.668 | 1919.1 samples/s | 30.0 steps/s
[Step=47650 Epoch=454.1] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=8.669 | 6151.5 samples/s | 96.1 steps/s
[Step=47700 Epoch=454.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.975 | L2-Norm(final)=8.669 | 2004.9 samples/s | 31.3 steps/s
[Step=47750 Epoch=455.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=8.670 | 5757.4 samples/s | 90.0 steps/s
[Step=47800 Epoch=455.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.915 | L2-Norm(final)=8.670 | 2030.6 samples/s | 31.7 steps/s
[Step=47850 Epoch=456.1] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.884 | L2-Norm(final)=8.670 | 5341.3 samples/s | 83.5 steps/s
[Step=47900 Epoch=456.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.854 | L2-Norm(final)=8.671 | 2094.0 samples/s | 32.7 steps/s
[Step=47950 Epoch=457.0] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=8.671 | 4924.2 samples/s | 76.9 steps/s
[Step=48000 Epoch=457.5] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.794 | L2-Norm(final)=8.672 | 2181.7 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11394 | acc=0.9588 | tpr=0.9750 | fpr=0.0763 | 4662.6 samples/s | 18.2 steps/s
Avg test loss: 0.11878, Avg test acc: 0.95769, Avg tpr: 0.97400, Avg fpr: 0.07820, total FA: 610

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11322 | acc=0.9587 | tpr=0.9740 | fpr=0.0743 | 4727.5 samples/s | 18.5 steps/s
Avg test loss: 0.11479, Avg test acc: 0.95805, Avg tpr: 0.97284, Avg fpr: 0.07448, total FA: 581

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10815 | acc=0.9599 | tpr=0.9747 | fpr=0.0721 | 4799.4 samples/s | 18.7 steps/s
Avg test loss: 0.11102, Avg test acc: 0.95873, Avg tpr: 0.97319, Avg fpr: 0.07307, total FA: 570

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10062 | acc=0.9555 | tpr=0.9618 | fpr=0.0580 | 4925.4 samples/s | 19.2 steps/s
Avg test loss: 0.10518, Avg test acc: 0.95472, Avg tpr: 0.96206, Avg fpr: 0.06140, total FA: 479

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11441 | acc=0.9587 | tpr=0.9715 | fpr=0.0689 | 4822.4 samples/s | 18.8 steps/s
Avg test loss: 0.12335, Avg test acc: 0.95849, Avg tpr: 0.97127, Avg fpr: 0.06961, total FA: 543

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.46700 | acc=0.2894 | tpr=0.0139 | fpr=0.1125 | 4773.2 samples/s | 18.6 steps/s
Avg test loss: 5.46986, Avg test acc: 0.28881, Avg tpr: 0.01585, Avg fpr: 0.11088, total FA: 865

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.78977 | acc=0.3004 | tpr=0.0055 | fpr=0.0592 | 4798.8 samples/s | 18.7 steps/s
Avg test loss: 4.80543, Avg test acc: 0.29790, Avg tpr: 0.00571, Avg fpr: 0.05948, total FA: 464

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.02282 | acc=0.2878 | tpr=0.0120 | fpr=0.1132 | 4857.2 samples/s | 19.0 steps/s
Avg test loss: 5.02613, Avg test acc: 0.28516, Avg tpr: 0.01160, Avg fpr: 0.11319, total FA: 883

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.19225 | acc=0.2963 | tpr=0.0173 | fpr=0.0979 | 4772.4 samples/s | 18.6 steps/s
Avg test loss: 5.18611, Avg test acc: 0.29502, Avg tpr: 0.01766, Avg fpr: 0.09499, total FA: 741

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.83583 | acc=0.2977 | tpr=0.0108 | fpr=0.0795 | 4887.1 samples/s | 19.1 steps/s
Avg test loss: 4.84067, Avg test acc: 0.29558, Avg tpr: 0.01183, Avg fpr: 0.08037, total FA: 627

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.10993 | acc=0.0852 | tpr=0.5531 | fpr=0.9232 | 4652.0 samples/s | 18.2 steps/s
[Step= 100] | Loss=6.08878 | acc=0.0859 | tpr=0.5352 | fpr=0.9224 | 7436.4 samples/s | 29.0 steps/s
[Step= 150] | Loss=6.10740 | acc=0.0873 | tpr=0.5346 | fpr=0.9210 | 7725.7 samples/s | 30.2 steps/s
[Step= 200] | Loss=6.10650 | acc=0.0870 | tpr=0.5213 | fpr=0.9209 | 7669.1 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.11331 | acc=0.0877 | tpr=0.5249 | fpr=0.9203 | 7842.4 samples/s | 30.6 steps/s
[Step= 300] | Loss=6.10806 | acc=0.0878 | tpr=0.5360 | fpr=0.9204 | 7900.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.10558 | acc=0.0879 | tpr=0.5360 | fpr=0.9202 | 7808.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=6.10063 | acc=0.0883 | tpr=0.5356 | fpr=0.9199 | 7859.2 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.10597 | acc=0.0882 | tpr=0.5316 | fpr=0.9199 | 7775.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.11057 | acc=0.0881 | tpr=0.5286 | fpr=0.9199 | 7836.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=6.11313 | acc=0.0879 | tpr=0.5288 | fpr=0.9201 | 13638.5 samples/s | 53.3 steps/s
Avg test loss: 6.11494, Avg test acc: 0.08783, Avg tpr: 0.52892, Avg fpr: 0.92019, total FA: 127766

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.28978 | acc=0.0971 | tpr=0.5442 | fpr=0.9109 | 4825.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.28077 | acc=0.0968 | tpr=0.5586 | fpr=0.9118 | 6843.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=5.28456 | acc=0.0974 | tpr=0.5576 | fpr=0.9111 | 7919.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.28215 | acc=0.0975 | tpr=0.5486 | fpr=0.9107 | 8067.1 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.29218 | acc=0.0974 | tpr=0.5467 | fpr=0.9108 | 7828.0 samples/s | 30.6 steps/s
[Step= 300] | Loss=5.28468 | acc=0.0972 | tpr=0.5476 | fpr=0.9110 | 7665.2 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.28014 | acc=0.0976 | tpr=0.5492 | fpr=0.9106 | 8036.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.27568 | acc=0.0979 | tpr=0.5460 | fpr=0.9102 | 7348.8 samples/s | 28.7 steps/s
[Step= 450] | Loss=5.27922 | acc=0.0976 | tpr=0.5463 | fpr=0.9106 | 7904.5 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.28279 | acc=0.0971 | tpr=0.5454 | fpr=0.9110 | 7845.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.28525 | acc=0.0969 | tpr=0.5432 | fpr=0.9112 | 13193.0 samples/s | 51.5 steps/s
Avg test loss: 5.28738, Avg test acc: 0.09685, Avg tpr: 0.54239, Avg fpr: 0.91125, total FA: 126525

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.16121 | acc=0.0813 | tpr=0.4690 | fpr=0.9256 | 4981.2 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.13159 | acc=0.0819 | tpr=0.4691 | fpr=0.9253 | 6628.4 samples/s | 25.9 steps/s
[Step= 150] | Loss=6.14588 | acc=0.0825 | tpr=0.4582 | fpr=0.9244 | 7794.8 samples/s | 30.4 steps/s
[Step= 200] | Loss=6.14380 | acc=0.0823 | tpr=0.4667 | fpr=0.9247 | 8102.9 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.14376 | acc=0.0825 | tpr=0.4690 | fpr=0.9245 | 7295.3 samples/s | 28.5 steps/s
[Step= 300] | Loss=6.14187 | acc=0.0823 | tpr=0.4742 | fpr=0.9249 | 8221.5 samples/s | 32.1 steps/s
[Step= 350] | Loss=6.13640 | acc=0.0829 | tpr=0.4740 | fpr=0.9242 | 7538.1 samples/s | 29.4 steps/s
[Step= 400] | Loss=6.12970 | acc=0.0832 | tpr=0.4726 | fpr=0.9239 | 8229.4 samples/s | 32.1 steps/s
[Step= 450] | Loss=6.13098 | acc=0.0831 | tpr=0.4703 | fpr=0.9239 | 7788.9 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.13357 | acc=0.0831 | tpr=0.4705 | fpr=0.9239 | 8032.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=6.13692 | acc=0.0829 | tpr=0.4704 | fpr=0.9242 | 13833.3 samples/s | 54.0 steps/s
Avg test loss: 6.13824, Avg test acc: 0.08276, Avg tpr: 0.47108, Avg fpr: 0.92430, total FA: 128337

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=4.71470 | acc=0.1220 | tpr=0.4867 | fpr=0.8846 | 4859.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=4.68427 | acc=0.1239 | tpr=0.4797 | fpr=0.8827 | 6946.1 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.68776 | acc=0.1236 | tpr=0.4841 | fpr=0.8830 | 7996.5 samples/s | 31.2 steps/s
[Step= 200] | Loss=4.67745 | acc=0.1239 | tpr=0.4809 | fpr=0.8826 | 7794.9 samples/s | 30.4 steps/s
[Step= 250] | Loss=4.68003 | acc=0.1240 | tpr=0.4725 | fpr=0.8824 | 7692.2 samples/s | 30.0 steps/s
[Step= 300] | Loss=4.67608 | acc=0.1241 | tpr=0.4749 | fpr=0.8823 | 7952.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.67100 | acc=0.1246 | tpr=0.4753 | fpr=0.8818 | 8055.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=4.66467 | acc=0.1248 | tpr=0.4721 | fpr=0.8815 | 7783.1 samples/s | 30.4 steps/s
[Step= 450] | Loss=4.66956 | acc=0.1247 | tpr=0.4708 | fpr=0.8816 | 7842.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.67185 | acc=0.1244 | tpr=0.4670 | fpr=0.8818 | 7712.1 samples/s | 30.1 steps/s
[Step= 550] | Loss=4.67512 | acc=0.1241 | tpr=0.4656 | fpr=0.8821 | 14562.2 samples/s | 56.9 steps/s
Avg test loss: 4.67580, Avg test acc: 0.12402, Avg tpr: 0.46593, Avg fpr: 0.88219, total FA: 122491

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.46920 | acc=0.0982 | tpr=0.5841 | fpr=0.9105 | 4721.1 samples/s | 18.4 steps/s
[Step= 100] | Loss=6.43862 | acc=0.1004 | tpr=0.6055 | fpr=0.9090 | 7211.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.43914 | acc=0.1007 | tpr=0.5965 | fpr=0.9084 | 7860.8 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.43574 | acc=0.1005 | tpr=0.5869 | fpr=0.9083 | 8020.3 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.44530 | acc=0.1006 | tpr=0.5860 | fpr=0.9083 | 7603.1 samples/s | 29.7 steps/s
[Step= 300] | Loss=6.44354 | acc=0.1003 | tpr=0.5891 | fpr=0.9086 | 8055.6 samples/s | 31.5 steps/s
[Step= 350] | Loss=6.43444 | acc=0.1003 | tpr=0.5911 | fpr=0.9086 | 7766.4 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.43069 | acc=0.1010 | tpr=0.5930 | fpr=0.9079 | 7938.7 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.43305 | acc=0.1012 | tpr=0.5954 | fpr=0.9077 | 7904.4 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.43569 | acc=0.1010 | tpr=0.5921 | fpr=0.9079 | 7908.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.44078 | acc=0.1008 | tpr=0.5933 | fpr=0.9082 | 13650.5 samples/s | 53.3 steps/s
Avg test loss: 6.44237, Avg test acc: 0.10068, Avg tpr: 0.59311, Avg fpr: 0.90827, total FA: 126111

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09355 | acc=0.9817 | tpr=0.9513 | fpr=0.0177 | 4781.3 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09682 | acc=0.9816 | tpr=0.9531 | fpr=0.0179 | 7160.3 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.10006 | acc=0.9809 | tpr=0.9496 | fpr=0.0186 | 7869.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.10178 | acc=0.9808 | tpr=0.9530 | fpr=0.0187 | 7855.0 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.10015 | acc=0.9809 | tpr=0.9476 | fpr=0.0185 | 7738.7 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.10278 | acc=0.9805 | tpr=0.9455 | fpr=0.0189 | 7558.2 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.10380 | acc=0.9802 | tpr=0.9480 | fpr=0.0192 | 8207.6 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.10487 | acc=0.9800 | tpr=0.9431 | fpr=0.0193 | 7998.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.10692 | acc=0.9797 | tpr=0.9426 | fpr=0.0196 | 7558.5 samples/s | 29.5 steps/s
[Step= 500] | Loss=0.10611 | acc=0.9799 | tpr=0.9432 | fpr=0.0195 | 7850.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10566 | acc=0.9800 | tpr=0.9415 | fpr=0.0193 | 14532.2 samples/s | 56.8 steps/s
Avg test loss: 0.10557, Avg test acc: 0.98001, Avg tpr: 0.94176, Avg fpr: 0.01929, total FA: 2679

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09097 | acc=0.9829 | tpr=0.8982 | fpr=0.0156 | 4784.6 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09294 | acc=0.9827 | tpr=0.9041 | fpr=0.0159 | 7040.3 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.09578 | acc=0.9820 | tpr=0.9121 | fpr=0.0167 | 8086.6 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.09742 | acc=0.9820 | tpr=0.9158 | fpr=0.0168 | 7770.3 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.09605 | acc=0.9821 | tpr=0.9118 | fpr=0.0166 | 7603.6 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.09847 | acc=0.9818 | tpr=0.9105 | fpr=0.0169 | 7977.9 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09942 | acc=0.9816 | tpr=0.9142 | fpr=0.0171 | 7940.5 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.10058 | acc=0.9813 | tpr=0.9092 | fpr=0.0174 | 7788.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.10278 | acc=0.9809 | tpr=0.9056 | fpr=0.0178 | 8004.7 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.10189 | acc=0.9810 | tpr=0.9075 | fpr=0.0177 | 7444.6 samples/s | 29.1 steps/s
[Step= 550] | Loss=0.10167 | acc=0.9812 | tpr=0.9061 | fpr=0.0174 | 15300.3 samples/s | 59.8 steps/s
Avg test loss: 0.10154, Avg test acc: 0.98121, Avg tpr: 0.90650, Avg fpr: 0.01744, total FA: 2421

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08242 | acc=0.9820 | tpr=0.9602 | fpr=0.0176 | 4745.5 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.08379 | acc=0.9821 | tpr=0.9659 | fpr=0.0176 | 6987.8 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.08750 | acc=0.9812 | tpr=0.9625 | fpr=0.0184 | 8179.9 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.08896 | acc=0.9813 | tpr=0.9639 | fpr=0.0183 | 7994.8 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.08760 | acc=0.9816 | tpr=0.9633 | fpr=0.0181 | 7659.4 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.08983 | acc=0.9812 | tpr=0.9578 | fpr=0.0184 | 7715.9 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.09058 | acc=0.9809 | tpr=0.9593 | fpr=0.0187 | 8119.5 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.09162 | acc=0.9806 | tpr=0.9562 | fpr=0.0190 | 7720.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.09334 | acc=0.9803 | tpr=0.9547 | fpr=0.0192 | 8047.3 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.09270 | acc=0.9803 | tpr=0.9559 | fpr=0.0192 | 8166.8 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.09229 | acc=0.9805 | tpr=0.9554 | fpr=0.0191 | 13092.2 samples/s | 51.1 steps/s
Avg test loss: 0.09219, Avg test acc: 0.98049, Avg tpr: 0.95563, Avg fpr: 0.01906, total FA: 2646

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09486 | acc=0.9805 | tpr=0.9204 | fpr=0.0184 | 4631.6 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.09879 | acc=0.9799 | tpr=0.9232 | fpr=0.0190 | 7424.3 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.10353 | acc=0.9790 | tpr=0.9308 | fpr=0.0202 | 7738.7 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10490 | acc=0.9792 | tpr=0.9377 | fpr=0.0200 | 7969.8 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.10331 | acc=0.9796 | tpr=0.9380 | fpr=0.0197 | 7519.9 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.10519 | acc=0.9795 | tpr=0.9338 | fpr=0.0197 | 7765.9 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.10565 | acc=0.9793 | tpr=0.9355 | fpr=0.0200 | 8267.2 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.10593 | acc=0.9791 | tpr=0.9322 | fpr=0.0200 | 7730.6 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.10795 | acc=0.9789 | tpr=0.9314 | fpr=0.0202 | 7866.9 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10713 | acc=0.9791 | tpr=0.9339 | fpr=0.0200 | 7877.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.10687 | acc=0.9792 | tpr=0.9316 | fpr=0.0199 | 13943.0 samples/s | 54.5 steps/s
Avg test loss: 0.10670, Avg test acc: 0.97925, Avg tpr: 0.93146, Avg fpr: 0.01989, total FA: 2761

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08783 | acc=0.9823 | tpr=0.9115 | fpr=0.0164 | 4965.7 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.09169 | acc=0.9817 | tpr=0.9211 | fpr=0.0172 | 6704.4 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.09486 | acc=0.9809 | tpr=0.9251 | fpr=0.0181 | 8034.6 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.09657 | acc=0.9809 | tpr=0.9322 | fpr=0.0183 | 7615.2 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.09554 | acc=0.9812 | tpr=0.9293 | fpr=0.0179 | 7907.9 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.09775 | acc=0.9809 | tpr=0.9273 | fpr=0.0181 | 7820.4 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.09808 | acc=0.9807 | tpr=0.9299 | fpr=0.0183 | 7981.4 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.09953 | acc=0.9805 | tpr=0.9272 | fpr=0.0186 | 7810.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.10168 | acc=0.9802 | tpr=0.9245 | fpr=0.0188 | 7616.6 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.10099 | acc=0.9803 | tpr=0.9256 | fpr=0.0187 | 8200.4 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.10071 | acc=0.9805 | tpr=0.9260 | fpr=0.0185 | 13608.6 samples/s | 53.2 steps/s
Avg test loss: 0.10054, Avg test acc: 0.98053, Avg tpr: 0.92552, Avg fpr: 0.01847, total FA: 2564

server round 24/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=234.1] | Loss=0.00526 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.841 | L2-Norm(final)=13.691 | 5159.2 samples/s | 80.6 steps/s
[Step=48050 Epoch=234.3] | Loss=0.00281 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=13.698 | 4674.0 samples/s | 73.0 steps/s
[Step=48100 Epoch=234.5] | Loss=0.00326 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=13.710 | 4994.0 samples/s | 78.0 steps/s
[Step=48150 Epoch=234.8] | Loss=0.00360 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.849 | L2-Norm(final)=13.722 | 4899.7 samples/s | 76.6 steps/s
[Step=48200 Epoch=235.0] | Loss=0.00350 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.852 | L2-Norm(final)=13.733 | 7833.2 samples/s | 122.4 steps/s
[Step=48250 Epoch=235.3] | Loss=0.00361 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.854 | L2-Norm(final)=13.746 | 2219.0 samples/s | 34.7 steps/s
[Step=48300 Epoch=235.5] | Loss=0.00336 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.856 | L2-Norm(final)=13.758 | 4982.1 samples/s | 77.8 steps/s
[Step=48350 Epoch=235.8] | Loss=0.00335 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.858 | L2-Norm(final)=13.770 | 5033.6 samples/s | 78.7 steps/s
[Step=48400 Epoch=236.0] | Loss=0.00327 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.859 | L2-Norm(final)=13.782 | 6959.7 samples/s | 108.7 steps/s
[Step=48450 Epoch=236.3] | Loss=0.00311 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.860 | L2-Norm(final)=13.793 | 2271.7 samples/s | 35.5 steps/s
[Step=48500 Epoch=236.5] | Loss=0.00302 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.860 | L2-Norm(final)=13.805 | 5005.6 samples/s | 78.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=236.5] | Loss=0.00108 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.863 | L2-Norm(final)=13.920 | 5429.8 samples/s | 84.8 steps/s
[Step=48550 Epoch=236.7] | Loss=0.00280 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.865 | L2-Norm(final)=13.931 | 4152.0 samples/s | 64.9 steps/s
[Step=48600 Epoch=237.0] | Loss=0.00378 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.869 | L2-Norm(final)=13.940 | 4536.2 samples/s | 70.9 steps/s
[Step=48650 Epoch=237.2] | Loss=0.00454 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.875 | L2-Norm(final)=13.949 | 4457.0 samples/s | 69.6 steps/s
[Step=48700 Epoch=237.5] | Loss=0.00644 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=13.957 | 6542.4 samples/s | 102.2 steps/s
[Step=48750 Epoch=237.7] | Loss=0.00944 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.899 | L2-Norm(final)=13.964 | 2094.5 samples/s | 32.7 steps/s
[Step=48800 Epoch=238.0] | Loss=0.00988 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.916 | L2-Norm(final)=13.970 | 4444.5 samples/s | 69.4 steps/s
[Step=48850 Epoch=238.2] | Loss=0.00984 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.931 | L2-Norm(final)=13.977 | 4449.7 samples/s | 69.5 steps/s
[Step=48900 Epoch=238.4] | Loss=0.00975 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.945 | L2-Norm(final)=13.983 | 5888.8 samples/s | 92.0 steps/s
[Step=48950 Epoch=238.7] | Loss=0.00909 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.956 | L2-Norm(final)=13.990 | 2155.6 samples/s | 33.7 steps/s
[Step=49000 Epoch=238.9] | Loss=0.00862 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.964 | L2-Norm(final)=13.996 | 4472.4 samples/s | 69.9 steps/s
[Step=49050 Epoch=239.2] | Loss=0.00817 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.972 | L2-Norm(final)=14.002 | 4535.8 samples/s | 70.9 steps/s
[Step=49100 Epoch=239.4] | Loss=0.00786 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.978 | L2-Norm(final)=14.008 | 5232.3 samples/s | 81.8 steps/s
[Step=49150 Epoch=239.7] | Loss=0.00752 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.982 | L2-Norm(final)=14.013 | 2239.0 samples/s | 35.0 steps/s
[Step=49200 Epoch=239.9] | Loss=0.00717 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.986 | L2-Norm(final)=14.018 | 4406.2 samples/s | 68.8 steps/s
[Step=49250 Epoch=240.2] | Loss=0.00691 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.989 | L2-Norm(final)=14.023 | 4464.9 samples/s | 69.8 steps/s
[Step=49300 Epoch=240.4] | Loss=0.00671 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.991 | L2-Norm(final)=14.028 | 4977.0 samples/s | 77.8 steps/s
[Step=49350 Epoch=240.6] | Loss=0.00655 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.993 | L2-Norm(final)=14.032 | 2367.8 samples/s | 37.0 steps/s
[Step=49400 Epoch=240.9] | Loss=0.00633 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.995 | L2-Norm(final)=14.036 | 4492.7 samples/s | 70.2 steps/s
[Step=49450 Epoch=241.1] | Loss=0.00616 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.996 | L2-Norm(final)=14.040 | 4432.5 samples/s | 69.3 steps/s
[Step=49500 Epoch=241.4] | Loss=0.00605 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.996 | L2-Norm(final)=14.043 | 4514.4 samples/s | 70.5 steps/s
[Step=49550 Epoch=241.6] | Loss=0.00586 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.997 | L2-Norm(final)=14.047 | 2411.9 samples/s | 37.7 steps/s
[Step=49600 Epoch=241.9] | Loss=0.00572 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.997 | L2-Norm(final)=14.051 | 4485.5 samples/s | 70.1 steps/s
[Step=49650 Epoch=242.1] | Loss=0.00557 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.997 | L2-Norm(final)=14.054 | 4539.7 samples/s | 70.9 steps/s
[Step=49700 Epoch=242.3] | Loss=0.00545 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.996 | L2-Norm(final)=14.058 | 4404.9 samples/s | 68.8 steps/s
[Step=49750 Epoch=242.6] | Loss=0.00535 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.996 | L2-Norm(final)=14.061 | 2477.6 samples/s | 38.7 steps/s
[Step=49800 Epoch=242.8] | Loss=0.00530 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.995 | L2-Norm(final)=14.064 | 4447.7 samples/s | 69.5 steps/s
[Step=49850 Epoch=243.1] | Loss=0.00518 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.994 | L2-Norm(final)=14.067 | 4495.4 samples/s | 70.2 steps/s
[Step=49900 Epoch=243.3] | Loss=0.00512 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.992 | L2-Norm(final)=14.070 | 4351.4 samples/s | 68.0 steps/s
[Step=49950 Epoch=243.6] | Loss=0.00502 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.991 | L2-Norm(final)=14.073 | 2475.6 samples/s | 38.7 steps/s
[Step=50000 Epoch=243.8] | Loss=0.00495 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.989 | L2-Norm(final)=14.076 | 4451.1 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step50000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=234.2] | Loss=0.00303 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.685 | L2-Norm(final)=13.978 | 5353.7 samples/s | 83.7 steps/s
[Step=48050 Epoch=234.5] | Loss=0.00330 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.688 | L2-Norm(final)=13.988 | 4420.8 samples/s | 69.1 steps/s
[Step=48100 Epoch=234.7] | Loss=0.00317 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.691 | L2-Norm(final)=14.000 | 4996.1 samples/s | 78.1 steps/s
[Step=48150 Epoch=234.9] | Loss=0.00300 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.694 | L2-Norm(final)=14.013 | 5203.5 samples/s | 81.3 steps/s
[Step=48200 Epoch=235.2] | Loss=0.00278 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.697 | L2-Norm(final)=14.026 | 7312.2 samples/s | 114.3 steps/s
[Step=48250 Epoch=235.4] | Loss=0.00279 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=14.039 | 2193.8 samples/s | 34.3 steps/s
[Step=48300 Epoch=235.7] | Loss=0.00263 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.699 | L2-Norm(final)=14.051 | 4960.9 samples/s | 77.5 steps/s
[Step=48350 Epoch=235.9] | Loss=0.00260 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.699 | L2-Norm(final)=14.064 | 5081.4 samples/s | 79.4 steps/s
[Step=48400 Epoch=236.2] | Loss=0.00264 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.699 | L2-Norm(final)=14.075 | 7060.0 samples/s | 110.3 steps/s
[Step=48450 Epoch=236.4] | Loss=0.00269 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.699 | L2-Norm(final)=14.087 | 2302.6 samples/s | 36.0 steps/s
[Step=48500 Epoch=236.7] | Loss=0.00259 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.700 | L2-Norm(final)=14.099 | 4947.0 samples/s | 77.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=236.7] | Loss=0.00393 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=14.216 | 5414.4 samples/s | 84.6 steps/s
[Step=48550 Epoch=236.9] | Loss=0.00425 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=14.225 | 4067.7 samples/s | 63.6 steps/s
[Step=48600 Epoch=237.1] | Loss=0.00380 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.703 | L2-Norm(final)=14.234 | 4506.8 samples/s | 70.4 steps/s
[Step=48650 Epoch=237.4] | Loss=0.00516 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.711 | L2-Norm(final)=14.245 | 4534.2 samples/s | 70.8 steps/s
[Step=48700 Epoch=237.6] | Loss=0.00589 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.725 | L2-Norm(final)=14.254 | 6343.9 samples/s | 99.1 steps/s
[Step=48750 Epoch=237.9] | Loss=0.00589 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.738 | L2-Norm(final)=14.264 | 2077.7 samples/s | 32.5 steps/s
[Step=48800 Epoch=238.1] | Loss=0.00592 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=14.273 | 4469.9 samples/s | 69.8 steps/s
[Step=48850 Epoch=238.4] | Loss=0.00587 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.758 | L2-Norm(final)=14.281 | 4466.1 samples/s | 69.8 steps/s
[Step=48900 Epoch=238.6] | Loss=0.00586 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.766 | L2-Norm(final)=14.289 | 5867.0 samples/s | 91.7 steps/s
[Step=48950 Epoch=238.9] | Loss=0.00576 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=14.297 | 2139.9 samples/s | 33.4 steps/s
[Step=49000 Epoch=239.1] | Loss=0.00570 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.779 | L2-Norm(final)=14.304 | 4536.0 samples/s | 70.9 steps/s
[Step=49050 Epoch=239.3] | Loss=0.00542 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.784 | L2-Norm(final)=14.311 | 4431.9 samples/s | 69.2 steps/s
[Step=49100 Epoch=239.6] | Loss=0.00547 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.788 | L2-Norm(final)=14.317 | 5581.7 samples/s | 87.2 steps/s
[Step=49150 Epoch=239.8] | Loss=0.00540 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.792 | L2-Norm(final)=14.323 | 2207.8 samples/s | 34.5 steps/s
[Step=49200 Epoch=240.1] | Loss=0.00520 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=14.329 | 4436.6 samples/s | 69.3 steps/s
[Step=49250 Epoch=240.3] | Loss=0.00507 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.798 | L2-Norm(final)=14.335 | 4404.3 samples/s | 68.8 steps/s
[Step=49300 Epoch=240.6] | Loss=0.00500 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.800 | L2-Norm(final)=14.340 | 5201.9 samples/s | 81.3 steps/s
[Step=49350 Epoch=240.8] | Loss=0.00499 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=14.345 | 2273.0 samples/s | 35.5 steps/s
[Step=49400 Epoch=241.0] | Loss=0.00490 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.805 | L2-Norm(final)=14.350 | 4447.3 samples/s | 69.5 steps/s
[Step=49450 Epoch=241.3] | Loss=0.00484 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.807 | L2-Norm(final)=14.355 | 4506.1 samples/s | 70.4 steps/s
[Step=49500 Epoch=241.5] | Loss=0.00479 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.809 | L2-Norm(final)=14.360 | 4855.5 samples/s | 75.9 steps/s
[Step=49550 Epoch=241.8] | Loss=0.00467 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.810 | L2-Norm(final)=14.365 | 2357.5 samples/s | 36.8 steps/s
[Step=49600 Epoch=242.0] | Loss=0.00454 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.811 | L2-Norm(final)=14.369 | 4380.9 samples/s | 68.5 steps/s
[Step=49650 Epoch=242.3] | Loss=0.00446 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.812 | L2-Norm(final)=14.374 | 4404.8 samples/s | 68.8 steps/s
[Step=49700 Epoch=242.5] | Loss=0.00440 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=14.378 | 4577.7 samples/s | 71.5 steps/s
[Step=49750 Epoch=242.8] | Loss=0.00430 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=14.382 | 2394.5 samples/s | 37.4 steps/s
[Step=49800 Epoch=243.0] | Loss=0.00422 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.813 | L2-Norm(final)=14.386 | 4482.5 samples/s | 70.0 steps/s
[Step=49850 Epoch=243.2] | Loss=0.00415 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=14.390 | 4490.6 samples/s | 70.2 steps/s
[Step=49900 Epoch=243.5] | Loss=0.00407 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.812 | L2-Norm(final)=14.394 | 4446.8 samples/s | 69.5 steps/s
[Step=49950 Epoch=243.7] | Loss=0.00399 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.811 | L2-Norm(final)=14.398 | 2391.3 samples/s | 37.4 steps/s
[Step=50000 Epoch=244.0] | Loss=0.00390 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.810 | L2-Norm(final)=14.402 | 4388.2 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step50000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=233.9] | Loss=0.00713 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.312 | L2-Norm(final)=14.358 | 5570.8 samples/s | 87.0 steps/s
[Step=48050 Epoch=234.1] | Loss=0.00453 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.316 | L2-Norm(final)=14.367 | 4302.1 samples/s | 67.2 steps/s
[Step=48100 Epoch=234.4] | Loss=0.00425 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=14.378 | 5122.0 samples/s | 80.0 steps/s
[Step=48150 Epoch=234.6] | Loss=0.00387 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.321 | L2-Norm(final)=14.390 | 5009.8 samples/s | 78.3 steps/s
[Step=48200 Epoch=234.9] | Loss=0.00376 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.323 | L2-Norm(final)=14.403 | 7787.3 samples/s | 121.7 steps/s
[Step=48250 Epoch=235.1] | Loss=0.00346 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.325 | L2-Norm(final)=14.415 | 2203.4 samples/s | 34.4 steps/s
[Step=48300 Epoch=235.3] | Loss=0.00347 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.326 | L2-Norm(final)=14.426 | 5001.1 samples/s | 78.1 steps/s
[Step=48350 Epoch=235.6] | Loss=0.00338 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.327 | L2-Norm(final)=14.438 | 5055.6 samples/s | 79.0 steps/s
[Step=48400 Epoch=235.8] | Loss=0.00337 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.328 | L2-Norm(final)=14.450 | 6927.8 samples/s | 108.2 steps/s
[Step=48450 Epoch=236.1] | Loss=0.00339 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.329 | L2-Norm(final)=14.461 | 2308.7 samples/s | 36.1 steps/s
[Step=48500 Epoch=236.3] | Loss=0.00334 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.329 | L2-Norm(final)=14.472 | 5080.1 samples/s | 79.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=236.3] | Loss=0.00729 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.333 | L2-Norm(final)=14.582 | 5434.6 samples/s | 84.9 steps/s
[Step=48550 Epoch=236.6] | Loss=0.00285 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.333 | L2-Norm(final)=14.592 | 4042.9 samples/s | 63.2 steps/s
[Step=48600 Epoch=236.8] | Loss=0.00508 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.336 | L2-Norm(final)=14.599 | 4375.9 samples/s | 68.4 steps/s
[Step=48650 Epoch=237.0] | Loss=0.00556 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.340 | L2-Norm(final)=14.607 | 4448.4 samples/s | 69.5 steps/s
[Step=48700 Epoch=237.3] | Loss=0.00574 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.347 | L2-Norm(final)=14.616 | 6439.3 samples/s | 100.6 steps/s
[Step=48750 Epoch=237.5] | Loss=0.00573 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.355 | L2-Norm(final)=14.626 | 2098.0 samples/s | 32.8 steps/s
[Step=48800 Epoch=237.8] | Loss=0.00594 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.361 | L2-Norm(final)=14.634 | 4478.7 samples/s | 70.0 steps/s
[Step=48850 Epoch=238.0] | Loss=0.00607 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.367 | L2-Norm(final)=14.641 | 4535.5 samples/s | 70.9 steps/s
[Step=48900 Epoch=238.3] | Loss=0.00623 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.374 | L2-Norm(final)=14.648 | 5759.4 samples/s | 90.0 steps/s
[Step=48950 Epoch=238.5] | Loss=0.00622 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.381 | L2-Norm(final)=14.655 | 2136.2 samples/s | 33.4 steps/s
[Step=49000 Epoch=238.8] | Loss=0.00625 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.387 | L2-Norm(final)=14.662 | 4519.2 samples/s | 70.6 steps/s
[Step=49050 Epoch=239.0] | Loss=0.00624 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.393 | L2-Norm(final)=14.668 | 4451.1 samples/s | 69.5 steps/s
[Step=49100 Epoch=239.2] | Loss=0.00608 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.398 | L2-Norm(final)=14.674 | 5437.0 samples/s | 85.0 steps/s
[Step=49150 Epoch=239.5] | Loss=0.00588 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.402 | L2-Norm(final)=14.679 | 2252.2 samples/s | 35.2 steps/s
[Step=49200 Epoch=239.7] | Loss=0.00566 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.405 | L2-Norm(final)=14.685 | 4518.0 samples/s | 70.6 steps/s
[Step=49250 Epoch=240.0] | Loss=0.00547 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.408 | L2-Norm(final)=14.690 | 4451.1 samples/s | 69.5 steps/s
[Step=49300 Epoch=240.2] | Loss=0.00534 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.409 | L2-Norm(final)=14.695 | 4875.0 samples/s | 76.2 steps/s
[Step=49350 Epoch=240.5] | Loss=0.00517 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.411 | L2-Norm(final)=14.699 | 2262.0 samples/s | 35.3 steps/s
[Step=49400 Epoch=240.7] | Loss=0.00496 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.411 | L2-Norm(final)=14.704 | 4486.5 samples/s | 70.1 steps/s
[Step=49450 Epoch=240.9] | Loss=0.00483 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.412 | L2-Norm(final)=14.708 | 4529.0 samples/s | 70.8 steps/s
[Step=49500 Epoch=241.2] | Loss=0.00476 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.412 | L2-Norm(final)=14.712 | 4541.0 samples/s | 71.0 steps/s
[Step=49550 Epoch=241.4] | Loss=0.00469 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.411 | L2-Norm(final)=14.716 | 2428.3 samples/s | 37.9 steps/s
[Step=49600 Epoch=241.7] | Loss=0.00462 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.411 | L2-Norm(final)=14.720 | 4498.7 samples/s | 70.3 steps/s
[Step=49650 Epoch=241.9] | Loss=0.00453 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.410 | L2-Norm(final)=14.723 | 4457.8 samples/s | 69.7 steps/s
[Step=49700 Epoch=242.2] | Loss=0.00444 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.408 | L2-Norm(final)=14.727 | 4374.9 samples/s | 68.4 steps/s
[Step=49750 Epoch=242.4] | Loss=0.00435 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.407 | L2-Norm(final)=14.730 | 2451.4 samples/s | 38.3 steps/s
[Step=49800 Epoch=242.6] | Loss=0.00429 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.405 | L2-Norm(final)=14.733 | 4492.4 samples/s | 70.2 steps/s
[Step=49850 Epoch=242.9] | Loss=0.00422 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.403 | L2-Norm(final)=14.737 | 4484.3 samples/s | 70.1 steps/s
[Step=49900 Epoch=243.1] | Loss=0.00418 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.401 | L2-Norm(final)=14.740 | 4554.8 samples/s | 71.2 steps/s
[Step=49950 Epoch=243.4] | Loss=0.00415 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.399 | L2-Norm(final)=14.743 | 2447.8 samples/s | 38.2 steps/s
[Step=50000 Epoch=243.6] | Loss=0.00408 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.397 | L2-Norm(final)=14.746 | 4391.8 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step50000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=234.1] | Loss=0.00215 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.927 | L2-Norm(final)=14.215 | 5335.0 samples/s | 83.4 steps/s
[Step=48050 Epoch=234.3] | Loss=0.00297 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.934 | L2-Norm(final)=14.226 | 4549.8 samples/s | 71.1 steps/s
[Step=48100 Epoch=234.6] | Loss=0.00327 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.939 | L2-Norm(final)=14.240 | 4995.0 samples/s | 78.0 steps/s
[Step=48150 Epoch=234.8] | Loss=0.00366 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.943 | L2-Norm(final)=14.254 | 5069.8 samples/s | 79.2 steps/s
[Step=48200 Epoch=235.1] | Loss=0.00338 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.947 | L2-Norm(final)=14.267 | 7694.2 samples/s | 120.2 steps/s
[Step=48250 Epoch=235.3] | Loss=0.00321 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.951 | L2-Norm(final)=14.280 | 2230.5 samples/s | 34.9 steps/s
[Step=48300 Epoch=235.5] | Loss=0.00303 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.953 | L2-Norm(final)=14.293 | 5129.6 samples/s | 80.1 steps/s
[Step=48350 Epoch=235.8] | Loss=0.00303 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.955 | L2-Norm(final)=14.305 | 4950.5 samples/s | 77.4 steps/s
[Step=48400 Epoch=236.0] | Loss=0.00297 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.957 | L2-Norm(final)=14.317 | 6886.8 samples/s | 107.6 steps/s
[Step=48450 Epoch=236.3] | Loss=0.00292 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.958 | L2-Norm(final)=14.330 | 2298.8 samples/s | 35.9 steps/s
[Step=48500 Epoch=236.5] | Loss=0.00282 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.960 | L2-Norm(final)=14.342 | 5068.5 samples/s | 79.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=236.5] | Loss=0.00335 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.970 | L2-Norm(final)=14.463 | 5543.0 samples/s | 86.6 steps/s
[Step=48550 Epoch=236.8] | Loss=0.00374 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.972 | L2-Norm(final)=14.473 | 4004.6 samples/s | 62.6 steps/s
[Step=48600 Epoch=237.0] | Loss=0.00465 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.980 | L2-Norm(final)=14.482 | 4500.7 samples/s | 70.3 steps/s
[Step=48650 Epoch=237.2] | Loss=0.00980 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.998 | L2-Norm(final)=14.492 | 4465.2 samples/s | 69.8 steps/s
[Step=48700 Epoch=237.5] | Loss=0.00983 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.023 | L2-Norm(final)=14.498 | 6478.2 samples/s | 101.2 steps/s
[Step=48750 Epoch=237.7] | Loss=0.00958 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.042 | L2-Norm(final)=14.505 | 2061.9 samples/s | 32.2 steps/s
[Step=48800 Epoch=238.0] | Loss=0.00894 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.057 | L2-Norm(final)=14.512 | 4547.2 samples/s | 71.1 steps/s
[Step=48850 Epoch=238.2] | Loss=0.00840 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.069 | L2-Norm(final)=14.519 | 4453.9 samples/s | 69.6 steps/s
[Step=48900 Epoch=238.5] | Loss=0.00808 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.078 | L2-Norm(final)=14.525 | 5865.8 samples/s | 91.7 steps/s
[Step=48950 Epoch=238.7] | Loss=0.00777 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.086 | L2-Norm(final)=14.532 | 2161.6 samples/s | 33.8 steps/s
[Step=49000 Epoch=239.0] | Loss=0.00732 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.094 | L2-Norm(final)=14.538 | 4517.0 samples/s | 70.6 steps/s
[Step=49050 Epoch=239.2] | Loss=0.00697 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.100 | L2-Norm(final)=14.544 | 4309.0 samples/s | 67.3 steps/s
[Step=49100 Epoch=239.4] | Loss=0.00677 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.106 | L2-Norm(final)=14.549 | 5432.1 samples/s | 84.9 steps/s
[Step=49150 Epoch=239.7] | Loss=0.00641 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.110 | L2-Norm(final)=14.554 | 2276.2 samples/s | 35.6 steps/s
[Step=49200 Epoch=239.9] | Loss=0.00614 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.114 | L2-Norm(final)=14.559 | 4457.1 samples/s | 69.6 steps/s
[Step=49250 Epoch=240.2] | Loss=0.00593 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.117 | L2-Norm(final)=14.564 | 4477.0 samples/s | 70.0 steps/s
[Step=49300 Epoch=240.4] | Loss=0.00576 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.119 | L2-Norm(final)=14.569 | 4982.9 samples/s | 77.9 steps/s
[Step=49350 Epoch=240.7] | Loss=0.00553 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.121 | L2-Norm(final)=14.573 | 2316.7 samples/s | 36.2 steps/s
[Step=49400 Epoch=240.9] | Loss=0.00531 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.122 | L2-Norm(final)=14.577 | 4394.0 samples/s | 68.7 steps/s
[Step=49450 Epoch=241.1] | Loss=0.00510 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=14.581 | 4570.0 samples/s | 71.4 steps/s
[Step=49500 Epoch=241.4] | Loss=0.00497 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=14.585 | 4512.1 samples/s | 70.5 steps/s
[Step=49550 Epoch=241.6] | Loss=0.00483 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=14.589 | 2450.0 samples/s | 38.3 steps/s
[Step=49600 Epoch=241.9] | Loss=0.00474 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=14.592 | 4456.1 samples/s | 69.6 steps/s
[Step=49650 Epoch=242.1] | Loss=0.00457 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.123 | L2-Norm(final)=14.596 | 4536.0 samples/s | 70.9 steps/s
[Step=49700 Epoch=242.4] | Loss=0.00447 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.122 | L2-Norm(final)=14.599 | 4406.8 samples/s | 68.9 steps/s
[Step=49750 Epoch=242.6] | Loss=0.00437 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.121 | L2-Norm(final)=14.602 | 2459.3 samples/s | 38.4 steps/s
[Step=49800 Epoch=242.9] | Loss=0.00425 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.119 | L2-Norm(final)=14.606 | 4393.7 samples/s | 68.7 steps/s
[Step=49850 Epoch=243.1] | Loss=0.00414 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.118 | L2-Norm(final)=14.609 | 4446.0 samples/s | 69.5 steps/s
[Step=49900 Epoch=243.3] | Loss=0.00404 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.116 | L2-Norm(final)=14.612 | 4506.0 samples/s | 70.4 steps/s
[Step=49950 Epoch=243.6] | Loss=0.00401 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.114 | L2-Norm(final)=14.615 | 2459.6 samples/s | 38.4 steps/s
[Step=50000 Epoch=243.8] | Loss=0.00392 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.112 | L2-Norm(final)=14.618 | 4480.3 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step50000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=235.4] | Loss=0.00222 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.788 | L2-Norm(final)=14.314 | 5195.8 samples/s | 81.2 steps/s
[Step=48050 Epoch=235.6] | Loss=0.00403 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.791 | L2-Norm(final)=14.323 | 4325.2 samples/s | 67.6 steps/s
[Step=48100 Epoch=235.9] | Loss=0.00330 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.796 | L2-Norm(final)=14.336 | 4996.1 samples/s | 78.1 steps/s
[Step=48150 Epoch=236.1] | Loss=0.00322 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.799 | L2-Norm(final)=14.348 | 5072.4 samples/s | 79.3 steps/s
[Step=48200 Epoch=236.4] | Loss=0.00298 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.801 | L2-Norm(final)=14.361 | 8063.9 samples/s | 126.0 steps/s
[Step=48250 Epoch=236.6] | Loss=0.00278 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=14.373 | 2200.1 samples/s | 34.4 steps/s
[Step=48300 Epoch=236.9] | Loss=0.00271 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.804 | L2-Norm(final)=14.386 | 4977.4 samples/s | 77.8 steps/s
[Step=48350 Epoch=237.1] | Loss=0.00258 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.398 | 5045.6 samples/s | 78.8 steps/s
[Step=48400 Epoch=237.3] | Loss=0.00264 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.409 | 7445.1 samples/s | 116.3 steps/s
[Step=48450 Epoch=237.6] | Loss=0.00264 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.421 | 2218.2 samples/s | 34.7 steps/s
[Step=48500 Epoch=237.8] | Loss=0.00260 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.805 | L2-Norm(final)=14.433 | 5162.6 samples/s | 80.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=237.8] | Loss=0.00122 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.549 | 5541.7 samples/s | 86.6 steps/s
[Step=48550 Epoch=238.1] | Loss=0.00232 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.559 | 4064.6 samples/s | 63.5 steps/s
[Step=48600 Epoch=238.3] | Loss=0.00463 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.811 | L2-Norm(final)=14.568 | 4443.4 samples/s | 69.4 steps/s
[Step=48650 Epoch=238.6] | Loss=0.00533 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.821 | L2-Norm(final)=14.579 | 4477.3 samples/s | 70.0 steps/s
[Step=48700 Epoch=238.8] | Loss=0.00563 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.831 | L2-Norm(final)=14.588 | 6732.5 samples/s | 105.2 steps/s
[Step=48750 Epoch=239.1] | Loss=0.00555 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.840 | L2-Norm(final)=14.599 | 2053.7 samples/s | 32.1 steps/s
[Step=48800 Epoch=239.3] | Loss=0.00566 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.848 | L2-Norm(final)=14.608 | 4607.0 samples/s | 72.0 steps/s
[Step=48850 Epoch=239.6] | Loss=0.00557 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.854 | L2-Norm(final)=14.618 | 4386.4 samples/s | 68.5 steps/s
[Step=48900 Epoch=239.8] | Loss=0.00548 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.861 | L2-Norm(final)=14.627 | 6256.4 samples/s | 97.8 steps/s
[Step=48950 Epoch=240.0] | Loss=0.00535 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.866 | L2-Norm(final)=14.635 | 2139.4 samples/s | 33.4 steps/s
[Step=49000 Epoch=240.3] | Loss=0.00520 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.871 | L2-Norm(final)=14.643 | 4419.3 samples/s | 69.1 steps/s
[Step=49050 Epoch=240.5] | Loss=0.00491 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.875 | L2-Norm(final)=14.650 | 4487.2 samples/s | 70.1 steps/s
[Step=49100 Epoch=240.8] | Loss=0.00490 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.878 | L2-Norm(final)=14.657 | 5830.6 samples/s | 91.1 steps/s
[Step=49150 Epoch=241.0] | Loss=0.00475 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.880 | L2-Norm(final)=14.664 | 2125.9 samples/s | 33.2 steps/s
[Step=49200 Epoch=241.3] | Loss=0.00461 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.882 | L2-Norm(final)=14.670 | 4476.9 samples/s | 70.0 steps/s
[Step=49250 Epoch=241.5] | Loss=0.00451 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.883 | L2-Norm(final)=14.676 | 4568.4 samples/s | 71.4 steps/s
[Step=49300 Epoch=241.8] | Loss=0.00446 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=14.682 | 5384.2 samples/s | 84.1 steps/s
[Step=49350 Epoch=242.0] | Loss=0.00438 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=14.687 | 2236.7 samples/s | 34.9 steps/s
[Step=49400 Epoch=242.2] | Loss=0.00431 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=14.692 | 4459.0 samples/s | 69.7 steps/s
[Step=49450 Epoch=242.5] | Loss=0.00416 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.883 | L2-Norm(final)=14.697 | 4468.5 samples/s | 69.8 steps/s
[Step=49500 Epoch=242.7] | Loss=0.00405 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.883 | L2-Norm(final)=14.702 | 5105.5 samples/s | 79.8 steps/s
[Step=49550 Epoch=243.0] | Loss=0.00394 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.882 | L2-Norm(final)=14.706 | 2283.0 samples/s | 35.7 steps/s
[Step=49600 Epoch=243.2] | Loss=0.00385 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.880 | L2-Norm(final)=14.711 | 4538.2 samples/s | 70.9 steps/s
[Step=49650 Epoch=243.5] | Loss=0.00380 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.879 | L2-Norm(final)=14.715 | 4437.5 samples/s | 69.3 steps/s
[Step=49700 Epoch=243.7] | Loss=0.00381 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.877 | L2-Norm(final)=14.720 | 4941.8 samples/s | 77.2 steps/s
[Step=49750 Epoch=244.0] | Loss=0.00376 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.875 | L2-Norm(final)=14.724 | 2313.1 samples/s | 36.1 steps/s
[Step=49800 Epoch=244.2] | Loss=0.00369 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.873 | L2-Norm(final)=14.728 | 4417.8 samples/s | 69.0 steps/s
[Step=49850 Epoch=244.5] | Loss=0.00363 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.871 | L2-Norm(final)=14.731 | 4488.6 samples/s | 70.1 steps/s
[Step=49900 Epoch=244.7] | Loss=0.00358 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.868 | L2-Norm(final)=14.735 | 4652.5 samples/s | 72.7 steps/s
[Step=49950 Epoch=244.9] | Loss=0.00351 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.866 | L2-Norm(final)=14.739 | 2410.6 samples/s | 37.7 steps/s
[Step=50000 Epoch=245.2] | Loss=0.00347 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.863 | L2-Norm(final)=14.743 | 4465.6 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step50000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=454.9] | Loss=0.00017 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=7.566 | 5502.5 samples/s | 86.0 steps/s
[Step=48050 Epoch=455.3] | Loss=0.00075 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.170 | L2-Norm(final)=7.583 | 4156.5 samples/s | 64.9 steps/s
[Step=48100 Epoch=455.8] | Loss=0.00043 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.196 | L2-Norm(final)=7.599 | 7413.9 samples/s | 115.8 steps/s
[Step=48150 Epoch=456.3] | Loss=0.00031 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.210 | L2-Norm(final)=7.610 | 2123.9 samples/s | 33.2 steps/s
[Step=48200 Epoch=456.7] | Loss=0.00025 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.219 | L2-Norm(final)=7.618 | 6497.6 samples/s | 101.5 steps/s
[Step=48250 Epoch=457.2] | Loss=0.00020 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.225 | L2-Norm(final)=7.625 | 2200.5 samples/s | 34.4 steps/s
[Step=48300 Epoch=457.7] | Loss=0.00018 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.229 | L2-Norm(final)=7.631 | 5956.6 samples/s | 93.1 steps/s
[Step=48350 Epoch=458.2] | Loss=0.00016 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.232 | L2-Norm(final)=7.636 | 2312.6 samples/s | 36.1 steps/s
[Step=48400 Epoch=458.6] | Loss=0.00014 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.235 | L2-Norm(final)=7.641 | 5377.2 samples/s | 84.0 steps/s
[Step=48450 Epoch=459.1] | Loss=0.00013 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.237 | L2-Norm(final)=7.646 | 2335.7 samples/s | 36.5 steps/s
[Step=48500 Epoch=459.6] | Loss=0.00012 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.238 | L2-Norm(final)=7.651 | 4834.0 samples/s | 75.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=459.6] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.255 | L2-Norm(final)=7.696 | 5443.8 samples/s | 85.1 steps/s
[Step=48550 Epoch=460.1] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.246 | L2-Norm(final)=7.699 | 3652.9 samples/s | 57.1 steps/s
[Step=48600 Epoch=460.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.233 | L2-Norm(final)=7.701 | 6311.0 samples/s | 98.6 steps/s
[Step=48650 Epoch=461.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=7.703 | 2028.7 samples/s | 31.7 steps/s
[Step=48700 Epoch=461.5] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.199 | L2-Norm(final)=7.704 | 5564.3 samples/s | 86.9 steps/s
[Step=48750 Epoch=461.9] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.181 | L2-Norm(final)=7.704 | 2034.0 samples/s | 31.8 steps/s
[Step=48800 Epoch=462.4] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.163 | L2-Norm(final)=7.705 | 5190.2 samples/s | 81.1 steps/s
[Step=48850 Epoch=462.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=7.706 | 2183.8 samples/s | 34.1 steps/s
[Step=48900 Epoch=463.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.126 | L2-Norm(final)=7.706 | 4679.7 samples/s | 73.1 steps/s
[Step=48950 Epoch=463.8] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.107 | L2-Norm(final)=7.707 | 2279.3 samples/s | 35.6 steps/s
[Step=49000 Epoch=464.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=7.707 | 4211.9 samples/s | 65.8 steps/s
[Step=49050 Epoch=464.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.070 | L2-Norm(final)=7.708 | 2356.7 samples/s | 36.8 steps/s
[Step=49100 Epoch=465.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.050 | L2-Norm(final)=7.708 | 4180.4 samples/s | 65.3 steps/s
[Step=49150 Epoch=465.7] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.031 | L2-Norm(final)=7.709 | 2371.1 samples/s | 37.0 steps/s
[Step=49200 Epoch=466.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.012 | L2-Norm(final)=7.709 | 4241.0 samples/s | 66.3 steps/s
[Step=49250 Epoch=466.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.992 | L2-Norm(final)=7.710 | 2375.8 samples/s | 37.1 steps/s
[Step=49300 Epoch=467.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=7.710 | 4136.0 samples/s | 64.6 steps/s
[Step=49350 Epoch=467.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.953 | L2-Norm(final)=7.711 | 2498.9 samples/s | 39.0 steps/s
[Step=49400 Epoch=468.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.933 | L2-Norm(final)=7.711 | 4085.8 samples/s | 63.8 steps/s
[Step=49450 Epoch=468.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.913 | L2-Norm(final)=7.712 | 6455.1 samples/s | 100.9 steps/s
[Step=49500 Epoch=469.1] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.893 | L2-Norm(final)=7.713 | 2018.4 samples/s | 31.5 steps/s
[Step=49550 Epoch=469.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.873 | L2-Norm(final)=7.713 | 5718.8 samples/s | 89.4 steps/s
[Step=49600 Epoch=470.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.853 | L2-Norm(final)=7.714 | 2048.0 samples/s | 32.0 steps/s
[Step=49650 Epoch=470.5] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.832 | L2-Norm(final)=7.714 | 5251.2 samples/s | 82.1 steps/s
[Step=49700 Epoch=471.0] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.812 | L2-Norm(final)=7.715 | 2135.8 samples/s | 33.4 steps/s
[Step=49750 Epoch=471.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.791 | L2-Norm(final)=7.715 | 4820.8 samples/s | 75.3 steps/s
[Step=49800 Epoch=471.9] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=7.716 | 2237.5 samples/s | 35.0 steps/s
[Step=49850 Epoch=472.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.750 | L2-Norm(final)=7.717 | 4422.7 samples/s | 69.1 steps/s
[Step=49900 Epoch=472.8] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.729 | L2-Norm(final)=7.717 | 2250.3 samples/s | 35.2 steps/s
[Step=49950 Epoch=473.3] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.708 | L2-Norm(final)=7.718 | 4200.1 samples/s | 65.6 steps/s
[Step=50000 Epoch=473.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.686 | L2-Norm(final)=7.718 | 2396.4 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step50000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=456.6] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.277 | L2-Norm(final)=8.618 | 5714.0 samples/s | 89.3 steps/s
[Step=48050 Epoch=457.1] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=8.620 | 3872.5 samples/s | 60.5 steps/s
[Step=48100 Epoch=457.6] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=8.622 | 7586.6 samples/s | 118.5 steps/s
[Step=48150 Epoch=458.0] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=8.624 | 2095.2 samples/s | 32.7 steps/s
[Step=48200 Epoch=458.5] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=8.626 | 6704.3 samples/s | 104.8 steps/s
[Step=48250 Epoch=459.0] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=8.628 | 2206.0 samples/s | 34.5 steps/s
[Step=48300 Epoch=459.5] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.630 | 5939.4 samples/s | 92.8 steps/s
[Step=48350 Epoch=459.9] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.632 | 2320.8 samples/s | 36.3 steps/s
[Step=48400 Epoch=460.4] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.633 | 5399.2 samples/s | 84.4 steps/s
[Step=48450 Epoch=460.9] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.635 | 2393.4 samples/s | 37.4 steps/s
[Step=48500 Epoch=461.4] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.637 | 4891.1 samples/s | 76.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=461.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.287 | L2-Norm(final)=8.655 | 5650.3 samples/s | 88.3 steps/s
[Step=48550 Epoch=461.8] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.657 | 3706.8 samples/s | 57.9 steps/s
[Step=48600 Epoch=462.3] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=8.659 | 6323.1 samples/s | 98.8 steps/s
[Step=48650 Epoch=462.8] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=8.660 | 2051.3 samples/s | 32.1 steps/s
[Step=48700 Epoch=463.3] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.279 | L2-Norm(final)=8.661 | 5498.2 samples/s | 85.9 steps/s
[Step=48750 Epoch=463.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.277 | L2-Norm(final)=8.662 | 2061.4 samples/s | 32.2 steps/s
[Step=48800 Epoch=464.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.274 | L2-Norm(final)=8.663 | 5083.2 samples/s | 79.4 steps/s
[Step=48850 Epoch=464.7] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.271 | L2-Norm(final)=8.664 | 2218.6 samples/s | 34.7 steps/s
[Step=48900 Epoch=465.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.269 | L2-Norm(final)=8.665 | 4561.5 samples/s | 71.3 steps/s
[Step=48950 Epoch=465.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.266 | L2-Norm(final)=8.666 | 2231.8 samples/s | 34.9 steps/s
[Step=49000 Epoch=466.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.263 | L2-Norm(final)=8.667 | 4392.1 samples/s | 68.6 steps/s
[Step=49050 Epoch=466.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.260 | L2-Norm(final)=8.668 | 2308.4 samples/s | 36.1 steps/s
[Step=49100 Epoch=467.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.257 | L2-Norm(final)=8.669 | 4266.5 samples/s | 66.7 steps/s
[Step=49150 Epoch=467.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.254 | L2-Norm(final)=8.670 | 2379.5 samples/s | 37.2 steps/s
[Step=49200 Epoch=468.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.251 | L2-Norm(final)=8.670 | 4254.5 samples/s | 66.5 steps/s
[Step=49250 Epoch=468.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.248 | L2-Norm(final)=8.671 | 2381.2 samples/s | 37.2 steps/s
[Step=49300 Epoch=469.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.244 | L2-Norm(final)=8.672 | 4216.4 samples/s | 65.9 steps/s
[Step=49350 Epoch=469.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.241 | L2-Norm(final)=8.673 | 2437.2 samples/s | 38.1 steps/s
[Step=49400 Epoch=469.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.238 | L2-Norm(final)=8.673 | 4151.7 samples/s | 64.9 steps/s
[Step=49450 Epoch=470.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.235 | L2-Norm(final)=8.674 | 6488.3 samples/s | 101.4 steps/s
[Step=49500 Epoch=470.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.231 | L2-Norm(final)=8.675 | 1976.9 samples/s | 30.9 steps/s
[Step=49550 Epoch=471.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.228 | L2-Norm(final)=8.675 | 5912.2 samples/s | 92.4 steps/s
[Step=49600 Epoch=471.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.225 | L2-Norm(final)=8.676 | 2053.8 samples/s | 32.1 steps/s
[Step=49650 Epoch=472.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.221 | L2-Norm(final)=8.677 | 5258.4 samples/s | 82.2 steps/s
[Step=49700 Epoch=472.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.677 | 2144.2 samples/s | 33.5 steps/s
[Step=49750 Epoch=473.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=8.678 | 4844.8 samples/s | 75.7 steps/s
[Step=49800 Epoch=473.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.210 | L2-Norm(final)=8.679 | 2256.7 samples/s | 35.3 steps/s
[Step=49850 Epoch=474.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.206 | L2-Norm(final)=8.679 | 4425.7 samples/s | 69.2 steps/s
[Step=49900 Epoch=474.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.203 | L2-Norm(final)=8.680 | 2340.8 samples/s | 36.6 steps/s
[Step=49950 Epoch=475.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.199 | L2-Norm(final)=8.681 | 4093.3 samples/s | 64.0 steps/s
[Step=50000 Epoch=475.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.195 | L2-Norm(final)=8.681 | 2404.1 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step50000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=458.4] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=8.137 | 5211.6 samples/s | 81.4 steps/s
[Step=48050 Epoch=458.8] | Loss=0.00046 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=8.159 | 4145.0 samples/s | 64.8 steps/s
[Step=48100 Epoch=459.3] | Loss=0.00031 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.159 | L2-Norm(final)=8.177 | 7552.8 samples/s | 118.0 steps/s
[Step=48150 Epoch=459.8] | Loss=0.00024 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.175 | L2-Norm(final)=8.192 | 2107.4 samples/s | 32.9 steps/s
[Step=48200 Epoch=460.3] | Loss=0.00019 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.185 | L2-Norm(final)=8.203 | 6758.0 samples/s | 105.6 steps/s
[Step=48250 Epoch=460.8] | Loss=0.00016 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.192 | L2-Norm(final)=8.212 | 2173.3 samples/s | 34.0 steps/s
[Step=48300 Epoch=461.2] | Loss=0.00014 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.197 | L2-Norm(final)=8.219 | 6090.5 samples/s | 95.2 steps/s
[Step=48350 Epoch=461.7] | Loss=0.00012 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.201 | L2-Norm(final)=8.226 | 2256.2 samples/s | 35.3 steps/s
[Step=48400 Epoch=462.2] | Loss=0.00011 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.204 | L2-Norm(final)=8.232 | 5639.7 samples/s | 88.1 steps/s
[Step=48450 Epoch=462.7] | Loss=0.00010 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.206 | L2-Norm(final)=8.237 | 2337.1 samples/s | 36.5 steps/s
[Step=48500 Epoch=463.1] | Loss=0.00009 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.208 | L2-Norm(final)=8.243 | 5205.5 samples/s | 81.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=463.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.225 | L2-Norm(final)=8.295 | 4972.1 samples/s | 77.7 steps/s
[Step=48550 Epoch=463.6] | Loss=0.00014 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.205 | L2-Norm(final)=8.300 | 3944.3 samples/s | 61.6 steps/s
[Step=48600 Epoch=464.1] | Loss=0.00389 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.258 | L2-Norm(final)=8.304 | 6443.8 samples/s | 100.7 steps/s
[Step=48650 Epoch=464.6] | Loss=0.00288 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.305 | L2-Norm(final)=8.295 | 2001.9 samples/s | 31.3 steps/s
[Step=48700 Epoch=465.1] | Loss=0.00218 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.331 | L2-Norm(final)=8.291 | 5861.5 samples/s | 91.6 steps/s
[Step=48750 Epoch=465.5] | Loss=0.00175 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.346 | L2-Norm(final)=8.289 | 2063.6 samples/s | 32.2 steps/s
[Step=48800 Epoch=466.0] | Loss=0.00146 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.356 | L2-Norm(final)=8.288 | 5330.0 samples/s | 83.3 steps/s
[Step=48850 Epoch=466.5] | Loss=0.00126 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.363 | L2-Norm(final)=8.287 | 2162.3 samples/s | 33.8 steps/s
[Step=48900 Epoch=467.0] | Loss=0.00110 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.368 | L2-Norm(final)=8.287 | 5006.7 samples/s | 78.2 steps/s
[Step=48950 Epoch=467.4] | Loss=0.00098 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.371 | L2-Norm(final)=8.286 | 2209.8 samples/s | 34.5 steps/s
[Step=49000 Epoch=467.9] | Loss=0.00088 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.374 | L2-Norm(final)=8.286 | 4605.6 samples/s | 72.0 steps/s
[Step=49050 Epoch=468.4] | Loss=0.00080 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.376 | L2-Norm(final)=8.286 | 2251.4 samples/s | 35.2 steps/s
[Step=49100 Epoch=468.9] | Loss=0.00074 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.377 | L2-Norm(final)=8.286 | 4337.1 samples/s | 67.8 steps/s
[Step=49150 Epoch=469.4] | Loss=0.00068 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.378 | L2-Norm(final)=8.287 | 2372.6 samples/s | 37.1 steps/s
[Step=49200 Epoch=469.8] | Loss=0.00063 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.287 | 4143.7 samples/s | 64.7 steps/s
[Step=49250 Epoch=470.3] | Loss=0.00059 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.288 | 2394.8 samples/s | 37.4 steps/s
[Step=49300 Epoch=470.8] | Loss=0.00056 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.288 | 4263.7 samples/s | 66.6 steps/s
[Step=49350 Epoch=471.3] | Loss=0.00052 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.289 | 2363.9 samples/s | 36.9 steps/s
[Step=49400 Epoch=471.7] | Loss=0.00049 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.289 | 4313.9 samples/s | 67.4 steps/s
[Step=49450 Epoch=472.2] | Loss=0.00047 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.290 | 2410.1 samples/s | 37.7 steps/s
[Step=49500 Epoch=472.7] | Loss=0.00045 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.378 | L2-Norm(final)=8.290 | 4121.2 samples/s | 64.4 steps/s
[Step=49550 Epoch=473.2] | Loss=0.00042 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.378 | L2-Norm(final)=8.291 | 7030.3 samples/s | 109.8 steps/s
[Step=49600 Epoch=473.6] | Loss=0.00041 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.377 | L2-Norm(final)=8.292 | 1957.2 samples/s | 30.6 steps/s
[Step=49650 Epoch=474.1] | Loss=0.00039 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.376 | L2-Norm(final)=8.293 | 6333.5 samples/s | 99.0 steps/s
[Step=49700 Epoch=474.6] | Loss=0.00037 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.375 | L2-Norm(final)=8.293 | 1963.4 samples/s | 30.7 steps/s
[Step=49750 Epoch=475.1] | Loss=0.00036 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.375 | L2-Norm(final)=8.294 | 5860.0 samples/s | 91.6 steps/s
[Step=49800 Epoch=475.6] | Loss=0.00034 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.374 | L2-Norm(final)=8.295 | 2071.4 samples/s | 32.4 steps/s
[Step=49850 Epoch=476.0] | Loss=0.00033 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.295 | 5262.7 samples/s | 82.2 steps/s
[Step=49900 Epoch=476.5] | Loss=0.00032 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.372 | L2-Norm(final)=8.296 | 2163.7 samples/s | 33.8 steps/s
[Step=49950 Epoch=477.0] | Loss=0.00031 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.371 | L2-Norm(final)=8.297 | 4826.8 samples/s | 75.4 steps/s
[Step=50000 Epoch=477.5] | Loss=0.00030 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.369 | L2-Norm(final)=8.298 | 2220.5 samples/s | 34.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step50000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=452.3] | Loss=0.00003 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.354 | L2-Norm(final)=8.050 | 5492.1 samples/s | 85.8 steps/s
[Step=48050 Epoch=452.8] | Loss=0.00007 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.356 | L2-Norm(final)=8.050 | 4044.9 samples/s | 63.2 steps/s
[Step=48100 Epoch=453.2] | Loss=0.00007 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.358 | L2-Norm(final)=8.052 | 7170.3 samples/s | 112.0 steps/s
[Step=48150 Epoch=453.7] | Loss=0.00007 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.359 | L2-Norm(final)=8.053 | 2149.7 samples/s | 33.6 steps/s
[Step=48200 Epoch=454.2] | Loss=0.00006 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.360 | L2-Norm(final)=8.055 | 6267.0 samples/s | 97.9 steps/s
[Step=48250 Epoch=454.7] | Loss=0.00006 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.361 | L2-Norm(final)=8.056 | 2199.8 samples/s | 34.4 steps/s
[Step=48300 Epoch=455.1] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.362 | L2-Norm(final)=8.057 | 5632.4 samples/s | 88.0 steps/s
[Step=48350 Epoch=455.6] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.363 | L2-Norm(final)=8.059 | 2380.0 samples/s | 37.2 steps/s
[Step=48400 Epoch=456.1] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.364 | L2-Norm(final)=8.060 | 4970.3 samples/s | 77.7 steps/s
[Step=48450 Epoch=456.5] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.364 | L2-Norm(final)=8.061 | 2472.2 samples/s | 38.6 steps/s
[Step=48500 Epoch=457.0] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.365 | L2-Norm(final)=8.062 | 4763.4 samples/s | 74.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=457.0] | Loss=0.00003 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.370 | L2-Norm(final)=8.075 | 5378.3 samples/s | 84.0 steps/s
[Step=48550 Epoch=457.5] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.370 | L2-Norm(final)=8.076 | 3993.4 samples/s | 62.4 steps/s
[Step=48600 Epoch=458.0] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.369 | L2-Norm(final)=8.077 | 6010.2 samples/s | 93.9 steps/s
[Step=48650 Epoch=458.4] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.367 | L2-Norm(final)=8.078 | 2050.1 samples/s | 32.0 steps/s
[Step=48700 Epoch=458.9] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.366 | L2-Norm(final)=8.079 | 5444.6 samples/s | 85.1 steps/s
[Step=48750 Epoch=459.4] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.364 | L2-Norm(final)=8.079 | 2138.3 samples/s | 33.4 steps/s
[Step=48800 Epoch=459.8] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.362 | L2-Norm(final)=8.080 | 4883.0 samples/s | 76.3 steps/s
[Step=48850 Epoch=460.3] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.360 | L2-Norm(final)=8.081 | 2204.5 samples/s | 34.4 steps/s
[Step=48900 Epoch=460.8] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.358 | L2-Norm(final)=8.081 | 4491.9 samples/s | 70.2 steps/s
[Step=48950 Epoch=461.2] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.356 | L2-Norm(final)=8.082 | 2315.4 samples/s | 36.2 steps/s
[Step=49000 Epoch=461.7] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.354 | L2-Norm(final)=8.082 | 4223.5 samples/s | 66.0 steps/s
[Step=49050 Epoch=462.2] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.351 | L2-Norm(final)=8.083 | 2386.3 samples/s | 37.3 steps/s
[Step=49100 Epoch=462.7] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.349 | L2-Norm(final)=8.083 | 4142.8 samples/s | 64.7 steps/s
[Step=49150 Epoch=463.1] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.347 | L2-Norm(final)=8.084 | 2387.7 samples/s | 37.3 steps/s
[Step=49200 Epoch=463.6] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=8.084 | 4264.2 samples/s | 66.6 steps/s
[Step=49250 Epoch=464.1] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.342 | L2-Norm(final)=8.085 | 2660.3 samples/s | 41.6 steps/s
[Step=49300 Epoch=464.5] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.340 | L2-Norm(final)=8.085 | 3725.9 samples/s | 58.2 steps/s
[Step=49350 Epoch=465.0] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.338 | L2-Norm(final)=8.086 | 6123.5 samples/s | 95.7 steps/s
[Step=49400 Epoch=465.5] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.335 | L2-Norm(final)=8.086 | 1995.2 samples/s | 31.2 steps/s
[Step=49450 Epoch=466.0] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.332 | L2-Norm(final)=8.086 | 5542.9 samples/s | 86.6 steps/s
[Step=49500 Epoch=466.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.330 | L2-Norm(final)=8.087 | 2096.3 samples/s | 32.8 steps/s
[Step=49550 Epoch=466.9] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.327 | L2-Norm(final)=8.087 | 5029.6 samples/s | 78.6 steps/s
[Step=49600 Epoch=467.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.325 | L2-Norm(final)=8.088 | 2221.6 samples/s | 34.7 steps/s
[Step=49650 Epoch=467.8] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.322 | L2-Norm(final)=8.088 | 4470.9 samples/s | 69.9 steps/s
[Step=49700 Epoch=468.3] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.319 | L2-Norm(final)=8.088 | 2315.2 samples/s | 36.2 steps/s
[Step=49750 Epoch=468.8] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.316 | L2-Norm(final)=8.089 | 4129.0 samples/s | 64.5 steps/s
[Step=49800 Epoch=469.3] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.313 | L2-Norm(final)=8.089 | 2413.3 samples/s | 37.7 steps/s
[Step=49850 Epoch=469.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.310 | L2-Norm(final)=8.089 | 4208.4 samples/s | 65.8 steps/s
[Step=49900 Epoch=470.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.307 | L2-Norm(final)=8.090 | 2421.0 samples/s | 37.8 steps/s
[Step=49950 Epoch=470.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=8.090 | 4211.2 samples/s | 65.8 steps/s
[Step=50000 Epoch=471.1] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.301 | L2-Norm(final)=8.090 | 2491.4 samples/s | 38.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step50000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=457.5] | Loss=0.00013 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.237 | L2-Norm(final)=8.686 | 5071.9 samples/s | 79.2 steps/s
[Step=48050 Epoch=458.0] | Loss=0.00021 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.245 | L2-Norm(final)=8.703 | 4347.5 samples/s | 67.9 steps/s
[Step=48100 Epoch=458.4] | Loss=0.00015 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.257 | L2-Norm(final)=8.720 | 7255.3 samples/s | 113.4 steps/s
[Step=48150 Epoch=458.9] | Loss=0.00012 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.264 | L2-Norm(final)=8.733 | 2156.0 samples/s | 33.7 steps/s
[Step=48200 Epoch=459.4] | Loss=0.00010 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.269 | L2-Norm(final)=8.744 | 6644.5 samples/s | 103.8 steps/s
[Step=48250 Epoch=459.9] | Loss=0.00009 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.273 | L2-Norm(final)=8.754 | 2201.5 samples/s | 34.4 steps/s
[Step=48300 Epoch=460.3] | Loss=0.00009 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.276 | L2-Norm(final)=8.764 | 5974.2 samples/s | 93.3 steps/s
[Step=48350 Epoch=460.8] | Loss=0.00008 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.279 | L2-Norm(final)=8.773 | 2238.1 samples/s | 35.0 steps/s
[Step=48400 Epoch=461.3] | Loss=0.00007 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=8.782 | 5751.0 samples/s | 89.9 steps/s
[Step=48450 Epoch=461.8] | Loss=0.00007 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=8.790 | 2310.0 samples/s | 36.1 steps/s
[Step=48500 Epoch=462.2] | Loss=0.00007 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.287 | L2-Norm(final)=8.799 | 5282.4 samples/s | 82.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=462.3] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.308 | L2-Norm(final)=8.878 | 5372.2 samples/s | 83.9 steps/s
[Step=48550 Epoch=462.7] | Loss=0.00183 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.313 | L2-Norm(final)=8.884 | 3681.4 samples/s | 57.5 steps/s
[Step=48600 Epoch=463.2] | Loss=0.00264 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.377 | L2-Norm(final)=8.884 | 6355.2 samples/s | 99.3 steps/s
[Step=48650 Epoch=463.7] | Loss=0.00195 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.412 | L2-Norm(final)=8.883 | 2019.6 samples/s | 31.6 steps/s
[Step=48700 Epoch=464.2] | Loss=0.00148 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.430 | L2-Norm(final)=8.883 | 5777.8 samples/s | 90.3 steps/s
[Step=48750 Epoch=464.6] | Loss=0.00119 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.441 | L2-Norm(final)=8.884 | 2067.0 samples/s | 32.3 steps/s
[Step=48800 Epoch=465.1] | Loss=0.00099 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.448 | L2-Norm(final)=8.884 | 5366.1 samples/s | 83.8 steps/s
[Step=48850 Epoch=465.6] | Loss=0.00085 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.452 | L2-Norm(final)=8.884 | 2136.7 samples/s | 33.4 steps/s
[Step=48900 Epoch=466.1] | Loss=0.00075 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.455 | L2-Norm(final)=8.885 | 4894.0 samples/s | 76.5 steps/s
[Step=48950 Epoch=466.5] | Loss=0.00067 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.457 | L2-Norm(final)=8.885 | 2209.8 samples/s | 34.5 steps/s
[Step=49000 Epoch=467.0] | Loss=0.00060 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.459 | L2-Norm(final)=8.885 | 4621.7 samples/s | 72.2 steps/s
[Step=49050 Epoch=467.5] | Loss=0.00055 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.886 | 2279.4 samples/s | 35.6 steps/s
[Step=49100 Epoch=468.0] | Loss=0.00050 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.886 | 4357.1 samples/s | 68.1 steps/s
[Step=49150 Epoch=468.4] | Loss=0.00046 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.461 | L2-Norm(final)=8.886 | 2296.1 samples/s | 35.9 steps/s
[Step=49200 Epoch=468.9] | Loss=0.00043 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.461 | L2-Norm(final)=8.887 | 4197.5 samples/s | 65.6 steps/s
[Step=49250 Epoch=469.4] | Loss=0.00040 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.887 | 2413.7 samples/s | 37.7 steps/s
[Step=49300 Epoch=469.9] | Loss=0.00038 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.887 | 4160.5 samples/s | 65.0 steps/s
[Step=49350 Epoch=470.3] | Loss=0.00036 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.888 | 2430.2 samples/s | 38.0 steps/s
[Step=49400 Epoch=470.8] | Loss=0.00034 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.459 | L2-Norm(final)=8.888 | 4184.5 samples/s | 65.4 steps/s
[Step=49450 Epoch=471.3] | Loss=0.00032 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.459 | L2-Norm(final)=8.888 | 2316.0 samples/s | 36.2 steps/s
[Step=49500 Epoch=471.8] | Loss=0.00030 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.458 | L2-Norm(final)=8.889 | 4277.8 samples/s | 66.8 steps/s
[Step=49550 Epoch=472.3] | Loss=0.00029 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.457 | L2-Norm(final)=8.889 | 6994.0 samples/s | 109.3 steps/s
[Step=49600 Epoch=472.7] | Loss=0.00028 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.457 | L2-Norm(final)=8.889 | 1968.7 samples/s | 30.8 steps/s
[Step=49650 Epoch=473.2] | Loss=0.00026 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.456 | L2-Norm(final)=8.890 | 6089.8 samples/s | 95.2 steps/s
[Step=49700 Epoch=473.7] | Loss=0.00025 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.455 | L2-Norm(final)=8.890 | 1999.0 samples/s | 31.2 steps/s
[Step=49750 Epoch=474.2] | Loss=0.00024 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.454 | L2-Norm(final)=8.890 | 5703.3 samples/s | 89.1 steps/s
[Step=49800 Epoch=474.6] | Loss=0.00023 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.453 | L2-Norm(final)=8.891 | 2058.9 samples/s | 32.2 steps/s
[Step=49850 Epoch=475.1] | Loss=0.00023 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.452 | L2-Norm(final)=8.891 | 5325.0 samples/s | 83.2 steps/s
[Step=49900 Epoch=475.6] | Loss=0.00022 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.451 | L2-Norm(final)=8.891 | 2148.1 samples/s | 33.6 steps/s
[Step=49950 Epoch=476.1] | Loss=0.00021 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.449 | L2-Norm(final)=8.891 | 4953.7 samples/s | 77.4 steps/s
[Step=50000 Epoch=476.5] | Loss=0.00020 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.448 | L2-Norm(final)=8.892 | 2177.1 samples/s | 34.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11630 | acc=0.9560 | tpr=0.9668 | fpr=0.0674 | 4925.2 samples/s | 19.2 steps/s
Avg test loss: 0.11927, Avg test acc: 0.95508, Avg tpr: 0.96672, Avg fpr: 0.07050, total FA: 550

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11680 | acc=0.9579 | tpr=0.9748 | fpr=0.0788 | 4747.2 samples/s | 18.5 steps/s
Avg test loss: 0.12143, Avg test acc: 0.95701, Avg tpr: 0.97371, Avg fpr: 0.07973, total FA: 622

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10723 | acc=0.9566 | tpr=0.9716 | fpr=0.0761 | 4602.5 samples/s | 18.0 steps/s
Avg test loss: 0.11029, Avg test acc: 0.95613, Avg tpr: 0.97092, Avg fpr: 0.07640, total FA: 596

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10902 | acc=0.9584 | tpr=0.9699 | fpr=0.0667 | 4532.2 samples/s | 17.7 steps/s
Avg test loss: 0.11299, Avg test acc: 0.95813, Avg tpr: 0.97092, Avg fpr: 0.06999, total FA: 546

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10755 | acc=0.9585 | tpr=0.9703 | fpr=0.0671 | 4825.6 samples/s | 18.9 steps/s
Avg test loss: 0.11463, Avg test acc: 0.95777, Avg tpr: 0.96998, Avg fpr: 0.06909, total FA: 539

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.32562 | acc=0.2972 | tpr=0.0089 | fpr=0.0768 | 4787.4 samples/s | 18.7 steps/s
Avg test loss: 5.33151, Avg test acc: 0.29622, Avg tpr: 0.01014, Avg fpr: 0.07461, total FA: 582

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.90189 | acc=0.2948 | tpr=0.0108 | fpr=0.0885 | 4867.3 samples/s | 19.0 steps/s
Avg test loss: 4.91759, Avg test acc: 0.29141, Avg tpr: 0.01084, Avg fpr: 0.09153, total FA: 714

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.12730 | acc=0.2893 | tpr=0.0153 | fpr=0.1157 | 4689.1 samples/s | 18.3 steps/s
Avg test loss: 5.13556, Avg test acc: 0.28612, Avg tpr: 0.01533, Avg fpr: 0.11832, total FA: 923

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.73420 | acc=0.2900 | tpr=0.0264 | fpr=0.1375 | 4924.1 samples/s | 19.2 steps/s
Avg test loss: 5.72556, Avg test acc: 0.28828, Avg tpr: 0.02739, Avg fpr: 0.13793, total FA: 1076

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=6.02820 | acc=0.2952 | tpr=0.0139 | fpr=0.0939 | 5064.6 samples/s | 19.8 steps/s
Avg test loss: 6.04752, Avg test acc: 0.29201, Avg tpr: 0.01393, Avg fpr: 0.09640, total FA: 752

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.00975 | acc=0.0862 | tpr=0.5752 | fpr=0.9226 | 4756.7 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.98137 | acc=0.0879 | tpr=0.5800 | fpr=0.9213 | 7168.2 samples/s | 28.0 steps/s
[Step= 150] | Loss=5.99551 | acc=0.0887 | tpr=0.5778 | fpr=0.9203 | 7908.1 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.99615 | acc=0.0885 | tpr=0.5738 | fpr=0.9203 | 8074.5 samples/s | 31.5 steps/s
[Step= 250] | Loss=6.00428 | acc=0.0890 | tpr=0.5738 | fpr=0.9198 | 7962.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.00318 | acc=0.0891 | tpr=0.5847 | fpr=0.9199 | 7652.1 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.99927 | acc=0.0891 | tpr=0.5848 | fpr=0.9199 | 7952.5 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.99368 | acc=0.0898 | tpr=0.5864 | fpr=0.9192 | 7917.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.99826 | acc=0.0897 | tpr=0.5876 | fpr=0.9194 | 7862.0 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.00226 | acc=0.0894 | tpr=0.5811 | fpr=0.9194 | 7975.8 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.00701 | acc=0.0893 | tpr=0.5802 | fpr=0.9196 | 13873.6 samples/s | 54.2 steps/s
Avg test loss: 6.00862, Avg test acc: 0.08922, Avg tpr: 0.58082, Avg fpr: 0.91972, total FA: 127701

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.50742 | acc=0.0902 | tpr=0.5044 | fpr=0.9173 | 4842.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.48407 | acc=0.0907 | tpr=0.5011 | fpr=0.9170 | 6788.4 samples/s | 26.5 steps/s
[Step= 150] | Loss=5.49073 | acc=0.0908 | tpr=0.5014 | fpr=0.9167 | 7901.3 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.48624 | acc=0.0912 | tpr=0.4885 | fpr=0.9160 | 8052.2 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.49196 | acc=0.0914 | tpr=0.4873 | fpr=0.9158 | 8093.5 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.48619 | acc=0.0911 | tpr=0.4975 | fpr=0.9163 | 7756.3 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.48197 | acc=0.0913 | tpr=0.4972 | fpr=0.9161 | 7552.5 samples/s | 29.5 steps/s
[Step= 400] | Loss=5.47809 | acc=0.0914 | tpr=0.4912 | fpr=0.9158 | 8062.1 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.48235 | acc=0.0912 | tpr=0.4859 | fpr=0.9160 | 7829.2 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.48638 | acc=0.0906 | tpr=0.4811 | fpr=0.9165 | 7890.9 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.48833 | acc=0.0905 | tpr=0.4779 | fpr=0.9165 | 13731.3 samples/s | 53.6 steps/s
Avg test loss: 5.49043, Avg test acc: 0.09041, Avg tpr: 0.47742, Avg fpr: 0.91662, total FA: 127271

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.08051 | acc=0.0710 | tpr=0.4071 | fpr=0.9350 | 4721.7 samples/s | 18.4 steps/s
[Step= 100] | Loss=6.04955 | acc=0.0737 | tpr=0.4307 | fpr=0.9329 | 7357.8 samples/s | 28.7 steps/s
[Step= 150] | Loss=6.05767 | acc=0.0746 | tpr=0.4424 | fpr=0.9321 | 7770.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=6.05494 | acc=0.0745 | tpr=0.4339 | fpr=0.9320 | 7947.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.05331 | acc=0.0750 | tpr=0.4393 | fpr=0.9316 | 7593.3 samples/s | 29.7 steps/s
[Step= 300] | Loss=6.05222 | acc=0.0755 | tpr=0.4516 | fpr=0.9314 | 8011.0 samples/s | 31.3 steps/s
[Step= 350] | Loss=6.04543 | acc=0.0758 | tpr=0.4508 | fpr=0.9310 | 7816.2 samples/s | 30.5 steps/s
[Step= 400] | Loss=6.03913 | acc=0.0764 | tpr=0.4535 | fpr=0.9304 | 7894.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.04195 | acc=0.0764 | tpr=0.4518 | fpr=0.9304 | 7911.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.04416 | acc=0.0763 | tpr=0.4493 | fpr=0.9305 | 7783.8 samples/s | 30.4 steps/s
[Step= 550] | Loss=6.04577 | acc=0.0761 | tpr=0.4481 | fpr=0.9306 | 14251.5 samples/s | 55.7 steps/s
Avg test loss: 6.04739, Avg test acc: 0.07603, Avg tpr: 0.44849, Avg fpr: 0.93074, total FA: 129231

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.25264 | acc=0.1091 | tpr=0.6504 | fpr=0.9006 | 4703.3 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.22891 | acc=0.1086 | tpr=0.6397 | fpr=0.9013 | 7260.2 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.23654 | acc=0.1080 | tpr=0.6311 | fpr=0.9016 | 7777.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.23049 | acc=0.1073 | tpr=0.6251 | fpr=0.9021 | 8229.6 samples/s | 32.1 steps/s
[Step= 250] | Loss=5.23492 | acc=0.1079 | tpr=0.6253 | fpr=0.9015 | 7707.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.23120 | acc=0.1081 | tpr=0.6255 | fpr=0.9013 | 7697.5 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.22598 | acc=0.1081 | tpr=0.6230 | fpr=0.9012 | 7964.8 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.21845 | acc=0.1085 | tpr=0.6193 | fpr=0.9008 | 7776.2 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.22343 | acc=0.1086 | tpr=0.6168 | fpr=0.9006 | 8515.8 samples/s | 33.3 steps/s
[Step= 500] | Loss=5.22494 | acc=0.1083 | tpr=0.6145 | fpr=0.9009 | 7763.2 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.22747 | acc=0.1081 | tpr=0.6144 | fpr=0.9011 | 13735.1 samples/s | 53.7 steps/s
Avg test loss: 5.22818, Avg test acc: 0.10798, Avg tpr: 0.61410, Avg fpr: 0.90122, total FA: 125132

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.85513 | acc=0.0995 | tpr=0.5531 | fpr=0.9087 | 4778.0 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.82569 | acc=0.1028 | tpr=0.5565 | fpr=0.9057 | 7013.1 samples/s | 27.4 steps/s
[Step= 150] | Loss=5.82330 | acc=0.1037 | tpr=0.5519 | fpr=0.9046 | 8302.3 samples/s | 32.4 steps/s
[Step= 200] | Loss=5.82370 | acc=0.1031 | tpr=0.5410 | fpr=0.9048 | 7397.4 samples/s | 28.9 steps/s
[Step= 250] | Loss=5.83352 | acc=0.1036 | tpr=0.5415 | fpr=0.9043 | 7948.1 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.83270 | acc=0.1033 | tpr=0.5455 | fpr=0.9048 | 7982.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.82442 | acc=0.1036 | tpr=0.5479 | fpr=0.9045 | 7754.6 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.82024 | acc=0.1039 | tpr=0.5503 | fpr=0.9042 | 8035.2 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.82372 | acc=0.1041 | tpr=0.5487 | fpr=0.9039 | 7832.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.82660 | acc=0.1041 | tpr=0.5485 | fpr=0.9039 | 7933.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.83033 | acc=0.1040 | tpr=0.5491 | fpr=0.9041 | 13902.0 samples/s | 54.3 steps/s
Avg test loss: 5.83255, Avg test acc: 0.10385, Avg tpr: 0.54794, Avg fpr: 0.90423, total FA: 125550

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09029 | acc=0.9824 | tpr=0.9558 | fpr=0.0171 | 4908.6 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09311 | acc=0.9821 | tpr=0.9595 | fpr=0.0174 | 7052.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.09664 | acc=0.9814 | tpr=0.9582 | fpr=0.0182 | 7577.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.09869 | acc=0.9813 | tpr=0.9617 | fpr=0.0184 | 8002.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.09714 | acc=0.9815 | tpr=0.9555 | fpr=0.0180 | 7648.0 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.09951 | acc=0.9811 | tpr=0.9527 | fpr=0.0184 | 8040.2 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.10061 | acc=0.9808 | tpr=0.9537 | fpr=0.0187 | 7808.3 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.10170 | acc=0.9805 | tpr=0.9486 | fpr=0.0189 | 7834.2 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.10383 | acc=0.9802 | tpr=0.9455 | fpr=0.0192 | 7913.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.10303 | acc=0.9802 | tpr=0.9458 | fpr=0.0191 | 7880.4 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.10261 | acc=0.9804 | tpr=0.9443 | fpr=0.0190 | 13771.2 samples/s | 53.8 steps/s
Avg test loss: 0.10249, Avg test acc: 0.98039, Avg tpr: 0.94453, Avg fpr: 0.01896, total FA: 2633

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10042 | acc=0.9826 | tpr=0.9381 | fpr=0.0166 | 4614.5 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.10352 | acc=0.9823 | tpr=0.9318 | fpr=0.0167 | 7169.4 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.10702 | acc=0.9817 | tpr=0.9308 | fpr=0.0173 | 8357.1 samples/s | 32.6 steps/s
[Step= 200] | Loss=0.10939 | acc=0.9815 | tpr=0.9301 | fpr=0.0176 | 7636.9 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.10747 | acc=0.9817 | tpr=0.9293 | fpr=0.0173 | 7544.9 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.11032 | acc=0.9812 | tpr=0.9265 | fpr=0.0178 | 8367.3 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.11101 | acc=0.9810 | tpr=0.9305 | fpr=0.0180 | 8009.4 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.11238 | acc=0.9809 | tpr=0.9256 | fpr=0.0181 | 7615.9 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.11506 | acc=0.9806 | tpr=0.9245 | fpr=0.0184 | 8097.5 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11395 | acc=0.9807 | tpr=0.9269 | fpr=0.0183 | 7809.4 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.11376 | acc=0.9809 | tpr=0.9252 | fpr=0.0181 | 13460.4 samples/s | 52.6 steps/s
Avg test loss: 0.11363, Avg test acc: 0.98089, Avg tpr: 0.92552, Avg fpr: 0.01810, total FA: 2513

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09626 | acc=0.9790 | tpr=0.9469 | fpr=0.0204 | 4741.5 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.09700 | acc=0.9796 | tpr=0.9552 | fpr=0.0199 | 7084.8 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.10127 | acc=0.9791 | tpr=0.9568 | fpr=0.0205 | 7606.9 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.10269 | acc=0.9794 | tpr=0.9596 | fpr=0.0203 | 8253.0 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.10160 | acc=0.9796 | tpr=0.9581 | fpr=0.0200 | 8191.2 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.10404 | acc=0.9792 | tpr=0.9505 | fpr=0.0203 | 7437.3 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.10491 | acc=0.9789 | tpr=0.9493 | fpr=0.0206 | 8329.9 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.10585 | acc=0.9787 | tpr=0.9464 | fpr=0.0207 | 7621.3 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.10719 | acc=0.9786 | tpr=0.9450 | fpr=0.0208 | 7920.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.10636 | acc=0.9786 | tpr=0.9467 | fpr=0.0208 | 7768.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.10602 | acc=0.9787 | tpr=0.9471 | fpr=0.0207 | 14245.6 samples/s | 55.6 steps/s
Avg test loss: 0.10594, Avg test acc: 0.97873, Avg tpr: 0.94731, Avg fpr: 0.02070, total FA: 2874

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10556 | acc=0.9796 | tpr=0.9469 | fpr=0.0198 | 4683.5 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10962 | acc=0.9793 | tpr=0.9424 | fpr=0.0200 | 7182.3 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.11453 | acc=0.9785 | tpr=0.9438 | fpr=0.0209 | 7690.7 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.11580 | acc=0.9786 | tpr=0.9497 | fpr=0.0209 | 8155.8 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.11399 | acc=0.9791 | tpr=0.9520 | fpr=0.0204 | 8023.1 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.11678 | acc=0.9787 | tpr=0.9455 | fpr=0.0207 | 7883.0 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.11770 | acc=0.9785 | tpr=0.9468 | fpr=0.0209 | 7675.5 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.11810 | acc=0.9785 | tpr=0.9437 | fpr=0.0209 | 7912.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.12032 | acc=0.9782 | tpr=0.9401 | fpr=0.0211 | 7915.4 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.11947 | acc=0.9784 | tpr=0.9419 | fpr=0.0209 | 7681.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.11903 | acc=0.9786 | tpr=0.9419 | fpr=0.0207 | 13936.5 samples/s | 54.4 steps/s
Avg test loss: 0.11888, Avg test acc: 0.97862, Avg tpr: 0.94216, Avg fpr: 0.02071, total FA: 2876

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10257 | acc=0.9827 | tpr=0.8982 | fpr=0.0158 | 4697.6 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10646 | acc=0.9821 | tpr=0.9019 | fpr=0.0164 | 7035.1 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.11003 | acc=0.9815 | tpr=0.9092 | fpr=0.0171 | 8038.0 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.11177 | acc=0.9814 | tpr=0.9158 | fpr=0.0174 | 8050.5 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.11038 | acc=0.9818 | tpr=0.9170 | fpr=0.0170 | 7966.1 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.11284 | acc=0.9814 | tpr=0.9135 | fpr=0.0173 | 8100.7 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.11376 | acc=0.9812 | tpr=0.9142 | fpr=0.0176 | 7450.3 samples/s | 29.1 steps/s
[Step= 400] | Loss=0.11476 | acc=0.9810 | tpr=0.9103 | fpr=0.0177 | 7880.3 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11708 | acc=0.9809 | tpr=0.9099 | fpr=0.0179 | 7740.0 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.11626 | acc=0.9810 | tpr=0.9123 | fpr=0.0177 | 8184.2 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.11578 | acc=0.9811 | tpr=0.9109 | fpr=0.0176 | 13402.2 samples/s | 52.4 steps/s
Avg test loss: 0.11561, Avg test acc: 0.98113, Avg tpr: 0.91086, Avg fpr: 0.01759, total FA: 2442

server round 25/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=243.8] | Loss=0.00234 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.775 | L2-Norm(final)=14.161 | 5117.7 samples/s | 80.0 steps/s
[Step=50050 Epoch=244.1] | Loss=0.00309 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.775 | L2-Norm(final)=14.167 | 4782.8 samples/s | 74.7 steps/s
[Step=50100 Epoch=244.3] | Loss=0.00303 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.775 | L2-Norm(final)=14.176 | 4996.4 samples/s | 78.1 steps/s
[Step=50150 Epoch=244.5] | Loss=0.00336 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.774 | L2-Norm(final)=14.184 | 4944.1 samples/s | 77.3 steps/s
[Step=50200 Epoch=244.8] | Loss=0.00321 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.774 | L2-Norm(final)=14.191 | 7781.8 samples/s | 121.6 steps/s
[Step=50250 Epoch=245.0] | Loss=0.00313 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.774 | L2-Norm(final)=14.199 | 2204.6 samples/s | 34.4 steps/s
[Step=50300 Epoch=245.3] | Loss=0.00309 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.774 | L2-Norm(final)=14.207 | 4974.3 samples/s | 77.7 steps/s
[Step=50350 Epoch=245.5] | Loss=0.00298 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.774 | L2-Norm(final)=14.215 | 4943.9 samples/s | 77.2 steps/s
[Step=50400 Epoch=245.8] | Loss=0.00295 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=14.224 | 6923.1 samples/s | 108.2 steps/s
[Step=50450 Epoch=246.0] | Loss=0.00289 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.772 | L2-Norm(final)=14.232 | 2273.7 samples/s | 35.5 steps/s
[Step=50500 Epoch=246.2] | Loss=0.00288 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.771 | L2-Norm(final)=14.240 | 5063.5 samples/s | 79.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=246.3] | Loss=0.00092 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=14.322 | 6144.1 samples/s | 96.0 steps/s
[Step=50550 Epoch=246.5] | Loss=0.00271 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.763 | L2-Norm(final)=14.330 | 3700.9 samples/s | 57.8 steps/s
[Step=50600 Epoch=246.7] | Loss=0.00457 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.766 | L2-Norm(final)=14.337 | 4491.5 samples/s | 70.2 steps/s
[Step=50650 Epoch=247.0] | Loss=0.00463 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.772 | L2-Norm(final)=14.345 | 4402.9 samples/s | 68.8 steps/s
[Step=50700 Epoch=247.2] | Loss=0.00456 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.776 | L2-Norm(final)=14.352 | 6409.6 samples/s | 100.1 steps/s
[Step=50750 Epoch=247.5] | Loss=0.00471 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.780 | L2-Norm(final)=14.359 | 2088.6 samples/s | 32.6 steps/s
[Step=50800 Epoch=247.7] | Loss=0.00459 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.783 | L2-Norm(final)=14.366 | 4465.5 samples/s | 69.8 steps/s
[Step=50850 Epoch=248.0] | Loss=0.00460 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.786 | L2-Norm(final)=14.372 | 4498.1 samples/s | 70.3 steps/s
[Step=50900 Epoch=248.2] | Loss=0.00506 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.789 | L2-Norm(final)=14.377 | 5796.7 samples/s | 90.6 steps/s
[Step=50950 Epoch=248.4] | Loss=0.00502 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.793 | L2-Norm(final)=14.382 | 2164.2 samples/s | 33.8 steps/s
[Step=51000 Epoch=248.7] | Loss=0.00492 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.797 | L2-Norm(final)=14.387 | 4437.1 samples/s | 69.3 steps/s
[Step=51050 Epoch=248.9] | Loss=0.00476 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.799 | L2-Norm(final)=14.393 | 4494.4 samples/s | 70.2 steps/s
[Step=51100 Epoch=249.2] | Loss=0.00477 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.802 | L2-Norm(final)=14.397 | 5324.9 samples/s | 83.2 steps/s
[Step=51150 Epoch=249.4] | Loss=0.00465 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=14.402 | 2265.5 samples/s | 35.4 steps/s
[Step=51200 Epoch=249.7] | Loss=0.00454 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.804 | L2-Norm(final)=14.407 | 4475.6 samples/s | 69.9 steps/s
[Step=51250 Epoch=249.9] | Loss=0.00449 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.411 | 4510.3 samples/s | 70.5 steps/s
[Step=51300 Epoch=250.1] | Loss=0.00436 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.416 | 4934.3 samples/s | 77.1 steps/s
[Step=51350 Epoch=250.4] | Loss=0.00424 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.806 | L2-Norm(final)=14.420 | 2308.1 samples/s | 36.1 steps/s
[Step=51400 Epoch=250.6] | Loss=0.00412 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=14.424 | 4461.6 samples/s | 69.7 steps/s
[Step=51450 Epoch=250.9] | Loss=0.00403 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.804 | L2-Norm(final)=14.428 | 4442.5 samples/s | 69.4 steps/s
[Step=51500 Epoch=251.1] | Loss=0.00402 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=14.432 | 4619.4 samples/s | 72.2 steps/s
[Step=51550 Epoch=251.4] | Loss=0.00394 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.802 | L2-Norm(final)=14.435 | 2440.2 samples/s | 38.1 steps/s
[Step=51600 Epoch=251.6] | Loss=0.00391 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.801 | L2-Norm(final)=14.439 | 4390.0 samples/s | 68.6 steps/s
[Step=51650 Epoch=251.9] | Loss=0.00386 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.799 | L2-Norm(final)=14.442 | 4405.5 samples/s | 68.8 steps/s
[Step=51700 Epoch=252.1] | Loss=0.00381 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.797 | L2-Norm(final)=14.445 | 4441.1 samples/s | 69.4 steps/s
[Step=51750 Epoch=252.3] | Loss=0.00374 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=14.448 | 2415.5 samples/s | 37.7 steps/s
[Step=51800 Epoch=252.6] | Loss=0.00372 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.792 | L2-Norm(final)=14.452 | 4471.6 samples/s | 69.9 steps/s
[Step=51850 Epoch=252.8] | Loss=0.00365 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.790 | L2-Norm(final)=14.455 | 4455.3 samples/s | 69.6 steps/s
[Step=51900 Epoch=253.1] | Loss=0.00361 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.787 | L2-Norm(final)=14.458 | 4487.0 samples/s | 70.1 steps/s
[Step=51950 Epoch=253.3] | Loss=0.00356 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.784 | L2-Norm(final)=14.461 | 2479.4 samples/s | 38.7 steps/s
[Step=52000 Epoch=253.6] | Loss=0.00354 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.781 | L2-Norm(final)=14.464 | 4428.1 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step52000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=244.0] | Loss=0.00103 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.592 | L2-Norm(final)=14.512 | 5665.6 samples/s | 88.5 steps/s
[Step=50050 Epoch=244.2] | Loss=0.00244 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.591 | L2-Norm(final)=14.517 | 4248.1 samples/s | 66.4 steps/s
[Step=50100 Epoch=244.5] | Loss=0.00234 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.590 | L2-Norm(final)=14.524 | 5043.4 samples/s | 78.8 steps/s
[Step=50150 Epoch=244.7] | Loss=0.00227 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.590 | L2-Norm(final)=14.532 | 4962.8 samples/s | 77.5 steps/s
[Step=50200 Epoch=245.0] | Loss=0.00241 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.589 | L2-Norm(final)=14.541 | 7920.7 samples/s | 123.8 steps/s
[Step=50250 Epoch=245.2] | Loss=0.00233 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.588 | L2-Norm(final)=14.550 | 2217.8 samples/s | 34.7 steps/s
[Step=50300 Epoch=245.4] | Loss=0.00234 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.587 | L2-Norm(final)=14.559 | 4840.1 samples/s | 75.6 steps/s
[Step=50350 Epoch=245.7] | Loss=0.00227 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=14.567 | 5071.4 samples/s | 79.2 steps/s
[Step=50400 Epoch=245.9] | Loss=0.00227 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.584 | L2-Norm(final)=14.576 | 7097.4 samples/s | 110.9 steps/s
[Step=50450 Epoch=246.2] | Loss=0.00224 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=14.584 | 2236.0 samples/s | 34.9 steps/s
[Step=50500 Epoch=246.4] | Loss=0.00227 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=14.593 | 5048.8 samples/s | 78.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=246.4] | Loss=0.00311 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.563 | L2-Norm(final)=14.677 | 5430.1 samples/s | 84.8 steps/s
[Step=50550 Epoch=246.7] | Loss=0.00216 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.563 | L2-Norm(final)=14.686 | 4113.3 samples/s | 64.3 steps/s
[Step=50600 Epoch=246.9] | Loss=0.00359 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.564 | L2-Norm(final)=14.691 | 4461.4 samples/s | 69.7 steps/s
[Step=50650 Epoch=247.1] | Loss=0.00403 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.568 | L2-Norm(final)=14.697 | 4525.8 samples/s | 70.7 steps/s
[Step=50700 Epoch=247.4] | Loss=0.00419 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.573 | L2-Norm(final)=14.704 | 6504.1 samples/s | 101.6 steps/s
[Step=50750 Epoch=247.6] | Loss=0.00390 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.577 | L2-Norm(final)=14.712 | 2053.6 samples/s | 32.1 steps/s
[Step=50800 Epoch=247.9] | Loss=0.00382 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=14.719 | 4493.1 samples/s | 70.2 steps/s
[Step=50850 Epoch=248.1] | Loss=0.00386 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=14.726 | 4455.7 samples/s | 69.6 steps/s
[Step=50900 Epoch=248.4] | Loss=0.00385 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=14.733 | 6073.1 samples/s | 94.9 steps/s
[Step=50950 Epoch=248.6] | Loss=0.00392 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.585 | L2-Norm(final)=14.739 | 2142.1 samples/s | 33.5 steps/s
[Step=51000 Epoch=248.9] | Loss=0.00406 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=14.745 | 4452.3 samples/s | 69.6 steps/s
[Step=51050 Epoch=249.1] | Loss=0.00407 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.588 | L2-Norm(final)=14.751 | 4501.8 samples/s | 70.3 steps/s
[Step=51100 Epoch=249.3] | Loss=0.00412 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.590 | L2-Norm(final)=14.757 | 5478.8 samples/s | 85.6 steps/s
[Step=51150 Epoch=249.6] | Loss=0.00420 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.591 | L2-Norm(final)=14.762 | 2150.7 samples/s | 33.6 steps/s
[Step=51200 Epoch=249.8] | Loss=0.00410 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.593 | L2-Norm(final)=14.768 | 4456.8 samples/s | 69.6 steps/s
[Step=51250 Epoch=250.1] | Loss=0.00401 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.593 | L2-Norm(final)=14.773 | 4408.7 samples/s | 68.9 steps/s
[Step=51300 Epoch=250.3] | Loss=0.00398 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.594 | L2-Norm(final)=14.778 | 5228.5 samples/s | 81.7 steps/s
[Step=51350 Epoch=250.6] | Loss=0.00395 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.594 | L2-Norm(final)=14.783 | 2265.2 samples/s | 35.4 steps/s
[Step=51400 Epoch=250.8] | Loss=0.00392 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.594 | L2-Norm(final)=14.788 | 4481.8 samples/s | 70.0 steps/s
[Step=51450 Epoch=251.1] | Loss=0.00385 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.593 | L2-Norm(final)=14.793 | 4414.8 samples/s | 69.0 steps/s
[Step=51500 Epoch=251.3] | Loss=0.00375 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.592 | L2-Norm(final)=14.797 | 4817.2 samples/s | 75.3 steps/s
[Step=51550 Epoch=251.5] | Loss=0.00363 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.591 | L2-Norm(final)=14.802 | 2368.0 samples/s | 37.0 steps/s
[Step=51600 Epoch=251.8] | Loss=0.00361 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.589 | L2-Norm(final)=14.806 | 4434.5 samples/s | 69.3 steps/s
[Step=51650 Epoch=252.0] | Loss=0.00356 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.588 | L2-Norm(final)=14.810 | 4452.0 samples/s | 69.6 steps/s
[Step=51700 Epoch=252.3] | Loss=0.00348 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=14.814 | 4576.0 samples/s | 71.5 steps/s
[Step=51750 Epoch=252.5] | Loss=0.00346 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.583 | L2-Norm(final)=14.818 | 2431.4 samples/s | 38.0 steps/s
[Step=51800 Epoch=252.8] | Loss=0.00338 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=14.822 | 4393.4 samples/s | 68.6 steps/s
[Step=51850 Epoch=253.0] | Loss=0.00332 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=14.826 | 4473.6 samples/s | 69.9 steps/s
[Step=51900 Epoch=253.2] | Loss=0.00327 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.575 | L2-Norm(final)=14.830 | 4483.5 samples/s | 70.1 steps/s
[Step=51950 Epoch=253.5] | Loss=0.00326 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.572 | L2-Norm(final)=14.834 | 2447.1 samples/s | 38.2 steps/s
[Step=52000 Epoch=253.7] | Loss=0.00324 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.569 | L2-Norm(final)=14.837 | 4595.6 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step52000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=243.6] | Loss=0.00062 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=14.836 | 5032.2 samples/s | 78.6 steps/s
[Step=50050 Epoch=243.9] | Loss=0.00311 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.174 | L2-Norm(final)=14.844 | 4867.4 samples/s | 76.1 steps/s
[Step=50100 Epoch=244.1] | Loss=0.00275 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.172 | L2-Norm(final)=14.855 | 4768.8 samples/s | 74.5 steps/s
[Step=50150 Epoch=244.4] | Loss=0.00300 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=14.865 | 4940.3 samples/s | 77.2 steps/s
[Step=50200 Epoch=244.6] | Loss=0.00311 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=14.876 | 7902.7 samples/s | 123.5 steps/s
[Step=50250 Epoch=244.8] | Loss=0.00291 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.174 | L2-Norm(final)=14.886 | 2201.1 samples/s | 34.4 steps/s
[Step=50300 Epoch=245.1] | Loss=0.00283 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.174 | L2-Norm(final)=14.896 | 5116.0 samples/s | 79.9 steps/s
[Step=50350 Epoch=245.3] | Loss=0.00287 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=14.906 | 4961.3 samples/s | 77.5 steps/s
[Step=50400 Epoch=245.6] | Loss=0.00287 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=14.916 | 7001.4 samples/s | 109.4 steps/s
[Step=50450 Epoch=245.8] | Loss=0.00290 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.172 | L2-Norm(final)=14.926 | 2311.4 samples/s | 36.1 steps/s
[Step=50500 Epoch=246.1] | Loss=0.00288 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.172 | L2-Norm(final)=14.936 | 4922.3 samples/s | 76.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=246.1] | Loss=0.00020 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.166 | L2-Norm(final)=15.035 | 5021.1 samples/s | 78.5 steps/s
[Step=50550 Epoch=246.3] | Loss=0.00252 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.168 | L2-Norm(final)=15.046 | 4222.2 samples/s | 66.0 steps/s
[Step=50600 Epoch=246.5] | Loss=0.00366 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.171 | L2-Norm(final)=15.056 | 4555.6 samples/s | 71.2 steps/s
[Step=50650 Epoch=246.8] | Loss=0.00572 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.177 | L2-Norm(final)=15.063 | 4427.8 samples/s | 69.2 steps/s
[Step=50700 Epoch=247.0] | Loss=0.00610 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.188 | L2-Norm(final)=15.071 | 6545.2 samples/s | 102.3 steps/s
[Step=50750 Epoch=247.3] | Loss=0.00707 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.199 | L2-Norm(final)=15.079 | 2095.0 samples/s | 32.7 steps/s
[Step=50800 Epoch=247.5] | Loss=0.00807 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.209 | L2-Norm(final)=15.085 | 4472.7 samples/s | 69.9 steps/s
[Step=50850 Epoch=247.8] | Loss=0.00772 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.219 | L2-Norm(final)=15.092 | 4419.4 samples/s | 69.1 steps/s
[Step=50900 Epoch=248.0] | Loss=0.00735 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.228 | L2-Norm(final)=15.100 | 5801.0 samples/s | 90.6 steps/s
[Step=50950 Epoch=248.3] | Loss=0.00685 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.235 | L2-Norm(final)=15.107 | 2173.4 samples/s | 34.0 steps/s
[Step=51000 Epoch=248.5] | Loss=0.00650 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.241 | L2-Norm(final)=15.114 | 4518.5 samples/s | 70.6 steps/s
[Step=51050 Epoch=248.7] | Loss=0.00621 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.246 | L2-Norm(final)=15.120 | 4463.0 samples/s | 69.7 steps/s
[Step=51100 Epoch=249.0] | Loss=0.00605 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=15.126 | 5395.7 samples/s | 84.3 steps/s
[Step=51150 Epoch=249.2] | Loss=0.00577 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.252 | L2-Norm(final)=15.132 | 2280.1 samples/s | 35.6 steps/s
[Step=51200 Epoch=249.5] | Loss=0.00560 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=15.137 | 4346.7 samples/s | 67.9 steps/s
[Step=51250 Epoch=249.7] | Loss=0.00546 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=15.141 | 4529.3 samples/s | 70.8 steps/s
[Step=51300 Epoch=250.0] | Loss=0.00531 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=15.146 | 4927.4 samples/s | 77.0 steps/s
[Step=51350 Epoch=250.2] | Loss=0.00518 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=15.150 | 2337.8 samples/s | 36.5 steps/s
[Step=51400 Epoch=250.4] | Loss=0.00512 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=15.154 | 4461.8 samples/s | 69.7 steps/s
[Step=51450 Epoch=250.7] | Loss=0.00493 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=15.158 | 4443.8 samples/s | 69.4 steps/s
[Step=51500 Epoch=250.9] | Loss=0.00482 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=15.162 | 4603.6 samples/s | 71.9 steps/s
[Step=51550 Epoch=251.2] | Loss=0.00471 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.253 | L2-Norm(final)=15.166 | 2367.7 samples/s | 37.0 steps/s
[Step=51600 Epoch=251.4] | Loss=0.00463 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.251 | L2-Norm(final)=15.169 | 4458.7 samples/s | 69.7 steps/s
[Step=51650 Epoch=251.7] | Loss=0.00453 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=15.172 | 4507.7 samples/s | 70.4 steps/s
[Step=51700 Epoch=251.9] | Loss=0.00447 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.247 | L2-Norm(final)=15.176 | 4446.1 samples/s | 69.5 steps/s
[Step=51750 Epoch=252.2] | Loss=0.00437 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.245 | L2-Norm(final)=15.179 | 2470.7 samples/s | 38.6 steps/s
[Step=51800 Epoch=252.4] | Loss=0.00428 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.242 | L2-Norm(final)=15.182 | 4460.5 samples/s | 69.7 steps/s
[Step=51850 Epoch=252.6] | Loss=0.00425 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.240 | L2-Norm(final)=15.185 | 4433.9 samples/s | 69.3 steps/s
[Step=51900 Epoch=252.9] | Loss=0.00417 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.237 | L2-Norm(final)=15.188 | 4464.6 samples/s | 69.8 steps/s
[Step=51950 Epoch=253.1] | Loss=0.00411 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.234 | L2-Norm(final)=15.191 | 2448.7 samples/s | 38.3 steps/s
[Step=52000 Epoch=253.4] | Loss=0.00404 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.231 | L2-Norm(final)=15.195 | 4468.8 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step52000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=243.8] | Loss=0.00067 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.706 | 5243.1 samples/s | 81.9 steps/s
[Step=50050 Epoch=244.1] | Loss=0.00220 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.886 | L2-Norm(final)=14.713 | 4480.6 samples/s | 70.0 steps/s
[Step=50100 Epoch=244.3] | Loss=0.00250 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.886 | L2-Norm(final)=14.721 | 5106.9 samples/s | 79.8 steps/s
[Step=50150 Epoch=244.6] | Loss=0.00235 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.887 | L2-Norm(final)=14.730 | 5012.5 samples/s | 78.3 steps/s
[Step=50200 Epoch=244.8] | Loss=0.00250 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.739 | 7827.2 samples/s | 122.3 steps/s
[Step=50250 Epoch=245.0] | Loss=0.00247 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.748 | 2227.8 samples/s | 34.8 steps/s
[Step=50300 Epoch=245.3] | Loss=0.00252 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.758 | 5095.1 samples/s | 79.6 steps/s
[Step=50350 Epoch=245.5] | Loss=0.00251 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.767 | 4881.6 samples/s | 76.3 steps/s
[Step=50400 Epoch=245.8] | Loss=0.00240 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.776 | 6955.3 samples/s | 108.7 steps/s
[Step=50450 Epoch=246.0] | Loss=0.00236 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.785 | 2301.1 samples/s | 36.0 steps/s
[Step=50500 Epoch=246.3] | Loss=0.00233 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.887 | L2-Norm(final)=14.794 | 5054.4 samples/s | 79.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=246.3] | Loss=0.00026 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.882 | L2-Norm(final)=14.884 | 5840.2 samples/s | 91.3 steps/s
[Step=50550 Epoch=246.5] | Loss=0.00326 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=14.892 | 3788.3 samples/s | 59.2 steps/s
[Step=50600 Epoch=246.8] | Loss=0.00332 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=14.899 | 4431.1 samples/s | 69.2 steps/s
[Step=50650 Epoch=247.0] | Loss=0.00445 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.892 | L2-Norm(final)=14.907 | 4507.9 samples/s | 70.4 steps/s
[Step=50700 Epoch=247.2] | Loss=0.00491 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.899 | L2-Norm(final)=14.914 | 6480.5 samples/s | 101.3 steps/s
[Step=50750 Epoch=247.5] | Loss=0.00451 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.904 | L2-Norm(final)=14.921 | 2106.1 samples/s | 32.9 steps/s
[Step=50800 Epoch=247.7] | Loss=0.00472 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.909 | L2-Norm(final)=14.928 | 4478.9 samples/s | 70.0 steps/s
[Step=50850 Epoch=248.0] | Loss=0.00466 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.913 | L2-Norm(final)=14.935 | 4452.1 samples/s | 69.6 steps/s
[Step=50900 Epoch=248.2] | Loss=0.00464 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.917 | L2-Norm(final)=14.942 | 5957.7 samples/s | 93.1 steps/s
[Step=50950 Epoch=248.5] | Loss=0.00438 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.920 | L2-Norm(final)=14.948 | 2171.9 samples/s | 33.9 steps/s
[Step=51000 Epoch=248.7] | Loss=0.00423 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.923 | L2-Norm(final)=14.955 | 4471.5 samples/s | 69.9 steps/s
[Step=51050 Epoch=248.9] | Loss=0.00417 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.925 | L2-Norm(final)=14.961 | 4518.4 samples/s | 70.6 steps/s
[Step=51100 Epoch=249.2] | Loss=0.00412 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.927 | L2-Norm(final)=14.967 | 5346.1 samples/s | 83.5 steps/s
[Step=51150 Epoch=249.4] | Loss=0.00403 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.928 | L2-Norm(final)=14.973 | 2271.1 samples/s | 35.5 steps/s
[Step=51200 Epoch=249.7] | Loss=0.00388 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.929 | L2-Norm(final)=14.978 | 4455.2 samples/s | 69.6 steps/s
[Step=51250 Epoch=249.9] | Loss=0.00378 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.929 | L2-Norm(final)=14.983 | 4423.0 samples/s | 69.1 steps/s
[Step=51300 Epoch=250.2] | Loss=0.00374 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.928 | L2-Norm(final)=14.988 | 4991.2 samples/s | 78.0 steps/s
[Step=51350 Epoch=250.4] | Loss=0.00368 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.928 | L2-Norm(final)=14.993 | 2365.4 samples/s | 37.0 steps/s
[Step=51400 Epoch=250.7] | Loss=0.00356 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.927 | L2-Norm(final)=14.997 | 4377.1 samples/s | 68.4 steps/s
[Step=51450 Epoch=250.9] | Loss=0.00350 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.926 | L2-Norm(final)=15.002 | 4504.0 samples/s | 70.4 steps/s
[Step=51500 Epoch=251.1] | Loss=0.00344 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.925 | L2-Norm(final)=15.006 | 4573.6 samples/s | 71.5 steps/s
[Step=51550 Epoch=251.4] | Loss=0.00339 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.923 | L2-Norm(final)=15.010 | 2417.8 samples/s | 37.8 steps/s
[Step=51600 Epoch=251.6] | Loss=0.00338 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.922 | L2-Norm(final)=15.015 | 4451.3 samples/s | 69.6 steps/s
[Step=51650 Epoch=251.9] | Loss=0.00334 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.920 | L2-Norm(final)=15.019 | 4582.4 samples/s | 71.6 steps/s
[Step=51700 Epoch=252.1] | Loss=0.00336 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.919 | L2-Norm(final)=15.023 | 4384.2 samples/s | 68.5 steps/s
[Step=51750 Epoch=252.4] | Loss=0.00332 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.917 | L2-Norm(final)=15.027 | 2443.9 samples/s | 38.2 steps/s
[Step=51800 Epoch=252.6] | Loss=0.00329 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.914 | L2-Norm(final)=15.031 | 4511.9 samples/s | 70.5 steps/s
[Step=51850 Epoch=252.8] | Loss=0.00324 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.912 | L2-Norm(final)=15.034 | 4455.8 samples/s | 69.6 steps/s
[Step=51900 Epoch=253.1] | Loss=0.00324 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.910 | L2-Norm(final)=15.038 | 4478.5 samples/s | 70.0 steps/s
[Step=51950 Epoch=253.3] | Loss=0.00322 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.907 | L2-Norm(final)=15.042 | 2470.3 samples/s | 38.6 steps/s
[Step=52000 Epoch=253.6] | Loss=0.00322 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.905 | L2-Norm(final)=15.045 | 4458.4 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step52000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=245.2] | Loss=0.00260 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.621 | L2-Norm(final)=14.852 | 5053.1 samples/s | 79.0 steps/s
[Step=50050 Epoch=245.4] | Loss=0.00240 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.620 | L2-Norm(final)=14.860 | 4778.0 samples/s | 74.7 steps/s
[Step=50100 Epoch=245.7] | Loss=0.00237 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=14.872 | 4934.1 samples/s | 77.1 steps/s
[Step=50150 Epoch=245.9] | Loss=0.00229 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.624 | L2-Norm(final)=14.883 | 5028.5 samples/s | 78.6 steps/s
[Step=50200 Epoch=246.2] | Loss=0.00253 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.625 | L2-Norm(final)=14.895 | 7948.1 samples/s | 124.2 steps/s
[Step=50250 Epoch=246.4] | Loss=0.00231 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.624 | L2-Norm(final)=14.906 | 2178.1 samples/s | 34.0 steps/s
[Step=50300 Epoch=246.7] | Loss=0.00222 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=14.917 | 4948.0 samples/s | 77.3 steps/s
[Step=50350 Epoch=246.9] | Loss=0.00224 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.622 | L2-Norm(final)=14.927 | 5073.1 samples/s | 79.3 steps/s
[Step=50400 Epoch=247.2] | Loss=0.00235 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.621 | L2-Norm(final)=14.938 | 7409.0 samples/s | 115.8 steps/s
[Step=50450 Epoch=247.4] | Loss=0.00228 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.620 | L2-Norm(final)=14.949 | 2246.9 samples/s | 35.1 steps/s
[Step=50500 Epoch=247.6] | Loss=0.00228 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.618 | L2-Norm(final)=14.960 | 5042.1 samples/s | 78.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=247.6] | Loss=0.00161 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.607 | L2-Norm(final)=15.071 | 5696.8 samples/s | 89.0 steps/s
[Step=50550 Epoch=247.9] | Loss=0.00365 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.608 | L2-Norm(final)=15.081 | 3857.6 samples/s | 60.3 steps/s
[Step=50600 Epoch=248.1] | Loss=0.00543 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.614 | L2-Norm(final)=15.087 | 4488.1 samples/s | 70.1 steps/s
[Step=50650 Epoch=248.4] | Loss=0.00604 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.626 | L2-Norm(final)=15.097 | 4474.9 samples/s | 69.9 steps/s
[Step=50700 Epoch=248.6] | Loss=0.00641 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.640 | L2-Norm(final)=15.107 | 6697.0 samples/s | 104.6 steps/s
[Step=50750 Epoch=248.9] | Loss=0.00622 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.653 | L2-Norm(final)=15.117 | 2074.4 samples/s | 32.4 steps/s
[Step=50800 Epoch=249.1] | Loss=0.00603 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.664 | L2-Norm(final)=15.126 | 4458.6 samples/s | 69.7 steps/s
[Step=50850 Epoch=249.4] | Loss=0.00577 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.673 | L2-Norm(final)=15.135 | 4485.1 samples/s | 70.1 steps/s
[Step=50900 Epoch=249.6] | Loss=0.00596 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.681 | L2-Norm(final)=15.143 | 6271.0 samples/s | 98.0 steps/s
[Step=50950 Epoch=249.9] | Loss=0.00582 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.687 | L2-Norm(final)=15.150 | 2126.4 samples/s | 33.2 steps/s
[Step=51000 Epoch=250.1] | Loss=0.00562 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.692 | L2-Norm(final)=15.157 | 4477.8 samples/s | 70.0 steps/s
[Step=51050 Epoch=250.3] | Loss=0.00533 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.695 | L2-Norm(final)=15.163 | 4402.3 samples/s | 68.8 steps/s
[Step=51100 Epoch=250.6] | Loss=0.00511 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=15.169 | 5891.8 samples/s | 92.1 steps/s
[Step=51150 Epoch=250.8] | Loss=0.00498 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.700 | L2-Norm(final)=15.175 | 2177.6 samples/s | 34.0 steps/s
[Step=51200 Epoch=251.1] | Loss=0.00498 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.702 | L2-Norm(final)=15.181 | 4464.8 samples/s | 69.8 steps/s
[Step=51250 Epoch=251.3] | Loss=0.00486 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.703 | L2-Norm(final)=15.185 | 4541.5 samples/s | 71.0 steps/s
[Step=51300 Epoch=251.6] | Loss=0.00478 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.704 | L2-Norm(final)=15.190 | 5396.0 samples/s | 84.3 steps/s
[Step=51350 Epoch=251.8] | Loss=0.00458 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.705 | L2-Norm(final)=15.195 | 2216.1 samples/s | 34.6 steps/s
[Step=51400 Epoch=252.1] | Loss=0.00451 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.705 | L2-Norm(final)=15.200 | 4505.7 samples/s | 70.4 steps/s
[Step=51450 Epoch=252.3] | Loss=0.00450 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.706 | L2-Norm(final)=15.204 | 4455.5 samples/s | 69.6 steps/s
[Step=51500 Epoch=252.5] | Loss=0.00438 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.706 | L2-Norm(final)=15.208 | 5211.4 samples/s | 81.4 steps/s
[Step=51550 Epoch=252.8] | Loss=0.00426 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.706 | L2-Norm(final)=15.213 | 2286.2 samples/s | 35.7 steps/s
[Step=51600 Epoch=253.0] | Loss=0.00418 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.705 | L2-Norm(final)=15.217 | 4482.8 samples/s | 70.0 steps/s
[Step=51650 Epoch=253.3] | Loss=0.00410 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.705 | L2-Norm(final)=15.221 | 4504.1 samples/s | 70.4 steps/s
[Step=51700 Epoch=253.5] | Loss=0.00403 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.704 | L2-Norm(final)=15.225 | 4924.3 samples/s | 76.9 steps/s
[Step=51750 Epoch=253.8] | Loss=0.00395 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.702 | L2-Norm(final)=15.228 | 2328.6 samples/s | 36.4 steps/s
[Step=51800 Epoch=254.0] | Loss=0.00386 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.701 | L2-Norm(final)=15.232 | 4482.1 samples/s | 70.0 steps/s
[Step=51850 Epoch=254.3] | Loss=0.00376 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.699 | L2-Norm(final)=15.236 | 4503.8 samples/s | 70.4 steps/s
[Step=51900 Epoch=254.5] | Loss=0.00369 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.697 | L2-Norm(final)=15.239 | 4590.4 samples/s | 71.7 steps/s
[Step=51950 Epoch=254.8] | Loss=0.00363 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.695 | L2-Norm(final)=15.243 | 2374.2 samples/s | 37.1 steps/s
[Step=52000 Epoch=255.0] | Loss=0.00355 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.693 | L2-Norm(final)=15.246 | 4479.8 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step52000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=473.8] | Loss=0.00007 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.098 | L2-Norm(final)=7.738 | 5535.7 samples/s | 86.5 steps/s
[Step=50050 Epoch=474.3] | Loss=0.00008 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=7.754 | 3970.7 samples/s | 62.0 steps/s
[Step=50100 Epoch=474.7] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.111 | L2-Norm(final)=7.767 | 7442.8 samples/s | 116.3 steps/s
[Step=50150 Epoch=475.2] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.117 | L2-Norm(final)=7.779 | 2120.3 samples/s | 33.1 steps/s
[Step=50200 Epoch=475.7] | Loss=0.00004 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=7.789 | 6614.7 samples/s | 103.4 steps/s
[Step=50250 Epoch=476.2] | Loss=0.00004 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=7.799 | 2230.0 samples/s | 34.8 steps/s
[Step=50300 Epoch=476.6] | Loss=0.00004 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.128 | L2-Norm(final)=7.808 | 5785.3 samples/s | 90.4 steps/s
[Step=50350 Epoch=477.1] | Loss=0.00004 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=7.817 | 2319.7 samples/s | 36.2 steps/s
[Step=50400 Epoch=477.6] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.825 | 5341.2 samples/s | 83.5 steps/s
[Step=50450 Epoch=478.1] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=7.833 | 2393.5 samples/s | 37.4 steps/s
[Step=50500 Epoch=478.5] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=7.841 | 4914.4 samples/s | 76.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=478.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.151 | L2-Norm(final)=7.918 | 5683.4 samples/s | 88.8 steps/s
[Step=50550 Epoch=479.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.127 | L2-Norm(final)=7.923 | 3690.7 samples/s | 57.7 steps/s
[Step=50600 Epoch=479.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.091 | L2-Norm(final)=7.927 | 6246.8 samples/s | 97.6 steps/s
[Step=50650 Epoch=480.0] | Loss=0.00223 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=7.926 | 2042.6 samples/s | 31.9 steps/s
[Step=50700 Epoch=480.4] | Loss=0.00215 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=7.922 | 5475.8 samples/s | 85.6 steps/s
[Step=50750 Epoch=480.9] | Loss=0.00182 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=7.921 | 2126.6 samples/s | 33.2 steps/s
[Step=50800 Epoch=481.4] | Loss=0.00152 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.122 | L2-Norm(final)=7.920 | 5009.9 samples/s | 78.3 steps/s
[Step=50850 Epoch=481.8] | Loss=0.00134 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.128 | L2-Norm(final)=7.921 | 2199.3 samples/s | 34.4 steps/s
[Step=50900 Epoch=482.3] | Loss=0.00118 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=7.921 | 4639.5 samples/s | 72.5 steps/s
[Step=50950 Epoch=482.8] | Loss=0.00105 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=7.921 | 2277.1 samples/s | 35.6 steps/s
[Step=51000 Epoch=483.3] | Loss=0.00094 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=7.922 | 4257.7 samples/s | 66.5 steps/s
[Step=51050 Epoch=483.7] | Loss=0.00086 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=7.922 | 2340.5 samples/s | 36.6 steps/s
[Step=51100 Epoch=484.2] | Loss=0.00079 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=7.923 | 4197.5 samples/s | 65.6 steps/s
[Step=51150 Epoch=484.7] | Loss=0.00073 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=7.923 | 2389.9 samples/s | 37.3 steps/s
[Step=51200 Epoch=485.2] | Loss=0.00068 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=7.924 | 4218.8 samples/s | 65.9 steps/s
[Step=51250 Epoch=485.6] | Loss=0.00063 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=7.924 | 2412.3 samples/s | 37.7 steps/s
[Step=51300 Epoch=486.1] | Loss=0.00059 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=7.924 | 4207.8 samples/s | 65.7 steps/s
[Step=51350 Epoch=486.6] | Loss=0.00056 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=7.925 | 2473.3 samples/s | 38.6 steps/s
[Step=51400 Epoch=487.1] | Loss=0.00053 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=7.925 | 4049.1 samples/s | 63.3 steps/s
[Step=51450 Epoch=487.5] | Loss=0.00050 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=7.925 | 6239.2 samples/s | 97.5 steps/s
[Step=51500 Epoch=488.0] | Loss=0.00048 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=7.926 | 1990.7 samples/s | 31.1 steps/s
[Step=51550 Epoch=488.5] | Loss=0.00045 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=7.926 | 5814.8 samples/s | 90.9 steps/s
[Step=51600 Epoch=489.0] | Loss=0.00043 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=7.926 | 2081.4 samples/s | 32.5 steps/s
[Step=51650 Epoch=489.4] | Loss=0.00042 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=7.927 | 5226.5 samples/s | 81.7 steps/s
[Step=51700 Epoch=489.9] | Loss=0.00040 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=7.927 | 2145.7 samples/s | 33.5 steps/s
[Step=51750 Epoch=490.4] | Loss=0.00038 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.140 | L2-Norm(final)=7.927 | 4741.5 samples/s | 74.1 steps/s
[Step=51800 Epoch=490.8] | Loss=0.00037 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.140 | L2-Norm(final)=7.928 | 2226.4 samples/s | 34.8 steps/s
[Step=51850 Epoch=491.3] | Loss=0.00036 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=7.928 | 4477.4 samples/s | 70.0 steps/s
[Step=51900 Epoch=491.8] | Loss=0.00034 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.138 | L2-Norm(final)=7.928 | 2299.4 samples/s | 35.9 steps/s
[Step=51950 Epoch=492.3] | Loss=0.00033 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=7.929 | 4253.9 samples/s | 66.5 steps/s
[Step=52000 Epoch=492.7] | Loss=0.00032 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=7.929 | 2400.0 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step52000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=475.6] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.179 | L2-Norm(final)=8.700 | 5408.2 samples/s | 84.5 steps/s
[Step=50050 Epoch=476.1] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=8.704 | 4036.8 samples/s | 63.1 steps/s
[Step=50100 Epoch=476.6] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.182 | L2-Norm(final)=8.709 | 7574.5 samples/s | 118.4 steps/s
[Step=50150 Epoch=477.1] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=8.714 | 2198.5 samples/s | 34.4 steps/s
[Step=50200 Epoch=477.5] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.186 | L2-Norm(final)=8.719 | 6248.4 samples/s | 97.6 steps/s
[Step=50250 Epoch=478.0] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=8.724 | 2240.7 samples/s | 35.0 steps/s
[Step=50300 Epoch=478.5] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.188 | L2-Norm(final)=8.729 | 5846.1 samples/s | 91.3 steps/s
[Step=50350 Epoch=479.0] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.189 | L2-Norm(final)=8.734 | 2309.0 samples/s | 36.1 steps/s
[Step=50400 Epoch=479.4] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.190 | L2-Norm(final)=8.738 | 5246.5 samples/s | 82.0 steps/s
[Step=50450 Epoch=479.9] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.190 | L2-Norm(final)=8.743 | 2389.4 samples/s | 37.3 steps/s
[Step=50500 Epoch=480.4] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.191 | L2-Norm(final)=8.747 | 4960.2 samples/s | 77.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=480.4] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.195 | L2-Norm(final)=8.791 | 5283.1 samples/s | 82.5 steps/s
[Step=50550 Epoch=480.9] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.193 | L2-Norm(final)=8.796 | 3785.4 samples/s | 59.1 steps/s
[Step=50600 Epoch=481.3] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.190 | L2-Norm(final)=8.800 | 6259.7 samples/s | 97.8 steps/s
[Step=50650 Epoch=481.8] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=8.803 | 2010.9 samples/s | 31.4 steps/s
[Step=50700 Epoch=482.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.178 | L2-Norm(final)=8.806 | 5691.5 samples/s | 88.9 steps/s
[Step=50750 Epoch=482.8] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.171 | L2-Norm(final)=8.808 | 2117.6 samples/s | 33.1 steps/s
[Step=50800 Epoch=483.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.164 | L2-Norm(final)=8.810 | 5149.2 samples/s | 80.5 steps/s
[Step=50850 Epoch=483.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.157 | L2-Norm(final)=8.812 | 2200.2 samples/s | 34.4 steps/s
[Step=50900 Epoch=484.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.150 | L2-Norm(final)=8.813 | 4698.2 samples/s | 73.4 steps/s
[Step=50950 Epoch=484.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.815 | 2279.9 samples/s | 35.6 steps/s
[Step=51000 Epoch=485.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=8.817 | 4317.0 samples/s | 67.5 steps/s
[Step=51050 Epoch=485.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.128 | L2-Norm(final)=8.818 | 2418.8 samples/s | 37.8 steps/s
[Step=51100 Epoch=486.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=8.819 | 4206.5 samples/s | 65.7 steps/s
[Step=51150 Epoch=486.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=8.821 | 2414.5 samples/s | 37.7 steps/s
[Step=51200 Epoch=487.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.105 | L2-Norm(final)=8.822 | 4207.6 samples/s | 65.7 steps/s
[Step=51250 Epoch=487.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.098 | L2-Norm(final)=8.824 | 2370.8 samples/s | 37.0 steps/s
[Step=51300 Epoch=488.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.090 | L2-Norm(final)=8.825 | 4302.0 samples/s | 67.2 steps/s
[Step=51350 Epoch=488.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=8.826 | 2492.9 samples/s | 39.0 steps/s
[Step=51400 Epoch=488.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=8.828 | 3833.8 samples/s | 59.9 steps/s
[Step=51450 Epoch=489.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=8.829 | 6621.2 samples/s | 103.5 steps/s
[Step=51500 Epoch=489.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=8.830 | 2002.9 samples/s | 31.3 steps/s
[Step=51550 Epoch=490.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.049 | L2-Norm(final)=8.832 | 5882.7 samples/s | 91.9 steps/s
[Step=51600 Epoch=490.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.041 | L2-Norm(final)=8.833 | 2065.6 samples/s | 32.3 steps/s
[Step=51650 Epoch=491.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.032 | L2-Norm(final)=8.834 | 5360.6 samples/s | 83.8 steps/s
[Step=51700 Epoch=491.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.024 | L2-Norm(final)=8.836 | 2187.0 samples/s | 34.2 steps/s
[Step=51750 Epoch=492.3] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.015 | L2-Norm(final)=8.837 | 4792.4 samples/s | 74.9 steps/s
[Step=51800 Epoch=492.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.006 | L2-Norm(final)=8.839 | 1687.3 samples/s | 26.4 steps/s
[Step=51850 Epoch=493.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.997 | L2-Norm(final)=8.840 | 4436.1 samples/s | 69.3 steps/s
[Step=51900 Epoch=493.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=8.841 | 2295.1 samples/s | 35.9 steps/s
[Step=51950 Epoch=494.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.980 | L2-Norm(final)=8.843 | 4315.5 samples/s | 67.4 steps/s
[Step=52000 Epoch=494.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.970 | L2-Norm(final)=8.844 | 2398.0 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step52000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=477.5] | Loss=0.00014 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=8.321 | 5259.5 samples/s | 82.2 steps/s
[Step=50050 Epoch=477.9] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.322 | 4093.0 samples/s | 64.0 steps/s
[Step=50100 Epoch=478.4] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.322 | 7557.1 samples/s | 118.1 steps/s
[Step=50150 Epoch=478.9] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.323 | 2138.1 samples/s | 33.4 steps/s
[Step=50200 Epoch=479.4] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.324 | 6649.5 samples/s | 103.9 steps/s
[Step=50250 Epoch=479.9] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.324 | 2198.7 samples/s | 34.4 steps/s
[Step=50300 Epoch=480.3] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.325 | 6102.3 samples/s | 95.3 steps/s
[Step=50350 Epoch=480.8] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.326 | 2284.4 samples/s | 35.7 steps/s
[Step=50400 Epoch=481.3] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.327 | 5554.9 samples/s | 86.8 steps/s
[Step=50450 Epoch=481.8] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.328 | 2343.4 samples/s | 36.6 steps/s
[Step=50500 Epoch=482.2] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.330 | 5205.1 samples/s | 81.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=482.3] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=8.344 | 5241.4 samples/s | 81.9 steps/s
[Step=50550 Epoch=482.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=8.346 | 3814.3 samples/s | 59.6 steps/s
[Step=50600 Epoch=483.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=8.348 | 6335.5 samples/s | 99.0 steps/s
[Step=50650 Epoch=483.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.213 | L2-Norm(final)=8.349 | 1998.2 samples/s | 31.2 steps/s
[Step=50700 Epoch=484.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.211 | L2-Norm(final)=8.350 | 5854.3 samples/s | 91.5 steps/s
[Step=50750 Epoch=484.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.208 | L2-Norm(final)=8.351 | 2056.5 samples/s | 32.1 steps/s
[Step=50800 Epoch=485.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.206 | L2-Norm(final)=8.352 | 5406.9 samples/s | 84.5 steps/s
[Step=50850 Epoch=485.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.204 | L2-Norm(final)=8.353 | 2130.1 samples/s | 33.3 steps/s
[Step=50900 Epoch=486.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.201 | L2-Norm(final)=8.354 | 4951.0 samples/s | 77.4 steps/s
[Step=50950 Epoch=486.5] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.198 | L2-Norm(final)=8.355 | 2191.4 samples/s | 34.2 steps/s
[Step=51000 Epoch=487.0] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.196 | L2-Norm(final)=8.355 | 4676.2 samples/s | 73.1 steps/s
[Step=51050 Epoch=487.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.193 | L2-Norm(final)=8.356 | 2302.6 samples/s | 36.0 steps/s
[Step=51100 Epoch=488.0] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.190 | L2-Norm(final)=8.356 | 4312.7 samples/s | 67.4 steps/s
[Step=51150 Epoch=488.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=8.357 | 2347.1 samples/s | 36.7 steps/s
[Step=51200 Epoch=488.9] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.185 | L2-Norm(final)=8.358 | 4235.8 samples/s | 66.2 steps/s
[Step=51250 Epoch=489.4] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.182 | L2-Norm(final)=8.358 | 2402.6 samples/s | 37.5 steps/s
[Step=51300 Epoch=489.9] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.179 | L2-Norm(final)=8.359 | 4234.2 samples/s | 66.2 steps/s
[Step=51350 Epoch=490.4] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.176 | L2-Norm(final)=8.359 | 2393.9 samples/s | 37.4 steps/s
[Step=51400 Epoch=490.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.173 | L2-Norm(final)=8.360 | 4275.7 samples/s | 66.8 steps/s
[Step=51450 Epoch=491.3] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.170 | L2-Norm(final)=8.360 | 2394.9 samples/s | 37.4 steps/s
[Step=51500 Epoch=491.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.166 | L2-Norm(final)=8.361 | 4238.9 samples/s | 66.2 steps/s
[Step=51550 Epoch=492.3] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.163 | L2-Norm(final)=8.361 | 6953.0 samples/s | 108.6 steps/s
[Step=51600 Epoch=492.7] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.160 | L2-Norm(final)=8.362 | 1953.5 samples/s | 30.5 steps/s
[Step=51650 Epoch=493.2] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.157 | L2-Norm(final)=8.362 | 6360.1 samples/s | 99.4 steps/s
[Step=51700 Epoch=493.7] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.154 | L2-Norm(final)=8.363 | 2006.8 samples/s | 31.4 steps/s
[Step=51750 Epoch=494.2] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.150 | L2-Norm(final)=8.363 | 5811.8 samples/s | 90.8 steps/s
[Step=51800 Epoch=494.7] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.147 | L2-Norm(final)=8.364 | 2077.2 samples/s | 32.5 steps/s
[Step=51850 Epoch=495.1] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.364 | 5356.2 samples/s | 83.7 steps/s
[Step=51900 Epoch=495.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.140 | L2-Norm(final)=8.365 | 2143.0 samples/s | 33.5 steps/s
[Step=51950 Epoch=496.1] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=8.365 | 4938.7 samples/s | 77.2 steps/s
[Step=52000 Epoch=496.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=8.366 | 2212.2 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step52000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=471.2] | Loss=0.00010 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.274 | L2-Norm(final)=8.101 | 5945.7 samples/s | 92.9 steps/s
[Step=50050 Epoch=471.6] | Loss=0.00006 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.275 | L2-Norm(final)=8.103 | 3783.8 samples/s | 59.1 steps/s
[Step=50100 Epoch=472.1] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.278 | L2-Norm(final)=8.107 | 7278.0 samples/s | 113.7 steps/s
[Step=50150 Epoch=472.6] | Loss=0.00006 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=8.111 | 2132.8 samples/s | 33.3 steps/s
[Step=50200 Epoch=473.0] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=8.115 | 6160.5 samples/s | 96.3 steps/s
[Step=50250 Epoch=473.5] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.287 | L2-Norm(final)=8.119 | 2217.5 samples/s | 34.6 steps/s
[Step=50300 Epoch=474.0] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.289 | L2-Norm(final)=8.123 | 5419.8 samples/s | 84.7 steps/s
[Step=50350 Epoch=474.4] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.290 | L2-Norm(final)=8.126 | 2295.7 samples/s | 35.9 steps/s
[Step=50400 Epoch=474.9] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.291 | L2-Norm(final)=8.129 | 5099.3 samples/s | 79.7 steps/s
[Step=50450 Epoch=475.4] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.292 | L2-Norm(final)=8.132 | 2402.3 samples/s | 37.5 steps/s
[Step=50500 Epoch=475.9] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.293 | L2-Norm(final)=8.136 | 4686.4 samples/s | 73.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=475.9] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.301 | L2-Norm(final)=8.166 | 5256.7 samples/s | 82.1 steps/s
[Step=50550 Epoch=476.3] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.299 | L2-Norm(final)=8.168 | 3707.1 samples/s | 57.9 steps/s
[Step=50600 Epoch=476.8] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.171 | 6138.2 samples/s | 95.9 steps/s
[Step=50650 Epoch=477.3] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.293 | L2-Norm(final)=8.173 | 2009.0 samples/s | 31.4 steps/s
[Step=50700 Epoch=477.7] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.289 | L2-Norm(final)=8.175 | 5369.4 samples/s | 83.9 steps/s
[Step=50750 Epoch=478.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=8.177 | 2094.4 samples/s | 32.7 steps/s
[Step=50800 Epoch=478.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.279 | L2-Norm(final)=8.178 | 4913.0 samples/s | 76.8 steps/s
[Step=50850 Epoch=479.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.274 | L2-Norm(final)=8.179 | 2207.4 samples/s | 34.5 steps/s
[Step=50900 Epoch=479.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.268 | L2-Norm(final)=8.180 | 4414.3 samples/s | 69.0 steps/s
[Step=50950 Epoch=480.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.263 | L2-Norm(final)=8.181 | 2269.5 samples/s | 35.5 steps/s
[Step=51000 Epoch=480.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.257 | L2-Norm(final)=8.182 | 4252.0 samples/s | 66.4 steps/s
[Step=51050 Epoch=481.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.251 | L2-Norm(final)=8.183 | 2378.9 samples/s | 37.2 steps/s
[Step=51100 Epoch=481.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.245 | L2-Norm(final)=8.184 | 4179.2 samples/s | 65.3 steps/s
[Step=51150 Epoch=482.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.239 | L2-Norm(final)=8.185 | 2368.7 samples/s | 37.0 steps/s
[Step=51200 Epoch=482.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.232 | L2-Norm(final)=8.185 | 4207.6 samples/s | 65.7 steps/s
[Step=51250 Epoch=482.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.226 | L2-Norm(final)=8.186 | 2589.4 samples/s | 40.5 steps/s
[Step=51300 Epoch=483.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.220 | L2-Norm(final)=8.187 | 3680.4 samples/s | 57.5 steps/s
[Step=51350 Epoch=483.9] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.213 | L2-Norm(final)=8.188 | 6107.8 samples/s | 95.4 steps/s
[Step=51400 Epoch=484.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.207 | L2-Norm(final)=8.188 | 1995.4 samples/s | 31.2 steps/s
[Step=51450 Epoch=484.8] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.200 | L2-Norm(final)=8.189 | 5493.2 samples/s | 85.8 steps/s
[Step=51500 Epoch=485.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.193 | L2-Norm(final)=8.190 | 2106.6 samples/s | 32.9 steps/s
[Step=51550 Epoch=485.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=8.191 | 4878.4 samples/s | 76.2 steps/s
[Step=51600 Epoch=486.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=8.191 | 2156.1 samples/s | 33.7 steps/s
[Step=51650 Epoch=486.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.173 | L2-Norm(final)=8.192 | 4534.8 samples/s | 70.9 steps/s
[Step=51700 Epoch=487.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.166 | L2-Norm(final)=8.193 | 2274.3 samples/s | 35.5 steps/s
[Step=51750 Epoch=487.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.159 | L2-Norm(final)=8.193 | 4142.2 samples/s | 64.7 steps/s
[Step=51800 Epoch=488.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.151 | L2-Norm(final)=8.194 | 2355.7 samples/s | 36.8 steps/s
[Step=51850 Epoch=488.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=8.195 | 4247.6 samples/s | 66.4 steps/s
[Step=51900 Epoch=489.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.196 | 2344.3 samples/s | 36.6 steps/s
[Step=51950 Epoch=489.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.129 | L2-Norm(final)=8.196 | 4220.2 samples/s | 65.9 steps/s
[Step=52000 Epoch=490.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=8.197 | 2481.3 samples/s | 38.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step52000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=476.6] | Loss=0.00009 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.291 | L2-Norm(final)=8.899 | 5236.8 samples/s | 81.8 steps/s
[Step=50050 Epoch=477.0] | Loss=0.00010 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.294 | L2-Norm(final)=8.900 | 4083.2 samples/s | 63.8 steps/s
[Step=50100 Epoch=477.5] | Loss=0.00008 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.295 | L2-Norm(final)=8.901 | 7464.4 samples/s | 116.6 steps/s
[Step=50150 Epoch=478.0] | Loss=0.00006 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.295 | L2-Norm(final)=8.903 | 2116.0 samples/s | 33.1 steps/s
[Step=50200 Epoch=478.5] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.905 | 6746.1 samples/s | 105.4 steps/s
[Step=50250 Epoch=478.9] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.906 | 2162.8 samples/s | 33.8 steps/s
[Step=50300 Epoch=479.4] | Loss=0.00005 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.908 | 6100.6 samples/s | 95.3 steps/s
[Step=50350 Epoch=479.9] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.909 | 2205.0 samples/s | 34.5 steps/s
[Step=50400 Epoch=480.4] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.911 | 5665.2 samples/s | 88.5 steps/s
[Step=50450 Epoch=480.8] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=8.912 | 2334.8 samples/s | 36.5 steps/s
[Step=50500 Epoch=481.3] | Loss=0.00004 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=8.914 | 5157.8 samples/s | 80.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=481.3] | Loss=0.00003 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=8.929 | 5701.8 samples/s | 89.1 steps/s
[Step=50550 Epoch=481.8] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=8.930 | 3629.9 samples/s | 56.7 steps/s
[Step=50600 Epoch=482.3] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=8.932 | 6108.0 samples/s | 95.4 steps/s
[Step=50650 Epoch=482.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.295 | L2-Norm(final)=8.932 | 1994.7 samples/s | 31.2 steps/s
[Step=50700 Epoch=483.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.293 | L2-Norm(final)=8.933 | 5645.2 samples/s | 88.2 steps/s
[Step=50750 Epoch=483.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.291 | L2-Norm(final)=8.934 | 2041.4 samples/s | 31.9 steps/s
[Step=50800 Epoch=484.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.288 | L2-Norm(final)=8.934 | 5325.5 samples/s | 83.2 steps/s
[Step=50850 Epoch=484.6] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.286 | L2-Norm(final)=8.935 | 2138.0 samples/s | 33.4 steps/s
[Step=50900 Epoch=485.1] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=8.935 | 4795.3 samples/s | 74.9 steps/s
[Step=50950 Epoch=485.6] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.281 | L2-Norm(final)=8.936 | 2194.0 samples/s | 34.3 steps/s
[Step=51000 Epoch=486.1] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.278 | L2-Norm(final)=8.936 | 4553.6 samples/s | 71.2 steps/s
[Step=51050 Epoch=486.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.276 | L2-Norm(final)=8.937 | 2250.8 samples/s | 35.2 steps/s
[Step=51100 Epoch=487.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.273 | L2-Norm(final)=8.937 | 4307.7 samples/s | 67.3 steps/s
[Step=51150 Epoch=487.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.270 | L2-Norm(final)=8.938 | 2332.4 samples/s | 36.4 steps/s
[Step=51200 Epoch=488.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.267 | L2-Norm(final)=8.938 | 4193.2 samples/s | 65.5 steps/s
[Step=51250 Epoch=488.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.264 | L2-Norm(final)=8.938 | 2373.5 samples/s | 37.1 steps/s
[Step=51300 Epoch=488.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.261 | L2-Norm(final)=8.939 | 4252.7 samples/s | 66.4 steps/s
[Step=51350 Epoch=489.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.258 | L2-Norm(final)=8.939 | 2346.8 samples/s | 36.7 steps/s
[Step=51400 Epoch=489.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.255 | L2-Norm(final)=8.940 | 4215.8 samples/s | 65.9 steps/s
[Step=51450 Epoch=490.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.251 | L2-Norm(final)=8.940 | 2373.9 samples/s | 37.1 steps/s
[Step=51500 Epoch=490.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.248 | L2-Norm(final)=8.940 | 4072.7 samples/s | 63.6 steps/s
[Step=51550 Epoch=491.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.245 | L2-Norm(final)=8.941 | 6992.8 samples/s | 109.3 steps/s
[Step=51600 Epoch=491.8] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.241 | L2-Norm(final)=8.941 | 1920.7 samples/s | 30.0 steps/s
[Step=51650 Epoch=492.3] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.238 | L2-Norm(final)=8.942 | 6213.5 samples/s | 97.1 steps/s
[Step=51700 Epoch=492.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.234 | L2-Norm(final)=8.942 | 1983.8 samples/s | 31.0 steps/s
[Step=51750 Epoch=493.2] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.231 | L2-Norm(final)=8.942 | 5774.1 samples/s | 90.2 steps/s
[Step=51800 Epoch=493.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.227 | L2-Norm(final)=8.943 | 2049.7 samples/s | 32.0 steps/s
[Step=51850 Epoch=494.2] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.223 | L2-Norm(final)=8.943 | 5277.2 samples/s | 82.5 steps/s
[Step=51900 Epoch=494.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.220 | L2-Norm(final)=8.944 | 2103.5 samples/s | 32.9 steps/s
[Step=51950 Epoch=495.1] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=8.944 | 4844.8 samples/s | 75.7 steps/s
[Step=52000 Epoch=495.6] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.212 | L2-Norm(final)=8.945 | 2170.8 samples/s | 33.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11267 | acc=0.9575 | tpr=0.9679 | fpr=0.0652 | 4462.4 samples/s | 17.4 steps/s
Avg test loss: 0.11757, Avg test acc: 0.95673, Avg tpr: 0.96783, Avg fpr: 0.06768, total FA: 528

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10699 | acc=0.9577 | tpr=0.9716 | fpr=0.0723 | 4765.5 samples/s | 18.6 steps/s
Avg test loss: 0.10922, Avg test acc: 0.95745, Avg tpr: 0.97062, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11413 | acc=0.9593 | tpr=0.9744 | fpr=0.0736 | 4709.8 samples/s | 18.4 steps/s
Avg test loss: 0.11700, Avg test acc: 0.95765, Avg tpr: 0.97290, Avg fpr: 0.07589, total FA: 592

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10270 | acc=0.9604 | tpr=0.9711 | fpr=0.0629 | 4694.5 samples/s | 18.3 steps/s
Avg test loss: 0.10884, Avg test acc: 0.95937, Avg tpr: 0.97214, Avg fpr: 0.06871, total FA: 536

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10951 | acc=0.9598 | tpr=0.9688 | fpr=0.0600 | 4896.6 samples/s | 19.1 steps/s
Avg test loss: 0.11899, Avg test acc: 0.95801, Avg tpr: 0.96788, Avg fpr: 0.06371, total FA: 497

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.82907 | acc=0.3018 | tpr=0.0113 | fpr=0.0674 | 4830.6 samples/s | 18.9 steps/s
Avg test loss: 4.83853, Avg test acc: 0.30034, Avg tpr: 0.01236, Avg fpr: 0.06627, total FA: 517

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.74767 | acc=0.2944 | tpr=0.0081 | fpr=0.0840 | 5088.9 samples/s | 19.9 steps/s
Avg test loss: 4.76373, Avg test acc: 0.29097, Avg tpr: 0.00833, Avg fpr: 0.08742, total FA: 682

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.50686 | acc=0.2751 | tpr=0.0188 | fpr=0.1685 | 4801.8 samples/s | 18.8 steps/s
Avg test loss: 5.50402, Avg test acc: 0.27338, Avg tpr: 0.01929, Avg fpr: 0.16780, total FA: 1309

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.56535 | acc=0.2888 | tpr=0.0215 | fpr=0.1306 | 4537.7 samples/s | 17.7 steps/s
Avg test loss: 5.55625, Avg test acc: 0.28732, Avg tpr: 0.02238, Avg fpr: 0.12998, total FA: 1014

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.18830 | acc=0.2942 | tpr=0.0170 | fpr=0.1038 | 4568.7 samples/s | 17.8 steps/s
Avg test loss: 5.20063, Avg test acc: 0.29373, Avg tpr: 0.01813, Avg fpr: 0.10012, total FA: 781

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.62909 | acc=0.1067 | tpr=0.5619 | fpr=0.9015 | 4880.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.60502 | acc=0.1088 | tpr=0.5373 | fpr=0.8992 | 6903.9 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.61664 | acc=0.1095 | tpr=0.5403 | fpr=0.8984 | 7858.7 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.61379 | acc=0.1094 | tpr=0.5301 | fpr=0.8983 | 7499.3 samples/s | 29.3 steps/s
[Step= 250] | Loss=5.61868 | acc=0.1101 | tpr=0.5319 | fpr=0.8976 | 7908.2 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.61524 | acc=0.1104 | tpr=0.5404 | fpr=0.8975 | 7857.9 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.61158 | acc=0.1107 | tpr=0.5385 | fpr=0.8970 | 7826.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.60681 | acc=0.1109 | tpr=0.5367 | fpr=0.8968 | 8160.5 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.61272 | acc=0.1108 | tpr=0.5341 | fpr=0.8969 | 7531.3 samples/s | 29.4 steps/s
[Step= 500] | Loss=5.61778 | acc=0.1107 | tpr=0.5286 | fpr=0.8969 | 7783.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=5.62110 | acc=0.1106 | tpr=0.5269 | fpr=0.8970 | 14052.8 samples/s | 54.9 steps/s
Avg test loss: 5.62284, Avg test acc: 0.11049, Avg tpr: 0.52694, Avg fpr: 0.89708, total FA: 124558

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.42282 | acc=0.0877 | tpr=0.5177 | fpr=0.9200 | 4907.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.41169 | acc=0.0885 | tpr=0.5203 | fpr=0.9196 | 6817.8 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.41082 | acc=0.0890 | tpr=0.5317 | fpr=0.9191 | 7810.9 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.40657 | acc=0.0885 | tpr=0.5257 | fpr=0.9195 | 7693.3 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.41735 | acc=0.0882 | tpr=0.5205 | fpr=0.9197 | 7893.1 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.41183 | acc=0.0878 | tpr=0.5265 | fpr=0.9202 | 7923.9 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.40673 | acc=0.0882 | tpr=0.5247 | fpr=0.9197 | 7751.6 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.40280 | acc=0.0885 | tpr=0.5213 | fpr=0.9193 | 7687.4 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.40597 | acc=0.0882 | tpr=0.5200 | fpr=0.9196 | 7929.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.40910 | acc=0.0878 | tpr=0.5172 | fpr=0.9199 | 7921.7 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.41126 | acc=0.0876 | tpr=0.5137 | fpr=0.9201 | 13809.4 samples/s | 53.9 steps/s
Avg test loss: 5.41328, Avg test acc: 0.08754, Avg tpr: 0.51307, Avg fpr: 0.92019, total FA: 127767

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.29197 | acc=0.0847 | tpr=0.4513 | fpr=0.9219 | 4874.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.25536 | acc=0.0866 | tpr=0.4499 | fpr=0.9202 | 6910.4 samples/s | 27.0 steps/s
[Step= 150] | Loss=6.26541 | acc=0.0873 | tpr=0.4510 | fpr=0.9194 | 7627.7 samples/s | 29.8 steps/s
[Step= 200] | Loss=6.26327 | acc=0.0875 | tpr=0.4426 | fpr=0.9190 | 8030.4 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.26325 | acc=0.0877 | tpr=0.4445 | fpr=0.9188 | 7565.4 samples/s | 29.6 steps/s
[Step= 300] | Loss=6.26148 | acc=0.0875 | tpr=0.4487 | fpr=0.9191 | 8044.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.25508 | acc=0.0878 | tpr=0.4477 | fpr=0.9188 | 7667.7 samples/s | 30.0 steps/s
[Step= 400] | Loss=6.24854 | acc=0.0885 | tpr=0.4486 | fpr=0.9180 | 7856.6 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.25062 | acc=0.0886 | tpr=0.4430 | fpr=0.9179 | 7678.8 samples/s | 30.0 steps/s
[Step= 500] | Loss=6.25369 | acc=0.0884 | tpr=0.4410 | fpr=0.9179 | 7954.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.25633 | acc=0.0884 | tpr=0.4405 | fpr=0.9180 | 13899.5 samples/s | 54.3 steps/s
Avg test loss: 6.25843, Avg test acc: 0.08827, Avg tpr: 0.44097, Avg fpr: 0.91814, total FA: 127482

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.42804 | acc=0.1084 | tpr=0.5265 | fpr=0.8992 | 4952.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.41486 | acc=0.1102 | tpr=0.5245 | fpr=0.8976 | 7185.9 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.42217 | acc=0.1098 | tpr=0.5331 | fpr=0.8979 | 7390.9 samples/s | 28.9 steps/s
[Step= 200] | Loss=5.41275 | acc=0.1091 | tpr=0.5311 | fpr=0.8986 | 7742.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.41887 | acc=0.1094 | tpr=0.5275 | fpr=0.8983 | 7678.7 samples/s | 30.0 steps/s
[Step= 300] | Loss=5.41492 | acc=0.1095 | tpr=0.5295 | fpr=0.8982 | 8148.5 samples/s | 31.8 steps/s
[Step= 350] | Loss=5.40701 | acc=0.1096 | tpr=0.5254 | fpr=0.8980 | 7687.0 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.39839 | acc=0.1099 | tpr=0.5213 | fpr=0.8976 | 7922.7 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.40245 | acc=0.1099 | tpr=0.5229 | fpr=0.8976 | 7778.5 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.40488 | acc=0.1095 | tpr=0.5198 | fpr=0.8979 | 7807.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.40828 | acc=0.1092 | tpr=0.5169 | fpr=0.8982 | 13776.4 samples/s | 53.8 steps/s
Avg test loss: 5.40878, Avg test acc: 0.10907, Avg tpr: 0.51664, Avg fpr: 0.89834, total FA: 124733

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.88292 | acc=0.1042 | tpr=0.5265 | fpr=0.9034 | 5028.6 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.86047 | acc=0.1053 | tpr=0.5203 | fpr=0.9024 | 6536.5 samples/s | 25.5 steps/s
[Step= 150] | Loss=5.86371 | acc=0.1054 | tpr=0.5173 | fpr=0.9022 | 7873.1 samples/s | 30.8 steps/s
[Step= 200] | Loss=5.86322 | acc=0.1048 | tpr=0.5005 | fpr=0.9024 | 7770.3 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.87497 | acc=0.1051 | tpr=0.5083 | fpr=0.9023 | 8121.5 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.87526 | acc=0.1050 | tpr=0.5164 | fpr=0.9025 | 7692.6 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.86598 | acc=0.1050 | tpr=0.5160 | fpr=0.9025 | 7739.5 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.86099 | acc=0.1056 | tpr=0.5137 | fpr=0.9019 | 8003.4 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.86391 | acc=0.1055 | tpr=0.5146 | fpr=0.9019 | 7738.2 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.86585 | acc=0.1055 | tpr=0.5088 | fpr=0.9018 | 7842.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.87000 | acc=0.1053 | tpr=0.5109 | fpr=0.9021 | 13918.1 samples/s | 54.4 steps/s
Avg test loss: 5.87169, Avg test acc: 0.10514, Avg tpr: 0.50990, Avg fpr: 0.90222, total FA: 125271

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08110 | acc=0.9820 | tpr=0.9381 | fpr=0.0173 | 4893.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08299 | acc=0.9822 | tpr=0.9446 | fpr=0.0171 | 6969.5 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.08631 | acc=0.9816 | tpr=0.9452 | fpr=0.0178 | 7976.3 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.08757 | acc=0.9815 | tpr=0.9508 | fpr=0.0180 | 7617.4 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.08673 | acc=0.9816 | tpr=0.9485 | fpr=0.0178 | 7721.1 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.08891 | acc=0.9812 | tpr=0.9462 | fpr=0.0181 | 7793.0 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.08983 | acc=0.9810 | tpr=0.9474 | fpr=0.0184 | 7956.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09071 | acc=0.9807 | tpr=0.9415 | fpr=0.0186 | 7733.5 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.09229 | acc=0.9804 | tpr=0.9391 | fpr=0.0189 | 7718.0 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.09148 | acc=0.9805 | tpr=0.9392 | fpr=0.0187 | 8132.0 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.09119 | acc=0.9807 | tpr=0.9363 | fpr=0.0185 | 13693.6 samples/s | 53.5 steps/s
Avg test loss: 0.09110, Avg test acc: 0.98072, Avg tpr: 0.93661, Avg fpr: 0.01847, total FA: 2565

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09217 | acc=0.9829 | tpr=0.9425 | fpr=0.0164 | 4899.1 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.09550 | acc=0.9824 | tpr=0.9275 | fpr=0.0166 | 7074.1 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.09896 | acc=0.9817 | tpr=0.9236 | fpr=0.0172 | 7426.3 samples/s | 29.0 steps/s
[Step= 200] | Loss=0.10103 | acc=0.9816 | tpr=0.9257 | fpr=0.0174 | 7964.2 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.09941 | acc=0.9818 | tpr=0.9258 | fpr=0.0172 | 7889.6 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.10206 | acc=0.9814 | tpr=0.9236 | fpr=0.0175 | 7377.7 samples/s | 28.8 steps/s
[Step= 350] | Loss=0.10261 | acc=0.9813 | tpr=0.9274 | fpr=0.0177 | 8330.6 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.10394 | acc=0.9811 | tpr=0.9212 | fpr=0.0178 | 7568.5 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.10633 | acc=0.9809 | tpr=0.9197 | fpr=0.0180 | 8015.9 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.10529 | acc=0.9810 | tpr=0.9229 | fpr=0.0180 | 8054.2 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.10508 | acc=0.9811 | tpr=0.9216 | fpr=0.0178 | 13525.2 samples/s | 52.8 steps/s
Avg test loss: 0.10498, Avg test acc: 0.98111, Avg tpr: 0.92195, Avg fpr: 0.01781, total FA: 2473

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09982 | acc=0.9803 | tpr=0.9558 | fpr=0.0192 | 4881.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.10222 | acc=0.9806 | tpr=0.9595 | fpr=0.0190 | 6898.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.10649 | acc=0.9798 | tpr=0.9597 | fpr=0.0198 | 7926.6 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10803 | acc=0.9800 | tpr=0.9628 | fpr=0.0197 | 7484.4 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.10624 | acc=0.9802 | tpr=0.9616 | fpr=0.0194 | 8228.6 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.10873 | acc=0.9799 | tpr=0.9549 | fpr=0.0196 | 8087.3 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.10961 | acc=0.9796 | tpr=0.9555 | fpr=0.0200 | 7843.6 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.11080 | acc=0.9794 | tpr=0.9535 | fpr=0.0202 | 7598.2 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.11275 | acc=0.9792 | tpr=0.9518 | fpr=0.0203 | 8086.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.11209 | acc=0.9792 | tpr=0.9533 | fpr=0.0204 | 7825.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.11172 | acc=0.9793 | tpr=0.9522 | fpr=0.0202 | 13776.2 samples/s | 53.8 steps/s
Avg test loss: 0.11166, Avg test acc: 0.97932, Avg tpr: 0.95246, Avg fpr: 0.02019, total FA: 2804

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09718 | acc=0.9806 | tpr=0.9513 | fpr=0.0188 | 4865.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10133 | acc=0.9800 | tpr=0.9446 | fpr=0.0194 | 6823.5 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.10595 | acc=0.9790 | tpr=0.9452 | fpr=0.0203 | 8259.4 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.10716 | acc=0.9792 | tpr=0.9519 | fpr=0.0203 | 7607.4 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.10559 | acc=0.9798 | tpr=0.9546 | fpr=0.0197 | 7811.7 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.10804 | acc=0.9796 | tpr=0.9476 | fpr=0.0198 | 7785.2 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.10880 | acc=0.9794 | tpr=0.9487 | fpr=0.0200 | 7924.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.10924 | acc=0.9794 | tpr=0.9458 | fpr=0.0200 | 7818.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.11133 | acc=0.9792 | tpr=0.9426 | fpr=0.0202 | 7688.3 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.11051 | acc=0.9793 | tpr=0.9445 | fpr=0.0201 | 8042.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.11008 | acc=0.9794 | tpr=0.9443 | fpr=0.0199 | 13902.6 samples/s | 54.3 steps/s
Avg test loss: 0.10995, Avg test acc: 0.97944, Avg tpr: 0.94453, Avg fpr: 0.01992, total FA: 2766

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09843 | acc=0.9820 | tpr=0.9336 | fpr=0.0171 | 4873.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.10469 | acc=0.9811 | tpr=0.9318 | fpr=0.0179 | 7034.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.10835 | acc=0.9803 | tpr=0.9337 | fpr=0.0189 | 7530.2 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.11039 | acc=0.9801 | tpr=0.9388 | fpr=0.0192 | 8129.7 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.10889 | acc=0.9805 | tpr=0.9362 | fpr=0.0187 | 7774.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11148 | acc=0.9801 | tpr=0.9309 | fpr=0.0190 | 7727.4 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.11221 | acc=0.9800 | tpr=0.9336 | fpr=0.0192 | 8154.2 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.11360 | acc=0.9798 | tpr=0.9311 | fpr=0.0193 | 7402.3 samples/s | 28.9 steps/s
[Step= 450] | Loss=0.11580 | acc=0.9796 | tpr=0.9289 | fpr=0.0195 | 8244.0 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.11497 | acc=0.9797 | tpr=0.9291 | fpr=0.0194 | 7490.3 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.11458 | acc=0.9799 | tpr=0.9284 | fpr=0.0192 | 14895.7 samples/s | 58.2 steps/s
Avg test loss: 0.11445, Avg test acc: 0.97987, Avg tpr: 0.92868, Avg fpr: 0.01920, total FA: 2666

server round 26/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=253.6] | Loss=0.00196 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=14.551 | 5576.4 samples/s | 87.1 steps/s
[Step=52050 Epoch=253.8] | Loss=0.00260 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=14.557 | 4319.9 samples/s | 67.5 steps/s
[Step=52100 Epoch=254.0] | Loss=0.00280 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.574 | L2-Norm(final)=14.565 | 5031.3 samples/s | 78.6 steps/s
[Step=52150 Epoch=254.3] | Loss=0.00303 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.573 | L2-Norm(final)=14.574 | 5197.2 samples/s | 81.2 steps/s
[Step=52200 Epoch=254.5] | Loss=0.00288 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.572 | L2-Norm(final)=14.582 | 7422.7 samples/s | 116.0 steps/s
[Step=52250 Epoch=254.8] | Loss=0.00295 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.572 | L2-Norm(final)=14.591 | 2175.0 samples/s | 34.0 steps/s
[Step=52300 Epoch=255.0] | Loss=0.00276 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.572 | L2-Norm(final)=14.601 | 5167.4 samples/s | 80.7 steps/s
[Step=52350 Epoch=255.3] | Loss=0.00272 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.571 | L2-Norm(final)=14.610 | 4946.1 samples/s | 77.3 steps/s
[Step=52400 Epoch=255.5] | Loss=0.00270 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.570 | L2-Norm(final)=14.619 | 6944.3 samples/s | 108.5 steps/s
[Step=52450 Epoch=255.8] | Loss=0.00270 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.570 | L2-Norm(final)=14.628 | 2334.9 samples/s | 36.5 steps/s
[Step=52500 Epoch=256.0] | Loss=0.00267 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.569 | L2-Norm(final)=14.637 | 4947.4 samples/s | 77.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=256.0] | Loss=0.00261 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.555 | L2-Norm(final)=14.726 | 5683.3 samples/s | 88.8 steps/s
[Step=52550 Epoch=256.2] | Loss=0.00244 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.555 | L2-Norm(final)=14.734 | 3877.5 samples/s | 60.6 steps/s
[Step=52600 Epoch=256.5] | Loss=0.00417 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.559 | L2-Norm(final)=14.741 | 4425.0 samples/s | 69.1 steps/s
[Step=52650 Epoch=256.7] | Loss=0.00522 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.569 | L2-Norm(final)=14.749 | 4439.3 samples/s | 69.4 steps/s
[Step=52700 Epoch=257.0] | Loss=0.00584 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=14.758 | 6537.3 samples/s | 102.1 steps/s
[Step=52750 Epoch=257.2] | Loss=0.00576 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.593 | L2-Norm(final)=14.768 | 2088.9 samples/s | 32.6 steps/s
[Step=52800 Epoch=257.5] | Loss=0.00590 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.605 | L2-Norm(final)=14.776 | 4478.7 samples/s | 70.0 steps/s
[Step=52850 Epoch=257.7] | Loss=0.00595 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.614 | L2-Norm(final)=14.785 | 4501.2 samples/s | 70.3 steps/s
[Step=52900 Epoch=258.0] | Loss=0.00594 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.624 | L2-Norm(final)=14.793 | 5862.7 samples/s | 91.6 steps/s
[Step=52950 Epoch=258.2] | Loss=0.00597 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.632 | L2-Norm(final)=14.800 | 2156.5 samples/s | 33.7 steps/s
[Step=53000 Epoch=258.4] | Loss=0.00577 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=14.806 | 4371.4 samples/s | 68.3 steps/s
[Step=53050 Epoch=258.7] | Loss=0.00556 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.645 | L2-Norm(final)=14.813 | 4464.6 samples/s | 69.8 steps/s
[Step=53100 Epoch=258.9] | Loss=0.00533 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.650 | L2-Norm(final)=14.819 | 5433.1 samples/s | 84.9 steps/s
[Step=53150 Epoch=259.2] | Loss=0.00514 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.653 | L2-Norm(final)=14.825 | 2267.7 samples/s | 35.4 steps/s
[Step=53200 Epoch=259.4] | Loss=0.00511 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.656 | L2-Norm(final)=14.831 | 4404.2 samples/s | 68.8 steps/s
[Step=53250 Epoch=259.7] | Loss=0.00501 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.659 | L2-Norm(final)=14.836 | 4441.4 samples/s | 69.4 steps/s
[Step=53300 Epoch=259.9] | Loss=0.00486 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.661 | L2-Norm(final)=14.841 | 4920.5 samples/s | 76.9 steps/s
[Step=53350 Epoch=260.1] | Loss=0.00468 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.663 | L2-Norm(final)=14.846 | 2335.0 samples/s | 36.5 steps/s
[Step=53400 Epoch=260.4] | Loss=0.00455 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.664 | L2-Norm(final)=14.851 | 4462.3 samples/s | 69.7 steps/s
[Step=53450 Epoch=260.6] | Loss=0.00452 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.665 | L2-Norm(final)=14.855 | 4473.4 samples/s | 69.9 steps/s
[Step=53500 Epoch=260.9] | Loss=0.00445 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.666 | L2-Norm(final)=14.860 | 4625.9 samples/s | 72.3 steps/s
[Step=53550 Epoch=261.1] | Loss=0.00437 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.667 | L2-Norm(final)=14.864 | 2409.9 samples/s | 37.7 steps/s
[Step=53600 Epoch=261.4] | Loss=0.00433 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.667 | L2-Norm(final)=14.868 | 4358.1 samples/s | 68.1 steps/s
[Step=53650 Epoch=261.6] | Loss=0.00428 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.667 | L2-Norm(final)=14.872 | 4479.4 samples/s | 70.0 steps/s
[Step=53700 Epoch=261.9] | Loss=0.00422 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.666 | L2-Norm(final)=14.875 | 4458.2 samples/s | 69.7 steps/s
[Step=53750 Epoch=262.1] | Loss=0.00412 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.665 | L2-Norm(final)=14.879 | 2469.4 samples/s | 38.6 steps/s
[Step=53800 Epoch=262.3] | Loss=0.00403 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.664 | L2-Norm(final)=14.882 | 4428.3 samples/s | 69.2 steps/s
[Step=53850 Epoch=262.6] | Loss=0.00396 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.663 | L2-Norm(final)=14.886 | 4504.5 samples/s | 70.4 steps/s
[Step=53900 Epoch=262.8] | Loss=0.00390 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.661 | L2-Norm(final)=14.889 | 4463.1 samples/s | 69.7 steps/s
[Step=53950 Epoch=263.1] | Loss=0.00383 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.660 | L2-Norm(final)=14.892 | 2435.2 samples/s | 38.1 steps/s
[Step=54000 Epoch=263.3] | Loss=0.00379 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.658 | L2-Norm(final)=14.896 | 4428.6 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step54000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=253.7] | Loss=0.00041 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.345 | L2-Norm(final)=14.944 | 5586.1 samples/s | 87.3 steps/s
[Step=52050 Epoch=254.0] | Loss=0.00293 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=14.952 | 4322.3 samples/s | 67.5 steps/s
[Step=52100 Epoch=254.2] | Loss=0.00265 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=14.962 | 5002.7 samples/s | 78.2 steps/s
[Step=52150 Epoch=254.5] | Loss=0.00252 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.341 | L2-Norm(final)=14.972 | 5034.6 samples/s | 78.7 steps/s
[Step=52200 Epoch=254.7] | Loss=0.00227 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.340 | L2-Norm(final)=14.982 | 7856.0 samples/s | 122.8 steps/s
[Step=52250 Epoch=255.0] | Loss=0.00231 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.338 | L2-Norm(final)=14.991 | 2202.0 samples/s | 34.4 steps/s
[Step=52300 Epoch=255.2] | Loss=0.00222 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.336 | L2-Norm(final)=15.001 | 4925.9 samples/s | 77.0 steps/s
[Step=52350 Epoch=255.4] | Loss=0.00213 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.334 | L2-Norm(final)=15.011 | 5065.9 samples/s | 79.2 steps/s
[Step=52400 Epoch=255.7] | Loss=0.00216 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.332 | L2-Norm(final)=15.020 | 7149.8 samples/s | 111.7 steps/s
[Step=52450 Epoch=255.9] | Loss=0.00216 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=15.030 | 2285.1 samples/s | 35.7 steps/s
[Step=52500 Epoch=256.2] | Loss=0.00218 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=15.039 | 5122.2 samples/s | 80.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=256.2] | Loss=0.00546 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.303 | L2-Norm(final)=15.135 | 5468.6 samples/s | 85.4 steps/s
[Step=52550 Epoch=256.4] | Loss=0.00265 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.303 | L2-Norm(final)=15.145 | 3971.7 samples/s | 62.1 steps/s
[Step=52600 Epoch=256.7] | Loss=0.00255 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.305 | L2-Norm(final)=15.154 | 4428.7 samples/s | 69.2 steps/s
[Step=52650 Epoch=256.9] | Loss=0.00428 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=15.163 | 4416.8 samples/s | 69.0 steps/s
[Step=52700 Epoch=257.2] | Loss=0.00510 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=15.173 | 6570.7 samples/s | 102.7 steps/s
[Step=52750 Epoch=257.4] | Loss=0.00548 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.338 | L2-Norm(final)=15.183 | 2071.0 samples/s | 32.4 steps/s
[Step=52800 Epoch=257.6] | Loss=0.00575 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.351 | L2-Norm(final)=15.192 | 4500.7 samples/s | 70.3 steps/s
[Step=52850 Epoch=257.9] | Loss=0.00562 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.362 | L2-Norm(final)=15.201 | 4437.4 samples/s | 69.3 steps/s
[Step=52900 Epoch=258.1] | Loss=0.00558 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.371 | L2-Norm(final)=15.210 | 6105.6 samples/s | 95.4 steps/s
[Step=52950 Epoch=258.4] | Loss=0.00540 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=15.217 | 2136.6 samples/s | 33.4 steps/s
[Step=53000 Epoch=258.6] | Loss=0.00529 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=15.224 | 4473.2 samples/s | 69.9 steps/s
[Step=53050 Epoch=258.9] | Loss=0.00536 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.391 | L2-Norm(final)=15.231 | 4524.4 samples/s | 70.7 steps/s
[Step=53100 Epoch=259.1] | Loss=0.00520 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.396 | L2-Norm(final)=15.237 | 5495.9 samples/s | 85.9 steps/s
[Step=53150 Epoch=259.3] | Loss=0.00502 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.400 | L2-Norm(final)=15.243 | 2196.0 samples/s | 34.3 steps/s
[Step=53200 Epoch=259.6] | Loss=0.00487 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.404 | L2-Norm(final)=15.249 | 4473.0 samples/s | 69.9 steps/s
[Step=53250 Epoch=259.8] | Loss=0.00468 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.407 | L2-Norm(final)=15.255 | 4495.4 samples/s | 70.2 steps/s
[Step=53300 Epoch=260.1] | Loss=0.00451 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.409 | L2-Norm(final)=15.260 | 5161.2 samples/s | 80.6 steps/s
[Step=53350 Epoch=260.3] | Loss=0.00443 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.410 | L2-Norm(final)=15.266 | 2228.5 samples/s | 34.8 steps/s
[Step=53400 Epoch=260.6] | Loss=0.00447 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=15.271 | 4487.7 samples/s | 70.1 steps/s
[Step=53450 Epoch=260.8] | Loss=0.00439 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=15.275 | 4428.1 samples/s | 69.2 steps/s
[Step=53500 Epoch=261.1] | Loss=0.00429 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=15.279 | 4848.9 samples/s | 75.8 steps/s
[Step=53550 Epoch=261.3] | Loss=0.00419 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=15.283 | 2359.6 samples/s | 36.9 steps/s
[Step=53600 Epoch=261.5] | Loss=0.00408 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=15.287 | 4486.2 samples/s | 70.1 steps/s
[Step=53650 Epoch=261.8] | Loss=0.00400 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.411 | L2-Norm(final)=15.291 | 4427.4 samples/s | 69.2 steps/s
[Step=53700 Epoch=262.0] | Loss=0.00394 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.410 | L2-Norm(final)=15.295 | 4477.0 samples/s | 70.0 steps/s
[Step=53750 Epoch=262.3] | Loss=0.00383 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.408 | L2-Norm(final)=15.299 | 2410.6 samples/s | 37.7 steps/s
[Step=53800 Epoch=262.5] | Loss=0.00377 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.407 | L2-Norm(final)=15.302 | 4528.6 samples/s | 70.8 steps/s
[Step=53850 Epoch=262.8] | Loss=0.00368 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=15.305 | 4395.7 samples/s | 68.7 steps/s
[Step=53900 Epoch=263.0] | Loss=0.00363 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.403 | L2-Norm(final)=15.309 | 4486.8 samples/s | 70.1 steps/s
[Step=53950 Epoch=263.3] | Loss=0.00356 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.400 | L2-Norm(final)=15.312 | 2455.3 samples/s | 38.4 steps/s
[Step=54000 Epoch=263.5] | Loss=0.00350 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.398 | L2-Norm(final)=15.315 | 4378.4 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step54000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=253.4] | Loss=0.00025 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.004 | L2-Norm(final)=15.288 | 5256.2 samples/s | 82.1 steps/s
[Step=52050 Epoch=253.6] | Loss=0.00247 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.002 | L2-Norm(final)=15.293 | 4539.7 samples/s | 70.9 steps/s
[Step=52100 Epoch=253.9] | Loss=0.00274 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.001 | L2-Norm(final)=15.302 | 5006.7 samples/s | 78.2 steps/s
[Step=52150 Epoch=254.1] | Loss=0.00286 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.999 | L2-Norm(final)=15.310 | 5053.1 samples/s | 79.0 steps/s
[Step=52200 Epoch=254.3] | Loss=0.00279 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.997 | L2-Norm(final)=15.318 | 7874.3 samples/s | 123.0 steps/s
[Step=52250 Epoch=254.6] | Loss=0.00275 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.996 | L2-Norm(final)=15.327 | 2204.3 samples/s | 34.4 steps/s
[Step=52300 Epoch=254.8] | Loss=0.00271 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.994 | L2-Norm(final)=15.335 | 5085.4 samples/s | 79.5 steps/s
[Step=52350 Epoch=255.1] | Loss=0.00269 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.992 | L2-Norm(final)=15.344 | 5031.9 samples/s | 78.6 steps/s
[Step=52400 Epoch=255.3] | Loss=0.00261 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.990 | L2-Norm(final)=15.353 | 6678.8 samples/s | 104.4 steps/s
[Step=52450 Epoch=255.6] | Loss=0.00253 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.988 | L2-Norm(final)=15.361 | 2309.6 samples/s | 36.1 steps/s
[Step=52500 Epoch=255.8] | Loss=0.00252 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.986 | L2-Norm(final)=15.370 | 5122.7 samples/s | 80.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=255.8] | Loss=0.00021 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.965 | L2-Norm(final)=15.460 | 5789.7 samples/s | 90.5 steps/s
[Step=52550 Epoch=256.0] | Loss=0.00248 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.963 | L2-Norm(final)=15.468 | 3884.9 samples/s | 60.7 steps/s
[Step=52600 Epoch=256.3] | Loss=0.00304 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.962 | L2-Norm(final)=15.474 | 4384.8 samples/s | 68.5 steps/s
[Step=52650 Epoch=256.5] | Loss=0.00644 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.966 | L2-Norm(final)=15.480 | 4477.5 samples/s | 70.0 steps/s
[Step=52700 Epoch=256.8] | Loss=0.00780 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.982 | L2-Norm(final)=15.487 | 6522.2 samples/s | 101.9 steps/s
[Step=52750 Epoch=257.0] | Loss=0.00751 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.001 | L2-Norm(final)=15.494 | 2064.8 samples/s | 32.3 steps/s
[Step=52800 Epoch=257.3] | Loss=0.00731 | Reg=0.00289 | acc=0.9688 | L2-Norm=17.015 | L2-Norm(final)=15.502 | 4443.7 samples/s | 69.4 steps/s
[Step=52850 Epoch=257.5] | Loss=0.00697 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.026 | L2-Norm(final)=15.508 | 4483.4 samples/s | 70.1 steps/s
[Step=52900 Epoch=257.8] | Loss=0.00673 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.034 | L2-Norm(final)=15.515 | 5886.2 samples/s | 92.0 steps/s
[Step=52950 Epoch=258.0] | Loss=0.00638 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.041 | L2-Norm(final)=15.521 | 2179.1 samples/s | 34.0 steps/s
[Step=53000 Epoch=258.2] | Loss=0.00618 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.047 | L2-Norm(final)=15.526 | 4494.4 samples/s | 70.2 steps/s
[Step=53050 Epoch=258.5] | Loss=0.00594 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.051 | L2-Norm(final)=15.531 | 4417.2 samples/s | 69.0 steps/s
[Step=53100 Epoch=258.7] | Loss=0.00583 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.055 | L2-Norm(final)=15.536 | 5278.2 samples/s | 82.5 steps/s
[Step=53150 Epoch=259.0] | Loss=0.00567 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.057 | L2-Norm(final)=15.540 | 2281.2 samples/s | 35.6 steps/s
[Step=53200 Epoch=259.2] | Loss=0.00547 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.060 | L2-Norm(final)=15.545 | 4382.9 samples/s | 68.5 steps/s
[Step=53250 Epoch=259.5] | Loss=0.00526 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.061 | L2-Norm(final)=15.549 | 4458.0 samples/s | 69.7 steps/s
[Step=53300 Epoch=259.7] | Loss=0.00511 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.062 | L2-Norm(final)=15.553 | 4973.3 samples/s | 77.7 steps/s
[Step=53350 Epoch=259.9] | Loss=0.00497 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.062 | L2-Norm(final)=15.557 | 2314.5 samples/s | 36.2 steps/s
[Step=53400 Epoch=260.2] | Loss=0.00478 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.062 | L2-Norm(final)=15.561 | 4468.0 samples/s | 69.8 steps/s
[Step=53450 Epoch=260.4] | Loss=0.00465 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.062 | L2-Norm(final)=15.564 | 4390.9 samples/s | 68.6 steps/s
[Step=53500 Epoch=260.7] | Loss=0.00456 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.061 | L2-Norm(final)=15.568 | 4604.7 samples/s | 71.9 steps/s
[Step=53550 Epoch=260.9] | Loss=0.00444 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.060 | L2-Norm(final)=15.571 | 2433.8 samples/s | 38.0 steps/s
[Step=53600 Epoch=261.2] | Loss=0.00434 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.058 | L2-Norm(final)=15.574 | 4514.9 samples/s | 70.5 steps/s
[Step=53650 Epoch=261.4] | Loss=0.00426 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.057 | L2-Norm(final)=15.577 | 4474.7 samples/s | 69.9 steps/s
[Step=53700 Epoch=261.7] | Loss=0.00415 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.055 | L2-Norm(final)=15.580 | 4472.2 samples/s | 69.9 steps/s
[Step=53750 Epoch=261.9] | Loss=0.00410 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.052 | L2-Norm(final)=15.583 | 2464.0 samples/s | 38.5 steps/s
[Step=53800 Epoch=262.1] | Loss=0.00401 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.050 | L2-Norm(final)=15.586 | 4379.8 samples/s | 68.4 steps/s
[Step=53850 Epoch=262.4] | Loss=0.00398 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.048 | L2-Norm(final)=15.589 | 4443.3 samples/s | 69.4 steps/s
[Step=53900 Epoch=262.6] | Loss=0.00391 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.045 | L2-Norm(final)=15.592 | 4462.8 samples/s | 69.7 steps/s
[Step=53950 Epoch=262.9] | Loss=0.00383 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.042 | L2-Norm(final)=15.595 | 2485.4 samples/s | 38.8 steps/s
[Step=54000 Epoch=263.1] | Loss=0.00383 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.039 | L2-Norm(final)=15.597 | 4444.7 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step54000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=253.6] | Loss=0.00149 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.695 | L2-Norm(final)=15.151 | 5671.8 samples/s | 88.6 steps/s
[Step=52050 Epoch=253.8] | Loss=0.00242 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.694 | L2-Norm(final)=15.158 | 4153.0 samples/s | 64.9 steps/s
[Step=52100 Epoch=254.1] | Loss=0.00206 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.694 | L2-Norm(final)=15.168 | 5100.4 samples/s | 79.7 steps/s
[Step=52150 Epoch=254.3] | Loss=0.00228 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.694 | L2-Norm(final)=15.178 | 5003.3 samples/s | 78.2 steps/s
[Step=52200 Epoch=254.6] | Loss=0.00221 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.693 | L2-Norm(final)=15.188 | 7769.1 samples/s | 121.4 steps/s
[Step=52250 Epoch=254.8] | Loss=0.00219 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.692 | L2-Norm(final)=15.198 | 2209.9 samples/s | 34.5 steps/s
[Step=52300 Epoch=255.0] | Loss=0.00212 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.691 | L2-Norm(final)=15.208 | 5050.7 samples/s | 78.9 steps/s
[Step=52350 Epoch=255.3] | Loss=0.00220 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.690 | L2-Norm(final)=15.218 | 5025.5 samples/s | 78.5 steps/s
[Step=52400 Epoch=255.5] | Loss=0.00212 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.689 | L2-Norm(final)=15.228 | 6969.6 samples/s | 108.9 steps/s
[Step=52450 Epoch=255.8] | Loss=0.00209 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.687 | L2-Norm(final)=15.237 | 2276.7 samples/s | 35.6 steps/s
[Step=52500 Epoch=256.0] | Loss=0.00211 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.685 | L2-Norm(final)=15.247 | 5107.6 samples/s | 79.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=256.0] | Loss=0.00030 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.668 | L2-Norm(final)=15.341 | 5238.0 samples/s | 81.8 steps/s
[Step=52550 Epoch=256.3] | Loss=0.00154 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.666 | L2-Norm(final)=15.349 | 4094.5 samples/s | 64.0 steps/s
[Step=52600 Epoch=256.5] | Loss=0.00396 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.669 | L2-Norm(final)=15.357 | 4540.4 samples/s | 70.9 steps/s
[Step=52650 Epoch=256.8] | Loss=0.00430 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.677 | L2-Norm(final)=15.364 | 4422.5 samples/s | 69.1 steps/s
[Step=52700 Epoch=257.0] | Loss=0.00575 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.688 | L2-Norm(final)=15.373 | 6546.6 samples/s | 102.3 steps/s
[Step=52750 Epoch=257.2] | Loss=0.00614 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.701 | L2-Norm(final)=15.381 | 2076.1 samples/s | 32.4 steps/s
[Step=52800 Epoch=257.5] | Loss=0.00593 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.713 | L2-Norm(final)=15.390 | 4413.1 samples/s | 69.0 steps/s
[Step=52850 Epoch=257.7] | Loss=0.00582 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.723 | L2-Norm(final)=15.399 | 4504.6 samples/s | 70.4 steps/s
[Step=52900 Epoch=258.0] | Loss=0.00577 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.732 | L2-Norm(final)=15.407 | 5813.1 samples/s | 90.8 steps/s
[Step=52950 Epoch=258.2] | Loss=0.00552 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.740 | L2-Norm(final)=15.415 | 2179.6 samples/s | 34.1 steps/s
[Step=53000 Epoch=258.5] | Loss=0.00524 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=15.423 | 4510.8 samples/s | 70.5 steps/s
[Step=53050 Epoch=258.7] | Loss=0.00509 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.752 | L2-Norm(final)=15.430 | 4453.3 samples/s | 69.6 steps/s
[Step=53100 Epoch=258.9] | Loss=0.00504 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.756 | L2-Norm(final)=15.436 | 5384.3 samples/s | 84.1 steps/s
[Step=53150 Epoch=259.2] | Loss=0.00492 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.760 | L2-Norm(final)=15.442 | 2230.9 samples/s | 34.9 steps/s
[Step=53200 Epoch=259.4] | Loss=0.00472 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=15.447 | 4491.3 samples/s | 70.2 steps/s
[Step=53250 Epoch=259.7] | Loss=0.00458 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.765 | L2-Norm(final)=15.453 | 4508.2 samples/s | 70.4 steps/s
[Step=53300 Epoch=259.9] | Loss=0.00451 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.766 | L2-Norm(final)=15.458 | 4968.2 samples/s | 77.6 steps/s
[Step=53350 Epoch=260.2] | Loss=0.00439 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.767 | L2-Norm(final)=15.463 | 2335.6 samples/s | 36.5 steps/s
[Step=53400 Epoch=260.4] | Loss=0.00431 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.768 | L2-Norm(final)=15.467 | 4436.8 samples/s | 69.3 steps/s
[Step=53450 Epoch=260.7] | Loss=0.00417 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.769 | L2-Norm(final)=15.472 | 4491.3 samples/s | 70.2 steps/s
[Step=53500 Epoch=260.9] | Loss=0.00402 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.769 | L2-Norm(final)=15.476 | 4524.0 samples/s | 70.7 steps/s
[Step=53550 Epoch=261.1] | Loss=0.00393 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.768 | L2-Norm(final)=15.480 | 2401.1 samples/s | 37.5 steps/s
[Step=53600 Epoch=261.4] | Loss=0.00385 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.768 | L2-Norm(final)=15.484 | 4502.4 samples/s | 70.3 steps/s
[Step=53650 Epoch=261.6] | Loss=0.00378 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.766 | L2-Norm(final)=15.488 | 4360.3 samples/s | 68.1 steps/s
[Step=53700 Epoch=261.9] | Loss=0.00368 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.765 | L2-Norm(final)=15.492 | 4410.2 samples/s | 68.9 steps/s
[Step=53750 Epoch=262.1] | Loss=0.00359 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.763 | L2-Norm(final)=15.495 | 2425.3 samples/s | 37.9 steps/s
[Step=53800 Epoch=262.4] | Loss=0.00353 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=15.499 | 4365.1 samples/s | 68.2 steps/s
[Step=53850 Epoch=262.6] | Loss=0.00351 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.760 | L2-Norm(final)=15.502 | 4286.7 samples/s | 67.0 steps/s
[Step=53900 Epoch=262.8] | Loss=0.00347 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.757 | L2-Norm(final)=15.505 | 4490.2 samples/s | 70.2 steps/s
[Step=53950 Epoch=263.1] | Loss=0.00342 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.755 | L2-Norm(final)=15.508 | 2380.3 samples/s | 37.2 steps/s
[Step=54000 Epoch=263.3] | Loss=0.00339 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.753 | L2-Norm(final)=15.512 | 4475.0 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step54000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=255.0] | Loss=0.00064 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.471 | L2-Norm(final)=15.350 | 5751.0 samples/s | 89.9 steps/s
[Step=52050 Epoch=255.2] | Loss=0.00222 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.469 | L2-Norm(final)=15.358 | 4209.9 samples/s | 65.8 steps/s
[Step=52100 Epoch=255.5] | Loss=0.00218 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.468 | L2-Norm(final)=15.367 | 5096.1 samples/s | 79.6 steps/s
[Step=52150 Epoch=255.7] | Loss=0.00220 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=15.375 | 4956.4 samples/s | 77.4 steps/s
[Step=52200 Epoch=256.0] | Loss=0.00204 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.465 | L2-Norm(final)=15.383 | 7757.7 samples/s | 121.2 steps/s
[Step=52250 Epoch=256.2] | Loss=0.00197 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.463 | L2-Norm(final)=15.391 | 2210.2 samples/s | 34.5 steps/s
[Step=52300 Epoch=256.5] | Loss=0.00198 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.461 | L2-Norm(final)=15.399 | 5069.1 samples/s | 79.2 steps/s
[Step=52350 Epoch=256.7] | Loss=0.00189 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.458 | L2-Norm(final)=15.407 | 4905.4 samples/s | 76.6 steps/s
[Step=52400 Epoch=257.0] | Loss=0.00198 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.456 | L2-Norm(final)=15.415 | 7467.6 samples/s | 116.7 steps/s
[Step=52450 Epoch=257.2] | Loss=0.00189 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.453 | L2-Norm(final)=15.423 | 2265.1 samples/s | 35.4 steps/s
[Step=52500 Epoch=257.5] | Loss=0.00186 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.451 | L2-Norm(final)=15.432 | 4952.3 samples/s | 77.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=257.5] | Loss=0.00302 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.426 | L2-Norm(final)=15.517 | 5594.7 samples/s | 87.4 steps/s
[Step=52550 Epoch=257.7] | Loss=0.00161 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.424 | L2-Norm(final)=15.526 | 3859.9 samples/s | 60.3 steps/s
[Step=52600 Epoch=257.9] | Loss=0.00392 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.426 | L2-Norm(final)=15.533 | 4480.4 samples/s | 70.0 steps/s
[Step=52650 Epoch=258.2] | Loss=0.00731 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.441 | L2-Norm(final)=15.539 | 4426.1 samples/s | 69.2 steps/s
[Step=52700 Epoch=258.4] | Loss=0.00698 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.461 | L2-Norm(final)=15.547 | 6664.4 samples/s | 104.1 steps/s
[Step=52750 Epoch=258.7] | Loss=0.00716 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.478 | L2-Norm(final)=15.554 | 2075.9 samples/s | 32.4 steps/s
[Step=52800 Epoch=258.9] | Loss=0.00739 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.491 | L2-Norm(final)=15.560 | 4444.0 samples/s | 69.4 steps/s
[Step=52850 Epoch=259.2] | Loss=0.00688 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.502 | L2-Norm(final)=15.567 | 4460.1 samples/s | 69.7 steps/s
[Step=52900 Epoch=259.4] | Loss=0.00663 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.511 | L2-Norm(final)=15.575 | 6076.8 samples/s | 95.0 steps/s
[Step=52950 Epoch=259.7] | Loss=0.00636 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.519 | L2-Norm(final)=15.581 | 2124.3 samples/s | 33.2 steps/s
[Step=53000 Epoch=259.9] | Loss=0.00600 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.525 | L2-Norm(final)=15.588 | 4446.4 samples/s | 69.5 steps/s
[Step=53050 Epoch=260.1] | Loss=0.00564 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.530 | L2-Norm(final)=15.594 | 4519.5 samples/s | 70.6 steps/s
[Step=53100 Epoch=260.4] | Loss=0.00538 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.534 | L2-Norm(final)=15.599 | 5790.8 samples/s | 90.5 steps/s
[Step=53150 Epoch=260.6] | Loss=0.00523 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.537 | L2-Norm(final)=15.604 | 2180.5 samples/s | 34.1 steps/s
[Step=53200 Epoch=260.9] | Loss=0.00505 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=15.609 | 4440.2 samples/s | 69.4 steps/s
[Step=53250 Epoch=261.1] | Loss=0.00487 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.541 | L2-Norm(final)=15.614 | 4390.6 samples/s | 68.6 steps/s
[Step=53300 Epoch=261.4] | Loss=0.00469 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.542 | L2-Norm(final)=15.618 | 5478.9 samples/s | 85.6 steps/s
[Step=53350 Epoch=261.6] | Loss=0.00455 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.543 | L2-Norm(final)=15.623 | 2234.7 samples/s | 34.9 steps/s
[Step=53400 Epoch=261.9] | Loss=0.00437 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.543 | L2-Norm(final)=15.627 | 4486.9 samples/s | 70.1 steps/s
[Step=53450 Epoch=262.1] | Loss=0.00425 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.543 | L2-Norm(final)=15.631 | 4361.1 samples/s | 68.1 steps/s
[Step=53500 Epoch=262.4] | Loss=0.00427 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.542 | L2-Norm(final)=15.635 | 5210.2 samples/s | 81.4 steps/s
[Step=53550 Epoch=262.6] | Loss=0.00417 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.541 | L2-Norm(final)=15.638 | 2272.6 samples/s | 35.5 steps/s
[Step=53600 Epoch=262.8] | Loss=0.00405 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.540 | L2-Norm(final)=15.642 | 4367.5 samples/s | 68.2 steps/s
[Step=53650 Epoch=263.1] | Loss=0.00394 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=15.645 | 4426.9 samples/s | 69.2 steps/s
[Step=53700 Epoch=263.3] | Loss=0.00385 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.537 | L2-Norm(final)=15.648 | 4907.4 samples/s | 76.7 steps/s
[Step=53750 Epoch=263.6] | Loss=0.00378 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.536 | L2-Norm(final)=15.651 | 2364.0 samples/s | 36.9 steps/s
[Step=53800 Epoch=263.8] | Loss=0.00370 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=15.655 | 4400.8 samples/s | 68.8 steps/s
[Step=53850 Epoch=264.1] | Loss=0.00368 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=15.658 | 4608.1 samples/s | 72.0 steps/s
[Step=53900 Epoch=264.3] | Loss=0.00359 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.529 | L2-Norm(final)=15.661 | 4492.8 samples/s | 70.2 steps/s
[Step=53950 Epoch=264.6] | Loss=0.00354 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.527 | L2-Norm(final)=15.663 | 2325.8 samples/s | 36.3 steps/s
[Step=54000 Epoch=264.8] | Loss=0.00350 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.524 | L2-Norm(final)=15.666 | 4506.0 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step54000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=492.8] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.146 | L2-Norm(final)=7.939 | 5014.4 samples/s | 78.4 steps/s
[Step=52050 Epoch=493.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.146 | L2-Norm(final)=7.939 | 4298.8 samples/s | 67.2 steps/s
[Step=52100 Epoch=493.7] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.146 | L2-Norm(final)=7.940 | 7421.7 samples/s | 116.0 steps/s
[Step=52150 Epoch=494.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.146 | L2-Norm(final)=7.941 | 2123.4 samples/s | 33.2 steps/s
[Step=52200 Epoch=494.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.147 | L2-Norm(final)=7.943 | 6504.7 samples/s | 101.6 steps/s
[Step=52250 Epoch=495.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.147 | L2-Norm(final)=7.944 | 2153.6 samples/s | 33.6 steps/s
[Step=52300 Epoch=495.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.147 | L2-Norm(final)=7.945 | 5884.7 samples/s | 91.9 steps/s
[Step=52350 Epoch=496.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=7.946 | 2290.7 samples/s | 35.8 steps/s
[Step=52400 Epoch=496.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=7.947 | 5333.9 samples/s | 83.3 steps/s
[Step=52450 Epoch=497.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=7.947 | 2468.6 samples/s | 38.6 steps/s
[Step=52500 Epoch=497.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=7.949 | 4807.8 samples/s | 75.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=497.5] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.149 | L2-Norm(final)=7.959 | 5462.6 samples/s | 85.4 steps/s
[Step=52550 Epoch=498.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=7.960 | 3636.6 samples/s | 56.8 steps/s
[Step=52600 Epoch=498.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.146 | L2-Norm(final)=7.961 | 6142.8 samples/s | 96.0 steps/s
[Step=52650 Epoch=498.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=7.961 | 2029.6 samples/s | 31.7 steps/s
[Step=52700 Epoch=499.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=7.962 | 5551.4 samples/s | 86.7 steps/s
[Step=52750 Epoch=499.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=7.963 | 2090.6 samples/s | 32.7 steps/s
[Step=52800 Epoch=500.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=7.963 | 4947.6 samples/s | 77.3 steps/s
[Step=52850 Epoch=500.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=7.964 | 2170.4 samples/s | 33.9 steps/s
[Step=52900 Epoch=501.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.134 | L2-Norm(final)=7.964 | 4648.9 samples/s | 72.6 steps/s
[Step=52950 Epoch=501.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=7.965 | 2264.9 samples/s | 35.4 steps/s
[Step=53000 Epoch=502.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.129 | L2-Norm(final)=7.965 | 4295.1 samples/s | 67.1 steps/s
[Step=53050 Epoch=502.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.126 | L2-Norm(final)=7.966 | 2349.8 samples/s | 36.7 steps/s
[Step=53100 Epoch=503.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.124 | L2-Norm(final)=7.966 | 4069.5 samples/s | 63.6 steps/s
[Step=53150 Epoch=503.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=7.967 | 2393.1 samples/s | 37.4 steps/s
[Step=53200 Epoch=504.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.118 | L2-Norm(final)=7.967 | 4254.5 samples/s | 66.5 steps/s
[Step=53250 Epoch=504.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.115 | L2-Norm(final)=7.967 | 2371.1 samples/s | 37.0 steps/s
[Step=53300 Epoch=505.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.112 | L2-Norm(final)=7.968 | 4192.0 samples/s | 65.5 steps/s
[Step=53350 Epoch=505.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.110 | L2-Norm(final)=7.968 | 2512.5 samples/s | 39.3 steps/s
[Step=53400 Epoch=506.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.107 | L2-Norm(final)=7.969 | 3781.3 samples/s | 59.1 steps/s
[Step=53450 Epoch=506.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=7.969 | 6409.6 samples/s | 100.2 steps/s
[Step=53500 Epoch=507.0] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=7.969 | 1993.9 samples/s | 31.2 steps/s
[Step=53550 Epoch=507.4] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=7.970 | 5834.3 samples/s | 91.2 steps/s
[Step=53600 Epoch=507.9] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=7.970 | 2057.3 samples/s | 32.1 steps/s
[Step=53650 Epoch=508.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.091 | L2-Norm(final)=7.970 | 5335.4 samples/s | 83.4 steps/s
[Step=53700 Epoch=508.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=7.971 | 2151.5 samples/s | 33.6 steps/s
[Step=53750 Epoch=509.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=7.971 | 4708.2 samples/s | 73.6 steps/s
[Step=53800 Epoch=509.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=7.972 | 2246.6 samples/s | 35.1 steps/s
[Step=53850 Epoch=510.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=7.972 | 4444.1 samples/s | 69.4 steps/s
[Step=53900 Epoch=510.7] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=7.972 | 2326.8 samples/s | 36.4 steps/s
[Step=53950 Epoch=511.2] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=7.973 | 4213.3 samples/s | 65.8 steps/s
[Step=54000 Epoch=511.7] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.067 | L2-Norm(final)=7.973 | 2319.8 samples/s | 36.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step54000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=494.7] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.061 | L2-Norm(final)=8.887 | 5468.7 samples/s | 85.4 steps/s
[Step=52050 Epoch=495.1] | Loss=0.00005 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=8.899 | 4088.9 samples/s | 63.9 steps/s
[Step=52100 Epoch=495.6] | Loss=0.00005 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=8.916 | 7335.4 samples/s | 114.6 steps/s
[Step=52150 Epoch=496.1] | Loss=0.00005 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=8.934 | 2151.8 samples/s | 33.6 steps/s
[Step=52200 Epoch=496.6] | Loss=0.00004 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=8.948 | 6555.4 samples/s | 102.4 steps/s
[Step=52250 Epoch=497.0] | Loss=0.00004 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.093 | L2-Norm(final)=8.961 | 2181.0 samples/s | 34.1 steps/s
[Step=52300 Epoch=497.5] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.096 | L2-Norm(final)=8.973 | 5999.6 samples/s | 93.7 steps/s
[Step=52350 Epoch=498.0] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.098 | L2-Norm(final)=8.984 | 2276.8 samples/s | 35.6 steps/s
[Step=52400 Epoch=498.5] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.994 | 5395.0 samples/s | 84.3 steps/s
[Step=52450 Epoch=498.9] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.102 | L2-Norm(final)=9.004 | 2437.5 samples/s | 38.1 steps/s
[Step=52500 Epoch=499.4] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=9.013 | 4868.5 samples/s | 76.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=499.4] | Loss=0.00007 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=9.104 | 5027.9 samples/s | 78.6 steps/s
[Step=52550 Epoch=499.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.104 | L2-Norm(final)=9.111 | 3808.3 samples/s | 59.5 steps/s
[Step=52600 Epoch=500.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.091 | L2-Norm(final)=9.117 | 6371.9 samples/s | 99.6 steps/s
[Step=52650 Epoch=500.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.075 | L2-Norm(final)=9.121 | 2025.8 samples/s | 31.7 steps/s
[Step=52700 Epoch=501.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.059 | L2-Norm(final)=9.124 | 5665.1 samples/s | 88.5 steps/s
[Step=52750 Epoch=501.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.043 | L2-Norm(final)=9.127 | 2130.5 samples/s | 33.3 steps/s
[Step=52800 Epoch=502.3] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.026 | L2-Norm(final)=9.129 | 5009.9 samples/s | 78.3 steps/s
[Step=52850 Epoch=502.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.132 | 2165.1 samples/s | 33.8 steps/s
[Step=52900 Epoch=503.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.992 | L2-Norm(final)=9.134 | 4583.6 samples/s | 71.6 steps/s
[Step=52950 Epoch=503.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.975 | L2-Norm(final)=9.136 | 2243.8 samples/s | 35.1 steps/s
[Step=53000 Epoch=504.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=9.138 | 4395.4 samples/s | 68.7 steps/s
[Step=53050 Epoch=504.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.940 | L2-Norm(final)=9.140 | 2356.9 samples/s | 36.8 steps/s
[Step=53100 Epoch=505.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=9.142 | 4172.8 samples/s | 65.2 steps/s
[Step=53150 Epoch=505.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=9.144 | 2366.9 samples/s | 37.0 steps/s
[Step=53200 Epoch=506.1] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.887 | L2-Norm(final)=9.146 | 4192.4 samples/s | 65.5 steps/s
[Step=53250 Epoch=506.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.870 | L2-Norm(final)=9.148 | 2386.4 samples/s | 37.3 steps/s
[Step=53300 Epoch=507.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.852 | L2-Norm(final)=9.150 | 4222.7 samples/s | 66.0 steps/s
[Step=53350 Epoch=507.5] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.834 | L2-Norm(final)=9.152 | 2419.5 samples/s | 37.8 steps/s
[Step=53400 Epoch=508.0] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.816 | L2-Norm(final)=9.154 | 4253.5 samples/s | 66.5 steps/s
[Step=53450 Epoch=508.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.797 | L2-Norm(final)=9.157 | 6330.5 samples/s | 98.9 steps/s
[Step=53500 Epoch=508.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.779 | L2-Norm(final)=9.159 | 2025.3 samples/s | 31.6 steps/s
[Step=53550 Epoch=509.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.761 | L2-Norm(final)=9.161 | 5892.8 samples/s | 92.1 steps/s
[Step=53600 Epoch=509.9] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.743 | L2-Norm(final)=9.163 | 2051.2 samples/s | 32.1 steps/s
[Step=53650 Epoch=510.3] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.724 | L2-Norm(final)=9.166 | 5338.4 samples/s | 83.4 steps/s
[Step=53700 Epoch=510.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.705 | L2-Norm(final)=9.168 | 2117.7 samples/s | 33.1 steps/s
[Step=53750 Epoch=511.3] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.687 | L2-Norm(final)=9.171 | 4837.0 samples/s | 75.6 steps/s
[Step=53800 Epoch=511.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.668 | L2-Norm(final)=9.173 | 2229.0 samples/s | 34.8 steps/s
[Step=53850 Epoch=512.2] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.649 | L2-Norm(final)=9.176 | 4482.7 samples/s | 70.0 steps/s
[Step=53900 Epoch=512.7] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.630 | L2-Norm(final)=9.178 | 2351.1 samples/s | 36.7 steps/s
[Step=53950 Epoch=513.2] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.611 | L2-Norm(final)=9.181 | 4145.9 samples/s | 64.8 steps/s
[Step=54000 Epoch=513.7] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.592 | L2-Norm(final)=9.184 | 2365.1 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step54000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=496.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=8.380 | 5186.8 samples/s | 81.0 steps/s
[Step=52050 Epoch=497.0] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=8.382 | 4029.3 samples/s | 63.0 steps/s
[Step=52100 Epoch=497.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.386 | 7581.1 samples/s | 118.5 steps/s
[Step=52150 Epoch=498.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.138 | L2-Norm(final)=8.389 | 2129.1 samples/s | 33.3 steps/s
[Step=52200 Epoch=498.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=8.393 | 6688.2 samples/s | 104.5 steps/s
[Step=52250 Epoch=499.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.140 | L2-Norm(final)=8.397 | 2154.5 samples/s | 33.7 steps/s
[Step=52300 Epoch=499.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.401 | 5986.0 samples/s | 93.5 steps/s
[Step=52350 Epoch=499.9] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.404 | 2196.1 samples/s | 34.3 steps/s
[Step=52400 Epoch=500.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.408 | 5565.0 samples/s | 87.0 steps/s
[Step=52450 Epoch=500.9] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.412 | 2231.8 samples/s | 34.9 steps/s
[Step=52500 Epoch=501.3] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.415 | 5152.1 samples/s | 80.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=501.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=8.452 | 5284.7 samples/s | 82.6 steps/s
[Step=52550 Epoch=501.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.455 | 3783.2 samples/s | 59.1 steps/s
[Step=52600 Epoch=502.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=8.458 | 6217.9 samples/s | 97.2 steps/s
[Step=52650 Epoch=502.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=8.460 | 2029.0 samples/s | 31.7 steps/s
[Step=52700 Epoch=503.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=8.461 | 5639.1 samples/s | 88.1 steps/s
[Step=52750 Epoch=503.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.119 | L2-Norm(final)=8.463 | 2070.7 samples/s | 32.4 steps/s
[Step=52800 Epoch=504.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=8.464 | 5314.1 samples/s | 83.0 steps/s
[Step=52850 Epoch=504.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.107 | L2-Norm(final)=8.465 | 2117.3 samples/s | 33.1 steps/s
[Step=52900 Epoch=505.2] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.466 | 4954.7 samples/s | 77.4 steps/s
[Step=52950 Epoch=505.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=8.467 | 2204.9 samples/s | 34.5 steps/s
[Step=53000 Epoch=506.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.087 | L2-Norm(final)=8.468 | 4612.3 samples/s | 72.1 steps/s
[Step=53050 Epoch=506.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=8.469 | 2297.6 samples/s | 35.9 steps/s
[Step=53100 Epoch=507.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=8.470 | 4291.5 samples/s | 67.1 steps/s
[Step=53150 Epoch=507.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.067 | L2-Norm(final)=8.471 | 2303.1 samples/s | 36.0 steps/s
[Step=53200 Epoch=508.0] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=8.472 | 4255.2 samples/s | 66.5 steps/s
[Step=53250 Epoch=508.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.053 | L2-Norm(final)=8.473 | 2376.5 samples/s | 37.1 steps/s
[Step=53300 Epoch=509.0] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.046 | L2-Norm(final)=8.474 | 4233.9 samples/s | 66.2 steps/s
[Step=53350 Epoch=509.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.039 | L2-Norm(final)=8.475 | 2392.8 samples/s | 37.4 steps/s
[Step=53400 Epoch=509.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.032 | L2-Norm(final)=8.476 | 4267.1 samples/s | 66.7 steps/s
[Step=53450 Epoch=510.4] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.024 | L2-Norm(final)=8.476 | 2302.6 samples/s | 36.0 steps/s
[Step=53500 Epoch=510.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=8.477 | 4245.3 samples/s | 66.3 steps/s
[Step=53550 Epoch=511.4] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=8.478 | 6933.6 samples/s | 108.3 steps/s
[Step=53600 Epoch=511.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.002 | L2-Norm(final)=8.479 | 1948.4 samples/s | 30.4 steps/s
[Step=53650 Epoch=512.3] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=8.480 | 6309.2 samples/s | 98.6 steps/s
[Step=53700 Epoch=512.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=8.481 | 2001.9 samples/s | 31.3 steps/s
[Step=53750 Epoch=513.3] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.979 | L2-Norm(final)=8.482 | 5759.0 samples/s | 90.0 steps/s
[Step=53800 Epoch=513.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.971 | L2-Norm(final)=8.483 | 2074.7 samples/s | 32.4 steps/s
[Step=53850 Epoch=514.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.963 | L2-Norm(final)=8.484 | 5313.7 samples/s | 83.0 steps/s
[Step=53900 Epoch=514.7] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.955 | L2-Norm(final)=8.484 | 2151.9 samples/s | 33.6 steps/s
[Step=53950 Epoch=515.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.947 | L2-Norm(final)=8.485 | 4909.0 samples/s | 76.7 steps/s
[Step=54000 Epoch=515.7] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.938 | L2-Norm(final)=8.486 | 2200.6 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step54000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=490.0] | Loss=0.00032 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=8.219 | 5422.8 samples/s | 84.7 steps/s
[Step=52050 Epoch=490.5] | Loss=0.00006 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=8.226 | 3975.8 samples/s | 62.1 steps/s
[Step=52100 Epoch=490.9] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.191 | L2-Norm(final)=8.238 | 7308.0 samples/s | 114.2 steps/s
[Step=52150 Epoch=491.4] | Loss=0.00006 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.198 | L2-Norm(final)=8.250 | 2161.8 samples/s | 33.8 steps/s
[Step=52200 Epoch=491.9] | Loss=0.00005 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.203 | L2-Norm(final)=8.259 | 6270.4 samples/s | 98.0 steps/s
[Step=52250 Epoch=492.3] | Loss=0.00005 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.207 | L2-Norm(final)=8.268 | 2223.4 samples/s | 34.7 steps/s
[Step=52300 Epoch=492.8] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.210 | L2-Norm(final)=8.276 | 5500.3 samples/s | 85.9 steps/s
[Step=52350 Epoch=493.3] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.212 | L2-Norm(final)=8.284 | 2308.4 samples/s | 36.1 steps/s
[Step=52400 Epoch=493.8] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=8.291 | 5011.1 samples/s | 78.3 steps/s
[Step=52450 Epoch=494.2] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=8.298 | 2505.2 samples/s | 39.1 steps/s
[Step=52500 Epoch=494.7] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.218 | L2-Norm(final)=8.306 | 4667.4 samples/s | 72.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=494.7] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.234 | L2-Norm(final)=8.379 | 5157.2 samples/s | 80.6 steps/s
[Step=52550 Epoch=495.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.229 | L2-Norm(final)=8.384 | 3876.5 samples/s | 60.6 steps/s
[Step=52600 Epoch=495.6] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.218 | L2-Norm(final)=8.387 | 5996.7 samples/s | 93.7 steps/s
[Step=52650 Epoch=496.1] | Loss=0.00002 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.211 | L2-Norm(final)=8.392 | 2039.1 samples/s | 31.9 steps/s
[Step=52700 Epoch=496.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.201 | L2-Norm(final)=8.396 | 5360.9 samples/s | 83.8 steps/s
[Step=52750 Epoch=497.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.189 | L2-Norm(final)=8.399 | 2127.5 samples/s | 33.2 steps/s
[Step=52800 Epoch=497.5] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.177 | L2-Norm(final)=8.401 | 4929.6 samples/s | 77.0 steps/s
[Step=52850 Epoch=498.0] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.164 | L2-Norm(final)=8.403 | 2199.0 samples/s | 34.4 steps/s
[Step=52900 Epoch=498.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.150 | L2-Norm(final)=8.404 | 4421.9 samples/s | 69.1 steps/s
[Step=52950 Epoch=498.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.136 | L2-Norm(final)=8.406 | 2330.2 samples/s | 36.4 steps/s
[Step=53000 Epoch=499.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.122 | L2-Norm(final)=8.407 | 4283.8 samples/s | 66.9 steps/s
[Step=53050 Epoch=499.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=8.408 | 2418.7 samples/s | 37.8 steps/s
[Step=53100 Epoch=500.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=8.410 | 4169.3 samples/s | 65.1 steps/s
[Step=53150 Epoch=500.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.079 | L2-Norm(final)=8.411 | 2413.7 samples/s | 37.7 steps/s
[Step=53200 Epoch=501.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=8.412 | 4208.6 samples/s | 65.8 steps/s
[Step=53250 Epoch=501.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.049 | L2-Norm(final)=8.413 | 2678.7 samples/s | 41.9 steps/s
[Step=53300 Epoch=502.2] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=8.414 | 3613.7 samples/s | 56.5 steps/s
[Step=53350 Epoch=502.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.019 | L2-Norm(final)=8.416 | 6237.2 samples/s | 97.5 steps/s
[Step=53400 Epoch=503.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=8.417 | 2018.3 samples/s | 31.5 steps/s
[Step=53450 Epoch=503.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=8.418 | 5522.8 samples/s | 86.3 steps/s
[Step=53500 Epoch=504.1] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=8.419 | 2045.8 samples/s | 32.0 steps/s
[Step=53550 Epoch=504.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=8.420 | 4951.1 samples/s | 77.4 steps/s
[Step=53600 Epoch=505.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.941 | L2-Norm(final)=8.421 | 2207.2 samples/s | 34.5 steps/s
[Step=53650 Epoch=505.5] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.925 | L2-Norm(final)=8.423 | 4441.5 samples/s | 69.4 steps/s
[Step=53700 Epoch=506.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.909 | L2-Norm(final)=8.424 | 2333.5 samples/s | 36.5 steps/s
[Step=53750 Epoch=506.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.893 | L2-Norm(final)=8.425 | 4150.0 samples/s | 64.8 steps/s
[Step=53800 Epoch=506.9] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.877 | L2-Norm(final)=8.426 | 2390.8 samples/s | 37.4 steps/s
[Step=53850 Epoch=507.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.860 | L2-Norm(final)=8.428 | 4282.8 samples/s | 66.9 steps/s
[Step=53900 Epoch=507.9] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.844 | L2-Norm(final)=8.429 | 2397.7 samples/s | 37.5 steps/s
[Step=53950 Epoch=508.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.827 | L2-Norm(final)=8.431 | 4115.8 samples/s | 64.3 steps/s
[Step=54000 Epoch=508.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.810 | L2-Norm(final)=8.432 | 2564.4 samples/s | 40.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step54000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=495.6] | Loss=0.00003 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.213 | L2-Norm(final)=8.959 | 5074.9 samples/s | 79.3 steps/s
[Step=52050 Epoch=496.1] | Loss=0.00005 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=8.962 | 4254.8 samples/s | 66.5 steps/s
[Step=52100 Epoch=496.6] | Loss=0.00004 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.215 | L2-Norm(final)=8.968 | 7426.9 samples/s | 116.0 steps/s
[Step=52150 Epoch=497.0] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.217 | L2-Norm(final)=8.972 | 2114.6 samples/s | 33.0 steps/s
[Step=52200 Epoch=497.5] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.218 | L2-Norm(final)=8.977 | 6874.3 samples/s | 107.4 steps/s
[Step=52250 Epoch=498.0] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.219 | L2-Norm(final)=8.982 | 2189.4 samples/s | 34.2 steps/s
[Step=52300 Epoch=498.5] | Loss=0.00004 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.221 | L2-Norm(final)=8.987 | 6248.8 samples/s | 97.6 steps/s
[Step=52350 Epoch=498.9] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.222 | L2-Norm(final)=8.992 | 2245.9 samples/s | 35.1 steps/s
[Step=52400 Epoch=499.4] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.223 | L2-Norm(final)=8.997 | 5674.9 samples/s | 88.7 steps/s
[Step=52450 Epoch=499.9] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.223 | L2-Norm(final)=9.002 | 2314.0 samples/s | 36.2 steps/s
[Step=52500 Epoch=500.4] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.224 | L2-Norm(final)=9.007 | 5264.6 samples/s | 82.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=500.4] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.231 | L2-Norm(final)=9.054 | 5311.1 samples/s | 83.0 steps/s
[Step=52550 Epoch=500.8] | Loss=0.00002 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.230 | L2-Norm(final)=9.059 | 3756.6 samples/s | 58.7 steps/s
[Step=52600 Epoch=501.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.226 | L2-Norm(final)=9.062 | 6294.7 samples/s | 98.4 steps/s
[Step=52650 Epoch=501.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.220 | L2-Norm(final)=9.065 | 1982.7 samples/s | 31.0 steps/s
[Step=52700 Epoch=502.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=9.066 | 5655.2 samples/s | 88.4 steps/s
[Step=52750 Epoch=502.8] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.208 | L2-Norm(final)=9.068 | 2086.7 samples/s | 32.6 steps/s
[Step=52800 Epoch=503.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.201 | L2-Norm(final)=9.069 | 5299.2 samples/s | 82.8 steps/s
[Step=52850 Epoch=503.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.194 | L2-Norm(final)=9.070 | 2151.7 samples/s | 33.6 steps/s
[Step=52900 Epoch=504.2] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.188 | L2-Norm(final)=9.072 | 4911.5 samples/s | 76.7 steps/s
[Step=52950 Epoch=504.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=9.073 | 2154.0 samples/s | 33.7 steps/s
[Step=53000 Epoch=505.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.173 | L2-Norm(final)=9.074 | 4589.2 samples/s | 71.7 steps/s
[Step=53050 Epoch=505.6] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.166 | L2-Norm(final)=9.074 | 2276.4 samples/s | 35.6 steps/s
[Step=53100 Epoch=506.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.158 | L2-Norm(final)=9.075 | 4326.2 samples/s | 67.6 steps/s
[Step=53150 Epoch=506.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.151 | L2-Norm(final)=9.076 | 2359.9 samples/s | 36.9 steps/s
[Step=53200 Epoch=507.0] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=9.077 | 4133.4 samples/s | 64.6 steps/s
[Step=53250 Epoch=507.5] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=9.078 | 2411.1 samples/s | 37.7 steps/s
[Step=53300 Epoch=508.0] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.128 | L2-Norm(final)=9.079 | 4212.2 samples/s | 65.8 steps/s
[Step=53350 Epoch=508.5] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.120 | L2-Norm(final)=9.079 | 2363.8 samples/s | 36.9 steps/s
[Step=53400 Epoch=509.0] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.112 | L2-Norm(final)=9.080 | 4272.2 samples/s | 66.8 steps/s
[Step=53450 Epoch=509.4] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=9.081 | 2377.0 samples/s | 37.1 steps/s
[Step=53500 Epoch=509.9] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.095 | L2-Norm(final)=9.082 | 4179.8 samples/s | 65.3 steps/s
[Step=53550 Epoch=510.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.087 | L2-Norm(final)=9.083 | 6962.2 samples/s | 108.8 steps/s
[Step=53600 Epoch=510.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=9.083 | 1938.7 samples/s | 30.3 steps/s
[Step=53650 Epoch=511.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.070 | L2-Norm(final)=9.084 | 6368.2 samples/s | 99.5 steps/s
[Step=53700 Epoch=511.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.061 | L2-Norm(final)=9.085 | 2001.0 samples/s | 31.3 steps/s
[Step=53750 Epoch=512.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.052 | L2-Norm(final)=9.086 | 5842.2 samples/s | 91.3 steps/s
[Step=53800 Epoch=512.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.043 | L2-Norm(final)=9.087 | 2044.1 samples/s | 31.9 steps/s
[Step=53850 Epoch=513.2] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=9.088 | 5331.1 samples/s | 83.3 steps/s
[Step=53900 Epoch=513.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.025 | L2-Norm(final)=9.088 | 2145.0 samples/s | 33.5 steps/s
[Step=53950 Epoch=514.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=9.089 | 4954.4 samples/s | 77.4 steps/s
[Step=54000 Epoch=514.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.007 | L2-Norm(final)=9.090 | 2211.9 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10834 | acc=0.9596 | tpr=0.9736 | fpr=0.0709 | 4893.9 samples/s | 19.1 steps/s
Avg test loss: 0.11380, Avg test acc: 0.95741, Avg tpr: 0.97132, Avg fpr: 0.07320, total FA: 571

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11936 | acc=0.9573 | tpr=0.9715 | fpr=0.0733 | 4812.6 samples/s | 18.8 steps/s
Avg test loss: 0.12241, Avg test acc: 0.95613, Avg tpr: 0.96940, Avg fpr: 0.07307, total FA: 570

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10812 | acc=0.9577 | tpr=0.9723 | fpr=0.0741 | 4628.7 samples/s | 18.1 steps/s
Avg test loss: 0.11030, Avg test acc: 0.95641, Avg tpr: 0.97045, Avg fpr: 0.07448, total FA: 581

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10610 | acc=0.9587 | tpr=0.9701 | fpr=0.0662 | 4623.4 samples/s | 18.1 steps/s
Avg test loss: 0.11191, Avg test acc: 0.95757, Avg tpr: 0.97039, Avg fpr: 0.07063, total FA: 551

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11063 | acc=0.9594 | tpr=0.9727 | fpr=0.0696 | 4938.4 samples/s | 19.3 steps/s
Avg test loss: 0.11862, Avg test acc: 0.95801, Avg tpr: 0.97196, Avg fpr: 0.07268, total FA: 567

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.68980 | acc=0.2857 | tpr=0.0162 | fpr=0.1291 | 4793.5 samples/s | 18.7 steps/s
Avg test loss: 5.69512, Avg test acc: 0.28468, Avg tpr: 0.01708, Avg fpr: 0.12678, total FA: 989

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.69287 | acc=0.2959 | tpr=0.0055 | fpr=0.0736 | 4822.5 samples/s | 18.8 steps/s
Avg test loss: 4.70783, Avg test acc: 0.29297, Avg tpr: 0.00600, Avg fpr: 0.07589, total FA: 592

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.30859 | acc=0.2811 | tpr=0.0165 | fpr=0.1444 | 4780.3 samples/s | 18.7 steps/s
Avg test loss: 5.30514, Avg test acc: 0.27807, Avg tpr: 0.01649, Avg fpr: 0.14665, total FA: 1144

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.41561 | acc=0.2926 | tpr=0.0134 | fpr=0.1011 | 4774.7 samples/s | 18.7 steps/s
Avg test loss: 5.41027, Avg test acc: 0.29089, Avg tpr: 0.01434, Avg fpr: 0.10088, total FA: 787

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.92542 | acc=0.2964 | tpr=0.0177 | fpr=0.0984 | 4765.5 samples/s | 18.6 steps/s
Avg test loss: 4.93303, Avg test acc: 0.29526, Avg tpr: 0.01836, Avg fpr: 0.09576, total FA: 747

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.87672 | acc=0.0859 | tpr=0.5973 | fpr=0.9233 | 4988.0 samples/s | 19.5 steps/s
[Step= 100] | Loss=5.85005 | acc=0.0891 | tpr=0.5821 | fpr=0.9201 | 7099.1 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.86495 | acc=0.0900 | tpr=0.5720 | fpr=0.9189 | 7110.3 samples/s | 27.8 steps/s
[Step= 200] | Loss=5.86244 | acc=0.0897 | tpr=0.5585 | fpr=0.9189 | 8145.5 samples/s | 31.8 steps/s
[Step= 250] | Loss=5.87071 | acc=0.0905 | tpr=0.5642 | fpr=0.9181 | 8258.9 samples/s | 32.3 steps/s
[Step= 300] | Loss=5.86774 | acc=0.0908 | tpr=0.5738 | fpr=0.9180 | 7723.3 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.86298 | acc=0.0913 | tpr=0.5686 | fpr=0.9174 | 8155.5 samples/s | 31.9 steps/s
[Step= 400] | Loss=5.85789 | acc=0.0915 | tpr=0.5651 | fpr=0.9171 | 7339.1 samples/s | 28.7 steps/s
[Step= 450] | Loss=5.86275 | acc=0.0913 | tpr=0.5633 | fpr=0.9173 | 8157.1 samples/s | 31.9 steps/s
[Step= 500] | Loss=5.86696 | acc=0.0911 | tpr=0.5590 | fpr=0.9174 | 7934.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.86993 | acc=0.0910 | tpr=0.5583 | fpr=0.9175 | 13692.8 samples/s | 53.5 steps/s
Avg test loss: 5.87177, Avg test acc: 0.09092, Avg tpr: 0.55824, Avg fpr: 0.91758, total FA: 127404

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.51998 | acc=0.1039 | tpr=0.5354 | fpr=0.9038 | 4860.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.49937 | acc=0.1042 | tpr=0.5373 | fpr=0.9039 | 6879.8 samples/s | 26.9 steps/s
[Step= 150] | Loss=5.50121 | acc=0.1044 | tpr=0.5447 | fpr=0.9037 | 8088.6 samples/s | 31.6 steps/s
[Step= 200] | Loss=5.49677 | acc=0.1044 | tpr=0.5388 | fpr=0.9035 | 7797.6 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.50727 | acc=0.1045 | tpr=0.5397 | fpr=0.9035 | 7564.4 samples/s | 29.5 steps/s
[Step= 300] | Loss=5.50131 | acc=0.1043 | tpr=0.5455 | fpr=0.9037 | 8121.0 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.49829 | acc=0.1045 | tpr=0.5441 | fpr=0.9035 | 8027.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.49576 | acc=0.1049 | tpr=0.5460 | fpr=0.9032 | 7701.8 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.49815 | acc=0.1045 | tpr=0.5424 | fpr=0.9035 | 7973.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.50192 | acc=0.1043 | tpr=0.5414 | fpr=0.9036 | 7745.6 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.50489 | acc=0.1042 | tpr=0.5352 | fpr=0.9037 | 14356.4 samples/s | 56.1 steps/s
Avg test loss: 5.50731, Avg test acc: 0.10410, Avg tpr: 0.53487, Avg fpr: 0.90373, total FA: 125481

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.86729 | acc=0.0801 | tpr=0.3717 | fpr=0.9252 | 4918.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.83595 | acc=0.0831 | tpr=0.3731 | fpr=0.9223 | 7032.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.84354 | acc=0.0843 | tpr=0.3746 | fpr=0.9210 | 7798.2 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.84474 | acc=0.0841 | tpr=0.3694 | fpr=0.9211 | 8053.3 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.84419 | acc=0.0847 | tpr=0.3747 | fpr=0.9206 | 7598.4 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.84384 | acc=0.0849 | tpr=0.3855 | fpr=0.9206 | 7642.7 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.83851 | acc=0.0854 | tpr=0.3813 | fpr=0.9200 | 8215.6 samples/s | 32.1 steps/s
[Step= 400] | Loss=5.83207 | acc=0.0858 | tpr=0.3775 | fpr=0.9195 | 7803.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.83393 | acc=0.0859 | tpr=0.3754 | fpr=0.9193 | 7984.6 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.83632 | acc=0.0856 | tpr=0.3718 | fpr=0.9196 | 7791.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=5.83862 | acc=0.0854 | tpr=0.3721 | fpr=0.9198 | 14703.8 samples/s | 57.4 steps/s
Avg test loss: 5.83958, Avg test acc: 0.08523, Avg tpr: 0.37203, Avg fpr: 0.91998, total FA: 127738

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.18778 | acc=0.1137 | tpr=0.5841 | fpr=0.8948 | 4633.8 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.17556 | acc=0.1127 | tpr=0.5842 | fpr=0.8961 | 7360.7 samples/s | 28.8 steps/s
[Step= 150] | Loss=5.18027 | acc=0.1117 | tpr=0.5720 | fpr=0.8967 | 8040.7 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.16945 | acc=0.1115 | tpr=0.5661 | fpr=0.8967 | 7884.3 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.17275 | acc=0.1119 | tpr=0.5668 | fpr=0.8964 | 7857.7 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.17149 | acc=0.1118 | tpr=0.5658 | fpr=0.8965 | 7853.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.16754 | acc=0.1117 | tpr=0.5636 | fpr=0.8965 | 7990.8 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.15974 | acc=0.1121 | tpr=0.5542 | fpr=0.8959 | 8064.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.16417 | acc=0.1117 | tpr=0.5540 | fpr=0.8963 | 7834.9 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.16739 | acc=0.1113 | tpr=0.5480 | fpr=0.8966 | 7251.1 samples/s | 28.3 steps/s
[Step= 550] | Loss=5.17115 | acc=0.1113 | tpr=0.5464 | fpr=0.8966 | 15245.7 samples/s | 59.6 steps/s
Avg test loss: 5.17177, Avg test acc: 0.11117, Avg tpr: 0.54675, Avg fpr: 0.89674, total FA: 124511

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.33631 | acc=0.0934 | tpr=0.5354 | fpr=0.9146 | 4992.6 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.30849 | acc=0.0958 | tpr=0.5416 | fpr=0.9125 | 6734.1 samples/s | 26.3 steps/s
[Step= 150] | Loss=6.30878 | acc=0.0963 | tpr=0.5403 | fpr=0.9119 | 7871.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.30522 | acc=0.0962 | tpr=0.5311 | fpr=0.9117 | 8381.8 samples/s | 32.7 steps/s
[Step= 250] | Loss=6.31421 | acc=0.0970 | tpr=0.5336 | fpr=0.9109 | 7713.7 samples/s | 30.1 steps/s
[Step= 300] | Loss=6.31570 | acc=0.0970 | tpr=0.5389 | fpr=0.9111 | 7452.6 samples/s | 29.1 steps/s
[Step= 350] | Loss=6.30808 | acc=0.0972 | tpr=0.5379 | fpr=0.9108 | 8329.3 samples/s | 32.5 steps/s
[Step= 400] | Loss=6.30249 | acc=0.0977 | tpr=0.5388 | fpr=0.9104 | 7870.8 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.30400 | acc=0.0980 | tpr=0.5419 | fpr=0.9101 | 7926.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.30786 | acc=0.0979 | tpr=0.5379 | fpr=0.9101 | 7583.2 samples/s | 29.6 steps/s
[Step= 550] | Loss=6.31241 | acc=0.0977 | tpr=0.5404 | fpr=0.9103 | 14705.6 samples/s | 57.4 steps/s
Avg test loss: 6.31459, Avg test acc: 0.09760, Avg tpr: 0.54041, Avg fpr: 0.91045, total FA: 126414

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10022 | acc=0.9813 | tpr=0.9558 | fpr=0.0182 | 4812.1 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.10366 | acc=0.9812 | tpr=0.9595 | fpr=0.0184 | 7212.0 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.10703 | acc=0.9807 | tpr=0.9539 | fpr=0.0188 | 7695.0 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.10889 | acc=0.9806 | tpr=0.9574 | fpr=0.0190 | 7834.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.10721 | acc=0.9808 | tpr=0.9520 | fpr=0.0187 | 7970.7 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10992 | acc=0.9803 | tpr=0.9491 | fpr=0.0192 | 7852.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.11101 | acc=0.9800 | tpr=0.9512 | fpr=0.0195 | 7638.1 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.11201 | acc=0.9798 | tpr=0.9469 | fpr=0.0196 | 8054.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.11400 | acc=0.9795 | tpr=0.9445 | fpr=0.0199 | 7844.8 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.11309 | acc=0.9796 | tpr=0.9454 | fpr=0.0198 | 8263.5 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.11257 | acc=0.9797 | tpr=0.9427 | fpr=0.0196 | 13105.9 samples/s | 51.2 steps/s
Avg test loss: 0.11249, Avg test acc: 0.97974, Avg tpr: 0.94295, Avg fpr: 0.01959, total FA: 2720

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08422 | acc=0.9829 | tpr=0.9381 | fpr=0.0163 | 4901.2 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08730 | acc=0.9826 | tpr=0.9254 | fpr=0.0163 | 6960.9 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.09047 | acc=0.9821 | tpr=0.9265 | fpr=0.0169 | 7763.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.09244 | acc=0.9821 | tpr=0.9301 | fpr=0.0169 | 8084.3 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.09094 | acc=0.9823 | tpr=0.9284 | fpr=0.0167 | 7617.6 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.09320 | acc=0.9819 | tpr=0.9258 | fpr=0.0171 | 7981.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09373 | acc=0.9818 | tpr=0.9292 | fpr=0.0172 | 7728.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09496 | acc=0.9815 | tpr=0.9234 | fpr=0.0174 | 8352.6 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.09714 | acc=0.9813 | tpr=0.9236 | fpr=0.0176 | 7457.6 samples/s | 29.1 steps/s
[Step= 500] | Loss=0.09617 | acc=0.9814 | tpr=0.9260 | fpr=0.0176 | 7832.1 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09599 | acc=0.9814 | tpr=0.9244 | fpr=0.0175 | 14057.5 samples/s | 54.9 steps/s
Avg test loss: 0.09591, Avg test acc: 0.98145, Avg tpr: 0.92472, Avg fpr: 0.01752, total FA: 2432

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09460 | acc=0.9805 | tpr=0.9602 | fpr=0.0191 | 5022.1 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.09667 | acc=0.9811 | tpr=0.9616 | fpr=0.0186 | 6890.1 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.10062 | acc=0.9803 | tpr=0.9611 | fpr=0.0193 | 7507.1 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.10217 | acc=0.9804 | tpr=0.9639 | fpr=0.0193 | 7938.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.10041 | acc=0.9806 | tpr=0.9624 | fpr=0.0190 | 7806.8 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.10285 | acc=0.9802 | tpr=0.9556 | fpr=0.0194 | 7920.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.10367 | acc=0.9798 | tpr=0.9562 | fpr=0.0197 | 7872.8 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.10482 | acc=0.9797 | tpr=0.9546 | fpr=0.0199 | 7964.3 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.10670 | acc=0.9795 | tpr=0.9533 | fpr=0.0201 | 7517.1 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.10599 | acc=0.9795 | tpr=0.9551 | fpr=0.0201 | 8257.6 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.10562 | acc=0.9796 | tpr=0.9538 | fpr=0.0199 | 13379.6 samples/s | 52.3 steps/s
Avg test loss: 0.10554, Avg test acc: 0.97961, Avg tpr: 0.95404, Avg fpr: 0.01993, total FA: 2767

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09037 | acc=0.9815 | tpr=0.9381 | fpr=0.0177 | 4822.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09390 | acc=0.9811 | tpr=0.9424 | fpr=0.0181 | 7261.1 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.09790 | acc=0.9803 | tpr=0.9438 | fpr=0.0190 | 7530.1 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.09925 | acc=0.9805 | tpr=0.9508 | fpr=0.0190 | 7976.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09790 | acc=0.9809 | tpr=0.9485 | fpr=0.0185 | 7747.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.10006 | acc=0.9807 | tpr=0.9433 | fpr=0.0186 | 8509.8 samples/s | 33.2 steps/s
[Step= 350] | Loss=0.10078 | acc=0.9806 | tpr=0.9449 | fpr=0.0188 | 7853.1 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10127 | acc=0.9804 | tpr=0.9404 | fpr=0.0188 | 7463.3 samples/s | 29.2 steps/s
[Step= 450] | Loss=0.10327 | acc=0.9802 | tpr=0.9377 | fpr=0.0190 | 8016.3 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.10243 | acc=0.9803 | tpr=0.9401 | fpr=0.0190 | 8189.0 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.10208 | acc=0.9804 | tpr=0.9403 | fpr=0.0189 | 13231.9 samples/s | 51.7 steps/s
Avg test loss: 0.10195, Avg test acc: 0.98043, Avg tpr: 0.94057, Avg fpr: 0.01884, total FA: 2616

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09713 | acc=0.9812 | tpr=0.9292 | fpr=0.0178 | 4583.0 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.10295 | acc=0.9808 | tpr=0.9318 | fpr=0.0183 | 7163.0 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.10640 | acc=0.9799 | tpr=0.9352 | fpr=0.0192 | 7867.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.10849 | acc=0.9798 | tpr=0.9399 | fpr=0.0195 | 8086.3 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.10706 | acc=0.9802 | tpr=0.9371 | fpr=0.0190 | 7896.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.10952 | acc=0.9799 | tpr=0.9316 | fpr=0.0193 | 7825.5 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.11021 | acc=0.9798 | tpr=0.9355 | fpr=0.0194 | 7771.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.11162 | acc=0.9796 | tpr=0.9327 | fpr=0.0196 | 7874.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.11377 | acc=0.9793 | tpr=0.9309 | fpr=0.0198 | 8015.0 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.11296 | acc=0.9793 | tpr=0.9313 | fpr=0.0198 | 7896.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.11256 | acc=0.9795 | tpr=0.9304 | fpr=0.0196 | 13741.2 samples/s | 53.7 steps/s
Avg test loss: 0.11241, Avg test acc: 0.97954, Avg tpr: 0.93027, Avg fpr: 0.01956, total FA: 2716

server round 27/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=263.3] | Loss=0.00069 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=14.987 | 5592.2 samples/s | 87.4 steps/s
[Step=54050 Epoch=263.6] | Loss=0.00341 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.384 | L2-Norm(final)=14.992 | 4248.6 samples/s | 66.4 steps/s
[Step=54100 Epoch=263.8] | Loss=0.00269 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.384 | L2-Norm(final)=14.998 | 4970.7 samples/s | 77.7 steps/s
[Step=54150 Epoch=264.0] | Loss=0.00315 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.383 | L2-Norm(final)=15.004 | 5095.5 samples/s | 79.6 steps/s
[Step=54200 Epoch=264.3] | Loss=0.00307 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.383 | L2-Norm(final)=15.011 | 7647.0 samples/s | 119.5 steps/s
[Step=54250 Epoch=264.5] | Loss=0.00287 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.382 | L2-Norm(final)=15.019 | 2228.9 samples/s | 34.8 steps/s
[Step=54300 Epoch=264.8] | Loss=0.00288 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.380 | L2-Norm(final)=15.026 | 4839.1 samples/s | 75.6 steps/s
[Step=54350 Epoch=265.0] | Loss=0.00274 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.379 | L2-Norm(final)=15.033 | 4975.5 samples/s | 77.7 steps/s
[Step=54400 Epoch=265.3] | Loss=0.00270 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.377 | L2-Norm(final)=15.041 | 6471.9 samples/s | 101.1 steps/s
[Step=54450 Epoch=265.5] | Loss=0.00269 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.375 | L2-Norm(final)=15.048 | 2272.1 samples/s | 35.5 steps/s
[Step=54500 Epoch=265.8] | Loss=0.00263 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.374 | L2-Norm(final)=15.056 | 4981.2 samples/s | 77.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=265.8] | Loss=0.00015 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.357 | L2-Norm(final)=15.131 | 5543.9 samples/s | 86.6 steps/s
[Step=54550 Epoch=266.0] | Loss=0.00284 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.356 | L2-Norm(final)=15.138 | 4181.4 samples/s | 65.3 steps/s
[Step=54600 Epoch=266.2] | Loss=0.00414 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.358 | L2-Norm(final)=15.144 | 4382.8 samples/s | 68.5 steps/s
[Step=54650 Epoch=266.5] | Loss=0.00477 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.364 | L2-Norm(final)=15.151 | 4479.8 samples/s | 70.0 steps/s
[Step=54700 Epoch=266.7] | Loss=0.00521 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.370 | L2-Norm(final)=15.159 | 6495.4 samples/s | 101.5 steps/s
[Step=54750 Epoch=267.0] | Loss=0.00556 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.379 | L2-Norm(final)=15.167 | 2077.4 samples/s | 32.5 steps/s
[Step=54800 Epoch=267.2] | Loss=0.00567 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.389 | L2-Norm(final)=15.176 | 4414.0 samples/s | 69.0 steps/s
[Step=54850 Epoch=267.5] | Loss=0.00585 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.399 | L2-Norm(final)=15.185 | 4407.4 samples/s | 68.9 steps/s
[Step=54900 Epoch=267.7] | Loss=0.00632 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.408 | L2-Norm(final)=15.192 | 5909.0 samples/s | 92.3 steps/s
[Step=54950 Epoch=267.9] | Loss=0.00622 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.417 | L2-Norm(final)=15.199 | 2194.8 samples/s | 34.3 steps/s
[Step=55000 Epoch=268.2] | Loss=0.00590 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.424 | L2-Norm(final)=15.206 | 4362.4 samples/s | 68.2 steps/s
[Step=55050 Epoch=268.4] | Loss=0.00584 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.430 | L2-Norm(final)=15.213 | 4473.6 samples/s | 69.9 steps/s
[Step=55100 Epoch=268.7] | Loss=0.00576 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.435 | L2-Norm(final)=15.218 | 5356.2 samples/s | 83.7 steps/s
[Step=55150 Epoch=268.9] | Loss=0.00551 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.439 | L2-Norm(final)=15.224 | 2224.4 samples/s | 34.8 steps/s
[Step=55200 Epoch=269.2] | Loss=0.00531 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.442 | L2-Norm(final)=15.229 | 4462.1 samples/s | 69.7 steps/s
[Step=55250 Epoch=269.4] | Loss=0.00518 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.445 | L2-Norm(final)=15.235 | 4442.6 samples/s | 69.4 steps/s
[Step=55300 Epoch=269.7] | Loss=0.00506 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.447 | L2-Norm(final)=15.240 | 4975.3 samples/s | 77.7 steps/s
[Step=55350 Epoch=269.9] | Loss=0.00493 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.449 | L2-Norm(final)=15.245 | 2318.8 samples/s | 36.2 steps/s
[Step=55400 Epoch=270.1] | Loss=0.00481 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.450 | L2-Norm(final)=15.250 | 4466.6 samples/s | 69.8 steps/s
[Step=55450 Epoch=270.4] | Loss=0.00469 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.451 | L2-Norm(final)=15.254 | 4486.0 samples/s | 70.1 steps/s
[Step=55500 Epoch=270.6] | Loss=0.00457 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.452 | L2-Norm(final)=15.259 | 4466.8 samples/s | 69.8 steps/s
[Step=55550 Epoch=270.9] | Loss=0.00453 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.452 | L2-Norm(final)=15.263 | 2403.2 samples/s | 37.6 steps/s
[Step=55600 Epoch=271.1] | Loss=0.00442 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.452 | L2-Norm(final)=15.267 | 4442.7 samples/s | 69.4 steps/s
[Step=55650 Epoch=271.4] | Loss=0.00433 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.452 | L2-Norm(final)=15.271 | 4531.0 samples/s | 70.8 steps/s
[Step=55700 Epoch=271.6] | Loss=0.00427 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.451 | L2-Norm(final)=15.275 | 4384.1 samples/s | 68.5 steps/s
[Step=55750 Epoch=271.8] | Loss=0.00419 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.450 | L2-Norm(final)=15.279 | 2464.6 samples/s | 38.5 steps/s
[Step=55800 Epoch=272.1] | Loss=0.00407 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.449 | L2-Norm(final)=15.282 | 4413.0 samples/s | 69.0 steps/s
[Step=55850 Epoch=272.3] | Loss=0.00402 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.447 | L2-Norm(final)=15.286 | 4401.6 samples/s | 68.8 steps/s
[Step=55900 Epoch=272.6] | Loss=0.00400 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.446 | L2-Norm(final)=15.289 | 4431.2 samples/s | 69.2 steps/s
[Step=55950 Epoch=272.8] | Loss=0.00394 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.444 | L2-Norm(final)=15.292 | 2440.9 samples/s | 38.1 steps/s
[Step=56000 Epoch=273.1] | Loss=0.00386 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.442 | L2-Norm(final)=15.295 | 4479.2 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step56000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=263.5] | Loss=0.00549 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.097 | L2-Norm(final)=15.407 | 5254.9 samples/s | 82.1 steps/s
[Step=54050 Epoch=263.7] | Loss=0.00292 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.096 | L2-Norm(final)=15.414 | 4306.0 samples/s | 67.3 steps/s
[Step=54100 Epoch=264.0] | Loss=0.00248 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=15.422 | 5017.9 samples/s | 78.4 steps/s
[Step=54150 Epoch=264.2] | Loss=0.00213 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=15.430 | 5071.5 samples/s | 79.2 steps/s
[Step=54200 Epoch=264.5] | Loss=0.00223 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.093 | L2-Norm(final)=15.439 | 7558.0 samples/s | 118.1 steps/s
[Step=54250 Epoch=264.7] | Loss=0.00207 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=15.447 | 2197.0 samples/s | 34.3 steps/s
[Step=54300 Epoch=265.0] | Loss=0.00208 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=15.456 | 5059.9 samples/s | 79.1 steps/s
[Step=54350 Epoch=265.2] | Loss=0.00206 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.087 | L2-Norm(final)=15.464 | 4949.8 samples/s | 77.3 steps/s
[Step=54400 Epoch=265.4] | Loss=0.00211 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.085 | L2-Norm(final)=15.472 | 7134.2 samples/s | 111.5 steps/s
[Step=54450 Epoch=265.7] | Loss=0.00205 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=15.480 | 2248.5 samples/s | 35.1 steps/s
[Step=54500 Epoch=265.9] | Loss=0.00209 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=15.488 | 4988.0 samples/s | 77.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=265.9] | Loss=0.00009 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.056 | L2-Norm(final)=15.572 | 5348.4 samples/s | 83.6 steps/s
[Step=54550 Epoch=266.2] | Loss=0.00283 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.057 | L2-Norm(final)=15.579 | 4027.7 samples/s | 62.9 steps/s
[Step=54600 Epoch=266.4] | Loss=0.00401 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.059 | L2-Norm(final)=15.586 | 4489.4 samples/s | 70.1 steps/s
[Step=54650 Epoch=266.7] | Loss=0.00543 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=15.595 | 4446.4 samples/s | 69.5 steps/s
[Step=54700 Epoch=266.9] | Loss=0.00764 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.089 | L2-Norm(final)=15.602 | 6495.0 samples/s | 101.5 steps/s
[Step=54750 Epoch=267.2] | Loss=0.00703 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.106 | L2-Norm(final)=15.611 | 2067.2 samples/s | 32.3 steps/s
[Step=54800 Epoch=267.4] | Loss=0.00674 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=15.620 | 4477.7 samples/s | 70.0 steps/s
[Step=54850 Epoch=267.6] | Loss=0.00642 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=15.628 | 4347.4 samples/s | 67.9 steps/s
[Step=54900 Epoch=267.9] | Loss=0.00625 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=15.635 | 5845.2 samples/s | 91.3 steps/s
[Step=54950 Epoch=268.1] | Loss=0.00588 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=15.643 | 2151.2 samples/s | 33.6 steps/s
[Step=55000 Epoch=268.4] | Loss=0.00560 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=15.650 | 4408.6 samples/s | 68.9 steps/s
[Step=55050 Epoch=268.6] | Loss=0.00545 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.158 | L2-Norm(final)=15.656 | 4504.9 samples/s | 70.4 steps/s
[Step=55100 Epoch=268.9] | Loss=0.00528 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.162 | L2-Norm(final)=15.663 | 5524.0 samples/s | 86.3 steps/s
[Step=55150 Epoch=269.1] | Loss=0.00511 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=15.668 | 2201.8 samples/s | 34.4 steps/s
[Step=55200 Epoch=269.4] | Loss=0.00489 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.168 | L2-Norm(final)=15.674 | 4398.8 samples/s | 68.7 steps/s
[Step=55250 Epoch=269.6] | Loss=0.00480 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=15.679 | 4463.1 samples/s | 69.7 steps/s
[Step=55300 Epoch=269.8] | Loss=0.00463 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=15.684 | 5190.7 samples/s | 81.1 steps/s
[Step=55350 Epoch=270.1] | Loss=0.00456 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.688 | 2292.2 samples/s | 35.8 steps/s
[Step=55400 Epoch=270.3] | Loss=0.00440 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.692 | 4486.9 samples/s | 70.1 steps/s
[Step=55450 Epoch=270.6] | Loss=0.00431 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.696 | 4529.9 samples/s | 70.8 steps/s
[Step=55500 Epoch=270.8] | Loss=0.00428 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.700 | 4818.2 samples/s | 75.3 steps/s
[Step=55550 Epoch=271.1] | Loss=0.00427 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.704 | 2379.7 samples/s | 37.2 steps/s
[Step=55600 Epoch=271.3] | Loss=0.00418 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.173 | L2-Norm(final)=15.707 | 4345.6 samples/s | 67.9 steps/s
[Step=55650 Epoch=271.5] | Loss=0.00413 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=15.711 | 4485.3 samples/s | 70.1 steps/s
[Step=55700 Epoch=271.8] | Loss=0.00404 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.171 | L2-Norm(final)=15.714 | 4608.7 samples/s | 72.0 steps/s
[Step=55750 Epoch=272.0] | Loss=0.00397 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=15.718 | 2408.9 samples/s | 37.6 steps/s
[Step=55800 Epoch=272.3] | Loss=0.00388 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=15.721 | 4519.3 samples/s | 70.6 steps/s
[Step=55850 Epoch=272.5] | Loss=0.00381 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=15.724 | 4521.0 samples/s | 70.6 steps/s
[Step=55900 Epoch=272.8] | Loss=0.00373 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=15.727 | 4373.3 samples/s | 68.3 steps/s
[Step=55950 Epoch=273.0] | Loss=0.00368 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.164 | L2-Norm(final)=15.730 | 2446.8 samples/s | 38.2 steps/s
[Step=56000 Epoch=273.3] | Loss=0.00361 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.162 | L2-Norm(final)=15.734 | 4534.9 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step56000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=263.1] | Loss=0.00263 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=15.675 | 5400.4 samples/s | 84.4 steps/s
[Step=54050 Epoch=263.4] | Loss=0.00282 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.749 | L2-Norm(final)=15.683 | 4500.3 samples/s | 70.3 steps/s
[Step=54100 Epoch=263.6] | Loss=0.00302 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=15.692 | 5090.1 samples/s | 79.5 steps/s
[Step=54150 Epoch=263.8] | Loss=0.00285 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=15.700 | 4981.6 samples/s | 77.8 steps/s
[Step=54200 Epoch=264.1] | Loss=0.00289 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=15.709 | 7893.5 samples/s | 123.3 steps/s
[Step=54250 Epoch=264.3] | Loss=0.00265 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=15.717 | 2196.0 samples/s | 34.3 steps/s
[Step=54300 Epoch=264.6] | Loss=0.00268 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=15.726 | 5171.1 samples/s | 80.8 steps/s
[Step=54350 Epoch=264.8] | Loss=0.00264 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.746 | L2-Norm(final)=15.734 | 5051.2 samples/s | 78.9 steps/s
[Step=54400 Epoch=265.1] | Loss=0.00268 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.745 | L2-Norm(final)=15.743 | 6818.8 samples/s | 106.5 steps/s
[Step=54450 Epoch=265.3] | Loss=0.00262 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=15.752 | 2295.2 samples/s | 35.9 steps/s
[Step=54500 Epoch=265.6] | Loss=0.00267 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.743 | L2-Norm(final)=15.760 | 5075.2 samples/s | 79.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=265.6] | Loss=0.00164 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.735 | L2-Norm(final)=15.850 | 5776.1 samples/s | 90.3 steps/s
[Step=54550 Epoch=265.8] | Loss=0.00252 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.735 | L2-Norm(final)=15.859 | 3830.6 samples/s | 59.9 steps/s
[Step=54600 Epoch=266.0] | Loss=0.00345 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.739 | L2-Norm(final)=15.866 | 4454.0 samples/s | 69.6 steps/s
[Step=54650 Epoch=266.3] | Loss=0.00416 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.743 | L2-Norm(final)=15.874 | 4466.3 samples/s | 69.8 steps/s
[Step=54700 Epoch=266.5] | Loss=0.00490 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=15.882 | 6520.2 samples/s | 101.9 steps/s
[Step=54750 Epoch=266.8] | Loss=0.00515 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.758 | L2-Norm(final)=15.890 | 2109.4 samples/s | 33.0 steps/s
[Step=54800 Epoch=267.0] | Loss=0.00584 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.767 | L2-Norm(final)=15.898 | 4493.1 samples/s | 70.2 steps/s
[Step=54850 Epoch=267.3] | Loss=0.00592 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.775 | L2-Norm(final)=15.905 | 4445.9 samples/s | 69.5 steps/s
[Step=54900 Epoch=267.5] | Loss=0.00578 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.783 | L2-Norm(final)=15.912 | 5933.1 samples/s | 92.7 steps/s
[Step=54950 Epoch=267.7] | Loss=0.00554 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.790 | L2-Norm(final)=15.919 | 2185.2 samples/s | 34.1 steps/s
[Step=55000 Epoch=268.0] | Loss=0.00544 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=15.925 | 4530.4 samples/s | 70.8 steps/s
[Step=55050 Epoch=268.2] | Loss=0.00530 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.800 | L2-Norm(final)=15.931 | 4481.9 samples/s | 70.0 steps/s
[Step=55100 Epoch=268.5] | Loss=0.00532 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.804 | L2-Norm(final)=15.937 | 5384.5 samples/s | 84.1 steps/s
[Step=55150 Epoch=268.7] | Loss=0.00533 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.808 | L2-Norm(final)=15.943 | 2264.3 samples/s | 35.4 steps/s
[Step=55200 Epoch=269.0] | Loss=0.00518 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.812 | L2-Norm(final)=15.949 | 4434.0 samples/s | 69.3 steps/s
[Step=55250 Epoch=269.2] | Loss=0.00513 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.815 | L2-Norm(final)=15.954 | 4571.1 samples/s | 71.4 steps/s
[Step=55300 Epoch=269.4] | Loss=0.00502 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.819 | L2-Norm(final)=15.959 | 4887.3 samples/s | 76.4 steps/s
[Step=55350 Epoch=269.7] | Loss=0.00493 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.821 | L2-Norm(final)=15.964 | 2338.7 samples/s | 36.5 steps/s
[Step=55400 Epoch=269.9] | Loss=0.00487 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.823 | L2-Norm(final)=15.969 | 4487.4 samples/s | 70.1 steps/s
[Step=55450 Epoch=270.2] | Loss=0.00473 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.825 | L2-Norm(final)=15.974 | 4600.4 samples/s | 71.9 steps/s
[Step=55500 Epoch=270.4] | Loss=0.00464 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.826 | L2-Norm(final)=15.979 | 4493.7 samples/s | 70.2 steps/s
[Step=55550 Epoch=270.7] | Loss=0.00453 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.827 | L2-Norm(final)=15.983 | 2415.0 samples/s | 37.7 steps/s
[Step=55600 Epoch=270.9] | Loss=0.00442 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.828 | L2-Norm(final)=15.987 | 4518.9 samples/s | 70.6 steps/s
[Step=55650 Epoch=271.2] | Loss=0.00437 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.828 | L2-Norm(final)=15.991 | 4462.4 samples/s | 69.7 steps/s
[Step=55700 Epoch=271.4] | Loss=0.00429 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.828 | L2-Norm(final)=15.995 | 4470.0 samples/s | 69.8 steps/s
[Step=55750 Epoch=271.6] | Loss=0.00420 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.827 | L2-Norm(final)=15.999 | 2489.1 samples/s | 38.9 steps/s
[Step=55800 Epoch=271.9] | Loss=0.00411 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.827 | L2-Norm(final)=16.003 | 4355.8 samples/s | 68.1 steps/s
[Step=55850 Epoch=272.1] | Loss=0.00406 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.826 | L2-Norm(final)=16.007 | 4488.2 samples/s | 70.1 steps/s
[Step=55900 Epoch=272.4] | Loss=0.00403 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.825 | L2-Norm(final)=16.010 | 4489.3 samples/s | 70.1 steps/s
[Step=55950 Epoch=272.6] | Loss=0.00394 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.823 | L2-Norm(final)=16.014 | 2451.7 samples/s | 38.3 steps/s
[Step=56000 Epoch=272.9] | Loss=0.00388 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.822 | L2-Norm(final)=16.017 | 4465.9 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step56000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=263.3] | Loss=0.00118 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.471 | L2-Norm(final)=15.606 | 5137.1 samples/s | 80.3 steps/s
[Step=54050 Epoch=263.6] | Loss=0.00216 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.469 | L2-Norm(final)=15.613 | 4429.3 samples/s | 69.2 steps/s
[Step=54100 Epoch=263.8] | Loss=0.00265 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=15.622 | 5058.0 samples/s | 79.0 steps/s
[Step=54150 Epoch=264.1] | Loss=0.00256 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=15.631 | 4982.4 samples/s | 77.8 steps/s
[Step=54200 Epoch=264.3] | Loss=0.00239 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.466 | L2-Norm(final)=15.640 | 7886.6 samples/s | 123.2 steps/s
[Step=54250 Epoch=264.6] | Loss=0.00218 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.465 | L2-Norm(final)=15.650 | 2215.1 samples/s | 34.6 steps/s
[Step=54300 Epoch=264.8] | Loss=0.00210 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.463 | L2-Norm(final)=15.659 | 5056.4 samples/s | 79.0 steps/s
[Step=54350 Epoch=265.0] | Loss=0.00216 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.461 | L2-Norm(final)=15.667 | 5009.3 samples/s | 78.3 steps/s
[Step=54400 Epoch=265.3] | Loss=0.00220 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.459 | L2-Norm(final)=15.676 | 7026.8 samples/s | 109.8 steps/s
[Step=54450 Epoch=265.5] | Loss=0.00214 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.457 | L2-Norm(final)=15.685 | 2289.1 samples/s | 35.8 steps/s
[Step=54500 Epoch=265.8] | Loss=0.00212 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.456 | L2-Norm(final)=15.694 | 4959.0 samples/s | 77.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=265.8] | Loss=0.00328 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.436 | L2-Norm(final)=15.784 | 5320.9 samples/s | 83.1 steps/s
[Step=54550 Epoch=266.0] | Loss=0.00230 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.437 | L2-Norm(final)=15.793 | 4035.8 samples/s | 63.1 steps/s
[Step=54600 Epoch=266.3] | Loss=0.00337 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.440 | L2-Norm(final)=15.802 | 4449.6 samples/s | 69.5 steps/s
[Step=54650 Epoch=266.5] | Loss=0.00441 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.447 | L2-Norm(final)=15.811 | 4505.1 samples/s | 70.4 steps/s
[Step=54700 Epoch=266.7] | Loss=0.00488 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.458 | L2-Norm(final)=15.820 | 6504.1 samples/s | 101.6 steps/s
[Step=54750 Epoch=267.0] | Loss=0.00495 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.469 | L2-Norm(final)=15.830 | 2117.1 samples/s | 33.1 steps/s
[Step=54800 Epoch=267.2] | Loss=0.00562 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.478 | L2-Norm(final)=15.839 | 4404.4 samples/s | 68.8 steps/s
[Step=54850 Epoch=267.5] | Loss=0.00572 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.487 | L2-Norm(final)=15.847 | 4581.4 samples/s | 71.6 steps/s
[Step=54900 Epoch=267.7] | Loss=0.00562 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.496 | L2-Norm(final)=15.855 | 5821.3 samples/s | 91.0 steps/s
[Step=54950 Epoch=268.0] | Loss=0.00542 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.504 | L2-Norm(final)=15.863 | 2192.3 samples/s | 34.3 steps/s
[Step=55000 Epoch=268.2] | Loss=0.00528 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.511 | L2-Norm(final)=15.870 | 4454.0 samples/s | 69.6 steps/s
[Step=55050 Epoch=268.5] | Loss=0.00530 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.517 | L2-Norm(final)=15.876 | 4533.8 samples/s | 70.8 steps/s
[Step=55100 Epoch=268.7] | Loss=0.00543 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.521 | L2-Norm(final)=15.883 | 5338.8 samples/s | 83.4 steps/s
[Step=55150 Epoch=268.9] | Loss=0.00522 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.525 | L2-Norm(final)=15.888 | 2256.1 samples/s | 35.3 steps/s
[Step=55200 Epoch=269.2] | Loss=0.00500 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.529 | L2-Norm(final)=15.894 | 4533.2 samples/s | 70.8 steps/s
[Step=55250 Epoch=269.4] | Loss=0.00490 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.531 | L2-Norm(final)=15.899 | 4433.8 samples/s | 69.3 steps/s
[Step=55300 Epoch=269.7] | Loss=0.00470 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.534 | L2-Norm(final)=15.904 | 5025.7 samples/s | 78.5 steps/s
[Step=55350 Epoch=269.9] | Loss=0.00453 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.535 | L2-Norm(final)=15.909 | 2311.8 samples/s | 36.1 steps/s
[Step=55400 Epoch=270.2] | Loss=0.00445 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.536 | L2-Norm(final)=15.914 | 4509.7 samples/s | 70.5 steps/s
[Step=55450 Epoch=270.4] | Loss=0.00434 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.537 | L2-Norm(final)=15.918 | 4489.8 samples/s | 70.2 steps/s
[Step=55500 Epoch=270.6] | Loss=0.00424 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.538 | L2-Norm(final)=15.923 | 4574.4 samples/s | 71.5 steps/s
[Step=55550 Epoch=270.9] | Loss=0.00412 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.538 | L2-Norm(final)=15.927 | 2475.6 samples/s | 38.7 steps/s
[Step=55600 Epoch=271.1] | Loss=0.00406 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.538 | L2-Norm(final)=15.931 | 4366.7 samples/s | 68.2 steps/s
[Step=55650 Epoch=271.4] | Loss=0.00395 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.537 | L2-Norm(final)=15.935 | 4464.7 samples/s | 69.8 steps/s
[Step=55700 Epoch=271.6] | Loss=0.00384 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.536 | L2-Norm(final)=15.938 | 4483.9 samples/s | 70.1 steps/s
[Step=55750 Epoch=271.9] | Loss=0.00381 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.535 | L2-Norm(final)=15.942 | 2500.7 samples/s | 39.1 steps/s
[Step=55800 Epoch=272.1] | Loss=0.00373 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.534 | L2-Norm(final)=15.945 | 4464.7 samples/s | 69.8 steps/s
[Step=55850 Epoch=272.4] | Loss=0.00362 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.533 | L2-Norm(final)=15.949 | 4584.0 samples/s | 71.6 steps/s
[Step=55900 Epoch=272.6] | Loss=0.00358 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.531 | L2-Norm(final)=15.952 | 4368.1 samples/s | 68.3 steps/s
[Step=55950 Epoch=272.8] | Loss=0.00357 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.529 | L2-Norm(final)=15.955 | 2499.4 samples/s | 39.1 steps/s
[Step=56000 Epoch=273.1] | Loss=0.00352 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.527 | L2-Norm(final)=15.958 | 4476.6 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step56000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=264.8] | Loss=0.00160 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.241 | L2-Norm(final)=15.754 | 5199.1 samples/s | 81.2 steps/s
[Step=54050 Epoch=265.1] | Loss=0.00217 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.241 | L2-Norm(final)=15.761 | 4449.3 samples/s | 69.5 steps/s
[Step=54100 Epoch=265.3] | Loss=0.00225 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.242 | L2-Norm(final)=15.769 | 4946.0 samples/s | 77.3 steps/s
[Step=54150 Epoch=265.5] | Loss=0.00231 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.241 | L2-Norm(final)=15.777 | 5148.9 samples/s | 80.5 steps/s
[Step=54200 Epoch=265.8] | Loss=0.00232 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=15.785 | 7874.2 samples/s | 123.0 steps/s
[Step=54250 Epoch=266.0] | Loss=0.00221 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.238 | L2-Norm(final)=15.793 | 2184.3 samples/s | 34.1 steps/s
[Step=54300 Epoch=266.3] | Loss=0.00215 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.236 | L2-Norm(final)=15.801 | 5062.7 samples/s | 79.1 steps/s
[Step=54350 Epoch=266.5] | Loss=0.00210 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=15.809 | 4995.3 samples/s | 78.1 steps/s
[Step=54400 Epoch=266.8] | Loss=0.00206 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.232 | L2-Norm(final)=15.817 | 7473.5 samples/s | 116.8 steps/s
[Step=54450 Epoch=267.0] | Loss=0.00199 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.230 | L2-Norm(final)=15.825 | 2248.6 samples/s | 35.1 steps/s
[Step=54500 Epoch=267.3] | Loss=0.00199 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.228 | L2-Norm(final)=15.834 | 5044.0 samples/s | 78.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=267.3] | Loss=0.00029 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.208 | L2-Norm(final)=15.918 | 5267.7 samples/s | 82.3 steps/s
[Step=54550 Epoch=267.5] | Loss=0.00191 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.209 | L2-Norm(final)=15.926 | 4117.6 samples/s | 64.3 steps/s
[Step=54600 Epoch=267.7] | Loss=0.00267 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.211 | L2-Norm(final)=15.935 | 4473.6 samples/s | 69.9 steps/s
[Step=54650 Epoch=268.0] | Loss=0.00351 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.215 | L2-Norm(final)=15.942 | 4465.2 samples/s | 69.8 steps/s
[Step=54700 Epoch=268.2] | Loss=0.00505 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.223 | L2-Norm(final)=15.950 | 6760.8 samples/s | 105.6 steps/s
[Step=54750 Epoch=268.5] | Loss=0.00515 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.236 | L2-Norm(final)=15.958 | 2082.0 samples/s | 32.5 steps/s
[Step=54800 Epoch=268.7] | Loss=0.00517 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.248 | L2-Norm(final)=15.966 | 4518.3 samples/s | 70.6 steps/s
[Step=54850 Epoch=269.0] | Loss=0.00577 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.260 | L2-Norm(final)=15.974 | 4419.1 samples/s | 69.0 steps/s
[Step=54900 Epoch=269.2] | Loss=0.00572 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.271 | L2-Norm(final)=15.982 | 6304.8 samples/s | 98.5 steps/s
[Step=54950 Epoch=269.5] | Loss=0.00548 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.282 | L2-Norm(final)=15.990 | 2118.3 samples/s | 33.1 steps/s
[Step=55000 Epoch=269.7] | Loss=0.00522 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.290 | L2-Norm(final)=15.997 | 4475.3 samples/s | 69.9 steps/s
[Step=55050 Epoch=270.0] | Loss=0.00509 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.297 | L2-Norm(final)=16.004 | 4486.0 samples/s | 70.1 steps/s
[Step=55100 Epoch=270.2] | Loss=0.00505 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.302 | L2-Norm(final)=16.010 | 5846.0 samples/s | 91.3 steps/s
[Step=55150 Epoch=270.4] | Loss=0.00483 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=16.015 | 2206.5 samples/s | 34.5 steps/s
[Step=55200 Epoch=270.7] | Loss=0.00459 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.310 | L2-Norm(final)=16.021 | 4361.6 samples/s | 68.2 steps/s
[Step=55250 Epoch=270.9] | Loss=0.00445 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.313 | L2-Norm(final)=16.026 | 4486.7 samples/s | 70.1 steps/s
[Step=55300 Epoch=271.2] | Loss=0.00431 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.315 | L2-Norm(final)=16.031 | 5508.1 samples/s | 86.1 steps/s
[Step=55350 Epoch=271.4] | Loss=0.00415 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.317 | L2-Norm(final)=16.035 | 2229.9 samples/s | 34.8 steps/s
[Step=55400 Epoch=271.7] | Loss=0.00403 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=16.040 | 4490.1 samples/s | 70.2 steps/s
[Step=55450 Epoch=271.9] | Loss=0.00392 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=16.044 | 4450.7 samples/s | 69.5 steps/s
[Step=55500 Epoch=272.2] | Loss=0.00383 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=16.048 | 5235.1 samples/s | 81.8 steps/s
[Step=55550 Epoch=272.4] | Loss=0.00375 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=16.052 | 2286.7 samples/s | 35.7 steps/s
[Step=55600 Epoch=272.7] | Loss=0.00370 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=16.056 | 4474.2 samples/s | 69.9 steps/s
[Step=55650 Epoch=272.9] | Loss=0.00365 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.317 | L2-Norm(final)=16.059 | 4400.9 samples/s | 68.8 steps/s
[Step=55700 Epoch=273.1] | Loss=0.00357 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.316 | L2-Norm(final)=16.063 | 4916.3 samples/s | 76.8 steps/s
[Step=55750 Epoch=273.4] | Loss=0.00349 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.315 | L2-Norm(final)=16.066 | 2306.7 samples/s | 36.0 steps/s
[Step=55800 Epoch=273.6] | Loss=0.00339 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=16.069 | 4459.7 samples/s | 69.7 steps/s
[Step=55850 Epoch=273.9] | Loss=0.00335 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.312 | L2-Norm(final)=16.072 | 4541.1 samples/s | 71.0 steps/s
[Step=55900 Epoch=274.1] | Loss=0.00333 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.310 | L2-Norm(final)=16.076 | 4660.8 samples/s | 72.8 steps/s
[Step=55950 Epoch=274.4] | Loss=0.00336 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.309 | L2-Norm(final)=16.078 | 2408.4 samples/s | 37.6 steps/s
[Step=56000 Epoch=274.6] | Loss=0.00331 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=16.081 | 4444.8 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step56000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=511.7] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.931 | L2-Norm(final)=7.984 | 5142.6 samples/s | 80.4 steps/s
[Step=54050 Epoch=512.2] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.935 | L2-Norm(final)=7.988 | 4270.3 samples/s | 66.7 steps/s
[Step=54100 Epoch=512.6] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.938 | L2-Norm(final)=7.992 | 7262.3 samples/s | 113.5 steps/s
[Step=54150 Epoch=513.1] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.940 | L2-Norm(final)=7.996 | 2177.0 samples/s | 34.0 steps/s
[Step=54200 Epoch=513.6] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.941 | L2-Norm(final)=8.000 | 6233.6 samples/s | 97.4 steps/s
[Step=54250 Epoch=514.1] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.942 | L2-Norm(final)=8.003 | 2230.8 samples/s | 34.9 steps/s
[Step=54300 Epoch=514.5] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.943 | L2-Norm(final)=8.007 | 5845.3 samples/s | 91.3 steps/s
[Step=54350 Epoch=515.0] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.944 | L2-Norm(final)=8.010 | 2308.3 samples/s | 36.1 steps/s
[Step=54400 Epoch=515.5] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=8.013 | 5312.2 samples/s | 83.0 steps/s
[Step=54450 Epoch=516.0] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=8.016 | 2446.0 samples/s | 38.2 steps/s
[Step=54500 Epoch=516.4] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.946 | L2-Norm(final)=8.020 | 4770.7 samples/s | 74.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=516.4] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.951 | L2-Norm(final)=8.052 | 5622.4 samples/s | 87.8 steps/s
[Step=54550 Epoch=516.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.948 | L2-Norm(final)=8.055 | 3688.4 samples/s | 57.6 steps/s
[Step=54600 Epoch=517.4] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.944 | L2-Norm(final)=8.057 | 6301.1 samples/s | 98.5 steps/s
[Step=54650 Epoch=517.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.940 | L2-Norm(final)=8.059 | 2022.2 samples/s | 31.6 steps/s
[Step=54700 Epoch=518.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.935 | L2-Norm(final)=8.061 | 5541.7 samples/s | 86.6 steps/s
[Step=54750 Epoch=518.8] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.929 | L2-Norm(final)=8.062 | 1650.5 samples/s | 25.8 steps/s
[Step=54800 Epoch=519.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=8.063 | 5107.0 samples/s | 79.8 steps/s
[Step=54850 Epoch=519.8] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.917 | L2-Norm(final)=8.065 | 2174.7 samples/s | 34.0 steps/s
[Step=54900 Epoch=520.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.911 | L2-Norm(final)=8.066 | 4692.8 samples/s | 73.3 steps/s
[Step=54950 Epoch=520.7] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=8.067 | 2272.1 samples/s | 35.5 steps/s
[Step=55000 Epoch=521.2] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.898 | L2-Norm(final)=8.067 | 4347.5 samples/s | 67.9 steps/s
[Step=55050 Epoch=521.6] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.892 | L2-Norm(final)=8.068 | 2380.1 samples/s | 37.2 steps/s
[Step=55100 Epoch=522.1] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.885 | L2-Norm(final)=8.069 | 4156.3 samples/s | 64.9 steps/s
[Step=55150 Epoch=522.6] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.879 | L2-Norm(final)=8.070 | 2384.6 samples/s | 37.3 steps/s
[Step=55200 Epoch=523.1] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.872 | L2-Norm(final)=8.071 | 4228.9 samples/s | 66.1 steps/s
[Step=55250 Epoch=523.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.865 | L2-Norm(final)=8.072 | 2391.4 samples/s | 37.4 steps/s
[Step=55300 Epoch=524.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.858 | L2-Norm(final)=8.073 | 4188.2 samples/s | 65.4 steps/s
[Step=55350 Epoch=524.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.851 | L2-Norm(final)=8.073 | 2543.0 samples/s | 39.7 steps/s
[Step=55400 Epoch=525.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.844 | L2-Norm(final)=8.074 | 3857.9 samples/s | 60.3 steps/s
[Step=55450 Epoch=525.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.837 | L2-Norm(final)=8.075 | 6452.3 samples/s | 100.8 steps/s
[Step=55500 Epoch=525.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.830 | L2-Norm(final)=8.076 | 1998.9 samples/s | 31.2 steps/s
[Step=55550 Epoch=526.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.823 | L2-Norm(final)=8.077 | 5871.6 samples/s | 91.7 steps/s
[Step=55600 Epoch=526.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.815 | L2-Norm(final)=8.077 | 2099.6 samples/s | 32.8 steps/s
[Step=55650 Epoch=527.3] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.808 | L2-Norm(final)=8.078 | 5093.1 samples/s | 79.6 steps/s
[Step=55700 Epoch=527.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.800 | L2-Norm(final)=8.079 | 2155.8 samples/s | 33.7 steps/s
[Step=55750 Epoch=528.3] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.793 | L2-Norm(final)=8.080 | 4864.1 samples/s | 76.0 steps/s
[Step=55800 Epoch=528.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.785 | L2-Norm(final)=8.081 | 2243.2 samples/s | 35.1 steps/s
[Step=55850 Epoch=529.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.777 | L2-Norm(final)=8.082 | 4435.4 samples/s | 69.3 steps/s
[Step=55900 Epoch=529.7] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=8.083 | 2359.5 samples/s | 36.9 steps/s
[Step=55950 Epoch=530.2] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.762 | L2-Norm(final)=8.083 | 4155.9 samples/s | 64.9 steps/s
[Step=56000 Epoch=530.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.754 | L2-Norm(final)=8.084 | 2405.5 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step56000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=513.7] | Loss=0.00010 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.780 | L2-Norm(final)=9.269 | 4992.8 samples/s | 78.0 steps/s
[Step=54050 Epoch=514.1] | Loss=0.00105 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.799 | L2-Norm(final)=9.288 | 4153.5 samples/s | 64.9 steps/s
[Step=54100 Epoch=514.6] | Loss=0.00061 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.826 | L2-Norm(final)=9.299 | 7590.3 samples/s | 118.6 steps/s
[Step=54150 Epoch=515.1] | Loss=0.00042 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.838 | L2-Norm(final)=9.305 | 2132.8 samples/s | 33.3 steps/s
[Step=54200 Epoch=515.6] | Loss=0.00033 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.845 | L2-Norm(final)=9.310 | 6682.6 samples/s | 104.4 steps/s
[Step=54250 Epoch=516.1] | Loss=0.00027 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.849 | L2-Norm(final)=9.314 | 2231.7 samples/s | 34.9 steps/s
[Step=54300 Epoch=516.5] | Loss=0.00023 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.852 | L2-Norm(final)=9.318 | 5855.8 samples/s | 91.5 steps/s
[Step=54350 Epoch=517.0] | Loss=0.00020 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.854 | L2-Norm(final)=9.321 | 2314.2 samples/s | 36.2 steps/s
[Step=54400 Epoch=517.5] | Loss=0.00018 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.855 | L2-Norm(final)=9.324 | 5357.6 samples/s | 83.7 steps/s
[Step=54450 Epoch=518.0] | Loss=0.00017 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.857 | L2-Norm(final)=9.327 | 2407.2 samples/s | 37.6 steps/s
[Step=54500 Epoch=518.4] | Loss=0.00015 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.858 | L2-Norm(final)=9.330 | 4799.6 samples/s | 75.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=518.4] | Loss=0.00006 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.869 | L2-Norm(final)=9.360 | 5402.5 samples/s | 84.4 steps/s
[Step=54550 Epoch=518.9] | Loss=0.00305 | Reg=0.00062 | acc=0.9844 | L2-Norm=7.866 | L2-Norm(final)=9.361 | 3821.0 samples/s | 59.7 steps/s
[Step=54600 Epoch=519.4] | Loss=0.00453 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.925 | L2-Norm(final)=9.350 | 6249.9 samples/s | 97.7 steps/s
[Step=54650 Epoch=519.9] | Loss=0.00330 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=9.345 | 2004.1 samples/s | 31.3 steps/s
[Step=54700 Epoch=520.3] | Loss=0.00250 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.974 | L2-Norm(final)=9.343 | 5658.6 samples/s | 88.4 steps/s
[Step=54750 Epoch=520.8] | Loss=0.00217 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.343 | 2087.3 samples/s | 32.6 steps/s
[Step=54800 Epoch=521.3] | Loss=0.00182 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.995 | L2-Norm(final)=9.343 | 5154.3 samples/s | 80.5 steps/s
[Step=54850 Epoch=521.8] | Loss=0.00156 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=9.343 | 2164.4 samples/s | 33.8 steps/s
[Step=54900 Epoch=522.2] | Loss=0.00137 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.005 | L2-Norm(final)=9.344 | 4665.9 samples/s | 72.9 steps/s
[Step=54950 Epoch=522.7] | Loss=0.00122 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.345 | 2264.6 samples/s | 35.4 steps/s
[Step=55000 Epoch=523.2] | Loss=0.00110 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.011 | L2-Norm(final)=9.345 | 4355.0 samples/s | 68.0 steps/s
[Step=55050 Epoch=523.7] | Loss=0.00100 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.013 | L2-Norm(final)=9.346 | 2378.5 samples/s | 37.2 steps/s
[Step=55100 Epoch=524.1] | Loss=0.00092 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=9.346 | 4241.1 samples/s | 66.3 steps/s
[Step=55150 Epoch=524.6] | Loss=0.00085 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.015 | L2-Norm(final)=9.347 | 2396.1 samples/s | 37.4 steps/s
[Step=55200 Epoch=525.1] | Loss=0.00079 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=9.347 | 4293.0 samples/s | 67.1 steps/s
[Step=55250 Epoch=525.6] | Loss=0.00074 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.348 | 2412.6 samples/s | 37.7 steps/s
[Step=55300 Epoch=526.0] | Loss=0.00069 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.348 | 4271.5 samples/s | 66.7 steps/s
[Step=55350 Epoch=526.5] | Loss=0.00065 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.349 | 2575.2 samples/s | 40.2 steps/s
[Step=55400 Epoch=527.0] | Loss=0.00062 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.349 | 3864.4 samples/s | 60.4 steps/s
[Step=55450 Epoch=527.5] | Loss=0.00059 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.350 | 6602.0 samples/s | 103.2 steps/s
[Step=55500 Epoch=527.9] | Loss=0.00056 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.350 | 2014.3 samples/s | 31.5 steps/s
[Step=55550 Epoch=528.4] | Loss=0.00053 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=9.350 | 5831.5 samples/s | 91.1 steps/s
[Step=55600 Epoch=528.9] | Loss=0.00051 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=9.351 | 2078.8 samples/s | 32.5 steps/s
[Step=55650 Epoch=529.4] | Loss=0.00049 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.015 | L2-Norm(final)=9.351 | 5315.6 samples/s | 83.1 steps/s
[Step=55700 Epoch=529.8] | Loss=0.00047 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.015 | L2-Norm(final)=9.352 | 2144.9 samples/s | 33.5 steps/s
[Step=55750 Epoch=530.3] | Loss=0.00045 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=9.352 | 4881.9 samples/s | 76.3 steps/s
[Step=55800 Epoch=530.8] | Loss=0.00043 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=9.353 | 2219.9 samples/s | 34.7 steps/s
[Step=55850 Epoch=531.3] | Loss=0.00042 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.013 | L2-Norm(final)=9.353 | 4502.7 samples/s | 70.4 steps/s
[Step=55900 Epoch=531.7] | Loss=0.00040 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.012 | L2-Norm(final)=9.354 | 2337.6 samples/s | 36.5 steps/s
[Step=55950 Epoch=532.2] | Loss=0.00039 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.012 | L2-Norm(final)=9.354 | 4257.2 samples/s | 66.5 steps/s
[Step=56000 Epoch=532.7] | Loss=0.00037 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.011 | L2-Norm(final)=9.354 | 2410.7 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step56000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=515.7] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.872 | L2-Norm(final)=8.515 | 5310.1 samples/s | 83.0 steps/s
[Step=54050 Epoch=516.1] | Loss=0.00004 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.875 | L2-Norm(final)=8.524 | 4178.0 samples/s | 65.3 steps/s
[Step=54100 Epoch=516.6] | Loss=0.00005 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.881 | L2-Norm(final)=8.536 | 7498.6 samples/s | 117.2 steps/s
[Step=54150 Epoch=517.1] | Loss=0.00005 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.888 | L2-Norm(final)=8.549 | 2092.3 samples/s | 32.7 steps/s
[Step=54200 Epoch=517.6] | Loss=0.00004 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.894 | L2-Norm(final)=8.558 | 6737.0 samples/s | 105.3 steps/s
[Step=54250 Epoch=518.1] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.897 | L2-Norm(final)=8.567 | 2158.1 samples/s | 33.7 steps/s
[Step=54300 Epoch=518.5] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.900 | L2-Norm(final)=8.574 | 6171.9 samples/s | 96.4 steps/s
[Step=54350 Epoch=519.0] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.901 | L2-Norm(final)=8.581 | 2305.7 samples/s | 36.0 steps/s
[Step=54400 Epoch=519.5] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.903 | L2-Norm(final)=8.588 | 5353.6 samples/s | 83.7 steps/s
[Step=54450 Epoch=520.0] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.904 | L2-Norm(final)=8.594 | 2283.4 samples/s | 35.7 steps/s
[Step=54500 Epoch=520.4] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=8.600 | 4973.2 samples/s | 77.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=520.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.911 | L2-Norm(final)=8.661 | 5327.6 samples/s | 83.2 steps/s
[Step=54550 Epoch=520.9] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.904 | L2-Norm(final)=8.666 | 3651.1 samples/s | 57.0 steps/s
[Step=54600 Epoch=521.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.893 | L2-Norm(final)=8.670 | 6370.0 samples/s | 99.5 steps/s
[Step=54650 Epoch=521.9] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.881 | L2-Norm(final)=8.673 | 1986.7 samples/s | 31.0 steps/s
[Step=54700 Epoch=522.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.867 | L2-Norm(final)=8.675 | 5698.8 samples/s | 89.0 steps/s
[Step=54750 Epoch=522.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.853 | L2-Norm(final)=8.677 | 2047.4 samples/s | 32.0 steps/s
[Step=54800 Epoch=523.3] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.839 | L2-Norm(final)=8.679 | 5343.0 samples/s | 83.5 steps/s
[Step=54850 Epoch=523.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=8.680 | 2127.7 samples/s | 33.2 steps/s
[Step=54900 Epoch=524.3] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.809 | L2-Norm(final)=8.682 | 4941.7 samples/s | 77.2 steps/s
[Step=54950 Epoch=524.7] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.794 | L2-Norm(final)=8.683 | 2172.3 samples/s | 33.9 steps/s
[Step=55000 Epoch=525.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.779 | L2-Norm(final)=8.685 | 4577.2 samples/s | 71.5 steps/s
[Step=55050 Epoch=525.7] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=8.686 | 2255.5 samples/s | 35.2 steps/s
[Step=55100 Epoch=526.2] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.749 | L2-Norm(final)=8.688 | 4293.4 samples/s | 67.1 steps/s
[Step=55150 Epoch=526.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.734 | L2-Norm(final)=8.689 | 2313.8 samples/s | 36.2 steps/s
[Step=55200 Epoch=527.1] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.718 | L2-Norm(final)=8.691 | 4174.1 samples/s | 65.2 steps/s
[Step=55250 Epoch=527.6] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.703 | L2-Norm(final)=8.692 | 2332.9 samples/s | 36.5 steps/s
[Step=55300 Epoch=528.1] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.687 | L2-Norm(final)=8.693 | 4208.1 samples/s | 65.8 steps/s
[Step=55350 Epoch=528.6] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.672 | L2-Norm(final)=8.695 | 2369.7 samples/s | 37.0 steps/s
[Step=55400 Epoch=529.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.656 | L2-Norm(final)=8.697 | 4161.3 samples/s | 65.0 steps/s
[Step=55450 Epoch=529.5] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.640 | L2-Norm(final)=8.698 | 2330.3 samples/s | 36.4 steps/s
[Step=55500 Epoch=530.0] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=8.700 | 4252.9 samples/s | 66.5 steps/s
[Step=55550 Epoch=530.5] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.608 | L2-Norm(final)=8.701 | 6805.7 samples/s | 106.3 steps/s
[Step=55600 Epoch=530.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.592 | L2-Norm(final)=8.703 | 1915.5 samples/s | 29.9 steps/s
[Step=55650 Epoch=531.4] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.576 | L2-Norm(final)=8.705 | 6312.6 samples/s | 98.6 steps/s
[Step=55700 Epoch=531.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.559 | L2-Norm(final)=8.707 | 1988.3 samples/s | 31.1 steps/s
[Step=55750 Epoch=532.4] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.543 | L2-Norm(final)=8.708 | 5814.8 samples/s | 90.9 steps/s
[Step=55800 Epoch=532.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.526 | L2-Norm(final)=8.710 | 2078.0 samples/s | 32.5 steps/s
[Step=55850 Epoch=533.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.509 | L2-Norm(final)=8.712 | 5075.6 samples/s | 79.3 steps/s
[Step=55900 Epoch=533.8] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.493 | L2-Norm(final)=8.714 | 2121.4 samples/s | 33.1 steps/s
[Step=55950 Epoch=534.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.476 | L2-Norm(final)=8.716 | 4861.0 samples/s | 76.0 steps/s
[Step=56000 Epoch=534.8] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.459 | L2-Norm(final)=8.718 | 2181.0 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step56000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=508.8] | Loss=0.00003 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.900 | L2-Norm(final)=8.476 | 5286.0 samples/s | 82.6 steps/s
[Step=54050 Epoch=509.3] | Loss=0.00014 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.912 | L2-Norm(final)=8.496 | 3942.0 samples/s | 61.6 steps/s
[Step=54100 Epoch=509.8] | Loss=0.00013 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.939 | L2-Norm(final)=8.527 | 7344.5 samples/s | 114.8 steps/s
[Step=54150 Epoch=510.2] | Loss=0.00011 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.956 | L2-Norm(final)=8.550 | 2134.5 samples/s | 33.4 steps/s
[Step=54200 Epoch=510.7] | Loss=0.00009 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.967 | L2-Norm(final)=8.567 | 6150.7 samples/s | 96.1 steps/s
[Step=54250 Epoch=511.2] | Loss=0.00007 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=8.580 | 2217.6 samples/s | 34.7 steps/s
[Step=54300 Epoch=511.7] | Loss=0.00007 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.978 | L2-Norm(final)=8.592 | 5612.5 samples/s | 87.7 steps/s
[Step=54350 Epoch=512.1] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.982 | L2-Norm(final)=8.603 | 2342.7 samples/s | 36.6 steps/s
[Step=54400 Epoch=512.6] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.985 | L2-Norm(final)=8.613 | 4908.4 samples/s | 76.7 steps/s
[Step=54450 Epoch=513.1] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=8.622 | 2452.6 samples/s | 38.3 steps/s
[Step=54500 Epoch=513.5] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=8.630 | 4739.5 samples/s | 74.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=513.6] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.005 | L2-Norm(final)=8.712 | 5072.4 samples/s | 79.3 steps/s
[Step=54550 Epoch=514.0] | Loss=0.00007 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.992 | L2-Norm(final)=8.718 | 3850.5 samples/s | 60.2 steps/s
[Step=54600 Epoch=514.5] | Loss=0.00278 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.041 | L2-Norm(final)=8.716 | 6066.4 samples/s | 94.8 steps/s
[Step=54650 Epoch=515.0] | Loss=0.00198 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.083 | L2-Norm(final)=8.717 | 1999.0 samples/s | 31.2 steps/s
[Step=54700 Epoch=515.4] | Loss=0.00154 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.105 | L2-Norm(final)=8.720 | 5397.3 samples/s | 84.3 steps/s
[Step=54750 Epoch=515.9] | Loss=0.00124 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.118 | L2-Norm(final)=8.723 | 2104.8 samples/s | 32.9 steps/s
[Step=54800 Epoch=516.4] | Loss=0.00104 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.127 | L2-Norm(final)=8.725 | 4920.7 samples/s | 76.9 steps/s
[Step=54850 Epoch=516.8] | Loss=0.00089 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.133 | L2-Norm(final)=8.727 | 2194.2 samples/s | 34.3 steps/s
[Step=54900 Epoch=517.3] | Loss=0.00078 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.729 | 4412.8 samples/s | 69.0 steps/s
[Step=54950 Epoch=517.8] | Loss=0.00070 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=8.731 | 2271.8 samples/s | 35.5 steps/s
[Step=55000 Epoch=518.3] | Loss=0.00063 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.732 | 4201.4 samples/s | 65.6 steps/s
[Step=55050 Epoch=518.7] | Loss=0.00057 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.734 | 2365.7 samples/s | 37.0 steps/s
[Step=55100 Epoch=519.2] | Loss=0.00052 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.736 | 4125.6 samples/s | 64.5 steps/s
[Step=55150 Epoch=519.7] | Loss=0.00049 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.737 | 2373.7 samples/s | 37.1 steps/s
[Step=55200 Epoch=520.1] | Loss=0.00045 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.739 | 4205.1 samples/s | 65.7 steps/s
[Step=55250 Epoch=520.6] | Loss=0.00042 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.741 | 2508.0 samples/s | 39.2 steps/s
[Step=55300 Epoch=521.1] | Loss=0.00040 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.742 | 3829.9 samples/s | 59.8 steps/s
[Step=55350 Epoch=521.6] | Loss=0.00037 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.142 | L2-Norm(final)=8.744 | 6223.7 samples/s | 97.2 steps/s
[Step=55400 Epoch=522.0] | Loss=0.00035 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.745 | 1990.5 samples/s | 31.1 steps/s
[Step=55450 Epoch=522.5] | Loss=0.00033 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.140 | L2-Norm(final)=8.747 | 5389.2 samples/s | 84.2 steps/s
[Step=55500 Epoch=523.0] | Loss=0.00032 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=8.748 | 2100.0 samples/s | 32.8 steps/s
[Step=55550 Epoch=523.4] | Loss=0.00030 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.138 | L2-Norm(final)=8.749 | 4955.0 samples/s | 77.4 steps/s
[Step=55600 Epoch=523.9] | Loss=0.00029 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.751 | 2173.0 samples/s | 34.0 steps/s
[Step=55650 Epoch=524.4] | Loss=0.00028 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=8.752 | 4483.1 samples/s | 70.0 steps/s
[Step=55700 Epoch=524.9] | Loss=0.00027 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.134 | L2-Norm(final)=8.753 | 2268.7 samples/s | 35.4 steps/s
[Step=55750 Epoch=525.3] | Loss=0.00026 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=8.755 | 4280.9 samples/s | 66.9 steps/s
[Step=55800 Epoch=525.8] | Loss=0.00025 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=8.756 | 2363.6 samples/s | 36.9 steps/s
[Step=55850 Epoch=526.3] | Loss=0.00024 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.129 | L2-Norm(final)=8.757 | 4162.6 samples/s | 65.0 steps/s
[Step=55900 Epoch=526.7] | Loss=0.00023 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.127 | L2-Norm(final)=8.758 | 2339.6 samples/s | 36.6 steps/s
[Step=55950 Epoch=527.2] | Loss=0.00022 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=8.760 | 4211.0 samples/s | 65.8 steps/s
[Step=56000 Epoch=527.7] | Loss=0.00021 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.124 | L2-Norm(final)=8.761 | 2506.7 samples/s | 39.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step56000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=514.7] | Loss=0.00003 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.943 | L2-Norm(final)=9.117 | 5225.8 samples/s | 81.7 steps/s
[Step=54050 Epoch=515.1] | Loss=0.00007 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=9.127 | 4023.8 samples/s | 62.9 steps/s
[Step=54100 Epoch=515.6] | Loss=0.00008 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.958 | L2-Norm(final)=9.146 | 7380.7 samples/s | 115.3 steps/s
[Step=54150 Epoch=516.1] | Loss=0.00006 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.966 | L2-Norm(final)=9.162 | 2089.7 samples/s | 32.7 steps/s
[Step=54200 Epoch=516.6] | Loss=0.00006 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.971 | L2-Norm(final)=9.174 | 6782.5 samples/s | 106.0 steps/s
[Step=54250 Epoch=517.1] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.976 | L2-Norm(final)=9.186 | 2182.6 samples/s | 34.1 steps/s
[Step=54300 Epoch=517.5] | Loss=0.00005 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.979 | L2-Norm(final)=9.196 | 5944.6 samples/s | 92.9 steps/s
[Step=54350 Epoch=518.0] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.981 | L2-Norm(final)=9.205 | 2219.6 samples/s | 34.7 steps/s
[Step=54400 Epoch=518.5] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.983 | L2-Norm(final)=9.214 | 5612.3 samples/s | 87.7 steps/s
[Step=54450 Epoch=519.0] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.985 | L2-Norm(final)=9.223 | 2339.5 samples/s | 36.6 steps/s
[Step=54500 Epoch=519.4] | Loss=0.00004 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.231 | 4984.9 samples/s | 77.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=519.4] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.998 | L2-Norm(final)=9.312 | 5426.8 samples/s | 84.8 steps/s
[Step=54550 Epoch=519.9] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.991 | L2-Norm(final)=9.318 | 3675.2 samples/s | 57.4 steps/s
[Step=54600 Epoch=520.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.980 | L2-Norm(final)=9.323 | 6213.9 samples/s | 97.1 steps/s
[Step=54650 Epoch=520.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.968 | L2-Norm(final)=9.327 | 1994.0 samples/s | 31.2 steps/s
[Step=54700 Epoch=521.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.954 | L2-Norm(final)=9.330 | 5756.4 samples/s | 89.9 steps/s
[Step=54750 Epoch=521.8] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.939 | L2-Norm(final)=9.332 | 2067.1 samples/s | 32.3 steps/s
[Step=54800 Epoch=522.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=9.333 | 5217.2 samples/s | 81.5 steps/s
[Step=54850 Epoch=522.8] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.907 | L2-Norm(final)=9.335 | 2148.7 samples/s | 33.6 steps/s
[Step=54900 Epoch=523.2] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.891 | L2-Norm(final)=9.336 | 4841.2 samples/s | 75.6 steps/s
[Step=54950 Epoch=523.7] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.875 | L2-Norm(final)=9.337 | 2170.1 samples/s | 33.9 steps/s
[Step=55000 Epoch=524.2] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.858 | L2-Norm(final)=9.339 | 4585.9 samples/s | 71.7 steps/s
[Step=55050 Epoch=524.7] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.841 | L2-Norm(final)=9.340 | 2278.6 samples/s | 35.6 steps/s
[Step=55100 Epoch=525.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.825 | L2-Norm(final)=9.341 | 4292.5 samples/s | 67.1 steps/s
[Step=55150 Epoch=525.6] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.808 | L2-Norm(final)=9.342 | 2339.9 samples/s | 36.6 steps/s
[Step=55200 Epoch=526.1] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.790 | L2-Norm(final)=9.343 | 4305.7 samples/s | 67.3 steps/s
[Step=55250 Epoch=526.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.773 | L2-Norm(final)=9.345 | 2375.2 samples/s | 37.1 steps/s
[Step=55300 Epoch=527.1] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.756 | L2-Norm(final)=9.346 | 4175.7 samples/s | 65.2 steps/s
[Step=55350 Epoch=527.5] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.738 | L2-Norm(final)=9.347 | 2363.1 samples/s | 36.9 steps/s
[Step=55400 Epoch=528.0] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.720 | L2-Norm(final)=9.348 | 4167.2 samples/s | 65.1 steps/s
[Step=55450 Epoch=528.5] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.703 | L2-Norm(final)=9.349 | 2182.4 samples/s | 34.1 steps/s
[Step=55500 Epoch=529.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.685 | L2-Norm(final)=9.351 | 4021.3 samples/s | 62.8 steps/s
[Step=55550 Epoch=529.4] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.667 | L2-Norm(final)=9.352 | 6510.2 samples/s | 101.7 steps/s
[Step=55600 Epoch=529.9] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.648 | L2-Norm(final)=9.353 | 1812.9 samples/s | 28.3 steps/s
[Step=55650 Epoch=530.4] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.630 | L2-Norm(final)=9.355 | 5984.4 samples/s | 93.5 steps/s
[Step=55700 Epoch=530.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.356 | 1871.3 samples/s | 29.2 steps/s
[Step=55750 Epoch=531.3] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.593 | L2-Norm(final)=9.358 | 5399.9 samples/s | 84.4 steps/s
[Step=55800 Epoch=531.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.574 | L2-Norm(final)=9.359 | 2045.5 samples/s | 32.0 steps/s
[Step=55850 Epoch=532.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.556 | L2-Norm(final)=9.361 | 5244.0 samples/s | 81.9 steps/s
[Step=55900 Epoch=532.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.537 | L2-Norm(final)=9.362 | 2117.4 samples/s | 33.1 steps/s
[Step=55950 Epoch=533.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.517 | L2-Norm(final)=9.364 | 4941.9 samples/s | 77.2 steps/s
[Step=56000 Epoch=533.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.498 | L2-Norm(final)=9.366 | 2238.0 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11242 | acc=0.9553 | tpr=0.9687 | fpr=0.0738 | 4789.1 samples/s | 18.7 steps/s
Avg test loss: 0.11753, Avg test acc: 0.95573, Avg tpr: 0.96888, Avg fpr: 0.07320, total FA: 571

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11586 | acc=0.9562 | tpr=0.9715 | fpr=0.0771 | 4889.1 samples/s | 19.1 steps/s
Avg test loss: 0.12088, Avg test acc: 0.95645, Avg tpr: 0.97092, Avg fpr: 0.07537, total FA: 588

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11327 | acc=0.9580 | tpr=0.9699 | fpr=0.0679 | 4888.9 samples/s | 19.1 steps/s
Avg test loss: 0.11655, Avg test acc: 0.95629, Avg tpr: 0.96788, Avg fpr: 0.06922, total FA: 540

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10942 | acc=0.9586 | tpr=0.9702 | fpr=0.0667 | 4730.9 samples/s | 18.5 steps/s
Avg test loss: 0.11427, Avg test acc: 0.95757, Avg tpr: 0.97016, Avg fpr: 0.07012, total FA: 547

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10479 | acc=0.9585 | tpr=0.9686 | fpr=0.0634 | 4743.2 samples/s | 18.5 steps/s
Avg test loss: 0.11300, Avg test acc: 0.95737, Avg tpr: 0.96724, Avg fpr: 0.06435, total FA: 502

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.49810 | acc=0.2885 | tpr=0.0129 | fpr=0.1130 | 4738.1 samples/s | 18.5 steps/s
Avg test loss: 5.50275, Avg test acc: 0.28780, Avg tpr: 0.01393, Avg fpr: 0.10986, total FA: 857

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.18683 | acc=0.3056 | tpr=0.0031 | fpr=0.0374 | 4856.6 samples/s | 19.0 steps/s
Avg test loss: 4.20008, Avg test acc: 0.30235, Avg tpr: 0.00315, Avg fpr: 0.03961, total FA: 309

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.00694 | acc=0.2842 | tpr=0.0153 | fpr=0.1318 | 4764.8 samples/s | 18.6 steps/s
Avg test loss: 5.00537, Avg test acc: 0.28171, Avg tpr: 0.01533, Avg fpr: 0.13242, total FA: 1033

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.56415 | acc=0.2947 | tpr=0.0152 | fpr=0.0984 | 4609.1 samples/s | 18.0 steps/s
Avg test loss: 5.55639, Avg test acc: 0.29349, Avg tpr: 0.01568, Avg fpr: 0.09550, total FA: 745

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.71084 | acc=0.2967 | tpr=0.0136 | fpr=0.0885 | 4854.1 samples/s | 19.0 steps/s
Avg test loss: 4.71538, Avg test acc: 0.29514, Avg tpr: 0.01411, Avg fpr: 0.08678, total FA: 677

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.03210 | acc=0.0952 | tpr=0.5796 | fpr=0.9135 | 4970.7 samples/s | 19.4 steps/s
[Step= 100] | Loss=6.00994 | acc=0.0977 | tpr=0.5864 | fpr=0.9115 | 6871.4 samples/s | 26.8 steps/s
[Step= 150] | Loss=6.02433 | acc=0.0979 | tpr=0.5908 | fpr=0.9111 | 7657.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=6.02282 | acc=0.0971 | tpr=0.5738 | fpr=0.9115 | 8123.0 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.02695 | acc=0.0978 | tpr=0.5747 | fpr=0.9108 | 7883.2 samples/s | 30.8 steps/s
[Step= 300] | Loss=6.02298 | acc=0.0979 | tpr=0.5825 | fpr=0.9109 | 7929.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=6.01824 | acc=0.0983 | tpr=0.5874 | fpr=0.9106 | 7767.7 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.01272 | acc=0.0984 | tpr=0.5875 | fpr=0.9105 | 7682.8 samples/s | 30.0 steps/s
[Step= 450] | Loss=6.01804 | acc=0.0981 | tpr=0.5828 | fpr=0.9107 | 7774.3 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.02246 | acc=0.0980 | tpr=0.5784 | fpr=0.9106 | 7966.5 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.02519 | acc=0.0977 | tpr=0.5758 | fpr=0.9110 | 14115.7 samples/s | 55.1 steps/s
Avg test loss: 6.02706, Avg test acc: 0.09761, Avg tpr: 0.57647, Avg fpr: 0.91110, total FA: 126504

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.61094 | acc=0.0969 | tpr=0.4956 | fpr=0.9103 | 4579.1 samples/s | 17.9 steps/s
[Step= 100] | Loss=5.58986 | acc=0.0975 | tpr=0.5139 | fpr=0.9103 | 7596.9 samples/s | 29.7 steps/s
[Step= 150] | Loss=5.59525 | acc=0.0982 | tpr=0.5115 | fpr=0.9094 | 7855.0 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.58895 | acc=0.0987 | tpr=0.5082 | fpr=0.9087 | 7874.1 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.59651 | acc=0.0989 | tpr=0.5135 | fpr=0.9086 | 7810.4 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.58895 | acc=0.0989 | tpr=0.5164 | fpr=0.9087 | 7663.4 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.58529 | acc=0.0992 | tpr=0.5122 | fpr=0.9083 | 8247.9 samples/s | 32.2 steps/s
[Step= 400] | Loss=5.57945 | acc=0.0997 | tpr=0.5093 | fpr=0.9078 | 7555.7 samples/s | 29.5 steps/s
[Step= 450] | Loss=5.58450 | acc=0.0994 | tpr=0.5073 | fpr=0.9080 | 7612.3 samples/s | 29.7 steps/s
[Step= 500] | Loss=5.58761 | acc=0.0989 | tpr=0.5062 | fpr=0.9084 | 8076.9 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.58983 | acc=0.0985 | tpr=0.4990 | fpr=0.9088 | 14666.8 samples/s | 57.3 steps/s
Avg test loss: 5.59214, Avg test acc: 0.09840, Avg tpr: 0.49842, Avg fpr: 0.90887, total FA: 126195

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.31234 | acc=0.0842 | tpr=0.3982 | fpr=0.9214 | 4662.7 samples/s | 18.2 steps/s
[Step= 100] | Loss=6.28144 | acc=0.0865 | tpr=0.4051 | fpr=0.9195 | 7338.1 samples/s | 28.7 steps/s
[Step= 150] | Loss=6.28677 | acc=0.0872 | tpr=0.4063 | fpr=0.9187 | 7969.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=6.28141 | acc=0.0867 | tpr=0.3945 | fpr=0.9189 | 7686.4 samples/s | 30.0 steps/s
[Step= 250] | Loss=6.28078 | acc=0.0874 | tpr=0.4000 | fpr=0.9183 | 7906.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.28036 | acc=0.0876 | tpr=0.4065 | fpr=0.9182 | 7766.5 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.27521 | acc=0.0880 | tpr=0.4045 | fpr=0.9177 | 7800.0 samples/s | 30.5 steps/s
[Step= 400] | Loss=6.26848 | acc=0.0885 | tpr=0.3999 | fpr=0.9172 | 7989.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.27046 | acc=0.0886 | tpr=0.3978 | fpr=0.9170 | 7780.7 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.27117 | acc=0.0882 | tpr=0.3960 | fpr=0.9173 | 7660.4 samples/s | 29.9 steps/s
[Step= 550] | Loss=6.27446 | acc=0.0882 | tpr=0.3959 | fpr=0.9174 | 14700.0 samples/s | 57.4 steps/s
Avg test loss: 6.27558, Avg test acc: 0.08811, Avg tpr: 0.39659, Avg fpr: 0.91750, total FA: 127393

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.46746 | acc=0.1165 | tpr=0.5929 | fpr=0.8921 | 4767.2 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.46209 | acc=0.1165 | tpr=0.5906 | fpr=0.8923 | 7118.4 samples/s | 27.8 steps/s
[Step= 150] | Loss=5.46828 | acc=0.1155 | tpr=0.5865 | fpr=0.8932 | 7698.5 samples/s | 30.1 steps/s
[Step= 200] | Loss=5.45618 | acc=0.1151 | tpr=0.5760 | fpr=0.8933 | 8006.5 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.46273 | acc=0.1156 | tpr=0.5729 | fpr=0.8927 | 7975.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.46291 | acc=0.1156 | tpr=0.5709 | fpr=0.8927 | 7737.5 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.45585 | acc=0.1154 | tpr=0.5729 | fpr=0.8929 | 8033.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.44802 | acc=0.1156 | tpr=0.5706 | fpr=0.8927 | 7860.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.45315 | acc=0.1153 | tpr=0.5662 | fpr=0.8929 | 7663.8 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.45547 | acc=0.1151 | tpr=0.5661 | fpr=0.8931 | 8195.4 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.45923 | acc=0.1150 | tpr=0.5655 | fpr=0.8931 | 13323.1 samples/s | 52.0 steps/s
Avg test loss: 5.46047, Avg test acc: 0.11494, Avg tpr: 0.56577, Avg fpr: 0.89325, total FA: 124026

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.52295 | acc=0.1108 | tpr=0.5044 | fpr=0.8963 | 4849.2 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.51100 | acc=0.1113 | tpr=0.5011 | fpr=0.8959 | 6917.2 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.51113 | acc=0.1118 | tpr=0.5072 | fpr=0.8955 | 7914.6 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.51129 | acc=0.1115 | tpr=0.4907 | fpr=0.8954 | 7796.2 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.51993 | acc=0.1120 | tpr=0.4978 | fpr=0.8950 | 7868.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.51933 | acc=0.1118 | tpr=0.5018 | fpr=0.8954 | 8084.7 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.51245 | acc=0.1120 | tpr=0.4978 | fpr=0.8950 | 7756.9 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.51078 | acc=0.1122 | tpr=0.4945 | fpr=0.8947 | 8238.5 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.51444 | acc=0.1125 | tpr=0.4961 | fpr=0.8945 | 7514.4 samples/s | 29.4 steps/s
[Step= 500] | Loss=5.51685 | acc=0.1124 | tpr=0.4934 | fpr=0.8945 | 7895.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.51989 | acc=0.1121 | tpr=0.4966 | fpr=0.8948 | 13973.4 samples/s | 54.6 steps/s
Avg test loss: 5.52205, Avg test acc: 0.11200, Avg tpr: 0.49564, Avg fpr: 0.89498, total FA: 124266

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09482 | acc=0.9817 | tpr=0.9513 | fpr=0.0177 | 4877.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.09832 | acc=0.9814 | tpr=0.9510 | fpr=0.0180 | 7025.0 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.10156 | acc=0.9809 | tpr=0.9510 | fpr=0.0186 | 7750.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.10349 | acc=0.9807 | tpr=0.9563 | fpr=0.0188 | 7736.0 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.10202 | acc=0.9810 | tpr=0.9502 | fpr=0.0185 | 8295.7 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.10457 | acc=0.9805 | tpr=0.9484 | fpr=0.0189 | 7597.6 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.10554 | acc=0.9802 | tpr=0.9505 | fpr=0.0192 | 7777.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10658 | acc=0.9799 | tpr=0.9469 | fpr=0.0195 | 7998.3 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.10860 | acc=0.9796 | tpr=0.9435 | fpr=0.0197 | 7793.4 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.10774 | acc=0.9798 | tpr=0.9445 | fpr=0.0195 | 8004.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.10724 | acc=0.9799 | tpr=0.9423 | fpr=0.0194 | 13983.4 samples/s | 54.6 steps/s
Avg test loss: 0.10713, Avg test acc: 0.97993, Avg tpr: 0.94255, Avg fpr: 0.01940, total FA: 2693

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08273 | acc=0.9830 | tpr=0.8805 | fpr=0.0152 | 4790.8 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.08497 | acc=0.9825 | tpr=0.8763 | fpr=0.0155 | 7035.1 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.08792 | acc=0.9820 | tpr=0.8804 | fpr=0.0161 | 7864.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.08981 | acc=0.9821 | tpr=0.8896 | fpr=0.0162 | 7727.2 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.08765 | acc=0.9822 | tpr=0.8900 | fpr=0.0161 | 8189.8 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.08953 | acc=0.9820 | tpr=0.8916 | fpr=0.0163 | 7661.0 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.08980 | acc=0.9820 | tpr=0.8967 | fpr=0.0165 | 7729.2 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09083 | acc=0.9817 | tpr=0.8922 | fpr=0.0166 | 8005.5 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.09278 | acc=0.9814 | tpr=0.8895 | fpr=0.0169 | 7885.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.09188 | acc=0.9815 | tpr=0.8912 | fpr=0.0168 | 7844.9 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09190 | acc=0.9817 | tpr=0.8894 | fpr=0.0166 | 14220.5 samples/s | 55.5 steps/s
Avg test loss: 0.09174, Avg test acc: 0.98168, Avg tpr: 0.88946, Avg fpr: 0.01664, total FA: 2311

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08813 | acc=0.9811 | tpr=0.9646 | fpr=0.0186 | 4768.4 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.08951 | acc=0.9814 | tpr=0.9680 | fpr=0.0184 | 7107.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09346 | acc=0.9801 | tpr=0.9654 | fpr=0.0196 | 7771.8 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.09510 | acc=0.9802 | tpr=0.9683 | fpr=0.0196 | 7938.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.09356 | acc=0.9805 | tpr=0.9668 | fpr=0.0193 | 7925.7 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.09578 | acc=0.9800 | tpr=0.9600 | fpr=0.0197 | 7916.3 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.09652 | acc=0.9797 | tpr=0.9606 | fpr=0.0200 | 7614.2 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.09760 | acc=0.9795 | tpr=0.9579 | fpr=0.0202 | 8205.4 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.09932 | acc=0.9792 | tpr=0.9572 | fpr=0.0204 | 7502.5 samples/s | 29.3 steps/s
[Step= 500] | Loss=0.09867 | acc=0.9792 | tpr=0.9586 | fpr=0.0204 | 8259.4 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.09828 | acc=0.9794 | tpr=0.9574 | fpr=0.0202 | 13425.6 samples/s | 52.4 steps/s
Avg test loss: 0.09818, Avg test acc: 0.97939, Avg tpr: 0.95761, Avg fpr: 0.02021, total FA: 2806

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09499 | acc=0.9813 | tpr=0.9292 | fpr=0.0177 | 4682.5 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.09807 | acc=0.9807 | tpr=0.9254 | fpr=0.0183 | 7357.5 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.10071 | acc=0.9803 | tpr=0.9323 | fpr=0.0188 | 7853.4 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.10215 | acc=0.9804 | tpr=0.9388 | fpr=0.0188 | 8016.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.10097 | acc=0.9807 | tpr=0.9336 | fpr=0.0184 | 7613.0 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.10378 | acc=0.9804 | tpr=0.9309 | fpr=0.0187 | 8023.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.10418 | acc=0.9802 | tpr=0.9317 | fpr=0.0189 | 7613.1 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.10450 | acc=0.9800 | tpr=0.9305 | fpr=0.0191 | 8195.2 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.10633 | acc=0.9798 | tpr=0.9265 | fpr=0.0192 | 7626.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=0.10560 | acc=0.9798 | tpr=0.9273 | fpr=0.0192 | 7790.3 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.10516 | acc=0.9800 | tpr=0.9268 | fpr=0.0190 | 14494.7 samples/s | 56.6 steps/s
Avg test loss: 0.10504, Avg test acc: 0.98003, Avg tpr: 0.92710, Avg fpr: 0.01901, total FA: 2639

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08916 | acc=0.9820 | tpr=0.9381 | fpr=0.0172 | 4898.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.09395 | acc=0.9811 | tpr=0.9339 | fpr=0.0181 | 6515.8 samples/s | 25.5 steps/s
[Step= 150] | Loss=0.09703 | acc=0.9802 | tpr=0.9366 | fpr=0.0190 | 8125.6 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.09891 | acc=0.9802 | tpr=0.9443 | fpr=0.0192 | 7693.7 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.09766 | acc=0.9806 | tpr=0.9415 | fpr=0.0187 | 7840.9 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09980 | acc=0.9802 | tpr=0.9360 | fpr=0.0190 | 8072.4 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.10030 | acc=0.9800 | tpr=0.9374 | fpr=0.0192 | 7933.8 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.10168 | acc=0.9799 | tpr=0.9354 | fpr=0.0193 | 8036.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.10374 | acc=0.9796 | tpr=0.9323 | fpr=0.0195 | 7976.7 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10301 | acc=0.9796 | tpr=0.9322 | fpr=0.0195 | 7768.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.10266 | acc=0.9798 | tpr=0.9312 | fpr=0.0193 | 13561.9 samples/s | 53.0 steps/s
Avg test loss: 0.10252, Avg test acc: 0.97983, Avg tpr: 0.93106, Avg fpr: 0.01929, total FA: 2678

server round 28/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=273.1] | Loss=0.00408 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.194 | L2-Norm(final)=15.389 | 5408.2 samples/s | 84.5 steps/s
[Step=56050 Epoch=273.3] | Loss=0.00291 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=15.396 | 4697.0 samples/s | 73.4 steps/s
[Step=56100 Epoch=273.6] | Loss=0.00282 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.200 | L2-Norm(final)=15.406 | 5163.4 samples/s | 80.7 steps/s
[Step=56150 Epoch=273.8] | Loss=0.00278 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.202 | L2-Norm(final)=15.417 | 4739.3 samples/s | 74.1 steps/s
[Step=56200 Epoch=274.0] | Loss=0.00301 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.203 | L2-Norm(final)=15.427 | 7656.9 samples/s | 119.6 steps/s
[Step=56250 Epoch=274.3] | Loss=0.00302 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.205 | L2-Norm(final)=15.438 | 2228.9 samples/s | 34.8 steps/s
[Step=56300 Epoch=274.5] | Loss=0.00291 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.206 | L2-Norm(final)=15.448 | 4939.7 samples/s | 77.2 steps/s
[Step=56350 Epoch=274.8] | Loss=0.00291 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.206 | L2-Norm(final)=15.458 | 5004.5 samples/s | 78.2 steps/s
[Step=56400 Epoch=275.0] | Loss=0.00290 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.207 | L2-Norm(final)=15.468 | 6987.2 samples/s | 109.2 steps/s
[Step=56450 Epoch=275.3] | Loss=0.00277 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.207 | L2-Norm(final)=15.479 | 2282.7 samples/s | 35.7 steps/s
[Step=56500 Epoch=275.5] | Loss=0.00281 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.207 | L2-Norm(final)=15.489 | 5011.6 samples/s | 78.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=275.5] | Loss=0.00051 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.207 | L2-Norm(final)=15.590 | 5153.7 samples/s | 80.5 steps/s
[Step=56550 Epoch=275.7] | Loss=0.00313 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.209 | L2-Norm(final)=15.601 | 4070.6 samples/s | 63.6 steps/s
[Step=56600 Epoch=276.0] | Loss=0.00460 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.213 | L2-Norm(final)=15.611 | 4462.3 samples/s | 69.7 steps/s
[Step=56650 Epoch=276.2] | Loss=0.00523 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.220 | L2-Norm(final)=15.619 | 4516.4 samples/s | 70.6 steps/s
[Step=56700 Epoch=276.5] | Loss=0.00572 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.229 | L2-Norm(final)=15.628 | 6354.9 samples/s | 99.3 steps/s
[Step=56750 Epoch=276.7] | Loss=0.00553 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=15.636 | 2103.6 samples/s | 32.9 steps/s
[Step=56800 Epoch=277.0] | Loss=0.00578 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.250 | L2-Norm(final)=15.645 | 4423.1 samples/s | 69.1 steps/s
[Step=56850 Epoch=277.2] | Loss=0.00575 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.258 | L2-Norm(final)=15.653 | 4358.6 samples/s | 68.1 steps/s
[Step=56900 Epoch=277.5] | Loss=0.00626 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.266 | L2-Norm(final)=15.661 | 5778.6 samples/s | 90.3 steps/s
[Step=56950 Epoch=277.7] | Loss=0.00611 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.276 | L2-Norm(final)=15.669 | 2163.9 samples/s | 33.8 steps/s
[Step=57000 Epoch=277.9] | Loss=0.00587 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.284 | L2-Norm(final)=15.677 | 4457.5 samples/s | 69.6 steps/s
[Step=57050 Epoch=278.2] | Loss=0.00579 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.291 | L2-Norm(final)=15.684 | 4484.6 samples/s | 70.1 steps/s
[Step=57100 Epoch=278.4] | Loss=0.00553 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.296 | L2-Norm(final)=15.691 | 5387.1 samples/s | 84.2 steps/s
[Step=57150 Epoch=278.7] | Loss=0.00541 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.301 | L2-Norm(final)=15.697 | 2242.8 samples/s | 35.0 steps/s
[Step=57200 Epoch=278.9] | Loss=0.00525 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.305 | L2-Norm(final)=15.703 | 4403.0 samples/s | 68.8 steps/s
[Step=57250 Epoch=279.2] | Loss=0.00513 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.308 | L2-Norm(final)=15.708 | 4419.4 samples/s | 69.1 steps/s
[Step=57300 Epoch=279.4] | Loss=0.00508 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=15.714 | 4929.7 samples/s | 77.0 steps/s
[Step=57350 Epoch=279.6] | Loss=0.00496 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.313 | L2-Norm(final)=15.718 | 2305.0 samples/s | 36.0 steps/s
[Step=57400 Epoch=279.9] | Loss=0.00478 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=15.723 | 4465.4 samples/s | 69.8 steps/s
[Step=57450 Epoch=280.1] | Loss=0.00468 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.315 | L2-Norm(final)=15.728 | 4464.2 samples/s | 69.8 steps/s
[Step=57500 Epoch=280.4] | Loss=0.00459 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.316 | L2-Norm(final)=15.732 | 4554.3 samples/s | 71.2 steps/s
[Step=57550 Epoch=280.6] | Loss=0.00448 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.316 | L2-Norm(final)=15.736 | 2416.6 samples/s | 37.8 steps/s
[Step=57600 Epoch=280.9] | Loss=0.00437 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.316 | L2-Norm(final)=15.741 | 4293.7 samples/s | 67.1 steps/s
[Step=57650 Epoch=281.1] | Loss=0.00426 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.315 | L2-Norm(final)=15.744 | 4495.6 samples/s | 70.2 steps/s
[Step=57700 Epoch=281.4] | Loss=0.00421 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.315 | L2-Norm(final)=15.748 | 4405.7 samples/s | 68.8 steps/s
[Step=57750 Epoch=281.6] | Loss=0.00417 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.314 | L2-Norm(final)=15.752 | 2451.9 samples/s | 38.3 steps/s
[Step=57800 Epoch=281.8] | Loss=0.00409 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.312 | L2-Norm(final)=15.755 | 4432.8 samples/s | 69.3 steps/s
[Step=57850 Epoch=282.1] | Loss=0.00403 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=15.759 | 4441.4 samples/s | 69.4 steps/s
[Step=57900 Epoch=282.3] | Loss=0.00397 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.309 | L2-Norm(final)=15.762 | 4462.3 samples/s | 69.7 steps/s
[Step=57950 Epoch=282.6] | Loss=0.00392 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.308 | L2-Norm(final)=15.765 | 2414.8 samples/s | 37.7 steps/s
[Step=58000 Epoch=282.8] | Loss=0.00387 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.306 | L2-Norm(final)=15.768 | 4350.7 samples/s | 68.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step58000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=273.3] | Loss=0.00072 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.911 | L2-Norm(final)=15.829 | 4989.1 samples/s | 78.0 steps/s
[Step=56050 Epoch=273.5] | Loss=0.00244 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=15.836 | 4488.1 samples/s | 70.1 steps/s
[Step=56100 Epoch=273.7] | Loss=0.00249 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.914 | L2-Norm(final)=15.845 | 5066.6 samples/s | 79.2 steps/s
[Step=56150 Epoch=274.0] | Loss=0.00246 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.915 | L2-Norm(final)=15.855 | 4887.9 samples/s | 76.4 steps/s
[Step=56200 Epoch=274.2] | Loss=0.00250 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.916 | L2-Norm(final)=15.866 | 7834.3 samples/s | 122.4 steps/s
[Step=56250 Epoch=274.5] | Loss=0.00246 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=15.876 | 2164.0 samples/s | 33.8 steps/s
[Step=56300 Epoch=274.7] | Loss=0.00242 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=15.886 | 5054.8 samples/s | 79.0 steps/s
[Step=56350 Epoch=275.0] | Loss=0.00236 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=15.896 | 5019.9 samples/s | 78.4 steps/s
[Step=56400 Epoch=275.2] | Loss=0.00234 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.916 | L2-Norm(final)=15.905 | 7021.5 samples/s | 109.7 steps/s
[Step=56450 Epoch=275.4] | Loss=0.00235 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.916 | L2-Norm(final)=15.915 | 2258.9 samples/s | 35.3 steps/s
[Step=56500 Epoch=275.7] | Loss=0.00230 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.915 | L2-Norm(final)=15.924 | 5084.9 samples/s | 79.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=275.7] | Loss=0.00118 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.910 | L2-Norm(final)=16.020 | 5777.4 samples/s | 90.3 steps/s
[Step=56550 Epoch=275.9] | Loss=0.00272 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.910 | L2-Norm(final)=16.029 | 3852.3 samples/s | 60.2 steps/s
[Step=56600 Epoch=276.2] | Loss=0.00244 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.040 | 4397.6 samples/s | 68.7 steps/s
[Step=56650 Epoch=276.4] | Loss=0.00324 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.915 | L2-Norm(final)=16.049 | 4469.6 samples/s | 69.8 steps/s
[Step=56700 Epoch=276.7] | Loss=0.00396 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.920 | L2-Norm(final)=16.058 | 6572.7 samples/s | 102.7 steps/s
[Step=56750 Epoch=276.9] | Loss=0.00425 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.927 | L2-Norm(final)=16.066 | 2068.0 samples/s | 32.3 steps/s
[Step=56800 Epoch=277.2] | Loss=0.00403 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=16.075 | 4400.2 samples/s | 68.8 steps/s
[Step=56850 Epoch=277.4] | Loss=0.00427 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.937 | L2-Norm(final)=16.083 | 4507.9 samples/s | 70.4 steps/s
[Step=56900 Epoch=277.6] | Loss=0.00417 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.941 | L2-Norm(final)=16.091 | 5931.4 samples/s | 92.7 steps/s
[Step=56950 Epoch=277.9] | Loss=0.00417 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=16.099 | 2110.7 samples/s | 33.0 steps/s
[Step=57000 Epoch=278.1] | Loss=0.00416 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=16.106 | 4413.1 samples/s | 69.0 steps/s
[Step=57050 Epoch=278.4] | Loss=0.00421 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=16.113 | 4447.8 samples/s | 69.5 steps/s
[Step=57100 Epoch=278.6] | Loss=0.00431 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.952 | L2-Norm(final)=16.119 | 5493.9 samples/s | 85.8 steps/s
[Step=57150 Epoch=278.9] | Loss=0.00435 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=16.126 | 2201.3 samples/s | 34.4 steps/s
[Step=57200 Epoch=279.1] | Loss=0.00425 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=16.132 | 4512.9 samples/s | 70.5 steps/s
[Step=57250 Epoch=279.4] | Loss=0.00424 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=16.138 | 4470.8 samples/s | 69.9 steps/s
[Step=57300 Epoch=279.6] | Loss=0.00410 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=16.144 | 5009.8 samples/s | 78.3 steps/s
[Step=57350 Epoch=279.8] | Loss=0.00406 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=16.150 | 2284.9 samples/s | 35.7 steps/s
[Step=57400 Epoch=280.1] | Loss=0.00394 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=16.155 | 4486.2 samples/s | 70.1 steps/s
[Step=57450 Epoch=280.3] | Loss=0.00394 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=16.161 | 4407.1 samples/s | 68.9 steps/s
[Step=57500 Epoch=280.6] | Loss=0.00393 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.965 | L2-Norm(final)=16.166 | 4894.6 samples/s | 76.5 steps/s
[Step=57550 Epoch=280.8] | Loss=0.00387 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=16.171 | 2366.6 samples/s | 37.0 steps/s
[Step=57600 Epoch=281.1] | Loss=0.00382 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.965 | L2-Norm(final)=16.175 | 4466.9 samples/s | 69.8 steps/s
[Step=57650 Epoch=281.3] | Loss=0.00373 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=16.180 | 4429.6 samples/s | 69.2 steps/s
[Step=57700 Epoch=281.5] | Loss=0.00371 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=16.185 | 4540.3 samples/s | 70.9 steps/s
[Step=57750 Epoch=281.8] | Loss=0.00364 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.963 | L2-Norm(final)=16.189 | 2449.2 samples/s | 38.3 steps/s
[Step=57800 Epoch=282.0] | Loss=0.00362 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=16.193 | 4394.3 samples/s | 68.7 steps/s
[Step=57850 Epoch=282.3] | Loss=0.00358 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=16.197 | 4488.8 samples/s | 70.1 steps/s
[Step=57900 Epoch=282.5] | Loss=0.00352 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=16.201 | 4455.1 samples/s | 69.6 steps/s
[Step=57950 Epoch=282.8] | Loss=0.00344 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=16.205 | 2455.2 samples/s | 38.4 steps/s
[Step=58000 Epoch=283.0] | Loss=0.00340 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=16.209 | 4474.6 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step58000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=272.9] | Loss=0.00260 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=16.117 | 5473.6 samples/s | 85.5 steps/s
[Step=56050 Epoch=273.1] | Loss=0.00307 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.577 | L2-Norm(final)=16.124 | 4848.3 samples/s | 75.8 steps/s
[Step=56100 Epoch=273.3] | Loss=0.00277 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=16.134 | 5122.4 samples/s | 80.0 steps/s
[Step=56150 Epoch=273.6] | Loss=0.00287 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.580 | L2-Norm(final)=16.144 | 4945.4 samples/s | 77.3 steps/s
[Step=56200 Epoch=273.8] | Loss=0.00289 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=16.155 | 7799.0 samples/s | 121.9 steps/s
[Step=56250 Epoch=274.1] | Loss=0.00280 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=16.165 | 2229.4 samples/s | 34.8 steps/s
[Step=56300 Epoch=274.3] | Loss=0.00278 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=16.175 | 4997.2 samples/s | 78.1 steps/s
[Step=56350 Epoch=274.6] | Loss=0.00271 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=16.185 | 4963.8 samples/s | 77.6 steps/s
[Step=56400 Epoch=274.8] | Loss=0.00271 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=16.195 | 6908.5 samples/s | 107.9 steps/s
[Step=56450 Epoch=275.1] | Loss=0.00275 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=16.205 | 2283.6 samples/s | 35.7 steps/s
[Step=56500 Epoch=275.3] | Loss=0.00268 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.583 | L2-Norm(final)=16.215 | 5140.0 samples/s | 80.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=275.3] | Loss=0.00063 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=16.316 | 5011.4 samples/s | 78.3 steps/s
[Step=56550 Epoch=275.5] | Loss=0.00227 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=16.325 | 4216.0 samples/s | 65.9 steps/s
[Step=56600 Epoch=275.8] | Loss=0.00322 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=16.334 | 4546.0 samples/s | 71.0 steps/s
[Step=56650 Epoch=276.0] | Loss=0.00426 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.589 | L2-Norm(final)=16.341 | 4299.0 samples/s | 67.2 steps/s
[Step=56700 Epoch=276.3] | Loss=0.00464 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.595 | L2-Norm(final)=16.349 | 6595.6 samples/s | 103.1 steps/s
[Step=56750 Epoch=276.5] | Loss=0.00499 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.602 | L2-Norm(final)=16.357 | 2089.3 samples/s | 32.6 steps/s
[Step=56800 Epoch=276.8] | Loss=0.00508 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.609 | L2-Norm(final)=16.365 | 4480.6 samples/s | 70.0 steps/s
[Step=56850 Epoch=277.0] | Loss=0.00558 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.617 | L2-Norm(final)=16.372 | 4489.4 samples/s | 70.1 steps/s
[Step=56900 Epoch=277.2] | Loss=0.00540 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.625 | L2-Norm(final)=16.380 | 5961.0 samples/s | 93.1 steps/s
[Step=56950 Epoch=277.5] | Loss=0.00538 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.631 | L2-Norm(final)=16.387 | 2155.9 samples/s | 33.7 steps/s
[Step=57000 Epoch=277.7] | Loss=0.00532 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.635 | L2-Norm(final)=16.393 | 4379.9 samples/s | 68.4 steps/s
[Step=57050 Epoch=278.0] | Loss=0.00508 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=16.399 | 4439.0 samples/s | 69.4 steps/s
[Step=57100 Epoch=278.2] | Loss=0.00509 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.642 | L2-Norm(final)=16.404 | 5260.1 samples/s | 82.2 steps/s
[Step=57150 Epoch=278.5] | Loss=0.00490 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.645 | L2-Norm(final)=16.410 | 2259.5 samples/s | 35.3 steps/s
[Step=57200 Epoch=278.7] | Loss=0.00480 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.646 | L2-Norm(final)=16.415 | 4512.9 samples/s | 70.5 steps/s
[Step=57250 Epoch=278.9] | Loss=0.00471 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.647 | L2-Norm(final)=16.420 | 4422.3 samples/s | 69.1 steps/s
[Step=57300 Epoch=279.2] | Loss=0.00456 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.648 | L2-Norm(final)=16.425 | 4895.0 samples/s | 76.5 steps/s
[Step=57350 Epoch=279.4] | Loss=0.00444 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.648 | L2-Norm(final)=16.430 | 2289.5 samples/s | 35.8 steps/s
[Step=57400 Epoch=279.7] | Loss=0.00428 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.648 | L2-Norm(final)=16.434 | 4494.0 samples/s | 70.2 steps/s
[Step=57450 Epoch=279.9] | Loss=0.00426 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.647 | L2-Norm(final)=16.438 | 4421.5 samples/s | 69.1 steps/s
[Step=57500 Epoch=280.2] | Loss=0.00428 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.646 | L2-Norm(final)=16.443 | 4612.9 samples/s | 72.1 steps/s
[Step=57550 Epoch=280.4] | Loss=0.00421 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.646 | L2-Norm(final)=16.447 | 2404.2 samples/s | 37.6 steps/s
[Step=57600 Epoch=280.7] | Loss=0.00422 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.645 | L2-Norm(final)=16.451 | 4407.1 samples/s | 68.9 steps/s
[Step=57650 Epoch=280.9] | Loss=0.00417 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.644 | L2-Norm(final)=16.455 | 4533.9 samples/s | 70.8 steps/s
[Step=57700 Epoch=281.1] | Loss=0.00414 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.643 | L2-Norm(final)=16.459 | 4267.9 samples/s | 66.7 steps/s
[Step=57750 Epoch=281.4] | Loss=0.00407 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.642 | L2-Norm(final)=16.462 | 2340.2 samples/s | 36.6 steps/s
[Step=57800 Epoch=281.6] | Loss=0.00402 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.641 | L2-Norm(final)=16.466 | 4347.6 samples/s | 67.9 steps/s
[Step=57850 Epoch=281.9] | Loss=0.00394 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=16.470 | 4441.9 samples/s | 69.4 steps/s
[Step=57900 Epoch=282.1] | Loss=0.00390 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.637 | L2-Norm(final)=16.473 | 4490.0 samples/s | 70.2 steps/s
[Step=57950 Epoch=282.4] | Loss=0.00387 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.635 | L2-Norm(final)=16.477 | 2471.0 samples/s | 38.6 steps/s
[Step=58000 Epoch=282.6] | Loss=0.00386 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.633 | L2-Norm(final)=16.480 | 4406.7 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step58000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=273.1] | Loss=0.00080 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.272 | L2-Norm(final)=16.052 | 5103.9 samples/s | 79.7 steps/s
[Step=56050 Epoch=273.3] | Loss=0.00231 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.274 | L2-Norm(final)=16.060 | 4658.3 samples/s | 72.8 steps/s
[Step=56100 Epoch=273.6] | Loss=0.00223 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.277 | L2-Norm(final)=16.071 | 5008.7 samples/s | 78.3 steps/s
[Step=56150 Epoch=273.8] | Loss=0.00243 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=16.081 | 5001.3 samples/s | 78.1 steps/s
[Step=56200 Epoch=274.1] | Loss=0.00239 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=16.091 | 7837.3 samples/s | 122.5 steps/s
[Step=56250 Epoch=274.3] | Loss=0.00237 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=16.102 | 2237.7 samples/s | 35.0 steps/s
[Step=56300 Epoch=274.6] | Loss=0.00236 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=16.113 | 4954.7 samples/s | 77.4 steps/s
[Step=56350 Epoch=274.8] | Loss=0.00230 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.280 | L2-Norm(final)=16.124 | 5045.8 samples/s | 78.8 steps/s
[Step=56400 Epoch=275.0] | Loss=0.00225 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=16.134 | 6885.8 samples/s | 107.6 steps/s
[Step=56450 Epoch=275.3] | Loss=0.00217 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=16.144 | 2267.1 samples/s | 35.4 steps/s
[Step=56500 Epoch=275.5] | Loss=0.00216 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=16.154 | 5116.9 samples/s | 80.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=275.5] | Loss=0.00129 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=16.256 | 5538.5 samples/s | 86.5 steps/s
[Step=56550 Epoch=275.8] | Loss=0.00178 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.276 | L2-Norm(final)=16.266 | 3952.6 samples/s | 61.8 steps/s
[Step=56600 Epoch=276.0] | Loss=0.00266 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.280 | L2-Norm(final)=16.274 | 4455.2 samples/s | 69.6 steps/s
[Step=56650 Epoch=276.3] | Loss=0.00497 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.288 | L2-Norm(final)=16.283 | 4485.0 samples/s | 70.1 steps/s
[Step=56700 Epoch=276.5] | Loss=0.00560 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.297 | L2-Norm(final)=16.290 | 6497.4 samples/s | 101.5 steps/s
[Step=56750 Epoch=276.7] | Loss=0.00539 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.308 | L2-Norm(final)=16.298 | 2077.6 samples/s | 32.5 steps/s
[Step=56800 Epoch=277.0] | Loss=0.00547 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.317 | L2-Norm(final)=16.305 | 4435.2 samples/s | 69.3 steps/s
[Step=56850 Epoch=277.2] | Loss=0.00556 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.325 | L2-Norm(final)=16.313 | 4484.6 samples/s | 70.1 steps/s
[Step=56900 Epoch=277.5] | Loss=0.00540 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.333 | L2-Norm(final)=16.321 | 5853.9 samples/s | 91.5 steps/s
[Step=56950 Epoch=277.7] | Loss=0.00512 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.341 | L2-Norm(final)=16.329 | 2180.1 samples/s | 34.1 steps/s
[Step=57000 Epoch=278.0] | Loss=0.00506 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=16.337 | 4412.3 samples/s | 68.9 steps/s
[Step=57050 Epoch=278.2] | Loss=0.00502 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.351 | L2-Norm(final)=16.343 | 4544.4 samples/s | 71.0 steps/s
[Step=57100 Epoch=278.5] | Loss=0.00494 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=16.349 | 5191.4 samples/s | 81.1 steps/s
[Step=57150 Epoch=278.7] | Loss=0.00477 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.359 | L2-Norm(final)=16.355 | 2247.4 samples/s | 35.1 steps/s
[Step=57200 Epoch=278.9] | Loss=0.00453 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.362 | L2-Norm(final)=16.361 | 4447.4 samples/s | 69.5 steps/s
[Step=57250 Epoch=279.2] | Loss=0.00456 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.364 | L2-Norm(final)=16.366 | 4489.4 samples/s | 70.1 steps/s
[Step=57300 Epoch=279.4] | Loss=0.00450 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.366 | L2-Norm(final)=16.371 | 4976.5 samples/s | 77.8 steps/s
[Step=57350 Epoch=279.7] | Loss=0.00440 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.368 | L2-Norm(final)=16.376 | 2329.3 samples/s | 36.4 steps/s
[Step=57400 Epoch=279.9] | Loss=0.00426 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.369 | L2-Norm(final)=16.381 | 4436.3 samples/s | 69.3 steps/s
[Step=57450 Epoch=280.2] | Loss=0.00413 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.370 | L2-Norm(final)=16.386 | 4459.8 samples/s | 69.7 steps/s
[Step=57500 Epoch=280.4] | Loss=0.00406 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.370 | L2-Norm(final)=16.390 | 4528.0 samples/s | 70.8 steps/s
[Step=57550 Epoch=280.6] | Loss=0.00397 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.370 | L2-Norm(final)=16.394 | 2452.9 samples/s | 38.3 steps/s
[Step=57600 Epoch=280.9] | Loss=0.00388 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.369 | L2-Norm(final)=16.399 | 4389.6 samples/s | 68.6 steps/s
[Step=57650 Epoch=281.1] | Loss=0.00378 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.369 | L2-Norm(final)=16.403 | 4463.8 samples/s | 69.7 steps/s
[Step=57700 Epoch=281.4] | Loss=0.00371 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.368 | L2-Norm(final)=16.407 | 4465.5 samples/s | 69.8 steps/s
[Step=57750 Epoch=281.6] | Loss=0.00365 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.367 | L2-Norm(final)=16.410 | 2507.0 samples/s | 39.2 steps/s
[Step=57800 Epoch=281.9] | Loss=0.00356 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.366 | L2-Norm(final)=16.414 | 4276.3 samples/s | 66.8 steps/s
[Step=57850 Epoch=282.1] | Loss=0.00349 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.364 | L2-Norm(final)=16.418 | 4468.6 samples/s | 69.8 steps/s
[Step=57900 Epoch=282.4] | Loss=0.00343 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.362 | L2-Norm(final)=16.422 | 4472.7 samples/s | 69.9 steps/s
[Step=57950 Epoch=282.6] | Loss=0.00336 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=16.425 | 2439.5 samples/s | 38.1 steps/s
[Step=58000 Epoch=282.8] | Loss=0.00329 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.358 | L2-Norm(final)=16.429 | 4506.6 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step58000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=274.6] | Loss=0.00100 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=16.170 | 5217.0 samples/s | 81.5 steps/s
[Step=56050 Epoch=274.9] | Loss=0.00286 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.068 | L2-Norm(final)=16.177 | 4468.0 samples/s | 69.8 steps/s
[Step=56100 Epoch=275.1] | Loss=0.00280 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=16.187 | 4944.2 samples/s | 77.3 steps/s
[Step=56150 Epoch=275.4] | Loss=0.00252 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=16.197 | 4968.1 samples/s | 77.6 steps/s
[Step=56200 Epoch=275.6] | Loss=0.00244 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=16.207 | 8015.2 samples/s | 125.2 steps/s
[Step=56250 Epoch=275.8] | Loss=0.00233 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.217 | 2201.0 samples/s | 34.4 steps/s
[Step=56300 Epoch=276.1] | Loss=0.00227 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.227 | 5029.9 samples/s | 78.6 steps/s
[Step=56350 Epoch=276.3] | Loss=0.00225 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.237 | 5087.2 samples/s | 79.5 steps/s
[Step=56400 Epoch=276.6] | Loss=0.00222 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.247 | 7375.5 samples/s | 115.2 steps/s
[Step=56450 Epoch=276.8] | Loss=0.00220 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=16.256 | 2240.5 samples/s | 35.0 steps/s
[Step=56500 Epoch=277.1] | Loss=0.00217 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=16.266 | 5091.0 samples/s | 79.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=277.1] | Loss=0.00020 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.061 | L2-Norm(final)=16.362 | 5760.3 samples/s | 90.0 steps/s
[Step=56550 Epoch=277.3] | Loss=0.00478 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=16.367 | 3844.4 samples/s | 60.1 steps/s
[Step=56600 Epoch=277.6] | Loss=0.00428 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=16.374 | 4454.1 samples/s | 69.6 steps/s
[Step=56650 Epoch=277.8] | Loss=0.00423 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.072 | L2-Norm(final)=16.382 | 4516.4 samples/s | 70.6 steps/s
[Step=56700 Epoch=278.0] | Loss=0.00423 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=16.393 | 6560.8 samples/s | 102.5 steps/s
[Step=56750 Epoch=278.3] | Loss=0.00455 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.089 | L2-Norm(final)=16.404 | 2082.4 samples/s | 32.5 steps/s
[Step=56800 Epoch=278.5] | Loss=0.00499 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.098 | L2-Norm(final)=16.413 | 4392.3 samples/s | 68.6 steps/s
[Step=56850 Epoch=278.8] | Loss=0.00554 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=16.422 | 4445.9 samples/s | 69.5 steps/s
[Step=56900 Epoch=279.0] | Loss=0.00621 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=16.430 | 6253.3 samples/s | 97.7 steps/s
[Step=56950 Epoch=279.3] | Loss=0.00585 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=16.438 | 2124.3 samples/s | 33.2 steps/s
[Step=57000 Epoch=279.5] | Loss=0.00556 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=16.446 | 4434.4 samples/s | 69.3 steps/s
[Step=57050 Epoch=279.8] | Loss=0.00539 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=16.453 | 4484.6 samples/s | 70.1 steps/s
[Step=57100 Epoch=280.0] | Loss=0.00524 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=16.460 | 5798.8 samples/s | 90.6 steps/s
[Step=57150 Epoch=280.3] | Loss=0.00509 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.157 | L2-Norm(final)=16.467 | 2169.3 samples/s | 33.9 steps/s
[Step=57200 Epoch=280.5] | Loss=0.00486 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.161 | L2-Norm(final)=16.473 | 4439.8 samples/s | 69.4 steps/s
[Step=57250 Epoch=280.7] | Loss=0.00465 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.164 | L2-Norm(final)=16.478 | 4533.8 samples/s | 70.8 steps/s
[Step=57300 Epoch=281.0] | Loss=0.00458 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=16.484 | 5366.1 samples/s | 83.8 steps/s
[Step=57350 Epoch=281.2] | Loss=0.00442 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=16.489 | 2210.6 samples/s | 34.5 steps/s
[Step=57400 Epoch=281.5] | Loss=0.00427 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=16.494 | 4396.9 samples/s | 68.7 steps/s
[Step=57450 Epoch=281.7] | Loss=0.00415 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.498 | 4478.7 samples/s | 70.0 steps/s
[Step=57500 Epoch=282.0] | Loss=0.00405 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.503 | 5140.9 samples/s | 80.3 steps/s
[Step=57550 Epoch=282.2] | Loss=0.00398 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.507 | 2198.2 samples/s | 34.3 steps/s
[Step=57600 Epoch=282.5] | Loss=0.00393 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.511 | 4532.3 samples/s | 70.8 steps/s
[Step=57650 Epoch=282.7] | Loss=0.00387 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.515 | 4424.1 samples/s | 69.1 steps/s
[Step=57700 Epoch=283.0] | Loss=0.00377 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=16.518 | 4923.2 samples/s | 76.9 steps/s
[Step=57750 Epoch=283.2] | Loss=0.00373 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=16.522 | 2359.7 samples/s | 36.9 steps/s
[Step=57800 Epoch=283.4] | Loss=0.00369 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=16.525 | 4466.0 samples/s | 69.8 steps/s
[Step=57850 Epoch=283.7] | Loss=0.00363 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=16.529 | 4425.5 samples/s | 69.1 steps/s
[Step=57900 Epoch=283.9] | Loss=0.00365 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.168 | L2-Norm(final)=16.532 | 4622.6 samples/s | 72.2 steps/s
[Step=57950 Epoch=284.2] | Loss=0.00361 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=16.535 | 2388.3 samples/s | 37.3 steps/s
[Step=58000 Epoch=284.4] | Loss=0.00355 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=16.538 | 4453.1 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step58000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=530.7] | Loss=0.00144 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.742 | L2-Norm(final)=8.112 | 4972.3 samples/s | 77.7 steps/s
[Step=56050 Epoch=531.1] | Loss=0.00039 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.773 | L2-Norm(final)=8.134 | 4282.0 samples/s | 66.9 steps/s
[Step=56100 Epoch=531.6] | Loss=0.00025 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.793 | L2-Norm(final)=8.151 | 7505.6 samples/s | 117.3 steps/s
[Step=56150 Epoch=532.1] | Loss=0.00018 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.802 | L2-Norm(final)=8.163 | 2152.6 samples/s | 33.6 steps/s
[Step=56200 Epoch=532.5] | Loss=0.00014 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.807 | L2-Norm(final)=8.171 | 6267.7 samples/s | 97.9 steps/s
[Step=56250 Epoch=533.0] | Loss=0.00012 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.811 | L2-Norm(final)=8.178 | 2217.0 samples/s | 34.6 steps/s
[Step=56300 Epoch=533.5] | Loss=0.00011 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.813 | L2-Norm(final)=8.184 | 5897.5 samples/s | 92.1 steps/s
[Step=56350 Epoch=534.0] | Loss=0.00009 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.815 | L2-Norm(final)=8.190 | 2318.2 samples/s | 36.2 steps/s
[Step=56400 Epoch=534.4] | Loss=0.00009 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.817 | L2-Norm(final)=8.196 | 5352.6 samples/s | 83.6 steps/s
[Step=56450 Epoch=534.9] | Loss=0.00008 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.818 | L2-Norm(final)=8.201 | 2371.6 samples/s | 37.1 steps/s
[Step=56500 Epoch=535.4] | Loss=0.00007 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.819 | L2-Norm(final)=8.206 | 4884.0 samples/s | 76.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=535.4] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.829 | L2-Norm(final)=8.256 | 5548.1 samples/s | 86.7 steps/s
[Step=56550 Epoch=535.9] | Loss=0.00002 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=8.260 | 3818.8 samples/s | 59.7 steps/s
[Step=56600 Epoch=536.3] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.814 | L2-Norm(final)=8.262 | 6093.3 samples/s | 95.2 steps/s
[Step=56650 Epoch=536.8] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.802 | L2-Norm(final)=8.264 | 2018.3 samples/s | 31.5 steps/s
[Step=56700 Epoch=537.3] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.789 | L2-Norm(final)=8.265 | 5678.4 samples/s | 88.7 steps/s
[Step=56750 Epoch=537.8] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.776 | L2-Norm(final)=8.266 | 2070.2 samples/s | 32.3 steps/s
[Step=56800 Epoch=538.2] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.763 | L2-Norm(final)=8.267 | 5172.1 samples/s | 80.8 steps/s
[Step=56850 Epoch=538.7] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.749 | L2-Norm(final)=8.268 | 2177.6 samples/s | 34.0 steps/s
[Step=56900 Epoch=539.2] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.735 | L2-Norm(final)=8.269 | 4647.7 samples/s | 72.6 steps/s
[Step=56950 Epoch=539.7] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.721 | L2-Norm(final)=8.269 | 2290.8 samples/s | 35.8 steps/s
[Step=57000 Epoch=540.1] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.707 | L2-Norm(final)=8.270 | 4223.3 samples/s | 66.0 steps/s
[Step=57050 Epoch=540.6] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.693 | L2-Norm(final)=8.270 | 2306.8 samples/s | 36.0 steps/s
[Step=57100 Epoch=541.1] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.679 | L2-Norm(final)=8.271 | 4271.5 samples/s | 66.7 steps/s
[Step=57150 Epoch=541.5] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.664 | L2-Norm(final)=8.272 | 2365.7 samples/s | 37.0 steps/s
[Step=57200 Epoch=542.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.650 | L2-Norm(final)=8.272 | 4315.8 samples/s | 67.4 steps/s
[Step=57250 Epoch=542.5] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.635 | L2-Norm(final)=8.273 | 2359.4 samples/s | 36.9 steps/s
[Step=57300 Epoch=543.0] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=8.274 | 4284.5 samples/s | 66.9 steps/s
[Step=57350 Epoch=543.4] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.605 | L2-Norm(final)=8.274 | 2395.7 samples/s | 37.4 steps/s
[Step=57400 Epoch=543.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.590 | L2-Norm(final)=8.275 | 4101.0 samples/s | 64.1 steps/s
[Step=57450 Epoch=544.4] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.575 | L2-Norm(final)=8.275 | 6571.4 samples/s | 102.7 steps/s
[Step=57500 Epoch=544.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.559 | L2-Norm(final)=8.276 | 2004.9 samples/s | 31.3 steps/s
[Step=57550 Epoch=545.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.544 | L2-Norm(final)=8.277 | 5894.3 samples/s | 92.1 steps/s
[Step=57600 Epoch=545.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.528 | L2-Norm(final)=8.277 | 2073.2 samples/s | 32.4 steps/s
[Step=57650 Epoch=546.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=8.278 | 5236.8 samples/s | 81.8 steps/s
[Step=57700 Epoch=546.8] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=8.279 | 2132.0 samples/s | 33.3 steps/s
[Step=57750 Epoch=547.2] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.481 | L2-Norm(final)=8.279 | 4848.9 samples/s | 75.8 steps/s
[Step=57800 Epoch=547.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.465 | L2-Norm(final)=8.280 | 2252.0 samples/s | 35.2 steps/s
[Step=57850 Epoch=548.2] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.448 | L2-Norm(final)=8.281 | 4397.3 samples/s | 68.7 steps/s
[Step=57900 Epoch=548.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.432 | L2-Norm(final)=8.282 | 2312.6 samples/s | 36.1 steps/s
[Step=57950 Epoch=549.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.416 | L2-Norm(final)=8.282 | 4133.8 samples/s | 64.6 steps/s
[Step=58000 Epoch=549.6] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=8.283 | 2415.1 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step58000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=532.7] | Loss=0.00022 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.767 | L2-Norm(final)=9.367 | 5460.3 samples/s | 85.3 steps/s
[Step=56050 Epoch=533.2] | Loss=0.00004 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.768 | L2-Norm(final)=9.368 | 4280.3 samples/s | 66.9 steps/s
[Step=56100 Epoch=533.7] | Loss=0.00004 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.769 | L2-Norm(final)=9.370 | 7360.3 samples/s | 115.0 steps/s
[Step=56150 Epoch=534.1] | Loss=0.00004 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=9.372 | 2146.4 samples/s | 33.5 steps/s
[Step=56200 Epoch=534.6] | Loss=0.00004 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=9.373 | 6287.7 samples/s | 98.2 steps/s
[Step=56250 Epoch=535.1] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=9.375 | 2197.8 samples/s | 34.3 steps/s
[Step=56300 Epoch=535.6] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=9.376 | 5989.9 samples/s | 93.6 steps/s
[Step=56350 Epoch=536.0] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=9.377 | 2301.0 samples/s | 36.0 steps/s
[Step=56400 Epoch=536.5] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=9.379 | 5437.6 samples/s | 85.0 steps/s
[Step=56450 Epoch=537.0] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.772 | L2-Norm(final)=9.380 | 2433.9 samples/s | 38.0 steps/s
[Step=56500 Epoch=537.5] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.772 | L2-Norm(final)=9.382 | 4719.9 samples/s | 73.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=537.5] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.774 | L2-Norm(final)=9.399 | 5327.5 samples/s | 83.2 steps/s
[Step=56550 Epoch=537.9] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.773 | L2-Norm(final)=9.400 | 3805.1 samples/s | 59.5 steps/s
[Step=56600 Epoch=538.4] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.772 | L2-Norm(final)=9.401 | 6218.4 samples/s | 97.2 steps/s
[Step=56650 Epoch=538.9] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=9.402 | 2029.1 samples/s | 31.7 steps/s
[Step=56700 Epoch=539.4] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=9.404 | 5640.8 samples/s | 88.1 steps/s
[Step=56750 Epoch=539.8] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.768 | L2-Norm(final)=9.405 | 2075.5 samples/s | 32.4 steps/s
[Step=56800 Epoch=540.3] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.767 | L2-Norm(final)=9.405 | 5150.5 samples/s | 80.5 steps/s
[Step=56850 Epoch=540.8] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.765 | L2-Norm(final)=9.406 | 2175.8 samples/s | 34.0 steps/s
[Step=56900 Epoch=541.3] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=9.407 | 4743.7 samples/s | 74.1 steps/s
[Step=56950 Epoch=541.7] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.762 | L2-Norm(final)=9.408 | 2245.0 samples/s | 35.1 steps/s
[Step=57000 Epoch=542.2] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.761 | L2-Norm(final)=9.409 | 4376.4 samples/s | 68.4 steps/s
[Step=57050 Epoch=542.7] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.759 | L2-Norm(final)=9.409 | 2382.3 samples/s | 37.2 steps/s
[Step=57100 Epoch=543.2] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.757 | L2-Norm(final)=9.410 | 4124.1 samples/s | 64.4 steps/s
[Step=57150 Epoch=543.6] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.755 | L2-Norm(final)=9.410 | 2385.0 samples/s | 37.3 steps/s
[Step=57200 Epoch=544.1] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.753 | L2-Norm(final)=9.411 | 4301.4 samples/s | 67.2 steps/s
[Step=57250 Epoch=544.6] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.752 | L2-Norm(final)=9.412 | 2391.4 samples/s | 37.4 steps/s
[Step=57300 Epoch=545.1] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.750 | L2-Norm(final)=9.412 | 4341.5 samples/s | 67.8 steps/s
[Step=57350 Epoch=545.5] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.748 | L2-Norm(final)=9.413 | 2480.8 samples/s | 38.8 steps/s
[Step=57400 Epoch=546.0] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.746 | L2-Norm(final)=9.413 | 3841.1 samples/s | 60.0 steps/s
[Step=57450 Epoch=546.5] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.744 | L2-Norm(final)=9.414 | 6573.0 samples/s | 102.7 steps/s
[Step=57500 Epoch=547.0] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.741 | L2-Norm(final)=9.414 | 1979.4 samples/s | 30.9 steps/s
[Step=57550 Epoch=547.4] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.739 | L2-Norm(final)=9.415 | 5872.4 samples/s | 91.8 steps/s
[Step=57600 Epoch=547.9] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.737 | L2-Norm(final)=9.415 | 2075.8 samples/s | 32.4 steps/s
[Step=57650 Epoch=548.4] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.735 | L2-Norm(final)=9.416 | 5257.7 samples/s | 82.2 steps/s
[Step=57700 Epoch=548.9] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.733 | L2-Norm(final)=9.416 | 2088.1 samples/s | 32.6 steps/s
[Step=57750 Epoch=549.3] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.730 | L2-Norm(final)=9.417 | 4876.9 samples/s | 76.2 steps/s
[Step=57800 Epoch=549.8] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.728 | L2-Norm(final)=9.417 | 2241.3 samples/s | 35.0 steps/s
[Step=57850 Epoch=550.3] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.726 | L2-Norm(final)=9.418 | 4490.6 samples/s | 70.2 steps/s
[Step=57900 Epoch=550.8] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.723 | L2-Norm(final)=9.418 | 2332.0 samples/s | 36.4 steps/s
[Step=57950 Epoch=551.2] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.721 | L2-Norm(final)=9.419 | 4143.7 samples/s | 64.7 steps/s
[Step=58000 Epoch=551.7] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.718 | L2-Norm(final)=9.419 | 2412.5 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step58000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=534.8] | Loss=0.00076 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.646 | L2-Norm(final)=8.780 | 5613.8 samples/s | 87.7 steps/s
[Step=56050 Epoch=535.2] | Loss=0.00041 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.688 | L2-Norm(final)=8.821 | 3970.2 samples/s | 62.0 steps/s
[Step=56100 Epoch=535.7] | Loss=0.00027 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.722 | L2-Norm(final)=8.848 | 7384.7 samples/s | 115.4 steps/s
[Step=56150 Epoch=536.2] | Loss=0.00020 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.738 | L2-Norm(final)=8.864 | 2114.3 samples/s | 33.0 steps/s
[Step=56200 Epoch=536.7] | Loss=0.00015 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.748 | L2-Norm(final)=8.875 | 6879.0 samples/s | 107.5 steps/s
[Step=56250 Epoch=537.2] | Loss=0.00013 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.754 | L2-Norm(final)=8.884 | 2134.9 samples/s | 33.4 steps/s
[Step=56300 Epoch=537.6] | Loss=0.00011 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.758 | L2-Norm(final)=8.891 | 6270.0 samples/s | 98.0 steps/s
[Step=56350 Epoch=538.1] | Loss=0.00010 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.761 | L2-Norm(final)=8.897 | 2248.0 samples/s | 35.1 steps/s
[Step=56400 Epoch=538.6] | Loss=0.00009 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.763 | L2-Norm(final)=8.903 | 5692.3 samples/s | 88.9 steps/s
[Step=56450 Epoch=539.1] | Loss=0.00008 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.765 | L2-Norm(final)=8.909 | 2394.6 samples/s | 37.4 steps/s
[Step=56500 Epoch=539.5] | Loss=0.00007 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.766 | L2-Norm(final)=8.914 | 5054.5 samples/s | 79.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=539.5] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.778 | L2-Norm(final)=8.966 | 5275.6 samples/s | 82.4 steps/s
[Step=56550 Epoch=540.0] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.761 | L2-Norm(final)=8.970 | 3733.7 samples/s | 58.3 steps/s
[Step=56600 Epoch=540.5] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.734 | L2-Norm(final)=8.972 | 6377.3 samples/s | 99.6 steps/s
[Step=56650 Epoch=541.0] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.704 | L2-Norm(final)=8.974 | 2049.4 samples/s | 32.0 steps/s
[Step=56700 Epoch=541.5] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.674 | L2-Norm(final)=8.975 | 5498.1 samples/s | 85.9 steps/s
[Step=56750 Epoch=541.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.643 | L2-Norm(final)=8.975 | 2075.0 samples/s | 32.4 steps/s
[Step=56800 Epoch=542.4] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.611 | L2-Norm(final)=8.976 | 5343.1 samples/s | 83.5 steps/s
[Step=56850 Epoch=542.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.580 | L2-Norm(final)=8.977 | 2097.3 samples/s | 32.8 steps/s
[Step=56900 Epoch=543.4] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.549 | L2-Norm(final)=8.977 | 5016.2 samples/s | 78.4 steps/s
[Step=56950 Epoch=543.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.517 | L2-Norm(final)=8.978 | 2198.6 samples/s | 34.4 steps/s
[Step=57000 Epoch=544.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.486 | L2-Norm(final)=8.978 | 4632.2 samples/s | 72.4 steps/s
[Step=57050 Epoch=544.8] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.455 | L2-Norm(final)=8.979 | 2250.8 samples/s | 35.2 steps/s
[Step=57100 Epoch=545.3] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.423 | L2-Norm(final)=8.980 | 4237.1 samples/s | 66.2 steps/s
[Step=57150 Epoch=545.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.392 | L2-Norm(final)=8.980 | 2366.8 samples/s | 37.0 steps/s
[Step=57200 Epoch=546.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.360 | L2-Norm(final)=8.981 | 4248.5 samples/s | 66.4 steps/s
[Step=57250 Epoch=546.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.329 | L2-Norm(final)=8.982 | 2379.1 samples/s | 37.2 steps/s
[Step=57300 Epoch=547.2] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=8.982 | 4190.1 samples/s | 65.5 steps/s
[Step=57350 Epoch=547.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.266 | L2-Norm(final)=8.983 | 2373.2 samples/s | 37.1 steps/s
[Step=57400 Epoch=548.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.235 | L2-Norm(final)=8.984 | 4166.8 samples/s | 65.1 steps/s
[Step=57450 Epoch=548.6] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.203 | L2-Norm(final)=8.985 | 2449.8 samples/s | 38.3 steps/s
[Step=57500 Epoch=549.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.172 | L2-Norm(final)=8.985 | 4093.5 samples/s | 64.0 steps/s
[Step=57550 Epoch=549.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.140 | L2-Norm(final)=8.986 | 7026.6 samples/s | 109.8 steps/s
[Step=57600 Epoch=550.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.108 | L2-Norm(final)=8.987 | 1953.3 samples/s | 30.5 steps/s
[Step=57650 Epoch=550.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=8.988 | 6213.6 samples/s | 97.1 steps/s
[Step=57700 Epoch=551.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=8.989 | 2005.3 samples/s | 31.3 steps/s
[Step=57750 Epoch=551.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=8.990 | 5814.6 samples/s | 90.9 steps/s
[Step=57800 Epoch=552.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.982 | L2-Norm(final)=8.991 | 2061.5 samples/s | 32.2 steps/s
[Step=57850 Epoch=552.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=8.992 | 5359.2 samples/s | 83.7 steps/s
[Step=57900 Epoch=552.9] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.918 | L2-Norm(final)=8.993 | 2134.8 samples/s | 33.4 steps/s
[Step=57950 Epoch=553.4] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.886 | L2-Norm(final)=8.995 | 4973.7 samples/s | 77.7 steps/s
[Step=58000 Epoch=553.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=8.996 | 2191.3 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step58000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=527.7] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.903 | L2-Norm(final)=8.796 | 5183.3 samples/s | 81.0 steps/s
[Step=56050 Epoch=528.2] | Loss=0.00008 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.906 | L2-Norm(final)=8.800 | 4349.3 samples/s | 68.0 steps/s
[Step=56100 Epoch=528.6] | Loss=0.00006 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.908 | L2-Norm(final)=8.804 | 7354.7 samples/s | 114.9 steps/s
[Step=56150 Epoch=529.1] | Loss=0.00005 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.909 | L2-Norm(final)=8.807 | 2144.1 samples/s | 33.5 steps/s
[Step=56200 Epoch=529.6] | Loss=0.00005 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.910 | L2-Norm(final)=8.811 | 6299.3 samples/s | 98.4 steps/s
[Step=56250 Epoch=530.0] | Loss=0.00005 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.912 | L2-Norm(final)=8.814 | 2212.0 samples/s | 34.6 steps/s
[Step=56300 Epoch=530.5] | Loss=0.00005 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.913 | L2-Norm(final)=8.818 | 5689.1 samples/s | 88.9 steps/s
[Step=56350 Epoch=531.0] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.914 | L2-Norm(final)=8.821 | 2336.7 samples/s | 36.5 steps/s
[Step=56400 Epoch=531.4] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.915 | L2-Norm(final)=8.825 | 5096.3 samples/s | 79.6 steps/s
[Step=56450 Epoch=531.9] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.916 | L2-Norm(final)=8.828 | 2459.8 samples/s | 38.4 steps/s
[Step=56500 Epoch=532.4] | Loss=0.00004 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.916 | L2-Norm(final)=8.832 | 4678.4 samples/s | 73.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=532.4] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.924 | L2-Norm(final)=8.867 | 5425.1 samples/s | 84.8 steps/s
[Step=56550 Epoch=532.9] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.925 | L2-Norm(final)=8.872 | 3642.0 samples/s | 56.9 steps/s
[Step=56600 Epoch=533.3] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.924 | L2-Norm(final)=8.875 | 6220.9 samples/s | 97.2 steps/s
[Step=56650 Epoch=533.8] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=8.878 | 2042.8 samples/s | 31.9 steps/s
[Step=56700 Epoch=534.3] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.921 | L2-Norm(final)=8.881 | 5413.3 samples/s | 84.6 steps/s
[Step=56750 Epoch=534.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.918 | L2-Norm(final)=8.883 | 2119.6 samples/s | 33.1 steps/s
[Step=56800 Epoch=535.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.915 | L2-Norm(final)=8.884 | 4964.6 samples/s | 77.6 steps/s
[Step=56850 Epoch=535.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.912 | L2-Norm(final)=8.886 | 2204.9 samples/s | 34.5 steps/s
[Step=56900 Epoch=536.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.908 | L2-Norm(final)=8.887 | 4389.1 samples/s | 68.6 steps/s
[Step=56950 Epoch=536.6] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=8.889 | 2321.3 samples/s | 36.3 steps/s
[Step=57000 Epoch=537.1] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.901 | L2-Norm(final)=8.890 | 4280.4 samples/s | 66.9 steps/s
[Step=57050 Epoch=537.6] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.897 | L2-Norm(final)=8.891 | 2392.5 samples/s | 37.4 steps/s
[Step=57100 Epoch=538.0] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.893 | L2-Norm(final)=8.893 | 4266.4 samples/s | 66.7 steps/s
[Step=57150 Epoch=538.5] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.890 | L2-Norm(final)=8.894 | 2324.7 samples/s | 36.3 steps/s
[Step=57200 Epoch=539.0] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.886 | L2-Norm(final)=8.895 | 4288.2 samples/s | 67.0 steps/s
[Step=57250 Epoch=539.5] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.882 | L2-Norm(final)=8.896 | 2603.0 samples/s | 40.7 steps/s
[Step=57300 Epoch=539.9] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.877 | L2-Norm(final)=8.897 | 3613.7 samples/s | 56.5 steps/s
[Step=57350 Epoch=540.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.873 | L2-Norm(final)=8.898 | 6309.6 samples/s | 98.6 steps/s
[Step=57400 Epoch=540.9] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.869 | L2-Norm(final)=8.900 | 1997.3 samples/s | 31.2 steps/s
[Step=57450 Epoch=541.3] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.865 | L2-Norm(final)=8.901 | 5562.8 samples/s | 86.9 steps/s
[Step=57500 Epoch=541.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.860 | L2-Norm(final)=8.902 | 2125.0 samples/s | 33.2 steps/s
[Step=57550 Epoch=542.3] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.856 | L2-Norm(final)=8.903 | 4919.1 samples/s | 76.9 steps/s
[Step=57600 Epoch=542.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.851 | L2-Norm(final)=8.904 | 2227.2 samples/s | 34.8 steps/s
[Step=57650 Epoch=543.2] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.847 | L2-Norm(final)=8.905 | 4439.9 samples/s | 69.4 steps/s
[Step=57700 Epoch=543.7] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.842 | L2-Norm(final)=8.906 | 2289.4 samples/s | 35.8 steps/s
[Step=57750 Epoch=544.2] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.838 | L2-Norm(final)=8.907 | 4204.9 samples/s | 65.7 steps/s
[Step=57800 Epoch=544.6] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.833 | L2-Norm(final)=8.908 | 2392.5 samples/s | 37.4 steps/s
[Step=57850 Epoch=545.1] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.828 | L2-Norm(final)=8.909 | 4272.4 samples/s | 66.8 steps/s
[Step=57900 Epoch=545.6] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.823 | L2-Norm(final)=8.910 | 2415.4 samples/s | 37.7 steps/s
[Step=57950 Epoch=546.1] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.818 | L2-Norm(final)=8.911 | 4215.3 samples/s | 65.9 steps/s
[Step=58000 Epoch=546.5] | Loss=0.00001 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.813 | L2-Norm(final)=8.912 | 2413.4 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step58000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=533.7] | Loss=0.00005 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.706 | L2-Norm(final)=9.417 | 5135.2 samples/s | 80.2 steps/s
[Step=56050 Epoch=534.2] | Loss=0.00037 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.739 | L2-Norm(final)=9.451 | 4167.5 samples/s | 65.1 steps/s
[Step=56100 Epoch=534.7] | Loss=0.00025 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.761 | L2-Norm(final)=9.475 | 7644.1 samples/s | 119.4 steps/s
[Step=56150 Epoch=535.2] | Loss=0.00019 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.775 | L2-Norm(final)=9.493 | 2132.1 samples/s | 33.3 steps/s
[Step=56200 Epoch=535.6] | Loss=0.00016 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.784 | L2-Norm(final)=9.507 | 6726.8 samples/s | 105.1 steps/s
[Step=56250 Epoch=536.1] | Loss=0.00014 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.791 | L2-Norm(final)=9.519 | 2161.7 samples/s | 33.8 steps/s
[Step=56300 Epoch=536.6] | Loss=0.00012 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.796 | L2-Norm(final)=9.529 | 6147.1 samples/s | 96.0 steps/s
[Step=56350 Epoch=537.1] | Loss=0.00011 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.800 | L2-Norm(final)=9.539 | 2232.0 samples/s | 34.9 steps/s
[Step=56400 Epoch=537.5] | Loss=0.00010 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.803 | L2-Norm(final)=9.547 | 5711.7 samples/s | 89.2 steps/s
[Step=56450 Epoch=538.0] | Loss=0.00009 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.806 | L2-Norm(final)=9.555 | 2370.0 samples/s | 37.0 steps/s
[Step=56500 Epoch=538.5] | Loss=0.00008 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.808 | L2-Norm(final)=9.562 | 5091.4 samples/s | 79.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=538.5] | Loss=0.00002 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.830 | L2-Norm(final)=9.635 | 5120.2 samples/s | 80.0 steps/s
[Step=56550 Epoch=539.0] | Loss=0.00699 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.873 | L2-Norm(final)=9.639 | 3747.7 samples/s | 58.6 steps/s
[Step=56600 Epoch=539.4] | Loss=0.00460 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.936 | L2-Norm(final)=9.632 | 6306.2 samples/s | 98.5 steps/s
[Step=56650 Epoch=539.9] | Loss=0.00323 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.965 | L2-Norm(final)=9.630 | 2016.9 samples/s | 31.5 steps/s
[Step=56700 Epoch=540.4] | Loss=0.00246 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.981 | L2-Norm(final)=9.630 | 5847.0 samples/s | 91.4 steps/s
[Step=56750 Epoch=540.9] | Loss=0.00198 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.991 | L2-Norm(final)=9.631 | 2073.7 samples/s | 32.4 steps/s
[Step=56800 Epoch=541.4] | Loss=0.00165 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.997 | L2-Norm(final)=9.632 | 5295.7 samples/s | 82.7 steps/s
[Step=56850 Epoch=541.8] | Loss=0.00142 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=9.632 | 2095.5 samples/s | 32.7 steps/s
[Step=56900 Epoch=542.3] | Loss=0.00124 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=9.632 | 4967.8 samples/s | 77.6 steps/s
[Step=56950 Epoch=542.8] | Loss=0.00111 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.006 | L2-Norm(final)=9.633 | 2174.3 samples/s | 34.0 steps/s
[Step=57000 Epoch=543.3] | Loss=0.00100 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.007 | L2-Norm(final)=9.633 | 4494.9 samples/s | 70.2 steps/s
[Step=57050 Epoch=543.7] | Loss=0.00091 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=9.634 | 2212.9 samples/s | 34.6 steps/s
[Step=57100 Epoch=544.2] | Loss=0.00083 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.634 | 4265.7 samples/s | 66.7 steps/s
[Step=57150 Epoch=544.7] | Loss=0.00077 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.635 | 2322.3 samples/s | 36.3 steps/s
[Step=57200 Epoch=545.2] | Loss=0.00072 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.635 | 4209.4 samples/s | 65.8 steps/s
[Step=57250 Epoch=545.6] | Loss=0.00067 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.636 | 2386.0 samples/s | 37.3 steps/s
[Step=57300 Epoch=546.1] | Loss=0.00063 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.637 | 4161.8 samples/s | 65.0 steps/s
[Step=57350 Epoch=546.6] | Loss=0.00059 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.637 | 2365.4 samples/s | 37.0 steps/s
[Step=57400 Epoch=547.1] | Loss=0.00056 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.009 | L2-Norm(final)=9.638 | 4260.8 samples/s | 66.6 steps/s
[Step=57450 Epoch=547.6] | Loss=0.00053 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=9.638 | 2339.0 samples/s | 36.5 steps/s
[Step=57500 Epoch=548.0] | Loss=0.00050 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=9.639 | 4219.1 samples/s | 65.9 steps/s
[Step=57550 Epoch=548.5] | Loss=0.00048 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.007 | L2-Norm(final)=9.639 | 6976.3 samples/s | 109.0 steps/s
[Step=57600 Epoch=549.0] | Loss=0.00046 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.006 | L2-Norm(final)=9.640 | 1962.1 samples/s | 30.7 steps/s
[Step=57650 Epoch=549.5] | Loss=0.00044 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.006 | L2-Norm(final)=9.641 | 6360.1 samples/s | 99.4 steps/s
[Step=57700 Epoch=549.9] | Loss=0.00042 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.005 | L2-Norm(final)=9.641 | 1989.9 samples/s | 31.1 steps/s
[Step=57750 Epoch=550.4] | Loss=0.00040 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.004 | L2-Norm(final)=9.642 | 5710.0 samples/s | 89.2 steps/s
[Step=57800 Epoch=550.9] | Loss=0.00039 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.003 | L2-Norm(final)=9.643 | 2077.9 samples/s | 32.5 steps/s
[Step=57850 Epoch=551.4] | Loss=0.00038 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.002 | L2-Norm(final)=9.643 | 5207.3 samples/s | 81.4 steps/s
[Step=57900 Epoch=551.8] | Loss=0.00036 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=9.644 | 2126.8 samples/s | 33.2 steps/s
[Step=57950 Epoch=552.3] | Loss=0.00035 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.000 | L2-Norm(final)=9.645 | 4939.0 samples/s | 77.2 steps/s
[Step=58000 Epoch=552.8] | Loss=0.00034 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.999 | L2-Norm(final)=9.645 | 2186.0 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11201 | acc=0.9566 | tpr=0.9692 | fpr=0.0706 | 4946.7 samples/s | 19.3 steps/s
Avg test loss: 0.11451, Avg test acc: 0.95496, Avg tpr: 0.96736, Avg fpr: 0.07230, total FA: 564

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12115 | acc=0.9582 | tpr=0.9758 | fpr=0.0800 | 4913.6 samples/s | 19.2 steps/s
Avg test loss: 0.12260, Avg test acc: 0.95793, Avg tpr: 0.97476, Avg fpr: 0.07909, total FA: 617

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10606 | acc=0.9584 | tpr=0.9730 | fpr=0.0731 | 4922.7 samples/s | 19.2 steps/s
Avg test loss: 0.10993, Avg test acc: 0.95741, Avg tpr: 0.97132, Avg fpr: 0.07320, total FA: 571

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.11022 | acc=0.9602 | tpr=0.9731 | fpr=0.0676 | 4825.5 samples/s | 18.8 steps/s
Avg test loss: 0.11651, Avg test acc: 0.95865, Avg tpr: 0.97307, Avg fpr: 0.07307, total FA: 570

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11862 | acc=0.9573 | tpr=0.9717 | fpr=0.0738 | 5267.1 samples/s | 20.6 steps/s
Avg test loss: 0.12138, Avg test acc: 0.95645, Avg tpr: 0.97092, Avg fpr: 0.07537, total FA: 588

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.40891 | acc=0.2927 | tpr=0.0107 | fpr=0.0951 | 4750.9 samples/s | 18.6 steps/s
Avg test loss: 5.41469, Avg test acc: 0.29201, Avg tpr: 0.01189, Avg fpr: 0.09191, total FA: 717

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.90797 | acc=0.2931 | tpr=0.0086 | fpr=0.0889 | 4987.0 samples/s | 19.5 steps/s
Avg test loss: 4.92096, Avg test acc: 0.29009, Avg tpr: 0.00857, Avg fpr: 0.09076, total FA: 708

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.15652 | acc=0.2956 | tpr=0.0060 | fpr=0.0756 | 4837.3 samples/s | 18.9 steps/s
Avg test loss: 5.16334, Avg test acc: 0.29389, Avg tpr: 0.00734, Avg fpr: 0.07589, total FA: 592

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.88873 | acc=0.2913 | tpr=0.0186 | fpr=0.1167 | 5035.7 samples/s | 19.7 steps/s
Avg test loss: 5.87954, Avg test acc: 0.28977, Avg tpr: 0.01953, Avg fpr: 0.11588, total FA: 904

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.40433 | acc=0.3030 | tpr=0.0165 | fpr=0.0748 | 4778.9 samples/s | 18.7 steps/s
Avg test loss: 4.41536, Avg test acc: 0.30147, Avg tpr: 0.01830, Avg fpr: 0.07576, total FA: 591

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.37294 | acc=0.1034 | tpr=0.5796 | fpr=0.9051 | 5051.3 samples/s | 19.7 steps/s
[Step= 100] | Loss=5.34105 | acc=0.1047 | tpr=0.5672 | fpr=0.9039 | 7087.3 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.35367 | acc=0.1053 | tpr=0.5634 | fpr=0.9032 | 7258.9 samples/s | 28.4 steps/s
[Step= 200] | Loss=5.34957 | acc=0.1045 | tpr=0.5530 | fpr=0.9037 | 7537.5 samples/s | 29.4 steps/s
[Step= 250] | Loss=5.35360 | acc=0.1053 | tpr=0.5555 | fpr=0.9029 | 8130.0 samples/s | 31.8 steps/s
[Step= 300] | Loss=5.34938 | acc=0.1060 | tpr=0.5622 | fpr=0.9023 | 7625.5 samples/s | 29.8 steps/s
[Step= 350] | Loss=5.34462 | acc=0.1063 | tpr=0.5648 | fpr=0.9020 | 8030.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.34204 | acc=0.1064 | tpr=0.5646 | fpr=0.9020 | 7808.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.34524 | acc=0.1064 | tpr=0.5662 | fpr=0.9019 | 7738.6 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.34884 | acc=0.1063 | tpr=0.5595 | fpr=0.9018 | 7980.3 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.35169 | acc=0.1062 | tpr=0.5567 | fpr=0.9020 | 13740.1 samples/s | 53.7 steps/s
Avg test loss: 5.35371, Avg test acc: 0.10617, Avg tpr: 0.55745, Avg fpr: 0.90204, total FA: 125246

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.86412 | acc=0.0914 | tpr=0.5310 | fpr=0.9165 | 4856.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.84619 | acc=0.0931 | tpr=0.5394 | fpr=0.9152 | 6945.7 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.85003 | acc=0.0933 | tpr=0.5461 | fpr=0.9151 | 7978.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.84398 | acc=0.0930 | tpr=0.5333 | fpr=0.9150 | 7859.8 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.84885 | acc=0.0933 | tpr=0.5397 | fpr=0.9148 | 7582.2 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.84400 | acc=0.0931 | tpr=0.5411 | fpr=0.9150 | 7932.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.84026 | acc=0.0933 | tpr=0.5435 | fpr=0.9149 | 7894.2 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.83440 | acc=0.0936 | tpr=0.5432 | fpr=0.9146 | 7552.6 samples/s | 29.5 steps/s
[Step= 450] | Loss=5.83958 | acc=0.0934 | tpr=0.5414 | fpr=0.9147 | 8086.0 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.84379 | acc=0.0932 | tpr=0.5383 | fpr=0.9148 | 8177.7 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.84722 | acc=0.0930 | tpr=0.5344 | fpr=0.9150 | 13515.4 samples/s | 52.8 steps/s
Avg test loss: 5.84955, Avg test acc: 0.09293, Avg tpr: 0.53368, Avg fpr: 0.91508, total FA: 127057

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.09496 | acc=0.0809 | tpr=0.3230 | fpr=0.9234 | 4924.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=6.05807 | acc=0.0829 | tpr=0.3412 | fpr=0.9219 | 6881.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=6.07172 | acc=0.0841 | tpr=0.3487 | fpr=0.9208 | 7747.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.06873 | acc=0.0839 | tpr=0.3475 | fpr=0.9209 | 8148.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=6.07028 | acc=0.0845 | tpr=0.3485 | fpr=0.9203 | 7725.5 samples/s | 30.2 steps/s
[Step= 300] | Loss=6.06737 | acc=0.0847 | tpr=0.3593 | fpr=0.9203 | 7874.0 samples/s | 30.8 steps/s
[Step= 350] | Loss=6.06127 | acc=0.0850 | tpr=0.3613 | fpr=0.9200 | 7835.8 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.05514 | acc=0.0855 | tpr=0.3649 | fpr=0.9196 | 7813.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.05848 | acc=0.0855 | tpr=0.3632 | fpr=0.9195 | 7799.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.06060 | acc=0.0855 | tpr=0.3621 | fpr=0.9195 | 7810.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=6.06449 | acc=0.0854 | tpr=0.3649 | fpr=0.9196 | 14407.6 samples/s | 56.3 steps/s
Avg test loss: 6.06582, Avg test acc: 0.08534, Avg tpr: 0.36569, Avg fpr: 0.91975, total FA: 127706

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.78192 | acc=0.1180 | tpr=0.5575 | fpr=0.8899 | 4708.8 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.76638 | acc=0.1181 | tpr=0.5650 | fpr=0.8902 | 7268.9 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.77462 | acc=0.1172 | tpr=0.5749 | fpr=0.8912 | 7713.4 samples/s | 30.1 steps/s
[Step= 200] | Loss=5.76176 | acc=0.1165 | tpr=0.5661 | fpr=0.8917 | 8260.8 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.76507 | acc=0.1168 | tpr=0.5624 | fpr=0.8913 | 7919.8 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.76377 | acc=0.1165 | tpr=0.5629 | fpr=0.8916 | 7746.7 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.75638 | acc=0.1165 | tpr=0.5579 | fpr=0.8915 | 7665.7 samples/s | 29.9 steps/s
[Step= 400] | Loss=5.74926 | acc=0.1167 | tpr=0.5520 | fpr=0.8913 | 8076.8 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.75484 | acc=0.1167 | tpr=0.5526 | fpr=0.8913 | 7912.9 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.75645 | acc=0.1160 | tpr=0.5476 | fpr=0.8917 | 7764.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.76189 | acc=0.1159 | tpr=0.5432 | fpr=0.8919 | 14198.8 samples/s | 55.5 steps/s
Avg test loss: 5.76272, Avg test acc: 0.11582, Avg tpr: 0.54319, Avg fpr: 0.89195, total FA: 123846

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.62067 | acc=0.1141 | tpr=0.5398 | fpr=0.8936 | 4826.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.59641 | acc=0.1157 | tpr=0.5458 | fpr=0.8923 | 6692.2 samples/s | 26.1 steps/s
[Step= 150] | Loss=5.59468 | acc=0.1157 | tpr=0.5490 | fpr=0.8923 | 8279.4 samples/s | 32.3 steps/s
[Step= 200] | Loss=5.59362 | acc=0.1151 | tpr=0.5290 | fpr=0.8924 | 8262.1 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.60148 | acc=0.1157 | tpr=0.5345 | fpr=0.8919 | 7537.5 samples/s | 29.4 steps/s
[Step= 300] | Loss=5.60105 | acc=0.1153 | tpr=0.5440 | fpr=0.8925 | 7890.6 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.59347 | acc=0.1153 | tpr=0.5429 | fpr=0.8925 | 7783.6 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.58992 | acc=0.1158 | tpr=0.5438 | fpr=0.8920 | 7767.1 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.59348 | acc=0.1162 | tpr=0.5463 | fpr=0.8916 | 7719.8 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.59595 | acc=0.1160 | tpr=0.5432 | fpr=0.8917 | 8010.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.60055 | acc=0.1160 | tpr=0.5428 | fpr=0.8918 | 14324.7 samples/s | 56.0 steps/s
Avg test loss: 5.60269, Avg test acc: 0.11583, Avg tpr: 0.54200, Avg fpr: 0.89192, total FA: 123841

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09494 | acc=0.9819 | tpr=0.9646 | fpr=0.0178 | 4656.7 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.09770 | acc=0.9814 | tpr=0.9638 | fpr=0.0183 | 7389.8 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.10099 | acc=0.9808 | tpr=0.9597 | fpr=0.0188 | 7928.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10315 | acc=0.9806 | tpr=0.9628 | fpr=0.0190 | 7973.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.10167 | acc=0.9809 | tpr=0.9563 | fpr=0.0187 | 7449.7 samples/s | 29.1 steps/s
[Step= 300] | Loss=0.10427 | acc=0.9804 | tpr=0.9542 | fpr=0.0191 | 8025.5 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.10515 | acc=0.9802 | tpr=0.9549 | fpr=0.0194 | 8062.9 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.10619 | acc=0.9799 | tpr=0.9502 | fpr=0.0195 | 7520.7 samples/s | 29.4 steps/s
[Step= 450] | Loss=0.10825 | acc=0.9796 | tpr=0.9464 | fpr=0.0198 | 7988.6 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10739 | acc=0.9797 | tpr=0.9467 | fpr=0.0197 | 8046.7 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.10691 | acc=0.9798 | tpr=0.9447 | fpr=0.0196 | 13545.1 samples/s | 52.9 steps/s
Avg test loss: 0.10676, Avg test acc: 0.97983, Avg tpr: 0.94493, Avg fpr: 0.01954, total FA: 2713

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09144 | acc=0.9834 | tpr=0.9381 | fpr=0.0158 | 4739.5 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.09441 | acc=0.9829 | tpr=0.9318 | fpr=0.0161 | 7102.5 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.09729 | acc=0.9825 | tpr=0.9294 | fpr=0.0165 | 7955.4 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09908 | acc=0.9823 | tpr=0.9290 | fpr=0.0168 | 7978.3 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09723 | acc=0.9825 | tpr=0.9266 | fpr=0.0165 | 7575.8 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.09979 | acc=0.9820 | tpr=0.9244 | fpr=0.0170 | 7871.4 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10040 | acc=0.9819 | tpr=0.9286 | fpr=0.0172 | 7735.3 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.10182 | acc=0.9817 | tpr=0.9240 | fpr=0.0173 | 7968.7 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.10426 | acc=0.9814 | tpr=0.9226 | fpr=0.0176 | 7858.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10323 | acc=0.9814 | tpr=0.9251 | fpr=0.0175 | 7821.1 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.10305 | acc=0.9815 | tpr=0.9228 | fpr=0.0174 | 14472.1 samples/s | 56.5 steps/s
Avg test loss: 0.10292, Avg test acc: 0.98154, Avg tpr: 0.92274, Avg fpr: 0.01739, total FA: 2415

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08116 | acc=0.9823 | tpr=0.9602 | fpr=0.0173 | 4512.5 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.08283 | acc=0.9824 | tpr=0.9659 | fpr=0.0173 | 7731.8 samples/s | 30.2 steps/s
[Step= 150] | Loss=0.08680 | acc=0.9817 | tpr=0.9611 | fpr=0.0180 | 7938.1 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.08841 | acc=0.9819 | tpr=0.9661 | fpr=0.0178 | 7599.1 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.08687 | acc=0.9822 | tpr=0.9651 | fpr=0.0175 | 7911.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.08896 | acc=0.9818 | tpr=0.9585 | fpr=0.0178 | 7932.9 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.08979 | acc=0.9815 | tpr=0.9587 | fpr=0.0181 | 7760.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.09087 | acc=0.9812 | tpr=0.9551 | fpr=0.0183 | 8044.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.09245 | acc=0.9810 | tpr=0.9533 | fpr=0.0185 | 7867.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.09178 | acc=0.9810 | tpr=0.9555 | fpr=0.0185 | 7719.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.09143 | acc=0.9811 | tpr=0.9546 | fpr=0.0184 | 14408.6 samples/s | 56.3 steps/s
Avg test loss: 0.09132, Avg test acc: 0.98114, Avg tpr: 0.95483, Avg fpr: 0.01838, total FA: 2552

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09419 | acc=0.9817 | tpr=0.9381 | fpr=0.0175 | 4613.4 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.09832 | acc=0.9813 | tpr=0.9403 | fpr=0.0179 | 7417.9 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.10274 | acc=0.9803 | tpr=0.9409 | fpr=0.0190 | 7820.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.10413 | acc=0.9803 | tpr=0.9475 | fpr=0.0191 | 8223.0 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.10261 | acc=0.9808 | tpr=0.9502 | fpr=0.0187 | 7760.3 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.10497 | acc=0.9805 | tpr=0.9440 | fpr=0.0189 | 7812.4 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.10555 | acc=0.9803 | tpr=0.9449 | fpr=0.0191 | 7643.9 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.10610 | acc=0.9802 | tpr=0.9426 | fpr=0.0192 | 7860.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.10824 | acc=0.9799 | tpr=0.9391 | fpr=0.0193 | 8417.8 samples/s | 32.9 steps/s
[Step= 500] | Loss=0.10741 | acc=0.9800 | tpr=0.9405 | fpr=0.0193 | 7814.5 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.10702 | acc=0.9802 | tpr=0.9403 | fpr=0.0191 | 13208.3 samples/s | 51.6 steps/s
Avg test loss: 0.10685, Avg test acc: 0.98023, Avg tpr: 0.94017, Avg fpr: 0.01904, total FA: 2644

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09489 | acc=0.9813 | tpr=0.9159 | fpr=0.0175 | 4760.7 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.09844 | acc=0.9810 | tpr=0.9190 | fpr=0.0178 | 6814.5 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.10245 | acc=0.9803 | tpr=0.9222 | fpr=0.0187 | 7917.6 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.10390 | acc=0.9805 | tpr=0.9279 | fpr=0.0186 | 7646.8 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.10244 | acc=0.9808 | tpr=0.9266 | fpr=0.0182 | 8234.5 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.10511 | acc=0.9806 | tpr=0.9229 | fpr=0.0184 | 7766.2 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.10570 | acc=0.9805 | tpr=0.9242 | fpr=0.0185 | 7852.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10679 | acc=0.9803 | tpr=0.9207 | fpr=0.0187 | 8234.6 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.10931 | acc=0.9799 | tpr=0.9197 | fpr=0.0190 | 7123.5 samples/s | 27.8 steps/s
[Step= 500] | Loss=0.10845 | acc=0.9801 | tpr=0.9203 | fpr=0.0188 | 8511.6 samples/s | 33.2 steps/s
[Step= 550] | Loss=0.10847 | acc=0.9801 | tpr=0.9160 | fpr=0.0187 | 13127.3 samples/s | 51.3 steps/s
Avg test loss: 0.10827, Avg test acc: 0.98012, Avg tpr: 0.91601, Avg fpr: 0.01872, total FA: 2599

server round 29/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=282.8] | Loss=0.00756 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.024 | L2-Norm(final)=15.862 | 6027.4 samples/s | 94.2 steps/s
[Step=58050 Epoch=283.1] | Loss=0.00257 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=15.869 | 4110.0 samples/s | 64.2 steps/s
[Step=58100 Epoch=283.3] | Loss=0.00276 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.027 | L2-Norm(final)=15.880 | 5026.1 samples/s | 78.5 steps/s
[Step=58150 Epoch=283.6] | Loss=0.00289 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.028 | L2-Norm(final)=15.891 | 5056.8 samples/s | 79.0 steps/s
[Step=58200 Epoch=283.8] | Loss=0.00305 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=15.902 | 7745.2 samples/s | 121.0 steps/s
[Step=58250 Epoch=284.0] | Loss=0.00292 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.031 | L2-Norm(final)=15.912 | 2199.4 samples/s | 34.4 steps/s
[Step=58300 Epoch=284.3] | Loss=0.00279 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.031 | L2-Norm(final)=15.923 | 5000.2 samples/s | 78.1 steps/s
[Step=58350 Epoch=284.5] | Loss=0.00280 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.032 | L2-Norm(final)=15.934 | 4914.4 samples/s | 76.8 steps/s
[Step=58400 Epoch=284.8] | Loss=0.00284 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.032 | L2-Norm(final)=15.945 | 6909.3 samples/s | 108.0 steps/s
[Step=58450 Epoch=285.0] | Loss=0.00279 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.032 | L2-Norm(final)=15.956 | 2317.1 samples/s | 36.2 steps/s
[Step=58500 Epoch=285.3] | Loss=0.00280 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.033 | L2-Norm(final)=15.966 | 4963.2 samples/s | 77.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=285.3] | Loss=0.00146 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.036 | L2-Norm(final)=16.072 | 5469.9 samples/s | 85.5 steps/s
[Step=58550 Epoch=285.5] | Loss=0.00329 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.039 | L2-Norm(final)=16.082 | 4035.2 samples/s | 63.0 steps/s
[Step=58600 Epoch=285.7] | Loss=0.00407 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.045 | L2-Norm(final)=16.092 | 4359.8 samples/s | 68.1 steps/s
[Step=58650 Epoch=286.0] | Loss=0.00513 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.054 | L2-Norm(final)=16.102 | 4466.1 samples/s | 69.8 steps/s
[Step=58700 Epoch=286.2] | Loss=0.00527 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=16.115 | 6340.6 samples/s | 99.1 steps/s
[Step=58750 Epoch=286.5] | Loss=0.00575 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.077 | L2-Norm(final)=16.125 | 2092.8 samples/s | 32.7 steps/s
[Step=58800 Epoch=286.7] | Loss=0.00625 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.088 | L2-Norm(final)=16.134 | 4454.6 samples/s | 69.6 steps/s
[Step=58850 Epoch=287.0] | Loss=0.00675 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.100 | L2-Norm(final)=16.142 | 4506.3 samples/s | 70.4 steps/s
[Step=58900 Epoch=287.2] | Loss=0.00689 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=16.150 | 5881.0 samples/s | 91.9 steps/s
[Step=58950 Epoch=287.5] | Loss=0.00644 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=16.158 | 2184.7 samples/s | 34.1 steps/s
[Step=59000 Epoch=287.7] | Loss=0.00632 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.131 | L2-Norm(final)=16.166 | 4463.2 samples/s | 69.7 steps/s
[Step=59050 Epoch=287.9] | Loss=0.00629 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.138 | L2-Norm(final)=16.173 | 4339.1 samples/s | 67.8 steps/s
[Step=59100 Epoch=288.2] | Loss=0.00608 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=16.179 | 5386.3 samples/s | 84.2 steps/s
[Step=59150 Epoch=288.4] | Loss=0.00598 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=16.186 | 2266.9 samples/s | 35.4 steps/s
[Step=59200 Epoch=288.7] | Loss=0.00590 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.155 | L2-Norm(final)=16.192 | 4468.9 samples/s | 69.8 steps/s
[Step=59250 Epoch=288.9] | Loss=0.00568 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.159 | L2-Norm(final)=16.197 | 4484.6 samples/s | 70.1 steps/s
[Step=59300 Epoch=289.2] | Loss=0.00552 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.162 | L2-Norm(final)=16.203 | 4943.8 samples/s | 77.2 steps/s
[Step=59350 Epoch=289.4] | Loss=0.00534 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.165 | L2-Norm(final)=16.208 | 2343.8 samples/s | 36.6 steps/s
[Step=59400 Epoch=289.6] | Loss=0.00520 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=16.213 | 4440.6 samples/s | 69.4 steps/s
[Step=59450 Epoch=289.9] | Loss=0.00502 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=16.217 | 4472.5 samples/s | 69.9 steps/s
[Step=59500 Epoch=290.1] | Loss=0.00489 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=16.222 | 4599.3 samples/s | 71.9 steps/s
[Step=59550 Epoch=290.4] | Loss=0.00482 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.171 | L2-Norm(final)=16.226 | 2413.2 samples/s | 37.7 steps/s
[Step=59600 Epoch=290.6] | Loss=0.00471 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=16.230 | 4381.7 samples/s | 68.5 steps/s
[Step=59650 Epoch=290.9] | Loss=0.00460 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.171 | L2-Norm(final)=16.234 | 4410.7 samples/s | 68.9 steps/s
[Step=59700 Epoch=291.1] | Loss=0.00451 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=16.238 | 4488.6 samples/s | 70.1 steps/s
[Step=59750 Epoch=291.4] | Loss=0.00443 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=16.242 | 2418.4 samples/s | 37.8 steps/s
[Step=59800 Epoch=291.6] | Loss=0.00432 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=16.245 | 4310.3 samples/s | 67.3 steps/s
[Step=59850 Epoch=291.8] | Loss=0.00427 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=16.249 | 4275.3 samples/s | 66.8 steps/s
[Step=59900 Epoch=292.1] | Loss=0.00422 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.168 | L2-Norm(final)=16.252 | 4467.6 samples/s | 69.8 steps/s
[Step=59950 Epoch=292.3] | Loss=0.00418 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=16.255 | 2495.5 samples/s | 39.0 steps/s
[Step=60000 Epoch=292.6] | Loss=0.00413 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.165 | L2-Norm(final)=16.258 | 4427.4 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step60000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=283.0] | Loss=0.00240 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=16.327 | 5198.2 samples/s | 81.2 steps/s
[Step=58050 Epoch=283.3] | Loss=0.00349 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.672 | L2-Norm(final)=16.338 | 4511.5 samples/s | 70.5 steps/s
[Step=58100 Epoch=283.5] | Loss=0.00315 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.677 | L2-Norm(final)=16.351 | 5048.6 samples/s | 78.9 steps/s
[Step=58150 Epoch=283.7] | Loss=0.00264 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.680 | L2-Norm(final)=16.363 | 4978.7 samples/s | 77.8 steps/s
[Step=58200 Epoch=284.0] | Loss=0.00265 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=16.375 | 7932.0 samples/s | 123.9 steps/s
[Step=58250 Epoch=284.2] | Loss=0.00262 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.683 | L2-Norm(final)=16.388 | 2182.7 samples/s | 34.1 steps/s
[Step=58300 Epoch=284.5] | Loss=0.00257 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=16.400 | 4982.9 samples/s | 77.9 steps/s
[Step=58350 Epoch=284.7] | Loss=0.00246 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=16.412 | 4998.1 samples/s | 78.1 steps/s
[Step=58400 Epoch=285.0] | Loss=0.00239 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=16.424 | 7100.2 samples/s | 110.9 steps/s
[Step=58450 Epoch=285.2] | Loss=0.00239 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=16.436 | 2251.0 samples/s | 35.2 steps/s
[Step=58500 Epoch=285.5] | Loss=0.00237 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=16.447 | 4944.1 samples/s | 77.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=285.5] | Loss=0.00491 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.686 | L2-Norm(final)=16.563 | 4675.9 samples/s | 73.1 steps/s
[Step=58550 Epoch=285.7] | Loss=0.00382 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.690 | L2-Norm(final)=16.573 | 4508.4 samples/s | 70.4 steps/s
[Step=58600 Epoch=285.9] | Loss=0.00428 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.699 | L2-Norm(final)=16.585 | 4472.2 samples/s | 69.9 steps/s
[Step=58650 Epoch=286.2] | Loss=0.00579 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=16.597 | 4435.0 samples/s | 69.3 steps/s
[Step=58700 Epoch=286.4] | Loss=0.00632 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.738 | L2-Norm(final)=16.610 | 6584.2 samples/s | 102.9 steps/s
[Step=58750 Epoch=286.7] | Loss=0.00672 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=16.622 | 2098.3 samples/s | 32.8 steps/s
[Step=58800 Epoch=286.9] | Loss=0.00670 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=16.633 | 4486.1 samples/s | 70.1 steps/s
[Step=58850 Epoch=287.2] | Loss=0.00674 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.790 | L2-Norm(final)=16.644 | 4535.4 samples/s | 70.9 steps/s
[Step=58900 Epoch=287.4] | Loss=0.00675 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.803 | L2-Norm(final)=16.653 | 5815.7 samples/s | 90.9 steps/s
[Step=58950 Epoch=287.6] | Loss=0.00672 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.815 | L2-Norm(final)=16.662 | 2152.1 samples/s | 33.6 steps/s
[Step=59000 Epoch=287.9] | Loss=0.00642 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=16.670 | 4499.5 samples/s | 70.3 steps/s
[Step=59050 Epoch=288.1] | Loss=0.00614 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.834 | L2-Norm(final)=16.678 | 4446.1 samples/s | 69.5 steps/s
[Step=59100 Epoch=288.4] | Loss=0.00595 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.841 | L2-Norm(final)=16.685 | 5475.9 samples/s | 85.6 steps/s
[Step=59150 Epoch=288.6] | Loss=0.00578 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.847 | L2-Norm(final)=16.692 | 2203.8 samples/s | 34.4 steps/s
[Step=59200 Epoch=288.9] | Loss=0.00564 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.852 | L2-Norm(final)=16.698 | 4389.2 samples/s | 68.6 steps/s
[Step=59250 Epoch=289.1] | Loss=0.00538 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.856 | L2-Norm(final)=16.704 | 4544.7 samples/s | 71.0 steps/s
[Step=59300 Epoch=289.4] | Loss=0.00524 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.859 | L2-Norm(final)=16.709 | 5078.0 samples/s | 79.3 steps/s
[Step=59350 Epoch=289.6] | Loss=0.00509 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.862 | L2-Norm(final)=16.714 | 2271.9 samples/s | 35.5 steps/s
[Step=59400 Epoch=289.8] | Loss=0.00493 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.864 | L2-Norm(final)=16.719 | 4443.2 samples/s | 69.4 steps/s
[Step=59450 Epoch=290.1] | Loss=0.00483 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.865 | L2-Norm(final)=16.724 | 4577.4 samples/s | 71.5 steps/s
[Step=59500 Epoch=290.3] | Loss=0.00468 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.866 | L2-Norm(final)=16.728 | 4745.0 samples/s | 74.1 steps/s
[Step=59550 Epoch=290.6] | Loss=0.00458 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=16.733 | 2380.2 samples/s | 37.2 steps/s
[Step=59600 Epoch=290.8] | Loss=0.00446 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.868 | L2-Norm(final)=16.737 | 4369.3 samples/s | 68.3 steps/s
[Step=59650 Epoch=291.1] | Loss=0.00436 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.868 | L2-Norm(final)=16.741 | 4440.7 samples/s | 69.4 steps/s
[Step=59700 Epoch=291.3] | Loss=0.00428 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.868 | L2-Norm(final)=16.744 | 4574.9 samples/s | 71.5 steps/s
[Step=59750 Epoch=291.6] | Loss=0.00414 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=16.748 | 2421.4 samples/s | 37.8 steps/s
[Step=59800 Epoch=291.8] | Loss=0.00404 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.866 | L2-Norm(final)=16.752 | 4400.7 samples/s | 68.8 steps/s
[Step=59850 Epoch=292.0] | Loss=0.00397 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.865 | L2-Norm(final)=16.755 | 4440.6 samples/s | 69.4 steps/s
[Step=59900 Epoch=292.3] | Loss=0.00394 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.864 | L2-Norm(final)=16.758 | 4475.8 samples/s | 69.9 steps/s
[Step=59950 Epoch=292.5] | Loss=0.00388 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=16.762 | 2487.8 samples/s | 38.9 steps/s
[Step=60000 Epoch=292.8] | Loss=0.00380 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.862 | L2-Norm(final)=16.765 | 4386.8 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step60000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=282.6] | Loss=0.00358 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.350 | L2-Norm(final)=16.581 | 5896.8 samples/s | 92.1 steps/s
[Step=58050 Epoch=282.8] | Loss=0.00570 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=16.587 | 4450.8 samples/s | 69.5 steps/s
[Step=58100 Epoch=283.1] | Loss=0.00524 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=16.601 | 4924.0 samples/s | 76.9 steps/s
[Step=58150 Epoch=283.3] | Loss=0.00469 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.365 | L2-Norm(final)=16.614 | 5041.9 samples/s | 78.8 steps/s
[Step=58200 Epoch=283.6] | Loss=0.00451 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.369 | L2-Norm(final)=16.627 | 7842.3 samples/s | 122.5 steps/s
[Step=58250 Epoch=283.8] | Loss=0.00448 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.374 | L2-Norm(final)=16.641 | 2234.9 samples/s | 34.9 steps/s
[Step=58300 Epoch=284.1] | Loss=0.00429 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=16.655 | 5120.3 samples/s | 80.0 steps/s
[Step=58350 Epoch=284.3] | Loss=0.00411 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.381 | L2-Norm(final)=16.669 | 4955.3 samples/s | 77.4 steps/s
[Step=58400 Epoch=284.6] | Loss=0.00409 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=16.682 | 6781.2 samples/s | 106.0 steps/s
[Step=58450 Epoch=284.8] | Loss=0.00394 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.389 | L2-Norm(final)=16.695 | 2301.9 samples/s | 36.0 steps/s
[Step=58500 Epoch=285.0] | Loss=0.00384 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.392 | L2-Norm(final)=16.708 | 4994.0 samples/s | 78.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=285.0] | Loss=0.00236 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.420 | L2-Norm(final)=16.836 | 5760.5 samples/s | 90.0 steps/s
[Step=58550 Epoch=285.3] | Loss=0.00393 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.423 | L2-Norm(final)=16.848 | 3810.0 samples/s | 59.5 steps/s
[Step=58600 Epoch=285.5] | Loss=0.00470 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.432 | L2-Norm(final)=16.859 | 4456.1 samples/s | 69.6 steps/s
[Step=58650 Epoch=285.8] | Loss=0.00594 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.443 | L2-Norm(final)=16.867 | 4481.6 samples/s | 70.0 steps/s
[Step=58700 Epoch=286.0] | Loss=0.00641 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.454 | L2-Norm(final)=16.876 | 6483.1 samples/s | 101.3 steps/s
[Step=58750 Epoch=286.3] | Loss=0.00664 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.466 | L2-Norm(final)=16.885 | 2089.1 samples/s | 32.6 steps/s
[Step=58800 Epoch=286.5] | Loss=0.00784 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.480 | L2-Norm(final)=16.894 | 4453.8 samples/s | 69.6 steps/s
[Step=58850 Epoch=286.7] | Loss=0.00810 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.495 | L2-Norm(final)=16.902 | 4481.3 samples/s | 70.0 steps/s
[Step=58900 Epoch=287.0] | Loss=0.00788 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.509 | L2-Norm(final)=16.910 | 5859.6 samples/s | 91.6 steps/s
[Step=58950 Epoch=287.2] | Loss=0.00763 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=16.918 | 2176.5 samples/s | 34.0 steps/s
[Step=59000 Epoch=287.5] | Loss=0.00736 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=16.925 | 4466.7 samples/s | 69.8 steps/s
[Step=59050 Epoch=287.7] | Loss=0.00726 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.541 | L2-Norm(final)=16.931 | 4455.6 samples/s | 69.6 steps/s
[Step=59100 Epoch=288.0] | Loss=0.00705 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.548 | L2-Norm(final)=16.937 | 5385.0 samples/s | 84.1 steps/s
[Step=59150 Epoch=288.2] | Loss=0.00675 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.554 | L2-Norm(final)=16.943 | 2284.7 samples/s | 35.7 steps/s
[Step=59200 Epoch=288.5] | Loss=0.00653 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.559 | L2-Norm(final)=16.948 | 4328.3 samples/s | 67.6 steps/s
[Step=59250 Epoch=288.7] | Loss=0.00634 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.564 | L2-Norm(final)=16.953 | 4460.8 samples/s | 69.7 steps/s
[Step=59300 Epoch=288.9] | Loss=0.00610 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=16.958 | 4929.2 samples/s | 77.0 steps/s
[Step=59350 Epoch=289.2] | Loss=0.00588 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.570 | L2-Norm(final)=16.963 | 2312.9 samples/s | 36.1 steps/s
[Step=59400 Epoch=289.4] | Loss=0.00571 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.573 | L2-Norm(final)=16.967 | 4483.6 samples/s | 70.1 steps/s
[Step=59450 Epoch=289.7] | Loss=0.00558 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=16.971 | 4481.4 samples/s | 70.0 steps/s
[Step=59500 Epoch=289.9] | Loss=0.00541 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=16.975 | 4514.6 samples/s | 70.5 steps/s
[Step=59550 Epoch=290.2] | Loss=0.00529 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.577 | L2-Norm(final)=16.979 | 2401.3 samples/s | 37.5 steps/s
[Step=59600 Epoch=290.4] | Loss=0.00511 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=16.983 | 4471.4 samples/s | 69.9 steps/s
[Step=59650 Epoch=290.6] | Loss=0.00497 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=16.986 | 4625.7 samples/s | 72.3 steps/s
[Step=59700 Epoch=290.9] | Loss=0.00490 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=16.990 | 4348.7 samples/s | 67.9 steps/s
[Step=59750 Epoch=291.1] | Loss=0.00480 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=16.993 | 2445.5 samples/s | 38.2 steps/s
[Step=59800 Epoch=291.4] | Loss=0.00471 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=16.996 | 4481.7 samples/s | 70.0 steps/s
[Step=59850 Epoch=291.6] | Loss=0.00462 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.577 | L2-Norm(final)=16.999 | 4483.2 samples/s | 70.1 steps/s
[Step=59900 Epoch=291.9] | Loss=0.00455 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=17.002 | 4451.1 samples/s | 69.5 steps/s
[Step=59950 Epoch=292.1] | Loss=0.00447 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=17.005 | 2510.5 samples/s | 39.2 steps/s
[Step=60000 Epoch=292.3] | Loss=0.00438 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.574 | L2-Norm(final)=17.008 | 4334.3 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step60000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=282.8] | Loss=0.00477 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=16.531 | 5261.4 samples/s | 82.2 steps/s
[Step=58050 Epoch=283.1] | Loss=0.00235 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=16.540 | 4481.1 samples/s | 70.0 steps/s
[Step=58100 Epoch=283.3] | Loss=0.00251 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.064 | L2-Norm(final)=16.553 | 5034.6 samples/s | 78.7 steps/s
[Step=58150 Epoch=283.6] | Loss=0.00230 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=16.565 | 5021.4 samples/s | 78.5 steps/s
[Step=58200 Epoch=283.8] | Loss=0.00249 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=16.577 | 7932.6 samples/s | 123.9 steps/s
[Step=58250 Epoch=284.1] | Loss=0.00246 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.068 | L2-Norm(final)=16.589 | 2212.9 samples/s | 34.6 steps/s
[Step=58300 Epoch=284.3] | Loss=0.00234 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=16.601 | 5009.1 samples/s | 78.3 steps/s
[Step=58350 Epoch=284.5] | Loss=0.00230 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=16.613 | 5119.2 samples/s | 80.0 steps/s
[Step=58400 Epoch=284.8] | Loss=0.00237 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=16.625 | 6889.9 samples/s | 107.7 steps/s
[Step=58450 Epoch=285.0] | Loss=0.00231 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.636 | 2297.7 samples/s | 35.9 steps/s
[Step=58500 Epoch=285.3] | Loss=0.00233 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=16.648 | 5130.1 samples/s | 80.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=285.3] | Loss=0.00229 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=16.767 | 5754.6 samples/s | 89.9 steps/s
[Step=58550 Epoch=285.5] | Loss=0.00220 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.078 | L2-Norm(final)=16.777 | 3959.9 samples/s | 61.9 steps/s
[Step=58600 Epoch=285.8] | Loss=0.00341 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=16.789 | 4441.7 samples/s | 69.4 steps/s
[Step=58650 Epoch=286.0] | Loss=0.00470 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.095 | L2-Norm(final)=16.798 | 4484.4 samples/s | 70.1 steps/s
[Step=58700 Epoch=286.3] | Loss=0.00742 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.111 | L2-Norm(final)=16.807 | 6580.6 samples/s | 102.8 steps/s
[Step=58750 Epoch=286.5] | Loss=0.00799 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.132 | L2-Norm(final)=16.816 | 1615.3 samples/s | 25.2 steps/s
[Step=58800 Epoch=286.7] | Loss=0.00806 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.150 | L2-Norm(final)=16.825 | 4431.8 samples/s | 69.2 steps/s
[Step=58850 Epoch=287.0] | Loss=0.00793 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.165 | L2-Norm(final)=16.834 | 4277.2 samples/s | 66.8 steps/s
[Step=58900 Epoch=287.2] | Loss=0.00764 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.178 | L2-Norm(final)=16.843 | 5893.0 samples/s | 92.1 steps/s
[Step=58950 Epoch=287.5] | Loss=0.00729 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.190 | L2-Norm(final)=16.851 | 2117.9 samples/s | 33.1 steps/s
[Step=59000 Epoch=287.7] | Loss=0.00706 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.200 | L2-Norm(final)=16.859 | 4524.1 samples/s | 70.7 steps/s
[Step=59050 Epoch=288.0] | Loss=0.00674 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.209 | L2-Norm(final)=16.866 | 4430.0 samples/s | 69.2 steps/s
[Step=59100 Epoch=288.2] | Loss=0.00661 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.216 | L2-Norm(final)=16.873 | 5446.7 samples/s | 85.1 steps/s
[Step=59150 Epoch=288.4] | Loss=0.00634 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.222 | L2-Norm(final)=16.879 | 2234.5 samples/s | 34.9 steps/s
[Step=59200 Epoch=288.7] | Loss=0.00601 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.227 | L2-Norm(final)=16.885 | 4488.3 samples/s | 70.1 steps/s
[Step=59250 Epoch=288.9] | Loss=0.00582 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.232 | L2-Norm(final)=16.890 | 4503.9 samples/s | 70.4 steps/s
[Step=59300 Epoch=289.2] | Loss=0.00564 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.236 | L2-Norm(final)=16.896 | 4956.4 samples/s | 77.4 steps/s
[Step=59350 Epoch=289.4] | Loss=0.00538 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.238 | L2-Norm(final)=16.901 | 2358.8 samples/s | 36.9 steps/s
[Step=59400 Epoch=289.7] | Loss=0.00517 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.241 | L2-Norm(final)=16.906 | 4531.0 samples/s | 70.8 steps/s
[Step=59450 Epoch=289.9] | Loss=0.00501 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.243 | L2-Norm(final)=16.910 | 4474.8 samples/s | 69.9 steps/s
[Step=59500 Epoch=290.2] | Loss=0.00495 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.244 | L2-Norm(final)=16.915 | 4580.0 samples/s | 71.6 steps/s
[Step=59550 Epoch=290.4] | Loss=0.00478 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=16.919 | 2462.7 samples/s | 38.5 steps/s
[Step=59600 Epoch=290.6] | Loss=0.00463 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.246 | L2-Norm(final)=16.923 | 4460.2 samples/s | 69.7 steps/s
[Step=59650 Epoch=290.9] | Loss=0.00451 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=16.927 | 4511.0 samples/s | 70.5 steps/s
[Step=59700 Epoch=291.1] | Loss=0.00440 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=16.931 | 4452.6 samples/s | 69.6 steps/s
[Step=59750 Epoch=291.4] | Loss=0.00431 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=16.935 | 2489.4 samples/s | 38.9 steps/s
[Step=59800 Epoch=291.6] | Loss=0.00418 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=16.939 | 4323.6 samples/s | 67.6 steps/s
[Step=59850 Epoch=291.9] | Loss=0.00407 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=16.942 | 4451.9 samples/s | 69.6 steps/s
[Step=59900 Epoch=292.1] | Loss=0.00404 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.246 | L2-Norm(final)=16.946 | 4503.8 samples/s | 70.4 steps/s
[Step=59950 Epoch=292.3] | Loss=0.00397 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=16.949 | 2441.4 samples/s | 38.1 steps/s
[Step=60000 Epoch=292.6] | Loss=0.00391 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.244 | L2-Norm(final)=16.952 | 4460.6 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step60000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=284.4] | Loss=0.01068 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.890 | L2-Norm(final)=16.636 | 5912.6 samples/s | 92.4 steps/s
[Step=58050 Epoch=284.7] | Loss=0.00374 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=16.643 | 4123.7 samples/s | 64.4 steps/s
[Step=58100 Epoch=284.9] | Loss=0.00363 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=16.651 | 4959.8 samples/s | 77.5 steps/s
[Step=58150 Epoch=285.2] | Loss=0.00311 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.895 | L2-Norm(final)=16.658 | 5133.2 samples/s | 80.2 steps/s
[Step=58200 Epoch=285.4] | Loss=0.00325 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.896 | L2-Norm(final)=16.666 | 7961.7 samples/s | 124.4 steps/s
[Step=58250 Epoch=285.6] | Loss=0.00308 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.897 | L2-Norm(final)=16.675 | 2224.5 samples/s | 34.8 steps/s
[Step=58300 Epoch=285.9] | Loss=0.00281 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.897 | L2-Norm(final)=16.684 | 4951.6 samples/s | 77.4 steps/s
[Step=58350 Epoch=286.1] | Loss=0.00279 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.897 | L2-Norm(final)=16.694 | 5063.3 samples/s | 79.1 steps/s
[Step=58400 Epoch=286.4] | Loss=0.00292 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.897 | L2-Norm(final)=16.703 | 7272.3 samples/s | 113.6 steps/s
[Step=58450 Epoch=286.6] | Loss=0.00284 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=16.711 | 2263.9 samples/s | 35.4 steps/s
[Step=58500 Epoch=286.9] | Loss=0.00274 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=16.720 | 4997.8 samples/s | 78.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=286.9] | Loss=0.00231 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.900 | L2-Norm(final)=16.811 | 5268.7 samples/s | 82.3 steps/s
[Step=58550 Epoch=287.1] | Loss=0.00255 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=16.820 | 4091.1 samples/s | 63.9 steps/s
[Step=58600 Epoch=287.4] | Loss=0.00277 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=16.829 | 4551.8 samples/s | 71.1 steps/s
[Step=58650 Epoch=287.6] | Loss=0.00367 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.911 | L2-Norm(final)=16.836 | 4354.3 samples/s | 68.0 steps/s
[Step=58700 Epoch=287.9] | Loss=0.00423 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.918 | L2-Norm(final)=16.844 | 6740.2 samples/s | 105.3 steps/s
[Step=58750 Epoch=288.1] | Loss=0.00392 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.926 | L2-Norm(final)=16.853 | 2078.4 samples/s | 32.5 steps/s
[Step=58800 Epoch=288.3] | Loss=0.00403 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.932 | L2-Norm(final)=16.861 | 4533.6 samples/s | 70.8 steps/s
[Step=58850 Epoch=288.6] | Loss=0.00485 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.938 | L2-Norm(final)=16.869 | 4434.3 samples/s | 69.3 steps/s
[Step=58900 Epoch=288.8] | Loss=0.00516 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=16.876 | 5980.4 samples/s | 93.4 steps/s
[Step=58950 Epoch=289.1] | Loss=0.00504 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.953 | L2-Norm(final)=16.883 | 2088.6 samples/s | 32.6 steps/s
[Step=59000 Epoch=289.3] | Loss=0.00483 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=16.890 | 4429.8 samples/s | 69.2 steps/s
[Step=59050 Epoch=289.6] | Loss=0.00466 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=16.897 | 4241.5 samples/s | 66.3 steps/s
[Step=59100 Epoch=289.8] | Loss=0.00452 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=16.903 | 5696.6 samples/s | 89.0 steps/s
[Step=59150 Epoch=290.1] | Loss=0.00438 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=16.910 | 2098.5 samples/s | 32.8 steps/s
[Step=59200 Epoch=290.3] | Loss=0.00429 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.976 | L2-Norm(final)=16.916 | 4500.0 samples/s | 70.3 steps/s
[Step=59250 Epoch=290.6] | Loss=0.00419 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.979 | L2-Norm(final)=16.922 | 4485.7 samples/s | 70.1 steps/s
[Step=59300 Epoch=290.8] | Loss=0.00408 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.981 | L2-Norm(final)=16.927 | 5418.5 samples/s | 84.7 steps/s
[Step=59350 Epoch=291.0] | Loss=0.00398 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.983 | L2-Norm(final)=16.932 | 2210.0 samples/s | 34.5 steps/s
[Step=59400 Epoch=291.3] | Loss=0.00392 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=16.937 | 4465.9 samples/s | 69.8 steps/s
[Step=59450 Epoch=291.5] | Loss=0.00379 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=16.942 | 4526.9 samples/s | 70.7 steps/s
[Step=59500 Epoch=291.8] | Loss=0.00376 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.985 | L2-Norm(final)=16.947 | 5104.4 samples/s | 79.8 steps/s
[Step=59550 Epoch=292.0] | Loss=0.00376 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=16.951 | 2276.3 samples/s | 35.6 steps/s
[Step=59600 Epoch=292.3] | Loss=0.00376 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=16.955 | 4566.7 samples/s | 71.4 steps/s
[Step=59650 Epoch=292.5] | Loss=0.00369 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=16.959 | 4371.7 samples/s | 68.3 steps/s
[Step=59700 Epoch=292.8] | Loss=0.00364 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=16.963 | 4913.9 samples/s | 76.8 steps/s
[Step=59750 Epoch=293.0] | Loss=0.00357 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.985 | L2-Norm(final)=16.967 | 2355.1 samples/s | 36.8 steps/s
[Step=59800 Epoch=293.2] | Loss=0.00366 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=16.971 | 4404.9 samples/s | 68.8 steps/s
[Step=59850 Epoch=293.5] | Loss=0.00359 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.983 | L2-Norm(final)=16.974 | 4496.3 samples/s | 70.3 steps/s
[Step=59900 Epoch=293.7] | Loss=0.00352 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=16.978 | 4656.6 samples/s | 72.8 steps/s
[Step=59950 Epoch=294.0] | Loss=0.00345 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.981 | L2-Norm(final)=16.981 | 2385.8 samples/s | 37.3 steps/s
[Step=60000 Epoch=294.2] | Loss=0.00341 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.979 | L2-Norm(final)=16.985 | 4502.2 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step60000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=549.6] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=8.307 | 5445.0 samples/s | 85.1 steps/s
[Step=58050 Epoch=550.1] | Loss=0.00011 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.538 | L2-Norm(final)=8.325 | 4330.1 samples/s | 67.7 steps/s
[Step=58100 Epoch=550.5] | Loss=0.00009 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.551 | L2-Norm(final)=8.347 | 7356.0 samples/s | 114.9 steps/s
[Step=58150 Epoch=551.0] | Loss=0.00007 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.560 | L2-Norm(final)=8.365 | 2163.8 samples/s | 33.8 steps/s
[Step=58200 Epoch=551.5] | Loss=0.00006 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.566 | L2-Norm(final)=8.379 | 6395.6 samples/s | 99.9 steps/s
[Step=58250 Epoch=552.0] | Loss=0.00006 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.570 | L2-Norm(final)=8.391 | 2240.9 samples/s | 35.0 steps/s
[Step=58300 Epoch=552.4] | Loss=0.00005 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.574 | L2-Norm(final)=8.402 | 5782.9 samples/s | 90.4 steps/s
[Step=58350 Epoch=552.9] | Loss=0.00005 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.576 | L2-Norm(final)=8.412 | 2295.6 samples/s | 35.9 steps/s
[Step=58400 Epoch=553.4] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.579 | L2-Norm(final)=8.422 | 5364.3 samples/s | 83.8 steps/s
[Step=58450 Epoch=553.9] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.581 | L2-Norm(final)=8.431 | 2446.3 samples/s | 38.2 steps/s
[Step=58500 Epoch=554.3] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.582 | L2-Norm(final)=8.440 | 4733.7 samples/s | 74.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=554.3] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.597 | L2-Norm(final)=8.527 | 5228.0 samples/s | 81.7 steps/s
[Step=58550 Epoch=554.8] | Loss=0.00002 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.583 | L2-Norm(final)=8.535 | 3814.2 samples/s | 59.6 steps/s
[Step=58600 Epoch=555.3] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.558 | L2-Norm(final)=8.539 | 6109.5 samples/s | 95.5 steps/s
[Step=58650 Epoch=555.8] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=8.543 | 2017.9 samples/s | 31.5 steps/s
[Step=58700 Epoch=556.2] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.507 | L2-Norm(final)=8.546 | 5660.6 samples/s | 88.4 steps/s
[Step=58750 Epoch=556.7] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.479 | L2-Norm(final)=8.548 | 2084.1 samples/s | 32.6 steps/s
[Step=58800 Epoch=557.2] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.450 | L2-Norm(final)=8.549 | 5124.9 samples/s | 80.1 steps/s
[Step=58850 Epoch=557.7] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.421 | L2-Norm(final)=8.550 | 2159.2 samples/s | 33.7 steps/s
[Step=58900 Epoch=558.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.391 | L2-Norm(final)=8.552 | 4702.0 samples/s | 73.5 steps/s
[Step=58950 Epoch=558.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.362 | L2-Norm(final)=8.553 | 2248.9 samples/s | 35.1 steps/s
[Step=59000 Epoch=559.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.331 | L2-Norm(final)=8.554 | 4355.2 samples/s | 68.0 steps/s
[Step=59050 Epoch=559.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.301 | L2-Norm(final)=8.555 | 2360.5 samples/s | 36.9 steps/s
[Step=59100 Epoch=560.0] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.271 | L2-Norm(final)=8.556 | 4149.7 samples/s | 64.8 steps/s
[Step=59150 Epoch=560.5] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.241 | L2-Norm(final)=8.557 | 2416.0 samples/s | 37.8 steps/s
[Step=59200 Epoch=561.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.210 | L2-Norm(final)=8.558 | 4243.1 samples/s | 66.3 steps/s
[Step=59250 Epoch=561.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.180 | L2-Norm(final)=8.559 | 2422.4 samples/s | 37.8 steps/s
[Step=59300 Epoch=561.9] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.150 | L2-Norm(final)=8.560 | 4149.8 samples/s | 64.8 steps/s
[Step=59350 Epoch=562.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.119 | L2-Norm(final)=8.561 | 2491.5 samples/s | 38.9 steps/s
[Step=59400 Epoch=562.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.089 | L2-Norm(final)=8.562 | 3867.5 samples/s | 60.4 steps/s
[Step=59450 Epoch=563.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.058 | L2-Norm(final)=8.564 | 6521.2 samples/s | 101.9 steps/s
[Step=59500 Epoch=563.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=8.565 | 1981.1 samples/s | 31.0 steps/s
[Step=59550 Epoch=564.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.997 | L2-Norm(final)=8.566 | 5809.0 samples/s | 90.8 steps/s
[Step=59600 Epoch=564.8] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.966 | L2-Norm(final)=8.568 | 2082.7 samples/s | 32.5 steps/s
[Step=59650 Epoch=565.2] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=8.569 | 5274.4 samples/s | 82.4 steps/s
[Step=59700 Epoch=565.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.904 | L2-Norm(final)=8.570 | 2139.8 samples/s | 33.4 steps/s
[Step=59750 Epoch=566.2] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.873 | L2-Norm(final)=8.572 | 4768.1 samples/s | 74.5 steps/s
[Step=59800 Epoch=566.7] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.842 | L2-Norm(final)=8.573 | 2261.7 samples/s | 35.3 steps/s
[Step=59850 Epoch=567.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.812 | L2-Norm(final)=8.575 | 4329.5 samples/s | 67.6 steps/s
[Step=59900 Epoch=567.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.781 | L2-Norm(final)=8.577 | 2310.0 samples/s | 36.1 steps/s
[Step=59950 Epoch=568.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.750 | L2-Norm(final)=8.578 | 4253.8 samples/s | 66.5 steps/s
[Step=60000 Epoch=568.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=8.580 | 2376.3 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step60000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=551.7] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.538 | L2-Norm(final)=9.433 | 5241.9 samples/s | 81.9 steps/s
[Step=58050 Epoch=552.2] | Loss=0.00006 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.541 | L2-Norm(final)=9.437 | 4094.9 samples/s | 64.0 steps/s
[Step=58100 Epoch=552.7] | Loss=0.00005 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.543 | L2-Norm(final)=9.441 | 7459.5 samples/s | 116.6 steps/s
[Step=58150 Epoch=553.2] | Loss=0.00005 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.545 | L2-Norm(final)=9.446 | 2138.3 samples/s | 33.4 steps/s
[Step=58200 Epoch=553.6] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.547 | L2-Norm(final)=9.450 | 6582.2 samples/s | 102.8 steps/s
[Step=58250 Epoch=554.1] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.549 | L2-Norm(final)=9.454 | 2187.4 samples/s | 34.2 steps/s
[Step=58300 Epoch=554.6] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.550 | L2-Norm(final)=9.458 | 5567.6 samples/s | 87.0 steps/s
[Step=58350 Epoch=555.1] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.552 | L2-Norm(final)=9.462 | 2240.6 samples/s | 35.0 steps/s
[Step=58400 Epoch=555.5] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.553 | L2-Norm(final)=9.466 | 5349.2 samples/s | 83.6 steps/s
[Step=58450 Epoch=556.0] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.554 | L2-Norm(final)=9.470 | 2384.2 samples/s | 37.3 steps/s
[Step=58500 Epoch=556.5] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.555 | L2-Norm(final)=9.473 | 4793.8 samples/s | 74.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=556.5] | Loss=0.00004 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.566 | L2-Norm(final)=9.512 | 5138.0 samples/s | 80.3 steps/s
[Step=58550 Epoch=557.0] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.565 | L2-Norm(final)=9.516 | 3828.1 samples/s | 59.8 steps/s
[Step=58600 Epoch=557.4] | Loss=0.00002 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.563 | L2-Norm(final)=9.519 | 6266.3 samples/s | 97.9 steps/s
[Step=58650 Epoch=557.9] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.560 | L2-Norm(final)=9.521 | 1981.0 samples/s | 31.0 steps/s
[Step=58700 Epoch=558.4] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.556 | L2-Norm(final)=9.522 | 5652.2 samples/s | 88.3 steps/s
[Step=58750 Epoch=558.9] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.552 | L2-Norm(final)=9.524 | 2080.6 samples/s | 32.5 steps/s
[Step=58800 Epoch=559.3] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.548 | L2-Norm(final)=9.525 | 5127.1 samples/s | 80.1 steps/s
[Step=58850 Epoch=559.8] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.544 | L2-Norm(final)=9.526 | 2152.5 samples/s | 33.6 steps/s
[Step=58900 Epoch=560.3] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.540 | L2-Norm(final)=9.527 | 4701.2 samples/s | 73.5 steps/s
[Step=58950 Epoch=560.8] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.535 | L2-Norm(final)=9.528 | 2204.2 samples/s | 34.4 steps/s
[Step=59000 Epoch=561.2] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=9.529 | 4357.0 samples/s | 68.1 steps/s
[Step=59050 Epoch=561.7] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.526 | L2-Norm(final)=9.530 | 2322.1 samples/s | 36.3 steps/s
[Step=59100 Epoch=562.2] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.521 | L2-Norm(final)=9.531 | 4233.9 samples/s | 66.2 steps/s
[Step=59150 Epoch=562.7] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.516 | L2-Norm(final)=9.532 | 2348.7 samples/s | 36.7 steps/s
[Step=59200 Epoch=563.1] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.512 | L2-Norm(final)=9.533 | 4152.8 samples/s | 64.9 steps/s
[Step=59250 Epoch=563.6] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.507 | L2-Norm(final)=9.534 | 2376.1 samples/s | 37.1 steps/s
[Step=59300 Epoch=564.1] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.502 | L2-Norm(final)=9.535 | 4132.9 samples/s | 64.6 steps/s
[Step=59350 Epoch=564.6] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=9.536 | 2531.5 samples/s | 39.6 steps/s
[Step=59400 Epoch=565.0] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.491 | L2-Norm(final)=9.537 | 3859.1 samples/s | 60.3 steps/s
[Step=59450 Epoch=565.5] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.486 | L2-Norm(final)=9.538 | 6380.9 samples/s | 99.7 steps/s
[Step=59500 Epoch=566.0] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.481 | L2-Norm(final)=9.538 | 1968.3 samples/s | 30.8 steps/s
[Step=59550 Epoch=566.5] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.476 | L2-Norm(final)=9.539 | 5832.3 samples/s | 91.1 steps/s
[Step=59600 Epoch=566.9] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.470 | L2-Norm(final)=9.540 | 2034.6 samples/s | 31.8 steps/s
[Step=59650 Epoch=567.4] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.465 | L2-Norm(final)=9.541 | 5291.6 samples/s | 82.7 steps/s
[Step=59700 Epoch=567.9] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.459 | L2-Norm(final)=9.542 | 2123.7 samples/s | 33.2 steps/s
[Step=59750 Epoch=568.4] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.454 | L2-Norm(final)=9.543 | 4830.8 samples/s | 75.5 steps/s
[Step=59800 Epoch=568.8] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.448 | L2-Norm(final)=9.543 | 2196.6 samples/s | 34.3 steps/s
[Step=59850 Epoch=569.3] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.442 | L2-Norm(final)=9.544 | 4424.5 samples/s | 69.1 steps/s
[Step=59900 Epoch=569.8] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.436 | L2-Norm(final)=9.545 | 2302.0 samples/s | 36.0 steps/s
[Step=59950 Epoch=570.3] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.431 | L2-Norm(final)=9.546 | 4153.0 samples/s | 64.9 steps/s
[Step=60000 Epoch=570.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.425 | L2-Norm(final)=9.547 | 2316.6 samples/s | 36.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step60000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=553.9] | Loss=0.00011 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.466 | L2-Norm(final)=9.033 | 4621.0 samples/s | 72.2 steps/s
[Step=58050 Epoch=554.3] | Loss=0.00008 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.473 | L2-Norm(final)=9.057 | 4330.8 samples/s | 67.7 steps/s
[Step=58100 Epoch=554.8] | Loss=0.00007 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.485 | L2-Norm(final)=9.080 | 7559.0 samples/s | 118.1 steps/s
[Step=58150 Epoch=555.3] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.496 | L2-Norm(final)=9.100 | 2083.4 samples/s | 32.6 steps/s
[Step=58200 Epoch=555.8] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.115 | 6775.1 samples/s | 105.9 steps/s
[Step=58250 Epoch=556.3] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.507 | L2-Norm(final)=9.128 | 2161.9 samples/s | 33.8 steps/s
[Step=58300 Epoch=556.7] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.511 | L2-Norm(final)=9.139 | 6061.3 samples/s | 94.7 steps/s
[Step=58350 Epoch=557.2] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=9.149 | 2250.1 samples/s | 35.2 steps/s
[Step=58400 Epoch=557.7] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.516 | L2-Norm(final)=9.159 | 5571.7 samples/s | 87.1 steps/s
[Step=58450 Epoch=558.2] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.517 | L2-Norm(final)=9.168 | 2298.4 samples/s | 35.9 steps/s
[Step=58500 Epoch=558.6] | Loss=0.00003 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.519 | L2-Norm(final)=9.176 | 5224.9 samples/s | 81.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=558.6] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=9.262 | 5336.8 samples/s | 83.4 steps/s
[Step=58550 Epoch=559.1] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=9.269 | 3699.2 samples/s | 57.8 steps/s
[Step=58600 Epoch=559.6] | Loss=0.00216 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.522 | L2-Norm(final)=9.269 | 6239.8 samples/s | 97.5 steps/s
[Step=58650 Epoch=560.1] | Loss=0.00173 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.558 | L2-Norm(final)=9.265 | 1993.8 samples/s | 31.2 steps/s
[Step=58700 Epoch=560.5] | Loss=0.00132 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.581 | L2-Norm(final)=9.265 | 5744.4 samples/s | 89.8 steps/s
[Step=58750 Epoch=561.0] | Loss=0.00109 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.596 | L2-Norm(final)=9.266 | 2051.9 samples/s | 32.1 steps/s
[Step=58800 Epoch=561.5] | Loss=0.00091 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.606 | L2-Norm(final)=9.268 | 5270.5 samples/s | 82.4 steps/s
[Step=58850 Epoch=562.0] | Loss=0.00078 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.268 | 2106.7 samples/s | 32.9 steps/s
[Step=58900 Epoch=562.5] | Loss=0.00068 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.617 | L2-Norm(final)=9.269 | 4923.5 samples/s | 76.9 steps/s
[Step=58950 Epoch=562.9] | Loss=0.00061 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=9.270 | 2191.3 samples/s | 34.2 steps/s
[Step=59000 Epoch=563.4] | Loss=0.00055 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.622 | L2-Norm(final)=9.270 | 4558.2 samples/s | 71.2 steps/s
[Step=59050 Epoch=563.9] | Loss=0.00050 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=9.271 | 2245.9 samples/s | 35.1 steps/s
[Step=59100 Epoch=564.4] | Loss=0.00046 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.272 | 4308.7 samples/s | 67.3 steps/s
[Step=59150 Epoch=564.8] | Loss=0.00042 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.272 | 2322.2 samples/s | 36.3 steps/s
[Step=59200 Epoch=565.3] | Loss=0.00039 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.626 | L2-Norm(final)=9.272 | 4275.3 samples/s | 66.8 steps/s
[Step=59250 Epoch=565.8] | Loss=0.00037 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.273 | 2357.4 samples/s | 36.8 steps/s
[Step=59300 Epoch=566.3] | Loss=0.00035 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.273 | 4063.4 samples/s | 63.5 steps/s
[Step=59350 Epoch=566.8] | Loss=0.00033 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.274 | 2340.7 samples/s | 36.6 steps/s
[Step=59400 Epoch=567.2] | Loss=0.00031 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=9.274 | 4317.8 samples/s | 67.5 steps/s
[Step=59450 Epoch=567.7] | Loss=0.00029 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=9.275 | 2319.9 samples/s | 36.2 steps/s
[Step=59500 Epoch=568.2] | Loss=0.00028 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.623 | L2-Norm(final)=9.275 | 4169.7 samples/s | 65.2 steps/s
[Step=59550 Epoch=568.7] | Loss=0.00026 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.622 | L2-Norm(final)=9.275 | 6924.5 samples/s | 108.2 steps/s
[Step=59600 Epoch=569.1] | Loss=0.00025 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.621 | L2-Norm(final)=9.276 | 1922.8 samples/s | 30.0 steps/s
[Step=59650 Epoch=569.6] | Loss=0.00024 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=9.276 | 6322.9 samples/s | 98.8 steps/s
[Step=59700 Epoch=570.1] | Loss=0.00023 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.619 | L2-Norm(final)=9.276 | 1982.3 samples/s | 31.0 steps/s
[Step=59750 Epoch=570.6] | Loss=0.00022 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.618 | L2-Norm(final)=9.276 | 5716.8 samples/s | 89.3 steps/s
[Step=59800 Epoch=571.1] | Loss=0.00021 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.616 | L2-Norm(final)=9.277 | 2056.6 samples/s | 32.1 steps/s
[Step=59850 Epoch=571.5] | Loss=0.00021 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.615 | L2-Norm(final)=9.277 | 5269.6 samples/s | 82.3 steps/s
[Step=59900 Epoch=572.0] | Loss=0.00020 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.614 | L2-Norm(final)=9.277 | 2118.1 samples/s | 33.1 steps/s
[Step=59950 Epoch=572.5] | Loss=0.00019 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.277 | 4912.0 samples/s | 76.8 steps/s
[Step=60000 Epoch=573.0] | Loss=0.00018 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.610 | L2-Norm(final)=9.278 | 2173.0 samples/s | 34.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step60000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=546.5] | Loss=0.00020 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.639 | L2-Norm(final)=8.944 | 4968.5 samples/s | 77.6 steps/s
[Step=58050 Epoch=547.0] | Loss=0.00011 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.648 | L2-Norm(final)=8.958 | 4204.7 samples/s | 65.7 steps/s
[Step=58100 Epoch=547.5] | Loss=0.00008 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.656 | L2-Norm(final)=8.971 | 7339.8 samples/s | 114.7 steps/s
[Step=58150 Epoch=547.9] | Loss=0.00006 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.660 | L2-Norm(final)=8.980 | 2121.0 samples/s | 33.1 steps/s
[Step=58200 Epoch=548.4] | Loss=0.00006 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.664 | L2-Norm(final)=8.989 | 6307.6 samples/s | 98.6 steps/s
[Step=58250 Epoch=548.9] | Loss=0.00005 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.667 | L2-Norm(final)=8.999 | 2242.4 samples/s | 35.0 steps/s
[Step=58300 Epoch=549.4] | Loss=0.00005 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.670 | L2-Norm(final)=9.007 | 5565.0 samples/s | 87.0 steps/s
[Step=58350 Epoch=549.8] | Loss=0.00005 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.672 | L2-Norm(final)=9.016 | 2347.9 samples/s | 36.7 steps/s
[Step=58400 Epoch=550.3] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.675 | L2-Norm(final)=9.024 | 4995.7 samples/s | 78.1 steps/s
[Step=58450 Epoch=550.8] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.677 | L2-Norm(final)=9.032 | 2421.0 samples/s | 37.8 steps/s
[Step=58500 Epoch=551.2] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.678 | L2-Norm(final)=9.040 | 4808.7 samples/s | 75.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=551.2] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.695 | L2-Norm(final)=9.118 | 5262.2 samples/s | 82.2 steps/s
[Step=58550 Epoch=551.7] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.692 | L2-Norm(final)=9.124 | 3751.3 samples/s | 58.6 steps/s
[Step=58600 Epoch=552.2] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.690 | L2-Norm(final)=9.132 | 6084.9 samples/s | 95.1 steps/s
[Step=58650 Epoch=552.7] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.687 | L2-Norm(final)=9.138 | 1984.1 samples/s | 31.0 steps/s
[Step=58700 Epoch=553.1] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.680 | L2-Norm(final)=9.142 | 5445.1 samples/s | 85.1 steps/s
[Step=58750 Epoch=553.6] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.673 | L2-Norm(final)=9.145 | 2073.7 samples/s | 32.4 steps/s
[Step=58800 Epoch=554.1] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.665 | L2-Norm(final)=9.147 | 4898.3 samples/s | 76.5 steps/s
[Step=58850 Epoch=554.5] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.657 | L2-Norm(final)=9.150 | 2202.7 samples/s | 34.4 steps/s
[Step=58900 Epoch=555.0] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.648 | L2-Norm(final)=9.152 | 4364.5 samples/s | 68.2 steps/s
[Step=58950 Epoch=555.5] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.639 | L2-Norm(final)=9.154 | 2323.0 samples/s | 36.3 steps/s
[Step=59000 Epoch=555.9] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.631 | L2-Norm(final)=9.156 | 4168.7 samples/s | 65.1 steps/s
[Step=59050 Epoch=556.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.621 | L2-Norm(final)=9.157 | 2376.4 samples/s | 37.1 steps/s
[Step=59100 Epoch=556.9] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.159 | 4313.6 samples/s | 67.4 steps/s
[Step=59150 Epoch=557.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.603 | L2-Norm(final)=9.161 | 2361.9 samples/s | 36.9 steps/s
[Step=59200 Epoch=557.8] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.593 | L2-Norm(final)=9.162 | 4255.5 samples/s | 66.5 steps/s
[Step=59250 Epoch=558.3] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.584 | L2-Norm(final)=9.164 | 2549.5 samples/s | 39.8 steps/s
[Step=59300 Epoch=558.8] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.574 | L2-Norm(final)=9.166 | 3674.9 samples/s | 57.4 steps/s
[Step=59350 Epoch=559.2] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.565 | L2-Norm(final)=9.167 | 5934.1 samples/s | 92.7 steps/s
[Step=59400 Epoch=559.7] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.555 | L2-Norm(final)=9.169 | 1891.3 samples/s | 29.6 steps/s
[Step=59450 Epoch=560.2] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.545 | L2-Norm(final)=9.170 | 5250.8 samples/s | 82.0 steps/s
[Step=59500 Epoch=560.7] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.535 | L2-Norm(final)=9.172 | 1958.9 samples/s | 30.6 steps/s
[Step=59550 Epoch=561.1] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.525 | L2-Norm(final)=9.174 | 4776.2 samples/s | 74.6 steps/s
[Step=59600 Epoch=561.6] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.515 | L2-Norm(final)=9.175 | 2037.5 samples/s | 31.8 steps/s
[Step=59650 Epoch=562.1] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.504 | L2-Norm(final)=9.177 | 4303.6 samples/s | 67.2 steps/s
[Step=59700 Epoch=562.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.494 | L2-Norm(final)=9.179 | 2230.9 samples/s | 34.9 steps/s
[Step=59750 Epoch=563.0] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.484 | L2-Norm(final)=9.180 | 4264.2 samples/s | 66.6 steps/s
[Step=59800 Epoch=563.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.473 | L2-Norm(final)=9.182 | 2355.7 samples/s | 36.8 steps/s
[Step=59850 Epoch=564.0] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.463 | L2-Norm(final)=9.184 | 4243.0 samples/s | 66.3 steps/s
[Step=59900 Epoch=564.4] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.452 | L2-Norm(final)=9.186 | 2388.9 samples/s | 37.3 steps/s
[Step=59950 Epoch=564.9] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.441 | L2-Norm(final)=9.188 | 4292.1 samples/s | 67.1 steps/s
[Step=60000 Epoch=565.4] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.430 | L2-Norm(final)=9.190 | 2469.6 samples/s | 38.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step60000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=552.8] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.669 | L2-Norm(final)=9.666 | 5463.7 samples/s | 85.4 steps/s
[Step=58050 Epoch=553.3] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.670 | L2-Norm(final)=9.667 | 3858.2 samples/s | 60.3 steps/s
[Step=58100 Epoch=553.7] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.672 | L2-Norm(final)=9.669 | 7645.9 samples/s | 119.5 steps/s
[Step=58150 Epoch=554.2] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.673 | L2-Norm(final)=9.671 | 2125.0 samples/s | 33.2 steps/s
[Step=58200 Epoch=554.7] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.674 | L2-Norm(final)=9.673 | 6713.0 samples/s | 104.9 steps/s
[Step=58250 Epoch=555.2] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.675 | L2-Norm(final)=9.674 | 2200.8 samples/s | 34.4 steps/s
[Step=58300 Epoch=555.7] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.675 | L2-Norm(final)=9.676 | 6124.8 samples/s | 95.7 steps/s
[Step=58350 Epoch=556.1] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.676 | L2-Norm(final)=9.677 | 2246.3 samples/s | 35.1 steps/s
[Step=58400 Epoch=556.6] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.676 | L2-Norm(final)=9.679 | 5539.0 samples/s | 86.5 steps/s
[Step=58450 Epoch=557.1] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.676 | L2-Norm(final)=9.680 | 2331.4 samples/s | 36.4 steps/s
[Step=58500 Epoch=557.6] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.677 | L2-Norm(final)=9.682 | 5233.3 samples/s | 81.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=557.6] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.678 | L2-Norm(final)=9.696 | 4979.0 samples/s | 77.8 steps/s
[Step=58550 Epoch=558.0] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.678 | L2-Norm(final)=9.698 | 3877.7 samples/s | 60.6 steps/s
[Step=58600 Epoch=558.5] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.677 | L2-Norm(final)=9.699 | 6400.5 samples/s | 100.0 steps/s
[Step=58650 Epoch=559.0] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.676 | L2-Norm(final)=9.700 | 1993.1 samples/s | 31.1 steps/s
[Step=58700 Epoch=559.5] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.674 | L2-Norm(final)=9.701 | 5783.7 samples/s | 90.4 steps/s
[Step=58750 Epoch=559.9] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.672 | L2-Norm(final)=9.701 | 2080.9 samples/s | 32.5 steps/s
[Step=58800 Epoch=560.4] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.671 | L2-Norm(final)=9.702 | 5307.7 samples/s | 82.9 steps/s
[Step=58850 Epoch=560.9] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.669 | L2-Norm(final)=9.703 | 2132.7 samples/s | 33.3 steps/s
[Step=58900 Epoch=561.4] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.667 | L2-Norm(final)=9.703 | 4974.2 samples/s | 77.7 steps/s
[Step=58950 Epoch=561.8] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.665 | L2-Norm(final)=9.704 | 2189.8 samples/s | 34.2 steps/s
[Step=59000 Epoch=562.3] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.663 | L2-Norm(final)=9.704 | 4607.1 samples/s | 72.0 steps/s
[Step=59050 Epoch=562.8] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.661 | L2-Norm(final)=9.705 | 2272.7 samples/s | 35.5 steps/s
[Step=59100 Epoch=563.3] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.659 | L2-Norm(final)=9.705 | 4308.9 samples/s | 67.3 steps/s
[Step=59150 Epoch=563.8] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.656 | L2-Norm(final)=9.706 | 2359.8 samples/s | 36.9 steps/s
[Step=59200 Epoch=564.2] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.654 | L2-Norm(final)=9.706 | 4165.3 samples/s | 65.1 steps/s
[Step=59250 Epoch=564.7] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.652 | L2-Norm(final)=9.707 | 2325.1 samples/s | 36.3 steps/s
[Step=59300 Epoch=565.2] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.649 | L2-Norm(final)=9.707 | 4265.4 samples/s | 66.6 steps/s
[Step=59350 Epoch=565.7] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.647 | L2-Norm(final)=9.708 | 2388.3 samples/s | 37.3 steps/s
[Step=59400 Epoch=566.1] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.644 | L2-Norm(final)=9.708 | 4261.7 samples/s | 66.6 steps/s
[Step=59450 Epoch=566.6] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.642 | L2-Norm(final)=9.708 | 2422.0 samples/s | 37.8 steps/s
[Step=59500 Epoch=567.1] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.639 | L2-Norm(final)=9.709 | 4063.4 samples/s | 63.5 steps/s
[Step=59550 Epoch=567.6] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.637 | L2-Norm(final)=9.709 | 6908.0 samples/s | 107.9 steps/s
[Step=59600 Epoch=568.0] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.634 | L2-Norm(final)=9.710 | 1966.6 samples/s | 30.7 steps/s
[Step=59650 Epoch=568.5] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.632 | L2-Norm(final)=9.710 | 6165.9 samples/s | 96.3 steps/s
[Step=59700 Epoch=569.0] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.629 | L2-Norm(final)=9.710 | 2027.5 samples/s | 31.7 steps/s
[Step=59750 Epoch=569.5] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.626 | L2-Norm(final)=9.711 | 5713.4 samples/s | 89.3 steps/s
[Step=59800 Epoch=569.9] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=9.711 | 2037.4 samples/s | 31.8 steps/s
[Step=59850 Epoch=570.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.621 | L2-Norm(final)=9.711 | 5348.5 samples/s | 83.6 steps/s
[Step=59900 Epoch=570.9] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.618 | L2-Norm(final)=9.712 | 2118.1 samples/s | 33.1 steps/s
[Step=59950 Epoch=571.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.615 | L2-Norm(final)=9.712 | 4947.6 samples/s | 77.3 steps/s
[Step=60000 Epoch=571.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.713 | 2200.6 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11505 | acc=0.9577 | tpr=0.9788 | fpr=0.0882 | 4533.3 samples/s | 17.7 steps/s
Avg test loss: 0.11895, Avg test acc: 0.95649, Avg tpr: 0.97715, Avg fpr: 0.08896, total FA: 694

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.12322 | acc=0.9578 | tpr=0.9758 | fpr=0.0813 | 4728.5 samples/s | 18.5 steps/s
Avg test loss: 0.12445, Avg test acc: 0.95733, Avg tpr: 0.97488, Avg fpr: 0.08127, total FA: 634

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11207 | acc=0.9577 | tpr=0.9724 | fpr=0.0743 | 4774.5 samples/s | 18.7 steps/s
Avg test loss: 0.11530, Avg test acc: 0.95621, Avg tpr: 0.97033, Avg fpr: 0.07486, total FA: 584

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.11216 | acc=0.9586 | tpr=0.9746 | fpr=0.0761 | 4815.4 samples/s | 18.8 steps/s
Avg test loss: 0.11750, Avg test acc: 0.95745, Avg tpr: 0.97470, Avg fpr: 0.08050, total FA: 628

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11063 | acc=0.9576 | tpr=0.9741 | fpr=0.0783 | 4876.9 samples/s | 19.1 steps/s
Avg test loss: 0.11557, Avg test acc: 0.95749, Avg tpr: 0.97412, Avg fpr: 0.07909, total FA: 617

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.96925 | acc=0.2993 | tpr=0.0083 | fpr=0.0689 | 4906.0 samples/s | 19.2 steps/s
Avg test loss: 4.97628, Avg test acc: 0.29826, Avg tpr: 0.00950, Avg fpr: 0.06666, total FA: 520

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.70321 | acc=0.2916 | tpr=0.0099 | fpr=0.0966 | 5088.1 samples/s | 19.9 steps/s
Avg test loss: 4.71513, Avg test acc: 0.28901, Avg tpr: 0.01032, Avg fpr: 0.09806, total FA: 765

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.64467 | acc=0.2888 | tpr=0.0091 | fpr=0.1041 | 5095.2 samples/s | 19.9 steps/s
Avg test loss: 5.65075, Avg test acc: 0.28540, Avg tpr: 0.00933, Avg fpr: 0.10742, total FA: 838

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.49935 | acc=0.2949 | tpr=0.0153 | fpr=0.0979 | 4961.0 samples/s | 19.4 steps/s
Avg test loss: 5.49224, Avg test acc: 0.29229, Avg tpr: 0.01655, Avg fpr: 0.10127, total FA: 790

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.85898 | acc=0.3063 | tpr=0.0269 | fpr=0.0870 | 4966.0 samples/s | 19.4 steps/s
Avg test loss: 4.86852, Avg test acc: 0.30415, Avg tpr: 0.02757, Avg fpr: 0.08755, total FA: 683

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.07064 | acc=0.0852 | tpr=0.6372 | fpr=0.9248 | 5268.9 samples/s | 20.6 steps/s
[Step= 100] | Loss=6.04191 | acc=0.0873 | tpr=0.6141 | fpr=0.9225 | 6843.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.05807 | acc=0.0878 | tpr=0.6124 | fpr=0.9219 | 7157.1 samples/s | 28.0 steps/s
[Step= 200] | Loss=6.05588 | acc=0.0877 | tpr=0.6044 | fpr=0.9217 | 7846.1 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.05883 | acc=0.0885 | tpr=0.6096 | fpr=0.9210 | 7641.5 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.05424 | acc=0.0893 | tpr=0.6182 | fpr=0.9204 | 8316.6 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.04768 | acc=0.0893 | tpr=0.6174 | fpr=0.9203 | 7626.0 samples/s | 29.8 steps/s
[Step= 400] | Loss=6.04387 | acc=0.0895 | tpr=0.6171 | fpr=0.9201 | 7885.2 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.04741 | acc=0.0895 | tpr=0.6105 | fpr=0.9199 | 7958.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=6.05156 | acc=0.0894 | tpr=0.6079 | fpr=0.9200 | 7611.0 samples/s | 29.7 steps/s
[Step= 550] | Loss=6.05450 | acc=0.0893 | tpr=0.6076 | fpr=0.9201 | 14665.2 samples/s | 57.3 steps/s
Avg test loss: 6.05673, Avg test acc: 0.08923, Avg tpr: 0.60737, Avg fpr: 0.92019, total FA: 127766

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.74624 | acc=0.0901 | tpr=0.5265 | fpr=0.9178 | 4792.5 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.71787 | acc=0.0918 | tpr=0.5373 | fpr=0.9165 | 7192.1 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.71633 | acc=0.0913 | tpr=0.5360 | fpr=0.9169 | 7744.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.71178 | acc=0.0912 | tpr=0.5246 | fpr=0.9167 | 8021.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.72051 | acc=0.0910 | tpr=0.5249 | fpr=0.9169 | 7980.0 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.71486 | acc=0.0909 | tpr=0.5273 | fpr=0.9170 | 8071.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=5.70966 | acc=0.0909 | tpr=0.5222 | fpr=0.9170 | 7501.2 samples/s | 29.3 steps/s
[Step= 400] | Loss=5.70643 | acc=0.0914 | tpr=0.5246 | fpr=0.9165 | 7881.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.70958 | acc=0.0914 | tpr=0.5195 | fpr=0.9164 | 7850.0 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.71394 | acc=0.0909 | tpr=0.5141 | fpr=0.9167 | 8064.9 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.71720 | acc=0.0908 | tpr=0.5113 | fpr=0.9168 | 13847.8 samples/s | 54.1 steps/s
Avg test loss: 5.71938, Avg test acc: 0.09074, Avg tpr: 0.51030, Avg fpr: 0.91689, total FA: 127308

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.96429 | acc=0.0862 | tpr=0.3761 | fpr=0.9190 | 4652.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.94158 | acc=0.0883 | tpr=0.4115 | fpr=0.9178 | 7296.9 samples/s | 28.5 steps/s
[Step= 150] | Loss=5.95228 | acc=0.0888 | tpr=0.4164 | fpr=0.9173 | 7910.2 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.94942 | acc=0.0888 | tpr=0.4120 | fpr=0.9171 | 7459.8 samples/s | 29.1 steps/s
[Step= 250] | Loss=5.94881 | acc=0.0889 | tpr=0.4166 | fpr=0.9171 | 7995.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.94605 | acc=0.0888 | tpr=0.4189 | fpr=0.9172 | 7964.2 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.93786 | acc=0.0891 | tpr=0.4170 | fpr=0.9169 | 7795.8 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.92939 | acc=0.0898 | tpr=0.4196 | fpr=0.9162 | 8041.3 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.93226 | acc=0.0899 | tpr=0.4163 | fpr=0.9161 | 7844.6 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.93324 | acc=0.0897 | tpr=0.4145 | fpr=0.9162 | 7683.5 samples/s | 30.0 steps/s
[Step= 550] | Loss=5.93684 | acc=0.0896 | tpr=0.4150 | fpr=0.9164 | 14058.6 samples/s | 54.9 steps/s
Avg test loss: 5.93849, Avg test acc: 0.08944, Avg tpr: 0.41521, Avg fpr: 0.91648, total FA: 127252

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.84239 | acc=0.1042 | tpr=0.5664 | fpr=0.9041 | 4820.8 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.82531 | acc=0.1059 | tpr=0.5672 | fpr=0.9027 | 6973.1 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.83101 | acc=0.1052 | tpr=0.5677 | fpr=0.9033 | 7927.7 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.82013 | acc=0.1041 | tpr=0.5617 | fpr=0.9042 | 8036.6 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.82389 | acc=0.1047 | tpr=0.5659 | fpr=0.9037 | 7623.6 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.81980 | acc=0.1051 | tpr=0.5651 | fpr=0.9033 | 7920.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.81199 | acc=0.1048 | tpr=0.5654 | fpr=0.9035 | 7857.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.80531 | acc=0.1051 | tpr=0.5651 | fpr=0.9033 | 8040.4 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.81025 | acc=0.1051 | tpr=0.5623 | fpr=0.9032 | 7525.8 samples/s | 29.4 steps/s
[Step= 500] | Loss=5.81069 | acc=0.1048 | tpr=0.5617 | fpr=0.9035 | 7852.1 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.81519 | acc=0.1048 | tpr=0.5575 | fpr=0.9034 | 14606.3 samples/s | 57.1 steps/s
Avg test loss: 5.81660, Avg test acc: 0.10468, Avg tpr: 0.55705, Avg fpr: 0.90354, total FA: 125455

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.19744 | acc=0.0875 | tpr=0.5177 | fpr=0.9202 | 4994.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.16664 | acc=0.0904 | tpr=0.5501 | fpr=0.9182 | 6974.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=6.16228 | acc=0.0909 | tpr=0.5692 | fpr=0.9179 | 7920.4 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.16240 | acc=0.0905 | tpr=0.5585 | fpr=0.9180 | 7362.5 samples/s | 28.8 steps/s
[Step= 250] | Loss=6.17063 | acc=0.0912 | tpr=0.5616 | fpr=0.9174 | 7991.0 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.17083 | acc=0.0913 | tpr=0.5644 | fpr=0.9173 | 7769.0 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.16306 | acc=0.0915 | tpr=0.5642 | fpr=0.9171 | 8039.5 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.16086 | acc=0.0921 | tpr=0.5673 | fpr=0.9165 | 7520.5 samples/s | 29.4 steps/s
[Step= 450] | Loss=6.16362 | acc=0.0924 | tpr=0.5691 | fpr=0.9162 | 8172.3 samples/s | 31.9 steps/s
[Step= 500] | Loss=6.16488 | acc=0.0923 | tpr=0.5648 | fpr=0.9162 | 7764.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.16951 | acc=0.0922 | tpr=0.5635 | fpr=0.9164 | 14037.8 samples/s | 54.8 steps/s
Avg test loss: 6.17144, Avg test acc: 0.09205, Avg tpr: 0.56260, Avg fpr: 0.91651, total FA: 127255

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08885 | acc=0.9819 | tpr=0.9646 | fpr=0.0178 | 4863.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09043 | acc=0.9814 | tpr=0.9638 | fpr=0.0183 | 7402.5 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.09403 | acc=0.9805 | tpr=0.9611 | fpr=0.0191 | 7380.8 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.09593 | acc=0.9806 | tpr=0.9661 | fpr=0.0191 | 7802.5 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09455 | acc=0.9808 | tpr=0.9598 | fpr=0.0188 | 8070.5 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.09676 | acc=0.9805 | tpr=0.9600 | fpr=0.0191 | 7750.4 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.09762 | acc=0.9803 | tpr=0.9593 | fpr=0.0194 | 7971.5 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09872 | acc=0.9800 | tpr=0.9546 | fpr=0.0196 | 7771.1 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.10079 | acc=0.9796 | tpr=0.9503 | fpr=0.0199 | 7842.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10002 | acc=0.9796 | tpr=0.9511 | fpr=0.0198 | 8036.6 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.09950 | acc=0.9798 | tpr=0.9491 | fpr=0.0196 | 13672.0 samples/s | 53.4 steps/s
Avg test loss: 0.09940, Avg test acc: 0.97982, Avg tpr: 0.94929, Avg fpr: 0.01963, total FA: 2725

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09411 | acc=0.9823 | tpr=0.9381 | fpr=0.0169 | 5024.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.09713 | acc=0.9821 | tpr=0.9382 | fpr=0.0171 | 6422.8 samples/s | 25.1 steps/s
[Step= 150] | Loss=0.10033 | acc=0.9815 | tpr=0.9366 | fpr=0.0177 | 7947.7 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10235 | acc=0.9813 | tpr=0.9355 | fpr=0.0178 | 8195.9 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.10043 | acc=0.9816 | tpr=0.9345 | fpr=0.0176 | 7608.6 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.10306 | acc=0.9812 | tpr=0.9324 | fpr=0.0179 | 7875.6 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.10384 | acc=0.9809 | tpr=0.9355 | fpr=0.0182 | 7512.5 samples/s | 29.3 steps/s
[Step= 400] | Loss=0.10524 | acc=0.9808 | tpr=0.9311 | fpr=0.0183 | 8314.7 samples/s | 32.5 steps/s
[Step= 450] | Loss=0.10769 | acc=0.9805 | tpr=0.9304 | fpr=0.0185 | 7819.5 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.10667 | acc=0.9806 | tpr=0.9326 | fpr=0.0185 | 7596.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.10646 | acc=0.9807 | tpr=0.9312 | fpr=0.0184 | 14507.6 samples/s | 56.7 steps/s
Avg test loss: 0.10632, Avg test acc: 0.98075, Avg tpr: 0.93146, Avg fpr: 0.01836, total FA: 2549

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.10066 | acc=0.9813 | tpr=0.9425 | fpr=0.0180 | 4909.9 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.10169 | acc=0.9816 | tpr=0.9595 | fpr=0.0180 | 6739.1 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.10632 | acc=0.9809 | tpr=0.9553 | fpr=0.0186 | 7830.6 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.10792 | acc=0.9812 | tpr=0.9617 | fpr=0.0185 | 7887.1 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.10574 | acc=0.9816 | tpr=0.9598 | fpr=0.0180 | 7958.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10803 | acc=0.9813 | tpr=0.9542 | fpr=0.0182 | 7733.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.10861 | acc=0.9811 | tpr=0.9543 | fpr=0.0184 | 8034.7 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.10941 | acc=0.9809 | tpr=0.9508 | fpr=0.0185 | 7849.1 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.11140 | acc=0.9806 | tpr=0.9503 | fpr=0.0188 | 7920.2 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.11050 | acc=0.9806 | tpr=0.9498 | fpr=0.0188 | 7685.9 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.11005 | acc=0.9808 | tpr=0.9487 | fpr=0.0186 | 14136.3 samples/s | 55.2 steps/s
Avg test loss: 0.10984, Avg test acc: 0.98079, Avg tpr: 0.94889, Avg fpr: 0.01863, total FA: 2587

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09241 | acc=0.9814 | tpr=0.9425 | fpr=0.0179 | 4774.6 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09579 | acc=0.9811 | tpr=0.9510 | fpr=0.0183 | 6877.7 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.10020 | acc=0.9801 | tpr=0.9481 | fpr=0.0193 | 8236.2 samples/s | 32.2 steps/s
[Step= 200] | Loss=0.10154 | acc=0.9801 | tpr=0.9541 | fpr=0.0194 | 7774.7 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.10004 | acc=0.9806 | tpr=0.9546 | fpr=0.0189 | 7806.1 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.10229 | acc=0.9804 | tpr=0.9498 | fpr=0.0190 | 7851.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10305 | acc=0.9802 | tpr=0.9499 | fpr=0.0192 | 7916.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.10366 | acc=0.9801 | tpr=0.9469 | fpr=0.0193 | 7642.6 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.10572 | acc=0.9798 | tpr=0.9445 | fpr=0.0195 | 8089.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.10495 | acc=0.9799 | tpr=0.9458 | fpr=0.0195 | 7760.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.10451 | acc=0.9801 | tpr=0.9451 | fpr=0.0193 | 14194.1 samples/s | 55.4 steps/s
Avg test loss: 0.10434, Avg test acc: 0.98008, Avg tpr: 0.94532, Avg fpr: 0.01929, total FA: 2678

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10057 | acc=0.9816 | tpr=0.9292 | fpr=0.0175 | 4759.0 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10694 | acc=0.9808 | tpr=0.9275 | fpr=0.0182 | 7183.4 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.11079 | acc=0.9798 | tpr=0.9308 | fpr=0.0193 | 8279.7 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.11308 | acc=0.9796 | tpr=0.9366 | fpr=0.0196 | 7312.7 samples/s | 28.6 steps/s
[Step= 250] | Loss=0.11142 | acc=0.9802 | tpr=0.9345 | fpr=0.0190 | 8092.0 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.11415 | acc=0.9799 | tpr=0.9295 | fpr=0.0192 | 7898.3 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.11480 | acc=0.9797 | tpr=0.9324 | fpr=0.0194 | 7771.8 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.11627 | acc=0.9795 | tpr=0.9289 | fpr=0.0195 | 7804.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.11884 | acc=0.9793 | tpr=0.9279 | fpr=0.0198 | 8001.7 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.11801 | acc=0.9794 | tpr=0.9295 | fpr=0.0197 | 7859.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.11776 | acc=0.9796 | tpr=0.9284 | fpr=0.0195 | 13819.9 samples/s | 54.0 steps/s
Avg test loss: 0.11758, Avg test acc: 0.97960, Avg tpr: 0.92868, Avg fpr: 0.01947, total FA: 2704

server round 30/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=292.6] | Loss=0.00208 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.901 | L2-Norm(final)=16.352 | 6311.2 samples/s | 98.6 steps/s
[Step=60050 Epoch=292.8] | Loss=0.00313 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=16.355 | 3944.5 samples/s | 61.6 steps/s
[Step=60100 Epoch=293.1] | Loss=0.00295 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.360 | 4947.3 samples/s | 77.3 steps/s
[Step=60150 Epoch=293.3] | Loss=0.00313 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.365 | 5030.2 samples/s | 78.6 steps/s
[Step=60200 Epoch=293.5] | Loss=0.00299 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.370 | 7833.8 samples/s | 122.4 steps/s
[Step=60250 Epoch=293.8] | Loss=0.00289 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.905 | L2-Norm(final)=16.376 | 2202.9 samples/s | 34.4 steps/s
[Step=60300 Epoch=294.0] | Loss=0.00292 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.382 | 4998.6 samples/s | 78.1 steps/s
[Step=60350 Epoch=294.3] | Loss=0.00296 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.905 | L2-Norm(final)=16.387 | 5043.3 samples/s | 78.8 steps/s
[Step=60400 Epoch=294.5] | Loss=0.00283 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.392 | 7021.9 samples/s | 109.7 steps/s
[Step=60450 Epoch=294.8] | Loss=0.00275 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.398 | 2317.3 samples/s | 36.2 steps/s
[Step=60500 Epoch=295.0] | Loss=0.00278 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.403 | 4885.3 samples/s | 76.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=295.0] | Loss=0.00049 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=16.456 | 5610.2 samples/s | 87.7 steps/s
[Step=60550 Epoch=295.3] | Loss=0.00222 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=16.461 | 3971.9 samples/s | 62.1 steps/s
[Step=60600 Epoch=295.5] | Loss=0.00296 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.904 | L2-Norm(final)=16.466 | 4504.1 samples/s | 70.4 steps/s
[Step=60650 Epoch=295.7] | Loss=0.00307 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.470 | 4450.1 samples/s | 69.5 steps/s
[Step=60700 Epoch=296.0] | Loss=0.00328 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.475 | 6532.5 samples/s | 102.1 steps/s
[Step=60750 Epoch=296.2] | Loss=0.00456 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.907 | L2-Norm(final)=16.479 | 2080.4 samples/s | 32.5 steps/s
[Step=60800 Epoch=296.5] | Loss=0.00463 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.909 | L2-Norm(final)=16.483 | 4521.4 samples/s | 70.6 steps/s
[Step=60850 Epoch=296.7] | Loss=0.00441 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.911 | L2-Norm(final)=16.487 | 4354.9 samples/s | 68.0 steps/s
[Step=60900 Epoch=297.0] | Loss=0.00411 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.490 | 5977.4 samples/s | 93.4 steps/s
[Step=60950 Epoch=297.2] | Loss=0.00392 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.494 | 2153.0 samples/s | 33.6 steps/s
[Step=61000 Epoch=297.4] | Loss=0.00383 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.498 | 4469.4 samples/s | 69.8 steps/s
[Step=61050 Epoch=297.7] | Loss=0.00374 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.501 | 4477.0 samples/s | 70.0 steps/s
[Step=61100 Epoch=297.9] | Loss=0.00360 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.504 | 5425.2 samples/s | 84.8 steps/s
[Step=61150 Epoch=298.2] | Loss=0.00347 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=16.507 | 2217.2 samples/s | 34.6 steps/s
[Step=61200 Epoch=298.4] | Loss=0.00332 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.911 | L2-Norm(final)=16.511 | 4503.1 samples/s | 70.4 steps/s
[Step=61250 Epoch=298.7] | Loss=0.00322 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.910 | L2-Norm(final)=16.514 | 4443.6 samples/s | 69.4 steps/s
[Step=61300 Epoch=298.9] | Loss=0.00322 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.909 | L2-Norm(final)=16.517 | 4968.7 samples/s | 77.6 steps/s
[Step=61350 Epoch=299.2] | Loss=0.00318 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.908 | L2-Norm(final)=16.519 | 2308.0 samples/s | 36.1 steps/s
[Step=61400 Epoch=299.4] | Loss=0.00315 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.907 | L2-Norm(final)=16.522 | 4488.9 samples/s | 70.1 steps/s
[Step=61450 Epoch=299.6] | Loss=0.00310 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=16.525 | 4486.9 samples/s | 70.1 steps/s
[Step=61500 Epoch=299.9] | Loss=0.00305 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.905 | L2-Norm(final)=16.528 | 4562.4 samples/s | 71.3 steps/s
[Step=61550 Epoch=300.1] | Loss=0.00305 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=16.531 | 2380.9 samples/s | 37.2 steps/s
[Step=61600 Epoch=300.4] | Loss=0.00305 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.902 | L2-Norm(final)=16.533 | 4475.0 samples/s | 69.9 steps/s
[Step=61650 Epoch=300.6] | Loss=0.00298 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.901 | L2-Norm(final)=16.536 | 4461.3 samples/s | 69.7 steps/s
[Step=61700 Epoch=300.9] | Loss=0.00296 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.899 | L2-Norm(final)=16.539 | 4600.6 samples/s | 71.9 steps/s
[Step=61750 Epoch=301.1] | Loss=0.00291 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=16.541 | 2445.2 samples/s | 38.2 steps/s
[Step=61800 Epoch=301.3] | Loss=0.00289 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.896 | L2-Norm(final)=16.544 | 4489.7 samples/s | 70.2 steps/s
[Step=61850 Epoch=301.6] | Loss=0.00284 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=16.546 | 4472.9 samples/s | 69.9 steps/s
[Step=61900 Epoch=301.8] | Loss=0.00280 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=16.549 | 4379.4 samples/s | 68.4 steps/s
[Step=61950 Epoch=302.1] | Loss=0.00278 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.891 | L2-Norm(final)=16.551 | 2470.9 samples/s | 38.6 steps/s
[Step=62000 Epoch=302.3] | Loss=0.00275 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.889 | L2-Norm(final)=16.553 | 4464.2 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step62000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=292.8] | Loss=0.00379 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=16.859 | 5200.7 samples/s | 81.3 steps/s
[Step=60050 Epoch=293.0] | Loss=0.00320 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=16.863 | 4338.6 samples/s | 67.8 steps/s
[Step=60100 Epoch=293.3] | Loss=0.00293 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=16.868 | 5007.2 samples/s | 78.2 steps/s
[Step=60150 Epoch=293.5] | Loss=0.00269 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=16.873 | 5120.2 samples/s | 80.0 steps/s
[Step=60200 Epoch=293.7] | Loss=0.00264 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.878 | 7480.4 samples/s | 116.9 steps/s
[Step=60250 Epoch=294.0] | Loss=0.00255 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.883 | 2219.0 samples/s | 34.7 steps/s
[Step=60300 Epoch=294.2] | Loss=0.00252 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.888 | 5008.8 samples/s | 78.3 steps/s
[Step=60350 Epoch=294.5] | Loss=0.00251 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.893 | 5061.2 samples/s | 79.1 steps/s
[Step=60400 Epoch=294.7] | Loss=0.00245 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.898 | 6774.4 samples/s | 105.8 steps/s
[Step=60450 Epoch=295.0] | Loss=0.00242 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.903 | 2283.6 samples/s | 35.7 steps/s
[Step=60500 Epoch=295.2] | Loss=0.00236 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.908 | 4956.1 samples/s | 77.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=295.2] | Loss=0.00437 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=16.959 | 5100.8 samples/s | 79.7 steps/s
[Step=60550 Epoch=295.5] | Loss=0.00260 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.591 | L2-Norm(final)=16.965 | 3973.1 samples/s | 62.1 steps/s
[Step=60600 Epoch=295.7] | Loss=0.00272 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.591 | L2-Norm(final)=16.969 | 4355.7 samples/s | 68.1 steps/s
[Step=60650 Epoch=295.9] | Loss=0.00257 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=16.974 | 4473.8 samples/s | 69.9 steps/s
[Step=60700 Epoch=296.2] | Loss=0.00275 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.978 | 6534.9 samples/s | 102.1 steps/s
[Step=60750 Epoch=296.4] | Loss=0.00256 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.981 | 2081.2 samples/s | 32.5 steps/s
[Step=60800 Epoch=296.7] | Loss=0.00253 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.985 | 4394.3 samples/s | 68.7 steps/s
[Step=60850 Epoch=296.9] | Loss=0.00250 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.989 | 4426.9 samples/s | 69.2 steps/s
[Step=60900 Epoch=297.2] | Loss=0.00248 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.993 | 5879.6 samples/s | 91.9 steps/s
[Step=60950 Epoch=297.4] | Loss=0.00248 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=16.996 | 2136.1 samples/s | 33.4 steps/s
[Step=61000 Epoch=297.7] | Loss=0.00246 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=17.000 | 4486.4 samples/s | 70.1 steps/s
[Step=61050 Epoch=297.9] | Loss=0.00239 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.591 | L2-Norm(final)=17.003 | 4454.5 samples/s | 69.6 steps/s
[Step=61100 Epoch=298.1] | Loss=0.00234 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.591 | L2-Norm(final)=17.007 | 5539.7 samples/s | 86.6 steps/s
[Step=61150 Epoch=298.4] | Loss=0.00228 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=17.010 | 2232.8 samples/s | 34.9 steps/s
[Step=61200 Epoch=298.6] | Loss=0.00224 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=17.013 | 4474.5 samples/s | 69.9 steps/s
[Step=61250 Epoch=298.9] | Loss=0.00224 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=17.017 | 4423.4 samples/s | 69.1 steps/s
[Step=61300 Epoch=299.1] | Loss=0.00220 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.586 | L2-Norm(final)=17.020 | 5017.0 samples/s | 78.4 steps/s
[Step=61350 Epoch=299.4] | Loss=0.00218 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=17.023 | 2311.6 samples/s | 36.1 steps/s
[Step=61400 Epoch=299.6] | Loss=0.00218 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.583 | L2-Norm(final)=17.026 | 4471.7 samples/s | 69.9 steps/s
[Step=61450 Epoch=299.8] | Loss=0.00218 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=17.029 | 4351.0 samples/s | 68.0 steps/s
[Step=61500 Epoch=300.1] | Loss=0.00216 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=17.032 | 4871.6 samples/s | 76.1 steps/s
[Step=61550 Epoch=300.3] | Loss=0.00214 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.579 | L2-Norm(final)=17.035 | 2318.4 samples/s | 36.2 steps/s
[Step=61600 Epoch=300.6] | Loss=0.00215 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.577 | L2-Norm(final)=17.038 | 4470.3 samples/s | 69.8 steps/s
[Step=61650 Epoch=300.8] | Loss=0.00215 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.575 | L2-Norm(final)=17.041 | 4449.9 samples/s | 69.5 steps/s
[Step=61700 Epoch=301.1] | Loss=0.00214 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.573 | L2-Norm(final)=17.044 | 4535.4 samples/s | 70.9 steps/s
[Step=61750 Epoch=301.3] | Loss=0.00210 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=17.046 | 2414.2 samples/s | 37.7 steps/s
[Step=61800 Epoch=301.6] | Loss=0.00208 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.569 | L2-Norm(final)=17.049 | 4518.0 samples/s | 70.6 steps/s
[Step=61850 Epoch=301.8] | Loss=0.00208 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.567 | L2-Norm(final)=17.052 | 4527.4 samples/s | 70.7 steps/s
[Step=61900 Epoch=302.0] | Loss=0.00207 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=17.055 | 4296.2 samples/s | 67.1 steps/s
[Step=61950 Epoch=302.3] | Loss=0.00203 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=17.058 | 2369.6 samples/s | 37.0 steps/s
[Step=62000 Epoch=302.5] | Loss=0.00200 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=17.061 | 4453.3 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step62000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=292.4] | Loss=0.00154 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=17.095 | 5140.8 samples/s | 80.3 steps/s
[Step=60050 Epoch=292.6] | Loss=0.00362 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.319 | L2-Norm(final)=17.098 | 4628.9 samples/s | 72.3 steps/s
[Step=60100 Epoch=292.8] | Loss=0.00313 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.321 | L2-Norm(final)=17.103 | 5020.3 samples/s | 78.4 steps/s
[Step=60150 Epoch=293.1] | Loss=0.00332 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=17.108 | 5020.2 samples/s | 78.4 steps/s
[Step=60200 Epoch=293.3] | Loss=0.00323 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.112 | 7846.8 samples/s | 122.6 steps/s
[Step=60250 Epoch=293.6] | Loss=0.00307 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.117 | 2203.1 samples/s | 34.4 steps/s
[Step=60300 Epoch=293.8] | Loss=0.00288 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.121 | 4949.7 samples/s | 77.3 steps/s
[Step=60350 Epoch=294.1] | Loss=0.00288 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.126 | 5110.9 samples/s | 79.9 steps/s
[Step=60400 Epoch=294.3] | Loss=0.00294 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.131 | 6814.0 samples/s | 106.5 steps/s
[Step=60450 Epoch=294.5] | Loss=0.00290 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=17.136 | 2310.1 samples/s | 36.1 steps/s
[Step=60500 Epoch=294.8] | Loss=0.00289 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=17.140 | 5114.1 samples/s | 79.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=294.8] | Loss=0.00058 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.188 | 5377.7 samples/s | 84.0 steps/s
[Step=60550 Epoch=295.0] | Loss=0.00355 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=17.193 | 3967.3 samples/s | 62.0 steps/s
[Step=60600 Epoch=295.3] | Loss=0.00348 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.325 | L2-Norm(final)=17.197 | 4454.3 samples/s | 69.6 steps/s
[Step=60650 Epoch=295.5] | Loss=0.00299 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.326 | L2-Norm(final)=17.201 | 4418.5 samples/s | 69.0 steps/s
[Step=60700 Epoch=295.8] | Loss=0.00288 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.205 | 6541.4 samples/s | 102.2 steps/s
[Step=60750 Epoch=296.0] | Loss=0.00286 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.209 | 2095.8 samples/s | 32.7 steps/s
[Step=60800 Epoch=296.2] | Loss=0.00298 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.213 | 4563.2 samples/s | 71.3 steps/s
[Step=60850 Epoch=296.5] | Loss=0.00292 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.217 | 4465.1 samples/s | 69.8 steps/s
[Step=60900 Epoch=296.7] | Loss=0.00287 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.220 | 5689.4 samples/s | 88.9 steps/s
[Step=60950 Epoch=297.0] | Loss=0.00283 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=17.224 | 2169.5 samples/s | 33.9 steps/s
[Step=61000 Epoch=297.2] | Loss=0.00279 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.326 | L2-Norm(final)=17.227 | 4431.1 samples/s | 69.2 steps/s
[Step=61050 Epoch=297.5] | Loss=0.00272 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.326 | L2-Norm(final)=17.230 | 4450.6 samples/s | 69.5 steps/s
[Step=61100 Epoch=297.7] | Loss=0.00267 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.325 | L2-Norm(final)=17.234 | 5367.1 samples/s | 83.9 steps/s
[Step=61150 Epoch=298.0] | Loss=0.00267 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.324 | L2-Norm(final)=17.237 | 2244.9 samples/s | 35.1 steps/s
[Step=61200 Epoch=298.2] | Loss=0.00261 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=17.240 | 4385.5 samples/s | 68.5 steps/s
[Step=61250 Epoch=298.4] | Loss=0.00257 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=17.243 | 4498.8 samples/s | 70.3 steps/s
[Step=61300 Epoch=298.7] | Loss=0.00254 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.321 | L2-Norm(final)=17.246 | 4824.4 samples/s | 75.4 steps/s
[Step=61350 Epoch=298.9] | Loss=0.00249 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.320 | L2-Norm(final)=17.249 | 2313.0 samples/s | 36.1 steps/s
[Step=61400 Epoch=299.2] | Loss=0.00246 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.319 | L2-Norm(final)=17.252 | 4479.6 samples/s | 70.0 steps/s
[Step=61450 Epoch=299.4] | Loss=0.00245 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.317 | L2-Norm(final)=17.255 | 4447.5 samples/s | 69.5 steps/s
[Step=61500 Epoch=299.7] | Loss=0.00245 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.316 | L2-Norm(final)=17.258 | 4611.5 samples/s | 72.1 steps/s
[Step=61550 Epoch=299.9] | Loss=0.00243 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=17.260 | 2412.8 samples/s | 37.7 steps/s
[Step=61600 Epoch=300.1] | Loss=0.00242 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.312 | L2-Norm(final)=17.263 | 4544.9 samples/s | 71.0 steps/s
[Step=61650 Epoch=300.4] | Loss=0.00240 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=17.266 | 4266.9 samples/s | 66.7 steps/s
[Step=61700 Epoch=300.6] | Loss=0.00236 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.309 | L2-Norm(final)=17.269 | 4455.3 samples/s | 69.6 steps/s
[Step=61750 Epoch=300.9] | Loss=0.00239 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=17.271 | 2469.2 samples/s | 38.6 steps/s
[Step=61800 Epoch=301.1] | Loss=0.00237 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.305 | L2-Norm(final)=17.274 | 4374.5 samples/s | 68.4 steps/s
[Step=61850 Epoch=301.4] | Loss=0.00237 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.303 | L2-Norm(final)=17.277 | 4432.3 samples/s | 69.3 steps/s
[Step=61900 Epoch=301.6] | Loss=0.00234 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.301 | L2-Norm(final)=17.279 | 4434.5 samples/s | 69.3 steps/s
[Step=61950 Epoch=301.9] | Loss=0.00229 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.299 | L2-Norm(final)=17.282 | 2462.6 samples/s | 38.5 steps/s
[Step=62000 Epoch=302.1] | Loss=0.00228 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.297 | L2-Norm(final)=17.285 | 4458.1 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step62000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=292.6] | Loss=0.00896 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=17.047 | 5290.0 samples/s | 82.7 steps/s
[Step=60050 Epoch=292.8] | Loss=0.00211 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.984 | L2-Norm(final)=17.051 | 4506.3 samples/s | 70.4 steps/s
[Step=60100 Epoch=293.1] | Loss=0.00247 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=17.056 | 4912.2 samples/s | 76.8 steps/s
[Step=60150 Epoch=293.3] | Loss=0.00260 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.061 | 5095.5 samples/s | 79.6 steps/s
[Step=60200 Epoch=293.6] | Loss=0.00252 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.066 | 7693.2 samples/s | 120.2 steps/s
[Step=60250 Epoch=293.8] | Loss=0.00245 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.986 | L2-Norm(final)=17.071 | 2183.2 samples/s | 34.1 steps/s
[Step=60300 Epoch=294.1] | Loss=0.00235 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.076 | 4872.5 samples/s | 76.1 steps/s
[Step=60350 Epoch=294.3] | Loss=0.00241 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.081 | 4956.7 samples/s | 77.4 steps/s
[Step=60400 Epoch=294.5] | Loss=0.00238 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.086 | 7005.1 samples/s | 109.5 steps/s
[Step=60450 Epoch=294.8] | Loss=0.00235 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.986 | L2-Norm(final)=17.091 | 2303.0 samples/s | 36.0 steps/s
[Step=60500 Epoch=295.0] | Loss=0.00233 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.096 | 5111.9 samples/s | 79.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=295.0] | Loss=0.00498 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=17.147 | 5676.4 samples/s | 88.7 steps/s
[Step=60550 Epoch=295.3] | Loss=0.00239 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.152 | 3849.1 samples/s | 60.1 steps/s
[Step=60600 Epoch=295.5] | Loss=0.00215 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=17.157 | 4502.5 samples/s | 70.4 steps/s
[Step=60650 Epoch=295.8] | Loss=0.00245 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.988 | L2-Norm(final)=17.162 | 4378.8 samples/s | 68.4 steps/s
[Step=60700 Epoch=296.0] | Loss=0.00242 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=17.167 | 6554.8 samples/s | 102.4 steps/s
[Step=60750 Epoch=296.3] | Loss=0.00242 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.171 | 2096.8 samples/s | 32.8 steps/s
[Step=60800 Epoch=296.5] | Loss=0.00255 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.176 | 4483.4 samples/s | 70.1 steps/s
[Step=60850 Epoch=296.7] | Loss=0.00240 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.180 | 4471.3 samples/s | 69.9 steps/s
[Step=60900 Epoch=297.0] | Loss=0.00234 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.184 | 5962.7 samples/s | 93.2 steps/s
[Step=60950 Epoch=297.2] | Loss=0.00223 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.188 | 2150.0 samples/s | 33.6 steps/s
[Step=61000 Epoch=297.5] | Loss=0.00216 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=17.191 | 4389.3 samples/s | 68.6 steps/s
[Step=61050 Epoch=297.7] | Loss=0.00209 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=17.195 | 4466.5 samples/s | 69.8 steps/s
[Step=61100 Epoch=298.0] | Loss=0.00208 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.988 | L2-Norm(final)=17.199 | 5420.3 samples/s | 84.7 steps/s
[Step=61150 Epoch=298.2] | Loss=0.00208 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=17.202 | 2264.0 samples/s | 35.4 steps/s
[Step=61200 Epoch=298.4] | Loss=0.00206 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=17.205 | 4556.4 samples/s | 71.2 steps/s
[Step=61250 Epoch=298.7] | Loss=0.00206 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.985 | L2-Norm(final)=17.209 | 4404.1 samples/s | 68.8 steps/s
[Step=61300 Epoch=298.9] | Loss=0.00205 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.984 | L2-Norm(final)=17.212 | 4928.2 samples/s | 77.0 steps/s
[Step=61350 Epoch=299.2] | Loss=0.00197 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.982 | L2-Norm(final)=17.215 | 2316.9 samples/s | 36.2 steps/s
[Step=61400 Epoch=299.4] | Loss=0.00195 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.981 | L2-Norm(final)=17.218 | 4490.1 samples/s | 70.2 steps/s
[Step=61450 Epoch=299.7] | Loss=0.00200 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.979 | L2-Norm(final)=17.221 | 4415.4 samples/s | 69.0 steps/s
[Step=61500 Epoch=299.9] | Loss=0.00201 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=17.224 | 4631.9 samples/s | 72.4 steps/s
[Step=61550 Epoch=300.2] | Loss=0.00197 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.976 | L2-Norm(final)=17.227 | 2393.3 samples/s | 37.4 steps/s
[Step=61600 Epoch=300.4] | Loss=0.00193 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=17.230 | 4502.8 samples/s | 70.4 steps/s
[Step=61650 Epoch=300.6] | Loss=0.00190 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=17.233 | 4440.1 samples/s | 69.4 steps/s
[Step=61700 Epoch=300.9] | Loss=0.00189 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=17.236 | 4452.3 samples/s | 69.6 steps/s
[Step=61750 Epoch=301.1] | Loss=0.00189 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=17.238 | 2394.7 samples/s | 37.4 steps/s
[Step=61800 Epoch=301.4] | Loss=0.00187 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=17.241 | 4621.5 samples/s | 72.2 steps/s
[Step=61850 Epoch=301.6] | Loss=0.00184 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=17.244 | 4324.5 samples/s | 67.6 steps/s
[Step=61900 Epoch=301.9] | Loss=0.00182 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.963 | L2-Norm(final)=17.247 | 4472.4 samples/s | 69.9 steps/s
[Step=61950 Epoch=302.1] | Loss=0.00183 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=17.250 | 2461.8 samples/s | 38.5 steps/s
[Step=62000 Epoch=302.3] | Loss=0.00179 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=17.252 | 4442.7 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step62000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=294.2] | Loss=0.00168 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.729 | L2-Norm(final)=17.087 | 4810.8 samples/s | 75.2 steps/s
[Step=60050 Epoch=294.5] | Loss=0.00337 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.730 | L2-Norm(final)=17.089 | 4627.3 samples/s | 72.3 steps/s
[Step=60100 Epoch=294.7] | Loss=0.00333 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.731 | L2-Norm(final)=17.094 | 5025.3 samples/s | 78.5 steps/s
[Step=60150 Epoch=295.0] | Loss=0.00313 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.733 | L2-Norm(final)=17.100 | 5059.0 samples/s | 79.0 steps/s
[Step=60200 Epoch=295.2] | Loss=0.00288 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.733 | L2-Norm(final)=17.106 | 7933.0 samples/s | 124.0 steps/s
[Step=60250 Epoch=295.5] | Loss=0.00283 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.734 | L2-Norm(final)=17.111 | 2190.1 samples/s | 34.2 steps/s
[Step=60300 Epoch=295.7] | Loss=0.00274 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=17.117 | 5010.8 samples/s | 78.3 steps/s
[Step=60350 Epoch=295.9] | Loss=0.00267 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=17.123 | 5096.7 samples/s | 79.6 steps/s
[Step=60400 Epoch=296.2] | Loss=0.00262 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=17.128 | 7192.1 samples/s | 112.4 steps/s
[Step=60450 Epoch=296.4] | Loss=0.00257 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=17.134 | 2202.1 samples/s | 34.4 steps/s
[Step=60500 Epoch=296.7] | Loss=0.00252 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=17.139 | 5103.7 samples/s | 79.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=296.7] | Loss=0.00071 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=17.194 | 5866.6 samples/s | 91.7 steps/s
[Step=60550 Epoch=296.9] | Loss=0.00298 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.739 | L2-Norm(final)=17.199 | 3772.0 samples/s | 58.9 steps/s
[Step=60600 Epoch=297.2] | Loss=0.00265 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.740 | L2-Norm(final)=17.204 | 4578.4 samples/s | 71.5 steps/s
[Step=60650 Epoch=297.4] | Loss=0.00251 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.741 | L2-Norm(final)=17.210 | 4409.4 samples/s | 68.9 steps/s
[Step=60700 Epoch=297.7] | Loss=0.00251 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.742 | L2-Norm(final)=17.215 | 6710.5 samples/s | 104.9 steps/s
[Step=60750 Epoch=297.9] | Loss=0.00238 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=17.220 | 2066.1 samples/s | 32.3 steps/s
[Step=60800 Epoch=298.2] | Loss=0.00253 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.743 | L2-Norm(final)=17.224 | 4500.3 samples/s | 70.3 steps/s
[Step=60850 Epoch=298.4] | Loss=0.00245 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=17.228 | 4472.6 samples/s | 69.9 steps/s
[Step=60900 Epoch=298.6] | Loss=0.00246 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=17.232 | 6241.8 samples/s | 97.5 steps/s
[Step=60950 Epoch=298.9] | Loss=0.00237 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=17.236 | 2131.7 samples/s | 33.3 steps/s
[Step=61000 Epoch=299.1] | Loss=0.00236 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.742 | L2-Norm(final)=17.240 | 4463.4 samples/s | 69.7 steps/s
[Step=61050 Epoch=299.4] | Loss=0.00230 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.742 | L2-Norm(final)=17.244 | 4472.5 samples/s | 69.9 steps/s
[Step=61100 Epoch=299.6] | Loss=0.00221 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.741 | L2-Norm(final)=17.247 | 5753.0 samples/s | 89.9 steps/s
[Step=61150 Epoch=299.9] | Loss=0.00218 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.740 | L2-Norm(final)=17.251 | 2172.9 samples/s | 34.0 steps/s
[Step=61200 Epoch=300.1] | Loss=0.00212 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.739 | L2-Norm(final)=17.254 | 4468.4 samples/s | 69.8 steps/s
[Step=61250 Epoch=300.4] | Loss=0.00212 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.738 | L2-Norm(final)=17.257 | 4495.1 samples/s | 70.2 steps/s
[Step=61300 Epoch=300.6] | Loss=0.00206 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=17.261 | 5536.2 samples/s | 86.5 steps/s
[Step=61350 Epoch=300.9] | Loss=0.00206 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=17.264 | 2204.2 samples/s | 34.4 steps/s
[Step=61400 Epoch=301.1] | Loss=0.00205 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.734 | L2-Norm(final)=17.267 | 4402.7 samples/s | 68.8 steps/s
[Step=61450 Epoch=301.3] | Loss=0.00202 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=17.270 | 4431.5 samples/s | 69.2 steps/s
[Step=61500 Epoch=301.6] | Loss=0.00199 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.731 | L2-Norm(final)=17.273 | 5234.8 samples/s | 81.8 steps/s
[Step=61550 Epoch=301.8] | Loss=0.00195 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.729 | L2-Norm(final)=17.276 | 2276.7 samples/s | 35.6 steps/s
[Step=61600 Epoch=302.1] | Loss=0.00192 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=17.279 | 4515.5 samples/s | 70.6 steps/s
[Step=61650 Epoch=302.3] | Loss=0.00190 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.726 | L2-Norm(final)=17.282 | 4443.0 samples/s | 69.4 steps/s
[Step=61700 Epoch=302.6] | Loss=0.00194 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=17.285 | 4931.7 samples/s | 77.1 steps/s
[Step=61750 Epoch=302.8] | Loss=0.00195 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.722 | L2-Norm(final)=17.288 | 2335.6 samples/s | 36.5 steps/s
[Step=61800 Epoch=303.1] | Loss=0.00192 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=17.291 | 4425.7 samples/s | 69.2 steps/s
[Step=61850 Epoch=303.3] | Loss=0.00190 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=17.294 | 4528.5 samples/s | 70.8 steps/s
[Step=61900 Epoch=303.5] | Loss=0.00188 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.716 | L2-Norm(final)=17.297 | 4614.9 samples/s | 72.1 steps/s
[Step=61950 Epoch=303.8] | Loss=0.00188 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.714 | L2-Norm(final)=17.300 | 2432.3 samples/s | 38.0 steps/s
[Step=62000 Epoch=304.0] | Loss=0.00187 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=17.303 | 4428.1 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step62000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=568.6] | Loss=0.00043 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.299 | L2-Norm(final)=8.635 | 5351.7 samples/s | 83.6 steps/s
[Step=60050 Epoch=569.0] | Loss=0.00010 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.305 | L2-Norm(final)=8.654 | 4237.9 samples/s | 66.2 steps/s
[Step=60100 Epoch=569.5] | Loss=0.00008 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=8.673 | 7165.7 samples/s | 112.0 steps/s
[Step=60150 Epoch=570.0] | Loss=0.00007 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=8.686 | 2151.1 samples/s | 33.6 steps/s
[Step=60200 Epoch=570.4] | Loss=0.00006 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.327 | L2-Norm(final)=8.698 | 6428.5 samples/s | 100.4 steps/s
[Step=60250 Epoch=570.9] | Loss=0.00006 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.331 | L2-Norm(final)=8.708 | 2188.9 samples/s | 34.2 steps/s
[Step=60300 Epoch=571.4] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=8.718 | 5764.2 samples/s | 90.1 steps/s
[Step=60350 Epoch=571.9] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.338 | L2-Norm(final)=8.727 | 2215.4 samples/s | 34.6 steps/s
[Step=60400 Epoch=572.3] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.341 | L2-Norm(final)=8.735 | 5161.0 samples/s | 80.6 steps/s
[Step=60450 Epoch=572.8] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.343 | L2-Norm(final)=8.743 | 2384.8 samples/s | 37.3 steps/s
[Step=60500 Epoch=573.3] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.345 | L2-Norm(final)=8.750 | 4875.3 samples/s | 76.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=573.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.367 | L2-Norm(final)=8.825 | 5364.8 samples/s | 83.8 steps/s
[Step=60550 Epoch=573.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.348 | L2-Norm(final)=8.830 | 3742.4 samples/s | 58.5 steps/s
[Step=60600 Epoch=574.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.323 | L2-Norm(final)=8.833 | 6213.1 samples/s | 97.1 steps/s
[Step=60650 Epoch=574.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=8.835 | 2013.9 samples/s | 31.5 steps/s
[Step=60700 Epoch=575.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=8.837 | 5475.0 samples/s | 85.5 steps/s
[Step=60750 Epoch=575.7] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.237 | L2-Norm(final)=8.838 | 2081.6 samples/s | 32.5 steps/s
[Step=60800 Epoch=576.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.206 | L2-Norm(final)=8.839 | 5114.2 samples/s | 79.9 steps/s
[Step=60850 Epoch=576.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.175 | L2-Norm(final)=8.840 | 2175.8 samples/s | 34.0 steps/s
[Step=60900 Epoch=577.1] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.144 | L2-Norm(final)=8.841 | 4717.3 samples/s | 73.7 steps/s
[Step=60950 Epoch=577.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=8.841 | 2263.4 samples/s | 35.4 steps/s
[Step=61000 Epoch=578.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.082 | L2-Norm(final)=8.842 | 4309.2 samples/s | 67.3 steps/s
[Step=61050 Epoch=578.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.050 | L2-Norm(final)=8.843 | 2332.4 samples/s | 36.4 steps/s
[Step=61100 Epoch=579.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.019 | L2-Norm(final)=8.844 | 4243.7 samples/s | 66.3 steps/s
[Step=61150 Epoch=579.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.988 | L2-Norm(final)=8.844 | 2388.4 samples/s | 37.3 steps/s
[Step=61200 Epoch=579.9] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.956 | L2-Norm(final)=8.845 | 4249.7 samples/s | 66.4 steps/s
[Step=61250 Epoch=580.4] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.925 | L2-Norm(final)=8.846 | 2342.2 samples/s | 36.6 steps/s
[Step=61300 Epoch=580.9] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.893 | L2-Norm(final)=8.847 | 4211.2 samples/s | 65.8 steps/s
[Step=61350 Epoch=581.3] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=8.848 | 2435.7 samples/s | 38.1 steps/s
[Step=61400 Epoch=581.8] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=8.849 | 4108.2 samples/s | 64.2 steps/s
[Step=61450 Epoch=582.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.799 | L2-Norm(final)=8.850 | 6304.3 samples/s | 98.5 steps/s
[Step=61500 Epoch=582.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.768 | L2-Norm(final)=8.851 | 2007.0 samples/s | 31.4 steps/s
[Step=61550 Epoch=583.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.736 | L2-Norm(final)=8.852 | 5720.9 samples/s | 89.4 steps/s
[Step=61600 Epoch=583.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.705 | L2-Norm(final)=8.853 | 2055.3 samples/s | 32.1 steps/s
[Step=61650 Epoch=584.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.673 | L2-Norm(final)=8.854 | 5251.5 samples/s | 82.1 steps/s
[Step=61700 Epoch=584.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.642 | L2-Norm(final)=8.855 | 2139.4 samples/s | 33.4 steps/s
[Step=61750 Epoch=585.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.611 | L2-Norm(final)=8.856 | 4855.4 samples/s | 75.9 steps/s
[Step=61800 Epoch=585.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.579 | L2-Norm(final)=8.858 | 2234.5 samples/s | 34.9 steps/s
[Step=61850 Epoch=586.1] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.548 | L2-Norm(final)=8.859 | 4382.5 samples/s | 68.5 steps/s
[Step=61900 Epoch=586.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.517 | L2-Norm(final)=8.860 | 2323.0 samples/s | 36.3 steps/s
[Step=61950 Epoch=587.0] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.485 | L2-Norm(final)=8.861 | 4378.0 samples/s | 68.4 steps/s
[Step=62000 Epoch=587.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.454 | L2-Norm(final)=8.863 | 2363.4 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step62000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=570.8] | Loss=0.00007 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.340 | L2-Norm(final)=9.573 | 4769.5 samples/s | 74.5 steps/s
[Step=60050 Epoch=571.2] | Loss=0.00008 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.344 | L2-Norm(final)=9.579 | 4283.6 samples/s | 66.9 steps/s
[Step=60100 Epoch=571.7] | Loss=0.00007 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.348 | L2-Norm(final)=9.586 | 7448.0 samples/s | 116.4 steps/s
[Step=60150 Epoch=572.2] | Loss=0.00006 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.351 | L2-Norm(final)=9.592 | 2094.0 samples/s | 32.7 steps/s
[Step=60200 Epoch=572.7] | Loss=0.00006 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.353 | L2-Norm(final)=9.598 | 6425.7 samples/s | 100.4 steps/s
[Step=60250 Epoch=573.1] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=9.604 | 2198.7 samples/s | 34.4 steps/s
[Step=60300 Epoch=573.6] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.358 | L2-Norm(final)=9.610 | 5958.0 samples/s | 93.1 steps/s
[Step=60350 Epoch=574.1] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.361 | L2-Norm(final)=9.615 | 2317.8 samples/s | 36.2 steps/s
[Step=60400 Epoch=574.6] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.363 | L2-Norm(final)=9.620 | 5139.5 samples/s | 80.3 steps/s
[Step=60450 Epoch=575.0] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.365 | L2-Norm(final)=9.626 | 2345.7 samples/s | 36.7 steps/s
[Step=60500 Epoch=575.5] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.367 | L2-Norm(final)=9.631 | 4927.6 samples/s | 77.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=575.5] | Loss=0.00006 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=9.684 | 5006.2 samples/s | 78.2 steps/s
[Step=60550 Epoch=576.0] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.385 | L2-Norm(final)=9.689 | 3980.2 samples/s | 62.2 steps/s
[Step=60600 Epoch=576.5] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.383 | L2-Norm(final)=9.692 | 6147.7 samples/s | 96.1 steps/s
[Step=60650 Epoch=576.9] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.379 | L2-Norm(final)=9.695 | 2017.4 samples/s | 31.5 steps/s
[Step=60700 Epoch=577.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.375 | L2-Norm(final)=9.697 | 5399.8 samples/s | 84.4 steps/s
[Step=60750 Epoch=577.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.371 | L2-Norm(final)=9.698 | 2057.2 samples/s | 32.1 steps/s
[Step=60800 Epoch=578.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.366 | L2-Norm(final)=9.700 | 5151.3 samples/s | 80.5 steps/s
[Step=60850 Epoch=578.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.361 | L2-Norm(final)=9.701 | 2170.7 samples/s | 33.9 steps/s
[Step=60900 Epoch=579.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=9.702 | 4684.6 samples/s | 73.2 steps/s
[Step=60950 Epoch=579.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=9.704 | 2252.5 samples/s | 35.2 steps/s
[Step=61000 Epoch=580.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.345 | L2-Norm(final)=9.705 | 4321.0 samples/s | 67.5 steps/s
[Step=61050 Epoch=580.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.339 | L2-Norm(final)=9.706 | 2356.3 samples/s | 36.8 steps/s
[Step=61100 Epoch=581.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=9.707 | 4236.4 samples/s | 66.2 steps/s
[Step=61150 Epoch=581.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.328 | L2-Norm(final)=9.708 | 2382.8 samples/s | 37.2 steps/s
[Step=61200 Epoch=582.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=9.709 | 4207.8 samples/s | 65.7 steps/s
[Step=61250 Epoch=582.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=9.710 | 2383.8 samples/s | 37.2 steps/s
[Step=61300 Epoch=583.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.310 | L2-Norm(final)=9.711 | 4315.0 samples/s | 67.4 steps/s
[Step=61350 Epoch=583.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=9.712 | 2394.7 samples/s | 37.4 steps/s
[Step=61400 Epoch=584.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=9.713 | 4122.7 samples/s | 64.4 steps/s
[Step=61450 Epoch=584.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.714 | 6410.2 samples/s | 100.2 steps/s
[Step=61500 Epoch=585.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.285 | L2-Norm(final)=9.715 | 1984.4 samples/s | 31.0 steps/s
[Step=61550 Epoch=585.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.278 | L2-Norm(final)=9.716 | 5890.9 samples/s | 92.0 steps/s
[Step=61600 Epoch=586.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.272 | L2-Norm(final)=9.716 | 2033.3 samples/s | 31.8 steps/s
[Step=61650 Epoch=586.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.265 | L2-Norm(final)=9.717 | 5339.9 samples/s | 83.4 steps/s
[Step=61700 Epoch=586.9] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.258 | L2-Norm(final)=9.718 | 2179.8 samples/s | 34.1 steps/s
[Step=61750 Epoch=587.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.252 | L2-Norm(final)=9.719 | 4756.2 samples/s | 74.3 steps/s
[Step=61800 Epoch=587.9] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.245 | L2-Norm(final)=9.720 | 2218.0 samples/s | 34.7 steps/s
[Step=61850 Epoch=588.3] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.238 | L2-Norm(final)=9.721 | 4448.6 samples/s | 69.5 steps/s
[Step=61900 Epoch=588.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.230 | L2-Norm(final)=9.722 | 2269.0 samples/s | 35.5 steps/s
[Step=61950 Epoch=589.3] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.223 | L2-Norm(final)=9.723 | 4239.9 samples/s | 66.2 steps/s
[Step=62000 Epoch=589.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=9.724 | 2409.8 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step62000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=573.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.398 | L2-Norm(final)=9.284 | 5313.2 samples/s | 83.0 steps/s
[Step=60050 Epoch=573.4] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.398 | L2-Norm(final)=9.285 | 4057.4 samples/s | 63.4 steps/s
[Step=60100 Epoch=573.9] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.398 | L2-Norm(final)=9.286 | 7587.9 samples/s | 118.6 steps/s
[Step=60150 Epoch=574.4] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=9.287 | 2079.9 samples/s | 32.5 steps/s
[Step=60200 Epoch=574.9] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=9.288 | 6867.2 samples/s | 107.3 steps/s
[Step=60250 Epoch=575.4] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=9.289 | 2196.0 samples/s | 34.3 steps/s
[Step=60300 Epoch=575.8] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=9.290 | 6094.7 samples/s | 95.2 steps/s
[Step=60350 Epoch=576.3] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=9.291 | 2235.3 samples/s | 34.9 steps/s
[Step=60400 Epoch=576.8] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=9.292 | 5750.7 samples/s | 89.9 steps/s
[Step=60450 Epoch=577.3] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=9.293 | 2317.2 samples/s | 36.2 steps/s
[Step=60500 Epoch=577.7] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=9.294 | 5232.3 samples/s | 81.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=577.7] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.402 | L2-Norm(final)=9.303 | 5426.1 samples/s | 84.8 steps/s
[Step=60550 Epoch=578.2] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.401 | L2-Norm(final)=9.304 | 3914.5 samples/s | 61.2 steps/s
[Step=60600 Epoch=578.7] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.400 | L2-Norm(final)=9.305 | 6129.3 samples/s | 95.8 steps/s
[Step=60650 Epoch=579.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=9.306 | 2042.3 samples/s | 31.9 steps/s
[Step=60700 Epoch=579.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.398 | L2-Norm(final)=9.306 | 5608.3 samples/s | 87.6 steps/s
[Step=60750 Epoch=580.1] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.397 | L2-Norm(final)=9.307 | 2031.0 samples/s | 31.7 steps/s
[Step=60800 Epoch=580.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.396 | L2-Norm(final)=9.308 | 5348.8 samples/s | 83.6 steps/s
[Step=60850 Epoch=581.1] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.395 | L2-Norm(final)=9.308 | 2105.9 samples/s | 32.9 steps/s
[Step=60900 Epoch=581.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.393 | L2-Norm(final)=9.309 | 4992.4 samples/s | 78.0 steps/s
[Step=60950 Epoch=582.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.392 | L2-Norm(final)=9.309 | 2137.3 samples/s | 33.4 steps/s
[Step=61000 Epoch=582.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.391 | L2-Norm(final)=9.310 | 4438.8 samples/s | 69.4 steps/s
[Step=61050 Epoch=583.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=9.310 | 2235.4 samples/s | 34.9 steps/s
[Step=61100 Epoch=583.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=9.310 | 4332.8 samples/s | 67.7 steps/s
[Step=61150 Epoch=583.9] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.386 | L2-Norm(final)=9.311 | 2355.8 samples/s | 36.8 steps/s
[Step=61200 Epoch=584.4] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.384 | L2-Norm(final)=9.311 | 4364.1 samples/s | 68.2 steps/s
[Step=61250 Epoch=584.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.382 | L2-Norm(final)=9.312 | 2323.6 samples/s | 36.3 steps/s
[Step=61300 Epoch=585.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.381 | L2-Norm(final)=9.312 | 4239.2 samples/s | 66.2 steps/s
[Step=61350 Epoch=585.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.379 | L2-Norm(final)=9.312 | 2350.1 samples/s | 36.7 steps/s
[Step=61400 Epoch=586.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.377 | L2-Norm(final)=9.313 | 4269.1 samples/s | 66.7 steps/s
[Step=61450 Epoch=586.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.375 | L2-Norm(final)=9.313 | 2360.5 samples/s | 36.9 steps/s
[Step=61500 Epoch=587.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.373 | L2-Norm(final)=9.313 | 4226.4 samples/s | 66.0 steps/s
[Step=61550 Epoch=587.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.371 | L2-Norm(final)=9.314 | 6961.0 samples/s | 108.8 steps/s
[Step=61600 Epoch=588.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.369 | L2-Norm(final)=9.314 | 1921.8 samples/s | 30.0 steps/s
[Step=61650 Epoch=588.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.367 | L2-Norm(final)=9.314 | 6313.8 samples/s | 98.7 steps/s
[Step=61700 Epoch=589.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.365 | L2-Norm(final)=9.315 | 2011.5 samples/s | 31.4 steps/s
[Step=61750 Epoch=589.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.363 | L2-Norm(final)=9.315 | 5741.3 samples/s | 89.7 steps/s
[Step=61800 Epoch=590.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.360 | L2-Norm(final)=9.315 | 2066.0 samples/s | 32.3 steps/s
[Step=61850 Epoch=590.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.358 | L2-Norm(final)=9.316 | 5291.7 samples/s | 82.7 steps/s
[Step=61900 Epoch=591.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=9.316 | 2083.5 samples/s | 32.6 steps/s
[Step=61950 Epoch=591.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.354 | L2-Norm(final)=9.316 | 4961.2 samples/s | 77.5 steps/s
[Step=62000 Epoch=592.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.351 | L2-Norm(final)=9.317 | 2191.9 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step62000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=565.4] | Loss=0.00012 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=9.247 | 5342.9 samples/s | 83.5 steps/s
[Step=60050 Epoch=565.8] | Loss=0.00020 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.397 | L2-Norm(final)=9.259 | 4039.0 samples/s | 63.1 steps/s
[Step=60100 Epoch=566.3] | Loss=0.00018 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.410 | L2-Norm(final)=9.275 | 7364.0 samples/s | 115.1 steps/s
[Step=60150 Epoch=566.8] | Loss=0.00014 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.418 | L2-Norm(final)=9.286 | 2130.9 samples/s | 33.3 steps/s
[Step=60200 Epoch=567.3] | Loss=0.00013 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.423 | L2-Norm(final)=9.295 | 6304.7 samples/s | 98.5 steps/s
[Step=60250 Epoch=567.7] | Loss=0.00011 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.428 | L2-Norm(final)=9.303 | 2245.8 samples/s | 35.1 steps/s
[Step=60300 Epoch=568.2] | Loss=0.00010 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.431 | L2-Norm(final)=9.310 | 5657.4 samples/s | 88.4 steps/s
[Step=60350 Epoch=568.7] | Loss=0.00009 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.434 | L2-Norm(final)=9.316 | 2333.1 samples/s | 36.5 steps/s
[Step=60400 Epoch=569.1] | Loss=0.00009 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.437 | L2-Norm(final)=9.322 | 5074.7 samples/s | 79.3 steps/s
[Step=60450 Epoch=569.6] | Loss=0.00008 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.440 | L2-Norm(final)=9.328 | 2452.4 samples/s | 38.3 steps/s
[Step=60500 Epoch=570.1] | Loss=0.00008 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.442 | L2-Norm(final)=9.333 | 4728.4 samples/s | 73.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=570.1] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.464 | L2-Norm(final)=9.386 | 5440.0 samples/s | 85.0 steps/s
[Step=60550 Epoch=570.6] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.461 | L2-Norm(final)=9.389 | 3717.4 samples/s | 58.1 steps/s
[Step=60600 Epoch=571.0] | Loss=0.00029 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=9.397 | 6157.0 samples/s | 96.2 steps/s
[Step=60650 Epoch=571.5] | Loss=0.00033 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.484 | L2-Norm(final)=9.403 | 2028.2 samples/s | 31.7 steps/s
[Step=60700 Epoch=572.0] | Loss=0.00026 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.493 | L2-Norm(final)=9.408 | 5473.7 samples/s | 85.5 steps/s
[Step=60750 Epoch=572.4] | Loss=0.00021 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=9.411 | 2132.6 samples/s | 33.3 steps/s
[Step=60800 Epoch=572.9] | Loss=0.00018 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.500 | L2-Norm(final)=9.414 | 4834.2 samples/s | 75.5 steps/s
[Step=60850 Epoch=573.4] | Loss=0.00015 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.502 | L2-Norm(final)=9.416 | 2192.2 samples/s | 34.3 steps/s
[Step=60900 Epoch=573.9] | Loss=0.00014 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.418 | 4486.9 samples/s | 70.1 steps/s
[Step=60950 Epoch=574.3] | Loss=0.00012 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.419 | 2312.7 samples/s | 36.1 steps/s
[Step=61000 Epoch=574.8] | Loss=0.00011 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.504 | L2-Norm(final)=9.420 | 4213.5 samples/s | 65.8 steps/s
[Step=61050 Epoch=575.3] | Loss=0.00010 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.421 | 2365.7 samples/s | 37.0 steps/s
[Step=61100 Epoch=575.7] | Loss=0.00009 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.422 | 4122.6 samples/s | 64.4 steps/s
[Step=61150 Epoch=576.2] | Loss=0.00009 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.503 | L2-Norm(final)=9.423 | 2438.4 samples/s | 38.1 steps/s
[Step=61200 Epoch=576.7] | Loss=0.00008 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.502 | L2-Norm(final)=9.423 | 4176.0 samples/s | 65.2 steps/s
[Step=61250 Epoch=577.1] | Loss=0.00008 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.501 | L2-Norm(final)=9.424 | 2676.4 samples/s | 41.8 steps/s
[Step=61300 Epoch=577.6] | Loss=0.00007 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.500 | L2-Norm(final)=9.425 | 3811.8 samples/s | 59.6 steps/s
[Step=61350 Epoch=578.1] | Loss=0.00007 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.499 | L2-Norm(final)=9.425 | 6099.5 samples/s | 95.3 steps/s
[Step=61400 Epoch=578.6] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.498 | L2-Norm(final)=9.426 | 1996.0 samples/s | 31.2 steps/s
[Step=61450 Epoch=579.0] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=9.427 | 5556.0 samples/s | 86.8 steps/s
[Step=61500 Epoch=579.5] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.496 | L2-Norm(final)=9.427 | 2081.6 samples/s | 32.5 steps/s
[Step=61550 Epoch=580.0] | Loss=0.00006 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.495 | L2-Norm(final)=9.428 | 4971.5 samples/s | 77.7 steps/s
[Step=61600 Epoch=580.4] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.494 | L2-Norm(final)=9.428 | 2180.4 samples/s | 34.1 steps/s
[Step=61650 Epoch=580.9] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.492 | L2-Norm(final)=9.429 | 4522.8 samples/s | 70.7 steps/s
[Step=61700 Epoch=581.4] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.491 | L2-Norm(final)=9.429 | 2295.6 samples/s | 35.9 steps/s
[Step=61750 Epoch=581.9] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.490 | L2-Norm(final)=9.430 | 4326.9 samples/s | 67.6 steps/s
[Step=61800 Epoch=582.3] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.488 | L2-Norm(final)=9.430 | 2349.4 samples/s | 36.7 steps/s
[Step=61850 Epoch=582.8] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.487 | L2-Norm(final)=9.430 | 4311.7 samples/s | 67.4 steps/s
[Step=61900 Epoch=583.3] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.485 | L2-Norm(final)=9.431 | 2328.9 samples/s | 36.4 steps/s
[Step=61950 Epoch=583.7] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.484 | L2-Norm(final)=9.431 | 4212.9 samples/s | 65.8 steps/s
[Step=62000 Epoch=584.2] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.482 | L2-Norm(final)=9.432 | 2529.4 samples/s | 39.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step62000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=571.9] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.463 | L2-Norm(final)=9.723 | 5037.8 samples/s | 78.7 steps/s
[Step=60050 Epoch=572.3] | Loss=0.00007 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.467 | L2-Norm(final)=9.726 | 4192.9 samples/s | 65.5 steps/s
[Step=60100 Epoch=572.8] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.469 | L2-Norm(final)=9.728 | 7438.2 samples/s | 116.2 steps/s
[Step=60150 Epoch=573.3] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.470 | L2-Norm(final)=9.730 | 2117.0 samples/s | 33.1 steps/s
[Step=60200 Epoch=573.8] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.471 | L2-Norm(final)=9.732 | 6649.3 samples/s | 103.9 steps/s
[Step=60250 Epoch=574.2] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=9.734 | 2166.9 samples/s | 33.9 steps/s
[Step=60300 Epoch=574.7] | Loss=0.00005 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.473 | L2-Norm(final)=9.737 | 6141.4 samples/s | 96.0 steps/s
[Step=60350 Epoch=575.2] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.474 | L2-Norm(final)=9.739 | 2259.3 samples/s | 35.3 steps/s
[Step=60400 Epoch=575.7] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.475 | L2-Norm(final)=9.741 | 5723.2 samples/s | 89.4 steps/s
[Step=60450 Epoch=576.1] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.476 | L2-Norm(final)=9.743 | 2340.3 samples/s | 36.6 steps/s
[Step=60500 Epoch=576.6] | Loss=0.00004 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.477 | L2-Norm(final)=9.745 | 5144.1 samples/s | 80.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=576.6] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.487 | L2-Norm(final)=9.767 | 5789.4 samples/s | 90.5 steps/s
[Step=60550 Epoch=577.1] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.486 | L2-Norm(final)=9.769 | 3524.9 samples/s | 55.1 steps/s
[Step=60600 Epoch=577.6] | Loss=0.00003 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.486 | L2-Norm(final)=9.771 | 6304.7 samples/s | 98.5 steps/s
[Step=60650 Epoch=578.0] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.484 | L2-Norm(final)=9.772 | 2017.9 samples/s | 31.5 steps/s
[Step=60700 Epoch=578.5] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.483 | L2-Norm(final)=9.773 | 5721.7 samples/s | 89.4 steps/s
[Step=60750 Epoch=579.0] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.481 | L2-Norm(final)=9.774 | 2039.7 samples/s | 31.9 steps/s
[Step=60800 Epoch=579.5] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.479 | L2-Norm(final)=9.775 | 5371.1 samples/s | 83.9 steps/s
[Step=60850 Epoch=580.0] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.477 | L2-Norm(final)=9.776 | 2152.8 samples/s | 33.6 steps/s
[Step=60900 Epoch=580.4] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.474 | L2-Norm(final)=9.777 | 4924.3 samples/s | 76.9 steps/s
[Step=60950 Epoch=580.9] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=9.778 | 2258.9 samples/s | 35.3 steps/s
[Step=61000 Epoch=581.4] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.470 | L2-Norm(final)=9.778 | 4495.1 samples/s | 70.2 steps/s
[Step=61050 Epoch=581.9] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.467 | L2-Norm(final)=9.779 | 2267.5 samples/s | 35.4 steps/s
[Step=61100 Epoch=582.3] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.465 | L2-Norm(final)=9.780 | 4349.8 samples/s | 68.0 steps/s
[Step=61150 Epoch=582.8] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.462 | L2-Norm(final)=9.780 | 2370.2 samples/s | 37.0 steps/s
[Step=61200 Epoch=583.3] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.460 | L2-Norm(final)=9.781 | 4201.1 samples/s | 65.6 steps/s
[Step=61250 Epoch=583.8] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.457 | L2-Norm(final)=9.781 | 2400.8 samples/s | 37.5 steps/s
[Step=61300 Epoch=584.2] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.454 | L2-Norm(final)=9.782 | 4223.8 samples/s | 66.0 steps/s
[Step=61350 Epoch=584.7] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.452 | L2-Norm(final)=9.783 | 2335.3 samples/s | 36.5 steps/s
[Step=61400 Epoch=585.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.449 | L2-Norm(final)=9.783 | 4379.6 samples/s | 68.4 steps/s
[Step=61450 Epoch=585.7] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.446 | L2-Norm(final)=9.784 | 2361.4 samples/s | 36.9 steps/s
[Step=61500 Epoch=586.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.443 | L2-Norm(final)=9.784 | 4371.1 samples/s | 68.3 steps/s
[Step=61550 Epoch=586.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.440 | L2-Norm(final)=9.785 | 6763.3 samples/s | 105.7 steps/s
[Step=61600 Epoch=587.1] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.437 | L2-Norm(final)=9.785 | 1932.4 samples/s | 30.2 steps/s
[Step=61650 Epoch=587.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.434 | L2-Norm(final)=9.786 | 6277.7 samples/s | 98.1 steps/s
[Step=61700 Epoch=588.1] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.431 | L2-Norm(final)=9.786 | 2010.1 samples/s | 31.4 steps/s
[Step=61750 Epoch=588.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.428 | L2-Norm(final)=9.787 | 5782.8 samples/s | 90.4 steps/s
[Step=61800 Epoch=589.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.424 | L2-Norm(final)=9.787 | 2078.5 samples/s | 32.5 steps/s
[Step=61850 Epoch=589.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.421 | L2-Norm(final)=9.788 | 5264.6 samples/s | 82.3 steps/s
[Step=61900 Epoch=590.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.418 | L2-Norm(final)=9.788 | 2114.8 samples/s | 33.0 steps/s
[Step=61950 Epoch=590.4] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.414 | L2-Norm(final)=9.789 | 4993.5 samples/s | 78.0 steps/s
[Step=62000 Epoch=590.9] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.411 | L2-Norm(final)=9.789 | 2217.5 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10750 | acc=0.9587 | tpr=0.9755 | fpr=0.0778 | 4725.2 samples/s | 18.5 steps/s
Avg test loss: 0.11183, Avg test acc: 0.95737, Avg tpr: 0.97418, Avg fpr: 0.07961, total FA: 621

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11578 | acc=0.9585 | tpr=0.9762 | fpr=0.0798 | 4771.0 samples/s | 18.6 steps/s
Avg test loss: 0.11590, Avg test acc: 0.95829, Avg tpr: 0.97523, Avg fpr: 0.07896, total FA: 616

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10593 | acc=0.9597 | tpr=0.9724 | fpr=0.0679 | 4705.0 samples/s | 18.4 steps/s
Avg test loss: 0.10872, Avg test acc: 0.95845, Avg tpr: 0.97057, Avg fpr: 0.06820, total FA: 532

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10038 | acc=0.9610 | tpr=0.9711 | fpr=0.0610 | 4784.8 samples/s | 18.7 steps/s
Avg test loss: 0.10665, Avg test acc: 0.95961, Avg tpr: 0.97162, Avg fpr: 0.06679, total FA: 521

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10761 | acc=0.9600 | tpr=0.9734 | fpr=0.0691 | 4918.9 samples/s | 19.2 steps/s
Avg test loss: 0.11431, Avg test acc: 0.95901, Avg tpr: 0.97255, Avg fpr: 0.07076, total FA: 552

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.07623 | acc=0.3025 | tpr=0.0059 | fpr=0.0535 | 4965.3 samples/s | 19.4 steps/s
Avg test loss: 5.08486, Avg test acc: 0.30175, Avg tpr: 0.00746, Avg fpr: 0.05102, total FA: 398

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.80484 | acc=0.2959 | tpr=0.0060 | fpr=0.0746 | 4752.0 samples/s | 18.6 steps/s
Avg test loss: 4.81709, Avg test acc: 0.29257, Avg tpr: 0.00647, Avg fpr: 0.07820, total FA: 610

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.52068 | acc=0.2821 | tpr=0.0169 | fpr=0.1420 | 4856.8 samples/s | 19.0 steps/s
Avg test loss: 5.51761, Avg test acc: 0.27971, Avg tpr: 0.01760, Avg fpr: 0.14383, total FA: 1122

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.58201 | acc=0.2970 | tpr=0.0181 | fpr=0.0976 | 4912.7 samples/s | 19.2 steps/s
Avg test loss: 5.57930, Avg test acc: 0.29470, Avg tpr: 0.01871, Avg fpr: 0.09832, total FA: 767

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.86755 | acc=0.3045 | tpr=0.0223 | fpr=0.0825 | 4879.8 samples/s | 19.1 steps/s
Avg test loss: 4.87404, Avg test acc: 0.30327, Avg tpr: 0.02296, Avg fpr: 0.08025, total FA: 626

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.15702 | acc=0.0918 | tpr=0.6106 | fpr=0.9175 | 4814.1 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.12606 | acc=0.0946 | tpr=0.6141 | fpr=0.9151 | 6881.9 samples/s | 26.9 steps/s
[Step= 150] | Loss=6.13641 | acc=0.0947 | tpr=0.6167 | fpr=0.9149 | 8085.9 samples/s | 31.6 steps/s
[Step= 200] | Loss=6.13047 | acc=0.0946 | tpr=0.6131 | fpr=0.9148 | 8038.6 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.13436 | acc=0.0956 | tpr=0.6183 | fpr=0.9139 | 7481.0 samples/s | 29.2 steps/s
[Step= 300] | Loss=6.13222 | acc=0.0958 | tpr=0.6196 | fpr=0.9138 | 5883.8 samples/s | 23.0 steps/s
[Step= 350] | Loss=6.12488 | acc=0.0959 | tpr=0.6180 | fpr=0.9135 | 8069.0 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.12023 | acc=0.0962 | tpr=0.6198 | fpr=0.9133 | 7889.5 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.12447 | acc=0.0962 | tpr=0.6144 | fpr=0.9132 | 7773.2 samples/s | 30.4 steps/s
[Step= 500] | Loss=6.12910 | acc=0.0961 | tpr=0.6097 | fpr=0.9132 | 7717.9 samples/s | 30.1 steps/s
[Step= 550] | Loss=6.13297 | acc=0.0960 | tpr=0.6088 | fpr=0.9134 | 14183.9 samples/s | 55.4 steps/s
Avg test loss: 6.13527, Avg test acc: 0.09589, Avg tpr: 0.60895, Avg fpr: 0.91344, total FA: 126829

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.86974 | acc=0.0926 | tpr=0.4867 | fpr=0.9145 | 4986.1 samples/s | 19.5 steps/s
[Step= 100] | Loss=5.85243 | acc=0.0941 | tpr=0.4989 | fpr=0.9135 | 6707.5 samples/s | 26.2 steps/s
[Step= 150] | Loss=5.85504 | acc=0.0941 | tpr=0.5173 | fpr=0.9137 | 7890.3 samples/s | 30.8 steps/s
[Step= 200] | Loss=5.84963 | acc=0.0940 | tpr=0.5060 | fpr=0.9135 | 7830.3 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.85445 | acc=0.0940 | tpr=0.5118 | fpr=0.9136 | 5778.7 samples/s | 22.6 steps/s
[Step= 300] | Loss=5.84796 | acc=0.0939 | tpr=0.5178 | fpr=0.9139 | 7691.8 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.84183 | acc=0.0941 | tpr=0.5166 | fpr=0.9136 | 8076.9 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.83676 | acc=0.0942 | tpr=0.5170 | fpr=0.9134 | 7685.0 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.84168 | acc=0.0940 | tpr=0.5146 | fpr=0.9136 | 7775.5 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.84592 | acc=0.0940 | tpr=0.5123 | fpr=0.9136 | 7755.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.85020 | acc=0.0938 | tpr=0.5097 | fpr=0.9137 | 14654.0 samples/s | 57.2 steps/s
Avg test loss: 5.85258, Avg test acc: 0.09371, Avg tpr: 0.50872, Avg fpr: 0.91383, total FA: 126884

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.12082 | acc=0.0869 | tpr=0.3584 | fpr=0.9180 | 4779.6 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.09039 | acc=0.0881 | tpr=0.3582 | fpr=0.9170 | 7044.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.10473 | acc=0.0890 | tpr=0.3689 | fpr=0.9162 | 7966.6 samples/s | 31.1 steps/s
[Step= 200] | Loss=6.10108 | acc=0.0894 | tpr=0.3672 | fpr=0.9157 | 7794.9 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.09945 | acc=0.0896 | tpr=0.3686 | fpr=0.9155 | 5877.1 samples/s | 23.0 steps/s
[Step= 300] | Loss=6.09584 | acc=0.0901 | tpr=0.3745 | fpr=0.9151 | 7699.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.09055 | acc=0.0904 | tpr=0.3688 | fpr=0.9147 | 7879.5 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.08511 | acc=0.0910 | tpr=0.3709 | fpr=0.9141 | 7818.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=6.08913 | acc=0.0912 | tpr=0.3676 | fpr=0.9138 | 8144.5 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.09180 | acc=0.0909 | tpr=0.3678 | fpr=0.9141 | 7694.2 samples/s | 30.1 steps/s
[Step= 550] | Loss=6.09566 | acc=0.0908 | tpr=0.3665 | fpr=0.9142 | 13672.7 samples/s | 53.4 steps/s
Avg test loss: 6.09694, Avg test acc: 0.09065, Avg tpr: 0.36648, Avg fpr: 0.91436, total FA: 126957

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.48537 | acc=0.1235 | tpr=0.4646 | fpr=0.8826 | 4794.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.46606 | acc=0.1236 | tpr=0.4627 | fpr=0.8828 | 7046.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.47624 | acc=0.1220 | tpr=0.4769 | fpr=0.8846 | 7801.9 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.46653 | acc=0.1215 | tpr=0.4776 | fpr=0.8849 | 8114.4 samples/s | 31.7 steps/s
[Step= 250] | Loss=5.46904 | acc=0.1223 | tpr=0.4838 | fpr=0.8843 | 6536.5 samples/s | 25.5 steps/s
[Step= 300] | Loss=5.46706 | acc=0.1223 | tpr=0.4909 | fpr=0.8845 | 7878.8 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.45804 | acc=0.1222 | tpr=0.4872 | fpr=0.8844 | 7784.0 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.45059 | acc=0.1223 | tpr=0.4825 | fpr=0.8843 | 7680.0 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.45570 | acc=0.1223 | tpr=0.4791 | fpr=0.8842 | 7267.2 samples/s | 28.4 steps/s
[Step= 500] | Loss=5.45779 | acc=0.1220 | tpr=0.4753 | fpr=0.8844 | 7746.6 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.46279 | acc=0.1219 | tpr=0.4735 | fpr=0.8845 | 13423.1 samples/s | 52.4 steps/s
Avg test loss: 5.46388, Avg test acc: 0.12175, Avg tpr: 0.47306, Avg fpr: 0.88464, total FA: 122830

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.93370 | acc=0.1109 | tpr=0.5177 | fpr=0.8964 | 4800.3 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.91067 | acc=0.1133 | tpr=0.5160 | fpr=0.8942 | 7107.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=5.91032 | acc=0.1143 | tpr=0.5245 | fpr=0.8932 | 7526.8 samples/s | 29.4 steps/s
[Step= 200] | Loss=5.90653 | acc=0.1140 | tpr=0.5060 | fpr=0.8931 | 7598.3 samples/s | 29.7 steps/s
[Step= 250] | Loss=5.91437 | acc=0.1148 | tpr=0.5214 | fpr=0.8927 | 7490.5 samples/s | 29.3 steps/s
[Step= 300] | Loss=5.91378 | acc=0.1147 | tpr=0.5236 | fpr=0.8928 | 8078.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.90517 | acc=0.1147 | tpr=0.5191 | fpr=0.8926 | 7902.5 samples/s | 30.9 steps/s
[Step= 400] | Loss=5.90104 | acc=0.1154 | tpr=0.5230 | fpr=0.8920 | 6389.4 samples/s | 25.0 steps/s
[Step= 450] | Loss=5.90497 | acc=0.1159 | tpr=0.5239 | fpr=0.8916 | 7528.2 samples/s | 29.4 steps/s
[Step= 500] | Loss=5.90755 | acc=0.1155 | tpr=0.5189 | fpr=0.8917 | 7932.5 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.91133 | acc=0.1153 | tpr=0.5185 | fpr=0.8920 | 13650.9 samples/s | 53.3 steps/s
Avg test loss: 5.91364, Avg test acc: 0.11519, Avg tpr: 0.51783, Avg fpr: 0.89213, total FA: 123871

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08685 | acc=0.9828 | tpr=0.9602 | fpr=0.0168 | 4886.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08864 | acc=0.9826 | tpr=0.9574 | fpr=0.0169 | 6937.8 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.09219 | acc=0.9816 | tpr=0.9568 | fpr=0.0180 | 8204.7 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.09406 | acc=0.9817 | tpr=0.9607 | fpr=0.0179 | 5411.7 samples/s | 21.1 steps/s
[Step= 250] | Loss=0.09262 | acc=0.9819 | tpr=0.9555 | fpr=0.0177 | 8089.1 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.09476 | acc=0.9816 | tpr=0.9556 | fpr=0.0180 | 7601.8 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.09567 | acc=0.9812 | tpr=0.9555 | fpr=0.0183 | 7943.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.09672 | acc=0.9809 | tpr=0.9508 | fpr=0.0186 | 7943.0 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.09887 | acc=0.9805 | tpr=0.9464 | fpr=0.0189 | 7849.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.09810 | acc=0.9806 | tpr=0.9467 | fpr=0.0188 | 7731.3 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.09764 | acc=0.9807 | tpr=0.9443 | fpr=0.0186 | 14282.7 samples/s | 55.8 steps/s
Avg test loss: 0.09751, Avg test acc: 0.98073, Avg tpr: 0.94453, Avg fpr: 0.01861, total FA: 2584

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08819 | acc=0.9830 | tpr=0.9336 | fpr=0.0161 | 4895.4 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.09142 | acc=0.9827 | tpr=0.9275 | fpr=0.0163 | 6917.7 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.09454 | acc=0.9822 | tpr=0.9280 | fpr=0.0168 | 7750.4 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.09645 | acc=0.9821 | tpr=0.9290 | fpr=0.0169 | 5787.0 samples/s | 22.6 steps/s
[Step= 250] | Loss=0.09463 | acc=0.9823 | tpr=0.9275 | fpr=0.0167 | 7733.2 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.09705 | acc=0.9820 | tpr=0.9265 | fpr=0.0170 | 7661.8 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.09763 | acc=0.9818 | tpr=0.9299 | fpr=0.0173 | 8013.0 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09902 | acc=0.9815 | tpr=0.9240 | fpr=0.0174 | 7750.2 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10129 | acc=0.9813 | tpr=0.9236 | fpr=0.0177 | 8087.2 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.10033 | acc=0.9814 | tpr=0.9260 | fpr=0.0176 | 7733.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.10014 | acc=0.9815 | tpr=0.9248 | fpr=0.0175 | 14156.8 samples/s | 55.3 steps/s
Avg test loss: 0.10002, Avg test acc: 0.98149, Avg tpr: 0.92512, Avg fpr: 0.01749, total FA: 2428

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.09254 | acc=0.9813 | tpr=0.9602 | fpr=0.0183 | 4875.7 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09475 | acc=0.9815 | tpr=0.9595 | fpr=0.0181 | 6950.0 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.09879 | acc=0.9808 | tpr=0.9553 | fpr=0.0188 | 5912.0 samples/s | 23.1 steps/s
[Step= 200] | Loss=0.10009 | acc=0.9809 | tpr=0.9607 | fpr=0.0187 | 7470.8 samples/s | 29.2 steps/s
[Step= 250] | Loss=0.09839 | acc=0.9811 | tpr=0.9607 | fpr=0.0185 | 7817.4 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.10082 | acc=0.9807 | tpr=0.9564 | fpr=0.0189 | 8055.9 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.10174 | acc=0.9804 | tpr=0.9574 | fpr=0.0192 | 7595.1 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.10280 | acc=0.9802 | tpr=0.9557 | fpr=0.0193 | 7880.2 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.10465 | acc=0.9800 | tpr=0.9552 | fpr=0.0196 | 7821.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10399 | acc=0.9800 | tpr=0.9564 | fpr=0.0196 | 8070.1 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.10354 | acc=0.9801 | tpr=0.9550 | fpr=0.0194 | 13495.0 samples/s | 52.7 steps/s
Avg test loss: 0.10343, Avg test acc: 0.98012, Avg tpr: 0.95523, Avg fpr: 0.01943, total FA: 2698

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09158 | acc=0.9820 | tpr=0.9292 | fpr=0.0170 | 4969.5 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.09586 | acc=0.9813 | tpr=0.9339 | fpr=0.0178 | 6824.7 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.09951 | acc=0.9808 | tpr=0.9352 | fpr=0.0184 | 5389.4 samples/s | 21.1 steps/s
[Step= 200] | Loss=0.10091 | acc=0.9810 | tpr=0.9432 | fpr=0.0183 | 8727.8 samples/s | 34.1 steps/s
[Step= 250] | Loss=0.09926 | acc=0.9814 | tpr=0.9450 | fpr=0.0179 | 7955.6 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10126 | acc=0.9812 | tpr=0.9396 | fpr=0.0181 | 7437.6 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.10194 | acc=0.9810 | tpr=0.9411 | fpr=0.0182 | 7556.6 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.10223 | acc=0.9810 | tpr=0.9382 | fpr=0.0182 | 7840.2 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.10433 | acc=0.9807 | tpr=0.9348 | fpr=0.0185 | 7989.2 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10361 | acc=0.9807 | tpr=0.9366 | fpr=0.0185 | 7941.8 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.10333 | acc=0.9809 | tpr=0.9363 | fpr=0.0183 | 13848.5 samples/s | 54.1 steps/s
Avg test loss: 0.10313, Avg test acc: 0.98092, Avg tpr: 0.93661, Avg fpr: 0.01827, total FA: 2537

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09823 | acc=0.9816 | tpr=0.9292 | fpr=0.0174 | 4599.1 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.10412 | acc=0.9810 | tpr=0.9296 | fpr=0.0181 | 7572.3 samples/s | 29.6 steps/s
[Step= 150] | Loss=0.10763 | acc=0.9801 | tpr=0.9323 | fpr=0.0191 | 5631.2 samples/s | 22.0 steps/s
[Step= 200] | Loss=0.10972 | acc=0.9800 | tpr=0.9377 | fpr=0.0192 | 8083.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.10814 | acc=0.9805 | tpr=0.9354 | fpr=0.0187 | 7733.7 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.11080 | acc=0.9801 | tpr=0.9295 | fpr=0.0190 | 8269.4 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.11144 | acc=0.9800 | tpr=0.9324 | fpr=0.0192 | 7734.1 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.11290 | acc=0.9798 | tpr=0.9305 | fpr=0.0193 | 7627.1 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.11533 | acc=0.9795 | tpr=0.9289 | fpr=0.0195 | 8035.1 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.11449 | acc=0.9796 | tpr=0.9304 | fpr=0.0195 | 8097.8 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.11419 | acc=0.9798 | tpr=0.9288 | fpr=0.0193 | 13321.3 samples/s | 52.0 steps/s
Avg test loss: 0.11402, Avg test acc: 0.97982, Avg tpr: 0.92908, Avg fpr: 0.01926, total FA: 2674

server round 31/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=302.3] | Loss=0.01591 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.687 | L2-Norm(final)=16.626 | 5574.1 samples/s | 87.1 steps/s
[Step=62050 Epoch=302.6] | Loss=0.00392 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.693 | L2-Norm(final)=16.631 | 4326.6 samples/s | 67.6 steps/s
[Step=62100 Epoch=302.8] | Loss=0.00339 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.697 | L2-Norm(final)=16.638 | 5028.1 samples/s | 78.6 steps/s
[Step=62150 Epoch=303.1] | Loss=0.00355 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.699 | L2-Norm(final)=16.646 | 5180.3 samples/s | 80.9 steps/s
[Step=62200 Epoch=303.3] | Loss=0.00344 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.701 | L2-Norm(final)=16.653 | 7472.8 samples/s | 116.8 steps/s
[Step=62250 Epoch=303.5] | Loss=0.00330 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.702 | L2-Norm(final)=16.660 | 2215.0 samples/s | 34.6 steps/s
[Step=62300 Epoch=303.8] | Loss=0.00323 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.704 | L2-Norm(final)=16.668 | 4906.7 samples/s | 76.7 steps/s
[Step=62350 Epoch=304.0] | Loss=0.00312 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.705 | L2-Norm(final)=16.675 | 5149.1 samples/s | 80.5 steps/s
[Step=62400 Epoch=304.3] | Loss=0.00310 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=16.682 | 6696.2 samples/s | 104.6 steps/s
[Step=62450 Epoch=304.5] | Loss=0.00305 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=16.689 | 2275.6 samples/s | 35.6 steps/s
[Step=62500 Epoch=304.8] | Loss=0.00299 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=16.696 | 5002.2 samples/s | 78.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=304.8] | Loss=0.00443 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.713 | L2-Norm(final)=16.765 | 5679.7 samples/s | 88.7 steps/s
[Step=62550 Epoch=305.0] | Loss=0.00315 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.716 | L2-Norm(final)=16.773 | 3848.6 samples/s | 60.1 steps/s
[Step=62600 Epoch=305.2] | Loss=0.00326 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=16.780 | 4430.6 samples/s | 69.2 steps/s
[Step=62650 Epoch=305.5] | Loss=0.00334 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.723 | L2-Norm(final)=16.786 | 4534.0 samples/s | 70.8 steps/s
[Step=62700 Epoch=305.7] | Loss=0.00388 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=16.792 | 6306.8 samples/s | 98.5 steps/s
[Step=62750 Epoch=306.0] | Loss=0.00392 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.728 | L2-Norm(final)=16.797 | 2075.1 samples/s | 32.4 steps/s
[Step=62800 Epoch=306.2] | Loss=0.00378 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.730 | L2-Norm(final)=16.803 | 4444.9 samples/s | 69.5 steps/s
[Step=62850 Epoch=306.5] | Loss=0.00360 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=16.808 | 4450.9 samples/s | 69.5 steps/s
[Step=62900 Epoch=306.7] | Loss=0.00371 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.734 | L2-Norm(final)=16.813 | 5877.5 samples/s | 91.8 steps/s
[Step=62950 Epoch=307.0] | Loss=0.00365 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=16.817 | 2179.6 samples/s | 34.1 steps/s
[Step=63000 Epoch=307.2] | Loss=0.00358 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=16.821 | 4445.2 samples/s | 69.5 steps/s
[Step=63050 Epoch=307.4] | Loss=0.00349 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=16.825 | 4450.9 samples/s | 69.5 steps/s
[Step=63100 Epoch=307.7] | Loss=0.00337 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=16.829 | 5319.1 samples/s | 83.1 steps/s
[Step=63150 Epoch=307.9] | Loss=0.00325 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.736 | L2-Norm(final)=16.833 | 1687.7 samples/s | 26.4 steps/s
[Step=63200 Epoch=308.2] | Loss=0.00324 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=16.837 | 4431.0 samples/s | 69.2 steps/s
[Step=63250 Epoch=308.4] | Loss=0.00315 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.735 | L2-Norm(final)=16.841 | 4280.5 samples/s | 66.9 steps/s
[Step=63300 Epoch=308.7] | Loss=0.00303 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.734 | L2-Norm(final)=16.844 | 4927.2 samples/s | 77.0 steps/s
[Step=63350 Epoch=308.9] | Loss=0.00298 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.733 | L2-Norm(final)=16.848 | 2293.1 samples/s | 35.8 steps/s
[Step=63400 Epoch=309.2] | Loss=0.00294 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.733 | L2-Norm(final)=16.851 | 4465.8 samples/s | 69.8 steps/s
[Step=63450 Epoch=309.4] | Loss=0.00291 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=16.855 | 4467.4 samples/s | 69.8 steps/s
[Step=63500 Epoch=309.6] | Loss=0.00289 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.730 | L2-Norm(final)=16.858 | 4580.5 samples/s | 71.6 steps/s
[Step=63550 Epoch=309.9] | Loss=0.00283 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.729 | L2-Norm(final)=16.861 | 2427.2 samples/s | 37.9 steps/s
[Step=63600 Epoch=310.1] | Loss=0.00279 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.728 | L2-Norm(final)=16.864 | 4403.9 samples/s | 68.8 steps/s
[Step=63650 Epoch=310.4] | Loss=0.00276 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.726 | L2-Norm(final)=16.867 | 4439.5 samples/s | 69.4 steps/s
[Step=63700 Epoch=310.6] | Loss=0.00272 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=16.870 | 4470.9 samples/s | 69.9 steps/s
[Step=63750 Epoch=310.9] | Loss=0.00273 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.723 | L2-Norm(final)=16.873 | 2458.0 samples/s | 38.4 steps/s
[Step=63800 Epoch=311.1] | Loss=0.00268 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.722 | L2-Norm(final)=16.876 | 4535.5 samples/s | 70.9 steps/s
[Step=63850 Epoch=311.3] | Loss=0.00263 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=16.879 | 4326.2 samples/s | 67.6 steps/s
[Step=63900 Epoch=311.6] | Loss=0.00269 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=16.882 | 4426.4 samples/s | 69.2 steps/s
[Step=63950 Epoch=311.8] | Loss=0.00268 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.717 | L2-Norm(final)=16.885 | 2457.3 samples/s | 38.4 steps/s
[Step=64000 Epoch=312.1] | Loss=0.00263 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=16.888 | 4476.9 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step64000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=302.5] | Loss=0.00139 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=17.145 | 5060.0 samples/s | 79.1 steps/s
[Step=62050 Epoch=302.8] | Loss=0.00235 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=17.152 | 4483.1 samples/s | 70.0 steps/s
[Step=62100 Epoch=303.0] | Loss=0.00284 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=17.161 | 5057.4 samples/s | 79.0 steps/s
[Step=62150 Epoch=303.3] | Loss=0.00291 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.355 | L2-Norm(final)=17.170 | 5007.9 samples/s | 78.2 steps/s
[Step=62200 Epoch=303.5] | Loss=0.00272 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=17.179 | 7754.0 samples/s | 121.2 steps/s
[Step=62250 Epoch=303.8] | Loss=0.00261 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=17.188 | 2147.9 samples/s | 33.6 steps/s
[Step=62300 Epoch=304.0] | Loss=0.00251 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=17.197 | 5056.4 samples/s | 79.0 steps/s
[Step=62350 Epoch=304.2] | Loss=0.00251 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=17.206 | 5066.3 samples/s | 79.2 steps/s
[Step=62400 Epoch=304.5] | Loss=0.00251 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=17.214 | 6900.8 samples/s | 107.8 steps/s
[Step=62450 Epoch=304.7] | Loss=0.00243 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=17.222 | 2181.9 samples/s | 34.1 steps/s
[Step=62500 Epoch=305.0] | Loss=0.00243 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=17.231 | 5020.4 samples/s | 78.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=305.0] | Loss=0.00405 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=17.314 | 5676.3 samples/s | 88.7 steps/s
[Step=62550 Epoch=305.2] | Loss=0.00353 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=17.322 | 3831.6 samples/s | 59.9 steps/s
[Step=62600 Epoch=305.5] | Loss=0.00375 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=17.330 | 4465.1 samples/s | 69.8 steps/s
[Step=62650 Epoch=305.7] | Loss=0.00388 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=17.339 | 4424.7 samples/s | 69.1 steps/s
[Step=62700 Epoch=305.9] | Loss=0.00397 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.386 | L2-Norm(final)=17.346 | 6588.4 samples/s | 102.9 steps/s
[Step=62750 Epoch=306.2] | Loss=0.00378 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=17.353 | 2089.6 samples/s | 32.6 steps/s
[Step=62800 Epoch=306.4] | Loss=0.00361 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=17.359 | 4346.4 samples/s | 67.9 steps/s
[Step=62850 Epoch=306.7] | Loss=0.00363 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=17.365 | 4470.7 samples/s | 69.9 steps/s
[Step=62900 Epoch=306.9] | Loss=0.00365 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=17.371 | 6052.2 samples/s | 94.6 steps/s
[Step=62950 Epoch=307.2] | Loss=0.00355 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=17.377 | 2133.7 samples/s | 33.3 steps/s
[Step=63000 Epoch=307.4] | Loss=0.00348 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.402 | L2-Norm(final)=17.382 | 4517.0 samples/s | 70.6 steps/s
[Step=63050 Epoch=307.7] | Loss=0.00330 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=17.388 | 4428.1 samples/s | 69.2 steps/s
[Step=63100 Epoch=307.9] | Loss=0.00332 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=17.392 | 5559.0 samples/s | 86.9 steps/s
[Step=63150 Epoch=308.1] | Loss=0.00320 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.397 | 2223.8 samples/s | 34.7 steps/s
[Step=63200 Epoch=308.4] | Loss=0.00311 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.402 | 4509.6 samples/s | 70.5 steps/s
[Step=63250 Epoch=308.6] | Loss=0.00308 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.406 | 4522.1 samples/s | 70.7 steps/s
[Step=63300 Epoch=308.9] | Loss=0.00305 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.410 | 5054.4 samples/s | 79.0 steps/s
[Step=63350 Epoch=309.1] | Loss=0.00295 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.414 | 2300.3 samples/s | 35.9 steps/s
[Step=63400 Epoch=309.4] | Loss=0.00287 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=17.418 | 4437.0 samples/s | 69.3 steps/s
[Step=63450 Epoch=309.6] | Loss=0.00278 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=17.422 | 4455.0 samples/s | 69.6 steps/s
[Step=63500 Epoch=309.9] | Loss=0.00276 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=17.426 | 4809.0 samples/s | 75.1 steps/s
[Step=63550 Epoch=310.1] | Loss=0.00272 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.402 | L2-Norm(final)=17.429 | 2346.2 samples/s | 36.7 steps/s
[Step=63600 Epoch=310.3] | Loss=0.00272 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.401 | L2-Norm(final)=17.433 | 4464.6 samples/s | 69.8 steps/s
[Step=63650 Epoch=310.6] | Loss=0.00267 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=17.436 | 4410.0 samples/s | 68.9 steps/s
[Step=63700 Epoch=310.8] | Loss=0.00262 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=17.439 | 4565.1 samples/s | 71.3 steps/s
[Step=63750 Epoch=311.1] | Loss=0.00258 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.397 | L2-Norm(final)=17.442 | 2420.8 samples/s | 37.8 steps/s
[Step=63800 Epoch=311.3] | Loss=0.00255 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=17.446 | 4415.8 samples/s | 69.0 steps/s
[Step=63850 Epoch=311.6] | Loss=0.00252 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=17.449 | 4513.3 samples/s | 70.5 steps/s
[Step=63900 Epoch=311.8] | Loss=0.00249 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=17.452 | 4480.5 samples/s | 70.0 steps/s
[Step=63950 Epoch=312.0] | Loss=0.00245 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=17.455 | 2427.1 samples/s | 37.9 steps/s
[Step=64000 Epoch=312.3] | Loss=0.00242 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=17.458 | 4541.0 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step64000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=302.1] | Loss=0.00482 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=17.364 | 5061.4 samples/s | 79.1 steps/s
[Step=62050 Epoch=302.3] | Loss=0.00337 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=17.371 | 4491.8 samples/s | 70.2 steps/s
[Step=62100 Epoch=302.6] | Loss=0.00331 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.097 | L2-Norm(final)=17.380 | 5154.0 samples/s | 80.5 steps/s
[Step=62150 Epoch=302.8] | Loss=0.00346 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.099 | L2-Norm(final)=17.389 | 4895.8 samples/s | 76.5 steps/s
[Step=62200 Epoch=303.1] | Loss=0.00324 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.102 | L2-Norm(final)=17.398 | 7768.9 samples/s | 121.4 steps/s
[Step=62250 Epoch=303.3] | Loss=0.00307 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.103 | L2-Norm(final)=17.407 | 2233.6 samples/s | 34.9 steps/s
[Step=62300 Epoch=303.6] | Loss=0.00300 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.104 | L2-Norm(final)=17.415 | 5016.9 samples/s | 78.4 steps/s
[Step=62350 Epoch=303.8] | Loss=0.00297 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.106 | L2-Norm(final)=17.424 | 5017.1 samples/s | 78.4 steps/s
[Step=62400 Epoch=304.0] | Loss=0.00306 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=17.432 | 6814.2 samples/s | 106.5 steps/s
[Step=62450 Epoch=304.3] | Loss=0.00302 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.108 | L2-Norm(final)=17.441 | 2325.0 samples/s | 36.3 steps/s
[Step=62500 Epoch=304.5] | Loss=0.00298 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=17.449 | 4915.1 samples/s | 76.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=304.5] | Loss=0.00225 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.119 | L2-Norm(final)=17.534 | 5366.8 samples/s | 83.9 steps/s
[Step=62550 Epoch=304.8] | Loss=0.00236 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=17.541 | 4019.9 samples/s | 62.8 steps/s
[Step=62600 Epoch=305.0] | Loss=0.00394 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=17.548 | 4521.9 samples/s | 70.7 steps/s
[Step=62650 Epoch=305.3] | Loss=0.00442 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=17.555 | 4432.7 samples/s | 69.3 steps/s
[Step=62700 Epoch=305.5] | Loss=0.00436 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.133 | L2-Norm(final)=17.562 | 6526.2 samples/s | 102.0 steps/s
[Step=62750 Epoch=305.7] | Loss=0.00407 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=17.568 | 2095.0 samples/s | 32.7 steps/s
[Step=62800 Epoch=306.0] | Loss=0.00386 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.139 | L2-Norm(final)=17.575 | 4442.1 samples/s | 69.4 steps/s
[Step=62850 Epoch=306.2] | Loss=0.00378 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=17.581 | 4455.1 samples/s | 69.6 steps/s
[Step=62900 Epoch=306.5] | Loss=0.00383 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.142 | L2-Norm(final)=17.586 | 5898.1 samples/s | 92.2 steps/s
[Step=62950 Epoch=306.7] | Loss=0.00359 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=17.591 | 2187.1 samples/s | 34.2 steps/s
[Step=63000 Epoch=307.0] | Loss=0.00354 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.144 | L2-Norm(final)=17.596 | 4421.4 samples/s | 69.1 steps/s
[Step=63050 Epoch=307.2] | Loss=0.00348 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.144 | L2-Norm(final)=17.600 | 4446.1 samples/s | 69.5 steps/s
[Step=63100 Epoch=307.5] | Loss=0.00337 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=17.605 | 5395.7 samples/s | 84.3 steps/s
[Step=63150 Epoch=307.7] | Loss=0.00333 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=17.609 | 2274.1 samples/s | 35.5 steps/s
[Step=63200 Epoch=307.9] | Loss=0.00323 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=17.613 | 4419.0 samples/s | 69.0 steps/s
[Step=63250 Epoch=308.2] | Loss=0.00316 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=17.617 | 4470.7 samples/s | 69.9 steps/s
[Step=63300 Epoch=308.4] | Loss=0.00310 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=17.621 | 4882.1 samples/s | 76.3 steps/s
[Step=63350 Epoch=308.7] | Loss=0.00300 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.142 | L2-Norm(final)=17.625 | 2332.1 samples/s | 36.4 steps/s
[Step=63400 Epoch=308.9] | Loss=0.00290 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=17.629 | 4449.8 samples/s | 69.5 steps/s
[Step=63450 Epoch=309.2] | Loss=0.00287 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=17.632 | 4476.5 samples/s | 69.9 steps/s
[Step=63500 Epoch=309.4] | Loss=0.00288 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=17.636 | 4612.8 samples/s | 72.1 steps/s
[Step=63550 Epoch=309.6] | Loss=0.00282 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=17.639 | 2429.5 samples/s | 38.0 steps/s
[Step=63600 Epoch=309.9] | Loss=0.00282 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=17.643 | 4392.1 samples/s | 68.6 steps/s
[Step=63650 Epoch=310.1] | Loss=0.00278 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=17.646 | 4499.9 samples/s | 70.3 steps/s
[Step=63700 Epoch=310.4] | Loss=0.00272 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.132 | L2-Norm(final)=17.650 | 4529.9 samples/s | 70.8 steps/s
[Step=63750 Epoch=310.6] | Loss=0.00269 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=17.653 | 2463.7 samples/s | 38.5 steps/s
[Step=63800 Epoch=310.9] | Loss=0.00268 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.129 | L2-Norm(final)=17.656 | 4439.8 samples/s | 69.4 steps/s
[Step=63850 Epoch=311.1] | Loss=0.00267 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=17.659 | 4390.1 samples/s | 68.6 steps/s
[Step=63900 Epoch=311.4] | Loss=0.00264 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=17.662 | 4569.5 samples/s | 71.4 steps/s
[Step=63950 Epoch=311.6] | Loss=0.00260 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=17.666 | 2438.6 samples/s | 38.1 steps/s
[Step=64000 Epoch=311.8] | Loss=0.00257 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=17.669 | 4479.9 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step64000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=302.4] | Loss=0.00526 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.753 | L2-Norm(final)=17.334 | 5115.9 samples/s | 79.9 steps/s
[Step=62050 Epoch=302.6] | Loss=0.00242 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.754 | L2-Norm(final)=17.341 | 4397.0 samples/s | 68.7 steps/s
[Step=62100 Epoch=302.8] | Loss=0.00238 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.757 | L2-Norm(final)=17.351 | 5006.9 samples/s | 78.2 steps/s
[Step=62150 Epoch=303.1] | Loss=0.00260 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.760 | L2-Norm(final)=17.361 | 5075.5 samples/s | 79.3 steps/s
[Step=62200 Epoch=303.3] | Loss=0.00252 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.762 | L2-Norm(final)=17.371 | 7811.9 samples/s | 122.1 steps/s
[Step=62250 Epoch=303.6] | Loss=0.00255 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=17.380 | 2209.6 samples/s | 34.5 steps/s
[Step=62300 Epoch=303.8] | Loss=0.00256 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=17.390 | 5015.2 samples/s | 78.4 steps/s
[Step=62350 Epoch=304.1] | Loss=0.00253 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.767 | L2-Norm(final)=17.399 | 5065.2 samples/s | 79.1 steps/s
[Step=62400 Epoch=304.3] | Loss=0.00244 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=17.407 | 6905.3 samples/s | 107.9 steps/s
[Step=62450 Epoch=304.5] | Loss=0.00245 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=17.416 | 2320.2 samples/s | 36.3 steps/s
[Step=62500 Epoch=304.8] | Loss=0.00244 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.770 | L2-Norm(final)=17.425 | 4977.7 samples/s | 77.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=304.8] | Loss=0.00233 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.780 | L2-Norm(final)=17.514 | 5483.1 samples/s | 85.7 steps/s
[Step=62550 Epoch=305.0] | Loss=0.00325 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=17.522 | 4069.6 samples/s | 63.6 steps/s
[Step=62600 Epoch=305.3] | Loss=0.00423 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.790 | L2-Norm(final)=17.531 | 4451.8 samples/s | 69.6 steps/s
[Step=62650 Epoch=305.5] | Loss=0.00407 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.798 | L2-Norm(final)=17.540 | 4548.2 samples/s | 71.1 steps/s
[Step=62700 Epoch=305.8] | Loss=0.00383 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.803 | L2-Norm(final)=17.548 | 6458.4 samples/s | 100.9 steps/s
[Step=62750 Epoch=306.0] | Loss=0.00412 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.807 | L2-Norm(final)=17.555 | 2113.8 samples/s | 33.0 steps/s
[Step=62800 Epoch=306.2] | Loss=0.00410 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.811 | L2-Norm(final)=17.561 | 4433.4 samples/s | 69.3 steps/s
[Step=62850 Epoch=306.5] | Loss=0.00384 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=17.567 | 4482.2 samples/s | 70.0 steps/s
[Step=62900 Epoch=306.7] | Loss=0.00372 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.815 | L2-Norm(final)=17.572 | 5926.0 samples/s | 92.6 steps/s
[Step=62950 Epoch=307.0] | Loss=0.00352 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.817 | L2-Norm(final)=17.577 | 2174.9 samples/s | 34.0 steps/s
[Step=63000 Epoch=307.2] | Loss=0.00343 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.818 | L2-Norm(final)=17.582 | 4528.4 samples/s | 70.8 steps/s
[Step=63050 Epoch=307.5] | Loss=0.00331 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=17.587 | 4488.8 samples/s | 70.1 steps/s
[Step=63100 Epoch=307.7] | Loss=0.00319 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=17.591 | 5333.4 samples/s | 83.3 steps/s
[Step=63150 Epoch=308.0] | Loss=0.00304 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=17.595 | 2266.0 samples/s | 35.4 steps/s
[Step=63200 Epoch=308.2] | Loss=0.00294 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=17.599 | 4543.3 samples/s | 71.0 steps/s
[Step=63250 Epoch=308.4] | Loss=0.00282 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=17.603 | 4403.1 samples/s | 68.8 steps/s
[Step=63300 Epoch=308.7] | Loss=0.00282 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=17.607 | 5001.6 samples/s | 78.1 steps/s
[Step=63350 Epoch=308.9] | Loss=0.00281 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.817 | L2-Norm(final)=17.611 | 2328.5 samples/s | 36.4 steps/s
[Step=63400 Epoch=309.2] | Loss=0.00274 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.816 | L2-Norm(final)=17.614 | 4474.0 samples/s | 69.9 steps/s
[Step=63450 Epoch=309.4] | Loss=0.00265 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.815 | L2-Norm(final)=17.617 | 4522.8 samples/s | 70.7 steps/s
[Step=63500 Epoch=309.7] | Loss=0.00261 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=17.621 | 4554.5 samples/s | 71.2 steps/s
[Step=63550 Epoch=309.9] | Loss=0.00254 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.812 | L2-Norm(final)=17.624 | 2438.3 samples/s | 38.1 steps/s
[Step=63600 Epoch=310.1] | Loss=0.00253 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.811 | L2-Norm(final)=17.627 | 4494.0 samples/s | 70.2 steps/s
[Step=63650 Epoch=310.4] | Loss=0.00248 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.810 | L2-Norm(final)=17.631 | 4464.9 samples/s | 69.8 steps/s
[Step=63700 Epoch=310.6] | Loss=0.00245 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.808 | L2-Norm(final)=17.634 | 4481.5 samples/s | 70.0 steps/s
[Step=63750 Epoch=310.9] | Loss=0.00243 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.806 | L2-Norm(final)=17.637 | 2500.0 samples/s | 39.1 steps/s
[Step=63800 Epoch=311.1] | Loss=0.00237 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.804 | L2-Norm(final)=17.640 | 4434.7 samples/s | 69.3 steps/s
[Step=63850 Epoch=311.4] | Loss=0.00232 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.803 | L2-Norm(final)=17.643 | 4463.9 samples/s | 69.7 steps/s
[Step=63900 Epoch=311.6] | Loss=0.00229 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.800 | L2-Norm(final)=17.646 | 4471.3 samples/s | 69.9 steps/s
[Step=63950 Epoch=311.9] | Loss=0.00227 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.798 | L2-Norm(final)=17.649 | 2481.5 samples/s | 38.8 steps/s
[Step=64000 Epoch=312.1] | Loss=0.00224 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.796 | L2-Norm(final)=17.652 | 4470.4 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step64000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=304.0] | Loss=0.00088 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=17.387 | 5177.4 samples/s | 80.9 steps/s
[Step=62050 Epoch=304.3] | Loss=0.00213 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=17.394 | 4405.7 samples/s | 68.8 steps/s
[Step=62100 Epoch=304.5] | Loss=0.00271 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=17.403 | 4966.9 samples/s | 77.6 steps/s
[Step=62150 Epoch=304.8] | Loss=0.00264 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=17.412 | 5011.3 samples/s | 78.3 steps/s
[Step=62200 Epoch=305.0] | Loss=0.00291 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.509 | L2-Norm(final)=17.420 | 8140.1 samples/s | 127.2 steps/s
[Step=62250 Epoch=305.3] | Loss=0.00293 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.510 | L2-Norm(final)=17.430 | 2172.3 samples/s | 33.9 steps/s
[Step=62300 Epoch=305.5] | Loss=0.00276 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.512 | L2-Norm(final)=17.439 | 5021.3 samples/s | 78.5 steps/s
[Step=62350 Epoch=305.8] | Loss=0.00270 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=17.448 | 5095.5 samples/s | 79.6 steps/s
[Step=62400 Epoch=306.0] | Loss=0.00276 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=17.456 | 7327.7 samples/s | 114.5 steps/s
[Step=62450 Epoch=306.2] | Loss=0.00269 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.515 | L2-Norm(final)=17.465 | 2240.9 samples/s | 35.0 steps/s
[Step=62500 Epoch=306.5] | Loss=0.00262 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.516 | L2-Norm(final)=17.474 | 5097.3 samples/s | 79.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=306.5] | Loss=0.00312 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=17.559 | 5363.1 samples/s | 83.8 steps/s
[Step=62550 Epoch=306.7] | Loss=0.00228 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.527 | L2-Norm(final)=17.567 | 4039.7 samples/s | 63.1 steps/s
[Step=62600 Epoch=307.0] | Loss=0.00289 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.530 | L2-Norm(final)=17.574 | 4481.1 samples/s | 70.0 steps/s
[Step=62650 Epoch=307.2] | Loss=0.00341 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=17.581 | 4513.8 samples/s | 70.5 steps/s
[Step=62700 Epoch=307.5] | Loss=0.00351 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.539 | L2-Norm(final)=17.588 | 6583.1 samples/s | 102.9 steps/s
[Step=62750 Epoch=307.7] | Loss=0.00336 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.543 | L2-Norm(final)=17.595 | 2083.7 samples/s | 32.6 steps/s
[Step=62800 Epoch=308.0] | Loss=0.00342 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=17.601 | 4456.3 samples/s | 69.6 steps/s
[Step=62850 Epoch=308.2] | Loss=0.00339 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=17.606 | 4486.7 samples/s | 70.1 steps/s
[Step=62900 Epoch=308.5] | Loss=0.00331 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=17.612 | 6184.0 samples/s | 96.6 steps/s
[Step=62950 Epoch=308.7] | Loss=0.00323 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=17.617 | 2127.4 samples/s | 33.2 steps/s
[Step=63000 Epoch=308.9] | Loss=0.00315 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.622 | 4468.6 samples/s | 69.8 steps/s
[Step=63050 Epoch=309.2] | Loss=0.00299 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.627 | 4497.0 samples/s | 70.3 steps/s
[Step=63100 Epoch=309.4] | Loss=0.00295 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.631 | 5841.8 samples/s | 91.3 steps/s
[Step=63150 Epoch=309.7] | Loss=0.00283 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.635 | 2166.3 samples/s | 33.8 steps/s
[Step=63200 Epoch=309.9] | Loss=0.00273 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.639 | 4532.9 samples/s | 70.8 steps/s
[Step=63250 Epoch=310.2] | Loss=0.00272 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=17.643 | 4422.4 samples/s | 69.1 steps/s
[Step=63300 Epoch=310.4] | Loss=0.00268 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=17.647 | 5539.2 samples/s | 86.5 steps/s
[Step=63350 Epoch=310.7] | Loss=0.00262 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=17.651 | 2223.6 samples/s | 34.7 steps/s
[Step=63400 Epoch=310.9] | Loss=0.00256 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.552 | L2-Norm(final)=17.655 | 4363.7 samples/s | 68.2 steps/s
[Step=63450 Epoch=311.1] | Loss=0.00249 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=17.659 | 4384.3 samples/s | 68.5 steps/s
[Step=63500 Epoch=311.4] | Loss=0.00245 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.550 | L2-Norm(final)=17.662 | 5033.2 samples/s | 78.6 steps/s
[Step=63550 Epoch=311.6] | Loss=0.00238 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=17.666 | 2269.6 samples/s | 35.5 steps/s
[Step=63600 Epoch=311.9] | Loss=0.00237 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=17.669 | 4396.1 samples/s | 68.7 steps/s
[Step=63650 Epoch=312.1] | Loss=0.00233 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=17.673 | 4590.9 samples/s | 71.7 steps/s
[Step=63700 Epoch=312.4] | Loss=0.00230 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=17.676 | 4958.4 samples/s | 77.5 steps/s
[Step=63750 Epoch=312.6] | Loss=0.00227 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=17.679 | 2358.9 samples/s | 36.9 steps/s
[Step=63800 Epoch=312.9] | Loss=0.00223 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=17.682 | 4490.1 samples/s | 70.2 steps/s
[Step=63850 Epoch=313.1] | Loss=0.00221 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=17.686 | 4415.4 samples/s | 69.0 steps/s
[Step=63900 Epoch=313.4] | Loss=0.00220 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.538 | L2-Norm(final)=17.689 | 4420.8 samples/s | 69.1 steps/s
[Step=63950 Epoch=313.6] | Loss=0.00218 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.536 | L2-Norm(final)=17.692 | 2257.3 samples/s | 35.3 steps/s
[Step=64000 Epoch=313.8] | Loss=0.00218 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=17.695 | 4509.6 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step64000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=587.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=8.906 | 5216.9 samples/s | 81.5 steps/s
[Step=62050 Epoch=588.0] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=8.921 | 3899.5 samples/s | 60.9 steps/s
[Step=62100 Epoch=588.5] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=8.936 | 7447.5 samples/s | 116.4 steps/s
[Step=62150 Epoch=588.9] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=8.948 | 2092.0 samples/s | 32.7 steps/s
[Step=62200 Epoch=589.4] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=8.958 | 6574.7 samples/s | 102.7 steps/s
[Step=62250 Epoch=589.9] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=8.967 | 2165.7 samples/s | 33.8 steps/s
[Step=62300 Epoch=590.3] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=8.975 | 5811.5 samples/s | 90.8 steps/s
[Step=62350 Epoch=590.8] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.093 | L2-Norm(final)=8.983 | 2288.3 samples/s | 35.8 steps/s
[Step=62400 Epoch=591.3] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.095 | L2-Norm(final)=8.990 | 5230.7 samples/s | 81.7 steps/s
[Step=62450 Epoch=591.8] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=8.996 | 2407.6 samples/s | 37.6 steps/s
[Step=62500 Epoch=592.2] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=9.003 | 4745.9 samples/s | 74.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=592.3] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=9.066 | 5493.8 samples/s | 85.8 steps/s
[Step=62550 Epoch=592.7] | Loss=0.00019 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.110 | L2-Norm(final)=9.076 | 3624.6 samples/s | 56.6 steps/s
[Step=62600 Epoch=593.2] | Loss=0.00178 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.134 | L2-Norm(final)=9.082 | 6084.1 samples/s | 95.1 steps/s
[Step=62650 Epoch=593.7] | Loss=0.00128 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.148 | L2-Norm(final)=9.085 | 2011.3 samples/s | 31.4 steps/s
[Step=62700 Epoch=594.1] | Loss=0.00103 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.156 | L2-Norm(final)=9.087 | 5518.5 samples/s | 86.2 steps/s
[Step=62750 Epoch=594.6] | Loss=0.00083 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.161 | L2-Norm(final)=9.089 | 2054.0 samples/s | 32.1 steps/s
[Step=62800 Epoch=595.1] | Loss=0.00070 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.164 | L2-Norm(final)=9.090 | 5106.0 samples/s | 79.8 steps/s
[Step=62850 Epoch=595.6] | Loss=0.00060 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.167 | L2-Norm(final)=9.091 | 2159.2 samples/s | 33.7 steps/s
[Step=62900 Epoch=596.0] | Loss=0.00053 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.092 | 4568.1 samples/s | 71.4 steps/s
[Step=62950 Epoch=596.5] | Loss=0.00047 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.092 | 2266.7 samples/s | 35.4 steps/s
[Step=63000 Epoch=597.0] | Loss=0.00042 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.093 | 4240.2 samples/s | 66.3 steps/s
[Step=63050 Epoch=597.5] | Loss=0.00039 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.093 | 2305.0 samples/s | 36.0 steps/s
[Step=63100 Epoch=597.9] | Loss=0.00036 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.094 | 4182.8 samples/s | 65.4 steps/s
[Step=63150 Epoch=598.4] | Loss=0.00033 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.094 | 2387.2 samples/s | 37.3 steps/s
[Step=63200 Epoch=598.9] | Loss=0.00031 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.095 | 4167.4 samples/s | 65.1 steps/s
[Step=63250 Epoch=599.3] | Loss=0.00029 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.095 | 2349.7 samples/s | 36.7 steps/s
[Step=63300 Epoch=599.8] | Loss=0.00027 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.095 | 4209.5 samples/s | 65.8 steps/s
[Step=63350 Epoch=600.3] | Loss=0.00025 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.096 | 2422.7 samples/s | 37.9 steps/s
[Step=63400 Epoch=600.8] | Loss=0.00024 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.096 | 4159.9 samples/s | 65.0 steps/s
[Step=63450 Epoch=601.2] | Loss=0.00023 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.096 | 6304.4 samples/s | 98.5 steps/s
[Step=63500 Epoch=601.7] | Loss=0.00022 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.097 | 1970.9 samples/s | 30.8 steps/s
[Step=63550 Epoch=602.2] | Loss=0.00021 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.097 | 5797.7 samples/s | 90.6 steps/s
[Step=63600 Epoch=602.7] | Loss=0.00020 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.097 | 2066.4 samples/s | 32.3 steps/s
[Step=63650 Epoch=603.1] | Loss=0.00019 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.097 | 5038.7 samples/s | 78.7 steps/s
[Step=63700 Epoch=603.6] | Loss=0.00018 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.098 | 2115.8 samples/s | 33.1 steps/s
[Step=63750 Epoch=604.1] | Loss=0.00017 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.098 | 4815.3 samples/s | 75.2 steps/s
[Step=63800 Epoch=604.6] | Loss=0.00017 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.098 | 2224.8 samples/s | 34.8 steps/s
[Step=63850 Epoch=605.0] | Loss=0.00016 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.098 | 4359.6 samples/s | 68.1 steps/s
[Step=63900 Epoch=605.5] | Loss=0.00016 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.167 | L2-Norm(final)=9.099 | 2290.9 samples/s | 35.8 steps/s
[Step=63950 Epoch=606.0] | Loss=0.00015 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.167 | L2-Norm(final)=9.099 | 4230.9 samples/s | 66.1 steps/s
[Step=64000 Epoch=606.5] | Loss=0.00015 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.166 | L2-Norm(final)=9.099 | 2357.6 samples/s | 36.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step64000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=589.8] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.119 | L2-Norm(final)=9.753 | 4733.8 samples/s | 74.0 steps/s
[Step=62050 Epoch=590.2] | Loss=0.00008 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.124 | L2-Norm(final)=9.764 | 4391.3 samples/s | 68.6 steps/s
[Step=62100 Epoch=590.7] | Loss=0.00006 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.131 | L2-Norm(final)=9.777 | 7097.1 samples/s | 110.9 steps/s
[Step=62150 Epoch=591.2] | Loss=0.00005 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.136 | L2-Norm(final)=9.788 | 2092.7 samples/s | 32.7 steps/s
[Step=62200 Epoch=591.7] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.139 | L2-Norm(final)=9.797 | 6599.1 samples/s | 103.1 steps/s
[Step=62250 Epoch=592.2] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.142 | L2-Norm(final)=9.805 | 2206.7 samples/s | 34.5 steps/s
[Step=62300 Epoch=592.6] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.145 | L2-Norm(final)=9.813 | 5686.2 samples/s | 88.8 steps/s
[Step=62350 Epoch=593.1] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.147 | L2-Norm(final)=9.821 | 2261.3 samples/s | 35.3 steps/s
[Step=62400 Epoch=593.6] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.149 | L2-Norm(final)=9.828 | 5287.3 samples/s | 82.6 steps/s
[Step=62450 Epoch=594.1] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.151 | L2-Norm(final)=9.835 | 2374.3 samples/s | 37.1 steps/s
[Step=62500 Epoch=594.5] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.153 | L2-Norm(final)=9.842 | 4877.1 samples/s | 76.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=594.5] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.911 | 5440.7 samples/s | 85.0 steps/s
[Step=62550 Epoch=595.0] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.164 | L2-Norm(final)=9.916 | 3722.0 samples/s | 58.2 steps/s
[Step=62600 Epoch=595.5] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.156 | L2-Norm(final)=9.920 | 6189.7 samples/s | 96.7 steps/s
[Step=62650 Epoch=596.0] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.146 | L2-Norm(final)=9.923 | 1976.9 samples/s | 30.9 steps/s
[Step=62700 Epoch=596.4] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.136 | L2-Norm(final)=9.926 | 5662.8 samples/s | 88.5 steps/s
[Step=62750 Epoch=596.9] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.124 | L2-Norm(final)=9.928 | 2085.1 samples/s | 32.6 steps/s
[Step=62800 Epoch=597.4] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=9.930 | 5019.2 samples/s | 78.4 steps/s
[Step=62850 Epoch=597.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=9.931 | 2147.9 samples/s | 33.6 steps/s
[Step=62900 Epoch=598.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=9.933 | 4608.2 samples/s | 72.0 steps/s
[Step=62950 Epoch=598.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.934 | 2285.6 samples/s | 35.7 steps/s
[Step=63000 Epoch=599.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=9.935 | 4240.3 samples/s | 66.3 steps/s
[Step=63050 Epoch=599.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.049 | L2-Norm(final)=9.937 | 2314.1 samples/s | 36.2 steps/s
[Step=63100 Epoch=600.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.036 | L2-Norm(final)=9.938 | 4139.1 samples/s | 64.7 steps/s
[Step=63150 Epoch=600.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.023 | L2-Norm(final)=9.939 | 2342.0 samples/s | 36.6 steps/s
[Step=63200 Epoch=601.2] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=9.941 | 4194.9 samples/s | 65.5 steps/s
[Step=63250 Epoch=601.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.996 | L2-Norm(final)=9.942 | 2380.0 samples/s | 37.2 steps/s
[Step=63300 Epoch=602.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.982 | L2-Norm(final)=9.943 | 4189.5 samples/s | 65.5 steps/s
[Step=63350 Epoch=602.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.968 | L2-Norm(final)=9.944 | 2439.7 samples/s | 38.1 steps/s
[Step=63400 Epoch=603.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=9.946 | 3908.4 samples/s | 61.1 steps/s
[Step=63450 Epoch=603.6] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.940 | L2-Norm(final)=9.947 | 6500.2 samples/s | 101.6 steps/s
[Step=63500 Epoch=604.0] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.948 | 1965.1 samples/s | 30.7 steps/s
[Step=63550 Epoch=604.5] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.912 | L2-Norm(final)=9.950 | 5775.9 samples/s | 90.2 steps/s
[Step=63600 Epoch=605.0] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.898 | L2-Norm(final)=9.951 | 2049.3 samples/s | 32.0 steps/s
[Step=63650 Epoch=605.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=9.953 | 5201.1 samples/s | 81.3 steps/s
[Step=63700 Epoch=605.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=9.954 | 2098.1 samples/s | 32.8 steps/s
[Step=63750 Epoch=606.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=9.956 | 4870.9 samples/s | 76.1 steps/s
[Step=63800 Epoch=606.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.839 | L2-Norm(final)=9.957 | 2204.5 samples/s | 34.4 steps/s
[Step=63850 Epoch=607.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.824 | L2-Norm(final)=9.959 | 4436.9 samples/s | 69.3 steps/s
[Step=63900 Epoch=607.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.809 | L2-Norm(final)=9.960 | 2295.6 samples/s | 35.9 steps/s
[Step=63950 Epoch=608.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.794 | L2-Norm(final)=9.962 | 4123.2 samples/s | 64.4 steps/s
[Step=64000 Epoch=608.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.778 | L2-Norm(final)=9.963 | 2369.3 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step64000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=592.1] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.327 | 5393.9 samples/s | 84.3 steps/s
[Step=62050 Epoch=592.5] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.328 | 3807.1 samples/s | 59.5 steps/s
[Step=62100 Epoch=593.0] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.330 | 7554.3 samples/s | 118.0 steps/s
[Step=62150 Epoch=593.5] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.332 | 2104.7 samples/s | 32.9 steps/s
[Step=62200 Epoch=594.0] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.334 | 6769.4 samples/s | 105.8 steps/s
[Step=62250 Epoch=594.4] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.336 | 2143.9 samples/s | 33.5 steps/s
[Step=62300 Epoch=594.9] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.338 | 6163.2 samples/s | 96.3 steps/s
[Step=62350 Epoch=595.4] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.340 | 2213.1 samples/s | 34.6 steps/s
[Step=62400 Epoch=595.9] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.342 | 5693.7 samples/s | 89.0 steps/s
[Step=62450 Epoch=596.4] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.344 | 2317.2 samples/s | 36.2 steps/s
[Step=62500 Epoch=596.8] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.347 | 5103.6 samples/s | 79.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=596.8] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=9.367 | 5262.8 samples/s | 82.2 steps/s
[Step=62550 Epoch=597.3] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.169 | L2-Norm(final)=9.369 | 3758.4 samples/s | 58.7 steps/s
[Step=62600 Epoch=597.8] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.166 | L2-Norm(final)=9.371 | 6394.6 samples/s | 99.9 steps/s
[Step=62650 Epoch=598.3] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.163 | L2-Norm(final)=9.372 | 2001.4 samples/s | 31.3 steps/s
[Step=62700 Epoch=598.7] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.160 | L2-Norm(final)=9.374 | 5838.1 samples/s | 91.2 steps/s
[Step=62750 Epoch=599.2] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=9.375 | 2071.6 samples/s | 32.4 steps/s
[Step=62800 Epoch=599.7] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.153 | L2-Norm(final)=9.376 | 5420.9 samples/s | 84.7 steps/s
[Step=62850 Epoch=600.2] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.150 | L2-Norm(final)=9.377 | 2087.0 samples/s | 32.6 steps/s
[Step=62900 Epoch=600.7] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.146 | L2-Norm(final)=9.378 | 4755.6 samples/s | 74.3 steps/s
[Step=62950 Epoch=601.1] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.142 | L2-Norm(final)=9.379 | 2087.8 samples/s | 32.6 steps/s
[Step=63000 Epoch=601.6] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.138 | L2-Norm(final)=9.380 | 4290.2 samples/s | 67.0 steps/s
[Step=63050 Epoch=602.1] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.134 | L2-Norm(final)=9.381 | 2126.9 samples/s | 33.2 steps/s
[Step=63100 Epoch=602.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.130 | L2-Norm(final)=9.382 | 4045.8 samples/s | 63.2 steps/s
[Step=63150 Epoch=603.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.125 | L2-Norm(final)=9.382 | 2212.2 samples/s | 34.6 steps/s
[Step=63200 Epoch=603.5] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.121 | L2-Norm(final)=9.383 | 4074.5 samples/s | 63.7 steps/s
[Step=63250 Epoch=604.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.116 | L2-Norm(final)=9.384 | 2342.5 samples/s | 36.6 steps/s
[Step=63300 Epoch=604.5] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.112 | L2-Norm(final)=9.385 | 4215.1 samples/s | 65.9 steps/s
[Step=63350 Epoch=605.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.107 | L2-Norm(final)=9.386 | 2375.1 samples/s | 37.1 steps/s
[Step=63400 Epoch=605.4] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.103 | L2-Norm(final)=9.386 | 4226.4 samples/s | 66.0 steps/s
[Step=63450 Epoch=605.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=9.387 | 2378.0 samples/s | 37.2 steps/s
[Step=63500 Epoch=606.4] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.093 | L2-Norm(final)=9.388 | 4265.9 samples/s | 66.7 steps/s
[Step=63550 Epoch=606.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=9.388 | 6830.3 samples/s | 106.7 steps/s
[Step=63600 Epoch=607.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.083 | L2-Norm(final)=9.389 | 1937.1 samples/s | 30.3 steps/s
[Step=63650 Epoch=607.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=9.390 | 6289.3 samples/s | 98.3 steps/s
[Step=63700 Epoch=608.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.073 | L2-Norm(final)=9.391 | 1945.7 samples/s | 30.4 steps/s
[Step=63750 Epoch=608.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.068 | L2-Norm(final)=9.391 | 5863.9 samples/s | 91.6 steps/s
[Step=63800 Epoch=609.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=9.392 | 2085.9 samples/s | 32.6 steps/s
[Step=63850 Epoch=609.7] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=9.393 | 5391.2 samples/s | 84.2 steps/s
[Step=63900 Epoch=610.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.394 | 2161.4 samples/s | 33.8 steps/s
[Step=63950 Epoch=610.7] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=9.394 | 4703.3 samples/s | 73.5 steps/s
[Step=64000 Epoch=611.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.041 | L2-Norm(final)=9.395 | 2212.2 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step64000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=584.2] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.261 | L2-Norm(final)=9.444 | 5029.7 samples/s | 78.6 steps/s
[Step=62050 Epoch=584.7] | Loss=0.00005 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.262 | L2-Norm(final)=9.447 | 4264.8 samples/s | 66.6 steps/s
[Step=62100 Epoch=585.2] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=9.450 | 6932.1 samples/s | 108.3 steps/s
[Step=62150 Epoch=585.6] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.264 | L2-Norm(final)=9.453 | 2139.3 samples/s | 33.4 steps/s
[Step=62200 Epoch=586.1] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.265 | L2-Norm(final)=9.456 | 6170.5 samples/s | 96.4 steps/s
[Step=62250 Epoch=586.6] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.266 | L2-Norm(final)=9.459 | 2254.8 samples/s | 35.2 steps/s
[Step=62300 Epoch=587.0] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=9.461 | 5637.0 samples/s | 88.1 steps/s
[Step=62350 Epoch=587.5] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=9.464 | 2377.7 samples/s | 37.2 steps/s
[Step=62400 Epoch=588.0] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.269 | L2-Norm(final)=9.467 | 4909.6 samples/s | 76.7 steps/s
[Step=62450 Epoch=588.5] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.269 | L2-Norm(final)=9.469 | 2485.1 samples/s | 38.8 steps/s
[Step=62500 Epoch=588.9] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.270 | L2-Norm(final)=9.472 | 4691.5 samples/s | 73.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=588.9] | Loss=0.00009 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.276 | L2-Norm(final)=9.498 | 5144.1 samples/s | 80.4 steps/s
[Step=62550 Epoch=589.4] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.276 | L2-Norm(final)=9.501 | 4109.7 samples/s | 64.2 steps/s
[Step=62600 Epoch=589.9] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.275 | L2-Norm(final)=9.503 | 6243.6 samples/s | 97.6 steps/s
[Step=62650 Epoch=590.3] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.273 | L2-Norm(final)=9.505 | 2043.2 samples/s | 31.9 steps/s
[Step=62700 Epoch=590.8] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.272 | L2-Norm(final)=9.507 | 5507.9 samples/s | 86.1 steps/s
[Step=62750 Epoch=591.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.270 | L2-Norm(final)=9.508 | 2134.2 samples/s | 33.3 steps/s
[Step=62800 Epoch=591.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=9.509 | 4898.8 samples/s | 76.5 steps/s
[Step=62850 Epoch=592.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.265 | L2-Norm(final)=9.511 | 2224.8 samples/s | 34.8 steps/s
[Step=62900 Epoch=592.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=9.512 | 4520.4 samples/s | 70.6 steps/s
[Step=62950 Epoch=593.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=9.513 | 2315.9 samples/s | 36.2 steps/s
[Step=63000 Epoch=593.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.258 | L2-Norm(final)=9.514 | 4260.8 samples/s | 66.6 steps/s
[Step=63050 Epoch=594.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.255 | L2-Norm(final)=9.515 | 2365.8 samples/s | 37.0 steps/s
[Step=63100 Epoch=594.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.252 | L2-Norm(final)=9.516 | 4269.9 samples/s | 66.7 steps/s
[Step=63150 Epoch=595.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.249 | L2-Norm(final)=9.517 | 2420.8 samples/s | 37.8 steps/s
[Step=63200 Epoch=595.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.246 | L2-Norm(final)=9.517 | 4219.8 samples/s | 65.9 steps/s
[Step=63250 Epoch=596.0] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.243 | L2-Norm(final)=9.518 | 2712.3 samples/s | 42.4 steps/s
[Step=63300 Epoch=596.5] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.240 | L2-Norm(final)=9.519 | 3665.8 samples/s | 57.3 steps/s
[Step=63350 Epoch=596.9] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.237 | L2-Norm(final)=9.520 | 6268.5 samples/s | 97.9 steps/s
[Step=63400 Epoch=597.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.234 | L2-Norm(final)=9.521 | 2013.7 samples/s | 31.5 steps/s
[Step=63450 Epoch=597.9] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.230 | L2-Norm(final)=9.521 | 5642.4 samples/s | 88.2 steps/s
[Step=63500 Epoch=598.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=9.522 | 2129.3 samples/s | 33.3 steps/s
[Step=63550 Epoch=598.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.223 | L2-Norm(final)=9.523 | 4935.0 samples/s | 77.1 steps/s
[Step=63600 Epoch=599.3] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.220 | L2-Norm(final)=9.524 | 2193.5 samples/s | 34.3 steps/s
[Step=63650 Epoch=599.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=9.524 | 4529.6 samples/s | 70.8 steps/s
[Step=63700 Epoch=600.2] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.213 | L2-Norm(final)=9.525 | 2310.2 samples/s | 36.1 steps/s
[Step=63750 Epoch=600.7] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.209 | L2-Norm(final)=9.526 | 4191.2 samples/s | 65.5 steps/s
[Step=63800 Epoch=601.2] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.205 | L2-Norm(final)=9.527 | 2371.8 samples/s | 37.1 steps/s
[Step=63850 Epoch=601.6] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.201 | L2-Norm(final)=9.527 | 4295.5 samples/s | 67.1 steps/s
[Step=63900 Epoch=602.1] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.197 | L2-Norm(final)=9.528 | 2372.4 samples/s | 37.1 steps/s
[Step=63950 Epoch=602.6] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.193 | L2-Norm(final)=9.529 | 4162.9 samples/s | 65.0 steps/s
[Step=64000 Epoch=603.1] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.189 | L2-Norm(final)=9.530 | 2546.3 samples/s | 39.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step64000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=590.9] | Loss=0.00010 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.235 | L2-Norm(final)=9.804 | 5200.8 samples/s | 81.3 steps/s
[Step=62050 Epoch=591.4] | Loss=0.00005 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.237 | L2-Norm(final)=9.808 | 3984.7 samples/s | 62.3 steps/s
[Step=62100 Epoch=591.9] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.240 | L2-Norm(final)=9.813 | 7466.6 samples/s | 116.7 steps/s
[Step=62150 Epoch=592.3] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.243 | L2-Norm(final)=9.818 | 2114.5 samples/s | 33.0 steps/s
[Step=62200 Epoch=592.8] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.246 | L2-Norm(final)=9.823 | 6529.9 samples/s | 102.0 steps/s
[Step=62250 Epoch=593.3] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.248 | L2-Norm(final)=9.827 | 2179.7 samples/s | 34.1 steps/s
[Step=62300 Epoch=593.8] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.250 | L2-Norm(final)=9.831 | 6249.5 samples/s | 97.6 steps/s
[Step=62350 Epoch=594.3] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.252 | L2-Norm(final)=9.836 | 2283.9 samples/s | 35.7 steps/s
[Step=62400 Epoch=594.7] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.253 | L2-Norm(final)=9.840 | 5672.3 samples/s | 88.6 steps/s
[Step=62450 Epoch=595.2] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.254 | L2-Norm(final)=9.844 | 2319.1 samples/s | 36.2 steps/s
[Step=62500 Epoch=595.7] | Loss=0.00003 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.256 | L2-Norm(final)=9.848 | 5150.4 samples/s | 80.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=595.7] | Loss=0.00004 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.266 | L2-Norm(final)=9.886 | 5604.1 samples/s | 87.6 steps/s
[Step=62550 Epoch=596.2] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.266 | L2-Norm(final)=9.890 | 3700.5 samples/s | 57.8 steps/s
[Step=62600 Epoch=596.6] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=9.893 | 6162.3 samples/s | 96.3 steps/s
[Step=62650 Epoch=597.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.259 | L2-Norm(final)=9.895 | 2007.0 samples/s | 31.4 steps/s
[Step=62700 Epoch=597.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.255 | L2-Norm(final)=9.897 | 5845.1 samples/s | 91.3 steps/s
[Step=62750 Epoch=598.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.250 | L2-Norm(final)=9.898 | 2058.8 samples/s | 32.2 steps/s
[Step=62800 Epoch=598.5] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.244 | L2-Norm(final)=9.900 | 5324.5 samples/s | 83.2 steps/s
[Step=62850 Epoch=599.0] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.239 | L2-Norm(final)=9.901 | 2139.4 samples/s | 33.4 steps/s
[Step=62900 Epoch=599.5] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.233 | L2-Norm(final)=9.902 | 4975.0 samples/s | 77.7 steps/s
[Step=62950 Epoch=600.0] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=9.903 | 2218.9 samples/s | 34.7 steps/s
[Step=63000 Epoch=600.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.221 | L2-Norm(final)=9.904 | 4661.9 samples/s | 72.8 steps/s
[Step=63050 Epoch=600.9] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.215 | L2-Norm(final)=9.905 | 2282.0 samples/s | 35.7 steps/s
[Step=63100 Epoch=601.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.209 | L2-Norm(final)=9.906 | 4295.7 samples/s | 67.1 steps/s
[Step=63150 Epoch=601.9] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.203 | L2-Norm(final)=9.906 | 2371.1 samples/s | 37.0 steps/s
[Step=63200 Epoch=602.4] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.197 | L2-Norm(final)=9.907 | 4352.2 samples/s | 68.0 steps/s
[Step=63250 Epoch=602.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.190 | L2-Norm(final)=9.908 | 2372.1 samples/s | 37.1 steps/s
[Step=63300 Epoch=603.3] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.184 | L2-Norm(final)=9.909 | 4185.5 samples/s | 65.4 steps/s
[Step=63350 Epoch=603.8] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.177 | L2-Norm(final)=9.910 | 2376.7 samples/s | 37.1 steps/s
[Step=63400 Epoch=604.3] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.911 | 4264.8 samples/s | 66.6 steps/s
[Step=63450 Epoch=604.7] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.164 | L2-Norm(final)=9.911 | 2409.7 samples/s | 37.7 steps/s
[Step=63500 Epoch=605.2] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=9.912 | 4200.7 samples/s | 65.6 steps/s
[Step=63550 Epoch=605.7] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.150 | L2-Norm(final)=9.913 | 6928.1 samples/s | 108.3 steps/s
[Step=63600 Epoch=606.2] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.143 | L2-Norm(final)=9.914 | 1962.1 samples/s | 30.7 steps/s
[Step=63650 Epoch=606.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.136 | L2-Norm(final)=9.915 | 6342.8 samples/s | 99.1 steps/s
[Step=63700 Epoch=607.1] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.129 | L2-Norm(final)=9.916 | 1993.4 samples/s | 31.1 steps/s
[Step=63750 Epoch=607.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=9.916 | 5728.6 samples/s | 89.5 steps/s
[Step=63800 Epoch=608.1] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.114 | L2-Norm(final)=9.917 | 2076.3 samples/s | 32.4 steps/s
[Step=63850 Epoch=608.5] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.107 | L2-Norm(final)=9.918 | 5370.3 samples/s | 83.9 steps/s
[Step=63900 Epoch=609.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=9.919 | 2127.1 samples/s | 33.2 steps/s
[Step=63950 Epoch=609.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=9.920 | 4898.5 samples/s | 76.5 steps/s
[Step=64000 Epoch=610.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.084 | L2-Norm(final)=9.921 | 2204.5 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10907 | acc=0.9574 | tpr=0.9673 | fpr=0.0639 | 4684.4 samples/s | 18.3 steps/s
Avg test loss: 0.11360, Avg test acc: 0.95625, Avg tpr: 0.96637, Avg fpr: 0.06602, total FA: 515

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11193 | acc=0.9560 | tpr=0.9658 | fpr=0.0652 | 4795.7 samples/s | 18.7 steps/s
Avg test loss: 0.11333, Avg test acc: 0.95605, Avg tpr: 0.96515, Avg fpr: 0.06397, total FA: 499

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11060 | acc=0.9596 | tpr=0.9749 | fpr=0.0736 | 4672.5 samples/s | 18.3 steps/s
Avg test loss: 0.11296, Avg test acc: 0.95853, Avg tpr: 0.97342, Avg fpr: 0.07422, total FA: 579

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10427 | acc=0.9608 | tpr=0.9698 | fpr=0.0587 | 4817.5 samples/s | 18.8 steps/s
Avg test loss: 0.10998, Avg test acc: 0.95909, Avg tpr: 0.96934, Avg fpr: 0.06345, total FA: 495

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10570 | acc=0.9584 | tpr=0.9684 | fpr=0.0634 | 4893.4 samples/s | 19.1 steps/s
Avg test loss: 0.11282, Avg test acc: 0.95793, Avg tpr: 0.96818, Avg fpr: 0.06461, total FA: 504

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.29794 | acc=0.3023 | tpr=0.0098 | fpr=0.0624 | 4735.5 samples/s | 18.5 steps/s
Avg test loss: 5.30546, Avg test acc: 0.30175, Avg tpr: 0.01107, Avg fpr: 0.05897, total FA: 460

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.66056 | acc=0.2979 | tpr=0.0056 | fpr=0.0674 | 4778.2 samples/s | 18.7 steps/s
Avg test loss: 4.67491, Avg test acc: 0.29461, Avg tpr: 0.00548, Avg fpr: 0.06948, total FA: 542

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.33606 | acc=0.2873 | tpr=0.0153 | fpr=0.1222 | 4735.2 samples/s | 18.5 steps/s
Avg test loss: 5.33578, Avg test acc: 0.28404, Avg tpr: 0.01562, Avg fpr: 0.12562, total FA: 980

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.56169 | acc=0.2945 | tpr=0.0180 | fpr=0.1053 | 4646.4 samples/s | 18.2 steps/s
Avg test loss: 5.55584, Avg test acc: 0.29337, Avg tpr: 0.01964, Avg fpr: 0.10460, total FA: 816

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.79902 | acc=0.3034 | tpr=0.0170 | fpr=0.0746 | 4938.7 samples/s | 19.3 steps/s
Avg test loss: 4.80507, Avg test acc: 0.30187, Avg tpr: 0.01813, Avg fpr: 0.07409, total FA: 578

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.95088 | acc=0.1103 | tpr=0.5575 | fpr=0.8977 | 4830.9 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.91616 | acc=0.1120 | tpr=0.5480 | fpr=0.8961 | 6862.7 samples/s | 26.8 steps/s
[Step= 150] | Loss=5.92848 | acc=0.1123 | tpr=0.5476 | fpr=0.8957 | 8069.4 samples/s | 31.5 steps/s
[Step= 200] | Loss=5.92340 | acc=0.1118 | tpr=0.5377 | fpr=0.8960 | 7707.5 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.92526 | acc=0.1129 | tpr=0.5432 | fpr=0.8950 | 7849.8 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.92013 | acc=0.1131 | tpr=0.5505 | fpr=0.8949 | 7808.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.91216 | acc=0.1132 | tpr=0.5479 | fpr=0.8947 | 8076.8 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.90865 | acc=0.1135 | tpr=0.5443 | fpr=0.8944 | 7909.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.91267 | acc=0.1139 | tpr=0.5389 | fpr=0.8938 | 7819.4 samples/s | 30.5 steps/s
[Step= 500] | Loss=5.91470 | acc=0.1139 | tpr=0.5348 | fpr=0.8937 | 7741.6 samples/s | 30.2 steps/s
[Step= 550] | Loss=5.91825 | acc=0.1136 | tpr=0.5316 | fpr=0.8940 | 14339.5 samples/s | 56.0 steps/s
Avg test loss: 5.92035, Avg test acc: 0.11351, Avg tpr: 0.53170, Avg fpr: 0.89409, total FA: 124143

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.09962 | acc=0.1148 | tpr=0.4425 | fpr=0.8910 | 4740.3 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.07918 | acc=0.1163 | tpr=0.4563 | fpr=0.8901 | 7185.9 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.07830 | acc=0.1163 | tpr=0.4683 | fpr=0.8902 | 7965.2 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.07161 | acc=0.1163 | tpr=0.4623 | fpr=0.8900 | 7895.5 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.07614 | acc=0.1164 | tpr=0.4611 | fpr=0.8899 | 7597.2 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.07111 | acc=0.1164 | tpr=0.4691 | fpr=0.8900 | 7899.0 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.06634 | acc=0.1165 | tpr=0.4665 | fpr=0.8899 | 8035.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.06186 | acc=0.1167 | tpr=0.4633 | fpr=0.8896 | 7862.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.06697 | acc=0.1166 | tpr=0.4620 | fpr=0.8896 | 7984.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.07032 | acc=0.1165 | tpr=0.4599 | fpr=0.8897 | 7882.3 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.07467 | acc=0.1163 | tpr=0.4572 | fpr=0.8899 | 13688.9 samples/s | 53.5 steps/s
Avg test loss: 5.07705, Avg test acc: 0.11616, Avg tpr: 0.45642, Avg fpr: 0.89002, total FA: 123578

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.37083 | acc=0.0820 | tpr=0.3628 | fpr=0.9231 | 4885.8 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.33893 | acc=0.0832 | tpr=0.3838 | fpr=0.9224 | 7039.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.35081 | acc=0.0841 | tpr=0.3934 | fpr=0.9216 | 7674.2 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.34583 | acc=0.0845 | tpr=0.3923 | fpr=0.9211 | 7846.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.34548 | acc=0.0850 | tpr=0.3983 | fpr=0.9207 | 7793.6 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.34202 | acc=0.0854 | tpr=0.4044 | fpr=0.9204 | 7827.2 samples/s | 30.6 steps/s
[Step= 350] | Loss=6.33554 | acc=0.0858 | tpr=0.4020 | fpr=0.9199 | 7794.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=6.32945 | acc=0.0861 | tpr=0.4037 | fpr=0.9196 | 8095.3 samples/s | 31.6 steps/s
[Step= 450] | Loss=6.33336 | acc=0.0864 | tpr=0.3997 | fpr=0.9193 | 7953.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=6.33509 | acc=0.0861 | tpr=0.3987 | fpr=0.9195 | 7961.5 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.33878 | acc=0.0858 | tpr=0.3987 | fpr=0.9199 | 13367.5 samples/s | 52.2 steps/s
Avg test loss: 6.34021, Avg test acc: 0.08564, Avg tpr: 0.39937, Avg fpr: 0.92006, total FA: 127749

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.38536 | acc=0.1268 | tpr=0.4735 | fpr=0.8794 | 4887.3 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.36405 | acc=0.1271 | tpr=0.4712 | fpr=0.8794 | 6975.3 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.37661 | acc=0.1258 | tpr=0.4827 | fpr=0.8808 | 7565.5 samples/s | 29.6 steps/s
[Step= 200] | Loss=5.36624 | acc=0.1254 | tpr=0.4831 | fpr=0.8811 | 7969.8 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.37010 | acc=0.1263 | tpr=0.4882 | fpr=0.8802 | 7900.2 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.36889 | acc=0.1262 | tpr=0.4967 | fpr=0.8806 | 7947.9 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.35891 | acc=0.1261 | tpr=0.4941 | fpr=0.8806 | 7722.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.35204 | acc=0.1263 | tpr=0.4912 | fpr=0.8803 | 7763.5 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.35737 | acc=0.1264 | tpr=0.4898 | fpr=0.8802 | 8062.0 samples/s | 31.5 steps/s
[Step= 500] | Loss=5.35831 | acc=0.1261 | tpr=0.4863 | fpr=0.8804 | 7514.5 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.36253 | acc=0.1260 | tpr=0.4831 | fpr=0.8805 | 15387.9 samples/s | 60.1 steps/s
Avg test loss: 5.36346, Avg test acc: 0.12585, Avg tpr: 0.48296, Avg fpr: 0.88065, total FA: 122276

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.76808 | acc=0.1236 | tpr=0.4602 | fpr=0.8825 | 4650.5 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.74402 | acc=0.1251 | tpr=0.4584 | fpr=0.8811 | 7360.2 samples/s | 28.8 steps/s
[Step= 150] | Loss=5.74272 | acc=0.1263 | tpr=0.4683 | fpr=0.8800 | 7737.2 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.74105 | acc=0.1258 | tpr=0.4437 | fpr=0.8799 | 8249.5 samples/s | 32.2 steps/s
[Step= 250] | Loss=5.74696 | acc=0.1270 | tpr=0.4524 | fpr=0.8789 | 7657.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.74762 | acc=0.1268 | tpr=0.4582 | fpr=0.8792 | 7394.8 samples/s | 28.9 steps/s
[Step= 350] | Loss=5.73860 | acc=0.1271 | tpr=0.4571 | fpr=0.8788 | 7935.5 samples/s | 31.0 steps/s
[Step= 400] | Loss=5.73524 | acc=0.1274 | tpr=0.4573 | fpr=0.8786 | 7727.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.73894 | acc=0.1277 | tpr=0.4528 | fpr=0.8782 | 8402.6 samples/s | 32.8 steps/s
[Step= 500] | Loss=5.74166 | acc=0.1275 | tpr=0.4493 | fpr=0.8783 | 7494.8 samples/s | 29.3 steps/s
[Step= 550] | Loss=5.74603 | acc=0.1272 | tpr=0.4501 | fpr=0.8787 | 14224.3 samples/s | 55.6 steps/s
Avg test loss: 5.74824, Avg test acc: 0.12704, Avg tpr: 0.44929, Avg fpr: 0.87882, total FA: 122022

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08152 | acc=0.9826 | tpr=0.9292 | fpr=0.0165 | 4601.4 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.08466 | acc=0.9824 | tpr=0.9403 | fpr=0.0168 | 7475.8 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.08786 | acc=0.9817 | tpr=0.9409 | fpr=0.0175 | 7693.8 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.08906 | acc=0.9818 | tpr=0.9486 | fpr=0.0176 | 8024.7 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.08708 | acc=0.9820 | tpr=0.9424 | fpr=0.0173 | 8038.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.08935 | acc=0.9815 | tpr=0.9404 | fpr=0.0177 | 7599.0 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.09049 | acc=0.9812 | tpr=0.9405 | fpr=0.0180 | 7958.5 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09137 | acc=0.9810 | tpr=0.9376 | fpr=0.0182 | 7781.0 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.09295 | acc=0.9807 | tpr=0.9357 | fpr=0.0185 | 7816.5 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.09214 | acc=0.9809 | tpr=0.9366 | fpr=0.0183 | 8110.9 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.09173 | acc=0.9810 | tpr=0.9343 | fpr=0.0182 | 13805.7 samples/s | 53.9 steps/s
Avg test loss: 0.09164, Avg test acc: 0.98101, Avg tpr: 0.93423, Avg fpr: 0.01814, total FA: 2519

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08619 | acc=0.9821 | tpr=0.9381 | fpr=0.0171 | 4641.9 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.08920 | acc=0.9822 | tpr=0.9339 | fpr=0.0169 | 7399.1 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.09231 | acc=0.9818 | tpr=0.9337 | fpr=0.0173 | 7973.2 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09429 | acc=0.9817 | tpr=0.9366 | fpr=0.0175 | 7658.4 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.09264 | acc=0.9819 | tpr=0.9354 | fpr=0.0172 | 7759.0 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.09481 | acc=0.9816 | tpr=0.9324 | fpr=0.0175 | 8086.1 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.09540 | acc=0.9815 | tpr=0.9361 | fpr=0.0177 | 7937.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.09668 | acc=0.9812 | tpr=0.9305 | fpr=0.0178 | 7477.2 samples/s | 29.2 steps/s
[Step= 450] | Loss=0.09885 | acc=0.9811 | tpr=0.9294 | fpr=0.0180 | 7990.6 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.09802 | acc=0.9811 | tpr=0.9317 | fpr=0.0180 | 8016.7 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.09785 | acc=0.9812 | tpr=0.9296 | fpr=0.0179 | 13594.1 samples/s | 53.1 steps/s
Avg test loss: 0.09774, Avg test acc: 0.98119, Avg tpr: 0.92987, Avg fpr: 0.01788, total FA: 2482

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08811 | acc=0.9819 | tpr=0.9602 | fpr=0.0177 | 5036.4 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.09003 | acc=0.9819 | tpr=0.9638 | fpr=0.0177 | 6937.8 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.09400 | acc=0.9811 | tpr=0.9597 | fpr=0.0185 | 7409.2 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.09536 | acc=0.9811 | tpr=0.9639 | fpr=0.0186 | 7787.3 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.09372 | acc=0.9813 | tpr=0.9633 | fpr=0.0183 | 7692.0 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.09595 | acc=0.9809 | tpr=0.9578 | fpr=0.0187 | 7704.3 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.09675 | acc=0.9806 | tpr=0.9593 | fpr=0.0190 | 8236.9 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.09781 | acc=0.9804 | tpr=0.9568 | fpr=0.0192 | 7692.2 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.09962 | acc=0.9801 | tpr=0.9562 | fpr=0.0194 | 8084.4 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.09896 | acc=0.9801 | tpr=0.9573 | fpr=0.0194 | 7778.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.09856 | acc=0.9803 | tpr=0.9562 | fpr=0.0192 | 13794.0 samples/s | 53.9 steps/s
Avg test loss: 0.09845, Avg test acc: 0.98031, Avg tpr: 0.95642, Avg fpr: 0.01925, total FA: 2673

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09760 | acc=0.9800 | tpr=0.9469 | fpr=0.0194 | 4814.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.10080 | acc=0.9798 | tpr=0.9531 | fpr=0.0197 | 6938.4 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.10526 | acc=0.9789 | tpr=0.9510 | fpr=0.0206 | 7562.2 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.10622 | acc=0.9792 | tpr=0.9563 | fpr=0.0204 | 8145.3 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.10457 | acc=0.9798 | tpr=0.9581 | fpr=0.0198 | 7869.4 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.10675 | acc=0.9796 | tpr=0.9535 | fpr=0.0199 | 7824.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.10749 | acc=0.9794 | tpr=0.9530 | fpr=0.0202 | 7779.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10810 | acc=0.9792 | tpr=0.9497 | fpr=0.0203 | 8103.8 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.11019 | acc=0.9790 | tpr=0.9469 | fpr=0.0204 | 7739.3 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.10942 | acc=0.9791 | tpr=0.9480 | fpr=0.0204 | 7874.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.10893 | acc=0.9793 | tpr=0.9475 | fpr=0.0202 | 13767.1 samples/s | 53.8 steps/s
Avg test loss: 0.10873, Avg test acc: 0.97928, Avg tpr: 0.94770, Avg fpr: 0.02014, total FA: 2797

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09405 | acc=0.9820 | tpr=0.9336 | fpr=0.0172 | 5083.6 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.09927 | acc=0.9810 | tpr=0.9360 | fpr=0.0181 | 6784.3 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.10265 | acc=0.9802 | tpr=0.9366 | fpr=0.0190 | 7637.9 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.10456 | acc=0.9801 | tpr=0.9432 | fpr=0.0193 | 7752.3 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.10296 | acc=0.9805 | tpr=0.9397 | fpr=0.0188 | 7484.7 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.10541 | acc=0.9801 | tpr=0.9353 | fpr=0.0191 | 7862.9 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10598 | acc=0.9800 | tpr=0.9380 | fpr=0.0193 | 8151.1 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.10737 | acc=0.9798 | tpr=0.9354 | fpr=0.0194 | 7878.2 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.10964 | acc=0.9795 | tpr=0.9338 | fpr=0.0196 | 7984.6 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10889 | acc=0.9796 | tpr=0.9344 | fpr=0.0196 | 7990.4 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.10856 | acc=0.9798 | tpr=0.9335 | fpr=0.0194 | 13440.8 samples/s | 52.5 steps/s
Avg test loss: 0.10839, Avg test acc: 0.97982, Avg tpr: 0.93344, Avg fpr: 0.01934, total FA: 2685

server round 32/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=312.1] | Loss=0.00248 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.556 | L2-Norm(final)=16.973 | 5798.5 samples/s | 90.6 steps/s
[Step=64050 Epoch=312.3] | Loss=0.00245 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=16.980 | 4370.2 samples/s | 68.3 steps/s
[Step=64100 Epoch=312.6] | Loss=0.00271 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=16.989 | 4970.9 samples/s | 77.7 steps/s
[Step=64150 Epoch=312.8] | Loss=0.00292 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=16.998 | 5072.5 samples/s | 79.3 steps/s
[Step=64200 Epoch=313.1] | Loss=0.00293 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=17.006 | 7691.9 samples/s | 120.2 steps/s
[Step=64250 Epoch=313.3] | Loss=0.00298 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=17.014 | 2246.3 samples/s | 35.1 steps/s
[Step=64300 Epoch=313.5] | Loss=0.00286 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=17.022 | 4961.3 samples/s | 77.5 steps/s
[Step=64350 Epoch=313.8] | Loss=0.00275 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.567 | L2-Norm(final)=17.031 | 4993.7 samples/s | 78.0 steps/s
[Step=64400 Epoch=314.0] | Loss=0.00277 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.568 | L2-Norm(final)=17.039 | 6852.7 samples/s | 107.1 steps/s
[Step=64450 Epoch=314.3] | Loss=0.00278 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.569 | L2-Norm(final)=17.047 | 2293.0 samples/s | 35.8 steps/s
[Step=64500 Epoch=314.5] | Loss=0.00277 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.570 | L2-Norm(final)=17.055 | 5106.3 samples/s | 79.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=314.5] | Loss=0.01068 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.582 | L2-Norm(final)=17.136 | 5616.3 samples/s | 87.8 steps/s
[Step=64550 Epoch=314.8] | Loss=0.00224 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=17.143 | 3865.8 samples/s | 60.4 steps/s
[Step=64600 Epoch=315.0] | Loss=0.00315 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=17.151 | 4520.6 samples/s | 70.6 steps/s
[Step=64650 Epoch=315.2] | Loss=0.00396 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.592 | L2-Norm(final)=17.157 | 4380.5 samples/s | 68.4 steps/s
[Step=64700 Epoch=315.5] | Loss=0.00409 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=17.164 | 6487.1 samples/s | 101.4 steps/s
[Step=64750 Epoch=315.7] | Loss=0.00396 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.600 | L2-Norm(final)=17.170 | 2090.9 samples/s | 32.7 steps/s
[Step=64800 Epoch=316.0] | Loss=0.00367 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=17.176 | 4457.9 samples/s | 69.7 steps/s
[Step=64850 Epoch=316.2] | Loss=0.00365 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.604 | L2-Norm(final)=17.182 | 4462.9 samples/s | 69.7 steps/s
[Step=64900 Epoch=316.5] | Loss=0.00377 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=17.187 | 5912.0 samples/s | 92.4 steps/s
[Step=64950 Epoch=316.7] | Loss=0.00376 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=17.192 | 2125.9 samples/s | 33.2 steps/s
[Step=65000 Epoch=317.0] | Loss=0.00370 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=17.197 | 4476.9 samples/s | 70.0 steps/s
[Step=65050 Epoch=317.2] | Loss=0.00349 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.608 | L2-Norm(final)=17.201 | 4459.0 samples/s | 69.7 steps/s
[Step=65100 Epoch=317.4] | Loss=0.00334 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.609 | L2-Norm(final)=17.206 | 5407.1 samples/s | 84.5 steps/s
[Step=65150 Epoch=317.7] | Loss=0.00323 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.609 | L2-Norm(final)=17.210 | 2207.6 samples/s | 34.5 steps/s
[Step=65200 Epoch=317.9] | Loss=0.00316 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.609 | L2-Norm(final)=17.214 | 4465.3 samples/s | 69.8 steps/s
[Step=65250 Epoch=318.2] | Loss=0.00316 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.608 | L2-Norm(final)=17.218 | 4451.7 samples/s | 69.6 steps/s
[Step=65300 Epoch=318.4] | Loss=0.00307 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.608 | L2-Norm(final)=17.222 | 4903.1 samples/s | 76.6 steps/s
[Step=65350 Epoch=318.7] | Loss=0.00302 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=17.225 | 2342.0 samples/s | 36.6 steps/s
[Step=65400 Epoch=318.9] | Loss=0.00297 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=17.229 | 4433.7 samples/s | 69.3 steps/s
[Step=65450 Epoch=319.1] | Loss=0.00298 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.605 | L2-Norm(final)=17.232 | 4464.1 samples/s | 69.8 steps/s
[Step=65500 Epoch=319.4] | Loss=0.00294 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.604 | L2-Norm(final)=17.236 | 4585.1 samples/s | 71.6 steps/s
[Step=65550 Epoch=319.6] | Loss=0.00288 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.603 | L2-Norm(final)=17.239 | 2387.9 samples/s | 37.3 steps/s
[Step=65600 Epoch=319.9] | Loss=0.00287 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=17.242 | 4402.1 samples/s | 68.8 steps/s
[Step=65650 Epoch=320.1] | Loss=0.00286 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=17.246 | 4427.6 samples/s | 69.2 steps/s
[Step=65700 Epoch=320.4] | Loss=0.00285 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.600 | L2-Norm(final)=17.249 | 4436.5 samples/s | 69.3 steps/s
[Step=65750 Epoch=320.6] | Loss=0.00281 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.598 | L2-Norm(final)=17.252 | 2456.2 samples/s | 38.4 steps/s
[Step=65800 Epoch=320.9] | Loss=0.00277 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=17.255 | 4446.0 samples/s | 69.5 steps/s
[Step=65850 Epoch=321.1] | Loss=0.00272 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.596 | L2-Norm(final)=17.258 | 4473.0 samples/s | 69.9 steps/s
[Step=65900 Epoch=321.3] | Loss=0.00270 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.594 | L2-Norm(final)=17.262 | 4442.5 samples/s | 69.4 steps/s
[Step=65950 Epoch=321.6] | Loss=0.00270 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=17.265 | 2439.1 samples/s | 38.1 steps/s
[Step=66000 Epoch=321.8] | Loss=0.00264 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=17.268 | 4447.0 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step66000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=312.3] | Loss=0.00827 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.224 | L2-Norm(final)=17.550 | 5233.3 samples/s | 81.8 steps/s
[Step=64050 Epoch=312.5] | Loss=0.00248 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=17.559 | 4786.9 samples/s | 74.8 steps/s
[Step=64100 Epoch=312.8] | Loss=0.00291 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.227 | L2-Norm(final)=17.568 | 4983.0 samples/s | 77.9 steps/s
[Step=64150 Epoch=313.0] | Loss=0.00283 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.228 | L2-Norm(final)=17.577 | 5075.7 samples/s | 79.3 steps/s
[Step=64200 Epoch=313.3] | Loss=0.00263 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.229 | L2-Norm(final)=17.585 | 7777.5 samples/s | 121.5 steps/s
[Step=64250 Epoch=313.5] | Loss=0.00256 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=17.594 | 2207.5 samples/s | 34.5 steps/s
[Step=64300 Epoch=313.8] | Loss=0.00253 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=17.602 | 4767.8 samples/s | 74.5 steps/s
[Step=64350 Epoch=314.0] | Loss=0.00244 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.231 | L2-Norm(final)=17.611 | 5038.7 samples/s | 78.7 steps/s
[Step=64400 Epoch=314.2] | Loss=0.00244 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.232 | L2-Norm(final)=17.619 | 7084.0 samples/s | 110.7 steps/s
[Step=64450 Epoch=314.5] | Loss=0.00242 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.232 | L2-Norm(final)=17.628 | 2280.8 samples/s | 35.6 steps/s
[Step=64500 Epoch=314.7] | Loss=0.00242 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=17.636 | 5108.1 samples/s | 79.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=314.7] | Loss=0.00047 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=17.720 | 5519.6 samples/s | 86.2 steps/s
[Step=64550 Epoch=315.0] | Loss=0.00287 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=17.727 | 4105.9 samples/s | 64.2 steps/s
[Step=64600 Epoch=315.2] | Loss=0.00341 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=17.736 | 4430.1 samples/s | 69.2 steps/s
[Step=64650 Epoch=315.5] | Loss=0.00343 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.249 | L2-Norm(final)=17.743 | 4312.3 samples/s | 67.4 steps/s
[Step=64700 Epoch=315.7] | Loss=0.00370 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.253 | L2-Norm(final)=17.750 | 6487.0 samples/s | 101.4 steps/s
[Step=64750 Epoch=315.9] | Loss=0.00360 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=17.756 | 2087.0 samples/s | 32.6 steps/s
[Step=64800 Epoch=316.2] | Loss=0.00351 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=17.762 | 4489.9 samples/s | 70.2 steps/s
[Step=64850 Epoch=316.4] | Loss=0.00334 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=17.768 | 4588.2 samples/s | 71.7 steps/s
[Step=64900 Epoch=316.7] | Loss=0.00331 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.262 | L2-Norm(final)=17.774 | 5859.7 samples/s | 91.6 steps/s
[Step=64950 Epoch=316.9] | Loss=0.00337 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=17.779 | 2144.2 samples/s | 33.5 steps/s
[Step=65000 Epoch=317.2] | Loss=0.00323 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.264 | L2-Norm(final)=17.785 | 4406.3 samples/s | 68.8 steps/s
[Step=65050 Epoch=317.4] | Loss=0.00314 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=17.789 | 4483.3 samples/s | 70.1 steps/s
[Step=65100 Epoch=317.7] | Loss=0.00304 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=17.794 | 5599.8 samples/s | 87.5 steps/s
[Step=65150 Epoch=317.9] | Loss=0.00296 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.266 | L2-Norm(final)=17.799 | 2220.0 samples/s | 34.7 steps/s
[Step=65200 Epoch=318.1] | Loss=0.00288 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.266 | L2-Norm(final)=17.804 | 4514.7 samples/s | 70.5 steps/s
[Step=65250 Epoch=318.4] | Loss=0.00279 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.266 | L2-Norm(final)=17.808 | 4452.2 samples/s | 69.6 steps/s
[Step=65300 Epoch=318.6] | Loss=0.00277 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=17.812 | 5210.7 samples/s | 81.4 steps/s
[Step=65350 Epoch=318.9] | Loss=0.00273 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=17.816 | 2270.0 samples/s | 35.5 steps/s
[Step=65400 Epoch=319.1] | Loss=0.00272 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.264 | L2-Norm(final)=17.821 | 4464.7 samples/s | 69.8 steps/s
[Step=65450 Epoch=319.4] | Loss=0.00270 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=17.824 | 4568.9 samples/s | 71.4 steps/s
[Step=65500 Epoch=319.6] | Loss=0.00270 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=17.828 | 4779.3 samples/s | 74.7 steps/s
[Step=65550 Epoch=319.9] | Loss=0.00263 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=17.832 | 2337.6 samples/s | 36.5 steps/s
[Step=65600 Epoch=320.1] | Loss=0.00258 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=17.836 | 4564.7 samples/s | 71.3 steps/s
[Step=65650 Epoch=320.3] | Loss=0.00256 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=17.839 | 4418.1 samples/s | 69.0 steps/s
[Step=65700 Epoch=320.6] | Loss=0.00250 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=17.843 | 4496.6 samples/s | 70.3 steps/s
[Step=65750 Epoch=320.8] | Loss=0.00246 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=17.846 | 2430.6 samples/s | 38.0 steps/s
[Step=65800 Epoch=321.1] | Loss=0.00241 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.255 | L2-Norm(final)=17.850 | 4533.3 samples/s | 70.8 steps/s
[Step=65850 Epoch=321.3] | Loss=0.00239 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.253 | L2-Norm(final)=17.853 | 4562.1 samples/s | 71.3 steps/s
[Step=65900 Epoch=321.6] | Loss=0.00238 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=17.856 | 4382.1 samples/s | 68.5 steps/s
[Step=65950 Epoch=321.8] | Loss=0.00237 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=17.860 | 2489.8 samples/s | 38.9 steps/s
[Step=66000 Epoch=322.0] | Loss=0.00233 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.248 | L2-Norm(final)=17.863 | 4490.2 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step66000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=311.8] | Loss=0.00082 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=17.762 | 5169.9 samples/s | 80.8 steps/s
[Step=64050 Epoch=312.1] | Loss=0.00239 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=17.770 | 4498.4 samples/s | 70.3 steps/s
[Step=64100 Epoch=312.3] | Loss=0.00272 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.949 | L2-Norm(final)=17.779 | 5038.5 samples/s | 78.7 steps/s
[Step=64150 Epoch=312.6] | Loss=0.00285 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=17.788 | 5052.7 samples/s | 78.9 steps/s
[Step=64200 Epoch=312.8] | Loss=0.00282 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=17.798 | 7917.9 samples/s | 123.7 steps/s
[Step=64250 Epoch=313.1] | Loss=0.00271 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.952 | L2-Norm(final)=17.807 | 2219.5 samples/s | 34.7 steps/s
[Step=64300 Epoch=313.3] | Loss=0.00278 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.953 | L2-Norm(final)=17.816 | 5059.2 samples/s | 79.1 steps/s
[Step=64350 Epoch=313.5] | Loss=0.00267 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=17.826 | 5130.4 samples/s | 80.2 steps/s
[Step=64400 Epoch=313.8] | Loss=0.00269 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=17.835 | 6739.3 samples/s | 105.3 steps/s
[Step=64450 Epoch=314.0] | Loss=0.00271 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=17.844 | 2233.2 samples/s | 34.9 steps/s
[Step=64500 Epoch=314.3] | Loss=0.00270 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=17.853 | 5111.1 samples/s | 79.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=314.3] | Loss=0.00085 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=17.944 | 5212.3 samples/s | 81.4 steps/s
[Step=64550 Epoch=314.5] | Loss=0.00280 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.963 | L2-Norm(final)=17.953 | 4127.0 samples/s | 64.5 steps/s
[Step=64600 Epoch=314.8] | Loss=0.00379 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=17.961 | 4461.7 samples/s | 69.7 steps/s
[Step=64650 Epoch=315.0] | Loss=0.00440 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=17.969 | 4495.5 samples/s | 70.2 steps/s
[Step=64700 Epoch=315.2] | Loss=0.00423 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=17.977 | 6595.2 samples/s | 103.1 steps/s
[Step=64750 Epoch=315.5] | Loss=0.00428 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=17.985 | 2088.9 samples/s | 32.6 steps/s
[Step=64800 Epoch=315.7] | Loss=0.00438 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=17.992 | 4474.0 samples/s | 69.9 steps/s
[Step=64850 Epoch=316.0] | Loss=0.00411 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=17.998 | 4506.5 samples/s | 70.4 steps/s
[Step=64900 Epoch=316.2] | Loss=0.00396 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.993 | L2-Norm(final)=18.005 | 5881.4 samples/s | 91.9 steps/s
[Step=64950 Epoch=316.5] | Loss=0.00408 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=18.010 | 2142.7 samples/s | 33.5 steps/s
[Step=65000 Epoch=316.7] | Loss=0.00391 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=18.016 | 4448.0 samples/s | 69.5 steps/s
[Step=65050 Epoch=317.0] | Loss=0.00380 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=18.021 | 4439.8 samples/s | 69.4 steps/s
[Step=65100 Epoch=317.2] | Loss=0.00377 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.998 | L2-Norm(final)=18.026 | 5136.8 samples/s | 80.3 steps/s
[Step=65150 Epoch=317.4] | Loss=0.00363 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=18.031 | 2158.1 samples/s | 33.7 steps/s
[Step=65200 Epoch=317.7] | Loss=0.00359 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=18.035 | 4386.4 samples/s | 68.5 steps/s
[Step=65250 Epoch=317.9] | Loss=0.00351 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.000 | L2-Norm(final)=18.039 | 4470.6 samples/s | 69.9 steps/s
[Step=65300 Epoch=318.2] | Loss=0.00344 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.000 | L2-Norm(final)=18.044 | 4953.1 samples/s | 77.4 steps/s
[Step=65350 Epoch=318.4] | Loss=0.00338 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.999 | L2-Norm(final)=18.048 | 2331.5 samples/s | 36.4 steps/s
[Step=65400 Epoch=318.7] | Loss=0.00329 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=18.052 | 4473.3 samples/s | 69.9 steps/s
[Step=65450 Epoch=318.9] | Loss=0.00325 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.998 | L2-Norm(final)=18.055 | 4384.9 samples/s | 68.5 steps/s
[Step=65500 Epoch=319.1] | Loss=0.00316 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.997 | L2-Norm(final)=18.059 | 4605.7 samples/s | 72.0 steps/s
[Step=65550 Epoch=319.4] | Loss=0.00309 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.997 | L2-Norm(final)=18.063 | 2458.7 samples/s | 38.4 steps/s
[Step=65600 Epoch=319.6] | Loss=0.00301 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=18.067 | 4397.5 samples/s | 68.7 steps/s
[Step=65650 Epoch=319.9] | Loss=0.00294 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=18.070 | 4436.4 samples/s | 69.3 steps/s
[Step=65700 Epoch=320.1] | Loss=0.00293 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=18.074 | 4600.7 samples/s | 71.9 steps/s
[Step=65750 Epoch=320.4] | Loss=0.00289 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=18.077 | 2421.1 samples/s | 37.8 steps/s
[Step=65800 Epoch=320.6] | Loss=0.00285 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.991 | L2-Norm(final)=18.080 | 4412.4 samples/s | 68.9 steps/s
[Step=65850 Epoch=320.9] | Loss=0.00282 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=18.083 | 4441.7 samples/s | 69.4 steps/s
[Step=65900 Epoch=321.1] | Loss=0.00280 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=18.087 | 4480.7 samples/s | 70.0 steps/s
[Step=65950 Epoch=321.3] | Loss=0.00275 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=18.090 | 2439.8 samples/s | 38.1 steps/s
[Step=66000 Epoch=321.6] | Loss=0.00274 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.984 | L2-Norm(final)=18.093 | 4462.3 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step66000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=312.1] | Loss=0.00081 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.620 | L2-Norm(final)=17.739 | 5005.5 samples/s | 78.2 steps/s
[Step=64050 Epoch=312.3] | Loss=0.00223 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.620 | L2-Norm(final)=17.746 | 4508.4 samples/s | 70.4 steps/s
[Step=64100 Epoch=312.6] | Loss=0.00214 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.622 | L2-Norm(final)=17.756 | 4951.9 samples/s | 77.4 steps/s
[Step=64150 Epoch=312.8] | Loss=0.00229 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.624 | L2-Norm(final)=17.765 | 4973.3 samples/s | 77.7 steps/s
[Step=64200 Epoch=313.1] | Loss=0.00224 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.626 | L2-Norm(final)=17.775 | 7846.6 samples/s | 122.6 steps/s
[Step=64250 Epoch=313.3] | Loss=0.00243 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.628 | L2-Norm(final)=17.785 | 2209.4 samples/s | 34.5 steps/s
[Step=64300 Epoch=313.6] | Loss=0.00240 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.629 | L2-Norm(final)=17.795 | 4961.8 samples/s | 77.5 steps/s
[Step=64350 Epoch=313.8] | Loss=0.00236 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.630 | L2-Norm(final)=17.804 | 5023.0 samples/s | 78.5 steps/s
[Step=64400 Epoch=314.1] | Loss=0.00230 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.631 | L2-Norm(final)=17.813 | 6972.1 samples/s | 108.9 steps/s
[Step=64450 Epoch=314.3] | Loss=0.00224 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.632 | L2-Norm(final)=17.822 | 2284.1 samples/s | 35.7 steps/s
[Step=64500 Epoch=314.5] | Loss=0.00224 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.633 | L2-Norm(final)=17.831 | 5143.1 samples/s | 80.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=314.5] | Loss=0.00133 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.640 | L2-Norm(final)=17.919 | 5362.8 samples/s | 83.8 steps/s
[Step=64550 Epoch=314.8] | Loss=0.00223 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.643 | L2-Norm(final)=17.928 | 4114.4 samples/s | 64.3 steps/s
[Step=64600 Epoch=315.0] | Loss=0.00300 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.647 | L2-Norm(final)=17.937 | 4373.8 samples/s | 68.3 steps/s
[Step=64650 Epoch=315.3] | Loss=0.00345 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.655 | L2-Norm(final)=17.947 | 4471.2 samples/s | 69.9 steps/s
[Step=64700 Epoch=315.5] | Loss=0.00393 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.661 | L2-Norm(final)=17.954 | 6572.1 samples/s | 102.7 steps/s
[Step=64750 Epoch=315.8] | Loss=0.00394 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.666 | L2-Norm(final)=17.962 | 2089.9 samples/s | 32.7 steps/s
[Step=64800 Epoch=316.0] | Loss=0.00400 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.671 | L2-Norm(final)=17.969 | 4512.9 samples/s | 70.5 steps/s
[Step=64850 Epoch=316.2] | Loss=0.00379 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=17.975 | 4443.0 samples/s | 69.4 steps/s
[Step=64900 Epoch=316.5] | Loss=0.00368 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.677 | L2-Norm(final)=17.982 | 5857.2 samples/s | 91.5 steps/s
[Step=64950 Epoch=316.7] | Loss=0.00349 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.680 | L2-Norm(final)=17.987 | 2166.9 samples/s | 33.9 steps/s
[Step=65000 Epoch=317.0] | Loss=0.00338 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=17.993 | 4496.1 samples/s | 70.3 steps/s
[Step=65050 Epoch=317.2] | Loss=0.00327 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.683 | L2-Norm(final)=17.998 | 4451.9 samples/s | 69.6 steps/s
[Step=65100 Epoch=317.5] | Loss=0.00316 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.684 | L2-Norm(final)=18.003 | 5400.7 samples/s | 84.4 steps/s
[Step=65150 Epoch=317.7] | Loss=0.00303 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=18.007 | 2219.1 samples/s | 34.7 steps/s
[Step=65200 Epoch=318.0] | Loss=0.00289 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=18.012 | 4534.7 samples/s | 70.9 steps/s
[Step=65250 Epoch=318.2] | Loss=0.00284 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=18.016 | 4476.0 samples/s | 69.9 steps/s
[Step=65300 Epoch=318.4] | Loss=0.00276 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=18.020 | 4852.8 samples/s | 75.8 steps/s
[Step=65350 Epoch=318.7] | Loss=0.00272 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=18.024 | 2317.5 samples/s | 36.2 steps/s
[Step=65400 Epoch=318.9] | Loss=0.00262 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=18.028 | 4508.1 samples/s | 70.4 steps/s
[Step=65450 Epoch=319.2] | Loss=0.00255 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.683 | L2-Norm(final)=18.032 | 4434.7 samples/s | 69.3 steps/s
[Step=65500 Epoch=319.4] | Loss=0.00251 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.682 | L2-Norm(final)=18.035 | 4481.4 samples/s | 70.0 steps/s
[Step=65550 Epoch=319.7] | Loss=0.00247 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=18.039 | 2450.7 samples/s | 38.3 steps/s
[Step=65600 Epoch=319.9] | Loss=0.00244 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.680 | L2-Norm(final)=18.042 | 4424.1 samples/s | 69.1 steps/s
[Step=65650 Epoch=320.1] | Loss=0.00239 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.679 | L2-Norm(final)=18.046 | 4443.2 samples/s | 69.4 steps/s
[Step=65700 Epoch=320.4] | Loss=0.00234 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.677 | L2-Norm(final)=18.049 | 4466.2 samples/s | 69.8 steps/s
[Step=65750 Epoch=320.6] | Loss=0.00232 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=18.053 | 2489.6 samples/s | 38.9 steps/s
[Step=65800 Epoch=320.9] | Loss=0.00229 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=18.056 | 4415.6 samples/s | 69.0 steps/s
[Step=65850 Epoch=321.1] | Loss=0.00226 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.672 | L2-Norm(final)=18.059 | 4384.3 samples/s | 68.5 steps/s
[Step=65900 Epoch=321.4] | Loss=0.00222 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.671 | L2-Norm(final)=18.062 | 4470.9 samples/s | 69.9 steps/s
[Step=65950 Epoch=321.6] | Loss=0.00221 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=18.065 | 2458.2 samples/s | 38.4 steps/s
[Step=66000 Epoch=321.9] | Loss=0.00218 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.667 | L2-Norm(final)=18.068 | 4476.1 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step66000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=313.9] | Loss=0.00150 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=17.790 | 5116.1 samples/s | 79.9 steps/s
[Step=64050 Epoch=314.1] | Loss=0.00232 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=17.797 | 4674.8 samples/s | 73.0 steps/s
[Step=64100 Epoch=314.3] | Loss=0.00233 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=17.806 | 4874.3 samples/s | 76.2 steps/s
[Step=64150 Epoch=314.6] | Loss=0.00233 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=17.816 | 4976.5 samples/s | 77.8 steps/s
[Step=64200 Epoch=314.8] | Loss=0.00242 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=17.826 | 8069.9 samples/s | 126.1 steps/s
[Step=64250 Epoch=315.1] | Loss=0.00241 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=17.835 | 2204.5 samples/s | 34.4 steps/s
[Step=64300 Epoch=315.3] | Loss=0.00236 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.374 | L2-Norm(final)=17.845 | 5025.5 samples/s | 78.5 steps/s
[Step=64350 Epoch=315.6] | Loss=0.00230 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.374 | L2-Norm(final)=17.854 | 5220.4 samples/s | 81.6 steps/s
[Step=64400 Epoch=315.8] | Loss=0.00228 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=17.863 | 7032.6 samples/s | 109.9 steps/s
[Step=64450 Epoch=316.1] | Loss=0.00226 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=17.872 | 2233.2 samples/s | 34.9 steps/s
[Step=64500 Epoch=316.3] | Loss=0.00224 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=17.881 | 5077.4 samples/s | 79.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=316.3] | Loss=0.00051 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=17.971 | 5242.6 samples/s | 81.9 steps/s
[Step=64550 Epoch=316.5] | Loss=0.00328 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.385 | L2-Norm(final)=17.979 | 4046.3 samples/s | 63.2 steps/s
[Step=64600 Epoch=316.8] | Loss=0.00304 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=17.987 | 4468.7 samples/s | 69.8 steps/s
[Step=64650 Epoch=317.0] | Loss=0.00344 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=17.996 | 4501.5 samples/s | 70.3 steps/s
[Step=64700 Epoch=317.3] | Loss=0.00345 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=18.004 | 6564.5 samples/s | 102.6 steps/s
[Step=64750 Epoch=317.5] | Loss=0.00360 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=18.011 | 2094.1 samples/s | 32.7 steps/s
[Step=64800 Epoch=317.8] | Loss=0.00352 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=18.018 | 4293.3 samples/s | 67.1 steps/s
[Step=64850 Epoch=318.0] | Loss=0.00344 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.409 | L2-Norm(final)=18.024 | 4413.6 samples/s | 69.0 steps/s
[Step=64900 Epoch=318.3] | Loss=0.00337 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=18.030 | 6058.3 samples/s | 94.7 steps/s
[Step=64950 Epoch=318.5] | Loss=0.00342 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.413 | L2-Norm(final)=18.036 | 2106.9 samples/s | 32.9 steps/s
[Step=65000 Epoch=318.7] | Loss=0.00328 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=18.041 | 4492.8 samples/s | 70.2 steps/s
[Step=65050 Epoch=319.0] | Loss=0.00318 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=18.046 | 4521.0 samples/s | 70.6 steps/s
[Step=65100 Epoch=319.2] | Loss=0.00308 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=18.050 | 5860.7 samples/s | 91.6 steps/s
[Step=65150 Epoch=319.5] | Loss=0.00297 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=18.055 | 2162.0 samples/s | 33.8 steps/s
[Step=65200 Epoch=319.7] | Loss=0.00288 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=18.059 | 4376.6 samples/s | 68.4 steps/s
[Step=65250 Epoch=320.0] | Loss=0.00279 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=18.064 | 4434.0 samples/s | 69.3 steps/s
[Step=65300 Epoch=320.2] | Loss=0.00281 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.415 | L2-Norm(final)=18.068 | 5555.8 samples/s | 86.8 steps/s
[Step=65350 Epoch=320.5] | Loss=0.00270 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=18.071 | 2235.3 samples/s | 34.9 steps/s
[Step=65400 Epoch=320.7] | Loss=0.00265 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=18.075 | 4381.4 samples/s | 68.5 steps/s
[Step=65450 Epoch=321.0] | Loss=0.00261 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.413 | L2-Norm(final)=18.079 | 4421.3 samples/s | 69.1 steps/s
[Step=65500 Epoch=321.2] | Loss=0.00260 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.413 | L2-Norm(final)=18.083 | 5237.0 samples/s | 81.8 steps/s
[Step=65550 Epoch=321.4] | Loss=0.00257 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.412 | L2-Norm(final)=18.086 | 2253.4 samples/s | 35.2 steps/s
[Step=65600 Epoch=321.7] | Loss=0.00254 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=18.090 | 4449.4 samples/s | 69.5 steps/s
[Step=65650 Epoch=321.9] | Loss=0.00248 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.410 | L2-Norm(final)=18.093 | 4430.4 samples/s | 69.2 steps/s
[Step=65700 Epoch=322.2] | Loss=0.00241 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.408 | L2-Norm(final)=18.097 | 4935.6 samples/s | 77.1 steps/s
[Step=65750 Epoch=322.4] | Loss=0.00239 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.407 | L2-Norm(final)=18.100 | 2351.1 samples/s | 36.7 steps/s
[Step=65800 Epoch=322.7] | Loss=0.00236 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=18.104 | 4484.4 samples/s | 70.1 steps/s
[Step=65850 Epoch=322.9] | Loss=0.00234 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=18.107 | 4587.7 samples/s | 71.7 steps/s
[Step=65900 Epoch=323.2] | Loss=0.00231 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=18.110 | 4517.8 samples/s | 70.6 steps/s
[Step=65950 Epoch=323.4] | Loss=0.00226 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.401 | L2-Norm(final)=18.113 | 2359.5 samples/s | 36.9 steps/s
[Step=66000 Epoch=323.7] | Loss=0.00222 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=18.117 | 4461.5 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step66000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=606.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.106 | 5272.6 samples/s | 82.4 steps/s
[Step=64050 Epoch=606.9] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.107 | 3965.2 samples/s | 62.0 steps/s
[Step=64100 Epoch=607.4] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.107 | 7431.8 samples/s | 116.1 steps/s
[Step=64150 Epoch=607.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.108 | 2123.6 samples/s | 33.2 steps/s
[Step=64200 Epoch=608.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.108 | 6557.7 samples/s | 102.5 steps/s
[Step=64250 Epoch=608.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.109 | 2236.7 samples/s | 34.9 steps/s
[Step=64300 Epoch=609.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.109 | 5844.1 samples/s | 91.3 steps/s
[Step=64350 Epoch=609.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.110 | 2280.1 samples/s | 35.6 steps/s
[Step=64400 Epoch=610.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.111 | 5357.1 samples/s | 83.7 steps/s
[Step=64450 Epoch=610.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.111 | 2374.7 samples/s | 37.1 steps/s
[Step=64500 Epoch=611.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.112 | 4806.9 samples/s | 75.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=611.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.117 | 4887.9 samples/s | 76.4 steps/s
[Step=64550 Epoch=611.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.118 | 4009.5 samples/s | 62.6 steps/s
[Step=64600 Epoch=612.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.118 | 6280.8 samples/s | 98.1 steps/s
[Step=64650 Epoch=612.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.119 | 2021.9 samples/s | 31.6 steps/s
[Step=64700 Epoch=613.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.119 | 5562.5 samples/s | 86.9 steps/s
[Step=64750 Epoch=613.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.051 | L2-Norm(final)=9.120 | 2087.2 samples/s | 32.6 steps/s
[Step=64800 Epoch=614.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.050 | L2-Norm(final)=9.120 | 5154.4 samples/s | 80.5 steps/s
[Step=64850 Epoch=614.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.049 | L2-Norm(final)=9.120 | 2199.4 samples/s | 34.4 steps/s
[Step=64900 Epoch=615.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.049 | L2-Norm(final)=9.121 | 4629.0 samples/s | 72.3 steps/s
[Step=64950 Epoch=615.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.048 | L2-Norm(final)=9.121 | 2228.4 samples/s | 34.8 steps/s
[Step=65000 Epoch=615.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=9.121 | 4431.1 samples/s | 69.2 steps/s
[Step=65050 Epoch=616.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=9.122 | 2355.4 samples/s | 36.8 steps/s
[Step=65100 Epoch=616.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=9.122 | 4202.7 samples/s | 65.7 steps/s
[Step=65150 Epoch=617.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=9.122 | 2349.0 samples/s | 36.7 steps/s
[Step=65200 Epoch=617.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.042 | L2-Norm(final)=9.123 | 4343.0 samples/s | 67.9 steps/s
[Step=65250 Epoch=618.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.041 | L2-Norm(final)=9.123 | 2384.8 samples/s | 37.3 steps/s
[Step=65300 Epoch=618.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.039 | L2-Norm(final)=9.123 | 4264.1 samples/s | 66.6 steps/s
[Step=65350 Epoch=619.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=9.124 | 2432.0 samples/s | 38.0 steps/s
[Step=65400 Epoch=619.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.037 | L2-Norm(final)=9.124 | 4046.2 samples/s | 63.2 steps/s
[Step=65450 Epoch=620.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.035 | L2-Norm(final)=9.124 | 6525.6 samples/s | 102.0 steps/s
[Step=65500 Epoch=620.7] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.034 | L2-Norm(final)=9.124 | 1978.0 samples/s | 30.9 steps/s
[Step=65550 Epoch=621.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=9.125 | 5863.5 samples/s | 91.6 steps/s
[Step=65600 Epoch=621.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=9.125 | 2063.3 samples/s | 32.2 steps/s
[Step=65650 Epoch=622.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=9.125 | 5138.9 samples/s | 80.3 steps/s
[Step=65700 Epoch=622.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=9.125 | 2162.1 samples/s | 33.8 steps/s
[Step=65750 Epoch=623.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=9.126 | 4781.0 samples/s | 74.7 steps/s
[Step=65800 Epoch=623.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.025 | L2-Norm(final)=9.126 | 2193.9 samples/s | 34.3 steps/s
[Step=65850 Epoch=624.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.023 | L2-Norm(final)=9.126 | 4405.8 samples/s | 68.8 steps/s
[Step=65900 Epoch=624.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.022 | L2-Norm(final)=9.127 | 2232.8 samples/s | 34.9 steps/s
[Step=65950 Epoch=624.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.020 | L2-Norm(final)=9.127 | 4133.1 samples/s | 64.6 steps/s
[Step=66000 Epoch=625.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.018 | L2-Norm(final)=9.127 | 2362.7 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step66000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=608.8] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.974 | L2-Norm(final)=10.013 | 5308.8 samples/s | 82.9 steps/s
[Step=64050 Epoch=609.3] | Loss=0.00021 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.978 | L2-Norm(final)=10.029 | 4116.7 samples/s | 64.3 steps/s
[Step=64100 Epoch=609.8] | Loss=0.00013 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.989 | L2-Norm(final)=10.041 | 7414.3 samples/s | 115.8 steps/s
[Step=64150 Epoch=610.2] | Loss=0.00010 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.995 | L2-Norm(final)=10.049 | 2175.1 samples/s | 34.0 steps/s
[Step=64200 Epoch=610.7] | Loss=0.00009 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.999 | L2-Norm(final)=10.055 | 6090.8 samples/s | 95.2 steps/s
[Step=64250 Epoch=611.2] | Loss=0.00008 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.002 | L2-Norm(final)=10.060 | 2171.6 samples/s | 33.9 steps/s
[Step=64300 Epoch=611.7] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.004 | L2-Norm(final)=10.065 | 5901.8 samples/s | 92.2 steps/s
[Step=64350 Epoch=612.1] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.007 | L2-Norm(final)=10.069 | 2290.3 samples/s | 35.8 steps/s
[Step=64400 Epoch=612.6] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.073 | 5383.9 samples/s | 84.1 steps/s
[Step=64450 Epoch=613.1] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=10.077 | 2388.7 samples/s | 37.3 steps/s
[Step=64500 Epoch=613.6] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.012 | L2-Norm(final)=10.081 | 4913.1 samples/s | 76.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=613.6] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=10.121 | 5496.2 samples/s | 85.9 steps/s
[Step=64550 Epoch=614.0] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=10.125 | 3767.5 samples/s | 58.9 steps/s
[Step=64600 Epoch=614.5] | Loss=0.00019 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=10.132 | 5996.1 samples/s | 93.7 steps/s
[Step=64650 Epoch=615.0] | Loss=0.00059 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.056 | L2-Norm(final)=10.135 | 2009.1 samples/s | 31.4 steps/s
[Step=64700 Epoch=615.5] | Loss=0.00045 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=10.137 | 5691.3 samples/s | 88.9 steps/s
[Step=64750 Epoch=615.9] | Loss=0.00036 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=10.138 | 2091.5 samples/s | 32.7 steps/s
[Step=64800 Epoch=616.4] | Loss=0.00030 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.082 | L2-Norm(final)=10.139 | 4997.2 samples/s | 78.1 steps/s
[Step=64850 Epoch=616.9] | Loss=0.00026 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=10.140 | 2178.1 samples/s | 34.0 steps/s
[Step=64900 Epoch=617.4] | Loss=0.00023 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.087 | L2-Norm(final)=10.140 | 4710.9 samples/s | 73.6 steps/s
[Step=64950 Epoch=617.8] | Loss=0.00020 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.089 | L2-Norm(final)=10.141 | 2275.3 samples/s | 35.6 steps/s
[Step=65000 Epoch=618.3] | Loss=0.00018 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=10.141 | 4316.0 samples/s | 67.4 steps/s
[Step=65050 Epoch=618.8] | Loss=0.00017 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.142 | 2331.1 samples/s | 36.4 steps/s
[Step=65100 Epoch=619.3] | Loss=0.00016 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.142 | 4182.6 samples/s | 65.4 steps/s
[Step=65150 Epoch=619.7] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.142 | 2462.1 samples/s | 38.5 steps/s
[Step=65200 Epoch=620.2] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.143 | 4005.7 samples/s | 62.6 steps/s
[Step=65250 Epoch=620.7] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.143 | 2454.6 samples/s | 38.4 steps/s
[Step=65300 Epoch=621.2] | Loss=0.00012 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.143 | 4072.5 samples/s | 63.6 steps/s
[Step=65350 Epoch=621.6] | Loss=0.00011 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.144 | 2494.5 samples/s | 39.0 steps/s
[Step=65400 Epoch=622.1] | Loss=0.00011 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.144 | 3833.8 samples/s | 59.9 steps/s
[Step=65450 Epoch=622.6] | Loss=0.00010 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.144 | 6531.6 samples/s | 102.1 steps/s
[Step=65500 Epoch=623.1] | Loss=0.00010 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.144 | 1988.7 samples/s | 31.1 steps/s
[Step=65550 Epoch=623.5] | Loss=0.00009 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=10.145 | 5832.1 samples/s | 91.1 steps/s
[Step=65600 Epoch=624.0] | Loss=0.00009 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=10.145 | 2056.3 samples/s | 32.1 steps/s
[Step=65650 Epoch=624.5] | Loss=0.00008 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.089 | L2-Norm(final)=10.145 | 5314.7 samples/s | 83.0 steps/s
[Step=65700 Epoch=625.0] | Loss=0.00008 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=10.145 | 2114.9 samples/s | 33.0 steps/s
[Step=65750 Epoch=625.4] | Loss=0.00008 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=10.145 | 4754.2 samples/s | 74.3 steps/s
[Step=65800 Epoch=625.9] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.087 | L2-Norm(final)=10.146 | 2230.3 samples/s | 34.8 steps/s
[Step=65850 Epoch=626.4] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.086 | L2-Norm(final)=10.146 | 4482.4 samples/s | 70.0 steps/s
[Step=65900 Epoch=626.9] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.086 | L2-Norm(final)=10.146 | 2298.7 samples/s | 35.9 steps/s
[Step=65950 Epoch=627.3] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=10.146 | 4189.1 samples/s | 65.5 steps/s
[Step=66000 Epoch=627.8] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.084 | L2-Norm(final)=10.147 | 2352.4 samples/s | 36.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step66000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=611.2] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.017 | L2-Norm(final)=9.418 | 5381.0 samples/s | 84.1 steps/s
[Step=64050 Epoch=611.6] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.017 | L2-Norm(final)=9.424 | 4134.5 samples/s | 64.6 steps/s
[Step=64100 Epoch=612.1] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.021 | L2-Norm(final)=9.432 | 7594.7 samples/s | 118.7 steps/s
[Step=64150 Epoch=612.6] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.023 | L2-Norm(final)=9.439 | 2130.2 samples/s | 33.3 steps/s
[Step=64200 Epoch=613.1] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=9.447 | 6803.0 samples/s | 106.3 steps/s
[Step=64250 Epoch=613.5] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=9.453 | 2152.7 samples/s | 33.6 steps/s
[Step=64300 Epoch=614.0] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=9.460 | 6218.3 samples/s | 97.2 steps/s
[Step=64350 Epoch=614.5] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=9.466 | 2246.4 samples/s | 35.1 steps/s
[Step=64400 Epoch=615.0] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=9.472 | 5682.8 samples/s | 88.8 steps/s
[Step=64450 Epoch=615.5] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.034 | L2-Norm(final)=9.478 | 2338.6 samples/s | 36.5 steps/s
[Step=64500 Epoch=615.9] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.035 | L2-Norm(final)=9.484 | 5220.1 samples/s | 81.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=615.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=9.542 | 5533.6 samples/s | 86.5 steps/s
[Step=64550 Epoch=616.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.042 | L2-Norm(final)=9.547 | 3662.4 samples/s | 57.2 steps/s
[Step=64600 Epoch=616.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.036 | L2-Norm(final)=9.551 | 6220.0 samples/s | 97.2 steps/s
[Step=64650 Epoch=617.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=9.554 | 2012.5 samples/s | 31.4 steps/s
[Step=64700 Epoch=617.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.020 | L2-Norm(final)=9.556 | 5837.2 samples/s | 91.2 steps/s
[Step=64750 Epoch=618.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=9.558 | 2050.8 samples/s | 32.0 steps/s
[Step=64800 Epoch=618.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=9.560 | 5373.9 samples/s | 84.0 steps/s
[Step=64850 Epoch=619.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.991 | L2-Norm(final)=9.562 | 2110.3 samples/s | 33.0 steps/s
[Step=64900 Epoch=619.8] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.982 | L2-Norm(final)=9.563 | 4935.8 samples/s | 77.1 steps/s
[Step=64950 Epoch=620.2] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.972 | L2-Norm(final)=9.565 | 2204.6 samples/s | 34.4 steps/s
[Step=65000 Epoch=620.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.962 | L2-Norm(final)=9.566 | 4592.9 samples/s | 71.8 steps/s
[Step=65050 Epoch=621.2] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.951 | L2-Norm(final)=9.568 | 2287.4 samples/s | 35.7 steps/s
[Step=65100 Epoch=621.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.941 | L2-Norm(final)=9.569 | 4223.7 samples/s | 66.0 steps/s
[Step=65150 Epoch=622.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.571 | 2327.7 samples/s | 36.4 steps/s
[Step=65200 Epoch=622.6] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.920 | L2-Norm(final)=9.572 | 4317.4 samples/s | 67.5 steps/s
[Step=65250 Epoch=623.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=9.574 | 2378.5 samples/s | 37.2 steps/s
[Step=65300 Epoch=623.6] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.898 | L2-Norm(final)=9.575 | 4238.2 samples/s | 66.2 steps/s
[Step=65350 Epoch=624.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.888 | L2-Norm(final)=9.577 | 2406.9 samples/s | 37.6 steps/s
[Step=65400 Epoch=624.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=9.578 | 4070.1 samples/s | 63.6 steps/s
[Step=65450 Epoch=625.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.866 | L2-Norm(final)=9.580 | 2409.8 samples/s | 37.7 steps/s
[Step=65500 Epoch=625.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=9.581 | 4181.3 samples/s | 65.3 steps/s
[Step=65550 Epoch=626.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.843 | L2-Norm(final)=9.583 | 7119.8 samples/s | 111.2 steps/s
[Step=65600 Epoch=626.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.832 | L2-Norm(final)=9.584 | 1964.3 samples/s | 30.7 steps/s
[Step=65650 Epoch=626.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.820 | L2-Norm(final)=9.586 | 6433.3 samples/s | 100.5 steps/s
[Step=65700 Epoch=627.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.809 | L2-Norm(final)=9.588 | 1993.5 samples/s | 31.1 steps/s
[Step=65750 Epoch=627.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=9.589 | 5836.2 samples/s | 91.2 steps/s
[Step=65800 Epoch=628.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.785 | L2-Norm(final)=9.591 | 2083.8 samples/s | 32.6 steps/s
[Step=65850 Epoch=628.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.773 | L2-Norm(final)=9.593 | 5410.3 samples/s | 84.5 steps/s
[Step=65900 Epoch=629.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.761 | L2-Norm(final)=9.595 | 2155.6 samples/s | 33.7 steps/s
[Step=65950 Epoch=629.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.749 | L2-Norm(final)=9.596 | 4892.2 samples/s | 76.4 steps/s
[Step=66000 Epoch=630.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.737 | L2-Norm(final)=9.598 | 2186.8 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step66000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=603.1] | Loss=0.00029 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.131 | L2-Norm(final)=9.553 | 5553.3 samples/s | 86.8 steps/s
[Step=64050 Epoch=603.5] | Loss=0.00005 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.134 | L2-Norm(final)=9.559 | 4022.5 samples/s | 62.9 steps/s
[Step=64100 Epoch=604.0] | Loss=0.00005 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.138 | L2-Norm(final)=9.568 | 7360.4 samples/s | 115.0 steps/s
[Step=64150 Epoch=604.5] | Loss=0.00005 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.141 | L2-Norm(final)=9.576 | 2162.1 samples/s | 33.8 steps/s
[Step=64200 Epoch=604.9] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.144 | L2-Norm(final)=9.585 | 6257.9 samples/s | 97.8 steps/s
[Step=64250 Epoch=605.4] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.147 | L2-Norm(final)=9.592 | 2245.2 samples/s | 35.1 steps/s
[Step=64300 Epoch=605.9] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.149 | L2-Norm(final)=9.600 | 5554.0 samples/s | 86.8 steps/s
[Step=64350 Epoch=606.4] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.151 | L2-Norm(final)=9.607 | 2355.3 samples/s | 36.8 steps/s
[Step=64400 Epoch=606.8] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.153 | L2-Norm(final)=9.614 | 5044.5 samples/s | 78.8 steps/s
[Step=64450 Epoch=607.3] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.155 | L2-Norm(final)=9.620 | 2474.0 samples/s | 38.7 steps/s
[Step=64500 Epoch=607.8] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=9.627 | 4871.2 samples/s | 76.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=607.8] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.172 | L2-Norm(final)=9.690 | 5883.7 samples/s | 91.9 steps/s
[Step=64550 Epoch=608.2] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.694 | 3517.3 samples/s | 55.0 steps/s
[Step=64600 Epoch=608.7] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.168 | L2-Norm(final)=9.700 | 6232.0 samples/s | 97.4 steps/s
[Step=64650 Epoch=609.2] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.165 | L2-Norm(final)=9.704 | 2021.8 samples/s | 31.6 steps/s
[Step=64700 Epoch=609.7] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.161 | L2-Norm(final)=9.707 | 5524.8 samples/s | 86.3 steps/s
[Step=64750 Epoch=610.1] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.156 | L2-Norm(final)=9.710 | 2107.0 samples/s | 32.9 steps/s
[Step=64800 Epoch=610.6] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.150 | L2-Norm(final)=9.712 | 4920.5 samples/s | 76.9 steps/s
[Step=64850 Epoch=611.1] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.143 | L2-Norm(final)=9.713 | 2181.9 samples/s | 34.1 steps/s
[Step=64900 Epoch=611.5] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.137 | L2-Norm(final)=9.715 | 4517.3 samples/s | 70.6 steps/s
[Step=64950 Epoch=612.0] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.130 | L2-Norm(final)=9.716 | 2334.7 samples/s | 36.5 steps/s
[Step=65000 Epoch=612.5] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.123 | L2-Norm(final)=9.718 | 4226.9 samples/s | 66.0 steps/s
[Step=65050 Epoch=613.0] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.116 | L2-Norm(final)=9.719 | 2372.2 samples/s | 37.1 steps/s
[Step=65100 Epoch=613.4] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.108 | L2-Norm(final)=9.720 | 4064.0 samples/s | 63.5 steps/s
[Step=65150 Epoch=613.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.101 | L2-Norm(final)=9.721 | 2263.9 samples/s | 35.4 steps/s
[Step=65200 Epoch=614.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.093 | L2-Norm(final)=9.722 | 4149.4 samples/s | 64.8 steps/s
[Step=65250 Epoch=614.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.086 | L2-Norm(final)=9.724 | 2583.4 samples/s | 40.4 steps/s
[Step=65300 Epoch=615.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=9.725 | 3752.9 samples/s | 58.6 steps/s
[Step=65350 Epoch=615.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.070 | L2-Norm(final)=9.726 | 6160.3 samples/s | 96.3 steps/s
[Step=65400 Epoch=616.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=9.727 | 2010.9 samples/s | 31.4 steps/s
[Step=65450 Epoch=616.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.054 | L2-Norm(final)=9.728 | 5525.7 samples/s | 86.3 steps/s
[Step=65500 Epoch=617.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=9.729 | 2134.2 samples/s | 33.3 steps/s
[Step=65550 Epoch=617.7] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=9.730 | 4904.2 samples/s | 76.6 steps/s
[Step=65600 Epoch=618.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.029 | L2-Norm(final)=9.731 | 2185.7 samples/s | 34.2 steps/s
[Step=65650 Epoch=618.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.021 | L2-Norm(final)=9.733 | 4552.4 samples/s | 71.1 steps/s
[Step=65700 Epoch=619.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.012 | L2-Norm(final)=9.734 | 2285.2 samples/s | 35.7 steps/s
[Step=65750 Epoch=619.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.004 | L2-Norm(final)=9.735 | 4302.7 samples/s | 67.2 steps/s
[Step=65800 Epoch=620.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.995 | L2-Norm(final)=9.736 | 2355.9 samples/s | 36.8 steps/s
[Step=65850 Epoch=620.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.986 | L2-Norm(final)=9.738 | 4178.7 samples/s | 65.3 steps/s
[Step=65900 Epoch=621.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.977 | L2-Norm(final)=9.739 | 2392.6 samples/s | 37.4 steps/s
[Step=65950 Epoch=621.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.968 | L2-Norm(final)=9.740 | 4289.2 samples/s | 67.0 steps/s
[Step=66000 Epoch=621.9] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.959 | L2-Norm(final)=9.741 | 2500.8 samples/s | 39.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step66000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=610.0] | Loss=0.00015 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=9.948 | 5163.1 samples/s | 80.7 steps/s
[Step=64050 Epoch=610.5] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.083 | L2-Norm(final)=9.958 | 4141.5 samples/s | 64.7 steps/s
[Step=64100 Epoch=610.9] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=9.971 | 7603.8 samples/s | 118.8 steps/s
[Step=64150 Epoch=611.4] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=9.984 | 2125.9 samples/s | 33.2 steps/s
[Step=64200 Epoch=611.9] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.102 | L2-Norm(final)=9.995 | 6837.9 samples/s | 106.8 steps/s
[Step=64250 Epoch=612.4] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.107 | L2-Norm(final)=10.005 | 2192.3 samples/s | 34.3 steps/s
[Step=64300 Epoch=612.8] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.110 | L2-Norm(final)=10.014 | 5993.4 samples/s | 93.6 steps/s
[Step=64350 Epoch=613.3] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=10.023 | 2289.9 samples/s | 35.8 steps/s
[Step=64400 Epoch=613.8] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.116 | L2-Norm(final)=10.031 | 5517.3 samples/s | 86.2 steps/s
[Step=64450 Epoch=614.3] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.118 | L2-Norm(final)=10.039 | 2335.0 samples/s | 36.5 steps/s
[Step=64500 Epoch=614.7] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=10.047 | 5158.9 samples/s | 80.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=614.8] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.138 | L2-Norm(final)=10.122 | 5259.4 samples/s | 82.2 steps/s
[Step=64550 Epoch=615.2] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.134 | L2-Norm(final)=10.127 | 3840.5 samples/s | 60.0 steps/s
[Step=64600 Epoch=615.7] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.126 | L2-Norm(final)=10.132 | 6211.9 samples/s | 97.1 steps/s
[Step=64650 Epoch=616.2] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.124 | L2-Norm(final)=10.138 | 2039.3 samples/s | 31.9 steps/s
[Step=64700 Epoch=616.6] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=10.143 | 5698.0 samples/s | 89.0 steps/s
[Step=64750 Epoch=617.1] | Loss=0.00002 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=10.147 | 2077.3 samples/s | 32.5 steps/s
[Step=64800 Epoch=617.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.106 | L2-Norm(final)=10.150 | 5328.2 samples/s | 83.3 steps/s
[Step=64850 Epoch=618.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=10.152 | 2111.1 samples/s | 33.0 steps/s
[Step=64900 Epoch=618.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.087 | L2-Norm(final)=10.154 | 4904.9 samples/s | 76.6 steps/s
[Step=64950 Epoch=619.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=10.156 | 2215.5 samples/s | 34.6 steps/s
[Step=65000 Epoch=619.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=10.157 | 4602.2 samples/s | 71.9 steps/s
[Step=65050 Epoch=620.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=10.158 | 2262.5 samples/s | 35.4 steps/s
[Step=65100 Epoch=620.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.159 | 4335.9 samples/s | 67.7 steps/s
[Step=65150 Epoch=620.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.035 | L2-Norm(final)=10.160 | 2303.5 samples/s | 36.0 steps/s
[Step=65200 Epoch=621.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.024 | L2-Norm(final)=10.161 | 4200.4 samples/s | 65.6 steps/s
[Step=65250 Epoch=621.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=10.162 | 2374.6 samples/s | 37.1 steps/s
[Step=65300 Epoch=622.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=10.163 | 4230.0 samples/s | 66.1 steps/s
[Step=65350 Epoch=622.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.990 | L2-Norm(final)=10.164 | 2410.4 samples/s | 37.7 steps/s
[Step=65400 Epoch=623.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.978 | L2-Norm(final)=10.165 | 4272.0 samples/s | 66.8 steps/s
[Step=65450 Epoch=623.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.966 | L2-Norm(final)=10.166 | 2125.6 samples/s | 33.2 steps/s
[Step=65500 Epoch=624.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.954 | L2-Norm(final)=10.167 | 2915.7 samples/s | 45.6 steps/s
[Step=65550 Epoch=624.8] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=10.168 | 6841.0 samples/s | 106.9 steps/s
[Step=65600 Epoch=625.2] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=10.169 | 1944.4 samples/s | 30.4 steps/s
[Step=65650 Epoch=625.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.917 | L2-Norm(final)=10.170 | 6269.8 samples/s | 98.0 steps/s
[Step=65700 Epoch=626.2] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.905 | L2-Norm(final)=10.171 | 1983.2 samples/s | 31.0 steps/s
[Step=65750 Epoch=626.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.892 | L2-Norm(final)=10.172 | 5773.0 samples/s | 90.2 steps/s
[Step=65800 Epoch=627.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.879 | L2-Norm(final)=10.173 | 2076.9 samples/s | 32.5 steps/s
[Step=65850 Epoch=627.6] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.867 | L2-Norm(final)=10.174 | 5366.7 samples/s | 83.9 steps/s
[Step=65900 Epoch=628.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=10.175 | 2126.1 samples/s | 33.2 steps/s
[Step=65950 Epoch=628.6] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=10.176 | 4959.4 samples/s | 77.5 steps/s
[Step=66000 Epoch=629.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.828 | L2-Norm(final)=10.178 | 2199.5 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11078 | acc=0.9584 | tpr=0.9695 | fpr=0.0657 | 4719.6 samples/s | 18.4 steps/s
Avg test loss: 0.11535, Avg test acc: 0.95673, Avg tpr: 0.96841, Avg fpr: 0.06897, total FA: 538

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11422 | acc=0.9585 | tpr=0.9756 | fpr=0.0785 | 4794.6 samples/s | 18.7 steps/s
Avg test loss: 0.11533, Avg test acc: 0.95785, Avg tpr: 0.97453, Avg fpr: 0.07884, total FA: 615

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11292 | acc=0.9585 | tpr=0.9770 | fpr=0.0815 | 4902.2 samples/s | 19.1 steps/s
Avg test loss: 0.11494, Avg test acc: 0.95713, Avg tpr: 0.97517, Avg fpr: 0.08255, total FA: 644

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10328 | acc=0.9605 | tpr=0.9715 | fpr=0.0632 | 4744.2 samples/s | 18.5 steps/s
Avg test loss: 0.10934, Avg test acc: 0.95897, Avg tpr: 0.97132, Avg fpr: 0.06820, total FA: 532

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10944 | acc=0.9579 | tpr=0.9700 | fpr=0.0684 | 4882.4 samples/s | 19.1 steps/s
Avg test loss: 0.11598, Avg test acc: 0.95729, Avg tpr: 0.96981, Avg fpr: 0.07025, total FA: 548

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.65864 | acc=0.2905 | tpr=0.0134 | fpr=0.1078 | 4866.8 samples/s | 19.0 steps/s
Avg test loss: 5.66291, Avg test acc: 0.28993, Avg tpr: 0.01393, Avg fpr: 0.10306, total FA: 804

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.71920 | acc=0.3038 | tpr=0.0070 | fpr=0.0518 | 4716.2 samples/s | 18.4 steps/s
Avg test loss: 4.72901, Avg test acc: 0.30147, Avg tpr: 0.00711, Avg fpr: 0.05115, total FA: 399

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.13285 | acc=0.2911 | tpr=0.0119 | fpr=0.1026 | 5041.3 samples/s | 19.7 steps/s
Avg test loss: 5.13529, Avg test acc: 0.28768, Avg tpr: 0.01230, Avg fpr: 0.10665, total FA: 832

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.40889 | acc=0.2963 | tpr=0.0157 | fpr=0.0946 | 4833.1 samples/s | 18.9 steps/s
Avg test loss: 5.40530, Avg test acc: 0.29466, Avg tpr: 0.01702, Avg fpr: 0.09473, total FA: 739

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.76258 | acc=0.3023 | tpr=0.0121 | fpr=0.0674 | 4990.7 samples/s | 19.5 steps/s
Avg test loss: 4.76653, Avg test acc: 0.29994, Avg tpr: 0.01300, Avg fpr: 0.06897, total FA: 538

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.83742 | acc=0.1074 | tpr=0.5531 | fpr=0.9006 | 5069.2 samples/s | 19.8 steps/s
[Step= 100] | Loss=5.80633 | acc=0.1091 | tpr=0.5544 | fpr=0.8992 | 7152.2 samples/s | 27.9 steps/s
[Step= 150] | Loss=5.82019 | acc=0.1097 | tpr=0.5533 | fpr=0.8985 | 7010.8 samples/s | 27.4 steps/s
[Step= 200] | Loss=5.81565 | acc=0.1096 | tpr=0.5432 | fpr=0.8983 | 7928.0 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.81791 | acc=0.1106 | tpr=0.5520 | fpr=0.8975 | 7958.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=5.81330 | acc=0.1108 | tpr=0.5593 | fpr=0.8974 | 7941.0 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.80676 | acc=0.1109 | tpr=0.5560 | fpr=0.8972 | 7729.7 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.80421 | acc=0.1108 | tpr=0.5553 | fpr=0.8972 | 7913.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.80907 | acc=0.1111 | tpr=0.5511 | fpr=0.8969 | 8191.6 samples/s | 32.0 steps/s
[Step= 500] | Loss=5.81181 | acc=0.1109 | tpr=0.5471 | fpr=0.8969 | 7590.6 samples/s | 29.7 steps/s
[Step= 550] | Loss=5.81488 | acc=0.1107 | tpr=0.5436 | fpr=0.8972 | 14154.6 samples/s | 55.3 steps/s
Avg test loss: 5.81688, Avg test acc: 0.11057, Avg tpr: 0.54358, Avg fpr: 0.89730, total FA: 124589

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.82498 | acc=0.0911 | tpr=0.5310 | fpr=0.9168 | 4822.0 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.80300 | acc=0.0922 | tpr=0.5288 | fpr=0.9159 | 7235.5 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.80295 | acc=0.0922 | tpr=0.5432 | fpr=0.9161 | 7662.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.79806 | acc=0.0916 | tpr=0.5355 | fpr=0.9165 | 7853.5 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.80318 | acc=0.0914 | tpr=0.5415 | fpr=0.9168 | 7926.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.79720 | acc=0.0914 | tpr=0.5447 | fpr=0.9169 | 7875.6 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.79056 | acc=0.0916 | tpr=0.5416 | fpr=0.9165 | 8058.8 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.78616 | acc=0.0921 | tpr=0.5432 | fpr=0.9161 | 8031.2 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.79017 | acc=0.0918 | tpr=0.5419 | fpr=0.9164 | 7552.4 samples/s | 29.5 steps/s
[Step= 500] | Loss=5.79363 | acc=0.0917 | tpr=0.5401 | fpr=0.9164 | 7927.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.79831 | acc=0.0912 | tpr=0.5364 | fpr=0.9168 | 14351.0 samples/s | 56.1 steps/s
Avg test loss: 5.80086, Avg test acc: 0.09116, Avg tpr: 0.53526, Avg fpr: 0.91691, total FA: 127311

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.32440 | acc=0.0777 | tpr=0.3717 | fpr=0.9276 | 4763.1 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.29139 | acc=0.0791 | tpr=0.3689 | fpr=0.9263 | 7540.2 samples/s | 29.5 steps/s
[Step= 150] | Loss=6.30475 | acc=0.0805 | tpr=0.3833 | fpr=0.9251 | 7328.6 samples/s | 28.6 steps/s
[Step= 200] | Loss=6.29943 | acc=0.0805 | tpr=0.3770 | fpr=0.9249 | 8357.8 samples/s | 32.6 steps/s
[Step= 250] | Loss=6.29734 | acc=0.0812 | tpr=0.3869 | fpr=0.9244 | 7723.7 samples/s | 30.2 steps/s
[Step= 300] | Loss=6.29385 | acc=0.0814 | tpr=0.3920 | fpr=0.9242 | 7713.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.28850 | acc=0.0817 | tpr=0.3876 | fpr=0.9239 | 7910.6 samples/s | 30.9 steps/s
[Step= 400] | Loss=6.28275 | acc=0.0821 | tpr=0.3895 | fpr=0.9235 | 7850.9 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.28679 | acc=0.0821 | tpr=0.3846 | fpr=0.9234 | 7940.8 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.28850 | acc=0.0819 | tpr=0.3837 | fpr=0.9235 | 7517.9 samples/s | 29.4 steps/s
[Step= 550] | Loss=6.29282 | acc=0.0817 | tpr=0.3860 | fpr=0.9238 | 15009.6 samples/s | 58.6 steps/s
Avg test loss: 6.29427, Avg test acc: 0.08162, Avg tpr: 0.38669, Avg fpr: 0.92392, total FA: 128285

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.66209 | acc=0.1158 | tpr=0.5044 | fpr=0.8912 | 4827.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.64472 | acc=0.1171 | tpr=0.5096 | fpr=0.8902 | 7236.2 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.65829 | acc=0.1164 | tpr=0.5274 | fpr=0.8912 | 7630.0 samples/s | 29.8 steps/s
[Step= 200] | Loss=5.64757 | acc=0.1154 | tpr=0.5246 | fpr=0.8921 | 8105.7 samples/s | 31.7 steps/s
[Step= 250] | Loss=5.65214 | acc=0.1162 | tpr=0.5301 | fpr=0.8913 | 7623.5 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.65086 | acc=0.1160 | tpr=0.5345 | fpr=0.8916 | 7838.8 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.64227 | acc=0.1160 | tpr=0.5341 | fpr=0.8916 | 7638.5 samples/s | 29.8 steps/s
[Step= 400] | Loss=5.63559 | acc=0.1160 | tpr=0.5312 | fpr=0.8915 | 8113.4 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.64106 | acc=0.1160 | tpr=0.5282 | fpr=0.8915 | 7740.8 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.64236 | acc=0.1157 | tpr=0.5264 | fpr=0.8917 | 7520.3 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.64671 | acc=0.1155 | tpr=0.5221 | fpr=0.8919 | 15042.9 samples/s | 58.8 steps/s
Avg test loss: 5.64781, Avg test acc: 0.11540, Avg tpr: 0.52219, Avg fpr: 0.89200, total FA: 123852

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.16211 | acc=0.1097 | tpr=0.4867 | fpr=0.8971 | 4802.4 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.13593 | acc=0.1115 | tpr=0.4840 | fpr=0.8954 | 7301.3 samples/s | 28.5 steps/s
[Step= 150] | Loss=6.13412 | acc=0.1118 | tpr=0.4870 | fpr=0.8951 | 7430.2 samples/s | 29.0 steps/s
[Step= 200] | Loss=6.12867 | acc=0.1115 | tpr=0.4689 | fpr=0.8950 | 7786.1 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.13505 | acc=0.1126 | tpr=0.4795 | fpr=0.8941 | 8115.0 samples/s | 31.7 steps/s
[Step= 300] | Loss=6.13510 | acc=0.1122 | tpr=0.4851 | fpr=0.8946 | 7723.7 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.12534 | acc=0.1123 | tpr=0.4834 | fpr=0.8944 | 7732.2 samples/s | 30.2 steps/s
[Step= 400] | Loss=6.12155 | acc=0.1125 | tpr=0.4858 | fpr=0.8943 | 8247.3 samples/s | 32.2 steps/s
[Step= 450] | Loss=6.12464 | acc=0.1129 | tpr=0.4859 | fpr=0.8939 | 7745.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=6.12732 | acc=0.1128 | tpr=0.4815 | fpr=0.8939 | 7826.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=6.13195 | acc=0.1124 | tpr=0.4835 | fpr=0.8943 | 14005.2 samples/s | 54.7 steps/s
Avg test loss: 6.13423, Avg test acc: 0.11232, Avg tpr: 0.48296, Avg fpr: 0.89442, total FA: 124188

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09693 | acc=0.9824 | tpr=0.9602 | fpr=0.0172 | 4701.0 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10006 | acc=0.9818 | tpr=0.9595 | fpr=0.0177 | 7398.2 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.10345 | acc=0.9811 | tpr=0.9539 | fpr=0.0184 | 7897.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.10543 | acc=0.9809 | tpr=0.9596 | fpr=0.0187 | 7860.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.10368 | acc=0.9812 | tpr=0.9537 | fpr=0.0183 | 7585.3 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.10618 | acc=0.9807 | tpr=0.9520 | fpr=0.0188 | 7869.3 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10714 | acc=0.9804 | tpr=0.9530 | fpr=0.0191 | 7701.2 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.10808 | acc=0.9802 | tpr=0.9497 | fpr=0.0192 | 7951.1 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.11012 | acc=0.9799 | tpr=0.9460 | fpr=0.0195 | 8033.4 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.10926 | acc=0.9800 | tpr=0.9471 | fpr=0.0194 | 7848.8 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10868 | acc=0.9801 | tpr=0.9443 | fpr=0.0192 | 13925.5 samples/s | 54.4 steps/s
Avg test loss: 0.10851, Avg test acc: 0.98016, Avg tpr: 0.94453, Avg fpr: 0.01919, total FA: 2665

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09126 | acc=0.9814 | tpr=0.9159 | fpr=0.0174 | 4924.5 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09275 | acc=0.9814 | tpr=0.9104 | fpr=0.0172 | 6974.1 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.09489 | acc=0.9812 | tpr=0.9150 | fpr=0.0176 | 7216.8 samples/s | 28.2 steps/s
[Step= 200] | Loss=0.09667 | acc=0.9810 | tpr=0.9191 | fpr=0.0179 | 8166.4 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.09475 | acc=0.9813 | tpr=0.9197 | fpr=0.0176 | 7986.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.09672 | acc=0.9810 | tpr=0.9178 | fpr=0.0179 | 7483.1 samples/s | 29.2 steps/s
[Step= 350] | Loss=0.09758 | acc=0.9808 | tpr=0.9211 | fpr=0.0181 | 8071.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.09893 | acc=0.9806 | tpr=0.9163 | fpr=0.0182 | 8421.9 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.10131 | acc=0.9803 | tpr=0.9153 | fpr=0.0186 | 7641.8 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.10036 | acc=0.9804 | tpr=0.9185 | fpr=0.0185 | 7802.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.10024 | acc=0.9805 | tpr=0.9164 | fpr=0.0183 | 13464.2 samples/s | 52.6 steps/s
Avg test loss: 0.10015, Avg test acc: 0.98049, Avg tpr: 0.91680, Avg fpr: 0.01835, total FA: 2548

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08406 | acc=0.9815 | tpr=0.9602 | fpr=0.0181 | 4585.4 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.08588 | acc=0.9820 | tpr=0.9680 | fpr=0.0177 | 7618.2 samples/s | 29.8 steps/s
[Step= 150] | Loss=0.08976 | acc=0.9810 | tpr=0.9625 | fpr=0.0186 | 7790.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.09124 | acc=0.9812 | tpr=0.9672 | fpr=0.0186 | 8034.1 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.08962 | acc=0.9815 | tpr=0.9668 | fpr=0.0183 | 7801.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.09169 | acc=0.9811 | tpr=0.9622 | fpr=0.0186 | 7820.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.09240 | acc=0.9808 | tpr=0.9631 | fpr=0.0189 | 7954.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09349 | acc=0.9806 | tpr=0.9601 | fpr=0.0191 | 8070.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.09515 | acc=0.9803 | tpr=0.9586 | fpr=0.0193 | 7576.3 samples/s | 29.6 steps/s
[Step= 500] | Loss=0.09451 | acc=0.9803 | tpr=0.9604 | fpr=0.0193 | 8082.1 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.09413 | acc=0.9804 | tpr=0.9586 | fpr=0.0192 | 13811.5 samples/s | 54.0 steps/s
Avg test loss: 0.09401, Avg test acc: 0.98043, Avg tpr: 0.95880, Avg fpr: 0.01917, total FA: 2662

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09426 | acc=0.9802 | tpr=0.9469 | fpr=0.0192 | 4921.0 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09706 | acc=0.9801 | tpr=0.9552 | fpr=0.0195 | 6970.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.10138 | acc=0.9791 | tpr=0.9524 | fpr=0.0204 | 7736.1 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10248 | acc=0.9793 | tpr=0.9574 | fpr=0.0203 | 7927.6 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.10092 | acc=0.9799 | tpr=0.9563 | fpr=0.0197 | 7655.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.10294 | acc=0.9797 | tpr=0.9542 | fpr=0.0198 | 8261.8 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.10369 | acc=0.9795 | tpr=0.9537 | fpr=0.0201 | 7497.5 samples/s | 29.3 steps/s
[Step= 400] | Loss=0.10428 | acc=0.9793 | tpr=0.9502 | fpr=0.0202 | 8189.7 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.10630 | acc=0.9791 | tpr=0.9474 | fpr=0.0204 | 7662.2 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.10551 | acc=0.9791 | tpr=0.9480 | fpr=0.0203 | 7853.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10507 | acc=0.9793 | tpr=0.9479 | fpr=0.0201 | 13971.6 samples/s | 54.6 steps/s
Avg test loss: 0.10489, Avg test acc: 0.97936, Avg tpr: 0.94810, Avg fpr: 0.02007, total FA: 2787

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09498 | acc=0.9810 | tpr=0.9204 | fpr=0.0179 | 4799.8 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09927 | acc=0.9803 | tpr=0.9296 | fpr=0.0187 | 7259.8 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.10289 | acc=0.9793 | tpr=0.9308 | fpr=0.0198 | 7524.2 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.10465 | acc=0.9793 | tpr=0.9388 | fpr=0.0199 | 7767.5 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.10303 | acc=0.9798 | tpr=0.9362 | fpr=0.0194 | 7860.8 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.10545 | acc=0.9795 | tpr=0.9316 | fpr=0.0197 | 8251.9 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.10617 | acc=0.9792 | tpr=0.9330 | fpr=0.0199 | 7540.3 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.10753 | acc=0.9792 | tpr=0.9311 | fpr=0.0200 | 8259.3 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.10978 | acc=0.9789 | tpr=0.9289 | fpr=0.0202 | 7429.8 samples/s | 29.0 steps/s
[Step= 500] | Loss=0.10902 | acc=0.9790 | tpr=0.9300 | fpr=0.0201 | 7863.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10862 | acc=0.9793 | tpr=0.9304 | fpr=0.0199 | 14634.3 samples/s | 57.2 steps/s
Avg test loss: 0.10843, Avg test acc: 0.97926, Avg tpr: 0.92987, Avg fpr: 0.01984, total FA: 2755

server round 33/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=321.8] | Loss=0.00080 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=17.359 | 5588.2 samples/s | 87.3 steps/s
[Step=66050 Epoch=322.1] | Loss=0.00277 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=17.366 | 4499.1 samples/s | 70.3 steps/s
[Step=66100 Epoch=322.3] | Loss=0.00253 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=17.375 | 4910.1 samples/s | 76.7 steps/s
[Step=66150 Epoch=322.6] | Loss=0.00277 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=17.384 | 5086.7 samples/s | 79.5 steps/s
[Step=66200 Epoch=322.8] | Loss=0.00295 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=17.392 | 7697.6 samples/s | 120.3 steps/s
[Step=66250 Epoch=323.0] | Loss=0.00312 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.441 | L2-Norm(final)=17.400 | 2213.7 samples/s | 34.6 steps/s
[Step=66300 Epoch=323.3] | Loss=0.00308 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.443 | L2-Norm(final)=17.409 | 5096.2 samples/s | 79.6 steps/s
[Step=66350 Epoch=323.5] | Loss=0.00292 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.444 | L2-Norm(final)=17.416 | 5085.3 samples/s | 79.5 steps/s
[Step=66400 Epoch=323.8] | Loss=0.00291 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.445 | L2-Norm(final)=17.424 | 6623.4 samples/s | 103.5 steps/s
[Step=66450 Epoch=324.0] | Loss=0.00285 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.446 | L2-Norm(final)=17.432 | 2271.8 samples/s | 35.5 steps/s
[Step=66500 Epoch=324.3] | Loss=0.00280 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.446 | L2-Norm(final)=17.440 | 4963.1 samples/s | 77.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=324.3] | Loss=0.00058 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.454 | L2-Norm(final)=17.518 | 5482.3 samples/s | 85.7 steps/s
[Step=66550 Epoch=324.5] | Loss=0.00347 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.457 | L2-Norm(final)=17.524 | 4168.9 samples/s | 65.1 steps/s
[Step=66600 Epoch=324.8] | Loss=0.00370 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=17.531 | 4397.6 samples/s | 68.7 steps/s
[Step=66650 Epoch=325.0] | Loss=0.00434 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=17.538 | 4466.5 samples/s | 69.8 steps/s
[Step=66700 Epoch=325.2] | Loss=0.00500 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.471 | L2-Norm(final)=17.545 | 6505.1 samples/s | 101.6 steps/s
[Step=66750 Epoch=325.5] | Loss=0.00482 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=17.551 | 2105.0 samples/s | 32.9 steps/s
[Step=66800 Epoch=325.7] | Loss=0.00500 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=17.556 | 4478.5 samples/s | 70.0 steps/s
[Step=66850 Epoch=326.0] | Loss=0.00472 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.484 | L2-Norm(final)=17.561 | 4492.2 samples/s | 70.2 steps/s
[Step=66900 Epoch=326.2] | Loss=0.00456 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.487 | L2-Norm(final)=17.566 | 5889.4 samples/s | 92.0 steps/s
[Step=66950 Epoch=326.5] | Loss=0.00429 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.490 | L2-Norm(final)=17.571 | 2183.1 samples/s | 34.1 steps/s
[Step=67000 Epoch=326.7] | Loss=0.00411 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=17.576 | 4533.0 samples/s | 70.8 steps/s
[Step=67050 Epoch=326.9] | Loss=0.00391 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.494 | L2-Norm(final)=17.580 | 4497.2 samples/s | 70.3 steps/s
[Step=67100 Epoch=327.2] | Loss=0.00387 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=17.584 | 5311.9 samples/s | 83.0 steps/s
[Step=67150 Epoch=327.4] | Loss=0.00380 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=17.588 | 2242.1 samples/s | 35.0 steps/s
[Step=67200 Epoch=327.7] | Loss=0.00364 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=17.592 | 4516.7 samples/s | 70.6 steps/s
[Step=67250 Epoch=327.9] | Loss=0.00353 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=17.595 | 4512.8 samples/s | 70.5 steps/s
[Step=67300 Epoch=328.2] | Loss=0.00356 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.498 | L2-Norm(final)=17.599 | 4924.4 samples/s | 76.9 steps/s
[Step=67350 Epoch=328.4] | Loss=0.00347 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=17.602 | 2346.2 samples/s | 36.7 steps/s
[Step=67400 Epoch=328.7] | Loss=0.00340 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=17.605 | 4446.4 samples/s | 69.5 steps/s
[Step=67450 Epoch=328.9] | Loss=0.00330 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.498 | L2-Norm(final)=17.609 | 4504.6 samples/s | 70.4 steps/s
[Step=67500 Epoch=329.1] | Loss=0.00326 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=17.612 | 4594.7 samples/s | 71.8 steps/s
[Step=67550 Epoch=329.4] | Loss=0.00318 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=17.615 | 2435.1 samples/s | 38.0 steps/s
[Step=67600 Epoch=329.6] | Loss=0.00311 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=17.618 | 4405.2 samples/s | 68.8 steps/s
[Step=67650 Epoch=329.9] | Loss=0.00307 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=17.620 | 4451.3 samples/s | 69.6 steps/s
[Step=67700 Epoch=330.1] | Loss=0.00305 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.496 | L2-Norm(final)=17.623 | 4551.2 samples/s | 71.1 steps/s
[Step=67750 Epoch=330.4] | Loss=0.00300 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=17.626 | 2484.8 samples/s | 38.8 steps/s
[Step=67800 Epoch=330.6] | Loss=0.00294 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.494 | L2-Norm(final)=17.629 | 4360.6 samples/s | 68.1 steps/s
[Step=67850 Epoch=330.8] | Loss=0.00293 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=17.632 | 4499.6 samples/s | 70.3 steps/s
[Step=67900 Epoch=331.1] | Loss=0.00290 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=17.634 | 4453.8 samples/s | 69.6 steps/s
[Step=67950 Epoch=331.3] | Loss=0.00285 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.491 | L2-Norm(final)=17.637 | 2464.1 samples/s | 38.5 steps/s
[Step=68000 Epoch=331.6] | Loss=0.00280 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.490 | L2-Norm(final)=17.639 | 4512.8 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step68000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=322.1] | Loss=0.00080 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.076 | L2-Norm(final)=17.961 | 5142.5 samples/s | 80.4 steps/s
[Step=66050 Epoch=322.3] | Loss=0.00348 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=17.969 | 4399.5 samples/s | 68.7 steps/s
[Step=66100 Epoch=322.5] | Loss=0.00266 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=17.977 | 5176.9 samples/s | 80.9 steps/s
[Step=66150 Epoch=322.8] | Loss=0.00265 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=17.986 | 4952.6 samples/s | 77.4 steps/s
[Step=66200 Epoch=323.0] | Loss=0.00262 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=17.994 | 7766.8 samples/s | 121.4 steps/s
[Step=66250 Epoch=323.3] | Loss=0.00251 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.085 | L2-Norm(final)=18.003 | 2199.5 samples/s | 34.4 steps/s
[Step=66300 Epoch=323.5] | Loss=0.00258 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=18.012 | 5101.0 samples/s | 79.7 steps/s
[Step=66350 Epoch=323.8] | Loss=0.00251 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=18.021 | 5069.8 samples/s | 79.2 steps/s
[Step=66400 Epoch=324.0] | Loss=0.00243 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.089 | L2-Norm(final)=18.030 | 6966.8 samples/s | 108.9 steps/s
[Step=66450 Epoch=324.2] | Loss=0.00244 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=18.038 | 2280.4 samples/s | 35.6 steps/s
[Step=66500 Epoch=324.5] | Loss=0.00240 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=18.047 | 5044.8 samples/s | 78.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=324.5] | Loss=0.00115 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.099 | L2-Norm(final)=18.129 | 5447.1 samples/s | 85.1 steps/s
[Step=66550 Epoch=324.7] | Loss=0.00278 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.100 | L2-Norm(final)=18.135 | 4007.3 samples/s | 62.6 steps/s
[Step=66600 Epoch=325.0] | Loss=0.00373 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.103 | L2-Norm(final)=18.142 | 4477.6 samples/s | 70.0 steps/s
[Step=66650 Epoch=325.2] | Loss=0.00362 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.107 | L2-Norm(final)=18.149 | 4534.4 samples/s | 70.9 steps/s
[Step=66700 Epoch=325.5] | Loss=0.00394 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.111 | L2-Norm(final)=18.156 | 6470.4 samples/s | 101.1 steps/s
[Step=66750 Epoch=325.7] | Loss=0.00359 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=18.163 | 2083.8 samples/s | 32.6 steps/s
[Step=66800 Epoch=326.0] | Loss=0.00350 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=18.170 | 4550.2 samples/s | 71.1 steps/s
[Step=66850 Epoch=326.2] | Loss=0.00334 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=18.177 | 4419.1 samples/s | 69.0 steps/s
[Step=66900 Epoch=326.4] | Loss=0.00337 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=18.183 | 6031.8 samples/s | 94.2 steps/s
[Step=66950 Epoch=326.7] | Loss=0.00316 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.126 | L2-Norm(final)=18.189 | 2133.3 samples/s | 33.3 steps/s
[Step=67000 Epoch=326.9] | Loss=0.00312 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.127 | L2-Norm(final)=18.194 | 4490.1 samples/s | 70.2 steps/s
[Step=67050 Epoch=327.2] | Loss=0.00304 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=18.199 | 4555.2 samples/s | 71.2 steps/s
[Step=67100 Epoch=327.4] | Loss=0.00295 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=18.204 | 5489.8 samples/s | 85.8 steps/s
[Step=67150 Epoch=327.7] | Loss=0.00287 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=18.209 | 2242.6 samples/s | 35.0 steps/s
[Step=67200 Epoch=327.9] | Loss=0.00279 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=18.214 | 4420.1 samples/s | 69.1 steps/s
[Step=67250 Epoch=328.1] | Loss=0.00279 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=18.219 | 4488.7 samples/s | 70.1 steps/s
[Step=67300 Epoch=328.4] | Loss=0.00277 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=18.223 | 5156.5 samples/s | 80.6 steps/s
[Step=67350 Epoch=328.6] | Loss=0.00277 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=18.227 | 2275.3 samples/s | 35.6 steps/s
[Step=67400 Epoch=328.9] | Loss=0.00268 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=18.232 | 4482.9 samples/s | 70.0 steps/s
[Step=67450 Epoch=329.1] | Loss=0.00266 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=18.236 | 4472.7 samples/s | 69.9 steps/s
[Step=67500 Epoch=329.4] | Loss=0.00262 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=18.240 | 4829.1 samples/s | 75.5 steps/s
[Step=67550 Epoch=329.6] | Loss=0.00260 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=18.244 | 2348.1 samples/s | 36.7 steps/s
[Step=67600 Epoch=329.9] | Loss=0.00257 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=18.248 | 4506.1 samples/s | 70.4 steps/s
[Step=67650 Epoch=330.1] | Loss=0.00256 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=18.251 | 4412.1 samples/s | 68.9 steps/s
[Step=67700 Epoch=330.3] | Loss=0.00253 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=18.255 | 4518.9 samples/s | 70.6 steps/s
[Step=67750 Epoch=330.6] | Loss=0.00248 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=18.259 | 2411.6 samples/s | 37.7 steps/s
[Step=67800 Epoch=330.8] | Loss=0.00253 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=18.262 | 4527.2 samples/s | 70.7 steps/s
[Step=67850 Epoch=331.1] | Loss=0.00249 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=18.266 | 4535.1 samples/s | 70.9 steps/s
[Step=67900 Epoch=331.3] | Loss=0.00246 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=18.269 | 4416.1 samples/s | 69.0 steps/s
[Step=67950 Epoch=331.6] | Loss=0.00244 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=18.273 | 2464.5 samples/s | 38.5 steps/s
[Step=68000 Epoch=331.8] | Loss=0.00242 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=18.276 | 4457.2 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step68000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=321.6] | Loss=0.00360 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.812 | L2-Norm(final)=18.187 | 5008.0 samples/s | 78.3 steps/s
[Step=66050 Epoch=321.8] | Loss=0.00322 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=18.193 | 4504.7 samples/s | 70.4 steps/s
[Step=66100 Epoch=322.1] | Loss=0.00311 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=18.203 | 5012.2 samples/s | 78.3 steps/s
[Step=66150 Epoch=322.3] | Loss=0.00330 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.818 | L2-Norm(final)=18.212 | 5184.0 samples/s | 81.0 steps/s
[Step=66200 Epoch=322.6] | Loss=0.00308 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.819 | L2-Norm(final)=18.221 | 7509.2 samples/s | 117.3 steps/s
[Step=66250 Epoch=322.8] | Loss=0.00286 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.821 | L2-Norm(final)=18.230 | 2208.3 samples/s | 34.5 steps/s
[Step=66300 Epoch=323.0] | Loss=0.00282 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.822 | L2-Norm(final)=18.239 | 5137.3 samples/s | 80.3 steps/s
[Step=66350 Epoch=323.3] | Loss=0.00287 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.823 | L2-Norm(final)=18.248 | 4972.4 samples/s | 77.7 steps/s
[Step=66400 Epoch=323.5] | Loss=0.00288 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=18.257 | 6949.5 samples/s | 108.6 steps/s
[Step=66450 Epoch=323.8] | Loss=0.00288 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.826 | L2-Norm(final)=18.265 | 2297.7 samples/s | 35.9 steps/s
[Step=66500 Epoch=324.0] | Loss=0.00282 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.827 | L2-Norm(final)=18.274 | 5151.4 samples/s | 80.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=324.0] | Loss=0.00356 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.838 | L2-Norm(final)=18.362 | 5243.5 samples/s | 81.9 steps/s
[Step=66550 Epoch=324.3] | Loss=0.00334 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.841 | L2-Norm(final)=18.371 | 4115.9 samples/s | 64.3 steps/s
[Step=66600 Epoch=324.5] | Loss=0.00415 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.845 | L2-Norm(final)=18.379 | 4393.5 samples/s | 68.6 steps/s
[Step=66650 Epoch=324.8] | Loss=0.00482 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.850 | L2-Norm(final)=18.387 | 4492.1 samples/s | 70.2 steps/s
[Step=66700 Epoch=325.0] | Loss=0.00497 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.857 | L2-Norm(final)=18.395 | 6593.6 samples/s | 103.0 steps/s
[Step=66750 Epoch=325.2] | Loss=0.00483 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.862 | L2-Norm(final)=18.402 | 2106.8 samples/s | 32.9 steps/s
[Step=66800 Epoch=325.5] | Loss=0.00469 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=18.409 | 4568.4 samples/s | 71.4 steps/s
[Step=66850 Epoch=325.7] | Loss=0.00468 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.870 | L2-Norm(final)=18.415 | 4373.6 samples/s | 68.3 steps/s
[Step=66900 Epoch=326.0] | Loss=0.00452 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.873 | L2-Norm(final)=18.420 | 5822.4 samples/s | 91.0 steps/s
[Step=66950 Epoch=326.2] | Loss=0.00430 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.876 | L2-Norm(final)=18.425 | 2217.3 samples/s | 34.6 steps/s
[Step=67000 Epoch=326.5] | Loss=0.00409 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.877 | L2-Norm(final)=18.430 | 4359.6 samples/s | 68.1 steps/s
[Step=67050 Epoch=326.7] | Loss=0.00408 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.879 | L2-Norm(final)=18.435 | 4468.0 samples/s | 69.8 steps/s
[Step=67100 Epoch=326.9] | Loss=0.00400 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=18.439 | 5427.3 samples/s | 84.8 steps/s
[Step=67150 Epoch=327.2] | Loss=0.00382 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=18.443 | 2247.6 samples/s | 35.1 steps/s
[Step=67200 Epoch=327.4] | Loss=0.00368 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=18.447 | 4463.0 samples/s | 69.7 steps/s
[Step=67250 Epoch=327.7] | Loss=0.00376 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=18.451 | 4479.5 samples/s | 70.0 steps/s
[Step=67300 Epoch=327.9] | Loss=0.00378 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=18.455 | 5015.1 samples/s | 78.4 steps/s
[Step=67350 Epoch=328.2] | Loss=0.00364 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=18.458 | 2327.3 samples/s | 36.4 steps/s
[Step=67400 Epoch=328.4] | Loss=0.00354 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=18.461 | 4461.3 samples/s | 69.7 steps/s
[Step=67450 Epoch=328.6] | Loss=0.00345 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=18.465 | 4488.3 samples/s | 70.1 steps/s
[Step=67500 Epoch=328.9] | Loss=0.00337 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=18.468 | 4605.4 samples/s | 72.0 steps/s
[Step=67550 Epoch=329.1] | Loss=0.00332 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=18.471 | 2404.9 samples/s | 37.6 steps/s
[Step=67600 Epoch=329.4] | Loss=0.00329 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.879 | L2-Norm(final)=18.474 | 4577.7 samples/s | 71.5 steps/s
[Step=67650 Epoch=329.6] | Loss=0.00322 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=18.477 | 4415.7 samples/s | 69.0 steps/s
[Step=67700 Epoch=329.9] | Loss=0.00314 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.877 | L2-Norm(final)=18.480 | 4490.8 samples/s | 70.2 steps/s
[Step=67750 Epoch=330.1] | Loss=0.00310 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.876 | L2-Norm(final)=18.483 | 2501.4 samples/s | 39.1 steps/s
[Step=67800 Epoch=330.4] | Loss=0.00305 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.875 | L2-Norm(final)=18.486 | 4445.2 samples/s | 69.5 steps/s
[Step=67850 Epoch=330.6] | Loss=0.00298 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.874 | L2-Norm(final)=18.489 | 4514.4 samples/s | 70.5 steps/s
[Step=67900 Epoch=330.8] | Loss=0.00294 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.872 | L2-Norm(final)=18.491 | 4455.6 samples/s | 69.6 steps/s
[Step=67950 Epoch=331.1] | Loss=0.00291 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.871 | L2-Norm(final)=18.494 | 2499.5 samples/s | 39.1 steps/s
[Step=68000 Epoch=331.3] | Loss=0.00287 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.869 | L2-Norm(final)=18.497 | 4417.9 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step68000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=321.9] | Loss=0.00105 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=18.158 | 4909.9 samples/s | 76.7 steps/s
[Step=66050 Epoch=322.1] | Loss=0.00354 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=18.166 | 4742.0 samples/s | 74.1 steps/s
[Step=66100 Epoch=322.3] | Loss=0.00293 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=18.174 | 4839.2 samples/s | 75.6 steps/s
[Step=66150 Epoch=322.6] | Loss=0.00274 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=18.183 | 5160.8 samples/s | 80.6 steps/s
[Step=66200 Epoch=322.8] | Loss=0.00259 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.499 | L2-Norm(final)=18.193 | 7564.6 samples/s | 118.2 steps/s
[Step=66250 Epoch=323.1] | Loss=0.00251 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.500 | L2-Norm(final)=18.202 | 2227.7 samples/s | 34.8 steps/s
[Step=66300 Epoch=323.3] | Loss=0.00247 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.501 | L2-Norm(final)=18.211 | 5026.1 samples/s | 78.5 steps/s
[Step=66350 Epoch=323.6] | Loss=0.00242 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=18.220 | 5063.0 samples/s | 79.1 steps/s
[Step=66400 Epoch=323.8] | Loss=0.00242 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.503 | L2-Norm(final)=18.229 | 6907.4 samples/s | 107.9 steps/s
[Step=66450 Epoch=324.0] | Loss=0.00236 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=18.238 | 2308.2 samples/s | 36.1 steps/s
[Step=66500 Epoch=324.3] | Loss=0.00235 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=18.247 | 5161.6 samples/s | 80.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=324.3] | Loss=0.00047 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=18.334 | 5181.0 samples/s | 81.0 steps/s
[Step=66550 Epoch=324.5] | Loss=0.00319 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=18.343 | 4138.5 samples/s | 64.7 steps/s
[Step=66600 Epoch=324.8] | Loss=0.00395 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.523 | L2-Norm(final)=18.352 | 4475.1 samples/s | 69.9 steps/s
[Step=66650 Epoch=325.0] | Loss=0.00385 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=18.362 | 4475.7 samples/s | 69.9 steps/s
[Step=66700 Epoch=325.3] | Loss=0.00390 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.537 | L2-Norm(final)=18.371 | 6565.2 samples/s | 102.6 steps/s
[Step=66750 Epoch=325.5] | Loss=0.00401 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=18.379 | 2087.6 samples/s | 32.6 steps/s
[Step=66800 Epoch=325.8] | Loss=0.00384 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=18.387 | 4495.6 samples/s | 70.2 steps/s
[Step=66850 Epoch=326.0] | Loss=0.00380 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=18.394 | 4462.3 samples/s | 69.7 steps/s
[Step=66900 Epoch=326.2] | Loss=0.00364 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=18.400 | 5905.3 samples/s | 92.3 steps/s
[Step=66950 Epoch=326.5] | Loss=0.00365 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.557 | L2-Norm(final)=18.405 | 2093.6 samples/s | 32.7 steps/s
[Step=67000 Epoch=326.7] | Loss=0.00351 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=18.411 | 4388.9 samples/s | 68.6 steps/s
[Step=67050 Epoch=327.0] | Loss=0.00335 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=18.416 | 4439.6 samples/s | 69.4 steps/s
[Step=67100 Epoch=327.2] | Loss=0.00321 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.562 | L2-Norm(final)=18.421 | 5237.0 samples/s | 81.8 steps/s
[Step=67150 Epoch=327.5] | Loss=0.00310 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=18.425 | 2228.4 samples/s | 34.8 steps/s
[Step=67200 Epoch=327.7] | Loss=0.00306 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=18.430 | 4223.0 samples/s | 66.0 steps/s
[Step=67250 Epoch=327.9] | Loss=0.00300 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=18.434 | 4341.5 samples/s | 67.8 steps/s
[Step=67300 Epoch=328.2] | Loss=0.00297 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=18.437 | 4880.5 samples/s | 76.3 steps/s
[Step=67350 Epoch=328.4] | Loss=0.00285 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=18.441 | 2321.1 samples/s | 36.3 steps/s
[Step=67400 Epoch=328.7] | Loss=0.00279 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=18.445 | 4420.4 samples/s | 69.1 steps/s
[Step=67450 Epoch=328.9] | Loss=0.00273 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=18.448 | 4463.2 samples/s | 69.7 steps/s
[Step=67500 Epoch=329.2] | Loss=0.00267 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=18.452 | 4563.1 samples/s | 71.3 steps/s
[Step=67550 Epoch=329.4] | Loss=0.00264 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=18.455 | 2411.4 samples/s | 37.7 steps/s
[Step=67600 Epoch=329.7] | Loss=0.00255 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=18.459 | 4474.6 samples/s | 69.9 steps/s
[Step=67650 Epoch=329.9] | Loss=0.00251 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=18.462 | 4462.9 samples/s | 69.7 steps/s
[Step=67700 Epoch=330.1] | Loss=0.00250 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.562 | L2-Norm(final)=18.465 | 4376.7 samples/s | 68.4 steps/s
[Step=67750 Epoch=330.4] | Loss=0.00246 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=18.468 | 2441.6 samples/s | 38.1 steps/s
[Step=67800 Epoch=330.6] | Loss=0.00242 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.560 | L2-Norm(final)=18.471 | 4401.7 samples/s | 68.8 steps/s
[Step=67850 Epoch=330.9] | Loss=0.00236 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=18.474 | 4470.4 samples/s | 69.8 steps/s
[Step=67900 Epoch=331.1] | Loss=0.00234 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.557 | L2-Norm(final)=18.477 | 4477.5 samples/s | 70.0 steps/s
[Step=67950 Epoch=331.4] | Loss=0.00234 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.556 | L2-Norm(final)=18.480 | 2410.7 samples/s | 37.7 steps/s
[Step=68000 Epoch=331.6] | Loss=0.00231 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.555 | L2-Norm(final)=18.483 | 4419.4 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step68000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=323.7] | Loss=0.00587 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=18.212 | 5257.4 samples/s | 82.1 steps/s
[Step=66050 Epoch=323.9] | Loss=0.00247 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=18.220 | 4482.0 samples/s | 70.0 steps/s
[Step=66100 Epoch=324.1] | Loss=0.00264 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.235 | L2-Norm(final)=18.228 | 4925.9 samples/s | 77.0 steps/s
[Step=66150 Epoch=324.4] | Loss=0.00250 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=18.238 | 5030.0 samples/s | 78.6 steps/s
[Step=66200 Epoch=324.6] | Loss=0.00240 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=18.247 | 7940.4 samples/s | 124.1 steps/s
[Step=66250 Epoch=324.9] | Loss=0.00236 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.239 | L2-Norm(final)=18.256 | 2169.7 samples/s | 33.9 steps/s
[Step=66300 Epoch=325.1] | Loss=0.00231 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=18.265 | 4936.5 samples/s | 77.1 steps/s
[Step=66350 Epoch=325.4] | Loss=0.00218 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=18.274 | 4958.6 samples/s | 77.5 steps/s
[Step=66400 Epoch=325.6] | Loss=0.00224 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=18.283 | 7362.8 samples/s | 115.0 steps/s
[Step=66450 Epoch=325.9] | Loss=0.00231 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=18.292 | 2212.8 samples/s | 34.6 steps/s
[Step=66500 Epoch=326.1] | Loss=0.00225 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=18.301 | 5034.2 samples/s | 78.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=326.1] | Loss=0.00394 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=18.388 | 5280.2 samples/s | 82.5 steps/s
[Step=66550 Epoch=326.4] | Loss=0.00220 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=18.397 | 3960.6 samples/s | 61.9 steps/s
[Step=66600 Epoch=326.6] | Loss=0.00261 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=18.406 | 4493.0 samples/s | 70.2 steps/s
[Step=66650 Epoch=326.8] | Loss=0.00312 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=18.414 | 4386.0 samples/s | 68.5 steps/s
[Step=66700 Epoch=327.1] | Loss=0.00386 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=18.421 | 6564.6 samples/s | 102.6 steps/s
[Step=66750 Epoch=327.3] | Loss=0.00396 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.272 | L2-Norm(final)=18.428 | 2054.7 samples/s | 32.1 steps/s
[Step=66800 Epoch=327.6] | Loss=0.00380 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.276 | L2-Norm(final)=18.435 | 4319.8 samples/s | 67.5 steps/s
[Step=66850 Epoch=327.8] | Loss=0.00397 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.279 | L2-Norm(final)=18.441 | 4422.7 samples/s | 69.1 steps/s
[Step=66900 Epoch=328.1] | Loss=0.00376 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.281 | L2-Norm(final)=18.446 | 6215.4 samples/s | 97.1 steps/s
[Step=66950 Epoch=328.3] | Loss=0.00363 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=18.452 | 2088.4 samples/s | 32.6 steps/s
[Step=67000 Epoch=328.6] | Loss=0.00351 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.285 | L2-Norm(final)=18.457 | 4390.6 samples/s | 68.6 steps/s
[Step=67050 Epoch=328.8] | Loss=0.00338 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=18.461 | 4563.8 samples/s | 71.3 steps/s
[Step=67100 Epoch=329.0] | Loss=0.00331 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=18.466 | 5591.6 samples/s | 87.4 steps/s
[Step=67150 Epoch=329.3] | Loss=0.00315 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=18.470 | 2150.0 samples/s | 33.6 steps/s
[Step=67200 Epoch=329.5] | Loss=0.00302 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=18.475 | 4419.8 samples/s | 69.1 steps/s
[Step=67250 Epoch=329.8] | Loss=0.00291 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=18.479 | 4434.6 samples/s | 69.3 steps/s
[Step=67300 Epoch=330.0] | Loss=0.00284 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=18.483 | 5438.6 samples/s | 85.0 steps/s
[Step=67350 Epoch=330.3] | Loss=0.00281 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=18.486 | 2175.9 samples/s | 34.0 steps/s
[Step=67400 Epoch=330.5] | Loss=0.00271 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=18.490 | 4390.6 samples/s | 68.6 steps/s
[Step=67450 Epoch=330.8] | Loss=0.00264 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=18.494 | 4408.9 samples/s | 68.9 steps/s
[Step=67500 Epoch=331.0] | Loss=0.00260 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=18.497 | 5140.1 samples/s | 80.3 steps/s
[Step=67550 Epoch=331.3] | Loss=0.00253 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.285 | L2-Norm(final)=18.501 | 2246.2 samples/s | 35.1 steps/s
[Step=67600 Epoch=331.5] | Loss=0.00246 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.284 | L2-Norm(final)=18.504 | 4381.5 samples/s | 68.5 steps/s
[Step=67650 Epoch=331.7] | Loss=0.00241 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=18.508 | 4439.9 samples/s | 69.4 steps/s
[Step=67700 Epoch=332.0] | Loss=0.00240 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.282 | L2-Norm(final)=18.511 | 4893.3 samples/s | 76.5 steps/s
[Step=67750 Epoch=332.2] | Loss=0.00238 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.281 | L2-Norm(final)=18.514 | 2303.7 samples/s | 36.0 steps/s
[Step=67800 Epoch=332.5] | Loss=0.00236 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=18.517 | 4339.4 samples/s | 67.8 steps/s
[Step=67850 Epoch=332.7] | Loss=0.00232 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.279 | L2-Norm(final)=18.520 | 4412.2 samples/s | 68.9 steps/s
[Step=67900 Epoch=333.0] | Loss=0.00228 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.277 | L2-Norm(final)=18.524 | 4643.0 samples/s | 72.5 steps/s
[Step=67950 Epoch=333.2] | Loss=0.00225 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.276 | L2-Norm(final)=18.527 | 2366.3 samples/s | 37.0 steps/s
[Step=68000 Epoch=333.5] | Loss=0.00227 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.274 | L2-Norm(final)=18.530 | 4385.9 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step68000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=625.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.136 | 5378.8 samples/s | 84.0 steps/s
[Step=66050 Epoch=625.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.137 | 4123.9 samples/s | 64.4 steps/s
[Step=66100 Epoch=626.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.139 | 7037.4 samples/s | 110.0 steps/s
[Step=66150 Epoch=626.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.934 | L2-Norm(final)=9.141 | 2092.0 samples/s | 32.7 steps/s
[Step=66200 Epoch=627.3] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=9.143 | 6513.2 samples/s | 101.8 steps/s
[Step=66250 Epoch=627.8] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=9.145 | 2202.3 samples/s | 34.4 steps/s
[Step=66300 Epoch=628.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.936 | L2-Norm(final)=9.147 | 5722.4 samples/s | 89.4 steps/s
[Step=66350 Epoch=628.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.149 | 2306.9 samples/s | 36.0 steps/s
[Step=66400 Epoch=629.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.151 | 5180.0 samples/s | 80.9 steps/s
[Step=66450 Epoch=629.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=9.153 | 2377.6 samples/s | 37.1 steps/s
[Step=66500 Epoch=630.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=9.155 | 4805.0 samples/s | 75.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=630.2] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=9.175 | 5381.6 samples/s | 84.1 steps/s
[Step=66550 Epoch=630.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=9.177 | 3687.2 samples/s | 57.6 steps/s
[Step=66600 Epoch=631.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.941 | L2-Norm(final)=9.178 | 6240.2 samples/s | 97.5 steps/s
[Step=66650 Epoch=631.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.939 | L2-Norm(final)=9.180 | 2007.2 samples/s | 31.4 steps/s
[Step=66700 Epoch=632.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.181 | 5481.2 samples/s | 85.6 steps/s
[Step=66750 Epoch=632.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.934 | L2-Norm(final)=9.182 | 2072.3 samples/s | 32.4 steps/s
[Step=66800 Epoch=633.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.183 | 5048.8 samples/s | 78.9 steps/s
[Step=66850 Epoch=633.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.184 | 2160.2 samples/s | 33.8 steps/s
[Step=66900 Epoch=633.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=9.184 | 4590.8 samples/s | 71.7 steps/s
[Step=66950 Epoch=634.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=9.185 | 2230.8 samples/s | 34.9 steps/s
[Step=67000 Epoch=634.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.920 | L2-Norm(final)=9.186 | 4308.7 samples/s | 67.3 steps/s
[Step=67050 Epoch=635.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.917 | L2-Norm(final)=9.187 | 2333.8 samples/s | 36.5 steps/s
[Step=67100 Epoch=635.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.914 | L2-Norm(final)=9.187 | 4195.9 samples/s | 65.6 steps/s
[Step=67150 Epoch=636.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.911 | L2-Norm(final)=9.188 | 2355.3 samples/s | 36.8 steps/s
[Step=67200 Epoch=636.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.908 | L2-Norm(final)=9.189 | 4295.0 samples/s | 67.1 steps/s
[Step=67250 Epoch=637.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.904 | L2-Norm(final)=9.189 | 2340.3 samples/s | 36.6 steps/s
[Step=67300 Epoch=637.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.901 | L2-Norm(final)=9.190 | 4154.1 samples/s | 64.9 steps/s
[Step=67350 Epoch=638.2] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.897 | L2-Norm(final)=9.191 | 2413.1 samples/s | 37.7 steps/s
[Step=67400 Epoch=638.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.894 | L2-Norm(final)=9.191 | 4099.3 samples/s | 64.1 steps/s
[Step=67450 Epoch=639.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.890 | L2-Norm(final)=9.192 | 6380.5 samples/s | 99.7 steps/s
[Step=67500 Epoch=639.6] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=9.193 | 1974.9 samples/s | 30.9 steps/s
[Step=67550 Epoch=640.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=9.193 | 5647.5 samples/s | 88.2 steps/s
[Step=67600 Epoch=640.6] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.879 | L2-Norm(final)=9.194 | 2037.8 samples/s | 31.8 steps/s
[Step=67650 Epoch=641.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.875 | L2-Norm(final)=9.195 | 5225.0 samples/s | 81.6 steps/s
[Step=67700 Epoch=641.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.871 | L2-Norm(final)=9.195 | 2141.6 samples/s | 33.5 steps/s
[Step=67750 Epoch=642.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.867 | L2-Norm(final)=9.196 | 4798.9 samples/s | 75.0 steps/s
[Step=67800 Epoch=642.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=9.196 | 2171.6 samples/s | 33.9 steps/s
[Step=67850 Epoch=642.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=9.197 | 4427.7 samples/s | 69.2 steps/s
[Step=67900 Epoch=643.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=9.198 | 2304.5 samples/s | 36.0 steps/s
[Step=67950 Epoch=643.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.851 | L2-Norm(final)=9.198 | 4215.9 samples/s | 65.9 steps/s
[Step=68000 Epoch=644.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.846 | L2-Norm(final)=9.199 | 2384.1 samples/s | 37.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step68000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=627.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=10.153 | 5117.7 samples/s | 80.0 steps/s
[Step=66050 Epoch=628.3] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=10.153 | 4223.2 samples/s | 66.0 steps/s
[Step=66100 Epoch=628.8] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.944 | L2-Norm(final)=10.154 | 7284.7 samples/s | 113.8 steps/s
[Step=66150 Epoch=629.3] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.945 | L2-Norm(final)=10.155 | 2131.7 samples/s | 33.3 steps/s
[Step=66200 Epoch=629.7] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.945 | L2-Norm(final)=10.156 | 6269.2 samples/s | 98.0 steps/s
[Step=66250 Epoch=630.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=10.157 | 2220.0 samples/s | 34.7 steps/s
[Step=66300 Epoch=630.7] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=10.158 | 5815.5 samples/s | 90.9 steps/s
[Step=66350 Epoch=631.2] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.947 | L2-Norm(final)=10.159 | 2290.9 samples/s | 35.8 steps/s
[Step=66400 Epoch=631.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.947 | L2-Norm(final)=10.160 | 5379.6 samples/s | 84.1 steps/s
[Step=66450 Epoch=632.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.947 | L2-Norm(final)=10.160 | 2410.0 samples/s | 37.7 steps/s
[Step=66500 Epoch=632.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.947 | L2-Norm(final)=10.161 | 4904.9 samples/s | 76.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=632.6] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=10.170 | 5763.0 samples/s | 90.0 steps/s
[Step=66550 Epoch=633.1] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=10.171 | 3648.2 samples/s | 57.0 steps/s
[Step=66600 Epoch=633.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.950 | L2-Norm(final)=10.172 | 6276.0 samples/s | 98.1 steps/s
[Step=66650 Epoch=634.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.949 | L2-Norm(final)=10.173 | 1974.8 samples/s | 30.9 steps/s
[Step=66700 Epoch=634.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.948 | L2-Norm(final)=10.173 | 5373.7 samples/s | 84.0 steps/s
[Step=66750 Epoch=635.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.947 | L2-Norm(final)=10.174 | 1959.4 samples/s | 30.6 steps/s
[Step=66800 Epoch=635.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.945 | L2-Norm(final)=10.175 | 4916.6 samples/s | 76.8 steps/s
[Step=66850 Epoch=635.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.944 | L2-Norm(final)=10.175 | 2025.7 samples/s | 31.7 steps/s
[Step=66900 Epoch=636.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=10.176 | 4420.0 samples/s | 69.1 steps/s
[Step=66950 Epoch=636.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.941 | L2-Norm(final)=10.176 | 2079.9 samples/s | 32.5 steps/s
[Step=67000 Epoch=637.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.940 | L2-Norm(final)=10.177 | 4166.0 samples/s | 65.1 steps/s
[Step=67050 Epoch=637.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=10.177 | 2283.8 samples/s | 35.7 steps/s
[Step=67100 Epoch=638.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=10.178 | 4275.0 samples/s | 66.8 steps/s
[Step=67150 Epoch=638.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=10.178 | 2440.1 samples/s | 38.1 steps/s
[Step=67200 Epoch=639.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=10.179 | 4202.3 samples/s | 65.7 steps/s
[Step=67250 Epoch=639.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=10.179 | 2346.9 samples/s | 36.7 steps/s
[Step=67300 Epoch=640.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.930 | L2-Norm(final)=10.179 | 4239.6 samples/s | 66.2 steps/s
[Step=67350 Epoch=640.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=10.180 | 2545.6 samples/s | 39.8 steps/s
[Step=67400 Epoch=641.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=10.180 | 3876.8 samples/s | 60.6 steps/s
[Step=67450 Epoch=641.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.924 | L2-Norm(final)=10.181 | 6568.7 samples/s | 102.6 steps/s
[Step=67500 Epoch=642.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.922 | L2-Norm(final)=10.181 | 1964.8 samples/s | 30.7 steps/s
[Step=67550 Epoch=642.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.920 | L2-Norm(final)=10.182 | 5925.4 samples/s | 92.6 steps/s
[Step=67600 Epoch=643.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.918 | L2-Norm(final)=10.182 | 2116.3 samples/s | 33.1 steps/s
[Step=67650 Epoch=643.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.916 | L2-Norm(final)=10.182 | 5174.4 samples/s | 80.8 steps/s
[Step=67700 Epoch=644.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.914 | L2-Norm(final)=10.183 | 2149.5 samples/s | 33.6 steps/s
[Step=67750 Epoch=644.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.912 | L2-Norm(final)=10.183 | 4845.6 samples/s | 75.7 steps/s
[Step=67800 Epoch=644.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.910 | L2-Norm(final)=10.184 | 2211.7 samples/s | 34.6 steps/s
[Step=67850 Epoch=645.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.908 | L2-Norm(final)=10.184 | 4487.8 samples/s | 70.1 steps/s
[Step=67900 Epoch=645.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.905 | L2-Norm(final)=10.185 | 2324.1 samples/s | 36.3 steps/s
[Step=67950 Epoch=646.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.903 | L2-Norm(final)=10.185 | 4206.4 samples/s | 65.7 steps/s
[Step=68000 Epoch=646.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.901 | L2-Norm(final)=10.185 | 2371.9 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step68000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=630.3] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.836 | L2-Norm(final)=9.655 | 5506.5 samples/s | 86.0 steps/s
[Step=66050 Epoch=630.7] | Loss=0.00005 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.844 | L2-Norm(final)=9.675 | 3877.8 samples/s | 60.6 steps/s
[Step=66100 Epoch=631.2] | Loss=0.00005 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.854 | L2-Norm(final)=9.697 | 7421.4 samples/s | 116.0 steps/s
[Step=66150 Epoch=631.7] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=9.715 | 2076.1 samples/s | 32.4 steps/s
[Step=66200 Epoch=632.2] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=9.730 | 6546.5 samples/s | 102.3 steps/s
[Step=66250 Epoch=632.6] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.872 | L2-Norm(final)=9.742 | 2189.8 samples/s | 34.2 steps/s
[Step=66300 Epoch=633.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.875 | L2-Norm(final)=9.753 | 6163.9 samples/s | 96.3 steps/s
[Step=66350 Epoch=633.6] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=9.764 | 2265.9 samples/s | 35.4 steps/s
[Step=66400 Epoch=634.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.880 | L2-Norm(final)=9.774 | 5437.9 samples/s | 85.0 steps/s
[Step=66450 Epoch=634.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=9.783 | 2352.6 samples/s | 36.8 steps/s
[Step=66500 Epoch=635.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.884 | L2-Norm(final)=9.792 | 5213.3 samples/s | 81.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=635.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.900 | L2-Norm(final)=9.883 | 5161.1 samples/s | 80.6 steps/s
[Step=66550 Epoch=635.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.891 | L2-Norm(final)=9.890 | 3859.7 samples/s | 60.3 steps/s
[Step=66600 Epoch=636.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.874 | L2-Norm(final)=9.894 | 6340.1 samples/s | 99.1 steps/s
[Step=66650 Epoch=636.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=9.898 | 1995.5 samples/s | 31.2 steps/s
[Step=66700 Epoch=636.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.835 | L2-Norm(final)=9.900 | 5696.9 samples/s | 89.0 steps/s
[Step=66750 Epoch=637.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.814 | L2-Norm(final)=9.903 | 2044.9 samples/s | 32.0 steps/s
[Step=66800 Epoch=637.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.792 | L2-Norm(final)=9.904 | 5383.5 samples/s | 84.1 steps/s
[Step=66850 Epoch=638.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.771 | L2-Norm(final)=9.906 | 2123.2 samples/s | 33.2 steps/s
[Step=66900 Epoch=638.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.749 | L2-Norm(final)=9.908 | 4996.1 samples/s | 78.1 steps/s
[Step=66950 Epoch=639.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.727 | L2-Norm(final)=9.910 | 2201.2 samples/s | 34.4 steps/s
[Step=67000 Epoch=639.8] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.705 | L2-Norm(final)=9.912 | 4615.7 samples/s | 72.1 steps/s
[Step=67050 Epoch=640.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.683 | L2-Norm(final)=9.913 | 2271.9 samples/s | 35.5 steps/s
[Step=67100 Epoch=640.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.661 | L2-Norm(final)=9.915 | 4354.0 samples/s | 68.0 steps/s
[Step=67150 Epoch=641.2] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.638 | L2-Norm(final)=9.917 | 2332.8 samples/s | 36.5 steps/s
[Step=67200 Epoch=641.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.616 | L2-Norm(final)=9.919 | 4277.3 samples/s | 66.8 steps/s
[Step=67250 Epoch=642.2] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.593 | L2-Norm(final)=9.921 | 2366.2 samples/s | 37.0 steps/s
[Step=67300 Epoch=642.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.571 | L2-Norm(final)=9.923 | 4248.5 samples/s | 66.4 steps/s
[Step=67350 Epoch=643.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.548 | L2-Norm(final)=9.925 | 2378.6 samples/s | 37.2 steps/s
[Step=67400 Epoch=643.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.526 | L2-Norm(final)=9.927 | 4225.4 samples/s | 66.0 steps/s
[Step=67450 Epoch=644.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.503 | L2-Norm(final)=9.930 | 2429.5 samples/s | 38.0 steps/s
[Step=67500 Epoch=644.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.480 | L2-Norm(final)=9.932 | 4166.2 samples/s | 65.1 steps/s
[Step=67550 Epoch=645.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.458 | L2-Norm(final)=9.934 | 6816.6 samples/s | 106.5 steps/s
[Step=67600 Epoch=645.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.435 | L2-Norm(final)=9.937 | 1916.1 samples/s | 29.9 steps/s
[Step=67650 Epoch=646.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.412 | L2-Norm(final)=9.939 | 6263.7 samples/s | 97.9 steps/s
[Step=67700 Epoch=646.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.389 | L2-Norm(final)=9.942 | 2033.5 samples/s | 31.8 steps/s
[Step=67750 Epoch=647.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.366 | L2-Norm(final)=9.945 | 5639.5 samples/s | 88.1 steps/s
[Step=67800 Epoch=647.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=9.947 | 2050.5 samples/s | 32.0 steps/s
[Step=67850 Epoch=647.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.320 | L2-Norm(final)=9.950 | 5252.1 samples/s | 82.1 steps/s
[Step=67900 Epoch=648.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.297 | L2-Norm(final)=9.953 | 2116.6 samples/s | 33.1 steps/s
[Step=67950 Epoch=648.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.274 | L2-Norm(final)=9.956 | 4988.9 samples/s | 78.0 steps/s
[Step=68000 Epoch=649.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.251 | L2-Norm(final)=9.959 | 2198.0 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step68000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=621.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.961 | L2-Norm(final)=9.781 | 5482.8 samples/s | 85.7 steps/s
[Step=66050 Epoch=622.4] | Loss=0.00023 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.977 | L2-Norm(final)=9.801 | 4071.2 samples/s | 63.6 steps/s
[Step=66100 Epoch=622.9] | Loss=0.00017 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.987 | L2-Norm(final)=9.817 | 7156.4 samples/s | 111.8 steps/s
[Step=66150 Epoch=623.3] | Loss=0.00013 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.994 | L2-Norm(final)=9.828 | 2121.7 samples/s | 33.2 steps/s
[Step=66200 Epoch=623.8] | Loss=0.00011 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.998 | L2-Norm(final)=9.836 | 6319.6 samples/s | 98.7 steps/s
[Step=66250 Epoch=624.3] | Loss=0.00009 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=9.843 | 2251.0 samples/s | 35.2 steps/s
[Step=66300 Epoch=624.7] | Loss=0.00008 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.004 | L2-Norm(final)=9.849 | 5615.3 samples/s | 87.7 steps/s
[Step=66350 Epoch=625.2] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.006 | L2-Norm(final)=9.854 | 2350.1 samples/s | 36.7 steps/s
[Step=66400 Epoch=625.7] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.008 | L2-Norm(final)=9.859 | 4942.8 samples/s | 77.2 steps/s
[Step=66450 Epoch=626.1] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=9.864 | 2480.5 samples/s | 38.8 steps/s
[Step=66500 Epoch=626.6] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.011 | L2-Norm(final)=9.869 | 4674.5 samples/s | 73.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=626.6] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=9.916 | 5308.9 samples/s | 83.0 steps/s
[Step=66550 Epoch=627.1] | Loss=0.00049 | Reg=0.00049 | acc=0.9844 | L2-Norm=7.031 | L2-Norm(final)=9.921 | 3817.1 samples/s | 59.6 steps/s
[Step=66600 Epoch=627.6] | Loss=0.00047 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.928 | 6063.7 samples/s | 94.7 steps/s
[Step=66650 Epoch=628.0] | Loss=0.00034 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.063 | L2-Norm(final)=9.933 | 2047.7 samples/s | 32.0 steps/s
[Step=66700 Epoch=628.5] | Loss=0.00026 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=9.935 | 5350.0 samples/s | 83.6 steps/s
[Step=66750 Epoch=629.0] | Loss=0.00021 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.072 | L2-Norm(final)=9.937 | 2121.7 samples/s | 33.2 steps/s
[Step=66800 Epoch=629.4] | Loss=0.00018 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.074 | L2-Norm(final)=9.939 | 4871.9 samples/s | 76.1 steps/s
[Step=66850 Epoch=629.9] | Loss=0.00016 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.940 | 2231.1 samples/s | 34.9 steps/s
[Step=66900 Epoch=630.4] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.941 | 4457.1 samples/s | 69.6 steps/s
[Step=66950 Epoch=630.9] | Loss=0.00012 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.942 | 2332.7 samples/s | 36.4 steps/s
[Step=67000 Epoch=631.3] | Loss=0.00011 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.943 | 4188.5 samples/s | 65.4 steps/s
[Step=67050 Epoch=631.8] | Loss=0.00010 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.944 | 2379.3 samples/s | 37.2 steps/s
[Step=67100 Epoch=632.3] | Loss=0.00009 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.944 | 4263.1 samples/s | 66.6 steps/s
[Step=67150 Epoch=632.7] | Loss=0.00009 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.074 | L2-Norm(final)=9.945 | 2405.9 samples/s | 37.6 steps/s
[Step=67200 Epoch=633.2] | Loss=0.00008 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.074 | L2-Norm(final)=9.946 | 4154.0 samples/s | 64.9 steps/s
[Step=67250 Epoch=633.7] | Loss=0.00008 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.073 | L2-Norm(final)=9.946 | 2652.6 samples/s | 41.4 steps/s
[Step=67300 Epoch=634.2] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.072 | L2-Norm(final)=9.947 | 3594.1 samples/s | 56.2 steps/s
[Step=67350 Epoch=634.6] | Loss=0.00007 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.071 | L2-Norm(final)=9.947 | 6191.2 samples/s | 96.7 steps/s
[Step=67400 Epoch=635.1] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.070 | L2-Norm(final)=9.948 | 2021.1 samples/s | 31.6 steps/s
[Step=67450 Epoch=635.6] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=9.948 | 5519.2 samples/s | 86.2 steps/s
[Step=67500 Epoch=636.0] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.068 | L2-Norm(final)=9.949 | 2135.8 samples/s | 33.4 steps/s
[Step=67550 Epoch=636.5] | Loss=0.00006 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=9.949 | 4978.5 samples/s | 77.8 steps/s
[Step=67600 Epoch=637.0] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.066 | L2-Norm(final)=9.949 | 2171.8 samples/s | 33.9 steps/s
[Step=67650 Epoch=637.5] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.065 | L2-Norm(final)=9.950 | 4491.8 samples/s | 70.2 steps/s
[Step=67700 Epoch=637.9] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.063 | L2-Norm(final)=9.950 | 2324.1 samples/s | 36.3 steps/s
[Step=67750 Epoch=638.4] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=9.951 | 4250.4 samples/s | 66.4 steps/s
[Step=67800 Epoch=638.9] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.061 | L2-Norm(final)=9.951 | 2394.9 samples/s | 37.4 steps/s
[Step=67850 Epoch=639.3] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.060 | L2-Norm(final)=9.952 | 4208.7 samples/s | 65.8 steps/s
[Step=67900 Epoch=639.8] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.058 | L2-Norm(final)=9.952 | 2358.8 samples/s | 36.9 steps/s
[Step=67950 Epoch=640.3] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=9.952 | 4212.3 samples/s | 65.8 steps/s
[Step=68000 Epoch=640.8] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.055 | L2-Norm(final)=9.953 | 2473.6 samples/s | 38.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step68000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=629.0] | Loss=0.00029 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.908 | L2-Norm(final)=10.215 | 5225.0 samples/s | 81.6 steps/s
[Step=66050 Epoch=629.5] | Loss=0.00007 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.917 | L2-Norm(final)=10.236 | 4025.0 samples/s | 62.9 steps/s
[Step=66100 Epoch=630.0] | Loss=0.00006 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=10.258 | 7650.8 samples/s | 119.5 steps/s
[Step=66150 Epoch=630.5] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.936 | L2-Norm(final)=10.275 | 2151.9 samples/s | 33.6 steps/s
[Step=66200 Epoch=630.9] | Loss=0.00005 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=10.289 | 6555.3 samples/s | 102.4 steps/s
[Step=66250 Epoch=631.4] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.946 | L2-Norm(final)=10.302 | 2197.0 samples/s | 34.3 steps/s
[Step=66300 Epoch=631.9] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.949 | L2-Norm(final)=10.313 | 6192.5 samples/s | 96.8 steps/s
[Step=66350 Epoch=632.4] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.952 | L2-Norm(final)=10.323 | 2264.7 samples/s | 35.4 steps/s
[Step=66400 Epoch=632.9] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.955 | L2-Norm(final)=10.333 | 5733.7 samples/s | 89.6 steps/s
[Step=66450 Epoch=633.3] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.957 | L2-Norm(final)=10.342 | 2343.8 samples/s | 36.6 steps/s
[Step=66500 Epoch=633.8] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.959 | L2-Norm(final)=10.351 | 5084.5 samples/s | 79.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=633.8] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.977 | L2-Norm(final)=10.440 | 5542.1 samples/s | 86.6 steps/s
[Step=66550 Epoch=634.3] | Loss=0.00011 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.979 | L2-Norm(final)=10.448 | 3692.5 samples/s | 57.7 steps/s
[Step=66600 Epoch=634.8] | Loss=0.00031 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.996 | L2-Norm(final)=10.456 | 6256.5 samples/s | 97.8 steps/s
[Step=66650 Epoch=635.2] | Loss=0.00025 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=10.462 | 2024.8 samples/s | 31.6 steps/s
[Step=66700 Epoch=635.7] | Loss=0.00019 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.022 | L2-Norm(final)=10.466 | 5779.4 samples/s | 90.3 steps/s
[Step=66750 Epoch=636.2] | Loss=0.00017 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=10.469 | 2040.5 samples/s | 31.9 steps/s
[Step=66800 Epoch=636.7] | Loss=0.00014 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=10.471 | 5344.5 samples/s | 83.5 steps/s
[Step=66850 Epoch=637.1] | Loss=0.00012 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.032 | L2-Norm(final)=10.473 | 2131.2 samples/s | 33.3 steps/s
[Step=66900 Epoch=637.6] | Loss=0.00011 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.474 | 5002.0 samples/s | 78.2 steps/s
[Step=66950 Epoch=638.1] | Loss=0.00010 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.475 | 2184.7 samples/s | 34.1 steps/s
[Step=67000 Epoch=638.6] | Loss=0.00009 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.476 | 4617.1 samples/s | 72.1 steps/s
[Step=67050 Epoch=639.0] | Loss=0.00008 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.477 | 2261.1 samples/s | 35.3 steps/s
[Step=67100 Epoch=639.5] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.478 | 4269.0 samples/s | 66.7 steps/s
[Step=67150 Epoch=640.0] | Loss=0.00007 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.032 | L2-Norm(final)=10.478 | 2352.0 samples/s | 36.8 steps/s
[Step=67200 Epoch=640.5] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=10.479 | 4255.8 samples/s | 66.5 steps/s
[Step=67250 Epoch=641.0] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=10.479 | 2434.4 samples/s | 38.0 steps/s
[Step=67300 Epoch=641.4] | Loss=0.00006 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=10.480 | 4032.7 samples/s | 63.0 steps/s
[Step=67350 Epoch=641.9] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.029 | L2-Norm(final)=10.480 | 2411.3 samples/s | 37.7 steps/s
[Step=67400 Epoch=642.4] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.027 | L2-Norm(final)=10.481 | 4278.1 samples/s | 66.8 steps/s
[Step=67450 Epoch=642.9] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=10.481 | 2367.7 samples/s | 37.0 steps/s
[Step=67500 Epoch=643.3] | Loss=0.00005 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.025 | L2-Norm(final)=10.482 | 4245.8 samples/s | 66.3 steps/s
[Step=67550 Epoch=643.8] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.024 | L2-Norm(final)=10.482 | 6977.4 samples/s | 109.0 steps/s
[Step=67600 Epoch=644.3] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.022 | L2-Norm(final)=10.483 | 1942.7 samples/s | 30.4 steps/s
[Step=67650 Epoch=644.8] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.021 | L2-Norm(final)=10.483 | 6353.9 samples/s | 99.3 steps/s
[Step=67700 Epoch=645.2] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.019 | L2-Norm(final)=10.483 | 2006.0 samples/s | 31.3 steps/s
[Step=67750 Epoch=645.7] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.018 | L2-Norm(final)=10.484 | 5832.4 samples/s | 91.1 steps/s
[Step=67800 Epoch=646.2] | Loss=0.00004 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.016 | L2-Norm(final)=10.484 | 2061.7 samples/s | 32.2 steps/s
[Step=67850 Epoch=646.7] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.015 | L2-Norm(final)=10.485 | 5330.8 samples/s | 83.3 steps/s
[Step=67900 Epoch=647.1] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=10.485 | 2121.2 samples/s | 33.1 steps/s
[Step=67950 Epoch=647.6] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.011 | L2-Norm(final)=10.485 | 4963.2 samples/s | 77.6 steps/s
[Step=68000 Epoch=648.1] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.486 | 2225.6 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10909 | acc=0.9570 | tpr=0.9669 | fpr=0.0647 | 4792.7 samples/s | 18.7 steps/s
Avg test loss: 0.11567, Avg test acc: 0.95524, Avg tpr: 0.96590, Avg fpr: 0.06820, total FA: 532

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11583 | acc=0.9581 | tpr=0.9762 | fpr=0.0810 | 4770.2 samples/s | 18.6 steps/s
Avg test loss: 0.11557, Avg test acc: 0.95793, Avg tpr: 0.97465, Avg fpr: 0.07884, total FA: 615

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10830 | acc=0.9578 | tpr=0.9709 | fpr=0.0706 | 4845.1 samples/s | 18.9 steps/s
Avg test loss: 0.11053, Avg test acc: 0.95637, Avg tpr: 0.96905, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10456 | acc=0.9602 | tpr=0.9727 | fpr=0.0669 | 4592.7 samples/s | 17.9 steps/s
Avg test loss: 0.11242, Avg test acc: 0.95877, Avg tpr: 0.97307, Avg fpr: 0.07268, total FA: 567

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11068 | acc=0.9556 | tpr=0.9700 | fpr=0.0756 | 4943.5 samples/s | 19.3 steps/s
Avg test loss: 0.11479, Avg test acc: 0.95609, Avg tpr: 0.97080, Avg fpr: 0.07627, total FA: 595

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.52200 | acc=0.2925 | tpr=0.0131 | fpr=0.1008 | 4674.4 samples/s | 18.3 steps/s
Avg test loss: 5.52714, Avg test acc: 0.29149, Avg tpr: 0.01399, Avg fpr: 0.09819, total FA: 766

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.99109 | acc=0.2970 | tpr=0.0055 | fpr=0.0699 | 4888.1 samples/s | 19.1 steps/s
Avg test loss: 5.00132, Avg test acc: 0.29413, Avg tpr: 0.00600, Avg fpr: 0.07217, total FA: 563

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.95735 | acc=0.2948 | tpr=0.0073 | fpr=0.0808 | 4636.8 samples/s | 18.1 steps/s
Avg test loss: 4.96306, Avg test acc: 0.29265, Avg tpr: 0.00874, Avg fpr: 0.08294, total FA: 647

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.80584 | acc=0.3000 | tpr=0.0124 | fpr=0.0756 | 4713.5 samples/s | 18.4 steps/s
Avg test loss: 5.79626, Avg test acc: 0.29882, Avg tpr: 0.01411, Avg fpr: 0.07499, total FA: 585

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.82456 | acc=0.3060 | tpr=0.0189 | fpr=0.0706 | 4682.0 samples/s | 18.3 steps/s
Avg test loss: 4.82545, Avg test acc: 0.30435, Avg tpr: 0.01918, Avg fpr: 0.06845, total FA: 534

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.73307 | acc=0.1129 | tpr=0.5841 | fpr=0.8956 | 4864.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.70481 | acc=0.1150 | tpr=0.5650 | fpr=0.8934 | 6814.0 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.71702 | acc=0.1147 | tpr=0.5634 | fpr=0.8936 | 8245.3 samples/s | 32.2 steps/s
[Step= 200] | Loss=5.71032 | acc=0.1143 | tpr=0.5574 | fpr=0.8938 | 7722.2 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.71232 | acc=0.1155 | tpr=0.5659 | fpr=0.8927 | 7746.3 samples/s | 30.3 steps/s
[Step= 300] | Loss=5.70771 | acc=0.1156 | tpr=0.5738 | fpr=0.8928 | 7685.2 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.70042 | acc=0.1158 | tpr=0.5736 | fpr=0.8925 | 8122.2 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.69603 | acc=0.1159 | tpr=0.5733 | fpr=0.8924 | 7415.7 samples/s | 29.0 steps/s
[Step= 450] | Loss=5.70075 | acc=0.1160 | tpr=0.5711 | fpr=0.8922 | 7994.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.70274 | acc=0.1159 | tpr=0.5670 | fpr=0.8923 | 8322.4 samples/s | 32.5 steps/s
[Step= 550] | Loss=5.70575 | acc=0.1157 | tpr=0.5631 | fpr=0.8925 | 13443.5 samples/s | 52.5 steps/s
Avg test loss: 5.70767, Avg test acc: 0.11557, Avg tpr: 0.56300, Avg fpr: 0.89256, total FA: 123930

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.79037 | acc=0.0916 | tpr=0.5265 | fpr=0.9162 | 4668.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.77446 | acc=0.0921 | tpr=0.5203 | fpr=0.9159 | 7436.5 samples/s | 29.0 steps/s
[Step= 150] | Loss=5.77742 | acc=0.0921 | tpr=0.5288 | fpr=0.9159 | 7828.9 samples/s | 30.6 steps/s
[Step= 200] | Loss=5.77028 | acc=0.0917 | tpr=0.5191 | fpr=0.9160 | 7742.0 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.77505 | acc=0.0918 | tpr=0.5266 | fpr=0.9161 | 7946.4 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.76856 | acc=0.0915 | tpr=0.5273 | fpr=0.9164 | 7962.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.76228 | acc=0.0916 | tpr=0.5254 | fpr=0.9163 | 7558.6 samples/s | 29.5 steps/s
[Step= 400] | Loss=5.75810 | acc=0.0920 | tpr=0.5263 | fpr=0.9159 | 7842.4 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.76301 | acc=0.0916 | tpr=0.5224 | fpr=0.9162 | 8373.5 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.76651 | acc=0.0914 | tpr=0.5194 | fpr=0.9163 | 7521.9 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.77100 | acc=0.0912 | tpr=0.5161 | fpr=0.9165 | 14237.9 samples/s | 55.6 steps/s
Avg test loss: 5.77319, Avg test acc: 0.09109, Avg tpr: 0.51506, Avg fpr: 0.91662, total FA: 127271

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.09104 | acc=0.0870 | tpr=0.3319 | fpr=0.9174 | 4877.0 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.05831 | acc=0.0888 | tpr=0.3412 | fpr=0.9159 | 6836.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.07101 | acc=0.0900 | tpr=0.3545 | fpr=0.9148 | 8049.5 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.06470 | acc=0.0903 | tpr=0.3508 | fpr=0.9144 | 7629.4 samples/s | 29.8 steps/s
[Step= 250] | Loss=6.06421 | acc=0.0910 | tpr=0.3598 | fpr=0.9138 | 7891.2 samples/s | 30.8 steps/s
[Step= 300] | Loss=6.06087 | acc=0.0913 | tpr=0.3702 | fpr=0.9137 | 7925.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=6.05425 | acc=0.0916 | tpr=0.3669 | fpr=0.9134 | 7545.6 samples/s | 29.5 steps/s
[Step= 400] | Loss=6.04965 | acc=0.0921 | tpr=0.3682 | fpr=0.9130 | 8391.8 samples/s | 32.8 steps/s
[Step= 450] | Loss=6.05442 | acc=0.0923 | tpr=0.3671 | fpr=0.9127 | 7702.9 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.05599 | acc=0.0920 | tpr=0.3652 | fpr=0.9129 | 7741.5 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.06008 | acc=0.0918 | tpr=0.3661 | fpr=0.9132 | 14151.6 samples/s | 55.3 steps/s
Avg test loss: 6.06140, Avg test acc: 0.09163, Avg tpr: 0.36648, Avg fpr: 0.91337, total FA: 126819

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.63861 | acc=0.1169 | tpr=0.5000 | fpr=0.8900 | 4967.5 samples/s | 19.4 steps/s
[Step= 100] | Loss=5.61842 | acc=0.1164 | tpr=0.4904 | fpr=0.8905 | 7040.6 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.62958 | acc=0.1152 | tpr=0.5043 | fpr=0.8920 | 7481.5 samples/s | 29.2 steps/s
[Step= 200] | Loss=5.62028 | acc=0.1144 | tpr=0.5027 | fpr=0.8927 | 8047.4 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.62283 | acc=0.1154 | tpr=0.5039 | fpr=0.8917 | 7781.6 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.62089 | acc=0.1153 | tpr=0.5105 | fpr=0.8919 | 7814.1 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.61210 | acc=0.1156 | tpr=0.5141 | fpr=0.8917 | 7758.7 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.60456 | acc=0.1160 | tpr=0.5126 | fpr=0.8912 | 8103.5 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.60959 | acc=0.1157 | tpr=0.5097 | fpr=0.8914 | 7818.9 samples/s | 30.5 steps/s
[Step= 500] | Loss=5.61079 | acc=0.1156 | tpr=0.5075 | fpr=0.8915 | 7670.1 samples/s | 30.0 steps/s
[Step= 550] | Loss=5.61521 | acc=0.1155 | tpr=0.5014 | fpr=0.8915 | 14500.0 samples/s | 56.6 steps/s
Avg test loss: 5.61633, Avg test acc: 0.11538, Avg tpr: 0.50119, Avg fpr: 0.89163, total FA: 123801

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.02761 | acc=0.1037 | tpr=0.5265 | fpr=0.9038 | 4754.6 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.00697 | acc=0.1058 | tpr=0.5224 | fpr=0.9020 | 7326.4 samples/s | 28.6 steps/s
[Step= 150] | Loss=6.00744 | acc=0.1058 | tpr=0.5245 | fpr=0.9019 | 7819.4 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.00475 | acc=0.1054 | tpr=0.5115 | fpr=0.9020 | 7879.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.00909 | acc=0.1059 | tpr=0.5170 | fpr=0.9016 | 7403.1 samples/s | 28.9 steps/s
[Step= 300] | Loss=6.01043 | acc=0.1059 | tpr=0.5207 | fpr=0.9016 | 8394.3 samples/s | 32.8 steps/s
[Step= 350] | Loss=6.00180 | acc=0.1060 | tpr=0.5178 | fpr=0.9014 | 7692.8 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.99818 | acc=0.1062 | tpr=0.5181 | fpr=0.9013 | 7863.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.00078 | acc=0.1064 | tpr=0.5166 | fpr=0.9011 | 8324.0 samples/s | 32.5 steps/s
[Step= 500] | Loss=6.00281 | acc=0.1063 | tpr=0.5123 | fpr=0.9010 | 7588.5 samples/s | 29.6 steps/s
[Step= 550] | Loss=6.00846 | acc=0.1061 | tpr=0.5125 | fpr=0.9013 | 13733.9 samples/s | 53.6 steps/s
Avg test loss: 6.01064, Avg test acc: 0.10598, Avg tpr: 0.51228, Avg fpr: 0.90141, total FA: 125159

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09577 | acc=0.9820 | tpr=0.9646 | fpr=0.0177 | 4651.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.09846 | acc=0.9815 | tpr=0.9638 | fpr=0.0181 | 7449.8 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.10186 | acc=0.9807 | tpr=0.9597 | fpr=0.0189 | 8268.4 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.10374 | acc=0.9806 | tpr=0.9639 | fpr=0.0191 | 7461.3 samples/s | 29.1 steps/s
[Step= 250] | Loss=0.10205 | acc=0.9809 | tpr=0.9590 | fpr=0.0187 | 8184.1 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.10453 | acc=0.9804 | tpr=0.9571 | fpr=0.0191 | 7946.6 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.10550 | acc=0.9802 | tpr=0.9574 | fpr=0.0194 | 7589.1 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.10647 | acc=0.9799 | tpr=0.9535 | fpr=0.0196 | 7899.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10847 | acc=0.9796 | tpr=0.9494 | fpr=0.0199 | 7767.6 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.10764 | acc=0.9797 | tpr=0.9502 | fpr=0.0198 | 8000.3 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.10705 | acc=0.9798 | tpr=0.9479 | fpr=0.0196 | 14164.7 samples/s | 55.3 steps/s
Avg test loss: 0.10689, Avg test acc: 0.97980, Avg tpr: 0.94810, Avg fpr: 0.01963, total FA: 2725

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08948 | acc=0.9829 | tpr=0.9336 | fpr=0.0162 | 4645.5 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.09235 | acc=0.9825 | tpr=0.9232 | fpr=0.0164 | 7520.2 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.09513 | acc=0.9821 | tpr=0.9265 | fpr=0.0168 | 7980.9 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.09708 | acc=0.9821 | tpr=0.9268 | fpr=0.0169 | 7657.6 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.09523 | acc=0.9824 | tpr=0.9249 | fpr=0.0166 | 7920.0 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.09768 | acc=0.9820 | tpr=0.9236 | fpr=0.0170 | 7758.3 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.09834 | acc=0.9818 | tpr=0.9280 | fpr=0.0172 | 7969.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.09969 | acc=0.9816 | tpr=0.9234 | fpr=0.0174 | 7406.4 samples/s | 28.9 steps/s
[Step= 450] | Loss=0.10201 | acc=0.9813 | tpr=0.9231 | fpr=0.0176 | 8127.9 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.10105 | acc=0.9814 | tpr=0.9251 | fpr=0.0176 | 8204.3 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.10093 | acc=0.9815 | tpr=0.9232 | fpr=0.0174 | 13606.3 samples/s | 53.1 steps/s
Avg test loss: 0.10082, Avg test acc: 0.98152, Avg tpr: 0.92314, Avg fpr: 0.01741, total FA: 2418

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.07996 | acc=0.9820 | tpr=0.9602 | fpr=0.0176 | 4704.2 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.08216 | acc=0.9819 | tpr=0.9659 | fpr=0.0178 | 7140.6 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.08601 | acc=0.9811 | tpr=0.9625 | fpr=0.0186 | 7828.4 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.08770 | acc=0.9813 | tpr=0.9672 | fpr=0.0185 | 7672.7 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.08622 | acc=0.9817 | tpr=0.9668 | fpr=0.0181 | 8087.9 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.08813 | acc=0.9814 | tpr=0.9629 | fpr=0.0183 | 8229.8 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.08883 | acc=0.9811 | tpr=0.9637 | fpr=0.0186 | 7801.0 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.08984 | acc=0.9808 | tpr=0.9606 | fpr=0.0188 | 7433.6 samples/s | 29.0 steps/s
[Step= 450] | Loss=0.09134 | acc=0.9805 | tpr=0.9586 | fpr=0.0191 | 8354.5 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.09076 | acc=0.9805 | tpr=0.9604 | fpr=0.0191 | 7742.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.09041 | acc=0.9806 | tpr=0.9586 | fpr=0.0190 | 14055.3 samples/s | 54.9 steps/s
Avg test loss: 0.09028, Avg test acc: 0.98064, Avg tpr: 0.95880, Avg fpr: 0.01896, total FA: 2633

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09150 | acc=0.9812 | tpr=0.9425 | fpr=0.0181 | 5017.3 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.09460 | acc=0.9810 | tpr=0.9446 | fpr=0.0183 | 6627.0 samples/s | 25.9 steps/s
[Step= 150] | Loss=0.09857 | acc=0.9801 | tpr=0.9424 | fpr=0.0193 | 7801.4 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.09999 | acc=0.9802 | tpr=0.9497 | fpr=0.0192 | 7716.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.09841 | acc=0.9806 | tpr=0.9467 | fpr=0.0188 | 7960.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10024 | acc=0.9805 | tpr=0.9440 | fpr=0.0188 | 7779.6 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.10104 | acc=0.9804 | tpr=0.9455 | fpr=0.0189 | 7857.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10160 | acc=0.9804 | tpr=0.9426 | fpr=0.0189 | 8093.2 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.10356 | acc=0.9801 | tpr=0.9391 | fpr=0.0192 | 7891.1 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10276 | acc=0.9802 | tpr=0.9414 | fpr=0.0191 | 7853.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10239 | acc=0.9803 | tpr=0.9407 | fpr=0.0190 | 13801.4 samples/s | 53.9 steps/s
Avg test loss: 0.10220, Avg test acc: 0.98031, Avg tpr: 0.94097, Avg fpr: 0.01897, total FA: 2634

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08778 | acc=0.9824 | tpr=0.9248 | fpr=0.0165 | 4802.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09265 | acc=0.9814 | tpr=0.9318 | fpr=0.0176 | 7085.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.09553 | acc=0.9808 | tpr=0.9308 | fpr=0.0183 | 7931.2 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.09740 | acc=0.9807 | tpr=0.9366 | fpr=0.0185 | 7711.2 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.09600 | acc=0.9810 | tpr=0.9354 | fpr=0.0182 | 8029.2 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.09826 | acc=0.9807 | tpr=0.9324 | fpr=0.0184 | 7560.0 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.09888 | acc=0.9805 | tpr=0.9343 | fpr=0.0186 | 8049.9 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.10022 | acc=0.9803 | tpr=0.9327 | fpr=0.0188 | 7917.2 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10220 | acc=0.9801 | tpr=0.9309 | fpr=0.0190 | 7723.4 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.10167 | acc=0.9802 | tpr=0.9313 | fpr=0.0190 | 7696.2 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.10128 | acc=0.9803 | tpr=0.9308 | fpr=0.0188 | 14957.1 samples/s | 58.4 steps/s
Avg test loss: 0.10119, Avg test acc: 0.98031, Avg tpr: 0.93067, Avg fpr: 0.01878, total FA: 2608

server round 34/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=331.6] | Loss=0.00765 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.344 | L2-Norm(final)=17.718 | 5487.8 samples/s | 85.7 steps/s
[Step=68050 Epoch=331.8] | Loss=0.00344 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=17.724 | 4432.9 samples/s | 69.3 steps/s
[Step=68100 Epoch=332.1] | Loss=0.00294 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.347 | L2-Norm(final)=17.731 | 5072.4 samples/s | 79.3 steps/s
[Step=68150 Epoch=332.3] | Loss=0.00318 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=17.739 | 5068.0 samples/s | 79.2 steps/s
[Step=68200 Epoch=332.6] | Loss=0.00303 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=17.747 | 7669.5 samples/s | 119.8 steps/s
[Step=68250 Epoch=332.8] | Loss=0.00286 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=17.755 | 2183.5 samples/s | 34.1 steps/s
[Step=68300 Epoch=333.0] | Loss=0.00284 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=17.763 | 5012.0 samples/s | 78.3 steps/s
[Step=68350 Epoch=333.3] | Loss=0.00292 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.355 | L2-Norm(final)=17.771 | 5090.0 samples/s | 79.5 steps/s
[Step=68400 Epoch=333.5] | Loss=0.00287 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=17.778 | 6950.5 samples/s | 108.6 steps/s
[Step=68450 Epoch=333.8] | Loss=0.00283 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=17.786 | 2310.5 samples/s | 36.1 steps/s
[Step=68500 Epoch=334.0] | Loss=0.00279 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.358 | L2-Norm(final)=17.794 | 5137.8 samples/s | 80.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=334.0] | Loss=0.00198 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=17.871 | 5466.1 samples/s | 85.4 steps/s
[Step=68550 Epoch=334.3] | Loss=0.00227 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=17.879 | 4127.8 samples/s | 64.5 steps/s
[Step=68600 Epoch=334.5] | Loss=0.00339 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=17.887 | 4485.3 samples/s | 70.1 steps/s
[Step=68650 Epoch=334.8] | Loss=0.00361 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=17.894 | 4494.6 samples/s | 70.2 steps/s
[Step=68700 Epoch=335.0] | Loss=0.00391 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.385 | L2-Norm(final)=17.900 | 6575.8 samples/s | 102.7 steps/s
[Step=68750 Epoch=335.2] | Loss=0.00388 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=17.906 | 2101.5 samples/s | 32.8 steps/s
[Step=68800 Epoch=335.5] | Loss=0.00384 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=17.911 | 4546.1 samples/s | 71.0 steps/s
[Step=68850 Epoch=335.7] | Loss=0.00375 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.393 | L2-Norm(final)=17.917 | 4487.9 samples/s | 70.1 steps/s
[Step=68900 Epoch=336.0] | Loss=0.00365 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=17.922 | 5766.9 samples/s | 90.1 steps/s
[Step=68950 Epoch=336.2] | Loss=0.00364 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=17.927 | 2129.5 samples/s | 33.3 steps/s
[Step=69000 Epoch=336.5] | Loss=0.00351 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.397 | L2-Norm(final)=17.932 | 4433.7 samples/s | 69.3 steps/s
[Step=69050 Epoch=336.7] | Loss=0.00342 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=17.936 | 4510.3 samples/s | 70.5 steps/s
[Step=69100 Epoch=336.9] | Loss=0.00336 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=17.941 | 5413.3 samples/s | 84.6 steps/s
[Step=69150 Epoch=337.2] | Loss=0.00334 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=17.945 | 2280.4 samples/s | 35.6 steps/s
[Step=69200 Epoch=337.4] | Loss=0.00327 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=17.948 | 4486.6 samples/s | 70.1 steps/s
[Step=69250 Epoch=337.7] | Loss=0.00324 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=17.952 | 4364.4 samples/s | 68.2 steps/s
[Step=69300 Epoch=337.9] | Loss=0.00323 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=17.956 | 4921.9 samples/s | 76.9 steps/s
[Step=69350 Epoch=338.2] | Loss=0.00313 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=17.959 | 2326.6 samples/s | 36.4 steps/s
[Step=69400 Epoch=338.4] | Loss=0.00303 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=17.963 | 4478.5 samples/s | 70.0 steps/s
[Step=69450 Epoch=338.7] | Loss=0.00296 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.399 | L2-Norm(final)=17.966 | 4476.9 samples/s | 70.0 steps/s
[Step=69500 Epoch=338.9] | Loss=0.00297 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.398 | L2-Norm(final)=17.970 | 4584.7 samples/s | 71.6 steps/s
[Step=69550 Epoch=339.1] | Loss=0.00297 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.397 | L2-Norm(final)=17.973 | 2437.8 samples/s | 38.1 steps/s
[Step=69600 Epoch=339.4] | Loss=0.00288 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.397 | L2-Norm(final)=17.976 | 4377.3 samples/s | 68.4 steps/s
[Step=69650 Epoch=339.6] | Loss=0.00285 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=17.979 | 4497.8 samples/s | 70.3 steps/s
[Step=69700 Epoch=339.9] | Loss=0.00285 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=17.982 | 4507.9 samples/s | 70.4 steps/s
[Step=69750 Epoch=340.1] | Loss=0.00280 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=17.985 | 2477.8 samples/s | 38.7 steps/s
[Step=69800 Epoch=340.4] | Loss=0.00278 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.393 | L2-Norm(final)=17.989 | 4499.2 samples/s | 70.3 steps/s
[Step=69850 Epoch=340.6] | Loss=0.00276 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=17.992 | 4477.1 samples/s | 70.0 steps/s
[Step=69900 Epoch=340.8] | Loss=0.00274 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=17.994 | 4473.7 samples/s | 69.9 steps/s
[Step=69950 Epoch=341.1] | Loss=0.00273 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=17.997 | 2437.6 samples/s | 38.1 steps/s
[Step=70000 Epoch=341.3] | Loss=0.00271 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=18.000 | 4471.2 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step70000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=331.8] | Loss=0.00278 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=18.381 | 5216.4 samples/s | 81.5 steps/s
[Step=68050 Epoch=332.1] | Loss=0.00231 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.957 | L2-Norm(final)=18.388 | 4395.3 samples/s | 68.7 steps/s
[Step=68100 Epoch=332.3] | Loss=0.00246 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=18.398 | 5075.8 samples/s | 79.3 steps/s
[Step=68150 Epoch=332.5] | Loss=0.00243 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=18.408 | 4999.0 samples/s | 78.1 steps/s
[Step=68200 Epoch=332.8] | Loss=0.00262 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=18.417 | 7864.4 samples/s | 122.9 steps/s
[Step=68250 Epoch=333.0] | Loss=0.00260 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.964 | L2-Norm(final)=18.426 | 2194.8 samples/s | 34.3 steps/s
[Step=68300 Epoch=333.3] | Loss=0.00249 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.966 | L2-Norm(final)=18.436 | 4929.9 samples/s | 77.0 steps/s
[Step=68350 Epoch=333.5] | Loss=0.00247 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=18.445 | 5052.7 samples/s | 78.9 steps/s
[Step=68400 Epoch=333.8] | Loss=0.00252 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=18.454 | 7161.6 samples/s | 111.9 steps/s
[Step=68450 Epoch=334.0] | Loss=0.00253 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.970 | L2-Norm(final)=18.462 | 2282.7 samples/s | 35.7 steps/s
[Step=68500 Epoch=334.2] | Loss=0.00247 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=18.471 | 4994.8 samples/s | 78.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=334.3] | Loss=0.00038 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=18.558 | 5091.6 samples/s | 79.6 steps/s
[Step=68550 Epoch=334.5] | Loss=0.00360 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=18.566 | 4206.6 samples/s | 65.7 steps/s
[Step=68600 Epoch=334.7] | Loss=0.00386 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=18.576 | 4471.0 samples/s | 69.9 steps/s
[Step=68650 Epoch=335.0] | Loss=0.00402 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=18.584 | 4376.7 samples/s | 68.4 steps/s
[Step=68700 Epoch=335.2] | Loss=0.00392 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=18.593 | 6637.3 samples/s | 103.7 steps/s
[Step=68750 Epoch=335.5] | Loss=0.00362 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=18.602 | 2108.9 samples/s | 33.0 steps/s
[Step=68800 Epoch=335.7] | Loss=0.00407 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=18.609 | 4460.8 samples/s | 69.7 steps/s
[Step=68850 Epoch=336.0] | Loss=0.00409 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=18.615 | 4463.0 samples/s | 69.7 steps/s
[Step=68900 Epoch=336.2] | Loss=0.00395 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=18.621 | 5867.8 samples/s | 91.7 steps/s
[Step=68950 Epoch=336.4] | Loss=0.00376 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.021 | L2-Norm(final)=18.626 | 2135.8 samples/s | 33.4 steps/s
[Step=69000 Epoch=336.7] | Loss=0.00359 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=18.631 | 4440.2 samples/s | 69.4 steps/s
[Step=69050 Epoch=336.9] | Loss=0.00341 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=18.636 | 4465.6 samples/s | 69.8 steps/s
[Step=69100 Epoch=337.2] | Loss=0.00334 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.025 | L2-Norm(final)=18.641 | 5552.9 samples/s | 86.8 steps/s
[Step=69150 Epoch=337.4] | Loss=0.00323 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=18.646 | 2223.2 samples/s | 34.7 steps/s
[Step=69200 Epoch=337.7] | Loss=0.00316 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=18.650 | 4457.4 samples/s | 69.6 steps/s
[Step=69250 Epoch=337.9] | Loss=0.00307 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=18.654 | 4500.7 samples/s | 70.3 steps/s
[Step=69300 Epoch=338.2] | Loss=0.00298 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=18.658 | 5161.3 samples/s | 80.6 steps/s
[Step=69350 Epoch=338.4] | Loss=0.00292 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=18.662 | 2259.9 samples/s | 35.3 steps/s
[Step=69400 Epoch=338.6] | Loss=0.00286 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.026 | L2-Norm(final)=18.666 | 4571.2 samples/s | 71.4 steps/s
[Step=69450 Epoch=338.9] | Loss=0.00279 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=18.670 | 4364.6 samples/s | 68.2 steps/s
[Step=69500 Epoch=339.1] | Loss=0.00274 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=18.674 | 4831.4 samples/s | 75.5 steps/s
[Step=69550 Epoch=339.4] | Loss=0.00271 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=18.677 | 2350.6 samples/s | 36.7 steps/s
[Step=69600 Epoch=339.6] | Loss=0.00268 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=18.681 | 4482.0 samples/s | 70.0 steps/s
[Step=69650 Epoch=339.9] | Loss=0.00264 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.022 | L2-Norm(final)=18.684 | 4580.1 samples/s | 71.6 steps/s
[Step=69700 Epoch=340.1] | Loss=0.00262 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=18.688 | 4416.1 samples/s | 69.0 steps/s
[Step=69750 Epoch=340.3] | Loss=0.00255 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=18.691 | 2428.0 samples/s | 37.9 steps/s
[Step=69800 Epoch=340.6] | Loss=0.00249 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=18.694 | 4490.2 samples/s | 70.2 steps/s
[Step=69850 Epoch=340.8] | Loss=0.00248 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=18.698 | 4489.3 samples/s | 70.1 steps/s
[Step=69900 Epoch=341.1] | Loss=0.00246 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.015 | L2-Norm(final)=18.701 | 4568.1 samples/s | 71.4 steps/s
[Step=69950 Epoch=341.3] | Loss=0.00242 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=18.704 | 2451.7 samples/s | 38.3 steps/s
[Step=70000 Epoch=341.6] | Loss=0.00239 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.012 | L2-Norm(final)=18.707 | 4327.7 samples/s | 67.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step70000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=331.3] | Loss=0.00163 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=18.581 | 5383.7 samples/s | 84.1 steps/s
[Step=68050 Epoch=331.6] | Loss=0.00274 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.714 | L2-Norm(final)=18.586 | 4562.2 samples/s | 71.3 steps/s
[Step=68100 Epoch=331.8] | Loss=0.00279 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.716 | L2-Norm(final)=18.594 | 4922.3 samples/s | 76.9 steps/s
[Step=68150 Epoch=332.1] | Loss=0.00279 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=18.603 | 5041.5 samples/s | 78.8 steps/s
[Step=68200 Epoch=332.3] | Loss=0.00291 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=18.612 | 7849.3 samples/s | 122.6 steps/s
[Step=68250 Epoch=332.5] | Loss=0.00277 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.722 | L2-Norm(final)=18.620 | 2221.5 samples/s | 34.7 steps/s
[Step=68300 Epoch=332.8] | Loss=0.00288 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=18.629 | 5149.2 samples/s | 80.5 steps/s
[Step=68350 Epoch=333.0] | Loss=0.00285 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=18.637 | 4964.4 samples/s | 77.6 steps/s
[Step=68400 Epoch=333.3] | Loss=0.00278 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.726 | L2-Norm(final)=18.645 | 6756.3 samples/s | 105.6 steps/s
[Step=68450 Epoch=333.5] | Loss=0.00275 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=18.653 | 2305.9 samples/s | 36.0 steps/s
[Step=68500 Epoch=333.8] | Loss=0.00264 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.728 | L2-Norm(final)=18.661 | 5134.8 samples/s | 80.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=333.8] | Loss=0.00057 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=18.740 | 5327.2 samples/s | 83.2 steps/s
[Step=68550 Epoch=334.0] | Loss=0.00338 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.739 | L2-Norm(final)=18.748 | 4063.9 samples/s | 63.5 steps/s
[Step=68600 Epoch=334.3] | Loss=0.00360 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=18.755 | 4536.5 samples/s | 70.9 steps/s
[Step=68650 Epoch=334.5] | Loss=0.00375 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.747 | L2-Norm(final)=18.763 | 4434.3 samples/s | 69.3 steps/s
[Step=68700 Epoch=334.7] | Loss=0.00403 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.752 | L2-Norm(final)=18.770 | 6566.3 samples/s | 102.6 steps/s
[Step=68750 Epoch=335.0] | Loss=0.00419 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.756 | L2-Norm(final)=18.777 | 2100.1 samples/s | 32.8 steps/s
[Step=68800 Epoch=335.2] | Loss=0.00398 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.759 | L2-Norm(final)=18.784 | 4478.3 samples/s | 70.0 steps/s
[Step=68850 Epoch=335.5] | Loss=0.00382 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=18.789 | 4479.6 samples/s | 70.0 steps/s
[Step=68900 Epoch=335.7] | Loss=0.00365 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=18.795 | 5915.3 samples/s | 92.4 steps/s
[Step=68950 Epoch=336.0] | Loss=0.00362 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=18.800 | 2178.3 samples/s | 34.0 steps/s
[Step=69000 Epoch=336.2] | Loss=0.00352 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=18.805 | 4490.3 samples/s | 70.2 steps/s
[Step=69050 Epoch=336.4] | Loss=0.00355 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.767 | L2-Norm(final)=18.810 | 4422.8 samples/s | 69.1 steps/s
[Step=69100 Epoch=336.7] | Loss=0.00344 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=18.814 | 5302.0 samples/s | 82.8 steps/s
[Step=69150 Epoch=336.9] | Loss=0.00339 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=18.819 | 2246.9 samples/s | 35.1 steps/s
[Step=69200 Epoch=337.2] | Loss=0.00334 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.823 | 4520.9 samples/s | 70.6 steps/s
[Step=69250 Epoch=337.4] | Loss=0.00329 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.827 | 4455.5 samples/s | 69.6 steps/s
[Step=69300 Epoch=337.7] | Loss=0.00321 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.832 | 4978.3 samples/s | 77.8 steps/s
[Step=69350 Epoch=337.9] | Loss=0.00318 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.836 | 2389.1 samples/s | 37.3 steps/s
[Step=69400 Epoch=338.1] | Loss=0.00315 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.840 | 4319.6 samples/s | 67.5 steps/s
[Step=69450 Epoch=338.4] | Loss=0.00308 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=18.844 | 4433.7 samples/s | 69.3 steps/s
[Step=69500 Epoch=338.6] | Loss=0.00300 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=18.848 | 4622.1 samples/s | 72.2 steps/s
[Step=69550 Epoch=338.9] | Loss=0.00294 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=18.851 | 2426.6 samples/s | 37.9 steps/s
[Step=69600 Epoch=339.1] | Loss=0.00293 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.767 | L2-Norm(final)=18.855 | 4476.1 samples/s | 69.9 steps/s
[Step=69650 Epoch=339.4] | Loss=0.00293 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=18.859 | 4512.9 samples/s | 70.5 steps/s
[Step=69700 Epoch=339.6] | Loss=0.00286 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=18.862 | 4485.8 samples/s | 70.1 steps/s
[Step=69750 Epoch=339.9] | Loss=0.00281 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=18.866 | 2449.9 samples/s | 38.3 steps/s
[Step=69800 Epoch=340.1] | Loss=0.00276 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=18.869 | 4445.5 samples/s | 69.5 steps/s
[Step=69850 Epoch=340.3] | Loss=0.00274 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.762 | L2-Norm(final)=18.873 | 4529.3 samples/s | 70.8 steps/s
[Step=69900 Epoch=340.6] | Loss=0.00273 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=18.876 | 4379.2 samples/s | 68.4 steps/s
[Step=69950 Epoch=340.8] | Loss=0.00275 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.760 | L2-Norm(final)=18.879 | 2462.7 samples/s | 38.5 steps/s
[Step=70000 Epoch=341.1] | Loss=0.00273 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=18.883 | 4462.6 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step70000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=331.6] | Loss=0.00153 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=18.573 | 5210.8 samples/s | 81.4 steps/s
[Step=68050 Epoch=331.9] | Loss=0.00273 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=18.581 | 4579.2 samples/s | 71.6 steps/s
[Step=68100 Epoch=332.1] | Loss=0.00247 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=18.589 | 4989.3 samples/s | 78.0 steps/s
[Step=68150 Epoch=332.3] | Loss=0.00252 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=18.597 | 5024.2 samples/s | 78.5 steps/s
[Step=68200 Epoch=332.6] | Loss=0.00249 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=18.606 | 7715.3 samples/s | 120.6 steps/s
[Step=68250 Epoch=332.8] | Loss=0.00240 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.407 | L2-Norm(final)=18.614 | 2220.8 samples/s | 34.7 steps/s
[Step=68300 Epoch=333.1] | Loss=0.00225 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.408 | L2-Norm(final)=18.623 | 5004.9 samples/s | 78.2 steps/s
[Step=68350 Epoch=333.3] | Loss=0.00233 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.409 | L2-Norm(final)=18.631 | 5130.4 samples/s | 80.2 steps/s
[Step=68400 Epoch=333.6] | Loss=0.00231 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.410 | L2-Norm(final)=18.639 | 6809.6 samples/s | 106.4 steps/s
[Step=68450 Epoch=333.8] | Loss=0.00234 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=18.647 | 2271.5 samples/s | 35.5 steps/s
[Step=68500 Epoch=334.0] | Loss=0.00234 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.412 | L2-Norm(final)=18.655 | 4985.2 samples/s | 77.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=334.0] | Loss=0.00608 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.420 | L2-Norm(final)=18.738 | 5715.8 samples/s | 89.3 steps/s
[Step=68550 Epoch=334.3] | Loss=0.00258 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=18.746 | 3847.1 samples/s | 60.1 steps/s
[Step=68600 Epoch=334.5] | Loss=0.00303 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=18.755 | 4489.0 samples/s | 70.1 steps/s
[Step=68650 Epoch=334.8] | Loss=0.00365 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.434 | L2-Norm(final)=18.763 | 4479.1 samples/s | 70.0 steps/s
[Step=68700 Epoch=335.0] | Loss=0.00374 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=18.771 | 6572.7 samples/s | 102.7 steps/s
[Step=68750 Epoch=335.3] | Loss=0.00347 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.444 | L2-Norm(final)=18.777 | 2096.1 samples/s | 32.8 steps/s
[Step=68800 Epoch=335.5] | Loss=0.00363 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.448 | L2-Norm(final)=18.784 | 4435.7 samples/s | 69.3 steps/s
[Step=68850 Epoch=335.8] | Loss=0.00353 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.450 | L2-Norm(final)=18.789 | 4437.3 samples/s | 69.3 steps/s
[Step=68900 Epoch=336.0] | Loss=0.00349 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=18.795 | 5947.0 samples/s | 92.9 steps/s
[Step=68950 Epoch=336.2] | Loss=0.00346 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.455 | L2-Norm(final)=18.800 | 2170.7 samples/s | 33.9 steps/s
[Step=69000 Epoch=336.5] | Loss=0.00337 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.457 | L2-Norm(final)=18.805 | 4537.8 samples/s | 70.9 steps/s
[Step=69050 Epoch=336.7] | Loss=0.00322 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.458 | L2-Norm(final)=18.810 | 4388.3 samples/s | 68.6 steps/s
[Step=69100 Epoch=337.0] | Loss=0.00324 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.460 | L2-Norm(final)=18.815 | 5424.6 samples/s | 84.8 steps/s
[Step=69150 Epoch=337.2] | Loss=0.00318 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=18.819 | 2219.1 samples/s | 34.7 steps/s
[Step=69200 Epoch=337.5] | Loss=0.00311 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=18.824 | 4487.4 samples/s | 70.1 steps/s
[Step=69250 Epoch=337.7] | Loss=0.00303 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=18.828 | 4504.6 samples/s | 70.4 steps/s
[Step=69300 Epoch=337.9] | Loss=0.00296 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=18.832 | 4958.0 samples/s | 77.5 steps/s
[Step=69350 Epoch=338.2] | Loss=0.00286 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=18.836 | 2375.8 samples/s | 37.1 steps/s
[Step=69400 Epoch=338.4] | Loss=0.00282 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=18.839 | 4429.4 samples/s | 69.2 steps/s
[Step=69450 Epoch=338.7] | Loss=0.00277 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=18.843 | 4540.8 samples/s | 70.9 steps/s
[Step=69500 Epoch=338.9] | Loss=0.00272 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=18.847 | 4474.5 samples/s | 69.9 steps/s
[Step=69550 Epoch=339.2] | Loss=0.00268 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=18.850 | 2387.3 samples/s | 37.3 steps/s
[Step=69600 Epoch=339.4] | Loss=0.00266 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=18.853 | 4482.3 samples/s | 70.0 steps/s
[Step=69650 Epoch=339.7] | Loss=0.00261 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=18.857 | 4449.8 samples/s | 69.5 steps/s
[Step=69700 Epoch=339.9] | Loss=0.00255 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=18.860 | 4481.2 samples/s | 70.0 steps/s
[Step=69750 Epoch=340.1] | Loss=0.00252 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.460 | L2-Norm(final)=18.863 | 2498.8 samples/s | 39.0 steps/s
[Step=69800 Epoch=340.4] | Loss=0.00245 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.459 | L2-Norm(final)=18.866 | 4496.1 samples/s | 70.3 steps/s
[Step=69850 Epoch=340.6] | Loss=0.00243 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.458 | L2-Norm(final)=18.869 | 4313.0 samples/s | 67.4 steps/s
[Step=69900 Epoch=340.9] | Loss=0.00246 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.457 | L2-Norm(final)=18.872 | 4441.6 samples/s | 69.4 steps/s
[Step=69950 Epoch=341.1] | Loss=0.00243 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=18.875 | 2459.1 samples/s | 38.4 steps/s
[Step=70000 Epoch=341.4] | Loss=0.00239 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.455 | L2-Norm(final)=18.878 | 4483.9 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step70000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=333.5] | Loss=0.00056 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.110 | L2-Norm(final)=18.616 | 5432.1 samples/s | 84.9 steps/s
[Step=68050 Epoch=333.7] | Loss=0.00277 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.113 | L2-Norm(final)=18.623 | 4434.3 samples/s | 69.3 steps/s
[Step=68100 Epoch=334.0] | Loss=0.00251 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=18.631 | 5221.2 samples/s | 81.6 steps/s
[Step=68150 Epoch=334.2] | Loss=0.00249 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=18.640 | 4849.2 samples/s | 75.8 steps/s
[Step=68200 Epoch=334.4] | Loss=0.00253 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=18.649 | 7968.5 samples/s | 124.5 steps/s
[Step=68250 Epoch=334.7] | Loss=0.00244 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=18.658 | 2183.0 samples/s | 34.1 steps/s
[Step=68300 Epoch=334.9] | Loss=0.00242 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=18.667 | 4971.4 samples/s | 77.7 steps/s
[Step=68350 Epoch=335.2] | Loss=0.00238 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.122 | L2-Norm(final)=18.675 | 5041.1 samples/s | 78.8 steps/s
[Step=68400 Epoch=335.4] | Loss=0.00237 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=18.684 | 7312.4 samples/s | 114.3 steps/s
[Step=68450 Epoch=335.7] | Loss=0.00236 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=18.692 | 2239.1 samples/s | 35.0 steps/s
[Step=68500 Epoch=335.9] | Loss=0.00234 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=18.701 | 4948.7 samples/s | 77.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=335.9] | Loss=0.00075 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=18.785 | 5688.0 samples/s | 88.9 steps/s
[Step=68550 Epoch=336.2] | Loss=0.00292 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=18.793 | 3868.1 samples/s | 60.4 steps/s
[Step=68600 Epoch=336.4] | Loss=0.00259 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=18.801 | 4458.8 samples/s | 69.7 steps/s
[Step=68650 Epoch=336.6] | Loss=0.00373 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.142 | L2-Norm(final)=18.808 | 4487.8 samples/s | 70.1 steps/s
[Step=68700 Epoch=336.9] | Loss=0.00421 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=18.815 | 6752.8 samples/s | 105.5 steps/s
[Step=68750 Epoch=337.1] | Loss=0.00405 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.153 | L2-Norm(final)=18.822 | 2085.3 samples/s | 32.6 steps/s
[Step=68800 Epoch=337.4] | Loss=0.00380 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=18.828 | 4399.5 samples/s | 68.7 steps/s
[Step=68850 Epoch=337.6] | Loss=0.00376 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=18.834 | 4585.9 samples/s | 71.7 steps/s
[Step=68900 Epoch=337.9] | Loss=0.00377 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=18.840 | 5947.0 samples/s | 92.9 steps/s
[Step=68950 Epoch=338.1] | Loss=0.00349 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=18.846 | 2110.7 samples/s | 33.0 steps/s
[Step=69000 Epoch=338.4] | Loss=0.00341 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=18.851 | 4382.0 samples/s | 68.5 steps/s
[Step=69050 Epoch=338.6] | Loss=0.00329 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=18.856 | 4477.0 samples/s | 70.0 steps/s
[Step=69100 Epoch=338.9] | Loss=0.00321 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=18.861 | 5852.5 samples/s | 91.4 steps/s
[Step=69150 Epoch=339.1] | Loss=0.00307 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=18.865 | 2178.2 samples/s | 34.0 steps/s
[Step=69200 Epoch=339.3] | Loss=0.00306 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.869 | 4436.5 samples/s | 69.3 steps/s
[Step=69250 Epoch=339.6] | Loss=0.00294 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.873 | 4425.4 samples/s | 69.1 steps/s
[Step=69300 Epoch=339.8] | Loss=0.00288 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.174 | L2-Norm(final)=18.877 | 5453.6 samples/s | 85.2 steps/s
[Step=69350 Epoch=340.1] | Loss=0.00281 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.881 | 2229.5 samples/s | 34.8 steps/s
[Step=69400 Epoch=340.3] | Loss=0.00273 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.885 | 4418.6 samples/s | 69.0 steps/s
[Step=69450 Epoch=340.6] | Loss=0.00271 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.888 | 4436.4 samples/s | 69.3 steps/s
[Step=69500 Epoch=340.8] | Loss=0.00264 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.892 | 5241.4 samples/s | 81.9 steps/s
[Step=69550 Epoch=341.1] | Loss=0.00259 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=18.895 | 2259.1 samples/s | 35.3 steps/s
[Step=69600 Epoch=341.3] | Loss=0.00254 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=18.899 | 4367.0 samples/s | 68.2 steps/s
[Step=69650 Epoch=341.6] | Loss=0.00249 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=18.902 | 4500.3 samples/s | 70.3 steps/s
[Step=69700 Epoch=341.8] | Loss=0.00246 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=18.906 | 4946.8 samples/s | 77.3 steps/s
[Step=69750 Epoch=342.0] | Loss=0.00245 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.171 | L2-Norm(final)=18.909 | 2314.7 samples/s | 36.2 steps/s
[Step=69800 Epoch=342.3] | Loss=0.00240 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=18.912 | 4474.1 samples/s | 69.9 steps/s
[Step=69850 Epoch=342.5] | Loss=0.00239 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.169 | L2-Norm(final)=18.915 | 4488.4 samples/s | 70.1 steps/s
[Step=69900 Epoch=342.8] | Loss=0.00235 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=18.918 | 4678.8 samples/s | 73.1 steps/s
[Step=69950 Epoch=343.0] | Loss=0.00230 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=18.921 | 2367.0 samples/s | 37.0 steps/s
[Step=70000 Epoch=343.3] | Loss=0.00227 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=18.925 | 4489.1 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step70000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=644.4] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.799 | L2-Norm(final)=9.219 | 5583.0 samples/s | 87.2 steps/s
[Step=68050 Epoch=644.8] | Loss=0.00005 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.802 | L2-Norm(final)=9.225 | 3965.0 samples/s | 62.0 steps/s
[Step=68100 Epoch=645.3] | Loss=0.00004 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.807 | L2-Norm(final)=9.233 | 7276.0 samples/s | 113.7 steps/s
[Step=68150 Epoch=645.8] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.810 | L2-Norm(final)=9.240 | 2121.7 samples/s | 33.2 steps/s
[Step=68200 Epoch=646.3] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.812 | L2-Norm(final)=9.246 | 6656.4 samples/s | 104.0 steps/s
[Step=68250 Epoch=646.7] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.814 | L2-Norm(final)=9.252 | 2201.3 samples/s | 34.4 steps/s
[Step=68300 Epoch=647.2] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.816 | L2-Norm(final)=9.259 | 5914.5 samples/s | 92.4 steps/s
[Step=68350 Epoch=647.7] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.818 | L2-Norm(final)=9.264 | 2306.2 samples/s | 36.0 steps/s
[Step=68400 Epoch=648.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.820 | L2-Norm(final)=9.270 | 5316.2 samples/s | 83.1 steps/s
[Step=68450 Epoch=648.6] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.822 | L2-Norm(final)=9.276 | 2403.6 samples/s | 37.6 steps/s
[Step=68500 Epoch=649.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.823 | L2-Norm(final)=9.281 | 4910.8 samples/s | 76.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=649.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.837 | L2-Norm(final)=9.335 | 5054.5 samples/s | 79.0 steps/s
[Step=68550 Epoch=649.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=9.339 | 3879.0 samples/s | 60.6 steps/s
[Step=68600 Epoch=650.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=9.342 | 6261.9 samples/s | 97.8 steps/s
[Step=68650 Epoch=650.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.824 | L2-Norm(final)=9.345 | 1999.8 samples/s | 31.2 steps/s
[Step=68700 Epoch=651.0] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.818 | L2-Norm(final)=9.347 | 5692.5 samples/s | 88.9 steps/s
[Step=68750 Epoch=651.5] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.811 | L2-Norm(final)=9.349 | 2106.2 samples/s | 32.9 steps/s
[Step=68800 Epoch=651.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.804 | L2-Norm(final)=9.351 | 5145.5 samples/s | 80.4 steps/s
[Step=68850 Epoch=652.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.796 | L2-Norm(final)=9.352 | 2124.0 samples/s | 33.2 steps/s
[Step=68900 Epoch=652.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.789 | L2-Norm(final)=9.354 | 4744.5 samples/s | 74.1 steps/s
[Step=68950 Epoch=653.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.781 | L2-Norm(final)=9.355 | 2264.4 samples/s | 35.4 steps/s
[Step=69000 Epoch=653.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.773 | L2-Norm(final)=9.356 | 4247.7 samples/s | 66.4 steps/s
[Step=69050 Epoch=654.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.765 | L2-Norm(final)=9.357 | 2326.0 samples/s | 36.3 steps/s
[Step=69100 Epoch=654.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.757 | L2-Norm(final)=9.359 | 4135.7 samples/s | 64.6 steps/s
[Step=69150 Epoch=655.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.749 | L2-Norm(final)=9.360 | 2415.7 samples/s | 37.7 steps/s
[Step=69200 Epoch=655.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.740 | L2-Norm(final)=9.361 | 4108.3 samples/s | 64.2 steps/s
[Step=69250 Epoch=656.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.732 | L2-Norm(final)=9.362 | 2412.5 samples/s | 37.7 steps/s
[Step=69300 Epoch=656.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.723 | L2-Norm(final)=9.363 | 4134.2 samples/s | 64.6 steps/s
[Step=69350 Epoch=657.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.714 | L2-Norm(final)=9.364 | 2370.0 samples/s | 37.0 steps/s
[Step=69400 Epoch=657.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.706 | L2-Norm(final)=9.366 | 4108.5 samples/s | 64.2 steps/s
[Step=69450 Epoch=658.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.697 | L2-Norm(final)=9.367 | 6387.9 samples/s | 99.8 steps/s
[Step=69500 Epoch=658.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.688 | L2-Norm(final)=9.368 | 2007.4 samples/s | 31.4 steps/s
[Step=69550 Epoch=659.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.679 | L2-Norm(final)=9.369 | 5742.2 samples/s | 89.7 steps/s
[Step=69600 Epoch=659.5] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.670 | L2-Norm(final)=9.370 | 2084.7 samples/s | 32.6 steps/s
[Step=69650 Epoch=660.0] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.660 | L2-Norm(final)=9.371 | 5255.4 samples/s | 82.1 steps/s
[Step=69700 Epoch=660.5] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.651 | L2-Norm(final)=9.373 | 2114.7 samples/s | 33.0 steps/s
[Step=69750 Epoch=660.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.641 | L2-Norm(final)=9.374 | 4884.4 samples/s | 76.3 steps/s
[Step=69800 Epoch=661.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.632 | L2-Norm(final)=9.375 | 2210.7 samples/s | 34.5 steps/s
[Step=69850 Epoch=661.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.622 | L2-Norm(final)=9.376 | 4478.2 samples/s | 70.0 steps/s
[Step=69900 Epoch=662.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.613 | L2-Norm(final)=9.378 | 2333.8 samples/s | 36.5 steps/s
[Step=69950 Epoch=662.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.603 | L2-Norm(final)=9.379 | 4249.0 samples/s | 66.4 steps/s
[Step=70000 Epoch=663.3] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.593 | L2-Norm(final)=9.380 | 2347.5 samples/s | 36.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step70000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=646.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.823 | L2-Norm(final)=10.199 | 5593.4 samples/s | 87.4 steps/s
[Step=68050 Epoch=647.3] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.825 | L2-Norm(final)=10.202 | 3987.0 samples/s | 62.3 steps/s
[Step=68100 Epoch=647.8] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.828 | L2-Norm(final)=10.205 | 7500.7 samples/s | 117.2 steps/s
[Step=68150 Epoch=648.3] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.829 | L2-Norm(final)=10.208 | 2125.3 samples/s | 33.2 steps/s
[Step=68200 Epoch=648.8] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.831 | L2-Norm(final)=10.211 | 6532.7 samples/s | 102.1 steps/s
[Step=68250 Epoch=649.2] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.832 | L2-Norm(final)=10.214 | 2201.3 samples/s | 34.4 steps/s
[Step=68300 Epoch=649.7] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.833 | L2-Norm(final)=10.217 | 5879.4 samples/s | 91.9 steps/s
[Step=68350 Epoch=650.2] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=10.220 | 2322.1 samples/s | 36.3 steps/s
[Step=68400 Epoch=650.7] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.835 | L2-Norm(final)=10.223 | 5331.0 samples/s | 83.3 steps/s
[Step=68450 Epoch=651.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.835 | L2-Norm(final)=10.226 | 2414.5 samples/s | 37.7 steps/s
[Step=68500 Epoch=651.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.836 | L2-Norm(final)=10.229 | 4887.3 samples/s | 76.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=651.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.844 | L2-Norm(final)=10.258 | 5603.9 samples/s | 87.6 steps/s
[Step=68550 Epoch=652.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.842 | L2-Norm(final)=10.260 | 3645.3 samples/s | 57.0 steps/s
[Step=68600 Epoch=652.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.840 | L2-Norm(final)=10.262 | 6179.6 samples/s | 96.6 steps/s
[Step=68650 Epoch=653.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.837 | L2-Norm(final)=10.265 | 2011.5 samples/s | 31.4 steps/s
[Step=68700 Epoch=653.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=10.266 | 5697.5 samples/s | 89.0 steps/s
[Step=68750 Epoch=654.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.831 | L2-Norm(final)=10.268 | 2095.0 samples/s | 32.7 steps/s
[Step=68800 Epoch=654.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.827 | L2-Norm(final)=10.269 | 5132.8 samples/s | 80.2 steps/s
[Step=68850 Epoch=654.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.823 | L2-Norm(final)=10.270 | 2166.9 samples/s | 33.9 steps/s
[Step=68900 Epoch=655.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.819 | L2-Norm(final)=10.272 | 4763.9 samples/s | 74.4 steps/s
[Step=68950 Epoch=655.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.815 | L2-Norm(final)=10.273 | 2259.7 samples/s | 35.3 steps/s
[Step=69000 Epoch=656.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.811 | L2-Norm(final)=10.274 | 4423.1 samples/s | 69.1 steps/s
[Step=69050 Epoch=656.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.807 | L2-Norm(final)=10.275 | 2367.4 samples/s | 37.0 steps/s
[Step=69100 Epoch=657.3] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.802 | L2-Norm(final)=10.276 | 4272.2 samples/s | 66.8 steps/s
[Step=69150 Epoch=657.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.798 | L2-Norm(final)=10.277 | 2380.1 samples/s | 37.2 steps/s
[Step=69200 Epoch=658.3] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.793 | L2-Norm(final)=10.278 | 4183.3 samples/s | 65.4 steps/s
[Step=69250 Epoch=658.7] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.789 | L2-Norm(final)=10.279 | 2399.6 samples/s | 37.5 steps/s
[Step=69300 Epoch=659.2] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.784 | L2-Norm(final)=10.280 | 4320.6 samples/s | 67.5 steps/s
[Step=69350 Epoch=659.7] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.779 | L2-Norm(final)=10.280 | 2587.7 samples/s | 40.4 steps/s
[Step=69400 Epoch=660.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.774 | L2-Norm(final)=10.281 | 3879.0 samples/s | 60.6 steps/s
[Step=69450 Epoch=660.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.769 | L2-Norm(final)=10.282 | 6443.9 samples/s | 100.7 steps/s
[Step=69500 Epoch=661.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.764 | L2-Norm(final)=10.283 | 1953.7 samples/s | 30.5 steps/s
[Step=69550 Epoch=661.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.759 | L2-Norm(final)=10.284 | 5846.6 samples/s | 91.4 steps/s
[Step=69600 Epoch=662.1] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.754 | L2-Norm(final)=10.285 | 2094.4 samples/s | 32.7 steps/s
[Step=69650 Epoch=662.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.749 | L2-Norm(final)=10.286 | 5263.6 samples/s | 82.2 steps/s
[Step=69700 Epoch=663.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.743 | L2-Norm(final)=10.287 | 2181.9 samples/s | 34.1 steps/s
[Step=69750 Epoch=663.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.738 | L2-Norm(final)=10.288 | 4782.7 samples/s | 74.7 steps/s
[Step=69800 Epoch=664.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.733 | L2-Norm(final)=10.288 | 2222.9 samples/s | 34.7 steps/s
[Step=69850 Epoch=664.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.727 | L2-Norm(final)=10.289 | 4522.0 samples/s | 70.7 steps/s
[Step=69900 Epoch=664.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.722 | L2-Norm(final)=10.290 | 2330.4 samples/s | 36.4 steps/s
[Step=69950 Epoch=665.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.716 | L2-Norm(final)=10.291 | 4253.9 samples/s | 66.5 steps/s
[Step=70000 Epoch=665.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.710 | L2-Norm(final)=10.292 | 2386.8 samples/s | 37.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step70000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=649.4] | Loss=0.00008 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.679 | L2-Norm(final)=10.052 | 5252.6 samples/s | 82.1 steps/s
[Step=68050 Epoch=649.8] | Loss=0.00010 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.689 | L2-Norm(final)=10.078 | 4114.5 samples/s | 64.3 steps/s
[Step=68100 Epoch=650.3] | Loss=0.00007 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.700 | L2-Norm(final)=10.100 | 7467.0 samples/s | 116.7 steps/s
[Step=68150 Epoch=650.8] | Loss=0.00006 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.707 | L2-Norm(final)=10.117 | 2120.4 samples/s | 33.1 steps/s
[Step=68200 Epoch=651.3] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.712 | L2-Norm(final)=10.131 | 6850.8 samples/s | 107.0 steps/s
[Step=68250 Epoch=651.7] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.717 | L2-Norm(final)=10.143 | 2183.3 samples/s | 34.1 steps/s
[Step=68300 Epoch=652.2] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=10.153 | 6163.3 samples/s | 96.3 steps/s
[Step=68350 Epoch=652.7] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.723 | L2-Norm(final)=10.163 | 2214.3 samples/s | 34.6 steps/s
[Step=68400 Epoch=653.2] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.725 | L2-Norm(final)=10.172 | 5649.2 samples/s | 88.3 steps/s
[Step=68450 Epoch=653.7] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.727 | L2-Norm(final)=10.180 | 2347.1 samples/s | 36.7 steps/s
[Step=68500 Epoch=654.1] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.729 | L2-Norm(final)=10.188 | 5193.0 samples/s | 81.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=654.1] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.747 | L2-Norm(final)=10.265 | 5365.0 samples/s | 83.8 steps/s
[Step=68550 Epoch=654.6] | Loss=0.00002 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.726 | L2-Norm(final)=10.271 | 3853.1 samples/s | 60.2 steps/s
[Step=68600 Epoch=655.1] | Loss=0.00093 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.730 | L2-Norm(final)=10.280 | 6349.3 samples/s | 99.2 steps/s
[Step=68650 Epoch=655.6] | Loss=0.00068 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.743 | L2-Norm(final)=10.285 | 1975.0 samples/s | 30.9 steps/s
[Step=68700 Epoch=656.0] | Loss=0.00052 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.751 | L2-Norm(final)=10.289 | 5831.2 samples/s | 91.1 steps/s
[Step=68750 Epoch=656.5] | Loss=0.00042 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.755 | L2-Norm(final)=10.291 | 2102.5 samples/s | 32.9 steps/s
[Step=68800 Epoch=657.0] | Loss=0.00035 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.758 | L2-Norm(final)=10.293 | 5204.6 samples/s | 81.3 steps/s
[Step=68850 Epoch=657.5] | Loss=0.00030 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.760 | L2-Norm(final)=10.294 | 2125.7 samples/s | 33.2 steps/s
[Step=68900 Epoch=658.0] | Loss=0.00026 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.761 | L2-Norm(final)=10.295 | 4888.4 samples/s | 76.4 steps/s
[Step=68950 Epoch=658.4] | Loss=0.00024 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.762 | L2-Norm(final)=10.296 | 2221.5 samples/s | 34.7 steps/s
[Step=69000 Epoch=658.9] | Loss=0.00021 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.297 | 4502.4 samples/s | 70.3 steps/s
[Step=69050 Epoch=659.4] | Loss=0.00019 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.297 | 2282.3 samples/s | 35.7 steps/s
[Step=69100 Epoch=659.9] | Loss=0.00018 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.298 | 4377.2 samples/s | 68.4 steps/s
[Step=69150 Epoch=660.3] | Loss=0.00016 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.298 | 2369.6 samples/s | 37.0 steps/s
[Step=69200 Epoch=660.8] | Loss=0.00015 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.299 | 4163.5 samples/s | 65.1 steps/s
[Step=69250 Epoch=661.3] | Loss=0.00014 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.299 | 2412.6 samples/s | 37.7 steps/s
[Step=69300 Epoch=661.8] | Loss=0.00013 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.762 | L2-Norm(final)=10.300 | 4185.9 samples/s | 65.4 steps/s
[Step=69350 Epoch=662.3] | Loss=0.00013 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.762 | L2-Norm(final)=10.300 | 2387.8 samples/s | 37.3 steps/s
[Step=69400 Epoch=662.7] | Loss=0.00012 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.761 | L2-Norm(final)=10.300 | 4284.9 samples/s | 67.0 steps/s
[Step=69450 Epoch=663.2] | Loss=0.00011 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.760 | L2-Norm(final)=10.300 | 2382.0 samples/s | 37.2 steps/s
[Step=69500 Epoch=663.7] | Loss=0.00011 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.760 | L2-Norm(final)=10.301 | 4202.5 samples/s | 65.7 steps/s
[Step=69550 Epoch=664.2] | Loss=0.00010 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.759 | L2-Norm(final)=10.301 | 7018.5 samples/s | 109.7 steps/s
[Step=69600 Epoch=664.6] | Loss=0.00010 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.758 | L2-Norm(final)=10.301 | 1977.2 samples/s | 30.9 steps/s
[Step=69650 Epoch=665.1] | Loss=0.00009 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.757 | L2-Norm(final)=10.301 | 6310.1 samples/s | 98.6 steps/s
[Step=69700 Epoch=665.6] | Loss=0.00009 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.757 | L2-Norm(final)=10.302 | 2046.3 samples/s | 32.0 steps/s
[Step=69750 Epoch=666.1] | Loss=0.00009 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.756 | L2-Norm(final)=10.302 | 5608.1 samples/s | 87.6 steps/s
[Step=69800 Epoch=666.5] | Loss=0.00008 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.755 | L2-Norm(final)=10.302 | 2047.2 samples/s | 32.0 steps/s
[Step=69850 Epoch=667.0] | Loss=0.00008 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.754 | L2-Norm(final)=10.302 | 5366.3 samples/s | 83.8 steps/s
[Step=69900 Epoch=667.5] | Loss=0.00008 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.753 | L2-Norm(final)=10.302 | 2136.4 samples/s | 33.4 steps/s
[Step=69950 Epoch=668.0] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.752 | L2-Norm(final)=10.303 | 4969.0 samples/s | 77.6 steps/s
[Step=70000 Epoch=668.5] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.751 | L2-Norm(final)=10.303 | 2243.8 samples/s | 35.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step70000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=640.8] | Loss=0.00020 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=9.964 | 5063.1 samples/s | 79.1 steps/s
[Step=68050 Epoch=641.2] | Loss=0.00006 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=9.966 | 4146.3 samples/s | 64.8 steps/s
[Step=68100 Epoch=641.7] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.932 | L2-Norm(final)=9.969 | 7141.8 samples/s | 111.6 steps/s
[Step=68150 Epoch=642.2] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=9.971 | 2165.5 samples/s | 33.8 steps/s
[Step=68200 Epoch=642.6] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.934 | L2-Norm(final)=9.973 | 6389.8 samples/s | 99.8 steps/s
[Step=68250 Epoch=643.1] | Loss=0.00004 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=9.976 | 2253.2 samples/s | 35.2 steps/s
[Step=68300 Epoch=643.6] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.936 | L2-Norm(final)=9.978 | 5478.5 samples/s | 85.6 steps/s
[Step=68350 Epoch=644.1] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.980 | 2356.7 samples/s | 36.8 steps/s
[Step=68400 Epoch=644.5] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.937 | L2-Norm(final)=9.982 | 5044.8 samples/s | 78.8 steps/s
[Step=68450 Epoch=645.0] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=9.985 | 2502.1 samples/s | 39.1 steps/s
[Step=68500 Epoch=645.5] | Loss=0.00003 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=9.987 | 4761.4 samples/s | 74.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=645.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=10.009 | 4926.6 samples/s | 77.0 steps/s
[Step=68550 Epoch=645.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.943 | L2-Norm(final)=10.011 | 2534.5 samples/s | 39.6 steps/s
[Step=68600 Epoch=646.4] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.942 | L2-Norm(final)=10.013 | 6156.2 samples/s | 96.2 steps/s
[Step=68650 Epoch=646.9] | Loss=0.00002 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.941 | L2-Norm(final)=10.015 | 1983.0 samples/s | 31.0 steps/s
[Step=68700 Epoch=647.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.939 | L2-Norm(final)=10.017 | 5498.0 samples/s | 85.9 steps/s
[Step=68750 Epoch=647.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=10.018 | 2133.0 samples/s | 33.3 steps/s
[Step=68800 Epoch=648.3] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.935 | L2-Norm(final)=10.019 | 4936.8 samples/s | 77.1 steps/s
[Step=68850 Epoch=648.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.933 | L2-Norm(final)=10.020 | 2212.0 samples/s | 34.6 steps/s
[Step=68900 Epoch=649.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.931 | L2-Norm(final)=10.021 | 4391.6 samples/s | 68.6 steps/s
[Step=68950 Epoch=649.7] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.928 | L2-Norm(final)=10.022 | 2316.6 samples/s | 36.2 steps/s
[Step=69000 Epoch=650.2] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.926 | L2-Norm(final)=10.023 | 4362.2 samples/s | 68.2 steps/s
[Step=69050 Epoch=650.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.923 | L2-Norm(final)=10.023 | 2371.7 samples/s | 37.1 steps/s
[Step=69100 Epoch=651.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.920 | L2-Norm(final)=10.024 | 4285.0 samples/s | 67.0 steps/s
[Step=69150 Epoch=651.6] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.918 | L2-Norm(final)=10.025 | 2415.5 samples/s | 37.7 steps/s
[Step=69200 Epoch=652.1] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.915 | L2-Norm(final)=10.026 | 4141.5 samples/s | 64.7 steps/s
[Step=69250 Epoch=652.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.912 | L2-Norm(final)=10.026 | 2646.1 samples/s | 41.3 steps/s
[Step=69300 Epoch=653.0] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=10.027 | 3617.8 samples/s | 56.5 steps/s
[Step=69350 Epoch=653.5] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.906 | L2-Norm(final)=10.028 | 6343.7 samples/s | 99.1 steps/s
[Step=69400 Epoch=653.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.903 | L2-Norm(final)=10.029 | 2040.4 samples/s | 31.9 steps/s
[Step=69450 Epoch=654.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.900 | L2-Norm(final)=10.029 | 5456.2 samples/s | 85.3 steps/s
[Step=69500 Epoch=654.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.897 | L2-Norm(final)=10.030 | 2093.5 samples/s | 32.7 steps/s
[Step=69550 Epoch=655.4] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.893 | L2-Norm(final)=10.031 | 5045.8 samples/s | 78.8 steps/s
[Step=69600 Epoch=655.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.890 | L2-Norm(final)=10.031 | 2211.9 samples/s | 34.6 steps/s
[Step=69650 Epoch=656.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=10.032 | 4504.7 samples/s | 70.4 steps/s
[Step=69700 Epoch=656.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=10.033 | 2301.3 samples/s | 36.0 steps/s
[Step=69750 Epoch=657.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.880 | L2-Norm(final)=10.034 | 4353.3 samples/s | 68.0 steps/s
[Step=69800 Epoch=657.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.876 | L2-Norm(final)=10.034 | 2347.2 samples/s | 36.7 steps/s
[Step=69850 Epoch=658.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.872 | L2-Norm(final)=10.035 | 4221.3 samples/s | 66.0 steps/s
[Step=69900 Epoch=658.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.869 | L2-Norm(final)=10.036 | 2399.7 samples/s | 37.5 steps/s
[Step=69950 Epoch=659.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.865 | L2-Norm(final)=10.036 | 4277.5 samples/s | 66.8 steps/s
[Step=70000 Epoch=659.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.037 | 2530.8 samples/s | 39.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step70000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=648.1] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.886 | L2-Norm(final)=10.497 | 5196.4 samples/s | 81.2 steps/s
[Step=68050 Epoch=648.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.886 | L2-Norm(final)=10.498 | 4055.7 samples/s | 63.4 steps/s
[Step=68100 Epoch=649.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.886 | L2-Norm(final)=10.500 | 7584.9 samples/s | 118.5 steps/s
[Step=68150 Epoch=649.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=10.502 | 2139.1 samples/s | 33.4 steps/s
[Step=68200 Epoch=650.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=10.504 | 6823.7 samples/s | 106.6 steps/s
[Step=68250 Epoch=650.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=10.507 | 2184.1 samples/s | 34.1 steps/s
[Step=68300 Epoch=651.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.888 | L2-Norm(final)=10.509 | 6245.1 samples/s | 97.6 steps/s
[Step=68350 Epoch=651.4] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.888 | L2-Norm(final)=10.511 | 2228.2 samples/s | 34.8 steps/s
[Step=68400 Epoch=651.9] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.889 | L2-Norm(final)=10.513 | 5670.9 samples/s | 88.6 steps/s
[Step=68450 Epoch=652.4] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.889 | L2-Norm(final)=10.515 | 2340.6 samples/s | 36.6 steps/s
[Step=68500 Epoch=652.9] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.889 | L2-Norm(final)=10.517 | 5250.4 samples/s | 82.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=652.9] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.892 | L2-Norm(final)=10.539 | 4931.3 samples/s | 77.1 steps/s
[Step=68550 Epoch=653.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.891 | L2-Norm(final)=10.541 | 3979.7 samples/s | 62.2 steps/s
[Step=68600 Epoch=653.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.889 | L2-Norm(final)=10.543 | 6355.7 samples/s | 99.3 steps/s
[Step=68650 Epoch=654.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.887 | L2-Norm(final)=10.545 | 2001.7 samples/s | 31.3 steps/s
[Step=68700 Epoch=654.8] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.885 | L2-Norm(final)=10.546 | 5728.1 samples/s | 89.5 steps/s
[Step=68750 Epoch=655.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=10.547 | 2064.5 samples/s | 32.3 steps/s
[Step=68800 Epoch=655.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.880 | L2-Norm(final)=10.549 | 5382.7 samples/s | 84.1 steps/s
[Step=68850 Epoch=656.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=10.550 | 2156.3 samples/s | 33.7 steps/s
[Step=68900 Epoch=656.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.874 | L2-Norm(final)=10.551 | 4893.1 samples/s | 76.5 steps/s
[Step=68950 Epoch=657.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.871 | L2-Norm(final)=10.552 | 2188.2 samples/s | 34.2 steps/s
[Step=69000 Epoch=657.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=10.553 | 4602.8 samples/s | 71.9 steps/s
[Step=69050 Epoch=658.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.865 | L2-Norm(final)=10.553 | 2279.2 samples/s | 35.6 steps/s
[Step=69100 Epoch=658.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.862 | L2-Norm(final)=10.554 | 4342.7 samples/s | 67.9 steps/s
[Step=69150 Epoch=659.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=10.555 | 2337.4 samples/s | 36.5 steps/s
[Step=69200 Epoch=659.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.556 | 4198.6 samples/s | 65.6 steps/s
[Step=69250 Epoch=660.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.852 | L2-Norm(final)=10.557 | 2295.8 samples/s | 35.9 steps/s
[Step=69300 Epoch=660.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.848 | L2-Norm(final)=10.557 | 4232.2 samples/s | 66.1 steps/s
[Step=69350 Epoch=661.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.845 | L2-Norm(final)=10.558 | 2397.6 samples/s | 37.5 steps/s
[Step=69400 Epoch=661.4] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=10.559 | 4285.4 samples/s | 67.0 steps/s
[Step=69450 Epoch=661.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.837 | L2-Norm(final)=10.560 | 2405.0 samples/s | 37.6 steps/s
[Step=69500 Epoch=662.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=10.560 | 4152.6 samples/s | 64.9 steps/s
[Step=69550 Epoch=662.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=10.561 | 6987.9 samples/s | 109.2 steps/s
[Step=69600 Epoch=663.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.826 | L2-Norm(final)=10.562 | 1953.5 samples/s | 30.5 steps/s
[Step=69650 Epoch=663.8] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.822 | L2-Norm(final)=10.562 | 6338.1 samples/s | 99.0 steps/s
[Step=69700 Epoch=664.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.818 | L2-Norm(final)=10.563 | 1996.8 samples/s | 31.2 steps/s
[Step=69750 Epoch=664.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.814 | L2-Norm(final)=10.564 | 5864.8 samples/s | 91.6 steps/s
[Step=69800 Epoch=665.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.810 | L2-Norm(final)=10.565 | 2040.9 samples/s | 31.9 steps/s
[Step=69850 Epoch=665.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=10.565 | 5406.9 samples/s | 84.5 steps/s
[Step=69900 Epoch=666.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.802 | L2-Norm(final)=10.566 | 2119.2 samples/s | 33.1 steps/s
[Step=69950 Epoch=666.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=10.567 | 4968.5 samples/s | 77.6 steps/s
[Step=70000 Epoch=667.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.793 | L2-Norm(final)=10.568 | 2191.4 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10371 | acc=0.9578 | tpr=0.9706 | fpr=0.0699 | 4634.5 samples/s | 18.1 steps/s
Avg test loss: 0.10881, Avg test acc: 0.95585, Avg tpr: 0.96917, Avg fpr: 0.07345, total FA: 573

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11919 | acc=0.9571 | tpr=0.9763 | fpr=0.0845 | 5051.1 samples/s | 19.7 steps/s
Avg test loss: 0.11854, Avg test acc: 0.95709, Avg tpr: 0.97599, Avg fpr: 0.08448, total FA: 659

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10685 | acc=0.9576 | tpr=0.9751 | fpr=0.0805 | 4777.1 samples/s | 18.7 steps/s
Avg test loss: 0.10828, Avg test acc: 0.95657, Avg tpr: 0.97325, Avg fpr: 0.08012, total FA: 625

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10338 | acc=0.9586 | tpr=0.9707 | fpr=0.0676 | 4846.9 samples/s | 18.9 steps/s
Avg test loss: 0.10835, Avg test acc: 0.95753, Avg tpr: 0.97080, Avg fpr: 0.07166, total FA: 559

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11335 | acc=0.9581 | tpr=0.9690 | fpr=0.0654 | 5008.0 samples/s | 19.6 steps/s
Avg test loss: 0.11936, Avg test acc: 0.95717, Avg tpr: 0.96876, Avg fpr: 0.06832, total FA: 533

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.32682 | acc=0.2976 | tpr=0.0110 | fpr=0.0800 | 4900.5 samples/s | 19.1 steps/s
Avg test loss: 5.33293, Avg test acc: 0.29578, Avg tpr: 0.01142, Avg fpr: 0.07884, total FA: 615

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.92202 | acc=0.2984 | tpr=0.0047 | fpr=0.0639 | 4712.4 samples/s | 18.4 steps/s
Avg test loss: 4.93357, Avg test acc: 0.29558, Avg tpr: 0.00513, Avg fpr: 0.06563, total FA: 512

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=6.10973 | acc=0.2967 | tpr=0.0068 | fpr=0.0738 | 4906.0 samples/s | 19.2 steps/s
Avg test loss: 6.11942, Avg test acc: 0.29409, Avg tpr: 0.00676, Avg fpr: 0.07396, total FA: 577

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.58641 | acc=0.2966 | tpr=0.0162 | fpr=0.0946 | 4975.0 samples/s | 19.4 steps/s
Avg test loss: 5.58064, Avg test acc: 0.29538, Avg tpr: 0.01754, Avg fpr: 0.09358, total FA: 730

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.91738 | acc=0.3034 | tpr=0.0177 | fpr=0.0763 | 4883.6 samples/s | 19.1 steps/s
Avg test loss: 4.92019, Avg test acc: 0.30215, Avg tpr: 0.01900, Avg fpr: 0.07512, total FA: 586

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.78709 | acc=0.1002 | tpr=0.5487 | fpr=0.9078 | 4850.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.75218 | acc=0.1031 | tpr=0.5437 | fpr=0.9051 | 7060.4 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.76348 | acc=0.1039 | tpr=0.5461 | fpr=0.9042 | 7678.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.75885 | acc=0.1034 | tpr=0.5410 | fpr=0.9045 | 8226.4 samples/s | 32.1 steps/s
[Step= 250] | Loss=5.76127 | acc=0.1043 | tpr=0.5476 | fpr=0.9037 | 7608.3 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.75664 | acc=0.1045 | tpr=0.5593 | fpr=0.9037 | 7923.4 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.74926 | acc=0.1047 | tpr=0.5548 | fpr=0.9034 | 7990.8 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.74572 | acc=0.1050 | tpr=0.5498 | fpr=0.9031 | 7915.7 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.74921 | acc=0.1053 | tpr=0.5458 | fpr=0.9027 | 7776.5 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.75086 | acc=0.1050 | tpr=0.5401 | fpr=0.9029 | 7912.9 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.75412 | acc=0.1045 | tpr=0.5356 | fpr=0.9034 | 14036.1 samples/s | 54.8 steps/s
Avg test loss: 5.75601, Avg test acc: 0.10437, Avg tpr: 0.53566, Avg fpr: 0.90347, total FA: 125445

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.13191 | acc=0.0852 | tpr=0.5487 | fpr=0.9232 | 4946.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.11002 | acc=0.0862 | tpr=0.5416 | fpr=0.9223 | 6472.6 samples/s | 25.3 steps/s
[Step= 150] | Loss=6.11270 | acc=0.0869 | tpr=0.5548 | fpr=0.9217 | 8277.6 samples/s | 32.3 steps/s
[Step= 200] | Loss=6.10450 | acc=0.0862 | tpr=0.5486 | fpr=0.9223 | 8036.0 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.10966 | acc=0.0866 | tpr=0.5581 | fpr=0.9220 | 7784.8 samples/s | 30.4 steps/s
[Step= 300] | Loss=6.10390 | acc=0.0864 | tpr=0.5593 | fpr=0.9222 | 7856.4 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.09831 | acc=0.0865 | tpr=0.5560 | fpr=0.9220 | 8061.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.09308 | acc=0.0868 | tpr=0.5574 | fpr=0.9217 | 7896.9 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.09779 | acc=0.0867 | tpr=0.5565 | fpr=0.9219 | 7705.5 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.10150 | acc=0.0864 | tpr=0.5537 | fpr=0.9220 | 8280.7 samples/s | 32.3 steps/s
[Step= 550] | Loss=6.10634 | acc=0.0861 | tpr=0.5507 | fpr=0.9223 | 13204.7 samples/s | 51.6 steps/s
Avg test loss: 6.10881, Avg test acc: 0.08606, Avg tpr: 0.54952, Avg fpr: 0.92236, total FA: 128068

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.07467 | acc=0.0805 | tpr=0.3319 | fpr=0.9240 | 4670.0 samples/s | 18.2 steps/s
[Step= 100] | Loss=6.03714 | acc=0.0821 | tpr=0.3497 | fpr=0.9229 | 7555.0 samples/s | 29.5 steps/s
[Step= 150] | Loss=6.05305 | acc=0.0825 | tpr=0.3602 | fpr=0.9226 | 7852.5 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.04622 | acc=0.0823 | tpr=0.3563 | fpr=0.9227 | 7740.6 samples/s | 30.2 steps/s
[Step= 250] | Loss=6.04551 | acc=0.0830 | tpr=0.3668 | fpr=0.9222 | 7963.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.04139 | acc=0.0831 | tpr=0.3731 | fpr=0.9222 | 7743.7 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.03505 | acc=0.0835 | tpr=0.3707 | fpr=0.9217 | 7746.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.03139 | acc=0.0840 | tpr=0.3704 | fpr=0.9212 | 8048.8 samples/s | 31.4 steps/s
[Step= 450] | Loss=6.03546 | acc=0.0840 | tpr=0.3656 | fpr=0.9211 | 8146.4 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.03741 | acc=0.0838 | tpr=0.3656 | fpr=0.9213 | 7646.5 samples/s | 29.9 steps/s
[Step= 550] | Loss=6.04094 | acc=0.0836 | tpr=0.3669 | fpr=0.9216 | 14552.2 samples/s | 56.8 steps/s
Avg test loss: 6.04199, Avg test acc: 0.08346, Avg tpr: 0.36727, Avg fpr: 0.92170, total FA: 127976

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.43848 | acc=0.1179 | tpr=0.4956 | fpr=0.8889 | 4921.8 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.41777 | acc=0.1175 | tpr=0.4968 | fpr=0.8895 | 6954.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.43045 | acc=0.1165 | tpr=0.5058 | fpr=0.8907 | 7868.4 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.42046 | acc=0.1154 | tpr=0.5060 | fpr=0.8917 | 7675.1 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.42304 | acc=0.1163 | tpr=0.5135 | fpr=0.8909 | 8099.2 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.42178 | acc=0.1163 | tpr=0.5215 | fpr=0.8911 | 7803.5 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.41374 | acc=0.1165 | tpr=0.5241 | fpr=0.8909 | 7373.9 samples/s | 28.8 steps/s
[Step= 400] | Loss=5.40951 | acc=0.1167 | tpr=0.5197 | fpr=0.8907 | 8159.6 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.41485 | acc=0.1167 | tpr=0.5175 | fpr=0.8906 | 7881.0 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.41682 | acc=0.1164 | tpr=0.5132 | fpr=0.8907 | 8050.4 samples/s | 31.4 steps/s
[Step= 550] | Loss=5.42157 | acc=0.1162 | tpr=0.5090 | fpr=0.8909 | 13647.5 samples/s | 53.3 steps/s
Avg test loss: 5.42263, Avg test acc: 0.11609, Avg tpr: 0.50872, Avg fpr: 0.89105, total FA: 123720

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.15491 | acc=0.1159 | tpr=0.4513 | fpr=0.8902 | 5012.5 samples/s | 19.6 steps/s
[Step= 100] | Loss=6.13088 | acc=0.1178 | tpr=0.4456 | fpr=0.8883 | 6474.2 samples/s | 25.3 steps/s
[Step= 150] | Loss=6.13155 | acc=0.1181 | tpr=0.4496 | fpr=0.8880 | 8201.0 samples/s | 32.0 steps/s
[Step= 200] | Loss=6.12709 | acc=0.1174 | tpr=0.4306 | fpr=0.8883 | 7522.1 samples/s | 29.4 steps/s
[Step= 250] | Loss=6.13206 | acc=0.1180 | tpr=0.4384 | fpr=0.8878 | 8054.3 samples/s | 31.5 steps/s
[Step= 300] | Loss=6.13218 | acc=0.1179 | tpr=0.4451 | fpr=0.8881 | 8079.6 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.12203 | acc=0.1181 | tpr=0.4458 | fpr=0.8878 | 7859.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=6.11906 | acc=0.1183 | tpr=0.4437 | fpr=0.8877 | 8185.1 samples/s | 32.0 steps/s
[Step= 450] | Loss=6.12297 | acc=0.1188 | tpr=0.4440 | fpr=0.8871 | 7835.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.12563 | acc=0.1186 | tpr=0.4427 | fpr=0.8872 | 7690.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.13058 | acc=0.1181 | tpr=0.4449 | fpr=0.8878 | 14038.5 samples/s | 54.8 steps/s
Avg test loss: 6.13262, Avg test acc: 0.11804, Avg tpr: 0.44414, Avg fpr: 0.88788, total FA: 123281

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09272 | acc=0.9820 | tpr=0.9646 | fpr=0.0177 | 4788.1 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09506 | acc=0.9815 | tpr=0.9659 | fpr=0.0182 | 7170.4 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.09859 | acc=0.9805 | tpr=0.9611 | fpr=0.0191 | 7762.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.10041 | acc=0.9806 | tpr=0.9672 | fpr=0.0192 | 8005.3 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.09884 | acc=0.9809 | tpr=0.9624 | fpr=0.0187 | 7890.8 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.10125 | acc=0.9806 | tpr=0.9607 | fpr=0.0191 | 7967.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.10220 | acc=0.9803 | tpr=0.9599 | fpr=0.0193 | 7830.6 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.10322 | acc=0.9800 | tpr=0.9557 | fpr=0.0195 | 7903.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.10520 | acc=0.9796 | tpr=0.9513 | fpr=0.0199 | 7774.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.10440 | acc=0.9797 | tpr=0.9515 | fpr=0.0198 | 7918.1 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.10380 | acc=0.9799 | tpr=0.9495 | fpr=0.0196 | 14017.1 samples/s | 54.8 steps/s
Avg test loss: 0.10367, Avg test acc: 0.97987, Avg tpr: 0.94968, Avg fpr: 0.01958, total FA: 2719

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08637 | acc=0.9829 | tpr=0.9292 | fpr=0.0161 | 5107.8 samples/s | 20.0 steps/s
[Step= 100] | Loss=0.08928 | acc=0.9826 | tpr=0.9254 | fpr=0.0164 | 6427.0 samples/s | 25.1 steps/s
[Step= 150] | Loss=0.09215 | acc=0.9822 | tpr=0.9280 | fpr=0.0168 | 7933.3 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.09408 | acc=0.9822 | tpr=0.9290 | fpr=0.0169 | 7876.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.09232 | acc=0.9825 | tpr=0.9284 | fpr=0.0165 | 7930.5 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.09465 | acc=0.9821 | tpr=0.9258 | fpr=0.0169 | 7929.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09521 | acc=0.9819 | tpr=0.9292 | fpr=0.0171 | 7919.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.09650 | acc=0.9817 | tpr=0.9256 | fpr=0.0173 | 7968.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.09871 | acc=0.9814 | tpr=0.9250 | fpr=0.0175 | 7782.6 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.09777 | acc=0.9816 | tpr=0.9264 | fpr=0.0174 | 8070.4 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.09763 | acc=0.9817 | tpr=0.9244 | fpr=0.0173 | 13608.3 samples/s | 53.2 steps/s
Avg test loss: 0.09753, Avg test acc: 0.98165, Avg tpr: 0.92433, Avg fpr: 0.01731, total FA: 2403

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08633 | acc=0.9815 | tpr=0.9513 | fpr=0.0180 | 4901.8 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08846 | acc=0.9815 | tpr=0.9552 | fpr=0.0180 | 7037.5 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.09256 | acc=0.9810 | tpr=0.9496 | fpr=0.0184 | 7805.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.09377 | acc=0.9812 | tpr=0.9552 | fpr=0.0184 | 7905.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.09189 | acc=0.9815 | tpr=0.9572 | fpr=0.0181 | 7767.1 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.09419 | acc=0.9811 | tpr=0.9505 | fpr=0.0184 | 7572.7 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.09484 | acc=0.9808 | tpr=0.9518 | fpr=0.0187 | 8232.6 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.09603 | acc=0.9806 | tpr=0.9486 | fpr=0.0188 | 7978.1 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.09760 | acc=0.9804 | tpr=0.9479 | fpr=0.0190 | 7806.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.09695 | acc=0.9805 | tpr=0.9480 | fpr=0.0189 | 7794.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.09660 | acc=0.9807 | tpr=0.9471 | fpr=0.0187 | 14051.6 samples/s | 54.9 steps/s
Avg test loss: 0.09646, Avg test acc: 0.98068, Avg tpr: 0.94691, Avg fpr: 0.01870, total FA: 2597

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09710 | acc=0.9796 | tpr=0.9469 | fpr=0.0198 | 4840.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.09976 | acc=0.9797 | tpr=0.9552 | fpr=0.0199 | 7172.8 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.10387 | acc=0.9787 | tpr=0.9524 | fpr=0.0208 | 7894.8 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.10486 | acc=0.9790 | tpr=0.9574 | fpr=0.0206 | 7885.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.10330 | acc=0.9796 | tpr=0.9581 | fpr=0.0200 | 8203.1 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.10540 | acc=0.9794 | tpr=0.9542 | fpr=0.0202 | 7631.5 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.10617 | acc=0.9792 | tpr=0.9537 | fpr=0.0204 | 7780.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10682 | acc=0.9790 | tpr=0.9508 | fpr=0.0205 | 8005.7 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.10881 | acc=0.9788 | tpr=0.9479 | fpr=0.0207 | 7797.4 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.10804 | acc=0.9788 | tpr=0.9489 | fpr=0.0206 | 7964.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.10748 | acc=0.9791 | tpr=0.9487 | fpr=0.0204 | 14222.9 samples/s | 55.6 steps/s
Avg test loss: 0.10728, Avg test acc: 0.97908, Avg tpr: 0.94889, Avg fpr: 0.02037, total FA: 2828

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09557 | acc=0.9813 | tpr=0.9425 | fpr=0.0180 | 4673.6 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10045 | acc=0.9806 | tpr=0.9424 | fpr=0.0187 | 7521.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.10375 | acc=0.9796 | tpr=0.9380 | fpr=0.0196 | 7355.9 samples/s | 28.7 steps/s
[Step= 200] | Loss=0.10551 | acc=0.9796 | tpr=0.9443 | fpr=0.0198 | 8452.8 samples/s | 33.0 steps/s
[Step= 250] | Loss=0.10366 | acc=0.9801 | tpr=0.9415 | fpr=0.0192 | 7890.9 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.10609 | acc=0.9798 | tpr=0.9389 | fpr=0.0195 | 8216.8 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.10669 | acc=0.9797 | tpr=0.9411 | fpr=0.0196 | 7922.7 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.10808 | acc=0.9795 | tpr=0.9382 | fpr=0.0198 | 7763.7 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.11029 | acc=0.9792 | tpr=0.9367 | fpr=0.0200 | 7881.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10968 | acc=0.9793 | tpr=0.9379 | fpr=0.0200 | 7965.1 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.10925 | acc=0.9795 | tpr=0.9371 | fpr=0.0197 | 14017.7 samples/s | 54.8 steps/s
Avg test loss: 0.10908, Avg test acc: 0.97952, Avg tpr: 0.93740, Avg fpr: 0.01971, total FA: 2737

server round 35/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=341.3] | Loss=0.00417 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=18.086 | 5110.2 samples/s | 79.8 steps/s
[Step=70050 Epoch=341.6] | Loss=0.00331 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.265 | L2-Norm(final)=18.092 | 4866.5 samples/s | 76.0 steps/s
[Step=70100 Epoch=341.8] | Loss=0.00284 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=18.100 | 5119.8 samples/s | 80.0 steps/s
[Step=70150 Epoch=342.1] | Loss=0.00263 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=18.108 | 4738.7 samples/s | 74.0 steps/s
[Step=70200 Epoch=342.3] | Loss=0.00280 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=18.115 | 7906.4 samples/s | 123.5 steps/s
[Step=70250 Epoch=342.6] | Loss=0.00266 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.271 | L2-Norm(final)=18.123 | 2207.5 samples/s | 34.5 steps/s
[Step=70300 Epoch=342.8] | Loss=0.00265 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.272 | L2-Norm(final)=18.131 | 5075.0 samples/s | 79.3 steps/s
[Step=70350 Epoch=343.0] | Loss=0.00257 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.273 | L2-Norm(final)=18.138 | 5020.7 samples/s | 78.4 steps/s
[Step=70400 Epoch=343.3] | Loss=0.00264 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.274 | L2-Norm(final)=18.146 | 6986.6 samples/s | 109.2 steps/s
[Step=70450 Epoch=343.5] | Loss=0.00256 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.274 | L2-Norm(final)=18.154 | 2276.6 samples/s | 35.6 steps/s
[Step=70500 Epoch=343.8] | Loss=0.00250 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.275 | L2-Norm(final)=18.161 | 5025.2 samples/s | 78.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=343.8] | Loss=0.00123 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=18.237 | 5729.7 samples/s | 89.5 steps/s
[Step=70550 Epoch=344.0] | Loss=0.00256 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.284 | L2-Norm(final)=18.245 | 3845.0 samples/s | 60.1 steps/s
[Step=70600 Epoch=344.3] | Loss=0.00351 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=18.253 | 4488.7 samples/s | 70.1 steps/s
[Step=70650 Epoch=344.5] | Loss=0.00449 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=18.260 | 4495.6 samples/s | 70.2 steps/s
[Step=70700 Epoch=344.7] | Loss=0.00451 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.299 | L2-Norm(final)=18.268 | 6537.8 samples/s | 102.2 steps/s
[Step=70750 Epoch=345.0] | Loss=0.00452 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=18.275 | 2098.6 samples/s | 32.8 steps/s
[Step=70800 Epoch=345.2] | Loss=0.00451 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=18.281 | 4432.6 samples/s | 69.3 steps/s
[Step=70850 Epoch=345.5] | Loss=0.00438 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=18.287 | 4518.0 samples/s | 70.6 steps/s
[Step=70900 Epoch=345.7] | Loss=0.00428 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.313 | L2-Norm(final)=18.292 | 5901.4 samples/s | 92.2 steps/s
[Step=70950 Epoch=346.0] | Loss=0.00411 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.316 | L2-Norm(final)=18.297 | 2167.7 samples/s | 33.9 steps/s
[Step=71000 Epoch=346.2] | Loss=0.00395 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=18.302 | 4486.5 samples/s | 70.1 steps/s
[Step=71050 Epoch=346.5] | Loss=0.00378 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=18.306 | 4594.3 samples/s | 71.8 steps/s
[Step=71100 Epoch=346.7] | Loss=0.00372 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.320 | L2-Norm(final)=18.311 | 5274.5 samples/s | 82.4 steps/s
[Step=71150 Epoch=346.9] | Loss=0.00365 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.321 | L2-Norm(final)=18.315 | 2248.4 samples/s | 35.1 steps/s
[Step=71200 Epoch=347.2] | Loss=0.00365 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.321 | L2-Norm(final)=18.319 | 4538.1 samples/s | 70.9 steps/s
[Step=71250 Epoch=347.4] | Loss=0.00360 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=18.322 | 4574.6 samples/s | 71.5 steps/s
[Step=71300 Epoch=347.7] | Loss=0.00343 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=18.326 | 4803.7 samples/s | 75.1 steps/s
[Step=71350 Epoch=347.9] | Loss=0.00333 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=18.330 | 2351.5 samples/s | 36.7 steps/s
[Step=71400 Epoch=348.2] | Loss=0.00321 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=18.333 | 4486.3 samples/s | 70.1 steps/s
[Step=71450 Epoch=348.4] | Loss=0.00317 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.321 | L2-Norm(final)=18.336 | 4587.1 samples/s | 71.7 steps/s
[Step=71500 Epoch=348.6] | Loss=0.00314 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.321 | L2-Norm(final)=18.340 | 4488.5 samples/s | 70.1 steps/s
[Step=71550 Epoch=348.9] | Loss=0.00312 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.320 | L2-Norm(final)=18.343 | 2405.0 samples/s | 37.6 steps/s
[Step=71600 Epoch=349.1] | Loss=0.00303 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.320 | L2-Norm(final)=18.346 | 4493.9 samples/s | 70.2 steps/s
[Step=71650 Epoch=349.4] | Loss=0.00301 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=18.349 | 4487.8 samples/s | 70.1 steps/s
[Step=71700 Epoch=349.6] | Loss=0.00298 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=18.352 | 4518.2 samples/s | 70.6 steps/s
[Step=71750 Epoch=349.9] | Loss=0.00293 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=18.355 | 2463.4 samples/s | 38.5 steps/s
[Step=71800 Epoch=350.1] | Loss=0.00293 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.316 | L2-Norm(final)=18.358 | 4528.0 samples/s | 70.7 steps/s
[Step=71850 Epoch=350.4] | Loss=0.00291 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=18.361 | 4372.9 samples/s | 68.3 steps/s
[Step=71900 Epoch=350.6] | Loss=0.00287 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=18.364 | 4461.2 samples/s | 69.7 steps/s
[Step=71950 Epoch=350.8] | Loss=0.00281 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.313 | L2-Norm(final)=18.366 | 2473.1 samples/s | 38.6 steps/s
[Step=72000 Epoch=351.1] | Loss=0.00277 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.312 | L2-Norm(final)=18.369 | 4479.9 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step72000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=341.6] | Loss=0.00070 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.874 | L2-Norm(final)=18.804 | 5313.2 samples/s | 83.0 steps/s
[Step=70050 Epoch=341.8] | Loss=0.00279 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.875 | L2-Norm(final)=18.810 | 4684.1 samples/s | 73.2 steps/s
[Step=70100 Epoch=342.1] | Loss=0.00239 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.875 | L2-Norm(final)=18.817 | 4916.8 samples/s | 76.8 steps/s
[Step=70150 Epoch=342.3] | Loss=0.00232 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.877 | L2-Norm(final)=18.826 | 5066.7 samples/s | 79.2 steps/s
[Step=70200 Epoch=342.5] | Loss=0.00238 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=18.835 | 7906.6 samples/s | 123.5 steps/s
[Step=70250 Epoch=342.8] | Loss=0.00233 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.880 | L2-Norm(final)=18.844 | 2216.4 samples/s | 34.6 steps/s
[Step=70300 Epoch=343.0] | Loss=0.00230 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=18.853 | 4985.2 samples/s | 77.9 steps/s
[Step=70350 Epoch=343.3] | Loss=0.00230 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.882 | L2-Norm(final)=18.862 | 5003.2 samples/s | 78.2 steps/s
[Step=70400 Epoch=343.5] | Loss=0.00228 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=18.871 | 7192.2 samples/s | 112.4 steps/s
[Step=70450 Epoch=343.8] | Loss=0.00226 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=18.879 | 2281.8 samples/s | 35.7 steps/s
[Step=70500 Epoch=344.0] | Loss=0.00224 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=18.888 | 4957.4 samples/s | 77.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=344.0] | Loss=0.00071 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=18.973 | 5404.0 samples/s | 84.4 steps/s
[Step=70550 Epoch=344.3] | Loss=0.00203 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.894 | L2-Norm(final)=18.982 | 4291.9 samples/s | 67.1 steps/s
[Step=70600 Epoch=344.5] | Loss=0.00303 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.898 | L2-Norm(final)=18.990 | 4398.1 samples/s | 68.7 steps/s
[Step=70650 Epoch=344.7] | Loss=0.00356 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.903 | L2-Norm(final)=18.998 | 4500.4 samples/s | 70.3 steps/s
[Step=70700 Epoch=345.0] | Loss=0.00385 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.908 | L2-Norm(final)=19.005 | 6520.9 samples/s | 101.9 steps/s
[Step=70750 Epoch=345.2] | Loss=0.00368 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.912 | L2-Norm(final)=19.012 | 2091.2 samples/s | 32.7 steps/s
[Step=70800 Epoch=345.5] | Loss=0.00352 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.916 | L2-Norm(final)=19.020 | 4476.7 samples/s | 69.9 steps/s
[Step=70850 Epoch=345.7] | Loss=0.00345 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=19.026 | 4520.1 samples/s | 70.6 steps/s
[Step=70900 Epoch=346.0] | Loss=0.00352 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.921 | L2-Norm(final)=19.032 | 5994.3 samples/s | 93.7 steps/s
[Step=70950 Epoch=346.2] | Loss=0.00346 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=19.038 | 2124.7 samples/s | 33.2 steps/s
[Step=71000 Epoch=346.4] | Loss=0.00336 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=19.043 | 4519.0 samples/s | 70.6 steps/s
[Step=71050 Epoch=346.7] | Loss=0.00325 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=19.048 | 4449.3 samples/s | 69.5 steps/s
[Step=71100 Epoch=346.9] | Loss=0.00312 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=19.053 | 5565.4 samples/s | 87.0 steps/s
[Step=71150 Epoch=347.2] | Loss=0.00309 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=19.057 | 2240.7 samples/s | 35.0 steps/s
[Step=71200 Epoch=347.4] | Loss=0.00306 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=19.062 | 4481.6 samples/s | 70.0 steps/s
[Step=71250 Epoch=347.7] | Loss=0.00296 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.928 | L2-Norm(final)=19.066 | 4445.6 samples/s | 69.5 steps/s
[Step=71300 Epoch=347.9] | Loss=0.00287 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.928 | L2-Norm(final)=19.070 | 5205.3 samples/s | 81.3 steps/s
[Step=71350 Epoch=348.2] | Loss=0.00281 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=19.075 | 2272.2 samples/s | 35.5 steps/s
[Step=71400 Epoch=348.4] | Loss=0.00275 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=19.078 | 4607.6 samples/s | 72.0 steps/s
[Step=71450 Epoch=348.6] | Loss=0.00267 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=19.082 | 4346.7 samples/s | 67.9 steps/s
[Step=71500 Epoch=348.9] | Loss=0.00262 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=19.086 | 4878.0 samples/s | 76.2 steps/s
[Step=71550 Epoch=349.1] | Loss=0.00259 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=19.090 | 2387.8 samples/s | 37.3 steps/s
[Step=71600 Epoch=349.4] | Loss=0.00252 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=19.094 | 4473.1 samples/s | 69.9 steps/s
[Step=71650 Epoch=349.6] | Loss=0.00248 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.923 | L2-Norm(final)=19.097 | 4444.3 samples/s | 69.4 steps/s
[Step=71700 Epoch=349.9] | Loss=0.00245 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.921 | L2-Norm(final)=19.101 | 4568.3 samples/s | 71.4 steps/s
[Step=71750 Epoch=350.1] | Loss=0.00243 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.920 | L2-Norm(final)=19.104 | 2451.2 samples/s | 38.3 steps/s
[Step=71800 Epoch=350.4] | Loss=0.00241 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.919 | L2-Norm(final)=19.107 | 4422.2 samples/s | 69.1 steps/s
[Step=71850 Epoch=350.6] | Loss=0.00237 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.917 | L2-Norm(final)=19.111 | 4480.7 samples/s | 70.0 steps/s
[Step=71900 Epoch=350.8] | Loss=0.00233 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=19.114 | 4522.7 samples/s | 70.7 steps/s
[Step=71950 Epoch=351.1] | Loss=0.00231 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=19.117 | 2500.0 samples/s | 39.1 steps/s
[Step=72000 Epoch=351.3] | Loss=0.00226 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.912 | L2-Norm(final)=19.121 | 4306.7 samples/s | 67.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step72000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=341.1] | Loss=0.00021 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.626 | L2-Norm(final)=18.982 | 4962.0 samples/s | 77.5 steps/s
[Step=70050 Epoch=341.3] | Loss=0.00274 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.628 | L2-Norm(final)=18.989 | 4547.0 samples/s | 71.0 steps/s
[Step=70100 Epoch=341.6] | Loss=0.00323 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.629 | L2-Norm(final)=18.997 | 5034.4 samples/s | 78.7 steps/s
[Step=70150 Epoch=341.8] | Loss=0.00316 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.631 | L2-Norm(final)=19.005 | 5037.6 samples/s | 78.7 steps/s
[Step=70200 Epoch=342.0] | Loss=0.00294 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.633 | L2-Norm(final)=19.013 | 7792.6 samples/s | 121.8 steps/s
[Step=70250 Epoch=342.3] | Loss=0.00275 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.634 | L2-Norm(final)=19.021 | 2227.1 samples/s | 34.8 steps/s
[Step=70300 Epoch=342.5] | Loss=0.00277 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.635 | L2-Norm(final)=19.029 | 5035.7 samples/s | 78.7 steps/s
[Step=70350 Epoch=342.8] | Loss=0.00284 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.636 | L2-Norm(final)=19.037 | 5054.5 samples/s | 79.0 steps/s
[Step=70400 Epoch=343.0] | Loss=0.00274 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.636 | L2-Norm(final)=19.045 | 6853.8 samples/s | 107.1 steps/s
[Step=70450 Epoch=343.3] | Loss=0.00271 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.637 | L2-Norm(final)=19.053 | 2298.4 samples/s | 35.9 steps/s
[Step=70500 Epoch=343.5] | Loss=0.00270 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.638 | L2-Norm(final)=19.062 | 5042.2 samples/s | 78.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=343.5] | Loss=0.00297 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.645 | L2-Norm(final)=19.144 | 5439.6 samples/s | 85.0 steps/s
[Step=70550 Epoch=343.8] | Loss=0.00337 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.648 | L2-Norm(final)=19.153 | 3957.7 samples/s | 61.8 steps/s
[Step=70600 Epoch=344.0] | Loss=0.00322 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.651 | L2-Norm(final)=19.161 | 4502.2 samples/s | 70.3 steps/s
[Step=70650 Epoch=344.2] | Loss=0.00378 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.654 | L2-Norm(final)=19.168 | 4399.5 samples/s | 68.7 steps/s
[Step=70700 Epoch=344.5] | Loss=0.00429 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.657 | L2-Norm(final)=19.175 | 6402.8 samples/s | 100.0 steps/s
[Step=70750 Epoch=344.7] | Loss=0.00439 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.661 | L2-Norm(final)=19.181 | 2069.8 samples/s | 32.3 steps/s
[Step=70800 Epoch=345.0] | Loss=0.00477 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.665 | L2-Norm(final)=19.187 | 4422.9 samples/s | 69.1 steps/s
[Step=70850 Epoch=345.2] | Loss=0.00485 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.668 | L2-Norm(final)=19.192 | 4369.3 samples/s | 68.3 steps/s
[Step=70900 Epoch=345.5] | Loss=0.00479 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.672 | L2-Norm(final)=19.198 | 5899.9 samples/s | 92.2 steps/s
[Step=70950 Epoch=345.7] | Loss=0.00454 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=19.203 | 2096.6 samples/s | 32.8 steps/s
[Step=71000 Epoch=345.9] | Loss=0.00430 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=19.207 | 4337.8 samples/s | 67.8 steps/s
[Step=71050 Epoch=346.2] | Loss=0.00412 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.678 | L2-Norm(final)=19.212 | 4452.2 samples/s | 69.6 steps/s
[Step=71100 Epoch=346.4] | Loss=0.00401 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.679 | L2-Norm(final)=19.216 | 5298.9 samples/s | 82.8 steps/s
[Step=71150 Epoch=346.7] | Loss=0.00385 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.680 | L2-Norm(final)=19.220 | 2233.3 samples/s | 34.9 steps/s
[Step=71200 Epoch=346.9] | Loss=0.00364 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=19.223 | 4391.9 samples/s | 68.6 steps/s
[Step=71250 Epoch=347.2] | Loss=0.00355 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=19.227 | 4477.1 samples/s | 70.0 steps/s
[Step=71300 Epoch=347.4] | Loss=0.00354 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=19.230 | 4806.3 samples/s | 75.1 steps/s
[Step=71350 Epoch=347.7] | Loss=0.00346 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.682 | L2-Norm(final)=19.234 | 2296.0 samples/s | 35.9 steps/s
[Step=71400 Epoch=347.9] | Loss=0.00337 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.682 | L2-Norm(final)=19.237 | 4536.3 samples/s | 70.9 steps/s
[Step=71450 Epoch=348.1] | Loss=0.00328 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=19.240 | 4320.9 samples/s | 67.5 steps/s
[Step=71500 Epoch=348.4] | Loss=0.00322 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=19.244 | 4537.5 samples/s | 70.9 steps/s
[Step=71550 Epoch=348.6] | Loss=0.00317 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=19.247 | 2388.3 samples/s | 37.3 steps/s
[Step=71600 Epoch=348.9] | Loss=0.00310 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.681 | L2-Norm(final)=19.250 | 4419.4 samples/s | 69.1 steps/s
[Step=71650 Epoch=349.1] | Loss=0.00303 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.680 | L2-Norm(final)=19.253 | 4410.5 samples/s | 68.9 steps/s
[Step=71700 Epoch=349.4] | Loss=0.00300 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.680 | L2-Norm(final)=19.256 | 4485.5 samples/s | 70.1 steps/s
[Step=71750 Epoch=349.6] | Loss=0.00295 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.679 | L2-Norm(final)=19.258 | 2403.6 samples/s | 37.6 steps/s
[Step=71800 Epoch=349.8] | Loss=0.00289 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.678 | L2-Norm(final)=19.261 | 4412.2 samples/s | 68.9 steps/s
[Step=71850 Epoch=350.1] | Loss=0.00287 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.677 | L2-Norm(final)=19.264 | 4452.4 samples/s | 69.6 steps/s
[Step=71900 Epoch=350.3] | Loss=0.00286 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=19.267 | 4403.5 samples/s | 68.8 steps/s
[Step=71950 Epoch=350.6] | Loss=0.00280 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.675 | L2-Norm(final)=19.270 | 2431.0 samples/s | 38.0 steps/s
[Step=72000 Epoch=350.8] | Loss=0.00277 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.674 | L2-Norm(final)=19.272 | 4420.9 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step72000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=341.4] | Loss=0.00037 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=18.968 | 4748.5 samples/s | 74.2 steps/s
[Step=70050 Epoch=341.6] | Loss=0.00196 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=18.974 | 4687.9 samples/s | 73.2 steps/s
[Step=70100 Epoch=341.8] | Loss=0.00215 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=18.981 | 4948.2 samples/s | 77.3 steps/s
[Step=70150 Epoch=342.1] | Loss=0.00204 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=18.989 | 4971.0 samples/s | 77.7 steps/s
[Step=70200 Epoch=342.3] | Loss=0.00207 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=18.997 | 7761.0 samples/s | 121.3 steps/s
[Step=70250 Epoch=342.6] | Loss=0.00215 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=19.005 | 2230.6 samples/s | 34.9 steps/s
[Step=70300 Epoch=342.8] | Loss=0.00225 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=19.013 | 4943.5 samples/s | 77.2 steps/s
[Step=70350 Epoch=343.1] | Loss=0.00216 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=19.020 | 4967.4 samples/s | 77.6 steps/s
[Step=70400 Epoch=343.3] | Loss=0.00212 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=19.028 | 6783.2 samples/s | 106.0 steps/s
[Step=70450 Epoch=343.6] | Loss=0.00207 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=19.035 | 2336.6 samples/s | 36.5 steps/s
[Step=70500 Epoch=343.8] | Loss=0.00203 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=19.043 | 4726.2 samples/s | 73.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=343.8] | Loss=0.00076 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.338 | L2-Norm(final)=19.119 | 5921.3 samples/s | 92.5 steps/s
[Step=70550 Epoch=344.0] | Loss=0.00136 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.339 | L2-Norm(final)=19.126 | 3829.6 samples/s | 59.8 steps/s
[Step=70600 Epoch=344.3] | Loss=0.00366 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.342 | L2-Norm(final)=19.133 | 4375.6 samples/s | 68.4 steps/s
[Step=70650 Epoch=344.5] | Loss=0.00521 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.347 | L2-Norm(final)=19.139 | 4415.3 samples/s | 69.0 steps/s
[Step=70700 Epoch=344.8] | Loss=0.00482 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=19.146 | 6482.4 samples/s | 101.3 steps/s
[Step=70750 Epoch=345.0] | Loss=0.00448 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.358 | L2-Norm(final)=19.153 | 2065.2 samples/s | 32.3 steps/s
[Step=70800 Epoch=345.3] | Loss=0.00426 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=19.160 | 4425.4 samples/s | 69.1 steps/s
[Step=70850 Epoch=345.5] | Loss=0.00401 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=19.166 | 4484.8 samples/s | 70.1 steps/s
[Step=70900 Epoch=345.7] | Loss=0.00389 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=19.172 | 5755.3 samples/s | 89.9 steps/s
[Step=70950 Epoch=346.0] | Loss=0.00367 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=19.177 | 2137.1 samples/s | 33.4 steps/s
[Step=71000 Epoch=346.2] | Loss=0.00351 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=19.182 | 4549.6 samples/s | 71.1 steps/s
[Step=71050 Epoch=346.5] | Loss=0.00341 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=19.187 | 4313.8 samples/s | 67.4 steps/s
[Step=71100 Epoch=346.7] | Loss=0.00327 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=19.191 | 5392.9 samples/s | 84.3 steps/s
[Step=71150 Epoch=347.0] | Loss=0.00315 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=19.196 | 2205.0 samples/s | 34.5 steps/s
[Step=71200 Epoch=347.2] | Loss=0.00304 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=19.200 | 4427.0 samples/s | 69.2 steps/s
[Step=71250 Epoch=347.5] | Loss=0.00296 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.373 | L2-Norm(final)=19.205 | 4472.4 samples/s | 69.9 steps/s
[Step=71300 Epoch=347.7] | Loss=0.00292 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=19.209 | 4874.3 samples/s | 76.2 steps/s
[Step=71350 Epoch=347.9] | Loss=0.00283 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=19.212 | 2297.9 samples/s | 35.9 steps/s
[Step=71400 Epoch=348.2] | Loss=0.00279 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=19.216 | 4396.9 samples/s | 68.7 steps/s
[Step=71450 Epoch=348.4] | Loss=0.00276 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=19.220 | 4435.1 samples/s | 69.3 steps/s
[Step=71500 Epoch=348.7] | Loss=0.00269 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=19.223 | 4592.3 samples/s | 71.8 steps/s
[Step=71550 Epoch=348.9] | Loss=0.00264 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=19.227 | 2391.8 samples/s | 37.4 steps/s
[Step=71600 Epoch=349.2] | Loss=0.00260 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=19.231 | 4402.3 samples/s | 68.8 steps/s
[Step=71650 Epoch=349.4] | Loss=0.00256 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=19.234 | 4394.0 samples/s | 68.7 steps/s
[Step=71700 Epoch=349.6] | Loss=0.00253 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.367 | L2-Norm(final)=19.238 | 4427.3 samples/s | 69.2 steps/s
[Step=71750 Epoch=349.9] | Loss=0.00248 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=19.241 | 2432.4 samples/s | 38.0 steps/s
[Step=71800 Epoch=350.1] | Loss=0.00243 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=19.244 | 4433.2 samples/s | 69.3 steps/s
[Step=71850 Epoch=350.4] | Loss=0.00237 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=19.248 | 4405.4 samples/s | 68.8 steps/s
[Step=71900 Epoch=350.6] | Loss=0.00234 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=19.251 | 4505.9 samples/s | 70.4 steps/s
[Step=71950 Epoch=350.9] | Loss=0.00234 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=19.254 | 2405.0 samples/s | 37.6 steps/s
[Step=72000 Epoch=351.1] | Loss=0.00231 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=19.257 | 4415.0 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step72000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=343.3] | Loss=0.00125 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=19.016 | 4985.8 samples/s | 77.9 steps/s
[Step=70050 Epoch=343.5] | Loss=0.00177 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=19.022 | 4644.6 samples/s | 72.6 steps/s
[Step=70100 Epoch=343.8] | Loss=0.00220 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=19.030 | 4998.6 samples/s | 78.1 steps/s
[Step=70150 Epoch=344.0] | Loss=0.00234 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=19.038 | 5037.6 samples/s | 78.7 steps/s
[Step=70200 Epoch=344.2] | Loss=0.00227 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=19.046 | 7936.9 samples/s | 124.0 steps/s
[Step=70250 Epoch=344.5] | Loss=0.00229 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=19.054 | 2190.1 samples/s | 34.2 steps/s
[Step=70300 Epoch=344.7] | Loss=0.00222 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=19.063 | 5017.9 samples/s | 78.4 steps/s
[Step=70350 Epoch=345.0] | Loss=0.00213 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=19.071 | 4796.6 samples/s | 74.9 steps/s
[Step=70400 Epoch=345.2] | Loss=0.00216 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.044 | L2-Norm(final)=19.079 | 7405.3 samples/s | 115.7 steps/s
[Step=70450 Epoch=345.5] | Loss=0.00207 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=19.087 | 2237.7 samples/s | 35.0 steps/s
[Step=70500 Epoch=345.7] | Loss=0.00204 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=19.095 | 4871.8 samples/s | 76.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=345.7] | Loss=0.00346 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=19.177 | 5386.6 samples/s | 84.2 steps/s
[Step=70550 Epoch=346.0] | Loss=0.00201 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=19.186 | 3934.5 samples/s | 61.5 steps/s
[Step=70600 Epoch=346.2] | Loss=0.00263 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.055 | L2-Norm(final)=19.194 | 4430.3 samples/s | 69.2 steps/s
[Step=70650 Epoch=346.5] | Loss=0.00304 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=19.202 | 4453.5 samples/s | 69.6 steps/s
[Step=70700 Epoch=346.7] | Loss=0.00329 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=19.210 | 6623.3 samples/s | 103.5 steps/s
[Step=70750 Epoch=346.9] | Loss=0.00351 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.070 | L2-Norm(final)=19.218 | 2046.7 samples/s | 32.0 steps/s
[Step=70800 Epoch=347.2] | Loss=0.00337 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.074 | L2-Norm(final)=19.224 | 4336.0 samples/s | 67.8 steps/s
[Step=70850 Epoch=347.4] | Loss=0.00357 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.076 | L2-Norm(final)=19.230 | 4529.3 samples/s | 70.8 steps/s
[Step=70900 Epoch=347.7] | Loss=0.00368 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=19.235 | 6040.4 samples/s | 94.4 steps/s
[Step=70950 Epoch=347.9] | Loss=0.00358 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=19.241 | 2110.5 samples/s | 33.0 steps/s
[Step=71000 Epoch=348.2] | Loss=0.00345 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=19.246 | 4406.6 samples/s | 68.9 steps/s
[Step=71050 Epoch=348.4] | Loss=0.00338 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.085 | L2-Norm(final)=19.251 | 4430.5 samples/s | 69.2 steps/s
[Step=71100 Epoch=348.7] | Loss=0.00327 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=19.256 | 5839.3 samples/s | 91.2 steps/s
[Step=71150 Epoch=348.9] | Loss=0.00314 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=19.261 | 2137.5 samples/s | 33.4 steps/s
[Step=71200 Epoch=349.2] | Loss=0.00318 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=19.265 | 4433.1 samples/s | 69.3 steps/s
[Step=71250 Epoch=349.4] | Loss=0.00318 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=19.270 | 4397.0 samples/s | 68.7 steps/s
[Step=71300 Epoch=349.6] | Loss=0.00307 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=19.274 | 5483.5 samples/s | 85.7 steps/s
[Step=71350 Epoch=349.9] | Loss=0.00299 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=19.278 | 2186.2 samples/s | 34.2 steps/s
[Step=71400 Epoch=350.1] | Loss=0.00289 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=19.282 | 4469.2 samples/s | 69.8 steps/s
[Step=71450 Epoch=350.4] | Loss=0.00286 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=19.286 | 4376.1 samples/s | 68.4 steps/s
[Step=71500 Epoch=350.6] | Loss=0.00277 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=19.289 | 5171.6 samples/s | 80.8 steps/s
[Step=71550 Epoch=350.9] | Loss=0.00272 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=19.293 | 2261.0 samples/s | 35.3 steps/s
[Step=71600 Epoch=351.1] | Loss=0.00267 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=19.296 | 4364.8 samples/s | 68.2 steps/s
[Step=71650 Epoch=351.4] | Loss=0.00261 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=19.300 | 4441.9 samples/s | 69.4 steps/s
[Step=71700 Epoch=351.6] | Loss=0.00256 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=19.303 | 4820.9 samples/s | 75.3 steps/s
[Step=71750 Epoch=351.9] | Loss=0.00249 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=19.306 | 2325.1 samples/s | 36.3 steps/s
[Step=71800 Epoch=352.1] | Loss=0.00245 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=19.310 | 4374.3 samples/s | 68.3 steps/s
[Step=71850 Epoch=352.3] | Loss=0.00243 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=19.313 | 4395.1 samples/s | 68.7 steps/s
[Step=71900 Epoch=352.6] | Loss=0.00238 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=19.316 | 4647.4 samples/s | 72.6 steps/s
[Step=71950 Epoch=352.8] | Loss=0.00235 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.085 | L2-Norm(final)=19.319 | 2355.3 samples/s | 36.8 steps/s
[Step=72000 Epoch=353.1] | Loss=0.00232 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=19.322 | 4454.7 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step72000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=663.3] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.701 | L2-Norm(final)=9.421 | 4707.6 samples/s | 73.6 steps/s
[Step=70050 Epoch=663.8] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.704 | L2-Norm(final)=9.435 | 4340.3 samples/s | 67.8 steps/s
[Step=70100 Epoch=664.3] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.712 | L2-Norm(final)=9.454 | 7145.3 samples/s | 111.6 steps/s
[Step=70150 Epoch=664.7] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=9.471 | 2111.5 samples/s | 33.0 steps/s
[Step=70200 Epoch=665.2] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.726 | L2-Norm(final)=9.485 | 6576.0 samples/s | 102.8 steps/s
[Step=70250 Epoch=665.7] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.731 | L2-Norm(final)=9.497 | 2227.4 samples/s | 34.8 steps/s
[Step=70300 Epoch=666.2] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.735 | L2-Norm(final)=9.507 | 5569.6 samples/s | 87.0 steps/s
[Step=70350 Epoch=666.6] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.738 | L2-Norm(final)=9.517 | 2264.1 samples/s | 35.4 steps/s
[Step=70400 Epoch=667.1] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.741 | L2-Norm(final)=9.527 | 5277.3 samples/s | 82.5 steps/s
[Step=70450 Epoch=667.6] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.744 | L2-Norm(final)=9.536 | 2414.2 samples/s | 37.7 steps/s
[Step=70500 Epoch=668.0] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.746 | L2-Norm(final)=9.544 | 4832.7 samples/s | 75.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=668.1] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.765 | L2-Norm(final)=9.627 | 5283.2 samples/s | 82.5 steps/s
[Step=70550 Epoch=668.5] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.757 | L2-Norm(final)=9.633 | 3768.2 samples/s | 58.9 steps/s
[Step=70600 Epoch=669.0] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.744 | L2-Norm(final)=9.637 | 6331.7 samples/s | 98.9 steps/s
[Step=70650 Epoch=669.5] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.729 | L2-Norm(final)=9.640 | 2015.4 samples/s | 31.5 steps/s
[Step=70700 Epoch=669.9] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.713 | L2-Norm(final)=9.643 | 5672.3 samples/s | 88.6 steps/s
[Step=70750 Epoch=670.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.696 | L2-Norm(final)=9.645 | 2062.3 samples/s | 32.2 steps/s
[Step=70800 Epoch=670.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.678 | L2-Norm(final)=9.646 | 4871.3 samples/s | 76.1 steps/s
[Step=70850 Epoch=671.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.660 | L2-Norm(final)=9.648 | 2026.2 samples/s | 31.7 steps/s
[Step=70900 Epoch=671.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.642 | L2-Norm(final)=9.649 | 4489.0 samples/s | 70.1 steps/s
[Step=70950 Epoch=672.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.624 | L2-Norm(final)=9.651 | 2099.8 samples/s | 32.8 steps/s
[Step=71000 Epoch=672.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.605 | L2-Norm(final)=9.652 | 4081.2 samples/s | 63.8 steps/s
[Step=71050 Epoch=673.3] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.587 | L2-Norm(final)=9.653 | 2194.9 samples/s | 34.3 steps/s
[Step=71100 Epoch=673.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.568 | L2-Norm(final)=9.655 | 4121.7 samples/s | 64.4 steps/s
[Step=71150 Epoch=674.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.549 | L2-Norm(final)=9.656 | 2315.3 samples/s | 36.2 steps/s
[Step=71200 Epoch=674.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.530 | L2-Norm(final)=9.658 | 4285.6 samples/s | 67.0 steps/s
[Step=71250 Epoch=675.2] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.512 | L2-Norm(final)=9.659 | 2339.6 samples/s | 36.6 steps/s
[Step=71300 Epoch=675.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=9.661 | 4257.7 samples/s | 66.5 steps/s
[Step=71350 Epoch=676.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.473 | L2-Norm(final)=9.663 | 2555.5 samples/s | 39.9 steps/s
[Step=71400 Epoch=676.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.454 | L2-Norm(final)=9.664 | 4001.2 samples/s | 62.5 steps/s
[Step=71450 Epoch=677.1] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.435 | L2-Norm(final)=9.666 | 6527.6 samples/s | 102.0 steps/s
[Step=71500 Epoch=677.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.416 | L2-Norm(final)=9.668 | 2007.5 samples/s | 31.4 steps/s
[Step=71550 Epoch=678.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.397 | L2-Norm(final)=9.669 | 5761.9 samples/s | 90.0 steps/s
[Step=71600 Epoch=678.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=9.671 | 2071.9 samples/s | 32.4 steps/s
[Step=71650 Epoch=678.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.358 | L2-Norm(final)=9.673 | 5160.3 samples/s | 80.6 steps/s
[Step=71700 Epoch=679.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.338 | L2-Norm(final)=9.675 | 2150.8 samples/s | 33.6 steps/s
[Step=71750 Epoch=679.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=9.677 | 4860.8 samples/s | 76.0 steps/s
[Step=71800 Epoch=680.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.299 | L2-Norm(final)=9.679 | 2268.2 samples/s | 35.4 steps/s
[Step=71850 Epoch=680.8] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.279 | L2-Norm(final)=9.681 | 4321.8 samples/s | 67.5 steps/s
[Step=71900 Epoch=681.3] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=9.683 | 2307.3 samples/s | 36.1 steps/s
[Step=71950 Epoch=681.8] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.239 | L2-Norm(final)=9.686 | 4309.4 samples/s | 67.3 steps/s
[Step=72000 Epoch=682.3] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=9.688 | 2370.8 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step72000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=665.9] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.735 | L2-Norm(final)=10.320 | 5417.9 samples/s | 84.7 steps/s
[Step=70050 Epoch=666.3] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.738 | L2-Norm(final)=10.328 | 4013.3 samples/s | 62.7 steps/s
[Step=70100 Epoch=666.8] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.744 | L2-Norm(final)=10.337 | 7435.5 samples/s | 116.2 steps/s
[Step=70150 Epoch=667.3] | Loss=0.00004 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.748 | L2-Norm(final)=10.346 | 2142.4 samples/s | 33.5 steps/s
[Step=70200 Epoch=667.8] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.752 | L2-Norm(final)=10.354 | 6540.2 samples/s | 102.2 steps/s
[Step=70250 Epoch=668.3] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.754 | L2-Norm(final)=10.361 | 2199.6 samples/s | 34.4 steps/s
[Step=70300 Epoch=668.7] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.757 | L2-Norm(final)=10.368 | 5953.8 samples/s | 93.0 steps/s
[Step=70350 Epoch=669.2] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.759 | L2-Norm(final)=10.375 | 2315.4 samples/s | 36.2 steps/s
[Step=70400 Epoch=669.7] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.760 | L2-Norm(final)=10.382 | 5226.9 samples/s | 81.7 steps/s
[Step=70450 Epoch=670.2] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.762 | L2-Norm(final)=10.388 | 2416.9 samples/s | 37.8 steps/s
[Step=70500 Epoch=670.6] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.395 | 4931.9 samples/s | 77.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=670.6] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.776 | L2-Norm(final)=10.456 | 5422.6 samples/s | 84.7 steps/s
[Step=70550 Epoch=671.1] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.773 | L2-Norm(final)=10.462 | 3734.3 samples/s | 58.3 steps/s
[Step=70600 Epoch=671.6] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.767 | L2-Norm(final)=10.466 | 6275.7 samples/s | 98.1 steps/s
[Step=70650 Epoch=672.1] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.759 | L2-Norm(final)=10.469 | 2018.9 samples/s | 31.5 steps/s
[Step=70700 Epoch=672.5] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.750 | L2-Norm(final)=10.471 | 5572.9 samples/s | 87.1 steps/s
[Step=70750 Epoch=673.0] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.740 | L2-Norm(final)=10.474 | 2104.0 samples/s | 32.9 steps/s
[Step=70800 Epoch=673.5] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.730 | L2-Norm(final)=10.476 | 5058.6 samples/s | 79.0 steps/s
[Step=70850 Epoch=674.0] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=10.477 | 2190.2 samples/s | 34.2 steps/s
[Step=70900 Epoch=674.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.710 | L2-Norm(final)=10.479 | 4726.3 samples/s | 73.8 steps/s
[Step=70950 Epoch=674.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.699 | L2-Norm(final)=10.480 | 2256.6 samples/s | 35.3 steps/s
[Step=71000 Epoch=675.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.689 | L2-Norm(final)=10.482 | 4245.5 samples/s | 66.3 steps/s
[Step=71050 Epoch=675.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.678 | L2-Norm(final)=10.483 | 2355.3 samples/s | 36.8 steps/s
[Step=71100 Epoch=676.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.667 | L2-Norm(final)=10.485 | 4195.3 samples/s | 65.6 steps/s
[Step=71150 Epoch=676.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.656 | L2-Norm(final)=10.486 | 2415.8 samples/s | 37.7 steps/s
[Step=71200 Epoch=677.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.645 | L2-Norm(final)=10.488 | 4225.1 samples/s | 66.0 steps/s
[Step=71250 Epoch=677.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.634 | L2-Norm(final)=10.489 | 2388.7 samples/s | 37.3 steps/s
[Step=71300 Epoch=678.2] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.622 | L2-Norm(final)=10.491 | 4172.8 samples/s | 65.2 steps/s
[Step=71350 Epoch=678.7] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.611 | L2-Norm(final)=10.492 | 2537.6 samples/s | 39.6 steps/s
[Step=71400 Epoch=679.2] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.599 | L2-Norm(final)=10.494 | 4010.7 samples/s | 62.7 steps/s
[Step=71450 Epoch=679.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.588 | L2-Norm(final)=10.495 | 6535.0 samples/s | 102.1 steps/s
[Step=71500 Epoch=680.1] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.576 | L2-Norm(final)=10.497 | 2047.8 samples/s | 32.0 steps/s
[Step=71550 Epoch=680.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.564 | L2-Norm(final)=10.498 | 5625.3 samples/s | 87.9 steps/s
[Step=71600 Epoch=681.1] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.552 | L2-Norm(final)=10.500 | 2037.8 samples/s | 31.8 steps/s
[Step=71650 Epoch=681.6] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.540 | L2-Norm(final)=10.502 | 5296.4 samples/s | 82.8 steps/s
[Step=71700 Epoch=682.0] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.528 | L2-Norm(final)=10.503 | 2142.8 samples/s | 33.5 steps/s
[Step=71750 Epoch=682.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.516 | L2-Norm(final)=10.505 | 4852.6 samples/s | 75.8 steps/s
[Step=71800 Epoch=683.0] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.503 | L2-Norm(final)=10.507 | 2230.8 samples/s | 34.9 steps/s
[Step=71850 Epoch=683.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.491 | L2-Norm(final)=10.508 | 4470.7 samples/s | 69.9 steps/s
[Step=71900 Epoch=683.9] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.479 | L2-Norm(final)=10.510 | 2257.8 samples/s | 35.3 steps/s
[Step=71950 Epoch=684.4] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.466 | L2-Norm(final)=10.512 | 4296.3 samples/s | 67.1 steps/s
[Step=72000 Epoch=684.9] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.514 | 2402.2 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step72000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=668.5] | Loss=0.00010 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.718 | L2-Norm(final)=10.308 | 5135.8 samples/s | 80.2 steps/s
[Step=70050 Epoch=668.9] | Loss=0.00003 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.308 | 4074.8 samples/s | 63.7 steps/s
[Step=70100 Epoch=669.4] | Loss=0.00002 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.309 | 7506.1 samples/s | 117.3 steps/s
[Step=70150 Epoch=669.9] | Loss=0.00002 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.310 | 2085.4 samples/s | 32.6 steps/s
[Step=70200 Epoch=670.4] | Loss=0.00002 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.311 | 6575.7 samples/s | 102.7 steps/s
[Step=70250 Epoch=670.8] | Loss=0.00002 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.312 | 2196.3 samples/s | 34.3 steps/s
[Step=70300 Epoch=671.3] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.312 | 6121.1 samples/s | 95.6 steps/s
[Step=70350 Epoch=671.8] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.313 | 2247.7 samples/s | 35.1 steps/s
[Step=70400 Epoch=672.3] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.314 | 5721.2 samples/s | 89.4 steps/s
[Step=70450 Epoch=672.8] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.315 | 2295.8 samples/s | 35.9 steps/s
[Step=70500 Epoch=673.2] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.316 | 5184.6 samples/s | 81.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=673.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=10.326 | 5346.0 samples/s | 83.5 steps/s
[Step=70550 Epoch=673.7] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.326 | 3853.6 samples/s | 60.2 steps/s
[Step=70600 Epoch=674.2] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.718 | L2-Norm(final)=10.327 | 6421.4 samples/s | 100.3 steps/s
[Step=70650 Epoch=674.7] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.717 | L2-Norm(final)=10.328 | 2011.7 samples/s | 31.4 steps/s
[Step=70700 Epoch=675.1] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.716 | L2-Norm(final)=10.329 | 5824.9 samples/s | 91.0 steps/s
[Step=70750 Epoch=675.6] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.715 | L2-Norm(final)=10.329 | 2009.2 samples/s | 31.4 steps/s
[Step=70800 Epoch=676.1] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.713 | L2-Norm(final)=10.330 | 5320.0 samples/s | 83.1 steps/s
[Step=70850 Epoch=676.6] | Loss=0.00001 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.711 | L2-Norm(final)=10.330 | 2125.0 samples/s | 33.2 steps/s
[Step=70900 Epoch=677.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.710 | L2-Norm(final)=10.331 | 4984.8 samples/s | 77.9 steps/s
[Step=70950 Epoch=677.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.708 | L2-Norm(final)=10.331 | 2227.9 samples/s | 34.8 steps/s
[Step=71000 Epoch=678.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.706 | L2-Norm(final)=10.332 | 4549.0 samples/s | 71.1 steps/s
[Step=71050 Epoch=678.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.704 | L2-Norm(final)=10.332 | 2246.1 samples/s | 35.1 steps/s
[Step=71100 Epoch=679.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.702 | L2-Norm(final)=10.332 | 4353.5 samples/s | 68.0 steps/s
[Step=71150 Epoch=679.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.700 | L2-Norm(final)=10.333 | 2361.8 samples/s | 36.9 steps/s
[Step=71200 Epoch=679.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.698 | L2-Norm(final)=10.333 | 4277.1 samples/s | 66.8 steps/s
[Step=71250 Epoch=680.4] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.695 | L2-Norm(final)=10.334 | 2374.5 samples/s | 37.1 steps/s
[Step=71300 Epoch=680.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.693 | L2-Norm(final)=10.334 | 4190.2 samples/s | 65.5 steps/s
[Step=71350 Epoch=681.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.691 | L2-Norm(final)=10.334 | 2414.9 samples/s | 37.7 steps/s
[Step=71400 Epoch=681.8] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.688 | L2-Norm(final)=10.335 | 4145.6 samples/s | 64.8 steps/s
[Step=71450 Epoch=682.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.686 | L2-Norm(final)=10.335 | 2444.7 samples/s | 38.2 steps/s
[Step=71500 Epoch=682.8] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.684 | L2-Norm(final)=10.336 | 4258.9 samples/s | 66.5 steps/s
[Step=71550 Epoch=683.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.681 | L2-Norm(final)=10.336 | 6817.0 samples/s | 106.5 steps/s
[Step=71600 Epoch=683.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.679 | L2-Norm(final)=10.336 | 1957.6 samples/s | 30.6 steps/s
[Step=71650 Epoch=684.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.676 | L2-Norm(final)=10.337 | 6228.4 samples/s | 97.3 steps/s
[Step=71700 Epoch=684.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.673 | L2-Norm(final)=10.337 | 2015.3 samples/s | 31.5 steps/s
[Step=71750 Epoch=685.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.671 | L2-Norm(final)=10.338 | 5689.7 samples/s | 88.9 steps/s
[Step=71800 Epoch=685.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.668 | L2-Norm(final)=10.338 | 2073.4 samples/s | 32.4 steps/s
[Step=71850 Epoch=686.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.665 | L2-Norm(final)=10.339 | 5334.1 samples/s | 83.3 steps/s
[Step=71900 Epoch=686.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.663 | L2-Norm(final)=10.339 | 2135.0 samples/s | 33.4 steps/s
[Step=71950 Epoch=687.1] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.660 | L2-Norm(final)=10.339 | 4936.2 samples/s | 77.1 steps/s
[Step=72000 Epoch=687.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.657 | L2-Norm(final)=10.340 | 2211.2 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step72000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=659.6] | Loss=0.00009 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.844 | L2-Norm(final)=10.057 | 5230.4 samples/s | 81.7 steps/s
[Step=70050 Epoch=660.1] | Loss=0.00005 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.846 | L2-Norm(final)=10.062 | 4242.5 samples/s | 66.3 steps/s
[Step=70100 Epoch=660.5] | Loss=0.00005 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.849 | L2-Norm(final)=10.069 | 6990.7 samples/s | 109.2 steps/s
[Step=70150 Epoch=661.0] | Loss=0.00005 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.077 | 2124.3 samples/s | 33.2 steps/s
[Step=70200 Epoch=661.5] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.855 | L2-Norm(final)=10.083 | 6381.2 samples/s | 99.7 steps/s
[Step=70250 Epoch=662.0] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.089 | 2232.1 samples/s | 34.9 steps/s
[Step=70300 Epoch=662.4] | Loss=0.00004 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.860 | L2-Norm(final)=10.095 | 5618.6 samples/s | 87.8 steps/s
[Step=70350 Epoch=662.9] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.861 | L2-Norm(final)=10.101 | 2373.0 samples/s | 37.1 steps/s
[Step=70400 Epoch=663.4] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.106 | 5019.9 samples/s | 78.4 steps/s
[Step=70450 Epoch=663.8] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.864 | L2-Norm(final)=10.111 | 2449.1 samples/s | 38.3 steps/s
[Step=70500 Epoch=664.3] | Loss=0.00003 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.865 | L2-Norm(final)=10.116 | 4706.3 samples/s | 73.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=664.3] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=10.166 | 5143.6 samples/s | 80.4 steps/s
[Step=70550 Epoch=664.8] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.875 | L2-Norm(final)=10.171 | 3900.9 samples/s | 61.0 steps/s
[Step=70600 Epoch=665.3] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.872 | L2-Norm(final)=10.174 | 6021.6 samples/s | 94.1 steps/s
[Step=70650 Epoch=665.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.869 | L2-Norm(final)=10.178 | 2029.8 samples/s | 31.7 steps/s
[Step=70700 Epoch=666.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.864 | L2-Norm(final)=10.180 | 5531.4 samples/s | 86.4 steps/s
[Step=70750 Epoch=666.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.859 | L2-Norm(final)=10.182 | 2106.5 samples/s | 32.9 steps/s
[Step=70800 Epoch=667.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.853 | L2-Norm(final)=10.184 | 4924.8 samples/s | 76.9 steps/s
[Step=70850 Epoch=667.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.847 | L2-Norm(final)=10.185 | 2255.7 samples/s | 35.2 steps/s
[Step=70900 Epoch=668.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.840 | L2-Norm(final)=10.187 | 4425.9 samples/s | 69.2 steps/s
[Step=70950 Epoch=668.6] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.833 | L2-Norm(final)=10.188 | 2343.3 samples/s | 36.6 steps/s
[Step=71000 Epoch=669.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.827 | L2-Norm(final)=10.189 | 4073.1 samples/s | 63.6 steps/s
[Step=71050 Epoch=669.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.820 | L2-Norm(final)=10.190 | 2328.2 samples/s | 36.4 steps/s
[Step=71100 Epoch=670.0] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.813 | L2-Norm(final)=10.191 | 4206.2 samples/s | 65.7 steps/s
[Step=71150 Epoch=670.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.805 | L2-Norm(final)=10.192 | 2288.7 samples/s | 35.8 steps/s
[Step=71200 Epoch=670.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.798 | L2-Norm(final)=10.194 | 4122.2 samples/s | 64.4 steps/s
[Step=71250 Epoch=671.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.791 | L2-Norm(final)=10.195 | 2578.5 samples/s | 40.3 steps/s
[Step=71300 Epoch=671.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.783 | L2-Norm(final)=10.196 | 3786.1 samples/s | 59.2 steps/s
[Step=71350 Epoch=672.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.776 | L2-Norm(final)=10.197 | 6045.0 samples/s | 94.5 steps/s
[Step=71400 Epoch=672.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.768 | L2-Norm(final)=10.198 | 2012.5 samples/s | 31.4 steps/s
[Step=71450 Epoch=673.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.760 | L2-Norm(final)=10.199 | 5614.6 samples/s | 87.7 steps/s
[Step=71500 Epoch=673.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.752 | L2-Norm(final)=10.200 | 2116.2 samples/s | 33.1 steps/s
[Step=71550 Epoch=674.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.744 | L2-Norm(final)=10.201 | 4922.0 samples/s | 76.9 steps/s
[Step=71600 Epoch=674.7] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.736 | L2-Norm(final)=10.202 | 2180.8 samples/s | 34.1 steps/s
[Step=71650 Epoch=675.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.728 | L2-Norm(final)=10.203 | 4483.1 samples/s | 70.0 steps/s
[Step=71700 Epoch=675.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.719 | L2-Norm(final)=10.204 | 2309.7 samples/s | 36.1 steps/s
[Step=71750 Epoch=676.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.711 | L2-Norm(final)=10.205 | 4245.2 samples/s | 66.3 steps/s
[Step=71800 Epoch=676.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.702 | L2-Norm(final)=10.206 | 2420.9 samples/s | 37.8 steps/s
[Step=71850 Epoch=677.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.694 | L2-Norm(final)=10.207 | 4116.1 samples/s | 64.3 steps/s
[Step=71900 Epoch=677.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.685 | L2-Norm(final)=10.209 | 2362.7 samples/s | 36.9 steps/s
[Step=71950 Epoch=678.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.676 | L2-Norm(final)=10.210 | 4235.5 samples/s | 66.2 steps/s
[Step=72000 Epoch=678.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.667 | L2-Norm(final)=10.211 | 2496.2 samples/s | 39.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step72000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=667.2] | Loss=0.00007 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.791 | L2-Norm(final)=10.589 | 4987.4 samples/s | 77.9 steps/s
[Step=70050 Epoch=667.6] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.792 | L2-Norm(final)=10.594 | 4377.6 samples/s | 68.4 steps/s
[Step=70100 Epoch=668.1] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.795 | L2-Norm(final)=10.600 | 7550.0 samples/s | 118.0 steps/s
[Step=70150 Epoch=668.6] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=10.607 | 2115.7 samples/s | 33.1 steps/s
[Step=70200 Epoch=669.1] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.799 | L2-Norm(final)=10.614 | 6528.2 samples/s | 102.0 steps/s
[Step=70250 Epoch=669.5] | Loss=0.00003 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.801 | L2-Norm(final)=10.620 | 2180.3 samples/s | 34.1 steps/s
[Step=70300 Epoch=670.0] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.802 | L2-Norm(final)=10.626 | 6221.2 samples/s | 97.2 steps/s
[Step=70350 Epoch=670.5] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.804 | L2-Norm(final)=10.632 | 2240.3 samples/s | 35.0 steps/s
[Step=70400 Epoch=671.0] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.805 | L2-Norm(final)=10.637 | 5639.9 samples/s | 88.1 steps/s
[Step=70450 Epoch=671.5] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=10.643 | 2375.7 samples/s | 37.1 steps/s
[Step=70500 Epoch=671.9] | Loss=0.00002 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.807 | L2-Norm(final)=10.648 | 4968.9 samples/s | 77.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=671.9] | Loss=0.00005 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.818 | L2-Norm(final)=10.703 | 5334.4 samples/s | 83.4 steps/s
[Step=70550 Epoch=672.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.816 | L2-Norm(final)=10.708 | 3741.5 samples/s | 58.5 steps/s
[Step=70600 Epoch=672.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.811 | L2-Norm(final)=10.712 | 6372.5 samples/s | 99.6 steps/s
[Step=70650 Epoch=673.4] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=10.715 | 2033.1 samples/s | 31.8 steps/s
[Step=70700 Epoch=673.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.799 | L2-Norm(final)=10.718 | 5646.5 samples/s | 88.2 steps/s
[Step=70750 Epoch=674.3] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.792 | L2-Norm(final)=10.720 | 2063.9 samples/s | 32.2 steps/s
[Step=70800 Epoch=674.8] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.785 | L2-Norm(final)=10.722 | 5258.0 samples/s | 82.2 steps/s
[Step=70850 Epoch=675.3] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.777 | L2-Norm(final)=10.724 | 2116.2 samples/s | 33.1 steps/s
[Step=70900 Epoch=675.7] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.769 | L2-Norm(final)=10.725 | 4974.8 samples/s | 77.7 steps/s
[Step=70950 Epoch=676.2] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.761 | L2-Norm(final)=10.727 | 2212.9 samples/s | 34.6 steps/s
[Step=71000 Epoch=676.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.753 | L2-Norm(final)=10.728 | 4543.3 samples/s | 71.0 steps/s
[Step=71050 Epoch=677.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.745 | L2-Norm(final)=10.730 | 2255.8 samples/s | 35.2 steps/s
[Step=71100 Epoch=677.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.737 | L2-Norm(final)=10.731 | 4301.1 samples/s | 67.2 steps/s
[Step=71150 Epoch=678.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.728 | L2-Norm(final)=10.732 | 2359.2 samples/s | 36.9 steps/s
[Step=71200 Epoch=678.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.720 | L2-Norm(final)=10.734 | 4245.6 samples/s | 66.3 steps/s
[Step=71250 Epoch=679.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.711 | L2-Norm(final)=10.735 | 2382.2 samples/s | 37.2 steps/s
[Step=71300 Epoch=679.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.702 | L2-Norm(final)=10.736 | 4345.2 samples/s | 67.9 steps/s
[Step=71350 Epoch=680.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.693 | L2-Norm(final)=10.738 | 2342.8 samples/s | 36.6 steps/s
[Step=71400 Epoch=680.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.684 | L2-Norm(final)=10.739 | 4211.4 samples/s | 65.8 steps/s
[Step=71450 Epoch=681.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.740 | 2403.0 samples/s | 37.5 steps/s
[Step=71500 Epoch=681.5] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.666 | L2-Norm(final)=10.742 | 4234.6 samples/s | 66.2 steps/s
[Step=71550 Epoch=681.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.657 | L2-Norm(final)=10.743 | 6899.3 samples/s | 107.8 steps/s
[Step=71600 Epoch=682.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.647 | L2-Norm(final)=10.745 | 1940.7 samples/s | 30.3 steps/s
[Step=71650 Epoch=682.9] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.638 | L2-Norm(final)=10.746 | 6237.6 samples/s | 97.5 steps/s
[Step=71700 Epoch=683.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.628 | L2-Norm(final)=10.747 | 1976.4 samples/s | 30.9 steps/s
[Step=71750 Epoch=683.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.619 | L2-Norm(final)=10.749 | 5776.8 samples/s | 90.3 steps/s
[Step=71800 Epoch=684.3] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.609 | L2-Norm(final)=10.750 | 2075.8 samples/s | 32.4 steps/s
[Step=71850 Epoch=684.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.599 | L2-Norm(final)=10.752 | 5314.1 samples/s | 83.0 steps/s
[Step=71900 Epoch=685.3] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.589 | L2-Norm(final)=10.754 | 2152.8 samples/s | 33.6 steps/s
[Step=71950 Epoch=685.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.579 | L2-Norm(final)=10.755 | 4819.3 samples/s | 75.3 steps/s
[Step=72000 Epoch=686.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.569 | L2-Norm(final)=10.757 | 2185.9 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10774 | acc=0.9569 | tpr=0.9649 | fpr=0.0605 | 4924.8 samples/s | 19.2 steps/s
Avg test loss: 0.11357, Avg test acc: 0.95492, Avg tpr: 0.96369, Avg fpr: 0.06435, total FA: 502

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11851 | acc=0.9585 | tpr=0.9732 | fpr=0.0733 | 4628.2 samples/s | 18.1 steps/s
Avg test loss: 0.11943, Avg test acc: 0.95793, Avg tpr: 0.97196, Avg fpr: 0.07294, total FA: 569

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11251 | acc=0.9575 | tpr=0.9687 | fpr=0.0669 | 4832.1 samples/s | 18.9 steps/s
Avg test loss: 0.11546, Avg test acc: 0.95613, Avg tpr: 0.96643, Avg fpr: 0.06653, total FA: 519

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10583 | acc=0.9607 | tpr=0.9747 | fpr=0.0696 | 4838.9 samples/s | 18.9 steps/s
Avg test loss: 0.11095, Avg test acc: 0.95945, Avg tpr: 0.97459, Avg fpr: 0.07384, total FA: 576

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11200 | acc=0.9582 | tpr=0.9701 | fpr=0.0676 | 4780.1 samples/s | 18.7 steps/s
Avg test loss: 0.11729, Avg test acc: 0.95733, Avg tpr: 0.96969, Avg fpr: 0.06986, total FA: 545

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.44399 | acc=0.3035 | tpr=0.0041 | fpr=0.0463 | 4766.7 samples/s | 18.6 steps/s
Avg test loss: 5.45550, Avg test acc: 0.30203, Avg tpr: 0.00554, Avg fpr: 0.04589, total FA: 358

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.70903 | acc=0.2980 | tpr=0.0047 | fpr=0.0649 | 4924.4 samples/s | 19.2 steps/s
Avg test loss: 4.72194, Avg test acc: 0.29530, Avg tpr: 0.00525, Avg fpr: 0.06679, total FA: 521

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.53301 | acc=0.2838 | tpr=0.0156 | fpr=0.1340 | 4714.9 samples/s | 18.4 steps/s
Avg test loss: 5.53171, Avg test acc: 0.28223, Avg tpr: 0.01690, Avg fpr: 0.13421, total FA: 1047

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.59128 | acc=0.2995 | tpr=0.0110 | fpr=0.0741 | 4830.7 samples/s | 18.9 steps/s
Avg test loss: 5.59096, Avg test acc: 0.29762, Avg tpr: 0.01212, Avg fpr: 0.07448, total FA: 581

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.86001 | acc=0.3020 | tpr=0.0116 | fpr=0.0676 | 4884.1 samples/s | 19.1 steps/s
Avg test loss: 4.86458, Avg test acc: 0.30018, Avg tpr: 0.01276, Avg fpr: 0.06768, total FA: 528

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.74496 | acc=0.1180 | tpr=0.5310 | fpr=0.8895 | 4917.6 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.70800 | acc=0.1202 | tpr=0.5330 | fpr=0.8875 | 6991.2 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.72104 | acc=0.1200 | tpr=0.5360 | fpr=0.8876 | 7595.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=5.71440 | acc=0.1197 | tpr=0.5290 | fpr=0.8877 | 7937.2 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.71732 | acc=0.1206 | tpr=0.5345 | fpr=0.8869 | 7588.6 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.71103 | acc=0.1209 | tpr=0.5418 | fpr=0.8868 | 8403.0 samples/s | 32.8 steps/s
[Step= 350] | Loss=5.70236 | acc=0.1208 | tpr=0.5385 | fpr=0.8867 | 7439.9 samples/s | 29.1 steps/s
[Step= 400] | Loss=5.69850 | acc=0.1209 | tpr=0.5356 | fpr=0.8866 | 7988.4 samples/s | 31.2 steps/s
[Step= 450] | Loss=5.70232 | acc=0.1213 | tpr=0.5351 | fpr=0.8862 | 7792.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.70358 | acc=0.1213 | tpr=0.5295 | fpr=0.8861 | 7588.6 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.70680 | acc=0.1210 | tpr=0.5261 | fpr=0.8864 | 14379.6 samples/s | 56.2 steps/s
Avg test loss: 5.70898, Avg test acc: 0.12088, Avg tpr: 0.52615, Avg fpr: 0.88649, total FA: 123087

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.90243 | acc=0.1044 | tpr=0.4867 | fpr=0.9025 | 5007.2 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.87967 | acc=0.1050 | tpr=0.5032 | fpr=0.9025 | 6977.3 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.87915 | acc=0.1052 | tpr=0.5072 | fpr=0.9022 | 7281.8 samples/s | 28.4 steps/s
[Step= 200] | Loss=5.87261 | acc=0.1046 | tpr=0.4929 | fpr=0.9025 | 7958.7 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.87614 | acc=0.1049 | tpr=0.5031 | fpr=0.9023 | 7926.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.86986 | acc=0.1045 | tpr=0.5076 | fpr=0.9028 | 8045.8 samples/s | 31.4 steps/s
[Step= 350] | Loss=5.86399 | acc=0.1047 | tpr=0.5059 | fpr=0.9026 | 7668.8 samples/s | 30.0 steps/s
[Step= 400] | Loss=5.85979 | acc=0.1048 | tpr=0.5055 | fpr=0.9025 | 7707.6 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.86508 | acc=0.1048 | tpr=0.5054 | fpr=0.9024 | 8038.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.86854 | acc=0.1047 | tpr=0.5026 | fpr=0.9025 | 7856.7 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.87380 | acc=0.1044 | tpr=0.4978 | fpr=0.9027 | 13768.6 samples/s | 53.8 steps/s
Avg test loss: 5.87644, Avg test acc: 0.10433, Avg tpr: 0.49683, Avg fpr: 0.90280, total FA: 125352

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.09695 | acc=0.0956 | tpr=0.2920 | fpr=0.9079 | 4887.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.05748 | acc=0.0984 | tpr=0.3028 | fpr=0.9055 | 7056.3 samples/s | 27.6 steps/s
[Step= 150] | Loss=6.07109 | acc=0.0993 | tpr=0.3127 | fpr=0.9046 | 7595.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=6.06432 | acc=0.0998 | tpr=0.3038 | fpr=0.9039 | 7891.8 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.06337 | acc=0.1005 | tpr=0.3083 | fpr=0.9033 | 8035.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=6.05807 | acc=0.1009 | tpr=0.3171 | fpr=0.9030 | 7484.4 samples/s | 29.2 steps/s
[Step= 350] | Loss=6.05058 | acc=0.1014 | tpr=0.3156 | fpr=0.9025 | 8161.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.04592 | acc=0.1020 | tpr=0.3173 | fpr=0.9019 | 7950.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=6.05109 | acc=0.1021 | tpr=0.3111 | fpr=0.9017 | 7852.5 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.05277 | acc=0.1019 | tpr=0.3123 | fpr=0.9019 | 7889.4 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.05723 | acc=0.1017 | tpr=0.3132 | fpr=0.9021 | 13956.2 samples/s | 54.5 steps/s
Avg test loss: 6.05871, Avg test acc: 0.10157, Avg tpr: 0.31339, Avg fpr: 0.90228, total FA: 125280

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.84812 | acc=0.1094 | tpr=0.5442 | fpr=0.8984 | 4883.9 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.82027 | acc=0.1099 | tpr=0.5480 | fpr=0.8983 | 6818.9 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.83569 | acc=0.1092 | tpr=0.5548 | fpr=0.8990 | 7656.0 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.82554 | acc=0.1080 | tpr=0.5497 | fpr=0.9000 | 8240.5 samples/s | 32.2 steps/s
[Step= 250] | Loss=5.82811 | acc=0.1092 | tpr=0.5537 | fpr=0.8989 | 7869.1 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.82713 | acc=0.1092 | tpr=0.5556 | fpr=0.8989 | 7857.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.81680 | acc=0.1094 | tpr=0.5554 | fpr=0.8987 | 7744.3 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.81110 | acc=0.1095 | tpr=0.5503 | fpr=0.8985 | 7760.5 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.81802 | acc=0.1093 | tpr=0.5487 | fpr=0.8987 | 7673.4 samples/s | 30.0 steps/s
[Step= 500] | Loss=5.81919 | acc=0.1091 | tpr=0.5449 | fpr=0.8988 | 8084.4 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.82337 | acc=0.1089 | tpr=0.5396 | fpr=0.8990 | 14258.8 samples/s | 55.7 steps/s
Avg test loss: 5.82457, Avg test acc: 0.10875, Avg tpr: 0.53922, Avg fpr: 0.89908, total FA: 124835

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.22440 | acc=0.1140 | tpr=0.4602 | fpr=0.8922 | 4953.3 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.20223 | acc=0.1148 | tpr=0.4542 | fpr=0.8915 | 6862.3 samples/s | 26.8 steps/s
[Step= 150] | Loss=6.20116 | acc=0.1148 | tpr=0.4625 | fpr=0.8916 | 8213.9 samples/s | 32.1 steps/s
[Step= 200] | Loss=6.19782 | acc=0.1144 | tpr=0.4459 | fpr=0.8916 | 7441.3 samples/s | 29.1 steps/s
[Step= 250] | Loss=6.20117 | acc=0.1154 | tpr=0.4585 | fpr=0.8908 | 7797.3 samples/s | 30.5 steps/s
[Step= 300] | Loss=6.20275 | acc=0.1154 | tpr=0.4625 | fpr=0.8909 | 7701.2 samples/s | 30.1 steps/s
[Step= 350] | Loss=6.19286 | acc=0.1156 | tpr=0.4627 | fpr=0.8907 | 8048.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.18992 | acc=0.1158 | tpr=0.4617 | fpr=0.8905 | 7822.1 samples/s | 30.6 steps/s
[Step= 450] | Loss=6.19371 | acc=0.1160 | tpr=0.4620 | fpr=0.8903 | 8023.4 samples/s | 31.3 steps/s
[Step= 500] | Loss=6.19510 | acc=0.1160 | tpr=0.4595 | fpr=0.8902 | 7673.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.19925 | acc=0.1157 | tpr=0.4608 | fpr=0.8906 | 13853.3 samples/s | 54.1 steps/s
Avg test loss: 6.20152, Avg test acc: 0.11557, Avg tpr: 0.46038, Avg fpr: 0.89069, total FA: 123671

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.07444 | acc=0.9841 | tpr=0.9469 | fpr=0.0152 | 4600.0 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.07616 | acc=0.9839 | tpr=0.9488 | fpr=0.0154 | 7674.5 samples/s | 30.0 steps/s
[Step= 150] | Loss=0.07918 | acc=0.9832 | tpr=0.9496 | fpr=0.0162 | 7797.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.08064 | acc=0.9831 | tpr=0.9541 | fpr=0.0163 | 7819.5 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.07954 | acc=0.9835 | tpr=0.9493 | fpr=0.0159 | 8103.1 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.08148 | acc=0.9831 | tpr=0.9498 | fpr=0.0163 | 7856.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.08223 | acc=0.9827 | tpr=0.9487 | fpr=0.0166 | 8074.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.08320 | acc=0.9825 | tpr=0.9442 | fpr=0.0169 | 7415.7 samples/s | 29.0 steps/s
[Step= 450] | Loss=0.08495 | acc=0.9821 | tpr=0.9401 | fpr=0.0172 | 8314.8 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.08421 | acc=0.9822 | tpr=0.9405 | fpr=0.0171 | 7603.0 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.08383 | acc=0.9823 | tpr=0.9391 | fpr=0.0169 | 13886.7 samples/s | 54.2 steps/s
Avg test loss: 0.08373, Avg test acc: 0.98232, Avg tpr: 0.93899, Avg fpr: 0.01689, total FA: 2345

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08244 | acc=0.9823 | tpr=0.9292 | fpr=0.0168 | 4692.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.08522 | acc=0.9824 | tpr=0.9296 | fpr=0.0166 | 7085.4 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.08809 | acc=0.9819 | tpr=0.9294 | fpr=0.0171 | 8104.8 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.09005 | acc=0.9820 | tpr=0.9344 | fpr=0.0171 | 7387.7 samples/s | 28.9 steps/s
[Step= 250] | Loss=0.08850 | acc=0.9822 | tpr=0.9345 | fpr=0.0169 | 8011.8 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.09060 | acc=0.9819 | tpr=0.9338 | fpr=0.0172 | 8211.6 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.09119 | acc=0.9818 | tpr=0.9374 | fpr=0.0174 | 7647.4 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.09238 | acc=0.9815 | tpr=0.9327 | fpr=0.0176 | 7905.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.09441 | acc=0.9813 | tpr=0.9314 | fpr=0.0178 | 7783.8 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.09357 | acc=0.9813 | tpr=0.9335 | fpr=0.0178 | 8055.1 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.09335 | acc=0.9814 | tpr=0.9316 | fpr=0.0177 | 13880.3 samples/s | 54.2 steps/s
Avg test loss: 0.09328, Avg test acc: 0.98143, Avg tpr: 0.93185, Avg fpr: 0.01767, total FA: 2453

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08915 | acc=0.9812 | tpr=0.9602 | fpr=0.0185 | 4936.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.09095 | acc=0.9814 | tpr=0.9659 | fpr=0.0183 | 6876.3 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.09514 | acc=0.9806 | tpr=0.9611 | fpr=0.0191 | 7793.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.09636 | acc=0.9807 | tpr=0.9639 | fpr=0.0190 | 7797.4 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09463 | acc=0.9810 | tpr=0.9633 | fpr=0.0187 | 7731.4 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.09687 | acc=0.9805 | tpr=0.9585 | fpr=0.0191 | 7987.8 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09774 | acc=0.9801 | tpr=0.9606 | fpr=0.0195 | 7773.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.09877 | acc=0.9799 | tpr=0.9579 | fpr=0.0197 | 7542.3 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.10047 | acc=0.9797 | tpr=0.9572 | fpr=0.0199 | 8003.3 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.09988 | acc=0.9797 | tpr=0.9590 | fpr=0.0199 | 7889.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.09939 | acc=0.9798 | tpr=0.9578 | fpr=0.0198 | 13925.5 samples/s | 54.4 steps/s
Avg test loss: 0.09928, Avg test acc: 0.97983, Avg tpr: 0.95800, Avg fpr: 0.01977, total FA: 2745

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.08868 | acc=0.9810 | tpr=0.9469 | fpr=0.0184 | 5057.8 samples/s | 19.8 steps/s
[Step= 100] | Loss=0.09121 | acc=0.9812 | tpr=0.9510 | fpr=0.0182 | 6815.2 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.09491 | acc=0.9803 | tpr=0.9496 | fpr=0.0191 | 8046.7 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.09612 | acc=0.9806 | tpr=0.9541 | fpr=0.0190 | 7591.1 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.09482 | acc=0.9810 | tpr=0.9511 | fpr=0.0184 | 7799.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.09686 | acc=0.9808 | tpr=0.9476 | fpr=0.0186 | 7795.0 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.09752 | acc=0.9806 | tpr=0.9480 | fpr=0.0188 | 8023.4 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09814 | acc=0.9805 | tpr=0.9453 | fpr=0.0189 | 7520.4 samples/s | 29.4 steps/s
[Step= 450] | Loss=0.10006 | acc=0.9802 | tpr=0.9430 | fpr=0.0191 | 8218.9 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.09929 | acc=0.9803 | tpr=0.9445 | fpr=0.0191 | 7926.4 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.09889 | acc=0.9804 | tpr=0.9443 | fpr=0.0189 | 13473.0 samples/s | 52.6 steps/s
Avg test loss: 0.09871, Avg test acc: 0.98045, Avg tpr: 0.94453, Avg fpr: 0.01890, total FA: 2624

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08897 | acc=0.9817 | tpr=0.9425 | fpr=0.0176 | 4869.1 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09326 | acc=0.9810 | tpr=0.9424 | fpr=0.0183 | 6729.6 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.09613 | acc=0.9802 | tpr=0.9409 | fpr=0.0191 | 8144.7 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.09773 | acc=0.9801 | tpr=0.9464 | fpr=0.0193 | 8208.7 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.09609 | acc=0.9805 | tpr=0.9441 | fpr=0.0189 | 7195.8 samples/s | 28.1 steps/s
[Step= 300] | Loss=0.09828 | acc=0.9802 | tpr=0.9411 | fpr=0.0191 | 8036.5 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.09876 | acc=0.9800 | tpr=0.9418 | fpr=0.0193 | 7825.4 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.10004 | acc=0.9798 | tpr=0.9387 | fpr=0.0194 | 7744.1 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10209 | acc=0.9795 | tpr=0.9362 | fpr=0.0197 | 7764.7 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.10150 | acc=0.9795 | tpr=0.9361 | fpr=0.0197 | 7922.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.10117 | acc=0.9798 | tpr=0.9363 | fpr=0.0194 | 14316.8 samples/s | 55.9 steps/s
Avg test loss: 0.10101, Avg test acc: 0.97978, Avg tpr: 0.93582, Avg fpr: 0.01942, total FA: 2697

server round 36/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=351.1] | Loss=0.01088 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.116 | L2-Norm(final)=18.450 | 5635.0 samples/s | 88.0 steps/s
[Step=72050 Epoch=351.3] | Loss=0.00431 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=18.458 | 4253.4 samples/s | 66.5 steps/s
[Step=72100 Epoch=351.6] | Loss=0.00370 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=18.467 | 5024.1 samples/s | 78.5 steps/s
[Step=72150 Epoch=351.8] | Loss=0.00364 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=18.477 | 5066.0 samples/s | 79.2 steps/s
[Step=72200 Epoch=352.1] | Loss=0.00365 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=18.487 | 7833.3 samples/s | 122.4 steps/s
[Step=72250 Epoch=352.3] | Loss=0.00339 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=18.496 | 2183.5 samples/s | 34.1 steps/s
[Step=72300 Epoch=352.5] | Loss=0.00328 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=18.506 | 5044.8 samples/s | 78.8 steps/s
[Step=72350 Epoch=352.8] | Loss=0.00332 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.138 | L2-Norm(final)=18.515 | 5017.3 samples/s | 78.4 steps/s
[Step=72400 Epoch=353.0] | Loss=0.00337 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=18.524 | 6978.2 samples/s | 109.0 steps/s
[Step=72450 Epoch=353.3] | Loss=0.00329 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=18.533 | 2299.9 samples/s | 35.9 steps/s
[Step=72500 Epoch=353.5] | Loss=0.00324 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.145 | L2-Norm(final)=18.542 | 5105.2 samples/s | 79.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=353.5] | Loss=0.00052 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=18.629 | 5133.0 samples/s | 80.2 steps/s
[Step=72550 Epoch=353.8] | Loss=0.00364 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.171 | L2-Norm(final)=18.637 | 4149.3 samples/s | 64.8 steps/s
[Step=72600 Epoch=354.0] | Loss=0.00452 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=18.645 | 4465.1 samples/s | 69.8 steps/s
[Step=72650 Epoch=354.3] | Loss=0.00405 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=18.653 | 4413.5 samples/s | 69.0 steps/s
[Step=72700 Epoch=354.5] | Loss=0.00442 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=18.660 | 6492.1 samples/s | 101.4 steps/s
[Step=72750 Epoch=354.7] | Loss=0.00422 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.191 | L2-Norm(final)=18.667 | 2094.2 samples/s | 32.7 steps/s
[Step=72800 Epoch=355.0] | Loss=0.00387 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=18.674 | 4514.1 samples/s | 70.5 steps/s
[Step=72850 Epoch=355.2] | Loss=0.00384 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=18.680 | 4496.1 samples/s | 70.3 steps/s
[Step=72900 Epoch=355.5] | Loss=0.00400 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.199 | L2-Norm(final)=18.686 | 5887.5 samples/s | 92.0 steps/s
[Step=72950 Epoch=355.7] | Loss=0.00395 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=18.691 | 2151.0 samples/s | 33.6 steps/s
[Step=73000 Epoch=356.0] | Loss=0.00389 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=18.696 | 4475.3 samples/s | 69.9 steps/s
[Step=73050 Epoch=356.2] | Loss=0.00391 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=18.701 | 4450.0 samples/s | 69.5 steps/s
[Step=73100 Epoch=356.4] | Loss=0.00387 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=18.705 | 5439.9 samples/s | 85.0 steps/s
[Step=73150 Epoch=356.7] | Loss=0.00376 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=18.710 | 2260.8 samples/s | 35.3 steps/s
[Step=73200 Epoch=356.9] | Loss=0.00369 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.209 | L2-Norm(final)=18.714 | 4507.7 samples/s | 70.4 steps/s
[Step=73250 Epoch=357.2] | Loss=0.00361 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=18.718 | 4434.5 samples/s | 69.3 steps/s
[Step=73300 Epoch=357.4] | Loss=0.00352 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=18.723 | 4892.9 samples/s | 76.5 steps/s
[Step=73350 Epoch=357.7] | Loss=0.00340 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.211 | L2-Norm(final)=18.726 | 2309.9 samples/s | 36.1 steps/s
[Step=73400 Epoch=357.9] | Loss=0.00328 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=18.730 | 4505.1 samples/s | 70.4 steps/s
[Step=73450 Epoch=358.2] | Loss=0.00325 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.211 | L2-Norm(final)=18.734 | 4404.2 samples/s | 68.8 steps/s
[Step=73500 Epoch=358.4] | Loss=0.00324 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=18.738 | 4598.9 samples/s | 71.9 steps/s
[Step=73550 Epoch=358.6] | Loss=0.00323 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.211 | L2-Norm(final)=18.741 | 2453.0 samples/s | 38.3 steps/s
[Step=73600 Epoch=358.9] | Loss=0.00317 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=18.745 | 4483.3 samples/s | 70.1 steps/s
[Step=73650 Epoch=359.1] | Loss=0.00313 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=18.748 | 4366.9 samples/s | 68.2 steps/s
[Step=73700 Epoch=359.4] | Loss=0.00310 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=18.752 | 4438.7 samples/s | 69.4 steps/s
[Step=73750 Epoch=359.6] | Loss=0.00302 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.209 | L2-Norm(final)=18.755 | 2462.6 samples/s | 38.5 steps/s
[Step=73800 Epoch=359.9] | Loss=0.00301 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.209 | L2-Norm(final)=18.758 | 4537.6 samples/s | 70.9 steps/s
[Step=73850 Epoch=360.1] | Loss=0.00296 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=18.761 | 4458.5 samples/s | 69.7 steps/s
[Step=73900 Epoch=360.4] | Loss=0.00292 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=18.765 | 4434.6 samples/s | 69.3 steps/s
[Step=73950 Epoch=360.6] | Loss=0.00289 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.206 | L2-Norm(final)=18.768 | 2455.6 samples/s | 38.4 steps/s
[Step=74000 Epoch=360.8] | Loss=0.00286 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=18.771 | 4492.9 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step74000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=351.3] | Loss=0.00051 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=19.219 | 5226.4 samples/s | 81.7 steps/s
[Step=72050 Epoch=351.6] | Loss=0.00255 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=19.227 | 4536.6 samples/s | 70.9 steps/s
[Step=72100 Epoch=351.8] | Loss=0.00300 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=19.238 | 5096.2 samples/s | 79.6 steps/s
[Step=72150 Epoch=352.1] | Loss=0.00279 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=19.250 | 5033.7 samples/s | 78.7 steps/s
[Step=72200 Epoch=352.3] | Loss=0.00277 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=19.261 | 7920.9 samples/s | 123.8 steps/s
[Step=72250 Epoch=352.5] | Loss=0.00281 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=19.272 | 2235.0 samples/s | 34.9 steps/s
[Step=72300 Epoch=352.8] | Loss=0.00276 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.717 | L2-Norm(final)=19.283 | 5081.1 samples/s | 79.4 steps/s
[Step=72350 Epoch=353.0] | Loss=0.00263 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=19.293 | 4819.7 samples/s | 75.3 steps/s
[Step=72400 Epoch=353.3] | Loss=0.00267 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=19.304 | 7042.8 samples/s | 110.0 steps/s
[Step=72450 Epoch=353.5] | Loss=0.00265 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.724 | L2-Norm(final)=19.314 | 2292.6 samples/s | 35.8 steps/s
[Step=72500 Epoch=353.8] | Loss=0.00263 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=19.324 | 4967.8 samples/s | 77.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=353.8] | Loss=0.00054 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=19.423 | 4974.4 samples/s | 77.7 steps/s
[Step=72550 Epoch=354.0] | Loss=0.00385 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=19.432 | 4298.8 samples/s | 67.2 steps/s
[Step=72600 Epoch=354.3] | Loss=0.00527 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.759 | L2-Norm(final)=19.443 | 4455.3 samples/s | 69.6 steps/s
[Step=72650 Epoch=354.5] | Loss=0.00499 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=19.453 | 4481.1 samples/s | 70.0 steps/s
[Step=72700 Epoch=354.7] | Loss=0.00502 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=19.462 | 6439.6 samples/s | 100.6 steps/s
[Step=72750 Epoch=355.0] | Loss=0.00476 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=19.470 | 2063.8 samples/s | 32.2 steps/s
[Step=72800 Epoch=355.2] | Loss=0.00460 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.792 | L2-Norm(final)=19.478 | 4523.7 samples/s | 70.7 steps/s
[Step=72850 Epoch=355.5] | Loss=0.00479 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.797 | L2-Norm(final)=19.484 | 4441.6 samples/s | 69.4 steps/s
[Step=72900 Epoch=355.7] | Loss=0.00484 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.801 | L2-Norm(final)=19.490 | 6077.8 samples/s | 95.0 steps/s
[Step=72950 Epoch=356.0] | Loss=0.00459 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.805 | L2-Norm(final)=19.495 | 2175.2 samples/s | 34.0 steps/s
[Step=73000 Epoch=356.2] | Loss=0.00446 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.808 | L2-Norm(final)=19.501 | 4398.9 samples/s | 68.7 steps/s
[Step=73050 Epoch=356.5] | Loss=0.00422 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.811 | L2-Norm(final)=19.505 | 4418.1 samples/s | 69.0 steps/s
[Step=73100 Epoch=356.7] | Loss=0.00411 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.813 | L2-Norm(final)=19.510 | 5621.8 samples/s | 87.8 steps/s
[Step=73150 Epoch=356.9] | Loss=0.00403 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=19.514 | 2196.3 samples/s | 34.3 steps/s
[Step=73200 Epoch=357.2] | Loss=0.00387 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=19.519 | 4481.8 samples/s | 70.0 steps/s
[Step=73250 Epoch=357.4] | Loss=0.00374 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.818 | L2-Norm(final)=19.523 | 4518.9 samples/s | 70.6 steps/s
[Step=73300 Epoch=357.7] | Loss=0.00363 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.819 | L2-Norm(final)=19.527 | 5171.1 samples/s | 80.8 steps/s
[Step=73350 Epoch=357.9] | Loss=0.00349 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=19.530 | 2267.0 samples/s | 35.4 steps/s
[Step=73400 Epoch=358.2] | Loss=0.00339 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=19.534 | 4416.5 samples/s | 69.0 steps/s
[Step=73450 Epoch=358.4] | Loss=0.00332 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=19.537 | 4513.7 samples/s | 70.5 steps/s
[Step=73500 Epoch=358.6] | Loss=0.00323 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=19.541 | 4825.3 samples/s | 75.4 steps/s
[Step=73550 Epoch=358.9] | Loss=0.00315 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=19.544 | 2356.0 samples/s | 36.8 steps/s
[Step=73600 Epoch=359.1] | Loss=0.00307 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=19.547 | 4493.8 samples/s | 70.2 steps/s
[Step=73650 Epoch=359.4] | Loss=0.00298 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=19.551 | 4480.6 samples/s | 70.0 steps/s
[Step=73700 Epoch=359.6] | Loss=0.00293 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=19.554 | 4545.1 samples/s | 71.0 steps/s
[Step=73750 Epoch=359.9] | Loss=0.00288 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=19.557 | 2399.1 samples/s | 37.5 steps/s
[Step=73800 Epoch=360.1] | Loss=0.00285 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.819 | L2-Norm(final)=19.560 | 4405.4 samples/s | 68.8 steps/s
[Step=73850 Epoch=360.4] | Loss=0.00286 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.819 | L2-Norm(final)=19.563 | 4570.5 samples/s | 71.4 steps/s
[Step=73900 Epoch=360.6] | Loss=0.00280 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.818 | L2-Norm(final)=19.565 | 4412.6 samples/s | 68.9 steps/s
[Step=73950 Epoch=360.8] | Loss=0.00275 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=19.568 | 2463.3 samples/s | 38.5 steps/s
[Step=74000 Epoch=361.1] | Loss=0.00273 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=19.571 | 4403.7 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step74000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=350.8] | Loss=0.00353 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=19.355 | 5078.7 samples/s | 79.4 steps/s
[Step=72050 Epoch=351.1] | Loss=0.00309 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.489 | L2-Norm(final)=19.362 | 4502.6 samples/s | 70.4 steps/s
[Step=72100 Epoch=351.3] | Loss=0.00379 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=19.371 | 5118.8 samples/s | 80.0 steps/s
[Step=72150 Epoch=351.5] | Loss=0.00361 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=19.381 | 4981.0 samples/s | 77.8 steps/s
[Step=72200 Epoch=351.8] | Loss=0.00362 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.498 | L2-Norm(final)=19.390 | 7864.6 samples/s | 122.9 steps/s
[Step=72250 Epoch=352.0] | Loss=0.00344 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.500 | L2-Norm(final)=19.399 | 2259.5 samples/s | 35.3 steps/s
[Step=72300 Epoch=352.3] | Loss=0.00337 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=19.407 | 4907.2 samples/s | 76.7 steps/s
[Step=72350 Epoch=352.5] | Loss=0.00334 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=19.416 | 5014.4 samples/s | 78.4 steps/s
[Step=72400 Epoch=352.8] | Loss=0.00338 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=19.425 | 6979.3 samples/s | 109.1 steps/s
[Step=72450 Epoch=353.0] | Loss=0.00333 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.509 | L2-Norm(final)=19.433 | 2268.3 samples/s | 35.4 steps/s
[Step=72500 Epoch=353.3] | Loss=0.00324 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=19.442 | 5074.7 samples/s | 79.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=353.3] | Loss=0.00204 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=19.529 | 6114.5 samples/s | 95.5 steps/s
[Step=72550 Epoch=353.5] | Loss=0.00315 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=19.536 | 3758.9 samples/s | 58.7 steps/s
[Step=72600 Epoch=353.7] | Loss=0.00442 | Reg=0.00241 | acc=0.9531 | L2-Norm=15.540 | L2-Norm(final)=19.544 | 4481.9 samples/s | 70.0 steps/s
[Step=72650 Epoch=354.0] | Loss=0.00506 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=19.553 | 4447.7 samples/s | 69.5 steps/s
[Step=72700 Epoch=354.2] | Loss=0.00562 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=19.560 | 6586.4 samples/s | 102.9 steps/s
[Step=72750 Epoch=354.5] | Loss=0.00540 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.561 | L2-Norm(final)=19.568 | 2083.5 samples/s | 32.6 steps/s
[Step=72800 Epoch=354.7] | Loss=0.00532 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=19.574 | 4502.1 samples/s | 70.3 steps/s
[Step=72850 Epoch=355.0] | Loss=0.00501 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=19.580 | 4436.9 samples/s | 69.3 steps/s
[Step=72900 Epoch=355.2] | Loss=0.00500 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.574 | L2-Norm(final)=19.586 | 5943.1 samples/s | 92.9 steps/s
[Step=72950 Epoch=355.4] | Loss=0.00478 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.577 | L2-Norm(final)=19.591 | 2187.9 samples/s | 34.2 steps/s
[Step=73000 Epoch=355.7] | Loss=0.00452 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=19.596 | 4386.3 samples/s | 68.5 steps/s
[Step=73050 Epoch=355.9] | Loss=0.00441 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=19.600 | 4519.9 samples/s | 70.6 steps/s
[Step=73100 Epoch=356.2] | Loss=0.00432 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=19.605 | 5284.0 samples/s | 82.6 steps/s
[Step=73150 Epoch=356.4] | Loss=0.00417 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=19.609 | 2238.9 samples/s | 35.0 steps/s
[Step=73200 Epoch=356.7] | Loss=0.00404 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=19.613 | 4421.4 samples/s | 69.1 steps/s
[Step=73250 Epoch=356.9] | Loss=0.00391 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=19.616 | 4454.5 samples/s | 69.6 steps/s
[Step=73300 Epoch=357.2] | Loss=0.00382 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=19.620 | 4933.9 samples/s | 77.1 steps/s
[Step=73350 Epoch=357.4] | Loss=0.00371 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=19.624 | 2319.6 samples/s | 36.2 steps/s
[Step=73400 Epoch=357.6] | Loss=0.00361 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=19.627 | 4579.0 samples/s | 71.5 steps/s
[Step=73450 Epoch=357.9] | Loss=0.00355 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=19.631 | 4279.1 samples/s | 66.9 steps/s
[Step=73500 Epoch=358.1] | Loss=0.00348 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=19.634 | 4596.2 samples/s | 71.8 steps/s
[Step=73550 Epoch=358.4] | Loss=0.00342 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=19.637 | 2417.9 samples/s | 37.8 steps/s
[Step=73600 Epoch=358.6] | Loss=0.00334 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=19.640 | 4475.1 samples/s | 69.9 steps/s
[Step=73650 Epoch=358.9] | Loss=0.00332 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=19.643 | 4480.5 samples/s | 70.0 steps/s
[Step=73700 Epoch=359.1] | Loss=0.00324 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=19.647 | 4492.4 samples/s | 70.2 steps/s
[Step=73750 Epoch=359.3] | Loss=0.00322 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=19.650 | 2476.6 samples/s | 38.7 steps/s
[Step=73800 Epoch=359.6] | Loss=0.00314 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=19.653 | 4301.4 samples/s | 67.2 steps/s
[Step=73850 Epoch=359.8] | Loss=0.00310 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=19.656 | 4473.0 samples/s | 69.9 steps/s
[Step=73900 Epoch=360.1] | Loss=0.00306 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=19.659 | 4504.5 samples/s | 70.4 steps/s
[Step=73950 Epoch=360.3] | Loss=0.00300 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=19.662 | 2458.4 samples/s | 38.4 steps/s
[Step=74000 Epoch=360.6] | Loss=0.00296 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.586 | L2-Norm(final)=19.664 | 4551.6 samples/s | 71.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step74000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=351.1] | Loss=0.00416 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=19.352 | 5638.8 samples/s | 88.1 steps/s
[Step=72050 Epoch=351.4] | Loss=0.00320 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=19.359 | 4365.7 samples/s | 68.2 steps/s
[Step=72100 Epoch=351.6] | Loss=0.00328 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=19.370 | 4928.4 samples/s | 77.0 steps/s
[Step=72150 Epoch=351.8] | Loss=0.00312 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=19.382 | 4921.0 samples/s | 76.9 steps/s
[Step=72200 Epoch=352.1] | Loss=0.00309 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=19.393 | 7704.9 samples/s | 120.4 steps/s
[Step=72250 Epoch=352.3] | Loss=0.00302 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=19.403 | 2213.1 samples/s | 34.6 steps/s
[Step=72300 Epoch=352.6] | Loss=0.00293 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=19.414 | 5056.6 samples/s | 79.0 steps/s
[Step=72350 Epoch=352.8] | Loss=0.00288 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=19.424 | 5023.9 samples/s | 78.5 steps/s
[Step=72400 Epoch=353.1] | Loss=0.00283 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=19.434 | 6984.3 samples/s | 109.1 steps/s
[Step=72450 Epoch=353.3] | Loss=0.00274 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=19.444 | 2311.1 samples/s | 36.1 steps/s
[Step=72500 Epoch=353.6] | Loss=0.00275 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=19.454 | 4934.4 samples/s | 77.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=353.6] | Loss=0.00057 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=19.552 | 5335.4 samples/s | 83.4 steps/s
[Step=72550 Epoch=353.8] | Loss=0.00355 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=19.560 | 4293.8 samples/s | 67.1 steps/s
[Step=72600 Epoch=354.0] | Loss=0.00397 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.219 | L2-Norm(final)=19.570 | 4355.8 samples/s | 68.1 steps/s
[Step=72650 Epoch=354.3] | Loss=0.00472 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.226 | L2-Norm(final)=19.578 | 4467.6 samples/s | 69.8 steps/s
[Step=72700 Epoch=354.5] | Loss=0.00461 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.232 | L2-Norm(final)=19.586 | 6601.0 samples/s | 103.1 steps/s
[Step=72750 Epoch=354.8] | Loss=0.00451 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=19.594 | 2091.3 samples/s | 32.7 steps/s
[Step=72800 Epoch=355.0] | Loss=0.00455 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=19.601 | 4434.4 samples/s | 69.3 steps/s
[Step=72850 Epoch=355.3] | Loss=0.00450 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.247 | L2-Norm(final)=19.608 | 4385.2 samples/s | 68.5 steps/s
[Step=72900 Epoch=355.5] | Loss=0.00423 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=19.614 | 5803.9 samples/s | 90.7 steps/s
[Step=72950 Epoch=355.7] | Loss=0.00396 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.253 | L2-Norm(final)=19.619 | 2191.8 samples/s | 34.2 steps/s
[Step=73000 Epoch=356.0] | Loss=0.00377 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.255 | L2-Norm(final)=19.625 | 4272.9 samples/s | 66.8 steps/s
[Step=73050 Epoch=356.2] | Loss=0.00356 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=19.630 | 4398.9 samples/s | 68.7 steps/s
[Step=73100 Epoch=356.5] | Loss=0.00349 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=19.635 | 5156.4 samples/s | 80.6 steps/s
[Step=73150 Epoch=356.7] | Loss=0.00337 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=19.640 | 2231.5 samples/s | 34.9 steps/s
[Step=73200 Epoch=357.0] | Loss=0.00327 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=19.644 | 4417.7 samples/s | 69.0 steps/s
[Step=73250 Epoch=357.2] | Loss=0.00319 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.649 | 4432.7 samples/s | 69.3 steps/s
[Step=73300 Epoch=357.5] | Loss=0.00306 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.653 | 4944.3 samples/s | 77.3 steps/s
[Step=73350 Epoch=357.7] | Loss=0.00301 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.262 | L2-Norm(final)=19.657 | 2355.2 samples/s | 36.8 steps/s
[Step=73400 Epoch=357.9] | Loss=0.00292 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=19.661 | 4481.7 samples/s | 70.0 steps/s
[Step=73450 Epoch=358.2] | Loss=0.00287 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=19.664 | 4411.1 samples/s | 68.9 steps/s
[Step=73500 Epoch=358.4] | Loss=0.00280 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.668 | 4620.7 samples/s | 72.2 steps/s
[Step=73550 Epoch=358.7] | Loss=0.00285 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.261 | L2-Norm(final)=19.671 | 2386.7 samples/s | 37.3 steps/s
[Step=73600 Epoch=358.9] | Loss=0.00285 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.675 | 4460.9 samples/s | 69.7 steps/s
[Step=73650 Epoch=359.2] | Loss=0.00285 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.678 | 4455.6 samples/s | 69.6 steps/s
[Step=73700 Epoch=359.4] | Loss=0.00277 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=19.682 | 4444.5 samples/s | 69.4 steps/s
[Step=73750 Epoch=359.6] | Loss=0.00274 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=19.685 | 2479.5 samples/s | 38.7 steps/s
[Step=73800 Epoch=359.9] | Loss=0.00269 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=19.689 | 4393.3 samples/s | 68.6 steps/s
[Step=73850 Epoch=360.1] | Loss=0.00266 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=19.692 | 4434.3 samples/s | 69.3 steps/s
[Step=73900 Epoch=360.4] | Loss=0.00266 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=19.696 | 4378.9 samples/s | 68.4 steps/s
[Step=73950 Epoch=360.6] | Loss=0.00262 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=19.699 | 2484.0 samples/s | 38.8 steps/s
[Step=74000 Epoch=360.9] | Loss=0.00258 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=19.702 | 4369.0 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step74000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=353.1] | Loss=0.00592 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.889 | L2-Norm(final)=19.412 | 5476.7 samples/s | 85.6 steps/s
[Step=72050 Epoch=353.3] | Loss=0.00280 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.892 | L2-Norm(final)=19.420 | 4475.7 samples/s | 69.9 steps/s
[Step=72100 Epoch=353.6] | Loss=0.00300 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.896 | L2-Norm(final)=19.430 | 5058.1 samples/s | 79.0 steps/s
[Step=72150 Epoch=353.8] | Loss=0.00270 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.899 | L2-Norm(final)=19.439 | 4900.4 samples/s | 76.6 steps/s
[Step=72200 Epoch=354.1] | Loss=0.00289 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=19.449 | 8008.4 samples/s | 125.1 steps/s
[Step=72250 Epoch=354.3] | Loss=0.00281 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.905 | L2-Norm(final)=19.459 | 2192.7 samples/s | 34.3 steps/s
[Step=72300 Epoch=354.5] | Loss=0.00271 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.907 | L2-Norm(final)=19.468 | 4748.8 samples/s | 74.2 steps/s
[Step=72350 Epoch=354.8] | Loss=0.00270 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.910 | L2-Norm(final)=19.477 | 5104.7 samples/s | 79.8 steps/s
[Step=72400 Epoch=355.0] | Loss=0.00269 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.912 | L2-Norm(final)=19.486 | 7285.4 samples/s | 113.8 steps/s
[Step=72450 Epoch=355.3] | Loss=0.00267 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=19.495 | 2250.5 samples/s | 35.2 steps/s
[Step=72500 Epoch=355.5] | Loss=0.00269 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=19.504 | 5063.2 samples/s | 79.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=355.5] | Loss=0.00080 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=19.593 | 5624.8 samples/s | 87.9 steps/s
[Step=72550 Epoch=355.8] | Loss=0.00296 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=19.601 | 3865.7 samples/s | 60.4 steps/s
[Step=72600 Epoch=356.0] | Loss=0.00319 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.945 | L2-Norm(final)=19.610 | 4485.9 samples/s | 70.1 steps/s
[Step=72650 Epoch=356.3] | Loss=0.00342 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.951 | L2-Norm(final)=19.618 | 4466.7 samples/s | 69.8 steps/s
[Step=72700 Epoch=356.5] | Loss=0.00364 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.957 | L2-Norm(final)=19.626 | 6596.2 samples/s | 103.1 steps/s
[Step=72750 Epoch=356.8] | Loss=0.00430 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=19.634 | 2087.6 samples/s | 32.6 steps/s
[Step=72800 Epoch=357.0] | Loss=0.00421 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=19.641 | 4346.0 samples/s | 67.9 steps/s
[Step=72850 Epoch=357.2] | Loss=0.00400 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.971 | L2-Norm(final)=19.648 | 4599.7 samples/s | 71.9 steps/s
[Step=72900 Epoch=357.5] | Loss=0.00389 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=19.654 | 5998.1 samples/s | 93.7 steps/s
[Step=72950 Epoch=357.7] | Loss=0.00375 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=19.659 | 2071.6 samples/s | 32.4 steps/s
[Step=73000 Epoch=358.0] | Loss=0.00354 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.979 | L2-Norm(final)=19.665 | 4531.3 samples/s | 70.8 steps/s
[Step=73050 Epoch=358.2] | Loss=0.00345 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=19.670 | 4397.6 samples/s | 68.7 steps/s
[Step=73100 Epoch=358.5] | Loss=0.00330 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=19.675 | 5821.3 samples/s | 91.0 steps/s
[Step=73150 Epoch=358.7] | Loss=0.00318 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.983 | L2-Norm(final)=19.679 | 2162.5 samples/s | 33.8 steps/s
[Step=73200 Epoch=359.0] | Loss=0.00312 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=19.684 | 4447.5 samples/s | 69.5 steps/s
[Step=73250 Epoch=359.2] | Loss=0.00303 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=19.688 | 4413.5 samples/s | 69.0 steps/s
[Step=73300 Epoch=359.5] | Loss=0.00298 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=19.692 | 5429.2 samples/s | 84.8 steps/s
[Step=73350 Epoch=359.7] | Loss=0.00296 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=19.696 | 2202.0 samples/s | 34.4 steps/s
[Step=73400 Epoch=359.9] | Loss=0.00287 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=19.700 | 4452.7 samples/s | 69.6 steps/s
[Step=73450 Epoch=360.2] | Loss=0.00286 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=19.704 | 4443.6 samples/s | 69.4 steps/s
[Step=73500 Epoch=360.4] | Loss=0.00279 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=19.708 | 5216.8 samples/s | 81.5 steps/s
[Step=73550 Epoch=360.7] | Loss=0.00279 | Reg=0.00225 | acc=0.9688 | L2-Norm=14.986 | L2-Norm(final)=19.711 | 2300.8 samples/s | 36.0 steps/s
[Step=73600 Epoch=360.9] | Loss=0.00272 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=19.715 | 4354.9 samples/s | 68.0 steps/s
[Step=73650 Epoch=361.2] | Loss=0.00266 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.986 | L2-Norm(final)=19.719 | 4421.2 samples/s | 69.1 steps/s
[Step=73700 Epoch=361.4] | Loss=0.00264 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=19.722 | 4931.3 samples/s | 77.1 steps/s
[Step=73750 Epoch=361.7] | Loss=0.00260 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=19.726 | 2316.6 samples/s | 36.2 steps/s
[Step=73800 Epoch=361.9] | Loss=0.00253 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=19.729 | 4463.9 samples/s | 69.7 steps/s
[Step=73850 Epoch=362.1] | Loss=0.00251 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=19.732 | 4545.7 samples/s | 71.0 steps/s
[Step=73900 Epoch=362.4] | Loss=0.00248 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=19.736 | 4597.6 samples/s | 71.8 steps/s
[Step=73950 Epoch=362.6] | Loss=0.00245 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=19.739 | 2375.1 samples/s | 37.1 steps/s
[Step=74000 Epoch=362.9] | Loss=0.00240 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=19.742 | 4481.1 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step74000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=682.3] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.445 | L2-Norm(final)=9.765 | 5675.8 samples/s | 88.7 steps/s
[Step=72050 Epoch=682.7] | Loss=0.00012 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=9.792 | 4026.1 samples/s | 62.9 steps/s
[Step=72100 Epoch=683.2] | Loss=0.00010 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.476 | L2-Norm(final)=9.816 | 7385.4 samples/s | 115.4 steps/s
[Step=72150 Epoch=683.7] | Loss=0.00008 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.486 | L2-Norm(final)=9.833 | 2111.0 samples/s | 33.0 steps/s
[Step=72200 Epoch=684.2] | Loss=0.00007 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=9.846 | 6519.8 samples/s | 101.9 steps/s
[Step=72250 Epoch=684.6] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.498 | L2-Norm(final)=9.857 | 2201.8 samples/s | 34.4 steps/s
[Step=72300 Epoch=685.1] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.502 | L2-Norm(final)=9.866 | 5920.6 samples/s | 92.5 steps/s
[Step=72350 Epoch=685.6] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.506 | L2-Norm(final)=9.875 | 2304.9 samples/s | 36.0 steps/s
[Step=72400 Epoch=686.1] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.508 | L2-Norm(final)=9.883 | 5290.4 samples/s | 82.7 steps/s
[Step=72450 Epoch=686.5] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.511 | L2-Norm(final)=9.891 | 2392.8 samples/s | 37.4 steps/s
[Step=72500 Epoch=687.0] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.514 | L2-Norm(final)=9.898 | 4819.9 samples/s | 75.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=687.0] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.536 | L2-Norm(final)=9.971 | 5461.4 samples/s | 85.3 steps/s
[Step=72550 Epoch=687.5] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.527 | L2-Norm(final)=9.976 | 3695.7 samples/s | 57.7 steps/s
[Step=72600 Epoch=687.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.509 | L2-Norm(final)=9.979 | 6182.7 samples/s | 96.6 steps/s
[Step=72650 Epoch=688.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.487 | L2-Norm(final)=9.981 | 2020.6 samples/s | 31.6 steps/s
[Step=72700 Epoch=688.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.462 | L2-Norm(final)=9.983 | 5599.2 samples/s | 87.5 steps/s
[Step=72750 Epoch=689.4] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.436 | L2-Norm(final)=9.984 | 2120.1 samples/s | 33.1 steps/s
[Step=72800 Epoch=689.8] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.410 | L2-Norm(final)=9.984 | 5102.0 samples/s | 79.7 steps/s
[Step=72850 Epoch=690.3] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.383 | L2-Norm(final)=9.985 | 2184.5 samples/s | 34.1 steps/s
[Step=72900 Epoch=690.8] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.356 | L2-Norm(final)=9.986 | 4667.4 samples/s | 72.9 steps/s
[Step=72950 Epoch=691.3] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=9.987 | 1734.1 samples/s | 27.1 steps/s
[Step=73000 Epoch=691.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.301 | L2-Norm(final)=9.987 | 4299.1 samples/s | 67.2 steps/s
[Step=73050 Epoch=692.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.274 | L2-Norm(final)=9.988 | 2326.1 samples/s | 36.3 steps/s
[Step=73100 Epoch=692.7] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.246 | L2-Norm(final)=9.989 | 4285.7 samples/s | 67.0 steps/s
[Step=73150 Epoch=693.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=9.989 | 2316.2 samples/s | 36.2 steps/s
[Step=73200 Epoch=693.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.191 | L2-Norm(final)=9.990 | 4261.8 samples/s | 66.6 steps/s
[Step=73250 Epoch=694.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.164 | L2-Norm(final)=9.991 | 2416.1 samples/s | 37.8 steps/s
[Step=73300 Epoch=694.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=9.992 | 4257.8 samples/s | 66.5 steps/s
[Step=73350 Epoch=695.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.109 | L2-Norm(final)=9.992 | 2447.0 samples/s | 38.2 steps/s
[Step=73400 Epoch=695.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.081 | L2-Norm(final)=9.993 | 3923.9 samples/s | 61.3 steps/s
[Step=73450 Epoch=696.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.053 | L2-Norm(final)=9.994 | 6548.9 samples/s | 102.3 steps/s
[Step=73500 Epoch=696.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.026 | L2-Norm(final)=9.995 | 1999.5 samples/s | 31.2 steps/s
[Step=73550 Epoch=696.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=9.996 | 5871.1 samples/s | 91.7 steps/s
[Step=73600 Epoch=697.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.971 | L2-Norm(final)=9.997 | 2081.5 samples/s | 32.5 steps/s
[Step=73650 Epoch=697.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.943 | L2-Norm(final)=9.998 | 5245.7 samples/s | 82.0 steps/s
[Step=73700 Epoch=698.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.916 | L2-Norm(final)=10.000 | 2116.3 samples/s | 33.1 steps/s
[Step=73750 Epoch=698.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.888 | L2-Norm(final)=10.001 | 4856.9 samples/s | 75.9 steps/s
[Step=73800 Epoch=699.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.861 | L2-Norm(final)=10.002 | 2268.0 samples/s | 35.4 steps/s
[Step=73850 Epoch=699.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.833 | L2-Norm(final)=10.003 | 4348.4 samples/s | 67.9 steps/s
[Step=73900 Epoch=700.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.806 | L2-Norm(final)=10.005 | 2362.6 samples/s | 36.9 steps/s
[Step=73950 Epoch=700.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=10.006 | 4109.3 samples/s | 64.2 steps/s
[Step=74000 Epoch=701.2] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.752 | L2-Norm(final)=10.007 | 2341.0 samples/s | 36.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step74000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=684.9] | Loss=0.00008 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.473 | L2-Norm(final)=10.571 | 5454.1 samples/s | 85.2 steps/s
[Step=72050 Epoch=685.4] | Loss=0.00009 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.483 | L2-Norm(final)=10.590 | 4123.5 samples/s | 64.4 steps/s
[Step=72100 Epoch=685.9] | Loss=0.00007 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=10.610 | 7559.2 samples/s | 118.1 steps/s
[Step=72150 Epoch=686.3] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.500 | L2-Norm(final)=10.626 | 2185.8 samples/s | 34.2 steps/s
[Step=72200 Epoch=686.8] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.505 | L2-Norm(final)=10.639 | 6247.0 samples/s | 97.6 steps/s
[Step=72250 Epoch=687.3] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.509 | L2-Norm(final)=10.650 | 2179.7 samples/s | 34.1 steps/s
[Step=72300 Epoch=687.8] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.512 | L2-Norm(final)=10.661 | 5929.1 samples/s | 92.6 steps/s
[Step=72350 Epoch=688.2] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.515 | L2-Norm(final)=10.671 | 2313.5 samples/s | 36.1 steps/s
[Step=72400 Epoch=688.7] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.518 | L2-Norm(final)=10.680 | 5349.5 samples/s | 83.6 steps/s
[Step=72450 Epoch=689.2] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.521 | L2-Norm(final)=10.689 | 2402.6 samples/s | 37.5 steps/s
[Step=72500 Epoch=689.7] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.523 | L2-Norm(final)=10.698 | 4922.0 samples/s | 76.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=689.7] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.544 | L2-Norm(final)=10.783 | 5630.2 samples/s | 88.0 steps/s
[Step=72550 Epoch=690.1] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.534 | L2-Norm(final)=10.789 | 3571.8 samples/s | 55.8 steps/s
[Step=72600 Epoch=690.6] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.521 | L2-Norm(final)=10.794 | 6315.2 samples/s | 98.7 steps/s
[Step=72650 Epoch=691.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.514 | L2-Norm(final)=10.800 | 2023.4 samples/s | 31.6 steps/s
[Step=72700 Epoch=691.6] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.511 | L2-Norm(final)=10.807 | 5675.8 samples/s | 88.7 steps/s
[Step=72750 Epoch=692.0] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.506 | L2-Norm(final)=10.812 | 2089.1 samples/s | 32.6 steps/s
[Step=72800 Epoch=692.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.499 | L2-Norm(final)=10.815 | 5181.5 samples/s | 81.0 steps/s
[Step=72850 Epoch=693.0] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.492 | L2-Norm(final)=10.818 | 2143.1 samples/s | 33.5 steps/s
[Step=72900 Epoch=693.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.483 | L2-Norm(final)=10.820 | 4741.0 samples/s | 74.1 steps/s
[Step=72950 Epoch=693.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.474 | L2-Norm(final)=10.822 | 2267.6 samples/s | 35.4 steps/s
[Step=73000 Epoch=694.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.823 | 4379.6 samples/s | 68.4 steps/s
[Step=73050 Epoch=694.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.454 | L2-Norm(final)=10.825 | 2367.2 samples/s | 37.0 steps/s
[Step=73100 Epoch=695.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.444 | L2-Norm(final)=10.826 | 4223.4 samples/s | 66.0 steps/s
[Step=73150 Epoch=695.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.434 | L2-Norm(final)=10.828 | 2375.0 samples/s | 37.1 steps/s
[Step=73200 Epoch=696.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.423 | L2-Norm(final)=10.829 | 4185.1 samples/s | 65.4 steps/s
[Step=73250 Epoch=696.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.412 | L2-Norm(final)=10.830 | 2408.7 samples/s | 37.6 steps/s
[Step=73300 Epoch=697.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.401 | L2-Norm(final)=10.831 | 4190.1 samples/s | 65.5 steps/s
[Step=73350 Epoch=697.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.390 | L2-Norm(final)=10.832 | 2456.2 samples/s | 38.4 steps/s
[Step=73400 Epoch=698.2] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.379 | L2-Norm(final)=10.833 | 4196.9 samples/s | 65.6 steps/s
[Step=73450 Epoch=698.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.367 | L2-Norm(final)=10.834 | 6234.4 samples/s | 97.4 steps/s
[Step=73500 Epoch=699.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.356 | L2-Norm(final)=10.836 | 1976.2 samples/s | 30.9 steps/s
[Step=73550 Epoch=699.6] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=10.837 | 5861.2 samples/s | 91.6 steps/s
[Step=73600 Epoch=700.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=10.838 | 2109.0 samples/s | 33.0 steps/s
[Step=73650 Epoch=700.6] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.321 | L2-Norm(final)=10.839 | 5150.7 samples/s | 80.5 steps/s
[Step=73700 Epoch=701.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.309 | L2-Norm(final)=10.840 | 2131.9 samples/s | 33.3 steps/s
[Step=73750 Epoch=701.5] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.297 | L2-Norm(final)=10.841 | 4811.3 samples/s | 75.2 steps/s
[Step=73800 Epoch=702.0] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.284 | L2-Norm(final)=10.843 | 2251.4 samples/s | 35.2 steps/s
[Step=73850 Epoch=702.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=10.844 | 4329.8 samples/s | 67.7 steps/s
[Step=73900 Epoch=703.0] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=10.845 | 2331.7 samples/s | 36.4 steps/s
[Step=73950 Epoch=703.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.247 | L2-Norm(final)=10.847 | 4274.1 samples/s | 66.8 steps/s
[Step=74000 Epoch=703.9] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.235 | L2-Norm(final)=10.848 | 2404.5 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step74000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=687.6] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.487 | L2-Norm(final)=10.352 | 5225.2 samples/s | 81.6 steps/s
[Step=72050 Epoch=688.0] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.487 | L2-Norm(final)=10.354 | 4152.5 samples/s | 64.9 steps/s
[Step=72100 Epoch=688.5] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.488 | L2-Norm(final)=10.358 | 7607.5 samples/s | 118.9 steps/s
[Step=72150 Epoch=689.0] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.489 | L2-Norm(final)=10.362 | 2119.3 samples/s | 33.1 steps/s
[Step=72200 Epoch=689.5] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.490 | L2-Norm(final)=10.365 | 6902.8 samples/s | 107.9 steps/s
[Step=72250 Epoch=689.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.491 | L2-Norm(final)=10.369 | 2194.1 samples/s | 34.3 steps/s
[Step=72300 Epoch=690.4] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.492 | L2-Norm(final)=10.372 | 6081.0 samples/s | 95.0 steps/s
[Step=72350 Epoch=690.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=10.376 | 2249.6 samples/s | 35.1 steps/s
[Step=72400 Epoch=691.4] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=10.379 | 5741.7 samples/s | 89.7 steps/s
[Step=72450 Epoch=691.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.494 | L2-Norm(final)=10.383 | 2393.7 samples/s | 37.4 steps/s
[Step=72500 Epoch=692.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.495 | L2-Norm(final)=10.386 | 5091.7 samples/s | 79.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=692.3] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.502 | L2-Norm(final)=10.420 | 5838.3 samples/s | 91.2 steps/s
[Step=72550 Epoch=692.8] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.501 | L2-Norm(final)=10.423 | 3532.2 samples/s | 55.2 steps/s
[Step=72600 Epoch=693.3] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.498 | L2-Norm(final)=10.426 | 6183.2 samples/s | 96.6 steps/s
[Step=72650 Epoch=693.8] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.495 | L2-Norm(final)=10.428 | 1974.3 samples/s | 30.8 steps/s
[Step=72700 Epoch=694.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.492 | L2-Norm(final)=10.429 | 5819.7 samples/s | 90.9 steps/s
[Step=72750 Epoch=694.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.487 | L2-Norm(final)=10.431 | 2070.2 samples/s | 32.3 steps/s
[Step=72800 Epoch=695.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.483 | L2-Norm(final)=10.432 | 5318.7 samples/s | 83.1 steps/s
[Step=72850 Epoch=695.7] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.478 | L2-Norm(final)=10.433 | 2140.6 samples/s | 33.4 steps/s
[Step=72900 Epoch=696.2] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.473 | L2-Norm(final)=10.434 | 4900.8 samples/s | 76.6 steps/s
[Step=72950 Epoch=696.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.469 | L2-Norm(final)=10.435 | 2213.9 samples/s | 34.6 steps/s
[Step=73000 Epoch=697.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.436 | 4585.6 samples/s | 71.7 steps/s
[Step=73050 Epoch=697.6] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.459 | L2-Norm(final)=10.437 | 2280.3 samples/s | 35.6 steps/s
[Step=73100 Epoch=698.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.438 | 4354.9 samples/s | 68.0 steps/s
[Step=73150 Epoch=698.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.448 | L2-Norm(final)=10.439 | 2363.6 samples/s | 36.9 steps/s
[Step=73200 Epoch=699.0] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.443 | L2-Norm(final)=10.440 | 4161.7 samples/s | 65.0 steps/s
[Step=73250 Epoch=699.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.437 | L2-Norm(final)=10.441 | 2384.9 samples/s | 37.3 steps/s
[Step=73300 Epoch=700.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.432 | L2-Norm(final)=10.442 | 4251.7 samples/s | 66.4 steps/s
[Step=73350 Epoch=700.4] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.426 | L2-Norm(final)=10.443 | 2404.6 samples/s | 37.6 steps/s
[Step=73400 Epoch=700.9] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.420 | L2-Norm(final)=10.444 | 4181.5 samples/s | 65.3 steps/s
[Step=73450 Epoch=701.4] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.414 | L2-Norm(final)=10.445 | 2368.9 samples/s | 37.0 steps/s
[Step=73500 Epoch=701.9] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.409 | L2-Norm(final)=10.446 | 4306.7 samples/s | 67.3 steps/s
[Step=73550 Epoch=702.4] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.403 | L2-Norm(final)=10.447 | 6887.5 samples/s | 107.6 steps/s
[Step=73600 Epoch=702.8] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.396 | L2-Norm(final)=10.448 | 1944.5 samples/s | 30.4 steps/s
[Step=73650 Epoch=703.3] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.390 | L2-Norm(final)=10.449 | 6305.5 samples/s | 98.5 steps/s
[Step=73700 Epoch=703.8] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.384 | L2-Norm(final)=10.450 | 2006.9 samples/s | 31.4 steps/s
[Step=73750 Epoch=704.3] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.378 | L2-Norm(final)=10.451 | 5579.4 samples/s | 87.2 steps/s
[Step=73800 Epoch=704.7] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.371 | L2-Norm(final)=10.452 | 1962.2 samples/s | 30.7 steps/s
[Step=73850 Epoch=705.2] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.365 | L2-Norm(final)=10.453 | 5337.9 samples/s | 83.4 steps/s
[Step=73900 Epoch=705.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.358 | L2-Norm(final)=10.454 | 2156.5 samples/s | 33.7 steps/s
[Step=73950 Epoch=706.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.352 | L2-Norm(final)=10.455 | 4861.7 samples/s | 76.0 steps/s
[Step=74000 Epoch=706.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.456 | 2201.6 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step74000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=678.5] | Loss=0.00013 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.576 | L2-Norm(final)=10.247 | 5173.6 samples/s | 80.8 steps/s
[Step=72050 Epoch=678.9] | Loss=0.00013 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.585 | L2-Norm(final)=10.264 | 4154.4 samples/s | 64.9 steps/s
[Step=72100 Epoch=679.4] | Loss=0.00012 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.597 | L2-Norm(final)=10.283 | 7381.3 samples/s | 115.3 steps/s
[Step=72150 Epoch=679.9] | Loss=0.00009 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.604 | L2-Norm(final)=10.295 | 2165.4 samples/s | 33.8 steps/s
[Step=72200 Epoch=680.3] | Loss=0.00008 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.610 | L2-Norm(final)=10.305 | 6258.9 samples/s | 97.8 steps/s
[Step=72250 Epoch=680.8] | Loss=0.00008 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.614 | L2-Norm(final)=10.314 | 2223.4 samples/s | 34.7 steps/s
[Step=72300 Epoch=681.3] | Loss=0.00007 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.619 | L2-Norm(final)=10.322 | 5599.0 samples/s | 87.5 steps/s
[Step=72350 Epoch=681.7] | Loss=0.00006 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.622 | L2-Norm(final)=10.330 | 2348.1 samples/s | 36.7 steps/s
[Step=72400 Epoch=682.2] | Loss=0.00006 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.625 | L2-Norm(final)=10.336 | 4994.2 samples/s | 78.0 steps/s
[Step=72450 Epoch=682.7] | Loss=0.00006 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.628 | L2-Norm(final)=10.343 | 2465.8 samples/s | 38.5 steps/s
[Step=72500 Epoch=683.2] | Loss=0.00005 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.630 | L2-Norm(final)=10.348 | 4676.1 samples/s | 73.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=683.2] | Loss=0.00018 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.651 | L2-Norm(final)=10.404 | 5244.8 samples/s | 82.0 steps/s
[Step=72550 Epoch=683.6] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.652 | L2-Norm(final)=10.409 | 3787.6 samples/s | 59.2 steps/s
[Step=72600 Epoch=684.1] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.648 | L2-Norm(final)=10.413 | 6195.2 samples/s | 96.8 steps/s
[Step=72650 Epoch=684.6] | Loss=0.00019 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.655 | L2-Norm(final)=10.418 | 1991.2 samples/s | 31.1 steps/s
[Step=72700 Epoch=685.0] | Loss=0.00017 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.662 | L2-Norm(final)=10.423 | 5518.3 samples/s | 86.2 steps/s
[Step=72750 Epoch=685.5] | Loss=0.00014 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.668 | L2-Norm(final)=10.428 | 2097.9 samples/s | 32.8 steps/s
[Step=72800 Epoch=686.0] | Loss=0.00012 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.671 | L2-Norm(final)=10.431 | 4950.1 samples/s | 77.3 steps/s
[Step=72850 Epoch=686.5] | Loss=0.00010 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.673 | L2-Norm(final)=10.433 | 2229.3 samples/s | 34.8 steps/s
[Step=72900 Epoch=686.9] | Loss=0.00009 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.435 | 4442.4 samples/s | 69.4 steps/s
[Step=72950 Epoch=687.4] | Loss=0.00008 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.436 | 2299.8 samples/s | 35.9 steps/s
[Step=73000 Epoch=687.9] | Loss=0.00007 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.676 | L2-Norm(final)=10.437 | 4263.1 samples/s | 66.6 steps/s
[Step=73050 Epoch=688.3] | Loss=0.00007 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.676 | L2-Norm(final)=10.438 | 2382.0 samples/s | 37.2 steps/s
[Step=73100 Epoch=688.8] | Loss=0.00006 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.439 | 4374.5 samples/s | 68.4 steps/s
[Step=73150 Epoch=689.3] | Loss=0.00006 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.440 | 2684.2 samples/s | 41.9 steps/s
[Step=73200 Epoch=689.8] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.675 | L2-Norm(final)=10.441 | 3444.2 samples/s | 53.8 steps/s
[Step=73250 Epoch=690.2] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.674 | L2-Norm(final)=10.442 | 2601.0 samples/s | 40.6 steps/s
[Step=73300 Epoch=690.7] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.673 | L2-Norm(final)=10.443 | 3679.9 samples/s | 57.5 steps/s
[Step=73350 Epoch=691.2] | Loss=0.00005 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.673 | L2-Norm(final)=10.443 | 6175.9 samples/s | 96.5 steps/s
[Step=73400 Epoch=691.6] | Loss=0.00004 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.672 | L2-Norm(final)=10.444 | 2031.3 samples/s | 31.7 steps/s
[Step=73450 Epoch=692.1] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.671 | L2-Norm(final)=10.444 | 5551.0 samples/s | 86.7 steps/s
[Step=73500 Epoch=692.6] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.670 | L2-Norm(final)=10.445 | 2126.6 samples/s | 33.2 steps/s
[Step=73550 Epoch=693.1] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.669 | L2-Norm(final)=10.445 | 4879.5 samples/s | 76.2 steps/s
[Step=73600 Epoch=693.5] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.667 | L2-Norm(final)=10.446 | 2231.6 samples/s | 34.9 steps/s
[Step=73650 Epoch=694.0] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.666 | L2-Norm(final)=10.446 | 4443.4 samples/s | 69.4 steps/s
[Step=73700 Epoch=694.5] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.665 | L2-Norm(final)=10.447 | 2306.0 samples/s | 36.0 steps/s
[Step=73750 Epoch=694.9] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.664 | L2-Norm(final)=10.447 | 4231.8 samples/s | 66.1 steps/s
[Step=73800 Epoch=695.4] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.662 | L2-Norm(final)=10.448 | 2388.7 samples/s | 37.3 steps/s
[Step=73850 Epoch=695.9] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.661 | L2-Norm(final)=10.448 | 4251.4 samples/s | 66.4 steps/s
[Step=73900 Epoch=696.3] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.660 | L2-Norm(final)=10.449 | 2393.2 samples/s | 37.4 steps/s
[Step=73950 Epoch=696.8] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.658 | L2-Norm(final)=10.449 | 4239.5 samples/s | 66.2 steps/s
[Step=74000 Epoch=697.3] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.657 | L2-Norm(final)=10.449 | 2691.6 samples/s | 42.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step74000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=686.2] | Loss=0.00009 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.516 | L2-Norm(final)=10.807 | 5174.3 samples/s | 80.8 steps/s
[Step=72050 Epoch=686.7] | Loss=0.00010 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.529 | L2-Norm(final)=10.830 | 3925.9 samples/s | 61.3 steps/s
[Step=72100 Epoch=687.2] | Loss=0.00008 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.540 | L2-Norm(final)=10.847 | 7600.5 samples/s | 118.8 steps/s
[Step=72150 Epoch=687.7] | Loss=0.00006 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.546 | L2-Norm(final)=10.861 | 2163.0 samples/s | 33.8 steps/s
[Step=72200 Epoch=688.1] | Loss=0.00006 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.551 | L2-Norm(final)=10.872 | 6264.7 samples/s | 97.9 steps/s
[Step=72250 Epoch=688.6] | Loss=0.00005 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.554 | L2-Norm(final)=10.881 | 2172.2 samples/s | 33.9 steps/s
[Step=72300 Epoch=689.1] | Loss=0.00005 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.557 | L2-Norm(final)=10.890 | 6175.1 samples/s | 96.5 steps/s
[Step=72350 Epoch=689.6] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.560 | L2-Norm(final)=10.899 | 2236.3 samples/s | 34.9 steps/s
[Step=72400 Epoch=690.0] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.562 | L2-Norm(final)=10.907 | 5656.7 samples/s | 88.4 steps/s
[Step=72450 Epoch=690.5] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.564 | L2-Norm(final)=10.915 | 2378.4 samples/s | 37.2 steps/s
[Step=72500 Epoch=691.0] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.566 | L2-Norm(final)=10.922 | 5113.8 samples/s | 79.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=691.0] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.585 | L2-Norm(final)=10.997 | 5275.5 samples/s | 82.4 steps/s
[Step=72550 Epoch=691.5] | Loss=0.00023 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.586 | L2-Norm(final)=11.005 | 3731.3 samples/s | 58.3 steps/s
[Step=72600 Epoch=691.9] | Loss=0.00013 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.601 | L2-Norm(final)=11.012 | 6372.0 samples/s | 99.6 steps/s
[Step=72650 Epoch=692.4] | Loss=0.00009 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.605 | L2-Norm(final)=11.015 | 2024.6 samples/s | 31.6 steps/s
[Step=72700 Epoch=692.9] | Loss=0.00007 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.606 | L2-Norm(final)=11.017 | 5664.5 samples/s | 88.5 steps/s
[Step=72750 Epoch=693.4] | Loss=0.00006 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.605 | L2-Norm(final)=11.018 | 2076.9 samples/s | 32.5 steps/s
[Step=72800 Epoch=693.8] | Loss=0.00005 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.603 | L2-Norm(final)=11.019 | 5313.0 samples/s | 83.0 steps/s
[Step=72850 Epoch=694.3] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.601 | L2-Norm(final)=11.020 | 2086.8 samples/s | 32.6 steps/s
[Step=72900 Epoch=694.8] | Loss=0.00004 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.599 | L2-Norm(final)=11.021 | 4981.3 samples/s | 77.8 steps/s
[Step=72950 Epoch=695.3] | Loss=0.00003 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.596 | L2-Norm(final)=11.022 | 2160.0 samples/s | 33.7 steps/s
[Step=73000 Epoch=695.8] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.593 | L2-Norm(final)=11.022 | 4548.0 samples/s | 71.1 steps/s
[Step=73050 Epoch=696.2] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.590 | L2-Norm(final)=11.023 | 2277.4 samples/s | 35.6 steps/s
[Step=73100 Epoch=696.7] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.587 | L2-Norm(final)=11.024 | 4348.0 samples/s | 67.9 steps/s
[Step=73150 Epoch=697.2] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.584 | L2-Norm(final)=11.024 | 2343.2 samples/s | 36.6 steps/s
[Step=73200 Epoch=697.7] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.580 | L2-Norm(final)=11.025 | 4160.2 samples/s | 65.0 steps/s
[Step=73250 Epoch=698.1] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.577 | L2-Norm(final)=11.025 | 2339.5 samples/s | 36.6 steps/s
[Step=73300 Epoch=698.6] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.573 | L2-Norm(final)=11.025 | 4253.0 samples/s | 66.5 steps/s
[Step=73350 Epoch=699.1] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.570 | L2-Norm(final)=11.026 | 2376.1 samples/s | 37.1 steps/s
[Step=73400 Epoch=699.6] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.566 | L2-Norm(final)=11.026 | 4264.6 samples/s | 66.6 steps/s
[Step=73450 Epoch=700.0] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.562 | L2-Norm(final)=11.027 | 2361.2 samples/s | 36.9 steps/s
[Step=73500 Epoch=700.5] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.559 | L2-Norm(final)=11.027 | 4104.8 samples/s | 64.1 steps/s
[Step=73550 Epoch=701.0] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.555 | L2-Norm(final)=11.028 | 7012.6 samples/s | 109.6 steps/s
[Step=73600 Epoch=701.5] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.551 | L2-Norm(final)=11.028 | 1963.0 samples/s | 30.7 steps/s
[Step=73650 Epoch=702.0] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.547 | L2-Norm(final)=11.028 | 6277.2 samples/s | 98.1 steps/s
[Step=73700 Epoch=702.4] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.543 | L2-Norm(final)=11.029 | 2002.6 samples/s | 31.3 steps/s
[Step=73750 Epoch=702.9] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.539 | L2-Norm(final)=11.029 | 5800.6 samples/s | 90.6 steps/s
[Step=73800 Epoch=703.4] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.534 | L2-Norm(final)=11.030 | 2027.7 samples/s | 31.7 steps/s
[Step=73850 Epoch=703.9] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.530 | L2-Norm(final)=11.030 | 5344.8 samples/s | 83.5 steps/s
[Step=73900 Epoch=704.3] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.526 | L2-Norm(final)=11.030 | 2111.7 samples/s | 33.0 steps/s
[Step=73950 Epoch=704.8] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.521 | L2-Norm(final)=11.031 | 4798.6 samples/s | 75.0 steps/s
[Step=74000 Epoch=705.3] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.517 | L2-Norm(final)=11.031 | 2206.0 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10628 | acc=0.9573 | tpr=0.9701 | fpr=0.0704 | 4653.0 samples/s | 18.2 steps/s
Avg test loss: 0.11106, Avg test acc: 0.95581, Avg tpr: 0.96864, Avg fpr: 0.07243, total FA: 565

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11692 | acc=0.9567 | tpr=0.9757 | fpr=0.0845 | 4822.7 samples/s | 18.8 steps/s
Avg test loss: 0.11671, Avg test acc: 0.95597, Avg tpr: 0.97441, Avg fpr: 0.08460, total FA: 660

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10867 | acc=0.9572 | tpr=0.9718 | fpr=0.0746 | 4796.3 samples/s | 18.7 steps/s
Avg test loss: 0.11135, Avg test acc: 0.95593, Avg tpr: 0.96987, Avg fpr: 0.07473, total FA: 583

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10369 | acc=0.9595 | tpr=0.9706 | fpr=0.0644 | 4823.8 samples/s | 18.8 steps/s
Avg test loss: 0.10851, Avg test acc: 0.95749, Avg tpr: 0.97016, Avg fpr: 0.07038, total FA: 549

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11135 | acc=0.9586 | tpr=0.9731 | fpr=0.0728 | 4890.4 samples/s | 19.1 steps/s
Avg test loss: 0.11641, Avg test acc: 0.95765, Avg tpr: 0.97249, Avg fpr: 0.07499, total FA: 585

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.37673 | acc=0.3043 | tpr=0.0046 | fpr=0.0448 | 4942.1 samples/s | 19.3 steps/s
Avg test loss: 5.38710, Avg test acc: 0.30287, Avg tpr: 0.00560, Avg fpr: 0.04333, total FA: 338

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.87785 | acc=0.3020 | tpr=0.0034 | fpr=0.0496 | 4856.9 samples/s | 19.0 steps/s
Avg test loss: 4.89584, Avg test acc: 0.29910, Avg tpr: 0.00379, Avg fpr: 0.05140, total FA: 401

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.25382 | acc=0.2891 | tpr=0.0130 | fpr=0.1115 | 5071.5 samples/s | 19.8 steps/s
Avg test loss: 5.25400, Avg test acc: 0.28788, Avg tpr: 0.01475, Avg fpr: 0.11140, total FA: 869

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=6.09181 | acc=0.3007 | tpr=0.0128 | fpr=0.0741 | 4891.7 samples/s | 19.1 steps/s
Avg test loss: 6.09522, Avg test acc: 0.29918, Avg tpr: 0.01399, Avg fpr: 0.07358, total FA: 574

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.99000 | acc=0.3058 | tpr=0.0137 | fpr=0.0600 | 4850.1 samples/s | 18.9 steps/s
Avg test loss: 4.99845, Avg test acc: 0.30371, Avg tpr: 0.01463, Avg fpr: 0.06051, total FA: 472

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.97688 | acc=0.1004 | tpr=0.6018 | fpr=0.9086 | 4973.1 samples/s | 19.4 steps/s
[Step= 100] | Loss=5.94352 | acc=0.1035 | tpr=0.5970 | fpr=0.9057 | 6999.2 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.95558 | acc=0.1033 | tpr=0.5980 | fpr=0.9058 | 7362.6 samples/s | 28.8 steps/s
[Step= 200] | Loss=5.94873 | acc=0.1029 | tpr=0.5902 | fpr=0.9060 | 8064.0 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.95059 | acc=0.1039 | tpr=0.6000 | fpr=0.9052 | 8072.1 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.94489 | acc=0.1039 | tpr=0.6058 | fpr=0.9052 | 7613.2 samples/s | 29.7 steps/s
[Step= 350] | Loss=5.93689 | acc=0.1040 | tpr=0.6024 | fpr=0.9051 | 7958.3 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.93398 | acc=0.1041 | tpr=0.5996 | fpr=0.9049 | 7795.8 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.93860 | acc=0.1045 | tpr=0.5983 | fpr=0.9044 | 7899.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.94028 | acc=0.1045 | tpr=0.5960 | fpr=0.9044 | 7971.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.94262 | acc=0.1042 | tpr=0.5925 | fpr=0.9046 | 13753.7 samples/s | 53.7 steps/s
Avg test loss: 5.94461, Avg test acc: 0.10415, Avg tpr: 0.59231, Avg fpr: 0.90472, total FA: 125619

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.91738 | acc=0.0881 | tpr=0.5221 | fpr=0.9197 | 4918.1 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.89863 | acc=0.0886 | tpr=0.5352 | fpr=0.9197 | 6705.0 samples/s | 26.2 steps/s
[Step= 150] | Loss=5.89883 | acc=0.0893 | tpr=0.5360 | fpr=0.9190 | 7823.0 samples/s | 30.6 steps/s
[Step= 200] | Loss=5.88873 | acc=0.0883 | tpr=0.5311 | fpr=0.9198 | 8303.6 samples/s | 32.4 steps/s
[Step= 250] | Loss=5.89230 | acc=0.0884 | tpr=0.5345 | fpr=0.9197 | 7523.0 samples/s | 29.4 steps/s
[Step= 300] | Loss=5.88702 | acc=0.0880 | tpr=0.5360 | fpr=0.9201 | 7874.1 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.88108 | acc=0.0882 | tpr=0.5360 | fpr=0.9199 | 7710.7 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.87602 | acc=0.0884 | tpr=0.5356 | fpr=0.9197 | 7948.6 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.88110 | acc=0.0884 | tpr=0.5341 | fpr=0.9197 | 7800.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=5.88394 | acc=0.0883 | tpr=0.5291 | fpr=0.9196 | 8196.2 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.88919 | acc=0.0881 | tpr=0.5265 | fpr=0.9199 | 13418.0 samples/s | 52.4 steps/s
Avg test loss: 5.89169, Avg test acc: 0.08804, Avg tpr: 0.52536, Avg fpr: 0.91991, total FA: 127727

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.98971 | acc=0.0884 | tpr=0.3540 | fpr=0.9164 | 4686.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.95292 | acc=0.0907 | tpr=0.3454 | fpr=0.9140 | 7577.4 samples/s | 29.6 steps/s
[Step= 150] | Loss=5.96557 | acc=0.0916 | tpr=0.3530 | fpr=0.9132 | 7823.2 samples/s | 30.6 steps/s
[Step= 200] | Loss=5.95737 | acc=0.0921 | tpr=0.3530 | fpr=0.9127 | 7272.4 samples/s | 28.4 steps/s
[Step= 250] | Loss=5.95658 | acc=0.0931 | tpr=0.3598 | fpr=0.9118 | 8068.7 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.95247 | acc=0.0935 | tpr=0.3673 | fpr=0.9115 | 7883.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.94602 | acc=0.0937 | tpr=0.3669 | fpr=0.9113 | 7953.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.94181 | acc=0.0939 | tpr=0.3660 | fpr=0.9110 | 7546.0 samples/s | 29.5 steps/s
[Step= 450] | Loss=5.94709 | acc=0.0938 | tpr=0.3612 | fpr=0.9110 | 7635.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=5.94793 | acc=0.0935 | tpr=0.3639 | fpr=0.9113 | 8344.8 samples/s | 32.6 steps/s
[Step= 550] | Loss=5.95181 | acc=0.0932 | tpr=0.3645 | fpr=0.9117 | 13933.3 samples/s | 54.4 steps/s
Avg test loss: 5.95320, Avg test acc: 0.09311, Avg tpr: 0.36490, Avg fpr: 0.91183, total FA: 126606

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.83422 | acc=0.1084 | tpr=0.5265 | fpr=0.8992 | 4938.3 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.81236 | acc=0.1079 | tpr=0.5224 | fpr=0.8999 | 6550.7 samples/s | 25.6 steps/s
[Step= 150] | Loss=5.82505 | acc=0.1064 | tpr=0.5303 | fpr=0.9014 | 8701.5 samples/s | 34.0 steps/s
[Step= 200] | Loss=5.81474 | acc=0.1057 | tpr=0.5268 | fpr=0.9020 | 7028.8 samples/s | 27.5 steps/s
[Step= 250] | Loss=5.82078 | acc=0.1066 | tpr=0.5284 | fpr=0.9011 | 7778.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.81826 | acc=0.1068 | tpr=0.5338 | fpr=0.9010 | 8155.8 samples/s | 31.9 steps/s
[Step= 350] | Loss=5.80897 | acc=0.1068 | tpr=0.5348 | fpr=0.9009 | 7824.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.80341 | acc=0.1069 | tpr=0.5301 | fpr=0.9008 | 7878.6 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.80882 | acc=0.1069 | tpr=0.5273 | fpr=0.9007 | 8107.0 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.80911 | acc=0.1068 | tpr=0.5220 | fpr=0.9007 | 7796.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.81495 | acc=0.1065 | tpr=0.5161 | fpr=0.9009 | 13576.6 samples/s | 53.0 steps/s
Avg test loss: 5.81621, Avg test acc: 0.10639, Avg tpr: 0.51585, Avg fpr: 0.90106, total FA: 125110

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.29716 | acc=0.1057 | tpr=0.5133 | fpr=0.9016 | 4675.1 samples/s | 18.3 steps/s
[Step= 100] | Loss=6.27116 | acc=0.1071 | tpr=0.5032 | fpr=0.9002 | 7504.1 samples/s | 29.3 steps/s
[Step= 150] | Loss=6.27093 | acc=0.1071 | tpr=0.5072 | fpr=0.9003 | 7287.8 samples/s | 28.5 steps/s
[Step= 200] | Loss=6.26829 | acc=0.1068 | tpr=0.4984 | fpr=0.9003 | 8227.8 samples/s | 32.1 steps/s
[Step= 250] | Loss=6.27172 | acc=0.1078 | tpr=0.5100 | fpr=0.8995 | 7620.0 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.27264 | acc=0.1076 | tpr=0.5113 | fpr=0.8997 | 7957.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.26301 | acc=0.1079 | tpr=0.5085 | fpr=0.8994 | 8094.2 samples/s | 31.6 steps/s
[Step= 400] | Loss=6.26084 | acc=0.1078 | tpr=0.5077 | fpr=0.8995 | 7754.9 samples/s | 30.3 steps/s
[Step= 450] | Loss=6.26522 | acc=0.1082 | tpr=0.5063 | fpr=0.8990 | 7836.8 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.26705 | acc=0.1081 | tpr=0.5031 | fpr=0.8990 | 7891.7 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.27154 | acc=0.1077 | tpr=0.5022 | fpr=0.8995 | 14019.1 samples/s | 54.8 steps/s
Avg test loss: 6.27363, Avg test acc: 0.10757, Avg tpr: 0.50158, Avg fpr: 0.89959, total FA: 124906

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08232 | acc=0.9830 | tpr=0.9558 | fpr=0.0165 | 4880.2 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08400 | acc=0.9828 | tpr=0.9552 | fpr=0.0167 | 6943.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.08750 | acc=0.9819 | tpr=0.9582 | fpr=0.0177 | 7858.9 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.08954 | acc=0.9820 | tpr=0.9617 | fpr=0.0176 | 7695.0 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.08833 | acc=0.9823 | tpr=0.9563 | fpr=0.0173 | 8007.2 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.09009 | acc=0.9820 | tpr=0.9556 | fpr=0.0175 | 7771.4 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.09085 | acc=0.9817 | tpr=0.9549 | fpr=0.0178 | 7738.1 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09181 | acc=0.9814 | tpr=0.9497 | fpr=0.0181 | 8052.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.09376 | acc=0.9809 | tpr=0.9460 | fpr=0.0184 | 7961.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09306 | acc=0.9810 | tpr=0.9458 | fpr=0.0183 | 7775.5 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.09255 | acc=0.9812 | tpr=0.9435 | fpr=0.0182 | 13741.1 samples/s | 53.7 steps/s
Avg test loss: 0.09244, Avg test acc: 0.98118, Avg tpr: 0.94374, Avg fpr: 0.01814, total FA: 2519

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07849 | acc=0.9831 | tpr=0.9071 | fpr=0.0155 | 4788.1 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.08140 | acc=0.9830 | tpr=0.9126 | fpr=0.0157 | 7257.1 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.08459 | acc=0.9827 | tpr=0.9193 | fpr=0.0161 | 7675.7 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.08657 | acc=0.9827 | tpr=0.9213 | fpr=0.0162 | 7877.3 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.08537 | acc=0.9831 | tpr=0.9231 | fpr=0.0158 | 7468.8 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.08737 | acc=0.9829 | tpr=0.9222 | fpr=0.0160 | 8224.4 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.08802 | acc=0.9827 | tpr=0.9236 | fpr=0.0163 | 8024.2 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.08914 | acc=0.9825 | tpr=0.9190 | fpr=0.0163 | 7697.0 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.09116 | acc=0.9822 | tpr=0.9182 | fpr=0.0166 | 7953.1 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09042 | acc=0.9824 | tpr=0.9207 | fpr=0.0165 | 7557.4 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.09028 | acc=0.9824 | tpr=0.9168 | fpr=0.0164 | 14745.3 samples/s | 57.6 steps/s
Avg test loss: 0.09021, Avg test acc: 0.98244, Avg tpr: 0.91719, Avg fpr: 0.01638, total FA: 2274

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08646 | acc=0.9810 | tpr=0.9602 | fpr=0.0186 | 4945.7 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.08821 | acc=0.9813 | tpr=0.9680 | fpr=0.0185 | 6733.8 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.09250 | acc=0.9803 | tpr=0.9625 | fpr=0.0193 | 7749.5 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.09372 | acc=0.9805 | tpr=0.9683 | fpr=0.0193 | 7666.1 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.09212 | acc=0.9808 | tpr=0.9677 | fpr=0.0189 | 8137.2 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.09428 | acc=0.9804 | tpr=0.9629 | fpr=0.0193 | 7925.3 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09510 | acc=0.9801 | tpr=0.9643 | fpr=0.0196 | 7726.7 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09611 | acc=0.9799 | tpr=0.9617 | fpr=0.0198 | 8183.9 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.09771 | acc=0.9797 | tpr=0.9606 | fpr=0.0200 | 7719.1 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.09715 | acc=0.9797 | tpr=0.9621 | fpr=0.0200 | 7711.4 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.09674 | acc=0.9798 | tpr=0.9610 | fpr=0.0198 | 14555.3 samples/s | 56.9 steps/s
Avg test loss: 0.09663, Avg test acc: 0.97985, Avg tpr: 0.96117, Avg fpr: 0.01981, total FA: 2751

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.08791 | acc=0.9823 | tpr=0.9425 | fpr=0.0170 | 4841.1 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.08976 | acc=0.9818 | tpr=0.9446 | fpr=0.0175 | 6914.9 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.09296 | acc=0.9808 | tpr=0.9380 | fpr=0.0184 | 7975.9 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.09415 | acc=0.9811 | tpr=0.9475 | fpr=0.0183 | 7680.2 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.09309 | acc=0.9815 | tpr=0.9459 | fpr=0.0179 | 8022.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.09511 | acc=0.9813 | tpr=0.9469 | fpr=0.0181 | 8295.3 samples/s | 32.4 steps/s
[Step= 350] | Loss=0.09620 | acc=0.9810 | tpr=0.9474 | fpr=0.0184 | 7443.7 samples/s | 29.1 steps/s
[Step= 400] | Loss=0.09670 | acc=0.9809 | tpr=0.9464 | fpr=0.0185 | 7647.6 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.09862 | acc=0.9806 | tpr=0.9430 | fpr=0.0187 | 7974.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.09793 | acc=0.9808 | tpr=0.9449 | fpr=0.0186 | 7805.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.09758 | acc=0.9809 | tpr=0.9443 | fpr=0.0184 | 14084.9 samples/s | 55.0 steps/s
Avg test loss: 0.09738, Avg test acc: 0.98095, Avg tpr: 0.94453, Avg fpr: 0.01839, total FA: 2553

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09159 | acc=0.9818 | tpr=0.9115 | fpr=0.0169 | 4686.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.09692 | acc=0.9811 | tpr=0.9147 | fpr=0.0177 | 7272.5 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.09945 | acc=0.9804 | tpr=0.9164 | fpr=0.0184 | 8099.9 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.10098 | acc=0.9804 | tpr=0.9279 | fpr=0.0186 | 7604.1 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.09951 | acc=0.9808 | tpr=0.9266 | fpr=0.0182 | 7782.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.10203 | acc=0.9804 | tpr=0.9229 | fpr=0.0185 | 7528.0 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.10259 | acc=0.9802 | tpr=0.9236 | fpr=0.0187 | 8301.8 samples/s | 32.4 steps/s
[Step= 400] | Loss=0.10391 | acc=0.9800 | tpr=0.9218 | fpr=0.0189 | 8207.5 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.10600 | acc=0.9797 | tpr=0.9197 | fpr=0.0192 | 7717.0 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.10541 | acc=0.9797 | tpr=0.9203 | fpr=0.0192 | 7708.0 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.10511 | acc=0.9799 | tpr=0.9196 | fpr=0.0190 | 14058.0 samples/s | 54.9 steps/s
Avg test loss: 0.10496, Avg test acc: 0.97993, Avg tpr: 0.91918, Avg fpr: 0.01897, total FA: 2634

server round 37/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=360.8] | Loss=0.00648 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=18.864 | 5233.8 samples/s | 81.8 steps/s
[Step=74050 Epoch=361.1] | Loss=0.00443 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=18.872 | 4520.0 samples/s | 70.6 steps/s
[Step=74100 Epoch=361.3] | Loss=0.00440 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=18.885 | 5032.6 samples/s | 78.6 steps/s
[Step=74150 Epoch=361.6] | Loss=0.00438 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=18.897 | 4993.3 samples/s | 78.0 steps/s
[Step=74200 Epoch=361.8] | Loss=0.00415 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=18.909 | 7901.1 samples/s | 123.5 steps/s
[Step=74250 Epoch=362.1] | Loss=0.00404 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.043 | L2-Norm(final)=18.920 | 2220.6 samples/s | 34.7 steps/s
[Step=74300 Epoch=362.3] | Loss=0.00394 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=18.931 | 4876.2 samples/s | 76.2 steps/s
[Step=74350 Epoch=362.5] | Loss=0.00400 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.051 | L2-Norm(final)=18.942 | 5042.7 samples/s | 78.8 steps/s
[Step=74400 Epoch=362.8] | Loss=0.00389 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.055 | L2-Norm(final)=18.953 | 6909.0 samples/s | 108.0 steps/s
[Step=74450 Epoch=363.0] | Loss=0.00390 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=18.963 | 2294.7 samples/s | 35.9 steps/s
[Step=74500 Epoch=363.3] | Loss=0.00381 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=18.973 | 5034.1 samples/s | 78.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=363.3] | Loss=0.00253 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=19.074 | 5564.0 samples/s | 86.9 steps/s
[Step=74550 Epoch=363.5] | Loss=0.00507 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=19.083 | 4089.5 samples/s | 63.9 steps/s
[Step=74600 Epoch=363.8] | Loss=0.00573 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=19.092 | 4385.4 samples/s | 68.5 steps/s
[Step=74650 Epoch=364.0] | Loss=0.00585 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=19.101 | 4409.4 samples/s | 68.9 steps/s
[Step=74700 Epoch=364.3] | Loss=0.00629 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=19.109 | 6532.8 samples/s | 102.1 steps/s
[Step=74750 Epoch=364.5] | Loss=0.00604 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.131 | L2-Norm(final)=19.116 | 2122.0 samples/s | 33.2 steps/s
[Step=74800 Epoch=364.7] | Loss=0.00607 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=19.123 | 4320.0 samples/s | 67.5 steps/s
[Step=74850 Epoch=365.0] | Loss=0.00593 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=19.129 | 4474.6 samples/s | 69.9 steps/s
[Step=74900 Epoch=365.2] | Loss=0.00560 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=19.135 | 5876.1 samples/s | 91.8 steps/s
[Step=74950 Epoch=365.5] | Loss=0.00529 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=19.140 | 2146.5 samples/s | 33.5 steps/s
[Step=75000 Epoch=365.7] | Loss=0.00503 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=19.145 | 4485.8 samples/s | 70.1 steps/s
[Step=75050 Epoch=366.0] | Loss=0.00482 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=19.150 | 4455.9 samples/s | 69.6 steps/s
[Step=75100 Epoch=366.2] | Loss=0.00462 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.158 | L2-Norm(final)=19.155 | 5402.4 samples/s | 84.4 steps/s
[Step=75150 Epoch=366.4] | Loss=0.00447 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=19.159 | 2229.1 samples/s | 34.8 steps/s
[Step=75200 Epoch=366.7] | Loss=0.00431 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=19.163 | 4506.7 samples/s | 70.4 steps/s
[Step=75250 Epoch=366.9] | Loss=0.00422 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=19.167 | 4428.4 samples/s | 69.2 steps/s
[Step=75300 Epoch=367.2] | Loss=0.00410 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.163 | L2-Norm(final)=19.171 | 4862.5 samples/s | 76.0 steps/s
[Step=75350 Epoch=367.4] | Loss=0.00400 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=19.175 | 2316.9 samples/s | 36.2 steps/s
[Step=75400 Epoch=367.7] | Loss=0.00395 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=19.179 | 4510.3 samples/s | 70.5 steps/s
[Step=75450 Epoch=367.9] | Loss=0.00387 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.165 | L2-Norm(final)=19.182 | 4510.0 samples/s | 70.5 steps/s
[Step=75500 Epoch=368.2] | Loss=0.00377 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.186 | 4496.3 samples/s | 70.3 steps/s
[Step=75550 Epoch=368.4] | Loss=0.00368 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.189 | 2465.4 samples/s | 38.5 steps/s
[Step=75600 Epoch=368.6] | Loss=0.00364 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.192 | 4323.1 samples/s | 67.5 steps/s
[Step=75650 Epoch=368.9] | Loss=0.00358 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.196 | 4492.1 samples/s | 70.2 steps/s
[Step=75700 Epoch=369.1] | Loss=0.00350 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=19.199 | 4426.0 samples/s | 69.2 steps/s
[Step=75750 Epoch=369.4] | Loss=0.00347 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=19.202 | 2434.0 samples/s | 38.0 steps/s
[Step=75800 Epoch=369.6] | Loss=0.00343 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.205 | 4506.1 samples/s | 70.4 steps/s
[Step=75850 Epoch=369.9] | Loss=0.00339 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.208 | 4418.5 samples/s | 69.0 steps/s
[Step=75900 Epoch=370.1] | Loss=0.00334 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=19.211 | 4419.0 samples/s | 69.0 steps/s
[Step=75950 Epoch=370.3] | Loss=0.00331 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.166 | L2-Norm(final)=19.214 | 2429.3 samples/s | 38.0 steps/s
[Step=76000 Epoch=370.6] | Loss=0.00326 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=19.217 | 4485.5 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step76000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=361.1] | Loss=0.00997 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=19.654 | 5723.3 samples/s | 89.4 steps/s
[Step=74050 Epoch=361.3] | Loss=0.00430 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=19.662 | 4236.1 samples/s | 66.2 steps/s
[Step=74100 Epoch=361.6] | Loss=0.00415 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.634 | L2-Norm(final)=19.673 | 5095.7 samples/s | 79.6 steps/s
[Step=74150 Epoch=361.8] | Loss=0.00383 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=19.683 | 4820.1 samples/s | 75.3 steps/s
[Step=74200 Epoch=362.1] | Loss=0.00385 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=19.694 | 7938.9 samples/s | 124.0 steps/s
[Step=74250 Epoch=362.3] | Loss=0.00364 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=19.704 | 2158.9 samples/s | 33.7 steps/s
[Step=74300 Epoch=362.5] | Loss=0.00359 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=19.714 | 5136.1 samples/s | 80.3 steps/s
[Step=74350 Epoch=362.8] | Loss=0.00360 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=19.724 | 4868.3 samples/s | 76.1 steps/s
[Step=74400 Epoch=363.0] | Loss=0.00354 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=19.734 | 7131.7 samples/s | 111.4 steps/s
[Step=74450 Epoch=363.3] | Loss=0.00341 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=19.744 | 2243.3 samples/s | 35.1 steps/s
[Step=74500 Epoch=363.5] | Loss=0.00339 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=19.753 | 4729.3 samples/s | 73.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=363.5] | Loss=0.00336 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=19.849 | 5972.3 samples/s | 93.3 steps/s
[Step=74550 Epoch=363.8] | Loss=0.00303 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.700 | L2-Norm(final)=19.858 | 3666.3 samples/s | 57.3 steps/s
[Step=74600 Epoch=364.0] | Loss=0.00519 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=19.866 | 4429.2 samples/s | 69.2 steps/s
[Step=74650 Epoch=364.3] | Loss=0.00502 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.713 | L2-Norm(final)=19.873 | 4448.7 samples/s | 69.5 steps/s
[Step=74700 Epoch=364.5] | Loss=0.00499 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=19.881 | 6509.0 samples/s | 101.7 steps/s
[Step=74750 Epoch=364.7] | Loss=0.00492 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=19.888 | 2065.9 samples/s | 32.3 steps/s
[Step=74800 Epoch=365.0] | Loss=0.00491 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=19.895 | 4426.5 samples/s | 69.2 steps/s
[Step=74850 Epoch=365.2] | Loss=0.00475 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=19.901 | 4404.1 samples/s | 68.8 steps/s
[Step=74900 Epoch=365.5] | Loss=0.00457 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.738 | L2-Norm(final)=19.908 | 5960.9 samples/s | 93.1 steps/s
[Step=74950 Epoch=365.7] | Loss=0.00434 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=19.914 | 2121.1 samples/s | 33.1 steps/s
[Step=75000 Epoch=366.0] | Loss=0.00416 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=19.919 | 4390.0 samples/s | 68.6 steps/s
[Step=75050 Epoch=366.2] | Loss=0.00402 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=19.925 | 4422.3 samples/s | 69.1 steps/s
[Step=75100 Epoch=366.5] | Loss=0.00387 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=19.930 | 5506.9 samples/s | 86.0 steps/s
[Step=75150 Epoch=366.7] | Loss=0.00369 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=19.935 | 2184.4 samples/s | 34.1 steps/s
[Step=75200 Epoch=366.9] | Loss=0.00356 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.750 | L2-Norm(final)=19.939 | 4378.2 samples/s | 68.4 steps/s
[Step=75250 Epoch=367.2] | Loss=0.00346 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.751 | L2-Norm(final)=19.944 | 4408.9 samples/s | 68.9 steps/s
[Step=75300 Epoch=367.4] | Loss=0.00340 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.752 | L2-Norm(final)=19.948 | 5157.7 samples/s | 80.6 steps/s
[Step=75350 Epoch=367.7] | Loss=0.00331 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.952 | 2245.5 samples/s | 35.1 steps/s
[Step=75400 Epoch=367.9] | Loss=0.00324 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.956 | 4389.3 samples/s | 68.6 steps/s
[Step=75450 Epoch=368.2] | Loss=0.00317 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=19.960 | 4427.5 samples/s | 69.2 steps/s
[Step=75500 Epoch=368.4] | Loss=0.00309 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=19.964 | 4802.3 samples/s | 75.0 steps/s
[Step=75550 Epoch=368.6] | Loss=0.00303 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=19.967 | 2308.7 samples/s | 36.1 steps/s
[Step=75600 Epoch=368.9] | Loss=0.00298 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=19.971 | 4408.1 samples/s | 68.9 steps/s
[Step=75650 Epoch=369.1] | Loss=0.00295 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=19.974 | 4432.7 samples/s | 69.3 steps/s
[Step=75700 Epoch=369.4] | Loss=0.00292 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.978 | 4511.3 samples/s | 70.5 steps/s
[Step=75750 Epoch=369.6] | Loss=0.00288 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.981 | 2389.2 samples/s | 37.3 steps/s
[Step=75800 Epoch=369.9] | Loss=0.00284 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.985 | 4446.2 samples/s | 69.5 steps/s
[Step=75850 Epoch=370.1] | Loss=0.00282 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=19.988 | 4439.7 samples/s | 69.4 steps/s
[Step=75900 Epoch=370.4] | Loss=0.00281 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.752 | L2-Norm(final)=19.991 | 4518.1 samples/s | 70.6 steps/s
[Step=75950 Epoch=370.6] | Loss=0.00280 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.752 | L2-Norm(final)=19.995 | 2376.3 samples/s | 37.1 steps/s
[Step=76000 Epoch=370.8] | Loss=0.00276 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.752 | L2-Norm(final)=19.998 | 4468.7 samples/s | 69.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step76000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=360.6] | Loss=0.00452 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=19.751 | 5189.4 samples/s | 81.1 steps/s
[Step=74050 Epoch=360.8] | Loss=0.00494 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.409 | L2-Norm(final)=19.759 | 4599.1 samples/s | 71.9 steps/s
[Step=74100 Epoch=361.1] | Loss=0.00473 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=19.768 | 4969.8 samples/s | 77.7 steps/s
[Step=74150 Epoch=361.3] | Loss=0.00463 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.420 | L2-Norm(final)=19.778 | 4995.5 samples/s | 78.1 steps/s
[Step=74200 Epoch=361.5] | Loss=0.00461 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=19.788 | 7780.2 samples/s | 121.6 steps/s
[Step=74250 Epoch=361.8] | Loss=0.00449 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=19.799 | 2195.6 samples/s | 34.3 steps/s
[Step=74300 Epoch=362.0] | Loss=0.00446 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=19.809 | 5016.1 samples/s | 78.4 steps/s
[Step=74350 Epoch=362.3] | Loss=0.00442 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=19.819 | 4998.8 samples/s | 78.1 steps/s
[Step=74400 Epoch=362.5] | Loss=0.00428 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=19.828 | 6800.9 samples/s | 106.3 steps/s
[Step=74450 Epoch=362.8] | Loss=0.00416 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.444 | L2-Norm(final)=19.838 | 2257.1 samples/s | 35.3 steps/s
[Step=74500 Epoch=363.0] | Loss=0.00407 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.447 | L2-Norm(final)=19.847 | 4970.0 samples/s | 77.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=363.0] | Loss=0.00141 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.478 | L2-Norm(final)=19.940 | 5254.8 samples/s | 82.1 steps/s
[Step=74550 Epoch=363.2] | Loss=0.00334 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.483 | L2-Norm(final)=19.948 | 3991.5 samples/s | 62.4 steps/s
[Step=74600 Epoch=363.5] | Loss=0.00501 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.489 | L2-Norm(final)=19.956 | 4420.2 samples/s | 69.1 steps/s
[Step=74650 Epoch=363.7] | Loss=0.00615 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.497 | L2-Norm(final)=19.963 | 4455.1 samples/s | 69.6 steps/s
[Step=74700 Epoch=364.0] | Loss=0.00630 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=19.970 | 6475.2 samples/s | 101.2 steps/s
[Step=74750 Epoch=364.2] | Loss=0.00591 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.510 | L2-Norm(final)=19.976 | 2078.2 samples/s | 32.5 steps/s
[Step=74800 Epoch=364.5] | Loss=0.00587 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.515 | L2-Norm(final)=19.983 | 4421.8 samples/s | 69.1 steps/s
[Step=74850 Epoch=364.7] | Loss=0.00568 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.520 | L2-Norm(final)=19.989 | 4469.6 samples/s | 69.8 steps/s
[Step=74900 Epoch=364.9] | Loss=0.00534 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.523 | L2-Norm(final)=19.995 | 5823.0 samples/s | 91.0 steps/s
[Step=74950 Epoch=365.2] | Loss=0.00523 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.527 | L2-Norm(final)=20.000 | 2141.9 samples/s | 33.5 steps/s
[Step=75000 Epoch=365.4] | Loss=0.00487 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.529 | L2-Norm(final)=20.005 | 4342.2 samples/s | 67.8 steps/s
[Step=75050 Epoch=365.7] | Loss=0.00478 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=20.010 | 4429.2 samples/s | 69.2 steps/s
[Step=75100 Epoch=365.9] | Loss=0.00463 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.534 | L2-Norm(final)=20.014 | 5374.8 samples/s | 84.0 steps/s
[Step=75150 Epoch=366.2] | Loss=0.00464 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.535 | L2-Norm(final)=20.019 | 2229.9 samples/s | 34.8 steps/s
[Step=75200 Epoch=366.4] | Loss=0.00449 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.537 | L2-Norm(final)=20.023 | 4447.1 samples/s | 69.5 steps/s
[Step=75250 Epoch=366.7] | Loss=0.00434 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.538 | L2-Norm(final)=20.027 | 4433.2 samples/s | 69.3 steps/s
[Step=75300 Epoch=366.9] | Loss=0.00422 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.539 | L2-Norm(final)=20.031 | 4882.0 samples/s | 76.3 steps/s
[Step=75350 Epoch=367.1] | Loss=0.00413 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=20.035 | 2286.2 samples/s | 35.7 steps/s
[Step=75400 Epoch=367.4] | Loss=0.00402 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=20.038 | 4424.3 samples/s | 69.1 steps/s
[Step=75450 Epoch=367.6] | Loss=0.00393 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.541 | L2-Norm(final)=20.042 | 4399.7 samples/s | 68.7 steps/s
[Step=75500 Epoch=367.9] | Loss=0.00387 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.541 | L2-Norm(final)=20.046 | 4488.3 samples/s | 70.1 steps/s
[Step=75550 Epoch=368.1] | Loss=0.00375 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.542 | L2-Norm(final)=20.049 | 2404.1 samples/s | 37.6 steps/s
[Step=75600 Epoch=368.4] | Loss=0.00372 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.053 | 4269.7 samples/s | 66.7 steps/s
[Step=75650 Epoch=368.6] | Loss=0.00367 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.056 | 4451.1 samples/s | 69.5 steps/s
[Step=75700 Epoch=368.8] | Loss=0.00361 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.059 | 4230.2 samples/s | 66.1 steps/s
[Step=75750 Epoch=369.1] | Loss=0.00356 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.062 | 2442.2 samples/s | 38.2 steps/s
[Step=75800 Epoch=369.3] | Loss=0.00350 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.065 | 4436.2 samples/s | 69.3 steps/s
[Step=75850 Epoch=369.6] | Loss=0.00344 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=20.068 | 4373.5 samples/s | 68.3 steps/s
[Step=75900 Epoch=369.8] | Loss=0.00338 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=20.071 | 4516.4 samples/s | 70.6 steps/s
[Step=75950 Epoch=370.1] | Loss=0.00336 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=20.074 | 2380.6 samples/s | 37.2 steps/s
[Step=76000 Epoch=370.3] | Loss=0.00329 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=20.077 | 4412.1 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step76000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=360.9] | Loss=0.00571 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=19.799 | 5530.0 samples/s | 86.4 steps/s
[Step=74050 Epoch=361.1] | Loss=0.00602 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.080 | L2-Norm(final)=19.807 | 4448.2 samples/s | 69.5 steps/s
[Step=74100 Epoch=361.4] | Loss=0.00482 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=19.817 | 5048.1 samples/s | 78.9 steps/s
[Step=74150 Epoch=361.6] | Loss=0.00437 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=19.828 | 4945.3 samples/s | 77.3 steps/s
[Step=74200 Epoch=361.8] | Loss=0.00437 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=19.838 | 7691.8 samples/s | 120.2 steps/s
[Step=74250 Epoch=362.1] | Loss=0.00422 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=19.848 | 2184.2 samples/s | 34.1 steps/s
[Step=74300 Epoch=362.3] | Loss=0.00400 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=19.858 | 4915.3 samples/s | 76.8 steps/s
[Step=74350 Epoch=362.6] | Loss=0.00389 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=19.867 | 4998.1 samples/s | 78.1 steps/s
[Step=74400 Epoch=362.8] | Loss=0.00381 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.113 | L2-Norm(final)=19.877 | 6844.7 samples/s | 106.9 steps/s
[Step=74450 Epoch=363.1] | Loss=0.00377 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=19.886 | 2277.1 samples/s | 35.6 steps/s
[Step=74500 Epoch=363.3] | Loss=0.00366 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=19.896 | 5056.6 samples/s | 79.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=363.3] | Loss=0.00328 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=19.990 | 5473.9 samples/s | 85.5 steps/s
[Step=74550 Epoch=363.5] | Loss=0.00271 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=19.998 | 3941.6 samples/s | 61.6 steps/s
[Step=74600 Epoch=363.8] | Loss=0.00380 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=20.006 | 4464.3 samples/s | 69.8 steps/s
[Step=74650 Epoch=364.0] | Loss=0.00536 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=20.014 | 4329.8 samples/s | 67.7 steps/s
[Step=74700 Epoch=364.3] | Loss=0.00568 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.177 | L2-Norm(final)=20.022 | 6426.5 samples/s | 100.4 steps/s
[Step=74750 Epoch=364.5] | Loss=0.00513 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=20.029 | 2072.5 samples/s | 32.4 steps/s
[Step=74800 Epoch=364.8] | Loss=0.00515 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=20.036 | 4392.4 samples/s | 68.6 steps/s
[Step=74850 Epoch=365.0] | Loss=0.00499 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=20.041 | 4413.5 samples/s | 69.0 steps/s
[Step=74900 Epoch=365.3] | Loss=0.00478 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=20.047 | 5876.1 samples/s | 91.8 steps/s
[Step=74950 Epoch=365.5] | Loss=0.00450 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=20.052 | 2160.6 samples/s | 33.8 steps/s
[Step=75000 Epoch=365.7] | Loss=0.00429 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=20.057 | 4324.2 samples/s | 67.6 steps/s
[Step=75050 Epoch=366.0] | Loss=0.00411 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=20.062 | 4458.0 samples/s | 69.7 steps/s
[Step=75100 Epoch=366.2] | Loss=0.00393 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.066 | 5350.2 samples/s | 83.6 steps/s
[Step=75150 Epoch=366.5] | Loss=0.00375 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.207 | L2-Norm(final)=20.070 | 2201.0 samples/s | 34.4 steps/s
[Step=75200 Epoch=366.7] | Loss=0.00356 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=20.074 | 4454.3 samples/s | 69.6 steps/s
[Step=75250 Epoch=367.0] | Loss=0.00351 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.209 | L2-Norm(final)=20.078 | 4366.5 samples/s | 68.2 steps/s
[Step=75300 Epoch=367.2] | Loss=0.00337 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=20.082 | 4901.4 samples/s | 76.6 steps/s
[Step=75350 Epoch=367.4] | Loss=0.00329 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=20.086 | 2298.4 samples/s | 35.9 steps/s
[Step=75400 Epoch=367.7] | Loss=0.00317 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=20.090 | 4386.3 samples/s | 68.5 steps/s
[Step=75450 Epoch=367.9] | Loss=0.00312 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.093 | 4479.0 samples/s | 70.0 steps/s
[Step=75500 Epoch=368.2] | Loss=0.00310 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.212 | L2-Norm(final)=20.097 | 4479.6 samples/s | 70.0 steps/s
[Step=75550 Epoch=368.4] | Loss=0.00303 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.100 | 2395.1 samples/s | 37.4 steps/s
[Step=75600 Epoch=368.7] | Loss=0.00296 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.104 | 4429.1 samples/s | 69.2 steps/s
[Step=75650 Epoch=368.9] | Loss=0.00293 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.107 | 4447.2 samples/s | 69.5 steps/s
[Step=75700 Epoch=369.2] | Loss=0.00289 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.110 | 4365.2 samples/s | 68.2 steps/s
[Step=75750 Epoch=369.4] | Loss=0.00285 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=20.113 | 2399.0 samples/s | 37.5 steps/s
[Step=75800 Epoch=369.6] | Loss=0.00280 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.212 | L2-Norm(final)=20.117 | 4425.0 samples/s | 69.1 steps/s
[Step=75850 Epoch=369.9] | Loss=0.00273 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=20.120 | 4492.7 samples/s | 70.2 steps/s
[Step=75900 Epoch=370.1] | Loss=0.00271 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=20.123 | 4374.0 samples/s | 68.3 steps/s
[Step=75950 Epoch=370.4] | Loss=0.00266 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=20.126 | 2413.7 samples/s | 37.7 steps/s
[Step=76000 Epoch=370.6] | Loss=0.00264 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=20.129 | 4425.3 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step76000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=362.9] | Loss=0.00321 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.791 | L2-Norm(final)=19.839 | 5083.1 samples/s | 79.4 steps/s
[Step=74050 Epoch=363.1] | Loss=0.00437 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=19.849 | 4734.6 samples/s | 74.0 steps/s
[Step=74100 Epoch=363.4] | Loss=0.00381 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.801 | L2-Norm(final)=19.861 | 5013.5 samples/s | 78.3 steps/s
[Step=74150 Epoch=363.6] | Loss=0.00365 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.805 | L2-Norm(final)=19.872 | 4938.9 samples/s | 77.2 steps/s
[Step=74200 Epoch=363.9] | Loss=0.00358 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=19.884 | 8023.0 samples/s | 125.4 steps/s
[Step=74250 Epoch=364.1] | Loss=0.00351 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.813 | L2-Norm(final)=19.895 | 2185.0 samples/s | 34.1 steps/s
[Step=74300 Epoch=364.4] | Loss=0.00355 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=19.906 | 5208.4 samples/s | 81.4 steps/s
[Step=74350 Epoch=364.6] | Loss=0.00349 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=19.917 | 4780.7 samples/s | 74.7 steps/s
[Step=74400 Epoch=364.8] | Loss=0.00338 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.823 | L2-Norm(final)=19.928 | 7435.2 samples/s | 116.2 steps/s
[Step=74450 Epoch=365.1] | Loss=0.00336 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=19.938 | 2184.7 samples/s | 34.1 steps/s
[Step=74500 Epoch=365.3] | Loss=0.00326 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=19.949 | 4829.6 samples/s | 75.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=365.3] | Loss=0.00245 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.860 | L2-Norm(final)=20.052 | 5075.4 samples/s | 79.3 steps/s
[Step=74550 Epoch=365.6] | Loss=0.00522 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.867 | L2-Norm(final)=20.062 | 3966.6 samples/s | 62.0 steps/s
[Step=74600 Epoch=365.8] | Loss=0.00602 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=20.071 | 4305.5 samples/s | 67.3 steps/s
[Step=74650 Epoch=366.1] | Loss=0.00598 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.889 | L2-Norm(final)=20.081 | 4296.0 samples/s | 67.1 steps/s
[Step=74700 Epoch=366.3] | Loss=0.00590 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.897 | L2-Norm(final)=20.089 | 6261.9 samples/s | 97.8 steps/s
[Step=74750 Epoch=366.6] | Loss=0.00558 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.904 | L2-Norm(final)=20.097 | 1944.6 samples/s | 30.4 steps/s
[Step=74800 Epoch=366.8] | Loss=0.00527 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.909 | L2-Norm(final)=20.104 | 4300.2 samples/s | 67.2 steps/s
[Step=74850 Epoch=367.1] | Loss=0.00517 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.913 | L2-Norm(final)=20.110 | 4247.6 samples/s | 66.4 steps/s
[Step=74900 Epoch=367.3] | Loss=0.00483 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=20.116 | 6037.4 samples/s | 94.3 steps/s
[Step=74950 Epoch=367.5] | Loss=0.00455 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=20.121 | 2083.7 samples/s | 32.6 steps/s
[Step=75000 Epoch=367.8] | Loss=0.00430 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.921 | L2-Norm(final)=20.126 | 4412.8 samples/s | 68.9 steps/s
[Step=75050 Epoch=368.0] | Loss=0.00411 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=20.131 | 4462.0 samples/s | 69.7 steps/s
[Step=75100 Epoch=368.3] | Loss=0.00396 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=20.136 | 5778.2 samples/s | 90.3 steps/s
[Step=75150 Epoch=368.5] | Loss=0.00385 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=20.140 | 2176.8 samples/s | 34.0 steps/s
[Step=75200 Epoch=368.8] | Loss=0.00371 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=20.144 | 4471.1 samples/s | 69.9 steps/s
[Step=75250 Epoch=369.0] | Loss=0.00358 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.928 | L2-Norm(final)=20.149 | 4414.1 samples/s | 69.0 steps/s
[Step=75300 Epoch=369.3] | Loss=0.00349 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=20.153 | 5472.6 samples/s | 85.5 steps/s
[Step=75350 Epoch=369.5] | Loss=0.00340 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=20.156 | 2200.4 samples/s | 34.4 steps/s
[Step=75400 Epoch=369.7] | Loss=0.00332 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=20.160 | 4457.3 samples/s | 69.6 steps/s
[Step=75450 Epoch=370.0] | Loss=0.00323 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.164 | 4449.1 samples/s | 69.5 steps/s
[Step=75500 Epoch=370.2] | Loss=0.00317 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.168 | 5220.5 samples/s | 81.6 steps/s
[Step=75550 Epoch=370.5] | Loss=0.00308 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.171 | 2288.1 samples/s | 35.8 steps/s
[Step=75600 Epoch=370.7] | Loss=0.00300 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.175 | 4407.1 samples/s | 68.9 steps/s
[Step=75650 Epoch=371.0] | Loss=0.00294 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.178 | 4537.1 samples/s | 70.9 steps/s
[Step=75700 Epoch=371.2] | Loss=0.00293 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.181 | 4813.9 samples/s | 75.2 steps/s
[Step=75750 Epoch=371.5] | Loss=0.00289 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.185 | 2328.4 samples/s | 36.4 steps/s
[Step=75800 Epoch=371.7] | Loss=0.00284 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.930 | L2-Norm(final)=20.188 | 4532.3 samples/s | 70.8 steps/s
[Step=75850 Epoch=372.0] | Loss=0.00280 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=20.191 | 4370.2 samples/s | 68.3 steps/s
[Step=75900 Epoch=372.2] | Loss=0.00276 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=20.194 | 4620.6 samples/s | 72.2 steps/s
[Step=75950 Epoch=372.4] | Loss=0.00270 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=20.197 | 2367.7 samples/s | 37.0 steps/s
[Step=76000 Epoch=372.7] | Loss=0.00265 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=20.200 | 4301.5 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step76000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=701.2] | Loss=0.00135 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.237 | L2-Norm(final)=10.051 | 5203.9 samples/s | 81.3 steps/s
[Step=74050 Epoch=701.7] | Loss=0.00022 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.246 | L2-Norm(final)=10.068 | 4014.4 samples/s | 62.7 steps/s
[Step=74100 Epoch=702.2] | Loss=0.00014 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=10.079 | 7410.2 samples/s | 115.8 steps/s
[Step=74150 Epoch=702.6] | Loss=0.00010 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=10.086 | 2113.4 samples/s | 33.0 steps/s
[Step=74200 Epoch=703.1] | Loss=0.00008 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.263 | L2-Norm(final)=10.091 | 6546.3 samples/s | 102.3 steps/s
[Step=74250 Epoch=703.6] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=10.096 | 2214.6 samples/s | 34.6 steps/s
[Step=74300 Epoch=704.1] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=10.100 | 5765.2 samples/s | 90.1 steps/s
[Step=74350 Epoch=704.5] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.268 | L2-Norm(final)=10.104 | 2263.7 samples/s | 35.4 steps/s
[Step=74400 Epoch=705.0] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.270 | L2-Norm(final)=10.108 | 5262.9 samples/s | 82.2 steps/s
[Step=74450 Epoch=705.5] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=10.111 | 2471.7 samples/s | 38.6 steps/s
[Step=74500 Epoch=706.0] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=10.115 | 4638.5 samples/s | 72.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=706.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.285 | L2-Norm(final)=10.149 | 5845.5 samples/s | 91.3 steps/s
[Step=74550 Epoch=706.4] | Loss=0.00099 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.302 | L2-Norm(final)=10.156 | 3485.9 samples/s | 54.5 steps/s
[Step=74600 Epoch=706.9] | Loss=0.00111 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.322 | L2-Norm(final)=10.160 | 6209.2 samples/s | 97.0 steps/s
[Step=74650 Epoch=707.4] | Loss=0.00076 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=10.163 | 2003.2 samples/s | 31.3 steps/s
[Step=74700 Epoch=707.8] | Loss=0.00057 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.338 | L2-Norm(final)=10.165 | 5555.8 samples/s | 86.8 steps/s
[Step=74750 Epoch=708.3] | Loss=0.00047 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.341 | L2-Norm(final)=10.167 | 2098.0 samples/s | 32.8 steps/s
[Step=74800 Epoch=708.8] | Loss=0.00039 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=10.168 | 5024.0 samples/s | 78.5 steps/s
[Step=74850 Epoch=709.3] | Loss=0.00034 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=10.169 | 2167.9 samples/s | 33.9 steps/s
[Step=74900 Epoch=709.7] | Loss=0.00030 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.169 | 4621.6 samples/s | 72.2 steps/s
[Step=74950 Epoch=710.2] | Loss=0.00027 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.170 | 2253.4 samples/s | 35.2 steps/s
[Step=75000 Epoch=710.7] | Loss=0.00024 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=10.171 | 4386.1 samples/s | 68.5 steps/s
[Step=75050 Epoch=711.2] | Loss=0.00022 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=10.171 | 2352.9 samples/s | 36.8 steps/s
[Step=75100 Epoch=711.6] | Loss=0.00020 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=10.172 | 4142.7 samples/s | 64.7 steps/s
[Step=75150 Epoch=712.1] | Loss=0.00019 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=10.172 | 2391.8 samples/s | 37.4 steps/s
[Step=75200 Epoch=712.6] | Loss=0.00017 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=10.172 | 4108.3 samples/s | 64.2 steps/s
[Step=75250 Epoch=713.1] | Loss=0.00016 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.173 | 2374.3 samples/s | 37.1 steps/s
[Step=75300 Epoch=713.5] | Loss=0.00015 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.173 | 4325.4 samples/s | 67.6 steps/s
[Step=75350 Epoch=714.0] | Loss=0.00015 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.345 | L2-Norm(final)=10.174 | 2459.3 samples/s | 38.4 steps/s
[Step=75400 Epoch=714.5] | Loss=0.00014 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=10.174 | 4054.3 samples/s | 63.3 steps/s
[Step=75450 Epoch=715.0] | Loss=0.00013 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=10.174 | 6343.4 samples/s | 99.1 steps/s
[Step=75500 Epoch=715.4] | Loss=0.00012 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=10.175 | 1977.8 samples/s | 30.9 steps/s
[Step=75550 Epoch=715.9] | Loss=0.00012 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=10.175 | 5777.9 samples/s | 90.3 steps/s
[Step=75600 Epoch=716.4] | Loss=0.00011 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=10.175 | 2058.3 samples/s | 32.2 steps/s
[Step=75650 Epoch=716.8] | Loss=0.00011 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.342 | L2-Norm(final)=10.176 | 5299.6 samples/s | 82.8 steps/s
[Step=75700 Epoch=717.3] | Loss=0.00010 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.342 | L2-Norm(final)=10.176 | 2133.3 samples/s | 33.3 steps/s
[Step=75750 Epoch=717.8] | Loss=0.00010 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.341 | L2-Norm(final)=10.176 | 4846.1 samples/s | 75.7 steps/s
[Step=75800 Epoch=718.3] | Loss=0.00010 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.341 | L2-Norm(final)=10.176 | 2169.8 samples/s | 33.9 steps/s
[Step=75850 Epoch=718.7] | Loss=0.00009 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.340 | L2-Norm(final)=10.177 | 4449.4 samples/s | 69.5 steps/s
[Step=75900 Epoch=719.2] | Loss=0.00009 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.339 | L2-Norm(final)=10.177 | 2309.9 samples/s | 36.1 steps/s
[Step=75950 Epoch=719.7] | Loss=0.00009 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.339 | L2-Norm(final)=10.177 | 4258.1 samples/s | 66.5 steps/s
[Step=76000 Epoch=720.2] | Loss=0.00008 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.338 | L2-Norm(final)=10.178 | 2391.5 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step76000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=703.9] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=10.890 | 5115.5 samples/s | 79.9 steps/s
[Step=74050 Epoch=704.4] | Loss=0.00014 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=10.911 | 4198.5 samples/s | 65.6 steps/s
[Step=74100 Epoch=704.9] | Loss=0.00009 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.277 | L2-Norm(final)=10.929 | 7575.8 samples/s | 118.4 steps/s
[Step=74150 Epoch=705.4] | Loss=0.00008 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.284 | L2-Norm(final)=10.941 | 2128.5 samples/s | 33.3 steps/s
[Step=74200 Epoch=705.8] | Loss=0.00006 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.288 | L2-Norm(final)=10.950 | 6587.8 samples/s | 102.9 steps/s
[Step=74250 Epoch=706.3] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.292 | L2-Norm(final)=10.958 | 2223.8 samples/s | 34.7 steps/s
[Step=74300 Epoch=706.8] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.295 | L2-Norm(final)=10.965 | 5853.1 samples/s | 91.5 steps/s
[Step=74350 Epoch=707.3] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.297 | L2-Norm(final)=10.972 | 2297.6 samples/s | 35.9 steps/s
[Step=74400 Epoch=707.7] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.300 | L2-Norm(final)=10.979 | 5255.4 samples/s | 82.1 steps/s
[Step=74450 Epoch=708.2] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.302 | L2-Norm(final)=10.986 | 2386.6 samples/s | 37.3 steps/s
[Step=74500 Epoch=708.7] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.303 | L2-Norm(final)=10.992 | 4861.0 samples/s | 76.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=708.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.321 | L2-Norm(final)=11.053 | 5775.1 samples/s | 90.2 steps/s
[Step=74550 Epoch=709.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.315 | L2-Norm(final)=11.058 | 3614.5 samples/s | 56.5 steps/s
[Step=74600 Epoch=709.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.302 | L2-Norm(final)=11.061 | 6311.8 samples/s | 98.6 steps/s
[Step=74650 Epoch=710.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.285 | L2-Norm(final)=11.063 | 2010.0 samples/s | 31.4 steps/s
[Step=74700 Epoch=710.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=11.065 | 5581.7 samples/s | 87.2 steps/s
[Step=74750 Epoch=711.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.249 | L2-Norm(final)=11.066 | 2090.9 samples/s | 32.7 steps/s
[Step=74800 Epoch=711.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.229 | L2-Norm(final)=11.067 | 5112.8 samples/s | 79.9 steps/s
[Step=74850 Epoch=712.0] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.209 | L2-Norm(final)=11.068 | 2180.4 samples/s | 34.1 steps/s
[Step=74900 Epoch=712.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.189 | L2-Norm(final)=11.069 | 4694.4 samples/s | 73.3 steps/s
[Step=74950 Epoch=713.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.169 | L2-Norm(final)=11.070 | 2211.3 samples/s | 34.6 steps/s
[Step=75000 Epoch=713.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=11.071 | 4324.5 samples/s | 67.6 steps/s
[Step=75050 Epoch=713.9] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.071 | 2344.7 samples/s | 36.6 steps/s
[Step=75100 Epoch=714.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.107 | L2-Norm(final)=11.072 | 4172.0 samples/s | 65.2 steps/s
[Step=75150 Epoch=714.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.073 | 2417.1 samples/s | 37.8 steps/s
[Step=75200 Epoch=715.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.066 | L2-Norm(final)=11.074 | 4168.9 samples/s | 65.1 steps/s
[Step=75250 Epoch=715.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.045 | L2-Norm(final)=11.075 | 2377.3 samples/s | 37.1 steps/s
[Step=75300 Epoch=716.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.024 | L2-Norm(final)=11.076 | 4251.2 samples/s | 66.4 steps/s
[Step=75350 Epoch=716.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.003 | L2-Norm(final)=11.077 | 2518.1 samples/s | 39.3 steps/s
[Step=75400 Epoch=717.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.982 | L2-Norm(final)=11.078 | 3839.7 samples/s | 60.0 steps/s
[Step=75450 Epoch=717.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.960 | L2-Norm(final)=11.079 | 6618.9 samples/s | 103.4 steps/s
[Step=75500 Epoch=718.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.939 | L2-Norm(final)=11.080 | 1970.2 samples/s | 30.8 steps/s
[Step=75550 Epoch=718.7] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.917 | L2-Norm(final)=11.081 | 5792.0 samples/s | 90.5 steps/s
[Step=75600 Epoch=719.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=11.082 | 2068.0 samples/s | 32.3 steps/s
[Step=75650 Epoch=719.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.083 | 5261.5 samples/s | 82.2 steps/s
[Step=75700 Epoch=720.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.853 | L2-Norm(final)=11.085 | 2121.0 samples/s | 33.1 steps/s
[Step=75750 Epoch=720.6] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.831 | L2-Norm(final)=11.086 | 4668.6 samples/s | 72.9 steps/s
[Step=75800 Epoch=721.0] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.809 | L2-Norm(final)=11.087 | 2137.0 samples/s | 33.4 steps/s
[Step=75850 Epoch=721.5] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.788 | L2-Norm(final)=11.088 | 4487.1 samples/s | 70.1 steps/s
[Step=75900 Epoch=722.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.766 | L2-Norm(final)=11.090 | 2296.0 samples/s | 35.9 steps/s
[Step=75950 Epoch=722.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.744 | L2-Norm(final)=11.091 | 4255.2 samples/s | 66.5 steps/s
[Step=76000 Epoch=722.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.722 | L2-Norm(final)=11.093 | 2444.8 samples/s | 38.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step76000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=706.7] | Loss=0.00018 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.243 | L2-Norm(final)=10.490 | 4831.2 samples/s | 75.5 steps/s
[Step=74050 Epoch=707.1] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.248 | L2-Norm(final)=10.503 | 4314.3 samples/s | 67.4 steps/s
[Step=74100 Epoch=707.6] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.254 | L2-Norm(final)=10.519 | 7163.6 samples/s | 111.9 steps/s
[Step=74150 Epoch=708.1] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=10.533 | 2120.4 samples/s | 33.1 steps/s
[Step=74200 Epoch=708.6] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.263 | L2-Norm(final)=10.545 | 6782.5 samples/s | 106.0 steps/s
[Step=74250 Epoch=709.0] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=10.555 | 2156.9 samples/s | 33.7 steps/s
[Step=74300 Epoch=709.5] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.270 | L2-Norm(final)=10.565 | 6254.0 samples/s | 97.7 steps/s
[Step=74350 Epoch=710.0] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.273 | L2-Norm(final)=10.575 | 2223.6 samples/s | 34.7 steps/s
[Step=74400 Epoch=710.5] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.276 | L2-Norm(final)=10.584 | 5659.3 samples/s | 88.4 steps/s
[Step=74450 Epoch=711.0] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.278 | L2-Norm(final)=10.592 | 2402.1 samples/s | 37.5 steps/s
[Step=74500 Epoch=711.4] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.280 | L2-Norm(final)=10.601 | 5036.2 samples/s | 78.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=711.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.298 | L2-Norm(final)=10.682 | 5459.8 samples/s | 85.3 steps/s
[Step=74550 Epoch=711.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.293 | L2-Norm(final)=10.687 | 3905.9 samples/s | 61.0 steps/s
[Step=74600 Epoch=712.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.286 | L2-Norm(final)=10.692 | 6361.3 samples/s | 99.4 steps/s
[Step=74650 Epoch=712.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.276 | L2-Norm(final)=10.696 | 2009.5 samples/s | 31.4 steps/s
[Step=74700 Epoch=713.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=10.698 | 5591.7 samples/s | 87.4 steps/s
[Step=74750 Epoch=713.8] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=10.701 | 2096.4 samples/s | 32.8 steps/s
[Step=74800 Epoch=714.3] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.243 | L2-Norm(final)=10.703 | 5269.2 samples/s | 82.3 steps/s
[Step=74850 Epoch=714.8] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=10.704 | 2145.0 samples/s | 33.5 steps/s
[Step=74900 Epoch=715.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=10.706 | 4879.0 samples/s | 76.2 steps/s
[Step=74950 Epoch=715.7] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.207 | L2-Norm(final)=10.708 | 2169.1 samples/s | 33.9 steps/s
[Step=75000 Epoch=716.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.195 | L2-Norm(final)=10.710 | 4596.3 samples/s | 71.8 steps/s
[Step=75050 Epoch=716.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.182 | L2-Norm(final)=10.711 | 2246.0 samples/s | 35.1 steps/s
[Step=75100 Epoch=717.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.170 | L2-Norm(final)=10.713 | 4352.0 samples/s | 68.0 steps/s
[Step=75150 Epoch=717.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=10.714 | 2343.9 samples/s | 36.6 steps/s
[Step=75200 Epoch=718.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.144 | L2-Norm(final)=10.716 | 4246.2 samples/s | 66.3 steps/s
[Step=75250 Epoch=718.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=10.718 | 2332.0 samples/s | 36.4 steps/s
[Step=75300 Epoch=719.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.118 | L2-Norm(final)=10.719 | 4257.5 samples/s | 66.5 steps/s
[Step=75350 Epoch=719.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.105 | L2-Norm(final)=10.721 | 2355.3 samples/s | 36.8 steps/s
[Step=75400 Epoch=720.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.092 | L2-Norm(final)=10.723 | 4246.3 samples/s | 66.3 steps/s
[Step=75450 Epoch=720.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.078 | L2-Norm(final)=10.725 | 2378.5 samples/s | 37.2 steps/s
[Step=75500 Epoch=721.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.065 | L2-Norm(final)=10.727 | 4166.4 samples/s | 65.1 steps/s
[Step=75550 Epoch=721.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.051 | L2-Norm(final)=10.728 | 6994.1 samples/s | 109.3 steps/s
[Step=75600 Epoch=721.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.038 | L2-Norm(final)=10.730 | 1949.0 samples/s | 30.5 steps/s
[Step=75650 Epoch=722.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.024 | L2-Norm(final)=10.732 | 6317.1 samples/s | 98.7 steps/s
[Step=75700 Epoch=722.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.010 | L2-Norm(final)=10.734 | 2026.4 samples/s | 31.7 steps/s
[Step=75750 Epoch=723.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.996 | L2-Norm(final)=10.736 | 5591.6 samples/s | 87.4 steps/s
[Step=75800 Epoch=723.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.982 | L2-Norm(final)=10.738 | 2062.0 samples/s | 32.2 steps/s
[Step=75850 Epoch=724.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.968 | L2-Norm(final)=10.741 | 5357.7 samples/s | 83.7 steps/s
[Step=75900 Epoch=724.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.954 | L2-Norm(final)=10.743 | 2128.1 samples/s | 33.3 steps/s
[Step=75950 Epoch=725.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.940 | L2-Norm(final)=10.745 | 4966.0 samples/s | 77.6 steps/s
[Step=76000 Epoch=725.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.925 | L2-Norm(final)=10.747 | 2235.1 samples/s | 34.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step76000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=697.3] | Loss=0.00035 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.441 | L2-Norm(final)=10.461 | 5287.7 samples/s | 82.6 steps/s
[Step=74050 Epoch=697.8] | Loss=0.00009 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.446 | L2-Norm(final)=10.463 | 4104.0 samples/s | 64.1 steps/s
[Step=74100 Epoch=698.2] | Loss=0.00007 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.449 | L2-Norm(final)=10.468 | 7230.0 samples/s | 113.0 steps/s
[Step=74150 Epoch=698.7] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.452 | L2-Norm(final)=10.473 | 2144.6 samples/s | 33.5 steps/s
[Step=74200 Epoch=699.2] | Loss=0.00006 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.454 | L2-Norm(final)=10.478 | 6349.0 samples/s | 99.2 steps/s
[Step=74250 Epoch=699.6] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.455 | L2-Norm(final)=10.482 | 2220.2 samples/s | 34.7 steps/s
[Step=74300 Epoch=700.1] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.457 | L2-Norm(final)=10.486 | 5675.5 samples/s | 88.7 steps/s
[Step=74350 Epoch=700.6] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.458 | L2-Norm(final)=10.490 | 2332.2 samples/s | 36.4 steps/s
[Step=74400 Epoch=701.1] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.460 | L2-Norm(final)=10.494 | 4990.1 samples/s | 78.0 steps/s
[Step=74450 Epoch=701.5] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=10.498 | 2541.8 samples/s | 39.7 steps/s
[Step=74500 Epoch=702.0] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.462 | L2-Norm(final)=10.502 | 4501.6 samples/s | 70.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=702.0] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.474 | L2-Norm(final)=10.541 | 5384.9 samples/s | 84.1 steps/s
[Step=74550 Epoch=702.5] | Loss=0.00005 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.475 | L2-Norm(final)=10.545 | 3723.2 samples/s | 58.2 steps/s
[Step=74600 Epoch=702.9] | Loss=0.00004 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.478 | L2-Norm(final)=10.549 | 6100.9 samples/s | 95.3 steps/s
[Step=74650 Epoch=703.4] | Loss=0.00003 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.478 | L2-Norm(final)=10.553 | 2009.7 samples/s | 31.4 steps/s
[Step=74700 Epoch=703.9] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.477 | L2-Norm(final)=10.555 | 5502.2 samples/s | 86.0 steps/s
[Step=74750 Epoch=704.4] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.476 | L2-Norm(final)=10.557 | 2112.7 samples/s | 33.0 steps/s
[Step=74800 Epoch=704.8] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.475 | L2-Norm(final)=10.559 | 4856.3 samples/s | 75.9 steps/s
[Step=74850 Epoch=705.3] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.473 | L2-Norm(final)=10.560 | 2215.6 samples/s | 34.6 steps/s
[Step=74900 Epoch=705.8] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.471 | L2-Norm(final)=10.561 | 4487.1 samples/s | 70.1 steps/s
[Step=74950 Epoch=706.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.468 | L2-Norm(final)=10.563 | 2299.4 samples/s | 35.9 steps/s
[Step=75000 Epoch=706.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.466 | L2-Norm(final)=10.564 | 4261.6 samples/s | 66.6 steps/s
[Step=75050 Epoch=707.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.464 | L2-Norm(final)=10.565 | 2377.5 samples/s | 37.1 steps/s
[Step=75100 Epoch=707.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.461 | L2-Norm(final)=10.566 | 4154.0 samples/s | 64.9 steps/s
[Step=75150 Epoch=708.1] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.458 | L2-Norm(final)=10.567 | 2363.0 samples/s | 36.9 steps/s
[Step=75200 Epoch=708.6] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.456 | L2-Norm(final)=10.568 | 4167.5 samples/s | 65.1 steps/s
[Step=75250 Epoch=709.1] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.569 | 2526.5 samples/s | 39.5 steps/s
[Step=75300 Epoch=709.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.450 | L2-Norm(final)=10.569 | 3737.8 samples/s | 58.4 steps/s
[Step=75350 Epoch=710.0] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.447 | L2-Norm(final)=10.570 | 6337.0 samples/s | 99.0 steps/s
[Step=75400 Epoch=710.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.444 | L2-Norm(final)=10.571 | 2003.5 samples/s | 31.3 steps/s
[Step=75450 Epoch=711.0] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.441 | L2-Norm(final)=10.572 | 5561.6 samples/s | 86.9 steps/s
[Step=75500 Epoch=711.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.438 | L2-Norm(final)=10.573 | 2094.8 samples/s | 32.7 steps/s
[Step=75550 Epoch=711.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.435 | L2-Norm(final)=10.574 | 4904.1 samples/s | 76.6 steps/s
[Step=75600 Epoch=712.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.432 | L2-Norm(final)=10.575 | 2167.0 samples/s | 33.9 steps/s
[Step=75650 Epoch=712.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.428 | L2-Norm(final)=10.575 | 4557.6 samples/s | 71.2 steps/s
[Step=75700 Epoch=713.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.425 | L2-Norm(final)=10.576 | 2335.7 samples/s | 36.5 steps/s
[Step=75750 Epoch=713.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.422 | L2-Norm(final)=10.577 | 4201.0 samples/s | 65.6 steps/s
[Step=75800 Epoch=714.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.418 | L2-Norm(final)=10.578 | 2387.9 samples/s | 37.3 steps/s
[Step=75850 Epoch=714.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.415 | L2-Norm(final)=10.579 | 4289.9 samples/s | 67.0 steps/s
[Step=75900 Epoch=715.2] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.411 | L2-Norm(final)=10.580 | 2371.8 samples/s | 37.1 steps/s
[Step=75950 Epoch=715.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.408 | L2-Norm(final)=10.581 | 4222.3 samples/s | 66.0 steps/s
[Step=76000 Epoch=716.1] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.404 | L2-Norm(final)=10.581 | 2523.9 samples/s | 39.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step76000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=705.3] | Loss=0.00028 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.351 | L2-Norm(final)=11.043 | 5100.6 samples/s | 79.7 steps/s
[Step=74050 Epoch=705.8] | Loss=0.00010 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.360 | L2-Norm(final)=11.051 | 4042.6 samples/s | 63.2 steps/s
[Step=74100 Epoch=706.2] | Loss=0.00008 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.366 | L2-Norm(final)=11.058 | 7265.1 samples/s | 113.5 steps/s
[Step=74150 Epoch=706.7] | Loss=0.00007 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.369 | L2-Norm(final)=11.065 | 2143.4 samples/s | 33.5 steps/s
[Step=74200 Epoch=707.2] | Loss=0.00006 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.372 | L2-Norm(final)=11.070 | 6423.0 samples/s | 100.4 steps/s
[Step=74250 Epoch=707.7] | Loss=0.00005 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.374 | L2-Norm(final)=11.075 | 2171.7 samples/s | 33.9 steps/s
[Step=74300 Epoch=708.1] | Loss=0.00005 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.376 | L2-Norm(final)=11.080 | 6144.5 samples/s | 96.0 steps/s
[Step=74350 Epoch=708.6] | Loss=0.00005 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.378 | L2-Norm(final)=11.085 | 2249.9 samples/s | 35.2 steps/s
[Step=74400 Epoch=709.1] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.379 | L2-Norm(final)=11.089 | 5495.6 samples/s | 85.9 steps/s
[Step=74450 Epoch=709.6] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.381 | L2-Norm(final)=11.094 | 2308.8 samples/s | 36.1 steps/s
[Step=74500 Epoch=710.1] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.382 | L2-Norm(final)=11.098 | 5111.6 samples/s | 79.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=710.1] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.395 | L2-Norm(final)=11.142 | 5186.8 samples/s | 81.0 steps/s
[Step=74550 Epoch=710.5] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.393 | L2-Norm(final)=11.145 | 3805.6 samples/s | 59.5 steps/s
[Step=74600 Epoch=711.0] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.389 | L2-Norm(final)=11.148 | 6359.4 samples/s | 99.4 steps/s
[Step=74650 Epoch=711.5] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.384 | L2-Norm(final)=11.150 | 2011.0 samples/s | 31.4 steps/s
[Step=74700 Epoch=712.0] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.378 | L2-Norm(final)=11.152 | 5611.7 samples/s | 87.7 steps/s
[Step=74750 Epoch=712.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.372 | L2-Norm(final)=11.153 | 2065.0 samples/s | 32.3 steps/s
[Step=74800 Epoch=712.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.365 | L2-Norm(final)=11.155 | 5300.4 samples/s | 82.8 steps/s
[Step=74850 Epoch=713.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.358 | L2-Norm(final)=11.156 | 2119.4 samples/s | 33.1 steps/s
[Step=74900 Epoch=713.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.351 | L2-Norm(final)=11.157 | 4961.8 samples/s | 77.5 steps/s
[Step=74950 Epoch=714.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.344 | L2-Norm(final)=11.158 | 2185.4 samples/s | 34.1 steps/s
[Step=75000 Epoch=714.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.337 | L2-Norm(final)=11.159 | 4487.0 samples/s | 70.1 steps/s
[Step=75050 Epoch=715.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=11.160 | 2295.5 samples/s | 35.9 steps/s
[Step=75100 Epoch=715.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.322 | L2-Norm(final)=11.161 | 4301.0 samples/s | 67.2 steps/s
[Step=75150 Epoch=716.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.314 | L2-Norm(final)=11.161 | 2346.0 samples/s | 36.7 steps/s
[Step=75200 Epoch=716.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.306 | L2-Norm(final)=11.162 | 4220.9 samples/s | 66.0 steps/s
[Step=75250 Epoch=717.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.298 | L2-Norm(final)=11.163 | 2365.8 samples/s | 37.0 steps/s
[Step=75300 Epoch=717.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.290 | L2-Norm(final)=11.164 | 4242.4 samples/s | 66.3 steps/s
[Step=75350 Epoch=718.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.282 | L2-Norm(final)=11.165 | 2369.9 samples/s | 37.0 steps/s
[Step=75400 Epoch=718.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.274 | L2-Norm(final)=11.166 | 4260.1 samples/s | 66.6 steps/s
[Step=75450 Epoch=719.1] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.167 | 2387.7 samples/s | 37.3 steps/s
[Step=75500 Epoch=719.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.257 | L2-Norm(final)=11.167 | 4202.0 samples/s | 65.7 steps/s
[Step=75550 Epoch=720.1] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.248 | L2-Norm(final)=11.168 | 6945.6 samples/s | 108.5 steps/s
[Step=75600 Epoch=720.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.240 | L2-Norm(final)=11.169 | 1923.7 samples/s | 30.1 steps/s
[Step=75650 Epoch=721.0] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.231 | L2-Norm(final)=11.170 | 6293.7 samples/s | 98.3 steps/s
[Step=75700 Epoch=721.5] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=11.171 | 1998.4 samples/s | 31.2 steps/s
[Step=75750 Epoch=722.0] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.213 | L2-Norm(final)=11.172 | 5698.2 samples/s | 89.0 steps/s
[Step=75800 Epoch=722.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.204 | L2-Norm(final)=11.172 | 2071.7 samples/s | 32.4 steps/s
[Step=75850 Epoch=722.9] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.195 | L2-Norm(final)=11.173 | 5242.3 samples/s | 81.9 steps/s
[Step=75900 Epoch=723.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.186 | L2-Norm(final)=11.174 | 2135.5 samples/s | 33.4 steps/s
[Step=75950 Epoch=723.9] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.177 | L2-Norm(final)=11.175 | 4882.9 samples/s | 76.3 steps/s
[Step=76000 Epoch=724.3] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=11.176 | 2205.6 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10693 | acc=0.9573 | tpr=0.9733 | fpr=0.0776 | 4858.5 samples/s | 19.0 steps/s
Avg test loss: 0.11152, Avg test acc: 0.95504, Avg tpr: 0.97138, Avg fpr: 0.08089, total FA: 631

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11542 | acc=0.9562 | tpr=0.9762 | fpr=0.0872 | 4894.1 samples/s | 19.1 steps/s
Avg test loss: 0.11502, Avg test acc: 0.95621, Avg tpr: 0.97581, Avg fpr: 0.08691, total FA: 678

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11066 | acc=0.9578 | tpr=0.9691 | fpr=0.0667 | 4923.2 samples/s | 19.2 steps/s
Avg test loss: 0.11364, Avg test acc: 0.95557, Avg tpr: 0.96596, Avg fpr: 0.06730, total FA: 525

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10129 | acc=0.9564 | tpr=0.9711 | fpr=0.0756 | 4705.8 samples/s | 18.4 steps/s
Avg test loss: 0.10482, Avg test acc: 0.95633, Avg tpr: 0.97278, Avg fpr: 0.07986, total FA: 623

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11307 | acc=0.9564 | tpr=0.9691 | fpr=0.0711 | 4938.6 samples/s | 19.3 steps/s
Avg test loss: 0.11722, Avg test acc: 0.95589, Avg tpr: 0.96911, Avg fpr: 0.07320, total FA: 571

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.28098 | acc=0.3048 | tpr=0.0062 | fpr=0.0468 | 4875.4 samples/s | 19.0 steps/s
Avg test loss: 5.28999, Avg test acc: 0.30367, Avg tpr: 0.00775, Avg fpr: 0.04551, total FA: 355

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.78436 | acc=0.3061 | tpr=0.0033 | fpr=0.0364 | 4931.8 samples/s | 19.3 steps/s
Avg test loss: 4.79901, Avg test acc: 0.30323, Avg tpr: 0.00326, Avg fpr: 0.03705, total FA: 289

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.95696 | acc=0.2930 | tpr=0.0081 | fpr=0.0882 | 4896.5 samples/s | 19.1 steps/s
Avg test loss: 4.95991, Avg test acc: 0.29169, Avg tpr: 0.00927, Avg fpr: 0.08717, total FA: 680

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.58531 | acc=0.2984 | tpr=0.0151 | fpr=0.0862 | 4942.5 samples/s | 19.3 steps/s
Avg test loss: 5.58407, Avg test acc: 0.29694, Avg tpr: 0.01620, Avg fpr: 0.08563, total FA: 668

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.86223 | acc=0.3014 | tpr=0.0094 | fpr=0.0644 | 4851.1 samples/s | 18.9 steps/s
Avg test loss: 4.86981, Avg test acc: 0.29914, Avg tpr: 0.00973, Avg fpr: 0.06435, total FA: 502

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.80517 | acc=0.0992 | tpr=0.5973 | fpr=0.9097 | 4863.4 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.77083 | acc=0.1012 | tpr=0.5885 | fpr=0.9079 | 6957.0 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.78400 | acc=0.1015 | tpr=0.5908 | fpr=0.9075 | 7972.6 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.77659 | acc=0.1010 | tpr=0.5836 | fpr=0.9078 | 7843.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.77741 | acc=0.1018 | tpr=0.5930 | fpr=0.9072 | 7852.1 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.77183 | acc=0.1018 | tpr=0.5985 | fpr=0.9072 | 7735.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=5.76375 | acc=0.1016 | tpr=0.5936 | fpr=0.9074 | 7597.5 samples/s | 29.7 steps/s
[Step= 400] | Loss=5.76107 | acc=0.1018 | tpr=0.5886 | fpr=0.9070 | 8173.5 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.76541 | acc=0.1023 | tpr=0.5871 | fpr=0.9065 | 7778.6 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.76890 | acc=0.1022 | tpr=0.5833 | fpr=0.9065 | 7895.7 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.77190 | acc=0.1020 | tpr=0.5794 | fpr=0.9066 | 10252.8 samples/s | 40.1 steps/s
Avg test loss: 5.77355, Avg test acc: 0.10195, Avg tpr: 0.57924, Avg fpr: 0.90673, total FA: 125897

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.84730 | acc=0.0885 | tpr=0.5044 | fpr=0.9190 | 5024.9 samples/s | 19.6 steps/s
[Step= 100] | Loss=5.82596 | acc=0.0893 | tpr=0.5224 | fpr=0.9188 | 7273.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.82506 | acc=0.0897 | tpr=0.5245 | fpr=0.9183 | 7254.3 samples/s | 28.3 steps/s
[Step= 200] | Loss=5.81873 | acc=0.0892 | tpr=0.5169 | fpr=0.9186 | 7614.5 samples/s | 29.7 steps/s
[Step= 250] | Loss=5.82310 | acc=0.0893 | tpr=0.5240 | fpr=0.9186 | 7790.6 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.81745 | acc=0.0892 | tpr=0.5273 | fpr=0.9188 | 7902.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.81138 | acc=0.0893 | tpr=0.5241 | fpr=0.9186 | 8182.0 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.80773 | acc=0.0893 | tpr=0.5213 | fpr=0.9185 | 7575.6 samples/s | 29.6 steps/s
[Step= 450] | Loss=5.81266 | acc=0.0893 | tpr=0.5204 | fpr=0.9186 | 7978.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.81617 | acc=0.0892 | tpr=0.5145 | fpr=0.9185 | 7527.5 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.82172 | acc=0.0889 | tpr=0.5117 | fpr=0.9188 | 9118.6 samples/s | 35.6 steps/s
Avg test loss: 5.82413, Avg test acc: 0.08880, Avg tpr: 0.51109, Avg fpr: 0.91888, total FA: 127584

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.89869 | acc=0.0975 | tpr=0.2876 | fpr=0.9059 | 4884.9 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.86500 | acc=0.0998 | tpr=0.2921 | fpr=0.9038 | 7195.9 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.87570 | acc=0.1005 | tpr=0.2839 | fpr=0.9029 | 7554.0 samples/s | 29.5 steps/s
[Step= 200] | Loss=5.86877 | acc=0.1008 | tpr=0.2809 | fpr=0.9025 | 7847.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.86943 | acc=0.1015 | tpr=0.2908 | fpr=0.9019 | 7610.7 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.86329 | acc=0.1020 | tpr=0.3011 | fpr=0.9016 | 8001.4 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.85623 | acc=0.1024 | tpr=0.2993 | fpr=0.9012 | 7809.3 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.85249 | acc=0.1026 | tpr=0.3014 | fpr=0.9010 | 7749.6 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.85813 | acc=0.1028 | tpr=0.2970 | fpr=0.9007 | 7965.5 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.85917 | acc=0.1026 | tpr=0.2982 | fpr=0.9009 | 6073.7 samples/s | 23.7 steps/s
[Step= 550] | Loss=5.86321 | acc=0.1024 | tpr=0.2984 | fpr=0.9012 | 11827.2 samples/s | 46.2 steps/s
Avg test loss: 5.86453, Avg test acc: 0.10228, Avg tpr: 0.29913, Avg fpr: 0.90129, total FA: 125143

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.49001 | acc=0.1037 | tpr=0.5354 | fpr=0.9041 | 4688.8 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.47128 | acc=0.1036 | tpr=0.5245 | fpr=0.9042 | 7368.6 samples/s | 28.8 steps/s
[Step= 150] | Loss=5.48925 | acc=0.1024 | tpr=0.5375 | fpr=0.9056 | 7808.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.47805 | acc=0.1015 | tpr=0.5344 | fpr=0.9064 | 8188.7 samples/s | 32.0 steps/s
[Step= 250] | Loss=5.48055 | acc=0.1025 | tpr=0.5441 | fpr=0.9056 | 7794.7 samples/s | 30.4 steps/s
[Step= 300] | Loss=5.47709 | acc=0.1021 | tpr=0.5505 | fpr=0.9060 | 7674.9 samples/s | 30.0 steps/s
[Step= 350] | Loss=5.46662 | acc=0.1021 | tpr=0.5498 | fpr=0.9061 | 7770.4 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.46218 | acc=0.1019 | tpr=0.5443 | fpr=0.9062 | 7778.9 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.46836 | acc=0.1018 | tpr=0.5414 | fpr=0.9062 | 7977.3 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.46929 | acc=0.1016 | tpr=0.5344 | fpr=0.9062 | 5599.2 samples/s | 21.9 steps/s
[Step= 550] | Loss=5.47406 | acc=0.1012 | tpr=0.5296 | fpr=0.9066 | 14908.2 samples/s | 58.2 steps/s
Avg test loss: 5.47484, Avg test acc: 0.10112, Avg tpr: 0.52932, Avg fpr: 0.90666, total FA: 125888

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.04091 | acc=0.1159 | tpr=0.4513 | fpr=0.8902 | 4820.3 samples/s | 18.8 steps/s
[Step= 100] | Loss=6.02141 | acc=0.1168 | tpr=0.4435 | fpr=0.8893 | 6784.8 samples/s | 26.5 steps/s
[Step= 150] | Loss=6.01907 | acc=0.1170 | tpr=0.4524 | fpr=0.8892 | 7980.3 samples/s | 31.2 steps/s
[Step= 200] | Loss=6.01596 | acc=0.1165 | tpr=0.4361 | fpr=0.8893 | 7823.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.01967 | acc=0.1178 | tpr=0.4445 | fpr=0.8882 | 7953.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.02006 | acc=0.1178 | tpr=0.4502 | fpr=0.8883 | 8152.0 samples/s | 31.8 steps/s
[Step= 350] | Loss=6.01147 | acc=0.1181 | tpr=0.4471 | fpr=0.8879 | 7818.1 samples/s | 30.5 steps/s
[Step= 400] | Loss=6.00905 | acc=0.1181 | tpr=0.4447 | fpr=0.8878 | 7766.1 samples/s | 30.3 steps/s
[Step= 450] | Loss=6.01376 | acc=0.1184 | tpr=0.4416 | fpr=0.8875 | 7734.6 samples/s | 30.2 steps/s
[Step= 500] | Loss=6.01605 | acc=0.1183 | tpr=0.4374 | fpr=0.8875 | 6059.9 samples/s | 23.7 steps/s
[Step= 550] | Loss=6.02154 | acc=0.1179 | tpr=0.4393 | fpr=0.8879 | 13542.9 samples/s | 52.9 steps/s
Avg test loss: 6.02385, Avg test acc: 0.11782, Avg tpr: 0.43899, Avg fpr: 0.88801, total FA: 123299

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10808 | acc=0.9791 | tpr=0.9558 | fpr=0.0204 | 4686.0 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.10892 | acc=0.9792 | tpr=0.9488 | fpr=0.0202 | 7166.9 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.11439 | acc=0.9781 | tpr=0.9481 | fpr=0.0214 | 8061.7 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.11613 | acc=0.9782 | tpr=0.9552 | fpr=0.0214 | 7663.4 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.11425 | acc=0.9786 | tpr=0.9528 | fpr=0.0210 | 7794.3 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.11688 | acc=0.9781 | tpr=0.9520 | fpr=0.0214 | 7938.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.11845 | acc=0.9779 | tpr=0.9512 | fpr=0.0217 | 7691.3 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.11935 | acc=0.9777 | tpr=0.9486 | fpr=0.0218 | 8011.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.12167 | acc=0.9772 | tpr=0.9445 | fpr=0.0222 | 6135.9 samples/s | 24.0 steps/s
[Step= 500] | Loss=0.12075 | acc=0.9773 | tpr=0.9467 | fpr=0.0221 | 7417.2 samples/s | 29.0 steps/s
[Step= 550] | Loss=0.12011 | acc=0.9775 | tpr=0.9451 | fpr=0.0219 | 13317.1 samples/s | 52.0 steps/s
Avg test loss: 0.11990, Avg test acc: 0.97755, Avg tpr: 0.94532, Avg fpr: 0.02187, total FA: 3036

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08050 | acc=0.9826 | tpr=0.9336 | fpr=0.0165 | 4767.1 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.08287 | acc=0.9828 | tpr=0.9296 | fpr=0.0162 | 6873.4 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.08611 | acc=0.9822 | tpr=0.9308 | fpr=0.0168 | 8147.2 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.08828 | acc=0.9823 | tpr=0.9355 | fpr=0.0169 | 7886.7 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.08673 | acc=0.9826 | tpr=0.9362 | fpr=0.0165 | 7625.6 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.08851 | acc=0.9824 | tpr=0.9353 | fpr=0.0168 | 8036.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.08918 | acc=0.9821 | tpr=0.9355 | fpr=0.0171 | 7833.2 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.09027 | acc=0.9819 | tpr=0.9316 | fpr=0.0172 | 7716.1 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.09228 | acc=0.9816 | tpr=0.9294 | fpr=0.0174 | 5974.1 samples/s | 23.3 steps/s
[Step= 500] | Loss=0.09154 | acc=0.9817 | tpr=0.9308 | fpr=0.0174 | 8683.3 samples/s | 33.9 steps/s
[Step= 550] | Loss=0.09125 | acc=0.9818 | tpr=0.9280 | fpr=0.0172 | 12855.1 samples/s | 50.2 steps/s
Avg test loss: 0.09116, Avg test acc: 0.98182, Avg tpr: 0.92829, Avg fpr: 0.01721, total FA: 2389

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08352 | acc=0.9802 | tpr=0.9646 | fpr=0.0195 | 4703.9 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.08534 | acc=0.9803 | tpr=0.9701 | fpr=0.0195 | 7163.9 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.08960 | acc=0.9794 | tpr=0.9669 | fpr=0.0203 | 7952.2 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09098 | acc=0.9798 | tpr=0.9716 | fpr=0.0201 | 7911.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.08963 | acc=0.9801 | tpr=0.9703 | fpr=0.0197 | 7677.1 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.09162 | acc=0.9798 | tpr=0.9673 | fpr=0.0200 | 7687.2 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.09236 | acc=0.9795 | tpr=0.9681 | fpr=0.0203 | 8147.2 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.09332 | acc=0.9793 | tpr=0.9644 | fpr=0.0204 | 7562.4 samples/s | 29.5 steps/s
[Step= 450] | Loss=0.09479 | acc=0.9791 | tpr=0.9620 | fpr=0.0206 | 5720.3 samples/s | 22.3 steps/s
[Step= 500] | Loss=0.09430 | acc=0.9791 | tpr=0.9634 | fpr=0.0207 | 7841.6 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09386 | acc=0.9793 | tpr=0.9622 | fpr=0.0204 | 14354.4 samples/s | 56.1 steps/s
Avg test loss: 0.09376, Avg test acc: 0.97927, Avg tpr: 0.96236, Avg fpr: 0.02043, total FA: 2836

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09511 | acc=0.9802 | tpr=0.9469 | fpr=0.0192 | 4725.6 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.09679 | acc=0.9804 | tpr=0.9552 | fpr=0.0191 | 7271.6 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.10075 | acc=0.9793 | tpr=0.9510 | fpr=0.0202 | 7631.5 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.10180 | acc=0.9794 | tpr=0.9563 | fpr=0.0201 | 7831.2 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.10033 | acc=0.9799 | tpr=0.9546 | fpr=0.0196 | 7959.1 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10248 | acc=0.9797 | tpr=0.9520 | fpr=0.0198 | 7907.7 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.10332 | acc=0.9795 | tpr=0.9530 | fpr=0.0200 | 7778.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10395 | acc=0.9794 | tpr=0.9508 | fpr=0.0201 | 8069.1 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.10583 | acc=0.9792 | tpr=0.9489 | fpr=0.0203 | 6596.4 samples/s | 25.8 steps/s
[Step= 500] | Loss=0.10506 | acc=0.9794 | tpr=0.9498 | fpr=0.0201 | 7759.0 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.10455 | acc=0.9795 | tpr=0.9495 | fpr=0.0199 | 13560.6 samples/s | 53.0 steps/s
Avg test loss: 0.10435, Avg test acc: 0.97954, Avg tpr: 0.94968, Avg fpr: 0.01992, total FA: 2766

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08406 | acc=0.9818 | tpr=0.9204 | fpr=0.0171 | 4504.5 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.08787 | acc=0.9813 | tpr=0.9296 | fpr=0.0177 | 7741.8 samples/s | 30.2 steps/s
[Step= 150] | Loss=0.09054 | acc=0.9805 | tpr=0.9337 | fpr=0.0187 | 8019.9 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.09179 | acc=0.9803 | tpr=0.9432 | fpr=0.0190 | 7766.7 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.09037 | acc=0.9807 | tpr=0.9415 | fpr=0.0186 | 7830.5 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09229 | acc=0.9805 | tpr=0.9382 | fpr=0.0188 | 7733.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.09273 | acc=0.9803 | tpr=0.9405 | fpr=0.0190 | 8213.2 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.09396 | acc=0.9800 | tpr=0.9360 | fpr=0.0192 | 7578.5 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.09596 | acc=0.9798 | tpr=0.9348 | fpr=0.0194 | 8091.5 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.09540 | acc=0.9798 | tpr=0.9357 | fpr=0.0194 | 7555.0 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.09510 | acc=0.9800 | tpr=0.9355 | fpr=0.0192 | 14822.6 samples/s | 57.9 steps/s
Avg test loss: 0.09497, Avg test acc: 0.98003, Avg tpr: 0.93502, Avg fpr: 0.01915, total FA: 2659

server round 38/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=370.6] | Loss=0.00883 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=19.306 | 5373.1 samples/s | 84.0 steps/s
[Step=76050 Epoch=370.8] | Loss=0.00524 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=19.314 | 4445.6 samples/s | 69.5 steps/s
[Step=76100 Epoch=371.1] | Loss=0.00501 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=19.326 | 5093.5 samples/s | 79.6 steps/s
[Step=76150 Epoch=371.3] | Loss=0.00482 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=19.337 | 4964.5 samples/s | 77.6 steps/s
[Step=76200 Epoch=371.6] | Loss=0.00477 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=19.347 | 7697.2 samples/s | 120.3 steps/s
[Step=76250 Epoch=371.8] | Loss=0.00455 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=19.358 | 2180.9 samples/s | 34.1 steps/s
[Step=76300 Epoch=372.1] | Loss=0.00444 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=19.368 | 5026.2 samples/s | 78.5 steps/s
[Step=76350 Epoch=372.3] | Loss=0.00444 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.033 | L2-Norm(final)=19.377 | 5102.3 samples/s | 79.7 steps/s
[Step=76400 Epoch=372.5] | Loss=0.00440 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=19.387 | 6854.3 samples/s | 107.1 steps/s
[Step=76450 Epoch=372.8] | Loss=0.00432 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=19.397 | 2335.3 samples/s | 36.5 steps/s
[Step=76500 Epoch=373.0] | Loss=0.00426 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=19.407 | 4921.6 samples/s | 76.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=373.0] | Loss=0.00225 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=19.503 | 5258.7 samples/s | 82.2 steps/s
[Step=76550 Epoch=373.3] | Loss=0.00543 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=19.512 | 4011.3 samples/s | 62.7 steps/s
[Step=76600 Epoch=373.5] | Loss=0.00629 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=19.522 | 4487.8 samples/s | 70.1 steps/s
[Step=76650 Epoch=373.8] | Loss=0.00639 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=19.530 | 4516.3 samples/s | 70.6 steps/s
[Step=76700 Epoch=374.0] | Loss=0.00615 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=19.537 | 6445.1 samples/s | 100.7 steps/s
[Step=76750 Epoch=374.2] | Loss=0.00577 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=19.544 | 2079.9 samples/s | 32.5 steps/s
[Step=76800 Epoch=374.5] | Loss=0.00581 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.119 | L2-Norm(final)=19.551 | 4459.5 samples/s | 69.7 steps/s
[Step=76850 Epoch=374.7] | Loss=0.00568 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=19.557 | 4475.8 samples/s | 69.9 steps/s
[Step=76900 Epoch=375.0] | Loss=0.00541 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=19.563 | 5818.4 samples/s | 90.9 steps/s
[Step=76950 Epoch=375.2] | Loss=0.00519 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=19.569 | 2141.9 samples/s | 33.5 steps/s
[Step=77000 Epoch=375.5] | Loss=0.00500 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=19.575 | 4424.4 samples/s | 69.1 steps/s
[Step=77050 Epoch=375.7] | Loss=0.00482 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=19.580 | 4475.0 samples/s | 69.9 steps/s
[Step=77100 Epoch=376.0] | Loss=0.00464 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=19.585 | 5420.7 samples/s | 84.7 steps/s
[Step=77150 Epoch=376.2] | Loss=0.00442 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.140 | L2-Norm(final)=19.590 | 2259.2 samples/s | 35.3 steps/s
[Step=77200 Epoch=376.4] | Loss=0.00433 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.142 | L2-Norm(final)=19.594 | 4472.3 samples/s | 69.9 steps/s
[Step=77250 Epoch=376.7] | Loss=0.00422 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=19.598 | 4310.1 samples/s | 67.3 steps/s
[Step=77300 Epoch=376.9] | Loss=0.00418 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.144 | L2-Norm(final)=19.603 | 4978.8 samples/s | 77.8 steps/s
[Step=77350 Epoch=377.2] | Loss=0.00407 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.145 | L2-Norm(final)=19.607 | 2357.0 samples/s | 36.8 steps/s
[Step=77400 Epoch=377.4] | Loss=0.00398 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.146 | L2-Norm(final)=19.610 | 4454.7 samples/s | 69.6 steps/s
[Step=77450 Epoch=377.7] | Loss=0.00389 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=19.614 | 4457.5 samples/s | 69.6 steps/s
[Step=77500 Epoch=377.9] | Loss=0.00382 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.147 | L2-Norm(final)=19.618 | 4561.3 samples/s | 71.3 steps/s
[Step=77550 Epoch=378.1] | Loss=0.00375 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.148 | L2-Norm(final)=19.622 | 2403.2 samples/s | 37.5 steps/s
[Step=77600 Epoch=378.4] | Loss=0.00371 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=19.625 | 4409.3 samples/s | 68.9 steps/s
[Step=77650 Epoch=378.6] | Loss=0.00367 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.149 | L2-Norm(final)=19.629 | 4502.6 samples/s | 70.4 steps/s
[Step=77700 Epoch=378.9] | Loss=0.00362 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=19.632 | 4419.1 samples/s | 69.0 steps/s
[Step=77750 Epoch=379.1] | Loss=0.00355 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=19.635 | 2470.6 samples/s | 38.6 steps/s
[Step=77800 Epoch=379.4] | Loss=0.00353 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=19.639 | 4448.2 samples/s | 69.5 steps/s
[Step=77850 Epoch=379.6] | Loss=0.00348 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=19.642 | 4594.8 samples/s | 71.8 steps/s
[Step=77900 Epoch=379.9] | Loss=0.00342 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=19.645 | 4374.0 samples/s | 68.3 steps/s
[Step=77950 Epoch=380.1] | Loss=0.00335 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=19.648 | 2399.0 samples/s | 37.5 steps/s
[Step=78000 Epoch=380.3] | Loss=0.00329 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=19.651 | 4417.4 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step78000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=370.8] | Loss=0.01042 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.587 | L2-Norm(final)=20.095 | 5384.6 samples/s | 84.1 steps/s
[Step=76050 Epoch=371.1] | Loss=0.00426 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=20.103 | 4495.0 samples/s | 70.2 steps/s
[Step=76100 Epoch=371.3] | Loss=0.00414 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=20.115 | 4852.6 samples/s | 75.8 steps/s
[Step=76150 Epoch=371.6] | Loss=0.00424 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=20.127 | 5057.5 samples/s | 79.0 steps/s
[Step=76200 Epoch=371.8] | Loss=0.00403 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=20.139 | 7953.5 samples/s | 124.3 steps/s
[Step=76250 Epoch=372.1] | Loss=0.00413 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.610 | L2-Norm(final)=20.151 | 2211.6 samples/s | 34.6 steps/s
[Step=76300 Epoch=372.3] | Loss=0.00406 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=20.162 | 4944.0 samples/s | 77.2 steps/s
[Step=76350 Epoch=372.6] | Loss=0.00393 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=20.173 | 5108.3 samples/s | 79.8 steps/s
[Step=76400 Epoch=372.8] | Loss=0.00385 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=20.183 | 6801.4 samples/s | 106.3 steps/s
[Step=76450 Epoch=373.0] | Loss=0.00379 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=20.194 | 2282.8 samples/s | 35.7 steps/s
[Step=76500 Epoch=373.3] | Loss=0.00373 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=20.204 | 5061.3 samples/s | 79.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=373.3] | Loss=0.00152 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=20.308 | 5304.7 samples/s | 82.9 steps/s
[Step=76550 Epoch=373.5] | Loss=0.00560 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=20.316 | 4100.4 samples/s | 64.1 steps/s
[Step=76600 Epoch=373.8] | Loss=0.00698 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=20.325 | 4371.4 samples/s | 68.3 steps/s
[Step=76650 Epoch=374.0] | Loss=0.00717 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=20.334 | 4468.3 samples/s | 69.8 steps/s
[Step=76700 Epoch=374.3] | Loss=0.00674 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.697 | L2-Norm(final)=20.343 | 6598.5 samples/s | 103.1 steps/s
[Step=76750 Epoch=374.5] | Loss=0.00652 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.704 | L2-Norm(final)=20.351 | 2118.3 samples/s | 33.1 steps/s
[Step=76800 Epoch=374.7] | Loss=0.00595 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=20.358 | 4362.0 samples/s | 68.2 steps/s
[Step=76850 Epoch=375.0] | Loss=0.00564 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.715 | L2-Norm(final)=20.365 | 4481.4 samples/s | 70.0 steps/s
[Step=76900 Epoch=375.2] | Loss=0.00535 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=20.372 | 6060.3 samples/s | 94.7 steps/s
[Step=76950 Epoch=375.5] | Loss=0.00511 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.723 | L2-Norm(final)=20.378 | 2131.0 samples/s | 33.3 steps/s
[Step=77000 Epoch=375.7] | Loss=0.00476 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.726 | L2-Norm(final)=20.383 | 4424.4 samples/s | 69.1 steps/s
[Step=77050 Epoch=376.0] | Loss=0.00454 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.728 | L2-Norm(final)=20.388 | 4475.2 samples/s | 69.9 steps/s
[Step=77100 Epoch=376.2] | Loss=0.00448 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=20.393 | 5609.4 samples/s | 87.6 steps/s
[Step=77150 Epoch=376.5] | Loss=0.00425 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.732 | L2-Norm(final)=20.398 | 2239.2 samples/s | 35.0 steps/s
[Step=77200 Epoch=376.7] | Loss=0.00402 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=20.402 | 4361.4 samples/s | 68.1 steps/s
[Step=77250 Epoch=376.9] | Loss=0.00394 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=20.407 | 4490.6 samples/s | 70.2 steps/s
[Step=77300 Epoch=377.2] | Loss=0.00387 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.736 | L2-Norm(final)=20.411 | 5169.6 samples/s | 80.8 steps/s
[Step=77350 Epoch=377.4] | Loss=0.00375 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.737 | L2-Norm(final)=20.415 | 2223.6 samples/s | 34.7 steps/s
[Step=77400 Epoch=377.7] | Loss=0.00367 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.737 | L2-Norm(final)=20.419 | 4466.0 samples/s | 69.8 steps/s
[Step=77450 Epoch=377.9] | Loss=0.00357 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.738 | L2-Norm(final)=20.423 | 4566.1 samples/s | 71.3 steps/s
[Step=77500 Epoch=378.2] | Loss=0.00352 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=20.426 | 4769.1 samples/s | 74.5 steps/s
[Step=77550 Epoch=378.4] | Loss=0.00341 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=20.430 | 2352.1 samples/s | 36.8 steps/s
[Step=77600 Epoch=378.7] | Loss=0.00333 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=20.434 | 4477.8 samples/s | 70.0 steps/s
[Step=77650 Epoch=378.9] | Loss=0.00325 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=20.437 | 4436.6 samples/s | 69.3 steps/s
[Step=77700 Epoch=379.1] | Loss=0.00319 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=20.441 | 4528.2 samples/s | 70.8 steps/s
[Step=77750 Epoch=379.4] | Loss=0.00319 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=20.445 | 2424.8 samples/s | 37.9 steps/s
[Step=77800 Epoch=379.6] | Loss=0.00314 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=20.448 | 4497.6 samples/s | 70.3 steps/s
[Step=77850 Epoch=379.9] | Loss=0.00312 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.740 | L2-Norm(final)=20.451 | 4446.2 samples/s | 69.5 steps/s
[Step=77900 Epoch=380.1] | Loss=0.00308 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.740 | L2-Norm(final)=20.455 | 4502.8 samples/s | 70.4 steps/s
[Step=77950 Epoch=380.4] | Loss=0.00306 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=20.458 | 2458.0 samples/s | 38.4 steps/s
[Step=78000 Epoch=380.6] | Loss=0.00301 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=20.461 | 4290.8 samples/s | 67.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step78000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=370.3] | Loss=0.00539 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=20.167 | 4525.5 samples/s | 70.7 steps/s
[Step=76050 Epoch=370.6] | Loss=0.00480 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.380 | L2-Norm(final)=20.176 | 2887.7 samples/s | 45.1 steps/s
[Step=76100 Epoch=370.8] | Loss=0.00493 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.384 | L2-Norm(final)=20.187 | 5097.4 samples/s | 79.6 steps/s
[Step=76150 Epoch=371.0] | Loss=0.00453 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=20.197 | 4724.2 samples/s | 73.8 steps/s
[Step=76200 Epoch=371.3] | Loss=0.00455 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=20.208 | 7914.9 samples/s | 123.7 steps/s
[Step=76250 Epoch=371.5] | Loss=0.00448 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=20.219 | 2180.1 samples/s | 34.1 steps/s
[Step=76300 Epoch=371.8] | Loss=0.00444 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=20.230 | 4981.7 samples/s | 77.8 steps/s
[Step=76350 Epoch=372.0] | Loss=0.00428 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=20.240 | 4993.1 samples/s | 78.0 steps/s
[Step=76400 Epoch=372.3] | Loss=0.00433 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.407 | L2-Norm(final)=20.250 | 6881.1 samples/s | 107.5 steps/s
[Step=76450 Epoch=372.5] | Loss=0.00425 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=20.261 | 2303.7 samples/s | 36.0 steps/s
[Step=76500 Epoch=372.7] | Loss=0.00417 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=20.271 | 5130.6 samples/s | 80.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=372.7] | Loss=0.00396 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.447 | L2-Norm(final)=20.371 | 5168.1 samples/s | 80.8 steps/s
[Step=76550 Epoch=373.0] | Loss=0.00445 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=20.381 | 4146.7 samples/s | 64.8 steps/s
[Step=76600 Epoch=373.2] | Loss=0.00671 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=20.390 | 4472.0 samples/s | 69.9 steps/s
[Step=76650 Epoch=373.5] | Loss=0.00646 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.470 | L2-Norm(final)=20.399 | 4441.9 samples/s | 69.4 steps/s
[Step=76700 Epoch=373.7] | Loss=0.00643 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.477 | L2-Norm(final)=20.407 | 6479.5 samples/s | 101.2 steps/s
[Step=76750 Epoch=374.0] | Loss=0.00601 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.484 | L2-Norm(final)=20.415 | 2109.1 samples/s | 33.0 steps/s
[Step=76800 Epoch=374.2] | Loss=0.00583 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.489 | L2-Norm(final)=20.422 | 4425.2 samples/s | 69.1 steps/s
[Step=76850 Epoch=374.4] | Loss=0.00550 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.493 | L2-Norm(final)=20.428 | 4519.5 samples/s | 70.6 steps/s
[Step=76900 Epoch=374.7] | Loss=0.00526 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=20.434 | 5848.7 samples/s | 91.4 steps/s
[Step=76950 Epoch=374.9] | Loss=0.00503 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.500 | L2-Norm(final)=20.440 | 2164.2 samples/s | 33.8 steps/s
[Step=77000 Epoch=375.2] | Loss=0.00483 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.503 | L2-Norm(final)=20.445 | 4412.1 samples/s | 68.9 steps/s
[Step=77050 Epoch=375.4] | Loss=0.00470 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=20.450 | 4447.1 samples/s | 69.5 steps/s
[Step=77100 Epoch=375.7] | Loss=0.00464 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=20.455 | 5444.4 samples/s | 85.1 steps/s
[Step=77150 Epoch=375.9] | Loss=0.00442 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.508 | L2-Norm(final)=20.459 | 2235.9 samples/s | 34.9 steps/s
[Step=77200 Epoch=376.2] | Loss=0.00419 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.510 | L2-Norm(final)=20.464 | 4469.4 samples/s | 69.8 steps/s
[Step=77250 Epoch=376.4] | Loss=0.00407 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=20.468 | 4473.5 samples/s | 69.9 steps/s
[Step=77300 Epoch=376.6] | Loss=0.00402 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.512 | L2-Norm(final)=20.472 | 4968.6 samples/s | 77.6 steps/s
[Step=77350 Epoch=376.9] | Loss=0.00394 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.512 | L2-Norm(final)=20.476 | 2308.3 samples/s | 36.1 steps/s
[Step=77400 Epoch=377.1] | Loss=0.00385 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.513 | L2-Norm(final)=20.479 | 4483.0 samples/s | 70.0 steps/s
[Step=77450 Epoch=377.4] | Loss=0.00377 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=20.483 | 4559.0 samples/s | 71.2 steps/s
[Step=77500 Epoch=377.6] | Loss=0.00371 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.487 | 4503.5 samples/s | 70.4 steps/s
[Step=77550 Epoch=377.9] | Loss=0.00364 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.490 | 2437.2 samples/s | 38.1 steps/s
[Step=77600 Epoch=378.1] | Loss=0.00360 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.494 | 4479.8 samples/s | 70.0 steps/s
[Step=77650 Epoch=378.3] | Loss=0.00356 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.497 | 4503.9 samples/s | 70.4 steps/s
[Step=77700 Epoch=378.6] | Loss=0.00349 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.501 | 4397.0 samples/s | 68.7 steps/s
[Step=77750 Epoch=378.8] | Loss=0.00343 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.504 | 2439.8 samples/s | 38.1 steps/s
[Step=77800 Epoch=379.1] | Loss=0.00336 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.514 | L2-Norm(final)=20.507 | 4434.1 samples/s | 69.3 steps/s
[Step=77850 Epoch=379.3] | Loss=0.00329 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=20.511 | 4461.7 samples/s | 69.7 steps/s
[Step=77900 Epoch=379.6] | Loss=0.00327 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=20.514 | 4503.8 samples/s | 70.4 steps/s
[Step=77950 Epoch=379.8] | Loss=0.00326 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=20.517 | 2441.0 samples/s | 38.1 steps/s
[Step=78000 Epoch=380.1] | Loss=0.00324 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.512 | L2-Norm(final)=20.520 | 4493.5 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step78000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=370.6] | Loss=0.00560 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=20.220 | 5255.6 samples/s | 82.1 steps/s
[Step=76050 Epoch=370.9] | Loss=0.00500 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.049 | L2-Norm(final)=20.231 | 4418.1 samples/s | 69.0 steps/s
[Step=76100 Epoch=371.1] | Loss=0.00444 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.055 | L2-Norm(final)=20.244 | 5129.6 samples/s | 80.1 steps/s
[Step=76150 Epoch=371.4] | Loss=0.00432 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=20.257 | 4958.9 samples/s | 77.5 steps/s
[Step=76200 Epoch=371.6] | Loss=0.00437 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=20.269 | 7913.7 samples/s | 123.7 steps/s
[Step=76250 Epoch=371.8] | Loss=0.00426 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=20.281 | 2216.4 samples/s | 34.6 steps/s
[Step=76300 Epoch=372.1] | Loss=0.00416 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=20.292 | 5118.3 samples/s | 80.0 steps/s
[Step=76350 Epoch=372.3] | Loss=0.00412 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.079 | L2-Norm(final)=20.304 | 4909.8 samples/s | 76.7 steps/s
[Step=76400 Epoch=372.6] | Loss=0.00403 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=20.315 | 6989.1 samples/s | 109.2 steps/s
[Step=76450 Epoch=372.8] | Loss=0.00399 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=20.326 | 2232.6 samples/s | 34.9 steps/s
[Step=76500 Epoch=373.1] | Loss=0.00397 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=20.337 | 5066.5 samples/s | 79.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=373.1] | Loss=0.00263 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=20.443 | 5557.3 samples/s | 86.8 steps/s
[Step=76550 Epoch=373.3] | Loss=0.00629 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.138 | L2-Norm(final)=20.454 | 4096.0 samples/s | 64.0 steps/s
[Step=76600 Epoch=373.5] | Loss=0.00739 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=20.464 | 4440.3 samples/s | 69.4 steps/s
[Step=76650 Epoch=373.8] | Loss=0.00748 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=20.473 | 4459.1 samples/s | 69.7 steps/s
[Step=76700 Epoch=374.0] | Loss=0.00709 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=20.481 | 6566.2 samples/s | 102.6 steps/s
[Step=76750 Epoch=374.3] | Loss=0.00627 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=20.489 | 2087.3 samples/s | 32.6 steps/s
[Step=76800 Epoch=374.5] | Loss=0.00595 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=20.496 | 4539.8 samples/s | 70.9 steps/s
[Step=76850 Epoch=374.8] | Loss=0.00547 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=20.502 | 4435.3 samples/s | 69.3 steps/s
[Step=76900 Epoch=375.0] | Loss=0.00518 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=20.508 | 5843.8 samples/s | 91.3 steps/s
[Step=76950 Epoch=375.3] | Loss=0.00491 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=20.513 | 2163.5 samples/s | 33.8 steps/s
[Step=77000 Epoch=375.5] | Loss=0.00471 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=20.518 | 4459.6 samples/s | 69.7 steps/s
[Step=77050 Epoch=375.7] | Loss=0.00454 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=20.523 | 4475.5 samples/s | 69.9 steps/s
[Step=77100 Epoch=376.0] | Loss=0.00434 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=20.527 | 5301.3 samples/s | 82.8 steps/s
[Step=77150 Epoch=376.2] | Loss=0.00418 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=20.532 | 2223.0 samples/s | 34.7 steps/s
[Step=77200 Epoch=376.5] | Loss=0.00400 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=20.536 | 4613.0 samples/s | 72.1 steps/s
[Step=77250 Epoch=376.7] | Loss=0.00390 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=20.540 | 4369.9 samples/s | 68.3 steps/s
[Step=77300 Epoch=377.0] | Loss=0.00381 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.203 | L2-Norm(final)=20.544 | 4974.8 samples/s | 77.7 steps/s
[Step=77350 Epoch=377.2] | Loss=0.00369 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=20.548 | 2364.8 samples/s | 37.0 steps/s
[Step=77400 Epoch=377.4] | Loss=0.00358 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=20.551 | 4376.6 samples/s | 68.4 steps/s
[Step=77450 Epoch=377.7] | Loss=0.00348 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.555 | 4406.3 samples/s | 68.8 steps/s
[Step=77500 Epoch=377.9] | Loss=0.00339 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.559 | 4587.4 samples/s | 71.7 steps/s
[Step=77550 Epoch=378.2] | Loss=0.00332 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.562 | 2421.7 samples/s | 37.8 steps/s
[Step=77600 Epoch=378.4] | Loss=0.00322 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.566 | 4486.6 samples/s | 70.1 steps/s
[Step=77650 Epoch=378.7] | Loss=0.00314 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.569 | 4425.4 samples/s | 69.1 steps/s
[Step=77700 Epoch=378.9] | Loss=0.00309 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.572 | 4489.0 samples/s | 70.1 steps/s
[Step=77750 Epoch=379.2] | Loss=0.00305 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.576 | 2464.0 samples/s | 38.5 steps/s
[Step=77800 Epoch=379.4] | Loss=0.00298 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.579 | 4391.9 samples/s | 68.6 steps/s
[Step=77850 Epoch=379.6] | Loss=0.00293 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.582 | 4499.5 samples/s | 70.3 steps/s
[Step=77900 Epoch=379.9] | Loss=0.00288 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.585 | 4476.6 samples/s | 69.9 steps/s
[Step=77950 Epoch=380.1] | Loss=0.00285 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.588 | 2463.8 samples/s | 38.5 steps/s
[Step=78000 Epoch=380.4] | Loss=0.00281 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=20.592 | 4499.9 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step78000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=372.7] | Loss=0.00651 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=20.293 | 5044.8 samples/s | 78.8 steps/s
[Step=76050 Epoch=372.9] | Loss=0.00463 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=20.303 | 4400.2 samples/s | 68.8 steps/s
[Step=76100 Epoch=373.2] | Loss=0.00416 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=20.314 | 5096.2 samples/s | 79.6 steps/s
[Step=76150 Epoch=373.4] | Loss=0.00407 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=20.325 | 5035.4 samples/s | 78.7 steps/s
[Step=76200 Epoch=373.7] | Loss=0.00413 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.782 | L2-Norm(final)=20.336 | 7854.5 samples/s | 122.7 steps/s
[Step=76250 Epoch=373.9] | Loss=0.00422 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=20.346 | 2209.6 samples/s | 34.5 steps/s
[Step=76300 Epoch=374.2] | Loss=0.00401 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.790 | L2-Norm(final)=20.357 | 5157.1 samples/s | 80.6 steps/s
[Step=76350 Epoch=374.4] | Loss=0.00388 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.794 | L2-Norm(final)=20.367 | 4879.5 samples/s | 76.2 steps/s
[Step=76400 Epoch=374.7] | Loss=0.00380 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.797 | L2-Norm(final)=20.377 | 7422.3 samples/s | 116.0 steps/s
[Step=76450 Epoch=374.9] | Loss=0.00373 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.801 | L2-Norm(final)=20.388 | 2262.9 samples/s | 35.4 steps/s
[Step=76500 Epoch=375.1] | Loss=0.00368 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.804 | L2-Norm(final)=20.398 | 4915.3 samples/s | 76.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=375.1] | Loss=0.00379 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=20.498 | 5617.4 samples/s | 87.8 steps/s
[Step=76550 Epoch=375.4] | Loss=0.00371 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=20.508 | 3899.7 samples/s | 60.9 steps/s
[Step=76600 Epoch=375.6] | Loss=0.00552 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.849 | L2-Norm(final)=20.516 | 4512.6 samples/s | 70.5 steps/s
[Step=76650 Epoch=375.9] | Loss=0.00599 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.858 | L2-Norm(final)=20.525 | 4388.5 samples/s | 68.6 steps/s
[Step=76700 Epoch=376.1] | Loss=0.00616 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=20.532 | 6715.9 samples/s | 104.9 steps/s
[Step=76750 Epoch=376.4] | Loss=0.00561 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.872 | L2-Norm(final)=20.539 | 2059.3 samples/s | 32.2 steps/s
[Step=76800 Epoch=376.6] | Loss=0.00539 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.877 | L2-Norm(final)=20.546 | 4408.3 samples/s | 68.9 steps/s
[Step=76850 Epoch=376.9] | Loss=0.00511 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=20.552 | 4536.3 samples/s | 70.9 steps/s
[Step=76900 Epoch=377.1] | Loss=0.00487 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=20.558 | 6159.5 samples/s | 96.2 steps/s
[Step=76950 Epoch=377.4] | Loss=0.00463 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=20.564 | 2125.6 samples/s | 33.2 steps/s
[Step=77000 Epoch=377.6] | Loss=0.00441 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.890 | L2-Norm(final)=20.569 | 4581.0 samples/s | 71.6 steps/s
[Step=77050 Epoch=377.8] | Loss=0.00424 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.892 | L2-Norm(final)=20.574 | 4406.5 samples/s | 68.9 steps/s
[Step=77100 Epoch=378.1] | Loss=0.00408 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.894 | L2-Norm(final)=20.579 | 5885.9 samples/s | 92.0 steps/s
[Step=77150 Epoch=378.3] | Loss=0.00392 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.896 | L2-Norm(final)=20.584 | 2131.5 samples/s | 33.3 steps/s
[Step=77200 Epoch=378.6] | Loss=0.00382 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.897 | L2-Norm(final)=20.588 | 4492.4 samples/s | 70.2 steps/s
[Step=77250 Epoch=378.8] | Loss=0.00371 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.898 | L2-Norm(final)=20.593 | 4516.2 samples/s | 70.6 steps/s
[Step=77300 Epoch=379.1] | Loss=0.00361 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.899 | L2-Norm(final)=20.597 | 5457.9 samples/s | 85.3 steps/s
[Step=77350 Epoch=379.3] | Loss=0.00348 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.900 | L2-Norm(final)=20.601 | 2231.9 samples/s | 34.9 steps/s
[Step=77400 Epoch=379.6] | Loss=0.00339 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.605 | 4476.4 samples/s | 69.9 steps/s
[Step=77450 Epoch=379.8] | Loss=0.00330 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.609 | 4469.0 samples/s | 69.8 steps/s
[Step=77500 Epoch=380.0] | Loss=0.00323 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.613 | 5152.2 samples/s | 80.5 steps/s
[Step=77550 Epoch=380.3] | Loss=0.00316 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=20.617 | 2277.4 samples/s | 35.6 steps/s
[Step=77600 Epoch=380.5] | Loss=0.00308 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.902 | L2-Norm(final)=20.621 | 4489.9 samples/s | 70.2 steps/s
[Step=77650 Epoch=380.8] | Loss=0.00301 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=20.624 | 4530.1 samples/s | 70.8 steps/s
[Step=77700 Epoch=381.0] | Loss=0.00296 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=20.628 | 4846.0 samples/s | 75.7 steps/s
[Step=77750 Epoch=381.3] | Loss=0.00290 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.902 | L2-Norm(final)=20.631 | 2345.4 samples/s | 36.6 steps/s
[Step=77800 Epoch=381.5] | Loss=0.00284 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.635 | 4389.3 samples/s | 68.6 steps/s
[Step=77850 Epoch=381.8] | Loss=0.00282 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.638 | 4457.4 samples/s | 69.6 steps/s
[Step=77900 Epoch=382.0] | Loss=0.00278 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=20.642 | 4675.7 samples/s | 73.1 steps/s
[Step=77950 Epoch=382.3] | Loss=0.00273 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=20.645 | 2381.0 samples/s | 37.2 steps/s
[Step=78000 Epoch=382.5] | Loss=0.00270 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=20.648 | 4501.4 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step78000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=720.2] | Loss=0.00063 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.124 | L2-Norm(final)=10.186 | 4998.7 samples/s | 78.1 steps/s
[Step=76050 Epoch=720.6] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=10.187 | 4104.3 samples/s | 64.1 steps/s
[Step=76100 Epoch=721.1] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=10.188 | 7394.1 samples/s | 115.5 steps/s
[Step=76150 Epoch=721.6] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=10.189 | 2106.9 samples/s | 32.9 steps/s
[Step=76200 Epoch=722.1] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=10.190 | 6625.0 samples/s | 103.5 steps/s
[Step=76250 Epoch=722.5] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=10.192 | 2212.3 samples/s | 34.6 steps/s
[Step=76300 Epoch=723.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=10.193 | 5896.7 samples/s | 92.1 steps/s
[Step=76350 Epoch=723.5] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=10.194 | 2299.7 samples/s | 35.9 steps/s
[Step=76400 Epoch=724.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=10.195 | 5325.9 samples/s | 83.2 steps/s
[Step=76450 Epoch=724.4] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=10.196 | 2348.3 samples/s | 36.7 steps/s
[Step=76500 Epoch=724.9] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=10.198 | 4920.6 samples/s | 76.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=724.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.210 | 5398.8 samples/s | 84.4 steps/s
[Step=76550 Epoch=725.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.212 | 3739.7 samples/s | 58.4 steps/s
[Step=76600 Epoch=725.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.213 | 6233.0 samples/s | 97.4 steps/s
[Step=76650 Epoch=726.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.214 | 2049.3 samples/s | 32.0 steps/s
[Step=76700 Epoch=726.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.215 | 5347.8 samples/s | 83.6 steps/s
[Step=76750 Epoch=727.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=10.216 | 2093.3 samples/s | 32.7 steps/s
[Step=76800 Epoch=727.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=10.217 | 5034.6 samples/s | 78.7 steps/s
[Step=76850 Epoch=728.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=10.217 | 2161.8 samples/s | 33.8 steps/s
[Step=76900 Epoch=728.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=10.218 | 4764.9 samples/s | 74.5 steps/s
[Step=76950 Epoch=729.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.132 | L2-Norm(final)=10.219 | 2242.7 samples/s | 35.0 steps/s
[Step=77000 Epoch=729.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=10.220 | 4311.6 samples/s | 67.4 steps/s
[Step=77050 Epoch=730.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=10.220 | 2362.1 samples/s | 36.9 steps/s
[Step=77100 Epoch=730.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=10.221 | 4238.3 samples/s | 66.2 steps/s
[Step=77150 Epoch=731.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=10.221 | 2442.3 samples/s | 38.2 steps/s
[Step=77200 Epoch=731.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=10.222 | 4184.5 samples/s | 65.4 steps/s
[Step=77250 Epoch=732.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=10.223 | 2376.8 samples/s | 37.1 steps/s
[Step=77300 Epoch=732.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.124 | L2-Norm(final)=10.223 | 4246.4 samples/s | 66.3 steps/s
[Step=77350 Epoch=733.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=10.224 | 2524.8 samples/s | 39.4 steps/s
[Step=77400 Epoch=733.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.121 | L2-Norm(final)=10.224 | 3796.5 samples/s | 59.3 steps/s
[Step=77450 Epoch=733.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.120 | L2-Norm(final)=10.225 | 6496.3 samples/s | 101.5 steps/s
[Step=77500 Epoch=734.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.119 | L2-Norm(final)=10.225 | 1990.1 samples/s | 31.1 steps/s
[Step=77550 Epoch=734.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.117 | L2-Norm(final)=10.226 | 5877.5 samples/s | 91.8 steps/s
[Step=77600 Epoch=735.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=10.226 | 2056.0 samples/s | 32.1 steps/s
[Step=77650 Epoch=735.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.114 | L2-Norm(final)=10.227 | 5258.3 samples/s | 82.2 steps/s
[Step=77700 Epoch=736.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=10.227 | 2151.4 samples/s | 33.6 steps/s
[Step=77750 Epoch=736.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=10.228 | 4822.1 samples/s | 75.3 steps/s
[Step=77800 Epoch=737.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.109 | L2-Norm(final)=10.228 | 2252.4 samples/s | 35.2 steps/s
[Step=77850 Epoch=737.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.107 | L2-Norm(final)=10.229 | 4385.1 samples/s | 68.5 steps/s
[Step=77900 Epoch=738.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.105 | L2-Norm(final)=10.229 | 2253.1 samples/s | 35.2 steps/s
[Step=77950 Epoch=738.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.103 | L2-Norm(final)=10.230 | 4265.7 samples/s | 66.7 steps/s
[Step=78000 Epoch=739.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.102 | L2-Norm(final)=10.230 | 2373.9 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step78000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=723.0] | Loss=0.00008 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=11.137 | 5588.6 samples/s | 87.3 steps/s
[Step=76050 Epoch=723.4] | Loss=0.00006 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.069 | L2-Norm(final)=11.153 | 3974.0 samples/s | 62.1 steps/s
[Step=76100 Epoch=723.9] | Loss=0.00005 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.079 | L2-Norm(final)=11.171 | 7616.8 samples/s | 119.0 steps/s
[Step=76150 Epoch=724.4] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=11.187 | 2119.5 samples/s | 33.1 steps/s
[Step=76200 Epoch=724.9] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.091 | L2-Norm(final)=11.199 | 6687.8 samples/s | 104.5 steps/s
[Step=76250 Epoch=725.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.095 | L2-Norm(final)=11.211 | 2225.3 samples/s | 34.8 steps/s
[Step=76300 Epoch=725.8] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.222 | 5931.8 samples/s | 92.7 steps/s
[Step=76350 Epoch=726.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.101 | L2-Norm(final)=11.232 | 2333.7 samples/s | 36.5 steps/s
[Step=76400 Epoch=726.8] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.104 | L2-Norm(final)=11.241 | 5404.8 samples/s | 84.4 steps/s
[Step=76450 Epoch=727.2] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.106 | L2-Norm(final)=11.250 | 2376.0 samples/s | 37.1 steps/s
[Step=76500 Epoch=727.7] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.108 | L2-Norm(final)=11.259 | 4947.9 samples/s | 77.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=727.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.346 | 5459.6 samples/s | 85.3 steps/s
[Step=76550 Epoch=728.2] | Loss=0.00040 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=11.354 | 3842.9 samples/s | 60.0 steps/s
[Step=76600 Epoch=728.7] | Loss=0.00028 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.146 | L2-Norm(final)=11.361 | 6301.0 samples/s | 98.5 steps/s
[Step=76650 Epoch=729.1] | Loss=0.00020 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.155 | L2-Norm(final)=11.365 | 2038.0 samples/s | 31.8 steps/s
[Step=76700 Epoch=729.6] | Loss=0.00015 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=11.368 | 5594.3 samples/s | 87.4 steps/s
[Step=76750 Epoch=730.1] | Loss=0.00012 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=11.370 | 2075.0 samples/s | 32.4 steps/s
[Step=76800 Epoch=730.6] | Loss=0.00010 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.163 | L2-Norm(final)=11.371 | 5183.3 samples/s | 81.0 steps/s
[Step=76850 Epoch=731.0] | Loss=0.00009 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.163 | L2-Norm(final)=11.373 | 2194.6 samples/s | 34.3 steps/s
[Step=76900 Epoch=731.5] | Loss=0.00008 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.163 | L2-Norm(final)=11.374 | 4587.2 samples/s | 71.7 steps/s
[Step=76950 Epoch=732.0] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=11.374 | 2254.6 samples/s | 35.2 steps/s
[Step=77000 Epoch=732.5] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=11.375 | 4361.2 samples/s | 68.1 steps/s
[Step=77050 Epoch=732.9] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=11.376 | 2312.0 samples/s | 36.1 steps/s
[Step=77100 Epoch=733.4] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=11.377 | 4252.3 samples/s | 66.4 steps/s
[Step=77150 Epoch=733.9] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=11.377 | 2375.3 samples/s | 37.1 steps/s
[Step=77200 Epoch=734.4] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=11.378 | 4389.8 samples/s | 68.6 steps/s
[Step=77250 Epoch=734.8] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=11.378 | 2352.1 samples/s | 36.8 steps/s
[Step=77300 Epoch=735.3] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.153 | L2-Norm(final)=11.379 | 4130.7 samples/s | 64.5 steps/s
[Step=77350 Epoch=735.8] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.151 | L2-Norm(final)=11.379 | 2621.6 samples/s | 41.0 steps/s
[Step=77400 Epoch=736.3] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=11.380 | 3716.0 samples/s | 58.1 steps/s
[Step=77450 Epoch=736.7] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=11.380 | 6566.9 samples/s | 102.6 steps/s
[Step=77500 Epoch=737.2] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.145 | L2-Norm(final)=11.381 | 2026.0 samples/s | 31.7 steps/s
[Step=77550 Epoch=737.7] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.143 | L2-Norm(final)=11.381 | 5803.4 samples/s | 90.7 steps/s
[Step=77600 Epoch=738.2] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.141 | L2-Norm(final)=11.382 | 2081.8 samples/s | 32.5 steps/s
[Step=77650 Epoch=738.6] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.139 | L2-Norm(final)=11.382 | 5107.8 samples/s | 79.8 steps/s
[Step=77700 Epoch=739.1] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=11.383 | 2134.7 samples/s | 33.4 steps/s
[Step=77750 Epoch=739.6] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.383 | 4916.8 samples/s | 76.8 steps/s
[Step=77800 Epoch=740.1] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.132 | L2-Norm(final)=11.383 | 2278.4 samples/s | 35.6 steps/s
[Step=77850 Epoch=740.5] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=11.384 | 4385.2 samples/s | 68.5 steps/s
[Step=77900 Epoch=741.0] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.384 | 2301.9 samples/s | 36.0 steps/s
[Step=77950 Epoch=741.5] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.125 | L2-Norm(final)=11.385 | 4289.8 samples/s | 67.0 steps/s
[Step=78000 Epoch=742.0] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=11.385 | 2451.0 samples/s | 38.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step78000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=725.8] | Loss=0.00005 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.018 | L2-Norm(final)=10.818 | 5098.4 samples/s | 79.7 steps/s
[Step=76050 Epoch=726.2] | Loss=0.00014 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.029 | L2-Norm(final)=10.836 | 4337.9 samples/s | 67.8 steps/s
[Step=76100 Epoch=726.7] | Loss=0.00010 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.037 | L2-Norm(final)=10.848 | 6987.0 samples/s | 109.2 steps/s
[Step=76150 Epoch=727.2] | Loss=0.00008 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=10.857 | 2097.9 samples/s | 32.8 steps/s
[Step=76200 Epoch=727.7] | Loss=0.00006 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.047 | L2-Norm(final)=10.866 | 6882.3 samples/s | 107.5 steps/s
[Step=76250 Epoch=728.1] | Loss=0.00006 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.051 | L2-Norm(final)=10.873 | 2183.6 samples/s | 34.1 steps/s
[Step=76300 Epoch=728.6] | Loss=0.00005 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.054 | L2-Norm(final)=10.880 | 6286.6 samples/s | 98.2 steps/s
[Step=76350 Epoch=729.1] | Loss=0.00005 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.056 | L2-Norm(final)=10.886 | 2296.8 samples/s | 35.9 steps/s
[Step=76400 Epoch=729.6] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.059 | L2-Norm(final)=10.892 | 5455.6 samples/s | 85.2 steps/s
[Step=76450 Epoch=730.1] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.061 | L2-Norm(final)=10.898 | 2331.9 samples/s | 36.4 steps/s
[Step=76500 Epoch=730.5] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.063 | L2-Norm(final)=10.904 | 5150.8 samples/s | 80.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=730.5] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=10.958 | 5243.7 samples/s | 81.9 steps/s
[Step=76550 Epoch=731.0] | Loss=0.00030 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.092 | L2-Norm(final)=10.966 | 3815.7 samples/s | 59.6 steps/s
[Step=76600 Epoch=731.5] | Loss=0.00073 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=10.972 | 6356.6 samples/s | 99.3 steps/s
[Step=76650 Epoch=732.0] | Loss=0.00050 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.139 | L2-Norm(final)=10.975 | 2021.4 samples/s | 31.6 steps/s
[Step=76700 Epoch=732.4] | Loss=0.00038 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=10.978 | 5725.3 samples/s | 89.5 steps/s
[Step=76750 Epoch=732.9] | Loss=0.00031 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.152 | L2-Norm(final)=10.980 | 2032.5 samples/s | 31.8 steps/s
[Step=76800 Epoch=733.4] | Loss=0.00026 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=10.981 | 5381.8 samples/s | 84.1 steps/s
[Step=76850 Epoch=733.9] | Loss=0.00023 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=10.982 | 2129.4 samples/s | 33.3 steps/s
[Step=76900 Epoch=734.3] | Loss=0.00020 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=10.983 | 4944.2 samples/s | 77.3 steps/s
[Step=76950 Epoch=734.8] | Loss=0.00018 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=10.984 | 2223.1 samples/s | 34.7 steps/s
[Step=77000 Epoch=735.3] | Loss=0.00016 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=10.985 | 4532.2 samples/s | 70.8 steps/s
[Step=77050 Epoch=735.8] | Loss=0.00015 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=10.985 | 2243.9 samples/s | 35.1 steps/s
[Step=77100 Epoch=736.3] | Loss=0.00014 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=10.986 | 4337.4 samples/s | 67.8 steps/s
[Step=77150 Epoch=736.7] | Loss=0.00013 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=10.987 | 2357.1 samples/s | 36.8 steps/s
[Step=77200 Epoch=737.2] | Loss=0.00012 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=10.987 | 4301.4 samples/s | 67.2 steps/s
[Step=77250 Epoch=737.7] | Loss=0.00011 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=10.988 | 2369.5 samples/s | 37.0 steps/s
[Step=77300 Epoch=738.2] | Loss=0.00010 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=10.988 | 4281.4 samples/s | 66.9 steps/s
[Step=77350 Epoch=738.6] | Loss=0.00010 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=10.989 | 2334.5 samples/s | 36.5 steps/s
[Step=77400 Epoch=739.1] | Loss=0.00009 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=10.989 | 4290.0 samples/s | 67.0 steps/s
[Step=77450 Epoch=739.6] | Loss=0.00009 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=10.990 | 2423.2 samples/s | 37.9 steps/s
[Step=77500 Epoch=740.1] | Loss=0.00008 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=10.990 | 4145.7 samples/s | 64.8 steps/s
[Step=77550 Epoch=740.6] | Loss=0.00008 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=10.991 | 7006.0 samples/s | 109.5 steps/s
[Step=77600 Epoch=741.0] | Loss=0.00008 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=10.991 | 1956.3 samples/s | 30.6 steps/s
[Step=77650 Epoch=741.5] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=10.992 | 6133.1 samples/s | 95.8 steps/s
[Step=77700 Epoch=742.0] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=10.992 | 2022.9 samples/s | 31.6 steps/s
[Step=77750 Epoch=742.5] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=10.992 | 5654.4 samples/s | 88.4 steps/s
[Step=77800 Epoch=742.9] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=10.993 | 2084.8 samples/s | 32.6 steps/s
[Step=77850 Epoch=743.4] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=10.993 | 5290.4 samples/s | 82.7 steps/s
[Step=77900 Epoch=743.9] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=10.993 | 2131.3 samples/s | 33.3 steps/s
[Step=77950 Epoch=744.4] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.155 | L2-Norm(final)=10.994 | 4930.5 samples/s | 77.0 steps/s
[Step=78000 Epoch=744.9] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=10.994 | 2224.4 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step78000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=716.1] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.243 | L2-Norm(final)=10.607 | 5097.3 samples/s | 79.6 steps/s
[Step=76050 Epoch=716.6] | Loss=0.00010 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.250 | L2-Norm(final)=10.615 | 4213.4 samples/s | 65.8 steps/s
[Step=76100 Epoch=717.1] | Loss=0.00010 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.258 | L2-Norm(final)=10.630 | 7413.6 samples/s | 115.8 steps/s
[Step=76150 Epoch=717.6] | Loss=0.00009 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=10.642 | 2131.0 samples/s | 33.3 steps/s
[Step=76200 Epoch=718.0] | Loss=0.00008 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=10.652 | 6297.6 samples/s | 98.4 steps/s
[Step=76250 Epoch=718.5] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.275 | L2-Norm(final)=10.662 | 2206.8 samples/s | 34.5 steps/s
[Step=76300 Epoch=719.0] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.279 | L2-Norm(final)=10.670 | 5560.0 samples/s | 86.9 steps/s
[Step=76350 Epoch=719.4] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.283 | L2-Norm(final)=10.678 | 2383.3 samples/s | 37.2 steps/s
[Step=76400 Epoch=719.9] | Loss=0.00006 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.286 | L2-Norm(final)=10.686 | 5011.5 samples/s | 78.3 steps/s
[Step=76450 Epoch=720.4] | Loss=0.00006 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.289 | L2-Norm(final)=10.693 | 2519.2 samples/s | 39.4 steps/s
[Step=76500 Epoch=720.8] | Loss=0.00006 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.292 | L2-Norm(final)=10.700 | 4485.6 samples/s | 70.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=720.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=10.772 | 5603.3 samples/s | 87.6 steps/s
[Step=76550 Epoch=721.3] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=10.777 | 3603.8 samples/s | 56.3 steps/s
[Step=76600 Epoch=721.8] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.320 | L2-Norm(final)=10.782 | 6224.7 samples/s | 97.3 steps/s
[Step=76650 Epoch=722.3] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.317 | L2-Norm(final)=10.785 | 2021.3 samples/s | 31.6 steps/s
[Step=76700 Epoch=722.7] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.314 | L2-Norm(final)=10.788 | 5539.3 samples/s | 86.6 steps/s
[Step=76750 Epoch=723.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.309 | L2-Norm(final)=10.789 | 2113.6 samples/s | 33.0 steps/s
[Step=76800 Epoch=723.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.304 | L2-Norm(final)=10.791 | 4831.7 samples/s | 75.5 steps/s
[Step=76850 Epoch=724.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.299 | L2-Norm(final)=10.792 | 2202.4 samples/s | 34.4 steps/s
[Step=76900 Epoch=724.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.294 | L2-Norm(final)=10.793 | 4507.4 samples/s | 70.4 steps/s
[Step=76950 Epoch=725.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.288 | L2-Norm(final)=10.794 | 2331.1 samples/s | 36.4 steps/s
[Step=77000 Epoch=725.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.282 | L2-Norm(final)=10.795 | 4250.2 samples/s | 66.4 steps/s
[Step=77050 Epoch=726.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.276 | L2-Norm(final)=10.796 | 2396.9 samples/s | 37.5 steps/s
[Step=77100 Epoch=726.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.270 | L2-Norm(final)=10.797 | 4177.5 samples/s | 65.3 steps/s
[Step=77150 Epoch=727.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=10.798 | 2395.8 samples/s | 37.4 steps/s
[Step=77200 Epoch=727.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.257 | L2-Norm(final)=10.799 | 4225.6 samples/s | 66.0 steps/s
[Step=77250 Epoch=727.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.251 | L2-Norm(final)=10.800 | 2614.3 samples/s | 40.8 steps/s
[Step=77300 Epoch=728.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.244 | L2-Norm(final)=10.801 | 3855.8 samples/s | 60.2 steps/s
[Step=77350 Epoch=728.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.238 | L2-Norm(final)=10.802 | 6273.0 samples/s | 98.0 steps/s
[Step=77400 Epoch=729.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.231 | L2-Norm(final)=10.803 | 2019.0 samples/s | 31.5 steps/s
[Step=77450 Epoch=729.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.224 | L2-Norm(final)=10.804 | 5570.2 samples/s | 87.0 steps/s
[Step=77500 Epoch=730.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.217 | L2-Norm(final)=10.805 | 2097.5 samples/s | 32.8 steps/s
[Step=77550 Epoch=730.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.210 | L2-Norm(final)=10.806 | 5003.4 samples/s | 78.2 steps/s
[Step=77600 Epoch=731.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.203 | L2-Norm(final)=10.806 | 2193.7 samples/s | 34.3 steps/s
[Step=77650 Epoch=731.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.196 | L2-Norm(final)=10.807 | 4512.7 samples/s | 70.5 steps/s
[Step=77700 Epoch=732.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.188 | L2-Norm(final)=10.808 | 2254.1 samples/s | 35.2 steps/s
[Step=77750 Epoch=732.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.181 | L2-Norm(final)=10.809 | 4248.1 samples/s | 66.4 steps/s
[Step=77800 Epoch=733.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.173 | L2-Norm(final)=10.810 | 2408.2 samples/s | 37.6 steps/s
[Step=77850 Epoch=733.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.166 | L2-Norm(final)=10.811 | 4272.9 samples/s | 66.8 steps/s
[Step=77900 Epoch=734.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=10.812 | 2368.3 samples/s | 37.0 steps/s
[Step=77950 Epoch=734.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.150 | L2-Norm(final)=10.813 | 4255.9 samples/s | 66.5 steps/s
[Step=78000 Epoch=735.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.143 | L2-Norm(final)=10.814 | 2508.0 samples/s | 39.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step78000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=724.4] | Loss=0.00009 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=11.205 | 5455.0 samples/s | 85.2 steps/s
[Step=76050 Epoch=724.8] | Loss=0.00008 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=11.220 | 4008.7 samples/s | 62.6 steps/s
[Step=76100 Epoch=725.3] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.163 | L2-Norm(final)=11.237 | 7640.0 samples/s | 119.4 steps/s
[Step=76150 Epoch=725.8] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.169 | L2-Norm(final)=11.251 | 2138.9 samples/s | 33.4 steps/s
[Step=76200 Epoch=726.3] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.175 | L2-Norm(final)=11.264 | 6850.0 samples/s | 107.0 steps/s
[Step=76250 Epoch=726.7] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.179 | L2-Norm(final)=11.275 | 2183.4 samples/s | 34.1 steps/s
[Step=76300 Epoch=727.2] | Loss=0.00005 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.183 | L2-Norm(final)=11.286 | 6190.3 samples/s | 96.7 steps/s
[Step=76350 Epoch=727.7] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.187 | L2-Norm(final)=11.296 | 2302.9 samples/s | 36.0 steps/s
[Step=76400 Epoch=728.2] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.190 | L2-Norm(final)=11.306 | 5427.4 samples/s | 84.8 steps/s
[Step=76450 Epoch=728.6] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.193 | L2-Norm(final)=11.315 | 2375.7 samples/s | 37.1 steps/s
[Step=76500 Epoch=729.1] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.196 | L2-Norm(final)=11.324 | 4945.2 samples/s | 77.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=729.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=11.412 | 5466.7 samples/s | 85.4 steps/s
[Step=76550 Epoch=729.6] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=11.418 | 3692.6 samples/s | 57.7 steps/s
[Step=76600 Epoch=730.1] | Loss=0.00047 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.236 | L2-Norm(final)=11.429 | 6146.7 samples/s | 96.0 steps/s
[Step=76650 Epoch=730.5] | Loss=0.00038 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.251 | L2-Norm(final)=11.435 | 2020.2 samples/s | 31.6 steps/s
[Step=76700 Epoch=731.0] | Loss=0.00029 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=11.440 | 5740.7 samples/s | 89.7 steps/s
[Step=76750 Epoch=731.5] | Loss=0.00023 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.442 | 2105.6 samples/s | 32.9 steps/s
[Step=76800 Epoch=732.0] | Loss=0.00019 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=11.444 | 5140.5 samples/s | 80.3 steps/s
[Step=76850 Epoch=732.4] | Loss=0.00017 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.269 | L2-Norm(final)=11.446 | 2090.0 samples/s | 32.7 steps/s
[Step=76900 Epoch=732.9] | Loss=0.00015 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=11.447 | 4876.3 samples/s | 76.2 steps/s
[Step=76950 Epoch=733.4] | Loss=0.00013 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=11.448 | 2201.8 samples/s | 34.4 steps/s
[Step=77000 Epoch=733.9] | Loss=0.00012 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.449 | 4631.4 samples/s | 72.4 steps/s
[Step=77050 Epoch=734.4] | Loss=0.00011 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.450 | 2322.8 samples/s | 36.3 steps/s
[Step=77100 Epoch=734.8] | Loss=0.00010 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.450 | 4194.1 samples/s | 65.5 steps/s
[Step=77150 Epoch=735.3] | Loss=0.00009 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.451 | 2365.2 samples/s | 37.0 steps/s
[Step=77200 Epoch=735.8] | Loss=0.00009 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.451 | 4274.5 samples/s | 66.8 steps/s
[Step=77250 Epoch=736.3] | Loss=0.00008 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.272 | L2-Norm(final)=11.452 | 2379.9 samples/s | 37.2 steps/s
[Step=77300 Epoch=736.7] | Loss=0.00008 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=11.452 | 4230.6 samples/s | 66.1 steps/s
[Step=77350 Epoch=737.2] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.271 | L2-Norm(final)=11.453 | 2385.0 samples/s | 37.3 steps/s
[Step=77400 Epoch=737.7] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.270 | L2-Norm(final)=11.453 | 4159.2 samples/s | 65.0 steps/s
[Step=77450 Epoch=738.2] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.269 | L2-Norm(final)=11.453 | 2389.8 samples/s | 37.3 steps/s
[Step=77500 Epoch=738.6] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.269 | L2-Norm(final)=11.454 | 4230.2 samples/s | 66.1 steps/s
[Step=77550 Epoch=739.1] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.268 | L2-Norm(final)=11.454 | 6703.5 samples/s | 104.7 steps/s
[Step=77600 Epoch=739.6] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=11.454 | 1979.8 samples/s | 30.9 steps/s
[Step=77650 Epoch=740.1] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=11.455 | 6145.8 samples/s | 96.0 steps/s
[Step=77700 Epoch=740.6] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.455 | 2007.1 samples/s | 31.4 steps/s
[Step=77750 Epoch=741.0] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.455 | 5778.4 samples/s | 90.3 steps/s
[Step=77800 Epoch=741.5] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.263 | L2-Norm(final)=11.455 | 2073.6 samples/s | 32.4 steps/s
[Step=77850 Epoch=742.0] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.262 | L2-Norm(final)=11.456 | 5346.0 samples/s | 83.5 steps/s
[Step=77900 Epoch=742.5] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.261 | L2-Norm(final)=11.456 | 2141.7 samples/s | 33.5 steps/s
[Step=77950 Epoch=742.9] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=11.456 | 4859.9 samples/s | 75.9 steps/s
[Step=78000 Epoch=743.4] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.258 | L2-Norm(final)=11.457 | 2192.7 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10657 | acc=0.9555 | tpr=0.9663 | fpr=0.0679 | 4764.6 samples/s | 18.6 steps/s
Avg test loss: 0.11148, Avg test acc: 0.95348, Avg tpr: 0.96456, Avg fpr: 0.07089, total FA: 553

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10272 | acc=0.9582 | tpr=0.9710 | fpr=0.0696 | 4760.2 samples/s | 18.6 steps/s
Avg test loss: 0.10218, Avg test acc: 0.95761, Avg tpr: 0.96998, Avg fpr: 0.06961, total FA: 543

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10935 | acc=0.9572 | tpr=0.9703 | fpr=0.0714 | 4779.4 samples/s | 18.7 steps/s
Avg test loss: 0.11173, Avg test acc: 0.95528, Avg tpr: 0.96823, Avg fpr: 0.07320, total FA: 571

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10455 | acc=0.9580 | tpr=0.9661 | fpr=0.0597 | 4923.4 samples/s | 19.2 steps/s
Avg test loss: 0.10897, Avg test acc: 0.95629, Avg tpr: 0.96654, Avg fpr: 0.06627, total FA: 517

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11934 | acc=0.9558 | tpr=0.9738 | fpr=0.0833 | 4641.5 samples/s | 18.1 steps/s
Avg test loss: 0.12235, Avg test acc: 0.95504, Avg tpr: 0.97325, Avg fpr: 0.08499, total FA: 663

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.50860 | acc=0.2975 | tpr=0.0115 | fpr=0.0815 | 4724.7 samples/s | 18.5 steps/s
Avg test loss: 5.51579, Avg test acc: 0.29642, Avg tpr: 0.01253, Avg fpr: 0.07922, total FA: 618

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.95785 | acc=0.3017 | tpr=0.0054 | fpr=0.0548 | 4901.3 samples/s | 19.1 steps/s
Avg test loss: 4.97400, Avg test acc: 0.29910, Avg tpr: 0.00548, Avg fpr: 0.05512, total FA: 430

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.54361 | acc=0.2972 | tpr=0.0107 | fpr=0.0808 | 4956.6 samples/s | 19.4 steps/s
Avg test loss: 5.54966, Avg test acc: 0.29490, Avg tpr: 0.01154, Avg fpr: 0.08191, total FA: 639

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.52161 | acc=0.2978 | tpr=0.0126 | fpr=0.0828 | 4838.8 samples/s | 18.9 steps/s
Avg test loss: 5.52356, Avg test acc: 0.29694, Avg tpr: 0.01422, Avg fpr: 0.08127, total FA: 634

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.37576 | acc=0.3038 | tpr=0.0122 | fpr=0.0632 | 4841.1 samples/s | 18.9 steps/s
Avg test loss: 5.38514, Avg test acc: 0.30235, Avg tpr: 0.01323, Avg fpr: 0.06179, total FA: 482

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.57920 | acc=0.1141 | tpr=0.5487 | fpr=0.8937 | 4812.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.54435 | acc=0.1161 | tpr=0.5437 | fpr=0.8919 | 6916.1 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.55468 | acc=0.1154 | tpr=0.5490 | fpr=0.8925 | 7945.6 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.54670 | acc=0.1151 | tpr=0.5464 | fpr=0.8927 | 7814.9 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.54955 | acc=0.1164 | tpr=0.5616 | fpr=0.8917 | 8108.6 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.54380 | acc=0.1165 | tpr=0.5658 | fpr=0.8917 | 7950.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.53693 | acc=0.1162 | tpr=0.5623 | fpr=0.8919 | 7781.0 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.53467 | acc=0.1165 | tpr=0.5602 | fpr=0.8916 | 7663.2 samples/s | 29.9 steps/s
[Step= 450] | Loss=5.53969 | acc=0.1168 | tpr=0.5604 | fpr=0.8912 | 7732.8 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.54214 | acc=0.1166 | tpr=0.5555 | fpr=0.8913 | 8265.3 samples/s | 32.3 steps/s
[Step= 550] | Loss=5.54524 | acc=0.1165 | tpr=0.5487 | fpr=0.8914 | 13700.4 samples/s | 53.5 steps/s
Avg test loss: 5.54721, Avg test acc: 0.11637, Avg tpr: 0.54873, Avg fpr: 0.89149, total FA: 123782

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.23130 | acc=0.1005 | tpr=0.5044 | fpr=0.9068 | 4648.1 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.21171 | acc=0.1014 | tpr=0.5203 | fpr=0.9064 | 7536.1 samples/s | 29.4 steps/s
[Step= 150] | Loss=5.20764 | acc=0.1014 | tpr=0.5159 | fpr=0.9062 | 7684.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.20019 | acc=0.1010 | tpr=0.5104 | fpr=0.9064 | 7714.4 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.20324 | acc=0.1013 | tpr=0.5197 | fpr=0.9063 | 8107.0 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.19892 | acc=0.1011 | tpr=0.5178 | fpr=0.9065 | 7410.7 samples/s | 28.9 steps/s
[Step= 350] | Loss=5.19304 | acc=0.1011 | tpr=0.5172 | fpr=0.9064 | 8268.9 samples/s | 32.3 steps/s
[Step= 400] | Loss=5.18962 | acc=0.1013 | tpr=0.5126 | fpr=0.9062 | 8076.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.19448 | acc=0.1013 | tpr=0.5141 | fpr=0.9062 | 7684.2 samples/s | 30.0 steps/s
[Step= 500] | Loss=5.19699 | acc=0.1013 | tpr=0.5119 | fpr=0.9061 | 8058.0 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.20214 | acc=0.1009 | tpr=0.5066 | fpr=0.9065 | 13600.1 samples/s | 53.1 steps/s
Avg test loss: 5.20439, Avg test acc: 0.10082, Avg tpr: 0.50594, Avg fpr: 0.90655, total FA: 125872

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.85681 | acc=0.0984 | tpr=0.2876 | fpr=0.9050 | 4751.0 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.82421 | acc=0.0999 | tpr=0.2836 | fpr=0.9035 | 7239.7 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.83625 | acc=0.1008 | tpr=0.2810 | fpr=0.9025 | 7915.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.82822 | acc=0.1011 | tpr=0.2743 | fpr=0.9021 | 7735.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.82814 | acc=0.1019 | tpr=0.2856 | fpr=0.9014 | 7707.5 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.82222 | acc=0.1024 | tpr=0.2916 | fpr=0.9011 | 8147.1 samples/s | 31.8 steps/s
[Step= 350] | Loss=5.81598 | acc=0.1027 | tpr=0.2912 | fpr=0.9007 | 7816.5 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.81380 | acc=0.1029 | tpr=0.2932 | fpr=0.9006 | 8133.8 samples/s | 31.8 steps/s
[Step= 450] | Loss=5.81910 | acc=0.1030 | tpr=0.2921 | fpr=0.9004 | 7823.0 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.81985 | acc=0.1028 | tpr=0.2930 | fpr=0.9006 | 7718.3 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.82390 | acc=0.1024 | tpr=0.2921 | fpr=0.9010 | 13834.8 samples/s | 54.0 steps/s
Avg test loss: 5.82542, Avg test acc: 0.10233, Avg tpr: 0.29279, Avg fpr: 0.90114, total FA: 125121

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.60341 | acc=0.1169 | tpr=0.4823 | fpr=0.8897 | 4789.5 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.58488 | acc=0.1158 | tpr=0.4733 | fpr=0.8909 | 7097.5 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.59893 | acc=0.1147 | tpr=0.4841 | fpr=0.8921 | 7901.9 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.58874 | acc=0.1138 | tpr=0.4809 | fpr=0.8929 | 7955.9 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.59280 | acc=0.1146 | tpr=0.4882 | fpr=0.8922 | 8118.3 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.59092 | acc=0.1147 | tpr=0.4975 | fpr=0.8923 | 7451.5 samples/s | 29.1 steps/s
[Step= 350] | Loss=5.58123 | acc=0.1148 | tpr=0.4966 | fpr=0.8921 | 8213.9 samples/s | 32.1 steps/s
[Step= 400] | Loss=5.57651 | acc=0.1149 | tpr=0.4923 | fpr=0.8919 | 7486.2 samples/s | 29.2 steps/s
[Step= 450] | Loss=5.58193 | acc=0.1148 | tpr=0.4903 | fpr=0.8920 | 8043.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.58225 | acc=0.1148 | tpr=0.4868 | fpr=0.8919 | 7931.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.58815 | acc=0.1145 | tpr=0.4795 | fpr=0.8922 | 13907.1 samples/s | 54.3 steps/s
Avg test loss: 5.58951, Avg test acc: 0.11435, Avg tpr: 0.47940, Avg fpr: 0.89229, total FA: 123892

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.16234 | acc=0.1073 | tpr=0.4469 | fpr=0.8988 | 4707.9 samples/s | 18.4 steps/s
[Step= 100] | Loss=6.14099 | acc=0.1084 | tpr=0.4606 | fpr=0.8981 | 7031.1 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.14274 | acc=0.1085 | tpr=0.4712 | fpr=0.8981 | 7964.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=6.13866 | acc=0.1081 | tpr=0.4656 | fpr=0.8984 | 7915.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.14234 | acc=0.1091 | tpr=0.4760 | fpr=0.8976 | 8053.8 samples/s | 31.5 steps/s
[Step= 300] | Loss=6.14162 | acc=0.1091 | tpr=0.4793 | fpr=0.8976 | 7921.0 samples/s | 30.9 steps/s
[Step= 350] | Loss=6.13205 | acc=0.1096 | tpr=0.4759 | fpr=0.8971 | 7823.9 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.13034 | acc=0.1095 | tpr=0.4721 | fpr=0.8971 | 8099.0 samples/s | 31.6 steps/s
[Step= 450] | Loss=6.13528 | acc=0.1098 | tpr=0.4708 | fpr=0.8968 | 7744.0 samples/s | 30.3 steps/s
[Step= 500] | Loss=6.13818 | acc=0.1096 | tpr=0.4692 | fpr=0.8969 | 7734.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.14390 | acc=0.1095 | tpr=0.4704 | fpr=0.8971 | 13951.8 samples/s | 54.5 steps/s
Avg test loss: 6.14578, Avg test acc: 0.10940, Avg tpr: 0.46989, Avg fpr: 0.89715, total FA: 124568

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09593 | acc=0.9821 | tpr=0.9646 | fpr=0.0176 | 4848.8 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.09768 | acc=0.9817 | tpr=0.9659 | fpr=0.0180 | 7130.5 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.10143 | acc=0.9807 | tpr=0.9640 | fpr=0.0190 | 7943.0 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.10334 | acc=0.9807 | tpr=0.9683 | fpr=0.0191 | 7612.5 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.10181 | acc=0.9809 | tpr=0.9624 | fpr=0.0188 | 8057.1 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.10415 | acc=0.9805 | tpr=0.9600 | fpr=0.0191 | 7860.2 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.10520 | acc=0.9803 | tpr=0.9606 | fpr=0.0193 | 7755.7 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.10621 | acc=0.9799 | tpr=0.9562 | fpr=0.0196 | 7645.5 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.10819 | acc=0.9795 | tpr=0.9523 | fpr=0.0200 | 8177.0 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.10737 | acc=0.9796 | tpr=0.9529 | fpr=0.0199 | 7855.0 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10671 | acc=0.9798 | tpr=0.9507 | fpr=0.0197 | 14467.1 samples/s | 56.5 steps/s
Avg test loss: 0.10655, Avg test acc: 0.97976, Avg tpr: 0.95087, Avg fpr: 0.01971, total FA: 2737

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08980 | acc=0.9827 | tpr=0.9159 | fpr=0.0161 | 4975.9 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.09264 | acc=0.9825 | tpr=0.9168 | fpr=0.0163 | 6681.3 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.09619 | acc=0.9822 | tpr=0.9236 | fpr=0.0167 | 7990.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.09875 | acc=0.9821 | tpr=0.9279 | fpr=0.0169 | 7639.4 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.09698 | acc=0.9826 | tpr=0.9293 | fpr=0.0164 | 7902.0 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.09929 | acc=0.9823 | tpr=0.9265 | fpr=0.0167 | 8110.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.09986 | acc=0.9821 | tpr=0.9299 | fpr=0.0170 | 7587.0 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.10097 | acc=0.9819 | tpr=0.9261 | fpr=0.0171 | 8064.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.10334 | acc=0.9816 | tpr=0.9255 | fpr=0.0174 | 7737.6 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.10242 | acc=0.9816 | tpr=0.9264 | fpr=0.0174 | 7931.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.10221 | acc=0.9817 | tpr=0.9236 | fpr=0.0172 | 13840.9 samples/s | 54.1 steps/s
Avg test loss: 0.10212, Avg test acc: 0.98172, Avg tpr: 0.92393, Avg fpr: 0.01723, total FA: 2392

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.07987 | acc=0.9824 | tpr=0.9469 | fpr=0.0169 | 4661.5 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.08106 | acc=0.9827 | tpr=0.9552 | fpr=0.0168 | 7241.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.08493 | acc=0.9820 | tpr=0.9510 | fpr=0.0174 | 8152.0 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.08681 | acc=0.9822 | tpr=0.9574 | fpr=0.0174 | 7868.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.08529 | acc=0.9825 | tpr=0.9590 | fpr=0.0171 | 7699.9 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.08726 | acc=0.9821 | tpr=0.9535 | fpr=0.0174 | 7839.2 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.08818 | acc=0.9816 | tpr=0.9518 | fpr=0.0178 | 8068.3 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.08939 | acc=0.9813 | tpr=0.9491 | fpr=0.0181 | 7834.7 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.09113 | acc=0.9811 | tpr=0.9484 | fpr=0.0183 | 7902.7 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.09060 | acc=0.9811 | tpr=0.9493 | fpr=0.0183 | 8364.9 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.09023 | acc=0.9812 | tpr=0.9487 | fpr=0.0182 | 12647.5 samples/s | 49.4 steps/s
Avg test loss: 0.09010, Avg test acc: 0.98121, Avg tpr: 0.94889, Avg fpr: 0.01820, total FA: 2527

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09441 | acc=0.9802 | tpr=0.9469 | fpr=0.0192 | 4867.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09580 | acc=0.9803 | tpr=0.9552 | fpr=0.0193 | 7287.2 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.09965 | acc=0.9794 | tpr=0.9510 | fpr=0.0201 | 7391.0 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.10099 | acc=0.9796 | tpr=0.9574 | fpr=0.0199 | 8164.4 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.09964 | acc=0.9801 | tpr=0.9563 | fpr=0.0195 | 7709.4 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.10171 | acc=0.9798 | tpr=0.9535 | fpr=0.0197 | 7821.9 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.10256 | acc=0.9797 | tpr=0.9537 | fpr=0.0199 | 8020.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.10315 | acc=0.9795 | tpr=0.9519 | fpr=0.0200 | 7992.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.10497 | acc=0.9793 | tpr=0.9499 | fpr=0.0202 | 7884.5 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10416 | acc=0.9794 | tpr=0.9507 | fpr=0.0201 | 7741.6 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.10365 | acc=0.9796 | tpr=0.9511 | fpr=0.0199 | 13985.0 samples/s | 54.6 steps/s
Avg test loss: 0.10346, Avg test acc: 0.97961, Avg tpr: 0.95127, Avg fpr: 0.01987, total FA: 2759

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09429 | acc=0.9820 | tpr=0.9159 | fpr=0.0168 | 4815.8 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09657 | acc=0.9820 | tpr=0.9296 | fpr=0.0170 | 7044.5 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.09972 | acc=0.9812 | tpr=0.9337 | fpr=0.0179 | 7593.2 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.10080 | acc=0.9811 | tpr=0.9410 | fpr=0.0182 | 7636.9 samples/s | 29.8 steps/s
[Step= 250] | Loss=0.09889 | acc=0.9817 | tpr=0.9424 | fpr=0.0176 | 7952.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.10105 | acc=0.9813 | tpr=0.9360 | fpr=0.0179 | 7612.5 samples/s | 29.7 steps/s
[Step= 350] | Loss=0.10163 | acc=0.9811 | tpr=0.9380 | fpr=0.0181 | 7805.4 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.10291 | acc=0.9809 | tpr=0.9349 | fpr=0.0182 | 8036.1 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.10559 | acc=0.9806 | tpr=0.9323 | fpr=0.0185 | 7614.0 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.10502 | acc=0.9807 | tpr=0.9322 | fpr=0.0185 | 7837.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.10471 | acc=0.9808 | tpr=0.9316 | fpr=0.0183 | 13809.7 samples/s | 53.9 steps/s
Avg test loss: 0.10457, Avg test acc: 0.98081, Avg tpr: 0.93106, Avg fpr: 0.01829, total FA: 2539

server round 39/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=380.3] | Loss=0.00398 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=19.744 | 5654.8 samples/s | 88.4 steps/s
[Step=78050 Epoch=380.6] | Loss=0.00394 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.074 | L2-Norm(final)=19.750 | 4159.9 samples/s | 65.0 steps/s
[Step=78100 Epoch=380.8] | Loss=0.00343 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=19.758 | 4970.7 samples/s | 77.7 steps/s
[Step=78150 Epoch=381.1] | Loss=0.00347 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.079 | L2-Norm(final)=19.767 | 5034.6 samples/s | 78.7 steps/s
[Step=78200 Epoch=381.3] | Loss=0.00351 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.081 | L2-Norm(final)=19.776 | 7728.0 samples/s | 120.7 steps/s
[Step=78250 Epoch=381.6] | Loss=0.00352 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=19.785 | 2233.2 samples/s | 34.9 steps/s
[Step=78300 Epoch=381.8] | Loss=0.00345 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=19.794 | 4845.4 samples/s | 75.7 steps/s
[Step=78350 Epoch=382.0] | Loss=0.00343 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=19.803 | 4986.3 samples/s | 77.9 steps/s
[Step=78400 Epoch=382.3] | Loss=0.00338 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=19.812 | 6891.9 samples/s | 107.7 steps/s
[Step=78450 Epoch=382.5] | Loss=0.00336 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=19.820 | 2272.0 samples/s | 35.5 steps/s
[Step=78500 Epoch=382.8] | Loss=0.00334 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=19.829 | 4981.7 samples/s | 77.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=382.8] | Loss=0.00335 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=19.916 | 5206.5 samples/s | 81.4 steps/s
[Step=78550 Epoch=383.0] | Loss=0.00282 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=19.925 | 4050.9 samples/s | 63.3 steps/s
[Step=78600 Epoch=383.3] | Loss=0.00387 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=19.933 | 4445.9 samples/s | 69.5 steps/s
[Step=78650 Epoch=383.5] | Loss=0.00390 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=19.941 | 4414.7 samples/s | 69.0 steps/s
[Step=78700 Epoch=383.8] | Loss=0.00463 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.135 | L2-Norm(final)=19.949 | 6528.3 samples/s | 102.0 steps/s
[Step=78750 Epoch=384.0] | Loss=0.00468 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.140 | L2-Norm(final)=19.957 | 2059.3 samples/s | 32.2 steps/s
[Step=78800 Epoch=384.2] | Loss=0.00453 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=19.964 | 4449.5 samples/s | 69.5 steps/s
[Step=78850 Epoch=384.5] | Loss=0.00442 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=19.970 | 4405.3 samples/s | 68.8 steps/s
[Step=78900 Epoch=384.7] | Loss=0.00440 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=19.976 | 5879.4 samples/s | 91.9 steps/s
[Step=78950 Epoch=385.0] | Loss=0.00426 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=19.982 | 2143.2 samples/s | 33.5 steps/s
[Step=79000 Epoch=385.2] | Loss=0.00418 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=19.988 | 4512.9 samples/s | 70.5 steps/s
[Step=79050 Epoch=385.5] | Loss=0.00412 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.158 | L2-Norm(final)=19.993 | 4336.7 samples/s | 67.8 steps/s
[Step=79100 Epoch=385.7] | Loss=0.00405 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=19.998 | 5366.1 samples/s | 83.8 steps/s
[Step=79150 Epoch=386.0] | Loss=0.00389 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=20.003 | 2216.4 samples/s | 34.6 steps/s
[Step=79200 Epoch=386.2] | Loss=0.00373 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=20.008 | 4556.1 samples/s | 71.2 steps/s
[Step=79250 Epoch=386.4] | Loss=0.00373 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=20.012 | 4325.2 samples/s | 67.6 steps/s
[Step=79300 Epoch=386.7] | Loss=0.00373 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=20.016 | 4938.4 samples/s | 77.2 steps/s
[Step=79350 Epoch=386.9] | Loss=0.00365 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=20.021 | 2305.6 samples/s | 36.0 steps/s
[Step=79400 Epoch=387.2] | Loss=0.00355 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.025 | 4427.6 samples/s | 69.2 steps/s
[Step=79450 Epoch=387.4] | Loss=0.00352 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.029 | 4438.5 samples/s | 69.4 steps/s
[Step=79500 Epoch=387.7] | Loss=0.00348 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.165 | L2-Norm(final)=20.032 | 4560.6 samples/s | 71.3 steps/s
[Step=79550 Epoch=387.9] | Loss=0.00341 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.036 | 2381.3 samples/s | 37.2 steps/s
[Step=79600 Epoch=388.1] | Loss=0.00332 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.040 | 4360.4 samples/s | 68.1 steps/s
[Step=79650 Epoch=388.4] | Loss=0.00332 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.043 | 4433.2 samples/s | 69.3 steps/s
[Step=79700 Epoch=388.6] | Loss=0.00329 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=20.047 | 4403.2 samples/s | 68.8 steps/s
[Step=79750 Epoch=388.9] | Loss=0.00325 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=20.050 | 2454.2 samples/s | 38.3 steps/s
[Step=79800 Epoch=389.1] | Loss=0.00317 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=20.054 | 4477.4 samples/s | 70.0 steps/s
[Step=79850 Epoch=389.4] | Loss=0.00312 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=20.057 | 4311.2 samples/s | 67.4 steps/s
[Step=79900 Epoch=389.6] | Loss=0.00310 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.163 | L2-Norm(final)=20.060 | 4447.9 samples/s | 69.5 steps/s
[Step=79950 Epoch=389.9] | Loss=0.00307 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=20.063 | 2441.5 samples/s | 38.1 steps/s
[Step=80000 Epoch=390.1] | Loss=0.00305 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=20.066 | 4428.8 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step80000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=380.6] | Loss=0.00273 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=20.561 | 5168.7 samples/s | 80.8 steps/s
[Step=78050 Epoch=380.8] | Loss=0.00196 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=20.568 | 4320.8 samples/s | 67.5 steps/s
[Step=78100 Epoch=381.1] | Loss=0.00258 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=20.578 | 4987.5 samples/s | 77.9 steps/s
[Step=78150 Epoch=381.3] | Loss=0.00294 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=20.587 | 5021.0 samples/s | 78.5 steps/s
[Step=78200 Epoch=381.6] | Loss=0.00315 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.677 | L2-Norm(final)=20.596 | 7874.1 samples/s | 123.0 steps/s
[Step=78250 Epoch=381.8] | Loss=0.00303 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.680 | L2-Norm(final)=20.605 | 2161.0 samples/s | 33.8 steps/s
[Step=78300 Epoch=382.1] | Loss=0.00295 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=20.614 | 5058.4 samples/s | 79.0 steps/s
[Step=78350 Epoch=382.3] | Loss=0.00292 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=20.623 | 4943.6 samples/s | 77.2 steps/s
[Step=78400 Epoch=382.6] | Loss=0.00297 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.687 | L2-Norm(final)=20.632 | 7026.1 samples/s | 109.8 steps/s
[Step=78450 Epoch=382.8] | Loss=0.00294 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.641 | 2229.2 samples/s | 34.8 steps/s
[Step=78500 Epoch=383.0] | Loss=0.00293 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=20.649 | 4919.0 samples/s | 76.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=383.0] | Loss=0.00038 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.713 | L2-Norm(final)=20.738 | 5772.0 samples/s | 90.2 steps/s
[Step=78550 Epoch=383.3] | Loss=0.00278 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=20.746 | 3736.0 samples/s | 58.4 steps/s
[Step=78600 Epoch=383.5] | Loss=0.00468 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=20.754 | 4459.1 samples/s | 69.7 steps/s
[Step=78650 Epoch=383.8] | Loss=0.00480 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.730 | L2-Norm(final)=20.762 | 4432.3 samples/s | 69.3 steps/s
[Step=78700 Epoch=384.0] | Loss=0.00543 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.736 | L2-Norm(final)=20.769 | 6467.5 samples/s | 101.1 steps/s
[Step=78750 Epoch=384.3] | Loss=0.00536 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=20.775 | 2092.3 samples/s | 32.7 steps/s
[Step=78800 Epoch=384.5] | Loss=0.00511 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.745 | L2-Norm(final)=20.782 | 4374.4 samples/s | 68.3 steps/s
[Step=78850 Epoch=384.8] | Loss=0.00490 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=20.788 | 4476.1 samples/s | 69.9 steps/s
[Step=78900 Epoch=385.0] | Loss=0.00469 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.752 | L2-Norm(final)=20.794 | 5935.9 samples/s | 92.7 steps/s
[Step=78950 Epoch=385.2] | Loss=0.00464 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=20.799 | 2105.9 samples/s | 32.9 steps/s
[Step=79000 Epoch=385.5] | Loss=0.00449 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.757 | L2-Norm(final)=20.804 | 4413.0 samples/s | 69.0 steps/s
[Step=79050 Epoch=385.7] | Loss=0.00433 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.759 | L2-Norm(final)=20.809 | 4555.8 samples/s | 71.2 steps/s
[Step=79100 Epoch=386.0] | Loss=0.00426 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.761 | L2-Norm(final)=20.814 | 5345.6 samples/s | 83.5 steps/s
[Step=79150 Epoch=386.2] | Loss=0.00420 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=20.819 | 2176.8 samples/s | 34.0 steps/s
[Step=79200 Epoch=386.5] | Loss=0.00415 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=20.823 | 4469.2 samples/s | 69.8 steps/s
[Step=79250 Epoch=386.7] | Loss=0.00407 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.765 | L2-Norm(final)=20.828 | 4454.1 samples/s | 69.6 steps/s
[Step=79300 Epoch=386.9] | Loss=0.00396 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.766 | L2-Norm(final)=20.832 | 5112.3 samples/s | 79.9 steps/s
[Step=79350 Epoch=387.2] | Loss=0.00385 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.767 | L2-Norm(final)=20.836 | 2248.2 samples/s | 35.1 steps/s
[Step=79400 Epoch=387.4] | Loss=0.00380 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=20.840 | 4438.4 samples/s | 69.3 steps/s
[Step=79450 Epoch=387.7] | Loss=0.00373 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=20.844 | 4455.8 samples/s | 69.6 steps/s
[Step=79500 Epoch=387.9] | Loss=0.00367 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=20.848 | 4819.2 samples/s | 75.3 steps/s
[Step=79550 Epoch=388.2] | Loss=0.00356 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=20.852 | 2290.2 samples/s | 35.8 steps/s
[Step=79600 Epoch=388.4] | Loss=0.00349 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=20.855 | 4448.1 samples/s | 69.5 steps/s
[Step=79650 Epoch=388.7] | Loss=0.00341 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=20.859 | 4434.8 samples/s | 69.3 steps/s
[Step=79700 Epoch=388.9] | Loss=0.00335 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=20.862 | 4522.9 samples/s | 70.7 steps/s
[Step=79750 Epoch=389.1] | Loss=0.00328 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=20.866 | 2379.3 samples/s | 37.2 steps/s
[Step=79800 Epoch=389.4] | Loss=0.00321 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=20.869 | 4456.9 samples/s | 69.6 steps/s
[Step=79850 Epoch=389.6] | Loss=0.00316 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=20.872 | 4427.1 samples/s | 69.2 steps/s
[Step=79900 Epoch=389.9] | Loss=0.00312 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.769 | L2-Norm(final)=20.875 | 4468.1 samples/s | 69.8 steps/s
[Step=79950 Epoch=390.1] | Loss=0.00308 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=20.879 | 2397.4 samples/s | 37.5 steps/s
[Step=80000 Epoch=390.4] | Loss=0.00303 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=20.882 | 4420.5 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step80000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=380.1] | Loss=0.00312 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=20.617 | 5494.5 samples/s | 85.9 steps/s
[Step=78050 Epoch=380.3] | Loss=0.00358 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=20.623 | 4236.5 samples/s | 66.2 steps/s
[Step=78100 Epoch=380.5] | Loss=0.00383 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=20.632 | 5262.8 samples/s | 82.2 steps/s
[Step=78150 Epoch=380.8] | Loss=0.00377 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.442 | L2-Norm(final)=20.642 | 4800.1 samples/s | 75.0 steps/s
[Step=78200 Epoch=381.0] | Loss=0.00380 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.445 | L2-Norm(final)=20.651 | 7707.2 samples/s | 120.4 steps/s
[Step=78250 Epoch=381.3] | Loss=0.00362 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.448 | L2-Norm(final)=20.660 | 2196.6 samples/s | 34.3 steps/s
[Step=78300 Epoch=381.5] | Loss=0.00355 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.450 | L2-Norm(final)=20.669 | 4949.6 samples/s | 77.3 steps/s
[Step=78350 Epoch=381.8] | Loss=0.00356 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=20.678 | 5128.8 samples/s | 80.1 steps/s
[Step=78400 Epoch=382.0] | Loss=0.00359 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.455 | L2-Norm(final)=20.687 | 6662.1 samples/s | 104.1 steps/s
[Step=78450 Epoch=382.2] | Loss=0.00350 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.457 | L2-Norm(final)=20.697 | 2302.7 samples/s | 36.0 steps/s
[Step=78500 Epoch=382.5] | Loss=0.00348 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.460 | L2-Norm(final)=20.706 | 4865.3 samples/s | 76.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=382.5] | Loss=0.00403 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=20.795 | 5769.7 samples/s | 90.2 steps/s
[Step=78550 Epoch=382.7] | Loss=0.00408 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=20.804 | 4006.8 samples/s | 62.6 steps/s
[Step=78600 Epoch=383.0] | Loss=0.00553 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.494 | L2-Norm(final)=20.813 | 4420.2 samples/s | 69.1 steps/s
[Step=78650 Epoch=383.2] | Loss=0.00576 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=20.821 | 4460.8 samples/s | 69.7 steps/s
[Step=78700 Epoch=383.5] | Loss=0.00573 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.509 | L2-Norm(final)=20.829 | 6418.4 samples/s | 100.3 steps/s
[Step=78750 Epoch=383.7] | Loss=0.00549 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.515 | L2-Norm(final)=20.837 | 2062.7 samples/s | 32.2 steps/s
[Step=78800 Epoch=384.0] | Loss=0.00537 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=20.843 | 4453.4 samples/s | 69.6 steps/s
[Step=78850 Epoch=384.2] | Loss=0.00551 | Reg=0.00241 | acc=0.9531 | L2-Norm=15.524 | L2-Norm(final)=20.849 | 4426.4 samples/s | 69.2 steps/s
[Step=78900 Epoch=384.4] | Loss=0.00535 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.528 | L2-Norm(final)=20.855 | 5827.1 samples/s | 91.0 steps/s
[Step=78950 Epoch=384.7] | Loss=0.00546 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=20.860 | 2149.7 samples/s | 33.6 steps/s
[Step=79000 Epoch=384.9] | Loss=0.00517 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.534 | L2-Norm(final)=20.865 | 4453.9 samples/s | 69.6 steps/s
[Step=79050 Epoch=385.2] | Loss=0.00503 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.537 | L2-Norm(final)=20.870 | 4458.9 samples/s | 69.7 steps/s
[Step=79100 Epoch=385.4] | Loss=0.00489 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.539 | L2-Norm(final)=20.875 | 5382.1 samples/s | 84.1 steps/s
[Step=79150 Epoch=385.7] | Loss=0.00477 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=20.879 | 2263.4 samples/s | 35.4 steps/s
[Step=79200 Epoch=385.9] | Loss=0.00459 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=20.883 | 4480.9 samples/s | 70.0 steps/s
[Step=79250 Epoch=386.1] | Loss=0.00443 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.544 | L2-Norm(final)=20.887 | 4461.6 samples/s | 69.7 steps/s
[Step=79300 Epoch=386.4] | Loss=0.00430 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=20.891 | 4996.8 samples/s | 78.1 steps/s
[Step=79350 Epoch=386.6] | Loss=0.00426 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=20.895 | 2343.5 samples/s | 36.6 steps/s
[Step=79400 Epoch=386.9] | Loss=0.00418 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=20.899 | 4437.8 samples/s | 69.3 steps/s
[Step=79450 Epoch=387.1] | Loss=0.00406 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=20.902 | 4521.4 samples/s | 70.6 steps/s
[Step=79500 Epoch=387.4] | Loss=0.00399 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.906 | 4420.8 samples/s | 69.1 steps/s
[Step=79550 Epoch=387.6] | Loss=0.00387 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.909 | 2252.3 samples/s | 35.2 steps/s
[Step=79600 Epoch=387.8] | Loss=0.00380 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.912 | 4264.5 samples/s | 66.6 steps/s
[Step=79650 Epoch=388.1] | Loss=0.00374 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.916 | 4252.2 samples/s | 66.4 steps/s
[Step=79700 Epoch=388.3] | Loss=0.00367 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.919 | 4265.0 samples/s | 66.6 steps/s
[Step=79750 Epoch=388.6] | Loss=0.00361 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.922 | 2271.1 samples/s | 35.5 steps/s
[Step=79800 Epoch=388.8] | Loss=0.00355 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.925 | 4255.9 samples/s | 66.5 steps/s
[Step=79850 Epoch=389.1] | Loss=0.00349 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=20.928 | 4273.0 samples/s | 66.8 steps/s
[Step=79900 Epoch=389.3] | Loss=0.00343 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=20.931 | 4289.4 samples/s | 67.0 steps/s
[Step=79950 Epoch=389.6] | Loss=0.00338 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=20.934 | 2368.4 samples/s | 37.0 steps/s
[Step=80000 Epoch=389.8] | Loss=0.00331 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=20.937 | 4408.1 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step80000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=380.4] | Loss=0.00067 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=20.685 | 4938.7 samples/s | 77.2 steps/s
[Step=78050 Epoch=380.6] | Loss=0.00420 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=20.691 | 4547.0 samples/s | 71.0 steps/s
[Step=78100 Epoch=380.9] | Loss=0.00393 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=20.699 | 5013.1 samples/s | 78.3 steps/s
[Step=78150 Epoch=381.1] | Loss=0.00371 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.138 | L2-Norm(final)=20.708 | 5124.4 samples/s | 80.1 steps/s
[Step=78200 Epoch=381.3] | Loss=0.00361 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=20.718 | 7709.1 samples/s | 120.5 steps/s
[Step=78250 Epoch=381.6] | Loss=0.00336 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=20.727 | 2194.6 samples/s | 34.3 steps/s
[Step=78300 Epoch=381.8] | Loss=0.00339 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=20.736 | 5010.5 samples/s | 78.3 steps/s
[Step=78350 Epoch=382.1] | Loss=0.00334 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=20.745 | 5123.5 samples/s | 80.1 steps/s
[Step=78400 Epoch=382.3] | Loss=0.00330 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=20.754 | 6853.6 samples/s | 107.1 steps/s
[Step=78450 Epoch=382.6] | Loss=0.00330 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.155 | L2-Norm(final)=20.763 | 2308.8 samples/s | 36.1 steps/s
[Step=78500 Epoch=382.8] | Loss=0.00324 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=20.772 | 5034.8 samples/s | 78.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=382.8] | Loss=0.00189 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=20.861 | 5724.3 samples/s | 89.4 steps/s
[Step=78550 Epoch=383.1] | Loss=0.00448 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.186 | L2-Norm(final)=20.870 | 3839.5 samples/s | 60.0 steps/s
[Step=78600 Epoch=383.3] | Loss=0.00520 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=20.878 | 4417.5 samples/s | 69.0 steps/s
[Step=78650 Epoch=383.5] | Loss=0.00529 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=20.886 | 4499.5 samples/s | 70.3 steps/s
[Step=78700 Epoch=383.8] | Loss=0.00547 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=20.893 | 6578.6 samples/s | 102.8 steps/s
[Step=78750 Epoch=384.0] | Loss=0.00508 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.213 | L2-Norm(final)=20.900 | 2114.2 samples/s | 33.0 steps/s
[Step=78800 Epoch=384.3] | Loss=0.00507 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.218 | L2-Norm(final)=20.907 | 4435.5 samples/s | 69.3 steps/s
[Step=78850 Epoch=384.5] | Loss=0.00489 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=20.912 | 4482.5 samples/s | 70.0 steps/s
[Step=78900 Epoch=384.8] | Loss=0.00474 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=20.918 | 5945.4 samples/s | 92.9 steps/s
[Step=78950 Epoch=385.0] | Loss=0.00444 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.228 | L2-Norm(final)=20.923 | 2159.0 samples/s | 33.7 steps/s
[Step=79000 Epoch=385.2] | Loss=0.00416 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=20.928 | 4524.0 samples/s | 70.7 steps/s
[Step=79050 Epoch=385.5] | Loss=0.00406 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=20.932 | 4446.2 samples/s | 69.5 steps/s
[Step=79100 Epoch=385.7] | Loss=0.00399 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=20.937 | 5395.1 samples/s | 84.3 steps/s
[Step=79150 Epoch=386.0] | Loss=0.00382 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=20.941 | 2254.7 samples/s | 35.2 steps/s
[Step=79200 Epoch=386.2] | Loss=0.00372 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=20.945 | 4520.2 samples/s | 70.6 steps/s
[Step=79250 Epoch=386.5] | Loss=0.00364 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=20.949 | 4403.6 samples/s | 68.8 steps/s
[Step=79300 Epoch=386.7] | Loss=0.00358 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.239 | L2-Norm(final)=20.953 | 4903.1 samples/s | 76.6 steps/s
[Step=79350 Epoch=387.0] | Loss=0.00350 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=20.956 | 2309.7 samples/s | 36.1 steps/s
[Step=79400 Epoch=387.2] | Loss=0.00353 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=20.960 | 4516.1 samples/s | 70.6 steps/s
[Step=79450 Epoch=387.4] | Loss=0.00347 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=20.963 | 4471.2 samples/s | 69.9 steps/s
[Step=79500 Epoch=387.7] | Loss=0.00340 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.241 | L2-Norm(final)=20.967 | 4622.5 samples/s | 72.2 steps/s
[Step=79550 Epoch=387.9] | Loss=0.00333 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.970 | 2414.9 samples/s | 37.7 steps/s
[Step=79600 Epoch=388.2] | Loss=0.00321 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.974 | 4456.7 samples/s | 69.6 steps/s
[Step=79650 Epoch=388.4] | Loss=0.00322 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.242 | L2-Norm(final)=20.977 | 4414.4 samples/s | 69.0 steps/s
[Step=79700 Epoch=388.7] | Loss=0.00314 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.980 | 4519.5 samples/s | 70.6 steps/s
[Step=79750 Epoch=388.9] | Loss=0.00311 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.983 | 2466.0 samples/s | 38.5 steps/s
[Step=79800 Epoch=389.1] | Loss=0.00306 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.987 | 4463.5 samples/s | 69.7 steps/s
[Step=79850 Epoch=389.4] | Loss=0.00299 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=20.990 | 4504.9 samples/s | 70.4 steps/s
[Step=79900 Epoch=389.6] | Loss=0.00295 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=20.993 | 4445.4 samples/s | 69.5 steps/s
[Step=79950 Epoch=389.9] | Loss=0.00294 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=20.996 | 2445.3 samples/s | 38.2 steps/s
[Step=80000 Epoch=390.1] | Loss=0.00289 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=20.998 | 4419.1 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step80000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=382.5] | Loss=0.00264 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=20.748 | 5377.5 samples/s | 84.0 steps/s
[Step=78050 Epoch=382.7] | Loss=0.00363 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.824 | L2-Norm(final)=20.757 | 4468.2 samples/s | 69.8 steps/s
[Step=78100 Epoch=383.0] | Loss=0.00314 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.827 | L2-Norm(final)=20.767 | 4978.8 samples/s | 77.8 steps/s
[Step=78150 Epoch=383.2] | Loss=0.00313 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.830 | L2-Norm(final)=20.775 | 5122.1 samples/s | 80.0 steps/s
[Step=78200 Epoch=383.5] | Loss=0.00307 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.832 | L2-Norm(final)=20.784 | 7956.7 samples/s | 124.3 steps/s
[Step=78250 Epoch=383.7] | Loss=0.00303 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.834 | L2-Norm(final)=20.793 | 2199.9 samples/s | 34.4 steps/s
[Step=78300 Epoch=384.0] | Loss=0.00288 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.836 | L2-Norm(final)=20.802 | 5039.8 samples/s | 78.7 steps/s
[Step=78350 Epoch=384.2] | Loss=0.00285 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.838 | L2-Norm(final)=20.811 | 5015.1 samples/s | 78.4 steps/s
[Step=78400 Epoch=384.5] | Loss=0.00291 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=20.820 | 7331.8 samples/s | 114.6 steps/s
[Step=78450 Epoch=384.7] | Loss=0.00285 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=20.829 | 2244.0 samples/s | 35.1 steps/s
[Step=78500 Epoch=385.0] | Loss=0.00280 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=20.838 | 5013.2 samples/s | 78.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=385.0] | Loss=0.00174 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.862 | L2-Norm(final)=20.927 | 5006.3 samples/s | 78.2 steps/s
[Step=78550 Epoch=385.2] | Loss=0.00256 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.865 | L2-Norm(final)=20.935 | 4293.3 samples/s | 67.1 steps/s
[Step=78600 Epoch=385.4] | Loss=0.00288 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=20.944 | 4523.5 samples/s | 70.7 steps/s
[Step=78650 Epoch=385.7] | Loss=0.00345 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.875 | L2-Norm(final)=20.952 | 4446.4 samples/s | 69.5 steps/s
[Step=78700 Epoch=385.9] | Loss=0.00437 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.880 | L2-Norm(final)=20.960 | 6567.8 samples/s | 102.6 steps/s
[Step=78750 Epoch=386.2] | Loss=0.00435 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.886 | L2-Norm(final)=20.968 | 2091.3 samples/s | 32.7 steps/s
[Step=78800 Epoch=386.4] | Loss=0.00471 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.891 | L2-Norm(final)=20.974 | 4496.0 samples/s | 70.2 steps/s
[Step=78850 Epoch=386.7] | Loss=0.00481 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.895 | L2-Norm(final)=20.981 | 4484.1 samples/s | 70.1 steps/s
[Step=78900 Epoch=386.9] | Loss=0.00511 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=20.987 | 6260.4 samples/s | 97.8 steps/s
[Step=78950 Epoch=387.2] | Loss=0.00481 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=20.993 | 2127.7 samples/s | 33.2 steps/s
[Step=79000 Epoch=387.4] | Loss=0.00450 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.907 | L2-Norm(final)=20.998 | 4414.9 samples/s | 69.0 steps/s
[Step=79050 Epoch=387.6] | Loss=0.00428 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.909 | L2-Norm(final)=21.003 | 4481.4 samples/s | 70.0 steps/s
[Step=79100 Epoch=387.9] | Loss=0.00419 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.911 | L2-Norm(final)=21.008 | 5869.2 samples/s | 91.7 steps/s
[Step=79150 Epoch=388.1] | Loss=0.00401 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.913 | L2-Norm(final)=21.013 | 2187.3 samples/s | 34.2 steps/s
[Step=79200 Epoch=388.4] | Loss=0.00384 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=21.017 | 4553.9 samples/s | 71.2 steps/s
[Step=79250 Epoch=388.6] | Loss=0.00367 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=21.022 | 4453.1 samples/s | 69.6 steps/s
[Step=79300 Epoch=388.9] | Loss=0.00358 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.917 | L2-Norm(final)=21.026 | 5528.2 samples/s | 86.4 steps/s
[Step=79350 Epoch=389.1] | Loss=0.00344 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.918 | L2-Norm(final)=21.030 | 2203.2 samples/s | 34.4 steps/s
[Step=79400 Epoch=389.4] | Loss=0.00333 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.918 | L2-Norm(final)=21.034 | 4446.8 samples/s | 69.5 steps/s
[Step=79450 Epoch=389.6] | Loss=0.00326 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.037 | 4510.5 samples/s | 70.5 steps/s
[Step=79500 Epoch=389.9] | Loss=0.00319 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.041 | 5181.1 samples/s | 81.0 steps/s
[Step=79550 Epoch=390.1] | Loss=0.00314 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.044 | 2251.0 samples/s | 35.2 steps/s
[Step=79600 Epoch=390.3] | Loss=0.00311 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.048 | 4577.6 samples/s | 71.5 steps/s
[Step=79650 Epoch=390.6] | Loss=0.00302 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.051 | 4465.6 samples/s | 69.8 steps/s
[Step=79700 Epoch=390.8] | Loss=0.00295 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.054 | 4864.1 samples/s | 76.0 steps/s
[Step=79750 Epoch=391.1] | Loss=0.00287 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.918 | L2-Norm(final)=21.057 | 2294.9 samples/s | 35.9 steps/s
[Step=79800 Epoch=391.3] | Loss=0.00288 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.918 | L2-Norm(final)=21.061 | 4512.2 samples/s | 70.5 steps/s
[Step=79850 Epoch=391.6] | Loss=0.00288 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.917 | L2-Norm(final)=21.064 | 4474.7 samples/s | 69.9 steps/s
[Step=79900 Epoch=391.8] | Loss=0.00282 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.917 | L2-Norm(final)=21.067 | 4674.4 samples/s | 73.0 steps/s
[Step=79950 Epoch=392.1] | Loss=0.00277 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=21.070 | 2399.9 samples/s | 37.5 steps/s
[Step=80000 Epoch=392.3] | Loss=0.00274 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=21.073 | 4538.0 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step80000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=739.1] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.141 | L2-Norm(final)=10.244 | 5127.4 samples/s | 80.1 steps/s
[Step=78050 Epoch=739.6] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.143 | L2-Norm(final)=10.247 | 4310.9 samples/s | 67.4 steps/s
[Step=78100 Epoch=740.1] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.145 | L2-Norm(final)=10.251 | 7102.9 samples/s | 111.0 steps/s
[Step=78150 Epoch=740.5] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=10.256 | 2118.4 samples/s | 33.1 steps/s
[Step=78200 Epoch=741.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=10.260 | 6668.1 samples/s | 104.2 steps/s
[Step=78250 Epoch=741.5] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.151 | L2-Norm(final)=10.264 | 2208.3 samples/s | 34.5 steps/s
[Step=78300 Epoch=742.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.153 | L2-Norm(final)=10.268 | 5884.7 samples/s | 91.9 steps/s
[Step=78350 Epoch=742.4] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.155 | L2-Norm(final)=10.272 | 2275.2 samples/s | 35.5 steps/s
[Step=78400 Epoch=742.9] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=10.276 | 5389.2 samples/s | 84.2 steps/s
[Step=78450 Epoch=743.4] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=10.280 | 2448.2 samples/s | 38.3 steps/s
[Step=78500 Epoch=743.9] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=10.284 | 4777.7 samples/s | 74.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=743.9] | Loss=0.00006 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.174 | L2-Norm(final)=10.322 | 5322.5 samples/s | 83.2 steps/s
[Step=78550 Epoch=744.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.175 | L2-Norm(final)=10.325 | 3780.5 samples/s | 59.1 steps/s
[Step=78600 Epoch=744.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.174 | L2-Norm(final)=10.328 | 6151.5 samples/s | 96.1 steps/s
[Step=78650 Epoch=745.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.172 | L2-Norm(final)=10.330 | 1998.5 samples/s | 31.2 steps/s
[Step=78700 Epoch=745.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.170 | L2-Norm(final)=10.332 | 5502.0 samples/s | 86.0 steps/s
[Step=78750 Epoch=746.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=10.333 | 2101.8 samples/s | 32.8 steps/s
[Step=78800 Epoch=746.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.164 | L2-Norm(final)=10.335 | 5174.3 samples/s | 80.8 steps/s
[Step=78850 Epoch=747.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=10.336 | 2163.7 samples/s | 33.8 steps/s
[Step=78900 Epoch=747.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=10.337 | 4736.6 samples/s | 74.0 steps/s
[Step=78950 Epoch=748.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.153 | L2-Norm(final)=10.338 | 2232.4 samples/s | 34.9 steps/s
[Step=79000 Epoch=748.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.150 | L2-Norm(final)=10.339 | 4351.0 samples/s | 68.0 steps/s
[Step=79050 Epoch=749.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.146 | L2-Norm(final)=10.340 | 2361.3 samples/s | 36.9 steps/s
[Step=79100 Epoch=749.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.142 | L2-Norm(final)=10.341 | 4275.0 samples/s | 66.8 steps/s
[Step=79150 Epoch=750.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=10.341 | 2388.1 samples/s | 37.3 steps/s
[Step=79200 Epoch=750.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=10.342 | 4273.2 samples/s | 66.8 steps/s
[Step=79250 Epoch=751.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=10.343 | 2338.6 samples/s | 36.5 steps/s
[Step=79300 Epoch=751.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=10.344 | 4272.7 samples/s | 66.8 steps/s
[Step=79350 Epoch=751.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=10.345 | 2479.2 samples/s | 38.7 steps/s
[Step=79400 Epoch=752.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.118 | L2-Norm(final)=10.346 | 4000.5 samples/s | 62.5 steps/s
[Step=79450 Epoch=752.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.113 | L2-Norm(final)=10.346 | 6570.4 samples/s | 102.7 steps/s
[Step=79500 Epoch=753.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.109 | L2-Norm(final)=10.347 | 1989.7 samples/s | 31.1 steps/s
[Step=79550 Epoch=753.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.105 | L2-Norm(final)=10.348 | 5826.5 samples/s | 91.0 steps/s
[Step=79600 Epoch=754.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.100 | L2-Norm(final)=10.349 | 2074.9 samples/s | 32.4 steps/s
[Step=79650 Epoch=754.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.096 | L2-Norm(final)=10.350 | 5307.3 samples/s | 82.9 steps/s
[Step=79700 Epoch=755.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.091 | L2-Norm(final)=10.350 | 2150.3 samples/s | 33.6 steps/s
[Step=79750 Epoch=755.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=10.351 | 4868.8 samples/s | 76.1 steps/s
[Step=79800 Epoch=756.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.082 | L2-Norm(final)=10.352 | 2235.1 samples/s | 34.9 steps/s
[Step=79850 Epoch=756.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.077 | L2-Norm(final)=10.353 | 4357.6 samples/s | 68.1 steps/s
[Step=79900 Epoch=757.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.072 | L2-Norm(final)=10.354 | 2342.8 samples/s | 36.6 steps/s
[Step=79950 Epoch=757.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=10.354 | 4257.4 samples/s | 66.5 steps/s
[Step=80000 Epoch=758.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.062 | L2-Norm(final)=10.355 | 2381.3 samples/s | 37.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step80000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=742.0] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=11.397 | 5103.9 samples/s | 79.7 steps/s
[Step=78050 Epoch=742.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=11.399 | 4057.0 samples/s | 63.4 steps/s
[Step=78100 Epoch=742.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=11.402 | 7435.8 samples/s | 116.2 steps/s
[Step=78150 Epoch=743.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.151 | L2-Norm(final)=11.405 | 2131.5 samples/s | 33.3 steps/s
[Step=78200 Epoch=743.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.153 | L2-Norm(final)=11.409 | 6631.9 samples/s | 103.6 steps/s
[Step=78250 Epoch=744.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=11.411 | 2250.6 samples/s | 35.2 steps/s
[Step=78300 Epoch=744.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=11.414 | 5795.6 samples/s | 90.6 steps/s
[Step=78350 Epoch=745.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=11.417 | 2271.7 samples/s | 35.5 steps/s
[Step=78400 Epoch=745.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=11.420 | 5290.4 samples/s | 82.7 steps/s
[Step=78450 Epoch=746.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=11.422 | 2382.6 samples/s | 37.2 steps/s
[Step=78500 Epoch=746.7] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=11.425 | 4942.7 samples/s | 77.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=746.7] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.168 | L2-Norm(final)=11.453 | 5484.5 samples/s | 85.7 steps/s
[Step=78550 Epoch=747.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=11.455 | 3839.9 samples/s | 60.0 steps/s
[Step=78600 Epoch=747.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.165 | L2-Norm(final)=11.457 | 6341.7 samples/s | 99.1 steps/s
[Step=78650 Epoch=748.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=11.459 | 2004.6 samples/s | 31.3 steps/s
[Step=78700 Epoch=748.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.159 | L2-Norm(final)=11.460 | 5690.4 samples/s | 88.9 steps/s
[Step=78750 Epoch=749.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=11.462 | 2125.6 samples/s | 33.2 steps/s
[Step=78800 Epoch=749.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.152 | L2-Norm(final)=11.463 | 5062.9 samples/s | 79.1 steps/s
[Step=78850 Epoch=750.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.148 | L2-Norm(final)=11.464 | 2176.5 samples/s | 34.0 steps/s
[Step=78900 Epoch=750.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.144 | L2-Norm(final)=11.465 | 4788.6 samples/s | 74.8 steps/s
[Step=78950 Epoch=751.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.140 | L2-Norm(final)=11.466 | 2267.4 samples/s | 35.4 steps/s
[Step=79000 Epoch=751.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.467 | 4332.9 samples/s | 67.7 steps/s
[Step=79050 Epoch=752.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=11.468 | 2361.6 samples/s | 36.9 steps/s
[Step=79100 Epoch=752.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=11.469 | 4292.7 samples/s | 67.1 steps/s
[Step=79150 Epoch=752.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.470 | 2406.2 samples/s | 37.6 steps/s
[Step=79200 Epoch=753.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.117 | L2-Norm(final)=11.471 | 4287.0 samples/s | 67.0 steps/s
[Step=79250 Epoch=753.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.472 | 2377.9 samples/s | 37.2 steps/s
[Step=79300 Epoch=754.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.108 | L2-Norm(final)=11.473 | 4207.6 samples/s | 65.7 steps/s
[Step=79350 Epoch=754.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.103 | L2-Norm(final)=11.474 | 2522.8 samples/s | 39.4 steps/s
[Step=79400 Epoch=755.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.475 | 3885.9 samples/s | 60.7 steps/s
[Step=79450 Epoch=755.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.093 | L2-Norm(final)=11.476 | 6452.9 samples/s | 100.8 steps/s
[Step=79500 Epoch=756.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.088 | L2-Norm(final)=11.477 | 1991.3 samples/s | 31.1 steps/s
[Step=79550 Epoch=756.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=11.478 | 5825.7 samples/s | 91.0 steps/s
[Step=79600 Epoch=757.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.077 | L2-Norm(final)=11.479 | 2039.1 samples/s | 31.9 steps/s
[Step=79650 Epoch=757.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.072 | L2-Norm(final)=11.480 | 5354.4 samples/s | 83.7 steps/s
[Step=79700 Epoch=758.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=11.481 | 2157.0 samples/s | 33.7 steps/s
[Step=79750 Epoch=758.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.061 | L2-Norm(final)=11.482 | 4861.6 samples/s | 76.0 steps/s
[Step=79800 Epoch=759.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.056 | L2-Norm(final)=11.483 | 2216.4 samples/s | 34.6 steps/s
[Step=79850 Epoch=759.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.050 | L2-Norm(final)=11.484 | 4411.1 samples/s | 68.9 steps/s
[Step=79900 Epoch=760.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.045 | L2-Norm(final)=11.485 | 2317.7 samples/s | 36.2 steps/s
[Step=79950 Epoch=760.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.486 | 4206.2 samples/s | 65.7 steps/s
[Step=80000 Epoch=761.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.033 | L2-Norm(final)=11.487 | 2397.3 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step80000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=744.9] | Loss=0.00007 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.132 | L2-Norm(final)=11.004 | 4951.7 samples/s | 77.4 steps/s
[Step=78050 Epoch=745.3] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.005 | 4199.4 samples/s | 65.6 steps/s
[Step=78100 Epoch=745.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.006 | 7454.4 samples/s | 116.5 steps/s
[Step=78150 Epoch=746.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.007 | 2105.0 samples/s | 32.9 steps/s
[Step=78200 Epoch=746.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=11.009 | 6660.1 samples/s | 104.1 steps/s
[Step=78250 Epoch=747.2] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=11.010 | 2175.2 samples/s | 34.0 steps/s
[Step=78300 Epoch=747.7] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=11.011 | 6191.8 samples/s | 96.7 steps/s
[Step=78350 Epoch=748.2] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.013 | 2309.2 samples/s | 36.1 steps/s
[Step=78400 Epoch=748.7] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.014 | 5310.7 samples/s | 83.0 steps/s
[Step=78450 Epoch=749.1] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.015 | 2296.4 samples/s | 35.9 steps/s
[Step=78500 Epoch=749.6] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.017 | 5233.7 samples/s | 81.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=749.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=11.030 | 5075.0 samples/s | 79.3 steps/s
[Step=78550 Epoch=750.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=11.031 | 3901.7 samples/s | 61.0 steps/s
[Step=78600 Epoch=750.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=11.033 | 6378.4 samples/s | 99.7 steps/s
[Step=78650 Epoch=751.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=11.034 | 2012.3 samples/s | 31.4 steps/s
[Step=78700 Epoch=751.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.035 | 5740.7 samples/s | 89.7 steps/s
[Step=78750 Epoch=752.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=11.036 | 2068.9 samples/s | 32.3 steps/s
[Step=78800 Epoch=752.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.036 | 5411.0 samples/s | 84.5 steps/s
[Step=78850 Epoch=753.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=11.037 | 2138.5 samples/s | 33.4 steps/s
[Step=78900 Epoch=753.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.130 | L2-Norm(final)=11.038 | 4988.7 samples/s | 77.9 steps/s
[Step=78950 Epoch=753.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.038 | 2222.6 samples/s | 34.7 steps/s
[Step=79000 Epoch=754.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=11.039 | 4539.2 samples/s | 70.9 steps/s
[Step=79050 Epoch=754.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.125 | L2-Norm(final)=11.040 | 2268.7 samples/s | 35.4 steps/s
[Step=79100 Epoch=755.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=11.040 | 4369.8 samples/s | 68.3 steps/s
[Step=79150 Epoch=755.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.121 | L2-Norm(final)=11.041 | 2384.0 samples/s | 37.2 steps/s
[Step=79200 Epoch=756.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.119 | L2-Norm(final)=11.041 | 4210.2 samples/s | 65.8 steps/s
[Step=79250 Epoch=756.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.117 | L2-Norm(final)=11.042 | 2366.2 samples/s | 37.0 steps/s
[Step=79300 Epoch=757.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=11.042 | 4229.2 samples/s | 66.1 steps/s
[Step=79350 Epoch=757.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.113 | L2-Norm(final)=11.043 | 2390.7 samples/s | 37.4 steps/s
[Step=79400 Epoch=758.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.043 | 4344.0 samples/s | 67.9 steps/s
[Step=79450 Epoch=758.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.109 | L2-Norm(final)=11.044 | 2349.4 samples/s | 36.7 steps/s
[Step=79500 Epoch=759.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.107 | L2-Norm(final)=11.045 | 4298.3 samples/s | 67.2 steps/s
[Step=79550 Epoch=759.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.104 | L2-Norm(final)=11.045 | 6879.8 samples/s | 107.5 steps/s
[Step=79600 Epoch=760.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.102 | L2-Norm(final)=11.046 | 1957.4 samples/s | 30.6 steps/s
[Step=79650 Epoch=760.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.100 | L2-Norm(final)=11.046 | 6237.5 samples/s | 97.5 steps/s
[Step=79700 Epoch=761.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.097 | L2-Norm(final)=11.047 | 2023.3 samples/s | 31.6 steps/s
[Step=79750 Epoch=761.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.095 | L2-Norm(final)=11.047 | 5786.3 samples/s | 90.4 steps/s
[Step=79800 Epoch=762.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.092 | L2-Norm(final)=11.048 | 2061.8 samples/s | 32.2 steps/s
[Step=79850 Epoch=762.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.090 | L2-Norm(final)=11.048 | 5349.7 samples/s | 83.6 steps/s
[Step=79900 Epoch=763.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.049 | 2101.7 samples/s | 32.8 steps/s
[Step=79950 Epoch=763.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.085 | L2-Norm(final)=11.049 | 5007.1 samples/s | 78.2 steps/s
[Step=80000 Epoch=764.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.082 | L2-Norm(final)=11.050 | 2184.8 samples/s | 34.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step80000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=735.0] | Loss=0.00024 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.244 | L2-Norm(final)=10.844 | 5529.0 samples/s | 86.4 steps/s
[Step=78050 Epoch=735.5] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.253 | L2-Norm(final)=10.857 | 3981.5 samples/s | 62.2 steps/s
[Step=78100 Epoch=735.9] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=10.869 | 7435.7 samples/s | 116.2 steps/s
[Step=78150 Epoch=736.4] | Loss=0.00007 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.267 | L2-Norm(final)=10.882 | 2182.3 samples/s | 34.1 steps/s
[Step=78200 Epoch=736.9] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.274 | L2-Norm(final)=10.893 | 6115.1 samples/s | 95.5 steps/s
[Step=78250 Epoch=737.3] | Loss=0.00006 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.279 | L2-Norm(final)=10.903 | 2234.2 samples/s | 34.9 steps/s
[Step=78300 Epoch=737.8] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.283 | L2-Norm(final)=10.912 | 5685.3 samples/s | 88.8 steps/s
[Step=78350 Epoch=738.3] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.287 | L2-Norm(final)=10.920 | 2373.1 samples/s | 37.1 steps/s
[Step=78400 Epoch=738.8] | Loss=0.00005 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.290 | L2-Norm(final)=10.927 | 4973.7 samples/s | 77.7 steps/s
[Step=78450 Epoch=739.2] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.292 | L2-Norm(final)=10.934 | 2451.5 samples/s | 38.3 steps/s
[Step=78500 Epoch=739.7] | Loss=0.00004 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.295 | L2-Norm(final)=10.941 | 4715.2 samples/s | 73.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=739.7] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=11.009 | 4901.4 samples/s | 76.6 steps/s
[Step=78550 Epoch=740.2] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.318 | L2-Norm(final)=11.014 | 4005.0 samples/s | 62.6 steps/s
[Step=78600 Epoch=740.6] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.315 | L2-Norm(final)=11.019 | 6205.4 samples/s | 97.0 steps/s
[Step=78650 Epoch=741.1] | Loss=0.00049 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.317 | L2-Norm(final)=11.024 | 2050.2 samples/s | 32.0 steps/s
[Step=78700 Epoch=741.6] | Loss=0.00074 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=11.025 | 5462.4 samples/s | 85.3 steps/s
[Step=78750 Epoch=742.0] | Loss=0.00067 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.337 | L2-Norm(final)=11.026 | 2075.3 samples/s | 32.4 steps/s
[Step=78800 Epoch=742.5] | Loss=0.00056 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=11.027 | 4993.3 samples/s | 78.0 steps/s
[Step=78850 Epoch=743.0] | Loss=0.00052 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.347 | L2-Norm(final)=11.028 | 2255.3 samples/s | 35.2 steps/s
[Step=78900 Epoch=743.5] | Loss=0.00045 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.351 | L2-Norm(final)=11.029 | 4431.6 samples/s | 69.2 steps/s
[Step=78950 Epoch=743.9] | Loss=0.00041 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.354 | L2-Norm(final)=11.030 | 2320.2 samples/s | 36.3 steps/s
[Step=79000 Epoch=744.4] | Loss=0.00037 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.356 | L2-Norm(final)=11.031 | 4206.8 samples/s | 65.7 steps/s
[Step=79050 Epoch=744.9] | Loss=0.00033 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.358 | L2-Norm(final)=11.031 | 2353.3 samples/s | 36.8 steps/s
[Step=79100 Epoch=745.3] | Loss=0.00031 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.360 | L2-Norm(final)=11.032 | 4282.8 samples/s | 66.9 steps/s
[Step=79150 Epoch=745.8] | Loss=0.00028 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.361 | L2-Norm(final)=11.032 | 2403.6 samples/s | 37.6 steps/s
[Step=79200 Epoch=746.3] | Loss=0.00026 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.362 | L2-Norm(final)=11.033 | 4327.6 samples/s | 67.6 steps/s
[Step=79250 Epoch=746.8] | Loss=0.00025 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.362 | L2-Norm(final)=11.033 | 2536.5 samples/s | 39.6 steps/s
[Step=79300 Epoch=747.2] | Loss=0.00023 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.034 | 3760.3 samples/s | 58.8 steps/s
[Step=79350 Epoch=747.7] | Loss=0.00022 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.034 | 6277.3 samples/s | 98.1 steps/s
[Step=79400 Epoch=748.2] | Loss=0.00021 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.035 | 2030.7 samples/s | 31.7 steps/s
[Step=79450 Epoch=748.6] | Loss=0.00020 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.035 | 5551.4 samples/s | 86.7 steps/s
[Step=79500 Epoch=749.1] | Loss=0.00019 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.035 | 2125.3 samples/s | 33.2 steps/s
[Step=79550 Epoch=749.6] | Loss=0.00018 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.036 | 5012.8 samples/s | 78.3 steps/s
[Step=79600 Epoch=750.1] | Loss=0.00017 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.036 | 2199.8 samples/s | 34.4 steps/s
[Step=79650 Epoch=750.5] | Loss=0.00016 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.036 | 4551.4 samples/s | 71.1 steps/s
[Step=79700 Epoch=751.0] | Loss=0.00016 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.037 | 2296.8 samples/s | 35.9 steps/s
[Step=79750 Epoch=751.5] | Loss=0.00015 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.037 | 4233.7 samples/s | 66.2 steps/s
[Step=79800 Epoch=751.9] | Loss=0.00015 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.037 | 2407.6 samples/s | 37.6 steps/s
[Step=79850 Epoch=752.4] | Loss=0.00014 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.038 | 4277.9 samples/s | 66.8 steps/s
[Step=79900 Epoch=752.9] | Loss=0.00014 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.038 | 2354.4 samples/s | 36.8 steps/s
[Step=79950 Epoch=753.4] | Loss=0.00013 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.038 | 4335.5 samples/s | 67.7 steps/s
[Step=80000 Epoch=753.8] | Loss=0.00013 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.363 | L2-Norm(final)=11.039 | 2583.9 samples/s | 40.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step80000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=743.4] | Loss=0.00005 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.250 | L2-Norm(final)=11.464 | 5753.5 samples/s | 89.9 steps/s
[Step=78050 Epoch=743.9] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.251 | L2-Norm(final)=11.465 | 3927.1 samples/s | 61.4 steps/s
[Step=78100 Epoch=744.4] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.252 | L2-Norm(final)=11.466 | 7482.5 samples/s | 116.9 steps/s
[Step=78150 Epoch=744.8] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.252 | L2-Norm(final)=11.468 | 2097.9 samples/s | 32.8 steps/s
[Step=78200 Epoch=745.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.253 | L2-Norm(final)=11.470 | 6672.8 samples/s | 104.3 steps/s
[Step=78250 Epoch=745.8] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.253 | L2-Norm(final)=11.471 | 2198.6 samples/s | 34.4 steps/s
[Step=78300 Epoch=746.3] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.254 | L2-Norm(final)=11.473 | 6247.7 samples/s | 97.6 steps/s
[Step=78350 Epoch=746.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.254 | L2-Norm(final)=11.475 | 2267.0 samples/s | 35.4 steps/s
[Step=78400 Epoch=747.2] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.254 | L2-Norm(final)=11.477 | 5635.8 samples/s | 88.1 steps/s
[Step=78450 Epoch=747.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=11.478 | 2349.3 samples/s | 36.7 steps/s
[Step=78500 Epoch=748.2] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=11.480 | 5143.9 samples/s | 80.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=748.2] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=11.497 | 5138.3 samples/s | 80.3 steps/s
[Step=78550 Epoch=748.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=11.499 | 3860.7 samples/s | 60.3 steps/s
[Step=78600 Epoch=749.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.258 | L2-Norm(final)=11.500 | 6395.8 samples/s | 99.9 steps/s
[Step=78650 Epoch=749.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.257 | L2-Norm(final)=11.502 | 1996.2 samples/s | 31.2 steps/s
[Step=78700 Epoch=750.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.256 | L2-Norm(final)=11.503 | 5813.8 samples/s | 90.8 steps/s
[Step=78750 Epoch=750.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=11.504 | 2069.6 samples/s | 32.3 steps/s
[Step=78800 Epoch=751.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.253 | L2-Norm(final)=11.505 | 5254.7 samples/s | 82.1 steps/s
[Step=78850 Epoch=751.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.252 | L2-Norm(final)=11.506 | 2137.6 samples/s | 33.4 steps/s
[Step=78900 Epoch=752.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.250 | L2-Norm(final)=11.506 | 4986.5 samples/s | 77.9 steps/s
[Step=78950 Epoch=752.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.248 | L2-Norm(final)=11.507 | 2215.0 samples/s | 34.6 steps/s
[Step=79000 Epoch=752.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.246 | L2-Norm(final)=11.508 | 4671.3 samples/s | 73.0 steps/s
[Step=79050 Epoch=753.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.244 | L2-Norm(final)=11.509 | 2263.1 samples/s | 35.4 steps/s
[Step=79100 Epoch=753.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.242 | L2-Norm(final)=11.509 | 4343.6 samples/s | 67.9 steps/s
[Step=79150 Epoch=754.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.239 | L2-Norm(final)=11.510 | 2376.7 samples/s | 37.1 steps/s
[Step=79200 Epoch=754.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.237 | L2-Norm(final)=11.511 | 4243.6 samples/s | 66.3 steps/s
[Step=79250 Epoch=755.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.235 | L2-Norm(final)=11.511 | 2346.9 samples/s | 36.7 steps/s
[Step=79300 Epoch=755.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=11.512 | 4280.5 samples/s | 66.9 steps/s
[Step=79350 Epoch=756.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.230 | L2-Norm(final)=11.513 | 2360.3 samples/s | 36.9 steps/s
[Step=79400 Epoch=756.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.227 | L2-Norm(final)=11.513 | 4305.8 samples/s | 67.3 steps/s
[Step=79450 Epoch=757.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.225 | L2-Norm(final)=11.514 | 2384.6 samples/s | 37.3 steps/s
[Step=79500 Epoch=757.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=11.514 | 4195.0 samples/s | 65.5 steps/s
[Step=79550 Epoch=758.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.220 | L2-Norm(final)=11.515 | 7021.0 samples/s | 109.7 steps/s
[Step=79600 Epoch=758.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.217 | L2-Norm(final)=11.516 | 1941.6 samples/s | 30.3 steps/s
[Step=79650 Epoch=759.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.214 | L2-Norm(final)=11.516 | 6227.0 samples/s | 97.3 steps/s
[Step=79700 Epoch=759.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.211 | L2-Norm(final)=11.517 | 1978.9 samples/s | 30.9 steps/s
[Step=79750 Epoch=760.1] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.209 | L2-Norm(final)=11.517 | 5812.9 samples/s | 90.8 steps/s
[Step=79800 Epoch=760.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.206 | L2-Norm(final)=11.518 | 2066.5 samples/s | 32.3 steps/s
[Step=79850 Epoch=761.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.203 | L2-Norm(final)=11.519 | 5320.6 samples/s | 83.1 steps/s
[Step=79900 Epoch=761.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.200 | L2-Norm(final)=11.519 | 2149.8 samples/s | 33.6 steps/s
[Step=79950 Epoch=762.0] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.197 | L2-Norm(final)=11.520 | 4786.7 samples/s | 74.8 steps/s
[Step=80000 Epoch=762.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.194 | L2-Norm(final)=11.521 | 2241.0 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10516 | acc=0.9566 | tpr=0.9706 | fpr=0.0738 | 4675.4 samples/s | 18.3 steps/s
Avg test loss: 0.10816, Avg test acc: 0.95508, Avg tpr: 0.96911, Avg fpr: 0.07576, total FA: 591

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11636 | acc=0.9563 | tpr=0.9767 | fpr=0.0880 | 5050.8 samples/s | 19.7 steps/s
Avg test loss: 0.11462, Avg test acc: 0.95605, Avg tpr: 0.97628, Avg fpr: 0.08845, total FA: 690

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11069 | acc=0.9562 | tpr=0.9695 | fpr=0.0728 | 4775.7 samples/s | 18.7 steps/s
Avg test loss: 0.11284, Avg test acc: 0.95460, Avg tpr: 0.96713, Avg fpr: 0.07294, total FA: 569

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09971 | acc=0.9566 | tpr=0.9675 | fpr=0.0669 | 4687.7 samples/s | 18.3 steps/s
Avg test loss: 0.10440, Avg test acc: 0.95577, Avg tpr: 0.96818, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11496 | acc=0.9559 | tpr=0.9684 | fpr=0.0711 | 4786.2 samples/s | 18.7 steps/s
Avg test loss: 0.11898, Avg test acc: 0.95577, Avg tpr: 0.96870, Avg fpr: 0.07268, total FA: 567

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.53109 | acc=0.2973 | tpr=0.0107 | fpr=0.0805 | 5038.6 samples/s | 19.7 steps/s
Avg test loss: 5.53850, Avg test acc: 0.29622, Avg tpr: 0.01189, Avg fpr: 0.07845, total FA: 612

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.92095 | acc=0.3008 | tpr=0.0056 | fpr=0.0582 | 4587.4 samples/s | 17.9 steps/s
Avg test loss: 4.93477, Avg test acc: 0.29778, Avg tpr: 0.00577, Avg fpr: 0.05999, total FA: 468

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.34094 | acc=0.2906 | tpr=0.0126 | fpr=0.1056 | 4931.2 samples/s | 19.3 steps/s
Avg test loss: 5.34330, Avg test acc: 0.28873, Avg tpr: 0.01376, Avg fpr: 0.10652, total FA: 831

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.55304 | acc=0.2978 | tpr=0.0128 | fpr=0.0833 | 4780.2 samples/s | 18.7 steps/s
Avg test loss: 5.55295, Avg test acc: 0.29714, Avg tpr: 0.01387, Avg fpr: 0.07986, total FA: 623

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.99948 | acc=0.3044 | tpr=0.0134 | fpr=0.0637 | 4739.6 samples/s | 18.5 steps/s
Avg test loss: 5.00740, Avg test acc: 0.30219, Avg tpr: 0.01405, Avg fpr: 0.06409, total FA: 500

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.71524 | acc=0.1113 | tpr=0.5841 | fpr=0.8972 | 4847.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.68069 | acc=0.1133 | tpr=0.5842 | fpr=0.8955 | 6808.8 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.69212 | acc=0.1128 | tpr=0.5836 | fpr=0.8959 | 6901.1 samples/s | 27.0 steps/s
[Step= 200] | Loss=5.68293 | acc=0.1117 | tpr=0.5760 | fpr=0.8967 | 7760.7 samples/s | 30.3 steps/s
[Step= 250] | Loss=5.68544 | acc=0.1131 | tpr=0.5860 | fpr=0.8955 | 7713.5 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.68025 | acc=0.1129 | tpr=0.5905 | fpr=0.8958 | 8025.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=5.67147 | acc=0.1131 | tpr=0.5842 | fpr=0.8955 | 6780.3 samples/s | 26.5 steps/s
[Step= 400] | Loss=5.66953 | acc=0.1133 | tpr=0.5815 | fpr=0.8952 | 7776.3 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.67334 | acc=0.1136 | tpr=0.5823 | fpr=0.8949 | 7792.6 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.67534 | acc=0.1134 | tpr=0.5762 | fpr=0.8949 | 7847.8 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.67782 | acc=0.1134 | tpr=0.5734 | fpr=0.8950 | 13732.5 samples/s | 53.6 steps/s
Avg test loss: 5.67979, Avg test acc: 0.11332, Avg tpr: 0.57330, Avg fpr: 0.89504, total FA: 124275

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.79885 | acc=0.0908 | tpr=0.5000 | fpr=0.9166 | 4774.0 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.78504 | acc=0.0911 | tpr=0.5139 | fpr=0.9168 | 7044.2 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.78512 | acc=0.0908 | tpr=0.5216 | fpr=0.9171 | 7309.6 samples/s | 28.6 steps/s
[Step= 200] | Loss=5.77867 | acc=0.0902 | tpr=0.5202 | fpr=0.9176 | 7715.1 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.78403 | acc=0.0903 | tpr=0.5249 | fpr=0.9176 | 7523.8 samples/s | 29.4 steps/s
[Step= 300] | Loss=5.77937 | acc=0.0902 | tpr=0.5287 | fpr=0.9178 | 6591.2 samples/s | 25.7 steps/s
[Step= 350] | Loss=5.77318 | acc=0.0905 | tpr=0.5266 | fpr=0.9175 | 7891.5 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.77002 | acc=0.0906 | tpr=0.5263 | fpr=0.9174 | 7732.8 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.77474 | acc=0.0905 | tpr=0.5263 | fpr=0.9174 | 7662.2 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.77767 | acc=0.0904 | tpr=0.5238 | fpr=0.9175 | 7993.7 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.78317 | acc=0.0901 | tpr=0.5201 | fpr=0.9177 | 14128.0 samples/s | 55.2 steps/s
Avg test loss: 5.78527, Avg test acc: 0.09002, Avg tpr: 0.51941, Avg fpr: 0.91779, total FA: 127433

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.94778 | acc=0.0972 | tpr=0.3097 | fpr=0.9066 | 4859.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.91384 | acc=0.0985 | tpr=0.3028 | fpr=0.9053 | 6405.4 samples/s | 25.0 steps/s
[Step= 150] | Loss=5.92867 | acc=0.0989 | tpr=0.3040 | fpr=0.9049 | 8241.1 samples/s | 32.2 steps/s
[Step= 200] | Loss=5.91838 | acc=0.0993 | tpr=0.3016 | fpr=0.9044 | 7643.1 samples/s | 29.9 steps/s
[Step= 250] | Loss=5.91869 | acc=0.1002 | tpr=0.3092 | fpr=0.9037 | 7661.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.91412 | acc=0.1005 | tpr=0.3149 | fpr=0.9034 | 6235.3 samples/s | 24.4 steps/s
[Step= 350] | Loss=5.90756 | acc=0.1009 | tpr=0.3131 | fpr=0.9029 | 8100.0 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.90531 | acc=0.1010 | tpr=0.3140 | fpr=0.9029 | 7648.9 samples/s | 29.9 steps/s
[Step= 450] | Loss=5.91023 | acc=0.1011 | tpr=0.3092 | fpr=0.9027 | 7659.0 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.91101 | acc=0.1008 | tpr=0.3088 | fpr=0.9030 | 7922.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.91572 | acc=0.1005 | tpr=0.3088 | fpr=0.9033 | 14030.9 samples/s | 54.8 steps/s
Avg test loss: 5.91722, Avg test acc: 0.10035, Avg tpr: 0.30943, Avg fpr: 0.90346, total FA: 125443

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.42047 | acc=0.1120 | tpr=0.5177 | fpr=0.8953 | 4947.0 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.39601 | acc=0.1112 | tpr=0.5096 | fpr=0.8962 | 5848.2 samples/s | 22.8 steps/s
[Step= 150] | Loss=5.40415 | acc=0.1100 | tpr=0.5187 | fpr=0.8975 | 8895.8 samples/s | 34.7 steps/s
[Step= 200] | Loss=5.39491 | acc=0.1087 | tpr=0.5169 | fpr=0.8987 | 7278.8 samples/s | 28.4 steps/s
[Step= 250] | Loss=5.39817 | acc=0.1095 | tpr=0.5188 | fpr=0.8980 | 7604.5 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.39536 | acc=0.1096 | tpr=0.5273 | fpr=0.8980 | 6906.0 samples/s | 27.0 steps/s
[Step= 350] | Loss=5.38528 | acc=0.1096 | tpr=0.5272 | fpr=0.8980 | 7475.9 samples/s | 29.2 steps/s
[Step= 400] | Loss=5.38073 | acc=0.1097 | tpr=0.5213 | fpr=0.8978 | 8059.3 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.38619 | acc=0.1096 | tpr=0.5175 | fpr=0.8978 | 7600.9 samples/s | 29.7 steps/s
[Step= 500] | Loss=5.38625 | acc=0.1095 | tpr=0.5137 | fpr=0.8978 | 7605.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=5.39051 | acc=0.1089 | tpr=0.5054 | fpr=0.8983 | 14691.3 samples/s | 57.4 steps/s
Avg test loss: 5.39206, Avg test acc: 0.10879, Avg tpr: 0.50515, Avg fpr: 0.89841, total FA: 124743

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.07874 | acc=0.1113 | tpr=0.4823 | fpr=0.8953 | 4851.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.05233 | acc=0.1127 | tpr=0.4840 | fpr=0.8942 | 6320.9 samples/s | 24.7 steps/s
[Step= 150] | Loss=6.05343 | acc=0.1126 | tpr=0.4914 | fpr=0.8944 | 7766.6 samples/s | 30.3 steps/s
[Step= 200] | Loss=6.04767 | acc=0.1128 | tpr=0.4852 | fpr=0.8940 | 7983.8 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.05016 | acc=0.1139 | tpr=0.4961 | fpr=0.8931 | 6208.8 samples/s | 24.3 steps/s
[Step= 300] | Loss=6.04986 | acc=0.1138 | tpr=0.5011 | fpr=0.8932 | 8078.8 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.04063 | acc=0.1142 | tpr=0.4991 | fpr=0.8928 | 7657.3 samples/s | 29.9 steps/s
[Step= 400] | Loss=6.03957 | acc=0.1141 | tpr=0.4951 | fpr=0.8928 | 7841.8 samples/s | 30.6 steps/s
[Step= 450] | Loss=6.04456 | acc=0.1144 | tpr=0.4932 | fpr=0.8925 | 8036.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.04732 | acc=0.1143 | tpr=0.4907 | fpr=0.8925 | 7750.7 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.05328 | acc=0.1137 | tpr=0.4891 | fpr=0.8931 | 13809.9 samples/s | 53.9 steps/s
Avg test loss: 6.05563, Avg test acc: 0.11359, Avg tpr: 0.48851, Avg fpr: 0.89322, total FA: 124022

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09266 | acc=0.9818 | tpr=0.9646 | fpr=0.0179 | 4905.4 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.09422 | acc=0.9816 | tpr=0.9638 | fpr=0.0181 | 7008.3 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.09796 | acc=0.9808 | tpr=0.9625 | fpr=0.0189 | 7300.6 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.09984 | acc=0.9809 | tpr=0.9672 | fpr=0.0189 | 8511.8 samples/s | 33.2 steps/s
[Step= 250] | Loss=0.09837 | acc=0.9811 | tpr=0.9616 | fpr=0.0185 | 5773.9 samples/s | 22.6 steps/s
[Step= 300] | Loss=0.10064 | acc=0.9808 | tpr=0.9593 | fpr=0.0188 | 7476.1 samples/s | 29.2 steps/s
[Step= 350] | Loss=0.10159 | acc=0.9805 | tpr=0.9593 | fpr=0.0191 | 8424.9 samples/s | 32.9 steps/s
[Step= 400] | Loss=0.10260 | acc=0.9801 | tpr=0.9551 | fpr=0.0194 | 7753.6 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10453 | acc=0.9798 | tpr=0.9513 | fpr=0.0197 | 7859.0 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10379 | acc=0.9798 | tpr=0.9515 | fpr=0.0197 | 7540.4 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.10313 | acc=0.9800 | tpr=0.9503 | fpr=0.0195 | 15036.5 samples/s | 58.7 steps/s
Avg test loss: 0.10299, Avg test acc: 0.97995, Avg tpr: 0.95008, Avg fpr: 0.01950, total FA: 2708

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08971 | acc=0.9821 | tpr=0.9248 | fpr=0.0169 | 4629.4 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.09249 | acc=0.9820 | tpr=0.9296 | fpr=0.0170 | 7303.9 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.09584 | acc=0.9815 | tpr=0.9294 | fpr=0.0176 | 8209.7 samples/s | 32.1 steps/s
[Step= 200] | Loss=0.09800 | acc=0.9816 | tpr=0.9311 | fpr=0.0175 | 7802.6 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09616 | acc=0.9819 | tpr=0.9310 | fpr=0.0171 | 5683.0 samples/s | 22.2 steps/s
[Step= 300] | Loss=0.09847 | acc=0.9816 | tpr=0.9295 | fpr=0.0174 | 7968.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.09903 | acc=0.9815 | tpr=0.9324 | fpr=0.0177 | 7849.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10033 | acc=0.9812 | tpr=0.9278 | fpr=0.0178 | 7626.5 samples/s | 29.8 steps/s
[Step= 450] | Loss=0.10260 | acc=0.9810 | tpr=0.9275 | fpr=0.0180 | 8195.5 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.10177 | acc=0.9811 | tpr=0.9291 | fpr=0.0180 | 7820.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.10149 | acc=0.9812 | tpr=0.9276 | fpr=0.0178 | 13734.4 samples/s | 53.6 steps/s
Avg test loss: 0.10140, Avg test acc: 0.98124, Avg tpr: 0.92789, Avg fpr: 0.01779, total FA: 2470

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08529 | acc=0.9819 | tpr=0.9602 | fpr=0.0177 | 4775.6 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.08656 | acc=0.9822 | tpr=0.9659 | fpr=0.0175 | 7193.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.09081 | acc=0.9812 | tpr=0.9611 | fpr=0.0184 | 7690.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.09209 | acc=0.9814 | tpr=0.9661 | fpr=0.0183 | 5981.1 samples/s | 23.4 steps/s
[Step= 250] | Loss=0.09047 | acc=0.9816 | tpr=0.9659 | fpr=0.0181 | 7330.7 samples/s | 28.6 steps/s
[Step= 300] | Loss=0.09267 | acc=0.9812 | tpr=0.9607 | fpr=0.0184 | 8319.2 samples/s | 32.5 steps/s
[Step= 350] | Loss=0.09349 | acc=0.9809 | tpr=0.9624 | fpr=0.0188 | 7563.9 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.09453 | acc=0.9807 | tpr=0.9595 | fpr=0.0190 | 8082.2 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.09618 | acc=0.9804 | tpr=0.9586 | fpr=0.0192 | 7944.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.09560 | acc=0.9804 | tpr=0.9604 | fpr=0.0192 | 7714.2 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.09514 | acc=0.9805 | tpr=0.9594 | fpr=0.0191 | 14058.9 samples/s | 54.9 steps/s
Avg test loss: 0.09502, Avg test acc: 0.98051, Avg tpr: 0.95959, Avg fpr: 0.01911, total FA: 2653

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.08747 | acc=0.9809 | tpr=0.9381 | fpr=0.0184 | 4873.6 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.09065 | acc=0.9808 | tpr=0.9446 | fpr=0.0185 | 6790.9 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.09465 | acc=0.9800 | tpr=0.9438 | fpr=0.0194 | 8028.1 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.09558 | acc=0.9801 | tpr=0.9519 | fpr=0.0193 | 5767.1 samples/s | 22.5 steps/s
[Step= 250] | Loss=0.09421 | acc=0.9805 | tpr=0.9467 | fpr=0.0189 | 8184.9 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.09604 | acc=0.9803 | tpr=0.9462 | fpr=0.0191 | 7439.0 samples/s | 29.1 steps/s
[Step= 350] | Loss=0.09703 | acc=0.9801 | tpr=0.9474 | fpr=0.0193 | 8066.2 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.09754 | acc=0.9801 | tpr=0.9458 | fpr=0.0193 | 7894.7 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.09950 | acc=0.9798 | tpr=0.9421 | fpr=0.0195 | 7842.6 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.09881 | acc=0.9799 | tpr=0.9449 | fpr=0.0194 | 7663.3 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.09835 | acc=0.9801 | tpr=0.9451 | fpr=0.0192 | 14342.1 samples/s | 56.0 steps/s
Avg test loss: 0.09816, Avg test acc: 0.98016, Avg tpr: 0.94532, Avg fpr: 0.01921, total FA: 2667

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09441 | acc=0.9812 | tpr=0.9292 | fpr=0.0178 | 4745.7 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.09819 | acc=0.9806 | tpr=0.9339 | fpr=0.0185 | 7047.9 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.10172 | acc=0.9796 | tpr=0.9337 | fpr=0.0196 | 8018.5 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.10319 | acc=0.9796 | tpr=0.9432 | fpr=0.0197 | 5715.2 samples/s | 22.3 steps/s
[Step= 250] | Loss=0.10152 | acc=0.9800 | tpr=0.9415 | fpr=0.0193 | 8719.5 samples/s | 34.1 steps/s
[Step= 300] | Loss=0.10369 | acc=0.9797 | tpr=0.9375 | fpr=0.0195 | 7476.3 samples/s | 29.2 steps/s
[Step= 350] | Loss=0.10433 | acc=0.9795 | tpr=0.9393 | fpr=0.0197 | 7835.2 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.10560 | acc=0.9793 | tpr=0.9365 | fpr=0.0199 | 7663.4 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.10781 | acc=0.9791 | tpr=0.9348 | fpr=0.0201 | 7849.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10729 | acc=0.9791 | tpr=0.9352 | fpr=0.0201 | 8621.7 samples/s | 33.7 steps/s
[Step= 550] | Loss=0.10688 | acc=0.9793 | tpr=0.9355 | fpr=0.0199 | 12400.6 samples/s | 48.4 steps/s
Avg test loss: 0.10672, Avg test acc: 0.97934, Avg tpr: 0.93542, Avg fpr: 0.01986, total FA: 2758

server round 40/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=390.1] | Loss=0.00172 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=20.159 | 5265.6 samples/s | 82.3 steps/s
[Step=80050 Epoch=390.3] | Loss=0.00272 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=20.162 | 4581.9 samples/s | 71.6 steps/s
[Step=80100 Epoch=390.6] | Loss=0.00295 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.074 | L2-Norm(final)=20.166 | 4985.7 samples/s | 77.9 steps/s
[Step=80150 Epoch=390.8] | Loss=0.00270 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.074 | L2-Norm(final)=20.170 | 5032.7 samples/s | 78.6 steps/s
[Step=80200 Epoch=391.1] | Loss=0.00282 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=20.174 | 7888.8 samples/s | 123.3 steps/s
[Step=80250 Epoch=391.3] | Loss=0.00278 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=20.178 | 2189.0 samples/s | 34.2 steps/s
[Step=80300 Epoch=391.6] | Loss=0.00280 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.076 | L2-Norm(final)=20.182 | 5009.3 samples/s | 78.3 steps/s
[Step=80350 Epoch=391.8] | Loss=0.00271 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.076 | L2-Norm(final)=20.187 | 5045.4 samples/s | 78.8 steps/s
[Step=80400 Epoch=392.0] | Loss=0.00269 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=20.191 | 7029.6 samples/s | 109.8 steps/s
[Step=80450 Epoch=392.3] | Loss=0.00272 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=20.195 | 2297.7 samples/s | 35.9 steps/s
[Step=80500 Epoch=392.5] | Loss=0.00270 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=20.199 | 5188.6 samples/s | 81.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=392.5] | Loss=0.00078 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=20.239 | 5365.0 samples/s | 83.8 steps/s
[Step=80550 Epoch=392.8] | Loss=0.00206 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=20.244 | 3927.8 samples/s | 61.4 steps/s
[Step=80600 Epoch=393.0] | Loss=0.00276 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.086 | L2-Norm(final)=20.247 | 4490.3 samples/s | 70.2 steps/s
[Step=80650 Epoch=393.3] | Loss=0.00287 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=20.252 | 4460.9 samples/s | 69.7 steps/s
[Step=80700 Epoch=393.5] | Loss=0.00329 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=20.256 | 6549.9 samples/s | 102.3 steps/s
[Step=80750 Epoch=393.8] | Loss=0.00315 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=20.259 | 2113.0 samples/s | 33.0 steps/s
[Step=80800 Epoch=394.0] | Loss=0.00305 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=20.263 | 4379.1 samples/s | 68.4 steps/s
[Step=80850 Epoch=394.2] | Loss=0.00303 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=20.266 | 4471.4 samples/s | 69.9 steps/s
[Step=80900 Epoch=394.5] | Loss=0.00291 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=20.270 | 5885.3 samples/s | 92.0 steps/s
[Step=80950 Epoch=394.7] | Loss=0.00278 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.273 | 2112.7 samples/s | 33.0 steps/s
[Step=81000 Epoch=395.0] | Loss=0.00279 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.276 | 4481.4 samples/s | 70.0 steps/s
[Step=81050 Epoch=395.2] | Loss=0.00277 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.279 | 4559.6 samples/s | 71.2 steps/s
[Step=81100 Epoch=395.5] | Loss=0.00271 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.281 | 5325.5 samples/s | 83.2 steps/s
[Step=81150 Epoch=395.7] | Loss=0.00268 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=20.284 | 2263.1 samples/s | 35.4 steps/s
[Step=81200 Epoch=395.9] | Loss=0.00262 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=20.287 | 4474.6 samples/s | 69.9 steps/s
[Step=81250 Epoch=396.2] | Loss=0.00257 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=20.289 | 4404.7 samples/s | 68.8 steps/s
[Step=81300 Epoch=396.4] | Loss=0.00254 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=20.292 | 4940.0 samples/s | 77.2 steps/s
[Step=81350 Epoch=396.7] | Loss=0.00248 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.095 | L2-Norm(final)=20.295 | 2360.7 samples/s | 36.9 steps/s
[Step=81400 Epoch=396.9] | Loss=0.00247 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.297 | 4438.3 samples/s | 69.3 steps/s
[Step=81450 Epoch=397.2] | Loss=0.00247 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.094 | L2-Norm(final)=20.300 | 4518.8 samples/s | 70.6 steps/s
[Step=81500 Epoch=397.4] | Loss=0.00243 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.094 | L2-Norm(final)=20.302 | 4551.4 samples/s | 71.1 steps/s
[Step=81550 Epoch=397.7] | Loss=0.00241 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.304 | 2452.5 samples/s | 38.3 steps/s
[Step=81600 Epoch=397.9] | Loss=0.00239 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=20.307 | 4375.5 samples/s | 68.4 steps/s
[Step=81650 Epoch=398.1] | Loss=0.00238 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=20.309 | 4470.0 samples/s | 69.8 steps/s
[Step=81700 Epoch=398.4] | Loss=0.00236 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=20.312 | 4478.7 samples/s | 70.0 steps/s
[Step=81750 Epoch=398.6] | Loss=0.00232 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=20.314 | 2439.6 samples/s | 38.1 steps/s
[Step=81800 Epoch=398.9] | Loss=0.00228 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=20.316 | 4473.2 samples/s | 69.9 steps/s
[Step=81850 Epoch=399.1] | Loss=0.00228 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.092 | L2-Norm(final)=20.319 | 4479.3 samples/s | 70.0 steps/s
[Step=81900 Epoch=399.4] | Loss=0.00227 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=20.321 | 4473.8 samples/s | 69.9 steps/s
[Step=81950 Epoch=399.6] | Loss=0.00228 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=20.324 | 2090.8 samples/s | 32.7 steps/s
[Step=82000 Epoch=399.8] | Loss=0.00225 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=20.326 | 3866.7 samples/s | 60.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step82000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=390.4] | Loss=0.00036 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.977 | 5625.6 samples/s | 87.9 steps/s
[Step=80050 Epoch=390.6] | Loss=0.00251 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.980 | 4312.0 samples/s | 67.4 steps/s
[Step=80100 Epoch=390.9] | Loss=0.00230 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.984 | 5060.5 samples/s | 79.1 steps/s
[Step=80150 Epoch=391.1] | Loss=0.00249 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.988 | 5006.4 samples/s | 78.2 steps/s
[Step=80200 Epoch=391.3] | Loss=0.00249 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=20.992 | 7835.7 samples/s | 122.4 steps/s
[Step=80250 Epoch=391.6] | Loss=0.00250 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=20.995 | 2178.7 samples/s | 34.0 steps/s
[Step=80300 Epoch=391.8] | Loss=0.00242 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=20.999 | 5010.0 samples/s | 78.3 steps/s
[Step=80350 Epoch=392.1] | Loss=0.00243 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=21.003 | 5117.6 samples/s | 80.0 steps/s
[Step=80400 Epoch=392.3] | Loss=0.00236 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=21.007 | 6955.9 samples/s | 108.7 steps/s
[Step=80450 Epoch=392.6] | Loss=0.00241 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=21.011 | 2260.7 samples/s | 35.3 steps/s
[Step=80500 Epoch=392.8] | Loss=0.00239 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=21.015 | 5074.6 samples/s | 79.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=392.8] | Loss=0.00098 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.694 | L2-Norm(final)=21.054 | 5314.3 samples/s | 83.0 steps/s
[Step=80550 Epoch=393.0] | Loss=0.00292 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=21.058 | 4068.1 samples/s | 63.6 steps/s
[Step=80600 Epoch=393.3] | Loss=0.00311 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=21.062 | 4379.2 samples/s | 68.4 steps/s
[Step=80650 Epoch=393.5] | Loss=0.00273 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=21.066 | 4517.4 samples/s | 70.6 steps/s
[Step=80700 Epoch=393.8] | Loss=0.00270 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=21.069 | 6433.6 samples/s | 100.5 steps/s
[Step=80750 Epoch=394.0] | Loss=0.00256 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=21.073 | 2119.7 samples/s | 33.1 steps/s
[Step=80800 Epoch=394.3] | Loss=0.00246 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.700 | L2-Norm(final)=21.076 | 4324.4 samples/s | 67.6 steps/s
[Step=80850 Epoch=394.5] | Loss=0.00249 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=21.080 | 4504.2 samples/s | 70.4 steps/s
[Step=80900 Epoch=394.8] | Loss=0.00244 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=21.083 | 6044.2 samples/s | 94.4 steps/s
[Step=80950 Epoch=395.0] | Loss=0.00245 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.086 | 2125.0 samples/s | 33.2 steps/s
[Step=81000 Epoch=395.2] | Loss=0.00238 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.089 | 4445.1 samples/s | 69.5 steps/s
[Step=81050 Epoch=395.5] | Loss=0.00235 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.092 | 4554.8 samples/s | 71.2 steps/s
[Step=81100 Epoch=395.7] | Loss=0.00229 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=21.095 | 5476.2 samples/s | 85.6 steps/s
[Step=81150 Epoch=396.0] | Loss=0.00226 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=21.098 | 2210.7 samples/s | 34.5 steps/s
[Step=81200 Epoch=396.2] | Loss=0.00224 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=21.101 | 4428.2 samples/s | 69.2 steps/s
[Step=81250 Epoch=396.5] | Loss=0.00221 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=21.104 | 4449.8 samples/s | 69.5 steps/s
[Step=81300 Epoch=396.7] | Loss=0.00218 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=21.107 | 5225.1 samples/s | 81.6 steps/s
[Step=81350 Epoch=397.0] | Loss=0.00213 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.110 | 2233.6 samples/s | 34.9 steps/s
[Step=81400 Epoch=397.2] | Loss=0.00212 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.112 | 4475.7 samples/s | 69.9 steps/s
[Step=81450 Epoch=397.4] | Loss=0.00209 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.115 | 4543.5 samples/s | 71.0 steps/s
[Step=81500 Epoch=397.7] | Loss=0.00205 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.118 | 4789.5 samples/s | 74.8 steps/s
[Step=81550 Epoch=397.9] | Loss=0.00206 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=21.120 | 2335.8 samples/s | 36.5 steps/s
[Step=81600 Epoch=398.2] | Loss=0.00205 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=21.123 | 4484.6 samples/s | 70.1 steps/s
[Step=81650 Epoch=398.4] | Loss=0.00206 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=21.126 | 4452.8 samples/s | 69.6 steps/s
[Step=81700 Epoch=398.7] | Loss=0.00203 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.700 | L2-Norm(final)=21.128 | 4465.2 samples/s | 69.8 steps/s
[Step=81750 Epoch=398.9] | Loss=0.00201 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.700 | L2-Norm(final)=21.131 | 2398.3 samples/s | 37.5 steps/s
[Step=81800 Epoch=399.1] | Loss=0.00198 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.700 | L2-Norm(final)=21.134 | 4549.7 samples/s | 71.1 steps/s
[Step=81850 Epoch=399.4] | Loss=0.00194 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=21.136 | 4354.5 samples/s | 68.0 steps/s
[Step=81900 Epoch=399.6] | Loss=0.00196 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=21.139 | 4477.6 samples/s | 70.0 steps/s
[Step=81950 Epoch=399.9] | Loss=0.00195 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.698 | L2-Norm(final)=21.141 | 2440.2 samples/s | 38.1 steps/s
[Step=82000 Epoch=400.1] | Loss=0.00193 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=21.144 | 4376.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step82000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=389.8] | Loss=0.00198 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.460 | L2-Norm(final)=21.026 | 5727.4 samples/s | 89.5 steps/s
[Step=80050 Epoch=390.0] | Loss=0.00350 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=21.029 | 4205.1 samples/s | 65.7 steps/s
[Step=80100 Epoch=390.3] | Loss=0.00313 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=21.032 | 5051.0 samples/s | 78.9 steps/s
[Step=80150 Epoch=390.5] | Loss=0.00312 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=21.036 | 5090.9 samples/s | 79.5 steps/s
[Step=80200 Epoch=390.8] | Loss=0.00311 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.464 | L2-Norm(final)=21.040 | 7777.8 samples/s | 121.5 steps/s
[Step=80250 Epoch=391.0] | Loss=0.00295 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.464 | L2-Norm(final)=21.043 | 2213.2 samples/s | 34.6 steps/s
[Step=80300 Epoch=391.3] | Loss=0.00291 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=21.047 | 5047.8 samples/s | 78.9 steps/s
[Step=80350 Epoch=391.5] | Loss=0.00290 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=21.051 | 5055.5 samples/s | 79.0 steps/s
[Step=80400 Epoch=391.7] | Loss=0.00291 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=21.054 | 6543.6 samples/s | 102.2 steps/s
[Step=80450 Epoch=392.0] | Loss=0.00291 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=21.058 | 2289.8 samples/s | 35.8 steps/s
[Step=80500 Epoch=392.2] | Loss=0.00293 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.467 | L2-Norm(final)=21.062 | 5043.8 samples/s | 78.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=392.2] | Loss=0.00446 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.471 | L2-Norm(final)=21.099 | 5570.1 samples/s | 87.0 steps/s
[Step=80550 Epoch=392.5] | Loss=0.00257 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=21.103 | 4207.4 samples/s | 65.7 steps/s
[Step=80600 Epoch=392.7] | Loss=0.00284 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.473 | L2-Norm(final)=21.106 | 4466.9 samples/s | 69.8 steps/s
[Step=80650 Epoch=393.0] | Loss=0.00320 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.475 | L2-Norm(final)=21.110 | 4483.9 samples/s | 70.1 steps/s
[Step=80700 Epoch=393.2] | Loss=0.00322 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=21.114 | 6407.1 samples/s | 100.1 steps/s
[Step=80750 Epoch=393.5] | Loss=0.00297 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.477 | L2-Norm(final)=21.117 | 2048.5 samples/s | 32.0 steps/s
[Step=80800 Epoch=393.7] | Loss=0.00290 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.478 | L2-Norm(final)=21.121 | 4556.1 samples/s | 71.2 steps/s
[Step=80850 Epoch=393.9] | Loss=0.00294 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=21.124 | 4512.4 samples/s | 70.5 steps/s
[Step=80900 Epoch=394.2] | Loss=0.00289 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=21.127 | 5651.3 samples/s | 88.3 steps/s
[Step=80950 Epoch=394.4] | Loss=0.00276 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=21.130 | 2165.1 samples/s | 33.8 steps/s
[Step=81000 Epoch=394.7] | Loss=0.00276 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=21.134 | 4427.1 samples/s | 69.2 steps/s
[Step=81050 Epoch=394.9] | Loss=0.00265 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=21.137 | 4391.2 samples/s | 68.6 steps/s
[Step=81100 Epoch=395.2] | Loss=0.00258 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.139 | 5419.3 samples/s | 84.7 steps/s
[Step=81150 Epoch=395.4] | Loss=0.00257 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.142 | 2267.2 samples/s | 35.4 steps/s
[Step=81200 Epoch=395.6] | Loss=0.00253 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.145 | 4422.6 samples/s | 69.1 steps/s
[Step=81250 Epoch=395.9] | Loss=0.00254 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.148 | 4474.4 samples/s | 69.9 steps/s
[Step=81300 Epoch=396.1] | Loss=0.00251 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.151 | 4941.5 samples/s | 77.2 steps/s
[Step=81350 Epoch=396.4] | Loss=0.00247 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.153 | 2329.5 samples/s | 36.4 steps/s
[Step=81400 Epoch=396.6] | Loss=0.00243 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.156 | 4470.7 samples/s | 69.9 steps/s
[Step=81450 Epoch=396.9] | Loss=0.00241 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.158 | 4386.3 samples/s | 68.5 steps/s
[Step=81500 Epoch=397.1] | Loss=0.00241 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.161 | 4622.3 samples/s | 72.2 steps/s
[Step=81550 Epoch=397.4] | Loss=0.00240 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.164 | 2438.0 samples/s | 38.1 steps/s
[Step=81600 Epoch=397.6] | Loss=0.00239 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=21.166 | 4454.6 samples/s | 69.6 steps/s
[Step=81650 Epoch=397.8] | Loss=0.00239 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=21.169 | 4580.2 samples/s | 71.6 steps/s
[Step=81700 Epoch=398.1] | Loss=0.00234 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=21.171 | 4421.8 samples/s | 69.1 steps/s
[Step=81750 Epoch=398.3] | Loss=0.00232 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=21.174 | 2438.6 samples/s | 38.1 steps/s
[Step=81800 Epoch=398.6] | Loss=0.00230 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=21.176 | 4528.1 samples/s | 70.8 steps/s
[Step=81850 Epoch=398.8] | Loss=0.00229 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=21.178 | 4497.6 samples/s | 70.3 steps/s
[Step=81900 Epoch=399.1] | Loss=0.00228 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=21.181 | 4462.4 samples/s | 69.7 steps/s
[Step=81950 Epoch=399.3] | Loss=0.00225 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=21.183 | 2461.7 samples/s | 38.5 steps/s
[Step=82000 Epoch=399.5] | Loss=0.00223 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=21.186 | 4554.3 samples/s | 71.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step82000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=390.1] | Loss=0.00369 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=21.085 | 5414.0 samples/s | 84.6 steps/s
[Step=80050 Epoch=390.4] | Loss=0.00224 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=21.089 | 4554.4 samples/s | 71.2 steps/s
[Step=80100 Epoch=390.6] | Loss=0.00251 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.158 | L2-Norm(final)=21.093 | 5006.3 samples/s | 78.2 steps/s
[Step=80150 Epoch=390.9] | Loss=0.00249 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=21.096 | 5202.1 samples/s | 81.3 steps/s
[Step=80200 Epoch=391.1] | Loss=0.00261 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=21.100 | 7693.2 samples/s | 120.2 steps/s
[Step=80250 Epoch=391.3] | Loss=0.00249 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=21.104 | 2189.5 samples/s | 34.2 steps/s
[Step=80300 Epoch=391.6] | Loss=0.00248 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=21.108 | 5046.5 samples/s | 78.9 steps/s
[Step=80350 Epoch=391.8] | Loss=0.00243 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=21.112 | 5072.6 samples/s | 79.3 steps/s
[Step=80400 Epoch=392.1] | Loss=0.00251 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=21.116 | 6866.2 samples/s | 107.3 steps/s
[Step=80450 Epoch=392.3] | Loss=0.00246 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=21.120 | 2303.1 samples/s | 36.0 steps/s
[Step=80500 Epoch=392.6] | Loss=0.00250 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=21.124 | 5004.9 samples/s | 78.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=392.6] | Loss=0.00076 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=21.164 | 5263.6 samples/s | 82.2 steps/s
[Step=80550 Epoch=392.8] | Loss=0.00267 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=21.168 | 4092.8 samples/s | 63.9 steps/s
[Step=80600 Epoch=393.1] | Loss=0.00240 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=21.173 | 4539.0 samples/s | 70.9 steps/s
[Step=80650 Epoch=393.3] | Loss=0.00236 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=21.177 | 4551.7 samples/s | 71.1 steps/s
[Step=80700 Epoch=393.5] | Loss=0.00245 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=21.180 | 6317.7 samples/s | 98.7 steps/s
[Step=80750 Epoch=393.8] | Loss=0.00225 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.175 | L2-Norm(final)=21.184 | 2110.7 samples/s | 33.0 steps/s
[Step=80800 Epoch=394.0] | Loss=0.00227 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=21.187 | 4375.0 samples/s | 68.4 steps/s
[Step=80850 Epoch=394.3] | Loss=0.00227 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=21.191 | 4554.5 samples/s | 71.2 steps/s
[Step=80900 Epoch=394.5] | Loss=0.00230 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.177 | L2-Norm(final)=21.194 | 5817.5 samples/s | 90.9 steps/s
[Step=80950 Epoch=394.8] | Loss=0.00229 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.197 | 2149.6 samples/s | 33.6 steps/s
[Step=81000 Epoch=395.0] | Loss=0.00225 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.200 | 4512.2 samples/s | 70.5 steps/s
[Step=81050 Epoch=395.2] | Loss=0.00224 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.203 | 4422.5 samples/s | 69.1 steps/s
[Step=81100 Epoch=395.5] | Loss=0.00215 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.206 | 5431.8 samples/s | 84.9 steps/s
[Step=81150 Epoch=395.7] | Loss=0.00208 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.179 | L2-Norm(final)=21.209 | 2196.7 samples/s | 34.3 steps/s
[Step=81200 Epoch=396.0] | Loss=0.00204 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.212 | 4465.0 samples/s | 69.8 steps/s
[Step=81250 Epoch=396.2] | Loss=0.00202 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.214 | 4464.7 samples/s | 69.8 steps/s
[Step=81300 Epoch=396.5] | Loss=0.00199 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.217 | 4984.5 samples/s | 77.9 steps/s
[Step=81350 Epoch=396.7] | Loss=0.00202 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.220 | 2320.6 samples/s | 36.3 steps/s
[Step=81400 Epoch=397.0] | Loss=0.00197 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=21.222 | 4455.3 samples/s | 69.6 steps/s
[Step=81450 Epoch=397.2] | Loss=0.00195 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.225 | 4456.4 samples/s | 69.6 steps/s
[Step=81500 Epoch=397.4] | Loss=0.00194 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.228 | 4533.0 samples/s | 70.8 steps/s
[Step=81550 Epoch=397.7] | Loss=0.00190 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.230 | 2412.4 samples/s | 37.7 steps/s
[Step=81600 Epoch=397.9] | Loss=0.00187 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=21.233 | 4494.2 samples/s | 70.2 steps/s
[Step=81650 Epoch=398.2] | Loss=0.00187 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=21.235 | 4521.8 samples/s | 70.7 steps/s
[Step=81700 Epoch=398.4] | Loss=0.00188 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=21.238 | 4426.9 samples/s | 69.2 steps/s
[Step=81750 Epoch=398.7] | Loss=0.00187 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=21.240 | 2484.6 samples/s | 38.8 steps/s
[Step=81800 Epoch=398.9] | Loss=0.00185 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=21.243 | 4462.0 samples/s | 69.7 steps/s
[Step=81850 Epoch=399.1] | Loss=0.00183 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=21.245 | 4396.0 samples/s | 68.7 steps/s
[Step=81900 Epoch=399.4] | Loss=0.00183 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.175 | L2-Norm(final)=21.247 | 4479.8 samples/s | 70.0 steps/s
[Step=81950 Epoch=399.6] | Loss=0.00182 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.175 | L2-Norm(final)=21.250 | 2477.9 samples/s | 38.7 steps/s
[Step=82000 Epoch=399.9] | Loss=0.00180 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=21.252 | 4384.2 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step82000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=392.3] | Loss=0.00895 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.826 | L2-Norm(final)=21.162 | 5138.2 samples/s | 80.3 steps/s
[Step=80050 Epoch=392.6] | Loss=0.00239 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=21.165 | 4432.5 samples/s | 69.3 steps/s
[Step=80100 Epoch=392.8] | Loss=0.00272 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=21.169 | 5006.8 samples/s | 78.2 steps/s
[Step=80150 Epoch=393.0] | Loss=0.00245 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=21.172 | 4886.9 samples/s | 76.4 steps/s
[Step=80200 Epoch=393.3] | Loss=0.00239 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=21.176 | 8056.9 samples/s | 125.9 steps/s
[Step=80250 Epoch=393.5] | Loss=0.00243 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=21.180 | 2222.8 samples/s | 34.7 steps/s
[Step=80300 Epoch=393.8] | Loss=0.00234 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=21.183 | 5017.4 samples/s | 78.4 steps/s
[Step=80350 Epoch=394.0] | Loss=0.00228 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=21.187 | 5060.6 samples/s | 79.1 steps/s
[Step=80400 Epoch=394.3] | Loss=0.00233 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=21.191 | 7372.2 samples/s | 115.2 steps/s
[Step=80450 Epoch=394.5] | Loss=0.00234 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=21.195 | 2255.4 samples/s | 35.2 steps/s
[Step=80500 Epoch=394.8] | Loss=0.00234 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.830 | L2-Norm(final)=21.198 | 4989.1 samples/s | 78.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=394.8] | Loss=0.00088 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.833 | L2-Norm(final)=21.237 | 5364.6 samples/s | 83.8 steps/s
[Step=80550 Epoch=395.0] | Loss=0.00207 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.834 | L2-Norm(final)=21.240 | 4134.7 samples/s | 64.6 steps/s
[Step=80600 Epoch=395.2] | Loss=0.00237 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.835 | L2-Norm(final)=21.244 | 4493.0 samples/s | 70.2 steps/s
[Step=80650 Epoch=395.5] | Loss=0.00232 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.836 | L2-Norm(final)=21.248 | 4459.9 samples/s | 69.7 steps/s
[Step=80700 Epoch=395.7] | Loss=0.00242 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.838 | L2-Norm(final)=21.252 | 6745.7 samples/s | 105.4 steps/s
[Step=80750 Epoch=396.0] | Loss=0.00225 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=21.256 | 2081.3 samples/s | 32.5 steps/s
[Step=80800 Epoch=396.2] | Loss=0.00221 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=21.259 | 4501.5 samples/s | 70.3 steps/s
[Step=80850 Epoch=396.5] | Loss=0.00222 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=21.263 | 4353.6 samples/s | 68.0 steps/s
[Step=80900 Epoch=396.7] | Loss=0.00218 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=21.266 | 6292.3 samples/s | 98.3 steps/s
[Step=80950 Epoch=397.0] | Loss=0.00211 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.269 | 2129.4 samples/s | 33.3 steps/s
[Step=81000 Epoch=397.2] | Loss=0.00214 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.272 | 4505.8 samples/s | 70.4 steps/s
[Step=81050 Epoch=397.5] | Loss=0.00210 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.275 | 4387.4 samples/s | 68.6 steps/s
[Step=81100 Epoch=397.7] | Loss=0.00206 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.278 | 5896.5 samples/s | 92.1 steps/s
[Step=81150 Epoch=397.9] | Loss=0.00201 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.841 | L2-Norm(final)=21.281 | 2208.5 samples/s | 34.5 steps/s
[Step=81200 Epoch=398.2] | Loss=0.00199 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.283 | 4258.0 samples/s | 66.5 steps/s
[Step=81250 Epoch=398.4] | Loss=0.00205 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.286 | 4448.6 samples/s | 69.5 steps/s
[Step=81300 Epoch=398.7] | Loss=0.00205 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.289 | 5517.5 samples/s | 86.2 steps/s
[Step=81350 Epoch=398.9] | Loss=0.00201 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.291 | 2225.0 samples/s | 34.8 steps/s
[Step=81400 Epoch=399.2] | Loss=0.00201 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.294 | 4444.3 samples/s | 69.4 steps/s
[Step=81450 Epoch=399.4] | Loss=0.00197 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.297 | 4496.5 samples/s | 70.3 steps/s
[Step=81500 Epoch=399.7] | Loss=0.00192 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=21.299 | 5222.5 samples/s | 81.6 steps/s
[Step=81550 Epoch=399.9] | Loss=0.00194 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=21.302 | 2267.5 samples/s | 35.4 steps/s
[Step=81600 Epoch=400.2] | Loss=0.00192 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=21.305 | 4454.1 samples/s | 69.6 steps/s
[Step=81650 Epoch=400.4] | Loss=0.00188 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=21.307 | 4488.1 samples/s | 70.1 steps/s
[Step=81700 Epoch=400.6] | Loss=0.00187 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=21.310 | 4952.6 samples/s | 77.4 steps/s
[Step=81750 Epoch=400.9] | Loss=0.00183 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=21.312 | 2320.7 samples/s | 36.3 steps/s
[Step=81800 Epoch=401.1] | Loss=0.00181 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.838 | L2-Norm(final)=21.315 | 4567.0 samples/s | 71.4 steps/s
[Step=81850 Epoch=401.4] | Loss=0.00180 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.838 | L2-Norm(final)=21.317 | 4418.6 samples/s | 69.0 steps/s
[Step=81900 Epoch=401.6] | Loss=0.00179 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=21.319 | 4608.3 samples/s | 72.0 steps/s
[Step=81950 Epoch=401.9] | Loss=0.00178 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=21.322 | 2353.1 samples/s | 36.8 steps/s
[Step=82000 Epoch=402.1] | Loss=0.00177 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.836 | L2-Norm(final)=21.324 | 4490.3 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step82000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=758.1] | Loss=0.00005 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.119 | L2-Norm(final)=10.380 | 5235.3 samples/s | 81.8 steps/s
[Step=80050 Epoch=758.5] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.120 | L2-Norm(final)=10.384 | 4169.4 samples/s | 65.1 steps/s
[Step=80100 Epoch=759.0] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=10.389 | 7443.7 samples/s | 116.3 steps/s
[Step=80150 Epoch=759.5] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=10.395 | 2153.1 samples/s | 33.6 steps/s
[Step=80200 Epoch=760.0] | Loss=0.00004 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=10.400 | 6256.4 samples/s | 97.8 steps/s
[Step=80250 Epoch=760.4] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=10.405 | 2235.7 samples/s | 34.9 steps/s
[Step=80300 Epoch=760.9] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=10.410 | 5655.4 samples/s | 88.4 steps/s
[Step=80350 Epoch=761.4] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=10.414 | 2323.5 samples/s | 36.3 steps/s
[Step=80400 Epoch=761.9] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=10.418 | 5183.0 samples/s | 81.0 steps/s
[Step=80450 Epoch=762.3] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=10.423 | 2415.2 samples/s | 37.7 steps/s
[Step=80500 Epoch=762.8] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.140 | L2-Norm(final)=10.427 | 4837.5 samples/s | 75.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=762.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.155 | L2-Norm(final)=10.468 | 5425.2 samples/s | 84.8 steps/s
[Step=80550 Epoch=763.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=10.472 | 3730.3 samples/s | 58.3 steps/s
[Step=80600 Epoch=763.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=10.474 | 6184.6 samples/s | 96.6 steps/s
[Step=80650 Epoch=764.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.152 | L2-Norm(final)=10.476 | 2031.7 samples/s | 31.7 steps/s
[Step=80700 Epoch=764.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=10.478 | 5653.7 samples/s | 88.3 steps/s
[Step=80750 Epoch=765.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.145 | L2-Norm(final)=10.479 | 2112.6 samples/s | 33.0 steps/s
[Step=80800 Epoch=765.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.141 | L2-Norm(final)=10.481 | 5016.9 samples/s | 78.4 steps/s
[Step=80850 Epoch=766.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=10.482 | 2182.8 samples/s | 34.1 steps/s
[Step=80900 Epoch=766.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=10.483 | 4709.4 samples/s | 73.6 steps/s
[Step=80950 Epoch=767.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=10.484 | 2256.7 samples/s | 35.3 steps/s
[Step=81000 Epoch=767.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.125 | L2-Norm(final)=10.485 | 4342.7 samples/s | 67.9 steps/s
[Step=81050 Epoch=768.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.120 | L2-Norm(final)=10.485 | 2340.1 samples/s | 36.6 steps/s
[Step=81100 Epoch=768.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=10.486 | 4181.5 samples/s | 65.3 steps/s
[Step=81150 Epoch=769.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=10.487 | 2422.5 samples/s | 37.9 steps/s
[Step=81200 Epoch=769.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.106 | L2-Norm(final)=10.488 | 4153.0 samples/s | 64.9 steps/s
[Step=81250 Epoch=769.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.101 | L2-Norm(final)=10.489 | 2387.3 samples/s | 37.3 steps/s
[Step=81300 Epoch=770.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.096 | L2-Norm(final)=10.489 | 4190.7 samples/s | 65.5 steps/s
[Step=81350 Epoch=770.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.091 | L2-Norm(final)=10.490 | 2446.9 samples/s | 38.2 steps/s
[Step=81400 Epoch=771.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=10.491 | 4032.6 samples/s | 63.0 steps/s
[Step=81450 Epoch=771.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.080 | L2-Norm(final)=10.492 | 6564.4 samples/s | 102.6 steps/s
[Step=81500 Epoch=772.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.075 | L2-Norm(final)=10.493 | 2003.3 samples/s | 31.3 steps/s
[Step=81550 Epoch=772.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.070 | L2-Norm(final)=10.493 | 5866.4 samples/s | 91.7 steps/s
[Step=81600 Epoch=773.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.064 | L2-Norm(final)=10.494 | 2066.0 samples/s | 32.3 steps/s
[Step=81650 Epoch=773.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.059 | L2-Norm(final)=10.495 | 5287.1 samples/s | 82.6 steps/s
[Step=81700 Epoch=774.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.053 | L2-Norm(final)=10.496 | 2093.8 samples/s | 32.7 steps/s
[Step=81750 Epoch=774.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.048 | L2-Norm(final)=10.496 | 4879.4 samples/s | 76.2 steps/s
[Step=81800 Epoch=775.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.042 | L2-Norm(final)=10.497 | 2262.2 samples/s | 35.3 steps/s
[Step=81850 Epoch=775.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.036 | L2-Norm(final)=10.498 | 4349.8 samples/s | 68.0 steps/s
[Step=81900 Epoch=776.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.030 | L2-Norm(final)=10.499 | 2342.2 samples/s | 36.6 steps/s
[Step=81950 Epoch=776.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.024 | L2-Norm(final)=10.500 | 4229.3 samples/s | 66.1 steps/s
[Step=82000 Epoch=777.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.018 | L2-Norm(final)=10.500 | 2357.7 samples/s | 36.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step82000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=761.0] | Loss=0.00012 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.107 | L2-Norm(final)=11.520 | 5235.0 samples/s | 81.8 steps/s
[Step=80050 Epoch=761.5] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=11.525 | 4217.7 samples/s | 65.9 steps/s
[Step=80100 Epoch=762.0] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.113 | L2-Norm(final)=11.530 | 7290.8 samples/s | 113.9 steps/s
[Step=80150 Epoch=762.4] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.535 | 2139.5 samples/s | 33.4 steps/s
[Step=80200 Epoch=762.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.118 | L2-Norm(final)=11.539 | 6609.2 samples/s | 103.3 steps/s
[Step=80250 Epoch=763.4] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.120 | L2-Norm(final)=11.543 | 2188.0 samples/s | 34.2 steps/s
[Step=80300 Epoch=763.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.548 | 5938.3 samples/s | 92.8 steps/s
[Step=80350 Epoch=764.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=11.551 | 2305.3 samples/s | 36.0 steps/s
[Step=80400 Epoch=764.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.125 | L2-Norm(final)=11.555 | 5369.3 samples/s | 83.9 steps/s
[Step=80450 Epoch=765.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.126 | L2-Norm(final)=11.559 | 2458.0 samples/s | 38.4 steps/s
[Step=80500 Epoch=765.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=11.563 | 4650.8 samples/s | 72.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=765.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.140 | L2-Norm(final)=11.599 | 5778.5 samples/s | 90.3 steps/s
[Step=80550 Epoch=766.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=11.602 | 3525.6 samples/s | 55.1 steps/s
[Step=80600 Epoch=766.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.136 | L2-Norm(final)=11.605 | 6274.7 samples/s | 98.0 steps/s
[Step=80650 Epoch=767.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.607 | 2027.5 samples/s | 31.7 steps/s
[Step=80700 Epoch=767.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.129 | L2-Norm(final)=11.609 | 5664.6 samples/s | 88.5 steps/s
[Step=80750 Epoch=768.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.124 | L2-Norm(final)=11.610 | 2102.6 samples/s | 32.9 steps/s
[Step=80800 Epoch=768.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.120 | L2-Norm(final)=11.612 | 5178.9 samples/s | 80.9 steps/s
[Step=80850 Epoch=769.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=11.613 | 2143.0 samples/s | 33.5 steps/s
[Step=80900 Epoch=769.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=11.614 | 4683.0 samples/s | 73.2 steps/s
[Step=80950 Epoch=770.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.105 | L2-Norm(final)=11.615 | 2257.2 samples/s | 35.3 steps/s
[Step=81000 Epoch=770.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.100 | L2-Norm(final)=11.616 | 4352.8 samples/s | 68.0 steps/s
[Step=81050 Epoch=771.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.095 | L2-Norm(final)=11.617 | 2345.9 samples/s | 36.7 steps/s
[Step=81100 Epoch=771.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.090 | L2-Norm(final)=11.618 | 4238.6 samples/s | 66.2 steps/s
[Step=81150 Epoch=771.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.084 | L2-Norm(final)=11.619 | 2352.0 samples/s | 36.7 steps/s
[Step=81200 Epoch=772.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.079 | L2-Norm(final)=11.620 | 4326.4 samples/s | 67.6 steps/s
[Step=81250 Epoch=772.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=11.621 | 2375.8 samples/s | 37.1 steps/s
[Step=81300 Epoch=773.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=11.622 | 4372.1 samples/s | 68.3 steps/s
[Step=81350 Epoch=773.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.061 | L2-Norm(final)=11.623 | 2479.6 samples/s | 38.7 steps/s
[Step=81400 Epoch=774.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.055 | L2-Norm(final)=11.624 | 3858.4 samples/s | 60.3 steps/s
[Step=81450 Epoch=774.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.049 | L2-Norm(final)=11.625 | 6507.9 samples/s | 101.7 steps/s
[Step=81500 Epoch=775.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.626 | 2015.6 samples/s | 31.5 steps/s
[Step=81550 Epoch=775.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.037 | L2-Norm(final)=11.627 | 5768.1 samples/s | 90.1 steps/s
[Step=81600 Epoch=776.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.031 | L2-Norm(final)=11.628 | 2071.1 samples/s | 32.4 steps/s
[Step=81650 Epoch=776.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.025 | L2-Norm(final)=11.629 | 5284.9 samples/s | 82.6 steps/s
[Step=81700 Epoch=777.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.018 | L2-Norm(final)=11.630 | 2112.7 samples/s | 33.0 steps/s
[Step=81750 Epoch=777.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.012 | L2-Norm(final)=11.631 | 4901.7 samples/s | 76.6 steps/s
[Step=81800 Epoch=778.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.005 | L2-Norm(final)=11.632 | 2252.2 samples/s | 35.2 steps/s
[Step=81850 Epoch=778.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=11.633 | 4470.7 samples/s | 69.9 steps/s
[Step=81900 Epoch=779.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.992 | L2-Norm(final)=11.634 | 2297.7 samples/s | 35.9 steps/s
[Step=81950 Epoch=779.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.985 | L2-Norm(final)=11.635 | 4251.0 samples/s | 66.4 steps/s
[Step=82000 Epoch=780.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.978 | L2-Norm(final)=11.636 | 2363.9 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step82000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=764.0] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.065 | 4939.1 samples/s | 77.2 steps/s
[Step=80050 Epoch=764.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.067 | 4277.5 samples/s | 66.8 steps/s
[Step=80100 Epoch=764.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.069 | 7584.3 samples/s | 118.5 steps/s
[Step=80150 Epoch=765.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.113 | L2-Norm(final)=11.071 | 2129.8 samples/s | 33.3 steps/s
[Step=80200 Epoch=765.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.114 | L2-Norm(final)=11.073 | 6865.4 samples/s | 107.3 steps/s
[Step=80250 Epoch=766.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.114 | L2-Norm(final)=11.075 | 2171.9 samples/s | 33.9 steps/s
[Step=80300 Epoch=766.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=11.077 | 6116.5 samples/s | 95.6 steps/s
[Step=80350 Epoch=767.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.115 | L2-Norm(final)=11.079 | 2250.4 samples/s | 35.2 steps/s
[Step=80400 Epoch=767.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.081 | 5737.8 samples/s | 89.7 steps/s
[Step=80450 Epoch=768.2] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.083 | 2373.8 samples/s | 37.1 steps/s
[Step=80500 Epoch=768.7] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.117 | L2-Norm(final)=11.085 | 5183.1 samples/s | 81.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=768.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=11.105 | 5195.2 samples/s | 81.2 steps/s
[Step=80550 Epoch=769.2] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.123 | L2-Norm(final)=11.107 | 3771.5 samples/s | 58.9 steps/s
[Step=80600 Epoch=769.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.109 | 6393.7 samples/s | 99.9 steps/s
[Step=80650 Epoch=770.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.121 | L2-Norm(final)=11.110 | 2019.9 samples/s | 31.6 steps/s
[Step=80700 Epoch=770.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.119 | L2-Norm(final)=11.111 | 5809.1 samples/s | 90.8 steps/s
[Step=80750 Epoch=771.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.118 | L2-Norm(final)=11.112 | 2071.1 samples/s | 32.4 steps/s
[Step=80800 Epoch=771.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.113 | 5402.3 samples/s | 84.4 steps/s
[Step=80850 Epoch=772.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.114 | L2-Norm(final)=11.114 | 2120.3 samples/s | 33.1 steps/s
[Step=80900 Epoch=772.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.115 | 4999.6 samples/s | 78.1 steps/s
[Step=80950 Epoch=773.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=11.116 | 2213.2 samples/s | 34.6 steps/s
[Step=81000 Epoch=773.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.108 | L2-Norm(final)=11.117 | 4656.0 samples/s | 72.8 steps/s
[Step=81050 Epoch=774.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.105 | L2-Norm(final)=11.117 | 2262.5 samples/s | 35.4 steps/s
[Step=81100 Epoch=774.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.103 | L2-Norm(final)=11.118 | 4326.9 samples/s | 67.6 steps/s
[Step=81150 Epoch=774.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.101 | L2-Norm(final)=11.119 | 2314.0 samples/s | 36.2 steps/s
[Step=81200 Epoch=775.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.120 | 4292.1 samples/s | 67.1 steps/s
[Step=81250 Epoch=775.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.096 | L2-Norm(final)=11.120 | 2378.1 samples/s | 37.2 steps/s
[Step=81300 Epoch=776.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.093 | L2-Norm(final)=11.121 | 4250.8 samples/s | 66.4 steps/s
[Step=81350 Epoch=776.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.090 | L2-Norm(final)=11.122 | 2411.2 samples/s | 37.7 steps/s
[Step=81400 Epoch=777.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.122 | 4263.8 samples/s | 66.6 steps/s
[Step=81450 Epoch=777.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.085 | L2-Norm(final)=11.123 | 2352.5 samples/s | 36.8 steps/s
[Step=81500 Epoch=778.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.082 | L2-Norm(final)=11.123 | 4194.2 samples/s | 65.5 steps/s
[Step=81550 Epoch=778.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.079 | L2-Norm(final)=11.124 | 6916.9 samples/s | 108.1 steps/s
[Step=81600 Epoch=779.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.076 | L2-Norm(final)=11.125 | 1976.5 samples/s | 30.9 steps/s
[Step=81650 Epoch=779.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=11.125 | 6198.1 samples/s | 96.8 steps/s
[Step=81700 Epoch=780.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.070 | L2-Norm(final)=11.126 | 1990.1 samples/s | 31.1 steps/s
[Step=81750 Epoch=780.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.066 | L2-Norm(final)=11.127 | 5727.1 samples/s | 89.5 steps/s
[Step=81800 Epoch=781.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.063 | L2-Norm(final)=11.127 | 2051.2 samples/s | 32.0 steps/s
[Step=81850 Epoch=781.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.060 | L2-Norm(final)=11.128 | 5376.7 samples/s | 84.0 steps/s
[Step=81900 Epoch=782.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=11.128 | 2161.3 samples/s | 33.8 steps/s
[Step=81950 Epoch=782.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.053 | L2-Norm(final)=11.129 | 4809.8 samples/s | 75.2 steps/s
[Step=82000 Epoch=783.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.050 | L2-Norm(final)=11.130 | 2186.5 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step82000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=753.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=11.047 | 5280.9 samples/s | 82.5 steps/s
[Step=80050 Epoch=754.3] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.047 | 3969.8 samples/s | 62.0 steps/s
[Step=80100 Epoch=754.8] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.047 | 7438.1 samples/s | 116.2 steps/s
[Step=80150 Epoch=755.2] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.047 | 2125.8 samples/s | 33.2 steps/s
[Step=80200 Epoch=755.7] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.048 | 6445.8 samples/s | 100.7 steps/s
[Step=80250 Epoch=756.2] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.048 | 2225.0 samples/s | 34.8 steps/s
[Step=80300 Epoch=756.7] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.048 | 5529.9 samples/s | 86.4 steps/s
[Step=80350 Epoch=757.1] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.049 | 2349.2 samples/s | 36.7 steps/s
[Step=80400 Epoch=757.6] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.049 | 5071.5 samples/s | 79.2 steps/s
[Step=80450 Epoch=758.1] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.050 | 2485.2 samples/s | 38.8 steps/s
[Step=80500 Epoch=758.5] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.050 | 4788.4 samples/s | 74.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=758.5] | Loss=0.00003 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.054 | 5356.4 samples/s | 83.7 steps/s
[Step=80550 Epoch=759.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.055 | 3738.3 samples/s | 58.4 steps/s
[Step=80600 Epoch=759.5] | Loss=0.00002 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.055 | 6070.8 samples/s | 94.9 steps/s
[Step=80650 Epoch=760.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.056 | 2027.0 samples/s | 31.7 steps/s
[Step=80700 Epoch=760.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.334 | L2-Norm(final)=11.056 | 5507.7 samples/s | 86.1 steps/s
[Step=80750 Epoch=760.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.056 | 2139.1 samples/s | 33.4 steps/s
[Step=80800 Epoch=761.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.057 | 4912.8 samples/s | 76.8 steps/s
[Step=80850 Epoch=761.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.333 | L2-Norm(final)=11.057 | 2200.3 samples/s | 34.4 steps/s
[Step=80900 Epoch=762.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=11.057 | 4440.2 samples/s | 69.4 steps/s
[Step=80950 Epoch=762.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=11.058 | 2332.8 samples/s | 36.4 steps/s
[Step=81000 Epoch=763.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=11.058 | 4197.7 samples/s | 65.6 steps/s
[Step=81050 Epoch=763.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.331 | L2-Norm(final)=11.058 | 2394.3 samples/s | 37.4 steps/s
[Step=81100 Epoch=764.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.331 | L2-Norm(final)=11.059 | 4270.5 samples/s | 66.7 steps/s
[Step=81150 Epoch=764.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.330 | L2-Norm(final)=11.059 | 2358.9 samples/s | 36.9 steps/s
[Step=81200 Epoch=765.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.330 | L2-Norm(final)=11.059 | 4245.5 samples/s | 66.3 steps/s
[Step=81250 Epoch=765.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=11.060 | 2618.7 samples/s | 40.9 steps/s
[Step=81300 Epoch=766.1] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=11.060 | 3773.3 samples/s | 59.0 steps/s
[Step=81350 Epoch=766.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=11.060 | 6140.9 samples/s | 96.0 steps/s
[Step=81400 Epoch=767.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.328 | L2-Norm(final)=11.060 | 2015.6 samples/s | 31.5 steps/s
[Step=81450 Epoch=767.5] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=11.061 | 5580.0 samples/s | 87.2 steps/s
[Step=81500 Epoch=768.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=11.061 | 2070.0 samples/s | 32.3 steps/s
[Step=81550 Epoch=768.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.326 | L2-Norm(final)=11.061 | 4933.3 samples/s | 77.1 steps/s
[Step=81600 Epoch=768.9] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.326 | L2-Norm(final)=11.062 | 2200.7 samples/s | 34.4 steps/s
[Step=81650 Epoch=769.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.325 | L2-Norm(final)=11.062 | 4567.2 samples/s | 71.4 steps/s
[Step=81700 Epoch=769.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.324 | L2-Norm(final)=11.062 | 2301.5 samples/s | 36.0 steps/s
[Step=81750 Epoch=770.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.324 | L2-Norm(final)=11.062 | 4143.6 samples/s | 64.7 steps/s
[Step=81800 Epoch=770.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.323 | L2-Norm(final)=11.063 | 2434.7 samples/s | 38.0 steps/s
[Step=81850 Epoch=771.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.322 | L2-Norm(final)=11.063 | 4299.3 samples/s | 67.2 steps/s
[Step=81900 Epoch=771.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.322 | L2-Norm(final)=11.063 | 2355.6 samples/s | 36.8 steps/s
[Step=81950 Epoch=772.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.321 | L2-Norm(final)=11.064 | 4202.0 samples/s | 65.7 steps/s
[Step=82000 Epoch=772.7] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.320 | L2-Norm(final)=11.064 | 2562.4 samples/s | 40.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step82000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=762.5] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.215 | L2-Norm(final)=11.539 | 5121.7 samples/s | 80.0 steps/s
[Step=80050 Epoch=762.9] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.217 | L2-Norm(final)=11.541 | 4191.9 samples/s | 65.5 steps/s
[Step=80100 Epoch=763.4] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.218 | L2-Norm(final)=11.543 | 7541.6 samples/s | 117.8 steps/s
[Step=80150 Epoch=763.9] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.219 | L2-Norm(final)=11.546 | 2093.4 samples/s | 32.7 steps/s
[Step=80200 Epoch=764.4] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.220 | L2-Norm(final)=11.548 | 6861.4 samples/s | 107.2 steps/s
[Step=80250 Epoch=764.9] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.221 | L2-Norm(final)=11.551 | 2163.5 samples/s | 33.8 steps/s
[Step=80300 Epoch=765.3] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=11.554 | 6182.5 samples/s | 96.6 steps/s
[Step=80350 Epoch=765.8] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.223 | L2-Norm(final)=11.556 | 2269.4 samples/s | 35.5 steps/s
[Step=80400 Epoch=766.3] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.224 | L2-Norm(final)=11.559 | 5660.4 samples/s | 88.4 steps/s
[Step=80450 Epoch=766.8] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.225 | L2-Norm(final)=11.562 | 2365.4 samples/s | 37.0 steps/s
[Step=80500 Epoch=767.2] | Loss=0.00003 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.225 | L2-Norm(final)=11.564 | 5175.8 samples/s | 80.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=767.2] | Loss=0.00004 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.233 | L2-Norm(final)=11.590 | 5262.8 samples/s | 82.2 steps/s
[Step=80550 Epoch=767.7] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=11.592 | 3921.7 samples/s | 61.3 steps/s
[Step=80600 Epoch=768.2] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=11.595 | 6335.9 samples/s | 99.0 steps/s
[Step=80650 Epoch=768.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.230 | L2-Norm(final)=11.596 | 2004.3 samples/s | 31.3 steps/s
[Step=80700 Epoch=769.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.229 | L2-Norm(final)=11.598 | 5739.5 samples/s | 89.7 steps/s
[Step=80750 Epoch=769.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.227 | L2-Norm(final)=11.599 | 2094.0 samples/s | 32.7 steps/s
[Step=80800 Epoch=770.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.225 | L2-Norm(final)=11.600 | 5183.1 samples/s | 81.0 steps/s
[Step=80850 Epoch=770.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.222 | L2-Norm(final)=11.601 | 2139.7 samples/s | 33.4 steps/s
[Step=80900 Epoch=771.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.220 | L2-Norm(final)=11.602 | 4943.0 samples/s | 77.2 steps/s
[Step=80950 Epoch=771.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.218 | L2-Norm(final)=11.603 | 2226.5 samples/s | 34.8 steps/s
[Step=81000 Epoch=772.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.215 | L2-Norm(final)=11.604 | 4591.3 samples/s | 71.7 steps/s
[Step=81050 Epoch=772.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.212 | L2-Norm(final)=11.605 | 2271.5 samples/s | 35.5 steps/s
[Step=81100 Epoch=773.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.210 | L2-Norm(final)=11.606 | 4327.1 samples/s | 67.6 steps/s
[Step=81150 Epoch=773.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.207 | L2-Norm(final)=11.606 | 2336.7 samples/s | 36.5 steps/s
[Step=81200 Epoch=773.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.204 | L2-Norm(final)=11.607 | 4286.0 samples/s | 67.0 steps/s
[Step=81250 Epoch=774.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.201 | L2-Norm(final)=11.608 | 2415.3 samples/s | 37.7 steps/s
[Step=81300 Epoch=774.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.198 | L2-Norm(final)=11.609 | 4216.9 samples/s | 65.9 steps/s
[Step=81350 Epoch=775.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.195 | L2-Norm(final)=11.610 | 2372.2 samples/s | 37.1 steps/s
[Step=81400 Epoch=775.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.192 | L2-Norm(final)=11.610 | 4265.6 samples/s | 66.7 steps/s
[Step=81450 Epoch=776.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.189 | L2-Norm(final)=11.611 | 2391.2 samples/s | 37.4 steps/s
[Step=81500 Epoch=776.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.185 | L2-Norm(final)=11.612 | 4240.1 samples/s | 66.3 steps/s
[Step=81550 Epoch=777.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.182 | L2-Norm(final)=11.613 | 7009.0 samples/s | 109.5 steps/s
[Step=81600 Epoch=777.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.179 | L2-Norm(final)=11.613 | 1940.9 samples/s | 30.3 steps/s
[Step=81650 Epoch=778.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.175 | L2-Norm(final)=11.614 | 6311.4 samples/s | 98.6 steps/s
[Step=81700 Epoch=778.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.172 | L2-Norm(final)=11.615 | 2037.1 samples/s | 31.8 steps/s
[Step=81750 Epoch=779.2] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.168 | L2-Norm(final)=11.615 | 5690.5 samples/s | 88.9 steps/s
[Step=81800 Epoch=779.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.165 | L2-Norm(final)=11.616 | 2081.8 samples/s | 32.5 steps/s
[Step=81850 Epoch=780.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.161 | L2-Norm(final)=11.617 | 5257.9 samples/s | 82.2 steps/s
[Step=81900 Epoch=780.6] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=11.618 | 2132.2 samples/s | 33.3 steps/s
[Step=81950 Epoch=781.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.153 | L2-Norm(final)=11.618 | 5003.1 samples/s | 78.2 steps/s
[Step=82000 Epoch=781.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.149 | L2-Norm(final)=11.619 | 2229.0 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10653 | acc=0.9566 | tpr=0.9667 | fpr=0.0652 | 4826.8 samples/s | 18.9 steps/s
Avg test loss: 0.11127, Avg test acc: 0.95472, Avg tpr: 0.96485, Avg fpr: 0.06756, total FA: 527

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11247 | acc=0.9570 | tpr=0.9675 | fpr=0.0659 | 4698.1 samples/s | 18.4 steps/s
Avg test loss: 0.11291, Avg test acc: 0.95689, Avg tpr: 0.96736, Avg fpr: 0.06615, total FA: 516

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11018 | acc=0.9577 | tpr=0.9736 | fpr=0.0768 | 4744.1 samples/s | 18.5 steps/s
Avg test loss: 0.11147, Avg test acc: 0.95577, Avg tpr: 0.97068, Avg fpr: 0.07704, total FA: 601

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09962 | acc=0.9598 | tpr=0.9710 | fpr=0.0647 | 4804.8 samples/s | 18.8 steps/s
Avg test loss: 0.10522, Avg test acc: 0.95721, Avg tpr: 0.97051, Avg fpr: 0.07204, total FA: 562

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10989 | acc=0.9562 | tpr=0.9660 | fpr=0.0652 | 4668.5 samples/s | 18.2 steps/s
Avg test loss: 0.11547, Avg test acc: 0.95520, Avg tpr: 0.96538, Avg fpr: 0.06717, total FA: 524

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.47044 | acc=0.2969 | tpr=0.0100 | fpr=0.0803 | 4811.4 samples/s | 18.8 steps/s
Avg test loss: 5.47731, Avg test acc: 0.29594, Avg tpr: 0.01125, Avg fpr: 0.07794, total FA: 608

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.83147 | acc=0.3010 | tpr=0.0058 | fpr=0.0580 | 4982.0 samples/s | 19.5 steps/s
Avg test loss: 4.84510, Avg test acc: 0.29770, Avg tpr: 0.00583, Avg fpr: 0.06038, total FA: 471

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.26642 | acc=0.2895 | tpr=0.0126 | fpr=0.1093 | 4818.7 samples/s | 18.8 steps/s
Avg test loss: 5.26852, Avg test acc: 0.28792, Avg tpr: 0.01405, Avg fpr: 0.10973, total FA: 856

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.57883 | acc=0.2977 | tpr=0.0177 | fpr=0.0942 | 4675.3 samples/s | 18.3 steps/s
Avg test loss: 5.57442, Avg test acc: 0.29598, Avg tpr: 0.01900, Avg fpr: 0.09486, total FA: 740

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.95519 | acc=0.3036 | tpr=0.0140 | fpr=0.0676 | 4725.3 samples/s | 18.5 steps/s
Avg test loss: 4.96216, Avg test acc: 0.30103, Avg tpr: 0.01434, Avg fpr: 0.06845, total FA: 534

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.69811 | acc=0.1179 | tpr=0.5442 | fpr=0.8898 | 4950.7 samples/s | 19.3 steps/s
[Step= 100] | Loss=5.66358 | acc=0.1211 | tpr=0.5352 | fpr=0.8866 | 6651.1 samples/s | 26.0 steps/s
[Step= 150] | Loss=5.67487 | acc=0.1209 | tpr=0.5389 | fpr=0.8868 | 8446.7 samples/s | 33.0 steps/s
[Step= 200] | Loss=5.66406 | acc=0.1209 | tpr=0.5322 | fpr=0.8866 | 7613.1 samples/s | 29.7 steps/s
[Step= 250] | Loss=5.66586 | acc=0.1217 | tpr=0.5450 | fpr=0.8860 | 7642.7 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.66065 | acc=0.1217 | tpr=0.5513 | fpr=0.8861 | 8104.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.65197 | acc=0.1217 | tpr=0.5466 | fpr=0.8860 | 7861.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.65055 | acc=0.1219 | tpr=0.5438 | fpr=0.8858 | 7849.7 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.65525 | acc=0.1220 | tpr=0.5438 | fpr=0.8856 | 7783.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.65719 | acc=0.1219 | tpr=0.5414 | fpr=0.8857 | 8234.7 samples/s | 32.2 steps/s
[Step= 550] | Loss=5.66004 | acc=0.1218 | tpr=0.5376 | fpr=0.8858 | 13427.9 samples/s | 52.5 steps/s
Avg test loss: 5.66182, Avg test acc: 0.12166, Avg tpr: 0.53764, Avg fpr: 0.88590, total FA: 123005

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.55435 | acc=0.1080 | tpr=0.3584 | fpr=0.8965 | 4836.0 samples/s | 18.9 steps/s
[Step= 100] | Loss=5.53519 | acc=0.1091 | tpr=0.3881 | fpr=0.8961 | 6685.1 samples/s | 26.1 steps/s
[Step= 150] | Loss=5.53301 | acc=0.1092 | tpr=0.3977 | fpr=0.8961 | 8169.5 samples/s | 31.9 steps/s
[Step= 200] | Loss=5.52589 | acc=0.1086 | tpr=0.3891 | fpr=0.8965 | 7919.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=5.52839 | acc=0.1089 | tpr=0.3974 | fpr=0.8963 | 7995.2 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.52321 | acc=0.1089 | tpr=0.4029 | fpr=0.8965 | 7601.3 samples/s | 29.7 steps/s
[Step= 350] | Loss=5.51751 | acc=0.1091 | tpr=0.4039 | fpr=0.8962 | 7932.5 samples/s | 31.0 steps/s
[Step= 400] | Loss=5.51460 | acc=0.1093 | tpr=0.4054 | fpr=0.8961 | 7973.3 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.51987 | acc=0.1095 | tpr=0.4046 | fpr=0.8959 | 8028.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.52312 | acc=0.1095 | tpr=0.4004 | fpr=0.8957 | 7667.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=5.52913 | acc=0.1093 | tpr=0.4027 | fpr=0.8961 | 14280.9 samples/s | 55.8 steps/s
Avg test loss: 5.53159, Avg test acc: 0.10919, Avg tpr: 0.40214, Avg fpr: 0.89613, total FA: 124426

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.22174 | acc=0.0910 | tpr=0.3363 | fpr=0.9134 | 4882.0 samples/s | 19.1 steps/s
[Step= 100] | Loss=6.18552 | acc=0.0919 | tpr=0.3284 | fpr=0.9125 | 6926.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=6.20022 | acc=0.0927 | tpr=0.3285 | fpr=0.9117 | 7991.3 samples/s | 31.2 steps/s
[Step= 200] | Loss=6.19109 | acc=0.0923 | tpr=0.3191 | fpr=0.9118 | 7857.5 samples/s | 30.7 steps/s
[Step= 250] | Loss=6.19176 | acc=0.0927 | tpr=0.3258 | fpr=0.9115 | 7717.9 samples/s | 30.1 steps/s
[Step= 300] | Loss=6.18602 | acc=0.0930 | tpr=0.3360 | fpr=0.9114 | 8074.9 samples/s | 31.5 steps/s
[Step= 350] | Loss=6.17877 | acc=0.0937 | tpr=0.3344 | fpr=0.9107 | 8042.5 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.17744 | acc=0.0937 | tpr=0.3364 | fpr=0.9107 | 7619.4 samples/s | 29.8 steps/s
[Step= 450] | Loss=6.18330 | acc=0.0941 | tpr=0.3335 | fpr=0.9103 | 7864.6 samples/s | 30.7 steps/s
[Step= 500] | Loss=6.18486 | acc=0.0938 | tpr=0.3322 | fpr=0.9105 | 8109.3 samples/s | 31.7 steps/s
[Step= 550] | Loss=6.18923 | acc=0.0937 | tpr=0.3315 | fpr=0.9106 | 13599.5 samples/s | 53.1 steps/s
Avg test loss: 6.19054, Avg test acc: 0.09355, Avg tpr: 0.33201, Avg fpr: 0.91079, total FA: 126461

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.71332 | acc=0.1138 | tpr=0.5044 | fpr=0.8933 | 4719.2 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.68721 | acc=0.1137 | tpr=0.4947 | fpr=0.8934 | 7227.8 samples/s | 28.2 steps/s
[Step= 150] | Loss=5.70032 | acc=0.1126 | tpr=0.5043 | fpr=0.8947 | 7789.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.69018 | acc=0.1115 | tpr=0.5038 | fpr=0.8957 | 8245.5 samples/s | 32.2 steps/s
[Step= 250] | Loss=5.69545 | acc=0.1122 | tpr=0.5057 | fpr=0.8950 | 8180.6 samples/s | 32.0 steps/s
[Step= 300] | Loss=5.69248 | acc=0.1122 | tpr=0.5127 | fpr=0.8951 | 7839.7 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.68218 | acc=0.1123 | tpr=0.5103 | fpr=0.8949 | 7463.5 samples/s | 29.2 steps/s
[Step= 400] | Loss=5.67861 | acc=0.1123 | tpr=0.5055 | fpr=0.8948 | 7678.1 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.68442 | acc=0.1122 | tpr=0.5024 | fpr=0.8949 | 8412.3 samples/s | 32.9 steps/s
[Step= 500] | Loss=5.68561 | acc=0.1122 | tpr=0.4982 | fpr=0.8948 | 7913.6 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.69057 | acc=0.1119 | tpr=0.4922 | fpr=0.8950 | 13545.9 samples/s | 52.9 steps/s
Avg test loss: 5.69198, Avg test acc: 0.11177, Avg tpr: 0.49208, Avg fpr: 0.89514, total FA: 124289

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.85771 | acc=0.1287 | tpr=0.4071 | fpr=0.8763 | 4750.1 samples/s | 18.6 steps/s
[Step= 100] | Loss=5.83332 | acc=0.1304 | tpr=0.4072 | fpr=0.8748 | 6978.3 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.83104 | acc=0.1309 | tpr=0.4179 | fpr=0.8743 | 8133.8 samples/s | 31.8 steps/s
[Step= 200] | Loss=5.82597 | acc=0.1304 | tpr=0.4011 | fpr=0.8745 | 7878.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.82975 | acc=0.1313 | tpr=0.4131 | fpr=0.8739 | 7944.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.82969 | acc=0.1315 | tpr=0.4153 | fpr=0.8737 | 7867.9 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.82071 | acc=0.1319 | tpr=0.4152 | fpr=0.8733 | 7508.6 samples/s | 29.3 steps/s
[Step= 400] | Loss=5.81919 | acc=0.1318 | tpr=0.4152 | fpr=0.8733 | 8064.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.82467 | acc=0.1321 | tpr=0.4138 | fpr=0.8730 | 8151.3 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.82673 | acc=0.1318 | tpr=0.4115 | fpr=0.8733 | 7745.4 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.83205 | acc=0.1313 | tpr=0.4131 | fpr=0.8738 | 14107.5 samples/s | 55.1 steps/s
Avg test loss: 5.83442, Avg test acc: 0.13116, Avg tpr: 0.41244, Avg fpr: 0.87395, total FA: 121346

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09093 | acc=0.9821 | tpr=0.9646 | fpr=0.0176 | 4824.9 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09258 | acc=0.9820 | tpr=0.9638 | fpr=0.0177 | 7181.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.09620 | acc=0.9812 | tpr=0.9625 | fpr=0.0184 | 7815.4 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.09806 | acc=0.9813 | tpr=0.9683 | fpr=0.0185 | 7817.9 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09671 | acc=0.9815 | tpr=0.9624 | fpr=0.0182 | 7903.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.09898 | acc=0.9811 | tpr=0.9600 | fpr=0.0185 | 7941.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09993 | acc=0.9808 | tpr=0.9593 | fpr=0.0188 | 7856.5 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10094 | acc=0.9805 | tpr=0.9551 | fpr=0.0191 | 7934.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.10289 | acc=0.9801 | tpr=0.9508 | fpr=0.0194 | 7679.9 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.10213 | acc=0.9801 | tpr=0.9511 | fpr=0.0193 | 8095.2 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.10149 | acc=0.9803 | tpr=0.9499 | fpr=0.0192 | 13657.9 samples/s | 53.4 steps/s
Avg test loss: 0.10136, Avg test acc: 0.98029, Avg tpr: 0.94968, Avg fpr: 0.01915, total FA: 2659

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09014 | acc=0.9820 | tpr=0.9248 | fpr=0.0169 | 4955.1 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.09316 | acc=0.9820 | tpr=0.9318 | fpr=0.0171 | 6921.1 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.09657 | acc=0.9814 | tpr=0.9308 | fpr=0.0177 | 7582.5 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.09868 | acc=0.9816 | tpr=0.9355 | fpr=0.0176 | 7888.0 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.09692 | acc=0.9819 | tpr=0.9362 | fpr=0.0173 | 7764.6 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.09918 | acc=0.9815 | tpr=0.9360 | fpr=0.0176 | 7849.0 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.09975 | acc=0.9813 | tpr=0.9380 | fpr=0.0179 | 7511.5 samples/s | 29.3 steps/s
[Step= 400] | Loss=0.10105 | acc=0.9810 | tpr=0.9327 | fpr=0.0181 | 7764.6 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10332 | acc=0.9808 | tpr=0.9318 | fpr=0.0183 | 7764.0 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.10253 | acc=0.9809 | tpr=0.9330 | fpr=0.0183 | 7785.0 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.10223 | acc=0.9810 | tpr=0.9308 | fpr=0.0181 | 14506.0 samples/s | 56.7 steps/s
Avg test loss: 0.10214, Avg test acc: 0.98099, Avg tpr: 0.93106, Avg fpr: 0.01810, total FA: 2513

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08568 | acc=0.9814 | tpr=0.9646 | fpr=0.0183 | 4726.2 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.08707 | acc=0.9818 | tpr=0.9701 | fpr=0.0180 | 7110.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09133 | acc=0.9808 | tpr=0.9654 | fpr=0.0189 | 7878.8 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.09256 | acc=0.9810 | tpr=0.9694 | fpr=0.0188 | 7733.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.09100 | acc=0.9813 | tpr=0.9686 | fpr=0.0185 | 7542.5 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.09317 | acc=0.9809 | tpr=0.9622 | fpr=0.0188 | 7855.3 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.09398 | acc=0.9805 | tpr=0.9637 | fpr=0.0191 | 7635.5 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.09501 | acc=0.9803 | tpr=0.9617 | fpr=0.0193 | 7642.6 samples/s | 29.9 steps/s
[Step= 450] | Loss=0.09664 | acc=0.9801 | tpr=0.9606 | fpr=0.0196 | 8200.4 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.09606 | acc=0.9800 | tpr=0.9621 | fpr=0.0196 | 7433.0 samples/s | 29.0 steps/s
[Step= 550] | Loss=0.09557 | acc=0.9802 | tpr=0.9610 | fpr=0.0195 | 15020.1 samples/s | 58.7 steps/s
Avg test loss: 0.09546, Avg test acc: 0.98019, Avg tpr: 0.96117, Avg fpr: 0.01946, total FA: 2702

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.10073 | acc=0.9798 | tpr=0.9513 | fpr=0.0197 | 4763.3 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.10304 | acc=0.9795 | tpr=0.9574 | fpr=0.0201 | 7123.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.10718 | acc=0.9784 | tpr=0.9524 | fpr=0.0211 | 7848.3 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.10826 | acc=0.9787 | tpr=0.9574 | fpr=0.0209 | 7790.5 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.10668 | acc=0.9790 | tpr=0.9572 | fpr=0.0206 | 7423.4 samples/s | 29.0 steps/s
[Step= 300] | Loss=0.10895 | acc=0.9788 | tpr=0.9556 | fpr=0.0208 | 8120.0 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.10990 | acc=0.9786 | tpr=0.9562 | fpr=0.0210 | 7697.3 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.11049 | acc=0.9785 | tpr=0.9546 | fpr=0.0211 | 7696.3 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.11244 | acc=0.9783 | tpr=0.9523 | fpr=0.0212 | 8062.8 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.11163 | acc=0.9784 | tpr=0.9529 | fpr=0.0211 | 7546.0 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.11091 | acc=0.9786 | tpr=0.9522 | fpr=0.0209 | 14423.4 samples/s | 56.3 steps/s
Avg test loss: 0.11069, Avg test acc: 0.97864, Avg tpr: 0.95246, Avg fpr: 0.02089, total FA: 2900

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09477 | acc=0.9812 | tpr=0.9292 | fpr=0.0178 | 4695.9 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.09875 | acc=0.9806 | tpr=0.9382 | fpr=0.0186 | 7002.5 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.10236 | acc=0.9795 | tpr=0.9366 | fpr=0.0197 | 8123.4 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.10389 | acc=0.9794 | tpr=0.9454 | fpr=0.0200 | 7738.8 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.10230 | acc=0.9798 | tpr=0.9441 | fpr=0.0196 | 7616.4 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.10447 | acc=0.9795 | tpr=0.9404 | fpr=0.0198 | 7955.9 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.10512 | acc=0.9792 | tpr=0.9418 | fpr=0.0201 | 7782.5 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.10640 | acc=0.9790 | tpr=0.9387 | fpr=0.0203 | 7940.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.10856 | acc=0.9787 | tpr=0.9367 | fpr=0.0205 | 7905.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.10801 | acc=0.9788 | tpr=0.9374 | fpr=0.0205 | 7691.8 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.10755 | acc=0.9790 | tpr=0.9379 | fpr=0.0202 | 13877.3 samples/s | 54.2 steps/s
Avg test loss: 0.10739, Avg test acc: 0.97901, Avg tpr: 0.93780, Avg fpr: 0.02024, total FA: 2810

server round 41/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=399.9] | Loss=0.00802 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.018 | L2-Norm(final)=20.394 | 5570.1 samples/s | 87.0 steps/s
[Step=82050 Epoch=400.1] | Loss=0.00240 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=20.399 | 4285.7 samples/s | 67.0 steps/s
[Step=82100 Epoch=400.3] | Loss=0.00281 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=20.404 | 5075.7 samples/s | 79.3 steps/s
[Step=82150 Epoch=400.6] | Loss=0.00273 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=20.410 | 4872.5 samples/s | 76.1 steps/s
[Step=82200 Epoch=400.8] | Loss=0.00285 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=20.415 | 7694.2 samples/s | 120.2 steps/s
[Step=82250 Epoch=401.1] | Loss=0.00264 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=20.420 | 2165.5 samples/s | 33.8 steps/s
[Step=82300 Epoch=401.3] | Loss=0.00274 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=20.425 | 4960.1 samples/s | 77.5 steps/s
[Step=82350 Epoch=401.6] | Loss=0.00276 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=20.430 | 5001.3 samples/s | 78.1 steps/s
[Step=82400 Epoch=401.8] | Loss=0.00276 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=20.436 | 6874.7 samples/s | 107.4 steps/s
[Step=82450 Epoch=402.0] | Loss=0.00275 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=20.441 | 2271.2 samples/s | 35.5 steps/s
[Step=82500 Epoch=402.3] | Loss=0.00272 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=20.445 | 4971.5 samples/s | 77.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=402.3] | Loss=0.00081 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=20.494 | 5433.5 samples/s | 84.9 steps/s
[Step=82550 Epoch=402.5] | Loss=0.00226 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=20.499 | 4002.2 samples/s | 62.5 steps/s
[Step=82600 Epoch=402.8] | Loss=0.00339 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.035 | L2-Norm(final)=20.503 | 4319.4 samples/s | 67.5 steps/s
[Step=82650 Epoch=403.0] | Loss=0.00320 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=20.508 | 4492.9 samples/s | 70.2 steps/s
[Step=82700 Epoch=403.3] | Loss=0.00313 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.039 | L2-Norm(final)=20.512 | 6357.9 samples/s | 99.3 steps/s
[Step=82750 Epoch=403.5] | Loss=0.00289 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=20.516 | 2054.2 samples/s | 32.1 steps/s
[Step=82800 Epoch=403.7] | Loss=0.00297 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.042 | L2-Norm(final)=20.520 | 4500.0 samples/s | 70.3 steps/s
[Step=82850 Epoch=404.0] | Loss=0.00287 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=20.523 | 4461.2 samples/s | 69.7 steps/s
[Step=82900 Epoch=404.2] | Loss=0.00288 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=20.527 | 5699.0 samples/s | 89.0 steps/s
[Step=82950 Epoch=404.5] | Loss=0.00282 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=20.530 | 2149.0 samples/s | 33.6 steps/s
[Step=83000 Epoch=404.7] | Loss=0.00276 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=20.533 | 4464.8 samples/s | 69.8 steps/s
[Step=83050 Epoch=405.0] | Loss=0.00269 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=20.537 | 4372.0 samples/s | 68.3 steps/s
[Step=83100 Epoch=405.2] | Loss=0.00271 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.540 | 5391.0 samples/s | 84.2 steps/s
[Step=83150 Epoch=405.5] | Loss=0.00268 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=20.543 | 2212.5 samples/s | 34.6 steps/s
[Step=83200 Epoch=405.7] | Loss=0.00259 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.546 | 4432.6 samples/s | 69.3 steps/s
[Step=83250 Epoch=405.9] | Loss=0.00255 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.548 | 4437.0 samples/s | 69.3 steps/s
[Step=83300 Epoch=406.2] | Loss=0.00253 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.551 | 4907.9 samples/s | 76.7 steps/s
[Step=83350 Epoch=406.4] | Loss=0.00249 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.554 | 2316.8 samples/s | 36.2 steps/s
[Step=83400 Epoch=406.7] | Loss=0.00245 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.556 | 4402.3 samples/s | 68.8 steps/s
[Step=83450 Epoch=406.9] | Loss=0.00242 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=20.559 | 4420.6 samples/s | 69.1 steps/s
[Step=83500 Epoch=407.2] | Loss=0.00243 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=20.562 | 4566.3 samples/s | 71.3 steps/s
[Step=83550 Epoch=407.4] | Loss=0.00238 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.564 | 2379.7 samples/s | 37.2 steps/s
[Step=83600 Epoch=407.6] | Loss=0.00233 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=20.567 | 4528.2 samples/s | 70.8 steps/s
[Step=83650 Epoch=407.9] | Loss=0.00235 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=20.569 | 4360.9 samples/s | 68.1 steps/s
[Step=83700 Epoch=408.1] | Loss=0.00235 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=20.571 | 4473.0 samples/s | 69.9 steps/s
[Step=83750 Epoch=408.4] | Loss=0.00234 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=20.574 | 2390.1 samples/s | 37.3 steps/s
[Step=83800 Epoch=408.6] | Loss=0.00234 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=20.576 | 4452.2 samples/s | 69.6 steps/s
[Step=83850 Epoch=408.9] | Loss=0.00231 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=20.579 | 4424.5 samples/s | 69.1 steps/s
[Step=83900 Epoch=409.1] | Loss=0.00229 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=20.581 | 4432.7 samples/s | 69.3 steps/s
[Step=83950 Epoch=409.4] | Loss=0.00226 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=20.583 | 2431.3 samples/s | 38.0 steps/s
[Step=84000 Epoch=409.6] | Loss=0.00226 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.042 | L2-Norm(final)=20.586 | 4409.2 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step84000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=400.1] | Loss=0.00065 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=21.220 | 4704.1 samples/s | 73.5 steps/s
[Step=82050 Epoch=400.4] | Loss=0.00230 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=21.224 | 4700.4 samples/s | 73.4 steps/s
[Step=82100 Epoch=400.6] | Loss=0.00240 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=21.229 | 5068.5 samples/s | 79.2 steps/s
[Step=82150 Epoch=400.9] | Loss=0.00254 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=21.235 | 5035.2 samples/s | 78.7 steps/s
[Step=82200 Epoch=401.1] | Loss=0.00253 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=21.240 | 7894.9 samples/s | 123.4 steps/s
[Step=82250 Epoch=401.3] | Loss=0.00249 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=21.246 | 2183.1 samples/s | 34.1 steps/s
[Step=82300 Epoch=401.6] | Loss=0.00253 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=21.251 | 5043.1 samples/s | 78.8 steps/s
[Step=82350 Epoch=401.8] | Loss=0.00249 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=21.256 | 5019.3 samples/s | 78.4 steps/s
[Step=82400 Epoch=402.1] | Loss=0.00241 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=21.262 | 7112.6 samples/s | 111.1 steps/s
[Step=82450 Epoch=402.3] | Loss=0.00239 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=21.267 | 2252.3 samples/s | 35.2 steps/s
[Step=82500 Epoch=402.6] | Loss=0.00239 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=21.272 | 5043.4 samples/s | 78.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=402.6] | Loss=0.00201 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=21.323 | 5098.9 samples/s | 79.7 steps/s
[Step=82550 Epoch=402.8] | Loss=0.00291 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.635 | L2-Norm(final)=21.328 | 3895.9 samples/s | 60.9 steps/s
[Step=82600 Epoch=403.0] | Loss=0.00358 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=21.333 | 4211.1 samples/s | 65.8 steps/s
[Step=82650 Epoch=403.3] | Loss=0.00375 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=21.337 | 4280.3 samples/s | 66.9 steps/s
[Step=82700 Epoch=403.5] | Loss=0.00341 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.641 | L2-Norm(final)=21.342 | 6114.5 samples/s | 95.5 steps/s
[Step=82750 Epoch=403.8] | Loss=0.00321 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=21.346 | 1901.7 samples/s | 29.7 steps/s
[Step=82800 Epoch=404.0] | Loss=0.00306 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.644 | L2-Norm(final)=21.349 | 4220.6 samples/s | 65.9 steps/s
[Step=82850 Epoch=404.3] | Loss=0.00287 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=21.353 | 4248.8 samples/s | 66.4 steps/s
[Step=82900 Epoch=404.5] | Loss=0.00278 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=21.356 | 5691.4 samples/s | 88.9 steps/s
[Step=82950 Epoch=404.8] | Loss=0.00281 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=21.360 | 2026.9 samples/s | 31.7 steps/s
[Step=83000 Epoch=405.0] | Loss=0.00275 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=21.363 | 4515.6 samples/s | 70.6 steps/s
[Step=83050 Epoch=405.2] | Loss=0.00271 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=21.367 | 4456.6 samples/s | 69.6 steps/s
[Step=83100 Epoch=405.5] | Loss=0.00265 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.370 | 5400.0 samples/s | 84.4 steps/s
[Step=83150 Epoch=405.7] | Loss=0.00259 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.648 | L2-Norm(final)=21.373 | 2198.3 samples/s | 34.3 steps/s
[Step=83200 Epoch=406.0] | Loss=0.00253 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.376 | 4524.8 samples/s | 70.7 steps/s
[Step=83250 Epoch=406.2] | Loss=0.00246 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.379 | 4447.2 samples/s | 69.5 steps/s
[Step=83300 Epoch=406.5] | Loss=0.00245 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.382 | 5223.0 samples/s | 81.6 steps/s
[Step=83350 Epoch=406.7] | Loss=0.00240 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.384 | 2255.6 samples/s | 35.2 steps/s
[Step=83400 Epoch=407.0] | Loss=0.00233 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.387 | 4453.2 samples/s | 69.6 steps/s
[Step=83450 Epoch=407.2] | Loss=0.00233 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.390 | 4414.1 samples/s | 69.0 steps/s
[Step=83500 Epoch=407.4] | Loss=0.00227 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.393 | 4825.0 samples/s | 75.4 steps/s
[Step=83550 Epoch=407.7] | Loss=0.00225 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.395 | 2359.8 samples/s | 36.9 steps/s
[Step=83600 Epoch=407.9] | Loss=0.00220 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=21.398 | 4518.9 samples/s | 70.6 steps/s
[Step=83650 Epoch=408.2] | Loss=0.00215 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=21.400 | 4446.0 samples/s | 69.5 steps/s
[Step=83700 Epoch=408.4] | Loss=0.00216 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=21.403 | 4560.3 samples/s | 71.3 steps/s
[Step=83750 Epoch=408.7] | Loss=0.00214 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=21.405 | 2385.8 samples/s | 37.3 steps/s
[Step=83800 Epoch=408.9] | Loss=0.00212 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=21.408 | 4440.0 samples/s | 69.4 steps/s
[Step=83850 Epoch=409.1] | Loss=0.00212 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=21.410 | 4446.8 samples/s | 69.5 steps/s
[Step=83900 Epoch=409.4] | Loss=0.00208 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=21.413 | 4541.6 samples/s | 71.0 steps/s
[Step=83950 Epoch=409.6] | Loss=0.00207 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=21.415 | 2461.0 samples/s | 38.5 steps/s
[Step=84000 Epoch=409.9] | Loss=0.00206 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.644 | L2-Norm(final)=21.418 | 4417.2 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step84000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=399.5] | Loss=0.00195 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.407 | L2-Norm(final)=21.258 | 5114.6 samples/s | 79.9 steps/s
[Step=82050 Epoch=399.8] | Loss=0.00338 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.408 | L2-Norm(final)=21.263 | 4389.6 samples/s | 68.6 steps/s
[Step=82100 Epoch=400.0] | Loss=0.00323 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.409 | L2-Norm(final)=21.268 | 5047.7 samples/s | 78.9 steps/s
[Step=82150 Epoch=400.3] | Loss=0.00301 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.410 | L2-Norm(final)=21.273 | 4910.3 samples/s | 76.7 steps/s
[Step=82200 Epoch=400.5] | Loss=0.00298 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=21.279 | 7913.2 samples/s | 123.6 steps/s
[Step=82250 Epoch=400.8] | Loss=0.00293 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.412 | L2-Norm(final)=21.284 | 2255.7 samples/s | 35.2 steps/s
[Step=82300 Epoch=401.0] | Loss=0.00287 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.412 | L2-Norm(final)=21.289 | 4993.6 samples/s | 78.0 steps/s
[Step=82350 Epoch=401.2] | Loss=0.00281 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.413 | L2-Norm(final)=21.295 | 4921.2 samples/s | 76.9 steps/s
[Step=82400 Epoch=401.5] | Loss=0.00283 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=21.300 | 6928.0 samples/s | 108.3 steps/s
[Step=82450 Epoch=401.7] | Loss=0.00291 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=21.305 | 2279.9 samples/s | 35.6 steps/s
[Step=82500 Epoch=402.0] | Loss=0.00284 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=21.310 | 5141.8 samples/s | 80.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=402.0] | Loss=0.00253 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.422 | L2-Norm(final)=21.362 | 5549.9 samples/s | 86.7 steps/s
[Step=82550 Epoch=402.2] | Loss=0.00281 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=21.367 | 4073.8 samples/s | 63.7 steps/s
[Step=82600 Epoch=402.5] | Loss=0.00347 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.426 | L2-Norm(final)=21.372 | 4456.9 samples/s | 69.6 steps/s
[Step=82650 Epoch=402.7] | Loss=0.00323 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=21.376 | 4492.6 samples/s | 70.2 steps/s
[Step=82700 Epoch=403.0] | Loss=0.00336 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=21.381 | 6504.9 samples/s | 101.6 steps/s
[Step=82750 Epoch=403.2] | Loss=0.00338 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.432 | L2-Norm(final)=21.385 | 2102.3 samples/s | 32.8 steps/s
[Step=82800 Epoch=403.4] | Loss=0.00331 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=21.389 | 4375.3 samples/s | 68.4 steps/s
[Step=82850 Epoch=403.7] | Loss=0.00317 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=21.393 | 4482.4 samples/s | 70.0 steps/s
[Step=82900 Epoch=403.9] | Loss=0.00308 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=21.397 | 5914.9 samples/s | 92.4 steps/s
[Step=82950 Epoch=404.2] | Loss=0.00295 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=21.400 | 2176.3 samples/s | 34.0 steps/s
[Step=83000 Epoch=404.4] | Loss=0.00288 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=21.404 | 4489.6 samples/s | 70.1 steps/s
[Step=83050 Epoch=404.7] | Loss=0.00285 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=21.407 | 4429.7 samples/s | 69.2 steps/s
[Step=83100 Epoch=404.9] | Loss=0.00279 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.410 | 5378.6 samples/s | 84.0 steps/s
[Step=83150 Epoch=405.1] | Loss=0.00274 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.413 | 2226.1 samples/s | 34.8 steps/s
[Step=83200 Epoch=405.4] | Loss=0.00266 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.417 | 4467.0 samples/s | 69.8 steps/s
[Step=83250 Epoch=405.6] | Loss=0.00261 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.420 | 4468.8 samples/s | 69.8 steps/s
[Step=83300 Epoch=405.9] | Loss=0.00266 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=21.422 | 4979.7 samples/s | 77.8 steps/s
[Step=83350 Epoch=406.1] | Loss=0.00262 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=21.425 | 2347.0 samples/s | 36.7 steps/s
[Step=83400 Epoch=406.4] | Loss=0.00258 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=21.428 | 4515.1 samples/s | 70.5 steps/s
[Step=83450 Epoch=406.6] | Loss=0.00253 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=21.431 | 4426.2 samples/s | 69.2 steps/s
[Step=83500 Epoch=406.9] | Loss=0.00250 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.434 | 4494.2 samples/s | 70.2 steps/s
[Step=83550 Epoch=407.1] | Loss=0.00245 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.437 | 2429.7 samples/s | 38.0 steps/s
[Step=83600 Epoch=407.3] | Loss=0.00241 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.439 | 4465.5 samples/s | 69.8 steps/s
[Step=83650 Epoch=407.6] | Loss=0.00238 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=21.442 | 4467.7 samples/s | 69.8 steps/s
[Step=83700 Epoch=407.8] | Loss=0.00239 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=21.445 | 4516.0 samples/s | 70.6 steps/s
[Step=83750 Epoch=408.1] | Loss=0.00236 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=21.447 | 2462.2 samples/s | 38.5 steps/s
[Step=83800 Epoch=408.3] | Loss=0.00234 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=21.450 | 4523.2 samples/s | 70.7 steps/s
[Step=83850 Epoch=408.6] | Loss=0.00234 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=21.452 | 4333.2 samples/s | 67.7 steps/s
[Step=83900 Epoch=408.8] | Loss=0.00230 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=21.455 | 4405.6 samples/s | 68.8 steps/s
[Step=83950 Epoch=409.0] | Loss=0.00228 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=21.457 | 2483.8 samples/s | 38.8 steps/s
[Step=84000 Epoch=409.3] | Loss=0.00225 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=21.460 | 4448.8 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step84000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=399.9] | Loss=0.00296 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=21.324 | 5255.1 samples/s | 82.1 steps/s
[Step=82050 Epoch=400.1] | Loss=0.00228 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=21.329 | 4562.0 samples/s | 71.3 steps/s
[Step=82100 Epoch=400.4] | Loss=0.00233 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=21.335 | 4939.6 samples/s | 77.2 steps/s
[Step=82150 Epoch=400.6] | Loss=0.00252 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.103 | L2-Norm(final)=21.341 | 5124.4 samples/s | 80.1 steps/s
[Step=82200 Epoch=400.9] | Loss=0.00255 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.104 | L2-Norm(final)=21.348 | 7479.4 samples/s | 116.9 steps/s
[Step=82250 Epoch=401.1] | Loss=0.00239 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.105 | L2-Norm(final)=21.354 | 2203.3 samples/s | 34.4 steps/s
[Step=82300 Epoch=401.3] | Loss=0.00242 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=21.359 | 5113.6 samples/s | 79.9 steps/s
[Step=82350 Epoch=401.6] | Loss=0.00247 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.107 | L2-Norm(final)=21.365 | 4885.8 samples/s | 76.3 steps/s
[Step=82400 Epoch=401.8] | Loss=0.00241 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=21.371 | 6962.0 samples/s | 108.8 steps/s
[Step=82450 Epoch=402.1] | Loss=0.00244 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=21.377 | 2313.3 samples/s | 36.1 steps/s
[Step=82500 Epoch=402.3] | Loss=0.00240 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=21.382 | 5043.5 samples/s | 78.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=402.3] | Loss=0.00254 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=21.438 | 5106.7 samples/s | 79.8 steps/s
[Step=82550 Epoch=402.6] | Loss=0.00243 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.118 | L2-Norm(final)=21.444 | 4084.5 samples/s | 63.8 steps/s
[Step=82600 Epoch=402.8] | Loss=0.00286 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.120 | L2-Norm(final)=21.449 | 4500.5 samples/s | 70.3 steps/s
[Step=82650 Epoch=403.0] | Loss=0.00311 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=21.453 | 4416.6 samples/s | 69.0 steps/s
[Step=82700 Epoch=403.3] | Loss=0.00298 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=21.458 | 6585.9 samples/s | 102.9 steps/s
[Step=82750 Epoch=403.5] | Loss=0.00276 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=21.463 | 2088.4 samples/s | 32.6 steps/s
[Step=82800 Epoch=403.8] | Loss=0.00258 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=21.467 | 4469.8 samples/s | 69.8 steps/s
[Step=82850 Epoch=404.0] | Loss=0.00258 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=21.471 | 4494.5 samples/s | 70.2 steps/s
[Step=82900 Epoch=404.3] | Loss=0.00252 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=21.474 | 5786.9 samples/s | 90.4 steps/s
[Step=82950 Epoch=404.5] | Loss=0.00249 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.131 | L2-Norm(final)=21.478 | 2137.0 samples/s | 33.4 steps/s
[Step=83000 Epoch=404.8] | Loss=0.00245 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=21.481 | 4483.6 samples/s | 70.1 steps/s
[Step=83050 Epoch=405.0] | Loss=0.00245 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=21.484 | 4473.7 samples/s | 69.9 steps/s
[Step=83100 Epoch=405.2] | Loss=0.00241 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.133 | L2-Norm(final)=21.487 | 5430.7 samples/s | 84.9 steps/s
[Step=83150 Epoch=405.5] | Loss=0.00235 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.491 | 2261.0 samples/s | 35.3 steps/s
[Step=83200 Epoch=405.7] | Loss=0.00228 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.133 | L2-Norm(final)=21.494 | 4470.7 samples/s | 69.9 steps/s
[Step=83250 Epoch=406.0] | Loss=0.00222 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.496 | 4350.7 samples/s | 68.0 steps/s
[Step=83300 Epoch=406.2] | Loss=0.00219 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.499 | 4970.9 samples/s | 77.7 steps/s
[Step=83350 Epoch=406.5] | Loss=0.00214 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.502 | 2315.2 samples/s | 36.2 steps/s
[Step=83400 Epoch=406.7] | Loss=0.00215 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.505 | 4455.9 samples/s | 69.6 steps/s
[Step=83450 Epoch=406.9] | Loss=0.00211 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.508 | 4512.4 samples/s | 70.5 steps/s
[Step=83500 Epoch=407.2] | Loss=0.00206 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.510 | 4569.9 samples/s | 71.4 steps/s
[Step=83550 Epoch=407.4] | Loss=0.00203 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.513 | 2410.0 samples/s | 37.7 steps/s
[Step=83600 Epoch=407.7] | Loss=0.00200 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=21.515 | 4415.3 samples/s | 69.0 steps/s
[Step=83650 Epoch=407.9] | Loss=0.00197 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=21.518 | 4469.2 samples/s | 69.8 steps/s
[Step=83700 Epoch=408.2] | Loss=0.00196 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=21.520 | 4464.0 samples/s | 69.7 steps/s
[Step=83750 Epoch=408.4] | Loss=0.00194 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=21.523 | 2485.7 samples/s | 38.8 steps/s
[Step=83800 Epoch=408.7] | Loss=0.00193 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=21.525 | 4437.7 samples/s | 69.3 steps/s
[Step=83850 Epoch=408.9] | Loss=0.00193 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=21.528 | 4496.4 samples/s | 70.3 steps/s
[Step=83900 Epoch=409.1] | Loss=0.00190 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.130 | L2-Norm(final)=21.530 | 4436.8 samples/s | 69.3 steps/s
[Step=83950 Epoch=409.4] | Loss=0.00187 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=21.533 | 2410.6 samples/s | 37.7 steps/s
[Step=84000 Epoch=409.6] | Loss=0.00183 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=21.535 | 4500.5 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step84000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=402.1] | Loss=0.00071 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=21.396 | 5507.0 samples/s | 86.0 steps/s
[Step=82050 Epoch=402.4] | Loss=0.00195 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=21.401 | 4397.6 samples/s | 68.7 steps/s
[Step=82100 Epoch=402.6] | Loss=0.00215 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.761 | L2-Norm(final)=21.406 | 5047.5 samples/s | 78.9 steps/s
[Step=82150 Epoch=402.9] | Loss=0.00241 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.761 | L2-Norm(final)=21.412 | 4928.7 samples/s | 77.0 steps/s
[Step=82200 Epoch=403.1] | Loss=0.00239 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=21.418 | 8144.7 samples/s | 127.3 steps/s
[Step=82250 Epoch=403.3] | Loss=0.00234 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=21.424 | 2204.1 samples/s | 34.4 steps/s
[Step=82300 Epoch=403.6] | Loss=0.00235 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.763 | L2-Norm(final)=21.430 | 4913.6 samples/s | 76.8 steps/s
[Step=82350 Epoch=403.8] | Loss=0.00239 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.763 | L2-Norm(final)=21.435 | 5252.5 samples/s | 82.1 steps/s
[Step=82400 Epoch=404.1] | Loss=0.00231 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=21.441 | 7073.1 samples/s | 110.5 steps/s
[Step=82450 Epoch=404.3] | Loss=0.00229 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.765 | L2-Norm(final)=21.446 | 2257.8 samples/s | 35.3 steps/s
[Step=82500 Epoch=404.6] | Loss=0.00226 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.765 | L2-Norm(final)=21.452 | 4976.9 samples/s | 77.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=404.6] | Loss=0.00143 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=21.506 | 5501.0 samples/s | 86.0 steps/s
[Step=82550 Epoch=404.8] | Loss=0.00232 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.772 | L2-Norm(final)=21.512 | 4127.7 samples/s | 64.5 steps/s
[Step=82600 Epoch=405.1] | Loss=0.00302 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.774 | L2-Norm(final)=21.517 | 4369.4 samples/s | 68.3 steps/s
[Step=82650 Epoch=405.3] | Loss=0.00350 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.777 | L2-Norm(final)=21.522 | 4393.3 samples/s | 68.6 steps/s
[Step=82700 Epoch=405.5] | Loss=0.00328 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=21.527 | 6753.0 samples/s | 105.5 steps/s
[Step=82750 Epoch=405.8] | Loss=0.00300 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.781 | L2-Norm(final)=21.531 | 2101.2 samples/s | 32.8 steps/s
[Step=82800 Epoch=406.0] | Loss=0.00289 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.782 | L2-Norm(final)=21.535 | 4357.5 samples/s | 68.1 steps/s
[Step=82850 Epoch=406.3] | Loss=0.00297 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.783 | L2-Norm(final)=21.539 | 4477.8 samples/s | 70.0 steps/s
[Step=82900 Epoch=406.5] | Loss=0.00295 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.784 | L2-Norm(final)=21.542 | 6255.8 samples/s | 97.7 steps/s
[Step=82950 Epoch=406.8] | Loss=0.00277 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=21.546 | 2082.4 samples/s | 32.5 steps/s
[Step=83000 Epoch=407.0] | Loss=0.00278 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=21.549 | 4466.9 samples/s | 69.8 steps/s
[Step=83050 Epoch=407.3] | Loss=0.00272 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=21.552 | 4470.5 samples/s | 69.9 steps/s
[Step=83100 Epoch=407.5] | Loss=0.00270 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.555 | 5882.0 samples/s | 91.9 steps/s
[Step=83150 Epoch=407.8] | Loss=0.00258 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.558 | 2177.7 samples/s | 34.0 steps/s
[Step=83200 Epoch=408.0] | Loss=0.00254 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.561 | 4523.6 samples/s | 70.7 steps/s
[Step=83250 Epoch=408.2] | Loss=0.00245 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.564 | 4425.7 samples/s | 69.2 steps/s
[Step=83300 Epoch=408.5] | Loss=0.00240 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.567 | 5525.3 samples/s | 86.3 steps/s
[Step=83350 Epoch=408.7] | Loss=0.00235 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.569 | 2164.6 samples/s | 33.8 steps/s
[Step=83400 Epoch=409.0] | Loss=0.00232 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.572 | 4453.9 samples/s | 69.6 steps/s
[Step=83450 Epoch=409.2] | Loss=0.00224 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.575 | 4516.9 samples/s | 70.6 steps/s
[Step=83500 Epoch=409.5] | Loss=0.00220 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=21.577 | 5167.6 samples/s | 80.7 steps/s
[Step=83550 Epoch=409.7] | Loss=0.00216 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=21.580 | 2296.9 samples/s | 35.9 steps/s
[Step=83600 Epoch=410.0] | Loss=0.00212 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=21.583 | 4429.3 samples/s | 69.2 steps/s
[Step=83650 Epoch=410.2] | Loss=0.00210 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=21.585 | 4466.0 samples/s | 69.8 steps/s
[Step=83700 Epoch=410.5] | Loss=0.00208 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=21.588 | 4859.4 samples/s | 75.9 steps/s
[Step=83750 Epoch=410.7] | Loss=0.00205 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=21.590 | 2331.6 samples/s | 36.4 steps/s
[Step=83800 Epoch=410.9] | Loss=0.00200 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=21.593 | 4513.5 samples/s | 70.5 steps/s
[Step=83850 Epoch=411.2] | Loss=0.00200 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=21.595 | 4534.7 samples/s | 70.9 steps/s
[Step=83900 Epoch=411.4] | Loss=0.00197 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.783 | L2-Norm(final)=21.598 | 4597.2 samples/s | 71.8 steps/s
[Step=83950 Epoch=411.7] | Loss=0.00194 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.783 | L2-Norm(final)=21.600 | 2424.7 samples/s | 37.9 steps/s
[Step=84000 Epoch=411.9] | Loss=0.00192 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.782 | L2-Norm(final)=21.603 | 4340.0 samples/s | 67.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step84000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=777.0] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.047 | L2-Norm(final)=10.526 | 5648.8 samples/s | 88.3 steps/s
[Step=82050 Epoch=777.5] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.050 | L2-Norm(final)=10.534 | 3997.2 samples/s | 62.5 steps/s
[Step=82100 Epoch=778.0] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.054 | L2-Norm(final)=10.543 | 7324.2 samples/s | 114.4 steps/s
[Step=82150 Epoch=778.4] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=10.551 | 2171.2 samples/s | 33.9 steps/s
[Step=82200 Epoch=778.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.061 | L2-Norm(final)=10.558 | 6177.8 samples/s | 96.5 steps/s
[Step=82250 Epoch=779.4] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.063 | L2-Norm(final)=10.564 | 2223.9 samples/s | 34.7 steps/s
[Step=82300 Epoch=779.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.066 | L2-Norm(final)=10.570 | 5698.7 samples/s | 89.0 steps/s
[Step=82350 Epoch=780.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.068 | L2-Norm(final)=10.576 | 2334.0 samples/s | 36.5 steps/s
[Step=82400 Epoch=780.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.069 | L2-Norm(final)=10.581 | 5210.8 samples/s | 81.4 steps/s
[Step=82450 Epoch=781.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.071 | L2-Norm(final)=10.586 | 2400.0 samples/s | 37.5 steps/s
[Step=82500 Epoch=781.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=10.591 | 4878.3 samples/s | 76.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=781.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=10.640 | 5217.5 samples/s | 81.5 steps/s
[Step=82550 Epoch=782.2] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=10.645 | 3835.2 samples/s | 59.9 steps/s
[Step=82600 Epoch=782.7] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=10.651 | 6063.1 samples/s | 94.7 steps/s
[Step=82650 Epoch=783.2] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.084 | L2-Norm(final)=10.655 | 1994.8 samples/s | 31.2 steps/s
[Step=82700 Epoch=783.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.080 | L2-Norm(final)=10.657 | 5696.5 samples/s | 89.0 steps/s
[Step=82750 Epoch=784.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.075 | L2-Norm(final)=10.659 | 2102.8 samples/s | 32.9 steps/s
[Step=82800 Epoch=784.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.069 | L2-Norm(final)=10.661 | 5173.4 samples/s | 80.8 steps/s
[Step=82850 Epoch=785.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.063 | L2-Norm(final)=10.662 | 2189.2 samples/s | 34.2 steps/s
[Step=82900 Epoch=785.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=10.663 | 4634.6 samples/s | 72.4 steps/s
[Step=82950 Epoch=786.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.050 | L2-Norm(final)=10.664 | 2280.4 samples/s | 35.6 steps/s
[Step=83000 Epoch=786.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=10.665 | 4305.7 samples/s | 67.3 steps/s
[Step=83050 Epoch=787.0] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.036 | L2-Norm(final)=10.666 | 2350.1 samples/s | 36.7 steps/s
[Step=83100 Epoch=787.4] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.029 | L2-Norm(final)=10.666 | 4235.0 samples/s | 66.2 steps/s
[Step=83150 Epoch=787.9] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.021 | L2-Norm(final)=10.667 | 2392.7 samples/s | 37.4 steps/s
[Step=83200 Epoch=788.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.014 | L2-Norm(final)=10.668 | 4266.4 samples/s | 66.7 steps/s
[Step=83250 Epoch=788.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.006 | L2-Norm(final)=10.669 | 2381.9 samples/s | 37.2 steps/s
[Step=83300 Epoch=789.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=10.669 | 4273.3 samples/s | 66.8 steps/s
[Step=83350 Epoch=789.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.991 | L2-Norm(final)=10.670 | 2534.5 samples/s | 39.6 steps/s
[Step=83400 Epoch=790.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.983 | L2-Norm(final)=10.671 | 3816.7 samples/s | 59.6 steps/s
[Step=83450 Epoch=790.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.975 | L2-Norm(final)=10.672 | 6377.5 samples/s | 99.6 steps/s
[Step=83500 Epoch=791.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.967 | L2-Norm(final)=10.673 | 1989.8 samples/s | 31.1 steps/s
[Step=83550 Epoch=791.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.959 | L2-Norm(final)=10.673 | 5805.4 samples/s | 90.7 steps/s
[Step=83600 Epoch=792.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.950 | L2-Norm(final)=10.674 | 2068.8 samples/s | 32.3 steps/s
[Step=83650 Epoch=792.7] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.942 | L2-Norm(final)=10.675 | 5294.8 samples/s | 82.7 steps/s
[Step=83700 Epoch=793.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.934 | L2-Norm(final)=10.676 | 2170.0 samples/s | 33.9 steps/s
[Step=83750 Epoch=793.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.925 | L2-Norm(final)=10.677 | 4795.6 samples/s | 74.9 steps/s
[Step=83800 Epoch=794.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.917 | L2-Norm(final)=10.678 | 2171.6 samples/s | 33.9 steps/s
[Step=83850 Epoch=794.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.908 | L2-Norm(final)=10.678 | 4449.2 samples/s | 69.5 steps/s
[Step=83900 Epoch=795.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.899 | L2-Norm(final)=10.679 | 2324.6 samples/s | 36.3 steps/s
[Step=83950 Epoch=795.5] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.890 | L2-Norm(final)=10.680 | 4270.9 samples/s | 66.7 steps/s
[Step=84000 Epoch=796.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.881 | L2-Norm(final)=10.681 | 2372.8 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step84000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=780.0] | Loss=0.00006 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.032 | L2-Norm(final)=11.668 | 5294.5 samples/s | 82.7 steps/s
[Step=82050 Epoch=780.5] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.033 | L2-Norm(final)=11.676 | 4043.2 samples/s | 63.2 steps/s
[Step=82100 Epoch=781.0] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.038 | L2-Norm(final)=11.685 | 7511.1 samples/s | 117.4 steps/s
[Step=82150 Epoch=781.5] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.041 | L2-Norm(final)=11.692 | 2133.3 samples/s | 33.3 steps/s
[Step=82200 Epoch=781.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.044 | L2-Norm(final)=11.698 | 6657.3 samples/s | 104.0 steps/s
[Step=82250 Epoch=782.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.046 | L2-Norm(final)=11.704 | 2232.5 samples/s | 34.9 steps/s
[Step=82300 Epoch=782.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.048 | L2-Norm(final)=11.710 | 5917.6 samples/s | 92.5 steps/s
[Step=82350 Epoch=783.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.049 | L2-Norm(final)=11.715 | 2269.7 samples/s | 35.5 steps/s
[Step=82400 Epoch=783.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.051 | L2-Norm(final)=11.721 | 5360.1 samples/s | 83.8 steps/s
[Step=82450 Epoch=784.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.052 | L2-Norm(final)=11.726 | 2457.5 samples/s | 38.4 steps/s
[Step=82500 Epoch=784.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.053 | L2-Norm(final)=11.731 | 4800.4 samples/s | 75.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=784.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.064 | L2-Norm(final)=11.779 | 5626.1 samples/s | 87.9 steps/s
[Step=82550 Epoch=785.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.062 | L2-Norm(final)=11.785 | 3636.7 samples/s | 56.8 steps/s
[Step=82600 Epoch=785.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.056 | L2-Norm(final)=11.789 | 6321.5 samples/s | 98.8 steps/s
[Step=82650 Epoch=786.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.048 | L2-Norm(final)=11.791 | 2018.1 samples/s | 31.5 steps/s
[Step=82700 Epoch=786.7] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.793 | 5685.7 samples/s | 88.8 steps/s
[Step=82750 Epoch=787.2] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.029 | L2-Norm(final)=11.795 | 2101.7 samples/s | 32.8 steps/s
[Step=82800 Epoch=787.6] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.019 | L2-Norm(final)=11.796 | 5199.8 samples/s | 81.2 steps/s
[Step=82850 Epoch=788.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.008 | L2-Norm(final)=11.798 | 2188.4 samples/s | 34.2 steps/s
[Step=82900 Epoch=788.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.998 | L2-Norm(final)=11.799 | 4629.4 samples/s | 72.3 steps/s
[Step=82950 Epoch=789.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.987 | L2-Norm(final)=11.801 | 2230.3 samples/s | 34.8 steps/s
[Step=83000 Epoch=789.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.976 | L2-Norm(final)=11.802 | 4379.8 samples/s | 68.4 steps/s
[Step=83050 Epoch=790.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.965 | L2-Norm(final)=11.803 | 2354.3 samples/s | 36.8 steps/s
[Step=83100 Epoch=790.5] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.954 | L2-Norm(final)=11.804 | 4222.7 samples/s | 66.0 steps/s
[Step=83150 Epoch=791.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.942 | L2-Norm(final)=11.806 | 2388.3 samples/s | 37.3 steps/s
[Step=83200 Epoch=791.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.931 | L2-Norm(final)=11.807 | 4149.9 samples/s | 64.8 steps/s
[Step=83250 Epoch=791.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.919 | L2-Norm(final)=11.808 | 2420.1 samples/s | 37.8 steps/s
[Step=83300 Epoch=792.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.908 | L2-Norm(final)=11.809 | 4256.5 samples/s | 66.5 steps/s
[Step=83350 Epoch=792.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=11.811 | 2545.0 samples/s | 39.8 steps/s
[Step=83400 Epoch=793.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.884 | L2-Norm(final)=11.812 | 3994.9 samples/s | 62.4 steps/s
[Step=83450 Epoch=793.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.872 | L2-Norm(final)=11.813 | 6608.5 samples/s | 103.3 steps/s
[Step=83500 Epoch=794.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.860 | L2-Norm(final)=11.815 | 2014.8 samples/s | 31.5 steps/s
[Step=83550 Epoch=794.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.848 | L2-Norm(final)=11.816 | 5583.6 samples/s | 87.2 steps/s
[Step=83600 Epoch=795.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.836 | L2-Norm(final)=11.817 | 2052.0 samples/s | 32.1 steps/s
[Step=83650 Epoch=795.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.824 | L2-Norm(final)=11.819 | 5345.2 samples/s | 83.5 steps/s
[Step=83700 Epoch=796.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.811 | L2-Norm(final)=11.820 | 2171.1 samples/s | 33.9 steps/s
[Step=83750 Epoch=796.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.799 | L2-Norm(final)=11.822 | 4796.5 samples/s | 74.9 steps/s
[Step=83800 Epoch=797.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.787 | L2-Norm(final)=11.823 | 2213.7 samples/s | 34.6 steps/s
[Step=83850 Epoch=797.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.774 | L2-Norm(final)=11.825 | 4492.8 samples/s | 70.2 steps/s
[Step=83900 Epoch=798.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.761 | L2-Norm(final)=11.827 | 2329.9 samples/s | 36.4 steps/s
[Step=83950 Epoch=798.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.749 | L2-Norm(final)=11.828 | 4309.9 samples/s | 67.3 steps/s
[Step=84000 Epoch=799.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.736 | L2-Norm(final)=11.830 | 2359.3 samples/s | 36.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step84000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=783.1] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.036 | L2-Norm(final)=11.149 | 5718.3 samples/s | 89.3 steps/s
[Step=82050 Epoch=783.5] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.036 | L2-Norm(final)=11.153 | 4026.7 samples/s | 62.9 steps/s
[Step=82100 Epoch=784.0] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.038 | L2-Norm(final)=11.158 | 7305.1 samples/s | 114.1 steps/s
[Step=82150 Epoch=784.5] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.162 | 2114.6 samples/s | 33.0 steps/s
[Step=82200 Epoch=785.0] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.041 | L2-Norm(final)=11.167 | 6846.0 samples/s | 107.0 steps/s
[Step=82250 Epoch=785.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.042 | L2-Norm(final)=11.171 | 2193.1 samples/s | 34.3 steps/s
[Step=82300 Epoch=785.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.176 | 6145.8 samples/s | 96.0 steps/s
[Step=82350 Epoch=786.4] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.044 | L2-Norm(final)=11.180 | 2243.2 samples/s | 35.1 steps/s
[Step=82400 Epoch=786.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.045 | L2-Norm(final)=11.184 | 5680.6 samples/s | 88.8 steps/s
[Step=82450 Epoch=787.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.046 | L2-Norm(final)=11.188 | 2387.9 samples/s | 37.3 steps/s
[Step=82500 Epoch=787.8] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.047 | L2-Norm(final)=11.192 | 5087.1 samples/s | 79.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=787.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.056 | L2-Norm(final)=11.232 | 5169.0 samples/s | 80.8 steps/s
[Step=82550 Epoch=788.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.055 | L2-Norm(final)=11.236 | 3802.7 samples/s | 59.4 steps/s
[Step=82600 Epoch=788.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.052 | L2-Norm(final)=11.239 | 6301.2 samples/s | 98.5 steps/s
[Step=82650 Epoch=789.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.048 | L2-Norm(final)=11.241 | 1989.6 samples/s | 31.1 steps/s
[Step=82700 Epoch=789.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.243 | 5891.6 samples/s | 92.1 steps/s
[Step=82750 Epoch=790.2] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.037 | L2-Norm(final)=11.244 | 2084.9 samples/s | 32.6 steps/s
[Step=82800 Epoch=790.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.032 | L2-Norm(final)=11.246 | 5373.5 samples/s | 84.0 steps/s
[Step=82850 Epoch=791.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.026 | L2-Norm(final)=11.247 | 2111.7 samples/s | 33.0 steps/s
[Step=82900 Epoch=791.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.020 | L2-Norm(final)=11.248 | 4982.6 samples/s | 77.9 steps/s
[Step=82950 Epoch=792.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.014 | L2-Norm(final)=11.249 | 2216.6 samples/s | 34.6 steps/s
[Step=83000 Epoch=792.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.008 | L2-Norm(final)=11.251 | 4494.9 samples/s | 70.2 steps/s
[Step=83050 Epoch=793.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.002 | L2-Norm(final)=11.252 | 2270.1 samples/s | 35.5 steps/s
[Step=83100 Epoch=793.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.996 | L2-Norm(final)=11.253 | 4394.8 samples/s | 68.7 steps/s
[Step=83150 Epoch=794.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.989 | L2-Norm(final)=11.254 | 2327.9 samples/s | 36.4 steps/s
[Step=83200 Epoch=794.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.983 | L2-Norm(final)=11.255 | 4227.6 samples/s | 66.1 steps/s
[Step=83250 Epoch=795.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.976 | L2-Norm(final)=11.256 | 2312.3 samples/s | 36.1 steps/s
[Step=83300 Epoch=795.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.969 | L2-Norm(final)=11.257 | 4300.4 samples/s | 67.2 steps/s
[Step=83350 Epoch=795.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.962 | L2-Norm(final)=11.258 | 2394.8 samples/s | 37.4 steps/s
[Step=83400 Epoch=796.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.956 | L2-Norm(final)=11.259 | 4227.8 samples/s | 66.1 steps/s
[Step=83450 Epoch=796.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.949 | L2-Norm(final)=11.261 | 2394.6 samples/s | 37.4 steps/s
[Step=83500 Epoch=797.4] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.942 | L2-Norm(final)=11.262 | 4227.9 samples/s | 66.1 steps/s
[Step=83550 Epoch=797.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.934 | L2-Norm(final)=11.263 | 6839.8 samples/s | 106.9 steps/s
[Step=83600 Epoch=798.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.927 | L2-Norm(final)=11.264 | 1966.1 samples/s | 30.7 steps/s
[Step=83650 Epoch=798.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.920 | L2-Norm(final)=11.265 | 6345.3 samples/s | 99.1 steps/s
[Step=83700 Epoch=799.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.913 | L2-Norm(final)=11.266 | 2005.3 samples/s | 31.3 steps/s
[Step=83750 Epoch=799.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.905 | L2-Norm(final)=11.268 | 5836.4 samples/s | 91.2 steps/s
[Step=83800 Epoch=800.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.898 | L2-Norm(final)=11.269 | 2072.2 samples/s | 32.4 steps/s
[Step=83850 Epoch=800.7] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.890 | L2-Norm(final)=11.270 | 5247.2 samples/s | 82.0 steps/s
[Step=83900 Epoch=801.2] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=11.271 | 2139.0 samples/s | 33.4 steps/s
[Step=83950 Epoch=801.7] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=11.273 | 4970.1 samples/s | 77.7 steps/s
[Step=84000 Epoch=802.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=11.274 | 2205.8 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step84000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=772.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.072 | 5377.3 samples/s | 84.0 steps/s
[Step=82050 Epoch=773.1] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.263 | L2-Norm(final)=11.073 | 4014.2 samples/s | 62.7 steps/s
[Step=82100 Epoch=773.6] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.074 | 7211.3 samples/s | 112.7 steps/s
[Step=82150 Epoch=774.1] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.076 | 2138.3 samples/s | 33.4 steps/s
[Step=82200 Epoch=774.6] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.077 | 6373.1 samples/s | 99.6 steps/s
[Step=82250 Epoch=775.0] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.078 | 2247.3 samples/s | 35.1 steps/s
[Step=82300 Epoch=775.5] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.079 | 5675.7 samples/s | 88.7 steps/s
[Step=82350 Epoch=776.0] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.080 | 2351.3 samples/s | 36.7 steps/s
[Step=82400 Epoch=776.4] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.081 | 4954.1 samples/s | 77.4 steps/s
[Step=82450 Epoch=776.9] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.083 | 2456.5 samples/s | 38.4 steps/s
[Step=82500 Epoch=777.4] | Loss=0.00002 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.084 | 4797.4 samples/s | 75.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=777.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=11.096 | 5120.7 samples/s | 80.0 steps/s
[Step=82550 Epoch=777.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=11.097 | 3886.4 samples/s | 60.7 steps/s
[Step=82600 Epoch=778.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.266 | L2-Norm(final)=11.098 | 6206.9 samples/s | 97.0 steps/s
[Step=82650 Epoch=778.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.265 | L2-Norm(final)=11.099 | 2016.0 samples/s | 31.5 steps/s
[Step=82700 Epoch=779.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.264 | L2-Norm(final)=11.100 | 5399.5 samples/s | 84.4 steps/s
[Step=82750 Epoch=779.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.263 | L2-Norm(final)=11.101 | 2126.8 samples/s | 33.2 steps/s
[Step=82800 Epoch=780.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.262 | L2-Norm(final)=11.102 | 4916.7 samples/s | 76.8 steps/s
[Step=82850 Epoch=780.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.261 | L2-Norm(final)=11.103 | 2258.6 samples/s | 35.3 steps/s
[Step=82900 Epoch=781.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=11.103 | 4366.6 samples/s | 68.2 steps/s
[Step=82950 Epoch=781.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.259 | L2-Norm(final)=11.104 | 2330.3 samples/s | 36.4 steps/s
[Step=83000 Epoch=782.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.258 | L2-Norm(final)=11.105 | 4213.3 samples/s | 65.8 steps/s
[Step=83050 Epoch=782.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.257 | L2-Norm(final)=11.105 | 2388.9 samples/s | 37.3 steps/s
[Step=83100 Epoch=783.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.255 | L2-Norm(final)=11.106 | 4265.9 samples/s | 66.7 steps/s
[Step=83150 Epoch=783.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.254 | L2-Norm(final)=11.107 | 2406.8 samples/s | 37.6 steps/s
[Step=83200 Epoch=784.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.253 | L2-Norm(final)=11.107 | 4296.8 samples/s | 67.1 steps/s
[Step=83250 Epoch=784.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.251 | L2-Norm(final)=11.108 | 2558.7 samples/s | 40.0 steps/s
[Step=83300 Epoch=784.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.250 | L2-Norm(final)=11.109 | 3704.8 samples/s | 57.9 steps/s
[Step=83350 Epoch=785.4] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.248 | L2-Norm(final)=11.109 | 6323.7 samples/s | 98.8 steps/s
[Step=83400 Epoch=785.9] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.247 | L2-Norm(final)=11.110 | 2040.6 samples/s | 31.9 steps/s
[Step=83450 Epoch=786.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.245 | L2-Norm(final)=11.110 | 5501.0 samples/s | 86.0 steps/s
[Step=83500 Epoch=786.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.244 | L2-Norm(final)=11.111 | 2120.8 samples/s | 33.1 steps/s
[Step=83550 Epoch=787.3] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.242 | L2-Norm(final)=11.111 | 5013.6 samples/s | 78.3 steps/s
[Step=83600 Epoch=787.8] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.240 | L2-Norm(final)=11.112 | 2179.5 samples/s | 34.1 steps/s
[Step=83650 Epoch=788.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.239 | L2-Norm(final)=11.113 | 4408.3 samples/s | 68.9 steps/s
[Step=83700 Epoch=788.7] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.237 | L2-Norm(final)=11.113 | 2291.6 samples/s | 35.8 steps/s
[Step=83750 Epoch=789.2] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.235 | L2-Norm(final)=11.114 | 4214.9 samples/s | 65.9 steps/s
[Step=83800 Epoch=789.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.233 | L2-Norm(final)=11.114 | 2403.1 samples/s | 37.5 steps/s
[Step=83850 Epoch=790.1] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.231 | L2-Norm(final)=11.115 | 4188.6 samples/s | 65.4 steps/s
[Step=83900 Epoch=790.6] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.230 | L2-Norm(final)=11.115 | 2361.9 samples/s | 36.9 steps/s
[Step=83950 Epoch=791.0] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.228 | L2-Norm(final)=11.116 | 4221.4 samples/s | 66.0 steps/s
[Step=84000 Epoch=791.5] | Loss=0.00001 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.226 | L2-Norm(final)=11.116 | 2532.8 samples/s | 39.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step84000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=781.5] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.131 | L2-Norm(final)=11.642 | 5446.2 samples/s | 85.1 steps/s
[Step=82050 Epoch=782.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.647 | 4224.5 samples/s | 66.0 steps/s
[Step=82100 Epoch=782.5] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.135 | L2-Norm(final)=11.653 | 7248.1 samples/s | 113.3 steps/s
[Step=82150 Epoch=783.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.137 | L2-Norm(final)=11.658 | 2080.3 samples/s | 32.5 steps/s
[Step=82200 Epoch=783.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=11.664 | 6716.7 samples/s | 104.9 steps/s
[Step=82250 Epoch=783.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.140 | L2-Norm(final)=11.669 | 2191.4 samples/s | 34.2 steps/s
[Step=82300 Epoch=784.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.141 | L2-Norm(final)=11.674 | 5991.1 samples/s | 93.6 steps/s
[Step=82350 Epoch=784.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.143 | L2-Norm(final)=11.679 | 2287.0 samples/s | 35.7 steps/s
[Step=82400 Epoch=785.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.144 | L2-Norm(final)=11.684 | 5448.1 samples/s | 85.1 steps/s
[Step=82450 Epoch=785.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.145 | L2-Norm(final)=11.689 | 2297.2 samples/s | 35.9 steps/s
[Step=82500 Epoch=786.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.146 | L2-Norm(final)=11.694 | 5243.1 samples/s | 81.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=786.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=11.740 | 5494.4 samples/s | 85.8 steps/s
[Step=82550 Epoch=786.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.156 | L2-Norm(final)=11.744 | 3778.1 samples/s | 59.0 steps/s
[Step=82600 Epoch=787.3] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.154 | L2-Norm(final)=11.749 | 6098.3 samples/s | 95.3 steps/s
[Step=82650 Epoch=787.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.151 | L2-Norm(final)=11.753 | 2003.1 samples/s | 31.3 steps/s
[Step=82700 Epoch=788.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=11.755 | 5793.8 samples/s | 90.5 steps/s
[Step=82750 Epoch=788.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.143 | L2-Norm(final)=11.757 | 2033.7 samples/s | 31.8 steps/s
[Step=82800 Epoch=789.2] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.138 | L2-Norm(final)=11.759 | 5327.0 samples/s | 83.2 steps/s
[Step=82850 Epoch=789.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=11.760 | 2125.9 samples/s | 33.2 steps/s
[Step=82900 Epoch=790.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.762 | 4981.7 samples/s | 77.8 steps/s
[Step=82950 Epoch=790.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.763 | 2192.6 samples/s | 34.3 steps/s
[Step=83000 Epoch=791.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.764 | 4499.4 samples/s | 70.3 steps/s
[Step=83050 Epoch=791.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=11.765 | 2266.5 samples/s | 35.4 steps/s
[Step=83100 Epoch=792.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.104 | L2-Norm(final)=11.767 | 4317.8 samples/s | 67.5 steps/s
[Step=83150 Epoch=792.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.768 | 2320.8 samples/s | 36.3 steps/s
[Step=83200 Epoch=793.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.092 | L2-Norm(final)=11.769 | 4326.2 samples/s | 67.6 steps/s
[Step=83250 Epoch=793.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=11.770 | 2375.2 samples/s | 37.1 steps/s
[Step=83300 Epoch=793.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.079 | L2-Norm(final)=11.771 | 4148.4 samples/s | 64.8 steps/s
[Step=83350 Epoch=794.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=11.772 | 2368.9 samples/s | 37.0 steps/s
[Step=83400 Epoch=794.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.066 | L2-Norm(final)=11.773 | 4256.9 samples/s | 66.5 steps/s
[Step=83450 Epoch=795.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.060 | L2-Norm(final)=11.774 | 2376.8 samples/s | 37.1 steps/s
[Step=83500 Epoch=795.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.053 | L2-Norm(final)=11.775 | 4346.6 samples/s | 67.9 steps/s
[Step=83550 Epoch=796.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.046 | L2-Norm(final)=11.776 | 6803.4 samples/s | 106.3 steps/s
[Step=83600 Epoch=796.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.777 | 1922.5 samples/s | 30.0 steps/s
[Step=83650 Epoch=797.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.032 | L2-Norm(final)=11.779 | 6361.6 samples/s | 99.4 steps/s
[Step=83700 Epoch=797.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.025 | L2-Norm(final)=11.780 | 2012.2 samples/s | 31.4 steps/s
[Step=83750 Epoch=798.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.018 | L2-Norm(final)=11.781 | 5790.1 samples/s | 90.5 steps/s
[Step=83800 Epoch=798.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.011 | L2-Norm(final)=11.782 | 2044.4 samples/s | 31.9 steps/s
[Step=83850 Epoch=799.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.003 | L2-Norm(final)=11.783 | 5383.1 samples/s | 84.1 steps/s
[Step=83900 Epoch=799.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.996 | L2-Norm(final)=11.784 | 2109.8 samples/s | 33.0 steps/s
[Step=83950 Epoch=800.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.988 | L2-Norm(final)=11.786 | 4785.1 samples/s | 74.8 steps/s
[Step=84000 Epoch=800.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.981 | L2-Norm(final)=11.787 | 2211.9 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10935 | acc=0.9560 | tpr=0.9676 | fpr=0.0691 | 4688.3 samples/s | 18.3 steps/s
Avg test loss: 0.11353, Avg test acc: 0.95424, Avg tpr: 0.96625, Avg fpr: 0.07217, total FA: 563

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11596 | acc=0.9572 | tpr=0.9731 | fpr=0.0773 | 4722.3 samples/s | 18.4 steps/s
Avg test loss: 0.11541, Avg test acc: 0.95737, Avg tpr: 0.97278, Avg fpr: 0.07653, total FA: 597

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11157 | acc=0.9572 | tpr=0.9719 | fpr=0.0748 | 4880.4 samples/s | 19.1 steps/s
Avg test loss: 0.11397, Avg test acc: 0.95553, Avg tpr: 0.96923, Avg fpr: 0.07461, total FA: 582

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10510 | acc=0.9588 | tpr=0.9673 | fpr=0.0595 | 4920.6 samples/s | 19.2 steps/s
Avg test loss: 0.11115, Avg test acc: 0.95641, Avg tpr: 0.96724, Avg fpr: 0.06743, total FA: 526

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11356 | acc=0.9559 | tpr=0.9681 | fpr=0.0706 | 4760.3 samples/s | 18.6 steps/s
Avg test loss: 0.11775, Avg test acc: 0.95561, Avg tpr: 0.96812, Avg fpr: 0.07191, total FA: 561

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.39416 | acc=0.2995 | tpr=0.0084 | fpr=0.0686 | 4869.9 samples/s | 19.0 steps/s
Avg test loss: 5.40225, Avg test acc: 0.29834, Avg tpr: 0.00944, Avg fpr: 0.06627, total FA: 517

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.75993 | acc=0.3025 | tpr=0.0046 | fpr=0.0505 | 4836.8 samples/s | 18.9 steps/s
Avg test loss: 4.77510, Avg test acc: 0.29990, Avg tpr: 0.00443, Avg fpr: 0.05025, total FA: 392

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.19890 | acc=0.2928 | tpr=0.0088 | fpr=0.0904 | 4818.7 samples/s | 18.8 steps/s
Avg test loss: 5.20269, Avg test acc: 0.29033, Avg tpr: 0.00979, Avg fpr: 0.09268, total FA: 723

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.67683 | acc=0.2972 | tpr=0.0155 | fpr=0.0912 | 4702.7 samples/s | 18.4 steps/s
Avg test loss: 5.67389, Avg test acc: 0.29618, Avg tpr: 0.01743, Avg fpr: 0.09076, total FA: 708

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.95967 | acc=0.3024 | tpr=0.0114 | fpr=0.0657 | 4787.8 samples/s | 18.7 steps/s
Avg test loss: 4.96712, Avg test acc: 0.30002, Avg tpr: 0.01189, Avg fpr: 0.06627, total FA: 517

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.97705 | acc=0.1127 | tpr=0.5708 | fpr=0.8955 | 4698.0 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.94351 | acc=0.1161 | tpr=0.5586 | fpr=0.8921 | 5373.2 samples/s | 21.0 steps/s
[Step= 150] | Loss=5.95373 | acc=0.1158 | tpr=0.5591 | fpr=0.8924 | 8460.1 samples/s | 33.0 steps/s
[Step= 200] | Loss=5.94446 | acc=0.1153 | tpr=0.5486 | fpr=0.8926 | 7441.4 samples/s | 29.1 steps/s
[Step= 250] | Loss=5.94681 | acc=0.1162 | tpr=0.5563 | fpr=0.8919 | 8155.2 samples/s | 31.9 steps/s
[Step= 300] | Loss=5.94101 | acc=0.1160 | tpr=0.5644 | fpr=0.8922 | 7810.4 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.93202 | acc=0.1163 | tpr=0.5611 | fpr=0.8918 | 7899.1 samples/s | 30.9 steps/s
[Step= 400] | Loss=5.93087 | acc=0.1162 | tpr=0.5563 | fpr=0.8918 | 7534.0 samples/s | 29.4 steps/s
[Step= 450] | Loss=5.93574 | acc=0.1165 | tpr=0.5550 | fpr=0.8915 | 8011.9 samples/s | 31.3 steps/s
[Step= 500] | Loss=5.93744 | acc=0.1163 | tpr=0.5515 | fpr=0.8916 | 8070.6 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.94048 | acc=0.1162 | tpr=0.5480 | fpr=0.8916 | 13400.0 samples/s | 52.3 steps/s
Avg test loss: 5.94241, Avg test acc: 0.11611, Avg tpr: 0.54794, Avg fpr: 0.89174, total FA: 123816

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.03493 | acc=0.0967 | tpr=0.4690 | fpr=0.9100 | 4862.2 samples/s | 19.0 steps/s
[Step= 100] | Loss=6.01808 | acc=0.0966 | tpr=0.4712 | fpr=0.9103 | 5426.7 samples/s | 21.2 steps/s
[Step= 150] | Loss=6.01775 | acc=0.0970 | tpr=0.4784 | fpr=0.9100 | 7551.0 samples/s | 29.5 steps/s
[Step= 200] | Loss=6.01008 | acc=0.0967 | tpr=0.4623 | fpr=0.9100 | 7896.4 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.01343 | acc=0.0970 | tpr=0.4681 | fpr=0.9098 | 7312.9 samples/s | 28.6 steps/s
[Step= 300] | Loss=6.00773 | acc=0.0969 | tpr=0.4742 | fpr=0.9100 | 8307.5 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.00128 | acc=0.0971 | tpr=0.4746 | fpr=0.9098 | 8074.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=5.99885 | acc=0.0972 | tpr=0.4765 | fpr=0.9097 | 7684.6 samples/s | 30.0 steps/s
[Step= 450] | Loss=6.00440 | acc=0.0973 | tpr=0.4776 | fpr=0.9096 | 8062.9 samples/s | 31.5 steps/s
[Step= 500] | Loss=6.00827 | acc=0.0974 | tpr=0.4740 | fpr=0.9094 | 7677.4 samples/s | 30.0 steps/s
[Step= 550] | Loss=6.01471 | acc=0.0971 | tpr=0.4719 | fpr=0.9097 | 14181.6 samples/s | 55.4 steps/s
Avg test loss: 6.01716, Avg test acc: 0.09702, Avg tpr: 0.47108, Avg fpr: 0.90978, total FA: 126321

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.02371 | acc=0.1002 | tpr=0.3186 | fpr=0.9037 | 4852.0 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.98522 | acc=0.1023 | tpr=0.3113 | fpr=0.9016 | 6300.3 samples/s | 24.6 steps/s
[Step= 150] | Loss=5.99914 | acc=0.1033 | tpr=0.3098 | fpr=0.9005 | 6747.7 samples/s | 26.4 steps/s
[Step= 200] | Loss=5.98939 | acc=0.1036 | tpr=0.2984 | fpr=0.9000 | 7247.8 samples/s | 28.3 steps/s
[Step= 250] | Loss=5.99058 | acc=0.1041 | tpr=0.3092 | fpr=0.8996 | 7652.8 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.98485 | acc=0.1045 | tpr=0.3156 | fpr=0.8994 | 7762.6 samples/s | 30.3 steps/s
[Step= 350] | Loss=5.97766 | acc=0.1051 | tpr=0.3143 | fpr=0.8987 | 8092.1 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.97671 | acc=0.1052 | tpr=0.3173 | fpr=0.8986 | 7758.4 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.98270 | acc=0.1054 | tpr=0.3150 | fpr=0.8984 | 7917.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.98393 | acc=0.1052 | tpr=0.3137 | fpr=0.8986 | 8017.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.98839 | acc=0.1048 | tpr=0.3144 | fpr=0.8990 | 13514.3 samples/s | 52.8 steps/s
Avg test loss: 5.98979, Avg test acc: 0.10470, Avg tpr: 0.31498, Avg fpr: 0.89913, total FA: 124842

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.92825 | acc=0.1224 | tpr=0.4867 | fpr=0.8841 | 4392.0 samples/s | 17.2 steps/s
[Step= 100] | Loss=5.89866 | acc=0.1223 | tpr=0.4691 | fpr=0.8842 | 6399.1 samples/s | 25.0 steps/s
[Step= 150] | Loss=5.91299 | acc=0.1208 | tpr=0.4827 | fpr=0.8859 | 7399.1 samples/s | 28.9 steps/s
[Step= 200] | Loss=5.90158 | acc=0.1198 | tpr=0.4754 | fpr=0.8866 | 7691.2 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.90749 | acc=0.1207 | tpr=0.4795 | fpr=0.8859 | 7646.5 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.90443 | acc=0.1208 | tpr=0.4873 | fpr=0.8859 | 8052.9 samples/s | 31.5 steps/s
[Step= 350] | Loss=5.89411 | acc=0.1210 | tpr=0.4847 | fpr=0.8856 | 7864.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.89038 | acc=0.1212 | tpr=0.4819 | fpr=0.8854 | 7741.4 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.89632 | acc=0.1211 | tpr=0.4800 | fpr=0.8854 | 7895.8 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.89762 | acc=0.1211 | tpr=0.4784 | fpr=0.8854 | 7799.5 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.90326 | acc=0.1206 | tpr=0.4723 | fpr=0.8858 | 14371.9 samples/s | 56.1 steps/s
Avg test loss: 5.90467, Avg test acc: 0.12053, Avg tpr: 0.47227, Avg fpr: 0.88586, total FA: 123000

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=6.24650 | acc=0.1153 | tpr=0.4602 | fpr=0.8909 | 4113.0 samples/s | 16.1 steps/s
[Step= 100] | Loss=6.22070 | acc=0.1175 | tpr=0.4627 | fpr=0.8889 | 6838.0 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.21997 | acc=0.1173 | tpr=0.4640 | fpr=0.8890 | 7604.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=6.21416 | acc=0.1171 | tpr=0.4579 | fpr=0.8891 | 7898.7 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.21812 | acc=0.1181 | tpr=0.4672 | fpr=0.8882 | 7637.2 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.21823 | acc=0.1180 | tpr=0.4720 | fpr=0.8885 | 7934.7 samples/s | 31.0 steps/s
[Step= 350] | Loss=6.20883 | acc=0.1183 | tpr=0.4715 | fpr=0.8881 | 7980.0 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.20745 | acc=0.1181 | tpr=0.4688 | fpr=0.8883 | 8054.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.21268 | acc=0.1183 | tpr=0.4664 | fpr=0.8880 | 7797.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=6.21538 | acc=0.1181 | tpr=0.4639 | fpr=0.8881 | 7739.6 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.22101 | acc=0.1177 | tpr=0.4636 | fpr=0.8886 | 14009.0 samples/s | 54.7 steps/s
Avg test loss: 6.22329, Avg test acc: 0.11756, Avg tpr: 0.46276, Avg fpr: 0.88871, total FA: 123396

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08849 | acc=0.9819 | tpr=0.9558 | fpr=0.0177 | 4209.2 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.09012 | acc=0.9820 | tpr=0.9616 | fpr=0.0177 | 7105.9 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09384 | acc=0.9811 | tpr=0.9582 | fpr=0.0185 | 6821.9 samples/s | 26.6 steps/s
[Step= 200] | Loss=0.09559 | acc=0.9812 | tpr=0.9639 | fpr=0.0185 | 7937.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.09437 | acc=0.9815 | tpr=0.9598 | fpr=0.0181 | 7846.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.09650 | acc=0.9811 | tpr=0.9578 | fpr=0.0184 | 8276.3 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.09752 | acc=0.9808 | tpr=0.9574 | fpr=0.0187 | 7530.4 samples/s | 29.4 steps/s
[Step= 400] | Loss=0.09853 | acc=0.9805 | tpr=0.9530 | fpr=0.0190 | 7825.2 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.10051 | acc=0.9801 | tpr=0.9489 | fpr=0.0193 | 8258.4 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.09980 | acc=0.9802 | tpr=0.9489 | fpr=0.0193 | 7635.1 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.09918 | acc=0.9804 | tpr=0.9479 | fpr=0.0190 | 14057.7 samples/s | 54.9 steps/s
Avg test loss: 0.09906, Avg test acc: 0.98036, Avg tpr: 0.94770, Avg fpr: 0.01904, total FA: 2644

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08730 | acc=0.9816 | tpr=0.9336 | fpr=0.0176 | 4074.6 samples/s | 15.9 steps/s
[Step= 100] | Loss=0.09011 | acc=0.9817 | tpr=0.9360 | fpr=0.0174 | 7109.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09350 | acc=0.9813 | tpr=0.9337 | fpr=0.0178 | 7587.1 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.09565 | acc=0.9814 | tpr=0.9377 | fpr=0.0178 | 7784.5 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.09404 | acc=0.9818 | tpr=0.9389 | fpr=0.0174 | 7696.8 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.09617 | acc=0.9814 | tpr=0.9367 | fpr=0.0178 | 7962.8 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.09677 | acc=0.9812 | tpr=0.9380 | fpr=0.0180 | 7984.6 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.09795 | acc=0.9809 | tpr=0.9327 | fpr=0.0182 | 7973.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.10011 | acc=0.9807 | tpr=0.9309 | fpr=0.0184 | 7828.8 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.09938 | acc=0.9808 | tpr=0.9326 | fpr=0.0183 | 7938.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.09906 | acc=0.9809 | tpr=0.9296 | fpr=0.0182 | 13705.9 samples/s | 53.5 steps/s
Avg test loss: 0.09896, Avg test acc: 0.98091, Avg tpr: 0.92987, Avg fpr: 0.01816, total FA: 2522

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08152 | acc=0.9814 | tpr=0.9646 | fpr=0.0183 | 4867.9 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.08320 | acc=0.9818 | tpr=0.9701 | fpr=0.0179 | 7030.1 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.08726 | acc=0.9809 | tpr=0.9654 | fpr=0.0188 | 7529.6 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.08863 | acc=0.9811 | tpr=0.9694 | fpr=0.0187 | 8249.2 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.08724 | acc=0.9814 | tpr=0.9686 | fpr=0.0183 | 7654.1 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.08931 | acc=0.9811 | tpr=0.9644 | fpr=0.0186 | 7993.4 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09002 | acc=0.9808 | tpr=0.9656 | fpr=0.0189 | 8022.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09104 | acc=0.9806 | tpr=0.9628 | fpr=0.0191 | 7503.3 samples/s | 29.3 steps/s
[Step= 450] | Loss=0.09258 | acc=0.9804 | tpr=0.9611 | fpr=0.0192 | 8220.8 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.09205 | acc=0.9804 | tpr=0.9626 | fpr=0.0193 | 7854.0 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.09159 | acc=0.9806 | tpr=0.9618 | fpr=0.0191 | 13611.9 samples/s | 53.2 steps/s
Avg test loss: 0.09149, Avg test acc: 0.98055, Avg tpr: 0.96197, Avg fpr: 0.01911, total FA: 2653

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09989 | acc=0.9798 | tpr=0.9469 | fpr=0.0196 | 5055.1 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.10196 | acc=0.9796 | tpr=0.9552 | fpr=0.0200 | 6747.7 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.10610 | acc=0.9785 | tpr=0.9510 | fpr=0.0210 | 7619.3 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.10721 | acc=0.9788 | tpr=0.9563 | fpr=0.0208 | 8025.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.10569 | acc=0.9792 | tpr=0.9563 | fpr=0.0204 | 7555.5 samples/s | 29.5 steps/s
[Step= 300] | Loss=0.10794 | acc=0.9790 | tpr=0.9542 | fpr=0.0206 | 8088.1 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.10885 | acc=0.9789 | tpr=0.9555 | fpr=0.0207 | 8049.9 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.10945 | acc=0.9788 | tpr=0.9540 | fpr=0.0208 | 7949.0 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.11138 | acc=0.9786 | tpr=0.9518 | fpr=0.0209 | 7956.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.11056 | acc=0.9787 | tpr=0.9524 | fpr=0.0208 | 7645.1 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.10990 | acc=0.9789 | tpr=0.9522 | fpr=0.0206 | 14010.2 samples/s | 54.7 steps/s
Avg test loss: 0.10969, Avg test acc: 0.97891, Avg tpr: 0.95246, Avg fpr: 0.02061, total FA: 2861

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08879 | acc=0.9812 | tpr=0.9204 | fpr=0.0177 | 4713.1 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.09241 | acc=0.9809 | tpr=0.9360 | fpr=0.0182 | 7375.1 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.09563 | acc=0.9800 | tpr=0.9366 | fpr=0.0192 | 7576.0 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.09703 | acc=0.9800 | tpr=0.9454 | fpr=0.0194 | 8018.8 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.09568 | acc=0.9803 | tpr=0.9441 | fpr=0.0190 | 7621.3 samples/s | 29.8 steps/s
[Step= 300] | Loss=0.09770 | acc=0.9801 | tpr=0.9396 | fpr=0.0192 | 7990.0 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.09823 | acc=0.9799 | tpr=0.9424 | fpr=0.0195 | 8091.8 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.09953 | acc=0.9796 | tpr=0.9387 | fpr=0.0196 | 7881.2 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.10163 | acc=0.9794 | tpr=0.9367 | fpr=0.0199 | 7718.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.10107 | acc=0.9794 | tpr=0.9366 | fpr=0.0198 | 7935.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.10068 | acc=0.9796 | tpr=0.9367 | fpr=0.0196 | 14240.4 samples/s | 55.6 steps/s
Avg test loss: 0.10054, Avg test acc: 0.97961, Avg tpr: 0.93661, Avg fpr: 0.01960, total FA: 2722

server round 42/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=409.6] | Loss=0.00167 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=20.656 | 5484.0 samples/s | 85.7 steps/s
[Step=84050 Epoch=409.8] | Loss=0.00380 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.933 | L2-Norm(final)=20.662 | 4337.3 samples/s | 67.8 steps/s
[Step=84100 Epoch=410.1] | Loss=0.00406 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.936 | L2-Norm(final)=20.669 | 5060.4 samples/s | 79.1 steps/s
[Step=84150 Epoch=410.3] | Loss=0.00393 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=20.676 | 5030.4 samples/s | 78.6 steps/s
[Step=84200 Epoch=410.6] | Loss=0.00382 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=20.683 | 7930.8 samples/s | 123.9 steps/s
[Step=84250 Epoch=410.8] | Loss=0.00368 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=20.689 | 2190.2 samples/s | 34.2 steps/s
[Step=84300 Epoch=411.1] | Loss=0.00365 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=20.695 | 4905.9 samples/s | 76.7 steps/s
[Step=84350 Epoch=411.3] | Loss=0.00353 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=20.700 | 5176.1 samples/s | 80.9 steps/s
[Step=84400 Epoch=411.6] | Loss=0.00356 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.947 | L2-Norm(final)=20.706 | 6882.7 samples/s | 107.5 steps/s
[Step=84450 Epoch=411.8] | Loss=0.00359 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=20.712 | 2313.9 samples/s | 36.2 steps/s
[Step=84500 Epoch=412.0] | Loss=0.00354 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=20.718 | 5154.0 samples/s | 80.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=412.0] | Loss=0.00214 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=20.773 | 5121.0 samples/s | 80.0 steps/s
[Step=84550 Epoch=412.3] | Loss=0.00360 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.968 | L2-Norm(final)=20.779 | 4187.9 samples/s | 65.4 steps/s
[Step=84600 Epoch=412.5] | Loss=0.00413 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=20.784 | 4486.5 samples/s | 70.1 steps/s
[Step=84650 Epoch=412.8] | Loss=0.00423 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=20.788 | 4364.3 samples/s | 68.2 steps/s
[Step=84700 Epoch=413.0] | Loss=0.00411 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=20.792 | 6526.6 samples/s | 102.0 steps/s
[Step=84750 Epoch=413.3] | Loss=0.00380 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=20.796 | 2104.5 samples/s | 32.9 steps/s
[Step=84800 Epoch=413.5] | Loss=0.00344 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=20.800 | 4482.7 samples/s | 70.0 steps/s
[Step=84850 Epoch=413.7] | Loss=0.00344 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.983 | L2-Norm(final)=20.803 | 4478.4 samples/s | 70.0 steps/s
[Step=84900 Epoch=414.0] | Loss=0.00343 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=20.807 | 5957.7 samples/s | 93.1 steps/s
[Step=84950 Epoch=414.2] | Loss=0.00342 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=20.810 | 2192.5 samples/s | 34.3 steps/s
[Step=85000 Epoch=414.5] | Loss=0.00329 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=20.813 | 4380.1 samples/s | 68.4 steps/s
[Step=85050 Epoch=414.7] | Loss=0.00319 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.987 | L2-Norm(final)=20.816 | 4457.7 samples/s | 69.7 steps/s
[Step=85100 Epoch=415.0] | Loss=0.00316 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.988 | L2-Norm(final)=20.819 | 5409.9 samples/s | 84.5 steps/s
[Step=85150 Epoch=415.2] | Loss=0.00313 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=20.821 | 2262.4 samples/s | 35.3 steps/s
[Step=85200 Epoch=415.5] | Loss=0.00307 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=20.824 | 4469.8 samples/s | 69.8 steps/s
[Step=85250 Epoch=415.7] | Loss=0.00299 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=20.827 | 4491.9 samples/s | 70.2 steps/s
[Step=85300 Epoch=415.9] | Loss=0.00293 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.829 | 4981.2 samples/s | 77.8 steps/s
[Step=85350 Epoch=416.2] | Loss=0.00289 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.832 | 2347.7 samples/s | 36.7 steps/s
[Step=85400 Epoch=416.4] | Loss=0.00284 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.835 | 4478.6 samples/s | 70.0 steps/s
[Step=85450 Epoch=416.7] | Loss=0.00280 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.837 | 4389.6 samples/s | 68.6 steps/s
[Step=85500 Epoch=416.9] | Loss=0.00276 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.839 | 4570.2 samples/s | 71.4 steps/s
[Step=85550 Epoch=417.2] | Loss=0.00272 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.842 | 2428.0 samples/s | 37.9 steps/s
[Step=85600 Epoch=417.4] | Loss=0.00268 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.844 | 4524.4 samples/s | 70.7 steps/s
[Step=85650 Epoch=417.6] | Loss=0.00264 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.847 | 4418.7 samples/s | 69.0 steps/s
[Step=85700 Epoch=417.9] | Loss=0.00263 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.849 | 4390.7 samples/s | 68.6 steps/s
[Step=85750 Epoch=418.1] | Loss=0.00262 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.851 | 2449.1 samples/s | 38.3 steps/s
[Step=85800 Epoch=418.4] | Loss=0.00256 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.854 | 4514.9 samples/s | 70.5 steps/s
[Step=85850 Epoch=418.6] | Loss=0.00254 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=20.856 | 4438.7 samples/s | 69.4 steps/s
[Step=85900 Epoch=418.9] | Loss=0.00253 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.858 | 4469.9 samples/s | 69.8 steps/s
[Step=85950 Epoch=419.1] | Loss=0.00253 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.861 | 2485.0 samples/s | 38.8 steps/s
[Step=86000 Epoch=419.4] | Loss=0.00249 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=20.863 | 4406.6 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step86000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=409.9] | Loss=0.00197 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=21.492 | 6058.8 samples/s | 94.7 steps/s
[Step=84050 Epoch=410.1] | Loss=0.00359 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=21.497 | 4086.4 samples/s | 63.9 steps/s
[Step=84100 Epoch=410.4] | Loss=0.00394 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.534 | L2-Norm(final)=21.505 | 5018.0 samples/s | 78.4 steps/s
[Step=84150 Epoch=410.6] | Loss=0.00358 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.536 | L2-Norm(final)=21.511 | 5048.6 samples/s | 78.9 steps/s
[Step=84200 Epoch=410.9] | Loss=0.00338 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=21.518 | 7843.4 samples/s | 122.6 steps/s
[Step=84250 Epoch=411.1] | Loss=0.00316 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.539 | L2-Norm(final)=21.524 | 2206.8 samples/s | 34.5 steps/s
[Step=84300 Epoch=411.3] | Loss=0.00323 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.541 | L2-Norm(final)=21.530 | 5059.7 samples/s | 79.1 steps/s
[Step=84350 Epoch=411.6] | Loss=0.00326 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=21.536 | 5128.1 samples/s | 80.1 steps/s
[Step=84400 Epoch=411.8] | Loss=0.00320 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.543 | L2-Norm(final)=21.542 | 6839.8 samples/s | 106.9 steps/s
[Step=84450 Epoch=412.1] | Loss=0.00308 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=21.548 | 2217.7 samples/s | 34.7 steps/s
[Step=84500 Epoch=412.3] | Loss=0.00300 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.546 | L2-Norm(final)=21.554 | 5112.5 samples/s | 79.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=412.3] | Loss=0.00416 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=21.611 | 5824.5 samples/s | 91.0 steps/s
[Step=84550 Epoch=412.6] | Loss=0.00495 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=21.616 | 3791.8 samples/s | 59.2 steps/s
[Step=84600 Epoch=412.8] | Loss=0.00437 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.564 | L2-Norm(final)=21.621 | 4479.0 samples/s | 70.0 steps/s
[Step=84650 Epoch=413.1] | Loss=0.00397 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.568 | L2-Norm(final)=21.626 | 4510.2 samples/s | 70.5 steps/s
[Step=84700 Epoch=413.3] | Loss=0.00409 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=21.631 | 6542.4 samples/s | 102.2 steps/s
[Step=84750 Epoch=413.5] | Loss=0.00378 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=21.635 | 2041.6 samples/s | 31.9 steps/s
[Step=84800 Epoch=413.8] | Loss=0.00367 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.574 | L2-Norm(final)=21.639 | 4485.3 samples/s | 70.1 steps/s
[Step=84850 Epoch=414.0] | Loss=0.00342 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=21.642 | 4496.8 samples/s | 70.3 steps/s
[Step=84900 Epoch=414.3] | Loss=0.00335 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.577 | L2-Norm(final)=21.646 | 5997.2 samples/s | 93.7 steps/s
[Step=84950 Epoch=414.5] | Loss=0.00315 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=21.649 | 2161.2 samples/s | 33.8 steps/s
[Step=85000 Epoch=414.8] | Loss=0.00307 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.579 | L2-Norm(final)=21.653 | 4530.6 samples/s | 70.8 steps/s
[Step=85050 Epoch=415.0] | Loss=0.00299 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.580 | L2-Norm(final)=21.656 | 4362.5 samples/s | 68.2 steps/s
[Step=85100 Epoch=415.2] | Loss=0.00290 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.580 | L2-Norm(final)=21.659 | 5474.9 samples/s | 85.5 steps/s
[Step=85150 Epoch=415.5] | Loss=0.00279 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.581 | L2-Norm(final)=21.662 | 2227.9 samples/s | 34.8 steps/s
[Step=85200 Epoch=415.7] | Loss=0.00273 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.581 | L2-Norm(final)=21.665 | 4375.7 samples/s | 68.4 steps/s
[Step=85250 Epoch=416.0] | Loss=0.00265 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.668 | 4433.2 samples/s | 69.3 steps/s
[Step=85300 Epoch=416.2] | Loss=0.00262 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.671 | 5181.6 samples/s | 81.0 steps/s
[Step=85350 Epoch=416.5] | Loss=0.00258 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.674 | 2282.9 samples/s | 35.7 steps/s
[Step=85400 Epoch=416.7] | Loss=0.00255 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.676 | 4360.1 samples/s | 68.1 steps/s
[Step=85450 Epoch=417.0] | Loss=0.00248 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.679 | 4428.4 samples/s | 69.2 steps/s
[Step=85500 Epoch=417.2] | Loss=0.00247 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.682 | 4868.6 samples/s | 76.1 steps/s
[Step=85550 Epoch=417.4] | Loss=0.00243 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.684 | 2374.6 samples/s | 37.1 steps/s
[Step=85600 Epoch=417.7] | Loss=0.00239 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.687 | 4435.1 samples/s | 69.3 steps/s
[Step=85650 Epoch=417.9] | Loss=0.00235 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.690 | 4509.8 samples/s | 70.5 steps/s
[Step=85700 Epoch=418.2] | Loss=0.00235 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.692 | 4555.4 samples/s | 71.2 steps/s
[Step=85750 Epoch=418.4] | Loss=0.00232 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=21.695 | 2380.4 samples/s | 37.2 steps/s
[Step=85800 Epoch=418.7] | Loss=0.00228 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.697 | 4451.8 samples/s | 69.6 steps/s
[Step=85850 Epoch=418.9] | Loss=0.00228 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.700 | 4489.6 samples/s | 70.1 steps/s
[Step=85900 Epoch=419.2] | Loss=0.00225 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.703 | 4505.8 samples/s | 70.4 steps/s
[Step=85950 Epoch=419.4] | Loss=0.00223 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.705 | 2453.0 samples/s | 38.3 steps/s
[Step=86000 Epoch=419.6] | Loss=0.00220 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.708 | 4406.4 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step86000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=409.3] | Loss=0.00050 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=21.536 | 5188.8 samples/s | 81.1 steps/s
[Step=84050 Epoch=409.5] | Loss=0.00354 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=21.541 | 4321.6 samples/s | 67.5 steps/s
[Step=84100 Epoch=409.8] | Loss=0.00341 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=21.548 | 5182.1 samples/s | 81.0 steps/s
[Step=84150 Epoch=410.0] | Loss=0.00358 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=21.555 | 5035.9 samples/s | 78.7 steps/s
[Step=84200 Epoch=410.3] | Loss=0.00358 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=21.562 | 7401.1 samples/s | 115.6 steps/s
[Step=84250 Epoch=410.5] | Loss=0.00355 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=21.569 | 2218.8 samples/s | 34.7 steps/s
[Step=84300 Epoch=410.7] | Loss=0.00355 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=21.575 | 5125.2 samples/s | 80.1 steps/s
[Step=84350 Epoch=411.0] | Loss=0.00356 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=21.582 | 5080.0 samples/s | 79.4 steps/s
[Step=84400 Epoch=411.2] | Loss=0.00350 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.338 | L2-Norm(final)=21.588 | 6804.5 samples/s | 106.3 steps/s
[Step=84450 Epoch=411.5] | Loss=0.00349 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.339 | L2-Norm(final)=21.595 | 2284.0 samples/s | 35.7 steps/s
[Step=84500 Epoch=411.7] | Loss=0.00349 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=21.601 | 5045.9 samples/s | 78.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=411.7] | Loss=0.00092 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=21.662 | 5899.0 samples/s | 92.2 steps/s
[Step=84550 Epoch=412.0] | Loss=0.00436 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.358 | L2-Norm(final)=21.668 | 3775.2 samples/s | 59.0 steps/s
[Step=84600 Epoch=412.2] | Loss=0.00452 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=21.673 | 4474.4 samples/s | 69.9 steps/s
[Step=84650 Epoch=412.5] | Loss=0.00435 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=21.678 | 4479.5 samples/s | 70.0 steps/s
[Step=84700 Epoch=412.7] | Loss=0.00424 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=21.683 | 6582.0 samples/s | 102.8 steps/s
[Step=84750 Epoch=412.9] | Loss=0.00385 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=21.687 | 2067.3 samples/s | 32.3 steps/s
[Step=84800 Epoch=413.2] | Loss=0.00361 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=21.691 | 4387.0 samples/s | 68.5 steps/s
[Step=84850 Epoch=413.4] | Loss=0.00368 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=21.695 | 4510.9 samples/s | 70.5 steps/s
[Step=84900 Epoch=413.7] | Loss=0.00368 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.374 | L2-Norm(final)=21.698 | 5908.5 samples/s | 92.3 steps/s
[Step=84950 Epoch=413.9] | Loss=0.00361 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=21.702 | 2188.3 samples/s | 34.2 steps/s
[Step=85000 Epoch=414.2] | Loss=0.00348 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=21.705 | 4548.9 samples/s | 71.1 steps/s
[Step=85050 Epoch=414.4] | Loss=0.00337 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=21.708 | 4385.5 samples/s | 68.5 steps/s
[Step=85100 Epoch=414.6] | Loss=0.00330 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=21.711 | 5365.4 samples/s | 83.8 steps/s
[Step=85150 Epoch=414.9] | Loss=0.00326 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.379 | L2-Norm(final)=21.714 | 2232.0 samples/s | 34.9 steps/s
[Step=85200 Epoch=415.1] | Loss=0.00317 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.380 | L2-Norm(final)=21.717 | 4467.4 samples/s | 69.8 steps/s
[Step=85250 Epoch=415.4] | Loss=0.00310 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.380 | L2-Norm(final)=21.720 | 4506.9 samples/s | 70.4 steps/s
[Step=85300 Epoch=415.6] | Loss=0.00304 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=21.723 | 4963.7 samples/s | 77.6 steps/s
[Step=85350 Epoch=415.9] | Loss=0.00299 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=21.726 | 2340.5 samples/s | 36.6 steps/s
[Step=85400 Epoch=416.1] | Loss=0.00292 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=21.729 | 4503.9 samples/s | 70.4 steps/s
[Step=85450 Epoch=416.4] | Loss=0.00289 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.731 | 4471.0 samples/s | 69.9 steps/s
[Step=85500 Epoch=416.6] | Loss=0.00286 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.734 | 4525.9 samples/s | 70.7 steps/s
[Step=85550 Epoch=416.8] | Loss=0.00284 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.382 | L2-Norm(final)=21.737 | 2413.0 samples/s | 37.7 steps/s
[Step=85600 Epoch=417.1] | Loss=0.00276 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.739 | 4469.8 samples/s | 69.8 steps/s
[Step=85650 Epoch=417.3] | Loss=0.00273 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.742 | 4429.6 samples/s | 69.2 steps/s
[Step=85700 Epoch=417.6] | Loss=0.00271 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.382 | L2-Norm(final)=21.744 | 4463.5 samples/s | 69.7 steps/s
[Step=85750 Epoch=417.8] | Loss=0.00269 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.747 | 2467.3 samples/s | 38.6 steps/s
[Step=85800 Epoch=418.1] | Loss=0.00265 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.749 | 4534.5 samples/s | 70.9 steps/s
[Step=85850 Epoch=418.3] | Loss=0.00263 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.751 | 4373.7 samples/s | 68.3 steps/s
[Step=85900 Epoch=418.5] | Loss=0.00259 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.754 | 4497.6 samples/s | 70.3 steps/s
[Step=85950 Epoch=418.8] | Loss=0.00255 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.756 | 2429.7 samples/s | 38.0 steps/s
[Step=86000 Epoch=419.0] | Loss=0.00252 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=21.759 | 4482.1 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step86000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=409.6] | Loss=0.00380 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.012 | L2-Norm(final)=21.607 | 4930.8 samples/s | 77.0 steps/s
[Step=84050 Epoch=409.9] | Loss=0.00336 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=21.612 | 4646.9 samples/s | 72.6 steps/s
[Step=84100 Epoch=410.1] | Loss=0.00332 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=21.619 | 4987.2 samples/s | 77.9 steps/s
[Step=84150 Epoch=410.4] | Loss=0.00345 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=21.626 | 5016.5 samples/s | 78.4 steps/s
[Step=84200 Epoch=410.6] | Loss=0.00351 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=21.633 | 7658.7 samples/s | 119.7 steps/s
[Step=84250 Epoch=410.9] | Loss=0.00351 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=21.639 | 2241.8 samples/s | 35.0 steps/s
[Step=84300 Epoch=411.1] | Loss=0.00341 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=21.645 | 5005.2 samples/s | 78.2 steps/s
[Step=84350 Epoch=411.3] | Loss=0.00334 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=21.651 | 5007.1 samples/s | 78.2 steps/s
[Step=84400 Epoch=411.6] | Loss=0.00330 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=21.657 | 6997.6 samples/s | 109.3 steps/s
[Step=84450 Epoch=411.8] | Loss=0.00322 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=21.662 | 2309.4 samples/s | 36.1 steps/s
[Step=84500 Epoch=412.1] | Loss=0.00320 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=21.668 | 5014.0 samples/s | 78.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=412.1] | Loss=0.00476 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=21.722 | 5248.2 samples/s | 82.0 steps/s
[Step=84550 Epoch=412.3] | Loss=0.00353 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=21.727 | 4072.3 samples/s | 63.6 steps/s
[Step=84600 Epoch=412.6] | Loss=0.00394 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=21.732 | 4505.5 samples/s | 70.4 steps/s
[Step=84650 Epoch=412.8] | Loss=0.00396 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.053 | L2-Norm(final)=21.736 | 4488.2 samples/s | 70.1 steps/s
[Step=84700 Epoch=413.0] | Loss=0.00370 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=21.740 | 6520.1 samples/s | 101.9 steps/s
[Step=84750 Epoch=413.3] | Loss=0.00358 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.058 | L2-Norm(final)=21.744 | 2092.5 samples/s | 32.7 steps/s
[Step=84800 Epoch=413.5] | Loss=0.00337 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=21.748 | 4455.4 samples/s | 69.6 steps/s
[Step=84850 Epoch=413.8] | Loss=0.00329 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=21.751 | 4432.0 samples/s | 69.2 steps/s
[Step=84900 Epoch=414.0] | Loss=0.00317 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=21.754 | 5754.8 samples/s | 89.9 steps/s
[Step=84950 Epoch=414.3] | Loss=0.00312 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=21.758 | 2185.2 samples/s | 34.1 steps/s
[Step=85000 Epoch=414.5] | Loss=0.00298 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=21.761 | 4509.8 samples/s | 70.5 steps/s
[Step=85050 Epoch=414.8] | Loss=0.00286 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=21.764 | 4514.9 samples/s | 70.5 steps/s
[Step=85100 Epoch=415.0] | Loss=0.00278 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=21.766 | 5319.5 samples/s | 83.1 steps/s
[Step=85150 Epoch=415.2] | Loss=0.00272 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=21.769 | 2242.9 samples/s | 35.0 steps/s
[Step=85200 Epoch=415.5] | Loss=0.00266 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.068 | L2-Norm(final)=21.772 | 4401.9 samples/s | 68.8 steps/s
[Step=85250 Epoch=415.7] | Loss=0.00263 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=21.774 | 4444.5 samples/s | 69.4 steps/s
[Step=85300 Epoch=416.0] | Loss=0.00255 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=21.777 | 4955.7 samples/s | 77.4 steps/s
[Step=85350 Epoch=416.2] | Loss=0.00250 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=21.780 | 2326.0 samples/s | 36.3 steps/s
[Step=85400 Epoch=416.5] | Loss=0.00246 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.782 | 4464.9 samples/s | 69.8 steps/s
[Step=85450 Epoch=416.7] | Loss=0.00244 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.784 | 4587.0 samples/s | 71.7 steps/s
[Step=85500 Epoch=416.9] | Loss=0.00239 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.787 | 4557.4 samples/s | 71.2 steps/s
[Step=85550 Epoch=417.2] | Loss=0.00234 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.789 | 2396.3 samples/s | 37.4 steps/s
[Step=85600 Epoch=417.4] | Loss=0.00229 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.792 | 4453.6 samples/s | 69.6 steps/s
[Step=85650 Epoch=417.7] | Loss=0.00225 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.794 | 4482.4 samples/s | 70.0 steps/s
[Step=85700 Epoch=417.9] | Loss=0.00221 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.796 | 4472.2 samples/s | 69.9 steps/s
[Step=85750 Epoch=418.2] | Loss=0.00219 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.799 | 2478.7 samples/s | 38.7 steps/s
[Step=85800 Epoch=418.4] | Loss=0.00215 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.801 | 4441.5 samples/s | 69.4 steps/s
[Step=85850 Epoch=418.7] | Loss=0.00213 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.803 | 4499.8 samples/s | 70.3 steps/s
[Step=85900 Epoch=418.9] | Loss=0.00211 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=21.805 | 4463.4 samples/s | 69.7 steps/s
[Step=85950 Epoch=419.1] | Loss=0.00211 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=21.808 | 2383.8 samples/s | 37.2 steps/s
[Step=86000 Epoch=419.4] | Loss=0.00209 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=21.810 | 4434.0 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step86000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=411.9] | Loss=0.00163 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=21.676 | 5802.3 samples/s | 90.7 steps/s
[Step=84050 Epoch=412.2] | Loss=0.00296 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=21.681 | 4188.8 samples/s | 65.4 steps/s
[Step=84100 Epoch=412.4] | Loss=0.00310 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=21.687 | 5040.4 samples/s | 78.8 steps/s
[Step=84150 Epoch=412.7] | Loss=0.00297 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=21.694 | 5065.6 samples/s | 79.1 steps/s
[Step=84200 Epoch=412.9] | Loss=0.00315 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=21.701 | 8051.9 samples/s | 125.8 steps/s
[Step=84250 Epoch=413.1] | Loss=0.00306 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=21.708 | 2189.9 samples/s | 34.2 steps/s
[Step=84300 Epoch=413.4] | Loss=0.00293 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=21.714 | 4999.6 samples/s | 78.1 steps/s
[Step=84350 Epoch=413.6] | Loss=0.00294 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=21.720 | 5067.4 samples/s | 79.2 steps/s
[Step=84400 Epoch=413.9] | Loss=0.00300 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=21.726 | 7416.0 samples/s | 115.9 steps/s
[Step=84450 Epoch=414.1] | Loss=0.00295 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=21.732 | 2261.5 samples/s | 35.3 steps/s
[Step=84500 Epoch=414.4] | Loss=0.00290 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=21.738 | 4925.3 samples/s | 77.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=414.4] | Loss=0.00208 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.697 | L2-Norm(final)=21.797 | 5578.8 samples/s | 87.2 steps/s
[Step=84550 Epoch=414.6] | Loss=0.00326 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=21.802 | 3853.5 samples/s | 60.2 steps/s
[Step=84600 Epoch=414.9] | Loss=0.00317 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=21.807 | 4506.4 samples/s | 70.4 steps/s
[Step=84650 Epoch=415.1] | Loss=0.00356 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=21.812 | 4406.0 samples/s | 68.8 steps/s
[Step=84700 Epoch=415.4] | Loss=0.00347 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.708 | L2-Norm(final)=21.817 | 6662.3 samples/s | 104.1 steps/s
[Step=84750 Epoch=415.6] | Loss=0.00323 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=21.822 | 2089.6 samples/s | 32.6 steps/s
[Step=84800 Epoch=415.8] | Loss=0.00323 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=21.826 | 4498.3 samples/s | 70.3 steps/s
[Step=84850 Epoch=416.1] | Loss=0.00311 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=21.830 | 4493.1 samples/s | 70.2 steps/s
[Step=84900 Epoch=416.3] | Loss=0.00300 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=21.834 | 6234.9 samples/s | 97.4 steps/s
[Step=84950 Epoch=416.6] | Loss=0.00299 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.717 | L2-Norm(final)=21.837 | 2133.0 samples/s | 33.3 steps/s
[Step=85000 Epoch=416.8] | Loss=0.00294 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.718 | L2-Norm(final)=21.840 | 4398.2 samples/s | 68.7 steps/s
[Step=85050 Epoch=417.1] | Loss=0.00284 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=21.844 | 4498.1 samples/s | 70.3 steps/s
[Step=85100 Epoch=417.3] | Loss=0.00273 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=21.847 | 5894.4 samples/s | 92.1 steps/s
[Step=85150 Epoch=417.6] | Loss=0.00260 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=21.850 | 2175.4 samples/s | 34.0 steps/s
[Step=85200 Epoch=417.8] | Loss=0.00252 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=21.853 | 4474.5 samples/s | 69.9 steps/s
[Step=85250 Epoch=418.1] | Loss=0.00245 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=21.856 | 4508.0 samples/s | 70.4 steps/s
[Step=85300 Epoch=418.3] | Loss=0.00246 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=21.858 | 5475.0 samples/s | 85.5 steps/s
[Step=85350 Epoch=418.5] | Loss=0.00239 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.861 | 2196.9 samples/s | 34.3 steps/s
[Step=85400 Epoch=418.8] | Loss=0.00234 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.723 | L2-Norm(final)=21.864 | 4453.6 samples/s | 69.6 steps/s
[Step=85450 Epoch=419.0] | Loss=0.00230 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.866 | 4513.8 samples/s | 70.5 steps/s
[Step=85500 Epoch=419.3] | Loss=0.00226 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.723 | L2-Norm(final)=21.869 | 5142.7 samples/s | 80.4 steps/s
[Step=85550 Epoch=419.5] | Loss=0.00222 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.872 | 2261.9 samples/s | 35.3 steps/s
[Step=85600 Epoch=419.8] | Loss=0.00220 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.723 | L2-Norm(final)=21.874 | 4474.1 samples/s | 69.9 steps/s
[Step=85650 Epoch=420.0] | Loss=0.00218 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.877 | 4400.7 samples/s | 68.8 steps/s
[Step=85700 Epoch=420.3] | Loss=0.00215 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.879 | 4938.5 samples/s | 77.2 steps/s
[Step=85750 Epoch=420.5] | Loss=0.00209 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.881 | 2320.2 samples/s | 36.3 steps/s
[Step=85800 Epoch=420.7] | Loss=0.00208 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.884 | 4569.7 samples/s | 71.4 steps/s
[Step=85850 Epoch=421.0] | Loss=0.00206 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=21.886 | 4382.9 samples/s | 68.5 steps/s
[Step=85900 Epoch=421.2] | Loss=0.00203 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=21.889 | 4696.1 samples/s | 73.4 steps/s
[Step=85950 Epoch=421.5] | Loss=0.00201 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=21.891 | 2398.1 samples/s | 37.5 steps/s
[Step=86000 Epoch=421.7] | Loss=0.00200 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=21.893 | 4436.3 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step86000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=796.0] | Loss=0.00012 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.876 | L2-Norm(final)=10.711 | 5084.0 samples/s | 79.4 steps/s
[Step=84050 Epoch=796.4] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.879 | L2-Norm(final)=10.721 | 4234.6 samples/s | 66.2 steps/s
[Step=84100 Epoch=796.9] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.884 | L2-Norm(final)=10.732 | 7503.8 samples/s | 117.2 steps/s
[Step=84150 Epoch=797.4] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.889 | L2-Norm(final)=10.742 | 2138.5 samples/s | 33.4 steps/s
[Step=84200 Epoch=797.9] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.893 | L2-Norm(final)=10.751 | 6533.7 samples/s | 102.1 steps/s
[Step=84250 Epoch=798.3] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=10.758 | 2222.2 samples/s | 34.7 steps/s
[Step=84300 Epoch=798.8] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.899 | L2-Norm(final)=10.765 | 5849.6 samples/s | 91.4 steps/s
[Step=84350 Epoch=799.3] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.901 | L2-Norm(final)=10.772 | 2307.7 samples/s | 36.1 steps/s
[Step=84400 Epoch=799.8] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.903 | L2-Norm(final)=10.778 | 5385.0 samples/s | 84.1 steps/s
[Step=84450 Epoch=800.2] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.905 | L2-Norm(final)=10.783 | 2448.7 samples/s | 38.3 steps/s
[Step=84500 Epoch=800.7] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.907 | L2-Norm(final)=10.789 | 4842.7 samples/s | 75.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=800.7] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.925 | L2-Norm(final)=10.843 | 5260.9 samples/s | 82.2 steps/s
[Step=84550 Epoch=801.2] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.926 | L2-Norm(final)=10.849 | 3722.9 samples/s | 58.2 steps/s
[Step=84600 Epoch=801.7] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.925 | L2-Norm(final)=10.854 | 6294.2 samples/s | 98.3 steps/s
[Step=84650 Epoch=802.1] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.922 | L2-Norm(final)=10.857 | 2011.9 samples/s | 31.4 steps/s
[Step=84700 Epoch=802.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.917 | L2-Norm(final)=10.859 | 5656.0 samples/s | 88.4 steps/s
[Step=84750 Epoch=803.1] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.911 | L2-Norm(final)=10.861 | 2108.6 samples/s | 32.9 steps/s
[Step=84800 Epoch=803.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.905 | L2-Norm(final)=10.862 | 5136.0 samples/s | 80.3 steps/s
[Step=84850 Epoch=804.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.898 | L2-Norm(final)=10.863 | 2156.1 samples/s | 33.7 steps/s
[Step=84900 Epoch=804.5] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.891 | L2-Norm(final)=10.864 | 4705.6 samples/s | 73.5 steps/s
[Step=84950 Epoch=805.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=10.865 | 2252.0 samples/s | 35.2 steps/s
[Step=85000 Epoch=805.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.876 | L2-Norm(final)=10.866 | 4346.1 samples/s | 67.9 steps/s
[Step=85050 Epoch=805.9] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.868 | L2-Norm(final)=10.867 | 2342.1 samples/s | 36.6 steps/s
[Step=85100 Epoch=806.4] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.860 | L2-Norm(final)=10.868 | 4297.5 samples/s | 67.1 steps/s
[Step=85150 Epoch=806.9] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.852 | L2-Norm(final)=10.868 | 2385.5 samples/s | 37.3 steps/s
[Step=85200 Epoch=807.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.844 | L2-Norm(final)=10.869 | 4154.8 samples/s | 64.9 steps/s
[Step=85250 Epoch=807.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.836 | L2-Norm(final)=10.870 | 2386.3 samples/s | 37.3 steps/s
[Step=85300 Epoch=808.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.828 | L2-Norm(final)=10.871 | 4293.6 samples/s | 67.1 steps/s
[Step=85350 Epoch=808.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.819 | L2-Norm(final)=10.871 | 2504.8 samples/s | 39.1 steps/s
[Step=85400 Epoch=809.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.811 | L2-Norm(final)=10.872 | 3859.6 samples/s | 60.3 steps/s
[Step=85450 Epoch=809.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.802 | L2-Norm(final)=10.873 | 6446.2 samples/s | 100.7 steps/s
[Step=85500 Epoch=810.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.793 | L2-Norm(final)=10.874 | 1989.5 samples/s | 31.1 steps/s
[Step=85550 Epoch=810.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=10.875 | 5689.6 samples/s | 88.9 steps/s
[Step=85600 Epoch=811.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.776 | L2-Norm(final)=10.875 | 2059.7 samples/s | 32.2 steps/s
[Step=85650 Epoch=811.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.767 | L2-Norm(final)=10.876 | 5335.0 samples/s | 83.4 steps/s
[Step=85700 Epoch=812.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.758 | L2-Norm(final)=10.877 | 2129.9 samples/s | 33.3 steps/s
[Step=85750 Epoch=812.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.748 | L2-Norm(final)=10.878 | 4781.4 samples/s | 74.7 steps/s
[Step=85800 Epoch=813.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.739 | L2-Norm(final)=10.879 | 2219.2 samples/s | 34.7 steps/s
[Step=85850 Epoch=813.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.730 | L2-Norm(final)=10.880 | 4491.0 samples/s | 70.2 steps/s
[Step=85900 Epoch=814.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.721 | L2-Norm(final)=10.881 | 2344.5 samples/s | 36.6 steps/s
[Step=85950 Epoch=814.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.711 | L2-Norm(final)=10.882 | 4214.7 samples/s | 65.9 steps/s
[Step=86000 Epoch=814.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.701 | L2-Norm(final)=10.883 | 2374.6 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step86000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=799.1] | Loss=0.00022 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.849 | L2-Norm(final)=11.881 | 5439.3 samples/s | 85.0 steps/s
[Step=84050 Epoch=799.5] | Loss=0.00007 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.852 | L2-Norm(final)=11.893 | 4008.0 samples/s | 62.6 steps/s
[Step=84100 Epoch=800.0] | Loss=0.00005 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.858 | L2-Norm(final)=11.903 | 7477.6 samples/s | 116.8 steps/s
[Step=84150 Epoch=800.5] | Loss=0.00004 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.861 | L2-Norm(final)=11.911 | 2196.2 samples/s | 34.3 steps/s
[Step=84200 Epoch=801.0] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.864 | L2-Norm(final)=11.918 | 6247.4 samples/s | 97.6 steps/s
[Step=84250 Epoch=801.4] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=11.924 | 2205.4 samples/s | 34.5 steps/s
[Step=84300 Epoch=801.9] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.869 | L2-Norm(final)=11.929 | 5864.9 samples/s | 91.6 steps/s
[Step=84350 Epoch=802.4] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.871 | L2-Norm(final)=11.935 | 2285.8 samples/s | 35.7 steps/s
[Step=84400 Epoch=802.9] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.872 | L2-Norm(final)=11.940 | 5274.5 samples/s | 82.4 steps/s
[Step=84450 Epoch=803.3] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.945 | 2434.8 samples/s | 38.0 steps/s
[Step=84500 Epoch=803.8] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=11.950 | 4862.1 samples/s | 76.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=803.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.890 | L2-Norm(final)=12.000 | 5329.1 samples/s | 83.3 steps/s
[Step=84550 Epoch=804.3] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.885 | L2-Norm(final)=12.005 | 3778.8 samples/s | 59.0 steps/s
[Step=84600 Epoch=804.8] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=12.008 | 6246.2 samples/s | 97.6 steps/s
[Step=84650 Epoch=805.2] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.862 | L2-Norm(final)=12.010 | 1996.4 samples/s | 31.2 steps/s
[Step=84700 Epoch=805.7] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.847 | L2-Norm(final)=12.011 | 5577.2 samples/s | 87.1 steps/s
[Step=84750 Epoch=806.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.831 | L2-Norm(final)=12.012 | 2123.0 samples/s | 33.2 steps/s
[Step=84800 Epoch=806.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.816 | L2-Norm(final)=12.014 | 4998.2 samples/s | 78.1 steps/s
[Step=84850 Epoch=807.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.799 | L2-Norm(final)=12.015 | 2167.7 samples/s | 33.9 steps/s
[Step=84900 Epoch=807.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.783 | L2-Norm(final)=12.015 | 4662.2 samples/s | 72.8 steps/s
[Step=84950 Epoch=808.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.766 | L2-Norm(final)=12.016 | 2301.2 samples/s | 36.0 steps/s
[Step=85000 Epoch=808.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.750 | L2-Norm(final)=12.017 | 4272.5 samples/s | 66.8 steps/s
[Step=85050 Epoch=809.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.733 | L2-Norm(final)=12.018 | 2355.0 samples/s | 36.8 steps/s
[Step=85100 Epoch=809.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.716 | L2-Norm(final)=12.019 | 4290.9 samples/s | 67.0 steps/s
[Step=85150 Epoch=810.0] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.698 | L2-Norm(final)=12.020 | 2395.3 samples/s | 37.4 steps/s
[Step=85200 Epoch=810.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.681 | L2-Norm(final)=12.021 | 4147.6 samples/s | 64.8 steps/s
[Step=85250 Epoch=810.9] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.664 | L2-Norm(final)=12.022 | 2398.2 samples/s | 37.5 steps/s
[Step=85300 Epoch=811.4] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.647 | L2-Norm(final)=12.023 | 4231.4 samples/s | 66.1 steps/s
[Step=85350 Epoch=811.9] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.629 | L2-Norm(final)=12.024 | 2566.7 samples/s | 40.1 steps/s
[Step=85400 Epoch=812.4] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.612 | L2-Norm(final)=12.025 | 3835.2 samples/s | 59.9 steps/s
[Step=85450 Epoch=812.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.594 | L2-Norm(final)=12.026 | 6504.2 samples/s | 101.6 steps/s
[Step=85500 Epoch=813.3] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.577 | L2-Norm(final)=12.027 | 1971.0 samples/s | 30.8 steps/s
[Step=85550 Epoch=813.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.028 | 5865.8 samples/s | 91.7 steps/s
[Step=85600 Epoch=814.3] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.029 | 2070.6 samples/s | 32.4 steps/s
[Step=85650 Epoch=814.7] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=12.031 | 5302.3 samples/s | 82.8 steps/s
[Step=85700 Epoch=815.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=12.032 | 2151.2 samples/s | 33.6 steps/s
[Step=85750 Epoch=815.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.489 | L2-Norm(final)=12.033 | 4854.6 samples/s | 75.9 steps/s
[Step=85800 Epoch=816.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.471 | L2-Norm(final)=12.034 | 2172.3 samples/s | 33.9 steps/s
[Step=85850 Epoch=816.6] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.454 | L2-Norm(final)=12.036 | 4522.2 samples/s | 70.7 steps/s
[Step=85900 Epoch=817.1] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.436 | L2-Norm(final)=12.037 | 2307.9 samples/s | 36.1 steps/s
[Step=85950 Epoch=817.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.418 | L2-Norm(final)=12.039 | 4251.3 samples/s | 66.4 steps/s
[Step=86000 Epoch=818.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.400 | L2-Norm(final)=12.040 | 2418.5 samples/s | 37.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step86000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=802.2] | Loss=0.00006 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.850 | L2-Norm(final)=11.314 | 5444.5 samples/s | 85.1 steps/s
[Step=84050 Epoch=802.6] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.852 | L2-Norm(final)=11.326 | 4059.3 samples/s | 63.4 steps/s
[Step=84100 Epoch=803.1] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.857 | L2-Norm(final)=11.339 | 7686.6 samples/s | 120.1 steps/s
[Step=84150 Epoch=803.6] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.862 | L2-Norm(final)=11.350 | 2126.2 samples/s | 33.2 steps/s
[Step=84200 Epoch=804.1] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.866 | L2-Norm(final)=11.360 | 6804.6 samples/s | 106.3 steps/s
[Step=84250 Epoch=804.5] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.869 | L2-Norm(final)=11.368 | 2193.4 samples/s | 34.3 steps/s
[Step=84300 Epoch=805.0] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.872 | L2-Norm(final)=11.376 | 6210.6 samples/s | 97.0 steps/s
[Step=84350 Epoch=805.5] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.383 | 2243.1 samples/s | 35.0 steps/s
[Step=84400 Epoch=806.0] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.876 | L2-Norm(final)=11.390 | 5713.8 samples/s | 89.3 steps/s
[Step=84450 Epoch=806.4] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.878 | L2-Norm(final)=11.397 | 2351.5 samples/s | 36.7 steps/s
[Step=84500 Epoch=806.9] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.880 | L2-Norm(final)=11.403 | 5166.7 samples/s | 80.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=806.9] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.897 | L2-Norm(final)=11.466 | 5760.0 samples/s | 90.0 steps/s
[Step=84550 Epoch=807.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.892 | L2-Norm(final)=11.470 | 3586.1 samples/s | 56.0 steps/s
[Step=84600 Epoch=807.9] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.886 | L2-Norm(final)=11.474 | 6332.1 samples/s | 98.9 steps/s
[Step=84650 Epoch=808.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.878 | L2-Norm(final)=11.477 | 1989.9 samples/s | 31.1 steps/s
[Step=84700 Epoch=808.8] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.868 | L2-Norm(final)=11.479 | 5807.1 samples/s | 90.7 steps/s
[Step=84750 Epoch=809.3] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.858 | L2-Norm(final)=11.481 | 2074.8 samples/s | 32.4 steps/s
[Step=84800 Epoch=809.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.848 | L2-Norm(final)=11.483 | 5310.2 samples/s | 83.0 steps/s
[Step=84850 Epoch=810.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.837 | L2-Norm(final)=11.484 | 2144.5 samples/s | 33.5 steps/s
[Step=84900 Epoch=810.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.826 | L2-Norm(final)=11.485 | 4924.7 samples/s | 76.9 steps/s
[Step=84950 Epoch=811.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.815 | L2-Norm(final)=11.487 | 2123.6 samples/s | 33.2 steps/s
[Step=85000 Epoch=811.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.804 | L2-Norm(final)=11.488 | 4654.0 samples/s | 72.7 steps/s
[Step=85050 Epoch=812.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.792 | L2-Norm(final)=11.489 | 2279.4 samples/s | 35.6 steps/s
[Step=85100 Epoch=812.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=11.490 | 4382.4 samples/s | 68.5 steps/s
[Step=85150 Epoch=813.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.768 | L2-Norm(final)=11.491 | 2350.0 samples/s | 36.7 steps/s
[Step=85200 Epoch=813.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.756 | L2-Norm(final)=11.492 | 4151.2 samples/s | 64.9 steps/s
[Step=85250 Epoch=814.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.744 | L2-Norm(final)=11.493 | 2394.1 samples/s | 37.4 steps/s
[Step=85300 Epoch=814.6] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.732 | L2-Norm(final)=11.494 | 4386.6 samples/s | 68.5 steps/s
[Step=85350 Epoch=815.0] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.719 | L2-Norm(final)=11.495 | 2343.1 samples/s | 36.6 steps/s
[Step=85400 Epoch=815.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.707 | L2-Norm(final)=11.497 | 4227.3 samples/s | 66.1 steps/s
[Step=85450 Epoch=816.0] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.695 | L2-Norm(final)=11.498 | 2383.0 samples/s | 37.2 steps/s
[Step=85500 Epoch=816.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.682 | L2-Norm(final)=11.499 | 4238.7 samples/s | 66.2 steps/s
[Step=85550 Epoch=817.0] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=11.501 | 6857.3 samples/s | 107.1 steps/s
[Step=85600 Epoch=817.4] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.657 | L2-Norm(final)=11.502 | 1959.5 samples/s | 30.6 steps/s
[Step=85650 Epoch=817.9] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.644 | L2-Norm(final)=11.503 | 6378.3 samples/s | 99.7 steps/s
[Step=85700 Epoch=818.4] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.631 | L2-Norm(final)=11.505 | 2006.1 samples/s | 31.3 steps/s
[Step=85750 Epoch=818.9] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.618 | L2-Norm(final)=11.506 | 5826.5 samples/s | 91.0 steps/s
[Step=85800 Epoch=819.3] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.605 | L2-Norm(final)=11.508 | 2048.1 samples/s | 32.0 steps/s
[Step=85850 Epoch=819.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.592 | L2-Norm(final)=11.509 | 5350.0 samples/s | 83.6 steps/s
[Step=85900 Epoch=820.3] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.579 | L2-Norm(final)=11.511 | 2132.6 samples/s | 33.3 steps/s
[Step=85950 Epoch=820.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.566 | L2-Norm(final)=11.512 | 4957.8 samples/s | 77.5 steps/s
[Step=86000 Epoch=821.2] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.552 | L2-Norm(final)=11.514 | 2214.4 samples/s | 34.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step86000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=791.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.088 | L2-Norm(final)=11.133 | 5344.5 samples/s | 83.5 steps/s
[Step=84050 Epoch=792.0] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.135 | 4077.1 samples/s | 63.7 steps/s
[Step=84100 Epoch=792.5] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.089 | L2-Norm(final)=11.139 | 7435.2 samples/s | 116.2 steps/s
[Step=84150 Epoch=792.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.091 | L2-Norm(final)=11.144 | 2145.7 samples/s | 33.5 steps/s
[Step=84200 Epoch=793.4] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.093 | L2-Norm(final)=11.148 | 6420.8 samples/s | 100.3 steps/s
[Step=84250 Epoch=793.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.095 | L2-Norm(final)=11.152 | 2261.6 samples/s | 35.3 steps/s
[Step=84300 Epoch=794.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.096 | L2-Norm(final)=11.156 | 5702.6 samples/s | 89.1 steps/s
[Step=84350 Epoch=794.8] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.097 | L2-Norm(final)=11.160 | 2345.3 samples/s | 36.6 steps/s
[Step=84400 Epoch=795.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.164 | 5049.7 samples/s | 78.9 steps/s
[Step=84450 Epoch=795.8] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.099 | L2-Norm(final)=11.167 | 2488.7 samples/s | 38.9 steps/s
[Step=84500 Epoch=796.2] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.100 | L2-Norm(final)=11.171 | 4700.6 samples/s | 73.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=796.2] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.207 | 5375.7 samples/s | 84.0 steps/s
[Step=84550 Epoch=796.7] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.210 | 3825.0 samples/s | 59.8 steps/s
[Step=84600 Epoch=797.2] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.112 | L2-Norm(final)=11.213 | 6126.8 samples/s | 95.7 steps/s
[Step=84650 Epoch=797.6] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.215 | 2030.2 samples/s | 31.7 steps/s
[Step=84700 Epoch=798.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.109 | L2-Norm(final)=11.217 | 5508.1 samples/s | 86.1 steps/s
[Step=84750 Epoch=798.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.106 | L2-Norm(final)=11.218 | 2107.9 samples/s | 32.9 steps/s
[Step=84800 Epoch=799.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.104 | L2-Norm(final)=11.219 | 4923.5 samples/s | 76.9 steps/s
[Step=84850 Epoch=799.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.101 | L2-Norm(final)=11.220 | 2191.2 samples/s | 34.2 steps/s
[Step=84900 Epoch=800.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.098 | L2-Norm(final)=11.221 | 4504.5 samples/s | 70.4 steps/s
[Step=84950 Epoch=800.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.095 | L2-Norm(final)=11.222 | 2336.2 samples/s | 36.5 steps/s
[Step=85000 Epoch=800.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.092 | L2-Norm(final)=11.223 | 4231.9 samples/s | 66.1 steps/s
[Step=85050 Epoch=801.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.089 | L2-Norm(final)=11.224 | 2400.3 samples/s | 37.5 steps/s
[Step=85100 Epoch=801.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=11.225 | 4227.6 samples/s | 66.1 steps/s
[Step=85150 Epoch=802.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=11.226 | 2406.2 samples/s | 37.6 steps/s
[Step=85200 Epoch=802.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.080 | L2-Norm(final)=11.227 | 4262.9 samples/s | 66.6 steps/s
[Step=85250 Epoch=803.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.076 | L2-Norm(final)=11.228 | 2605.0 samples/s | 40.7 steps/s
[Step=85300 Epoch=803.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=11.229 | 3659.5 samples/s | 57.2 steps/s
[Step=85350 Epoch=804.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.069 | L2-Norm(final)=11.229 | 6317.2 samples/s | 98.7 steps/s
[Step=85400 Epoch=804.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.066 | L2-Norm(final)=11.230 | 2039.6 samples/s | 31.9 steps/s
[Step=85450 Epoch=805.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.062 | L2-Norm(final)=11.231 | 5583.8 samples/s | 87.2 steps/s
[Step=85500 Epoch=805.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.058 | L2-Norm(final)=11.232 | 2124.0 samples/s | 33.2 steps/s
[Step=85550 Epoch=806.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.054 | L2-Norm(final)=11.233 | 4969.3 samples/s | 77.6 steps/s
[Step=85600 Epoch=806.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.051 | L2-Norm(final)=11.233 | 2195.2 samples/s | 34.3 steps/s
[Step=85650 Epoch=807.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.047 | L2-Norm(final)=11.234 | 4596.3 samples/s | 71.8 steps/s
[Step=85700 Epoch=807.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.235 | 2287.4 samples/s | 35.7 steps/s
[Step=85750 Epoch=808.0] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.236 | 4246.7 samples/s | 66.4 steps/s
[Step=85800 Epoch=808.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.035 | L2-Norm(final)=11.237 | 2378.0 samples/s | 37.2 steps/s
[Step=85850 Epoch=809.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.031 | L2-Norm(final)=11.237 | 4290.4 samples/s | 67.0 steps/s
[Step=85900 Epoch=809.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.026 | L2-Norm(final)=11.238 | 2401.8 samples/s | 37.5 steps/s
[Step=85950 Epoch=809.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.022 | L2-Norm(final)=11.239 | 4239.9 samples/s | 66.2 steps/s
[Step=86000 Epoch=810.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.018 | L2-Norm(final)=11.240 | 2461.3 samples/s | 38.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step86000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=800.6] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.937 | L2-Norm(final)=11.824 | 5312.4 samples/s | 83.0 steps/s
[Step=84050 Epoch=801.1] | Loss=0.00006 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.940 | L2-Norm(final)=11.834 | 4045.4 samples/s | 63.2 steps/s
[Step=84100 Epoch=801.5] | Loss=0.00005 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.946 | L2-Norm(final)=11.844 | 7349.8 samples/s | 114.8 steps/s
[Step=84150 Epoch=802.0] | Loss=0.00005 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.950 | L2-Norm(final)=11.853 | 2116.8 samples/s | 33.1 steps/s
[Step=84200 Epoch=802.5] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.954 | L2-Norm(final)=11.861 | 6868.4 samples/s | 107.3 steps/s
[Step=84250 Epoch=803.0] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.957 | L2-Norm(final)=11.869 | 2187.4 samples/s | 34.2 steps/s
[Step=84300 Epoch=803.5] | Loss=0.00004 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.959 | L2-Norm(final)=11.875 | 6195.8 samples/s | 96.8 steps/s
[Step=84350 Epoch=803.9] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.962 | L2-Norm(final)=11.881 | 2244.6 samples/s | 35.1 steps/s
[Step=84400 Epoch=804.4] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.964 | L2-Norm(final)=11.887 | 5724.8 samples/s | 89.5 steps/s
[Step=84450 Epoch=804.9] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.966 | L2-Norm(final)=11.893 | 2371.1 samples/s | 37.0 steps/s
[Step=84500 Epoch=805.4] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.968 | L2-Norm(final)=11.899 | 5146.1 samples/s | 80.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=805.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.985 | L2-Norm(final)=11.954 | 5028.1 samples/s | 78.6 steps/s
[Step=84550 Epoch=805.8] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.986 | L2-Norm(final)=11.960 | 3915.7 samples/s | 61.2 steps/s
[Step=84600 Epoch=806.3] | Loss=0.00002 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.984 | L2-Norm(final)=11.964 | 6455.6 samples/s | 100.9 steps/s
[Step=84650 Epoch=806.8] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.979 | L2-Norm(final)=11.966 | 2001.3 samples/s | 31.3 steps/s
[Step=84700 Epoch=807.3] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.972 | L2-Norm(final)=11.968 | 5700.2 samples/s | 89.1 steps/s
[Step=84750 Epoch=807.7] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.964 | L2-Norm(final)=11.969 | 2061.7 samples/s | 32.2 steps/s
[Step=84800 Epoch=808.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.956 | L2-Norm(final)=11.971 | 5351.3 samples/s | 83.6 steps/s
[Step=84850 Epoch=808.7] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.948 | L2-Norm(final)=11.972 | 2141.9 samples/s | 33.5 steps/s
[Step=84900 Epoch=809.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.939 | L2-Norm(final)=11.973 | 4966.1 samples/s | 77.6 steps/s
[Step=84950 Epoch=809.7] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.931 | L2-Norm(final)=11.974 | 2174.5 samples/s | 34.0 steps/s
[Step=85000 Epoch=810.1] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.921 | L2-Norm(final)=11.975 | 4605.3 samples/s | 72.0 steps/s
[Step=85050 Epoch=810.6] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.912 | L2-Norm(final)=11.976 | 2279.4 samples/s | 35.6 steps/s
[Step=85100 Epoch=811.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.903 | L2-Norm(final)=11.977 | 4340.1 samples/s | 67.8 steps/s
[Step=85150 Epoch=811.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.893 | L2-Norm(final)=11.977 | 2395.2 samples/s | 37.4 steps/s
[Step=85200 Epoch=812.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.884 | L2-Norm(final)=11.978 | 4091.2 samples/s | 63.9 steps/s
[Step=85250 Epoch=812.5] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.979 | 2355.9 samples/s | 36.8 steps/s
[Step=85300 Epoch=813.0] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.864 | L2-Norm(final)=11.980 | 4262.0 samples/s | 66.6 steps/s
[Step=85350 Epoch=813.5] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.854 | L2-Norm(final)=11.981 | 2394.5 samples/s | 37.4 steps/s
[Step=85400 Epoch=813.9] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.844 | L2-Norm(final)=11.982 | 4202.3 samples/s | 65.7 steps/s
[Step=85450 Epoch=814.4] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.834 | L2-Norm(final)=11.983 | 2412.0 samples/s | 37.7 steps/s
[Step=85500 Epoch=814.9] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.824 | L2-Norm(final)=11.984 | 4124.2 samples/s | 64.4 steps/s
[Step=85550 Epoch=815.4] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.813 | L2-Norm(final)=11.985 | 7036.3 samples/s | 109.9 steps/s
[Step=85600 Epoch=815.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.803 | L2-Norm(final)=11.986 | 1953.4 samples/s | 30.5 steps/s
[Step=85650 Epoch=816.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.792 | L2-Norm(final)=11.987 | 6222.8 samples/s | 97.2 steps/s
[Step=85700 Epoch=816.8] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.782 | L2-Norm(final)=11.988 | 2033.7 samples/s | 31.8 steps/s
[Step=85750 Epoch=817.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.771 | L2-Norm(final)=11.989 | 5740.5 samples/s | 89.7 steps/s
[Step=85800 Epoch=817.8] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.760 | L2-Norm(final)=11.990 | 2100.9 samples/s | 32.8 steps/s
[Step=85850 Epoch=818.2] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.749 | L2-Norm(final)=11.991 | 5167.5 samples/s | 80.7 steps/s
[Step=85900 Epoch=818.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.738 | L2-Norm(final)=11.992 | 2130.3 samples/s | 33.3 steps/s
[Step=85950 Epoch=819.2] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.727 | L2-Norm(final)=11.993 | 4968.3 samples/s | 77.6 steps/s
[Step=86000 Epoch=819.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.716 | L2-Norm(final)=11.994 | 2222.7 samples/s | 34.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.11146 | acc=0.9567 | tpr=0.9699 | fpr=0.0719 | 4912.9 samples/s | 19.2 steps/s
Avg test loss: 0.11576, Avg test acc: 0.95504, Avg tpr: 0.96847, Avg fpr: 0.07448, total FA: 581

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.11564 | acc=0.9569 | tpr=0.9739 | fpr=0.0800 | 4784.6 samples/s | 18.7 steps/s
Avg test loss: 0.11455, Avg test acc: 0.95689, Avg tpr: 0.97354, Avg fpr: 0.07973, total FA: 622

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.11144 | acc=0.9569 | tpr=0.9728 | fpr=0.0778 | 4638.9 samples/s | 18.1 steps/s
Avg test loss: 0.11357, Avg test acc: 0.95480, Avg tpr: 0.96981, Avg fpr: 0.07820, total FA: 610

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.10286 | acc=0.9590 | tpr=0.9725 | fpr=0.0704 | 4878.1 samples/s | 19.1 steps/s
Avg test loss: 0.10876, Avg test acc: 0.95677, Avg tpr: 0.97208, Avg fpr: 0.07691, total FA: 600

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.11108 | acc=0.9559 | tpr=0.9667 | fpr=0.0676 | 4966.0 samples/s | 19.4 steps/s
Avg test loss: 0.11593, Avg test acc: 0.95476, Avg tpr: 0.96625, Avg fpr: 0.07050, total FA: 550

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.36293 | acc=0.2994 | tpr=0.0072 | fpr=0.0662 | 4729.8 samples/s | 18.5 steps/s
Avg test loss: 5.37045, Avg test acc: 0.29858, Avg tpr: 0.00863, Avg fpr: 0.06371, total FA: 497

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.84283 | acc=0.3086 | tpr=0.0029 | fpr=0.0275 | 4654.4 samples/s | 18.2 steps/s
Avg test loss: 4.85909, Avg test acc: 0.30527, Avg tpr: 0.00245, Avg fpr: 0.02871, total FA: 224

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=4.95769 | acc=0.2948 | tpr=0.0071 | fpr=0.0805 | 4778.3 samples/s | 18.7 steps/s
Avg test loss: 4.96291, Avg test acc: 0.29309, Avg tpr: 0.00828, Avg fpr: 0.08050, total FA: 628

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.63627 | acc=0.2986 | tpr=0.0137 | fpr=0.0828 | 4833.2 samples/s | 18.9 steps/s
Avg test loss: 5.63633, Avg test acc: 0.29746, Avg tpr: 0.01498, Avg fpr: 0.08127, total FA: 634

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.82906 | acc=0.3020 | tpr=0.0097 | fpr=0.0634 | 4780.3 samples/s | 18.7 steps/s
Avg test loss: 4.83628, Avg test acc: 0.29934, Avg tpr: 0.01043, Avg fpr: 0.06525, total FA: 509

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.26645 | acc=0.1053 | tpr=0.5575 | fpr=0.9028 | 4755.3 samples/s | 18.6 steps/s
[Step= 100] | Loss=6.23485 | acc=0.1077 | tpr=0.5458 | fpr=0.9005 | 7182.5 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.24956 | acc=0.1078 | tpr=0.5504 | fpr=0.9004 | 7921.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.24101 | acc=0.1075 | tpr=0.5410 | fpr=0.9004 | 7878.5 samples/s | 30.8 steps/s
[Step= 250] | Loss=6.24471 | acc=0.1080 | tpr=0.5493 | fpr=0.9000 | 7500.2 samples/s | 29.3 steps/s
[Step= 300] | Loss=6.23800 | acc=0.1081 | tpr=0.5578 | fpr=0.9001 | 8284.5 samples/s | 32.4 steps/s
[Step= 350] | Loss=6.22866 | acc=0.1081 | tpr=0.5554 | fpr=0.9000 | 8161.3 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.22741 | acc=0.1082 | tpr=0.5536 | fpr=0.8999 | 7497.2 samples/s | 29.3 steps/s
[Step= 450] | Loss=6.23209 | acc=0.1085 | tpr=0.5536 | fpr=0.8996 | 7947.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.23424 | acc=0.1085 | tpr=0.5502 | fpr=0.8995 | 8185.8 samples/s | 32.0 steps/s
[Step= 550] | Loss=6.23782 | acc=0.1082 | tpr=0.5448 | fpr=0.8997 | 13493.8 samples/s | 52.7 steps/s
Avg test loss: 6.23983, Avg test acc: 0.10814, Avg tpr: 0.54477, Avg fpr: 0.89980, total FA: 124935

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.04139 | acc=0.0908 | tpr=0.4735 | fpr=0.9161 | 4997.2 samples/s | 19.5 steps/s
[Step= 100] | Loss=6.02529 | acc=0.0907 | tpr=0.4925 | fpr=0.9168 | 7209.3 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.02598 | acc=0.0904 | tpr=0.4914 | fpr=0.9170 | 7267.3 samples/s | 28.4 steps/s
[Step= 200] | Loss=6.01894 | acc=0.0900 | tpr=0.4820 | fpr=0.9171 | 7989.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.02144 | acc=0.0906 | tpr=0.4908 | fpr=0.9167 | 7745.8 samples/s | 30.3 steps/s
[Step= 300] | Loss=6.01721 | acc=0.0907 | tpr=0.4975 | fpr=0.9167 | 7743.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=6.01096 | acc=0.0905 | tpr=0.4953 | fpr=0.9168 | 8023.5 samples/s | 31.3 steps/s
[Step= 400] | Loss=6.00822 | acc=0.0905 | tpr=0.4940 | fpr=0.9168 | 8017.7 samples/s | 31.3 steps/s
[Step= 450] | Loss=6.01376 | acc=0.0906 | tpr=0.4966 | fpr=0.9168 | 7670.8 samples/s | 30.0 steps/s
[Step= 500] | Loss=6.01795 | acc=0.0906 | tpr=0.4925 | fpr=0.9167 | 7727.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=6.02404 | acc=0.0902 | tpr=0.4891 | fpr=0.9170 | 15082.5 samples/s | 58.9 steps/s
Avg test loss: 6.02632, Avg test acc: 0.09017, Avg tpr: 0.48930, Avg fpr: 0.91709, total FA: 127336

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=6.29095 | acc=0.0927 | tpr=0.3142 | fpr=0.9112 | 4786.7 samples/s | 18.7 steps/s
[Step= 100] | Loss=6.25508 | acc=0.0943 | tpr=0.3198 | fpr=0.9100 | 7200.2 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.26901 | acc=0.0950 | tpr=0.3141 | fpr=0.9090 | 7796.2 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.25959 | acc=0.0949 | tpr=0.3082 | fpr=0.9090 | 7965.3 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.26051 | acc=0.0953 | tpr=0.3162 | fpr=0.9087 | 7639.6 samples/s | 29.8 steps/s
[Step= 300] | Loss=6.25463 | acc=0.0954 | tpr=0.3222 | fpr=0.9087 | 8185.1 samples/s | 32.0 steps/s
[Step= 350] | Loss=6.24715 | acc=0.0959 | tpr=0.3206 | fpr=0.9082 | 7607.7 samples/s | 29.7 steps/s
[Step= 400] | Loss=6.24597 | acc=0.0961 | tpr=0.3244 | fpr=0.9080 | 8615.2 samples/s | 33.7 steps/s
[Step= 450] | Loss=6.25169 | acc=0.0963 | tpr=0.3213 | fpr=0.9078 | 7283.1 samples/s | 28.4 steps/s
[Step= 500] | Loss=6.25328 | acc=0.0962 | tpr=0.3207 | fpr=0.9079 | 8289.6 samples/s | 32.4 steps/s
[Step= 550] | Loss=6.25782 | acc=0.0960 | tpr=0.3223 | fpr=0.9081 | 13428.6 samples/s | 52.5 steps/s
Avg test loss: 6.25914, Avg test acc: 0.09587, Avg tpr: 0.32290, Avg fpr: 0.90826, total FA: 126110

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=6.04136 | acc=0.1071 | tpr=0.5000 | fpr=0.9000 | 4933.5 samples/s | 19.3 steps/s
[Step= 100] | Loss=6.01475 | acc=0.1064 | tpr=0.5011 | fpr=0.9010 | 6986.5 samples/s | 27.3 steps/s
[Step= 150] | Loss=6.02832 | acc=0.1059 | tpr=0.5115 | fpr=0.9015 | 7773.2 samples/s | 30.4 steps/s
[Step= 200] | Loss=6.01787 | acc=0.1048 | tpr=0.5071 | fpr=0.9025 | 7643.7 samples/s | 29.9 steps/s
[Step= 250] | Loss=6.02397 | acc=0.1058 | tpr=0.5127 | fpr=0.9016 | 8243.1 samples/s | 32.2 steps/s
[Step= 300] | Loss=6.02122 | acc=0.1059 | tpr=0.5207 | fpr=0.9017 | 7659.6 samples/s | 29.9 steps/s
[Step= 350] | Loss=6.01060 | acc=0.1060 | tpr=0.5191 | fpr=0.9015 | 8091.5 samples/s | 31.6 steps/s
[Step= 400] | Loss=6.00699 | acc=0.1061 | tpr=0.5153 | fpr=0.9014 | 7874.8 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.01289 | acc=0.1061 | tpr=0.5127 | fpr=0.9013 | 8018.7 samples/s | 31.3 steps/s
[Step= 500] | Loss=6.01398 | acc=0.1061 | tpr=0.5106 | fpr=0.9012 | 7605.8 samples/s | 29.7 steps/s
[Step= 550] | Loss=6.01952 | acc=0.1058 | tpr=0.5038 | fpr=0.9014 | 14240.2 samples/s | 55.6 steps/s
Avg test loss: 6.02089, Avg test acc: 0.10570, Avg tpr: 0.50357, Avg fpr: 0.90153, total FA: 125176

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.91510 | acc=0.1205 | tpr=0.4248 | fpr=0.8849 | 4870.8 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.89140 | acc=0.1230 | tpr=0.4392 | fpr=0.8829 | 6630.1 samples/s | 25.9 steps/s
[Step= 150] | Loss=5.89018 | acc=0.1236 | tpr=0.4467 | fpr=0.8824 | 7803.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.88392 | acc=0.1236 | tpr=0.4393 | fpr=0.8822 | 7885.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.88713 | acc=0.1245 | tpr=0.4445 | fpr=0.8814 | 7588.6 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.88788 | acc=0.1245 | tpr=0.4465 | fpr=0.8814 | 7982.5 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.87922 | acc=0.1250 | tpr=0.4477 | fpr=0.8808 | 7759.9 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.87828 | acc=0.1249 | tpr=0.4447 | fpr=0.8809 | 7557.0 samples/s | 29.5 steps/s
[Step= 450] | Loss=5.88356 | acc=0.1252 | tpr=0.4416 | fpr=0.8805 | 8342.7 samples/s | 32.6 steps/s
[Step= 500] | Loss=5.88570 | acc=0.1249 | tpr=0.4388 | fpr=0.8808 | 7505.6 samples/s | 29.3 steps/s
[Step= 550] | Loss=5.89086 | acc=0.1245 | tpr=0.4373 | fpr=0.8812 | 13920.1 samples/s | 54.4 steps/s
Avg test loss: 5.89308, Avg test acc: 0.12437, Avg tpr: 0.43661, Avg fpr: 0.88131, total FA: 122368

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08649 | acc=0.9819 | tpr=0.9602 | fpr=0.0177 | 4670.5 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.08766 | acc=0.9820 | tpr=0.9638 | fpr=0.0177 | 7128.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.09143 | acc=0.9809 | tpr=0.9611 | fpr=0.0187 | 7650.4 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.09323 | acc=0.9812 | tpr=0.9672 | fpr=0.0186 | 8167.2 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.09203 | acc=0.9814 | tpr=0.9642 | fpr=0.0182 | 7674.7 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.09401 | acc=0.9811 | tpr=0.9629 | fpr=0.0185 | 7808.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.09497 | acc=0.9808 | tpr=0.9624 | fpr=0.0188 | 7850.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.09597 | acc=0.9806 | tpr=0.9573 | fpr=0.0190 | 7932.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.09789 | acc=0.9802 | tpr=0.9533 | fpr=0.0193 | 7330.0 samples/s | 28.6 steps/s
[Step= 500] | Loss=0.09721 | acc=0.9802 | tpr=0.9533 | fpr=0.0193 | 7971.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.09658 | acc=0.9804 | tpr=0.9515 | fpr=0.0191 | 14653.1 samples/s | 57.2 steps/s
Avg test loss: 0.09648, Avg test acc: 0.98040, Avg tpr: 0.95166, Avg fpr: 0.01908, total FA: 2649

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07526 | acc=0.9827 | tpr=0.9159 | fpr=0.0161 | 4569.2 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.07786 | acc=0.9827 | tpr=0.9168 | fpr=0.0161 | 7380.9 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.08102 | acc=0.9825 | tpr=0.9193 | fpr=0.0163 | 8084.4 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.08298 | acc=0.9826 | tpr=0.9268 | fpr=0.0164 | 7489.9 samples/s | 29.3 steps/s
[Step= 250] | Loss=0.08166 | acc=0.9830 | tpr=0.9284 | fpr=0.0160 | 8253.7 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.08334 | acc=0.9827 | tpr=0.9280 | fpr=0.0163 | 7298.5 samples/s | 28.5 steps/s
[Step= 350] | Loss=0.08392 | acc=0.9826 | tpr=0.9286 | fpr=0.0164 | 8202.4 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.08491 | acc=0.9824 | tpr=0.9240 | fpr=0.0165 | 7911.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.08683 | acc=0.9821 | tpr=0.9226 | fpr=0.0168 | 7765.9 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.08616 | acc=0.9822 | tpr=0.9242 | fpr=0.0168 | 7760.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.08591 | acc=0.9823 | tpr=0.9212 | fpr=0.0166 | 14224.3 samples/s | 55.6 steps/s
Avg test loss: 0.08581, Avg test acc: 0.98227, Avg tpr: 0.92116, Avg fpr: 0.01662, total FA: 2308

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08413 | acc=0.9809 | tpr=0.9690 | fpr=0.0188 | 4634.6 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.08580 | acc=0.9807 | tpr=0.9723 | fpr=0.0192 | 7554.7 samples/s | 29.5 steps/s
[Step= 150] | Loss=0.08999 | acc=0.9798 | tpr=0.9683 | fpr=0.0200 | 7410.9 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.09141 | acc=0.9802 | tpr=0.9727 | fpr=0.0197 | 7934.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.09008 | acc=0.9804 | tpr=0.9712 | fpr=0.0195 | 8237.0 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.09208 | acc=0.9800 | tpr=0.9680 | fpr=0.0198 | 7391.2 samples/s | 28.9 steps/s
[Step= 350] | Loss=0.09287 | acc=0.9798 | tpr=0.9687 | fpr=0.0200 | 7717.4 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.09393 | acc=0.9796 | tpr=0.9655 | fpr=0.0202 | 7597.2 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.09541 | acc=0.9794 | tpr=0.9635 | fpr=0.0203 | 8020.5 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.09497 | acc=0.9793 | tpr=0.9648 | fpr=0.0204 | 7832.1 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09453 | acc=0.9794 | tpr=0.9634 | fpr=0.0203 | 14213.1 samples/s | 55.5 steps/s
Avg test loss: 0.09442, Avg test acc: 0.97944, Avg tpr: 0.96355, Avg fpr: 0.02027, total FA: 2814

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09686 | acc=0.9802 | tpr=0.9513 | fpr=0.0192 | 4594.3 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.09875 | acc=0.9801 | tpr=0.9574 | fpr=0.0195 | 7316.8 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.10272 | acc=0.9790 | tpr=0.9524 | fpr=0.0205 | 7920.9 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.10395 | acc=0.9792 | tpr=0.9574 | fpr=0.0204 | 7655.0 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.10252 | acc=0.9796 | tpr=0.9563 | fpr=0.0199 | 8030.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.10474 | acc=0.9794 | tpr=0.9542 | fpr=0.0201 | 7675.7 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.10556 | acc=0.9792 | tpr=0.9543 | fpr=0.0203 | 7556.9 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.10613 | acc=0.9791 | tpr=0.9519 | fpr=0.0204 | 8166.9 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.10799 | acc=0.9789 | tpr=0.9499 | fpr=0.0206 | 8046.1 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.10718 | acc=0.9791 | tpr=0.9511 | fpr=0.0204 | 7620.5 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.10655 | acc=0.9793 | tpr=0.9511 | fpr=0.0202 | 14155.9 samples/s | 55.3 steps/s
Avg test loss: 0.10636, Avg test acc: 0.97930, Avg tpr: 0.95127, Avg fpr: 0.02019, total FA: 2804

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08480 | acc=0.9819 | tpr=0.9336 | fpr=0.0173 | 4889.9 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.08803 | acc=0.9816 | tpr=0.9488 | fpr=0.0178 | 6819.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.09111 | acc=0.9804 | tpr=0.9496 | fpr=0.0190 | 7698.8 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.09247 | acc=0.9804 | tpr=0.9585 | fpr=0.0192 | 7858.9 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.09136 | acc=0.9807 | tpr=0.9546 | fpr=0.0189 | 7902.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.09317 | acc=0.9804 | tpr=0.9513 | fpr=0.0191 | 7754.4 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.09365 | acc=0.9802 | tpr=0.9530 | fpr=0.0193 | 7932.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.09491 | acc=0.9799 | tpr=0.9486 | fpr=0.0196 | 7772.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.09689 | acc=0.9796 | tpr=0.9460 | fpr=0.0197 | 8106.3 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.09633 | acc=0.9797 | tpr=0.9458 | fpr=0.0197 | 7669.7 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.09592 | acc=0.9799 | tpr=0.9459 | fpr=0.0195 | 12900.8 samples/s | 50.4 steps/s
Avg test loss: 0.09581, Avg test acc: 0.97989, Avg tpr: 0.94572, Avg fpr: 0.01949, total FA: 2706

server round 43/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=419.4] | Loss=0.00481 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.849 | L2-Norm(final)=20.931 | 5329.7 samples/s | 83.3 steps/s
[Step=86050 Epoch=419.6] | Loss=0.00728 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.851 | L2-Norm(final)=20.936 | 4242.4 samples/s | 66.3 steps/s
[Step=86100 Epoch=419.8] | Loss=0.00681 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.855 | L2-Norm(final)=20.944 | 4698.1 samples/s | 73.4 steps/s
[Step=86150 Epoch=420.1] | Loss=0.00681 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.860 | L2-Norm(final)=20.951 | 4820.5 samples/s | 75.3 steps/s
[Step=86200 Epoch=420.3] | Loss=0.00643 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.863 | L2-Norm(final)=20.957 | 7417.7 samples/s | 115.9 steps/s
[Step=86250 Epoch=420.6] | Loss=0.00610 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=20.963 | 2066.0 samples/s | 32.3 steps/s
[Step=86300 Epoch=420.8] | Loss=0.00617 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.869 | L2-Norm(final)=20.969 | 4921.5 samples/s | 76.9 steps/s
[Step=86350 Epoch=421.1] | Loss=0.00607 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.871 | L2-Norm(final)=20.975 | 4946.2 samples/s | 77.3 steps/s
[Step=86400 Epoch=421.3] | Loss=0.00595 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.874 | L2-Norm(final)=20.981 | 6996.1 samples/s | 109.3 steps/s
[Step=86450 Epoch=421.5] | Loss=0.00586 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=20.986 | 2250.1 samples/s | 35.2 steps/s
[Step=86500 Epoch=421.8] | Loss=0.00585 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=20.992 | 5036.5 samples/s | 78.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=421.8] | Loss=0.00999 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=21.045 | 5506.6 samples/s | 86.0 steps/s
[Step=86550 Epoch=422.0] | Loss=0.00604 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=21.049 | 4201.9 samples/s | 65.7 steps/s
[Step=86600 Epoch=422.3] | Loss=0.00628 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.907 | L2-Norm(final)=21.053 | 4529.0 samples/s | 70.8 steps/s
[Step=86650 Epoch=422.5] | Loss=0.00637 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.911 | L2-Norm(final)=21.058 | 4424.0 samples/s | 69.1 steps/s
[Step=86700 Epoch=422.8] | Loss=0.00592 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=21.062 | 6553.1 samples/s | 102.4 steps/s
[Step=86750 Epoch=423.0] | Loss=0.00539 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.918 | L2-Norm(final)=21.065 | 2080.8 samples/s | 32.5 steps/s
[Step=86800 Epoch=423.3] | Loss=0.00501 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.920 | L2-Norm(final)=21.069 | 4470.3 samples/s | 69.8 steps/s
[Step=86850 Epoch=423.5] | Loss=0.00470 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.922 | L2-Norm(final)=21.072 | 4537.5 samples/s | 70.9 steps/s
[Step=86900 Epoch=423.7] | Loss=0.00452 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=21.075 | 5827.3 samples/s | 91.1 steps/s
[Step=86950 Epoch=424.0] | Loss=0.00446 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=21.078 | 2185.2 samples/s | 34.1 steps/s
[Step=87000 Epoch=424.2] | Loss=0.00428 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=21.080 | 4445.3 samples/s | 69.5 steps/s
[Step=87050 Epoch=424.5] | Loss=0.00413 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.928 | L2-Norm(final)=21.083 | 4472.9 samples/s | 69.9 steps/s
[Step=87100 Epoch=424.7] | Loss=0.00403 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=21.086 | 5340.6 samples/s | 83.4 steps/s
[Step=87150 Epoch=425.0] | Loss=0.00393 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=21.088 | 2217.1 samples/s | 34.6 steps/s
[Step=87200 Epoch=425.2] | Loss=0.00378 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=21.091 | 4551.2 samples/s | 71.1 steps/s
[Step=87250 Epoch=425.4] | Loss=0.00369 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.932 | L2-Norm(final)=21.093 | 4486.3 samples/s | 70.1 steps/s
[Step=87300 Epoch=425.7] | Loss=0.00365 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.933 | L2-Norm(final)=21.096 | 4876.1 samples/s | 76.2 steps/s
[Step=87350 Epoch=425.9] | Loss=0.00358 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.934 | L2-Norm(final)=21.098 | 2326.0 samples/s | 36.3 steps/s
[Step=87400 Epoch=426.2] | Loss=0.00353 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=21.101 | 4564.3 samples/s | 71.3 steps/s
[Step=87450 Epoch=426.4] | Loss=0.00351 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.935 | L2-Norm(final)=21.103 | 4420.7 samples/s | 69.1 steps/s
[Step=87500 Epoch=426.7] | Loss=0.00343 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.936 | L2-Norm(final)=21.105 | 4491.9 samples/s | 70.2 steps/s
[Step=87550 Epoch=426.9] | Loss=0.00340 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=21.108 | 2436.5 samples/s | 38.1 steps/s
[Step=87600 Epoch=427.2] | Loss=0.00334 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=21.110 | 4493.2 samples/s | 70.2 steps/s
[Step=87650 Epoch=427.4] | Loss=0.00331 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=21.112 | 4521.5 samples/s | 70.6 steps/s
[Step=87700 Epoch=427.6] | Loss=0.00325 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=21.114 | 4412.4 samples/s | 68.9 steps/s
[Step=87750 Epoch=427.9] | Loss=0.00320 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=21.116 | 2492.7 samples/s | 38.9 steps/s
[Step=87800 Epoch=428.1] | Loss=0.00317 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=21.119 | 4396.5 samples/s | 68.7 steps/s
[Step=87850 Epoch=428.4] | Loss=0.00314 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=21.121 | 4403.0 samples/s | 68.8 steps/s
[Step=87900 Epoch=428.6] | Loss=0.00311 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=21.123 | 4466.0 samples/s | 69.8 steps/s
[Step=87950 Epoch=428.9] | Loss=0.00308 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=21.125 | 2506.3 samples/s | 39.2 steps/s
[Step=88000 Epoch=429.1] | Loss=0.00303 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.941 | L2-Norm(final)=21.127 | 4430.7 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step88000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=419.6] | Loss=0.00287 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.438 | L2-Norm(final)=21.784 | 5598.4 samples/s | 87.5 steps/s
[Step=86050 Epoch=419.9] | Loss=0.00515 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.441 | L2-Norm(final)=21.791 | 4411.9 samples/s | 68.9 steps/s
[Step=86100 Epoch=420.1] | Loss=0.00540 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.444 | L2-Norm(final)=21.799 | 4997.3 samples/s | 78.1 steps/s
[Step=86150 Epoch=420.4] | Loss=0.00547 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.448 | L2-Norm(final)=21.808 | 5087.8 samples/s | 79.5 steps/s
[Step=86200 Epoch=420.6] | Loss=0.00530 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.451 | L2-Norm(final)=21.816 | 7673.7 samples/s | 119.9 steps/s
[Step=86250 Epoch=420.9] | Loss=0.00514 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.454 | L2-Norm(final)=21.824 | 2227.0 samples/s | 34.8 steps/s
[Step=86300 Epoch=421.1] | Loss=0.00511 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.457 | L2-Norm(final)=21.831 | 5045.4 samples/s | 78.8 steps/s
[Step=86350 Epoch=421.3] | Loss=0.00513 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.459 | L2-Norm(final)=21.838 | 5041.7 samples/s | 78.8 steps/s
[Step=86400 Epoch=421.6] | Loss=0.00498 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.462 | L2-Norm(final)=21.844 | 7103.8 samples/s | 111.0 steps/s
[Step=86450 Epoch=421.8] | Loss=0.00490 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.464 | L2-Norm(final)=21.851 | 2280.8 samples/s | 35.6 steps/s
[Step=86500 Epoch=422.1] | Loss=0.00486 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.467 | L2-Norm(final)=21.857 | 4985.5 samples/s | 77.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=422.1] | Loss=0.00312 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.489 | L2-Norm(final)=21.919 | 5267.3 samples/s | 82.3 steps/s
[Step=86550 Epoch=422.3] | Loss=0.00521 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.493 | L2-Norm(final)=21.924 | 4074.5 samples/s | 63.7 steps/s
[Step=86600 Epoch=422.6] | Loss=0.00656 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=21.928 | 4489.4 samples/s | 70.1 steps/s
[Step=86650 Epoch=422.8] | Loss=0.00624 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.501 | L2-Norm(final)=21.932 | 4500.3 samples/s | 70.3 steps/s
[Step=86700 Epoch=423.1] | Loss=0.00601 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.505 | L2-Norm(final)=21.937 | 6598.6 samples/s | 103.1 steps/s
[Step=86750 Epoch=423.3] | Loss=0.00538 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.508 | L2-Norm(final)=21.941 | 2100.2 samples/s | 32.8 steps/s
[Step=86800 Epoch=423.5] | Loss=0.00506 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=21.945 | 4484.0 samples/s | 70.1 steps/s
[Step=86850 Epoch=423.8] | Loss=0.00475 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.512 | L2-Norm(final)=21.948 | 4429.9 samples/s | 69.2 steps/s
[Step=86900 Epoch=424.0] | Loss=0.00459 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.514 | L2-Norm(final)=21.952 | 5979.2 samples/s | 93.4 steps/s
[Step=86950 Epoch=424.3] | Loss=0.00433 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.516 | L2-Norm(final)=21.955 | 2149.7 samples/s | 33.6 steps/s
[Step=87000 Epoch=424.5] | Loss=0.00411 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.518 | L2-Norm(final)=21.958 | 4490.8 samples/s | 70.2 steps/s
[Step=87050 Epoch=424.8] | Loss=0.00394 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.519 | L2-Norm(final)=21.961 | 4415.1 samples/s | 69.0 steps/s
[Step=87100 Epoch=425.0] | Loss=0.00381 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=21.964 | 5610.9 samples/s | 87.7 steps/s
[Step=87150 Epoch=425.3] | Loss=0.00377 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.521 | L2-Norm(final)=21.967 | 2215.1 samples/s | 34.6 steps/s
[Step=87200 Epoch=425.5] | Loss=0.00365 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.522 | L2-Norm(final)=21.970 | 4382.1 samples/s | 68.5 steps/s
[Step=87250 Epoch=425.7] | Loss=0.00356 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.523 | L2-Norm(final)=21.973 | 4507.8 samples/s | 70.4 steps/s
[Step=87300 Epoch=426.0] | Loss=0.00349 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.524 | L2-Norm(final)=21.976 | 5182.8 samples/s | 81.0 steps/s
[Step=87350 Epoch=426.2] | Loss=0.00339 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=21.978 | 2313.4 samples/s | 36.1 steps/s
[Step=87400 Epoch=426.5] | Loss=0.00331 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.526 | L2-Norm(final)=21.981 | 4342.6 samples/s | 67.9 steps/s
[Step=87450 Epoch=426.7] | Loss=0.00322 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.527 | L2-Norm(final)=21.983 | 4509.4 samples/s | 70.5 steps/s
[Step=87500 Epoch=427.0] | Loss=0.00318 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.527 | L2-Norm(final)=21.986 | 4858.0 samples/s | 75.9 steps/s
[Step=87550 Epoch=427.2] | Loss=0.00314 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.528 | L2-Norm(final)=21.989 | 2322.6 samples/s | 36.3 steps/s
[Step=87600 Epoch=427.4] | Loss=0.00308 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.528 | L2-Norm(final)=21.991 | 4471.1 samples/s | 69.9 steps/s
[Step=87650 Epoch=427.7] | Loss=0.00302 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=21.994 | 4489.1 samples/s | 70.1 steps/s
[Step=87700 Epoch=427.9] | Loss=0.00300 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.529 | L2-Norm(final)=21.996 | 4530.0 samples/s | 70.8 steps/s
[Step=87750 Epoch=428.2] | Loss=0.00295 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=21.998 | 2421.3 samples/s | 37.8 steps/s
[Step=87800 Epoch=428.4] | Loss=0.00289 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=22.001 | 4502.1 samples/s | 70.3 steps/s
[Step=87850 Epoch=428.7] | Loss=0.00291 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=22.003 | 4478.1 samples/s | 70.0 steps/s
[Step=87900 Epoch=428.9] | Loss=0.00285 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=22.006 | 4370.6 samples/s | 68.3 steps/s
[Step=87950 Epoch=429.2] | Loss=0.00281 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=22.008 | 2436.4 samples/s | 38.1 steps/s
[Step=88000 Epoch=429.4] | Loss=0.00279 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=22.010 | 4479.5 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step88000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=419.0] | Loss=0.00353 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=21.830 | 4940.4 samples/s | 77.2 steps/s
[Step=86050 Epoch=419.3] | Loss=0.00750 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.247 | L2-Norm(final)=21.836 | 4571.4 samples/s | 71.4 steps/s
[Step=86100 Epoch=419.5] | Loss=0.00662 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=21.843 | 5051.1 samples/s | 78.9 steps/s
[Step=86150 Epoch=419.8] | Loss=0.00610 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=21.850 | 5050.9 samples/s | 78.9 steps/s
[Step=86200 Epoch=420.0] | Loss=0.00614 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.257 | L2-Norm(final)=21.856 | 7813.6 samples/s | 122.1 steps/s
[Step=86250 Epoch=420.3] | Loss=0.00605 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=21.862 | 2174.1 samples/s | 34.0 steps/s
[Step=86300 Epoch=420.5] | Loss=0.00603 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=21.868 | 5110.0 samples/s | 79.8 steps/s
[Step=86350 Epoch=420.7] | Loss=0.00587 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=21.874 | 5029.7 samples/s | 78.6 steps/s
[Step=86400 Epoch=421.0] | Loss=0.00571 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=21.880 | 6850.9 samples/s | 107.0 steps/s
[Step=86450 Epoch=421.2] | Loss=0.00569 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=21.886 | 2283.2 samples/s | 35.7 steps/s
[Step=86500 Epoch=421.5] | Loss=0.00560 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.271 | L2-Norm(final)=21.891 | 5150.0 samples/s | 80.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=421.5] | Loss=0.00125 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.292 | L2-Norm(final)=21.947 | 5444.3 samples/s | 85.1 steps/s
[Step=86550 Epoch=421.7] | Loss=0.00573 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=21.952 | 3879.7 samples/s | 60.6 steps/s
[Step=86600 Epoch=422.0] | Loss=0.00570 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.300 | L2-Norm(final)=21.957 | 4502.8 samples/s | 70.4 steps/s
[Step=86650 Epoch=422.2] | Loss=0.00584 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=21.961 | 4466.5 samples/s | 69.8 steps/s
[Step=86700 Epoch=422.4] | Loss=0.00587 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.307 | L2-Norm(final)=21.965 | 6549.8 samples/s | 102.3 steps/s
[Step=86750 Epoch=422.7] | Loss=0.00546 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=21.969 | 2100.7 samples/s | 32.8 steps/s
[Step=86800 Epoch=422.9] | Loss=0.00511 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.313 | L2-Norm(final)=21.973 | 4476.6 samples/s | 69.9 steps/s
[Step=86850 Epoch=423.2] | Loss=0.00524 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.315 | L2-Norm(final)=21.976 | 4561.9 samples/s | 71.3 steps/s
[Step=86900 Epoch=423.4] | Loss=0.00504 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=21.979 | 5746.8 samples/s | 89.8 steps/s
[Step=86950 Epoch=423.7] | Loss=0.00486 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=21.983 | 2143.1 samples/s | 33.5 steps/s
[Step=87000 Epoch=423.9] | Loss=0.00463 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.320 | L2-Norm(final)=21.985 | 4464.4 samples/s | 69.8 steps/s
[Step=87050 Epoch=424.1] | Loss=0.00467 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=21.988 | 4472.3 samples/s | 69.9 steps/s
[Step=87100 Epoch=424.4] | Loss=0.00453 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.323 | L2-Norm(final)=21.991 | 5413.1 samples/s | 84.6 steps/s
[Step=87150 Epoch=424.6] | Loss=0.00433 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=21.994 | 2272.6 samples/s | 35.5 steps/s
[Step=87200 Epoch=424.9] | Loss=0.00422 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=21.996 | 4530.6 samples/s | 70.8 steps/s
[Step=87250 Epoch=425.1] | Loss=0.00409 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=21.999 | 4371.8 samples/s | 68.3 steps/s
[Step=87300 Epoch=425.4] | Loss=0.00404 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=22.001 | 4950.4 samples/s | 77.4 steps/s
[Step=87350 Epoch=425.6] | Loss=0.00398 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=22.004 | 2343.4 samples/s | 36.6 steps/s
[Step=87400 Epoch=425.9] | Loss=0.00389 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=22.006 | 4504.5 samples/s | 70.4 steps/s
[Step=87450 Epoch=426.1] | Loss=0.00384 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=22.009 | 4546.2 samples/s | 71.0 steps/s
[Step=87500 Epoch=426.3] | Loss=0.00376 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=22.011 | 4533.8 samples/s | 70.8 steps/s
[Step=87550 Epoch=426.6] | Loss=0.00367 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=22.013 | 2441.0 samples/s | 38.1 steps/s
[Step=87600 Epoch=426.8] | Loss=0.00363 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=22.016 | 4412.2 samples/s | 68.9 steps/s
[Step=87650 Epoch=427.1] | Loss=0.00355 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=22.018 | 4474.0 samples/s | 69.9 steps/s
[Step=87700 Epoch=427.3] | Loss=0.00349 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=22.020 | 4458.7 samples/s | 69.7 steps/s
[Step=87750 Epoch=427.6] | Loss=0.00344 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=22.022 | 2471.6 samples/s | 38.6 steps/s
[Step=87800 Epoch=427.8] | Loss=0.00340 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=22.025 | 4474.0 samples/s | 69.9 steps/s
[Step=87850 Epoch=428.0] | Loss=0.00334 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=22.027 | 4573.4 samples/s | 71.5 steps/s
[Step=87900 Epoch=428.3] | Loss=0.00330 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=22.029 | 4396.4 samples/s | 68.7 steps/s
[Step=87950 Epoch=428.5] | Loss=0.00326 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=22.031 | 2434.4 samples/s | 38.0 steps/s
[Step=88000 Epoch=428.8] | Loss=0.00322 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=22.034 | 4462.8 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step88000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=419.4] | Loss=0.00228 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=21.875 | 5089.3 samples/s | 79.5 steps/s
[Step=86050 Epoch=419.6] | Loss=0.00772 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=21.881 | 4569.8 samples/s | 71.4 steps/s
[Step=86100 Epoch=419.9] | Loss=0.00763 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=21.888 | 5043.3 samples/s | 78.8 steps/s
[Step=86150 Epoch=420.1] | Loss=0.00684 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=21.895 | 5064.9 samples/s | 79.1 steps/s
[Step=86200 Epoch=420.4] | Loss=0.00653 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=21.902 | 7780.7 samples/s | 121.6 steps/s
[Step=86250 Epoch=420.6] | Loss=0.00625 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=21.908 | 2207.2 samples/s | 34.5 steps/s
[Step=86300 Epoch=420.8] | Loss=0.00614 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=21.915 | 4929.3 samples/s | 77.0 steps/s
[Step=86350 Epoch=421.1] | Loss=0.00607 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=21.921 | 5043.1 samples/s | 78.8 steps/s
[Step=86400 Epoch=421.3] | Loss=0.00590 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=21.926 | 7012.6 samples/s | 109.6 steps/s
[Step=86450 Epoch=421.6] | Loss=0.00582 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.949 | L2-Norm(final)=21.932 | 2293.4 samples/s | 35.8 steps/s
[Step=86500 Epoch=421.8] | Loss=0.00573 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=21.938 | 5059.7 samples/s | 79.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=421.8] | Loss=0.01257 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=21.993 | 5492.3 samples/s | 85.8 steps/s
[Step=86550 Epoch=422.1] | Loss=0.00699 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=21.998 | 3955.2 samples/s | 61.8 steps/s
[Step=86600 Epoch=422.3] | Loss=0.00608 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=22.003 | 4502.6 samples/s | 70.4 steps/s
[Step=86650 Epoch=422.6] | Loss=0.00551 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=22.007 | 4382.2 samples/s | 68.5 steps/s
[Step=86700 Epoch=422.8] | Loss=0.00541 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.987 | L2-Norm(final)=22.011 | 6564.0 samples/s | 102.6 steps/s
[Step=86750 Epoch=423.0] | Loss=0.00503 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=22.015 | 2103.8 samples/s | 32.9 steps/s
[Step=86800 Epoch=423.3] | Loss=0.00461 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.993 | L2-Norm(final)=22.019 | 4487.5 samples/s | 70.1 steps/s
[Step=86850 Epoch=423.5] | Loss=0.00439 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=22.022 | 4547.0 samples/s | 71.0 steps/s
[Step=86900 Epoch=423.8] | Loss=0.00419 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.997 | L2-Norm(final)=22.025 | 5846.2 samples/s | 91.3 steps/s
[Step=86950 Epoch=424.0] | Loss=0.00400 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=22.028 | 2143.6 samples/s | 33.5 steps/s
[Step=87000 Epoch=424.3] | Loss=0.00388 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=22.031 | 4530.4 samples/s | 70.8 steps/s
[Step=87050 Epoch=424.5] | Loss=0.00370 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=22.034 | 4390.5 samples/s | 68.6 steps/s
[Step=87100 Epoch=424.7] | Loss=0.00359 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=22.036 | 5357.3 samples/s | 83.7 steps/s
[Step=87150 Epoch=425.0] | Loss=0.00352 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=22.039 | 2297.8 samples/s | 35.9 steps/s
[Step=87200 Epoch=425.2] | Loss=0.00345 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=22.042 | 4338.4 samples/s | 67.8 steps/s
[Step=87250 Epoch=425.5] | Loss=0.00334 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=22.044 | 4508.5 samples/s | 70.4 steps/s
[Step=87300 Epoch=425.7] | Loss=0.00327 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=22.047 | 4950.4 samples/s | 77.4 steps/s
[Step=87350 Epoch=426.0] | Loss=0.00315 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=22.049 | 2311.2 samples/s | 36.1 steps/s
[Step=87400 Epoch=426.2] | Loss=0.00308 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=22.052 | 4487.5 samples/s | 70.1 steps/s
[Step=87450 Epoch=426.5] | Loss=0.00302 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=22.054 | 4503.4 samples/s | 70.4 steps/s
[Step=87500 Epoch=426.7] | Loss=0.00299 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=22.056 | 4578.0 samples/s | 71.5 steps/s
[Step=87550 Epoch=426.9] | Loss=0.00293 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=22.059 | 2426.4 samples/s | 37.9 steps/s
[Step=87600 Epoch=427.2] | Loss=0.00286 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=22.061 | 4439.7 samples/s | 69.4 steps/s
[Step=87650 Epoch=427.4] | Loss=0.00285 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.012 | L2-Norm(final)=22.063 | 4503.6 samples/s | 70.4 steps/s
[Step=87700 Epoch=427.7] | Loss=0.00285 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.065 | 4462.5 samples/s | 69.7 steps/s
[Step=87750 Epoch=427.9] | Loss=0.00280 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.067 | 2405.9 samples/s | 37.6 steps/s
[Step=87800 Epoch=428.2] | Loss=0.00275 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=22.070 | 4493.3 samples/s | 70.2 steps/s
[Step=87850 Epoch=428.4] | Loss=0.00272 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=22.072 | 4469.9 samples/s | 69.8 steps/s
[Step=87900 Epoch=428.6] | Loss=0.00269 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=22.074 | 4468.9 samples/s | 69.8 steps/s
[Step=87950 Epoch=428.9] | Loss=0.00265 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=22.076 | 2465.5 samples/s | 38.5 steps/s
[Step=88000 Epoch=429.1] | Loss=0.00263 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=22.078 | 4464.0 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step88000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=421.7] | Loss=0.00597 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.575 | L2-Norm(final)=21.964 | 5014.3 samples/s | 78.3 steps/s
[Step=86050 Epoch=422.0] | Loss=0.00558 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=21.970 | 4694.8 samples/s | 73.4 steps/s
[Step=86100 Epoch=422.2] | Loss=0.00507 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.582 | L2-Norm(final)=21.977 | 4988.8 samples/s | 78.0 steps/s
[Step=86150 Epoch=422.5] | Loss=0.00522 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=21.984 | 5121.2 samples/s | 80.0 steps/s
[Step=86200 Epoch=422.7] | Loss=0.00514 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.588 | L2-Norm(final)=21.991 | 7909.1 samples/s | 123.6 steps/s
[Step=86250 Epoch=423.0] | Loss=0.00500 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=21.997 | 2205.5 samples/s | 34.5 steps/s
[Step=86300 Epoch=423.2] | Loss=0.00498 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=22.004 | 5125.5 samples/s | 80.1 steps/s
[Step=86350 Epoch=423.4] | Loss=0.00495 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=22.010 | 4940.3 samples/s | 77.2 steps/s
[Step=86400 Epoch=423.7] | Loss=0.00490 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=22.016 | 7340.9 samples/s | 114.7 steps/s
[Step=86450 Epoch=423.9] | Loss=0.00481 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=22.022 | 2211.7 samples/s | 34.6 steps/s
[Step=86500 Epoch=424.2] | Loss=0.00475 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.602 | L2-Norm(final)=22.028 | 5035.4 samples/s | 78.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=424.2] | Loss=0.00338 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=22.087 | 5624.9 samples/s | 87.9 steps/s
[Step=86550 Epoch=424.4] | Loss=0.00531 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=22.092 | 3973.6 samples/s | 62.1 steps/s
[Step=86600 Epoch=424.7] | Loss=0.00591 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=22.097 | 4465.0 samples/s | 69.8 steps/s
[Step=86650 Epoch=424.9] | Loss=0.00551 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.636 | L2-Norm(final)=22.101 | 4486.7 samples/s | 70.1 steps/s
[Step=86700 Epoch=425.2] | Loss=0.00562 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.640 | L2-Norm(final)=22.106 | 6677.9 samples/s | 104.3 steps/s
[Step=86750 Epoch=425.4] | Loss=0.00529 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.643 | L2-Norm(final)=22.110 | 2070.6 samples/s | 32.4 steps/s
[Step=86800 Epoch=425.7] | Loss=0.00484 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=22.113 | 4500.0 samples/s | 70.3 steps/s
[Step=86850 Epoch=425.9] | Loss=0.00461 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=22.117 | 4459.3 samples/s | 69.7 steps/s
[Step=86900 Epoch=426.1] | Loss=0.00427 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=22.120 | 6275.8 samples/s | 98.1 steps/s
[Step=86950 Epoch=426.4] | Loss=0.00421 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=22.123 | 2139.7 samples/s | 33.4 steps/s
[Step=87000 Epoch=426.6] | Loss=0.00401 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.653 | L2-Norm(final)=22.126 | 4477.0 samples/s | 70.0 steps/s
[Step=87050 Epoch=426.9] | Loss=0.00391 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=22.129 | 4510.3 samples/s | 70.5 steps/s
[Step=87100 Epoch=427.1] | Loss=0.00375 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=22.132 | 5665.5 samples/s | 88.5 steps/s
[Step=87150 Epoch=427.4] | Loss=0.00360 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.656 | L2-Norm(final)=22.135 | 2164.9 samples/s | 33.8 steps/s
[Step=87200 Epoch=427.6] | Loss=0.00352 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=22.138 | 4474.2 samples/s | 69.9 steps/s
[Step=87250 Epoch=427.9] | Loss=0.00342 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.658 | L2-Norm(final)=22.140 | 4487.8 samples/s | 70.1 steps/s
[Step=87300 Epoch=428.1] | Loss=0.00330 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=22.143 | 5526.5 samples/s | 86.4 steps/s
[Step=87350 Epoch=428.4] | Loss=0.00320 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=22.146 | 2234.4 samples/s | 34.9 steps/s
[Step=87400 Epoch=428.6] | Loss=0.00312 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=22.148 | 4399.2 samples/s | 68.7 steps/s
[Step=87450 Epoch=428.8] | Loss=0.00308 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=22.151 | 4418.0 samples/s | 69.0 steps/s
[Step=87500 Epoch=429.1] | Loss=0.00302 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=22.153 | 5200.7 samples/s | 81.3 steps/s
[Step=87550 Epoch=429.3] | Loss=0.00296 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=22.155 | 2304.6 samples/s | 36.0 steps/s
[Step=87600 Epoch=429.6] | Loss=0.00291 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=22.158 | 4355.2 samples/s | 68.1 steps/s
[Step=87650 Epoch=429.8] | Loss=0.00284 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=22.160 | 4511.4 samples/s | 70.5 steps/s
[Step=87700 Epoch=430.1] | Loss=0.00280 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=22.163 | 4912.7 samples/s | 76.8 steps/s
[Step=87750 Epoch=430.3] | Loss=0.00278 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=22.165 | 2325.7 samples/s | 36.3 steps/s
[Step=87800 Epoch=430.6] | Loss=0.00275 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=22.167 | 4429.0 samples/s | 69.2 steps/s
[Step=87850 Epoch=430.8] | Loss=0.00270 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=22.170 | 4477.7 samples/s | 70.0 steps/s
[Step=87900 Epoch=431.0] | Loss=0.00265 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=22.172 | 4698.1 samples/s | 73.4 steps/s
[Step=87950 Epoch=431.3] | Loss=0.00261 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=22.174 | 2413.5 samples/s | 37.7 steps/s
[Step=88000 Epoch=431.5] | Loss=0.00258 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=22.176 | 4463.7 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step88000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=814.9] | Loss=0.00008 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.620 | L2-Norm(final)=10.913 | 5144.0 samples/s | 80.4 steps/s
[Step=86050 Epoch=815.4] | Loss=0.00007 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.624 | L2-Norm(final)=10.924 | 4043.9 samples/s | 63.2 steps/s
[Step=86100 Epoch=815.9] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.630 | L2-Norm(final)=10.935 | 7258.1 samples/s | 113.4 steps/s
[Step=86150 Epoch=816.3] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.635 | L2-Norm(final)=10.943 | 2110.9 samples/s | 33.0 steps/s
[Step=86200 Epoch=816.8] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.638 | L2-Norm(final)=10.950 | 6649.6 samples/s | 103.9 steps/s
[Step=86250 Epoch=817.3] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.641 | L2-Norm(final)=10.956 | 2247.3 samples/s | 35.1 steps/s
[Step=86300 Epoch=817.8] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.644 | L2-Norm(final)=10.962 | 5830.7 samples/s | 91.1 steps/s
[Step=86350 Epoch=818.2] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.647 | L2-Norm(final)=10.968 | 2311.7 samples/s | 36.1 steps/s
[Step=86400 Epoch=818.7] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.649 | L2-Norm(final)=10.973 | 5300.7 samples/s | 82.8 steps/s
[Step=86450 Epoch=819.2] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.651 | L2-Norm(final)=10.978 | 2390.7 samples/s | 37.4 steps/s
[Step=86500 Epoch=819.7] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.653 | L2-Norm(final)=10.983 | 4808.0 samples/s | 75.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=819.7] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.673 | L2-Norm(final)=11.031 | 5245.3 samples/s | 82.0 steps/s
[Step=86550 Epoch=820.1] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.676 | L2-Norm(final)=11.036 | 3808.0 samples/s | 59.5 steps/s
[Step=86600 Epoch=820.6] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.677 | L2-Norm(final)=11.039 | 6317.1 samples/s | 98.7 steps/s
[Step=86650 Epoch=821.1] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.674 | L2-Norm(final)=11.042 | 2019.9 samples/s | 31.6 steps/s
[Step=86700 Epoch=821.6] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=11.044 | 5565.3 samples/s | 87.0 steps/s
[Step=86750 Epoch=822.0] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.663 | L2-Norm(final)=11.045 | 2089.6 samples/s | 32.6 steps/s
[Step=86800 Epoch=822.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.656 | L2-Norm(final)=11.046 | 5161.3 samples/s | 80.6 steps/s
[Step=86850 Epoch=823.0] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.649 | L2-Norm(final)=11.047 | 2177.6 samples/s | 34.0 steps/s
[Step=86900 Epoch=823.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.642 | L2-Norm(final)=11.047 | 4731.9 samples/s | 73.9 steps/s
[Step=86950 Epoch=823.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.634 | L2-Norm(final)=11.048 | 2268.6 samples/s | 35.4 steps/s
[Step=87000 Epoch=824.4] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.626 | L2-Norm(final)=11.049 | 4268.2 samples/s | 66.7 steps/s
[Step=87050 Epoch=824.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.618 | L2-Norm(final)=11.049 | 2366.3 samples/s | 37.0 steps/s
[Step=87100 Epoch=825.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.610 | L2-Norm(final)=11.050 | 4218.5 samples/s | 65.9 steps/s
[Step=87150 Epoch=825.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.601 | L2-Norm(final)=11.050 | 2424.8 samples/s | 37.9 steps/s
[Step=87200 Epoch=826.3] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.593 | L2-Norm(final)=11.051 | 4282.5 samples/s | 66.9 steps/s
[Step=87250 Epoch=826.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.584 | L2-Norm(final)=11.052 | 2350.0 samples/s | 36.7 steps/s
[Step=87300 Epoch=827.2] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.576 | L2-Norm(final)=11.052 | 4182.0 samples/s | 65.3 steps/s
[Step=87350 Epoch=827.7] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.567 | L2-Norm(final)=11.053 | 2550.9 samples/s | 39.9 steps/s
[Step=87400 Epoch=828.2] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.558 | L2-Norm(final)=11.053 | 3872.7 samples/s | 60.5 steps/s
[Step=87450 Epoch=828.7] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.549 | L2-Norm(final)=11.054 | 6572.2 samples/s | 102.7 steps/s
[Step=87500 Epoch=829.1] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.540 | L2-Norm(final)=11.054 | 2005.2 samples/s | 31.3 steps/s
[Step=87550 Epoch=829.6] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.530 | L2-Norm(final)=11.055 | 5879.8 samples/s | 91.9 steps/s
[Step=87600 Epoch=830.1] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.521 | L2-Norm(final)=11.056 | 2051.8 samples/s | 32.1 steps/s
[Step=87650 Epoch=830.6] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.512 | L2-Norm(final)=11.056 | 5229.3 samples/s | 81.7 steps/s
[Step=87700 Epoch=831.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.502 | L2-Norm(final)=11.057 | 2154.2 samples/s | 33.7 steps/s
[Step=87750 Epoch=831.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.493 | L2-Norm(final)=11.058 | 4840.6 samples/s | 75.6 steps/s
[Step=87800 Epoch=832.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.483 | L2-Norm(final)=11.058 | 2256.0 samples/s | 35.3 steps/s
[Step=87850 Epoch=832.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.473 | L2-Norm(final)=11.059 | 4428.3 samples/s | 69.2 steps/s
[Step=87900 Epoch=832.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.463 | L2-Norm(final)=11.060 | 2265.0 samples/s | 35.4 steps/s
[Step=87950 Epoch=833.4] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.453 | L2-Norm(final)=11.060 | 4255.4 samples/s | 66.5 steps/s
[Step=88000 Epoch=833.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.443 | L2-Norm(final)=11.061 | 2371.5 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step88000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=818.1] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.596 | L2-Norm(final)=12.084 | 5162.2 samples/s | 80.7 steps/s
[Step=86050 Epoch=818.5] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.598 | L2-Norm(final)=12.099 | 4331.2 samples/s | 67.7 steps/s
[Step=86100 Epoch=819.0] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.605 | L2-Norm(final)=12.112 | 7574.5 samples/s | 118.4 steps/s
[Step=86150 Epoch=819.5] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.609 | L2-Norm(final)=12.122 | 2115.3 samples/s | 33.1 steps/s
[Step=86200 Epoch=820.0] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.613 | L2-Norm(final)=12.130 | 6579.2 samples/s | 102.8 steps/s
[Step=86250 Epoch=820.5] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.616 | L2-Norm(final)=12.138 | 2208.4 samples/s | 34.5 steps/s
[Step=86300 Epoch=820.9] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.618 | L2-Norm(final)=12.145 | 5988.4 samples/s | 93.6 steps/s
[Step=86350 Epoch=821.4] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.621 | L2-Norm(final)=12.151 | 2319.3 samples/s | 36.2 steps/s
[Step=86400 Epoch=821.9] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.623 | L2-Norm(final)=12.157 | 5437.0 samples/s | 85.0 steps/s
[Step=86450 Epoch=822.4] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.625 | L2-Norm(final)=12.163 | 2425.6 samples/s | 37.9 steps/s
[Step=86500 Epoch=822.8] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.626 | L2-Norm(final)=12.168 | 4812.4 samples/s | 75.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=822.8] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.643 | L2-Norm(final)=12.221 | 5018.6 samples/s | 78.4 steps/s
[Step=86550 Epoch=823.3] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.643 | L2-Norm(final)=12.227 | 3861.7 samples/s | 60.3 steps/s
[Step=86600 Epoch=823.8] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.641 | L2-Norm(final)=12.231 | 6377.0 samples/s | 99.6 steps/s
[Step=86650 Epoch=824.3] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.635 | L2-Norm(final)=12.233 | 2042.4 samples/s | 31.9 steps/s
[Step=86700 Epoch=824.7] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.628 | L2-Norm(final)=12.235 | 5681.4 samples/s | 88.8 steps/s
[Step=86750 Epoch=825.2] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.620 | L2-Norm(final)=12.237 | 2059.2 samples/s | 32.2 steps/s
[Step=86800 Epoch=825.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.612 | L2-Norm(final)=12.238 | 5188.8 samples/s | 81.1 steps/s
[Step=86850 Epoch=826.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.603 | L2-Norm(final)=12.239 | 2184.4 samples/s | 34.1 steps/s
[Step=86900 Epoch=826.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.593 | L2-Norm(final)=12.240 | 4760.2 samples/s | 74.4 steps/s
[Step=86950 Epoch=827.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.584 | L2-Norm(final)=12.241 | 2258.9 samples/s | 35.3 steps/s
[Step=87000 Epoch=827.6] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.574 | L2-Norm(final)=12.242 | 4343.6 samples/s | 67.9 steps/s
[Step=87050 Epoch=828.1] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.564 | L2-Norm(final)=12.243 | 2325.6 samples/s | 36.3 steps/s
[Step=87100 Epoch=828.5] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.554 | L2-Norm(final)=12.243 | 4235.0 samples/s | 66.2 steps/s
[Step=87150 Epoch=829.0] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=12.244 | 2410.2 samples/s | 37.7 steps/s
[Step=87200 Epoch=829.5] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=12.245 | 4314.9 samples/s | 67.4 steps/s
[Step=87250 Epoch=830.0] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=12.246 | 2335.5 samples/s | 36.5 steps/s
[Step=87300 Epoch=830.4] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.513 | L2-Norm(final)=12.247 | 4208.4 samples/s | 65.8 steps/s
[Step=87350 Epoch=830.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=12.247 | 2499.7 samples/s | 39.1 steps/s
[Step=87400 Epoch=831.4] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.492 | L2-Norm(final)=12.248 | 3991.9 samples/s | 62.4 steps/s
[Step=87450 Epoch=831.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.482 | L2-Norm(final)=12.249 | 6628.9 samples/s | 103.6 steps/s
[Step=87500 Epoch=832.3] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.471 | L2-Norm(final)=12.250 | 1985.0 samples/s | 31.0 steps/s
[Step=87550 Epoch=832.8] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.460 | L2-Norm(final)=12.251 | 5891.4 samples/s | 92.1 steps/s
[Step=87600 Epoch=833.3] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.449 | L2-Norm(final)=12.252 | 2042.8 samples/s | 31.9 steps/s
[Step=87650 Epoch=833.8] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.438 | L2-Norm(final)=12.253 | 5370.0 samples/s | 83.9 steps/s
[Step=87700 Epoch=834.2] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.427 | L2-Norm(final)=12.254 | 2150.1 samples/s | 33.6 steps/s
[Step=87750 Epoch=834.7] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.415 | L2-Norm(final)=12.255 | 4850.2 samples/s | 75.8 steps/s
[Step=87800 Epoch=835.2] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.404 | L2-Norm(final)=12.256 | 2242.4 samples/s | 35.0 steps/s
[Step=87850 Epoch=835.7] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.393 | L2-Norm(final)=12.257 | 4450.2 samples/s | 69.5 steps/s
[Step=87900 Epoch=836.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.381 | L2-Norm(final)=12.258 | 2327.5 samples/s | 36.4 steps/s
[Step=87950 Epoch=836.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.259 | 4216.3 samples/s | 65.9 steps/s
[Step=88000 Epoch=837.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.358 | L2-Norm(final)=12.260 | 2454.9 samples/s | 38.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step88000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=821.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.579 | L2-Norm(final)=11.565 | 5067.7 samples/s | 79.2 steps/s
[Step=86050 Epoch=821.7] | Loss=0.00009 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.583 | L2-Norm(final)=11.578 | 4277.2 samples/s | 66.8 steps/s
[Step=86100 Epoch=822.2] | Loss=0.00011 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.589 | L2-Norm(final)=11.587 | 7578.0 samples/s | 118.4 steps/s
[Step=86150 Epoch=822.7] | Loss=0.00009 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.593 | L2-Norm(final)=11.593 | 2097.7 samples/s | 32.8 steps/s
[Step=86200 Epoch=823.2] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.596 | L2-Norm(final)=11.597 | 6804.2 samples/s | 106.3 steps/s
[Step=86250 Epoch=823.6] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.598 | L2-Norm(final)=11.600 | 2205.5 samples/s | 34.5 steps/s
[Step=86300 Epoch=824.1] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.599 | L2-Norm(final)=11.603 | 6134.2 samples/s | 95.8 steps/s
[Step=86350 Epoch=824.6] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.600 | L2-Norm(final)=11.606 | 2280.9 samples/s | 35.6 steps/s
[Step=86400 Epoch=825.1] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.602 | L2-Norm(final)=11.608 | 5710.7 samples/s | 89.2 steps/s
[Step=86450 Epoch=825.5] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.603 | L2-Norm(final)=11.610 | 2342.9 samples/s | 36.6 steps/s
[Step=86500 Epoch=826.0] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.604 | L2-Norm(final)=11.613 | 5195.5 samples/s | 81.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=826.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.614 | L2-Norm(final)=11.635 | 5568.7 samples/s | 87.0 steps/s
[Step=86550 Epoch=826.5] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.619 | L2-Norm(final)=11.638 | 3797.5 samples/s | 59.3 steps/s
[Step=86600 Epoch=827.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.621 | L2-Norm(final)=11.640 | 6412.1 samples/s | 100.2 steps/s
[Step=86650 Epoch=827.5] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.620 | L2-Norm(final)=11.641 | 2042.6 samples/s | 31.9 steps/s
[Step=86700 Epoch=827.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.616 | L2-Norm(final)=11.642 | 5650.6 samples/s | 88.3 steps/s
[Step=86750 Epoch=828.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.611 | L2-Norm(final)=11.642 | 2048.8 samples/s | 32.0 steps/s
[Step=86800 Epoch=828.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.606 | L2-Norm(final)=11.643 | 5395.7 samples/s | 84.3 steps/s
[Step=86850 Epoch=829.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.600 | L2-Norm(final)=11.643 | 2143.0 samples/s | 33.5 steps/s
[Step=86900 Epoch=829.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.594 | L2-Norm(final)=11.644 | 5001.3 samples/s | 78.1 steps/s
[Step=86950 Epoch=830.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.587 | L2-Norm(final)=11.644 | 2252.9 samples/s | 35.2 steps/s
[Step=87000 Epoch=830.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.581 | L2-Norm(final)=11.644 | 4467.1 samples/s | 69.8 steps/s
[Step=87050 Epoch=831.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.574 | L2-Norm(final)=11.644 | 2255.4 samples/s | 35.2 steps/s
[Step=87100 Epoch=831.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.567 | L2-Norm(final)=11.645 | 4353.8 samples/s | 68.0 steps/s
[Step=87150 Epoch=832.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.561 | L2-Norm(final)=11.645 | 2360.3 samples/s | 36.9 steps/s
[Step=87200 Epoch=832.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.553 | L2-Norm(final)=11.645 | 4298.6 samples/s | 67.2 steps/s
[Step=87250 Epoch=833.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.546 | L2-Norm(final)=11.646 | 2397.4 samples/s | 37.5 steps/s
[Step=87300 Epoch=833.7] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.539 | L2-Norm(final)=11.646 | 4280.6 samples/s | 66.9 steps/s
[Step=87350 Epoch=834.1] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.532 | L2-Norm(final)=11.646 | 2346.3 samples/s | 36.7 steps/s
[Step=87400 Epoch=834.6] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=11.646 | 4325.3 samples/s | 67.6 steps/s
[Step=87450 Epoch=835.1] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.516 | L2-Norm(final)=11.647 | 2415.2 samples/s | 37.7 steps/s
[Step=87500 Epoch=835.6] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=11.647 | 4118.3 samples/s | 64.3 steps/s
[Step=87550 Epoch=836.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=11.647 | 6949.2 samples/s | 108.6 steps/s
[Step=87600 Epoch=836.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.493 | L2-Norm(final)=11.647 | 1966.6 samples/s | 30.7 steps/s
[Step=87650 Epoch=837.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.485 | L2-Norm(final)=11.648 | 6119.3 samples/s | 95.6 steps/s
[Step=87700 Epoch=837.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.477 | L2-Norm(final)=11.648 | 1987.8 samples/s | 31.1 steps/s
[Step=87750 Epoch=838.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.469 | L2-Norm(final)=11.648 | 5644.9 samples/s | 88.2 steps/s
[Step=87800 Epoch=838.4] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.461 | L2-Norm(final)=11.648 | 2061.5 samples/s | 32.2 steps/s
[Step=87850 Epoch=838.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.452 | L2-Norm(final)=11.649 | 5366.2 samples/s | 83.8 steps/s
[Step=87900 Epoch=839.4] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.444 | L2-Norm(final)=11.649 | 2136.0 samples/s | 33.4 steps/s
[Step=87950 Epoch=839.9] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.435 | L2-Norm(final)=11.649 | 4882.7 samples/s | 76.3 steps/s
[Step=88000 Epoch=840.3] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.427 | L2-Norm(final)=11.650 | 2204.4 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step88000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=810.4] | Loss=0.00079 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.808 | L2-Norm(final)=11.265 | 5160.3 samples/s | 80.6 steps/s
[Step=86050 Epoch=810.8] | Loss=0.00010 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.813 | L2-Norm(final)=11.273 | 4163.8 samples/s | 65.1 steps/s
[Step=86100 Epoch=811.3] | Loss=0.00010 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.819 | L2-Norm(final)=11.285 | 7315.4 samples/s | 114.3 steps/s
[Step=86150 Epoch=811.8] | Loss=0.00012 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.824 | L2-Norm(final)=11.294 | 2155.8 samples/s | 33.7 steps/s
[Step=86200 Epoch=812.2] | Loss=0.00011 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.828 | L2-Norm(final)=11.302 | 6307.7 samples/s | 98.6 steps/s
[Step=86250 Epoch=812.7] | Loss=0.00009 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.831 | L2-Norm(final)=11.308 | 2237.6 samples/s | 35.0 steps/s
[Step=86300 Epoch=813.2] | Loss=0.00009 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.833 | L2-Norm(final)=11.312 | 5595.9 samples/s | 87.4 steps/s
[Step=86350 Epoch=813.7] | Loss=0.00008 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.836 | L2-Norm(final)=11.317 | 2375.1 samples/s | 37.1 steps/s
[Step=86400 Epoch=814.1] | Loss=0.00008 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.838 | L2-Norm(final)=11.321 | 4936.2 samples/s | 77.1 steps/s
[Step=86450 Epoch=814.6] | Loss=0.00008 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.840 | L2-Norm(final)=11.325 | 2482.4 samples/s | 38.8 steps/s
[Step=86500 Epoch=815.1] | Loss=0.00007 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.842 | L2-Norm(final)=11.329 | 4799.2 samples/s | 75.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=815.1] | Loss=0.00009 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.859 | L2-Norm(final)=11.365 | 5475.4 samples/s | 85.6 steps/s
[Step=86550 Epoch=815.5] | Loss=0.00024 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=11.370 | 3818.1 samples/s | 59.7 steps/s
[Step=86600 Epoch=816.0] | Loss=0.00020 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=11.375 | 6195.4 samples/s | 96.8 steps/s
[Step=86650 Epoch=816.5] | Loss=0.00015 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.878 | L2-Norm(final)=11.378 | 2034.6 samples/s | 31.8 steps/s
[Step=86700 Epoch=817.0] | Loss=0.00012 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.881 | L2-Norm(final)=11.380 | 5385.3 samples/s | 84.1 steps/s
[Step=86750 Epoch=817.4] | Loss=0.00010 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.381 | 2134.8 samples/s | 33.4 steps/s
[Step=86800 Epoch=817.9] | Loss=0.00008 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.383 | 4849.2 samples/s | 75.8 steps/s
[Step=86850 Epoch=818.4] | Loss=0.00007 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=11.384 | 2235.7 samples/s | 34.9 steps/s
[Step=86900 Epoch=818.8] | Loss=0.00006 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=11.384 | 4458.0 samples/s | 69.7 steps/s
[Step=86950 Epoch=819.3] | Loss=0.00006 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=11.385 | 2320.8 samples/s | 36.3 steps/s
[Step=87000 Epoch=819.8] | Loss=0.00005 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.386 | 4306.0 samples/s | 67.3 steps/s
[Step=87050 Epoch=820.3] | Loss=0.00005 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.387 | 2421.1 samples/s | 37.8 steps/s
[Step=87100 Epoch=820.7] | Loss=0.00005 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.882 | L2-Norm(final)=11.387 | 4177.4 samples/s | 65.3 steps/s
[Step=87150 Epoch=821.2] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.881 | L2-Norm(final)=11.388 | 2380.2 samples/s | 37.2 steps/s
[Step=87200 Epoch=821.7] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.881 | L2-Norm(final)=11.388 | 4238.3 samples/s | 66.2 steps/s
[Step=87250 Epoch=822.1] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.880 | L2-Norm(final)=11.389 | 2640.7 samples/s | 41.3 steps/s
[Step=87300 Epoch=822.6] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.879 | L2-Norm(final)=11.389 | 3664.4 samples/s | 57.3 steps/s
[Step=87350 Epoch=823.1] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.879 | L2-Norm(final)=11.390 | 6369.6 samples/s | 99.5 steps/s
[Step=87400 Epoch=823.6] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.878 | L2-Norm(final)=11.390 | 2019.3 samples/s | 31.6 steps/s
[Step=87450 Epoch=824.0] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.877 | L2-Norm(final)=11.391 | 5614.9 samples/s | 87.7 steps/s
[Step=87500 Epoch=824.5] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.877 | L2-Norm(final)=11.391 | 2116.3 samples/s | 33.1 steps/s
[Step=87550 Epoch=825.0] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.876 | L2-Norm(final)=11.391 | 4996.7 samples/s | 78.1 steps/s
[Step=87600 Epoch=825.4] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=11.392 | 2203.0 samples/s | 34.4 steps/s
[Step=87650 Epoch=825.9] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.392 | 4529.8 samples/s | 70.8 steps/s
[Step=87700 Epoch=826.4] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.873 | L2-Norm(final)=11.393 | 2300.4 samples/s | 35.9 steps/s
[Step=87750 Epoch=826.9] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.872 | L2-Norm(final)=11.393 | 4173.6 samples/s | 65.2 steps/s
[Step=87800 Epoch=827.3] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.871 | L2-Norm(final)=11.393 | 2398.8 samples/s | 37.5 steps/s
[Step=87850 Epoch=827.8] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.870 | L2-Norm(final)=11.394 | 4277.4 samples/s | 66.8 steps/s
[Step=87900 Epoch=828.3] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.869 | L2-Norm(final)=11.394 | 2383.1 samples/s | 37.2 steps/s
[Step=87950 Epoch=828.7] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.868 | L2-Norm(final)=11.394 | 4283.4 samples/s | 66.9 steps/s
[Step=88000 Epoch=829.2] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=11.395 | 2461.1 samples/s | 38.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step88000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=819.7] | Loss=0.00028 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.678 | L2-Norm(final)=12.028 | 5007.0 samples/s | 78.2 steps/s
[Step=86050 Epoch=820.1] | Loss=0.00008 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.684 | L2-Norm(final)=12.044 | 4278.2 samples/s | 66.8 steps/s
[Step=86100 Epoch=820.6] | Loss=0.00007 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.691 | L2-Norm(final)=12.058 | 7156.8 samples/s | 111.8 steps/s
[Step=86150 Epoch=821.1] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.697 | L2-Norm(final)=12.070 | 2107.1 samples/s | 32.9 steps/s
[Step=86200 Epoch=821.6] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.702 | L2-Norm(final)=12.081 | 6900.3 samples/s | 107.8 steps/s
[Step=86250 Epoch=822.0] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.706 | L2-Norm(final)=12.090 | 2156.3 samples/s | 33.7 steps/s
[Step=86300 Epoch=822.5] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.709 | L2-Norm(final)=12.098 | 6167.7 samples/s | 96.4 steps/s
[Step=86350 Epoch=823.0] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.712 | L2-Norm(final)=12.105 | 2272.2 samples/s | 35.5 steps/s
[Step=86400 Epoch=823.5] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.715 | L2-Norm(final)=12.112 | 5671.2 samples/s | 88.6 steps/s
[Step=86450 Epoch=823.9] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.718 | L2-Norm(final)=12.119 | 2337.3 samples/s | 36.5 steps/s
[Step=86500 Epoch=824.4] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.720 | L2-Norm(final)=12.126 | 5123.4 samples/s | 80.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=824.4] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.744 | L2-Norm(final)=12.190 | 5344.3 samples/s | 83.5 steps/s
[Step=86550 Epoch=824.9] | Loss=0.00014 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.751 | L2-Norm(final)=12.198 | 3698.7 samples/s | 57.8 steps/s
[Step=86600 Epoch=825.4] | Loss=0.00035 | Reg=0.00033 | acc=0.9844 | L2-Norm=5.760 | L2-Norm(final)=12.204 | 6343.5 samples/s | 99.1 steps/s
[Step=86650 Epoch=825.9] | Loss=0.00030 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.767 | L2-Norm(final)=12.209 | 2045.6 samples/s | 32.0 steps/s
[Step=86700 Epoch=826.3] | Loss=0.00023 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.772 | L2-Norm(final)=12.212 | 5634.6 samples/s | 88.0 steps/s
[Step=86750 Epoch=826.8] | Loss=0.00020 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.775 | L2-Norm(final)=12.214 | 2060.3 samples/s | 32.2 steps/s
[Step=86800 Epoch=827.3] | Loss=0.00017 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.777 | L2-Norm(final)=12.215 | 5306.1 samples/s | 82.9 steps/s
[Step=86850 Epoch=827.8] | Loss=0.00014 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.778 | L2-Norm(final)=12.216 | 2097.7 samples/s | 32.8 steps/s
[Step=86900 Epoch=828.2] | Loss=0.00013 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=12.217 | 4885.2 samples/s | 76.3 steps/s
[Step=86950 Epoch=828.7] | Loss=0.00011 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.218 | 2223.0 samples/s | 34.7 steps/s
[Step=87000 Epoch=829.2] | Loss=0.00010 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.219 | 4470.0 samples/s | 69.8 steps/s
[Step=87050 Epoch=829.7] | Loss=0.00009 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.219 | 2283.3 samples/s | 35.7 steps/s
[Step=87100 Epoch=830.1] | Loss=0.00009 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.220 | 4278.6 samples/s | 66.9 steps/s
[Step=87150 Epoch=830.6] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.220 | 2351.2 samples/s | 36.7 steps/s
[Step=87200 Epoch=831.1] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.221 | 4204.1 samples/s | 65.7 steps/s
[Step=87250 Epoch=831.6] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.221 | 2423.0 samples/s | 37.9 steps/s
[Step=87300 Epoch=832.0] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.221 | 4158.2 samples/s | 65.0 steps/s
[Step=87350 Epoch=832.5] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.222 | 2390.1 samples/s | 37.3 steps/s
[Step=87400 Epoch=833.0] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.222 | 4149.5 samples/s | 64.8 steps/s
[Step=87450 Epoch=833.5] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.222 | 2355.4 samples/s | 36.8 steps/s
[Step=87500 Epoch=834.0] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.223 | 4313.1 samples/s | 67.4 steps/s
[Step=87550 Epoch=834.4] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.223 | 6898.6 samples/s | 107.8 steps/s
[Step=87600 Epoch=834.9] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=12.223 | 1967.2 samples/s | 30.7 steps/s
[Step=87650 Epoch=835.4] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=12.223 | 6347.5 samples/s | 99.2 steps/s
[Step=87700 Epoch=835.9] | Loss=0.00005 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=12.224 | 1987.4 samples/s | 31.1 steps/s
[Step=87750 Epoch=836.3] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=12.224 | 5792.7 samples/s | 90.5 steps/s
[Step=87800 Epoch=836.8] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.779 | L2-Norm(final)=12.224 | 2076.7 samples/s | 32.4 steps/s
[Step=87850 Epoch=837.3] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.778 | L2-Norm(final)=12.224 | 5387.9 samples/s | 84.2 steps/s
[Step=87900 Epoch=837.8] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.778 | L2-Norm(final)=12.225 | 2080.0 samples/s | 32.5 steps/s
[Step=87950 Epoch=838.2] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.777 | L2-Norm(final)=12.225 | 4909.0 samples/s | 76.7 steps/s
[Step=88000 Epoch=838.7] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.777 | L2-Norm(final)=12.225 | 2192.4 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10489 | acc=0.9549 | tpr=0.9636 | fpr=0.0639 | 4750.1 samples/s | 18.6 steps/s
Avg test loss: 0.10946, Avg test acc: 0.95264, Avg tpr: 0.96200, Avg fpr: 0.06794, total FA: 530

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10732 | acc=0.9555 | tpr=0.9692 | fpr=0.0743 | 4971.4 samples/s | 19.4 steps/s
Avg test loss: 0.10707, Avg test acc: 0.95621, Avg tpr: 0.96975, Avg fpr: 0.07358, total FA: 574

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10336 | acc=0.9566 | tpr=0.9727 | fpr=0.0783 | 4864.2 samples/s | 19.0 steps/s
Avg test loss: 0.10522, Avg test acc: 0.95436, Avg tpr: 0.96987, Avg fpr: 0.07973, total FA: 622

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09886 | acc=0.9560 | tpr=0.9663 | fpr=0.0664 | 4888.3 samples/s | 19.1 steps/s
Avg test loss: 0.10422, Avg test acc: 0.95412, Avg tpr: 0.96660, Avg fpr: 0.07332, total FA: 572

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10842 | acc=0.9539 | tpr=0.9653 | fpr=0.0709 | 4747.1 samples/s | 18.5 steps/s
Avg test loss: 0.11291, Avg test acc: 0.95340, Avg tpr: 0.96515, Avg fpr: 0.07243, total FA: 565

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.49689 | acc=0.3029 | tpr=0.0056 | fpr=0.0515 | 4790.8 samples/s | 18.7 steps/s
Avg test loss: 5.50632, Avg test acc: 0.30127, Avg tpr: 0.00653, Avg fpr: 0.05051, total FA: 394

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.72366 | acc=0.3052 | tpr=0.0042 | fpr=0.0411 | 4627.7 samples/s | 18.1 steps/s
Avg test loss: 4.73871, Avg test acc: 0.30215, Avg tpr: 0.00437, Avg fpr: 0.04294, total FA: 335

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.17852 | acc=0.2979 | tpr=0.0059 | fpr=0.0681 | 4911.4 samples/s | 19.2 steps/s
Avg test loss: 5.18410, Avg test acc: 0.29602, Avg tpr: 0.00705, Avg fpr: 0.06845, total FA: 534

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.69409 | acc=0.3020 | tpr=0.0110 | fpr=0.0659 | 4903.0 samples/s | 19.2 steps/s
Avg test loss: 5.69594, Avg test acc: 0.30054, Avg tpr: 0.01201, Avg fpr: 0.06486, total FA: 506

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.15460 | acc=0.3041 | tpr=0.0122 | fpr=0.0622 | 4721.9 samples/s | 18.4 steps/s
Avg test loss: 5.16085, Avg test acc: 0.30227, Avg tpr: 0.01282, Avg fpr: 0.06115, total FA: 477

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.41093 | acc=0.1205 | tpr=0.5177 | fpr=0.8867 | 4923.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.38354 | acc=0.1228 | tpr=0.5011 | fpr=0.8842 | 6800.7 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.39327 | acc=0.1235 | tpr=0.5029 | fpr=0.8835 | 7968.3 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.38502 | acc=0.1236 | tpr=0.4984 | fpr=0.8832 | 7805.3 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.38807 | acc=0.1244 | tpr=0.5135 | fpr=0.8827 | 7869.6 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.38300 | acc=0.1241 | tpr=0.5222 | fpr=0.8832 | 7986.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.37495 | acc=0.1243 | tpr=0.5210 | fpr=0.8829 | 7800.8 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.37394 | acc=0.1242 | tpr=0.5191 | fpr=0.8829 | 7898.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.37937 | acc=0.1245 | tpr=0.5175 | fpr=0.8826 | 7688.7 samples/s | 30.0 steps/s
[Step= 500] | Loss=5.38100 | acc=0.1246 | tpr=0.5119 | fpr=0.8824 | 7851.5 samples/s | 30.7 steps/s
[Step= 550] | Loss=5.38403 | acc=0.1244 | tpr=0.5078 | fpr=0.8825 | 14520.7 samples/s | 56.7 steps/s
Avg test loss: 5.38577, Avg test acc: 0.12435, Avg tpr: 0.50792, Avg fpr: 0.88263, total FA: 122551

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.30360 | acc=0.1030 | tpr=0.4336 | fpr=0.9030 | 4819.2 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.28830 | acc=0.1036 | tpr=0.4499 | fpr=0.9028 | 7256.2 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.28652 | acc=0.1039 | tpr=0.4553 | fpr=0.9025 | 7871.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.27961 | acc=0.1033 | tpr=0.4415 | fpr=0.9029 | 7843.4 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.28281 | acc=0.1036 | tpr=0.4437 | fpr=0.9026 | 7397.0 samples/s | 28.9 steps/s
[Step= 300] | Loss=5.27881 | acc=0.1034 | tpr=0.4487 | fpr=0.9029 | 8222.7 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.27356 | acc=0.1036 | tpr=0.4452 | fpr=0.9026 | 7969.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.27076 | acc=0.1035 | tpr=0.4426 | fpr=0.9027 | 8003.4 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.27542 | acc=0.1038 | tpr=0.4445 | fpr=0.9024 | 7935.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.27949 | acc=0.1038 | tpr=0.4405 | fpr=0.9023 | 7682.0 samples/s | 30.0 steps/s
[Step= 550] | Loss=5.28524 | acc=0.1033 | tpr=0.4389 | fpr=0.9028 | 13902.2 samples/s | 54.3 steps/s
Avg test loss: 5.28749, Avg test acc: 0.10328, Avg tpr: 0.43819, Avg fpr: 0.90281, total FA: 125353

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.70111 | acc=0.0996 | tpr=0.2788 | fpr=0.9036 | 4520.6 samples/s | 17.7 steps/s
[Step= 100] | Loss=5.66942 | acc=0.1010 | tpr=0.2793 | fpr=0.9023 | 7910.7 samples/s | 30.9 steps/s
[Step= 150] | Loss=5.68380 | acc=0.1025 | tpr=0.2767 | fpr=0.9007 | 7903.1 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.67543 | acc=0.1024 | tpr=0.2732 | fpr=0.9007 | 7596.2 samples/s | 29.7 steps/s
[Step= 250] | Loss=5.67605 | acc=0.1029 | tpr=0.2838 | fpr=0.9004 | 7989.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.67045 | acc=0.1033 | tpr=0.2938 | fpr=0.9002 | 7934.8 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.66372 | acc=0.1036 | tpr=0.2937 | fpr=0.8998 | 7942.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=5.66341 | acc=0.1037 | tpr=0.2965 | fpr=0.8999 | 7875.7 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.66904 | acc=0.1038 | tpr=0.2921 | fpr=0.8996 | 7651.8 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.67023 | acc=0.1038 | tpr=0.2916 | fpr=0.8996 | 7899.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=5.67348 | acc=0.1036 | tpr=0.2933 | fpr=0.8998 | 14581.5 samples/s | 57.0 steps/s
Avg test loss: 5.67494, Avg test acc: 0.10348, Avg tpr: 0.29398, Avg fpr: 0.89998, total FA: 124961

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.24322 | acc=0.1231 | tpr=0.5088 | fpr=0.8838 | 4810.1 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.21713 | acc=0.1224 | tpr=0.4968 | fpr=0.8846 | 6761.1 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.22732 | acc=0.1213 | tpr=0.5086 | fpr=0.8858 | 8269.0 samples/s | 32.3 steps/s
[Step= 200] | Loss=5.21745 | acc=0.1206 | tpr=0.5049 | fpr=0.8863 | 7660.2 samples/s | 29.9 steps/s
[Step= 250] | Loss=5.22194 | acc=0.1214 | tpr=0.5066 | fpr=0.8856 | 8143.6 samples/s | 31.8 steps/s
[Step= 300] | Loss=5.21958 | acc=0.1215 | tpr=0.5127 | fpr=0.8856 | 7821.7 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.21079 | acc=0.1219 | tpr=0.5097 | fpr=0.8851 | 7812.6 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.20743 | acc=0.1221 | tpr=0.5082 | fpr=0.8850 | 7558.4 samples/s | 29.5 steps/s
[Step= 450] | Loss=5.21308 | acc=0.1220 | tpr=0.5063 | fpr=0.8850 | 8078.6 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.21343 | acc=0.1222 | tpr=0.5022 | fpr=0.8847 | 7838.2 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.21843 | acc=0.1217 | tpr=0.4946 | fpr=0.8851 | 14246.4 samples/s | 55.6 steps/s
Avg test loss: 5.21983, Avg test acc: 0.12159, Avg tpr: 0.49485, Avg fpr: 0.88520, total FA: 122908

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.71276 | acc=0.1173 | tpr=0.4159 | fpr=0.8880 | 4633.3 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.69179 | acc=0.1202 | tpr=0.4264 | fpr=0.8856 | 7281.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.68989 | acc=0.1204 | tpr=0.4280 | fpr=0.8853 | 7871.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.68467 | acc=0.1203 | tpr=0.4186 | fpr=0.8851 | 7993.2 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.68802 | acc=0.1213 | tpr=0.4262 | fpr=0.8842 | 7715.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.68893 | acc=0.1214 | tpr=0.4313 | fpr=0.8842 | 8102.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.67962 | acc=0.1221 | tpr=0.4289 | fpr=0.8834 | 7884.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.67898 | acc=0.1219 | tpr=0.4251 | fpr=0.8836 | 7704.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.68384 | acc=0.1223 | tpr=0.4241 | fpr=0.8832 | 7978.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.68582 | acc=0.1220 | tpr=0.4203 | fpr=0.8834 | 7797.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.69119 | acc=0.1215 | tpr=0.4214 | fpr=0.8839 | 14393.7 samples/s | 56.2 steps/s
Avg test loss: 5.69326, Avg test acc: 0.12140, Avg tpr: 0.42076, Avg fpr: 0.88405, total FA: 122748

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08459 | acc=0.9821 | tpr=0.9558 | fpr=0.0174 | 4712.3 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.08591 | acc=0.9825 | tpr=0.9595 | fpr=0.0171 | 7305.2 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.08956 | acc=0.9816 | tpr=0.9611 | fpr=0.0180 | 7922.7 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.09142 | acc=0.9819 | tpr=0.9650 | fpr=0.0178 | 7952.8 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.09026 | acc=0.9821 | tpr=0.9598 | fpr=0.0175 | 7947.4 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.09216 | acc=0.9819 | tpr=0.9600 | fpr=0.0177 | 8048.8 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.09311 | acc=0.9816 | tpr=0.9599 | fpr=0.0180 | 7658.0 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.09406 | acc=0.9813 | tpr=0.9546 | fpr=0.0182 | 7828.7 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.09608 | acc=0.9809 | tpr=0.9499 | fpr=0.0186 | 7868.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.09541 | acc=0.9809 | tpr=0.9502 | fpr=0.0186 | 8016.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.09487 | acc=0.9810 | tpr=0.9483 | fpr=0.0184 | 13542.7 samples/s | 52.9 steps/s
Avg test loss: 0.09474, Avg test acc: 0.98104, Avg tpr: 0.94810, Avg fpr: 0.01836, total FA: 2549

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08557 | acc=0.9820 | tpr=0.9292 | fpr=0.0171 | 4851.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.08837 | acc=0.9818 | tpr=0.9318 | fpr=0.0173 | 7075.7 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.09182 | acc=0.9814 | tpr=0.9323 | fpr=0.0177 | 7874.7 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.09397 | acc=0.9816 | tpr=0.9388 | fpr=0.0176 | 7449.6 samples/s | 29.1 steps/s
[Step= 250] | Loss=0.09240 | acc=0.9820 | tpr=0.9380 | fpr=0.0172 | 8108.4 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.09435 | acc=0.9817 | tpr=0.9375 | fpr=0.0175 | 7917.2 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.09499 | acc=0.9814 | tpr=0.9374 | fpr=0.0178 | 7812.1 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.09612 | acc=0.9812 | tpr=0.9327 | fpr=0.0179 | 7684.2 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.09824 | acc=0.9810 | tpr=0.9304 | fpr=0.0181 | 8131.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.09750 | acc=0.9810 | tpr=0.9317 | fpr=0.0181 | 8062.9 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.09712 | acc=0.9812 | tpr=0.9292 | fpr=0.0179 | 13224.2 samples/s | 51.7 steps/s
Avg test loss: 0.09702, Avg test acc: 0.98118, Avg tpr: 0.92908, Avg fpr: 0.01787, total FA: 2481

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08140 | acc=0.9823 | tpr=0.9690 | fpr=0.0175 | 4651.2 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.08318 | acc=0.9816 | tpr=0.9680 | fpr=0.0182 | 7437.2 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.08696 | acc=0.9809 | tpr=0.9654 | fpr=0.0188 | 7707.1 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.08833 | acc=0.9811 | tpr=0.9705 | fpr=0.0187 | 8049.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.08702 | acc=0.9813 | tpr=0.9686 | fpr=0.0184 | 8108.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.08892 | acc=0.9811 | tpr=0.9658 | fpr=0.0186 | 7942.5 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.08958 | acc=0.9809 | tpr=0.9668 | fpr=0.0189 | 7904.3 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.09069 | acc=0.9807 | tpr=0.9639 | fpr=0.0190 | 7709.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.09223 | acc=0.9804 | tpr=0.9620 | fpr=0.0193 | 7953.2 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09177 | acc=0.9804 | tpr=0.9634 | fpr=0.0193 | 7834.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09135 | acc=0.9805 | tpr=0.9618 | fpr=0.0192 | 14070.3 samples/s | 55.0 steps/s
Avg test loss: 0.09122, Avg test acc: 0.98051, Avg tpr: 0.96197, Avg fpr: 0.01916, total FA: 2660

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09237 | acc=0.9801 | tpr=0.9381 | fpr=0.0192 | 4815.3 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.09434 | acc=0.9804 | tpr=0.9488 | fpr=0.0190 | 7066.0 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.09820 | acc=0.9796 | tpr=0.9481 | fpr=0.0198 | 7799.9 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.09942 | acc=0.9799 | tpr=0.9530 | fpr=0.0196 | 8024.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.09803 | acc=0.9804 | tpr=0.9511 | fpr=0.0191 | 7682.2 samples/s | 30.0 steps/s
[Step= 300] | Loss=0.10009 | acc=0.9802 | tpr=0.9505 | fpr=0.0192 | 8404.4 samples/s | 32.8 steps/s
[Step= 350] | Loss=0.10081 | acc=0.9800 | tpr=0.9505 | fpr=0.0195 | 7637.8 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.10116 | acc=0.9799 | tpr=0.9475 | fpr=0.0195 | 7784.1 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.10287 | acc=0.9797 | tpr=0.9460 | fpr=0.0197 | 8098.4 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.10211 | acc=0.9798 | tpr=0.9471 | fpr=0.0196 | 7380.7 samples/s | 28.8 steps/s
[Step= 550] | Loss=0.10158 | acc=0.9800 | tpr=0.9479 | fpr=0.0195 | 14569.1 samples/s | 56.9 steps/s
Avg test loss: 0.10141, Avg test acc: 0.97998, Avg tpr: 0.94770, Avg fpr: 0.01943, total FA: 2698

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.08508 | acc=0.9824 | tpr=0.9204 | fpr=0.0165 | 4764.8 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.08858 | acc=0.9819 | tpr=0.9296 | fpr=0.0171 | 7256.5 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.09157 | acc=0.9809 | tpr=0.9337 | fpr=0.0182 | 7681.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.09260 | acc=0.9810 | tpr=0.9421 | fpr=0.0183 | 7977.4 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09124 | acc=0.9813 | tpr=0.9415 | fpr=0.0180 | 7514.2 samples/s | 29.4 steps/s
[Step= 300] | Loss=0.09312 | acc=0.9810 | tpr=0.9375 | fpr=0.0182 | 7972.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.09367 | acc=0.9808 | tpr=0.9405 | fpr=0.0185 | 7747.1 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.09487 | acc=0.9805 | tpr=0.9371 | fpr=0.0187 | 8223.5 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.09691 | acc=0.9803 | tpr=0.9348 | fpr=0.0189 | 7878.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.09656 | acc=0.9802 | tpr=0.9344 | fpr=0.0189 | 7950.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.09621 | acc=0.9805 | tpr=0.9339 | fpr=0.0187 | 14049.1 samples/s | 54.9 steps/s
Avg test loss: 0.09606, Avg test acc: 0.98047, Avg tpr: 0.93423, Avg fpr: 0.01869, total FA: 2595

server round 44/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=429.1] | Loss=0.00365 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=21.192 | 5876.3 samples/s | 91.8 steps/s
[Step=88050 Epoch=429.3] | Loss=0.00583 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=21.197 | 4156.5 samples/s | 64.9 steps/s
[Step=88100 Epoch=429.6] | Loss=0.00592 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=21.204 | 5034.8 samples/s | 78.7 steps/s
[Step=88150 Epoch=429.8] | Loss=0.00579 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.873 | L2-Norm(final)=21.210 | 5050.9 samples/s | 78.9 steps/s
[Step=88200 Epoch=430.1] | Loss=0.00585 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=21.216 | 7925.4 samples/s | 123.8 steps/s
[Step=88250 Epoch=430.3] | Loss=0.00574 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=21.222 | 2222.0 samples/s | 34.7 steps/s
[Step=88300 Epoch=430.6] | Loss=0.00570 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=21.228 | 4971.8 samples/s | 77.7 steps/s
[Step=88350 Epoch=430.8] | Loss=0.00552 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.883 | L2-Norm(final)=21.234 | 4937.7 samples/s | 77.2 steps/s
[Step=88400 Epoch=431.1] | Loss=0.00557 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.886 | L2-Norm(final)=21.240 | 7034.7 samples/s | 109.9 steps/s
[Step=88450 Epoch=431.3] | Loss=0.00561 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.888 | L2-Norm(final)=21.246 | 2298.3 samples/s | 35.9 steps/s
[Step=88500 Epoch=431.5] | Loss=0.00551 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.890 | L2-Norm(final)=21.252 | 4998.2 samples/s | 78.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=431.5] | Loss=0.00839 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.911 | L2-Norm(final)=21.308 | 5695.4 samples/s | 89.0 steps/s
[Step=88550 Epoch=431.8] | Loss=0.00599 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.915 | L2-Norm(final)=21.313 | 3973.6 samples/s | 62.1 steps/s
[Step=88600 Epoch=432.0] | Loss=0.00591 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=21.318 | 4451.9 samples/s | 69.6 steps/s
[Step=88650 Epoch=432.3] | Loss=0.00553 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.923 | L2-Norm(final)=21.322 | 4461.6 samples/s | 69.7 steps/s
[Step=88700 Epoch=432.5] | Loss=0.00582 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.926 | L2-Norm(final)=21.327 | 6376.7 samples/s | 99.6 steps/s
[Step=88750 Epoch=432.8] | Loss=0.00545 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.929 | L2-Norm(final)=21.331 | 2120.9 samples/s | 33.1 steps/s
[Step=88800 Epoch=433.0] | Loss=0.00540 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.932 | L2-Norm(final)=21.335 | 4421.4 samples/s | 69.1 steps/s
[Step=88850 Epoch=433.2] | Loss=0.00513 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.934 | L2-Norm(final)=21.338 | 4601.2 samples/s | 71.9 steps/s
[Step=88900 Epoch=433.5] | Loss=0.00503 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.936 | L2-Norm(final)=21.342 | 5723.1 samples/s | 89.4 steps/s
[Step=88950 Epoch=433.7] | Loss=0.00489 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=21.345 | 2153.0 samples/s | 33.6 steps/s
[Step=89000 Epoch=434.0] | Loss=0.00463 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.939 | L2-Norm(final)=21.348 | 4398.3 samples/s | 68.7 steps/s
[Step=89050 Epoch=434.2] | Loss=0.00452 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.941 | L2-Norm(final)=21.351 | 4413.4 samples/s | 69.0 steps/s
[Step=89100 Epoch=434.5] | Loss=0.00441 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=21.354 | 5437.5 samples/s | 85.0 steps/s
[Step=89150 Epoch=434.7] | Loss=0.00422 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=21.357 | 2241.6 samples/s | 35.0 steps/s
[Step=89200 Epoch=435.0] | Loss=0.00415 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.944 | L2-Norm(final)=21.360 | 4499.6 samples/s | 70.3 steps/s
[Step=89250 Epoch=435.2] | Loss=0.00406 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=21.362 | 4447.2 samples/s | 69.5 steps/s
[Step=89300 Epoch=435.4] | Loss=0.00395 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=21.365 | 5005.0 samples/s | 78.2 steps/s
[Step=89350 Epoch=435.7] | Loss=0.00392 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=21.368 | 2327.1 samples/s | 36.4 steps/s
[Step=89400 Epoch=435.9] | Loss=0.00382 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=21.370 | 4420.6 samples/s | 69.1 steps/s
[Step=89450 Epoch=436.2] | Loss=0.00381 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=21.373 | 4492.7 samples/s | 70.2 steps/s
[Step=89500 Epoch=436.4] | Loss=0.00372 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=21.375 | 4614.4 samples/s | 72.1 steps/s
[Step=89550 Epoch=436.7] | Loss=0.00363 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=21.378 | 2430.2 samples/s | 38.0 steps/s
[Step=89600 Epoch=436.9] | Loss=0.00356 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=21.380 | 4446.3 samples/s | 69.5 steps/s
[Step=89650 Epoch=437.2] | Loss=0.00353 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=21.383 | 4503.6 samples/s | 70.4 steps/s
[Step=89700 Epoch=437.4] | Loss=0.00351 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=21.385 | 4430.0 samples/s | 69.2 steps/s
[Step=89750 Epoch=437.6] | Loss=0.00344 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=21.387 | 2456.1 samples/s | 38.4 steps/s
[Step=89800 Epoch=437.9] | Loss=0.00338 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=21.390 | 4358.0 samples/s | 68.1 steps/s
[Step=89850 Epoch=438.1] | Loss=0.00333 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=21.392 | 4456.8 samples/s | 69.6 steps/s
[Step=89900 Epoch=438.4] | Loss=0.00332 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.954 | L2-Norm(final)=21.394 | 4467.4 samples/s | 69.8 steps/s
[Step=89950 Epoch=438.6] | Loss=0.00329 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=21.397 | 2475.1 samples/s | 38.7 steps/s
[Step=90000 Epoch=438.9] | Loss=0.00326 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=21.399 | 4559.4 samples/s | 71.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step90000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=429.4] | Loss=0.00584 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.454 | L2-Norm(final)=22.079 | 5037.8 samples/s | 78.7 steps/s
[Step=88050 Epoch=429.6] | Loss=0.00507 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.457 | L2-Norm(final)=22.085 | 4769.3 samples/s | 74.5 steps/s
[Step=88100 Epoch=429.9] | Loss=0.00500 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.460 | L2-Norm(final)=22.093 | 4904.3 samples/s | 76.6 steps/s
[Step=88150 Epoch=430.1] | Loss=0.00501 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.462 | L2-Norm(final)=22.100 | 5135.1 samples/s | 80.2 steps/s
[Step=88200 Epoch=430.4] | Loss=0.00505 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.465 | L2-Norm(final)=22.107 | 7674.3 samples/s | 119.9 steps/s
[Step=88250 Epoch=430.6] | Loss=0.00502 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.467 | L2-Norm(final)=22.114 | 2197.0 samples/s | 34.3 steps/s
[Step=88300 Epoch=430.9] | Loss=0.00502 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.470 | L2-Norm(final)=22.121 | 5003.3 samples/s | 78.2 steps/s
[Step=88350 Epoch=431.1] | Loss=0.00498 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.472 | L2-Norm(final)=22.128 | 5036.1 samples/s | 78.7 steps/s
[Step=88400 Epoch=431.4] | Loss=0.00491 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.475 | L2-Norm(final)=22.134 | 7194.5 samples/s | 112.4 steps/s
[Step=88450 Epoch=431.6] | Loss=0.00485 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.477 | L2-Norm(final)=22.141 | 2268.2 samples/s | 35.4 steps/s
[Step=88500 Epoch=431.8] | Loss=0.00485 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.479 | L2-Norm(final)=22.147 | 5223.9 samples/s | 81.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=431.8] | Loss=0.00296 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.502 | L2-Norm(final)=22.210 | 5504.0 samples/s | 86.0 steps/s
[Step=88550 Epoch=432.1] | Loss=0.00527 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.506 | L2-Norm(final)=22.216 | 3931.5 samples/s | 61.4 steps/s
[Step=88600 Epoch=432.3] | Loss=0.00556 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=22.222 | 4504.3 samples/s | 70.4 steps/s
[Step=88650 Epoch=432.6] | Loss=0.00532 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=22.227 | 4464.7 samples/s | 69.8 steps/s
[Step=88700 Epoch=432.8] | Loss=0.00546 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.519 | L2-Norm(final)=22.232 | 6598.0 samples/s | 103.1 steps/s
[Step=88750 Epoch=433.1] | Loss=0.00518 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.522 | L2-Norm(final)=22.236 | 2078.7 samples/s | 32.5 steps/s
[Step=88800 Epoch=433.3] | Loss=0.00491 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=22.240 | 4385.9 samples/s | 68.5 steps/s
[Step=88850 Epoch=433.5] | Loss=0.00462 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.527 | L2-Norm(final)=22.244 | 4474.0 samples/s | 69.9 steps/s
[Step=88900 Epoch=433.8] | Loss=0.00441 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=22.248 | 6080.4 samples/s | 95.0 steps/s
[Step=88950 Epoch=434.0] | Loss=0.00426 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=22.252 | 2150.6 samples/s | 33.6 steps/s
[Step=89000 Epoch=434.3] | Loss=0.00411 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.533 | L2-Norm(final)=22.255 | 4446.6 samples/s | 69.5 steps/s
[Step=89050 Epoch=434.5] | Loss=0.00401 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.534 | L2-Norm(final)=22.258 | 4491.8 samples/s | 70.2 steps/s
[Step=89100 Epoch=434.8] | Loss=0.00387 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.535 | L2-Norm(final)=22.261 | 5538.0 samples/s | 86.5 steps/s
[Step=89150 Epoch=435.0] | Loss=0.00374 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.537 | L2-Norm(final)=22.265 | 2153.0 samples/s | 33.6 steps/s
[Step=89200 Epoch=435.3] | Loss=0.00364 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=22.268 | 4548.5 samples/s | 71.1 steps/s
[Step=89250 Epoch=435.5] | Loss=0.00354 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.539 | L2-Norm(final)=22.271 | 4467.8 samples/s | 69.8 steps/s
[Step=89300 Epoch=435.7] | Loss=0.00347 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.540 | L2-Norm(final)=22.274 | 5182.3 samples/s | 81.0 steps/s
[Step=89350 Epoch=436.0] | Loss=0.00342 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.541 | L2-Norm(final)=22.277 | 2286.4 samples/s | 35.7 steps/s
[Step=89400 Epoch=436.2] | Loss=0.00333 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.542 | L2-Norm(final)=22.279 | 4519.4 samples/s | 70.6 steps/s
[Step=89450 Epoch=436.5] | Loss=0.00329 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.543 | L2-Norm(final)=22.282 | 4362.8 samples/s | 68.2 steps/s
[Step=89500 Epoch=436.7] | Loss=0.00324 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.543 | L2-Norm(final)=22.285 | 4825.8 samples/s | 75.4 steps/s
[Step=89550 Epoch=437.0] | Loss=0.00318 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=22.288 | 2363.8 samples/s | 36.9 steps/s
[Step=89600 Epoch=437.2] | Loss=0.00313 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.545 | L2-Norm(final)=22.291 | 4477.3 samples/s | 70.0 steps/s
[Step=89650 Epoch=437.5] | Loss=0.00307 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.545 | L2-Norm(final)=22.293 | 4483.2 samples/s | 70.1 steps/s
[Step=89700 Epoch=437.7] | Loss=0.00303 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.546 | L2-Norm(final)=22.296 | 4633.6 samples/s | 72.4 steps/s
[Step=89750 Epoch=437.9] | Loss=0.00299 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.546 | L2-Norm(final)=22.299 | 2399.9 samples/s | 37.5 steps/s
[Step=89800 Epoch=438.2] | Loss=0.00294 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.547 | L2-Norm(final)=22.301 | 4430.7 samples/s | 69.2 steps/s
[Step=89850 Epoch=438.4] | Loss=0.00290 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.547 | L2-Norm(final)=22.304 | 4529.7 samples/s | 70.8 steps/s
[Step=89900 Epoch=438.7] | Loss=0.00288 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=22.306 | 4414.5 samples/s | 69.0 steps/s
[Step=89950 Epoch=438.9] | Loss=0.00284 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=22.309 | 2495.4 samples/s | 39.0 steps/s
[Step=90000 Epoch=439.2] | Loss=0.00280 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.549 | L2-Norm(final)=22.311 | 4436.6 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step90000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=428.8] | Loss=0.00812 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.260 | L2-Norm(final)=22.099 | 4978.9 samples/s | 77.8 steps/s
[Step=88050 Epoch=429.0] | Loss=0.00563 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=22.105 | 4523.6 samples/s | 70.7 steps/s
[Step=88100 Epoch=429.3] | Loss=0.00570 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=22.111 | 4973.9 samples/s | 77.7 steps/s
[Step=88150 Epoch=429.5] | Loss=0.00585 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=22.117 | 4971.6 samples/s | 77.7 steps/s
[Step=88200 Epoch=429.8] | Loss=0.00585 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.271 | L2-Norm(final)=22.123 | 7898.9 samples/s | 123.4 steps/s
[Step=88250 Epoch=430.0] | Loss=0.00588 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.273 | L2-Norm(final)=22.130 | 2230.8 samples/s | 34.9 steps/s
[Step=88300 Epoch=430.2] | Loss=0.00577 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.276 | L2-Norm(final)=22.136 | 5065.5 samples/s | 79.1 steps/s
[Step=88350 Epoch=430.5] | Loss=0.00566 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.278 | L2-Norm(final)=22.142 | 5101.1 samples/s | 79.7 steps/s
[Step=88400 Epoch=430.7] | Loss=0.00561 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=22.148 | 6782.4 samples/s | 106.0 steps/s
[Step=88450 Epoch=431.0] | Loss=0.00552 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.282 | L2-Norm(final)=22.154 | 2309.7 samples/s | 36.1 steps/s
[Step=88500 Epoch=431.2] | Loss=0.00544 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.285 | L2-Norm(final)=22.160 | 4843.1 samples/s | 75.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=431.2] | Loss=0.00296 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.306 | L2-Norm(final)=22.217 | 5449.2 samples/s | 85.1 steps/s
[Step=88550 Epoch=431.5] | Loss=0.00563 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=22.222 | 4077.3 samples/s | 63.7 steps/s
[Step=88600 Epoch=431.7] | Loss=0.00605 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=22.228 | 4449.4 samples/s | 69.5 steps/s
[Step=88650 Epoch=431.9] | Loss=0.00601 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=22.232 | 4477.7 samples/s | 70.0 steps/s
[Step=88700 Epoch=432.2] | Loss=0.00596 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.323 | L2-Norm(final)=22.237 | 6543.5 samples/s | 102.2 steps/s
[Step=88750 Epoch=432.4] | Loss=0.00561 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=22.241 | 2111.1 samples/s | 33.0 steps/s
[Step=88800 Epoch=432.7] | Loss=0.00529 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=22.245 | 4402.8 samples/s | 68.8 steps/s
[Step=88850 Epoch=432.9] | Loss=0.00507 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=22.249 | 4471.0 samples/s | 69.9 steps/s
[Step=88900 Epoch=433.2] | Loss=0.00494 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=22.252 | 5927.0 samples/s | 92.6 steps/s
[Step=88950 Epoch=433.4] | Loss=0.00474 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=22.256 | 2191.8 samples/s | 34.2 steps/s
[Step=89000 Epoch=433.7] | Loss=0.00455 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=22.259 | 4440.5 samples/s | 69.4 steps/s
[Step=89050 Epoch=433.9] | Loss=0.00438 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.337 | L2-Norm(final)=22.262 | 4513.3 samples/s | 70.5 steps/s
[Step=89100 Epoch=434.1] | Loss=0.00426 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.339 | L2-Norm(final)=22.265 | 5379.2 samples/s | 84.0 steps/s
[Step=89150 Epoch=434.4] | Loss=0.00420 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.340 | L2-Norm(final)=22.268 | 2211.0 samples/s | 34.5 steps/s
[Step=89200 Epoch=434.6] | Loss=0.00407 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=22.271 | 4465.3 samples/s | 69.8 steps/s
[Step=89250 Epoch=434.9] | Loss=0.00397 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.342 | L2-Norm(final)=22.274 | 4464.4 samples/s | 69.8 steps/s
[Step=89300 Epoch=435.1] | Loss=0.00390 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=22.276 | 5000.1 samples/s | 78.1 steps/s
[Step=89350 Epoch=435.4] | Loss=0.00383 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=22.279 | 2349.5 samples/s | 36.7 steps/s
[Step=89400 Epoch=435.6] | Loss=0.00375 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=22.282 | 4498.2 samples/s | 70.3 steps/s
[Step=89450 Epoch=435.8] | Loss=0.00368 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=22.285 | 4476.6 samples/s | 69.9 steps/s
[Step=89500 Epoch=436.1] | Loss=0.00362 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=22.287 | 4562.9 samples/s | 71.3 steps/s
[Step=89550 Epoch=436.3] | Loss=0.00357 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.347 | L2-Norm(final)=22.290 | 2348.0 samples/s | 36.7 steps/s
[Step=89600 Epoch=436.6] | Loss=0.00353 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=22.292 | 4502.6 samples/s | 70.4 steps/s
[Step=89650 Epoch=436.8] | Loss=0.00350 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=22.295 | 4485.4 samples/s | 70.1 steps/s
[Step=89700 Epoch=437.1] | Loss=0.00345 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=22.297 | 4443.4 samples/s | 69.4 steps/s
[Step=89750 Epoch=437.3] | Loss=0.00340 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.350 | L2-Norm(final)=22.300 | 2489.7 samples/s | 38.9 steps/s
[Step=89800 Epoch=437.5] | Loss=0.00336 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.350 | L2-Norm(final)=22.302 | 4449.2 samples/s | 69.5 steps/s
[Step=89850 Epoch=437.8] | Loss=0.00332 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=22.305 | 4460.4 samples/s | 69.7 steps/s
[Step=89900 Epoch=438.0] | Loss=0.00328 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=22.307 | 4456.8 samples/s | 69.6 steps/s
[Step=89950 Epoch=438.3] | Loss=0.00325 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=22.310 | 2452.7 samples/s | 38.3 steps/s
[Step=90000 Epoch=438.5] | Loss=0.00322 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=22.312 | 4444.4 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step90000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=429.1] | Loss=0.00432 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=22.142 | 5333.0 samples/s | 83.3 steps/s
[Step=88050 Epoch=429.4] | Loss=0.00560 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=22.148 | 4546.3 samples/s | 71.0 steps/s
[Step=88100 Epoch=429.6] | Loss=0.00591 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=22.155 | 4966.9 samples/s | 77.6 steps/s
[Step=88150 Epoch=429.9] | Loss=0.00578 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=22.161 | 5049.3 samples/s | 78.9 steps/s
[Step=88200 Epoch=430.1] | Loss=0.00570 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=22.168 | 7799.5 samples/s | 121.9 steps/s
[Step=88250 Epoch=430.4] | Loss=0.00549 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=22.175 | 2171.6 samples/s | 33.9 steps/s
[Step=88300 Epoch=430.6] | Loss=0.00545 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=22.181 | 4933.7 samples/s | 77.1 steps/s
[Step=88350 Epoch=430.8] | Loss=0.00541 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=22.188 | 5213.6 samples/s | 81.5 steps/s
[Step=88400 Epoch=431.1] | Loss=0.00539 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=22.194 | 6644.7 samples/s | 103.8 steps/s
[Step=88450 Epoch=431.3] | Loss=0.00537 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=22.200 | 2322.9 samples/s | 36.3 steps/s
[Step=88500 Epoch=431.6] | Loss=0.00538 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=22.206 | 4853.2 samples/s | 75.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=431.6] | Loss=0.00613 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=22.265 | 5565.3 samples/s | 87.0 steps/s
[Step=88550 Epoch=431.8] | Loss=0.00539 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=22.271 | 3882.6 samples/s | 60.7 steps/s
[Step=88600 Epoch=432.1] | Loss=0.00563 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=22.276 | 4485.2 samples/s | 70.1 steps/s
[Step=88650 Epoch=432.3] | Loss=0.00565 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=22.281 | 4471.0 samples/s | 69.9 steps/s
[Step=88700 Epoch=432.6] | Loss=0.00554 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=22.286 | 6556.6 samples/s | 102.4 steps/s
[Step=88750 Epoch=432.8] | Loss=0.00504 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=22.290 | 2084.6 samples/s | 32.6 steps/s
[Step=88800 Epoch=433.0] | Loss=0.00474 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=22.294 | 4484.9 samples/s | 70.1 steps/s
[Step=88850 Epoch=433.3] | Loss=0.00453 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=22.298 | 4495.5 samples/s | 70.2 steps/s
[Step=88900 Epoch=433.5] | Loss=0.00445 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.011 | L2-Norm(final)=22.301 | 5891.4 samples/s | 92.1 steps/s
[Step=88950 Epoch=433.8] | Loss=0.00420 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.305 | 2150.8 samples/s | 33.6 steps/s
[Step=89000 Epoch=434.0] | Loss=0.00403 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=22.308 | 4470.6 samples/s | 69.9 steps/s
[Step=89050 Epoch=434.3] | Loss=0.00391 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=22.311 | 4456.3 samples/s | 69.6 steps/s
[Step=89100 Epoch=434.5] | Loss=0.00377 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=22.314 | 5401.1 samples/s | 84.4 steps/s
[Step=89150 Epoch=434.7] | Loss=0.00373 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=22.317 | 2229.5 samples/s | 34.8 steps/s
[Step=89200 Epoch=435.0] | Loss=0.00363 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=22.320 | 4499.2 samples/s | 70.3 steps/s
[Step=89250 Epoch=435.2] | Loss=0.00354 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=22.323 | 4350.0 samples/s | 68.0 steps/s
[Step=89300 Epoch=435.5] | Loss=0.00349 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=22.326 | 4955.1 samples/s | 77.4 steps/s
[Step=89350 Epoch=435.7] | Loss=0.00336 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=22.328 | 2368.2 samples/s | 37.0 steps/s
[Step=89400 Epoch=436.0] | Loss=0.00331 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=22.331 | 4381.5 samples/s | 68.5 steps/s
[Step=89450 Epoch=436.2] | Loss=0.00324 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=22.334 | 4511.8 samples/s | 70.5 steps/s
[Step=89500 Epoch=436.5] | Loss=0.00319 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=22.336 | 4605.9 samples/s | 72.0 steps/s
[Step=89550 Epoch=436.7] | Loss=0.00313 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=22.339 | 2410.3 samples/s | 37.7 steps/s
[Step=89600 Epoch=436.9] | Loss=0.00307 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=22.341 | 4458.8 samples/s | 69.7 steps/s
[Step=89650 Epoch=437.2] | Loss=0.00303 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=22.344 | 4387.6 samples/s | 68.6 steps/s
[Step=89700 Epoch=437.4] | Loss=0.00300 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=22.346 | 4487.5 samples/s | 70.1 steps/s
[Step=89750 Epoch=437.7] | Loss=0.00292 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=22.349 | 2462.5 samples/s | 38.5 steps/s
[Step=89800 Epoch=437.9] | Loss=0.00290 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=22.351 | 4536.0 samples/s | 70.9 steps/s
[Step=89850 Epoch=438.2] | Loss=0.00285 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=22.354 | 4428.4 samples/s | 69.2 steps/s
[Step=89900 Epoch=438.4] | Loss=0.00281 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=22.356 | 4463.6 samples/s | 69.7 steps/s
[Step=89950 Epoch=438.6] | Loss=0.00279 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=22.359 | 2446.8 samples/s | 38.2 steps/s
[Step=90000 Epoch=438.9] | Loss=0.00275 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=22.361 | 4518.9 samples/s | 70.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step90000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=431.5] | Loss=0.00419 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.587 | L2-Norm(final)=22.245 | 5353.8 samples/s | 83.7 steps/s
[Step=88050 Epoch=431.8] | Loss=0.00528 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.589 | L2-Norm(final)=22.250 | 4494.5 samples/s | 70.2 steps/s
[Step=88100 Epoch=432.0] | Loss=0.00526 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=22.257 | 4934.7 samples/s | 77.1 steps/s
[Step=88150 Epoch=432.3] | Loss=0.00493 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=22.263 | 5058.0 samples/s | 79.0 steps/s
[Step=88200 Epoch=432.5] | Loss=0.00504 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.598 | L2-Norm(final)=22.270 | 8062.1 samples/s | 126.0 steps/s
[Step=88250 Epoch=432.8] | Loss=0.00511 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=22.276 | 2187.5 samples/s | 34.2 steps/s
[Step=88300 Epoch=433.0] | Loss=0.00496 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.603 | L2-Norm(final)=22.282 | 4882.9 samples/s | 76.3 steps/s
[Step=88350 Epoch=433.3] | Loss=0.00487 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=22.288 | 5110.8 samples/s | 79.9 steps/s
[Step=88400 Epoch=433.5] | Loss=0.00481 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=22.294 | 7337.8 samples/s | 114.7 steps/s
[Step=88450 Epoch=433.7] | Loss=0.00477 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.610 | L2-Norm(final)=22.300 | 2258.4 samples/s | 35.3 steps/s
[Step=88500 Epoch=434.0] | Loss=0.00475 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.612 | L2-Norm(final)=22.306 | 5294.0 samples/s | 82.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=434.0] | Loss=0.00168 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=22.363 | 5066.0 samples/s | 79.2 steps/s
[Step=88550 Epoch=434.2] | Loss=0.00486 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=22.368 | 4171.4 samples/s | 65.2 steps/s
[Step=88600 Epoch=434.5] | Loss=0.00568 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=22.373 | 4424.8 samples/s | 69.1 steps/s
[Step=88650 Epoch=434.7] | Loss=0.00523 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=22.378 | 4498.7 samples/s | 70.3 steps/s
[Step=88700 Epoch=435.0] | Loss=0.00549 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=22.383 | 6656.3 samples/s | 104.0 steps/s
[Step=88750 Epoch=435.2] | Loss=0.00541 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=22.387 | 2080.0 samples/s | 32.5 steps/s
[Step=88800 Epoch=435.5] | Loss=0.00504 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=22.391 | 4524.0 samples/s | 70.7 steps/s
[Step=88850 Epoch=435.7] | Loss=0.00492 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=22.395 | 4380.3 samples/s | 68.4 steps/s
[Step=88900 Epoch=436.0] | Loss=0.00467 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=22.398 | 6248.4 samples/s | 97.6 steps/s
[Step=88950 Epoch=436.2] | Loss=0.00445 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=22.402 | 2102.1 samples/s | 32.8 steps/s
[Step=89000 Epoch=436.4] | Loss=0.00429 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=22.405 | 4418.5 samples/s | 69.0 steps/s
[Step=89050 Epoch=436.7] | Loss=0.00406 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=22.408 | 4494.8 samples/s | 70.2 steps/s
[Step=89100 Epoch=436.9] | Loss=0.00400 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.664 | L2-Norm(final)=22.411 | 5877.8 samples/s | 91.8 steps/s
[Step=89150 Epoch=437.2] | Loss=0.00382 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=22.414 | 2154.3 samples/s | 33.7 steps/s
[Step=89200 Epoch=437.4] | Loss=0.00370 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=22.417 | 4511.0 samples/s | 70.5 steps/s
[Step=89250 Epoch=437.7] | Loss=0.00362 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=22.419 | 4588.3 samples/s | 71.7 steps/s
[Step=89300 Epoch=437.9] | Loss=0.00350 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=22.422 | 5359.1 samples/s | 83.7 steps/s
[Step=89350 Epoch=438.2] | Loss=0.00344 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=22.425 | 2182.2 samples/s | 34.1 steps/s
[Step=89400 Epoch=438.4] | Loss=0.00334 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=22.427 | 4495.1 samples/s | 70.2 steps/s
[Step=89450 Epoch=438.6] | Loss=0.00328 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.671 | L2-Norm(final)=22.430 | 4562.0 samples/s | 71.3 steps/s
[Step=89500 Epoch=438.9] | Loss=0.00319 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=22.433 | 5117.7 samples/s | 80.0 steps/s
[Step=89550 Epoch=439.1] | Loss=0.00314 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=22.435 | 2271.8 samples/s | 35.5 steps/s
[Step=89600 Epoch=439.4] | Loss=0.00309 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=22.438 | 4459.7 samples/s | 69.7 steps/s
[Step=89650 Epoch=439.6] | Loss=0.00302 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=22.440 | 4425.5 samples/s | 69.1 steps/s
[Step=89700 Epoch=439.9] | Loss=0.00299 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=22.443 | 4848.8 samples/s | 75.8 steps/s
[Step=89750 Epoch=440.1] | Loss=0.00293 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=22.445 | 2363.0 samples/s | 36.9 steps/s
[Step=89800 Epoch=440.4] | Loss=0.00288 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=22.448 | 4480.1 samples/s | 70.0 steps/s
[Step=89850 Epoch=440.6] | Loss=0.00283 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=22.450 | 4366.7 samples/s | 68.2 steps/s
[Step=89900 Epoch=440.9] | Loss=0.00280 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=22.452 | 4717.8 samples/s | 73.7 steps/s
[Step=89950 Epoch=441.1] | Loss=0.00277 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=22.455 | 2418.6 samples/s | 37.8 steps/s
[Step=90000 Epoch=441.3] | Loss=0.00273 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=22.457 | 4435.4 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step90000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=833.9] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.523 | L2-Norm(final)=11.084 | 5451.0 samples/s | 85.2 steps/s
[Step=88050 Epoch=834.4] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.525 | L2-Norm(final)=11.094 | 4079.0 samples/s | 63.7 steps/s
[Step=88100 Epoch=834.8] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.532 | L2-Norm(final)=11.105 | 7466.6 samples/s | 116.7 steps/s
[Step=88150 Epoch=835.3] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=11.114 | 2176.6 samples/s | 34.0 steps/s
[Step=88200 Epoch=835.8] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.541 | L2-Norm(final)=11.122 | 6372.3 samples/s | 99.6 steps/s
[Step=88250 Epoch=836.2] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.545 | L2-Norm(final)=11.130 | 2218.4 samples/s | 34.7 steps/s
[Step=88300 Epoch=836.7] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.548 | L2-Norm(final)=11.136 | 5727.0 samples/s | 89.5 steps/s
[Step=88350 Epoch=837.2] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.551 | L2-Norm(final)=11.142 | 2238.2 samples/s | 35.0 steps/s
[Step=88400 Epoch=837.7] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.553 | L2-Norm(final)=11.148 | 5398.8 samples/s | 84.4 steps/s
[Step=88450 Epoch=838.1] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.556 | L2-Norm(final)=11.154 | 2393.2 samples/s | 37.4 steps/s
[Step=88500 Epoch=838.6] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.558 | L2-Norm(final)=11.159 | 4829.3 samples/s | 75.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=838.6] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.580 | L2-Norm(final)=11.212 | 5228.1 samples/s | 81.7 steps/s
[Step=88550 Epoch=839.1] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.582 | L2-Norm(final)=11.217 | 3823.7 samples/s | 59.7 steps/s
[Step=88600 Epoch=839.6] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.584 | L2-Norm(final)=11.222 | 6169.4 samples/s | 96.4 steps/s
[Step=88650 Epoch=840.0] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.582 | L2-Norm(final)=11.225 | 2007.4 samples/s | 31.4 steps/s
[Step=88700 Epoch=840.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.579 | L2-Norm(final)=11.227 | 5531.8 samples/s | 86.4 steps/s
[Step=88750 Epoch=841.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.574 | L2-Norm(final)=11.228 | 2111.9 samples/s | 33.0 steps/s
[Step=88800 Epoch=841.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.568 | L2-Norm(final)=11.229 | 5164.9 samples/s | 80.7 steps/s
[Step=88850 Epoch=841.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.562 | L2-Norm(final)=11.230 | 2169.9 samples/s | 33.9 steps/s
[Step=88900 Epoch=842.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.556 | L2-Norm(final)=11.231 | 4610.2 samples/s | 72.0 steps/s
[Step=88950 Epoch=842.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.550 | L2-Norm(final)=11.232 | 2257.0 samples/s | 35.3 steps/s
[Step=89000 Epoch=843.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=11.233 | 4380.4 samples/s | 68.4 steps/s
[Step=89050 Epoch=843.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=11.233 | 2337.4 samples/s | 36.5 steps/s
[Step=89100 Epoch=844.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.530 | L2-Norm(final)=11.234 | 4272.9 samples/s | 66.8 steps/s
[Step=89150 Epoch=844.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.523 | L2-Norm(final)=11.235 | 2393.0 samples/s | 37.4 steps/s
[Step=89200 Epoch=845.2] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.516 | L2-Norm(final)=11.235 | 4180.4 samples/s | 65.3 steps/s
[Step=89250 Epoch=845.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=11.236 | 2397.9 samples/s | 37.5 steps/s
[Step=89300 Epoch=846.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.502 | L2-Norm(final)=11.237 | 4226.9 samples/s | 66.0 steps/s
[Step=89350 Epoch=846.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.495 | L2-Norm(final)=11.237 | 2640.2 samples/s | 41.3 steps/s
[Step=89400 Epoch=847.1] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.487 | L2-Norm(final)=11.238 | 3709.2 samples/s | 58.0 steps/s
[Step=89450 Epoch=847.6] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.480 | L2-Norm(final)=11.239 | 6504.1 samples/s | 101.6 steps/s
[Step=89500 Epoch=848.1] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.472 | L2-Norm(final)=11.239 | 1976.4 samples/s | 30.9 steps/s
[Step=89550 Epoch=848.6] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.465 | L2-Norm(final)=11.240 | 5884.4 samples/s | 91.9 steps/s
[Step=89600 Epoch=849.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.457 | L2-Norm(final)=11.241 | 2083.7 samples/s | 32.6 steps/s
[Step=89650 Epoch=849.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.449 | L2-Norm(final)=11.241 | 5299.8 samples/s | 82.8 steps/s
[Step=89700 Epoch=850.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.441 | L2-Norm(final)=11.242 | 2160.7 samples/s | 33.8 steps/s
[Step=89750 Epoch=850.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.433 | L2-Norm(final)=11.243 | 4843.0 samples/s | 75.7 steps/s
[Step=89800 Epoch=850.9] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.425 | L2-Norm(final)=11.244 | 2180.8 samples/s | 34.1 steps/s
[Step=89850 Epoch=851.4] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.417 | L2-Norm(final)=11.244 | 4494.4 samples/s | 70.2 steps/s
[Step=89900 Epoch=851.9] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.409 | L2-Norm(final)=11.245 | 2368.8 samples/s | 37.0 steps/s
[Step=89950 Epoch=852.4] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.400 | L2-Norm(final)=11.246 | 4215.9 samples/s | 65.9 steps/s
[Step=90000 Epoch=852.8] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.392 | L2-Norm(final)=11.247 | 2371.2 samples/s | 37.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step90000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=837.1] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.495 | L2-Norm(final)=12.296 | 5275.6 samples/s | 82.4 steps/s
[Step=88050 Epoch=837.6] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.496 | L2-Norm(final)=12.307 | 4156.5 samples/s | 64.9 steps/s
[Step=88100 Epoch=838.0] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=12.319 | 7434.7 samples/s | 116.2 steps/s
[Step=88150 Epoch=838.5] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.505 | L2-Norm(final)=12.330 | 2137.7 samples/s | 33.4 steps/s
[Step=88200 Epoch=839.0] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=12.339 | 6699.3 samples/s | 104.7 steps/s
[Step=88250 Epoch=839.5] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.512 | L2-Norm(final)=12.348 | 2234.5 samples/s | 34.9 steps/s
[Step=88300 Epoch=840.0] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.515 | L2-Norm(final)=12.356 | 5916.9 samples/s | 92.5 steps/s
[Step=88350 Epoch=840.4] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.518 | L2-Norm(final)=12.363 | 2269.7 samples/s | 35.5 steps/s
[Step=88400 Epoch=840.9] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.520 | L2-Norm(final)=12.370 | 5327.9 samples/s | 83.2 steps/s
[Step=88450 Epoch=841.4] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.522 | L2-Norm(final)=12.377 | 2392.5 samples/s | 37.4 steps/s
[Step=88500 Epoch=841.9] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=12.383 | 4949.3 samples/s | 77.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=841.9] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.446 | 5406.4 samples/s | 84.5 steps/s
[Step=88550 Epoch=842.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.452 | 3755.3 samples/s | 58.7 steps/s
[Step=88600 Epoch=842.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.531 | L2-Norm(final)=12.455 | 6137.9 samples/s | 95.9 steps/s
[Step=88650 Epoch=843.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.517 | L2-Norm(final)=12.457 | 2014.4 samples/s | 31.5 steps/s
[Step=88700 Epoch=843.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=12.458 | 5575.0 samples/s | 87.1 steps/s
[Step=88750 Epoch=844.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.487 | L2-Norm(final)=12.460 | 2110.5 samples/s | 33.0 steps/s
[Step=88800 Epoch=844.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.471 | L2-Norm(final)=12.461 | 5092.3 samples/s | 79.6 steps/s
[Step=88850 Epoch=845.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.455 | L2-Norm(final)=12.462 | 2158.4 samples/s | 33.7 steps/s
[Step=88900 Epoch=845.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.463 | 4743.9 samples/s | 74.1 steps/s
[Step=88950 Epoch=846.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.422 | L2-Norm(final)=12.464 | 2215.5 samples/s | 34.6 steps/s
[Step=89000 Epoch=846.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.406 | L2-Norm(final)=12.465 | 4354.0 samples/s | 68.0 steps/s
[Step=89050 Epoch=847.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.389 | L2-Norm(final)=12.466 | 2317.0 samples/s | 36.2 steps/s
[Step=89100 Epoch=847.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.467 | 4326.3 samples/s | 67.6 steps/s
[Step=89150 Epoch=848.0] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.356 | L2-Norm(final)=12.468 | 2383.3 samples/s | 37.2 steps/s
[Step=89200 Epoch=848.5] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.339 | L2-Norm(final)=12.470 | 4160.4 samples/s | 65.0 steps/s
[Step=89250 Epoch=849.0] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.322 | L2-Norm(final)=12.471 | 2342.2 samples/s | 36.6 steps/s
[Step=89300 Epoch=849.5] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.305 | L2-Norm(final)=12.472 | 4253.3 samples/s | 66.5 steps/s
[Step=89350 Epoch=849.9] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.288 | L2-Norm(final)=12.473 | 2420.5 samples/s | 37.8 steps/s
[Step=89400 Epoch=850.4] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.271 | L2-Norm(final)=12.474 | 4064.0 samples/s | 63.5 steps/s
[Step=89450 Epoch=850.9] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.254 | L2-Norm(final)=12.476 | 6555.5 samples/s | 102.4 steps/s
[Step=89500 Epoch=851.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.237 | L2-Norm(final)=12.477 | 1975.2 samples/s | 30.9 steps/s
[Step=89550 Epoch=851.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.220 | L2-Norm(final)=12.478 | 5844.2 samples/s | 91.3 steps/s
[Step=89600 Epoch=852.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=12.480 | 2102.7 samples/s | 32.9 steps/s
[Step=89650 Epoch=852.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.186 | L2-Norm(final)=12.481 | 5239.3 samples/s | 81.9 steps/s
[Step=89700 Epoch=853.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.169 | L2-Norm(final)=12.483 | 2142.2 samples/s | 33.5 steps/s
[Step=89750 Epoch=853.7] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.152 | L2-Norm(final)=12.484 | 4823.2 samples/s | 75.4 steps/s
[Step=89800 Epoch=854.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.135 | L2-Norm(final)=12.486 | 2196.4 samples/s | 34.3 steps/s
[Step=89850 Epoch=854.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.118 | L2-Norm(final)=12.487 | 4484.9 samples/s | 70.1 steps/s
[Step=89900 Epoch=855.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.101 | L2-Norm(final)=12.489 | 2316.2 samples/s | 36.2 steps/s
[Step=89950 Epoch=855.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.083 | L2-Norm(final)=12.490 | 4247.2 samples/s | 66.4 steps/s
[Step=90000 Epoch=856.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.066 | L2-Norm(final)=12.492 | 2400.3 samples/s | 37.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step90000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=840.4] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.659 | 4987.4 samples/s | 77.9 steps/s
[Step=88050 Epoch=840.8] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.663 | 4156.3 samples/s | 64.9 steps/s
[Step=88100 Epoch=841.3] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.499 | L2-Norm(final)=11.668 | 7667.8 samples/s | 119.8 steps/s
[Step=88150 Epoch=841.8] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=11.673 | 2147.3 samples/s | 33.6 steps/s
[Step=88200 Epoch=842.3] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=11.678 | 6609.9 samples/s | 103.3 steps/s
[Step=88250 Epoch=842.7] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.505 | L2-Norm(final)=11.683 | 2178.1 samples/s | 34.0 steps/s
[Step=88300 Epoch=843.2] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.687 | 6234.3 samples/s | 97.4 steps/s
[Step=88350 Epoch=843.7] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=11.692 | 2271.6 samples/s | 35.5 steps/s
[Step=88400 Epoch=844.2] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.511 | L2-Norm(final)=11.696 | 5596.1 samples/s | 87.4 steps/s
[Step=88450 Epoch=844.6] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.512 | L2-Norm(final)=11.701 | 2345.7 samples/s | 36.7 steps/s
[Step=88500 Epoch=845.1] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.514 | L2-Norm(final)=11.705 | 5232.3 samples/s | 81.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=845.1] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.530 | L2-Norm(final)=11.747 | 5363.9 samples/s | 83.8 steps/s
[Step=88550 Epoch=845.6] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.751 | 3824.5 samples/s | 59.8 steps/s
[Step=88600 Epoch=846.1] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.755 | 6331.3 samples/s | 98.9 steps/s
[Step=88650 Epoch=846.6] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.758 | 2010.7 samples/s | 31.4 steps/s
[Step=88700 Epoch=847.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=11.760 | 5883.2 samples/s | 91.9 steps/s
[Step=88750 Epoch=847.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.529 | L2-Norm(final)=11.761 | 2068.9 samples/s | 32.3 steps/s
[Step=88800 Epoch=848.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.525 | L2-Norm(final)=11.762 | 5379.8 samples/s | 84.1 steps/s
[Step=88850 Epoch=848.5] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.520 | L2-Norm(final)=11.763 | 2137.7 samples/s | 33.4 steps/s
[Step=88900 Epoch=848.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.514 | L2-Norm(final)=11.763 | 4881.4 samples/s | 76.3 steps/s
[Step=88950 Epoch=849.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=11.764 | 2202.6 samples/s | 34.4 steps/s
[Step=89000 Epoch=849.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=11.765 | 4662.0 samples/s | 72.8 steps/s
[Step=89050 Epoch=850.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.765 | 2305.4 samples/s | 36.0 steps/s
[Step=89100 Epoch=850.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.491 | L2-Norm(final)=11.766 | 4330.2 samples/s | 67.7 steps/s
[Step=89150 Epoch=851.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.484 | L2-Norm(final)=11.766 | 2348.7 samples/s | 36.7 steps/s
[Step=89200 Epoch=851.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.478 | L2-Norm(final)=11.767 | 4245.5 samples/s | 66.3 steps/s
[Step=89250 Epoch=852.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.472 | L2-Norm(final)=11.767 | 2389.3 samples/s | 37.3 steps/s
[Step=89300 Epoch=852.8] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.465 | L2-Norm(final)=11.768 | 4344.3 samples/s | 67.9 steps/s
[Step=89350 Epoch=853.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.458 | L2-Norm(final)=11.768 | 2417.8 samples/s | 37.8 steps/s
[Step=89400 Epoch=853.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.451 | L2-Norm(final)=11.769 | 4222.0 samples/s | 66.0 steps/s
[Step=89450 Epoch=854.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.445 | L2-Norm(final)=11.770 | 2378.9 samples/s | 37.2 steps/s
[Step=89500 Epoch=854.7] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.438 | L2-Norm(final)=11.770 | 4263.5 samples/s | 66.6 steps/s
[Step=89550 Epoch=855.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.431 | L2-Norm(final)=11.771 | 6992.3 samples/s | 109.3 steps/s
[Step=89600 Epoch=855.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.423 | L2-Norm(final)=11.771 | 1945.9 samples/s | 30.4 steps/s
[Step=89650 Epoch=856.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.416 | L2-Norm(final)=11.772 | 6387.2 samples/s | 99.8 steps/s
[Step=89700 Epoch=856.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.409 | L2-Norm(final)=11.772 | 2006.6 samples/s | 31.4 steps/s
[Step=89750 Epoch=857.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.401 | L2-Norm(final)=11.773 | 5841.7 samples/s | 91.3 steps/s
[Step=89800 Epoch=857.5] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.394 | L2-Norm(final)=11.773 | 2078.5 samples/s | 32.5 steps/s
[Step=89850 Epoch=858.0] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.386 | L2-Norm(final)=11.774 | 5354.3 samples/s | 83.7 steps/s
[Step=89900 Epoch=858.5] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=11.775 | 2146.4 samples/s | 33.5 steps/s
[Step=89950 Epoch=859.0] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=11.775 | 4864.0 samples/s | 76.0 steps/s
[Step=90000 Epoch=859.4] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.363 | L2-Norm(final)=11.776 | 2252.4 samples/s | 35.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step90000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=829.2] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.751 | L2-Norm(final)=11.406 | 5284.4 samples/s | 82.6 steps/s
[Step=88050 Epoch=829.7] | Loss=0.00010 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.754 | L2-Norm(final)=11.408 | 4149.9 samples/s | 64.8 steps/s
[Step=88100 Epoch=830.2] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.757 | L2-Norm(final)=11.412 | 7392.2 samples/s | 115.5 steps/s
[Step=88150 Epoch=830.6] | Loss=0.00008 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.759 | L2-Norm(final)=11.416 | 2162.6 samples/s | 33.8 steps/s
[Step=88200 Epoch=831.1] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.761 | L2-Norm(final)=11.420 | 6123.4 samples/s | 95.7 steps/s
[Step=88250 Epoch=831.6] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.763 | L2-Norm(final)=11.424 | 2239.7 samples/s | 35.0 steps/s
[Step=88300 Epoch=832.0] | Loss=0.00007 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.765 | L2-Norm(final)=11.427 | 5670.6 samples/s | 88.6 steps/s
[Step=88350 Epoch=832.5] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.766 | L2-Norm(final)=11.431 | 2326.1 samples/s | 36.3 steps/s
[Step=88400 Epoch=833.0] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.768 | L2-Norm(final)=11.434 | 5073.3 samples/s | 79.3 steps/s
[Step=88450 Epoch=833.5] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.769 | L2-Norm(final)=11.437 | 2495.9 samples/s | 39.0 steps/s
[Step=88500 Epoch=833.9] | Loss=0.00006 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.771 | L2-Norm(final)=11.440 | 4676.9 samples/s | 73.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=833.9] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=11.472 | 5222.9 samples/s | 81.6 steps/s
[Step=88550 Epoch=834.4] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.786 | L2-Norm(final)=11.475 | 4019.4 samples/s | 62.8 steps/s
[Step=88600 Epoch=834.9] | Loss=0.00004 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.787 | L2-Norm(final)=11.478 | 6066.5 samples/s | 94.8 steps/s
[Step=88650 Epoch=835.3] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.788 | L2-Norm(final)=11.480 | 2024.6 samples/s | 31.6 steps/s
[Step=88700 Epoch=835.8] | Loss=0.00003 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.787 | L2-Norm(final)=11.482 | 5483.1 samples/s | 85.7 steps/s
[Step=88750 Epoch=836.3] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.787 | L2-Norm(final)=11.483 | 2138.3 samples/s | 33.4 steps/s
[Step=88800 Epoch=836.7] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.786 | L2-Norm(final)=11.484 | 4898.9 samples/s | 76.5 steps/s
[Step=88850 Epoch=837.2] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.785 | L2-Norm(final)=11.485 | 2231.4 samples/s | 34.9 steps/s
[Step=88900 Epoch=837.7] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=11.486 | 4459.5 samples/s | 69.7 steps/s
[Step=88950 Epoch=838.2] | Loss=0.00002 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.783 | L2-Norm(final)=11.487 | 2318.5 samples/s | 36.2 steps/s
[Step=89000 Epoch=838.6] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=11.488 | 4260.8 samples/s | 66.6 steps/s
[Step=89050 Epoch=839.1] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=11.489 | 2426.6 samples/s | 37.9 steps/s
[Step=89100 Epoch=839.6] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.778 | L2-Norm(final)=11.490 | 4177.5 samples/s | 65.3 steps/s
[Step=89150 Epoch=840.0] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.776 | L2-Norm(final)=11.490 | 2406.0 samples/s | 37.6 steps/s
[Step=89200 Epoch=840.5] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.775 | L2-Norm(final)=11.491 | 4219.2 samples/s | 65.9 steps/s
[Step=89250 Epoch=841.0] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.773 | L2-Norm(final)=11.492 | 2532.7 samples/s | 39.6 steps/s
[Step=89300 Epoch=841.5] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.771 | L2-Norm(final)=11.492 | 3964.7 samples/s | 61.9 steps/s
[Step=89350 Epoch=841.9] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.769 | L2-Norm(final)=11.493 | 6324.9 samples/s | 98.8 steps/s
[Step=89400 Epoch=842.4] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.767 | L2-Norm(final)=11.494 | 2017.1 samples/s | 31.5 steps/s
[Step=89450 Epoch=842.9] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.765 | L2-Norm(final)=11.494 | 5563.5 samples/s | 86.9 steps/s
[Step=89500 Epoch=843.3] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.763 | L2-Norm(final)=11.495 | 2098.0 samples/s | 32.8 steps/s
[Step=89550 Epoch=843.8] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.761 | L2-Norm(final)=11.496 | 5049.4 samples/s | 78.9 steps/s
[Step=89600 Epoch=844.3] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.759 | L2-Norm(final)=11.496 | 2227.3 samples/s | 34.8 steps/s
[Step=89650 Epoch=844.8] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.756 | L2-Norm(final)=11.497 | 4475.8 samples/s | 69.9 steps/s
[Step=89700 Epoch=845.2] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.754 | L2-Norm(final)=11.497 | 2339.9 samples/s | 36.6 steps/s
[Step=89750 Epoch=845.7] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.752 | L2-Norm(final)=11.498 | 4163.0 samples/s | 65.0 steps/s
[Step=89800 Epoch=846.2] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.750 | L2-Norm(final)=11.499 | 2420.3 samples/s | 37.8 steps/s
[Step=89850 Epoch=846.6] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.747 | L2-Norm(final)=11.499 | 4046.9 samples/s | 63.2 steps/s
[Step=89900 Epoch=847.1] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.745 | L2-Norm(final)=11.500 | 2402.8 samples/s | 37.5 steps/s
[Step=89950 Epoch=847.6] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.742 | L2-Norm(final)=11.500 | 4227.2 samples/s | 66.1 steps/s
[Step=90000 Epoch=848.1] | Loss=0.00001 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.740 | L2-Norm(final)=11.501 | 2589.6 samples/s | 40.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step90000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=838.7] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.654 | L2-Norm(final)=12.232 | 4936.1 samples/s | 77.1 steps/s
[Step=88050 Epoch=839.2] | Loss=0.00010 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.657 | L2-Norm(final)=12.232 | 4121.3 samples/s | 64.4 steps/s
[Step=88100 Epoch=839.7] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.658 | L2-Norm(final)=12.234 | 7545.2 samples/s | 117.9 steps/s
[Step=88150 Epoch=840.1] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.659 | L2-Norm(final)=12.236 | 2110.7 samples/s | 33.0 steps/s
[Step=88200 Epoch=840.6] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.660 | L2-Norm(final)=12.237 | 6844.6 samples/s | 106.9 steps/s
[Step=88250 Epoch=841.1] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.660 | L2-Norm(final)=12.239 | 2205.5 samples/s | 34.5 steps/s
[Step=88300 Epoch=841.6] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.661 | L2-Norm(final)=12.240 | 6115.8 samples/s | 95.6 steps/s
[Step=88350 Epoch=842.1] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.661 | L2-Norm(final)=12.242 | 2289.7 samples/s | 35.8 steps/s
[Step=88400 Epoch=842.5] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.662 | L2-Norm(final)=12.243 | 5552.9 samples/s | 86.8 steps/s
[Step=88450 Epoch=843.0] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.662 | L2-Norm(final)=12.245 | 2359.0 samples/s | 36.9 steps/s
[Step=88500 Epoch=843.5] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.663 | L2-Norm(final)=12.247 | 5222.1 samples/s | 81.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=843.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.668 | L2-Norm(final)=12.263 | 5694.3 samples/s | 89.0 steps/s
[Step=88550 Epoch=844.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.668 | L2-Norm(final)=12.264 | 3672.5 samples/s | 57.4 steps/s
[Step=88600 Epoch=844.4] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=12.266 | 6271.0 samples/s | 98.0 steps/s
[Step=88650 Epoch=844.9] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=12.267 | 2037.6 samples/s | 31.8 steps/s
[Step=88700 Epoch=845.4] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=12.268 | 5704.2 samples/s | 89.1 steps/s
[Step=88750 Epoch=845.9] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.669 | L2-Norm(final)=12.269 | 2049.8 samples/s | 32.0 steps/s
[Step=88800 Epoch=846.3] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.668 | L2-Norm(final)=12.270 | 5389.0 samples/s | 84.2 steps/s
[Step=88850 Epoch=846.8] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.668 | L2-Norm(final)=12.271 | 2132.0 samples/s | 33.3 steps/s
[Step=88900 Epoch=847.3] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.668 | L2-Norm(final)=12.272 | 4996.9 samples/s | 78.1 steps/s
[Step=88950 Epoch=847.8] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.667 | L2-Norm(final)=12.273 | 2216.5 samples/s | 34.6 steps/s
[Step=89000 Epoch=848.3] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.667 | L2-Norm(final)=12.273 | 4588.2 samples/s | 71.7 steps/s
[Step=89050 Epoch=848.7] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.666 | L2-Norm(final)=12.274 | 2257.2 samples/s | 35.3 steps/s
[Step=89100 Epoch=849.2] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.665 | L2-Norm(final)=12.275 | 4361.1 samples/s | 68.1 steps/s
[Step=89150 Epoch=849.7] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.665 | L2-Norm(final)=12.276 | 2365.5 samples/s | 37.0 steps/s
[Step=89200 Epoch=850.2] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.664 | L2-Norm(final)=12.276 | 4220.0 samples/s | 65.9 steps/s
[Step=89250 Epoch=850.6] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.663 | L2-Norm(final)=12.277 | 2358.9 samples/s | 36.9 steps/s
[Step=89300 Epoch=851.1] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.663 | L2-Norm(final)=12.278 | 4295.5 samples/s | 67.1 steps/s
[Step=89350 Epoch=851.6] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.662 | L2-Norm(final)=12.278 | 2346.5 samples/s | 36.7 steps/s
[Step=89400 Epoch=852.1] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.661 | L2-Norm(final)=12.279 | 4198.6 samples/s | 65.6 steps/s
[Step=89450 Epoch=852.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.660 | L2-Norm(final)=12.280 | 2383.0 samples/s | 37.2 steps/s
[Step=89500 Epoch=853.0] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.659 | L2-Norm(final)=12.280 | 4274.4 samples/s | 66.8 steps/s
[Step=89550 Epoch=853.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.658 | L2-Norm(final)=12.281 | 6906.2 samples/s | 107.9 steps/s
[Step=89600 Epoch=854.0] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.657 | L2-Norm(final)=12.282 | 1936.5 samples/s | 30.3 steps/s
[Step=89650 Epoch=854.4] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.656 | L2-Norm(final)=12.282 | 6336.8 samples/s | 99.0 steps/s
[Step=89700 Epoch=854.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.655 | L2-Norm(final)=12.283 | 2007.2 samples/s | 31.4 steps/s
[Step=89750 Epoch=855.4] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.654 | L2-Norm(final)=12.283 | 5800.2 samples/s | 90.6 steps/s
[Step=89800 Epoch=855.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.653 | L2-Norm(final)=12.284 | 2087.5 samples/s | 32.6 steps/s
[Step=89850 Epoch=856.4] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.652 | L2-Norm(final)=12.285 | 5372.2 samples/s | 83.9 steps/s
[Step=89900 Epoch=856.8] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.650 | L2-Norm(final)=12.285 | 2123.5 samples/s | 33.2 steps/s
[Step=89950 Epoch=857.3] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.649 | L2-Norm(final)=12.286 | 4991.1 samples/s | 78.0 steps/s
[Step=90000 Epoch=857.8] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.648 | L2-Norm(final)=12.286 | 2241.0 samples/s | 35.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10284 | acc=0.9555 | tpr=0.9668 | fpr=0.0691 | 4760.4 samples/s | 18.6 steps/s
Avg test loss: 0.10673, Avg test acc: 0.95356, Avg tpr: 0.96561, Avg fpr: 0.07294, total FA: 569

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10957 | acc=0.9548 | tpr=0.9733 | fpr=0.0855 | 4865.2 samples/s | 19.0 steps/s
Avg test loss: 0.10852, Avg test acc: 0.95512, Avg tpr: 0.97325, Avg fpr: 0.08473, total FA: 661

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10370 | acc=0.9559 | tpr=0.9691 | fpr=0.0726 | 4939.7 samples/s | 19.3 steps/s
Avg test loss: 0.10594, Avg test acc: 0.95436, Avg tpr: 0.96707, Avg fpr: 0.07358, total FA: 574

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09721 | acc=0.9576 | tpr=0.9701 | fpr=0.0696 | 4723.7 samples/s | 18.5 steps/s
Avg test loss: 0.10338, Avg test acc: 0.95597, Avg tpr: 0.97057, Avg fpr: 0.07614, total FA: 594

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10681 | acc=0.9555 | tpr=0.9681 | fpr=0.0716 | 4792.6 samples/s | 18.7 steps/s
Avg test loss: 0.11081, Avg test acc: 0.95384, Avg tpr: 0.96689, Avg fpr: 0.07486, total FA: 584

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.45817 | acc=0.3005 | tpr=0.0066 | fpr=0.0614 | 4847.1 samples/s | 18.9 steps/s
Avg test loss: 5.46428, Avg test acc: 0.29894, Avg tpr: 0.00769, Avg fpr: 0.06051, total FA: 472

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.83471 | acc=0.3079 | tpr=0.0023 | fpr=0.0285 | 4812.5 samples/s | 18.8 steps/s
Avg test loss: 4.84962, Avg test acc: 0.30471, Avg tpr: 0.00216, Avg fpr: 0.02987, total FA: 233

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.16868 | acc=0.2968 | tpr=0.0058 | fpr=0.0714 | 4818.3 samples/s | 18.8 steps/s
Avg test loss: 5.17417, Avg test acc: 0.29457, Avg tpr: 0.00688, Avg fpr: 0.07268, total FA: 567

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.59813 | acc=0.3002 | tpr=0.0130 | fpr=0.0763 | 4633.3 samples/s | 18.1 steps/s
Avg test loss: 5.59932, Avg test acc: 0.29898, Avg tpr: 0.01434, Avg fpr: 0.07499, total FA: 585

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.99155 | acc=0.3042 | tpr=0.0134 | fpr=0.0642 | 4847.7 samples/s | 18.9 steps/s
Avg test loss: 4.99891, Avg test acc: 0.30147, Avg tpr: 0.01317, Avg fpr: 0.06448, total FA: 503

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.68004 | acc=0.1095 | tpr=0.5133 | fpr=0.8978 | 4777.3 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.64946 | acc=0.1117 | tpr=0.4989 | fpr=0.8955 | 7097.2 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.65929 | acc=0.1116 | tpr=0.4971 | fpr=0.8955 | 8059.3 samples/s | 31.5 steps/s
[Step= 200] | Loss=5.65088 | acc=0.1117 | tpr=0.4896 | fpr=0.8952 | 7781.1 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.65472 | acc=0.1126 | tpr=0.5031 | fpr=0.8945 | 8001.5 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.64998 | acc=0.1126 | tpr=0.5098 | fpr=0.8947 | 7834.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.64110 | acc=0.1128 | tpr=0.5059 | fpr=0.8944 | 7752.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.63986 | acc=0.1128 | tpr=0.5049 | fpr=0.8944 | 8105.3 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.64502 | acc=0.1132 | tpr=0.5034 | fpr=0.8939 | 7640.7 samples/s | 29.8 steps/s
[Step= 500] | Loss=5.64682 | acc=0.1133 | tpr=0.4960 | fpr=0.8936 | 8167.9 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.65001 | acc=0.1132 | tpr=0.4914 | fpr=0.8937 | 13575.4 samples/s | 53.0 steps/s
Avg test loss: 5.65168, Avg test acc: 0.11308, Avg tpr: 0.49168, Avg fpr: 0.89380, total FA: 124103

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.60591 | acc=0.0909 | tpr=0.4735 | fpr=0.9160 | 4709.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.59066 | acc=0.0903 | tpr=0.4861 | fpr=0.9171 | 7485.1 samples/s | 29.2 steps/s
[Step= 150] | Loss=5.58994 | acc=0.0907 | tpr=0.4942 | fpr=0.9168 | 7669.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.58265 | acc=0.0899 | tpr=0.4874 | fpr=0.9173 | 7846.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.58644 | acc=0.0903 | tpr=0.4934 | fpr=0.9170 | 8015.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.58229 | acc=0.0904 | tpr=0.4989 | fpr=0.9170 | 7831.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.57626 | acc=0.0904 | tpr=0.4991 | fpr=0.9170 | 7843.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.57362 | acc=0.0903 | tpr=0.4962 | fpr=0.9171 | 7937.0 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.57858 | acc=0.0905 | tpr=0.4971 | fpr=0.9168 | 7488.8 samples/s | 29.3 steps/s
[Step= 500] | Loss=5.58245 | acc=0.0907 | tpr=0.4952 | fpr=0.9166 | 8168.6 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.58836 | acc=0.0903 | tpr=0.4903 | fpr=0.9170 | 12607.2 samples/s | 49.2 steps/s
Avg test loss: 5.59050, Avg test acc: 0.09021, Avg tpr: 0.49049, Avg fpr: 0.91707, total FA: 127333

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.44645 | acc=0.1122 | tpr=0.2743 | fpr=0.8907 | 4629.0 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.41278 | acc=0.1147 | tpr=0.2772 | fpr=0.8883 | 7221.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=5.42569 | acc=0.1158 | tpr=0.2767 | fpr=0.8872 | 7900.9 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.41805 | acc=0.1164 | tpr=0.2667 | fpr=0.8863 | 7868.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.41930 | acc=0.1168 | tpr=0.2725 | fpr=0.8860 | 7923.6 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.41396 | acc=0.1173 | tpr=0.2807 | fpr=0.8856 | 7445.1 samples/s | 29.1 steps/s
[Step= 350] | Loss=5.40754 | acc=0.1178 | tpr=0.2805 | fpr=0.8852 | 7708.6 samples/s | 30.1 steps/s
[Step= 400] | Loss=5.40657 | acc=0.1178 | tpr=0.2828 | fpr=0.8852 | 8211.6 samples/s | 32.1 steps/s
[Step= 450] | Loss=5.41257 | acc=0.1179 | tpr=0.2790 | fpr=0.8850 | 7804.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=5.41343 | acc=0.1179 | tpr=0.2784 | fpr=0.8850 | 7708.1 samples/s | 30.1 steps/s
[Step= 550] | Loss=5.41673 | acc=0.1176 | tpr=0.2801 | fpr=0.8853 | 13997.1 samples/s | 54.7 steps/s
Avg test loss: 5.41824, Avg test acc: 0.11749, Avg tpr: 0.28090, Avg fpr: 0.88548, total FA: 122947

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.59507 | acc=0.1105 | tpr=0.5088 | fpr=0.8967 | 4676.3 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.56954 | acc=0.1104 | tpr=0.5032 | fpr=0.8970 | 7234.6 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.58287 | acc=0.1095 | tpr=0.5101 | fpr=0.8979 | 7777.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.57313 | acc=0.1087 | tpr=0.5005 | fpr=0.8985 | 7811.8 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.57864 | acc=0.1092 | tpr=0.5031 | fpr=0.8980 | 7800.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.57748 | acc=0.1095 | tpr=0.5127 | fpr=0.8979 | 7794.6 samples/s | 30.4 steps/s
[Step= 350] | Loss=5.56768 | acc=0.1098 | tpr=0.5116 | fpr=0.8975 | 7883.4 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.56509 | acc=0.1097 | tpr=0.5088 | fpr=0.8975 | 7768.5 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.57038 | acc=0.1097 | tpr=0.5049 | fpr=0.8974 | 7787.5 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.57128 | acc=0.1098 | tpr=0.5009 | fpr=0.8973 | 7723.4 samples/s | 30.2 steps/s
[Step= 550] | Loss=5.57648 | acc=0.1093 | tpr=0.4942 | fpr=0.8977 | 14128.8 samples/s | 55.2 steps/s
Avg test loss: 5.57784, Avg test acc: 0.10917, Avg tpr: 0.49445, Avg fpr: 0.89784, total FA: 124663

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.72514 | acc=0.1177 | tpr=0.4204 | fpr=0.8878 | 4801.6 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.70167 | acc=0.1203 | tpr=0.4179 | fpr=0.8853 | 6979.3 samples/s | 27.3 steps/s
[Step= 150] | Loss=5.69981 | acc=0.1204 | tpr=0.4193 | fpr=0.8851 | 7891.1 samples/s | 30.8 steps/s
[Step= 200] | Loss=5.69290 | acc=0.1204 | tpr=0.4131 | fpr=0.8849 | 7405.9 samples/s | 28.9 steps/s
[Step= 250] | Loss=5.69495 | acc=0.1214 | tpr=0.4227 | fpr=0.8841 | 8037.8 samples/s | 31.4 steps/s
[Step= 300] | Loss=5.69606 | acc=0.1212 | tpr=0.4269 | fpr=0.8844 | 7833.3 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.68701 | acc=0.1216 | tpr=0.4283 | fpr=0.8840 | 7852.4 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.68668 | acc=0.1212 | tpr=0.4261 | fpr=0.8843 | 7763.7 samples/s | 30.3 steps/s
[Step= 450] | Loss=5.69210 | acc=0.1216 | tpr=0.4245 | fpr=0.8839 | 7890.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.69406 | acc=0.1214 | tpr=0.4225 | fpr=0.8841 | 8000.9 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.69898 | acc=0.1211 | tpr=0.4226 | fpr=0.8844 | 13388.1 samples/s | 52.3 steps/s
Avg test loss: 5.70110, Avg test acc: 0.12091, Avg tpr: 0.42195, Avg fpr: 0.88456, total FA: 122820

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08804 | acc=0.9821 | tpr=0.9558 | fpr=0.0174 | 4686.7 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.08910 | acc=0.9822 | tpr=0.9595 | fpr=0.0174 | 7183.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.09280 | acc=0.9811 | tpr=0.9611 | fpr=0.0185 | 7802.8 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.09464 | acc=0.9814 | tpr=0.9650 | fpr=0.0183 | 7828.1 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.09340 | acc=0.9816 | tpr=0.9616 | fpr=0.0180 | 7924.2 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.09542 | acc=0.9813 | tpr=0.9615 | fpr=0.0184 | 7828.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.09632 | acc=0.9810 | tpr=0.9612 | fpr=0.0186 | 8153.5 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.09739 | acc=0.9807 | tpr=0.9562 | fpr=0.0189 | 7813.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.09946 | acc=0.9803 | tpr=0.9513 | fpr=0.0191 | 7756.4 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.09875 | acc=0.9804 | tpr=0.9515 | fpr=0.0191 | 7468.7 samples/s | 29.2 steps/s
[Step= 550] | Loss=0.09816 | acc=0.9805 | tpr=0.9499 | fpr=0.0189 | 14415.8 samples/s | 56.3 steps/s
Avg test loss: 0.09803, Avg test acc: 0.98053, Avg tpr: 0.95008, Avg fpr: 0.01892, total FA: 2627

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07846 | acc=0.9830 | tpr=0.9204 | fpr=0.0158 | 4771.1 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.08111 | acc=0.9829 | tpr=0.9232 | fpr=0.0160 | 6920.8 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.08453 | acc=0.9826 | tpr=0.9280 | fpr=0.0164 | 7729.3 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.08675 | acc=0.9826 | tpr=0.9366 | fpr=0.0166 | 8017.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.08535 | acc=0.9829 | tpr=0.9371 | fpr=0.0163 | 7815.4 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.08698 | acc=0.9826 | tpr=0.9367 | fpr=0.0166 | 7714.7 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.08758 | acc=0.9824 | tpr=0.9374 | fpr=0.0167 | 7599.8 samples/s | 29.7 steps/s
[Step= 400] | Loss=0.08858 | acc=0.9823 | tpr=0.9322 | fpr=0.0168 | 7762.5 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.09056 | acc=0.9820 | tpr=0.9299 | fpr=0.0171 | 8152.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.08991 | acc=0.9820 | tpr=0.9313 | fpr=0.0171 | 7698.9 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.08959 | acc=0.9822 | tpr=0.9288 | fpr=0.0169 | 14104.8 samples/s | 55.1 steps/s
Avg test loss: 0.08947, Avg test acc: 0.98215, Avg tpr: 0.92868, Avg fpr: 0.01687, total FA: 2343

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08314 | acc=0.9816 | tpr=0.9690 | fpr=0.0181 | 4705.4 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.08471 | acc=0.9814 | tpr=0.9723 | fpr=0.0184 | 7041.9 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.08893 | acc=0.9807 | tpr=0.9683 | fpr=0.0191 | 7842.6 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.09028 | acc=0.9809 | tpr=0.9727 | fpr=0.0190 | 8092.8 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.08890 | acc=0.9812 | tpr=0.9712 | fpr=0.0186 | 7565.8 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.09083 | acc=0.9809 | tpr=0.9680 | fpr=0.0189 | 8065.8 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.09158 | acc=0.9806 | tpr=0.9687 | fpr=0.0191 | 7250.8 samples/s | 28.3 steps/s
[Step= 400] | Loss=0.09252 | acc=0.9804 | tpr=0.9655 | fpr=0.0193 | 7841.6 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.09399 | acc=0.9802 | tpr=0.9635 | fpr=0.0195 | 7892.5 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.09352 | acc=0.9801 | tpr=0.9648 | fpr=0.0196 | 7841.6 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.09309 | acc=0.9803 | tpr=0.9630 | fpr=0.0194 | 13244.4 samples/s | 51.7 steps/s
Avg test loss: 0.09299, Avg test acc: 0.98028, Avg tpr: 0.96276, Avg fpr: 0.01940, total FA: 2694

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09463 | acc=0.9802 | tpr=0.9513 | fpr=0.0192 | 4693.2 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.09633 | acc=0.9802 | tpr=0.9574 | fpr=0.0194 | 7254.6 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.10031 | acc=0.9792 | tpr=0.9539 | fpr=0.0203 | 7600.0 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.10148 | acc=0.9795 | tpr=0.9585 | fpr=0.0201 | 8156.3 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.10020 | acc=0.9799 | tpr=0.9581 | fpr=0.0197 | 7614.1 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.10238 | acc=0.9797 | tpr=0.9564 | fpr=0.0199 | 8053.1 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.10317 | acc=0.9795 | tpr=0.9562 | fpr=0.0201 | 7942.4 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.10368 | acc=0.9794 | tpr=0.9535 | fpr=0.0201 | 7956.2 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.10546 | acc=0.9792 | tpr=0.9513 | fpr=0.0203 | 7475.2 samples/s | 29.2 steps/s
[Step= 500] | Loss=0.10470 | acc=0.9793 | tpr=0.9529 | fpr=0.0202 | 8298.7 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.10409 | acc=0.9795 | tpr=0.9526 | fpr=0.0200 | 13447.9 samples/s | 52.5 steps/s
Avg test loss: 0.10391, Avg test acc: 0.97952, Avg tpr: 0.95285, Avg fpr: 0.01999, total FA: 2776

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09535 | acc=0.9808 | tpr=0.9381 | fpr=0.0185 | 4629.0 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.09874 | acc=0.9803 | tpr=0.9467 | fpr=0.0191 | 7512.8 samples/s | 29.3 steps/s
[Step= 150] | Loss=0.10239 | acc=0.9792 | tpr=0.9438 | fpr=0.0202 | 7851.8 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.10378 | acc=0.9793 | tpr=0.9541 | fpr=0.0202 | 7859.8 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.10236 | acc=0.9796 | tpr=0.9511 | fpr=0.0199 | 7486.7 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.10443 | acc=0.9792 | tpr=0.9476 | fpr=0.0202 | 8315.6 samples/s | 32.5 steps/s
[Step= 350] | Loss=0.10507 | acc=0.9790 | tpr=0.9493 | fpr=0.0204 | 7916.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.10636 | acc=0.9787 | tpr=0.9447 | fpr=0.0206 | 7608.2 samples/s | 29.7 steps/s
[Step= 450] | Loss=0.10845 | acc=0.9785 | tpr=0.9426 | fpr=0.0209 | 7874.7 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10795 | acc=0.9785 | tpr=0.9423 | fpr=0.0209 | 7645.8 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.10741 | acc=0.9787 | tpr=0.9427 | fpr=0.0206 | 14880.8 samples/s | 58.1 steps/s
Avg test loss: 0.10729, Avg test acc: 0.97870, Avg tpr: 0.94255, Avg fpr: 0.02064, total FA: 2866

server round 45/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=438.9] | Loss=0.00910 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.872 | L2-Norm(final)=21.467 | 5773.9 samples/s | 90.2 steps/s
[Step=90050 Epoch=439.1] | Loss=0.00772 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.875 | L2-Norm(final)=21.473 | 4407.5 samples/s | 68.9 steps/s
[Step=90100 Epoch=439.3] | Loss=0.00710 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=21.480 | 5187.8 samples/s | 81.1 steps/s
[Step=90150 Epoch=439.6] | Loss=0.00703 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.882 | L2-Norm(final)=21.487 | 4889.9 samples/s | 76.4 steps/s
[Step=90200 Epoch=439.8] | Loss=0.00682 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.885 | L2-Norm(final)=21.494 | 7905.8 samples/s | 123.5 steps/s
[Step=90250 Epoch=440.1] | Loss=0.00688 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=21.500 | 2205.2 samples/s | 34.5 steps/s
[Step=90300 Epoch=440.3] | Loss=0.00659 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.890 | L2-Norm(final)=21.506 | 4955.6 samples/s | 77.4 steps/s
[Step=90350 Epoch=440.6] | Loss=0.00651 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.892 | L2-Norm(final)=21.513 | 5114.5 samples/s | 79.9 steps/s
[Step=90400 Epoch=440.8] | Loss=0.00648 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.895 | L2-Norm(final)=21.519 | 6781.3 samples/s | 106.0 steps/s
[Step=90450 Epoch=441.1] | Loss=0.00640 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.897 | L2-Norm(final)=21.525 | 2321.5 samples/s | 36.3 steps/s
[Step=90500 Epoch=441.3] | Loss=0.00631 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.899 | L2-Norm(final)=21.530 | 4979.1 samples/s | 77.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=441.3] | Loss=0.00860 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=21.589 | 5754.6 samples/s | 89.9 steps/s
[Step=90550 Epoch=441.5] | Loss=0.00667 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.926 | L2-Norm(final)=21.594 | 3892.9 samples/s | 60.8 steps/s
[Step=90600 Epoch=441.8] | Loss=0.00719 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=21.600 | 4412.9 samples/s | 69.0 steps/s
[Step=90650 Epoch=442.0] | Loss=0.00678 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.935 | L2-Norm(final)=21.604 | 4454.7 samples/s | 69.6 steps/s
[Step=90700 Epoch=442.3] | Loss=0.00670 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=21.609 | 6622.5 samples/s | 103.5 steps/s
[Step=90750 Epoch=442.5] | Loss=0.00617 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=21.613 | 2100.9 samples/s | 32.8 steps/s
[Step=90800 Epoch=442.8] | Loss=0.00568 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=21.617 | 4440.4 samples/s | 69.4 steps/s
[Step=90850 Epoch=443.0] | Loss=0.00556 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=21.620 | 4490.0 samples/s | 70.2 steps/s
[Step=90900 Epoch=443.2] | Loss=0.00543 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=21.624 | 5896.1 samples/s | 92.1 steps/s
[Step=90950 Epoch=443.5] | Loss=0.00520 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=21.627 | 2173.2 samples/s | 34.0 steps/s
[Step=91000 Epoch=443.7] | Loss=0.00512 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=21.630 | 4362.9 samples/s | 68.2 steps/s
[Step=91050 Epoch=444.0] | Loss=0.00491 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=21.633 | 4490.4 samples/s | 70.2 steps/s
[Step=91100 Epoch=444.2] | Loss=0.00484 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=21.636 | 5391.1 samples/s | 84.2 steps/s
[Step=91150 Epoch=444.5] | Loss=0.00469 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=21.639 | 2247.0 samples/s | 35.1 steps/s
[Step=91200 Epoch=444.7] | Loss=0.00453 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=21.642 | 4482.4 samples/s | 70.0 steps/s
[Step=91250 Epoch=445.0] | Loss=0.00435 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=21.645 | 4491.9 samples/s | 70.2 steps/s
[Step=91300 Epoch=445.2] | Loss=0.00431 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=21.647 | 4835.7 samples/s | 75.6 steps/s
[Step=91350 Epoch=445.4] | Loss=0.00423 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=21.650 | 2297.2 samples/s | 35.9 steps/s
[Step=91400 Epoch=445.7] | Loss=0.00412 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=21.653 | 4452.2 samples/s | 69.6 steps/s
[Step=91450 Epoch=445.9] | Loss=0.00401 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=21.655 | 4434.2 samples/s | 69.3 steps/s
[Step=91500 Epoch=446.2] | Loss=0.00396 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=21.658 | 4644.4 samples/s | 72.6 steps/s
[Step=91550 Epoch=446.4] | Loss=0.00395 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.964 | L2-Norm(final)=21.660 | 2406.4 samples/s | 37.6 steps/s
[Step=91600 Epoch=446.7] | Loss=0.00387 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=21.663 | 4485.3 samples/s | 70.1 steps/s
[Step=91650 Epoch=446.9] | Loss=0.00380 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=21.665 | 4361.5 samples/s | 68.1 steps/s
[Step=91700 Epoch=447.1] | Loss=0.00379 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=21.667 | 4478.3 samples/s | 70.0 steps/s
[Step=91750 Epoch=447.4] | Loss=0.00376 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=21.670 | 2447.5 samples/s | 38.2 steps/s
[Step=91800 Epoch=447.6] | Loss=0.00373 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.968 | L2-Norm(final)=21.672 | 4462.9 samples/s | 69.7 steps/s
[Step=91850 Epoch=447.9] | Loss=0.00368 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.968 | L2-Norm(final)=21.675 | 4439.0 samples/s | 69.4 steps/s
[Step=91900 Epoch=448.1] | Loss=0.00362 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=21.677 | 4535.4 samples/s | 70.9 steps/s
[Step=91950 Epoch=448.4] | Loss=0.00356 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=21.679 | 2461.8 samples/s | 38.5 steps/s
[Step=92000 Epoch=448.6] | Loss=0.00350 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=21.682 | 4410.6 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step92000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=439.2] | Loss=0.00249 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.464 | L2-Norm(final)=22.387 | 5649.4 samples/s | 88.3 steps/s
[Step=90050 Epoch=439.4] | Loss=0.00660 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.465 | L2-Norm(final)=22.394 | 4274.4 samples/s | 66.8 steps/s
[Step=90100 Epoch=439.6] | Loss=0.00638 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.468 | L2-Norm(final)=22.401 | 5037.6 samples/s | 78.7 steps/s
[Step=90150 Epoch=439.9] | Loss=0.00606 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.471 | L2-Norm(final)=22.409 | 5103.1 samples/s | 79.7 steps/s
[Step=90200 Epoch=440.1] | Loss=0.00583 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.474 | L2-Norm(final)=22.416 | 7795.9 samples/s | 121.8 steps/s
[Step=90250 Epoch=440.4] | Loss=0.00562 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.477 | L2-Norm(final)=22.423 | 2214.8 samples/s | 34.6 steps/s
[Step=90300 Epoch=440.6] | Loss=0.00558 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.479 | L2-Norm(final)=22.430 | 4994.4 samples/s | 78.0 steps/s
[Step=90350 Epoch=440.9] | Loss=0.00553 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.482 | L2-Norm(final)=22.437 | 4925.0 samples/s | 77.0 steps/s
[Step=90400 Epoch=441.1] | Loss=0.00559 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.484 | L2-Norm(final)=22.444 | 7066.4 samples/s | 110.4 steps/s
[Step=90450 Epoch=441.4] | Loss=0.00553 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.487 | L2-Norm(final)=22.450 | 2266.3 samples/s | 35.4 steps/s
[Step=90500 Epoch=441.6] | Loss=0.00549 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.489 | L2-Norm(final)=22.457 | 5034.4 samples/s | 78.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=441.6] | Loss=0.00213 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.512 | L2-Norm(final)=22.521 | 5623.3 samples/s | 87.9 steps/s
[Step=90550 Epoch=441.8] | Loss=0.00677 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.516 | L2-Norm(final)=22.526 | 3936.8 samples/s | 61.5 steps/s
[Step=90600 Epoch=442.1] | Loss=0.00668 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.521 | L2-Norm(final)=22.532 | 4387.0 samples/s | 68.5 steps/s
[Step=90650 Epoch=442.3] | Loss=0.00613 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=22.537 | 4477.9 samples/s | 70.0 steps/s
[Step=90700 Epoch=442.6] | Loss=0.00596 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=22.542 | 6417.4 samples/s | 100.3 steps/s
[Step=90750 Epoch=442.8] | Loss=0.00571 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=22.546 | 2088.5 samples/s | 32.6 steps/s
[Step=90800 Epoch=443.1] | Loss=0.00553 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.534 | L2-Norm(final)=22.550 | 4509.6 samples/s | 70.5 steps/s
[Step=90850 Epoch=443.3] | Loss=0.00539 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.537 | L2-Norm(final)=22.554 | 4476.6 samples/s | 69.9 steps/s
[Step=90900 Epoch=443.5] | Loss=0.00500 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.539 | L2-Norm(final)=22.558 | 5965.6 samples/s | 93.2 steps/s
[Step=90950 Epoch=443.8] | Loss=0.00480 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.540 | L2-Norm(final)=22.561 | 2153.7 samples/s | 33.7 steps/s
[Step=91000 Epoch=444.0] | Loss=0.00455 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.542 | L2-Norm(final)=22.565 | 4405.1 samples/s | 68.8 steps/s
[Step=91050 Epoch=444.3] | Loss=0.00446 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=22.568 | 4479.6 samples/s | 70.0 steps/s
[Step=91100 Epoch=444.5] | Loss=0.00433 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.545 | L2-Norm(final)=22.571 | 5544.7 samples/s | 86.6 steps/s
[Step=91150 Epoch=444.8] | Loss=0.00419 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.546 | L2-Norm(final)=22.574 | 2200.7 samples/s | 34.4 steps/s
[Step=91200 Epoch=445.0] | Loss=0.00406 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=22.577 | 4465.2 samples/s | 69.8 steps/s
[Step=91250 Epoch=445.3] | Loss=0.00399 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.549 | L2-Norm(final)=22.580 | 4541.0 samples/s | 71.0 steps/s
[Step=91300 Epoch=445.5] | Loss=0.00393 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.550 | L2-Norm(final)=22.583 | 5124.5 samples/s | 80.1 steps/s
[Step=91350 Epoch=445.7] | Loss=0.00385 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.551 | L2-Norm(final)=22.586 | 2250.2 samples/s | 35.2 steps/s
[Step=91400 Epoch=446.0] | Loss=0.00376 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=22.589 | 4442.0 samples/s | 69.4 steps/s
[Step=91450 Epoch=446.2] | Loss=0.00369 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.553 | L2-Norm(final)=22.592 | 4527.6 samples/s | 70.7 steps/s
[Step=91500 Epoch=446.5] | Loss=0.00361 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.554 | L2-Norm(final)=22.594 | 4773.2 samples/s | 74.6 steps/s
[Step=91550 Epoch=446.7] | Loss=0.00356 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.554 | L2-Norm(final)=22.597 | 2377.4 samples/s | 37.1 steps/s
[Step=91600 Epoch=447.0] | Loss=0.00350 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.555 | L2-Norm(final)=22.600 | 4446.4 samples/s | 69.5 steps/s
[Step=91650 Epoch=447.2] | Loss=0.00344 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.556 | L2-Norm(final)=22.603 | 4464.9 samples/s | 69.8 steps/s
[Step=91700 Epoch=447.5] | Loss=0.00338 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.557 | L2-Norm(final)=22.605 | 4531.4 samples/s | 70.8 steps/s
[Step=91750 Epoch=447.7] | Loss=0.00333 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.557 | L2-Norm(final)=22.608 | 2382.3 samples/s | 37.2 steps/s
[Step=91800 Epoch=447.9] | Loss=0.00327 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=22.611 | 4536.9 samples/s | 70.9 steps/s
[Step=91850 Epoch=448.2] | Loss=0.00323 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=22.613 | 4432.8 samples/s | 69.3 steps/s
[Step=91900 Epoch=448.4] | Loss=0.00320 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.559 | L2-Norm(final)=22.616 | 4454.3 samples/s | 69.6 steps/s
[Step=91950 Epoch=448.7] | Loss=0.00315 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=22.618 | 2412.6 samples/s | 37.7 steps/s
[Step=92000 Epoch=448.9] | Loss=0.00310 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=22.621 | 4484.0 samples/s | 70.1 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step92000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=438.5] | Loss=0.01111 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.271 | L2-Norm(final)=22.384 | 5127.1 samples/s | 80.1 steps/s
[Step=90050 Epoch=438.8] | Loss=0.00684 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.273 | L2-Norm(final)=22.390 | 4518.7 samples/s | 70.6 steps/s
[Step=90100 Epoch=439.0] | Loss=0.00692 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.277 | L2-Norm(final)=22.398 | 5044.8 samples/s | 78.8 steps/s
[Step=90150 Epoch=439.3] | Loss=0.00677 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=22.405 | 5046.0 samples/s | 78.8 steps/s
[Step=90200 Epoch=439.5] | Loss=0.00653 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=22.412 | 7745.3 samples/s | 121.0 steps/s
[Step=90250 Epoch=439.7] | Loss=0.00650 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=22.419 | 2244.5 samples/s | 35.1 steps/s
[Step=90300 Epoch=440.0] | Loss=0.00646 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=22.425 | 5076.3 samples/s | 79.3 steps/s
[Step=90350 Epoch=440.2] | Loss=0.00644 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.291 | L2-Norm(final)=22.432 | 5121.4 samples/s | 80.0 steps/s
[Step=90400 Epoch=440.5] | Loss=0.00636 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=22.438 | 6635.3 samples/s | 103.7 steps/s
[Step=90450 Epoch=440.7] | Loss=0.00630 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=22.444 | 2251.7 samples/s | 35.2 steps/s
[Step=90500 Epoch=441.0] | Loss=0.00624 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.299 | L2-Norm(final)=22.450 | 5058.9 samples/s | 79.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=441.0] | Loss=0.00374 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=22.510 | 5213.0 samples/s | 81.5 steps/s
[Step=90550 Epoch=441.2] | Loss=0.00592 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=22.515 | 4378.5 samples/s | 68.4 steps/s
[Step=90600 Epoch=441.4] | Loss=0.00628 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=22.521 | 4445.7 samples/s | 69.5 steps/s
[Step=90650 Epoch=441.7] | Loss=0.00650 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=22.526 | 4478.5 samples/s | 70.0 steps/s
[Step=90700 Epoch=441.9] | Loss=0.00639 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.338 | L2-Norm(final)=22.531 | 6572.3 samples/s | 102.7 steps/s
[Step=90750 Epoch=442.2] | Loss=0.00591 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=22.535 | 2064.7 samples/s | 32.3 steps/s
[Step=90800 Epoch=442.4] | Loss=0.00574 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=22.539 | 4493.2 samples/s | 70.2 steps/s
[Step=90850 Epoch=442.7] | Loss=0.00551 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=22.543 | 4480.5 samples/s | 70.0 steps/s
[Step=90900 Epoch=442.9] | Loss=0.00534 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=22.547 | 5863.6 samples/s | 91.6 steps/s
[Step=90950 Epoch=443.2] | Loss=0.00514 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=22.550 | 2192.3 samples/s | 34.3 steps/s
[Step=91000 Epoch=443.4] | Loss=0.00494 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.352 | L2-Norm(final)=22.554 | 4441.1 samples/s | 69.4 steps/s
[Step=91050 Epoch=443.6] | Loss=0.00479 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=22.557 | 4574.3 samples/s | 71.5 steps/s
[Step=91100 Epoch=443.9] | Loss=0.00467 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.355 | L2-Norm(final)=22.560 | 5177.1 samples/s | 80.9 steps/s
[Step=91150 Epoch=444.1] | Loss=0.00455 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=22.563 | 2177.9 samples/s | 34.0 steps/s
[Step=91200 Epoch=444.4] | Loss=0.00442 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.358 | L2-Norm(final)=22.566 | 4505.8 samples/s | 70.4 steps/s
[Step=91250 Epoch=444.6] | Loss=0.00436 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.359 | L2-Norm(final)=22.569 | 4453.7 samples/s | 69.6 steps/s
[Step=91300 Epoch=444.9] | Loss=0.00429 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=22.571 | 4980.5 samples/s | 77.8 steps/s
[Step=91350 Epoch=445.1] | Loss=0.00419 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=22.574 | 2335.1 samples/s | 36.5 steps/s
[Step=91400 Epoch=445.3] | Loss=0.00409 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=22.577 | 4515.7 samples/s | 70.6 steps/s
[Step=91450 Epoch=445.6] | Loss=0.00401 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=22.580 | 4333.3 samples/s | 67.7 steps/s
[Step=91500 Epoch=445.8] | Loss=0.00394 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.364 | L2-Norm(final)=22.582 | 4629.8 samples/s | 72.3 steps/s
[Step=91550 Epoch=446.1] | Loss=0.00389 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=22.585 | 2435.2 samples/s | 38.1 steps/s
[Step=91600 Epoch=446.3] | Loss=0.00386 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=22.587 | 4441.0 samples/s | 69.4 steps/s
[Step=91650 Epoch=446.6] | Loss=0.00377 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=22.590 | 4600.2 samples/s | 71.9 steps/s
[Step=91700 Epoch=446.8] | Loss=0.00370 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=22.593 | 4371.5 samples/s | 68.3 steps/s
[Step=91750 Epoch=447.0] | Loss=0.00369 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=22.595 | 2487.7 samples/s | 38.9 steps/s
[Step=91800 Epoch=447.3] | Loss=0.00366 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=22.598 | 4338.0 samples/s | 67.8 steps/s
[Step=91850 Epoch=447.5] | Loss=0.00360 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.369 | L2-Norm(final)=22.600 | 4564.7 samples/s | 71.3 steps/s
[Step=91900 Epoch=447.8] | Loss=0.00356 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.370 | L2-Norm(final)=22.602 | 4482.2 samples/s | 70.0 steps/s
[Step=91950 Epoch=448.0] | Loss=0.00352 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=22.605 | 2479.6 samples/s | 38.7 steps/s
[Step=92000 Epoch=448.3] | Loss=0.00348 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=22.607 | 4434.2 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step92000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=438.9] | Loss=0.00423 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=22.433 | 5358.8 samples/s | 83.7 steps/s
[Step=90050 Epoch=439.1] | Loss=0.00757 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=22.439 | 4532.3 samples/s | 70.8 steps/s
[Step=90100 Epoch=439.4] | Loss=0.00743 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=22.446 | 4884.4 samples/s | 76.3 steps/s
[Step=90150 Epoch=439.6] | Loss=0.00689 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=22.454 | 5042.9 samples/s | 78.8 steps/s
[Step=90200 Epoch=439.9] | Loss=0.00683 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.960 | L2-Norm(final)=22.461 | 7713.5 samples/s | 120.5 steps/s
[Step=90250 Epoch=440.1] | Loss=0.00674 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=22.468 | 2228.0 samples/s | 34.8 steps/s
[Step=90300 Epoch=440.4] | Loss=0.00664 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=22.475 | 5040.3 samples/s | 78.8 steps/s
[Step=90350 Epoch=440.6] | Loss=0.00648 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=22.481 | 5001.4 samples/s | 78.1 steps/s
[Step=90400 Epoch=440.8] | Loss=0.00653 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=22.488 | 6990.4 samples/s | 109.2 steps/s
[Step=90450 Epoch=441.1] | Loss=0.00644 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=22.494 | 2299.1 samples/s | 35.9 steps/s
[Step=90500 Epoch=441.3] | Loss=0.00639 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=22.500 | 4903.1 samples/s | 76.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=441.3] | Loss=0.00341 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=22.559 | 5509.0 samples/s | 86.1 steps/s
[Step=90550 Epoch=441.6] | Loss=0.00677 | Reg=0.00225 | acc=0.9688 | L2-Norm=15.004 | L2-Norm(final)=22.564 | 3973.3 samples/s | 62.1 steps/s
[Step=90600 Epoch=441.8] | Loss=0.00807 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=22.569 | 4457.4 samples/s | 69.6 steps/s
[Step=90650 Epoch=442.1] | Loss=0.00766 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.573 | 4470.7 samples/s | 69.9 steps/s
[Step=90700 Epoch=442.3] | Loss=0.00712 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=22.578 | 6585.7 samples/s | 102.9 steps/s
[Step=90750 Epoch=442.5] | Loss=0.00634 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=22.582 | 2092.8 samples/s | 32.7 steps/s
[Step=90800 Epoch=442.8] | Loss=0.00590 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=22.586 | 4423.2 samples/s | 69.1 steps/s
[Step=90850 Epoch=443.0] | Loss=0.00566 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=22.589 | 4446.6 samples/s | 69.5 steps/s
[Step=90900 Epoch=443.3] | Loss=0.00544 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=22.592 | 5912.0 samples/s | 92.4 steps/s
[Step=90950 Epoch=443.5] | Loss=0.00515 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=22.595 | 2185.4 samples/s | 34.1 steps/s
[Step=91000 Epoch=443.8] | Loss=0.00498 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=22.599 | 4366.8 samples/s | 68.2 steps/s
[Step=91050 Epoch=444.0] | Loss=0.00489 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=22.601 | 4457.8 samples/s | 69.7 steps/s
[Step=91100 Epoch=444.3] | Loss=0.00466 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=22.604 | 5466.5 samples/s | 85.4 steps/s
[Step=91150 Epoch=444.5] | Loss=0.00446 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=22.607 | 2238.4 samples/s | 35.0 steps/s
[Step=91200 Epoch=444.7] | Loss=0.00429 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=22.610 | 4450.0 samples/s | 69.5 steps/s
[Step=91250 Epoch=445.0] | Loss=0.00425 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=22.613 | 4478.6 samples/s | 70.0 steps/s
[Step=91300 Epoch=445.2] | Loss=0.00413 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=22.615 | 4981.8 samples/s | 77.8 steps/s
[Step=91350 Epoch=445.5] | Loss=0.00400 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=22.618 | 2324.1 samples/s | 36.3 steps/s
[Step=91400 Epoch=445.7] | Loss=0.00388 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=22.620 | 4479.8 samples/s | 70.0 steps/s
[Step=91450 Epoch=446.0] | Loss=0.00380 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=22.623 | 4454.0 samples/s | 69.6 steps/s
[Step=91500 Epoch=446.2] | Loss=0.00374 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=22.625 | 4635.7 samples/s | 72.4 steps/s
[Step=91550 Epoch=446.4] | Loss=0.00370 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=22.628 | 2363.9 samples/s | 36.9 steps/s
[Step=91600 Epoch=446.7] | Loss=0.00367 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=22.630 | 4476.1 samples/s | 69.9 steps/s
[Step=91650 Epoch=446.9] | Loss=0.00360 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=22.633 | 4574.5 samples/s | 71.5 steps/s
[Step=91700 Epoch=447.2] | Loss=0.00356 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=22.635 | 4361.5 samples/s | 68.1 steps/s
[Step=91750 Epoch=447.4] | Loss=0.00350 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=22.637 | 2492.0 samples/s | 38.9 steps/s
[Step=91800 Epoch=447.7] | Loss=0.00343 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=22.640 | 4506.4 samples/s | 70.4 steps/s
[Step=91850 Epoch=447.9] | Loss=0.00338 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=22.642 | 4430.5 samples/s | 69.2 steps/s
[Step=91900 Epoch=448.2] | Loss=0.00335 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=22.644 | 4364.9 samples/s | 68.2 steps/s
[Step=91950 Epoch=448.4] | Loss=0.00330 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=22.647 | 2463.7 samples/s | 38.5 steps/s
[Step=92000 Epoch=448.6] | Loss=0.00324 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.049 | L2-Norm(final)=22.649 | 4538.6 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step92000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=441.4] | Loss=0.00538 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.589 | L2-Norm(final)=22.529 | 5165.1 samples/s | 80.7 steps/s
[Step=90050 Epoch=441.6] | Loss=0.00606 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=22.535 | 4636.9 samples/s | 72.5 steps/s
[Step=90100 Epoch=441.8] | Loss=0.00605 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=22.541 | 5055.0 samples/s | 79.0 steps/s
[Step=90150 Epoch=442.1] | Loss=0.00581 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=22.548 | 5010.8 samples/s | 78.3 steps/s
[Step=90200 Epoch=442.3] | Loss=0.00579 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.601 | L2-Norm(final)=22.555 | 8143.3 samples/s | 127.2 steps/s
[Step=90250 Epoch=442.6] | Loss=0.00558 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=22.562 | 2220.5 samples/s | 34.7 steps/s
[Step=90300 Epoch=442.8] | Loss=0.00558 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.607 | L2-Norm(final)=22.568 | 4769.5 samples/s | 74.5 steps/s
[Step=90350 Epoch=443.1] | Loss=0.00553 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=22.575 | 5206.0 samples/s | 81.3 steps/s
[Step=90400 Epoch=443.3] | Loss=0.00550 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.612 | L2-Norm(final)=22.581 | 7084.1 samples/s | 110.7 steps/s
[Step=90450 Epoch=443.6] | Loss=0.00540 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=22.587 | 2262.2 samples/s | 35.3 steps/s
[Step=90500 Epoch=443.8] | Loss=0.00533 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=22.593 | 5014.0 samples/s | 78.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=443.8] | Loss=0.00341 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=22.653 | 5497.7 samples/s | 85.9 steps/s
[Step=90550 Epoch=444.0] | Loss=0.00644 | Reg=0.00214 | acc=0.9688 | L2-Norm=14.643 | L2-Norm(final)=22.659 | 3917.3 samples/s | 61.2 steps/s
[Step=90600 Epoch=444.3] | Loss=0.00580 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=22.664 | 4373.4 samples/s | 68.3 steps/s
[Step=90650 Epoch=444.5] | Loss=0.00633 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=22.669 | 4454.4 samples/s | 69.6 steps/s
[Step=90700 Epoch=444.8] | Loss=0.00612 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=22.673 | 6750.5 samples/s | 105.5 steps/s
[Step=90750 Epoch=445.0] | Loss=0.00588 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=22.677 | 2092.9 samples/s | 32.7 steps/s
[Step=90800 Epoch=445.3] | Loss=0.00543 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=22.681 | 4471.7 samples/s | 69.9 steps/s
[Step=90850 Epoch=445.5] | Loss=0.00511 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=22.685 | 4527.1 samples/s | 70.7 steps/s
[Step=90900 Epoch=445.8] | Loss=0.00488 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=22.688 | 6009.9 samples/s | 93.9 steps/s
[Step=90950 Epoch=446.0] | Loss=0.00465 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=22.692 | 2085.0 samples/s | 32.6 steps/s
[Step=91000 Epoch=446.2] | Loss=0.00449 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=22.695 | 4439.2 samples/s | 69.4 steps/s
[Step=91050 Epoch=446.5] | Loss=0.00431 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=22.698 | 4492.2 samples/s | 70.2 steps/s
[Step=91100 Epoch=446.7] | Loss=0.00421 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=22.701 | 5829.2 samples/s | 91.1 steps/s
[Step=91150 Epoch=447.0] | Loss=0.00408 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.671 | L2-Norm(final)=22.704 | 2201.9 samples/s | 34.4 steps/s
[Step=91200 Epoch=447.2] | Loss=0.00399 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=22.707 | 4379.1 samples/s | 68.4 steps/s
[Step=91250 Epoch=447.5] | Loss=0.00391 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=22.710 | 4410.6 samples/s | 68.9 steps/s
[Step=91300 Epoch=447.7] | Loss=0.00378 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=22.713 | 5476.4 samples/s | 85.6 steps/s
[Step=91350 Epoch=448.0] | Loss=0.00367 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.675 | L2-Norm(final)=22.716 | 2224.7 samples/s | 34.8 steps/s
[Step=91400 Epoch=448.2] | Loss=0.00358 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=22.718 | 4498.0 samples/s | 70.3 steps/s
[Step=91450 Epoch=448.5] | Loss=0.00350 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.677 | L2-Norm(final)=22.721 | 4470.6 samples/s | 69.9 steps/s
[Step=91500 Epoch=448.7] | Loss=0.00344 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.678 | L2-Norm(final)=22.724 | 5206.5 samples/s | 81.4 steps/s
[Step=91550 Epoch=448.9] | Loss=0.00339 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=22.726 | 2274.0 samples/s | 35.5 steps/s
[Step=91600 Epoch=449.2] | Loss=0.00336 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=22.729 | 4380.0 samples/s | 68.4 steps/s
[Step=91650 Epoch=449.4] | Loss=0.00331 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.680 | L2-Norm(final)=22.732 | 4450.2 samples/s | 69.5 steps/s
[Step=91700 Epoch=449.7] | Loss=0.00324 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=22.734 | 4919.1 samples/s | 76.9 steps/s
[Step=91750 Epoch=449.9] | Loss=0.00317 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=22.737 | 2336.0 samples/s | 36.5 steps/s
[Step=91800 Epoch=450.2] | Loss=0.00310 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=22.739 | 4410.7 samples/s | 68.9 steps/s
[Step=91850 Epoch=450.4] | Loss=0.00306 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=22.742 | 4419.1 samples/s | 69.0 steps/s
[Step=91900 Epoch=450.7] | Loss=0.00302 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=22.744 | 4726.5 samples/s | 73.9 steps/s
[Step=91950 Epoch=450.9] | Loss=0.00303 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=22.747 | 2367.4 samples/s | 37.0 steps/s
[Step=92000 Epoch=451.2] | Loss=0.00299 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=22.749 | 4429.4 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step92000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=852.8] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.390 | L2-Norm(final)=11.272 | 4973.6 samples/s | 77.7 steps/s
[Step=90050 Epoch=853.3] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.393 | L2-Norm(final)=11.281 | 4138.7 samples/s | 64.7 steps/s
[Step=90100 Epoch=853.8] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.398 | L2-Norm(final)=11.291 | 7532.8 samples/s | 117.7 steps/s
[Step=90150 Epoch=854.2] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.403 | L2-Norm(final)=11.300 | 2145.2 samples/s | 33.5 steps/s
[Step=90200 Epoch=854.7] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.407 | L2-Norm(final)=11.308 | 6603.4 samples/s | 103.2 steps/s
[Step=90250 Epoch=855.2] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.411 | L2-Norm(final)=11.315 | 2177.0 samples/s | 34.0 steps/s
[Step=90300 Epoch=855.7] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.414 | L2-Norm(final)=11.321 | 5890.6 samples/s | 92.0 steps/s
[Step=90350 Epoch=856.1] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.417 | L2-Norm(final)=11.327 | 2350.2 samples/s | 36.7 steps/s
[Step=90400 Epoch=856.6] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.420 | L2-Norm(final)=11.333 | 5114.8 samples/s | 79.9 steps/s
[Step=90450 Epoch=857.1] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.422 | L2-Norm(final)=11.338 | 2439.9 samples/s | 38.1 steps/s
[Step=90500 Epoch=857.6] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.425 | L2-Norm(final)=11.343 | 4657.6 samples/s | 72.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=857.6] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.447 | L2-Norm(final)=11.393 | 5366.1 samples/s | 83.8 steps/s
[Step=90550 Epoch=858.0] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.447 | L2-Norm(final)=11.397 | 3726.3 samples/s | 58.2 steps/s
[Step=90600 Epoch=858.5] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.443 | L2-Norm(final)=11.400 | 6248.6 samples/s | 97.6 steps/s
[Step=90650 Epoch=859.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.437 | L2-Norm(final)=11.401 | 2008.0 samples/s | 31.4 steps/s
[Step=90700 Epoch=859.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.429 | L2-Norm(final)=11.403 | 5614.4 samples/s | 87.7 steps/s
[Step=90750 Epoch=859.9] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.419 | L2-Norm(final)=11.404 | 2092.6 samples/s | 32.7 steps/s
[Step=90800 Epoch=860.4] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.410 | L2-Norm(final)=11.405 | 5059.2 samples/s | 79.1 steps/s
[Step=90850 Epoch=860.9] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.399 | L2-Norm(final)=11.405 | 2124.3 samples/s | 33.2 steps/s
[Step=90900 Epoch=861.4] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.389 | L2-Norm(final)=11.406 | 4677.4 samples/s | 73.1 steps/s
[Step=90950 Epoch=861.8] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=11.407 | 2261.4 samples/s | 35.3 steps/s
[Step=91000 Epoch=862.3] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.367 | L2-Norm(final)=11.407 | 4344.3 samples/s | 67.9 steps/s
[Step=91050 Epoch=862.8] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.356 | L2-Norm(final)=11.408 | 2386.6 samples/s | 37.3 steps/s
[Step=91100 Epoch=863.3] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.345 | L2-Norm(final)=11.409 | 4125.6 samples/s | 64.5 steps/s
[Step=91150 Epoch=863.7] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.334 | L2-Norm(final)=11.409 | 2378.0 samples/s | 37.2 steps/s
[Step=91200 Epoch=864.2] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.323 | L2-Norm(final)=11.410 | 4322.4 samples/s | 67.5 steps/s
[Step=91250 Epoch=864.7] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.311 | L2-Norm(final)=11.411 | 2378.0 samples/s | 37.2 steps/s
[Step=91300 Epoch=865.1] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.300 | L2-Norm(final)=11.411 | 4236.2 samples/s | 66.2 steps/s
[Step=91350 Epoch=865.6] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.288 | L2-Norm(final)=11.412 | 2529.3 samples/s | 39.5 steps/s
[Step=91400 Epoch=866.1] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.276 | L2-Norm(final)=11.413 | 3752.3 samples/s | 58.6 steps/s
[Step=91450 Epoch=866.6] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.264 | L2-Norm(final)=11.414 | 6511.0 samples/s | 101.7 steps/s
[Step=91500 Epoch=867.0] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.252 | L2-Norm(final)=11.414 | 2001.3 samples/s | 31.3 steps/s
[Step=91550 Epoch=867.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.240 | L2-Norm(final)=11.415 | 5792.6 samples/s | 90.5 steps/s
[Step=91600 Epoch=868.0] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.228 | L2-Norm(final)=11.416 | 2072.8 samples/s | 32.4 steps/s
[Step=91650 Epoch=868.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.216 | L2-Norm(final)=11.417 | 5258.1 samples/s | 82.2 steps/s
[Step=91700 Epoch=868.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=11.417 | 2159.6 samples/s | 33.7 steps/s
[Step=91750 Epoch=869.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.191 | L2-Norm(final)=11.418 | 4732.6 samples/s | 73.9 steps/s
[Step=91800 Epoch=869.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.179 | L2-Norm(final)=11.419 | 2215.9 samples/s | 34.6 steps/s
[Step=91850 Epoch=870.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.166 | L2-Norm(final)=11.420 | 4483.9 samples/s | 70.1 steps/s
[Step=91900 Epoch=870.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.153 | L2-Norm(final)=11.421 | 2322.7 samples/s | 36.3 steps/s
[Step=91950 Epoch=871.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=11.422 | 4241.7 samples/s | 66.3 steps/s
[Step=92000 Epoch=871.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.128 | L2-Norm(final)=11.423 | 2335.1 samples/s | 36.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step92000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=856.1] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.347 | L2-Norm(final)=12.544 | 5252.8 samples/s | 82.1 steps/s
[Step=90050 Epoch=856.6] | Loss=0.00007 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.349 | L2-Norm(final)=12.556 | 4137.6 samples/s | 64.7 steps/s
[Step=90100 Epoch=857.1] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.354 | L2-Norm(final)=12.564 | 7323.2 samples/s | 114.4 steps/s
[Step=90150 Epoch=857.6] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.358 | L2-Norm(final)=12.570 | 2185.9 samples/s | 34.2 steps/s
[Step=90200 Epoch=858.0] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.360 | L2-Norm(final)=12.576 | 6186.1 samples/s | 96.7 steps/s
[Step=90250 Epoch=858.5] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.362 | L2-Norm(final)=12.581 | 2193.2 samples/s | 34.3 steps/s
[Step=90300 Epoch=859.0] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.365 | L2-Norm(final)=12.586 | 5981.3 samples/s | 93.5 steps/s
[Step=90350 Epoch=859.5] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.366 | L2-Norm(final)=12.590 | 2324.4 samples/s | 36.3 steps/s
[Step=90400 Epoch=859.9] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.368 | L2-Norm(final)=12.594 | 5364.7 samples/s | 83.8 steps/s
[Step=90450 Epoch=860.4] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.599 | 2377.9 samples/s | 37.2 steps/s
[Step=90500 Epoch=860.9] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=12.603 | 4948.3 samples/s | 77.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=860.9] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.385 | L2-Norm(final)=12.642 | 5574.3 samples/s | 87.1 steps/s
[Step=90550 Epoch=861.4] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.388 | L2-Norm(final)=12.647 | 3559.5 samples/s | 55.6 steps/s
[Step=90600 Epoch=861.8] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.384 | L2-Norm(final)=12.650 | 6368.7 samples/s | 99.5 steps/s
[Step=90650 Epoch=862.3] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.377 | L2-Norm(final)=12.652 | 2028.0 samples/s | 31.7 steps/s
[Step=90700 Epoch=862.8] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.369 | L2-Norm(final)=12.653 | 5635.5 samples/s | 88.1 steps/s
[Step=90750 Epoch=863.3] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.359 | L2-Norm(final)=12.654 | 2089.9 samples/s | 32.7 steps/s
[Step=90800 Epoch=863.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.349 | L2-Norm(final)=12.655 | 5193.1 samples/s | 81.1 steps/s
[Step=90850 Epoch=864.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.339 | L2-Norm(final)=12.656 | 2152.0 samples/s | 33.6 steps/s
[Step=90900 Epoch=864.7] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.328 | L2-Norm(final)=12.656 | 4772.4 samples/s | 74.6 steps/s
[Step=90950 Epoch=865.2] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.318 | L2-Norm(final)=12.657 | 2294.9 samples/s | 35.9 steps/s
[Step=91000 Epoch=865.6] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.307 | L2-Norm(final)=12.658 | 4246.7 samples/s | 66.4 steps/s
[Step=91050 Epoch=866.1] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.295 | L2-Norm(final)=12.658 | 2361.5 samples/s | 36.9 steps/s
[Step=91100 Epoch=866.6] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.284 | L2-Norm(final)=12.659 | 4206.3 samples/s | 65.7 steps/s
[Step=91150 Epoch=867.1] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.273 | L2-Norm(final)=12.660 | 2337.2 samples/s | 36.5 steps/s
[Step=91200 Epoch=867.5] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.261 | L2-Norm(final)=12.660 | 4257.4 samples/s | 66.5 steps/s
[Step=91250 Epoch=868.0] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.250 | L2-Norm(final)=12.661 | 2391.4 samples/s | 37.4 steps/s
[Step=91300 Epoch=868.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.238 | L2-Norm(final)=12.661 | 4251.9 samples/s | 66.4 steps/s
[Step=91350 Epoch=869.0] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=12.662 | 2439.6 samples/s | 38.1 steps/s
[Step=91400 Epoch=869.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.214 | L2-Norm(final)=12.663 | 4073.6 samples/s | 63.6 steps/s
[Step=91450 Epoch=869.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.202 | L2-Norm(final)=12.663 | 6380.5 samples/s | 99.7 steps/s
[Step=91500 Epoch=870.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.190 | L2-Norm(final)=12.664 | 1995.6 samples/s | 31.2 steps/s
[Step=91550 Epoch=870.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.178 | L2-Norm(final)=12.665 | 5809.5 samples/s | 90.8 steps/s
[Step=91600 Epoch=871.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.166 | L2-Norm(final)=12.666 | 2091.8 samples/s | 32.7 steps/s
[Step=91650 Epoch=871.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.153 | L2-Norm(final)=12.666 | 5329.0 samples/s | 83.3 steps/s
[Step=91700 Epoch=872.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=12.667 | 2129.6 samples/s | 33.3 steps/s
[Step=91750 Epoch=872.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.128 | L2-Norm(final)=12.668 | 4898.4 samples/s | 76.5 steps/s
[Step=91800 Epoch=873.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.116 | L2-Norm(final)=12.669 | 2240.7 samples/s | 35.0 steps/s
[Step=91850 Epoch=873.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.103 | L2-Norm(final)=12.670 | 4506.4 samples/s | 70.4 steps/s
[Step=91900 Epoch=874.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.090 | L2-Norm(final)=12.670 | 2312.7 samples/s | 36.1 steps/s
[Step=91950 Epoch=874.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.078 | L2-Norm(final)=12.671 | 4301.7 samples/s | 67.2 steps/s
[Step=92000 Epoch=875.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.065 | L2-Norm(final)=12.672 | 2367.2 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step92000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=859.5] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.363 | L2-Norm(final)=11.796 | 5272.2 samples/s | 82.4 steps/s
[Step=90050 Epoch=859.9] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.365 | L2-Norm(final)=11.804 | 4087.7 samples/s | 63.9 steps/s
[Step=90100 Epoch=860.4] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=11.814 | 7577.7 samples/s | 118.4 steps/s
[Step=90150 Epoch=860.9] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.374 | L2-Norm(final)=11.823 | 2153.1 samples/s | 33.6 steps/s
[Step=90200 Epoch=861.4] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=11.831 | 6695.0 samples/s | 104.6 steps/s
[Step=90250 Epoch=861.8] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.381 | L2-Norm(final)=11.838 | 2171.6 samples/s | 33.9 steps/s
[Step=90300 Epoch=862.3] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.383 | L2-Norm(final)=11.844 | 6079.7 samples/s | 95.0 steps/s
[Step=90350 Epoch=862.8] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.386 | L2-Norm(final)=11.850 | 2249.4 samples/s | 35.1 steps/s
[Step=90400 Epoch=863.3] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.388 | L2-Norm(final)=11.856 | 5681.3 samples/s | 88.8 steps/s
[Step=90450 Epoch=863.7] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.390 | L2-Norm(final)=11.862 | 2359.8 samples/s | 36.9 steps/s
[Step=90500 Epoch=864.2] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.392 | L2-Norm(final)=11.867 | 5148.7 samples/s | 80.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=864.2] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.411 | L2-Norm(final)=11.919 | 5080.9 samples/s | 79.4 steps/s
[Step=90550 Epoch=864.7] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.411 | L2-Norm(final)=11.923 | 3877.6 samples/s | 60.6 steps/s
[Step=90600 Epoch=865.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.406 | L2-Norm(final)=11.926 | 6163.2 samples/s | 96.3 steps/s
[Step=90650 Epoch=865.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.399 | L2-Norm(final)=11.928 | 1997.3 samples/s | 31.2 steps/s
[Step=90700 Epoch=866.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.391 | L2-Norm(final)=11.929 | 5874.3 samples/s | 91.8 steps/s
[Step=90750 Epoch=866.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.381 | L2-Norm(final)=11.930 | 2073.5 samples/s | 32.4 steps/s
[Step=90800 Epoch=867.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=11.931 | 5307.7 samples/s | 82.9 steps/s
[Step=90850 Epoch=867.6] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.361 | L2-Norm(final)=11.932 | 2138.5 samples/s | 33.4 steps/s
[Step=90900 Epoch=868.0] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.351 | L2-Norm(final)=11.933 | 4922.5 samples/s | 76.9 steps/s
[Step=90950 Epoch=868.5] | Loss=0.00000 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.340 | L2-Norm(final)=11.933 | 2187.3 samples/s | 34.2 steps/s
[Step=91000 Epoch=869.0] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.329 | L2-Norm(final)=11.934 | 4604.9 samples/s | 72.0 steps/s
[Step=91050 Epoch=869.5] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.318 | L2-Norm(final)=11.935 | 2276.6 samples/s | 35.6 steps/s
[Step=91100 Epoch=869.9] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.307 | L2-Norm(final)=11.936 | 4373.9 samples/s | 68.3 steps/s
[Step=91150 Epoch=870.4] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.296 | L2-Norm(final)=11.936 | 2367.9 samples/s | 37.0 steps/s
[Step=91200 Epoch=870.9] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.284 | L2-Norm(final)=11.937 | 4313.5 samples/s | 67.4 steps/s
[Step=91250 Epoch=871.4] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.273 | L2-Norm(final)=11.938 | 2355.6 samples/s | 36.8 steps/s
[Step=91300 Epoch=871.9] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.261 | L2-Norm(final)=11.939 | 4222.3 samples/s | 66.0 steps/s
[Step=91350 Epoch=872.3] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.250 | L2-Norm(final)=11.939 | 2402.8 samples/s | 37.5 steps/s
[Step=91400 Epoch=872.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.238 | L2-Norm(final)=11.940 | 4147.9 samples/s | 64.8 steps/s
[Step=91450 Epoch=873.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=11.941 | 2335.4 samples/s | 36.5 steps/s
[Step=91500 Epoch=873.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.214 | L2-Norm(final)=11.942 | 4180.6 samples/s | 65.3 steps/s
[Step=91550 Epoch=874.2] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.202 | L2-Norm(final)=11.943 | 7049.0 samples/s | 110.1 steps/s
[Step=91600 Epoch=874.7] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.190 | L2-Norm(final)=11.944 | 1960.9 samples/s | 30.6 steps/s
[Step=91650 Epoch=875.2] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.178 | L2-Norm(final)=11.945 | 6249.5 samples/s | 97.6 steps/s
[Step=91700 Epoch=875.7] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.166 | L2-Norm(final)=11.946 | 2016.7 samples/s | 31.5 steps/s
[Step=91750 Epoch=876.2] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.154 | L2-Norm(final)=11.947 | 5649.0 samples/s | 88.3 steps/s
[Step=91800 Epoch=876.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=11.948 | 2025.7 samples/s | 31.7 steps/s
[Step=91850 Epoch=877.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.129 | L2-Norm(final)=11.949 | 5316.6 samples/s | 83.1 steps/s
[Step=91900 Epoch=877.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.116 | L2-Norm(final)=11.950 | 2141.1 samples/s | 33.5 steps/s
[Step=91950 Epoch=878.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.104 | L2-Norm(final)=11.951 | 4989.1 samples/s | 78.0 steps/s
[Step=92000 Epoch=878.5] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.091 | L2-Norm(final)=11.952 | 2208.3 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step92000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=848.1] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.619 | L2-Norm(final)=11.519 | 4941.2 samples/s | 77.2 steps/s
[Step=90050 Epoch=848.5] | Loss=0.00021 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.623 | L2-Norm(final)=11.525 | 4249.6 samples/s | 66.4 steps/s
[Step=90100 Epoch=849.0] | Loss=0.00015 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.628 | L2-Norm(final)=11.531 | 7397.7 samples/s | 115.6 steps/s
[Step=90150 Epoch=849.5] | Loss=0.00011 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.632 | L2-Norm(final)=11.535 | 2142.9 samples/s | 33.5 steps/s
[Step=90200 Epoch=849.9] | Loss=0.00011 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.635 | L2-Norm(final)=11.539 | 6402.5 samples/s | 100.0 steps/s
[Step=90250 Epoch=850.4] | Loss=0.00010 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.637 | L2-Norm(final)=11.544 | 2232.8 samples/s | 34.9 steps/s
[Step=90300 Epoch=850.9] | Loss=0.00009 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.639 | L2-Norm(final)=11.548 | 5648.8 samples/s | 88.3 steps/s
[Step=90350 Epoch=851.4] | Loss=0.00009 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.641 | L2-Norm(final)=11.552 | 2282.2 samples/s | 35.7 steps/s
[Step=90400 Epoch=851.8] | Loss=0.00009 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.643 | L2-Norm(final)=11.555 | 5084.4 samples/s | 79.4 steps/s
[Step=90450 Epoch=852.3] | Loss=0.00008 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.645 | L2-Norm(final)=11.559 | 2484.5 samples/s | 38.8 steps/s
[Step=90500 Epoch=852.8] | Loss=0.00008 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.647 | L2-Norm(final)=11.563 | 4845.6 samples/s | 75.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=852.8] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.663 | L2-Norm(final)=11.598 | 5469.1 samples/s | 85.5 steps/s
[Step=90550 Epoch=853.2] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.665 | L2-Norm(final)=11.601 | 3736.7 samples/s | 58.4 steps/s
[Step=90600 Epoch=853.7] | Loss=0.00016 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.670 | L2-Norm(final)=11.605 | 6032.7 samples/s | 94.3 steps/s
[Step=90650 Epoch=854.2] | Loss=0.00014 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.676 | L2-Norm(final)=11.609 | 2027.8 samples/s | 31.7 steps/s
[Step=90700 Epoch=854.7] | Loss=0.00010 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.680 | L2-Norm(final)=11.612 | 5373.4 samples/s | 84.0 steps/s
[Step=90750 Epoch=855.1] | Loss=0.00012 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.682 | L2-Norm(final)=11.615 | 2120.2 samples/s | 33.1 steps/s
[Step=90800 Epoch=855.6] | Loss=0.00010 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.685 | L2-Norm(final)=11.617 | 4954.8 samples/s | 77.4 steps/s
[Step=90850 Epoch=856.1] | Loss=0.00009 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.687 | L2-Norm(final)=11.618 | 2212.2 samples/s | 34.6 steps/s
[Step=90900 Epoch=856.5] | Loss=0.00008 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.688 | L2-Norm(final)=11.620 | 4367.5 samples/s | 68.2 steps/s
[Step=90950 Epoch=857.0] | Loss=0.00007 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.688 | L2-Norm(final)=11.621 | 2326.7 samples/s | 36.4 steps/s
[Step=91000 Epoch=857.5] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.622 | 4276.5 samples/s | 66.8 steps/s
[Step=91050 Epoch=858.0] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.623 | 2402.3 samples/s | 37.5 steps/s
[Step=91100 Epoch=858.4] | Loss=0.00006 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.623 | 4344.2 samples/s | 67.9 steps/s
[Step=91150 Epoch=858.9] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.624 | 2391.5 samples/s | 37.4 steps/s
[Step=91200 Epoch=859.4] | Loss=0.00005 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.625 | 4105.9 samples/s | 64.2 steps/s
[Step=91250 Epoch=859.8] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.689 | L2-Norm(final)=11.625 | 2741.0 samples/s | 42.8 steps/s
[Step=91300 Epoch=860.3] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.688 | L2-Norm(final)=11.626 | 3470.1 samples/s | 54.2 steps/s
[Step=91350 Epoch=860.8] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.688 | L2-Norm(final)=11.626 | 6213.6 samples/s | 97.1 steps/s
[Step=91400 Epoch=861.2] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.687 | L2-Norm(final)=11.627 | 2063.7 samples/s | 32.2 steps/s
[Step=91450 Epoch=861.7] | Loss=0.00004 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.687 | L2-Norm(final)=11.627 | 5419.0 samples/s | 84.7 steps/s
[Step=91500 Epoch=862.2] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.686 | L2-Norm(final)=11.628 | 2091.7 samples/s | 32.7 steps/s
[Step=91550 Epoch=862.7] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.685 | L2-Norm(final)=11.628 | 4938.5 samples/s | 77.2 steps/s
[Step=91600 Epoch=863.1] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.685 | L2-Norm(final)=11.628 | 2215.5 samples/s | 34.6 steps/s
[Step=91650 Epoch=863.6] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.684 | L2-Norm(final)=11.629 | 4534.4 samples/s | 70.9 steps/s
[Step=91700 Epoch=864.1] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.683 | L2-Norm(final)=11.629 | 2306.0 samples/s | 36.0 steps/s
[Step=91750 Epoch=864.5] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.682 | L2-Norm(final)=11.629 | 4325.2 samples/s | 67.6 steps/s
[Step=91800 Epoch=865.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.682 | L2-Norm(final)=11.630 | 1738.6 samples/s | 27.2 steps/s
[Step=91850 Epoch=865.5] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.681 | L2-Norm(final)=11.630 | 4222.1 samples/s | 66.0 steps/s
[Step=91900 Epoch=866.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.680 | L2-Norm(final)=11.630 | 2355.1 samples/s | 36.8 steps/s
[Step=91950 Epoch=866.4] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.679 | L2-Norm(final)=11.631 | 4262.2 samples/s | 66.6 steps/s
[Step=92000 Epoch=866.9] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.678 | L2-Norm(final)=11.631 | 2578.9 samples/s | 40.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step92000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=857.8] | Loss=0.00012 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.523 | L2-Norm(final)=12.304 | 4769.6 samples/s | 74.5 steps/s
[Step=90050 Epoch=858.3] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.526 | L2-Norm(final)=12.308 | 4315.7 samples/s | 67.4 steps/s
[Step=90100 Epoch=858.7] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.528 | L2-Norm(final)=12.314 | 7608.2 samples/s | 118.9 steps/s
[Step=90150 Epoch=859.2] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.531 | L2-Norm(final)=12.319 | 2109.5 samples/s | 33.0 steps/s
[Step=90200 Epoch=859.7] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=12.323 | 6892.5 samples/s | 107.7 steps/s
[Step=90250 Epoch=860.2] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=12.328 | 2176.3 samples/s | 34.0 steps/s
[Step=90300 Epoch=860.6] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=12.333 | 6145.1 samples/s | 96.0 steps/s
[Step=90350 Epoch=861.1] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.539 | L2-Norm(final)=12.337 | 2212.3 samples/s | 34.6 steps/s
[Step=90400 Epoch=861.6] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.540 | L2-Norm(final)=12.341 | 5671.5 samples/s | 88.6 steps/s
[Step=90450 Epoch=862.1] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.345 | 2348.9 samples/s | 36.7 steps/s
[Step=90500 Epoch=862.5] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=12.350 | 5223.5 samples/s | 81.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=862.6] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.391 | 5045.0 samples/s | 78.8 steps/s
[Step=90550 Epoch=863.0] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.561 | L2-Norm(final)=12.395 | 3881.8 samples/s | 60.7 steps/s
[Step=90600 Epoch=863.5] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.562 | L2-Norm(final)=12.398 | 6359.4 samples/s | 99.4 steps/s
[Step=90650 Epoch=864.0] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.562 | L2-Norm(final)=12.400 | 1985.2 samples/s | 31.0 steps/s
[Step=90700 Epoch=864.5] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.561 | L2-Norm(final)=12.402 | 5621.7 samples/s | 87.8 steps/s
[Step=90750 Epoch=864.9] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.560 | L2-Norm(final)=12.404 | 2067.4 samples/s | 32.3 steps/s
[Step=90800 Epoch=865.4] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.406 | 5367.1 samples/s | 83.9 steps/s
[Step=90850 Epoch=865.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.557 | L2-Norm(final)=12.407 | 2130.8 samples/s | 33.3 steps/s
[Step=90900 Epoch=866.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.556 | L2-Norm(final)=12.408 | 4906.2 samples/s | 76.7 steps/s
[Step=90950 Epoch=866.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.554 | L2-Norm(final)=12.410 | 2163.6 samples/s | 33.8 steps/s
[Step=91000 Epoch=867.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.552 | L2-Norm(final)=12.411 | 4571.6 samples/s | 71.4 steps/s
[Step=91050 Epoch=867.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.550 | L2-Norm(final)=12.412 | 2255.1 samples/s | 35.2 steps/s
[Step=91100 Epoch=868.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.548 | L2-Norm(final)=12.413 | 4341.4 samples/s | 67.8 steps/s
[Step=91150 Epoch=868.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.545 | L2-Norm(final)=12.414 | 2426.6 samples/s | 37.9 steps/s
[Step=91200 Epoch=869.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.543 | L2-Norm(final)=12.415 | 4204.8 samples/s | 65.7 steps/s
[Step=91250 Epoch=869.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.540 | L2-Norm(final)=12.416 | 2343.0 samples/s | 36.6 steps/s
[Step=91300 Epoch=870.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.538 | L2-Norm(final)=12.417 | 4260.0 samples/s | 66.6 steps/s
[Step=91350 Epoch=870.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=12.418 | 2352.8 samples/s | 36.8 steps/s
[Step=91400 Epoch=871.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=12.418 | 4236.9 samples/s | 66.2 steps/s
[Step=91450 Epoch=871.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.530 | L2-Norm(final)=12.419 | 2390.6 samples/s | 37.4 steps/s
[Step=91500 Epoch=872.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.527 | L2-Norm(final)=12.420 | 4263.3 samples/s | 66.6 steps/s
[Step=91550 Epoch=872.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=12.421 | 6751.0 samples/s | 105.5 steps/s
[Step=91600 Epoch=873.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.522 | L2-Norm(final)=12.422 | 1940.5 samples/s | 30.3 steps/s
[Step=91650 Epoch=873.5] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.519 | L2-Norm(final)=12.423 | 6382.4 samples/s | 99.7 steps/s
[Step=91700 Epoch=874.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.516 | L2-Norm(final)=12.424 | 2009.7 samples/s | 31.4 steps/s
[Step=91750 Epoch=874.5] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.513 | L2-Norm(final)=12.424 | 5827.1 samples/s | 91.0 steps/s
[Step=91800 Epoch=874.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=12.425 | 2074.2 samples/s | 32.4 steps/s
[Step=91850 Epoch=875.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.506 | L2-Norm(final)=12.426 | 5285.9 samples/s | 82.6 steps/s
[Step=91900 Epoch=875.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=12.427 | 2123.6 samples/s | 33.2 steps/s
[Step=91950 Epoch=876.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.500 | L2-Norm(final)=12.428 | 4966.7 samples/s | 77.6 steps/s
[Step=92000 Epoch=876.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.496 | L2-Norm(final)=12.429 | 2203.8 samples/s | 34.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.10648 | acc=0.9552 | tpr=0.9726 | fpr=0.0825 | 4857.7 samples/s | 19.0 steps/s
Avg test loss: 0.11014, Avg test acc: 0.95332, Avg tpr: 0.97109, Avg fpr: 0.08576, total FA: 669

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10817 | acc=0.9556 | tpr=0.9722 | fpr=0.0803 | 4995.1 samples/s | 19.5 steps/s
Avg test loss: 0.10864, Avg test acc: 0.95601, Avg tpr: 0.97249, Avg fpr: 0.08025, total FA: 626

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10460 | acc=0.9557 | tpr=0.9712 | fpr=0.0780 | 4821.3 samples/s | 18.8 steps/s
Avg test loss: 0.10633, Avg test acc: 0.95448, Avg tpr: 0.96946, Avg fpr: 0.07845, total FA: 612

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09625 | acc=0.9573 | tpr=0.9725 | fpr=0.0756 | 4609.7 samples/s | 18.0 steps/s
Avg test loss: 0.10193, Avg test acc: 0.95589, Avg tpr: 0.97266, Avg fpr: 0.08102, total FA: 632

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10478 | acc=0.9548 | tpr=0.9688 | fpr=0.0756 | 4946.5 samples/s | 19.3 steps/s
Avg test loss: 0.10807, Avg test acc: 0.95364, Avg tpr: 0.96800, Avg fpr: 0.07794, total FA: 608

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.53270 | acc=0.3022 | tpr=0.0049 | fpr=0.0523 | 4807.4 samples/s | 18.8 steps/s
Avg test loss: 5.54126, Avg test acc: 0.30075, Avg tpr: 0.00600, Avg fpr: 0.05102, total FA: 398

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.78562 | acc=0.3063 | tpr=0.0033 | fpr=0.0359 | 4895.3 samples/s | 19.1 steps/s
Avg test loss: 4.80055, Avg test acc: 0.30331, Avg tpr: 0.00332, Avg fpr: 0.03692, total FA: 288

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.01976 | acc=0.2972 | tpr=0.0054 | fpr=0.0691 | 4885.6 samples/s | 19.1 steps/s
Avg test loss: 5.02581, Avg test acc: 0.29586, Avg tpr: 0.00670, Avg fpr: 0.06820, total FA: 532

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.62190 | acc=0.3023 | tpr=0.0103 | fpr=0.0637 | 4764.5 samples/s | 18.6 steps/s
Avg test loss: 5.62336, Avg test acc: 0.30107, Avg tpr: 0.01137, Avg fpr: 0.06179, total FA: 482

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.09228 | acc=0.3030 | tpr=0.0094 | fpr=0.0592 | 4772.9 samples/s | 18.6 steps/s
Avg test loss: 5.10015, Avg test acc: 0.30063, Avg tpr: 0.01014, Avg fpr: 0.06051, total FA: 472

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.96616 | acc=0.0984 | tpr=0.5708 | fpr=0.9101 | 4853.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=5.93675 | acc=0.0999 | tpr=0.5458 | fpr=0.9084 | 6828.9 samples/s | 26.7 steps/s
[Step= 150] | Loss=5.95091 | acc=0.0999 | tpr=0.5476 | fpr=0.9083 | 8059.8 samples/s | 31.5 steps/s
[Step= 200] | Loss=5.94264 | acc=0.1001 | tpr=0.5388 | fpr=0.9079 | 8045.4 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.94717 | acc=0.1004 | tpr=0.5485 | fpr=0.9077 | 7595.8 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.94323 | acc=0.1005 | tpr=0.5556 | fpr=0.9078 | 7651.6 samples/s | 29.9 steps/s
[Step= 350] | Loss=5.93495 | acc=0.1008 | tpr=0.5529 | fpr=0.9074 | 7869.9 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.93436 | acc=0.1007 | tpr=0.5503 | fpr=0.9075 | 8201.6 samples/s | 32.0 steps/s
[Step= 450] | Loss=5.93930 | acc=0.1011 | tpr=0.5487 | fpr=0.9070 | 7905.8 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.94188 | acc=0.1012 | tpr=0.5427 | fpr=0.9067 | 7615.2 samples/s | 29.7 steps/s
[Step= 550] | Loss=5.94498 | acc=0.1010 | tpr=0.5392 | fpr=0.9070 | 14307.8 samples/s | 55.9 steps/s
Avg test loss: 5.94664, Avg test acc: 0.10088, Avg tpr: 0.53922, Avg fpr: 0.90709, total FA: 125947

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.64974 | acc=0.0928 | tpr=0.4381 | fpr=0.9134 | 4778.0 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.63658 | acc=0.0936 | tpr=0.4563 | fpr=0.9131 | 7061.8 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.63832 | acc=0.0945 | tpr=0.4524 | fpr=0.9121 | 7700.8 samples/s | 30.1 steps/s
[Step= 200] | Loss=5.63306 | acc=0.0939 | tpr=0.4350 | fpr=0.9123 | 8365.6 samples/s | 32.7 steps/s
[Step= 250] | Loss=5.63700 | acc=0.0943 | tpr=0.4419 | fpr=0.9121 | 7693.5 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.63237 | acc=0.0943 | tpr=0.4509 | fpr=0.9122 | 8116.2 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.62702 | acc=0.0944 | tpr=0.4471 | fpr=0.9120 | 7635.7 samples/s | 29.8 steps/s
[Step= 400] | Loss=5.62406 | acc=0.0942 | tpr=0.4420 | fpr=0.9121 | 7603.1 samples/s | 29.7 steps/s
[Step= 450] | Loss=5.62896 | acc=0.0943 | tpr=0.4426 | fpr=0.9120 | 8071.1 samples/s | 31.5 steps/s
[Step= 500] | Loss=5.63329 | acc=0.0945 | tpr=0.4366 | fpr=0.9117 | 7814.4 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.63998 | acc=0.0941 | tpr=0.4361 | fpr=0.9121 | 14711.5 samples/s | 57.5 steps/s
Avg test loss: 5.64223, Avg test acc: 0.09403, Avg tpr: 0.43621, Avg fpr: 0.91219, total FA: 126656

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.63960 | acc=0.1036 | tpr=0.2965 | fpr=0.8999 | 4713.1 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.60725 | acc=0.1048 | tpr=0.2921 | fpr=0.8987 | 7318.1 samples/s | 28.6 steps/s
[Step= 150] | Loss=5.62139 | acc=0.1061 | tpr=0.2867 | fpr=0.8972 | 7965.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.61235 | acc=0.1065 | tpr=0.2776 | fpr=0.8966 | 7837.9 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.61451 | acc=0.1071 | tpr=0.2856 | fpr=0.8961 | 7882.1 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.60952 | acc=0.1075 | tpr=0.2945 | fpr=0.8959 | 7842.9 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.60333 | acc=0.1076 | tpr=0.2930 | fpr=0.8957 | 7751.0 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.60282 | acc=0.1077 | tpr=0.2960 | fpr=0.8957 | 7815.5 samples/s | 30.5 steps/s
[Step= 450] | Loss=5.60891 | acc=0.1078 | tpr=0.2921 | fpr=0.8955 | 7995.3 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.60969 | acc=0.1078 | tpr=0.2930 | fpr=0.8955 | 8009.3 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.61289 | acc=0.1075 | tpr=0.2945 | fpr=0.8959 | 13924.0 samples/s | 54.4 steps/s
Avg test loss: 5.61424, Avg test acc: 0.10740, Avg tpr: 0.29517, Avg fpr: 0.89601, total FA: 124409

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.51907 | acc=0.1065 | tpr=0.5088 | fpr=0.9007 | 4893.7 samples/s | 19.1 steps/s
[Step= 100] | Loss=5.49145 | acc=0.1067 | tpr=0.5117 | fpr=0.9008 | 6973.5 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.50567 | acc=0.1063 | tpr=0.5231 | fpr=0.9014 | 7598.2 samples/s | 29.7 steps/s
[Step= 200] | Loss=5.49668 | acc=0.1054 | tpr=0.5202 | fpr=0.9022 | 7906.7 samples/s | 30.9 steps/s
[Step= 250] | Loss=5.50227 | acc=0.1062 | tpr=0.5275 | fpr=0.9015 | 8480.4 samples/s | 33.1 steps/s
[Step= 300] | Loss=5.50144 | acc=0.1064 | tpr=0.5353 | fpr=0.9015 | 7507.4 samples/s | 29.3 steps/s
[Step= 350] | Loss=5.49211 | acc=0.1067 | tpr=0.5341 | fpr=0.9010 | 7957.3 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.48967 | acc=0.1067 | tpr=0.5345 | fpr=0.9011 | 7702.2 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.49493 | acc=0.1066 | tpr=0.5307 | fpr=0.9011 | 7944.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.49609 | acc=0.1066 | tpr=0.5286 | fpr=0.9010 | 7837.2 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.50089 | acc=0.1061 | tpr=0.5225 | fpr=0.9015 | 13754.3 samples/s | 53.7 steps/s
Avg test loss: 5.50221, Avg test acc: 0.10603, Avg tpr: 0.52258, Avg fpr: 0.90155, total FA: 125178

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.52256 | acc=0.1133 | tpr=0.4558 | fpr=0.8929 | 4682.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.50177 | acc=0.1170 | tpr=0.4563 | fpr=0.8894 | 7196.1 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.50194 | acc=0.1169 | tpr=0.4553 | fpr=0.8894 | 8059.1 samples/s | 31.5 steps/s
[Step= 200] | Loss=5.49556 | acc=0.1166 | tpr=0.4536 | fpr=0.8895 | 7757.7 samples/s | 30.3 steps/s
[Step= 250] | Loss=5.49795 | acc=0.1176 | tpr=0.4646 | fpr=0.8887 | 7869.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.49955 | acc=0.1178 | tpr=0.4655 | fpr=0.8886 | 8118.7 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.49094 | acc=0.1182 | tpr=0.4652 | fpr=0.8881 | 7854.7 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.49105 | acc=0.1177 | tpr=0.4612 | fpr=0.8886 | 7724.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=5.49639 | acc=0.1179 | tpr=0.4601 | fpr=0.8883 | 7963.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.49925 | acc=0.1175 | tpr=0.4564 | fpr=0.8886 | 7571.5 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.50366 | acc=0.1173 | tpr=0.4552 | fpr=0.8889 | 15098.1 samples/s | 59.0 steps/s
Avg test loss: 5.50566, Avg test acc: 0.11712, Avg tpr: 0.45444, Avg fpr: 0.88902, total FA: 123438

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08452 | acc=0.9830 | tpr=0.9602 | fpr=0.0166 | 4865.3 samples/s | 19.0 steps/s
[Step= 100] | Loss=0.08599 | acc=0.9829 | tpr=0.9638 | fpr=0.0167 | 6929.4 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.08966 | acc=0.9818 | tpr=0.9640 | fpr=0.0179 | 7583.8 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.09166 | acc=0.9820 | tpr=0.9672 | fpr=0.0178 | 8287.9 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.09045 | acc=0.9821 | tpr=0.9633 | fpr=0.0175 | 7700.4 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.09221 | acc=0.9818 | tpr=0.9629 | fpr=0.0178 | 7958.9 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.09302 | acc=0.9816 | tpr=0.9624 | fpr=0.0181 | 7737.8 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.09398 | acc=0.9812 | tpr=0.9568 | fpr=0.0184 | 7933.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.09601 | acc=0.9808 | tpr=0.9523 | fpr=0.0187 | 7801.4 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.09536 | acc=0.9808 | tpr=0.9520 | fpr=0.0187 | 7972.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.09481 | acc=0.9810 | tpr=0.9503 | fpr=0.0185 | 14024.8 samples/s | 54.8 steps/s
Avg test loss: 0.09470, Avg test acc: 0.98099, Avg tpr: 0.95048, Avg fpr: 0.01846, total FA: 2563

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08197 | acc=0.9826 | tpr=0.9292 | fpr=0.0165 | 4751.9 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.08461 | acc=0.9823 | tpr=0.9318 | fpr=0.0167 | 7076.6 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.08802 | acc=0.9820 | tpr=0.9323 | fpr=0.0171 | 8005.0 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.09022 | acc=0.9820 | tpr=0.9399 | fpr=0.0172 | 7767.8 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.08878 | acc=0.9824 | tpr=0.9389 | fpr=0.0168 | 7604.8 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.09050 | acc=0.9821 | tpr=0.9382 | fpr=0.0171 | 8045.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.09114 | acc=0.9820 | tpr=0.9386 | fpr=0.0172 | 8019.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09215 | acc=0.9818 | tpr=0.9349 | fpr=0.0174 | 7799.0 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.09419 | acc=0.9815 | tpr=0.9328 | fpr=0.0176 | 7928.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.09351 | acc=0.9815 | tpr=0.9339 | fpr=0.0176 | 7508.6 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.09316 | acc=0.9817 | tpr=0.9320 | fpr=0.0174 | 14530.3 samples/s | 56.8 steps/s
Avg test loss: 0.09305, Avg test acc: 0.98167, Avg tpr: 0.93185, Avg fpr: 0.01742, total FA: 2419

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08591 | acc=0.9802 | tpr=0.9690 | fpr=0.0196 | 4728.7 samples/s | 18.5 steps/s
[Step= 100] | Loss=0.08782 | acc=0.9801 | tpr=0.9723 | fpr=0.0198 | 7334.9 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.09192 | acc=0.9791 | tpr=0.9683 | fpr=0.0207 | 7736.7 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.09328 | acc=0.9796 | tpr=0.9727 | fpr=0.0203 | 7783.1 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.09220 | acc=0.9795 | tpr=0.9721 | fpr=0.0203 | 7954.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.09412 | acc=0.9791 | tpr=0.9687 | fpr=0.0207 | 7649.5 samples/s | 29.9 steps/s
[Step= 350] | Loss=0.09488 | acc=0.9789 | tpr=0.9687 | fpr=0.0210 | 8133.5 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.09587 | acc=0.9786 | tpr=0.9655 | fpr=0.0212 | 7574.7 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.09734 | acc=0.9783 | tpr=0.9645 | fpr=0.0214 | 8585.9 samples/s | 33.5 steps/s
[Step= 500] | Loss=0.09697 | acc=0.9782 | tpr=0.9656 | fpr=0.0215 | 7776.8 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.09647 | acc=0.9785 | tpr=0.9646 | fpr=0.0213 | 13508.7 samples/s | 52.8 steps/s
Avg test loss: 0.09636, Avg test acc: 0.97847, Avg tpr: 0.96474, Avg fpr: 0.02128, total FA: 2955

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09016 | acc=0.9811 | tpr=0.9469 | fpr=0.0183 | 4668.8 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.09144 | acc=0.9809 | tpr=0.9531 | fpr=0.0185 | 7652.1 samples/s | 29.9 steps/s
[Step= 150] | Loss=0.09492 | acc=0.9800 | tpr=0.9496 | fpr=0.0194 | 7559.7 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.09614 | acc=0.9803 | tpr=0.9541 | fpr=0.0193 | 7693.2 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.09486 | acc=0.9807 | tpr=0.9528 | fpr=0.0188 | 7982.2 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.09691 | acc=0.9805 | tpr=0.9513 | fpr=0.0190 | 7860.1 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.09768 | acc=0.9803 | tpr=0.9518 | fpr=0.0191 | 7990.6 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.09816 | acc=0.9802 | tpr=0.9497 | fpr=0.0193 | 7759.8 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10003 | acc=0.9799 | tpr=0.9479 | fpr=0.0195 | 7975.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.09922 | acc=0.9801 | tpr=0.9489 | fpr=0.0194 | 7902.9 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.09865 | acc=0.9803 | tpr=0.9491 | fpr=0.0192 | 14000.2 samples/s | 54.7 steps/s
Avg test loss: 0.09847, Avg test acc: 0.98030, Avg tpr: 0.94929, Avg fpr: 0.01914, total FA: 2657

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09250 | acc=0.9812 | tpr=0.9381 | fpr=0.0180 | 4775.7 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.09568 | acc=0.9807 | tpr=0.9467 | fpr=0.0186 | 6979.4 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.09911 | acc=0.9797 | tpr=0.9467 | fpr=0.0197 | 8036.7 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.10051 | acc=0.9798 | tpr=0.9563 | fpr=0.0198 | 7534.5 samples/s | 29.4 steps/s
[Step= 250] | Loss=0.09926 | acc=0.9800 | tpr=0.9528 | fpr=0.0195 | 8336.6 samples/s | 32.6 steps/s
[Step= 300] | Loss=0.10123 | acc=0.9798 | tpr=0.9505 | fpr=0.0197 | 7499.7 samples/s | 29.3 steps/s
[Step= 350] | Loss=0.10183 | acc=0.9796 | tpr=0.9518 | fpr=0.0199 | 7982.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.10313 | acc=0.9793 | tpr=0.9475 | fpr=0.0201 | 8178.6 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.10520 | acc=0.9791 | tpr=0.9450 | fpr=0.0203 | 7837.6 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.10470 | acc=0.9791 | tpr=0.9449 | fpr=0.0203 | 7589.8 samples/s | 29.6 steps/s
[Step= 550] | Loss=0.10417 | acc=0.9793 | tpr=0.9447 | fpr=0.0200 | 14645.4 samples/s | 57.2 steps/s
Avg test loss: 0.10407, Avg test acc: 0.97933, Avg tpr: 0.94453, Avg fpr: 0.02004, total FA: 2782

server round 46/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=448.6] | Loss=0.00763 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=21.751 | 5732.7 samples/s | 89.6 steps/s
[Step=92050 Epoch=448.9] | Loss=0.00885 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=21.757 | 4159.8 samples/s | 65.0 steps/s
[Step=92100 Epoch=449.1] | Loss=0.00936 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=21.764 | 5066.3 samples/s | 79.2 steps/s
[Step=92150 Epoch=449.3] | Loss=0.00915 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=21.771 | 5211.8 samples/s | 81.4 steps/s
[Step=92200 Epoch=449.6] | Loss=0.00906 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.894 | L2-Norm(final)=21.777 | 7421.2 samples/s | 116.0 steps/s
[Step=92250 Epoch=449.8] | Loss=0.00876 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.897 | L2-Norm(final)=21.783 | 2201.5 samples/s | 34.4 steps/s
[Step=92300 Epoch=450.1] | Loss=0.00871 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.900 | L2-Norm(final)=21.790 | 5098.2 samples/s | 79.7 steps/s
[Step=92350 Epoch=450.3] | Loss=0.00841 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=21.796 | 5030.5 samples/s | 78.6 steps/s
[Step=92400 Epoch=450.6] | Loss=0.00844 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.905 | L2-Norm(final)=21.802 | 6890.2 samples/s | 107.7 steps/s
[Step=92450 Epoch=450.8] | Loss=0.00835 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.908 | L2-Norm(final)=21.808 | 2288.4 samples/s | 35.8 steps/s
[Step=92500 Epoch=451.0] | Loss=0.00832 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.910 | L2-Norm(final)=21.813 | 5006.7 samples/s | 78.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=451.1] | Loss=0.00907 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.933 | L2-Norm(final)=21.870 | 5966.3 samples/s | 93.2 steps/s
[Step=92550 Epoch=451.3] | Loss=0.00948 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=21.876 | 3754.7 samples/s | 58.7 steps/s
[Step=92600 Epoch=451.5] | Loss=0.00898 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=21.880 | 4449.8 samples/s | 69.5 steps/s
[Step=92650 Epoch=451.8] | Loss=0.00869 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=21.885 | 4531.3 samples/s | 70.8 steps/s
[Step=92700 Epoch=452.0] | Loss=0.00836 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=21.889 | 6399.0 samples/s | 100.0 steps/s
[Step=92750 Epoch=452.3] | Loss=0.00866 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=21.893 | 2070.0 samples/s | 32.3 steps/s
[Step=92800 Epoch=452.5] | Loss=0.00811 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=21.897 | 4539.9 samples/s | 70.9 steps/s
[Step=92850 Epoch=452.8] | Loss=0.00766 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=21.900 | 4456.7 samples/s | 69.6 steps/s
[Step=92900 Epoch=453.0] | Loss=0.00722 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=21.904 | 5768.6 samples/s | 90.1 steps/s
[Step=92950 Epoch=453.2] | Loss=0.00686 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=21.907 | 2162.5 samples/s | 33.8 steps/s
[Step=93000 Epoch=453.5] | Loss=0.00657 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=21.909 | 4487.5 samples/s | 70.1 steps/s
[Step=93050 Epoch=453.7] | Loss=0.00628 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.968 | L2-Norm(final)=21.912 | 4442.2 samples/s | 69.4 steps/s
[Step=93100 Epoch=454.0] | Loss=0.00606 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=21.915 | 5416.1 samples/s | 84.6 steps/s
[Step=93150 Epoch=454.2] | Loss=0.00585 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=21.918 | 2189.3 samples/s | 34.2 steps/s
[Step=93200 Epoch=454.5] | Loss=0.00564 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=21.920 | 4424.8 samples/s | 69.1 steps/s
[Step=93250 Epoch=454.7] | Loss=0.00549 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=21.923 | 4497.9 samples/s | 70.3 steps/s
[Step=93300 Epoch=454.9] | Loss=0.00538 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=21.925 | 4985.5 samples/s | 77.9 steps/s
[Step=93350 Epoch=455.2] | Loss=0.00523 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=21.928 | 2303.8 samples/s | 36.0 steps/s
[Step=93400 Epoch=455.4] | Loss=0.00507 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=21.930 | 4501.5 samples/s | 70.3 steps/s
[Step=93450 Epoch=455.7] | Loss=0.00499 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.978 | L2-Norm(final)=21.932 | 4494.3 samples/s | 70.2 steps/s
[Step=93500 Epoch=455.9] | Loss=0.00491 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.979 | L2-Norm(final)=21.935 | 4448.9 samples/s | 69.5 steps/s
[Step=93550 Epoch=456.2] | Loss=0.00481 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=21.937 | 2437.5 samples/s | 38.1 steps/s
[Step=93600 Epoch=456.4] | Loss=0.00467 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=21.939 | 4425.6 samples/s | 69.2 steps/s
[Step=93650 Epoch=456.7] | Loss=0.00461 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=21.942 | 4445.5 samples/s | 69.5 steps/s
[Step=93700 Epoch=456.9] | Loss=0.00457 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=21.944 | 4451.4 samples/s | 69.6 steps/s
[Step=93750 Epoch=457.1] | Loss=0.00449 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=21.946 | 2441.5 samples/s | 38.1 steps/s
[Step=93800 Epoch=457.4] | Loss=0.00442 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=21.948 | 4478.7 samples/s | 70.0 steps/s
[Step=93850 Epoch=457.6] | Loss=0.00436 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=21.951 | 4389.0 samples/s | 68.6 steps/s
[Step=93900 Epoch=457.9] | Loss=0.00430 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.985 | L2-Norm(final)=21.953 | 4523.1 samples/s | 70.7 steps/s
[Step=93950 Epoch=458.1] | Loss=0.00425 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=21.955 | 2441.7 samples/s | 38.2 steps/s
[Step=94000 Epoch=458.4] | Loss=0.00420 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.987 | L2-Norm(final)=21.957 | 4557.1 samples/s | 71.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step94000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=448.9] | Loss=0.00718 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.469 | L2-Norm(final)=22.697 | 4894.0 samples/s | 76.5 steps/s
[Step=92050 Epoch=449.2] | Loss=0.00884 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.473 | L2-Norm(final)=22.703 | 4622.3 samples/s | 72.2 steps/s
[Step=92100 Epoch=449.4] | Loss=0.00763 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.478 | L2-Norm(final)=22.711 | 4915.0 samples/s | 76.8 steps/s
[Step=92150 Epoch=449.6] | Loss=0.00726 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.482 | L2-Norm(final)=22.719 | 4929.3 samples/s | 77.0 steps/s
[Step=92200 Epoch=449.9] | Loss=0.00732 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.485 | L2-Norm(final)=22.726 | 7933.7 samples/s | 124.0 steps/s
[Step=92250 Epoch=450.1] | Loss=0.00732 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.488 | L2-Norm(final)=22.734 | 2228.0 samples/s | 34.8 steps/s
[Step=92300 Epoch=450.4] | Loss=0.00710 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.491 | L2-Norm(final)=22.740 | 4998.3 samples/s | 78.1 steps/s
[Step=92350 Epoch=450.6] | Loss=0.00706 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=22.747 | 4909.3 samples/s | 76.7 steps/s
[Step=92400 Epoch=450.9] | Loss=0.00698 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=22.754 | 7189.4 samples/s | 112.3 steps/s
[Step=92450 Epoch=451.1] | Loss=0.00707 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.499 | L2-Norm(final)=22.760 | 2280.1 samples/s | 35.6 steps/s
[Step=92500 Epoch=451.4] | Loss=0.00694 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.502 | L2-Norm(final)=22.767 | 5097.5 samples/s | 79.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=451.4] | Loss=0.00641 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=22.831 | 5482.2 samples/s | 85.7 steps/s
[Step=92550 Epoch=451.6] | Loss=0.00809 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.534 | L2-Norm(final)=22.837 | 4115.9 samples/s | 64.3 steps/s
[Step=92600 Epoch=451.8] | Loss=0.00810 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=22.842 | 4567.7 samples/s | 71.4 steps/s
[Step=92650 Epoch=452.1] | Loss=0.00754 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.543 | L2-Norm(final)=22.847 | 4406.1 samples/s | 68.8 steps/s
[Step=92700 Epoch=452.3] | Loss=0.00717 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.546 | L2-Norm(final)=22.851 | 6633.2 samples/s | 103.6 steps/s
[Step=92750 Epoch=452.6] | Loss=0.00677 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.549 | L2-Norm(final)=22.855 | 2090.7 samples/s | 32.7 steps/s
[Step=92800 Epoch=452.8] | Loss=0.00629 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=22.859 | 4436.4 samples/s | 69.3 steps/s
[Step=92850 Epoch=453.1] | Loss=0.00600 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.554 | L2-Norm(final)=22.863 | 4404.8 samples/s | 68.8 steps/s
[Step=92900 Epoch=453.3] | Loss=0.00568 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.556 | L2-Norm(final)=22.867 | 6070.1 samples/s | 94.8 steps/s
[Step=92950 Epoch=453.6] | Loss=0.00540 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=22.870 | 2117.8 samples/s | 33.1 steps/s
[Step=93000 Epoch=453.8] | Loss=0.00510 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=22.873 | 4445.6 samples/s | 69.5 steps/s
[Step=93050 Epoch=454.0] | Loss=0.00493 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.561 | L2-Norm(final)=22.876 | 4463.0 samples/s | 69.7 steps/s
[Step=93100 Epoch=454.3] | Loss=0.00483 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.563 | L2-Norm(final)=22.880 | 5632.9 samples/s | 88.0 steps/s
[Step=93150 Epoch=454.5] | Loss=0.00467 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.564 | L2-Norm(final)=22.883 | 2184.7 samples/s | 34.1 steps/s
[Step=93200 Epoch=454.8] | Loss=0.00459 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.566 | L2-Norm(final)=22.886 | 4396.8 samples/s | 68.7 steps/s
[Step=93250 Epoch=455.0] | Loss=0.00457 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.567 | L2-Norm(final)=22.889 | 4478.5 samples/s | 70.0 steps/s
[Step=93300 Epoch=455.3] | Loss=0.00443 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.568 | L2-Norm(final)=22.891 | 5204.4 samples/s | 81.3 steps/s
[Step=93350 Epoch=455.5] | Loss=0.00430 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.569 | L2-Norm(final)=22.894 | 2273.8 samples/s | 35.5 steps/s
[Step=93400 Epoch=455.7] | Loss=0.00416 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=22.897 | 4531.9 samples/s | 70.8 steps/s
[Step=93450 Epoch=456.0] | Loss=0.00410 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.572 | L2-Norm(final)=22.900 | 4417.2 samples/s | 69.0 steps/s
[Step=93500 Epoch=456.2] | Loss=0.00409 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.572 | L2-Norm(final)=22.903 | 4850.0 samples/s | 75.8 steps/s
[Step=93550 Epoch=456.5] | Loss=0.00402 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=22.905 | 2329.6 samples/s | 36.4 steps/s
[Step=93600 Epoch=456.7] | Loss=0.00396 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.574 | L2-Norm(final)=22.908 | 4533.0 samples/s | 70.8 steps/s
[Step=93650 Epoch=457.0] | Loss=0.00388 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.575 | L2-Norm(final)=22.910 | 4424.3 samples/s | 69.1 steps/s
[Step=93700 Epoch=457.2] | Loss=0.00383 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=22.913 | 4572.1 samples/s | 71.4 steps/s
[Step=93750 Epoch=457.5] | Loss=0.00378 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.577 | L2-Norm(final)=22.916 | 2472.5 samples/s | 38.6 steps/s
[Step=93800 Epoch=457.7] | Loss=0.00372 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=22.918 | 4327.8 samples/s | 67.6 steps/s
[Step=93850 Epoch=457.9] | Loss=0.00369 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.578 | L2-Norm(final)=22.921 | 4508.2 samples/s | 70.4 steps/s
[Step=93900 Epoch=458.2] | Loss=0.00365 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.579 | L2-Norm(final)=22.923 | 4368.1 samples/s | 68.3 steps/s
[Step=93950 Epoch=458.4] | Loss=0.00362 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.580 | L2-Norm(final)=22.926 | 2436.6 samples/s | 38.1 steps/s
[Step=94000 Epoch=458.7] | Loss=0.00356 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.581 | L2-Norm(final)=22.928 | 4395.8 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step94000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=448.3] | Loss=0.01703 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.283 | L2-Norm(final)=22.680 | 5409.0 samples/s | 84.5 steps/s
[Step=92050 Epoch=448.5] | Loss=0.00941 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=22.685 | 4457.5 samples/s | 69.6 steps/s
[Step=92100 Epoch=448.8] | Loss=0.00904 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.291 | L2-Norm(final)=22.692 | 5087.2 samples/s | 79.5 steps/s
[Step=92150 Epoch=449.0] | Loss=0.00891 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.295 | L2-Norm(final)=22.699 | 4983.4 samples/s | 77.9 steps/s
[Step=92200 Epoch=449.2] | Loss=0.00863 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.298 | L2-Norm(final)=22.706 | 7851.4 samples/s | 122.7 steps/s
[Step=92250 Epoch=449.5] | Loss=0.00825 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.301 | L2-Norm(final)=22.712 | 2183.5 samples/s | 34.1 steps/s
[Step=92300 Epoch=449.7] | Loss=0.00817 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=22.719 | 5082.5 samples/s | 79.4 steps/s
[Step=92350 Epoch=450.0] | Loss=0.00814 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=22.725 | 5182.9 samples/s | 81.0 steps/s
[Step=92400 Epoch=450.2] | Loss=0.00814 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=22.731 | 6627.8 samples/s | 103.6 steps/s
[Step=92450 Epoch=450.5] | Loss=0.00796 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.312 | L2-Norm(final)=22.737 | 2344.6 samples/s | 36.6 steps/s
[Step=92500 Epoch=450.7] | Loss=0.00793 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=22.743 | 5040.5 samples/s | 78.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=450.7] | Loss=0.00307 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.340 | L2-Norm(final)=22.801 | 5366.1 samples/s | 83.8 steps/s
[Step=92550 Epoch=450.9] | Loss=0.00788 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.344 | L2-Norm(final)=22.807 | 3912.0 samples/s | 61.1 steps/s
[Step=92600 Epoch=451.2] | Loss=0.00790 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=22.812 | 4470.9 samples/s | 69.9 steps/s
[Step=92650 Epoch=451.4] | Loss=0.00769 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=22.817 | 4472.9 samples/s | 69.9 steps/s
[Step=92700 Epoch=451.7] | Loss=0.00754 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=22.821 | 6546.1 samples/s | 102.3 steps/s
[Step=92750 Epoch=451.9] | Loss=0.00708 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=22.825 | 2084.1 samples/s | 32.6 steps/s
[Step=92800 Epoch=452.2] | Loss=0.00676 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.362 | L2-Norm(final)=22.829 | 4475.2 samples/s | 69.9 steps/s
[Step=92850 Epoch=452.4] | Loss=0.00663 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=22.833 | 4471.6 samples/s | 69.9 steps/s
[Step=92900 Epoch=452.7] | Loss=0.00642 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=22.836 | 5886.6 samples/s | 92.0 steps/s
[Step=92950 Epoch=452.9] | Loss=0.00611 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=22.840 | 2124.6 samples/s | 33.2 steps/s
[Step=93000 Epoch=453.1] | Loss=0.00587 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.371 | L2-Norm(final)=22.843 | 4493.4 samples/s | 70.2 steps/s
[Step=93050 Epoch=453.4] | Loss=0.00567 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=22.846 | 4440.8 samples/s | 69.4 steps/s
[Step=93100 Epoch=453.6] | Loss=0.00558 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.374 | L2-Norm(final)=22.849 | 5425.7 samples/s | 84.8 steps/s
[Step=93150 Epoch=453.9] | Loss=0.00537 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=22.852 | 2254.0 samples/s | 35.2 steps/s
[Step=93200 Epoch=454.1] | Loss=0.00524 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=22.855 | 4448.0 samples/s | 69.5 steps/s
[Step=93250 Epoch=454.4] | Loss=0.00511 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=22.858 | 4463.7 samples/s | 69.7 steps/s
[Step=93300 Epoch=454.6] | Loss=0.00499 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.379 | L2-Norm(final)=22.860 | 4865.6 samples/s | 76.0 steps/s
[Step=93350 Epoch=454.8] | Loss=0.00494 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.381 | L2-Norm(final)=22.863 | 2327.4 samples/s | 36.4 steps/s
[Step=93400 Epoch=455.1] | Loss=0.00483 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=22.866 | 4574.7 samples/s | 71.5 steps/s
[Step=93450 Epoch=455.3] | Loss=0.00482 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=22.869 | 4406.1 samples/s | 68.8 steps/s
[Step=93500 Epoch=455.6] | Loss=0.00472 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.384 | L2-Norm(final)=22.871 | 4610.1 samples/s | 72.0 steps/s
[Step=93550 Epoch=455.8] | Loss=0.00461 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.385 | L2-Norm(final)=22.874 | 2450.9 samples/s | 38.3 steps/s
[Step=93600 Epoch=456.1] | Loss=0.00451 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.386 | L2-Norm(final)=22.876 | 4427.0 samples/s | 69.2 steps/s
[Step=93650 Epoch=456.3] | Loss=0.00444 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.387 | L2-Norm(final)=22.879 | 4360.6 samples/s | 68.1 steps/s
[Step=93700 Epoch=456.6] | Loss=0.00438 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=22.881 | 4483.9 samples/s | 70.1 steps/s
[Step=93750 Epoch=456.8] | Loss=0.00434 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=22.884 | 2450.6 samples/s | 38.3 steps/s
[Step=93800 Epoch=457.0] | Loss=0.00426 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=22.886 | 4489.3 samples/s | 70.1 steps/s
[Step=93850 Epoch=457.3] | Loss=0.00419 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.390 | L2-Norm(final)=22.889 | 4461.2 samples/s | 69.7 steps/s
[Step=93900 Epoch=457.5] | Loss=0.00414 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=22.891 | 4465.5 samples/s | 69.8 steps/s
[Step=93950 Epoch=457.8] | Loss=0.00411 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=22.894 | 2460.9 samples/s | 38.5 steps/s
[Step=94000 Epoch=458.0] | Loss=0.00406 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.392 | L2-Norm(final)=22.896 | 4498.1 samples/s | 70.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step94000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=448.6] | Loss=0.01241 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=22.718 | 5390.9 samples/s | 84.2 steps/s
[Step=92050 Epoch=448.9] | Loss=0.01159 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.966 | L2-Norm(final)=22.722 | 4492.0 samples/s | 70.2 steps/s
[Step=92100 Epoch=449.1] | Loss=0.01025 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=22.729 | 5085.2 samples/s | 79.5 steps/s
[Step=92150 Epoch=449.4] | Loss=0.00960 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=22.735 | 4973.5 samples/s | 77.7 steps/s
[Step=92200 Epoch=449.6] | Loss=0.00902 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.977 | L2-Norm(final)=22.741 | 7915.5 samples/s | 123.7 steps/s
[Step=92250 Epoch=449.9] | Loss=0.00867 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=22.747 | 2239.6 samples/s | 35.0 steps/s
[Step=92300 Epoch=450.1] | Loss=0.00849 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=22.753 | 4923.4 samples/s | 76.9 steps/s
[Step=92350 Epoch=450.4] | Loss=0.00839 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=22.759 | 4875.1 samples/s | 76.2 steps/s
[Step=92400 Epoch=450.6] | Loss=0.00825 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.987 | L2-Norm(final)=22.765 | 7036.9 samples/s | 110.0 steps/s
[Step=92450 Epoch=450.8] | Loss=0.00824 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=22.771 | 2292.4 samples/s | 35.8 steps/s
[Step=92500 Epoch=451.1] | Loss=0.00814 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=22.777 | 5032.9 samples/s | 78.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=451.1] | Loss=0.00552 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=22.834 | 5567.6 samples/s | 87.0 steps/s
[Step=92550 Epoch=451.3] | Loss=0.00776 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=22.838 | 3897.4 samples/s | 60.9 steps/s
[Step=92600 Epoch=451.6] | Loss=0.00758 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=22.843 | 4481.9 samples/s | 70.0 steps/s
[Step=92650 Epoch=451.8] | Loss=0.00788 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=22.848 | 4374.5 samples/s | 68.4 steps/s
[Step=92700 Epoch=452.1] | Loss=0.00769 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=22.852 | 6581.0 samples/s | 102.8 steps/s
[Step=92750 Epoch=452.3] | Loss=0.00714 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.035 | L2-Norm(final)=22.857 | 2095.0 samples/s | 32.7 steps/s
[Step=92800 Epoch=452.5] | Loss=0.00672 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=22.860 | 4410.2 samples/s | 68.9 steps/s
[Step=92850 Epoch=452.8] | Loss=0.00638 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=22.864 | 4507.6 samples/s | 70.4 steps/s
[Step=92900 Epoch=453.0] | Loss=0.00600 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=22.868 | 5905.3 samples/s | 92.3 steps/s
[Step=92950 Epoch=453.3] | Loss=0.00568 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=22.871 | 2183.4 samples/s | 34.1 steps/s
[Step=93000 Epoch=453.5] | Loss=0.00550 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=22.874 | 4452.4 samples/s | 69.6 steps/s
[Step=93050 Epoch=453.8] | Loss=0.00532 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=22.877 | 4373.4 samples/s | 68.3 steps/s
[Step=93100 Epoch=454.0] | Loss=0.00512 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=22.880 | 5443.9 samples/s | 85.1 steps/s
[Step=93150 Epoch=454.3] | Loss=0.00489 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=22.883 | 2253.2 samples/s | 35.2 steps/s
[Step=93200 Epoch=454.5] | Loss=0.00479 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.053 | L2-Norm(final)=22.886 | 4422.4 samples/s | 69.1 steps/s
[Step=93250 Epoch=454.7] | Loss=0.00466 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=22.889 | 4462.9 samples/s | 69.7 steps/s
[Step=93300 Epoch=455.0] | Loss=0.00458 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=22.891 | 5008.6 samples/s | 78.3 steps/s
[Step=93350 Epoch=455.2] | Loss=0.00443 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=22.894 | 2320.2 samples/s | 36.3 steps/s
[Step=93400 Epoch=455.5] | Loss=0.00435 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.058 | L2-Norm(final)=22.897 | 4431.3 samples/s | 69.2 steps/s
[Step=93450 Epoch=455.7] | Loss=0.00424 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=22.899 | 4493.5 samples/s | 70.2 steps/s
[Step=93500 Epoch=456.0] | Loss=0.00418 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=22.902 | 4607.6 samples/s | 72.0 steps/s
[Step=93550 Epoch=456.2] | Loss=0.00409 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=22.905 | 2422.7 samples/s | 37.9 steps/s
[Step=93600 Epoch=456.4] | Loss=0.00401 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=22.907 | 4592.5 samples/s | 71.8 steps/s
[Step=93650 Epoch=456.7] | Loss=0.00393 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=22.910 | 4344.7 samples/s | 67.9 steps/s
[Step=93700 Epoch=456.9] | Loss=0.00387 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=22.912 | 4463.0 samples/s | 69.7 steps/s
[Step=93750 Epoch=457.2] | Loss=0.00384 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.065 | L2-Norm(final)=22.915 | 2468.5 samples/s | 38.6 steps/s
[Step=93800 Epoch=457.4] | Loss=0.00379 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=22.917 | 4320.4 samples/s | 67.5 steps/s
[Step=93850 Epoch=457.7] | Loss=0.00371 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=22.919 | 4487.8 samples/s | 70.1 steps/s
[Step=93900 Epoch=457.9] | Loss=0.00364 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=22.922 | 4469.8 samples/s | 69.8 steps/s
[Step=93950 Epoch=458.2] | Loss=0.00359 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.068 | L2-Norm(final)=22.924 | 2500.0 samples/s | 39.1 steps/s
[Step=94000 Epoch=458.4] | Loss=0.00353 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=22.927 | 4398.0 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step94000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=451.2] | Loss=0.01359 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.594 | L2-Norm(final)=22.822 | 4919.5 samples/s | 76.9 steps/s
[Step=92050 Epoch=451.4] | Loss=0.00767 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=22.827 | 4670.8 samples/s | 73.0 steps/s
[Step=92100 Epoch=451.6] | Loss=0.00799 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=22.834 | 5052.0 samples/s | 78.9 steps/s
[Step=92150 Epoch=451.9] | Loss=0.00762 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.605 | L2-Norm(final)=22.841 | 5036.5 samples/s | 78.7 steps/s
[Step=92200 Epoch=452.1] | Loss=0.00737 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=22.848 | 8118.2 samples/s | 126.8 steps/s
[Step=92250 Epoch=452.4] | Loss=0.00733 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.611 | L2-Norm(final)=22.854 | 2210.7 samples/s | 34.5 steps/s
[Step=92300 Epoch=452.6] | Loss=0.00725 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=22.861 | 4967.4 samples/s | 77.6 steps/s
[Step=92350 Epoch=452.9] | Loss=0.00700 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=22.867 | 5057.8 samples/s | 79.0 steps/s
[Step=92400 Epoch=453.1] | Loss=0.00703 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=22.873 | 7360.1 samples/s | 115.0 steps/s
[Step=92450 Epoch=453.4] | Loss=0.00697 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=22.879 | 2223.4 samples/s | 34.7 steps/s
[Step=92500 Epoch=453.6] | Loss=0.00692 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.624 | L2-Norm(final)=22.885 | 5202.1 samples/s | 81.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=453.6] | Loss=0.00181 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=22.943 | 5404.1 samples/s | 84.4 steps/s
[Step=92550 Epoch=453.9] | Loss=0.00729 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=22.948 | 4007.3 samples/s | 62.6 steps/s
[Step=92600 Epoch=454.1] | Loss=0.00758 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=22.953 | 4512.2 samples/s | 70.5 steps/s
[Step=92650 Epoch=454.3] | Loss=0.00767 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=22.958 | 4494.1 samples/s | 70.2 steps/s
[Step=92700 Epoch=454.6] | Loss=0.00708 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=22.962 | 6663.6 samples/s | 104.1 steps/s
[Step=92750 Epoch=454.8] | Loss=0.00660 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=22.966 | 2089.8 samples/s | 32.7 steps/s
[Step=92800 Epoch=455.1] | Loss=0.00622 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=22.970 | 4343.0 samples/s | 67.9 steps/s
[Step=92850 Epoch=455.3] | Loss=0.00582 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=22.973 | 4487.3 samples/s | 70.1 steps/s
[Step=92900 Epoch=455.6] | Loss=0.00553 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=22.977 | 6237.6 samples/s | 97.5 steps/s
[Step=92950 Epoch=455.8] | Loss=0.00538 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.676 | L2-Norm(final)=22.980 | 2107.5 samples/s | 32.9 steps/s
[Step=93000 Epoch=456.1] | Loss=0.00521 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=22.983 | 4446.6 samples/s | 69.5 steps/s
[Step=93050 Epoch=456.3] | Loss=0.00501 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=22.986 | 4498.0 samples/s | 70.3 steps/s
[Step=93100 Epoch=456.5] | Loss=0.00479 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=22.989 | 5684.2 samples/s | 88.8 steps/s
[Step=93150 Epoch=456.8] | Loss=0.00464 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=22.992 | 2165.8 samples/s | 33.8 steps/s
[Step=93200 Epoch=457.0] | Loss=0.00453 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=22.995 | 4489.3 samples/s | 70.1 steps/s
[Step=93250 Epoch=457.3] | Loss=0.00437 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=22.998 | 4449.2 samples/s | 69.5 steps/s
[Step=93300 Epoch=457.5] | Loss=0.00431 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.685 | L2-Norm(final)=23.001 | 5531.6 samples/s | 86.4 steps/s
[Step=93350 Epoch=457.8] | Loss=0.00420 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=23.004 | 2225.7 samples/s | 34.8 steps/s
[Step=93400 Epoch=458.0] | Loss=0.00411 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=23.006 | 4526.5 samples/s | 70.7 steps/s
[Step=93450 Epoch=458.3] | Loss=0.00399 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=23.009 | 4321.2 samples/s | 67.5 steps/s
[Step=93500 Epoch=458.5] | Loss=0.00394 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=23.012 | 5250.8 samples/s | 82.0 steps/s
[Step=93550 Epoch=458.8] | Loss=0.00385 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=23.014 | 2293.1 samples/s | 35.8 steps/s
[Step=93600 Epoch=459.0] | Loss=0.00378 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=23.017 | 4449.8 samples/s | 69.5 steps/s
[Step=93650 Epoch=459.2] | Loss=0.00372 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=23.020 | 4471.9 samples/s | 69.9 steps/s
[Step=93700 Epoch=459.5] | Loss=0.00367 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.693 | L2-Norm(final)=23.022 | 4915.0 samples/s | 76.8 steps/s
[Step=93750 Epoch=459.7] | Loss=0.00365 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.694 | L2-Norm(final)=23.025 | 2323.6 samples/s | 36.3 steps/s
[Step=93800 Epoch=460.0] | Loss=0.00360 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.694 | L2-Norm(final)=23.027 | 4423.8 samples/s | 69.1 steps/s
[Step=93850 Epoch=460.2] | Loss=0.00353 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=23.030 | 4477.2 samples/s | 70.0 steps/s
[Step=93900 Epoch=460.5] | Loss=0.00347 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=23.032 | 4630.6 samples/s | 72.4 steps/s
[Step=93950 Epoch=460.7] | Loss=0.00341 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=23.035 | 2407.6 samples/s | 37.6 steps/s
[Step=94000 Epoch=461.0] | Loss=0.00336 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.697 | L2-Norm(final)=23.037 | 4363.5 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step94000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=871.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.224 | L2-Norm(final)=11.451 | 5548.4 samples/s | 86.7 steps/s
[Step=92050 Epoch=872.3] | Loss=0.00006 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.227 | L2-Norm(final)=11.463 | 3960.0 samples/s | 61.9 steps/s
[Step=92100 Epoch=872.7] | Loss=0.00007 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.235 | L2-Norm(final)=11.475 | 7204.0 samples/s | 112.6 steps/s
[Step=92150 Epoch=873.2] | Loss=0.00006 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.241 | L2-Norm(final)=11.485 | 2114.0 samples/s | 33.0 steps/s
[Step=92200 Epoch=873.7] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.246 | L2-Norm(final)=11.493 | 6552.6 samples/s | 102.4 steps/s
[Step=92250 Epoch=874.1] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.249 | L2-Norm(final)=11.500 | 2259.2 samples/s | 35.3 steps/s
[Step=92300 Epoch=874.6] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.252 | L2-Norm(final)=11.506 | 5624.6 samples/s | 87.9 steps/s
[Step=92350 Epoch=875.1] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.255 | L2-Norm(final)=11.511 | 2309.4 samples/s | 36.1 steps/s
[Step=92400 Epoch=875.6] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.258 | L2-Norm(final)=11.516 | 5246.7 samples/s | 82.0 steps/s
[Step=92450 Epoch=876.0] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.260 | L2-Norm(final)=11.521 | 2398.8 samples/s | 37.5 steps/s
[Step=92500 Epoch=876.5] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.262 | L2-Norm(final)=11.526 | 4909.1 samples/s | 76.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=876.5] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.283 | L2-Norm(final)=11.573 | 4949.4 samples/s | 77.3 steps/s
[Step=92550 Epoch=877.0] | Loss=0.00013 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.293 | L2-Norm(final)=11.578 | 3930.8 samples/s | 61.4 steps/s
[Step=92600 Epoch=877.5] | Loss=0.00009 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.302 | L2-Norm(final)=11.584 | 6226.6 samples/s | 97.3 steps/s
[Step=92650 Epoch=877.9] | Loss=0.00007 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.306 | L2-Norm(final)=11.587 | 2011.2 samples/s | 31.4 steps/s
[Step=92700 Epoch=878.4] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.308 | L2-Norm(final)=11.589 | 5506.7 samples/s | 86.0 steps/s
[Step=92750 Epoch=878.9] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.308 | L2-Norm(final)=11.591 | 2087.6 samples/s | 32.6 steps/s
[Step=92800 Epoch=879.4] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.307 | L2-Norm(final)=11.592 | 5154.7 samples/s | 80.5 steps/s
[Step=92850 Epoch=879.8] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.307 | L2-Norm(final)=11.593 | 2167.8 samples/s | 33.9 steps/s
[Step=92900 Epoch=880.3] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.305 | L2-Norm(final)=11.594 | 4736.9 samples/s | 74.0 steps/s
[Step=92950 Epoch=880.8] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.304 | L2-Norm(final)=11.594 | 2268.9 samples/s | 35.5 steps/s
[Step=93000 Epoch=881.3] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.303 | L2-Norm(final)=11.595 | 4206.9 samples/s | 65.7 steps/s
[Step=93050 Epoch=881.7] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.301 | L2-Norm(final)=11.595 | 2352.2 samples/s | 36.8 steps/s
[Step=93100 Epoch=882.2] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.299 | L2-Norm(final)=11.596 | 4235.9 samples/s | 66.2 steps/s
[Step=93150 Epoch=882.7] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.297 | L2-Norm(final)=11.596 | 2398.8 samples/s | 37.5 steps/s
[Step=93200 Epoch=883.2] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.295 | L2-Norm(final)=11.597 | 4140.5 samples/s | 64.7 steps/s
[Step=93250 Epoch=883.6] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.294 | L2-Norm(final)=11.597 | 2374.7 samples/s | 37.1 steps/s
[Step=93300 Epoch=884.1] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.292 | L2-Norm(final)=11.598 | 4303.8 samples/s | 67.2 steps/s
[Step=93350 Epoch=884.6] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.289 | L2-Norm(final)=11.598 | 2546.6 samples/s | 39.8 steps/s
[Step=93400 Epoch=885.0] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.287 | L2-Norm(final)=11.598 | 3886.1 samples/s | 60.7 steps/s
[Step=93450 Epoch=885.5] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.285 | L2-Norm(final)=11.599 | 6389.8 samples/s | 99.8 steps/s
[Step=93500 Epoch=886.0] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.283 | L2-Norm(final)=11.599 | 2026.4 samples/s | 31.7 steps/s
[Step=93550 Epoch=886.5] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.281 | L2-Norm(final)=11.600 | 5684.7 samples/s | 88.8 steps/s
[Step=93600 Epoch=886.9] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.278 | L2-Norm(final)=11.600 | 2024.4 samples/s | 31.6 steps/s
[Step=93650 Epoch=887.4] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.276 | L2-Norm(final)=11.600 | 5220.7 samples/s | 81.6 steps/s
[Step=93700 Epoch=887.9] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.274 | L2-Norm(final)=11.601 | 2178.9 samples/s | 34.0 steps/s
[Step=93750 Epoch=888.4] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.271 | L2-Norm(final)=11.601 | 4691.3 samples/s | 73.3 steps/s
[Step=93800 Epoch=888.8] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.269 | L2-Norm(final)=11.602 | 2259.1 samples/s | 35.3 steps/s
[Step=93850 Epoch=889.3] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.266 | L2-Norm(final)=11.602 | 4329.2 samples/s | 67.6 steps/s
[Step=93900 Epoch=889.8] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.263 | L2-Norm(final)=11.602 | 2294.6 samples/s | 35.9 steps/s
[Step=93950 Epoch=890.3] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.261 | L2-Norm(final)=11.603 | 4353.6 samples/s | 68.0 steps/s
[Step=94000 Epoch=890.7] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.258 | L2-Norm(final)=11.603 | 2369.1 samples/s | 37.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step94000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=875.2] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=12.700 | 5581.4 samples/s | 87.2 steps/s
[Step=92050 Epoch=875.6] | Loss=0.00013 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.189 | L2-Norm(final)=12.707 | 4279.2 samples/s | 66.9 steps/s
[Step=92100 Epoch=876.1] | Loss=0.00009 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.193 | L2-Norm(final)=12.712 | 7510.1 samples/s | 117.3 steps/s
[Step=92150 Epoch=876.6] | Loss=0.00007 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=12.716 | 2140.0 samples/s | 33.4 steps/s
[Step=92200 Epoch=877.1] | Loss=0.00006 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.197 | L2-Norm(final)=12.719 | 6634.4 samples/s | 103.7 steps/s
[Step=92250 Epoch=877.5] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.199 | L2-Norm(final)=12.723 | 2235.3 samples/s | 34.9 steps/s
[Step=92300 Epoch=878.0] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.200 | L2-Norm(final)=12.726 | 5886.2 samples/s | 92.0 steps/s
[Step=92350 Epoch=878.5] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.201 | L2-Norm(final)=12.729 | 2324.8 samples/s | 36.3 steps/s
[Step=92400 Epoch=879.0] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=12.732 | 5320.8 samples/s | 83.1 steps/s
[Step=92450 Epoch=879.4] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.204 | L2-Norm(final)=12.735 | 2402.5 samples/s | 37.5 steps/s
[Step=92500 Epoch=879.9] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.205 | L2-Norm(final)=12.738 | 4968.4 samples/s | 77.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=879.9] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.217 | L2-Norm(final)=12.767 | 5540.9 samples/s | 86.6 steps/s
[Step=92550 Epoch=880.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.212 | L2-Norm(final)=12.769 | 3721.7 samples/s | 58.2 steps/s
[Step=92600 Epoch=880.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=12.770 | 6115.6 samples/s | 95.6 steps/s
[Step=92650 Epoch=881.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.194 | L2-Norm(final)=12.771 | 2005.0 samples/s | 31.3 steps/s
[Step=92700 Epoch=881.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.182 | L2-Norm(final)=12.772 | 5686.6 samples/s | 88.9 steps/s
[Step=92750 Epoch=882.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.169 | L2-Norm(final)=12.773 | 2088.4 samples/s | 32.6 steps/s
[Step=92800 Epoch=882.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.156 | L2-Norm(final)=12.773 | 5169.2 samples/s | 80.8 steps/s
[Step=92850 Epoch=883.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=12.774 | 2157.0 samples/s | 33.7 steps/s
[Step=92900 Epoch=883.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.127 | L2-Norm(final)=12.774 | 4774.0 samples/s | 74.6 steps/s
[Step=92950 Epoch=884.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.112 | L2-Norm(final)=12.774 | 2270.0 samples/s | 35.5 steps/s
[Step=93000 Epoch=884.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.098 | L2-Norm(final)=12.775 | 4363.3 samples/s | 68.2 steps/s
[Step=93050 Epoch=885.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.083 | L2-Norm(final)=12.775 | 2388.1 samples/s | 37.3 steps/s
[Step=93100 Epoch=885.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.068 | L2-Norm(final)=12.775 | 4268.1 samples/s | 66.7 steps/s
[Step=93150 Epoch=886.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.052 | L2-Norm(final)=12.776 | 2417.6 samples/s | 37.8 steps/s
[Step=93200 Epoch=886.6] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.037 | L2-Norm(final)=12.776 | 4057.6 samples/s | 63.4 steps/s
[Step=93250 Epoch=887.0] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.022 | L2-Norm(final)=12.777 | 2380.2 samples/s | 37.2 steps/s
[Step=93300 Epoch=887.5] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.006 | L2-Norm(final)=12.777 | 4246.8 samples/s | 66.4 steps/s
[Step=93350 Epoch=888.0] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.991 | L2-Norm(final)=12.777 | 2486.6 samples/s | 38.9 steps/s
[Step=93400 Epoch=888.5] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.976 | L2-Norm(final)=12.778 | 3973.6 samples/s | 62.1 steps/s
[Step=93450 Epoch=888.9] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.960 | L2-Norm(final)=12.778 | 6579.4 samples/s | 102.8 steps/s
[Step=93500 Epoch=889.4] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.945 | L2-Norm(final)=12.779 | 2004.1 samples/s | 31.3 steps/s
[Step=93550 Epoch=889.9] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.929 | L2-Norm(final)=12.779 | 5841.1 samples/s | 91.3 steps/s
[Step=93600 Epoch=890.4] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.914 | L2-Norm(final)=12.779 | 2082.2 samples/s | 32.5 steps/s
[Step=93650 Epoch=890.8] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.898 | L2-Norm(final)=12.780 | 5265.3 samples/s | 82.3 steps/s
[Step=93700 Epoch=891.3] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.883 | L2-Norm(final)=12.780 | 2156.2 samples/s | 33.7 steps/s
[Step=93750 Epoch=891.8] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.867 | L2-Norm(final)=12.781 | 4820.7 samples/s | 75.3 steps/s
[Step=93800 Epoch=892.3] | Loss=0.00000 | Reg=0.00024 | acc=1.0000 | L2-Norm=4.852 | L2-Norm(final)=12.781 | 2222.5 samples/s | 34.7 steps/s
[Step=93850 Epoch=892.7] | Loss=0.00000 | Reg=0.00023 | acc=1.0000 | L2-Norm=4.836 | L2-Norm(final)=12.782 | 4507.2 samples/s | 70.4 steps/s
[Step=93900 Epoch=893.2] | Loss=0.00000 | Reg=0.00023 | acc=1.0000 | L2-Norm=4.821 | L2-Norm(final)=12.782 | 2366.6 samples/s | 37.0 steps/s
[Step=93950 Epoch=893.7] | Loss=0.00000 | Reg=0.00023 | acc=1.0000 | L2-Norm=4.805 | L2-Norm(final)=12.783 | 4190.3 samples/s | 65.5 steps/s
[Step=94000 Epoch=894.2] | Loss=0.00000 | Reg=0.00023 | acc=1.0000 | L2-Norm=4.790 | L2-Norm(final)=12.784 | 2394.7 samples/s | 37.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step94000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=878.6] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=11.985 | 5444.6 samples/s | 85.1 steps/s
[Step=92050 Epoch=879.0] | Loss=0.00007 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.197 | L2-Norm(final)=11.998 | 4008.2 samples/s | 62.6 steps/s
[Step=92100 Epoch=879.5] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.206 | L2-Norm(final)=12.013 | 7532.6 samples/s | 117.7 steps/s
[Step=92150 Epoch=880.0] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.211 | L2-Norm(final)=12.023 | 2119.3 samples/s | 33.1 steps/s
[Step=92200 Epoch=880.5] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.215 | L2-Norm(final)=12.031 | 6799.1 samples/s | 106.2 steps/s
[Step=92250 Epoch=880.9] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.218 | L2-Norm(final)=12.038 | 2199.2 samples/s | 34.4 steps/s
[Step=92300 Epoch=881.4] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.221 | L2-Norm(final)=12.044 | 6181.1 samples/s | 96.6 steps/s
[Step=92350 Epoch=881.9] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.224 | L2-Norm(final)=12.051 | 2277.8 samples/s | 35.6 steps/s
[Step=92400 Epoch=882.4] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.227 | L2-Norm(final)=12.056 | 5544.4 samples/s | 86.6 steps/s
[Step=92450 Epoch=882.8] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.229 | L2-Norm(final)=12.062 | 2342.1 samples/s | 36.6 steps/s
[Step=92500 Epoch=883.3] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.231 | L2-Norm(final)=12.067 | 5016.1 samples/s | 78.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=883.3] | Loss=0.00000 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.251 | L2-Norm(final)=12.117 | 5521.6 samples/s | 86.3 steps/s
[Step=92550 Epoch=883.8] | Loss=0.00012 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.246 | L2-Norm(final)=12.120 | 3750.2 samples/s | 58.6 steps/s
[Step=92600 Epoch=884.3] | Loss=0.00008 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.250 | L2-Norm(final)=12.124 | 6398.2 samples/s | 100.0 steps/s
[Step=92650 Epoch=884.8] | Loss=0.00006 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.253 | L2-Norm(final)=12.126 | 2040.3 samples/s | 31.9 steps/s
[Step=92700 Epoch=885.2] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.254 | L2-Norm(final)=12.128 | 5695.9 samples/s | 89.0 steps/s
[Step=92750 Epoch=885.7] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.254 | L2-Norm(final)=12.130 | 2051.3 samples/s | 32.1 steps/s
[Step=92800 Epoch=886.2] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.254 | L2-Norm(final)=12.131 | 5408.8 samples/s | 84.5 steps/s
[Step=92850 Epoch=886.7] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.253 | L2-Norm(final)=12.132 | 2143.5 samples/s | 33.5 steps/s
[Step=92900 Epoch=887.1] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.252 | L2-Norm(final)=12.132 | 5003.8 samples/s | 78.2 steps/s
[Step=92950 Epoch=887.6] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.251 | L2-Norm(final)=12.133 | 2250.4 samples/s | 35.2 steps/s
[Step=93000 Epoch=888.1] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.250 | L2-Norm(final)=12.134 | 4541.3 samples/s | 71.0 steps/s
[Step=93050 Epoch=888.6] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.249 | L2-Norm(final)=12.134 | 2286.5 samples/s | 35.7 steps/s
[Step=93100 Epoch=889.0] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.247 | L2-Norm(final)=12.135 | 4350.8 samples/s | 68.0 steps/s
[Step=93150 Epoch=889.5] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.246 | L2-Norm(final)=12.136 | 2321.2 samples/s | 36.3 steps/s
[Step=93200 Epoch=890.0] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.244 | L2-Norm(final)=12.136 | 4258.5 samples/s | 66.5 steps/s
[Step=93250 Epoch=890.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.243 | L2-Norm(final)=12.137 | 2387.4 samples/s | 37.3 steps/s
[Step=93300 Epoch=891.0] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.241 | L2-Norm(final)=12.137 | 4240.2 samples/s | 66.3 steps/s
[Step=93350 Epoch=891.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.240 | L2-Norm(final)=12.138 | 2383.5 samples/s | 37.2 steps/s
[Step=93400 Epoch=891.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.238 | L2-Norm(final)=12.138 | 4246.6 samples/s | 66.4 steps/s
[Step=93450 Epoch=892.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.236 | L2-Norm(final)=12.139 | 2400.5 samples/s | 37.5 steps/s
[Step=93500 Epoch=892.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.234 | L2-Norm(final)=12.139 | 4252.8 samples/s | 66.4 steps/s
[Step=93550 Epoch=893.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.232 | L2-Norm(final)=12.140 | 7069.1 samples/s | 110.5 steps/s
[Step=93600 Epoch=893.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.230 | L2-Norm(final)=12.140 | 1965.3 samples/s | 30.7 steps/s
[Step=93650 Epoch=894.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.228 | L2-Norm(final)=12.141 | 6364.0 samples/s | 99.4 steps/s
[Step=93700 Epoch=894.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=12.141 | 2020.4 samples/s | 31.6 steps/s
[Step=93750 Epoch=895.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.224 | L2-Norm(final)=12.141 | 5870.8 samples/s | 91.7 steps/s
[Step=93800 Epoch=895.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.222 | L2-Norm(final)=12.142 | 2101.1 samples/s | 32.8 steps/s
[Step=93850 Epoch=896.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.220 | L2-Norm(final)=12.142 | 5265.0 samples/s | 82.3 steps/s
[Step=93900 Epoch=896.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.218 | L2-Norm(final)=12.143 | 2125.6 samples/s | 33.2 steps/s
[Step=93950 Epoch=897.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.215 | L2-Norm(final)=12.143 | 4927.5 samples/s | 77.0 steps/s
[Step=94000 Epoch=897.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.213 | L2-Norm(final)=12.144 | 2193.9 samples/s | 34.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step94000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=866.9] | Loss=0.00062 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=11.640 | 4999.0 samples/s | 78.1 steps/s
[Step=92050 Epoch=867.4] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.642 | 4259.2 samples/s | 66.6 steps/s
[Step=92100 Epoch=867.8] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.509 | L2-Norm(final)=11.646 | 7060.0 samples/s | 110.3 steps/s
[Step=92150 Epoch=868.3] | Loss=0.00009 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.511 | L2-Norm(final)=11.650 | 2131.2 samples/s | 33.3 steps/s
[Step=92200 Epoch=868.8] | Loss=0.00009 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.514 | L2-Norm(final)=11.655 | 6399.0 samples/s | 100.0 steps/s
[Step=92250 Epoch=869.3] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.516 | L2-Norm(final)=11.658 | 2254.8 samples/s | 35.2 steps/s
[Step=92300 Epoch=869.7] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.518 | L2-Norm(final)=11.662 | 5678.2 samples/s | 88.7 steps/s
[Step=92350 Epoch=870.2] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.520 | L2-Norm(final)=11.666 | 2356.5 samples/s | 36.8 steps/s
[Step=92400 Epoch=870.7] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.522 | L2-Norm(final)=11.669 | 5000.2 samples/s | 78.1 steps/s
[Step=92450 Epoch=871.1] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.523 | L2-Norm(final)=11.673 | 2503.0 samples/s | 39.1 steps/s
[Step=92500 Epoch=871.6] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.525 | L2-Norm(final)=11.676 | 4795.6 samples/s | 74.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=871.6] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=11.711 | 5784.2 samples/s | 90.4 steps/s
[Step=92550 Epoch=872.1] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.546 | L2-Norm(final)=11.714 | 3622.4 samples/s | 56.6 steps/s
[Step=92600 Epoch=872.6] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.549 | L2-Norm(final)=11.717 | 6192.8 samples/s | 96.8 steps/s
[Step=92650 Epoch=873.0] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.550 | L2-Norm(final)=11.719 | 2050.6 samples/s | 32.0 steps/s
[Step=92700 Epoch=873.5] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.550 | L2-Norm(final)=11.720 | 5356.3 samples/s | 83.7 steps/s
[Step=92750 Epoch=874.0] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.550 | L2-Norm(final)=11.721 | 2116.6 samples/s | 33.1 steps/s
[Step=92800 Epoch=874.4] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.549 | L2-Norm(final)=11.722 | 4965.5 samples/s | 77.6 steps/s
[Step=92850 Epoch=874.9] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.549 | L2-Norm(final)=11.722 | 2238.8 samples/s | 35.0 steps/s
[Step=92900 Epoch=875.4] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.548 | L2-Norm(final)=11.723 | 4504.6 samples/s | 70.4 steps/s
[Step=92950 Epoch=875.9] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.547 | L2-Norm(final)=11.724 | 2322.2 samples/s | 36.3 steps/s
[Step=93000 Epoch=876.3] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.546 | L2-Norm(final)=11.724 | 4238.7 samples/s | 66.2 steps/s
[Step=93050 Epoch=876.8] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=11.725 | 2396.1 samples/s | 37.4 steps/s
[Step=93100 Epoch=877.3] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.543 | L2-Norm(final)=11.725 | 4209.7 samples/s | 65.8 steps/s
[Step=93150 Epoch=877.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=11.726 | 2409.3 samples/s | 37.6 steps/s
[Step=93200 Epoch=878.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.540 | L2-Norm(final)=11.726 | 4345.1 samples/s | 67.9 steps/s
[Step=93250 Epoch=878.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.539 | L2-Norm(final)=11.727 | 2637.5 samples/s | 41.2 steps/s
[Step=93300 Epoch=879.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=11.727 | 3590.0 samples/s | 56.1 steps/s
[Step=93350 Epoch=879.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.728 | 6228.7 samples/s | 97.3 steps/s
[Step=93400 Epoch=880.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.728 | 2033.6 samples/s | 31.8 steps/s
[Step=93450 Epoch=880.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.532 | L2-Norm(final)=11.729 | 5598.1 samples/s | 87.5 steps/s
[Step=93500 Epoch=881.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.531 | L2-Norm(final)=11.729 | 2092.3 samples/s | 32.7 steps/s
[Step=93550 Epoch=881.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.529 | L2-Norm(final)=11.729 | 5043.9 samples/s | 78.8 steps/s
[Step=93600 Epoch=882.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.527 | L2-Norm(final)=11.730 | 2202.4 samples/s | 34.4 steps/s
[Step=93650 Epoch=882.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.525 | L2-Norm(final)=11.730 | 4550.9 samples/s | 71.1 steps/s
[Step=93700 Epoch=882.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.523 | L2-Norm(final)=11.731 | 2299.3 samples/s | 35.9 steps/s
[Step=93750 Epoch=883.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.521 | L2-Norm(final)=11.731 | 4270.9 samples/s | 66.7 steps/s
[Step=93800 Epoch=883.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.519 | L2-Norm(final)=11.732 | 2399.9 samples/s | 37.5 steps/s
[Step=93850 Epoch=884.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.517 | L2-Norm(final)=11.732 | 4304.1 samples/s | 67.3 steps/s
[Step=93900 Epoch=884.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.515 | L2-Norm(final)=11.732 | 2406.0 samples/s | 37.6 steps/s
[Step=93950 Epoch=885.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.513 | L2-Norm(final)=11.733 | 4222.8 samples/s | 66.0 steps/s
[Step=94000 Epoch=885.7] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.511 | L2-Norm(final)=11.733 | 2534.4 samples/s | 39.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step94000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=876.9] | Loss=0.00043 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.359 | L2-Norm(final)=12.454 | 5026.3 samples/s | 78.5 steps/s
[Step=92050 Epoch=877.3] | Loss=0.00007 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.364 | L2-Norm(final)=12.463 | 4219.4 samples/s | 65.9 steps/s
[Step=92100 Epoch=877.8] | Loss=0.00009 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.474 | 7292.7 samples/s | 113.9 steps/s
[Step=92150 Epoch=878.3] | Loss=0.00008 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.375 | L2-Norm(final)=12.483 | 2128.3 samples/s | 33.3 steps/s
[Step=92200 Epoch=878.7] | Loss=0.00008 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.490 | 6892.1 samples/s | 107.7 steps/s
[Step=92250 Epoch=879.2] | Loss=0.00007 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.383 | L2-Norm(final)=12.498 | 2167.5 samples/s | 33.9 steps/s
[Step=92300 Epoch=879.7] | Loss=0.00007 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.387 | L2-Norm(final)=12.504 | 6189.9 samples/s | 96.7 steps/s
[Step=92350 Epoch=880.2] | Loss=0.00007 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.390 | L2-Norm(final)=12.510 | 2267.9 samples/s | 35.4 steps/s
[Step=92400 Epoch=880.7] | Loss=0.00006 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.392 | L2-Norm(final)=12.516 | 5732.7 samples/s | 89.6 steps/s
[Step=92450 Epoch=881.1] | Loss=0.00006 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.395 | L2-Norm(final)=12.522 | 2332.6 samples/s | 36.4 steps/s
[Step=92500 Epoch=881.6] | Loss=0.00006 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.397 | L2-Norm(final)=12.527 | 5169.2 samples/s | 80.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=881.6] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.421 | L2-Norm(final)=12.578 | 5731.8 samples/s | 89.6 steps/s
[Step=92550 Epoch=882.1] | Loss=0.00068 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.425 | L2-Norm(final)=12.583 | 3579.0 samples/s | 55.9 steps/s
[Step=92600 Epoch=882.6] | Loss=0.00070 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.431 | L2-Norm(final)=12.585 | 6345.8 samples/s | 99.2 steps/s
[Step=92650 Epoch=883.0] | Loss=0.00048 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.434 | L2-Norm(final)=12.586 | 2037.9 samples/s | 31.8 steps/s
[Step=92700 Epoch=883.5] | Loss=0.00037 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.436 | L2-Norm(final)=12.587 | 5731.8 samples/s | 89.6 steps/s
[Step=92750 Epoch=884.0] | Loss=0.00030 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.437 | L2-Norm(final)=12.588 | 2060.2 samples/s | 32.2 steps/s
[Step=92800 Epoch=884.5] | Loss=0.00025 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.438 | L2-Norm(final)=12.588 | 5373.9 samples/s | 84.0 steps/s
[Step=92850 Epoch=884.9] | Loss=0.00022 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.438 | L2-Norm(final)=12.589 | 2126.8 samples/s | 33.2 steps/s
[Step=92900 Epoch=885.4] | Loss=0.00019 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.589 | 4959.9 samples/s | 77.5 steps/s
[Step=92950 Epoch=885.9] | Loss=0.00017 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.590 | 2210.6 samples/s | 34.5 steps/s
[Step=93000 Epoch=886.4] | Loss=0.00016 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.590 | 4636.4 samples/s | 72.4 steps/s
[Step=93050 Epoch=886.9] | Loss=0.00014 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.590 | 2279.6 samples/s | 35.6 steps/s
[Step=93100 Epoch=887.3] | Loss=0.00013 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.591 | 4329.1 samples/s | 67.6 steps/s
[Step=93150 Epoch=887.8] | Loss=0.00012 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.591 | 2357.9 samples/s | 36.8 steps/s
[Step=93200 Epoch=888.3] | Loss=0.00012 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.591 | 4243.3 samples/s | 66.3 steps/s
[Step=93250 Epoch=888.8] | Loss=0.00011 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.592 | 2346.9 samples/s | 36.7 steps/s
[Step=93300 Epoch=889.2] | Loss=0.00010 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.592 | 4280.3 samples/s | 66.9 steps/s
[Step=93350 Epoch=889.7] | Loss=0.00010 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.592 | 2389.2 samples/s | 37.3 steps/s
[Step=93400 Epoch=890.2] | Loss=0.00009 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.592 | 4296.2 samples/s | 67.1 steps/s
[Step=93450 Epoch=890.7] | Loss=0.00009 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.593 | 2378.5 samples/s | 37.2 steps/s
[Step=93500 Epoch=891.1] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.593 | 4259.5 samples/s | 66.6 steps/s
[Step=93550 Epoch=891.6] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.593 | 6985.4 samples/s | 109.1 steps/s
[Step=93600 Epoch=892.1] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.593 | 1967.3 samples/s | 30.7 steps/s
[Step=93650 Epoch=892.6] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.594 | 6246.8 samples/s | 97.6 steps/s
[Step=93700 Epoch=893.0] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.594 | 2009.3 samples/s | 31.4 steps/s
[Step=93750 Epoch=893.5] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.594 | 5702.5 samples/s | 89.1 steps/s
[Step=93800 Epoch=894.0] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.594 | 2063.8 samples/s | 32.2 steps/s
[Step=93850 Epoch=894.5] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.440 | L2-Norm(final)=12.594 | 5399.4 samples/s | 84.4 steps/s
[Step=93900 Epoch=895.0] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.595 | 2136.9 samples/s | 33.4 steps/s
[Step=93950 Epoch=895.4] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.595 | 4996.1 samples/s | 78.1 steps/s
[Step=94000 Epoch=895.9] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.439 | L2-Norm(final)=12.595 | 2206.5 samples/s | 34.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.09808 | acc=0.9542 | tpr=0.9643 | fpr=0.0676 | 4837.5 samples/s | 18.9 steps/s
Avg test loss: 0.10230, Avg test acc: 0.95248, Avg tpr: 0.96340, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10473 | acc=0.9546 | tpr=0.9719 | fpr=0.0830 | 4819.5 samples/s | 18.8 steps/s
Avg test loss: 0.10475, Avg test acc: 0.95512, Avg tpr: 0.97202, Avg fpr: 0.08204, total FA: 640

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10078 | acc=0.9552 | tpr=0.9704 | fpr=0.0778 | 4943.3 samples/s | 19.3 steps/s
Avg test loss: 0.10284, Avg test acc: 0.95372, Avg tpr: 0.96829, Avg fpr: 0.07832, total FA: 611

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09370 | acc=0.9562 | tpr=0.9658 | fpr=0.0647 | 4737.7 samples/s | 18.5 steps/s
Avg test loss: 0.09894, Avg test acc: 0.95424, Avg tpr: 0.96573, Avg fpr: 0.07102, total FA: 554

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10624 | acc=0.9538 | tpr=0.9710 | fpr=0.0835 | 4827.9 samples/s | 18.9 steps/s
Avg test loss: 0.10950, Avg test acc: 0.95284, Avg tpr: 0.97057, Avg fpr: 0.08614, total FA: 672

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.92494 | acc=0.3007 | tpr=0.0064 | fpr=0.0602 | 4662.1 samples/s | 18.2 steps/s
Avg test loss: 5.93222, Avg test acc: 0.29926, Avg tpr: 0.00752, Avg fpr: 0.05909, total FA: 461

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.77438 | acc=0.3076 | tpr=0.0026 | fpr=0.0302 | 4997.0 samples/s | 19.5 steps/s
Avg test loss: 4.78905, Avg test acc: 0.30479, Avg tpr: 0.00256, Avg fpr: 0.03051, total FA: 238

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.20765 | acc=0.2967 | tpr=0.0058 | fpr=0.0716 | 4698.9 samples/s | 18.4 steps/s
Avg test loss: 5.21235, Avg test acc: 0.29470, Avg tpr: 0.00670, Avg fpr: 0.07191, total FA: 561

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.62570 | acc=0.3014 | tpr=0.0114 | fpr=0.0689 | 4699.5 samples/s | 18.4 steps/s
Avg test loss: 5.62695, Avg test acc: 0.29962, Avg tpr: 0.01236, Avg fpr: 0.06858, total FA: 535

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.93417 | acc=0.3043 | tpr=0.0107 | fpr=0.0582 | 4649.7 samples/s | 18.2 steps/s
Avg test loss: 4.93781, Avg test acc: 0.30147, Avg tpr: 0.01137, Avg fpr: 0.06051, total FA: 472

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.31430 | acc=0.1083 | tpr=0.5044 | fpr=0.8988 | 4812.0 samples/s | 18.8 steps/s
[Step= 100] | Loss=5.28674 | acc=0.1118 | tpr=0.4968 | fpr=0.8953 | 6879.5 samples/s | 26.9 steps/s
[Step= 150] | Loss=5.29674 | acc=0.1122 | tpr=0.4957 | fpr=0.8948 | 7962.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.28989 | acc=0.1125 | tpr=0.4852 | fpr=0.8943 | 7737.7 samples/s | 30.2 steps/s
[Step= 250] | Loss=5.29393 | acc=0.1134 | tpr=0.4961 | fpr=0.8935 | 7712.9 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.29075 | acc=0.1134 | tpr=0.5055 | fpr=0.8938 | 7938.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.28267 | acc=0.1135 | tpr=0.5009 | fpr=0.8935 | 8028.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.28188 | acc=0.1136 | tpr=0.4984 | fpr=0.8934 | 7660.2 samples/s | 29.9 steps/s
[Step= 450] | Loss=5.28668 | acc=0.1140 | tpr=0.4946 | fpr=0.8929 | 7902.3 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.28855 | acc=0.1140 | tpr=0.4894 | fpr=0.8928 | 7752.2 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.29175 | acc=0.1137 | tpr=0.4847 | fpr=0.8930 | 13968.7 samples/s | 54.6 steps/s
Avg test loss: 5.29343, Avg test acc: 0.11364, Avg tpr: 0.48494, Avg fpr: 0.89311, total FA: 124007

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.30657 | acc=0.0939 | tpr=0.4292 | fpr=0.9121 | 4685.7 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.29550 | acc=0.0946 | tpr=0.4478 | fpr=0.9119 | 7431.4 samples/s | 29.0 steps/s
[Step= 150] | Loss=5.29452 | acc=0.0957 | tpr=0.4409 | fpr=0.9107 | 7446.4 samples/s | 29.1 steps/s
[Step= 200] | Loss=5.28840 | acc=0.0949 | tpr=0.4240 | fpr=0.9110 | 7967.7 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.29209 | acc=0.0953 | tpr=0.4306 | fpr=0.9108 | 7821.7 samples/s | 30.6 steps/s
[Step= 300] | Loss=5.28854 | acc=0.0951 | tpr=0.4349 | fpr=0.9111 | 7613.2 samples/s | 29.7 steps/s
[Step= 350] | Loss=5.28340 | acc=0.0953 | tpr=0.4314 | fpr=0.9108 | 7966.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.28037 | acc=0.0952 | tpr=0.4316 | fpr=0.9109 | 7792.6 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.28537 | acc=0.0953 | tpr=0.4333 | fpr=0.9108 | 8019.8 samples/s | 31.3 steps/s
[Step= 500] | Loss=5.28977 | acc=0.0954 | tpr=0.4295 | fpr=0.9107 | 7673.9 samples/s | 30.0 steps/s
[Step= 550] | Loss=5.29592 | acc=0.0948 | tpr=0.4278 | fpr=0.9112 | 13802.4 samples/s | 53.9 steps/s
Avg test loss: 5.29805, Avg test acc: 0.09481, Avg tpr: 0.42829, Avg fpr: 0.91125, total FA: 126525

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.47153 | acc=0.1036 | tpr=0.3186 | fpr=0.9003 | 4644.9 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.43926 | acc=0.1059 | tpr=0.3006 | fpr=0.8978 | 7266.0 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.45534 | acc=0.1065 | tpr=0.2925 | fpr=0.8969 | 7998.3 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.44648 | acc=0.1071 | tpr=0.2852 | fpr=0.8961 | 7682.8 samples/s | 30.0 steps/s
[Step= 250] | Loss=5.44823 | acc=0.1074 | tpr=0.2908 | fpr=0.8959 | 7811.9 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.44413 | acc=0.1074 | tpr=0.2967 | fpr=0.8960 | 7703.4 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.43772 | acc=0.1076 | tpr=0.2918 | fpr=0.8957 | 7859.8 samples/s | 30.7 steps/s
[Step= 400] | Loss=5.43736 | acc=0.1077 | tpr=0.2888 | fpr=0.8956 | 8139.8 samples/s | 31.8 steps/s
[Step= 450] | Loss=5.44344 | acc=0.1077 | tpr=0.2858 | fpr=0.8955 | 7137.5 samples/s | 27.9 steps/s
[Step= 500] | Loss=5.44473 | acc=0.1076 | tpr=0.2850 | fpr=0.8956 | 8190.9 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.44814 | acc=0.1074 | tpr=0.2865 | fpr=0.8959 | 14112.4 samples/s | 55.1 steps/s
Avg test loss: 5.44941, Avg test acc: 0.10727, Avg tpr: 0.28724, Avg fpr: 0.89600, total FA: 124408

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.24296 | acc=0.1166 | tpr=0.4646 | fpr=0.8896 | 4713.4 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.21446 | acc=0.1173 | tpr=0.4520 | fpr=0.8889 | 7318.8 samples/s | 28.6 steps/s
[Step= 150] | Loss=5.22705 | acc=0.1163 | tpr=0.4611 | fpr=0.8900 | 7620.4 samples/s | 29.8 steps/s
[Step= 200] | Loss=5.21902 | acc=0.1157 | tpr=0.4536 | fpr=0.8904 | 7970.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.22428 | acc=0.1166 | tpr=0.4576 | fpr=0.8896 | 8010.9 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.22308 | acc=0.1170 | tpr=0.4669 | fpr=0.8894 | 7985.9 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.21450 | acc=0.1175 | tpr=0.4640 | fpr=0.8888 | 7340.6 samples/s | 28.7 steps/s
[Step= 400] | Loss=5.21226 | acc=0.1174 | tpr=0.4617 | fpr=0.8888 | 8236.0 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.21737 | acc=0.1174 | tpr=0.4586 | fpr=0.8888 | 7821.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.21849 | acc=0.1176 | tpr=0.4568 | fpr=0.8885 | 7636.2 samples/s | 29.8 steps/s
[Step= 550] | Loss=5.22372 | acc=0.1170 | tpr=0.4517 | fpr=0.8890 | 14748.1 samples/s | 57.6 steps/s
Avg test loss: 5.22507, Avg test acc: 0.11693, Avg tpr: 0.45206, Avg fpr: 0.88916, total FA: 123458

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.68014 | acc=0.1101 | tpr=0.4513 | fpr=0.8961 | 4503.1 samples/s | 17.6 steps/s
[Step= 100] | Loss=5.65966 | acc=0.1123 | tpr=0.4606 | fpr=0.8942 | 7571.8 samples/s | 29.6 steps/s
[Step= 150] | Loss=5.66142 | acc=0.1122 | tpr=0.4510 | fpr=0.8941 | 7975.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.65562 | acc=0.1117 | tpr=0.4459 | fpr=0.8943 | 7788.3 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.65709 | acc=0.1127 | tpr=0.4611 | fpr=0.8937 | 7616.4 samples/s | 29.8 steps/s
[Step= 300] | Loss=5.65873 | acc=0.1128 | tpr=0.4618 | fpr=0.8936 | 7867.2 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.64975 | acc=0.1132 | tpr=0.4621 | fpr=0.8931 | 7590.5 samples/s | 29.7 steps/s
[Step= 400] | Loss=5.65009 | acc=0.1123 | tpr=0.4595 | fpr=0.8940 | 8022.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.65546 | acc=0.1127 | tpr=0.4601 | fpr=0.8936 | 7702.1 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.65894 | acc=0.1123 | tpr=0.4555 | fpr=0.8939 | 7977.7 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.66415 | acc=0.1118 | tpr=0.4540 | fpr=0.8944 | 14051.5 samples/s | 54.9 steps/s
Avg test loss: 5.66628, Avg test acc: 0.11168, Avg tpr: 0.45325, Avg fpr: 0.89452, total FA: 124203

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08952 | acc=0.9822 | tpr=0.9558 | fpr=0.0173 | 4715.2 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.09083 | acc=0.9823 | tpr=0.9552 | fpr=0.0172 | 7092.3 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.09464 | acc=0.9814 | tpr=0.9582 | fpr=0.0181 | 7969.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.09655 | acc=0.9816 | tpr=0.9628 | fpr=0.0181 | 7817.2 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09538 | acc=0.9817 | tpr=0.9590 | fpr=0.0179 | 7510.6 samples/s | 29.3 steps/s
[Step= 300] | Loss=0.09737 | acc=0.9815 | tpr=0.9585 | fpr=0.0181 | 7925.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09837 | acc=0.9812 | tpr=0.9580 | fpr=0.0184 | 7652.5 samples/s | 29.9 steps/s
[Step= 400] | Loss=0.09929 | acc=0.9809 | tpr=0.9540 | fpr=0.0186 | 7705.2 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.10143 | acc=0.9805 | tpr=0.9503 | fpr=0.0189 | 7874.9 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.10083 | acc=0.9806 | tpr=0.9511 | fpr=0.0189 | 7672.6 samples/s | 30.0 steps/s
[Step= 550] | Loss=0.10019 | acc=0.9807 | tpr=0.9499 | fpr=0.0187 | 14194.1 samples/s | 55.4 steps/s
Avg test loss: 0.10005, Avg test acc: 0.98074, Avg tpr: 0.94968, Avg fpr: 0.01870, total FA: 2596

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07863 | acc=0.9831 | tpr=0.9248 | fpr=0.0158 | 4641.5 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.08117 | acc=0.9830 | tpr=0.9275 | fpr=0.0159 | 7483.0 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.08459 | acc=0.9826 | tpr=0.9308 | fpr=0.0164 | 7523.4 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.08675 | acc=0.9826 | tpr=0.9388 | fpr=0.0166 | 7690.2 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.08530 | acc=0.9828 | tpr=0.9380 | fpr=0.0164 | 8357.5 samples/s | 32.6 steps/s
[Step= 300] | Loss=0.08687 | acc=0.9826 | tpr=0.9375 | fpr=0.0166 | 7742.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.08759 | acc=0.9823 | tpr=0.9374 | fpr=0.0168 | 7471.6 samples/s | 29.2 steps/s
[Step= 400] | Loss=0.08853 | acc=0.9821 | tpr=0.9333 | fpr=0.0170 | 8405.2 samples/s | 32.8 steps/s
[Step= 450] | Loss=0.09048 | acc=0.9819 | tpr=0.9318 | fpr=0.0172 | 7813.0 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.08990 | acc=0.9819 | tpr=0.9330 | fpr=0.0172 | 7546.3 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.08959 | acc=0.9821 | tpr=0.9312 | fpr=0.0170 | 14866.6 samples/s | 58.1 steps/s
Avg test loss: 0.08946, Avg test acc: 0.98208, Avg tpr: 0.93106, Avg fpr: 0.01700, total FA: 2360

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08740 | acc=0.9785 | tpr=0.9646 | fpr=0.0212 | 4669.7 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.08908 | acc=0.9788 | tpr=0.9701 | fpr=0.0210 | 7372.2 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.09298 | acc=0.9781 | tpr=0.9669 | fpr=0.0217 | 7677.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.09383 | acc=0.9787 | tpr=0.9716 | fpr=0.0211 | 7977.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09279 | acc=0.9790 | tpr=0.9703 | fpr=0.0208 | 7809.9 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.09486 | acc=0.9786 | tpr=0.9680 | fpr=0.0213 | 7924.7 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09533 | acc=0.9784 | tpr=0.9681 | fpr=0.0215 | 8160.1 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.09630 | acc=0.9780 | tpr=0.9650 | fpr=0.0217 | 7668.7 samples/s | 30.0 steps/s
[Step= 450] | Loss=0.09758 | acc=0.9780 | tpr=0.9640 | fpr=0.0218 | 7738.5 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.09710 | acc=0.9779 | tpr=0.9652 | fpr=0.0219 | 8105.8 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.09657 | acc=0.9781 | tpr=0.9638 | fpr=0.0217 | 13509.1 samples/s | 52.8 steps/s
Avg test loss: 0.09646, Avg test acc: 0.97810, Avg tpr: 0.96395, Avg fpr: 0.02164, total FA: 3005

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09178 | acc=0.9807 | tpr=0.9646 | fpr=0.0190 | 4933.3 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.09325 | acc=0.9805 | tpr=0.9638 | fpr=0.0192 | 6788.5 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.09707 | acc=0.9798 | tpr=0.9582 | fpr=0.0198 | 7609.0 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.09838 | acc=0.9802 | tpr=0.9617 | fpr=0.0195 | 7802.6 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.09724 | acc=0.9805 | tpr=0.9607 | fpr=0.0192 | 8291.2 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.09938 | acc=0.9802 | tpr=0.9585 | fpr=0.0194 | 7708.6 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.10008 | acc=0.9800 | tpr=0.9580 | fpr=0.0196 | 7853.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10059 | acc=0.9799 | tpr=0.9551 | fpr=0.0197 | 7927.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.10242 | acc=0.9796 | tpr=0.9528 | fpr=0.0199 | 8049.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.10166 | acc=0.9797 | tpr=0.9533 | fpr=0.0198 | 7230.2 samples/s | 28.2 steps/s
[Step= 550] | Loss=0.10108 | acc=0.9799 | tpr=0.9534 | fpr=0.0196 | 15379.4 samples/s | 60.1 steps/s
Avg test loss: 0.10091, Avg test acc: 0.97996, Avg tpr: 0.95365, Avg fpr: 0.01956, total FA: 2716

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09863 | acc=0.9805 | tpr=0.9469 | fpr=0.0189 | 4797.8 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.10253 | acc=0.9800 | tpr=0.9531 | fpr=0.0195 | 7026.3 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.10677 | acc=0.9787 | tpr=0.9524 | fpr=0.0208 | 7648.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.10843 | acc=0.9786 | tpr=0.9596 | fpr=0.0210 | 7937.7 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.10691 | acc=0.9789 | tpr=0.9563 | fpr=0.0207 | 8205.9 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.10899 | acc=0.9786 | tpr=0.9527 | fpr=0.0209 | 7675.6 samples/s | 30.0 steps/s
[Step= 350] | Loss=0.10974 | acc=0.9784 | tpr=0.9537 | fpr=0.0211 | 7731.9 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.11077 | acc=0.9782 | tpr=0.9502 | fpr=0.0213 | 8281.4 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.11306 | acc=0.9779 | tpr=0.9474 | fpr=0.0215 | 7744.4 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.11256 | acc=0.9780 | tpr=0.9480 | fpr=0.0215 | 8048.9 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.11201 | acc=0.9783 | tpr=0.9491 | fpr=0.0212 | 13350.4 samples/s | 52.2 steps/s
Avg test loss: 0.11192, Avg test acc: 0.97826, Avg tpr: 0.94889, Avg fpr: 0.02120, total FA: 2944

server round 47/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=458.4] | Loss=0.01032 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.939 | L2-Norm(final)=22.021 | 5225.1 samples/s | 81.6 steps/s
[Step=94050 Epoch=458.6] | Loss=0.00927 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=22.027 | 4575.0 samples/s | 71.5 steps/s
[Step=94100 Epoch=458.8] | Loss=0.00855 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=22.033 | 4990.8 samples/s | 78.0 steps/s
[Step=94150 Epoch=459.1] | Loss=0.00791 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=22.039 | 5039.5 samples/s | 78.7 steps/s
[Step=94200 Epoch=459.3] | Loss=0.00768 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=22.044 | 7911.2 samples/s | 123.6 steps/s
[Step=94250 Epoch=459.6] | Loss=0.00737 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=22.050 | 2219.9 samples/s | 34.7 steps/s
[Step=94300 Epoch=459.8] | Loss=0.00741 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=22.055 | 4873.4 samples/s | 76.1 steps/s
[Step=94350 Epoch=460.1] | Loss=0.00727 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=22.061 | 4991.6 samples/s | 78.0 steps/s
[Step=94400 Epoch=460.3] | Loss=0.00744 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=22.066 | 7021.8 samples/s | 109.7 steps/s
[Step=94450 Epoch=460.6] | Loss=0.00734 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=22.072 | 2294.4 samples/s | 35.8 steps/s
[Step=94500 Epoch=460.8] | Loss=0.00730 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=22.077 | 5060.2 samples/s | 79.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=460.8] | Loss=0.00317 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.986 | L2-Norm(final)=22.130 | 5288.6 samples/s | 82.6 steps/s
[Step=94550 Epoch=461.0] | Loss=0.00781 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.990 | L2-Norm(final)=22.135 | 4067.4 samples/s | 63.6 steps/s
[Step=94600 Epoch=461.3] | Loss=0.00795 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=22.140 | 4525.3 samples/s | 70.7 steps/s
[Step=94650 Epoch=461.5] | Loss=0.00754 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.998 | L2-Norm(final)=22.145 | 4339.5 samples/s | 67.8 steps/s
[Step=94700 Epoch=461.8] | Loss=0.00741 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=22.149 | 6477.7 samples/s | 101.2 steps/s
[Step=94750 Epoch=462.0] | Loss=0.00697 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=22.153 | 2110.5 samples/s | 33.0 steps/s
[Step=94800 Epoch=462.3] | Loss=0.00655 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=22.157 | 4547.8 samples/s | 71.1 steps/s
[Step=94850 Epoch=462.5] | Loss=0.00641 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=22.161 | 4433.1 samples/s | 69.3 steps/s
[Step=94900 Epoch=462.8] | Loss=0.00615 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=22.164 | 5841.4 samples/s | 91.3 steps/s
[Step=94950 Epoch=463.0] | Loss=0.00580 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.168 | 2160.5 samples/s | 33.8 steps/s
[Step=95000 Epoch=463.2] | Loss=0.00561 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=22.171 | 4412.3 samples/s | 68.9 steps/s
[Step=95050 Epoch=463.5] | Loss=0.00546 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=22.174 | 4415.7 samples/s | 69.0 steps/s
[Step=95100 Epoch=463.7] | Loss=0.00530 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=22.177 | 5427.2 samples/s | 84.8 steps/s
[Step=95150 Epoch=464.0] | Loss=0.00520 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=22.180 | 2264.8 samples/s | 35.4 steps/s
[Step=95200 Epoch=464.2] | Loss=0.00502 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=22.183 | 4586.9 samples/s | 71.7 steps/s
[Step=95250 Epoch=464.5] | Loss=0.00491 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=22.186 | 4347.4 samples/s | 67.9 steps/s
[Step=95300 Epoch=464.7] | Loss=0.00486 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=22.189 | 5006.6 samples/s | 78.2 steps/s
[Step=95350 Epoch=464.9] | Loss=0.00480 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=22.192 | 2299.9 samples/s | 35.9 steps/s
[Step=95400 Epoch=465.2] | Loss=0.00469 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=22.194 | 4571.8 samples/s | 71.4 steps/s
[Step=95450 Epoch=465.4] | Loss=0.00460 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=22.197 | 4416.3 samples/s | 69.0 steps/s
[Step=95500 Epoch=465.7] | Loss=0.00458 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=22.200 | 4593.3 samples/s | 71.8 steps/s
[Step=95550 Epoch=465.9] | Loss=0.00448 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=22.203 | 2427.1 samples/s | 37.9 steps/s
[Step=95600 Epoch=466.2] | Loss=0.00443 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.030 | L2-Norm(final)=22.205 | 4366.7 samples/s | 68.2 steps/s
[Step=95650 Epoch=466.4] | Loss=0.00436 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=22.208 | 4536.3 samples/s | 70.9 steps/s
[Step=95700 Epoch=466.7] | Loss=0.00429 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=22.210 | 4351.3 samples/s | 68.0 steps/s
[Step=95750 Epoch=466.9] | Loss=0.00420 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=22.213 | 2486.6 samples/s | 38.9 steps/s
[Step=95800 Epoch=467.1] | Loss=0.00414 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=22.215 | 4404.0 samples/s | 68.8 steps/s
[Step=95850 Epoch=467.4] | Loss=0.00410 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=22.218 | 4563.4 samples/s | 71.3 steps/s
[Step=95900 Epoch=467.6] | Loss=0.00404 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.035 | L2-Norm(final)=22.220 | 4386.1 samples/s | 68.5 steps/s
[Step=95950 Epoch=467.9] | Loss=0.00401 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=22.223 | 2444.3 samples/s | 38.2 steps/s
[Step=96000 Epoch=468.1] | Loss=0.00396 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=22.225 | 4472.1 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step96000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=458.7] | Loss=0.00555 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.532 | L2-Norm(final)=23.004 | 5472.6 samples/s | 85.5 steps/s
[Step=94050 Epoch=458.9] | Loss=0.00682 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.536 | L2-Norm(final)=23.009 | 4134.6 samples/s | 64.6 steps/s
[Step=94100 Epoch=459.2] | Loss=0.00613 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=23.016 | 5024.1 samples/s | 78.5 steps/s
[Step=94150 Epoch=459.4] | Loss=0.00649 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.541 | L2-Norm(final)=23.023 | 5072.1 samples/s | 79.3 steps/s
[Step=94200 Epoch=459.7] | Loss=0.00644 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.544 | L2-Norm(final)=23.030 | 7868.4 samples/s | 122.9 steps/s
[Step=94250 Epoch=459.9] | Loss=0.00636 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.547 | L2-Norm(final)=23.037 | 2257.9 samples/s | 35.3 steps/s
[Step=94300 Epoch=460.1] | Loss=0.00629 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.549 | L2-Norm(final)=23.043 | 4809.3 samples/s | 75.1 steps/s
[Step=94350 Epoch=460.4] | Loss=0.00622 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=23.050 | 5025.0 samples/s | 78.5 steps/s
[Step=94400 Epoch=460.6] | Loss=0.00617 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.554 | L2-Norm(final)=23.056 | 6936.7 samples/s | 108.4 steps/s
[Step=94450 Epoch=460.9] | Loss=0.00614 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.557 | L2-Norm(final)=23.063 | 2288.2 samples/s | 35.8 steps/s
[Step=94500 Epoch=461.1] | Loss=0.00603 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.559 | L2-Norm(final)=23.069 | 4982.1 samples/s | 77.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=461.1] | Loss=0.00750 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=23.133 | 5918.1 samples/s | 92.5 steps/s
[Step=94550 Epoch=461.4] | Loss=0.00666 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.588 | L2-Norm(final)=23.139 | 4087.4 samples/s | 63.9 steps/s
[Step=94600 Epoch=461.6] | Loss=0.00687 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=23.145 | 4467.0 samples/s | 69.8 steps/s
[Step=94650 Epoch=461.8] | Loss=0.00715 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=23.150 | 4535.1 samples/s | 70.9 steps/s
[Step=94700 Epoch=462.1] | Loss=0.00678 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=23.155 | 6440.5 samples/s | 100.6 steps/s
[Step=94750 Epoch=462.3] | Loss=0.00637 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.603 | L2-Norm(final)=23.159 | 2049.9 samples/s | 32.0 steps/s
[Step=94800 Epoch=462.6] | Loss=0.00596 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.605 | L2-Norm(final)=23.163 | 4620.0 samples/s | 72.2 steps/s
[Step=94850 Epoch=462.8] | Loss=0.00586 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.608 | L2-Norm(final)=23.167 | 4344.4 samples/s | 67.9 steps/s
[Step=94900 Epoch=463.1] | Loss=0.00557 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.610 | L2-Norm(final)=23.171 | 6071.8 samples/s | 94.9 steps/s
[Step=94950 Epoch=463.3] | Loss=0.00532 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.612 | L2-Norm(final)=23.175 | 2128.9 samples/s | 33.3 steps/s
[Step=95000 Epoch=463.6] | Loss=0.00504 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=23.178 | 4482.9 samples/s | 70.0 steps/s
[Step=95050 Epoch=463.8] | Loss=0.00485 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.615 | L2-Norm(final)=23.182 | 4465.5 samples/s | 69.8 steps/s
[Step=95100 Epoch=464.0] | Loss=0.00472 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=23.185 | 5450.0 samples/s | 85.2 steps/s
[Step=95150 Epoch=464.3] | Loss=0.00461 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=23.188 | 2196.7 samples/s | 34.3 steps/s
[Step=95200 Epoch=464.5] | Loss=0.00448 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=23.192 | 4453.9 samples/s | 69.6 steps/s
[Step=95250 Epoch=464.8] | Loss=0.00438 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.620 | L2-Norm(final)=23.195 | 4472.4 samples/s | 69.9 steps/s
[Step=95300 Epoch=465.0] | Loss=0.00431 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=23.198 | 5229.2 samples/s | 81.7 steps/s
[Step=95350 Epoch=465.3] | Loss=0.00424 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=23.201 | 2273.9 samples/s | 35.5 steps/s
[Step=95400 Epoch=465.5] | Loss=0.00418 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=23.204 | 4328.1 samples/s | 67.6 steps/s
[Step=95450 Epoch=465.8] | Loss=0.00410 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=23.207 | 4535.6 samples/s | 70.9 steps/s
[Step=95500 Epoch=466.0] | Loss=0.00401 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=23.210 | 4769.0 samples/s | 74.5 steps/s
[Step=95550 Epoch=466.2] | Loss=0.00395 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.627 | L2-Norm(final)=23.213 | 2342.6 samples/s | 36.6 steps/s
[Step=95600 Epoch=466.5] | Loss=0.00387 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=23.216 | 4457.9 samples/s | 69.7 steps/s
[Step=95650 Epoch=466.7] | Loss=0.00381 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=23.219 | 4464.9 samples/s | 69.8 steps/s
[Step=95700 Epoch=467.0] | Loss=0.00376 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.630 | L2-Norm(final)=23.222 | 4600.4 samples/s | 71.9 steps/s
[Step=95750 Epoch=467.2] | Loss=0.00371 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.630 | L2-Norm(final)=23.225 | 2370.6 samples/s | 37.0 steps/s
[Step=95800 Epoch=467.5] | Loss=0.00365 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=23.227 | 4454.1 samples/s | 69.6 steps/s
[Step=95850 Epoch=467.7] | Loss=0.00361 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=23.230 | 4452.4 samples/s | 69.6 steps/s
[Step=95900 Epoch=467.9] | Loss=0.00357 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=23.233 | 4496.4 samples/s | 70.3 steps/s
[Step=95950 Epoch=468.2] | Loss=0.00353 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.633 | L2-Norm(final)=23.236 | 2457.7 samples/s | 38.4 steps/s
[Step=96000 Epoch=468.4] | Loss=0.00347 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.634 | L2-Norm(final)=23.238 | 4482.9 samples/s | 70.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step96000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=458.0] | Loss=0.00428 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=22.968 | 5076.4 samples/s | 79.3 steps/s
[Step=94050 Epoch=458.3] | Loss=0.00852 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=22.973 | 4533.9 samples/s | 70.8 steps/s
[Step=94100 Epoch=458.5] | Loss=0.00833 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=22.980 | 5042.9 samples/s | 78.8 steps/s
[Step=94150 Epoch=458.7] | Loss=0.00778 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.355 | L2-Norm(final)=22.986 | 5231.2 samples/s | 81.7 steps/s
[Step=94200 Epoch=459.0] | Loss=0.00762 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.358 | L2-Norm(final)=22.992 | 7531.9 samples/s | 117.7 steps/s
[Step=94250 Epoch=459.2] | Loss=0.00741 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.360 | L2-Norm(final)=22.998 | 2218.7 samples/s | 34.7 steps/s
[Step=94300 Epoch=459.5] | Loss=0.00750 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=23.004 | 5010.7 samples/s | 78.3 steps/s
[Step=94350 Epoch=459.7] | Loss=0.00738 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=23.010 | 5079.4 samples/s | 79.4 steps/s
[Step=94400 Epoch=460.0] | Loss=0.00733 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=23.016 | 6913.5 samples/s | 108.0 steps/s
[Step=94450 Epoch=460.2] | Loss=0.00731 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=23.021 | 2299.2 samples/s | 35.9 steps/s
[Step=94500 Epoch=460.4] | Loss=0.00729 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=23.027 | 5001.8 samples/s | 78.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=460.5] | Loss=0.01274 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=23.083 | 5417.5 samples/s | 84.6 steps/s
[Step=94550 Epoch=460.7] | Loss=0.00827 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.400 | L2-Norm(final)=23.088 | 4006.0 samples/s | 62.6 steps/s
[Step=94600 Epoch=460.9] | Loss=0.00833 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=23.093 | 4485.9 samples/s | 70.1 steps/s
[Step=94650 Epoch=461.2] | Loss=0.00853 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.407 | L2-Norm(final)=23.098 | 4453.1 samples/s | 69.6 steps/s
[Step=94700 Epoch=461.4] | Loss=0.00824 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.411 | L2-Norm(final)=23.102 | 6557.8 samples/s | 102.5 steps/s
[Step=94750 Epoch=461.7] | Loss=0.00778 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=23.106 | 2060.2 samples/s | 32.2 steps/s
[Step=94800 Epoch=461.9] | Loss=0.00725 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=23.110 | 4387.6 samples/s | 68.6 steps/s
[Step=94850 Epoch=462.2] | Loss=0.00690 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.419 | L2-Norm(final)=23.114 | 4473.7 samples/s | 69.9 steps/s
[Step=94900 Epoch=462.4] | Loss=0.00657 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.421 | L2-Norm(final)=23.117 | 5907.4 samples/s | 92.3 steps/s
[Step=94950 Epoch=462.6] | Loss=0.00628 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.423 | L2-Norm(final)=23.121 | 2166.6 samples/s | 33.9 steps/s
[Step=95000 Epoch=462.9] | Loss=0.00598 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=23.124 | 4477.7 samples/s | 70.0 steps/s
[Step=95050 Epoch=463.1] | Loss=0.00579 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=23.127 | 4486.2 samples/s | 70.1 steps/s
[Step=95100 Epoch=463.4] | Loss=0.00566 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.427 | L2-Norm(final)=23.130 | 5402.1 samples/s | 84.4 steps/s
[Step=95150 Epoch=463.6] | Loss=0.00545 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=23.133 | 2186.6 samples/s | 34.2 steps/s
[Step=95200 Epoch=463.9] | Loss=0.00529 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.430 | L2-Norm(final)=23.136 | 4485.1 samples/s | 70.1 steps/s
[Step=95250 Epoch=464.1] | Loss=0.00518 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.431 | L2-Norm(final)=23.139 | 4472.7 samples/s | 69.9 steps/s
[Step=95300 Epoch=464.3] | Loss=0.00504 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.432 | L2-Norm(final)=23.142 | 4917.5 samples/s | 76.8 steps/s
[Step=95350 Epoch=464.6] | Loss=0.00498 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.434 | L2-Norm(final)=23.144 | 2355.7 samples/s | 36.8 steps/s
[Step=95400 Epoch=464.8] | Loss=0.00485 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=23.147 | 4454.5 samples/s | 69.6 steps/s
[Step=95450 Epoch=465.1] | Loss=0.00480 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=23.150 | 4446.1 samples/s | 69.5 steps/s
[Step=95500 Epoch=465.3] | Loss=0.00471 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=23.152 | 4507.8 samples/s | 70.4 steps/s
[Step=95550 Epoch=465.6] | Loss=0.00463 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=23.155 | 2430.1 samples/s | 38.0 steps/s
[Step=95600 Epoch=465.8] | Loss=0.00456 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=23.157 | 4500.5 samples/s | 70.3 steps/s
[Step=95650 Epoch=466.1] | Loss=0.00449 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=23.160 | 4464.4 samples/s | 69.8 steps/s
[Step=95700 Epoch=466.3] | Loss=0.00441 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=23.163 | 4489.0 samples/s | 70.1 steps/s
[Step=95750 Epoch=466.5] | Loss=0.00436 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.441 | L2-Norm(final)=23.165 | 2477.4 samples/s | 38.7 steps/s
[Step=95800 Epoch=466.8] | Loss=0.00430 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.442 | L2-Norm(final)=23.167 | 4348.0 samples/s | 67.9 steps/s
[Step=95850 Epoch=467.0] | Loss=0.00423 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.442 | L2-Norm(final)=23.170 | 4472.8 samples/s | 69.9 steps/s
[Step=95900 Epoch=467.3] | Loss=0.00418 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.443 | L2-Norm(final)=23.172 | 4402.4 samples/s | 68.8 steps/s
[Step=95950 Epoch=467.5] | Loss=0.00415 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.444 | L2-Norm(final)=23.175 | 2437.6 samples/s | 38.1 steps/s
[Step=96000 Epoch=467.8] | Loss=0.00410 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.444 | L2-Norm(final)=23.177 | 4583.4 samples/s | 71.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step96000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=458.4] | Loss=0.01794 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.018 | L2-Norm(final)=22.998 | 5114.4 samples/s | 79.9 steps/s
[Step=94050 Epoch=458.6] | Loss=0.00768 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=23.002 | 4432.4 samples/s | 69.3 steps/s
[Step=94100 Epoch=458.9] | Loss=0.00711 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.025 | L2-Norm(final)=23.009 | 5037.5 samples/s | 78.7 steps/s
[Step=94150 Epoch=459.1] | Loss=0.00719 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=23.015 | 4926.6 samples/s | 77.0 steps/s
[Step=94200 Epoch=459.4] | Loss=0.00751 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=23.022 | 7858.3 samples/s | 122.8 steps/s
[Step=94250 Epoch=459.6] | Loss=0.00740 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=23.029 | 2234.9 samples/s | 34.9 steps/s
[Step=94300 Epoch=459.9] | Loss=0.00719 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=23.035 | 5036.2 samples/s | 78.7 steps/s
[Step=94350 Epoch=460.1] | Loss=0.00721 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=23.041 | 4934.0 samples/s | 77.1 steps/s
[Step=94400 Epoch=460.3] | Loss=0.00727 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=23.048 | 6994.6 samples/s | 109.3 steps/s
[Step=94450 Epoch=460.6] | Loss=0.00715 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=23.054 | 2299.0 samples/s | 35.9 steps/s
[Step=94500 Epoch=460.8] | Loss=0.00714 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=23.060 | 4932.5 samples/s | 77.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=460.8] | Loss=0.00249 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=23.122 | 5494.1 samples/s | 85.8 steps/s
[Step=94550 Epoch=461.1] | Loss=0.00885 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.077 | L2-Norm(final)=23.127 | 3996.5 samples/s | 62.4 steps/s
[Step=94600 Epoch=461.3] | Loss=0.00869 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=23.132 | 4596.1 samples/s | 71.8 steps/s
[Step=94650 Epoch=461.6] | Loss=0.00861 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=23.137 | 4382.7 samples/s | 68.5 steps/s
[Step=94700 Epoch=461.8] | Loss=0.00800 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.089 | L2-Norm(final)=23.142 | 6595.5 samples/s | 103.1 steps/s
[Step=94750 Epoch=462.1] | Loss=0.00734 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.093 | L2-Norm(final)=23.146 | 2097.7 samples/s | 32.8 steps/s
[Step=94800 Epoch=462.3] | Loss=0.00687 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=23.150 | 4470.1 samples/s | 69.8 steps/s
[Step=94850 Epoch=462.5] | Loss=0.00646 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=23.154 | 4338.0 samples/s | 67.8 steps/s
[Step=94900 Epoch=462.8] | Loss=0.00614 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.100 | L2-Norm(final)=23.157 | 5945.9 samples/s | 92.9 steps/s
[Step=94950 Epoch=463.0] | Loss=0.00587 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=23.161 | 2169.3 samples/s | 33.9 steps/s
[Step=95000 Epoch=463.3] | Loss=0.00562 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.104 | L2-Norm(final)=23.164 | 4531.4 samples/s | 70.8 steps/s
[Step=95050 Epoch=463.5] | Loss=0.00544 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.105 | L2-Norm(final)=23.168 | 4472.2 samples/s | 69.9 steps/s
[Step=95100 Epoch=463.8] | Loss=0.00520 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.107 | L2-Norm(final)=23.171 | 5352.1 samples/s | 83.6 steps/s
[Step=95150 Epoch=464.0] | Loss=0.00505 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=23.174 | 2255.5 samples/s | 35.2 steps/s
[Step=95200 Epoch=464.2] | Loss=0.00492 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.110 | L2-Norm(final)=23.177 | 4267.4 samples/s | 66.7 steps/s
[Step=95250 Epoch=464.5] | Loss=0.00474 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.111 | L2-Norm(final)=23.180 | 4493.9 samples/s | 70.2 steps/s
[Step=95300 Epoch=464.7] | Loss=0.00464 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.113 | L2-Norm(final)=23.183 | 4962.0 samples/s | 77.5 steps/s
[Step=95350 Epoch=465.0] | Loss=0.00454 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=23.186 | 2341.2 samples/s | 36.6 steps/s
[Step=95400 Epoch=465.2] | Loss=0.00442 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=23.188 | 4503.2 samples/s | 70.4 steps/s
[Step=95450 Epoch=465.5] | Loss=0.00429 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=23.191 | 4449.0 samples/s | 69.5 steps/s
[Step=95500 Epoch=465.7] | Loss=0.00422 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=23.194 | 4616.5 samples/s | 72.1 steps/s
[Step=95550 Epoch=466.0] | Loss=0.00415 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.118 | L2-Norm(final)=23.196 | 2383.7 samples/s | 37.2 steps/s
[Step=95600 Epoch=466.2] | Loss=0.00407 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=23.199 | 4448.6 samples/s | 69.5 steps/s
[Step=95650 Epoch=466.4] | Loss=0.00397 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=23.202 | 4475.8 samples/s | 69.9 steps/s
[Step=95700 Epoch=466.7] | Loss=0.00395 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=23.204 | 4494.9 samples/s | 70.2 steps/s
[Step=95750 Epoch=466.9] | Loss=0.00389 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=23.207 | 2479.0 samples/s | 38.7 steps/s
[Step=95800 Epoch=467.2] | Loss=0.00385 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=23.209 | 4484.2 samples/s | 70.1 steps/s
[Step=95850 Epoch=467.4] | Loss=0.00377 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=23.212 | 4514.3 samples/s | 70.5 steps/s
[Step=95900 Epoch=467.7] | Loss=0.00372 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.124 | L2-Norm(final)=23.215 | 4363.7 samples/s | 68.2 steps/s
[Step=95950 Epoch=467.9] | Loss=0.00367 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=23.217 | 2467.4 samples/s | 38.6 steps/s
[Step=96000 Epoch=468.1] | Loss=0.00359 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=23.220 | 4508.8 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step96000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=461.0] | Loss=0.01866 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.647 | L2-Norm(final)=23.111 | 5470.8 samples/s | 85.5 steps/s
[Step=94050 Epoch=461.2] | Loss=0.00774 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=23.115 | 4386.4 samples/s | 68.5 steps/s
[Step=94100 Epoch=461.5] | Loss=0.00667 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=23.121 | 5006.7 samples/s | 78.2 steps/s
[Step=94150 Epoch=461.7] | Loss=0.00652 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=23.128 | 5051.0 samples/s | 78.9 steps/s
[Step=94200 Epoch=461.9] | Loss=0.00652 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=23.134 | 8080.1 samples/s | 126.3 steps/s
[Step=94250 Epoch=462.2] | Loss=0.00647 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=23.140 | 2182.6 samples/s | 34.1 steps/s
[Step=94300 Epoch=462.4] | Loss=0.00634 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=23.147 | 5049.8 samples/s | 78.9 steps/s
[Step=94350 Epoch=462.7] | Loss=0.00615 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=23.153 | 5034.4 samples/s | 78.7 steps/s
[Step=94400 Epoch=462.9] | Loss=0.00619 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=23.159 | 7348.2 samples/s | 114.8 steps/s
[Step=94450 Epoch=463.2] | Loss=0.00613 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=23.165 | 2255.9 samples/s | 35.2 steps/s
[Step=94500 Epoch=463.4] | Loss=0.00612 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=23.171 | 5037.5 samples/s | 78.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=463.4] | Loss=0.00302 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.696 | L2-Norm(final)=23.230 | 5137.7 samples/s | 80.3 steps/s
[Step=94550 Epoch=463.7] | Loss=0.00521 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=23.235 | 4105.7 samples/s | 64.2 steps/s
[Step=94600 Epoch=463.9] | Loss=0.00649 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=23.240 | 4412.1 samples/s | 68.9 steps/s
[Step=94650 Epoch=464.1] | Loss=0.00664 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=23.245 | 4516.7 samples/s | 70.6 steps/s
[Step=94700 Epoch=464.4] | Loss=0.00642 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=23.250 | 6655.0 samples/s | 104.0 steps/s
[Step=94750 Epoch=464.6] | Loss=0.00611 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=23.255 | 2069.3 samples/s | 32.3 steps/s
[Step=94800 Epoch=464.9] | Loss=0.00590 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=23.259 | 4519.2 samples/s | 70.6 steps/s
[Step=94850 Epoch=465.1] | Loss=0.00590 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=23.263 | 4438.9 samples/s | 69.4 steps/s
[Step=94900 Epoch=465.4] | Loss=0.00566 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.721 | L2-Norm(final)=23.267 | 6251.6 samples/s | 97.7 steps/s
[Step=94950 Epoch=465.6] | Loss=0.00540 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=23.271 | 2112.8 samples/s | 33.0 steps/s
[Step=95000 Epoch=465.9] | Loss=0.00521 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=23.274 | 4475.0 samples/s | 69.9 steps/s
[Step=95050 Epoch=466.1] | Loss=0.00504 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=23.278 | 4501.7 samples/s | 70.3 steps/s
[Step=95100 Epoch=466.4] | Loss=0.00487 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.728 | L2-Norm(final)=23.281 | 5809.4 samples/s | 90.8 steps/s
[Step=95150 Epoch=466.6] | Loss=0.00467 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.729 | L2-Norm(final)=23.284 | 2150.5 samples/s | 33.6 steps/s
[Step=95200 Epoch=466.8] | Loss=0.00450 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.731 | L2-Norm(final)=23.287 | 4552.0 samples/s | 71.1 steps/s
[Step=95250 Epoch=467.1] | Loss=0.00442 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.732 | L2-Norm(final)=23.290 | 4528.9 samples/s | 70.8 steps/s
[Step=95300 Epoch=467.3] | Loss=0.00431 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=23.293 | 5230.1 samples/s | 81.7 steps/s
[Step=95350 Epoch=467.6] | Loss=0.00422 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=23.296 | 2210.5 samples/s | 34.5 steps/s
[Step=95400 Epoch=467.8] | Loss=0.00407 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=23.299 | 4502.0 samples/s | 70.3 steps/s
[Step=95450 Epoch=468.1] | Loss=0.00399 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.736 | L2-Norm(final)=23.301 | 4520.1 samples/s | 70.6 steps/s
[Step=95500 Epoch=468.3] | Loss=0.00394 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.737 | L2-Norm(final)=23.304 | 5143.5 samples/s | 80.4 steps/s
[Step=95550 Epoch=468.6] | Loss=0.00386 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.738 | L2-Norm(final)=23.307 | 2269.7 samples/s | 35.5 steps/s
[Step=95600 Epoch=468.8] | Loss=0.00381 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=23.310 | 4459.1 samples/s | 69.7 steps/s
[Step=95650 Epoch=469.1] | Loss=0.00373 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=23.312 | 4458.5 samples/s | 69.7 steps/s
[Step=95700 Epoch=469.3] | Loss=0.00365 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=23.315 | 4867.0 samples/s | 76.0 steps/s
[Step=95750 Epoch=469.5] | Loss=0.00361 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=23.318 | 2333.7 samples/s | 36.5 steps/s
[Step=95800 Epoch=469.8] | Loss=0.00355 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.742 | L2-Norm(final)=23.320 | 4457.6 samples/s | 69.7 steps/s
[Step=95850 Epoch=470.0] | Loss=0.00351 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.742 | L2-Norm(final)=23.323 | 4487.3 samples/s | 70.1 steps/s
[Step=95900 Epoch=470.3] | Loss=0.00346 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=23.325 | 4694.6 samples/s | 73.4 steps/s
[Step=95950 Epoch=470.5] | Loss=0.00341 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.743 | L2-Norm(final)=23.328 | 2392.1 samples/s | 37.4 steps/s
[Step=96000 Epoch=470.8] | Loss=0.00338 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.744 | L2-Norm(final)=23.330 | 4443.1 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step96000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=890.7] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.206 | L2-Norm(final)=11.615 | 5586.0 samples/s | 87.3 steps/s
[Step=94050 Epoch=891.2] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.208 | L2-Norm(final)=11.619 | 4093.0 samples/s | 64.0 steps/s
[Step=94100 Epoch=891.7] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.212 | L2-Norm(final)=11.625 | 7368.4 samples/s | 115.1 steps/s
[Step=94150 Epoch=892.2] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.215 | L2-Norm(final)=11.631 | 2126.5 samples/s | 33.2 steps/s
[Step=94200 Epoch=892.6] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.218 | L2-Norm(final)=11.636 | 6649.0 samples/s | 103.9 steps/s
[Step=94250 Epoch=893.1] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.220 | L2-Norm(final)=11.641 | 2221.3 samples/s | 34.7 steps/s
[Step=94300 Epoch=893.6] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.222 | L2-Norm(final)=11.645 | 5843.7 samples/s | 91.3 steps/s
[Step=94350 Epoch=894.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.224 | L2-Norm(final)=11.650 | 2347.3 samples/s | 36.7 steps/s
[Step=94400 Epoch=894.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=11.654 | 5135.5 samples/s | 80.2 steps/s
[Step=94450 Epoch=895.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.228 | L2-Norm(final)=11.658 | 2394.7 samples/s | 37.4 steps/s
[Step=94500 Epoch=895.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.230 | L2-Norm(final)=11.662 | 4887.1 samples/s | 76.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=895.5] | Loss=0.00003 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.247 | L2-Norm(final)=11.703 | 5291.4 samples/s | 82.7 steps/s
[Step=94550 Epoch=895.9] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.249 | L2-Norm(final)=11.707 | 3840.2 samples/s | 60.0 steps/s
[Step=94600 Epoch=896.4] | Loss=0.00002 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.249 | L2-Norm(final)=11.710 | 6178.8 samples/s | 96.5 steps/s
[Step=94650 Epoch=896.9] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.248 | L2-Norm(final)=11.712 | 2010.5 samples/s | 31.4 steps/s
[Step=94700 Epoch=897.4] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.246 | L2-Norm(final)=11.714 | 5604.5 samples/s | 87.6 steps/s
[Step=94750 Epoch=897.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.243 | L2-Norm(final)=11.715 | 2112.5 samples/s | 33.0 steps/s
[Step=94800 Epoch=898.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.240 | L2-Norm(final)=11.717 | 5017.7 samples/s | 78.4 steps/s
[Step=94850 Epoch=898.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.236 | L2-Norm(final)=11.718 | 2153.3 samples/s | 33.6 steps/s
[Step=94900 Epoch=899.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.232 | L2-Norm(final)=11.719 | 4722.6 samples/s | 73.8 steps/s
[Step=94950 Epoch=899.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.229 | L2-Norm(final)=11.720 | 2298.2 samples/s | 35.9 steps/s
[Step=95000 Epoch=900.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.224 | L2-Norm(final)=11.721 | 4325.1 samples/s | 67.6 steps/s
[Step=95050 Epoch=900.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.220 | L2-Norm(final)=11.721 | 2333.6 samples/s | 36.5 steps/s
[Step=95100 Epoch=901.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.216 | L2-Norm(final)=11.722 | 4266.9 samples/s | 66.7 steps/s
[Step=95150 Epoch=901.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.212 | L2-Norm(final)=11.723 | 2397.1 samples/s | 37.5 steps/s
[Step=95200 Epoch=902.1] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.207 | L2-Norm(final)=11.724 | 4110.9 samples/s | 64.2 steps/s
[Step=95250 Epoch=902.6] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.202 | L2-Norm(final)=11.725 | 2386.4 samples/s | 37.3 steps/s
[Step=95300 Epoch=903.1] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.198 | L2-Norm(final)=11.726 | 4315.9 samples/s | 67.4 steps/s
[Step=95350 Epoch=903.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.193 | L2-Norm(final)=11.726 | 2511.9 samples/s | 39.2 steps/s
[Step=95400 Epoch=904.0] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=11.727 | 3966.1 samples/s | 62.0 steps/s
[Step=95450 Epoch=904.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.183 | L2-Norm(final)=11.728 | 6348.2 samples/s | 99.2 steps/s
[Step=95500 Epoch=904.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.178 | L2-Norm(final)=11.729 | 1967.8 samples/s | 30.7 steps/s
[Step=95550 Epoch=905.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.173 | L2-Norm(final)=11.729 | 5888.6 samples/s | 92.0 steps/s
[Step=95600 Epoch=905.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.168 | L2-Norm(final)=11.730 | 2080.1 samples/s | 32.5 steps/s
[Step=95650 Epoch=906.4] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.163 | L2-Norm(final)=11.731 | 5262.4 samples/s | 82.2 steps/s
[Step=95700 Epoch=906.8] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.157 | L2-Norm(final)=11.732 | 2167.0 samples/s | 33.9 steps/s
[Step=95750 Epoch=907.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.152 | L2-Norm(final)=11.732 | 4735.0 samples/s | 74.0 steps/s
[Step=95800 Epoch=907.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.147 | L2-Norm(final)=11.733 | 2209.7 samples/s | 34.5 steps/s
[Step=95850 Epoch=908.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=11.734 | 4501.2 samples/s | 70.3 steps/s
[Step=95900 Epoch=908.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.135 | L2-Norm(final)=11.735 | 2315.6 samples/s | 36.2 steps/s
[Step=95950 Epoch=909.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.130 | L2-Norm(final)=11.736 | 4260.4 samples/s | 66.6 steps/s
[Step=96000 Epoch=909.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.124 | L2-Norm(final)=11.737 | 2385.2 samples/s | 37.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step96000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=894.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.139 | L2-Norm(final)=12.801 | 5426.8 samples/s | 84.8 steps/s
[Step=94050 Epoch=894.6] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.136 | L2-Norm(final)=12.805 | 3891.6 samples/s | 60.8 steps/s
[Step=94100 Epoch=895.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.139 | L2-Norm(final)=12.812 | 7607.0 samples/s | 118.9 steps/s
[Step=94150 Epoch=895.6] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.142 | L2-Norm(final)=12.819 | 2142.5 samples/s | 33.5 steps/s
[Step=94200 Epoch=896.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.144 | L2-Norm(final)=12.825 | 6612.6 samples/s | 103.3 steps/s
[Step=94250 Epoch=896.6] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.146 | L2-Norm(final)=12.830 | 2219.0 samples/s | 34.7 steps/s
[Step=94300 Epoch=897.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.148 | L2-Norm(final)=12.835 | 5825.2 samples/s | 91.0 steps/s
[Step=94350 Epoch=897.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=12.840 | 2251.3 samples/s | 35.2 steps/s
[Step=94400 Epoch=898.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.153 | L2-Norm(final)=12.845 | 5403.3 samples/s | 84.4 steps/s
[Step=94450 Epoch=898.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.155 | L2-Norm(final)=12.850 | 2415.7 samples/s | 37.7 steps/s
[Step=94500 Epoch=898.9] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.157 | L2-Norm(final)=12.854 | 4939.2 samples/s | 77.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=898.9] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.174 | L2-Norm(final)=12.895 | 5397.0 samples/s | 84.3 steps/s
[Step=94550 Epoch=899.4] | Loss=0.00007 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.179 | L2-Norm(final)=12.898 | 3680.9 samples/s | 57.5 steps/s
[Step=94600 Epoch=899.9] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.186 | L2-Norm(final)=12.902 | 6200.0 samples/s | 96.9 steps/s
[Step=94650 Epoch=900.4] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=12.905 | 2040.9 samples/s | 31.9 steps/s
[Step=94700 Epoch=900.8] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.187 | L2-Norm(final)=12.906 | 5588.8 samples/s | 87.3 steps/s
[Step=94750 Epoch=901.3] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.186 | L2-Norm(final)=12.907 | 2088.9 samples/s | 32.6 steps/s
[Step=94800 Epoch=901.8] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.184 | L2-Norm(final)=12.908 | 5141.2 samples/s | 80.3 steps/s
[Step=94850 Epoch=902.3] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.182 | L2-Norm(final)=12.909 | 2200.7 samples/s | 34.4 steps/s
[Step=94900 Epoch=902.7] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.180 | L2-Norm(final)=12.909 | 4583.5 samples/s | 71.6 steps/s
[Step=94950 Epoch=903.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.178 | L2-Norm(final)=12.910 | 2276.9 samples/s | 35.6 steps/s
[Step=95000 Epoch=903.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.175 | L2-Norm(final)=12.911 | 4344.1 samples/s | 67.9 steps/s
[Step=95050 Epoch=904.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.172 | L2-Norm(final)=12.911 | 2389.1 samples/s | 37.3 steps/s
[Step=95100 Epoch=904.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.170 | L2-Norm(final)=12.912 | 4285.8 samples/s | 67.0 steps/s
[Step=95150 Epoch=905.1] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.167 | L2-Norm(final)=12.912 | 2351.5 samples/s | 36.7 steps/s
[Step=95200 Epoch=905.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.164 | L2-Norm(final)=12.912 | 4196.7 samples/s | 65.6 steps/s
[Step=95250 Epoch=906.1] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.161 | L2-Norm(final)=12.913 | 2396.1 samples/s | 37.4 steps/s
[Step=95300 Epoch=906.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.158 | L2-Norm(final)=12.913 | 4263.1 samples/s | 66.6 steps/s
[Step=95350 Epoch=907.0] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.155 | L2-Norm(final)=12.914 | 2465.4 samples/s | 38.5 steps/s
[Step=95400 Epoch=907.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=12.914 | 4023.4 samples/s | 62.9 steps/s
[Step=95450 Epoch=908.0] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.148 | L2-Norm(final)=12.915 | 6566.7 samples/s | 102.6 steps/s
[Step=95500 Epoch=908.4] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.145 | L2-Norm(final)=12.915 | 1991.2 samples/s | 31.1 steps/s
[Step=95550 Epoch=908.9] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.142 | L2-Norm(final)=12.915 | 5916.1 samples/s | 92.4 steps/s
[Step=95600 Epoch=909.4] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.138 | L2-Norm(final)=12.916 | 2070.9 samples/s | 32.4 steps/s
[Step=95650 Epoch=909.9] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.135 | L2-Norm(final)=12.916 | 5312.4 samples/s | 83.0 steps/s
[Step=95700 Epoch=910.3] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.131 | L2-Norm(final)=12.917 | 2146.4 samples/s | 33.5 steps/s
[Step=95750 Epoch=910.8] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.128 | L2-Norm(final)=12.917 | 4851.9 samples/s | 75.8 steps/s
[Step=95800 Epoch=911.3] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.124 | L2-Norm(final)=12.918 | 2158.2 samples/s | 33.7 steps/s
[Step=95850 Epoch=911.8] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.120 | L2-Norm(final)=12.918 | 4470.0 samples/s | 69.8 steps/s
[Step=95900 Epoch=912.2] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.117 | L2-Norm(final)=12.918 | 2306.1 samples/s | 36.0 steps/s
[Step=95950 Epoch=912.7] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.113 | L2-Norm(final)=12.919 | 4269.2 samples/s | 66.7 steps/s
[Step=96000 Epoch=913.2] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.109 | L2-Norm(final)=12.919 | 2406.4 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step96000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=897.7] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.185 | L2-Norm(final)=12.157 | 4964.2 samples/s | 77.6 steps/s
[Step=94050 Epoch=898.1] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.186 | L2-Norm(final)=12.160 | 4367.0 samples/s | 68.2 steps/s
[Step=94100 Epoch=898.6] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=12.165 | 7563.6 samples/s | 118.2 steps/s
[Step=94150 Epoch=899.1] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.189 | L2-Norm(final)=12.169 | 2179.1 samples/s | 34.0 steps/s
[Step=94200 Epoch=899.6] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.191 | L2-Norm(final)=12.172 | 6424.0 samples/s | 100.4 steps/s
[Step=94250 Epoch=900.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.192 | L2-Norm(final)=12.176 | 2172.1 samples/s | 33.9 steps/s
[Step=94300 Epoch=900.5] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.193 | L2-Norm(final)=12.180 | 6187.8 samples/s | 96.7 steps/s
[Step=94350 Epoch=901.0] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=12.183 | 2225.4 samples/s | 34.8 steps/s
[Step=94400 Epoch=901.5] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.196 | L2-Norm(final)=12.187 | 5566.0 samples/s | 87.0 steps/s
[Step=94450 Epoch=901.9] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.197 | L2-Norm(final)=12.190 | 2343.2 samples/s | 36.6 steps/s
[Step=94500 Epoch=902.4] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.198 | L2-Norm(final)=12.194 | 5242.6 samples/s | 81.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=902.4] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.209 | L2-Norm(final)=12.227 | 5672.0 samples/s | 88.6 steps/s
[Step=94550 Epoch=902.9] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.208 | L2-Norm(final)=12.230 | 3687.4 samples/s | 57.6 steps/s
[Step=94600 Epoch=903.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.209 | L2-Norm(final)=12.233 | 6288.4 samples/s | 98.3 steps/s
[Step=94650 Epoch=903.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.207 | L2-Norm(final)=12.235 | 1983.9 samples/s | 31.0 steps/s
[Step=94700 Epoch=904.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.205 | L2-Norm(final)=12.236 | 5841.6 samples/s | 91.3 steps/s
[Step=94750 Epoch=904.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.202 | L2-Norm(final)=12.237 | 2087.8 samples/s | 32.6 steps/s
[Step=94800 Epoch=905.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.199 | L2-Norm(final)=12.238 | 5354.4 samples/s | 83.7 steps/s
[Step=94850 Epoch=905.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.196 | L2-Norm(final)=12.239 | 2126.7 samples/s | 33.2 steps/s
[Step=94900 Epoch=906.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.192 | L2-Norm(final)=12.240 | 4903.4 samples/s | 76.6 steps/s
[Step=94950 Epoch=906.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=12.241 | 2177.5 samples/s | 34.0 steps/s
[Step=95000 Epoch=907.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.185 | L2-Norm(final)=12.242 | 4638.7 samples/s | 72.5 steps/s
[Step=95050 Epoch=907.7] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.181 | L2-Norm(final)=12.243 | 2274.1 samples/s | 35.5 steps/s
[Step=95100 Epoch=908.1] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.177 | L2-Norm(final)=12.244 | 4362.2 samples/s | 68.2 steps/s
[Step=95150 Epoch=908.6] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.173 | L2-Norm(final)=12.244 | 2350.7 samples/s | 36.7 steps/s
[Step=95200 Epoch=909.1] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.169 | L2-Norm(final)=12.245 | 4215.7 samples/s | 65.9 steps/s
[Step=95250 Epoch=909.6] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.164 | L2-Norm(final)=12.246 | 2348.0 samples/s | 36.7 steps/s
[Step=95300 Epoch=910.1] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.160 | L2-Norm(final)=12.247 | 4262.9 samples/s | 66.6 steps/s
[Step=95350 Epoch=910.5] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.156 | L2-Norm(final)=12.247 | 2374.3 samples/s | 37.1 steps/s
[Step=95400 Epoch=911.0] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=12.248 | 4264.7 samples/s | 66.6 steps/s
[Step=95450 Epoch=911.5] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.147 | L2-Norm(final)=12.249 | 2630.8 samples/s | 41.1 steps/s
[Step=95500 Epoch=912.0] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.142 | L2-Norm(final)=12.250 | 3649.4 samples/s | 57.0 steps/s
[Step=95550 Epoch=912.4] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.137 | L2-Norm(final)=12.250 | 6913.7 samples/s | 108.0 steps/s
[Step=95600 Epoch=912.9] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.133 | L2-Norm(final)=12.251 | 1960.0 samples/s | 30.6 steps/s
[Step=95650 Epoch=913.4] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.128 | L2-Norm(final)=12.252 | 6352.8 samples/s | 99.3 steps/s
[Step=95700 Epoch=913.9] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.123 | L2-Norm(final)=12.253 | 2019.9 samples/s | 31.6 steps/s
[Step=95750 Epoch=914.4] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.118 | L2-Norm(final)=12.253 | 5678.8 samples/s | 88.7 steps/s
[Step=95800 Epoch=914.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.113 | L2-Norm(final)=12.254 | 1560.9 samples/s | 24.4 steps/s
[Step=95850 Epoch=915.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.108 | L2-Norm(final)=12.255 | 5367.1 samples/s | 83.9 steps/s
[Step=95900 Epoch=915.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.103 | L2-Norm(final)=12.256 | 2128.5 samples/s | 33.3 steps/s
[Step=95950 Epoch=916.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.098 | L2-Norm(final)=12.257 | 4901.8 samples/s | 76.6 steps/s
[Step=96000 Epoch=916.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.092 | L2-Norm(final)=12.257 | 2219.7 samples/s | 34.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step96000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=885.8] | Loss=0.00005 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.454 | L2-Norm(final)=11.746 | 5263.9 samples/s | 82.2 steps/s
[Step=94050 Epoch=886.2] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.457 | L2-Norm(final)=11.749 | 4181.0 samples/s | 65.3 steps/s
[Step=94100 Epoch=886.7] | Loss=0.00009 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.462 | L2-Norm(final)=11.756 | 7320.8 samples/s | 114.4 steps/s
[Step=94150 Epoch=887.2] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.466 | L2-Norm(final)=11.761 | 2149.0 samples/s | 33.6 steps/s
[Step=94200 Epoch=887.6] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.469 | L2-Norm(final)=11.766 | 6327.5 samples/s | 98.9 steps/s
[Step=94250 Epoch=888.1] | Loss=0.00008 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.472 | L2-Norm(final)=11.771 | 2248.8 samples/s | 35.1 steps/s
[Step=94300 Epoch=888.6] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.474 | L2-Norm(final)=11.776 | 5523.7 samples/s | 86.3 steps/s
[Step=94350 Epoch=889.0] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.477 | L2-Norm(final)=11.780 | 2285.6 samples/s | 35.7 steps/s
[Step=94400 Epoch=889.5] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.479 | L2-Norm(final)=11.784 | 5082.1 samples/s | 79.4 steps/s
[Step=94450 Epoch=890.0] | Loss=0.00007 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.482 | L2-Norm(final)=11.788 | 2488.9 samples/s | 38.9 steps/s
[Step=94500 Epoch=890.5] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.484 | L2-Norm(final)=11.792 | 4625.3 samples/s | 72.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=890.5] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.502 | L2-Norm(final)=11.831 | 4828.4 samples/s | 75.4 steps/s
[Step=94550 Epoch=890.9] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.506 | L2-Norm(final)=11.834 | 4087.3 samples/s | 63.9 steps/s
[Step=94600 Epoch=891.4] | Loss=0.00025 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.511 | L2-Norm(final)=11.838 | 5985.1 samples/s | 93.5 steps/s
[Step=94650 Epoch=891.9] | Loss=0.00046 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.519 | L2-Norm(final)=11.841 | 1978.8 samples/s | 30.9 steps/s
[Step=94700 Epoch=892.3] | Loss=0.00036 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.525 | L2-Norm(final)=11.844 | 5444.1 samples/s | 85.1 steps/s
[Step=94750 Epoch=892.8] | Loss=0.00029 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.528 | L2-Norm(final)=11.846 | 2111.2 samples/s | 33.0 steps/s
[Step=94800 Epoch=893.3] | Loss=0.00025 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.530 | L2-Norm(final)=11.847 | 4917.5 samples/s | 76.8 steps/s
[Step=94850 Epoch=893.8] | Loss=0.00021 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.532 | L2-Norm(final)=11.848 | 2245.6 samples/s | 35.1 steps/s
[Step=94900 Epoch=894.2] | Loss=0.00019 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=11.849 | 4348.7 samples/s | 67.9 steps/s
[Step=94950 Epoch=894.7] | Loss=0.00017 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.850 | 2313.9 samples/s | 36.2 steps/s
[Step=95000 Epoch=895.2] | Loss=0.00015 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.851 | 4234.9 samples/s | 66.2 steps/s
[Step=95050 Epoch=895.6] | Loss=0.00014 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.851 | 2391.4 samples/s | 37.4 steps/s
[Step=95100 Epoch=896.1] | Loss=0.00013 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.852 | 4250.5 samples/s | 66.4 steps/s
[Step=95150 Epoch=896.6] | Loss=0.00012 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.853 | 2407.5 samples/s | 37.6 steps/s
[Step=95200 Epoch=897.1] | Loss=0.00011 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.853 | 4176.7 samples/s | 65.3 steps/s
[Step=95250 Epoch=897.5] | Loss=0.00011 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.854 | 2673.0 samples/s | 41.8 steps/s
[Step=95300 Epoch=898.0] | Loss=0.00010 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.854 | 3613.8 samples/s | 56.5 steps/s
[Step=95350 Epoch=898.5] | Loss=0.00009 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.854 | 6341.7 samples/s | 99.1 steps/s
[Step=95400 Epoch=898.9] | Loss=0.00009 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.855 | 2006.0 samples/s | 31.3 steps/s
[Step=95450 Epoch=899.4] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.855 | 5589.3 samples/s | 87.3 steps/s
[Step=95500 Epoch=899.9] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.536 | L2-Norm(final)=11.856 | 2087.1 samples/s | 32.6 steps/s
[Step=95550 Epoch=900.4] | Loss=0.00008 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.856 | 4969.7 samples/s | 77.7 steps/s
[Step=95600 Epoch=900.8] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.856 | 2232.3 samples/s | 34.9 steps/s
[Step=95650 Epoch=901.3] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.857 | 4450.4 samples/s | 69.5 steps/s
[Step=95700 Epoch=901.8] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=11.857 | 2302.1 samples/s | 36.0 steps/s
[Step=95750 Epoch=902.2] | Loss=0.00007 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.857 | 4245.2 samples/s | 66.3 steps/s
[Step=95800 Epoch=902.7] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.858 | 2337.0 samples/s | 36.5 steps/s
[Step=95850 Epoch=903.2] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.534 | L2-Norm(final)=11.858 | 4233.7 samples/s | 66.2 steps/s
[Step=95900 Epoch=903.7] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=11.858 | 2358.8 samples/s | 36.9 steps/s
[Step=95950 Epoch=904.1] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=11.859 | 4248.7 samples/s | 66.4 steps/s
[Step=96000 Epoch=904.6] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=11.859 | 2558.9 samples/s | 40.0 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step96000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=895.9] | Loss=0.00009 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.368 | L2-Norm(final)=12.601 | 5044.6 samples/s | 78.8 steps/s
[Step=94050 Epoch=896.4] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.368 | L2-Norm(final)=12.602 | 4016.3 samples/s | 62.8 steps/s
[Step=94100 Epoch=896.9] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.369 | L2-Norm(final)=12.603 | 7536.9 samples/s | 117.8 steps/s
[Step=94150 Epoch=897.3] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.369 | L2-Norm(final)=12.604 | 2141.7 samples/s | 33.5 steps/s
[Step=94200 Epoch=897.8] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.606 | 6591.5 samples/s | 103.0 steps/s
[Step=94250 Epoch=898.3] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.607 | 2184.9 samples/s | 34.1 steps/s
[Step=94300 Epoch=898.8] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=12.608 | 6100.0 samples/s | 95.3 steps/s
[Step=94350 Epoch=899.2] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=12.610 | 2241.0 samples/s | 35.0 steps/s
[Step=94400 Epoch=899.7] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.611 | 5652.3 samples/s | 88.3 steps/s
[Step=94450 Epoch=900.2] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.612 | 2359.3 samples/s | 36.9 steps/s
[Step=94500 Epoch=900.7] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.373 | L2-Norm(final)=12.614 | 5220.5 samples/s | 81.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=900.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.377 | L2-Norm(final)=12.627 | 5281.9 samples/s | 82.5 steps/s
[Step=94550 Epoch=901.1] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.628 | 3765.7 samples/s | 58.8 steps/s
[Step=94600 Epoch=901.6] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.629 | 6262.1 samples/s | 97.8 steps/s
[Step=94650 Epoch=902.1] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.630 | 1990.8 samples/s | 31.1 steps/s
[Step=94700 Epoch=902.6] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.632 | 5806.6 samples/s | 90.7 steps/s
[Step=94750 Epoch=903.1] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.633 | 2063.3 samples/s | 32.2 steps/s
[Step=94800 Epoch=903.5] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.634 | 5381.4 samples/s | 84.1 steps/s
[Step=94850 Epoch=904.0] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.634 | 2136.9 samples/s | 33.4 steps/s
[Step=94900 Epoch=904.5] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.635 | 4922.8 samples/s | 76.9 steps/s
[Step=94950 Epoch=905.0] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.636 | 2155.7 samples/s | 33.7 steps/s
[Step=95000 Epoch=905.4] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.637 | 4561.7 samples/s | 71.3 steps/s
[Step=95050 Epoch=905.9] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.637 | 2267.6 samples/s | 35.4 steps/s
[Step=95100 Epoch=906.4] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.638 | 4335.3 samples/s | 67.7 steps/s
[Step=95150 Epoch=906.9] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.639 | 2361.3 samples/s | 36.9 steps/s
[Step=95200 Epoch=907.3] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.639 | 4200.0 samples/s | 65.6 steps/s
[Step=95250 Epoch=907.8] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.640 | 2392.9 samples/s | 37.4 steps/s
[Step=95300 Epoch=908.3] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.641 | 4254.9 samples/s | 66.5 steps/s
[Step=95350 Epoch=908.8] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.377 | L2-Norm(final)=12.641 | 2392.1 samples/s | 37.4 steps/s
[Step=95400 Epoch=909.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.377 | L2-Norm(final)=12.642 | 4250.4 samples/s | 66.4 steps/s
[Step=95450 Epoch=909.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.376 | L2-Norm(final)=12.643 | 2391.0 samples/s | 37.4 steps/s
[Step=95500 Epoch=910.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.376 | L2-Norm(final)=12.643 | 4275.7 samples/s | 66.8 steps/s
[Step=95550 Epoch=910.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.375 | L2-Norm(final)=12.644 | 6712.7 samples/s | 104.9 steps/s
[Step=95600 Epoch=911.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.375 | L2-Norm(final)=12.644 | 1948.5 samples/s | 30.4 steps/s
[Step=95650 Epoch=911.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.374 | L2-Norm(final)=12.645 | 6391.6 samples/s | 99.9 steps/s
[Step=95700 Epoch=912.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.374 | L2-Norm(final)=12.645 | 2018.1 samples/s | 31.5 steps/s
[Step=95750 Epoch=912.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.373 | L2-Norm(final)=12.646 | 5608.7 samples/s | 87.6 steps/s
[Step=95800 Epoch=913.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.646 | 2034.1 samples/s | 31.8 steps/s
[Step=95850 Epoch=913.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.647 | 5371.6 samples/s | 83.9 steps/s
[Step=95900 Epoch=914.0] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=12.647 | 2139.0 samples/s | 33.4 steps/s
[Step=95950 Epoch=914.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.648 | 4949.4 samples/s | 77.3 steps/s
[Step=96000 Epoch=915.0] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.648 | 2225.7 samples/s | 34.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.09870 | acc=0.9556 | tpr=0.9674 | fpr=0.0699 | 4659.5 samples/s | 18.2 steps/s
Avg test loss: 0.10293, Avg test acc: 0.95372, Avg tpr: 0.96631, Avg fpr: 0.07396, total FA: 577

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10324 | acc=0.9555 | tpr=0.9673 | fpr=0.0701 | 4942.3 samples/s | 19.3 steps/s
Avg test loss: 0.10361, Avg test acc: 0.95573, Avg tpr: 0.96794, Avg fpr: 0.07114, total FA: 555

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.09812 | acc=0.9563 | tpr=0.9715 | fpr=0.0768 | 4983.2 samples/s | 19.5 steps/s
Avg test loss: 0.10031, Avg test acc: 0.95480, Avg tpr: 0.96934, Avg fpr: 0.07717, total FA: 602

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09326 | acc=0.9564 | tpr=0.9702 | fpr=0.0736 | 4818.0 samples/s | 18.8 steps/s
Avg test loss: 0.09906, Avg test acc: 0.95456, Avg tpr: 0.97004, Avg fpr: 0.07948, total FA: 620

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10133 | acc=0.9537 | tpr=0.9647 | fpr=0.0701 | 4699.1 samples/s | 18.4 steps/s
Avg test loss: 0.10591, Avg test acc: 0.95244, Avg tpr: 0.96427, Avg fpr: 0.07358, total FA: 574

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.68306 | acc=0.2995 | tpr=0.0063 | fpr=0.0637 | 4691.4 samples/s | 18.3 steps/s
Avg test loss: 5.68990, Avg test acc: 0.29842, Avg tpr: 0.00752, Avg fpr: 0.06179, total FA: 482

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.04557 | acc=0.3044 | tpr=0.0030 | fpr=0.0411 | 4961.5 samples/s | 19.4 steps/s
Avg test loss: 5.06327, Avg test acc: 0.30123, Avg tpr: 0.00321, Avg fpr: 0.04333, total FA: 338

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.22129 | acc=0.2979 | tpr=0.0058 | fpr=0.0679 | 4823.2 samples/s | 18.8 steps/s
Avg test loss: 5.22599, Avg test acc: 0.29574, Avg tpr: 0.00653, Avg fpr: 0.06820, total FA: 532

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.51228 | acc=0.3009 | tpr=0.0094 | fpr=0.0662 | 4670.7 samples/s | 18.2 steps/s
Avg test loss: 5.51171, Avg test acc: 0.29962, Avg tpr: 0.01096, Avg fpr: 0.06550, total FA: 511

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.00551 | acc=0.3046 | tpr=0.0115 | fpr=0.0590 | 4636.5 samples/s | 18.1 steps/s
Avg test loss: 5.01208, Avg test acc: 0.30167, Avg tpr: 0.01160, Avg fpr: 0.06038, total FA: 471

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.47675 | acc=0.1096 | tpr=0.5088 | fpr=0.8976 | 4731.1 samples/s | 18.5 steps/s
[Step= 100] | Loss=5.44842 | acc=0.1114 | tpr=0.4968 | fpr=0.8958 | 7162.1 samples/s | 28.0 steps/s
[Step= 150] | Loss=5.46003 | acc=0.1113 | tpr=0.4870 | fpr=0.8956 | 8034.0 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.45203 | acc=0.1115 | tpr=0.4809 | fpr=0.8952 | 7839.3 samples/s | 30.6 steps/s
[Step= 250] | Loss=5.45553 | acc=0.1125 | tpr=0.4891 | fpr=0.8943 | 7714.6 samples/s | 30.1 steps/s
[Step= 300] | Loss=5.45226 | acc=0.1125 | tpr=0.5004 | fpr=0.8946 | 7791.6 samples/s | 30.4 steps/s
[Step= 350] | Loss=5.44534 | acc=0.1126 | tpr=0.4947 | fpr=0.8943 | 8107.5 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.44482 | acc=0.1123 | tpr=0.4923 | fpr=0.8946 | 7870.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.44998 | acc=0.1127 | tpr=0.4903 | fpr=0.8942 | 7888.2 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.45223 | acc=0.1127 | tpr=0.4877 | fpr=0.8941 | 7497.2 samples/s | 29.3 steps/s
[Step= 550] | Loss=5.45554 | acc=0.1125 | tpr=0.4851 | fpr=0.8943 | 14599.9 samples/s | 57.0 steps/s
Avg test loss: 5.45716, Avg test acc: 0.11236, Avg tpr: 0.48534, Avg fpr: 0.89442, total FA: 124189

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.22636 | acc=0.1035 | tpr=0.3717 | fpr=0.9013 | 4799.4 samples/s | 18.7 steps/s
[Step= 100] | Loss=5.21527 | acc=0.1034 | tpr=0.3923 | fpr=0.9020 | 7298.4 samples/s | 28.5 steps/s
[Step= 150] | Loss=5.21491 | acc=0.1041 | tpr=0.3818 | fpr=0.9010 | 7675.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=5.20885 | acc=0.1036 | tpr=0.3661 | fpr=0.9012 | 7788.7 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.21360 | acc=0.1040 | tpr=0.3703 | fpr=0.9009 | 7799.8 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.21013 | acc=0.1036 | tpr=0.3760 | fpr=0.9014 | 8183.0 samples/s | 32.0 steps/s
[Step= 350] | Loss=5.20485 | acc=0.1035 | tpr=0.3719 | fpr=0.9014 | 7439.1 samples/s | 29.1 steps/s
[Step= 400] | Loss=5.20162 | acc=0.1033 | tpr=0.3698 | fpr=0.9016 | 8046.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.20642 | acc=0.1033 | tpr=0.3710 | fpr=0.9015 | 7744.8 samples/s | 30.3 steps/s
[Step= 500] | Loss=5.21107 | acc=0.1034 | tpr=0.3661 | fpr=0.9013 | 7830.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.21729 | acc=0.1029 | tpr=0.3681 | fpr=0.9019 | 14300.8 samples/s | 55.9 steps/s
Avg test loss: 5.21945, Avg test acc: 0.10290, Avg tpr: 0.36846, Avg fpr: 0.90193, total FA: 125231

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.32725 | acc=0.1074 | tpr=0.2832 | fpr=0.8957 | 4651.2 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.29697 | acc=0.1081 | tpr=0.2687 | fpr=0.8949 | 7525.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=5.31192 | acc=0.1086 | tpr=0.2651 | fpr=0.8942 | 7745.7 samples/s | 30.3 steps/s
[Step= 200] | Loss=5.30339 | acc=0.1094 | tpr=0.2601 | fpr=0.8933 | 7565.2 samples/s | 29.6 steps/s
[Step= 250] | Loss=5.30524 | acc=0.1098 | tpr=0.2681 | fpr=0.8931 | 8086.2 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.30189 | acc=0.1099 | tpr=0.2764 | fpr=0.8931 | 7893.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.29566 | acc=0.1102 | tpr=0.2724 | fpr=0.8927 | 8013.0 samples/s | 31.3 steps/s
[Step= 400] | Loss=5.29510 | acc=0.1105 | tpr=0.2724 | fpr=0.8925 | 7788.6 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.30092 | acc=0.1106 | tpr=0.2712 | fpr=0.8923 | 7704.7 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.30239 | acc=0.1105 | tpr=0.2705 | fpr=0.8923 | 7979.0 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.30569 | acc=0.1102 | tpr=0.2714 | fpr=0.8927 | 13874.3 samples/s | 54.2 steps/s
Avg test loss: 5.30697, Avg test acc: 0.11006, Avg tpr: 0.27219, Avg fpr: 0.89289, total FA: 123976

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.32138 | acc=0.1120 | tpr=0.4956 | fpr=0.8949 | 4705.0 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.29306 | acc=0.1114 | tpr=0.4883 | fpr=0.8956 | 7170.2 samples/s | 28.0 steps/s
[Step= 150] | Loss=5.30568 | acc=0.1107 | tpr=0.4971 | fpr=0.8964 | 8142.9 samples/s | 31.8 steps/s
[Step= 200] | Loss=5.29819 | acc=0.1100 | tpr=0.4874 | fpr=0.8969 | 7700.9 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.30331 | acc=0.1107 | tpr=0.4943 | fpr=0.8963 | 7676.7 samples/s | 30.0 steps/s
[Step= 300] | Loss=5.30255 | acc=0.1106 | tpr=0.5025 | fpr=0.8965 | 7696.1 samples/s | 30.1 steps/s
[Step= 350] | Loss=5.29424 | acc=0.1108 | tpr=0.5009 | fpr=0.8962 | 7768.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=5.29213 | acc=0.1108 | tpr=0.5005 | fpr=0.8963 | 8413.4 samples/s | 32.9 steps/s
[Step= 450] | Loss=5.29678 | acc=0.1108 | tpr=0.4981 | fpr=0.8962 | 7949.0 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.29793 | acc=0.1110 | tpr=0.4947 | fpr=0.8959 | 7811.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.30334 | acc=0.1105 | tpr=0.4883 | fpr=0.8964 | 13635.7 samples/s | 53.3 steps/s
Avg test loss: 5.30470, Avg test acc: 0.11039, Avg tpr: 0.48851, Avg fpr: 0.89648, total FA: 124475

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.36586 | acc=0.1243 | tpr=0.4159 | fpr=0.8809 | 4664.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.34476 | acc=0.1275 | tpr=0.4158 | fpr=0.8779 | 7288.7 samples/s | 28.5 steps/s
[Step= 150] | Loss=5.34609 | acc=0.1272 | tpr=0.4121 | fpr=0.8781 | 7664.2 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.34027 | acc=0.1267 | tpr=0.4011 | fpr=0.8783 | 8259.3 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.34197 | acc=0.1276 | tpr=0.4096 | fpr=0.8775 | 7580.5 samples/s | 29.6 steps/s
[Step= 300] | Loss=5.34337 | acc=0.1273 | tpr=0.4131 | fpr=0.8779 | 8171.1 samples/s | 31.9 steps/s
[Step= 350] | Loss=5.33523 | acc=0.1278 | tpr=0.4126 | fpr=0.8774 | 7993.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.33556 | acc=0.1270 | tpr=0.4103 | fpr=0.8782 | 8092.3 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.34093 | acc=0.1270 | tpr=0.4094 | fpr=0.8781 | 7402.5 samples/s | 28.9 steps/s
[Step= 500] | Loss=5.34343 | acc=0.1267 | tpr=0.4057 | fpr=0.8784 | 8007.4 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.34802 | acc=0.1263 | tpr=0.4067 | fpr=0.8788 | 13679.0 samples/s | 53.4 steps/s
Avg test loss: 5.35007, Avg test acc: 0.12614, Avg tpr: 0.40610, Avg fpr: 0.87895, total FA: 122041

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08898 | acc=0.9820 | tpr=0.9646 | fpr=0.0177 | 4755.2 samples/s | 18.6 steps/s
[Step= 100] | Loss=0.09024 | acc=0.9823 | tpr=0.9638 | fpr=0.0174 | 7174.9 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.09386 | acc=0.9813 | tpr=0.9640 | fpr=0.0184 | 7672.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.09584 | acc=0.9815 | tpr=0.9672 | fpr=0.0182 | 7985.4 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09470 | acc=0.9817 | tpr=0.9642 | fpr=0.0180 | 7839.6 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09667 | acc=0.9813 | tpr=0.9636 | fpr=0.0183 | 7736.6 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.09761 | acc=0.9810 | tpr=0.9643 | fpr=0.0187 | 7773.4 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.09859 | acc=0.9807 | tpr=0.9595 | fpr=0.0189 | 8437.5 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.10068 | acc=0.9803 | tpr=0.9557 | fpr=0.0192 | 7525.8 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.10005 | acc=0.9804 | tpr=0.9564 | fpr=0.0192 | 7853.8 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.09939 | acc=0.9805 | tpr=0.9546 | fpr=0.0190 | 14216.1 samples/s | 55.5 steps/s
Avg test loss: 0.09927, Avg test acc: 0.98053, Avg tpr: 0.95483, Avg fpr: 0.01900, total FA: 2638

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08722 | acc=0.9826 | tpr=0.9292 | fpr=0.0165 | 4847.3 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.08987 | acc=0.9824 | tpr=0.9232 | fpr=0.0165 | 6835.7 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.09352 | acc=0.9819 | tpr=0.9236 | fpr=0.0171 | 7909.6 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.09557 | acc=0.9820 | tpr=0.9290 | fpr=0.0171 | 7983.6 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.09399 | acc=0.9824 | tpr=0.9301 | fpr=0.0167 | 7702.8 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.09602 | acc=0.9820 | tpr=0.9302 | fpr=0.0170 | 7789.9 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.09670 | acc=0.9818 | tpr=0.9311 | fpr=0.0173 | 8012.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09783 | acc=0.9816 | tpr=0.9272 | fpr=0.0175 | 7858.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.10011 | acc=0.9813 | tpr=0.9255 | fpr=0.0177 | 7953.4 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09936 | acc=0.9814 | tpr=0.9278 | fpr=0.0176 | 7761.1 samples/s | 30.3 steps/s
[Step= 550] | Loss=0.09901 | acc=0.9815 | tpr=0.9264 | fpr=0.0175 | 14066.5 samples/s | 54.9 steps/s
Avg test loss: 0.09891, Avg test acc: 0.98147, Avg tpr: 0.92631, Avg fpr: 0.01752, total FA: 2433

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08122 | acc=0.9817 | tpr=0.9690 | fpr=0.0181 | 4785.4 samples/s | 18.7 steps/s
[Step= 100] | Loss=0.08302 | acc=0.9813 | tpr=0.9723 | fpr=0.0185 | 6942.2 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.08693 | acc=0.9805 | tpr=0.9683 | fpr=0.0193 | 8052.9 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.08829 | acc=0.9808 | tpr=0.9727 | fpr=0.0191 | 7946.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.08723 | acc=0.9809 | tpr=0.9721 | fpr=0.0189 | 7721.2 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.08913 | acc=0.9807 | tpr=0.9695 | fpr=0.0191 | 8148.2 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.08976 | acc=0.9805 | tpr=0.9699 | fpr=0.0193 | 7577.8 samples/s | 29.6 steps/s
[Step= 400] | Loss=0.09071 | acc=0.9803 | tpr=0.9666 | fpr=0.0195 | 7841.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.09217 | acc=0.9801 | tpr=0.9649 | fpr=0.0196 | 8075.7 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.09171 | acc=0.9801 | tpr=0.9661 | fpr=0.0197 | 7665.1 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.09125 | acc=0.9802 | tpr=0.9650 | fpr=0.0195 | 14501.6 samples/s | 56.6 steps/s
Avg test loss: 0.09115, Avg test acc: 0.98022, Avg tpr: 0.96513, Avg fpr: 0.01950, total FA: 2708

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.08903 | acc=0.9809 | tpr=0.9602 | fpr=0.0187 | 4894.6 samples/s | 19.1 steps/s
[Step= 100] | Loss=0.09002 | acc=0.9807 | tpr=0.9616 | fpr=0.0190 | 6756.7 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.09364 | acc=0.9799 | tpr=0.9582 | fpr=0.0197 | 8107.8 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.09477 | acc=0.9801 | tpr=0.9617 | fpr=0.0195 | 7537.3 samples/s | 29.4 steps/s
[Step= 250] | Loss=0.09373 | acc=0.9803 | tpr=0.9590 | fpr=0.0193 | 7961.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.09569 | acc=0.9801 | tpr=0.9578 | fpr=0.0195 | 7951.9 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.09637 | acc=0.9799 | tpr=0.9580 | fpr=0.0197 | 7995.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.09681 | acc=0.9798 | tpr=0.9568 | fpr=0.0198 | 7910.9 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.09846 | acc=0.9795 | tpr=0.9537 | fpr=0.0200 | 7763.0 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.09787 | acc=0.9796 | tpr=0.9537 | fpr=0.0199 | 7911.9 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.09731 | acc=0.9798 | tpr=0.9534 | fpr=0.0197 | 13775.6 samples/s | 53.8 steps/s
Avg test loss: 0.09712, Avg test acc: 0.97983, Avg tpr: 0.95365, Avg fpr: 0.01969, total FA: 2734

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09683 | acc=0.9809 | tpr=0.9602 | fpr=0.0188 | 4699.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.10030 | acc=0.9804 | tpr=0.9659 | fpr=0.0193 | 7219.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.10400 | acc=0.9792 | tpr=0.9582 | fpr=0.0204 | 7671.3 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.10554 | acc=0.9791 | tpr=0.9639 | fpr=0.0206 | 8128.3 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.10426 | acc=0.9793 | tpr=0.9590 | fpr=0.0203 | 7740.3 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.10620 | acc=0.9791 | tpr=0.9564 | fpr=0.0205 | 7621.5 samples/s | 29.8 steps/s
[Step= 350] | Loss=0.10699 | acc=0.9789 | tpr=0.9568 | fpr=0.0207 | 7862.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.10821 | acc=0.9786 | tpr=0.9530 | fpr=0.0210 | 8144.8 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.11035 | acc=0.9783 | tpr=0.9499 | fpr=0.0212 | 7771.1 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.10984 | acc=0.9783 | tpr=0.9498 | fpr=0.0212 | 8104.1 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.10921 | acc=0.9786 | tpr=0.9503 | fpr=0.0209 | 13409.4 samples/s | 52.4 steps/s
Avg test loss: 0.10911, Avg test acc: 0.97860, Avg tpr: 0.95008, Avg fpr: 0.02088, total FA: 2899

server round 48/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=468.1] | Loss=0.00225 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=22.297 | 5454.8 samples/s | 85.2 steps/s
[Step=96050 Epoch=468.4] | Loss=0.00655 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=22.301 | 4314.5 samples/s | 67.4 steps/s
[Step=96100 Epoch=468.6] | Loss=0.00618 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=22.307 | 5055.2 samples/s | 79.0 steps/s
[Step=96150 Epoch=468.8] | Loss=0.00657 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=22.313 | 4960.7 samples/s | 77.5 steps/s
[Step=96200 Epoch=469.1] | Loss=0.00650 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=22.319 | 7911.7 samples/s | 123.6 steps/s
[Step=96250 Epoch=469.3] | Loss=0.00650 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=22.325 | 2254.0 samples/s | 35.2 steps/s
[Step=96300 Epoch=469.6] | Loss=0.00629 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=22.331 | 4910.7 samples/s | 76.7 steps/s
[Step=96350 Epoch=469.8] | Loss=0.00622 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=22.337 | 5076.9 samples/s | 79.3 steps/s
[Step=96400 Epoch=470.1] | Loss=0.00622 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=22.342 | 6954.1 samples/s | 108.7 steps/s
[Step=96450 Epoch=470.3] | Loss=0.00615 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.028 | L2-Norm(final)=22.348 | 2301.6 samples/s | 36.0 steps/s
[Step=96500 Epoch=470.6] | Loss=0.00614 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=22.354 | 4982.4 samples/s | 77.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=470.6] | Loss=0.00358 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=22.410 | 5444.3 samples/s | 85.1 steps/s
[Step=96550 Epoch=470.8] | Loss=0.00694 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=22.415 | 3965.3 samples/s | 62.0 steps/s
[Step=96600 Epoch=471.0] | Loss=0.00720 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=22.420 | 4491.8 samples/s | 70.2 steps/s
[Step=96650 Epoch=471.3] | Loss=0.00670 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=22.425 | 4463.9 samples/s | 69.7 steps/s
[Step=96700 Epoch=471.5] | Loss=0.00655 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=22.429 | 6586.6 samples/s | 102.9 steps/s
[Step=96750 Epoch=471.8] | Loss=0.00601 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=22.433 | 2103.8 samples/s | 32.9 steps/s
[Step=96800 Epoch=472.0] | Loss=0.00587 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.068 | L2-Norm(final)=22.437 | 4398.5 samples/s | 68.7 steps/s
[Step=96850 Epoch=472.3] | Loss=0.00562 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=22.441 | 4479.8 samples/s | 70.0 steps/s
[Step=96900 Epoch=472.5] | Loss=0.00557 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=22.444 | 5941.5 samples/s | 92.8 steps/s
[Step=96950 Epoch=472.7] | Loss=0.00532 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.074 | L2-Norm(final)=22.448 | 2205.7 samples/s | 34.5 steps/s
[Step=97000 Epoch=473.0] | Loss=0.00507 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=22.451 | 4352.4 samples/s | 68.0 steps/s
[Step=97050 Epoch=473.2] | Loss=0.00497 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=22.454 | 4519.0 samples/s | 70.6 steps/s
[Step=97100 Epoch=473.5] | Loss=0.00492 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.078 | L2-Norm(final)=22.457 | 5315.6 samples/s | 83.1 steps/s
[Step=97150 Epoch=473.7] | Loss=0.00476 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.079 | L2-Norm(final)=22.460 | 2167.7 samples/s | 33.9 steps/s
[Step=97200 Epoch=474.0] | Loss=0.00468 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=22.463 | 4492.9 samples/s | 70.2 steps/s
[Step=97250 Epoch=474.2] | Loss=0.00462 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=22.466 | 4478.2 samples/s | 70.0 steps/s
[Step=97300 Epoch=474.5] | Loss=0.00454 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=22.469 | 4958.4 samples/s | 77.5 steps/s
[Step=97350 Epoch=474.7] | Loss=0.00447 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=22.472 | 2320.1 samples/s | 36.3 steps/s
[Step=97400 Epoch=474.9] | Loss=0.00433 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.085 | L2-Norm(final)=22.475 | 4478.3 samples/s | 70.0 steps/s
[Step=97450 Epoch=475.2] | Loss=0.00433 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=22.477 | 4387.2 samples/s | 68.6 steps/s
[Step=97500 Epoch=475.4] | Loss=0.00429 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.086 | L2-Norm(final)=22.480 | 4595.5 samples/s | 71.8 steps/s
[Step=97550 Epoch=475.7] | Loss=0.00419 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=22.483 | 2434.3 samples/s | 38.0 steps/s
[Step=97600 Epoch=475.9] | Loss=0.00410 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=22.485 | 4397.5 samples/s | 68.7 steps/s
[Step=97650 Epoch=476.2] | Loss=0.00404 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.089 | L2-Norm(final)=22.488 | 4493.7 samples/s | 70.2 steps/s
[Step=97700 Epoch=476.4] | Loss=0.00402 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=22.490 | 4447.5 samples/s | 69.5 steps/s
[Step=97750 Epoch=476.6] | Loss=0.00394 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.090 | L2-Norm(final)=22.493 | 2445.7 samples/s | 38.2 steps/s
[Step=97800 Epoch=476.9] | Loss=0.00386 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=22.495 | 4360.8 samples/s | 68.1 steps/s
[Step=97850 Epoch=477.1] | Loss=0.00383 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=22.498 | 4467.6 samples/s | 69.8 steps/s
[Step=97900 Epoch=477.4] | Loss=0.00377 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=22.500 | 4528.6 samples/s | 70.8 steps/s
[Step=97950 Epoch=477.6] | Loss=0.00376 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=22.503 | 2491.8 samples/s | 38.9 steps/s
[Step=98000 Epoch=477.9] | Loss=0.00369 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=22.505 | 4447.9 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step98000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=468.4] | Loss=0.00898 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.605 | L2-Norm(final)=23.320 | 5150.3 samples/s | 80.5 steps/s
[Step=96050 Epoch=468.7] | Loss=0.00515 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.607 | L2-Norm(final)=23.325 | 4520.1 samples/s | 70.6 steps/s
[Step=96100 Epoch=468.9] | Loss=0.00524 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=23.332 | 4918.3 samples/s | 76.8 steps/s
[Step=96150 Epoch=469.2] | Loss=0.00528 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.612 | L2-Norm(final)=23.339 | 4957.9 samples/s | 77.5 steps/s
[Step=96200 Epoch=469.4] | Loss=0.00554 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=23.345 | 7788.9 samples/s | 121.7 steps/s
[Step=96250 Epoch=469.7] | Loss=0.00535 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=23.351 | 2214.1 samples/s | 34.6 steps/s
[Step=96300 Epoch=469.9] | Loss=0.00534 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=23.358 | 5073.4 samples/s | 79.3 steps/s
[Step=96350 Epoch=470.1] | Loss=0.00537 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=23.364 | 5172.5 samples/s | 80.8 steps/s
[Step=96400 Epoch=470.4] | Loss=0.00527 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=23.370 | 6879.3 samples/s | 107.5 steps/s
[Step=96450 Epoch=470.6] | Loss=0.00535 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=23.376 | 2249.2 samples/s | 35.1 steps/s
[Step=96500 Epoch=470.9] | Loss=0.00533 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=23.383 | 4970.6 samples/s | 77.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=470.9] | Loss=0.00457 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=23.443 | 5747.6 samples/s | 89.8 steps/s
[Step=96550 Epoch=471.1] | Loss=0.00560 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.652 | L2-Norm(final)=23.449 | 3814.7 samples/s | 59.6 steps/s
[Step=96600 Epoch=471.4] | Loss=0.00554 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=23.454 | 4466.0 samples/s | 69.8 steps/s
[Step=96650 Epoch=471.6] | Loss=0.00592 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=23.459 | 4511.2 samples/s | 70.5 steps/s
[Step=96700 Epoch=471.9] | Loss=0.00624 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=23.463 | 6577.5 samples/s | 102.8 steps/s
[Step=96750 Epoch=472.1] | Loss=0.00596 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=23.468 | 2087.8 samples/s | 32.6 steps/s
[Step=96800 Epoch=472.3] | Loss=0.00564 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=23.472 | 4383.6 samples/s | 68.5 steps/s
[Step=96850 Epoch=472.6] | Loss=0.00552 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.669 | L2-Norm(final)=23.476 | 4392.0 samples/s | 68.6 steps/s
[Step=96900 Epoch=472.8] | Loss=0.00523 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=23.480 | 6072.3 samples/s | 94.9 steps/s
[Step=96950 Epoch=473.1] | Loss=0.00502 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.673 | L2-Norm(final)=23.484 | 2142.5 samples/s | 33.5 steps/s
[Step=97000 Epoch=473.3] | Loss=0.00482 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.675 | L2-Norm(final)=23.487 | 4457.8 samples/s | 69.7 steps/s
[Step=97050 Epoch=473.6] | Loss=0.00467 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=23.490 | 4459.7 samples/s | 69.7 steps/s
[Step=97100 Epoch=473.8] | Loss=0.00452 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=23.494 | 5635.1 samples/s | 88.0 steps/s
[Step=97150 Epoch=474.0] | Loss=0.00436 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=23.497 | 2191.2 samples/s | 34.2 steps/s
[Step=97200 Epoch=474.3] | Loss=0.00427 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.680 | L2-Norm(final)=23.500 | 4436.8 samples/s | 69.3 steps/s
[Step=97250 Epoch=474.5] | Loss=0.00418 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=23.503 | 4434.5 samples/s | 69.3 steps/s
[Step=97300 Epoch=474.8] | Loss=0.00410 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=23.506 | 5231.7 samples/s | 81.7 steps/s
[Step=97350 Epoch=475.0] | Loss=0.00400 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=23.509 | 2289.8 samples/s | 35.8 steps/s
[Step=97400 Epoch=475.3] | Loss=0.00392 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=23.512 | 4414.1 samples/s | 69.0 steps/s
[Step=97450 Epoch=475.5] | Loss=0.00384 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.685 | L2-Norm(final)=23.515 | 4532.6 samples/s | 70.8 steps/s
[Step=97500 Epoch=475.8] | Loss=0.00379 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=23.518 | 4795.4 samples/s | 74.9 steps/s
[Step=97550 Epoch=476.0] | Loss=0.00375 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.687 | L2-Norm(final)=23.521 | 2310.0 samples/s | 36.1 steps/s
[Step=97600 Epoch=476.2] | Loss=0.00370 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=23.523 | 4452.3 samples/s | 69.6 steps/s
[Step=97650 Epoch=476.5] | Loss=0.00364 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=23.526 | 4483.6 samples/s | 70.1 steps/s
[Step=97700 Epoch=476.7] | Loss=0.00357 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=23.529 | 4592.4 samples/s | 71.8 steps/s
[Step=97750 Epoch=477.0] | Loss=0.00351 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=23.531 | 2424.7 samples/s | 37.9 steps/s
[Step=97800 Epoch=477.2] | Loss=0.00344 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=23.534 | 4465.9 samples/s | 69.8 steps/s
[Step=97850 Epoch=477.5] | Loss=0.00339 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=23.537 | 4455.2 samples/s | 69.6 steps/s
[Step=97900 Epoch=477.7] | Loss=0.00336 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=23.539 | 4377.6 samples/s | 68.4 steps/s
[Step=97950 Epoch=478.0] | Loss=0.00334 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=23.542 | 2431.5 samples/s | 38.0 steps/s
[Step=98000 Epoch=478.2] | Loss=0.00328 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=23.545 | 4475.1 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step98000.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=467.8] | Loss=0.00701 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=23.250 | 5340.9 samples/s | 83.5 steps/s
[Step=96050 Epoch=468.0] | Loss=0.00712 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.418 | L2-Norm(final)=23.254 | 4603.7 samples/s | 71.9 steps/s
[Step=96100 Epoch=468.2] | Loss=0.00654 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.420 | L2-Norm(final)=23.260 | 4865.5 samples/s | 76.0 steps/s
[Step=96150 Epoch=468.5] | Loss=0.00624 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.422 | L2-Norm(final)=23.266 | 5074.8 samples/s | 79.3 steps/s
[Step=96200 Epoch=468.7] | Loss=0.00636 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=23.272 | 7716.7 samples/s | 120.6 steps/s
[Step=96250 Epoch=469.0] | Loss=0.00615 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.427 | L2-Norm(final)=23.277 | 2201.6 samples/s | 34.4 steps/s
[Step=96300 Epoch=469.2] | Loss=0.00622 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=23.283 | 4976.2 samples/s | 77.8 steps/s
[Step=96350 Epoch=469.5] | Loss=0.00617 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.431 | L2-Norm(final)=23.288 | 5035.9 samples/s | 78.7 steps/s
[Step=96400 Epoch=469.7] | Loss=0.00608 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=23.294 | 6956.8 samples/s | 108.7 steps/s
[Step=96450 Epoch=470.0] | Loss=0.00603 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=23.299 | 2268.3 samples/s | 35.4 steps/s
[Step=96500 Epoch=470.2] | Loss=0.00599 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=23.305 | 5059.0 samples/s | 79.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=470.2] | Loss=0.00643 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=23.358 | 5187.6 samples/s | 81.1 steps/s
[Step=96550 Epoch=470.4] | Loss=0.00596 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.459 | L2-Norm(final)=23.363 | 4107.7 samples/s | 64.2 steps/s
[Step=96600 Epoch=470.7] | Loss=0.00699 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=23.368 | 4420.3 samples/s | 69.1 steps/s
[Step=96650 Epoch=470.9] | Loss=0.00719 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=23.373 | 4474.1 samples/s | 69.9 steps/s
[Step=96700 Epoch=471.2] | Loss=0.00715 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.469 | L2-Norm(final)=23.377 | 6508.6 samples/s | 101.7 steps/s
[Step=96750 Epoch=471.4] | Loss=0.00668 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=23.381 | 2114.4 samples/s | 33.0 steps/s
[Step=96800 Epoch=471.7] | Loss=0.00634 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.474 | L2-Norm(final)=23.385 | 4472.9 samples/s | 69.9 steps/s
[Step=96850 Epoch=471.9] | Loss=0.00606 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=23.389 | 4433.2 samples/s | 69.3 steps/s
[Step=96900 Epoch=472.1] | Loss=0.00586 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.478 | L2-Norm(final)=23.392 | 5947.9 samples/s | 92.9 steps/s
[Step=96950 Epoch=472.4] | Loss=0.00565 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=23.396 | 2117.3 samples/s | 33.1 steps/s
[Step=97000 Epoch=472.6] | Loss=0.00549 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=23.399 | 4471.4 samples/s | 69.9 steps/s
[Step=97050 Epoch=472.9] | Loss=0.00527 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=23.402 | 4465.8 samples/s | 69.8 steps/s
[Step=97100 Epoch=473.1] | Loss=0.00512 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.484 | L2-Norm(final)=23.405 | 5420.3 samples/s | 84.7 steps/s
[Step=97150 Epoch=473.4] | Loss=0.00493 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=23.408 | 2225.3 samples/s | 34.8 steps/s
[Step=97200 Epoch=473.6] | Loss=0.00478 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=23.411 | 4499.7 samples/s | 70.3 steps/s
[Step=97250 Epoch=473.8] | Loss=0.00468 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.487 | L2-Norm(final)=23.414 | 4477.1 samples/s | 70.0 steps/s
[Step=97300 Epoch=474.1] | Loss=0.00465 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.488 | L2-Norm(final)=23.417 | 4864.5 samples/s | 76.0 steps/s
[Step=97350 Epoch=474.3] | Loss=0.00454 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.489 | L2-Norm(final)=23.419 | 2332.4 samples/s | 36.4 steps/s
[Step=97400 Epoch=474.6] | Loss=0.00441 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.490 | L2-Norm(final)=23.422 | 4488.6 samples/s | 70.1 steps/s
[Step=97450 Epoch=474.8] | Loss=0.00432 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=23.425 | 4461.3 samples/s | 69.7 steps/s
[Step=97500 Epoch=475.1] | Loss=0.00429 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=23.428 | 4618.7 samples/s | 72.2 steps/s
[Step=97550 Epoch=475.3] | Loss=0.00423 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=23.430 | 2424.4 samples/s | 37.9 steps/s
[Step=97600 Epoch=475.6] | Loss=0.00418 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=23.433 | 4429.1 samples/s | 69.2 steps/s
[Step=97650 Epoch=475.8] | Loss=0.00410 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.494 | L2-Norm(final)=23.435 | 4398.1 samples/s | 68.7 steps/s
[Step=97700 Epoch=476.0] | Loss=0.00403 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.495 | L2-Norm(final)=23.438 | 4526.7 samples/s | 70.7 steps/s
[Step=97750 Epoch=476.3] | Loss=0.00400 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=23.441 | 2436.0 samples/s | 38.1 steps/s
[Step=97800 Epoch=476.5] | Loss=0.00393 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.496 | L2-Norm(final)=23.443 | 4470.7 samples/s | 69.9 steps/s
[Step=97850 Epoch=476.8] | Loss=0.00388 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=23.446 | 4505.2 samples/s | 70.4 steps/s
[Step=97900 Epoch=477.0] | Loss=0.00382 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=23.448 | 4464.2 samples/s | 69.8 steps/s
[Step=97950 Epoch=477.3] | Loss=0.00381 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=23.451 | 2420.8 samples/s | 37.8 steps/s
[Step=98000 Epoch=477.5] | Loss=0.00377 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=23.453 | 4528.3 samples/s | 70.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step98000.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=468.2] | Loss=0.00815 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=23.295 | 5642.6 samples/s | 88.2 steps/s
[Step=96050 Epoch=468.4] | Loss=0.00693 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=23.299 | 4297.8 samples/s | 67.2 steps/s
[Step=96100 Epoch=468.6] | Loss=0.00622 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=23.305 | 5024.0 samples/s | 78.5 steps/s
[Step=96150 Epoch=468.9] | Loss=0.00645 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.104 | L2-Norm(final)=23.312 | 5195.6 samples/s | 81.2 steps/s
[Step=96200 Epoch=469.1] | Loss=0.00642 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=23.318 | 7538.0 samples/s | 117.8 steps/s
[Step=96250 Epoch=469.4] | Loss=0.00614 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.109 | L2-Norm(final)=23.324 | 2212.2 samples/s | 34.6 steps/s
[Step=96300 Epoch=469.6] | Loss=0.00604 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.111 | L2-Norm(final)=23.330 | 4924.1 samples/s | 76.9 steps/s
[Step=96350 Epoch=469.9] | Loss=0.00604 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.113 | L2-Norm(final)=23.336 | 5095.6 samples/s | 79.6 steps/s
[Step=96400 Epoch=470.1] | Loss=0.00606 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=23.342 | 6745.7 samples/s | 105.4 steps/s
[Step=96450 Epoch=470.3] | Loss=0.00617 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=23.347 | 2316.0 samples/s | 36.2 steps/s
[Step=96500 Epoch=470.6] | Loss=0.00615 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=23.353 | 5027.0 samples/s | 78.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=470.6] | Loss=0.00560 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=23.411 | 5606.0 samples/s | 87.6 steps/s
[Step=96550 Epoch=470.8] | Loss=0.00703 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=23.416 | 3996.0 samples/s | 62.4 steps/s
[Step=96600 Epoch=471.1] | Loss=0.00716 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.147 | L2-Norm(final)=23.421 | 4484.4 samples/s | 70.1 steps/s
[Step=96650 Epoch=471.3] | Loss=0.00740 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=23.425 | 4343.7 samples/s | 67.9 steps/s
[Step=96700 Epoch=471.6] | Loss=0.00705 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.154 | L2-Norm(final)=23.429 | 6558.9 samples/s | 102.5 steps/s
[Step=96750 Epoch=471.8] | Loss=0.00652 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=23.433 | 2106.0 samples/s | 32.9 steps/s
[Step=96800 Epoch=472.1] | Loss=0.00602 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=23.437 | 4456.2 samples/s | 69.6 steps/s
[Step=96850 Epoch=472.3] | Loss=0.00564 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=23.441 | 4482.9 samples/s | 70.0 steps/s
[Step=96900 Epoch=472.5] | Loss=0.00543 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=23.444 | 5955.9 samples/s | 93.1 steps/s
[Step=96950 Epoch=472.8] | Loss=0.00526 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.165 | L2-Norm(final)=23.447 | 2192.4 samples/s | 34.3 steps/s
[Step=97000 Epoch=473.0] | Loss=0.00507 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=23.451 | 4410.2 samples/s | 68.9 steps/s
[Step=97050 Epoch=473.3] | Loss=0.00489 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=23.454 | 4451.0 samples/s | 69.5 steps/s
[Step=97100 Epoch=473.5] | Loss=0.00470 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=23.457 | 5405.9 samples/s | 84.5 steps/s
[Step=97150 Epoch=473.8] | Loss=0.00458 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=23.460 | 2273.9 samples/s | 35.5 steps/s
[Step=97200 Epoch=474.0] | Loss=0.00447 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=23.463 | 4409.4 samples/s | 68.9 steps/s
[Step=97250 Epoch=474.2] | Loss=0.00432 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=23.465 | 4503.7 samples/s | 70.4 steps/s
[Step=97300 Epoch=474.5] | Loss=0.00423 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=23.468 | 4964.6 samples/s | 77.6 steps/s
[Step=97350 Epoch=474.7] | Loss=0.00415 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.175 | L2-Norm(final)=23.471 | 2273.4 samples/s | 35.5 steps/s
[Step=97400 Epoch=475.0] | Loss=0.00405 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=23.474 | 4484.0 samples/s | 70.1 steps/s
[Step=97450 Epoch=475.2] | Loss=0.00394 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=23.476 | 4553.1 samples/s | 71.1 steps/s
[Step=97500 Epoch=475.5] | Loss=0.00389 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=23.479 | 4540.7 samples/s | 70.9 steps/s
[Step=97550 Epoch=475.7] | Loss=0.00383 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=23.482 | 2410.8 samples/s | 37.7 steps/s
[Step=97600 Epoch=476.0] | Loss=0.00376 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=23.484 | 4490.9 samples/s | 70.2 steps/s
[Step=97650 Epoch=476.2] | Loss=0.00372 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=23.487 | 4490.7 samples/s | 70.2 steps/s
[Step=97700 Epoch=476.4] | Loss=0.00365 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=23.489 | 4418.4 samples/s | 69.0 steps/s
[Step=97750 Epoch=476.7] | Loss=0.00362 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=23.492 | 2449.4 samples/s | 38.3 steps/s
[Step=97800 Epoch=476.9] | Loss=0.00358 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=23.494 | 4407.1 samples/s | 68.9 steps/s
[Step=97850 Epoch=477.2] | Loss=0.00354 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=23.497 | 4509.4 samples/s | 70.5 steps/s
[Step=97900 Epoch=477.4] | Loss=0.00348 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=23.499 | 4436.3 samples/s | 69.3 steps/s
[Step=97950 Epoch=477.7] | Loss=0.00343 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=23.502 | 2490.4 samples/s | 38.9 steps/s
[Step=98000 Epoch=477.9] | Loss=0.00339 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=23.504 | 4459.3 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step98000.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=470.8] | Loss=0.01126 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.713 | L2-Norm(final)=23.406 | 4803.2 samples/s | 75.0 steps/s
[Step=96050 Epoch=471.0] | Loss=0.00589 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=23.411 | 4729.6 samples/s | 73.9 steps/s
[Step=96100 Epoch=471.3] | Loss=0.00576 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=23.417 | 4922.5 samples/s | 76.9 steps/s
[Step=96150 Epoch=471.5] | Loss=0.00560 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=23.423 | 5040.4 samples/s | 78.8 steps/s
[Step=96200 Epoch=471.7] | Loss=0.00536 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=23.429 | 8013.9 samples/s | 125.2 steps/s
[Step=96250 Epoch=472.0] | Loss=0.00525 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=23.435 | 2246.6 samples/s | 35.1 steps/s
[Step=96300 Epoch=472.2] | Loss=0.00519 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=23.440 | 5016.3 samples/s | 78.4 steps/s
[Step=96350 Epoch=472.5] | Loss=0.00517 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.729 | L2-Norm(final)=23.446 | 4901.1 samples/s | 76.6 steps/s
[Step=96400 Epoch=472.7] | Loss=0.00514 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.731 | L2-Norm(final)=23.452 | 7124.4 samples/s | 111.3 steps/s
[Step=96450 Epoch=473.0] | Loss=0.00514 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=23.457 | 2202.7 samples/s | 34.4 steps/s
[Step=96500 Epoch=473.2] | Loss=0.00505 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=23.463 | 5136.7 samples/s | 80.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=473.2] | Loss=0.00583 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=23.518 | 5310.1 samples/s | 83.0 steps/s
[Step=96550 Epoch=473.5] | Loss=0.00650 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.757 | L2-Norm(final)=23.523 | 4061.4 samples/s | 63.5 steps/s
[Step=96600 Epoch=473.7] | Loss=0.00682 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=23.528 | 4478.7 samples/s | 70.0 steps/s
[Step=96650 Epoch=474.0] | Loss=0.00682 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=23.533 | 4523.8 samples/s | 70.7 steps/s
[Step=96700 Epoch=474.2] | Loss=0.00646 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.767 | L2-Norm(final)=23.538 | 6671.2 samples/s | 104.2 steps/s
[Step=96750 Epoch=474.4] | Loss=0.00603 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.769 | L2-Norm(final)=23.542 | 2061.9 samples/s | 32.2 steps/s
[Step=96800 Epoch=474.7] | Loss=0.00561 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.771 | L2-Norm(final)=23.546 | 4341.8 samples/s | 67.8 steps/s
[Step=96850 Epoch=474.9] | Loss=0.00530 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.773 | L2-Norm(final)=23.549 | 4539.3 samples/s | 70.9 steps/s
[Step=96900 Epoch=475.2] | Loss=0.00511 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.775 | L2-Norm(final)=23.553 | 6146.2 samples/s | 96.0 steps/s
[Step=96950 Epoch=475.4] | Loss=0.00492 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.776 | L2-Norm(final)=23.556 | 2126.6 samples/s | 33.2 steps/s
[Step=97000 Epoch=475.7] | Loss=0.00469 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=23.560 | 4517.6 samples/s | 70.6 steps/s
[Step=97050 Epoch=475.9] | Loss=0.00458 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=23.563 | 4335.6 samples/s | 67.7 steps/s
[Step=97100 Epoch=476.2] | Loss=0.00449 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.780 | L2-Norm(final)=23.566 | 5780.0 samples/s | 90.3 steps/s
[Step=97150 Epoch=476.4] | Loss=0.00434 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.782 | L2-Norm(final)=23.569 | 2161.0 samples/s | 33.8 steps/s
[Step=97200 Epoch=476.7] | Loss=0.00418 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.783 | L2-Norm(final)=23.572 | 4472.7 samples/s | 69.9 steps/s
[Step=97250 Epoch=476.9] | Loss=0.00412 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.784 | L2-Norm(final)=23.575 | 4504.8 samples/s | 70.4 steps/s
[Step=97300 Epoch=477.1] | Loss=0.00401 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=23.578 | 5482.6 samples/s | 85.7 steps/s
[Step=97350 Epoch=477.4] | Loss=0.00391 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=23.581 | 2204.0 samples/s | 34.4 steps/s
[Step=97400 Epoch=477.6] | Loss=0.00382 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=23.584 | 4387.8 samples/s | 68.6 steps/s
[Step=97450 Epoch=477.9] | Loss=0.00373 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=23.586 | 4499.8 samples/s | 70.3 steps/s
[Step=97500 Epoch=478.1] | Loss=0.00371 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.788 | L2-Norm(final)=23.589 | 5140.1 samples/s | 80.3 steps/s
[Step=97550 Epoch=478.4] | Loss=0.00363 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.789 | L2-Norm(final)=23.592 | 2277.0 samples/s | 35.6 steps/s
[Step=97600 Epoch=478.6] | Loss=0.00357 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.790 | L2-Norm(final)=23.594 | 4479.5 samples/s | 70.0 steps/s
[Step=97650 Epoch=478.9] | Loss=0.00348 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.790 | L2-Norm(final)=23.597 | 4498.6 samples/s | 70.3 steps/s
[Step=97700 Epoch=479.1] | Loss=0.00343 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.791 | L2-Norm(final)=23.600 | 4950.6 samples/s | 77.4 steps/s
[Step=97750 Epoch=479.4] | Loss=0.00338 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.792 | L2-Norm(final)=23.602 | 2320.3 samples/s | 36.3 steps/s
[Step=97800 Epoch=479.6] | Loss=0.00333 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.792 | L2-Norm(final)=23.605 | 4444.6 samples/s | 69.4 steps/s
[Step=97850 Epoch=479.8] | Loss=0.00330 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=23.607 | 4439.9 samples/s | 69.4 steps/s
[Step=97900 Epoch=480.1] | Loss=0.00325 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=23.610 | 4705.8 samples/s | 73.5 steps/s
[Step=97950 Epoch=480.3] | Loss=0.00322 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.794 | L2-Norm(final)=23.612 | 2399.6 samples/s | 37.5 steps/s
[Step=98000 Epoch=480.6] | Loss=0.00318 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.794 | L2-Norm(final)=23.615 | 4595.3 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step98000.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=909.7] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.181 | L2-Norm(final)=11.762 | 5234.7 samples/s | 81.8 steps/s
[Step=96050 Epoch=910.2] | Loss=0.00007 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.184 | L2-Norm(final)=11.769 | 4234.6 samples/s | 66.2 steps/s
[Step=96100 Epoch=910.6] | Loss=0.00005 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.189 | L2-Norm(final)=11.778 | 7353.6 samples/s | 114.9 steps/s
[Step=96150 Epoch=911.1] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.193 | L2-Norm(final)=11.784 | 2123.1 samples/s | 33.2 steps/s
[Step=96200 Epoch=911.6] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=11.789 | 6514.7 samples/s | 101.8 steps/s
[Step=96250 Epoch=912.1] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.198 | L2-Norm(final)=11.795 | 2205.2 samples/s | 34.5 steps/s
[Step=96300 Epoch=912.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.201 | L2-Norm(final)=11.800 | 5938.4 samples/s | 92.8 steps/s
[Step=96350 Epoch=913.0] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=11.804 | 2297.9 samples/s | 35.9 steps/s
[Step=96400 Epoch=913.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.205 | L2-Norm(final)=11.809 | 5381.1 samples/s | 84.1 steps/s
[Step=96450 Epoch=913.9] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.207 | L2-Norm(final)=11.813 | 2375.3 samples/s | 37.1 steps/s
[Step=96500 Epoch=914.4] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.208 | L2-Norm(final)=11.818 | 4868.5 samples/s | 76.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=914.4] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=11.860 | 5422.9 samples/s | 84.7 steps/s
[Step=96550 Epoch=914.9] | Loss=0.00006 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.232 | L2-Norm(final)=11.865 | 3872.0 samples/s | 60.5 steps/s
[Step=96600 Epoch=915.4] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.238 | L2-Norm(final)=11.870 | 6279.9 samples/s | 98.1 steps/s
[Step=96650 Epoch=915.8] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.240 | L2-Norm(final)=11.873 | 2008.5 samples/s | 31.4 steps/s
[Step=96700 Epoch=916.3] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.239 | L2-Norm(final)=11.875 | 5684.8 samples/s | 88.8 steps/s
[Step=96750 Epoch=916.8] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.238 | L2-Norm(final)=11.876 | 2115.5 samples/s | 33.1 steps/s
[Step=96800 Epoch=917.3] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.236 | L2-Norm(final)=11.877 | 4971.0 samples/s | 77.7 steps/s
[Step=96850 Epoch=917.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.234 | L2-Norm(final)=11.878 | 2165.9 samples/s | 33.8 steps/s
[Step=96900 Epoch=918.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.231 | L2-Norm(final)=11.879 | 4723.9 samples/s | 73.8 steps/s
[Step=96950 Epoch=918.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.229 | L2-Norm(final)=11.880 | 2251.7 samples/s | 35.2 steps/s
[Step=97000 Epoch=919.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.226 | L2-Norm(final)=11.881 | 4373.0 samples/s | 68.3 steps/s
[Step=97050 Epoch=919.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.223 | L2-Norm(final)=11.881 | 2403.6 samples/s | 37.6 steps/s
[Step=97100 Epoch=920.1] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.219 | L2-Norm(final)=11.882 | 4236.4 samples/s | 66.2 steps/s
[Step=97150 Epoch=920.6] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.216 | L2-Norm(final)=11.883 | 2417.9 samples/s | 37.8 steps/s
[Step=97200 Epoch=921.1] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.213 | L2-Norm(final)=11.883 | 4100.9 samples/s | 64.1 steps/s
[Step=97250 Epoch=921.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.210 | L2-Norm(final)=11.884 | 2371.3 samples/s | 37.1 steps/s
[Step=97300 Epoch=922.0] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.206 | L2-Norm(final)=11.885 | 4209.4 samples/s | 65.8 steps/s
[Step=97350 Epoch=922.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.203 | L2-Norm(final)=11.885 | 2550.0 samples/s | 39.8 steps/s
[Step=97400 Epoch=922.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.199 | L2-Norm(final)=11.886 | 3835.7 samples/s | 59.9 steps/s
[Step=97450 Epoch=923.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=11.886 | 6541.5 samples/s | 102.2 steps/s
[Step=97500 Epoch=923.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.192 | L2-Norm(final)=11.887 | 2019.5 samples/s | 31.6 steps/s
[Step=97550 Epoch=924.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.188 | L2-Norm(final)=11.888 | 5647.9 samples/s | 88.2 steps/s
[Step=97600 Epoch=924.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.184 | L2-Norm(final)=11.888 | 2073.5 samples/s | 32.4 steps/s
[Step=97650 Epoch=925.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.180 | L2-Norm(final)=11.889 | 5298.6 samples/s | 82.8 steps/s
[Step=97700 Epoch=925.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.176 | L2-Norm(final)=11.889 | 2126.5 samples/s | 33.2 steps/s
[Step=97750 Epoch=926.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.172 | L2-Norm(final)=11.890 | 4872.9 samples/s | 76.1 steps/s
[Step=97800 Epoch=926.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.168 | L2-Norm(final)=11.891 | 2215.2 samples/s | 34.6 steps/s
[Step=97850 Epoch=927.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.164 | L2-Norm(final)=11.891 | 4487.8 samples/s | 70.1 steps/s
[Step=97900 Epoch=927.7] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.159 | L2-Norm(final)=11.892 | 2342.3 samples/s | 36.6 steps/s
[Step=97950 Epoch=928.2] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.155 | L2-Norm(final)=11.892 | 4185.1 samples/s | 65.4 steps/s
[Step=98000 Epoch=928.6] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=11.893 | 2415.7 samples/s | 37.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step98000.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=913.2] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.147 | L2-Norm(final)=12.932 | 5099.1 samples/s | 79.7 steps/s
[Step=96050 Epoch=913.7] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.148 | L2-Norm(final)=12.937 | 4020.7 samples/s | 62.8 steps/s
[Step=96100 Epoch=914.1] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.150 | L2-Norm(final)=12.941 | 7602.6 samples/s | 118.8 steps/s
[Step=96150 Epoch=914.6] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=12.946 | 2109.1 samples/s | 33.0 steps/s
[Step=96200 Epoch=915.1] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.153 | L2-Norm(final)=12.950 | 6676.2 samples/s | 104.3 steps/s
[Step=96250 Epoch=915.6] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.155 | L2-Norm(final)=12.954 | 2222.1 samples/s | 34.7 steps/s
[Step=96300 Epoch=916.1] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.156 | L2-Norm(final)=12.959 | 5949.9 samples/s | 93.0 steps/s
[Step=96350 Epoch=916.5] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.157 | L2-Norm(final)=12.963 | 2331.6 samples/s | 36.4 steps/s
[Step=96400 Epoch=917.0] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.159 | L2-Norm(final)=12.967 | 5217.9 samples/s | 81.5 steps/s
[Step=96450 Epoch=917.5] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.160 | L2-Norm(final)=12.971 | 2449.7 samples/s | 38.3 steps/s
[Step=96500 Epoch=918.0] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.161 | L2-Norm(final)=12.975 | 5037.6 samples/s | 78.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=918.0] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.173 | L2-Norm(final)=13.013 | 5694.8 samples/s | 89.0 steps/s
[Step=96550 Epoch=918.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.172 | L2-Norm(final)=13.017 | 3577.5 samples/s | 55.9 steps/s
[Step=96600 Epoch=918.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.170 | L2-Norm(final)=13.020 | 6316.9 samples/s | 98.7 steps/s
[Step=96650 Epoch=919.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.166 | L2-Norm(final)=13.022 | 2005.7 samples/s | 31.3 steps/s
[Step=96700 Epoch=919.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.162 | L2-Norm(final)=13.023 | 5700.6 samples/s | 89.1 steps/s
[Step=96750 Epoch=920.3] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.156 | L2-Norm(final)=13.025 | 2087.0 samples/s | 32.6 steps/s
[Step=96800 Epoch=920.8] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.151 | L2-Norm(final)=13.026 | 5183.6 samples/s | 81.0 steps/s
[Step=96850 Epoch=921.3] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.145 | L2-Norm(final)=13.027 | 2162.2 samples/s | 33.8 steps/s
[Step=96900 Epoch=921.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.139 | L2-Norm(final)=13.029 | 4766.3 samples/s | 74.5 steps/s
[Step=96950 Epoch=922.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.133 | L2-Norm(final)=13.030 | 2292.5 samples/s | 35.8 steps/s
[Step=97000 Epoch=922.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.127 | L2-Norm(final)=13.031 | 4305.9 samples/s | 67.3 steps/s
[Step=97050 Epoch=923.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.120 | L2-Norm(final)=13.032 | 2374.6 samples/s | 37.1 steps/s
[Step=97100 Epoch=923.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.114 | L2-Norm(final)=13.033 | 4181.5 samples/s | 65.3 steps/s
[Step=97150 Epoch=924.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.107 | L2-Norm(final)=13.034 | 2412.7 samples/s | 37.7 steps/s
[Step=97200 Epoch=924.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.100 | L2-Norm(final)=13.035 | 4408.7 samples/s | 68.9 steps/s
[Step=97250 Epoch=925.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.093 | L2-Norm(final)=13.036 | 2365.7 samples/s | 37.0 steps/s
[Step=97300 Epoch=925.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.086 | L2-Norm(final)=13.036 | 4169.7 samples/s | 65.2 steps/s
[Step=97350 Epoch=926.0] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.079 | L2-Norm(final)=13.037 | 2489.3 samples/s | 38.9 steps/s
[Step=97400 Epoch=926.5] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.072 | L2-Norm(final)=13.038 | 4021.0 samples/s | 62.8 steps/s
[Step=97450 Epoch=927.0] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.065 | L2-Norm(final)=13.039 | 6529.0 samples/s | 102.0 steps/s
[Step=97500 Epoch=927.5] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.058 | L2-Norm(final)=13.040 | 1982.7 samples/s | 31.0 steps/s
[Step=97550 Epoch=927.9] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.051 | L2-Norm(final)=13.041 | 5924.3 samples/s | 92.6 steps/s
[Step=97600 Epoch=928.4] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.043 | L2-Norm(final)=13.042 | 2064.8 samples/s | 32.3 steps/s
[Step=97650 Epoch=928.9] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.036 | L2-Norm(final)=13.044 | 5299.9 samples/s | 82.8 steps/s
[Step=97700 Epoch=929.4] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.028 | L2-Norm(final)=13.045 | 2190.0 samples/s | 34.2 steps/s
[Step=97750 Epoch=929.8] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.020 | L2-Norm(final)=13.046 | 4723.0 samples/s | 73.8 steps/s
[Step=97800 Epoch=930.3] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.013 | L2-Norm(final)=13.047 | 2243.9 samples/s | 35.1 steps/s
[Step=97850 Epoch=930.8] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.005 | L2-Norm(final)=13.048 | 4429.1 samples/s | 69.2 steps/s
[Step=97900 Epoch=931.3] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.997 | L2-Norm(final)=13.049 | 2301.4 samples/s | 36.0 steps/s
[Step=97950 Epoch=931.7] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.989 | L2-Norm(final)=13.050 | 4251.9 samples/s | 66.4 steps/s
[Step=98000 Epoch=932.2] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.981 | L2-Norm(final)=13.051 | 2408.2 samples/s | 37.6 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step98000.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=916.8] | Loss=0.00004 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.157 | L2-Norm(final)=12.282 | 5175.9 samples/s | 80.9 steps/s
[Step=96050 Epoch=917.2] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.158 | L2-Norm(final)=12.290 | 4172.9 samples/s | 65.2 steps/s
[Step=96100 Epoch=917.7] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.162 | L2-Norm(final)=12.298 | 7510.6 samples/s | 117.4 steps/s
[Step=96150 Epoch=918.2] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.165 | L2-Norm(final)=12.306 | 2114.8 samples/s | 33.0 steps/s
[Step=96200 Epoch=918.7] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.167 | L2-Norm(final)=12.313 | 6906.4 samples/s | 107.9 steps/s
[Step=96250 Epoch=919.1] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.169 | L2-Norm(final)=12.320 | 2186.1 samples/s | 34.2 steps/s
[Step=96300 Epoch=919.6] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.172 | L2-Norm(final)=12.326 | 6242.0 samples/s | 97.5 steps/s
[Step=96350 Epoch=920.1] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.174 | L2-Norm(final)=12.332 | 2258.1 samples/s | 35.3 steps/s
[Step=96400 Epoch=920.6] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.175 | L2-Norm(final)=12.338 | 5630.7 samples/s | 88.0 steps/s
[Step=96450 Epoch=921.0] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.177 | L2-Norm(final)=12.344 | 2342.7 samples/s | 36.6 steps/s
[Step=96500 Epoch=921.5] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.179 | L2-Norm(final)=12.349 | 5200.1 samples/s | 81.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=921.5] | Loss=0.00003 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.195 | L2-Norm(final)=12.404 | 5162.9 samples/s | 80.7 steps/s
[Step=96550 Epoch=922.0] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.194 | L2-Norm(final)=12.407 | 3908.0 samples/s | 61.1 steps/s
[Step=96600 Epoch=922.5] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.192 | L2-Norm(final)=12.411 | 6215.1 samples/s | 97.1 steps/s
[Step=96650 Epoch=922.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.187 | L2-Norm(final)=12.414 | 2008.0 samples/s | 31.4 steps/s
[Step=96700 Epoch=923.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.182 | L2-Norm(final)=12.416 | 5753.3 samples/s | 89.9 steps/s
[Step=96750 Epoch=923.9] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.175 | L2-Norm(final)=12.417 | 2078.8 samples/s | 32.5 steps/s
[Step=96800 Epoch=924.4] | Loss=0.00001 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.168 | L2-Norm(final)=12.418 | 5246.3 samples/s | 82.0 steps/s
[Step=96850 Epoch=924.9] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.160 | L2-Norm(final)=12.419 | 2147.2 samples/s | 33.5 steps/s
[Step=96900 Epoch=925.3] | Loss=0.00000 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.153 | L2-Norm(final)=12.421 | 4864.3 samples/s | 76.0 steps/s
[Step=96950 Epoch=925.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.145 | L2-Norm(final)=12.422 | 2220.3 samples/s | 34.7 steps/s
[Step=97000 Epoch=926.3] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.137 | L2-Norm(final)=12.423 | 4650.9 samples/s | 72.7 steps/s
[Step=97050 Epoch=926.8] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.128 | L2-Norm(final)=12.424 | 2265.7 samples/s | 35.4 steps/s
[Step=97100 Epoch=927.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.120 | L2-Norm(final)=12.425 | 4327.6 samples/s | 67.6 steps/s
[Step=97150 Epoch=927.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.112 | L2-Norm(final)=12.426 | 2341.3 samples/s | 36.6 steps/s
[Step=97200 Epoch=928.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.103 | L2-Norm(final)=12.427 | 4227.6 samples/s | 66.1 steps/s
[Step=97250 Epoch=928.7] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.095 | L2-Norm(final)=12.428 | 2376.5 samples/s | 37.1 steps/s
[Step=97300 Epoch=929.2] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.086 | L2-Norm(final)=12.429 | 4323.2 samples/s | 67.5 steps/s
[Step=97350 Epoch=929.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.077 | L2-Norm(final)=12.430 | 2359.7 samples/s | 36.9 steps/s
[Step=97400 Epoch=930.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.068 | L2-Norm(final)=12.431 | 4251.7 samples/s | 66.4 steps/s
[Step=97450 Epoch=930.6] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.060 | L2-Norm(final)=12.432 | 2413.1 samples/s | 37.7 steps/s
[Step=97500 Epoch=931.1] | Loss=0.00000 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.051 | L2-Norm(final)=12.433 | 4121.3 samples/s | 64.4 steps/s
[Step=97550 Epoch=931.5] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.041 | L2-Norm(final)=12.434 | 6808.4 samples/s | 106.4 steps/s
[Step=97600 Epoch=932.0] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.032 | L2-Norm(final)=12.435 | 1964.0 samples/s | 30.7 steps/s
[Step=97650 Epoch=932.5] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.023 | L2-Norm(final)=12.436 | 6153.0 samples/s | 96.1 steps/s
[Step=97700 Epoch=933.0] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.014 | L2-Norm(final)=12.437 | 2002.4 samples/s | 31.3 steps/s
[Step=97750 Epoch=933.5] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=5.004 | L2-Norm(final)=12.438 | 5773.9 samples/s | 90.2 steps/s
[Step=97800 Epoch=933.9] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.995 | L2-Norm(final)=12.440 | 2094.2 samples/s | 32.7 steps/s
[Step=97850 Epoch=934.4] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.986 | L2-Norm(final)=12.441 | 5290.5 samples/s | 82.7 steps/s
[Step=97900 Epoch=934.9] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.976 | L2-Norm(final)=12.442 | 2123.4 samples/s | 33.2 steps/s
[Step=97950 Epoch=935.4] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.967 | L2-Norm(final)=12.444 | 5007.7 samples/s | 78.2 steps/s
[Step=98000 Epoch=935.8] | Loss=0.00000 | Reg=0.00025 | acc=1.0000 | L2-Norm=4.957 | L2-Norm(final)=12.445 | 2187.1 samples/s | 34.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step98000.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=904.6] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.496 | L2-Norm(final)=11.869 | 5180.5 samples/s | 80.9 steps/s
[Step=96050 Epoch=905.1] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.496 | L2-Norm(final)=11.870 | 4174.3 samples/s | 65.2 steps/s
[Step=96100 Epoch=905.5] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.871 | 7304.4 samples/s | 114.1 steps/s
[Step=96150 Epoch=906.0] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.873 | 2137.8 samples/s | 33.4 steps/s
[Step=96200 Epoch=906.5] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.498 | L2-Norm(final)=11.875 | 6437.2 samples/s | 100.6 steps/s
[Step=96250 Epoch=906.9] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.499 | L2-Norm(final)=11.876 | 2216.3 samples/s | 34.6 steps/s
[Step=96300 Epoch=907.4] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.499 | L2-Norm(final)=11.878 | 5670.1 samples/s | 88.6 steps/s
[Step=96350 Epoch=907.9] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.500 | L2-Norm(final)=11.880 | 2355.9 samples/s | 36.8 steps/s
[Step=96400 Epoch=908.4] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.500 | L2-Norm(final)=11.881 | 5055.7 samples/s | 79.0 steps/s
[Step=96450 Epoch=908.8] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=11.883 | 2476.5 samples/s | 38.7 steps/s
[Step=96500 Epoch=909.3] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=11.885 | 4749.1 samples/s | 74.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=909.3] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.506 | L2-Norm(final)=11.902 | 5334.2 samples/s | 83.3 steps/s
[Step=96550 Epoch=909.8] | Loss=0.00004 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.903 | 3698.4 samples/s | 57.8 steps/s
[Step=96600 Epoch=910.2] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.905 | 6252.4 samples/s | 97.7 steps/s
[Step=96650 Epoch=910.7] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.906 | 2029.5 samples/s | 31.7 steps/s
[Step=96700 Epoch=911.2] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.907 | 5424.6 samples/s | 84.8 steps/s
[Step=96750 Epoch=911.7] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.909 | 2108.7 samples/s | 32.9 steps/s
[Step=96800 Epoch=912.1] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.910 | 4955.9 samples/s | 77.4 steps/s
[Step=96850 Epoch=912.6] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.507 | L2-Norm(final)=11.911 | 2247.3 samples/s | 35.1 steps/s
[Step=96900 Epoch=913.1] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.506 | L2-Norm(final)=11.912 | 4377.1 samples/s | 68.4 steps/s
[Step=96950 Epoch=913.5] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.506 | L2-Norm(final)=11.912 | 2335.4 samples/s | 36.5 steps/s
[Step=97000 Epoch=914.0] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.505 | L2-Norm(final)=11.913 | 4234.3 samples/s | 66.2 steps/s
[Step=97050 Epoch=914.5] | Loss=0.00002 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.505 | L2-Norm(final)=11.914 | 2393.8 samples/s | 37.4 steps/s
[Step=97100 Epoch=915.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.504 | L2-Norm(final)=11.915 | 4225.8 samples/s | 66.0 steps/s
[Step=97150 Epoch=915.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.504 | L2-Norm(final)=11.916 | 2398.2 samples/s | 37.5 steps/s
[Step=97200 Epoch=915.9] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=11.917 | 4307.0 samples/s | 67.3 steps/s
[Step=97250 Epoch=916.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.503 | L2-Norm(final)=11.917 | 2530.3 samples/s | 39.5 steps/s
[Step=97300 Epoch=916.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.502 | L2-Norm(final)=11.918 | 3757.5 samples/s | 58.7 steps/s
[Step=97350 Epoch=917.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.501 | L2-Norm(final)=11.919 | 6359.4 samples/s | 99.4 steps/s
[Step=97400 Epoch=917.8] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.500 | L2-Norm(final)=11.919 | 2007.4 samples/s | 31.4 steps/s
[Step=97450 Epoch=918.3] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.500 | L2-Norm(final)=11.920 | 5507.0 samples/s | 86.0 steps/s
[Step=97500 Epoch=918.7] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.499 | L2-Norm(final)=11.921 | 2144.7 samples/s | 33.5 steps/s
[Step=97550 Epoch=919.2] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.498 | L2-Norm(final)=11.921 | 4822.0 samples/s | 75.3 steps/s
[Step=97600 Epoch=919.7] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=11.922 | 2208.4 samples/s | 34.5 steps/s
[Step=97650 Epoch=920.1] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.496 | L2-Norm(final)=11.923 | 4451.9 samples/s | 69.6 steps/s
[Step=97700 Epoch=920.6] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.495 | L2-Norm(final)=11.923 | 2299.8 samples/s | 35.9 steps/s
[Step=97750 Epoch=921.1] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.494 | L2-Norm(final)=11.924 | 4211.5 samples/s | 65.8 steps/s
[Step=97800 Epoch=921.6] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.493 | L2-Norm(final)=11.925 | 2392.8 samples/s | 37.4 steps/s
[Step=97850 Epoch=922.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.492 | L2-Norm(final)=11.925 | 4259.8 samples/s | 66.6 steps/s
[Step=97900 Epoch=922.5] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.491 | L2-Norm(final)=11.926 | 2390.8 samples/s | 37.4 steps/s
[Step=97950 Epoch=923.0] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.490 | L2-Norm(final)=11.927 | 4264.3 samples/s | 66.6 steps/s
[Step=98000 Epoch=923.4] | Loss=0.00001 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.489 | L2-Norm(final)=11.927 | 2639.2 samples/s | 41.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step98000.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=915.0] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.359 | L2-Norm(final)=12.664 | 4978.4 samples/s | 77.8 steps/s
[Step=96050 Epoch=915.4] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.360 | L2-Norm(final)=12.666 | 4249.8 samples/s | 66.4 steps/s
[Step=96100 Epoch=915.9] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.362 | L2-Norm(final)=12.669 | 7232.9 samples/s | 113.0 steps/s
[Step=96150 Epoch=916.4] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.363 | L2-Norm(final)=12.672 | 2136.6 samples/s | 33.4 steps/s
[Step=96200 Epoch=916.9] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.364 | L2-Norm(final)=12.675 | 6766.2 samples/s | 105.7 steps/s
[Step=96250 Epoch=917.3] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.365 | L2-Norm(final)=12.678 | 2175.7 samples/s | 34.0 steps/s
[Step=96300 Epoch=917.8] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.366 | L2-Norm(final)=12.681 | 6190.9 samples/s | 96.7 steps/s
[Step=96350 Epoch=918.3] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.367 | L2-Norm(final)=12.684 | 2265.9 samples/s | 35.4 steps/s
[Step=96400 Epoch=918.8] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.368 | L2-Norm(final)=12.687 | 5694.1 samples/s | 89.0 steps/s
[Step=96450 Epoch=919.3] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.369 | L2-Norm(final)=12.690 | 2339.8 samples/s | 36.6 steps/s
[Step=96500 Epoch=919.7] | Loss=0.00004 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.370 | L2-Norm(final)=12.694 | 5259.4 samples/s | 82.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=919.7] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.381 | L2-Norm(final)=12.725 | 5608.8 samples/s | 87.6 steps/s
[Step=96550 Epoch=920.2] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.382 | L2-Norm(final)=12.728 | 3777.4 samples/s | 59.0 steps/s
[Step=96600 Epoch=920.7] | Loss=0.00003 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.382 | L2-Norm(final)=12.730 | 6287.1 samples/s | 98.2 steps/s
[Step=96650 Epoch=921.2] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.383 | L2-Norm(final)=12.732 | 2016.4 samples/s | 31.5 steps/s
[Step=96700 Epoch=921.6] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.382 | L2-Norm(final)=12.734 | 5717.5 samples/s | 89.3 steps/s
[Step=96750 Epoch=922.1] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.382 | L2-Norm(final)=12.736 | 2055.3 samples/s | 32.1 steps/s
[Step=96800 Epoch=922.6] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.381 | L2-Norm(final)=12.737 | 5378.5 samples/s | 84.0 steps/s
[Step=96850 Epoch=923.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.380 | L2-Norm(final)=12.738 | 2126.7 samples/s | 33.2 steps/s
[Step=96900 Epoch=923.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.379 | L2-Norm(final)=12.740 | 4946.5 samples/s | 77.3 steps/s
[Step=96950 Epoch=924.0] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.378 | L2-Norm(final)=12.741 | 2201.9 samples/s | 34.4 steps/s
[Step=97000 Epoch=924.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.376 | L2-Norm(final)=12.742 | 4651.6 samples/s | 72.7 steps/s
[Step=97050 Epoch=925.0] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.375 | L2-Norm(final)=12.743 | 2257.5 samples/s | 35.3 steps/s
[Step=97100 Epoch=925.5] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.374 | L2-Norm(final)=12.744 | 4324.7 samples/s | 67.6 steps/s
[Step=97150 Epoch=925.9] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.372 | L2-Norm(final)=12.745 | 2377.4 samples/s | 37.1 steps/s
[Step=97200 Epoch=926.4] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.371 | L2-Norm(final)=12.746 | 4117.0 samples/s | 64.3 steps/s
[Step=97250 Epoch=926.9] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.369 | L2-Norm(final)=12.746 | 2383.0 samples/s | 37.2 steps/s
[Step=97300 Epoch=927.4] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.367 | L2-Norm(final)=12.747 | 4326.2 samples/s | 67.6 steps/s
[Step=97350 Epoch=927.8] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.365 | L2-Norm(final)=12.748 | 2315.1 samples/s | 36.2 steps/s
[Step=97400 Epoch=928.3] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.363 | L2-Norm(final)=12.749 | 4135.6 samples/s | 64.6 steps/s
[Step=97450 Epoch=928.8] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.362 | L2-Norm(final)=12.750 | 2351.8 samples/s | 36.7 steps/s
[Step=97500 Epoch=929.3] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.360 | L2-Norm(final)=12.750 | 4246.7 samples/s | 66.4 steps/s
[Step=97550 Epoch=929.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.358 | L2-Norm(final)=12.751 | 6896.5 samples/s | 107.8 steps/s
[Step=97600 Epoch=930.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.355 | L2-Norm(final)=12.752 | 1893.2 samples/s | 29.6 steps/s
[Step=97650 Epoch=930.7] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.353 | L2-Norm(final)=12.753 | 5922.9 samples/s | 92.5 steps/s
[Step=97700 Epoch=931.2] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.351 | L2-Norm(final)=12.754 | 1903.7 samples/s | 29.7 steps/s
[Step=97750 Epoch=931.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.349 | L2-Norm(final)=12.754 | 5750.3 samples/s | 89.8 steps/s
[Step=97800 Epoch=932.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.347 | L2-Norm(final)=12.755 | 2029.0 samples/s | 31.7 steps/s
[Step=97850 Epoch=932.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.344 | L2-Norm(final)=12.756 | 5311.3 samples/s | 83.0 steps/s
[Step=97900 Epoch=933.1] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.342 | L2-Norm(final)=12.756 | 2100.6 samples/s | 32.8 steps/s
[Step=97950 Epoch=933.6] | Loss=0.00001 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.340 | L2-Norm(final)=12.757 | 4880.6 samples/s | 76.3 steps/s
[Step=98000 Epoch=934.0] | Loss=0.00001 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.337 | L2-Norm(final)=12.758 | 2166.0 samples/s | 33.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.09955 | acc=0.9566 | tpr=0.9725 | fpr=0.0778 | 4530.1 samples/s | 17.7 steps/s
Avg test loss: 0.10423, Avg test acc: 0.95408, Avg tpr: 0.97092, Avg fpr: 0.08294, total FA: 647

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.10535 | acc=0.9562 | tpr=0.9704 | fpr=0.0748 | 4742.2 samples/s | 18.5 steps/s
Avg test loss: 0.10586, Avg test acc: 0.95617, Avg tpr: 0.97039, Avg fpr: 0.07512, total FA: 586

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.10076 | acc=0.9552 | tpr=0.9634 | fpr=0.0627 | 4659.6 samples/s | 18.2 steps/s
Avg test loss: 0.10361, Avg test acc: 0.95316, Avg tpr: 0.96072, Avg fpr: 0.06345, total FA: 495

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.09497 | acc=0.9573 | tpr=0.9718 | fpr=0.0743 | 4638.0 samples/s | 18.1 steps/s
Avg test loss: 0.10102, Avg test acc: 0.95520, Avg tpr: 0.97150, Avg fpr: 0.08063, total FA: 629

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.10370 | acc=0.9538 | tpr=0.9639 | fpr=0.0681 | 4725.2 samples/s | 18.5 steps/s
Avg test loss: 0.10891, Avg test acc: 0.95220, Avg tpr: 0.96311, Avg fpr: 0.07179, total FA: 560

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.73392 | acc=0.3035 | tpr=0.0058 | fpr=0.0500 | 4732.6 samples/s | 18.5 steps/s
Avg test loss: 5.74023, Avg test acc: 0.30223, Avg tpr: 0.00729, Avg fpr: 0.04910, total FA: 383

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.80969 | acc=0.3056 | tpr=0.0042 | fpr=0.0399 | 4728.0 samples/s | 18.5 steps/s
Avg test loss: 4.82625, Avg test acc: 0.30243, Avg tpr: 0.00414, Avg fpr: 0.04153, total FA: 324

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.14751 | acc=0.2996 | tpr=0.0041 | fpr=0.0587 | 4737.6 samples/s | 18.5 steps/s
Avg test loss: 5.15401, Avg test acc: 0.29762, Avg tpr: 0.00501, Avg fpr: 0.05884, total FA: 459

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.68208 | acc=0.3014 | tpr=0.0115 | fpr=0.0691 | 4800.7 samples/s | 18.8 steps/s
Avg test loss: 5.68262, Avg test acc: 0.30022, Avg tpr: 0.01329, Avg fpr: 0.06871, total FA: 536

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=5.24476 | acc=0.3039 | tpr=0.0089 | fpr=0.0555 | 4826.1 samples/s | 18.9 steps/s
Avg test loss: 5.25217, Avg test acc: 0.30187, Avg tpr: 0.00973, Avg fpr: 0.05563, total FA: 434

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.84870 | acc=0.1043 | tpr=0.5487 | fpr=0.9037 | 4694.9 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.82020 | acc=0.1056 | tpr=0.5330 | fpr=0.9024 | 7223.3 samples/s | 28.2 steps/s
[Step= 150] | Loss=5.83385 | acc=0.1064 | tpr=0.5331 | fpr=0.9014 | 7940.8 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.82545 | acc=0.1061 | tpr=0.5246 | fpr=0.9015 | 7709.1 samples/s | 30.1 steps/s
[Step= 250] | Loss=5.82943 | acc=0.1070 | tpr=0.5345 | fpr=0.9008 | 8069.2 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.82626 | acc=0.1069 | tpr=0.5433 | fpr=0.9011 | 7828.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=5.81843 | acc=0.1067 | tpr=0.5348 | fpr=0.9011 | 7556.7 samples/s | 29.5 steps/s
[Step= 400] | Loss=5.81790 | acc=0.1063 | tpr=0.5317 | fpr=0.9014 | 7833.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.82348 | acc=0.1067 | tpr=0.5302 | fpr=0.9010 | 8183.6 samples/s | 32.0 steps/s
[Step= 500] | Loss=5.82601 | acc=0.1068 | tpr=0.5260 | fpr=0.9008 | 7575.2 samples/s | 29.6 steps/s
[Step= 550] | Loss=5.82931 | acc=0.1065 | tpr=0.5225 | fpr=0.9011 | 13897.6 samples/s | 54.3 steps/s
Avg test loss: 5.83090, Avg test acc: 0.10639, Avg tpr: 0.52258, Avg fpr: 0.90117, total FA: 125126

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.50873 | acc=0.0961 | tpr=0.4027 | fpr=0.9094 | 4646.1 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.49671 | acc=0.0964 | tpr=0.4179 | fpr=0.9096 | 7236.1 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.49868 | acc=0.0969 | tpr=0.4135 | fpr=0.9089 | 8006.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.49312 | acc=0.0966 | tpr=0.3978 | fpr=0.9089 | 7780.3 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.49817 | acc=0.0969 | tpr=0.4052 | fpr=0.9087 | 7594.7 samples/s | 29.7 steps/s
[Step= 300] | Loss=5.49467 | acc=0.0967 | tpr=0.4138 | fpr=0.9091 | 8008.4 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.48885 | acc=0.0968 | tpr=0.4064 | fpr=0.9089 | 7660.2 samples/s | 29.9 steps/s
[Step= 400] | Loss=5.48591 | acc=0.0967 | tpr=0.4043 | fpr=0.9089 | 7914.2 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.49117 | acc=0.0969 | tpr=0.4056 | fpr=0.9087 | 7980.2 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.49596 | acc=0.0971 | tpr=0.4000 | fpr=0.9084 | 7251.3 samples/s | 28.3 steps/s
[Step= 550] | Loss=5.50261 | acc=0.0965 | tpr=0.3995 | fpr=0.9090 | 15190.2 samples/s | 59.3 steps/s
Avg test loss: 5.50476, Avg test acc: 0.09651, Avg tpr: 0.40016, Avg fpr: 0.90901, total FA: 126214

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=5.19637 | acc=0.1178 | tpr=0.2035 | fpr=0.8837 | 4713.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=5.16546 | acc=0.1197 | tpr=0.2175 | fpr=0.8821 | 7182.8 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.18001 | acc=0.1201 | tpr=0.2205 | fpr=0.8817 | 7707.4 samples/s | 30.1 steps/s
[Step= 200] | Loss=5.17029 | acc=0.1209 | tpr=0.2077 | fpr=0.8807 | 8407.1 samples/s | 32.8 steps/s
[Step= 250] | Loss=5.17323 | acc=0.1213 | tpr=0.2166 | fpr=0.8804 | 7479.0 samples/s | 29.2 steps/s
[Step= 300] | Loss=5.17047 | acc=0.1213 | tpr=0.2269 | fpr=0.8806 | 7533.0 samples/s | 29.4 steps/s
[Step= 350] | Loss=5.16488 | acc=0.1214 | tpr=0.2223 | fpr=0.8805 | 7977.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.16419 | acc=0.1213 | tpr=0.2221 | fpr=0.8805 | 7965.2 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.17005 | acc=0.1213 | tpr=0.2181 | fpr=0.8804 | 7980.5 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.17121 | acc=0.1215 | tpr=0.2185 | fpr=0.8803 | 7727.3 samples/s | 30.2 steps/s
[Step= 550] | Loss=5.17425 | acc=0.1212 | tpr=0.2205 | fpr=0.8806 | 14235.9 samples/s | 55.6 steps/s
Avg test loss: 5.17546, Avg test acc: 0.12104, Avg tpr: 0.22108, Avg fpr: 0.88078, total FA: 122295

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=5.62227 | acc=0.1043 | tpr=0.4735 | fpr=0.9023 | 4605.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=5.59200 | acc=0.1045 | tpr=0.4670 | fpr=0.9023 | 7136.4 samples/s | 27.9 steps/s
[Step= 150] | Loss=5.60609 | acc=0.1039 | tpr=0.4741 | fpr=0.9029 | 7952.5 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.59831 | acc=0.1033 | tpr=0.4656 | fpr=0.9033 | 7396.0 samples/s | 28.9 steps/s
[Step= 250] | Loss=5.60413 | acc=0.1041 | tpr=0.4734 | fpr=0.9026 | 7641.6 samples/s | 29.9 steps/s
[Step= 300] | Loss=5.60341 | acc=0.1043 | tpr=0.4822 | fpr=0.9026 | 7933.3 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.59499 | acc=0.1047 | tpr=0.4796 | fpr=0.9022 | 7896.8 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.59318 | acc=0.1047 | tpr=0.4776 | fpr=0.9021 | 7995.2 samples/s | 31.2 steps/s
[Step= 450] | Loss=5.59810 | acc=0.1045 | tpr=0.4747 | fpr=0.9022 | 7595.6 samples/s | 29.7 steps/s
[Step= 500] | Loss=5.59941 | acc=0.1046 | tpr=0.4722 | fpr=0.9021 | 7827.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.60468 | acc=0.1041 | tpr=0.4676 | fpr=0.9025 | 14403.3 samples/s | 56.3 steps/s
Avg test loss: 5.60599, Avg test acc: 0.10404, Avg tpr: 0.46791, Avg fpr: 0.90258, total FA: 125321

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=5.52022 | acc=0.1256 | tpr=0.4336 | fpr=0.8799 | 4903.3 samples/s | 19.2 steps/s
[Step= 100] | Loss=5.49893 | acc=0.1293 | tpr=0.4392 | fpr=0.8764 | 6865.8 samples/s | 26.8 steps/s
[Step= 150] | Loss=5.50066 | acc=0.1291 | tpr=0.4323 | fpr=0.8764 | 7794.3 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.49411 | acc=0.1285 | tpr=0.4219 | fpr=0.8768 | 7869.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.49582 | acc=0.1292 | tpr=0.4323 | fpr=0.8764 | 7671.5 samples/s | 30.0 steps/s
[Step= 300] | Loss=5.49810 | acc=0.1290 | tpr=0.4356 | fpr=0.8766 | 8206.4 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.48984 | acc=0.1296 | tpr=0.4364 | fpr=0.8760 | 7800.9 samples/s | 30.5 steps/s
[Step= 400] | Loss=5.49059 | acc=0.1289 | tpr=0.4316 | fpr=0.8766 | 7599.1 samples/s | 29.7 steps/s
[Step= 450] | Loss=5.49660 | acc=0.1290 | tpr=0.4328 | fpr=0.8765 | 7960.2 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.49970 | acc=0.1287 | tpr=0.4295 | fpr=0.8767 | 7839.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.50422 | acc=0.1285 | tpr=0.4302 | fpr=0.8770 | 14348.6 samples/s | 56.0 steps/s
Avg test loss: 5.50635, Avg test acc: 0.12834, Avg tpr: 0.42948, Avg fpr: 0.87714, total FA: 121789

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08876 | acc=0.9823 | tpr=0.9602 | fpr=0.0173 | 4843.7 samples/s | 18.9 steps/s
[Step= 100] | Loss=0.08997 | acc=0.9825 | tpr=0.9574 | fpr=0.0171 | 7158.0 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.09349 | acc=0.9816 | tpr=0.9597 | fpr=0.0180 | 7308.4 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.09553 | acc=0.9818 | tpr=0.9639 | fpr=0.0179 | 8029.5 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.09433 | acc=0.9820 | tpr=0.9598 | fpr=0.0176 | 8105.8 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.09634 | acc=0.9817 | tpr=0.9593 | fpr=0.0179 | 7565.2 samples/s | 29.6 steps/s
[Step= 350] | Loss=0.09728 | acc=0.9814 | tpr=0.9606 | fpr=0.0182 | 8096.2 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.09822 | acc=0.9811 | tpr=0.9568 | fpr=0.0185 | 8112.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.10038 | acc=0.9806 | tpr=0.9533 | fpr=0.0189 | 7678.6 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.09975 | acc=0.9807 | tpr=0.9533 | fpr=0.0188 | 7739.9 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.09910 | acc=0.9808 | tpr=0.9526 | fpr=0.0187 | 14311.5 samples/s | 55.9 steps/s
Avg test loss: 0.09897, Avg test acc: 0.98084, Avg tpr: 0.95285, Avg fpr: 0.01865, total FA: 2590

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08453 | acc=0.9821 | tpr=0.9336 | fpr=0.0170 | 4950.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.08699 | acc=0.9822 | tpr=0.9339 | fpr=0.0169 | 6529.5 samples/s | 25.5 steps/s
[Step= 150] | Loss=0.09048 | acc=0.9817 | tpr=0.9337 | fpr=0.0174 | 8264.2 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.09264 | acc=0.9819 | tpr=0.9421 | fpr=0.0174 | 7729.1 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.09129 | acc=0.9821 | tpr=0.9415 | fpr=0.0172 | 8261.9 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.09318 | acc=0.9818 | tpr=0.9404 | fpr=0.0175 | 7555.0 samples/s | 29.5 steps/s
[Step= 350] | Loss=0.09378 | acc=0.9815 | tpr=0.9405 | fpr=0.0177 | 7491.7 samples/s | 29.3 steps/s
[Step= 400] | Loss=0.09480 | acc=0.9813 | tpr=0.9349 | fpr=0.0178 | 8074.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.09687 | acc=0.9811 | tpr=0.9333 | fpr=0.0180 | 7879.8 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.09625 | acc=0.9811 | tpr=0.9348 | fpr=0.0180 | 8242.5 samples/s | 32.2 steps/s
[Step= 550] | Loss=0.09586 | acc=0.9813 | tpr=0.9335 | fpr=0.0178 | 13386.9 samples/s | 52.3 steps/s
Avg test loss: 0.09575, Avg test acc: 0.98129, Avg tpr: 0.93384, Avg fpr: 0.01785, total FA: 2478

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08011 | acc=0.9811 | tpr=0.9690 | fpr=0.0187 | 4910.6 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.08204 | acc=0.9809 | tpr=0.9723 | fpr=0.0189 | 7159.8 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.08592 | acc=0.9802 | tpr=0.9683 | fpr=0.0196 | 7221.2 samples/s | 28.2 steps/s
[Step= 200] | Loss=0.08726 | acc=0.9806 | tpr=0.9727 | fpr=0.0193 | 8062.5 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.08624 | acc=0.9807 | tpr=0.9721 | fpr=0.0191 | 7875.8 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.08812 | acc=0.9804 | tpr=0.9687 | fpr=0.0193 | 7937.0 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.08877 | acc=0.9802 | tpr=0.9687 | fpr=0.0196 | 7762.1 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.08972 | acc=0.9800 | tpr=0.9655 | fpr=0.0198 | 8013.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.09115 | acc=0.9798 | tpr=0.9635 | fpr=0.0199 | 7956.9 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.09072 | acc=0.9797 | tpr=0.9648 | fpr=0.0200 | 7550.6 samples/s | 29.5 steps/s
[Step= 550] | Loss=0.09027 | acc=0.9798 | tpr=0.9634 | fpr=0.0199 | 14366.1 samples/s | 56.1 steps/s
Avg test loss: 0.09017, Avg test acc: 0.97984, Avg tpr: 0.96315, Avg fpr: 0.01986, total FA: 2757

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09649 | acc=0.9802 | tpr=0.9646 | fpr=0.0196 | 4671.3 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.09778 | acc=0.9801 | tpr=0.9638 | fpr=0.0196 | 7513.5 samples/s | 29.3 steps/s
[Step= 150] | Loss=0.10186 | acc=0.9793 | tpr=0.9582 | fpr=0.0203 | 7298.0 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.10301 | acc=0.9795 | tpr=0.9617 | fpr=0.0201 | 8413.5 samples/s | 32.9 steps/s
[Step= 250] | Loss=0.10184 | acc=0.9798 | tpr=0.9607 | fpr=0.0198 | 7586.4 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.10403 | acc=0.9796 | tpr=0.9600 | fpr=0.0200 | 7926.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.10481 | acc=0.9794 | tpr=0.9599 | fpr=0.0203 | 8051.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.10530 | acc=0.9793 | tpr=0.9568 | fpr=0.0203 | 8024.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.10715 | acc=0.9790 | tpr=0.9537 | fpr=0.0205 | 7685.6 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.10639 | acc=0.9791 | tpr=0.9542 | fpr=0.0204 | 8151.5 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.10577 | acc=0.9793 | tpr=0.9546 | fpr=0.0202 | 13225.4 samples/s | 51.7 steps/s
Avg test loss: 0.10559, Avg test acc: 0.97935, Avg tpr: 0.95483, Avg fpr: 0.02020, total FA: 2805

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.09366 | acc=0.9823 | tpr=0.9558 | fpr=0.0173 | 4525.9 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.09704 | acc=0.9813 | tpr=0.9552 | fpr=0.0182 | 7398.7 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.10028 | acc=0.9802 | tpr=0.9510 | fpr=0.0193 | 8192.4 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.10180 | acc=0.9800 | tpr=0.9585 | fpr=0.0196 | 8001.5 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.10062 | acc=0.9801 | tpr=0.9546 | fpr=0.0194 | 7821.4 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.10255 | acc=0.9799 | tpr=0.9520 | fpr=0.0196 | 7922.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.10330 | acc=0.9797 | tpr=0.9530 | fpr=0.0198 | 7943.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.10456 | acc=0.9795 | tpr=0.9497 | fpr=0.0200 | 7588.4 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.10670 | acc=0.9792 | tpr=0.9469 | fpr=0.0202 | 7974.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.10618 | acc=0.9792 | tpr=0.9467 | fpr=0.0202 | 7970.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.10563 | acc=0.9795 | tpr=0.9467 | fpr=0.0200 | 13437.8 samples/s | 52.5 steps/s
Avg test loss: 0.10552, Avg test acc: 0.97944, Avg tpr: 0.94651, Avg fpr: 0.01996, total FA: 2771

server round 49/50

clients selected: [0 1 2 3 4 5 6 7 8 9]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=477.9] | Loss=0.00564 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=22.577 | 5250.5 samples/s | 82.0 steps/s
[Step=98050 Epoch=478.1] | Loss=0.00632 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=22.582 | 4529.3 samples/s | 70.8 steps/s
[Step=98100 Epoch=478.4] | Loss=0.00649 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=22.589 | 5087.8 samples/s | 79.5 steps/s
[Step=98150 Epoch=478.6] | Loss=0.00633 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=22.595 | 5053.0 samples/s | 79.0 steps/s
[Step=98200 Epoch=478.8] | Loss=0.00661 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=22.602 | 7639.8 samples/s | 119.4 steps/s
[Step=98250 Epoch=479.1] | Loss=0.00653 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=22.608 | 2207.4 samples/s | 34.5 steps/s
[Step=98300 Epoch=479.3] | Loss=0.00653 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=22.614 | 5049.3 samples/s | 78.9 steps/s
[Step=98350 Epoch=479.6] | Loss=0.00642 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=22.620 | 5082.5 samples/s | 79.4 steps/s
[Step=98400 Epoch=479.8] | Loss=0.00644 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=22.626 | 6889.9 samples/s | 107.7 steps/s
[Step=98450 Epoch=480.1] | Loss=0.00637 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=22.632 | 2305.7 samples/s | 36.0 steps/s
[Step=98500 Epoch=480.3] | Loss=0.00625 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.068 | L2-Norm(final)=22.637 | 5194.6 samples/s | 81.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_0/client_state-step98500.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=478.2] | Loss=0.00783 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=23.621 | 5478.6 samples/s | 85.6 steps/s
[Step=98050 Epoch=478.4] | Loss=0.00608 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=23.627 | 4279.1 samples/s | 66.9 steps/s
[Step=98100 Epoch=478.7] | Loss=0.00591 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=23.633 | 4949.2 samples/s | 77.3 steps/s
[Step=98150 Epoch=478.9] | Loss=0.00576 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.650 | L2-Norm(final)=23.640 | 5048.5 samples/s | 78.9 steps/s
[Step=98200 Epoch=479.2] | Loss=0.00561 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=23.647 | 7835.0 samples/s | 122.4 steps/s
[Step=98250 Epoch=479.4] | Loss=0.00552 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=23.654 | 2220.0 samples/s | 34.7 steps/s
[Step=98300 Epoch=479.7] | Loss=0.00546 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.656 | L2-Norm(final)=23.660 | 4896.8 samples/s | 76.5 steps/s
[Step=98350 Epoch=479.9] | Loss=0.00541 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=23.666 | 5117.1 samples/s | 80.0 steps/s
[Step=98400 Epoch=480.1] | Loss=0.00543 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=23.672 | 7047.7 samples/s | 110.1 steps/s
[Step=98450 Epoch=480.4] | Loss=0.00540 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=23.678 | 2230.8 samples/s | 34.9 steps/s
[Step=98500 Epoch=480.6] | Loss=0.00534 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=23.684 | 5003.3 samples/s | 78.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_1/client_state-step98500.h5

Train client 2: client_asml1_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=477.5] | Loss=0.00838 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=23.527 | 5230.7 samples/s | 81.7 steps/s
[Step=98050 Epoch=477.7] | Loss=0.00657 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.454 | L2-Norm(final)=23.532 | 4295.3 samples/s | 67.1 steps/s
[Step=98100 Epoch=478.0] | Loss=0.00615 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.457 | L2-Norm(final)=23.538 | 5060.2 samples/s | 79.1 steps/s
[Step=98150 Epoch=478.2] | Loss=0.00667 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.459 | L2-Norm(final)=23.545 | 5103.9 samples/s | 79.7 steps/s
[Step=98200 Epoch=478.5] | Loss=0.00640 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=23.551 | 7603.4 samples/s | 118.8 steps/s
[Step=98250 Epoch=478.7] | Loss=0.00629 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=23.557 | 2228.9 samples/s | 34.8 steps/s
[Step=98300 Epoch=479.0] | Loss=0.00623 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=23.563 | 4989.5 samples/s | 78.0 steps/s
[Step=98350 Epoch=479.2] | Loss=0.00624 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.467 | L2-Norm(final)=23.568 | 4953.9 samples/s | 77.4 steps/s
[Step=98400 Epoch=479.5] | Loss=0.00633 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.469 | L2-Norm(final)=23.574 | 6984.8 samples/s | 109.1 steps/s
[Step=98450 Epoch=479.7] | Loss=0.00624 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.471 | L2-Norm(final)=23.580 | 2293.9 samples/s | 35.8 steps/s
[Step=98500 Epoch=479.9] | Loss=0.00624 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.473 | L2-Norm(final)=23.585 | 5135.6 samples/s | 80.2 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_2/client_state-step98500.h5

Train client 3: client_asml1_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=477.9] | Loss=0.00857 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=23.577 | 5348.6 samples/s | 83.6 steps/s
[Step=98050 Epoch=478.1] | Loss=0.00653 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=23.582 | 4213.2 samples/s | 65.8 steps/s
[Step=98100 Epoch=478.4] | Loss=0.00606 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.142 | L2-Norm(final)=23.589 | 5023.2 samples/s | 78.5 steps/s
[Step=98150 Epoch=478.6] | Loss=0.00629 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=23.596 | 4948.6 samples/s | 77.3 steps/s
[Step=98200 Epoch=478.9] | Loss=0.00621 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=23.602 | 7878.7 samples/s | 123.1 steps/s
[Step=98250 Epoch=479.1] | Loss=0.00610 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=23.609 | 2218.2 samples/s | 34.7 steps/s
[Step=98300 Epoch=479.4] | Loss=0.00605 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=23.615 | 5110.2 samples/s | 79.8 steps/s
[Step=98350 Epoch=479.6] | Loss=0.00610 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.153 | L2-Norm(final)=23.621 | 5104.7 samples/s | 79.8 steps/s
[Step=98400 Epoch=479.9] | Loss=0.00611 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.155 | L2-Norm(final)=23.627 | 6664.9 samples/s | 104.1 steps/s
[Step=98450 Epoch=480.1] | Loss=0.00607 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=23.633 | 2323.6 samples/s | 36.3 steps/s
[Step=98500 Epoch=480.3] | Loss=0.00597 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=23.638 | 5022.8 samples/s | 78.5 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_3/client_state-step98500.h5

Train client 4: client_asml1_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=480.6] | Loss=0.00612 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=23.689 | 5433.0 samples/s | 84.9 steps/s
[Step=98050 Epoch=480.8] | Loss=0.00601 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.749 | L2-Norm(final)=23.694 | 4414.3 samples/s | 69.0 steps/s
[Step=98100 Epoch=481.1] | Loss=0.00571 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.751 | L2-Norm(final)=23.700 | 5077.9 samples/s | 79.3 steps/s
[Step=98150 Epoch=481.3] | Loss=0.00523 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.753 | L2-Norm(final)=23.706 | 4997.9 samples/s | 78.1 steps/s
[Step=98200 Epoch=481.6] | Loss=0.00541 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.756 | L2-Norm(final)=23.712 | 8117.7 samples/s | 126.8 steps/s
[Step=98250 Epoch=481.8] | Loss=0.00529 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.758 | L2-Norm(final)=23.718 | 2208.9 samples/s | 34.5 steps/s
[Step=98300 Epoch=482.0] | Loss=0.00521 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.760 | L2-Norm(final)=23.724 | 5037.2 samples/s | 78.7 steps/s
[Step=98350 Epoch=482.3] | Loss=0.00519 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=23.730 | 5042.2 samples/s | 78.8 steps/s
[Step=98400 Epoch=482.5] | Loss=0.00521 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=23.736 | 7131.9 samples/s | 111.4 steps/s
[Step=98450 Epoch=482.8] | Loss=0.00518 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.766 | L2-Norm(final)=23.741 | 2222.5 samples/s | 34.7 steps/s
[Step=98500 Epoch=483.0] | Loss=0.00512 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=23.747 | 5173.2 samples/s | 80.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_asml1_4/client_state-step98500.h5

Train client 5: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=928.6] | Loss=0.00001 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.126 | L2-Norm(final)=11.912 | 5360.0 samples/s | 83.8 steps/s
[Step=98050 Epoch=929.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.127 | L2-Norm(final)=11.917 | 4110.1 samples/s | 64.2 steps/s
[Step=98100 Epoch=929.6] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.129 | L2-Norm(final)=11.923 | 7458.8 samples/s | 116.5 steps/s
[Step=98150 Epoch=930.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.133 | L2-Norm(final)=11.931 | 2106.9 samples/s | 32.9 steps/s
[Step=98200 Epoch=930.5] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.136 | L2-Norm(final)=11.937 | 6528.4 samples/s | 102.0 steps/s
[Step=98250 Epoch=931.0] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.139 | L2-Norm(final)=11.943 | 2208.5 samples/s | 34.5 steps/s
[Step=98300 Epoch=931.5] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.141 | L2-Norm(final)=11.948 | 5963.7 samples/s | 93.2 steps/s
[Step=98350 Epoch=932.0] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.144 | L2-Norm(final)=11.953 | 2321.0 samples/s | 36.3 steps/s
[Step=98400 Epoch=932.4] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.146 | L2-Norm(final)=11.958 | 5379.3 samples/s | 84.1 steps/s
[Step=98450 Epoch=932.9] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.147 | L2-Norm(final)=11.963 | 2425.9 samples/s | 37.9 steps/s
[Step=98500 Epoch=933.4] | Loss=0.00002 | Reg=0.00027 | acc=1.0000 | L2-Norm=5.149 | L2-Norm(final)=11.968 | 4784.9 samples/s | 74.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_0/client_state-step98500.h5

Train client 6: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=932.2] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.060 | L2-Norm(final)=13.087 | 4932.3 samples/s | 77.1 steps/s
[Step=98050 Epoch=932.7] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.061 | L2-Norm(final)=13.095 | 4267.1 samples/s | 66.7 steps/s
[Step=98100 Epoch=933.2] | Loss=0.00004 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.068 | L2-Norm(final)=13.106 | 7586.2 samples/s | 118.5 steps/s
[Step=98150 Epoch=933.7] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.072 | L2-Norm(final)=13.115 | 2168.1 samples/s | 33.9 steps/s
[Step=98200 Epoch=934.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.076 | L2-Norm(final)=13.122 | 6405.8 samples/s | 100.1 steps/s
[Step=98250 Epoch=934.6] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.079 | L2-Norm(final)=13.129 | 2239.8 samples/s | 35.0 steps/s
[Step=98300 Epoch=935.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.081 | L2-Norm(final)=13.134 | 5680.6 samples/s | 88.8 steps/s
[Step=98350 Epoch=935.6] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.083 | L2-Norm(final)=13.140 | 2291.6 samples/s | 35.8 steps/s
[Step=98400 Epoch=936.0] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.085 | L2-Norm(final)=13.146 | 5399.6 samples/s | 84.4 steps/s
[Step=98450 Epoch=936.5] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.087 | L2-Norm(final)=13.151 | 2452.9 samples/s | 38.3 steps/s
[Step=98500 Epoch=937.0] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.089 | L2-Norm(final)=13.156 | 4654.0 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_1/client_state-step98500.h5

Train client 7: client_iccad2012_2
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=935.8] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.062 | L2-Norm(final)=12.485 | 5159.6 samples/s | 80.6 steps/s
[Step=98050 Epoch=936.3] | Loss=0.00005 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.065 | L2-Norm(final)=12.498 | 4120.0 samples/s | 64.4 steps/s
[Step=98100 Epoch=936.8] | Loss=0.00005 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.072 | L2-Norm(final)=12.510 | 7476.4 samples/s | 116.8 steps/s
[Step=98150 Epoch=937.3] | Loss=0.00004 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.077 | L2-Norm(final)=12.518 | 2142.1 samples/s | 33.5 steps/s
[Step=98200 Epoch=937.7] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.080 | L2-Norm(final)=12.525 | 6620.6 samples/s | 103.4 steps/s
[Step=98250 Epoch=938.2] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.083 | L2-Norm(final)=12.531 | 2191.4 samples/s | 34.2 steps/s
[Step=98300 Epoch=938.7] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.085 | L2-Norm(final)=12.536 | 6193.2 samples/s | 96.8 steps/s
[Step=98350 Epoch=939.2] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.088 | L2-Norm(final)=12.541 | 2270.4 samples/s | 35.5 steps/s
[Step=98400 Epoch=939.7] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.090 | L2-Norm(final)=12.546 | 5515.6 samples/s | 86.2 steps/s
[Step=98450 Epoch=940.1] | Loss=0.00003 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.092 | L2-Norm(final)=12.550 | 2382.1 samples/s | 37.2 steps/s
[Step=98500 Epoch=940.6] | Loss=0.00002 | Reg=0.00026 | acc=1.0000 | L2-Norm=5.093 | L2-Norm(final)=12.555 | 5010.2 samples/s | 78.3 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_2/client_state-step98500.h5

Train client 8: client_iccad2012_3
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=923.4] | Loss=0.00002 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.420 | L2-Norm(final)=11.946 | 4899.2 samples/s | 76.6 steps/s
[Step=98050 Epoch=923.9] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.421 | L2-Norm(final)=11.949 | 4513.2 samples/s | 70.5 steps/s
[Step=98100 Epoch=924.4] | Loss=0.00006 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.424 | L2-Norm(final)=11.954 | 7161.6 samples/s | 111.9 steps/s
[Step=98150 Epoch=924.9] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.426 | L2-Norm(final)=11.958 | 2136.9 samples/s | 33.4 steps/s
[Step=98200 Epoch=925.3] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.427 | L2-Norm(final)=11.962 | 6327.1 samples/s | 98.9 steps/s
[Step=98250 Epoch=925.8] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.429 | L2-Norm(final)=11.966 | 2241.0 samples/s | 35.0 steps/s
[Step=98300 Epoch=926.3] | Loss=0.00005 | Reg=0.00029 | acc=1.0000 | L2-Norm=5.430 | L2-Norm(final)=11.970 | 5648.4 samples/s | 88.3 steps/s
[Step=98350 Epoch=926.7] | Loss=0.00005 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.432 | L2-Norm(final)=11.974 | 2363.5 samples/s | 36.9 steps/s
[Step=98400 Epoch=927.2] | Loss=0.00005 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.433 | L2-Norm(final)=11.978 | 4979.1 samples/s | 77.8 steps/s
[Step=98450 Epoch=927.7] | Loss=0.00005 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.435 | L2-Norm(final)=11.982 | 2502.5 samples/s | 39.1 steps/s
[Step=98500 Epoch=928.2] | Loss=0.00005 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.436 | L2-Norm(final)=11.986 | 4724.1 samples/s | 73.8 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_3/client_state-step98500.h5

Train client 9: client_iccad2012_4
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=934.0] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.282 | L2-Norm(final)=12.780 | 5368.4 samples/s | 83.9 steps/s
[Step=98050 Epoch=934.5] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.285 | L2-Norm(final)=12.786 | 4106.6 samples/s | 64.2 steps/s
[Step=98100 Epoch=935.0] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.288 | L2-Norm(final)=12.793 | 7561.6 samples/s | 118.1 steps/s
[Step=98150 Epoch=935.5] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.292 | L2-Norm(final)=12.801 | 2110.7 samples/s | 33.0 steps/s
[Step=98200 Epoch=935.9] | Loss=0.00005 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.295 | L2-Norm(final)=12.807 | 6847.4 samples/s | 107.0 steps/s
[Step=98250 Epoch=936.4] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.297 | L2-Norm(final)=12.813 | 2202.3 samples/s | 34.4 steps/s
[Step=98300 Epoch=936.9] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.299 | L2-Norm(final)=12.819 | 5863.8 samples/s | 91.6 steps/s
[Step=98350 Epoch=937.4] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.301 | L2-Norm(final)=12.824 | 2266.3 samples/s | 35.4 steps/s
[Step=98400 Epoch=937.8] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.304 | L2-Norm(final)=12.830 | 5607.7 samples/s | 87.6 steps/s
[Step=98450 Epoch=938.3] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.306 | L2-Norm(final)=12.835 | 2329.2 samples/s | 36.4 steps/s
[Step=98500 Epoch=938.8] | Loss=0.00004 | Reg=0.00028 | acc=1.0000 | L2-Norm=5.308 | L2-Norm(final)=12.840 | 5167.5 samples/s | 80.7 steps/s
Client model saved at models/model-local_fc12_ht.v2-a5i5-sel1.0-ch32/client_iccad2012_4/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08761 | acc=0.9550 | tpr=0.9694 | fpr=0.0763 | 4720.6 samples/s | 18.4 steps/s
Avg test loss: 0.09062, Avg test acc: 0.95340, Avg tpr: 0.96911, Avg fpr: 0.08114, total FA: 633

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.09032 | acc=0.9534 | tpr=0.9678 | fpr=0.0780 | 4641.7 samples/s | 18.1 steps/s
Avg test loss: 0.09112, Avg test acc: 0.95396, Avg tpr: 0.96876, Avg fpr: 0.07858, total FA: 613

Testing client_asml1_2 on asml1
[Step=  50] | Loss=0.08995 | acc=0.9538 | tpr=0.9636 | fpr=0.0674 | 4734.2 samples/s | 18.5 steps/s
Avg test loss: 0.09203, Avg test acc: 0.95228, Avg tpr: 0.96188, Avg fpr: 0.06884, total FA: 537

Testing client_asml1_3 on asml1
[Step=  50] | Loss=0.08148 | acc=0.9542 | tpr=0.9628 | fpr=0.0644 | 4884.1 samples/s | 19.1 steps/s
Avg test loss: 0.08630, Avg test acc: 0.95244, Avg tpr: 0.96281, Avg fpr: 0.07038, total FA: 549

Testing client_asml1_4 on asml1
[Step=  50] | Loss=0.08906 | acc=0.9540 | tpr=0.9674 | fpr=0.0751 | 4782.6 samples/s | 18.7 steps/s
Avg test loss: 0.09277, Avg test acc: 0.95256, Avg tpr: 0.96602, Avg fpr: 0.07704, total FA: 601

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.60798 | acc=0.3000 | tpr=0.0098 | fpr=0.0699 | 4828.5 samples/s | 18.9 steps/s
Avg test loss: 5.61260, Avg test acc: 0.29810, Avg tpr: 0.01055, Avg fpr: 0.06948, total FA: 542

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.58808 | acc=0.2997 | tpr=0.0081 | fpr=0.0671 | 4568.7 samples/s | 17.8 steps/s
Avg test loss: 4.60208, Avg test acc: 0.29626, Avg tpr: 0.00828, Avg fpr: 0.07038, total FA: 549

Testing client_iccad2012_2 on asml1
[Step=  50] | Loss=5.00074 | acc=0.2904 | tpr=0.0112 | fpr=0.1033 | 4865.4 samples/s | 19.0 steps/s
Avg test loss: 5.00140, Avg test acc: 0.28804, Avg tpr: 0.01183, Avg fpr: 0.10447, total FA: 815

Testing client_iccad2012_3 on asml1
[Step=  50] | Loss=5.26268 | acc=0.3021 | tpr=0.0148 | fpr=0.0741 | 4872.2 samples/s | 19.0 steps/s
Avg test loss: 5.26156, Avg test acc: 0.30135, Avg tpr: 0.01661, Avg fpr: 0.07243, total FA: 565

Testing client_iccad2012_4 on asml1
[Step=  50] | Loss=4.70214 | acc=0.3051 | tpr=0.0172 | fpr=0.0699 | 5001.2 samples/s | 19.5 steps/s
Avg test loss: 4.70737, Avg test acc: 0.30211, Avg tpr: 0.01655, Avg fpr: 0.06986, total FA: 545

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.93276 | acc=0.1052 | tpr=0.5133 | fpr=0.9021 | 4823.1 samples/s | 18.8 steps/s
[Step= 100] | Loss=4.90362 | acc=0.1074 | tpr=0.4947 | fpr=0.8998 | 7156.1 samples/s | 28.0 steps/s
[Step= 150] | Loss=4.91444 | acc=0.1074 | tpr=0.4841 | fpr=0.8995 | 7890.5 samples/s | 30.8 steps/s
[Step= 200] | Loss=4.90868 | acc=0.1078 | tpr=0.4754 | fpr=0.8989 | 7546.8 samples/s | 29.5 steps/s
[Step= 250] | Loss=4.91140 | acc=0.1083 | tpr=0.4943 | fpr=0.8987 | 8180.5 samples/s | 32.0 steps/s
[Step= 300] | Loss=4.91073 | acc=0.1081 | tpr=0.5004 | fpr=0.8991 | 7687.5 samples/s | 30.0 steps/s
[Step= 350] | Loss=4.90452 | acc=0.1081 | tpr=0.4934 | fpr=0.8989 | 8043.7 samples/s | 31.4 steps/s
[Step= 400] | Loss=4.90403 | acc=0.1080 | tpr=0.4918 | fpr=0.8990 | 7898.8 samples/s | 30.9 steps/s
[Step= 450] | Loss=4.90780 | acc=0.1084 | tpr=0.4907 | fpr=0.8985 | 7658.9 samples/s | 29.9 steps/s
[Step= 500] | Loss=4.91033 | acc=0.1085 | tpr=0.4872 | fpr=0.8983 | 7907.7 samples/s | 30.9 steps/s
[Step= 550] | Loss=4.91282 | acc=0.1083 | tpr=0.4839 | fpr=0.8986 | 13998.9 samples/s | 54.7 steps/s
Avg test loss: 4.91409, Avg test acc: 0.10817, Avg tpr: 0.48415, Avg fpr: 0.89867, total FA: 124778

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.63700 | acc=0.1020 | tpr=0.4425 | fpr=0.9041 | 4773.4 samples/s | 18.6 steps/s
[Step= 100] | Loss=4.62888 | acc=0.1016 | tpr=0.4456 | fpr=0.9049 | 6775.0 samples/s | 26.5 steps/s
[Step= 150] | Loss=4.63237 | acc=0.1013 | tpr=0.4380 | fpr=0.9049 | 8424.3 samples/s | 32.9 steps/s
[Step= 200] | Loss=4.62910 | acc=0.1012 | tpr=0.4208 | fpr=0.9047 | 7739.4 samples/s | 30.2 steps/s
[Step= 250] | Loss=4.63132 | acc=0.1016 | tpr=0.4262 | fpr=0.9043 | 8021.8 samples/s | 31.3 steps/s
[Step= 300] | Loss=4.62839 | acc=0.1014 | tpr=0.4335 | fpr=0.9047 | 7820.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=4.62437 | acc=0.1015 | tpr=0.4258 | fpr=0.9044 | 7601.4 samples/s | 29.7 steps/s
[Step= 400] | Loss=4.62278 | acc=0.1014 | tpr=0.4261 | fpr=0.9045 | 8127.7 samples/s | 31.7 steps/s
[Step= 450] | Loss=4.62800 | acc=0.1017 | tpr=0.4255 | fpr=0.9042 | 7696.0 samples/s | 30.1 steps/s
[Step= 500] | Loss=4.63168 | acc=0.1019 | tpr=0.4220 | fpr=0.9039 | 7983.6 samples/s | 31.2 steps/s
[Step= 550] | Loss=4.63746 | acc=0.1014 | tpr=0.4190 | fpr=0.9043 | 14050.6 samples/s | 54.9 steps/s
Avg test loss: 4.63953, Avg test acc: 0.10138, Avg tpr: 0.41918, Avg fpr: 0.90439, total FA: 125573

Testing client_asml1_2 on iccad2012
[Step=  50] | Loss=4.54451 | acc=0.1206 | tpr=0.1726 | fpr=0.8803 | 4786.2 samples/s | 18.7 steps/s
[Step= 100] | Loss=4.51264 | acc=0.1213 | tpr=0.1983 | fpr=0.8801 | 7275.2 samples/s | 28.4 steps/s
[Step= 150] | Loss=4.52537 | acc=0.1211 | tpr=0.1988 | fpr=0.8803 | 7757.9 samples/s | 30.3 steps/s
[Step= 200] | Loss=4.51937 | acc=0.1222 | tpr=0.1880 | fpr=0.8789 | 7935.2 samples/s | 31.0 steps/s
[Step= 250] | Loss=4.52110 | acc=0.1230 | tpr=0.1983 | fpr=0.8784 | 7720.7 samples/s | 30.2 steps/s
[Step= 300] | Loss=4.51863 | acc=0.1229 | tpr=0.2051 | fpr=0.8786 | 7962.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.51327 | acc=0.1230 | tpr=0.2004 | fpr=0.8784 | 7753.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=4.51367 | acc=0.1231 | tpr=0.1991 | fpr=0.8783 | 7979.1 samples/s | 31.2 steps/s
[Step= 450] | Loss=4.51943 | acc=0.1231 | tpr=0.1972 | fpr=0.8782 | 7864.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=4.52115 | acc=0.1232 | tpr=0.1987 | fpr=0.8781 | 7726.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=4.52414 | acc=0.1231 | tpr=0.2010 | fpr=0.8784 | 14053.6 samples/s | 54.9 steps/s
Avg test loss: 4.52533, Avg test acc: 0.12294, Avg tpr: 0.20166, Avg fpr: 0.87849, total FA: 121977

Testing client_asml1_3 on iccad2012
[Step=  50] | Loss=4.20406 | acc=0.1338 | tpr=0.4248 | fpr=0.8715 | 4832.4 samples/s | 18.9 steps/s
[Step= 100] | Loss=4.17592 | acc=0.1330 | tpr=0.4136 | fpr=0.8723 | 6863.8 samples/s | 26.8 steps/s
[Step= 150] | Loss=4.18864 | acc=0.1319 | tpr=0.4092 | fpr=0.8732 | 8191.7 samples/s | 32.0 steps/s
[Step= 200] | Loss=4.18282 | acc=0.1309 | tpr=0.3934 | fpr=0.8739 | 7948.8 samples/s | 31.1 steps/s
[Step= 250] | Loss=4.18758 | acc=0.1311 | tpr=0.3913 | fpr=0.8736 | 7646.2 samples/s | 29.9 steps/s
[Step= 300] | Loss=4.18731 | acc=0.1311 | tpr=0.3956 | fpr=0.8737 | 7925.0 samples/s | 31.0 steps/s
[Step= 350] | Loss=4.18048 | acc=0.1319 | tpr=0.3920 | fpr=0.8728 | 8089.0 samples/s | 31.6 steps/s
[Step= 400] | Loss=4.17986 | acc=0.1315 | tpr=0.3862 | fpr=0.8731 | 7960.2 samples/s | 31.1 steps/s
[Step= 450] | Loss=4.18428 | acc=0.1315 | tpr=0.3870 | fpr=0.8731 | 7694.3 samples/s | 30.1 steps/s
[Step= 500] | Loss=4.18588 | acc=0.1315 | tpr=0.3824 | fpr=0.8731 | 7734.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=4.19018 | acc=0.1309 | tpr=0.3800 | fpr=0.8737 | 14361.8 samples/s | 56.1 steps/s
Avg test loss: 4.19126, Avg test acc: 0.13076, Avg tpr: 0.38035, Avg fpr: 0.87378, total FA: 121322

Testing client_asml1_4 on iccad2012
[Step=  50] | Loss=4.70556 | acc=0.1281 | tpr=0.4292 | fpr=0.8773 | 4720.4 samples/s | 18.4 steps/s
[Step= 100] | Loss=4.68388 | acc=0.1298 | tpr=0.4286 | fpr=0.8758 | 7204.7 samples/s | 28.1 steps/s
[Step= 150] | Loss=4.68472 | acc=0.1290 | tpr=0.4150 | fpr=0.8763 | 8100.7 samples/s | 31.6 steps/s
[Step= 200] | Loss=4.68095 | acc=0.1288 | tpr=0.4000 | fpr=0.8761 | 7642.3 samples/s | 29.9 steps/s
[Step= 250] | Loss=4.68309 | acc=0.1298 | tpr=0.4122 | fpr=0.8753 | 7794.8 samples/s | 30.4 steps/s
[Step= 300] | Loss=4.68447 | acc=0.1294 | tpr=0.4167 | fpr=0.8759 | 8056.9 samples/s | 31.5 steps/s
[Step= 350] | Loss=4.67858 | acc=0.1295 | tpr=0.4108 | fpr=0.8756 | 7412.5 samples/s | 29.0 steps/s
[Step= 400] | Loss=4.67879 | acc=0.1287 | tpr=0.4092 | fpr=0.8764 | 8270.3 samples/s | 32.3 steps/s
[Step= 450] | Loss=4.68377 | acc=0.1289 | tpr=0.4099 | fpr=0.8762 | 8056.5 samples/s | 31.5 steps/s
[Step= 500] | Loss=4.68526 | acc=0.1286 | tpr=0.4097 | fpr=0.8765 | 7935.9 samples/s | 31.0 steps/s
[Step= 550] | Loss=4.68917 | acc=0.1283 | tpr=0.4103 | fpr=0.8769 | 13655.9 samples/s | 53.3 steps/s
Avg test loss: 4.69095, Avg test acc: 0.12807, Avg tpr: 0.40967, Avg fpr: 0.87705, total FA: 121777

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08520 | acc=0.9823 | tpr=0.9646 | fpr=0.0173 | 4663.8 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.08643 | acc=0.9822 | tpr=0.9680 | fpr=0.0175 | 7085.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.08924 | acc=0.9814 | tpr=0.9669 | fpr=0.0184 | 8188.9 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.09079 | acc=0.9813 | tpr=0.9716 | fpr=0.0185 | 8074.6 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.08984 | acc=0.9814 | tpr=0.9668 | fpr=0.0183 | 7772.0 samples/s | 30.4 steps/s
[Step= 300] | Loss=0.09170 | acc=0.9811 | tpr=0.9658 | fpr=0.0186 | 7855.4 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.09258 | acc=0.9809 | tpr=0.9668 | fpr=0.0189 | 8014.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.09341 | acc=0.9805 | tpr=0.9628 | fpr=0.0192 | 8061.9 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.09518 | acc=0.9802 | tpr=0.9591 | fpr=0.0194 | 7671.5 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.09461 | acc=0.9802 | tpr=0.9595 | fpr=0.0194 | 7924.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.09388 | acc=0.9803 | tpr=0.9582 | fpr=0.0193 | 13351.2 samples/s | 52.2 steps/s
Avg test loss: 0.09376, Avg test acc: 0.98036, Avg tpr: 0.95840, Avg fpr: 0.01924, total FA: 2671

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.08960 | acc=0.9811 | tpr=0.9248 | fpr=0.0179 | 4699.8 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.09225 | acc=0.9813 | tpr=0.9360 | fpr=0.0178 | 7377.2 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.09595 | acc=0.9807 | tpr=0.9395 | fpr=0.0186 | 7843.2 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.09786 | acc=0.9809 | tpr=0.9443 | fpr=0.0185 | 7787.8 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.09665 | acc=0.9811 | tpr=0.9432 | fpr=0.0182 | 7846.1 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.09885 | acc=0.9807 | tpr=0.9425 | fpr=0.0186 | 7924.3 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.09952 | acc=0.9805 | tpr=0.9455 | fpr=0.0189 | 8072.6 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.10061 | acc=0.9803 | tpr=0.9409 | fpr=0.0190 | 7746.2 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.10273 | acc=0.9801 | tpr=0.9396 | fpr=0.0192 | 7906.0 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.10213 | acc=0.9801 | tpr=0.9410 | fpr=0.0192 | 7909.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.10173 | acc=0.9802 | tpr=0.9399 | fpr=0.0190 | 14196.3 samples/s | 55.5 steps/s
Avg test loss: 0.10162, Avg test acc: 0.98024, Avg tpr: 0.94017, Avg fpr: 0.01904, total FA: 2643

Testing client_iccad2012_2 on iccad2012
[Step=  50] | Loss=0.08627 | acc=0.9794 | tpr=0.9690 | fpr=0.0204 | 4816.7 samples/s | 18.8 steps/s
[Step= 100] | Loss=0.08745 | acc=0.9795 | tpr=0.9723 | fpr=0.0204 | 7068.7 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.09157 | acc=0.9786 | tpr=0.9697 | fpr=0.0212 | 7482.0 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.09276 | acc=0.9789 | tpr=0.9749 | fpr=0.0211 | 8147.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.09187 | acc=0.9791 | tpr=0.9738 | fpr=0.0208 | 8163.8 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.09387 | acc=0.9788 | tpr=0.9709 | fpr=0.0211 | 7717.6 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.09461 | acc=0.9785 | tpr=0.9718 | fpr=0.0214 | 7776.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.09540 | acc=0.9783 | tpr=0.9694 | fpr=0.0215 | 8077.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.09676 | acc=0.9781 | tpr=0.9679 | fpr=0.0217 | 7860.6 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.09643 | acc=0.9781 | tpr=0.9678 | fpr=0.0217 | 7923.0 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.09580 | acc=0.9783 | tpr=0.9666 | fpr=0.0214 | 13752.1 samples/s | 53.7 steps/s
Avg test loss: 0.09570, Avg test acc: 0.97833, Avg tpr: 0.96672, Avg fpr: 0.02146, total FA: 2980

Testing client_iccad2012_3 on iccad2012
[Step=  50] | Loss=0.09788 | acc=0.9784 | tpr=0.9690 | fpr=0.0214 | 4952.2 samples/s | 19.3 steps/s
[Step= 100] | Loss=0.09887 | acc=0.9786 | tpr=0.9659 | fpr=0.0212 | 6829.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.10297 | acc=0.9776 | tpr=0.9597 | fpr=0.0221 | 7613.4 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.10380 | acc=0.9777 | tpr=0.9628 | fpr=0.0221 | 7730.6 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.10257 | acc=0.9781 | tpr=0.9616 | fpr=0.0216 | 8266.6 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.10473 | acc=0.9779 | tpr=0.9607 | fpr=0.0218 | 7481.7 samples/s | 29.2 steps/s
[Step= 350] | Loss=0.10558 | acc=0.9776 | tpr=0.9618 | fpr=0.0221 | 8014.4 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.10614 | acc=0.9776 | tpr=0.9590 | fpr=0.0221 | 7891.1 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.10787 | acc=0.9773 | tpr=0.9562 | fpr=0.0223 | 7858.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.10715 | acc=0.9774 | tpr=0.9564 | fpr=0.0222 | 7866.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.10642 | acc=0.9776 | tpr=0.9570 | fpr=0.0220 | 13891.5 samples/s | 54.3 steps/s
Avg test loss: 0.10623, Avg test acc: 0.97766, Avg tpr: 0.95721, Avg fpr: 0.02197, total FA: 3050

Testing client_iccad2012_4 on iccad2012
[Step=  50] | Loss=0.10068 | acc=0.9796 | tpr=0.9779 | fpr=0.0204 | 4522.3 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.10432 | acc=0.9788 | tpr=0.9701 | fpr=0.0211 | 7879.9 samples/s | 30.8 steps/s
[Step= 150] | Loss=0.10825 | acc=0.9774 | tpr=0.9640 | fpr=0.0224 | 7730.8 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10976 | acc=0.9771 | tpr=0.9694 | fpr=0.0228 | 7984.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.10852 | acc=0.9773 | tpr=0.9651 | fpr=0.0225 | 7948.8 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.11027 | acc=0.9771 | tpr=0.9629 | fpr=0.0227 | 7715.2 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.11122 | acc=0.9768 | tpr=0.9631 | fpr=0.0230 | 7856.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.11236 | acc=0.9766 | tpr=0.9601 | fpr=0.0231 | 7716.6 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.11437 | acc=0.9763 | tpr=0.9562 | fpr=0.0233 | 8052.0 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.11390 | acc=0.9763 | tpr=0.9559 | fpr=0.0233 | 7592.3 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.11312 | acc=0.9766 | tpr=0.9562 | fpr=0.0230 | 14930.7 samples/s | 58.3 steps/s
Avg test loss: 0.11304, Avg test acc: 0.97659, Avg tpr: 0.95642, Avg fpr: 0.02304, total FA: 3199
