#clients of iccad2012: 1
#clients of asml1: 1
select ratio: 1.0
Total num clients: 2
client model path: ['models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0', 'models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (49916, 144, 26)
Resampled dataset to size (65551, 144, 26)
Using transform option: train
#pos = 34281, #neg = 31270
loading data into the main memory...
Allocated dataset with size (18300, 144, 26)
Resampled dataset to size (33952, 144, 26)
Using transform option: train
#pos = 16856, #neg = 17096
loading data into the main memory...
Allocated dataset with size (24958, 144, 26)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 26)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.33734 | Reg=0.00355 | acc=0.5625 | L2-Norm=18.851 | L2-Norm(final)=2.027 | 2400.4 samples/s | 37.5 steps/s
[Step=  50 Epoch= 0.0] | Loss=0.33652 | Reg=0.00355 | acc=0.5781 | L2-Norm=18.851 | L2-Norm(final)=2.034 | 5701.5 samples/s | 89.1 steps/s
[Step= 100 Epoch= 0.1] | Loss=0.33292 | Reg=0.00355 | acc=0.6250 | L2-Norm=18.851 | L2-Norm(final)=2.050 | 6198.7 samples/s | 96.9 steps/s
[Step= 150 Epoch= 0.1] | Loss=0.33200 | Reg=0.00355 | acc=0.5938 | L2-Norm=18.851 | L2-Norm(final)=2.070 | 6002.1 samples/s | 93.8 steps/s
[Step= 200 Epoch= 0.2] | Loss=0.33018 | Reg=0.00355 | acc=0.5156 | L2-Norm=18.851 | L2-Norm(final)=2.091 | 6179.4 samples/s | 96.6 steps/s
[Step= 250 Epoch= 0.2] | Loss=0.32876 | Reg=0.00355 | acc=0.5938 | L2-Norm=18.851 | L2-Norm(final)=2.114 | 6103.4 samples/s | 95.4 steps/s
[Step= 300 Epoch= 0.3] | Loss=0.32760 | Reg=0.00355 | acc=0.5781 | L2-Norm=18.851 | L2-Norm(final)=2.139 | 6050.8 samples/s | 94.5 steps/s
[Step= 350 Epoch= 0.3] | Loss=0.32627 | Reg=0.00355 | acc=0.6406 | L2-Norm=18.851 | L2-Norm(final)=2.166 | 6189.7 samples/s | 96.7 steps/s
[Step= 400 Epoch= 0.4] | Loss=0.32481 | Reg=0.00355 | acc=0.6875 | L2-Norm=18.851 | L2-Norm(final)=2.195 | 6207.6 samples/s | 97.0 steps/s
[Step= 450 Epoch= 0.4] | Loss=0.32397 | Reg=0.00355 | acc=0.5781 | L2-Norm=18.851 | L2-Norm(final)=2.226 | 6203.2 samples/s | 96.9 steps/s
[Step= 500 Epoch= 0.5] | Loss=0.32261 | Reg=0.00355 | acc=0.5469 | L2-Norm=18.851 | L2-Norm(final)=2.259 | 6292.0 samples/s | 98.3 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.5] | Loss=0.29296 | Reg=0.00355 | acc=0.7500 | L2-Norm=18.851 | L2-Norm(final)=2.603 | 4392.1 samples/s | 68.6 steps/s
[Step= 550 Epoch= 0.5] | Loss=0.28882 | Reg=0.00343 | acc=0.8125 | L2-Norm=18.525 | L2-Norm(final)=2.600 | 4580.2 samples/s | 71.6 steps/s
[Step= 600 Epoch= 0.6] | Loss=0.25353 | Reg=0.00339 | acc=0.8281 | L2-Norm=18.418 | L2-Norm(final)=2.612 | 4817.3 samples/s | 75.3 steps/s
[Step= 650 Epoch= 0.6] | Loss=0.22564 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.355 | L2-Norm(final)=2.626 | 4809.1 samples/s | 75.1 steps/s
[Step= 700 Epoch= 0.7] | Loss=0.20992 | Reg=0.00335 | acc=0.9531 | L2-Norm=18.309 | L2-Norm(final)=2.637 | 4807.9 samples/s | 75.1 steps/s
[Step= 750 Epoch= 0.7] | Loss=0.19699 | Reg=0.00334 | acc=0.7969 | L2-Norm=18.276 | L2-Norm(final)=2.646 | 4888.7 samples/s | 76.4 steps/s
[Step= 800 Epoch= 0.8] | Loss=0.18702 | Reg=0.00333 | acc=0.8594 | L2-Norm=18.250 | L2-Norm(final)=2.655 | 4855.1 samples/s | 75.9 steps/s
[Step= 850 Epoch= 0.8] | Loss=0.17745 | Reg=0.00332 | acc=0.9062 | L2-Norm=18.230 | L2-Norm(final)=2.664 | 4871.6 samples/s | 76.1 steps/s
[Step= 900 Epoch= 0.9] | Loss=0.17052 | Reg=0.00332 | acc=0.8906 | L2-Norm=18.217 | L2-Norm(final)=2.672 | 4853.7 samples/s | 75.8 steps/s
[Step= 950 Epoch= 0.9] | Loss=0.16410 | Reg=0.00332 | acc=0.9219 | L2-Norm=18.209 | L2-Norm(final)=2.679 | 4830.7 samples/s | 75.5 steps/s
[Step=1000 Epoch= 1.0] | Loss=0.15786 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.204 | L2-Norm(final)=2.686 | 4855.3 samples/s | 75.9 steps/s
[Step=1050 Epoch= 1.0] | Loss=0.15274 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.199 | L2-Norm(final)=2.693 | 4893.2 samples/s | 76.5 steps/s
[Step=1100 Epoch= 1.1] | Loss=0.14855 | Reg=0.00331 | acc=0.9062 | L2-Norm=18.196 | L2-Norm(final)=2.700 | 4840.2 samples/s | 75.6 steps/s
[Step=1150 Epoch= 1.1] | Loss=0.14423 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.194 | L2-Norm(final)=2.706 | 4858.9 samples/s | 75.9 steps/s
[Step=1200 Epoch= 1.2] | Loss=0.14148 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.193 | L2-Norm(final)=2.711 | 4887.1 samples/s | 76.4 steps/s
[Step=1250 Epoch= 1.2] | Loss=0.13776 | Reg=0.00331 | acc=0.9062 | L2-Norm=18.193 | L2-Norm(final)=2.716 | 4886.4 samples/s | 76.3 steps/s
[Step=1300 Epoch= 1.3] | Loss=0.13451 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.193 | L2-Norm(final)=2.721 | 4913.4 samples/s | 76.8 steps/s
[Step=1350 Epoch= 1.3] | Loss=0.13209 | Reg=0.00331 | acc=0.9062 | L2-Norm=18.194 | L2-Norm(final)=2.726 | 4825.6 samples/s | 75.4 steps/s
[Step=1400 Epoch= 1.4] | Loss=0.12911 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.196 | L2-Norm(final)=2.731 | 4861.5 samples/s | 76.0 steps/s
[Step=1450 Epoch= 1.4] | Loss=0.12635 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.198 | L2-Norm(final)=2.735 | 4843.9 samples/s | 75.7 steps/s
[Step=1500 Epoch= 1.5] | Loss=0.12357 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.199 | L2-Norm(final)=2.740 | 5199.2 samples/s | 81.2 steps/s
[Step=1550 Epoch= 1.5] | Loss=0.12096 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.201 | L2-Norm(final)=2.744 | 2131.6 samples/s | 33.3 steps/s
[Step=1600 Epoch= 1.6] | Loss=0.11867 | Reg=0.00331 | acc=0.9062 | L2-Norm=18.204 | L2-Norm(final)=2.748 | 4884.0 samples/s | 76.3 steps/s
[Step=1650 Epoch= 1.6] | Loss=0.11651 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.206 | L2-Norm(final)=2.752 | 4887.6 samples/s | 76.4 steps/s
[Step=1700 Epoch= 1.7] | Loss=0.11441 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.208 | L2-Norm(final)=2.757 | 4774.6 samples/s | 74.6 steps/s
[Step=1750 Epoch= 1.7] | Loss=0.11231 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.212 | L2-Norm(final)=2.761 | 4874.8 samples/s | 76.2 steps/s
[Step=1800 Epoch= 1.8] | Loss=0.11022 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.216 | L2-Norm(final)=2.765 | 4892.3 samples/s | 76.4 steps/s
[Step=1850 Epoch= 1.8] | Loss=0.10846 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.220 | L2-Norm(final)=2.769 | 4838.0 samples/s | 75.6 steps/s
[Step=1900 Epoch= 1.9] | Loss=0.10687 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.225 | L2-Norm(final)=2.773 | 4851.3 samples/s | 75.8 steps/s
[Step=1950 Epoch= 1.9] | Loss=0.10534 | Reg=0.00332 | acc=0.9219 | L2-Norm=18.229 | L2-Norm(final)=2.776 | 4856.9 samples/s | 75.9 steps/s
[Step=2000 Epoch= 2.0] | Loss=0.10398 | Reg=0.00332 | acc=0.9531 | L2-Norm=18.234 | L2-Norm(final)=2.779 | 4840.4 samples/s | 75.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step2000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.36843 | Reg=0.00355 | acc=0.5625 | L2-Norm=18.851 | L2-Norm(final)=2.027 | 4013.8 samples/s | 62.7 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.31923 | Reg=0.00355 | acc=0.5156 | L2-Norm=18.851 | L2-Norm(final)=2.043 | 5062.1 samples/s | 79.1 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.30972 | Reg=0.00355 | acc=0.6406 | L2-Norm=18.851 | L2-Norm(final)=2.071 | 5845.9 samples/s | 91.3 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.29964 | Reg=0.00355 | acc=0.7344 | L2-Norm=18.851 | L2-Norm(final)=2.120 | 5759.0 samples/s | 90.0 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.29099 | Reg=0.00355 | acc=0.8906 | L2-Norm=18.851 | L2-Norm(final)=2.183 | 5719.8 samples/s | 89.4 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.28404 | Reg=0.00355 | acc=0.8125 | L2-Norm=18.851 | L2-Norm(final)=2.255 | 5723.4 samples/s | 89.4 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.27788 | Reg=0.00355 | acc=0.8750 | L2-Norm=18.851 | L2-Norm(final)=2.332 | 5854.1 samples/s | 91.5 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.27199 | Reg=0.00355 | acc=0.7969 | L2-Norm=18.851 | L2-Norm(final)=2.414 | 5779.1 samples/s | 90.3 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.26634 | Reg=0.00355 | acc=0.9062 | L2-Norm=18.851 | L2-Norm(final)=2.497 | 5816.5 samples/s | 90.9 steps/s
[Step= 450 Epoch= 0.8] | Loss=0.26104 | Reg=0.00355 | acc=0.7656 | L2-Norm=18.851 | L2-Norm(final)=2.582 | 5650.9 samples/s | 88.3 steps/s
[Step= 500 Epoch= 0.9] | Loss=0.25597 | Reg=0.00355 | acc=0.8594 | L2-Norm=18.851 | L2-Norm(final)=2.667 | 5905.7 samples/s | 92.3 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.9] | Loss=0.25124 | Reg=0.00355 | acc=0.7812 | L2-Norm=18.851 | L2-Norm(final)=3.521 | 4398.6 samples/s | 68.7 steps/s
[Step= 550 Epoch= 1.0] | Loss=0.17881 | Reg=0.00345 | acc=0.9062 | L2-Norm=18.563 | L2-Norm(final)=3.528 | 4228.4 samples/s | 66.1 steps/s
[Step= 600 Epoch= 1.1] | Loss=0.12350 | Reg=0.00342 | acc=0.9688 | L2-Norm=18.487 | L2-Norm(final)=3.550 | 4577.5 samples/s | 71.5 steps/s
[Step= 650 Epoch= 1.2] | Loss=0.09521 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.431 | L2-Norm(final)=3.561 | 4579.1 samples/s | 71.5 steps/s
[Step= 700 Epoch= 1.3] | Loss=0.07759 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.386 | L2-Norm(final)=3.571 | 4696.3 samples/s | 73.4 steps/s
[Step= 750 Epoch= 1.4] | Loss=0.06729 | Reg=0.00337 | acc=1.0000 | L2-Norm=18.350 | L2-Norm(final)=3.580 | 4442.3 samples/s | 69.4 steps/s
[Step= 800 Epoch= 1.5] | Loss=0.05867 | Reg=0.00336 | acc=0.9531 | L2-Norm=18.322 | L2-Norm(final)=3.588 | 4649.3 samples/s | 72.6 steps/s
[Step= 850 Epoch= 1.6] | Loss=0.05188 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.296 | L2-Norm(final)=3.596 | 4612.5 samples/s | 72.1 steps/s
[Step= 900 Epoch= 1.7] | Loss=0.04648 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.270 | L2-Norm(final)=3.603 | 4523.7 samples/s | 70.7 steps/s
[Step= 950 Epoch= 1.8] | Loss=0.04244 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.245 | L2-Norm(final)=3.610 | 4680.1 samples/s | 73.1 steps/s
[Step=1000 Epoch= 1.9] | Loss=0.03890 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.221 | L2-Norm(final)=3.617 | 4556.1 samples/s | 71.2 steps/s
[Step=1050 Epoch= 2.0] | Loss=0.03622 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.198 | L2-Norm(final)=3.622 | 2140.9 samples/s | 33.5 steps/s
[Step=1100 Epoch= 2.1] | Loss=0.03346 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.176 | L2-Norm(final)=3.627 | 4646.0 samples/s | 72.6 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.03101 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.154 | L2-Norm(final)=3.633 | 4658.4 samples/s | 72.8 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.02908 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.131 | L2-Norm(final)=3.638 | 4582.6 samples/s | 71.6 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.02729 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.108 | L2-Norm(final)=3.642 | 4581.7 samples/s | 71.6 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.02591 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.086 | L2-Norm(final)=3.647 | 4610.3 samples/s | 72.0 steps/s
[Step=1350 Epoch= 2.5] | Loss=0.02467 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.065 | L2-Norm(final)=3.651 | 4644.3 samples/s | 72.6 steps/s
[Step=1400 Epoch= 2.6] | Loss=0.02356 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.044 | L2-Norm(final)=3.654 | 4612.7 samples/s | 72.1 steps/s
[Step=1450 Epoch= 2.7] | Loss=0.02252 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.023 | L2-Norm(final)=3.658 | 4633.9 samples/s | 72.4 steps/s
[Step=1500 Epoch= 2.8] | Loss=0.02165 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.003 | L2-Norm(final)=3.661 | 4705.8 samples/s | 73.5 steps/s
[Step=1550 Epoch= 2.9] | Loss=0.02070 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.984 | L2-Norm(final)=3.664 | 5678.0 samples/s | 88.7 steps/s
[Step=1600 Epoch= 3.0] | Loss=0.01983 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.965 | L2-Norm(final)=3.667 | 1952.1 samples/s | 30.5 steps/s
[Step=1650 Epoch= 3.1] | Loss=0.01899 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.946 | L2-Norm(final)=3.671 | 4608.5 samples/s | 72.0 steps/s
[Step=1700 Epoch= 3.2] | Loss=0.01836 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.927 | L2-Norm(final)=3.674 | 4631.6 samples/s | 72.4 steps/s
[Step=1750 Epoch= 3.3] | Loss=0.01767 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.908 | L2-Norm(final)=3.677 | 4613.0 samples/s | 72.1 steps/s
[Step=1800 Epoch= 3.4] | Loss=0.01715 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.890 | L2-Norm(final)=3.680 | 4596.2 samples/s | 71.8 steps/s
[Step=1850 Epoch= 3.5] | Loss=0.01656 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.872 | L2-Norm(final)=3.682 | 4653.0 samples/s | 72.7 steps/s
[Step=1900 Epoch= 3.6] | Loss=0.01601 | Reg=0.00319 | acc=1.0000 | L2-Norm=17.854 | L2-Norm(final)=3.685 | 4602.9 samples/s | 71.9 steps/s
[Step=1950 Epoch= 3.7] | Loss=0.01563 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.837 | L2-Norm(final)=3.688 | 4644.2 samples/s | 72.6 steps/s
[Step=2000 Epoch= 3.8] | Loss=0.01521 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.821 | L2-Norm(final)=3.690 | 4535.6 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06566 | acc=0.9496 | tpr=0.9509 | fpr=0.0533 | 3920.8 samples/s | 15.3 steps/s
Avg test loss: 0.06891, Avg test acc: 0.94847, Avg tpr: 0.94952, Avg fpr: 0.05384, total FA: 420

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.69327 | acc=0.3244 | tpr=0.0318 | fpr=0.0404 | 4226.0 samples/s | 16.5 steps/s
Avg test loss: 6.70804, Avg test acc: 0.32142, Avg tpr: 0.03147, Avg fpr: 0.04089, total FA: 319

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.21307 | acc=0.1465 | tpr=0.5929 | fpr=0.8615 | 4261.1 samples/s | 16.6 steps/s
[Step= 100] | Loss=2.20409 | acc=0.1450 | tpr=0.5608 | fpr=0.8627 | 8014.4 samples/s | 31.3 steps/s
[Step= 150] | Loss=2.20365 | acc=0.1440 | tpr=0.5591 | fpr=0.8637 | 7795.8 samples/s | 30.5 steps/s
[Step= 200] | Loss=2.20063 | acc=0.1441 | tpr=0.5519 | fpr=0.8634 | 8039.8 samples/s | 31.4 steps/s
[Step= 250] | Loss=2.20093 | acc=0.1442 | tpr=0.5511 | fpr=0.8633 | 8255.0 samples/s | 32.2 steps/s
[Step= 300] | Loss=2.20021 | acc=0.1442 | tpr=0.5556 | fpr=0.8633 | 7794.7 samples/s | 30.4 steps/s
[Step= 350] | Loss=2.19760 | acc=0.1435 | tpr=0.5510 | fpr=0.8639 | 7998.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=2.19656 | acc=0.1434 | tpr=0.5492 | fpr=0.8639 | 7983.2 samples/s | 31.2 steps/s
[Step= 450] | Loss=2.19939 | acc=0.1432 | tpr=0.5521 | fpr=0.8643 | 8113.7 samples/s | 31.7 steps/s
[Step= 500] | Loss=2.19949 | acc=0.1427 | tpr=0.5489 | fpr=0.8646 | 7887.8 samples/s | 30.8 steps/s
[Step= 550] | Loss=2.20016 | acc=0.1428 | tpr=0.5539 | fpr=0.8647 | 14538.4 samples/s | 56.8 steps/s
Avg test loss: 2.20024, Avg test acc: 0.14277, Avg tpr: 0.55388, Avg fpr: 0.86470, total FA: 120062

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14958 | acc=0.9641 | tpr=0.9602 | fpr=0.0359 | 4238.9 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.15191 | acc=0.9636 | tpr=0.9680 | fpr=0.0365 | 7775.7 samples/s | 30.4 steps/s
[Step= 150] | Loss=0.15724 | acc=0.9631 | tpr=0.9755 | fpr=0.0371 | 8006.2 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.15942 | acc=0.9632 | tpr=0.9760 | fpr=0.0370 | 8072.5 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.15713 | acc=0.9632 | tpr=0.9721 | fpr=0.0369 | 7806.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.15916 | acc=0.9629 | tpr=0.9695 | fpr=0.0372 | 8093.2 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.16033 | acc=0.9627 | tpr=0.9674 | fpr=0.0374 | 7991.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.16218 | acc=0.9624 | tpr=0.9655 | fpr=0.0377 | 7888.5 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.16387 | acc=0.9623 | tpr=0.9659 | fpr=0.0378 | 7870.7 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.16358 | acc=0.9623 | tpr=0.9665 | fpr=0.0377 | 7804.0 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.16229 | acc=0.9625 | tpr=0.9670 | fpr=0.0375 | 15000.0 samples/s | 58.6 steps/s
Avg test loss: 0.16191, Avg test acc: 0.96258, Avg tpr: 0.96712, Avg fpr: 0.03750, total FA: 5207

server round 1/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=2001 Epoch= 2.0] | Loss=0.18092 | Reg=0.00283 | acc=0.8125 | L2-Norm=16.832 | L2-Norm(final)=2.868 | 4008.2 samples/s | 62.6 steps/s
[Step=2050 Epoch= 2.0] | Loss=0.18080 | Reg=0.00283 | acc=0.9219 | L2-Norm=16.833 | L2-Norm(final)=2.907 | 5165.0 samples/s | 80.7 steps/s
[Step=2100 Epoch= 2.1] | Loss=0.17208 | Reg=0.00283 | acc=0.8125 | L2-Norm=16.833 | L2-Norm(final)=2.981 | 5080.6 samples/s | 79.4 steps/s
[Step=2150 Epoch= 2.1] | Loss=0.16716 | Reg=0.00283 | acc=0.8438 | L2-Norm=16.833 | L2-Norm(final)=3.050 | 5364.2 samples/s | 83.8 steps/s
[Step=2200 Epoch= 2.1] | Loss=0.16250 | Reg=0.00283 | acc=0.8594 | L2-Norm=16.834 | L2-Norm(final)=3.121 | 5479.8 samples/s | 85.6 steps/s
[Step=2250 Epoch= 2.2] | Loss=0.16066 | Reg=0.00283 | acc=0.8594 | L2-Norm=16.834 | L2-Norm(final)=3.185 | 5623.8 samples/s | 87.9 steps/s
[Step=2300 Epoch= 2.2] | Loss=0.15867 | Reg=0.00283 | acc=0.8906 | L2-Norm=16.834 | L2-Norm(final)=3.245 | 5569.0 samples/s | 87.0 steps/s
[Step=2350 Epoch= 2.3] | Loss=0.15629 | Reg=0.00283 | acc=0.9219 | L2-Norm=16.834 | L2-Norm(final)=3.302 | 5672.3 samples/s | 88.6 steps/s
[Step=2400 Epoch= 2.3] | Loss=0.15609 | Reg=0.00283 | acc=0.8750 | L2-Norm=16.834 | L2-Norm(final)=3.357 | 5564.7 samples/s | 86.9 steps/s
[Step=2450 Epoch= 2.4] | Loss=0.15479 | Reg=0.00283 | acc=0.7812 | L2-Norm=16.834 | L2-Norm(final)=3.409 | 5698.2 samples/s | 89.0 steps/s
[Step=2500 Epoch= 2.4] | Loss=0.15360 | Reg=0.00283 | acc=0.8594 | L2-Norm=16.834 | L2-Norm(final)=3.460 | 5485.9 samples/s | 85.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 2.4] | Loss=0.15176 | Reg=0.00283 | acc=0.8750 | L2-Norm=16.834 | L2-Norm(final)=3.966 | 4181.2 samples/s | 65.3 steps/s
[Step=2550 Epoch= 2.5] | Loss=0.13499 | Reg=0.00289 | acc=0.8906 | L2-Norm=17.007 | L2-Norm(final)=3.968 | 4723.9 samples/s | 73.8 steps/s
[Step=2600 Epoch= 2.5] | Loss=0.11923 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.118 | L2-Norm(final)=3.964 | 4862.2 samples/s | 76.0 steps/s
[Step=2650 Epoch= 2.6] | Loss=0.11301 | Reg=0.00296 | acc=0.9219 | L2-Norm=17.190 | L2-Norm(final)=3.962 | 4842.9 samples/s | 75.7 steps/s
[Step=2700 Epoch= 2.6] | Loss=0.10573 | Reg=0.00297 | acc=0.8750 | L2-Norm=17.243 | L2-Norm(final)=3.962 | 4834.6 samples/s | 75.5 steps/s
[Step=2750 Epoch= 2.7] | Loss=0.10363 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.283 | L2-Norm(final)=3.959 | 4894.7 samples/s | 76.5 steps/s
[Step=2800 Epoch= 2.7] | Loss=0.09935 | Reg=0.00300 | acc=0.9062 | L2-Norm=17.315 | L2-Norm(final)=3.958 | 4643.4 samples/s | 72.6 steps/s
[Step=2850 Epoch= 2.8] | Loss=0.09743 | Reg=0.00301 | acc=0.8906 | L2-Norm=17.343 | L2-Norm(final)=3.955 | 4684.6 samples/s | 73.2 steps/s
[Step=2900 Epoch= 2.8] | Loss=0.09596 | Reg=0.00302 | acc=0.9219 | L2-Norm=17.368 | L2-Norm(final)=3.953 | 4735.5 samples/s | 74.0 steps/s
[Step=2950 Epoch= 2.9] | Loss=0.09301 | Reg=0.00302 | acc=0.9531 | L2-Norm=17.390 | L2-Norm(final)=3.951 | 4580.4 samples/s | 71.6 steps/s
[Step=3000 Epoch= 2.9] | Loss=0.09110 | Reg=0.00303 | acc=0.8906 | L2-Norm=17.410 | L2-Norm(final)=3.949 | 4621.5 samples/s | 72.2 steps/s
[Step=3050 Epoch= 3.0] | Loss=0.08929 | Reg=0.00304 | acc=0.9375 | L2-Norm=17.427 | L2-Norm(final)=3.949 | 4603.9 samples/s | 71.9 steps/s
[Step=3100 Epoch= 3.0] | Loss=0.08737 | Reg=0.00304 | acc=0.9844 | L2-Norm=17.444 | L2-Norm(final)=3.948 | 4624.5 samples/s | 72.3 steps/s
[Step=3150 Epoch= 3.1] | Loss=0.08542 | Reg=0.00305 | acc=0.9219 | L2-Norm=17.460 | L2-Norm(final)=3.948 | 4654.6 samples/s | 72.7 steps/s
[Step=3200 Epoch= 3.1] | Loss=0.08390 | Reg=0.00305 | acc=0.9531 | L2-Norm=17.476 | L2-Norm(final)=3.948 | 4832.3 samples/s | 75.5 steps/s
[Step=3250 Epoch= 3.2] | Loss=0.08235 | Reg=0.00306 | acc=0.9219 | L2-Norm=17.493 | L2-Norm(final)=3.948 | 4556.2 samples/s | 71.2 steps/s
[Step=3300 Epoch= 3.2] | Loss=0.08094 | Reg=0.00307 | acc=0.9062 | L2-Norm=17.508 | L2-Norm(final)=3.948 | 4689.7 samples/s | 73.3 steps/s
[Step=3350 Epoch= 3.3] | Loss=0.07976 | Reg=0.00307 | acc=0.9219 | L2-Norm=17.521 | L2-Norm(final)=3.948 | 4581.7 samples/s | 71.6 steps/s
[Step=3400 Epoch= 3.3] | Loss=0.07872 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.534 | L2-Norm(final)=3.947 | 4639.0 samples/s | 72.5 steps/s
[Step=3450 Epoch= 3.4] | Loss=0.07751 | Reg=0.00308 | acc=0.9688 | L2-Norm=17.547 | L2-Norm(final)=3.946 | 4540.0 samples/s | 70.9 steps/s
[Step=3500 Epoch= 3.4] | Loss=0.07659 | Reg=0.00308 | acc=0.9844 | L2-Norm=17.559 | L2-Norm(final)=3.945 | 5155.7 samples/s | 80.6 steps/s
[Step=3550 Epoch= 3.5] | Loss=0.07561 | Reg=0.00309 | acc=0.9688 | L2-Norm=17.570 | L2-Norm(final)=3.944 | 2089.8 samples/s | 32.7 steps/s
[Step=3600 Epoch= 3.5] | Loss=0.07456 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.581 | L2-Norm(final)=3.943 | 4951.7 samples/s | 77.4 steps/s
[Step=3650 Epoch= 3.6] | Loss=0.07347 | Reg=0.00310 | acc=0.9531 | L2-Norm=17.592 | L2-Norm(final)=3.942 | 4824.3 samples/s | 75.4 steps/s
[Step=3700 Epoch= 3.6] | Loss=0.07272 | Reg=0.00310 | acc=0.9531 | L2-Norm=17.602 | L2-Norm(final)=3.941 | 4851.1 samples/s | 75.8 steps/s
[Step=3750 Epoch= 3.7] | Loss=0.07174 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.613 | L2-Norm(final)=3.941 | 4824.9 samples/s | 75.4 steps/s
[Step=3800 Epoch= 3.7] | Loss=0.07079 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.625 | L2-Norm(final)=3.940 | 4854.5 samples/s | 75.9 steps/s
[Step=3850 Epoch= 3.8] | Loss=0.06977 | Reg=0.00311 | acc=0.9531 | L2-Norm=17.637 | L2-Norm(final)=3.939 | 4868.5 samples/s | 76.1 steps/s
[Step=3900 Epoch= 3.8] | Loss=0.06899 | Reg=0.00312 | acc=0.9531 | L2-Norm=17.648 | L2-Norm(final)=3.939 | 4889.5 samples/s | 76.4 steps/s
[Step=3950 Epoch= 3.9] | Loss=0.06825 | Reg=0.00312 | acc=0.9375 | L2-Norm=17.660 | L2-Norm(final)=3.938 | 4904.7 samples/s | 76.6 steps/s
[Step=4000 Epoch= 3.9] | Loss=0.06746 | Reg=0.00312 | acc=0.9688 | L2-Norm=17.671 | L2-Norm(final)=3.938 | 4900.8 samples/s | 76.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step4000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=2001 Epoch= 3.8] | Loss=0.07926 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.832 | L2-Norm(final)=3.754 | 4220.8 samples/s | 65.9 steps/s
[Step=2050 Epoch= 3.9] | Loss=0.07386 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.827 | L2-Norm(final)=3.737 | 5031.5 samples/s | 78.6 steps/s
[Step=2100 Epoch= 4.0] | Loss=0.06568 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.826 | L2-Norm(final)=3.827 | 5281.4 samples/s | 82.5 steps/s
[Step=2150 Epoch= 4.1] | Loss=0.06219 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.826 | L2-Norm(final)=3.918 | 5311.7 samples/s | 83.0 steps/s
[Step=2200 Epoch= 4.1] | Loss=0.06004 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.826 | L2-Norm(final)=4.003 | 5339.1 samples/s | 83.4 steps/s
[Step=2250 Epoch= 4.2] | Loss=0.05893 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.826 | L2-Norm(final)=4.082 | 5406.7 samples/s | 84.5 steps/s
[Step=2300 Epoch= 4.3] | Loss=0.05751 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.826 | L2-Norm(final)=4.156 | 5201.1 samples/s | 81.3 steps/s
[Step=2350 Epoch= 4.4] | Loss=0.05685 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.826 | L2-Norm(final)=4.223 | 5301.0 samples/s | 82.8 steps/s
[Step=2400 Epoch= 4.5] | Loss=0.05576 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.826 | L2-Norm(final)=4.287 | 5431.3 samples/s | 84.9 steps/s
[Step=2450 Epoch= 4.6] | Loss=0.05482 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.826 | L2-Norm(final)=4.350 | 5147.4 samples/s | 80.4 steps/s
[Step=2500 Epoch= 4.7] | Loss=0.05354 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.826 | L2-Norm(final)=4.410 | 5383.1 samples/s | 84.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.7] | Loss=0.03493 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.825 | L2-Norm(final)=4.996 | 4016.7 samples/s | 62.8 steps/s
[Step=2550 Epoch= 4.8] | Loss=0.03209 | Reg=0.00288 | acc=0.9531 | L2-Norm=16.975 | L2-Norm(final)=5.007 | 4226.6 samples/s | 66.0 steps/s
[Step=2600 Epoch= 4.9] | Loss=0.02498 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.072 | L2-Norm(final)=4.994 | 4478.6 samples/s | 70.0 steps/s
[Step=2650 Epoch= 5.0] | Loss=0.02056 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.117 | L2-Norm(final)=4.988 | 4546.5 samples/s | 71.0 steps/s
[Step=2700 Epoch= 5.1] | Loss=0.01815 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.131 | L2-Norm(final)=4.982 | 4445.4 samples/s | 69.5 steps/s
[Step=2750 Epoch= 5.2] | Loss=0.01603 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.134 | L2-Norm(final)=4.979 | 4610.0 samples/s | 72.0 steps/s
[Step=2800 Epoch= 5.3] | Loss=0.01450 | Reg=0.00293 | acc=0.9375 | L2-Norm=17.131 | L2-Norm(final)=4.978 | 4656.4 samples/s | 72.8 steps/s
[Step=2850 Epoch= 5.4] | Loss=0.01317 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.127 | L2-Norm(final)=4.976 | 4634.9 samples/s | 72.4 steps/s
[Step=2900 Epoch= 5.5] | Loss=0.01195 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.120 | L2-Norm(final)=4.975 | 4712.0 samples/s | 73.6 steps/s
[Step=2950 Epoch= 5.6] | Loss=0.01100 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.108 | L2-Norm(final)=4.974 | 4571.1 samples/s | 71.4 steps/s
[Step=3000 Epoch= 5.7] | Loss=0.01022 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.094 | L2-Norm(final)=4.973 | 4670.9 samples/s | 73.0 steps/s
[Step=3050 Epoch= 5.7] | Loss=0.00960 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.080 | L2-Norm(final)=4.972 | 2167.0 samples/s | 33.9 steps/s
[Step=3100 Epoch= 5.8] | Loss=0.00893 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.065 | L2-Norm(final)=4.972 | 4601.0 samples/s | 71.9 steps/s
[Step=3150 Epoch= 5.9] | Loss=0.00844 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.049 | L2-Norm(final)=4.971 | 4635.3 samples/s | 72.4 steps/s
[Step=3200 Epoch= 6.0] | Loss=0.00798 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.032 | L2-Norm(final)=4.971 | 4702.3 samples/s | 73.5 steps/s
[Step=3250 Epoch= 6.1] | Loss=0.00760 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.014 | L2-Norm(final)=4.972 | 4516.5 samples/s | 70.6 steps/s
[Step=3300 Epoch= 6.2] | Loss=0.00731 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.997 | L2-Norm(final)=4.972 | 4643.1 samples/s | 72.5 steps/s
[Step=3350 Epoch= 6.3] | Loss=0.00700 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.980 | L2-Norm(final)=4.972 | 4595.8 samples/s | 71.8 steps/s
[Step=3400 Epoch= 6.4] | Loss=0.00667 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.962 | L2-Norm(final)=4.972 | 4670.0 samples/s | 73.0 steps/s
[Step=3450 Epoch= 6.5] | Loss=0.00635 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.944 | L2-Norm(final)=4.973 | 4642.1 samples/s | 72.5 steps/s
[Step=3500 Epoch= 6.6] | Loss=0.00607 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.924 | L2-Norm(final)=4.973 | 4614.3 samples/s | 72.1 steps/s
[Step=3550 Epoch= 6.7] | Loss=0.00579 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.905 | L2-Norm(final)=4.974 | 5742.7 samples/s | 89.7 steps/s
[Step=3600 Epoch= 6.8] | Loss=0.00553 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=4.975 | 1950.4 samples/s | 30.5 steps/s
[Step=3650 Epoch= 6.9] | Loss=0.00530 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.863 | L2-Norm(final)=4.975 | 4624.3 samples/s | 72.3 steps/s
[Step=3700 Epoch= 7.0] | Loss=0.00510 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.841 | L2-Norm(final)=4.976 | 4601.8 samples/s | 71.9 steps/s
[Step=3750 Epoch= 7.1] | Loss=0.00489 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.818 | L2-Norm(final)=4.977 | 4631.0 samples/s | 72.4 steps/s
[Step=3800 Epoch= 7.2] | Loss=0.00479 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.796 | L2-Norm(final)=4.977 | 4669.5 samples/s | 73.0 steps/s
[Step=3850 Epoch= 7.3] | Loss=0.00483 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.777 | L2-Norm(final)=4.978 | 4588.6 samples/s | 71.7 steps/s
[Step=3900 Epoch= 7.4] | Loss=0.00474 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.760 | L2-Norm(final)=4.978 | 4606.6 samples/s | 72.0 steps/s
[Step=3950 Epoch= 7.4] | Loss=0.00471 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=4.977 | 4651.7 samples/s | 72.7 steps/s
[Step=4000 Epoch= 7.5] | Loss=0.00499 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.731 | L2-Norm(final)=4.976 | 4568.2 samples/s | 71.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06041 | acc=0.9553 | tpr=0.9536 | fpr=0.0409 | 4230.8 samples/s | 16.5 steps/s
Avg test loss: 0.06272, Avg test acc: 0.95392, Avg tpr: 0.95174, Avg fpr: 0.04128, total FA: 322

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.60223 | acc=0.3095 | tpr=0.0547 | fpr=0.1373 | 4107.0 samples/s | 16.0 steps/s
Avg test loss: 3.60071, Avg test acc: 0.30760, Avg tpr: 0.05490, Avg fpr: 0.13665, total FA: 1066

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.76516 | acc=0.1645 | tpr=0.4779 | fpr=0.8412 | 4205.4 samples/s | 16.4 steps/s
[Step= 100] | Loss=2.75456 | acc=0.1655 | tpr=0.4584 | fpr=0.8400 | 7810.9 samples/s | 30.5 steps/s
[Step= 150] | Loss=2.75819 | acc=0.1640 | tpr=0.4827 | fpr=0.8418 | 7958.1 samples/s | 31.1 steps/s
[Step= 200] | Loss=2.74742 | acc=0.1641 | tpr=0.4776 | fpr=0.8416 | 8146.0 samples/s | 31.8 steps/s
[Step= 250] | Loss=2.74681 | acc=0.1643 | tpr=0.4838 | fpr=0.8415 | 8125.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=2.74398 | acc=0.1645 | tpr=0.4880 | fpr=0.8414 | 7877.9 samples/s | 30.8 steps/s
[Step= 350] | Loss=2.74125 | acc=0.1646 | tpr=0.4796 | fpr=0.8412 | 7837.4 samples/s | 30.6 steps/s
[Step= 400] | Loss=2.74011 | acc=0.1647 | tpr=0.4732 | fpr=0.8409 | 8186.0 samples/s | 32.0 steps/s
[Step= 450] | Loss=2.74204 | acc=0.1646 | tpr=0.4727 | fpr=0.8410 | 7691.6 samples/s | 30.0 steps/s
[Step= 500] | Loss=2.74346 | acc=0.1645 | tpr=0.4692 | fpr=0.8410 | 8117.2 samples/s | 31.7 steps/s
[Step= 550] | Loss=2.74344 | acc=0.1645 | tpr=0.4704 | fpr=0.8410 | 14437.6 samples/s | 56.4 steps/s
Avg test loss: 2.74423, Avg test acc: 0.16444, Avg tpr: 0.47108, Avg fpr: 0.84114, total FA: 116790

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11522 | acc=0.9605 | tpr=0.9690 | fpr=0.0396 | 4211.1 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.11687 | acc=0.9604 | tpr=0.9787 | fpr=0.0400 | 8026.1 samples/s | 31.4 steps/s
[Step= 150] | Loss=0.12075 | acc=0.9599 | tpr=0.9798 | fpr=0.0404 | 7934.1 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.12104 | acc=0.9603 | tpr=0.9825 | fpr=0.0402 | 8065.2 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.12078 | acc=0.9601 | tpr=0.9808 | fpr=0.0403 | 7974.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.12264 | acc=0.9597 | tpr=0.9789 | fpr=0.0406 | 7890.4 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.12385 | acc=0.9595 | tpr=0.9787 | fpr=0.0409 | 7985.4 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.12475 | acc=0.9593 | tpr=0.9770 | fpr=0.0410 | 8271.6 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.12624 | acc=0.9590 | tpr=0.9757 | fpr=0.0413 | 7989.6 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.12620 | acc=0.9589 | tpr=0.9762 | fpr=0.0414 | 7428.4 samples/s | 29.0 steps/s
[Step= 550] | Loss=0.12510 | acc=0.9591 | tpr=0.9753 | fpr=0.0412 | 15206.4 samples/s | 59.4 steps/s
Avg test loss: 0.12489, Avg test acc: 0.95918, Avg tpr: 0.97544, Avg fpr: 0.04112, total FA: 5709

server round 2/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=4001 Epoch= 3.9] | Loss=0.16099 | Reg=0.00267 | acc=0.8594 | L2-Norm=16.342 | L2-Norm(final)=3.928 | 4064.3 samples/s | 63.5 steps/s
[Step=4050 Epoch= 4.0] | Loss=0.14654 | Reg=0.00267 | acc=0.8438 | L2-Norm=16.348 | L2-Norm(final)=3.986 | 5472.8 samples/s | 85.5 steps/s
[Step=4100 Epoch= 4.0] | Loss=0.14441 | Reg=0.00267 | acc=0.8594 | L2-Norm=16.349 | L2-Norm(final)=4.072 | 5569.1 samples/s | 87.0 steps/s
[Step=4150 Epoch= 4.1] | Loss=0.14084 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.349 | L2-Norm(final)=4.159 | 5558.7 samples/s | 86.9 steps/s
[Step=4200 Epoch= 4.1] | Loss=0.13864 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.349 | L2-Norm(final)=4.241 | 5624.7 samples/s | 87.9 steps/s
[Step=4250 Epoch= 4.1] | Loss=0.13731 | Reg=0.00267 | acc=0.8750 | L2-Norm=16.349 | L2-Norm(final)=4.319 | 5612.5 samples/s | 87.7 steps/s
[Step=4300 Epoch= 4.2] | Loss=0.13645 | Reg=0.00267 | acc=0.9062 | L2-Norm=16.349 | L2-Norm(final)=4.391 | 5530.9 samples/s | 86.4 steps/s
[Step=4350 Epoch= 4.2] | Loss=0.13464 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.350 | L2-Norm(final)=4.459 | 5628.5 samples/s | 87.9 steps/s
[Step=4400 Epoch= 4.3] | Loss=0.13418 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.350 | L2-Norm(final)=4.525 | 5671.1 samples/s | 88.6 steps/s
[Step=4450 Epoch= 4.3] | Loss=0.13339 | Reg=0.00267 | acc=0.8594 | L2-Norm=16.350 | L2-Norm(final)=4.588 | 5552.9 samples/s | 86.8 steps/s
[Step=4500 Epoch= 4.4] | Loss=0.13255 | Reg=0.00267 | acc=0.9062 | L2-Norm=16.350 | L2-Norm(final)=4.649 | 5596.4 samples/s | 87.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 4.4] | Loss=0.19650 | Reg=0.00267 | acc=0.7969 | L2-Norm=16.350 | L2-Norm(final)=5.240 | 4310.9 samples/s | 67.4 steps/s
[Step=4550 Epoch= 4.4] | Loss=0.10775 | Reg=0.00272 | acc=0.9531 | L2-Norm=16.498 | L2-Norm(final)=5.252 | 4358.9 samples/s | 68.1 steps/s
[Step=4600 Epoch= 4.5] | Loss=0.10050 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.622 | L2-Norm(final)=5.243 | 4880.9 samples/s | 76.3 steps/s
[Step=4650 Epoch= 4.5] | Loss=0.09211 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.709 | L2-Norm(final)=5.236 | 4774.6 samples/s | 74.6 steps/s
[Step=4700 Epoch= 4.6] | Loss=0.08776 | Reg=0.00282 | acc=0.9219 | L2-Norm=16.777 | L2-Norm(final)=5.229 | 4839.1 samples/s | 75.6 steps/s
[Step=4750 Epoch= 4.6] | Loss=0.08491 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.831 | L2-Norm(final)=5.222 | 4903.8 samples/s | 76.6 steps/s
[Step=4800 Epoch= 4.7] | Loss=0.08152 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.882 | L2-Norm(final)=5.217 | 4779.2 samples/s | 74.7 steps/s
[Step=4850 Epoch= 4.7] | Loss=0.07843 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.925 | L2-Norm(final)=5.212 | 4818.4 samples/s | 75.3 steps/s
[Step=4900 Epoch= 4.8] | Loss=0.07701 | Reg=0.00288 | acc=0.9688 | L2-Norm=16.965 | L2-Norm(final)=5.208 | 4848.5 samples/s | 75.8 steps/s
[Step=4950 Epoch= 4.8] | Loss=0.07534 | Reg=0.00289 | acc=0.9062 | L2-Norm=17.004 | L2-Norm(final)=5.205 | 4837.8 samples/s | 75.6 steps/s
[Step=5000 Epoch= 4.9] | Loss=0.07334 | Reg=0.00290 | acc=0.9375 | L2-Norm=17.040 | L2-Norm(final)=5.202 | 4881.9 samples/s | 76.3 steps/s
[Step=5050 Epoch= 4.9] | Loss=0.07212 | Reg=0.00292 | acc=0.9688 | L2-Norm=17.074 | L2-Norm(final)=5.199 | 4819.3 samples/s | 75.3 steps/s
[Step=5100 Epoch= 5.0] | Loss=0.07155 | Reg=0.00293 | acc=0.9531 | L2-Norm=17.104 | L2-Norm(final)=5.194 | 4804.7 samples/s | 75.1 steps/s
[Step=5150 Epoch= 5.0] | Loss=0.07042 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.131 | L2-Norm(final)=5.190 | 4811.0 samples/s | 75.2 steps/s
[Step=5200 Epoch= 5.1] | Loss=0.06983 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.157 | L2-Norm(final)=5.187 | 4897.2 samples/s | 76.5 steps/s
[Step=5250 Epoch= 5.1] | Loss=0.06891 | Reg=0.00295 | acc=0.9531 | L2-Norm=17.180 | L2-Norm(final)=5.183 | 4799.5 samples/s | 75.0 steps/s
[Step=5300 Epoch= 5.2] | Loss=0.06823 | Reg=0.00296 | acc=0.9531 | L2-Norm=17.204 | L2-Norm(final)=5.179 | 4821.4 samples/s | 75.3 steps/s
[Step=5350 Epoch= 5.2] | Loss=0.06698 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.227 | L2-Norm(final)=5.176 | 4879.9 samples/s | 76.2 steps/s
[Step=5400 Epoch= 5.3] | Loss=0.06612 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.249 | L2-Norm(final)=5.173 | 4855.6 samples/s | 75.9 steps/s
[Step=5450 Epoch= 5.3] | Loss=0.06509 | Reg=0.00298 | acc=0.9844 | L2-Norm=17.271 | L2-Norm(final)=5.169 | 4813.8 samples/s | 75.2 steps/s
[Step=5500 Epoch= 5.4] | Loss=0.06398 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.292 | L2-Norm(final)=5.166 | 5200.6 samples/s | 81.3 steps/s
[Step=5550 Epoch= 5.4] | Loss=0.06290 | Reg=0.00300 | acc=0.9688 | L2-Norm=17.312 | L2-Norm(final)=5.164 | 2151.2 samples/s | 33.6 steps/s
[Step=5600 Epoch= 5.5] | Loss=0.06189 | Reg=0.00301 | acc=0.9375 | L2-Norm=17.332 | L2-Norm(final)=5.161 | 4860.6 samples/s | 75.9 steps/s
[Step=5650 Epoch= 5.5] | Loss=0.06108 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.352 | L2-Norm(final)=5.159 | 4860.6 samples/s | 75.9 steps/s
[Step=5700 Epoch= 5.6] | Loss=0.06042 | Reg=0.00302 | acc=0.9531 | L2-Norm=17.371 | L2-Norm(final)=5.157 | 4863.6 samples/s | 76.0 steps/s
[Step=5750 Epoch= 5.6] | Loss=0.05997 | Reg=0.00303 | acc=0.9375 | L2-Norm=17.389 | L2-Norm(final)=5.154 | 4859.9 samples/s | 75.9 steps/s
[Step=5800 Epoch= 5.7] | Loss=0.05905 | Reg=0.00303 | acc=0.9844 | L2-Norm=17.407 | L2-Norm(final)=5.151 | 4800.8 samples/s | 75.0 steps/s
[Step=5850 Epoch= 5.7] | Loss=0.05853 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.423 | L2-Norm(final)=5.149 | 4771.6 samples/s | 74.6 steps/s
[Step=5900 Epoch= 5.8] | Loss=0.05795 | Reg=0.00304 | acc=0.9531 | L2-Norm=17.440 | L2-Norm(final)=5.147 | 4840.5 samples/s | 75.6 steps/s
[Step=5950 Epoch= 5.8] | Loss=0.05724 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.456 | L2-Norm(final)=5.145 | 4808.9 samples/s | 75.1 steps/s
[Step=6000 Epoch= 5.9] | Loss=0.05664 | Reg=0.00305 | acc=0.9531 | L2-Norm=17.473 | L2-Norm(final)=5.142 | 4806.9 samples/s | 75.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step6000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=4001 Epoch= 7.5] | Loss=0.04254 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.342 | L2-Norm(final)=4.906 | 4171.6 samples/s | 65.2 steps/s
[Step=4050 Epoch= 7.6] | Loss=0.07784 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.351 | L2-Norm(final)=4.904 | 4823.2 samples/s | 75.4 steps/s
[Step=4100 Epoch= 7.7] | Loss=0.06281 | Reg=0.00267 | acc=0.9219 | L2-Norm=16.353 | L2-Norm(final)=4.954 | 5244.2 samples/s | 81.9 steps/s
[Step=4150 Epoch= 7.8] | Loss=0.05602 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.354 | L2-Norm(final)=5.042 | 5266.3 samples/s | 82.3 steps/s
[Step=4200 Epoch= 7.9] | Loss=0.05300 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.354 | L2-Norm(final)=5.144 | 5334.6 samples/s | 83.4 steps/s
[Step=4250 Epoch= 8.0] | Loss=0.05081 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.354 | L2-Norm(final)=5.243 | 5202.6 samples/s | 81.3 steps/s
[Step=4300 Epoch= 8.1] | Loss=0.04928 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=5.337 | 5293.9 samples/s | 82.7 steps/s
[Step=4350 Epoch= 8.2] | Loss=0.04778 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=5.428 | 5272.3 samples/s | 82.4 steps/s
[Step=4400 Epoch= 8.3] | Loss=0.04611 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=5.516 | 5390.4 samples/s | 84.2 steps/s
[Step=4450 Epoch= 8.4] | Loss=0.04492 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=5.603 | 5289.8 samples/s | 82.7 steps/s
[Step=4500 Epoch= 8.5] | Loss=0.04412 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=5.684 | 5233.1 samples/s | 81.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.5] | Loss=0.02409 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=6.470 | 4055.4 samples/s | 63.4 steps/s
[Step=4550 Epoch= 8.6] | Loss=0.02952 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.503 | L2-Norm(final)=6.483 | 4347.5 samples/s | 67.9 steps/s
[Step=4600 Epoch= 8.7] | Loss=0.01999 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.633 | L2-Norm(final)=6.470 | 4592.6 samples/s | 71.8 steps/s
[Step=4650 Epoch= 8.8] | Loss=0.01557 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.678 | L2-Norm(final)=6.464 | 4608.0 samples/s | 72.0 steps/s
[Step=4700 Epoch= 8.9] | Loss=0.01307 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.695 | L2-Norm(final)=6.461 | 4603.9 samples/s | 71.9 steps/s
[Step=4750 Epoch= 9.0] | Loss=0.01191 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.700 | L2-Norm(final)=6.457 | 4581.3 samples/s | 71.6 steps/s
[Step=4800 Epoch= 9.0] | Loss=0.01056 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.702 | L2-Norm(final)=6.454 | 4590.4 samples/s | 71.7 steps/s
[Step=4850 Epoch= 9.1] | Loss=0.00966 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.697 | L2-Norm(final)=6.452 | 4684.5 samples/s | 73.2 steps/s
[Step=4900 Epoch= 9.2] | Loss=0.00898 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.687 | L2-Norm(final)=6.450 | 4620.2 samples/s | 72.2 steps/s
[Step=4950 Epoch= 9.3] | Loss=0.00836 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.676 | L2-Norm(final)=6.448 | 4575.3 samples/s | 71.5 steps/s
[Step=5000 Epoch= 9.4] | Loss=0.00761 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.663 | L2-Norm(final)=6.448 | 4671.0 samples/s | 73.0 steps/s
[Step=5050 Epoch= 9.5] | Loss=0.00701 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.646 | L2-Norm(final)=6.447 | 2109.7 samples/s | 33.0 steps/s
[Step=5100 Epoch= 9.6] | Loss=0.00643 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.627 | L2-Norm(final)=6.447 | 4751.5 samples/s | 74.2 steps/s
[Step=5150 Epoch= 9.7] | Loss=0.00604 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.605 | L2-Norm(final)=6.447 | 4562.7 samples/s | 71.3 steps/s
[Step=5200 Epoch= 9.8] | Loss=0.00564 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=6.447 | 4643.7 samples/s | 72.6 steps/s
[Step=5250 Epoch= 9.9] | Loss=0.00527 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.558 | L2-Norm(final)=6.448 | 4581.1 samples/s | 71.6 steps/s
[Step=5300 Epoch=10.0] | Loss=0.00495 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.533 | L2-Norm(final)=6.448 | 4637.3 samples/s | 72.5 steps/s
[Step=5350 Epoch=10.1] | Loss=0.00466 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.506 | L2-Norm(final)=6.449 | 4630.8 samples/s | 72.4 steps/s
[Step=5400 Epoch=10.2] | Loss=0.00441 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=6.449 | 4639.1 samples/s | 72.5 steps/s
[Step=5450 Epoch=10.3] | Loss=0.00418 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.451 | L2-Norm(final)=6.450 | 4609.9 samples/s | 72.0 steps/s
[Step=5500 Epoch=10.4] | Loss=0.00398 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=6.451 | 4747.5 samples/s | 74.2 steps/s
[Step=5550 Epoch=10.5] | Loss=0.00379 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.393 | L2-Norm(final)=6.452 | 5641.5 samples/s | 88.1 steps/s
[Step=5600 Epoch=10.6] | Loss=0.00362 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.364 | L2-Norm(final)=6.452 | 1958.9 samples/s | 30.6 steps/s
[Step=5650 Epoch=10.7] | Loss=0.00346 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.334 | L2-Norm(final)=6.453 | 4525.5 samples/s | 70.7 steps/s
[Step=5700 Epoch=10.7] | Loss=0.00332 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=6.454 | 4619.7 samples/s | 72.2 steps/s
[Step=5750 Epoch=10.8] | Loss=0.00319 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.273 | L2-Norm(final)=6.455 | 4633.9 samples/s | 72.4 steps/s
[Step=5800 Epoch=10.9] | Loss=0.00307 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.242 | L2-Norm(final)=6.455 | 4543.4 samples/s | 71.0 steps/s
[Step=5850 Epoch=11.0] | Loss=0.00295 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.211 | L2-Norm(final)=6.456 | 4650.8 samples/s | 72.7 steps/s
[Step=5900 Epoch=11.1] | Loss=0.00285 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.179 | L2-Norm(final)=6.456 | 4612.7 samples/s | 72.1 steps/s
[Step=5950 Epoch=11.2] | Loss=0.00275 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.147 | L2-Norm(final)=6.457 | 4606.3 samples/s | 72.0 steps/s
[Step=6000 Epoch=11.3] | Loss=0.00266 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=6.458 | 4622.1 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06127 | acc=0.9571 | tpr=0.9516 | fpr=0.0310 | 4266.7 samples/s | 16.7 steps/s
Avg test loss: 0.06667, Avg test acc: 0.95212, Avg tpr: 0.94504, Avg fpr: 0.03230, total FA: 252

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.66860 | acc=0.3154 | tpr=0.0145 | fpr=0.0312 | 4215.7 samples/s | 16.5 steps/s
Avg test loss: 7.68566, Avg test acc: 0.31325, Avg tpr: 0.01550, Avg fpr: 0.03192, total FA: 249

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.44983 | acc=0.1498 | tpr=0.5619 | fpr=0.8576 | 4189.4 samples/s | 16.4 steps/s
[Step= 100] | Loss=3.43989 | acc=0.1495 | tpr=0.5160 | fpr=0.8573 | 7747.7 samples/s | 30.3 steps/s
[Step= 150] | Loss=3.43408 | acc=0.1488 | tpr=0.5130 | fpr=0.8579 | 8349.9 samples/s | 32.6 steps/s
[Step= 200] | Loss=3.42853 | acc=0.1496 | tpr=0.5071 | fpr=0.8569 | 8000.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=3.42620 | acc=0.1493 | tpr=0.5022 | fpr=0.8571 | 7790.2 samples/s | 30.4 steps/s
[Step= 300] | Loss=3.42514 | acc=0.1497 | tpr=0.5113 | fpr=0.8569 | 8179.7 samples/s | 32.0 steps/s
[Step= 350] | Loss=3.42189 | acc=0.1499 | tpr=0.5116 | fpr=0.8567 | 7784.1 samples/s | 30.4 steps/s
[Step= 400] | Loss=3.42072 | acc=0.1499 | tpr=0.5098 | fpr=0.8567 | 7989.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=3.42471 | acc=0.1495 | tpr=0.5088 | fpr=0.8570 | 8097.4 samples/s | 31.6 steps/s
[Step= 500] | Loss=3.42732 | acc=0.1494 | tpr=0.5097 | fpr=0.8571 | 7790.9 samples/s | 30.4 steps/s
[Step= 550] | Loss=3.42788 | acc=0.1493 | tpr=0.5078 | fpr=0.8572 | 15188.4 samples/s | 59.3 steps/s
Avg test loss: 3.42876, Avg test acc: 0.14931, Avg tpr: 0.50872, Avg fpr: 0.85723, total FA: 119024

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13952 | acc=0.9796 | tpr=0.9469 | fpr=0.0198 | 4212.2 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.14552 | acc=0.9796 | tpr=0.9595 | fpr=0.0201 | 7804.3 samples/s | 30.5 steps/s
[Step= 150] | Loss=0.15101 | acc=0.9787 | tpr=0.9625 | fpr=0.0210 | 8196.2 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.15212 | acc=0.9788 | tpr=0.9650 | fpr=0.0209 | 8014.5 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.15006 | acc=0.9789 | tpr=0.9624 | fpr=0.0208 | 7816.6 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.15296 | acc=0.9786 | tpr=0.9600 | fpr=0.0211 | 8597.1 samples/s | 33.6 steps/s
[Step= 350] | Loss=0.15369 | acc=0.9785 | tpr=0.9606 | fpr=0.0212 | 7454.2 samples/s | 29.1 steps/s
[Step= 400] | Loss=0.15569 | acc=0.9782 | tpr=0.9568 | fpr=0.0214 | 8106.5 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.15807 | acc=0.9781 | tpr=0.9562 | fpr=0.0215 | 7939.8 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15855 | acc=0.9781 | tpr=0.9568 | fpr=0.0216 | 7717.8 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.15694 | acc=0.9783 | tpr=0.9554 | fpr=0.0213 | 14968.2 samples/s | 58.5 steps/s
Avg test loss: 0.15673, Avg test acc: 0.97831, Avg tpr: 0.95523, Avg fpr: 0.02128, total FA: 2954

server round 3/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=6001 Epoch= 5.9] | Loss=0.09092 | Reg=0.00250 | acc=0.9375 | L2-Norm=15.813 | L2-Norm(final)=5.076 | 4201.4 samples/s | 65.6 steps/s
[Step=6050 Epoch= 5.9] | Loss=0.09269 | Reg=0.00250 | acc=0.9375 | L2-Norm=15.816 | L2-Norm(final)=5.080 | 5241.3 samples/s | 81.9 steps/s
[Step=6100 Epoch= 6.0] | Loss=0.09418 | Reg=0.00250 | acc=0.9062 | L2-Norm=15.817 | L2-Norm(final)=5.114 | 5471.6 samples/s | 85.5 steps/s
[Step=6150 Epoch= 6.0] | Loss=0.09027 | Reg=0.00250 | acc=0.8906 | L2-Norm=15.817 | L2-Norm(final)=5.147 | 5688.9 samples/s | 88.9 steps/s
[Step=6200 Epoch= 6.1] | Loss=0.09073 | Reg=0.00250 | acc=0.9062 | L2-Norm=15.817 | L2-Norm(final)=5.184 | 5475.0 samples/s | 85.5 steps/s
[Step=6250 Epoch= 6.1] | Loss=0.09009 | Reg=0.00250 | acc=0.8906 | L2-Norm=15.817 | L2-Norm(final)=5.215 | 5498.7 samples/s | 85.9 steps/s
[Step=6300 Epoch= 6.2] | Loss=0.09046 | Reg=0.00250 | acc=0.9219 | L2-Norm=15.817 | L2-Norm(final)=5.245 | 5747.9 samples/s | 89.8 steps/s
[Step=6350 Epoch= 6.2] | Loss=0.09012 | Reg=0.00250 | acc=0.9375 | L2-Norm=15.817 | L2-Norm(final)=5.272 | 5437.5 samples/s | 85.0 steps/s
[Step=6400 Epoch= 6.2] | Loss=0.08981 | Reg=0.00250 | acc=0.9219 | L2-Norm=15.817 | L2-Norm(final)=5.299 | 5688.7 samples/s | 88.9 steps/s
[Step=6450 Epoch= 6.3] | Loss=0.08934 | Reg=0.00250 | acc=0.8906 | L2-Norm=15.817 | L2-Norm(final)=5.324 | 5623.6 samples/s | 87.9 steps/s
[Step=6500 Epoch= 6.3] | Loss=0.08955 | Reg=0.00250 | acc=0.8906 | L2-Norm=15.817 | L2-Norm(final)=5.347 | 5563.8 samples/s | 86.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch= 6.3] | Loss=0.13649 | Reg=0.00250 | acc=0.9062 | L2-Norm=15.817 | L2-Norm(final)=5.582 | 3910.3 samples/s | 61.1 steps/s
[Step=6550 Epoch= 6.4] | Loss=0.07710 | Reg=0.00254 | acc=0.9219 | L2-Norm=15.922 | L2-Norm(final)=5.592 | 4832.1 samples/s | 75.5 steps/s
[Step=6600 Epoch= 6.4] | Loss=0.07327 | Reg=0.00257 | acc=0.9375 | L2-Norm=16.034 | L2-Norm(final)=5.587 | 4907.4 samples/s | 76.7 steps/s
[Step=6650 Epoch= 6.5] | Loss=0.07002 | Reg=0.00260 | acc=0.9531 | L2-Norm=16.124 | L2-Norm(final)=5.584 | 4880.2 samples/s | 76.3 steps/s
[Step=6700 Epoch= 6.5] | Loss=0.06975 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.202 | L2-Norm(final)=5.576 | 4826.8 samples/s | 75.4 steps/s
[Step=6750 Epoch= 6.6] | Loss=0.06756 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.267 | L2-Norm(final)=5.570 | 4870.2 samples/s | 76.1 steps/s
[Step=6800 Epoch= 6.6] | Loss=0.06601 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.324 | L2-Norm(final)=5.563 | 4903.0 samples/s | 76.6 steps/s
[Step=6850 Epoch= 6.7] | Loss=0.06363 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.375 | L2-Norm(final)=5.558 | 4930.0 samples/s | 77.0 steps/s
[Step=6900 Epoch= 6.7] | Loss=0.06224 | Reg=0.00270 | acc=0.9062 | L2-Norm=16.421 | L2-Norm(final)=5.553 | 4831.1 samples/s | 75.5 steps/s
[Step=6950 Epoch= 6.8] | Loss=0.06156 | Reg=0.00271 | acc=0.9375 | L2-Norm=16.465 | L2-Norm(final)=5.548 | 4894.1 samples/s | 76.5 steps/s
[Step=7000 Epoch= 6.8] | Loss=0.06044 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.507 | L2-Norm(final)=5.544 | 4821.5 samples/s | 75.3 steps/s
[Step=7050 Epoch= 6.9] | Loss=0.05984 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.547 | L2-Norm(final)=5.539 | 4794.6 samples/s | 74.9 steps/s
[Step=7100 Epoch= 6.9] | Loss=0.05890 | Reg=0.00275 | acc=0.9531 | L2-Norm=16.586 | L2-Norm(final)=5.535 | 4873.7 samples/s | 76.2 steps/s
[Step=7150 Epoch= 7.0] | Loss=0.05776 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=5.531 | 4860.3 samples/s | 75.9 steps/s
[Step=7200 Epoch= 7.0] | Loss=0.05691 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.658 | L2-Norm(final)=5.527 | 4861.6 samples/s | 76.0 steps/s
[Step=7250 Epoch= 7.1] | Loss=0.05664 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.693 | L2-Norm(final)=5.522 | 4890.0 samples/s | 76.4 steps/s
[Step=7300 Epoch= 7.1] | Loss=0.05583 | Reg=0.00280 | acc=0.9375 | L2-Norm=16.727 | L2-Norm(final)=5.517 | 4863.0 samples/s | 76.0 steps/s
[Step=7350 Epoch= 7.2] | Loss=0.05560 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.760 | L2-Norm(final)=5.512 | 4803.3 samples/s | 75.1 steps/s
[Step=7400 Epoch= 7.2] | Loss=0.05484 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.791 | L2-Norm(final)=5.507 | 4837.3 samples/s | 75.6 steps/s
[Step=7450 Epoch= 7.3] | Loss=0.05449 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.820 | L2-Norm(final)=5.502 | 4875.0 samples/s | 76.2 steps/s
[Step=7500 Epoch= 7.3] | Loss=0.05378 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.848 | L2-Norm(final)=5.498 | 5177.2 samples/s | 80.9 steps/s
[Step=7550 Epoch= 7.4] | Loss=0.05292 | Reg=0.00285 | acc=0.9688 | L2-Norm=16.875 | L2-Norm(final)=5.493 | 2166.4 samples/s | 33.9 steps/s
[Step=7600 Epoch= 7.4] | Loss=0.05218 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.900 | L2-Norm(final)=5.489 | 4866.6 samples/s | 76.0 steps/s
[Step=7650 Epoch= 7.5] | Loss=0.05162 | Reg=0.00287 | acc=0.9688 | L2-Norm=16.925 | L2-Norm(final)=5.485 | 4845.5 samples/s | 75.7 steps/s
[Step=7700 Epoch= 7.5] | Loss=0.05099 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.948 | L2-Norm(final)=5.480 | 4885.1 samples/s | 76.3 steps/s
[Step=7750 Epoch= 7.6] | Loss=0.05056 | Reg=0.00288 | acc=0.9531 | L2-Norm=16.971 | L2-Norm(final)=5.477 | 4789.6 samples/s | 74.8 steps/s
[Step=7800 Epoch= 7.6] | Loss=0.04986 | Reg=0.00289 | acc=0.9062 | L2-Norm=16.993 | L2-Norm(final)=5.473 | 4867.4 samples/s | 76.1 steps/s
[Step=7850 Epoch= 7.7] | Loss=0.04953 | Reg=0.00290 | acc=0.9688 | L2-Norm=17.014 | L2-Norm(final)=5.470 | 4829.9 samples/s | 75.5 steps/s
[Step=7900 Epoch= 7.7] | Loss=0.04897 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.035 | L2-Norm(final)=5.466 | 4868.6 samples/s | 76.1 steps/s
[Step=7950 Epoch= 7.8] | Loss=0.04862 | Reg=0.00291 | acc=0.9688 | L2-Norm=17.055 | L2-Norm(final)=5.462 | 4827.2 samples/s | 75.4 steps/s
[Step=8000 Epoch= 7.8] | Loss=0.04800 | Reg=0.00292 | acc=0.9219 | L2-Norm=17.075 | L2-Norm(final)=5.459 | 4847.9 samples/s | 75.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step8000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=6001 Epoch=11.3] | Loss=0.01409 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.813 | L2-Norm(final)=6.474 | 4028.2 samples/s | 62.9 steps/s
[Step=6050 Epoch=11.4] | Loss=0.02098 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.803 | L2-Norm(final)=6.486 | 4943.0 samples/s | 77.2 steps/s
[Step=6100 Epoch=11.5] | Loss=0.01731 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.802 | L2-Norm(final)=6.535 | 5228.9 samples/s | 81.7 steps/s
[Step=6150 Epoch=11.6] | Loss=0.01640 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=6.604 | 5327.5 samples/s | 83.2 steps/s
[Step=6200 Epoch=11.7] | Loss=0.01517 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.801 | L2-Norm(final)=6.675 | 5310.7 samples/s | 83.0 steps/s
[Step=6250 Epoch=11.8] | Loss=0.01464 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=6.747 | 5261.9 samples/s | 82.2 steps/s
[Step=6300 Epoch=11.9] | Loss=0.01437 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=6.818 | 5364.5 samples/s | 83.8 steps/s
[Step=6350 Epoch=12.0] | Loss=0.01421 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.801 | L2-Norm(final)=6.887 | 5291.4 samples/s | 82.7 steps/s
[Step=6400 Epoch=12.1] | Loss=0.01378 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=6.952 | 5213.2 samples/s | 81.5 steps/s
[Step=6450 Epoch=12.2] | Loss=0.01379 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=7.016 | 5394.9 samples/s | 84.3 steps/s
[Step=6500 Epoch=12.3] | Loss=0.01349 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.800 | L2-Norm(final)=7.077 | 5252.8 samples/s | 82.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.3] | Loss=0.01801 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.800 | L2-Norm(final)=7.693 | 4239.0 samples/s | 66.2 steps/s
[Step=6550 Epoch=12.3] | Loss=0.02099 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.024 | L2-Norm(final)=7.700 | 4216.7 samples/s | 65.9 steps/s
[Step=6600 Epoch=12.4] | Loss=0.02111 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.219 | L2-Norm(final)=7.664 | 4670.8 samples/s | 73.0 steps/s
[Step=6650 Epoch=12.5] | Loss=0.01729 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=7.637 | 4694.3 samples/s | 73.3 steps/s
[Step=6700 Epoch=12.6] | Loss=0.01435 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.380 | L2-Norm(final)=7.620 | 4574.5 samples/s | 71.5 steps/s
[Step=6750 Epoch=12.7] | Loss=0.01220 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.403 | L2-Norm(final)=7.612 | 4637.5 samples/s | 72.5 steps/s
[Step=6800 Epoch=12.8] | Loss=0.01100 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.410 | L2-Norm(final)=7.606 | 4613.8 samples/s | 72.1 steps/s
[Step=6850 Epoch=12.9] | Loss=0.00981 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.414 | L2-Norm(final)=7.601 | 4697.1 samples/s | 73.4 steps/s
[Step=6900 Epoch=13.0] | Loss=0.00904 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=7.596 | 4645.7 samples/s | 72.6 steps/s
[Step=6950 Epoch=13.1] | Loss=0.00875 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=7.590 | 4659.5 samples/s | 72.8 steps/s
[Step=7000 Epoch=13.2] | Loss=0.00938 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.416 | L2-Norm(final)=7.581 | 4672.9 samples/s | 73.0 steps/s
[Step=7050 Epoch=13.3] | Loss=0.00877 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=7.573 | 2154.2 samples/s | 33.7 steps/s
[Step=7100 Epoch=13.4] | Loss=0.00816 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.423 | L2-Norm(final)=7.566 | 4696.6 samples/s | 73.4 steps/s
[Step=7150 Epoch=13.5] | Loss=0.00784 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=7.560 | 4548.2 samples/s | 71.1 steps/s
[Step=7200 Epoch=13.6] | Loss=0.00741 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=7.555 | 4633.4 samples/s | 72.4 steps/s
[Step=7250 Epoch=13.7] | Loss=0.00699 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.412 | L2-Norm(final)=7.550 | 4609.0 samples/s | 72.0 steps/s
[Step=7300 Epoch=13.8] | Loss=0.00668 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=7.546 | 4631.3 samples/s | 72.4 steps/s
[Step=7350 Epoch=13.9] | Loss=0.00631 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.394 | L2-Norm(final)=7.544 | 4603.4 samples/s | 71.9 steps/s
[Step=7400 Epoch=13.9] | Loss=0.00612 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.382 | L2-Norm(final)=7.541 | 4559.4 samples/s | 71.2 steps/s
[Step=7450 Epoch=14.0] | Loss=0.00581 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.368 | L2-Norm(final)=7.538 | 4543.0 samples/s | 71.0 steps/s
[Step=7500 Epoch=14.1] | Loss=0.00555 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.353 | L2-Norm(final)=7.536 | 4586.0 samples/s | 71.7 steps/s
[Step=7550 Epoch=14.2] | Loss=0.00536 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.336 | L2-Norm(final)=7.534 | 5754.1 samples/s | 89.9 steps/s
[Step=7600 Epoch=14.3] | Loss=0.00513 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.318 | L2-Norm(final)=7.532 | 1980.4 samples/s | 30.9 steps/s
[Step=7650 Epoch=14.4] | Loss=0.00492 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.300 | L2-Norm(final)=7.531 | 4605.1 samples/s | 72.0 steps/s
[Step=7700 Epoch=14.5] | Loss=0.00471 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.280 | L2-Norm(final)=7.530 | 4595.9 samples/s | 71.8 steps/s
[Step=7750 Epoch=14.6] | Loss=0.00453 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=7.529 | 4570.7 samples/s | 71.4 steps/s
[Step=7800 Epoch=14.7] | Loss=0.00435 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=7.528 | 4577.0 samples/s | 71.5 steps/s
[Step=7850 Epoch=14.8] | Loss=0.00419 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.215 | L2-Norm(final)=7.527 | 4647.4 samples/s | 72.6 steps/s
[Step=7900 Epoch=14.9] | Loss=0.00405 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.191 | L2-Norm(final)=7.527 | 4576.6 samples/s | 71.5 steps/s
[Step=7950 Epoch=15.0] | Loss=0.00391 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=7.526 | 4636.4 samples/s | 72.4 steps/s
[Step=8000 Epoch=15.1] | Loss=0.00378 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=7.526 | 4619.5 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05937 | acc=0.9610 | tpr=0.9592 | fpr=0.0349 | 4378.1 samples/s | 17.1 steps/s
Avg test loss: 0.06409, Avg test acc: 0.95689, Avg tpr: 0.95401, Avg fpr: 0.03679, total FA: 287

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.06841 | acc=0.3251 | tpr=0.0272 | fpr=0.0280 | 4272.1 samples/s | 16.7 steps/s
Avg test loss: 7.08068, Avg test acc: 0.32210, Avg tpr: 0.02617, Avg fpr: 0.02705, total FA: 211

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.62120 | acc=0.1391 | tpr=0.6681 | fpr=0.8704 | 4091.5 samples/s | 16.0 steps/s
[Step= 100] | Loss=3.61197 | acc=0.1370 | tpr=0.6461 | fpr=0.8725 | 8016.4 samples/s | 31.3 steps/s
[Step= 150] | Loss=3.61684 | acc=0.1370 | tpr=0.6657 | fpr=0.8727 | 8004.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=3.60699 | acc=0.1371 | tpr=0.6721 | fpr=0.8726 | 8087.7 samples/s | 31.6 steps/s
[Step= 250] | Loss=3.60872 | acc=0.1374 | tpr=0.6812 | fpr=0.8725 | 8792.0 samples/s | 34.3 steps/s
[Step= 300] | Loss=3.60599 | acc=0.1380 | tpr=0.6895 | fpr=0.8720 | 7339.3 samples/s | 28.7 steps/s
[Step= 350] | Loss=3.60345 | acc=0.1379 | tpr=0.6963 | fpr=0.8723 | 7944.1 samples/s | 31.0 steps/s
[Step= 400] | Loss=3.60367 | acc=0.1379 | tpr=0.6975 | fpr=0.8722 | 8392.8 samples/s | 32.8 steps/s
[Step= 450] | Loss=3.60789 | acc=0.1375 | tpr=0.7006 | fpr=0.8727 | 7816.4 samples/s | 30.5 steps/s
[Step= 500] | Loss=3.60819 | acc=0.1375 | tpr=0.6991 | fpr=0.8726 | 7788.7 samples/s | 30.4 steps/s
[Step= 550] | Loss=3.60830 | acc=0.1372 | tpr=0.7019 | fpr=0.8730 | 15074.8 samples/s | 58.9 steps/s
Avg test loss: 3.60914, Avg test acc: 0.13714, Avg tpr: 0.70325, Avg fpr: 0.87315, total FA: 121235

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13967 | acc=0.9794 | tpr=0.9381 | fpr=0.0199 | 4208.4 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.14443 | acc=0.9788 | tpr=0.9531 | fpr=0.0207 | 8007.1 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.15190 | acc=0.9779 | tpr=0.9568 | fpr=0.0217 | 7849.0 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.15297 | acc=0.9781 | tpr=0.9617 | fpr=0.0216 | 8095.5 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.15090 | acc=0.9781 | tpr=0.9616 | fpr=0.0216 | 7862.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.15204 | acc=0.9781 | tpr=0.9615 | fpr=0.0216 | 8021.7 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.15450 | acc=0.9778 | tpr=0.9606 | fpr=0.0218 | 8172.2 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.15542 | acc=0.9776 | tpr=0.9573 | fpr=0.0220 | 7810.4 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.15841 | acc=0.9774 | tpr=0.9581 | fpr=0.0223 | 8407.4 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.15708 | acc=0.9775 | tpr=0.9581 | fpr=0.0222 | 7576.5 samples/s | 29.6 steps/s
[Step= 550] | Loss=0.15563 | acc=0.9777 | tpr=0.9594 | fpr=0.0220 | 14879.9 samples/s | 58.1 steps/s
Avg test loss: 0.15540, Avg test acc: 0.97770, Avg tpr: 0.95919, Avg fpr: 0.02196, total FA: 3049

server round 4/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=8001 Epoch= 7.8] | Loss=0.14454 | Reg=0.00244 | acc=0.8438 | L2-Norm=15.618 | L2-Norm(final)=5.350 | 3886.2 samples/s | 60.7 steps/s
[Step=8050 Epoch= 7.9] | Loss=0.12179 | Reg=0.00244 | acc=0.8594 | L2-Norm=15.628 | L2-Norm(final)=5.367 | 5319.9 samples/s | 83.1 steps/s
[Step=8100 Epoch= 7.9] | Loss=0.11568 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.630 | L2-Norm(final)=5.415 | 5274.0 samples/s | 82.4 steps/s
[Step=8150 Epoch= 8.0] | Loss=0.11426 | Reg=0.00244 | acc=0.8750 | L2-Norm=15.630 | L2-Norm(final)=5.462 | 5291.8 samples/s | 82.7 steps/s
[Step=8200 Epoch= 8.0] | Loss=0.11358 | Reg=0.00244 | acc=0.9219 | L2-Norm=15.631 | L2-Norm(final)=5.507 | 5236.0 samples/s | 81.8 steps/s
[Step=8250 Epoch= 8.1] | Loss=0.11244 | Reg=0.00244 | acc=0.9062 | L2-Norm=15.631 | L2-Norm(final)=5.547 | 5214.0 samples/s | 81.5 steps/s
[Step=8300 Epoch= 8.1] | Loss=0.11131 | Reg=0.00244 | acc=0.9219 | L2-Norm=15.631 | L2-Norm(final)=5.586 | 5592.4 samples/s | 87.4 steps/s
[Step=8350 Epoch= 8.2] | Loss=0.11120 | Reg=0.00244 | acc=0.9375 | L2-Norm=15.631 | L2-Norm(final)=5.624 | 5606.1 samples/s | 87.6 steps/s
[Step=8400 Epoch= 8.2] | Loss=0.10983 | Reg=0.00244 | acc=0.9375 | L2-Norm=15.631 | L2-Norm(final)=5.661 | 5604.8 samples/s | 87.6 steps/s
[Step=8450 Epoch= 8.3] | Loss=0.10998 | Reg=0.00244 | acc=0.9062 | L2-Norm=15.631 | L2-Norm(final)=5.698 | 5686.0 samples/s | 88.8 steps/s
[Step=8500 Epoch= 8.3] | Loss=0.11034 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.631 | L2-Norm(final)=5.731 | 5660.9 samples/s | 88.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch= 8.3] | Loss=0.07728 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.632 | L2-Norm(final)=6.058 | 4127.0 samples/s | 64.5 steps/s
[Step=8550 Epoch= 8.3] | Loss=0.07988 | Reg=0.00249 | acc=0.9375 | L2-Norm=15.771 | L2-Norm(final)=6.080 | 4690.1 samples/s | 73.3 steps/s
[Step=8600 Epoch= 8.4] | Loss=0.07327 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.926 | L2-Norm(final)=6.077 | 4870.9 samples/s | 76.1 steps/s
[Step=8650 Epoch= 8.4] | Loss=0.06825 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=6.067 | 4767.8 samples/s | 74.5 steps/s
[Step=8700 Epoch= 8.5] | Loss=0.06774 | Reg=0.00259 | acc=0.9375 | L2-Norm=16.106 | L2-Norm(final)=6.057 | 4847.4 samples/s | 75.7 steps/s
[Step=8750 Epoch= 8.5] | Loss=0.06509 | Reg=0.00262 | acc=0.9531 | L2-Norm=16.174 | L2-Norm(final)=6.050 | 4854.8 samples/s | 75.9 steps/s
[Step=8800 Epoch= 8.6] | Loss=0.06288 | Reg=0.00264 | acc=0.9375 | L2-Norm=16.233 | L2-Norm(final)=6.044 | 4867.7 samples/s | 76.1 steps/s
[Step=8850 Epoch= 8.6] | Loss=0.06218 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.286 | L2-Norm(final)=6.039 | 4794.9 samples/s | 74.9 steps/s
[Step=8900 Epoch= 8.7] | Loss=0.05987 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.336 | L2-Norm(final)=6.034 | 4813.6 samples/s | 75.2 steps/s
[Step=8950 Epoch= 8.7] | Loss=0.05887 | Reg=0.00268 | acc=0.9531 | L2-Norm=16.382 | L2-Norm(final)=6.029 | 4860.9 samples/s | 76.0 steps/s
[Step=9000 Epoch= 8.8] | Loss=0.05907 | Reg=0.00270 | acc=0.9375 | L2-Norm=16.426 | L2-Norm(final)=6.024 | 4883.6 samples/s | 76.3 steps/s
[Step=9050 Epoch= 8.8] | Loss=0.05814 | Reg=0.00271 | acc=0.8750 | L2-Norm=16.467 | L2-Norm(final)=6.019 | 4821.3 samples/s | 75.3 steps/s
[Step=9100 Epoch= 8.9] | Loss=0.05705 | Reg=0.00273 | acc=0.9375 | L2-Norm=16.504 | L2-Norm(final)=6.013 | 4851.8 samples/s | 75.8 steps/s
[Step=9150 Epoch= 8.9] | Loss=0.05601 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.540 | L2-Norm(final)=6.008 | 4882.5 samples/s | 76.3 steps/s
[Step=9200 Epoch= 9.0] | Loss=0.05513 | Reg=0.00275 | acc=0.9531 | L2-Norm=16.574 | L2-Norm(final)=6.003 | 4774.6 samples/s | 74.6 steps/s
[Step=9250 Epoch= 9.0] | Loss=0.05457 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.605 | L2-Norm(final)=5.998 | 4844.2 samples/s | 75.7 steps/s
[Step=9300 Epoch= 9.1] | Loss=0.05386 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.635 | L2-Norm(final)=5.993 | 4848.0 samples/s | 75.8 steps/s
[Step=9350 Epoch= 9.1] | Loss=0.05333 | Reg=0.00278 | acc=0.9531 | L2-Norm=16.664 | L2-Norm(final)=5.987 | 4841.0 samples/s | 75.6 steps/s
[Step=9400 Epoch= 9.2] | Loss=0.05225 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.692 | L2-Norm(final)=5.982 | 4877.0 samples/s | 76.2 steps/s
[Step=9450 Epoch= 9.2] | Loss=0.05153 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.720 | L2-Norm(final)=5.976 | 4851.6 samples/s | 75.8 steps/s
[Step=9500 Epoch= 9.3] | Loss=0.05058 | Reg=0.00281 | acc=0.9531 | L2-Norm=16.746 | L2-Norm(final)=5.971 | 5098.4 samples/s | 79.7 steps/s
[Step=9550 Epoch= 9.3] | Loss=0.04999 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.772 | L2-Norm(final)=5.966 | 2071.8 samples/s | 32.4 steps/s
[Step=9600 Epoch= 9.4] | Loss=0.04937 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.797 | L2-Norm(final)=5.961 | 4655.3 samples/s | 72.7 steps/s
[Step=9650 Epoch= 9.4] | Loss=0.04848 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.822 | L2-Norm(final)=5.956 | 4586.7 samples/s | 71.7 steps/s
[Step=9700 Epoch= 9.5] | Loss=0.04794 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.846 | L2-Norm(final)=5.952 | 4791.5 samples/s | 74.9 steps/s
[Step=9750 Epoch= 9.5] | Loss=0.04747 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.870 | L2-Norm(final)=5.948 | 4634.5 samples/s | 72.4 steps/s
[Step=9800 Epoch= 9.6] | Loss=0.04700 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.892 | L2-Norm(final)=5.944 | 4587.6 samples/s | 71.7 steps/s
[Step=9850 Epoch= 9.6] | Loss=0.04626 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.914 | L2-Norm(final)=5.941 | 4526.4 samples/s | 70.7 steps/s
[Step=9900 Epoch= 9.7] | Loss=0.04588 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.936 | L2-Norm(final)=5.938 | 4606.4 samples/s | 72.0 steps/s
[Step=9950 Epoch= 9.7] | Loss=0.04551 | Reg=0.00288 | acc=0.9219 | L2-Norm=16.958 | L2-Norm(final)=5.935 | 4613.2 samples/s | 72.1 steps/s
[Step=10000 Epoch= 9.8] | Loss=0.04517 | Reg=0.00289 | acc=0.9531 | L2-Norm=16.980 | L2-Norm(final)=5.932 | 4651.2 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step10000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=8001 Epoch=15.1] | Loss=0.00496 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=7.516 | 4017.8 samples/s | 62.8 steps/s
[Step=8050 Epoch=15.2] | Loss=0.01267 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.608 | L2-Norm(final)=7.563 | 4684.3 samples/s | 73.2 steps/s
[Step=8100 Epoch=15.3] | Loss=0.01087 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=7.642 | 5309.0 samples/s | 83.0 steps/s
[Step=8150 Epoch=15.4] | Loss=0.01019 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=7.719 | 5369.7 samples/s | 83.9 steps/s
[Step=8200 Epoch=15.5] | Loss=0.00946 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=7.795 | 5182.5 samples/s | 81.0 steps/s
[Step=8250 Epoch=15.6] | Loss=0.00921 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=7.872 | 5362.8 samples/s | 83.8 steps/s
[Step=8300 Epoch=15.6] | Loss=0.00923 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=7.947 | 5300.3 samples/s | 82.8 steps/s
[Step=8350 Epoch=15.7] | Loss=0.00882 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=8.020 | 5330.2 samples/s | 83.3 steps/s
[Step=8400 Epoch=15.8] | Loss=0.00864 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=8.089 | 5232.9 samples/s | 81.8 steps/s
[Step=8450 Epoch=15.9] | Loss=0.00846 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=8.157 | 5368.0 samples/s | 83.9 steps/s
[Step=8500 Epoch=16.0] | Loss=0.00839 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=8.220 | 5396.6 samples/s | 84.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.0] | Loss=0.00541 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=8.830 | 4204.0 samples/s | 65.7 steps/s
[Step=8550 Epoch=16.1] | Loss=0.00996 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=8.849 | 4164.0 samples/s | 65.1 steps/s
[Step=8600 Epoch=16.2] | Loss=0.01616 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.941 | L2-Norm(final)=8.816 | 4585.5 samples/s | 71.6 steps/s
[Step=8650 Epoch=16.3] | Loss=0.01502 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.099 | L2-Norm(final)=8.793 | 4560.6 samples/s | 71.3 steps/s
[Step=8700 Epoch=16.4] | Loss=0.01386 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.177 | L2-Norm(final)=8.772 | 4611.6 samples/s | 72.1 steps/s
[Step=8750 Epoch=16.5] | Loss=0.01141 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.216 | L2-Norm(final)=8.761 | 4622.8 samples/s | 72.2 steps/s
[Step=8800 Epoch=16.6] | Loss=0.01007 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=8.754 | 4667.6 samples/s | 72.9 steps/s
[Step=8850 Epoch=16.7] | Loss=0.00909 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.241 | L2-Norm(final)=8.749 | 4635.0 samples/s | 72.4 steps/s
[Step=8900 Epoch=16.8] | Loss=0.00847 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=8.745 | 4570.3 samples/s | 71.4 steps/s
[Step=8950 Epoch=16.9] | Loss=0.00836 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.243 | L2-Norm(final)=8.740 | 4619.3 samples/s | 72.2 steps/s
[Step=9000 Epoch=17.0] | Loss=0.00779 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.246 | L2-Norm(final)=8.734 | 4662.0 samples/s | 72.8 steps/s
[Step=9050 Epoch=17.1] | Loss=0.00718 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.244 | L2-Norm(final)=8.730 | 2139.6 samples/s | 33.4 steps/s
[Step=9100 Epoch=17.2] | Loss=0.00664 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=8.727 | 4664.9 samples/s | 72.9 steps/s
[Step=9150 Epoch=17.2] | Loss=0.00614 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.226 | L2-Norm(final)=8.725 | 4698.6 samples/s | 73.4 steps/s
[Step=9200 Epoch=17.3] | Loss=0.00588 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.212 | L2-Norm(final)=8.724 | 4534.4 samples/s | 70.9 steps/s
[Step=9250 Epoch=17.4] | Loss=0.00550 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=8.722 | 4712.5 samples/s | 73.6 steps/s
[Step=9300 Epoch=17.5] | Loss=0.00516 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.178 | L2-Norm(final)=8.721 | 4588.4 samples/s | 71.7 steps/s
[Step=9350 Epoch=17.6] | Loss=0.00487 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.158 | L2-Norm(final)=8.720 | 4656.3 samples/s | 72.8 steps/s
[Step=9400 Epoch=17.7] | Loss=0.00461 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=8.720 | 4574.5 samples/s | 71.5 steps/s
[Step=9450 Epoch=17.8] | Loss=0.00437 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.115 | L2-Norm(final)=8.720 | 4639.8 samples/s | 72.5 steps/s
[Step=9500 Epoch=17.9] | Loss=0.00415 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=8.720 | 4583.9 samples/s | 71.6 steps/s
[Step=9550 Epoch=18.0] | Loss=0.00398 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.067 | L2-Norm(final)=8.720 | 5765.2 samples/s | 90.1 steps/s
[Step=9600 Epoch=18.1] | Loss=0.00382 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=8.720 | 1954.9 samples/s | 30.5 steps/s
[Step=9650 Epoch=18.2] | Loss=0.00366 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.016 | L2-Norm(final)=8.720 | 4557.5 samples/s | 71.2 steps/s
[Step=9700 Epoch=18.3] | Loss=0.00351 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=8.720 | 4565.1 samples/s | 71.3 steps/s
[Step=9750 Epoch=18.4] | Loss=0.00337 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=8.721 | 4601.0 samples/s | 71.9 steps/s
[Step=9800 Epoch=18.5] | Loss=0.00324 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.937 | L2-Norm(final)=8.721 | 4647.8 samples/s | 72.6 steps/s
[Step=9850 Epoch=18.6] | Loss=0.00312 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.909 | L2-Norm(final)=8.721 | 4578.0 samples/s | 71.5 steps/s
[Step=9900 Epoch=18.7] | Loss=0.00301 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=8.721 | 4617.0 samples/s | 72.1 steps/s
[Step=9950 Epoch=18.8] | Loss=0.00291 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.854 | L2-Norm(final)=8.722 | 4620.7 samples/s | 72.2 steps/s
[Step=10000 Epoch=18.9] | Loss=0.00281 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.826 | L2-Norm(final)=8.722 | 4600.7 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05051 | acc=0.9673 | tpr=0.9756 | fpr=0.0505 | 4180.6 samples/s | 16.3 steps/s
Avg test loss: 0.05268, Avg test acc: 0.96522, Avg tpr: 0.97296, Avg fpr: 0.05179, total FA: 404

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.14000 | acc=0.3128 | tpr=0.0066 | fpr=0.0223 | 4215.9 samples/s | 16.5 steps/s
Avg test loss: 7.15497, Avg test acc: 0.31048, Avg tpr: 0.00734, Avg fpr: 0.02282, total FA: 178

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.62206 | acc=0.1316 | tpr=0.6858 | fpr=0.8784 | 4198.4 samples/s | 16.4 steps/s
[Step= 100] | Loss=3.62549 | acc=0.1303 | tpr=0.6588 | fpr=0.8796 | 7983.5 samples/s | 31.2 steps/s
[Step= 150] | Loss=3.62543 | acc=0.1308 | tpr=0.6715 | fpr=0.8792 | 7985.7 samples/s | 31.2 steps/s
[Step= 200] | Loss=3.61689 | acc=0.1310 | tpr=0.6743 | fpr=0.8789 | 7385.3 samples/s | 28.8 steps/s
[Step= 250] | Loss=3.61602 | acc=0.1310 | tpr=0.6786 | fpr=0.8789 | 8157.6 samples/s | 31.9 steps/s
[Step= 300] | Loss=3.61835 | acc=0.1310 | tpr=0.6858 | fpr=0.8791 | 8127.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=3.61489 | acc=0.1307 | tpr=0.6819 | fpr=0.8793 | 8059.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=3.61520 | acc=0.1308 | tpr=0.6898 | fpr=0.8794 | 7700.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=3.61896 | acc=0.1304 | tpr=0.6874 | fpr=0.8797 | 8065.7 samples/s | 31.5 steps/s
[Step= 500] | Loss=3.61978 | acc=0.1302 | tpr=0.6921 | fpr=0.8800 | 7960.4 samples/s | 31.1 steps/s
[Step= 550] | Loss=3.61921 | acc=0.1302 | tpr=0.6884 | fpr=0.8799 | 15026.9 samples/s | 58.7 steps/s
Avg test loss: 3.62014, Avg test acc: 0.13010, Avg tpr: 0.68899, Avg fpr: 0.88006, total FA: 122195

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13375 | acc=0.9818 | tpr=0.9558 | fpr=0.0177 | 4243.4 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.13671 | acc=0.9808 | tpr=0.9616 | fpr=0.0188 | 8178.9 samples/s | 31.9 steps/s
[Step= 150] | Loss=0.14454 | acc=0.9791 | tpr=0.9625 | fpr=0.0206 | 7895.3 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.14629 | acc=0.9789 | tpr=0.9650 | fpr=0.0209 | 7754.9 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.14311 | acc=0.9790 | tpr=0.9616 | fpr=0.0207 | 8070.3 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.14566 | acc=0.9786 | tpr=0.9600 | fpr=0.0211 | 7999.7 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.14668 | acc=0.9784 | tpr=0.9593 | fpr=0.0213 | 8199.0 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.14827 | acc=0.9781 | tpr=0.9584 | fpr=0.0215 | 7884.6 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.15089 | acc=0.9778 | tpr=0.9576 | fpr=0.0218 | 7942.6 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14981 | acc=0.9779 | tpr=0.9581 | fpr=0.0218 | 7995.1 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.14875 | acc=0.9781 | tpr=0.9574 | fpr=0.0215 | 14775.8 samples/s | 57.7 steps/s
Avg test loss: 0.14842, Avg test acc: 0.97812, Avg tpr: 0.95761, Avg fpr: 0.02151, total FA: 2986

server round 5/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=10001 Epoch= 9.8] | Loss=0.06968 | Reg=0.00238 | acc=0.9375 | L2-Norm=15.437 | L2-Norm(final)=5.830 | 4033.3 samples/s | 63.0 steps/s
[Step=10050 Epoch= 9.8] | Loss=0.10351 | Reg=0.00239 | acc=0.9531 | L2-Norm=15.449 | L2-Norm(final)=5.850 | 4916.6 samples/s | 76.8 steps/s
[Step=10100 Epoch= 9.9] | Loss=0.09894 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.451 | L2-Norm(final)=5.868 | 5238.3 samples/s | 81.8 steps/s
[Step=10150 Epoch= 9.9] | Loss=0.10141 | Reg=0.00239 | acc=0.8750 | L2-Norm=15.452 | L2-Norm(final)=5.898 | 5245.3 samples/s | 82.0 steps/s
[Step=10200 Epoch=10.0] | Loss=0.10121 | Reg=0.00239 | acc=0.8750 | L2-Norm=15.452 | L2-Norm(final)=5.923 | 5430.2 samples/s | 84.8 steps/s
[Step=10250 Epoch=10.0] | Loss=0.10158 | Reg=0.00239 | acc=0.8750 | L2-Norm=15.452 | L2-Norm(final)=5.949 | 5685.1 samples/s | 88.8 steps/s
[Step=10300 Epoch=10.1] | Loss=0.10003 | Reg=0.00239 | acc=0.9219 | L2-Norm=15.452 | L2-Norm(final)=5.979 | 5520.7 samples/s | 86.3 steps/s
[Step=10350 Epoch=10.1] | Loss=0.09887 | Reg=0.00239 | acc=0.9531 | L2-Norm=15.452 | L2-Norm(final)=6.014 | 5626.3 samples/s | 87.9 steps/s
[Step=10400 Epoch=10.2] | Loss=0.09787 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.452 | L2-Norm(final)=6.051 | 5263.3 samples/s | 82.2 steps/s
[Step=10450 Epoch=10.2] | Loss=0.09695 | Reg=0.00239 | acc=0.8594 | L2-Norm=15.452 | L2-Norm(final)=6.090 | 5257.2 samples/s | 82.1 steps/s
[Step=10500 Epoch=10.3] | Loss=0.09716 | Reg=0.00239 | acc=0.9062 | L2-Norm=15.452 | L2-Norm(final)=6.131 | 5260.8 samples/s | 82.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=10.3] | Loss=0.11200 | Reg=0.00239 | acc=0.8906 | L2-Norm=15.453 | L2-Norm(final)=6.537 | 4170.7 samples/s | 65.2 steps/s
[Step=10550 Epoch=10.3] | Loss=0.06725 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.630 | L2-Norm(final)=6.554 | 4707.8 samples/s | 73.6 steps/s
[Step=10600 Epoch=10.3] | Loss=0.06265 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.774 | L2-Norm(final)=6.553 | 4878.5 samples/s | 76.2 steps/s
[Step=10650 Epoch=10.4] | Loss=0.05904 | Reg=0.00252 | acc=0.9375 | L2-Norm=15.875 | L2-Norm(final)=6.539 | 4843.1 samples/s | 75.7 steps/s
[Step=10700 Epoch=10.4] | Loss=0.05620 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.954 | L2-Norm(final)=6.530 | 4840.6 samples/s | 75.6 steps/s
[Step=10750 Epoch=10.5] | Loss=0.05331 | Reg=0.00257 | acc=0.9375 | L2-Norm=16.021 | L2-Norm(final)=6.523 | 4726.0 samples/s | 73.8 steps/s
[Step=10800 Epoch=10.5] | Loss=0.05262 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.081 | L2-Norm(final)=6.518 | 4553.1 samples/s | 71.1 steps/s
[Step=10850 Epoch=10.6] | Loss=0.05150 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=6.510 | 4612.6 samples/s | 72.1 steps/s
[Step=10900 Epoch=10.6] | Loss=0.05067 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.189 | L2-Norm(final)=6.504 | 4577.9 samples/s | 71.5 steps/s
[Step=10950 Epoch=10.7] | Loss=0.04973 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.236 | L2-Norm(final)=6.499 | 4743.2 samples/s | 74.1 steps/s
[Step=11000 Epoch=10.7] | Loss=0.04976 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.280 | L2-Norm(final)=6.493 | 4783.6 samples/s | 74.7 steps/s
[Step=11050 Epoch=10.8] | Loss=0.04925 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=6.487 | 4533.6 samples/s | 70.8 steps/s
[Step=11100 Epoch=10.8] | Loss=0.04895 | Reg=0.00268 | acc=0.9531 | L2-Norm=16.361 | L2-Norm(final)=6.480 | 4651.5 samples/s | 72.7 steps/s
[Step=11150 Epoch=10.9] | Loss=0.04833 | Reg=0.00269 | acc=0.9531 | L2-Norm=16.398 | L2-Norm(final)=6.474 | 4675.5 samples/s | 73.1 steps/s
[Step=11200 Epoch=10.9] | Loss=0.04756 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.433 | L2-Norm(final)=6.469 | 4795.7 samples/s | 74.9 steps/s
[Step=11250 Epoch=11.0] | Loss=0.04764 | Reg=0.00271 | acc=0.9531 | L2-Norm=16.466 | L2-Norm(final)=6.463 | 4792.3 samples/s | 74.9 steps/s
[Step=11300 Epoch=11.0] | Loss=0.04759 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.499 | L2-Norm(final)=6.457 | 4824.5 samples/s | 75.4 steps/s
[Step=11350 Epoch=11.1] | Loss=0.04710 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.531 | L2-Norm(final)=6.452 | 4776.8 samples/s | 74.6 steps/s
[Step=11400 Epoch=11.1] | Loss=0.04721 | Reg=0.00274 | acc=0.9219 | L2-Norm=16.562 | L2-Norm(final)=6.447 | 4675.8 samples/s | 73.1 steps/s
[Step=11450 Epoch=11.2] | Loss=0.04691 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.593 | L2-Norm(final)=6.441 | 4563.4 samples/s | 71.3 steps/s
[Step=11500 Epoch=11.2] | Loss=0.04607 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=6.436 | 4930.7 samples/s | 77.0 steps/s
[Step=11550 Epoch=11.3] | Loss=0.04593 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.652 | L2-Norm(final)=6.432 | 2135.5 samples/s | 33.4 steps/s
[Step=11600 Epoch=11.3] | Loss=0.04519 | Reg=0.00278 | acc=0.9531 | L2-Norm=16.681 | L2-Norm(final)=6.428 | 4669.6 samples/s | 73.0 steps/s
[Step=11650 Epoch=11.4] | Loss=0.04431 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.709 | L2-Norm(final)=6.424 | 4612.1 samples/s | 72.1 steps/s
[Step=11700 Epoch=11.4] | Loss=0.04387 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.736 | L2-Norm(final)=6.421 | 4602.1 samples/s | 71.9 steps/s
[Step=11750 Epoch=11.5] | Loss=0.04330 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.762 | L2-Norm(final)=6.417 | 4585.2 samples/s | 71.6 steps/s
[Step=11800 Epoch=11.5] | Loss=0.04291 | Reg=0.00282 | acc=0.9531 | L2-Norm=16.786 | L2-Norm(final)=6.413 | 4829.1 samples/s | 75.5 steps/s
[Step=11850 Epoch=11.6] | Loss=0.04240 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.811 | L2-Norm(final)=6.409 | 4817.6 samples/s | 75.3 steps/s
[Step=11900 Epoch=11.6] | Loss=0.04221 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.834 | L2-Norm(final)=6.405 | 4808.4 samples/s | 75.1 steps/s
[Step=11950 Epoch=11.7] | Loss=0.04173 | Reg=0.00284 | acc=0.9531 | L2-Norm=16.858 | L2-Norm(final)=6.402 | 4775.0 samples/s | 74.6 steps/s
[Step=12000 Epoch=11.7] | Loss=0.04158 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.881 | L2-Norm(final)=6.398 | 4877.8 samples/s | 76.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step12000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=10001 Epoch=18.9] | Loss=0.00598 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=8.733 | 4300.1 samples/s | 67.2 steps/s
[Step=10050 Epoch=18.9] | Loss=0.00922 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=8.794 | 4550.6 samples/s | 71.1 steps/s
[Step=10100 Epoch=19.0] | Loss=0.00918 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.426 | L2-Norm(final)=8.876 | 5057.4 samples/s | 79.0 steps/s
[Step=10150 Epoch=19.1] | Loss=0.00826 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=8.954 | 5096.3 samples/s | 79.6 steps/s
[Step=10200 Epoch=19.2] | Loss=0.00852 | Reg=0.00238 | acc=0.9688 | L2-Norm=15.426 | L2-Norm(final)=9.030 | 5346.1 samples/s | 83.5 steps/s
[Step=10250 Epoch=19.3] | Loss=0.00829 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.101 | 5179.9 samples/s | 80.9 steps/s
[Step=10300 Epoch=19.4] | Loss=0.00796 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.171 | 5302.3 samples/s | 82.8 steps/s
[Step=10350 Epoch=19.5] | Loss=0.00783 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.238 | 5332.5 samples/s | 83.3 steps/s
[Step=10400 Epoch=19.6] | Loss=0.00784 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.302 | 5347.2 samples/s | 83.6 steps/s
[Step=10450 Epoch=19.7] | Loss=0.00760 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.364 | 5243.4 samples/s | 81.9 steps/s
[Step=10500 Epoch=19.8] | Loss=0.00753 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.425 | L2-Norm(final)=9.424 | 5422.1 samples/s | 84.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=19.8] | Loss=0.00214 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.425 | L2-Norm(final)=10.023 | 3950.9 samples/s | 61.7 steps/s
[Step=10550 Epoch=19.9] | Loss=0.01450 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.563 | L2-Norm(final)=10.026 | 4440.8 samples/s | 69.4 steps/s
[Step=10600 Epoch=20.0] | Loss=0.01489 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.830 | L2-Norm(final)=9.984 | 4599.8 samples/s | 71.9 steps/s
[Step=10650 Epoch=20.1] | Loss=0.01272 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=9.953 | 4554.5 samples/s | 71.2 steps/s
[Step=10700 Epoch=20.2] | Loss=0.01108 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=9.932 | 4687.1 samples/s | 73.2 steps/s
[Step=10750 Epoch=20.3] | Loss=0.00951 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=9.917 | 4597.0 samples/s | 71.8 steps/s
[Step=10800 Epoch=20.4] | Loss=0.00851 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.162 | L2-Norm(final)=9.908 | 4641.3 samples/s | 72.5 steps/s
[Step=10850 Epoch=20.5] | Loss=0.00797 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.186 | L2-Norm(final)=9.900 | 4639.2 samples/s | 72.5 steps/s
[Step=10900 Epoch=20.5] | Loss=0.00718 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.201 | L2-Norm(final)=9.893 | 4642.2 samples/s | 72.5 steps/s
[Step=10950 Epoch=20.6] | Loss=0.00654 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.208 | L2-Norm(final)=9.887 | 4629.9 samples/s | 72.3 steps/s
[Step=11000 Epoch=20.7] | Loss=0.00605 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.209 | L2-Norm(final)=9.883 | 4658.9 samples/s | 72.8 steps/s
[Step=11050 Epoch=20.8] | Loss=0.00605 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.208 | L2-Norm(final)=9.877 | 2083.4 samples/s | 32.6 steps/s
[Step=11100 Epoch=20.9] | Loss=0.00564 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.206 | L2-Norm(final)=9.871 | 4716.1 samples/s | 73.7 steps/s
[Step=11150 Epoch=21.0] | Loss=0.00541 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.201 | L2-Norm(final)=9.866 | 4601.8 samples/s | 71.9 steps/s
[Step=11200 Epoch=21.1] | Loss=0.00525 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=9.860 | 4581.3 samples/s | 71.6 steps/s
[Step=11250 Epoch=21.2] | Loss=0.00508 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.190 | L2-Norm(final)=9.855 | 4616.9 samples/s | 72.1 steps/s
[Step=11300 Epoch=21.3] | Loss=0.00480 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.183 | L2-Norm(final)=9.851 | 4610.8 samples/s | 72.0 steps/s
[Step=11350 Epoch=21.4] | Loss=0.00457 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.174 | L2-Norm(final)=9.847 | 4643.6 samples/s | 72.6 steps/s
[Step=11400 Epoch=21.5] | Loss=0.00433 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.164 | L2-Norm(final)=9.844 | 4568.7 samples/s | 71.4 steps/s
[Step=11450 Epoch=21.6] | Loss=0.00415 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=9.842 | 4636.4 samples/s | 72.4 steps/s
[Step=11500 Epoch=21.7] | Loss=0.00395 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=9.840 | 4611.8 samples/s | 72.1 steps/s
[Step=11550 Epoch=21.8] | Loss=0.00380 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.126 | L2-Norm(final)=9.838 | 5754.7 samples/s | 89.9 steps/s
[Step=11600 Epoch=21.9] | Loss=0.00365 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.112 | L2-Norm(final)=9.837 | 1964.7 samples/s | 30.7 steps/s
[Step=11650 Epoch=22.0] | Loss=0.00352 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.099 | L2-Norm(final)=9.836 | 4633.0 samples/s | 72.4 steps/s
[Step=11700 Epoch=22.1] | Loss=0.00345 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.087 | L2-Norm(final)=9.834 | 4597.9 samples/s | 71.8 steps/s
[Step=11750 Epoch=22.1] | Loss=0.00385 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=9.831 | 4677.1 samples/s | 73.1 steps/s
[Step=11800 Epoch=22.2] | Loss=0.00379 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.078 | L2-Norm(final)=9.826 | 4607.2 samples/s | 72.0 steps/s
[Step=11850 Epoch=22.3] | Loss=0.00371 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.076 | L2-Norm(final)=9.820 | 4678.7 samples/s | 73.1 steps/s
[Step=11900 Epoch=22.4] | Loss=0.00364 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=9.816 | 4547.9 samples/s | 71.1 steps/s
[Step=11950 Epoch=22.5] | Loss=0.00352 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.072 | L2-Norm(final)=9.812 | 4611.2 samples/s | 72.0 steps/s
[Step=12000 Epoch=22.6] | Loss=0.00354 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=9.807 | 4647.8 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06021 | acc=0.9552 | tpr=0.9474 | fpr=0.0280 | 4200.0 samples/s | 16.4 steps/s
Avg test loss: 0.06493, Avg test acc: 0.95236, Avg tpr: 0.94486, Avg fpr: 0.03115, total FA: 243

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.60585 | acc=0.3110 | tpr=0.0223 | fpr=0.0619 | 4227.5 samples/s | 16.5 steps/s
Avg test loss: 7.60091, Avg test acc: 0.30860, Avg tpr: 0.02267, Avg fpr: 0.06256, total FA: 488

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.83352 | acc=0.1768 | tpr=0.4956 | fpr=0.8289 | 4274.7 samples/s | 16.7 steps/s
[Step= 100] | Loss=2.82677 | acc=0.1779 | tpr=0.4776 | fpr=0.8277 | 7965.6 samples/s | 31.1 steps/s
[Step= 150] | Loss=2.82400 | acc=0.1781 | tpr=0.4899 | fpr=0.8276 | 7827.7 samples/s | 30.6 steps/s
[Step= 200] | Loss=2.81469 | acc=0.1793 | tpr=0.4929 | fpr=0.8264 | 7973.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=2.81177 | acc=0.1793 | tpr=0.4934 | fpr=0.8264 | 8111.5 samples/s | 31.7 steps/s
[Step= 300] | Loss=2.81309 | acc=0.1792 | tpr=0.4967 | fpr=0.8266 | 8050.6 samples/s | 31.4 steps/s
[Step= 350] | Loss=2.81111 | acc=0.1795 | tpr=0.4959 | fpr=0.8262 | 8238.0 samples/s | 32.2 steps/s
[Step= 400] | Loss=2.81242 | acc=0.1796 | tpr=0.5011 | fpr=0.8262 | 7947.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=2.81635 | acc=0.1792 | tpr=0.5015 | fpr=0.8266 | 7833.1 samples/s | 30.6 steps/s
[Step= 500] | Loss=2.81539 | acc=0.1792 | tpr=0.4991 | fpr=0.8266 | 7848.8 samples/s | 30.7 steps/s
[Step= 550] | Loss=2.81638 | acc=0.1794 | tpr=0.5054 | fpr=0.8265 | 14621.5 samples/s | 57.1 steps/s
Avg test loss: 2.81698, Avg test acc: 0.17931, Avg tpr: 0.50515, Avg fpr: 0.82662, total FA: 114774

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12311 | acc=0.9820 | tpr=0.9425 | fpr=0.0173 | 4255.9 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.12792 | acc=0.9812 | tpr=0.9552 | fpr=0.0183 | 8001.6 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.13556 | acc=0.9797 | tpr=0.9611 | fpr=0.0200 | 8028.4 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.13981 | acc=0.9793 | tpr=0.9607 | fpr=0.0203 | 8009.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.13826 | acc=0.9795 | tpr=0.9598 | fpr=0.0201 | 8106.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.14023 | acc=0.9792 | tpr=0.9571 | fpr=0.0204 | 7911.9 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.14206 | acc=0.9789 | tpr=0.9574 | fpr=0.0207 | 7951.3 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14287 | acc=0.9789 | tpr=0.9562 | fpr=0.0207 | 7887.9 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.14571 | acc=0.9784 | tpr=0.9542 | fpr=0.0211 | 8031.2 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.14544 | acc=0.9785 | tpr=0.9546 | fpr=0.0210 | 8096.6 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.14459 | acc=0.9788 | tpr=0.9558 | fpr=0.0208 | 14811.6 samples/s | 57.9 steps/s
Avg test loss: 0.14431, Avg test acc: 0.97879, Avg tpr: 0.95602, Avg fpr: 0.02080, total FA: 2888

server round 6/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=12001 Epoch=11.7] | Loss=0.10080 | Reg=0.00248 | acc=0.9219 | L2-Norm=15.760 | L2-Norm(final)=6.289 | 4514.6 samples/s | 70.5 steps/s
[Step=12050 Epoch=11.8] | Loss=0.12247 | Reg=0.00249 | acc=0.8594 | L2-Norm=15.777 | L2-Norm(final)=6.344 | 4855.0 samples/s | 75.9 steps/s
[Step=12100 Epoch=11.8] | Loss=0.12294 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.780 | L2-Norm(final)=6.416 | 5522.9 samples/s | 86.3 steps/s
[Step=12150 Epoch=11.9] | Loss=0.12059 | Reg=0.00249 | acc=0.8438 | L2-Norm=15.781 | L2-Norm(final)=6.477 | 5338.4 samples/s | 83.4 steps/s
[Step=12200 Epoch=11.9] | Loss=0.11988 | Reg=0.00249 | acc=0.9062 | L2-Norm=15.781 | L2-Norm(final)=6.535 | 5498.1 samples/s | 85.9 steps/s
[Step=12250 Epoch=12.0] | Loss=0.11921 | Reg=0.00249 | acc=0.9062 | L2-Norm=15.782 | L2-Norm(final)=6.585 | 5531.6 samples/s | 86.4 steps/s
[Step=12300 Epoch=12.0] | Loss=0.11850 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.782 | L2-Norm(final)=6.632 | 5616.5 samples/s | 87.8 steps/s
[Step=12350 Epoch=12.1] | Loss=0.11871 | Reg=0.00249 | acc=0.8750 | L2-Norm=15.782 | L2-Norm(final)=6.677 | 5231.8 samples/s | 81.7 steps/s
[Step=12400 Epoch=12.1] | Loss=0.11706 | Reg=0.00249 | acc=0.9062 | L2-Norm=15.782 | L2-Norm(final)=6.719 | 5605.7 samples/s | 87.6 steps/s
[Step=12450 Epoch=12.2] | Loss=0.11636 | Reg=0.00249 | acc=0.8438 | L2-Norm=15.782 | L2-Norm(final)=6.760 | 5425.9 samples/s | 84.8 steps/s
[Step=12500 Epoch=12.2] | Loss=0.11624 | Reg=0.00249 | acc=0.8750 | L2-Norm=15.782 | L2-Norm(final)=6.799 | 5417.0 samples/s | 84.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=12.2] | Loss=0.13351 | Reg=0.00249 | acc=0.8750 | L2-Norm=15.783 | L2-Norm(final)=7.172 | 3998.6 samples/s | 62.5 steps/s
[Step=12550 Epoch=12.3] | Loss=0.09325 | Reg=0.00254 | acc=0.9531 | L2-Norm=15.925 | L2-Norm(final)=7.178 | 4851.6 samples/s | 75.8 steps/s
[Step=12600 Epoch=12.3] | Loss=0.07515 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.059 | L2-Norm(final)=7.166 | 4876.0 samples/s | 76.2 steps/s
[Step=12650 Epoch=12.4] | Loss=0.06724 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.154 | L2-Norm(final)=7.162 | 4761.6 samples/s | 74.4 steps/s
[Step=12700 Epoch=12.4] | Loss=0.06296 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.231 | L2-Norm(final)=7.157 | 4811.3 samples/s | 75.2 steps/s
[Step=12750 Epoch=12.4] | Loss=0.06038 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.300 | L2-Norm(final)=7.152 | 4852.6 samples/s | 75.8 steps/s
[Step=12800 Epoch=12.5] | Loss=0.05959 | Reg=0.00268 | acc=0.9688 | L2-Norm=16.364 | L2-Norm(final)=7.146 | 4856.4 samples/s | 75.9 steps/s
[Step=12850 Epoch=12.5] | Loss=0.05767 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.423 | L2-Norm(final)=7.138 | 4818.5 samples/s | 75.3 steps/s
[Step=12900 Epoch=12.6] | Loss=0.05708 | Reg=0.00272 | acc=0.9219 | L2-Norm=16.476 | L2-Norm(final)=7.131 | 4848.3 samples/s | 75.8 steps/s
[Step=12950 Epoch=12.6] | Loss=0.05523 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.525 | L2-Norm(final)=7.125 | 4847.6 samples/s | 75.7 steps/s
[Step=13000 Epoch=12.7] | Loss=0.05372 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.569 | L2-Norm(final)=7.119 | 4825.5 samples/s | 75.4 steps/s
[Step=13050 Epoch=12.7] | Loss=0.05233 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.610 | L2-Norm(final)=7.114 | 4855.6 samples/s | 75.9 steps/s
[Step=13100 Epoch=12.8] | Loss=0.05157 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.651 | L2-Norm(final)=7.110 | 4839.3 samples/s | 75.6 steps/s
[Step=13150 Epoch=12.8] | Loss=0.05081 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.690 | L2-Norm(final)=7.105 | 4787.2 samples/s | 74.8 steps/s
[Step=13200 Epoch=12.9] | Loss=0.04988 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.725 | L2-Norm(final)=7.101 | 4893.1 samples/s | 76.5 steps/s
[Step=13250 Epoch=12.9] | Loss=0.04919 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.758 | L2-Norm(final)=7.097 | 4776.7 samples/s | 74.6 steps/s
[Step=13300 Epoch=13.0] | Loss=0.04816 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.789 | L2-Norm(final)=7.093 | 4851.6 samples/s | 75.8 steps/s
[Step=13350 Epoch=13.0] | Loss=0.04764 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.820 | L2-Norm(final)=7.089 | 4816.1 samples/s | 75.3 steps/s
[Step=13400 Epoch=13.1] | Loss=0.04720 | Reg=0.00284 | acc=0.9531 | L2-Norm=16.850 | L2-Norm(final)=7.085 | 4838.6 samples/s | 75.6 steps/s
[Step=13450 Epoch=13.1] | Loss=0.04680 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.880 | L2-Norm(final)=7.081 | 4703.3 samples/s | 73.5 steps/s
[Step=13500 Epoch=13.2] | Loss=0.04618 | Reg=0.00286 | acc=0.9688 | L2-Norm=16.908 | L2-Norm(final)=7.077 | 5109.1 samples/s | 79.8 steps/s
[Step=13550 Epoch=13.2] | Loss=0.04572 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.935 | L2-Norm(final)=7.072 | 2116.5 samples/s | 33.1 steps/s
[Step=13600 Epoch=13.3] | Loss=0.04526 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.960 | L2-Norm(final)=7.068 | 4937.7 samples/s | 77.2 steps/s
[Step=13650 Epoch=13.3] | Loss=0.04475 | Reg=0.00289 | acc=0.9531 | L2-Norm=16.986 | L2-Norm(final)=7.064 | 4793.9 samples/s | 74.9 steps/s
[Step=13700 Epoch=13.4] | Loss=0.04436 | Reg=0.00290 | acc=0.9531 | L2-Norm=17.011 | L2-Norm(final)=7.060 | 4862.9 samples/s | 76.0 steps/s
[Step=13750 Epoch=13.4] | Loss=0.04362 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.036 | L2-Norm(final)=7.057 | 4846.9 samples/s | 75.7 steps/s
[Step=13800 Epoch=13.5] | Loss=0.04318 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.060 | L2-Norm(final)=7.053 | 4851.1 samples/s | 75.8 steps/s
[Step=13850 Epoch=13.5] | Loss=0.04291 | Reg=0.00292 | acc=0.9688 | L2-Norm=17.084 | L2-Norm(final)=7.050 | 4930.1 samples/s | 77.0 steps/s
[Step=13900 Epoch=13.6] | Loss=0.04245 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.107 | L2-Norm(final)=7.047 | 4799.0 samples/s | 75.0 steps/s
[Step=13950 Epoch=13.6] | Loss=0.04206 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.129 | L2-Norm(final)=7.043 | 4876.4 samples/s | 76.2 steps/s
[Step=14000 Epoch=13.7] | Loss=0.04157 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.151 | L2-Norm(final)=7.040 | 4896.6 samples/s | 76.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step14000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=12001 Epoch=22.6] | Loss=0.01636 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.760 | L2-Norm(final)=9.671 | 4546.5 samples/s | 71.0 steps/s
[Step=12050 Epoch=22.7] | Loss=0.04075 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.768 | L2-Norm(final)=9.662 | 4306.1 samples/s | 67.3 steps/s
[Step=12100 Epoch=22.8] | Loss=0.03623 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=9.657 | 5330.5 samples/s | 83.3 steps/s
[Step=12150 Epoch=22.9] | Loss=0.03196 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.770 | L2-Norm(final)=9.702 | 5233.9 samples/s | 81.8 steps/s
[Step=12200 Epoch=23.0] | Loss=0.02935 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.770 | L2-Norm(final)=9.782 | 5288.1 samples/s | 82.6 steps/s
[Step=12250 Epoch=23.1] | Loss=0.02723 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.770 | L2-Norm(final)=9.879 | 5285.4 samples/s | 82.6 steps/s
[Step=12300 Epoch=23.2] | Loss=0.02567 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=9.976 | 5244.5 samples/s | 81.9 steps/s
[Step=12350 Epoch=23.3] | Loss=0.02485 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=10.072 | 5290.9 samples/s | 82.7 steps/s
[Step=12400 Epoch=23.4] | Loss=0.02388 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=10.168 | 5389.5 samples/s | 84.2 steps/s
[Step=12450 Epoch=23.5] | Loss=0.02309 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=10.261 | 5154.2 samples/s | 80.5 steps/s
[Step=12500 Epoch=23.6] | Loss=0.02242 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=10.351 | 5368.3 samples/s | 83.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=23.6] | Loss=0.01186 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=11.241 | 3994.1 samples/s | 62.4 steps/s
[Step=12550 Epoch=23.7] | Loss=0.00326 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=11.281 | 4391.2 samples/s | 68.6 steps/s
[Step=12600 Epoch=23.8] | Loss=0.00215 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.874 | L2-Norm(final)=11.290 | 4593.0 samples/s | 71.8 steps/s
[Step=12650 Epoch=23.8] | Loss=0.00433 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=11.287 | 4661.4 samples/s | 72.8 steps/s
[Step=12700 Epoch=23.9] | Loss=0.00738 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=11.267 | 4539.8 samples/s | 70.9 steps/s
[Step=12750 Epoch=24.0] | Loss=0.00642 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.056 | L2-Norm(final)=11.250 | 4640.6 samples/s | 72.5 steps/s
[Step=12800 Epoch=24.1] | Loss=0.00576 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.098 | L2-Norm(final)=11.239 | 4568.7 samples/s | 71.4 steps/s
[Step=12850 Epoch=24.2] | Loss=0.00545 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=11.230 | 4583.7 samples/s | 71.6 steps/s
[Step=12900 Epoch=24.3] | Loss=0.00511 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=11.223 | 4650.2 samples/s | 72.7 steps/s
[Step=12950 Epoch=24.4] | Loss=0.00475 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.159 | L2-Norm(final)=11.216 | 4624.6 samples/s | 72.3 steps/s
[Step=13000 Epoch=24.5] | Loss=0.00431 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.169 | L2-Norm(final)=11.212 | 4671.6 samples/s | 73.0 steps/s
[Step=13050 Epoch=24.6] | Loss=0.00403 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=11.209 | 2130.0 samples/s | 33.3 steps/s
[Step=13100 Epoch=24.7] | Loss=0.00382 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.171 | L2-Norm(final)=11.206 | 4613.6 samples/s | 72.1 steps/s
[Step=13150 Epoch=24.8] | Loss=0.00354 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.168 | L2-Norm(final)=11.205 | 4664.3 samples/s | 72.9 steps/s
[Step=13200 Epoch=24.9] | Loss=0.00335 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.161 | L2-Norm(final)=11.203 | 4645.6 samples/s | 72.6 steps/s
[Step=13250 Epoch=25.0] | Loss=0.00314 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=11.202 | 4545.6 samples/s | 71.0 steps/s
[Step=13300 Epoch=25.1] | Loss=0.00304 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=11.201 | 4649.5 samples/s | 72.6 steps/s
[Step=13350 Epoch=25.2] | Loss=0.00288 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=11.200 | 4696.3 samples/s | 73.4 steps/s
[Step=13400 Epoch=25.3] | Loss=0.00273 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.118 | L2-Norm(final)=11.200 | 4584.2 samples/s | 71.6 steps/s
[Step=13450 Epoch=25.4] | Loss=0.00260 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=11.200 | 4647.6 samples/s | 72.6 steps/s
[Step=13500 Epoch=25.4] | Loss=0.00247 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=11.201 | 4684.3 samples/s | 73.2 steps/s
[Step=13550 Epoch=25.5] | Loss=0.00236 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.076 | L2-Norm(final)=11.201 | 5670.9 samples/s | 88.6 steps/s
[Step=13600 Epoch=25.6] | Loss=0.00226 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=11.202 | 1951.2 samples/s | 30.5 steps/s
[Step=13650 Epoch=25.7] | Loss=0.00216 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.043 | L2-Norm(final)=11.202 | 4549.7 samples/s | 71.1 steps/s
[Step=13700 Epoch=25.8] | Loss=0.00207 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.025 | L2-Norm(final)=11.203 | 4635.3 samples/s | 72.4 steps/s
[Step=13750 Epoch=25.9] | Loss=0.00199 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.007 | L2-Norm(final)=11.203 | 4606.4 samples/s | 72.0 steps/s
[Step=13800 Epoch=26.0] | Loss=0.00191 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.988 | L2-Norm(final)=11.204 | 4602.1 samples/s | 71.9 steps/s
[Step=13850 Epoch=26.1] | Loss=0.00184 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=11.204 | 4628.7 samples/s | 72.3 steps/s
[Step=13900 Epoch=26.2] | Loss=0.00178 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=11.205 | 4670.7 samples/s | 73.0 steps/s
[Step=13950 Epoch=26.3] | Loss=0.00172 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.929 | L2-Norm(final)=11.205 | 4505.9 samples/s | 70.4 steps/s
[Step=14000 Epoch=26.4] | Loss=0.00166 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.909 | L2-Norm(final)=11.206 | 4617.9 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05889 | acc=0.9626 | tpr=0.9646 | fpr=0.0419 | 4195.8 samples/s | 16.4 steps/s
Avg test loss: 0.05940, Avg test acc: 0.96154, Avg tpr: 0.96246, Avg fpr: 0.04051, total FA: 316

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.39702 | acc=0.3133 | tpr=0.0064 | fpr=0.0203 | 4250.1 samples/s | 16.6 steps/s
Avg test loss: 10.37713, Avg test acc: 0.31104, Avg tpr: 0.00723, Avg fpr: 0.02077, total FA: 162

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.61272 | acc=0.1344 | tpr=0.5442 | fpr=0.8730 | 4298.1 samples/s | 16.8 steps/s
[Step= 100] | Loss=4.59944 | acc=0.1335 | tpr=0.5181 | fpr=0.8737 | 7712.1 samples/s | 30.1 steps/s
[Step= 150] | Loss=4.60683 | acc=0.1332 | tpr=0.5231 | fpr=0.8740 | 8053.3 samples/s | 31.5 steps/s
[Step= 200] | Loss=4.59548 | acc=0.1338 | tpr=0.5268 | fpr=0.8733 | 8079.0 samples/s | 31.6 steps/s
[Step= 250] | Loss=4.59087 | acc=0.1340 | tpr=0.5231 | fpr=0.8731 | 8087.5 samples/s | 31.6 steps/s
[Step= 300] | Loss=4.59422 | acc=0.1342 | tpr=0.5164 | fpr=0.8727 | 7654.2 samples/s | 29.9 steps/s
[Step= 350] | Loss=4.59080 | acc=0.1343 | tpr=0.5128 | fpr=0.8726 | 8244.3 samples/s | 32.2 steps/s
[Step= 400] | Loss=4.59009 | acc=0.1343 | tpr=0.5181 | fpr=0.8727 | 7822.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=4.59718 | acc=0.1339 | tpr=0.5122 | fpr=0.8730 | 8152.6 samples/s | 31.8 steps/s
[Step= 500] | Loss=4.59542 | acc=0.1339 | tpr=0.5128 | fpr=0.8729 | 7830.0 samples/s | 30.6 steps/s
[Step= 550] | Loss=4.59496 | acc=0.1343 | tpr=0.5141 | fpr=0.8726 | 14627.1 samples/s | 57.1 steps/s
Avg test loss: 4.59591, Avg test acc: 0.13421, Avg tpr: 0.51387, Avg fpr: 0.87269, total FA: 121171

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15081 | acc=0.9800 | tpr=0.9469 | fpr=0.0194 | 4249.9 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.15449 | acc=0.9795 | tpr=0.9616 | fpr=0.0201 | 7822.2 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.16078 | acc=0.9792 | tpr=0.9625 | fpr=0.0204 | 8019.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.16537 | acc=0.9791 | tpr=0.9639 | fpr=0.0206 | 8029.2 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.16242 | acc=0.9794 | tpr=0.9616 | fpr=0.0203 | 7922.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.16659 | acc=0.9788 | tpr=0.9585 | fpr=0.0208 | 8113.5 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.16778 | acc=0.9787 | tpr=0.9593 | fpr=0.0209 | 7747.8 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.16901 | acc=0.9786 | tpr=0.9584 | fpr=0.0210 | 7985.7 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.17214 | acc=0.9784 | tpr=0.9586 | fpr=0.0213 | 8021.7 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.17153 | acc=0.9784 | tpr=0.9595 | fpr=0.0212 | 7857.9 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.17025 | acc=0.9786 | tpr=0.9594 | fpr=0.0211 | 15190.1 samples/s | 59.3 steps/s
Avg test loss: 0.17017, Avg test acc: 0.97860, Avg tpr: 0.95880, Avg fpr: 0.02104, total FA: 2921

server round 7/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=14001 Epoch=13.7] | Loss=0.11916 | Reg=0.00249 | acc=0.8906 | L2-Norm=15.772 | L2-Norm(final)=6.938 | 3995.8 samples/s | 62.4 steps/s
[Step=14050 Epoch=13.7] | Loss=0.10487 | Reg=0.00249 | acc=0.9375 | L2-Norm=15.782 | L2-Norm(final)=6.969 | 5438.2 samples/s | 85.0 steps/s
[Step=14100 Epoch=13.8] | Loss=0.09940 | Reg=0.00249 | acc=0.8906 | L2-Norm=15.784 | L2-Norm(final)=7.008 | 5564.2 samples/s | 86.9 steps/s
[Step=14150 Epoch=13.8] | Loss=0.09680 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.784 | L2-Norm(final)=7.052 | 5617.4 samples/s | 87.8 steps/s
[Step=14200 Epoch=13.9] | Loss=0.09379 | Reg=0.00249 | acc=0.9219 | L2-Norm=15.784 | L2-Norm(final)=7.098 | 5509.7 samples/s | 86.1 steps/s
[Step=14250 Epoch=13.9] | Loss=0.09204 | Reg=0.00249 | acc=0.9062 | L2-Norm=15.785 | L2-Norm(final)=7.147 | 5640.7 samples/s | 88.1 steps/s
[Step=14300 Epoch=14.0] | Loss=0.09044 | Reg=0.00249 | acc=0.9375 | L2-Norm=15.785 | L2-Norm(final)=7.197 | 5653.6 samples/s | 88.3 steps/s
[Step=14350 Epoch=14.0] | Loss=0.08911 | Reg=0.00249 | acc=0.8906 | L2-Norm=15.785 | L2-Norm(final)=7.247 | 5526.5 samples/s | 86.4 steps/s
[Step=14400 Epoch=14.1] | Loss=0.08821 | Reg=0.00249 | acc=0.9219 | L2-Norm=15.785 | L2-Norm(final)=7.296 | 5595.7 samples/s | 87.4 steps/s
[Step=14450 Epoch=14.1] | Loss=0.08686 | Reg=0.00249 | acc=0.9219 | L2-Norm=15.785 | L2-Norm(final)=7.345 | 5551.9 samples/s | 86.7 steps/s
[Step=14500 Epoch=14.2] | Loss=0.08580 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.785 | L2-Norm(final)=7.395 | 5584.9 samples/s | 87.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=14.2] | Loss=0.09582 | Reg=0.00249 | acc=0.9375 | L2-Norm=15.785 | L2-Norm(final)=7.890 | 4151.7 samples/s | 64.9 steps/s
[Step=14550 Epoch=14.2] | Loss=0.05321 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.942 | L2-Norm(final)=7.908 | 4823.2 samples/s | 75.4 steps/s
[Step=14600 Epoch=14.3] | Loss=0.05466 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.079 | L2-Norm(final)=7.900 | 4817.4 samples/s | 75.3 steps/s
[Step=14650 Epoch=14.3] | Loss=0.05249 | Reg=0.00262 | acc=0.9375 | L2-Norm=16.172 | L2-Norm(final)=7.891 | 4826.5 samples/s | 75.4 steps/s
[Step=14700 Epoch=14.4] | Loss=0.05124 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.248 | L2-Norm(final)=7.884 | 4794.7 samples/s | 74.9 steps/s
[Step=14750 Epoch=14.4] | Loss=0.05079 | Reg=0.00266 | acc=0.9219 | L2-Norm=16.315 | L2-Norm(final)=7.879 | 4811.1 samples/s | 75.2 steps/s
[Step=14800 Epoch=14.4] | Loss=0.04997 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.372 | L2-Norm(final)=7.870 | 4868.6 samples/s | 76.1 steps/s
[Step=14850 Epoch=14.5] | Loss=0.04846 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.423 | L2-Norm(final)=7.862 | 4777.9 samples/s | 74.7 steps/s
[Step=14900 Epoch=14.5] | Loss=0.04801 | Reg=0.00271 | acc=0.9375 | L2-Norm=16.468 | L2-Norm(final)=7.854 | 4886.5 samples/s | 76.4 steps/s
[Step=14950 Epoch=14.6] | Loss=0.04707 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.511 | L2-Norm(final)=7.846 | 4827.6 samples/s | 75.4 steps/s
[Step=15000 Epoch=14.6] | Loss=0.04628 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.551 | L2-Norm(final)=7.839 | 4866.9 samples/s | 76.0 steps/s
[Step=15050 Epoch=14.7] | Loss=0.04605 | Reg=0.00275 | acc=0.9375 | L2-Norm=16.589 | L2-Norm(final)=7.832 | 4867.0 samples/s | 76.0 steps/s
[Step=15100 Epoch=14.7] | Loss=0.04519 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.626 | L2-Norm(final)=7.826 | 4813.8 samples/s | 75.2 steps/s
[Step=15150 Epoch=14.8] | Loss=0.04457 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.661 | L2-Norm(final)=7.820 | 4884.7 samples/s | 76.3 steps/s
[Step=15200 Epoch=14.8] | Loss=0.04391 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.694 | L2-Norm(final)=7.814 | 4791.9 samples/s | 74.9 steps/s
[Step=15250 Epoch=14.9] | Loss=0.04353 | Reg=0.00280 | acc=0.9531 | L2-Norm=16.725 | L2-Norm(final)=7.808 | 4884.3 samples/s | 76.3 steps/s
[Step=15300 Epoch=14.9] | Loss=0.04331 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.754 | L2-Norm(final)=7.802 | 4858.0 samples/s | 75.9 steps/s
[Step=15350 Epoch=15.0] | Loss=0.04298 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.784 | L2-Norm(final)=7.795 | 4854.7 samples/s | 75.9 steps/s
[Step=15400 Epoch=15.0] | Loss=0.04250 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.811 | L2-Norm(final)=7.790 | 4894.0 samples/s | 76.5 steps/s
[Step=15450 Epoch=15.1] | Loss=0.04239 | Reg=0.00284 | acc=0.9688 | L2-Norm=16.838 | L2-Norm(final)=7.784 | 4798.7 samples/s | 75.0 steps/s
[Step=15500 Epoch=15.1] | Loss=0.04251 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.863 | L2-Norm(final)=7.778 | 5256.5 samples/s | 82.1 steps/s
[Step=15550 Epoch=15.2] | Loss=0.04196 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.888 | L2-Norm(final)=7.773 | 2083.9 samples/s | 32.6 steps/s
[Step=15600 Epoch=15.2] | Loss=0.04135 | Reg=0.00286 | acc=0.9219 | L2-Norm=16.913 | L2-Norm(final)=7.767 | 4897.6 samples/s | 76.5 steps/s
[Step=15650 Epoch=15.3] | Loss=0.04064 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.938 | L2-Norm(final)=7.762 | 4818.7 samples/s | 75.3 steps/s
[Step=15700 Epoch=15.3] | Loss=0.04019 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.962 | L2-Norm(final)=7.757 | 4847.6 samples/s | 75.7 steps/s
[Step=15750 Epoch=15.4] | Loss=0.03962 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.985 | L2-Norm(final)=7.752 | 4865.6 samples/s | 76.0 steps/s
[Step=15800 Epoch=15.4] | Loss=0.03941 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.007 | L2-Norm(final)=7.748 | 4791.6 samples/s | 74.9 steps/s
[Step=15850 Epoch=15.5] | Loss=0.03914 | Reg=0.00290 | acc=0.9531 | L2-Norm=17.029 | L2-Norm(final)=7.744 | 4865.4 samples/s | 76.0 steps/s
[Step=15900 Epoch=15.5] | Loss=0.03881 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.051 | L2-Norm(final)=7.740 | 4906.3 samples/s | 76.7 steps/s
[Step=15950 Epoch=15.6] | Loss=0.03871 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.072 | L2-Norm(final)=7.736 | 4805.4 samples/s | 75.1 steps/s
[Step=16000 Epoch=15.6] | Loss=0.03851 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.094 | L2-Norm(final)=7.732 | 4849.8 samples/s | 75.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step16000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=14001 Epoch=26.4] | Loss=0.00111 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.772 | L2-Norm(final)=11.221 | 4159.4 samples/s | 65.0 steps/s
[Step=14050 Epoch=26.5] | Loss=0.00361 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=11.247 | 4382.9 samples/s | 68.5 steps/s
[Step=14100 Epoch=26.6] | Loss=0.00391 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.764 | L2-Norm(final)=11.273 | 4998.4 samples/s | 78.1 steps/s
[Step=14150 Epoch=26.7] | Loss=0.00359 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.298 | 5108.1 samples/s | 79.8 steps/s
[Step=14200 Epoch=26.8] | Loss=0.00355 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.327 | 5034.5 samples/s | 78.7 steps/s
[Step=14250 Epoch=26.9] | Loss=0.00355 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.354 | 5214.1 samples/s | 81.5 steps/s
[Step=14300 Epoch=27.0] | Loss=0.00339 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.381 | 5307.8 samples/s | 82.9 steps/s
[Step=14350 Epoch=27.0] | Loss=0.00340 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.763 | L2-Norm(final)=11.408 | 5271.0 samples/s | 82.4 steps/s
[Step=14400 Epoch=27.1] | Loss=0.00336 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.435 | 5235.5 samples/s | 81.8 steps/s
[Step=14450 Epoch=27.2] | Loss=0.00323 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.461 | 5342.3 samples/s | 83.5 steps/s
[Step=14500 Epoch=27.3] | Loss=0.00315 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.486 | 5449.3 samples/s | 85.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=27.3] | Loss=0.00035 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=11.721 | 3861.8 samples/s | 60.3 steps/s
[Step=14550 Epoch=27.4] | Loss=0.01987 | Reg=0.00251 | acc=0.9531 | L2-Norm=15.853 | L2-Norm(final)=11.703 | 4610.4 samples/s | 72.0 steps/s
[Step=14600 Epoch=27.5] | Loss=0.02033 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.099 | L2-Norm(final)=11.623 | 4612.7 samples/s | 72.1 steps/s
[Step=14650 Epoch=27.6] | Loss=0.01719 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.257 | L2-Norm(final)=11.572 | 4570.6 samples/s | 71.4 steps/s
[Step=14700 Epoch=27.7] | Loss=0.01414 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.351 | L2-Norm(final)=11.543 | 4622.8 samples/s | 72.2 steps/s
[Step=14750 Epoch=27.8] | Loss=0.01276 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.413 | L2-Norm(final)=11.520 | 4648.8 samples/s | 72.6 steps/s
[Step=14800 Epoch=27.9] | Loss=0.01079 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.451 | L2-Norm(final)=11.506 | 4627.3 samples/s | 72.3 steps/s
[Step=14850 Epoch=28.0] | Loss=0.00996 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.475 | L2-Norm(final)=11.495 | 4618.7 samples/s | 72.2 steps/s
[Step=14900 Epoch=28.1] | Loss=0.00887 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.490 | L2-Norm(final)=11.486 | 4590.3 samples/s | 71.7 steps/s
[Step=14950 Epoch=28.2] | Loss=0.00795 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.496 | L2-Norm(final)=11.479 | 4590.3 samples/s | 71.7 steps/s
[Step=15000 Epoch=28.3] | Loss=0.00731 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.494 | L2-Norm(final)=11.474 | 4665.9 samples/s | 72.9 steps/s
[Step=15050 Epoch=28.4] | Loss=0.00666 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.489 | L2-Norm(final)=11.470 | 2130.5 samples/s | 33.3 steps/s
[Step=15100 Epoch=28.5] | Loss=0.00615 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=11.467 | 4689.5 samples/s | 73.3 steps/s
[Step=15150 Epoch=28.6] | Loss=0.00569 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.467 | L2-Norm(final)=11.465 | 4563.4 samples/s | 71.3 steps/s
[Step=15200 Epoch=28.7] | Loss=0.00529 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.453 | L2-Norm(final)=11.464 | 4530.2 samples/s | 70.8 steps/s
[Step=15250 Epoch=28.7] | Loss=0.00494 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.437 | L2-Norm(final)=11.463 | 4626.9 samples/s | 72.3 steps/s
[Step=15300 Epoch=28.8] | Loss=0.00463 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.420 | L2-Norm(final)=11.462 | 4622.5 samples/s | 72.2 steps/s
[Step=15350 Epoch=28.9] | Loss=0.00436 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.401 | L2-Norm(final)=11.462 | 4571.8 samples/s | 71.4 steps/s
[Step=15400 Epoch=29.0] | Loss=0.00412 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.382 | L2-Norm(final)=11.462 | 4621.5 samples/s | 72.2 steps/s
[Step=15450 Epoch=29.1] | Loss=0.00391 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.363 | L2-Norm(final)=11.462 | 4594.8 samples/s | 71.8 steps/s
[Step=15500 Epoch=29.2] | Loss=0.00372 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=11.462 | 4660.8 samples/s | 72.8 steps/s
[Step=15550 Epoch=29.3] | Loss=0.00355 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=11.462 | 5666.3 samples/s | 88.5 steps/s
[Step=15600 Epoch=29.4] | Loss=0.00339 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.302 | L2-Norm(final)=11.462 | 1944.9 samples/s | 30.4 steps/s
[Step=15650 Epoch=29.5] | Loss=0.00324 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.280 | L2-Norm(final)=11.463 | 4585.4 samples/s | 71.6 steps/s
[Step=15700 Epoch=29.6] | Loss=0.00311 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=11.463 | 4647.2 samples/s | 72.6 steps/s
[Step=15750 Epoch=29.7] | Loss=0.00298 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=11.464 | 4548.7 samples/s | 71.1 steps/s
[Step=15800 Epoch=29.8] | Loss=0.00287 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.215 | L2-Norm(final)=11.464 | 4621.6 samples/s | 72.2 steps/s
[Step=15850 Epoch=29.9] | Loss=0.00276 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.193 | L2-Norm(final)=11.464 | 4666.8 samples/s | 72.9 steps/s
[Step=15900 Epoch=30.0] | Loss=0.00266 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=11.465 | 4526.8 samples/s | 70.7 steps/s
[Step=15950 Epoch=30.1] | Loss=0.00257 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.148 | L2-Norm(final)=11.465 | 4629.7 samples/s | 72.3 steps/s
[Step=16000 Epoch=30.2] | Loss=0.00249 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=11.466 | 4673.2 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05463 | acc=0.9655 | tpr=0.9768 | fpr=0.0590 | 4170.7 samples/s | 16.3 steps/s
Avg test loss: 0.05645, Avg test acc: 0.96530, Avg tpr: 0.97610, Avg fpr: 0.05845, total FA: 456

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.78973 | acc=0.3169 | tpr=0.0175 | fpr=0.0330 | 4264.6 samples/s | 16.7 steps/s
Avg test loss: 7.81395, Avg test acc: 0.31509, Avg tpr: 0.01859, Avg fpr: 0.03282, total FA: 256

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.65699 | acc=0.1130 | tpr=0.6239 | fpr=0.8961 | 4199.7 samples/s | 16.4 steps/s
[Step= 100] | Loss=4.64399 | acc=0.1129 | tpr=0.6034 | fpr=0.8963 | 7916.0 samples/s | 30.9 steps/s
[Step= 150] | Loss=4.65222 | acc=0.1124 | tpr=0.6167 | fpr=0.8969 | 8059.0 samples/s | 31.5 steps/s
[Step= 200] | Loss=4.63877 | acc=0.1126 | tpr=0.6164 | fpr=0.8966 | 8075.4 samples/s | 31.5 steps/s
[Step= 250] | Loss=4.63627 | acc=0.1124 | tpr=0.6044 | fpr=0.8966 | 8002.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=4.63593 | acc=0.1129 | tpr=0.6095 | fpr=0.8961 | 8295.5 samples/s | 32.4 steps/s
[Step= 350] | Loss=4.63035 | acc=0.1128 | tpr=0.6130 | fpr=0.8963 | 7853.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=4.62952 | acc=0.1128 | tpr=0.6160 | fpr=0.8963 | 7869.6 samples/s | 30.7 steps/s
[Step= 450] | Loss=4.63488 | acc=0.1126 | tpr=0.6134 | fpr=0.8965 | 7824.2 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.63498 | acc=0.1123 | tpr=0.6150 | fpr=0.8968 | 7980.1 samples/s | 31.2 steps/s
[Step= 550] | Loss=4.63394 | acc=0.1123 | tpr=0.6204 | fpr=0.8969 | 15360.4 samples/s | 60.0 steps/s
Avg test loss: 4.63482, Avg test acc: 0.11230, Avg tpr: 0.62084, Avg fpr: 0.89694, total FA: 124539

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14534 | acc=0.9797 | tpr=0.9513 | fpr=0.0198 | 4196.9 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.15801 | acc=0.9783 | tpr=0.9659 | fpr=0.0214 | 8002.9 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.16474 | acc=0.9779 | tpr=0.9683 | fpr=0.0219 | 7993.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.16693 | acc=0.9780 | tpr=0.9705 | fpr=0.0218 | 8026.8 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.16424 | acc=0.9783 | tpr=0.9694 | fpr=0.0215 | 7918.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.16781 | acc=0.9779 | tpr=0.9673 | fpr=0.0219 | 8618.6 samples/s | 33.7 steps/s
[Step= 350] | Loss=0.16902 | acc=0.9779 | tpr=0.9668 | fpr=0.0219 | 7822.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.16976 | acc=0.9776 | tpr=0.9639 | fpr=0.0221 | 7764.9 samples/s | 30.3 steps/s
[Step= 450] | Loss=0.17328 | acc=0.9774 | tpr=0.9640 | fpr=0.0224 | 7991.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.17256 | acc=0.9773 | tpr=0.9630 | fpr=0.0224 | 7921.3 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.17169 | acc=0.9774 | tpr=0.9618 | fpr=0.0223 | 14189.7 samples/s | 55.4 steps/s
Avg test loss: 0.17136, Avg test acc: 0.97745, Avg tpr: 0.96117, Avg fpr: 0.02225, total FA: 3090

server round 8/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=16001 Epoch=15.6] | Loss=0.08390 | Reg=0.00251 | acc=0.9219 | L2-Norm=15.846 | L2-Norm(final)=7.604 | 4270.0 samples/s | 66.7 steps/s
[Step=16050 Epoch=15.7] | Loss=0.09099 | Reg=0.00252 | acc=0.9219 | L2-Norm=15.860 | L2-Norm(final)=7.653 | 5021.5 samples/s | 78.5 steps/s
[Step=16100 Epoch=15.7] | Loss=0.08980 | Reg=0.00252 | acc=0.8906 | L2-Norm=15.863 | L2-Norm(final)=7.713 | 5610.5 samples/s | 87.7 steps/s
[Step=16150 Epoch=15.8] | Loss=0.09104 | Reg=0.00252 | acc=0.9375 | L2-Norm=15.863 | L2-Norm(final)=7.771 | 5532.2 samples/s | 86.4 steps/s
[Step=16200 Epoch=15.8] | Loss=0.08844 | Reg=0.00252 | acc=0.9531 | L2-Norm=15.864 | L2-Norm(final)=7.831 | 5725.8 samples/s | 89.5 steps/s
[Step=16250 Epoch=15.9] | Loss=0.08729 | Reg=0.00252 | acc=0.9688 | L2-Norm=15.864 | L2-Norm(final)=7.893 | 5537.0 samples/s | 86.5 steps/s
[Step=16300 Epoch=15.9] | Loss=0.08705 | Reg=0.00252 | acc=0.9219 | L2-Norm=15.864 | L2-Norm(final)=7.952 | 5508.3 samples/s | 86.1 steps/s
[Step=16350 Epoch=16.0] | Loss=0.08664 | Reg=0.00252 | acc=0.9531 | L2-Norm=15.864 | L2-Norm(final)=8.009 | 5714.4 samples/s | 89.3 steps/s
[Step=16400 Epoch=16.0] | Loss=0.08638 | Reg=0.00252 | acc=0.8906 | L2-Norm=15.864 | L2-Norm(final)=8.066 | 5461.4 samples/s | 85.3 steps/s
[Step=16450 Epoch=16.1] | Loss=0.08603 | Reg=0.00252 | acc=0.8906 | L2-Norm=15.864 | L2-Norm(final)=8.121 | 5573.1 samples/s | 87.1 steps/s
[Step=16500 Epoch=16.1] | Loss=0.08572 | Reg=0.00252 | acc=0.9688 | L2-Norm=15.864 | L2-Norm(final)=8.175 | 5488.7 samples/s | 85.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=16.1] | Loss=0.06893 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.865 | L2-Norm(final)=8.714 | 4527.3 samples/s | 70.7 steps/s
[Step=16550 Epoch=16.2] | Loss=0.05635 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.021 | L2-Norm(final)=8.735 | 4346.4 samples/s | 67.9 steps/s
[Step=16600 Epoch=16.2] | Loss=0.04894 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.143 | L2-Norm(final)=8.729 | 4806.5 samples/s | 75.1 steps/s
[Step=16650 Epoch=16.3] | Loss=0.04622 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.235 | L2-Norm(final)=8.723 | 4847.0 samples/s | 75.7 steps/s
[Step=16700 Epoch=16.3] | Loss=0.04396 | Reg=0.00266 | acc=0.9531 | L2-Norm=16.317 | L2-Norm(final)=8.717 | 4862.4 samples/s | 76.0 steps/s
[Step=16750 Epoch=16.4] | Loss=0.04244 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.384 | L2-Norm(final)=8.712 | 4875.2 samples/s | 76.2 steps/s
[Step=16800 Epoch=16.4] | Loss=0.04178 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.441 | L2-Norm(final)=8.706 | 4765.8 samples/s | 74.5 steps/s
[Step=16850 Epoch=16.5] | Loss=0.04115 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.490 | L2-Norm(final)=8.700 | 4867.5 samples/s | 76.1 steps/s
[Step=16900 Epoch=16.5] | Loss=0.04031 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.536 | L2-Norm(final)=8.695 | 4856.8 samples/s | 75.9 steps/s
[Step=16950 Epoch=16.5] | Loss=0.04054 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.580 | L2-Norm(final)=8.687 | 4719.3 samples/s | 73.7 steps/s
[Step=17000 Epoch=16.6] | Loss=0.04016 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.621 | L2-Norm(final)=8.680 | 4883.7 samples/s | 76.3 steps/s
[Step=17050 Epoch=16.6] | Loss=0.03997 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.659 | L2-Norm(final)=8.674 | 4824.7 samples/s | 75.4 steps/s
[Step=17100 Epoch=16.7] | Loss=0.03995 | Reg=0.00279 | acc=0.9219 | L2-Norm=16.696 | L2-Norm(final)=8.668 | 4826.5 samples/s | 75.4 steps/s
[Step=17150 Epoch=16.7] | Loss=0.03978 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.730 | L2-Norm(final)=8.662 | 4836.7 samples/s | 75.6 steps/s
[Step=17200 Epoch=16.8] | Loss=0.03981 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.763 | L2-Norm(final)=8.656 | 4835.6 samples/s | 75.6 steps/s
[Step=17250 Epoch=16.8] | Loss=0.03957 | Reg=0.00282 | acc=0.9219 | L2-Norm=16.795 | L2-Norm(final)=8.649 | 4829.1 samples/s | 75.5 steps/s
[Step=17300 Epoch=16.9] | Loss=0.03922 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.825 | L2-Norm(final)=8.643 | 4792.5 samples/s | 74.9 steps/s
[Step=17350 Epoch=16.9] | Loss=0.03892 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.854 | L2-Norm(final)=8.636 | 4877.1 samples/s | 76.2 steps/s
[Step=17400 Epoch=17.0] | Loss=0.03890 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.882 | L2-Norm(final)=8.630 | 4841.5 samples/s | 75.6 steps/s
[Step=17450 Epoch=17.0] | Loss=0.03895 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.910 | L2-Norm(final)=8.624 | 4870.5 samples/s | 76.1 steps/s
[Step=17500 Epoch=17.1] | Loss=0.03885 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.937 | L2-Norm(final)=8.618 | 5182.5 samples/s | 81.0 steps/s
[Step=17550 Epoch=17.1] | Loss=0.03861 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.965 | L2-Norm(final)=8.612 | 2090.3 samples/s | 32.7 steps/s
[Step=17600 Epoch=17.2] | Loss=0.03792 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.991 | L2-Norm(final)=8.606 | 4929.4 samples/s | 77.0 steps/s
[Step=17650 Epoch=17.2] | Loss=0.03708 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=8.600 | 4779.6 samples/s | 74.7 steps/s
[Step=17700 Epoch=17.3] | Loss=0.03673 | Reg=0.00291 | acc=0.9531 | L2-Norm=17.040 | L2-Norm(final)=8.595 | 4859.6 samples/s | 75.9 steps/s
[Step=17750 Epoch=17.3] | Loss=0.03615 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.063 | L2-Norm(final)=8.590 | 4786.0 samples/s | 74.8 steps/s
[Step=17800 Epoch=17.4] | Loss=0.03588 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.085 | L2-Norm(final)=8.586 | 4855.7 samples/s | 75.9 steps/s
[Step=17850 Epoch=17.4] | Loss=0.03570 | Reg=0.00293 | acc=0.9062 | L2-Norm=17.107 | L2-Norm(final)=8.581 | 4857.1 samples/s | 75.9 steps/s
[Step=17900 Epoch=17.5] | Loss=0.03538 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.128 | L2-Norm(final)=8.576 | 4797.5 samples/s | 75.0 steps/s
[Step=17950 Epoch=17.5] | Loss=0.03512 | Reg=0.00294 | acc=0.9531 | L2-Norm=17.150 | L2-Norm(final)=8.571 | 4826.3 samples/s | 75.4 steps/s
[Step=18000 Epoch=17.6] | Loss=0.03485 | Reg=0.00295 | acc=0.9688 | L2-Norm=17.171 | L2-Norm(final)=8.567 | 4901.2 samples/s | 76.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step18000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=16001 Epoch=30.2] | Loss=0.00349 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.846 | L2-Norm(final)=11.479 | 4147.3 samples/s | 64.8 steps/s
[Step=16050 Epoch=30.3] | Loss=0.00514 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.838 | L2-Norm(final)=11.514 | 4924.3 samples/s | 76.9 steps/s
[Step=16100 Epoch=30.3] | Loss=0.00562 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.838 | L2-Norm(final)=11.566 | 5374.4 samples/s | 84.0 steps/s
[Step=16150 Epoch=30.4] | Loss=0.00561 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.619 | 5145.5 samples/s | 80.4 steps/s
[Step=16200 Epoch=30.5] | Loss=0.00491 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.666 | 5250.8 samples/s | 82.0 steps/s
[Step=16250 Epoch=30.6] | Loss=0.00473 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.711 | 5331.6 samples/s | 83.3 steps/s
[Step=16300 Epoch=30.7] | Loss=0.00468 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.754 | 5288.7 samples/s | 82.6 steps/s
[Step=16350 Epoch=30.8] | Loss=0.00485 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.794 | 5246.4 samples/s | 82.0 steps/s
[Step=16400 Epoch=30.9] | Loss=0.00467 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.834 | 5355.4 samples/s | 83.7 steps/s
[Step=16450 Epoch=31.0] | Loss=0.00470 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.872 | 5234.2 samples/s | 81.8 steps/s
[Step=16500 Epoch=31.1] | Loss=0.00452 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=11.909 | 5447.8 samples/s | 85.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=31.1] | Loss=0.00968 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.837 | L2-Norm(final)=12.271 | 4023.6 samples/s | 62.9 steps/s
[Step=16550 Epoch=31.2] | Loss=0.00748 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=12.282 | 4381.2 samples/s | 68.5 steps/s
[Step=16600 Epoch=31.3] | Loss=0.01230 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.190 | L2-Norm(final)=12.257 | 4631.2 samples/s | 72.4 steps/s
[Step=16650 Epoch=31.4] | Loss=0.01199 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.386 | L2-Norm(final)=12.221 | 4621.9 samples/s | 72.2 steps/s
[Step=16700 Epoch=31.5] | Loss=0.01065 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.528 | L2-Norm(final)=12.190 | 4572.2 samples/s | 71.4 steps/s
[Step=16750 Epoch=31.6] | Loss=0.01021 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.617 | L2-Norm(final)=12.168 | 4653.0 samples/s | 72.7 steps/s
[Step=16800 Epoch=31.7] | Loss=0.00861 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.681 | L2-Norm(final)=12.152 | 4563.9 samples/s | 71.3 steps/s
[Step=16850 Epoch=31.8] | Loss=0.00840 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.725 | L2-Norm(final)=12.138 | 4638.6 samples/s | 72.5 steps/s
[Step=16900 Epoch=31.9] | Loss=0.00832 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=12.124 | 4590.6 samples/s | 71.7 steps/s
[Step=16950 Epoch=32.0] | Loss=0.00776 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.793 | L2-Norm(final)=12.110 | 4646.8 samples/s | 72.6 steps/s
[Step=17000 Epoch=32.0] | Loss=0.00743 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.818 | L2-Norm(final)=12.098 | 4619.3 samples/s | 72.2 steps/s
[Step=17050 Epoch=32.1] | Loss=0.00682 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.836 | L2-Norm(final)=12.089 | 2123.5 samples/s | 33.2 steps/s
[Step=17100 Epoch=32.2] | Loss=0.00635 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.847 | L2-Norm(final)=12.081 | 4661.5 samples/s | 72.8 steps/s
[Step=17150 Epoch=32.3] | Loss=0.00598 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.855 | L2-Norm(final)=12.075 | 4577.6 samples/s | 71.5 steps/s
[Step=17200 Epoch=32.4] | Loss=0.00581 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.861 | L2-Norm(final)=12.068 | 4584.2 samples/s | 71.6 steps/s
[Step=17250 Epoch=32.5] | Loss=0.00548 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.865 | L2-Norm(final)=12.062 | 4596.3 samples/s | 71.8 steps/s
[Step=17300 Epoch=32.6] | Loss=0.00537 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.867 | L2-Norm(final)=12.056 | 4610.6 samples/s | 72.0 steps/s
[Step=17350 Epoch=32.7] | Loss=0.00507 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.866 | L2-Norm(final)=12.050 | 4639.3 samples/s | 72.5 steps/s
[Step=17400 Epoch=32.8] | Loss=0.00481 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.864 | L2-Norm(final)=12.045 | 4604.7 samples/s | 71.9 steps/s
[Step=17450 Epoch=32.9] | Loss=0.00457 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.860 | L2-Norm(final)=12.040 | 4602.8 samples/s | 71.9 steps/s
[Step=17500 Epoch=33.0] | Loss=0.00440 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.855 | L2-Norm(final)=12.037 | 4621.5 samples/s | 72.2 steps/s
[Step=17550 Epoch=33.1] | Loss=0.00423 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.849 | L2-Norm(final)=12.033 | 5763.3 samples/s | 90.1 steps/s
[Step=17600 Epoch=33.2] | Loss=0.00404 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=12.030 | 1966.8 samples/s | 30.7 steps/s
[Step=17650 Epoch=33.3] | Loss=0.00386 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.834 | L2-Norm(final)=12.028 | 4557.2 samples/s | 71.2 steps/s
[Step=17700 Epoch=33.4] | Loss=0.00370 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.825 | L2-Norm(final)=12.025 | 4637.9 samples/s | 72.5 steps/s
[Step=17750 Epoch=33.5] | Loss=0.00356 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.815 | L2-Norm(final)=12.023 | 4591.4 samples/s | 71.7 steps/s
[Step=17800 Epoch=33.6] | Loss=0.00342 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=12.021 | 4621.1 samples/s | 72.2 steps/s
[Step=17850 Epoch=33.6] | Loss=0.00329 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.791 | L2-Norm(final)=12.020 | 4671.4 samples/s | 73.0 steps/s
[Step=17900 Epoch=33.7] | Loss=0.00318 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.777 | L2-Norm(final)=12.018 | 4631.7 samples/s | 72.4 steps/s
[Step=17950 Epoch=33.8] | Loss=0.00307 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.764 | L2-Norm(final)=12.017 | 4652.1 samples/s | 72.7 steps/s
[Step=18000 Epoch=33.9] | Loss=0.00297 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=12.016 | 4581.9 samples/s | 71.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05488 | acc=0.9647 | tpr=0.9728 | fpr=0.0530 | 4216.9 samples/s | 16.5 steps/s
Avg test loss: 0.05615, Avg test acc: 0.96450, Avg tpr: 0.97266, Avg fpr: 0.05345, total FA: 417

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=12.99251 | acc=0.3118 | tpr=0.0097 | fpr=0.0322 | 4282.8 samples/s | 16.7 steps/s
Avg test loss: 13.00121, Avg test acc: 0.30888, Avg tpr: 0.00968, Avg fpr: 0.03307, total FA: 258

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.20291 | acc=0.1361 | tpr=0.6150 | fpr=0.8725 | 4192.2 samples/s | 16.4 steps/s
[Step= 100] | Loss=4.18339 | acc=0.1361 | tpr=0.5949 | fpr=0.8725 | 7943.1 samples/s | 31.0 steps/s
[Step= 150] | Loss=4.18891 | acc=0.1367 | tpr=0.6110 | fpr=0.8720 | 7909.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=4.17868 | acc=0.1372 | tpr=0.6230 | fpr=0.8716 | 7988.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.18333 | acc=0.1366 | tpr=0.6114 | fpr=0.8721 | 7866.2 samples/s | 30.7 steps/s
[Step= 300] | Loss=4.18261 | acc=0.1372 | tpr=0.6240 | fpr=0.8717 | 8053.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=4.17814 | acc=0.1371 | tpr=0.6237 | fpr=0.8718 | 8004.6 samples/s | 31.3 steps/s
[Step= 400] | Loss=4.18020 | acc=0.1375 | tpr=0.6247 | fpr=0.8714 | 8382.2 samples/s | 32.7 steps/s
[Step= 450] | Loss=4.18784 | acc=0.1372 | tpr=0.6232 | fpr=0.8717 | 7796.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=4.18783 | acc=0.1368 | tpr=0.6189 | fpr=0.8719 | 7665.4 samples/s | 29.9 steps/s
[Step= 550] | Loss=4.18803 | acc=0.1370 | tpr=0.6204 | fpr=0.8718 | 14838.9 samples/s | 58.0 steps/s
Avg test loss: 4.18953, Avg test acc: 0.13692, Avg tpr: 0.62044, Avg fpr: 0.87187, total FA: 121057

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12397 | acc=0.9802 | tpr=0.9602 | fpr=0.0195 | 4230.6 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.13001 | acc=0.9803 | tpr=0.9659 | fpr=0.0194 | 7889.6 samples/s | 30.8 steps/s
[Step= 150] | Loss=0.13584 | acc=0.9799 | tpr=0.9683 | fpr=0.0199 | 8032.6 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.13756 | acc=0.9800 | tpr=0.9705 | fpr=0.0198 | 7929.1 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.13510 | acc=0.9800 | tpr=0.9686 | fpr=0.0197 | 7837.6 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.13874 | acc=0.9798 | tpr=0.9680 | fpr=0.0200 | 8111.4 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.13970 | acc=0.9797 | tpr=0.9674 | fpr=0.0200 | 8061.9 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.14015 | acc=0.9796 | tpr=0.9666 | fpr=0.0202 | 7959.8 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.14240 | acc=0.9794 | tpr=0.9664 | fpr=0.0203 | 7926.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14233 | acc=0.9795 | tpr=0.9656 | fpr=0.0203 | 8088.2 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.14145 | acc=0.9796 | tpr=0.9662 | fpr=0.0201 | 14528.4 samples/s | 56.8 steps/s
Avg test loss: 0.14114, Avg test acc: 0.97965, Avg tpr: 0.96632, Avg fpr: 0.02011, total FA: 2792

server round 9/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=18001 Epoch=17.6] | Loss=0.11346 | Reg=0.00263 | acc=0.9062 | L2-Norm=16.204 | L2-Norm(final)=8.424 | 4062.1 samples/s | 63.5 steps/s
[Step=18050 Epoch=17.6] | Loss=0.10714 | Reg=0.00263 | acc=0.9219 | L2-Norm=16.210 | L2-Norm(final)=8.474 | 5349.6 samples/s | 83.6 steps/s
[Step=18100 Epoch=17.7] | Loss=0.10385 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.211 | L2-Norm(final)=8.537 | 5631.5 samples/s | 88.0 steps/s
[Step=18150 Epoch=17.7] | Loss=0.09898 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.211 | L2-Norm(final)=8.594 | 5725.1 samples/s | 89.5 steps/s
[Step=18200 Epoch=17.8] | Loss=0.09881 | Reg=0.00263 | acc=0.8750 | L2-Norm=16.211 | L2-Norm(final)=8.647 | 5457.8 samples/s | 85.3 steps/s
[Step=18250 Epoch=17.8] | Loss=0.09722 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.211 | L2-Norm(final)=8.695 | 5600.4 samples/s | 87.5 steps/s
[Step=18300 Epoch=17.9] | Loss=0.09465 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.211 | L2-Norm(final)=8.743 | 5679.2 samples/s | 88.7 steps/s
[Step=18350 Epoch=17.9] | Loss=0.09453 | Reg=0.00263 | acc=0.8906 | L2-Norm=16.211 | L2-Norm(final)=8.790 | 5548.2 samples/s | 86.7 steps/s
[Step=18400 Epoch=18.0] | Loss=0.09391 | Reg=0.00263 | acc=0.9062 | L2-Norm=16.211 | L2-Norm(final)=8.835 | 5595.8 samples/s | 87.4 steps/s
[Step=18450 Epoch=18.0] | Loss=0.09297 | Reg=0.00263 | acc=0.9219 | L2-Norm=16.211 | L2-Norm(final)=8.879 | 5589.6 samples/s | 87.3 steps/s
[Step=18500 Epoch=18.1] | Loss=0.09220 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.212 | L2-Norm(final)=8.921 | 5627.5 samples/s | 87.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=18.1] | Loss=0.07503 | Reg=0.00263 | acc=0.9219 | L2-Norm=16.212 | L2-Norm(final)=9.340 | 4136.1 samples/s | 64.6 steps/s
[Step=18550 Epoch=18.1] | Loss=0.06481 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.419 | L2-Norm(final)=9.353 | 4818.8 samples/s | 75.3 steps/s
[Step=18600 Epoch=18.2] | Loss=0.06095 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.601 | L2-Norm(final)=9.348 | 4834.8 samples/s | 75.5 steps/s
[Step=18650 Epoch=18.2] | Loss=0.05662 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.721 | L2-Norm(final)=9.332 | 4818.5 samples/s | 75.3 steps/s
[Step=18700 Epoch=18.3] | Loss=0.05099 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.814 | L2-Norm(final)=9.321 | 4850.8 samples/s | 75.8 steps/s
[Step=18750 Epoch=18.3] | Loss=0.04923 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.886 | L2-Norm(final)=9.312 | 4852.5 samples/s | 75.8 steps/s
[Step=18800 Epoch=18.4] | Loss=0.04796 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.945 | L2-Norm(final)=9.303 | 4889.5 samples/s | 76.4 steps/s
[Step=18850 Epoch=18.4] | Loss=0.04623 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.996 | L2-Norm(final)=9.296 | 4801.3 samples/s | 75.0 steps/s
[Step=18900 Epoch=18.5] | Loss=0.04491 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.041 | L2-Norm(final)=9.291 | 4840.9 samples/s | 75.6 steps/s
[Step=18950 Epoch=18.5] | Loss=0.04446 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.083 | L2-Norm(final)=9.286 | 4870.2 samples/s | 76.1 steps/s
[Step=19000 Epoch=18.6] | Loss=0.04312 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.122 | L2-Norm(final)=9.280 | 4823.5 samples/s | 75.4 steps/s
[Step=19050 Epoch=18.6] | Loss=0.04277 | Reg=0.00295 | acc=0.9688 | L2-Norm=17.159 | L2-Norm(final)=9.274 | 4851.5 samples/s | 75.8 steps/s
[Step=19100 Epoch=18.6] | Loss=0.04267 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.193 | L2-Norm(final)=9.266 | 4861.3 samples/s | 76.0 steps/s
[Step=19150 Epoch=18.7] | Loss=0.04250 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.226 | L2-Norm(final)=9.259 | 4820.0 samples/s | 75.3 steps/s
[Step=19200 Epoch=18.7] | Loss=0.04201 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.258 | L2-Norm(final)=9.252 | 4865.9 samples/s | 76.0 steps/s
[Step=19250 Epoch=18.8] | Loss=0.04151 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.287 | L2-Norm(final)=9.246 | 4832.4 samples/s | 75.5 steps/s
[Step=19300 Epoch=18.8] | Loss=0.04095 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.316 | L2-Norm(final)=9.240 | 4880.2 samples/s | 76.3 steps/s
[Step=19350 Epoch=18.9] | Loss=0.04063 | Reg=0.00301 | acc=0.9531 | L2-Norm=17.343 | L2-Norm(final)=9.234 | 4800.8 samples/s | 75.0 steps/s
[Step=19400 Epoch=18.9] | Loss=0.04024 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.370 | L2-Norm(final)=9.228 | 4831.5 samples/s | 75.5 steps/s
[Step=19450 Epoch=19.0] | Loss=0.04016 | Reg=0.00303 | acc=0.9844 | L2-Norm=17.396 | L2-Norm(final)=9.222 | 4899.6 samples/s | 76.6 steps/s
[Step=19500 Epoch=19.0] | Loss=0.03987 | Reg=0.00304 | acc=0.9688 | L2-Norm=17.420 | L2-Norm(final)=9.217 | 5133.5 samples/s | 80.2 steps/s
[Step=19550 Epoch=19.1] | Loss=0.03929 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.444 | L2-Norm(final)=9.211 | 2157.5 samples/s | 33.7 steps/s
[Step=19600 Epoch=19.1] | Loss=0.03873 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.466 | L2-Norm(final)=9.205 | 4753.1 samples/s | 74.3 steps/s
[Step=19650 Epoch=19.2] | Loss=0.03803 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.487 | L2-Norm(final)=9.200 | 4808.2 samples/s | 75.1 steps/s
[Step=19700 Epoch=19.2] | Loss=0.03762 | Reg=0.00307 | acc=0.9844 | L2-Norm=17.508 | L2-Norm(final)=9.195 | 4824.7 samples/s | 75.4 steps/s
[Step=19750 Epoch=19.3] | Loss=0.03716 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.528 | L2-Norm(final)=9.190 | 4838.8 samples/s | 75.6 steps/s
[Step=19800 Epoch=19.3] | Loss=0.03693 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.547 | L2-Norm(final)=9.185 | 4818.8 samples/s | 75.3 steps/s
[Step=19850 Epoch=19.4] | Loss=0.03659 | Reg=0.00309 | acc=0.9531 | L2-Norm=17.566 | L2-Norm(final)=9.180 | 4910.5 samples/s | 76.7 steps/s
[Step=19900 Epoch=19.4] | Loss=0.03634 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.585 | L2-Norm(final)=9.175 | 4839.2 samples/s | 75.6 steps/s
[Step=19950 Epoch=19.5] | Loss=0.03611 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.603 | L2-Norm(final)=9.170 | 4828.2 samples/s | 75.4 steps/s
[Step=20000 Epoch=19.5] | Loss=0.03599 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.621 | L2-Norm(final)=9.165 | 4866.4 samples/s | 76.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step20000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=18001 Epoch=33.9] | Loss=0.00833 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.204 | L2-Norm(final)=11.994 | 4048.5 samples/s | 63.3 steps/s
[Step=18050 Epoch=34.0] | Loss=0.00616 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.198 | L2-Norm(final)=12.022 | 5003.5 samples/s | 78.2 steps/s
[Step=18100 Epoch=34.1] | Loss=0.00564 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.059 | 4953.9 samples/s | 77.4 steps/s
[Step=18150 Epoch=34.2] | Loss=0.00547 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.197 | L2-Norm(final)=12.097 | 5252.1 samples/s | 82.1 steps/s
[Step=18200 Epoch=34.3] | Loss=0.00521 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.131 | 5255.1 samples/s | 82.1 steps/s
[Step=18250 Epoch=34.4] | Loss=0.00502 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.166 | 5352.9 samples/s | 83.6 steps/s
[Step=18300 Epoch=34.5] | Loss=0.00495 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.202 | 5275.2 samples/s | 82.4 steps/s
[Step=18350 Epoch=34.6] | Loss=0.00479 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.237 | 5299.1 samples/s | 82.8 steps/s
[Step=18400 Epoch=34.7] | Loss=0.00471 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.270 | 5325.1 samples/s | 83.2 steps/s
[Step=18450 Epoch=34.8] | Loss=0.00469 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.304 | 5343.9 samples/s | 83.5 steps/s
[Step=18500 Epoch=34.9] | Loss=0.00465 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.337 | 5423.0 samples/s | 84.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=34.9] | Loss=0.00434 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.197 | L2-Norm(final)=12.670 | 4117.2 samples/s | 64.3 steps/s
[Step=18550 Epoch=35.0] | Loss=0.00251 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.233 | L2-Norm(final)=12.685 | 4519.7 samples/s | 70.6 steps/s
[Step=18600 Epoch=35.1] | Loss=0.00404 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.288 | L2-Norm(final)=12.685 | 4666.0 samples/s | 72.9 steps/s
[Step=18650 Epoch=35.2] | Loss=0.00790 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.392 | L2-Norm(final)=12.661 | 4540.6 samples/s | 70.9 steps/s
[Step=18700 Epoch=35.2] | Loss=0.00790 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.502 | L2-Norm(final)=12.624 | 4593.8 samples/s | 71.8 steps/s
[Step=18750 Epoch=35.3] | Loss=0.00699 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=12.599 | 4694.7 samples/s | 73.4 steps/s
[Step=18800 Epoch=35.4] | Loss=0.00642 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.634 | L2-Norm(final)=12.581 | 4550.1 samples/s | 71.1 steps/s
[Step=18850 Epoch=35.5] | Loss=0.00576 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.673 | L2-Norm(final)=12.569 | 4624.5 samples/s | 72.3 steps/s
[Step=18900 Epoch=35.6] | Loss=0.00555 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.703 | L2-Norm(final)=12.557 | 4644.2 samples/s | 72.6 steps/s
[Step=18950 Epoch=35.7] | Loss=0.00533 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.728 | L2-Norm(final)=12.546 | 4621.6 samples/s | 72.2 steps/s
[Step=19000 Epoch=35.8] | Loss=0.00499 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=12.537 | 4715.3 samples/s | 73.7 steps/s
[Step=19050 Epoch=35.9] | Loss=0.00485 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.765 | L2-Norm(final)=12.529 | 2068.5 samples/s | 32.3 steps/s
[Step=19100 Epoch=36.0] | Loss=0.00467 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.779 | L2-Norm(final)=12.520 | 4726.7 samples/s | 73.9 steps/s
[Step=19150 Epoch=36.1] | Loss=0.00436 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.790 | L2-Norm(final)=12.512 | 4528.2 samples/s | 70.8 steps/s
[Step=19200 Epoch=36.2] | Loss=0.00413 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.796 | L2-Norm(final)=12.506 | 4605.7 samples/s | 72.0 steps/s
[Step=19250 Epoch=36.3] | Loss=0.00389 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.799 | L2-Norm(final)=12.501 | 4578.3 samples/s | 71.5 steps/s
[Step=19300 Epoch=36.4] | Loss=0.00367 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.801 | L2-Norm(final)=12.496 | 4624.0 samples/s | 72.2 steps/s
[Step=19350 Epoch=36.5] | Loss=0.00345 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.799 | L2-Norm(final)=12.493 | 4617.8 samples/s | 72.2 steps/s
[Step=19400 Epoch=36.6] | Loss=0.00328 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=12.489 | 4610.1 samples/s | 72.0 steps/s
[Step=19450 Epoch=36.7] | Loss=0.00321 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.789 | L2-Norm(final)=12.487 | 4635.2 samples/s | 72.4 steps/s
[Step=19500 Epoch=36.8] | Loss=0.00306 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.782 | L2-Norm(final)=12.483 | 4611.5 samples/s | 72.1 steps/s
[Step=19550 Epoch=36.9] | Loss=0.00291 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=12.481 | 5803.9 samples/s | 90.7 steps/s
[Step=19600 Epoch=36.9] | Loss=0.00278 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.763 | L2-Norm(final)=12.479 | 1973.2 samples/s | 30.8 steps/s
[Step=19650 Epoch=37.0] | Loss=0.00266 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.752 | L2-Norm(final)=12.477 | 4613.8 samples/s | 72.1 steps/s
[Step=19700 Epoch=37.1] | Loss=0.00255 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.740 | L2-Norm(final)=12.475 | 4649.1 samples/s | 72.6 steps/s
[Step=19750 Epoch=37.2] | Loss=0.00245 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.727 | L2-Norm(final)=12.474 | 4647.6 samples/s | 72.6 steps/s
[Step=19800 Epoch=37.3] | Loss=0.00236 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.713 | L2-Norm(final)=12.472 | 4701.7 samples/s | 73.5 steps/s
[Step=19850 Epoch=37.4] | Loss=0.00227 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=12.472 | 4567.4 samples/s | 71.4 steps/s
[Step=19900 Epoch=37.5] | Loss=0.00219 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.682 | L2-Norm(final)=12.471 | 4634.1 samples/s | 72.4 steps/s
[Step=19950 Epoch=37.6] | Loss=0.00211 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.666 | L2-Norm(final)=12.470 | 4715.2 samples/s | 73.7 steps/s
[Step=20000 Epoch=37.7] | Loss=0.00204 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.650 | L2-Norm(final)=12.469 | 4543.3 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.04884 | acc=0.9666 | tpr=0.9719 | fpr=0.0451 | 4223.4 samples/s | 16.5 steps/s
Avg test loss: 0.05133, Avg test acc: 0.96514, Avg tpr: 0.96963, Avg fpr: 0.04474, total FA: 349

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.50045 | acc=0.3140 | tpr=0.0088 | fpr=0.0233 | 4153.0 samples/s | 16.2 steps/s
Avg test loss: 10.50631, Avg test acc: 0.31116, Avg tpr: 0.00868, Avg fpr: 0.02359, total FA: 184

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.80594 | acc=0.1445 | tpr=0.5442 | fpr=0.8627 | 4208.1 samples/s | 16.4 steps/s
[Step= 100] | Loss=3.78619 | acc=0.1435 | tpr=0.5245 | fpr=0.8636 | 8092.9 samples/s | 31.6 steps/s
[Step= 150] | Loss=3.78795 | acc=0.1433 | tpr=0.5115 | fpr=0.8635 | 8223.9 samples/s | 32.1 steps/s
[Step= 200] | Loss=3.77989 | acc=0.1435 | tpr=0.5115 | fpr=0.8632 | 7705.8 samples/s | 30.1 steps/s
[Step= 250] | Loss=3.77813 | acc=0.1429 | tpr=0.5231 | fpr=0.8640 | 8301.8 samples/s | 32.4 steps/s
[Step= 300] | Loss=3.77752 | acc=0.1429 | tpr=0.5229 | fpr=0.8640 | 7985.3 samples/s | 31.2 steps/s
[Step= 350] | Loss=3.77274 | acc=0.1435 | tpr=0.5241 | fpr=0.8634 | 7855.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=3.77162 | acc=0.1436 | tpr=0.5241 | fpr=0.8633 | 8031.2 samples/s | 31.4 steps/s
[Step= 450] | Loss=3.77529 | acc=0.1434 | tpr=0.5234 | fpr=0.8635 | 8026.7 samples/s | 31.4 steps/s
[Step= 500] | Loss=3.77471 | acc=0.1434 | tpr=0.5251 | fpr=0.8635 | 8075.7 samples/s | 31.5 steps/s
[Step= 550] | Loss=3.77302 | acc=0.1438 | tpr=0.5249 | fpr=0.8631 | 14421.2 samples/s | 56.3 steps/s
Avg test loss: 3.77412, Avg test acc: 0.14376, Avg tpr: 0.52496, Avg fpr: 0.86317, total FA: 119849

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14592 | acc=0.9807 | tpr=0.9602 | fpr=0.0189 | 4226.2 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.15011 | acc=0.9800 | tpr=0.9723 | fpr=0.0198 | 7995.6 samples/s | 31.2 steps/s
[Step= 150] | Loss=0.15628 | acc=0.9793 | tpr=0.9726 | fpr=0.0206 | 8057.5 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.15854 | acc=0.9792 | tpr=0.9705 | fpr=0.0206 | 8214.5 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.15648 | acc=0.9793 | tpr=0.9694 | fpr=0.0206 | 7880.3 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.15836 | acc=0.9791 | tpr=0.9687 | fpr=0.0207 | 8120.2 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.16047 | acc=0.9790 | tpr=0.9668 | fpr=0.0208 | 7691.9 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.16178 | acc=0.9788 | tpr=0.9655 | fpr=0.0210 | 7914.3 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.16507 | acc=0.9786 | tpr=0.9625 | fpr=0.0211 | 7975.0 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.16451 | acc=0.9786 | tpr=0.9630 | fpr=0.0211 | 7910.8 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.16363 | acc=0.9787 | tpr=0.9630 | fpr=0.0210 | 15252.1 samples/s | 59.6 steps/s
Avg test loss: 0.16335, Avg test acc: 0.97877, Avg tpr: 0.96276, Avg fpr: 0.02094, total FA: 2908

server round 10/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=20001 Epoch=19.5] | Loss=0.08763 | Reg=0.00268 | acc=0.9375 | L2-Norm=16.383 | L2-Norm(final)=9.027 | 3969.7 samples/s | 62.0 steps/s
[Step=20050 Epoch=19.6] | Loss=0.07665 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.386 | L2-Norm(final)=9.051 | 5523.0 samples/s | 86.3 steps/s
[Step=20100 Epoch=19.6] | Loss=0.07606 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.387 | L2-Norm(final)=9.074 | 5563.2 samples/s | 86.9 steps/s
[Step=20150 Epoch=19.7] | Loss=0.07563 | Reg=0.00269 | acc=0.9375 | L2-Norm=16.387 | L2-Norm(final)=9.094 | 5538.1 samples/s | 86.5 steps/s
[Step=20200 Epoch=19.7] | Loss=0.07552 | Reg=0.00269 | acc=0.9375 | L2-Norm=16.387 | L2-Norm(final)=9.113 | 5566.5 samples/s | 87.0 steps/s
[Step=20250 Epoch=19.8] | Loss=0.07521 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.387 | L2-Norm(final)=9.132 | 5747.3 samples/s | 89.8 steps/s
[Step=20300 Epoch=19.8] | Loss=0.07468 | Reg=0.00269 | acc=0.8594 | L2-Norm=16.387 | L2-Norm(final)=9.151 | 5503.1 samples/s | 86.0 steps/s
[Step=20350 Epoch=19.9] | Loss=0.07379 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.387 | L2-Norm(final)=9.168 | 5633.0 samples/s | 88.0 steps/s
[Step=20400 Epoch=19.9] | Loss=0.07289 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.387 | L2-Norm(final)=9.186 | 5641.3 samples/s | 88.1 steps/s
[Step=20450 Epoch=20.0] | Loss=0.07285 | Reg=0.00269 | acc=0.9219 | L2-Norm=16.387 | L2-Norm(final)=9.203 | 5526.5 samples/s | 86.4 steps/s
[Step=20500 Epoch=20.0] | Loss=0.07236 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.387 | L2-Norm(final)=9.220 | 5500.6 samples/s | 85.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=20.0] | Loss=0.05498 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.387 | L2-Norm(final)=9.393 | 4322.9 samples/s | 67.5 steps/s
[Step=20550 Epoch=20.1] | Loss=0.05135 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.437 | L2-Norm(final)=9.402 | 4528.0 samples/s | 70.8 steps/s
[Step=20600 Epoch=20.1] | Loss=0.04335 | Reg=0.00272 | acc=0.9375 | L2-Norm=16.478 | L2-Norm(final)=9.405 | 4838.4 samples/s | 75.6 steps/s
[Step=20650 Epoch=20.2] | Loss=0.04057 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.505 | L2-Norm(final)=9.404 | 4824.2 samples/s | 75.4 steps/s
[Step=20700 Epoch=20.2] | Loss=0.03789 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.526 | L2-Norm(final)=9.405 | 4847.1 samples/s | 75.7 steps/s
[Step=20750 Epoch=20.3] | Loss=0.03585 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.542 | L2-Norm(final)=9.404 | 4836.1 samples/s | 75.6 steps/s
[Step=20800 Epoch=20.3] | Loss=0.03379 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.555 | L2-Norm(final)=9.403 | 4892.7 samples/s | 76.4 steps/s
[Step=20850 Epoch=20.4] | Loss=0.03240 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.568 | L2-Norm(final)=9.402 | 4867.2 samples/s | 76.0 steps/s
[Step=20900 Epoch=20.4] | Loss=0.03183 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.578 | L2-Norm(final)=9.401 | 4792.3 samples/s | 74.9 steps/s
[Step=20950 Epoch=20.5] | Loss=0.03098 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.588 | L2-Norm(final)=9.401 | 4895.0 samples/s | 76.5 steps/s
[Step=21000 Epoch=20.5] | Loss=0.03005 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.596 | L2-Norm(final)=9.400 | 4793.1 samples/s | 74.9 steps/s
[Step=21050 Epoch=20.6] | Loss=0.02944 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.605 | L2-Norm(final)=9.400 | 4893.8 samples/s | 76.5 steps/s
[Step=21100 Epoch=20.6] | Loss=0.02902 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.612 | L2-Norm(final)=9.400 | 4839.9 samples/s | 75.6 steps/s
[Step=21150 Epoch=20.6] | Loss=0.02842 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.620 | L2-Norm(final)=9.399 | 4807.9 samples/s | 75.1 steps/s
[Step=21200 Epoch=20.7] | Loss=0.02799 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.626 | L2-Norm(final)=9.398 | 4830.5 samples/s | 75.5 steps/s
[Step=21250 Epoch=20.7] | Loss=0.02766 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.633 | L2-Norm(final)=9.398 | 4854.7 samples/s | 75.9 steps/s
[Step=21300 Epoch=20.8] | Loss=0.02734 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.639 | L2-Norm(final)=9.397 | 4830.5 samples/s | 75.5 steps/s
[Step=21350 Epoch=20.8] | Loss=0.02706 | Reg=0.00277 | acc=0.9531 | L2-Norm=16.645 | L2-Norm(final)=9.396 | 4820.8 samples/s | 75.3 steps/s
[Step=21400 Epoch=20.9] | Loss=0.02708 | Reg=0.00277 | acc=0.9531 | L2-Norm=16.651 | L2-Norm(final)=9.395 | 4823.0 samples/s | 75.4 steps/s
[Step=21450 Epoch=20.9] | Loss=0.02688 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.656 | L2-Norm(final)=9.394 | 4860.4 samples/s | 75.9 steps/s
[Step=21500 Epoch=21.0] | Loss=0.02684 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.661 | L2-Norm(final)=9.393 | 5216.7 samples/s | 81.5 steps/s
[Step=21550 Epoch=21.0] | Loss=0.02647 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.666 | L2-Norm(final)=9.392 | 2132.7 samples/s | 33.3 steps/s
[Step=21600 Epoch=21.1] | Loss=0.02599 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.671 | L2-Norm(final)=9.391 | 4826.4 samples/s | 75.4 steps/s
[Step=21650 Epoch=21.1] | Loss=0.02555 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.675 | L2-Norm(final)=9.391 | 4825.3 samples/s | 75.4 steps/s
[Step=21700 Epoch=21.2] | Loss=0.02523 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.679 | L2-Norm(final)=9.390 | 4845.2 samples/s | 75.7 steps/s
[Step=21750 Epoch=21.2] | Loss=0.02495 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.683 | L2-Norm(final)=9.390 | 4789.0 samples/s | 74.8 steps/s
[Step=21800 Epoch=21.3] | Loss=0.02469 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.687 | L2-Norm(final)=9.389 | 4784.6 samples/s | 74.8 steps/s
[Step=21850 Epoch=21.3] | Loss=0.02434 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.691 | L2-Norm(final)=9.389 | 4834.7 samples/s | 75.5 steps/s
[Step=21900 Epoch=21.4] | Loss=0.02413 | Reg=0.00279 | acc=0.9531 | L2-Norm=16.694 | L2-Norm(final)=9.389 | 4873.9 samples/s | 76.2 steps/s
[Step=21950 Epoch=21.4] | Loss=0.02384 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.698 | L2-Norm(final)=9.388 | 4791.0 samples/s | 74.9 steps/s
[Step=22000 Epoch=21.5] | Loss=0.02357 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.702 | L2-Norm(final)=9.388 | 4799.7 samples/s | 75.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step22000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=20001 Epoch=37.7] | Loss=0.00040 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.383 | L2-Norm(final)=12.451 | 3862.9 samples/s | 60.4 steps/s
[Step=20050 Epoch=37.8] | Loss=0.00534 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.379 | L2-Norm(final)=12.460 | 4858.4 samples/s | 75.9 steps/s
[Step=20100 Epoch=37.9] | Loss=0.00506 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.379 | L2-Norm(final)=12.471 | 5217.9 samples/s | 81.5 steps/s
[Step=20150 Epoch=38.0] | Loss=0.00458 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.379 | L2-Norm(final)=12.483 | 5272.2 samples/s | 82.4 steps/s
[Step=20200 Epoch=38.1] | Loss=0.00416 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.379 | L2-Norm(final)=12.495 | 5246.8 samples/s | 82.0 steps/s
[Step=20250 Epoch=38.2] | Loss=0.00411 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.508 | 5248.2 samples/s | 82.0 steps/s
[Step=20300 Epoch=38.3] | Loss=0.00409 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.522 | 5326.3 samples/s | 83.2 steps/s
[Step=20350 Epoch=38.4] | Loss=0.00417 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.378 | L2-Norm(final)=12.535 | 5372.2 samples/s | 83.9 steps/s
[Step=20400 Epoch=38.5] | Loss=0.00407 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.548 | 5230.7 samples/s | 81.7 steps/s
[Step=20450 Epoch=38.5] | Loss=0.00411 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.560 | 5379.5 samples/s | 84.1 steps/s
[Step=20500 Epoch=38.6] | Loss=0.00408 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.572 | 5381.2 samples/s | 84.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=38.6] | Loss=0.00090 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=12.694 | 4095.0 samples/s | 64.0 steps/s
[Step=20550 Epoch=38.7] | Loss=0.00153 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.356 | L2-Norm(final)=12.704 | 4380.9 samples/s | 68.5 steps/s
[Step=20600 Epoch=38.8] | Loss=0.00137 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=12.710 | 4593.8 samples/s | 71.8 steps/s
[Step=20650 Epoch=38.9] | Loss=0.00106 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.335 | L2-Norm(final)=12.713 | 4584.6 samples/s | 71.6 steps/s
[Step=20700 Epoch=39.0] | Loss=0.00082 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.321 | L2-Norm(final)=12.717 | 4580.9 samples/s | 71.6 steps/s
[Step=20750 Epoch=39.1] | Loss=0.00069 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=12.719 | 4584.4 samples/s | 71.6 steps/s
[Step=20800 Epoch=39.2] | Loss=0.00082 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.290 | L2-Norm(final)=12.720 | 4568.4 samples/s | 71.4 steps/s
[Step=20850 Epoch=39.3] | Loss=0.00072 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=12.721 | 4640.2 samples/s | 72.5 steps/s
[Step=20900 Epoch=39.4] | Loss=0.00064 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.264 | L2-Norm(final)=12.722 | 4651.6 samples/s | 72.7 steps/s
[Step=20950 Epoch=39.5] | Loss=0.00058 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.249 | L2-Norm(final)=12.723 | 4565.2 samples/s | 71.3 steps/s
[Step=21000 Epoch=39.6] | Loss=0.00052 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.233 | L2-Norm(final)=12.724 | 4678.4 samples/s | 73.1 steps/s
[Step=21050 Epoch=39.7] | Loss=0.00048 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=12.725 | 2125.1 samples/s | 33.2 steps/s
[Step=21100 Epoch=39.8] | Loss=0.00044 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.200 | L2-Norm(final)=12.726 | 4581.8 samples/s | 71.6 steps/s
[Step=21150 Epoch=39.9] | Loss=0.00040 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.183 | L2-Norm(final)=12.727 | 4630.2 samples/s | 72.3 steps/s
[Step=21200 Epoch=40.0] | Loss=0.00038 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=12.728 | 4582.5 samples/s | 71.6 steps/s
[Step=21250 Epoch=40.1] | Loss=0.00035 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.148 | L2-Norm(final)=12.729 | 4684.5 samples/s | 73.2 steps/s
[Step=21300 Epoch=40.2] | Loss=0.00033 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=12.729 | 4544.7 samples/s | 71.0 steps/s
[Step=21350 Epoch=40.2] | Loss=0.00031 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.113 | L2-Norm(final)=12.730 | 4608.7 samples/s | 72.0 steps/s
[Step=21400 Epoch=40.3] | Loss=0.00029 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.096 | L2-Norm(final)=12.730 | 4609.2 samples/s | 72.0 steps/s
[Step=21450 Epoch=40.4] | Loss=0.00028 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.078 | L2-Norm(final)=12.731 | 4659.2 samples/s | 72.8 steps/s
[Step=21500 Epoch=40.5] | Loss=0.00026 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=12.732 | 4578.8 samples/s | 71.5 steps/s
[Step=21550 Epoch=40.6] | Loss=0.00025 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=12.732 | 5778.8 samples/s | 90.3 steps/s
[Step=21600 Epoch=40.7] | Loss=0.00024 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=12.733 | 1946.9 samples/s | 30.4 steps/s
[Step=21650 Epoch=40.8] | Loss=0.00023 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.007 | L2-Norm(final)=12.733 | 4567.5 samples/s | 71.4 steps/s
[Step=21700 Epoch=40.9] | Loss=0.00022 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.989 | L2-Norm(final)=12.734 | 4588.9 samples/s | 71.7 steps/s
[Step=21750 Epoch=41.0] | Loss=0.00021 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=12.734 | 4631.2 samples/s | 72.4 steps/s
[Step=21800 Epoch=41.1] | Loss=0.00020 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.953 | L2-Norm(final)=12.735 | 4596.0 samples/s | 71.8 steps/s
[Step=21850 Epoch=41.2] | Loss=0.00020 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=12.735 | 4661.7 samples/s | 72.8 steps/s
[Step=21900 Epoch=41.3] | Loss=0.00019 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.916 | L2-Norm(final)=12.735 | 4578.5 samples/s | 71.5 steps/s
[Step=21950 Epoch=41.4] | Loss=0.00018 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.898 | L2-Norm(final)=12.736 | 4643.1 samples/s | 72.5 steps/s
[Step=22000 Epoch=41.5] | Loss=0.00018 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=12.736 | 4535.7 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05002 | acc=0.9700 | tpr=0.9708 | fpr=0.0317 | 4096.4 samples/s | 16.0 steps/s
Avg test loss: 0.05250, Avg test acc: 0.96967, Avg tpr: 0.97109, Avg fpr: 0.03346, total FA: 261

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.78220 | acc=0.2980 | tpr=0.0075 | fpr=0.0714 | 4301.2 samples/s | 16.8 steps/s
Avg test loss: 9.76885, Avg test acc: 0.29698, Avg tpr: 0.00828, Avg fpr: 0.06807, total FA: 531

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.74362 | acc=0.1508 | tpr=0.4823 | fpr=0.8552 | 4219.3 samples/s | 16.5 steps/s
[Step= 100] | Loss=4.73159 | acc=0.1499 | tpr=0.4520 | fpr=0.8558 | 7913.7 samples/s | 30.9 steps/s
[Step= 150] | Loss=4.72454 | acc=0.1517 | tpr=0.4640 | fpr=0.8540 | 7996.9 samples/s | 31.2 steps/s
[Step= 200] | Loss=4.71567 | acc=0.1520 | tpr=0.4699 | fpr=0.8538 | 7988.6 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.71408 | acc=0.1519 | tpr=0.4725 | fpr=0.8540 | 7944.6 samples/s | 31.0 steps/s
[Step= 300] | Loss=4.71530 | acc=0.1525 | tpr=0.4749 | fpr=0.8534 | 8079.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=4.70912 | acc=0.1528 | tpr=0.4790 | fpr=0.8531 | 7968.3 samples/s | 31.1 steps/s
[Step= 400] | Loss=4.70789 | acc=0.1528 | tpr=0.4836 | fpr=0.8532 | 7905.2 samples/s | 30.9 steps/s
[Step= 450] | Loss=4.71650 | acc=0.1521 | tpr=0.4786 | fpr=0.8538 | 7826.3 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.71393 | acc=0.1519 | tpr=0.4753 | fpr=0.8540 | 7915.2 samples/s | 30.9 steps/s
[Step= 550] | Loss=4.71312 | acc=0.1520 | tpr=0.4799 | fpr=0.8540 | 15001.0 samples/s | 58.6 steps/s
Avg test loss: 4.71423, Avg test acc: 0.15188, Avg tpr: 0.47940, Avg fpr: 0.85408, total FA: 118587

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14164 | acc=0.9824 | tpr=0.9469 | fpr=0.0169 | 4180.2 samples/s | 16.3 steps/s
[Step= 100] | Loss=0.14803 | acc=0.9822 | tpr=0.9616 | fpr=0.0174 | 8110.5 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.15303 | acc=0.9817 | tpr=0.9654 | fpr=0.0180 | 7884.0 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.15638 | acc=0.9813 | tpr=0.9617 | fpr=0.0183 | 8022.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.15439 | acc=0.9813 | tpr=0.9581 | fpr=0.0183 | 8297.1 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.15718 | acc=0.9810 | tpr=0.9542 | fpr=0.0185 | 7851.4 samples/s | 30.7 steps/s
[Step= 350] | Loss=0.15863 | acc=0.9808 | tpr=0.9549 | fpr=0.0187 | 8443.1 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.15945 | acc=0.9805 | tpr=0.9540 | fpr=0.0190 | 7860.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.16249 | acc=0.9803 | tpr=0.9528 | fpr=0.0192 | 7958.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.16160 | acc=0.9804 | tpr=0.9546 | fpr=0.0191 | 7743.9 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.16041 | acc=0.9806 | tpr=0.9530 | fpr=0.0189 | 15295.4 samples/s | 59.7 steps/s
Avg test loss: 0.16020, Avg test acc: 0.98057, Avg tpr: 0.95246, Avg fpr: 0.01892, total FA: 2627

server round 11/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=22001 Epoch=21.5] | Loss=0.02879 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.855 | L2-Norm(final)=9.389 | 3901.8 samples/s | 61.0 steps/s
[Step=22050 Epoch=21.5] | Loss=0.02882 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.856 | L2-Norm(final)=9.390 | 5386.1 samples/s | 84.2 steps/s
[Step=22100 Epoch=21.6] | Loss=0.02862 | Reg=0.00251 | acc=0.9531 | L2-Norm=15.856 | L2-Norm(final)=9.393 | 5748.6 samples/s | 89.8 steps/s
[Step=22150 Epoch=21.6] | Loss=0.02873 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.856 | L2-Norm(final)=9.400 | 5556.5 samples/s | 86.8 steps/s
[Step=22200 Epoch=21.7] | Loss=0.02845 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.856 | L2-Norm(final)=9.408 | 5478.4 samples/s | 85.6 steps/s
[Step=22250 Epoch=21.7] | Loss=0.02865 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.856 | L2-Norm(final)=9.417 | 5619.3 samples/s | 87.8 steps/s
[Step=22300 Epoch=21.8] | Loss=0.02821 | Reg=0.00251 | acc=0.9531 | L2-Norm=15.856 | L2-Norm(final)=9.426 | 5483.5 samples/s | 85.7 steps/s
[Step=22350 Epoch=21.8] | Loss=0.02791 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.856 | L2-Norm(final)=9.434 | 5682.2 samples/s | 88.8 steps/s
[Step=22400 Epoch=21.9] | Loss=0.02739 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.856 | L2-Norm(final)=9.444 | 5614.8 samples/s | 87.7 steps/s
[Step=22450 Epoch=21.9] | Loss=0.02762 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.856 | L2-Norm(final)=9.454 | 5689.7 samples/s | 88.9 steps/s
[Step=22500 Epoch=22.0] | Loss=0.02748 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.856 | L2-Norm(final)=9.464 | 5520.4 samples/s | 86.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=22.0] | Loss=0.03594 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.856 | L2-Norm(final)=9.564 | 4011.0 samples/s | 62.7 steps/s
[Step=22550 Epoch=22.0] | Loss=0.02187 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.878 | L2-Norm(final)=9.573 | 4649.8 samples/s | 72.7 steps/s
[Step=22600 Epoch=22.1] | Loss=0.02179 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.907 | L2-Norm(final)=9.575 | 4868.2 samples/s | 76.1 steps/s
[Step=22650 Epoch=22.1] | Loss=0.02282 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.934 | L2-Norm(final)=9.574 | 4820.0 samples/s | 75.3 steps/s
[Step=22700 Epoch=22.2] | Loss=0.02261 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.955 | L2-Norm(final)=9.572 | 4916.9 samples/s | 76.8 steps/s
[Step=22750 Epoch=22.2] | Loss=0.02256 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.974 | L2-Norm(final)=9.570 | 4801.0 samples/s | 75.0 steps/s
[Step=22800 Epoch=22.3] | Loss=0.02260 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.990 | L2-Norm(final)=9.570 | 4836.7 samples/s | 75.6 steps/s
[Step=22850 Epoch=22.3] | Loss=0.02291 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=9.568 | 4851.0 samples/s | 75.8 steps/s
[Step=22900 Epoch=22.4] | Loss=0.02295 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.020 | L2-Norm(final)=9.567 | 4842.8 samples/s | 75.7 steps/s
[Step=22950 Epoch=22.4] | Loss=0.02259 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.034 | L2-Norm(final)=9.566 | 4870.3 samples/s | 76.1 steps/s
[Step=23000 Epoch=22.5] | Loss=0.02240 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.046 | L2-Norm(final)=9.566 | 4872.2 samples/s | 76.1 steps/s
[Step=23050 Epoch=22.5] | Loss=0.02274 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.058 | L2-Norm(final)=9.565 | 4869.8 samples/s | 76.1 steps/s
[Step=23100 Epoch=22.6] | Loss=0.02245 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=9.565 | 4884.1 samples/s | 76.3 steps/s
[Step=23150 Epoch=22.6] | Loss=0.02219 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=9.564 | 4874.9 samples/s | 76.2 steps/s
[Step=23200 Epoch=22.7] | Loss=0.02199 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=9.564 | 4786.7 samples/s | 74.8 steps/s
[Step=23250 Epoch=22.7] | Loss=0.02213 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.098 | L2-Norm(final)=9.564 | 4834.5 samples/s | 75.5 steps/s
[Step=23300 Epoch=22.7] | Loss=0.02203 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.107 | L2-Norm(final)=9.564 | 4875.9 samples/s | 76.2 steps/s
[Step=23350 Epoch=22.8] | Loss=0.02215 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.116 | L2-Norm(final)=9.563 | 4897.2 samples/s | 76.5 steps/s
[Step=23400 Epoch=22.8] | Loss=0.02220 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.124 | L2-Norm(final)=9.562 | 4852.9 samples/s | 75.8 steps/s
[Step=23450 Epoch=22.9] | Loss=0.02193 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.133 | L2-Norm(final)=9.561 | 4622.1 samples/s | 72.2 steps/s
[Step=23500 Epoch=22.9] | Loss=0.02197 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.141 | L2-Norm(final)=9.561 | 5142.2 samples/s | 80.3 steps/s
[Step=23550 Epoch=23.0] | Loss=0.02167 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=9.560 | 2013.4 samples/s | 31.5 steps/s
[Step=23600 Epoch=23.0] | Loss=0.02132 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.158 | L2-Norm(final)=9.560 | 4327.1 samples/s | 67.6 steps/s
[Step=23650 Epoch=23.1] | Loss=0.02123 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.166 | L2-Norm(final)=9.560 | 4320.5 samples/s | 67.5 steps/s
[Step=23700 Epoch=23.1] | Loss=0.02114 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.174 | L2-Norm(final)=9.560 | 4668.8 samples/s | 72.9 steps/s
[Step=23750 Epoch=23.2] | Loss=0.02082 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.181 | L2-Norm(final)=9.560 | 4814.7 samples/s | 75.2 steps/s
[Step=23800 Epoch=23.2] | Loss=0.02073 | Reg=0.00262 | acc=0.9531 | L2-Norm=16.189 | L2-Norm(final)=9.560 | 4849.0 samples/s | 75.8 steps/s
[Step=23850 Epoch=23.3] | Loss=0.02062 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=9.560 | 4835.0 samples/s | 75.5 steps/s
[Step=23900 Epoch=23.3] | Loss=0.02037 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.202 | L2-Norm(final)=9.560 | 4844.2 samples/s | 75.7 steps/s
[Step=23950 Epoch=23.4] | Loss=0.02030 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.209 | L2-Norm(final)=9.560 | 4857.8 samples/s | 75.9 steps/s
[Step=24000 Epoch=23.4] | Loss=0.02015 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.216 | L2-Norm(final)=9.560 | 4854.2 samples/s | 75.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step24000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=22001 Epoch=41.5] | Loss=0.00453 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.855 | L2-Norm(final)=12.748 | 4120.2 samples/s | 64.4 steps/s
[Step=22050 Epoch=41.6] | Loss=0.00294 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.849 | L2-Norm(final)=12.772 | 4778.5 samples/s | 74.7 steps/s
[Step=22100 Epoch=41.7] | Loss=0.00328 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=12.788 | 5333.7 samples/s | 83.3 steps/s
[Step=22150 Epoch=41.8] | Loss=0.00280 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=12.803 | 5398.6 samples/s | 84.4 steps/s
[Step=22200 Epoch=41.8] | Loss=0.00258 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.848 | L2-Norm(final)=12.817 | 5178.3 samples/s | 80.9 steps/s
[Step=22250 Epoch=41.9] | Loss=0.00230 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=12.831 | 5241.3 samples/s | 81.9 steps/s
[Step=22300 Epoch=42.0] | Loss=0.00224 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=12.843 | 5309.8 samples/s | 83.0 steps/s
[Step=22350 Epoch=42.1] | Loss=0.00215 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=12.854 | 5309.1 samples/s | 83.0 steps/s
[Step=22400 Epoch=42.2] | Loss=0.00203 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=12.866 | 5284.0 samples/s | 82.6 steps/s
[Step=22450 Epoch=42.3] | Loss=0.00201 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=12.877 | 5251.6 samples/s | 82.1 steps/s
[Step=22500 Epoch=42.4] | Loss=0.00195 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=12.888 | 5395.4 samples/s | 84.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=42.4] | Loss=0.00034 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=12.995 | 4620.1 samples/s | 72.2 steps/s
[Step=22550 Epoch=42.5] | Loss=0.00231 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.871 | L2-Norm(final)=12.996 | 3953.9 samples/s | 61.8 steps/s
[Step=22600 Epoch=42.6] | Loss=0.00527 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.930 | L2-Norm(final)=12.990 | 4633.1 samples/s | 72.4 steps/s
[Step=22650 Epoch=42.7] | Loss=0.00509 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=12.977 | 4592.0 samples/s | 71.8 steps/s
[Step=22700 Epoch=42.8] | Loss=0.00512 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.039 | L2-Norm(final)=12.964 | 4594.6 samples/s | 71.8 steps/s
[Step=22750 Epoch=42.9] | Loss=0.00450 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=12.955 | 4558.6 samples/s | 71.2 steps/s
[Step=22800 Epoch=43.0] | Loss=0.00377 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.088 | L2-Norm(final)=12.950 | 4622.2 samples/s | 72.2 steps/s
[Step=22850 Epoch=43.1] | Loss=0.00349 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.098 | L2-Norm(final)=12.946 | 4592.7 samples/s | 71.8 steps/s
[Step=22900 Epoch=43.2] | Loss=0.00312 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.103 | L2-Norm(final)=12.942 | 4605.9 samples/s | 72.0 steps/s
[Step=22950 Epoch=43.3] | Loss=0.00279 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=12.939 | 4607.4 samples/s | 72.0 steps/s
[Step=23000 Epoch=43.4] | Loss=0.00252 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.103 | L2-Norm(final)=12.938 | 4658.7 samples/s | 72.8 steps/s
[Step=23050 Epoch=43.4] | Loss=0.00236 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.100 | L2-Norm(final)=12.936 | 2139.3 samples/s | 33.4 steps/s
[Step=23100 Epoch=43.5] | Loss=0.00216 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.096 | L2-Norm(final)=12.936 | 4719.6 samples/s | 73.7 steps/s
[Step=23150 Epoch=43.6] | Loss=0.00200 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=12.935 | 4535.2 samples/s | 70.9 steps/s
[Step=23200 Epoch=43.7] | Loss=0.00185 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=12.934 | 4615.3 samples/s | 72.1 steps/s
[Step=23250 Epoch=43.8] | Loss=0.00173 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.077 | L2-Norm(final)=12.934 | 4622.9 samples/s | 72.2 steps/s
[Step=23300 Epoch=43.9] | Loss=0.00163 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.069 | L2-Norm(final)=12.934 | 4605.3 samples/s | 72.0 steps/s
[Step=23350 Epoch=44.0] | Loss=0.00153 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=12.934 | 4594.5 samples/s | 71.8 steps/s
[Step=23400 Epoch=44.1] | Loss=0.00145 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.051 | L2-Norm(final)=12.933 | 4631.8 samples/s | 72.4 steps/s
[Step=23450 Epoch=44.2] | Loss=0.00137 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=12.933 | 4559.1 samples/s | 71.2 steps/s
[Step=23500 Epoch=44.3] | Loss=0.00130 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.032 | L2-Norm(final)=12.933 | 4655.2 samples/s | 72.7 steps/s
[Step=23550 Epoch=44.4] | Loss=0.00124 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.022 | L2-Norm(final)=12.934 | 5649.1 samples/s | 88.3 steps/s
[Step=23600 Epoch=44.5] | Loss=0.00118 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.012 | L2-Norm(final)=12.934 | 1962.6 samples/s | 30.7 steps/s
[Step=23650 Epoch=44.6] | Loss=0.00113 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.002 | L2-Norm(final)=12.934 | 4589.6 samples/s | 71.7 steps/s
[Step=23700 Epoch=44.7] | Loss=0.00109 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=12.934 | 4619.6 samples/s | 72.2 steps/s
[Step=23750 Epoch=44.8] | Loss=0.00104 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.980 | L2-Norm(final)=12.934 | 4545.0 samples/s | 71.0 steps/s
[Step=23800 Epoch=44.9] | Loss=0.00100 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=12.934 | 4635.7 samples/s | 72.4 steps/s
[Step=23850 Epoch=45.0] | Loss=0.00097 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=12.934 | 4677.4 samples/s | 73.1 steps/s
[Step=23900 Epoch=45.1] | Loss=0.00093 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.947 | L2-Norm(final)=12.935 | 4556.4 samples/s | 71.2 steps/s
[Step=23950 Epoch=45.1] | Loss=0.00090 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=12.935 | 4584.9 samples/s | 71.6 steps/s
[Step=24000 Epoch=45.2] | Loss=0.00087 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.924 | L2-Norm(final)=12.935 | 4631.1 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05192 | acc=0.9709 | tpr=0.9752 | fpr=0.0387 | 4153.9 samples/s | 16.2 steps/s
Avg test loss: 0.05580, Avg test acc: 0.96943, Avg tpr: 0.97377, Avg fpr: 0.04012, total FA: 313

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=11.15916 | acc=0.3084 | tpr=0.0041 | fpr=0.0307 | 4179.4 samples/s | 16.3 steps/s
Avg test loss: 11.15146, Avg test acc: 0.30583, Avg tpr: 0.00425, Avg fpr: 0.03089, total FA: 241

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.49009 | acc=0.1418 | tpr=0.4779 | fpr=0.8642 | 4042.5 samples/s | 15.8 steps/s
[Step= 100] | Loss=5.48703 | acc=0.1417 | tpr=0.4478 | fpr=0.8640 | 8048.7 samples/s | 31.4 steps/s
[Step= 150] | Loss=5.48713 | acc=0.1426 | tpr=0.4553 | fpr=0.8632 | 7979.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.47367 | acc=0.1422 | tpr=0.4448 | fpr=0.8633 | 7854.1 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.47188 | acc=0.1415 | tpr=0.4428 | fpr=0.8640 | 8011.4 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.46862 | acc=0.1421 | tpr=0.4538 | fpr=0.8636 | 8017.2 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.46277 | acc=0.1421 | tpr=0.4552 | fpr=0.8636 | 8033.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.46201 | acc=0.1421 | tpr=0.4568 | fpr=0.8636 | 7915.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.47118 | acc=0.1416 | tpr=0.4513 | fpr=0.8640 | 8101.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.47058 | acc=0.1414 | tpr=0.4485 | fpr=0.8642 | 7796.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.46880 | acc=0.1415 | tpr=0.4517 | fpr=0.8642 | 15280.2 samples/s | 59.7 steps/s
Avg test loss: 5.47093, Avg test acc: 0.14134, Avg tpr: 0.45087, Avg fpr: 0.86429, total FA: 120005

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14142 | acc=0.9812 | tpr=0.9469 | fpr=0.0181 | 4192.1 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.14712 | acc=0.9807 | tpr=0.9616 | fpr=0.0189 | 8084.6 samples/s | 31.6 steps/s
[Step= 150] | Loss=0.15221 | acc=0.9803 | tpr=0.9654 | fpr=0.0194 | 7767.0 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.15397 | acc=0.9804 | tpr=0.9650 | fpr=0.0193 | 8256.9 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.15152 | acc=0.9805 | tpr=0.9642 | fpr=0.0192 | 7882.3 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.15479 | acc=0.9802 | tpr=0.9615 | fpr=0.0194 | 8050.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.15566 | acc=0.9802 | tpr=0.9618 | fpr=0.0195 | 7848.4 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.15692 | acc=0.9799 | tpr=0.9595 | fpr=0.0197 | 8063.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.15996 | acc=0.9796 | tpr=0.9601 | fpr=0.0201 | 7937.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15938 | acc=0.9795 | tpr=0.9595 | fpr=0.0201 | 8104.1 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.15804 | acc=0.9798 | tpr=0.9598 | fpr=0.0199 | 14548.3 samples/s | 56.8 steps/s
Avg test loss: 0.15776, Avg test acc: 0.97980, Avg tpr: 0.95919, Avg fpr: 0.01983, total FA: 2753

server round 12/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=24001 Epoch=23.4] | Loss=0.01649 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.725 | L2-Norm(final)=9.559 | 4257.8 samples/s | 66.5 steps/s
[Step=24050 Epoch=23.5] | Loss=0.03251 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.727 | L2-Norm(final)=9.564 | 5379.4 samples/s | 84.1 steps/s
[Step=24100 Epoch=23.5] | Loss=0.03363 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=9.562 | 5643.2 samples/s | 88.2 steps/s
[Step=24150 Epoch=23.6] | Loss=0.03476 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.727 | L2-Norm(final)=9.561 | 5598.8 samples/s | 87.5 steps/s
[Step=24200 Epoch=23.6] | Loss=0.03525 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.727 | L2-Norm(final)=9.560 | 5672.8 samples/s | 88.6 steps/s
[Step=24250 Epoch=23.7] | Loss=0.03521 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.727 | L2-Norm(final)=9.562 | 5446.4 samples/s | 85.1 steps/s
[Step=24300 Epoch=23.7] | Loss=0.03534 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.727 | L2-Norm(final)=9.564 | 5694.8 samples/s | 89.0 steps/s
[Step=24350 Epoch=23.8] | Loss=0.03553 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.727 | L2-Norm(final)=9.568 | 5589.2 samples/s | 87.3 steps/s
[Step=24400 Epoch=23.8] | Loss=0.03570 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.727 | L2-Norm(final)=9.572 | 5663.2 samples/s | 88.5 steps/s
[Step=24450 Epoch=23.9] | Loss=0.03528 | Reg=0.00247 | acc=0.9375 | L2-Norm=15.727 | L2-Norm(final)=9.575 | 5523.4 samples/s | 86.3 steps/s
[Step=24500 Epoch=23.9] | Loss=0.03532 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=9.578 | 5611.8 samples/s | 87.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=23.9] | Loss=0.03178 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.727 | L2-Norm(final)=9.610 | 4162.1 samples/s | 65.0 steps/s
[Step=24550 Epoch=24.0] | Loss=0.02645 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.764 | L2-Norm(final)=9.618 | 4798.0 samples/s | 75.0 steps/s
[Step=24600 Epoch=24.0] | Loss=0.02352 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.801 | L2-Norm(final)=9.622 | 4819.6 samples/s | 75.3 steps/s
[Step=24650 Epoch=24.1] | Loss=0.02428 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.832 | L2-Norm(final)=9.619 | 4888.0 samples/s | 76.4 steps/s
[Step=24700 Epoch=24.1] | Loss=0.02421 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.858 | L2-Norm(final)=9.616 | 4736.6 samples/s | 74.0 steps/s
[Step=24750 Epoch=24.2] | Loss=0.02398 | Reg=0.00252 | acc=0.9531 | L2-Norm=15.879 | L2-Norm(final)=9.613 | 4903.4 samples/s | 76.6 steps/s
[Step=24800 Epoch=24.2] | Loss=0.02297 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.897 | L2-Norm(final)=9.611 | 4865.7 samples/s | 76.0 steps/s
[Step=24850 Epoch=24.3] | Loss=0.02301 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.914 | L2-Norm(final)=9.611 | 4898.1 samples/s | 76.5 steps/s
[Step=24900 Epoch=24.3] | Loss=0.02281 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.931 | L2-Norm(final)=9.609 | 4890.1 samples/s | 76.4 steps/s
[Step=24950 Epoch=24.4] | Loss=0.02274 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.947 | L2-Norm(final)=9.607 | 4888.8 samples/s | 76.4 steps/s
[Step=25000 Epoch=24.4] | Loss=0.02231 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=9.606 | 4874.8 samples/s | 76.2 steps/s
[Step=25050 Epoch=24.5] | Loss=0.02295 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.975 | L2-Norm(final)=9.604 | 4822.3 samples/s | 75.3 steps/s
[Step=25100 Epoch=24.5] | Loss=0.02260 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.988 | L2-Norm(final)=9.603 | 4846.7 samples/s | 75.7 steps/s
[Step=25150 Epoch=24.6] | Loss=0.02240 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.000 | L2-Norm(final)=9.601 | 4863.0 samples/s | 76.0 steps/s
[Step=25200 Epoch=24.6] | Loss=0.02238 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=9.599 | 4903.3 samples/s | 76.6 steps/s
[Step=25250 Epoch=24.7] | Loss=0.02239 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.020 | L2-Norm(final)=9.597 | 4856.2 samples/s | 75.9 steps/s
[Step=25300 Epoch=24.7] | Loss=0.02218 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=9.596 | 4845.9 samples/s | 75.7 steps/s
[Step=25350 Epoch=24.8] | Loss=0.02196 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.039 | L2-Norm(final)=9.594 | 4818.1 samples/s | 75.3 steps/s
[Step=25400 Epoch=24.8] | Loss=0.02189 | Reg=0.00258 | acc=0.9531 | L2-Norm=16.048 | L2-Norm(final)=9.593 | 4822.2 samples/s | 75.3 steps/s
[Step=25450 Epoch=24.8] | Loss=0.02182 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.056 | L2-Norm(final)=9.592 | 4908.6 samples/s | 76.7 steps/s
[Step=25500 Epoch=24.9] | Loss=0.02162 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.064 | L2-Norm(final)=9.591 | 5215.5 samples/s | 81.5 steps/s
[Step=25550 Epoch=24.9] | Loss=0.02166 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.072 | L2-Norm(final)=9.590 | 2096.2 samples/s | 32.8 steps/s
[Step=25600 Epoch=25.0] | Loss=0.02129 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=9.589 | 4896.5 samples/s | 76.5 steps/s
[Step=25650 Epoch=25.0] | Loss=0.02101 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.087 | L2-Norm(final)=9.588 | 4732.2 samples/s | 73.9 steps/s
[Step=25700 Epoch=25.1] | Loss=0.02067 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=9.587 | 4836.7 samples/s | 75.6 steps/s
[Step=25750 Epoch=25.1] | Loss=0.02060 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.100 | L2-Norm(final)=9.587 | 4818.3 samples/s | 75.3 steps/s
[Step=25800 Epoch=25.2] | Loss=0.02033 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.106 | L2-Norm(final)=9.586 | 4851.7 samples/s | 75.8 steps/s
[Step=25850 Epoch=25.2] | Loss=0.02029 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.113 | L2-Norm(final)=9.586 | 4876.7 samples/s | 76.2 steps/s
[Step=25900 Epoch=25.3] | Loss=0.02016 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.119 | L2-Norm(final)=9.585 | 4823.7 samples/s | 75.4 steps/s
[Step=25950 Epoch=25.3] | Loss=0.01984 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=9.585 | 4869.1 samples/s | 76.1 steps/s
[Step=26000 Epoch=25.4] | Loss=0.01969 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=9.585 | 4826.1 samples/s | 75.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step26000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=24001 Epoch=45.2] | Loss=0.00005 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=12.940 | 4039.6 samples/s | 63.1 steps/s
[Step=24050 Epoch=45.3] | Loss=0.00178 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=12.949 | 4414.6 samples/s | 69.0 steps/s
[Step=24100 Epoch=45.4] | Loss=0.00160 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.721 | L2-Norm(final)=12.958 | 5097.9 samples/s | 79.7 steps/s
[Step=24150 Epoch=45.5] | Loss=0.00127 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=12.967 | 5098.4 samples/s | 79.7 steps/s
[Step=24200 Epoch=45.6] | Loss=0.00122 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=12.976 | 5417.2 samples/s | 84.6 steps/s
[Step=24250 Epoch=45.7] | Loss=0.00113 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=12.985 | 5144.0 samples/s | 80.4 steps/s
[Step=24300 Epoch=45.8] | Loss=0.00119 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=12.992 | 5310.1 samples/s | 83.0 steps/s
[Step=24350 Epoch=45.9] | Loss=0.00122 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=13.000 | 5399.3 samples/s | 84.4 steps/s
[Step=24400 Epoch=46.0] | Loss=0.00121 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.720 | L2-Norm(final)=13.009 | 5246.4 samples/s | 82.0 steps/s
[Step=24450 Epoch=46.1] | Loss=0.00120 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=13.017 | 5140.4 samples/s | 80.3 steps/s
[Step=24500 Epoch=46.2] | Loss=0.00122 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=13.025 | 5363.4 samples/s | 83.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=46.2] | Loss=0.00006 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=13.103 | 4134.9 samples/s | 64.6 steps/s
[Step=24550 Epoch=46.3] | Loss=0.00111 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.723 | L2-Norm(final)=13.108 | 4388.4 samples/s | 68.6 steps/s
[Step=24600 Epoch=46.4] | Loss=0.00072 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.733 | L2-Norm(final)=13.111 | 4606.8 samples/s | 72.0 steps/s
[Step=24650 Epoch=46.5] | Loss=0.00400 | Reg=0.00248 | acc=0.9531 | L2-Norm=15.740 | L2-Norm(final)=13.109 | 4604.1 samples/s | 71.9 steps/s
[Step=24700 Epoch=46.6] | Loss=0.00452 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.771 | L2-Norm(final)=13.096 | 4455.7 samples/s | 69.6 steps/s
[Step=24750 Epoch=46.7] | Loss=0.00399 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.804 | L2-Norm(final)=13.083 | 4650.3 samples/s | 72.7 steps/s
[Step=24800 Epoch=46.7] | Loss=0.00391 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.827 | L2-Norm(final)=13.074 | 4628.7 samples/s | 72.3 steps/s
[Step=24850 Epoch=46.8] | Loss=0.00348 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.842 | L2-Norm(final)=13.067 | 4694.2 samples/s | 73.3 steps/s
[Step=24900 Epoch=46.9] | Loss=0.00308 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.852 | L2-Norm(final)=13.061 | 4618.0 samples/s | 72.2 steps/s
[Step=24950 Epoch=47.0] | Loss=0.00301 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.857 | L2-Norm(final)=13.057 | 4561.7 samples/s | 71.3 steps/s
[Step=25000 Epoch=47.1] | Loss=0.00295 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=13.052 | 4697.8 samples/s | 73.4 steps/s
[Step=25050 Epoch=47.2] | Loss=0.00278 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.869 | L2-Norm(final)=13.049 | 2115.2 samples/s | 33.1 steps/s
[Step=25100 Epoch=47.3] | Loss=0.00255 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.872 | L2-Norm(final)=13.046 | 4671.3 samples/s | 73.0 steps/s
[Step=25150 Epoch=47.4] | Loss=0.00236 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.874 | L2-Norm(final)=13.044 | 4586.3 samples/s | 71.7 steps/s
[Step=25200 Epoch=47.5] | Loss=0.00231 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.874 | L2-Norm(final)=13.042 | 4575.5 samples/s | 71.5 steps/s
[Step=25250 Epoch=47.6] | Loss=0.00217 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.873 | L2-Norm(final)=13.040 | 4667.8 samples/s | 72.9 steps/s
[Step=25300 Epoch=47.7] | Loss=0.00203 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.871 | L2-Norm(final)=13.039 | 4626.3 samples/s | 72.3 steps/s
[Step=25350 Epoch=47.8] | Loss=0.00191 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.869 | L2-Norm(final)=13.037 | 4630.1 samples/s | 72.3 steps/s
[Step=25400 Epoch=47.9] | Loss=0.00181 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.865 | L2-Norm(final)=13.036 | 4537.5 samples/s | 70.9 steps/s
[Step=25450 Epoch=48.0] | Loss=0.00172 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.861 | L2-Norm(final)=13.035 | 4651.9 samples/s | 72.7 steps/s
[Step=25500 Epoch=48.1] | Loss=0.00163 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.856 | L2-Norm(final)=13.035 | 4500.8 samples/s | 70.3 steps/s
[Step=25550 Epoch=48.2] | Loss=0.00155 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.850 | L2-Norm(final)=13.034 | 5730.4 samples/s | 89.5 steps/s
[Step=25600 Epoch=48.3] | Loss=0.00148 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.844 | L2-Norm(final)=13.033 | 1982.4 samples/s | 31.0 steps/s
[Step=25650 Epoch=48.4] | Loss=0.00142 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.838 | L2-Norm(final)=13.033 | 4560.3 samples/s | 71.3 steps/s
[Step=25700 Epoch=48.4] | Loss=0.00136 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.832 | L2-Norm(final)=13.032 | 4643.2 samples/s | 72.6 steps/s
[Step=25750 Epoch=48.5] | Loss=0.00131 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=13.032 | 4562.5 samples/s | 71.3 steps/s
[Step=25800 Epoch=48.6] | Loss=0.00125 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.817 | L2-Norm(final)=13.032 | 4655.0 samples/s | 72.7 steps/s
[Step=25850 Epoch=48.7] | Loss=0.00121 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.810 | L2-Norm(final)=13.031 | 4581.0 samples/s | 71.6 steps/s
[Step=25900 Epoch=48.8] | Loss=0.00117 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.802 | L2-Norm(final)=13.031 | 4692.9 samples/s | 73.3 steps/s
[Step=25950 Epoch=48.9] | Loss=0.00113 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.794 | L2-Norm(final)=13.031 | 4548.1 samples/s | 71.1 steps/s
[Step=26000 Epoch=49.0] | Loss=0.00109 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.786 | L2-Norm(final)=13.030 | 4664.4 samples/s | 72.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05533 | acc=0.9678 | tpr=0.9708 | fpr=0.0387 | 4264.2 samples/s | 16.7 steps/s
Avg test loss: 0.05814, Avg test acc: 0.96743, Avg tpr: 0.96987, Avg fpr: 0.03794, total FA: 296

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=12.50084 | acc=0.3088 | tpr=0.0027 | fpr=0.0265 | 4228.4 samples/s | 16.5 steps/s
Avg test loss: 12.50336, Avg test acc: 0.30676, Avg tpr: 0.00338, Avg fpr: 0.02602, total FA: 203

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.81191 | acc=0.1484 | tpr=0.4336 | fpr=0.8567 | 4366.0 samples/s | 17.1 steps/s
[Step= 100] | Loss=4.82281 | acc=0.1471 | tpr=0.3817 | fpr=0.8573 | 7815.4 samples/s | 30.5 steps/s
[Step= 150] | Loss=4.82446 | acc=0.1480 | tpr=0.3991 | fpr=0.8566 | 7578.4 samples/s | 29.6 steps/s
[Step= 200] | Loss=4.81538 | acc=0.1492 | tpr=0.3891 | fpr=0.8551 | 8006.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=4.81825 | acc=0.1488 | tpr=0.3913 | fpr=0.8557 | 7843.8 samples/s | 30.6 steps/s
[Step= 300] | Loss=4.81912 | acc=0.1491 | tpr=0.3920 | fpr=0.8553 | 8045.5 samples/s | 31.4 steps/s
[Step= 350] | Loss=4.80957 | acc=0.1495 | tpr=0.3901 | fpr=0.8548 | 8063.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=4.81015 | acc=0.1495 | tpr=0.3939 | fpr=0.8550 | 7998.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=4.81766 | acc=0.1492 | tpr=0.3924 | fpr=0.8552 | 7949.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=4.81754 | acc=0.1490 | tpr=0.3907 | fpr=0.8554 | 7884.0 samples/s | 30.8 steps/s
[Step= 550] | Loss=4.81631 | acc=0.1493 | tpr=0.3955 | fpr=0.8552 | 14798.8 samples/s | 57.8 steps/s
Avg test loss: 4.81826, Avg test acc: 0.14914, Avg tpr: 0.39501, Avg fpr: 0.85533, total FA: 118761

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16787 | acc=0.9811 | tpr=0.9558 | fpr=0.0185 | 4221.3 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.17414 | acc=0.9805 | tpr=0.9659 | fpr=0.0192 | 7954.6 samples/s | 31.1 steps/s
[Step= 150] | Loss=0.18042 | acc=0.9800 | tpr=0.9683 | fpr=0.0198 | 8287.5 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.18322 | acc=0.9799 | tpr=0.9705 | fpr=0.0199 | 7931.9 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.18049 | acc=0.9800 | tpr=0.9686 | fpr=0.0198 | 7860.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.18343 | acc=0.9797 | tpr=0.9665 | fpr=0.0200 | 8302.3 samples/s | 32.4 steps/s
[Step= 350] | Loss=0.18446 | acc=0.9796 | tpr=0.9656 | fpr=0.0201 | 7964.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.18592 | acc=0.9795 | tpr=0.9644 | fpr=0.0202 | 7891.0 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.19011 | acc=0.9793 | tpr=0.9635 | fpr=0.0204 | 8025.4 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.18900 | acc=0.9794 | tpr=0.9634 | fpr=0.0203 | 7973.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.18774 | acc=0.9796 | tpr=0.9634 | fpr=0.0201 | 14436.6 samples/s | 56.4 steps/s
Avg test loss: 0.18754, Avg test acc: 0.97960, Avg tpr: 0.96355, Avg fpr: 0.02011, total FA: 2792

server round 13/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=26001 Epoch=25.4] | Loss=0.07709 | Reg=0.00246 | acc=0.9219 | L2-Norm=15.673 | L2-Norm(final)=9.573 | 4289.4 samples/s | 67.0 steps/s
[Step=26050 Epoch=25.4] | Loss=0.03882 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.675 | L2-Norm(final)=9.573 | 4481.4 samples/s | 70.0 steps/s
[Step=26100 Epoch=25.5] | Loss=0.04190 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.675 | L2-Norm(final)=9.574 | 5559.1 samples/s | 86.9 steps/s
[Step=26150 Epoch=25.5] | Loss=0.04233 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.675 | L2-Norm(final)=9.574 | 5646.7 samples/s | 88.2 steps/s
[Step=26200 Epoch=25.6] | Loss=0.04067 | Reg=0.00246 | acc=0.9219 | L2-Norm=15.676 | L2-Norm(final)=9.575 | 5510.8 samples/s | 86.1 steps/s
[Step=26250 Epoch=25.6] | Loss=0.03922 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.676 | L2-Norm(final)=9.578 | 5611.5 samples/s | 87.7 steps/s
[Step=26300 Epoch=25.7] | Loss=0.03866 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.676 | L2-Norm(final)=9.581 | 5621.5 samples/s | 87.8 steps/s
[Step=26350 Epoch=25.7] | Loss=0.03791 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.676 | L2-Norm(final)=9.585 | 5553.6 samples/s | 86.8 steps/s
[Step=26400 Epoch=25.8] | Loss=0.03779 | Reg=0.00246 | acc=0.9375 | L2-Norm=15.676 | L2-Norm(final)=9.590 | 5606.5 samples/s | 87.6 steps/s
[Step=26450 Epoch=25.8] | Loss=0.03744 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.676 | L2-Norm(final)=9.596 | 5551.6 samples/s | 86.7 steps/s
[Step=26500 Epoch=25.9] | Loss=0.03696 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.676 | L2-Norm(final)=9.601 | 5642.0 samples/s | 88.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=25.9] | Loss=0.03587 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.676 | L2-Norm(final)=9.664 | 3969.3 samples/s | 62.0 steps/s
[Step=26550 Epoch=25.9] | Loss=0.02493 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.722 | L2-Norm(final)=9.668 | 4897.5 samples/s | 76.5 steps/s
[Step=26600 Epoch=26.0] | Loss=0.02454 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=9.666 | 4762.8 samples/s | 74.4 steps/s
[Step=26650 Epoch=26.0] | Loss=0.02401 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.795 | L2-Norm(final)=9.664 | 4831.7 samples/s | 75.5 steps/s
[Step=26700 Epoch=26.1] | Loss=0.02366 | Reg=0.00250 | acc=0.9531 | L2-Norm=15.818 | L2-Norm(final)=9.663 | 4807.3 samples/s | 75.1 steps/s
[Step=26750 Epoch=26.1] | Loss=0.02268 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.836 | L2-Norm(final)=9.664 | 4836.0 samples/s | 75.6 steps/s
[Step=26800 Epoch=26.2] | Loss=0.02181 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.852 | L2-Norm(final)=9.664 | 4838.8 samples/s | 75.6 steps/s
[Step=26850 Epoch=26.2] | Loss=0.02142 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.867 | L2-Norm(final)=9.665 | 4866.9 samples/s | 76.0 steps/s
[Step=26900 Epoch=26.3] | Loss=0.02100 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=9.665 | 4900.8 samples/s | 76.6 steps/s
[Step=26950 Epoch=26.3] | Loss=0.02126 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=9.664 | 4764.4 samples/s | 74.4 steps/s
[Step=27000 Epoch=26.4] | Loss=0.02130 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.907 | L2-Norm(final)=9.664 | 4885.7 samples/s | 76.3 steps/s
[Step=27050 Epoch=26.4] | Loss=0.02104 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.918 | L2-Norm(final)=9.663 | 4805.6 samples/s | 75.1 steps/s
[Step=27100 Epoch=26.5] | Loss=0.02120 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.929 | L2-Norm(final)=9.662 | 4888.7 samples/s | 76.4 steps/s
[Step=27150 Epoch=26.5] | Loss=0.02120 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.939 | L2-Norm(final)=9.661 | 4890.9 samples/s | 76.4 steps/s
[Step=27200 Epoch=26.6] | Loss=0.02123 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.949 | L2-Norm(final)=9.661 | 4855.4 samples/s | 75.9 steps/s
[Step=27250 Epoch=26.6] | Loss=0.02109 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.959 | L2-Norm(final)=9.660 | 4801.6 samples/s | 75.0 steps/s
[Step=27300 Epoch=26.7] | Loss=0.02136 | Reg=0.00255 | acc=0.9531 | L2-Norm=15.968 | L2-Norm(final)=9.659 | 4817.8 samples/s | 75.3 steps/s
[Step=27350 Epoch=26.7] | Loss=0.02118 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.978 | L2-Norm(final)=9.658 | 4860.2 samples/s | 75.9 steps/s
[Step=27400 Epoch=26.8] | Loss=0.02095 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.986 | L2-Norm(final)=9.658 | 4883.4 samples/s | 76.3 steps/s
[Step=27450 Epoch=26.8] | Loss=0.02095 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=9.657 | 4815.5 samples/s | 75.2 steps/s
[Step=27500 Epoch=26.8] | Loss=0.02082 | Reg=0.00256 | acc=0.9688 | L2-Norm=16.002 | L2-Norm(final)=9.657 | 5211.3 samples/s | 81.4 steps/s
[Step=27550 Epoch=26.9] | Loss=0.02056 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=9.656 | 2096.4 samples/s | 32.8 steps/s
[Step=27600 Epoch=26.9] | Loss=0.02032 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.017 | L2-Norm(final)=9.656 | 4843.0 samples/s | 75.7 steps/s
[Step=27650 Epoch=27.0] | Loss=0.02014 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=9.656 | 4798.1 samples/s | 75.0 steps/s
[Step=27700 Epoch=27.0] | Loss=0.01984 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=9.655 | 4814.4 samples/s | 75.2 steps/s
[Step=27750 Epoch=27.1] | Loss=0.01960 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.036 | L2-Norm(final)=9.655 | 4870.5 samples/s | 76.1 steps/s
[Step=27800 Epoch=27.1] | Loss=0.01949 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.042 | L2-Norm(final)=9.655 | 4833.7 samples/s | 75.5 steps/s
[Step=27850 Epoch=27.2] | Loss=0.01940 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.048 | L2-Norm(final)=9.655 | 4839.2 samples/s | 75.6 steps/s
[Step=27900 Epoch=27.2] | Loss=0.01925 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.053 | L2-Norm(final)=9.654 | 4928.5 samples/s | 77.0 steps/s
[Step=27950 Epoch=27.3] | Loss=0.01912 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.058 | L2-Norm(final)=9.654 | 4884.2 samples/s | 76.3 steps/s
[Step=28000 Epoch=27.3] | Loss=0.01906 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.064 | L2-Norm(final)=9.654 | 4805.3 samples/s | 75.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step28000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=26001 Epoch=49.0] | Loss=0.00110 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.673 | L2-Norm(final)=13.024 | 3956.9 samples/s | 61.8 steps/s
[Step=26050 Epoch=49.1] | Loss=0.00245 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.670 | L2-Norm(final)=13.022 | 4795.7 samples/s | 74.9 steps/s
[Step=26100 Epoch=49.2] | Loss=0.00138 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.670 | L2-Norm(final)=13.026 | 5297.9 samples/s | 82.8 steps/s
[Step=26150 Epoch=49.3] | Loss=0.00098 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.030 | 5372.7 samples/s | 83.9 steps/s
[Step=26200 Epoch=49.4] | Loss=0.00108 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.034 | 5262.1 samples/s | 82.2 steps/s
[Step=26250 Epoch=49.5] | Loss=0.00102 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.038 | 5310.9 samples/s | 83.0 steps/s
[Step=26300 Epoch=49.6] | Loss=0.00104 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.042 | 5242.6 samples/s | 81.9 steps/s
[Step=26350 Epoch=49.7] | Loss=0.00094 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.047 | 5321.6 samples/s | 83.1 steps/s
[Step=26400 Epoch=49.8] | Loss=0.00091 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.051 | 5245.4 samples/s | 82.0 steps/s
[Step=26450 Epoch=49.9] | Loss=0.00085 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.055 | 5406.0 samples/s | 84.5 steps/s
[Step=26500 Epoch=50.0] | Loss=0.00080 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.059 | 5279.4 samples/s | 82.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=50.0] | Loss=0.00002 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.099 | 4079.9 samples/s | 63.7 steps/s
[Step=26550 Epoch=50.0] | Loss=0.00024 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.652 | L2-Norm(final)=13.104 | 4247.9 samples/s | 66.4 steps/s
[Step=26600 Epoch=50.1] | Loss=0.00028 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.646 | L2-Norm(final)=13.108 | 4621.0 samples/s | 72.2 steps/s
[Step=26650 Epoch=50.2] | Loss=0.00022 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.644 | L2-Norm(final)=13.111 | 4613.8 samples/s | 72.1 steps/s
[Step=26700 Epoch=50.3] | Loss=0.00018 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.635 | L2-Norm(final)=13.113 | 4655.5 samples/s | 72.7 steps/s
[Step=26750 Epoch=50.4] | Loss=0.00015 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.623 | L2-Norm(final)=13.115 | 4620.6 samples/s | 72.2 steps/s
[Step=26800 Epoch=50.5] | Loss=0.00013 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.610 | L2-Norm(final)=13.117 | 4561.7 samples/s | 71.3 steps/s
[Step=26850 Epoch=50.6] | Loss=0.00011 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.596 | L2-Norm(final)=13.118 | 4584.3 samples/s | 71.6 steps/s
[Step=26900 Epoch=50.7] | Loss=0.00010 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=13.119 | 4645.0 samples/s | 72.6 steps/s
[Step=26950 Epoch=50.8] | Loss=0.00009 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.568 | L2-Norm(final)=13.120 | 4621.1 samples/s | 72.2 steps/s
[Step=27000 Epoch=50.9] | Loss=0.00008 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=13.121 | 4604.4 samples/s | 71.9 steps/s
[Step=27050 Epoch=51.0] | Loss=0.00007 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.538 | L2-Norm(final)=13.122 | 2070.8 samples/s | 32.4 steps/s
[Step=27100 Epoch=51.1] | Loss=0.00007 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.522 | L2-Norm(final)=13.123 | 4702.0 samples/s | 73.5 steps/s
[Step=27150 Epoch=51.2] | Loss=0.00006 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=13.124 | 4634.2 samples/s | 72.4 steps/s
[Step=27200 Epoch=51.3] | Loss=0.00006 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=13.124 | 4582.3 samples/s | 71.6 steps/s
[Step=27250 Epoch=51.4] | Loss=0.00006 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=13.125 | 4596.1 samples/s | 71.8 steps/s
[Step=27300 Epoch=51.5] | Loss=0.00005 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=13.126 | 4655.5 samples/s | 72.7 steps/s
[Step=27350 Epoch=51.6] | Loss=0.00005 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.445 | L2-Norm(final)=13.126 | 4623.7 samples/s | 72.2 steps/s
[Step=27400 Epoch=51.6] | Loss=0.00005 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=13.127 | 4555.1 samples/s | 71.2 steps/s
[Step=27450 Epoch=51.7] | Loss=0.00004 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=13.128 | 4597.1 samples/s | 71.8 steps/s
[Step=27500 Epoch=51.8] | Loss=0.00004 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=13.128 | 4616.4 samples/s | 72.1 steps/s
[Step=27550 Epoch=51.9] | Loss=0.00004 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=13.129 | 5711.9 samples/s | 89.2 steps/s
[Step=27600 Epoch=52.0] | Loss=0.00004 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=13.129 | 1963.8 samples/s | 30.7 steps/s
[Step=27650 Epoch=52.1] | Loss=0.00004 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=13.130 | 4652.0 samples/s | 72.7 steps/s
[Step=27700 Epoch=52.2] | Loss=0.00003 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=13.131 | 4569.2 samples/s | 71.4 steps/s
[Step=27750 Epoch=52.3] | Loss=0.00003 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.320 | L2-Norm(final)=13.131 | 4595.1 samples/s | 71.8 steps/s
[Step=27800 Epoch=52.4] | Loss=0.00003 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=13.132 | 4660.2 samples/s | 72.8 steps/s
[Step=27850 Epoch=52.5] | Loss=0.00003 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=13.133 | 4576.7 samples/s | 71.5 steps/s
[Step=27900 Epoch=52.6] | Loss=0.00003 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.272 | L2-Norm(final)=13.133 | 4634.5 samples/s | 72.4 steps/s
[Step=27950 Epoch=52.7] | Loss=0.00003 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=13.134 | 4590.6 samples/s | 71.7 steps/s
[Step=28000 Epoch=52.8] | Loss=0.00003 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=13.135 | 4592.5 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05037 | acc=0.9702 | tpr=0.9722 | fpr=0.0342 | 4201.2 samples/s | 16.4 steps/s
Avg test loss: 0.05143, Avg test acc: 0.96979, Avg tpr: 0.97202, Avg fpr: 0.03512, total FA: 274

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.75775 | acc=0.3009 | tpr=0.0048 | fpr=0.0560 | 4117.7 samples/s | 16.1 steps/s
Avg test loss: 10.73982, Avg test acc: 0.29878, Avg tpr: 0.00583, Avg fpr: 0.05692, total FA: 444

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.45693 | acc=0.1494 | tpr=0.4292 | fpr=0.8557 | 4176.3 samples/s | 16.3 steps/s
[Step= 100] | Loss=4.45015 | acc=0.1495 | tpr=0.4030 | fpr=0.8552 | 7996.0 samples/s | 31.2 steps/s
[Step= 150] | Loss=4.44031 | acc=0.1502 | tpr=0.4006 | fpr=0.8544 | 8062.4 samples/s | 31.5 steps/s
[Step= 200] | Loss=4.42636 | acc=0.1506 | tpr=0.4066 | fpr=0.8540 | 8025.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=4.42301 | acc=0.1502 | tpr=0.4079 | fpr=0.8545 | 7969.8 samples/s | 31.1 steps/s
[Step= 300] | Loss=4.42268 | acc=0.1505 | tpr=0.4189 | fpr=0.8544 | 8120.3 samples/s | 31.7 steps/s
[Step= 350] | Loss=4.41499 | acc=0.1506 | tpr=0.4164 | fpr=0.8542 | 7972.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=4.41781 | acc=0.1505 | tpr=0.4147 | fpr=0.8543 | 7852.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=4.42358 | acc=0.1500 | tpr=0.4153 | fpr=0.8548 | 8237.6 samples/s | 32.2 steps/s
[Step= 500] | Loss=4.42221 | acc=0.1497 | tpr=0.4123 | fpr=0.8550 | 7605.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=4.42218 | acc=0.1501 | tpr=0.4174 | fpr=0.8547 | 14281.7 samples/s | 55.8 steps/s
Avg test loss: 4.42355, Avg test acc: 0.15002, Avg tpr: 0.41719, Avg fpr: 0.85484, total FA: 118693

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16547 | acc=0.9804 | tpr=0.9513 | fpr=0.0191 | 4239.3 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.17113 | acc=0.9802 | tpr=0.9616 | fpr=0.0195 | 7944.6 samples/s | 31.0 steps/s
[Step= 150] | Loss=0.17645 | acc=0.9796 | tpr=0.9640 | fpr=0.0201 | 8127.4 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.17966 | acc=0.9793 | tpr=0.9650 | fpr=0.0204 | 7939.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.17694 | acc=0.9795 | tpr=0.9633 | fpr=0.0202 | 8023.3 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.17994 | acc=0.9793 | tpr=0.9600 | fpr=0.0204 | 7984.4 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.17980 | acc=0.9792 | tpr=0.9599 | fpr=0.0205 | 7890.6 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.18091 | acc=0.9790 | tpr=0.9584 | fpr=0.0206 | 8443.5 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.18437 | acc=0.9787 | tpr=0.9596 | fpr=0.0210 | 7856.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.18308 | acc=0.9788 | tpr=0.9599 | fpr=0.0209 | 7789.6 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.18188 | acc=0.9789 | tpr=0.9586 | fpr=0.0207 | 14907.2 samples/s | 58.2 steps/s
Avg test loss: 0.18159, Avg test acc: 0.97896, Avg tpr: 0.95840, Avg fpr: 0.02066, total FA: 2869

server round 14/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=28001 Epoch=27.3] | Loss=0.01229 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.333 | L2-Norm(final)=9.642 | 4071.1 samples/s | 63.6 steps/s
[Step=28050 Epoch=27.4] | Loss=0.01949 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.335 | L2-Norm(final)=9.645 | 5330.7 samples/s | 83.3 steps/s
[Step=28100 Epoch=27.4] | Loss=0.02035 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.645 | 5573.2 samples/s | 87.1 steps/s
[Step=28150 Epoch=27.5] | Loss=0.01971 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=9.647 | 5577.7 samples/s | 87.2 steps/s
[Step=28200 Epoch=27.5] | Loss=0.01892 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.650 | 5684.5 samples/s | 88.8 steps/s
[Step=28250 Epoch=27.6] | Loss=0.01848 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.655 | 5527.5 samples/s | 86.4 steps/s
[Step=28300 Epoch=27.6] | Loss=0.01869 | Reg=0.00235 | acc=0.9375 | L2-Norm=15.336 | L2-Norm(final)=9.660 | 5528.5 samples/s | 86.4 steps/s
[Step=28350 Epoch=27.7] | Loss=0.01873 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.664 | 5569.4 samples/s | 87.0 steps/s
[Step=28400 Epoch=27.7] | Loss=0.01828 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.669 | 5559.6 samples/s | 86.9 steps/s
[Step=28450 Epoch=27.8] | Loss=0.01830 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.336 | L2-Norm(final)=9.674 | 5661.0 samples/s | 88.5 steps/s
[Step=28500 Epoch=27.8] | Loss=0.01792 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.336 | L2-Norm(final)=9.679 | 5737.6 samples/s | 89.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=27.8] | Loss=0.00654 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=9.733 | 3994.2 samples/s | 62.4 steps/s
[Step=28550 Epoch=27.9] | Loss=0.01379 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.384 | L2-Norm(final)=9.739 | 4798.1 samples/s | 75.0 steps/s
[Step=28600 Epoch=27.9] | Loss=0.01523 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.420 | L2-Norm(final)=9.737 | 4841.9 samples/s | 75.7 steps/s
[Step=28650 Epoch=28.0] | Loss=0.01574 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.445 | L2-Norm(final)=9.735 | 4823.3 samples/s | 75.4 steps/s
[Step=28700 Epoch=28.0] | Loss=0.01656 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.468 | L2-Norm(final)=9.731 | 4846.7 samples/s | 75.7 steps/s
[Step=28750 Epoch=28.1] | Loss=0.01678 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.488 | L2-Norm(final)=9.728 | 4866.3 samples/s | 76.0 steps/s
[Step=28800 Epoch=28.1] | Loss=0.01637 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=9.726 | 4816.6 samples/s | 75.3 steps/s
[Step=28850 Epoch=28.2] | Loss=0.01668 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.520 | L2-Norm(final)=9.725 | 4800.5 samples/s | 75.0 steps/s
[Step=28900 Epoch=28.2] | Loss=0.01719 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=9.724 | 4851.0 samples/s | 75.8 steps/s
[Step=28950 Epoch=28.3] | Loss=0.01792 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=9.722 | 4812.2 samples/s | 75.2 steps/s
[Step=29000 Epoch=28.3] | Loss=0.01800 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.561 | L2-Norm(final)=9.719 | 4867.8 samples/s | 76.1 steps/s
[Step=29050 Epoch=28.4] | Loss=0.01823 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.573 | L2-Norm(final)=9.717 | 4843.9 samples/s | 75.7 steps/s
[Step=29100 Epoch=28.4] | Loss=0.01814 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.586 | L2-Norm(final)=9.715 | 4869.5 samples/s | 76.1 steps/s
[Step=29150 Epoch=28.5] | Loss=0.01816 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.597 | L2-Norm(final)=9.714 | 4850.5 samples/s | 75.8 steps/s
[Step=29200 Epoch=28.5] | Loss=0.01825 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.608 | L2-Norm(final)=9.713 | 4773.7 samples/s | 74.6 steps/s
[Step=29250 Epoch=28.6] | Loss=0.01797 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=9.711 | 4883.0 samples/s | 76.3 steps/s
[Step=29300 Epoch=28.6] | Loss=0.01810 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.628 | L2-Norm(final)=9.710 | 4824.6 samples/s | 75.4 steps/s
[Step=29350 Epoch=28.7] | Loss=0.01813 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.639 | L2-Norm(final)=9.709 | 4814.5 samples/s | 75.2 steps/s
[Step=29400 Epoch=28.7] | Loss=0.01818 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.648 | L2-Norm(final)=9.708 | 4799.6 samples/s | 75.0 steps/s
[Step=29450 Epoch=28.8] | Loss=0.01826 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=9.707 | 4863.8 samples/s | 76.0 steps/s
[Step=29500 Epoch=28.8] | Loss=0.01847 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.667 | L2-Norm(final)=9.705 | 5164.1 samples/s | 80.7 steps/s
[Step=29550 Epoch=28.9] | Loss=0.01844 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.677 | L2-Norm(final)=9.704 | 2146.4 samples/s | 33.5 steps/s
[Step=29600 Epoch=28.9] | Loss=0.01823 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.686 | L2-Norm(final)=9.702 | 4855.2 samples/s | 75.9 steps/s
[Step=29650 Epoch=28.9] | Loss=0.01804 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.695 | L2-Norm(final)=9.702 | 4878.6 samples/s | 76.2 steps/s
[Step=29700 Epoch=29.0] | Loss=0.01785 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.703 | L2-Norm(final)=9.701 | 4779.3 samples/s | 74.7 steps/s
[Step=29750 Epoch=29.0] | Loss=0.01769 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.711 | L2-Norm(final)=9.700 | 4828.5 samples/s | 75.4 steps/s
[Step=29800 Epoch=29.1] | Loss=0.01761 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.719 | L2-Norm(final)=9.699 | 4845.8 samples/s | 75.7 steps/s
[Step=29850 Epoch=29.1] | Loss=0.01756 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=9.699 | 4834.3 samples/s | 75.5 steps/s
[Step=29900 Epoch=29.2] | Loss=0.01743 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.734 | L2-Norm(final)=9.698 | 4922.8 samples/s | 76.9 steps/s
[Step=29950 Epoch=29.2] | Loss=0.01734 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.741 | L2-Norm(final)=9.698 | 4816.5 samples/s | 75.3 steps/s
[Step=30000 Epoch=29.3] | Loss=0.01731 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.748 | L2-Norm(final)=9.697 | 4873.9 samples/s | 76.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step30000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=28001 Epoch=52.8] | Loss=0.00408 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=13.155 | 4117.8 samples/s | 64.3 steps/s
[Step=28050 Epoch=52.9] | Loss=0.00101 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=13.167 | 5106.1 samples/s | 79.8 steps/s
[Step=28100 Epoch=53.0] | Loss=0.00123 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.182 | 5387.8 samples/s | 84.2 steps/s
[Step=28150 Epoch=53.1] | Loss=0.00132 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.195 | 5207.4 samples/s | 81.4 steps/s
[Step=28200 Epoch=53.2] | Loss=0.00188 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.203 | 5237.0 samples/s | 81.8 steps/s
[Step=28250 Epoch=53.3] | Loss=0.00170 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.212 | 5278.3 samples/s | 82.5 steps/s
[Step=28300 Epoch=53.3] | Loss=0.00156 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.223 | 5314.7 samples/s | 83.0 steps/s
[Step=28350 Epoch=53.4] | Loss=0.00179 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.234 | 5376.4 samples/s | 84.0 steps/s
[Step=28400 Epoch=53.5] | Loss=0.00172 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.244 | 5256.0 samples/s | 82.1 steps/s
[Step=28450 Epoch=53.6] | Loss=0.00164 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.327 | L2-Norm(final)=13.253 | 5313.7 samples/s | 83.0 steps/s
[Step=28500 Epoch=53.7] | Loss=0.00154 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=13.263 | 5315.9 samples/s | 83.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=53.7] | Loss=0.00002 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=13.358 | 3864.5 samples/s | 60.4 steps/s
[Step=28550 Epoch=53.8] | Loss=0.01538 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.422 | L2-Norm(final)=13.345 | 4471.0 samples/s | 69.9 steps/s
[Step=28600 Epoch=53.9] | Loss=0.01164 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=13.321 | 4568.1 samples/s | 71.4 steps/s
[Step=28650 Epoch=54.0] | Loss=0.00914 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.625 | L2-Norm(final)=13.307 | 4577.8 samples/s | 71.5 steps/s
[Step=28700 Epoch=54.1] | Loss=0.00826 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.663 | L2-Norm(final)=13.295 | 4641.2 samples/s | 72.5 steps/s
[Step=28750 Epoch=54.2] | Loss=0.00716 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=13.286 | 4590.3 samples/s | 71.7 steps/s
[Step=28800 Epoch=54.3] | Loss=0.00611 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.703 | L2-Norm(final)=13.279 | 4670.6 samples/s | 73.0 steps/s
[Step=28850 Epoch=54.4] | Loss=0.00532 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=13.275 | 4572.2 samples/s | 71.4 steps/s
[Step=28900 Epoch=54.5] | Loss=0.00476 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=13.273 | 4615.6 samples/s | 72.1 steps/s
[Step=28950 Epoch=54.6] | Loss=0.00427 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=13.270 | 4613.9 samples/s | 72.1 steps/s
[Step=29000 Epoch=54.7] | Loss=0.00386 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=13.268 | 4663.5 samples/s | 72.9 steps/s
[Step=29050 Epoch=54.8] | Loss=0.00351 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.720 | L2-Norm(final)=13.267 | 2157.2 samples/s | 33.7 steps/s
[Step=29100 Epoch=54.9] | Loss=0.00322 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=13.266 | 4689.7 samples/s | 73.3 steps/s
[Step=29150 Epoch=54.9] | Loss=0.00297 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=13.265 | 4586.2 samples/s | 71.7 steps/s
[Step=29200 Epoch=55.0] | Loss=0.00276 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.710 | L2-Norm(final)=13.264 | 4610.5 samples/s | 72.0 steps/s
[Step=29250 Epoch=55.1] | Loss=0.00258 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=13.264 | 4584.2 samples/s | 71.6 steps/s
[Step=29300 Epoch=55.2] | Loss=0.00242 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.700 | L2-Norm(final)=13.264 | 4627.8 samples/s | 72.3 steps/s
[Step=29350 Epoch=55.3] | Loss=0.00228 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.695 | L2-Norm(final)=13.264 | 4636.3 samples/s | 72.4 steps/s
[Step=29400 Epoch=55.4] | Loss=0.00215 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.689 | L2-Norm(final)=13.264 | 4593.6 samples/s | 71.8 steps/s
[Step=29450 Epoch=55.5] | Loss=0.00204 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.683 | L2-Norm(final)=13.264 | 4599.2 samples/s | 71.9 steps/s
[Step=29500 Epoch=55.6] | Loss=0.00194 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=13.264 | 4645.4 samples/s | 72.6 steps/s
[Step=29550 Epoch=55.7] | Loss=0.00185 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=13.264 | 5768.9 samples/s | 90.1 steps/s
[Step=29600 Epoch=55.8] | Loss=0.00176 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=13.264 | 1983.0 samples/s | 31.0 steps/s
[Step=29650 Epoch=55.9] | Loss=0.00169 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.654 | L2-Norm(final)=13.264 | 4677.9 samples/s | 73.1 steps/s
[Step=29700 Epoch=56.0] | Loss=0.00162 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.647 | L2-Norm(final)=13.264 | 4520.3 samples/s | 70.6 steps/s
[Step=29750 Epoch=56.1] | Loss=0.00155 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.639 | L2-Norm(final)=13.264 | 4623.0 samples/s | 72.2 steps/s
[Step=29800 Epoch=56.2] | Loss=0.00149 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.631 | L2-Norm(final)=13.264 | 4587.6 samples/s | 71.7 steps/s
[Step=29850 Epoch=56.3] | Loss=0.00144 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.623 | L2-Norm(final)=13.265 | 4667.7 samples/s | 72.9 steps/s
[Step=29900 Epoch=56.4] | Loss=0.00139 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.615 | L2-Norm(final)=13.265 | 4632.0 samples/s | 72.4 steps/s
[Step=29950 Epoch=56.5] | Loss=0.00134 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=13.265 | 4586.2 samples/s | 71.7 steps/s
[Step=30000 Epoch=56.6] | Loss=0.00130 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.598 | L2-Norm(final)=13.265 | 4595.2 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05709 | acc=0.9706 | tpr=0.9719 | fpr=0.0322 | 4197.4 samples/s | 16.4 steps/s
Avg test loss: 0.05774, Avg test acc: 0.96939, Avg tpr: 0.97150, Avg fpr: 0.03525, total FA: 275

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.79278 | acc=0.3021 | tpr=0.0064 | fpr=0.0557 | 4211.6 samples/s | 16.5 steps/s
Avg test loss: 10.76506, Avg test acc: 0.29994, Avg tpr: 0.00647, Avg fpr: 0.05461, total FA: 426

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.14245 | acc=0.1400 | tpr=0.4602 | fpr=0.8658 | 4219.9 samples/s | 16.5 steps/s
[Step= 100] | Loss=5.14069 | acc=0.1395 | tpr=0.4136 | fpr=0.8657 | 7903.2 samples/s | 30.9 steps/s
[Step= 150] | Loss=5.13382 | acc=0.1406 | tpr=0.4121 | fpr=0.8644 | 8350.6 samples/s | 32.6 steps/s
[Step= 200] | Loss=5.12215 | acc=0.1414 | tpr=0.4208 | fpr=0.8637 | 7772.9 samples/s | 30.4 steps/s
[Step= 250] | Loss=5.12274 | acc=0.1411 | tpr=0.4183 | fpr=0.8639 | 8036.1 samples/s | 31.4 steps/s
[Step= 300] | Loss=5.12444 | acc=0.1414 | tpr=0.4225 | fpr=0.8637 | 7897.6 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.11842 | acc=0.1411 | tpr=0.4233 | fpr=0.8640 | 8198.3 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.11980 | acc=0.1411 | tpr=0.4218 | fpr=0.8640 | 7783.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.12609 | acc=0.1406 | tpr=0.4236 | fpr=0.8645 | 8080.7 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.12302 | acc=0.1405 | tpr=0.4216 | fpr=0.8646 | 7791.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=5.12232 | acc=0.1406 | tpr=0.4230 | fpr=0.8645 | 15148.3 samples/s | 59.2 steps/s
Avg test loss: 5.12410, Avg test acc: 0.14057, Avg tpr: 0.42314, Avg fpr: 0.86456, total FA: 120043

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12750 | acc=0.9821 | tpr=0.9646 | fpr=0.0176 | 4175.2 samples/s | 16.3 steps/s
[Step= 100] | Loss=0.13281 | acc=0.9812 | tpr=0.9659 | fpr=0.0185 | 7812.9 samples/s | 30.5 steps/s
[Step= 150] | Loss=0.13803 | acc=0.9805 | tpr=0.9669 | fpr=0.0192 | 8150.7 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.13946 | acc=0.9806 | tpr=0.9694 | fpr=0.0192 | 7867.2 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.13765 | acc=0.9807 | tpr=0.9668 | fpr=0.0190 | 8001.7 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.14058 | acc=0.9804 | tpr=0.9644 | fpr=0.0193 | 7830.4 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.14126 | acc=0.9802 | tpr=0.9649 | fpr=0.0196 | 8279.5 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.14193 | acc=0.9800 | tpr=0.9633 | fpr=0.0196 | 7741.3 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.14504 | acc=0.9798 | tpr=0.9620 | fpr=0.0198 | 8221.5 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.14469 | acc=0.9799 | tpr=0.9621 | fpr=0.0198 | 7511.7 samples/s | 29.3 steps/s
[Step= 550] | Loss=0.14378 | acc=0.9800 | tpr=0.9622 | fpr=0.0196 | 15284.5 samples/s | 59.7 steps/s
Avg test loss: 0.14356, Avg test acc: 0.98005, Avg tpr: 0.96197, Avg fpr: 0.01962, total FA: 2724

server round 15/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=30001 Epoch=29.3] | Loss=0.05495 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.403 | L2-Norm(final)=9.680 | 4151.6 samples/s | 64.9 steps/s
[Step=30050 Epoch=29.3] | Loss=0.03641 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=9.689 | 5088.7 samples/s | 79.5 steps/s
[Step=30100 Epoch=29.4] | Loss=0.03486 | Reg=0.00237 | acc=0.9219 | L2-Norm=15.404 | L2-Norm(final)=9.689 | 5585.3 samples/s | 87.3 steps/s
[Step=30150 Epoch=29.4] | Loss=0.03349 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=9.692 | 5574.7 samples/s | 87.1 steps/s
[Step=30200 Epoch=29.5] | Loss=0.03343 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=9.696 | 5652.7 samples/s | 88.3 steps/s
[Step=30250 Epoch=29.5] | Loss=0.03435 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=9.701 | 5572.2 samples/s | 87.1 steps/s
[Step=30300 Epoch=29.6] | Loss=0.03435 | Reg=0.00237 | acc=0.9219 | L2-Norm=15.404 | L2-Norm(final)=9.705 | 5679.2 samples/s | 88.7 steps/s
[Step=30350 Epoch=29.6] | Loss=0.03363 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.404 | L2-Norm(final)=9.711 | 5561.3 samples/s | 86.9 steps/s
[Step=30400 Epoch=29.7] | Loss=0.03356 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.404 | L2-Norm(final)=9.716 | 5670.5 samples/s | 88.6 steps/s
[Step=30450 Epoch=29.7] | Loss=0.03309 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.404 | L2-Norm(final)=9.723 | 5558.4 samples/s | 86.8 steps/s
[Step=30500 Epoch=29.8] | Loss=0.03323 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=9.731 | 5651.4 samples/s | 88.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=29.8] | Loss=0.05190 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.405 | L2-Norm(final)=9.805 | 4435.6 samples/s | 69.3 steps/s
[Step=30550 Epoch=29.8] | Loss=0.02957 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=9.806 | 4464.6 samples/s | 69.8 steps/s
[Step=30600 Epoch=29.9] | Loss=0.02738 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.521 | L2-Norm(final)=9.803 | 4775.7 samples/s | 74.6 steps/s
[Step=30650 Epoch=29.9] | Loss=0.02495 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.557 | L2-Norm(final)=9.798 | 4860.3 samples/s | 75.9 steps/s
[Step=30700 Epoch=30.0] | Loss=0.02373 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.583 | L2-Norm(final)=9.795 | 4867.0 samples/s | 76.0 steps/s
[Step=30750 Epoch=30.0] | Loss=0.02344 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.604 | L2-Norm(final)=9.792 | 4811.3 samples/s | 75.2 steps/s
[Step=30800 Epoch=30.1] | Loss=0.02270 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.621 | L2-Norm(final)=9.790 | 4852.3 samples/s | 75.8 steps/s
[Step=30850 Epoch=30.1] | Loss=0.02198 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.636 | L2-Norm(final)=9.789 | 4876.6 samples/s | 76.2 steps/s
[Step=30900 Epoch=30.2] | Loss=0.02185 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.649 | L2-Norm(final)=9.788 | 4855.5 samples/s | 75.9 steps/s
[Step=30950 Epoch=30.2] | Loss=0.02119 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.661 | L2-Norm(final)=9.786 | 4778.9 samples/s | 74.7 steps/s
[Step=31000 Epoch=30.3] | Loss=0.02101 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.672 | L2-Norm(final)=9.784 | 4854.6 samples/s | 75.9 steps/s
[Step=31050 Epoch=30.3] | Loss=0.02076 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.683 | L2-Norm(final)=9.783 | 4827.7 samples/s | 75.4 steps/s
[Step=31100 Epoch=30.4] | Loss=0.02046 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.693 | L2-Norm(final)=9.782 | 4885.7 samples/s | 76.3 steps/s
[Step=31150 Epoch=30.4] | Loss=0.02026 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.702 | L2-Norm(final)=9.781 | 4845.2 samples/s | 75.7 steps/s
[Step=31200 Epoch=30.5] | Loss=0.02010 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.711 | L2-Norm(final)=9.780 | 4837.4 samples/s | 75.6 steps/s
[Step=31250 Epoch=30.5] | Loss=0.01979 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.719 | L2-Norm(final)=9.780 | 4877.5 samples/s | 76.2 steps/s
[Step=31300 Epoch=30.6] | Loss=0.01952 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.727 | L2-Norm(final)=9.779 | 4814.5 samples/s | 75.2 steps/s
[Step=31350 Epoch=30.6] | Loss=0.01919 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.734 | L2-Norm(final)=9.779 | 4867.7 samples/s | 76.1 steps/s
[Step=31400 Epoch=30.7] | Loss=0.01914 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.740 | L2-Norm(final)=9.779 | 4892.1 samples/s | 76.4 steps/s
[Step=31450 Epoch=30.7] | Loss=0.01902 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.747 | L2-Norm(final)=9.780 | 4865.6 samples/s | 76.0 steps/s
[Step=31500 Epoch=30.8] | Loss=0.01876 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.753 | L2-Norm(final)=9.780 | 5143.7 samples/s | 80.4 steps/s
[Step=31550 Epoch=30.8] | Loss=0.01876 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.760 | L2-Norm(final)=9.779 | 2090.6 samples/s | 32.7 steps/s
[Step=31600 Epoch=30.9] | Loss=0.01852 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.767 | L2-Norm(final)=9.779 | 4840.5 samples/s | 75.6 steps/s
[Step=31650 Epoch=30.9] | Loss=0.01837 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.773 | L2-Norm(final)=9.779 | 4853.4 samples/s | 75.8 steps/s
[Step=31700 Epoch=30.9] | Loss=0.01811 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.779 | L2-Norm(final)=9.779 | 4827.3 samples/s | 75.4 steps/s
[Step=31750 Epoch=31.0] | Loss=0.01786 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=9.780 | 4806.1 samples/s | 75.1 steps/s
[Step=31800 Epoch=31.0] | Loss=0.01769 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.791 | L2-Norm(final)=9.780 | 4827.9 samples/s | 75.4 steps/s
[Step=31850 Epoch=31.1] | Loss=0.01758 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.796 | L2-Norm(final)=9.780 | 4748.9 samples/s | 74.2 steps/s
[Step=31900 Epoch=31.1] | Loss=0.01747 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.802 | L2-Norm(final)=9.781 | 4854.7 samples/s | 75.9 steps/s
[Step=31950 Epoch=31.2] | Loss=0.01741 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.808 | L2-Norm(final)=9.781 | 4896.6 samples/s | 76.5 steps/s
[Step=32000 Epoch=31.2] | Loss=0.01732 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.814 | L2-Norm(final)=9.781 | 4832.8 samples/s | 75.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step32000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=30001 Epoch=56.6] | Loss=0.01166 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.403 | L2-Norm(final)=13.272 | 4164.9 samples/s | 65.1 steps/s
[Step=30050 Epoch=56.6] | Loss=0.00075 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=13.279 | 4908.9 samples/s | 76.7 steps/s
[Step=30100 Epoch=56.7] | Loss=0.00061 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=13.285 | 5272.9 samples/s | 82.4 steps/s
[Step=30150 Epoch=56.8] | Loss=0.00071 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=13.291 | 5355.0 samples/s | 83.7 steps/s
[Step=30200 Epoch=56.9] | Loss=0.00076 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.296 | 5244.8 samples/s | 81.9 steps/s
[Step=30250 Epoch=57.0] | Loss=0.00072 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.302 | 5385.9 samples/s | 84.2 steps/s
[Step=30300 Epoch=57.1] | Loss=0.00072 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.308 | 5214.9 samples/s | 81.5 steps/s
[Step=30350 Epoch=57.2] | Loss=0.00066 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.314 | 5311.4 samples/s | 83.0 steps/s
[Step=30400 Epoch=57.3] | Loss=0.00061 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.320 | 5212.1 samples/s | 81.4 steps/s
[Step=30450 Epoch=57.4] | Loss=0.00062 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.325 | 5486.5 samples/s | 85.7 steps/s
[Step=30500 Epoch=57.5] | Loss=0.00059 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.331 | 5308.6 samples/s | 82.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=57.5] | Loss=0.00000 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=13.385 | 3647.4 samples/s | 57.0 steps/s
[Step=30550 Epoch=57.6] | Loss=0.00034 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.393 | L2-Norm(final)=13.389 | 4566.9 samples/s | 71.4 steps/s
[Step=30600 Epoch=57.7] | Loss=0.00028 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=13.393 | 4594.0 samples/s | 71.8 steps/s
[Step=30650 Epoch=57.8] | Loss=0.00019 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=13.394 | 4562.1 samples/s | 71.3 steps/s
[Step=30700 Epoch=57.9] | Loss=0.00016 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=13.396 | 4551.9 samples/s | 71.1 steps/s
[Step=30750 Epoch=58.0] | Loss=0.00013 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=13.398 | 4622.5 samples/s | 72.2 steps/s
[Step=30800 Epoch=58.1] | Loss=0.00011 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=13.399 | 4628.5 samples/s | 72.3 steps/s
[Step=30850 Epoch=58.2] | Loss=0.00009 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=13.400 | 4673.4 samples/s | 73.0 steps/s
[Step=30900 Epoch=58.2] | Loss=0.00008 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=13.401 | 4565.5 samples/s | 71.3 steps/s
[Step=30950 Epoch=58.3] | Loss=0.00007 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.299 | L2-Norm(final)=13.402 | 4626.7 samples/s | 72.3 steps/s
[Step=31000 Epoch=58.4] | Loss=0.00007 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.284 | L2-Norm(final)=13.403 | 4610.9 samples/s | 72.0 steps/s
[Step=31050 Epoch=58.5] | Loss=0.00006 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=13.403 | 2098.7 samples/s | 32.8 steps/s
[Step=31100 Epoch=58.6] | Loss=0.00006 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.255 | L2-Norm(final)=13.404 | 4694.7 samples/s | 73.4 steps/s
[Step=31150 Epoch=58.7] | Loss=0.00005 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=13.405 | 4591.1 samples/s | 71.7 steps/s
[Step=31200 Epoch=58.8] | Loss=0.00005 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=13.405 | 4625.4 samples/s | 72.3 steps/s
[Step=31250 Epoch=58.9] | Loss=0.00005 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=13.406 | 4660.0 samples/s | 72.8 steps/s
[Step=31300 Epoch=59.0] | Loss=0.00004 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=13.407 | 4599.5 samples/s | 71.9 steps/s
[Step=31350 Epoch=59.1] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=13.408 | 4604.1 samples/s | 71.9 steps/s
[Step=31400 Epoch=59.2] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=13.409 | 4633.9 samples/s | 72.4 steps/s
[Step=31450 Epoch=59.3] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=13.409 | 4571.2 samples/s | 71.4 steps/s
[Step=31500 Epoch=59.4] | Loss=0.00004 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=13.410 | 4625.4 samples/s | 72.3 steps/s
[Step=31550 Epoch=59.5] | Loss=0.00003 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=13.411 | 5772.4 samples/s | 90.2 steps/s
[Step=31600 Epoch=59.6] | Loss=0.00003 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.103 | L2-Norm(final)=13.411 | 1984.3 samples/s | 31.0 steps/s
[Step=31650 Epoch=59.7] | Loss=0.00003 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=13.412 | 4601.4 samples/s | 71.9 steps/s
[Step=31700 Epoch=59.8] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.073 | L2-Norm(final)=13.413 | 4594.7 samples/s | 71.8 steps/s
[Step=31750 Epoch=59.8] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=13.414 | 4616.3 samples/s | 72.1 steps/s
[Step=31800 Epoch=59.9] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=13.415 | 4637.3 samples/s | 72.5 steps/s
[Step=31850 Epoch=60.0] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=13.416 | 4620.1 samples/s | 72.2 steps/s
[Step=31900 Epoch=60.1] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=13.417 | 4557.7 samples/s | 71.2 steps/s
[Step=31950 Epoch=60.2] | Loss=0.00002 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=13.418 | 4648.7 samples/s | 72.6 steps/s
[Step=32000 Epoch=60.3] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=13.419 | 4574.4 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05644 | acc=0.9710 | tpr=0.9746 | fpr=0.0367 | 4267.6 samples/s | 16.7 steps/s
Avg test loss: 0.05724, Avg test acc: 0.96971, Avg tpr: 0.97261, Avg fpr: 0.03666, total FA: 286

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.44499 | acc=0.2907 | tpr=0.0079 | fpr=0.0951 | 4270.5 samples/s | 16.7 steps/s
Avg test loss: 10.42567, Avg test acc: 0.28808, Avg tpr: 0.00764, Avg fpr: 0.09512, total FA: 742

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.78360 | acc=0.1332 | tpr=0.5088 | fpr=0.8735 | 4254.9 samples/s | 16.6 steps/s
[Step= 100] | Loss=5.77274 | acc=0.1321 | tpr=0.4542 | fpr=0.8739 | 7769.7 samples/s | 30.4 steps/s
[Step= 150] | Loss=5.76231 | acc=0.1329 | tpr=0.4553 | fpr=0.8731 | 7588.3 samples/s | 29.6 steps/s
[Step= 200] | Loss=5.75262 | acc=0.1337 | tpr=0.4481 | fpr=0.8720 | 8055.3 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.75040 | acc=0.1329 | tpr=0.4454 | fpr=0.8728 | 7809.8 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.75636 | acc=0.1330 | tpr=0.4524 | fpr=0.8728 | 8080.9 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.74840 | acc=0.1330 | tpr=0.4521 | fpr=0.8727 | 7875.7 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.75327 | acc=0.1328 | tpr=0.4535 | fpr=0.8730 | 8434.0 samples/s | 32.9 steps/s
[Step= 450] | Loss=5.75915 | acc=0.1323 | tpr=0.4547 | fpr=0.8736 | 7508.3 samples/s | 29.3 steps/s
[Step= 500] | Loss=5.75836 | acc=0.1319 | tpr=0.4546 | fpr=0.8739 | 8373.5 samples/s | 32.7 steps/s
[Step= 550] | Loss=5.75826 | acc=0.1320 | tpr=0.4548 | fpr=0.8739 | 13611.0 samples/s | 53.2 steps/s
Avg test loss: 5.76025, Avg test acc: 0.13192, Avg tpr: 0.45444, Avg fpr: 0.87394, total FA: 121345

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14587 | acc=0.9830 | tpr=0.9513 | fpr=0.0165 | 4271.8 samples/s | 16.7 steps/s
[Step= 100] | Loss=0.15159 | acc=0.9823 | tpr=0.9616 | fpr=0.0173 | 7727.4 samples/s | 30.2 steps/s
[Step= 150] | Loss=0.15576 | acc=0.9820 | tpr=0.9654 | fpr=0.0177 | 8299.8 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.15730 | acc=0.9820 | tpr=0.9639 | fpr=0.0177 | 7980.2 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.15518 | acc=0.9821 | tpr=0.9624 | fpr=0.0176 | 7959.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.15784 | acc=0.9815 | tpr=0.9585 | fpr=0.0181 | 7840.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.15797 | acc=0.9813 | tpr=0.9599 | fpr=0.0183 | 8137.6 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.15879 | acc=0.9812 | tpr=0.9590 | fpr=0.0184 | 7962.0 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.16181 | acc=0.9808 | tpr=0.9586 | fpr=0.0188 | 7724.3 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.16113 | acc=0.9808 | tpr=0.9581 | fpr=0.0188 | 8053.2 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.15998 | acc=0.9810 | tpr=0.9582 | fpr=0.0186 | 14671.3 samples/s | 57.3 steps/s
Avg test loss: 0.15997, Avg test acc: 0.98101, Avg tpr: 0.95840, Avg fpr: 0.01858, total FA: 2580

server round 16/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=32001 Epoch=31.2] | Loss=0.02984 | Reg=0.00228 | acc=0.9531 | L2-Norm=15.098 | L2-Norm(final)=9.786 | 3954.3 samples/s | 61.8 steps/s
[Step=32050 Epoch=31.3] | Loss=0.02205 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.100 | L2-Norm(final)=9.802 | 5599.8 samples/s | 87.5 steps/s
[Step=32100 Epoch=31.3] | Loss=0.01872 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.101 | L2-Norm(final)=9.817 | 5544.5 samples/s | 86.6 steps/s
[Step=32150 Epoch=31.4] | Loss=0.01889 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.831 | 5639.6 samples/s | 88.1 steps/s
[Step=32200 Epoch=31.4] | Loss=0.01805 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.845 | 5510.6 samples/s | 86.1 steps/s
[Step=32250 Epoch=31.5] | Loss=0.01816 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.101 | L2-Norm(final)=9.857 | 5649.0 samples/s | 88.3 steps/s
[Step=32300 Epoch=31.5] | Loss=0.01749 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.101 | L2-Norm(final)=9.867 | 5647.4 samples/s | 88.2 steps/s
[Step=32350 Epoch=31.6] | Loss=0.01730 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.877 | 5551.8 samples/s | 86.7 steps/s
[Step=32400 Epoch=31.6] | Loss=0.01727 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.887 | 5568.4 samples/s | 87.0 steps/s
[Step=32450 Epoch=31.7] | Loss=0.01757 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.101 | L2-Norm(final)=9.895 | 5546.9 samples/s | 86.7 steps/s
[Step=32500 Epoch=31.7] | Loss=0.01741 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.903 | 5631.4 samples/s | 88.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=31.7] | Loss=0.00290 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=9.976 | 4096.8 samples/s | 64.0 steps/s
[Step=32550 Epoch=31.8] | Loss=0.01628 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.138 | L2-Norm(final)=9.978 | 4664.6 samples/s | 72.9 steps/s
[Step=32600 Epoch=31.8] | Loss=0.01786 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.170 | L2-Norm(final)=9.977 | 4832.9 samples/s | 75.5 steps/s
[Step=32650 Epoch=31.9] | Loss=0.01643 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=9.975 | 4805.0 samples/s | 75.1 steps/s
[Step=32700 Epoch=31.9] | Loss=0.01554 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.219 | L2-Norm(final)=9.977 | 4793.3 samples/s | 74.9 steps/s
[Step=32750 Epoch=32.0] | Loss=0.01588 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=9.977 | 4707.4 samples/s | 73.6 steps/s
[Step=32800 Epoch=32.0] | Loss=0.01574 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.252 | L2-Norm(final)=9.977 | 4608.4 samples/s | 72.0 steps/s
[Step=32850 Epoch=32.1] | Loss=0.01549 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.265 | L2-Norm(final)=9.977 | 4694.4 samples/s | 73.4 steps/s
[Step=32900 Epoch=32.1] | Loss=0.01568 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.277 | L2-Norm(final)=9.977 | 4754.9 samples/s | 74.3 steps/s
[Step=32950 Epoch=32.2] | Loss=0.01604 | Reg=0.00234 | acc=0.9531 | L2-Norm=15.289 | L2-Norm(final)=9.976 | 4842.3 samples/s | 75.7 steps/s
[Step=33000 Epoch=32.2] | Loss=0.01639 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.300 | L2-Norm(final)=9.975 | 4881.6 samples/s | 76.3 steps/s
[Step=33050 Epoch=32.3] | Loss=0.01656 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.311 | L2-Norm(final)=9.974 | 4852.0 samples/s | 75.8 steps/s
[Step=33100 Epoch=32.3] | Loss=0.01643 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.322 | L2-Norm(final)=9.974 | 4806.4 samples/s | 75.1 steps/s
[Step=33150 Epoch=32.4] | Loss=0.01632 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.332 | L2-Norm(final)=9.974 | 4845.5 samples/s | 75.7 steps/s
[Step=33200 Epoch=32.4] | Loss=0.01643 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.342 | L2-Norm(final)=9.974 | 4887.5 samples/s | 76.4 steps/s
[Step=33250 Epoch=32.5] | Loss=0.01660 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.351 | L2-Norm(final)=9.974 | 4865.7 samples/s | 76.0 steps/s
[Step=33300 Epoch=32.5] | Loss=0.01682 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.361 | L2-Norm(final)=9.973 | 4877.6 samples/s | 76.2 steps/s
[Step=33350 Epoch=32.6] | Loss=0.01674 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.371 | L2-Norm(final)=9.973 | 4786.5 samples/s | 74.8 steps/s
[Step=33400 Epoch=32.6] | Loss=0.01690 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.381 | L2-Norm(final)=9.972 | 4858.9 samples/s | 75.9 steps/s
[Step=33450 Epoch=32.7] | Loss=0.01700 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=9.971 | 4817.3 samples/s | 75.3 steps/s
[Step=33500 Epoch=32.7] | Loss=0.01704 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.401 | L2-Norm(final)=9.970 | 5190.1 samples/s | 81.1 steps/s
[Step=33550 Epoch=32.8] | Loss=0.01716 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=9.969 | 2079.5 samples/s | 32.5 steps/s
[Step=33600 Epoch=32.8] | Loss=0.01698 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.420 | L2-Norm(final)=9.968 | 4852.5 samples/s | 75.8 steps/s
[Step=33650 Epoch=32.9] | Loss=0.01677 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=9.968 | 4860.1 samples/s | 75.9 steps/s
[Step=33700 Epoch=32.9] | Loss=0.01672 | Reg=0.00238 | acc=0.9688 | L2-Norm=15.439 | L2-Norm(final)=9.968 | 4891.7 samples/s | 76.4 steps/s
[Step=33750 Epoch=33.0] | Loss=0.01657 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.447 | L2-Norm(final)=9.968 | 4765.1 samples/s | 74.5 steps/s
[Step=33800 Epoch=33.0] | Loss=0.01651 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=9.968 | 4849.3 samples/s | 75.8 steps/s
[Step=33850 Epoch=33.0] | Loss=0.01642 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.464 | L2-Norm(final)=9.968 | 4867.3 samples/s | 76.1 steps/s
[Step=33900 Epoch=33.1] | Loss=0.01633 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.472 | L2-Norm(final)=9.968 | 4899.7 samples/s | 76.6 steps/s
[Step=33950 Epoch=33.1] | Loss=0.01626 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.479 | L2-Norm(final)=9.968 | 4826.7 samples/s | 75.4 steps/s
[Step=34000 Epoch=33.2] | Loss=0.01624 | Reg=0.00240 | acc=0.9219 | L2-Norm=15.487 | L2-Norm(final)=9.968 | 4804.4 samples/s | 75.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step34000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=32001 Epoch=60.3] | Loss=0.00007 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=13.449 | 3855.2 samples/s | 60.2 steps/s
[Step=32050 Epoch=60.4] | Loss=0.00213 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=13.454 | 5187.5 samples/s | 81.1 steps/s
[Step=32100 Epoch=60.5] | Loss=0.00242 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.468 | 5093.3 samples/s | 79.6 steps/s
[Step=32150 Epoch=60.6] | Loss=0.00234 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.482 | 5256.2 samples/s | 82.1 steps/s
[Step=32200 Epoch=60.7] | Loss=0.00228 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.498 | 5353.5 samples/s | 83.6 steps/s
[Step=32250 Epoch=60.8] | Loss=0.00236 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.092 | L2-Norm(final)=13.511 | 5334.8 samples/s | 83.4 steps/s
[Step=32300 Epoch=60.9] | Loss=0.00224 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.523 | 5137.7 samples/s | 80.3 steps/s
[Step=32350 Epoch=61.0] | Loss=0.00202 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.534 | 5273.4 samples/s | 82.4 steps/s
[Step=32400 Epoch=61.1] | Loss=0.00198 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.545 | 5301.1 samples/s | 82.8 steps/s
[Step=32450 Epoch=61.2] | Loss=0.00199 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.557 | 5318.6 samples/s | 83.1 steps/s
[Step=32500 Epoch=61.3] | Loss=0.00196 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.570 | 5321.9 samples/s | 83.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=61.3] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.694 | 4309.1 samples/s | 67.3 steps/s
[Step=32550 Epoch=61.4] | Loss=0.00717 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=13.683 | 4317.3 samples/s | 67.5 steps/s
[Step=32600 Epoch=61.5] | Loss=0.00841 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.297 | L2-Norm(final)=13.660 | 4530.7 samples/s | 70.8 steps/s
[Step=32650 Epoch=61.5] | Loss=0.00662 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=13.642 | 4607.3 samples/s | 72.0 steps/s
[Step=32700 Epoch=61.6] | Loss=0.00717 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.420 | L2-Norm(final)=13.630 | 4665.2 samples/s | 72.9 steps/s
[Step=32750 Epoch=61.7] | Loss=0.00626 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=13.617 | 4579.3 samples/s | 71.6 steps/s
[Step=32800 Epoch=61.8] | Loss=0.00534 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=13.608 | 4590.5 samples/s | 71.7 steps/s
[Step=32850 Epoch=61.9] | Loss=0.00537 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.496 | L2-Norm(final)=13.601 | 4617.1 samples/s | 72.1 steps/s
[Step=32900 Epoch=62.0] | Loss=0.00491 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=13.594 | 4602.2 samples/s | 71.9 steps/s
[Step=32950 Epoch=62.1] | Loss=0.00448 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=13.589 | 4632.6 samples/s | 72.4 steps/s
[Step=33000 Epoch=62.2] | Loss=0.00405 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=13.585 | 4632.8 samples/s | 72.4 steps/s
[Step=33050 Epoch=62.3] | Loss=0.00370 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=13.581 | 2086.1 samples/s | 32.6 steps/s
[Step=33100 Epoch=62.4] | Loss=0.00341 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=13.578 | 4681.4 samples/s | 73.1 steps/s
[Step=33150 Epoch=62.5] | Loss=0.00315 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=13.576 | 4686.9 samples/s | 73.2 steps/s
[Step=33200 Epoch=62.6] | Loss=0.00292 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=13.574 | 4536.1 samples/s | 70.9 steps/s
[Step=33250 Epoch=62.7] | Loss=0.00273 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=13.573 | 4639.4 samples/s | 72.5 steps/s
[Step=33300 Epoch=62.8] | Loss=0.00258 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=13.571 | 4627.2 samples/s | 72.3 steps/s
[Step=33350 Epoch=62.9] | Loss=0.00242 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=13.570 | 4567.9 samples/s | 71.4 steps/s
[Step=33400 Epoch=63.0] | Loss=0.00229 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=13.569 | 4639.7 samples/s | 72.5 steps/s
[Step=33450 Epoch=63.1] | Loss=0.00217 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.537 | L2-Norm(final)=13.569 | 4497.3 samples/s | 70.3 steps/s
[Step=33500 Epoch=63.1] | Loss=0.00206 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=13.568 | 4565.7 samples/s | 71.3 steps/s
[Step=33550 Epoch=63.2] | Loss=0.00197 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.530 | L2-Norm(final)=13.568 | 5771.3 samples/s | 90.2 steps/s
[Step=33600 Epoch=63.3] | Loss=0.00188 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.526 | L2-Norm(final)=13.568 | 1967.8 samples/s | 30.7 steps/s
[Step=33650 Epoch=63.4] | Loss=0.00180 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.522 | L2-Norm(final)=13.567 | 4625.3 samples/s | 72.3 steps/s
[Step=33700 Epoch=63.5] | Loss=0.00172 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.517 | L2-Norm(final)=13.567 | 4614.5 samples/s | 72.1 steps/s
[Step=33750 Epoch=63.6] | Loss=0.00165 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.512 | L2-Norm(final)=13.567 | 4569.4 samples/s | 71.4 steps/s
[Step=33800 Epoch=63.7] | Loss=0.00159 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=13.567 | 4642.8 samples/s | 72.5 steps/s
[Step=33850 Epoch=63.8] | Loss=0.00153 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=13.567 | 4585.3 samples/s | 71.6 steps/s
[Step=33900 Epoch=63.9] | Loss=0.00148 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.496 | L2-Norm(final)=13.567 | 4604.4 samples/s | 71.9 steps/s
[Step=33950 Epoch=64.0] | Loss=0.00142 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=13.567 | 4671.9 samples/s | 73.0 steps/s
[Step=34000 Epoch=64.1] | Loss=0.00138 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=13.567 | 4600.6 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05727 | acc=0.9717 | tpr=0.9774 | fpr=0.0406 | 4246.5 samples/s | 16.6 steps/s
Avg test loss: 0.05745, Avg test acc: 0.97083, Avg tpr: 0.97599, Avg fpr: 0.04051, total FA: 316

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=11.22057 | acc=0.3080 | tpr=0.0058 | fpr=0.0359 | 4262.6 samples/s | 16.7 steps/s
Avg test loss: 11.21921, Avg test acc: 0.30455, Avg tpr: 0.00589, Avg fpr: 0.03858, total FA: 301

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.63629 | acc=0.1245 | tpr=0.4867 | fpr=0.8821 | 4279.0 samples/s | 16.7 steps/s
[Step= 100] | Loss=5.63546 | acc=0.1253 | tpr=0.4435 | fpr=0.8807 | 7689.8 samples/s | 30.0 steps/s
[Step= 150] | Loss=5.62368 | acc=0.1259 | tpr=0.4481 | fpr=0.8800 | 8137.0 samples/s | 31.8 steps/s
[Step= 200] | Loss=5.61881 | acc=0.1261 | tpr=0.4514 | fpr=0.8798 | 7944.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.61491 | acc=0.1255 | tpr=0.4515 | fpr=0.8804 | 7908.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.61858 | acc=0.1253 | tpr=0.4575 | fpr=0.8807 | 8311.8 samples/s | 32.5 steps/s
[Step= 350] | Loss=5.61049 | acc=0.1254 | tpr=0.4527 | fpr=0.8805 | 7621.0 samples/s | 29.8 steps/s
[Step= 400] | Loss=5.61023 | acc=0.1254 | tpr=0.4513 | fpr=0.8806 | 8074.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.61667 | acc=0.1248 | tpr=0.4537 | fpr=0.8811 | 7949.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.61532 | acc=0.1245 | tpr=0.4520 | fpr=0.8814 | 7748.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.61577 | acc=0.1245 | tpr=0.4568 | fpr=0.8815 | 14968.9 samples/s | 58.5 steps/s
Avg test loss: 5.61710, Avg test acc: 0.12447, Avg tpr: 0.45642, Avg fpr: 0.88157, total FA: 122404

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12777 | acc=0.9820 | tpr=0.9558 | fpr=0.0175 | 4252.2 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.13245 | acc=0.9812 | tpr=0.9616 | fpr=0.0184 | 7845.1 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.13677 | acc=0.9804 | tpr=0.9654 | fpr=0.0193 | 8024.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.13881 | acc=0.9805 | tpr=0.9661 | fpr=0.0192 | 8056.7 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.13609 | acc=0.9810 | tpr=0.9668 | fpr=0.0188 | 7952.0 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.13807 | acc=0.9807 | tpr=0.9629 | fpr=0.0190 | 7987.4 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.13974 | acc=0.9807 | tpr=0.9637 | fpr=0.0190 | 8009.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.14105 | acc=0.9805 | tpr=0.9628 | fpr=0.0191 | 7923.5 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.14454 | acc=0.9802 | tpr=0.9606 | fpr=0.0194 | 7943.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14394 | acc=0.9802 | tpr=0.9604 | fpr=0.0194 | 8483.1 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.14297 | acc=0.9804 | tpr=0.9598 | fpr=0.0192 | 13191.8 samples/s | 51.5 steps/s
Avg test loss: 0.14285, Avg test acc: 0.98042, Avg tpr: 0.95880, Avg fpr: 0.01919, total FA: 2664

server round 17/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=34001 Epoch=33.2] | Loss=0.03494 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.262 | L2-Norm(final)=9.973 | 3926.5 samples/s | 61.4 steps/s
[Step=34050 Epoch=33.2] | Loss=0.03381 | Reg=0.00233 | acc=0.9375 | L2-Norm=15.266 | L2-Norm(final)=9.987 | 5334.3 samples/s | 83.3 steps/s
[Step=34100 Epoch=33.3] | Loss=0.03519 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.266 | L2-Norm(final)=9.993 | 5244.5 samples/s | 81.9 steps/s
[Step=34150 Epoch=33.3] | Loss=0.03389 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=9.997 | 5081.3 samples/s | 79.4 steps/s
[Step=34200 Epoch=33.4] | Loss=0.03577 | Reg=0.00233 | acc=0.9531 | L2-Norm=15.267 | L2-Norm(final)=10.003 | 5592.7 samples/s | 87.4 steps/s
[Step=34250 Epoch=33.4] | Loss=0.03559 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.267 | L2-Norm(final)=10.007 | 5772.7 samples/s | 90.2 steps/s
[Step=34300 Epoch=33.5] | Loss=0.03472 | Reg=0.00233 | acc=0.9531 | L2-Norm=15.267 | L2-Norm(final)=10.013 | 5400.9 samples/s | 84.4 steps/s
[Step=34350 Epoch=33.5] | Loss=0.03395 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.267 | L2-Norm(final)=10.021 | 5604.5 samples/s | 87.6 steps/s
[Step=34400 Epoch=33.6] | Loss=0.03401 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=10.029 | 5669.1 samples/s | 88.6 steps/s
[Step=34450 Epoch=33.6] | Loss=0.03421 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.267 | L2-Norm(final)=10.035 | 5659.1 samples/s | 88.4 steps/s
[Step=34500 Epoch=33.7] | Loss=0.03446 | Reg=0.00233 | acc=0.9531 | L2-Norm=15.267 | L2-Norm(final)=10.041 | 5576.2 samples/s | 87.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=33.7] | Loss=0.03396 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.267 | L2-Norm(final)=10.097 | 4252.0 samples/s | 66.4 steps/s
[Step=34550 Epoch=33.7] | Loss=0.02357 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.320 | L2-Norm(final)=10.104 | 4492.2 samples/s | 70.2 steps/s
[Step=34600 Epoch=33.8] | Loss=0.02444 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.360 | L2-Norm(final)=10.102 | 4808.2 samples/s | 75.1 steps/s
[Step=34650 Epoch=33.8] | Loss=0.02256 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.385 | L2-Norm(final)=10.098 | 4813.4 samples/s | 75.2 steps/s
[Step=34700 Epoch=33.9] | Loss=0.02173 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=10.096 | 4823.7 samples/s | 75.4 steps/s
[Step=34750 Epoch=33.9] | Loss=0.02050 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.422 | L2-Norm(final)=10.095 | 4820.1 samples/s | 75.3 steps/s
[Step=34800 Epoch=34.0] | Loss=0.01955 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=10.095 | 4840.7 samples/s | 75.6 steps/s
[Step=34850 Epoch=34.0] | Loss=0.01927 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.451 | L2-Norm(final)=10.095 | 4884.3 samples/s | 76.3 steps/s
[Step=34900 Epoch=34.1] | Loss=0.01956 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=10.094 | 4877.6 samples/s | 76.2 steps/s
[Step=34950 Epoch=34.1] | Loss=0.01939 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.478 | L2-Norm(final)=10.093 | 4866.2 samples/s | 76.0 steps/s
[Step=35000 Epoch=34.2] | Loss=0.01898 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=10.093 | 4921.5 samples/s | 76.9 steps/s
[Step=35050 Epoch=34.2] | Loss=0.01879 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.502 | L2-Norm(final)=10.092 | 4801.3 samples/s | 75.0 steps/s
[Step=35100 Epoch=34.3] | Loss=0.01869 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.513 | L2-Norm(final)=10.092 | 4884.0 samples/s | 76.3 steps/s
[Step=35150 Epoch=34.3] | Loss=0.01863 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.523 | L2-Norm(final)=10.092 | 4831.0 samples/s | 75.5 steps/s
[Step=35200 Epoch=34.4] | Loss=0.01869 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.533 | L2-Norm(final)=10.091 | 4854.7 samples/s | 75.9 steps/s
[Step=35250 Epoch=34.4] | Loss=0.01839 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=10.090 | 4802.2 samples/s | 75.0 steps/s
[Step=35300 Epoch=34.5] | Loss=0.01808 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=10.090 | 4853.3 samples/s | 75.8 steps/s
[Step=35350 Epoch=34.5] | Loss=0.01805 | Reg=0.00242 | acc=0.9375 | L2-Norm=15.562 | L2-Norm(final)=10.090 | 4826.5 samples/s | 75.4 steps/s
[Step=35400 Epoch=34.6] | Loss=0.01801 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=10.089 | 4890.3 samples/s | 76.4 steps/s
[Step=35450 Epoch=34.6] | Loss=0.01807 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=10.089 | 4824.2 samples/s | 75.4 steps/s
[Step=35500 Epoch=34.7] | Loss=0.01800 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.589 | L2-Norm(final)=10.089 | 5188.8 samples/s | 81.1 steps/s
[Step=35550 Epoch=34.7] | Loss=0.01798 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.597 | L2-Norm(final)=10.088 | 2063.6 samples/s | 32.2 steps/s
[Step=35600 Epoch=34.8] | Loss=0.01781 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=10.088 | 4778.0 samples/s | 74.7 steps/s
[Step=35650 Epoch=34.8] | Loss=0.01748 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.613 | L2-Norm(final)=10.088 | 4698.2 samples/s | 73.4 steps/s
[Step=35700 Epoch=34.9] | Loss=0.01719 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.620 | L2-Norm(final)=10.088 | 4806.1 samples/s | 75.1 steps/s
[Step=35750 Epoch=34.9] | Loss=0.01715 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.627 | L2-Norm(final)=10.088 | 4910.5 samples/s | 76.7 steps/s
[Step=35800 Epoch=35.0] | Loss=0.01706 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.634 | L2-Norm(final)=10.087 | 4801.4 samples/s | 75.0 steps/s
[Step=35850 Epoch=35.0] | Loss=0.01689 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.640 | L2-Norm(final)=10.087 | 4548.3 samples/s | 71.1 steps/s
[Step=35900 Epoch=35.1] | Loss=0.01680 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.646 | L2-Norm(final)=10.087 | 4819.0 samples/s | 75.3 steps/s
[Step=35950 Epoch=35.1] | Loss=0.01673 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.652 | L2-Norm(final)=10.087 | 4862.7 samples/s | 76.0 steps/s
[Step=36000 Epoch=35.1] | Loss=0.01675 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=10.087 | 4860.1 samples/s | 75.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step36000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=34001 Epoch=64.1] | Loss=0.00084 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=13.566 | 4650.4 samples/s | 72.7 steps/s
[Step=34050 Epoch=64.2] | Loss=0.00027 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.570 | 4333.4 samples/s | 67.7 steps/s
[Step=34100 Epoch=64.3] | Loss=0.00034 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.574 | 5284.6 samples/s | 82.6 steps/s
[Step=34150 Epoch=64.4] | Loss=0.00052 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.577 | 5213.3 samples/s | 81.5 steps/s
[Step=34200 Epoch=64.5] | Loss=0.00049 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.580 | 5327.7 samples/s | 83.2 steps/s
[Step=34250 Epoch=64.6] | Loss=0.00053 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.584 | 5351.3 samples/s | 83.6 steps/s
[Step=34300 Epoch=64.7] | Loss=0.00047 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.587 | 5314.0 samples/s | 83.0 steps/s
[Step=34350 Epoch=64.8] | Loss=0.00045 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.590 | 5276.7 samples/s | 82.4 steps/s
[Step=34400 Epoch=64.8] | Loss=0.00045 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.594 | 5438.6 samples/s | 85.0 steps/s
[Step=34450 Epoch=64.9] | Loss=0.00043 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.597 | 5261.6 samples/s | 82.2 steps/s
[Step=34500 Epoch=65.0] | Loss=0.00046 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.259 | L2-Norm(final)=13.601 | 5314.6 samples/s | 83.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=65.0] | Loss=0.00029 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=13.635 | 3713.5 samples/s | 58.0 steps/s
[Step=34550 Epoch=65.1] | Loss=0.00027 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.252 | L2-Norm(final)=13.639 | 4558.5 samples/s | 71.2 steps/s
[Step=34600 Epoch=65.2] | Loss=0.00016 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=13.642 | 4612.8 samples/s | 72.1 steps/s
[Step=34650 Epoch=65.3] | Loss=0.00012 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.235 | L2-Norm(final)=13.644 | 4616.2 samples/s | 72.1 steps/s
[Step=34700 Epoch=65.4] | Loss=0.00009 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.223 | L2-Norm(final)=13.645 | 4599.4 samples/s | 71.9 steps/s
[Step=34750 Epoch=65.5] | Loss=0.00008 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=13.646 | 4612.9 samples/s | 72.1 steps/s
[Step=34800 Epoch=65.6] | Loss=0.00007 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=13.648 | 4647.5 samples/s | 72.6 steps/s
[Step=34850 Epoch=65.7] | Loss=0.00007 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=13.649 | 4591.0 samples/s | 71.7 steps/s
[Step=34900 Epoch=65.8] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=13.650 | 4613.6 samples/s | 72.1 steps/s
[Step=34950 Epoch=65.9] | Loss=0.00007 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=13.652 | 4677.5 samples/s | 73.1 steps/s
[Step=35000 Epoch=66.0] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.158 | L2-Norm(final)=13.653 | 4633.0 samples/s | 72.4 steps/s
[Step=35050 Epoch=66.1] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=13.655 | 2148.3 samples/s | 33.6 steps/s
[Step=35100 Epoch=66.2] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=13.656 | 4667.0 samples/s | 72.9 steps/s
[Step=35150 Epoch=66.3] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=13.657 | 4609.8 samples/s | 72.0 steps/s
[Step=35200 Epoch=66.4] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=13.658 | 4636.8 samples/s | 72.4 steps/s
[Step=35250 Epoch=66.4] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.103 | L2-Norm(final)=13.659 | 4645.9 samples/s | 72.6 steps/s
[Step=35300 Epoch=66.5] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=13.659 | 4664.3 samples/s | 72.9 steps/s
[Step=35350 Epoch=66.6] | Loss=0.00004 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.080 | L2-Norm(final)=13.660 | 4649.0 samples/s | 72.6 steps/s
[Step=35400 Epoch=66.7] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=13.661 | 4548.7 samples/s | 71.1 steps/s
[Step=35450 Epoch=66.8] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=13.661 | 4599.4 samples/s | 71.9 steps/s
[Step=35500 Epoch=66.9] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=13.662 | 4610.1 samples/s | 72.0 steps/s
[Step=35550 Epoch=67.0] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.662 | 5700.7 samples/s | 89.1 steps/s
[Step=35600 Epoch=67.1] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=13.663 | 1965.1 samples/s | 30.7 steps/s
[Step=35650 Epoch=67.2] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=13.663 | 4609.9 samples/s | 72.0 steps/s
[Step=35700 Epoch=67.3] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=13.664 | 4632.3 samples/s | 72.4 steps/s
[Step=35750 Epoch=67.4] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=13.664 | 4590.8 samples/s | 71.7 steps/s
[Step=35800 Epoch=67.5] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=13.665 | 4622.2 samples/s | 72.2 steps/s
[Step=35850 Epoch=67.6] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=13.665 | 4596.3 samples/s | 71.8 steps/s
[Step=35900 Epoch=67.7] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=13.666 | 4655.8 samples/s | 72.7 steps/s
[Step=35950 Epoch=67.8] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.936 | L2-Norm(final)=13.666 | 4598.7 samples/s | 71.9 steps/s
[Step=36000 Epoch=67.9] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=13.667 | 4562.0 samples/s | 71.3 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05718 | acc=0.9685 | tpr=0.9718 | fpr=0.0387 | 4199.3 samples/s | 16.4 steps/s
Avg test loss: 0.05841, Avg test acc: 0.96895, Avg tpr: 0.97290, Avg fpr: 0.03974, total FA: 310

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.63594 | acc=0.2970 | tpr=0.0086 | fpr=0.0768 | 4261.7 samples/s | 16.6 steps/s
Avg test loss: 9.63104, Avg test acc: 0.29421, Avg tpr: 0.00898, Avg fpr: 0.07845, total FA: 612

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.42379 | acc=0.1470 | tpr=0.3540 | fpr=0.8568 | 4260.1 samples/s | 16.6 steps/s
[Step= 100] | Loss=5.41029 | acc=0.1458 | tpr=0.3348 | fpr=0.8577 | 7613.6 samples/s | 29.7 steps/s
[Step= 150] | Loss=5.39493 | acc=0.1468 | tpr=0.3458 | fpr=0.8568 | 8015.1 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.37774 | acc=0.1472 | tpr=0.3486 | fpr=0.8564 | 8035.4 samples/s | 31.4 steps/s
[Step= 250] | Loss=5.37605 | acc=0.1471 | tpr=0.3537 | fpr=0.8566 | 7951.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=5.38096 | acc=0.1476 | tpr=0.3585 | fpr=0.8563 | 7918.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.37660 | acc=0.1477 | tpr=0.3575 | fpr=0.8562 | 8046.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.38110 | acc=0.1475 | tpr=0.3589 | fpr=0.8563 | 8324.8 samples/s | 32.5 steps/s
[Step= 450] | Loss=5.38673 | acc=0.1469 | tpr=0.3583 | fpr=0.8569 | 7473.8 samples/s | 29.2 steps/s
[Step= 500] | Loss=5.38188 | acc=0.1467 | tpr=0.3564 | fpr=0.8571 | 8144.2 samples/s | 31.8 steps/s
[Step= 550] | Loss=5.38165 | acc=0.1469 | tpr=0.3613 | fpr=0.8570 | 14609.4 samples/s | 57.1 steps/s
Avg test loss: 5.38317, Avg test acc: 0.14683, Avg tpr: 0.36014, Avg fpr: 0.85705, total FA: 118999

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14169 | acc=0.9823 | tpr=0.9513 | fpr=0.0172 | 4218.8 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.14740 | acc=0.9815 | tpr=0.9552 | fpr=0.0180 | 7940.8 samples/s | 31.0 steps/s
[Step= 150] | Loss=0.15173 | acc=0.9806 | tpr=0.9597 | fpr=0.0190 | 7975.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.15443 | acc=0.9805 | tpr=0.9617 | fpr=0.0191 | 8131.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.15251 | acc=0.9807 | tpr=0.9598 | fpr=0.0189 | 8035.2 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.15481 | acc=0.9804 | tpr=0.9571 | fpr=0.0191 | 8020.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.15542 | acc=0.9803 | tpr=0.9580 | fpr=0.0193 | 7800.3 samples/s | 30.5 steps/s
[Step= 400] | Loss=0.15662 | acc=0.9800 | tpr=0.9557 | fpr=0.0195 | 8102.9 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.15960 | acc=0.9797 | tpr=0.9552 | fpr=0.0199 | 7808.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.15878 | acc=0.9798 | tpr=0.9551 | fpr=0.0198 | 7948.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.15743 | acc=0.9800 | tpr=0.9550 | fpr=0.0195 | 15112.7 samples/s | 59.0 steps/s
Avg test loss: 0.15734, Avg test acc: 0.98003, Avg tpr: 0.95483, Avg fpr: 0.01951, total FA: 2709

server round 18/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=36001 Epoch=35.1] | Loss=0.01240 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=10.083 | 4026.9 samples/s | 62.9 steps/s
[Step=36050 Epoch=35.2] | Loss=0.01261 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=10.095 | 5376.8 samples/s | 84.0 steps/s
[Step=36100 Epoch=35.2] | Loss=0.01273 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.108 | 5654.8 samples/s | 88.4 steps/s
[Step=36150 Epoch=35.3] | Loss=0.01318 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.119 | 5524.1 samples/s | 86.3 steps/s
[Step=36200 Epoch=35.3] | Loss=0.01365 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.129 | 5657.6 samples/s | 88.4 steps/s
[Step=36250 Epoch=35.4] | Loss=0.01397 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.071 | L2-Norm(final)=10.138 | 5564.6 samples/s | 86.9 steps/s
[Step=36300 Epoch=35.4] | Loss=0.01394 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.147 | 5616.7 samples/s | 87.8 steps/s
[Step=36350 Epoch=35.5] | Loss=0.01381 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.157 | 5682.9 samples/s | 88.8 steps/s
[Step=36400 Epoch=35.5] | Loss=0.01357 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.166 | 5696.1 samples/s | 89.0 steps/s
[Step=36450 Epoch=35.6] | Loss=0.01372 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.071 | L2-Norm(final)=10.175 | 5473.7 samples/s | 85.5 steps/s
[Step=36500 Epoch=35.6] | Loss=0.01391 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=10.183 | 5597.5 samples/s | 87.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=35.6] | Loss=0.01789 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.071 | L2-Norm(final)=10.263 | 4136.1 samples/s | 64.6 steps/s
[Step=36550 Epoch=35.7] | Loss=0.01502 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.101 | L2-Norm(final)=10.266 | 4509.4 samples/s | 70.5 steps/s
[Step=36600 Epoch=35.7] | Loss=0.01395 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=10.263 | 4786.9 samples/s | 74.8 steps/s
[Step=36650 Epoch=35.8] | Loss=0.01413 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=10.262 | 4885.9 samples/s | 76.3 steps/s
[Step=36700 Epoch=35.8] | Loss=0.01550 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=10.262 | 4779.9 samples/s | 74.7 steps/s
[Step=36750 Epoch=35.9] | Loss=0.01575 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=10.260 | 4846.5 samples/s | 75.7 steps/s
[Step=36800 Epoch=35.9] | Loss=0.01592 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=10.259 | 4839.1 samples/s | 75.6 steps/s
[Step=36850 Epoch=36.0] | Loss=0.01611 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=10.258 | 4829.3 samples/s | 75.5 steps/s
[Step=36900 Epoch=36.0] | Loss=0.01609 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.221 | L2-Norm(final)=10.259 | 4840.3 samples/s | 75.6 steps/s
[Step=36950 Epoch=36.1] | Loss=0.01618 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.233 | L2-Norm(final)=10.260 | 4902.1 samples/s | 76.6 steps/s
[Step=37000 Epoch=36.1] | Loss=0.01616 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.246 | L2-Norm(final)=10.260 | 4773.7 samples/s | 74.6 steps/s
[Step=37050 Epoch=36.2] | Loss=0.01647 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=10.260 | 4859.5 samples/s | 75.9 steps/s
[Step=37100 Epoch=36.2] | Loss=0.01670 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=10.260 | 4837.9 samples/s | 75.6 steps/s
[Step=37150 Epoch=36.3] | Loss=0.01701 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.282 | L2-Norm(final)=10.260 | 4860.6 samples/s | 75.9 steps/s
[Step=37200 Epoch=36.3] | Loss=0.01692 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=10.260 | 4908.8 samples/s | 76.7 steps/s
[Step=37250 Epoch=36.4] | Loss=0.01684 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.304 | L2-Norm(final)=10.260 | 4867.4 samples/s | 76.1 steps/s
[Step=37300 Epoch=36.4] | Loss=0.01676 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.314 | L2-Norm(final)=10.260 | 4854.9 samples/s | 75.9 steps/s
[Step=37350 Epoch=36.5] | Loss=0.01662 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=10.259 | 4788.9 samples/s | 74.8 steps/s
[Step=37400 Epoch=36.5] | Loss=0.01664 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.334 | L2-Norm(final)=10.259 | 4813.8 samples/s | 75.2 steps/s
[Step=37450 Epoch=36.6] | Loss=0.01654 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=10.259 | 4871.4 samples/s | 76.1 steps/s
[Step=37500 Epoch=36.6] | Loss=0.01647 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=10.258 | 5188.7 samples/s | 81.1 steps/s
[Step=37550 Epoch=36.7] | Loss=0.01631 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=10.258 | 2131.0 samples/s | 33.3 steps/s
[Step=37600 Epoch=36.7] | Loss=0.01619 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=10.258 | 4842.2 samples/s | 75.7 steps/s
[Step=37650 Epoch=36.8] | Loss=0.01619 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=10.257 | 4836.9 samples/s | 75.6 steps/s
[Step=37700 Epoch=36.8] | Loss=0.01602 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=10.257 | 4788.5 samples/s | 74.8 steps/s
[Step=37750 Epoch=36.9] | Loss=0.01591 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.398 | L2-Norm(final)=10.256 | 4876.3 samples/s | 76.2 steps/s
[Step=37800 Epoch=36.9] | Loss=0.01596 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=10.255 | 4767.3 samples/s | 74.5 steps/s
[Step=37850 Epoch=37.0] | Loss=0.01590 | Reg=0.00238 | acc=0.9375 | L2-Norm=15.414 | L2-Norm(final)=10.255 | 4787.5 samples/s | 74.8 steps/s
[Step=37900 Epoch=37.0] | Loss=0.01592 | Reg=0.00238 | acc=0.9531 | L2-Norm=15.422 | L2-Norm(final)=10.254 | 4864.3 samples/s | 76.0 steps/s
[Step=37950 Epoch=37.1] | Loss=0.01586 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=10.254 | 4889.2 samples/s | 76.4 steps/s
[Step=38000 Epoch=37.1] | Loss=0.01577 | Reg=0.00238 | acc=0.9688 | L2-Norm=15.437 | L2-Norm(final)=10.253 | 4814.2 samples/s | 75.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step38000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=36001 Epoch=67.9] | Loss=0.00070 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=13.680 | 4291.1 samples/s | 67.0 steps/s
[Step=36050 Epoch=68.0] | Loss=0.00110 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=13.682 | 4943.9 samples/s | 77.2 steps/s
[Step=36100 Epoch=68.0] | Loss=0.00146 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.689 | 5216.4 samples/s | 81.5 steps/s
[Step=36150 Epoch=68.1] | Loss=0.00122 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.698 | 5266.6 samples/s | 82.3 steps/s
[Step=36200 Epoch=68.2] | Loss=0.00103 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.707 | 5280.2 samples/s | 82.5 steps/s
[Step=36250 Epoch=68.3] | Loss=0.00095 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.716 | 5208.4 samples/s | 81.4 steps/s
[Step=36300 Epoch=68.4] | Loss=0.00084 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.726 | 5402.0 samples/s | 84.4 steps/s
[Step=36350 Epoch=68.5] | Loss=0.00080 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.736 | 5209.0 samples/s | 81.4 steps/s
[Step=36400 Epoch=68.6] | Loss=0.00081 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.747 | 5317.5 samples/s | 83.1 steps/s
[Step=36450 Epoch=68.7] | Loss=0.00080 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.759 | 5449.7 samples/s | 85.2 steps/s
[Step=36500 Epoch=68.8] | Loss=0.00079 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.770 | 5384.9 samples/s | 84.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=68.8] | Loss=0.00090 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=13.879 | 3940.9 samples/s | 61.6 steps/s
[Step=36550 Epoch=68.9] | Loss=0.00814 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=13.863 | 4645.0 samples/s | 72.6 steps/s
[Step=36600 Epoch=69.0] | Loss=0.00653 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=13.847 | 4630.1 samples/s | 72.3 steps/s
[Step=36650 Epoch=69.1] | Loss=0.00480 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.302 | L2-Norm(final)=13.836 | 4576.5 samples/s | 71.5 steps/s
[Step=36700 Epoch=69.2] | Loss=0.00481 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=13.829 | 4646.7 samples/s | 72.6 steps/s
[Step=36750 Epoch=69.3] | Loss=0.00430 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.347 | L2-Norm(final)=13.820 | 4638.1 samples/s | 72.5 steps/s
[Step=36800 Epoch=69.4] | Loss=0.00378 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=13.813 | 4568.2 samples/s | 71.4 steps/s
[Step=36850 Epoch=69.5] | Loss=0.00326 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=13.807 | 4615.8 samples/s | 72.1 steps/s
[Step=36900 Epoch=69.6] | Loss=0.00288 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=13.804 | 4583.3 samples/s | 71.6 steps/s
[Step=36950 Epoch=69.7] | Loss=0.00258 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.387 | L2-Norm(final)=13.801 | 4595.4 samples/s | 71.8 steps/s
[Step=37000 Epoch=69.7] | Loss=0.00232 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=13.799 | 4673.9 samples/s | 73.0 steps/s
[Step=37050 Epoch=69.8] | Loss=0.00211 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=13.797 | 2119.1 samples/s | 33.1 steps/s
[Step=37100 Epoch=69.9] | Loss=0.00194 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=13.796 | 4642.2 samples/s | 72.5 steps/s
[Step=37150 Epoch=70.0] | Loss=0.00179 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.386 | L2-Norm(final)=13.794 | 4642.6 samples/s | 72.5 steps/s
[Step=37200 Epoch=70.1] | Loss=0.00166 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=13.793 | 4586.4 samples/s | 71.7 steps/s
[Step=37250 Epoch=70.2] | Loss=0.00155 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.379 | L2-Norm(final)=13.793 | 4618.4 samples/s | 72.2 steps/s
[Step=37300 Epoch=70.3] | Loss=0.00146 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=13.792 | 4596.8 samples/s | 71.8 steps/s
[Step=37350 Epoch=70.4] | Loss=0.00137 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=13.791 | 4570.1 samples/s | 71.4 steps/s
[Step=37400 Epoch=70.5] | Loss=0.00130 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=13.791 | 4679.1 samples/s | 73.1 steps/s
[Step=37450 Epoch=70.6] | Loss=0.00123 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=13.791 | 4575.3 samples/s | 71.5 steps/s
[Step=37500 Epoch=70.7] | Loss=0.00117 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=13.790 | 4594.6 samples/s | 71.8 steps/s
[Step=37550 Epoch=70.8] | Loss=0.00111 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=13.790 | 5753.3 samples/s | 89.9 steps/s
[Step=37600 Epoch=70.9] | Loss=0.00106 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.342 | L2-Norm(final)=13.790 | 1968.3 samples/s | 30.8 steps/s
[Step=37650 Epoch=71.0] | Loss=0.00101 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=13.790 | 4605.6 samples/s | 72.0 steps/s
[Step=37700 Epoch=71.1] | Loss=0.00097 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=13.790 | 4600.3 samples/s | 71.9 steps/s
[Step=37750 Epoch=71.2] | Loss=0.00093 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.323 | L2-Norm(final)=13.790 | 4532.3 samples/s | 70.8 steps/s
[Step=37800 Epoch=71.3] | Loss=0.00090 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=13.790 | 4588.7 samples/s | 71.7 steps/s
[Step=37850 Epoch=71.3] | Loss=0.00086 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=13.790 | 4668.1 samples/s | 72.9 steps/s
[Step=37900 Epoch=71.4] | Loss=0.00083 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.303 | L2-Norm(final)=13.790 | 4580.4 samples/s | 71.6 steps/s
[Step=37950 Epoch=71.5] | Loss=0.00081 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=13.790 | 4638.2 samples/s | 72.5 steps/s
[Step=38000 Epoch=71.6] | Loss=0.00078 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=13.790 | 4621.0 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06313 | acc=0.9685 | tpr=0.9704 | fpr=0.0357 | 4218.8 samples/s | 16.5 steps/s
Avg test loss: 0.06437, Avg test acc: 0.96783, Avg tpr: 0.96958, Avg fpr: 0.03602, total FA: 281

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=11.24096 | acc=0.2995 | tpr=0.0139 | fpr=0.0803 | 4195.1 samples/s | 16.4 steps/s
Avg test loss: 11.23748, Avg test acc: 0.29718, Avg tpr: 0.01370, Avg fpr: 0.07935, total FA: 619

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.09278 | acc=0.1479 | tpr=0.4690 | fpr=0.8579 | 4226.0 samples/s | 16.5 steps/s
[Step= 100] | Loss=5.08720 | acc=0.1484 | tpr=0.4179 | fpr=0.8566 | 7984.4 samples/s | 31.2 steps/s
[Step= 150] | Loss=5.07652 | acc=0.1499 | tpr=0.4179 | fpr=0.8550 | 7844.8 samples/s | 30.6 steps/s
[Step= 200] | Loss=5.06682 | acc=0.1496 | tpr=0.4109 | fpr=0.8552 | 8305.6 samples/s | 32.4 steps/s
[Step= 250] | Loss=5.06654 | acc=0.1489 | tpr=0.4061 | fpr=0.8557 | 7898.0 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.06897 | acc=0.1495 | tpr=0.4145 | fpr=0.8554 | 7913.8 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.06492 | acc=0.1495 | tpr=0.4133 | fpr=0.8553 | 8301.1 samples/s | 32.4 steps/s
[Step= 400] | Loss=5.06650 | acc=0.1496 | tpr=0.4103 | fpr=0.8552 | 7877.8 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.07283 | acc=0.1493 | tpr=0.4129 | fpr=0.8554 | 7881.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=5.06939 | acc=0.1490 | tpr=0.4110 | fpr=0.8557 | 8194.8 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.07059 | acc=0.1490 | tpr=0.4127 | fpr=0.8558 | 14337.3 samples/s | 56.0 steps/s
Avg test loss: 5.07251, Avg test acc: 0.14891, Avg tpr: 0.41204, Avg fpr: 0.85587, total FA: 118836

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15772 | acc=0.9820 | tpr=0.9513 | fpr=0.0174 | 4233.9 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.16570 | acc=0.9817 | tpr=0.9638 | fpr=0.0180 | 8107.2 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.17089 | acc=0.9811 | tpr=0.9669 | fpr=0.0186 | 7808.7 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.17465 | acc=0.9812 | tpr=0.9672 | fpr=0.0186 | 8042.9 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.17085 | acc=0.9812 | tpr=0.9651 | fpr=0.0185 | 7999.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.17356 | acc=0.9809 | tpr=0.9622 | fpr=0.0187 | 8129.2 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.17393 | acc=0.9810 | tpr=0.9637 | fpr=0.0187 | 8155.4 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.17488 | acc=0.9808 | tpr=0.9606 | fpr=0.0188 | 7840.1 samples/s | 30.6 steps/s
[Step= 450] | Loss=0.17823 | acc=0.9806 | tpr=0.9586 | fpr=0.0190 | 7726.7 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.17690 | acc=0.9807 | tpr=0.9599 | fpr=0.0189 | 7979.7 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.17554 | acc=0.9809 | tpr=0.9586 | fpr=0.0187 | 14943.1 samples/s | 58.4 steps/s
Avg test loss: 0.17519, Avg test acc: 0.98096, Avg tpr: 0.95840, Avg fpr: 0.01863, total FA: 2587

server round 19/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=38001 Epoch=37.1] | Loss=0.02913 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.162 | L2-Norm(final)=10.239 | 4678.6 samples/s | 73.1 steps/s
[Step=38050 Epoch=37.1] | Loss=0.03084 | Reg=0.00230 | acc=0.9375 | L2-Norm=15.165 | L2-Norm(final)=10.239 | 4755.8 samples/s | 74.3 steps/s
[Step=38100 Epoch=37.2] | Loss=0.02835 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=10.240 | 5602.0 samples/s | 87.5 steps/s
[Step=38150 Epoch=37.2] | Loss=0.02757 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.165 | L2-Norm(final)=10.243 | 5524.8 samples/s | 86.3 steps/s
[Step=38200 Epoch=37.3] | Loss=0.02559 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=10.248 | 5583.2 samples/s | 87.2 steps/s
[Step=38250 Epoch=37.3] | Loss=0.02638 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=10.254 | 5591.9 samples/s | 87.4 steps/s
[Step=38300 Epoch=37.4] | Loss=0.02638 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.166 | L2-Norm(final)=10.260 | 5623.8 samples/s | 87.9 steps/s
[Step=38350 Epoch=37.4] | Loss=0.02599 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.166 | L2-Norm(final)=10.267 | 5639.0 samples/s | 88.1 steps/s
[Step=38400 Epoch=37.5] | Loss=0.02544 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.166 | L2-Norm(final)=10.273 | 5643.5 samples/s | 88.2 steps/s
[Step=38450 Epoch=37.5] | Loss=0.02515 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.166 | L2-Norm(final)=10.280 | 5570.7 samples/s | 87.0 steps/s
[Step=38500 Epoch=37.6] | Loss=0.02524 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.166 | L2-Norm(final)=10.287 | 5643.8 samples/s | 88.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=37.6] | Loss=0.00910 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=10.354 | 4171.1 samples/s | 65.2 steps/s
[Step=38550 Epoch=37.6] | Loss=0.01854 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=10.359 | 4603.3 samples/s | 71.9 steps/s
[Step=38600 Epoch=37.7] | Loss=0.01968 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.239 | L2-Norm(final)=10.359 | 4828.9 samples/s | 75.5 steps/s
[Step=38650 Epoch=37.7] | Loss=0.01930 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=10.359 | 4800.7 samples/s | 75.0 steps/s
[Step=38700 Epoch=37.8] | Loss=0.01951 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=10.358 | 4834.1 samples/s | 75.5 steps/s
[Step=38750 Epoch=37.8] | Loss=0.01836 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.297 | L2-Norm(final)=10.358 | 4827.9 samples/s | 75.4 steps/s
[Step=38800 Epoch=37.9] | Loss=0.01825 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.312 | L2-Norm(final)=10.358 | 4813.1 samples/s | 75.2 steps/s
[Step=38850 Epoch=37.9] | Loss=0.01802 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.327 | L2-Norm(final)=10.357 | 4814.7 samples/s | 75.2 steps/s
[Step=38900 Epoch=38.0] | Loss=0.01813 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=10.356 | 4882.5 samples/s | 76.3 steps/s
[Step=38950 Epoch=38.0] | Loss=0.01835 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.354 | L2-Norm(final)=10.355 | 4844.0 samples/s | 75.7 steps/s
[Step=39000 Epoch=38.1] | Loss=0.01837 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.366 | L2-Norm(final)=10.353 | 4852.9 samples/s | 75.8 steps/s
[Step=39050 Epoch=38.1] | Loss=0.01811 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=10.352 | 4874.5 samples/s | 76.2 steps/s
[Step=39100 Epoch=38.2] | Loss=0.01823 | Reg=0.00237 | acc=0.9219 | L2-Norm=15.387 | L2-Norm(final)=10.350 | 4777.4 samples/s | 74.6 steps/s
[Step=39150 Epoch=38.2] | Loss=0.01830 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.397 | L2-Norm(final)=10.349 | 4956.3 samples/s | 77.4 steps/s
[Step=39200 Epoch=38.3] | Loss=0.01843 | Reg=0.00237 | acc=0.9219 | L2-Norm=15.407 | L2-Norm(final)=10.348 | 4758.9 samples/s | 74.4 steps/s
[Step=39250 Epoch=38.3] | Loss=0.01833 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=10.346 | 4852.9 samples/s | 75.8 steps/s
[Step=39300 Epoch=38.4] | Loss=0.01832 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.426 | L2-Norm(final)=10.345 | 4846.8 samples/s | 75.7 steps/s
[Step=39350 Epoch=38.4] | Loss=0.01793 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=10.344 | 4861.8 samples/s | 76.0 steps/s
[Step=39400 Epoch=38.5] | Loss=0.01803 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.444 | L2-Norm(final)=10.343 | 4849.9 samples/s | 75.8 steps/s
[Step=39450 Epoch=38.5] | Loss=0.01787 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.453 | L2-Norm(final)=10.342 | 4881.3 samples/s | 76.3 steps/s
[Step=39500 Epoch=38.6] | Loss=0.01791 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.461 | L2-Norm(final)=10.342 | 5198.3 samples/s | 81.2 steps/s
[Step=39550 Epoch=38.6] | Loss=0.01784 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.469 | L2-Norm(final)=10.341 | 2124.9 samples/s | 33.2 steps/s
[Step=39600 Epoch=38.7] | Loss=0.01757 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.477 | L2-Norm(final)=10.340 | 4869.4 samples/s | 76.1 steps/s
[Step=39650 Epoch=38.7] | Loss=0.01740 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.484 | L2-Norm(final)=10.340 | 4733.2 samples/s | 74.0 steps/s
[Step=39700 Epoch=38.8] | Loss=0.01710 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.491 | L2-Norm(final)=10.339 | 4862.8 samples/s | 76.0 steps/s
[Step=39750 Epoch=38.8] | Loss=0.01693 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.498 | L2-Norm(final)=10.339 | 4814.8 samples/s | 75.2 steps/s
[Step=39800 Epoch=38.9] | Loss=0.01674 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=10.339 | 4888.1 samples/s | 76.4 steps/s
[Step=39850 Epoch=38.9] | Loss=0.01652 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=10.339 | 4859.9 samples/s | 75.9 steps/s
[Step=39900 Epoch=39.0] | Loss=0.01638 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.518 | L2-Norm(final)=10.339 | 4836.9 samples/s | 75.6 steps/s
[Step=39950 Epoch=39.0] | Loss=0.01643 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=10.339 | 4862.6 samples/s | 76.0 steps/s
[Step=40000 Epoch=39.1] | Loss=0.01626 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.531 | L2-Norm(final)=10.339 | 4882.7 samples/s | 76.3 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step40000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=38001 Epoch=71.6] | Loss=0.00146 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=13.794 | 4394.4 samples/s | 68.7 steps/s
[Step=38050 Epoch=71.7] | Loss=0.00054 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.795 | 4554.4 samples/s | 71.2 steps/s
[Step=38100 Epoch=71.8] | Loss=0.00060 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.796 | 5399.4 samples/s | 84.4 steps/s
[Step=38150 Epoch=71.9] | Loss=0.00072 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.798 | 5203.1 samples/s | 81.3 steps/s
[Step=38200 Epoch=72.0] | Loss=0.00081 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.801 | 5472.9 samples/s | 85.5 steps/s
[Step=38250 Epoch=72.1] | Loss=0.00072 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.804 | 5155.7 samples/s | 80.6 steps/s
[Step=38300 Epoch=72.2] | Loss=0.00065 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.807 | 5300.2 samples/s | 82.8 steps/s
[Step=38350 Epoch=72.3] | Loss=0.00058 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.810 | 5403.8 samples/s | 84.4 steps/s
[Step=38400 Epoch=72.4] | Loss=0.00065 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.813 | 5288.1 samples/s | 82.6 steps/s
[Step=38450 Epoch=72.5] | Loss=0.00061 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.815 | 5269.6 samples/s | 82.3 steps/s
[Step=38500 Epoch=72.6] | Loss=0.00059 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.818 | 5400.5 samples/s | 84.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=72.6] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.845 | 3984.2 samples/s | 62.3 steps/s
[Step=38550 Epoch=72.7] | Loss=0.00153 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=13.844 | 4536.7 samples/s | 70.9 steps/s
[Step=38600 Epoch=72.8] | Loss=0.00346 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=13.842 | 4662.5 samples/s | 72.9 steps/s
[Step=38650 Epoch=72.9] | Loss=0.00289 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=13.837 | 4571.6 samples/s | 71.4 steps/s
[Step=38700 Epoch=73.0] | Loss=0.00279 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=13.835 | 4602.3 samples/s | 71.9 steps/s
[Step=38750 Epoch=73.0] | Loss=0.00301 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=13.834 | 4675.7 samples/s | 73.1 steps/s
[Step=38800 Epoch=73.1] | Loss=0.00343 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=13.830 | 4570.6 samples/s | 71.4 steps/s
[Step=38850 Epoch=73.2] | Loss=0.00299 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=13.825 | 4665.6 samples/s | 72.9 steps/s
[Step=38900 Epoch=73.3] | Loss=0.00307 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.336 | L2-Norm(final)=13.821 | 4616.9 samples/s | 72.1 steps/s
[Step=38950 Epoch=73.4] | Loss=0.00279 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=13.819 | 4599.7 samples/s | 71.9 steps/s
[Step=39000 Epoch=73.5] | Loss=0.00255 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=13.817 | 4701.5 samples/s | 73.5 steps/s
[Step=39050 Epoch=73.6] | Loss=0.00240 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=13.815 | 2129.8 samples/s | 33.3 steps/s
[Step=39100 Epoch=73.7] | Loss=0.00220 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.365 | L2-Norm(final)=13.814 | 4669.3 samples/s | 73.0 steps/s
[Step=39150 Epoch=73.8] | Loss=0.00203 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=13.812 | 4640.0 samples/s | 72.5 steps/s
[Step=39200 Epoch=73.9] | Loss=0.00189 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=13.811 | 4624.0 samples/s | 72.3 steps/s
[Step=39250 Epoch=74.0] | Loss=0.00177 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=13.811 | 4639.7 samples/s | 72.5 steps/s
[Step=39300 Epoch=74.1] | Loss=0.00166 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=13.810 | 4589.8 samples/s | 71.7 steps/s
[Step=39350 Epoch=74.2] | Loss=0.00156 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=13.809 | 4633.4 samples/s | 72.4 steps/s
[Step=39400 Epoch=74.3] | Loss=0.00148 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=13.809 | 4538.1 samples/s | 70.9 steps/s
[Step=39450 Epoch=74.4] | Loss=0.00140 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=13.809 | 4612.6 samples/s | 72.1 steps/s
[Step=39500 Epoch=74.5] | Loss=0.00133 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=13.809 | 4675.3 samples/s | 73.1 steps/s
[Step=39550 Epoch=74.6] | Loss=0.00127 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=13.809 | 5670.3 samples/s | 88.6 steps/s
[Step=39600 Epoch=74.6] | Loss=0.00121 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=13.809 | 1950.0 samples/s | 30.5 steps/s
[Step=39650 Epoch=74.7] | Loss=0.00116 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=13.809 | 4562.8 samples/s | 71.3 steps/s
[Step=39700 Epoch=74.8] | Loss=0.00111 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=13.809 | 4647.2 samples/s | 72.6 steps/s
[Step=39750 Epoch=74.9] | Loss=0.00107 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=13.809 | 4562.2 samples/s | 71.3 steps/s
[Step=39800 Epoch=75.0] | Loss=0.00103 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.340 | L2-Norm(final)=13.809 | 4657.3 samples/s | 72.8 steps/s
[Step=39850 Epoch=75.1] | Loss=0.00099 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=13.809 | 4512.1 samples/s | 70.5 steps/s
[Step=39900 Epoch=75.2] | Loss=0.00095 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=13.810 | 4653.4 samples/s | 72.7 steps/s
[Step=39950 Epoch=75.3] | Loss=0.00092 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=13.810 | 4539.2 samples/s | 70.9 steps/s
[Step=40000 Epoch=75.4] | Loss=0.00089 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=13.810 | 4605.4 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06352 | acc=0.9693 | tpr=0.9690 | fpr=0.0300 | 4168.4 samples/s | 16.3 steps/s
Avg test loss: 0.06598, Avg test acc: 0.96771, Avg tpr: 0.96736, Avg fpr: 0.03153, total FA: 246

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.35352 | acc=0.3039 | tpr=0.0056 | fpr=0.0483 | 4262.6 samples/s | 16.7 steps/s
Avg test loss: 10.32864, Avg test acc: 0.30131, Avg tpr: 0.00589, Avg fpr: 0.04897, total FA: 382

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.25350 | acc=0.1570 | tpr=0.3407 | fpr=0.8463 | 4186.6 samples/s | 16.4 steps/s
[Step= 100] | Loss=5.23613 | acc=0.1577 | tpr=0.3156 | fpr=0.8453 | 8156.0 samples/s | 31.9 steps/s
[Step= 150] | Loss=5.22557 | acc=0.1595 | tpr=0.3300 | fpr=0.8437 | 7867.8 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.21266 | acc=0.1593 | tpr=0.3191 | fpr=0.8436 | 8010.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.20746 | acc=0.1593 | tpr=0.3074 | fpr=0.8434 | 7886.3 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.21022 | acc=0.1595 | tpr=0.3120 | fpr=0.8432 | 8225.8 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.20628 | acc=0.1595 | tpr=0.3118 | fpr=0.8433 | 7976.2 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.20796 | acc=0.1594 | tpr=0.3069 | fpr=0.8433 | 8079.4 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.21439 | acc=0.1588 | tpr=0.3096 | fpr=0.8440 | 7858.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=5.20918 | acc=0.1585 | tpr=0.3097 | fpr=0.8442 | 7957.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.20884 | acc=0.1588 | tpr=0.3136 | fpr=0.8440 | 14610.4 samples/s | 57.1 steps/s
Avg test loss: 5.21079, Avg test acc: 0.15865, Avg tpr: 0.31300, Avg fpr: 0.84416, total FA: 117210

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13064 | acc=0.9810 | tpr=0.9558 | fpr=0.0185 | 4200.1 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.13631 | acc=0.9805 | tpr=0.9659 | fpr=0.0192 | 8019.1 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.14141 | acc=0.9797 | tpr=0.9669 | fpr=0.0200 | 7952.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.14362 | acc=0.9799 | tpr=0.9650 | fpr=0.0198 | 8092.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.14124 | acc=0.9802 | tpr=0.9624 | fpr=0.0195 | 8037.3 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.14320 | acc=0.9798 | tpr=0.9615 | fpr=0.0198 | 7823.8 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.14409 | acc=0.9798 | tpr=0.9624 | fpr=0.0199 | 8042.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.14527 | acc=0.9797 | tpr=0.9606 | fpr=0.0200 | 8035.0 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.14782 | acc=0.9795 | tpr=0.9606 | fpr=0.0202 | 7957.2 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.14757 | acc=0.9794 | tpr=0.9604 | fpr=0.0202 | 8298.8 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.14650 | acc=0.9796 | tpr=0.9594 | fpr=0.0200 | 14019.1 samples/s | 54.8 steps/s
Avg test loss: 0.14619, Avg test acc: 0.97960, Avg tpr: 0.95880, Avg fpr: 0.02002, total FA: 2780

server round 20/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=40001 Epoch=39.1] | Loss=0.02419 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.236 | L2-Norm(final)=10.333 | 4112.4 samples/s | 64.3 steps/s
[Step=40050 Epoch=39.1] | Loss=0.02654 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.236 | L2-Norm(final)=10.335 | 5683.6 samples/s | 88.8 steps/s
[Step=40100 Epoch=39.2] | Loss=0.02549 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=10.338 | 5614.7 samples/s | 87.7 steps/s
[Step=40150 Epoch=39.2] | Loss=0.02489 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=10.341 | 5427.8 samples/s | 84.8 steps/s
[Step=40200 Epoch=39.2] | Loss=0.02500 | Reg=0.00232 | acc=0.9375 | L2-Norm=15.236 | L2-Norm(final)=10.344 | 5651.5 samples/s | 88.3 steps/s
[Step=40250 Epoch=39.3] | Loss=0.02578 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.236 | L2-Norm(final)=10.347 | 5660.4 samples/s | 88.4 steps/s
[Step=40300 Epoch=39.3] | Loss=0.02559 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.236 | L2-Norm(final)=10.349 | 5535.5 samples/s | 86.5 steps/s
[Step=40350 Epoch=39.4] | Loss=0.02545 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=10.351 | 5675.5 samples/s | 88.7 steps/s
[Step=40400 Epoch=39.4] | Loss=0.02599 | Reg=0.00232 | acc=0.9375 | L2-Norm=15.236 | L2-Norm(final)=10.353 | 5587.7 samples/s | 87.3 steps/s
[Step=40450 Epoch=39.5] | Loss=0.02574 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.236 | L2-Norm(final)=10.355 | 5646.9 samples/s | 88.2 steps/s
[Step=40500 Epoch=39.5] | Loss=0.02623 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.236 | L2-Norm(final)=10.357 | 5557.1 samples/s | 86.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=39.5] | Loss=0.00928 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=10.378 | 4509.5 samples/s | 70.5 steps/s
[Step=40550 Epoch=39.6] | Loss=0.01955 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.247 | L2-Norm(final)=10.378 | 4115.7 samples/s | 64.3 steps/s
[Step=40600 Epoch=39.6] | Loss=0.01713 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.256 | L2-Norm(final)=10.381 | 4832.1 samples/s | 75.5 steps/s
[Step=40650 Epoch=39.7] | Loss=0.01573 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.263 | L2-Norm(final)=10.382 | 4837.2 samples/s | 75.6 steps/s
[Step=40700 Epoch=39.7] | Loss=0.01459 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=10.383 | 4862.9 samples/s | 76.0 steps/s
[Step=40750 Epoch=39.8] | Loss=0.01392 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.272 | L2-Norm(final)=10.385 | 4787.7 samples/s | 74.8 steps/s
[Step=40800 Epoch=39.8] | Loss=0.01392 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.275 | L2-Norm(final)=10.386 | 4902.6 samples/s | 76.6 steps/s
[Step=40850 Epoch=39.9] | Loss=0.01398 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.278 | L2-Norm(final)=10.386 | 4833.2 samples/s | 75.5 steps/s
[Step=40900 Epoch=39.9] | Loss=0.01372 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.281 | L2-Norm(final)=10.386 | 4833.4 samples/s | 75.5 steps/s
[Step=40950 Epoch=40.0] | Loss=0.01355 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=10.387 | 4864.9 samples/s | 76.0 steps/s
[Step=41000 Epoch=40.0] | Loss=0.01343 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.285 | L2-Norm(final)=10.387 | 4853.6 samples/s | 75.8 steps/s
[Step=41050 Epoch=40.1] | Loss=0.01334 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.287 | L2-Norm(final)=10.387 | 4926.4 samples/s | 77.0 steps/s
[Step=41100 Epoch=40.1] | Loss=0.01336 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=10.388 | 4782.6 samples/s | 74.7 steps/s
[Step=41150 Epoch=40.2] | Loss=0.01321 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.291 | L2-Norm(final)=10.388 | 4918.1 samples/s | 76.8 steps/s
[Step=41200 Epoch=40.2] | Loss=0.01299 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=10.388 | 4859.8 samples/s | 75.9 steps/s
[Step=41250 Epoch=40.3] | Loss=0.01294 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=10.389 | 4812.3 samples/s | 75.2 steps/s
[Step=41300 Epoch=40.3] | Loss=0.01263 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=10.389 | 4849.2 samples/s | 75.8 steps/s
[Step=41350 Epoch=40.4] | Loss=0.01259 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.298 | L2-Norm(final)=10.390 | 4893.2 samples/s | 76.5 steps/s
[Step=41400 Epoch=40.4] | Loss=0.01259 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.299 | L2-Norm(final)=10.390 | 4772.7 samples/s | 74.6 steps/s
[Step=41450 Epoch=40.5] | Loss=0.01246 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.301 | L2-Norm(final)=10.390 | 4872.8 samples/s | 76.1 steps/s
[Step=41500 Epoch=40.5] | Loss=0.01238 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.302 | L2-Norm(final)=10.391 | 5248.0 samples/s | 82.0 steps/s
[Step=41550 Epoch=40.6] | Loss=0.01245 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.303 | L2-Norm(final)=10.391 | 2096.4 samples/s | 32.8 steps/s
[Step=41600 Epoch=40.6] | Loss=0.01218 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.305 | L2-Norm(final)=10.391 | 4663.7 samples/s | 72.9 steps/s
[Step=41650 Epoch=40.7] | Loss=0.01217 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.306 | L2-Norm(final)=10.392 | 4825.0 samples/s | 75.4 steps/s
[Step=41700 Epoch=40.7] | Loss=0.01206 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.307 | L2-Norm(final)=10.392 | 4833.8 samples/s | 75.5 steps/s
[Step=41750 Epoch=40.8] | Loss=0.01202 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.308 | L2-Norm(final)=10.392 | 4810.8 samples/s | 75.2 steps/s
[Step=41800 Epoch=40.8] | Loss=0.01184 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=10.393 | 4854.7 samples/s | 75.9 steps/s
[Step=41850 Epoch=40.9] | Loss=0.01174 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.311 | L2-Norm(final)=10.394 | 4811.0 samples/s | 75.2 steps/s
[Step=41900 Epoch=40.9] | Loss=0.01165 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.312 | L2-Norm(final)=10.394 | 4878.7 samples/s | 76.2 steps/s
[Step=41950 Epoch=41.0] | Loss=0.01166 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.313 | L2-Norm(final)=10.395 | 4824.5 samples/s | 75.4 steps/s
[Step=42000 Epoch=41.0] | Loss=0.01168 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=10.395 | 4854.7 samples/s | 75.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step42000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=40001 Epoch=75.4] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=13.815 | 4442.7 samples/s | 69.4 steps/s
[Step=40050 Epoch=75.5] | Loss=0.00070 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.235 | L2-Norm(final)=13.817 | 4722.6 samples/s | 73.8 steps/s
[Step=40100 Epoch=75.6] | Loss=0.00048 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.235 | L2-Norm(final)=13.820 | 5300.1 samples/s | 82.8 steps/s
[Step=40150 Epoch=75.7] | Loss=0.00038 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.823 | 5302.0 samples/s | 82.8 steps/s
[Step=40200 Epoch=75.8] | Loss=0.00032 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.825 | 5281.8 samples/s | 82.5 steps/s
[Step=40250 Epoch=75.9] | Loss=0.00036 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.827 | 5424.9 samples/s | 84.8 steps/s
[Step=40300 Epoch=76.0] | Loss=0.00035 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.829 | 5217.7 samples/s | 81.5 steps/s
[Step=40350 Epoch=76.1] | Loss=0.00036 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.831 | 5273.4 samples/s | 82.4 steps/s
[Step=40400 Epoch=76.2] | Loss=0.00036 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.234 | L2-Norm(final)=13.834 | 5342.0 samples/s | 83.5 steps/s
[Step=40450 Epoch=76.2] | Loss=0.00033 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.836 | 5389.3 samples/s | 84.2 steps/s
[Step=40500 Epoch=76.3] | Loss=0.00035 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.838 | 5447.4 samples/s | 85.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=76.3] | Loss=0.00005 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=13.860 | 4073.3 samples/s | 63.6 steps/s
[Step=40550 Epoch=76.4] | Loss=0.00038 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=13.864 | 4448.4 samples/s | 69.5 steps/s
[Step=40600 Epoch=76.5] | Loss=0.00025 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=13.865 | 4613.2 samples/s | 72.1 steps/s
[Step=40650 Epoch=76.6] | Loss=0.00019 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.215 | L2-Norm(final)=13.866 | 4540.6 samples/s | 70.9 steps/s
[Step=40700 Epoch=76.7] | Loss=0.00015 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=13.867 | 4619.2 samples/s | 72.2 steps/s
[Step=40750 Epoch=76.8] | Loss=0.00012 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=13.868 | 4589.7 samples/s | 71.7 steps/s
[Step=40800 Epoch=76.9] | Loss=0.00010 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=13.869 | 4580.6 samples/s | 71.6 steps/s
[Step=40850 Epoch=77.0] | Loss=0.00009 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.191 | L2-Norm(final)=13.869 | 4629.4 samples/s | 72.3 steps/s
[Step=40900 Epoch=77.1] | Loss=0.00008 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=13.870 | 4619.0 samples/s | 72.2 steps/s
[Step=40950 Epoch=77.2] | Loss=0.00007 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=13.871 | 4689.3 samples/s | 73.3 steps/s
[Step=41000 Epoch=77.3] | Loss=0.00007 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=13.871 | 4610.9 samples/s | 72.0 steps/s
[Step=41050 Epoch=77.4] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=13.872 | 2156.5 samples/s | 33.7 steps/s
[Step=41100 Epoch=77.5] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.872 | 4636.9 samples/s | 72.5 steps/s
[Step=41150 Epoch=77.6] | Loss=0.00005 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=13.873 | 4584.7 samples/s | 71.6 steps/s
[Step=41200 Epoch=77.7] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.146 | L2-Norm(final)=13.873 | 4609.8 samples/s | 72.0 steps/s
[Step=41250 Epoch=77.8] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=13.874 | 4617.8 samples/s | 72.2 steps/s
[Step=41300 Epoch=77.9] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=13.874 | 4633.0 samples/s | 72.4 steps/s
[Step=41350 Epoch=77.9] | Loss=0.00004 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=13.874 | 4589.4 samples/s | 71.7 steps/s
[Step=41400 Epoch=78.0] | Loss=0.00004 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=13.875 | 4649.6 samples/s | 72.6 steps/s
[Step=41450 Epoch=78.1] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=13.875 | 4648.2 samples/s | 72.6 steps/s
[Step=41500 Epoch=78.2] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.105 | L2-Norm(final)=13.875 | 4659.3 samples/s | 72.8 steps/s
[Step=41550 Epoch=78.3] | Loss=0.00004 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=13.876 | 5671.0 samples/s | 88.6 steps/s
[Step=41600 Epoch=78.4] | Loss=0.00003 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=13.876 | 1967.3 samples/s | 30.7 steps/s
[Step=41650 Epoch=78.5] | Loss=0.00003 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=13.876 | 4630.0 samples/s | 72.3 steps/s
[Step=41700 Epoch=78.6] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.077 | L2-Norm(final)=13.877 | 4605.5 samples/s | 72.0 steps/s
[Step=41750 Epoch=78.7] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.069 | L2-Norm(final)=13.877 | 4555.2 samples/s | 71.2 steps/s
[Step=41800 Epoch=78.8] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=13.877 | 4603.7 samples/s | 71.9 steps/s
[Step=41850 Epoch=78.9] | Loss=0.00003 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.055 | L2-Norm(final)=13.877 | 4623.2 samples/s | 72.2 steps/s
[Step=41900 Epoch=79.0] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=13.878 | 4605.1 samples/s | 72.0 steps/s
[Step=41950 Epoch=79.1] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.040 | L2-Norm(final)=13.878 | 4588.9 samples/s | 71.7 steps/s
[Step=42000 Epoch=79.2] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=13.878 | 4599.7 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06429 | acc=0.9709 | tpr=0.9758 | fpr=0.0396 | 4283.4 samples/s | 16.7 steps/s
Avg test loss: 0.06269, Avg test acc: 0.97127, Avg tpr: 0.97610, Avg fpr: 0.03935, total FA: 307

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.42424 | acc=0.2808 | tpr=0.0097 | fpr=0.1306 | 4165.6 samples/s | 16.3 steps/s
Avg test loss: 9.40653, Avg test acc: 0.27771, Avg tpr: 0.00985, Avg fpr: 0.13319, total FA: 1039

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.78596 | acc=0.1316 | tpr=0.3540 | fpr=0.8724 | 4205.1 samples/s | 16.4 steps/s
[Step= 100] | Loss=5.77599 | acc=0.1320 | tpr=0.3369 | fpr=0.8718 | 7959.6 samples/s | 31.1 steps/s
[Step= 150] | Loss=5.76681 | acc=0.1325 | tpr=0.3458 | fpr=0.8715 | 7988.8 samples/s | 31.2 steps/s
[Step= 200] | Loss=5.75629 | acc=0.1323 | tpr=0.3432 | fpr=0.8716 | 7508.6 samples/s | 29.3 steps/s
[Step= 250] | Loss=5.75686 | acc=0.1322 | tpr=0.3362 | fpr=0.8716 | 8223.9 samples/s | 32.1 steps/s
[Step= 300] | Loss=5.76023 | acc=0.1324 | tpr=0.3404 | fpr=0.8714 | 7926.4 samples/s | 31.0 steps/s
[Step= 350] | Loss=5.75530 | acc=0.1323 | tpr=0.3425 | fpr=0.8715 | 7833.1 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.75591 | acc=0.1322 | tpr=0.3425 | fpr=0.8717 | 8037.8 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.76150 | acc=0.1317 | tpr=0.3457 | fpr=0.8721 | 8028.4 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.75690 | acc=0.1316 | tpr=0.3467 | fpr=0.8723 | 7537.8 samples/s | 29.4 steps/s
[Step= 550] | Loss=5.75613 | acc=0.1319 | tpr=0.3502 | fpr=0.8721 | 11087.6 samples/s | 43.3 steps/s
Avg test loss: 5.75760, Avg test acc: 0.13177, Avg tpr: 0.34984, Avg fpr: 0.87220, total FA: 121103

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13331 | acc=0.9823 | tpr=0.9558 | fpr=0.0173 | 4185.0 samples/s | 16.3 steps/s
[Step= 100] | Loss=0.13775 | acc=0.9817 | tpr=0.9638 | fpr=0.0179 | 8119.1 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.14168 | acc=0.9815 | tpr=0.9654 | fpr=0.0182 | 7944.6 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.14377 | acc=0.9816 | tpr=0.9650 | fpr=0.0181 | 8969.2 samples/s | 35.0 steps/s
[Step= 250] | Loss=0.14142 | acc=0.9817 | tpr=0.9616 | fpr=0.0180 | 7289.5 samples/s | 28.5 steps/s
[Step= 300] | Loss=0.14365 | acc=0.9814 | tpr=0.9593 | fpr=0.0182 | 8026.5 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.14349 | acc=0.9811 | tpr=0.9593 | fpr=0.0185 | 7974.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.14463 | acc=0.9809 | tpr=0.9573 | fpr=0.0186 | 8489.9 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.14680 | acc=0.9808 | tpr=0.9567 | fpr=0.0188 | 7665.9 samples/s | 29.9 steps/s
[Step= 500] | Loss=0.14629 | acc=0.9808 | tpr=0.9568 | fpr=0.0188 | 5758.0 samples/s | 22.5 steps/s
[Step= 550] | Loss=0.14530 | acc=0.9809 | tpr=0.9562 | fpr=0.0186 | 15222.1 samples/s | 59.5 steps/s
Avg test loss: 0.14513, Avg test acc: 0.98094, Avg tpr: 0.95602, Avg fpr: 0.01860, total FA: 2583

server round 21/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=42001 Epoch=41.0] | Loss=0.01008 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.407 | 3972.4 samples/s | 62.1 steps/s
[Step=42050 Epoch=41.1] | Loss=0.01141 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.411 | 5454.9 samples/s | 85.2 steps/s
[Step=42100 Epoch=41.1] | Loss=0.01343 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.036 | L2-Norm(final)=10.414 | 5549.3 samples/s | 86.7 steps/s
[Step=42150 Epoch=41.2] | Loss=0.01336 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.036 | L2-Norm(final)=10.418 | 5558.4 samples/s | 86.8 steps/s
[Step=42200 Epoch=41.2] | Loss=0.01339 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.421 | 5727.4 samples/s | 89.5 steps/s
[Step=42250 Epoch=41.3] | Loss=0.01314 | Reg=0.00226 | acc=0.9375 | L2-Norm=15.036 | L2-Norm(final)=10.424 | 5422.2 samples/s | 84.7 steps/s
[Step=42300 Epoch=41.3] | Loss=0.01325 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.428 | 5637.8 samples/s | 88.1 steps/s
[Step=42350 Epoch=41.3] | Loss=0.01340 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.036 | L2-Norm(final)=10.432 | 5685.6 samples/s | 88.8 steps/s
[Step=42400 Epoch=41.4] | Loss=0.01301 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.436 | 5501.8 samples/s | 86.0 steps/s
[Step=42450 Epoch=41.4] | Loss=0.01310 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.440 | 5732.6 samples/s | 89.6 steps/s
[Step=42500 Epoch=41.5] | Loss=0.01323 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.443 | 5441.0 samples/s | 85.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=41.5] | Loss=0.01241 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=10.480 | 4109.8 samples/s | 64.2 steps/s
[Step=42550 Epoch=41.5] | Loss=0.01070 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.046 | L2-Norm(final)=10.483 | 4739.5 samples/s | 74.1 steps/s
[Step=42600 Epoch=41.6] | Loss=0.01018 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.053 | L2-Norm(final)=10.485 | 4807.2 samples/s | 75.1 steps/s
[Step=42650 Epoch=41.6] | Loss=0.01114 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.059 | L2-Norm(final)=10.486 | 4805.4 samples/s | 75.1 steps/s
[Step=42700 Epoch=41.7] | Loss=0.01077 | Reg=0.00227 | acc=0.9531 | L2-Norm=15.065 | L2-Norm(final)=10.488 | 4700.5 samples/s | 73.4 steps/s
[Step=42750 Epoch=41.7] | Loss=0.01050 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.069 | L2-Norm(final)=10.489 | 4718.8 samples/s | 73.7 steps/s
[Step=42800 Epoch=41.8] | Loss=0.01051 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.073 | L2-Norm(final)=10.490 | 4852.3 samples/s | 75.8 steps/s
[Step=42850 Epoch=41.8] | Loss=0.01048 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.077 | L2-Norm(final)=10.490 | 4850.5 samples/s | 75.8 steps/s
[Step=42900 Epoch=41.9] | Loss=0.01063 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.080 | L2-Norm(final)=10.491 | 4867.7 samples/s | 76.1 steps/s
[Step=42950 Epoch=41.9] | Loss=0.01082 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.083 | L2-Norm(final)=10.491 | 4823.7 samples/s | 75.4 steps/s
[Step=43000 Epoch=42.0] | Loss=0.01062 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=10.491 | 4892.3 samples/s | 76.4 steps/s
[Step=43050 Epoch=42.0] | Loss=0.01060 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.088 | L2-Norm(final)=10.492 | 4853.5 samples/s | 75.8 steps/s
[Step=43100 Epoch=42.1] | Loss=0.01077 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=10.492 | 4846.7 samples/s | 75.7 steps/s
[Step=43150 Epoch=42.1] | Loss=0.01079 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.094 | L2-Norm(final)=10.492 | 4872.7 samples/s | 76.1 steps/s
[Step=43200 Epoch=42.2] | Loss=0.01094 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=10.492 | 4871.0 samples/s | 76.1 steps/s
[Step=43250 Epoch=42.2] | Loss=0.01107 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.099 | L2-Norm(final)=10.492 | 4875.7 samples/s | 76.2 steps/s
[Step=43300 Epoch=42.3] | Loss=0.01105 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=10.492 | 4815.1 samples/s | 75.2 steps/s
[Step=43350 Epoch=42.3] | Loss=0.01102 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.104 | L2-Norm(final)=10.492 | 4825.2 samples/s | 75.4 steps/s
[Step=43400 Epoch=42.4] | Loss=0.01109 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.107 | L2-Norm(final)=10.493 | 4876.0 samples/s | 76.2 steps/s
[Step=43450 Epoch=42.4] | Loss=0.01101 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.109 | L2-Norm(final)=10.493 | 4859.8 samples/s | 75.9 steps/s
[Step=43500 Epoch=42.5] | Loss=0.01090 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=10.493 | 5159.6 samples/s | 80.6 steps/s
[Step=43550 Epoch=42.5] | Loss=0.01096 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.114 | L2-Norm(final)=10.494 | 2146.0 samples/s | 33.5 steps/s
[Step=43600 Epoch=42.6] | Loss=0.01085 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=10.495 | 4830.1 samples/s | 75.5 steps/s
[Step=43650 Epoch=42.6] | Loss=0.01084 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.119 | L2-Norm(final)=10.495 | 4803.9 samples/s | 75.1 steps/s
[Step=43700 Epoch=42.7] | Loss=0.01085 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.121 | L2-Norm(final)=10.496 | 4793.8 samples/s | 74.9 steps/s
[Step=43750 Epoch=42.7] | Loss=0.01083 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.123 | L2-Norm(final)=10.497 | 4824.9 samples/s | 75.4 steps/s
[Step=43800 Epoch=42.8] | Loss=0.01079 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=10.497 | 4914.3 samples/s | 76.8 steps/s
[Step=43850 Epoch=42.8] | Loss=0.01071 | Reg=0.00229 | acc=0.9688 | L2-Norm=15.127 | L2-Norm(final)=10.498 | 4818.5 samples/s | 75.3 steps/s
[Step=43900 Epoch=42.9] | Loss=0.01065 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.129 | L2-Norm(final)=10.499 | 4809.5 samples/s | 75.1 steps/s
[Step=43950 Epoch=42.9] | Loss=0.01055 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=10.500 | 4708.4 samples/s | 73.6 steps/s
[Step=44000 Epoch=43.0] | Loss=0.01061 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=10.500 | 4869.3 samples/s | 76.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step44000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=42001 Epoch=79.2] | Loss=0.00002 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=13.886 | 4090.8 samples/s | 63.9 steps/s
[Step=42050 Epoch=79.3] | Loss=0.00029 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.889 | 4583.4 samples/s | 71.6 steps/s
[Step=42100 Epoch=79.4] | Loss=0.00020 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.893 | 5327.4 samples/s | 83.2 steps/s
[Step=42150 Epoch=79.5] | Loss=0.00029 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.897 | 5351.7 samples/s | 83.6 steps/s
[Step=42200 Epoch=79.5] | Loss=0.00025 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.900 | 5154.5 samples/s | 80.5 steps/s
[Step=42250 Epoch=79.6] | Loss=0.00029 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.903 | 5326.5 samples/s | 83.2 steps/s
[Step=42300 Epoch=79.7] | Loss=0.00036 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.906 | 5281.5 samples/s | 82.5 steps/s
[Step=42350 Epoch=79.8] | Loss=0.00038 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.909 | 5284.2 samples/s | 82.6 steps/s
[Step=42400 Epoch=79.9] | Loss=0.00037 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.913 | 5278.8 samples/s | 82.5 steps/s
[Step=42450 Epoch=80.0] | Loss=0.00036 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.916 | 5294.2 samples/s | 82.7 steps/s
[Step=42500 Epoch=80.1] | Loss=0.00034 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.919 | 5388.8 samples/s | 84.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=80.1] | Loss=0.00001 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=13.950 | 4174.9 samples/s | 65.2 steps/s
[Step=42550 Epoch=80.2] | Loss=0.00014 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=13.952 | 4386.9 samples/s | 68.5 steps/s
[Step=42600 Epoch=80.3] | Loss=0.00009 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=13.954 | 4598.6 samples/s | 71.9 steps/s
[Step=42650 Epoch=80.4] | Loss=0.00007 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=13.955 | 4608.5 samples/s | 72.0 steps/s
[Step=42700 Epoch=80.5] | Loss=0.00006 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=13.956 | 4609.8 samples/s | 72.0 steps/s
[Step=42750 Epoch=80.6] | Loss=0.00005 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=13.957 | 4626.3 samples/s | 72.3 steps/s
[Step=42800 Epoch=80.7] | Loss=0.00004 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=13.958 | 4603.4 samples/s | 71.9 steps/s
[Step=42850 Epoch=80.8] | Loss=0.00004 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=13.959 | 4591.0 samples/s | 71.7 steps/s
[Step=42900 Epoch=80.9] | Loss=0.00003 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=13.959 | 4567.9 samples/s | 71.4 steps/s
[Step=42950 Epoch=81.0] | Loss=0.00003 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=13.960 | 4624.9 samples/s | 72.3 steps/s
[Step=43000 Epoch=81.1] | Loss=0.00003 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.934 | L2-Norm(final)=13.960 | 4653.9 samples/s | 72.7 steps/s
[Step=43050 Epoch=81.1] | Loss=0.00003 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.922 | L2-Norm(final)=13.961 | 2013.0 samples/s | 31.5 steps/s
[Step=43100 Epoch=81.2] | Loss=0.00003 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.911 | L2-Norm(final)=13.961 | 4395.7 samples/s | 68.7 steps/s
[Step=43150 Epoch=81.3] | Loss=0.00002 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.899 | L2-Norm(final)=13.962 | 4448.5 samples/s | 69.5 steps/s
[Step=43200 Epoch=81.4] | Loss=0.00002 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=13.962 | 4591.0 samples/s | 71.7 steps/s
[Step=43250 Epoch=81.5] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.875 | L2-Norm(final)=13.962 | 4563.4 samples/s | 71.3 steps/s
[Step=43300 Epoch=81.6] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.862 | L2-Norm(final)=13.963 | 4656.0 samples/s | 72.8 steps/s
[Step=43350 Epoch=81.7] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.850 | L2-Norm(final)=13.963 | 4572.4 samples/s | 71.4 steps/s
[Step=43400 Epoch=81.8] | Loss=0.00002 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=13.964 | 4629.9 samples/s | 72.3 steps/s
[Step=43450 Epoch=81.9] | Loss=0.00002 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=13.964 | 4633.8 samples/s | 72.4 steps/s
[Step=43500 Epoch=82.0] | Loss=0.00002 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.812 | L2-Norm(final)=13.964 | 4593.9 samples/s | 71.8 steps/s
[Step=43550 Epoch=82.1] | Loss=0.00002 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.799 | L2-Norm(final)=13.964 | 5754.6 samples/s | 89.9 steps/s
[Step=43600 Epoch=82.2] | Loss=0.00002 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=13.965 | 1931.4 samples/s | 30.2 steps/s
[Step=43650 Epoch=82.3] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=13.965 | 4579.2 samples/s | 71.6 steps/s
[Step=43700 Epoch=82.4] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.759 | L2-Norm(final)=13.965 | 4619.7 samples/s | 72.2 steps/s
[Step=43750 Epoch=82.5] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=13.966 | 4636.5 samples/s | 72.4 steps/s
[Step=43800 Epoch=82.6] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=13.966 | 4645.6 samples/s | 72.6 steps/s
[Step=43850 Epoch=82.7] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=13.966 | 4540.5 samples/s | 70.9 steps/s
[Step=43900 Epoch=82.8] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=13.966 | 4600.2 samples/s | 71.9 steps/s
[Step=43950 Epoch=82.8] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=13.967 | 4573.7 samples/s | 71.5 steps/s
[Step=44000 Epoch=82.9] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=13.967 | 4648.7 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06392 | acc=0.9705 | tpr=0.9744 | fpr=0.0379 | 4172.2 samples/s | 16.3 steps/s
Avg test loss: 0.06404, Avg test acc: 0.97031, Avg tpr: 0.97418, Avg fpr: 0.03820, total FA: 298

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.95287 | acc=0.2893 | tpr=0.0104 | fpr=0.1051 | 4232.3 samples/s | 16.5 steps/s
Avg test loss: 8.93505, Avg test acc: 0.28728, Avg tpr: 0.01107, Avg fpr: 0.10524, total FA: 821

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.62096 | acc=0.1416 | tpr=0.3805 | fpr=0.8627 | 4180.6 samples/s | 16.3 steps/s
[Step= 100] | Loss=5.60973 | acc=0.1426 | tpr=0.3561 | fpr=0.8614 | 8229.7 samples/s | 32.1 steps/s
[Step= 150] | Loss=5.59171 | acc=0.1435 | tpr=0.3674 | fpr=0.8606 | 7958.4 samples/s | 31.1 steps/s
[Step= 200] | Loss=5.58244 | acc=0.1430 | tpr=0.3639 | fpr=0.8610 | 7901.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=5.58214 | acc=0.1425 | tpr=0.3563 | fpr=0.8614 | 8092.6 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.58443 | acc=0.1428 | tpr=0.3651 | fpr=0.8612 | 8149.8 samples/s | 31.8 steps/s
[Step= 350] | Loss=5.58051 | acc=0.1427 | tpr=0.3632 | fpr=0.8613 | 5122.9 samples/s | 20.0 steps/s
[Step= 400] | Loss=5.58203 | acc=0.1428 | tpr=0.3632 | fpr=0.8612 | 8028.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.58586 | acc=0.1425 | tpr=0.3676 | fpr=0.8616 | 7969.9 samples/s | 31.1 steps/s
[Step= 500] | Loss=5.58169 | acc=0.1423 | tpr=0.3648 | fpr=0.8618 | 7828.8 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.58001 | acc=0.1423 | tpr=0.3681 | fpr=0.8618 | 13436.4 samples/s | 52.5 steps/s
Avg test loss: 5.58152, Avg test acc: 0.14217, Avg tpr: 0.36727, Avg fpr: 0.86192, total FA: 119676

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14597 | acc=0.9816 | tpr=0.9690 | fpr=0.0182 | 4221.9 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.15147 | acc=0.9812 | tpr=0.9701 | fpr=0.0186 | 7983.1 samples/s | 31.2 steps/s
[Step= 150] | Loss=0.15664 | acc=0.9805 | tpr=0.9697 | fpr=0.0193 | 8062.0 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.15963 | acc=0.9805 | tpr=0.9672 | fpr=0.0193 | 8006.5 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.15705 | acc=0.9806 | tpr=0.9642 | fpr=0.0191 | 7856.1 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.15893 | acc=0.9803 | tpr=0.9629 | fpr=0.0194 | 7943.5 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.15852 | acc=0.9802 | tpr=0.9637 | fpr=0.0195 | 5544.6 samples/s | 21.7 steps/s
[Step= 400] | Loss=0.15985 | acc=0.9800 | tpr=0.9623 | fpr=0.0197 | 8111.8 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.16243 | acc=0.9798 | tpr=0.9615 | fpr=0.0199 | 7859.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.16189 | acc=0.9798 | tpr=0.9617 | fpr=0.0199 | 6745.6 samples/s | 26.3 steps/s
[Step= 550] | Loss=0.16076 | acc=0.9799 | tpr=0.9606 | fpr=0.0197 | 15244.0 samples/s | 59.5 steps/s
Avg test loss: 0.16056, Avg test acc: 0.97993, Avg tpr: 0.96038, Avg fpr: 0.01972, total FA: 2738

server round 22/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=44001 Epoch=43.0] | Loss=0.01247 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.674 | L2-Norm(final)=10.519 | 4336.6 samples/s | 67.8 steps/s
[Step=44050 Epoch=43.0] | Loss=0.01018 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.520 | 4995.1 samples/s | 78.0 steps/s
[Step=44100 Epoch=43.1] | Loss=0.01045 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.522 | 5569.4 samples/s | 87.0 steps/s
[Step=44150 Epoch=43.1] | Loss=0.01029 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.524 | 5545.8 samples/s | 86.7 steps/s
[Step=44200 Epoch=43.2] | Loss=0.00978 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.527 | 5604.3 samples/s | 87.6 steps/s
[Step=44250 Epoch=43.2] | Loss=0.00951 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.674 | L2-Norm(final)=10.531 | 5523.5 samples/s | 86.3 steps/s
[Step=44300 Epoch=43.3] | Loss=0.00958 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.534 | 5600.4 samples/s | 87.5 steps/s
[Step=44350 Epoch=43.3] | Loss=0.00959 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.538 | 5593.6 samples/s | 87.4 steps/s
[Step=44400 Epoch=43.3] | Loss=0.00970 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.674 | L2-Norm(final)=10.542 | 5593.8 samples/s | 87.4 steps/s
[Step=44450 Epoch=43.4] | Loss=0.00986 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.546 | 5617.0 samples/s | 87.8 steps/s
[Step=44500 Epoch=43.4] | Loss=0.00978 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=10.549 | 5587.9 samples/s | 87.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=43.4] | Loss=0.01693 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.674 | L2-Norm(final)=10.586 | 4007.9 samples/s | 62.6 steps/s
[Step=44550 Epoch=43.5] | Loss=0.00853 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=10.590 | 4797.0 samples/s | 75.0 steps/s
[Step=44600 Epoch=43.5] | Loss=0.01023 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.697 | L2-Norm(final)=10.591 | 4812.8 samples/s | 75.2 steps/s
[Step=44650 Epoch=43.6] | Loss=0.01023 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.704 | L2-Norm(final)=10.591 | 4841.0 samples/s | 75.6 steps/s
[Step=44700 Epoch=43.6] | Loss=0.01028 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.710 | L2-Norm(final)=10.591 | 4859.6 samples/s | 75.9 steps/s
[Step=44750 Epoch=43.7] | Loss=0.01068 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=10.591 | 4859.1 samples/s | 75.9 steps/s
[Step=44800 Epoch=43.7] | Loss=0.01054 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=10.591 | 4889.9 samples/s | 76.4 steps/s
[Step=44850 Epoch=43.8] | Loss=0.01030 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.725 | L2-Norm(final)=10.592 | 4796.7 samples/s | 74.9 steps/s
[Step=44900 Epoch=43.8] | Loss=0.01028 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.729 | L2-Norm(final)=10.593 | 4848.6 samples/s | 75.8 steps/s
[Step=44950 Epoch=43.9] | Loss=0.01039 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.733 | L2-Norm(final)=10.593 | 4884.6 samples/s | 76.3 steps/s
[Step=45000 Epoch=43.9] | Loss=0.01043 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.737 | L2-Norm(final)=10.594 | 4765.3 samples/s | 74.5 steps/s
[Step=45050 Epoch=44.0] | Loss=0.01065 | Reg=0.00217 | acc=0.9375 | L2-Norm=14.741 | L2-Norm(final)=10.594 | 4808.7 samples/s | 75.1 steps/s
[Step=45100 Epoch=44.0] | Loss=0.01071 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.744 | L2-Norm(final)=10.594 | 4871.2 samples/s | 76.1 steps/s
[Step=45150 Epoch=44.1] | Loss=0.01091 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=10.595 | 4856.6 samples/s | 75.9 steps/s
[Step=45200 Epoch=44.1] | Loss=0.01096 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.751 | L2-Norm(final)=10.595 | 4838.4 samples/s | 75.6 steps/s
[Step=45250 Epoch=44.2] | Loss=0.01090 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.754 | L2-Norm(final)=10.596 | 4840.1 samples/s | 75.6 steps/s
[Step=45300 Epoch=44.2] | Loss=0.01078 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.758 | L2-Norm(final)=10.596 | 4888.3 samples/s | 76.4 steps/s
[Step=45350 Epoch=44.3] | Loss=0.01075 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.761 | L2-Norm(final)=10.597 | 4822.7 samples/s | 75.4 steps/s
[Step=45400 Epoch=44.3] | Loss=0.01084 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.764 | L2-Norm(final)=10.598 | 4850.3 samples/s | 75.8 steps/s
[Step=45450 Epoch=44.4] | Loss=0.01075 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=10.599 | 4872.1 samples/s | 76.1 steps/s
[Step=45500 Epoch=44.4] | Loss=0.01083 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.771 | L2-Norm(final)=10.600 | 5187.8 samples/s | 81.1 steps/s
[Step=45550 Epoch=44.5] | Loss=0.01086 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.774 | L2-Norm(final)=10.601 | 2099.3 samples/s | 32.8 steps/s
[Step=45600 Epoch=44.5] | Loss=0.01068 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.777 | L2-Norm(final)=10.601 | 4835.7 samples/s | 75.6 steps/s
[Step=45650 Epoch=44.6] | Loss=0.01068 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=10.602 | 4766.3 samples/s | 74.5 steps/s
[Step=45700 Epoch=44.6] | Loss=0.01060 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.782 | L2-Norm(final)=10.603 | 4827.1 samples/s | 75.4 steps/s
[Step=45750 Epoch=44.7] | Loss=0.01049 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=10.604 | 4837.4 samples/s | 75.6 steps/s
[Step=45800 Epoch=44.7] | Loss=0.01041 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.787 | L2-Norm(final)=10.604 | 4838.8 samples/s | 75.6 steps/s
[Step=45850 Epoch=44.8] | Loss=0.01044 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.790 | L2-Norm(final)=10.605 | 4826.7 samples/s | 75.4 steps/s
[Step=45900 Epoch=44.8] | Loss=0.01044 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.793 | L2-Norm(final)=10.606 | 4888.7 samples/s | 76.4 steps/s
[Step=45950 Epoch=44.9] | Loss=0.01038 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.795 | L2-Norm(final)=10.607 | 4808.2 samples/s | 75.1 steps/s
[Step=46000 Epoch=44.9] | Loss=0.01033 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.797 | L2-Norm(final)=10.608 | 4859.8 samples/s | 75.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step46000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=44001 Epoch=82.9] | Loss=0.00008 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=13.974 | 3723.5 samples/s | 58.2 steps/s
[Step=44050 Epoch=83.0] | Loss=0.00029 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=13.980 | 5185.3 samples/s | 81.0 steps/s
[Step=44100 Epoch=83.1] | Loss=0.00034 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=13.987 | 5255.1 samples/s | 82.1 steps/s
[Step=44150 Epoch=83.2] | Loss=0.00024 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=13.991 | 5337.0 samples/s | 83.4 steps/s
[Step=44200 Epoch=83.3] | Loss=0.00021 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=13.994 | 5256.8 samples/s | 82.1 steps/s
[Step=44250 Epoch=83.4] | Loss=0.00022 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=13.998 | 5308.1 samples/s | 82.9 steps/s
[Step=44300 Epoch=83.5] | Loss=0.00019 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.001 | 5369.4 samples/s | 83.9 steps/s
[Step=44350 Epoch=83.6] | Loss=0.00017 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.004 | 5158.1 samples/s | 80.6 steps/s
[Step=44400 Epoch=83.7] | Loss=0.00018 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.008 | 5312.3 samples/s | 83.0 steps/s
[Step=44450 Epoch=83.8] | Loss=0.00020 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.011 | 5442.3 samples/s | 85.0 steps/s
[Step=44500 Epoch=83.9] | Loss=0.00021 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.015 | 5284.9 samples/s | 82.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=83.9] | Loss=0.00002 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=14.056 | 3865.1 samples/s | 60.4 steps/s
[Step=44550 Epoch=84.0] | Loss=0.00003 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=14.057 | 4340.2 samples/s | 67.8 steps/s
[Step=44600 Epoch=84.1] | Loss=0.00009 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=14.058 | 4454.7 samples/s | 69.6 steps/s
[Step=44650 Epoch=84.2] | Loss=0.00084 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=14.057 | 4610.0 samples/s | 72.0 steps/s
[Step=44700 Epoch=84.3] | Loss=0.00139 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=14.054 | 4659.4 samples/s | 72.8 steps/s
[Step=44750 Epoch=84.4] | Loss=0.00134 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=14.049 | 4583.8 samples/s | 71.6 steps/s
[Step=44800 Epoch=84.4] | Loss=0.00120 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=14.046 | 4572.3 samples/s | 71.4 steps/s
[Step=44850 Epoch=84.5] | Loss=0.00105 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=14.044 | 4602.2 samples/s | 71.9 steps/s
[Step=44900 Epoch=84.6] | Loss=0.00092 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=14.042 | 4658.5 samples/s | 72.8 steps/s
[Step=44950 Epoch=84.7] | Loss=0.00082 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=14.041 | 4618.8 samples/s | 72.2 steps/s
[Step=45000 Epoch=84.8] | Loss=0.00074 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=14.041 | 4659.9 samples/s | 72.8 steps/s
[Step=45050 Epoch=84.9] | Loss=0.00069 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=14.040 | 2148.6 samples/s | 33.6 steps/s
[Step=45100 Epoch=85.0] | Loss=0.00064 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=14.040 | 4657.9 samples/s | 72.8 steps/s
[Step=45150 Epoch=85.1] | Loss=0.00059 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=14.039 | 4576.8 samples/s | 71.5 steps/s
[Step=45200 Epoch=85.2] | Loss=0.00055 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=14.039 | 4630.5 samples/s | 72.4 steps/s
[Step=45250 Epoch=85.3] | Loss=0.00051 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=14.039 | 4571.1 samples/s | 71.4 steps/s
[Step=45300 Epoch=85.4] | Loss=0.00048 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=14.039 | 4614.6 samples/s | 72.1 steps/s
[Step=45350 Epoch=85.5] | Loss=0.00045 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=14.039 | 4609.4 samples/s | 72.0 steps/s
[Step=45400 Epoch=85.6] | Loss=0.00043 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=14.039 | 4646.2 samples/s | 72.6 steps/s
[Step=45450 Epoch=85.7] | Loss=0.00041 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=14.039 | 4530.9 samples/s | 70.8 steps/s
[Step=45500 Epoch=85.8] | Loss=0.00039 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=14.040 | 4635.7 samples/s | 72.4 steps/s
[Step=45550 Epoch=85.9] | Loss=0.00037 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=14.040 | 5581.7 samples/s | 87.2 steps/s
[Step=45600 Epoch=86.0] | Loss=0.00036 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=14.040 | 1813.2 samples/s | 28.3 steps/s
[Step=45650 Epoch=86.1] | Loss=0.00034 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=14.041 | 4396.2 samples/s | 68.7 steps/s
[Step=45700 Epoch=86.1] | Loss=0.00033 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.635 | L2-Norm(final)=14.041 | 4278.4 samples/s | 66.9 steps/s
[Step=45750 Epoch=86.2] | Loss=0.00031 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=14.041 | 4351.1 samples/s | 68.0 steps/s
[Step=45800 Epoch=86.3] | Loss=0.00030 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=14.042 | 4557.0 samples/s | 71.2 steps/s
[Step=45850 Epoch=86.4] | Loss=0.00029 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=14.042 | 4639.6 samples/s | 72.5 steps/s
[Step=45900 Epoch=86.5] | Loss=0.00028 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=14.042 | 4649.5 samples/s | 72.6 steps/s
[Step=45950 Epoch=86.6] | Loss=0.00027 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=14.042 | 4587.2 samples/s | 71.7 steps/s
[Step=46000 Epoch=86.7] | Loss=0.00026 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=14.043 | 4604.9 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06951 | acc=0.9720 | tpr=0.9792 | fpr=0.0436 | 4095.2 samples/s | 16.0 steps/s
Avg test loss: 0.07050, Avg test acc: 0.97143, Avg tpr: 0.97867, Avg fpr: 0.04448, total FA: 347

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.88932 | acc=0.2992 | tpr=0.0098 | fpr=0.0723 | 4169.3 samples/s | 16.3 steps/s
Avg test loss: 10.85185, Avg test acc: 0.29618, Avg tpr: 0.01003, Avg fpr: 0.07448, total FA: 581

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.74182 | acc=0.1278 | tpr=0.3850 | fpr=0.8768 | 4303.1 samples/s | 16.8 steps/s
[Step= 100] | Loss=6.73101 | acc=0.1284 | tpr=0.3603 | fpr=0.8759 | 7783.0 samples/s | 30.4 steps/s
[Step= 150] | Loss=6.71444 | acc=0.1286 | tpr=0.3660 | fpr=0.8757 | 5227.8 samples/s | 20.4 steps/s
[Step= 200] | Loss=6.70596 | acc=0.1282 | tpr=0.3661 | fpr=0.8761 | 7290.4 samples/s | 28.5 steps/s
[Step= 250] | Loss=6.70343 | acc=0.1280 | tpr=0.3581 | fpr=0.8762 | 8014.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.70333 | acc=0.1283 | tpr=0.3636 | fpr=0.8760 | 8030.6 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.69916 | acc=0.1282 | tpr=0.3638 | fpr=0.8761 | 8140.4 samples/s | 31.8 steps/s
[Step= 400] | Loss=6.70099 | acc=0.1281 | tpr=0.3638 | fpr=0.8762 | 7789.8 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.70729 | acc=0.1276 | tpr=0.3695 | fpr=0.8768 | 8248.1 samples/s | 32.2 steps/s
[Step= 500] | Loss=6.70393 | acc=0.1272 | tpr=0.3656 | fpr=0.8771 | 7755.5 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.70092 | acc=0.1273 | tpr=0.3701 | fpr=0.8771 | 14007.9 samples/s | 54.7 steps/s
Avg test loss: 6.70264, Avg test acc: 0.12725, Avg tpr: 0.37005, Avg fpr: 0.87717, total FA: 121793

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16193 | acc=0.9820 | tpr=0.9558 | fpr=0.0176 | 4203.0 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.16991 | acc=0.9814 | tpr=0.9616 | fpr=0.0182 | 7979.0 samples/s | 31.2 steps/s
[Step= 150] | Loss=0.17648 | acc=0.9808 | tpr=0.9625 | fpr=0.0188 | 4984.2 samples/s | 19.5 steps/s
[Step= 200] | Loss=0.18169 | acc=0.9806 | tpr=0.9617 | fpr=0.0191 | 7856.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.17871 | acc=0.9807 | tpr=0.9590 | fpr=0.0189 | 8170.3 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.18128 | acc=0.9805 | tpr=0.9571 | fpr=0.0191 | 7828.5 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.18190 | acc=0.9805 | tpr=0.9580 | fpr=0.0191 | 8392.8 samples/s | 32.8 steps/s
[Step= 400] | Loss=0.18345 | acc=0.9803 | tpr=0.9546 | fpr=0.0192 | 7584.2 samples/s | 29.6 steps/s
[Step= 450] | Loss=0.18669 | acc=0.9800 | tpr=0.9542 | fpr=0.0195 | 7802.1 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.18554 | acc=0.9801 | tpr=0.9546 | fpr=0.0194 | 8014.1 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.18439 | acc=0.9803 | tpr=0.9538 | fpr=0.0192 | 14692.8 samples/s | 57.4 steps/s
Avg test loss: 0.18401, Avg test acc: 0.98034, Avg tpr: 0.95365, Avg fpr: 0.01918, total FA: 2663

server round 23/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=46001 Epoch=44.9] | Loss=0.00294 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.594 | L2-Norm(final)=10.636 | 4232.2 samples/s | 66.1 steps/s
[Step=46050 Epoch=45.0] | Loss=0.01426 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.641 | 5292.1 samples/s | 82.7 steps/s
[Step=46100 Epoch=45.0] | Loss=0.01491 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.595 | L2-Norm(final)=10.644 | 5509.9 samples/s | 86.1 steps/s
[Step=46150 Epoch=45.1] | Loss=0.01399 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.595 | L2-Norm(final)=10.647 | 5575.3 samples/s | 87.1 steps/s
[Step=46200 Epoch=45.1] | Loss=0.01384 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.651 | 5632.6 samples/s | 88.0 steps/s
[Step=46250 Epoch=45.2] | Loss=0.01339 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.655 | 5701.9 samples/s | 89.1 steps/s
[Step=46300 Epoch=45.2] | Loss=0.01371 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.595 | L2-Norm(final)=10.658 | 5498.0 samples/s | 85.9 steps/s
[Step=46350 Epoch=45.3] | Loss=0.01382 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.661 | 5535.6 samples/s | 86.5 steps/s
[Step=46400 Epoch=45.3] | Loss=0.01359 | Reg=0.00213 | acc=0.9531 | L2-Norm=14.595 | L2-Norm(final)=10.663 | 5546.7 samples/s | 86.7 steps/s
[Step=46450 Epoch=45.4] | Loss=0.01363 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.666 | 5645.9 samples/s | 88.2 steps/s
[Step=46500 Epoch=45.4] | Loss=0.01359 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=10.669 | 5627.2 samples/s | 87.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=45.4] | Loss=0.01478 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.595 | L2-Norm(final)=10.697 | 4126.1 samples/s | 64.5 steps/s
[Step=46550 Epoch=45.4] | Loss=0.01226 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.615 | L2-Norm(final)=10.698 | 4698.6 samples/s | 73.4 steps/s
[Step=46600 Epoch=45.5] | Loss=0.01171 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.630 | L2-Norm(final)=10.697 | 4756.8 samples/s | 74.3 steps/s
[Step=46650 Epoch=45.5] | Loss=0.01251 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=10.696 | 4869.0 samples/s | 76.1 steps/s
[Step=46700 Epoch=45.6] | Loss=0.01265 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=10.694 | 4793.5 samples/s | 74.9 steps/s
[Step=46750 Epoch=45.6] | Loss=0.01256 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.651 | L2-Norm(final)=10.693 | 4825.8 samples/s | 75.4 steps/s
[Step=46800 Epoch=45.7] | Loss=0.01267 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=10.692 | 4864.5 samples/s | 76.0 steps/s
[Step=46850 Epoch=45.7] | Loss=0.01245 | Reg=0.00215 | acc=0.9531 | L2-Norm=14.662 | L2-Norm(final)=10.691 | 4817.5 samples/s | 75.3 steps/s
[Step=46900 Epoch=45.8] | Loss=0.01226 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=10.691 | 4782.1 samples/s | 74.7 steps/s
[Step=46950 Epoch=45.8] | Loss=0.01244 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.671 | L2-Norm(final)=10.691 | 4777.4 samples/s | 74.6 steps/s
[Step=47000 Epoch=45.9] | Loss=0.01219 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=10.690 | 4866.5 samples/s | 76.0 steps/s
[Step=47050 Epoch=45.9] | Loss=0.01189 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.679 | L2-Norm(final)=10.691 | 4836.6 samples/s | 75.6 steps/s
[Step=47100 Epoch=46.0] | Loss=0.01184 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=10.691 | 4844.4 samples/s | 75.7 steps/s
[Step=47150 Epoch=46.0] | Loss=0.01163 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=10.692 | 4847.4 samples/s | 75.7 steps/s
[Step=47200 Epoch=46.1] | Loss=0.01147 | Reg=0.00216 | acc=0.9531 | L2-Norm=14.689 | L2-Norm(final)=10.693 | 4905.8 samples/s | 76.7 steps/s
[Step=47250 Epoch=46.1] | Loss=0.01142 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=10.693 | 4829.0 samples/s | 75.5 steps/s
[Step=47300 Epoch=46.2] | Loss=0.01148 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=10.694 | 4861.5 samples/s | 76.0 steps/s
[Step=47350 Epoch=46.2] | Loss=0.01136 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.698 | L2-Norm(final)=10.694 | 4866.1 samples/s | 76.0 steps/s
[Step=47400 Epoch=46.3] | Loss=0.01138 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.701 | L2-Norm(final)=10.694 | 4790.5 samples/s | 74.9 steps/s
[Step=47450 Epoch=46.3] | Loss=0.01145 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.704 | L2-Norm(final)=10.694 | 4807.3 samples/s | 75.1 steps/s
[Step=47500 Epoch=46.4] | Loss=0.01143 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=10.695 | 5201.4 samples/s | 81.3 steps/s
[Step=47550 Epoch=46.4] | Loss=0.01130 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=10.695 | 2094.6 samples/s | 32.7 steps/s
[Step=47600 Epoch=46.5] | Loss=0.01113 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=10.696 | 4819.0 samples/s | 75.3 steps/s
[Step=47650 Epoch=46.5] | Loss=0.01096 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=10.697 | 4864.2 samples/s | 76.0 steps/s
[Step=47700 Epoch=46.6] | Loss=0.01094 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=10.697 | 4805.8 samples/s | 75.1 steps/s
[Step=47750 Epoch=46.6] | Loss=0.01091 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.718 | L2-Norm(final)=10.698 | 4880.3 samples/s | 76.3 steps/s
[Step=47800 Epoch=46.7] | Loss=0.01087 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=10.699 | 4821.1 samples/s | 75.3 steps/s
[Step=47850 Epoch=46.7] | Loss=0.01081 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=10.699 | 4849.8 samples/s | 75.8 steps/s
[Step=47900 Epoch=46.8] | Loss=0.01071 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.726 | L2-Norm(final)=10.700 | 4879.3 samples/s | 76.2 steps/s
[Step=47950 Epoch=46.8] | Loss=0.01073 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.728 | L2-Norm(final)=10.701 | 4872.3 samples/s | 76.1 steps/s
[Step=48000 Epoch=46.9] | Loss=0.01072 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.730 | L2-Norm(final)=10.702 | 4857.2 samples/s | 75.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step48000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=46001 Epoch=86.7] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.594 | L2-Norm(final)=14.050 | 4126.5 samples/s | 64.5 steps/s
[Step=46050 Epoch=86.8] | Loss=0.00003 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.051 | 4802.8 samples/s | 75.0 steps/s
[Step=46100 Epoch=86.9] | Loss=0.00011 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.052 | 5198.1 samples/s | 81.2 steps/s
[Step=46150 Epoch=87.0] | Loss=0.00011 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.053 | 5326.1 samples/s | 83.2 steps/s
[Step=46200 Epoch=87.1] | Loss=0.00008 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.054 | 5210.5 samples/s | 81.4 steps/s
[Step=46250 Epoch=87.2] | Loss=0.00008 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.055 | 5236.3 samples/s | 81.8 steps/s
[Step=46300 Epoch=87.3] | Loss=0.00007 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.056 | 5369.4 samples/s | 83.9 steps/s
[Step=46350 Epoch=87.4] | Loss=0.00006 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.057 | 5351.0 samples/s | 83.6 steps/s
[Step=46400 Epoch=87.5] | Loss=0.00006 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.058 | 5248.0 samples/s | 82.0 steps/s
[Step=46450 Epoch=87.6] | Loss=0.00006 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.059 | 5190.2 samples/s | 81.1 steps/s
[Step=46500 Epoch=87.7] | Loss=0.00007 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.060 | 5303.4 samples/s | 82.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=87.7] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=14.074 | 3932.2 samples/s | 61.4 steps/s
[Step=46550 Epoch=87.7] | Loss=0.00006 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=14.075 | 4505.0 samples/s | 70.4 steps/s
[Step=46600 Epoch=87.8] | Loss=0.00004 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.581 | L2-Norm(final)=14.078 | 4587.3 samples/s | 71.7 steps/s
[Step=46650 Epoch=87.9] | Loss=0.00003 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.574 | L2-Norm(final)=14.080 | 4591.8 samples/s | 71.7 steps/s
[Step=46700 Epoch=88.0] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.565 | L2-Norm(final)=14.081 | 4642.3 samples/s | 72.5 steps/s
[Step=46750 Epoch=88.1] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.556 | L2-Norm(final)=14.081 | 4592.3 samples/s | 71.8 steps/s
[Step=46800 Epoch=88.2] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.547 | L2-Norm(final)=14.082 | 4547.3 samples/s | 71.1 steps/s
[Step=46850 Epoch=88.3] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=14.083 | 4586.1 samples/s | 71.7 steps/s
[Step=46900 Epoch=88.4] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=14.083 | 4606.5 samples/s | 72.0 steps/s
[Step=46950 Epoch=88.5] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=14.084 | 4645.5 samples/s | 72.6 steps/s
[Step=47000 Epoch=88.6] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=14.084 | 4652.6 samples/s | 72.7 steps/s
[Step=47050 Epoch=88.7] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=14.085 | 2139.5 samples/s | 33.4 steps/s
[Step=47100 Epoch=88.8] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=14.085 | 4659.9 samples/s | 72.8 steps/s
[Step=47150 Epoch=88.9] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.485 | L2-Norm(final)=14.086 | 4681.2 samples/s | 73.1 steps/s
[Step=47200 Epoch=89.0] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=14.086 | 4503.7 samples/s | 70.4 steps/s
[Step=47250 Epoch=89.1] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.467 | L2-Norm(final)=14.087 | 4639.0 samples/s | 72.5 steps/s
[Step=47300 Epoch=89.2] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.457 | L2-Norm(final)=14.087 | 4594.4 samples/s | 71.8 steps/s
[Step=47350 Epoch=89.3] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.448 | L2-Norm(final)=14.088 | 4564.1 samples/s | 71.3 steps/s
[Step=47400 Epoch=89.3] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.439 | L2-Norm(final)=14.088 | 4691.6 samples/s | 73.3 steps/s
[Step=47450 Epoch=89.4] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.429 | L2-Norm(final)=14.088 | 4627.8 samples/s | 72.3 steps/s
[Step=47500 Epoch=89.5] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.420 | L2-Norm(final)=14.089 | 4557.2 samples/s | 71.2 steps/s
[Step=47550 Epoch=89.6] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.410 | L2-Norm(final)=14.089 | 5765.7 samples/s | 90.1 steps/s
[Step=47600 Epoch=89.7] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.401 | L2-Norm(final)=14.090 | 1978.1 samples/s | 30.9 steps/s
[Step=47650 Epoch=89.8] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.391 | L2-Norm(final)=14.090 | 4523.4 samples/s | 70.7 steps/s
[Step=47700 Epoch=89.9] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.381 | L2-Norm(final)=14.090 | 4613.9 samples/s | 72.1 steps/s
[Step=47750 Epoch=90.0] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.372 | L2-Norm(final)=14.091 | 4604.8 samples/s | 72.0 steps/s
[Step=47800 Epoch=90.1] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=14.091 | 4646.7 samples/s | 72.6 steps/s
[Step=47850 Epoch=90.2] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.352 | L2-Norm(final)=14.091 | 4708.6 samples/s | 73.6 steps/s
[Step=47900 Epoch=90.3] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.342 | L2-Norm(final)=14.092 | 4508.9 samples/s | 70.5 steps/s
[Step=47950 Epoch=90.4] | Loss=0.00000 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.332 | L2-Norm(final)=14.092 | 4603.6 samples/s | 71.9 steps/s
[Step=48000 Epoch=90.5] | Loss=0.00000 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.322 | L2-Norm(final)=14.093 | 4626.9 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06097 | acc=0.9718 | tpr=0.9760 | fpr=0.0374 | 4167.0 samples/s | 16.3 steps/s
Avg test loss: 0.06234, Avg test acc: 0.97159, Avg tpr: 0.97628, Avg fpr: 0.03871, total FA: 302

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.47503 | acc=0.2865 | tpr=0.0105 | fpr=0.1142 | 4184.1 samples/s | 16.3 steps/s
Avg test loss: 9.45172, Avg test acc: 0.28296, Avg tpr: 0.01102, Avg fpr: 0.11896, total FA: 928

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.21572 | acc=0.1457 | tpr=0.3186 | fpr=0.8574 | 4210.0 samples/s | 16.4 steps/s
[Step= 100] | Loss=5.21482 | acc=0.1454 | tpr=0.2857 | fpr=0.8572 | 8100.3 samples/s | 31.6 steps/s
[Step= 150] | Loss=5.19500 | acc=0.1478 | tpr=0.3026 | fpr=0.8550 | 7938.7 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.18438 | acc=0.1482 | tpr=0.3093 | fpr=0.8547 | 4986.0 samples/s | 19.5 steps/s
[Step= 250] | Loss=5.18535 | acc=0.1477 | tpr=0.3066 | fpr=0.8552 | 8024.3 samples/s | 31.3 steps/s
[Step= 300] | Loss=5.18778 | acc=0.1480 | tpr=0.3149 | fpr=0.8550 | 7890.2 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.18239 | acc=0.1480 | tpr=0.3168 | fpr=0.8550 | 7977.9 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.18473 | acc=0.1478 | tpr=0.3189 | fpr=0.8553 | 8176.4 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.18865 | acc=0.1474 | tpr=0.3228 | fpr=0.8558 | 7718.1 samples/s | 30.1 steps/s
[Step= 500] | Loss=5.18462 | acc=0.1474 | tpr=0.3216 | fpr=0.8557 | 7962.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=5.18395 | acc=0.1475 | tpr=0.3255 | fpr=0.8558 | 14716.8 samples/s | 57.5 steps/s
Avg test loss: 5.18554, Avg test acc: 0.14736, Avg tpr: 0.32488, Avg fpr: 0.85586, total FA: 118835

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15175 | acc=0.9816 | tpr=0.9646 | fpr=0.0181 | 4261.5 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.15720 | acc=0.9816 | tpr=0.9659 | fpr=0.0181 | 7853.4 samples/s | 30.7 steps/s
[Step= 150] | Loss=0.16119 | acc=0.9812 | tpr=0.9669 | fpr=0.0185 | 5321.7 samples/s | 20.8 steps/s
[Step= 200] | Loss=0.16531 | acc=0.9809 | tpr=0.9639 | fpr=0.0188 | 7321.5 samples/s | 28.6 steps/s
[Step= 250] | Loss=0.16302 | acc=0.9811 | tpr=0.9616 | fpr=0.0186 | 7582.9 samples/s | 29.6 steps/s
[Step= 300] | Loss=0.16552 | acc=0.9807 | tpr=0.9593 | fpr=0.0189 | 8251.5 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.16523 | acc=0.9806 | tpr=0.9606 | fpr=0.0190 | 7738.7 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.16646 | acc=0.9805 | tpr=0.9590 | fpr=0.0191 | 8153.8 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.16878 | acc=0.9803 | tpr=0.9596 | fpr=0.0194 | 8033.6 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.16781 | acc=0.9803 | tpr=0.9595 | fpr=0.0193 | 7772.5 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.16683 | acc=0.9804 | tpr=0.9586 | fpr=0.0192 | 14994.1 samples/s | 58.6 steps/s
Avg test loss: 0.16659, Avg test acc: 0.98043, Avg tpr: 0.95840, Avg fpr: 0.01916, total FA: 2661

server round 24/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=48001 Epoch=46.9] | Loss=0.00034 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=10.724 | 4331.8 samples/s | 67.7 steps/s
[Step=48050 Epoch=46.9] | Loss=0.00730 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.363 | L2-Norm(final)=10.728 | 5573.6 samples/s | 87.1 steps/s
[Step=48100 Epoch=47.0] | Loss=0.00762 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.363 | L2-Norm(final)=10.733 | 5507.6 samples/s | 86.1 steps/s
[Step=48150 Epoch=47.0] | Loss=0.00828 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.738 | 5651.8 samples/s | 88.3 steps/s
[Step=48200 Epoch=47.1] | Loss=0.00874 | Reg=0.00206 | acc=0.9688 | L2-Norm=14.363 | L2-Norm(final)=10.743 | 5644.1 samples/s | 88.2 steps/s
[Step=48250 Epoch=47.1] | Loss=0.00896 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.363 | L2-Norm(final)=10.747 | 5574.6 samples/s | 87.1 steps/s
[Step=48300 Epoch=47.2] | Loss=0.00891 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.752 | 5535.0 samples/s | 86.5 steps/s
[Step=48350 Epoch=47.2] | Loss=0.00879 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.756 | 5642.4 samples/s | 88.2 steps/s
[Step=48400 Epoch=47.3] | Loss=0.00875 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.761 | 5642.7 samples/s | 88.2 steps/s
[Step=48450 Epoch=47.3] | Loss=0.00873 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.765 | 5576.4 samples/s | 87.1 steps/s
[Step=48500 Epoch=47.4] | Loss=0.00876 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.770 | 5655.2 samples/s | 88.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=47.4] | Loss=0.00535 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=10.815 | 4160.8 samples/s | 65.0 steps/s
[Step=48550 Epoch=47.4] | Loss=0.00941 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.377 | L2-Norm(final)=10.818 | 4549.5 samples/s | 71.1 steps/s
[Step=48600 Epoch=47.5] | Loss=0.00811 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.387 | L2-Norm(final)=10.819 | 4795.2 samples/s | 74.9 steps/s
[Step=48650 Epoch=47.5] | Loss=0.00913 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.394 | L2-Norm(final)=10.821 | 4858.0 samples/s | 75.9 steps/s
[Step=48700 Epoch=47.5] | Loss=0.00947 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.399 | L2-Norm(final)=10.822 | 4781.1 samples/s | 74.7 steps/s
[Step=48750 Epoch=47.6] | Loss=0.00925 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.404 | L2-Norm(final)=10.822 | 4865.7 samples/s | 76.0 steps/s
[Step=48800 Epoch=47.6] | Loss=0.00944 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.408 | L2-Norm(final)=10.823 | 4860.8 samples/s | 76.0 steps/s
[Step=48850 Epoch=47.7] | Loss=0.00929 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.411 | L2-Norm(final)=10.824 | 4815.6 samples/s | 75.2 steps/s
[Step=48900 Epoch=47.7] | Loss=0.00955 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.415 | L2-Norm(final)=10.825 | 4847.6 samples/s | 75.7 steps/s
[Step=48950 Epoch=47.8] | Loss=0.00956 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.418 | L2-Norm(final)=10.825 | 4806.4 samples/s | 75.1 steps/s
[Step=49000 Epoch=47.8] | Loss=0.00956 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.421 | L2-Norm(final)=10.827 | 4853.2 samples/s | 75.8 steps/s
[Step=49050 Epoch=47.9] | Loss=0.00946 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.425 | L2-Norm(final)=10.828 | 4837.1 samples/s | 75.6 steps/s
[Step=49100 Epoch=47.9] | Loss=0.00964 | Reg=0.00208 | acc=0.9844 | L2-Norm=14.428 | L2-Norm(final)=10.830 | 4895.6 samples/s | 76.5 steps/s
[Step=49150 Epoch=48.0] | Loss=0.00984 | Reg=0.00208 | acc=0.9688 | L2-Norm=14.432 | L2-Norm(final)=10.831 | 4879.2 samples/s | 76.2 steps/s
[Step=49200 Epoch=48.0] | Loss=0.00996 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.435 | L2-Norm(final)=10.832 | 4799.1 samples/s | 75.0 steps/s
[Step=49250 Epoch=48.1] | Loss=0.01004 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.439 | L2-Norm(final)=10.833 | 4883.1 samples/s | 76.3 steps/s
[Step=49300 Epoch=48.1] | Loss=0.01007 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.442 | L2-Norm(final)=10.834 | 4889.8 samples/s | 76.4 steps/s
[Step=49350 Epoch=48.2] | Loss=0.01001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.445 | L2-Norm(final)=10.835 | 4788.6 samples/s | 74.8 steps/s
[Step=49400 Epoch=48.2] | Loss=0.00994 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.448 | L2-Norm(final)=10.836 | 4868.7 samples/s | 76.1 steps/s
[Step=49450 Epoch=48.3] | Loss=0.00982 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.450 | L2-Norm(final)=10.837 | 4864.8 samples/s | 76.0 steps/s
[Step=49500 Epoch=48.3] | Loss=0.00988 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.453 | L2-Norm(final)=10.838 | 5217.1 samples/s | 81.5 steps/s
[Step=49550 Epoch=48.4] | Loss=0.00989 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.456 | L2-Norm(final)=10.840 | 2119.6 samples/s | 33.1 steps/s
[Step=49600 Epoch=48.4] | Loss=0.00973 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.458 | L2-Norm(final)=10.841 | 4875.4 samples/s | 76.2 steps/s
[Step=49650 Epoch=48.5] | Loss=0.00969 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.461 | L2-Norm(final)=10.842 | 4855.1 samples/s | 75.9 steps/s
[Step=49700 Epoch=48.5] | Loss=0.00963 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.463 | L2-Norm(final)=10.843 | 4779.1 samples/s | 74.7 steps/s
[Step=49750 Epoch=48.6] | Loss=0.00963 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.466 | L2-Norm(final)=10.845 | 4887.7 samples/s | 76.4 steps/s
[Step=49800 Epoch=48.6] | Loss=0.00968 | Reg=0.00209 | acc=0.9531 | L2-Norm=14.468 | L2-Norm(final)=10.846 | 4799.3 samples/s | 75.0 steps/s
[Step=49850 Epoch=48.7] | Loss=0.00961 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.471 | L2-Norm(final)=10.847 | 4855.0 samples/s | 75.9 steps/s
[Step=49900 Epoch=48.7] | Loss=0.00955 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.473 | L2-Norm(final)=10.848 | 4855.4 samples/s | 75.9 steps/s
[Step=49950 Epoch=48.8] | Loss=0.00955 | Reg=0.00210 | acc=0.9688 | L2-Norm=14.476 | L2-Norm(final)=10.849 | 4859.8 samples/s | 75.9 steps/s
[Step=50000 Epoch=48.8] | Loss=0.00949 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.478 | L2-Norm(final)=10.851 | 4839.5 samples/s | 75.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step50000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=48001 Epoch=90.5] | Loss=0.00016 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.362 | L2-Norm(final)=14.106 | 4081.1 samples/s | 63.8 steps/s
[Step=48050 Epoch=90.6] | Loss=0.00013 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.359 | L2-Norm(final)=14.108 | 4916.1 samples/s | 76.8 steps/s
[Step=48100 Epoch=90.7] | Loss=0.00015 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.112 | 5242.4 samples/s | 81.9 steps/s
[Step=48150 Epoch=90.8] | Loss=0.00012 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.117 | 5242.9 samples/s | 81.9 steps/s
[Step=48200 Epoch=90.9] | Loss=0.00011 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.122 | 5379.0 samples/s | 84.0 steps/s
[Step=48250 Epoch=91.0] | Loss=0.00010 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.126 | 5202.5 samples/s | 81.3 steps/s
[Step=48300 Epoch=91.0] | Loss=0.00010 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.130 | 5352.2 samples/s | 83.6 steps/s
[Step=48350 Epoch=91.1] | Loss=0.00009 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.135 | 5300.1 samples/s | 82.8 steps/s
[Step=48400 Epoch=91.2] | Loss=0.00009 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.139 | 5352.9 samples/s | 83.6 steps/s
[Step=48450 Epoch=91.3] | Loss=0.00008 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.142 | 5273.0 samples/s | 82.4 steps/s
[Step=48500 Epoch=91.4] | Loss=0.00008 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.146 | 5281.3 samples/s | 82.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=91.4] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.358 | L2-Norm(final)=14.182 | 3929.7 samples/s | 61.4 steps/s
[Step=48550 Epoch=91.5] | Loss=0.00008 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.352 | L2-Norm(final)=14.186 | 4459.1 samples/s | 69.7 steps/s
[Step=48600 Epoch=91.6] | Loss=0.00004 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.341 | L2-Norm(final)=14.188 | 4561.6 samples/s | 71.3 steps/s
[Step=48650 Epoch=91.7] | Loss=0.00003 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.327 | L2-Norm(final)=14.188 | 4663.7 samples/s | 72.9 steps/s
[Step=48700 Epoch=91.8] | Loss=0.00003 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.312 | L2-Norm(final)=14.189 | 4565.1 samples/s | 71.3 steps/s
[Step=48750 Epoch=91.9] | Loss=0.00002 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.297 | L2-Norm(final)=14.189 | 4573.9 samples/s | 71.5 steps/s
[Step=48800 Epoch=92.0] | Loss=0.00002 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.282 | L2-Norm(final)=14.189 | 4667.2 samples/s | 72.9 steps/s
[Step=48850 Epoch=92.1] | Loss=0.00002 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.266 | L2-Norm(final)=14.189 | 4551.7 samples/s | 71.1 steps/s
[Step=48900 Epoch=92.2] | Loss=0.00002 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.250 | L2-Norm(final)=14.189 | 4657.3 samples/s | 72.8 steps/s
[Step=48950 Epoch=92.3] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.233 | L2-Norm(final)=14.190 | 4577.3 samples/s | 71.5 steps/s
[Step=49000 Epoch=92.4] | Loss=0.00001 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.217 | L2-Norm(final)=14.190 | 4659.0 samples/s | 72.8 steps/s
[Step=49050 Epoch=92.5] | Loss=0.00001 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.200 | L2-Norm(final)=14.190 | 2067.5 samples/s | 32.3 steps/s
[Step=49100 Epoch=92.6] | Loss=0.00001 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.183 | L2-Norm(final)=14.191 | 4567.1 samples/s | 71.4 steps/s
[Step=49150 Epoch=92.6] | Loss=0.00001 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.166 | L2-Norm(final)=14.191 | 4490.3 samples/s | 70.2 steps/s
[Step=49200 Epoch=92.7] | Loss=0.00001 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.149 | L2-Norm(final)=14.191 | 4602.4 samples/s | 71.9 steps/s
[Step=49250 Epoch=92.8] | Loss=0.00001 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.132 | L2-Norm(final)=14.192 | 4631.9 samples/s | 72.4 steps/s
[Step=49300 Epoch=92.9] | Loss=0.00001 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.115 | L2-Norm(final)=14.192 | 4601.5 samples/s | 71.9 steps/s
[Step=49350 Epoch=93.0] | Loss=0.00001 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.097 | L2-Norm(final)=14.192 | 4522.1 samples/s | 70.7 steps/s
[Step=49400 Epoch=93.1] | Loss=0.00001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.080 | L2-Norm(final)=14.192 | 4633.8 samples/s | 72.4 steps/s
[Step=49450 Epoch=93.2] | Loss=0.00001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=14.192 | 4660.0 samples/s | 72.8 steps/s
[Step=49500 Epoch=93.3] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.045 | L2-Norm(final)=14.193 | 4617.5 samples/s | 72.1 steps/s
[Step=49550 Epoch=93.4] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.027 | L2-Norm(final)=14.193 | 5678.7 samples/s | 88.7 steps/s
[Step=49600 Epoch=93.5] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.009 | L2-Norm(final)=14.193 | 1986.1 samples/s | 31.0 steps/s
[Step=49650 Epoch=93.6] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.991 | L2-Norm(final)=14.193 | 4523.4 samples/s | 70.7 steps/s
[Step=49700 Epoch=93.7] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.973 | L2-Norm(final)=14.194 | 4654.1 samples/s | 72.7 steps/s
[Step=49750 Epoch=93.8] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=14.194 | 4561.5 samples/s | 71.3 steps/s
[Step=49800 Epoch=93.9] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.936 | L2-Norm(final)=14.194 | 4633.5 samples/s | 72.4 steps/s
[Step=49850 Epoch=94.0] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.917 | L2-Norm(final)=14.194 | 4673.4 samples/s | 73.0 steps/s
[Step=49900 Epoch=94.1] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.898 | L2-Norm(final)=14.195 | 4560.7 samples/s | 71.3 steps/s
[Step=49950 Epoch=94.2] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.879 | L2-Norm(final)=14.195 | 4630.1 samples/s | 72.3 steps/s
[Step=50000 Epoch=94.3] | Loss=0.00000 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.860 | L2-Norm(final)=14.195 | 4602.2 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07266 | acc=0.9718 | tpr=0.9772 | fpr=0.0399 | 3240.5 samples/s | 12.7 steps/s
Avg test loss: 0.07313, Avg test acc: 0.97135, Avg tpr: 0.97663, Avg fpr: 0.04025, total FA: 314

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.16211 | acc=0.2949 | tpr=0.0108 | fpr=0.0882 | 3180.7 samples/s | 12.4 steps/s
Avg test loss: 9.14917, Avg test acc: 0.29245, Avg tpr: 0.01131, Avg fpr: 0.08922, total FA: 696

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.18303 | acc=0.1516 | tpr=0.2699 | fpr=0.8506 | 3157.7 samples/s | 12.3 steps/s
[Step= 100] | Loss=6.17433 | acc=0.1533 | tpr=0.2537 | fpr=0.8486 | 8002.6 samples/s | 31.3 steps/s
[Step= 150] | Loss=6.14965 | acc=0.1544 | tpr=0.2622 | fpr=0.8476 | 7971.4 samples/s | 31.1 steps/s
[Step= 200] | Loss=6.13806 | acc=0.1547 | tpr=0.2656 | fpr=0.8473 | 8104.5 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.13933 | acc=0.1533 | tpr=0.2576 | fpr=0.8486 | 8098.2 samples/s | 31.6 steps/s
[Step= 300] | Loss=6.13937 | acc=0.1535 | tpr=0.2647 | fpr=0.8485 | 7866.8 samples/s | 30.7 steps/s
[Step= 350] | Loss=6.13336 | acc=0.1535 | tpr=0.2630 | fpr=0.8485 | 8062.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.13605 | acc=0.1533 | tpr=0.2670 | fpr=0.8487 | 8133.3 samples/s | 31.8 steps/s
[Step= 450] | Loss=6.13927 | acc=0.1530 | tpr=0.2717 | fpr=0.8491 | 7555.0 samples/s | 29.5 steps/s
[Step= 500] | Loss=6.13504 | acc=0.1529 | tpr=0.2696 | fpr=0.8492 | 8001.4 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.13373 | acc=0.1528 | tpr=0.2730 | fpr=0.8494 | 15071.5 samples/s | 58.9 steps/s
Avg test loss: 6.13585, Avg test acc: 0.15265, Avg tpr: 0.27298, Avg fpr: 0.84954, total FA: 117957

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14824 | acc=0.9817 | tpr=0.9646 | fpr=0.0180 | 4219.2 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.15408 | acc=0.9817 | tpr=0.9638 | fpr=0.0179 | 7932.7 samples/s | 31.0 steps/s
[Step= 150] | Loss=0.15752 | acc=0.9817 | tpr=0.9654 | fpr=0.0180 | 8129.9 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.16130 | acc=0.9815 | tpr=0.9639 | fpr=0.0182 | 8099.8 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.15910 | acc=0.9817 | tpr=0.9624 | fpr=0.0180 | 8131.9 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.16138 | acc=0.9813 | tpr=0.9615 | fpr=0.0183 | 7760.3 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.16079 | acc=0.9812 | tpr=0.9618 | fpr=0.0185 | 8164.0 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.16232 | acc=0.9810 | tpr=0.9601 | fpr=0.0186 | 7806.6 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.16451 | acc=0.9808 | tpr=0.9601 | fpr=0.0188 | 8303.8 samples/s | 32.4 steps/s
[Step= 500] | Loss=0.16369 | acc=0.9809 | tpr=0.9604 | fpr=0.0188 | 7842.5 samples/s | 30.6 steps/s
[Step= 550] | Loss=0.16266 | acc=0.9810 | tpr=0.9594 | fpr=0.0186 | 14455.6 samples/s | 56.5 steps/s
Avg test loss: 0.16246, Avg test acc: 0.98104, Avg tpr: 0.95919, Avg fpr: 0.01857, total FA: 2578

server round 25/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=50001 Epoch=48.8] | Loss=0.00091 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.866 | L2-Norm(final)=10.891 | 4263.1 samples/s | 66.6 steps/s
[Step=50050 Epoch=48.9] | Loss=0.00931 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=10.894 | 4862.4 samples/s | 76.0 steps/s
[Step=50100 Epoch=48.9] | Loss=0.00919 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.868 | L2-Norm(final)=10.896 | 5541.0 samples/s | 86.6 steps/s
[Step=50150 Epoch=49.0] | Loss=0.00894 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.897 | 5595.1 samples/s | 87.4 steps/s
[Step=50200 Epoch=49.0] | Loss=0.00907 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.898 | 5561.1 samples/s | 86.9 steps/s
[Step=50250 Epoch=49.1] | Loss=0.00888 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.901 | 5615.2 samples/s | 87.7 steps/s
[Step=50300 Epoch=49.1] | Loss=0.00898 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.903 | 5695.4 samples/s | 89.0 steps/s
[Step=50350 Epoch=49.2] | Loss=0.00884 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.868 | L2-Norm(final)=10.905 | 5574.6 samples/s | 87.1 steps/s
[Step=50400 Epoch=49.2] | Loss=0.00908 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.868 | L2-Norm(final)=10.908 | 5641.7 samples/s | 88.2 steps/s
[Step=50450 Epoch=49.3] | Loss=0.00894 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.910 | 5605.2 samples/s | 87.6 steps/s
[Step=50500 Epoch=49.3] | Loss=0.00913 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.912 | 5666.5 samples/s | 88.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=49.3] | Loss=0.00590 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=10.930 | 3827.5 samples/s | 59.8 steps/s
[Step=50550 Epoch=49.4] | Loss=0.01064 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.879 | L2-Norm(final)=10.930 | 4743.3 samples/s | 74.1 steps/s
[Step=50600 Epoch=49.4] | Loss=0.00926 | Reg=0.00193 | acc=0.9844 | L2-Norm=13.891 | L2-Norm(final)=10.932 | 4824.2 samples/s | 75.4 steps/s
[Step=50650 Epoch=49.5] | Loss=0.00989 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.900 | L2-Norm(final)=10.932 | 4807.9 samples/s | 75.1 steps/s
[Step=50700 Epoch=49.5] | Loss=0.00934 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.908 | L2-Norm(final)=10.931 | 4830.3 samples/s | 75.5 steps/s
[Step=50750 Epoch=49.5] | Loss=0.00926 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.914 | L2-Norm(final)=10.931 | 4912.6 samples/s | 76.8 steps/s
[Step=50800 Epoch=49.6] | Loss=0.00949 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.919 | L2-Norm(final)=10.931 | 4757.1 samples/s | 74.3 steps/s
[Step=50850 Epoch=49.6] | Loss=0.00938 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.925 | L2-Norm(final)=10.931 | 4844.5 samples/s | 75.7 steps/s
[Step=50900 Epoch=49.7] | Loss=0.00965 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.930 | L2-Norm(final)=10.932 | 4858.1 samples/s | 75.9 steps/s
[Step=50950 Epoch=49.7] | Loss=0.00976 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.935 | L2-Norm(final)=10.933 | 4830.9 samples/s | 75.5 steps/s
[Step=51000 Epoch=49.8] | Loss=0.00972 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=10.934 | 4856.1 samples/s | 75.9 steps/s
[Step=51050 Epoch=49.8] | Loss=0.00978 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.946 | L2-Norm(final)=10.935 | 4845.4 samples/s | 75.7 steps/s
[Step=51100 Epoch=49.9] | Loss=0.00987 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.951 | L2-Norm(final)=10.936 | 4889.4 samples/s | 76.4 steps/s
[Step=51150 Epoch=49.9] | Loss=0.01007 | Reg=0.00195 | acc=0.9688 | L2-Norm=13.955 | L2-Norm(final)=10.937 | 4840.3 samples/s | 75.6 steps/s
[Step=51200 Epoch=50.0] | Loss=0.01022 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.960 | L2-Norm(final)=10.937 | 4818.1 samples/s | 75.3 steps/s
[Step=51250 Epoch=50.0] | Loss=0.01029 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.964 | L2-Norm(final)=10.938 | 4862.1 samples/s | 76.0 steps/s
[Step=51300 Epoch=50.1] | Loss=0.01030 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.969 | L2-Norm(final)=10.939 | 4882.3 samples/s | 76.3 steps/s
[Step=51350 Epoch=50.1] | Loss=0.01035 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.973 | L2-Norm(final)=10.940 | 4926.5 samples/s | 77.0 steps/s
[Step=51400 Epoch=50.2] | Loss=0.01035 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.977 | L2-Norm(final)=10.942 | 4819.6 samples/s | 75.3 steps/s
[Step=51450 Epoch=50.2] | Loss=0.01045 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.981 | L2-Norm(final)=10.943 | 4867.3 samples/s | 76.1 steps/s
[Step=51500 Epoch=50.3] | Loss=0.01056 | Reg=0.00196 | acc=0.9531 | L2-Norm=13.985 | L2-Norm(final)=10.944 | 5208.3 samples/s | 81.4 steps/s
[Step=51550 Epoch=50.3] | Loss=0.01054 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.989 | L2-Norm(final)=10.945 | 2114.7 samples/s | 33.0 steps/s
[Step=51600 Epoch=50.4] | Loss=0.01047 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.993 | L2-Norm(final)=10.946 | 4766.0 samples/s | 74.5 steps/s
[Step=51650 Epoch=50.4] | Loss=0.01039 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.997 | L2-Norm(final)=10.947 | 4799.6 samples/s | 75.0 steps/s
[Step=51700 Epoch=50.5] | Loss=0.01037 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.000 | L2-Norm(final)=10.948 | 4864.8 samples/s | 76.0 steps/s
[Step=51750 Epoch=50.5] | Loss=0.01027 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.004 | L2-Norm(final)=10.949 | 4763.7 samples/s | 74.4 steps/s
[Step=51800 Epoch=50.6] | Loss=0.01019 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.007 | L2-Norm(final)=10.951 | 4833.5 samples/s | 75.5 steps/s
[Step=51850 Epoch=50.6] | Loss=0.01013 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.011 | L2-Norm(final)=10.952 | 4872.0 samples/s | 76.1 steps/s
[Step=51900 Epoch=50.7] | Loss=0.01005 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.014 | L2-Norm(final)=10.953 | 4794.5 samples/s | 74.9 steps/s
[Step=51950 Epoch=50.7] | Loss=0.00995 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.017 | L2-Norm(final)=10.954 | 4871.1 samples/s | 76.1 steps/s
[Step=52000 Epoch=50.8] | Loss=0.00993 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.020 | L2-Norm(final)=10.956 | 4787.1 samples/s | 74.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step52000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=50001 Epoch=94.3] | Loss=0.00000 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.866 | L2-Norm(final)=14.204 | 3669.9 samples/s | 57.3 steps/s
[Step=50050 Epoch=94.3] | Loss=0.00012 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.859 | L2-Norm(final)=14.218 | 5006.1 samples/s | 78.2 steps/s
[Step=50100 Epoch=94.4] | Loss=0.00010 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.231 | 5248.2 samples/s | 82.0 steps/s
[Step=50150 Epoch=94.5] | Loss=0.00020 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.243 | 5271.2 samples/s | 82.4 steps/s
[Step=50200 Epoch=94.6] | Loss=0.00016 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.254 | 5357.8 samples/s | 83.7 steps/s
[Step=50250 Epoch=94.7] | Loss=0.00015 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.262 | 5239.8 samples/s | 81.9 steps/s
[Step=50300 Epoch=94.8] | Loss=0.00013 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.270 | 5275.3 samples/s | 82.4 steps/s
[Step=50350 Epoch=94.9] | Loss=0.00013 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.278 | 5353.8 samples/s | 83.7 steps/s
[Step=50400 Epoch=95.0] | Loss=0.00012 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.286 | 5308.0 samples/s | 82.9 steps/s
[Step=50450 Epoch=95.1] | Loss=0.00011 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.294 | 5299.0 samples/s | 82.8 steps/s
[Step=50500 Epoch=95.2] | Loss=0.00011 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.858 | L2-Norm(final)=14.300 | 5378.2 samples/s | 84.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=95.2] | Loss=0.00000 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.857 | L2-Norm(final)=14.367 | 4195.5 samples/s | 65.6 steps/s
[Step=50550 Epoch=95.3] | Loss=0.00359 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.870 | L2-Norm(final)=14.359 | 4514.1 samples/s | 70.5 steps/s
[Step=50600 Epoch=95.4] | Loss=0.00203 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.911 | L2-Norm(final)=14.348 | 4660.2 samples/s | 72.8 steps/s
[Step=50650 Epoch=95.5] | Loss=0.00140 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.928 | L2-Norm(final)=14.344 | 4586.6 samples/s | 71.7 steps/s
[Step=50700 Epoch=95.6] | Loss=0.00105 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.935 | L2-Norm(final)=14.342 | 4593.2 samples/s | 71.8 steps/s
[Step=50750 Epoch=95.7] | Loss=0.00084 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=14.342 | 4542.6 samples/s | 71.0 steps/s
[Step=50800 Epoch=95.8] | Loss=0.00118 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.939 | L2-Norm(final)=14.340 | 4698.5 samples/s | 73.4 steps/s
[Step=50850 Epoch=95.9] | Loss=0.00109 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.945 | L2-Norm(final)=14.339 | 4593.7 samples/s | 71.8 steps/s
[Step=50900 Epoch=95.9] | Loss=0.00097 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.949 | L2-Norm(final)=14.337 | 4654.6 samples/s | 72.7 steps/s
[Step=50950 Epoch=96.0] | Loss=0.00086 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.952 | L2-Norm(final)=14.336 | 4568.6 samples/s | 71.4 steps/s
[Step=51000 Epoch=96.1] | Loss=0.00078 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=14.335 | 4676.6 samples/s | 73.1 steps/s
[Step=51050 Epoch=96.2] | Loss=0.00071 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.955 | L2-Norm(final)=14.335 | 2090.1 samples/s | 32.7 steps/s
[Step=51100 Epoch=96.3] | Loss=0.00065 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.955 | L2-Norm(final)=14.335 | 4718.9 samples/s | 73.7 steps/s
[Step=51150 Epoch=96.4] | Loss=0.00060 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=14.334 | 4564.2 samples/s | 71.3 steps/s
[Step=51200 Epoch=96.5] | Loss=0.00062 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=14.334 | 4610.2 samples/s | 72.0 steps/s
[Step=51250 Epoch=96.6] | Loss=0.00059 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.334 | 4552.5 samples/s | 71.1 steps/s
[Step=51300 Epoch=96.7] | Loss=0.00055 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.334 | 4639.5 samples/s | 72.5 steps/s
[Step=51350 Epoch=96.8] | Loss=0.00062 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.333 | 4590.6 samples/s | 71.7 steps/s
[Step=51400 Epoch=96.9] | Loss=0.00058 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.333 | 4654.8 samples/s | 72.7 steps/s
[Step=51450 Epoch=97.0] | Loss=0.00055 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.333 | 4674.0 samples/s | 73.0 steps/s
[Step=51500 Epoch=97.1] | Loss=0.00053 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.333 | 4629.4 samples/s | 72.3 steps/s
[Step=51550 Epoch=97.2] | Loss=0.00051 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.953 | L2-Norm(final)=14.333 | 5685.6 samples/s | 88.8 steps/s
[Step=51600 Epoch=97.3] | Loss=0.00049 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.952 | L2-Norm(final)=14.333 | 1948.8 samples/s | 30.5 steps/s
[Step=51650 Epoch=97.4] | Loss=0.00046 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.951 | L2-Norm(final)=14.333 | 4551.2 samples/s | 71.1 steps/s
[Step=51700 Epoch=97.5] | Loss=0.00045 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.951 | L2-Norm(final)=14.333 | 4632.0 samples/s | 72.4 steps/s
[Step=51750 Epoch=97.5] | Loss=0.00043 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.950 | L2-Norm(final)=14.333 | 4624.5 samples/s | 72.3 steps/s
[Step=51800 Epoch=97.6] | Loss=0.00042 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.948 | L2-Norm(final)=14.333 | 4610.9 samples/s | 72.0 steps/s
[Step=51850 Epoch=97.7] | Loss=0.00041 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.948 | L2-Norm(final)=14.333 | 4668.8 samples/s | 72.9 steps/s
[Step=51900 Epoch=97.8] | Loss=0.00039 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.947 | L2-Norm(final)=14.333 | 4607.0 samples/s | 72.0 steps/s
[Step=51950 Epoch=97.9] | Loss=0.00038 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.945 | L2-Norm(final)=14.333 | 4604.1 samples/s | 71.9 steps/s
[Step=52000 Epoch=98.0] | Loss=0.00037 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.944 | L2-Norm(final)=14.333 | 4682.5 samples/s | 73.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06873 | acc=0.9712 | tpr=0.9795 | fpr=0.0466 | 4185.5 samples/s | 16.3 steps/s
Avg test loss: 0.06749, Avg test acc: 0.97143, Avg tpr: 0.97878, Avg fpr: 0.04474, total FA: 349

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=11.42418 | acc=0.3003 | tpr=0.0063 | fpr=0.0612 | 4185.5 samples/s | 16.3 steps/s
Avg test loss: 11.39009, Avg test acc: 0.29742, Avg tpr: 0.00682, Avg fpr: 0.06345, total FA: 495

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.99374 | acc=0.1366 | tpr=0.4425 | fpr=0.8689 | 4234.0 samples/s | 16.5 steps/s
[Step= 100] | Loss=5.98241 | acc=0.1362 | tpr=0.4072 | fpr=0.8688 | 8184.3 samples/s | 32.0 steps/s
[Step= 150] | Loss=5.96249 | acc=0.1372 | tpr=0.4179 | fpr=0.8679 | 7933.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.95609 | acc=0.1373 | tpr=0.4164 | fpr=0.8678 | 8004.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.95666 | acc=0.1368 | tpr=0.4122 | fpr=0.8682 | 7988.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.95691 | acc=0.1367 | tpr=0.4138 | fpr=0.8683 | 8087.6 samples/s | 31.6 steps/s
[Step= 350] | Loss=5.95356 | acc=0.1368 | tpr=0.4170 | fpr=0.8683 | 8085.8 samples/s | 31.6 steps/s
[Step= 400] | Loss=5.95670 | acc=0.1364 | tpr=0.4163 | fpr=0.8687 | 7958.1 samples/s | 31.1 steps/s
[Step= 450] | Loss=5.96077 | acc=0.1360 | tpr=0.4202 | fpr=0.8692 | 7902.9 samples/s | 30.9 steps/s
[Step= 500] | Loss=5.95678 | acc=0.1357 | tpr=0.4176 | fpr=0.8694 | 7830.5 samples/s | 30.6 steps/s
[Step= 550] | Loss=5.95471 | acc=0.1357 | tpr=0.4218 | fpr=0.8695 | 14970.4 samples/s | 58.5 steps/s
Avg test loss: 5.95609, Avg test acc: 0.13561, Avg tpr: 0.42155, Avg fpr: 0.86959, total FA: 120741

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.17174 | acc=0.9810 | tpr=0.9602 | fpr=0.0186 | 4284.4 samples/s | 16.7 steps/s
[Step= 100] | Loss=0.17856 | acc=0.9809 | tpr=0.9638 | fpr=0.0188 | 7743.2 samples/s | 30.2 steps/s
[Step= 150] | Loss=0.18706 | acc=0.9801 | tpr=0.9654 | fpr=0.0197 | 8064.6 samples/s | 31.5 steps/s
[Step= 200] | Loss=0.19082 | acc=0.9801 | tpr=0.9639 | fpr=0.0196 | 7863.2 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.18710 | acc=0.9803 | tpr=0.9616 | fpr=0.0193 | 8156.6 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.19184 | acc=0.9800 | tpr=0.9593 | fpr=0.0196 | 7996.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.19182 | acc=0.9801 | tpr=0.9599 | fpr=0.0195 | 7886.8 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.19355 | acc=0.9800 | tpr=0.9590 | fpr=0.0196 | 7892.7 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.19718 | acc=0.9797 | tpr=0.9572 | fpr=0.0199 | 8108.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.19555 | acc=0.9798 | tpr=0.9577 | fpr=0.0198 | 7886.1 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.19416 | acc=0.9800 | tpr=0.9562 | fpr=0.0196 | 14932.3 samples/s | 58.3 steps/s
Avg test loss: 0.19391, Avg test acc: 0.98001, Avg tpr: 0.95602, Avg fpr: 0.01955, total FA: 2715

server round 26/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=52001 Epoch=50.8] | Loss=0.02565 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.925 | L2-Norm(final)=10.992 | 4383.7 samples/s | 68.5 steps/s
[Step=52050 Epoch=50.8] | Loss=0.01570 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.926 | L2-Norm(final)=10.999 | 5099.1 samples/s | 79.7 steps/s
[Step=52100 Epoch=50.9] | Loss=0.01652 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.010 | 5500.3 samples/s | 85.9 steps/s
[Step=52150 Epoch=50.9] | Loss=0.01614 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.020 | 5581.8 samples/s | 87.2 steps/s
[Step=52200 Epoch=51.0] | Loss=0.01573 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.926 | L2-Norm(final)=11.029 | 5600.3 samples/s | 87.5 steps/s
[Step=52250 Epoch=51.0] | Loss=0.01610 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.926 | L2-Norm(final)=11.036 | 5627.7 samples/s | 87.9 steps/s
[Step=52300 Epoch=51.1] | Loss=0.01605 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.042 | 5595.6 samples/s | 87.4 steps/s
[Step=52350 Epoch=51.1] | Loss=0.01583 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.926 | L2-Norm(final)=11.049 | 5577.4 samples/s | 87.1 steps/s
[Step=52400 Epoch=51.2] | Loss=0.01593 | Reg=0.00194 | acc=0.9688 | L2-Norm=13.926 | L2-Norm(final)=11.055 | 5700.1 samples/s | 89.1 steps/s
[Step=52450 Epoch=51.2] | Loss=0.01590 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.061 | 5601.4 samples/s | 87.5 steps/s
[Step=52500 Epoch=51.3] | Loss=0.01590 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.067 | 5447.3 samples/s | 85.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=51.3] | Loss=0.00884 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.926 | L2-Norm(final)=11.124 | 4146.3 samples/s | 64.8 steps/s
[Step=52550 Epoch=51.3] | Loss=0.01498 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.947 | L2-Norm(final)=11.125 | 4501.0 samples/s | 70.3 steps/s
[Step=52600 Epoch=51.4] | Loss=0.01393 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.962 | L2-Norm(final)=11.124 | 4843.4 samples/s | 75.7 steps/s
[Step=52650 Epoch=51.4] | Loss=0.01341 | Reg=0.00195 | acc=0.9688 | L2-Norm=13.974 | L2-Norm(final)=11.124 | 4816.0 samples/s | 75.2 steps/s
[Step=52700 Epoch=51.5] | Loss=0.01312 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.984 | L2-Norm(final)=11.123 | 4861.5 samples/s | 76.0 steps/s
[Step=52750 Epoch=51.5] | Loss=0.01283 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.993 | L2-Norm(final)=11.123 | 4840.8 samples/s | 75.6 steps/s
[Step=52800 Epoch=51.6] | Loss=0.01238 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.999 | L2-Norm(final)=11.123 | 4853.7 samples/s | 75.8 steps/s
[Step=52850 Epoch=51.6] | Loss=0.01226 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.006 | L2-Norm(final)=11.124 | 4917.1 samples/s | 76.8 steps/s
[Step=52900 Epoch=51.6] | Loss=0.01222 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.011 | L2-Norm(final)=11.125 | 4907.5 samples/s | 76.7 steps/s
[Step=52950 Epoch=51.7] | Loss=0.01202 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.017 | L2-Norm(final)=11.125 | 4820.7 samples/s | 75.3 steps/s
[Step=53000 Epoch=51.7] | Loss=0.01188 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.022 | L2-Norm(final)=11.126 | 4822.4 samples/s | 75.4 steps/s
[Step=53050 Epoch=51.8] | Loss=0.01150 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.027 | L2-Norm(final)=11.127 | 4908.5 samples/s | 76.7 steps/s
[Step=53100 Epoch=51.8] | Loss=0.01130 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.032 | L2-Norm(final)=11.128 | 4851.4 samples/s | 75.8 steps/s
[Step=53150 Epoch=51.9] | Loss=0.01119 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.036 | L2-Norm(final)=11.130 | 4825.9 samples/s | 75.4 steps/s
[Step=53200 Epoch=51.9] | Loss=0.01109 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.040 | L2-Norm(final)=11.130 | 4861.4 samples/s | 76.0 steps/s
[Step=53250 Epoch=52.0] | Loss=0.01101 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.045 | L2-Norm(final)=11.132 | 4830.9 samples/s | 75.5 steps/s
[Step=53300 Epoch=52.0] | Loss=0.01090 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.049 | L2-Norm(final)=11.133 | 4848.6 samples/s | 75.8 steps/s
[Step=53350 Epoch=52.1] | Loss=0.01074 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.053 | L2-Norm(final)=11.134 | 4803.4 samples/s | 75.1 steps/s
[Step=53400 Epoch=52.1] | Loss=0.01068 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.057 | L2-Norm(final)=11.135 | 4916.4 samples/s | 76.8 steps/s
[Step=53450 Epoch=52.2] | Loss=0.01088 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.061 | L2-Norm(final)=11.136 | 4770.6 samples/s | 74.5 steps/s
[Step=53500 Epoch=52.2] | Loss=0.01088 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.065 | L2-Norm(final)=11.137 | 5209.4 samples/s | 81.4 steps/s
[Step=53550 Epoch=52.3] | Loss=0.01088 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.069 | L2-Norm(final)=11.139 | 2063.0 samples/s | 32.2 steps/s
[Step=53600 Epoch=52.3] | Loss=0.01095 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.073 | L2-Norm(final)=11.140 | 4837.5 samples/s | 75.6 steps/s
[Step=53650 Epoch=52.4] | Loss=0.01086 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.076 | L2-Norm(final)=11.141 | 4787.5 samples/s | 74.8 steps/s
[Step=53700 Epoch=52.4] | Loss=0.01073 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.080 | L2-Norm(final)=11.142 | 4857.1 samples/s | 75.9 steps/s
[Step=53750 Epoch=52.5] | Loss=0.01079 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.084 | L2-Norm(final)=11.143 | 4767.8 samples/s | 74.5 steps/s
[Step=53800 Epoch=52.5] | Loss=0.01073 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.087 | L2-Norm(final)=11.144 | 4888.4 samples/s | 76.4 steps/s
[Step=53850 Epoch=52.6] | Loss=0.01069 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.090 | L2-Norm(final)=11.144 | 4834.9 samples/s | 75.5 steps/s
[Step=53900 Epoch=52.6] | Loss=0.01064 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.094 | L2-Norm(final)=11.145 | 4870.1 samples/s | 76.1 steps/s
[Step=53950 Epoch=52.7] | Loss=0.01056 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.097 | L2-Norm(final)=11.146 | 4850.3 samples/s | 75.8 steps/s
[Step=54000 Epoch=52.7] | Loss=0.01057 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.100 | L2-Norm(final)=11.147 | 4892.5 samples/s | 76.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step54000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=52001 Epoch=98.0] | Loss=0.00000 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.925 | L2-Norm(final)=14.337 | 3922.2 samples/s | 61.3 steps/s
[Step=52050 Epoch=98.1] | Loss=0.00015 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.338 | 5089.9 samples/s | 79.5 steps/s
[Step=52100 Epoch=98.2] | Loss=0.00009 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.340 | 5346.3 samples/s | 83.5 steps/s
[Step=52150 Epoch=98.3] | Loss=0.00007 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.341 | 5269.4 samples/s | 82.3 steps/s
[Step=52200 Epoch=98.4] | Loss=0.00006 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.342 | 5255.3 samples/s | 82.1 steps/s
[Step=52250 Epoch=98.5] | Loss=0.00009 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.343 | 5221.1 samples/s | 81.6 steps/s
[Step=52300 Epoch=98.6] | Loss=0.00008 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.344 | 5341.8 samples/s | 83.5 steps/s
[Step=52350 Epoch=98.7] | Loss=0.00008 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.345 | 5330.0 samples/s | 83.3 steps/s
[Step=52400 Epoch=98.8] | Loss=0.00007 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.346 | 5281.1 samples/s | 82.5 steps/s
[Step=52450 Epoch=98.9] | Loss=0.00007 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.346 | 5256.9 samples/s | 82.1 steps/s
[Step=52500 Epoch=99.0] | Loss=0.00006 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.347 | 5358.2 samples/s | 83.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=99.0] | Loss=0.00004 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=14.355 | 3917.4 samples/s | 61.2 steps/s
[Step=52550 Epoch=99.1] | Loss=0.00003 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.919 | L2-Norm(final)=14.356 | 4376.6 samples/s | 68.4 steps/s
[Step=52600 Epoch=99.2] | Loss=0.00002 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.915 | L2-Norm(final)=14.357 | 4598.6 samples/s | 71.9 steps/s
[Step=52650 Epoch=99.2] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.911 | L2-Norm(final)=14.358 | 4631.4 samples/s | 72.4 steps/s
[Step=52700 Epoch=99.3] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.907 | L2-Norm(final)=14.359 | 4338.5 samples/s | 67.8 steps/s
[Step=52750 Epoch=99.4] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.903 | L2-Norm(final)=14.359 | 4501.6 samples/s | 70.3 steps/s
[Step=52800 Epoch=99.5] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.899 | L2-Norm(final)=14.360 | 4652.8 samples/s | 72.7 steps/s
[Step=52850 Epoch=99.6] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.895 | L2-Norm(final)=14.361 | 4602.4 samples/s | 71.9 steps/s
[Step=52900 Epoch=99.7] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.890 | L2-Norm(final)=14.362 | 4559.8 samples/s | 71.2 steps/s
[Step=52950 Epoch=99.8] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.887 | L2-Norm(final)=14.363 | 4629.7 samples/s | 72.3 steps/s
[Step=53000 Epoch=99.9] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.883 | L2-Norm(final)=14.364 | 4675.8 samples/s | 73.1 steps/s
[Step=53050 Epoch=100.0] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.879 | L2-Norm(final)=14.365 | 2116.1 samples/s | 33.1 steps/s
[Step=53100 Epoch=100.1] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.874 | L2-Norm(final)=14.365 | 4692.0 samples/s | 73.3 steps/s
[Step=53150 Epoch=100.2] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.870 | L2-Norm(final)=14.366 | 4547.2 samples/s | 71.1 steps/s
[Step=53200 Epoch=100.3] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.865 | L2-Norm(final)=14.366 | 4600.7 samples/s | 71.9 steps/s
[Step=53250 Epoch=100.4] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.861 | L2-Norm(final)=14.367 | 4588.2 samples/s | 71.7 steps/s
[Step=53300 Epoch=100.5] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.856 | L2-Norm(final)=14.368 | 4636.1 samples/s | 72.4 steps/s
[Step=53350 Epoch=100.6] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.852 | L2-Norm(final)=14.368 | 4579.5 samples/s | 71.6 steps/s
[Step=53400 Epoch=100.7] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.847 | L2-Norm(final)=14.368 | 4630.6 samples/s | 72.4 steps/s
[Step=53450 Epoch=100.8] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.842 | L2-Norm(final)=14.369 | 4613.7 samples/s | 72.1 steps/s
[Step=53500 Epoch=100.8] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.837 | L2-Norm(final)=14.369 | 4696.7 samples/s | 73.4 steps/s
[Step=53550 Epoch=100.9] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.832 | L2-Norm(final)=14.370 | 5609.2 samples/s | 87.6 steps/s
[Step=53600 Epoch=101.0] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.827 | L2-Norm(final)=14.370 | 1967.0 samples/s | 30.7 steps/s
[Step=53650 Epoch=101.1] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.822 | L2-Norm(final)=14.371 | 4540.5 samples/s | 70.9 steps/s
[Step=53700 Epoch=101.2] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.817 | L2-Norm(final)=14.371 | 4620.4 samples/s | 72.2 steps/s
[Step=53750 Epoch=101.3] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.812 | L2-Norm(final)=14.372 | 4574.0 samples/s | 71.5 steps/s
[Step=53800 Epoch=101.4] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.807 | L2-Norm(final)=14.372 | 4587.5 samples/s | 71.7 steps/s
[Step=53850 Epoch=101.5] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.801 | L2-Norm(final)=14.373 | 4649.9 samples/s | 72.7 steps/s
[Step=53900 Epoch=101.6] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.796 | L2-Norm(final)=14.373 | 4599.8 samples/s | 71.9 steps/s
[Step=53950 Epoch=101.7] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.791 | L2-Norm(final)=14.373 | 4634.2 samples/s | 72.4 steps/s
[Step=54000 Epoch=101.8] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.785 | L2-Norm(final)=14.374 | 4596.8 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06364 | acc=0.9717 | tpr=0.9779 | fpr=0.0416 | 4166.5 samples/s | 16.3 steps/s
Avg test loss: 0.06335, Avg test acc: 0.97195, Avg tpr: 0.97826, Avg fpr: 0.04192, total FA: 327

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.21991 | acc=0.2903 | tpr=0.0082 | fpr=0.0971 | 4229.3 samples/s | 16.5 steps/s
Avg test loss: 9.19707, Avg test acc: 0.28860, Avg tpr: 0.00938, Avg fpr: 0.09730, total FA: 759

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.51271 | acc=0.1420 | tpr=0.2566 | fpr=0.8601 | 4253.1 samples/s | 16.6 steps/s
[Step= 100] | Loss=5.50504 | acc=0.1421 | tpr=0.2367 | fpr=0.8596 | 7939.8 samples/s | 31.0 steps/s
[Step= 150] | Loss=5.48278 | acc=0.1440 | tpr=0.2493 | fpr=0.8580 | 8311.7 samples/s | 32.5 steps/s
[Step= 200] | Loss=5.47811 | acc=0.1436 | tpr=0.2503 | fpr=0.8583 | 7589.8 samples/s | 29.6 steps/s
[Step= 250] | Loss=5.47458 | acc=0.1441 | tpr=0.2585 | fpr=0.8580 | 8062.5 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.47546 | acc=0.1444 | tpr=0.2655 | fpr=0.8578 | 8337.5 samples/s | 32.6 steps/s
[Step= 350] | Loss=5.46949 | acc=0.1446 | tpr=0.2674 | fpr=0.8576 | 7734.3 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.46956 | acc=0.1445 | tpr=0.2686 | fpr=0.8578 | 7700.6 samples/s | 30.1 steps/s
[Step= 450] | Loss=5.47227 | acc=0.1439 | tpr=0.2731 | fpr=0.8584 | 8189.2 samples/s | 32.0 steps/s
[Step= 500] | Loss=5.46847 | acc=0.1436 | tpr=0.2705 | fpr=0.8587 | 7805.6 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.46731 | acc=0.1434 | tpr=0.2714 | fpr=0.8589 | 14290.2 samples/s | 55.8 steps/s
Avg test loss: 5.46924, Avg test acc: 0.14333, Avg tpr: 0.27100, Avg fpr: 0.85899, total FA: 119269

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14301 | acc=0.9823 | tpr=0.9690 | fpr=0.0174 | 4220.8 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.14889 | acc=0.9817 | tpr=0.9659 | fpr=0.0180 | 7914.3 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.15387 | acc=0.9811 | tpr=0.9669 | fpr=0.0186 | 8019.8 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.15738 | acc=0.9810 | tpr=0.9639 | fpr=0.0187 | 7985.4 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.15489 | acc=0.9811 | tpr=0.9607 | fpr=0.0185 | 8075.3 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.15840 | acc=0.9807 | tpr=0.9600 | fpr=0.0189 | 8065.1 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.15785 | acc=0.9808 | tpr=0.9612 | fpr=0.0188 | 7885.8 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.15902 | acc=0.9807 | tpr=0.9590 | fpr=0.0189 | 8287.7 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.16162 | acc=0.9805 | tpr=0.9591 | fpr=0.0191 | 7809.2 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.16072 | acc=0.9805 | tpr=0.9595 | fpr=0.0191 | 7939.6 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.15981 | acc=0.9807 | tpr=0.9582 | fpr=0.0189 | 14544.2 samples/s | 56.8 steps/s
Avg test loss: 0.15960, Avg test acc: 0.98067, Avg tpr: 0.95800, Avg fpr: 0.01892, total FA: 2627

server round 27/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=54001 Epoch=52.7] | Loss=0.01021 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.866 | L2-Norm(final)=11.175 | 3732.4 samples/s | 58.3 steps/s
[Step=54050 Epoch=52.8] | Loss=0.01042 | Reg=0.00192 | acc=0.9688 | L2-Norm=13.867 | L2-Norm(final)=11.181 | 5520.6 samples/s | 86.3 steps/s
[Step=54100 Epoch=52.8] | Loss=0.00955 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.867 | L2-Norm(final)=11.191 | 5536.3 samples/s | 86.5 steps/s
[Step=54150 Epoch=52.9] | Loss=0.00921 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.201 | 5483.4 samples/s | 85.7 steps/s
[Step=54200 Epoch=52.9] | Loss=0.00938 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.210 | 5566.3 samples/s | 87.0 steps/s
[Step=54250 Epoch=53.0] | Loss=0.00960 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.219 | 5582.1 samples/s | 87.2 steps/s
[Step=54300 Epoch=53.0] | Loss=0.00979 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.227 | 5648.9 samples/s | 88.3 steps/s
[Step=54350 Epoch=53.1] | Loss=0.01003 | Reg=0.00192 | acc=0.9844 | L2-Norm=13.867 | L2-Norm(final)=11.235 | 5626.0 samples/s | 87.9 steps/s
[Step=54400 Epoch=53.1] | Loss=0.00999 | Reg=0.00192 | acc=0.9688 | L2-Norm=13.867 | L2-Norm(final)=11.243 | 5597.5 samples/s | 87.5 steps/s
[Step=54450 Epoch=53.2] | Loss=0.01000 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.251 | 5606.5 samples/s | 87.6 steps/s
[Step=54500 Epoch=53.2] | Loss=0.00988 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.259 | 5603.2 samples/s | 87.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=53.2] | Loss=0.00105 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=11.333 | 4117.2 samples/s | 64.3 steps/s
[Step=54550 Epoch=53.3] | Loss=0.00831 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.883 | L2-Norm(final)=11.336 | 4615.6 samples/s | 72.1 steps/s
[Step=54600 Epoch=53.3] | Loss=0.00874 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.895 | L2-Norm(final)=11.337 | 4830.7 samples/s | 75.5 steps/s
[Step=54650 Epoch=53.4] | Loss=0.00969 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.903 | L2-Norm(final)=11.338 | 4622.1 samples/s | 72.2 steps/s
[Step=54700 Epoch=53.4] | Loss=0.01001 | Reg=0.00193 | acc=0.9844 | L2-Norm=13.909 | L2-Norm(final)=11.338 | 4766.7 samples/s | 74.5 steps/s
[Step=54750 Epoch=53.5] | Loss=0.00977 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.915 | L2-Norm(final)=11.338 | 4862.6 samples/s | 76.0 steps/s
[Step=54800 Epoch=53.5] | Loss=0.00922 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.919 | L2-Norm(final)=11.339 | 4840.8 samples/s | 75.6 steps/s
[Step=54850 Epoch=53.6] | Loss=0.00922 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=11.341 | 4891.0 samples/s | 76.4 steps/s
[Step=54900 Epoch=53.6] | Loss=0.00955 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.928 | L2-Norm(final)=11.342 | 4832.4 samples/s | 75.5 steps/s
[Step=54950 Epoch=53.6] | Loss=0.00952 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.933 | L2-Norm(final)=11.342 | 4869.1 samples/s | 76.1 steps/s
[Step=55000 Epoch=53.7] | Loss=0.00931 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.937 | L2-Norm(final)=11.343 | 4855.2 samples/s | 75.9 steps/s
[Step=55050 Epoch=53.7] | Loss=0.00953 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.941 | L2-Norm(final)=11.344 | 4829.4 samples/s | 75.5 steps/s
[Step=55100 Epoch=53.8] | Loss=0.00952 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.945 | L2-Norm(final)=11.345 | 4875.9 samples/s | 76.2 steps/s
[Step=55150 Epoch=53.8] | Loss=0.00979 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.949 | L2-Norm(final)=11.345 | 4803.7 samples/s | 75.1 steps/s
[Step=55200 Epoch=53.9] | Loss=0.00990 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.953 | L2-Norm(final)=11.346 | 4799.9 samples/s | 75.0 steps/s
[Step=55250 Epoch=53.9] | Loss=0.00993 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.957 | L2-Norm(final)=11.346 | 4812.4 samples/s | 75.2 steps/s
[Step=55300 Epoch=54.0] | Loss=0.00987 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.960 | L2-Norm(final)=11.347 | 4842.9 samples/s | 75.7 steps/s
[Step=55350 Epoch=54.0] | Loss=0.01000 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.963 | L2-Norm(final)=11.347 | 4887.0 samples/s | 76.4 steps/s
[Step=55400 Epoch=54.1] | Loss=0.01000 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.967 | L2-Norm(final)=11.348 | 4755.2 samples/s | 74.3 steps/s
[Step=55450 Epoch=54.1] | Loss=0.01001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.970 | L2-Norm(final)=11.349 | 4803.6 samples/s | 75.1 steps/s
[Step=55500 Epoch=54.2] | Loss=0.00992 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.974 | L2-Norm(final)=11.350 | 5144.8 samples/s | 80.4 steps/s
[Step=55550 Epoch=54.2] | Loss=0.00984 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.977 | L2-Norm(final)=11.350 | 2084.3 samples/s | 32.6 steps/s
[Step=55600 Epoch=54.3] | Loss=0.00972 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.980 | L2-Norm(final)=11.351 | 4866.8 samples/s | 76.0 steps/s
[Step=55650 Epoch=54.3] | Loss=0.00959 | Reg=0.00196 | acc=0.9688 | L2-Norm=13.984 | L2-Norm(final)=11.353 | 4824.4 samples/s | 75.4 steps/s
[Step=55700 Epoch=54.4] | Loss=0.00957 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.987 | L2-Norm(final)=11.354 | 4838.5 samples/s | 75.6 steps/s
[Step=55750 Epoch=54.4] | Loss=0.00961 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.990 | L2-Norm(final)=11.355 | 4759.3 samples/s | 74.4 steps/s
[Step=55800 Epoch=54.5] | Loss=0.00965 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.993 | L2-Norm(final)=11.356 | 4862.0 samples/s | 76.0 steps/s
[Step=55850 Epoch=54.5] | Loss=0.00959 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.995 | L2-Norm(final)=11.357 | 4807.1 samples/s | 75.1 steps/s
[Step=55900 Epoch=54.6] | Loss=0.00952 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.998 | L2-Norm(final)=11.358 | 4838.4 samples/s | 75.6 steps/s
[Step=55950 Epoch=54.6] | Loss=0.00948 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.001 | L2-Norm(final)=11.359 | 4866.2 samples/s | 76.0 steps/s
[Step=56000 Epoch=54.7] | Loss=0.00940 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.003 | L2-Norm(final)=11.360 | 4773.7 samples/s | 74.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step56000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=54001 Epoch=101.8] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.866 | L2-Norm(final)=14.386 | 3826.4 samples/s | 59.8 steps/s
[Step=54050 Epoch=101.9] | Loss=0.00006 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.865 | L2-Norm(final)=14.388 | 4793.1 samples/s | 74.9 steps/s
[Step=54100 Epoch=102.0] | Loss=0.00006 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.389 | 5188.8 samples/s | 81.1 steps/s
[Step=54150 Epoch=102.1] | Loss=0.00007 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.391 | 5038.2 samples/s | 78.7 steps/s
[Step=54200 Epoch=102.2] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.394 | 5260.3 samples/s | 82.2 steps/s
[Step=54250 Epoch=102.3] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.397 | 5328.7 samples/s | 83.3 steps/s
[Step=54300 Epoch=102.4] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.400 | 5326.3 samples/s | 83.2 steps/s
[Step=54350 Epoch=102.5] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.403 | 5180.4 samples/s | 80.9 steps/s
[Step=54400 Epoch=102.5] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.406 | 5270.2 samples/s | 82.3 steps/s
[Step=54450 Epoch=102.6] | Loss=0.00009 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.409 | 5312.0 samples/s | 83.0 steps/s
[Step=54500 Epoch=102.7] | Loss=0.00012 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.412 | 5341.7 samples/s | 83.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=102.7] | Loss=0.00000 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.864 | L2-Norm(final)=14.443 | 4028.9 samples/s | 63.0 steps/s
[Step=54550 Epoch=102.8] | Loss=0.00004 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.857 | L2-Norm(final)=14.445 | 4410.1 samples/s | 68.9 steps/s
[Step=54600 Epoch=102.9] | Loss=0.00002 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.850 | L2-Norm(final)=14.447 | 4587.0 samples/s | 71.7 steps/s
[Step=54650 Epoch=103.0] | Loss=0.00002 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.841 | L2-Norm(final)=14.448 | 4565.1 samples/s | 71.3 steps/s
[Step=54700 Epoch=103.1] | Loss=0.00002 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.832 | L2-Norm(final)=14.449 | 4597.6 samples/s | 71.8 steps/s
[Step=54750 Epoch=103.2] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.823 | L2-Norm(final)=14.450 | 4602.6 samples/s | 71.9 steps/s
[Step=54800 Epoch=103.3] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.814 | L2-Norm(final)=14.451 | 4584.6 samples/s | 71.6 steps/s
[Step=54850 Epoch=103.4] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.805 | L2-Norm(final)=14.452 | 4572.6 samples/s | 71.4 steps/s
[Step=54900 Epoch=103.5] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.795 | L2-Norm(final)=14.453 | 4621.1 samples/s | 72.2 steps/s
[Step=54950 Epoch=103.6] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.786 | L2-Norm(final)=14.454 | 4663.9 samples/s | 72.9 steps/s
[Step=55000 Epoch=103.7] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.777 | L2-Norm(final)=14.455 | 4598.8 samples/s | 71.9 steps/s
[Step=55050 Epoch=103.8] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.767 | L2-Norm(final)=14.456 | 2092.4 samples/s | 32.7 steps/s
[Step=55100 Epoch=103.9] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=14.457 | 4751.1 samples/s | 74.2 steps/s
[Step=55150 Epoch=104.0] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.746 | L2-Norm(final)=14.457 | 4543.0 samples/s | 71.0 steps/s
[Step=55200 Epoch=104.1] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.736 | L2-Norm(final)=14.458 | 4554.2 samples/s | 71.2 steps/s
[Step=55250 Epoch=104.1] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.725 | L2-Norm(final)=14.458 | 4561.8 samples/s | 71.3 steps/s
[Step=55300 Epoch=104.2] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.715 | L2-Norm(final)=14.459 | 4632.5 samples/s | 72.4 steps/s
[Step=55350 Epoch=104.3] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.704 | L2-Norm(final)=14.459 | 4604.1 samples/s | 71.9 steps/s
[Step=55400 Epoch=104.4] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.693 | L2-Norm(final)=14.460 | 4569.7 samples/s | 71.4 steps/s
[Step=55450 Epoch=104.5] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.682 | L2-Norm(final)=14.460 | 4646.5 samples/s | 72.6 steps/s
[Step=55500 Epoch=104.6] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.671 | L2-Norm(final)=14.460 | 4561.6 samples/s | 71.3 steps/s
[Step=55550 Epoch=104.7] | Loss=0.00000 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.660 | L2-Norm(final)=14.461 | 5757.3 samples/s | 90.0 steps/s
[Step=55600 Epoch=104.8] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.649 | L2-Norm(final)=14.461 | 1938.5 samples/s | 30.3 steps/s
[Step=55650 Epoch=104.9] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.638 | L2-Norm(final)=14.462 | 4641.6 samples/s | 72.5 steps/s
[Step=55700 Epoch=105.0] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.626 | L2-Norm(final)=14.462 | 4550.1 samples/s | 71.1 steps/s
[Step=55750 Epoch=105.1] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.615 | L2-Norm(final)=14.462 | 4379.9 samples/s | 68.4 steps/s
[Step=55800 Epoch=105.2] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.603 | L2-Norm(final)=14.463 | 4600.4 samples/s | 71.9 steps/s
[Step=55850 Epoch=105.3] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.591 | L2-Norm(final)=14.463 | 4679.6 samples/s | 73.1 steps/s
[Step=55900 Epoch=105.4] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=14.463 | 4563.3 samples/s | 71.3 steps/s
[Step=55950 Epoch=105.5] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.567 | L2-Norm(final)=14.464 | 4611.7 samples/s | 72.1 steps/s
[Step=56000 Epoch=105.6] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.555 | L2-Norm(final)=14.464 | 4610.2 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06372 | acc=0.9712 | tpr=0.9770 | fpr=0.0414 | 4177.8 samples/s | 16.3 steps/s
Avg test loss: 0.06363, Avg test acc: 0.97035, Avg tpr: 0.97628, Avg fpr: 0.04269, total FA: 333

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.21295 | acc=0.2851 | tpr=0.0082 | fpr=0.1137 | 4208.0 samples/s | 16.4 steps/s
Avg test loss: 9.19645, Avg test acc: 0.28227, Avg tpr: 0.00956, Avg fpr: 0.11793, total FA: 920

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.02649 | acc=0.1528 | tpr=0.3628 | fpr=0.8510 | 4145.8 samples/s | 16.2 steps/s
[Step= 100] | Loss=5.02500 | acc=0.1534 | tpr=0.3305 | fpr=0.8499 | 8037.4 samples/s | 31.4 steps/s
[Step= 150] | Loss=5.00346 | acc=0.1545 | tpr=0.3256 | fpr=0.8487 | 7915.5 samples/s | 30.9 steps/s
[Step= 200] | Loss=4.99585 | acc=0.1541 | tpr=0.3257 | fpr=0.8490 | 7917.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=4.99751 | acc=0.1544 | tpr=0.3231 | fpr=0.8487 | 8186.5 samples/s | 32.0 steps/s
[Step= 300] | Loss=4.99835 | acc=0.1545 | tpr=0.3302 | fpr=0.8487 | 7965.1 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.99594 | acc=0.1546 | tpr=0.3312 | fpr=0.8486 | 8421.4 samples/s | 32.9 steps/s
[Step= 400] | Loss=4.99861 | acc=0.1545 | tpr=0.3326 | fpr=0.8487 | 7680.6 samples/s | 30.0 steps/s
[Step= 450] | Loss=5.00121 | acc=0.1542 | tpr=0.3354 | fpr=0.8491 | 8194.6 samples/s | 32.0 steps/s
[Step= 500] | Loss=4.99692 | acc=0.1542 | tpr=0.3357 | fpr=0.8490 | 7749.8 samples/s | 30.3 steps/s
[Step= 550] | Loss=4.99414 | acc=0.1541 | tpr=0.3366 | fpr=0.8492 | 15074.3 samples/s | 58.9 steps/s
Avg test loss: 4.99545, Avg test acc: 0.15403, Avg tpr: 0.33597, Avg fpr: 0.84927, total FA: 117920

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15260 | acc=0.9818 | tpr=0.9602 | fpr=0.0178 | 4226.3 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.15781 | acc=0.9817 | tpr=0.9638 | fpr=0.0179 | 7875.9 samples/s | 30.8 steps/s
[Step= 150] | Loss=0.16192 | acc=0.9812 | tpr=0.9654 | fpr=0.0185 | 7766.7 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.16576 | acc=0.9812 | tpr=0.9628 | fpr=0.0185 | 8298.7 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.16365 | acc=0.9813 | tpr=0.9607 | fpr=0.0183 | 7768.0 samples/s | 30.3 steps/s
[Step= 300] | Loss=0.16727 | acc=0.9809 | tpr=0.9600 | fpr=0.0188 | 8024.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.16651 | acc=0.9808 | tpr=0.9606 | fpr=0.0189 | 7970.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.16778 | acc=0.9806 | tpr=0.9606 | fpr=0.0190 | 8060.2 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.17033 | acc=0.9804 | tpr=0.9606 | fpr=0.0193 | 7827.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.16949 | acc=0.9804 | tpr=0.9608 | fpr=0.0193 | 7772.2 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.16858 | acc=0.9806 | tpr=0.9598 | fpr=0.0191 | 15059.8 samples/s | 58.8 steps/s
Avg test loss: 0.16840, Avg test acc: 0.98057, Avg tpr: 0.95959, Avg fpr: 0.01905, total FA: 2645

server round 28/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=56001 Epoch=54.7] | Loss=0.00088 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.593 | L2-Norm(final)=11.392 | 4095.0 samples/s | 64.0 steps/s
[Step=56050 Epoch=54.7] | Loss=0.00756 | Reg=0.00185 | acc=0.9531 | L2-Norm=13.594 | L2-Norm(final)=11.395 | 5333.0 samples/s | 83.3 steps/s
[Step=56100 Epoch=54.8] | Loss=0.00878 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.594 | L2-Norm(final)=11.399 | 5581.0 samples/s | 87.2 steps/s
[Step=56150 Epoch=54.8] | Loss=0.00826 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.594 | L2-Norm(final)=11.404 | 5505.2 samples/s | 86.0 steps/s
[Step=56200 Epoch=54.9] | Loss=0.00785 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.409 | 5710.3 samples/s | 89.2 steps/s
[Step=56250 Epoch=54.9] | Loss=0.00770 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.414 | 5513.3 samples/s | 86.1 steps/s
[Step=56300 Epoch=55.0] | Loss=0.00757 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.420 | 5581.2 samples/s | 87.2 steps/s
[Step=56350 Epoch=55.0] | Loss=0.00755 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.426 | 5584.3 samples/s | 87.3 steps/s
[Step=56400 Epoch=55.1] | Loss=0.00747 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.431 | 5598.0 samples/s | 87.5 steps/s
[Step=56450 Epoch=55.1] | Loss=0.00739 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.437 | 5706.3 samples/s | 89.2 steps/s
[Step=56500 Epoch=55.2] | Loss=0.00739 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.443 | 5659.9 samples/s | 88.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=55.2] | Loss=0.00029 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.500 | 4098.9 samples/s | 64.0 steps/s
[Step=56550 Epoch=55.2] | Loss=0.00713 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.603 | L2-Norm(final)=11.504 | 4646.1 samples/s | 72.6 steps/s
[Step=56600 Epoch=55.3] | Loss=0.00724 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.611 | L2-Norm(final)=11.504 | 4802.6 samples/s | 75.0 steps/s
[Step=56650 Epoch=55.3] | Loss=0.00833 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.617 | L2-Norm(final)=11.503 | 4855.3 samples/s | 75.9 steps/s
[Step=56700 Epoch=55.4] | Loss=0.00899 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.622 | L2-Norm(final)=11.502 | 4855.4 samples/s | 75.9 steps/s
[Step=56750 Epoch=55.4] | Loss=0.00890 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=11.503 | 4797.2 samples/s | 75.0 steps/s
[Step=56800 Epoch=55.5] | Loss=0.00894 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.632 | L2-Norm(final)=11.505 | 4864.4 samples/s | 76.0 steps/s
[Step=56850 Epoch=55.5] | Loss=0.00871 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.636 | L2-Norm(final)=11.506 | 4832.6 samples/s | 75.5 steps/s
[Step=56900 Epoch=55.6] | Loss=0.00885 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.640 | L2-Norm(final)=11.507 | 4826.4 samples/s | 75.4 steps/s
[Step=56950 Epoch=55.6] | Loss=0.00899 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.645 | L2-Norm(final)=11.508 | 4877.8 samples/s | 76.2 steps/s
[Step=57000 Epoch=55.7] | Loss=0.00907 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.650 | L2-Norm(final)=11.510 | 4837.7 samples/s | 75.6 steps/s
[Step=57050 Epoch=55.7] | Loss=0.00931 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.655 | L2-Norm(final)=11.511 | 4833.7 samples/s | 75.5 steps/s
[Step=57100 Epoch=55.7] | Loss=0.00977 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.660 | L2-Norm(final)=11.513 | 4862.6 samples/s | 76.0 steps/s
[Step=57150 Epoch=55.8] | Loss=0.00986 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.665 | L2-Norm(final)=11.514 | 4894.8 samples/s | 76.5 steps/s
[Step=57200 Epoch=55.8] | Loss=0.01001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.670 | L2-Norm(final)=11.515 | 4810.6 samples/s | 75.2 steps/s
[Step=57250 Epoch=55.9] | Loss=0.01020 | Reg=0.00187 | acc=0.9688 | L2-Norm=13.675 | L2-Norm(final)=11.516 | 4790.8 samples/s | 74.9 steps/s
[Step=57300 Epoch=55.9] | Loss=0.01008 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.680 | L2-Norm(final)=11.516 | 4922.7 samples/s | 76.9 steps/s
[Step=57350 Epoch=56.0] | Loss=0.01021 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.684 | L2-Norm(final)=11.518 | 4833.6 samples/s | 75.5 steps/s
[Step=57400 Epoch=56.0] | Loss=0.01022 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.689 | L2-Norm(final)=11.518 | 4900.3 samples/s | 76.6 steps/s
[Step=57450 Epoch=56.1] | Loss=0.01014 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.693 | L2-Norm(final)=11.519 | 4849.5 samples/s | 75.8 steps/s
[Step=57500 Epoch=56.1] | Loss=0.01004 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.697 | L2-Norm(final)=11.520 | 5227.3 samples/s | 81.7 steps/s
[Step=57550 Epoch=56.2] | Loss=0.01001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.701 | L2-Norm(final)=11.521 | 2153.3 samples/s | 33.6 steps/s
[Step=57600 Epoch=56.2] | Loss=0.01001 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.705 | L2-Norm(final)=11.522 | 4860.7 samples/s | 75.9 steps/s
[Step=57650 Epoch=56.3] | Loss=0.01006 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.708 | L2-Norm(final)=11.523 | 4816.2 samples/s | 75.3 steps/s
[Step=57700 Epoch=56.3] | Loss=0.00998 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.712 | L2-Norm(final)=11.524 | 4824.9 samples/s | 75.4 steps/s
[Step=57750 Epoch=56.4] | Loss=0.00983 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.715 | L2-Norm(final)=11.525 | 4786.8 samples/s | 74.8 steps/s
[Step=57800 Epoch=56.4] | Loss=0.00978 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.719 | L2-Norm(final)=11.526 | 4875.8 samples/s | 76.2 steps/s
[Step=57850 Epoch=56.5] | Loss=0.00975 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.722 | L2-Norm(final)=11.527 | 4861.7 samples/s | 76.0 steps/s
[Step=57900 Epoch=56.5] | Loss=0.00982 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.725 | L2-Norm(final)=11.528 | 4827.9 samples/s | 75.4 steps/s
[Step=57950 Epoch=56.6] | Loss=0.00986 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.728 | L2-Norm(final)=11.529 | 4887.2 samples/s | 76.4 steps/s
[Step=58000 Epoch=56.6] | Loss=0.00975 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.731 | L2-Norm(final)=11.530 | 4871.7 samples/s | 76.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step58000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=56001 Epoch=105.6] | Loss=0.00011 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.593 | L2-Norm(final)=14.474 | 4199.7 samples/s | 65.6 steps/s
[Step=56050 Epoch=105.7] | Loss=0.00014 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.589 | L2-Norm(final)=14.481 | 4754.0 samples/s | 74.3 steps/s
[Step=56100 Epoch=105.7] | Loss=0.00010 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.488 | 5294.0 samples/s | 82.7 steps/s
[Step=56150 Epoch=105.8] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.494 | 5249.4 samples/s | 82.0 steps/s
[Step=56200 Epoch=105.9] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.500 | 5321.8 samples/s | 83.2 steps/s
[Step=56250 Epoch=106.0] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.505 | 5264.1 samples/s | 82.3 steps/s
[Step=56300 Epoch=106.1] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.509 | 5276.3 samples/s | 82.4 steps/s
[Step=56350 Epoch=106.2] | Loss=0.00008 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.515 | 5309.4 samples/s | 83.0 steps/s
[Step=56400 Epoch=106.3] | Loss=0.00008 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.520 | 5331.8 samples/s | 83.3 steps/s
[Step=56450 Epoch=106.4] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.526 | 5355.8 samples/s | 83.7 steps/s
[Step=56500 Epoch=106.5] | Loss=0.00008 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.532 | 5371.7 samples/s | 83.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=106.5] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=14.587 | 3797.9 samples/s | 59.3 steps/s
[Step=56550 Epoch=106.6] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.576 | L2-Norm(final)=14.589 | 4538.9 samples/s | 70.9 steps/s
[Step=56600 Epoch=106.7] | Loss=0.00005 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.559 | L2-Norm(final)=14.590 | 4599.7 samples/s | 71.9 steps/s
[Step=56650 Epoch=106.8] | Loss=0.00029 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=14.588 | 4587.7 samples/s | 71.7 steps/s
[Step=56700 Epoch=106.9] | Loss=0.00059 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.574 | L2-Norm(final)=14.587 | 4648.3 samples/s | 72.6 steps/s
[Step=56750 Epoch=107.0] | Loss=0.00116 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.590 | L2-Norm(final)=14.584 | 4582.1 samples/s | 71.6 steps/s
[Step=56800 Epoch=107.1] | Loss=0.00128 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.606 | L2-Norm(final)=14.581 | 4634.8 samples/s | 72.4 steps/s
[Step=56850 Epoch=107.2] | Loss=0.00119 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=14.578 | 4611.5 samples/s | 72.1 steps/s
[Step=56900 Epoch=107.3] | Loss=0.00106 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.630 | L2-Norm(final)=14.576 | 4665.0 samples/s | 72.9 steps/s
[Step=56950 Epoch=107.4] | Loss=0.00095 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.637 | L2-Norm(final)=14.574 | 4637.9 samples/s | 72.5 steps/s
[Step=57000 Epoch=107.4] | Loss=0.00094 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.643 | L2-Norm(final)=14.573 | 4637.2 samples/s | 72.5 steps/s
[Step=57050 Epoch=107.5] | Loss=0.00085 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.648 | L2-Norm(final)=14.572 | 2091.0 samples/s | 32.7 steps/s
[Step=57100 Epoch=107.6] | Loss=0.00079 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.651 | L2-Norm(final)=14.572 | 4652.7 samples/s | 72.7 steps/s
[Step=57150 Epoch=107.7] | Loss=0.00074 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.654 | L2-Norm(final)=14.571 | 4600.2 samples/s | 71.9 steps/s
[Step=57200 Epoch=107.8] | Loss=0.00068 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=14.571 | 4591.4 samples/s | 71.7 steps/s
[Step=57250 Epoch=107.9] | Loss=0.00064 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.657 | L2-Norm(final)=14.571 | 4614.7 samples/s | 72.1 steps/s
[Step=57300 Epoch=108.0] | Loss=0.00060 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.657 | L2-Norm(final)=14.571 | 4628.5 samples/s | 72.3 steps/s
[Step=57350 Epoch=108.1] | Loss=0.00056 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.658 | L2-Norm(final)=14.571 | 4669.4 samples/s | 73.0 steps/s
[Step=57400 Epoch=108.2] | Loss=0.00053 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.657 | L2-Norm(final)=14.570 | 4526.2 samples/s | 70.7 steps/s
[Step=57450 Epoch=108.3] | Loss=0.00051 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.657 | L2-Norm(final)=14.570 | 4664.4 samples/s | 72.9 steps/s
[Step=57500 Epoch=108.4] | Loss=0.00048 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=14.570 | 4583.9 samples/s | 71.6 steps/s
[Step=57550 Epoch=108.5] | Loss=0.00046 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.655 | L2-Norm(final)=14.570 | 5694.9 samples/s | 89.0 steps/s
[Step=57600 Epoch=108.6] | Loss=0.00044 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.654 | L2-Norm(final)=14.570 | 1977.4 samples/s | 30.9 steps/s
[Step=57650 Epoch=108.7] | Loss=0.00042 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.653 | L2-Norm(final)=14.570 | 4568.5 samples/s | 71.4 steps/s
[Step=57700 Epoch=108.8] | Loss=0.00040 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.651 | L2-Norm(final)=14.571 | 4589.7 samples/s | 71.7 steps/s
[Step=57750 Epoch=108.9] | Loss=0.00039 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.650 | L2-Norm(final)=14.571 | 4648.6 samples/s | 72.6 steps/s
[Step=57800 Epoch=109.0] | Loss=0.00037 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.648 | L2-Norm(final)=14.571 | 4570.8 samples/s | 71.4 steps/s
[Step=57850 Epoch=109.0] | Loss=0.00036 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.646 | L2-Norm(final)=14.571 | 4589.4 samples/s | 71.7 steps/s
[Step=57900 Epoch=109.1] | Loss=0.00034 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.644 | L2-Norm(final)=14.571 | 4631.4 samples/s | 72.4 steps/s
[Step=57950 Epoch=109.2] | Loss=0.00033 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.642 | L2-Norm(final)=14.571 | 4584.7 samples/s | 71.6 steps/s
[Step=58000 Epoch=109.3] | Loss=0.00032 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.639 | L2-Norm(final)=14.571 | 4573.8 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06436 | acc=0.9723 | tpr=0.9774 | fpr=0.0389 | 4159.7 samples/s | 16.2 steps/s
Avg test loss: 0.06456, Avg test acc: 0.97199, Avg tpr: 0.97663, Avg fpr: 0.03820, total FA: 298

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.44238 | acc=0.2996 | tpr=0.0089 | fpr=0.0691 | 4186.8 samples/s | 16.4 steps/s
Avg test loss: 10.44100, Avg test acc: 0.29702, Avg tpr: 0.00921, Avg fpr: 0.06999, total FA: 546

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.50721 | acc=0.1526 | tpr=0.3186 | fpr=0.8504 | 4129.7 samples/s | 16.1 steps/s
[Step= 100] | Loss=5.50225 | acc=0.1535 | tpr=0.3028 | fpr=0.8493 | 7721.0 samples/s | 30.2 steps/s
[Step= 150] | Loss=5.48286 | acc=0.1539 | tpr=0.3055 | fpr=0.8489 | 8185.1 samples/s | 32.0 steps/s
[Step= 200] | Loss=5.47629 | acc=0.1535 | tpr=0.3005 | fpr=0.8492 | 7804.3 samples/s | 30.5 steps/s
[Step= 250] | Loss=5.47576 | acc=0.1537 | tpr=0.2978 | fpr=0.8489 | 8341.7 samples/s | 32.6 steps/s
[Step= 300] | Loss=5.47665 | acc=0.1538 | tpr=0.3018 | fpr=0.8489 | 7785.6 samples/s | 30.4 steps/s
[Step= 350] | Loss=5.47090 | acc=0.1536 | tpr=0.3012 | fpr=0.8491 | 7842.3 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.47273 | acc=0.1535 | tpr=0.2987 | fpr=0.8491 | 8189.9 samples/s | 32.0 steps/s
[Step= 450] | Loss=5.47587 | acc=0.1528 | tpr=0.2970 | fpr=0.8498 | 7739.0 samples/s | 30.2 steps/s
[Step= 500] | Loss=5.47237 | acc=0.1527 | tpr=0.2960 | fpr=0.8499 | 8089.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.47060 | acc=0.1526 | tpr=0.2973 | fpr=0.8500 | 14561.0 samples/s | 56.9 steps/s
Avg test loss: 5.47241, Avg test acc: 0.15251, Avg tpr: 0.29715, Avg fpr: 0.85012, total FA: 118037

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.19540 | acc=0.9809 | tpr=0.9690 | fpr=0.0189 | 4140.2 samples/s | 16.2 steps/s
[Step= 100] | Loss=0.20359 | acc=0.9802 | tpr=0.9701 | fpr=0.0196 | 8082.0 samples/s | 31.6 steps/s
[Step= 150] | Loss=0.21041 | acc=0.9795 | tpr=0.9697 | fpr=0.0204 | 8326.1 samples/s | 32.5 steps/s
[Step= 200] | Loss=0.21373 | acc=0.9794 | tpr=0.9683 | fpr=0.0204 | 7796.1 samples/s | 30.5 steps/s
[Step= 250] | Loss=0.20978 | acc=0.9797 | tpr=0.9659 | fpr=0.0201 | 7855.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.21292 | acc=0.9793 | tpr=0.9629 | fpr=0.0204 | 8188.7 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.21329 | acc=0.9793 | tpr=0.9631 | fpr=0.0204 | 7828.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.21549 | acc=0.9791 | tpr=0.9612 | fpr=0.0206 | 8026.6 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.21992 | acc=0.9788 | tpr=0.9606 | fpr=0.0209 | 7931.9 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.21826 | acc=0.9788 | tpr=0.9608 | fpr=0.0209 | 7816.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.21642 | acc=0.9790 | tpr=0.9606 | fpr=0.0207 | 14870.4 samples/s | 58.1 steps/s
Avg test loss: 0.21603, Avg test acc: 0.97903, Avg tpr: 0.96038, Avg fpr: 0.02063, total FA: 2865

server round 29/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=58001 Epoch=56.6] | Loss=0.00527 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=11.561 | 3910.2 samples/s | 61.1 steps/s
[Step=58050 Epoch=56.7] | Loss=0.01339 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.620 | L2-Norm(final)=11.552 | 5493.7 samples/s | 85.8 steps/s
[Step=58100 Epoch=56.7] | Loss=0.01300 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.550 | 5565.6 samples/s | 87.0 steps/s
[Step=58150 Epoch=56.8] | Loss=0.01360 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.551 | 5589.3 samples/s | 87.3 steps/s
[Step=58200 Epoch=56.8] | Loss=0.01410 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.552 | 5624.1 samples/s | 87.9 steps/s
[Step=58250 Epoch=56.9] | Loss=0.01424 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.620 | L2-Norm(final)=11.553 | 5549.4 samples/s | 86.7 steps/s
[Step=58300 Epoch=56.9] | Loss=0.01429 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.620 | L2-Norm(final)=11.553 | 5659.4 samples/s | 88.4 steps/s
[Step=58350 Epoch=57.0] | Loss=0.01404 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.554 | 5632.6 samples/s | 88.0 steps/s
[Step=58400 Epoch=57.0] | Loss=0.01397 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.555 | 5610.3 samples/s | 87.7 steps/s
[Step=58450 Epoch=57.1] | Loss=0.01400 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.620 | L2-Norm(final)=11.557 | 5590.9 samples/s | 87.4 steps/s
[Step=58500 Epoch=57.1] | Loss=0.01376 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.620 | L2-Norm(final)=11.558 | 5519.3 samples/s | 86.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=57.1] | Loss=0.01069 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.620 | L2-Norm(final)=11.576 | 4228.5 samples/s | 66.1 steps/s
[Step=58550 Epoch=57.2] | Loss=0.01281 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.635 | L2-Norm(final)=11.576 | 4532.8 samples/s | 70.8 steps/s
[Step=58600 Epoch=57.2] | Loss=0.01109 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.647 | L2-Norm(final)=11.576 | 4808.3 samples/s | 75.1 steps/s
[Step=58650 Epoch=57.3] | Loss=0.01110 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=11.578 | 4777.9 samples/s | 74.7 steps/s
[Step=58700 Epoch=57.3] | Loss=0.01023 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.663 | L2-Norm(final)=11.579 | 4807.8 samples/s | 75.1 steps/s
[Step=58750 Epoch=57.4] | Loss=0.01009 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.670 | L2-Norm(final)=11.581 | 4784.5 samples/s | 74.8 steps/s
[Step=58800 Epoch=57.4] | Loss=0.01003 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.676 | L2-Norm(final)=11.583 | 4876.4 samples/s | 76.2 steps/s
[Step=58850 Epoch=57.5] | Loss=0.01028 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=11.585 | 4859.7 samples/s | 75.9 steps/s
[Step=58900 Epoch=57.5] | Loss=0.01016 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.687 | L2-Norm(final)=11.586 | 4792.7 samples/s | 74.9 steps/s
[Step=58950 Epoch=57.6] | Loss=0.01021 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.692 | L2-Norm(final)=11.587 | 4841.3 samples/s | 75.6 steps/s
[Step=59000 Epoch=57.6] | Loss=0.01012 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.698 | L2-Norm(final)=11.588 | 4874.7 samples/s | 76.2 steps/s
[Step=59050 Epoch=57.7] | Loss=0.01037 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.703 | L2-Norm(final)=11.589 | 4889.6 samples/s | 76.4 steps/s
[Step=59100 Epoch=57.7] | Loss=0.01042 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.708 | L2-Norm(final)=11.590 | 4797.8 samples/s | 75.0 steps/s
[Step=59150 Epoch=57.8] | Loss=0.01041 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.712 | L2-Norm(final)=11.590 | 4859.1 samples/s | 75.9 steps/s
[Step=59200 Epoch=57.8] | Loss=0.01030 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.716 | L2-Norm(final)=11.591 | 4838.7 samples/s | 75.6 steps/s
[Step=59250 Epoch=57.8] | Loss=0.01027 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.721 | L2-Norm(final)=11.592 | 4882.6 samples/s | 76.3 steps/s
[Step=59300 Epoch=57.9] | Loss=0.01039 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.725 | L2-Norm(final)=11.592 | 4780.8 samples/s | 74.7 steps/s
[Step=59350 Epoch=57.9] | Loss=0.01031 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.729 | L2-Norm(final)=11.593 | 4842.2 samples/s | 75.7 steps/s
[Step=59400 Epoch=58.0] | Loss=0.01039 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.733 | L2-Norm(final)=11.593 | 4866.0 samples/s | 76.0 steps/s
[Step=59450 Epoch=58.0] | Loss=0.01042 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.737 | L2-Norm(final)=11.594 | 4799.5 samples/s | 75.0 steps/s
[Step=59500 Epoch=58.1] | Loss=0.01058 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.740 | L2-Norm(final)=11.595 | 5101.8 samples/s | 79.7 steps/s
[Step=59550 Epoch=58.1] | Loss=0.01060 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.744 | L2-Norm(final)=11.595 | 2097.5 samples/s | 32.8 steps/s
[Step=59600 Epoch=58.2] | Loss=0.01042 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.747 | L2-Norm(final)=11.596 | 4851.4 samples/s | 75.8 steps/s
[Step=59650 Epoch=58.2] | Loss=0.01033 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.751 | L2-Norm(final)=11.596 | 4839.4 samples/s | 75.6 steps/s
[Step=59700 Epoch=58.3] | Loss=0.01030 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.754 | L2-Norm(final)=11.597 | 4865.0 samples/s | 76.0 steps/s
[Step=59750 Epoch=58.3] | Loss=0.01025 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.757 | L2-Norm(final)=11.598 | 4820.8 samples/s | 75.3 steps/s
[Step=59800 Epoch=58.4] | Loss=0.01014 | Reg=0.00189 | acc=0.9688 | L2-Norm=13.760 | L2-Norm(final)=11.599 | 4838.8 samples/s | 75.6 steps/s
[Step=59850 Epoch=58.4] | Loss=0.01002 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.764 | L2-Norm(final)=11.600 | 4876.9 samples/s | 76.2 steps/s
[Step=59900 Epoch=58.5] | Loss=0.01006 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.767 | L2-Norm(final)=11.601 | 4818.5 samples/s | 75.3 steps/s
[Step=59950 Epoch=58.5] | Loss=0.00994 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.770 | L2-Norm(final)=11.601 | 4856.3 samples/s | 75.9 steps/s
[Step=60000 Epoch=58.6] | Loss=0.00990 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.772 | L2-Norm(final)=11.602 | 4872.8 samples/s | 76.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step60000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=58001 Epoch=109.3] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=14.575 | 4053.9 samples/s | 63.3 steps/s
[Step=58050 Epoch=109.4] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.576 | 4835.1 samples/s | 75.5 steps/s
[Step=58100 Epoch=109.5] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.578 | 5189.6 samples/s | 81.1 steps/s
[Step=58150 Epoch=109.6] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.580 | 5211.1 samples/s | 81.4 steps/s
[Step=58200 Epoch=109.7] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.582 | 5367.9 samples/s | 83.9 steps/s
[Step=58250 Epoch=109.8] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.584 | 5336.4 samples/s | 83.4 steps/s
[Step=58300 Epoch=109.9] | Loss=0.00006 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.585 | 5179.7 samples/s | 80.9 steps/s
[Step=58350 Epoch=110.0] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.587 | 5369.0 samples/s | 83.9 steps/s
[Step=58400 Epoch=110.1] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.589 | 5251.2 samples/s | 82.0 steps/s
[Step=58450 Epoch=110.2] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.591 | 5294.4 samples/s | 82.7 steps/s
[Step=58500 Epoch=110.3] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.592 | 5383.8 samples/s | 84.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=110.3] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=14.608 | 4298.6 samples/s | 67.2 steps/s
[Step=58550 Epoch=110.4] | Loss=0.00003 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.613 | L2-Norm(final)=14.609 | 4190.8 samples/s | 65.5 steps/s
[Step=58600 Epoch=110.5] | Loss=0.00003 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.609 | L2-Norm(final)=14.611 | 4569.1 samples/s | 71.4 steps/s
[Step=58650 Epoch=110.6] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.605 | L2-Norm(final)=14.612 | 4690.0 samples/s | 73.3 steps/s
[Step=58700 Epoch=110.7] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.600 | L2-Norm(final)=14.613 | 4596.2 samples/s | 71.8 steps/s
[Step=58750 Epoch=110.7] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=14.613 | 4627.9 samples/s | 72.3 steps/s
[Step=58800 Epoch=110.8] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.590 | L2-Norm(final)=14.614 | 4584.1 samples/s | 71.6 steps/s
[Step=58850 Epoch=110.9] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.585 | L2-Norm(final)=14.614 | 4567.7 samples/s | 71.4 steps/s
[Step=58900 Epoch=111.0] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.580 | L2-Norm(final)=14.615 | 4642.5 samples/s | 72.5 steps/s
[Step=58950 Epoch=111.1] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.574 | L2-Norm(final)=14.615 | 4598.6 samples/s | 71.9 steps/s
[Step=59000 Epoch=111.2] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.569 | L2-Norm(final)=14.615 | 4660.9 samples/s | 72.8 steps/s
[Step=59050 Epoch=111.3] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.564 | L2-Norm(final)=14.616 | 2091.0 samples/s | 32.7 steps/s
[Step=59100 Epoch=111.4] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.558 | L2-Norm(final)=14.616 | 4707.2 samples/s | 73.6 steps/s
[Step=59150 Epoch=111.5] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.552 | L2-Norm(final)=14.616 | 4624.5 samples/s | 72.3 steps/s
[Step=59200 Epoch=111.6] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.547 | L2-Norm(final)=14.617 | 4585.7 samples/s | 71.7 steps/s
[Step=59250 Epoch=111.7] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.541 | L2-Norm(final)=14.617 | 4626.8 samples/s | 72.3 steps/s
[Step=59300 Epoch=111.8] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.535 | L2-Norm(final)=14.617 | 4556.1 samples/s | 71.2 steps/s
[Step=59350 Epoch=111.9] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.530 | L2-Norm(final)=14.618 | 4642.3 samples/s | 72.5 steps/s
[Step=59400 Epoch=112.0] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.524 | L2-Norm(final)=14.618 | 4604.5 samples/s | 71.9 steps/s
[Step=59450 Epoch=112.1] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.518 | L2-Norm(final)=14.618 | 4570.1 samples/s | 71.4 steps/s
[Step=59500 Epoch=112.2] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.512 | L2-Norm(final)=14.618 | 4629.3 samples/s | 72.3 steps/s
[Step=59550 Epoch=112.3] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.506 | L2-Norm(final)=14.619 | 5727.3 samples/s | 89.5 steps/s
[Step=59600 Epoch=112.3] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.500 | L2-Norm(final)=14.619 | 1931.3 samples/s | 30.2 steps/s
[Step=59650 Epoch=112.4] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.493 | L2-Norm(final)=14.619 | 4614.2 samples/s | 72.1 steps/s
[Step=59700 Epoch=112.5] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.487 | L2-Norm(final)=14.619 | 4597.6 samples/s | 71.8 steps/s
[Step=59750 Epoch=112.6] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.481 | L2-Norm(final)=14.620 | 4611.5 samples/s | 72.1 steps/s
[Step=59800 Epoch=112.7] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.475 | L2-Norm(final)=14.620 | 4615.7 samples/s | 72.1 steps/s
[Step=59850 Epoch=112.8] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.468 | L2-Norm(final)=14.620 | 4616.4 samples/s | 72.1 steps/s
[Step=59900 Epoch=112.9] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.462 | L2-Norm(final)=14.621 | 4608.8 samples/s | 72.0 steps/s
[Step=59950 Epoch=113.0] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.455 | L2-Norm(final)=14.621 | 4593.5 samples/s | 71.8 steps/s
[Step=60000 Epoch=113.1] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.448 | L2-Norm(final)=14.621 | 4674.9 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07128 | acc=0.9720 | tpr=0.9777 | fpr=0.0404 | 4064.8 samples/s | 15.9 steps/s
Avg test loss: 0.07131, Avg test acc: 0.97219, Avg tpr: 0.97849, Avg fpr: 0.04166, total FA: 325

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.99449 | acc=0.2892 | tpr=0.0092 | fpr=0.1028 | 4177.8 samples/s | 16.3 steps/s
Avg test loss: 8.98712, Avg test acc: 0.28692, Avg tpr: 0.00985, Avg fpr: 0.10370, total FA: 809

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.20446 | acc=0.1298 | tpr=0.2522 | fpr=0.8724 | 4136.1 samples/s | 16.2 steps/s
[Step= 100] | Loss=6.19884 | acc=0.1315 | tpr=0.2303 | fpr=0.8704 | 7994.0 samples/s | 31.2 steps/s
[Step= 150] | Loss=6.17860 | acc=0.1310 | tpr=0.2363 | fpr=0.8709 | 8047.4 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.16728 | acc=0.1309 | tpr=0.2350 | fpr=0.8710 | 7915.8 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.16970 | acc=0.1310 | tpr=0.2332 | fpr=0.8709 | 7922.8 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.16921 | acc=0.1312 | tpr=0.2415 | fpr=0.8708 | 8084.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.16589 | acc=0.1311 | tpr=0.2448 | fpr=0.8709 | 7828.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.16641 | acc=0.1311 | tpr=0.2445 | fpr=0.8709 | 7939.6 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.16964 | acc=0.1308 | tpr=0.2449 | fpr=0.8713 | 8217.9 samples/s | 32.1 steps/s
[Step= 500] | Loss=6.16584 | acc=0.1305 | tpr=0.2427 | fpr=0.8715 | 7757.6 samples/s | 30.3 steps/s
[Step= 550] | Loss=6.16420 | acc=0.1306 | tpr=0.2459 | fpr=0.8715 | 14883.9 samples/s | 58.1 steps/s
Avg test loss: 6.16633, Avg test acc: 0.13055, Avg tpr: 0.24564, Avg fpr: 0.87154, total FA: 121012

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15346 | acc=0.9820 | tpr=0.9690 | fpr=0.0177 | 4096.2 samples/s | 16.0 steps/s
[Step= 100] | Loss=0.15794 | acc=0.9816 | tpr=0.9723 | fpr=0.0182 | 8046.8 samples/s | 31.4 steps/s
[Step= 150] | Loss=0.16210 | acc=0.9809 | tpr=0.9712 | fpr=0.0189 | 8041.2 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.16515 | acc=0.9811 | tpr=0.9694 | fpr=0.0187 | 7960.1 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.16247 | acc=0.9812 | tpr=0.9677 | fpr=0.0186 | 8241.8 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.16523 | acc=0.9810 | tpr=0.9651 | fpr=0.0188 | 7896.1 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.16505 | acc=0.9808 | tpr=0.9656 | fpr=0.0189 | 7986.6 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.16644 | acc=0.9805 | tpr=0.9639 | fpr=0.0192 | 7872.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.16934 | acc=0.9803 | tpr=0.9635 | fpr=0.0194 | 7851.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.16823 | acc=0.9803 | tpr=0.9639 | fpr=0.0194 | 8125.6 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.16715 | acc=0.9805 | tpr=0.9634 | fpr=0.0192 | 14422.1 samples/s | 56.3 steps/s
Avg test loss: 0.16692, Avg test acc: 0.98054, Avg tpr: 0.96276, Avg fpr: 0.01914, total FA: 2657

server round 30/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=60001 Epoch=58.6] | Loss=0.01839 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.514 | L2-Norm(final)=11.627 | 4426.9 samples/s | 69.2 steps/s
[Step=60050 Epoch=58.6] | Loss=0.00858 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.628 | 5189.4 samples/s | 81.1 steps/s
[Step=60100 Epoch=58.7] | Loss=0.00843 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.514 | L2-Norm(final)=11.631 | 5576.3 samples/s | 87.1 steps/s
[Step=60150 Epoch=58.7] | Loss=0.00767 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.634 | 5538.7 samples/s | 86.5 steps/s
[Step=60200 Epoch=58.8] | Loss=0.00807 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.636 | 5628.4 samples/s | 87.9 steps/s
[Step=60250 Epoch=58.8] | Loss=0.00800 | Reg=0.00183 | acc=0.9688 | L2-Norm=13.514 | L2-Norm(final)=11.639 | 5573.0 samples/s | 87.1 steps/s
[Step=60300 Epoch=58.9] | Loss=0.00804 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.642 | 5714.3 samples/s | 89.3 steps/s
[Step=60350 Epoch=58.9] | Loss=0.00802 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.644 | 5462.2 samples/s | 85.3 steps/s
[Step=60400 Epoch=59.0] | Loss=0.00798 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.647 | 5589.0 samples/s | 87.3 steps/s
[Step=60450 Epoch=59.0] | Loss=0.00788 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.514 | L2-Norm(final)=11.649 | 5575.9 samples/s | 87.1 steps/s
[Step=60500 Epoch=59.1] | Loss=0.00786 | Reg=0.00183 | acc=0.9688 | L2-Norm=13.514 | L2-Norm(final)=11.652 | 5668.1 samples/s | 88.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=59.1] | Loss=0.00205 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=11.676 | 3952.1 samples/s | 61.8 steps/s
[Step=60550 Epoch=59.1] | Loss=0.00907 | Reg=0.00183 | acc=0.9688 | L2-Norm=13.517 | L2-Norm(final)=11.678 | 4703.0 samples/s | 73.5 steps/s
[Step=60600 Epoch=59.2] | Loss=0.00851 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.519 | L2-Norm(final)=11.678 | 4812.6 samples/s | 75.2 steps/s
[Step=60650 Epoch=59.2] | Loss=0.00860 | Reg=0.00183 | acc=0.9688 | L2-Norm=13.522 | L2-Norm(final)=11.680 | 4812.5 samples/s | 75.2 steps/s
[Step=60700 Epoch=59.3] | Loss=0.00858 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.524 | L2-Norm(final)=11.681 | 4807.3 samples/s | 75.1 steps/s
[Step=60750 Epoch=59.3] | Loss=0.00819 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.525 | L2-Norm(final)=11.682 | 4856.1 samples/s | 75.9 steps/s
[Step=60800 Epoch=59.4] | Loss=0.00788 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.527 | L2-Norm(final)=11.682 | 4803.3 samples/s | 75.1 steps/s
[Step=60850 Epoch=59.4] | Loss=0.00752 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.528 | L2-Norm(final)=11.683 | 4865.7 samples/s | 76.0 steps/s
[Step=60900 Epoch=59.5] | Loss=0.00761 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.530 | L2-Norm(final)=11.684 | 4868.5 samples/s | 76.1 steps/s
[Step=60950 Epoch=59.5] | Loss=0.00756 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.531 | L2-Norm(final)=11.685 | 4821.2 samples/s | 75.3 steps/s
[Step=61000 Epoch=59.6] | Loss=0.00755 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.533 | L2-Norm(final)=11.686 | 4859.6 samples/s | 75.9 steps/s
[Step=61050 Epoch=59.6] | Loss=0.00761 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.534 | L2-Norm(final)=11.687 | 4849.6 samples/s | 75.8 steps/s
[Step=61100 Epoch=59.7] | Loss=0.00768 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.535 | L2-Norm(final)=11.687 | 4813.7 samples/s | 75.2 steps/s
[Step=61150 Epoch=59.7] | Loss=0.00763 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.537 | L2-Norm(final)=11.688 | 4831.5 samples/s | 75.5 steps/s
[Step=61200 Epoch=59.8] | Loss=0.00752 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.538 | L2-Norm(final)=11.689 | 4814.1 samples/s | 75.2 steps/s
[Step=61250 Epoch=59.8] | Loss=0.00747 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.539 | L2-Norm(final)=11.690 | 4883.3 samples/s | 76.3 steps/s
[Step=61300 Epoch=59.8] | Loss=0.00743 | Reg=0.00183 | acc=0.9688 | L2-Norm=13.540 | L2-Norm(final)=11.691 | 4822.9 samples/s | 75.4 steps/s
[Step=61350 Epoch=59.9] | Loss=0.00743 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.542 | L2-Norm(final)=11.692 | 4896.3 samples/s | 76.5 steps/s
[Step=61400 Epoch=59.9] | Loss=0.00750 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.543 | L2-Norm(final)=11.693 | 4729.2 samples/s | 73.9 steps/s
[Step=61450 Epoch=60.0] | Loss=0.00734 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.544 | L2-Norm(final)=11.693 | 4848.6 samples/s | 75.8 steps/s
[Step=61500 Epoch=60.0] | Loss=0.00730 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.545 | L2-Norm(final)=11.694 | 5166.1 samples/s | 80.7 steps/s
[Step=61550 Epoch=60.1] | Loss=0.00721 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.546 | L2-Norm(final)=11.695 | 2132.6 samples/s | 33.3 steps/s
[Step=61600 Epoch=60.1] | Loss=0.00713 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.547 | L2-Norm(final)=11.696 | 4808.9 samples/s | 75.1 steps/s
[Step=61650 Epoch=60.2] | Loss=0.00703 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.548 | L2-Norm(final)=11.697 | 4820.6 samples/s | 75.3 steps/s
[Step=61700 Epoch=60.2] | Loss=0.00696 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.548 | L2-Norm(final)=11.698 | 4833.5 samples/s | 75.5 steps/s
[Step=61750 Epoch=60.3] | Loss=0.00691 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.549 | L2-Norm(final)=11.699 | 4829.9 samples/s | 75.5 steps/s
[Step=61800 Epoch=60.3] | Loss=0.00686 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.550 | L2-Norm(final)=11.700 | 4830.8 samples/s | 75.5 steps/s
[Step=61850 Epoch=60.4] | Loss=0.00687 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.551 | L2-Norm(final)=11.701 | 4849.9 samples/s | 75.8 steps/s
[Step=61900 Epoch=60.4] | Loss=0.00685 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.552 | L2-Norm(final)=11.702 | 4779.4 samples/s | 74.7 steps/s
[Step=61950 Epoch=60.5] | Loss=0.00680 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.553 | L2-Norm(final)=11.703 | 4880.5 samples/s | 76.3 steps/s
[Step=62000 Epoch=60.5] | Loss=0.00681 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.554 | L2-Norm(final)=11.704 | 4803.9 samples/s | 75.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step62000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=60001 Epoch=113.1] | Loss=0.00000 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=14.631 | 3941.2 samples/s | 61.6 steps/s
[Step=60050 Epoch=113.2] | Loss=0.00009 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.633 | 5083.2 samples/s | 79.4 steps/s
[Step=60100 Epoch=113.3] | Loss=0.00011 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.638 | 5250.8 samples/s | 82.0 steps/s
[Step=60150 Epoch=113.4] | Loss=0.00010 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.641 | 5367.7 samples/s | 83.9 steps/s
[Step=60200 Epoch=113.5] | Loss=0.00009 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.644 | 5187.6 samples/s | 81.1 steps/s
[Step=60250 Epoch=113.6] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.647 | 5297.6 samples/s | 82.8 steps/s
[Step=60300 Epoch=113.7] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.649 | 5334.6 samples/s | 83.4 steps/s
[Step=60350 Epoch=113.8] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.652 | 5267.9 samples/s | 82.3 steps/s
[Step=60400 Epoch=113.9] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.655 | 5367.9 samples/s | 83.9 steps/s
[Step=60450 Epoch=113.9] | Loss=0.00011 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.657 | 5219.9 samples/s | 81.6 steps/s
[Step=60500 Epoch=114.0] | Loss=0.00011 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.660 | 5339.6 samples/s | 83.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=114.0] | Loss=0.00000 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=14.683 | 3929.2 samples/s | 61.4 steps/s
[Step=60550 Epoch=114.1] | Loss=0.00006 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.508 | L2-Norm(final)=14.686 | 4521.0 samples/s | 70.6 steps/s
[Step=60600 Epoch=114.2] | Loss=0.00004 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.503 | L2-Norm(final)=14.686 | 4612.6 samples/s | 72.1 steps/s
[Step=60650 Epoch=114.3] | Loss=0.00003 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.497 | L2-Norm(final)=14.687 | 4604.9 samples/s | 72.0 steps/s
[Step=60700 Epoch=114.4] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.491 | L2-Norm(final)=14.687 | 4538.0 samples/s | 70.9 steps/s
[Step=60750 Epoch=114.5] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.485 | L2-Norm(final)=14.688 | 4574.1 samples/s | 71.5 steps/s
[Step=60800 Epoch=114.6] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.479 | L2-Norm(final)=14.688 | 4620.7 samples/s | 72.2 steps/s
[Step=60850 Epoch=114.7] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.473 | L2-Norm(final)=14.688 | 4612.2 samples/s | 72.1 steps/s
[Step=60900 Epoch=114.8] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.467 | L2-Norm(final)=14.689 | 4634.4 samples/s | 72.4 steps/s
[Step=60950 Epoch=114.9] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.461 | L2-Norm(final)=14.689 | 4613.8 samples/s | 72.1 steps/s
[Step=61000 Epoch=115.0] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.454 | L2-Norm(final)=14.690 | 4687.1 samples/s | 73.2 steps/s
[Step=61050 Epoch=115.1] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.448 | L2-Norm(final)=14.690 | 2112.2 samples/s | 33.0 steps/s
[Step=61100 Epoch=115.2] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.442 | L2-Norm(final)=14.690 | 4702.3 samples/s | 73.5 steps/s
[Step=61150 Epoch=115.3] | Loss=0.00001 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.436 | L2-Norm(final)=14.691 | 4645.4 samples/s | 72.6 steps/s
[Step=61200 Epoch=115.4] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.429 | L2-Norm(final)=14.691 | 4613.5 samples/s | 72.1 steps/s
[Step=61250 Epoch=115.5] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.423 | L2-Norm(final)=14.691 | 4605.3 samples/s | 72.0 steps/s
[Step=61300 Epoch=115.6] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.416 | L2-Norm(final)=14.692 | 4584.1 samples/s | 71.6 steps/s
[Step=61350 Epoch=115.6] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.409 | L2-Norm(final)=14.692 | 4580.9 samples/s | 71.6 steps/s
[Step=61400 Epoch=115.7] | Loss=0.00001 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.403 | L2-Norm(final)=14.692 | 4663.0 samples/s | 72.9 steps/s
[Step=61450 Epoch=115.8] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.396 | L2-Norm(final)=14.693 | 4629.5 samples/s | 72.3 steps/s
[Step=61500 Epoch=115.9] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.389 | L2-Norm(final)=14.693 | 4564.0 samples/s | 71.3 steps/s
[Step=61550 Epoch=116.0] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.382 | L2-Norm(final)=14.693 | 5784.4 samples/s | 90.4 steps/s
[Step=61600 Epoch=116.1] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.375 | L2-Norm(final)=14.694 | 1963.2 samples/s | 30.7 steps/s
[Step=61650 Epoch=116.2] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.367 | L2-Norm(final)=14.694 | 4612.0 samples/s | 72.1 steps/s
[Step=61700 Epoch=116.3] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.360 | L2-Norm(final)=14.694 | 4605.7 samples/s | 72.0 steps/s
[Step=61750 Epoch=116.4] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.353 | L2-Norm(final)=14.695 | 4570.7 samples/s | 71.4 steps/s
[Step=61800 Epoch=116.5] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.345 | L2-Norm(final)=14.695 | 4612.2 samples/s | 72.1 steps/s
[Step=61850 Epoch=116.6] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.338 | L2-Norm(final)=14.696 | 4603.3 samples/s | 71.9 steps/s
[Step=61900 Epoch=116.7] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.330 | L2-Norm(final)=14.696 | 4681.8 samples/s | 73.2 steps/s
[Step=61950 Epoch=116.8] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.322 | L2-Norm(final)=14.696 | 4565.8 samples/s | 71.3 steps/s
[Step=62000 Epoch=116.9] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=14.697 | 4596.0 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07117 | acc=0.9705 | tpr=0.9759 | fpr=0.0414 | 4185.5 samples/s | 16.3 steps/s
Avg test loss: 0.07128, Avg test acc: 0.97111, Avg tpr: 0.97628, Avg fpr: 0.04025, total FA: 314

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.81293 | acc=0.2861 | tpr=0.0099 | fpr=0.1142 | 4253.2 samples/s | 16.6 steps/s
Avg test loss: 8.80021, Avg test acc: 0.28296, Avg tpr: 0.01037, Avg fpr: 0.11755, total FA: 917

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.48283 | acc=0.1526 | tpr=0.2611 | fpr=0.8494 | 4242.4 samples/s | 16.6 steps/s
[Step= 100] | Loss=5.48110 | acc=0.1546 | tpr=0.2495 | fpr=0.8471 | 7920.8 samples/s | 30.9 steps/s
[Step= 150] | Loss=5.46309 | acc=0.1552 | tpr=0.2565 | fpr=0.8467 | 8012.7 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.45474 | acc=0.1556 | tpr=0.2590 | fpr=0.8462 | 7925.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.45704 | acc=0.1556 | tpr=0.2559 | fpr=0.8463 | 8973.5 samples/s | 35.1 steps/s
[Step= 300] | Loss=5.45689 | acc=0.1558 | tpr=0.2647 | fpr=0.8462 | 7364.7 samples/s | 28.8 steps/s
[Step= 350] | Loss=5.45327 | acc=0.1560 | tpr=0.2718 | fpr=0.8461 | 7897.2 samples/s | 30.8 steps/s
[Step= 400] | Loss=5.45389 | acc=0.1562 | tpr=0.2713 | fpr=0.8459 | 7920.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.45659 | acc=0.1560 | tpr=0.2751 | fpr=0.8462 | 8190.1 samples/s | 32.0 steps/s
[Step= 500] | Loss=5.45194 | acc=0.1561 | tpr=0.2722 | fpr=0.8460 | 7763.6 samples/s | 30.3 steps/s
[Step= 550] | Loss=5.45096 | acc=0.1562 | tpr=0.2746 | fpr=0.8459 | 14746.9 samples/s | 57.6 steps/s
Avg test loss: 5.45281, Avg test acc: 0.15612, Avg tpr: 0.27456, Avg fpr: 0.84603, total FA: 117470

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14881 | acc=0.9816 | tpr=0.9558 | fpr=0.0179 | 4230.1 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.15306 | acc=0.9814 | tpr=0.9659 | fpr=0.0183 | 7831.0 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.15618 | acc=0.9809 | tpr=0.9669 | fpr=0.0189 | 8095.1 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.15915 | acc=0.9811 | tpr=0.9650 | fpr=0.0186 | 8002.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.15693 | acc=0.9812 | tpr=0.9633 | fpr=0.0184 | 7956.2 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.15961 | acc=0.9809 | tpr=0.9615 | fpr=0.0188 | 7979.9 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.15930 | acc=0.9807 | tpr=0.9631 | fpr=0.0189 | 7949.5 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.16042 | acc=0.9805 | tpr=0.9617 | fpr=0.0192 | 7965.6 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.16303 | acc=0.9802 | tpr=0.9615 | fpr=0.0194 | 7980.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.16207 | acc=0.9803 | tpr=0.9612 | fpr=0.0194 | 7262.3 samples/s | 28.4 steps/s
[Step= 550] | Loss=0.16112 | acc=0.9805 | tpr=0.9598 | fpr=0.0191 | 14842.3 samples/s | 58.0 steps/s
Avg test loss: 0.16091, Avg test acc: 0.98051, Avg tpr: 0.95959, Avg fpr: 0.01911, total FA: 2654

server round 31/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=62001 Epoch=60.5] | Loss=0.01112 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.313 | L2-Norm(final)=11.732 | 4181.9 samples/s | 65.3 steps/s
[Step=62050 Epoch=60.6] | Loss=0.00605 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.735 | 4999.2 samples/s | 78.1 steps/s
[Step=62100 Epoch=60.6] | Loss=0.00676 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.314 | L2-Norm(final)=11.738 | 5589.5 samples/s | 87.3 steps/s
[Step=62150 Epoch=60.7] | Loss=0.00646 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.742 | 5555.5 samples/s | 86.8 steps/s
[Step=62200 Epoch=60.7] | Loss=0.00647 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.314 | L2-Norm(final)=11.745 | 5611.7 samples/s | 87.7 steps/s
[Step=62250 Epoch=60.8] | Loss=0.00640 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.314 | L2-Norm(final)=11.749 | 5631.0 samples/s | 88.0 steps/s
[Step=62300 Epoch=60.8] | Loss=0.00658 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.752 | 5535.2 samples/s | 86.5 steps/s
[Step=62350 Epoch=60.9] | Loss=0.00657 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.755 | 5621.6 samples/s | 87.8 steps/s
[Step=62400 Epoch=60.9] | Loss=0.00646 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.758 | 5729.0 samples/s | 89.5 steps/s
[Step=62450 Epoch=61.0] | Loss=0.00655 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.761 | 5502.3 samples/s | 86.0 steps/s
[Step=62500 Epoch=61.0] | Loss=0.00646 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=11.764 | 5647.0 samples/s | 88.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=61.0] | Loss=0.01345 | Reg=0.00177 | acc=0.9844 | L2-Norm=13.314 | L2-Norm(final)=11.794 | 3909.9 samples/s | 61.1 steps/s
[Step=62550 Epoch=61.1] | Loss=0.00578 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.318 | L2-Norm(final)=11.797 | 4825.3 samples/s | 75.4 steps/s
[Step=62600 Epoch=61.1] | Loss=0.00609 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.321 | L2-Norm(final)=11.799 | 4723.8 samples/s | 73.8 steps/s
[Step=62650 Epoch=61.2] | Loss=0.00636 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.324 | L2-Norm(final)=11.799 | 4776.8 samples/s | 74.6 steps/s
[Step=62700 Epoch=61.2] | Loss=0.00681 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.327 | L2-Norm(final)=11.800 | 4825.5 samples/s | 75.4 steps/s
[Step=62750 Epoch=61.3] | Loss=0.00695 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.329 | L2-Norm(final)=11.800 | 4836.4 samples/s | 75.6 steps/s
[Step=62800 Epoch=61.3] | Loss=0.00731 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.330 | L2-Norm(final)=11.800 | 4845.3 samples/s | 75.7 steps/s
[Step=62850 Epoch=61.4] | Loss=0.00742 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.332 | L2-Norm(final)=11.800 | 4833.8 samples/s | 75.5 steps/s
[Step=62900 Epoch=61.4] | Loss=0.00731 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.334 | L2-Norm(final)=11.801 | 4795.5 samples/s | 74.9 steps/s
[Step=62950 Epoch=61.5] | Loss=0.00724 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.336 | L2-Norm(final)=11.802 | 4855.1 samples/s | 75.9 steps/s
[Step=63000 Epoch=61.5] | Loss=0.00708 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.337 | L2-Norm(final)=11.803 | 4853.2 samples/s | 75.8 steps/s
[Step=63050 Epoch=61.6] | Loss=0.00715 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.339 | L2-Norm(final)=11.804 | 4856.6 samples/s | 75.9 steps/s
[Step=63100 Epoch=61.6] | Loss=0.00717 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.341 | L2-Norm(final)=11.805 | 4872.1 samples/s | 76.1 steps/s
[Step=63150 Epoch=61.7] | Loss=0.00715 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.342 | L2-Norm(final)=11.806 | 4808.7 samples/s | 75.1 steps/s
[Step=63200 Epoch=61.7] | Loss=0.00727 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.344 | L2-Norm(final)=11.808 | 4782.9 samples/s | 74.7 steps/s
[Step=63250 Epoch=61.8] | Loss=0.00741 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.345 | L2-Norm(final)=11.809 | 4858.4 samples/s | 75.9 steps/s
[Step=63300 Epoch=61.8] | Loss=0.00736 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.347 | L2-Norm(final)=11.810 | 4842.0 samples/s | 75.7 steps/s
[Step=63350 Epoch=61.9] | Loss=0.00730 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.348 | L2-Norm(final)=11.811 | 4850.1 samples/s | 75.8 steps/s
[Step=63400 Epoch=61.9] | Loss=0.00732 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.350 | L2-Norm(final)=11.812 | 4775.6 samples/s | 74.6 steps/s
[Step=63450 Epoch=61.9] | Loss=0.00727 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.351 | L2-Norm(final)=11.814 | 4805.1 samples/s | 75.1 steps/s
[Step=63500 Epoch=62.0] | Loss=0.00728 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.353 | L2-Norm(final)=11.815 | 5228.6 samples/s | 81.7 steps/s
[Step=63550 Epoch=62.0] | Loss=0.00721 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.354 | L2-Norm(final)=11.816 | 2119.8 samples/s | 33.1 steps/s
[Step=63600 Epoch=62.1] | Loss=0.00717 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.356 | L2-Norm(final)=11.817 | 4850.8 samples/s | 75.8 steps/s
[Step=63650 Epoch=62.1] | Loss=0.00710 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.357 | L2-Norm(final)=11.819 | 4800.0 samples/s | 75.0 steps/s
[Step=63700 Epoch=62.2] | Loss=0.00697 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.358 | L2-Norm(final)=11.820 | 4824.0 samples/s | 75.4 steps/s
[Step=63750 Epoch=62.2] | Loss=0.00694 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.359 | L2-Norm(final)=11.822 | 4784.1 samples/s | 74.8 steps/s
[Step=63800 Epoch=62.3] | Loss=0.00690 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.361 | L2-Norm(final)=11.823 | 4818.8 samples/s | 75.3 steps/s
[Step=63850 Epoch=62.3] | Loss=0.00690 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.362 | L2-Norm(final)=11.824 | 4854.0 samples/s | 75.8 steps/s
[Step=63900 Epoch=62.4] | Loss=0.00690 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.363 | L2-Norm(final)=11.825 | 4859.6 samples/s | 75.9 steps/s
[Step=63950 Epoch=62.4] | Loss=0.00690 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.364 | L2-Norm(final)=11.826 | 4871.3 samples/s | 76.1 steps/s
[Step=64000 Epoch=62.5] | Loss=0.00690 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.365 | L2-Norm(final)=11.828 | 4824.8 samples/s | 75.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step64000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=62001 Epoch=116.9] | Loss=0.00000 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.313 | L2-Norm(final)=14.708 | 4188.0 samples/s | 65.4 steps/s
[Step=62050 Epoch=117.0] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.311 | L2-Norm(final)=14.710 | 4929.4 samples/s | 77.0 steps/s
[Step=62100 Epoch=117.1] | Loss=0.00005 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.715 | 5302.6 samples/s | 82.9 steps/s
[Step=62150 Epoch=117.2] | Loss=0.00004 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.720 | 5340.3 samples/s | 83.4 steps/s
[Step=62200 Epoch=117.2] | Loss=0.00004 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.726 | 5177.8 samples/s | 80.9 steps/s
[Step=62250 Epoch=117.3] | Loss=0.00005 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.731 | 5335.2 samples/s | 83.4 steps/s
[Step=62300 Epoch=117.4] | Loss=0.00005 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.736 | 5260.9 samples/s | 82.2 steps/s
[Step=62350 Epoch=117.5] | Loss=0.00005 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.741 | 5292.0 samples/s | 82.7 steps/s
[Step=62400 Epoch=117.6] | Loss=0.00007 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.745 | 5239.2 samples/s | 81.9 steps/s
[Step=62450 Epoch=117.7] | Loss=0.00007 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.749 | 5309.6 samples/s | 83.0 steps/s
[Step=62500 Epoch=117.8] | Loss=0.00006 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.753 | 5370.6 samples/s | 83.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=117.8] | Loss=0.00110 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.310 | L2-Norm(final)=14.792 | 4116.5 samples/s | 64.3 steps/s
[Step=62550 Epoch=117.9] | Loss=0.00004 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.307 | L2-Norm(final)=14.795 | 4478.9 samples/s | 70.0 steps/s
[Step=62600 Epoch=118.0] | Loss=0.00003 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.298 | L2-Norm(final)=14.796 | 4589.9 samples/s | 71.7 steps/s
[Step=62650 Epoch=118.1] | Loss=0.00002 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.287 | L2-Norm(final)=14.796 | 4586.0 samples/s | 71.7 steps/s
[Step=62700 Epoch=118.2] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.275 | L2-Norm(final)=14.797 | 4615.7 samples/s | 72.1 steps/s
[Step=62750 Epoch=118.3] | Loss=0.00002 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.263 | L2-Norm(final)=14.797 | 4647.6 samples/s | 72.6 steps/s
[Step=62800 Epoch=118.4] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.253 | L2-Norm(final)=14.798 | 4626.5 samples/s | 72.3 steps/s
[Step=62850 Epoch=118.5] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.241 | L2-Norm(final)=14.798 | 4626.0 samples/s | 72.3 steps/s
[Step=62900 Epoch=118.6] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.230 | L2-Norm(final)=14.799 | 4576.6 samples/s | 71.5 steps/s
[Step=62950 Epoch=118.7] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.218 | L2-Norm(final)=14.799 | 4610.8 samples/s | 72.0 steps/s
[Step=63000 Epoch=118.8] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.207 | L2-Norm(final)=14.799 | 4684.9 samples/s | 73.2 steps/s
[Step=63050 Epoch=118.9] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.195 | L2-Norm(final)=14.799 | 2040.1 samples/s | 31.9 steps/s
[Step=63100 Epoch=118.9] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.183 | L2-Norm(final)=14.800 | 4785.8 samples/s | 74.8 steps/s
[Step=63150 Epoch=119.0] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.170 | L2-Norm(final)=14.800 | 4487.7 samples/s | 70.1 steps/s
[Step=63200 Epoch=119.1] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.158 | L2-Norm(final)=14.800 | 4571.1 samples/s | 71.4 steps/s
[Step=63250 Epoch=119.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.145 | L2-Norm(final)=14.800 | 4598.9 samples/s | 71.9 steps/s
[Step=63300 Epoch=119.3] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.133 | L2-Norm(final)=14.801 | 4618.3 samples/s | 72.2 steps/s
[Step=63350 Epoch=119.4] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.120 | L2-Norm(final)=14.801 | 4605.9 samples/s | 72.0 steps/s
[Step=63400 Epoch=119.5] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.107 | L2-Norm(final)=14.801 | 4578.2 samples/s | 71.5 steps/s
[Step=63450 Epoch=119.6] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.094 | L2-Norm(final)=14.801 | 4625.9 samples/s | 72.3 steps/s
[Step=63500 Epoch=119.7] | Loss=0.00000 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.081 | L2-Norm(final)=14.801 | 4598.5 samples/s | 71.9 steps/s
[Step=63550 Epoch=119.8] | Loss=0.00000 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.068 | L2-Norm(final)=14.802 | 5721.0 samples/s | 89.4 steps/s
[Step=63600 Epoch=119.9] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.054 | L2-Norm(final)=14.802 | 1954.7 samples/s | 30.5 steps/s
[Step=63650 Epoch=120.0] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.041 | L2-Norm(final)=14.802 | 4564.2 samples/s | 71.3 steps/s
[Step=63700 Epoch=120.1] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.027 | L2-Norm(final)=14.802 | 4576.2 samples/s | 71.5 steps/s
[Step=63750 Epoch=120.2] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.013 | L2-Norm(final)=14.802 | 4605.5 samples/s | 72.0 steps/s
[Step=63800 Epoch=120.3] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.999 | L2-Norm(final)=14.803 | 4610.9 samples/s | 72.0 steps/s
[Step=63850 Epoch=120.4] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.985 | L2-Norm(final)=14.803 | 4602.7 samples/s | 71.9 steps/s
[Step=63900 Epoch=120.5] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.971 | L2-Norm(final)=14.803 | 4622.6 samples/s | 72.2 steps/s
[Step=63950 Epoch=120.5] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.956 | L2-Norm(final)=14.803 | 4614.7 samples/s | 72.1 steps/s
[Step=64000 Epoch=120.6] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.941 | L2-Norm(final)=14.804 | 4637.0 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07088 | acc=0.9725 | tpr=0.9808 | fpr=0.0456 | 4249.3 samples/s | 16.6 steps/s
Avg test loss: 0.07095, Avg test acc: 0.97255, Avg tpr: 0.98082, Avg fpr: 0.04564, total FA: 356

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.91888 | acc=0.2866 | tpr=0.0073 | fpr=0.1070 | 4111.4 samples/s | 16.1 steps/s
Avg test loss: 8.90882, Avg test acc: 0.28360, Avg tpr: 0.00787, Avg fpr: 0.10999, total FA: 858

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.28426 | acc=0.1353 | tpr=0.3142 | fpr=0.8679 | 4250.0 samples/s | 16.6 steps/s
[Step= 100] | Loss=6.27823 | acc=0.1364 | tpr=0.2836 | fpr=0.8663 | 7978.2 samples/s | 31.2 steps/s
[Step= 150] | Loss=6.25866 | acc=0.1365 | tpr=0.2882 | fpr=0.8663 | 8016.3 samples/s | 31.3 steps/s
[Step= 200] | Loss=6.25144 | acc=0.1361 | tpr=0.2831 | fpr=0.8665 | 8154.5 samples/s | 31.9 steps/s
[Step= 250] | Loss=6.25399 | acc=0.1365 | tpr=0.2873 | fpr=0.8663 | 8012.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=6.25326 | acc=0.1369 | tpr=0.2975 | fpr=0.8661 | 7754.3 samples/s | 30.3 steps/s
[Step= 350] | Loss=6.24940 | acc=0.1368 | tpr=0.3024 | fpr=0.8662 | 8069.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.25155 | acc=0.1364 | tpr=0.3009 | fpr=0.8666 | 7992.0 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.25454 | acc=0.1361 | tpr=0.3019 | fpr=0.8669 | 7958.8 samples/s | 31.1 steps/s
[Step= 500] | Loss=6.25125 | acc=0.1361 | tpr=0.3018 | fpr=0.8668 | 8078.4 samples/s | 31.6 steps/s
[Step= 550] | Loss=6.25052 | acc=0.1361 | tpr=0.3052 | fpr=0.8669 | 14051.2 samples/s | 54.9 steps/s
Avg test loss: 6.25242, Avg test acc: 0.13605, Avg tpr: 0.30507, Avg fpr: 0.86702, total FA: 120384

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14668 | acc=0.9820 | tpr=0.9602 | fpr=0.0176 | 4203.2 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.15116 | acc=0.9818 | tpr=0.9616 | fpr=0.0178 | 7960.7 samples/s | 31.1 steps/s
[Step= 150] | Loss=0.15425 | acc=0.9813 | tpr=0.9625 | fpr=0.0184 | 8308.0 samples/s | 32.5 steps/s
[Step= 200] | Loss=0.15705 | acc=0.9814 | tpr=0.9617 | fpr=0.0183 | 7733.7 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.15500 | acc=0.9815 | tpr=0.9590 | fpr=0.0181 | 8060.9 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.15794 | acc=0.9810 | tpr=0.9578 | fpr=0.0185 | 8175.3 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.15744 | acc=0.9809 | tpr=0.9599 | fpr=0.0187 | 7907.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.15850 | acc=0.9807 | tpr=0.9590 | fpr=0.0189 | 8425.3 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.16098 | acc=0.9805 | tpr=0.9591 | fpr=0.0191 | 7530.0 samples/s | 29.4 steps/s
[Step= 500] | Loss=0.15999 | acc=0.9805 | tpr=0.9590 | fpr=0.0191 | 8002.2 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.15903 | acc=0.9807 | tpr=0.9578 | fpr=0.0189 | 14375.1 samples/s | 56.2 steps/s
Avg test loss: 0.15889, Avg test acc: 0.98072, Avg tpr: 0.95721, Avg fpr: 0.01886, total FA: 2618

server round 32/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=64001 Epoch=62.5] | Loss=0.00019 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.860 | 4055.7 samples/s | 63.4 steps/s
[Step=64050 Epoch=62.5] | Loss=0.00735 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.864 | 5377.7 samples/s | 84.0 steps/s
[Step=64100 Epoch=62.6] | Loss=0.00859 | Reg=0.00167 | acc=0.9688 | L2-Norm=12.926 | L2-Norm(final)=11.869 | 5565.9 samples/s | 87.0 steps/s
[Step=64150 Epoch=62.6] | Loss=0.00821 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.926 | L2-Norm(final)=11.873 | 5591.2 samples/s | 87.4 steps/s
[Step=64200 Epoch=62.7] | Loss=0.00822 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.877 | 5589.7 samples/s | 87.3 steps/s
[Step=64250 Epoch=62.7] | Loss=0.00797 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.881 | 5527.9 samples/s | 86.4 steps/s
[Step=64300 Epoch=62.8] | Loss=0.00820 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.885 | 5556.4 samples/s | 86.8 steps/s
[Step=64350 Epoch=62.8] | Loss=0.00812 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.888 | 5660.4 samples/s | 88.4 steps/s
[Step=64400 Epoch=62.9] | Loss=0.00806 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.926 | L2-Norm(final)=11.892 | 5655.4 samples/s | 88.4 steps/s
[Step=64450 Epoch=62.9] | Loss=0.00813 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.895 | 5438.4 samples/s | 85.0 steps/s
[Step=64500 Epoch=63.0] | Loss=0.00800 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.899 | 5537.8 samples/s | 86.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=63.0] | Loss=0.00370 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=11.936 | 4015.4 samples/s | 62.7 steps/s
[Step=64550 Epoch=63.0] | Loss=0.00786 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.931 | L2-Norm(final)=11.937 | 4629.8 samples/s | 72.3 steps/s
[Step=64600 Epoch=63.1] | Loss=0.00675 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.936 | L2-Norm(final)=11.937 | 4816.7 samples/s | 75.3 steps/s
[Step=64650 Epoch=63.1] | Loss=0.00625 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.939 | L2-Norm(final)=11.939 | 4813.1 samples/s | 75.2 steps/s
[Step=64700 Epoch=63.2] | Loss=0.00581 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.943 | L2-Norm(final)=11.941 | 4829.1 samples/s | 75.5 steps/s
[Step=64750 Epoch=63.2] | Loss=0.00670 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.945 | L2-Norm(final)=11.943 | 4823.5 samples/s | 75.4 steps/s
[Step=64800 Epoch=63.3] | Loss=0.00699 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.948 | L2-Norm(final)=11.944 | 4914.1 samples/s | 76.8 steps/s
[Step=64850 Epoch=63.3] | Loss=0.00721 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.951 | L2-Norm(final)=11.944 | 4756.7 samples/s | 74.3 steps/s
[Step=64900 Epoch=63.4] | Loss=0.00744 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.953 | L2-Norm(final)=11.945 | 4846.2 samples/s | 75.7 steps/s
[Step=64950 Epoch=63.4] | Loss=0.00751 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.956 | L2-Norm(final)=11.946 | 4822.2 samples/s | 75.3 steps/s
[Step=65000 Epoch=63.5] | Loss=0.00756 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.958 | L2-Norm(final)=11.948 | 4521.3 samples/s | 70.6 steps/s
[Step=65050 Epoch=63.5] | Loss=0.00738 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.961 | L2-Norm(final)=11.949 | 4368.6 samples/s | 68.3 steps/s
[Step=65100 Epoch=63.6] | Loss=0.00749 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.963 | L2-Norm(final)=11.950 | 4775.7 samples/s | 74.6 steps/s
[Step=65150 Epoch=63.6] | Loss=0.00747 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.965 | L2-Norm(final)=11.952 | 4880.6 samples/s | 76.3 steps/s
[Step=65200 Epoch=63.7] | Loss=0.00755 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.967 | L2-Norm(final)=11.953 | 4870.6 samples/s | 76.1 steps/s
[Step=65250 Epoch=63.7] | Loss=0.00757 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.969 | L2-Norm(final)=11.955 | 4847.3 samples/s | 75.7 steps/s
[Step=65300 Epoch=63.8] | Loss=0.00752 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.971 | L2-Norm(final)=11.956 | 4806.3 samples/s | 75.1 steps/s
[Step=65350 Epoch=63.8] | Loss=0.00749 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.973 | L2-Norm(final)=11.958 | 4815.0 samples/s | 75.2 steps/s
[Step=65400 Epoch=63.9] | Loss=0.00749 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.975 | L2-Norm(final)=11.959 | 4845.4 samples/s | 75.7 steps/s
[Step=65450 Epoch=63.9] | Loss=0.00745 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.977 | L2-Norm(final)=11.960 | 4796.8 samples/s | 75.0 steps/s
[Step=65500 Epoch=64.0] | Loss=0.00747 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.979 | L2-Norm(final)=11.962 | 5206.4 samples/s | 81.4 steps/s
[Step=65550 Epoch=64.0] | Loss=0.00749 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.981 | L2-Norm(final)=11.963 | 2131.2 samples/s | 33.3 steps/s
[Step=65600 Epoch=64.0] | Loss=0.00751 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.983 | L2-Norm(final)=11.964 | 4849.2 samples/s | 75.8 steps/s
[Step=65650 Epoch=64.1] | Loss=0.00745 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.984 | L2-Norm(final)=11.966 | 4878.0 samples/s | 76.2 steps/s
[Step=65700 Epoch=64.1] | Loss=0.00738 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.986 | L2-Norm(final)=11.967 | 4754.7 samples/s | 74.3 steps/s
[Step=65750 Epoch=64.2] | Loss=0.00735 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.988 | L2-Norm(final)=11.968 | 4816.4 samples/s | 75.3 steps/s
[Step=65800 Epoch=64.2] | Loss=0.00728 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.989 | L2-Norm(final)=11.970 | 4804.2 samples/s | 75.1 steps/s
[Step=65850 Epoch=64.3] | Loss=0.00727 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.991 | L2-Norm(final)=11.971 | 4887.9 samples/s | 76.4 steps/s
[Step=65900 Epoch=64.3] | Loss=0.00721 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.992 | L2-Norm(final)=11.972 | 4770.0 samples/s | 74.5 steps/s
[Step=65950 Epoch=64.4] | Loss=0.00717 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.994 | L2-Norm(final)=11.973 | 4818.6 samples/s | 75.3 steps/s
[Step=66000 Epoch=64.4] | Loss=0.00723 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.995 | L2-Norm(final)=11.975 | 4841.8 samples/s | 75.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step66000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=64001 Epoch=120.6] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=14.812 | 4070.6 samples/s | 63.6 steps/s
[Step=64050 Epoch=120.7] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.920 | L2-Norm(final)=14.813 | 5007.4 samples/s | 78.2 steps/s
[Step=64100 Epoch=120.8] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.920 | L2-Norm(final)=14.815 | 5253.5 samples/s | 82.1 steps/s
[Step=64150 Epoch=120.9] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.920 | L2-Norm(final)=14.817 | 5257.0 samples/s | 82.1 steps/s
[Step=64200 Epoch=121.0] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.820 | 5292.9 samples/s | 82.7 steps/s
[Step=64250 Epoch=121.1] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.822 | 5303.2 samples/s | 82.9 steps/s
[Step=64300 Epoch=121.2] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.824 | 5418.1 samples/s | 84.7 steps/s
[Step=64350 Epoch=121.3] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.826 | 5286.0 samples/s | 82.6 steps/s
[Step=64400 Epoch=121.4] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.828 | 5197.5 samples/s | 81.2 steps/s
[Step=64450 Epoch=121.5] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.830 | 5358.7 samples/s | 83.7 steps/s
[Step=64500 Epoch=121.6] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.832 | 5334.9 samples/s | 83.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=121.6] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=14.851 | 4006.9 samples/s | 62.6 steps/s
[Step=64550 Epoch=121.7] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.903 | L2-Norm(final)=14.852 | 4485.0 samples/s | 70.1 steps/s
[Step=64600 Epoch=121.8] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.880 | L2-Norm(final)=14.853 | 4631.7 samples/s | 72.4 steps/s
[Step=64650 Epoch=121.9] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.856 | L2-Norm(final)=14.854 | 4637.2 samples/s | 72.5 steps/s
[Step=64700 Epoch=122.0] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.832 | L2-Norm(final)=14.855 | 4576.9 samples/s | 71.5 steps/s
[Step=64750 Epoch=122.1] | Loss=0.00000 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.807 | L2-Norm(final)=14.855 | 4616.5 samples/s | 72.1 steps/s
[Step=64800 Epoch=122.1] | Loss=0.00000 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.782 | L2-Norm(final)=14.856 | 4670.6 samples/s | 73.0 steps/s
[Step=64850 Epoch=122.2] | Loss=0.00000 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.757 | L2-Norm(final)=14.857 | 4584.1 samples/s | 71.6 steps/s
[Step=64900 Epoch=122.3] | Loss=0.00000 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.731 | L2-Norm(final)=14.857 | 4591.8 samples/s | 71.7 steps/s
[Step=64950 Epoch=122.4] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.706 | L2-Norm(final)=14.858 | 4661.7 samples/s | 72.8 steps/s
[Step=65000 Epoch=122.5] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.680 | L2-Norm(final)=14.858 | 4621.9 samples/s | 72.2 steps/s
[Step=65050 Epoch=122.6] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.654 | L2-Norm(final)=14.859 | 2063.6 samples/s | 32.2 steps/s
[Step=65100 Epoch=122.7] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.628 | L2-Norm(final)=14.859 | 4722.0 samples/s | 73.8 steps/s
[Step=65150 Epoch=122.8] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.602 | L2-Norm(final)=14.860 | 4628.5 samples/s | 72.3 steps/s
[Step=65200 Epoch=122.9] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=14.861 | 4620.9 samples/s | 72.2 steps/s
[Step=65250 Epoch=123.0] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=14.861 | 4571.3 samples/s | 71.4 steps/s
[Step=65300 Epoch=123.1] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.523 | L2-Norm(final)=14.862 | 4600.0 samples/s | 71.9 steps/s
[Step=65350 Epoch=123.2] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.496 | L2-Norm(final)=14.862 | 4683.6 samples/s | 73.2 steps/s
[Step=65400 Epoch=123.3] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.469 | L2-Norm(final)=14.863 | 4525.0 samples/s | 70.7 steps/s
[Step=65450 Epoch=123.4] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.442 | L2-Norm(final)=14.864 | 4594.1 samples/s | 71.8 steps/s
[Step=65500 Epoch=123.5] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.414 | L2-Norm(final)=14.864 | 4597.3 samples/s | 71.8 steps/s
[Step=65550 Epoch=123.6] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.387 | L2-Norm(final)=14.865 | 5598.8 samples/s | 87.5 steps/s
[Step=65600 Epoch=123.7] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.359 | L2-Norm(final)=14.866 | 1962.2 samples/s | 30.7 steps/s
[Step=65650 Epoch=123.8] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.331 | L2-Norm(final)=14.866 | 4633.7 samples/s | 72.4 steps/s
[Step=65700 Epoch=123.8] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.303 | L2-Norm(final)=14.867 | 4522.3 samples/s | 70.7 steps/s
[Step=65750 Epoch=123.9] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.275 | L2-Norm(final)=14.868 | 4623.6 samples/s | 72.2 steps/s
[Step=65800 Epoch=124.0] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.247 | L2-Norm(final)=14.868 | 4606.2 samples/s | 72.0 steps/s
[Step=65850 Epoch=124.1] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.218 | L2-Norm(final)=14.869 | 4613.0 samples/s | 72.1 steps/s
[Step=65900 Epoch=124.2] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.189 | L2-Norm(final)=14.870 | 4577.1 samples/s | 71.5 steps/s
[Step=65950 Epoch=124.3] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.160 | L2-Norm(final)=14.871 | 4596.3 samples/s | 71.8 steps/s
[Step=66000 Epoch=124.4] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.131 | L2-Norm(final)=14.872 | 4592.0 samples/s | 71.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06528 | acc=0.9712 | tpr=0.9746 | fpr=0.0359 | 4039.3 samples/s | 15.8 steps/s
Avg test loss: 0.06629, Avg test acc: 0.97119, Avg tpr: 0.97447, Avg fpr: 0.03602, total FA: 281

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.70373 | acc=0.2666 | tpr=0.0207 | fpr=0.1995 | 4190.1 samples/s | 16.4 steps/s
Avg test loss: 6.68839, Avg test acc: 0.26160, Avg tpr: 0.02040, Avg fpr: 0.20792, total FA: 1622

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.12343 | acc=0.1541 | tpr=0.2345 | fpr=0.8473 | 4217.4 samples/s | 16.5 steps/s
[Step= 100] | Loss=5.11810 | acc=0.1557 | tpr=0.2217 | fpr=0.8455 | 8216.0 samples/s | 32.1 steps/s
[Step= 150] | Loss=5.09867 | acc=0.1568 | tpr=0.2334 | fpr=0.8446 | 7939.2 samples/s | 31.0 steps/s
[Step= 200] | Loss=5.09114 | acc=0.1572 | tpr=0.2295 | fpr=0.8441 | 7867.2 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.09274 | acc=0.1573 | tpr=0.2306 | fpr=0.8441 | 7924.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=5.09200 | acc=0.1576 | tpr=0.2378 | fpr=0.8439 | 7968.1 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.08886 | acc=0.1573 | tpr=0.2417 | fpr=0.8442 | 7904.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=5.09030 | acc=0.1574 | tpr=0.2440 | fpr=0.8442 | 8248.9 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.09274 | acc=0.1569 | tpr=0.2463 | fpr=0.8448 | 7666.8 samples/s | 29.9 steps/s
[Step= 500] | Loss=5.08945 | acc=0.1570 | tpr=0.2441 | fpr=0.8446 | 7928.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=5.08860 | acc=0.1569 | tpr=0.2467 | fpr=0.8447 | 14456.2 samples/s | 56.5 steps/s
Avg test loss: 5.09024, Avg test acc: 0.15676, Avg tpr: 0.24643, Avg fpr: 0.84487, total FA: 117308

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.18548 | acc=0.9757 | tpr=0.9735 | fpr=0.0243 | 4061.9 samples/s | 15.9 steps/s
[Step= 100] | Loss=0.19101 | acc=0.9752 | tpr=0.9787 | fpr=0.0249 | 8048.8 samples/s | 31.4 steps/s
[Step= 150] | Loss=0.19599 | acc=0.9744 | tpr=0.9769 | fpr=0.0256 | 8039.8 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.19981 | acc=0.9741 | tpr=0.9781 | fpr=0.0259 | 7923.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.19704 | acc=0.9744 | tpr=0.9747 | fpr=0.0256 | 7927.2 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.20077 | acc=0.9739 | tpr=0.9745 | fpr=0.0261 | 7968.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.20098 | acc=0.9738 | tpr=0.9756 | fpr=0.0262 | 8111.3 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.20250 | acc=0.9733 | tpr=0.9732 | fpr=0.0267 | 7857.4 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.20537 | acc=0.9731 | tpr=0.9727 | fpr=0.0269 | 8169.7 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.20451 | acc=0.9731 | tpr=0.9718 | fpr=0.0269 | 7720.8 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.20278 | acc=0.9734 | tpr=0.9713 | fpr=0.0266 | 15068.5 samples/s | 58.9 steps/s
Avg test loss: 0.20264, Avg test acc: 0.97342, Avg tpr: 0.97068, Avg fpr: 0.02653, total FA: 3683

server round 33/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=66001 Epoch=64.4] | Loss=0.00282 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.011 | 4312.3 samples/s | 67.4 steps/s
[Step=66050 Epoch=64.5] | Loss=0.00983 | Reg=0.00147 | acc=0.9844 | L2-Norm=12.107 | L2-Norm(final)=12.012 | 5213.3 samples/s | 81.5 steps/s
[Step=66100 Epoch=64.5] | Loss=0.01228 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.010 | 5535.2 samples/s | 86.5 steps/s
[Step=66150 Epoch=64.6] | Loss=0.01079 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.009 | 5693.9 samples/s | 89.0 steps/s
[Step=66200 Epoch=64.6] | Loss=0.01106 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.009 | 5436.0 samples/s | 84.9 steps/s
[Step=66250 Epoch=64.7] | Loss=0.01069 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.011 | 5703.2 samples/s | 89.1 steps/s
[Step=66300 Epoch=64.7] | Loss=0.01048 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.013 | 5685.2 samples/s | 88.8 steps/s
[Step=66350 Epoch=64.8] | Loss=0.01033 | Reg=0.00147 | acc=0.9844 | L2-Norm=12.107 | L2-Norm(final)=12.015 | 5400.7 samples/s | 84.4 steps/s
[Step=66400 Epoch=64.8] | Loss=0.01032 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.017 | 5618.0 samples/s | 87.8 steps/s
[Step=66450 Epoch=64.9] | Loss=0.01023 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.019 | 5611.8 samples/s | 87.7 steps/s
[Step=66500 Epoch=64.9] | Loss=0.01030 | Reg=0.00147 | acc=0.9844 | L2-Norm=12.107 | L2-Norm(final)=12.022 | 5714.7 samples/s | 89.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=64.9] | Loss=0.00217 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=12.048 | 3905.2 samples/s | 61.0 steps/s
[Step=66550 Epoch=65.0] | Loss=0.00927 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.116 | L2-Norm(final)=12.051 | 4678.9 samples/s | 73.1 steps/s
[Step=66600 Epoch=65.0] | Loss=0.00906 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.124 | L2-Norm(final)=12.053 | 4763.6 samples/s | 74.4 steps/s
[Step=66650 Epoch=65.1] | Loss=0.00868 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.131 | L2-Norm(final)=12.055 | 4920.1 samples/s | 76.9 steps/s
[Step=66700 Epoch=65.1] | Loss=0.00909 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.137 | L2-Norm(final)=12.057 | 4740.0 samples/s | 74.1 steps/s
[Step=66750 Epoch=65.2] | Loss=0.00865 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.142 | L2-Norm(final)=12.059 | 4873.9 samples/s | 76.2 steps/s
[Step=66800 Epoch=65.2] | Loss=0.00875 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.147 | L2-Norm(final)=12.061 | 4784.0 samples/s | 74.8 steps/s
[Step=66850 Epoch=65.3] | Loss=0.00881 | Reg=0.00148 | acc=0.9688 | L2-Norm=12.152 | L2-Norm(final)=12.063 | 4846.2 samples/s | 75.7 steps/s
[Step=66900 Epoch=65.3] | Loss=0.00880 | Reg=0.00148 | acc=0.9844 | L2-Norm=12.156 | L2-Norm(final)=12.065 | 4851.7 samples/s | 75.8 steps/s
[Step=66950 Epoch=65.4] | Loss=0.00884 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.161 | L2-Norm(final)=12.067 | 4895.4 samples/s | 76.5 steps/s
[Step=67000 Epoch=65.4] | Loss=0.00882 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.165 | L2-Norm(final)=12.070 | 4809.9 samples/s | 75.2 steps/s
[Step=67050 Epoch=65.5] | Loss=0.00904 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.169 | L2-Norm(final)=12.072 | 4825.3 samples/s | 75.4 steps/s
[Step=67100 Epoch=65.5] | Loss=0.00897 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.173 | L2-Norm(final)=12.075 | 4886.3 samples/s | 76.3 steps/s
[Step=67150 Epoch=65.6] | Loss=0.00880 | Reg=0.00148 | acc=0.9844 | L2-Norm=12.177 | L2-Norm(final)=12.077 | 4876.1 samples/s | 76.2 steps/s
[Step=67200 Epoch=65.6] | Loss=0.00891 | Reg=0.00148 | acc=0.9844 | L2-Norm=12.180 | L2-Norm(final)=12.080 | 4791.5 samples/s | 74.9 steps/s
[Step=67250 Epoch=65.7] | Loss=0.00890 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.184 | L2-Norm(final)=12.082 | 4817.0 samples/s | 75.3 steps/s
[Step=67300 Epoch=65.7] | Loss=0.00895 | Reg=0.00149 | acc=0.9844 | L2-Norm=12.187 | L2-Norm(final)=12.085 | 4832.4 samples/s | 75.5 steps/s
[Step=67350 Epoch=65.8] | Loss=0.00893 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.191 | L2-Norm(final)=12.087 | 4831.3 samples/s | 75.5 steps/s
[Step=67400 Epoch=65.8] | Loss=0.00897 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.194 | L2-Norm(final)=12.089 | 4831.4 samples/s | 75.5 steps/s
[Step=67450 Epoch=65.9] | Loss=0.00892 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.197 | L2-Norm(final)=12.091 | 4829.0 samples/s | 75.5 steps/s
[Step=67500 Epoch=65.9] | Loss=0.00890 | Reg=0.00149 | acc=0.9688 | L2-Norm=12.200 | L2-Norm(final)=12.093 | 5208.8 samples/s | 81.4 steps/s
[Step=67550 Epoch=66.0] | Loss=0.00877 | Reg=0.00149 | acc=0.9844 | L2-Norm=12.203 | L2-Norm(final)=12.095 | 2131.3 samples/s | 33.3 steps/s
[Step=67600 Epoch=66.0] | Loss=0.00864 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.206 | L2-Norm(final)=12.097 | 4864.6 samples/s | 76.0 steps/s
[Step=67650 Epoch=66.0] | Loss=0.00855 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.208 | L2-Norm(final)=12.099 | 4797.9 samples/s | 75.0 steps/s
[Step=67700 Epoch=66.1] | Loss=0.00848 | Reg=0.00149 | acc=0.9844 | L2-Norm=12.211 | L2-Norm(final)=12.101 | 4822.3 samples/s | 75.3 steps/s
[Step=67750 Epoch=66.1] | Loss=0.00843 | Reg=0.00149 | acc=0.9844 | L2-Norm=12.214 | L2-Norm(final)=12.103 | 4896.2 samples/s | 76.5 steps/s
[Step=67800 Epoch=66.2] | Loss=0.00837 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.216 | L2-Norm(final)=12.105 | 4825.8 samples/s | 75.4 steps/s
[Step=67850 Epoch=66.2] | Loss=0.00827 | Reg=0.00149 | acc=0.9688 | L2-Norm=12.219 | L2-Norm(final)=12.106 | 4836.3 samples/s | 75.6 steps/s
[Step=67900 Epoch=66.3] | Loss=0.00828 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.221 | L2-Norm(final)=12.108 | 4845.1 samples/s | 75.7 steps/s
[Step=67950 Epoch=66.3] | Loss=0.00828 | Reg=0.00149 | acc=0.9844 | L2-Norm=12.224 | L2-Norm(final)=12.110 | 4651.9 samples/s | 72.7 steps/s
[Step=68000 Epoch=66.4] | Loss=0.00826 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.226 | L2-Norm(final)=12.112 | 4794.4 samples/s | 74.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step68000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=66001 Epoch=124.4] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=14.898 | 3931.4 samples/s | 61.4 steps/s
[Step=66050 Epoch=124.5] | Loss=0.00008 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.101 | L2-Norm(final)=14.901 | 5107.7 samples/s | 79.8 steps/s
[Step=66100 Epoch=124.6] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.905 | 5254.1 samples/s | 82.1 steps/s
[Step=66150 Epoch=124.7] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.910 | 5338.5 samples/s | 83.4 steps/s
[Step=66200 Epoch=124.8] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.914 | 5269.2 samples/s | 82.3 steps/s
[Step=66250 Epoch=124.9] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.919 | 5341.7 samples/s | 83.5 steps/s
[Step=66300 Epoch=125.0] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.924 | 5255.9 samples/s | 82.1 steps/s
[Step=66350 Epoch=125.1] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.928 | 5295.5 samples/s | 82.7 steps/s
[Step=66400 Epoch=125.2] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.931 | 5294.0 samples/s | 82.7 steps/s
[Step=66450 Epoch=125.3] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.935 | 5352.9 samples/s | 83.6 steps/s
[Step=66500 Epoch=125.4] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.937 | 5328.7 samples/s | 83.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=125.4] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=14.964 | 3941.9 samples/s | 61.6 steps/s
[Step=66550 Epoch=125.4] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.075 | L2-Norm(final)=14.965 | 4536.3 samples/s | 70.9 steps/s
[Step=66600 Epoch=125.5] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.036 | L2-Norm(final)=14.965 | 4630.4 samples/s | 72.3 steps/s
[Step=66650 Epoch=125.6] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.996 | L2-Norm(final)=14.966 | 4553.8 samples/s | 71.2 steps/s
[Step=66700 Epoch=125.7] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=14.966 | 4586.9 samples/s | 71.7 steps/s
[Step=66750 Epoch=125.8] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.914 | L2-Norm(final)=14.966 | 4696.0 samples/s | 73.4 steps/s
[Step=66800 Epoch=125.9] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.873 | L2-Norm(final)=14.967 | 4536.2 samples/s | 70.9 steps/s
[Step=66850 Epoch=126.0] | Loss=0.00000 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.831 | L2-Norm(final)=14.967 | 4606.4 samples/s | 72.0 steps/s
[Step=66900 Epoch=126.1] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.790 | L2-Norm(final)=14.967 | 4628.7 samples/s | 72.3 steps/s
[Step=66950 Epoch=126.2] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.748 | L2-Norm(final)=14.967 | 4624.3 samples/s | 72.3 steps/s
[Step=67000 Epoch=126.3] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.707 | L2-Norm(final)=14.968 | 4594.8 samples/s | 71.8 steps/s
[Step=67050 Epoch=126.4] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.665 | L2-Norm(final)=14.968 | 2083.7 samples/s | 32.6 steps/s
[Step=67100 Epoch=126.5] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.623 | L2-Norm(final)=14.968 | 4671.1 samples/s | 73.0 steps/s
[Step=67150 Epoch=126.6] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.582 | L2-Norm(final)=14.968 | 4609.2 samples/s | 72.0 steps/s
[Step=67200 Epoch=126.7] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.540 | L2-Norm(final)=14.969 | 4570.4 samples/s | 71.4 steps/s
[Step=67250 Epoch=126.8] | Loss=0.00001 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.498 | L2-Norm(final)=14.969 | 4641.9 samples/s | 72.5 steps/s
[Step=67300 Epoch=126.9] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.462 | L2-Norm(final)=14.969 | 4639.9 samples/s | 72.5 steps/s
[Step=67350 Epoch=127.0] | Loss=0.00005 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.432 | L2-Norm(final)=14.969 | 4589.8 samples/s | 71.7 steps/s
[Step=67400 Epoch=127.0] | Loss=0.00005 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.406 | L2-Norm(final)=14.969 | 4614.5 samples/s | 72.1 steps/s
[Step=67450 Epoch=127.1] | Loss=0.00005 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.382 | L2-Norm(final)=14.969 | 4624.0 samples/s | 72.2 steps/s
[Step=67500 Epoch=127.2] | Loss=0.00005 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=14.969 | 4655.6 samples/s | 72.7 steps/s
[Step=67550 Epoch=127.3] | Loss=0.00005 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.340 | L2-Norm(final)=14.969 | 5663.8 samples/s | 88.5 steps/s
[Step=67600 Epoch=127.4] | Loss=0.00007 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=14.969 | 1957.5 samples/s | 30.6 steps/s
[Step=67650 Epoch=127.5] | Loss=0.00008 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.306 | L2-Norm(final)=14.970 | 4619.4 samples/s | 72.2 steps/s
[Step=67700 Epoch=127.6] | Loss=0.00007 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.291 | L2-Norm(final)=14.970 | 4647.0 samples/s | 72.6 steps/s
[Step=67750 Epoch=127.7] | Loss=0.00007 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.278 | L2-Norm(final)=14.970 | 4568.8 samples/s | 71.4 steps/s
[Step=67800 Epoch=127.8] | Loss=0.00007 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.265 | L2-Norm(final)=14.970 | 4660.6 samples/s | 72.8 steps/s
[Step=67850 Epoch=127.9] | Loss=0.00007 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.253 | L2-Norm(final)=14.970 | 4558.4 samples/s | 71.2 steps/s
[Step=67900 Epoch=128.0] | Loss=0.00007 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.242 | L2-Norm(final)=14.970 | 4648.8 samples/s | 72.6 steps/s
[Step=67950 Epoch=128.1] | Loss=0.00006 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.231 | L2-Norm(final)=14.971 | 4590.7 samples/s | 71.7 steps/s
[Step=68000 Epoch=128.2] | Loss=0.00006 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.222 | L2-Norm(final)=14.971 | 4619.0 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06286 | acc=0.9709 | tpr=0.9759 | fpr=0.0401 | 4152.5 samples/s | 16.2 steps/s
Avg test loss: 0.06407, Avg test acc: 0.97059, Avg tpr: 0.97587, Avg fpr: 0.04102, total FA: 320

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.04887 | acc=0.3061 | tpr=0.0049 | fpr=0.0399 | 4205.5 samples/s | 16.4 steps/s
Avg test loss: 9.04433, Avg test acc: 0.30155, Avg tpr: 0.00490, Avg fpr: 0.04602, total FA: 359

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.87147 | acc=0.1494 | tpr=0.3097 | fpr=0.8535 | 4215.8 samples/s | 16.5 steps/s
[Step= 100] | Loss=4.86073 | acc=0.1502 | tpr=0.2857 | fpr=0.8524 | 7846.3 samples/s | 30.6 steps/s
[Step= 150] | Loss=4.84862 | acc=0.1511 | tpr=0.2983 | fpr=0.8516 | 8167.5 samples/s | 31.9 steps/s
[Step= 200] | Loss=4.84209 | acc=0.1509 | tpr=0.2874 | fpr=0.8516 | 7955.5 samples/s | 31.1 steps/s
[Step= 250] | Loss=4.84386 | acc=0.1510 | tpr=0.2865 | fpr=0.8515 | 7941.5 samples/s | 31.0 steps/s
[Step= 300] | Loss=4.84360 | acc=0.1512 | tpr=0.2924 | fpr=0.8513 | 8051.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=4.83996 | acc=0.1508 | tpr=0.2974 | fpr=0.8519 | 7817.1 samples/s | 30.5 steps/s
[Step= 400] | Loss=4.84139 | acc=0.1506 | tpr=0.2970 | fpr=0.8521 | 8114.6 samples/s | 31.7 steps/s
[Step= 450] | Loss=4.84379 | acc=0.1503 | tpr=0.3033 | fpr=0.8524 | 7885.3 samples/s | 30.8 steps/s
[Step= 500] | Loss=4.84172 | acc=0.1503 | tpr=0.3018 | fpr=0.8524 | 8541.2 samples/s | 33.4 steps/s
[Step= 550] | Loss=4.84190 | acc=0.1501 | tpr=0.3044 | fpr=0.8527 | 13094.7 samples/s | 51.2 steps/s
Avg test loss: 4.84354, Avg test acc: 0.14995, Avg tpr: 0.30428, Avg fpr: 0.85285, total FA: 118417

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12845 | acc=0.9833 | tpr=0.9558 | fpr=0.0162 | 4170.2 samples/s | 16.3 steps/s
[Step= 100] | Loss=0.13353 | acc=0.9825 | tpr=0.9638 | fpr=0.0172 | 8006.9 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.13801 | acc=0.9818 | tpr=0.9654 | fpr=0.0179 | 7966.1 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.14159 | acc=0.9817 | tpr=0.9661 | fpr=0.0180 | 7941.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.13916 | acc=0.9819 | tpr=0.9651 | fpr=0.0178 | 7980.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14164 | acc=0.9817 | tpr=0.9629 | fpr=0.0180 | 8059.8 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.14146 | acc=0.9816 | tpr=0.9631 | fpr=0.0181 | 8161.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.14267 | acc=0.9815 | tpr=0.9612 | fpr=0.0182 | 7782.7 samples/s | 30.4 steps/s
[Step= 450] | Loss=0.14526 | acc=0.9812 | tpr=0.9601 | fpr=0.0184 | 7152.2 samples/s | 27.9 steps/s
[Step= 500] | Loss=0.14415 | acc=0.9813 | tpr=0.9604 | fpr=0.0183 | 7595.3 samples/s | 29.7 steps/s
[Step= 550] | Loss=0.14300 | acc=0.9815 | tpr=0.9598 | fpr=0.0181 | 14376.1 samples/s | 56.2 steps/s
Avg test loss: 0.14278, Avg test acc: 0.98155, Avg tpr: 0.95919, Avg fpr: 0.01804, total FA: 2505

server round 34/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=68001 Epoch=66.4] | Loss=0.01816 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.562 | L2-Norm(final)=12.165 | 4435.5 samples/s | 69.3 steps/s
[Step=68050 Epoch=66.4] | Loss=0.01310 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=12.175 | 5073.2 samples/s | 79.3 steps/s
[Step=68100 Epoch=66.5] | Loss=0.01478 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.563 | L2-Norm(final)=12.186 | 5637.3 samples/s | 88.1 steps/s
[Step=68150 Epoch=66.5] | Loss=0.01597 | Reg=0.00134 | acc=0.9688 | L2-Norm=11.563 | L2-Norm(final)=12.196 | 5581.8 samples/s | 87.2 steps/s
[Step=68200 Epoch=66.6] | Loss=0.01606 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=12.203 | 5571.6 samples/s | 87.1 steps/s
[Step=68250 Epoch=66.6] | Loss=0.01574 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=12.211 | 5578.2 samples/s | 87.2 steps/s
[Step=68300 Epoch=66.7] | Loss=0.01586 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=12.218 | 5679.0 samples/s | 88.7 steps/s
[Step=68350 Epoch=66.7] | Loss=0.01572 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=12.226 | 5499.4 samples/s | 85.9 steps/s
[Step=68400 Epoch=66.8] | Loss=0.01624 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.563 | L2-Norm(final)=12.232 | 5803.8 samples/s | 90.7 steps/s
[Step=68450 Epoch=66.8] | Loss=0.01652 | Reg=0.00134 | acc=0.9688 | L2-Norm=11.563 | L2-Norm(final)=12.239 | 5523.7 samples/s | 86.3 steps/s
[Step=68500 Epoch=66.9] | Loss=0.01636 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.563 | L2-Norm(final)=12.245 | 5514.1 samples/s | 86.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=66.9] | Loss=0.04544 | Reg=0.00134 | acc=0.9531 | L2-Norm=11.563 | L2-Norm(final)=12.307 | 3842.2 samples/s | 60.0 steps/s
[Step=68550 Epoch=66.9] | Loss=0.01309 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.576 | L2-Norm(final)=12.313 | 4738.7 samples/s | 74.0 steps/s
[Step=68600 Epoch=67.0] | Loss=0.01167 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.586 | L2-Norm(final)=12.317 | 4847.4 samples/s | 75.7 steps/s
[Step=68650 Epoch=67.0] | Loss=0.01209 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.595 | L2-Norm(final)=12.319 | 4799.1 samples/s | 75.0 steps/s
[Step=68700 Epoch=67.1] | Loss=0.01175 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.603 | L2-Norm(final)=12.321 | 4832.4 samples/s | 75.5 steps/s
[Step=68750 Epoch=67.1] | Loss=0.01134 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.609 | L2-Norm(final)=12.323 | 4931.2 samples/s | 77.1 steps/s
[Step=68800 Epoch=67.2] | Loss=0.01120 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.615 | L2-Norm(final)=12.326 | 4836.5 samples/s | 75.6 steps/s
[Step=68850 Epoch=67.2] | Loss=0.01128 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.621 | L2-Norm(final)=12.328 | 4832.7 samples/s | 75.5 steps/s
[Step=68900 Epoch=67.3] | Loss=0.01092 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.626 | L2-Norm(final)=12.330 | 4838.1 samples/s | 75.6 steps/s
[Step=68950 Epoch=67.3] | Loss=0.01081 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.631 | L2-Norm(final)=12.332 | 4891.1 samples/s | 76.4 steps/s
[Step=69000 Epoch=67.4] | Loss=0.01074 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.635 | L2-Norm(final)=12.333 | 4847.9 samples/s | 75.7 steps/s
[Step=69050 Epoch=67.4] | Loss=0.01076 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.639 | L2-Norm(final)=12.335 | 4814.9 samples/s | 75.2 steps/s
[Step=69100 Epoch=67.5] | Loss=0.01065 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.643 | L2-Norm(final)=12.337 | 4860.1 samples/s | 75.9 steps/s
[Step=69150 Epoch=67.5] | Loss=0.01047 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.647 | L2-Norm(final)=12.339 | 4847.3 samples/s | 75.7 steps/s
[Step=69200 Epoch=67.6] | Loss=0.01056 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.651 | L2-Norm(final)=12.341 | 4822.5 samples/s | 75.4 steps/s
[Step=69250 Epoch=67.6] | Loss=0.01043 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.654 | L2-Norm(final)=12.343 | 4843.3 samples/s | 75.7 steps/s
[Step=69300 Epoch=67.7] | Loss=0.01046 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.658 | L2-Norm(final)=12.345 | 4822.5 samples/s | 75.4 steps/s
[Step=69350 Epoch=67.7] | Loss=0.01039 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.661 | L2-Norm(final)=12.346 | 4858.1 samples/s | 75.9 steps/s
[Step=69400 Epoch=67.8] | Loss=0.01031 | Reg=0.00136 | acc=0.9688 | L2-Norm=11.665 | L2-Norm(final)=12.348 | 4841.7 samples/s | 75.7 steps/s
[Step=69450 Epoch=67.8] | Loss=0.01027 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.668 | L2-Norm(final)=12.350 | 4843.6 samples/s | 75.7 steps/s
[Step=69500 Epoch=67.9] | Loss=0.01025 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.671 | L2-Norm(final)=12.352 | 5209.2 samples/s | 81.4 steps/s
[Step=69550 Epoch=67.9] | Loss=0.01017 | Reg=0.00136 | acc=0.9688 | L2-Norm=11.674 | L2-Norm(final)=12.354 | 2118.9 samples/s | 33.1 steps/s
[Step=69600 Epoch=68.0] | Loss=0.01003 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.677 | L2-Norm(final)=12.356 | 4886.0 samples/s | 76.3 steps/s
[Step=69650 Epoch=68.0] | Loss=0.00985 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.680 | L2-Norm(final)=12.358 | 4826.8 samples/s | 75.4 steps/s
[Step=69700 Epoch=68.1] | Loss=0.00972 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.683 | L2-Norm(final)=12.360 | 4851.1 samples/s | 75.8 steps/s
[Step=69750 Epoch=68.1] | Loss=0.00959 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.686 | L2-Norm(final)=12.362 | 4849.2 samples/s | 75.8 steps/s
[Step=69800 Epoch=68.1] | Loss=0.00952 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.688 | L2-Norm(final)=12.364 | 4816.0 samples/s | 75.3 steps/s
[Step=69850 Epoch=68.2] | Loss=0.00940 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.691 | L2-Norm(final)=12.366 | 4846.0 samples/s | 75.7 steps/s
[Step=69900 Epoch=68.2] | Loss=0.00944 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.694 | L2-Norm(final)=12.367 | 4849.2 samples/s | 75.8 steps/s
[Step=69950 Epoch=68.3] | Loss=0.00942 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.696 | L2-Norm(final)=12.369 | 4861.1 samples/s | 76.0 steps/s
[Step=70000 Epoch=68.3] | Loss=0.00935 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.699 | L2-Norm(final)=12.371 | 4862.5 samples/s | 76.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step70000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=68001 Epoch=128.2] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.979 | 3945.5 samples/s | 61.6 steps/s
[Step=68050 Epoch=128.3] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.980 | 4994.9 samples/s | 78.0 steps/s
[Step=68100 Epoch=128.4] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.980 | 5243.2 samples/s | 81.9 steps/s
[Step=68150 Epoch=128.5] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.981 | 5295.2 samples/s | 82.7 steps/s
[Step=68200 Epoch=128.6] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.982 | 5305.2 samples/s | 82.9 steps/s
[Step=68250 Epoch=128.7] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.982 | 5289.1 samples/s | 82.6 steps/s
[Step=68300 Epoch=128.7] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.982 | 5273.0 samples/s | 82.4 steps/s
[Step=68350 Epoch=128.8] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.983 | 5308.6 samples/s | 82.9 steps/s
[Step=68400 Epoch=128.9] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.983 | 5463.2 samples/s | 85.4 steps/s
[Step=68450 Epoch=129.0] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.984 | 5161.3 samples/s | 80.6 steps/s
[Step=68500 Epoch=129.1] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.984 | 5275.4 samples/s | 82.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=129.1] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=14.989 | 4353.4 samples/s | 68.0 steps/s
[Step=68550 Epoch=129.2] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.559 | L2-Norm(final)=14.990 | 3994.3 samples/s | 62.4 steps/s
[Step=68600 Epoch=129.3] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.556 | L2-Norm(final)=14.990 | 4689.1 samples/s | 73.3 steps/s
[Step=68650 Epoch=129.4] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.553 | L2-Norm(final)=14.991 | 4556.5 samples/s | 71.2 steps/s
[Step=68700 Epoch=129.5] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.550 | L2-Norm(final)=14.991 | 4636.0 samples/s | 72.4 steps/s
[Step=68750 Epoch=129.6] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.547 | L2-Norm(final)=14.992 | 4592.2 samples/s | 71.8 steps/s
[Step=68800 Epoch=129.7] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.544 | L2-Norm(final)=14.992 | 4590.5 samples/s | 71.7 steps/s
[Step=68850 Epoch=129.8] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.541 | L2-Norm(final)=14.993 | 4648.4 samples/s | 72.6 steps/s
[Step=68900 Epoch=129.9] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=14.993 | 4635.3 samples/s | 72.4 steps/s
[Step=68950 Epoch=130.0] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=14.993 | 4616.0 samples/s | 72.1 steps/s
[Step=69000 Epoch=130.1] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.532 | L2-Norm(final)=14.994 | 4663.9 samples/s | 72.9 steps/s
[Step=69050 Epoch=130.2] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.529 | L2-Norm(final)=14.994 | 2113.9 samples/s | 33.0 steps/s
[Step=69100 Epoch=130.3] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.526 | L2-Norm(final)=14.995 | 4634.7 samples/s | 72.4 steps/s
[Step=69150 Epoch=130.3] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.523 | L2-Norm(final)=14.995 | 4560.6 samples/s | 71.3 steps/s
[Step=69200 Epoch=130.4] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.520 | L2-Norm(final)=14.996 | 4637.3 samples/s | 72.5 steps/s
[Step=69250 Epoch=130.5] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.517 | L2-Norm(final)=14.996 | 4613.3 samples/s | 72.1 steps/s
[Step=69300 Epoch=130.6] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.514 | L2-Norm(final)=14.996 | 4607.7 samples/s | 72.0 steps/s
[Step=69350 Epoch=130.7] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.510 | L2-Norm(final)=14.997 | 4664.2 samples/s | 72.9 steps/s
[Step=69400 Epoch=130.8] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.507 | L2-Norm(final)=14.997 | 4605.2 samples/s | 72.0 steps/s
[Step=69450 Epoch=130.9] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.504 | L2-Norm(final)=14.997 | 4608.3 samples/s | 72.0 steps/s
[Step=69500 Epoch=131.0] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.500 | L2-Norm(final)=14.997 | 4631.9 samples/s | 72.4 steps/s
[Step=69550 Epoch=131.1] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.497 | L2-Norm(final)=14.998 | 5697.3 samples/s | 89.0 steps/s
[Step=69600 Epoch=131.2] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.493 | L2-Norm(final)=14.998 | 1962.9 samples/s | 30.7 steps/s
[Step=69650 Epoch=131.3] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.490 | L2-Norm(final)=14.998 | 4606.3 samples/s | 72.0 steps/s
[Step=69700 Epoch=131.4] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.486 | L2-Norm(final)=14.998 | 4610.7 samples/s | 72.0 steps/s
[Step=69750 Epoch=131.5] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.482 | L2-Norm(final)=14.999 | 4616.3 samples/s | 72.1 steps/s
[Step=69800 Epoch=131.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=14.999 | 4558.6 samples/s | 71.2 steps/s
[Step=69850 Epoch=131.7] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.474 | L2-Norm(final)=14.999 | 4628.8 samples/s | 72.3 steps/s
[Step=69900 Epoch=131.8] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.471 | L2-Norm(final)=14.999 | 4664.4 samples/s | 72.9 steps/s
[Step=69950 Epoch=131.9] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.467 | L2-Norm(final)=14.999 | 4615.1 samples/s | 72.1 steps/s
[Step=70000 Epoch=132.0] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.463 | L2-Norm(final)=15.000 | 4605.5 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05882 | acc=0.9724 | tpr=0.9781 | fpr=0.0399 | 4178.6 samples/s | 16.3 steps/s
Avg test loss: 0.06055, Avg test acc: 0.97207, Avg tpr: 0.97744, Avg fpr: 0.03974, total FA: 310

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.66092 | acc=0.2908 | tpr=0.0095 | fpr=0.0984 | 4270.4 samples/s | 16.7 steps/s
Avg test loss: 7.64962, Avg test acc: 0.28696, Avg tpr: 0.00921, Avg fpr: 0.10217, total FA: 797

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.81873 | acc=0.1406 | tpr=0.2699 | fpr=0.8617 | 4198.0 samples/s | 16.4 steps/s
[Step= 100] | Loss=4.80577 | acc=0.1412 | tpr=0.2580 | fpr=0.8610 | 7933.8 samples/s | 31.0 steps/s
[Step= 150] | Loss=4.79132 | acc=0.1421 | tpr=0.2695 | fpr=0.8602 | 7874.6 samples/s | 30.8 steps/s
[Step= 200] | Loss=4.78588 | acc=0.1413 | tpr=0.2557 | fpr=0.8608 | 7935.7 samples/s | 31.0 steps/s
[Step= 250] | Loss=4.78832 | acc=0.1414 | tpr=0.2568 | fpr=0.8607 | 8035.1 samples/s | 31.4 steps/s
[Step= 300] | Loss=4.78691 | acc=0.1416 | tpr=0.2640 | fpr=0.8606 | 8082.4 samples/s | 31.6 steps/s
[Step= 350] | Loss=4.78355 | acc=0.1415 | tpr=0.2649 | fpr=0.8607 | 7935.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=4.78537 | acc=0.1414 | tpr=0.2659 | fpr=0.8609 | 7956.4 samples/s | 31.1 steps/s
[Step= 450] | Loss=4.78777 | acc=0.1412 | tpr=0.2717 | fpr=0.8612 | 7818.7 samples/s | 30.5 steps/s
[Step= 500] | Loss=4.78623 | acc=0.1411 | tpr=0.2709 | fpr=0.8613 | 7807.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=4.78664 | acc=0.1408 | tpr=0.2746 | fpr=0.8616 | 15240.5 samples/s | 59.5 steps/s
Avg test loss: 4.78807, Avg test acc: 0.14070, Avg tpr: 0.27417, Avg fpr: 0.86173, total FA: 119649

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13948 | acc=0.9805 | tpr=0.9602 | fpr=0.0192 | 4210.8 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.14524 | acc=0.9802 | tpr=0.9659 | fpr=0.0195 | 7882.3 samples/s | 30.8 steps/s
[Step= 150] | Loss=0.14885 | acc=0.9793 | tpr=0.9669 | fpr=0.0204 | 8718.5 samples/s | 34.1 steps/s
[Step= 200] | Loss=0.15189 | acc=0.9794 | tpr=0.9694 | fpr=0.0205 | 7563.6 samples/s | 29.5 steps/s
[Step= 250] | Loss=0.14960 | acc=0.9797 | tpr=0.9686 | fpr=0.0201 | 7818.1 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.15247 | acc=0.9794 | tpr=0.9680 | fpr=0.0204 | 8393.9 samples/s | 32.8 steps/s
[Step= 350] | Loss=0.15211 | acc=0.9793 | tpr=0.9687 | fpr=0.0205 | 7871.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.15335 | acc=0.9792 | tpr=0.9666 | fpr=0.0206 | 7914.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.15575 | acc=0.9789 | tpr=0.9659 | fpr=0.0208 | 8168.1 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.15474 | acc=0.9790 | tpr=0.9656 | fpr=0.0208 | 7728.1 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.15352 | acc=0.9792 | tpr=0.9650 | fpr=0.0205 | 14773.3 samples/s | 57.7 steps/s
Avg test loss: 0.15337, Avg test acc: 0.97923, Avg tpr: 0.96434, Avg fpr: 0.02050, total FA: 2847

server round 35/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=70001 Epoch=68.3] | Loss=0.00588 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.537 | L2-Norm(final)=12.426 | 4614.9 samples/s | 72.1 steps/s
[Step=70050 Epoch=68.4] | Loss=0.00947 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=12.430 | 4953.9 samples/s | 77.4 steps/s
[Step=70100 Epoch=68.4] | Loss=0.00937 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=12.435 | 5527.3 samples/s | 86.4 steps/s
[Step=70150 Epoch=68.5] | Loss=0.00929 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.440 | 5645.9 samples/s | 88.2 steps/s
[Step=70200 Epoch=68.5] | Loss=0.00982 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=12.445 | 5615.9 samples/s | 87.7 steps/s
[Step=70250 Epoch=68.6] | Loss=0.00956 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.451 | 5512.5 samples/s | 86.1 steps/s
[Step=70300 Epoch=68.6] | Loss=0.00929 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.456 | 5705.9 samples/s | 89.2 steps/s
[Step=70350 Epoch=68.7] | Loss=0.00919 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.462 | 5556.9 samples/s | 86.8 steps/s
[Step=70400 Epoch=68.7] | Loss=0.00922 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.467 | 5577.2 samples/s | 87.1 steps/s
[Step=70450 Epoch=68.8] | Loss=0.00891 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.538 | L2-Norm(final)=12.472 | 5697.5 samples/s | 89.0 steps/s
[Step=70500 Epoch=68.8] | Loss=0.00885 | Reg=0.00133 | acc=0.9688 | L2-Norm=11.538 | L2-Norm(final)=12.477 | 5508.6 samples/s | 86.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=68.8] | Loss=0.01776 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=12.529 | 4259.1 samples/s | 66.5 steps/s
[Step=70550 Epoch=68.9] | Loss=0.00902 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.545 | L2-Norm(final)=12.533 | 4618.7 samples/s | 72.2 steps/s
[Step=70600 Epoch=68.9] | Loss=0.00927 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.552 | L2-Norm(final)=12.536 | 4802.1 samples/s | 75.0 steps/s
[Step=70650 Epoch=69.0] | Loss=0.00893 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.558 | L2-Norm(final)=12.538 | 4866.2 samples/s | 76.0 steps/s
[Step=70700 Epoch=69.0] | Loss=0.00862 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.564 | L2-Norm(final)=12.541 | 4892.0 samples/s | 76.4 steps/s
[Step=70750 Epoch=69.1] | Loss=0.00859 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.568 | L2-Norm(final)=12.543 | 4786.2 samples/s | 74.8 steps/s
[Step=70800 Epoch=69.1] | Loss=0.00840 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.573 | L2-Norm(final)=12.546 | 4870.6 samples/s | 76.1 steps/s
[Step=70850 Epoch=69.2] | Loss=0.00900 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.577 | L2-Norm(final)=12.549 | 4817.5 samples/s | 75.3 steps/s
[Step=70900 Epoch=69.2] | Loss=0.00909 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.581 | L2-Norm(final)=12.551 | 4839.7 samples/s | 75.6 steps/s
[Step=70950 Epoch=69.3] | Loss=0.00889 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.585 | L2-Norm(final)=12.553 | 4867.3 samples/s | 76.1 steps/s
[Step=71000 Epoch=69.3] | Loss=0.00901 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.589 | L2-Norm(final)=12.555 | 4857.9 samples/s | 75.9 steps/s
[Step=71050 Epoch=69.4] | Loss=0.00883 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.592 | L2-Norm(final)=12.557 | 4781.5 samples/s | 74.7 steps/s
[Step=71100 Epoch=69.4] | Loss=0.00876 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.595 | L2-Norm(final)=12.560 | 4859.5 samples/s | 75.9 steps/s
[Step=71150 Epoch=69.5] | Loss=0.00902 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.599 | L2-Norm(final)=12.562 | 4836.1 samples/s | 75.6 steps/s
[Step=71200 Epoch=69.5] | Loss=0.00880 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.602 | L2-Norm(final)=12.564 | 4849.3 samples/s | 75.8 steps/s
[Step=71250 Epoch=69.6] | Loss=0.00865 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.605 | L2-Norm(final)=12.566 | 4879.2 samples/s | 76.2 steps/s
[Step=71300 Epoch=69.6] | Loss=0.00869 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.608 | L2-Norm(final)=12.568 | 4822.7 samples/s | 75.4 steps/s
[Step=71350 Epoch=69.7] | Loss=0.00862 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.611 | L2-Norm(final)=12.571 | 4833.1 samples/s | 75.5 steps/s
[Step=71400 Epoch=69.7] | Loss=0.00867 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.613 | L2-Norm(final)=12.573 | 4873.8 samples/s | 76.2 steps/s
[Step=71450 Epoch=69.8] | Loss=0.00877 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.616 | L2-Norm(final)=12.575 | 4801.8 samples/s | 75.0 steps/s
[Step=71500 Epoch=69.8] | Loss=0.00878 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.619 | L2-Norm(final)=12.577 | 5176.0 samples/s | 80.9 steps/s
[Step=71550 Epoch=69.9] | Loss=0.00882 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.622 | L2-Norm(final)=12.579 | 2080.7 samples/s | 32.5 steps/s
[Step=71600 Epoch=69.9] | Loss=0.00879 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.624 | L2-Norm(final)=12.581 | 4768.5 samples/s | 74.5 steps/s
[Step=71650 Epoch=70.0] | Loss=0.00871 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.627 | L2-Norm(final)=12.583 | 4823.2 samples/s | 75.4 steps/s
[Step=71700 Epoch=70.0] | Loss=0.00864 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.630 | L2-Norm(final)=12.585 | 4816.7 samples/s | 75.3 steps/s
[Step=71750 Epoch=70.1] | Loss=0.00863 | Reg=0.00135 | acc=0.9688 | L2-Norm=11.632 | L2-Norm(final)=12.588 | 4812.3 samples/s | 75.2 steps/s
[Step=71800 Epoch=70.1] | Loss=0.00853 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.635 | L2-Norm(final)=12.590 | 4847.3 samples/s | 75.7 steps/s
[Step=71850 Epoch=70.1] | Loss=0.00846 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.637 | L2-Norm(final)=12.592 | 4835.8 samples/s | 75.6 steps/s
[Step=71900 Epoch=70.2] | Loss=0.00845 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.640 | L2-Norm(final)=12.594 | 4829.6 samples/s | 75.5 steps/s
[Step=71950 Epoch=70.2] | Loss=0.00842 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.642 | L2-Norm(final)=12.596 | 4917.5 samples/s | 76.8 steps/s
[Step=72000 Epoch=70.3] | Loss=0.00840 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.644 | L2-Norm(final)=12.598 | 4813.5 samples/s | 75.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step72000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=70001 Epoch=132.0] | Loss=0.00002 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.537 | L2-Norm(final)=15.006 | 4430.0 samples/s | 69.2 steps/s
[Step=70050 Epoch=132.0] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.536 | L2-Norm(final)=15.007 | 4336.5 samples/s | 67.8 steps/s
[Step=70100 Epoch=132.1] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.009 | 5290.0 samples/s | 82.7 steps/s
[Step=70150 Epoch=132.2] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.012 | 5348.3 samples/s | 83.6 steps/s
[Step=70200 Epoch=132.3] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.014 | 5211.2 samples/s | 81.4 steps/s
[Step=70250 Epoch=132.4] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.016 | 5232.8 samples/s | 81.8 steps/s
[Step=70300 Epoch=132.5] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.018 | 5374.8 samples/s | 84.0 steps/s
[Step=70350 Epoch=132.6] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.020 | 5343.0 samples/s | 83.5 steps/s
[Step=70400 Epoch=132.7] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.022 | 5219.1 samples/s | 81.5 steps/s
[Step=70450 Epoch=132.8] | Loss=0.00002 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.024 | 5247.9 samples/s | 82.0 steps/s
[Step=70500 Epoch=132.9] | Loss=0.00002 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.027 | 5402.4 samples/s | 84.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=132.9] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=15.050 | 4108.4 samples/s | 64.2 steps/s
[Step=70550 Epoch=133.0] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.530 | L2-Norm(final)=15.052 | 4378.4 samples/s | 68.4 steps/s
[Step=70600 Epoch=133.1] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.524 | L2-Norm(final)=15.053 | 4521.8 samples/s | 70.7 steps/s
[Step=70650 Epoch=133.2] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.517 | L2-Norm(final)=15.054 | 4573.6 samples/s | 71.5 steps/s
[Step=70700 Epoch=133.3] | Loss=0.00001 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.510 | L2-Norm(final)=15.055 | 4494.3 samples/s | 70.2 steps/s
[Step=70750 Epoch=133.4] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=15.056 | 4680.2 samples/s | 73.1 steps/s
[Step=70800 Epoch=133.5] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.495 | L2-Norm(final)=15.057 | 4574.5 samples/s | 71.5 steps/s
[Step=70850 Epoch=133.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.487 | L2-Norm(final)=15.058 | 4648.6 samples/s | 72.6 steps/s
[Step=70900 Epoch=133.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.480 | L2-Norm(final)=15.058 | 4602.1 samples/s | 71.9 steps/s
[Step=70950 Epoch=133.7] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.472 | L2-Norm(final)=15.059 | 4603.5 samples/s | 71.9 steps/s
[Step=71000 Epoch=133.8] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=15.060 | 4663.9 samples/s | 72.9 steps/s
[Step=71050 Epoch=133.9] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.457 | L2-Norm(final)=15.061 | 2139.0 samples/s | 33.4 steps/s
[Step=71100 Epoch=134.0] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.449 | L2-Norm(final)=15.061 | 4634.7 samples/s | 72.4 steps/s
[Step=71150 Epoch=134.1] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.441 | L2-Norm(final)=15.062 | 4706.4 samples/s | 73.5 steps/s
[Step=71200 Epoch=134.2] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.432 | L2-Norm(final)=15.063 | 4558.5 samples/s | 71.2 steps/s
[Step=71250 Epoch=134.3] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.424 | L2-Norm(final)=15.063 | 4633.1 samples/s | 72.4 steps/s
[Step=71300 Epoch=134.4] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.416 | L2-Norm(final)=15.064 | 4586.4 samples/s | 71.7 steps/s
[Step=71350 Epoch=134.5] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.407 | L2-Norm(final)=15.064 | 4649.9 samples/s | 72.7 steps/s
[Step=71400 Epoch=134.6] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.399 | L2-Norm(final)=15.065 | 4574.8 samples/s | 71.5 steps/s
[Step=71450 Epoch=134.7] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.390 | L2-Norm(final)=15.066 | 4704.4 samples/s | 73.5 steps/s
[Step=71500 Epoch=134.8] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.382 | L2-Norm(final)=15.066 | 4537.7 samples/s | 70.9 steps/s
[Step=71550 Epoch=134.9] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.373 | L2-Norm(final)=15.067 | 5785.3 samples/s | 90.4 steps/s
[Step=71600 Epoch=135.0] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.364 | L2-Norm(final)=15.067 | 1962.4 samples/s | 30.7 steps/s
[Step=71650 Epoch=135.1] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=15.068 | 4560.8 samples/s | 71.3 steps/s
[Step=71700 Epoch=135.2] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.346 | L2-Norm(final)=15.069 | 4592.9 samples/s | 71.8 steps/s
[Step=71750 Epoch=135.2] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.337 | L2-Norm(final)=15.069 | 4643.9 samples/s | 72.6 steps/s
[Step=71800 Epoch=135.3] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.070 | 4544.8 samples/s | 71.0 steps/s
[Step=71850 Epoch=135.4] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.318 | L2-Norm(final)=15.070 | 4565.1 samples/s | 71.3 steps/s
[Step=71900 Epoch=135.5] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.308 | L2-Norm(final)=15.071 | 4610.7 samples/s | 72.0 steps/s
[Step=71950 Epoch=135.6] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.299 | L2-Norm(final)=15.071 | 4623.4 samples/s | 72.2 steps/s
[Step=72000 Epoch=135.7] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.289 | L2-Norm(final)=15.072 | 4653.9 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06186 | acc=0.9715 | tpr=0.9799 | fpr=0.0468 | 3924.1 samples/s | 15.3 steps/s
Avg test loss: 0.06257, Avg test acc: 0.97143, Avg tpr: 0.97989, Avg fpr: 0.04717, total FA: 368

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.58947 | acc=0.2945 | tpr=0.0079 | fpr=0.0833 | 4205.4 samples/s | 16.4 steps/s
Avg test loss: 7.57996, Avg test acc: 0.29089, Avg tpr: 0.00793, Avg fpr: 0.08678, total FA: 677

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.79614 | acc=0.1420 | tpr=0.3451 | fpr=0.8617 | 4213.4 samples/s | 16.5 steps/s
[Step= 100] | Loss=4.78284 | acc=0.1431 | tpr=0.3284 | fpr=0.8604 | 7833.7 samples/s | 30.6 steps/s
[Step= 150] | Loss=4.76907 | acc=0.1433 | tpr=0.3271 | fpr=0.8600 | 7978.7 samples/s | 31.2 steps/s
[Step= 200] | Loss=4.76421 | acc=0.1429 | tpr=0.3126 | fpr=0.8602 | 8011.7 samples/s | 31.3 steps/s
[Step= 250] | Loss=4.76580 | acc=0.1431 | tpr=0.3118 | fpr=0.8599 | 8177.7 samples/s | 31.9 steps/s
[Step= 300] | Loss=4.76458 | acc=0.1433 | tpr=0.3142 | fpr=0.8598 | 8045.5 samples/s | 31.4 steps/s
[Step= 350] | Loss=4.76061 | acc=0.1432 | tpr=0.3175 | fpr=0.8600 | 7731.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=4.76259 | acc=0.1430 | tpr=0.3167 | fpr=0.8601 | 8174.7 samples/s | 31.9 steps/s
[Step= 450] | Loss=4.76522 | acc=0.1426 | tpr=0.3179 | fpr=0.8606 | 7823.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.76348 | acc=0.1426 | tpr=0.3181 | fpr=0.8606 | 7971.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=4.76386 | acc=0.1425 | tpr=0.3207 | fpr=0.8607 | 14572.7 samples/s | 56.9 steps/s
Avg test loss: 4.76536, Avg test acc: 0.14240, Avg tpr: 0.32052, Avg fpr: 0.86084, total FA: 119526

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13060 | acc=0.9816 | tpr=0.9513 | fpr=0.0179 | 4201.8 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.13565 | acc=0.9809 | tpr=0.9574 | fpr=0.0187 | 7962.6 samples/s | 31.1 steps/s
[Step= 150] | Loss=0.13855 | acc=0.9802 | tpr=0.9611 | fpr=0.0194 | 8031.0 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.14115 | acc=0.9805 | tpr=0.9661 | fpr=0.0193 | 8059.1 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.13921 | acc=0.9806 | tpr=0.9633 | fpr=0.0190 | 8019.8 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.14207 | acc=0.9802 | tpr=0.9615 | fpr=0.0194 | 7969.3 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.14170 | acc=0.9803 | tpr=0.9624 | fpr=0.0194 | 7709.2 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.14289 | acc=0.9801 | tpr=0.9612 | fpr=0.0196 | 8208.4 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.14501 | acc=0.9799 | tpr=0.9611 | fpr=0.0198 | 7792.3 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.14412 | acc=0.9799 | tpr=0.9608 | fpr=0.0198 | 7943.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.14307 | acc=0.9801 | tpr=0.9598 | fpr=0.0195 | 15046.4 samples/s | 58.8 steps/s
Avg test loss: 0.14295, Avg test acc: 0.98010, Avg tpr: 0.95919, Avg fpr: 0.01952, total FA: 2711

server round 36/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=72001 Epoch=70.3] | Loss=0.00901 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.331 | L2-Norm(final)=12.661 | 4070.0 samples/s | 63.6 steps/s
[Step=72050 Epoch=70.3] | Loss=0.01147 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.666 | 5416.7 samples/s | 84.6 steps/s
[Step=72100 Epoch=70.4] | Loss=0.01208 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.672 | 5586.1 samples/s | 87.3 steps/s
[Step=72150 Epoch=70.4] | Loss=0.01094 | Reg=0.00128 | acc=0.9844 | L2-Norm=11.332 | L2-Norm(final)=12.678 | 5544.1 samples/s | 86.6 steps/s
[Step=72200 Epoch=70.5] | Loss=0.01068 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.684 | 5568.0 samples/s | 87.0 steps/s
[Step=72250 Epoch=70.5] | Loss=0.01040 | Reg=0.00128 | acc=0.9844 | L2-Norm=11.332 | L2-Norm(final)=12.689 | 5621.4 samples/s | 87.8 steps/s
[Step=72300 Epoch=70.6] | Loss=0.01000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.694 | 5524.0 samples/s | 86.3 steps/s
[Step=72350 Epoch=70.6] | Loss=0.00986 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.700 | 5558.9 samples/s | 86.9 steps/s
[Step=72400 Epoch=70.7] | Loss=0.00958 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.705 | 5632.3 samples/s | 88.0 steps/s
[Step=72450 Epoch=70.7] | Loss=0.00932 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=12.711 | 5592.2 samples/s | 87.4 steps/s
[Step=72500 Epoch=70.8] | Loss=0.00912 | Reg=0.00128 | acc=0.9844 | L2-Norm=11.332 | L2-Norm(final)=12.717 | 5670.3 samples/s | 88.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=70.8] | Loss=0.00991 | Reg=0.00128 | acc=0.9844 | L2-Norm=11.332 | L2-Norm(final)=12.772 | 4126.5 samples/s | 64.5 steps/s
[Step=72550 Epoch=70.8] | Loss=0.00827 | Reg=0.00129 | acc=0.9844 | L2-Norm=11.338 | L2-Norm(final)=12.776 | 4641.3 samples/s | 72.5 steps/s
[Step=72600 Epoch=70.9] | Loss=0.00861 | Reg=0.00129 | acc=0.9844 | L2-Norm=11.346 | L2-Norm(final)=12.780 | 4847.8 samples/s | 75.7 steps/s
[Step=72650 Epoch=70.9] | Loss=0.00877 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.353 | L2-Norm(final)=12.783 | 4870.7 samples/s | 76.1 steps/s
[Step=72700 Epoch=71.0] | Loss=0.00902 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.359 | L2-Norm(final)=12.787 | 4860.6 samples/s | 75.9 steps/s
[Step=72750 Epoch=71.0] | Loss=0.00917 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.365 | L2-Norm(final)=12.790 | 4831.3 samples/s | 75.5 steps/s
[Step=72800 Epoch=71.1] | Loss=0.00922 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.370 | L2-Norm(final)=12.793 | 4856.9 samples/s | 75.9 steps/s
[Step=72850 Epoch=71.1] | Loss=0.00896 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.375 | L2-Norm(final)=12.795 | 4839.4 samples/s | 75.6 steps/s
[Step=72900 Epoch=71.2] | Loss=0.00903 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.379 | L2-Norm(final)=12.798 | 4788.7 samples/s | 74.8 steps/s
[Step=72950 Epoch=71.2] | Loss=0.00900 | Reg=0.00130 | acc=0.9688 | L2-Norm=11.383 | L2-Norm(final)=12.800 | 4855.6 samples/s | 75.9 steps/s
[Step=73000 Epoch=71.3] | Loss=0.00899 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.387 | L2-Norm(final)=12.803 | 4843.0 samples/s | 75.7 steps/s
[Step=73050 Epoch=71.3] | Loss=0.00911 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.391 | L2-Norm(final)=12.805 | 4781.8 samples/s | 74.7 steps/s
[Step=73100 Epoch=71.4] | Loss=0.00923 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.395 | L2-Norm(final)=12.807 | 4831.9 samples/s | 75.5 steps/s
[Step=73150 Epoch=71.4] | Loss=0.00901 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.398 | L2-Norm(final)=12.810 | 4905.7 samples/s | 76.7 steps/s
[Step=73200 Epoch=71.5] | Loss=0.00888 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.402 | L2-Norm(final)=12.813 | 4869.3 samples/s | 76.1 steps/s
[Step=73250 Epoch=71.5] | Loss=0.00881 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.405 | L2-Norm(final)=12.815 | 4883.4 samples/s | 76.3 steps/s
[Step=73300 Epoch=71.6] | Loss=0.00869 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.409 | L2-Norm(final)=12.818 | 4846.7 samples/s | 75.7 steps/s
[Step=73350 Epoch=71.6] | Loss=0.00867 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.412 | L2-Norm(final)=12.821 | 4851.2 samples/s | 75.8 steps/s
[Step=73400 Epoch=71.7] | Loss=0.00864 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.415 | L2-Norm(final)=12.823 | 4857.8 samples/s | 75.9 steps/s
[Step=73450 Epoch=71.7] | Loss=0.00854 | Reg=0.00130 | acc=0.9844 | L2-Norm=11.418 | L2-Norm(final)=12.826 | 4863.0 samples/s | 76.0 steps/s
[Step=73500 Epoch=71.8] | Loss=0.00864 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.421 | L2-Norm(final)=12.828 | 5218.4 samples/s | 81.5 steps/s
[Step=73550 Epoch=71.8] | Loss=0.00858 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.424 | L2-Norm(final)=12.830 | 2117.1 samples/s | 33.1 steps/s
[Step=73600 Epoch=71.9] | Loss=0.00855 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.427 | L2-Norm(final)=12.832 | 4860.5 samples/s | 75.9 steps/s
[Step=73650 Epoch=71.9] | Loss=0.00853 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.430 | L2-Norm(final)=12.834 | 4848.1 samples/s | 75.8 steps/s
[Step=73700 Epoch=72.0] | Loss=0.00840 | Reg=0.00131 | acc=0.9844 | L2-Norm=11.433 | L2-Norm(final)=12.837 | 4800.2 samples/s | 75.0 steps/s
[Step=73750 Epoch=72.0] | Loss=0.00840 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.436 | L2-Norm(final)=12.839 | 4859.4 samples/s | 75.9 steps/s
[Step=73800 Epoch=72.1] | Loss=0.00829 | Reg=0.00131 | acc=0.9844 | L2-Norm=11.438 | L2-Norm(final)=12.841 | 4843.1 samples/s | 75.7 steps/s
[Step=73850 Epoch=72.1] | Loss=0.00830 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.441 | L2-Norm(final)=12.843 | 4887.9 samples/s | 76.4 steps/s
[Step=73900 Epoch=72.2] | Loss=0.00823 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.444 | L2-Norm(final)=12.845 | 4850.9 samples/s | 75.8 steps/s
[Step=73950 Epoch=72.2] | Loss=0.00823 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.446 | L2-Norm(final)=12.847 | 4877.8 samples/s | 76.2 steps/s
[Step=74000 Epoch=72.2] | Loss=0.00815 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.449 | L2-Norm(final)=12.850 | 4842.7 samples/s | 75.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step74000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=72001 Epoch=135.7] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.331 | L2-Norm(final)=15.091 | 3934.4 samples/s | 61.5 steps/s
[Step=72050 Epoch=135.8] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.099 | 5076.0 samples/s | 79.3 steps/s
[Step=72100 Epoch=135.9] | Loss=0.00004 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.106 | 5250.7 samples/s | 82.0 steps/s
[Step=72150 Epoch=136.0] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.113 | 5280.7 samples/s | 82.5 steps/s
[Step=72200 Epoch=136.1] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.119 | 5231.1 samples/s | 81.7 steps/s
[Step=72250 Epoch=136.2] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.126 | 5399.9 samples/s | 84.4 steps/s
[Step=72300 Epoch=136.3] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.134 | 5253.0 samples/s | 82.1 steps/s
[Step=72350 Epoch=136.4] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.141 | 5308.0 samples/s | 82.9 steps/s
[Step=72400 Epoch=136.5] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.147 | 5284.1 samples/s | 82.6 steps/s
[Step=72450 Epoch=136.6] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.153 | 5359.7 samples/s | 83.7 steps/s
[Step=72500 Epoch=136.7] | Loss=0.00003 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.158 | 5397.0 samples/s | 84.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=136.7] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.327 | L2-Norm(final)=15.212 | 3855.8 samples/s | 60.2 steps/s
[Step=72550 Epoch=136.8] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.316 | L2-Norm(final)=15.214 | 4590.8 samples/s | 71.7 steps/s
[Step=72600 Epoch=136.9] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=15.216 | 4624.0 samples/s | 72.2 steps/s
[Step=72650 Epoch=136.9] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.283 | L2-Norm(final)=15.216 | 4554.5 samples/s | 71.2 steps/s
[Step=72700 Epoch=137.0] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.266 | L2-Norm(final)=15.217 | 4646.9 samples/s | 72.6 steps/s
[Step=72750 Epoch=137.1] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.249 | L2-Norm(final)=15.218 | 4592.8 samples/s | 71.8 steps/s
[Step=72800 Epoch=137.2] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.231 | L2-Norm(final)=15.219 | 4600.2 samples/s | 71.9 steps/s
[Step=72850 Epoch=137.3] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.213 | L2-Norm(final)=15.219 | 4589.0 samples/s | 71.7 steps/s
[Step=72900 Epoch=137.4] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.196 | L2-Norm(final)=15.220 | 4617.6 samples/s | 72.2 steps/s
[Step=72950 Epoch=137.5] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.178 | L2-Norm(final)=15.221 | 4655.2 samples/s | 72.7 steps/s
[Step=73000 Epoch=137.6] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.160 | L2-Norm(final)=15.221 | 4708.8 samples/s | 73.6 steps/s
[Step=73050 Epoch=137.7] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.142 | L2-Norm(final)=15.222 | 2131.7 samples/s | 33.3 steps/s
[Step=73100 Epoch=137.8] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.124 | L2-Norm(final)=15.223 | 4665.8 samples/s | 72.9 steps/s
[Step=73150 Epoch=137.9] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.105 | L2-Norm(final)=15.223 | 4669.6 samples/s | 73.0 steps/s
[Step=73200 Epoch=138.0] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.087 | L2-Norm(final)=15.224 | 4593.8 samples/s | 71.8 steps/s
[Step=73250 Epoch=138.1] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.068 | L2-Norm(final)=15.224 | 4639.5 samples/s | 72.5 steps/s
[Step=73300 Epoch=138.2] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.049 | L2-Norm(final)=15.225 | 4625.5 samples/s | 72.3 steps/s
[Step=73350 Epoch=138.3] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.030 | L2-Norm(final)=15.226 | 4574.1 samples/s | 71.5 steps/s
[Step=73400 Epoch=138.4] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.011 | L2-Norm(final)=15.226 | 4600.5 samples/s | 71.9 steps/s
[Step=73450 Epoch=138.5] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.991 | L2-Norm(final)=15.227 | 4643.5 samples/s | 72.6 steps/s
[Step=73500 Epoch=138.5] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.972 | L2-Norm(final)=15.227 | 4626.4 samples/s | 72.3 steps/s
[Step=73550 Epoch=138.6] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.952 | L2-Norm(final)=15.228 | 5753.3 samples/s | 89.9 steps/s
[Step=73600 Epoch=138.7] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.932 | L2-Norm(final)=15.229 | 1919.4 samples/s | 30.0 steps/s
[Step=73650 Epoch=138.8] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.913 | L2-Norm(final)=15.230 | 4587.2 samples/s | 71.7 steps/s
[Step=73700 Epoch=138.9] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.892 | L2-Norm(final)=15.230 | 4593.4 samples/s | 71.8 steps/s
[Step=73750 Epoch=139.0] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.872 | L2-Norm(final)=15.231 | 4675.0 samples/s | 73.0 steps/s
[Step=73800 Epoch=139.1] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.852 | L2-Norm(final)=15.232 | 4624.3 samples/s | 72.3 steps/s
[Step=73850 Epoch=139.2] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.831 | L2-Norm(final)=15.233 | 4615.0 samples/s | 72.1 steps/s
[Step=73900 Epoch=139.3] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.811 | L2-Norm(final)=15.233 | 4613.0 samples/s | 72.1 steps/s
[Step=73950 Epoch=139.4] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=15.234 | 4647.3 samples/s | 72.6 steps/s
[Step=74000 Epoch=139.5] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.769 | L2-Norm(final)=15.235 | 4633.5 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06430 | acc=0.9710 | tpr=0.9776 | fpr=0.0434 | 4229.9 samples/s | 16.5 steps/s
Avg test loss: 0.06607, Avg test acc: 0.97023, Avg tpr: 0.97645, Avg fpr: 0.04346, total FA: 339

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.49013 | acc=0.2952 | tpr=0.0070 | fpr=0.0790 | 4274.8 samples/s | 16.7 steps/s
Avg test loss: 7.48466, Avg test acc: 0.29141, Avg tpr: 0.00705, Avg fpr: 0.08319, total FA: 649

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.70790 | acc=0.1519 | tpr=0.3097 | fpr=0.8510 | 4330.0 samples/s | 16.9 steps/s
[Step= 100] | Loss=4.69184 | acc=0.1530 | tpr=0.2964 | fpr=0.8496 | 7696.7 samples/s | 30.1 steps/s
[Step= 150] | Loss=4.67557 | acc=0.1539 | tpr=0.2983 | fpr=0.8488 | 8353.8 samples/s | 32.6 steps/s
[Step= 200] | Loss=4.66787 | acc=0.1544 | tpr=0.2896 | fpr=0.8481 | 7480.4 samples/s | 29.2 steps/s
[Step= 250] | Loss=4.66867 | acc=0.1544 | tpr=0.2943 | fpr=0.8481 | 8123.6 samples/s | 31.7 steps/s
[Step= 300] | Loss=4.66668 | acc=0.1545 | tpr=0.2953 | fpr=0.8480 | 7375.1 samples/s | 28.8 steps/s
[Step= 350] | Loss=4.66295 | acc=0.1545 | tpr=0.2981 | fpr=0.8481 | 7896.1 samples/s | 30.8 steps/s
[Step= 400] | Loss=4.66532 | acc=0.1546 | tpr=0.2981 | fpr=0.8480 | 8128.5 samples/s | 31.8 steps/s
[Step= 450] | Loss=4.66776 | acc=0.1542 | tpr=0.3014 | fpr=0.8485 | 7876.0 samples/s | 30.8 steps/s
[Step= 500] | Loss=4.66598 | acc=0.1541 | tpr=0.3000 | fpr=0.8486 | 7879.5 samples/s | 30.8 steps/s
[Step= 550] | Loss=4.66638 | acc=0.1539 | tpr=0.3032 | fpr=0.8488 | 14913.3 samples/s | 58.3 steps/s
Avg test loss: 4.66776, Avg test acc: 0.15381, Avg tpr: 0.30309, Avg fpr: 0.84890, total FA: 117868

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13269 | acc=0.9808 | tpr=0.9558 | fpr=0.0188 | 4268.6 samples/s | 16.7 steps/s
[Step= 100] | Loss=0.13739 | acc=0.9803 | tpr=0.9616 | fpr=0.0193 | 7783.5 samples/s | 30.4 steps/s
[Step= 150] | Loss=0.14076 | acc=0.9797 | tpr=0.9625 | fpr=0.0200 | 7982.7 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.14300 | acc=0.9796 | tpr=0.9672 | fpr=0.0202 | 8256.5 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.14130 | acc=0.9798 | tpr=0.9642 | fpr=0.0199 | 8002.7 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.14429 | acc=0.9795 | tpr=0.9644 | fpr=0.0203 | 7959.4 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.14407 | acc=0.9795 | tpr=0.9649 | fpr=0.0203 | 8017.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.14524 | acc=0.9793 | tpr=0.9639 | fpr=0.0204 | 8109.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.14739 | acc=0.9791 | tpr=0.9635 | fpr=0.0206 | 7820.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.14669 | acc=0.9791 | tpr=0.9630 | fpr=0.0206 | 7910.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.14563 | acc=0.9794 | tpr=0.9618 | fpr=0.0203 | 15021.9 samples/s | 58.7 steps/s
Avg test loss: 0.14551, Avg test acc: 0.97936, Avg tpr: 0.96117, Avg fpr: 0.02031, total FA: 2820

server round 37/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=74001 Epoch=72.3] | Loss=0.01778 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.789 | L2-Norm(final)=12.913 | 4161.2 samples/s | 65.0 steps/s
[Step=74050 Epoch=72.3] | Loss=0.01065 | Reg=0.00116 | acc=0.9531 | L2-Norm=10.790 | L2-Norm(final)=12.922 | 5295.4 samples/s | 82.7 steps/s
[Step=74100 Epoch=72.3] | Loss=0.01060 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.790 | L2-Norm(final)=12.933 | 5564.1 samples/s | 86.9 steps/s
[Step=74150 Epoch=72.4] | Loss=0.01139 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.790 | L2-Norm(final)=12.942 | 5632.9 samples/s | 88.0 steps/s
[Step=74200 Epoch=72.4] | Loss=0.01174 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.790 | L2-Norm(final)=12.952 | 5557.6 samples/s | 86.8 steps/s
[Step=74250 Epoch=72.5] | Loss=0.01158 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=12.962 | 5611.6 samples/s | 87.7 steps/s
[Step=74300 Epoch=72.5] | Loss=0.01142 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=12.971 | 5617.4 samples/s | 87.8 steps/s
[Step=74350 Epoch=72.6] | Loss=0.01120 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=12.981 | 5683.0 samples/s | 88.8 steps/s
[Step=74400 Epoch=72.6] | Loss=0.01091 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=12.990 | 5582.2 samples/s | 87.2 steps/s
[Step=74450 Epoch=72.7] | Loss=0.01094 | Reg=0.00116 | acc=0.9688 | L2-Norm=10.790 | L2-Norm(final)=12.999 | 5513.3 samples/s | 86.1 steps/s
[Step=74500 Epoch=72.7] | Loss=0.01080 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=13.008 | 5598.2 samples/s | 87.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=72.7] | Loss=0.01348 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.790 | L2-Norm(final)=13.099 | 3968.9 samples/s | 62.0 steps/s
[Step=74550 Epoch=72.8] | Loss=0.01101 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.800 | L2-Norm(final)=13.104 | 4760.6 samples/s | 74.4 steps/s
[Step=74600 Epoch=72.8] | Loss=0.01093 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.810 | L2-Norm(final)=13.109 | 4771.2 samples/s | 74.6 steps/s
[Step=74650 Epoch=72.9] | Loss=0.01092 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.820 | L2-Norm(final)=13.113 | 4844.9 samples/s | 75.7 steps/s
[Step=74700 Epoch=72.9] | Loss=0.01073 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.828 | L2-Norm(final)=13.117 | 4891.9 samples/s | 76.4 steps/s
[Step=74750 Epoch=73.0] | Loss=0.01047 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.836 | L2-Norm(final)=13.121 | 4800.7 samples/s | 75.0 steps/s
[Step=74800 Epoch=73.0] | Loss=0.01043 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.843 | L2-Norm(final)=13.125 | 4881.0 samples/s | 76.3 steps/s
[Step=74850 Epoch=73.1] | Loss=0.01066 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.849 | L2-Norm(final)=13.128 | 4926.7 samples/s | 77.0 steps/s
[Step=74900 Epoch=73.1] | Loss=0.01063 | Reg=0.00118 | acc=0.9844 | L2-Norm=10.855 | L2-Norm(final)=13.131 | 4785.6 samples/s | 74.8 steps/s
[Step=74950 Epoch=73.2] | Loss=0.01069 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.860 | L2-Norm(final)=13.134 | 4873.1 samples/s | 76.1 steps/s
[Step=75000 Epoch=73.2] | Loss=0.01063 | Reg=0.00118 | acc=0.9844 | L2-Norm=10.865 | L2-Norm(final)=13.137 | 4893.1 samples/s | 76.5 steps/s
[Step=75050 Epoch=73.3] | Loss=0.01067 | Reg=0.00118 | acc=0.9844 | L2-Norm=10.870 | L2-Norm(final)=13.140 | 4875.3 samples/s | 76.2 steps/s
[Step=75100 Epoch=73.3] | Loss=0.01051 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.875 | L2-Norm(final)=13.143 | 4834.6 samples/s | 75.5 steps/s
[Step=75150 Epoch=73.4] | Loss=0.01064 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.880 | L2-Norm(final)=13.146 | 4860.4 samples/s | 75.9 steps/s
[Step=75200 Epoch=73.4] | Loss=0.01056 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.884 | L2-Norm(final)=13.149 | 4933.7 samples/s | 77.1 steps/s
[Step=75250 Epoch=73.5] | Loss=0.01062 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.888 | L2-Norm(final)=13.152 | 4788.7 samples/s | 74.8 steps/s
[Step=75300 Epoch=73.5] | Loss=0.01059 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.892 | L2-Norm(final)=13.155 | 4855.5 samples/s | 75.9 steps/s
[Step=75350 Epoch=73.6] | Loss=0.01060 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.896 | L2-Norm(final)=13.158 | 4848.3 samples/s | 75.8 steps/s
[Step=75400 Epoch=73.6] | Loss=0.01048 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.899 | L2-Norm(final)=13.161 | 4878.0 samples/s | 76.2 steps/s
[Step=75450 Epoch=73.7] | Loss=0.01040 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.903 | L2-Norm(final)=13.164 | 4828.9 samples/s | 75.5 steps/s
[Step=75500 Epoch=73.7] | Loss=0.01028 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.907 | L2-Norm(final)=13.167 | 5208.4 samples/s | 81.4 steps/s
[Step=75550 Epoch=73.8] | Loss=0.01028 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.910 | L2-Norm(final)=13.170 | 2118.7 samples/s | 33.1 steps/s
[Step=75600 Epoch=73.8] | Loss=0.01016 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.913 | L2-Norm(final)=13.173 | 4839.6 samples/s | 75.6 steps/s
[Step=75650 Epoch=73.9] | Loss=0.01008 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.917 | L2-Norm(final)=13.176 | 4847.6 samples/s | 75.7 steps/s
[Step=75700 Epoch=73.9] | Loss=0.01005 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.920 | L2-Norm(final)=13.179 | 4830.5 samples/s | 75.5 steps/s
[Step=75750 Epoch=74.0] | Loss=0.00995 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.923 | L2-Norm(final)=13.181 | 4865.1 samples/s | 76.0 steps/s
[Step=75800 Epoch=74.0] | Loss=0.00986 | Reg=0.00119 | acc=0.9844 | L2-Norm=10.926 | L2-Norm(final)=13.184 | 4878.8 samples/s | 76.2 steps/s
[Step=75850 Epoch=74.1] | Loss=0.00972 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.930 | L2-Norm(final)=13.187 | 4786.6 samples/s | 74.8 steps/s
[Step=75900 Epoch=74.1] | Loss=0.00965 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.933 | L2-Norm(final)=13.190 | 4824.9 samples/s | 75.4 steps/s
[Step=75950 Epoch=74.2] | Loss=0.00958 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.936 | L2-Norm(final)=13.193 | 4858.2 samples/s | 75.9 steps/s
[Step=76000 Epoch=74.2] | Loss=0.00957 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.939 | L2-Norm(final)=13.195 | 4882.1 samples/s | 76.3 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step76000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=74001 Epoch=139.5] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.789 | L2-Norm(final)=15.263 | 3980.5 samples/s | 62.2 steps/s
[Step=74050 Epoch=139.6] | Loss=0.00003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.781 | L2-Norm(final)=15.270 | 5045.2 samples/s | 78.8 steps/s
[Step=74100 Epoch=139.7] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.781 | L2-Norm(final)=15.277 | 5309.3 samples/s | 83.0 steps/s
[Step=74150 Epoch=139.8] | Loss=0.00003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.286 | 5278.9 samples/s | 82.5 steps/s
[Step=74200 Epoch=139.9] | Loss=0.00003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.294 | 5330.7 samples/s | 83.3 steps/s
[Step=74250 Epoch=140.0] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.301 | 5280.4 samples/s | 82.5 steps/s
[Step=74300 Epoch=140.1] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.308 | 5412.7 samples/s | 84.6 steps/s
[Step=74350 Epoch=140.2] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.314 | 5190.3 samples/s | 81.1 steps/s
[Step=74400 Epoch=140.2] | Loss=0.00003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.321 | 5239.9 samples/s | 81.9 steps/s
[Step=74450 Epoch=140.3] | Loss=0.00003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.328 | 5366.9 samples/s | 83.9 steps/s
[Step=74500 Epoch=140.4] | Loss=0.00002 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.335 | 5379.4 samples/s | 84.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=140.4] | Loss=0.00004 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.780 | L2-Norm(final)=15.400 | 3791.0 samples/s | 59.2 steps/s
[Step=74550 Epoch=140.5] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.758 | L2-Norm(final)=15.404 | 4726.6 samples/s | 73.9 steps/s
[Step=74600 Epoch=140.6] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.727 | L2-Norm(final)=15.406 | 4488.7 samples/s | 70.1 steps/s
[Step=74650 Epoch=140.7] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.693 | L2-Norm(final)=15.407 | 4582.1 samples/s | 71.6 steps/s
[Step=74700 Epoch=140.8] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.658 | L2-Norm(final)=15.408 | 4654.8 samples/s | 72.7 steps/s
[Step=74750 Epoch=140.9] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.623 | L2-Norm(final)=15.409 | 4581.6 samples/s | 71.6 steps/s
[Step=74800 Epoch=141.0] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.588 | L2-Norm(final)=15.410 | 4587.9 samples/s | 71.7 steps/s
[Step=74850 Epoch=141.1] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.553 | L2-Norm(final)=15.411 | 4629.0 samples/s | 72.3 steps/s
[Step=74900 Epoch=141.2] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.518 | L2-Norm(final)=15.412 | 4657.4 samples/s | 72.8 steps/s
[Step=74950 Epoch=141.3] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.483 | L2-Norm(final)=15.413 | 4557.6 samples/s | 71.2 steps/s
[Step=75000 Epoch=141.4] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.448 | L2-Norm(final)=15.414 | 4664.8 samples/s | 72.9 steps/s
[Step=75050 Epoch=141.5] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.414 | L2-Norm(final)=15.415 | 2145.1 samples/s | 33.5 steps/s
[Step=75100 Epoch=141.6] | Loss=0.00005 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.381 | L2-Norm(final)=15.416 | 4678.1 samples/s | 73.1 steps/s
[Step=75150 Epoch=141.7] | Loss=0.00006 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.355 | L2-Norm(final)=15.416 | 4618.5 samples/s | 72.2 steps/s
[Step=75200 Epoch=141.8] | Loss=0.00006 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.333 | L2-Norm(final)=15.417 | 4665.8 samples/s | 72.9 steps/s
[Step=75250 Epoch=141.8] | Loss=0.00006 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.314 | L2-Norm(final)=15.417 | 4550.2 samples/s | 71.1 steps/s
[Step=75300 Epoch=141.9] | Loss=0.00006 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.298 | L2-Norm(final)=15.418 | 4586.8 samples/s | 71.7 steps/s
[Step=75350 Epoch=142.0] | Loss=0.00006 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.283 | L2-Norm(final)=15.418 | 4641.9 samples/s | 72.5 steps/s
[Step=75400 Epoch=142.1] | Loss=0.00005 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=15.418 | 4599.0 samples/s | 71.9 steps/s
[Step=75450 Epoch=142.2] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=15.419 | 4622.2 samples/s | 72.2 steps/s
[Step=75500 Epoch=142.3] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.247 | L2-Norm(final)=15.419 | 4588.5 samples/s | 71.7 steps/s
[Step=75550 Epoch=142.4] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.237 | L2-Norm(final)=15.419 | 5700.6 samples/s | 89.1 steps/s
[Step=75600 Epoch=142.5] | Loss=0.00004 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.228 | L2-Norm(final)=15.419 | 1937.9 samples/s | 30.3 steps/s
[Step=75650 Epoch=142.6] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=15.420 | 4552.2 samples/s | 71.1 steps/s
[Step=75700 Epoch=142.7] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=15.420 | 4610.3 samples/s | 72.0 steps/s
[Step=75750 Epoch=142.8] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.204 | L2-Norm(final)=15.420 | 4663.6 samples/s | 72.9 steps/s
[Step=75800 Epoch=142.9] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.197 | L2-Norm(final)=15.420 | 4583.3 samples/s | 71.6 steps/s
[Step=75850 Epoch=143.0] | Loss=0.00004 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=15.421 | 4611.7 samples/s | 72.1 steps/s
[Step=75900 Epoch=143.1] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.184 | L2-Norm(final)=15.421 | 4616.8 samples/s | 72.1 steps/s
[Step=75950 Epoch=143.2] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.178 | L2-Norm(final)=15.421 | 4610.1 samples/s | 72.0 steps/s
[Step=76000 Epoch=143.3] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.172 | L2-Norm(final)=15.421 | 4637.3 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05976 | acc=0.9694 | tpr=0.9739 | fpr=0.0404 | 4178.3 samples/s | 16.3 steps/s
Avg test loss: 0.06107, Avg test acc: 0.96907, Avg tpr: 0.97342, Avg fpr: 0.04051, total FA: 316

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.02501 | acc=0.3021 | tpr=0.0060 | fpr=0.0550 | 4050.6 samples/s | 15.8 steps/s
Avg test loss: 9.01920, Avg test acc: 0.29814, Avg tpr: 0.00589, Avg fpr: 0.05909, total FA: 461

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.06799 | acc=0.1584 | tpr=0.2257 | fpr=0.8428 | 4211.6 samples/s | 16.5 steps/s
[Step= 100] | Loss=4.05562 | acc=0.1596 | tpr=0.2281 | fpr=0.8417 | 7989.0 samples/s | 31.2 steps/s
[Step= 150] | Loss=4.04185 | acc=0.1607 | tpr=0.2334 | fpr=0.8407 | 8308.6 samples/s | 32.5 steps/s
[Step= 200] | Loss=4.03665 | acc=0.1614 | tpr=0.2284 | fpr=0.8398 | 8009.5 samples/s | 31.3 steps/s
[Step= 250] | Loss=4.03779 | acc=0.1610 | tpr=0.2245 | fpr=0.8402 | 7925.5 samples/s | 31.0 steps/s
[Step= 300] | Loss=4.03598 | acc=0.1609 | tpr=0.2313 | fpr=0.8404 | 7893.1 samples/s | 30.8 steps/s
[Step= 350] | Loss=4.03333 | acc=0.1610 | tpr=0.2311 | fpr=0.8402 | 8138.0 samples/s | 31.8 steps/s
[Step= 400] | Loss=4.03515 | acc=0.1611 | tpr=0.2341 | fpr=0.8402 | 8131.3 samples/s | 31.8 steps/s
[Step= 450] | Loss=4.03805 | acc=0.1606 | tpr=0.2381 | fpr=0.8408 | 7713.1 samples/s | 30.1 steps/s
[Step= 500] | Loss=4.03629 | acc=0.1607 | tpr=0.2352 | fpr=0.8406 | 7847.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=4.03663 | acc=0.1608 | tpr=0.2400 | fpr=0.8407 | 14934.2 samples/s | 58.3 steps/s
Avg test loss: 4.03777, Avg test acc: 0.16064, Avg tpr: 0.23970, Avg fpr: 0.84080, total FA: 116743

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16277 | acc=0.9780 | tpr=0.9513 | fpr=0.0216 | 4222.2 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.16813 | acc=0.9776 | tpr=0.9595 | fpr=0.0220 | 7824.8 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.17197 | acc=0.9772 | tpr=0.9625 | fpr=0.0225 | 8114.2 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.17423 | acc=0.9772 | tpr=0.9650 | fpr=0.0226 | 8200.9 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.17215 | acc=0.9772 | tpr=0.9624 | fpr=0.0226 | 7795.6 samples/s | 30.5 steps/s
[Step= 300] | Loss=0.17501 | acc=0.9769 | tpr=0.9615 | fpr=0.0228 | 8069.4 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.17455 | acc=0.9769 | tpr=0.9631 | fpr=0.0228 | 8103.1 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.17593 | acc=0.9766 | tpr=0.9628 | fpr=0.0231 | 8070.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.17826 | acc=0.9765 | tpr=0.9625 | fpr=0.0233 | 7801.1 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.17732 | acc=0.9765 | tpr=0.9621 | fpr=0.0232 | 7965.0 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.17605 | acc=0.9768 | tpr=0.9614 | fpr=0.0229 | 14433.6 samples/s | 56.4 steps/s
Avg test loss: 0.17572, Avg test acc: 0.97682, Avg tpr: 0.96117, Avg fpr: 0.02290, total FA: 3179

server round 38/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=76001 Epoch=74.2] | Loss=0.01148 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.470 | L2-Norm(final)=13.277 | 4037.6 samples/s | 63.1 steps/s
[Step=76050 Epoch=74.3] | Loss=0.01347 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.276 | 5488.8 samples/s | 85.8 steps/s
[Step=76100 Epoch=74.3] | Loss=0.01421 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.277 | 5639.2 samples/s | 88.1 steps/s
[Step=76150 Epoch=74.3] | Loss=0.01431 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.471 | L2-Norm(final)=13.278 | 5512.6 samples/s | 86.1 steps/s
[Step=76200 Epoch=74.4] | Loss=0.01433 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.471 | L2-Norm(final)=13.279 | 5606.5 samples/s | 87.6 steps/s
[Step=76250 Epoch=74.4] | Loss=0.01421 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.282 | 5617.8 samples/s | 87.8 steps/s
[Step=76300 Epoch=74.5] | Loss=0.01429 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.284 | 5611.2 samples/s | 87.7 steps/s
[Step=76350 Epoch=74.5] | Loss=0.01396 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.287 | 5778.0 samples/s | 90.3 steps/s
[Step=76400 Epoch=74.6] | Loss=0.01375 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.471 | L2-Norm(final)=13.291 | 5614.0 samples/s | 87.7 steps/s
[Step=76450 Epoch=74.6] | Loss=0.01376 | Reg=0.00110 | acc=0.9531 | L2-Norm=10.471 | L2-Norm(final)=13.295 | 5492.8 samples/s | 85.8 steps/s
[Step=76500 Epoch=74.7] | Loss=0.01364 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.471 | L2-Norm(final)=13.299 | 5655.0 samples/s | 88.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=74.7] | Loss=0.02601 | Reg=0.00110 | acc=0.9688 | L2-Norm=10.471 | L2-Norm(final)=13.339 | 4237.5 samples/s | 66.2 steps/s
[Step=76550 Epoch=74.7] | Loss=0.01467 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.483 | L2-Norm(final)=13.344 | 4610.4 samples/s | 72.0 steps/s
[Step=76600 Epoch=74.8] | Loss=0.01315 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.495 | L2-Norm(final)=13.350 | 4834.9 samples/s | 75.5 steps/s
[Step=76650 Epoch=74.8] | Loss=0.01254 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.505 | L2-Norm(final)=13.354 | 4854.9 samples/s | 75.9 steps/s
[Step=76700 Epoch=74.9] | Loss=0.01209 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.513 | L2-Norm(final)=13.358 | 4865.0 samples/s | 76.0 steps/s
[Step=76750 Epoch=74.9] | Loss=0.01221 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.521 | L2-Norm(final)=13.363 | 4855.9 samples/s | 75.9 steps/s
[Step=76800 Epoch=75.0] | Loss=0.01222 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.529 | L2-Norm(final)=13.367 | 4826.0 samples/s | 75.4 steps/s
[Step=76850 Epoch=75.0] | Loss=0.01209 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=13.371 | 4832.0 samples/s | 75.5 steps/s
[Step=76900 Epoch=75.1] | Loss=0.01176 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.542 | L2-Norm(final)=13.374 | 4868.8 samples/s | 76.1 steps/s
[Step=76950 Epoch=75.1] | Loss=0.01165 | Reg=0.00111 | acc=0.9688 | L2-Norm=10.548 | L2-Norm(final)=13.377 | 4830.9 samples/s | 75.5 steps/s
[Step=77000 Epoch=75.2] | Loss=0.01151 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.553 | L2-Norm(final)=13.381 | 4816.1 samples/s | 75.3 steps/s
[Step=77050 Epoch=75.2] | Loss=0.01131 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.559 | L2-Norm(final)=13.384 | 4858.9 samples/s | 75.9 steps/s
[Step=77100 Epoch=75.3] | Loss=0.01135 | Reg=0.00112 | acc=0.9531 | L2-Norm=10.564 | L2-Norm(final)=13.387 | 4916.1 samples/s | 76.8 steps/s
[Step=77150 Epoch=75.3] | Loss=0.01125 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.568 | L2-Norm(final)=13.390 | 4832.0 samples/s | 75.5 steps/s
[Step=77200 Epoch=75.4] | Loss=0.01112 | Reg=0.00112 | acc=0.9531 | L2-Norm=10.573 | L2-Norm(final)=13.393 | 4890.1 samples/s | 76.4 steps/s
[Step=77250 Epoch=75.4] | Loss=0.01114 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.577 | L2-Norm(final)=13.396 | 4899.0 samples/s | 76.5 steps/s
[Step=77300 Epoch=75.5] | Loss=0.01103 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.581 | L2-Norm(final)=13.399 | 4825.2 samples/s | 75.4 steps/s
[Step=77350 Epoch=75.5] | Loss=0.01099 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.585 | L2-Norm(final)=13.402 | 4889.3 samples/s | 76.4 steps/s
[Step=77400 Epoch=75.6] | Loss=0.01083 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.589 | L2-Norm(final)=13.405 | 4857.1 samples/s | 75.9 steps/s
[Step=77450 Epoch=75.6] | Loss=0.01083 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.593 | L2-Norm(final)=13.408 | 4830.6 samples/s | 75.5 steps/s
[Step=77500 Epoch=75.7] | Loss=0.01084 | Reg=0.00112 | acc=0.9531 | L2-Norm=10.596 | L2-Norm(final)=13.411 | 5203.7 samples/s | 81.3 steps/s
[Step=77550 Epoch=75.7] | Loss=0.01081 | Reg=0.00112 | acc=0.9688 | L2-Norm=10.600 | L2-Norm(final)=13.414 | 2083.7 samples/s | 32.6 steps/s
[Step=77600 Epoch=75.8] | Loss=0.01058 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.604 | L2-Norm(final)=13.417 | 4851.9 samples/s | 75.8 steps/s
[Step=77650 Epoch=75.8] | Loss=0.01047 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.607 | L2-Norm(final)=13.420 | 4835.0 samples/s | 75.5 steps/s
[Step=77700 Epoch=75.9] | Loss=0.01039 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.611 | L2-Norm(final)=13.423 | 4656.2 samples/s | 72.8 steps/s
[Step=77750 Epoch=75.9] | Loss=0.01031 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.614 | L2-Norm(final)=13.425 | 4804.8 samples/s | 75.1 steps/s
[Step=77800 Epoch=76.0] | Loss=0.01031 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.617 | L2-Norm(final)=13.428 | 4818.0 samples/s | 75.3 steps/s
[Step=77850 Epoch=76.0] | Loss=0.01027 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.621 | L2-Norm(final)=13.431 | 4799.9 samples/s | 75.0 steps/s
[Step=77900 Epoch=76.1] | Loss=0.01022 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.624 | L2-Norm(final)=13.434 | 4889.4 samples/s | 76.4 steps/s
[Step=77950 Epoch=76.1] | Loss=0.01014 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.627 | L2-Norm(final)=13.436 | 4821.1 samples/s | 75.3 steps/s
[Step=78000 Epoch=76.2] | Loss=0.01009 | Reg=0.00113 | acc=0.9688 | L2-Norm=10.630 | L2-Norm(final)=13.439 | 4862.0 samples/s | 76.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step78000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=76001 Epoch=143.3] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.470 | L2-Norm(final)=15.427 | 3983.1 samples/s | 62.2 steps/s
[Step=76050 Epoch=143.4] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.427 | 5094.6 samples/s | 79.6 steps/s
[Step=76100 Epoch=143.4] | Loss=0.00003 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.429 | 5211.0 samples/s | 81.4 steps/s
[Step=76150 Epoch=143.5] | Loss=0.00003 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.430 | 5340.2 samples/s | 83.4 steps/s
[Step=76200 Epoch=143.6] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.431 | 5347.2 samples/s | 83.5 steps/s
[Step=76250 Epoch=143.7] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.431 | 5164.0 samples/s | 80.7 steps/s
[Step=76300 Epoch=143.8] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.431 | 5320.6 samples/s | 83.1 steps/s
[Step=76350 Epoch=143.9] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.432 | 5293.4 samples/s | 82.7 steps/s
[Step=76400 Epoch=144.0] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.432 | 5368.3 samples/s | 83.9 steps/s
[Step=76450 Epoch=144.1] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.433 | 5092.1 samples/s | 79.6 steps/s
[Step=76500 Epoch=144.2] | Loss=0.00002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.433 | 5365.0 samples/s | 83.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=144.2] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.469 | L2-Norm(final)=15.438 | 4280.2 samples/s | 66.9 steps/s
[Step=76550 Epoch=144.3] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=15.438 | 4161.2 samples/s | 65.0 steps/s
[Step=76600 Epoch=144.4] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.439 | 4590.2 samples/s | 71.7 steps/s
[Step=76650 Epoch=144.5] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.461 | L2-Norm(final)=15.440 | 4584.2 samples/s | 71.6 steps/s
[Step=76700 Epoch=144.6] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.459 | L2-Norm(final)=15.440 | 4614.1 samples/s | 72.1 steps/s
[Step=76750 Epoch=144.7] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.457 | L2-Norm(final)=15.441 | 4581.9 samples/s | 71.6 steps/s
[Step=76800 Epoch=144.8] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.455 | L2-Norm(final)=15.442 | 4627.1 samples/s | 72.3 steps/s
[Step=76850 Epoch=144.9] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.452 | L2-Norm(final)=15.442 | 4612.4 samples/s | 72.1 steps/s
[Step=76900 Epoch=145.0] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.449 | L2-Norm(final)=15.443 | 4655.3 samples/s | 72.7 steps/s
[Step=76950 Epoch=145.1] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.446 | L2-Norm(final)=15.443 | 4675.4 samples/s | 73.1 steps/s
[Step=77000 Epoch=145.1] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.444 | L2-Norm(final)=15.444 | 4699.8 samples/s | 73.4 steps/s
[Step=77050 Epoch=145.2] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.441 | L2-Norm(final)=15.444 | 2101.2 samples/s | 32.8 steps/s
[Step=77100 Epoch=145.3] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.437 | L2-Norm(final)=15.444 | 4659.8 samples/s | 72.8 steps/s
[Step=77150 Epoch=145.4] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.434 | L2-Norm(final)=15.445 | 4595.9 samples/s | 71.8 steps/s
[Step=77200 Epoch=145.5] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.431 | L2-Norm(final)=15.445 | 4600.0 samples/s | 71.9 steps/s
[Step=77250 Epoch=145.6] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.428 | L2-Norm(final)=15.445 | 4605.4 samples/s | 72.0 steps/s
[Step=77300 Epoch=145.7] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.425 | L2-Norm(final)=15.446 | 4581.9 samples/s | 71.6 steps/s
[Step=77350 Epoch=145.8] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.422 | L2-Norm(final)=15.446 | 4598.9 samples/s | 71.9 steps/s
[Step=77400 Epoch=145.9] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.418 | L2-Norm(final)=15.446 | 4612.7 samples/s | 72.1 steps/s
[Step=77450 Epoch=146.0] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.415 | L2-Norm(final)=15.446 | 4618.7 samples/s | 72.2 steps/s
[Step=77500 Epoch=146.1] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=15.447 | 4596.2 samples/s | 71.8 steps/s
[Step=77550 Epoch=146.2] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.408 | L2-Norm(final)=15.447 | 5765.0 samples/s | 90.1 steps/s
[Step=77600 Epoch=146.3] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.405 | L2-Norm(final)=15.447 | 1943.9 samples/s | 30.4 steps/s
[Step=77650 Epoch=146.4] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.401 | L2-Norm(final)=15.447 | 4528.5 samples/s | 70.8 steps/s
[Step=77700 Epoch=146.5] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.397 | L2-Norm(final)=15.448 | 4611.7 samples/s | 72.1 steps/s
[Step=77750 Epoch=146.6] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.394 | L2-Norm(final)=15.448 | 4557.3 samples/s | 71.2 steps/s
[Step=77800 Epoch=146.7] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.390 | L2-Norm(final)=15.448 | 4613.0 samples/s | 72.1 steps/s
[Step=77850 Epoch=146.7] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.386 | L2-Norm(final)=15.448 | 4615.6 samples/s | 72.1 steps/s
[Step=77900 Epoch=146.8] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.383 | L2-Norm(final)=15.449 | 4590.6 samples/s | 71.7 steps/s
[Step=77950 Epoch=146.9] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.379 | L2-Norm(final)=15.449 | 4622.1 samples/s | 72.2 steps/s
[Step=78000 Epoch=147.0] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.375 | L2-Norm(final)=15.449 | 4634.4 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06179 | acc=0.9720 | tpr=0.9759 | fpr=0.0364 | 4172.9 samples/s | 16.3 steps/s
Avg test loss: 0.06226, Avg test acc: 0.97103, Avg tpr: 0.97517, Avg fpr: 0.03807, total FA: 297

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.34994 | acc=0.3002 | tpr=0.0086 | fpr=0.0667 | 4199.2 samples/s | 16.4 steps/s
Avg test loss: 7.34162, Avg test acc: 0.29542, Avg tpr: 0.00804, Avg fpr: 0.07255, total FA: 566

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.49981 | acc=0.1487 | tpr=0.2743 | fpr=0.8535 | 4183.9 samples/s | 16.3 steps/s
[Step= 100] | Loss=4.47992 | acc=0.1491 | tpr=0.2751 | fpr=0.8532 | 7999.0 samples/s | 31.2 steps/s
[Step= 150] | Loss=4.46801 | acc=0.1499 | tpr=0.2810 | fpr=0.8525 | 7832.0 samples/s | 30.6 steps/s
[Step= 200] | Loss=4.46296 | acc=0.1504 | tpr=0.2699 | fpr=0.8518 | 8131.1 samples/s | 31.8 steps/s
[Step= 250] | Loss=4.46422 | acc=0.1505 | tpr=0.2672 | fpr=0.8516 | 8047.4 samples/s | 31.4 steps/s
[Step= 300] | Loss=4.46253 | acc=0.1508 | tpr=0.2713 | fpr=0.8514 | 7864.7 samples/s | 30.7 steps/s
[Step= 350] | Loss=4.46018 | acc=0.1506 | tpr=0.2711 | fpr=0.8516 | 8106.3 samples/s | 31.7 steps/s
[Step= 400] | Loss=4.46275 | acc=0.1503 | tpr=0.2724 | fpr=0.8519 | 7835.5 samples/s | 30.6 steps/s
[Step= 450] | Loss=4.46550 | acc=0.1500 | tpr=0.2751 | fpr=0.8523 | 8044.1 samples/s | 31.4 steps/s
[Step= 500] | Loss=4.46360 | acc=0.1500 | tpr=0.2736 | fpr=0.8523 | 7935.9 samples/s | 31.0 steps/s
[Step= 550] | Loss=4.46439 | acc=0.1499 | tpr=0.2758 | fpr=0.8524 | 14987.1 samples/s | 58.5 steps/s
Avg test loss: 4.46543, Avg test acc: 0.14987, Avg tpr: 0.27575, Avg fpr: 0.85242, total FA: 118357

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13231 | acc=0.9798 | tpr=0.9558 | fpr=0.0198 | 4216.1 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.13690 | acc=0.9793 | tpr=0.9616 | fpr=0.0203 | 7898.8 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.14032 | acc=0.9789 | tpr=0.9640 | fpr=0.0208 | 8016.3 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.14238 | acc=0.9789 | tpr=0.9683 | fpr=0.0209 | 8036.1 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.14046 | acc=0.9791 | tpr=0.9659 | fpr=0.0207 | 7846.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.14325 | acc=0.9788 | tpr=0.9658 | fpr=0.0210 | 8050.9 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.14288 | acc=0.9788 | tpr=0.9668 | fpr=0.0210 | 7891.6 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.14400 | acc=0.9786 | tpr=0.9655 | fpr=0.0211 | 8059.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.14603 | acc=0.9785 | tpr=0.9649 | fpr=0.0213 | 7896.4 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.14527 | acc=0.9785 | tpr=0.9643 | fpr=0.0213 | 7873.5 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.14422 | acc=0.9787 | tpr=0.9634 | fpr=0.0210 | 15114.7 samples/s | 59.0 steps/s
Avg test loss: 0.14402, Avg test acc: 0.97873, Avg tpr: 0.96315, Avg fpr: 0.02099, total FA: 2914

server round 39/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=78001 Epoch=76.2] | Loss=0.00837 | Reg=0.00109 | acc=0.9844 | L2-Norm=10.464 | L2-Norm(final)=13.519 | 4304.2 samples/s | 67.3 steps/s
[Step=78050 Epoch=76.2] | Loss=0.01530 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.465 | L2-Norm(final)=13.528 | 5094.4 samples/s | 79.6 steps/s
[Step=78100 Epoch=76.3] | Loss=0.01469 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.465 | L2-Norm(final)=13.539 | 5393.4 samples/s | 84.3 steps/s
[Step=78150 Epoch=76.3] | Loss=0.01458 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=13.550 | 5219.1 samples/s | 81.5 steps/s
[Step=78200 Epoch=76.3] | Loss=0.01445 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=13.559 | 5497.7 samples/s | 85.9 steps/s
[Step=78250 Epoch=76.4] | Loss=0.01444 | Reg=0.00110 | acc=0.9688 | L2-Norm=10.465 | L2-Norm(final)=13.569 | 5587.9 samples/s | 87.3 steps/s
[Step=78300 Epoch=76.4] | Loss=0.01447 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.465 | L2-Norm(final)=13.578 | 5707.5 samples/s | 89.2 steps/s
[Step=78350 Epoch=76.5] | Loss=0.01419 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.465 | L2-Norm(final)=13.587 | 5481.1 samples/s | 85.6 steps/s
[Step=78400 Epoch=76.5] | Loss=0.01391 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=13.595 | 5616.8 samples/s | 87.8 steps/s
[Step=78450 Epoch=76.6] | Loss=0.01342 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.465 | L2-Norm(final)=13.603 | 5661.3 samples/s | 88.5 steps/s
[Step=78500 Epoch=76.6] | Loss=0.01324 | Reg=0.00110 | acc=0.9531 | L2-Norm=10.465 | L2-Norm(final)=13.611 | 5579.5 samples/s | 87.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=76.6] | Loss=0.00550 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=13.691 | 4163.5 samples/s | 65.1 steps/s
[Step=78550 Epoch=76.7] | Loss=0.00713 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.473 | L2-Norm(final)=13.696 | 4841.6 samples/s | 75.6 steps/s
[Step=78600 Epoch=76.7] | Loss=0.01002 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.481 | L2-Norm(final)=13.699 | 4823.5 samples/s | 75.4 steps/s
[Step=78650 Epoch=76.8] | Loss=0.01003 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.489 | L2-Norm(final)=13.702 | 4790.2 samples/s | 74.8 steps/s
[Step=78700 Epoch=76.8] | Loss=0.00986 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.496 | L2-Norm(final)=13.706 | 4855.1 samples/s | 75.9 steps/s
[Step=78750 Epoch=76.9] | Loss=0.01006 | Reg=0.00110 | acc=0.9844 | L2-Norm=10.501 | L2-Norm(final)=13.709 | 4797.2 samples/s | 75.0 steps/s
[Step=78800 Epoch=76.9] | Loss=0.01013 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.507 | L2-Norm(final)=13.712 | 4824.6 samples/s | 75.4 steps/s
[Step=78850 Epoch=77.0] | Loss=0.01015 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.512 | L2-Norm(final)=13.714 | 4816.8 samples/s | 75.3 steps/s
[Step=78900 Epoch=77.0] | Loss=0.01027 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.517 | L2-Norm(final)=13.717 | 4872.8 samples/s | 76.1 steps/s
[Step=78950 Epoch=77.1] | Loss=0.01018 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.521 | L2-Norm(final)=13.720 | 4841.2 samples/s | 75.6 steps/s
[Step=79000 Epoch=77.1] | Loss=0.00998 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.525 | L2-Norm(final)=13.722 | 4840.2 samples/s | 75.6 steps/s
[Step=79050 Epoch=77.2] | Loss=0.01008 | Reg=0.00111 | acc=0.9688 | L2-Norm=10.530 | L2-Norm(final)=13.725 | 4789.9 samples/s | 74.8 steps/s
[Step=79100 Epoch=77.2] | Loss=0.00996 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.534 | L2-Norm(final)=13.728 | 4909.7 samples/s | 76.7 steps/s
[Step=79150 Epoch=77.3] | Loss=0.00985 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.538 | L2-Norm(final)=13.730 | 4810.1 samples/s | 75.2 steps/s
[Step=79200 Epoch=77.3] | Loss=0.00974 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.542 | L2-Norm(final)=13.733 | 4783.8 samples/s | 74.7 steps/s
[Step=79250 Epoch=77.4] | Loss=0.00984 | Reg=0.00111 | acc=0.9531 | L2-Norm=10.545 | L2-Norm(final)=13.736 | 4900.9 samples/s | 76.6 steps/s
[Step=79300 Epoch=77.4] | Loss=0.00984 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.549 | L2-Norm(final)=13.738 | 4789.1 samples/s | 74.8 steps/s
[Step=79350 Epoch=77.5] | Loss=0.00988 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.553 | L2-Norm(final)=13.741 | 4814.8 samples/s | 75.2 steps/s
[Step=79400 Epoch=77.5] | Loss=0.00985 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.556 | L2-Norm(final)=13.743 | 4885.2 samples/s | 76.3 steps/s
[Step=79450 Epoch=77.6] | Loss=0.00972 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.560 | L2-Norm(final)=13.746 | 4761.0 samples/s | 74.4 steps/s
[Step=79500 Epoch=77.6] | Loss=0.00969 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.563 | L2-Norm(final)=13.748 | 5193.8 samples/s | 81.2 steps/s
[Step=79550 Epoch=77.7] | Loss=0.00964 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.567 | L2-Norm(final)=13.751 | 2116.7 samples/s | 33.1 steps/s
[Step=79600 Epoch=77.7] | Loss=0.00951 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.570 | L2-Norm(final)=13.753 | 4852.8 samples/s | 75.8 steps/s
[Step=79650 Epoch=77.8] | Loss=0.00943 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.573 | L2-Norm(final)=13.756 | 4846.9 samples/s | 75.7 steps/s
[Step=79700 Epoch=77.8] | Loss=0.00943 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.576 | L2-Norm(final)=13.758 | 4813.2 samples/s | 75.2 steps/s
[Step=79750 Epoch=77.9] | Loss=0.00937 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.579 | L2-Norm(final)=13.761 | 4825.2 samples/s | 75.4 steps/s
[Step=79800 Epoch=77.9] | Loss=0.00929 | Reg=0.00112 | acc=0.9844 | L2-Norm=10.582 | L2-Norm(final)=13.763 | 4811.3 samples/s | 75.2 steps/s
[Step=79850 Epoch=78.0] | Loss=0.00920 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.585 | L2-Norm(final)=13.766 | 4863.7 samples/s | 76.0 steps/s
[Step=79900 Epoch=78.0] | Loss=0.00918 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.588 | L2-Norm(final)=13.768 | 4811.1 samples/s | 75.2 steps/s
[Step=79950 Epoch=78.1] | Loss=0.00915 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.591 | L2-Norm(final)=13.770 | 4881.3 samples/s | 76.3 steps/s
[Step=80000 Epoch=78.1] | Loss=0.00910 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.594 | L2-Norm(final)=13.773 | 4863.9 samples/s | 76.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step80000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=78001 Epoch=147.0] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.464 | L2-Norm(final)=15.456 | 4338.6 samples/s | 67.8 steps/s
[Step=78050 Epoch=147.1] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.463 | L2-Norm(final)=15.458 | 4803.4 samples/s | 75.1 steps/s
[Step=78100 Epoch=147.2] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.459 | 5242.4 samples/s | 81.9 steps/s
[Step=78150 Epoch=147.3] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.459 | 5266.1 samples/s | 82.3 steps/s
[Step=78200 Epoch=147.4] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.460 | 5309.5 samples/s | 83.0 steps/s
[Step=78250 Epoch=147.5] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.461 | 5317.2 samples/s | 83.1 steps/s
[Step=78300 Epoch=147.6] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.462 | 5231.4 samples/s | 81.7 steps/s
[Step=78350 Epoch=147.7] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.463 | 5359.9 samples/s | 83.7 steps/s
[Step=78400 Epoch=147.8] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.464 | 5245.4 samples/s | 82.0 steps/s
[Step=78450 Epoch=147.9] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.466 | 5235.7 samples/s | 81.8 steps/s
[Step=78500 Epoch=148.0] | Loss=0.00003 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.468 | 5350.0 samples/s | 83.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=148.0] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=15.488 | 4211.7 samples/s | 65.8 steps/s
[Step=78550 Epoch=148.1] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.457 | L2-Norm(final)=15.490 | 4388.9 samples/s | 68.6 steps/s
[Step=78600 Epoch=148.2] | Loss=0.00002 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.452 | L2-Norm(final)=15.492 | 4591.4 samples/s | 71.7 steps/s
[Step=78650 Epoch=148.3] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.447 | L2-Norm(final)=15.493 | 4609.5 samples/s | 72.0 steps/s
[Step=78700 Epoch=148.4] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.441 | L2-Norm(final)=15.494 | 4579.8 samples/s | 71.6 steps/s
[Step=78750 Epoch=148.4] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.434 | L2-Norm(final)=15.495 | 4686.6 samples/s | 73.2 steps/s
[Step=78800 Epoch=148.5] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.427 | L2-Norm(final)=15.496 | 4613.7 samples/s | 72.1 steps/s
[Step=78850 Epoch=148.6] | Loss=0.00001 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.420 | L2-Norm(final)=15.496 | 4645.2 samples/s | 72.6 steps/s
[Step=78900 Epoch=148.7] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.413 | L2-Norm(final)=15.497 | 4547.6 samples/s | 71.1 steps/s
[Step=78950 Epoch=148.8] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.406 | L2-Norm(final)=15.497 | 4596.9 samples/s | 71.8 steps/s
[Step=79000 Epoch=148.9] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.399 | L2-Norm(final)=15.498 | 4720.8 samples/s | 73.8 steps/s
[Step=79050 Epoch=149.0] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.391 | L2-Norm(final)=15.498 | 2076.8 samples/s | 32.4 steps/s
[Step=79100 Epoch=149.1] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.384 | L2-Norm(final)=15.499 | 4762.4 samples/s | 74.4 steps/s
[Step=79150 Epoch=149.2] | Loss=0.00001 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.377 | L2-Norm(final)=15.499 | 4603.4 samples/s | 71.9 steps/s
[Step=79200 Epoch=149.3] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.369 | L2-Norm(final)=15.500 | 4576.7 samples/s | 71.5 steps/s
[Step=79250 Epoch=149.4] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.361 | L2-Norm(final)=15.500 | 4541.1 samples/s | 71.0 steps/s
[Step=79300 Epoch=149.5] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.354 | L2-Norm(final)=15.501 | 4613.0 samples/s | 72.1 steps/s
[Step=79350 Epoch=149.6] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.346 | L2-Norm(final)=15.501 | 4612.9 samples/s | 72.1 steps/s
[Step=79400 Epoch=149.7] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.338 | L2-Norm(final)=15.502 | 4648.6 samples/s | 72.6 steps/s
[Step=79450 Epoch=149.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.330 | L2-Norm(final)=15.502 | 4599.7 samples/s | 71.9 steps/s
[Step=79500 Epoch=149.9] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.322 | L2-Norm(final)=15.502 | 4534.4 samples/s | 70.9 steps/s
[Step=79550 Epoch=150.0] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.314 | L2-Norm(final)=15.503 | 5760.0 samples/s | 90.0 steps/s
[Step=79600 Epoch=150.0] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.305 | L2-Norm(final)=15.503 | 1948.8 samples/s | 30.4 steps/s
[Step=79650 Epoch=150.1] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=15.504 | 4530.6 samples/s | 70.8 steps/s
[Step=79700 Epoch=150.2] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.289 | L2-Norm(final)=15.504 | 4581.7 samples/s | 71.6 steps/s
[Step=79750 Epoch=150.3] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=15.505 | 4607.0 samples/s | 72.0 steps/s
[Step=79800 Epoch=150.4] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=15.505 | 4592.9 samples/s | 71.8 steps/s
[Step=79850 Epoch=150.5] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.263 | L2-Norm(final)=15.506 | 4621.6 samples/s | 72.2 steps/s
[Step=79900 Epoch=150.6] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=15.506 | 4631.0 samples/s | 72.4 steps/s
[Step=79950 Epoch=150.7] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=15.507 | 4576.4 samples/s | 71.5 steps/s
[Step=80000 Epoch=150.8] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=15.507 | 4632.0 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06020 | acc=0.9700 | tpr=0.9755 | fpr=0.0419 | 4213.5 samples/s | 16.5 steps/s
Avg test loss: 0.06194, Avg test acc: 0.96983, Avg tpr: 0.97575, Avg fpr: 0.04320, total FA: 337

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.22271 | acc=0.2987 | tpr=0.0079 | fpr=0.0699 | 4231.6 samples/s | 16.5 steps/s
Avg test loss: 7.21268, Avg test acc: 0.29409, Avg tpr: 0.00758, Avg fpr: 0.07576, total FA: 591

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.24911 | acc=0.1523 | tpr=0.2832 | fpr=0.8501 | 4186.7 samples/s | 16.4 steps/s
[Step= 100] | Loss=4.23349 | acc=0.1545 | tpr=0.2814 | fpr=0.8478 | 8068.9 samples/s | 31.5 steps/s
[Step= 150] | Loss=4.22018 | acc=0.1552 | tpr=0.2853 | fpr=0.8472 | 7784.7 samples/s | 30.4 steps/s
[Step= 200] | Loss=4.21474 | acc=0.1551 | tpr=0.2743 | fpr=0.8471 | 8387.7 samples/s | 32.8 steps/s
[Step= 250] | Loss=4.21666 | acc=0.1552 | tpr=0.2725 | fpr=0.8469 | 8002.8 samples/s | 31.3 steps/s
[Step= 300] | Loss=4.21674 | acc=0.1555 | tpr=0.2764 | fpr=0.8467 | 7614.1 samples/s | 29.7 steps/s
[Step= 350] | Loss=4.21551 | acc=0.1555 | tpr=0.2761 | fpr=0.8467 | 8324.5 samples/s | 32.5 steps/s
[Step= 400] | Loss=4.21757 | acc=0.1554 | tpr=0.2768 | fpr=0.8468 | 7806.2 samples/s | 30.5 steps/s
[Step= 450] | Loss=4.21974 | acc=0.1550 | tpr=0.2795 | fpr=0.8472 | 8126.6 samples/s | 31.7 steps/s
[Step= 500] | Loss=4.21829 | acc=0.1550 | tpr=0.2789 | fpr=0.8473 | 7732.6 samples/s | 30.2 steps/s
[Step= 550] | Loss=4.21925 | acc=0.1548 | tpr=0.2797 | fpr=0.8475 | 15126.5 samples/s | 59.1 steps/s
Avg test loss: 4.22025, Avg test acc: 0.15471, Avg tpr: 0.27971, Avg fpr: 0.84757, total FA: 117683

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13295 | acc=0.9799 | tpr=0.9602 | fpr=0.0197 | 4278.5 samples/s | 16.7 steps/s
[Step= 100] | Loss=0.13728 | acc=0.9793 | tpr=0.9638 | fpr=0.0204 | 7746.5 samples/s | 30.3 steps/s
[Step= 150] | Loss=0.14083 | acc=0.9788 | tpr=0.9654 | fpr=0.0209 | 8050.3 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.14293 | acc=0.9789 | tpr=0.9694 | fpr=0.0209 | 8215.5 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.14094 | acc=0.9791 | tpr=0.9659 | fpr=0.0207 | 7903.4 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.14392 | acc=0.9788 | tpr=0.9651 | fpr=0.0210 | 7815.8 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.14361 | acc=0.9787 | tpr=0.9656 | fpr=0.0211 | 8134.6 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.14481 | acc=0.9786 | tpr=0.9644 | fpr=0.0212 | 7864.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.14692 | acc=0.9784 | tpr=0.9645 | fpr=0.0213 | 7974.0 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.14614 | acc=0.9785 | tpr=0.9643 | fpr=0.0213 | 7864.7 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.14510 | acc=0.9787 | tpr=0.9634 | fpr=0.0210 | 15066.2 samples/s | 58.9 steps/s
Avg test loss: 0.14491, Avg test acc: 0.97874, Avg tpr: 0.96315, Avg fpr: 0.02098, total FA: 2913

server round 40/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=80001 Epoch=78.1] | Loss=0.01618 | Reg=0.00106 | acc=0.9688 | L2-Norm=10.292 | L2-Norm(final)=13.845 | 4035.4 samples/s | 63.1 steps/s
[Step=80050 Epoch=78.2] | Loss=0.01027 | Reg=0.00106 | acc=0.9688 | L2-Norm=10.293 | L2-Norm(final)=13.844 | 5350.3 samples/s | 83.6 steps/s
[Step=80100 Epoch=78.2] | Loss=0.00967 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.843 | 5607.5 samples/s | 87.6 steps/s
[Step=80150 Epoch=78.3] | Loss=0.00935 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.842 | 5622.6 samples/s | 87.9 steps/s
[Step=80200 Epoch=78.3] | Loss=0.00942 | Reg=0.00106 | acc=0.9844 | L2-Norm=10.293 | L2-Norm(final)=13.843 | 5587.0 samples/s | 87.3 steps/s
[Step=80250 Epoch=78.4] | Loss=0.00995 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.843 | 5529.1 samples/s | 86.4 steps/s
[Step=80300 Epoch=78.4] | Loss=0.00963 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.844 | 5592.7 samples/s | 87.4 steps/s
[Step=80350 Epoch=78.4] | Loss=0.00910 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.845 | 5671.5 samples/s | 88.6 steps/s
[Step=80400 Epoch=78.5] | Loss=0.00932 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.846 | 5528.1 samples/s | 86.4 steps/s
[Step=80450 Epoch=78.5] | Loss=0.00920 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.846 | 5576.5 samples/s | 87.1 steps/s
[Step=80500 Epoch=78.6] | Loss=0.00918 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.847 | 5588.5 samples/s | 87.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=78.6] | Loss=0.00374 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=13.856 | 4005.1 samples/s | 62.6 steps/s
[Step=80550 Epoch=78.6] | Loss=0.00852 | Reg=0.00106 | acc=0.9844 | L2-Norm=10.296 | L2-Norm(final)=13.859 | 4694.7 samples/s | 73.4 steps/s
[Step=80600 Epoch=78.7] | Loss=0.00839 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.300 | L2-Norm(final)=13.862 | 4832.7 samples/s | 75.5 steps/s
[Step=80650 Epoch=78.7] | Loss=0.00831 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.303 | L2-Norm(final)=13.864 | 4862.0 samples/s | 76.0 steps/s
[Step=80700 Epoch=78.8] | Loss=0.00860 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.306 | L2-Norm(final)=13.867 | 4821.5 samples/s | 75.3 steps/s
[Step=80750 Epoch=78.8] | Loss=0.00845 | Reg=0.00106 | acc=0.9844 | L2-Norm=10.309 | L2-Norm(final)=13.869 | 4879.8 samples/s | 76.2 steps/s
[Step=80800 Epoch=78.9] | Loss=0.00828 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.311 | L2-Norm(final)=13.872 | 4860.1 samples/s | 75.9 steps/s
[Step=80850 Epoch=78.9] | Loss=0.00836 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.314 | L2-Norm(final)=13.874 | 4843.9 samples/s | 75.7 steps/s
[Step=80900 Epoch=79.0] | Loss=0.00845 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.317 | L2-Norm(final)=13.877 | 4871.9 samples/s | 76.1 steps/s
[Step=80950 Epoch=79.0] | Loss=0.00857 | Reg=0.00106 | acc=0.9844 | L2-Norm=10.319 | L2-Norm(final)=13.879 | 4867.8 samples/s | 76.1 steps/s
[Step=81000 Epoch=79.1] | Loss=0.00848 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.322 | L2-Norm(final)=13.881 | 4813.8 samples/s | 75.2 steps/s
[Step=81050 Epoch=79.1] | Loss=0.00832 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.324 | L2-Norm(final)=13.884 | 4833.2 samples/s | 75.5 steps/s
[Step=81100 Epoch=79.2] | Loss=0.00812 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.326 | L2-Norm(final)=13.886 | 4852.4 samples/s | 75.8 steps/s
[Step=81150 Epoch=79.2] | Loss=0.00805 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.329 | L2-Norm(final)=13.889 | 4845.9 samples/s | 75.7 steps/s
[Step=81200 Epoch=79.3] | Loss=0.00796 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.331 | L2-Norm(final)=13.891 | 4827.0 samples/s | 75.4 steps/s
[Step=81250 Epoch=79.3] | Loss=0.00808 | Reg=0.00107 | acc=0.9688 | L2-Norm=10.333 | L2-Norm(final)=13.893 | 4799.5 samples/s | 75.0 steps/s
[Step=81300 Epoch=79.4] | Loss=0.00809 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.335 | L2-Norm(final)=13.896 | 4849.4 samples/s | 75.8 steps/s
[Step=81350 Epoch=79.4] | Loss=0.00813 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.337 | L2-Norm(final)=13.898 | 4842.6 samples/s | 75.7 steps/s
[Step=81400 Epoch=79.5] | Loss=0.00803 | Reg=0.00107 | acc=0.9688 | L2-Norm=10.340 | L2-Norm(final)=13.900 | 4787.6 samples/s | 74.8 steps/s
[Step=81450 Epoch=79.5] | Loss=0.00795 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.342 | L2-Norm(final)=13.902 | 4840.4 samples/s | 75.6 steps/s
[Step=81500 Epoch=79.6] | Loss=0.00804 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.344 | L2-Norm(final)=13.905 | 5181.8 samples/s | 81.0 steps/s
[Step=81550 Epoch=79.6] | Loss=0.00792 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.346 | L2-Norm(final)=13.907 | 2131.8 samples/s | 33.3 steps/s
[Step=81600 Epoch=79.7] | Loss=0.00789 | Reg=0.00107 | acc=0.9844 | L2-Norm=10.347 | L2-Norm(final)=13.909 | 4811.4 samples/s | 75.2 steps/s
[Step=81650 Epoch=79.7] | Loss=0.00780 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.349 | L2-Norm(final)=13.911 | 4858.8 samples/s | 75.9 steps/s
[Step=81700 Epoch=79.8] | Loss=0.00775 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.351 | L2-Norm(final)=13.914 | 4829.4 samples/s | 75.5 steps/s
[Step=81750 Epoch=79.8] | Loss=0.00766 | Reg=0.00107 | acc=0.9844 | L2-Norm=10.353 | L2-Norm(final)=13.916 | 4816.2 samples/s | 75.3 steps/s
[Step=81800 Epoch=79.9] | Loss=0.00761 | Reg=0.00107 | acc=0.9844 | L2-Norm=10.355 | L2-Norm(final)=13.918 | 4856.5 samples/s | 75.9 steps/s
[Step=81850 Epoch=79.9] | Loss=0.00758 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.357 | L2-Norm(final)=13.920 | 4845.0 samples/s | 75.7 steps/s
[Step=81900 Epoch=80.0] | Loss=0.00751 | Reg=0.00107 | acc=0.9844 | L2-Norm=10.358 | L2-Norm(final)=13.923 | 4839.0 samples/s | 75.6 steps/s
[Step=81950 Epoch=80.0] | Loss=0.00745 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.360 | L2-Norm(final)=13.925 | 4849.7 samples/s | 75.8 steps/s
[Step=82000 Epoch=80.1] | Loss=0.00742 | Reg=0.00107 | acc=0.9844 | L2-Norm=10.362 | L2-Norm(final)=13.927 | 4860.2 samples/s | 75.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step82000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=80001 Epoch=150.8] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.292 | L2-Norm(final)=15.522 | 4188.2 samples/s | 65.4 steps/s
[Step=80050 Epoch=150.9] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.291 | L2-Norm(final)=15.524 | 4970.4 samples/s | 77.7 steps/s
[Step=80100 Epoch=151.0] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.291 | L2-Norm(final)=15.526 | 5364.5 samples/s | 83.8 steps/s
[Step=80150 Epoch=151.1] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.528 | 5231.5 samples/s | 81.7 steps/s
[Step=80200 Epoch=151.2] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.531 | 5296.9 samples/s | 82.8 steps/s
[Step=80250 Epoch=151.3] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.533 | 5260.9 samples/s | 82.2 steps/s
[Step=80300 Epoch=151.4] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.535 | 5450.4 samples/s | 85.2 steps/s
[Step=80350 Epoch=151.5] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.538 | 5144.1 samples/s | 80.4 steps/s
[Step=80400 Epoch=151.6] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.540 | 5262.8 samples/s | 82.2 steps/s
[Step=80450 Epoch=151.6] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.542 | 5343.3 samples/s | 83.5 steps/s
[Step=80500 Epoch=151.7] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.545 | 5340.0 samples/s | 83.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=151.7] | Loss=0.00005 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=15.569 | 4400.1 samples/s | 68.8 steps/s
[Step=80550 Epoch=151.8] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.284 | L2-Norm(final)=15.571 | 4213.6 samples/s | 65.8 steps/s
[Step=80600 Epoch=151.9] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.276 | L2-Norm(final)=15.572 | 4588.5 samples/s | 71.7 steps/s
[Step=80650 Epoch=152.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.269 | L2-Norm(final)=15.574 | 4623.8 samples/s | 72.2 steps/s
[Step=80700 Epoch=152.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.261 | L2-Norm(final)=15.575 | 4641.8 samples/s | 72.5 steps/s
[Step=80750 Epoch=152.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.253 | L2-Norm(final)=15.576 | 4657.0 samples/s | 72.8 steps/s
[Step=80800 Epoch=152.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=15.577 | 4492.5 samples/s | 70.2 steps/s
[Step=80850 Epoch=152.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.237 | L2-Norm(final)=15.578 | 4599.2 samples/s | 71.9 steps/s
[Step=80900 Epoch=152.5] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.229 | L2-Norm(final)=15.579 | 4668.2 samples/s | 72.9 steps/s
[Step=80950 Epoch=152.6] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.221 | L2-Norm(final)=15.580 | 4581.8 samples/s | 71.6 steps/s
[Step=81000 Epoch=152.7] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.213 | L2-Norm(final)=15.581 | 4676.3 samples/s | 73.1 steps/s
[Step=81050 Epoch=152.8] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.204 | L2-Norm(final)=15.582 | 2112.6 samples/s | 33.0 steps/s
[Step=81100 Epoch=152.9] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.196 | L2-Norm(final)=15.582 | 4705.1 samples/s | 73.5 steps/s
[Step=81150 Epoch=153.0] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.187 | L2-Norm(final)=15.583 | 4554.5 samples/s | 71.2 steps/s
[Step=81200 Epoch=153.1] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.179 | L2-Norm(final)=15.584 | 4612.9 samples/s | 72.1 steps/s
[Step=81250 Epoch=153.2] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.170 | L2-Norm(final)=15.584 | 4589.6 samples/s | 71.7 steps/s
[Step=81300 Epoch=153.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.161 | L2-Norm(final)=15.585 | 4681.2 samples/s | 73.1 steps/s
[Step=81350 Epoch=153.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.152 | L2-Norm(final)=15.586 | 4550.1 samples/s | 71.1 steps/s
[Step=81400 Epoch=153.4] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=15.586 | 4612.6 samples/s | 72.1 steps/s
[Step=81450 Epoch=153.5] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.133 | L2-Norm(final)=15.587 | 4610.3 samples/s | 72.0 steps/s
[Step=81500 Epoch=153.6] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.124 | L2-Norm(final)=15.587 | 4610.1 samples/s | 72.0 steps/s
[Step=81550 Epoch=153.7] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.115 | L2-Norm(final)=15.588 | 5700.1 samples/s | 89.1 steps/s
[Step=81600 Epoch=153.8] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=15.589 | 1947.3 samples/s | 30.4 steps/s
[Step=81650 Epoch=153.9] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.095 | L2-Norm(final)=15.589 | 4600.4 samples/s | 71.9 steps/s
[Step=81700 Epoch=154.0] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.086 | L2-Norm(final)=15.590 | 4608.2 samples/s | 72.0 steps/s
[Step=81750 Epoch=154.1] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.076 | L2-Norm(final)=15.591 | 4601.9 samples/s | 71.9 steps/s
[Step=81800 Epoch=154.2] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.066 | L2-Norm(final)=15.591 | 4630.2 samples/s | 72.3 steps/s
[Step=81850 Epoch=154.3] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.056 | L2-Norm(final)=15.592 | 4578.6 samples/s | 71.5 steps/s
[Step=81900 Epoch=154.4] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.046 | L2-Norm(final)=15.593 | 4636.5 samples/s | 72.4 steps/s
[Step=81950 Epoch=154.5] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.035 | L2-Norm(final)=15.593 | 4615.0 samples/s | 72.1 steps/s
[Step=82000 Epoch=154.6] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.025 | L2-Norm(final)=15.594 | 4647.0 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06359 | acc=0.9707 | tpr=0.9752 | fpr=0.0391 | 4192.4 samples/s | 16.4 steps/s
Avg test loss: 0.06539, Avg test acc: 0.97023, Avg tpr: 0.97505, Avg fpr: 0.04038, total FA: 315

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.07172 | acc=0.2993 | tpr=0.0071 | fpr=0.0662 | 4001.1 samples/s | 15.6 steps/s
Avg test loss: 7.06144, Avg test acc: 0.29542, Avg tpr: 0.00711, Avg fpr: 0.07050, total FA: 550

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.26077 | acc=0.1598 | tpr=0.2522 | fpr=0.8418 | 4212.0 samples/s | 16.5 steps/s
[Step= 100] | Loss=4.24560 | acc=0.1611 | tpr=0.2516 | fpr=0.8406 | 7955.0 samples/s | 31.1 steps/s
[Step= 150] | Loss=4.23171 | acc=0.1625 | tpr=0.2536 | fpr=0.8392 | 8091.4 samples/s | 31.6 steps/s
[Step= 200] | Loss=4.22628 | acc=0.1631 | tpr=0.2448 | fpr=0.8384 | 7935.9 samples/s | 31.0 steps/s
[Step= 250] | Loss=4.22833 | acc=0.1633 | tpr=0.2437 | fpr=0.8382 | 8095.4 samples/s | 31.6 steps/s
[Step= 300] | Loss=4.22778 | acc=0.1634 | tpr=0.2495 | fpr=0.8382 | 7972.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.22538 | acc=0.1634 | tpr=0.2517 | fpr=0.8382 | 7825.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=4.22707 | acc=0.1631 | tpr=0.2522 | fpr=0.8385 | 8083.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=4.23023 | acc=0.1625 | tpr=0.2546 | fpr=0.8392 | 8087.3 samples/s | 31.6 steps/s
[Step= 500] | Loss=4.22832 | acc=0.1623 | tpr=0.2555 | fpr=0.8393 | 7902.2 samples/s | 30.9 steps/s
[Step= 550] | Loss=4.22943 | acc=0.1622 | tpr=0.2563 | fpr=0.8395 | 14371.7 samples/s | 56.1 steps/s
Avg test loss: 4.23055, Avg test acc: 0.16210, Avg tpr: 0.25594, Avg fpr: 0.83960, total FA: 116577

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13084 | acc=0.9801 | tpr=0.9513 | fpr=0.0194 | 4226.2 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.13525 | acc=0.9795 | tpr=0.9595 | fpr=0.0202 | 7903.2 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.13879 | acc=0.9790 | tpr=0.9625 | fpr=0.0207 | 8033.9 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.14092 | acc=0.9791 | tpr=0.9672 | fpr=0.0207 | 7982.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.13888 | acc=0.9793 | tpr=0.9642 | fpr=0.0205 | 7999.8 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14190 | acc=0.9789 | tpr=0.9636 | fpr=0.0209 | 8010.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.14158 | acc=0.9788 | tpr=0.9643 | fpr=0.0209 | 8056.8 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.14288 | acc=0.9787 | tpr=0.9628 | fpr=0.0211 | 8080.5 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14501 | acc=0.9785 | tpr=0.9625 | fpr=0.0212 | 7930.6 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.14416 | acc=0.9785 | tpr=0.9626 | fpr=0.0212 | 8049.9 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.14315 | acc=0.9788 | tpr=0.9614 | fpr=0.0209 | 14075.3 samples/s | 55.0 steps/s
Avg test loss: 0.14294, Avg test acc: 0.97881, Avg tpr: 0.96117, Avg fpr: 0.02086, total FA: 2897

server round 41/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=82001 Epoch=80.1] | Loss=0.00340 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.042 | L2-Norm(final)=13.993 | 4204.9 samples/s | 65.7 steps/s
[Step=82050 Epoch=80.1] | Loss=0.01050 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.043 | L2-Norm(final)=13.994 | 5591.7 samples/s | 87.4 steps/s
[Step=82100 Epoch=80.2] | Loss=0.01013 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.043 | L2-Norm(final)=13.993 | 5611.9 samples/s | 87.7 steps/s
[Step=82150 Epoch=80.2] | Loss=0.01005 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.993 | 5541.6 samples/s | 86.6 steps/s
[Step=82200 Epoch=80.3] | Loss=0.01008 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.994 | 5509.3 samples/s | 86.1 steps/s
[Step=82250 Epoch=80.3] | Loss=0.01032 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.994 | 5569.9 samples/s | 87.0 steps/s
[Step=82300 Epoch=80.4] | Loss=0.01001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.043 | L2-Norm(final)=13.995 | 5616.4 samples/s | 87.8 steps/s
[Step=82350 Epoch=80.4] | Loss=0.01012 | Reg=0.00101 | acc=0.9688 | L2-Norm=10.043 | L2-Norm(final)=13.996 | 5730.2 samples/s | 89.5 steps/s
[Step=82400 Epoch=80.5] | Loss=0.01000 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.996 | 5486.0 samples/s | 85.7 steps/s
[Step=82450 Epoch=80.5] | Loss=0.01006 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.997 | 5585.6 samples/s | 87.3 steps/s
[Step=82500 Epoch=80.5] | Loss=0.01008 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.043 | L2-Norm(final)=13.998 | 5708.5 samples/s | 89.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=80.5] | Loss=0.00122 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.043 | L2-Norm(final)=14.006 | 3979.7 samples/s | 62.2 steps/s
[Step=82550 Epoch=80.6] | Loss=0.01024 | Reg=0.00101 | acc=0.9688 | L2-Norm=10.046 | L2-Norm(final)=14.009 | 4672.5 samples/s | 73.0 steps/s
[Step=82600 Epoch=80.6] | Loss=0.01035 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.051 | L2-Norm(final)=14.012 | 4841.8 samples/s | 75.7 steps/s
[Step=82650 Epoch=80.7] | Loss=0.01010 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.056 | L2-Norm(final)=14.015 | 4844.9 samples/s | 75.7 steps/s
[Step=82700 Epoch=80.7] | Loss=0.00985 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.060 | L2-Norm(final)=14.018 | 4808.9 samples/s | 75.1 steps/s
[Step=82750 Epoch=80.8] | Loss=0.00961 | Reg=0.00101 | acc=0.9688 | L2-Norm=10.063 | L2-Norm(final)=14.021 | 4812.3 samples/s | 75.2 steps/s
[Step=82800 Epoch=80.8] | Loss=0.00943 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.067 | L2-Norm(final)=14.023 | 4803.2 samples/s | 75.1 steps/s
[Step=82850 Epoch=80.9] | Loss=0.00918 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.070 | L2-Norm(final)=14.026 | 4817.9 samples/s | 75.3 steps/s
[Step=82900 Epoch=80.9] | Loss=0.00903 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.073 | L2-Norm(final)=14.028 | 4861.9 samples/s | 76.0 steps/s
[Step=82950 Epoch=81.0] | Loss=0.00892 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.076 | L2-Norm(final)=14.031 | 4855.3 samples/s | 75.9 steps/s
[Step=83000 Epoch=81.0] | Loss=0.00873 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.079 | L2-Norm(final)=14.033 | 4883.5 samples/s | 76.3 steps/s
[Step=83050 Epoch=81.1] | Loss=0.00881 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.082 | L2-Norm(final)=14.036 | 4762.5 samples/s | 74.4 steps/s
[Step=83100 Epoch=81.1] | Loss=0.00892 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.085 | L2-Norm(final)=14.038 | 4840.2 samples/s | 75.6 steps/s
[Step=83150 Epoch=81.2] | Loss=0.00893 | Reg=0.00102 | acc=0.9688 | L2-Norm=10.088 | L2-Norm(final)=14.041 | 4834.1 samples/s | 75.5 steps/s
[Step=83200 Epoch=81.2] | Loss=0.00882 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.091 | L2-Norm(final)=14.043 | 4841.8 samples/s | 75.7 steps/s
[Step=83250 Epoch=81.3] | Loss=0.00876 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.094 | L2-Norm(final)=14.046 | 4843.7 samples/s | 75.7 steps/s
[Step=83300 Epoch=81.3] | Loss=0.00885 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.096 | L2-Norm(final)=14.048 | 4812.7 samples/s | 75.2 steps/s
[Step=83350 Epoch=81.4] | Loss=0.00883 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.099 | L2-Norm(final)=14.051 | 4836.7 samples/s | 75.6 steps/s
[Step=83400 Epoch=81.4] | Loss=0.00889 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=14.053 | 4836.0 samples/s | 75.6 steps/s
[Step=83450 Epoch=81.5] | Loss=0.00881 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.104 | L2-Norm(final)=14.055 | 4852.7 samples/s | 75.8 steps/s
[Step=83500 Epoch=81.5] | Loss=0.00875 | Reg=0.00102 | acc=0.9688 | L2-Norm=10.106 | L2-Norm(final)=14.058 | 5151.7 samples/s | 80.5 steps/s
[Step=83550 Epoch=81.6] | Loss=0.00873 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=14.060 | 2057.0 samples/s | 32.1 steps/s
[Step=83600 Epoch=81.6] | Loss=0.00865 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.111 | L2-Norm(final)=14.062 | 4920.2 samples/s | 76.9 steps/s
[Step=83650 Epoch=81.7] | Loss=0.00856 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.113 | L2-Norm(final)=14.065 | 4789.7 samples/s | 74.8 steps/s
[Step=83700 Epoch=81.7] | Loss=0.00854 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.115 | L2-Norm(final)=14.067 | 4778.3 samples/s | 74.7 steps/s
[Step=83750 Epoch=81.8] | Loss=0.00842 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.117 | L2-Norm(final)=14.070 | 4823.8 samples/s | 75.4 steps/s
[Step=83800 Epoch=81.8] | Loss=0.00829 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.119 | L2-Norm(final)=14.072 | 4871.5 samples/s | 76.1 steps/s
[Step=83850 Epoch=81.9] | Loss=0.00826 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.121 | L2-Norm(final)=14.074 | 4830.2 samples/s | 75.5 steps/s
[Step=83900 Epoch=81.9] | Loss=0.00820 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.123 | L2-Norm(final)=14.076 | 4870.6 samples/s | 76.1 steps/s
[Step=83950 Epoch=82.0] | Loss=0.00814 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.125 | L2-Norm(final)=14.079 | 4794.5 samples/s | 74.9 steps/s
[Step=84000 Epoch=82.0] | Loss=0.00806 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.127 | L2-Norm(final)=14.081 | 4928.6 samples/s | 77.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step84000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=82001 Epoch=154.6] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.042 | L2-Norm(final)=15.615 | 4220.7 samples/s | 65.9 steps/s
[Step=82050 Epoch=154.7] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.039 | L2-Norm(final)=15.618 | 4643.4 samples/s | 72.6 steps/s
[Step=82100 Epoch=154.8] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.620 | 5256.6 samples/s | 82.1 steps/s
[Step=82150 Epoch=154.9] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.622 | 5303.0 samples/s | 82.9 steps/s
[Step=82200 Epoch=154.9] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.625 | 5301.2 samples/s | 82.8 steps/s
[Step=82250 Epoch=155.0] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.628 | 5350.8 samples/s | 83.6 steps/s
[Step=82300 Epoch=155.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.630 | 5362.0 samples/s | 83.8 steps/s
[Step=82350 Epoch=155.2] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.633 | 5219.8 samples/s | 81.6 steps/s
[Step=82400 Epoch=155.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.636 | 5370.2 samples/s | 83.9 steps/s
[Step=82450 Epoch=155.4] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.640 | 5152.1 samples/s | 80.5 steps/s
[Step=82500 Epoch=155.5] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.643 | 5408.2 samples/s | 84.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=155.5] | Loss=0.00004 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.038 | L2-Norm(final)=15.678 | 3884.9 samples/s | 60.7 steps/s
[Step=82550 Epoch=155.6] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.026 | L2-Norm(final)=15.682 | 4401.4 samples/s | 68.8 steps/s
[Step=82600 Epoch=155.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.011 | L2-Norm(final)=15.684 | 4675.7 samples/s | 73.1 steps/s
[Step=82650 Epoch=155.8] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.996 | L2-Norm(final)=15.686 | 4612.6 samples/s | 72.1 steps/s
[Step=82700 Epoch=155.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.980 | L2-Norm(final)=15.688 | 4568.2 samples/s | 71.4 steps/s
[Step=82750 Epoch=156.0] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.963 | L2-Norm(final)=15.689 | 4608.8 samples/s | 72.0 steps/s
[Step=82800 Epoch=156.1] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.947 | L2-Norm(final)=15.690 | 4645.9 samples/s | 72.6 steps/s
[Step=82850 Epoch=156.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.930 | L2-Norm(final)=15.692 | 4649.8 samples/s | 72.7 steps/s
[Step=82900 Epoch=156.3] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.913 | L2-Norm(final)=15.693 | 4639.3 samples/s | 72.5 steps/s
[Step=82950 Epoch=156.4] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.897 | L2-Norm(final)=15.694 | 4557.6 samples/s | 71.2 steps/s
[Step=83000 Epoch=156.5] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.880 | L2-Norm(final)=15.695 | 4643.1 samples/s | 72.5 steps/s
[Step=83050 Epoch=156.6] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.863 | L2-Norm(final)=15.697 | 2112.1 samples/s | 33.0 steps/s
[Step=83100 Epoch=156.6] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.845 | L2-Norm(final)=15.698 | 4617.6 samples/s | 72.1 steps/s
[Step=83150 Epoch=156.7] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.828 | L2-Norm(final)=15.699 | 4670.0 samples/s | 73.0 steps/s
[Step=83200 Epoch=156.8] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.811 | L2-Norm(final)=15.700 | 4579.4 samples/s | 71.6 steps/s
[Step=83250 Epoch=156.9] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.794 | L2-Norm(final)=15.701 | 4618.6 samples/s | 72.2 steps/s
[Step=83300 Epoch=157.0] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.776 | L2-Norm(final)=15.702 | 4685.2 samples/s | 73.2 steps/s
[Step=83350 Epoch=157.1] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.759 | L2-Norm(final)=15.703 | 4638.3 samples/s | 72.5 steps/s
[Step=83400 Epoch=157.2] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.741 | L2-Norm(final)=15.705 | 4610.5 samples/s | 72.0 steps/s
[Step=83450 Epoch=157.3] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.723 | L2-Norm(final)=15.706 | 4563.9 samples/s | 71.3 steps/s
[Step=83500 Epoch=157.4] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.705 | L2-Norm(final)=15.707 | 4594.3 samples/s | 71.8 steps/s
[Step=83550 Epoch=157.5] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.687 | L2-Norm(final)=15.708 | 5728.3 samples/s | 89.5 steps/s
[Step=83600 Epoch=157.6] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.670 | L2-Norm(final)=15.710 | 1925.8 samples/s | 30.1 steps/s
[Step=83650 Epoch=157.7] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.651 | L2-Norm(final)=15.711 | 4584.8 samples/s | 71.6 steps/s
[Step=83700 Epoch=157.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.633 | L2-Norm(final)=15.713 | 4601.1 samples/s | 71.9 steps/s
[Step=83750 Epoch=157.9] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.615 | L2-Norm(final)=15.714 | 4610.1 samples/s | 72.0 steps/s
[Step=83800 Epoch=158.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.597 | L2-Norm(final)=15.716 | 4669.3 samples/s | 73.0 steps/s
[Step=83850 Epoch=158.1] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.578 | L2-Norm(final)=15.717 | 4684.0 samples/s | 73.2 steps/s
[Step=83900 Epoch=158.2] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.560 | L2-Norm(final)=15.718 | 4651.3 samples/s | 72.7 steps/s
[Step=83950 Epoch=158.2] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.541 | L2-Norm(final)=15.720 | 4577.4 samples/s | 71.5 steps/s
[Step=84000 Epoch=158.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.522 | L2-Norm(final)=15.721 | 4631.7 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06111 | acc=0.9702 | tpr=0.9749 | fpr=0.0399 | 4236.2 samples/s | 16.5 steps/s
Avg test loss: 0.06282, Avg test acc: 0.96959, Avg tpr: 0.97453, Avg fpr: 0.04128, total FA: 322

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.98318 | acc=0.2988 | tpr=0.0067 | fpr=0.0669 | 4253.3 samples/s | 16.6 steps/s
Avg test loss: 6.97447, Avg test acc: 0.29486, Avg tpr: 0.00659, Avg fpr: 0.07114, total FA: 555

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.06782 | acc=0.1559 | tpr=0.2345 | fpr=0.8455 | 4238.0 samples/s | 16.6 steps/s
[Step= 100] | Loss=4.05179 | acc=0.1588 | tpr=0.2367 | fpr=0.8427 | 7880.3 samples/s | 30.8 steps/s
[Step= 150] | Loss=4.03796 | acc=0.1607 | tpr=0.2435 | fpr=0.8408 | 8007.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=4.03362 | acc=0.1616 | tpr=0.2415 | fpr=0.8399 | 7977.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.03494 | acc=0.1616 | tpr=0.2376 | fpr=0.8398 | 8089.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=4.03420 | acc=0.1618 | tpr=0.2422 | fpr=0.8397 | 8037.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=4.03170 | acc=0.1620 | tpr=0.2455 | fpr=0.8396 | 7834.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=4.03344 | acc=0.1617 | tpr=0.2456 | fpr=0.8398 | 8162.5 samples/s | 31.9 steps/s
[Step= 450] | Loss=4.03608 | acc=0.1613 | tpr=0.2493 | fpr=0.8403 | 7908.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=4.03434 | acc=0.1611 | tpr=0.2485 | fpr=0.8405 | 7860.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=4.03541 | acc=0.1609 | tpr=0.2495 | fpr=0.8407 | 14542.8 samples/s | 56.8 steps/s
Avg test loss: 4.03650, Avg test acc: 0.16075, Avg tpr: 0.24921, Avg fpr: 0.84086, total FA: 116752

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13406 | acc=0.9788 | tpr=0.9558 | fpr=0.0208 | 4283.1 samples/s | 16.7 steps/s
[Step= 100] | Loss=0.13804 | acc=0.9786 | tpr=0.9638 | fpr=0.0212 | 7767.9 samples/s | 30.3 steps/s
[Step= 150] | Loss=0.14225 | acc=0.9779 | tpr=0.9654 | fpr=0.0218 | 7862.4 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.14407 | acc=0.9780 | tpr=0.9694 | fpr=0.0219 | 8120.3 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.14189 | acc=0.9781 | tpr=0.9659 | fpr=0.0217 | 7993.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14486 | acc=0.9778 | tpr=0.9673 | fpr=0.0220 | 7971.1 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.14463 | acc=0.9778 | tpr=0.9681 | fpr=0.0220 | 7957.4 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14596 | acc=0.9777 | tpr=0.9666 | fpr=0.0221 | 8356.9 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.14818 | acc=0.9776 | tpr=0.9664 | fpr=0.0222 | 7701.6 samples/s | 30.1 steps/s
[Step= 500] | Loss=0.14730 | acc=0.9776 | tpr=0.9661 | fpr=0.0222 | 7819.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.14622 | acc=0.9779 | tpr=0.9650 | fpr=0.0219 | 15608.2 samples/s | 61.0 steps/s
Avg test loss: 0.14599, Avg test acc: 0.97791, Avg tpr: 0.96474, Avg fpr: 0.02185, total FA: 3034

server round 42/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=84001 Epoch=82.0] | Loss=0.00366 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.149 | 4213.0 samples/s | 65.8 steps/s
[Step=84050 Epoch=82.1] | Loss=0.01432 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.149 | 5167.3 samples/s | 80.7 steps/s
[Step=84100 Epoch=82.1] | Loss=0.01690 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.543 | L2-Norm(final)=14.147 | 5551.8 samples/s | 86.7 steps/s
[Step=84150 Epoch=82.2] | Loss=0.01650 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.144 | 5624.1 samples/s | 87.9 steps/s
[Step=84200 Epoch=82.2] | Loss=0.01597 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.143 | 5542.5 samples/s | 86.6 steps/s
[Step=84250 Epoch=82.3] | Loss=0.01586 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.142 | 5647.5 samples/s | 88.2 steps/s
[Step=84300 Epoch=82.3] | Loss=0.01540 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.142 | 5654.0 samples/s | 88.3 steps/s
[Step=84350 Epoch=82.4] | Loss=0.01514 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.143 | 5536.8 samples/s | 86.5 steps/s
[Step=84400 Epoch=82.4] | Loss=0.01478 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.144 | 5513.0 samples/s | 86.1 steps/s
[Step=84450 Epoch=82.5] | Loss=0.01473 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.543 | L2-Norm(final)=14.145 | 5387.9 samples/s | 84.2 steps/s
[Step=84500 Epoch=82.5] | Loss=0.01471 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.543 | L2-Norm(final)=14.146 | 5648.5 samples/s | 88.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=82.5] | Loss=0.00617 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=14.160 | 4137.8 samples/s | 64.7 steps/s
[Step=84550 Epoch=82.5] | Loss=0.01419 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.551 | L2-Norm(final)=14.162 | 4761.7 samples/s | 74.4 steps/s
[Step=84600 Epoch=82.6] | Loss=0.01438 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.558 | L2-Norm(final)=14.165 | 4739.1 samples/s | 74.0 steps/s
[Step=84650 Epoch=82.6] | Loss=0.01450 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.564 | L2-Norm(final)=14.168 | 4797.7 samples/s | 75.0 steps/s
[Step=84700 Epoch=82.7] | Loss=0.01360 | Reg=0.00092 | acc=0.9844 | L2-Norm=9.570 | L2-Norm(final)=14.171 | 4854.6 samples/s | 75.9 steps/s
[Step=84750 Epoch=82.7] | Loss=0.01357 | Reg=0.00092 | acc=0.9844 | L2-Norm=9.575 | L2-Norm(final)=14.174 | 4888.0 samples/s | 76.4 steps/s
[Step=84800 Epoch=82.8] | Loss=0.01310 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.580 | L2-Norm(final)=14.177 | 4811.9 samples/s | 75.2 steps/s
[Step=84850 Epoch=82.8] | Loss=0.01270 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.584 | L2-Norm(final)=14.180 | 4906.5 samples/s | 76.7 steps/s
[Step=84900 Epoch=82.9] | Loss=0.01270 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.589 | L2-Norm(final)=14.183 | 4805.5 samples/s | 75.1 steps/s
[Step=84950 Epoch=82.9] | Loss=0.01241 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.593 | L2-Norm(final)=14.186 | 4817.3 samples/s | 75.3 steps/s
[Step=85000 Epoch=83.0] | Loss=0.01219 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.597 | L2-Norm(final)=14.189 | 4900.5 samples/s | 76.6 steps/s
[Step=85050 Epoch=83.0] | Loss=0.01202 | Reg=0.00092 | acc=0.9844 | L2-Norm=9.601 | L2-Norm(final)=14.192 | 4837.0 samples/s | 75.6 steps/s
[Step=85100 Epoch=83.1] | Loss=0.01175 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.605 | L2-Norm(final)=14.195 | 4852.2 samples/s | 75.8 steps/s
[Step=85150 Epoch=83.1] | Loss=0.01172 | Reg=0.00092 | acc=0.9844 | L2-Norm=9.608 | L2-Norm(final)=14.197 | 4853.0 samples/s | 75.8 steps/s
[Step=85200 Epoch=83.2] | Loss=0.01152 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.611 | L2-Norm(final)=14.200 | 4874.9 samples/s | 76.2 steps/s
[Step=85250 Epoch=83.2] | Loss=0.01139 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.615 | L2-Norm(final)=14.203 | 4894.2 samples/s | 76.5 steps/s
[Step=85300 Epoch=83.3] | Loss=0.01122 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.618 | L2-Norm(final)=14.206 | 4829.1 samples/s | 75.5 steps/s
[Step=85350 Epoch=83.3] | Loss=0.01124 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.621 | L2-Norm(final)=14.209 | 4891.3 samples/s | 76.4 steps/s
[Step=85400 Epoch=83.4] | Loss=0.01110 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.624 | L2-Norm(final)=14.211 | 4860.3 samples/s | 75.9 steps/s
[Step=85450 Epoch=83.4] | Loss=0.01098 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.627 | L2-Norm(final)=14.214 | 4868.1 samples/s | 76.1 steps/s
[Step=85500 Epoch=83.5] | Loss=0.01097 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.630 | L2-Norm(final)=14.216 | 5115.1 samples/s | 79.9 steps/s
[Step=85550 Epoch=83.5] | Loss=0.01087 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.633 | L2-Norm(final)=14.219 | 2124.7 samples/s | 33.2 steps/s
[Step=85600 Epoch=83.6] | Loss=0.01078 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=14.222 | 4798.5 samples/s | 75.0 steps/s
[Step=85650 Epoch=83.6] | Loss=0.01066 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.639 | L2-Norm(final)=14.224 | 4848.4 samples/s | 75.8 steps/s
[Step=85700 Epoch=83.7] | Loss=0.01055 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.642 | L2-Norm(final)=14.227 | 4828.8 samples/s | 75.5 steps/s
[Step=85750 Epoch=83.7] | Loss=0.01048 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.645 | L2-Norm(final)=14.230 | 4848.7 samples/s | 75.8 steps/s
[Step=85800 Epoch=83.8] | Loss=0.01029 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=14.232 | 4854.9 samples/s | 75.9 steps/s
[Step=85850 Epoch=83.8] | Loss=0.01018 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.650 | L2-Norm(final)=14.235 | 4874.6 samples/s | 76.2 steps/s
[Step=85900 Epoch=83.9] | Loss=0.01005 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.653 | L2-Norm(final)=14.237 | 4818.3 samples/s | 75.3 steps/s
[Step=85950 Epoch=83.9] | Loss=0.00999 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=14.240 | 4806.4 samples/s | 75.1 steps/s
[Step=86000 Epoch=84.0] | Loss=0.00993 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.658 | L2-Norm(final)=14.242 | 4878.3 samples/s | 76.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step86000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=84001 Epoch=158.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.543 | L2-Norm(final)=15.769 | 4546.2 samples/s | 71.0 steps/s
[Step=84050 Epoch=158.4] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.537 | L2-Norm(final)=15.774 | 4403.7 samples/s | 68.8 steps/s
[Step=84100 Epoch=158.5] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.536 | L2-Norm(final)=15.781 | 5273.4 samples/s | 82.4 steps/s
[Step=84150 Epoch=158.6] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.536 | L2-Norm(final)=15.788 | 5282.0 samples/s | 82.5 steps/s
[Step=84200 Epoch=158.7] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.536 | L2-Norm(final)=15.793 | 5316.7 samples/s | 83.1 steps/s
[Step=84250 Epoch=158.8] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.799 | 5300.5 samples/s | 82.8 steps/s
[Step=84300 Epoch=158.9] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.805 | 5325.1 samples/s | 83.2 steps/s
[Step=84350 Epoch=159.0] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.811 | 5286.1 samples/s | 82.6 steps/s
[Step=84400 Epoch=159.1] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.817 | 5299.0 samples/s | 82.8 steps/s
[Step=84450 Epoch=159.2] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.822 | 5375.2 samples/s | 84.0 steps/s
[Step=84500 Epoch=159.3] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.828 | 5272.3 samples/s | 82.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=159.3] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=15.881 | 3720.3 samples/s | 58.1 steps/s
[Step=84550 Epoch=159.4] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.514 | L2-Norm(final)=15.886 | 4669.0 samples/s | 73.0 steps/s
[Step=84600 Epoch=159.5] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.486 | L2-Norm(final)=15.890 | 4660.7 samples/s | 72.8 steps/s
[Step=84650 Epoch=159.6] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.457 | L2-Norm(final)=15.893 | 4534.3 samples/s | 70.8 steps/s
[Step=84700 Epoch=159.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.428 | L2-Norm(final)=15.895 | 4633.0 samples/s | 72.4 steps/s
[Step=84750 Epoch=159.8] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.399 | L2-Norm(final)=15.898 | 4567.1 samples/s | 71.4 steps/s
[Step=84800 Epoch=159.8] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.370 | L2-Norm(final)=15.900 | 4619.0 samples/s | 72.2 steps/s
[Step=84850 Epoch=159.9] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.341 | L2-Norm(final)=15.902 | 4625.3 samples/s | 72.3 steps/s
[Step=84900 Epoch=160.0] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.312 | L2-Norm(final)=15.904 | 4645.8 samples/s | 72.6 steps/s
[Step=84950 Epoch=160.1] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.284 | L2-Norm(final)=15.907 | 4659.5 samples/s | 72.8 steps/s
[Step=85000 Epoch=160.2] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.256 | L2-Norm(final)=15.909 | 4743.3 samples/s | 74.1 steps/s
[Step=85050 Epoch=160.3] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.228 | L2-Norm(final)=15.911 | 2084.2 samples/s | 32.6 steps/s
[Step=85100 Epoch=160.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.201 | L2-Norm(final)=15.914 | 4502.8 samples/s | 70.4 steps/s
[Step=85150 Epoch=160.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=15.916 | 4601.4 samples/s | 71.9 steps/s
[Step=85200 Epoch=160.6] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.147 | L2-Norm(final)=15.918 | 4678.8 samples/s | 73.1 steps/s
[Step=85250 Epoch=160.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.121 | L2-Norm(final)=15.921 | 4579.8 samples/s | 71.6 steps/s
[Step=85300 Epoch=160.8] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.094 | L2-Norm(final)=15.923 | 4651.0 samples/s | 72.7 steps/s
[Step=85350 Epoch=160.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=15.925 | 4638.3 samples/s | 72.5 steps/s
[Step=85400 Epoch=161.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.042 | L2-Norm(final)=15.927 | 4634.0 samples/s | 72.4 steps/s
[Step=85450 Epoch=161.1] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.016 | L2-Norm(final)=15.930 | 4599.4 samples/s | 71.9 steps/s
[Step=85500 Epoch=161.2] | Loss=0.00007 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.992 | L2-Norm(final)=15.932 | 4590.9 samples/s | 71.7 steps/s
[Step=85550 Epoch=161.3] | Loss=0.00006 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.971 | L2-Norm(final)=15.934 | 5700.9 samples/s | 89.1 steps/s
[Step=85600 Epoch=161.4] | Loss=0.00006 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.951 | L2-Norm(final)=15.936 | 1942.4 samples/s | 30.3 steps/s
[Step=85650 Epoch=161.5] | Loss=0.00006 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.933 | L2-Norm(final)=15.937 | 4568.2 samples/s | 71.4 steps/s
[Step=85700 Epoch=161.5] | Loss=0.00006 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.917 | L2-Norm(final)=15.939 | 4639.8 samples/s | 72.5 steps/s
[Step=85750 Epoch=161.6] | Loss=0.00005 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.902 | L2-Norm(final)=15.940 | 4644.9 samples/s | 72.6 steps/s
[Step=85800 Epoch=161.7] | Loss=0.00005 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.888 | L2-Norm(final)=15.941 | 4574.9 samples/s | 71.5 steps/s
[Step=85850 Epoch=161.8] | Loss=0.00005 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.875 | L2-Norm(final)=15.942 | 4654.7 samples/s | 72.7 steps/s
[Step=85900 Epoch=161.9] | Loss=0.00005 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.863 | L2-Norm(final)=15.943 | 4624.9 samples/s | 72.3 steps/s
[Step=85950 Epoch=162.0] | Loss=0.00005 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.851 | L2-Norm(final)=15.945 | 4642.2 samples/s | 72.5 steps/s
[Step=86000 Epoch=162.1] | Loss=0.00005 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.841 | L2-Norm(final)=15.945 | 4619.4 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05594 | acc=0.9709 | tpr=0.9779 | fpr=0.0441 | 4206.4 samples/s | 16.4 steps/s
Avg test loss: 0.05796, Avg test acc: 0.97059, Avg tpr: 0.97733, Avg fpr: 0.04423, total FA: 345

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.75121 | acc=0.2936 | tpr=0.0079 | fpr=0.0860 | 4225.8 samples/s | 16.5 steps/s
Avg test loss: 6.74628, Avg test acc: 0.28877, Avg tpr: 0.00682, Avg fpr: 0.09114, total FA: 711

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.01632 | acc=0.1441 | tpr=0.2301 | fpr=0.8574 | 4276.5 samples/s | 16.7 steps/s
[Step= 100] | Loss=4.00423 | acc=0.1470 | tpr=0.2431 | fpr=0.8548 | 7818.1 samples/s | 30.5 steps/s
[Step= 150] | Loss=3.99265 | acc=0.1479 | tpr=0.2450 | fpr=0.8538 | 7798.0 samples/s | 30.5 steps/s
[Step= 200] | Loss=3.98799 | acc=0.1482 | tpr=0.2372 | fpr=0.8534 | 8031.9 samples/s | 31.4 steps/s
[Step= 250] | Loss=3.98960 | acc=0.1485 | tpr=0.2349 | fpr=0.8531 | 8147.6 samples/s | 31.8 steps/s
[Step= 300] | Loss=3.98858 | acc=0.1488 | tpr=0.2393 | fpr=0.8528 | 8118.2 samples/s | 31.7 steps/s
[Step= 350] | Loss=3.98629 | acc=0.1486 | tpr=0.2417 | fpr=0.8531 | 7897.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=3.98818 | acc=0.1484 | tpr=0.2396 | fpr=0.8532 | 8039.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=3.99101 | acc=0.1481 | tpr=0.2429 | fpr=0.8536 | 8001.8 samples/s | 31.3 steps/s
[Step= 500] | Loss=3.98937 | acc=0.1477 | tpr=0.2392 | fpr=0.8539 | 7776.4 samples/s | 30.4 steps/s
[Step= 550] | Loss=3.99005 | acc=0.1476 | tpr=0.2411 | fpr=0.8541 | 15101.9 samples/s | 59.0 steps/s
Avg test loss: 3.99107, Avg test acc: 0.14749, Avg tpr: 0.24128, Avg fpr: 0.85421, total FA: 118606

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11469 | acc=0.9791 | tpr=0.9469 | fpr=0.0203 | 4187.5 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.11683 | acc=0.9796 | tpr=0.9574 | fpr=0.0200 | 7902.8 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.12039 | acc=0.9790 | tpr=0.9597 | fpr=0.0207 | 8185.6 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.12185 | acc=0.9790 | tpr=0.9639 | fpr=0.0207 | 8007.6 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.12022 | acc=0.9794 | tpr=0.9607 | fpr=0.0203 | 8037.5 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.12290 | acc=0.9790 | tpr=0.9585 | fpr=0.0206 | 7785.0 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.12244 | acc=0.9791 | tpr=0.9599 | fpr=0.0205 | 8110.0 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.12365 | acc=0.9789 | tpr=0.9590 | fpr=0.0207 | 7817.4 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.12548 | acc=0.9788 | tpr=0.9596 | fpr=0.0209 | 7965.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12460 | acc=0.9789 | tpr=0.9599 | fpr=0.0208 | 7927.6 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.12378 | acc=0.9791 | tpr=0.9586 | fpr=0.0205 | 14880.1 samples/s | 58.1 steps/s
Avg test loss: 0.12365, Avg test acc: 0.97910, Avg tpr: 0.95840, Avg fpr: 0.02053, total FA: 2850

server round 43/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=86001 Epoch=84.0] | Loss=0.02469 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=14.316 | 4093.1 samples/s | 64.0 steps/s
[Step=86050 Epoch=84.0] | Loss=0.01832 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.325 | 5474.8 samples/s | 85.5 steps/s
[Step=86100 Epoch=84.1] | Loss=0.02031 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.335 | 5558.9 samples/s | 86.9 steps/s
[Step=86150 Epoch=84.1] | Loss=0.02105 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=14.344 | 5706.4 samples/s | 89.2 steps/s
[Step=86200 Epoch=84.2] | Loss=0.02127 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=14.354 | 5551.9 samples/s | 86.7 steps/s
[Step=86250 Epoch=84.2] | Loss=0.02153 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.363 | 5601.4 samples/s | 87.5 steps/s
[Step=86300 Epoch=84.3] | Loss=0.02158 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.371 | 5691.8 samples/s | 88.9 steps/s
[Step=86350 Epoch=84.3] | Loss=0.02145 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.379 | 5559.6 samples/s | 86.9 steps/s
[Step=86400 Epoch=84.4] | Loss=0.02166 | Reg=0.00083 | acc=0.9688 | L2-Norm=9.097 | L2-Norm(final)=14.387 | 5544.1 samples/s | 86.6 steps/s
[Step=86450 Epoch=84.4] | Loss=0.02187 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.097 | L2-Norm(final)=14.394 | 5618.5 samples/s | 87.8 steps/s
[Step=86500 Epoch=84.5] | Loss=0.02174 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=14.402 | 5614.3 samples/s | 87.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=84.5] | Loss=0.01310 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=14.474 | 4260.5 samples/s | 66.6 steps/s
[Step=86550 Epoch=84.5] | Loss=0.01802 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.105 | L2-Norm(final)=14.479 | 4603.9 samples/s | 71.9 steps/s
[Step=86600 Epoch=84.6] | Loss=0.01599 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.114 | L2-Norm(final)=14.484 | 4850.0 samples/s | 75.8 steps/s
[Step=86650 Epoch=84.6] | Loss=0.01566 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.122 | L2-Norm(final)=14.489 | 4809.6 samples/s | 75.1 steps/s
[Step=86700 Epoch=84.6] | Loss=0.01570 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=14.494 | 4896.1 samples/s | 76.5 steps/s
[Step=86750 Epoch=84.7] | Loss=0.01507 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.136 | L2-Norm(final)=14.498 | 4784.6 samples/s | 74.8 steps/s
[Step=86800 Epoch=84.7] | Loss=0.01469 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.142 | L2-Norm(final)=14.502 | 4811.6 samples/s | 75.2 steps/s
[Step=86850 Epoch=84.8] | Loss=0.01490 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=14.505 | 4921.6 samples/s | 76.9 steps/s
[Step=86900 Epoch=84.8] | Loss=0.01485 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.153 | L2-Norm(final)=14.509 | 4794.9 samples/s | 74.9 steps/s
[Step=86950 Epoch=84.9] | Loss=0.01478 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.159 | L2-Norm(final)=14.512 | 4894.6 samples/s | 76.5 steps/s
[Step=87000 Epoch=84.9] | Loss=0.01450 | Reg=0.00084 | acc=0.9531 | L2-Norm=9.164 | L2-Norm(final)=14.516 | 4851.8 samples/s | 75.8 steps/s
[Step=87050 Epoch=85.0] | Loss=0.01430 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.169 | L2-Norm(final)=14.519 | 4916.8 samples/s | 76.8 steps/s
[Step=87100 Epoch=85.0] | Loss=0.01414 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.174 | L2-Norm(final)=14.522 | 4791.1 samples/s | 74.9 steps/s
[Step=87150 Epoch=85.1] | Loss=0.01389 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.179 | L2-Norm(final)=14.525 | 4845.1 samples/s | 75.7 steps/s
[Step=87200 Epoch=85.1] | Loss=0.01370 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.183 | L2-Norm(final)=14.529 | 4884.4 samples/s | 76.3 steps/s
[Step=87250 Epoch=85.2] | Loss=0.01356 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.188 | L2-Norm(final)=14.532 | 4850.1 samples/s | 75.8 steps/s
[Step=87300 Epoch=85.2] | Loss=0.01337 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.192 | L2-Norm(final)=14.535 | 4869.8 samples/s | 76.1 steps/s
[Step=87350 Epoch=85.3] | Loss=0.01326 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.196 | L2-Norm(final)=14.538 | 4875.5 samples/s | 76.2 steps/s
[Step=87400 Epoch=85.3] | Loss=0.01318 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.200 | L2-Norm(final)=14.541 | 4921.7 samples/s | 76.9 steps/s
[Step=87450 Epoch=85.4] | Loss=0.01317 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.204 | L2-Norm(final)=14.544 | 4842.2 samples/s | 75.7 steps/s
[Step=87500 Epoch=85.4] | Loss=0.01293 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.207 | L2-Norm(final)=14.547 | 5228.9 samples/s | 81.7 steps/s
[Step=87550 Epoch=85.5] | Loss=0.01270 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.211 | L2-Norm(final)=14.550 | 2123.6 samples/s | 33.2 steps/s
[Step=87600 Epoch=85.5] | Loss=0.01251 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.215 | L2-Norm(final)=14.553 | 4815.1 samples/s | 75.2 steps/s
[Step=87650 Epoch=85.6] | Loss=0.01232 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.218 | L2-Norm(final)=14.556 | 4849.7 samples/s | 75.8 steps/s
[Step=87700 Epoch=85.6] | Loss=0.01218 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.222 | L2-Norm(final)=14.559 | 4839.5 samples/s | 75.6 steps/s
[Step=87750 Epoch=85.7] | Loss=0.01202 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.225 | L2-Norm(final)=14.562 | 4802.8 samples/s | 75.0 steps/s
[Step=87800 Epoch=85.7] | Loss=0.01195 | Reg=0.00085 | acc=0.9688 | L2-Norm=9.229 | L2-Norm(final)=14.565 | 4838.9 samples/s | 75.6 steps/s
[Step=87850 Epoch=85.8] | Loss=0.01182 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.232 | L2-Norm(final)=14.568 | 4893.8 samples/s | 76.5 steps/s
[Step=87900 Epoch=85.8] | Loss=0.01171 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.235 | L2-Norm(final)=14.571 | 4845.1 samples/s | 75.7 steps/s
[Step=87950 Epoch=85.9] | Loss=0.01162 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.238 | L2-Norm(final)=14.574 | 4784.7 samples/s | 74.8 steps/s
[Step=88000 Epoch=85.9] | Loss=0.01158 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.241 | L2-Norm(final)=14.576 | 4809.1 samples/s | 75.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step88000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=86001 Epoch=162.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=15.974 | 4065.6 samples/s | 63.5 steps/s
[Step=86050 Epoch=162.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.974 | 4701.6 samples/s | 73.5 steps/s
[Step=86100 Epoch=162.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.974 | 5335.2 samples/s | 83.4 steps/s
[Step=86150 Epoch=162.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.975 | 5431.1 samples/s | 84.9 steps/s
[Step=86200 Epoch=162.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.975 | 5219.7 samples/s | 81.6 steps/s
[Step=86250 Epoch=162.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.975 | 5305.5 samples/s | 82.9 steps/s
[Step=86300 Epoch=162.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.975 | 5239.4 samples/s | 81.9 steps/s
[Step=86350 Epoch=162.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.976 | 5446.9 samples/s | 85.1 steps/s
[Step=86400 Epoch=162.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.976 | 5177.2 samples/s | 80.9 steps/s
[Step=86450 Epoch=163.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.976 | 5224.6 samples/s | 81.6 steps/s
[Step=86500 Epoch=163.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.977 | 5368.6 samples/s | 83.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=163.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=15.981 | 3915.8 samples/s | 61.2 steps/s
[Step=86550 Epoch=163.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.094 | L2-Norm(final)=15.981 | 4601.9 samples/s | 71.9 steps/s
[Step=86600 Epoch=163.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.093 | L2-Norm(final)=15.982 | 4656.3 samples/s | 72.8 steps/s
[Step=86650 Epoch=163.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.092 | L2-Norm(final)=15.982 | 4622.7 samples/s | 72.2 steps/s
[Step=86700 Epoch=163.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.091 | L2-Norm(final)=15.983 | 4589.4 samples/s | 71.7 steps/s
[Step=86750 Epoch=163.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.090 | L2-Norm(final)=15.983 | 4617.1 samples/s | 72.1 steps/s
[Step=86800 Epoch=163.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=15.984 | 4639.0 samples/s | 72.5 steps/s
[Step=86850 Epoch=163.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.088 | L2-Norm(final)=15.984 | 4597.2 samples/s | 71.8 steps/s
[Step=86900 Epoch=163.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=15.985 | 4605.5 samples/s | 72.0 steps/s
[Step=86950 Epoch=163.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=15.985 | 4677.2 samples/s | 73.1 steps/s
[Step=87000 Epoch=164.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=15.986 | 4664.7 samples/s | 72.9 steps/s
[Step=87050 Epoch=164.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=15.986 | 2159.2 samples/s | 33.7 steps/s
[Step=87100 Epoch=164.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.083 | L2-Norm(final)=15.987 | 4726.8 samples/s | 73.9 steps/s
[Step=87150 Epoch=164.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.082 | L2-Norm(final)=15.987 | 4545.1 samples/s | 71.0 steps/s
[Step=87200 Epoch=164.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.081 | L2-Norm(final)=15.988 | 4594.4 samples/s | 71.8 steps/s
[Step=87250 Epoch=164.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.080 | L2-Norm(final)=15.988 | 4667.8 samples/s | 72.9 steps/s
[Step=87300 Epoch=164.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=15.989 | 4636.5 samples/s | 72.4 steps/s
[Step=87350 Epoch=164.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=15.989 | 4558.8 samples/s | 71.2 steps/s
[Step=87400 Epoch=164.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=15.989 | 4649.7 samples/s | 72.7 steps/s
[Step=87450 Epoch=164.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.076 | L2-Norm(final)=15.990 | 4595.4 samples/s | 71.8 steps/s
[Step=87500 Epoch=164.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.074 | L2-Norm(final)=15.990 | 4613.7 samples/s | 72.1 steps/s
[Step=87550 Epoch=165.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.073 | L2-Norm(final)=15.990 | 5738.7 samples/s | 89.7 steps/s
[Step=87600 Epoch=165.1] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.072 | L2-Norm(final)=15.991 | 1923.4 samples/s | 30.1 steps/s
[Step=87650 Epoch=165.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.071 | L2-Norm(final)=15.991 | 4650.8 samples/s | 72.7 steps/s
[Step=87700 Epoch=165.3] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.069 | L2-Norm(final)=15.992 | 4537.7 samples/s | 70.9 steps/s
[Step=87750 Epoch=165.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=15.992 | 4648.3 samples/s | 72.6 steps/s
[Step=87800 Epoch=165.5] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.067 | L2-Norm(final)=15.992 | 4538.1 samples/s | 70.9 steps/s
[Step=87850 Epoch=165.6] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.065 | L2-Norm(final)=15.993 | 4602.8 samples/s | 71.9 steps/s
[Step=87900 Epoch=165.7] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.064 | L2-Norm(final)=15.993 | 4563.2 samples/s | 71.3 steps/s
[Step=87950 Epoch=165.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.063 | L2-Norm(final)=15.993 | 4625.0 samples/s | 72.3 steps/s
[Step=88000 Epoch=165.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.061 | L2-Norm(final)=15.994 | 4543.6 samples/s | 71.0 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05287 | acc=0.9720 | tpr=0.9805 | fpr=0.0466 | 4197.2 samples/s | 16.4 steps/s
Avg test loss: 0.05475, Avg test acc: 0.97111, Avg tpr: 0.97995, Avg fpr: 0.04833, total FA: 377

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.59183 | acc=0.2971 | tpr=0.0073 | fpr=0.0736 | 4199.9 samples/s | 16.4 steps/s
Avg test loss: 6.58304, Avg test acc: 0.29281, Avg tpr: 0.00676, Avg fpr: 0.07807, total FA: 609

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.77451 | acc=0.1449 | tpr=0.2743 | fpr=0.8574 | 4069.6 samples/s | 15.9 steps/s
[Step= 100] | Loss=3.76337 | acc=0.1464 | tpr=0.2729 | fpr=0.8559 | 7753.2 samples/s | 30.3 steps/s
[Step= 150] | Loss=3.75183 | acc=0.1479 | tpr=0.2695 | fpr=0.8543 | 7986.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=3.74791 | acc=0.1481 | tpr=0.2656 | fpr=0.8541 | 8131.1 samples/s | 31.8 steps/s
[Step= 250] | Loss=3.74989 | acc=0.1481 | tpr=0.2629 | fpr=0.8540 | 8062.6 samples/s | 31.5 steps/s
[Step= 300] | Loss=3.74933 | acc=0.1484 | tpr=0.2655 | fpr=0.8537 | 8261.4 samples/s | 32.3 steps/s
[Step= 350] | Loss=3.74797 | acc=0.1482 | tpr=0.2674 | fpr=0.8539 | 7650.4 samples/s | 29.9 steps/s
[Step= 400] | Loss=3.74941 | acc=0.1481 | tpr=0.2653 | fpr=0.8540 | 8073.2 samples/s | 31.5 steps/s
[Step= 450] | Loss=3.75243 | acc=0.1477 | tpr=0.2692 | fpr=0.8545 | 7824.6 samples/s | 30.6 steps/s
[Step= 500] | Loss=3.75111 | acc=0.1475 | tpr=0.2692 | fpr=0.8547 | 8122.5 samples/s | 31.7 steps/s
[Step= 550] | Loss=3.75188 | acc=0.1475 | tpr=0.2706 | fpr=0.8548 | 14779.2 samples/s | 57.7 steps/s
Avg test loss: 3.75266, Avg test acc: 0.14736, Avg tpr: 0.27060, Avg fpr: 0.85488, total FA: 118698

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12176 | acc=0.9795 | tpr=0.9513 | fpr=0.0200 | 4194.0 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.12506 | acc=0.9794 | tpr=0.9595 | fpr=0.0203 | 7990.3 samples/s | 31.2 steps/s
[Step= 150] | Loss=0.12888 | acc=0.9786 | tpr=0.9625 | fpr=0.0211 | 7976.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.13048 | acc=0.9786 | tpr=0.9672 | fpr=0.0212 | 8015.3 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.12866 | acc=0.9788 | tpr=0.9651 | fpr=0.0209 | 8400.7 samples/s | 32.8 steps/s
[Step= 300] | Loss=0.13145 | acc=0.9784 | tpr=0.9651 | fpr=0.0213 | 7707.2 samples/s | 30.1 steps/s
[Step= 350] | Loss=0.13101 | acc=0.9785 | tpr=0.9656 | fpr=0.0212 | 8000.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.13217 | acc=0.9784 | tpr=0.9650 | fpr=0.0214 | 7918.2 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.13417 | acc=0.9782 | tpr=0.9649 | fpr=0.0215 | 7820.6 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.13329 | acc=0.9783 | tpr=0.9648 | fpr=0.0214 | 7795.3 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13235 | acc=0.9786 | tpr=0.9634 | fpr=0.0212 | 15278.6 samples/s | 59.7 steps/s
Avg test loss: 0.13217, Avg test acc: 0.97858, Avg tpr: 0.96315, Avg fpr: 0.02114, total FA: 2935

server round 44/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=88001 Epoch=85.9] | Loss=0.01871 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=14.657 | 4193.2 samples/s | 65.5 steps/s
[Step=88050 Epoch=86.0] | Loss=0.01478 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.659 | 5176.6 samples/s | 80.9 steps/s
[Step=88100 Epoch=86.0] | Loss=0.01403 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.155 | L2-Norm(final)=14.658 | 5465.8 samples/s | 85.4 steps/s
[Step=88150 Epoch=86.1] | Loss=0.01315 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.658 | 5588.0 samples/s | 87.3 steps/s
[Step=88200 Epoch=86.1] | Loss=0.01346 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.155 | L2-Norm(final)=14.658 | 5618.5 samples/s | 87.8 steps/s
[Step=88250 Epoch=86.2] | Loss=0.01335 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.658 | 5561.9 samples/s | 86.9 steps/s
[Step=88300 Epoch=86.2] | Loss=0.01307 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.659 | 5697.8 samples/s | 89.0 steps/s
[Step=88350 Epoch=86.3] | Loss=0.01273 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.155 | L2-Norm(final)=14.660 | 5500.8 samples/s | 85.9 steps/s
[Step=88400 Epoch=86.3] | Loss=0.01248 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.661 | 5660.9 samples/s | 88.5 steps/s
[Step=88450 Epoch=86.4] | Loss=0.01250 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.663 | 5569.8 samples/s | 87.0 steps/s
[Step=88500 Epoch=86.4] | Loss=0.01244 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.155 | L2-Norm(final)=14.664 | 5585.5 samples/s | 87.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=86.4] | Loss=0.01111 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=14.681 | 4214.8 samples/s | 65.9 steps/s
[Step=88550 Epoch=86.5] | Loss=0.01101 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.161 | L2-Norm(final)=14.684 | 4567.3 samples/s | 71.4 steps/s
[Step=88600 Epoch=86.5] | Loss=0.01065 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.167 | L2-Norm(final)=14.688 | 4797.9 samples/s | 75.0 steps/s
[Step=88650 Epoch=86.6] | Loss=0.01108 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.173 | L2-Norm(final)=14.691 | 4842.3 samples/s | 75.7 steps/s
[Step=88700 Epoch=86.6] | Loss=0.01103 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.178 | L2-Norm(final)=14.695 | 4821.2 samples/s | 75.3 steps/s
[Step=88750 Epoch=86.7] | Loss=0.01123 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=14.698 | 4868.8 samples/s | 76.1 steps/s
[Step=88800 Epoch=86.7] | Loss=0.01113 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.187 | L2-Norm(final)=14.701 | 4785.0 samples/s | 74.8 steps/s
[Step=88850 Epoch=86.7] | Loss=0.01107 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.191 | L2-Norm(final)=14.704 | 4837.2 samples/s | 75.6 steps/s
[Step=88900 Epoch=86.8] | Loss=0.01119 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.196 | L2-Norm(final)=14.708 | 4831.7 samples/s | 75.5 steps/s
[Step=88950 Epoch=86.8] | Loss=0.01121 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.200 | L2-Norm(final)=14.711 | 4849.5 samples/s | 75.8 steps/s
[Step=89000 Epoch=86.9] | Loss=0.01096 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.204 | L2-Norm(final)=14.714 | 4834.9 samples/s | 75.5 steps/s
[Step=89050 Epoch=86.9] | Loss=0.01072 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.208 | L2-Norm(final)=14.717 | 4868.8 samples/s | 76.1 steps/s
[Step=89100 Epoch=87.0] | Loss=0.01067 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.212 | L2-Norm(final)=14.720 | 4859.0 samples/s | 75.9 steps/s
[Step=89150 Epoch=87.0] | Loss=0.01060 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.216 | L2-Norm(final)=14.722 | 4841.0 samples/s | 75.6 steps/s
[Step=89200 Epoch=87.1] | Loss=0.01062 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.220 | L2-Norm(final)=14.725 | 4822.1 samples/s | 75.3 steps/s
[Step=89250 Epoch=87.1] | Loss=0.01052 | Reg=0.00085 | acc=0.9688 | L2-Norm=9.223 | L2-Norm(final)=14.728 | 4831.5 samples/s | 75.5 steps/s
[Step=89300 Epoch=87.2] | Loss=0.01058 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.226 | L2-Norm(final)=14.731 | 4880.9 samples/s | 76.3 steps/s
[Step=89350 Epoch=87.2] | Loss=0.01049 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.230 | L2-Norm(final)=14.733 | 4826.2 samples/s | 75.4 steps/s
[Step=89400 Epoch=87.3] | Loss=0.01054 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.233 | L2-Norm(final)=14.736 | 4853.3 samples/s | 75.8 steps/s
[Step=89450 Epoch=87.3] | Loss=0.01045 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.236 | L2-Norm(final)=14.739 | 4851.0 samples/s | 75.8 steps/s
[Step=89500 Epoch=87.4] | Loss=0.01042 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.239 | L2-Norm(final)=14.741 | 5169.6 samples/s | 80.8 steps/s
[Step=89550 Epoch=87.4] | Loss=0.01029 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.243 | L2-Norm(final)=14.744 | 2104.4 samples/s | 32.9 steps/s
[Step=89600 Epoch=87.5] | Loss=0.01018 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.246 | L2-Norm(final)=14.747 | 4904.9 samples/s | 76.6 steps/s
[Step=89650 Epoch=87.5] | Loss=0.01004 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.249 | L2-Norm(final)=14.749 | 4824.5 samples/s | 75.4 steps/s
[Step=89700 Epoch=87.6] | Loss=0.00995 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.252 | L2-Norm(final)=14.752 | 4820.7 samples/s | 75.3 steps/s
[Step=89750 Epoch=87.6] | Loss=0.00986 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.255 | L2-Norm(final)=14.755 | 4819.6 samples/s | 75.3 steps/s
[Step=89800 Epoch=87.7] | Loss=0.00973 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.258 | L2-Norm(final)=14.757 | 4835.4 samples/s | 75.6 steps/s
[Step=89850 Epoch=87.7] | Loss=0.00969 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.261 | L2-Norm(final)=14.760 | 4896.7 samples/s | 76.5 steps/s
[Step=89900 Epoch=87.8] | Loss=0.00963 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.264 | L2-Norm(final)=14.762 | 4826.9 samples/s | 75.4 steps/s
[Step=89950 Epoch=87.8] | Loss=0.00954 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.266 | L2-Norm(final)=14.765 | 4834.0 samples/s | 75.5 steps/s
[Step=90000 Epoch=87.9] | Loss=0.00951 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.269 | L2-Norm(final)=14.768 | 4833.9 samples/s | 75.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step90000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=88001 Epoch=165.9] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.005 | 3933.3 samples/s | 61.5 steps/s
[Step=88050 Epoch=166.0] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.004 | 4491.8 samples/s | 70.2 steps/s
[Step=88100 Epoch=166.1] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.004 | 5189.0 samples/s | 81.1 steps/s
[Step=88150 Epoch=166.2] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.004 | 5176.5 samples/s | 80.9 steps/s
[Step=88200 Epoch=166.3] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.003 | 5288.4 samples/s | 82.6 steps/s
[Step=88250 Epoch=166.4] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.003 | 5310.3 samples/s | 83.0 steps/s
[Step=88300 Epoch=166.4] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.003 | 5325.4 samples/s | 83.2 steps/s
[Step=88350 Epoch=166.5] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.003 | 5242.4 samples/s | 81.9 steps/s
[Step=88400 Epoch=166.6] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.002 | 5101.7 samples/s | 79.7 steps/s
[Step=88450 Epoch=166.7] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.002 | 5113.3 samples/s | 79.9 steps/s
[Step=88500 Epoch=166.8] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.002 | 5306.9 samples/s | 82.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=166.8] | Loss=0.00008 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=16.003 | 4024.8 samples/s | 62.9 steps/s
[Step=88550 Epoch=166.9] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.151 | L2-Norm(final)=16.003 | 4439.3 samples/s | 69.4 steps/s
[Step=88600 Epoch=167.0] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=16.004 | 4499.4 samples/s | 70.3 steps/s
[Step=88650 Epoch=167.1] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.146 | L2-Norm(final)=16.005 | 4608.6 samples/s | 72.0 steps/s
[Step=88700 Epoch=167.2] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.143 | L2-Norm(final)=16.007 | 4603.3 samples/s | 71.9 steps/s
[Step=88750 Epoch=167.3] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.140 | L2-Norm(final)=16.007 | 4592.4 samples/s | 71.8 steps/s
[Step=88800 Epoch=167.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.138 | L2-Norm(final)=16.008 | 4585.8 samples/s | 71.7 steps/s
[Step=88850 Epoch=167.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.135 | L2-Norm(final)=16.009 | 4595.3 samples/s | 71.8 steps/s
[Step=88900 Epoch=167.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.132 | L2-Norm(final)=16.010 | 4582.6 samples/s | 71.6 steps/s
[Step=88950 Epoch=167.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=16.011 | 4666.6 samples/s | 72.9 steps/s
[Step=89000 Epoch=167.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.126 | L2-Norm(final)=16.012 | 4612.7 samples/s | 72.1 steps/s
[Step=89050 Epoch=167.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.124 | L2-Norm(final)=16.012 | 2166.8 samples/s | 33.9 steps/s
[Step=89100 Epoch=168.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.121 | L2-Norm(final)=16.013 | 4680.7 samples/s | 73.1 steps/s
[Step=89150 Epoch=168.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.118 | L2-Norm(final)=16.014 | 4600.4 samples/s | 71.9 steps/s
[Step=89200 Epoch=168.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.115 | L2-Norm(final)=16.014 | 4640.9 samples/s | 72.5 steps/s
[Step=89250 Epoch=168.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.112 | L2-Norm(final)=16.015 | 4654.4 samples/s | 72.7 steps/s
[Step=89300 Epoch=168.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.108 | L2-Norm(final)=16.016 | 4588.9 samples/s | 71.7 steps/s
[Step=89350 Epoch=168.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.105 | L2-Norm(final)=16.016 | 4633.9 samples/s | 72.4 steps/s
[Step=89400 Epoch=168.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.102 | L2-Norm(final)=16.017 | 4546.0 samples/s | 71.0 steps/s
[Step=89450 Epoch=168.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.099 | L2-Norm(final)=16.017 | 4641.1 samples/s | 72.5 steps/s
[Step=89500 Epoch=168.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.096 | L2-Norm(final)=16.018 | 4629.9 samples/s | 72.3 steps/s
[Step=89550 Epoch=168.8] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.092 | L2-Norm(final)=16.019 | 5714.2 samples/s | 89.3 steps/s
[Step=89600 Epoch=168.9] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=16.019 | 1930.0 samples/s | 30.2 steps/s
[Step=89650 Epoch=169.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.085 | L2-Norm(final)=16.020 | 4626.5 samples/s | 72.3 steps/s
[Step=89700 Epoch=169.1] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.082 | L2-Norm(final)=16.020 | 4599.2 samples/s | 71.9 steps/s
[Step=89750 Epoch=169.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=16.021 | 4612.2 samples/s | 72.1 steps/s
[Step=89800 Epoch=169.3] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.075 | L2-Norm(final)=16.021 | 4662.4 samples/s | 72.8 steps/s
[Step=89850 Epoch=169.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.071 | L2-Norm(final)=16.022 | 4662.0 samples/s | 72.8 steps/s
[Step=89900 Epoch=169.5] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=16.023 | 4634.1 samples/s | 72.4 steps/s
[Step=89950 Epoch=169.6] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.064 | L2-Norm(final)=16.023 | 4592.9 samples/s | 71.8 steps/s
[Step=90000 Epoch=169.7] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.060 | L2-Norm(final)=16.024 | 4540.0 samples/s | 70.9 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05918 | acc=0.9702 | tpr=0.9738 | fpr=0.0377 | 4137.9 samples/s | 16.2 steps/s
Avg test loss: 0.06073, Avg test acc: 0.96971, Avg tpr: 0.97331, Avg fpr: 0.03820, total FA: 298

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.60357 | acc=0.2970 | tpr=0.0076 | fpr=0.0746 | 4173.4 samples/s | 16.3 steps/s
Avg test loss: 6.59463, Avg test acc: 0.29265, Avg tpr: 0.00723, Avg fpr: 0.07961, total FA: 621

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.94310 | acc=0.1541 | tpr=0.2345 | fpr=0.8474 | 4215.0 samples/s | 16.5 steps/s
[Step= 100] | Loss=3.93225 | acc=0.1565 | tpr=0.2388 | fpr=0.8451 | 7925.1 samples/s | 31.0 steps/s
[Step= 150] | Loss=3.92162 | acc=0.1575 | tpr=0.2421 | fpr=0.8441 | 7861.3 samples/s | 30.7 steps/s
[Step= 200] | Loss=3.91855 | acc=0.1579 | tpr=0.2372 | fpr=0.8435 | 7989.1 samples/s | 31.2 steps/s
[Step= 250] | Loss=3.92050 | acc=0.1583 | tpr=0.2332 | fpr=0.8431 | 8133.2 samples/s | 31.8 steps/s
[Step= 300] | Loss=3.91934 | acc=0.1582 | tpr=0.2371 | fpr=0.8432 | 7882.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=3.91783 | acc=0.1583 | tpr=0.2411 | fpr=0.8432 | 8095.0 samples/s | 31.6 steps/s
[Step= 400] | Loss=3.91945 | acc=0.1583 | tpr=0.2374 | fpr=0.8432 | 7997.2 samples/s | 31.2 steps/s
[Step= 450] | Loss=3.92262 | acc=0.1579 | tpr=0.2410 | fpr=0.8436 | 7828.9 samples/s | 30.6 steps/s
[Step= 500] | Loss=3.92113 | acc=0.1576 | tpr=0.2410 | fpr=0.8439 | 8043.0 samples/s | 31.4 steps/s
[Step= 550] | Loss=3.92202 | acc=0.1574 | tpr=0.2419 | fpr=0.8441 | 13872.9 samples/s | 54.2 steps/s
Avg test loss: 3.92293, Avg test acc: 0.15732, Avg tpr: 0.24208, Avg fpr: 0.84423, total FA: 117219

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12567 | acc=0.9800 | tpr=0.9558 | fpr=0.0196 | 4188.3 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.12928 | acc=0.9793 | tpr=0.9616 | fpr=0.0203 | 8021.4 samples/s | 31.3 steps/s
[Step= 150] | Loss=0.13337 | acc=0.9786 | tpr=0.9640 | fpr=0.0211 | 7979.2 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.13515 | acc=0.9787 | tpr=0.9683 | fpr=0.0212 | 8076.7 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.13331 | acc=0.9789 | tpr=0.9668 | fpr=0.0209 | 7899.3 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.13623 | acc=0.9784 | tpr=0.9665 | fpr=0.0214 | 8042.9 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.13576 | acc=0.9784 | tpr=0.9668 | fpr=0.0214 | 8020.7 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.13694 | acc=0.9783 | tpr=0.9661 | fpr=0.0215 | 8064.3 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.13905 | acc=0.9782 | tpr=0.9659 | fpr=0.0216 | 7873.6 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.13817 | acc=0.9783 | tpr=0.9656 | fpr=0.0215 | 7775.7 samples/s | 30.4 steps/s
[Step= 550] | Loss=0.13720 | acc=0.9786 | tpr=0.9650 | fpr=0.0212 | 15372.2 samples/s | 60.0 steps/s
Avg test loss: 0.13701, Avg test acc: 0.97858, Avg tpr: 0.96474, Avg fpr: 0.02117, total FA: 2939

server round 45/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=90001 Epoch=87.9] | Loss=0.01115 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.129 | L2-Norm(final)=14.843 | 4231.2 samples/s | 66.1 steps/s
[Step=90050 Epoch=87.9] | Loss=0.00934 | Reg=0.00083 | acc=0.9688 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5075.5 samples/s | 79.3 steps/s
[Step=90100 Epoch=88.0] | Loss=0.00984 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5650.6 samples/s | 88.3 steps/s
[Step=90150 Epoch=88.0] | Loss=0.01066 | Reg=0.00083 | acc=0.9688 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5582.6 samples/s | 87.2 steps/s
[Step=90200 Epoch=88.1] | Loss=0.01058 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5670.3 samples/s | 88.6 steps/s
[Step=90250 Epoch=88.1] | Loss=0.01061 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5567.4 samples/s | 87.0 steps/s
[Step=90300 Epoch=88.2] | Loss=0.01076 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5541.0 samples/s | 86.6 steps/s
[Step=90350 Epoch=88.2] | Loss=0.01078 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.845 | 5552.5 samples/s | 86.8 steps/s
[Step=90400 Epoch=88.3] | Loss=0.01061 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.846 | 5604.7 samples/s | 87.6 steps/s
[Step=90450 Epoch=88.3] | Loss=0.01070 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.130 | L2-Norm(final)=14.847 | 5617.6 samples/s | 87.8 steps/s
[Step=90500 Epoch=88.4] | Loss=0.01063 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.130 | L2-Norm(final)=14.848 | 5542.1 samples/s | 86.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=88.4] | Loss=0.00554 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.130 | L2-Norm(final)=14.857 | 4154.9 samples/s | 64.9 steps/s
[Step=90550 Epoch=88.4] | Loss=0.01062 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.135 | L2-Norm(final)=14.860 | 4544.8 samples/s | 71.0 steps/s
[Step=90600 Epoch=88.5] | Loss=0.00985 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.140 | L2-Norm(final)=14.863 | 4872.6 samples/s | 76.1 steps/s
[Step=90650 Epoch=88.5] | Loss=0.01019 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.145 | L2-Norm(final)=14.866 | 4810.2 samples/s | 75.2 steps/s
[Step=90700 Epoch=88.6] | Loss=0.01010 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.150 | L2-Norm(final)=14.870 | 4810.4 samples/s | 75.2 steps/s
[Step=90750 Epoch=88.6] | Loss=0.01014 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.155 | L2-Norm(final)=14.873 | 4896.2 samples/s | 76.5 steps/s
[Step=90800 Epoch=88.7] | Loss=0.01019 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.159 | L2-Norm(final)=14.875 | 4807.0 samples/s | 75.1 steps/s
[Step=90850 Epoch=88.7] | Loss=0.01011 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.164 | L2-Norm(final)=14.878 | 4887.7 samples/s | 76.4 steps/s
[Step=90900 Epoch=88.7] | Loss=0.01024 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.168 | L2-Norm(final)=14.881 | 4846.9 samples/s | 75.7 steps/s
[Step=90950 Epoch=88.8] | Loss=0.01049 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.172 | L2-Norm(final)=14.884 | 4842.4 samples/s | 75.7 steps/s
[Step=91000 Epoch=88.8] | Loss=0.01054 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.176 | L2-Norm(final)=14.887 | 4868.6 samples/s | 76.1 steps/s
[Step=91050 Epoch=88.9] | Loss=0.01039 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.180 | L2-Norm(final)=14.889 | 4920.7 samples/s | 76.9 steps/s
[Step=91100 Epoch=88.9] | Loss=0.01021 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.183 | L2-Norm(final)=14.892 | 4835.8 samples/s | 75.6 steps/s
[Step=91150 Epoch=89.0] | Loss=0.01008 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.187 | L2-Norm(final)=14.895 | 4767.3 samples/s | 74.5 steps/s
[Step=91200 Epoch=89.0] | Loss=0.01018 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.191 | L2-Norm(final)=14.897 | 4818.2 samples/s | 75.3 steps/s
[Step=91250 Epoch=89.1] | Loss=0.01012 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.194 | L2-Norm(final)=14.900 | 4862.9 samples/s | 76.0 steps/s
[Step=91300 Epoch=89.1] | Loss=0.00997 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.197 | L2-Norm(final)=14.902 | 4823.9 samples/s | 75.4 steps/s
[Step=91350 Epoch=89.2] | Loss=0.00992 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.200 | L2-Norm(final)=14.904 | 4867.0 samples/s | 76.0 steps/s
[Step=91400 Epoch=89.2] | Loss=0.00989 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.203 | L2-Norm(final)=14.907 | 4835.1 samples/s | 75.5 steps/s
[Step=91450 Epoch=89.3] | Loss=0.00978 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.206 | L2-Norm(final)=14.909 | 4835.5 samples/s | 75.6 steps/s
[Step=91500 Epoch=89.3] | Loss=0.00973 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.210 | L2-Norm(final)=14.912 | 5162.3 samples/s | 80.7 steps/s
[Step=91550 Epoch=89.4] | Loss=0.00963 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.213 | L2-Norm(final)=14.914 | 2119.4 samples/s | 33.1 steps/s
[Step=91600 Epoch=89.4] | Loss=0.00951 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.215 | L2-Norm(final)=14.916 | 4738.8 samples/s | 74.0 steps/s
[Step=91650 Epoch=89.5] | Loss=0.00946 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.218 | L2-Norm(final)=14.919 | 4761.8 samples/s | 74.4 steps/s
[Step=91700 Epoch=89.5] | Loss=0.00950 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.221 | L2-Norm(final)=14.921 | 4905.8 samples/s | 76.7 steps/s
[Step=91750 Epoch=89.6] | Loss=0.00934 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.224 | L2-Norm(final)=14.923 | 4800.7 samples/s | 75.0 steps/s
[Step=91800 Epoch=89.6] | Loss=0.00928 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.227 | L2-Norm(final)=14.925 | 4873.9 samples/s | 76.2 steps/s
[Step=91850 Epoch=89.7] | Loss=0.00921 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.229 | L2-Norm(final)=14.928 | 4849.4 samples/s | 75.8 steps/s
[Step=91900 Epoch=89.7] | Loss=0.00914 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.232 | L2-Norm(final)=14.930 | 4950.9 samples/s | 77.4 steps/s
[Step=91950 Epoch=89.8] | Loss=0.00905 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.234 | L2-Norm(final)=14.932 | 4791.5 samples/s | 74.9 steps/s
[Step=92000 Epoch=89.8] | Loss=0.00898 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.237 | L2-Norm(final)=14.934 | 4837.1 samples/s | 75.6 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step92000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=90001 Epoch=169.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=16.040 | 3915.1 samples/s | 61.2 steps/s
[Step=90050 Epoch=169.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.041 | 4861.0 samples/s | 76.0 steps/s
[Step=90100 Epoch=169.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.043 | 5330.0 samples/s | 83.3 steps/s
[Step=90150 Epoch=169.9] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.044 | 5316.7 samples/s | 83.1 steps/s
[Step=90200 Epoch=170.0] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.046 | 5220.4 samples/s | 81.6 steps/s
[Step=90250 Epoch=170.1] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.047 | 5226.0 samples/s | 81.7 steps/s
[Step=90300 Epoch=170.2] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.049 | 5267.6 samples/s | 82.3 steps/s
[Step=90350 Epoch=170.3] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.051 | 5542.2 samples/s | 86.6 steps/s
[Step=90400 Epoch=170.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.052 | 5189.6 samples/s | 81.1 steps/s
[Step=90450 Epoch=170.5] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.054 | 5216.9 samples/s | 81.5 steps/s
[Step=90500 Epoch=170.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.056 | 5404.4 samples/s | 84.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=170.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.128 | L2-Norm(final)=16.072 | 3941.1 samples/s | 61.6 steps/s
[Step=90550 Epoch=170.7] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=16.074 | 4398.4 samples/s | 68.7 steps/s
[Step=90600 Epoch=170.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.116 | L2-Norm(final)=16.076 | 4640.4 samples/s | 72.5 steps/s
[Step=90650 Epoch=170.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.110 | L2-Norm(final)=16.077 | 4662.3 samples/s | 72.8 steps/s
[Step=90700 Epoch=171.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.104 | L2-Norm(final)=16.078 | 4575.0 samples/s | 71.5 steps/s
[Step=90750 Epoch=171.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=16.080 | 4592.6 samples/s | 71.8 steps/s
[Step=90800 Epoch=171.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.091 | L2-Norm(final)=16.081 | 4583.1 samples/s | 71.6 steps/s
[Step=90850 Epoch=171.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=16.082 | 4627.9 samples/s | 72.3 steps/s
[Step=90900 Epoch=171.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=16.083 | 4665.4 samples/s | 72.9 steps/s
[Step=90950 Epoch=171.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.071 | L2-Norm(final)=16.084 | 4650.1 samples/s | 72.7 steps/s
[Step=91000 Epoch=171.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.064 | L2-Norm(final)=16.085 | 4590.0 samples/s | 71.7 steps/s
[Step=91050 Epoch=171.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.057 | L2-Norm(final)=16.086 | 2096.4 samples/s | 32.8 steps/s
[Step=91100 Epoch=171.7] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=16.087 | 4666.0 samples/s | 72.9 steps/s
[Step=91150 Epoch=171.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.043 | L2-Norm(final)=16.088 | 4574.8 samples/s | 71.5 steps/s
[Step=91200 Epoch=171.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.036 | L2-Norm(final)=16.089 | 4676.5 samples/s | 73.1 steps/s
[Step=91250 Epoch=172.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.029 | L2-Norm(final)=16.089 | 4568.4 samples/s | 71.4 steps/s
[Step=91300 Epoch=172.1] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.021 | L2-Norm(final)=16.090 | 4384.4 samples/s | 68.5 steps/s
[Step=91350 Epoch=172.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.014 | L2-Norm(final)=16.091 | 4417.3 samples/s | 69.0 steps/s
[Step=91400 Epoch=172.3] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=16.092 | 4344.3 samples/s | 67.9 steps/s
[Step=91450 Epoch=172.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.999 | L2-Norm(final)=16.093 | 4283.5 samples/s | 66.9 steps/s
[Step=91500 Epoch=172.5] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.992 | L2-Norm(final)=16.094 | 4170.5 samples/s | 65.2 steps/s
[Step=91550 Epoch=172.6] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.984 | L2-Norm(final)=16.095 | 5567.7 samples/s | 87.0 steps/s
[Step=91600 Epoch=172.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.976 | L2-Norm(final)=16.096 | 1946.0 samples/s | 30.4 steps/s
[Step=91650 Epoch=172.8] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.968 | L2-Norm(final)=16.097 | 4566.9 samples/s | 71.4 steps/s
[Step=91700 Epoch=172.9] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.960 | L2-Norm(final)=16.097 | 4528.0 samples/s | 70.8 steps/s
[Step=91750 Epoch=173.0] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.952 | L2-Norm(final)=16.098 | 4619.0 samples/s | 72.2 steps/s
[Step=91800 Epoch=173.0] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=16.099 | 4578.2 samples/s | 71.5 steps/s
[Step=91850 Epoch=173.1] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.936 | L2-Norm(final)=16.100 | 4617.0 samples/s | 72.1 steps/s
[Step=91900 Epoch=173.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.927 | L2-Norm(final)=16.101 | 4590.0 samples/s | 71.7 steps/s
[Step=91950 Epoch=173.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.919 | L2-Norm(final)=16.102 | 4663.8 samples/s | 72.9 steps/s
[Step=92000 Epoch=173.4] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.910 | L2-Norm(final)=16.103 | 4595.1 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05961 | acc=0.9701 | tpr=0.9730 | fpr=0.0362 | 4263.0 samples/s | 16.7 steps/s
Avg test loss: 0.06188, Avg test acc: 0.96951, Avg tpr: 0.97243, Avg fpr: 0.03692, total FA: 288

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.80117 | acc=0.2980 | tpr=0.0065 | fpr=0.0689 | 4223.8 samples/s | 16.5 steps/s
Avg test loss: 6.79342, Avg test acc: 0.29461, Avg tpr: 0.00618, Avg fpr: 0.07102, total FA: 554

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.92011 | acc=0.1582 | tpr=0.2345 | fpr=0.8432 | 4191.5 samples/s | 16.4 steps/s
[Step= 100] | Loss=3.90848 | acc=0.1603 | tpr=0.2217 | fpr=0.8408 | 7983.4 samples/s | 31.2 steps/s
[Step= 150] | Loss=3.89647 | acc=0.1621 | tpr=0.2277 | fpr=0.8391 | 7971.9 samples/s | 31.1 steps/s
[Step= 200] | Loss=3.89302 | acc=0.1620 | tpr=0.2230 | fpr=0.8391 | 7903.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=3.89449 | acc=0.1620 | tpr=0.2210 | fpr=0.8390 | 8186.9 samples/s | 32.0 steps/s
[Step= 300] | Loss=3.89367 | acc=0.1619 | tpr=0.2269 | fpr=0.8393 | 7802.2 samples/s | 30.5 steps/s
[Step= 350] | Loss=3.89171 | acc=0.1619 | tpr=0.2317 | fpr=0.8393 | 7944.8 samples/s | 31.0 steps/s
[Step= 400] | Loss=3.89338 | acc=0.1621 | tpr=0.2292 | fpr=0.8391 | 8408.3 samples/s | 32.8 steps/s
[Step= 450] | Loss=3.89645 | acc=0.1617 | tpr=0.2313 | fpr=0.8395 | 7562.2 samples/s | 29.5 steps/s
[Step= 500] | Loss=3.89484 | acc=0.1614 | tpr=0.2291 | fpr=0.8399 | 7859.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=3.89559 | acc=0.1611 | tpr=0.2292 | fpr=0.8402 | 15000.9 samples/s | 58.6 steps/s
Avg test loss: 3.89647, Avg test acc: 0.16097, Avg tpr: 0.22940, Avg fpr: 0.84028, total FA: 116671

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12472 | acc=0.9805 | tpr=0.9513 | fpr=0.0190 | 4221.3 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.12816 | acc=0.9800 | tpr=0.9595 | fpr=0.0197 | 8122.5 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.13225 | acc=0.9793 | tpr=0.9625 | fpr=0.0203 | 7846.0 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.13421 | acc=0.9795 | tpr=0.9672 | fpr=0.0203 | 8057.1 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.13239 | acc=0.9798 | tpr=0.9659 | fpr=0.0200 | 8204.2 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.13529 | acc=0.9793 | tpr=0.9658 | fpr=0.0204 | 7934.2 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.13493 | acc=0.9794 | tpr=0.9662 | fpr=0.0203 | 7640.1 samples/s | 29.8 steps/s
[Step= 400] | Loss=0.13612 | acc=0.9793 | tpr=0.9650 | fpr=0.0205 | 7369.9 samples/s | 28.8 steps/s
[Step= 450] | Loss=0.13830 | acc=0.9791 | tpr=0.9645 | fpr=0.0206 | 7681.8 samples/s | 30.0 steps/s
[Step= 500] | Loss=0.13741 | acc=0.9792 | tpr=0.9643 | fpr=0.0206 | 8077.9 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.13649 | acc=0.9794 | tpr=0.9638 | fpr=0.0203 | 15191.0 samples/s | 59.3 steps/s
Avg test loss: 0.13629, Avg test acc: 0.97942, Avg tpr: 0.96355, Avg fpr: 0.02030, total FA: 2818

server round 46/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=92001 Epoch=89.8] | Loss=0.01089 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=15.002 | 3820.4 samples/s | 59.7 steps/s
[Step=92050 Epoch=89.9] | Loss=0.01514 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.959 | L2-Norm(final)=14.999 | 5439.7 samples/s | 85.0 steps/s
[Step=92100 Epoch=89.9] | Loss=0.01593 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.959 | L2-Norm(final)=14.995 | 5695.6 samples/s | 89.0 steps/s
[Step=92150 Epoch=90.0] | Loss=0.01490 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.991 | 5663.9 samples/s | 88.5 steps/s
[Step=92200 Epoch=90.0] | Loss=0.01476 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.959 | L2-Norm(final)=14.988 | 5408.5 samples/s | 84.5 steps/s
[Step=92250 Epoch=90.1] | Loss=0.01509 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.959 | L2-Norm(final)=14.986 | 5579.4 samples/s | 87.2 steps/s
[Step=92300 Epoch=90.1] | Loss=0.01472 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.983 | 5745.5 samples/s | 89.8 steps/s
[Step=92350 Epoch=90.2] | Loss=0.01427 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.982 | 5482.7 samples/s | 85.7 steps/s
[Step=92400 Epoch=90.2] | Loss=0.01430 | Reg=0.00080 | acc=0.9688 | L2-Norm=8.959 | L2-Norm(final)=14.980 | 5561.5 samples/s | 86.9 steps/s
[Step=92450 Epoch=90.3] | Loss=0.01402 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.979 | 5615.8 samples/s | 87.7 steps/s
[Step=92500 Epoch=90.3] | Loss=0.01404 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.978 | 5612.7 samples/s | 87.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=90.3] | Loss=0.00501 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=14.968 | 4285.4 samples/s | 67.0 steps/s
[Step=92550 Epoch=90.4] | Loss=0.01243 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.965 | L2-Norm(final)=14.970 | 4721.2 samples/s | 73.8 steps/s
[Step=92600 Epoch=90.4] | Loss=0.01203 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.972 | L2-Norm(final)=14.972 | 4824.8 samples/s | 75.4 steps/s
[Step=92650 Epoch=90.5] | Loss=0.01160 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.978 | L2-Norm(final)=14.975 | 4845.1 samples/s | 75.7 steps/s
[Step=92700 Epoch=90.5] | Loss=0.01084 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.983 | L2-Norm(final)=14.978 | 4815.5 samples/s | 75.2 steps/s
[Step=92750 Epoch=90.6] | Loss=0.01041 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.988 | L2-Norm(final)=14.980 | 4823.0 samples/s | 75.4 steps/s
[Step=92800 Epoch=90.6] | Loss=0.01037 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.993 | L2-Norm(final)=14.983 | 4818.4 samples/s | 75.3 steps/s
[Step=92850 Epoch=90.7] | Loss=0.01015 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.998 | L2-Norm(final)=14.985 | 4875.2 samples/s | 76.2 steps/s
[Step=92900 Epoch=90.7] | Loss=0.00992 | Reg=0.00081 | acc=0.9844 | L2-Norm=9.003 | L2-Norm(final)=14.988 | 4869.2 samples/s | 76.1 steps/s
[Step=92950 Epoch=90.8] | Loss=0.01006 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=14.991 | 4843.4 samples/s | 75.7 steps/s
[Step=93000 Epoch=90.8] | Loss=0.01009 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.012 | L2-Norm(final)=14.993 | 4851.3 samples/s | 75.8 steps/s
[Step=93050 Epoch=90.8] | Loss=0.00989 | Reg=0.00081 | acc=0.9844 | L2-Norm=9.016 | L2-Norm(final)=14.996 | 4890.7 samples/s | 76.4 steps/s
[Step=93100 Epoch=90.9] | Loss=0.00984 | Reg=0.00081 | acc=0.9844 | L2-Norm=9.020 | L2-Norm(final)=14.998 | 4776.2 samples/s | 74.6 steps/s
[Step=93150 Epoch=90.9] | Loss=0.00986 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.024 | L2-Norm(final)=15.001 | 4845.1 samples/s | 75.7 steps/s
[Step=93200 Epoch=91.0] | Loss=0.00992 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.027 | L2-Norm(final)=15.003 | 4871.6 samples/s | 76.1 steps/s
[Step=93250 Epoch=91.0] | Loss=0.00987 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.031 | L2-Norm(final)=15.006 | 4782.7 samples/s | 74.7 steps/s
[Step=93300 Epoch=91.1] | Loss=0.01003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.035 | L2-Norm(final)=15.008 | 4860.6 samples/s | 75.9 steps/s
[Step=93350 Epoch=91.1] | Loss=0.00999 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.038 | L2-Norm(final)=15.010 | 4909.8 samples/s | 76.7 steps/s
[Step=93400 Epoch=91.2] | Loss=0.00998 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=15.012 | 4877.3 samples/s | 76.2 steps/s
[Step=93450 Epoch=91.2] | Loss=0.01006 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.045 | L2-Norm(final)=15.014 | 4807.9 samples/s | 75.1 steps/s
[Step=93500 Epoch=91.3] | Loss=0.01013 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=15.016 | 5162.7 samples/s | 80.7 steps/s
[Step=93550 Epoch=91.3] | Loss=0.01004 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.051 | L2-Norm(final)=15.018 | 2081.5 samples/s | 32.5 steps/s
[Step=93600 Epoch=91.4] | Loss=0.00994 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.054 | L2-Norm(final)=15.020 | 4939.2 samples/s | 77.2 steps/s
[Step=93650 Epoch=91.4] | Loss=0.00987 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.057 | L2-Norm(final)=15.022 | 4759.6 samples/s | 74.4 steps/s
[Step=93700 Epoch=91.5] | Loss=0.00975 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.060 | L2-Norm(final)=15.025 | 4840.8 samples/s | 75.6 steps/s
[Step=93750 Epoch=91.5] | Loss=0.00963 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.063 | L2-Norm(final)=15.027 | 4824.8 samples/s | 75.4 steps/s
[Step=93800 Epoch=91.6] | Loss=0.00966 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.066 | L2-Norm(final)=15.029 | 4869.5 samples/s | 76.1 steps/s
[Step=93850 Epoch=91.6] | Loss=0.00956 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.069 | L2-Norm(final)=15.031 | 4840.1 samples/s | 75.6 steps/s
[Step=93900 Epoch=91.7] | Loss=0.00948 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.072 | L2-Norm(final)=15.033 | 4860.0 samples/s | 75.9 steps/s
[Step=93950 Epoch=91.7] | Loss=0.00942 | Reg=0.00082 | acc=0.9688 | L2-Norm=9.075 | L2-Norm(final)=15.035 | 4860.9 samples/s | 76.0 steps/s
[Step=94000 Epoch=91.8] | Loss=0.00939 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=15.037 | 4786.5 samples/s | 74.8 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step94000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=92001 Epoch=173.4] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=16.130 | 3929.1 samples/s | 61.4 steps/s
[Step=92050 Epoch=173.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.956 | L2-Norm(final)=16.133 | 5248.9 samples/s | 82.0 steps/s
[Step=92100 Epoch=173.6] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.956 | L2-Norm(final)=16.136 | 5317.8 samples/s | 83.1 steps/s
[Step=92150 Epoch=173.7] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.139 | 5274.5 samples/s | 82.4 steps/s
[Step=92200 Epoch=173.8] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.142 | 5343.1 samples/s | 83.5 steps/s
[Step=92250 Epoch=173.9] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.145 | 5258.3 samples/s | 82.2 steps/s
[Step=92300 Epoch=174.0] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.148 | 5276.9 samples/s | 82.5 steps/s
[Step=92350 Epoch=174.1] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.152 | 5348.1 samples/s | 83.6 steps/s
[Step=92400 Epoch=174.2] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.155 | 5389.8 samples/s | 84.2 steps/s
[Step=92450 Epoch=174.3] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.159 | 5217.0 samples/s | 81.5 steps/s
[Step=92500 Epoch=174.4] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.162 | 5300.0 samples/s | 82.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=174.4] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.955 | L2-Norm(final)=16.198 | 3874.3 samples/s | 60.5 steps/s
[Step=92550 Epoch=174.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=16.201 | 4570.1 samples/s | 71.4 steps/s
[Step=92600 Epoch=174.6] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.929 | L2-Norm(final)=16.204 | 4545.0 samples/s | 71.0 steps/s
[Step=92650 Epoch=174.6] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.915 | L2-Norm(final)=16.207 | 4656.2 samples/s | 72.8 steps/s
[Step=92700 Epoch=174.7] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.900 | L2-Norm(final)=16.209 | 4557.5 samples/s | 71.2 steps/s
[Step=92750 Epoch=174.8] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.886 | L2-Norm(final)=16.211 | 4646.8 samples/s | 72.6 steps/s
[Step=92800 Epoch=174.9] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.871 | L2-Norm(final)=16.213 | 4654.8 samples/s | 72.7 steps/s
[Step=92850 Epoch=175.0] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.856 | L2-Norm(final)=16.215 | 4545.5 samples/s | 71.0 steps/s
[Step=92900 Epoch=175.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.841 | L2-Norm(final)=16.217 | 4628.6 samples/s | 72.3 steps/s
[Step=92950 Epoch=175.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.826 | L2-Norm(final)=16.219 | 4624.3 samples/s | 72.3 steps/s
[Step=93000 Epoch=175.3] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=16.221 | 4692.8 samples/s | 73.3 steps/s
[Step=93050 Epoch=175.4] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.796 | L2-Norm(final)=16.222 | 2121.3 samples/s | 33.1 steps/s
[Step=93100 Epoch=175.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.781 | L2-Norm(final)=16.224 | 4509.3 samples/s | 70.5 steps/s
[Step=93150 Epoch=175.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.765 | L2-Norm(final)=16.226 | 4597.0 samples/s | 71.8 steps/s
[Step=93200 Epoch=175.7] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.750 | L2-Norm(final)=16.227 | 4598.9 samples/s | 71.9 steps/s
[Step=93250 Epoch=175.8] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=16.229 | 4630.5 samples/s | 72.4 steps/s
[Step=93300 Epoch=175.9] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.719 | L2-Norm(final)=16.231 | 4677.5 samples/s | 73.1 steps/s
[Step=93350 Epoch=176.0] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.703 | L2-Norm(final)=16.232 | 4521.2 samples/s | 70.6 steps/s
[Step=93400 Epoch=176.1] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.687 | L2-Norm(final)=16.234 | 4591.0 samples/s | 71.7 steps/s
[Step=93450 Epoch=176.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.671 | L2-Norm(final)=16.235 | 4628.2 samples/s | 72.3 steps/s
[Step=93500 Epoch=176.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.655 | L2-Norm(final)=16.237 | 4621.2 samples/s | 72.2 steps/s
[Step=93550 Epoch=176.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.639 | L2-Norm(final)=16.239 | 5729.6 samples/s | 89.5 steps/s
[Step=93600 Epoch=176.4] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.622 | L2-Norm(final)=16.240 | 1916.5 samples/s | 29.9 steps/s
[Step=93650 Epoch=176.5] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.606 | L2-Norm(final)=16.242 | 4648.1 samples/s | 72.6 steps/s
[Step=93700 Epoch=176.6] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.590 | L2-Norm(final)=16.244 | 4567.8 samples/s | 71.4 steps/s
[Step=93750 Epoch=176.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.573 | L2-Norm(final)=16.246 | 4640.5 samples/s | 72.5 steps/s
[Step=93800 Epoch=176.8] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.557 | L2-Norm(final)=16.247 | 4604.1 samples/s | 71.9 steps/s
[Step=93850 Epoch=176.9] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.540 | L2-Norm(final)=16.249 | 4570.4 samples/s | 71.4 steps/s
[Step=93900 Epoch=177.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.524 | L2-Norm(final)=16.251 | 4600.2 samples/s | 71.9 steps/s
[Step=93950 Epoch=177.1] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.507 | L2-Norm(final)=16.253 | 4582.1 samples/s | 71.6 steps/s
[Step=94000 Epoch=177.2] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.490 | L2-Norm(final)=16.255 | 4641.7 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05776 | acc=0.9706 | tpr=0.9793 | fpr=0.0483 | 4185.7 samples/s | 16.4 steps/s
Avg test loss: 0.05976, Avg test acc: 0.97051, Avg tpr: 0.97943, Avg fpr: 0.04910, total FA: 383

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.68727 | acc=0.2969 | tpr=0.0059 | fpr=0.0714 | 4205.5 samples/s | 16.4 steps/s
Avg test loss: 6.67800, Avg test acc: 0.29333, Avg tpr: 0.00606, Avg fpr: 0.07486, total FA: 584

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.26656 | acc=0.1434 | tpr=0.2743 | fpr=0.8590 | 4315.3 samples/s | 16.9 steps/s
[Step= 100] | Loss=4.25282 | acc=0.1446 | tpr=0.2644 | fpr=0.8576 | 7514.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=4.23958 | acc=0.1465 | tpr=0.2666 | fpr=0.8557 | 8025.8 samples/s | 31.4 steps/s
[Step= 200] | Loss=4.23540 | acc=0.1465 | tpr=0.2601 | fpr=0.8556 | 8030.7 samples/s | 31.4 steps/s
[Step= 250] | Loss=4.23651 | acc=0.1469 | tpr=0.2559 | fpr=0.8551 | 8035.9 samples/s | 31.4 steps/s
[Step= 300] | Loss=4.23521 | acc=0.1470 | tpr=0.2560 | fpr=0.8550 | 7872.9 samples/s | 30.8 steps/s
[Step= 350] | Loss=4.23329 | acc=0.1470 | tpr=0.2605 | fpr=0.8551 | 8096.5 samples/s | 31.6 steps/s
[Step= 400] | Loss=4.23454 | acc=0.1467 | tpr=0.2604 | fpr=0.8553 | 8034.7 samples/s | 31.4 steps/s
[Step= 450] | Loss=4.23801 | acc=0.1465 | tpr=0.2644 | fpr=0.8557 | 7824.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=4.23636 | acc=0.1464 | tpr=0.2639 | fpr=0.8558 | 8081.1 samples/s | 31.6 steps/s
[Step= 550] | Loss=4.23717 | acc=0.1462 | tpr=0.2654 | fpr=0.8559 | 14617.7 samples/s | 57.1 steps/s
Avg test loss: 4.23824, Avg test acc: 0.14615, Avg tpr: 0.26545, Avg fpr: 0.85602, total FA: 118857

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13573 | acc=0.9781 | tpr=0.9558 | fpr=0.0215 | 4240.2 samples/s | 16.6 steps/s
[Step= 100] | Loss=0.13875 | acc=0.9774 | tpr=0.9659 | fpr=0.0224 | 7859.3 samples/s | 30.7 steps/s
[Step= 150] | Loss=0.14297 | acc=0.9767 | tpr=0.9669 | fpr=0.0231 | 7756.2 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.14489 | acc=0.9768 | tpr=0.9716 | fpr=0.0231 | 7921.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14310 | acc=0.9769 | tpr=0.9703 | fpr=0.0230 | 8326.8 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.14607 | acc=0.9766 | tpr=0.9702 | fpr=0.0233 | 7925.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.14579 | acc=0.9766 | tpr=0.9699 | fpr=0.0232 | 7760.5 samples/s | 30.3 steps/s
[Step= 400] | Loss=0.14723 | acc=0.9765 | tpr=0.9694 | fpr=0.0234 | 7935.1 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.14929 | acc=0.9763 | tpr=0.9688 | fpr=0.0235 | 7964.8 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.14841 | acc=0.9764 | tpr=0.9683 | fpr=0.0235 | 7857.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.14729 | acc=0.9766 | tpr=0.9670 | fpr=0.0232 | 15238.7 samples/s | 59.5 steps/s
Avg test loss: 0.14703, Avg test acc: 0.97664, Avg tpr: 0.96672, Avg fpr: 0.02318, total FA: 3219

server round 47/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=94001 Epoch=91.8] | Loss=0.02511 | Reg=0.00073 | acc=0.9688 | L2-Norm=8.538 | L2-Norm(final)=15.098 | 4189.4 samples/s | 65.5 steps/s
[Step=94050 Epoch=91.8] | Loss=0.01801 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.104 | 5319.1 samples/s | 83.1 steps/s
[Step=94100 Epoch=91.9] | Loss=0.01712 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.539 | L2-Norm(final)=15.110 | 5535.9 samples/s | 86.5 steps/s
[Step=94150 Epoch=91.9] | Loss=0.01697 | Reg=0.00073 | acc=0.9688 | L2-Norm=8.539 | L2-Norm(final)=15.117 | 5563.6 samples/s | 86.9 steps/s
[Step=94200 Epoch=92.0] | Loss=0.01670 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.539 | L2-Norm(final)=15.123 | 5517.9 samples/s | 86.2 steps/s
[Step=94250 Epoch=92.0] | Loss=0.01660 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.129 | 5625.8 samples/s | 87.9 steps/s
[Step=94300 Epoch=92.1] | Loss=0.01633 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.136 | 5645.4 samples/s | 88.2 steps/s
[Step=94350 Epoch=92.1] | Loss=0.01611 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.142 | 5519.6 samples/s | 86.2 steps/s
[Step=94400 Epoch=92.2] | Loss=0.01629 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.148 | 5656.1 samples/s | 88.4 steps/s
[Step=94450 Epoch=92.2] | Loss=0.01634 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.539 | L2-Norm(final)=15.154 | 5539.9 samples/s | 86.6 steps/s
[Step=94500 Epoch=92.3] | Loss=0.01634 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.159 | 5585.3 samples/s | 87.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=92.3] | Loss=0.01089 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.539 | L2-Norm(final)=15.215 | 3977.5 samples/s | 62.1 steps/s
[Step=94550 Epoch=92.3] | Loss=0.01612 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.545 | L2-Norm(final)=15.219 | 4736.1 samples/s | 74.0 steps/s
[Step=94600 Epoch=92.4] | Loss=0.01556 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.555 | L2-Norm(final)=15.224 | 4862.8 samples/s | 76.0 steps/s
[Step=94650 Epoch=92.4] | Loss=0.01503 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.563 | L2-Norm(final)=15.229 | 4805.3 samples/s | 75.1 steps/s
[Step=94700 Epoch=92.5] | Loss=0.01466 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.571 | L2-Norm(final)=15.233 | 4793.8 samples/s | 74.9 steps/s
[Step=94750 Epoch=92.5] | Loss=0.01415 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.578 | L2-Norm(final)=15.237 | 4837.5 samples/s | 75.6 steps/s
[Step=94800 Epoch=92.6] | Loss=0.01425 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.585 | L2-Norm(final)=15.241 | 4628.5 samples/s | 72.3 steps/s
[Step=94850 Epoch=92.6] | Loss=0.01413 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.592 | L2-Norm(final)=15.245 | 4656.3 samples/s | 72.8 steps/s
[Step=94900 Epoch=92.7] | Loss=0.01381 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.598 | L2-Norm(final)=15.249 | 4760.7 samples/s | 74.4 steps/s
[Step=94950 Epoch=92.7] | Loss=0.01368 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.604 | L2-Norm(final)=15.253 | 4867.0 samples/s | 76.0 steps/s
[Step=95000 Epoch=92.8] | Loss=0.01341 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.610 | L2-Norm(final)=15.256 | 4855.5 samples/s | 75.9 steps/s
[Step=95050 Epoch=92.8] | Loss=0.01328 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.615 | L2-Norm(final)=15.260 | 4801.5 samples/s | 75.0 steps/s
[Step=95100 Epoch=92.8] | Loss=0.01311 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.621 | L2-Norm(final)=15.264 | 4862.2 samples/s | 76.0 steps/s
[Step=95150 Epoch=92.9] | Loss=0.01298 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.626 | L2-Norm(final)=15.267 | 4796.4 samples/s | 74.9 steps/s
[Step=95200 Epoch=92.9] | Loss=0.01279 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.631 | L2-Norm(final)=15.270 | 4815.7 samples/s | 75.2 steps/s
[Step=95250 Epoch=93.0] | Loss=0.01269 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.636 | L2-Norm(final)=15.274 | 4870.3 samples/s | 76.1 steps/s
[Step=95300 Epoch=93.0] | Loss=0.01263 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.640 | L2-Norm(final)=15.277 | 4818.0 samples/s | 75.3 steps/s
[Step=95350 Epoch=93.1] | Loss=0.01265 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.645 | L2-Norm(final)=15.280 | 4829.7 samples/s | 75.5 steps/s
[Step=95400 Epoch=93.1] | Loss=0.01253 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.650 | L2-Norm(final)=15.283 | 4817.5 samples/s | 75.3 steps/s
[Step=95450 Epoch=93.2] | Loss=0.01238 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.654 | L2-Norm(final)=15.287 | 4804.4 samples/s | 75.1 steps/s
[Step=95500 Epoch=93.2] | Loss=0.01240 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.658 | L2-Norm(final)=15.290 | 5119.5 samples/s | 80.0 steps/s
[Step=95550 Epoch=93.3] | Loss=0.01247 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.662 | L2-Norm(final)=15.293 | 2074.0 samples/s | 32.4 steps/s
[Step=95600 Epoch=93.3] | Loss=0.01241 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.666 | L2-Norm(final)=15.296 | 4590.2 samples/s | 71.7 steps/s
[Step=95650 Epoch=93.4] | Loss=0.01230 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.670 | L2-Norm(final)=15.299 | 4691.1 samples/s | 73.3 steps/s
[Step=95700 Epoch=93.4] | Loss=0.01215 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.674 | L2-Norm(final)=15.302 | 4783.7 samples/s | 74.7 steps/s
[Step=95750 Epoch=93.5] | Loss=0.01203 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.678 | L2-Norm(final)=15.304 | 4788.2 samples/s | 74.8 steps/s
[Step=95800 Epoch=93.5] | Loss=0.01184 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.681 | L2-Norm(final)=15.307 | 4869.8 samples/s | 76.1 steps/s
[Step=95850 Epoch=93.6] | Loss=0.01168 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.685 | L2-Norm(final)=15.310 | 4797.1 samples/s | 75.0 steps/s
[Step=95900 Epoch=93.6] | Loss=0.01159 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.688 | L2-Norm(final)=15.313 | 4809.2 samples/s | 75.1 steps/s
[Step=95950 Epoch=93.7] | Loss=0.01150 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.692 | L2-Norm(final)=15.316 | 4835.9 samples/s | 75.6 steps/s
[Step=96000 Epoch=93.7] | Loss=0.01147 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.695 | L2-Norm(final)=15.319 | 4844.4 samples/s | 75.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step96000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=94001 Epoch=177.2] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.538 | L2-Norm(final)=16.312 | 4087.8 samples/s | 63.9 steps/s
[Step=94050 Epoch=177.3] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.533 | L2-Norm(final)=16.317 | 4883.5 samples/s | 76.3 steps/s
[Step=94100 Epoch=177.4] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.324 | 5263.8 samples/s | 82.2 steps/s
[Step=94150 Epoch=177.5] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.331 | 5418.1 samples/s | 84.7 steps/s
[Step=94200 Epoch=177.6] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.339 | 5042.1 samples/s | 78.8 steps/s
[Step=94250 Epoch=177.7] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.346 | 5250.0 samples/s | 82.0 steps/s
[Step=94300 Epoch=177.8] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.353 | 5374.5 samples/s | 84.0 steps/s
[Step=94350 Epoch=177.9] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.360 | 5405.0 samples/s | 84.5 steps/s
[Step=94400 Epoch=177.9] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.368 | 5118.2 samples/s | 80.0 steps/s
[Step=94450 Epoch=178.0] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.375 | 5329.1 samples/s | 83.3 steps/s
[Step=94500 Epoch=178.1] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.383 | 5327.1 samples/s | 83.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=178.1] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.532 | L2-Norm(final)=16.458 | 3849.8 samples/s | 60.2 steps/s
[Step=94550 Epoch=178.2] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.511 | L2-Norm(final)=16.464 | 4607.9 samples/s | 72.0 steps/s
[Step=94600 Epoch=178.3] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.487 | L2-Norm(final)=16.468 | 4615.2 samples/s | 72.1 steps/s
[Step=94650 Epoch=178.4] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.462 | L2-Norm(final)=16.471 | 4568.2 samples/s | 71.4 steps/s
[Step=94700 Epoch=178.5] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.436 | L2-Norm(final)=16.474 | 4626.1 samples/s | 72.3 steps/s
[Step=94750 Epoch=178.6] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.411 | L2-Norm(final)=16.476 | 4558.0 samples/s | 71.2 steps/s
[Step=94800 Epoch=178.7] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.386 | L2-Norm(final)=16.479 | 4626.2 samples/s | 72.3 steps/s
[Step=94850 Epoch=178.8] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.360 | L2-Norm(final)=16.481 | 4607.3 samples/s | 72.0 steps/s
[Step=94900 Epoch=178.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.335 | L2-Norm(final)=16.483 | 4605.5 samples/s | 72.0 steps/s
[Step=94950 Epoch=179.0] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.311 | L2-Norm(final)=16.486 | 4627.3 samples/s | 72.3 steps/s
[Step=95000 Epoch=179.1] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.287 | L2-Norm(final)=16.488 | 4618.5 samples/s | 72.2 steps/s
[Step=95050 Epoch=179.2] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.263 | L2-Norm(final)=16.491 | 2153.9 samples/s | 33.7 steps/s
[Step=95100 Epoch=179.3] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.240 | L2-Norm(final)=16.493 | 4691.8 samples/s | 73.3 steps/s
[Step=95150 Epoch=179.4] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=16.495 | 4573.3 samples/s | 71.5 steps/s
[Step=95200 Epoch=179.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.192 | L2-Norm(final)=16.497 | 4660.9 samples/s | 72.8 steps/s
[Step=95250 Epoch=179.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.168 | L2-Norm(final)=16.500 | 4619.1 samples/s | 72.2 steps/s
[Step=95300 Epoch=179.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=16.502 | 4599.6 samples/s | 71.9 steps/s
[Step=95350 Epoch=179.7] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=16.504 | 4592.7 samples/s | 71.8 steps/s
[Step=95400 Epoch=179.8] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=16.507 | 4654.8 samples/s | 72.7 steps/s
[Step=95450 Epoch=179.9] | Loss=0.00003 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.092 | L2-Norm(final)=16.508 | 4577.7 samples/s | 71.5 steps/s
[Step=95500 Epoch=180.0] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=16.510 | 4574.4 samples/s | 71.5 steps/s
[Step=95550 Epoch=180.1] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=16.512 | 5770.5 samples/s | 90.2 steps/s
[Step=95600 Epoch=180.2] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.054 | L2-Norm(final)=16.513 | 1960.3 samples/s | 30.6 steps/s
[Step=95650 Epoch=180.3] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.044 | L2-Norm(final)=16.515 | 4595.8 samples/s | 71.8 steps/s
[Step=95700 Epoch=180.4] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.034 | L2-Norm(final)=16.516 | 4588.4 samples/s | 71.7 steps/s
[Step=95750 Epoch=180.5] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.025 | L2-Norm(final)=16.517 | 4573.6 samples/s | 71.5 steps/s
[Step=95800 Epoch=180.6] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.016 | L2-Norm(final)=16.518 | 4688.7 samples/s | 73.3 steps/s
[Step=95850 Epoch=180.7] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=16.519 | 4480.7 samples/s | 70.0 steps/s
[Step=95900 Epoch=180.8] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=16.520 | 4630.6 samples/s | 72.4 steps/s
[Step=95950 Epoch=180.9] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=16.521 | 4602.9 samples/s | 71.9 steps/s
[Step=96000 Epoch=181.0] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.988 | L2-Norm(final)=16.522 | 4625.4 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05544 | acc=0.9706 | tpr=0.9742 | fpr=0.0372 | 4207.3 samples/s | 16.4 steps/s
Avg test loss: 0.05739, Avg test acc: 0.97019, Avg tpr: 0.97465, Avg fpr: 0.03961, total FA: 309

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.67939 | acc=0.3010 | tpr=0.0037 | fpr=0.0533 | 4190.0 samples/s | 16.4 steps/s
Avg test loss: 6.67642, Avg test acc: 0.29802, Avg tpr: 0.00373, Avg fpr: 0.05474, total FA: 427

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.84122 | acc=0.1501 | tpr=0.2168 | fpr=0.8511 | 4257.6 samples/s | 16.6 steps/s
[Step= 100] | Loss=3.82952 | acc=0.1517 | tpr=0.2196 | fpr=0.8496 | 7541.5 samples/s | 29.5 steps/s
[Step= 150] | Loss=3.81662 | acc=0.1535 | tpr=0.2262 | fpr=0.8478 | 8304.3 samples/s | 32.4 steps/s
[Step= 200] | Loss=3.81353 | acc=0.1536 | tpr=0.2186 | fpr=0.8476 | 7900.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=3.81562 | acc=0.1540 | tpr=0.2166 | fpr=0.8471 | 7932.8 samples/s | 31.0 steps/s
[Step= 300] | Loss=3.81414 | acc=0.1543 | tpr=0.2196 | fpr=0.8469 | 8117.5 samples/s | 31.7 steps/s
[Step= 350] | Loss=3.81229 | acc=0.1543 | tpr=0.2248 | fpr=0.8470 | 8185.8 samples/s | 32.0 steps/s
[Step= 400] | Loss=3.81406 | acc=0.1542 | tpr=0.2232 | fpr=0.8470 | 7975.3 samples/s | 31.2 steps/s
[Step= 450] | Loss=3.81705 | acc=0.1540 | tpr=0.2269 | fpr=0.8473 | 7780.7 samples/s | 30.4 steps/s
[Step= 500] | Loss=3.81540 | acc=0.1539 | tpr=0.2242 | fpr=0.8474 | 7872.4 samples/s | 30.8 steps/s
[Step= 550] | Loss=3.81613 | acc=0.1537 | tpr=0.2232 | fpr=0.8476 | 15155.6 samples/s | 59.2 steps/s
Avg test loss: 3.81718, Avg test acc: 0.15359, Avg tpr: 0.22306, Avg fpr: 0.84767, total FA: 117697

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11444 | acc=0.9802 | tpr=0.9513 | fpr=0.0193 | 4220.5 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.11762 | acc=0.9802 | tpr=0.9595 | fpr=0.0194 | 8133.8 samples/s | 31.8 steps/s
[Step= 150] | Loss=0.12150 | acc=0.9797 | tpr=0.9625 | fpr=0.0200 | 7957.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.12348 | acc=0.9799 | tpr=0.9683 | fpr=0.0199 | 7896.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.12211 | acc=0.9802 | tpr=0.9686 | fpr=0.0196 | 7850.4 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.12455 | acc=0.9798 | tpr=0.9680 | fpr=0.0200 | 8168.6 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.12465 | acc=0.9798 | tpr=0.9681 | fpr=0.0200 | 8273.6 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.12578 | acc=0.9795 | tpr=0.9666 | fpr=0.0202 | 7929.6 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.12778 | acc=0.9794 | tpr=0.9654 | fpr=0.0204 | 7961.6 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12700 | acc=0.9794 | tpr=0.9652 | fpr=0.0204 | 7722.7 samples/s | 30.2 steps/s
[Step= 550] | Loss=0.12602 | acc=0.9796 | tpr=0.9646 | fpr=0.0202 | 14773.5 samples/s | 57.7 steps/s
Avg test loss: 0.12582, Avg test acc: 0.97959, Avg tpr: 0.96434, Avg fpr: 0.02013, total FA: 2795

server round 48/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=96001 Epoch=93.7] | Loss=0.00806 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=15.403 | 3877.9 samples/s | 60.6 steps/s
[Step=96050 Epoch=93.8] | Loss=0.02403 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.253 | L2-Norm(final)=15.410 | 5143.7 samples/s | 80.4 steps/s
[Step=96100 Epoch=93.8] | Loss=0.02337 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.253 | L2-Norm(final)=15.418 | 5359.4 samples/s | 83.7 steps/s
[Step=96150 Epoch=93.9] | Loss=0.02356 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.253 | L2-Norm(final)=15.426 | 5452.6 samples/s | 85.2 steps/s
[Step=96200 Epoch=93.9] | Loss=0.02406 | Reg=0.00068 | acc=0.9688 | L2-Norm=8.253 | L2-Norm(final)=15.434 | 5503.7 samples/s | 86.0 steps/s
[Step=96250 Epoch=94.0] | Loss=0.02375 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.253 | L2-Norm(final)=15.442 | 5625.2 samples/s | 87.9 steps/s
[Step=96300 Epoch=94.0] | Loss=0.02322 | Reg=0.00068 | acc=0.9688 | L2-Norm=8.253 | L2-Norm(final)=15.451 | 5689.6 samples/s | 88.9 steps/s
[Step=96350 Epoch=94.1] | Loss=0.02367 | Reg=0.00068 | acc=0.9531 | L2-Norm=8.253 | L2-Norm(final)=15.459 | 5579.3 samples/s | 87.2 steps/s
[Step=96400 Epoch=94.1] | Loss=0.02353 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.253 | L2-Norm(final)=15.467 | 5600.4 samples/s | 87.5 steps/s
[Step=96450 Epoch=94.2] | Loss=0.02342 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.253 | L2-Norm(final)=15.474 | 5617.0 samples/s | 87.8 steps/s
[Step=96500 Epoch=94.2] | Loss=0.02321 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.253 | L2-Norm(final)=15.482 | 5595.1 samples/s | 87.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=94.2] | Loss=0.01375 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.253 | L2-Norm(final)=15.558 | 4204.6 samples/s | 65.7 steps/s
[Step=96550 Epoch=94.3] | Loss=0.02101 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.262 | L2-Norm(final)=15.565 | 4662.4 samples/s | 72.8 steps/s
[Step=96600 Epoch=94.3] | Loss=0.01990 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.272 | L2-Norm(final)=15.571 | 4829.4 samples/s | 75.5 steps/s
[Step=96650 Epoch=94.4] | Loss=0.01893 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=15.576 | 4828.4 samples/s | 75.4 steps/s
[Step=96700 Epoch=94.4] | Loss=0.01809 | Reg=0.00069 | acc=0.9688 | L2-Norm=8.291 | L2-Norm(final)=15.581 | 4819.7 samples/s | 75.3 steps/s
[Step=96750 Epoch=94.5] | Loss=0.01790 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.300 | L2-Norm(final)=15.586 | 4809.5 samples/s | 75.1 steps/s
[Step=96800 Epoch=94.5] | Loss=0.01732 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.308 | L2-Norm(final)=15.590 | 4839.4 samples/s | 75.6 steps/s
[Step=96850 Epoch=94.6] | Loss=0.01692 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.316 | L2-Norm(final)=15.594 | 4838.0 samples/s | 75.6 steps/s
[Step=96900 Epoch=94.6] | Loss=0.01661 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.323 | L2-Norm(final)=15.599 | 4865.5 samples/s | 76.0 steps/s
[Step=96950 Epoch=94.7] | Loss=0.01618 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.330 | L2-Norm(final)=15.603 | 4845.7 samples/s | 75.7 steps/s
[Step=97000 Epoch=94.7] | Loss=0.01600 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.336 | L2-Norm(final)=15.607 | 4873.1 samples/s | 76.1 steps/s
[Step=97050 Epoch=94.8] | Loss=0.01579 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.342 | L2-Norm(final)=15.611 | 4835.4 samples/s | 75.6 steps/s
[Step=97100 Epoch=94.8] | Loss=0.01541 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.348 | L2-Norm(final)=15.615 | 4831.3 samples/s | 75.5 steps/s
[Step=97150 Epoch=94.9] | Loss=0.01525 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.354 | L2-Norm(final)=15.618 | 4863.4 samples/s | 76.0 steps/s
[Step=97200 Epoch=94.9] | Loss=0.01509 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.359 | L2-Norm(final)=15.622 | 4885.8 samples/s | 76.3 steps/s
[Step=97250 Epoch=94.9] | Loss=0.01485 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.365 | L2-Norm(final)=15.626 | 4882.6 samples/s | 76.3 steps/s
[Step=97300 Epoch=95.0] | Loss=0.01487 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.370 | L2-Norm(final)=15.629 | 4874.0 samples/s | 76.2 steps/s
[Step=97350 Epoch=95.0] | Loss=0.01465 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.375 | L2-Norm(final)=15.633 | 4859.0 samples/s | 75.9 steps/s
[Step=97400 Epoch=95.1] | Loss=0.01450 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.380 | L2-Norm(final)=15.636 | 4859.8 samples/s | 75.9 steps/s
[Step=97450 Epoch=95.1] | Loss=0.01437 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.384 | L2-Norm(final)=15.639 | 4941.5 samples/s | 77.2 steps/s
[Step=97500 Epoch=95.2] | Loss=0.01413 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.389 | L2-Norm(final)=15.642 | 5166.3 samples/s | 80.7 steps/s
[Step=97550 Epoch=95.2] | Loss=0.01401 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.394 | L2-Norm(final)=15.646 | 2113.9 samples/s | 33.0 steps/s
[Step=97600 Epoch=95.3] | Loss=0.01386 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.398 | L2-Norm(final)=15.649 | 4842.5 samples/s | 75.7 steps/s
[Step=97650 Epoch=95.3] | Loss=0.01367 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.402 | L2-Norm(final)=15.652 | 4849.0 samples/s | 75.8 steps/s
[Step=97700 Epoch=95.4] | Loss=0.01350 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.407 | L2-Norm(final)=15.655 | 4873.9 samples/s | 76.2 steps/s
[Step=97750 Epoch=95.4] | Loss=0.01334 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.411 | L2-Norm(final)=15.659 | 4685.2 samples/s | 73.2 steps/s
[Step=97800 Epoch=95.5] | Loss=0.01314 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.415 | L2-Norm(final)=15.662 | 4713.1 samples/s | 73.6 steps/s
[Step=97850 Epoch=95.5] | Loss=0.01306 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.419 | L2-Norm(final)=15.665 | 4629.8 samples/s | 72.3 steps/s
[Step=97900 Epoch=95.6] | Loss=0.01297 | Reg=0.00071 | acc=0.9688 | L2-Norm=8.423 | L2-Norm(final)=15.668 | 4724.2 samples/s | 73.8 steps/s
[Step=97950 Epoch=95.6] | Loss=0.01287 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.427 | L2-Norm(final)=15.671 | 4790.7 samples/s | 74.9 steps/s
[Step=98000 Epoch=95.7] | Loss=0.01282 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.431 | L2-Norm(final)=15.674 | 4841.9 samples/s | 75.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step98000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=96001 Epoch=181.0] | Loss=0.00003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.550 | 3979.7 samples/s | 62.2 steps/s
[Step=96050 Epoch=181.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.550 | 4290.7 samples/s | 67.0 steps/s
[Step=96100 Epoch=181.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.550 | 5078.7 samples/s | 79.4 steps/s
[Step=96150 Epoch=181.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.551 | 5087.7 samples/s | 79.5 steps/s
[Step=96200 Epoch=181.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.551 | 5130.6 samples/s | 80.2 steps/s
[Step=96250 Epoch=181.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.552 | 5258.1 samples/s | 82.2 steps/s
[Step=96300 Epoch=181.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.552 | 5261.3 samples/s | 82.2 steps/s
[Step=96350 Epoch=181.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.553 | 5427.7 samples/s | 84.8 steps/s
[Step=96400 Epoch=181.7] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.553 | 5244.5 samples/s | 81.9 steps/s
[Step=96450 Epoch=181.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.554 | 5255.4 samples/s | 82.1 steps/s
[Step=96500 Epoch=181.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.554 | 5342.1 samples/s | 83.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=181.9] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.252 | L2-Norm(final)=16.559 | 3869.4 samples/s | 60.5 steps/s
[Step=96550 Epoch=182.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.248 | L2-Norm(final)=16.560 | 4611.3 samples/s | 72.1 steps/s
[Step=96600 Epoch=182.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.245 | L2-Norm(final)=16.561 | 4648.4 samples/s | 72.6 steps/s
[Step=96650 Epoch=182.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.243 | L2-Norm(final)=16.562 | 4652.9 samples/s | 72.7 steps/s
[Step=96700 Epoch=182.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.241 | L2-Norm(final)=16.562 | 4552.0 samples/s | 71.1 steps/s
[Step=96750 Epoch=182.4] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.239 | L2-Norm(final)=16.563 | 4621.9 samples/s | 72.2 steps/s
[Step=96800 Epoch=182.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.237 | L2-Norm(final)=16.563 | 4565.3 samples/s | 71.3 steps/s
[Step=96850 Epoch=182.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.235 | L2-Norm(final)=16.564 | 4593.8 samples/s | 71.8 steps/s
[Step=96900 Epoch=182.7] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.233 | L2-Norm(final)=16.565 | 4602.7 samples/s | 71.9 steps/s
[Step=96950 Epoch=182.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.231 | L2-Norm(final)=16.565 | 4612.3 samples/s | 72.1 steps/s
[Step=97000 Epoch=182.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.229 | L2-Norm(final)=16.566 | 4639.6 samples/s | 72.5 steps/s
[Step=97050 Epoch=182.9] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.227 | L2-Norm(final)=16.567 | 2084.6 samples/s | 32.6 steps/s
[Step=97100 Epoch=183.0] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.225 | L2-Norm(final)=16.567 | 4660.1 samples/s | 72.8 steps/s
[Step=97150 Epoch=183.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.223 | L2-Norm(final)=16.568 | 4619.9 samples/s | 72.2 steps/s
[Step=97200 Epoch=183.2] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.221 | L2-Norm(final)=16.569 | 4610.4 samples/s | 72.0 steps/s
[Step=97250 Epoch=183.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.220 | L2-Norm(final)=16.570 | 4567.1 samples/s | 71.4 steps/s
[Step=97300 Epoch=183.4] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.218 | L2-Norm(final)=16.570 | 4594.4 samples/s | 71.8 steps/s
[Step=97350 Epoch=183.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.216 | L2-Norm(final)=16.571 | 4639.2 samples/s | 72.5 steps/s
[Step=97400 Epoch=183.6] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.214 | L2-Norm(final)=16.572 | 4631.6 samples/s | 72.4 steps/s
[Step=97450 Epoch=183.7] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.212 | L2-Norm(final)=16.572 | 4613.3 samples/s | 72.1 steps/s
[Step=97500 Epoch=183.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.209 | L2-Norm(final)=16.573 | 4568.7 samples/s | 71.4 steps/s
[Step=97550 Epoch=183.9] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.207 | L2-Norm(final)=16.574 | 5805.6 samples/s | 90.7 steps/s
[Step=97600 Epoch=184.0] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.205 | L2-Norm(final)=16.574 | 1956.3 samples/s | 30.6 steps/s
[Step=97650 Epoch=184.1] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.203 | L2-Norm(final)=16.575 | 4533.7 samples/s | 70.8 steps/s
[Step=97700 Epoch=184.2] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.201 | L2-Norm(final)=16.575 | 4683.1 samples/s | 73.2 steps/s
[Step=97750 Epoch=184.3] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.199 | L2-Norm(final)=16.576 | 4515.9 samples/s | 70.6 steps/s
[Step=97800 Epoch=184.4] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.197 | L2-Norm(final)=16.577 | 4645.5 samples/s | 72.6 steps/s
[Step=97850 Epoch=184.4] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.194 | L2-Norm(final)=16.577 | 4590.6 samples/s | 71.7 steps/s
[Step=97900 Epoch=184.5] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.192 | L2-Norm(final)=16.578 | 4614.6 samples/s | 72.1 steps/s
[Step=97950 Epoch=184.6] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.190 | L2-Norm(final)=16.578 | 4600.0 samples/s | 71.9 steps/s
[Step=98000 Epoch=184.7] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=16.579 | 4525.7 samples/s | 70.7 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05329 | acc=0.9709 | tpr=0.9777 | fpr=0.0441 | 4208.7 samples/s | 16.4 steps/s
Avg test loss: 0.05513, Avg test acc: 0.97079, Avg tpr: 0.97774, Avg fpr: 0.04448, total FA: 347

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.30720 | acc=0.2998 | tpr=0.0049 | fpr=0.0600 | 4223.0 samples/s | 16.5 steps/s
Avg test loss: 6.30109, Avg test acc: 0.29686, Avg tpr: 0.00495, Avg fpr: 0.06115, total FA: 477

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.89143 | acc=0.1402 | tpr=0.2522 | fpr=0.8619 | 4341.0 samples/s | 17.0 steps/s
[Step= 100] | Loss=3.87725 | acc=0.1418 | tpr=0.2537 | fpr=0.8603 | 7681.1 samples/s | 30.0 steps/s
[Step= 150] | Loss=3.86561 | acc=0.1433 | tpr=0.2579 | fpr=0.8588 | 8050.9 samples/s | 31.4 steps/s
[Step= 200] | Loss=3.86112 | acc=0.1437 | tpr=0.2481 | fpr=0.8582 | 7858.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=3.86350 | acc=0.1440 | tpr=0.2498 | fpr=0.8580 | 8021.7 samples/s | 31.3 steps/s
[Step= 300] | Loss=3.86219 | acc=0.1440 | tpr=0.2480 | fpr=0.8579 | 7923.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=3.86022 | acc=0.1439 | tpr=0.2517 | fpr=0.8580 | 8117.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=3.86186 | acc=0.1438 | tpr=0.2500 | fpr=0.8582 | 7968.5 samples/s | 31.1 steps/s
[Step= 450] | Loss=3.86526 | acc=0.1435 | tpr=0.2527 | fpr=0.8585 | 8250.3 samples/s | 32.2 steps/s
[Step= 500] | Loss=3.86382 | acc=0.1434 | tpr=0.2515 | fpr=0.8586 | 7815.1 samples/s | 30.5 steps/s
[Step= 550] | Loss=3.86456 | acc=0.1432 | tpr=0.2511 | fpr=0.8587 | 14412.6 samples/s | 56.3 steps/s
Avg test loss: 3.86552, Avg test acc: 0.14310, Avg tpr: 0.25079, Avg fpr: 0.85886, total FA: 119251

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11472 | acc=0.9801 | tpr=0.9558 | fpr=0.0195 | 4236.7 samples/s | 16.5 steps/s
[Step= 100] | Loss=0.11789 | acc=0.9799 | tpr=0.9616 | fpr=0.0198 | 7843.0 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.12188 | acc=0.9794 | tpr=0.9640 | fpr=0.0203 | 8223.3 samples/s | 32.1 steps/s
[Step= 200] | Loss=0.12358 | acc=0.9796 | tpr=0.9694 | fpr=0.0202 | 7852.4 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12207 | acc=0.9798 | tpr=0.9677 | fpr=0.0200 | 7952.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.12465 | acc=0.9793 | tpr=0.9680 | fpr=0.0205 | 8019.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.12447 | acc=0.9794 | tpr=0.9681 | fpr=0.0204 | 8065.7 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.12556 | acc=0.9792 | tpr=0.9661 | fpr=0.0206 | 7817.8 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.12753 | acc=0.9790 | tpr=0.9654 | fpr=0.0207 | 8099.5 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.12665 | acc=0.9791 | tpr=0.9652 | fpr=0.0207 | 7916.7 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.12573 | acc=0.9793 | tpr=0.9646 | fpr=0.0204 | 14463.5 samples/s | 56.5 steps/s
Avg test loss: 0.12553, Avg test acc: 0.97936, Avg tpr: 0.96434, Avg fpr: 0.02037, total FA: 2828

server round 49/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=98001 Epoch=95.7] | Loss=0.01041 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.304 | L2-Norm(final)=15.763 | 4047.0 samples/s | 63.2 steps/s
[Step=98050 Epoch=95.7] | Loss=0.01548 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.304 | L2-Norm(final)=15.765 | 5443.5 samples/s | 85.1 steps/s
[Step=98100 Epoch=95.8] | Loss=0.01561 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=15.767 | 5586.3 samples/s | 87.3 steps/s
[Step=98150 Epoch=95.8] | Loss=0.01526 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=15.768 | 5596.1 samples/s | 87.4 steps/s
[Step=98200 Epoch=95.9] | Loss=0.01504 | Reg=0.00069 | acc=0.9688 | L2-Norm=8.304 | L2-Norm(final)=15.770 | 5561.8 samples/s | 86.9 steps/s
[Step=98250 Epoch=95.9] | Loss=0.01500 | Reg=0.00069 | acc=0.9688 | L2-Norm=8.304 | L2-Norm(final)=15.773 | 5628.2 samples/s | 87.9 steps/s
[Step=98300 Epoch=96.0] | Loss=0.01538 | Reg=0.00069 | acc=0.9688 | L2-Norm=8.304 | L2-Norm(final)=15.776 | 5718.9 samples/s | 89.4 steps/s
[Step=98350 Epoch=96.0] | Loss=0.01542 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=15.778 | 5505.2 samples/s | 86.0 steps/s
[Step=98400 Epoch=96.1] | Loss=0.01517 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=15.781 | 5744.0 samples/s | 89.7 steps/s
[Step=98450 Epoch=96.1] | Loss=0.01530 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=15.784 | 5493.0 samples/s | 85.8 steps/s
[Step=98500 Epoch=96.2] | Loss=0.01504 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.304 | L2-Norm(final)=15.788 | 5532.2 samples/s | 86.4 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_asml1_0/client_state-step98500.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Restoring layer fc1.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=98001 Epoch=184.7] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=16.597 | 4260.2 samples/s | 66.6 steps/s
[Step=98050 Epoch=184.8] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.303 | L2-Norm(final)=16.598 | 4191.3 samples/s | 65.5 steps/s
[Step=98100 Epoch=184.9] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.598 | 4700.5 samples/s | 73.4 steps/s
[Step=98150 Epoch=185.0] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.599 | 5025.4 samples/s | 78.5 steps/s
[Step=98200 Epoch=185.1] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.599 | 5214.2 samples/s | 81.5 steps/s
[Step=98250 Epoch=185.2] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.599 | 5376.8 samples/s | 84.0 steps/s
[Step=98300 Epoch=185.3] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.600 | 5326.0 samples/s | 83.2 steps/s
[Step=98350 Epoch=185.4] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.600 | 5378.9 samples/s | 84.0 steps/s
[Step=98400 Epoch=185.5] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.601 | 5414.8 samples/s | 84.6 steps/s
[Step=98450 Epoch=185.6] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.602 | 5206.0 samples/s | 81.3 steps/s
[Step=98500 Epoch=185.7] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=16.603 | 5384.1 samples/s | 84.1 steps/s
Client model saved at models/model-local_fc2-a1i1-sel1.0-ch26/client_iccad2012_0/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05270 | acc=0.9684 | tpr=0.9711 | fpr=0.0377 | 4206.0 samples/s | 16.4 steps/s
Avg test loss: 0.05474, Avg test acc: 0.96767, Avg tpr: 0.97080, Avg fpr: 0.03923, total FA: 306

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.47563 | acc=0.2983 | tpr=0.0045 | fpr=0.0637 | 4289.3 samples/s | 16.8 steps/s
Avg test loss: 5.46958, Avg test acc: 0.29506, Avg tpr: 0.00431, Avg fpr: 0.06550, total FA: 511

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.00946 | acc=0.1554 | tpr=0.1372 | fpr=0.8443 | 4190.0 samples/s | 16.4 steps/s
[Step= 100] | Loss=2.99649 | acc=0.1565 | tpr=0.1429 | fpr=0.8433 | 8211.2 samples/s | 32.1 steps/s
[Step= 150] | Loss=2.98869 | acc=0.1586 | tpr=0.1571 | fpr=0.8414 | 8096.4 samples/s | 31.6 steps/s
[Step= 200] | Loss=2.98473 | acc=0.1586 | tpr=0.1454 | fpr=0.8412 | 7788.4 samples/s | 30.4 steps/s
[Step= 250] | Loss=2.98641 | acc=0.1589 | tpr=0.1450 | fpr=0.8409 | 7881.4 samples/s | 30.8 steps/s
[Step= 300] | Loss=2.98552 | acc=0.1591 | tpr=0.1433 | fpr=0.8406 | 8024.9 samples/s | 31.3 steps/s
[Step= 350] | Loss=2.98402 | acc=0.1591 | tpr=0.1446 | fpr=0.8406 | 8028.4 samples/s | 31.4 steps/s
[Step= 400] | Loss=2.98569 | acc=0.1592 | tpr=0.1433 | fpr=0.8405 | 8052.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=2.98824 | acc=0.1588 | tpr=0.1436 | fpr=0.8410 | 8030.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=2.98705 | acc=0.1586 | tpr=0.1401 | fpr=0.8411 | 8002.0 samples/s | 31.3 steps/s
[Step= 550] | Loss=2.98797 | acc=0.1583 | tpr=0.1413 | fpr=0.8414 | 14404.3 samples/s | 56.3 steps/s
Avg test loss: 2.98866, Avg test acc: 0.15816, Avg tpr: 0.14144, Avg fpr: 0.84153, total FA: 116845

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09822 | acc=0.9803 | tpr=0.9513 | fpr=0.0192 | 4192.2 samples/s | 16.4 steps/s
[Step= 100] | Loss=0.10149 | acc=0.9801 | tpr=0.9574 | fpr=0.0195 | 8222.7 samples/s | 32.1 steps/s
[Step= 150] | Loss=0.10508 | acc=0.9796 | tpr=0.9611 | fpr=0.0201 | 7726.6 samples/s | 30.2 steps/s
[Step= 200] | Loss=0.10635 | acc=0.9797 | tpr=0.9650 | fpr=0.0200 | 8190.6 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.10507 | acc=0.9800 | tpr=0.9642 | fpr=0.0197 | 7866.8 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.10736 | acc=0.9796 | tpr=0.9636 | fpr=0.0201 | 7992.1 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.10703 | acc=0.9796 | tpr=0.9637 | fpr=0.0201 | 8142.8 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.10792 | acc=0.9794 | tpr=0.9623 | fpr=0.0203 | 7743.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=0.10959 | acc=0.9793 | tpr=0.9615 | fpr=0.0204 | 8211.2 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.10880 | acc=0.9793 | tpr=0.9612 | fpr=0.0204 | 7703.4 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.10799 | acc=0.9795 | tpr=0.9606 | fpr=0.0201 | 14999.8 samples/s | 58.6 steps/s
Avg test loss: 0.10782, Avg test acc: 0.97954, Avg tpr: 0.96038, Avg fpr: 0.02011, total FA: 2792
