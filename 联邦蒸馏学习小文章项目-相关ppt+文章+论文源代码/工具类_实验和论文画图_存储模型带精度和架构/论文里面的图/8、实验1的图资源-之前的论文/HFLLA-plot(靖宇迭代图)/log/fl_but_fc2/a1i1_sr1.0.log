#clients of iccad2012: 1
#clients of asml1: 1
select ratio: 1.0
Total num clients: 2
client model path: ['models/model-a1i1_sr1.0/client_asml1_0', 'models/model-a1i1_sr1.0/client_iccad2012_0']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (49916, 144, 32)
Resampled dataset to size (65551, 144, 32)
Using transform option: train
#pos = 34281, #neg = 31270
loading data into the main memory...
Allocated dataset with size (18300, 144, 32)
Resampled dataset to size (33952, 144, 32)
Using transform option: train
#pos = 16856, #neg = 17096
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 32)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.34405 | Reg=0.00358 | acc=0.5156 | L2-Norm=18.912 | L2-Norm(final)=1.970 | 3119.0 samples/s | 48.7 steps/s
[Step=  50 Epoch= 0.0] | Loss=0.34526 | Reg=0.00358 | acc=0.5000 | L2-Norm=18.912 | L2-Norm(final)=1.972 | 6266.1 samples/s | 97.9 steps/s
[Step= 100 Epoch= 0.1] | Loss=0.34068 | Reg=0.00358 | acc=0.6562 | L2-Norm=18.912 | L2-Norm(final)=1.981 | 6118.6 samples/s | 95.6 steps/s
[Step= 150 Epoch= 0.1] | Loss=0.33703 | Reg=0.00358 | acc=0.6562 | L2-Norm=18.912 | L2-Norm(final)=1.995 | 6322.9 samples/s | 98.8 steps/s
[Step= 200 Epoch= 0.2] | Loss=0.33442 | Reg=0.00358 | acc=0.6875 | L2-Norm=18.912 | L2-Norm(final)=2.011 | 6188.1 samples/s | 96.7 steps/s
[Step= 250 Epoch= 0.2] | Loss=0.33156 | Reg=0.00358 | acc=0.5781 | L2-Norm=18.912 | L2-Norm(final)=2.031 | 6012.6 samples/s | 93.9 steps/s
[Step= 300 Epoch= 0.3] | Loss=0.32898 | Reg=0.00358 | acc=0.6094 | L2-Norm=18.912 | L2-Norm(final)=2.053 | 5971.6 samples/s | 93.3 steps/s
[Step= 350 Epoch= 0.3] | Loss=0.32683 | Reg=0.00358 | acc=0.7031 | L2-Norm=18.912 | L2-Norm(final)=2.077 | 6075.7 samples/s | 94.9 steps/s
[Step= 400 Epoch= 0.4] | Loss=0.32505 | Reg=0.00358 | acc=0.6562 | L2-Norm=18.912 | L2-Norm(final)=2.103 | 6038.9 samples/s | 94.4 steps/s
[Step= 450 Epoch= 0.4] | Loss=0.32337 | Reg=0.00358 | acc=0.6562 | L2-Norm=18.912 | L2-Norm(final)=2.130 | 5990.9 samples/s | 93.6 steps/s
[Step= 500 Epoch= 0.5] | Loss=0.32231 | Reg=0.00358 | acc=0.6719 | L2-Norm=18.912 | L2-Norm(final)=2.159 | 6076.5 samples/s | 94.9 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.5] | Loss=0.31602 | Reg=0.00358 | acc=0.6094 | L2-Norm=18.912 | L2-Norm(final)=2.444 | 4194.1 samples/s | 65.5 steps/s
[Step= 550 Epoch= 0.5] | Loss=0.28429 | Reg=0.00343 | acc=0.8281 | L2-Norm=18.519 | L2-Norm(final)=2.447 | 5036.7 samples/s | 78.7 steps/s
[Step= 600 Epoch= 0.6] | Loss=0.25162 | Reg=0.00338 | acc=0.8750 | L2-Norm=18.379 | L2-Norm(final)=2.459 | 4985.5 samples/s | 77.9 steps/s
[Step= 650 Epoch= 0.6] | Loss=0.22342 | Reg=0.00335 | acc=0.8906 | L2-Norm=18.291 | L2-Norm(final)=2.465 | 4767.6 samples/s | 74.5 steps/s
[Step= 700 Epoch= 0.7] | Loss=0.20896 | Reg=0.00332 | acc=0.8125 | L2-Norm=18.227 | L2-Norm(final)=2.468 | 4865.5 samples/s | 76.0 steps/s
[Step= 750 Epoch= 0.7] | Loss=0.19475 | Reg=0.00330 | acc=0.9219 | L2-Norm=18.178 | L2-Norm(final)=2.472 | 4798.4 samples/s | 75.0 steps/s
[Step= 800 Epoch= 0.8] | Loss=0.18440 | Reg=0.00329 | acc=0.9219 | L2-Norm=18.138 | L2-Norm(final)=2.477 | 4914.1 samples/s | 76.8 steps/s
[Step= 850 Epoch= 0.8] | Loss=0.17495 | Reg=0.00328 | acc=0.9375 | L2-Norm=18.104 | L2-Norm(final)=2.482 | 4940.7 samples/s | 77.2 steps/s
[Step= 900 Epoch= 0.9] | Loss=0.16629 | Reg=0.00327 | acc=0.9219 | L2-Norm=18.074 | L2-Norm(final)=2.488 | 4874.3 samples/s | 76.2 steps/s
[Step= 950 Epoch= 0.9] | Loss=0.15946 | Reg=0.00326 | acc=0.9062 | L2-Norm=18.049 | L2-Norm(final)=2.494 | 4829.3 samples/s | 75.5 steps/s
[Step=1000 Epoch= 1.0] | Loss=0.15359 | Reg=0.00325 | acc=0.8594 | L2-Norm=18.029 | L2-Norm(final)=2.499 | 4809.2 samples/s | 75.1 steps/s
[Step=1050 Epoch= 1.0] | Loss=0.14855 | Reg=0.00324 | acc=0.9688 | L2-Norm=18.012 | L2-Norm(final)=2.503 | 4821.4 samples/s | 75.3 steps/s
[Step=1100 Epoch= 1.1] | Loss=0.14364 | Reg=0.00324 | acc=0.9531 | L2-Norm=17.996 | L2-Norm(final)=2.508 | 4796.4 samples/s | 74.9 steps/s
[Step=1150 Epoch= 1.1] | Loss=0.14005 | Reg=0.00323 | acc=0.8438 | L2-Norm=17.983 | L2-Norm(final)=2.512 | 4776.0 samples/s | 74.6 steps/s
[Step=1200 Epoch= 1.2] | Loss=0.13684 | Reg=0.00323 | acc=0.8750 | L2-Norm=17.970 | L2-Norm(final)=2.515 | 4820.1 samples/s | 75.3 steps/s
[Step=1250 Epoch= 1.2] | Loss=0.13400 | Reg=0.00323 | acc=0.9844 | L2-Norm=17.958 | L2-Norm(final)=2.519 | 4790.7 samples/s | 74.9 steps/s
[Step=1300 Epoch= 1.3] | Loss=0.13051 | Reg=0.00322 | acc=0.9375 | L2-Norm=17.947 | L2-Norm(final)=2.522 | 4840.5 samples/s | 75.6 steps/s
[Step=1350 Epoch= 1.3] | Loss=0.12774 | Reg=0.00322 | acc=0.9219 | L2-Norm=17.936 | L2-Norm(final)=2.524 | 4823.1 samples/s | 75.4 steps/s
[Step=1400 Epoch= 1.4] | Loss=0.12523 | Reg=0.00321 | acc=0.9375 | L2-Norm=17.926 | L2-Norm(final)=2.526 | 4844.9 samples/s | 75.7 steps/s
[Step=1450 Epoch= 1.4] | Loss=0.12268 | Reg=0.00321 | acc=0.9844 | L2-Norm=17.918 | L2-Norm(final)=2.528 | 4802.3 samples/s | 75.0 steps/s
[Step=1500 Epoch= 1.5] | Loss=0.12011 | Reg=0.00321 | acc=0.9688 | L2-Norm=17.910 | L2-Norm(final)=2.531 | 5153.8 samples/s | 80.5 steps/s
[Step=1550 Epoch= 1.5] | Loss=0.11766 | Reg=0.00321 | acc=0.9688 | L2-Norm=17.904 | L2-Norm(final)=2.532 | 2163.8 samples/s | 33.8 steps/s
[Step=1600 Epoch= 1.6] | Loss=0.11526 | Reg=0.00320 | acc=0.9688 | L2-Norm=17.898 | L2-Norm(final)=2.535 | 4957.3 samples/s | 77.5 steps/s
[Step=1650 Epoch= 1.6] | Loss=0.11295 | Reg=0.00320 | acc=0.9375 | L2-Norm=17.893 | L2-Norm(final)=2.537 | 4832.0 samples/s | 75.5 steps/s
[Step=1700 Epoch= 1.7] | Loss=0.11096 | Reg=0.00320 | acc=0.9688 | L2-Norm=17.888 | L2-Norm(final)=2.540 | 4770.7 samples/s | 74.5 steps/s
[Step=1750 Epoch= 1.7] | Loss=0.10883 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.883 | L2-Norm(final)=2.542 | 4789.0 samples/s | 74.8 steps/s
[Step=1800 Epoch= 1.8] | Loss=0.10731 | Reg=0.00320 | acc=0.9531 | L2-Norm=17.879 | L2-Norm(final)=2.543 | 4835.1 samples/s | 75.5 steps/s
[Step=1850 Epoch= 1.8] | Loss=0.10549 | Reg=0.00320 | acc=0.9062 | L2-Norm=17.876 | L2-Norm(final)=2.545 | 4796.2 samples/s | 74.9 steps/s
[Step=1900 Epoch= 1.9] | Loss=0.10415 | Reg=0.00319 | acc=0.9688 | L2-Norm=17.872 | L2-Norm(final)=2.546 | 4812.8 samples/s | 75.2 steps/s
[Step=1950 Epoch= 1.9] | Loss=0.10250 | Reg=0.00319 | acc=0.9844 | L2-Norm=17.870 | L2-Norm(final)=2.548 | 4834.3 samples/s | 75.5 steps/s
[Step=2000 Epoch= 2.0] | Loss=0.10102 | Reg=0.00319 | acc=0.9688 | L2-Norm=17.867 | L2-Norm(final)=2.549 | 4938.7 samples/s | 77.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step2000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.42863 | Reg=0.00358 | acc=0.4531 | L2-Norm=18.912 | L2-Norm(final)=1.968 | 4178.9 samples/s | 65.3 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.32904 | Reg=0.00358 | acc=0.5625 | L2-Norm=18.912 | L2-Norm(final)=1.968 | 5506.4 samples/s | 86.0 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.31053 | Reg=0.00358 | acc=0.7969 | L2-Norm=18.912 | L2-Norm(final)=1.992 | 5757.5 samples/s | 90.0 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.29590 | Reg=0.00358 | acc=0.8281 | L2-Norm=18.912 | L2-Norm(final)=2.043 | 5652.1 samples/s | 88.3 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.28425 | Reg=0.00358 | acc=0.7500 | L2-Norm=18.912 | L2-Norm(final)=2.108 | 5875.4 samples/s | 91.8 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.27370 | Reg=0.00358 | acc=0.7812 | L2-Norm=18.912 | L2-Norm(final)=2.181 | 5658.3 samples/s | 88.4 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.26467 | Reg=0.00358 | acc=0.8906 | L2-Norm=18.912 | L2-Norm(final)=2.260 | 5648.3 samples/s | 88.3 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.25653 | Reg=0.00358 | acc=0.8281 | L2-Norm=18.912 | L2-Norm(final)=2.343 | 5650.2 samples/s | 88.3 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.24905 | Reg=0.00358 | acc=0.9062 | L2-Norm=18.912 | L2-Norm(final)=2.429 | 5762.0 samples/s | 90.0 steps/s
[Step= 450 Epoch= 0.8] | Loss=0.24253 | Reg=0.00358 | acc=0.8750 | L2-Norm=18.912 | L2-Norm(final)=2.516 | 5545.9 samples/s | 86.7 steps/s
[Step= 500 Epoch= 0.9] | Loss=0.23680 | Reg=0.00358 | acc=0.8281 | L2-Norm=18.912 | L2-Norm(final)=2.602 | 5724.3 samples/s | 89.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.9] | Loss=0.17912 | Reg=0.00358 | acc=0.9062 | L2-Norm=18.912 | L2-Norm(final)=3.457 | 3934.5 samples/s | 61.5 steps/s
[Step= 550 Epoch= 1.0] | Loss=0.12102 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.435 | L2-Norm(final)=3.481 | 4499.8 samples/s | 70.3 steps/s
[Step= 600 Epoch= 1.1] | Loss=0.08539 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.249 | L2-Norm(final)=3.492 | 4526.8 samples/s | 70.7 steps/s
[Step= 650 Epoch= 1.2] | Loss=0.06353 | Reg=0.00329 | acc=0.9688 | L2-Norm=18.150 | L2-Norm(final)=3.500 | 4563.6 samples/s | 71.3 steps/s
[Step= 700 Epoch= 1.3] | Loss=0.05165 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.086 | L2-Norm(final)=3.507 | 4540.9 samples/s | 71.0 steps/s
[Step= 750 Epoch= 1.4] | Loss=0.04791 | Reg=0.00325 | acc=0.9844 | L2-Norm=18.038 | L2-Norm(final)=3.511 | 4504.9 samples/s | 70.4 steps/s
[Step= 800 Epoch= 1.5] | Loss=0.04256 | Reg=0.00324 | acc=0.9844 | L2-Norm=18.005 | L2-Norm(final)=3.512 | 4582.4 samples/s | 71.6 steps/s
[Step= 850 Epoch= 1.6] | Loss=0.03879 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.977 | L2-Norm(final)=3.513 | 4682.4 samples/s | 73.2 steps/s
[Step= 900 Epoch= 1.7] | Loss=0.03472 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.953 | L2-Norm(final)=3.515 | 4587.3 samples/s | 71.7 steps/s
[Step= 950 Epoch= 1.8] | Loss=0.03114 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.930 | L2-Norm(final)=3.517 | 4572.4 samples/s | 71.4 steps/s
[Step=1000 Epoch= 1.9] | Loss=0.02892 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.907 | L2-Norm(final)=3.519 | 4634.1 samples/s | 72.4 steps/s
[Step=1050 Epoch= 2.0] | Loss=0.02661 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.885 | L2-Norm(final)=3.521 | 2161.2 samples/s | 33.8 steps/s
[Step=1100 Epoch= 2.1] | Loss=0.02462 | Reg=0.00319 | acc=1.0000 | L2-Norm=17.863 | L2-Norm(final)=3.523 | 4651.9 samples/s | 72.7 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.02303 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.841 | L2-Norm(final)=3.524 | 4482.5 samples/s | 70.0 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.02165 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.820 | L2-Norm(final)=3.526 | 4584.7 samples/s | 71.6 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.02036 | Reg=0.00317 | acc=1.0000 | L2-Norm=17.798 | L2-Norm(final)=3.527 | 4580.2 samples/s | 71.6 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.01916 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.777 | L2-Norm(final)=3.528 | 4571.7 samples/s | 71.4 steps/s
[Step=1350 Epoch= 2.5] | Loss=0.01820 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.755 | L2-Norm(final)=3.530 | 4585.1 samples/s | 71.6 steps/s
[Step=1400 Epoch= 2.6] | Loss=0.01741 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.733 | L2-Norm(final)=3.531 | 4580.8 samples/s | 71.6 steps/s
[Step=1450 Epoch= 2.7] | Loss=0.01673 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.712 | L2-Norm(final)=3.532 | 4593.4 samples/s | 71.8 steps/s
[Step=1500 Epoch= 2.8] | Loss=0.01599 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.692 | L2-Norm(final)=3.533 | 4537.2 samples/s | 70.9 steps/s
[Step=1550 Epoch= 2.9] | Loss=0.01540 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.672 | L2-Norm(final)=3.535 | 5752.2 samples/s | 89.9 steps/s
[Step=1600 Epoch= 3.0] | Loss=0.01474 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.652 | L2-Norm(final)=3.536 | 1959.2 samples/s | 30.6 steps/s
[Step=1650 Epoch= 3.1] | Loss=0.01425 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.632 | L2-Norm(final)=3.537 | 4564.3 samples/s | 71.3 steps/s
[Step=1700 Epoch= 3.2] | Loss=0.01370 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=3.539 | 4550.7 samples/s | 71.1 steps/s
[Step=1750 Epoch= 3.3] | Loss=0.01319 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.595 | L2-Norm(final)=3.540 | 4545.1 samples/s | 71.0 steps/s
[Step=1800 Epoch= 3.4] | Loss=0.01271 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.576 | L2-Norm(final)=3.541 | 4585.1 samples/s | 71.6 steps/s
[Step=1850 Epoch= 3.5] | Loss=0.01229 | Reg=0.00308 | acc=0.9844 | L2-Norm=17.556 | L2-Norm(final)=3.543 | 4592.6 samples/s | 71.8 steps/s
[Step=1900 Epoch= 3.6] | Loss=0.01190 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.537 | L2-Norm(final)=3.544 | 4643.6 samples/s | 72.6 steps/s
[Step=1950 Epoch= 3.7] | Loss=0.01156 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.518 | L2-Norm(final)=3.545 | 4466.8 samples/s | 69.8 steps/s
[Step=2000 Epoch= 3.8] | Loss=0.01136 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.499 | L2-Norm(final)=3.546 | 4543.6 samples/s | 71.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06270 | acc=0.9534 | tpr=0.9644 | fpr=0.0706 | 4657.5 samples/s | 18.2 steps/s
Avg test loss: 0.06607, Avg test acc: 0.95144, Avg tpr: 0.96235, Avg fpr: 0.07255, total FA: 566

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.72457 | acc=0.3080 | tpr=0.0362 | fpr=0.1016 | 4548.2 samples/s | 17.8 steps/s
Avg test loss: 4.72609, Avg test acc: 0.30868, Avg tpr: 0.03783, Avg fpr: 0.09563, total FA: 746

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.56526 | acc=0.1409 | tpr=0.7434 | fpr=0.8700 | 4560.3 samples/s | 17.8 steps/s
[Step= 100] | Loss=2.54995 | acc=0.1394 | tpr=0.7271 | fpr=0.8716 | 9115.7 samples/s | 35.6 steps/s
[Step= 150] | Loss=2.55139 | acc=0.1390 | tpr=0.7334 | fpr=0.8719 | 8524.7 samples/s | 33.3 steps/s
[Step= 200] | Loss=2.54537 | acc=0.1396 | tpr=0.7290 | fpr=0.8711 | 8269.1 samples/s | 32.3 steps/s
[Step= 250] | Loss=2.54664 | acc=0.1401 | tpr=0.7319 | fpr=0.8706 | 8656.0 samples/s | 33.8 steps/s
[Step= 300] | Loss=2.54453 | acc=0.1393 | tpr=0.7258 | fpr=0.8713 | 8805.8 samples/s | 34.4 steps/s
[Step= 350] | Loss=2.54313 | acc=0.1390 | tpr=0.7307 | fpr=0.8717 | 8577.9 samples/s | 33.5 steps/s
[Step= 400] | Loss=2.54320 | acc=0.1393 | tpr=0.7341 | fpr=0.8715 | 8512.3 samples/s | 33.3 steps/s
[Step= 450] | Loss=2.54314 | acc=0.1394 | tpr=0.7405 | fpr=0.8715 | 8137.2 samples/s | 31.8 steps/s
[Step= 500] | Loss=2.54116 | acc=0.1393 | tpr=0.7396 | fpr=0.8715 | 8337.1 samples/s | 32.6 steps/s
[Step= 550] | Loss=2.54311 | acc=0.1392 | tpr=0.7429 | fpr=0.8718 | 15558.4 samples/s | 60.8 steps/s
Avg test loss: 2.54395, Avg test acc: 0.13904, Avg tpr: 0.74287, Avg fpr: 0.87193, total FA: 121066

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.07984 | acc=0.9770 | tpr=0.9602 | fpr=0.0227 | 4570.2 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.08158 | acc=0.9765 | tpr=0.9723 | fpr=0.0234 | 8754.5 samples/s | 34.2 steps/s
[Step= 150] | Loss=0.08346 | acc=0.9756 | tpr=0.9741 | fpr=0.0244 | 8281.4 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.08451 | acc=0.9758 | tpr=0.9770 | fpr=0.0242 | 8513.6 samples/s | 33.3 steps/s
[Step= 250] | Loss=0.08368 | acc=0.9758 | tpr=0.9790 | fpr=0.0243 | 9066.7 samples/s | 35.4 steps/s
[Step= 300] | Loss=0.08416 | acc=0.9755 | tpr=0.9775 | fpr=0.0245 | 8136.0 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.08472 | acc=0.9754 | tpr=0.9762 | fpr=0.0246 | 8704.7 samples/s | 34.0 steps/s
[Step= 400] | Loss=0.08554 | acc=0.9752 | tpr=0.9737 | fpr=0.0248 | 8247.7 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.08696 | acc=0.9749 | tpr=0.9713 | fpr=0.0250 | 8645.4 samples/s | 33.8 steps/s
[Step= 500] | Loss=0.08674 | acc=0.9749 | tpr=0.9718 | fpr=0.0251 | 8599.1 samples/s | 33.6 steps/s
[Step= 550] | Loss=0.08617 | acc=0.9750 | tpr=0.9702 | fpr=0.0249 | 14559.9 samples/s | 56.9 steps/s
Avg test loss: 0.08598, Avg test acc: 0.97507, Avg tpr: 0.97029, Avg fpr: 0.02484, total FA: 3449

server round 1/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=2001 Epoch= 2.0] | Loss=0.16570 | Reg=0.00273 | acc=0.8906 | L2-Norm=16.514 | L2-Norm(final)=2.587 | 4066.1 samples/s | 63.5 steps/s
[Step=2050 Epoch= 2.0] | Loss=0.20019 | Reg=0.00273 | acc=0.9062 | L2-Norm=16.514 | L2-Norm(final)=2.619 | 5328.0 samples/s | 83.3 steps/s
[Step=2100 Epoch= 2.1] | Loss=0.18925 | Reg=0.00273 | acc=0.7812 | L2-Norm=16.514 | L2-Norm(final)=2.703 | 5602.2 samples/s | 87.5 steps/s
[Step=2150 Epoch= 2.1] | Loss=0.18251 | Reg=0.00273 | acc=0.7656 | L2-Norm=16.514 | L2-Norm(final)=2.784 | 5478.3 samples/s | 85.6 steps/s
[Step=2200 Epoch= 2.1] | Loss=0.17755 | Reg=0.00273 | acc=0.8438 | L2-Norm=16.515 | L2-Norm(final)=2.861 | 5484.5 samples/s | 85.7 steps/s
[Step=2250 Epoch= 2.2] | Loss=0.17400 | Reg=0.00273 | acc=0.9062 | L2-Norm=16.515 | L2-Norm(final)=2.936 | 5542.9 samples/s | 86.6 steps/s
[Step=2300 Epoch= 2.2] | Loss=0.17203 | Reg=0.00273 | acc=0.9062 | L2-Norm=16.515 | L2-Norm(final)=3.005 | 5553.9 samples/s | 86.8 steps/s
[Step=2350 Epoch= 2.3] | Loss=0.17018 | Reg=0.00273 | acc=0.9375 | L2-Norm=16.515 | L2-Norm(final)=3.070 | 5506.4 samples/s | 86.0 steps/s
[Step=2400 Epoch= 2.3] | Loss=0.16779 | Reg=0.00273 | acc=0.8281 | L2-Norm=16.515 | L2-Norm(final)=3.132 | 5472.3 samples/s | 85.5 steps/s
[Step=2450 Epoch= 2.4] | Loss=0.16601 | Reg=0.00273 | acc=0.8906 | L2-Norm=16.515 | L2-Norm(final)=3.191 | 5568.0 samples/s | 87.0 steps/s
[Step=2500 Epoch= 2.4] | Loss=0.16461 | Reg=0.00273 | acc=0.8750 | L2-Norm=16.515 | L2-Norm(final)=3.248 | 5576.0 samples/s | 87.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 2.4] | Loss=0.14494 | Reg=0.00273 | acc=0.8594 | L2-Norm=16.515 | L2-Norm(final)=3.795 | 4452.2 samples/s | 69.6 steps/s
[Step=2550 Epoch= 2.5] | Loss=0.13467 | Reg=0.00279 | acc=0.9219 | L2-Norm=16.699 | L2-Norm(final)=3.799 | 4540.5 samples/s | 70.9 steps/s
[Step=2600 Epoch= 2.5] | Loss=0.12230 | Reg=0.00283 | acc=0.9062 | L2-Norm=16.818 | L2-Norm(final)=3.791 | 4849.7 samples/s | 75.8 steps/s
[Step=2650 Epoch= 2.6] | Loss=0.11093 | Reg=0.00285 | acc=0.9062 | L2-Norm=16.886 | L2-Norm(final)=3.784 | 4893.1 samples/s | 76.5 steps/s
[Step=2700 Epoch= 2.6] | Loss=0.10701 | Reg=0.00287 | acc=0.9375 | L2-Norm=16.933 | L2-Norm(final)=3.780 | 4933.5 samples/s | 77.1 steps/s
[Step=2750 Epoch= 2.7] | Loss=0.10158 | Reg=0.00288 | acc=0.9062 | L2-Norm=16.969 | L2-Norm(final)=3.777 | 4932.7 samples/s | 77.1 steps/s
[Step=2800 Epoch= 2.7] | Loss=0.09759 | Reg=0.00289 | acc=0.9688 | L2-Norm=16.998 | L2-Norm(final)=3.774 | 4885.5 samples/s | 76.3 steps/s
[Step=2850 Epoch= 2.8] | Loss=0.09474 | Reg=0.00290 | acc=0.8750 | L2-Norm=17.026 | L2-Norm(final)=3.773 | 4887.7 samples/s | 76.4 steps/s
[Step=2900 Epoch= 2.8] | Loss=0.09215 | Reg=0.00291 | acc=0.8750 | L2-Norm=17.050 | L2-Norm(final)=3.772 | 4941.8 samples/s | 77.2 steps/s
[Step=2950 Epoch= 2.9] | Loss=0.08960 | Reg=0.00291 | acc=0.9375 | L2-Norm=17.069 | L2-Norm(final)=3.770 | 4928.5 samples/s | 77.0 steps/s
[Step=3000 Epoch= 2.9] | Loss=0.08727 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.087 | L2-Norm(final)=3.768 | 4824.1 samples/s | 75.4 steps/s
[Step=3050 Epoch= 3.0] | Loss=0.08532 | Reg=0.00293 | acc=0.9375 | L2-Norm=17.103 | L2-Norm(final)=3.767 | 4798.6 samples/s | 75.0 steps/s
[Step=3100 Epoch= 3.0] | Loss=0.08293 | Reg=0.00293 | acc=0.9688 | L2-Norm=17.117 | L2-Norm(final)=3.766 | 4840.4 samples/s | 75.6 steps/s
[Step=3150 Epoch= 3.1] | Loss=0.08129 | Reg=0.00293 | acc=0.9375 | L2-Norm=17.129 | L2-Norm(final)=3.765 | 4816.9 samples/s | 75.3 steps/s
[Step=3200 Epoch= 3.1] | Loss=0.08025 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.140 | L2-Norm(final)=3.764 | 4813.2 samples/s | 75.2 steps/s
[Step=3250 Epoch= 3.2] | Loss=0.07925 | Reg=0.00294 | acc=0.9531 | L2-Norm=17.150 | L2-Norm(final)=3.763 | 4799.3 samples/s | 75.0 steps/s
[Step=3300 Epoch= 3.2] | Loss=0.07840 | Reg=0.00294 | acc=0.9375 | L2-Norm=17.160 | L2-Norm(final)=3.761 | 4735.4 samples/s | 74.0 steps/s
[Step=3350 Epoch= 3.3] | Loss=0.07738 | Reg=0.00295 | acc=0.9531 | L2-Norm=17.169 | L2-Norm(final)=3.760 | 4818.0 samples/s | 75.3 steps/s
[Step=3400 Epoch= 3.3] | Loss=0.07613 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.178 | L2-Norm(final)=3.759 | 4947.6 samples/s | 77.3 steps/s
[Step=3450 Epoch= 3.4] | Loss=0.07531 | Reg=0.00295 | acc=0.9375 | L2-Norm=17.187 | L2-Norm(final)=3.758 | 4913.2 samples/s | 76.8 steps/s
[Step=3500 Epoch= 3.4] | Loss=0.07463 | Reg=0.00296 | acc=0.9219 | L2-Norm=17.196 | L2-Norm(final)=3.757 | 5289.3 samples/s | 82.6 steps/s
[Step=3550 Epoch= 3.5] | Loss=0.07348 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.205 | L2-Norm(final)=3.756 | 2129.4 samples/s | 33.3 steps/s
[Step=3600 Epoch= 3.5] | Loss=0.07224 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.215 | L2-Norm(final)=3.755 | 4818.9 samples/s | 75.3 steps/s
[Step=3650 Epoch= 3.6] | Loss=0.07137 | Reg=0.00297 | acc=0.8594 | L2-Norm=17.225 | L2-Norm(final)=3.755 | 4758.3 samples/s | 74.3 steps/s
[Step=3700 Epoch= 3.6] | Loss=0.07029 | Reg=0.00297 | acc=0.9688 | L2-Norm=17.235 | L2-Norm(final)=3.754 | 4781.6 samples/s | 74.7 steps/s
[Step=3750 Epoch= 3.7] | Loss=0.06961 | Reg=0.00297 | acc=0.9531 | L2-Norm=17.245 | L2-Norm(final)=3.753 | 4857.5 samples/s | 75.9 steps/s
[Step=3800 Epoch= 3.7] | Loss=0.06865 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.254 | L2-Norm(final)=3.752 | 4742.7 samples/s | 74.1 steps/s
[Step=3850 Epoch= 3.8] | Loss=0.06757 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.264 | L2-Norm(final)=3.752 | 4769.3 samples/s | 74.5 steps/s
[Step=3900 Epoch= 3.8] | Loss=0.06662 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.273 | L2-Norm(final)=3.752 | 4786.5 samples/s | 74.8 steps/s
[Step=3950 Epoch= 3.9] | Loss=0.06624 | Reg=0.00299 | acc=0.9375 | L2-Norm=17.282 | L2-Norm(final)=3.751 | 4727.3 samples/s | 73.9 steps/s
[Step=4000 Epoch= 3.9] | Loss=0.06539 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.290 | L2-Norm(final)=3.750 | 4780.6 samples/s | 74.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step4000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=2001 Epoch= 3.8] | Loss=0.13101 | Reg=0.00273 | acc=0.9219 | L2-Norm=16.514 | L2-Norm(final)=3.563 | 4231.7 samples/s | 66.1 steps/s
[Step=2050 Epoch= 3.9] | Loss=0.06825 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.509 | L2-Norm(final)=3.597 | 4928.1 samples/s | 77.0 steps/s
[Step=2100 Epoch= 4.0] | Loss=0.05826 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=3.744 | 5269.8 samples/s | 82.3 steps/s
[Step=2150 Epoch= 4.1] | Loss=0.05289 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.508 | L2-Norm(final)=3.874 | 5328.0 samples/s | 83.2 steps/s
[Step=2200 Epoch= 4.1] | Loss=0.04916 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=3.993 | 5313.0 samples/s | 83.0 steps/s
[Step=2250 Epoch= 4.2] | Loss=0.04778 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.508 | L2-Norm(final)=4.103 | 5301.8 samples/s | 82.8 steps/s
[Step=2300 Epoch= 4.3] | Loss=0.04672 | Reg=0.00273 | acc=0.9531 | L2-Norm=16.508 | L2-Norm(final)=4.204 | 5269.5 samples/s | 82.3 steps/s
[Step=2350 Epoch= 4.4] | Loss=0.04489 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=4.298 | 5063.9 samples/s | 79.1 steps/s
[Step=2400 Epoch= 4.5] | Loss=0.04375 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.508 | L2-Norm(final)=4.385 | 5202.0 samples/s | 81.3 steps/s
[Step=2450 Epoch= 4.6] | Loss=0.04233 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=4.468 | 5346.9 samples/s | 83.5 steps/s
[Step=2500 Epoch= 4.7] | Loss=0.04134 | Reg=0.00273 | acc=0.9531 | L2-Norm=16.508 | L2-Norm(final)=4.546 | 5233.6 samples/s | 81.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.7] | Loss=0.01982 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=5.300 | 4206.6 samples/s | 65.7 steps/s
[Step=2550 Epoch= 4.8] | Loss=0.03221 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.635 | L2-Norm(final)=5.295 | 4443.4 samples/s | 69.4 steps/s
[Step=2600 Epoch= 4.9] | Loss=0.02895 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.716 | L2-Norm(final)=5.280 | 4513.6 samples/s | 70.5 steps/s
[Step=2650 Epoch= 5.0] | Loss=0.02260 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=5.266 | 4538.1 samples/s | 70.9 steps/s
[Step=2700 Epoch= 5.1] | Loss=0.01870 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.781 | L2-Norm(final)=5.260 | 4541.7 samples/s | 71.0 steps/s
[Step=2750 Epoch= 5.2] | Loss=0.01608 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.783 | L2-Norm(final)=5.256 | 4512.7 samples/s | 70.5 steps/s
[Step=2800 Epoch= 5.3] | Loss=0.01402 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.776 | L2-Norm(final)=5.254 | 4551.7 samples/s | 71.1 steps/s
[Step=2850 Epoch= 5.4] | Loss=0.01291 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.765 | L2-Norm(final)=5.252 | 4545.5 samples/s | 71.0 steps/s
[Step=2900 Epoch= 5.5] | Loss=0.01173 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=5.251 | 4579.1 samples/s | 71.5 steps/s
[Step=2950 Epoch= 5.6] | Loss=0.01081 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.735 | L2-Norm(final)=5.250 | 4566.0 samples/s | 71.3 steps/s
[Step=3000 Epoch= 5.7] | Loss=0.01001 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.718 | L2-Norm(final)=5.249 | 4624.8 samples/s | 72.3 steps/s
[Step=3050 Epoch= 5.7] | Loss=0.00932 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.700 | L2-Norm(final)=5.248 | 2158.2 samples/s | 33.7 steps/s
[Step=3100 Epoch= 5.8] | Loss=0.00860 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.681 | L2-Norm(final)=5.247 | 4806.0 samples/s | 75.1 steps/s
[Step=3150 Epoch= 5.9] | Loss=0.00799 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.660 | L2-Norm(final)=5.247 | 4636.5 samples/s | 72.4 steps/s
[Step=3200 Epoch= 6.0] | Loss=0.00743 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=5.248 | 4633.0 samples/s | 72.4 steps/s
[Step=3250 Epoch= 6.1] | Loss=0.00696 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.615 | L2-Norm(final)=5.248 | 4739.6 samples/s | 74.1 steps/s
[Step=3300 Epoch= 6.2] | Loss=0.00669 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.592 | L2-Norm(final)=5.248 | 4624.1 samples/s | 72.3 steps/s
[Step=3350 Epoch= 6.3] | Loss=0.00641 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.570 | L2-Norm(final)=5.248 | 4649.9 samples/s | 72.7 steps/s
[Step=3400 Epoch= 6.4] | Loss=0.00636 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.549 | L2-Norm(final)=5.248 | 4677.1 samples/s | 73.1 steps/s
[Step=3450 Epoch= 6.5] | Loss=0.00619 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.531 | L2-Norm(final)=5.247 | 4617.0 samples/s | 72.1 steps/s
[Step=3500 Epoch= 6.6] | Loss=0.00611 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.515 | L2-Norm(final)=5.246 | 4622.6 samples/s | 72.2 steps/s
[Step=3550 Epoch= 6.7] | Loss=0.00588 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.500 | L2-Norm(final)=5.245 | 5605.3 samples/s | 87.6 steps/s
[Step=3600 Epoch= 6.8] | Loss=0.00567 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.485 | L2-Norm(final)=5.244 | 1963.2 samples/s | 30.7 steps/s
[Step=3650 Epoch= 6.9] | Loss=0.00547 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.470 | L2-Norm(final)=5.243 | 4509.9 samples/s | 70.5 steps/s
[Step=3700 Epoch= 7.0] | Loss=0.00540 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.455 | L2-Norm(final)=5.243 | 4489.7 samples/s | 70.2 steps/s
[Step=3750 Epoch= 7.1] | Loss=0.00533 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.441 | L2-Norm(final)=5.242 | 4540.8 samples/s | 71.0 steps/s
[Step=3800 Epoch= 7.2] | Loss=0.00525 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.428 | L2-Norm(final)=5.240 | 4518.2 samples/s | 70.6 steps/s
[Step=3850 Epoch= 7.3] | Loss=0.00518 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.416 | L2-Norm(final)=5.239 | 4524.1 samples/s | 70.7 steps/s
[Step=3900 Epoch= 7.4] | Loss=0.00504 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.403 | L2-Norm(final)=5.237 | 4589.8 samples/s | 71.7 steps/s
[Step=3950 Epoch= 7.4] | Loss=0.00490 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.391 | L2-Norm(final)=5.236 | 4509.2 samples/s | 70.5 steps/s
[Step=4000 Epoch= 7.5] | Loss=0.00476 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.377 | L2-Norm(final)=5.235 | 4538.3 samples/s | 70.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05820 | acc=0.9605 | tpr=0.9742 | fpr=0.0694 | 4530.3 samples/s | 17.7 steps/s
Avg test loss: 0.05952, Avg test acc: 0.95941, Avg tpr: 0.97226, Avg fpr: 0.06884, total FA: 537

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.58152 | acc=0.3169 | tpr=0.0175 | fpr=0.0330 | 4648.5 samples/s | 18.2 steps/s
Avg test loss: 6.60197, Avg test acc: 0.31405, Avg tpr: 0.01649, Avg fpr: 0.03153, total FA: 246

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.36527 | acc=0.1191 | tpr=0.7832 | fpr=0.8928 | 4681.7 samples/s | 18.3 steps/s
[Step= 100] | Loss=3.35233 | acc=0.1188 | tpr=0.7996 | fpr=0.8939 | 8405.3 samples/s | 32.8 steps/s
[Step= 150] | Loss=3.35126 | acc=0.1192 | tpr=0.8012 | fpr=0.8933 | 9087.3 samples/s | 35.5 steps/s
[Step= 200] | Loss=3.34859 | acc=0.1188 | tpr=0.7945 | fpr=0.8935 | 8226.3 samples/s | 32.1 steps/s
[Step= 250] | Loss=3.35281 | acc=0.1194 | tpr=0.7956 | fpr=0.8929 | 8565.3 samples/s | 33.5 steps/s
[Step= 300] | Loss=3.34789 | acc=0.1197 | tpr=0.7985 | fpr=0.8927 | 8510.8 samples/s | 33.2 steps/s
[Step= 350] | Loss=3.34671 | acc=0.1192 | tpr=0.7996 | fpr=0.8931 | 8536.9 samples/s | 33.3 steps/s
[Step= 400] | Loss=3.34400 | acc=0.1200 | tpr=0.8020 | fpr=0.8924 | 8633.7 samples/s | 33.7 steps/s
[Step= 450] | Loss=3.34474 | acc=0.1204 | tpr=0.8062 | fpr=0.8921 | 8353.9 samples/s | 32.6 steps/s
[Step= 500] | Loss=3.34286 | acc=0.1205 | tpr=0.8093 | fpr=0.8919 | 8404.0 samples/s | 32.8 steps/s
[Step= 550] | Loss=3.34393 | acc=0.1208 | tpr=0.8110 | fpr=0.8918 | 14996.7 samples/s | 58.6 steps/s
Avg test loss: 3.34470, Avg test acc: 0.12065, Avg tpr: 0.81062, Avg fpr: 0.89189, total FA: 123837

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09996 | acc=0.9795 | tpr=0.9602 | fpr=0.0201 | 4515.1 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.10405 | acc=0.9789 | tpr=0.9744 | fpr=0.0210 | 8576.7 samples/s | 33.5 steps/s
[Step= 150] | Loss=0.10804 | acc=0.9783 | tpr=0.9712 | fpr=0.0216 | 8515.4 samples/s | 33.3 steps/s
[Step= 200] | Loss=0.10859 | acc=0.9783 | tpr=0.9738 | fpr=0.0216 | 8752.9 samples/s | 34.2 steps/s
[Step= 250] | Loss=0.10636 | acc=0.9784 | tpr=0.9694 | fpr=0.0214 | 8586.1 samples/s | 33.5 steps/s
[Step= 300] | Loss=0.10751 | acc=0.9782 | tpr=0.9695 | fpr=0.0216 | 8382.5 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.10804 | acc=0.9782 | tpr=0.9712 | fpr=0.0217 | 8639.5 samples/s | 33.7 steps/s
[Step= 400] | Loss=0.10880 | acc=0.9780 | tpr=0.9710 | fpr=0.0219 | 8339.7 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.11056 | acc=0.9778 | tpr=0.9693 | fpr=0.0220 | 8435.8 samples/s | 33.0 steps/s
[Step= 500] | Loss=0.11033 | acc=0.9778 | tpr=0.9700 | fpr=0.0221 | 8587.3 samples/s | 33.5 steps/s
[Step= 550] | Loss=0.10962 | acc=0.9780 | tpr=0.9694 | fpr=0.0219 | 15108.8 samples/s | 59.0 steps/s
Avg test loss: 0.10941, Avg test acc: 0.97801, Avg tpr: 0.96949, Avg fpr: 0.02184, total FA: 3032

server round 2/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=4001 Epoch= 3.9] | Loss=0.14263 | Reg=0.00253 | acc=0.8906 | L2-Norm=15.920 | L2-Norm(final)=3.734 | 4375.9 samples/s | 68.4 steps/s
[Step=4050 Epoch= 4.0] | Loss=0.16021 | Reg=0.00254 | acc=0.9062 | L2-Norm=15.922 | L2-Norm(final)=3.782 | 5221.3 samples/s | 81.6 steps/s
[Step=4100 Epoch= 4.0] | Loss=0.15273 | Reg=0.00254 | acc=0.8594 | L2-Norm=15.923 | L2-Norm(final)=3.863 | 5427.9 samples/s | 84.8 steps/s
[Step=4150 Epoch= 4.1] | Loss=0.15265 | Reg=0.00254 | acc=0.8438 | L2-Norm=15.923 | L2-Norm(final)=3.936 | 5472.8 samples/s | 85.5 steps/s
[Step=4200 Epoch= 4.1] | Loss=0.14968 | Reg=0.00254 | acc=0.9375 | L2-Norm=15.923 | L2-Norm(final)=3.998 | 5364.1 samples/s | 83.8 steps/s
[Step=4250 Epoch= 4.1] | Loss=0.14730 | Reg=0.00254 | acc=0.9062 | L2-Norm=15.923 | L2-Norm(final)=4.059 | 5532.6 samples/s | 86.4 steps/s
[Step=4300 Epoch= 4.2] | Loss=0.14627 | Reg=0.00254 | acc=0.9375 | L2-Norm=15.923 | L2-Norm(final)=4.116 | 5506.5 samples/s | 86.0 steps/s
[Step=4350 Epoch= 4.2] | Loss=0.14620 | Reg=0.00254 | acc=0.9375 | L2-Norm=15.923 | L2-Norm(final)=4.169 | 5541.1 samples/s | 86.6 steps/s
[Step=4400 Epoch= 4.3] | Loss=0.14461 | Reg=0.00254 | acc=0.8125 | L2-Norm=15.923 | L2-Norm(final)=4.218 | 5486.8 samples/s | 85.7 steps/s
[Step=4450 Epoch= 4.3] | Loss=0.14428 | Reg=0.00254 | acc=0.8594 | L2-Norm=15.923 | L2-Norm(final)=4.264 | 5509.1 samples/s | 86.1 steps/s
[Step=4500 Epoch= 4.4] | Loss=0.14297 | Reg=0.00254 | acc=0.8438 | L2-Norm=15.923 | L2-Norm(final)=4.309 | 5509.1 samples/s | 86.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 4.4] | Loss=0.16503 | Reg=0.00254 | acc=0.8594 | L2-Norm=15.923 | L2-Norm(final)=4.759 | 4278.8 samples/s | 66.9 steps/s
[Step=4550 Epoch= 4.4] | Loss=0.11413 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.102 | L2-Norm(final)=4.763 | 4470.4 samples/s | 69.9 steps/s
[Step=4600 Epoch= 4.5] | Loss=0.09309 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.218 | L2-Norm(final)=4.757 | 4500.7 samples/s | 70.3 steps/s
[Step=4650 Epoch= 4.5] | Loss=0.09077 | Reg=0.00265 | acc=0.9531 | L2-Norm=16.284 | L2-Norm(final)=4.751 | 4679.2 samples/s | 73.1 steps/s
[Step=4700 Epoch= 4.6] | Loss=0.08528 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.340 | L2-Norm(final)=4.747 | 4556.1 samples/s | 71.2 steps/s
[Step=4750 Epoch= 4.6] | Loss=0.08110 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.386 | L2-Norm(final)=4.742 | 4747.3 samples/s | 74.2 steps/s
[Step=4800 Epoch= 4.7] | Loss=0.07764 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.426 | L2-Norm(final)=4.738 | 4824.8 samples/s | 75.4 steps/s
[Step=4850 Epoch= 4.7] | Loss=0.07626 | Reg=0.00271 | acc=0.9531 | L2-Norm=16.461 | L2-Norm(final)=4.734 | 4889.6 samples/s | 76.4 steps/s
[Step=4900 Epoch= 4.8] | Loss=0.07470 | Reg=0.00272 | acc=0.9531 | L2-Norm=16.493 | L2-Norm(final)=4.730 | 4793.3 samples/s | 74.9 steps/s
[Step=4950 Epoch= 4.8] | Loss=0.07310 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.523 | L2-Norm(final)=4.725 | 4872.0 samples/s | 76.1 steps/s
[Step=5000 Epoch= 4.9] | Loss=0.07154 | Reg=0.00274 | acc=0.8438 | L2-Norm=16.549 | L2-Norm(final)=4.722 | 4789.8 samples/s | 74.8 steps/s
[Step=5050 Epoch= 4.9] | Loss=0.07183 | Reg=0.00275 | acc=0.9375 | L2-Norm=16.577 | L2-Norm(final)=4.716 | 4788.5 samples/s | 74.8 steps/s
[Step=5100 Epoch= 5.0] | Loss=0.07068 | Reg=0.00276 | acc=0.9375 | L2-Norm=16.604 | L2-Norm(final)=4.711 | 4774.6 samples/s | 74.6 steps/s
[Step=5150 Epoch= 5.0] | Loss=0.06948 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.629 | L2-Norm(final)=4.706 | 4715.6 samples/s | 73.7 steps/s
[Step=5200 Epoch= 5.1] | Loss=0.06800 | Reg=0.00277 | acc=0.9531 | L2-Norm=16.652 | L2-Norm(final)=4.703 | 4721.0 samples/s | 73.8 steps/s
[Step=5250 Epoch= 5.1] | Loss=0.06702 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.673 | L2-Norm(final)=4.699 | 4843.7 samples/s | 75.7 steps/s
[Step=5300 Epoch= 5.2] | Loss=0.06631 | Reg=0.00279 | acc=0.9062 | L2-Norm=16.693 | L2-Norm(final)=4.695 | 4866.4 samples/s | 76.0 steps/s
[Step=5350 Epoch= 5.2] | Loss=0.06528 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.711 | L2-Norm(final)=4.692 | 4986.9 samples/s | 77.9 steps/s
[Step=5400 Epoch= 5.3] | Loss=0.06449 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.729 | L2-Norm(final)=4.689 | 4770.1 samples/s | 74.5 steps/s
[Step=5450 Epoch= 5.3] | Loss=0.06385 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.746 | L2-Norm(final)=4.686 | 4732.3 samples/s | 73.9 steps/s
[Step=5500 Epoch= 5.4] | Loss=0.06323 | Reg=0.00281 | acc=0.9219 | L2-Norm=16.762 | L2-Norm(final)=4.683 | 5125.3 samples/s | 80.1 steps/s
[Step=5550 Epoch= 5.4] | Loss=0.06212 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.778 | L2-Norm(final)=4.680 | 2094.2 samples/s | 32.7 steps/s
[Step=5600 Epoch= 5.5] | Loss=0.06118 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.794 | L2-Norm(final)=4.678 | 4833.8 samples/s | 75.5 steps/s
[Step=5650 Epoch= 5.5] | Loss=0.06033 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.809 | L2-Norm(final)=4.676 | 4749.5 samples/s | 74.2 steps/s
[Step=5700 Epoch= 5.6] | Loss=0.05973 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.825 | L2-Norm(final)=4.674 | 4780.1 samples/s | 74.7 steps/s
[Step=5750 Epoch= 5.6] | Loss=0.05889 | Reg=0.00284 | acc=0.9375 | L2-Norm=16.840 | L2-Norm(final)=4.672 | 4794.5 samples/s | 74.9 steps/s
[Step=5800 Epoch= 5.7] | Loss=0.05846 | Reg=0.00284 | acc=0.9688 | L2-Norm=16.855 | L2-Norm(final)=4.671 | 4801.4 samples/s | 75.0 steps/s
[Step=5850 Epoch= 5.7] | Loss=0.05769 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.870 | L2-Norm(final)=4.670 | 4386.7 samples/s | 68.5 steps/s
[Step=5900 Epoch= 5.8] | Loss=0.05711 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.885 | L2-Norm(final)=4.668 | 4372.1 samples/s | 68.3 steps/s
[Step=5950 Epoch= 5.8] | Loss=0.05669 | Reg=0.00286 | acc=0.9531 | L2-Norm=16.899 | L2-Norm(final)=4.667 | 4368.1 samples/s | 68.3 steps/s
[Step=6000 Epoch= 5.9] | Loss=0.05592 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.913 | L2-Norm(final)=4.665 | 4356.3 samples/s | 68.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step6000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=4001 Epoch= 7.5] | Loss=0.08774 | Reg=0.00253 | acc=0.9219 | L2-Norm=15.920 | L2-Norm(final)=5.202 | 4130.9 samples/s | 64.5 steps/s
[Step=4050 Epoch= 7.6] | Loss=0.13735 | Reg=0.00253 | acc=0.9531 | L2-Norm=15.917 | L2-Norm(final)=5.049 | 5107.3 samples/s | 79.8 steps/s
[Step=4100 Epoch= 7.7] | Loss=0.09540 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.917 | L2-Norm(final)=5.078 | 5189.2 samples/s | 81.1 steps/s
[Step=4150 Epoch= 7.8] | Loss=0.07865 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=5.184 | 5246.9 samples/s | 82.0 steps/s
[Step=4200 Epoch= 7.9] | Loss=0.06959 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=5.293 | 5207.9 samples/s | 81.4 steps/s
[Step=4250 Epoch= 8.0] | Loss=0.06293 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=5.397 | 5169.0 samples/s | 80.8 steps/s
[Step=4300 Epoch= 8.1] | Loss=0.05884 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=5.495 | 5164.7 samples/s | 80.7 steps/s
[Step=4350 Epoch= 8.2] | Loss=0.05513 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=5.588 | 5136.3 samples/s | 80.3 steps/s
[Step=4400 Epoch= 8.3] | Loss=0.05225 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.917 | L2-Norm(final)=5.677 | 5319.6 samples/s | 83.1 steps/s
[Step=4450 Epoch= 8.4] | Loss=0.04987 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=5.764 | 5445.1 samples/s | 85.1 steps/s
[Step=4500 Epoch= 8.5] | Loss=0.04787 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.917 | L2-Norm(final)=5.848 | 5274.3 samples/s | 82.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.5] | Loss=0.05623 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.917 | L2-Norm(final)=6.669 | 4080.3 samples/s | 63.8 steps/s
[Step=4550 Epoch= 8.6] | Loss=0.02257 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=6.680 | 4321.3 samples/s | 67.5 steps/s
[Step=4600 Epoch= 8.7] | Loss=0.01747 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.223 | L2-Norm(final)=6.666 | 4538.0 samples/s | 70.9 steps/s
[Step=4650 Epoch= 8.8] | Loss=0.01448 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.284 | L2-Norm(final)=6.655 | 4518.3 samples/s | 70.6 steps/s
[Step=4700 Epoch= 8.9] | Loss=0.01508 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.317 | L2-Norm(final)=6.646 | 4526.7 samples/s | 70.7 steps/s
[Step=4750 Epoch= 9.0] | Loss=0.01367 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.340 | L2-Norm(final)=6.636 | 4575.8 samples/s | 71.5 steps/s
[Step=4800 Epoch= 9.0] | Loss=0.01207 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=6.629 | 4482.3 samples/s | 70.0 steps/s
[Step=4850 Epoch= 9.1] | Loss=0.01088 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=6.625 | 4617.4 samples/s | 72.1 steps/s
[Step=4900 Epoch= 9.2] | Loss=0.00973 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.334 | L2-Norm(final)=6.621 | 4513.0 samples/s | 70.5 steps/s
[Step=4950 Epoch= 9.3] | Loss=0.00892 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.321 | L2-Norm(final)=6.619 | 4570.2 samples/s | 71.4 steps/s
[Step=5000 Epoch= 9.4] | Loss=0.00807 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=6.617 | 4611.5 samples/s | 72.1 steps/s
[Step=5050 Epoch= 9.5] | Loss=0.00741 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.285 | L2-Norm(final)=6.616 | 2094.5 samples/s | 32.7 steps/s
[Step=5100 Epoch= 9.6] | Loss=0.00683 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.264 | L2-Norm(final)=6.615 | 4661.2 samples/s | 72.8 steps/s
[Step=5150 Epoch= 9.7] | Loss=0.00632 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.242 | L2-Norm(final)=6.614 | 4561.0 samples/s | 71.3 steps/s
[Step=5200 Epoch= 9.8] | Loss=0.00588 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.218 | L2-Norm(final)=6.614 | 4521.6 samples/s | 70.7 steps/s
[Step=5250 Epoch= 9.9] | Loss=0.00549 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.193 | L2-Norm(final)=6.614 | 4515.4 samples/s | 70.6 steps/s
[Step=5300 Epoch=10.0] | Loss=0.00515 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=6.614 | 4643.2 samples/s | 72.6 steps/s
[Step=5350 Epoch=10.1] | Loss=0.00485 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=6.613 | 4779.7 samples/s | 74.7 steps/s
[Step=5400 Epoch=10.2] | Loss=0.00458 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=6.613 | 4587.7 samples/s | 71.7 steps/s
[Step=5450 Epoch=10.3] | Loss=0.00434 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=6.614 | 4671.3 samples/s | 73.0 steps/s
[Step=5500 Epoch=10.4] | Loss=0.00413 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.055 | L2-Norm(final)=6.614 | 4586.5 samples/s | 71.7 steps/s
[Step=5550 Epoch=10.5] | Loss=0.00393 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.025 | L2-Norm(final)=6.614 | 5647.7 samples/s | 88.2 steps/s
[Step=5600 Epoch=10.6] | Loss=0.00375 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=6.614 | 1986.5 samples/s | 31.0 steps/s
[Step=5650 Epoch=10.7] | Loss=0.00359 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=6.614 | 4652.6 samples/s | 72.7 steps/s
[Step=5700 Epoch=10.7] | Loss=0.00344 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.936 | L2-Norm(final)=6.614 | 4508.4 samples/s | 70.4 steps/s
[Step=5750 Epoch=10.8] | Loss=0.00330 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.906 | L2-Norm(final)=6.614 | 4579.5 samples/s | 71.6 steps/s
[Step=5800 Epoch=10.9] | Loss=0.00318 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.875 | L2-Norm(final)=6.615 | 4629.1 samples/s | 72.3 steps/s
[Step=5850 Epoch=11.0] | Loss=0.00306 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.845 | L2-Norm(final)=6.615 | 4519.9 samples/s | 70.6 steps/s
[Step=5900 Epoch=11.1] | Loss=0.00295 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=6.615 | 4537.5 samples/s | 70.9 steps/s
[Step=5950 Epoch=11.2] | Loss=0.00285 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=6.615 | 4537.2 samples/s | 70.9 steps/s
[Step=6000 Epoch=11.3] | Loss=0.00275 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.752 | L2-Norm(final)=6.615 | 4574.1 samples/s | 71.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05290 | acc=0.9611 | tpr=0.9669 | fpr=0.0515 | 4572.7 samples/s | 17.9 steps/s
Avg test loss: 0.05467, Avg test acc: 0.96065, Avg tpr: 0.96654, Avg fpr: 0.05230, total FA: 408

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.34339 | acc=0.3155 | tpr=0.0064 | fpr=0.0134 | 4579.7 samples/s | 17.9 steps/s
Avg test loss: 8.38301, Avg test acc: 0.31277, Avg tpr: 0.00612, Avg fpr: 0.01282, total FA: 100

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.26465 | acc=0.1609 | tpr=0.7965 | fpr=0.8505 | 4584.9 samples/s | 17.9 steps/s
[Step= 100] | Loss=3.25649 | acc=0.1626 | tpr=0.7761 | fpr=0.8488 | 8461.2 samples/s | 33.1 steps/s
[Step= 150] | Loss=3.25257 | acc=0.1625 | tpr=0.7565 | fpr=0.8484 | 8455.3 samples/s | 33.0 steps/s
[Step= 200] | Loss=3.24560 | acc=0.1627 | tpr=0.7563 | fpr=0.8481 | 8358.6 samples/s | 32.7 steps/s
[Step= 250] | Loss=3.24428 | acc=0.1631 | tpr=0.7616 | fpr=0.8478 | 8978.0 samples/s | 35.1 steps/s
[Step= 300] | Loss=3.24290 | acc=0.1629 | tpr=0.7571 | fpr=0.8480 | 8288.8 samples/s | 32.4 steps/s
[Step= 350] | Loss=3.24570 | acc=0.1620 | tpr=0.7564 | fpr=0.8488 | 8339.9 samples/s | 32.6 steps/s
[Step= 400] | Loss=3.24381 | acc=0.1621 | tpr=0.7555 | fpr=0.8486 | 8604.0 samples/s | 33.6 steps/s
[Step= 450] | Loss=3.24639 | acc=0.1620 | tpr=0.7590 | fpr=0.8489 | 8657.9 samples/s | 33.8 steps/s
[Step= 500] | Loss=3.24533 | acc=0.1619 | tpr=0.7581 | fpr=0.8488 | 8123.8 samples/s | 31.7 steps/s
[Step= 550] | Loss=3.24558 | acc=0.1621 | tpr=0.7600 | fpr=0.8488 | 16063.5 samples/s | 62.7 steps/s
Avg test loss: 3.24718, Avg test acc: 0.16186, Avg tpr: 0.75951, Avg fpr: 0.84900, total FA: 117882

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12904 | acc=0.9827 | tpr=0.9646 | fpr=0.0170 | 4622.5 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.13556 | acc=0.9817 | tpr=0.9680 | fpr=0.0180 | 8252.5 samples/s | 32.2 steps/s
[Step= 150] | Loss=0.14115 | acc=0.9806 | tpr=0.9669 | fpr=0.0192 | 8865.2 samples/s | 34.6 steps/s
[Step= 200] | Loss=0.14244 | acc=0.9806 | tpr=0.9694 | fpr=0.0192 | 8381.1 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.13995 | acc=0.9806 | tpr=0.9668 | fpr=0.0191 | 8607.0 samples/s | 33.6 steps/s
[Step= 300] | Loss=0.14213 | acc=0.9803 | tpr=0.9665 | fpr=0.0194 | 8318.3 samples/s | 32.5 steps/s
[Step= 350] | Loss=0.14291 | acc=0.9802 | tpr=0.9668 | fpr=0.0195 | 8517.4 samples/s | 33.3 steps/s
[Step= 400] | Loss=0.14445 | acc=0.9801 | tpr=0.9644 | fpr=0.0196 | 8431.0 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.14700 | acc=0.9798 | tpr=0.9640 | fpr=0.0199 | 9003.6 samples/s | 35.2 steps/s
[Step= 500] | Loss=0.14627 | acc=0.9799 | tpr=0.9652 | fpr=0.0198 | 8626.5 samples/s | 33.7 steps/s
[Step= 550] | Loss=0.14540 | acc=0.9800 | tpr=0.9634 | fpr=0.0197 | 13667.8 samples/s | 53.4 steps/s
Avg test loss: 0.14513, Avg test acc: 0.98003, Avg tpr: 0.96355, Avg fpr: 0.01967, total FA: 2731

server round 3/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=6001 Epoch= 5.9] | Loss=0.16890 | Reg=0.00235 | acc=0.8438 | L2-Norm=15.337 | L2-Norm(final)=4.618 | 4246.1 samples/s | 66.3 steps/s
[Step=6050 Epoch= 5.9] | Loss=0.12719 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.340 | L2-Norm(final)=4.672 | 5364.5 samples/s | 83.8 steps/s
[Step=6100 Epoch= 6.0] | Loss=0.12194 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.340 | L2-Norm(final)=4.758 | 5514.5 samples/s | 86.2 steps/s
[Step=6150 Epoch= 6.0] | Loss=0.11928 | Reg=0.00235 | acc=0.9531 | L2-Norm=15.340 | L2-Norm(final)=4.840 | 5409.2 samples/s | 84.5 steps/s
[Step=6200 Epoch= 6.1] | Loss=0.11793 | Reg=0.00235 | acc=0.8594 | L2-Norm=15.341 | L2-Norm(final)=4.917 | 5457.4 samples/s | 85.3 steps/s
[Step=6250 Epoch= 6.1] | Loss=0.11686 | Reg=0.00235 | acc=0.9062 | L2-Norm=15.341 | L2-Norm(final)=4.988 | 5276.1 samples/s | 82.4 steps/s
[Step=6300 Epoch= 6.2] | Loss=0.11522 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.341 | L2-Norm(final)=5.057 | 5100.4 samples/s | 79.7 steps/s
[Step=6350 Epoch= 6.2] | Loss=0.11463 | Reg=0.00235 | acc=0.8906 | L2-Norm=15.341 | L2-Norm(final)=5.121 | 5433.0 samples/s | 84.9 steps/s
[Step=6400 Epoch= 6.2] | Loss=0.11374 | Reg=0.00235 | acc=0.9062 | L2-Norm=15.341 | L2-Norm(final)=5.183 | 5388.1 samples/s | 84.2 steps/s
[Step=6450 Epoch= 6.3] | Loss=0.11288 | Reg=0.00235 | acc=0.8750 | L2-Norm=15.341 | L2-Norm(final)=5.242 | 5349.2 samples/s | 83.6 steps/s
[Step=6500 Epoch= 6.3] | Loss=0.11180 | Reg=0.00235 | acc=0.8438 | L2-Norm=15.341 | L2-Norm(final)=5.298 | 5338.3 samples/s | 83.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch= 6.3] | Loss=0.14473 | Reg=0.00235 | acc=0.8594 | L2-Norm=15.341 | L2-Norm(final)=5.852 | 4415.1 samples/s | 69.0 steps/s
[Step=6550 Epoch= 6.4] | Loss=0.08667 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.533 | L2-Norm(final)=5.858 | 4452.5 samples/s | 69.6 steps/s
[Step=6600 Epoch= 6.4] | Loss=0.07590 | Reg=0.00246 | acc=0.8906 | L2-Norm=15.677 | L2-Norm(final)=5.855 | 4750.8 samples/s | 74.2 steps/s
[Step=6650 Epoch= 6.5] | Loss=0.07192 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.772 | L2-Norm(final)=5.851 | 4716.6 samples/s | 73.7 steps/s
[Step=6700 Epoch= 6.5] | Loss=0.06692 | Reg=0.00251 | acc=0.9375 | L2-Norm=15.848 | L2-Norm(final)=5.849 | 4789.6 samples/s | 74.8 steps/s
[Step=6750 Epoch= 6.6] | Loss=0.06589 | Reg=0.00253 | acc=0.9062 | L2-Norm=15.910 | L2-Norm(final)=5.843 | 4570.8 samples/s | 71.4 steps/s
[Step=6800 Epoch= 6.6] | Loss=0.06481 | Reg=0.00255 | acc=0.9531 | L2-Norm=15.964 | L2-Norm(final)=5.839 | 4376.0 samples/s | 68.4 steps/s
[Step=6850 Epoch= 6.7] | Loss=0.06238 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.013 | L2-Norm(final)=5.835 | 4750.9 samples/s | 74.2 steps/s
[Step=6900 Epoch= 6.7] | Loss=0.06133 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.055 | L2-Norm(final)=5.829 | 4742.5 samples/s | 74.1 steps/s
[Step=6950 Epoch= 6.8] | Loss=0.06096 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.091 | L2-Norm(final)=5.823 | 4810.0 samples/s | 75.2 steps/s
[Step=7000 Epoch= 6.8] | Loss=0.05978 | Reg=0.00260 | acc=0.9375 | L2-Norm=16.125 | L2-Norm(final)=5.818 | 4719.8 samples/s | 73.7 steps/s
[Step=7050 Epoch= 6.9] | Loss=0.05942 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.157 | L2-Norm(final)=5.813 | 4802.6 samples/s | 75.0 steps/s
[Step=7100 Epoch= 6.9] | Loss=0.05862 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.187 | L2-Norm(final)=5.809 | 4724.0 samples/s | 73.8 steps/s
[Step=7150 Epoch= 7.0] | Loss=0.05768 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.217 | L2-Norm(final)=5.804 | 4829.0 samples/s | 75.5 steps/s
[Step=7200 Epoch= 7.0] | Loss=0.05747 | Reg=0.00264 | acc=0.9062 | L2-Norm=16.246 | L2-Norm(final)=5.800 | 4837.0 samples/s | 75.6 steps/s
[Step=7250 Epoch= 7.1] | Loss=0.05687 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.274 | L2-Norm(final)=5.796 | 4715.6 samples/s | 73.7 steps/s
[Step=7300 Epoch= 7.1] | Loss=0.05628 | Reg=0.00266 | acc=0.9531 | L2-Norm=16.301 | L2-Norm(final)=5.792 | 4778.9 samples/s | 74.7 steps/s
[Step=7350 Epoch= 7.2] | Loss=0.05554 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=5.788 | 4729.6 samples/s | 73.9 steps/s
[Step=7400 Epoch= 7.2] | Loss=0.05518 | Reg=0.00268 | acc=0.9531 | L2-Norm=16.352 | L2-Norm(final)=5.783 | 4702.2 samples/s | 73.5 steps/s
[Step=7450 Epoch= 7.3] | Loss=0.05443 | Reg=0.00268 | acc=0.9688 | L2-Norm=16.376 | L2-Norm(final)=5.779 | 4768.7 samples/s | 74.5 steps/s
[Step=7500 Epoch= 7.3] | Loss=0.05395 | Reg=0.00269 | acc=0.9531 | L2-Norm=16.400 | L2-Norm(final)=5.774 | 5128.9 samples/s | 80.1 steps/s
[Step=7550 Epoch= 7.4] | Loss=0.05358 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.422 | L2-Norm(final)=5.770 | 2099.5 samples/s | 32.8 steps/s
[Step=7600 Epoch= 7.4] | Loss=0.05257 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.443 | L2-Norm(final)=5.766 | 4884.6 samples/s | 76.3 steps/s
[Step=7650 Epoch= 7.5] | Loss=0.05190 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.464 | L2-Norm(final)=5.762 | 4436.4 samples/s | 69.3 steps/s
[Step=7700 Epoch= 7.5] | Loss=0.05144 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.484 | L2-Norm(final)=5.758 | 4494.6 samples/s | 70.2 steps/s
[Step=7750 Epoch= 7.6] | Loss=0.05083 | Reg=0.00273 | acc=0.9375 | L2-Norm=16.503 | L2-Norm(final)=5.754 | 4733.1 samples/s | 74.0 steps/s
[Step=7800 Epoch= 7.6] | Loss=0.05024 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.522 | L2-Norm(final)=5.750 | 4732.0 samples/s | 73.9 steps/s
[Step=7850 Epoch= 7.7] | Loss=0.05000 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.540 | L2-Norm(final)=5.746 | 4398.9 samples/s | 68.7 steps/s
[Step=7900 Epoch= 7.7] | Loss=0.04946 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.558 | L2-Norm(final)=5.742 | 4503.8 samples/s | 70.4 steps/s
[Step=7950 Epoch= 7.8] | Loss=0.04943 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.575 | L2-Norm(final)=5.738 | 4680.5 samples/s | 73.1 steps/s
[Step=8000 Epoch= 7.8] | Loss=0.04911 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.593 | L2-Norm(final)=5.734 | 4794.2 samples/s | 74.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step8000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=6001 Epoch=11.3] | Loss=0.03070 | Reg=0.00235 | acc=0.9531 | L2-Norm=15.337 | L2-Norm(final)=6.619 | 4232.6 samples/s | 66.1 steps/s
[Step=6050 Epoch=11.4] | Loss=0.02570 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.327 | L2-Norm(final)=6.586 | 4661.4 samples/s | 72.8 steps/s
[Step=6100 Epoch=11.5] | Loss=0.02075 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=6.600 | 5275.8 samples/s | 82.4 steps/s
[Step=6150 Epoch=11.6] | Loss=0.01838 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=6.642 | 5084.6 samples/s | 79.4 steps/s
[Step=6200 Epoch=11.7] | Loss=0.01689 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=6.693 | 5130.7 samples/s | 80.2 steps/s
[Step=6250 Epoch=11.8] | Loss=0.01607 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.325 | L2-Norm(final)=6.749 | 5245.9 samples/s | 82.0 steps/s
[Step=6300 Epoch=11.9] | Loss=0.01514 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.325 | L2-Norm(final)=6.806 | 5218.8 samples/s | 81.5 steps/s
[Step=6350 Epoch=12.0] | Loss=0.01463 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=6.864 | 5254.8 samples/s | 82.1 steps/s
[Step=6400 Epoch=12.1] | Loss=0.01397 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.325 | L2-Norm(final)=6.919 | 5180.6 samples/s | 80.9 steps/s
[Step=6450 Epoch=12.2] | Loss=0.01359 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=6.973 | 5177.9 samples/s | 80.9 steps/s
[Step=6500 Epoch=12.3] | Loss=0.01318 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=7.027 | 5286.9 samples/s | 82.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.3] | Loss=0.00645 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=7.560 | 4210.3 samples/s | 65.8 steps/s
[Step=6550 Epoch=12.3] | Loss=0.02168 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.495 | L2-Norm(final)=7.561 | 4464.2 samples/s | 69.8 steps/s
[Step=6600 Epoch=12.4] | Loss=0.01670 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=7.537 | 4722.4 samples/s | 73.8 steps/s
[Step=6650 Epoch=12.5] | Loss=0.01778 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.862 | L2-Norm(final)=7.515 | 4545.9 samples/s | 71.0 steps/s
[Step=6700 Epoch=12.6] | Loss=0.01680 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=7.491 | 4674.3 samples/s | 73.0 steps/s
[Step=6750 Epoch=12.7] | Loss=0.01445 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.021 | L2-Norm(final)=7.476 | 4655.7 samples/s | 72.7 steps/s
[Step=6800 Epoch=12.8] | Loss=0.01241 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.053 | L2-Norm(final)=7.466 | 4537.2 samples/s | 70.9 steps/s
[Step=6850 Epoch=12.9] | Loss=0.01125 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=7.459 | 4677.2 samples/s | 73.1 steps/s
[Step=6900 Epoch=13.0] | Loss=0.01014 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=7.454 | 4701.7 samples/s | 73.5 steps/s
[Step=6950 Epoch=13.1] | Loss=0.00919 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=7.450 | 4662.7 samples/s | 72.9 steps/s
[Step=7000 Epoch=13.2] | Loss=0.00855 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.074 | L2-Norm(final)=7.447 | 4680.8 samples/s | 73.1 steps/s
[Step=7050 Epoch=13.3] | Loss=0.00795 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=7.444 | 2154.8 samples/s | 33.7 steps/s
[Step=7100 Epoch=13.4] | Loss=0.00732 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.053 | L2-Norm(final)=7.442 | 4697.9 samples/s | 73.4 steps/s
[Step=7150 Epoch=13.5] | Loss=0.00678 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.038 | L2-Norm(final)=7.440 | 4631.4 samples/s | 72.4 steps/s
[Step=7200 Epoch=13.6] | Loss=0.00631 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.020 | L2-Norm(final)=7.439 | 4699.4 samples/s | 73.4 steps/s
[Step=7250 Epoch=13.7] | Loss=0.00591 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.001 | L2-Norm(final)=7.438 | 4621.0 samples/s | 72.2 steps/s
[Step=7300 Epoch=13.8] | Loss=0.00557 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.979 | L2-Norm(final)=7.438 | 4720.8 samples/s | 73.8 steps/s
[Step=7350 Epoch=13.9] | Loss=0.00527 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=7.437 | 4643.9 samples/s | 72.6 steps/s
[Step=7400 Epoch=13.9] | Loss=0.00499 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.934 | L2-Norm(final)=7.437 | 4589.2 samples/s | 71.7 steps/s
[Step=7450 Epoch=14.0] | Loss=0.00474 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.910 | L2-Norm(final)=7.437 | 4590.0 samples/s | 71.7 steps/s
[Step=7500 Epoch=14.1] | Loss=0.00451 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.886 | L2-Norm(final)=7.437 | 4539.8 samples/s | 70.9 steps/s
[Step=7550 Epoch=14.2] | Loss=0.00435 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.860 | L2-Norm(final)=7.438 | 5724.3 samples/s | 89.4 steps/s
[Step=7600 Epoch=14.3] | Loss=0.00418 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=7.437 | 1997.6 samples/s | 31.2 steps/s
[Step=7650 Epoch=14.4] | Loss=0.00402 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.813 | L2-Norm(final)=7.438 | 4467.2 samples/s | 69.8 steps/s
[Step=7700 Epoch=14.5] | Loss=0.00403 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.791 | L2-Norm(final)=7.437 | 4508.4 samples/s | 70.4 steps/s
[Step=7750 Epoch=14.6] | Loss=0.00399 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.772 | L2-Norm(final)=7.436 | 4517.6 samples/s | 70.6 steps/s
[Step=7800 Epoch=14.7] | Loss=0.00396 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.755 | L2-Norm(final)=7.435 | 4518.5 samples/s | 70.6 steps/s
[Step=7850 Epoch=14.8] | Loss=0.00395 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.741 | L2-Norm(final)=7.434 | 4639.4 samples/s | 72.5 steps/s
[Step=7900 Epoch=14.9] | Loss=0.00414 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.728 | L2-Norm(final)=7.431 | 4509.2 samples/s | 70.5 steps/s
[Step=7950 Epoch=15.0] | Loss=0.00420 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.717 | L2-Norm(final)=7.427 | 4537.0 samples/s | 70.9 steps/s
[Step=8000 Epoch=15.1] | Loss=0.00410 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.708 | L2-Norm(final)=7.423 | 4513.6 samples/s | 70.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.04928 | acc=0.9628 | tpr=0.9660 | fpr=0.0441 | 4604.5 samples/s | 18.0 steps/s
Avg test loss: 0.05177, Avg test acc: 0.96146, Avg tpr: 0.96456, Avg fpr: 0.04538, total FA: 354

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.49297 | acc=0.3114 | tpr=0.0055 | fpr=0.0243 | 4567.2 samples/s | 17.8 steps/s
Avg test loss: 5.50394, Avg test acc: 0.30948, Avg tpr: 0.00565, Avg fpr: 0.02230, total FA: 174

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.91307 | acc=0.1370 | tpr=0.7168 | fpr=0.8735 | 4519.3 samples/s | 17.7 steps/s
[Step= 100] | Loss=3.89253 | acc=0.1389 | tpr=0.6972 | fpr=0.8716 | 8568.5 samples/s | 33.5 steps/s
[Step= 150] | Loss=3.88482 | acc=0.1386 | tpr=0.6888 | fpr=0.8715 | 8469.4 samples/s | 33.1 steps/s
[Step= 200] | Loss=3.87812 | acc=0.1393 | tpr=0.6885 | fpr=0.8707 | 8633.1 samples/s | 33.7 steps/s
[Step= 250] | Loss=3.87844 | acc=0.1393 | tpr=0.7031 | fpr=0.8710 | 8366.2 samples/s | 32.7 steps/s
[Step= 300] | Loss=3.87556 | acc=0.1393 | tpr=0.7084 | fpr=0.8711 | 8394.1 samples/s | 32.8 steps/s
[Step= 350] | Loss=3.87761 | acc=0.1392 | tpr=0.7063 | fpr=0.8711 | 8511.8 samples/s | 33.2 steps/s
[Step= 400] | Loss=3.87977 | acc=0.1394 | tpr=0.7112 | fpr=0.8710 | 8304.4 samples/s | 32.4 steps/s
[Step= 450] | Loss=3.88165 | acc=0.1394 | tpr=0.7128 | fpr=0.8710 | 8876.6 samples/s | 34.7 steps/s
[Step= 500] | Loss=3.87955 | acc=0.1397 | tpr=0.7106 | fpr=0.8706 | 7994.6 samples/s | 31.2 steps/s
[Step= 550] | Loss=3.88062 | acc=0.1398 | tpr=0.7095 | fpr=0.8706 | 15493.0 samples/s | 60.5 steps/s
Avg test loss: 3.88225, Avg test acc: 0.13965, Avg tpr: 0.70959, Avg fpr: 0.87071, total FA: 120896

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08071 | acc=0.9813 | tpr=0.9425 | fpr=0.0180 | 4589.6 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.08551 | acc=0.9803 | tpr=0.9510 | fpr=0.0191 | 8314.4 samples/s | 32.5 steps/s
[Step= 150] | Loss=0.08889 | acc=0.9800 | tpr=0.9524 | fpr=0.0195 | 8724.6 samples/s | 34.1 steps/s
[Step= 200] | Loss=0.08990 | acc=0.9801 | tpr=0.9563 | fpr=0.0194 | 8575.4 samples/s | 33.5 steps/s
[Step= 250] | Loss=0.08873 | acc=0.9804 | tpr=0.9563 | fpr=0.0192 | 8444.9 samples/s | 33.0 steps/s
[Step= 300] | Loss=0.09040 | acc=0.9800 | tpr=0.9542 | fpr=0.0195 | 8523.5 samples/s | 33.3 steps/s
[Step= 350] | Loss=0.09064 | acc=0.9799 | tpr=0.9555 | fpr=0.0197 | 8560.0 samples/s | 33.4 steps/s
[Step= 400] | Loss=0.09161 | acc=0.9797 | tpr=0.9562 | fpr=0.0199 | 8916.2 samples/s | 34.8 steps/s
[Step= 450] | Loss=0.09370 | acc=0.9794 | tpr=0.9547 | fpr=0.0202 | 8168.1 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.09313 | acc=0.9795 | tpr=0.9559 | fpr=0.0201 | 8349.1 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.09267 | acc=0.9795 | tpr=0.9534 | fpr=0.0200 | 15234.8 samples/s | 59.5 steps/s
Avg test loss: 0.09248, Avg test acc: 0.97951, Avg tpr: 0.95285, Avg fpr: 0.02001, total FA: 2778

server round 4/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=8001 Epoch= 7.8] | Loss=0.15296 | Reg=0.00234 | acc=0.8594 | L2-Norm=15.299 | L2-Norm(final)=5.612 | 4104.7 samples/s | 64.1 steps/s
[Step=8050 Epoch= 7.9] | Loss=0.15637 | Reg=0.00234 | acc=0.8906 | L2-Norm=15.307 | L2-Norm(final)=5.671 | 5180.6 samples/s | 80.9 steps/s
[Step=8100 Epoch= 7.9] | Loss=0.15223 | Reg=0.00234 | acc=0.9219 | L2-Norm=15.309 | L2-Norm(final)=5.771 | 4996.2 samples/s | 78.1 steps/s
[Step=8150 Epoch= 8.0] | Loss=0.15076 | Reg=0.00234 | acc=0.8594 | L2-Norm=15.309 | L2-Norm(final)=5.869 | 4903.4 samples/s | 76.6 steps/s
[Step=8200 Epoch= 8.0] | Loss=0.14793 | Reg=0.00234 | acc=0.9062 | L2-Norm=15.309 | L2-Norm(final)=5.966 | 5276.8 samples/s | 82.5 steps/s
[Step=8250 Epoch= 8.1] | Loss=0.14639 | Reg=0.00234 | acc=0.8750 | L2-Norm=15.310 | L2-Norm(final)=6.058 | 5433.7 samples/s | 84.9 steps/s
[Step=8300 Epoch= 8.1] | Loss=0.14519 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.310 | L2-Norm(final)=6.146 | 5492.2 samples/s | 85.8 steps/s
[Step=8350 Epoch= 8.2] | Loss=0.14386 | Reg=0.00234 | acc=0.8906 | L2-Norm=15.310 | L2-Norm(final)=6.229 | 5516.2 samples/s | 86.2 steps/s
[Step=8400 Epoch= 8.2] | Loss=0.14170 | Reg=0.00234 | acc=0.8438 | L2-Norm=15.310 | L2-Norm(final)=6.309 | 5468.2 samples/s | 85.4 steps/s
[Step=8450 Epoch= 8.3] | Loss=0.14005 | Reg=0.00234 | acc=0.8906 | L2-Norm=15.310 | L2-Norm(final)=6.385 | 5407.2 samples/s | 84.5 steps/s
[Step=8500 Epoch= 8.3] | Loss=0.13958 | Reg=0.00234 | acc=0.8438 | L2-Norm=15.310 | L2-Norm(final)=6.459 | 5358.3 samples/s | 83.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch= 8.3] | Loss=0.09475 | Reg=0.00234 | acc=0.9375 | L2-Norm=15.310 | L2-Norm(final)=7.175 | 4355.1 samples/s | 68.0 steps/s
[Step=8550 Epoch= 8.3] | Loss=0.08877 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.502 | L2-Norm(final)=7.188 | 4328.8 samples/s | 67.6 steps/s
[Step=8600 Epoch= 8.4] | Loss=0.08196 | Reg=0.00244 | acc=0.9375 | L2-Norm=15.635 | L2-Norm(final)=7.174 | 4461.3 samples/s | 69.7 steps/s
[Step=8650 Epoch= 8.4] | Loss=0.07446 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.718 | L2-Norm(final)=7.162 | 4476.4 samples/s | 69.9 steps/s
[Step=8700 Epoch= 8.5] | Loss=0.07198 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.783 | L2-Norm(final)=7.151 | 4761.5 samples/s | 74.4 steps/s
[Step=8750 Epoch= 8.5] | Loss=0.06797 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.841 | L2-Norm(final)=7.141 | 4877.2 samples/s | 76.2 steps/s
[Step=8800 Epoch= 8.6] | Loss=0.06530 | Reg=0.00253 | acc=0.9375 | L2-Norm=15.890 | L2-Norm(final)=7.134 | 4823.0 samples/s | 75.4 steps/s
[Step=8850 Epoch= 8.6] | Loss=0.06458 | Reg=0.00254 | acc=0.9375 | L2-Norm=15.936 | L2-Norm(final)=7.125 | 4874.9 samples/s | 76.2 steps/s
[Step=8900 Epoch= 8.7] | Loss=0.06279 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.980 | L2-Norm(final)=7.116 | 4696.1 samples/s | 73.4 steps/s
[Step=8950 Epoch= 8.7] | Loss=0.06084 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.020 | L2-Norm(final)=7.107 | 4736.0 samples/s | 74.0 steps/s
[Step=9000 Epoch= 8.8] | Loss=0.05981 | Reg=0.00258 | acc=0.9531 | L2-Norm=16.057 | L2-Norm(final)=7.100 | 4883.8 samples/s | 76.3 steps/s
[Step=9050 Epoch= 8.8] | Loss=0.05863 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.091 | L2-Norm(final)=7.093 | 4903.9 samples/s | 76.6 steps/s
[Step=9100 Epoch= 8.9] | Loss=0.05775 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=7.086 | 4947.9 samples/s | 77.3 steps/s
[Step=9150 Epoch= 8.9] | Loss=0.05685 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.156 | L2-Norm(final)=7.079 | 4885.1 samples/s | 76.3 steps/s
[Step=9200 Epoch= 9.0] | Loss=0.05589 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.185 | L2-Norm(final)=7.073 | 4847.0 samples/s | 75.7 steps/s
[Step=9250 Epoch= 9.0] | Loss=0.05536 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.214 | L2-Norm(final)=7.066 | 4806.4 samples/s | 75.1 steps/s
[Step=9300 Epoch= 9.1] | Loss=0.05492 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.242 | L2-Norm(final)=7.060 | 4828.5 samples/s | 75.4 steps/s
[Step=9350 Epoch= 9.1] | Loss=0.05436 | Reg=0.00265 | acc=0.9219 | L2-Norm=16.268 | L2-Norm(final)=7.054 | 4939.9 samples/s | 77.2 steps/s
[Step=9400 Epoch= 9.2] | Loss=0.05353 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.294 | L2-Norm(final)=7.048 | 4948.9 samples/s | 77.3 steps/s
[Step=9450 Epoch= 9.2] | Loss=0.05292 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.320 | L2-Norm(final)=7.042 | 4801.2 samples/s | 75.0 steps/s
[Step=9500 Epoch= 9.3] | Loss=0.05245 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.344 | L2-Norm(final)=7.037 | 5070.4 samples/s | 79.2 steps/s
[Step=9550 Epoch= 9.3] | Loss=0.05156 | Reg=0.00268 | acc=0.9688 | L2-Norm=16.368 | L2-Norm(final)=7.032 | 2127.7 samples/s | 33.2 steps/s
[Step=9600 Epoch= 9.4] | Loss=0.05112 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.392 | L2-Norm(final)=7.027 | 4786.2 samples/s | 74.8 steps/s
[Step=9650 Epoch= 9.4] | Loss=0.05032 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.415 | L2-Norm(final)=7.023 | 4751.7 samples/s | 74.2 steps/s
[Step=9700 Epoch= 9.5] | Loss=0.04960 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.438 | L2-Norm(final)=7.019 | 4714.2 samples/s | 73.7 steps/s
[Step=9750 Epoch= 9.5] | Loss=0.04879 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.460 | L2-Norm(final)=7.015 | 4483.4 samples/s | 70.1 steps/s
[Step=9800 Epoch= 9.6] | Loss=0.04793 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.482 | L2-Norm(final)=7.012 | 4514.5 samples/s | 70.5 steps/s
[Step=9850 Epoch= 9.6] | Loss=0.04753 | Reg=0.00273 | acc=0.9531 | L2-Norm=16.504 | L2-Norm(final)=7.009 | 4664.7 samples/s | 72.9 steps/s
[Step=9900 Epoch= 9.7] | Loss=0.04728 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.525 | L2-Norm(final)=7.005 | 4790.5 samples/s | 74.9 steps/s
[Step=9950 Epoch= 9.7] | Loss=0.04688 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.546 | L2-Norm(final)=7.002 | 4736.7 samples/s | 74.0 steps/s
[Step=10000 Epoch= 9.8] | Loss=0.04639 | Reg=0.00275 | acc=0.9375 | L2-Norm=16.567 | L2-Norm(final)=6.998 | 4437.6 samples/s | 69.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step10000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=8001 Epoch=15.1] | Loss=0.07086 | Reg=0.00234 | acc=0.9375 | L2-Norm=15.299 | L2-Norm(final)=7.304 | 4112.0 samples/s | 64.3 steps/s
[Step=8050 Epoch=15.2] | Loss=0.05055 | Reg=0.00234 | acc=0.9375 | L2-Norm=15.294 | L2-Norm(final)=7.325 | 5102.1 samples/s | 79.7 steps/s
[Step=8100 Epoch=15.3] | Loss=0.04188 | Reg=0.00234 | acc=0.9531 | L2-Norm=15.294 | L2-Norm(final)=7.386 | 5343.2 samples/s | 83.5 steps/s
[Step=8150 Epoch=15.4] | Loss=0.03641 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=7.475 | 5307.5 samples/s | 82.9 steps/s
[Step=8200 Epoch=15.5] | Loss=0.03389 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=7.580 | 5274.0 samples/s | 82.4 steps/s
[Step=8250 Epoch=15.6] | Loss=0.03235 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=7.690 | 5441.6 samples/s | 85.0 steps/s
[Step=8300 Epoch=15.6] | Loss=0.03101 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.293 | L2-Norm(final)=7.798 | 5245.5 samples/s | 82.0 steps/s
[Step=8350 Epoch=15.7] | Loss=0.02973 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=7.903 | 5361.2 samples/s | 83.8 steps/s
[Step=8400 Epoch=15.8] | Loss=0.02843 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=8.006 | 5392.4 samples/s | 84.3 steps/s
[Step=8450 Epoch=15.9] | Loss=0.02771 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.293 | L2-Norm(final)=8.109 | 5338.4 samples/s | 83.4 steps/s
[Step=8500 Epoch=16.0] | Loss=0.02679 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=8.209 | 5097.6 samples/s | 79.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.0] | Loss=0.01660 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=9.202 | 4110.8 samples/s | 64.2 steps/s
[Step=8550 Epoch=16.1] | Loss=0.00860 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=9.234 | 4388.4 samples/s | 68.6 steps/s
[Step=8600 Epoch=16.2] | Loss=0.00728 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.457 | L2-Norm(final)=9.226 | 4665.5 samples/s | 72.9 steps/s
[Step=8650 Epoch=16.3] | Loss=0.00665 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.499 | L2-Norm(final)=9.218 | 4657.4 samples/s | 72.8 steps/s
[Step=8700 Epoch=16.4] | Loss=0.00675 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.518 | L2-Norm(final)=9.211 | 4734.7 samples/s | 74.0 steps/s
[Step=8750 Epoch=16.5] | Loss=0.00671 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=9.203 | 4506.9 samples/s | 70.4 steps/s
[Step=8800 Epoch=16.6] | Loss=0.00651 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=9.194 | 4593.5 samples/s | 71.8 steps/s
[Step=8850 Epoch=16.7] | Loss=0.00627 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=9.185 | 4595.5 samples/s | 71.8 steps/s
[Step=8900 Epoch=16.8] | Loss=0.00611 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=9.177 | 4630.2 samples/s | 72.3 steps/s
[Step=8950 Epoch=16.9] | Loss=0.00617 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=9.170 | 4646.1 samples/s | 72.6 steps/s
[Step=9000 Epoch=17.0] | Loss=0.00586 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.595 | L2-Norm(final)=9.161 | 4750.5 samples/s | 74.2 steps/s
[Step=9050 Epoch=17.1] | Loss=0.00555 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.598 | L2-Norm(final)=9.153 | 2118.1 samples/s | 33.1 steps/s
[Step=9100 Epoch=17.2] | Loss=0.00518 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.597 | L2-Norm(final)=9.146 | 4660.5 samples/s | 72.8 steps/s
[Step=9150 Epoch=17.2] | Loss=0.00479 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=9.140 | 4523.9 samples/s | 70.7 steps/s
[Step=9200 Epoch=17.3] | Loss=0.00445 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=9.135 | 4651.8 samples/s | 72.7 steps/s
[Step=9250 Epoch=17.4] | Loss=0.00417 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.572 | L2-Norm(final)=9.131 | 4452.9 samples/s | 69.6 steps/s
[Step=9300 Epoch=17.5] | Loss=0.00391 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.557 | L2-Norm(final)=9.128 | 4552.1 samples/s | 71.1 steps/s
[Step=9350 Epoch=17.6] | Loss=0.00369 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=9.125 | 4566.0 samples/s | 71.3 steps/s
[Step=9400 Epoch=17.7] | Loss=0.00349 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.523 | L2-Norm(final)=9.123 | 4489.4 samples/s | 70.1 steps/s
[Step=9450 Epoch=17.8] | Loss=0.00331 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=9.121 | 4530.5 samples/s | 70.8 steps/s
[Step=9500 Epoch=17.9] | Loss=0.00314 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.484 | L2-Norm(final)=9.119 | 4622.3 samples/s | 72.2 steps/s
[Step=9550 Epoch=18.0] | Loss=0.00300 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.463 | L2-Norm(final)=9.117 | 5632.5 samples/s | 88.0 steps/s
[Step=9600 Epoch=18.1] | Loss=0.00286 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.441 | L2-Norm(final)=9.116 | 1984.7 samples/s | 31.0 steps/s
[Step=9650 Epoch=18.2] | Loss=0.00274 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.418 | L2-Norm(final)=9.114 | 4607.3 samples/s | 72.0 steps/s
[Step=9700 Epoch=18.3] | Loss=0.00264 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=9.113 | 4653.6 samples/s | 72.7 steps/s
[Step=9750 Epoch=18.4] | Loss=0.00285 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=9.111 | 4727.5 samples/s | 73.9 steps/s
[Step=9800 Epoch=18.5] | Loss=0.00294 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.359 | L2-Norm(final)=9.108 | 4563.2 samples/s | 71.3 steps/s
[Step=9850 Epoch=18.6] | Loss=0.00306 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.345 | L2-Norm(final)=9.104 | 4652.5 samples/s | 72.7 steps/s
[Step=9900 Epoch=18.7] | Loss=0.00305 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=9.099 | 4681.0 samples/s | 73.1 steps/s
[Step=9950 Epoch=18.8] | Loss=0.00305 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.323 | L2-Norm(final)=9.094 | 4581.8 samples/s | 71.6 steps/s
[Step=10000 Epoch=18.9] | Loss=0.00300 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.312 | L2-Norm(final)=9.090 | 4586.3 samples/s | 71.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05432 | acc=0.9672 | tpr=0.9830 | fpr=0.0671 | 4540.6 samples/s | 17.7 steps/s
Avg test loss: 0.05856, Avg test acc: 0.96414, Avg tpr: 0.98112, Avg fpr: 0.07320, total FA: 571

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.43654 | acc=0.3127 | tpr=0.0161 | fpr=0.0431 | 4652.0 samples/s | 18.2 steps/s
Avg test loss: 6.44152, Avg test acc: 0.30992, Avg tpr: 0.01603, Avg fpr: 0.04371, total FA: 341

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.43949 | acc=0.1229 | tpr=0.7920 | fpr=0.8891 | 4611.5 samples/s | 18.0 steps/s
[Step= 100] | Loss=4.41093 | acc=0.1223 | tpr=0.8038 | fpr=0.8904 | 8681.0 samples/s | 33.9 steps/s
[Step= 150] | Loss=4.40264 | acc=0.1221 | tpr=0.7968 | fpr=0.8903 | 8470.8 samples/s | 33.1 steps/s
[Step= 200] | Loss=4.39760 | acc=0.1220 | tpr=0.7934 | fpr=0.8902 | 8552.5 samples/s | 33.4 steps/s
[Step= 250] | Loss=4.39380 | acc=0.1222 | tpr=0.7921 | fpr=0.8900 | 8488.3 samples/s | 33.2 steps/s
[Step= 300] | Loss=4.39223 | acc=0.1220 | tpr=0.7978 | fpr=0.8903 | 9110.5 samples/s | 35.6 steps/s
[Step= 350] | Loss=4.39394 | acc=0.1212 | tpr=0.7952 | fpr=0.8910 | 8063.4 samples/s | 31.5 steps/s
[Step= 400] | Loss=4.39241 | acc=0.1216 | tpr=0.7981 | fpr=0.8907 | 8358.3 samples/s | 32.6 steps/s
[Step= 450] | Loss=4.39365 | acc=0.1217 | tpr=0.7989 | fpr=0.8906 | 8955.1 samples/s | 35.0 steps/s
[Step= 500] | Loss=4.39036 | acc=0.1222 | tpr=0.7987 | fpr=0.8900 | 8349.3 samples/s | 32.6 steps/s
[Step= 550] | Loss=4.39121 | acc=0.1223 | tpr=0.7971 | fpr=0.8900 | 13993.1 samples/s | 54.7 steps/s
Avg test loss: 4.39247, Avg test acc: 0.12210, Avg tpr: 0.79635, Avg fpr: 0.89016, total FA: 123597

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09498 | acc=0.9812 | tpr=0.9646 | fpr=0.0185 | 4643.9 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.10448 | acc=0.9799 | tpr=0.9723 | fpr=0.0200 | 8212.9 samples/s | 32.1 steps/s
[Step= 150] | Loss=0.10650 | acc=0.9789 | tpr=0.9712 | fpr=0.0209 | 8467.7 samples/s | 33.1 steps/s
[Step= 200] | Loss=0.10657 | acc=0.9790 | tpr=0.9749 | fpr=0.0210 | 8676.8 samples/s | 33.9 steps/s
[Step= 250] | Loss=0.10483 | acc=0.9792 | tpr=0.9712 | fpr=0.0207 | 8454.5 samples/s | 33.0 steps/s
[Step= 300] | Loss=0.10571 | acc=0.9790 | tpr=0.9724 | fpr=0.0209 | 8860.0 samples/s | 34.6 steps/s
[Step= 350] | Loss=0.10623 | acc=0.9788 | tpr=0.9706 | fpr=0.0210 | 8440.9 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.10738 | acc=0.9786 | tpr=0.9672 | fpr=0.0212 | 8558.0 samples/s | 33.4 steps/s
[Step= 450] | Loss=0.11009 | acc=0.9782 | tpr=0.9645 | fpr=0.0216 | 8445.6 samples/s | 33.0 steps/s
[Step= 500] | Loss=0.10916 | acc=0.9784 | tpr=0.9652 | fpr=0.0214 | 8441.5 samples/s | 33.0 steps/s
[Step= 550] | Loss=0.10864 | acc=0.9784 | tpr=0.9642 | fpr=0.0213 | 16097.4 samples/s | 62.9 steps/s
Avg test loss: 0.10856, Avg test acc: 0.97843, Avg tpr: 0.96395, Avg fpr: 0.02130, total FA: 2958

server round 5/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=10001 Epoch= 9.8] | Loss=0.15136 | Reg=0.00230 | acc=0.8906 | L2-Norm=15.182 | L2-Norm(final)=6.890 | 4138.6 samples/s | 64.7 steps/s
[Step=10050 Epoch= 9.8] | Loss=0.12761 | Reg=0.00231 | acc=0.9375 | L2-Norm=15.187 | L2-Norm(final)=6.909 | 5626.4 samples/s | 87.9 steps/s
[Step=10100 Epoch= 9.9] | Loss=0.12620 | Reg=0.00231 | acc=0.9219 | L2-Norm=15.189 | L2-Norm(final)=6.967 | 5676.8 samples/s | 88.7 steps/s
[Step=10150 Epoch= 9.9] | Loss=0.12509 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.189 | L2-Norm(final)=7.034 | 5653.4 samples/s | 88.3 steps/s
[Step=10200 Epoch=10.0] | Loss=0.12301 | Reg=0.00231 | acc=0.8750 | L2-Norm=15.189 | L2-Norm(final)=7.098 | 5677.4 samples/s | 88.7 steps/s
[Step=10250 Epoch=10.0] | Loss=0.12149 | Reg=0.00231 | acc=0.9531 | L2-Norm=15.189 | L2-Norm(final)=7.160 | 5656.2 samples/s | 88.4 steps/s
[Step=10300 Epoch=10.1] | Loss=0.12169 | Reg=0.00231 | acc=0.8750 | L2-Norm=15.189 | L2-Norm(final)=7.219 | 5684.0 samples/s | 88.8 steps/s
[Step=10350 Epoch=10.1] | Loss=0.12119 | Reg=0.00231 | acc=0.8750 | L2-Norm=15.189 | L2-Norm(final)=7.275 | 5584.9 samples/s | 87.3 steps/s
[Step=10400 Epoch=10.2] | Loss=0.12067 | Reg=0.00231 | acc=0.9219 | L2-Norm=15.190 | L2-Norm(final)=7.333 | 5501.4 samples/s | 86.0 steps/s
[Step=10450 Epoch=10.2] | Loss=0.11983 | Reg=0.00231 | acc=0.9219 | L2-Norm=15.190 | L2-Norm(final)=7.389 | 5557.0 samples/s | 86.8 steps/s
[Step=10500 Epoch=10.3] | Loss=0.11901 | Reg=0.00231 | acc=0.9375 | L2-Norm=15.190 | L2-Norm(final)=7.445 | 5537.2 samples/s | 86.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=10.3] | Loss=0.12100 | Reg=0.00231 | acc=0.8906 | L2-Norm=15.190 | L2-Norm(final)=8.001 | 4057.6 samples/s | 63.4 steps/s
[Step=10550 Epoch=10.3] | Loss=0.07496 | Reg=0.00236 | acc=0.9375 | L2-Norm=15.371 | L2-Norm(final)=8.019 | 4520.0 samples/s | 70.6 steps/s
[Step=10600 Epoch=10.3] | Loss=0.06809 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.528 | L2-Norm(final)=8.014 | 4336.7 samples/s | 67.8 steps/s
[Step=10650 Epoch=10.4] | Loss=0.06431 | Reg=0.00245 | acc=0.9375 | L2-Norm=15.641 | L2-Norm(final)=8.005 | 4404.7 samples/s | 68.8 steps/s
[Step=10700 Epoch=10.4] | Loss=0.06139 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.728 | L2-Norm(final)=7.994 | 4433.5 samples/s | 69.3 steps/s
[Step=10750 Epoch=10.5] | Loss=0.05816 | Reg=0.00250 | acc=0.9531 | L2-Norm=15.797 | L2-Norm(final)=7.984 | 4457.0 samples/s | 69.6 steps/s
[Step=10800 Epoch=10.5] | Loss=0.05727 | Reg=0.00252 | acc=0.9375 | L2-Norm=15.858 | L2-Norm(final)=7.974 | 4855.1 samples/s | 75.9 steps/s
[Step=10850 Epoch=10.6] | Loss=0.05624 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.913 | L2-Norm(final)=7.965 | 4770.4 samples/s | 74.5 steps/s
[Step=10900 Epoch=10.6] | Loss=0.05539 | Reg=0.00255 | acc=0.9375 | L2-Norm=15.962 | L2-Norm(final)=7.957 | 4626.2 samples/s | 72.3 steps/s
[Step=10950 Epoch=10.7] | Loss=0.05451 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.006 | L2-Norm(final)=7.949 | 4557.8 samples/s | 71.2 steps/s
[Step=11000 Epoch=10.7] | Loss=0.05400 | Reg=0.00258 | acc=0.9219 | L2-Norm=16.046 | L2-Norm(final)=7.942 | 4816.9 samples/s | 75.3 steps/s
[Step=11050 Epoch=10.8] | Loss=0.05323 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.084 | L2-Norm(final)=7.934 | 4790.4 samples/s | 74.9 steps/s
[Step=11100 Epoch=10.8] | Loss=0.05241 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.121 | L2-Norm(final)=7.927 | 4910.8 samples/s | 76.7 steps/s
[Step=11150 Epoch=10.9] | Loss=0.05197 | Reg=0.00261 | acc=0.9531 | L2-Norm=16.155 | L2-Norm(final)=7.920 | 4791.1 samples/s | 74.9 steps/s
[Step=11200 Epoch=10.9] | Loss=0.05136 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.188 | L2-Norm(final)=7.913 | 4709.4 samples/s | 73.6 steps/s
[Step=11250 Epoch=11.0] | Loss=0.05060 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.219 | L2-Norm(final)=7.908 | 4372.1 samples/s | 68.3 steps/s
[Step=11300 Epoch=11.0] | Loss=0.05010 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.248 | L2-Norm(final)=7.902 | 4841.4 samples/s | 75.6 steps/s
[Step=11350 Epoch=11.1] | Loss=0.04966 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.277 | L2-Norm(final)=7.897 | 4595.8 samples/s | 71.8 steps/s
[Step=11400 Epoch=11.1] | Loss=0.04880 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=7.892 | 4538.6 samples/s | 70.9 steps/s
[Step=11450 Epoch=11.2] | Loss=0.04830 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.331 | L2-Norm(final)=7.887 | 4882.1 samples/s | 76.3 steps/s
[Step=11500 Epoch=11.2] | Loss=0.04767 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.356 | L2-Norm(final)=7.882 | 4728.8 samples/s | 73.9 steps/s
[Step=11550 Epoch=11.3] | Loss=0.04747 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.381 | L2-Norm(final)=7.877 | 2188.4 samples/s | 34.2 steps/s
[Step=11600 Epoch=11.3] | Loss=0.04663 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=7.872 | 4686.6 samples/s | 73.2 steps/s
[Step=11650 Epoch=11.4] | Loss=0.04615 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.429 | L2-Norm(final)=7.867 | 4717.9 samples/s | 73.7 steps/s
[Step=11700 Epoch=11.4] | Loss=0.04551 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.452 | L2-Norm(final)=7.863 | 4343.8 samples/s | 67.9 steps/s
[Step=11750 Epoch=11.5] | Loss=0.04491 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.475 | L2-Norm(final)=7.858 | 4743.3 samples/s | 74.1 steps/s
[Step=11800 Epoch=11.5] | Loss=0.04426 | Reg=0.00272 | acc=0.9531 | L2-Norm=16.497 | L2-Norm(final)=7.854 | 4832.1 samples/s | 75.5 steps/s
[Step=11850 Epoch=11.6] | Loss=0.04383 | Reg=0.00273 | acc=0.9375 | L2-Norm=16.518 | L2-Norm(final)=7.851 | 4842.2 samples/s | 75.7 steps/s
[Step=11900 Epoch=11.6] | Loss=0.04331 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=7.847 | 4678.0 samples/s | 73.1 steps/s
[Step=11950 Epoch=11.7] | Loss=0.04300 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.559 | L2-Norm(final)=7.844 | 4378.7 samples/s | 68.4 steps/s
[Step=12000 Epoch=11.7] | Loss=0.04275 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.579 | L2-Norm(final)=7.840 | 4784.3 samples/s | 74.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step12000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=10001 Epoch=18.9] | Loss=0.04534 | Reg=0.00230 | acc=0.9375 | L2-Norm=15.182 | L2-Norm(final)=8.962 | 4026.0 samples/s | 62.9 steps/s
[Step=10050 Epoch=18.9] | Loss=0.01240 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.016 | 5026.0 samples/s | 78.5 steps/s
[Step=10100 Epoch=19.0] | Loss=0.01076 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.094 | 5123.8 samples/s | 80.1 steps/s
[Step=10150 Epoch=19.1] | Loss=0.01112 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.166 | 5193.0 samples/s | 81.1 steps/s
[Step=10200 Epoch=19.2] | Loss=0.01068 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.235 | 5472.9 samples/s | 85.5 steps/s
[Step=10250 Epoch=19.3] | Loss=0.01037 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.302 | 5118.1 samples/s | 80.0 steps/s
[Step=10300 Epoch=19.4] | Loss=0.00980 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.366 | 5452.0 samples/s | 85.2 steps/s
[Step=10350 Epoch=19.5] | Loss=0.00956 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.425 | 5193.7 samples/s | 81.2 steps/s
[Step=10400 Epoch=19.6] | Loss=0.00937 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.177 | L2-Norm(final)=9.483 | 5162.1 samples/s | 80.7 steps/s
[Step=10450 Epoch=19.7] | Loss=0.00916 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.177 | L2-Norm(final)=9.538 | 5274.6 samples/s | 82.4 steps/s
[Step=10500 Epoch=19.8] | Loss=0.00900 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=9.592 | 5263.7 samples/s | 82.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=19.8] | Loss=0.01285 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.177 | L2-Norm(final)=10.130 | 4230.7 samples/s | 66.1 steps/s
[Step=10550 Epoch=19.9] | Loss=0.00274 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.217 | L2-Norm(final)=10.155 | 4357.6 samples/s | 68.1 steps/s
[Step=10600 Epoch=20.0] | Loss=0.00525 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.281 | L2-Norm(final)=10.150 | 4551.3 samples/s | 71.1 steps/s
[Step=10650 Epoch=20.1] | Loss=0.00724 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=10.129 | 4560.8 samples/s | 71.3 steps/s
[Step=10700 Epoch=20.2] | Loss=0.00767 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.421 | L2-Norm(final)=10.108 | 4516.9 samples/s | 70.6 steps/s
[Step=10750 Epoch=20.3] | Loss=0.00853 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.483 | L2-Norm(final)=10.089 | 4571.9 samples/s | 71.4 steps/s
[Step=10800 Epoch=20.4] | Loss=0.00759 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.528 | L2-Norm(final)=10.072 | 4601.5 samples/s | 71.9 steps/s
[Step=10850 Epoch=20.5] | Loss=0.00668 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.553 | L2-Norm(final)=10.060 | 4525.7 samples/s | 70.7 steps/s
[Step=10900 Epoch=20.5] | Loss=0.00611 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.565 | L2-Norm(final)=10.051 | 4578.2 samples/s | 71.5 steps/s
[Step=10950 Epoch=20.6] | Loss=0.00564 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.568 | L2-Norm(final)=10.044 | 4530.6 samples/s | 70.8 steps/s
[Step=11000 Epoch=20.7] | Loss=0.00542 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.568 | L2-Norm(final)=10.037 | 4659.4 samples/s | 72.8 steps/s
[Step=11050 Epoch=20.8] | Loss=0.00513 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.567 | L2-Norm(final)=10.031 | 2158.4 samples/s | 33.7 steps/s
[Step=11100 Epoch=20.9] | Loss=0.00473 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=10.025 | 4578.1 samples/s | 71.5 steps/s
[Step=11150 Epoch=21.0] | Loss=0.00441 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=10.021 | 4530.7 samples/s | 70.8 steps/s
[Step=11200 Epoch=21.1] | Loss=0.00456 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.552 | L2-Norm(final)=10.016 | 4617.9 samples/s | 72.2 steps/s
[Step=11250 Epoch=21.2] | Loss=0.00449 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=10.010 | 4469.6 samples/s | 69.8 steps/s
[Step=11300 Epoch=21.3] | Loss=0.00423 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.538 | L2-Norm(final)=10.005 | 4608.3 samples/s | 72.0 steps/s
[Step=11350 Epoch=21.4] | Loss=0.00402 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.529 | L2-Norm(final)=10.001 | 4527.5 samples/s | 70.7 steps/s
[Step=11400 Epoch=21.5] | Loss=0.00384 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.519 | L2-Norm(final)=9.997 | 4529.9 samples/s | 70.8 steps/s
[Step=11450 Epoch=21.6] | Loss=0.00364 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.508 | L2-Norm(final)=9.993 | 4526.3 samples/s | 70.7 steps/s
[Step=11500 Epoch=21.7] | Loss=0.00348 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=9.990 | 4525.8 samples/s | 70.7 steps/s
[Step=11550 Epoch=21.8] | Loss=0.00332 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=9.987 | 5678.3 samples/s | 88.7 steps/s
[Step=11600 Epoch=21.9] | Loss=0.00320 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.468 | L2-Norm(final)=9.985 | 1965.0 samples/s | 30.7 steps/s
[Step=11650 Epoch=22.0] | Loss=0.00307 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=9.982 | 4623.0 samples/s | 72.2 steps/s
[Step=11700 Epoch=22.1] | Loss=0.00314 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.438 | L2-Norm(final)=9.980 | 4705.2 samples/s | 73.5 steps/s
[Step=11750 Epoch=22.1] | Loss=0.00311 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=9.977 | 4476.4 samples/s | 69.9 steps/s
[Step=11800 Epoch=22.2] | Loss=0.00307 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.415 | L2-Norm(final)=9.974 | 4477.4 samples/s | 70.0 steps/s
[Step=11850 Epoch=22.3] | Loss=0.00297 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=9.971 | 4587.7 samples/s | 71.7 steps/s
[Step=11900 Epoch=22.4] | Loss=0.00286 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.393 | L2-Norm(final)=9.968 | 4493.1 samples/s | 70.2 steps/s
[Step=11950 Epoch=22.5] | Loss=0.00277 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=9.966 | 4537.8 samples/s | 70.9 steps/s
[Step=12000 Epoch=22.6] | Loss=0.00268 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=9.964 | 4560.6 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05558 | acc=0.9609 | tpr=0.9595 | fpr=0.0362 | 4709.6 samples/s | 18.4 steps/s
Avg test loss: 0.05875, Avg test acc: 0.95957, Avg tpr: 0.95815, Avg fpr: 0.03730, total FA: 291

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.94998 | acc=0.3083 | tpr=0.0134 | fpr=0.0513 | 3965.3 samples/s | 15.5 steps/s
Avg test loss: 8.98082, Avg test acc: 0.30619, Avg tpr: 0.01393, Avg fpr: 0.05102, total FA: 398

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.59171 | acc=0.1726 | tpr=0.6195 | fpr=0.8355 | 3907.9 samples/s | 15.3 steps/s
[Step= 100] | Loss=3.58022 | acc=0.1741 | tpr=0.6162 | fpr=0.8342 | 8490.4 samples/s | 33.2 steps/s
[Step= 150] | Loss=3.56703 | acc=0.1750 | tpr=0.6167 | fpr=0.8331 | 8603.9 samples/s | 33.6 steps/s
[Step= 200] | Loss=3.55934 | acc=0.1751 | tpr=0.6175 | fpr=0.8329 | 8366.9 samples/s | 32.7 steps/s
[Step= 250] | Loss=3.56227 | acc=0.1755 | tpr=0.6157 | fpr=0.8325 | 8920.1 samples/s | 34.8 steps/s
[Step= 300] | Loss=3.55842 | acc=0.1751 | tpr=0.6087 | fpr=0.8328 | 8237.1 samples/s | 32.2 steps/s
[Step= 350] | Loss=3.55847 | acc=0.1741 | tpr=0.6111 | fpr=0.8339 | 8668.5 samples/s | 33.9 steps/s
[Step= 400] | Loss=3.55587 | acc=0.1747 | tpr=0.6176 | fpr=0.8333 | 8327.2 samples/s | 32.5 steps/s
[Step= 450] | Loss=3.55773 | acc=0.1749 | tpr=0.6168 | fpr=0.8331 | 8649.7 samples/s | 33.8 steps/s
[Step= 500] | Loss=3.55412 | acc=0.1755 | tpr=0.6194 | fpr=0.8325 | 8586.4 samples/s | 33.5 steps/s
[Step= 550] | Loss=3.55486 | acc=0.1756 | tpr=0.6168 | fpr=0.8324 | 14532.9 samples/s | 56.8 steps/s
Avg test loss: 3.55708, Avg test acc: 0.17540, Avg tpr: 0.61648, Avg fpr: 0.83262, total FA: 115607

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11704 | acc=0.9821 | tpr=0.9558 | fpr=0.0174 | 4684.8 samples/s | 18.3 steps/s
[Step= 100] | Loss=0.12392 | acc=0.9811 | tpr=0.9659 | fpr=0.0187 | 8280.8 samples/s | 32.3 steps/s
[Step= 150] | Loss=0.12686 | acc=0.9804 | tpr=0.9697 | fpr=0.0194 | 8367.9 samples/s | 32.7 steps/s
[Step= 200] | Loss=0.12805 | acc=0.9804 | tpr=0.9705 | fpr=0.0194 | 8539.7 samples/s | 33.4 steps/s
[Step= 250] | Loss=0.12788 | acc=0.9805 | tpr=0.9668 | fpr=0.0192 | 8806.9 samples/s | 34.4 steps/s
[Step= 300] | Loss=0.12929 | acc=0.9803 | tpr=0.9665 | fpr=0.0194 | 8212.1 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.13064 | acc=0.9802 | tpr=0.9674 | fpr=0.0196 | 8612.6 samples/s | 33.6 steps/s
[Step= 400] | Loss=0.13218 | acc=0.9800 | tpr=0.9644 | fpr=0.0198 | 8142.5 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.13483 | acc=0.9796 | tpr=0.9635 | fpr=0.0201 | 8533.5 samples/s | 33.3 steps/s
[Step= 500] | Loss=0.13438 | acc=0.9796 | tpr=0.9630 | fpr=0.0201 | 9029.0 samples/s | 35.3 steps/s
[Step= 550] | Loss=0.13346 | acc=0.9797 | tpr=0.9618 | fpr=0.0200 | 13956.0 samples/s | 54.5 steps/s
Avg test loss: 0.13322, Avg test acc: 0.97971, Avg tpr: 0.96117, Avg fpr: 0.01995, total FA: 2770

server round 6/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=12001 Epoch=11.7] | Loss=0.08357 | Reg=0.00231 | acc=0.9375 | L2-Norm=15.211 | L2-Norm(final)=7.713 | 3908.3 samples/s | 61.1 steps/s
[Step=12050 Epoch=11.8] | Loss=0.09734 | Reg=0.00232 | acc=0.8750 | L2-Norm=15.218 | L2-Norm(final)=7.761 | 5730.7 samples/s | 89.5 steps/s
[Step=12100 Epoch=11.8] | Loss=0.10542 | Reg=0.00232 | acc=0.8906 | L2-Norm=15.219 | L2-Norm(final)=7.805 | 5531.4 samples/s | 86.4 steps/s
[Step=12150 Epoch=11.9] | Loss=0.10366 | Reg=0.00232 | acc=0.8750 | L2-Norm=15.219 | L2-Norm(final)=7.838 | 5610.1 samples/s | 87.7 steps/s
[Step=12200 Epoch=11.9] | Loss=0.10528 | Reg=0.00232 | acc=0.9219 | L2-Norm=15.220 | L2-Norm(final)=7.868 | 5634.3 samples/s | 88.0 steps/s
[Step=12250 Epoch=12.0] | Loss=0.10492 | Reg=0.00232 | acc=0.9062 | L2-Norm=15.220 | L2-Norm(final)=7.897 | 5466.1 samples/s | 85.4 steps/s
[Step=12300 Epoch=12.0] | Loss=0.10472 | Reg=0.00232 | acc=0.9062 | L2-Norm=15.220 | L2-Norm(final)=7.928 | 5570.7 samples/s | 87.0 steps/s
[Step=12350 Epoch=12.1] | Loss=0.10466 | Reg=0.00232 | acc=0.9219 | L2-Norm=15.220 | L2-Norm(final)=7.958 | 5619.6 samples/s | 87.8 steps/s
[Step=12400 Epoch=12.1] | Loss=0.10412 | Reg=0.00232 | acc=0.9531 | L2-Norm=15.220 | L2-Norm(final)=7.988 | 5453.5 samples/s | 85.2 steps/s
[Step=12450 Epoch=12.2] | Loss=0.10430 | Reg=0.00232 | acc=0.8906 | L2-Norm=15.220 | L2-Norm(final)=8.019 | 5547.0 samples/s | 86.7 steps/s
[Step=12500 Epoch=12.2] | Loss=0.10400 | Reg=0.00232 | acc=0.9375 | L2-Norm=15.220 | L2-Norm(final)=8.049 | 5558.4 samples/s | 86.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=12.2] | Loss=0.13635 | Reg=0.00232 | acc=0.8750 | L2-Norm=15.220 | L2-Norm(final)=8.340 | 4234.5 samples/s | 66.2 steps/s
[Step=12550 Epoch=12.3] | Loss=0.07542 | Reg=0.00237 | acc=0.9062 | L2-Norm=15.401 | L2-Norm(final)=8.342 | 4662.0 samples/s | 72.8 steps/s
[Step=12600 Epoch=12.3] | Loss=0.07201 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.561 | L2-Norm(final)=8.324 | 4937.0 samples/s | 77.1 steps/s
[Step=12650 Epoch=12.4] | Loss=0.06535 | Reg=0.00245 | acc=0.9688 | L2-Norm=15.664 | L2-Norm(final)=8.315 | 4889.9 samples/s | 76.4 steps/s
[Step=12700 Epoch=12.4] | Loss=0.06106 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.740 | L2-Norm(final)=8.306 | 4904.8 samples/s | 76.6 steps/s
[Step=12750 Epoch=12.4] | Loss=0.05938 | Reg=0.00250 | acc=0.9219 | L2-Norm=15.804 | L2-Norm(final)=8.298 | 4915.4 samples/s | 76.8 steps/s
[Step=12800 Epoch=12.5] | Loss=0.05652 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.860 | L2-Norm(final)=8.292 | 4931.5 samples/s | 77.1 steps/s
[Step=12850 Epoch=12.5] | Loss=0.05539 | Reg=0.00253 | acc=0.9219 | L2-Norm=15.915 | L2-Norm(final)=8.285 | 4894.0 samples/s | 76.5 steps/s
[Step=12900 Epoch=12.6] | Loss=0.05440 | Reg=0.00255 | acc=0.9531 | L2-Norm=15.971 | L2-Norm(final)=8.277 | 4952.3 samples/s | 77.4 steps/s
[Step=12950 Epoch=12.6] | Loss=0.05386 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.024 | L2-Norm(final)=8.269 | 4905.2 samples/s | 76.6 steps/s
[Step=13000 Epoch=12.7] | Loss=0.05309 | Reg=0.00258 | acc=0.9375 | L2-Norm=16.073 | L2-Norm(final)=8.261 | 4947.6 samples/s | 77.3 steps/s
[Step=13050 Epoch=12.7] | Loss=0.05241 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.117 | L2-Norm(final)=8.253 | 4873.3 samples/s | 76.1 steps/s
[Step=13100 Epoch=12.8] | Loss=0.05138 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.157 | L2-Norm(final)=8.245 | 4950.6 samples/s | 77.4 steps/s
[Step=13150 Epoch=12.8] | Loss=0.05011 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.194 | L2-Norm(final)=8.238 | 4892.5 samples/s | 76.4 steps/s
[Step=13200 Epoch=12.9] | Loss=0.04972 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.230 | L2-Norm(final)=8.231 | 4893.2 samples/s | 76.5 steps/s
[Step=13250 Epoch=12.9] | Loss=0.04857 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.263 | L2-Norm(final)=8.225 | 4905.1 samples/s | 76.6 steps/s
[Step=13300 Epoch=13.0] | Loss=0.04767 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.296 | L2-Norm(final)=8.220 | 4940.5 samples/s | 77.2 steps/s
[Step=13350 Epoch=13.0] | Loss=0.04692 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.326 | L2-Norm(final)=8.215 | 4945.6 samples/s | 77.3 steps/s
[Step=13400 Epoch=13.1] | Loss=0.04645 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.357 | L2-Norm(final)=8.210 | 4926.6 samples/s | 77.0 steps/s
[Step=13450 Epoch=13.1] | Loss=0.04551 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.386 | L2-Norm(final)=8.205 | 4900.7 samples/s | 76.6 steps/s
[Step=13500 Epoch=13.2] | Loss=0.04520 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.414 | L2-Norm(final)=8.200 | 5287.6 samples/s | 82.6 steps/s
[Step=13550 Epoch=13.2] | Loss=0.04471 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.441 | L2-Norm(final)=8.194 | 2123.1 samples/s | 33.2 steps/s
[Step=13600 Epoch=13.3] | Loss=0.04394 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.468 | L2-Norm(final)=8.190 | 4748.4 samples/s | 74.2 steps/s
[Step=13650 Epoch=13.3] | Loss=0.04346 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.494 | L2-Norm(final)=8.184 | 4781.5 samples/s | 74.7 steps/s
[Step=13700 Epoch=13.4] | Loss=0.04266 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.518 | L2-Norm(final)=8.180 | 4779.0 samples/s | 74.7 steps/s
[Step=13750 Epoch=13.4] | Loss=0.04215 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.541 | L2-Norm(final)=8.175 | 4778.6 samples/s | 74.7 steps/s
[Step=13800 Epoch=13.5] | Loss=0.04155 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.564 | L2-Norm(final)=8.171 | 4774.1 samples/s | 74.6 steps/s
[Step=13850 Epoch=13.5] | Loss=0.04106 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.586 | L2-Norm(final)=8.167 | 4809.5 samples/s | 75.1 steps/s
[Step=13900 Epoch=13.6] | Loss=0.04071 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.608 | L2-Norm(final)=8.163 | 4823.1 samples/s | 75.4 steps/s
[Step=13950 Epoch=13.6] | Loss=0.04061 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.631 | L2-Norm(final)=8.159 | 4816.1 samples/s | 75.3 steps/s
[Step=14000 Epoch=13.7] | Loss=0.04028 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.653 | L2-Norm(final)=8.155 | 4817.3 samples/s | 75.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step14000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=12001 Epoch=22.6] | Loss=0.01686 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.211 | L2-Norm(final)=9.904 | 4404.8 samples/s | 68.8 steps/s
[Step=12050 Epoch=22.7] | Loss=0.00904 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.204 | L2-Norm(final)=9.915 | 4804.8 samples/s | 75.1 steps/s
[Step=12100 Epoch=22.8] | Loss=0.00757 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.203 | L2-Norm(final)=9.930 | 5140.0 samples/s | 80.3 steps/s
[Step=12150 Epoch=22.9] | Loss=0.00673 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=9.952 | 5217.3 samples/s | 81.5 steps/s
[Step=12200 Epoch=23.0] | Loss=0.00635 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=9.977 | 5226.6 samples/s | 81.7 steps/s
[Step=12250 Epoch=23.1] | Loss=0.00620 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=10.002 | 5157.4 samples/s | 80.6 steps/s
[Step=12300 Epoch=23.2] | Loss=0.00595 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.202 | L2-Norm(final)=10.028 | 5275.1 samples/s | 82.4 steps/s
[Step=12350 Epoch=23.3] | Loss=0.00574 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=10.056 | 5087.9 samples/s | 79.5 steps/s
[Step=12400 Epoch=23.4] | Loss=0.00561 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.202 | L2-Norm(final)=10.083 | 5340.4 samples/s | 83.4 steps/s
[Step=12450 Epoch=23.5] | Loss=0.00559 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=10.112 | 5123.8 samples/s | 80.1 steps/s
[Step=12500 Epoch=23.6] | Loss=0.00554 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=10.141 | 5312.7 samples/s | 83.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=23.6] | Loss=0.00133 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=10.443 | 4598.0 samples/s | 71.8 steps/s
[Step=12550 Epoch=23.7] | Loss=0.00362 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=10.472 | 4477.4 samples/s | 70.0 steps/s
[Step=12600 Epoch=23.8] | Loss=0.00346 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=10.471 | 4624.2 samples/s | 72.3 steps/s
[Step=12650 Epoch=23.8] | Loss=0.00504 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=10.458 | 4563.3 samples/s | 71.3 steps/s
[Step=12700 Epoch=23.9] | Loss=0.00586 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.436 | 4569.4 samples/s | 71.4 steps/s
[Step=12750 Epoch=24.0] | Loss=0.00585 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=10.416 | 4555.2 samples/s | 71.2 steps/s
[Step=12800 Epoch=24.1] | Loss=0.00614 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.499 | L2-Norm(final)=10.398 | 4547.0 samples/s | 71.0 steps/s
[Step=12850 Epoch=24.2] | Loss=0.00586 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=10.381 | 4603.9 samples/s | 71.9 steps/s
[Step=12900 Epoch=24.3] | Loss=0.00552 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=10.368 | 4492.7 samples/s | 70.2 steps/s
[Step=12950 Epoch=24.4] | Loss=0.00539 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.614 | L2-Norm(final)=10.356 | 4519.9 samples/s | 70.6 steps/s
[Step=13000 Epoch=24.5] | Loss=0.00540 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.636 | L2-Norm(final)=10.344 | 4609.2 samples/s | 72.0 steps/s
[Step=13050 Epoch=24.6] | Loss=0.00515 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.654 | L2-Norm(final)=10.333 | 2083.5 samples/s | 32.6 steps/s
[Step=13100 Epoch=24.7] | Loss=0.00473 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.665 | L2-Norm(final)=10.323 | 4610.5 samples/s | 72.0 steps/s
[Step=13150 Epoch=24.8] | Loss=0.00438 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.671 | L2-Norm(final)=10.316 | 4551.5 samples/s | 71.1 steps/s
[Step=13200 Epoch=24.9] | Loss=0.00407 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.672 | L2-Norm(final)=10.310 | 4551.3 samples/s | 71.1 steps/s
[Step=13250 Epoch=25.0] | Loss=0.00381 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.669 | L2-Norm(final)=10.305 | 4492.2 samples/s | 70.2 steps/s
[Step=13300 Epoch=25.1] | Loss=0.00357 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=10.301 | 4547.1 samples/s | 71.0 steps/s
[Step=13350 Epoch=25.2] | Loss=0.00337 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.656 | L2-Norm(final)=10.297 | 4510.1 samples/s | 70.5 steps/s
[Step=13400 Epoch=25.3] | Loss=0.00318 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.646 | L2-Norm(final)=10.294 | 4522.1 samples/s | 70.7 steps/s
[Step=13450 Epoch=25.4] | Loss=0.00302 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.635 | L2-Norm(final)=10.291 | 4525.7 samples/s | 70.7 steps/s
[Step=13500 Epoch=25.4] | Loss=0.00287 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.622 | L2-Norm(final)=10.289 | 4566.6 samples/s | 71.4 steps/s
[Step=13550 Epoch=25.5] | Loss=0.00275 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.609 | L2-Norm(final)=10.287 | 5643.9 samples/s | 88.2 steps/s
[Step=13600 Epoch=25.6] | Loss=0.00267 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.595 | L2-Norm(final)=10.285 | 1981.8 samples/s | 31.0 steps/s
[Step=13650 Epoch=25.7] | Loss=0.00256 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.581 | L2-Norm(final)=10.283 | 4702.1 samples/s | 73.5 steps/s
[Step=13700 Epoch=25.8] | Loss=0.00245 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=10.281 | 4451.0 samples/s | 69.5 steps/s
[Step=13750 Epoch=25.9] | Loss=0.00235 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=10.279 | 4575.2 samples/s | 71.5 steps/s
[Step=13800 Epoch=26.0] | Loss=0.00226 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=10.278 | 4506.2 samples/s | 70.4 steps/s
[Step=13850 Epoch=26.1] | Loss=0.00218 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.518 | L2-Norm(final)=10.277 | 4526.5 samples/s | 70.7 steps/s
[Step=13900 Epoch=26.2] | Loss=0.00210 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.501 | L2-Norm(final)=10.276 | 4558.4 samples/s | 71.2 steps/s
[Step=13950 Epoch=26.3] | Loss=0.00203 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.483 | L2-Norm(final)=10.274 | 4560.4 samples/s | 71.3 steps/s
[Step=14000 Epoch=26.4] | Loss=0.00196 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.465 | L2-Norm(final)=10.274 | 4584.8 samples/s | 71.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07301 | acc=0.9470 | tpr=0.9319 | fpr=0.0203 | 4634.7 samples/s | 18.1 steps/s
Avg test loss: 0.07495, Avg test acc: 0.94543, Avg tpr: 0.93035, Avg fpr: 0.02141, total FA: 167

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.55470 | acc=0.3115 | tpr=0.0135 | fpr=0.0414 | 4632.4 samples/s | 18.1 steps/s
Avg test loss: 7.57176, Avg test acc: 0.30916, Avg tpr: 0.01247, Avg fpr: 0.03833, total FA: 299

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.82059 | acc=0.2188 | tpr=0.4823 | fpr=0.7860 | 4652.8 samples/s | 18.2 steps/s
[Step= 100] | Loss=2.82764 | acc=0.2200 | tpr=0.4925 | fpr=0.7850 | 8332.5 samples/s | 32.5 steps/s
[Step= 150] | Loss=2.81503 | acc=0.2210 | tpr=0.5029 | fpr=0.7841 | 8559.4 samples/s | 33.4 steps/s
[Step= 200] | Loss=2.80775 | acc=0.2229 | tpr=0.5038 | fpr=0.7822 | 8520.8 samples/s | 33.3 steps/s
[Step= 250] | Loss=2.81033 | acc=0.2234 | tpr=0.5048 | fpr=0.7817 | 8408.6 samples/s | 32.8 steps/s
[Step= 300] | Loss=2.80604 | acc=0.2227 | tpr=0.5076 | fpr=0.7824 | 8459.3 samples/s | 33.0 steps/s
[Step= 350] | Loss=2.80414 | acc=0.2224 | tpr=0.5053 | fpr=0.7827 | 8562.0 samples/s | 33.4 steps/s
[Step= 400] | Loss=2.80253 | acc=0.2228 | tpr=0.5098 | fpr=0.7824 | 8946.9 samples/s | 34.9 steps/s
[Step= 450] | Loss=2.80605 | acc=0.2224 | tpr=0.5102 | fpr=0.7828 | 8213.2 samples/s | 32.1 steps/s
[Step= 500] | Loss=2.80321 | acc=0.2224 | tpr=0.5093 | fpr=0.7827 | 8591.3 samples/s | 33.6 steps/s
[Step= 550] | Loss=2.80362 | acc=0.2221 | tpr=0.5101 | fpr=0.7832 | 15004.4 samples/s | 58.6 steps/s
Avg test loss: 2.80473, Avg test acc: 0.22198, Avg tpr: 0.50951, Avg fpr: 0.78324, total FA: 108752

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12727 | acc=0.9823 | tpr=0.9602 | fpr=0.0173 | 4612.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.13342 | acc=0.9820 | tpr=0.9680 | fpr=0.0177 | 8453.0 samples/s | 33.0 steps/s
[Step= 150] | Loss=0.13664 | acc=0.9812 | tpr=0.9683 | fpr=0.0186 | 8299.9 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.13759 | acc=0.9812 | tpr=0.9672 | fpr=0.0186 | 8347.4 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.13652 | acc=0.9814 | tpr=0.9642 | fpr=0.0183 | 8508.4 samples/s | 33.2 steps/s
[Step= 300] | Loss=0.13765 | acc=0.9811 | tpr=0.9644 | fpr=0.0186 | 8385.2 samples/s | 32.8 steps/s
[Step= 350] | Loss=0.13947 | acc=0.9809 | tpr=0.9649 | fpr=0.0188 | 8498.9 samples/s | 33.2 steps/s
[Step= 400] | Loss=0.14080 | acc=0.9808 | tpr=0.9617 | fpr=0.0188 | 8471.1 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.14408 | acc=0.9805 | tpr=0.9620 | fpr=0.0191 | 8841.4 samples/s | 34.5 steps/s
[Step= 500] | Loss=0.14337 | acc=0.9806 | tpr=0.9626 | fpr=0.0191 | 8608.2 samples/s | 33.6 steps/s
[Step= 550] | Loss=0.14258 | acc=0.9807 | tpr=0.9610 | fpr=0.0189 | 15695.8 samples/s | 61.3 steps/s
Avg test loss: 0.14239, Avg test acc: 0.98072, Avg tpr: 0.96078, Avg fpr: 0.01892, total FA: 2627

server round 7/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=14001 Epoch=13.7] | Loss=0.11594 | Reg=0.00235 | acc=0.8906 | L2-Norm=15.326 | L2-Norm(final)=8.039 | 4185.8 samples/s | 65.4 steps/s
[Step=14050 Epoch=13.7] | Loss=0.09872 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.339 | L2-Norm(final)=8.071 | 5519.3 samples/s | 86.2 steps/s
[Step=14100 Epoch=13.8] | Loss=0.09518 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.341 | L2-Norm(final)=8.118 | 5402.1 samples/s | 84.4 steps/s
[Step=14150 Epoch=13.8] | Loss=0.09455 | Reg=0.00235 | acc=0.9062 | L2-Norm=15.342 | L2-Norm(final)=8.170 | 5463.2 samples/s | 85.4 steps/s
[Step=14200 Epoch=13.9] | Loss=0.09551 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.342 | L2-Norm(final)=8.214 | 5502.1 samples/s | 86.0 steps/s
[Step=14250 Epoch=13.9] | Loss=0.09573 | Reg=0.00235 | acc=0.9375 | L2-Norm=15.342 | L2-Norm(final)=8.256 | 5489.7 samples/s | 85.8 steps/s
[Step=14300 Epoch=14.0] | Loss=0.09439 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.342 | L2-Norm(final)=8.297 | 5591.9 samples/s | 87.4 steps/s
[Step=14350 Epoch=14.0] | Loss=0.09400 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.342 | L2-Norm(final)=8.339 | 5400.8 samples/s | 84.4 steps/s
[Step=14400 Epoch=14.1] | Loss=0.09371 | Reg=0.00235 | acc=0.8906 | L2-Norm=15.343 | L2-Norm(final)=8.382 | 5526.5 samples/s | 86.4 steps/s
[Step=14450 Epoch=14.1] | Loss=0.09309 | Reg=0.00235 | acc=0.9062 | L2-Norm=15.343 | L2-Norm(final)=8.424 | 5537.0 samples/s | 86.5 steps/s
[Step=14500 Epoch=14.2] | Loss=0.09259 | Reg=0.00235 | acc=0.9375 | L2-Norm=15.343 | L2-Norm(final)=8.464 | 5660.9 samples/s | 88.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=14.2] | Loss=0.09306 | Reg=0.00235 | acc=0.9375 | L2-Norm=15.343 | L2-Norm(final)=8.859 | 4172.0 samples/s | 65.2 steps/s
[Step=14550 Epoch=14.2] | Loss=0.06932 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.537 | L2-Norm(final)=8.864 | 4694.0 samples/s | 73.3 steps/s
[Step=14600 Epoch=14.3] | Loss=0.05877 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.693 | L2-Norm(final)=8.853 | 4729.6 samples/s | 73.9 steps/s
[Step=14650 Epoch=14.3] | Loss=0.05464 | Reg=0.00249 | acc=0.9375 | L2-Norm=15.787 | L2-Norm(final)=8.846 | 4764.5 samples/s | 74.4 steps/s
[Step=14700 Epoch=14.4] | Loss=0.05365 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.861 | L2-Norm(final)=8.840 | 4734.0 samples/s | 74.0 steps/s
[Step=14750 Epoch=14.4] | Loss=0.05120 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.923 | L2-Norm(final)=8.831 | 4771.1 samples/s | 74.5 steps/s
[Step=14800 Epoch=14.4] | Loss=0.05031 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.974 | L2-Norm(final)=8.824 | 4826.9 samples/s | 75.4 steps/s
[Step=14850 Epoch=14.5] | Loss=0.04939 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.021 | L2-Norm(final)=8.814 | 4757.6 samples/s | 74.3 steps/s
[Step=14900 Epoch=14.5] | Loss=0.04847 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=8.806 | 4826.1 samples/s | 75.4 steps/s
[Step=14950 Epoch=14.6] | Loss=0.04734 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=8.798 | 4817.9 samples/s | 75.3 steps/s
[Step=15000 Epoch=14.6] | Loss=0.04632 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.149 | L2-Norm(final)=8.791 | 4825.5 samples/s | 75.4 steps/s
[Step=15050 Epoch=14.7] | Loss=0.04569 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.188 | L2-Norm(final)=8.784 | 4845.4 samples/s | 75.7 steps/s
[Step=15100 Epoch=14.7] | Loss=0.04545 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.225 | L2-Norm(final)=8.777 | 4895.5 samples/s | 76.5 steps/s
[Step=15150 Epoch=14.8] | Loss=0.04509 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.259 | L2-Norm(final)=8.771 | 4742.6 samples/s | 74.1 steps/s
[Step=15200 Epoch=14.8] | Loss=0.04485 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.292 | L2-Norm(final)=8.764 | 4794.2 samples/s | 74.9 steps/s
[Step=15250 Epoch=14.9] | Loss=0.04399 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=8.758 | 4766.0 samples/s | 74.5 steps/s
[Step=15300 Epoch=14.9] | Loss=0.04367 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.350 | L2-Norm(final)=8.752 | 4784.8 samples/s | 74.8 steps/s
[Step=15350 Epoch=15.0] | Loss=0.04306 | Reg=0.00268 | acc=0.9688 | L2-Norm=16.378 | L2-Norm(final)=8.746 | 4825.7 samples/s | 75.4 steps/s
[Step=15400 Epoch=15.0] | Loss=0.04280 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.406 | L2-Norm(final)=8.741 | 4807.3 samples/s | 75.1 steps/s
[Step=15450 Epoch=15.1] | Loss=0.04261 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.433 | L2-Norm(final)=8.736 | 4872.5 samples/s | 76.1 steps/s
[Step=15500 Epoch=15.1] | Loss=0.04225 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.459 | L2-Norm(final)=8.731 | 5101.4 samples/s | 79.7 steps/s
[Step=15550 Epoch=15.2] | Loss=0.04214 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.485 | L2-Norm(final)=8.725 | 2096.8 samples/s | 32.8 steps/s
[Step=15600 Epoch=15.2] | Loss=0.04158 | Reg=0.00273 | acc=0.9531 | L2-Norm=16.510 | L2-Norm(final)=8.720 | 4741.2 samples/s | 74.1 steps/s
[Step=15650 Epoch=15.3] | Loss=0.04107 | Reg=0.00274 | acc=0.9375 | L2-Norm=16.534 | L2-Norm(final)=8.715 | 4825.3 samples/s | 75.4 steps/s
[Step=15700 Epoch=15.3] | Loss=0.04036 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.557 | L2-Norm(final)=8.710 | 4760.5 samples/s | 74.4 steps/s
[Step=15750 Epoch=15.4] | Loss=0.04005 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=8.705 | 4765.9 samples/s | 74.5 steps/s
[Step=15800 Epoch=15.4] | Loss=0.03970 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.601 | L2-Norm(final)=8.700 | 4794.8 samples/s | 74.9 steps/s
[Step=15850 Epoch=15.5] | Loss=0.03927 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=8.695 | 4762.9 samples/s | 74.4 steps/s
[Step=15900 Epoch=15.5] | Loss=0.03895 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.643 | L2-Norm(final)=8.690 | 4807.8 samples/s | 75.1 steps/s
[Step=15950 Epoch=15.6] | Loss=0.03889 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.665 | L2-Norm(final)=8.684 | 4805.3 samples/s | 75.1 steps/s
[Step=16000 Epoch=15.6] | Loss=0.03862 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.686 | L2-Norm(final)=8.679 | 4836.1 samples/s | 75.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step16000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=14001 Epoch=26.4] | Loss=0.00058 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=10.245 | 4295.5 samples/s | 67.1 steps/s
[Step=14050 Epoch=26.5] | Loss=0.00474 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=10.260 | 5206.3 samples/s | 81.3 steps/s
[Step=14100 Epoch=26.6] | Loss=0.00537 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.282 | 5312.1 samples/s | 83.0 steps/s
[Step=14150 Epoch=26.7] | Loss=0.00515 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.306 | 5151.7 samples/s | 80.5 steps/s
[Step=14200 Epoch=26.8] | Loss=0.00531 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.318 | L2-Norm(final)=10.330 | 5212.2 samples/s | 81.4 steps/s
[Step=14250 Epoch=26.9] | Loss=0.00530 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.355 | 5118.7 samples/s | 80.0 steps/s
[Step=14300 Epoch=27.0] | Loss=0.00519 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.381 | 5259.3 samples/s | 82.2 steps/s
[Step=14350 Epoch=27.0] | Loss=0.00522 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.318 | L2-Norm(final)=10.410 | 5155.6 samples/s | 80.6 steps/s
[Step=14400 Epoch=27.1] | Loss=0.00503 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.440 | 5180.4 samples/s | 80.9 steps/s
[Step=14450 Epoch=27.2] | Loss=0.00498 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.318 | L2-Norm(final)=10.471 | 5264.5 samples/s | 82.3 steps/s
[Step=14500 Epoch=27.3] | Loss=0.00491 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=10.503 | 5173.9 samples/s | 80.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=27.3] | Loss=0.00294 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=10.823 | 4201.2 samples/s | 65.6 steps/s
[Step=14550 Epoch=27.4] | Loss=0.00226 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=10.844 | 4506.9 samples/s | 70.4 steps/s
[Step=14600 Epoch=27.5] | Loss=0.01079 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.445 | L2-Norm(final)=10.817 | 4569.7 samples/s | 71.4 steps/s
[Step=14650 Epoch=27.6] | Loss=0.01143 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.636 | L2-Norm(final)=10.772 | 4551.6 samples/s | 71.1 steps/s
[Step=14700 Epoch=27.7] | Loss=0.01161 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.783 | L2-Norm(final)=10.732 | 4496.8 samples/s | 70.3 steps/s
[Step=14750 Epoch=27.8] | Loss=0.01048 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=10.701 | 4522.1 samples/s | 70.7 steps/s
[Step=14800 Epoch=27.9] | Loss=0.00912 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=10.680 | 4530.0 samples/s | 70.8 steps/s
[Step=14850 Epoch=28.0] | Loss=0.00827 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=10.664 | 4585.2 samples/s | 71.6 steps/s
[Step=14900 Epoch=28.1] | Loss=0.00756 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.028 | L2-Norm(final)=10.651 | 4554.5 samples/s | 71.2 steps/s
[Step=14950 Epoch=28.2] | Loss=0.00713 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.053 | L2-Norm(final)=10.640 | 4486.7 samples/s | 70.1 steps/s
[Step=15000 Epoch=28.3] | Loss=0.00723 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.072 | L2-Norm(final)=10.628 | 4615.4 samples/s | 72.1 steps/s
[Step=15050 Epoch=28.4] | Loss=0.00668 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=10.618 | 2128.1 samples/s | 33.3 steps/s
[Step=15100 Epoch=28.5] | Loss=0.00620 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.099 | L2-Norm(final)=10.609 | 4721.7 samples/s | 73.8 steps/s
[Step=15150 Epoch=28.6] | Loss=0.00573 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=10.602 | 4528.8 samples/s | 70.8 steps/s
[Step=15200 Epoch=28.7] | Loss=0.00536 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=10.596 | 4518.9 samples/s | 70.6 steps/s
[Step=15250 Epoch=28.7] | Loss=0.00501 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=10.591 | 4535.1 samples/s | 70.9 steps/s
[Step=15300 Epoch=28.8] | Loss=0.00470 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.104 | L2-Norm(final)=10.586 | 4641.5 samples/s | 72.5 steps/s
[Step=15350 Epoch=28.9] | Loss=0.00442 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.099 | L2-Norm(final)=10.583 | 4638.9 samples/s | 72.5 steps/s
[Step=15400 Epoch=29.0] | Loss=0.00418 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=10.579 | 4484.8 samples/s | 70.1 steps/s
[Step=15450 Epoch=29.1] | Loss=0.00396 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.083 | L2-Norm(final)=10.577 | 4525.1 samples/s | 70.7 steps/s
[Step=15500 Epoch=29.2] | Loss=0.00376 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.073 | L2-Norm(final)=10.574 | 4543.7 samples/s | 71.0 steps/s
[Step=15550 Epoch=29.3] | Loss=0.00359 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=10.572 | 5654.5 samples/s | 88.4 steps/s
[Step=15600 Epoch=29.4] | Loss=0.00342 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.049 | L2-Norm(final)=10.570 | 1955.7 samples/s | 30.6 steps/s
[Step=15650 Epoch=29.5] | Loss=0.00327 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.036 | L2-Norm(final)=10.568 | 4470.2 samples/s | 69.8 steps/s
[Step=15700 Epoch=29.6] | Loss=0.00314 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.022 | L2-Norm(final)=10.567 | 4508.9 samples/s | 70.5 steps/s
[Step=15750 Epoch=29.7] | Loss=0.00301 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.008 | L2-Norm(final)=10.565 | 4546.2 samples/s | 71.0 steps/s
[Step=15800 Epoch=29.8] | Loss=0.00290 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.993 | L2-Norm(final)=10.564 | 4559.3 samples/s | 71.2 steps/s
[Step=15850 Epoch=29.9] | Loss=0.00279 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.978 | L2-Norm(final)=10.563 | 4560.7 samples/s | 71.3 steps/s
[Step=15900 Epoch=30.0] | Loss=0.00269 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=10.562 | 4497.1 samples/s | 70.3 steps/s
[Step=15950 Epoch=30.1] | Loss=0.00260 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=10.561 | 4581.2 samples/s | 71.6 steps/s
[Step=16000 Epoch=30.2] | Loss=0.00251 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.929 | L2-Norm(final)=10.560 | 4481.5 samples/s | 70.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05518 | acc=0.9628 | tpr=0.9625 | fpr=0.0364 | 4638.6 samples/s | 18.1 steps/s
Avg test loss: 0.05998, Avg test acc: 0.96121, Avg tpr: 0.96083, Avg fpr: 0.03794, total FA: 296

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.59712 | acc=0.3128 | tpr=0.0067 | fpr=0.0225 | 4676.4 samples/s | 18.3 steps/s
Avg test loss: 8.60831, Avg test acc: 0.30980, Avg tpr: 0.00595, Avg fpr: 0.02192, total FA: 171

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.07527 | acc=0.1666 | tpr=0.5752 | fpr=0.8408 | 4591.1 samples/s | 17.9 steps/s
[Step= 100] | Loss=4.07249 | acc=0.1693 | tpr=0.5842 | fpr=0.8384 | 8908.2 samples/s | 34.8 steps/s
[Step= 150] | Loss=4.06171 | acc=0.1690 | tpr=0.5908 | fpr=0.8388 | 8439.6 samples/s | 33.0 steps/s
[Step= 200] | Loss=4.05148 | acc=0.1692 | tpr=0.5913 | fpr=0.8385 | 8713.1 samples/s | 34.0 steps/s
[Step= 250] | Loss=4.05614 | acc=0.1693 | tpr=0.5904 | fpr=0.8383 | 8373.7 samples/s | 32.7 steps/s
[Step= 300] | Loss=4.05427 | acc=0.1691 | tpr=0.5869 | fpr=0.8385 | 8422.5 samples/s | 32.9 steps/s
[Step= 350] | Loss=4.05186 | acc=0.1684 | tpr=0.5886 | fpr=0.8392 | 9024.5 samples/s | 35.3 steps/s
[Step= 400] | Loss=4.05021 | acc=0.1686 | tpr=0.5925 | fpr=0.8391 | 8132.6 samples/s | 31.8 steps/s
[Step= 450] | Loss=4.05505 | acc=0.1686 | tpr=0.5969 | fpr=0.8392 | 8567.4 samples/s | 33.5 steps/s
[Step= 500] | Loss=4.05406 | acc=0.1685 | tpr=0.5987 | fpr=0.8393 | 8578.6 samples/s | 33.5 steps/s
[Step= 550] | Loss=4.05461 | acc=0.1688 | tpr=0.6009 | fpr=0.8391 | 15497.2 samples/s | 60.5 steps/s
Avg test loss: 4.05576, Avg test acc: 0.16856, Avg tpr: 0.60103, Avg fpr: 0.83931, total FA: 116536

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13474 | acc=0.9818 | tpr=0.9469 | fpr=0.0176 | 4559.1 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.14010 | acc=0.9812 | tpr=0.9552 | fpr=0.0183 | 8561.9 samples/s | 33.4 steps/s
[Step= 150] | Loss=0.14283 | acc=0.9805 | tpr=0.9568 | fpr=0.0190 | 8452.5 samples/s | 33.0 steps/s
[Step= 200] | Loss=0.14296 | acc=0.9806 | tpr=0.9639 | fpr=0.0191 | 8376.9 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.14138 | acc=0.9809 | tpr=0.9607 | fpr=0.0187 | 8475.2 samples/s | 33.1 steps/s
[Step= 300] | Loss=0.14202 | acc=0.9807 | tpr=0.9593 | fpr=0.0189 | 8581.3 samples/s | 33.5 steps/s
[Step= 350] | Loss=0.14398 | acc=0.9805 | tpr=0.9599 | fpr=0.0191 | 8459.5 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.14526 | acc=0.9805 | tpr=0.9579 | fpr=0.0191 | 8434.0 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.14803 | acc=0.9801 | tpr=0.9562 | fpr=0.0194 | 8680.5 samples/s | 33.9 steps/s
[Step= 500] | Loss=0.14725 | acc=0.9802 | tpr=0.9568 | fpr=0.0193 | 8270.3 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.14627 | acc=0.9804 | tpr=0.9566 | fpr=0.0192 | 15157.6 samples/s | 59.2 steps/s
Avg test loss: 0.14618, Avg test acc: 0.98038, Avg tpr: 0.95642, Avg fpr: 0.01919, total FA: 2664

server round 8/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=16001 Epoch=15.6] | Loss=0.05999 | Reg=0.00243 | acc=0.9531 | L2-Norm=15.589 | L2-Norm(final)=8.511 | 4305.7 samples/s | 67.3 steps/s
[Step=16050 Epoch=15.7] | Loss=0.10289 | Reg=0.00243 | acc=0.9219 | L2-Norm=15.598 | L2-Norm(final)=8.541 | 5000.0 samples/s | 78.1 steps/s
[Step=16100 Epoch=15.7] | Loss=0.10021 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.600 | L2-Norm(final)=8.591 | 5542.7 samples/s | 86.6 steps/s
[Step=16150 Epoch=15.8] | Loss=0.10111 | Reg=0.00243 | acc=0.8594 | L2-Norm=15.600 | L2-Norm(final)=8.640 | 5438.1 samples/s | 85.0 steps/s
[Step=16200 Epoch=15.8] | Loss=0.10054 | Reg=0.00243 | acc=0.9062 | L2-Norm=15.601 | L2-Norm(final)=8.683 | 5515.3 samples/s | 86.2 steps/s
[Step=16250 Epoch=15.9] | Loss=0.10108 | Reg=0.00243 | acc=0.9219 | L2-Norm=15.601 | L2-Norm(final)=8.726 | 5431.3 samples/s | 84.9 steps/s
[Step=16300 Epoch=15.9] | Loss=0.10172 | Reg=0.00243 | acc=0.9219 | L2-Norm=15.601 | L2-Norm(final)=8.766 | 5547.4 samples/s | 86.7 steps/s
[Step=16350 Epoch=16.0] | Loss=0.10207 | Reg=0.00243 | acc=0.9062 | L2-Norm=15.601 | L2-Norm(final)=8.804 | 5580.0 samples/s | 87.2 steps/s
[Step=16400 Epoch=16.0] | Loss=0.10190 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.601 | L2-Norm(final)=8.840 | 5399.7 samples/s | 84.4 steps/s
[Step=16450 Epoch=16.1] | Loss=0.10125 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.601 | L2-Norm(final)=8.875 | 5560.7 samples/s | 86.9 steps/s
[Step=16500 Epoch=16.1] | Loss=0.10073 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.601 | L2-Norm(final)=8.912 | 5516.6 samples/s | 86.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=16.1] | Loss=0.11774 | Reg=0.00243 | acc=0.8906 | L2-Norm=15.602 | L2-Norm(final)=9.271 | 4329.9 samples/s | 67.7 steps/s
[Step=16550 Epoch=16.2] | Loss=0.06410 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=9.285 | 4778.7 samples/s | 74.7 steps/s
[Step=16600 Epoch=16.2] | Loss=0.05508 | Reg=0.00253 | acc=0.9531 | L2-Norm=15.917 | L2-Norm(final)=9.272 | 4865.5 samples/s | 76.0 steps/s
[Step=16650 Epoch=16.3] | Loss=0.05205 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.019 | L2-Norm(final)=9.256 | 4881.2 samples/s | 76.3 steps/s
[Step=16700 Epoch=16.3] | Loss=0.05145 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.100 | L2-Norm(final)=9.244 | 4895.8 samples/s | 76.5 steps/s
[Step=16750 Epoch=16.4] | Loss=0.05045 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.166 | L2-Norm(final)=9.233 | 4922.2 samples/s | 76.9 steps/s
[Step=16800 Epoch=16.4] | Loss=0.04929 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.219 | L2-Norm(final)=9.224 | 4898.5 samples/s | 76.5 steps/s
[Step=16850 Epoch=16.5] | Loss=0.04843 | Reg=0.00265 | acc=0.9531 | L2-Norm=16.269 | L2-Norm(final)=9.215 | 4918.5 samples/s | 76.9 steps/s
[Step=16900 Epoch=16.5] | Loss=0.04867 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.314 | L2-Norm(final)=9.206 | 4904.7 samples/s | 76.6 steps/s
[Step=16950 Epoch=16.5] | Loss=0.04842 | Reg=0.00268 | acc=0.9531 | L2-Norm=16.355 | L2-Norm(final)=9.197 | 4766.7 samples/s | 74.5 steps/s
[Step=17000 Epoch=16.6] | Loss=0.04657 | Reg=0.00269 | acc=0.9531 | L2-Norm=16.392 | L2-Norm(final)=9.190 | 4768.7 samples/s | 74.5 steps/s
[Step=17050 Epoch=16.6] | Loss=0.04529 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.425 | L2-Norm(final)=9.184 | 4773.6 samples/s | 74.6 steps/s
[Step=17100 Epoch=16.7] | Loss=0.04388 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.454 | L2-Norm(final)=9.179 | 4740.2 samples/s | 74.1 steps/s
[Step=17150 Epoch=16.7] | Loss=0.04301 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.482 | L2-Norm(final)=9.174 | 4662.1 samples/s | 72.8 steps/s
[Step=17200 Epoch=16.8] | Loss=0.04237 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.509 | L2-Norm(final)=9.169 | 4770.3 samples/s | 74.5 steps/s
[Step=17250 Epoch=16.8] | Loss=0.04186 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.535 | L2-Norm(final)=9.165 | 4817.7 samples/s | 75.3 steps/s
[Step=17300 Epoch=16.9] | Loss=0.04159 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.561 | L2-Norm(final)=9.160 | 4821.0 samples/s | 75.3 steps/s
[Step=17350 Epoch=16.9] | Loss=0.04116 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.586 | L2-Norm(final)=9.156 | 4835.5 samples/s | 75.6 steps/s
[Step=17400 Epoch=17.0] | Loss=0.04084 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.611 | L2-Norm(final)=9.152 | 4783.6 samples/s | 74.7 steps/s
[Step=17450 Epoch=17.0] | Loss=0.04027 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.634 | L2-Norm(final)=9.148 | 4772.8 samples/s | 74.6 steps/s
[Step=17500 Epoch=17.1] | Loss=0.04002 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.656 | L2-Norm(final)=9.144 | 5155.6 samples/s | 80.6 steps/s
[Step=17550 Epoch=17.1] | Loss=0.03999 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.677 | L2-Norm(final)=9.139 | 2086.7 samples/s | 32.6 steps/s
[Step=17600 Epoch=17.2] | Loss=0.03922 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.697 | L2-Norm(final)=9.134 | 4822.8 samples/s | 75.4 steps/s
[Step=17650 Epoch=17.2] | Loss=0.03883 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.717 | L2-Norm(final)=9.130 | 4794.9 samples/s | 74.9 steps/s
[Step=17700 Epoch=17.3] | Loss=0.03840 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.736 | L2-Norm(final)=9.126 | 4795.0 samples/s | 74.9 steps/s
[Step=17750 Epoch=17.3] | Loss=0.03796 | Reg=0.00281 | acc=0.9531 | L2-Norm=16.755 | L2-Norm(final)=9.122 | 4765.8 samples/s | 74.5 steps/s
[Step=17800 Epoch=17.4] | Loss=0.03745 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=9.119 | 4831.1 samples/s | 75.5 steps/s
[Step=17850 Epoch=17.4] | Loss=0.03722 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.790 | L2-Norm(final)=9.115 | 4813.0 samples/s | 75.2 steps/s
[Step=17900 Epoch=17.5] | Loss=0.03683 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.808 | L2-Norm(final)=9.111 | 4827.0 samples/s | 75.4 steps/s
[Step=17950 Epoch=17.5] | Loss=0.03653 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.824 | L2-Norm(final)=9.107 | 4775.7 samples/s | 74.6 steps/s
[Step=18000 Epoch=17.6] | Loss=0.03634 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.840 | L2-Norm(final)=9.104 | 4773.2 samples/s | 74.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step18000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=16001 Epoch=30.2] | Loss=0.00645 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=10.535 | 4068.6 samples/s | 63.6 steps/s
[Step=16050 Epoch=30.3] | Loss=0.00415 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.583 | L2-Norm(final)=10.576 | 5115.1 samples/s | 79.9 steps/s
[Step=16100 Epoch=30.3] | Loss=0.00465 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.618 | 5226.6 samples/s | 81.7 steps/s
[Step=16150 Epoch=30.4] | Loss=0.00451 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.657 | 5178.0 samples/s | 80.9 steps/s
[Step=16200 Epoch=30.5] | Loss=0.00434 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.696 | 5329.7 samples/s | 83.3 steps/s
[Step=16250 Epoch=30.6] | Loss=0.00415 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.735 | 5014.1 samples/s | 78.3 steps/s
[Step=16300 Epoch=30.7] | Loss=0.00431 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.773 | 5185.4 samples/s | 81.0 steps/s
[Step=16350 Epoch=30.8] | Loss=0.00424 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.808 | 5132.2 samples/s | 80.2 steps/s
[Step=16400 Epoch=30.9] | Loss=0.00408 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.843 | 5219.4 samples/s | 81.6 steps/s
[Step=16450 Epoch=31.0] | Loss=0.00400 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.878 | 5268.5 samples/s | 82.3 steps/s
[Step=16500 Epoch=31.1] | Loss=0.00394 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=10.912 | 5207.5 samples/s | 81.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=31.1] | Loss=0.00231 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=11.257 | 3996.6 samples/s | 62.4 steps/s
[Step=16550 Epoch=31.2] | Loss=0.00801 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.269 | 4653.6 samples/s | 72.7 steps/s
[Step=16600 Epoch=31.3] | Loss=0.00812 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.824 | L2-Norm(final)=11.245 | 4664.2 samples/s | 72.9 steps/s
[Step=16650 Epoch=31.4] | Loss=0.00776 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.943 | L2-Norm(final)=11.229 | 4681.2 samples/s | 73.1 steps/s
[Step=16700 Epoch=31.5] | Loss=0.00692 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.026 | L2-Norm(final)=11.214 | 4680.1 samples/s | 73.1 steps/s
[Step=16750 Epoch=31.6] | Loss=0.00614 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.090 | L2-Norm(final)=11.201 | 4562.8 samples/s | 71.3 steps/s
[Step=16800 Epoch=31.7] | Loss=0.00767 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.147 | L2-Norm(final)=11.188 | 4555.6 samples/s | 71.2 steps/s
[Step=16850 Epoch=31.8] | Loss=0.00737 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.209 | L2-Norm(final)=11.165 | 4567.1 samples/s | 71.4 steps/s
[Step=16900 Epoch=31.9] | Loss=0.00725 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.260 | L2-Norm(final)=11.146 | 4488.0 samples/s | 70.1 steps/s
[Step=16950 Epoch=32.0] | Loss=0.00690 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.300 | L2-Norm(final)=11.130 | 4570.2 samples/s | 71.4 steps/s
[Step=17000 Epoch=32.0] | Loss=0.00695 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.335 | L2-Norm(final)=11.116 | 4583.0 samples/s | 71.6 steps/s
[Step=17050 Epoch=32.1] | Loss=0.00678 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.369 | L2-Norm(final)=11.103 | 2175.0 samples/s | 34.0 steps/s
[Step=17100 Epoch=32.2] | Loss=0.00630 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.399 | L2-Norm(final)=11.092 | 4737.0 samples/s | 74.0 steps/s
[Step=17150 Epoch=32.3] | Loss=0.00591 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=11.083 | 4794.9 samples/s | 74.9 steps/s
[Step=17200 Epoch=32.4] | Loss=0.00551 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.440 | L2-Norm(final)=11.075 | 4470.7 samples/s | 69.9 steps/s
[Step=17250 Epoch=32.5] | Loss=0.00514 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.453 | L2-Norm(final)=11.070 | 4643.9 samples/s | 72.6 steps/s
[Step=17300 Epoch=32.6] | Loss=0.00499 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.462 | L2-Norm(final)=11.064 | 4454.9 samples/s | 69.6 steps/s
[Step=17350 Epoch=32.7] | Loss=0.00473 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.469 | L2-Norm(final)=11.059 | 4516.9 samples/s | 70.6 steps/s
[Step=17400 Epoch=32.8] | Loss=0.00447 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.472 | L2-Norm(final)=11.054 | 4581.7 samples/s | 71.6 steps/s
[Step=17450 Epoch=32.9] | Loss=0.00424 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.474 | L2-Norm(final)=11.050 | 4495.8 samples/s | 70.2 steps/s
[Step=17500 Epoch=33.0] | Loss=0.00403 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.472 | L2-Norm(final)=11.047 | 4548.5 samples/s | 71.1 steps/s
[Step=17550 Epoch=33.1] | Loss=0.00389 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.470 | L2-Norm(final)=11.044 | 5668.7 samples/s | 88.6 steps/s
[Step=17600 Epoch=33.2] | Loss=0.00372 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.468 | L2-Norm(final)=11.041 | 1964.2 samples/s | 30.7 steps/s
[Step=17650 Epoch=33.3] | Loss=0.00356 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.465 | L2-Norm(final)=11.039 | 4597.6 samples/s | 71.8 steps/s
[Step=17700 Epoch=33.4] | Loss=0.00342 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.460 | L2-Norm(final)=11.037 | 4519.3 samples/s | 70.6 steps/s
[Step=17750 Epoch=33.5] | Loss=0.00328 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.454 | L2-Norm(final)=11.035 | 4508.8 samples/s | 70.5 steps/s
[Step=17800 Epoch=33.6] | Loss=0.00316 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.447 | L2-Norm(final)=11.033 | 4561.8 samples/s | 71.3 steps/s
[Step=17850 Epoch=33.6] | Loss=0.00304 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.439 | L2-Norm(final)=11.031 | 4489.8 samples/s | 70.2 steps/s
[Step=17900 Epoch=33.7] | Loss=0.00293 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.430 | L2-Norm(final)=11.030 | 4628.9 samples/s | 72.3 steps/s
[Step=17950 Epoch=33.8] | Loss=0.00283 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.420 | L2-Norm(final)=11.029 | 4490.3 samples/s | 70.2 steps/s
[Step=18000 Epoch=33.9] | Loss=0.00276 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.410 | L2-Norm(final)=11.027 | 4590.5 samples/s | 71.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05331 | acc=0.9636 | tpr=0.9612 | fpr=0.0312 | 4590.6 samples/s | 17.9 steps/s
Avg test loss: 0.05592, Avg test acc: 0.96258, Avg tpr: 0.96118, Avg fpr: 0.03435, total FA: 268

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.96562 | acc=0.3040 | tpr=0.0164 | fpr=0.0716 | 4620.7 samples/s | 18.0 steps/s
Avg test loss: 10.00638, Avg test acc: 0.30243, Avg tpr: 0.01661, Avg fpr: 0.06897, total FA: 538

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.02363 | acc=0.1643 | tpr=0.6018 | fpr=0.8436 | 4510.4 samples/s | 17.6 steps/s
[Step= 100] | Loss=4.01297 | acc=0.1647 | tpr=0.6055 | fpr=0.8435 | 8539.0 samples/s | 33.4 steps/s
[Step= 150] | Loss=4.00270 | acc=0.1661 | tpr=0.6254 | fpr=0.8424 | 8868.9 samples/s | 34.6 steps/s
[Step= 200] | Loss=3.99575 | acc=0.1673 | tpr=0.6251 | fpr=0.8411 | 8309.2 samples/s | 32.5 steps/s
[Step= 250] | Loss=3.99596 | acc=0.1674 | tpr=0.6183 | fpr=0.8408 | 8411.6 samples/s | 32.9 steps/s
[Step= 300] | Loss=3.99442 | acc=0.1668 | tpr=0.6160 | fpr=0.8414 | 8798.5 samples/s | 34.4 steps/s
[Step= 350] | Loss=3.99366 | acc=0.1659 | tpr=0.6187 | fpr=0.8423 | 8548.2 samples/s | 33.4 steps/s
[Step= 400] | Loss=3.99779 | acc=0.1658 | tpr=0.6275 | fpr=0.8426 | 8311.7 samples/s | 32.5 steps/s
[Step= 450] | Loss=4.00409 | acc=0.1656 | tpr=0.6324 | fpr=0.8429 | 8520.5 samples/s | 33.3 steps/s
[Step= 500] | Loss=4.00218 | acc=0.1658 | tpr=0.6330 | fpr=0.8426 | 8392.9 samples/s | 32.8 steps/s
[Step= 550] | Loss=4.00343 | acc=0.1659 | tpr=0.6359 | fpr=0.8426 | 15215.6 samples/s | 59.4 steps/s
Avg test loss: 4.00543, Avg test acc: 0.16582, Avg tpr: 0.63590, Avg fpr: 0.84272, total FA: 117010

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13185 | acc=0.9821 | tpr=0.9735 | fpr=0.0177 | 4534.6 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.13937 | acc=0.9807 | tpr=0.9723 | fpr=0.0191 | 8413.8 samples/s | 32.9 steps/s
[Step= 150] | Loss=0.14477 | acc=0.9798 | tpr=0.9683 | fpr=0.0199 | 8802.6 samples/s | 34.4 steps/s
[Step= 200] | Loss=0.14649 | acc=0.9799 | tpr=0.9705 | fpr=0.0199 | 8373.1 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.14418 | acc=0.9800 | tpr=0.9642 | fpr=0.0197 | 8423.8 samples/s | 32.9 steps/s
[Step= 300] | Loss=0.14622 | acc=0.9797 | tpr=0.9651 | fpr=0.0200 | 8878.7 samples/s | 34.7 steps/s
[Step= 350] | Loss=0.14772 | acc=0.9795 | tpr=0.9656 | fpr=0.0203 | 8138.0 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.14887 | acc=0.9792 | tpr=0.9628 | fpr=0.0205 | 8634.4 samples/s | 33.7 steps/s
[Step= 450] | Loss=0.15258 | acc=0.9789 | tpr=0.9601 | fpr=0.0208 | 8831.9 samples/s | 34.5 steps/s
[Step= 500] | Loss=0.15106 | acc=0.9790 | tpr=0.9604 | fpr=0.0207 | 7994.3 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.15053 | acc=0.9790 | tpr=0.9598 | fpr=0.0206 | 15564.4 samples/s | 60.8 steps/s
Avg test loss: 0.15026, Avg test acc: 0.97906, Avg tpr: 0.95919, Avg fpr: 0.02058, total FA: 2858

server round 9/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=18001 Epoch=17.6] | Loss=0.13526 | Reg=0.00254 | acc=0.8594 | L2-Norm=15.933 | L2-Norm(final)=8.989 | 4591.5 samples/s | 71.7 steps/s
[Step=18050 Epoch=17.6] | Loss=0.11548 | Reg=0.00254 | acc=0.9531 | L2-Norm=15.943 | L2-Norm(final)=8.985 | 5042.2 samples/s | 78.8 steps/s
[Step=18100 Epoch=17.7] | Loss=0.11372 | Reg=0.00254 | acc=0.9375 | L2-Norm=15.944 | L2-Norm(final)=8.977 | 5536.5 samples/s | 86.5 steps/s
[Step=18150 Epoch=17.7] | Loss=0.11083 | Reg=0.00254 | acc=0.9219 | L2-Norm=15.945 | L2-Norm(final)=8.981 | 5506.4 samples/s | 86.0 steps/s
[Step=18200 Epoch=17.8] | Loss=0.10855 | Reg=0.00254 | acc=0.9062 | L2-Norm=15.945 | L2-Norm(final)=8.993 | 5355.7 samples/s | 83.7 steps/s
[Step=18250 Epoch=17.8] | Loss=0.10707 | Reg=0.00254 | acc=0.8750 | L2-Norm=15.945 | L2-Norm(final)=9.012 | 5568.6 samples/s | 87.0 steps/s
[Step=18300 Epoch=17.9] | Loss=0.10693 | Reg=0.00254 | acc=0.9219 | L2-Norm=15.945 | L2-Norm(final)=9.036 | 5680.1 samples/s | 88.8 steps/s
[Step=18350 Epoch=17.9] | Loss=0.10549 | Reg=0.00254 | acc=0.9219 | L2-Norm=15.945 | L2-Norm(final)=9.063 | 5724.7 samples/s | 89.4 steps/s
[Step=18400 Epoch=18.0] | Loss=0.10436 | Reg=0.00254 | acc=0.8906 | L2-Norm=15.945 | L2-Norm(final)=9.092 | 5647.3 samples/s | 88.2 steps/s
[Step=18450 Epoch=18.0] | Loss=0.10462 | Reg=0.00254 | acc=0.8438 | L2-Norm=15.945 | L2-Norm(final)=9.122 | 5695.3 samples/s | 89.0 steps/s
[Step=18500 Epoch=18.1] | Loss=0.10332 | Reg=0.00254 | acc=0.9531 | L2-Norm=15.946 | L2-Norm(final)=9.153 | 5645.8 samples/s | 88.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=18.1] | Loss=0.09569 | Reg=0.00254 | acc=0.9062 | L2-Norm=15.946 | L2-Norm(final)=9.478 | 4547.9 samples/s | 71.1 steps/s
[Step=18550 Epoch=18.1] | Loss=0.07246 | Reg=0.00260 | acc=0.9062 | L2-Norm=16.131 | L2-Norm(final)=9.480 | 4435.7 samples/s | 69.3 steps/s
[Step=18600 Epoch=18.2] | Loss=0.06287 | Reg=0.00265 | acc=0.9375 | L2-Norm=16.278 | L2-Norm(final)=9.460 | 4795.0 samples/s | 74.9 steps/s
[Step=18650 Epoch=18.2] | Loss=0.05758 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.377 | L2-Norm(final)=9.448 | 4799.0 samples/s | 75.0 steps/s
[Step=18700 Epoch=18.3] | Loss=0.05602 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.457 | L2-Norm(final)=9.437 | 4899.0 samples/s | 76.5 steps/s
[Step=18750 Epoch=18.3] | Loss=0.05441 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.530 | L2-Norm(final)=9.423 | 4879.9 samples/s | 76.2 steps/s
[Step=18800 Epoch=18.4] | Loss=0.05187 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.589 | L2-Norm(final)=9.412 | 4835.4 samples/s | 75.6 steps/s
[Step=18850 Epoch=18.4] | Loss=0.05066 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.639 | L2-Norm(final)=9.402 | 4771.0 samples/s | 74.5 steps/s
[Step=18900 Epoch=18.5] | Loss=0.04953 | Reg=0.00278 | acc=0.9531 | L2-Norm=16.684 | L2-Norm(final)=9.392 | 4763.7 samples/s | 74.4 steps/s
[Step=18950 Epoch=18.5] | Loss=0.04803 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.724 | L2-Norm(final)=9.383 | 4824.4 samples/s | 75.4 steps/s
[Step=19000 Epoch=18.6] | Loss=0.04744 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.762 | L2-Norm(final)=9.373 | 4798.4 samples/s | 75.0 steps/s
[Step=19050 Epoch=18.6] | Loss=0.04698 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.798 | L2-Norm(final)=9.365 | 4745.6 samples/s | 74.2 steps/s
[Step=19100 Epoch=18.6] | Loss=0.04609 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.830 | L2-Norm(final)=9.357 | 4825.1 samples/s | 75.4 steps/s
[Step=19150 Epoch=18.7] | Loss=0.04510 | Reg=0.00284 | acc=0.9531 | L2-Norm=16.860 | L2-Norm(final)=9.350 | 4757.0 samples/s | 74.3 steps/s
[Step=19200 Epoch=18.7] | Loss=0.04433 | Reg=0.00285 | acc=0.9375 | L2-Norm=16.887 | L2-Norm(final)=9.344 | 4794.7 samples/s | 74.9 steps/s
[Step=19250 Epoch=18.8] | Loss=0.04365 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.913 | L2-Norm(final)=9.339 | 4772.9 samples/s | 74.6 steps/s
[Step=19300 Epoch=18.8] | Loss=0.04295 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.937 | L2-Norm(final)=9.334 | 4790.5 samples/s | 74.9 steps/s
[Step=19350 Epoch=18.9] | Loss=0.04245 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.960 | L2-Norm(final)=9.329 | 4828.3 samples/s | 75.4 steps/s
[Step=19400 Epoch=18.9] | Loss=0.04225 | Reg=0.00289 | acc=0.9688 | L2-Norm=16.983 | L2-Norm(final)=9.324 | 4883.9 samples/s | 76.3 steps/s
[Step=19450 Epoch=19.0] | Loss=0.04176 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.005 | L2-Norm(final)=9.319 | 4870.4 samples/s | 76.1 steps/s
[Step=19500 Epoch=19.0] | Loss=0.04142 | Reg=0.00290 | acc=0.9375 | L2-Norm=17.026 | L2-Norm(final)=9.315 | 5243.6 samples/s | 81.9 steps/s
[Step=19550 Epoch=19.1] | Loss=0.04074 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.047 | L2-Norm(final)=9.310 | 2117.5 samples/s | 33.1 steps/s
[Step=19600 Epoch=19.1] | Loss=0.03993 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.066 | L2-Norm(final)=9.306 | 4866.7 samples/s | 76.0 steps/s
[Step=19650 Epoch=19.2] | Loss=0.03931 | Reg=0.00292 | acc=0.9688 | L2-Norm=17.085 | L2-Norm(final)=9.302 | 4660.8 samples/s | 72.8 steps/s
[Step=19700 Epoch=19.2] | Loss=0.03889 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.102 | L2-Norm(final)=9.298 | 4813.8 samples/s | 75.2 steps/s
[Step=19750 Epoch=19.3] | Loss=0.03827 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.120 | L2-Norm(final)=9.295 | 4799.6 samples/s | 75.0 steps/s
[Step=19800 Epoch=19.3] | Loss=0.03789 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.136 | L2-Norm(final)=9.291 | 4785.4 samples/s | 74.8 steps/s
[Step=19850 Epoch=19.4] | Loss=0.03744 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.153 | L2-Norm(final)=9.288 | 4740.1 samples/s | 74.1 steps/s
[Step=19900 Epoch=19.4] | Loss=0.03697 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.170 | L2-Norm(final)=9.285 | 4816.4 samples/s | 75.3 steps/s
[Step=19950 Epoch=19.5] | Loss=0.03687 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.187 | L2-Norm(final)=9.282 | 4837.5 samples/s | 75.6 steps/s
[Step=20000 Epoch=19.5] | Loss=0.03663 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.204 | L2-Norm(final)=9.279 | 4698.5 samples/s | 73.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step20000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00100, len=1
[Step=18001 Epoch=33.9] | Loss=0.00235 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=10.985 | 4032.8 samples/s | 63.0 steps/s
[Step=18050 Epoch=34.0] | Loss=0.00672 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.929 | L2-Norm(final)=10.990 | 5237.6 samples/s | 81.8 steps/s
[Step=18100 Epoch=34.1] | Loss=0.00575 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.011 | 5358.5 samples/s | 83.7 steps/s
[Step=18150 Epoch=34.2] | Loss=0.00536 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.034 | 5318.0 samples/s | 83.1 steps/s
[Step=18200 Epoch=34.3] | Loss=0.00538 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.059 | 5247.8 samples/s | 82.0 steps/s
[Step=18250 Epoch=34.4] | Loss=0.00532 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.083 | 5188.7 samples/s | 81.1 steps/s
[Step=18300 Epoch=34.5] | Loss=0.00520 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.109 | 5212.3 samples/s | 81.4 steps/s
[Step=18350 Epoch=34.6] | Loss=0.00509 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.135 | 5161.5 samples/s | 80.6 steps/s
[Step=18400 Epoch=34.7] | Loss=0.00517 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.928 | L2-Norm(final)=11.161 | 5220.2 samples/s | 81.6 steps/s
[Step=18450 Epoch=34.8] | Loss=0.00530 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.928 | L2-Norm(final)=11.187 | 5227.5 samples/s | 81.7 steps/s
[Step=18500 Epoch=34.9] | Loss=0.00522 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.928 | L2-Norm(final)=11.213 | 5165.8 samples/s | 80.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=34.9] | Loss=0.00045 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.927 | L2-Norm(final)=11.460 | 4346.5 samples/s | 67.9 steps/s
[Step=18550 Epoch=35.0] | Loss=0.00112 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.924 | L2-Norm(final)=11.475 | 4237.7 samples/s | 66.2 steps/s
[Step=18600 Epoch=35.1] | Loss=0.00325 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.933 | L2-Norm(final)=11.478 | 4568.2 samples/s | 71.4 steps/s
[Step=18650 Epoch=35.2] | Loss=0.00435 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.018 | L2-Norm(final)=11.466 | 4514.7 samples/s | 70.5 steps/s
[Step=18700 Epoch=35.2] | Loss=0.00432 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.094 | L2-Norm(final)=11.447 | 4537.1 samples/s | 70.9 steps/s
[Step=18750 Epoch=35.3] | Loss=0.00437 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=11.434 | 4397.7 samples/s | 68.7 steps/s
[Step=18800 Epoch=35.4] | Loss=0.00487 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.184 | L2-Norm(final)=11.420 | 4564.0 samples/s | 71.3 steps/s
[Step=18850 Epoch=35.5] | Loss=0.00498 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.219 | L2-Norm(final)=11.407 | 4538.5 samples/s | 70.9 steps/s
[Step=18900 Epoch=35.6] | Loss=0.00468 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.244 | L2-Norm(final)=11.396 | 4587.1 samples/s | 71.7 steps/s
[Step=18950 Epoch=35.7] | Loss=0.00423 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=11.389 | 4526.5 samples/s | 70.7 steps/s
[Step=19000 Epoch=35.8] | Loss=0.00382 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.267 | L2-Norm(final)=11.384 | 4569.5 samples/s | 71.4 steps/s
[Step=19050 Epoch=35.9] | Loss=0.00354 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.270 | L2-Norm(final)=11.379 | 2144.0 samples/s | 33.5 steps/s
[Step=19100 Epoch=36.0] | Loss=0.00325 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.269 | L2-Norm(final)=11.376 | 4478.5 samples/s | 70.0 steps/s
[Step=19150 Epoch=36.1] | Loss=0.00302 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.265 | L2-Norm(final)=11.374 | 4533.1 samples/s | 70.8 steps/s
[Step=19200 Epoch=36.2] | Loss=0.00280 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.259 | L2-Norm(final)=11.371 | 4563.0 samples/s | 71.3 steps/s
[Step=19250 Epoch=36.3] | Loss=0.00262 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.250 | L2-Norm(final)=11.370 | 4584.2 samples/s | 71.6 steps/s
[Step=19300 Epoch=36.4] | Loss=0.00245 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=11.368 | 4605.4 samples/s | 72.0 steps/s
[Step=19350 Epoch=36.5] | Loss=0.00235 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.228 | L2-Norm(final)=11.367 | 4494.5 samples/s | 70.2 steps/s
[Step=19400 Epoch=36.6] | Loss=0.00224 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=11.366 | 4545.0 samples/s | 71.0 steps/s
[Step=19450 Epoch=36.7] | Loss=0.00220 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.206 | L2-Norm(final)=11.364 | 4554.4 samples/s | 71.2 steps/s
[Step=19500 Epoch=36.8] | Loss=0.00220 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.196 | L2-Norm(final)=11.363 | 4620.7 samples/s | 72.2 steps/s
[Step=19550 Epoch=36.9] | Loss=0.00216 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.188 | L2-Norm(final)=11.361 | 5613.1 samples/s | 87.7 steps/s
[Step=19600 Epoch=36.9] | Loss=0.00252 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.182 | L2-Norm(final)=11.359 | 1960.5 samples/s | 30.6 steps/s
[Step=19650 Epoch=37.0] | Loss=0.00277 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.186 | L2-Norm(final)=11.354 | 4635.0 samples/s | 72.4 steps/s
[Step=19700 Epoch=37.1] | Loss=0.00298 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.195 | L2-Norm(final)=11.348 | 4573.8 samples/s | 71.5 steps/s
[Step=19750 Epoch=37.2] | Loss=0.00305 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.208 | L2-Norm(final)=11.342 | 4505.8 samples/s | 70.4 steps/s
[Step=19800 Epoch=37.3] | Loss=0.00298 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.220 | L2-Norm(final)=11.336 | 4580.3 samples/s | 71.6 steps/s
[Step=19850 Epoch=37.4] | Loss=0.00302 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.232 | L2-Norm(final)=11.330 | 4582.8 samples/s | 71.6 steps/s
[Step=19900 Epoch=37.5] | Loss=0.00301 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=11.324 | 4501.8 samples/s | 70.3 steps/s
[Step=19950 Epoch=37.6] | Loss=0.00300 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.257 | L2-Norm(final)=11.318 | 4523.3 samples/s | 70.7 steps/s
[Step=20000 Epoch=37.7] | Loss=0.00299 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.269 | L2-Norm(final)=11.312 | 4566.0 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05314 | acc=0.9633 | tpr=0.9727 | fpr=0.0572 | 4537.9 samples/s | 17.7 steps/s
Avg test loss: 0.05653, Avg test acc: 0.96302, Avg tpr: 0.97237, Avg fpr: 0.05756, total FA: 449

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.97775 | acc=0.3004 | tpr=0.0450 | fpr=0.1449 | 4512.0 samples/s | 17.6 steps/s
Avg test loss: 6.97678, Avg test acc: 0.29954, Avg tpr: 0.04360, Avg fpr: 0.13755, total FA: 1073

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.95043 | acc=0.1279 | tpr=0.6637 | fpr=0.8817 | 4560.4 samples/s | 17.8 steps/s
[Step= 100] | Loss=4.93094 | acc=0.1291 | tpr=0.6759 | fpr=0.8811 | 8680.1 samples/s | 33.9 steps/s
[Step= 150] | Loss=4.91685 | acc=0.1293 | tpr=0.6844 | fpr=0.8809 | 8883.0 samples/s | 34.7 steps/s
[Step= 200] | Loss=4.90911 | acc=0.1296 | tpr=0.6863 | fpr=0.8805 | 8669.5 samples/s | 33.9 steps/s
[Step= 250] | Loss=4.91443 | acc=0.1300 | tpr=0.6961 | fpr=0.8803 | 8090.5 samples/s | 31.6 steps/s
[Step= 300] | Loss=4.91340 | acc=0.1296 | tpr=0.7004 | fpr=0.8808 | 8868.4 samples/s | 34.6 steps/s
[Step= 350] | Loss=4.91115 | acc=0.1291 | tpr=0.6982 | fpr=0.8813 | 8418.5 samples/s | 32.9 steps/s
[Step= 400] | Loss=4.91166 | acc=0.1292 | tpr=0.7035 | fpr=0.8812 | 8623.3 samples/s | 33.7 steps/s
[Step= 450] | Loss=4.91519 | acc=0.1291 | tpr=0.7055 | fpr=0.8813 | 8469.2 samples/s | 33.1 steps/s
[Step= 500] | Loss=4.91215 | acc=0.1295 | tpr=0.7040 | fpr=0.8808 | 8396.4 samples/s | 32.8 steps/s
[Step= 550] | Loss=4.91350 | acc=0.1298 | tpr=0.7031 | fpr=0.8806 | 14999.6 samples/s | 58.6 steps/s
Avg test loss: 4.91564, Avg test acc: 0.12969, Avg tpr: 0.70325, Avg fpr: 0.88073, total FA: 122288

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.17582 | acc=0.9772 | tpr=0.9735 | fpr=0.0227 | 4607.6 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.18109 | acc=0.9761 | tpr=0.9851 | fpr=0.0240 | 9324.1 samples/s | 36.4 steps/s
[Step= 150] | Loss=0.18596 | acc=0.9749 | tpr=0.9827 | fpr=0.0252 | 7988.4 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.18536 | acc=0.9749 | tpr=0.9847 | fpr=0.0253 | 8612.3 samples/s | 33.6 steps/s
[Step= 250] | Loss=0.18497 | acc=0.9748 | tpr=0.9808 | fpr=0.0253 | 8281.7 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.18680 | acc=0.9741 | tpr=0.9789 | fpr=0.0260 | 8649.5 samples/s | 33.8 steps/s
[Step= 350] | Loss=0.18966 | acc=0.9741 | tpr=0.9781 | fpr=0.0260 | 8450.0 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.19038 | acc=0.9741 | tpr=0.9754 | fpr=0.0259 | 8568.6 samples/s | 33.5 steps/s
[Step= 450] | Loss=0.19451 | acc=0.9737 | tpr=0.9732 | fpr=0.0263 | 8608.8 samples/s | 33.6 steps/s
[Step= 500] | Loss=0.19361 | acc=0.9736 | tpr=0.9722 | fpr=0.0264 | 8310.0 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.19236 | acc=0.9737 | tpr=0.9713 | fpr=0.0263 | 15773.0 samples/s | 61.6 steps/s
Avg test loss: 0.19203, Avg test acc: 0.97367, Avg tpr: 0.97108, Avg fpr: 0.02628, total FA: 3649

server round 10/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=20001 Epoch=19.5] | Loss=0.08033 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.332 | L2-Norm(final)=9.187 | 4415.1 samples/s | 69.0 steps/s
[Step=20050 Epoch=19.6] | Loss=0.11651 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.336 | L2-Norm(final)=9.211 | 5255.4 samples/s | 82.1 steps/s
[Step=20100 Epoch=19.6] | Loss=0.10095 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.337 | L2-Norm(final)=9.240 | 5481.4 samples/s | 85.6 steps/s
[Step=20150 Epoch=19.7] | Loss=0.09381 | Reg=0.00267 | acc=0.9219 | L2-Norm=16.337 | L2-Norm(final)=9.264 | 5768.4 samples/s | 90.1 steps/s
[Step=20200 Epoch=19.7] | Loss=0.09221 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.337 | L2-Norm(final)=9.287 | 5634.5 samples/s | 88.0 steps/s
[Step=20250 Epoch=19.8] | Loss=0.09030 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.337 | L2-Norm(final)=9.308 | 5478.8 samples/s | 85.6 steps/s
[Step=20300 Epoch=19.8] | Loss=0.08889 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.337 | L2-Norm(final)=9.327 | 5684.5 samples/s | 88.8 steps/s
[Step=20350 Epoch=19.9] | Loss=0.08793 | Reg=0.00267 | acc=0.9375 | L2-Norm=16.337 | L2-Norm(final)=9.345 | 5798.4 samples/s | 90.6 steps/s
[Step=20400 Epoch=19.9] | Loss=0.08709 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.337 | L2-Norm(final)=9.364 | 5537.8 samples/s | 86.5 steps/s
[Step=20450 Epoch=20.0] | Loss=0.08621 | Reg=0.00267 | acc=0.9062 | L2-Norm=16.337 | L2-Norm(final)=9.383 | 5620.9 samples/s | 87.8 steps/s
[Step=20500 Epoch=20.0] | Loss=0.08533 | Reg=0.00267 | acc=0.9062 | L2-Norm=16.337 | L2-Norm(final)=9.402 | 5522.6 samples/s | 86.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=20.0] | Loss=0.09955 | Reg=0.00267 | acc=0.9062 | L2-Norm=16.337 | L2-Norm(final)=9.586 | 4316.8 samples/s | 67.4 steps/s
[Step=20550 Epoch=20.1] | Loss=0.06454 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.387 | L2-Norm(final)=9.592 | 4642.3 samples/s | 72.5 steps/s
[Step=20600 Epoch=20.1] | Loss=0.05352 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.430 | L2-Norm(final)=9.586 | 4827.0 samples/s | 75.4 steps/s
[Step=20650 Epoch=20.2] | Loss=0.04583 | Reg=0.00271 | acc=0.9375 | L2-Norm=16.459 | L2-Norm(final)=9.583 | 4784.7 samples/s | 74.8 steps/s
[Step=20700 Epoch=20.2] | Loss=0.04270 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.482 | L2-Norm(final)=9.580 | 4779.0 samples/s | 74.7 steps/s
[Step=20750 Epoch=20.3] | Loss=0.04140 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.499 | L2-Norm(final)=9.577 | 4791.1 samples/s | 74.9 steps/s
[Step=20800 Epoch=20.3] | Loss=0.03915 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.514 | L2-Norm(final)=9.576 | 4740.6 samples/s | 74.1 steps/s
[Step=20850 Epoch=20.4] | Loss=0.03791 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.528 | L2-Norm(final)=9.574 | 4766.1 samples/s | 74.5 steps/s
[Step=20900 Epoch=20.4] | Loss=0.03638 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=9.573 | 4798.1 samples/s | 75.0 steps/s
[Step=20950 Epoch=20.5] | Loss=0.03630 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.549 | L2-Norm(final)=9.572 | 4846.4 samples/s | 75.7 steps/s
[Step=21000 Epoch=20.5] | Loss=0.03517 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.558 | L2-Norm(final)=9.570 | 4794.7 samples/s | 74.9 steps/s
[Step=21050 Epoch=20.6] | Loss=0.03431 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.565 | L2-Norm(final)=9.568 | 4829.4 samples/s | 75.5 steps/s
[Step=21100 Epoch=20.6] | Loss=0.03363 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.572 | L2-Norm(final)=9.567 | 4808.6 samples/s | 75.1 steps/s
[Step=21150 Epoch=20.6] | Loss=0.03297 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.578 | L2-Norm(final)=9.565 | 4830.2 samples/s | 75.5 steps/s
[Step=21200 Epoch=20.7] | Loss=0.03229 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.584 | L2-Norm(final)=9.564 | 4770.6 samples/s | 74.5 steps/s
[Step=21250 Epoch=20.7] | Loss=0.03156 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.589 | L2-Norm(final)=9.563 | 4743.3 samples/s | 74.1 steps/s
[Step=21300 Epoch=20.8] | Loss=0.03102 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.594 | L2-Norm(final)=9.561 | 4788.6 samples/s | 74.8 steps/s
[Step=21350 Epoch=20.8] | Loss=0.03030 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.600 | L2-Norm(final)=9.560 | 4814.1 samples/s | 75.2 steps/s
[Step=21400 Epoch=20.9] | Loss=0.03003 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.605 | L2-Norm(final)=9.559 | 4778.3 samples/s | 74.7 steps/s
[Step=21450 Epoch=20.9] | Loss=0.02951 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.609 | L2-Norm(final)=9.558 | 4838.7 samples/s | 75.6 steps/s
[Step=21500 Epoch=21.0] | Loss=0.02952 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.614 | L2-Norm(final)=9.556 | 5191.4 samples/s | 81.1 steps/s
[Step=21550 Epoch=21.0] | Loss=0.02901 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.618 | L2-Norm(final)=9.555 | 2150.2 samples/s | 33.6 steps/s
[Step=21600 Epoch=21.1] | Loss=0.02833 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=9.554 | 4795.4 samples/s | 74.9 steps/s
[Step=21650 Epoch=21.1] | Loss=0.02793 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.627 | L2-Norm(final)=9.553 | 4782.2 samples/s | 74.7 steps/s
[Step=21700 Epoch=21.2] | Loss=0.02734 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.631 | L2-Norm(final)=9.553 | 4763.9 samples/s | 74.4 steps/s
[Step=21750 Epoch=21.2] | Loss=0.02706 | Reg=0.00277 | acc=0.9531 | L2-Norm=16.634 | L2-Norm(final)=9.552 | 4768.2 samples/s | 74.5 steps/s
[Step=21800 Epoch=21.3] | Loss=0.02680 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.638 | L2-Norm(final)=9.551 | 4738.3 samples/s | 74.0 steps/s
[Step=21850 Epoch=21.3] | Loss=0.02640 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.641 | L2-Norm(final)=9.551 | 4776.4 samples/s | 74.6 steps/s
[Step=21900 Epoch=21.4] | Loss=0.02604 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.644 | L2-Norm(final)=9.550 | 4846.5 samples/s | 75.7 steps/s
[Step=21950 Epoch=21.4] | Loss=0.02568 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.647 | L2-Norm(final)=9.549 | 4792.8 samples/s | 74.9 steps/s
[Step=22000 Epoch=21.5] | Loss=0.02560 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.650 | L2-Norm(final)=9.549 | 4817.8 samples/s | 75.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step22000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=20001 Epoch=37.7] | Loss=0.00040 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.332 | L2-Norm(final)=11.130 | 4249.4 samples/s | 66.4 steps/s
[Step=20050 Epoch=37.8] | Loss=0.00378 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.136 | 5025.3 samples/s | 78.5 steps/s
[Step=20100 Epoch=37.9] | Loss=0.00413 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.330 | L2-Norm(final)=11.141 | 5288.4 samples/s | 82.6 steps/s
[Step=20150 Epoch=38.0] | Loss=0.00409 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.146 | 5418.8 samples/s | 84.7 steps/s
[Step=20200 Epoch=38.1] | Loss=0.00390 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.149 | 5318.4 samples/s | 83.1 steps/s
[Step=20250 Epoch=38.2] | Loss=0.00418 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.330 | L2-Norm(final)=11.153 | 5318.8 samples/s | 83.1 steps/s
[Step=20300 Epoch=38.3] | Loss=0.00430 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.330 | L2-Norm(final)=11.156 | 5242.0 samples/s | 81.9 steps/s
[Step=20350 Epoch=38.4] | Loss=0.00417 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.159 | 5306.9 samples/s | 82.9 steps/s
[Step=20400 Epoch=38.5] | Loss=0.00398 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.163 | 5220.9 samples/s | 81.6 steps/s
[Step=20450 Epoch=38.5] | Loss=0.00412 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.168 | 5182.1 samples/s | 81.0 steps/s
[Step=20500 Epoch=38.6] | Loss=0.00405 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=11.172 | 5268.7 samples/s | 82.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=38.6] | Loss=0.00101 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.329 | L2-Norm(final)=11.219 | 4117.7 samples/s | 64.3 steps/s
[Step=20550 Epoch=38.7] | Loss=0.00194 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.303 | L2-Norm(final)=11.226 | 4465.1 samples/s | 69.8 steps/s
[Step=20600 Epoch=38.8] | Loss=0.00115 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.286 | L2-Norm(final)=11.230 | 4632.9 samples/s | 72.4 steps/s
[Step=20650 Epoch=38.9] | Loss=0.00079 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.268 | L2-Norm(final)=11.231 | 4685.2 samples/s | 73.2 steps/s
[Step=20700 Epoch=39.0] | Loss=0.00063 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.251 | L2-Norm(final)=11.233 | 4666.1 samples/s | 72.9 steps/s
[Step=20750 Epoch=39.1] | Loss=0.00052 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=11.234 | 4681.5 samples/s | 73.1 steps/s
[Step=20800 Epoch=39.2] | Loss=0.00044 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.218 | L2-Norm(final)=11.236 | 4619.5 samples/s | 72.2 steps/s
[Step=20850 Epoch=39.3] | Loss=0.00038 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.203 | L2-Norm(final)=11.237 | 4535.3 samples/s | 70.9 steps/s
[Step=20900 Epoch=39.4] | Loss=0.00034 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.188 | L2-Norm(final)=11.238 | 4533.9 samples/s | 70.8 steps/s
[Step=20950 Epoch=39.5] | Loss=0.00030 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=11.239 | 4560.8 samples/s | 71.3 steps/s
[Step=21000 Epoch=39.6] | Loss=0.00027 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.157 | L2-Norm(final)=11.239 | 4572.5 samples/s | 71.4 steps/s
[Step=21050 Epoch=39.7] | Loss=0.00025 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=11.240 | 2131.6 samples/s | 33.3 steps/s
[Step=21100 Epoch=39.8] | Loss=0.00023 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=11.241 | 4619.9 samples/s | 72.2 steps/s
[Step=21150 Epoch=39.9] | Loss=0.00021 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=11.241 | 4461.2 samples/s | 69.7 steps/s
[Step=21200 Epoch=40.0] | Loss=0.00019 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.097 | L2-Norm(final)=11.241 | 4543.6 samples/s | 71.0 steps/s
[Step=21250 Epoch=40.1] | Loss=0.00018 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=11.242 | 4531.0 samples/s | 70.8 steps/s
[Step=21300 Epoch=40.2] | Loss=0.00017 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.067 | L2-Norm(final)=11.242 | 4536.9 samples/s | 70.9 steps/s
[Step=21350 Epoch=40.2] | Loss=0.00016 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.053 | L2-Norm(final)=11.242 | 4549.5 samples/s | 71.1 steps/s
[Step=21400 Epoch=40.3] | Loss=0.00015 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.038 | L2-Norm(final)=11.243 | 4527.8 samples/s | 70.7 steps/s
[Step=21450 Epoch=40.4] | Loss=0.00014 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=11.243 | 4562.0 samples/s | 71.3 steps/s
[Step=21500 Epoch=40.5] | Loss=0.00014 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=11.243 | 4547.7 samples/s | 71.1 steps/s
[Step=21550 Epoch=40.6] | Loss=0.00013 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.995 | L2-Norm(final)=11.243 | 5875.5 samples/s | 91.8 steps/s
[Step=21600 Epoch=40.7] | Loss=0.00012 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.981 | L2-Norm(final)=11.244 | 1961.3 samples/s | 30.6 steps/s
[Step=21650 Epoch=40.8] | Loss=0.00012 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=11.244 | 4579.4 samples/s | 71.6 steps/s
[Step=21700 Epoch=40.9] | Loss=0.00011 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.952 | L2-Norm(final)=11.244 | 4629.1 samples/s | 72.3 steps/s
[Step=21750 Epoch=41.0] | Loss=0.00011 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.938 | L2-Norm(final)=11.244 | 4587.1 samples/s | 71.7 steps/s
[Step=21800 Epoch=41.1] | Loss=0.00010 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.924 | L2-Norm(final)=11.244 | 4522.7 samples/s | 70.7 steps/s
[Step=21850 Epoch=41.2] | Loss=0.00010 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.910 | L2-Norm(final)=11.245 | 4465.3 samples/s | 69.8 steps/s
[Step=21900 Epoch=41.3] | Loss=0.00010 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.896 | L2-Norm(final)=11.245 | 4551.5 samples/s | 71.1 steps/s
[Step=21950 Epoch=41.4] | Loss=0.00009 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.882 | L2-Norm(final)=11.245 | 4617.9 samples/s | 72.2 steps/s
[Step=22000 Epoch=41.5] | Loss=0.00009 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=11.245 | 4554.0 samples/s | 71.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.04736 | acc=0.9710 | tpr=0.9764 | fpr=0.0406 | 4588.2 samples/s | 17.9 steps/s
Avg test loss: 0.05232, Avg test acc: 0.96879, Avg tpr: 0.97465, Avg fpr: 0.04410, total FA: 344

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.82178 | acc=0.2986 | tpr=0.0196 | fpr=0.0956 | 4591.7 samples/s | 17.9 steps/s
Avg test loss: 6.83828, Avg test acc: 0.29762, Avg tpr: 0.01900, Avg fpr: 0.08960, total FA: 699

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.40002 | acc=0.1459 | tpr=0.5442 | fpr=0.8613 | 4638.2 samples/s | 18.1 steps/s
[Step= 100] | Loss=4.38381 | acc=0.1460 | tpr=0.5778 | fpr=0.8621 | 8128.3 samples/s | 31.8 steps/s
[Step= 150] | Loss=4.37881 | acc=0.1463 | tpr=0.5893 | fpr=0.8618 | 8488.9 samples/s | 33.2 steps/s
[Step= 200] | Loss=4.36796 | acc=0.1477 | tpr=0.6055 | fpr=0.8607 | 8540.8 samples/s | 33.4 steps/s
[Step= 250] | Loss=4.36742 | acc=0.1488 | tpr=0.6131 | fpr=0.8596 | 8736.2 samples/s | 34.1 steps/s
[Step= 300] | Loss=4.36382 | acc=0.1487 | tpr=0.6153 | fpr=0.8598 | 8246.6 samples/s | 32.2 steps/s
[Step= 350] | Loss=4.36024 | acc=0.1481 | tpr=0.6187 | fpr=0.8605 | 8384.8 samples/s | 32.8 steps/s
[Step= 400] | Loss=4.35779 | acc=0.1485 | tpr=0.6236 | fpr=0.8601 | 8782.9 samples/s | 34.3 steps/s
[Step= 450] | Loss=4.36208 | acc=0.1484 | tpr=0.6212 | fpr=0.8601 | 8068.6 samples/s | 31.5 steps/s
[Step= 500] | Loss=4.36178 | acc=0.1485 | tpr=0.6185 | fpr=0.8600 | 9132.2 samples/s | 35.7 steps/s
[Step= 550] | Loss=4.36241 | acc=0.1486 | tpr=0.6172 | fpr=0.8599 | 14044.6 samples/s | 54.9 steps/s
Avg test loss: 4.36328, Avg test acc: 0.14842, Avg tpr: 0.61688, Avg fpr: 0.86009, total FA: 119422

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13296 | acc=0.9817 | tpr=0.9602 | fpr=0.0179 | 4548.7 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.13897 | acc=0.9807 | tpr=0.9574 | fpr=0.0188 | 8325.8 samples/s | 32.5 steps/s
[Step= 150] | Loss=0.14229 | acc=0.9802 | tpr=0.9611 | fpr=0.0195 | 8941.0 samples/s | 34.9 steps/s
[Step= 200] | Loss=0.14157 | acc=0.9803 | tpr=0.9661 | fpr=0.0195 | 8644.6 samples/s | 33.8 steps/s
[Step= 250] | Loss=0.13967 | acc=0.9805 | tpr=0.9624 | fpr=0.0191 | 8239.8 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.14191 | acc=0.9803 | tpr=0.9622 | fpr=0.0194 | 8414.9 samples/s | 32.9 steps/s
[Step= 350] | Loss=0.14395 | acc=0.9800 | tpr=0.9618 | fpr=0.0196 | 8561.8 samples/s | 33.4 steps/s
[Step= 400] | Loss=0.14506 | acc=0.9800 | tpr=0.9595 | fpr=0.0196 | 8635.8 samples/s | 33.7 steps/s
[Step= 450] | Loss=0.14860 | acc=0.9796 | tpr=0.9567 | fpr=0.0200 | 8474.2 samples/s | 33.1 steps/s
[Step= 500] | Loss=0.14772 | acc=0.9796 | tpr=0.9568 | fpr=0.0200 | 8746.1 samples/s | 34.2 steps/s
[Step= 550] | Loss=0.14645 | acc=0.9798 | tpr=0.9554 | fpr=0.0198 | 14691.4 samples/s | 57.4 steps/s
Avg test loss: 0.14630, Avg test acc: 0.97978, Avg tpr: 0.95523, Avg fpr: 0.01977, total FA: 2745

server round 11/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=22001 Epoch=21.5] | Loss=0.03072 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.891 | L2-Norm(final)=9.524 | 4198.5 samples/s | 65.6 steps/s
[Step=22050 Epoch=21.5] | Loss=0.03594 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.891 | L2-Norm(final)=9.530 | 5435.1 samples/s | 84.9 steps/s
[Step=22100 Epoch=21.6] | Loss=0.03508 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.891 | L2-Norm(final)=9.541 | 5475.4 samples/s | 85.6 steps/s
[Step=22150 Epoch=21.6] | Loss=0.03226 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=9.556 | 5528.6 samples/s | 86.4 steps/s
[Step=22200 Epoch=21.7] | Loss=0.03116 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.892 | L2-Norm(final)=9.571 | 5437.3 samples/s | 85.0 steps/s
[Step=22250 Epoch=21.7] | Loss=0.03100 | Reg=0.00253 | acc=0.9219 | L2-Norm=15.892 | L2-Norm(final)=9.586 | 5505.0 samples/s | 86.0 steps/s
[Step=22300 Epoch=21.8] | Loss=0.03075 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.892 | L2-Norm(final)=9.601 | 5550.7 samples/s | 86.7 steps/s
[Step=22350 Epoch=21.8] | Loss=0.03067 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.892 | L2-Norm(final)=9.616 | 5424.6 samples/s | 84.8 steps/s
[Step=22400 Epoch=21.9] | Loss=0.03028 | Reg=0.00253 | acc=0.9531 | L2-Norm=15.892 | L2-Norm(final)=9.631 | 5496.2 samples/s | 85.9 steps/s
[Step=22450 Epoch=21.9] | Loss=0.03022 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.892 | L2-Norm(final)=9.645 | 5552.6 samples/s | 86.8 steps/s
[Step=22500 Epoch=22.0] | Loss=0.03014 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.892 | L2-Norm(final)=9.660 | 5542.6 samples/s | 86.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=22.0] | Loss=0.03293 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.892 | L2-Norm(final)=9.802 | 4281.0 samples/s | 66.9 steps/s
[Step=22550 Epoch=22.0] | Loss=0.02448 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.917 | L2-Norm(final)=9.809 | 4670.5 samples/s | 73.0 steps/s
[Step=22600 Epoch=22.1] | Loss=0.02401 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=9.809 | 4785.2 samples/s | 74.8 steps/s
[Step=22650 Epoch=22.1] | Loss=0.02517 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.974 | L2-Norm(final)=9.805 | 4777.6 samples/s | 74.7 steps/s
[Step=22700 Epoch=22.2] | Loss=0.02452 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=9.801 | 4761.2 samples/s | 74.4 steps/s
[Step=22750 Epoch=22.2] | Loss=0.02322 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.010 | L2-Norm(final)=9.799 | 4751.3 samples/s | 74.2 steps/s
[Step=22800 Epoch=22.3] | Loss=0.02309 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.024 | L2-Norm(final)=9.798 | 4771.5 samples/s | 74.6 steps/s
[Step=22850 Epoch=22.3] | Loss=0.02284 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.037 | L2-Norm(final)=9.797 | 4853.4 samples/s | 75.8 steps/s
[Step=22900 Epoch=22.4] | Loss=0.02311 | Reg=0.00258 | acc=0.9531 | L2-Norm=16.048 | L2-Norm(final)=9.795 | 4809.2 samples/s | 75.1 steps/s
[Step=22950 Epoch=22.4] | Loss=0.02324 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.059 | L2-Norm(final)=9.793 | 4822.5 samples/s | 75.4 steps/s
[Step=23000 Epoch=22.5] | Loss=0.02312 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.070 | L2-Norm(final)=9.792 | 4819.4 samples/s | 75.3 steps/s
[Step=23050 Epoch=22.5] | Loss=0.02296 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.079 | L2-Norm(final)=9.791 | 4786.0 samples/s | 74.8 steps/s
[Step=23100 Epoch=22.6] | Loss=0.02288 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.088 | L2-Norm(final)=9.791 | 4759.8 samples/s | 74.4 steps/s
[Step=23150 Epoch=22.6] | Loss=0.02313 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.096 | L2-Norm(final)=9.790 | 4778.1 samples/s | 74.7 steps/s
[Step=23200 Epoch=22.7] | Loss=0.02342 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.105 | L2-Norm(final)=9.788 | 4845.5 samples/s | 75.7 steps/s
[Step=23250 Epoch=22.7] | Loss=0.02338 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.113 | L2-Norm(final)=9.786 | 4794.2 samples/s | 74.9 steps/s
[Step=23300 Epoch=22.7] | Loss=0.02317 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.122 | L2-Norm(final)=9.785 | 4785.6 samples/s | 74.8 steps/s
[Step=23350 Epoch=22.8] | Loss=0.02288 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.130 | L2-Norm(final)=9.784 | 4778.2 samples/s | 74.7 steps/s
[Step=23400 Epoch=22.8] | Loss=0.02273 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.137 | L2-Norm(final)=9.783 | 4796.0 samples/s | 74.9 steps/s
[Step=23450 Epoch=22.9] | Loss=0.02267 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=9.782 | 4853.0 samples/s | 75.8 steps/s
[Step=23500 Epoch=22.9] | Loss=0.02270 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.151 | L2-Norm(final)=9.781 | 5151.7 samples/s | 80.5 steps/s
[Step=23550 Epoch=23.0] | Loss=0.02266 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.159 | L2-Norm(final)=9.780 | 2102.1 samples/s | 32.8 steps/s
[Step=23600 Epoch=23.0] | Loss=0.02244 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.166 | L2-Norm(final)=9.779 | 4941.8 samples/s | 77.2 steps/s
[Step=23650 Epoch=23.1] | Loss=0.02207 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.173 | L2-Norm(final)=9.778 | 4859.0 samples/s | 75.9 steps/s
[Step=23700 Epoch=23.1] | Loss=0.02182 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.179 | L2-Norm(final)=9.778 | 4904.1 samples/s | 76.6 steps/s
[Step=23750 Epoch=23.2] | Loss=0.02180 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.186 | L2-Norm(final)=9.777 | 4896.7 samples/s | 76.5 steps/s
[Step=23800 Epoch=23.2] | Loss=0.02170 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.192 | L2-Norm(final)=9.776 | 4871.1 samples/s | 76.1 steps/s
[Step=23850 Epoch=23.3] | Loss=0.02145 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.199 | L2-Norm(final)=9.776 | 4923.9 samples/s | 76.9 steps/s
[Step=23900 Epoch=23.3] | Loss=0.02124 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.206 | L2-Norm(final)=9.776 | 4913.5 samples/s | 76.8 steps/s
[Step=23950 Epoch=23.4] | Loss=0.02125 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.212 | L2-Norm(final)=9.775 | 4994.2 samples/s | 78.0 steps/s
[Step=24000 Epoch=23.4] | Loss=0.02122 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.219 | L2-Norm(final)=9.774 | 4845.7 samples/s | 75.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step24000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=22001 Epoch=41.5] | Loss=0.00354 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.891 | L2-Norm(final)=11.250 | 4092.0 samples/s | 63.9 steps/s
[Step=22050 Epoch=41.6] | Loss=0.00386 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.886 | L2-Norm(final)=11.271 | 5071.0 samples/s | 79.2 steps/s
[Step=22100 Epoch=41.7] | Loss=0.00392 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.886 | L2-Norm(final)=11.294 | 5399.2 samples/s | 84.4 steps/s
[Step=22150 Epoch=41.8] | Loss=0.00348 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.316 | 5265.9 samples/s | 82.3 steps/s
[Step=22200 Epoch=41.8] | Loss=0.00339 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.337 | 5393.9 samples/s | 84.3 steps/s
[Step=22250 Epoch=41.9] | Loss=0.00352 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.885 | L2-Norm(final)=11.355 | 5067.1 samples/s | 79.2 steps/s
[Step=22300 Epoch=42.0] | Loss=0.00342 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.372 | 5255.4 samples/s | 82.1 steps/s
[Step=22350 Epoch=42.1] | Loss=0.00328 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.390 | 5197.1 samples/s | 81.2 steps/s
[Step=22400 Epoch=42.2] | Loss=0.00362 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.885 | L2-Norm(final)=11.406 | 5294.0 samples/s | 82.7 steps/s
[Step=22450 Epoch=42.3] | Loss=0.00374 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.422 | 5113.8 samples/s | 79.9 steps/s
[Step=22500 Epoch=42.4] | Loss=0.00366 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.438 | 5322.8 samples/s | 83.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=42.4] | Loss=0.02494 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.885 | L2-Norm(final)=11.597 | 4252.0 samples/s | 66.4 steps/s
[Step=22550 Epoch=42.5] | Loss=0.00410 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.922 | L2-Norm(final)=11.599 | 4389.0 samples/s | 68.6 steps/s
[Step=22600 Epoch=42.6] | Loss=0.00409 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.974 | L2-Norm(final)=11.590 | 4522.4 samples/s | 70.7 steps/s
[Step=22650 Epoch=42.7] | Loss=0.00346 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.009 | L2-Norm(final)=11.583 | 4560.5 samples/s | 71.3 steps/s
[Step=22700 Epoch=42.8] | Loss=0.00263 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.024 | L2-Norm(final)=11.579 | 4504.5 samples/s | 70.4 steps/s
[Step=22750 Epoch=42.9] | Loss=0.00252 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=11.576 | 4560.4 samples/s | 71.3 steps/s
[Step=22800 Epoch=43.0] | Loss=0.00215 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.032 | L2-Norm(final)=11.574 | 4667.4 samples/s | 72.9 steps/s
[Step=22850 Epoch=43.1] | Loss=0.00207 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=11.572 | 4686.7 samples/s | 73.2 steps/s
[Step=22900 Epoch=43.2] | Loss=0.00187 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.029 | L2-Norm(final)=11.572 | 4687.5 samples/s | 73.2 steps/s
[Step=22950 Epoch=43.3] | Loss=0.00190 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.027 | L2-Norm(final)=11.571 | 4665.1 samples/s | 72.9 steps/s
[Step=23000 Epoch=43.4] | Loss=0.00173 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.025 | L2-Norm(final)=11.570 | 4716.5 samples/s | 73.7 steps/s
[Step=23050 Epoch=43.4] | Loss=0.00158 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.023 | L2-Norm(final)=11.570 | 2123.5 samples/s | 33.2 steps/s
[Step=23100 Epoch=43.5] | Loss=0.00145 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.018 | L2-Norm(final)=11.569 | 4593.2 samples/s | 71.8 steps/s
[Step=23150 Epoch=43.6] | Loss=0.00134 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.013 | L2-Norm(final)=11.569 | 4589.4 samples/s | 71.7 steps/s
[Step=23200 Epoch=43.7] | Loss=0.00125 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=11.569 | 4523.5 samples/s | 70.7 steps/s
[Step=23250 Epoch=43.8] | Loss=0.00125 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.999 | L2-Norm(final)=11.569 | 4486.3 samples/s | 70.1 steps/s
[Step=23300 Epoch=43.9] | Loss=0.00124 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.992 | L2-Norm(final)=11.568 | 4517.2 samples/s | 70.6 steps/s
[Step=23350 Epoch=44.0] | Loss=0.00119 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.987 | L2-Norm(final)=11.568 | 4537.9 samples/s | 70.9 steps/s
[Step=23400 Epoch=44.1] | Loss=0.00112 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=11.568 | 4576.1 samples/s | 71.5 steps/s
[Step=23450 Epoch=44.2] | Loss=0.00106 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.976 | L2-Norm(final)=11.568 | 4496.8 samples/s | 70.3 steps/s
[Step=23500 Epoch=44.3] | Loss=0.00101 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=11.568 | 4534.8 samples/s | 70.9 steps/s
[Step=23550 Epoch=44.4] | Loss=0.00096 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=11.568 | 5657.0 samples/s | 88.4 steps/s
[Step=23600 Epoch=44.5] | Loss=0.00092 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=11.568 | 1945.1 samples/s | 30.4 steps/s
[Step=23650 Epoch=44.6] | Loss=0.00088 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.946 | L2-Norm(final)=11.568 | 4691.0 samples/s | 73.3 steps/s
[Step=23700 Epoch=44.7] | Loss=0.00084 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.938 | L2-Norm(final)=11.568 | 4694.3 samples/s | 73.3 steps/s
[Step=23750 Epoch=44.8] | Loss=0.00081 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.930 | L2-Norm(final)=11.568 | 4626.4 samples/s | 72.3 steps/s
[Step=23800 Epoch=44.9] | Loss=0.00078 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.921 | L2-Norm(final)=11.568 | 4641.6 samples/s | 72.5 steps/s
[Step=23850 Epoch=45.0] | Loss=0.00075 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=11.568 | 4598.3 samples/s | 71.8 steps/s
[Step=23900 Epoch=45.1] | Loss=0.00072 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.903 | L2-Norm(final)=11.568 | 4539.2 samples/s | 70.9 steps/s
[Step=23950 Epoch=45.1] | Loss=0.00070 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.894 | L2-Norm(final)=11.568 | 4536.2 samples/s | 70.9 steps/s
[Step=24000 Epoch=45.2] | Loss=0.00068 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.884 | L2-Norm(final)=11.568 | 4537.0 samples/s | 70.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05600 | acc=0.9691 | tpr=0.9734 | fpr=0.0404 | 4606.3 samples/s | 18.0 steps/s
Avg test loss: 0.06177, Avg test acc: 0.96783, Avg tpr: 0.97179, Avg fpr: 0.04089, total FA: 319

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.77357 | acc=0.3004 | tpr=0.0197 | fpr=0.0902 | 4557.7 samples/s | 17.8 steps/s
Avg test loss: 8.80507, Avg test acc: 0.29902, Avg tpr: 0.02011, Avg fpr: 0.08755, total FA: 683

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.82429 | acc=0.1327 | tpr=0.6150 | fpr=0.8760 | 4625.7 samples/s | 18.1 steps/s
[Step= 100] | Loss=5.79713 | acc=0.1351 | tpr=0.6269 | fpr=0.8741 | 8304.6 samples/s | 32.4 steps/s
[Step= 150] | Loss=5.78796 | acc=0.1348 | tpr=0.6210 | fpr=0.8742 | 8689.0 samples/s | 33.9 steps/s
[Step= 200] | Loss=5.77829 | acc=0.1356 | tpr=0.6284 | fpr=0.8734 | 8230.5 samples/s | 32.2 steps/s
[Step= 250] | Loss=5.77956 | acc=0.1364 | tpr=0.6288 | fpr=0.8725 | 8630.8 samples/s | 33.7 steps/s
[Step= 300] | Loss=5.77457 | acc=0.1361 | tpr=0.6305 | fpr=0.8729 | 8291.0 samples/s | 32.4 steps/s
[Step= 350] | Loss=5.77331 | acc=0.1357 | tpr=0.6337 | fpr=0.8734 | 8635.9 samples/s | 33.7 steps/s
[Step= 400] | Loss=5.77133 | acc=0.1357 | tpr=0.6346 | fpr=0.8734 | 8472.0 samples/s | 33.1 steps/s
[Step= 450] | Loss=5.77356 | acc=0.1353 | tpr=0.6319 | fpr=0.8737 | 8366.4 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.77191 | acc=0.1355 | tpr=0.6295 | fpr=0.8734 | 8582.9 samples/s | 33.5 steps/s
[Step= 550] | Loss=5.77276 | acc=0.1360 | tpr=0.6319 | fpr=0.8730 | 15362.3 samples/s | 60.0 steps/s
Avg test loss: 5.77265, Avg test acc: 0.13586, Avg tpr: 0.63193, Avg fpr: 0.87316, total FA: 121236

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15434 | acc=0.9805 | tpr=0.9558 | fpr=0.0190 | 4565.6 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.16027 | acc=0.9803 | tpr=0.9531 | fpr=0.0192 | 8505.7 samples/s | 33.2 steps/s
[Step= 150] | Loss=0.16472 | acc=0.9796 | tpr=0.9539 | fpr=0.0200 | 8667.6 samples/s | 33.9 steps/s
[Step= 200] | Loss=0.16499 | acc=0.9798 | tpr=0.9574 | fpr=0.0198 | 8552.4 samples/s | 33.4 steps/s
[Step= 250] | Loss=0.16218 | acc=0.9800 | tpr=0.9537 | fpr=0.0196 | 8799.7 samples/s | 34.4 steps/s
[Step= 300] | Loss=0.16368 | acc=0.9798 | tpr=0.9556 | fpr=0.0197 | 8144.8 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.16606 | acc=0.9796 | tpr=0.9549 | fpr=0.0200 | 8925.3 samples/s | 34.9 steps/s
[Step= 400] | Loss=0.16664 | acc=0.9795 | tpr=0.9535 | fpr=0.0200 | 8049.6 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.17007 | acc=0.9792 | tpr=0.9508 | fpr=0.0203 | 8385.5 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.16868 | acc=0.9793 | tpr=0.9511 | fpr=0.0202 | 8753.1 samples/s | 34.2 steps/s
[Step= 550] | Loss=0.16746 | acc=0.9795 | tpr=0.9507 | fpr=0.0200 | 15064.2 samples/s | 58.8 steps/s
Avg test loss: 0.16744, Avg test acc: 0.97949, Avg tpr: 0.95048, Avg fpr: 0.01999, total FA: 2775

server round 12/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=24001 Epoch=23.4] | Loss=0.06209 | Reg=0.00248 | acc=0.9531 | L2-Norm=15.754 | L2-Norm(final)=9.753 | 4423.4 samples/s | 69.1 steps/s
[Step=24050 Epoch=23.5] | Loss=0.03679 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.755 | L2-Norm(final)=9.778 | 5044.1 samples/s | 78.8 steps/s
[Step=24100 Epoch=23.5] | Loss=0.03470 | Reg=0.00248 | acc=0.9375 | L2-Norm=15.756 | L2-Norm(final)=9.804 | 5584.3 samples/s | 87.3 steps/s
[Step=24150 Epoch=23.6] | Loss=0.03562 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=9.826 | 5731.6 samples/s | 89.6 steps/s
[Step=24200 Epoch=23.6] | Loss=0.03529 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.756 | L2-Norm(final)=9.846 | 5560.3 samples/s | 86.9 steps/s
[Step=24250 Epoch=23.7] | Loss=0.03512 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.756 | L2-Norm(final)=9.863 | 5697.5 samples/s | 89.0 steps/s
[Step=24300 Epoch=23.7] | Loss=0.03546 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=9.880 | 5704.1 samples/s | 89.1 steps/s
[Step=24350 Epoch=23.8] | Loss=0.03576 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=9.896 | 5626.9 samples/s | 87.9 steps/s
[Step=24400 Epoch=23.8] | Loss=0.03622 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=9.912 | 5577.6 samples/s | 87.1 steps/s
[Step=24450 Epoch=23.9] | Loss=0.03564 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.756 | L2-Norm(final)=9.928 | 5582.3 samples/s | 87.2 steps/s
[Step=24500 Epoch=23.9] | Loss=0.03587 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=9.944 | 5486.7 samples/s | 85.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=23.9] | Loss=0.02919 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=10.105 | 4038.7 samples/s | 63.1 steps/s
[Step=24550 Epoch=24.0] | Loss=0.03194 | Reg=0.00250 | acc=0.9531 | L2-Norm=15.810 | L2-Norm(final)=10.107 | 4648.7 samples/s | 72.6 steps/s
[Step=24600 Epoch=24.0] | Loss=0.02894 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.852 | L2-Norm(final)=10.101 | 4778.6 samples/s | 74.7 steps/s
[Step=24650 Epoch=24.1] | Loss=0.02664 | Reg=0.00252 | acc=0.9688 | L2-Norm=15.878 | L2-Norm(final)=10.098 | 4813.5 samples/s | 75.2 steps/s
[Step=24700 Epoch=24.1] | Loss=0.02725 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.900 | L2-Norm(final)=10.094 | 4790.3 samples/s | 74.8 steps/s
[Step=24750 Epoch=24.2] | Loss=0.02703 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.918 | L2-Norm(final)=10.091 | 4768.7 samples/s | 74.5 steps/s
[Step=24800 Epoch=24.2] | Loss=0.02582 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.933 | L2-Norm(final)=10.088 | 4825.2 samples/s | 75.4 steps/s
[Step=24850 Epoch=24.3] | Loss=0.02518 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.946 | L2-Norm(final)=10.087 | 4782.3 samples/s | 74.7 steps/s
[Step=24900 Epoch=24.3] | Loss=0.02500 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.958 | L2-Norm(final)=10.085 | 4751.0 samples/s | 74.2 steps/s
[Step=24950 Epoch=24.4] | Loss=0.02435 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.968 | L2-Norm(final)=10.084 | 4754.0 samples/s | 74.3 steps/s
[Step=25000 Epoch=24.4] | Loss=0.02391 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.978 | L2-Norm(final)=10.083 | 4797.4 samples/s | 75.0 steps/s
[Step=25050 Epoch=24.5] | Loss=0.02407 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.987 | L2-Norm(final)=10.082 | 4865.0 samples/s | 76.0 steps/s
[Step=25100 Epoch=24.5] | Loss=0.02378 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.996 | L2-Norm(final)=10.080 | 4761.4 samples/s | 74.4 steps/s
[Step=25150 Epoch=24.6] | Loss=0.02353 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.005 | L2-Norm(final)=10.078 | 4850.8 samples/s | 75.8 steps/s
[Step=25200 Epoch=24.6] | Loss=0.02334 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.013 | L2-Norm(final)=10.077 | 4760.6 samples/s | 74.4 steps/s
[Step=25250 Epoch=24.7] | Loss=0.02293 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.021 | L2-Norm(final)=10.075 | 4749.9 samples/s | 74.2 steps/s
[Step=25300 Epoch=24.7] | Loss=0.02305 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.028 | L2-Norm(final)=10.074 | 4800.5 samples/s | 75.0 steps/s
[Step=25350 Epoch=24.8] | Loss=0.02285 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.035 | L2-Norm(final)=10.072 | 4791.3 samples/s | 74.9 steps/s
[Step=25400 Epoch=24.8] | Loss=0.02250 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.042 | L2-Norm(final)=10.070 | 4804.5 samples/s | 75.1 steps/s
[Step=25450 Epoch=24.8] | Loss=0.02235 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.048 | L2-Norm(final)=10.068 | 4787.6 samples/s | 74.8 steps/s
[Step=25500 Epoch=24.9] | Loss=0.02215 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.055 | L2-Norm(final)=10.067 | 5088.7 samples/s | 79.5 steps/s
[Step=25550 Epoch=24.9] | Loss=0.02194 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=10.066 | 2121.4 samples/s | 33.1 steps/s
[Step=25600 Epoch=25.0] | Loss=0.02180 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.069 | L2-Norm(final)=10.065 | 4750.1 samples/s | 74.2 steps/s
[Step=25650 Epoch=25.0] | Loss=0.02152 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.076 | L2-Norm(final)=10.064 | 4738.9 samples/s | 74.0 steps/s
[Step=25700 Epoch=25.1] | Loss=0.02126 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.083 | L2-Norm(final)=10.063 | 4752.0 samples/s | 74.2 steps/s
[Step=25750 Epoch=25.1] | Loss=0.02105 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.089 | L2-Norm(final)=10.063 | 4765.8 samples/s | 74.5 steps/s
[Step=25800 Epoch=25.2] | Loss=0.02070 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.095 | L2-Norm(final)=10.062 | 4884.9 samples/s | 76.3 steps/s
[Step=25850 Epoch=25.2] | Loss=0.02057 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.101 | L2-Norm(final)=10.061 | 4718.1 samples/s | 73.7 steps/s
[Step=25900 Epoch=25.3] | Loss=0.02040 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.107 | L2-Norm(final)=10.060 | 4782.8 samples/s | 74.7 steps/s
[Step=25950 Epoch=25.3] | Loss=0.02032 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=10.059 | 4776.0 samples/s | 74.6 steps/s
[Step=26000 Epoch=25.4] | Loss=0.02021 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.118 | L2-Norm(final)=10.059 | 4789.8 samples/s | 74.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step26000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=24001 Epoch=45.2] | Loss=0.00002 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.754 | L2-Norm(final)=11.569 | 4155.5 samples/s | 64.9 steps/s
[Step=24050 Epoch=45.3] | Loss=0.00252 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.751 | L2-Norm(final)=11.574 | 4934.5 samples/s | 77.1 steps/s
[Step=24100 Epoch=45.4] | Loss=0.00237 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.580 | 5135.8 samples/s | 80.2 steps/s
[Step=24150 Epoch=45.5] | Loss=0.00244 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.587 | 5161.6 samples/s | 80.6 steps/s
[Step=24200 Epoch=45.6] | Loss=0.00210 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.595 | 5322.9 samples/s | 83.2 steps/s
[Step=24250 Epoch=45.7] | Loss=0.00205 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.603 | 5076.7 samples/s | 79.3 steps/s
[Step=24300 Epoch=45.8] | Loss=0.00199 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.611 | 5190.0 samples/s | 81.1 steps/s
[Step=24350 Epoch=45.9] | Loss=0.00212 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.618 | 5174.0 samples/s | 80.8 steps/s
[Step=24400 Epoch=46.0] | Loss=0.00218 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.626 | 5156.8 samples/s | 80.6 steps/s
[Step=24450 Epoch=46.1] | Loss=0.00206 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.634 | 5147.9 samples/s | 80.4 steps/s
[Step=24500 Epoch=46.2] | Loss=0.00201 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.641 | 5306.1 samples/s | 82.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=46.2] | Loss=0.00054 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.718 | 4515.6 samples/s | 70.6 steps/s
[Step=24550 Epoch=46.3] | Loss=0.00103 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.745 | L2-Norm(final)=11.723 | 4034.0 samples/s | 63.0 steps/s
[Step=24600 Epoch=46.4] | Loss=0.00262 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.763 | L2-Norm(final)=11.723 | 4526.0 samples/s | 70.7 steps/s
[Step=24650 Epoch=46.5] | Loss=0.00298 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.801 | L2-Norm(final)=11.716 | 4495.9 samples/s | 70.2 steps/s
[Step=24700 Epoch=46.6] | Loss=0.00247 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.829 | L2-Norm(final)=11.710 | 4630.1 samples/s | 72.3 steps/s
[Step=24750 Epoch=46.7] | Loss=0.00249 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.845 | L2-Norm(final)=11.706 | 4440.7 samples/s | 69.4 steps/s
[Step=24800 Epoch=46.7] | Loss=0.00230 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.858 | L2-Norm(final)=11.701 | 4580.8 samples/s | 71.6 steps/s
[Step=24850 Epoch=46.8] | Loss=0.00225 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=11.697 | 4595.6 samples/s | 71.8 steps/s
[Step=24900 Epoch=46.9] | Loss=0.00201 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.872 | L2-Norm(final)=11.692 | 4524.8 samples/s | 70.7 steps/s
[Step=24950 Epoch=47.0] | Loss=0.00207 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.875 | L2-Norm(final)=11.689 | 4570.7 samples/s | 71.4 steps/s
[Step=25000 Epoch=47.1] | Loss=0.00189 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.877 | L2-Norm(final)=11.686 | 4580.3 samples/s | 71.6 steps/s
[Step=25050 Epoch=47.2] | Loss=0.00175 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=11.683 | 2135.5 samples/s | 33.4 steps/s
[Step=25100 Epoch=47.3] | Loss=0.00167 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=11.681 | 4752.3 samples/s | 74.3 steps/s
[Step=25150 Epoch=47.4] | Loss=0.00170 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=11.679 | 4695.7 samples/s | 73.4 steps/s
[Step=25200 Epoch=47.5] | Loss=0.00175 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=11.676 | 4587.9 samples/s | 71.7 steps/s
[Step=25250 Epoch=47.6] | Loss=0.00175 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.882 | L2-Norm(final)=11.674 | 4633.1 samples/s | 72.4 steps/s
[Step=25300 Epoch=47.7] | Loss=0.00166 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.884 | L2-Norm(final)=11.671 | 4700.1 samples/s | 73.4 steps/s
[Step=25350 Epoch=47.8] | Loss=0.00158 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.669 | 4687.2 samples/s | 73.2 steps/s
[Step=25400 Epoch=47.9] | Loss=0.00150 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.668 | 4748.8 samples/s | 74.2 steps/s
[Step=25450 Epoch=48.0] | Loss=0.00142 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.885 | L2-Norm(final)=11.666 | 4654.1 samples/s | 72.7 steps/s
[Step=25500 Epoch=48.1] | Loss=0.00138 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.884 | L2-Norm(final)=11.665 | 4496.7 samples/s | 70.3 steps/s
[Step=25550 Epoch=48.2] | Loss=0.00131 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.883 | L2-Norm(final)=11.664 | 5857.3 samples/s | 91.5 steps/s
[Step=25600 Epoch=48.3] | Loss=0.00125 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.881 | L2-Norm(final)=11.662 | 2035.9 samples/s | 31.8 steps/s
[Step=25650 Epoch=48.4] | Loss=0.00120 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.878 | L2-Norm(final)=11.661 | 4532.7 samples/s | 70.8 steps/s
[Step=25700 Epoch=48.4] | Loss=0.00115 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.875 | L2-Norm(final)=11.660 | 4582.1 samples/s | 71.6 steps/s
[Step=25750 Epoch=48.5] | Loss=0.00110 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.871 | L2-Norm(final)=11.660 | 4592.5 samples/s | 71.8 steps/s
[Step=25800 Epoch=48.6] | Loss=0.00106 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.867 | L2-Norm(final)=11.659 | 4519.5 samples/s | 70.6 steps/s
[Step=25850 Epoch=48.7] | Loss=0.00102 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.862 | L2-Norm(final)=11.658 | 4607.5 samples/s | 72.0 steps/s
[Step=25900 Epoch=48.8] | Loss=0.00099 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.857 | L2-Norm(final)=11.658 | 4615.6 samples/s | 72.1 steps/s
[Step=25950 Epoch=48.9] | Loss=0.00095 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.852 | L2-Norm(final)=11.657 | 4488.5 samples/s | 70.1 steps/s
[Step=26000 Epoch=49.0] | Loss=0.00092 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.847 | L2-Norm(final)=11.656 | 4634.4 samples/s | 72.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05612 | acc=0.9684 | tpr=0.9684 | fpr=0.0317 | 4601.5 samples/s | 18.0 steps/s
Avg test loss: 0.06194, Avg test acc: 0.96682, Avg tpr: 0.96643, Avg fpr: 0.03230, total FA: 252

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.97127 | acc=0.2980 | tpr=0.0126 | fpr=0.0820 | 4527.2 samples/s | 17.7 steps/s
Avg test loss: 9.00639, Avg test acc: 0.29626, Avg tpr: 0.01183, Avg fpr: 0.07820, total FA: 610

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.41126 | acc=0.1553 | tpr=0.5664 | fpr=0.8521 | 4553.7 samples/s | 17.8 steps/s
[Step= 100] | Loss=5.36894 | acc=0.1579 | tpr=0.5821 | fpr=0.8500 | 8604.7 samples/s | 33.6 steps/s
[Step= 150] | Loss=5.36468 | acc=0.1577 | tpr=0.5922 | fpr=0.8503 | 8200.8 samples/s | 32.0 steps/s
[Step= 200] | Loss=5.35125 | acc=0.1572 | tpr=0.5956 | fpr=0.8507 | 8560.5 samples/s | 33.4 steps/s
[Step= 250] | Loss=5.34994 | acc=0.1580 | tpr=0.5930 | fpr=0.8499 | 8639.2 samples/s | 33.7 steps/s
[Step= 300] | Loss=5.34489 | acc=0.1577 | tpr=0.5971 | fpr=0.8503 | 8303.5 samples/s | 32.4 steps/s
[Step= 350] | Loss=5.34172 | acc=0.1571 | tpr=0.6011 | fpr=0.8509 | 8674.1 samples/s | 33.9 steps/s
[Step= 400] | Loss=5.34129 | acc=0.1573 | tpr=0.6039 | fpr=0.8508 | 8537.6 samples/s | 33.4 steps/s
[Step= 450] | Loss=5.34421 | acc=0.1572 | tpr=0.6047 | fpr=0.8509 | 8313.3 samples/s | 32.5 steps/s
[Step= 500] | Loss=5.34327 | acc=0.1573 | tpr=0.6026 | fpr=0.8507 | 8591.2 samples/s | 33.6 steps/s
[Step= 550] | Loss=5.34395 | acc=0.1575 | tpr=0.6041 | fpr=0.8506 | 14657.0 samples/s | 57.3 steps/s
Avg test loss: 5.34485, Avg test acc: 0.15735, Avg tpr: 0.60380, Avg fpr: 0.85076, total FA: 118127

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13801 | acc=0.9838 | tpr=0.9469 | fpr=0.0155 | 4587.7 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.14339 | acc=0.9831 | tpr=0.9574 | fpr=0.0164 | 8442.0 samples/s | 33.0 steps/s
[Step= 150] | Loss=0.14595 | acc=0.9823 | tpr=0.9611 | fpr=0.0173 | 8815.4 samples/s | 34.4 steps/s
[Step= 200] | Loss=0.14727 | acc=0.9823 | tpr=0.9661 | fpr=0.0174 | 8529.0 samples/s | 33.3 steps/s
[Step= 250] | Loss=0.14482 | acc=0.9826 | tpr=0.9598 | fpr=0.0170 | 8570.2 samples/s | 33.5 steps/s
[Step= 300] | Loss=0.14722 | acc=0.9824 | tpr=0.9593 | fpr=0.0172 | 8373.1 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.15011 | acc=0.9820 | tpr=0.9593 | fpr=0.0176 | 8480.0 samples/s | 33.1 steps/s
[Step= 400] | Loss=0.15088 | acc=0.9819 | tpr=0.9573 | fpr=0.0176 | 8661.3 samples/s | 33.8 steps/s
[Step= 450] | Loss=0.15448 | acc=0.9816 | tpr=0.9547 | fpr=0.0179 | 8385.3 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.15335 | acc=0.9816 | tpr=0.9551 | fpr=0.0179 | 8306.8 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.15232 | acc=0.9818 | tpr=0.9546 | fpr=0.0177 | 15240.2 samples/s | 59.5 steps/s
Avg test loss: 0.15227, Avg test acc: 0.98177, Avg tpr: 0.95444, Avg fpr: 0.01773, total FA: 2462

server round 13/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=26001 Epoch=25.4] | Loss=0.04489 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.727 | L2-Norm(final)=10.038 | 4332.0 samples/s | 67.7 steps/s
[Step=26050 Epoch=25.4] | Loss=0.04015 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.730 | L2-Norm(final)=10.052 | 5233.7 samples/s | 81.8 steps/s
[Step=26100 Epoch=25.5] | Loss=0.03950 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.731 | L2-Norm(final)=10.073 | 5776.1 samples/s | 90.3 steps/s
[Step=26150 Epoch=25.5] | Loss=0.03972 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.731 | L2-Norm(final)=10.089 | 5642.5 samples/s | 88.2 steps/s
[Step=26200 Epoch=25.6] | Loss=0.03809 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.731 | L2-Norm(final)=10.101 | 5452.5 samples/s | 85.2 steps/s
[Step=26250 Epoch=25.6] | Loss=0.03847 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.731 | L2-Norm(final)=10.112 | 5576.8 samples/s | 87.1 steps/s
[Step=26300 Epoch=25.7] | Loss=0.03916 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.731 | L2-Norm(final)=10.124 | 5485.2 samples/s | 85.7 steps/s
[Step=26350 Epoch=25.7] | Loss=0.03903 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.731 | L2-Norm(final)=10.134 | 5607.1 samples/s | 87.6 steps/s
[Step=26400 Epoch=25.8] | Loss=0.03921 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.731 | L2-Norm(final)=10.145 | 5500.3 samples/s | 85.9 steps/s
[Step=26450 Epoch=25.8] | Loss=0.03931 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.731 | L2-Norm(final)=10.156 | 5576.2 samples/s | 87.1 steps/s
[Step=26500 Epoch=25.9] | Loss=0.03946 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.731 | L2-Norm(final)=10.166 | 5571.5 samples/s | 87.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=25.9] | Loss=0.08712 | Reg=0.00247 | acc=0.8750 | L2-Norm=15.731 | L2-Norm(final)=10.268 | 4372.0 samples/s | 68.3 steps/s
[Step=26550 Epoch=25.9] | Loss=0.03439 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.806 | L2-Norm(final)=10.269 | 4728.2 samples/s | 73.9 steps/s
[Step=26600 Epoch=26.0] | Loss=0.03179 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.858 | L2-Norm(final)=10.263 | 4866.2 samples/s | 76.0 steps/s
[Step=26650 Epoch=26.0] | Loss=0.02805 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.890 | L2-Norm(final)=10.259 | 4921.2 samples/s | 76.9 steps/s
[Step=26700 Epoch=26.1] | Loss=0.02689 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.913 | L2-Norm(final)=10.256 | 4801.8 samples/s | 75.0 steps/s
[Step=26750 Epoch=26.1] | Loss=0.02522 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.931 | L2-Norm(final)=10.254 | 4807.1 samples/s | 75.1 steps/s
[Step=26800 Epoch=26.2] | Loss=0.02444 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.947 | L2-Norm(final)=10.253 | 4763.1 samples/s | 74.4 steps/s
[Step=26850 Epoch=26.2] | Loss=0.02418 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=10.252 | 4830.2 samples/s | 75.5 steps/s
[Step=26900 Epoch=26.3] | Loss=0.02386 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=10.250 | 4817.5 samples/s | 75.3 steps/s
[Step=26950 Epoch=26.3] | Loss=0.02362 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.984 | L2-Norm(final)=10.249 | 4928.7 samples/s | 77.0 steps/s
[Step=27000 Epoch=26.4] | Loss=0.02334 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=10.247 | 4852.2 samples/s | 75.8 steps/s
[Step=27050 Epoch=26.4] | Loss=0.02282 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.003 | L2-Norm(final)=10.246 | 4752.0 samples/s | 74.3 steps/s
[Step=27100 Epoch=26.5] | Loss=0.02297 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.012 | L2-Norm(final)=10.245 | 4782.0 samples/s | 74.7 steps/s
[Step=27150 Epoch=26.5] | Loss=0.02293 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.020 | L2-Norm(final)=10.244 | 4779.8 samples/s | 74.7 steps/s
[Step=27200 Epoch=26.6] | Loss=0.02290 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.029 | L2-Norm(final)=10.242 | 4762.4 samples/s | 74.4 steps/s
[Step=27250 Epoch=26.6] | Loss=0.02264 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.036 | L2-Norm(final)=10.241 | 4839.9 samples/s | 75.6 steps/s
[Step=27300 Epoch=26.7] | Loss=0.02249 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.044 | L2-Norm(final)=10.240 | 4847.0 samples/s | 75.7 steps/s
[Step=27350 Epoch=26.7] | Loss=0.02259 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.051 | L2-Norm(final)=10.239 | 4872.1 samples/s | 76.1 steps/s
[Step=27400 Epoch=26.8] | Loss=0.02260 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.058 | L2-Norm(final)=10.238 | 4773.8 samples/s | 74.6 steps/s
[Step=27450 Epoch=26.8] | Loss=0.02226 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.065 | L2-Norm(final)=10.237 | 4811.9 samples/s | 75.2 steps/s
[Step=27500 Epoch=26.8] | Loss=0.02214 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.071 | L2-Norm(final)=10.236 | 5165.5 samples/s | 80.7 steps/s
[Step=27550 Epoch=26.9] | Loss=0.02175 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.078 | L2-Norm(final)=10.235 | 2090.7 samples/s | 32.7 steps/s
[Step=27600 Epoch=26.9] | Loss=0.02140 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=10.234 | 4844.2 samples/s | 75.7 steps/s
[Step=27650 Epoch=27.0] | Loss=0.02104 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.090 | L2-Norm(final)=10.234 | 4746.7 samples/s | 74.2 steps/s
[Step=27700 Epoch=27.0] | Loss=0.02079 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.095 | L2-Norm(final)=10.233 | 4801.9 samples/s | 75.0 steps/s
[Step=27750 Epoch=27.1] | Loss=0.02055 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.101 | L2-Norm(final)=10.233 | 4783.9 samples/s | 74.7 steps/s
[Step=27800 Epoch=27.1] | Loss=0.02036 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.106 | L2-Norm(final)=10.232 | 4851.8 samples/s | 75.8 steps/s
[Step=27850 Epoch=27.2] | Loss=0.02012 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.111 | L2-Norm(final)=10.232 | 4873.7 samples/s | 76.2 steps/s
[Step=27900 Epoch=27.2] | Loss=0.01998 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.116 | L2-Norm(final)=10.231 | 4719.7 samples/s | 73.7 steps/s
[Step=27950 Epoch=27.3] | Loss=0.01978 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.121 | L2-Norm(final)=10.231 | 4794.6 samples/s | 74.9 steps/s
[Step=28000 Epoch=27.3] | Loss=0.01959 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=10.230 | 4812.2 samples/s | 75.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step28000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=26001 Epoch=49.0] | Loss=0.00002 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=11.641 | 4355.2 samples/s | 68.1 steps/s
[Step=26050 Epoch=49.1] | Loss=0.00073 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=11.644 | 4778.8 samples/s | 74.7 steps/s
[Step=26100 Epoch=49.2] | Loss=0.00087 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.650 | 5068.6 samples/s | 79.2 steps/s
[Step=26150 Epoch=49.3] | Loss=0.00126 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.724 | L2-Norm(final)=11.655 | 5201.4 samples/s | 81.3 steps/s
[Step=26200 Epoch=49.4] | Loss=0.00105 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.658 | 5330.9 samples/s | 83.3 steps/s
[Step=26250 Epoch=49.5] | Loss=0.00088 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.662 | 5062.6 samples/s | 79.1 steps/s
[Step=26300 Epoch=49.6] | Loss=0.00083 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.666 | 5135.5 samples/s | 80.2 steps/s
[Step=26350 Epoch=49.7] | Loss=0.00089 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.671 | 5178.9 samples/s | 80.9 steps/s
[Step=26400 Epoch=49.8] | Loss=0.00092 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.676 | 5378.9 samples/s | 84.0 steps/s
[Step=26450 Epoch=49.9] | Loss=0.00100 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.681 | 5397.2 samples/s | 84.3 steps/s
[Step=26500 Epoch=50.0] | Loss=0.00094 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.685 | 5449.3 samples/s | 85.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=50.0] | Loss=0.00028 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=11.734 | 4191.8 samples/s | 65.5 steps/s
[Step=26550 Epoch=50.0] | Loss=0.00052 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.713 | L2-Norm(final)=11.737 | 4503.7 samples/s | 70.4 steps/s
[Step=26600 Epoch=50.1] | Loss=0.00031 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=11.739 | 4647.0 samples/s | 72.6 steps/s
[Step=26650 Epoch=50.2] | Loss=0.00051 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.697 | L2-Norm(final)=11.741 | 4629.9 samples/s | 72.3 steps/s
[Step=26700 Epoch=50.3] | Loss=0.00045 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.696 | L2-Norm(final)=11.742 | 4699.9 samples/s | 73.4 steps/s
[Step=26750 Epoch=50.4] | Loss=0.00039 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.695 | L2-Norm(final)=11.743 | 4633.7 samples/s | 72.4 steps/s
[Step=26800 Epoch=50.5] | Loss=0.00038 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.694 | L2-Norm(final)=11.744 | 4535.0 samples/s | 70.9 steps/s
[Step=26850 Epoch=50.6] | Loss=0.00033 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.690 | L2-Norm(final)=11.744 | 4563.2 samples/s | 71.3 steps/s
[Step=26900 Epoch=50.7] | Loss=0.00030 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=11.744 | 4569.1 samples/s | 71.4 steps/s
[Step=26950 Epoch=50.8] | Loss=0.00074 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.682 | L2-Norm(final)=11.744 | 4462.5 samples/s | 69.7 steps/s
[Step=27000 Epoch=50.9] | Loss=0.00105 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.689 | L2-Norm(final)=11.741 | 4596.1 samples/s | 71.8 steps/s
[Step=27050 Epoch=51.0] | Loss=0.00103 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.698 | L2-Norm(final)=11.738 | 2123.7 samples/s | 33.2 steps/s
[Step=27100 Epoch=51.1] | Loss=0.00098 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=11.735 | 4575.2 samples/s | 71.5 steps/s
[Step=27150 Epoch=51.2] | Loss=0.00091 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=11.733 | 4562.7 samples/s | 71.3 steps/s
[Step=27200 Epoch=51.3] | Loss=0.00084 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.716 | L2-Norm(final)=11.731 | 4506.5 samples/s | 70.4 steps/s
[Step=27250 Epoch=51.4] | Loss=0.00079 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.719 | L2-Norm(final)=11.729 | 4477.2 samples/s | 70.0 steps/s
[Step=27300 Epoch=51.5] | Loss=0.00074 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.719 | L2-Norm(final)=11.728 | 4536.2 samples/s | 70.9 steps/s
[Step=27350 Epoch=51.6] | Loss=0.00069 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.719 | L2-Norm(final)=11.727 | 4517.2 samples/s | 70.6 steps/s
[Step=27400 Epoch=51.6] | Loss=0.00066 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.717 | L2-Norm(final)=11.726 | 4585.5 samples/s | 71.6 steps/s
[Step=27450 Epoch=51.7] | Loss=0.00062 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=11.725 | 4535.6 samples/s | 70.9 steps/s
[Step=27500 Epoch=51.8] | Loss=0.00062 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=11.724 | 4577.1 samples/s | 71.5 steps/s
[Step=27550 Epoch=51.9] | Loss=0.00059 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.709 | L2-Norm(final)=11.723 | 5658.4 samples/s | 88.4 steps/s
[Step=27600 Epoch=52.0] | Loss=0.00057 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.705 | L2-Norm(final)=11.723 | 1956.3 samples/s | 30.6 steps/s
[Step=27650 Epoch=52.1] | Loss=0.00054 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.701 | L2-Norm(final)=11.722 | 4695.3 samples/s | 73.4 steps/s
[Step=27700 Epoch=52.2] | Loss=0.00052 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.696 | L2-Norm(final)=11.722 | 4622.9 samples/s | 72.2 steps/s
[Step=27750 Epoch=52.3] | Loss=0.00050 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.691 | L2-Norm(final)=11.722 | 4654.3 samples/s | 72.7 steps/s
[Step=27800 Epoch=52.4] | Loss=0.00048 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.686 | L2-Norm(final)=11.722 | 4623.4 samples/s | 72.2 steps/s
[Step=27850 Epoch=52.5] | Loss=0.00046 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.680 | L2-Norm(final)=11.721 | 4463.7 samples/s | 69.7 steps/s
[Step=27900 Epoch=52.6] | Loss=0.00045 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=11.721 | 4559.1 samples/s | 71.2 steps/s
[Step=27950 Epoch=52.7] | Loss=0.00043 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.668 | L2-Norm(final)=11.721 | 4590.8 samples/s | 71.7 steps/s
[Step=28000 Epoch=52.8] | Loss=0.00042 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=11.721 | 4604.1 samples/s | 71.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05592 | acc=0.9714 | tpr=0.9777 | fpr=0.0424 | 4583.5 samples/s | 17.9 steps/s
Avg test loss: 0.06314, Avg test acc: 0.96975, Avg tpr: 0.97587, Avg fpr: 0.04371, total FA: 341

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.17217 | acc=0.3005 | tpr=0.0291 | fpr=0.1103 | 4598.2 samples/s | 18.0 steps/s
Avg test loss: 9.19951, Avg test acc: 0.29886, Avg tpr: 0.02961, Avg fpr: 0.10896, total FA: 850

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.78440 | acc=0.1398 | tpr=0.6372 | fpr=0.8692 | 4574.5 samples/s | 17.9 steps/s
[Step= 100] | Loss=5.74347 | acc=0.1413 | tpr=0.6418 | fpr=0.8681 | 8221.5 samples/s | 32.1 steps/s
[Step= 150] | Loss=5.74154 | acc=0.1400 | tpr=0.6427 | fpr=0.8693 | 8563.6 samples/s | 33.5 steps/s
[Step= 200] | Loss=5.73275 | acc=0.1398 | tpr=0.6393 | fpr=0.8692 | 8748.3 samples/s | 34.2 steps/s
[Step= 250] | Loss=5.72860 | acc=0.1408 | tpr=0.6393 | fpr=0.8683 | 8405.0 samples/s | 32.8 steps/s
[Step= 300] | Loss=5.72010 | acc=0.1402 | tpr=0.6385 | fpr=0.8689 | 8063.2 samples/s | 31.5 steps/s
[Step= 350] | Loss=5.71585 | acc=0.1397 | tpr=0.6406 | fpr=0.8694 | 8705.1 samples/s | 34.0 steps/s
[Step= 400] | Loss=5.71501 | acc=0.1399 | tpr=0.6395 | fpr=0.8692 | 8921.8 samples/s | 34.9 steps/s
[Step= 450] | Loss=5.71805 | acc=0.1399 | tpr=0.6358 | fpr=0.8691 | 8039.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=5.71666 | acc=0.1401 | tpr=0.6366 | fpr=0.8689 | 8502.6 samples/s | 33.2 steps/s
[Step= 550] | Loss=5.71816 | acc=0.1404 | tpr=0.6371 | fpr=0.8686 | 14664.0 samples/s | 57.3 steps/s
Avg test loss: 5.71924, Avg test acc: 0.14028, Avg tpr: 0.63708, Avg fpr: 0.86875, total FA: 120624

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.21324 | acc=0.9827 | tpr=0.9513 | fpr=0.0168 | 4586.3 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.22244 | acc=0.9821 | tpr=0.9595 | fpr=0.0175 | 8630.9 samples/s | 33.7 steps/s
[Step= 150] | Loss=0.22785 | acc=0.9817 | tpr=0.9597 | fpr=0.0179 | 8997.1 samples/s | 35.1 steps/s
[Step= 200] | Loss=0.22908 | acc=0.9817 | tpr=0.9650 | fpr=0.0180 | 7919.5 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.22602 | acc=0.9820 | tpr=0.9616 | fpr=0.0176 | 8501.1 samples/s | 33.2 steps/s
[Step= 300] | Loss=0.22911 | acc=0.9819 | tpr=0.9600 | fpr=0.0177 | 8568.4 samples/s | 33.5 steps/s
[Step= 350] | Loss=0.23131 | acc=0.9817 | tpr=0.9606 | fpr=0.0180 | 8362.5 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.23225 | acc=0.9815 | tpr=0.9590 | fpr=0.0181 | 8590.7 samples/s | 33.6 steps/s
[Step= 450] | Loss=0.23740 | acc=0.9812 | tpr=0.9557 | fpr=0.0184 | 8516.5 samples/s | 33.3 steps/s
[Step= 500] | Loss=0.23596 | acc=0.9813 | tpr=0.9564 | fpr=0.0183 | 8749.8 samples/s | 34.2 steps/s
[Step= 550] | Loss=0.23455 | acc=0.9814 | tpr=0.9558 | fpr=0.0181 | 14443.9 samples/s | 56.4 steps/s
Avg test loss: 0.23426, Avg test acc: 0.98144, Avg tpr: 0.95523, Avg fpr: 0.01808, total FA: 2511

server round 14/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=28001 Epoch=27.3] | Loss=0.02175 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.662 | L2-Norm(final)=10.219 | 4437.6 samples/s | 69.3 steps/s
[Step=28050 Epoch=27.4] | Loss=0.02588 | Reg=0.00245 | acc=0.9688 | L2-Norm=15.664 | L2-Norm(final)=10.237 | 5120.3 samples/s | 80.0 steps/s
[Step=28100 Epoch=27.4] | Loss=0.02831 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.664 | L2-Norm(final)=10.251 | 5635.8 samples/s | 88.1 steps/s
[Step=28150 Epoch=27.5] | Loss=0.02766 | Reg=0.00245 | acc=0.9531 | L2-Norm=15.664 | L2-Norm(final)=10.264 | 5519.0 samples/s | 86.2 steps/s
[Step=28200 Epoch=27.5] | Loss=0.02872 | Reg=0.00245 | acc=0.9531 | L2-Norm=15.664 | L2-Norm(final)=10.277 | 5365.2 samples/s | 83.8 steps/s
[Step=28250 Epoch=27.6] | Loss=0.02888 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=10.288 | 5535.0 samples/s | 86.5 steps/s
[Step=28300 Epoch=27.6] | Loss=0.02904 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.664 | L2-Norm(final)=10.298 | 5666.3 samples/s | 88.5 steps/s
[Step=28350 Epoch=27.7] | Loss=0.02967 | Reg=0.00245 | acc=0.9688 | L2-Norm=15.664 | L2-Norm(final)=10.307 | 5706.5 samples/s | 89.2 steps/s
[Step=28400 Epoch=27.7] | Loss=0.03005 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.664 | L2-Norm(final)=10.316 | 5668.2 samples/s | 88.6 steps/s
[Step=28450 Epoch=27.8] | Loss=0.02993 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=10.326 | 5592.0 samples/s | 87.4 steps/s
[Step=28500 Epoch=27.8] | Loss=0.03008 | Reg=0.00245 | acc=0.9688 | L2-Norm=15.664 | L2-Norm(final)=10.335 | 5649.1 samples/s | 88.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=27.8] | Loss=0.00167 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=10.429 | 3954.8 samples/s | 61.8 steps/s
[Step=28550 Epoch=27.9] | Loss=0.01904 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=10.434 | 4897.1 samples/s | 76.5 steps/s
[Step=28600 Epoch=27.9] | Loss=0.02148 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.749 | L2-Norm(final)=10.433 | 4726.4 samples/s | 73.8 steps/s
[Step=28650 Epoch=28.0] | Loss=0.02225 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=10.430 | 4760.6 samples/s | 74.4 steps/s
[Step=28700 Epoch=28.0] | Loss=0.02121 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.807 | L2-Norm(final)=10.427 | 4716.4 samples/s | 73.7 steps/s
[Step=28750 Epoch=28.1] | Loss=0.02122 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.829 | L2-Norm(final)=10.424 | 4666.8 samples/s | 72.9 steps/s
[Step=28800 Epoch=28.1] | Loss=0.02127 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.847 | L2-Norm(final)=10.421 | 4701.9 samples/s | 73.5 steps/s
[Step=28850 Epoch=28.2] | Loss=0.02094 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.862 | L2-Norm(final)=10.418 | 4854.9 samples/s | 75.9 steps/s
[Step=28900 Epoch=28.2] | Loss=0.02115 | Reg=0.00252 | acc=0.9531 | L2-Norm=15.875 | L2-Norm(final)=10.415 | 4774.7 samples/s | 74.6 steps/s
[Step=28950 Epoch=28.3] | Loss=0.02072 | Reg=0.00252 | acc=0.9375 | L2-Norm=15.886 | L2-Norm(final)=10.413 | 4838.6 samples/s | 75.6 steps/s
[Step=29000 Epoch=28.3] | Loss=0.02082 | Reg=0.00253 | acc=0.9375 | L2-Norm=15.898 | L2-Norm(final)=10.410 | 4783.5 samples/s | 74.7 steps/s
[Step=29050 Epoch=28.4] | Loss=0.02091 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.909 | L2-Norm(final)=10.408 | 4740.4 samples/s | 74.1 steps/s
[Step=29100 Epoch=28.4] | Loss=0.02068 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.919 | L2-Norm(final)=10.406 | 4813.4 samples/s | 75.2 steps/s
[Step=29150 Epoch=28.5] | Loss=0.02089 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.929 | L2-Norm(final)=10.404 | 4819.4 samples/s | 75.3 steps/s
[Step=29200 Epoch=28.5] | Loss=0.02116 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.939 | L2-Norm(final)=10.401 | 4826.0 samples/s | 75.4 steps/s
[Step=29250 Epoch=28.6] | Loss=0.02136 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.948 | L2-Norm(final)=10.398 | 4776.9 samples/s | 74.6 steps/s
[Step=29300 Epoch=28.6] | Loss=0.02122 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=10.396 | 4776.8 samples/s | 74.6 steps/s
[Step=29350 Epoch=28.7] | Loss=0.02111 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.964 | L2-Norm(final)=10.393 | 4796.2 samples/s | 74.9 steps/s
[Step=29400 Epoch=28.7] | Loss=0.02100 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.972 | L2-Norm(final)=10.391 | 4738.8 samples/s | 74.0 steps/s
[Step=29450 Epoch=28.8] | Loss=0.02093 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.980 | L2-Norm(final)=10.389 | 4784.5 samples/s | 74.8 steps/s
[Step=29500 Epoch=28.8] | Loss=0.02076 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.988 | L2-Norm(final)=10.387 | 5136.3 samples/s | 80.3 steps/s
[Step=29550 Epoch=28.9] | Loss=0.02079 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.996 | L2-Norm(final)=10.385 | 2095.8 samples/s | 32.7 steps/s
[Step=29600 Epoch=28.9] | Loss=0.02043 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.004 | L2-Norm(final)=10.384 | 4761.7 samples/s | 74.4 steps/s
[Step=29650 Epoch=28.9] | Loss=0.02023 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.012 | L2-Norm(final)=10.382 | 4779.1 samples/s | 74.7 steps/s
[Step=29700 Epoch=29.0] | Loss=0.01998 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.019 | L2-Norm(final)=10.381 | 4703.0 samples/s | 73.5 steps/s
[Step=29750 Epoch=29.0] | Loss=0.01985 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.026 | L2-Norm(final)=10.379 | 4871.0 samples/s | 76.1 steps/s
[Step=29800 Epoch=29.1] | Loss=0.01966 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.033 | L2-Norm(final)=10.377 | 4751.2 samples/s | 74.2 steps/s
[Step=29850 Epoch=29.1] | Loss=0.01947 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.039 | L2-Norm(final)=10.376 | 4815.6 samples/s | 75.2 steps/s
[Step=29900 Epoch=29.2] | Loss=0.01944 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.046 | L2-Norm(final)=10.374 | 4860.9 samples/s | 76.0 steps/s
[Step=29950 Epoch=29.2] | Loss=0.01934 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.052 | L2-Norm(final)=10.373 | 4761.0 samples/s | 74.4 steps/s
[Step=30000 Epoch=29.3] | Loss=0.01924 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.058 | L2-Norm(final)=10.371 | 4750.6 samples/s | 74.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step30000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=28001 Epoch=52.8] | Loss=0.00039 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=11.716 | 4169.1 samples/s | 65.1 steps/s
[Step=28050 Epoch=52.9] | Loss=0.00171 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.659 | L2-Norm(final)=11.721 | 4995.3 samples/s | 78.1 steps/s
[Step=28100 Epoch=53.0] | Loss=0.00128 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.729 | 5212.8 samples/s | 81.5 steps/s
[Step=28150 Epoch=53.1] | Loss=0.00132 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.737 | 5194.8 samples/s | 81.2 steps/s
[Step=28200 Epoch=53.2] | Loss=0.00148 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.743 | 5213.5 samples/s | 81.5 steps/s
[Step=28250 Epoch=53.3] | Loss=0.00133 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.748 | 5214.3 samples/s | 81.5 steps/s
[Step=28300 Epoch=53.3] | Loss=0.00134 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.753 | 5247.9 samples/s | 82.0 steps/s
[Step=28350 Epoch=53.4] | Loss=0.00145 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.757 | 5133.1 samples/s | 80.2 steps/s
[Step=28400 Epoch=53.5] | Loss=0.00147 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.761 | 5172.0 samples/s | 80.8 steps/s
[Step=28450 Epoch=53.6] | Loss=0.00137 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.765 | 5179.3 samples/s | 80.9 steps/s
[Step=28500 Epoch=53.7] | Loss=0.00131 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.770 | 5263.3 samples/s | 82.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=53.7] | Loss=0.00007 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.816 | 4020.6 samples/s | 62.8 steps/s
[Step=28550 Epoch=53.8] | Loss=0.00073 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.666 | L2-Norm(final)=11.816 | 4298.1 samples/s | 67.2 steps/s
[Step=28600 Epoch=53.9] | Loss=0.00046 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.667 | L2-Norm(final)=11.817 | 4623.9 samples/s | 72.2 steps/s
[Step=28650 Epoch=54.0] | Loss=0.00035 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=11.818 | 4510.8 samples/s | 70.5 steps/s
[Step=28700 Epoch=54.1] | Loss=0.00026 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.654 | L2-Norm(final)=11.819 | 4556.5 samples/s | 71.2 steps/s
[Step=28750 Epoch=54.2] | Loss=0.00022 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.642 | L2-Norm(final)=11.820 | 4507.6 samples/s | 70.4 steps/s
[Step=28800 Epoch=54.3] | Loss=0.00019 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.630 | L2-Norm(final)=11.821 | 4552.6 samples/s | 71.1 steps/s
[Step=28850 Epoch=54.4] | Loss=0.00016 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.617 | L2-Norm(final)=11.822 | 4532.9 samples/s | 70.8 steps/s
[Step=28900 Epoch=54.5] | Loss=0.00014 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.604 | L2-Norm(final)=11.822 | 4555.1 samples/s | 71.2 steps/s
[Step=28950 Epoch=54.6] | Loss=0.00012 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.590 | L2-Norm(final)=11.823 | 4515.4 samples/s | 70.6 steps/s
[Step=29000 Epoch=54.7] | Loss=0.00011 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.576 | L2-Norm(final)=11.823 | 4540.5 samples/s | 70.9 steps/s
[Step=29050 Epoch=54.8] | Loss=0.00010 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.562 | L2-Norm(final)=11.824 | 2113.1 samples/s | 33.0 steps/s
[Step=29100 Epoch=54.9] | Loss=0.00009 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=11.824 | 4655.6 samples/s | 72.7 steps/s
[Step=29150 Epoch=54.9] | Loss=0.00009 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=11.825 | 4661.8 samples/s | 72.8 steps/s
[Step=29200 Epoch=55.0] | Loss=0.00008 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=11.825 | 4603.9 samples/s | 71.9 steps/s
[Step=29250 Epoch=55.1] | Loss=0.00008 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=11.826 | 4573.6 samples/s | 71.5 steps/s
[Step=29300 Epoch=55.2] | Loss=0.00007 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=11.826 | 4572.4 samples/s | 71.4 steps/s
[Step=29350 Epoch=55.3] | Loss=0.00007 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=11.827 | 4558.9 samples/s | 71.2 steps/s
[Step=29400 Epoch=55.4] | Loss=0.00006 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=11.827 | 4579.2 samples/s | 71.5 steps/s
[Step=29450 Epoch=55.5] | Loss=0.00006 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.452 | L2-Norm(final)=11.827 | 4487.7 samples/s | 70.1 steps/s
[Step=29500 Epoch=55.6] | Loss=0.00006 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=11.828 | 4527.5 samples/s | 70.7 steps/s
[Step=29550 Epoch=55.7] | Loss=0.00006 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.424 | L2-Norm(final)=11.828 | 5667.2 samples/s | 88.5 steps/s
[Step=29600 Epoch=55.8] | Loss=0.00005 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.410 | L2-Norm(final)=11.828 | 1986.3 samples/s | 31.0 steps/s
[Step=29650 Epoch=55.9] | Loss=0.00005 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.396 | L2-Norm(final)=11.828 | 4569.7 samples/s | 71.4 steps/s
[Step=29700 Epoch=56.0] | Loss=0.00005 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.829 | 4533.1 samples/s | 70.8 steps/s
[Step=29750 Epoch=56.1] | Loss=0.00005 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=11.829 | 4636.0 samples/s | 72.4 steps/s
[Step=29800 Epoch=56.2] | Loss=0.00004 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.354 | L2-Norm(final)=11.829 | 4629.2 samples/s | 72.3 steps/s
[Step=29850 Epoch=56.3] | Loss=0.00004 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.340 | L2-Norm(final)=11.829 | 4590.4 samples/s | 71.7 steps/s
[Step=29900 Epoch=56.4] | Loss=0.00004 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=11.829 | 4565.4 samples/s | 71.3 steps/s
[Step=29950 Epoch=56.5] | Loss=0.00004 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=11.830 | 4460.1 samples/s | 69.7 steps/s
[Step=30000 Epoch=56.6] | Loss=0.00004 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=11.830 | 4509.8 samples/s | 70.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05678 | acc=0.9674 | tpr=0.9667 | fpr=0.0310 | 4595.9 samples/s | 18.0 steps/s
Avg test loss: 0.06080, Avg test acc: 0.96642, Avg tpr: 0.96550, Avg fpr: 0.03153, total FA: 246

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=9.70193 | acc=0.2908 | tpr=0.0163 | fpr=0.1132 | 4542.5 samples/s | 17.7 steps/s
Avg test loss: 9.72624, Avg test acc: 0.28905, Avg tpr: 0.01690, Avg fpr: 0.11242, total FA: 877

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.08963 | acc=0.1643 | tpr=0.4336 | fpr=0.8405 | 4523.4 samples/s | 17.7 steps/s
[Step= 100] | Loss=5.04349 | acc=0.1639 | tpr=0.4456 | fpr=0.8413 | 8707.4 samples/s | 34.0 steps/s
[Step= 150] | Loss=5.03972 | acc=0.1650 | tpr=0.4611 | fpr=0.8405 | 8369.0 samples/s | 32.7 steps/s
[Step= 200] | Loss=5.02853 | acc=0.1653 | tpr=0.4568 | fpr=0.8400 | 8473.4 samples/s | 33.1 steps/s
[Step= 250] | Loss=5.02730 | acc=0.1663 | tpr=0.4646 | fpr=0.8391 | 8418.4 samples/s | 32.9 steps/s
[Step= 300] | Loss=5.02160 | acc=0.1661 | tpr=0.4618 | fpr=0.8393 | 8653.1 samples/s | 33.8 steps/s
[Step= 350] | Loss=5.01711 | acc=0.1659 | tpr=0.4615 | fpr=0.8394 | 8336.8 samples/s | 32.6 steps/s
[Step= 400] | Loss=5.01611 | acc=0.1663 | tpr=0.4628 | fpr=0.8391 | 8442.4 samples/s | 33.0 steps/s
[Step= 450] | Loss=5.01845 | acc=0.1662 | tpr=0.4606 | fpr=0.8391 | 8483.9 samples/s | 33.1 steps/s
[Step= 500] | Loss=5.01580 | acc=0.1664 | tpr=0.4612 | fpr=0.8389 | 8395.3 samples/s | 32.8 steps/s
[Step= 550] | Loss=5.01716 | acc=0.1665 | tpr=0.4604 | fpr=0.8388 | 15786.1 samples/s | 61.7 steps/s
Avg test loss: 5.01849, Avg test acc: 0.16634, Avg tpr: 0.45998, Avg fpr: 0.83900, total FA: 116493

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16205 | acc=0.9836 | tpr=0.9513 | fpr=0.0158 | 4553.3 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.17226 | acc=0.9827 | tpr=0.9488 | fpr=0.0167 | 8606.2 samples/s | 33.6 steps/s
[Step= 150] | Loss=0.17858 | acc=0.9820 | tpr=0.9524 | fpr=0.0175 | 8297.6 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.17919 | acc=0.9818 | tpr=0.9530 | fpr=0.0177 | 8420.9 samples/s | 32.9 steps/s
[Step= 250] | Loss=0.17581 | acc=0.9822 | tpr=0.9502 | fpr=0.0172 | 9082.2 samples/s | 35.5 steps/s
[Step= 300] | Loss=0.17808 | acc=0.9821 | tpr=0.9520 | fpr=0.0174 | 8027.6 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.18074 | acc=0.9818 | tpr=0.9537 | fpr=0.0177 | 8387.6 samples/s | 32.8 steps/s
[Step= 400] | Loss=0.18179 | acc=0.9817 | tpr=0.9530 | fpr=0.0178 | 8494.4 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.18627 | acc=0.9813 | tpr=0.9494 | fpr=0.0181 | 8292.9 samples/s | 32.4 steps/s
[Step= 500] | Loss=0.18553 | acc=0.9814 | tpr=0.9498 | fpr=0.0181 | 8768.7 samples/s | 34.3 steps/s
[Step= 550] | Loss=0.18395 | acc=0.9815 | tpr=0.9499 | fpr=0.0179 | 15186.3 samples/s | 59.3 steps/s
Avg test loss: 0.18391, Avg test acc: 0.98151, Avg tpr: 0.94968, Avg fpr: 0.01791, total FA: 2487

server round 15/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=30001 Epoch=29.3] | Loss=0.01024 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.388 | L2-Norm(final)=10.327 | 4462.9 samples/s | 69.7 steps/s
[Step=30050 Epoch=29.3] | Loss=0.02125 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=10.331 | 5054.1 samples/s | 79.0 steps/s
[Step=30100 Epoch=29.4] | Loss=0.02208 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.389 | L2-Norm(final)=10.340 | 5687.1 samples/s | 88.9 steps/s
[Step=30150 Epoch=29.4] | Loss=0.02130 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.390 | L2-Norm(final)=10.348 | 5546.2 samples/s | 86.7 steps/s
[Step=30200 Epoch=29.5] | Loss=0.02062 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=10.358 | 5711.2 samples/s | 89.2 steps/s
[Step=30250 Epoch=29.5] | Loss=0.02034 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.390 | L2-Norm(final)=10.369 | 5685.6 samples/s | 88.8 steps/s
[Step=30300 Epoch=29.6] | Loss=0.01988 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.390 | L2-Norm(final)=10.379 | 5526.7 samples/s | 86.4 steps/s
[Step=30350 Epoch=29.6] | Loss=0.01959 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.390 | L2-Norm(final)=10.390 | 5535.3 samples/s | 86.5 steps/s
[Step=30400 Epoch=29.7] | Loss=0.01910 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=10.401 | 5482.3 samples/s | 85.7 steps/s
[Step=30450 Epoch=29.7] | Loss=0.01938 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=10.412 | 5615.0 samples/s | 87.7 steps/s
[Step=30500 Epoch=29.8] | Loss=0.01938 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.390 | L2-Norm(final)=10.423 | 5436.6 samples/s | 84.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=29.8] | Loss=0.00720 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=10.535 | 4120.3 samples/s | 64.4 steps/s
[Step=30550 Epoch=29.8] | Loss=0.01635 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.425 | L2-Norm(final)=10.533 | 4844.4 samples/s | 75.7 steps/s
[Step=30600 Epoch=29.9] | Loss=0.01668 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.459 | L2-Norm(final)=10.530 | 4716.6 samples/s | 73.7 steps/s
[Step=30650 Epoch=29.9] | Loss=0.01675 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.481 | L2-Norm(final)=10.526 | 4755.7 samples/s | 74.3 steps/s
[Step=30700 Epoch=30.0] | Loss=0.01613 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.495 | L2-Norm(final)=10.523 | 4758.6 samples/s | 74.4 steps/s
[Step=30750 Epoch=30.0] | Loss=0.01635 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.509 | L2-Norm(final)=10.521 | 4797.7 samples/s | 75.0 steps/s
[Step=30800 Epoch=30.1] | Loss=0.01698 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.522 | L2-Norm(final)=10.520 | 4744.3 samples/s | 74.1 steps/s
[Step=30850 Epoch=30.1] | Loss=0.01713 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.536 | L2-Norm(final)=10.518 | 4784.1 samples/s | 74.8 steps/s
[Step=30900 Epoch=30.2] | Loss=0.01722 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.550 | L2-Norm(final)=10.517 | 4907.0 samples/s | 76.7 steps/s
[Step=30950 Epoch=30.2] | Loss=0.01751 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.563 | L2-Norm(final)=10.515 | 4875.5 samples/s | 76.2 steps/s
[Step=31000 Epoch=30.3] | Loss=0.01749 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.574 | L2-Norm(final)=10.512 | 4753.9 samples/s | 74.3 steps/s
[Step=31050 Epoch=30.3] | Loss=0.01754 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.585 | L2-Norm(final)=10.510 | 4777.3 samples/s | 74.6 steps/s
[Step=31100 Epoch=30.4] | Loss=0.01742 | Reg=0.00243 | acc=0.9531 | L2-Norm=15.595 | L2-Norm(final)=10.508 | 4796.8 samples/s | 74.9 steps/s
[Step=31150 Epoch=30.4] | Loss=0.01724 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.605 | L2-Norm(final)=10.506 | 4774.9 samples/s | 74.6 steps/s
[Step=31200 Epoch=30.5] | Loss=0.01726 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.613 | L2-Norm(final)=10.503 | 4766.2 samples/s | 74.5 steps/s
[Step=31250 Epoch=30.5] | Loss=0.01731 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.621 | L2-Norm(final)=10.502 | 4787.0 samples/s | 74.8 steps/s
[Step=31300 Epoch=30.6] | Loss=0.01750 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.629 | L2-Norm(final)=10.500 | 4730.2 samples/s | 73.9 steps/s
[Step=31350 Epoch=30.6] | Loss=0.01740 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.636 | L2-Norm(final)=10.498 | 4771.7 samples/s | 74.6 steps/s
[Step=31400 Epoch=30.7] | Loss=0.01744 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.644 | L2-Norm(final)=10.496 | 4825.4 samples/s | 75.4 steps/s
[Step=31450 Epoch=30.7] | Loss=0.01743 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.651 | L2-Norm(final)=10.495 | 4818.3 samples/s | 75.3 steps/s
[Step=31500 Epoch=30.8] | Loss=0.01744 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.659 | L2-Norm(final)=10.493 | 5105.5 samples/s | 79.8 steps/s
[Step=31550 Epoch=30.8] | Loss=0.01743 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.666 | L2-Norm(final)=10.491 | 2162.4 samples/s | 33.8 steps/s
[Step=31600 Epoch=30.9] | Loss=0.01738 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.673 | L2-Norm(final)=10.490 | 4774.2 samples/s | 74.6 steps/s
[Step=31650 Epoch=30.9] | Loss=0.01721 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.680 | L2-Norm(final)=10.489 | 4927.5 samples/s | 77.0 steps/s
[Step=31700 Epoch=30.9] | Loss=0.01712 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.687 | L2-Norm(final)=10.488 | 4793.8 samples/s | 74.9 steps/s
[Step=31750 Epoch=31.0] | Loss=0.01703 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.694 | L2-Norm(final)=10.487 | 4804.8 samples/s | 75.1 steps/s
[Step=31800 Epoch=31.0] | Loss=0.01694 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.700 | L2-Norm(final)=10.485 | 4847.1 samples/s | 75.7 steps/s
[Step=31850 Epoch=31.1] | Loss=0.01686 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=10.484 | 4811.0 samples/s | 75.2 steps/s
[Step=31900 Epoch=31.1] | Loss=0.01681 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=10.483 | 4843.7 samples/s | 75.7 steps/s
[Step=31950 Epoch=31.2] | Loss=0.01682 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.718 | L2-Norm(final)=10.482 | 4817.2 samples/s | 75.3 steps/s
[Step=32000 Epoch=31.2] | Loss=0.01670 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.724 | L2-Norm(final)=10.481 | 4730.2 samples/s | 73.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step32000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=30001 Epoch=56.6] | Loss=0.00050 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=11.837 | 4370.7 samples/s | 68.3 steps/s
[Step=30050 Epoch=56.6] | Loss=0.00101 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=11.845 | 4809.3 samples/s | 75.1 steps/s
[Step=30100 Epoch=56.7] | Loss=0.00097 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=11.851 | 5155.8 samples/s | 80.6 steps/s
[Step=30150 Epoch=56.8] | Loss=0.00079 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.859 | 5159.6 samples/s | 80.6 steps/s
[Step=30200 Epoch=56.9] | Loss=0.00081 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.868 | 5235.9 samples/s | 81.8 steps/s
[Step=30250 Epoch=57.0] | Loss=0.00099 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.878 | 5206.6 samples/s | 81.4 steps/s
[Step=30300 Epoch=57.1] | Loss=0.00091 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.886 | 5174.9 samples/s | 80.9 steps/s
[Step=30350 Epoch=57.2] | Loss=0.00084 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.894 | 5166.7 samples/s | 80.7 steps/s
[Step=30400 Epoch=57.3] | Loss=0.00082 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.902 | 5224.4 samples/s | 81.6 steps/s
[Step=30450 Epoch=57.4] | Loss=0.00082 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.910 | 5144.2 samples/s | 80.4 steps/s
[Step=30500 Epoch=57.5] | Loss=0.00083 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.917 | 5201.0 samples/s | 81.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=57.5] | Loss=0.00152 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=11.997 | 3844.7 samples/s | 60.1 steps/s
[Step=30550 Epoch=57.6] | Loss=0.00541 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.407 | L2-Norm(final)=11.998 | 4564.1 samples/s | 71.3 steps/s
[Step=30600 Epoch=57.7] | Loss=0.00684 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.516 | L2-Norm(final)=11.981 | 4505.5 samples/s | 70.4 steps/s
[Step=30650 Epoch=57.8] | Loss=0.00815 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=11.961 | 4493.6 samples/s | 70.2 steps/s
[Step=30700 Epoch=57.9] | Loss=0.00756 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.647 | L2-Norm(final)=11.943 | 4639.3 samples/s | 72.5 steps/s
[Step=30750 Epoch=58.0] | Loss=0.00625 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.684 | L2-Norm(final)=11.929 | 4481.2 samples/s | 70.0 steps/s
[Step=30800 Epoch=58.1] | Loss=0.00544 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=11.920 | 4741.1 samples/s | 74.1 steps/s
[Step=30850 Epoch=58.2] | Loss=0.00486 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.721 | L2-Norm(final)=11.912 | 4517.0 samples/s | 70.6 steps/s
[Step=30900 Epoch=58.2] | Loss=0.00455 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=11.906 | 4618.5 samples/s | 72.2 steps/s
[Step=30950 Epoch=58.3] | Loss=0.00417 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.742 | L2-Norm(final)=11.901 | 4620.9 samples/s | 72.2 steps/s
[Step=31000 Epoch=58.4] | Loss=0.00382 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.750 | L2-Norm(final)=11.896 | 4712.4 samples/s | 73.6 steps/s
[Step=31050 Epoch=58.5] | Loss=0.00348 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.755 | L2-Norm(final)=11.892 | 2106.6 samples/s | 32.9 steps/s
[Step=31100 Epoch=58.6] | Loss=0.00319 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=11.888 | 4644.6 samples/s | 72.6 steps/s
[Step=31150 Epoch=58.7] | Loss=0.00295 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.759 | L2-Norm(final)=11.886 | 4553.4 samples/s | 71.1 steps/s
[Step=31200 Epoch=58.8] | Loss=0.00276 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.760 | L2-Norm(final)=11.884 | 4542.0 samples/s | 71.0 steps/s
[Step=31250 Epoch=58.9] | Loss=0.00258 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.759 | L2-Norm(final)=11.882 | 4565.5 samples/s | 71.3 steps/s
[Step=31300 Epoch=59.0] | Loss=0.00242 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=11.880 | 4573.0 samples/s | 71.5 steps/s
[Step=31350 Epoch=59.1] | Loss=0.00229 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.757 | L2-Norm(final)=11.879 | 4465.4 samples/s | 69.8 steps/s
[Step=31400 Epoch=59.2] | Loss=0.00216 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.754 | L2-Norm(final)=11.877 | 4534.9 samples/s | 70.9 steps/s
[Step=31450 Epoch=59.3] | Loss=0.00205 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.751 | L2-Norm(final)=11.876 | 4604.8 samples/s | 71.9 steps/s
[Step=31500 Epoch=59.4] | Loss=0.00195 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.748 | L2-Norm(final)=11.875 | 4526.4 samples/s | 70.7 steps/s
[Step=31550 Epoch=59.5] | Loss=0.00186 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.745 | L2-Norm(final)=11.875 | 5707.7 samples/s | 89.2 steps/s
[Step=31600 Epoch=59.6] | Loss=0.00178 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.741 | L2-Norm(final)=11.874 | 1987.6 samples/s | 31.1 steps/s
[Step=31650 Epoch=59.7] | Loss=0.00170 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=11.873 | 4664.5 samples/s | 72.9 steps/s
[Step=31700 Epoch=59.8] | Loss=0.00163 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=11.873 | 4663.9 samples/s | 72.9 steps/s
[Step=31750 Epoch=59.8] | Loss=0.00156 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.727 | L2-Norm(final)=11.873 | 4633.0 samples/s | 72.4 steps/s
[Step=31800 Epoch=59.9] | Loss=0.00150 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.722 | L2-Norm(final)=11.872 | 4584.9 samples/s | 71.6 steps/s
[Step=31850 Epoch=60.0] | Loss=0.00145 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.717 | L2-Norm(final)=11.872 | 4610.4 samples/s | 72.0 steps/s
[Step=31900 Epoch=60.1] | Loss=0.00140 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.711 | L2-Norm(final)=11.872 | 4475.4 samples/s | 69.9 steps/s
[Step=31950 Epoch=60.2] | Loss=0.00135 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=11.872 | 4611.9 samples/s | 72.1 steps/s
[Step=32000 Epoch=60.3] | Loss=0.00130 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.700 | L2-Norm(final)=11.872 | 4514.8 samples/s | 70.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05631 | acc=0.9705 | tpr=0.9746 | fpr=0.0382 | 4507.8 samples/s | 17.6 steps/s
Avg test loss: 0.06370, Avg test acc: 0.96931, Avg tpr: 0.97301, Avg fpr: 0.03884, total FA: 303

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.08458 | acc=0.3123 | tpr=0.0116 | fpr=0.0347 | 4586.1 samples/s | 17.9 steps/s
Avg test loss: 10.09808, Avg test acc: 0.30928, Avg tpr: 0.01166, Avg fpr: 0.03615, total FA: 282

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.70581 | acc=0.1199 | tpr=0.5044 | fpr=0.8870 | 4576.7 samples/s | 17.9 steps/s
[Step= 100] | Loss=6.67268 | acc=0.1220 | tpr=0.5011 | fpr=0.8851 | 8322.5 samples/s | 32.5 steps/s
[Step= 150] | Loss=6.67626 | acc=0.1218 | tpr=0.4986 | fpr=0.8852 | 8789.4 samples/s | 34.3 steps/s
[Step= 200] | Loss=6.66485 | acc=0.1220 | tpr=0.5027 | fpr=0.8850 | 8682.3 samples/s | 33.9 steps/s
[Step= 250] | Loss=6.66629 | acc=0.1227 | tpr=0.5039 | fpr=0.8843 | 8257.4 samples/s | 32.3 steps/s
[Step= 300] | Loss=6.66177 | acc=0.1221 | tpr=0.5076 | fpr=0.8850 | 8295.5 samples/s | 32.4 steps/s
[Step= 350] | Loss=6.65993 | acc=0.1215 | tpr=0.5072 | fpr=0.8855 | 9033.1 samples/s | 35.3 steps/s
[Step= 400] | Loss=6.66148 | acc=0.1214 | tpr=0.5038 | fpr=0.8855 | 7894.0 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.66450 | acc=0.1213 | tpr=0.4976 | fpr=0.8855 | 8522.8 samples/s | 33.3 steps/s
[Step= 500] | Loss=6.66280 | acc=0.1215 | tpr=0.4952 | fpr=0.8853 | 8496.9 samples/s | 33.2 steps/s
[Step= 550] | Loss=6.66309 | acc=0.1221 | tpr=0.4998 | fpr=0.8848 | 15385.2 samples/s | 60.1 steps/s
Avg test loss: 6.66419, Avg test acc: 0.12194, Avg tpr: 0.50000, Avg fpr: 0.88493, total FA: 122871

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16550 | acc=0.9820 | tpr=0.9602 | fpr=0.0176 | 4505.9 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.17416 | acc=0.9810 | tpr=0.9595 | fpr=0.0186 | 8688.6 samples/s | 33.9 steps/s
[Step= 150] | Loss=0.18096 | acc=0.9802 | tpr=0.9553 | fpr=0.0193 | 8939.1 samples/s | 34.9 steps/s
[Step= 200] | Loss=0.18355 | acc=0.9803 | tpr=0.9607 | fpr=0.0193 | 8345.0 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.18071 | acc=0.9806 | tpr=0.9598 | fpr=0.0190 | 8887.6 samples/s | 34.7 steps/s
[Step= 300] | Loss=0.18381 | acc=0.9805 | tpr=0.9607 | fpr=0.0192 | 8068.7 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.18650 | acc=0.9802 | tpr=0.9618 | fpr=0.0195 | 8443.5 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.18804 | acc=0.9801 | tpr=0.9595 | fpr=0.0195 | 8594.5 samples/s | 33.6 steps/s
[Step= 450] | Loss=0.19194 | acc=0.9796 | tpr=0.9562 | fpr=0.0200 | 8597.0 samples/s | 33.6 steps/s
[Step= 500] | Loss=0.19068 | acc=0.9797 | tpr=0.9559 | fpr=0.0199 | 8258.6 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.18923 | acc=0.9797 | tpr=0.9546 | fpr=0.0198 | 15429.6 samples/s | 60.3 steps/s
Avg test loss: 0.18874, Avg test acc: 0.97978, Avg tpr: 0.95444, Avg fpr: 0.01976, total FA: 2744

server round 16/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=32001 Epoch=31.2] | Loss=0.05017 | Reg=0.00239 | acc=0.9531 | L2-Norm=15.474 | L2-Norm(final)=10.451 | 4180.5 samples/s | 65.3 steps/s
[Step=32050 Epoch=31.3] | Loss=0.03391 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=10.444 | 5363.4 samples/s | 83.8 steps/s
[Step=32100 Epoch=31.3] | Loss=0.03637 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.477 | L2-Norm(final)=10.442 | 5542.5 samples/s | 86.6 steps/s
[Step=32150 Epoch=31.4] | Loss=0.03522 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.477 | L2-Norm(final)=10.445 | 5420.8 samples/s | 84.7 steps/s
[Step=32200 Epoch=31.4] | Loss=0.03539 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.477 | L2-Norm(final)=10.451 | 5461.8 samples/s | 85.3 steps/s
[Step=32250 Epoch=31.5] | Loss=0.03404 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.477 | L2-Norm(final)=10.459 | 5512.3 samples/s | 86.1 steps/s
[Step=32300 Epoch=31.5] | Loss=0.03306 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.477 | L2-Norm(final)=10.469 | 5558.9 samples/s | 86.9 steps/s
[Step=32350 Epoch=31.6] | Loss=0.03295 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.477 | L2-Norm(final)=10.478 | 5510.2 samples/s | 86.1 steps/s
[Step=32400 Epoch=31.6] | Loss=0.03344 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.477 | L2-Norm(final)=10.486 | 5409.1 samples/s | 84.5 steps/s
[Step=32450 Epoch=31.7] | Loss=0.03306 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.477 | L2-Norm(final)=10.493 | 5578.8 samples/s | 87.2 steps/s
[Step=32500 Epoch=31.7] | Loss=0.03304 | Reg=0.00240 | acc=0.9531 | L2-Norm=15.477 | L2-Norm(final)=10.500 | 5463.3 samples/s | 85.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=31.7] | Loss=0.02525 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.477 | L2-Norm(final)=10.568 | 4068.4 samples/s | 63.6 steps/s
[Step=32550 Epoch=31.8] | Loss=0.02320 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.524 | L2-Norm(final)=10.572 | 4672.3 samples/s | 73.0 steps/s
[Step=32600 Epoch=31.8] | Loss=0.02270 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=10.573 | 4810.9 samples/s | 75.2 steps/s
[Step=32650 Epoch=31.9] | Loss=0.02320 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.598 | L2-Norm(final)=10.570 | 4799.0 samples/s | 75.0 steps/s
[Step=32700 Epoch=31.9] | Loss=0.02338 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.623 | L2-Norm(final)=10.566 | 4733.4 samples/s | 74.0 steps/s
[Step=32750 Epoch=32.0] | Loss=0.02377 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.644 | L2-Norm(final)=10.563 | 4827.8 samples/s | 75.4 steps/s
[Step=32800 Epoch=32.0] | Loss=0.02312 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.663 | L2-Norm(final)=10.559 | 4912.8 samples/s | 76.8 steps/s
[Step=32850 Epoch=32.1] | Loss=0.02256 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.679 | L2-Norm(final)=10.557 | 4835.5 samples/s | 75.6 steps/s
[Step=32900 Epoch=32.1] | Loss=0.02212 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.693 | L2-Norm(final)=10.555 | 4793.1 samples/s | 74.9 steps/s
[Step=32950 Epoch=32.2] | Loss=0.02210 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.705 | L2-Norm(final)=10.553 | 4873.8 samples/s | 76.2 steps/s
[Step=33000 Epoch=32.2] | Loss=0.02177 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.717 | L2-Norm(final)=10.552 | 4795.8 samples/s | 74.9 steps/s
[Step=33050 Epoch=32.3] | Loss=0.02152 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.727 | L2-Norm(final)=10.550 | 4825.2 samples/s | 75.4 steps/s
[Step=33100 Epoch=32.3] | Loss=0.02130 | Reg=0.00248 | acc=0.9688 | L2-Norm=15.736 | L2-Norm(final)=10.549 | 4768.9 samples/s | 74.5 steps/s
[Step=33150 Epoch=32.4] | Loss=0.02115 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.744 | L2-Norm(final)=10.548 | 4811.6 samples/s | 75.2 steps/s
[Step=33200 Epoch=32.4] | Loss=0.02105 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.752 | L2-Norm(final)=10.547 | 4801.4 samples/s | 75.0 steps/s
[Step=33250 Epoch=32.5] | Loss=0.02089 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.759 | L2-Norm(final)=10.545 | 4739.0 samples/s | 74.0 steps/s
[Step=33300 Epoch=32.5] | Loss=0.02057 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=10.544 | 4821.9 samples/s | 75.3 steps/s
[Step=33350 Epoch=32.6] | Loss=0.02074 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.773 | L2-Norm(final)=10.543 | 4757.3 samples/s | 74.3 steps/s
[Step=33400 Epoch=32.6] | Loss=0.02064 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.779 | L2-Norm(final)=10.542 | 4864.3 samples/s | 76.0 steps/s
[Step=33450 Epoch=32.7] | Loss=0.02060 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.785 | L2-Norm(final)=10.540 | 4768.8 samples/s | 74.5 steps/s
[Step=33500 Epoch=32.7] | Loss=0.02036 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=10.539 | 5128.2 samples/s | 80.1 steps/s
[Step=33550 Epoch=32.8] | Loss=0.02011 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.798 | L2-Norm(final)=10.538 | 2132.4 samples/s | 33.3 steps/s
[Step=33600 Epoch=32.8] | Loss=0.01980 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.803 | L2-Norm(final)=10.538 | 4930.6 samples/s | 77.0 steps/s
[Step=33650 Epoch=32.9] | Loss=0.01957 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.809 | L2-Norm(final)=10.537 | 4718.2 samples/s | 73.7 steps/s
[Step=33700 Epoch=32.9] | Loss=0.01925 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=10.537 | 4788.3 samples/s | 74.8 steps/s
[Step=33750 Epoch=33.0] | Loss=0.01891 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.819 | L2-Norm(final)=10.536 | 4780.9 samples/s | 74.7 steps/s
[Step=33800 Epoch=33.0] | Loss=0.01884 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.823 | L2-Norm(final)=10.536 | 4755.8 samples/s | 74.3 steps/s
[Step=33850 Epoch=33.0] | Loss=0.01864 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.828 | L2-Norm(final)=10.536 | 4786.3 samples/s | 74.8 steps/s
[Step=33900 Epoch=33.1] | Loss=0.01856 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.833 | L2-Norm(final)=10.535 | 4776.1 samples/s | 74.6 steps/s
[Step=33950 Epoch=33.1] | Loss=0.01841 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.837 | L2-Norm(final)=10.535 | 4794.7 samples/s | 74.9 steps/s
[Step=34000 Epoch=33.2] | Loss=0.01825 | Reg=0.00251 | acc=0.9688 | L2-Norm=15.842 | L2-Norm(final)=10.535 | 4784.5 samples/s | 74.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step34000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=32001 Epoch=60.3] | Loss=0.00003 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.474 | L2-Norm(final)=11.873 | 4515.3 samples/s | 70.6 steps/s
[Step=32050 Epoch=60.4] | Loss=0.00029 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.875 | 4728.6 samples/s | 73.9 steps/s
[Step=32100 Epoch=60.5] | Loss=0.00045 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.877 | 5165.9 samples/s | 80.7 steps/s
[Step=32150 Epoch=60.6] | Loss=0.00041 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.879 | 5227.8 samples/s | 81.7 steps/s
[Step=32200 Epoch=60.7] | Loss=0.00043 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.882 | 5398.6 samples/s | 84.4 steps/s
[Step=32250 Epoch=60.8] | Loss=0.00040 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.884 | 5042.5 samples/s | 78.8 steps/s
[Step=32300 Epoch=60.9] | Loss=0.00044 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.886 | 5348.8 samples/s | 83.6 steps/s
[Step=32350 Epoch=61.0] | Loss=0.00044 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.889 | 5325.6 samples/s | 83.2 steps/s
[Step=32400 Epoch=61.1] | Loss=0.00045 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.891 | 5143.1 samples/s | 80.4 steps/s
[Step=32450 Epoch=61.2] | Loss=0.00042 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=11.894 | 5283.3 samples/s | 82.6 steps/s
[Step=32500 Epoch=61.3] | Loss=0.00043 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.471 | L2-Norm(final)=11.896 | 5319.0 samples/s | 83.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=61.3] | Loss=0.00002 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.471 | L2-Norm(final)=11.917 | 4030.6 samples/s | 63.0 steps/s
[Step=32550 Epoch=61.4] | Loss=0.00018 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.454 | L2-Norm(final)=11.920 | 4360.2 samples/s | 68.1 steps/s
[Step=32600 Epoch=61.5] | Loss=0.00019 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.447 | L2-Norm(final)=11.922 | 4598.9 samples/s | 71.9 steps/s
[Step=32650 Epoch=61.5] | Loss=0.00014 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.440 | L2-Norm(final)=11.925 | 4513.1 samples/s | 70.5 steps/s
[Step=32700 Epoch=61.6] | Loss=0.00078 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=11.925 | 4536.9 samples/s | 70.9 steps/s
[Step=32750 Epoch=61.7] | Loss=0.00110 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.440 | L2-Norm(final)=11.921 | 4564.3 samples/s | 71.3 steps/s
[Step=32800 Epoch=61.8] | Loss=0.00102 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.449 | L2-Norm(final)=11.917 | 4580.6 samples/s | 71.6 steps/s
[Step=32850 Epoch=61.9] | Loss=0.00092 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=11.915 | 4488.0 samples/s | 70.1 steps/s
[Step=32900 Epoch=62.0] | Loss=0.00082 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.454 | L2-Norm(final)=11.913 | 4599.1 samples/s | 71.9 steps/s
[Step=32950 Epoch=62.1] | Loss=0.00073 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=11.912 | 4620.6 samples/s | 72.2 steps/s
[Step=33000 Epoch=62.2] | Loss=0.00066 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.451 | L2-Norm(final)=11.911 | 4589.6 samples/s | 71.7 steps/s
[Step=33050 Epoch=62.3] | Loss=0.00060 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.447 | L2-Norm(final)=11.910 | 2113.0 samples/s | 33.0 steps/s
[Step=33100 Epoch=62.4] | Loss=0.00055 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.442 | L2-Norm(final)=11.910 | 4584.8 samples/s | 71.6 steps/s
[Step=33150 Epoch=62.5] | Loss=0.00051 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=11.909 | 4629.3 samples/s | 72.3 steps/s
[Step=33200 Epoch=62.6] | Loss=0.00047 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=11.909 | 4552.7 samples/s | 71.1 steps/s
[Step=33250 Epoch=62.7] | Loss=0.00044 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.423 | L2-Norm(final)=11.909 | 4515.9 samples/s | 70.6 steps/s
[Step=33300 Epoch=62.8] | Loss=0.00041 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=11.909 | 4549.1 samples/s | 71.1 steps/s
[Step=33350 Epoch=62.9] | Loss=0.00039 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.409 | L2-Norm(final)=11.909 | 4529.3 samples/s | 70.8 steps/s
[Step=33400 Epoch=63.0] | Loss=0.00037 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.401 | L2-Norm(final)=11.909 | 4553.7 samples/s | 71.2 steps/s
[Step=33450 Epoch=63.1] | Loss=0.00035 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=11.909 | 4502.4 samples/s | 70.4 steps/s
[Step=33500 Epoch=63.1] | Loss=0.00033 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.386 | L2-Norm(final)=11.909 | 4588.0 samples/s | 71.7 steps/s
[Step=33550 Epoch=63.2] | Loss=0.00032 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=11.909 | 5914.6 samples/s | 92.4 steps/s
[Step=33600 Epoch=63.3] | Loss=0.00030 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=11.909 | 1963.1 samples/s | 30.7 steps/s
[Step=33650 Epoch=63.4] | Loss=0.00029 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=11.909 | 4498.2 samples/s | 70.3 steps/s
[Step=33700 Epoch=63.5] | Loss=0.00028 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=11.909 | 4706.5 samples/s | 73.5 steps/s
[Step=33750 Epoch=63.6] | Loss=0.00027 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=11.910 | 4720.0 samples/s | 73.7 steps/s
[Step=33800 Epoch=63.7] | Loss=0.00026 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=11.910 | 4568.9 samples/s | 71.4 steps/s
[Step=33850 Epoch=63.8] | Loss=0.00025 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.326 | L2-Norm(final)=11.910 | 4734.8 samples/s | 74.0 steps/s
[Step=33900 Epoch=63.9] | Loss=0.00024 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=11.910 | 4674.3 samples/s | 73.0 steps/s
[Step=33950 Epoch=64.0] | Loss=0.00023 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.308 | L2-Norm(final)=11.910 | 4571.6 samples/s | 71.4 steps/s
[Step=34000 Epoch=64.1] | Loss=0.00022 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.299 | L2-Norm(final)=11.910 | 4542.6 samples/s | 71.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05468 | acc=0.9723 | tpr=0.9776 | fpr=0.0391 | 4509.1 samples/s | 17.6 steps/s
Avg test loss: 0.06013, Avg test acc: 0.97075, Avg tpr: 0.97610, Avg fpr: 0.04102, total FA: 320

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.15088 | acc=0.3050 | tpr=0.0160 | fpr=0.0674 | 4552.3 samples/s | 17.8 steps/s
Avg test loss: 7.16151, Avg test acc: 0.30195, Avg tpr: 0.01597, Avg fpr: 0.06909, total FA: 539

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.58213 | acc=0.1457 | tpr=0.5575 | fpr=0.8617 | 4616.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=6.52557 | acc=0.1468 | tpr=0.5522 | fpr=0.8608 | 8177.7 samples/s | 31.9 steps/s
[Step= 150] | Loss=6.52001 | acc=0.1466 | tpr=0.5576 | fpr=0.8610 | 8576.1 samples/s | 33.5 steps/s
[Step= 200] | Loss=6.50940 | acc=0.1465 | tpr=0.5727 | fpr=0.8612 | 8864.8 samples/s | 34.6 steps/s
[Step= 250] | Loss=6.51214 | acc=0.1471 | tpr=0.5799 | fpr=0.8608 | 8346.0 samples/s | 32.6 steps/s
[Step= 300] | Loss=6.50633 | acc=0.1471 | tpr=0.5825 | fpr=0.8608 | 8775.8 samples/s | 34.3 steps/s
[Step= 350] | Loss=6.50201 | acc=0.1468 | tpr=0.5905 | fpr=0.8613 | 8281.9 samples/s | 32.4 steps/s
[Step= 400] | Loss=6.50106 | acc=0.1469 | tpr=0.5935 | fpr=0.8613 | 8440.0 samples/s | 33.0 steps/s
[Step= 450] | Loss=6.50585 | acc=0.1467 | tpr=0.5906 | fpr=0.8614 | 8339.7 samples/s | 32.6 steps/s
[Step= 500] | Loss=6.50307 | acc=0.1470 | tpr=0.5907 | fpr=0.8610 | 8793.5 samples/s | 34.3 steps/s
[Step= 550] | Loss=6.50513 | acc=0.1474 | tpr=0.5881 | fpr=0.8606 | 13983.6 samples/s | 54.6 steps/s
Avg test loss: 6.50639, Avg test acc: 0.14726, Avg tpr: 0.58756, Avg fpr: 0.86075, total FA: 119513

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15967 | acc=0.9812 | tpr=0.9469 | fpr=0.0181 | 4542.9 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.16858 | acc=0.9798 | tpr=0.9510 | fpr=0.0196 | 8498.6 samples/s | 33.2 steps/s
[Step= 150] | Loss=0.17395 | acc=0.9792 | tpr=0.9582 | fpr=0.0204 | 8564.6 samples/s | 33.5 steps/s
[Step= 200] | Loss=0.17701 | acc=0.9793 | tpr=0.9639 | fpr=0.0204 | 9056.5 samples/s | 35.4 steps/s
[Step= 250] | Loss=0.17424 | acc=0.9796 | tpr=0.9616 | fpr=0.0200 | 8163.1 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.17685 | acc=0.9795 | tpr=0.9622 | fpr=0.0202 | 8917.3 samples/s | 34.8 steps/s
[Step= 350] | Loss=0.17995 | acc=0.9792 | tpr=0.9631 | fpr=0.0205 | 8319.8 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.18121 | acc=0.9791 | tpr=0.9612 | fpr=0.0206 | 8485.4 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.18498 | acc=0.9787 | tpr=0.9586 | fpr=0.0209 | 9026.2 samples/s | 35.3 steps/s
[Step= 500] | Loss=0.18388 | acc=0.9788 | tpr=0.9595 | fpr=0.0209 | 7961.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.18189 | acc=0.9790 | tpr=0.9590 | fpr=0.0207 | 15755.3 samples/s | 61.5 steps/s
Avg test loss: 0.18166, Avg test acc: 0.97897, Avg tpr: 0.95880, Avg fpr: 0.02066, total FA: 2869

server round 17/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=34001 Epoch=33.2] | Loss=0.02594 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.349 | L2-Norm(final)=10.527 | 4398.4 samples/s | 68.7 steps/s
[Step=34050 Epoch=33.2] | Loss=0.02338 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.351 | L2-Norm(final)=10.536 | 5125.5 samples/s | 80.1 steps/s
[Step=34100 Epoch=33.3] | Loss=0.02407 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.351 | L2-Norm(final)=10.550 | 5573.6 samples/s | 87.1 steps/s
[Step=34150 Epoch=33.3] | Loss=0.02283 | Reg=0.00236 | acc=0.9531 | L2-Norm=15.352 | L2-Norm(final)=10.559 | 5419.5 samples/s | 84.7 steps/s
[Step=34200 Epoch=33.4] | Loss=0.02233 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.352 | L2-Norm(final)=10.569 | 5441.5 samples/s | 85.0 steps/s
[Step=34250 Epoch=33.4] | Loss=0.02218 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.352 | L2-Norm(final)=10.581 | 5549.4 samples/s | 86.7 steps/s
[Step=34300 Epoch=33.5] | Loss=0.02238 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.352 | L2-Norm(final)=10.595 | 5554.9 samples/s | 86.8 steps/s
[Step=34350 Epoch=33.5] | Loss=0.02247 | Reg=0.00236 | acc=0.9531 | L2-Norm=15.352 | L2-Norm(final)=10.607 | 5536.2 samples/s | 86.5 steps/s
[Step=34400 Epoch=33.6] | Loss=0.02266 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.352 | L2-Norm(final)=10.619 | 5665.7 samples/s | 88.5 steps/s
[Step=34450 Epoch=33.6] | Loss=0.02264 | Reg=0.00236 | acc=0.9531 | L2-Norm=15.352 | L2-Norm(final)=10.630 | 5685.4 samples/s | 88.8 steps/s
[Step=34500 Epoch=33.7] | Loss=0.02234 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.352 | L2-Norm(final)=10.642 | 5622.8 samples/s | 87.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=33.7] | Loss=0.02581 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.352 | L2-Norm(final)=10.758 | 4330.4 samples/s | 67.7 steps/s
[Step=34550 Epoch=33.7] | Loss=0.01588 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.380 | L2-Norm(final)=10.766 | 4696.0 samples/s | 73.4 steps/s
[Step=34600 Epoch=33.8] | Loss=0.01629 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.409 | L2-Norm(final)=10.767 | 4765.3 samples/s | 74.5 steps/s
[Step=34650 Epoch=33.8] | Loss=0.01786 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.431 | L2-Norm(final)=10.764 | 4765.5 samples/s | 74.5 steps/s
[Step=34700 Epoch=33.9] | Loss=0.02009 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.453 | L2-Norm(final)=10.759 | 4748.4 samples/s | 74.2 steps/s
[Step=34750 Epoch=33.9] | Loss=0.01989 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=10.754 | 4766.7 samples/s | 74.5 steps/s
[Step=34800 Epoch=34.0] | Loss=0.01918 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.487 | L2-Norm(final)=10.751 | 4844.0 samples/s | 75.7 steps/s
[Step=34850 Epoch=34.0] | Loss=0.01904 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.501 | L2-Norm(final)=10.749 | 4888.5 samples/s | 76.4 steps/s
[Step=34900 Epoch=34.1] | Loss=0.01917 | Reg=0.00241 | acc=0.9531 | L2-Norm=15.513 | L2-Norm(final)=10.748 | 4750.1 samples/s | 74.2 steps/s
[Step=34950 Epoch=34.1] | Loss=0.01914 | Reg=0.00241 | acc=0.9375 | L2-Norm=15.525 | L2-Norm(final)=10.746 | 4810.5 samples/s | 75.2 steps/s
[Step=35000 Epoch=34.2] | Loss=0.01904 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.538 | L2-Norm(final)=10.745 | 4792.2 samples/s | 74.9 steps/s
[Step=35050 Epoch=34.2] | Loss=0.01853 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.549 | L2-Norm(final)=10.744 | 4797.3 samples/s | 75.0 steps/s
[Step=35100 Epoch=34.3] | Loss=0.01852 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=10.743 | 4790.7 samples/s | 74.9 steps/s
[Step=35150 Epoch=34.3] | Loss=0.01858 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.569 | L2-Norm(final)=10.742 | 4771.3 samples/s | 74.6 steps/s
[Step=35200 Epoch=34.4] | Loss=0.01864 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.579 | L2-Norm(final)=10.741 | 4854.1 samples/s | 75.8 steps/s
[Step=35250 Epoch=34.4] | Loss=0.01848 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=10.739 | 4865.7 samples/s | 76.0 steps/s
[Step=35300 Epoch=34.5] | Loss=0.01849 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.597 | L2-Norm(final)=10.738 | 4783.7 samples/s | 74.7 steps/s
[Step=35350 Epoch=34.5] | Loss=0.01835 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=10.736 | 4841.4 samples/s | 75.6 steps/s
[Step=35400 Epoch=34.6] | Loss=0.01804 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.613 | L2-Norm(final)=10.734 | 4838.0 samples/s | 75.6 steps/s
[Step=35450 Epoch=34.6] | Loss=0.01792 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.621 | L2-Norm(final)=10.733 | 4813.4 samples/s | 75.2 steps/s
[Step=35500 Epoch=34.7] | Loss=0.01800 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.628 | L2-Norm(final)=10.732 | 5125.8 samples/s | 80.1 steps/s
[Step=35550 Epoch=34.7] | Loss=0.01780 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.635 | L2-Norm(final)=10.731 | 2109.1 samples/s | 33.0 steps/s
[Step=35600 Epoch=34.8] | Loss=0.01756 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.642 | L2-Norm(final)=10.730 | 4791.6 samples/s | 74.9 steps/s
[Step=35650 Epoch=34.8] | Loss=0.01725 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.649 | L2-Norm(final)=10.729 | 4791.0 samples/s | 74.9 steps/s
[Step=35700 Epoch=34.9] | Loss=0.01708 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.655 | L2-Norm(final)=10.728 | 4718.2 samples/s | 73.7 steps/s
[Step=35750 Epoch=34.9] | Loss=0.01695 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=10.728 | 4786.6 samples/s | 74.8 steps/s
[Step=35800 Epoch=35.0] | Loss=0.01675 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.668 | L2-Norm(final)=10.727 | 4801.5 samples/s | 75.0 steps/s
[Step=35850 Epoch=35.0] | Loss=0.01669 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.673 | L2-Norm(final)=10.727 | 4770.4 samples/s | 74.5 steps/s
[Step=35900 Epoch=35.1] | Loss=0.01666 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.679 | L2-Norm(final)=10.726 | 4802.1 samples/s | 75.0 steps/s
[Step=35950 Epoch=35.1] | Loss=0.01668 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.685 | L2-Norm(final)=10.726 | 4868.3 samples/s | 76.1 steps/s
[Step=36000 Epoch=35.1] | Loss=0.01650 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.690 | L2-Norm(final)=10.725 | 4817.4 samples/s | 75.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step36000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=34001 Epoch=64.1] | Loss=0.00007 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=11.915 | 4389.9 samples/s | 68.6 steps/s
[Step=34050 Epoch=64.2] | Loss=0.00091 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=11.918 | 4780.7 samples/s | 74.7 steps/s
[Step=34100 Epoch=64.3] | Loss=0.00094 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=11.924 | 5242.4 samples/s | 81.9 steps/s
[Step=34150 Epoch=64.4] | Loss=0.00078 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.931 | 5312.5 samples/s | 83.0 steps/s
[Step=34200 Epoch=64.5] | Loss=0.00072 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.938 | 5307.9 samples/s | 82.9 steps/s
[Step=34250 Epoch=64.6] | Loss=0.00090 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.945 | 4982.8 samples/s | 77.9 steps/s
[Step=34300 Epoch=64.7] | Loss=0.00097 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.951 | 5336.0 samples/s | 83.4 steps/s
[Step=34350 Epoch=64.8] | Loss=0.00089 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.958 | 5308.0 samples/s | 82.9 steps/s
[Step=34400 Epoch=64.8] | Loss=0.00082 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.965 | 5152.9 samples/s | 80.5 steps/s
[Step=34450 Epoch=64.9] | Loss=0.00087 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.971 | 5202.0 samples/s | 81.3 steps/s
[Step=34500 Epoch=65.0] | Loss=0.00081 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=11.977 | 5253.8 samples/s | 82.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=65.0] | Loss=0.00034 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.345 | L2-Norm(final)=12.037 | 4598.9 samples/s | 71.9 steps/s
[Step=34550 Epoch=65.1] | Loss=0.00211 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=12.039 | 4138.2 samples/s | 64.7 steps/s
[Step=34600 Epoch=65.2] | Loss=0.00242 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.381 | L2-Norm(final)=12.038 | 4534.0 samples/s | 70.8 steps/s
[Step=34650 Epoch=65.3] | Loss=0.00445 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.413 | L2-Norm(final)=12.030 | 4601.2 samples/s | 71.9 steps/s
[Step=34700 Epoch=65.4] | Loss=0.00430 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.452 | L2-Norm(final)=12.019 | 4587.5 samples/s | 71.7 steps/s
[Step=34750 Epoch=65.5] | Loss=0.00379 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.483 | L2-Norm(final)=12.010 | 4578.3 samples/s | 71.5 steps/s
[Step=34800 Epoch=65.6] | Loss=0.00337 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.004 | 4559.7 samples/s | 71.2 steps/s
[Step=34850 Epoch=65.7] | Loss=0.00313 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=12.000 | 4618.2 samples/s | 72.2 steps/s
[Step=34900 Epoch=65.8] | Loss=0.00277 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.530 | L2-Norm(final)=11.997 | 4626.8 samples/s | 72.3 steps/s
[Step=34950 Epoch=65.9] | Loss=0.00249 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.537 | L2-Norm(final)=11.994 | 4560.4 samples/s | 71.3 steps/s
[Step=35000 Epoch=66.0] | Loss=0.00227 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=11.992 | 4614.8 samples/s | 72.1 steps/s
[Step=35050 Epoch=66.1] | Loss=0.00230 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=11.990 | 2135.1 samples/s | 33.4 steps/s
[Step=35100 Epoch=66.2] | Loss=0.00231 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.552 | L2-Norm(final)=11.988 | 4726.0 samples/s | 73.8 steps/s
[Step=35150 Epoch=66.3] | Loss=0.00215 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.556 | L2-Norm(final)=11.985 | 4669.1 samples/s | 73.0 steps/s
[Step=35200 Epoch=66.4] | Loss=0.00201 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=11.983 | 4604.1 samples/s | 71.9 steps/s
[Step=35250 Epoch=66.4] | Loss=0.00188 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.562 | L2-Norm(final)=11.982 | 4513.1 samples/s | 70.5 steps/s
[Step=35300 Epoch=66.5] | Loss=0.00177 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=11.980 | 4491.9 samples/s | 70.2 steps/s
[Step=35350 Epoch=66.6] | Loss=0.00166 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=11.979 | 3960.2 samples/s | 61.9 steps/s
[Step=35400 Epoch=66.7] | Loss=0.00157 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.562 | L2-Norm(final)=11.978 | 4043.0 samples/s | 63.2 steps/s
[Step=35450 Epoch=66.8] | Loss=0.00152 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=11.977 | 4063.2 samples/s | 63.5 steps/s
[Step=35500 Epoch=66.9] | Loss=0.00145 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=11.976 | 3842.6 samples/s | 60.0 steps/s
[Step=35550 Epoch=67.0] | Loss=0.00138 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.557 | L2-Norm(final)=11.975 | 4884.8 samples/s | 76.3 steps/s
[Step=35600 Epoch=67.1] | Loss=0.00132 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=11.974 | 1731.3 samples/s | 27.1 steps/s
[Step=35650 Epoch=67.2] | Loss=0.00126 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=11.973 | 3841.4 samples/s | 60.0 steps/s
[Step=35700 Epoch=67.3] | Loss=0.00121 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=11.972 | 3850.2 samples/s | 60.2 steps/s
[Step=35750 Epoch=67.4] | Loss=0.00116 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.544 | L2-Norm(final)=11.972 | 4565.5 samples/s | 71.3 steps/s
[Step=35800 Epoch=67.5] | Loss=0.00111 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=11.971 | 4563.5 samples/s | 71.3 steps/s
[Step=35850 Epoch=67.6] | Loss=0.00107 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.535 | L2-Norm(final)=11.971 | 4585.0 samples/s | 71.6 steps/s
[Step=35900 Epoch=67.7] | Loss=0.00104 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=11.970 | 4486.2 samples/s | 70.1 steps/s
[Step=35950 Epoch=67.8] | Loss=0.00100 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.526 | L2-Norm(final)=11.970 | 4559.4 samples/s | 71.2 steps/s
[Step=36000 Epoch=67.9] | Loss=0.00097 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=11.969 | 4522.8 samples/s | 70.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05961 | acc=0.9706 | tpr=0.9734 | fpr=0.0354 | 4565.5 samples/s | 17.8 steps/s
Avg test loss: 0.06601, Avg test acc: 0.97035, Avg tpr: 0.97290, Avg fpr: 0.03525, total FA: 275

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.31214 | acc=0.3007 | tpr=0.0207 | fpr=0.0912 | 4596.7 samples/s | 18.0 steps/s
Avg test loss: 7.34357, Avg test acc: 0.29878, Avg tpr: 0.02139, Avg fpr: 0.09114, total FA: 711

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.41423 | acc=0.1358 | tpr=0.4779 | fpr=0.8704 | 4568.6 samples/s | 17.8 steps/s
[Step= 100] | Loss=6.37605 | acc=0.1338 | tpr=0.4499 | fpr=0.8721 | 8475.5 samples/s | 33.1 steps/s
[Step= 150] | Loss=6.36828 | acc=0.1339 | tpr=0.4611 | fpr=0.8721 | 8520.4 samples/s | 33.3 steps/s
[Step= 200] | Loss=6.35019 | acc=0.1343 | tpr=0.4612 | fpr=0.8716 | 8587.2 samples/s | 33.5 steps/s
[Step= 250] | Loss=6.34914 | acc=0.1350 | tpr=0.4681 | fpr=0.8711 | 8857.3 samples/s | 34.6 steps/s
[Step= 300] | Loss=6.34315 | acc=0.1351 | tpr=0.4713 | fpr=0.8711 | 8310.2 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.34178 | acc=0.1350 | tpr=0.4690 | fpr=0.8710 | 8386.2 samples/s | 32.8 steps/s
[Step= 400] | Loss=6.33921 | acc=0.1354 | tpr=0.4699 | fpr=0.8707 | 8794.3 samples/s | 34.4 steps/s
[Step= 450] | Loss=6.33956 | acc=0.1351 | tpr=0.4703 | fpr=0.8710 | 8508.2 samples/s | 33.2 steps/s
[Step= 500] | Loss=6.34025 | acc=0.1353 | tpr=0.4714 | fpr=0.8708 | 8469.5 samples/s | 33.1 steps/s
[Step= 550] | Loss=6.34079 | acc=0.1356 | tpr=0.4723 | fpr=0.8705 | 15345.3 samples/s | 59.9 steps/s
Avg test loss: 6.34327, Avg test acc: 0.13549, Avg tpr: 0.47266, Avg fpr: 0.87064, total FA: 120887

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.17695 | acc=0.9789 | tpr=0.9602 | fpr=0.0208 | 4593.5 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.18625 | acc=0.9779 | tpr=0.9531 | fpr=0.0216 | 9097.1 samples/s | 35.5 steps/s
[Step= 150] | Loss=0.19396 | acc=0.9774 | tpr=0.9582 | fpr=0.0223 | 8149.0 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.19764 | acc=0.9777 | tpr=0.9628 | fpr=0.0220 | 8336.5 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.19434 | acc=0.9782 | tpr=0.9572 | fpr=0.0215 | 8620.7 samples/s | 33.7 steps/s
[Step= 300] | Loss=0.19788 | acc=0.9779 | tpr=0.9578 | fpr=0.0217 | 8773.7 samples/s | 34.3 steps/s
[Step= 350] | Loss=0.20027 | acc=0.9776 | tpr=0.9580 | fpr=0.0220 | 8449.6 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.20149 | acc=0.9776 | tpr=0.9573 | fpr=0.0221 | 8507.6 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.20560 | acc=0.9772 | tpr=0.9567 | fpr=0.0224 | 8852.5 samples/s | 34.6 steps/s
[Step= 500] | Loss=0.20447 | acc=0.9773 | tpr=0.9568 | fpr=0.0223 | 9002.3 samples/s | 35.2 steps/s
[Step= 550] | Loss=0.20298 | acc=0.9775 | tpr=0.9554 | fpr=0.0221 | 13993.4 samples/s | 54.7 steps/s
Avg test loss: 0.20257, Avg test acc: 0.97747, Avg tpr: 0.95483, Avg fpr: 0.02212, total FA: 3071

server round 18/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=36001 Epoch=35.1] | Loss=0.01074 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=10.711 | 4092.7 samples/s | 63.9 steps/s
[Step=36050 Epoch=35.2] | Loss=0.03147 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.402 | L2-Norm(final)=10.713 | 5537.9 samples/s | 86.5 steps/s
[Step=36100 Epoch=35.2] | Loss=0.03070 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.719 | 5367.9 samples/s | 83.9 steps/s
[Step=36150 Epoch=35.3] | Loss=0.03096 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.726 | 5522.1 samples/s | 86.3 steps/s
[Step=36200 Epoch=35.3] | Loss=0.02993 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.736 | 5553.4 samples/s | 86.8 steps/s
[Step=36250 Epoch=35.4] | Loss=0.02961 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.746 | 5467.1 samples/s | 85.4 steps/s
[Step=36300 Epoch=35.4] | Loss=0.02885 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.402 | L2-Norm(final)=10.756 | 5537.5 samples/s | 86.5 steps/s
[Step=36350 Epoch=35.5] | Loss=0.02842 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.402 | L2-Norm(final)=10.766 | 5530.0 samples/s | 86.4 steps/s
[Step=36400 Epoch=35.5] | Loss=0.02836 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.402 | L2-Norm(final)=10.776 | 5719.9 samples/s | 89.4 steps/s
[Step=36450 Epoch=35.6] | Loss=0.02837 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.402 | L2-Norm(final)=10.787 | 5581.4 samples/s | 87.2 steps/s
[Step=36500 Epoch=35.6] | Loss=0.02854 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.798 | 5650.8 samples/s | 88.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=35.6] | Loss=0.00872 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.402 | L2-Norm(final)=10.900 | 4126.9 samples/s | 64.5 steps/s
[Step=36550 Epoch=35.7] | Loss=0.01798 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.451 | L2-Norm(final)=10.904 | 4630.0 samples/s | 72.3 steps/s
[Step=36600 Epoch=35.7] | Loss=0.02016 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.489 | L2-Norm(final)=10.901 | 4790.3 samples/s | 74.8 steps/s
[Step=36650 Epoch=35.8] | Loss=0.02092 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.523 | L2-Norm(final)=10.896 | 4717.7 samples/s | 73.7 steps/s
[Step=36700 Epoch=35.8] | Loss=0.02063 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=10.894 | 4805.7 samples/s | 75.1 steps/s
[Step=36750 Epoch=35.9] | Loss=0.02018 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.573 | L2-Norm(final)=10.892 | 4802.2 samples/s | 75.0 steps/s
[Step=36800 Epoch=35.9] | Loss=0.01950 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.591 | L2-Norm(final)=10.891 | 4799.5 samples/s | 75.0 steps/s
[Step=36850 Epoch=36.0] | Loss=0.01993 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=10.889 | 4763.1 samples/s | 74.4 steps/s
[Step=36900 Epoch=36.0] | Loss=0.01974 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.621 | L2-Norm(final)=10.887 | 4870.9 samples/s | 76.1 steps/s
[Step=36950 Epoch=36.1] | Loss=0.01918 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.635 | L2-Norm(final)=10.885 | 4817.0 samples/s | 75.3 steps/s
[Step=37000 Epoch=36.1] | Loss=0.01945 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.647 | L2-Norm(final)=10.884 | 4769.6 samples/s | 74.5 steps/s
[Step=37050 Epoch=36.2] | Loss=0.01881 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=10.883 | 4819.3 samples/s | 75.3 steps/s
[Step=37100 Epoch=36.2] | Loss=0.01868 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.668 | L2-Norm(final)=10.882 | 4813.4 samples/s | 75.2 steps/s
[Step=37150 Epoch=36.3] | Loss=0.01866 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.678 | L2-Norm(final)=10.881 | 4753.5 samples/s | 74.3 steps/s
[Step=37200 Epoch=36.3] | Loss=0.01874 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.688 | L2-Norm(final)=10.880 | 4777.1 samples/s | 74.6 steps/s
[Step=37250 Epoch=36.4] | Loss=0.01923 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.697 | L2-Norm(final)=10.878 | 4801.4 samples/s | 75.0 steps/s
[Step=37300 Epoch=36.4] | Loss=0.01917 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.705 | L2-Norm(final)=10.876 | 4774.6 samples/s | 74.6 steps/s
[Step=37350 Epoch=36.5] | Loss=0.01888 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.714 | L2-Norm(final)=10.875 | 4782.6 samples/s | 74.7 steps/s
[Step=37400 Epoch=36.5] | Loss=0.01862 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.722 | L2-Norm(final)=10.873 | 4771.0 samples/s | 74.5 steps/s
[Step=37450 Epoch=36.6] | Loss=0.01869 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.730 | L2-Norm(final)=10.872 | 4795.0 samples/s | 74.9 steps/s
[Step=37500 Epoch=36.6] | Loss=0.01855 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=10.870 | 5195.1 samples/s | 81.2 steps/s
[Step=37550 Epoch=36.7] | Loss=0.01841 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.745 | L2-Norm(final)=10.869 | 2102.1 samples/s | 32.8 steps/s
[Step=37600 Epoch=36.7] | Loss=0.01822 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.752 | L2-Norm(final)=10.868 | 4875.5 samples/s | 76.2 steps/s
[Step=37650 Epoch=36.8] | Loss=0.01807 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.759 | L2-Norm(final)=10.866 | 4906.4 samples/s | 76.7 steps/s
[Step=37700 Epoch=36.8] | Loss=0.01778 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.766 | L2-Norm(final)=10.865 | 4832.7 samples/s | 75.5 steps/s
[Step=37750 Epoch=36.9] | Loss=0.01756 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.772 | L2-Norm(final)=10.864 | 4782.9 samples/s | 74.7 steps/s
[Step=37800 Epoch=36.9] | Loss=0.01739 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=10.863 | 4969.2 samples/s | 77.6 steps/s
[Step=37850 Epoch=37.0] | Loss=0.01720 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.784 | L2-Norm(final)=10.862 | 4741.2 samples/s | 74.1 steps/s
[Step=37900 Epoch=37.0] | Loss=0.01701 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.789 | L2-Norm(final)=10.861 | 4828.4 samples/s | 75.4 steps/s
[Step=37950 Epoch=37.1] | Loss=0.01699 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.795 | L2-Norm(final)=10.860 | 4746.3 samples/s | 74.2 steps/s
[Step=38000 Epoch=37.1] | Loss=0.01699 | Reg=0.00250 | acc=0.9688 | L2-Norm=15.800 | L2-Norm(final)=10.859 | 4807.1 samples/s | 75.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step38000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=36001 Epoch=67.9] | Loss=0.00002 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=11.958 | 4274.4 samples/s | 66.8 steps/s
[Step=36050 Epoch=68.0] | Loss=0.00060 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.962 | 4942.9 samples/s | 77.2 steps/s
[Step=36100 Epoch=68.0] | Loss=0.00059 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.968 | 5179.2 samples/s | 80.9 steps/s
[Step=36150 Epoch=68.1] | Loss=0.00056 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.974 | 5204.4 samples/s | 81.3 steps/s
[Step=36200 Epoch=68.2] | Loss=0.00053 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.979 | 5164.1 samples/s | 80.7 steps/s
[Step=36250 Epoch=68.3] | Loss=0.00045 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.984 | 5269.4 samples/s | 82.3 steps/s
[Step=36300 Epoch=68.4] | Loss=0.00056 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.987 | 5165.3 samples/s | 80.7 steps/s
[Step=36350 Epoch=68.5] | Loss=0.00055 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.990 | 5182.6 samples/s | 81.0 steps/s
[Step=36400 Epoch=68.6] | Loss=0.00049 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.993 | 5171.4 samples/s | 80.8 steps/s
[Step=36450 Epoch=68.7] | Loss=0.00046 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.997 | 5159.5 samples/s | 80.6 steps/s
[Step=36500 Epoch=68.8] | Loss=0.00042 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=12.000 | 5268.2 samples/s | 82.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=68.8] | Loss=0.00059 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=12.030 | 4076.6 samples/s | 63.7 steps/s
[Step=36550 Epoch=68.9] | Loss=0.00021 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=12.033 | 4536.8 samples/s | 70.9 steps/s
[Step=36600 Epoch=69.0] | Loss=0.00059 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=12.035 | 4566.9 samples/s | 71.4 steps/s
[Step=36650 Epoch=69.1] | Loss=0.00046 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=12.035 | 4522.2 samples/s | 70.7 steps/s
[Step=36700 Epoch=69.2] | Loss=0.00036 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=12.035 | 4566.5 samples/s | 71.4 steps/s
[Step=36750 Epoch=69.3] | Loss=0.00029 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=12.035 | 4606.0 samples/s | 72.0 steps/s
[Step=36800 Epoch=69.4] | Loss=0.00025 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=12.035 | 4469.7 samples/s | 69.8 steps/s
[Step=36850 Epoch=69.5] | Loss=0.00022 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.380 | L2-Norm(final)=12.035 | 4528.7 samples/s | 70.8 steps/s
[Step=36900 Epoch=69.6] | Loss=0.00019 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=12.035 | 4614.8 samples/s | 72.1 steps/s
[Step=36950 Epoch=69.7] | Loss=0.00017 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=12.036 | 4526.0 samples/s | 70.7 steps/s
[Step=37000 Epoch=69.7] | Loss=0.00015 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=12.036 | 4620.4 samples/s | 72.2 steps/s
[Step=37050 Epoch=69.8] | Loss=0.00014 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=12.036 | 2161.5 samples/s | 33.8 steps/s
[Step=37100 Epoch=69.9] | Loss=0.00013 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=12.037 | 4598.3 samples/s | 71.8 steps/s
[Step=37150 Epoch=70.0] | Loss=0.00012 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=12.037 | 4501.2 samples/s | 70.3 steps/s
[Step=37200 Epoch=70.1] | Loss=0.00011 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=12.037 | 4527.0 samples/s | 70.7 steps/s
[Step=37250 Epoch=70.2] | Loss=0.00010 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.300 | L2-Norm(final)=12.038 | 4546.0 samples/s | 71.0 steps/s
[Step=37300 Epoch=70.3] | Loss=0.00010 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=12.038 | 4500.0 samples/s | 70.3 steps/s
[Step=37350 Epoch=70.4] | Loss=0.00009 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.278 | L2-Norm(final)=12.039 | 4544.6 samples/s | 71.0 steps/s
[Step=37400 Epoch=70.5] | Loss=0.00009 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=12.039 | 4461.5 samples/s | 69.7 steps/s
[Step=37450 Epoch=70.6] | Loss=0.00008 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=12.040 | 4522.4 samples/s | 70.7 steps/s
[Step=37500 Epoch=70.7] | Loss=0.00008 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=12.040 | 4550.5 samples/s | 71.1 steps/s
[Step=37550 Epoch=70.8] | Loss=0.00007 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=12.041 | 5582.2 samples/s | 87.2 steps/s
[Step=37600 Epoch=70.9] | Loss=0.00007 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=12.041 | 1957.0 samples/s | 30.6 steps/s
[Step=37650 Epoch=71.0] | Loss=0.00007 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=12.042 | 4534.6 samples/s | 70.9 steps/s
[Step=37700 Epoch=71.1] | Loss=0.00006 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=12.042 | 4566.5 samples/s | 71.4 steps/s
[Step=37750 Epoch=71.2] | Loss=0.00006 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=12.043 | 4536.4 samples/s | 70.9 steps/s
[Step=37800 Epoch=71.3] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=12.043 | 4540.3 samples/s | 70.9 steps/s
[Step=37850 Epoch=71.3] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=12.043 | 4538.1 samples/s | 70.9 steps/s
[Step=37900 Epoch=71.4] | Loss=0.00006 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=12.044 | 4523.7 samples/s | 70.7 steps/s
[Step=37950 Epoch=71.5] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.140 | L2-Norm(final)=12.044 | 4526.5 samples/s | 70.7 steps/s
[Step=38000 Epoch=71.6] | Loss=0.00005 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=12.045 | 4565.9 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05576 | acc=0.9699 | tpr=0.9733 | fpr=0.0374 | 4460.2 samples/s | 17.4 steps/s
Avg test loss: 0.06266, Avg test acc: 0.96863, Avg tpr: 0.97220, Avg fpr: 0.03923, total FA: 306

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.84746 | acc=0.3033 | tpr=0.0193 | fpr=0.0800 | 4597.4 samples/s | 18.0 steps/s
Avg test loss: 8.87002, Avg test acc: 0.29894, Avg tpr: 0.01877, Avg fpr: 0.08486, total FA: 662

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.94193 | acc=0.1520 | tpr=0.4602 | fpr=0.8535 | 4695.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=5.89998 | acc=0.1540 | tpr=0.4606 | fpr=0.8517 | 8128.9 samples/s | 31.8 steps/s
[Step= 150] | Loss=5.90174 | acc=0.1550 | tpr=0.4654 | fpr=0.8507 | 8578.1 samples/s | 33.5 steps/s
[Step= 200] | Loss=5.89283 | acc=0.1550 | tpr=0.4721 | fpr=0.8508 | 8439.4 samples/s | 33.0 steps/s
[Step= 250] | Loss=5.89269 | acc=0.1557 | tpr=0.4716 | fpr=0.8501 | 8667.2 samples/s | 33.9 steps/s
[Step= 300] | Loss=5.88825 | acc=0.1553 | tpr=0.4727 | fpr=0.8505 | 8517.6 samples/s | 33.3 steps/s
[Step= 350] | Loss=5.88514 | acc=0.1549 | tpr=0.4759 | fpr=0.8509 | 8592.6 samples/s | 33.6 steps/s
[Step= 400] | Loss=5.88618 | acc=0.1552 | tpr=0.4754 | fpr=0.8506 | 8570.0 samples/s | 33.5 steps/s
[Step= 450] | Loss=5.88891 | acc=0.1553 | tpr=0.4752 | fpr=0.8505 | 8329.0 samples/s | 32.5 steps/s
[Step= 500] | Loss=5.88814 | acc=0.1555 | tpr=0.4780 | fpr=0.8503 | 8978.7 samples/s | 35.1 steps/s
[Step= 550] | Loss=5.88861 | acc=0.1555 | tpr=0.4807 | fpr=0.8504 | 13640.3 samples/s | 53.3 steps/s
Avg test loss: 5.88962, Avg test acc: 0.15533, Avg tpr: 0.48059, Avg fpr: 0.85058, total FA: 118101

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15081 | acc=0.9827 | tpr=0.9425 | fpr=0.0166 | 4636.2 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.15859 | acc=0.9820 | tpr=0.9403 | fpr=0.0173 | 8375.6 samples/s | 32.7 steps/s
[Step= 150] | Loss=0.16354 | acc=0.9813 | tpr=0.9452 | fpr=0.0180 | 8628.6 samples/s | 33.7 steps/s
[Step= 200] | Loss=0.16472 | acc=0.9815 | tpr=0.9519 | fpr=0.0180 | 8470.4 samples/s | 33.1 steps/s
[Step= 250] | Loss=0.16223 | acc=0.9817 | tpr=0.9485 | fpr=0.0177 | 8329.3 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.16425 | acc=0.9815 | tpr=0.9498 | fpr=0.0180 | 8936.6 samples/s | 34.9 steps/s
[Step= 350] | Loss=0.16661 | acc=0.9813 | tpr=0.9518 | fpr=0.0182 | 8419.5 samples/s | 32.9 steps/s
[Step= 400] | Loss=0.16741 | acc=0.9812 | tpr=0.9508 | fpr=0.0182 | 8403.2 samples/s | 32.8 steps/s
[Step= 450] | Loss=0.17133 | acc=0.9809 | tpr=0.9489 | fpr=0.0186 | 8617.4 samples/s | 33.7 steps/s
[Step= 500] | Loss=0.17076 | acc=0.9809 | tpr=0.9493 | fpr=0.0185 | 8293.3 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.16969 | acc=0.9811 | tpr=0.9483 | fpr=0.0183 | 15282.2 samples/s | 59.7 steps/s
Avg test loss: 0.16939, Avg test acc: 0.98106, Avg tpr: 0.94770, Avg fpr: 0.01833, total FA: 2545

server round 19/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=38001 Epoch=37.1] | Loss=0.00852 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=10.842 | 4152.7 samples/s | 64.9 steps/s
[Step=38050 Epoch=37.1] | Loss=0.01424 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.229 | L2-Norm(final)=10.846 | 5659.1 samples/s | 88.4 steps/s
[Step=38100 Epoch=37.2] | Loss=0.01592 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.229 | L2-Norm(final)=10.853 | 5639.9 samples/s | 88.1 steps/s
[Step=38150 Epoch=37.2] | Loss=0.01650 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.229 | L2-Norm(final)=10.861 | 5603.7 samples/s | 87.6 steps/s
[Step=38200 Epoch=37.3] | Loss=0.01729 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.229 | L2-Norm(final)=10.868 | 5558.5 samples/s | 86.9 steps/s
[Step=38250 Epoch=37.3] | Loss=0.01724 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.229 | L2-Norm(final)=10.873 | 5565.6 samples/s | 87.0 steps/s
[Step=38300 Epoch=37.4] | Loss=0.01711 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.229 | L2-Norm(final)=10.881 | 5498.4 samples/s | 85.9 steps/s
[Step=38350 Epoch=37.4] | Loss=0.01731 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=10.888 | 5437.0 samples/s | 85.0 steps/s
[Step=38400 Epoch=37.5] | Loss=0.01739 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=10.896 | 5564.4 samples/s | 86.9 steps/s
[Step=38450 Epoch=37.5] | Loss=0.01733 | Reg=0.00232 | acc=0.9531 | L2-Norm=15.230 | L2-Norm(final)=10.904 | 5510.8 samples/s | 86.1 steps/s
[Step=38500 Epoch=37.6] | Loss=0.01745 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=10.911 | 5544.5 samples/s | 86.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=37.6] | Loss=0.01051 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=10.987 | 4162.7 samples/s | 65.0 steps/s
[Step=38550 Epoch=37.6] | Loss=0.01809 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.276 | L2-Norm(final)=10.988 | 4580.2 samples/s | 71.6 steps/s
[Step=38600 Epoch=37.7] | Loss=0.01760 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.305 | L2-Norm(final)=10.984 | 4796.7 samples/s | 74.9 steps/s
[Step=38650 Epoch=37.7] | Loss=0.01761 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.324 | L2-Norm(final)=10.979 | 4691.4 samples/s | 73.3 steps/s
[Step=38700 Epoch=37.8] | Loss=0.01632 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.339 | L2-Norm(final)=10.978 | 4751.7 samples/s | 74.2 steps/s
[Step=38750 Epoch=37.8] | Loss=0.01635 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.351 | L2-Norm(final)=10.977 | 4718.0 samples/s | 73.7 steps/s
[Step=38800 Epoch=37.9] | Loss=0.01670 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=10.976 | 4786.4 samples/s | 74.8 steps/s
[Step=38850 Epoch=37.9] | Loss=0.01710 | Reg=0.00236 | acc=0.9531 | L2-Norm=15.375 | L2-Norm(final)=10.974 | 4815.5 samples/s | 75.2 steps/s
[Step=38900 Epoch=38.0] | Loss=0.01679 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.386 | L2-Norm(final)=10.973 | 4844.6 samples/s | 75.7 steps/s
[Step=38950 Epoch=38.0] | Loss=0.01748 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.396 | L2-Norm(final)=10.972 | 4834.1 samples/s | 75.5 steps/s
[Step=39000 Epoch=38.1] | Loss=0.01753 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=10.970 | 4808.5 samples/s | 75.1 steps/s
[Step=39050 Epoch=38.1] | Loss=0.01745 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.416 | L2-Norm(final)=10.968 | 4785.2 samples/s | 74.8 steps/s
[Step=39100 Epoch=38.2] | Loss=0.01760 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.425 | L2-Norm(final)=10.966 | 4753.6 samples/s | 74.3 steps/s
[Step=39150 Epoch=38.2] | Loss=0.01751 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=10.964 | 4780.8 samples/s | 74.7 steps/s
[Step=39200 Epoch=38.3] | Loss=0.01743 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.444 | L2-Norm(final)=10.962 | 4796.2 samples/s | 74.9 steps/s
[Step=39250 Epoch=38.3] | Loss=0.01724 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.452 | L2-Norm(final)=10.960 | 4786.8 samples/s | 74.8 steps/s
[Step=39300 Epoch=38.4] | Loss=0.01721 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.461 | L2-Norm(final)=10.958 | 4825.6 samples/s | 75.4 steps/s
[Step=39350 Epoch=38.4] | Loss=0.01733 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.469 | L2-Norm(final)=10.956 | 4761.2 samples/s | 74.4 steps/s
[Step=39400 Epoch=38.5] | Loss=0.01763 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.477 | L2-Norm(final)=10.954 | 4778.3 samples/s | 74.7 steps/s
[Step=39450 Epoch=38.5] | Loss=0.01765 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.485 | L2-Norm(final)=10.952 | 4787.2 samples/s | 74.8 steps/s
[Step=39500 Epoch=38.6] | Loss=0.01762 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=10.950 | 5161.3 samples/s | 80.6 steps/s
[Step=39550 Epoch=38.6] | Loss=0.01770 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.501 | L2-Norm(final)=10.948 | 2077.1 samples/s | 32.5 steps/s
[Step=39600 Epoch=38.7] | Loss=0.01764 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.509 | L2-Norm(final)=10.946 | 4805.5 samples/s | 75.1 steps/s
[Step=39650 Epoch=38.7] | Loss=0.01739 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.517 | L2-Norm(final)=10.945 | 4765.5 samples/s | 74.5 steps/s
[Step=39700 Epoch=38.8] | Loss=0.01734 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=10.943 | 4857.9 samples/s | 75.9 steps/s
[Step=39750 Epoch=38.8] | Loss=0.01711 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.533 | L2-Norm(final)=10.942 | 4864.8 samples/s | 76.0 steps/s
[Step=39800 Epoch=38.9] | Loss=0.01705 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=10.941 | 4956.8 samples/s | 77.4 steps/s
[Step=39850 Epoch=38.9] | Loss=0.01692 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=10.940 | 4792.8 samples/s | 74.9 steps/s
[Step=39900 Epoch=39.0] | Loss=0.01682 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.554 | L2-Norm(final)=10.938 | 4795.6 samples/s | 74.9 steps/s
[Step=39950 Epoch=39.0] | Loss=0.01672 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=10.937 | 4767.5 samples/s | 74.5 steps/s
[Step=40000 Epoch=39.1] | Loss=0.01661 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.567 | L2-Norm(final)=10.936 | 4834.2 samples/s | 75.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step40000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00050, len=1
[Step=38001 Epoch=71.6] | Loss=0.00002 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=12.057 | 4307.2 samples/s | 67.3 steps/s
[Step=38050 Epoch=71.7] | Loss=0.00017 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=12.062 | 4916.1 samples/s | 76.8 steps/s
[Step=38100 Epoch=71.8] | Loss=0.00019 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.068 | 5202.1 samples/s | 81.3 steps/s
[Step=38150 Epoch=71.9] | Loss=0.00015 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.075 | 5179.8 samples/s | 80.9 steps/s
[Step=38200 Epoch=72.0] | Loss=0.00021 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.082 | 5215.3 samples/s | 81.5 steps/s
[Step=38250 Epoch=72.1] | Loss=0.00022 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.089 | 5272.3 samples/s | 82.4 steps/s
[Step=38300 Epoch=72.2] | Loss=0.00020 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.096 | 5151.6 samples/s | 80.5 steps/s
[Step=38350 Epoch=72.3] | Loss=0.00020 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.104 | 5218.9 samples/s | 81.5 steps/s
[Step=38400 Epoch=72.4] | Loss=0.00021 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.110 | 5282.5 samples/s | 82.5 steps/s
[Step=38450 Epoch=72.5] | Loss=0.00020 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.116 | 5148.1 samples/s | 80.4 steps/s
[Step=38500 Epoch=72.6] | Loss=0.00019 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.122 | 5235.8 samples/s | 81.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=72.6] | Loss=0.00000 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=12.181 | 4700.7 samples/s | 73.4 steps/s
[Step=38550 Epoch=72.7] | Loss=0.00004 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.213 | L2-Norm(final)=12.186 | 4049.4 samples/s | 63.3 steps/s
[Step=38600 Epoch=72.8] | Loss=0.00020 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=12.187 | 4579.9 samples/s | 71.6 steps/s
[Step=38650 Epoch=72.9] | Loss=0.00227 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.231 | L2-Norm(final)=12.182 | 4553.5 samples/s | 71.1 steps/s
[Step=38700 Epoch=73.0] | Loss=0.00449 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=12.168 | 4514.5 samples/s | 70.5 steps/s
[Step=38750 Epoch=73.0] | Loss=0.00517 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=12.152 | 4532.8 samples/s | 70.8 steps/s
[Step=38800 Epoch=73.1] | Loss=0.00478 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=12.137 | 4591.8 samples/s | 71.7 steps/s
[Step=38850 Epoch=73.2] | Loss=0.00435 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.425 | L2-Norm(final)=12.127 | 4459.4 samples/s | 69.7 steps/s
[Step=38900 Epoch=73.3] | Loss=0.00383 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.449 | L2-Norm(final)=12.119 | 4563.0 samples/s | 71.3 steps/s
[Step=38950 Epoch=73.4] | Loss=0.00350 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.467 | L2-Norm(final)=12.112 | 4508.4 samples/s | 70.4 steps/s
[Step=39000 Epoch=73.5] | Loss=0.00316 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=12.107 | 4610.8 samples/s | 72.0 steps/s
[Step=39050 Epoch=73.6] | Loss=0.00288 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=12.103 | 2113.4 samples/s | 33.0 steps/s
[Step=39100 Epoch=73.7] | Loss=0.00264 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.499 | L2-Norm(final)=12.100 | 4647.8 samples/s | 72.6 steps/s
[Step=39150 Epoch=73.8] | Loss=0.00244 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=12.097 | 4557.1 samples/s | 71.2 steps/s
[Step=39200 Epoch=73.9] | Loss=0.00227 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=12.095 | 4569.3 samples/s | 71.4 steps/s
[Step=39250 Epoch=74.0] | Loss=0.00212 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.510 | L2-Norm(final)=12.093 | 4488.4 samples/s | 70.1 steps/s
[Step=39300 Epoch=74.1] | Loss=0.00198 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=12.091 | 4543.1 samples/s | 71.0 steps/s
[Step=39350 Epoch=74.2] | Loss=0.00187 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.511 | L2-Norm(final)=12.090 | 4525.8 samples/s | 70.7 steps/s
[Step=39400 Epoch=74.3] | Loss=0.00177 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.510 | L2-Norm(final)=12.089 | 4534.8 samples/s | 70.9 steps/s
[Step=39450 Epoch=74.4] | Loss=0.00168 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.509 | L2-Norm(final)=12.087 | 4531.0 samples/s | 70.8 steps/s
[Step=39500 Epoch=74.5] | Loss=0.00160 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.508 | L2-Norm(final)=12.086 | 4600.3 samples/s | 71.9 steps/s
[Step=39550 Epoch=74.6] | Loss=0.00152 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=12.085 | 5586.1 samples/s | 87.3 steps/s
[Step=39600 Epoch=74.6] | Loss=0.00145 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.503 | L2-Norm(final)=12.085 | 1967.0 samples/s | 30.7 steps/s
[Step=39650 Epoch=74.7] | Loss=0.00139 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.500 | L2-Norm(final)=12.084 | 4602.2 samples/s | 71.9 steps/s
[Step=39700 Epoch=74.8] | Loss=0.00133 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=12.083 | 4467.0 samples/s | 69.8 steps/s
[Step=39750 Epoch=74.9] | Loss=0.00128 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.493 | L2-Norm(final)=12.082 | 4525.8 samples/s | 70.7 steps/s
[Step=39800 Epoch=75.0] | Loss=0.00123 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.490 | L2-Norm(final)=12.082 | 4565.5 samples/s | 71.3 steps/s
[Step=39850 Epoch=75.1] | Loss=0.00118 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=12.081 | 4544.2 samples/s | 71.0 steps/s
[Step=39900 Epoch=75.2] | Loss=0.00114 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.481 | L2-Norm(final)=12.081 | 4604.8 samples/s | 72.0 steps/s
[Step=39950 Epoch=75.3] | Loss=0.00110 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=12.081 | 4583.4 samples/s | 71.6 steps/s
[Step=40000 Epoch=75.4] | Loss=0.00106 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.472 | L2-Norm(final)=12.080 | 4608.2 samples/s | 72.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05995 | acc=0.9699 | tpr=0.9756 | fpr=0.0424 | 4527.2 samples/s | 17.7 steps/s
Avg test loss: 0.06561, Avg test acc: 0.96923, Avg tpr: 0.97511, Avg fpr: 0.04371, total FA: 341

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.07525 | acc=0.3086 | tpr=0.0141 | fpr=0.0520 | 4586.7 samples/s | 17.9 steps/s
Avg test loss: 8.10317, Avg test acc: 0.30607, Avg tpr: 0.01422, Avg fpr: 0.05204, total FA: 406

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.71649 | acc=0.1451 | tpr=0.5310 | fpr=0.8619 | 4545.1 samples/s | 17.8 steps/s
[Step= 100] | Loss=6.67834 | acc=0.1457 | tpr=0.5117 | fpr=0.8611 | 8501.5 samples/s | 33.2 steps/s
[Step= 150] | Loss=6.67168 | acc=0.1458 | tpr=0.5159 | fpr=0.8611 | 8474.2 samples/s | 33.1 steps/s
[Step= 200] | Loss=6.66220 | acc=0.1464 | tpr=0.5191 | fpr=0.8604 | 8712.9 samples/s | 34.0 steps/s
[Step= 250] | Loss=6.65921 | acc=0.1465 | tpr=0.5144 | fpr=0.8602 | 8423.1 samples/s | 32.9 steps/s
[Step= 300] | Loss=6.65342 | acc=0.1467 | tpr=0.5193 | fpr=0.8601 | 9074.9 samples/s | 35.4 steps/s
[Step= 350] | Loss=6.65311 | acc=0.1463 | tpr=0.5160 | fpr=0.8604 | 7999.3 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.65239 | acc=0.1461 | tpr=0.5126 | fpr=0.8606 | 8545.1 samples/s | 33.4 steps/s
[Step= 450] | Loss=6.65642 | acc=0.1461 | tpr=0.5127 | fpr=0.8606 | 8567.8 samples/s | 33.5 steps/s
[Step= 500] | Loss=6.65481 | acc=0.1463 | tpr=0.5093 | fpr=0.8603 | 8562.1 samples/s | 33.4 steps/s
[Step= 550] | Loss=6.65747 | acc=0.1465 | tpr=0.5086 | fpr=0.8601 | 15126.1 samples/s | 59.1 steps/s
Avg test loss: 6.65905, Avg test acc: 0.14631, Avg tpr: 0.50832, Avg fpr: 0.86027, total FA: 119447

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.19380 | acc=0.9839 | tpr=0.9513 | fpr=0.0155 | 4709.2 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.21045 | acc=0.9829 | tpr=0.9552 | fpr=0.0166 | 8281.9 samples/s | 32.4 steps/s
[Step= 150] | Loss=0.21915 | acc=0.9824 | tpr=0.9597 | fpr=0.0172 | 8516.2 samples/s | 33.3 steps/s
[Step= 200] | Loss=0.22318 | acc=0.9822 | tpr=0.9628 | fpr=0.0174 | 8590.5 samples/s | 33.6 steps/s
[Step= 250] | Loss=0.22112 | acc=0.9823 | tpr=0.9590 | fpr=0.0173 | 8507.0 samples/s | 33.2 steps/s
[Step= 300] | Loss=0.22545 | acc=0.9820 | tpr=0.9593 | fpr=0.0176 | 8694.8 samples/s | 34.0 steps/s
[Step= 350] | Loss=0.22764 | acc=0.9818 | tpr=0.9606 | fpr=0.0179 | 8471.8 samples/s | 33.1 steps/s
[Step= 400] | Loss=0.22861 | acc=0.9816 | tpr=0.9579 | fpr=0.0179 | 8593.5 samples/s | 33.6 steps/s
[Step= 450] | Loss=0.23318 | acc=0.9813 | tpr=0.9562 | fpr=0.0182 | 8227.5 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.23241 | acc=0.9814 | tpr=0.9564 | fpr=0.0182 | 8437.6 samples/s | 33.0 steps/s
[Step= 550] | Loss=0.23122 | acc=0.9815 | tpr=0.9550 | fpr=0.0180 | 15480.6 samples/s | 60.5 steps/s
Avg test loss: 0.23102, Avg test acc: 0.98147, Avg tpr: 0.95444, Avg fpr: 0.01803, total FA: 2504

server round 20/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=40001 Epoch=39.1] | Loss=0.07167 | Reg=0.00235 | acc=0.9375 | L2-Norm=15.316 | L2-Norm(final)=10.902 | 4266.4 samples/s | 66.7 steps/s
[Step=40050 Epoch=39.1] | Loss=0.03515 | Reg=0.00235 | acc=0.9219 | L2-Norm=15.316 | L2-Norm(final)=10.911 | 5559.0 samples/s | 86.9 steps/s
[Step=40100 Epoch=39.2] | Loss=0.03244 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.316 | L2-Norm(final)=10.919 | 5628.6 samples/s | 87.9 steps/s
[Step=40150 Epoch=39.2] | Loss=0.03254 | Reg=0.00235 | acc=0.9531 | L2-Norm=15.316 | L2-Norm(final)=10.926 | 5689.8 samples/s | 88.9 steps/s
[Step=40200 Epoch=39.2] | Loss=0.03287 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.317 | L2-Norm(final)=10.932 | 5546.2 samples/s | 86.7 steps/s
[Step=40250 Epoch=39.3] | Loss=0.03299 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.317 | L2-Norm(final)=10.938 | 5559.3 samples/s | 86.9 steps/s
[Step=40300 Epoch=39.3] | Loss=0.03320 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.317 | L2-Norm(final)=10.943 | 5551.4 samples/s | 86.7 steps/s
[Step=40350 Epoch=39.4] | Loss=0.03311 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.317 | L2-Norm(final)=10.948 | 5615.9 samples/s | 87.7 steps/s
[Step=40400 Epoch=39.4] | Loss=0.03298 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.317 | L2-Norm(final)=10.953 | 5427.5 samples/s | 84.8 steps/s
[Step=40450 Epoch=39.5] | Loss=0.03353 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.317 | L2-Norm(final)=10.958 | 5571.0 samples/s | 87.0 steps/s
[Step=40500 Epoch=39.5] | Loss=0.03367 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.317 | L2-Norm(final)=10.963 | 5446.8 samples/s | 85.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=39.5] | Loss=0.01323 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.317 | L2-Norm(final)=11.011 | 3979.8 samples/s | 62.2 steps/s
[Step=40550 Epoch=39.6] | Loss=0.02369 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=11.014 | 4840.4 samples/s | 75.6 steps/s
[Step=40600 Epoch=39.6] | Loss=0.01934 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.344 | L2-Norm(final)=11.016 | 4721.2 samples/s | 73.8 steps/s
[Step=40650 Epoch=39.7] | Loss=0.01834 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.352 | L2-Norm(final)=11.015 | 4820.9 samples/s | 75.3 steps/s
[Step=40700 Epoch=39.7] | Loss=0.01653 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.358 | L2-Norm(final)=11.015 | 4774.0 samples/s | 74.6 steps/s
[Step=40750 Epoch=39.8] | Loss=0.01521 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.362 | L2-Norm(final)=11.015 | 4809.3 samples/s | 75.1 steps/s
[Step=40800 Epoch=39.8] | Loss=0.01491 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=11.015 | 4816.9 samples/s | 75.3 steps/s
[Step=40850 Epoch=39.9] | Loss=0.01476 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.369 | L2-Norm(final)=11.015 | 4804.4 samples/s | 75.1 steps/s
[Step=40900 Epoch=39.9] | Loss=0.01437 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=11.015 | 4864.9 samples/s | 76.0 steps/s
[Step=40950 Epoch=40.0] | Loss=0.01404 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=11.015 | 4698.2 samples/s | 73.4 steps/s
[Step=41000 Epoch=40.0] | Loss=0.01413 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.377 | L2-Norm(final)=11.014 | 4785.9 samples/s | 74.8 steps/s
[Step=41050 Epoch=40.1] | Loss=0.01400 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.379 | L2-Norm(final)=11.014 | 4805.3 samples/s | 75.1 steps/s
[Step=41100 Epoch=40.1] | Loss=0.01386 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.381 | L2-Norm(final)=11.014 | 4789.9 samples/s | 74.8 steps/s
[Step=41150 Epoch=40.2] | Loss=0.01359 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.383 | L2-Norm(final)=11.014 | 4838.5 samples/s | 75.6 steps/s
[Step=41200 Epoch=40.2] | Loss=0.01357 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.385 | L2-Norm(final)=11.014 | 4730.7 samples/s | 73.9 steps/s
[Step=41250 Epoch=40.3] | Loss=0.01333 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.387 | L2-Norm(final)=11.014 | 4759.7 samples/s | 74.4 steps/s
[Step=41300 Epoch=40.3] | Loss=0.01338 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.388 | L2-Norm(final)=11.014 | 4771.3 samples/s | 74.6 steps/s
[Step=41350 Epoch=40.4] | Loss=0.01348 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.390 | L2-Norm(final)=11.013 | 4793.7 samples/s | 74.9 steps/s
[Step=41400 Epoch=40.4] | Loss=0.01335 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.391 | L2-Norm(final)=11.013 | 4837.9 samples/s | 75.6 steps/s
[Step=41450 Epoch=40.5] | Loss=0.01321 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.393 | L2-Norm(final)=11.013 | 4821.5 samples/s | 75.3 steps/s
[Step=41500 Epoch=40.5] | Loss=0.01312 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=11.014 | 5171.5 samples/s | 80.8 steps/s
[Step=41550 Epoch=40.6] | Loss=0.01315 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.396 | L2-Norm(final)=11.014 | 2118.6 samples/s | 33.1 steps/s
[Step=41600 Epoch=40.6] | Loss=0.01291 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.397 | L2-Norm(final)=11.014 | 4953.6 samples/s | 77.4 steps/s
[Step=41650 Epoch=40.7] | Loss=0.01281 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=11.014 | 4908.4 samples/s | 76.7 steps/s
[Step=41700 Epoch=40.7] | Loss=0.01263 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=11.015 | 4883.7 samples/s | 76.3 steps/s
[Step=41750 Epoch=40.8] | Loss=0.01246 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.400 | L2-Norm(final)=11.015 | 4900.0 samples/s | 76.6 steps/s
[Step=41800 Epoch=40.8] | Loss=0.01238 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.401 | L2-Norm(final)=11.015 | 4912.3 samples/s | 76.8 steps/s
[Step=41850 Epoch=40.9] | Loss=0.01229 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=11.016 | 4931.0 samples/s | 77.0 steps/s
[Step=41900 Epoch=40.9] | Loss=0.01237 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=11.016 | 4949.7 samples/s | 77.3 steps/s
[Step=41950 Epoch=41.0] | Loss=0.01225 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.405 | L2-Norm(final)=11.017 | 4914.8 samples/s | 76.8 steps/s
[Step=42000 Epoch=41.0] | Loss=0.01215 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.406 | L2-Norm(final)=11.017 | 4933.7 samples/s | 77.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step42000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=40001 Epoch=75.4] | Loss=0.00243 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.316 | L2-Norm(final)=12.074 | 4734.1 samples/s | 74.0 steps/s
[Step=40050 Epoch=75.5] | Loss=0.00213 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=12.078 | 4571.4 samples/s | 71.4 steps/s
[Step=40100 Epoch=75.6] | Loss=0.00188 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=12.083 | 5158.4 samples/s | 80.6 steps/s
[Step=40150 Epoch=75.7] | Loss=0.00201 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=12.089 | 5126.4 samples/s | 80.1 steps/s
[Step=40200 Epoch=75.8] | Loss=0.00183 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=12.094 | 5196.4 samples/s | 81.2 steps/s
[Step=40250 Epoch=75.9] | Loss=0.00176 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.098 | 5171.0 samples/s | 80.8 steps/s
[Step=40300 Epoch=76.0] | Loss=0.00158 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.103 | 5168.3 samples/s | 80.8 steps/s
[Step=40350 Epoch=76.1] | Loss=0.00155 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.107 | 5316.7 samples/s | 83.1 steps/s
[Step=40400 Epoch=76.2] | Loss=0.00150 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.110 | 5166.2 samples/s | 80.7 steps/s
[Step=40450 Epoch=76.2] | Loss=0.00139 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.114 | 5257.6 samples/s | 82.2 steps/s
[Step=40500 Epoch=76.3] | Loss=0.00129 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.118 | 5243.3 samples/s | 81.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=76.3] | Loss=0.00000 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=12.151 | 4181.7 samples/s | 65.3 steps/s
[Step=40550 Epoch=76.4] | Loss=0.00026 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=12.154 | 4194.0 samples/s | 65.5 steps/s
[Step=40600 Epoch=76.5] | Loss=0.00015 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.301 | L2-Norm(final)=12.156 | 4555.9 samples/s | 71.2 steps/s
[Step=40650 Epoch=76.6] | Loss=0.00012 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.296 | L2-Norm(final)=12.159 | 4501.7 samples/s | 70.3 steps/s
[Step=40700 Epoch=76.7] | Loss=0.00013 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.290 | L2-Norm(final)=12.160 | 4698.4 samples/s | 73.4 steps/s
[Step=40750 Epoch=76.8] | Loss=0.00012 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=12.161 | 4659.4 samples/s | 72.8 steps/s
[Step=40800 Epoch=76.9] | Loss=0.00017 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.282 | L2-Norm(final)=12.162 | 4706.2 samples/s | 73.5 steps/s
[Step=40850 Epoch=77.0] | Loss=0.00015 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.278 | L2-Norm(final)=12.163 | 4658.1 samples/s | 72.8 steps/s
[Step=40900 Epoch=77.1] | Loss=0.00014 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.274 | L2-Norm(final)=12.163 | 4592.5 samples/s | 71.8 steps/s
[Step=40950 Epoch=77.2] | Loss=0.00012 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=12.164 | 4672.2 samples/s | 73.0 steps/s
[Step=41000 Epoch=77.3] | Loss=0.00011 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=12.164 | 4732.0 samples/s | 73.9 steps/s
[Step=41050 Epoch=77.4] | Loss=0.00010 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=12.165 | 2172.9 samples/s | 34.0 steps/s
[Step=41100 Epoch=77.5] | Loss=0.00009 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.255 | L2-Norm(final)=12.165 | 4665.5 samples/s | 72.9 steps/s
[Step=41150 Epoch=77.6] | Loss=0.00008 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=12.166 | 4559.8 samples/s | 71.2 steps/s
[Step=41200 Epoch=77.7] | Loss=0.00008 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=12.166 | 4451.0 samples/s | 69.5 steps/s
[Step=41250 Epoch=77.8] | Loss=0.00007 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.239 | L2-Norm(final)=12.166 | 4567.1 samples/s | 71.4 steps/s
[Step=41300 Epoch=77.9] | Loss=0.00007 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=12.167 | 4597.4 samples/s | 71.8 steps/s
[Step=41350 Epoch=77.9] | Loss=0.00007 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.228 | L2-Norm(final)=12.167 | 4550.7 samples/s | 71.1 steps/s
[Step=41400 Epoch=78.0] | Loss=0.00006 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=12.167 | 4569.4 samples/s | 71.4 steps/s
[Step=41450 Epoch=78.1] | Loss=0.00006 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.217 | L2-Norm(final)=12.167 | 4544.3 samples/s | 71.0 steps/s
[Step=41500 Epoch=78.2] | Loss=0.00006 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=12.167 | 4521.0 samples/s | 70.6 steps/s
[Step=41550 Epoch=78.3] | Loss=0.00005 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=12.168 | 5729.3 samples/s | 89.5 steps/s
[Step=41600 Epoch=78.4] | Loss=0.00005 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=12.168 | 1912.7 samples/s | 29.9 steps/s
[Step=41650 Epoch=78.5] | Loss=0.00005 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=12.168 | 4502.7 samples/s | 70.4 steps/s
[Step=41700 Epoch=78.6] | Loss=0.00005 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=12.168 | 4524.6 samples/s | 70.7 steps/s
[Step=41750 Epoch=78.7] | Loss=0.00005 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=12.168 | 4498.9 samples/s | 70.3 steps/s
[Step=41800 Epoch=78.8] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=12.168 | 4548.0 samples/s | 71.1 steps/s
[Step=41850 Epoch=78.9] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=12.169 | 4526.3 samples/s | 70.7 steps/s
[Step=41900 Epoch=79.0] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=12.169 | 4531.4 samples/s | 70.8 steps/s
[Step=41950 Epoch=79.1] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=12.169 | 4552.0 samples/s | 71.1 steps/s
[Step=42000 Epoch=79.2] | Loss=0.00004 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=12.169 | 4506.2 samples/s | 70.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06110 | acc=0.9715 | tpr=0.9742 | fpr=0.0344 | 4580.5 samples/s | 17.9 steps/s
Avg test loss: 0.06771, Avg test acc: 0.97067, Avg tpr: 0.97284, Avg fpr: 0.03410, total FA: 266

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.55211 | acc=0.3007 | tpr=0.0230 | fpr=0.0964 | 4608.2 samples/s | 18.0 steps/s
Avg test loss: 6.55983, Avg test acc: 0.29754, Avg tpr: 0.02314, Avg fpr: 0.09896, total FA: 772

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.10731 | acc=0.1334 | tpr=0.4646 | fpr=0.8726 | 4595.6 samples/s | 18.0 steps/s
[Step= 100] | Loss=7.05975 | acc=0.1322 | tpr=0.4392 | fpr=0.8735 | 8405.8 samples/s | 32.8 steps/s
[Step= 150] | Loss=7.05801 | acc=0.1323 | tpr=0.4452 | fpr=0.8734 | 8585.7 samples/s | 33.5 steps/s
[Step= 200] | Loss=7.04128 | acc=0.1328 | tpr=0.4393 | fpr=0.8728 | 8542.7 samples/s | 33.4 steps/s
[Step= 250] | Loss=7.04153 | acc=0.1335 | tpr=0.4393 | fpr=0.8720 | 8497.5 samples/s | 33.2 steps/s
[Step= 300] | Loss=7.03661 | acc=0.1336 | tpr=0.4400 | fpr=0.8720 | 8293.9 samples/s | 32.4 steps/s
[Step= 350] | Loss=7.03285 | acc=0.1329 | tpr=0.4421 | fpr=0.8727 | 9104.3 samples/s | 35.6 steps/s
[Step= 400] | Loss=7.03071 | acc=0.1330 | tpr=0.4404 | fpr=0.8725 | 8153.9 samples/s | 31.9 steps/s
[Step= 450] | Loss=7.03375 | acc=0.1328 | tpr=0.4401 | fpr=0.8728 | 8584.6 samples/s | 33.5 steps/s
[Step= 500] | Loss=7.03649 | acc=0.1327 | tpr=0.4401 | fpr=0.8729 | 7361.6 samples/s | 28.8 steps/s
[Step= 550] | Loss=7.03913 | acc=0.1330 | tpr=0.4405 | fpr=0.8726 | 10340.6 samples/s | 40.4 steps/s
Avg test loss: 7.04068, Avg test acc: 0.13283, Avg tpr: 0.44057, Avg fpr: 0.87277, total FA: 121182

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15952 | acc=0.9822 | tpr=0.9513 | fpr=0.0173 | 4592.9 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.17232 | acc=0.9814 | tpr=0.9574 | fpr=0.0181 | 8541.8 samples/s | 33.4 steps/s
[Step= 150] | Loss=0.17839 | acc=0.9812 | tpr=0.9611 | fpr=0.0185 | 8312.4 samples/s | 32.5 steps/s
[Step= 200] | Loss=0.18095 | acc=0.9811 | tpr=0.9683 | fpr=0.0187 | 8737.2 samples/s | 34.1 steps/s
[Step= 250] | Loss=0.17938 | acc=0.9812 | tpr=0.9616 | fpr=0.0184 | 8325.9 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.18226 | acc=0.9810 | tpr=0.9622 | fpr=0.0187 | 8710.6 samples/s | 34.0 steps/s
[Step= 350] | Loss=0.18467 | acc=0.9807 | tpr=0.9618 | fpr=0.0190 | 8345.2 samples/s | 32.6 steps/s
[Step= 400] | Loss=0.18550 | acc=0.9806 | tpr=0.9606 | fpr=0.0191 | 8572.9 samples/s | 33.5 steps/s
[Step= 450] | Loss=0.18939 | acc=0.9803 | tpr=0.9591 | fpr=0.0194 | 8657.9 samples/s | 33.8 steps/s
[Step= 500] | Loss=0.18886 | acc=0.9802 | tpr=0.9586 | fpr=0.0194 | 5353.9 samples/s | 20.9 steps/s
[Step= 550] | Loss=0.18787 | acc=0.9804 | tpr=0.9566 | fpr=0.0192 | 15180.4 samples/s | 59.3 steps/s
Avg test loss: 0.18759, Avg test acc: 0.98038, Avg tpr: 0.95642, Avg fpr: 0.01919, total FA: 2664

server round 21/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=42001 Epoch=41.0] | Loss=0.01190 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.027 | 4167.5 samples/s | 65.1 steps/s
[Step=42050 Epoch=41.1] | Loss=0.01631 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.032 | 5292.0 samples/s | 82.7 steps/s
[Step=42100 Epoch=41.1] | Loss=0.01604 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.037 | 5579.3 samples/s | 87.2 steps/s
[Step=42150 Epoch=41.2] | Loss=0.01639 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.151 | L2-Norm(final)=11.043 | 5311.4 samples/s | 83.0 steps/s
[Step=42200 Epoch=41.2] | Loss=0.01544 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=11.050 | 5431.5 samples/s | 84.9 steps/s
[Step=42250 Epoch=41.3] | Loss=0.01504 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=11.055 | 5470.5 samples/s | 85.5 steps/s
[Step=42300 Epoch=41.3] | Loss=0.01460 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.061 | 5507.2 samples/s | 86.1 steps/s
[Step=42350 Epoch=41.3] | Loss=0.01432 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=11.067 | 5493.9 samples/s | 85.8 steps/s
[Step=42400 Epoch=41.4] | Loss=0.01414 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.073 | 5528.8 samples/s | 86.4 steps/s
[Step=42450 Epoch=41.4] | Loss=0.01411 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=11.078 | 5442.6 samples/s | 85.0 steps/s
[Step=42500 Epoch=41.5] | Loss=0.01446 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.151 | L2-Norm(final)=11.084 | 5614.8 samples/s | 87.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=41.5] | Loss=0.02596 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.151 | L2-Norm(final)=11.134 | 4306.6 samples/s | 67.3 steps/s
[Step=42550 Epoch=41.5] | Loss=0.01386 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.161 | L2-Norm(final)=11.135 | 4644.0 samples/s | 72.6 steps/s
[Step=42600 Epoch=41.6] | Loss=0.01174 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=11.136 | 4953.2 samples/s | 77.4 steps/s
[Step=42650 Epoch=41.6] | Loss=0.01099 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.177 | L2-Norm(final)=11.137 | 4860.9 samples/s | 76.0 steps/s
[Step=42700 Epoch=41.7] | Loss=0.01177 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=11.138 | 4785.3 samples/s | 74.8 steps/s
[Step=42750 Epoch=41.7] | Loss=0.01225 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=11.138 | 4866.0 samples/s | 76.0 steps/s
[Step=42800 Epoch=41.8] | Loss=0.01211 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.190 | L2-Norm(final)=11.138 | 4830.9 samples/s | 75.5 steps/s
[Step=42850 Epoch=41.8] | Loss=0.01207 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=11.139 | 4780.5 samples/s | 74.7 steps/s
[Step=42900 Epoch=41.9] | Loss=0.01186 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=11.139 | 4874.6 samples/s | 76.2 steps/s
[Step=42950 Epoch=41.9] | Loss=0.01178 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=11.139 | 4755.1 samples/s | 74.3 steps/s
[Step=43000 Epoch=42.0] | Loss=0.01170 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=11.140 | 4797.7 samples/s | 75.0 steps/s
[Step=43050 Epoch=42.0] | Loss=0.01163 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=11.140 | 4776.0 samples/s | 74.6 steps/s
[Step=43100 Epoch=42.1] | Loss=0.01155 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=11.141 | 4777.7 samples/s | 74.7 steps/s
[Step=43150 Epoch=42.1] | Loss=0.01168 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.209 | L2-Norm(final)=11.142 | 4862.2 samples/s | 76.0 steps/s
[Step=43200 Epoch=42.2] | Loss=0.01151 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=11.142 | 4800.0 samples/s | 75.0 steps/s
[Step=43250 Epoch=42.2] | Loss=0.01139 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.214 | L2-Norm(final)=11.143 | 4867.7 samples/s | 76.1 steps/s
[Step=43300 Epoch=42.3] | Loss=0.01147 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.216 | L2-Norm(final)=11.144 | 4785.1 samples/s | 74.8 steps/s
[Step=43350 Epoch=42.3] | Loss=0.01137 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.219 | L2-Norm(final)=11.144 | 4800.3 samples/s | 75.0 steps/s
[Step=43400 Epoch=42.4] | Loss=0.01152 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.221 | L2-Norm(final)=11.145 | 4854.1 samples/s | 75.8 steps/s
[Step=43450 Epoch=42.4] | Loss=0.01157 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.223 | L2-Norm(final)=11.145 | 4766.5 samples/s | 74.5 steps/s
[Step=43500 Epoch=42.5] | Loss=0.01146 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=11.145 | 5102.1 samples/s | 79.7 steps/s
[Step=43550 Epoch=42.5] | Loss=0.01135 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.228 | L2-Norm(final)=11.146 | 2139.5 samples/s | 33.4 steps/s
[Step=43600 Epoch=42.6] | Loss=0.01129 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=11.146 | 4856.1 samples/s | 75.9 steps/s
[Step=43650 Epoch=42.6] | Loss=0.01117 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.232 | L2-Norm(final)=11.147 | 4796.2 samples/s | 74.9 steps/s
[Step=43700 Epoch=42.7] | Loss=0.01116 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=11.147 | 4721.3 samples/s | 73.8 steps/s
[Step=43750 Epoch=42.7] | Loss=0.01113 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.236 | L2-Norm(final)=11.147 | 4752.6 samples/s | 74.3 steps/s
[Step=43800 Epoch=42.8] | Loss=0.01109 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=11.147 | 4770.0 samples/s | 74.5 steps/s
[Step=43850 Epoch=42.8] | Loss=0.01104 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=11.148 | 4772.3 samples/s | 74.6 steps/s
[Step=43900 Epoch=42.9] | Loss=0.01103 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=11.148 | 4756.7 samples/s | 74.3 steps/s
[Step=43950 Epoch=42.9] | Loss=0.01093 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=11.148 | 4763.1 samples/s | 74.4 steps/s
[Step=44000 Epoch=43.0] | Loss=0.01093 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.244 | L2-Norm(final)=11.148 | 4761.2 samples/s | 74.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step44000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=42001 Epoch=79.2] | Loss=0.00000 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=12.173 | 4348.7 samples/s | 67.9 steps/s
[Step=42050 Epoch=79.3] | Loss=0.00033 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=12.176 | 4810.5 samples/s | 75.2 steps/s
[Step=42100 Epoch=79.4] | Loss=0.00038 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.179 | 5162.3 samples/s | 80.7 steps/s
[Step=42150 Epoch=79.5] | Loss=0.00038 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.181 | 5301.9 samples/s | 82.8 steps/s
[Step=42200 Epoch=79.5] | Loss=0.00034 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.184 | 5298.6 samples/s | 82.8 steps/s
[Step=42250 Epoch=79.6] | Loss=0.00032 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.187 | 4993.2 samples/s | 78.0 steps/s
[Step=42300 Epoch=79.7] | Loss=0.00037 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.190 | 5266.1 samples/s | 82.3 steps/s
[Step=42350 Epoch=79.8] | Loss=0.00034 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.192 | 5173.4 samples/s | 80.8 steps/s
[Step=42400 Epoch=79.9] | Loss=0.00032 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.195 | 5217.6 samples/s | 81.5 steps/s
[Step=42450 Epoch=80.0] | Loss=0.00036 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.197 | 5273.1 samples/s | 82.4 steps/s
[Step=42500 Epoch=80.1] | Loss=0.00034 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.200 | 5208.2 samples/s | 81.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=80.1] | Loss=0.00003 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.224 | 4662.6 samples/s | 72.9 steps/s
[Step=42550 Epoch=80.2] | Loss=0.00010 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=12.227 | 3965.2 samples/s | 62.0 steps/s
[Step=42600 Epoch=80.3] | Loss=0.00123 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=12.227 | 4567.8 samples/s | 71.4 steps/s
[Step=42650 Epoch=80.4] | Loss=0.00120 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=12.222 | 4573.9 samples/s | 71.5 steps/s
[Step=42700 Epoch=80.5] | Loss=0.00103 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=12.219 | 4556.4 samples/s | 71.2 steps/s
[Step=42750 Epoch=80.6] | Loss=0.00091 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=12.218 | 4545.0 samples/s | 71.0 steps/s
[Step=42800 Epoch=80.7] | Loss=0.00077 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.151 | L2-Norm(final)=12.216 | 4540.6 samples/s | 70.9 steps/s
[Step=42850 Epoch=80.8] | Loss=0.00066 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.150 | L2-Norm(final)=12.216 | 4559.3 samples/s | 71.2 steps/s
[Step=42900 Epoch=80.9] | Loss=0.00058 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.215 | 4547.6 samples/s | 71.1 steps/s
[Step=42950 Epoch=81.0] | Loss=0.00054 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.145 | L2-Norm(final)=12.214 | 4524.6 samples/s | 70.7 steps/s
[Step=43000 Epoch=81.1] | Loss=0.00049 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=12.214 | 4545.9 samples/s | 71.0 steps/s
[Step=43050 Epoch=81.1] | Loss=0.00045 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.140 | L2-Norm(final)=12.214 | 2109.8 samples/s | 33.0 steps/s
[Step=43100 Epoch=81.2] | Loss=0.00041 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=12.213 | 4604.5 samples/s | 71.9 steps/s
[Step=43150 Epoch=81.3] | Loss=0.00038 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=12.213 | 4580.5 samples/s | 71.6 steps/s
[Step=43200 Epoch=81.4] | Loss=0.00035 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=12.213 | 4563.0 samples/s | 71.3 steps/s
[Step=43250 Epoch=81.5] | Loss=0.00033 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=12.213 | 4575.7 samples/s | 71.5 steps/s
[Step=43300 Epoch=81.6] | Loss=0.00031 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=12.213 | 4617.3 samples/s | 72.1 steps/s
[Step=43350 Epoch=81.7] | Loss=0.00029 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=12.213 | 4601.2 samples/s | 71.9 steps/s
[Step=43400 Epoch=81.8] | Loss=0.00027 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.111 | L2-Norm(final)=12.212 | 4618.3 samples/s | 72.2 steps/s
[Step=43450 Epoch=81.9] | Loss=0.00026 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=12.212 | 4684.8 samples/s | 73.2 steps/s
[Step=43500 Epoch=82.0] | Loss=0.00025 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.101 | L2-Norm(final)=12.212 | 4655.5 samples/s | 72.7 steps/s
[Step=43550 Epoch=82.1] | Loss=0.00024 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=12.212 | 5854.2 samples/s | 91.5 steps/s
[Step=43600 Epoch=82.2] | Loss=0.00022 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=12.212 | 2022.0 samples/s | 31.6 steps/s
[Step=43650 Epoch=82.3] | Loss=0.00022 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.086 | L2-Norm(final)=12.212 | 4675.7 samples/s | 73.1 steps/s
[Step=43700 Epoch=82.4] | Loss=0.00021 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=12.212 | 4554.2 samples/s | 71.2 steps/s
[Step=43750 Epoch=82.5] | Loss=0.00020 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=12.212 | 4742.3 samples/s | 74.1 steps/s
[Step=43800 Epoch=82.6] | Loss=0.00019 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=12.212 | 4636.2 samples/s | 72.4 steps/s
[Step=43850 Epoch=82.7] | Loss=0.00018 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=12.212 | 4688.1 samples/s | 73.3 steps/s
[Step=43900 Epoch=82.8] | Loss=0.00018 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=12.212 | 4641.6 samples/s | 72.5 steps/s
[Step=43950 Epoch=82.8] | Loss=0.00017 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.053 | L2-Norm(final)=12.212 | 4539.8 samples/s | 70.9 steps/s
[Step=44000 Epoch=82.9] | Loss=0.00017 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.048 | L2-Norm(final)=12.212 | 4561.9 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06170 | acc=0.9728 | tpr=0.9787 | fpr=0.0399 | 4515.2 samples/s | 17.6 steps/s
Avg test loss: 0.06920, Avg test acc: 0.97159, Avg tpr: 0.97785, Avg fpr: 0.04217, total FA: 329

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=7.47685 | acc=0.2991 | tpr=0.0216 | fpr=0.0981 | 4667.9 samples/s | 18.2 steps/s
Avg test loss: 7.49169, Avg test acc: 0.29574, Avg tpr: 0.02092, Avg fpr: 0.09986, total FA: 779

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.75184 | acc=0.1246 | tpr=0.4912 | fpr=0.8820 | 4503.2 samples/s | 17.6 steps/s
[Step= 100] | Loss=7.69841 | acc=0.1240 | tpr=0.4584 | fpr=0.8822 | 8644.1 samples/s | 33.8 steps/s
[Step= 150] | Loss=7.69960 | acc=0.1232 | tpr=0.4611 | fpr=0.8831 | 8490.3 samples/s | 33.2 steps/s
[Step= 200] | Loss=7.68650 | acc=0.1240 | tpr=0.4579 | fpr=0.8821 | 8545.5 samples/s | 33.4 steps/s
[Step= 250] | Loss=7.68490 | acc=0.1246 | tpr=0.4620 | fpr=0.8816 | 8370.2 samples/s | 32.7 steps/s
[Step= 300] | Loss=7.68123 | acc=0.1240 | tpr=0.4567 | fpr=0.8820 | 8317.1 samples/s | 32.5 steps/s
[Step= 350] | Loss=7.67671 | acc=0.1236 | tpr=0.4552 | fpr=0.8824 | 4982.0 samples/s | 19.5 steps/s
[Step= 400] | Loss=7.67592 | acc=0.1237 | tpr=0.4562 | fpr=0.8823 | 8322.9 samples/s | 32.5 steps/s
[Step= 450] | Loss=7.67897 | acc=0.1236 | tpr=0.4567 | fpr=0.8824 | 8735.5 samples/s | 34.1 steps/s
[Step= 500] | Loss=7.68024 | acc=0.1238 | tpr=0.4581 | fpr=0.8822 | 8264.1 samples/s | 32.3 steps/s
[Step= 550] | Loss=7.68209 | acc=0.1239 | tpr=0.4592 | fpr=0.8822 | 15687.3 samples/s | 61.3 steps/s
Avg test loss: 7.68411, Avg test acc: 0.12372, Avg tpr: 0.45919, Avg fpr: 0.88238, total FA: 122517

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.18202 | acc=0.9813 | tpr=0.9513 | fpr=0.0181 | 4536.9 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.19609 | acc=0.9800 | tpr=0.9531 | fpr=0.0195 | 8654.0 samples/s | 33.8 steps/s
[Step= 150] | Loss=0.20343 | acc=0.9795 | tpr=0.9582 | fpr=0.0201 | 8568.0 samples/s | 33.5 steps/s
[Step= 200] | Loss=0.20453 | acc=0.9796 | tpr=0.9628 | fpr=0.0201 | 8673.5 samples/s | 33.9 steps/s
[Step= 250] | Loss=0.20311 | acc=0.9798 | tpr=0.9590 | fpr=0.0198 | 8373.1 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.20566 | acc=0.9795 | tpr=0.9585 | fpr=0.0202 | 7730.8 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.20787 | acc=0.9791 | tpr=0.9580 | fpr=0.0205 | 5254.3 samples/s | 20.5 steps/s
[Step= 400] | Loss=0.20932 | acc=0.9790 | tpr=0.9573 | fpr=0.0206 | 8880.8 samples/s | 34.7 steps/s
[Step= 450] | Loss=0.21396 | acc=0.9787 | tpr=0.9567 | fpr=0.0209 | 8249.1 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.21247 | acc=0.9787 | tpr=0.9555 | fpr=0.0209 | 8662.6 samples/s | 33.8 steps/s
[Step= 550] | Loss=0.21108 | acc=0.9787 | tpr=0.9534 | fpr=0.0208 | 15661.4 samples/s | 61.2 steps/s
Avg test loss: 0.21082, Avg test acc: 0.97873, Avg tpr: 0.95325, Avg fpr: 0.02081, total FA: 2889

server round 22/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=44001 Epoch=43.0] | Loss=0.02728 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.031 | L2-Norm(final)=11.158 | 4794.7 samples/s | 74.9 steps/s
[Step=44050 Epoch=43.0] | Loss=0.01215 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=11.161 | 5014.4 samples/s | 78.4 steps/s
[Step=44100 Epoch=43.1] | Loss=0.01377 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=11.169 | 5495.8 samples/s | 85.9 steps/s
[Step=44150 Epoch=43.1] | Loss=0.01492 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=11.177 | 5465.8 samples/s | 85.4 steps/s
[Step=44200 Epoch=43.2] | Loss=0.01494 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=11.185 | 5566.3 samples/s | 87.0 steps/s
[Step=44250 Epoch=43.2] | Loss=0.01468 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=11.192 | 5627.9 samples/s | 87.9 steps/s
[Step=44300 Epoch=43.3] | Loss=0.01426 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=11.199 | 5735.0 samples/s | 89.6 steps/s
[Step=44350 Epoch=43.3] | Loss=0.01401 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=11.205 | 5476.6 samples/s | 85.6 steps/s
[Step=44400 Epoch=43.3] | Loss=0.01413 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=11.212 | 5582.0 samples/s | 87.2 steps/s
[Step=44450 Epoch=43.4] | Loss=0.01460 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.032 | L2-Norm(final)=11.218 | 5511.1 samples/s | 86.1 steps/s
[Step=44500 Epoch=43.4] | Loss=0.01471 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=11.223 | 5676.3 samples/s | 88.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=43.4] | Loss=0.01487 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.032 | L2-Norm(final)=11.275 | 4712.3 samples/s | 73.6 steps/s
[Step=44550 Epoch=43.5] | Loss=0.01279 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.042 | L2-Norm(final)=11.277 | 4332.7 samples/s | 67.7 steps/s
[Step=44600 Epoch=43.5] | Loss=0.01072 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=11.278 | 4868.3 samples/s | 76.1 steps/s
[Step=44650 Epoch=43.6] | Loss=0.01165 | Reg=0.00227 | acc=0.9531 | L2-Norm=15.059 | L2-Norm(final)=11.278 | 4807.6 samples/s | 75.1 steps/s
[Step=44700 Epoch=43.6] | Loss=0.01146 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.065 | L2-Norm(final)=11.279 | 4809.1 samples/s | 75.1 steps/s
[Step=44750 Epoch=43.7] | Loss=0.01180 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=11.280 | 4727.2 samples/s | 73.9 steps/s
[Step=44800 Epoch=43.7] | Loss=0.01180 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=11.281 | 4765.4 samples/s | 74.5 steps/s
[Step=44850 Epoch=43.8] | Loss=0.01168 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.079 | L2-Norm(final)=11.281 | 4755.3 samples/s | 74.3 steps/s
[Step=44900 Epoch=43.8] | Loss=0.01130 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=11.281 | 4690.6 samples/s | 73.3 steps/s
[Step=44950 Epoch=43.9] | Loss=0.01142 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.087 | L2-Norm(final)=11.281 | 4834.5 samples/s | 75.5 steps/s
[Step=45000 Epoch=43.9] | Loss=0.01159 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.091 | L2-Norm(final)=11.282 | 4708.2 samples/s | 73.6 steps/s
[Step=45050 Epoch=44.0] | Loss=0.01168 | Reg=0.00228 | acc=0.9531 | L2-Norm=15.095 | L2-Norm(final)=11.282 | 4779.9 samples/s | 74.7 steps/s
[Step=45100 Epoch=44.0] | Loss=0.01166 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.098 | L2-Norm(final)=11.282 | 4888.7 samples/s | 76.4 steps/s
[Step=45150 Epoch=44.1] | Loss=0.01175 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.102 | L2-Norm(final)=11.282 | 4823.2 samples/s | 75.4 steps/s
[Step=45200 Epoch=44.1] | Loss=0.01174 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.105 | L2-Norm(final)=11.282 | 4879.5 samples/s | 76.2 steps/s
[Step=45250 Epoch=44.2] | Loss=0.01175 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=11.282 | 4938.6 samples/s | 77.2 steps/s
[Step=45300 Epoch=44.2] | Loss=0.01173 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.111 | L2-Norm(final)=11.282 | 4913.7 samples/s | 76.8 steps/s
[Step=45350 Epoch=44.3] | Loss=0.01161 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=11.282 | 4908.3 samples/s | 76.7 steps/s
[Step=45400 Epoch=44.3] | Loss=0.01159 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.116 | L2-Norm(final)=11.282 | 4943.0 samples/s | 77.2 steps/s
[Step=45450 Epoch=44.4] | Loss=0.01145 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.119 | L2-Norm(final)=11.282 | 4815.2 samples/s | 75.2 steps/s
[Step=45500 Epoch=44.4] | Loss=0.01148 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.121 | L2-Norm(final)=11.283 | 5190.6 samples/s | 81.1 steps/s
[Step=45550 Epoch=44.5] | Loss=0.01154 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=11.283 | 2150.1 samples/s | 33.6 steps/s
[Step=45600 Epoch=44.5] | Loss=0.01137 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.126 | L2-Norm(final)=11.283 | 4916.8 samples/s | 76.8 steps/s
[Step=45650 Epoch=44.6] | Loss=0.01129 | Reg=0.00229 | acc=0.9688 | L2-Norm=15.128 | L2-Norm(final)=11.284 | 4706.0 samples/s | 73.5 steps/s
[Step=45700 Epoch=44.6] | Loss=0.01116 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.130 | L2-Norm(final)=11.284 | 4795.3 samples/s | 74.9 steps/s
[Step=45750 Epoch=44.7] | Loss=0.01108 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=11.285 | 4792.0 samples/s | 74.9 steps/s
[Step=45800 Epoch=44.7] | Loss=0.01104 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=11.285 | 4809.1 samples/s | 75.1 steps/s
[Step=45850 Epoch=44.8] | Loss=0.01098 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=11.286 | 4775.2 samples/s | 74.6 steps/s
[Step=45900 Epoch=44.8] | Loss=0.01100 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.139 | L2-Norm(final)=11.286 | 4774.4 samples/s | 74.6 steps/s
[Step=45950 Epoch=44.9] | Loss=0.01089 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.141 | L2-Norm(final)=11.287 | 4802.1 samples/s | 75.0 steps/s
[Step=46000 Epoch=44.9] | Loss=0.01079 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.143 | L2-Norm(final)=11.287 | 4766.0 samples/s | 74.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step46000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=44001 Epoch=82.9] | Loss=0.00023 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=12.214 | 4295.7 samples/s | 67.1 steps/s
[Step=44050 Epoch=83.0] | Loss=0.00004 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.214 | 4846.3 samples/s | 75.7 steps/s
[Step=44100 Epoch=83.1] | Loss=0.00009 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.215 | 5129.5 samples/s | 80.1 steps/s
[Step=44150 Epoch=83.2] | Loss=0.00009 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.216 | 5220.8 samples/s | 81.6 steps/s
[Step=44200 Epoch=83.3] | Loss=0.00010 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.218 | 5212.8 samples/s | 81.5 steps/s
[Step=44250 Epoch=83.4] | Loss=0.00009 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.220 | 5286.6 samples/s | 82.6 steps/s
[Step=44300 Epoch=83.5] | Loss=0.00012 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.221 | 5165.8 samples/s | 80.7 steps/s
[Step=44350 Epoch=83.6] | Loss=0.00016 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.223 | 5297.1 samples/s | 82.8 steps/s
[Step=44400 Epoch=83.7] | Loss=0.00015 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.225 | 5158.1 samples/s | 80.6 steps/s
[Step=44450 Epoch=83.8] | Loss=0.00014 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.227 | 5251.6 samples/s | 82.1 steps/s
[Step=44500 Epoch=83.9] | Loss=0.00013 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.229 | 5355.4 samples/s | 83.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=83.9] | Loss=0.00000 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=12.244 | 4196.9 samples/s | 65.6 steps/s
[Step=44550 Epoch=84.0] | Loss=0.00014 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=12.246 | 4444.2 samples/s | 69.4 steps/s
[Step=44600 Epoch=84.1] | Loss=0.00008 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=12.248 | 4695.8 samples/s | 73.4 steps/s
[Step=44650 Epoch=84.2] | Loss=0.00005 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=12.249 | 4637.3 samples/s | 72.5 steps/s
[Step=44700 Epoch=84.3] | Loss=0.00004 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=12.250 | 4501.9 samples/s | 70.3 steps/s
[Step=44750 Epoch=84.4] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=12.250 | 4548.1 samples/s | 71.1 steps/s
[Step=44800 Epoch=84.4] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=12.251 | 4648.9 samples/s | 72.6 steps/s
[Step=44850 Epoch=84.5] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=12.251 | 4442.8 samples/s | 69.4 steps/s
[Step=44900 Epoch=84.6] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=12.251 | 4535.9 samples/s | 70.9 steps/s
[Step=44950 Epoch=84.7] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=12.252 | 4569.6 samples/s | 71.4 steps/s
[Step=45000 Epoch=84.8] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=12.252 | 4624.5 samples/s | 72.3 steps/s
[Step=45050 Epoch=84.9] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.934 | L2-Norm(final)=12.252 | 2194.4 samples/s | 34.3 steps/s
[Step=45100 Epoch=85.0] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=12.252 | 4644.1 samples/s | 72.6 steps/s
[Step=45150 Epoch=85.1] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=12.253 | 4649.9 samples/s | 72.7 steps/s
[Step=45200 Epoch=85.2] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.903 | L2-Norm(final)=12.253 | 4589.8 samples/s | 71.7 steps/s
[Step=45250 Epoch=85.3] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.893 | L2-Norm(final)=12.253 | 4676.6 samples/s | 73.1 steps/s
[Step=45300 Epoch=85.4] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=12.253 | 4659.4 samples/s | 72.8 steps/s
[Step=45350 Epoch=85.5] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.872 | L2-Norm(final)=12.253 | 4574.1 samples/s | 71.5 steps/s
[Step=45400 Epoch=85.6] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.862 | L2-Norm(final)=12.253 | 4557.5 samples/s | 71.2 steps/s
[Step=45450 Epoch=85.7] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.851 | L2-Norm(final)=12.253 | 4546.4 samples/s | 71.0 steps/s
[Step=45500 Epoch=85.8] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=12.254 | 4526.6 samples/s | 70.7 steps/s
[Step=45550 Epoch=85.9] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=12.254 | 5719.1 samples/s | 89.4 steps/s
[Step=45600 Epoch=86.0] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.818 | L2-Norm(final)=12.254 | 1965.4 samples/s | 30.7 steps/s
[Step=45650 Epoch=86.1] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=12.254 | 4597.0 samples/s | 71.8 steps/s
[Step=45700 Epoch=86.1] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=12.254 | 4566.8 samples/s | 71.4 steps/s
[Step=45750 Epoch=86.2] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=12.254 | 4646.9 samples/s | 72.6 steps/s
[Step=45800 Epoch=86.3] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.774 | L2-Norm(final)=12.254 | 4607.4 samples/s | 72.0 steps/s
[Step=45850 Epoch=86.4] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.763 | L2-Norm(final)=12.255 | 4625.2 samples/s | 72.3 steps/s
[Step=45900 Epoch=86.5] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.751 | L2-Norm(final)=12.255 | 4569.0 samples/s | 71.4 steps/s
[Step=45950 Epoch=86.6] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.255 | 4550.9 samples/s | 71.1 steps/s
[Step=46000 Epoch=86.7] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.728 | L2-Norm(final)=12.255 | 4548.3 samples/s | 71.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06297 | acc=0.9733 | tpr=0.9762 | fpr=0.0330 | 4625.5 samples/s | 18.1 steps/s
Avg test loss: 0.07062, Avg test acc: 0.97199, Avg tpr: 0.97523, Avg fpr: 0.03512, total FA: 274

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.42586 | acc=0.3035 | tpr=0.0240 | fpr=0.0894 | 4610.6 samples/s | 18.0 steps/s
Avg test loss: 6.43294, Avg test acc: 0.29910, Avg tpr: 0.02273, Avg fpr: 0.09306, total FA: 726

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.00966 | acc=0.1340 | tpr=0.4558 | fpr=0.8718 | 4587.7 samples/s | 17.9 steps/s
[Step= 100] | Loss=6.96183 | acc=0.1345 | tpr=0.4307 | fpr=0.8711 | 8575.9 samples/s | 33.5 steps/s
[Step= 150] | Loss=6.95835 | acc=0.1350 | tpr=0.4481 | fpr=0.8708 | 5557.0 samples/s | 21.7 steps/s
[Step= 200] | Loss=6.94161 | acc=0.1353 | tpr=0.4415 | fpr=0.8703 | 7295.1 samples/s | 28.5 steps/s
[Step= 250] | Loss=6.94196 | acc=0.1358 | tpr=0.4498 | fpr=0.8700 | 8411.4 samples/s | 32.9 steps/s
[Step= 300] | Loss=6.93988 | acc=0.1359 | tpr=0.4545 | fpr=0.8699 | 8418.1 samples/s | 32.9 steps/s
[Step= 350] | Loss=6.93666 | acc=0.1351 | tpr=0.4527 | fpr=0.8707 | 8415.6 samples/s | 32.9 steps/s
[Step= 400] | Loss=6.93716 | acc=0.1355 | tpr=0.4508 | fpr=0.8702 | 9044.2 samples/s | 35.3 steps/s
[Step= 450] | Loss=6.94096 | acc=0.1354 | tpr=0.4479 | fpr=0.8703 | 8206.5 samples/s | 32.1 steps/s
[Step= 500] | Loss=6.94458 | acc=0.1356 | tpr=0.4480 | fpr=0.8700 | 8312.9 samples/s | 32.5 steps/s
[Step= 550] | Loss=6.94435 | acc=0.1361 | tpr=0.4465 | fpr=0.8696 | 15905.3 samples/s | 62.1 steps/s
Avg test loss: 6.94630, Avg test acc: 0.13590, Avg tpr: 0.44691, Avg fpr: 0.86976, total FA: 120764

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15771 | acc=0.9826 | tpr=0.9425 | fpr=0.0167 | 4658.7 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.17110 | acc=0.9814 | tpr=0.9446 | fpr=0.0179 | 8102.8 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.17705 | acc=0.9809 | tpr=0.9539 | fpr=0.0186 | 5035.0 samples/s | 19.7 steps/s
[Step= 200] | Loss=0.17892 | acc=0.9809 | tpr=0.9574 | fpr=0.0187 | 8417.6 samples/s | 32.9 steps/s
[Step= 250] | Loss=0.17770 | acc=0.9812 | tpr=0.9537 | fpr=0.0183 | 8369.6 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.18001 | acc=0.9811 | tpr=0.9556 | fpr=0.0185 | 8533.7 samples/s | 33.3 steps/s
[Step= 350] | Loss=0.18211 | acc=0.9807 | tpr=0.9555 | fpr=0.0188 | 8733.4 samples/s | 34.1 steps/s
[Step= 400] | Loss=0.18329 | acc=0.9806 | tpr=0.9551 | fpr=0.0189 | 8575.1 samples/s | 33.5 steps/s
[Step= 450] | Loss=0.18716 | acc=0.9803 | tpr=0.9547 | fpr=0.0192 | 8316.4 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.18611 | acc=0.9804 | tpr=0.9542 | fpr=0.0192 | 8686.4 samples/s | 33.9 steps/s
[Step= 550] | Loss=0.18489 | acc=0.9805 | tpr=0.9534 | fpr=0.0190 | 14162.5 samples/s | 55.3 steps/s
Avg test loss: 0.18467, Avg test acc: 0.98052, Avg tpr: 0.95325, Avg fpr: 0.01898, total FA: 2636

server round 23/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=46001 Epoch=44.9] | Loss=0.00305 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.745 | L2-Norm(final)=11.302 | 4194.3 samples/s | 65.5 steps/s
[Step=46050 Epoch=45.0] | Loss=0.00981 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.746 | L2-Norm(final)=11.304 | 5194.3 samples/s | 81.2 steps/s
[Step=46100 Epoch=45.0] | Loss=0.00871 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.746 | L2-Norm(final)=11.307 | 5722.0 samples/s | 89.4 steps/s
[Step=46150 Epoch=45.1] | Loss=0.00874 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.746 | L2-Norm(final)=11.311 | 5444.7 samples/s | 85.1 steps/s
[Step=46200 Epoch=45.1] | Loss=0.00908 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.746 | L2-Norm(final)=11.314 | 5450.8 samples/s | 85.2 steps/s
[Step=46250 Epoch=45.2] | Loss=0.00942 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=11.316 | 5481.4 samples/s | 85.6 steps/s
[Step=46300 Epoch=45.2] | Loss=0.00972 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=11.319 | 5541.7 samples/s | 86.6 steps/s
[Step=46350 Epoch=45.3] | Loss=0.00961 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.746 | L2-Norm(final)=11.321 | 5576.2 samples/s | 87.1 steps/s
[Step=46400 Epoch=45.3] | Loss=0.00966 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.746 | L2-Norm(final)=11.324 | 5393.6 samples/s | 84.3 steps/s
[Step=46450 Epoch=45.4] | Loss=0.00966 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=11.328 | 5525.2 samples/s | 86.3 steps/s
[Step=46500 Epoch=45.4] | Loss=0.00943 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.746 | L2-Norm(final)=11.331 | 5517.1 samples/s | 86.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=45.4] | Loss=0.03649 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.746 | L2-Norm(final)=11.366 | 4521.9 samples/s | 70.7 steps/s
[Step=46550 Epoch=45.4] | Loss=0.00793 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.756 | L2-Norm(final)=11.368 | 4385.9 samples/s | 68.5 steps/s
[Step=46600 Epoch=45.5] | Loss=0.00982 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.764 | L2-Norm(final)=11.369 | 4751.5 samples/s | 74.2 steps/s
[Step=46650 Epoch=45.5] | Loss=0.01013 | Reg=0.00218 | acc=0.9531 | L2-Norm=14.770 | L2-Norm(final)=11.370 | 4770.1 samples/s | 74.5 steps/s
[Step=46700 Epoch=45.6] | Loss=0.01035 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.776 | L2-Norm(final)=11.370 | 4817.0 samples/s | 75.3 steps/s
[Step=46750 Epoch=45.6] | Loss=0.01051 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.781 | L2-Norm(final)=11.369 | 4857.1 samples/s | 75.9 steps/s
[Step=46800 Epoch=45.7] | Loss=0.01042 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=11.368 | 4828.2 samples/s | 75.4 steps/s
[Step=46850 Epoch=45.7] | Loss=0.01039 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.789 | L2-Norm(final)=11.368 | 4924.2 samples/s | 76.9 steps/s
[Step=46900 Epoch=45.8] | Loss=0.01049 | Reg=0.00219 | acc=0.9062 | L2-Norm=14.792 | L2-Norm(final)=11.367 | 4915.4 samples/s | 76.8 steps/s
[Step=46950 Epoch=45.8] | Loss=0.01035 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.795 | L2-Norm(final)=11.367 | 4938.2 samples/s | 77.2 steps/s
[Step=47000 Epoch=45.9] | Loss=0.01033 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.798 | L2-Norm(final)=11.367 | 4926.2 samples/s | 77.0 steps/s
[Step=47050 Epoch=45.9] | Loss=0.01033 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.801 | L2-Norm(final)=11.366 | 4943.1 samples/s | 77.2 steps/s
[Step=47100 Epoch=46.0] | Loss=0.01039 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.804 | L2-Norm(final)=11.366 | 4839.2 samples/s | 75.6 steps/s
[Step=47150 Epoch=46.0] | Loss=0.01041 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=11.366 | 4834.9 samples/s | 75.5 steps/s
[Step=47200 Epoch=46.1] | Loss=0.01034 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.809 | L2-Norm(final)=11.366 | 4848.7 samples/s | 75.8 steps/s
[Step=47250 Epoch=46.1] | Loss=0.01041 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.812 | L2-Norm(final)=11.366 | 4817.2 samples/s | 75.3 steps/s
[Step=47300 Epoch=46.2] | Loss=0.01046 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.814 | L2-Norm(final)=11.365 | 4788.8 samples/s | 74.8 steps/s
[Step=47350 Epoch=46.2] | Loss=0.01065 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.817 | L2-Norm(final)=11.365 | 4786.5 samples/s | 74.8 steps/s
[Step=47400 Epoch=46.3] | Loss=0.01059 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.819 | L2-Norm(final)=11.364 | 4772.5 samples/s | 74.6 steps/s
[Step=47450 Epoch=46.3] | Loss=0.01074 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.821 | L2-Norm(final)=11.364 | 4823.6 samples/s | 75.4 steps/s
[Step=47500 Epoch=46.4] | Loss=0.01067 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.824 | L2-Norm(final)=11.364 | 5190.8 samples/s | 81.1 steps/s
[Step=47550 Epoch=46.4] | Loss=0.01058 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=11.364 | 2142.6 samples/s | 33.5 steps/s
[Step=47600 Epoch=46.5] | Loss=0.01059 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.829 | L2-Norm(final)=11.364 | 4724.6 samples/s | 73.8 steps/s
[Step=47650 Epoch=46.5] | Loss=0.01043 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.831 | L2-Norm(final)=11.364 | 4746.0 samples/s | 74.2 steps/s
[Step=47700 Epoch=46.6] | Loss=0.01038 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.834 | L2-Norm(final)=11.365 | 4720.3 samples/s | 73.8 steps/s
[Step=47750 Epoch=46.6] | Loss=0.01038 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.836 | L2-Norm(final)=11.365 | 4835.8 samples/s | 75.6 steps/s
[Step=47800 Epoch=46.7] | Loss=0.01030 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.838 | L2-Norm(final)=11.365 | 4789.8 samples/s | 74.8 steps/s
[Step=47850 Epoch=46.7] | Loss=0.01031 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=11.365 | 4810.9 samples/s | 75.2 steps/s
[Step=47900 Epoch=46.8] | Loss=0.01030 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.843 | L2-Norm(final)=11.365 | 4712.5 samples/s | 73.6 steps/s
[Step=47950 Epoch=46.8] | Loss=0.01028 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.845 | L2-Norm(final)=11.365 | 4818.8 samples/s | 75.3 steps/s
[Step=48000 Epoch=46.9] | Loss=0.01022 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.846 | L2-Norm(final)=11.365 | 4800.7 samples/s | 75.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step48000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=46001 Epoch=86.7] | Loss=0.02244 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.745 | L2-Norm(final)=12.259 | 4133.4 samples/s | 64.6 steps/s
[Step=46050 Epoch=86.8] | Loss=0.00093 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=12.262 | 4672.4 samples/s | 73.0 steps/s
[Step=46100 Epoch=86.9] | Loss=0.00051 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=12.266 | 5182.3 samples/s | 81.0 steps/s
[Step=46150 Epoch=87.0] | Loss=0.00037 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=12.269 | 5162.6 samples/s | 80.7 steps/s
[Step=46200 Epoch=87.1] | Loss=0.00030 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.272 | 5284.4 samples/s | 82.6 steps/s
[Step=46250 Epoch=87.2] | Loss=0.00025 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.274 | 5103.9 samples/s | 79.7 steps/s
[Step=46300 Epoch=87.3] | Loss=0.00022 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.277 | 5200.4 samples/s | 81.3 steps/s
[Step=46350 Epoch=87.4] | Loss=0.00021 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.279 | 5205.8 samples/s | 81.3 steps/s
[Step=46400 Epoch=87.5] | Loss=0.00022 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.281 | 5182.4 samples/s | 81.0 steps/s
[Step=46450 Epoch=87.6] | Loss=0.00020 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.284 | 5299.5 samples/s | 82.8 steps/s
[Step=46500 Epoch=87.7] | Loss=0.00024 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.286 | 5356.2 samples/s | 83.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=87.7] | Loss=0.00004 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.740 | L2-Norm(final)=12.310 | 4007.6 samples/s | 62.6 steps/s
[Step=46550 Epoch=87.7] | Loss=0.00296 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.766 | L2-Norm(final)=12.317 | 4487.8 samples/s | 70.1 steps/s
[Step=46600 Epoch=87.8] | Loss=0.00214 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.795 | L2-Norm(final)=12.313 | 4547.2 samples/s | 71.1 steps/s
[Step=46650 Epoch=87.9] | Loss=0.00174 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.806 | L2-Norm(final)=12.311 | 4534.2 samples/s | 70.8 steps/s
[Step=46700 Epoch=88.0] | Loss=0.00155 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=12.309 | 4472.5 samples/s | 69.9 steps/s
[Step=46750 Epoch=88.1] | Loss=0.00125 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.823 | L2-Norm(final)=12.308 | 4576.1 samples/s | 71.5 steps/s
[Step=46800 Epoch=88.2] | Loss=0.00104 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=12.307 | 4548.1 samples/s | 71.1 steps/s
[Step=46850 Epoch=88.3] | Loss=0.00089 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=12.307 | 4643.4 samples/s | 72.6 steps/s
[Step=46900 Epoch=88.4] | Loss=0.00083 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.828 | L2-Norm(final)=12.306 | 4714.4 samples/s | 73.7 steps/s
[Step=46950 Epoch=88.5] | Loss=0.00074 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=12.306 | 4562.3 samples/s | 71.3 steps/s
[Step=47000 Epoch=88.6] | Loss=0.00068 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=12.306 | 4698.5 samples/s | 73.4 steps/s
[Step=47050 Epoch=88.7] | Loss=0.00062 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=12.306 | 2168.6 samples/s | 33.9 steps/s
[Step=47100 Epoch=88.8] | Loss=0.00057 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=12.305 | 4691.0 samples/s | 73.3 steps/s
[Step=47150 Epoch=88.9] | Loss=0.00052 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.824 | L2-Norm(final)=12.305 | 4636.6 samples/s | 72.4 steps/s
[Step=47200 Epoch=89.0] | Loss=0.00049 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.822 | L2-Norm(final)=12.305 | 4691.7 samples/s | 73.3 steps/s
[Step=47250 Epoch=89.1] | Loss=0.00045 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=12.305 | 4619.7 samples/s | 72.2 steps/s
[Step=47300 Epoch=89.2] | Loss=0.00043 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=12.305 | 4672.2 samples/s | 73.0 steps/s
[Step=47350 Epoch=89.3] | Loss=0.00040 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=12.305 | 4633.4 samples/s | 72.4 steps/s
[Step=47400 Epoch=89.3] | Loss=0.00038 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.812 | L2-Norm(final)=12.305 | 4540.2 samples/s | 70.9 steps/s
[Step=47450 Epoch=89.4] | Loss=0.00036 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=12.305 | 4554.6 samples/s | 71.2 steps/s
[Step=47500 Epoch=89.5] | Loss=0.00034 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.806 | L2-Norm(final)=12.305 | 4546.9 samples/s | 71.0 steps/s
[Step=47550 Epoch=89.6] | Loss=0.00033 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.803 | L2-Norm(final)=12.305 | 5741.1 samples/s | 89.7 steps/s
[Step=47600 Epoch=89.7] | Loss=0.00031 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.799 | L2-Norm(final)=12.305 | 2023.0 samples/s | 31.6 steps/s
[Step=47650 Epoch=89.8] | Loss=0.00030 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=12.305 | 4622.6 samples/s | 72.2 steps/s
[Step=47700 Epoch=89.9] | Loss=0.00028 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.792 | L2-Norm(final)=12.304 | 4552.4 samples/s | 71.1 steps/s
[Step=47750 Epoch=90.0] | Loss=0.00027 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.789 | L2-Norm(final)=12.304 | 4494.0 samples/s | 70.2 steps/s
[Step=47800 Epoch=90.1] | Loss=0.00026 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=12.304 | 4603.8 samples/s | 71.9 steps/s
[Step=47850 Epoch=90.2] | Loss=0.00025 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.781 | L2-Norm(final)=12.304 | 4436.1 samples/s | 69.3 steps/s
[Step=47900 Epoch=90.3] | Loss=0.00024 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.777 | L2-Norm(final)=12.304 | 4604.5 samples/s | 71.9 steps/s
[Step=47950 Epoch=90.4] | Loss=0.00024 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=12.304 | 4470.1 samples/s | 69.8 steps/s
[Step=48000 Epoch=90.5] | Loss=0.00023 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.769 | L2-Norm(final)=12.304 | 4524.7 samples/s | 70.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06234 | acc=0.9723 | tpr=0.9763 | fpr=0.0362 | 3336.8 samples/s | 13.0 steps/s
Avg test loss: 0.06967, Avg test acc: 0.97083, Avg tpr: 0.97494, Avg fpr: 0.03820, total FA: 298

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=10.43648 | acc=0.3086 | tpr=0.0129 | fpr=0.0493 | 3327.7 samples/s | 13.0 steps/s
Avg test loss: 10.46202, Avg test acc: 0.30555, Avg tpr: 0.01218, Avg fpr: 0.04922, total FA: 384

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.97432 | acc=0.1350 | tpr=0.4646 | fpr=0.8709 | 4647.1 samples/s | 18.2 steps/s
[Step= 100] | Loss=6.92447 | acc=0.1349 | tpr=0.4435 | fpr=0.8709 | 8354.5 samples/s | 32.6 steps/s
[Step= 150] | Loss=6.92122 | acc=0.1359 | tpr=0.4640 | fpr=0.8702 | 8682.2 samples/s | 33.9 steps/s
[Step= 200] | Loss=6.90878 | acc=0.1356 | tpr=0.4579 | fpr=0.8702 | 8520.5 samples/s | 33.3 steps/s
[Step= 250] | Loss=6.90867 | acc=0.1362 | tpr=0.4638 | fpr=0.8697 | 9060.7 samples/s | 35.4 steps/s
[Step= 300] | Loss=6.90525 | acc=0.1361 | tpr=0.4662 | fpr=0.8699 | 8191.1 samples/s | 32.0 steps/s
[Step= 350] | Loss=6.89951 | acc=0.1353 | tpr=0.4696 | fpr=0.8708 | 8606.1 samples/s | 33.6 steps/s
[Step= 400] | Loss=6.89983 | acc=0.1355 | tpr=0.4699 | fpr=0.8706 | 8567.0 samples/s | 33.5 steps/s
[Step= 450] | Loss=6.90334 | acc=0.1355 | tpr=0.4669 | fpr=0.8705 | 8341.0 samples/s | 32.6 steps/s
[Step= 500] | Loss=6.90628 | acc=0.1358 | tpr=0.4648 | fpr=0.8702 | 8613.9 samples/s | 33.6 steps/s
[Step= 550] | Loss=6.90735 | acc=0.1360 | tpr=0.4656 | fpr=0.8700 | 14956.8 samples/s | 58.4 steps/s
Avg test loss: 6.90899, Avg test acc: 0.13586, Avg tpr: 0.46593, Avg fpr: 0.87014, total FA: 120817

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.28026 | acc=0.9813 | tpr=0.9469 | fpr=0.0181 | 4667.8 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.30074 | acc=0.9799 | tpr=0.9488 | fpr=0.0195 | 8075.1 samples/s | 31.5 steps/s
[Step= 150] | Loss=0.31162 | acc=0.9794 | tpr=0.9510 | fpr=0.0201 | 8432.3 samples/s | 32.9 steps/s
[Step= 200] | Loss=0.31728 | acc=0.9795 | tpr=0.9552 | fpr=0.0201 | 8482.9 samples/s | 33.1 steps/s
[Step= 250] | Loss=0.31391 | acc=0.9795 | tpr=0.9485 | fpr=0.0200 | 8579.0 samples/s | 33.5 steps/s
[Step= 300] | Loss=0.31972 | acc=0.9792 | tpr=0.9498 | fpr=0.0203 | 8597.7 samples/s | 33.6 steps/s
[Step= 350] | Loss=0.32371 | acc=0.9789 | tpr=0.9499 | fpr=0.0205 | 8488.5 samples/s | 33.2 steps/s
[Step= 400] | Loss=0.32543 | acc=0.9789 | tpr=0.9486 | fpr=0.0205 | 8450.2 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.33236 | acc=0.9787 | tpr=0.9479 | fpr=0.0208 | 8367.2 samples/s | 32.7 steps/s
[Step= 500] | Loss=0.32969 | acc=0.9788 | tpr=0.9476 | fpr=0.0206 | 8551.6 samples/s | 33.4 steps/s
[Step= 550] | Loss=0.32730 | acc=0.9789 | tpr=0.9459 | fpr=0.0205 | 15039.8 samples/s | 58.7 steps/s
Avg test loss: 0.32671, Avg test acc: 0.97887, Avg tpr: 0.94572, Avg fpr: 0.02053, total FA: 2850

server round 24/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=48001 Epoch=46.9] | Loss=0.02483 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.711 | L2-Norm(final)=11.370 | 4788.3 samples/s | 74.8 steps/s
[Step=48050 Epoch=46.9] | Loss=0.01362 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=11.372 | 4732.7 samples/s | 73.9 steps/s
[Step=48100 Epoch=47.0] | Loss=0.01438 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=11.372 | 5481.5 samples/s | 85.6 steps/s
[Step=48150 Epoch=47.0] | Loss=0.01436 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=11.371 | 5546.0 samples/s | 86.7 steps/s
[Step=48200 Epoch=47.1] | Loss=0.01438 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.712 | L2-Norm(final)=11.371 | 5415.4 samples/s | 84.6 steps/s
[Step=48250 Epoch=47.1] | Loss=0.01460 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=11.370 | 5499.2 samples/s | 85.9 steps/s
[Step=48300 Epoch=47.2] | Loss=0.01482 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.712 | L2-Norm(final)=11.370 | 5551.0 samples/s | 86.7 steps/s
[Step=48350 Epoch=47.2] | Loss=0.01495 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.712 | L2-Norm(final)=11.370 | 5369.6 samples/s | 83.9 steps/s
[Step=48400 Epoch=47.3] | Loss=0.01480 | Reg=0.00216 | acc=0.9531 | L2-Norm=14.712 | L2-Norm(final)=11.371 | 5521.5 samples/s | 86.3 steps/s
[Step=48450 Epoch=47.3] | Loss=0.01459 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.712 | L2-Norm(final)=11.372 | 5504.2 samples/s | 86.0 steps/s
[Step=48500 Epoch=47.4] | Loss=0.01455 | Reg=0.00216 | acc=0.9531 | L2-Norm=14.712 | L2-Norm(final)=11.373 | 5538.2 samples/s | 86.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=47.4] | Loss=0.00279 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=11.386 | 4160.3 samples/s | 65.0 steps/s
[Step=48550 Epoch=47.4] | Loss=0.01297 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.734 | L2-Norm(final)=11.386 | 4618.8 samples/s | 72.2 steps/s
[Step=48600 Epoch=47.5] | Loss=0.01141 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.749 | L2-Norm(final)=11.384 | 4817.8 samples/s | 75.3 steps/s
[Step=48650 Epoch=47.5] | Loss=0.01242 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.759 | L2-Norm(final)=11.383 | 4861.7 samples/s | 76.0 steps/s
[Step=48700 Epoch=47.5] | Loss=0.01230 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.765 | L2-Norm(final)=11.382 | 4844.7 samples/s | 75.7 steps/s
[Step=48750 Epoch=47.6] | Loss=0.01171 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.770 | L2-Norm(final)=11.381 | 4784.0 samples/s | 74.7 steps/s
[Step=48800 Epoch=47.6] | Loss=0.01125 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.775 | L2-Norm(final)=11.380 | 4827.3 samples/s | 75.4 steps/s
[Step=48850 Epoch=47.7] | Loss=0.01111 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.779 | L2-Norm(final)=11.379 | 4797.4 samples/s | 75.0 steps/s
[Step=48900 Epoch=47.7] | Loss=0.01147 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.782 | L2-Norm(final)=11.379 | 4791.5 samples/s | 74.9 steps/s
[Step=48950 Epoch=47.8] | Loss=0.01129 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.786 | L2-Norm(final)=11.378 | 4818.8 samples/s | 75.3 steps/s
[Step=49000 Epoch=47.8] | Loss=0.01145 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.790 | L2-Norm(final)=11.377 | 4781.6 samples/s | 74.7 steps/s
[Step=49050 Epoch=47.9] | Loss=0.01156 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=11.376 | 4773.5 samples/s | 74.6 steps/s
[Step=49100 Epoch=47.9] | Loss=0.01150 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.797 | L2-Norm(final)=11.376 | 4881.1 samples/s | 76.3 steps/s
[Step=49150 Epoch=48.0] | Loss=0.01144 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.800 | L2-Norm(final)=11.376 | 4720.5 samples/s | 73.8 steps/s
[Step=49200 Epoch=48.0] | Loss=0.01139 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.803 | L2-Norm(final)=11.376 | 4782.4 samples/s | 74.7 steps/s
[Step=49250 Epoch=48.1] | Loss=0.01130 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=11.375 | 4783.5 samples/s | 74.7 steps/s
[Step=49300 Epoch=48.1] | Loss=0.01130 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.810 | L2-Norm(final)=11.375 | 4754.5 samples/s | 74.3 steps/s
[Step=49350 Epoch=48.2] | Loss=0.01126 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.812 | L2-Norm(final)=11.375 | 4765.1 samples/s | 74.5 steps/s
[Step=49400 Epoch=48.2] | Loss=0.01121 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=11.375 | 4844.0 samples/s | 75.7 steps/s
[Step=49450 Epoch=48.3] | Loss=0.01113 | Reg=0.00220 | acc=0.9531 | L2-Norm=14.818 | L2-Norm(final)=11.375 | 4746.7 samples/s | 74.2 steps/s
[Step=49500 Epoch=48.3] | Loss=0.01118 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=11.375 | 5141.2 samples/s | 80.3 steps/s
[Step=49550 Epoch=48.4] | Loss=0.01110 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.823 | L2-Norm(final)=11.375 | 2148.7 samples/s | 33.6 steps/s
[Step=49600 Epoch=48.4] | Loss=0.01095 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=11.375 | 4764.4 samples/s | 74.4 steps/s
[Step=49650 Epoch=48.5] | Loss=0.01092 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.827 | L2-Norm(final)=11.375 | 4793.6 samples/s | 74.9 steps/s
[Step=49700 Epoch=48.5] | Loss=0.01078 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=11.375 | 4881.3 samples/s | 76.3 steps/s
[Step=49750 Epoch=48.6] | Loss=0.01066 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.831 | L2-Norm(final)=11.375 | 4718.3 samples/s | 73.7 steps/s
[Step=49800 Epoch=48.6] | Loss=0.01065 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.833 | L2-Norm(final)=11.375 | 4743.0 samples/s | 74.1 steps/s
[Step=49850 Epoch=48.7] | Loss=0.01054 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.835 | L2-Norm(final)=11.375 | 4762.2 samples/s | 74.4 steps/s
[Step=49900 Epoch=48.7] | Loss=0.01048 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.837 | L2-Norm(final)=11.376 | 4768.4 samples/s | 74.5 steps/s
[Step=49950 Epoch=48.8] | Loss=0.01046 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=11.376 | 4806.9 samples/s | 75.1 steps/s
[Step=50000 Epoch=48.8] | Loss=0.01040 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.841 | L2-Norm(final)=11.376 | 4795.6 samples/s | 74.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step50000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=48001 Epoch=90.5] | Loss=0.00000 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=12.305 | 4100.2 samples/s | 64.1 steps/s
[Step=48050 Epoch=90.6] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=12.305 | 5117.7 samples/s | 80.0 steps/s
[Step=48100 Epoch=90.7] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=12.305 | 5158.0 samples/s | 80.6 steps/s
[Step=48150 Epoch=90.8] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.305 | 5180.3 samples/s | 80.9 steps/s
[Step=48200 Epoch=90.9] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.305 | 5140.2 samples/s | 80.3 steps/s
[Step=48250 Epoch=91.0] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.305 | 5267.5 samples/s | 82.3 steps/s
[Step=48300 Epoch=91.0] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.305 | 5114.8 samples/s | 79.9 steps/s
[Step=48350 Epoch=91.1] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.306 | 5207.2 samples/s | 81.4 steps/s
[Step=48400 Epoch=91.2] | Loss=0.00002 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.306 | 5318.1 samples/s | 83.1 steps/s
[Step=48450 Epoch=91.3] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.306 | 5479.4 samples/s | 85.6 steps/s
[Step=48500 Epoch=91.4] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.306 | 5418.7 samples/s | 84.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=91.4] | Loss=0.00004 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=12.308 | 4049.4 samples/s | 63.3 steps/s
[Step=48550 Epoch=91.5] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.702 | L2-Norm(final)=12.308 | 4596.4 samples/s | 71.8 steps/s
[Step=48600 Epoch=91.6] | Loss=0.00000 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=12.309 | 4540.2 samples/s | 70.9 steps/s
[Step=48650 Epoch=91.7] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=12.310 | 4546.6 samples/s | 71.0 steps/s
[Step=48700 Epoch=91.8] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=12.311 | 4491.0 samples/s | 70.2 steps/s
[Step=48750 Epoch=91.9] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=12.312 | 4537.9 samples/s | 70.9 steps/s
[Step=48800 Epoch=92.0] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=12.313 | 4527.7 samples/s | 70.7 steps/s
[Step=48850 Epoch=92.1] | Loss=0.00000 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=12.313 | 4521.8 samples/s | 70.7 steps/s
[Step=48900 Epoch=92.2] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.653 | L2-Norm(final)=12.314 | 4528.5 samples/s | 70.8 steps/s
[Step=48950 Epoch=92.3] | Loss=0.00000 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=12.314 | 4569.0 samples/s | 71.4 steps/s
[Step=49000 Epoch=92.4] | Loss=0.00000 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=12.314 | 4569.7 samples/s | 71.4 steps/s
[Step=49050 Epoch=92.5] | Loss=0.00000 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.631 | L2-Norm(final)=12.315 | 2106.5 samples/s | 32.9 steps/s
[Step=49100 Epoch=92.6] | Loss=0.00000 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=12.315 | 4666.7 samples/s | 72.9 steps/s
[Step=49150 Epoch=92.6] | Loss=0.00000 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=12.315 | 4568.1 samples/s | 71.4 steps/s
[Step=49200 Epoch=92.7] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=12.316 | 4547.4 samples/s | 71.1 steps/s
[Step=49250 Epoch=92.8] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=12.316 | 4643.5 samples/s | 72.6 steps/s
[Step=49300 Epoch=92.9] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=12.317 | 4604.8 samples/s | 72.0 steps/s
[Step=49350 Epoch=93.0] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=12.317 | 4527.0 samples/s | 70.7 steps/s
[Step=49400 Epoch=93.1] | Loss=0.00000 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.577 | L2-Norm(final)=12.317 | 4549.0 samples/s | 71.1 steps/s
[Step=49450 Epoch=93.2] | Loss=0.00000 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.569 | L2-Norm(final)=12.318 | 4538.9 samples/s | 70.9 steps/s
[Step=49500 Epoch=93.3] | Loss=0.00000 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=12.318 | 4535.8 samples/s | 70.9 steps/s
[Step=49550 Epoch=93.4] | Loss=0.00000 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.553 | L2-Norm(final)=12.318 | 5665.5 samples/s | 88.5 steps/s
[Step=49600 Epoch=93.5] | Loss=0.00000 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.545 | L2-Norm(final)=12.319 | 2008.2 samples/s | 31.4 steps/s
[Step=49650 Epoch=93.6] | Loss=0.00000 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.537 | L2-Norm(final)=12.319 | 4522.2 samples/s | 70.7 steps/s
[Step=49700 Epoch=93.7] | Loss=0.00000 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.528 | L2-Norm(final)=12.319 | 4490.7 samples/s | 70.2 steps/s
[Step=49750 Epoch=93.8] | Loss=0.00000 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=12.320 | 4556.1 samples/s | 71.2 steps/s
[Step=49800 Epoch=93.9] | Loss=0.00000 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.512 | L2-Norm(final)=12.320 | 4556.6 samples/s | 71.2 steps/s
[Step=49850 Epoch=94.0] | Loss=0.00000 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.503 | L2-Norm(final)=12.320 | 4566.6 samples/s | 71.4 steps/s
[Step=49900 Epoch=94.1] | Loss=0.00000 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.495 | L2-Norm(final)=12.321 | 4660.7 samples/s | 72.8 steps/s
[Step=49950 Epoch=94.2] | Loss=0.00000 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.486 | L2-Norm(final)=12.321 | 4660.9 samples/s | 72.8 steps/s
[Step=50000 Epoch=94.3] | Loss=0.00000 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.477 | L2-Norm(final)=12.321 | 4713.8 samples/s | 73.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06902 | acc=0.9725 | tpr=0.9781 | fpr=0.0396 | 4569.5 samples/s | 17.8 steps/s
Avg test loss: 0.07496, Avg test acc: 0.97087, Avg tpr: 0.97663, Avg fpr: 0.04179, total FA: 326

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.25553 | acc=0.2935 | tpr=0.0280 | fpr=0.1298 | 4575.3 samples/s | 17.9 steps/s
Avg test loss: 6.25116, Avg test acc: 0.29049, Avg tpr: 0.02774, Avg fpr: 0.13165, total FA: 1027

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.41157 | acc=0.1347 | tpr=0.4602 | fpr=0.8712 | 4558.2 samples/s | 17.8 steps/s
[Step= 100] | Loss=7.35053 | acc=0.1338 | tpr=0.4542 | fpr=0.8722 | 8302.9 samples/s | 32.4 steps/s
[Step= 150] | Loss=7.34509 | acc=0.1342 | tpr=0.4654 | fpr=0.8719 | 8757.2 samples/s | 34.2 steps/s
[Step= 200] | Loss=7.32923 | acc=0.1340 | tpr=0.4699 | fpr=0.8721 | 8277.0 samples/s | 32.3 steps/s
[Step= 250] | Loss=7.32873 | acc=0.1348 | tpr=0.4742 | fpr=0.8714 | 8360.9 samples/s | 32.7 steps/s
[Step= 300] | Loss=7.32484 | acc=0.1347 | tpr=0.4764 | fpr=0.8715 | 8394.0 samples/s | 32.8 steps/s
[Step= 350] | Loss=7.32044 | acc=0.1338 | tpr=0.4734 | fpr=0.8724 | 8659.2 samples/s | 33.8 steps/s
[Step= 400] | Loss=7.31956 | acc=0.1341 | tpr=0.4726 | fpr=0.8721 | 8595.6 samples/s | 33.6 steps/s
[Step= 450] | Loss=7.32315 | acc=0.1339 | tpr=0.4703 | fpr=0.8722 | 8368.4 samples/s | 32.7 steps/s
[Step= 500] | Loss=7.32384 | acc=0.1344 | tpr=0.4718 | fpr=0.8717 | 8405.0 samples/s | 32.8 steps/s
[Step= 550] | Loss=7.32356 | acc=0.1346 | tpr=0.4704 | fpr=0.8715 | 15659.4 samples/s | 61.2 steps/s
Avg test loss: 7.32530, Avg test acc: 0.13450, Avg tpr: 0.47029, Avg fpr: 0.87160, total FA: 121020

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.17546 | acc=0.9806 | tpr=0.9425 | fpr=0.0187 | 4713.5 samples/s | 18.4 steps/s
[Step= 100] | Loss=0.18830 | acc=0.9795 | tpr=0.9510 | fpr=0.0199 | 8286.7 samples/s | 32.4 steps/s
[Step= 150] | Loss=0.19423 | acc=0.9790 | tpr=0.9568 | fpr=0.0206 | 8565.8 samples/s | 33.5 steps/s
[Step= 200] | Loss=0.19703 | acc=0.9790 | tpr=0.9607 | fpr=0.0207 | 8630.4 samples/s | 33.7 steps/s
[Step= 250] | Loss=0.19546 | acc=0.9791 | tpr=0.9598 | fpr=0.0205 | 8606.8 samples/s | 33.6 steps/s
[Step= 300] | Loss=0.19868 | acc=0.9789 | tpr=0.9615 | fpr=0.0207 | 8331.2 samples/s | 32.5 steps/s
[Step= 350] | Loss=0.20067 | acc=0.9787 | tpr=0.9606 | fpr=0.0210 | 8618.1 samples/s | 33.7 steps/s
[Step= 400] | Loss=0.20167 | acc=0.9787 | tpr=0.9595 | fpr=0.0210 | 8371.1 samples/s | 32.7 steps/s
[Step= 450] | Loss=0.20577 | acc=0.9784 | tpr=0.9586 | fpr=0.0212 | 8390.9 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.20454 | acc=0.9784 | tpr=0.9581 | fpr=0.0212 | 8496.2 samples/s | 33.2 steps/s
[Step= 550] | Loss=0.20325 | acc=0.9785 | tpr=0.9566 | fpr=0.0211 | 14822.1 samples/s | 57.9 steps/s
Avg test loss: 0.20294, Avg test acc: 0.97855, Avg tpr: 0.95642, Avg fpr: 0.02105, total FA: 2923

server round 25/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=50001 Epoch=48.8] | Loss=0.01154 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.514 | L2-Norm(final)=11.383 | 3998.8 samples/s | 62.5 steps/s
[Step=50050 Epoch=48.9] | Loss=0.00650 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.386 | 5394.5 samples/s | 84.3 steps/s
[Step=50100 Epoch=48.9] | Loss=0.00738 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.391 | 5577.0 samples/s | 87.1 steps/s
[Step=50150 Epoch=49.0] | Loss=0.00743 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.515 | L2-Norm(final)=11.396 | 5352.3 samples/s | 83.6 steps/s
[Step=50200 Epoch=49.0] | Loss=0.00809 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.400 | 5553.8 samples/s | 86.8 steps/s
[Step=50250 Epoch=49.1] | Loss=0.00814 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.404 | 5454.8 samples/s | 85.2 steps/s
[Step=50300 Epoch=49.1] | Loss=0.00794 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.408 | 5719.9 samples/s | 89.4 steps/s
[Step=50350 Epoch=49.2] | Loss=0.00789 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.515 | L2-Norm(final)=11.412 | 5428.4 samples/s | 84.8 steps/s
[Step=50400 Epoch=49.2] | Loss=0.00824 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.416 | 5682.5 samples/s | 88.8 steps/s
[Step=50450 Epoch=49.3] | Loss=0.00849 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.421 | 5635.2 samples/s | 88.1 steps/s
[Step=50500 Epoch=49.3] | Loss=0.00831 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.515 | L2-Norm(final)=11.426 | 5704.5 samples/s | 89.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=49.3] | Loss=0.02993 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.515 | L2-Norm(final)=11.474 | 4255.9 samples/s | 66.5 steps/s
[Step=50550 Epoch=49.4] | Loss=0.00809 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.531 | L2-Norm(final)=11.475 | 4551.4 samples/s | 71.1 steps/s
[Step=50600 Epoch=49.4] | Loss=0.00783 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.541 | L2-Norm(final)=11.475 | 4740.7 samples/s | 74.1 steps/s
[Step=50650 Epoch=49.5] | Loss=0.00855 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.547 | L2-Norm(final)=11.475 | 4741.1 samples/s | 74.1 steps/s
[Step=50700 Epoch=49.5] | Loss=0.00833 | Reg=0.00212 | acc=0.9688 | L2-Norm=14.554 | L2-Norm(final)=11.475 | 4744.7 samples/s | 74.1 steps/s
[Step=50750 Epoch=49.5] | Loss=0.00852 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.559 | L2-Norm(final)=11.474 | 4811.7 samples/s | 75.2 steps/s
[Step=50800 Epoch=49.6] | Loss=0.00876 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.564 | L2-Norm(final)=11.473 | 4820.9 samples/s | 75.3 steps/s
[Step=50850 Epoch=49.6] | Loss=0.00947 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.568 | L2-Norm(final)=11.473 | 4844.1 samples/s | 75.7 steps/s
[Step=50900 Epoch=49.7] | Loss=0.00944 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.572 | L2-Norm(final)=11.472 | 4786.2 samples/s | 74.8 steps/s
[Step=50950 Epoch=49.7] | Loss=0.00957 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=11.471 | 4813.6 samples/s | 75.2 steps/s
[Step=51000 Epoch=49.8] | Loss=0.00974 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.579 | L2-Norm(final)=11.471 | 4804.0 samples/s | 75.1 steps/s
[Step=51050 Epoch=49.8] | Loss=0.00992 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.582 | L2-Norm(final)=11.470 | 4843.5 samples/s | 75.7 steps/s
[Step=51100 Epoch=49.9] | Loss=0.01010 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.585 | L2-Norm(final)=11.470 | 4737.9 samples/s | 74.0 steps/s
[Step=51150 Epoch=49.9] | Loss=0.01019 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.588 | L2-Norm(final)=11.469 | 4839.7 samples/s | 75.6 steps/s
[Step=51200 Epoch=50.0] | Loss=0.01005 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.591 | L2-Norm(final)=11.469 | 4870.8 samples/s | 76.1 steps/s
[Step=51250 Epoch=50.0] | Loss=0.01014 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.594 | L2-Norm(final)=11.469 | 4850.8 samples/s | 75.8 steps/s
[Step=51300 Epoch=50.1] | Loss=0.01009 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.597 | L2-Norm(final)=11.469 | 4796.1 samples/s | 74.9 steps/s
[Step=51350 Epoch=50.1] | Loss=0.01020 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.599 | L2-Norm(final)=11.469 | 4834.7 samples/s | 75.5 steps/s
[Step=51400 Epoch=50.2] | Loss=0.01023 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.602 | L2-Norm(final)=11.469 | 4850.3 samples/s | 75.8 steps/s
[Step=51450 Epoch=50.2] | Loss=0.01010 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.604 | L2-Norm(final)=11.469 | 4787.7 samples/s | 74.8 steps/s
[Step=51500 Epoch=50.3] | Loss=0.01020 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.607 | L2-Norm(final)=11.469 | 5158.4 samples/s | 80.6 steps/s
[Step=51550 Epoch=50.3] | Loss=0.01021 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=11.469 | 2164.7 samples/s | 33.8 steps/s
[Step=51600 Epoch=50.4] | Loss=0.01013 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.612 | L2-Norm(final)=11.470 | 4692.8 samples/s | 73.3 steps/s
[Step=51650 Epoch=50.4] | Loss=0.01014 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.614 | L2-Norm(final)=11.470 | 4727.9 samples/s | 73.9 steps/s
[Step=51700 Epoch=50.5] | Loss=0.01010 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.617 | L2-Norm(final)=11.470 | 4778.5 samples/s | 74.7 steps/s
[Step=51750 Epoch=50.5] | Loss=0.01009 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=11.470 | 4778.3 samples/s | 74.7 steps/s
[Step=51800 Epoch=50.6] | Loss=0.01003 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=11.470 | 4791.5 samples/s | 74.9 steps/s
[Step=51850 Epoch=50.6] | Loss=0.01003 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.623 | L2-Norm(final)=11.470 | 4881.1 samples/s | 76.3 steps/s
[Step=51900 Epoch=50.7] | Loss=0.01000 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.626 | L2-Norm(final)=11.471 | 4754.2 samples/s | 74.3 steps/s
[Step=51950 Epoch=50.7] | Loss=0.01003 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.628 | L2-Norm(final)=11.471 | 4771.1 samples/s | 74.5 steps/s
[Step=52000 Epoch=50.8] | Loss=0.00992 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.630 | L2-Norm(final)=11.471 | 4747.6 samples/s | 74.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step52000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=50001 Epoch=94.3] | Loss=0.00015 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.514 | L2-Norm(final)=12.332 | 4089.8 samples/s | 63.9 steps/s
[Step=50050 Epoch=94.3] | Loss=0.00008 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.338 | 5245.4 samples/s | 82.0 steps/s
[Step=50100 Epoch=94.4] | Loss=0.00018 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.344 | 5144.9 samples/s | 80.4 steps/s
[Step=50150 Epoch=94.5] | Loss=0.00014 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.349 | 5144.3 samples/s | 80.4 steps/s
[Step=50200 Epoch=94.6] | Loss=0.00012 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.353 | 5301.4 samples/s | 82.8 steps/s
[Step=50250 Epoch=94.7] | Loss=0.00012 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.356 | 5068.8 samples/s | 79.2 steps/s
[Step=50300 Epoch=94.8] | Loss=0.00011 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.511 | L2-Norm(final)=12.360 | 5265.5 samples/s | 82.3 steps/s
[Step=50350 Epoch=94.9] | Loss=0.00017 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=12.364 | 5131.3 samples/s | 80.2 steps/s
[Step=50400 Epoch=95.0] | Loss=0.00016 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=12.368 | 5176.1 samples/s | 80.9 steps/s
[Step=50450 Epoch=95.1] | Loss=0.00015 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=12.372 | 5222.5 samples/s | 81.6 steps/s
[Step=50500 Epoch=95.2] | Loss=0.00015 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=12.377 | 5262.6 samples/s | 82.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=95.2] | Loss=0.00013 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=12.419 | 4353.8 samples/s | 68.0 steps/s
[Step=50550 Epoch=95.3] | Loss=0.00004 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.506 | L2-Norm(final)=12.420 | 4207.8 samples/s | 65.7 steps/s
[Step=50600 Epoch=95.4] | Loss=0.00002 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.494 | L2-Norm(final)=12.421 | 4539.4 samples/s | 70.9 steps/s
[Step=50650 Epoch=95.5] | Loss=0.00002 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.480 | L2-Norm(final)=12.421 | 4529.5 samples/s | 70.8 steps/s
[Step=50700 Epoch=95.6] | Loss=0.00002 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.465 | L2-Norm(final)=12.422 | 4595.8 samples/s | 71.8 steps/s
[Step=50750 Epoch=95.7] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.451 | L2-Norm(final)=12.422 | 4533.3 samples/s | 70.8 steps/s
[Step=50800 Epoch=95.8] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.437 | L2-Norm(final)=12.422 | 4528.0 samples/s | 70.7 steps/s
[Step=50850 Epoch=95.9] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.422 | L2-Norm(final)=12.422 | 4557.1 samples/s | 71.2 steps/s
[Step=50900 Epoch=95.9] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.407 | L2-Norm(final)=12.422 | 4537.6 samples/s | 70.9 steps/s
[Step=50950 Epoch=96.0] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.392 | L2-Norm(final)=12.423 | 4589.1 samples/s | 71.7 steps/s
[Step=51000 Epoch=96.1] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.377 | L2-Norm(final)=12.423 | 4589.1 samples/s | 71.7 steps/s
[Step=51050 Epoch=96.2] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.361 | L2-Norm(final)=12.423 | 2078.0 samples/s | 32.5 steps/s
[Step=51100 Epoch=96.3] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.346 | L2-Norm(final)=12.423 | 4578.0 samples/s | 71.5 steps/s
[Step=51150 Epoch=96.4] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.330 | L2-Norm(final)=12.423 | 4526.2 samples/s | 70.7 steps/s
[Step=51200 Epoch=96.5] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.315 | L2-Norm(final)=12.423 | 4526.6 samples/s | 70.7 steps/s
[Step=51250 Epoch=96.6] | Loss=0.00000 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.299 | L2-Norm(final)=12.423 | 4451.4 samples/s | 69.6 steps/s
[Step=51300 Epoch=96.7] | Loss=0.00000 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.283 | L2-Norm(final)=12.423 | 4522.7 samples/s | 70.7 steps/s
[Step=51350 Epoch=96.8] | Loss=0.00000 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.267 | L2-Norm(final)=12.423 | 4507.6 samples/s | 70.4 steps/s
[Step=51400 Epoch=96.9] | Loss=0.00000 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.251 | L2-Norm(final)=12.423 | 4512.8 samples/s | 70.5 steps/s
[Step=51450 Epoch=97.0] | Loss=0.00000 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.235 | L2-Norm(final)=12.424 | 4584.5 samples/s | 71.6 steps/s
[Step=51500 Epoch=97.1] | Loss=0.00000 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.218 | L2-Norm(final)=12.424 | 4546.2 samples/s | 71.0 steps/s
[Step=51550 Epoch=97.2] | Loss=0.00000 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.202 | L2-Norm(final)=12.424 | 5738.8 samples/s | 89.7 steps/s
[Step=51600 Epoch=97.3] | Loss=0.00000 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.185 | L2-Norm(final)=12.424 | 1958.3 samples/s | 30.6 steps/s
[Step=51650 Epoch=97.4] | Loss=0.00000 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.168 | L2-Norm(final)=12.424 | 4603.8 samples/s | 71.9 steps/s
[Step=51700 Epoch=97.5] | Loss=0.00000 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.151 | L2-Norm(final)=12.424 | 4579.7 samples/s | 71.6 steps/s
[Step=51750 Epoch=97.5] | Loss=0.00000 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.134 | L2-Norm(final)=12.424 | 4402.7 samples/s | 68.8 steps/s
[Step=51800 Epoch=97.6] | Loss=0.00000 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.117 | L2-Norm(final)=12.424 | 4521.2 samples/s | 70.6 steps/s
[Step=51850 Epoch=97.7] | Loss=0.00000 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.100 | L2-Norm(final)=12.424 | 4536.0 samples/s | 70.9 steps/s
[Step=51900 Epoch=97.8] | Loss=0.00000 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.082 | L2-Norm(final)=12.424 | 4627.7 samples/s | 72.3 steps/s
[Step=51950 Epoch=97.9] | Loss=0.00000 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.065 | L2-Norm(final)=12.425 | 4453.7 samples/s | 69.6 steps/s
[Step=52000 Epoch=98.0] | Loss=0.00000 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.047 | L2-Norm(final)=12.425 | 4578.6 samples/s | 71.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06557 | acc=0.9738 | tpr=0.9812 | fpr=0.0424 | 4573.3 samples/s | 17.9 steps/s
Avg test loss: 0.07150, Avg test acc: 0.97267, Avg tpr: 0.98001, Avg fpr: 0.04346, total FA: 339

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.13390 | acc=0.2966 | tpr=0.0221 | fpr=0.1075 | 4623.2 samples/s | 18.1 steps/s
Avg test loss: 6.13058, Avg test acc: 0.29329, Avg tpr: 0.02145, Avg fpr: 0.10883, total FA: 849

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.43011 | acc=0.1275 | tpr=0.4469 | fpr=0.8782 | 4668.3 samples/s | 18.2 steps/s
[Step= 100] | Loss=7.37773 | acc=0.1276 | tpr=0.4350 | fpr=0.8781 | 8601.7 samples/s | 33.6 steps/s
[Step= 150] | Loss=7.37467 | acc=0.1282 | tpr=0.4366 | fpr=0.8775 | 8378.7 samples/s | 32.7 steps/s
[Step= 200] | Loss=7.35858 | acc=0.1284 | tpr=0.4317 | fpr=0.8771 | 8391.5 samples/s | 32.8 steps/s
[Step= 250] | Loss=7.35578 | acc=0.1288 | tpr=0.4349 | fpr=0.8767 | 8746.5 samples/s | 34.2 steps/s
[Step= 300] | Loss=7.35062 | acc=0.1288 | tpr=0.4378 | fpr=0.8768 | 8318.6 samples/s | 32.5 steps/s
[Step= 350] | Loss=7.34681 | acc=0.1285 | tpr=0.4396 | fpr=0.8771 | 8733.2 samples/s | 34.1 steps/s
[Step= 400] | Loss=7.34698 | acc=0.1287 | tpr=0.4409 | fpr=0.8770 | 8483.7 samples/s | 33.1 steps/s
[Step= 450] | Loss=7.35121 | acc=0.1286 | tpr=0.4377 | fpr=0.8770 | 8232.2 samples/s | 32.2 steps/s
[Step= 500] | Loss=7.35355 | acc=0.1288 | tpr=0.4379 | fpr=0.8768 | 8344.0 samples/s | 32.6 steps/s
[Step= 550] | Loss=7.35395 | acc=0.1291 | tpr=0.4393 | fpr=0.8765 | 15672.8 samples/s | 61.2 steps/s
Avg test loss: 7.35561, Avg test acc: 0.12894, Avg tpr: 0.43938, Avg fpr: 0.87671, total FA: 121729

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.17719 | acc=0.9810 | tpr=0.9469 | fpr=0.0184 | 4512.3 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.18949 | acc=0.9793 | tpr=0.9467 | fpr=0.0201 | 8908.2 samples/s | 34.8 steps/s
[Step= 150] | Loss=0.19650 | acc=0.9787 | tpr=0.9524 | fpr=0.0208 | 8153.8 samples/s | 31.9 steps/s
[Step= 200] | Loss=0.19820 | acc=0.9791 | tpr=0.9574 | fpr=0.0205 | 8361.4 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.19636 | acc=0.9794 | tpr=0.9563 | fpr=0.0202 | 8540.2 samples/s | 33.4 steps/s
[Step= 300] | Loss=0.19937 | acc=0.9792 | tpr=0.9556 | fpr=0.0203 | 8620.0 samples/s | 33.7 steps/s
[Step= 350] | Loss=0.20170 | acc=0.9790 | tpr=0.9549 | fpr=0.0206 | 8525.5 samples/s | 33.3 steps/s
[Step= 400] | Loss=0.20267 | acc=0.9789 | tpr=0.9546 | fpr=0.0206 | 8371.4 samples/s | 32.7 steps/s
[Step= 450] | Loss=0.20704 | acc=0.9786 | tpr=0.9537 | fpr=0.0209 | 8652.0 samples/s | 33.8 steps/s
[Step= 500] | Loss=0.20591 | acc=0.9786 | tpr=0.9537 | fpr=0.0209 | 8812.6 samples/s | 34.4 steps/s
[Step= 550] | Loss=0.20460 | acc=0.9787 | tpr=0.9522 | fpr=0.0208 | 15320.4 samples/s | 59.8 steps/s
Avg test loss: 0.20427, Avg test acc: 0.97872, Avg tpr: 0.95206, Avg fpr: 0.02079, total FA: 2887

server round 26/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=52001 Epoch=50.8] | Loss=0.01952 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.055 | L2-Norm(final)=11.481 | 4425.2 samples/s | 69.1 steps/s
[Step=52050 Epoch=50.8] | Loss=0.00760 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.486 | 5077.4 samples/s | 79.3 steps/s
[Step=52100 Epoch=50.9] | Loss=0.00834 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.492 | 5464.7 samples/s | 85.4 steps/s
[Step=52150 Epoch=50.9] | Loss=0.00863 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.056 | L2-Norm(final)=11.499 | 5523.0 samples/s | 86.3 steps/s
[Step=52200 Epoch=51.0] | Loss=0.00912 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.056 | L2-Norm(final)=11.505 | 5549.4 samples/s | 86.7 steps/s
[Step=52250 Epoch=51.0] | Loss=0.00895 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.511 | 5404.6 samples/s | 84.4 steps/s
[Step=52300 Epoch=51.1] | Loss=0.00915 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.516 | 5545.6 samples/s | 86.6 steps/s
[Step=52350 Epoch=51.1] | Loss=0.00926 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.056 | L2-Norm(final)=11.520 | 5499.7 samples/s | 85.9 steps/s
[Step=52400 Epoch=51.2] | Loss=0.00936 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.524 | 5584.4 samples/s | 87.3 steps/s
[Step=52450 Epoch=51.2] | Loss=0.00923 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.527 | 5486.2 samples/s | 85.7 steps/s
[Step=52500 Epoch=51.3] | Loss=0.00913 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.056 | L2-Norm(final)=11.531 | 5494.9 samples/s | 85.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=51.3] | Loss=0.00554 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.568 | 4217.4 samples/s | 65.9 steps/s
[Step=52550 Epoch=51.3] | Loss=0.01036 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.069 | L2-Norm(final)=11.571 | 4765.0 samples/s | 74.5 steps/s
[Step=52600 Epoch=51.4] | Loss=0.01009 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.080 | L2-Norm(final)=11.572 | 4814.7 samples/s | 75.2 steps/s
[Step=52650 Epoch=51.4] | Loss=0.01003 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.088 | L2-Norm(final)=11.572 | 4829.6 samples/s | 75.5 steps/s
[Step=52700 Epoch=51.5] | Loss=0.01035 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.095 | L2-Norm(final)=11.572 | 4815.8 samples/s | 75.2 steps/s
[Step=52750 Epoch=51.5] | Loss=0.01035 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.101 | L2-Norm(final)=11.572 | 4737.9 samples/s | 74.0 steps/s
[Step=52800 Epoch=51.6] | Loss=0.01025 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.107 | L2-Norm(final)=11.572 | 4809.9 samples/s | 75.2 steps/s
[Step=52850 Epoch=51.6] | Loss=0.01038 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.112 | L2-Norm(final)=11.573 | 4764.1 samples/s | 74.4 steps/s
[Step=52900 Epoch=51.6] | Loss=0.01024 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.117 | L2-Norm(final)=11.573 | 4814.0 samples/s | 75.2 steps/s
[Step=52950 Epoch=51.7] | Loss=0.01037 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.122 | L2-Norm(final)=11.574 | 4848.2 samples/s | 75.8 steps/s
[Step=53000 Epoch=51.7] | Loss=0.01046 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.126 | L2-Norm(final)=11.574 | 4869.9 samples/s | 76.1 steps/s
[Step=53050 Epoch=51.8] | Loss=0.01052 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.130 | L2-Norm(final)=11.575 | 4761.6 samples/s | 74.4 steps/s
[Step=53100 Epoch=51.8] | Loss=0.01039 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.134 | L2-Norm(final)=11.575 | 4809.0 samples/s | 75.1 steps/s
[Step=53150 Epoch=51.9] | Loss=0.01041 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.138 | L2-Norm(final)=11.576 | 4787.4 samples/s | 74.8 steps/s
[Step=53200 Epoch=51.9] | Loss=0.01033 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.141 | L2-Norm(final)=11.576 | 4812.6 samples/s | 75.2 steps/s
[Step=53250 Epoch=52.0] | Loss=0.01045 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.145 | L2-Norm(final)=11.577 | 4865.2 samples/s | 76.0 steps/s
[Step=53300 Epoch=52.0] | Loss=0.01050 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.148 | L2-Norm(final)=11.577 | 4797.8 samples/s | 75.0 steps/s
[Step=53350 Epoch=52.1] | Loss=0.01036 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.151 | L2-Norm(final)=11.578 | 4791.4 samples/s | 74.9 steps/s
[Step=53400 Epoch=52.1] | Loss=0.01029 | Reg=0.00200 | acc=0.9844 | L2-Norm=14.155 | L2-Norm(final)=11.579 | 4784.8 samples/s | 74.8 steps/s
[Step=53450 Epoch=52.2] | Loss=0.01025 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.158 | L2-Norm(final)=11.579 | 4779.8 samples/s | 74.7 steps/s
[Step=53500 Epoch=52.2] | Loss=0.01029 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.161 | L2-Norm(final)=11.580 | 5166.1 samples/s | 80.7 steps/s
[Step=53550 Epoch=52.3] | Loss=0.01029 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.164 | L2-Norm(final)=11.581 | 2117.0 samples/s | 33.1 steps/s
[Step=53600 Epoch=52.3] | Loss=0.01023 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=11.582 | 4802.4 samples/s | 75.0 steps/s
[Step=53650 Epoch=52.4] | Loss=0.01023 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.170 | L2-Norm(final)=11.583 | 4778.5 samples/s | 74.7 steps/s
[Step=53700 Epoch=52.4] | Loss=0.01027 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.172 | L2-Norm(final)=11.583 | 4858.7 samples/s | 75.9 steps/s
[Step=53750 Epoch=52.5] | Loss=0.01012 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.176 | L2-Norm(final)=11.584 | 4825.2 samples/s | 75.4 steps/s
[Step=53800 Epoch=52.5] | Loss=0.01007 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.178 | L2-Norm(final)=11.585 | 4766.5 samples/s | 74.5 steps/s
[Step=53850 Epoch=52.6] | Loss=0.00998 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.181 | L2-Norm(final)=11.585 | 4757.8 samples/s | 74.3 steps/s
[Step=53900 Epoch=52.6] | Loss=0.00989 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.184 | L2-Norm(final)=11.586 | 4798.6 samples/s | 75.0 steps/s
[Step=53950 Epoch=52.7] | Loss=0.00990 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.187 | L2-Norm(final)=11.587 | 4804.1 samples/s | 75.1 steps/s
[Step=54000 Epoch=52.7] | Loss=0.00991 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.190 | L2-Norm(final)=11.587 | 4879.3 samples/s | 76.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step54000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=52001 Epoch=98.0] | Loss=0.00015 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.055 | L2-Norm(final)=12.428 | 4088.1 samples/s | 63.9 steps/s
[Step=52050 Epoch=98.1] | Loss=0.00015 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.049 | L2-Norm(final)=12.433 | 5077.6 samples/s | 79.3 steps/s
[Step=52100 Epoch=98.2] | Loss=0.00023 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.442 | 5044.5 samples/s | 78.8 steps/s
[Step=52150 Epoch=98.3] | Loss=0.00022 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.450 | 5366.6 samples/s | 83.9 steps/s
[Step=52200 Epoch=98.4] | Loss=0.00019 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.458 | 5146.4 samples/s | 80.4 steps/s
[Step=52250 Epoch=98.5] | Loss=0.00017 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.464 | 5059.4 samples/s | 79.1 steps/s
[Step=52300 Epoch=98.6] | Loss=0.00018 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.470 | 5225.7 samples/s | 81.7 steps/s
[Step=52350 Epoch=98.7] | Loss=0.00018 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.476 | 5176.4 samples/s | 80.9 steps/s
[Step=52400 Epoch=98.8] | Loss=0.00027 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.482 | 5213.1 samples/s | 81.5 steps/s
[Step=52450 Epoch=98.9] | Loss=0.00026 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.488 | 5255.7 samples/s | 82.1 steps/s
[Step=52500 Epoch=99.0] | Loss=0.00025 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=12.494 | 5337.6 samples/s | 83.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=99.0] | Loss=0.00025 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.047 | L2-Norm(final)=12.552 | 4111.6 samples/s | 64.2 steps/s
[Step=52550 Epoch=99.1] | Loss=0.00343 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.049 | L2-Norm(final)=12.551 | 4321.5 samples/s | 67.5 steps/s
[Step=52600 Epoch=99.2] | Loss=0.00197 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.079 | L2-Norm(final)=12.545 | 4561.8 samples/s | 71.3 steps/s
[Step=52650 Epoch=99.2] | Loss=0.00237 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.093 | L2-Norm(final)=12.542 | 4514.0 samples/s | 70.5 steps/s
[Step=52700 Epoch=99.3] | Loss=0.00214 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.106 | L2-Norm(final)=12.539 | 4665.3 samples/s | 72.9 steps/s
[Step=52750 Epoch=99.4] | Loss=0.00184 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.114 | L2-Norm(final)=12.537 | 4605.1 samples/s | 72.0 steps/s
[Step=52800 Epoch=99.5] | Loss=0.00153 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.120 | L2-Norm(final)=12.535 | 4577.1 samples/s | 71.5 steps/s
[Step=52850 Epoch=99.6] | Loss=0.00132 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.123 | L2-Norm(final)=12.534 | 4531.9 samples/s | 70.8 steps/s
[Step=52900 Epoch=99.7] | Loss=0.00115 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=12.533 | 4527.8 samples/s | 70.7 steps/s
[Step=52950 Epoch=99.8] | Loss=0.00102 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=12.532 | 4533.9 samples/s | 70.8 steps/s
[Step=53000 Epoch=99.9] | Loss=0.00092 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.125 | L2-Norm(final)=12.531 | 4672.4 samples/s | 73.0 steps/s
[Step=53050 Epoch=100.0] | Loss=0.00084 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.124 | L2-Norm(final)=12.531 | 2164.7 samples/s | 33.8 steps/s
[Step=53100 Epoch=100.1] | Loss=0.00078 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.123 | L2-Norm(final)=12.531 | 4723.2 samples/s | 73.8 steps/s
[Step=53150 Epoch=100.2] | Loss=0.00072 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.121 | L2-Norm(final)=12.530 | 4674.9 samples/s | 73.0 steps/s
[Step=53200 Epoch=100.3] | Loss=0.00067 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.120 | L2-Norm(final)=12.530 | 4714.3 samples/s | 73.7 steps/s
[Step=53250 Epoch=100.4] | Loss=0.00062 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.118 | L2-Norm(final)=12.530 | 4623.3 samples/s | 72.2 steps/s
[Step=53300 Epoch=100.5] | Loss=0.00059 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.116 | L2-Norm(final)=12.530 | 4671.7 samples/s | 73.0 steps/s
[Step=53350 Epoch=100.6] | Loss=0.00055 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.114 | L2-Norm(final)=12.530 | 4565.7 samples/s | 71.3 steps/s
[Step=53400 Epoch=100.7] | Loss=0.00052 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.112 | L2-Norm(final)=12.531 | 4465.2 samples/s | 69.8 steps/s
[Step=53450 Epoch=100.8] | Loss=0.00049 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.109 | L2-Norm(final)=12.531 | 4577.5 samples/s | 71.5 steps/s
[Step=53500 Epoch=100.8] | Loss=0.00047 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.107 | L2-Norm(final)=12.531 | 4592.1 samples/s | 71.8 steps/s
[Step=53550 Epoch=100.9] | Loss=0.00045 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.104 | L2-Norm(final)=12.532 | 5626.0 samples/s | 87.9 steps/s
[Step=53600 Epoch=101.0] | Loss=0.00043 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.102 | L2-Norm(final)=12.532 | 1989.1 samples/s | 31.1 steps/s
[Step=53650 Epoch=101.1] | Loss=0.00041 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.099 | L2-Norm(final)=12.532 | 4470.4 samples/s | 69.9 steps/s
[Step=53700 Epoch=101.2] | Loss=0.00039 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.096 | L2-Norm(final)=12.533 | 4571.9 samples/s | 71.4 steps/s
[Step=53750 Epoch=101.3] | Loss=0.00038 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.093 | L2-Norm(final)=12.533 | 4545.0 samples/s | 71.0 steps/s
[Step=53800 Epoch=101.4] | Loss=0.00036 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.090 | L2-Norm(final)=12.533 | 4530.7 samples/s | 70.8 steps/s
[Step=53850 Epoch=101.5] | Loss=0.00035 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.087 | L2-Norm(final)=12.533 | 4535.5 samples/s | 70.9 steps/s
[Step=53900 Epoch=101.6] | Loss=0.00034 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.084 | L2-Norm(final)=12.534 | 4539.5 samples/s | 70.9 steps/s
[Step=53950 Epoch=101.7] | Loss=0.00032 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.081 | L2-Norm(final)=12.534 | 4538.1 samples/s | 70.9 steps/s
[Step=54000 Epoch=101.8] | Loss=0.00031 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.078 | L2-Norm(final)=12.534 | 4509.0 samples/s | 70.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06324 | acc=0.9728 | tpr=0.9783 | fpr=0.0391 | 4559.9 samples/s | 17.8 steps/s
Avg test loss: 0.06931, Avg test acc: 0.97175, Avg tpr: 0.97709, Avg fpr: 0.03999, total FA: 312

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=8.73609 | acc=0.3016 | tpr=0.0132 | fpr=0.0723 | 4576.9 samples/s | 17.9 steps/s
Avg test loss: 8.74597, Avg test acc: 0.29914, Avg tpr: 0.01300, Avg fpr: 0.07153, total FA: 558

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.04925 | acc=0.1492 | tpr=0.4779 | fpr=0.8567 | 4518.2 samples/s | 17.6 steps/s
[Step= 100] | Loss=6.00549 | acc=0.1494 | tpr=0.4542 | fpr=0.8563 | 8621.1 samples/s | 33.7 steps/s
[Step= 150] | Loss=6.00348 | acc=0.1507 | tpr=0.4582 | fpr=0.8550 | 8525.8 samples/s | 33.3 steps/s
[Step= 200] | Loss=5.99455 | acc=0.1507 | tpr=0.4525 | fpr=0.8548 | 8682.4 samples/s | 33.9 steps/s
[Step= 250] | Loss=5.99212 | acc=0.1514 | tpr=0.4576 | fpr=0.8541 | 8442.1 samples/s | 33.0 steps/s
[Step= 300] | Loss=5.98716 | acc=0.1511 | tpr=0.4604 | fpr=0.8546 | 8661.5 samples/s | 33.8 steps/s
[Step= 350] | Loss=5.98337 | acc=0.1508 | tpr=0.4615 | fpr=0.8549 | 8473.9 samples/s | 33.1 steps/s
[Step= 400] | Loss=5.98329 | acc=0.1509 | tpr=0.4650 | fpr=0.8548 | 8583.6 samples/s | 33.5 steps/s
[Step= 450] | Loss=5.98656 | acc=0.1510 | tpr=0.4630 | fpr=0.8547 | 8427.1 samples/s | 32.9 steps/s
[Step= 500] | Loss=5.98926 | acc=0.1511 | tpr=0.4630 | fpr=0.8545 | 8552.8 samples/s | 33.4 steps/s
[Step= 550] | Loss=5.98967 | acc=0.1514 | tpr=0.4620 | fpr=0.8542 | 15853.3 samples/s | 61.9 steps/s
Avg test loss: 5.99108, Avg test acc: 0.15127, Avg tpr: 0.46197, Avg fpr: 0.85437, total FA: 118628

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.19853 | acc=0.9809 | tpr=0.9513 | fpr=0.0186 | 4610.4 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.21283 | acc=0.9801 | tpr=0.9531 | fpr=0.0194 | 8783.3 samples/s | 34.3 steps/s
[Step= 150] | Loss=0.21908 | acc=0.9793 | tpr=0.9553 | fpr=0.0202 | 8105.7 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.22104 | acc=0.9796 | tpr=0.9607 | fpr=0.0201 | 8604.2 samples/s | 33.6 steps/s
[Step= 250] | Loss=0.21828 | acc=0.9797 | tpr=0.9555 | fpr=0.0198 | 8595.7 samples/s | 33.6 steps/s
[Step= 300] | Loss=0.22169 | acc=0.9796 | tpr=0.9564 | fpr=0.0200 | 8435.2 samples/s | 32.9 steps/s
[Step= 350] | Loss=0.22529 | acc=0.9793 | tpr=0.9568 | fpr=0.0202 | 8389.2 samples/s | 32.8 steps/s
[Step= 400] | Loss=0.22682 | acc=0.9793 | tpr=0.9562 | fpr=0.0203 | 8860.3 samples/s | 34.6 steps/s
[Step= 450] | Loss=0.23254 | acc=0.9790 | tpr=0.9537 | fpr=0.0205 | 8059.8 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.23124 | acc=0.9791 | tpr=0.9542 | fpr=0.0204 | 8452.9 samples/s | 33.0 steps/s
[Step= 550] | Loss=0.23012 | acc=0.9792 | tpr=0.9530 | fpr=0.0203 | 15387.4 samples/s | 60.1 steps/s
Avg test loss: 0.22967, Avg test acc: 0.97920, Avg tpr: 0.95246, Avg fpr: 0.02031, total FA: 2820

server round 27/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=54001 Epoch=52.7] | Loss=0.00324 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.063 | L2-Norm(final)=11.607 | 4429.1 samples/s | 69.2 steps/s
[Step=54050 Epoch=52.8] | Loss=0.02126 | Reg=0.00198 | acc=0.9531 | L2-Norm=14.063 | L2-Norm(final)=11.613 | 5384.1 samples/s | 84.1 steps/s
[Step=54100 Epoch=52.8] | Loss=0.02116 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.064 | L2-Norm(final)=11.623 | 5713.5 samples/s | 89.3 steps/s
[Step=54150 Epoch=52.9] | Loss=0.02021 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.064 | L2-Norm(final)=11.635 | 5505.3 samples/s | 86.0 steps/s
[Step=54200 Epoch=52.9] | Loss=0.01877 | Reg=0.00198 | acc=0.9531 | L2-Norm=14.064 | L2-Norm(final)=11.646 | 5616.7 samples/s | 87.8 steps/s
[Step=54250 Epoch=53.0] | Loss=0.01822 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=11.655 | 5780.3 samples/s | 90.3 steps/s
[Step=54300 Epoch=53.0] | Loss=0.01767 | Reg=0.00198 | acc=0.9688 | L2-Norm=14.064 | L2-Norm(final)=11.664 | 5573.6 samples/s | 87.1 steps/s
[Step=54350 Epoch=53.1] | Loss=0.01733 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=11.672 | 5671.7 samples/s | 88.6 steps/s
[Step=54400 Epoch=53.1] | Loss=0.01714 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.064 | L2-Norm(final)=11.680 | 5614.0 samples/s | 87.7 steps/s
[Step=54450 Epoch=53.2] | Loss=0.01678 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=11.687 | 5657.4 samples/s | 88.4 steps/s
[Step=54500 Epoch=53.2] | Loss=0.01654 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.064 | L2-Norm(final)=11.694 | 5696.1 samples/s | 89.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=53.2] | Loss=0.00225 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.064 | L2-Norm(final)=11.762 | 4515.3 samples/s | 70.6 steps/s
[Step=54550 Epoch=53.3] | Loss=0.01466 | Reg=0.00198 | acc=0.9844 | L2-Norm=14.083 | L2-Norm(final)=11.766 | 4573.3 samples/s | 71.5 steps/s
[Step=54600 Epoch=53.3] | Loss=0.01187 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.097 | L2-Norm(final)=11.766 | 4888.3 samples/s | 76.4 steps/s
[Step=54650 Epoch=53.4] | Loss=0.01108 | Reg=0.00199 | acc=0.9844 | L2-Norm=14.106 | L2-Norm(final)=11.766 | 4892.4 samples/s | 76.4 steps/s
[Step=54700 Epoch=53.4] | Loss=0.01120 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.113 | L2-Norm(final)=11.767 | 4929.8 samples/s | 77.0 steps/s
[Step=54750 Epoch=53.5] | Loss=0.01061 | Reg=0.00199 | acc=0.9688 | L2-Norm=14.120 | L2-Norm(final)=11.767 | 4871.4 samples/s | 76.1 steps/s
[Step=54800 Epoch=53.5] | Loss=0.01082 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.126 | L2-Norm(final)=11.767 | 4941.2 samples/s | 77.2 steps/s
[Step=54850 Epoch=53.6] | Loss=0.01037 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.131 | L2-Norm(final)=11.768 | 4908.3 samples/s | 76.7 steps/s
[Step=54900 Epoch=53.6] | Loss=0.01084 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.136 | L2-Norm(final)=11.768 | 4805.9 samples/s | 75.1 steps/s
[Step=54950 Epoch=53.6] | Loss=0.01101 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.141 | L2-Norm(final)=11.768 | 4814.9 samples/s | 75.2 steps/s
[Step=55000 Epoch=53.7] | Loss=0.01083 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.145 | L2-Norm(final)=11.768 | 4764.3 samples/s | 74.4 steps/s
[Step=55050 Epoch=53.7] | Loss=0.01063 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.149 | L2-Norm(final)=11.768 | 4823.3 samples/s | 75.4 steps/s
[Step=55100 Epoch=53.8] | Loss=0.01062 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.153 | L2-Norm(final)=11.768 | 4763.4 samples/s | 74.4 steps/s
[Step=55150 Epoch=53.8] | Loss=0.01072 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.157 | L2-Norm(final)=11.768 | 4798.2 samples/s | 75.0 steps/s
[Step=55200 Epoch=53.9] | Loss=0.01073 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.161 | L2-Norm(final)=11.769 | 4837.4 samples/s | 75.6 steps/s
[Step=55250 Epoch=53.9] | Loss=0.01064 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.164 | L2-Norm(final)=11.769 | 4820.1 samples/s | 75.3 steps/s
[Step=55300 Epoch=54.0] | Loss=0.01059 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=11.769 | 4725.9 samples/s | 73.8 steps/s
[Step=55350 Epoch=54.0] | Loss=0.01070 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.171 | L2-Norm(final)=11.770 | 4811.5 samples/s | 75.2 steps/s
[Step=55400 Epoch=54.1] | Loss=0.01066 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.174 | L2-Norm(final)=11.770 | 4801.7 samples/s | 75.0 steps/s
[Step=55450 Epoch=54.1] | Loss=0.01087 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.177 | L2-Norm(final)=11.771 | 4768.1 samples/s | 74.5 steps/s
[Step=55500 Epoch=54.2] | Loss=0.01077 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.180 | L2-Norm(final)=11.771 | 5189.0 samples/s | 81.1 steps/s
[Step=55550 Epoch=54.2] | Loss=0.01069 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.183 | L2-Norm(final)=11.772 | 2111.2 samples/s | 33.0 steps/s
[Step=55600 Epoch=54.3] | Loss=0.01052 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.186 | L2-Norm(final)=11.772 | 4875.4 samples/s | 76.2 steps/s
[Step=55650 Epoch=54.3] | Loss=0.01037 | Reg=0.00201 | acc=0.9844 | L2-Norm=14.189 | L2-Norm(final)=11.773 | 4868.7 samples/s | 76.1 steps/s
[Step=55700 Epoch=54.4] | Loss=0.01030 | Reg=0.00201 | acc=0.9688 | L2-Norm=14.191 | L2-Norm(final)=11.773 | 4892.2 samples/s | 76.4 steps/s
[Step=55750 Epoch=54.4] | Loss=0.01023 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.194 | L2-Norm(final)=11.774 | 4888.8 samples/s | 76.4 steps/s
[Step=55800 Epoch=54.5] | Loss=0.01015 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.196 | L2-Norm(final)=11.775 | 4860.3 samples/s | 75.9 steps/s
[Step=55850 Epoch=54.5] | Loss=0.01008 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.199 | L2-Norm(final)=11.775 | 4807.1 samples/s | 75.1 steps/s
[Step=55900 Epoch=54.6] | Loss=0.01001 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.201 | L2-Norm(final)=11.776 | 4870.9 samples/s | 76.1 steps/s
[Step=55950 Epoch=54.6] | Loss=0.01004 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.203 | L2-Norm(final)=11.776 | 4762.3 samples/s | 74.4 steps/s
[Step=56000 Epoch=54.7] | Loss=0.01001 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=11.777 | 4789.6 samples/s | 74.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step56000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=54001 Epoch=101.8] | Loss=0.00011 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.063 | L2-Norm(final)=12.542 | 4344.6 samples/s | 67.9 steps/s
[Step=54050 Epoch=101.9] | Loss=0.00002 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=12.542 | 4547.1 samples/s | 71.0 steps/s
[Step=54100 Epoch=102.0] | Loss=0.00003 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5135.5 samples/s | 80.2 steps/s
[Step=54150 Epoch=102.1] | Loss=0.00004 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5146.4 samples/s | 80.4 steps/s
[Step=54200 Epoch=102.2] | Loss=0.00004 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5177.9 samples/s | 80.9 steps/s
[Step=54250 Epoch=102.3] | Loss=0.00006 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5183.0 samples/s | 81.0 steps/s
[Step=54300 Epoch=102.4] | Loss=0.00009 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5177.8 samples/s | 80.9 steps/s
[Step=54350 Epoch=102.5] | Loss=0.00008 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.542 | 5224.1 samples/s | 81.6 steps/s
[Step=54400 Epoch=102.5] | Loss=0.00007 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.543 | 5188.4 samples/s | 81.1 steps/s
[Step=54450 Epoch=102.6] | Loss=0.00007 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.543 | 5227.4 samples/s | 81.7 steps/s
[Step=54500 Epoch=102.7] | Loss=0.00006 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.543 | 5110.0 samples/s | 79.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=102.7] | Loss=0.00012 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.061 | L2-Norm(final)=12.546 | 4299.8 samples/s | 67.2 steps/s
[Step=54550 Epoch=102.8] | Loss=0.00007 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=12.547 | 4333.3 samples/s | 67.7 steps/s
[Step=54600 Epoch=102.9] | Loss=0.00004 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.051 | L2-Norm(final)=12.547 | 4500.7 samples/s | 70.3 steps/s
[Step=54650 Epoch=103.0] | Loss=0.00003 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.046 | L2-Norm(final)=12.548 | 4486.4 samples/s | 70.1 steps/s
[Step=54700 Epoch=103.1] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.041 | L2-Norm(final)=12.548 | 4569.7 samples/s | 71.4 steps/s
[Step=54750 Epoch=103.2] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.035 | L2-Norm(final)=12.549 | 4516.6 samples/s | 70.6 steps/s
[Step=54800 Epoch=103.3] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.029 | L2-Norm(final)=12.549 | 4540.3 samples/s | 70.9 steps/s
[Step=54850 Epoch=103.4] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.024 | L2-Norm(final)=12.550 | 4491.5 samples/s | 70.2 steps/s
[Step=54900 Epoch=103.5] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.018 | L2-Norm(final)=12.551 | 4603.3 samples/s | 71.9 steps/s
[Step=54950 Epoch=103.6] | Loss=0.00002 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.013 | L2-Norm(final)=12.551 | 4463.6 samples/s | 69.7 steps/s
[Step=55000 Epoch=103.7] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.009 | L2-Norm(final)=12.551 | 4600.0 samples/s | 71.9 steps/s
[Step=55050 Epoch=103.8] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.004 | L2-Norm(final)=12.552 | 2136.9 samples/s | 33.4 steps/s
[Step=55100 Epoch=103.9] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.999 | L2-Norm(final)=12.552 | 4559.5 samples/s | 71.2 steps/s
[Step=55150 Epoch=104.0] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.993 | L2-Norm(final)=12.552 | 4463.3 samples/s | 69.7 steps/s
[Step=55200 Epoch=104.1] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.988 | L2-Norm(final)=12.553 | 4530.9 samples/s | 70.8 steps/s
[Step=55250 Epoch=104.1] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.982 | L2-Norm(final)=12.553 | 4481.0 samples/s | 70.0 steps/s
[Step=55300 Epoch=104.2] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.976 | L2-Norm(final)=12.554 | 4530.9 samples/s | 70.8 steps/s
[Step=55350 Epoch=104.3] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.970 | L2-Norm(final)=12.554 | 4556.7 samples/s | 71.2 steps/s
[Step=55400 Epoch=104.4] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.964 | L2-Norm(final)=12.554 | 4560.9 samples/s | 71.3 steps/s
[Step=55450 Epoch=104.5] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=12.555 | 4612.6 samples/s | 72.1 steps/s
[Step=55500 Epoch=104.6] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.952 | L2-Norm(final)=12.555 | 4504.9 samples/s | 70.4 steps/s
[Step=55550 Epoch=104.7] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.946 | L2-Norm(final)=12.556 | 5843.0 samples/s | 91.3 steps/s
[Step=55600 Epoch=104.8] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.940 | L2-Norm(final)=12.557 | 1971.6 samples/s | 30.8 steps/s
[Step=55650 Epoch=104.9] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.933 | L2-Norm(final)=12.557 | 4622.6 samples/s | 72.2 steps/s
[Step=55700 Epoch=105.0] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.927 | L2-Norm(final)=12.558 | 4460.4 samples/s | 69.7 steps/s
[Step=55750 Epoch=105.1] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.921 | L2-Norm(final)=12.558 | 4549.9 samples/s | 71.1 steps/s
[Step=55800 Epoch=105.2] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.914 | L2-Norm(final)=12.559 | 4614.4 samples/s | 72.1 steps/s
[Step=55850 Epoch=105.3] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.907 | L2-Norm(final)=12.559 | 4524.6 samples/s | 70.7 steps/s
[Step=55900 Epoch=105.4] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.901 | L2-Norm(final)=12.560 | 4514.8 samples/s | 70.5 steps/s
[Step=55950 Epoch=105.5] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.894 | L2-Norm(final)=12.560 | 4553.9 samples/s | 71.2 steps/s
[Step=56000 Epoch=105.6] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.887 | L2-Norm(final)=12.561 | 4512.8 samples/s | 70.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06764 | acc=0.9721 | tpr=0.9815 | fpr=0.0483 | 4514.6 samples/s | 17.6 steps/s
Avg test loss: 0.07445, Avg test acc: 0.97071, Avg tpr: 0.98030, Avg fpr: 0.05038, total FA: 393

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.54807 | acc=0.2927 | tpr=0.0199 | fpr=0.1150 | 4516.5 samples/s | 17.6 steps/s
Avg test loss: 6.53716, Avg test acc: 0.28977, Avg tpr: 0.01859, Avg fpr: 0.11383, total FA: 888

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.03074 | acc=0.1217 | tpr=0.4558 | fpr=0.8843 | 4533.2 samples/s | 17.7 steps/s
[Step= 100] | Loss=6.98512 | acc=0.1199 | tpr=0.4392 | fpr=0.8860 | 8343.6 samples/s | 32.6 steps/s
[Step= 150] | Loss=6.98642 | acc=0.1191 | tpr=0.4582 | fpr=0.8872 | 8472.1 samples/s | 33.1 steps/s
[Step= 200] | Loss=6.97450 | acc=0.1196 | tpr=0.4557 | fpr=0.8865 | 8548.6 samples/s | 33.4 steps/s
[Step= 250] | Loss=6.97077 | acc=0.1201 | tpr=0.4620 | fpr=0.8861 | 8631.2 samples/s | 33.7 steps/s
[Step= 300] | Loss=6.96725 | acc=0.1198 | tpr=0.4669 | fpr=0.8865 | 8373.8 samples/s | 32.7 steps/s
[Step= 350] | Loss=6.96337 | acc=0.1193 | tpr=0.4640 | fpr=0.8869 | 8542.7 samples/s | 33.4 steps/s
[Step= 400] | Loss=6.96396 | acc=0.1196 | tpr=0.4639 | fpr=0.8866 | 8859.0 samples/s | 34.6 steps/s
[Step= 450] | Loss=6.96473 | acc=0.1195 | tpr=0.4611 | fpr=0.8867 | 8455.1 samples/s | 33.0 steps/s
[Step= 500] | Loss=6.96915 | acc=0.1199 | tpr=0.4604 | fpr=0.8863 | 9238.9 samples/s | 36.1 steps/s
[Step= 550] | Loss=6.96897 | acc=0.1203 | tpr=0.4596 | fpr=0.8859 | 13531.9 samples/s | 52.9 steps/s
Avg test loss: 6.96989, Avg test acc: 0.12009, Avg tpr: 0.45919, Avg fpr: 0.88607, total FA: 123029

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14984 | acc=0.9827 | tpr=0.9425 | fpr=0.0166 | 4594.8 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.16021 | acc=0.9816 | tpr=0.9510 | fpr=0.0178 | 8490.2 samples/s | 33.2 steps/s
[Step= 150] | Loss=0.16556 | acc=0.9810 | tpr=0.9553 | fpr=0.0185 | 8159.9 samples/s | 31.9 steps/s
[Step= 200] | Loss=0.16639 | acc=0.9811 | tpr=0.9607 | fpr=0.0185 | 8549.8 samples/s | 33.4 steps/s
[Step= 250] | Loss=0.16470 | acc=0.9812 | tpr=0.9581 | fpr=0.0183 | 8438.1 samples/s | 33.0 steps/s
[Step= 300] | Loss=0.16663 | acc=0.9810 | tpr=0.9593 | fpr=0.0186 | 8381.7 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.16881 | acc=0.9808 | tpr=0.9580 | fpr=0.0187 | 8550.0 samples/s | 33.4 steps/s
[Step= 400] | Loss=0.16997 | acc=0.9808 | tpr=0.9557 | fpr=0.0188 | 8749.6 samples/s | 34.2 steps/s
[Step= 450] | Loss=0.17434 | acc=0.9804 | tpr=0.9537 | fpr=0.0192 | 8468.8 samples/s | 33.1 steps/s
[Step= 500] | Loss=0.17340 | acc=0.9804 | tpr=0.9533 | fpr=0.0191 | 8266.7 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.17229 | acc=0.9806 | tpr=0.9522 | fpr=0.0189 | 15577.8 samples/s | 60.9 steps/s
Avg test loss: 0.17202, Avg test acc: 0.98062, Avg tpr: 0.95206, Avg fpr: 0.01886, total FA: 2619

server round 28/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=56001 Epoch=54.7] | Loss=0.01257 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.940 | L2-Norm(final)=11.795 | 4146.6 samples/s | 64.8 steps/s
[Step=56050 Epoch=54.7] | Loss=0.01048 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.940 | L2-Norm(final)=11.803 | 5433.5 samples/s | 84.9 steps/s
[Step=56100 Epoch=54.8] | Loss=0.01067 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.940 | L2-Norm(final)=11.813 | 5473.1 samples/s | 85.5 steps/s
[Step=56150 Epoch=54.8] | Loss=0.01069 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.820 | 5509.3 samples/s | 86.1 steps/s
[Step=56200 Epoch=54.9] | Loss=0.01010 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.825 | 5460.5 samples/s | 85.3 steps/s
[Step=56250 Epoch=54.9] | Loss=0.00985 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.830 | 5428.5 samples/s | 84.8 steps/s
[Step=56300 Epoch=55.0] | Loss=0.00967 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.834 | 5521.6 samples/s | 86.3 steps/s
[Step=56350 Epoch=55.0] | Loss=0.00964 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.838 | 5698.7 samples/s | 89.0 steps/s
[Step=56400 Epoch=55.1] | Loss=0.00949 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.941 | L2-Norm(final)=11.843 | 5578.4 samples/s | 87.2 steps/s
[Step=56450 Epoch=55.1] | Loss=0.00945 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.941 | L2-Norm(final)=11.847 | 5657.0 samples/s | 88.4 steps/s
[Step=56500 Epoch=55.2] | Loss=0.00928 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.941 | L2-Norm(final)=11.852 | 5481.5 samples/s | 85.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=55.2] | Loss=0.01534 | Reg=0.00194 | acc=0.9844 | L2-Norm=13.941 | L2-Norm(final)=11.894 | 4451.3 samples/s | 69.6 steps/s
[Step=56550 Epoch=55.2] | Loss=0.00978 | Reg=0.00195 | acc=0.9844 | L2-Norm=13.950 | L2-Norm(final)=11.894 | 4427.6 samples/s | 69.2 steps/s
[Step=56600 Epoch=55.3] | Loss=0.00952 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.960 | L2-Norm(final)=11.894 | 4886.6 samples/s | 76.4 steps/s
[Step=56650 Epoch=55.3] | Loss=0.00960 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.969 | L2-Norm(final)=11.893 | 4884.7 samples/s | 76.3 steps/s
[Step=56700 Epoch=55.4] | Loss=0.00957 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.975 | L2-Norm(final)=11.893 | 4850.2 samples/s | 75.8 steps/s
[Step=56750 Epoch=55.4] | Loss=0.00913 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.981 | L2-Norm(final)=11.893 | 4805.5 samples/s | 75.1 steps/s
[Step=56800 Epoch=55.5] | Loss=0.00913 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.985 | L2-Norm(final)=11.893 | 4778.1 samples/s | 74.7 steps/s
[Step=56850 Epoch=55.5] | Loss=0.00927 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.990 | L2-Norm(final)=11.894 | 4767.4 samples/s | 74.5 steps/s
[Step=56900 Epoch=55.6] | Loss=0.00942 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.994 | L2-Norm(final)=11.894 | 4802.4 samples/s | 75.0 steps/s
[Step=56950 Epoch=55.6] | Loss=0.00970 | Reg=0.00196 | acc=0.9844 | L2-Norm=13.998 | L2-Norm(final)=11.894 | 4770.5 samples/s | 74.5 steps/s
[Step=57000 Epoch=55.7] | Loss=0.00959 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.002 | L2-Norm(final)=11.894 | 4787.6 samples/s | 74.8 steps/s
[Step=57050 Epoch=55.7] | Loss=0.00956 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.005 | L2-Norm(final)=11.895 | 4807.8 samples/s | 75.1 steps/s
[Step=57100 Epoch=55.7] | Loss=0.00956 | Reg=0.00196 | acc=0.9844 | L2-Norm=14.009 | L2-Norm(final)=11.895 | 4768.7 samples/s | 74.5 steps/s
[Step=57150 Epoch=55.8] | Loss=0.00979 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.013 | L2-Norm(final)=11.896 | 4821.7 samples/s | 75.3 steps/s
[Step=57200 Epoch=55.8] | Loss=0.00986 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.016 | L2-Norm(final)=11.896 | 4753.6 samples/s | 74.3 steps/s
[Step=57250 Epoch=55.9] | Loss=0.00994 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.019 | L2-Norm(final)=11.895 | 4777.5 samples/s | 74.6 steps/s
[Step=57300 Epoch=55.9] | Loss=0.00997 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.022 | L2-Norm(final)=11.896 | 4822.1 samples/s | 75.3 steps/s
[Step=57350 Epoch=56.0] | Loss=0.00986 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.026 | L2-Norm(final)=11.896 | 4831.6 samples/s | 75.5 steps/s
[Step=57400 Epoch=56.0] | Loss=0.00991 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.029 | L2-Norm(final)=11.896 | 4784.3 samples/s | 74.8 steps/s
[Step=57450 Epoch=56.1] | Loss=0.00993 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.032 | L2-Norm(final)=11.896 | 4849.6 samples/s | 75.8 steps/s
[Step=57500 Epoch=56.1] | Loss=0.00995 | Reg=0.00197 | acc=0.9688 | L2-Norm=14.035 | L2-Norm(final)=11.896 | 5175.8 samples/s | 80.9 steps/s
[Step=57550 Epoch=56.2] | Loss=0.01001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.038 | L2-Norm(final)=11.896 | 2162.9 samples/s | 33.8 steps/s
[Step=57600 Epoch=56.2] | Loss=0.00996 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.042 | L2-Norm(final)=11.896 | 4948.6 samples/s | 77.3 steps/s
[Step=57650 Epoch=56.3] | Loss=0.00998 | Reg=0.00197 | acc=0.9844 | L2-Norm=14.045 | L2-Norm(final)=11.897 | 4836.7 samples/s | 75.6 steps/s
[Step=57700 Epoch=56.3] | Loss=0.00998 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.048 | L2-Norm(final)=11.897 | 4953.3 samples/s | 77.4 steps/s
[Step=57750 Epoch=56.4] | Loss=0.00991 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.051 | L2-Norm(final)=11.897 | 4856.3 samples/s | 75.9 steps/s
[Step=57800 Epoch=56.4] | Loss=0.00985 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.054 | L2-Norm(final)=11.898 | 4842.6 samples/s | 75.7 steps/s
[Step=57850 Epoch=56.5] | Loss=0.00979 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.056 | L2-Norm(final)=11.898 | 4780.7 samples/s | 74.7 steps/s
[Step=57900 Epoch=56.5] | Loss=0.00976 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.059 | L2-Norm(final)=11.899 | 4788.8 samples/s | 74.8 steps/s
[Step=57950 Epoch=56.6] | Loss=0.00977 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=11.900 | 4913.8 samples/s | 76.8 steps/s
[Step=58000 Epoch=56.6] | Loss=0.00973 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.065 | L2-Norm(final)=11.900 | 4882.4 samples/s | 76.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step58000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=56001 Epoch=105.6] | Loss=0.00000 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.940 | L2-Norm(final)=12.575 | 4283.8 samples/s | 66.9 steps/s
[Step=56050 Epoch=105.7] | Loss=0.00011 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.578 | 4968.8 samples/s | 77.6 steps/s
[Step=56100 Epoch=105.7] | Loss=0.00023 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.581 | 5173.5 samples/s | 80.8 steps/s
[Step=56150 Epoch=105.8] | Loss=0.00021 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.585 | 5270.9 samples/s | 82.4 steps/s
[Step=56200 Epoch=105.9] | Loss=0.00019 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.589 | 5137.3 samples/s | 80.3 steps/s
[Step=56250 Epoch=106.0] | Loss=0.00017 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.593 | 5184.4 samples/s | 81.0 steps/s
[Step=56300 Epoch=106.1] | Loss=0.00016 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.596 | 5156.1 samples/s | 80.6 steps/s
[Step=56350 Epoch=106.2] | Loss=0.00015 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.599 | 5294.3 samples/s | 82.7 steps/s
[Step=56400 Epoch=106.3] | Loss=0.00015 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.603 | 5328.6 samples/s | 83.3 steps/s
[Step=56450 Epoch=106.4] | Loss=0.00015 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.606 | 5306.1 samples/s | 82.9 steps/s
[Step=56500 Epoch=106.5] | Loss=0.00014 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.609 | 5397.3 samples/s | 84.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=106.5] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.937 | L2-Norm(final)=12.642 | 3983.4 samples/s | 62.2 steps/s
[Step=56550 Epoch=106.6] | Loss=0.00004 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.930 | L2-Norm(final)=12.644 | 4563.4 samples/s | 71.3 steps/s
[Step=56600 Epoch=106.7] | Loss=0.00004 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.922 | L2-Norm(final)=12.646 | 4633.1 samples/s | 72.4 steps/s
[Step=56650 Epoch=106.8] | Loss=0.00002 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.914 | L2-Norm(final)=12.648 | 4646.3 samples/s | 72.6 steps/s
[Step=56700 Epoch=106.9] | Loss=0.00002 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.903 | L2-Norm(final)=12.649 | 4492.3 samples/s | 70.2 steps/s
[Step=56750 Epoch=107.0] | Loss=0.00002 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.892 | L2-Norm(final)=12.650 | 4566.9 samples/s | 71.4 steps/s
[Step=56800 Epoch=107.1] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.880 | L2-Norm(final)=12.650 | 4610.9 samples/s | 72.0 steps/s
[Step=56850 Epoch=107.2] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.867 | L2-Norm(final)=12.651 | 4576.9 samples/s | 71.5 steps/s
[Step=56900 Epoch=107.3] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.855 | L2-Norm(final)=12.651 | 4545.3 samples/s | 71.0 steps/s
[Step=56950 Epoch=107.4] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.843 | L2-Norm(final)=12.651 | 4610.2 samples/s | 72.0 steps/s
[Step=57000 Epoch=107.4] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.831 | L2-Norm(final)=12.652 | 4533.0 samples/s | 70.8 steps/s
[Step=57050 Epoch=107.5] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.819 | L2-Norm(final)=12.652 | 2130.1 samples/s | 33.3 steps/s
[Step=57100 Epoch=107.6] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.807 | L2-Norm(final)=12.652 | 4533.7 samples/s | 70.8 steps/s
[Step=57150 Epoch=107.7] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.794 | L2-Norm(final)=12.653 | 4538.0 samples/s | 70.9 steps/s
[Step=57200 Epoch=107.8] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.781 | L2-Norm(final)=12.653 | 4520.1 samples/s | 70.6 steps/s
[Step=57250 Epoch=107.9] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.769 | L2-Norm(final)=12.653 | 4508.2 samples/s | 70.4 steps/s
[Step=57300 Epoch=108.0] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=12.653 | 4602.4 samples/s | 71.9 steps/s
[Step=57350 Epoch=108.1] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.743 | L2-Norm(final)=12.654 | 4528.5 samples/s | 70.8 steps/s
[Step=57400 Epoch=108.2] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.730 | L2-Norm(final)=12.654 | 4563.5 samples/s | 71.3 steps/s
[Step=57450 Epoch=108.3] | Loss=0.00000 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=12.654 | 4510.2 samples/s | 70.5 steps/s
[Step=57500 Epoch=108.4] | Loss=0.00000 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.704 | L2-Norm(final)=12.654 | 4494.3 samples/s | 70.2 steps/s
[Step=57550 Epoch=108.5] | Loss=0.00000 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.691 | L2-Norm(final)=12.655 | 5712.0 samples/s | 89.3 steps/s
[Step=57600 Epoch=108.6] | Loss=0.00000 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.677 | L2-Norm(final)=12.655 | 1904.7 samples/s | 29.8 steps/s
[Step=57650 Epoch=108.7] | Loss=0.00000 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.664 | L2-Norm(final)=12.655 | 4576.7 samples/s | 71.5 steps/s
[Step=57700 Epoch=108.8] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.650 | L2-Norm(final)=12.655 | 4524.4 samples/s | 70.7 steps/s
[Step=57750 Epoch=108.9] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.636 | L2-Norm(final)=12.655 | 4528.9 samples/s | 70.8 steps/s
[Step=57800 Epoch=109.0] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.622 | L2-Norm(final)=12.655 | 4518.4 samples/s | 70.6 steps/s
[Step=57850 Epoch=109.0] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.608 | L2-Norm(final)=12.656 | 4578.5 samples/s | 71.5 steps/s
[Step=57900 Epoch=109.1] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=12.656 | 4476.5 samples/s | 69.9 steps/s
[Step=57950 Epoch=109.2] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.580 | L2-Norm(final)=12.656 | 4596.1 samples/s | 71.8 steps/s
[Step=58000 Epoch=109.3] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=12.656 | 4546.1 samples/s | 71.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06487 | acc=0.9699 | tpr=0.9700 | fpr=0.0302 | 4564.4 samples/s | 17.8 steps/s
Avg test loss: 0.07127, Avg test acc: 0.96923, Avg tpr: 0.96905, Avg fpr: 0.03038, total FA: 237

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.74247 | acc=0.2967 | tpr=0.0244 | fpr=0.1120 | 4677.7 samples/s | 18.3 steps/s
Avg test loss: 5.73622, Avg test acc: 0.29357, Avg tpr: 0.02331, Avg fpr: 0.11204, total FA: 874

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.97822 | acc=0.1529 | tpr=0.4425 | fpr=0.8523 | 4543.8 samples/s | 17.7 steps/s
[Step= 100] | Loss=5.92845 | acc=0.1518 | tpr=0.4136 | fpr=0.8531 | 8606.3 samples/s | 33.6 steps/s
[Step= 150] | Loss=5.92540 | acc=0.1523 | tpr=0.4308 | fpr=0.8528 | 8567.7 samples/s | 33.5 steps/s
[Step= 200] | Loss=5.91182 | acc=0.1523 | tpr=0.4273 | fpr=0.8527 | 8597.2 samples/s | 33.6 steps/s
[Step= 250] | Loss=5.91158 | acc=0.1532 | tpr=0.4279 | fpr=0.8518 | 8434.5 samples/s | 32.9 steps/s
[Step= 300] | Loss=5.90956 | acc=0.1530 | tpr=0.4298 | fpr=0.8521 | 8494.6 samples/s | 33.2 steps/s
[Step= 350] | Loss=5.90538 | acc=0.1525 | tpr=0.4271 | fpr=0.8525 | 8518.8 samples/s | 33.3 steps/s
[Step= 400] | Loss=5.90429 | acc=0.1528 | tpr=0.4283 | fpr=0.8522 | 8334.6 samples/s | 32.6 steps/s
[Step= 450] | Loss=5.90799 | acc=0.1529 | tpr=0.4255 | fpr=0.8521 | 8670.9 samples/s | 33.9 steps/s
[Step= 500] | Loss=5.90979 | acc=0.1531 | tpr=0.4256 | fpr=0.8518 | 8626.8 samples/s | 33.7 steps/s
[Step= 550] | Loss=5.91080 | acc=0.1532 | tpr=0.4282 | fpr=0.8518 | 14390.4 samples/s | 56.2 steps/s
Avg test loss: 5.91168, Avg test acc: 0.15301, Avg tpr: 0.42789, Avg fpr: 0.85199, total FA: 118297

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15282 | acc=0.9829 | tpr=0.9469 | fpr=0.0165 | 4588.5 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.16261 | acc=0.9819 | tpr=0.9510 | fpr=0.0175 | 8314.3 samples/s | 32.5 steps/s
[Step= 150] | Loss=0.16776 | acc=0.9810 | tpr=0.9553 | fpr=0.0185 | 8671.5 samples/s | 33.9 steps/s
[Step= 200] | Loss=0.16878 | acc=0.9809 | tpr=0.9607 | fpr=0.0187 | 8341.6 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.16705 | acc=0.9811 | tpr=0.9581 | fpr=0.0184 | 8457.7 samples/s | 33.0 steps/s
[Step= 300] | Loss=0.16928 | acc=0.9809 | tpr=0.9593 | fpr=0.0187 | 8435.6 samples/s | 33.0 steps/s
[Step= 350] | Loss=0.17176 | acc=0.9807 | tpr=0.9580 | fpr=0.0189 | 8402.9 samples/s | 32.8 steps/s
[Step= 400] | Loss=0.17271 | acc=0.9806 | tpr=0.9557 | fpr=0.0189 | 8923.8 samples/s | 34.9 steps/s
[Step= 450] | Loss=0.17688 | acc=0.9803 | tpr=0.9542 | fpr=0.0193 | 8409.0 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.17602 | acc=0.9802 | tpr=0.9533 | fpr=0.0193 | 8235.5 samples/s | 32.2 steps/s
[Step= 550] | Loss=0.17474 | acc=0.9804 | tpr=0.9526 | fpr=0.0191 | 15429.8 samples/s | 60.3 steps/s
Avg test loss: 0.17449, Avg test acc: 0.98043, Avg tpr: 0.95246, Avg fpr: 0.01906, total FA: 2647

server round 29/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=58001 Epoch=56.6] | Loss=0.00032 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=11.919 | 4074.8 samples/s | 63.7 steps/s
[Step=58050 Epoch=56.7] | Loss=0.00714 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.595 | L2-Norm(final)=11.924 | 5202.0 samples/s | 81.3 steps/s
[Step=58100 Epoch=56.7] | Loss=0.00764 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=11.932 | 5448.1 samples/s | 85.1 steps/s
[Step=58150 Epoch=56.8] | Loss=0.00755 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.595 | L2-Norm(final)=11.939 | 5640.5 samples/s | 88.1 steps/s
[Step=58200 Epoch=56.8] | Loss=0.00732 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=11.946 | 5361.4 samples/s | 83.8 steps/s
[Step=58250 Epoch=56.9] | Loss=0.00759 | Reg=0.00185 | acc=0.9688 | L2-Norm=13.595 | L2-Norm(final)=11.954 | 5552.4 samples/s | 86.8 steps/s
[Step=58300 Epoch=56.9] | Loss=0.00760 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=11.961 | 5439.4 samples/s | 85.0 steps/s
[Step=58350 Epoch=57.0] | Loss=0.00759 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.595 | L2-Norm(final)=11.968 | 5547.7 samples/s | 86.7 steps/s
[Step=58400 Epoch=57.0] | Loss=0.00770 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=11.974 | 5453.6 samples/s | 85.2 steps/s
[Step=58450 Epoch=57.1] | Loss=0.00773 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.595 | L2-Norm(final)=11.980 | 5535.8 samples/s | 86.5 steps/s
[Step=58500 Epoch=57.1] | Loss=0.00787 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=11.987 | 5579.4 samples/s | 87.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=57.1] | Loss=0.00131 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=12.053 | 4254.4 samples/s | 66.5 steps/s
[Step=58550 Epoch=57.2] | Loss=0.00828 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.604 | L2-Norm(final)=12.058 | 4656.6 samples/s | 72.8 steps/s
[Step=58600 Epoch=57.2] | Loss=0.00780 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.611 | L2-Norm(final)=12.061 | 4806.4 samples/s | 75.1 steps/s
[Step=58650 Epoch=57.3] | Loss=0.00878 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=12.062 | 4836.9 samples/s | 75.6 steps/s
[Step=58700 Epoch=57.3] | Loss=0.00909 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.626 | L2-Norm(final)=12.062 | 4718.1 samples/s | 73.7 steps/s
[Step=58750 Epoch=57.4] | Loss=0.00961 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.632 | L2-Norm(final)=12.061 | 4781.2 samples/s | 74.7 steps/s
[Step=58800 Epoch=57.4] | Loss=0.00951 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.638 | L2-Norm(final)=12.061 | 4761.7 samples/s | 74.4 steps/s
[Step=58850 Epoch=57.5] | Loss=0.00957 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.644 | L2-Norm(final)=12.062 | 4827.9 samples/s | 75.4 steps/s
[Step=58900 Epoch=57.5] | Loss=0.00992 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.650 | L2-Norm(final)=12.062 | 4738.8 samples/s | 74.0 steps/s
[Step=58950 Epoch=57.6] | Loss=0.00989 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=12.063 | 4853.8 samples/s | 75.8 steps/s
[Step=59000 Epoch=57.6] | Loss=0.00978 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.662 | L2-Norm(final)=12.064 | 4822.1 samples/s | 75.3 steps/s
[Step=59050 Epoch=57.7] | Loss=0.01013 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.667 | L2-Norm(final)=12.065 | 4505.7 samples/s | 70.4 steps/s
[Step=59100 Epoch=57.7] | Loss=0.01021 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.672 | L2-Norm(final)=12.065 | 4109.9 samples/s | 64.2 steps/s
[Step=59150 Epoch=57.8] | Loss=0.01016 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.677 | L2-Norm(final)=12.067 | 4487.3 samples/s | 70.1 steps/s
[Step=59200 Epoch=57.8] | Loss=0.01017 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=12.068 | 4086.8 samples/s | 63.9 steps/s
[Step=59250 Epoch=57.8] | Loss=0.01014 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.686 | L2-Norm(final)=12.069 | 4202.9 samples/s | 65.7 steps/s
[Step=59300 Epoch=57.9] | Loss=0.01005 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.690 | L2-Norm(final)=12.070 | 4221.7 samples/s | 66.0 steps/s
[Step=59350 Epoch=57.9] | Loss=0.01003 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.694 | L2-Norm(final)=12.071 | 4294.2 samples/s | 67.1 steps/s
[Step=59400 Epoch=58.0] | Loss=0.00997 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.697 | L2-Norm(final)=12.072 | 4302.4 samples/s | 67.2 steps/s
[Step=59450 Epoch=58.0] | Loss=0.00999 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.701 | L2-Norm(final)=12.074 | 4331.2 samples/s | 67.7 steps/s
[Step=59500 Epoch=58.1] | Loss=0.01004 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.704 | L2-Norm(final)=12.075 | 5137.8 samples/s | 80.3 steps/s
[Step=59550 Epoch=58.1] | Loss=0.00993 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.708 | L2-Norm(final)=12.076 | 2143.6 samples/s | 33.5 steps/s
[Step=59600 Epoch=58.2] | Loss=0.00984 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.711 | L2-Norm(final)=12.077 | 4796.5 samples/s | 74.9 steps/s
[Step=59650 Epoch=58.2] | Loss=0.00979 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.714 | L2-Norm(final)=12.078 | 4756.7 samples/s | 74.3 steps/s
[Step=59700 Epoch=58.3] | Loss=0.00979 | Reg=0.00188 | acc=0.9844 | L2-Norm=13.717 | L2-Norm(final)=12.080 | 4727.6 samples/s | 73.9 steps/s
[Step=59750 Epoch=58.3] | Loss=0.00976 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.720 | L2-Norm(final)=12.081 | 4892.2 samples/s | 76.4 steps/s
[Step=59800 Epoch=58.4] | Loss=0.00970 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.723 | L2-Norm(final)=12.082 | 4842.3 samples/s | 75.7 steps/s
[Step=59850 Epoch=58.4] | Loss=0.00978 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.726 | L2-Norm(final)=12.083 | 4812.5 samples/s | 75.2 steps/s
[Step=59900 Epoch=58.5] | Loss=0.00976 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.729 | L2-Norm(final)=12.084 | 4838.9 samples/s | 75.6 steps/s
[Step=59950 Epoch=58.5] | Loss=0.00972 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.732 | L2-Norm(final)=12.085 | 4902.8 samples/s | 76.6 steps/s
[Step=60000 Epoch=58.6] | Loss=0.00969 | Reg=0.00189 | acc=0.9844 | L2-Norm=13.734 | L2-Norm(final)=12.086 | 4860.0 samples/s | 75.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step60000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00025, len=1
[Step=58001 Epoch=109.3] | Loss=0.00009 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.594 | L2-Norm(final)=12.662 | 3946.3 samples/s | 61.7 steps/s
[Step=58050 Epoch=109.4] | Loss=0.00016 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.589 | L2-Norm(final)=12.667 | 5102.4 samples/s | 79.7 steps/s
[Step=58100 Epoch=109.5] | Loss=0.00012 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.589 | L2-Norm(final)=12.675 | 5180.1 samples/s | 80.9 steps/s
[Step=58150 Epoch=109.6] | Loss=0.00014 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.683 | 5174.5 samples/s | 80.9 steps/s
[Step=58200 Epoch=109.7] | Loss=0.00013 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.690 | 5154.9 samples/s | 80.5 steps/s
[Step=58250 Epoch=109.8] | Loss=0.00012 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.696 | 5193.3 samples/s | 81.1 steps/s
[Step=58300 Epoch=109.9] | Loss=0.00012 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.702 | 5331.7 samples/s | 83.3 steps/s
[Step=58350 Epoch=110.0] | Loss=0.00011 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.707 | 5084.0 samples/s | 79.4 steps/s
[Step=58400 Epoch=110.1] | Loss=0.00011 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.713 | 5198.4 samples/s | 81.2 steps/s
[Step=58450 Epoch=110.2] | Loss=0.00011 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.719 | 5196.1 samples/s | 81.2 steps/s
[Step=58500 Epoch=110.3] | Loss=0.00010 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.724 | 5197.4 samples/s | 81.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=110.3] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.588 | L2-Norm(final)=12.773 | 4090.2 samples/s | 63.9 steps/s
[Step=58550 Epoch=110.4] | Loss=0.00237 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.614 | L2-Norm(final)=12.772 | 4441.0 samples/s | 69.4 steps/s
[Step=58600 Epoch=110.5] | Loss=0.00255 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.644 | L2-Norm(final)=12.766 | 4608.7 samples/s | 72.0 steps/s
[Step=58650 Epoch=110.6] | Loss=0.00230 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.663 | L2-Norm(final)=12.761 | 4627.3 samples/s | 72.3 steps/s
[Step=58700 Epoch=110.7] | Loss=0.00174 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.676 | L2-Norm(final)=12.757 | 4725.3 samples/s | 73.8 steps/s
[Step=58750 Epoch=110.7] | Loss=0.00141 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=12.755 | 4593.1 samples/s | 71.8 steps/s
[Step=58800 Epoch=110.8] | Loss=0.00133 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.687 | L2-Norm(final)=12.754 | 4678.9 samples/s | 73.1 steps/s
[Step=58850 Epoch=110.9] | Loss=0.00116 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.692 | L2-Norm(final)=12.752 | 4682.2 samples/s | 73.2 steps/s
[Step=58900 Epoch=111.0] | Loss=0.00102 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.696 | L2-Norm(final)=12.752 | 4649.3 samples/s | 72.6 steps/s
[Step=58950 Epoch=111.1] | Loss=0.00093 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.698 | L2-Norm(final)=12.751 | 4547.1 samples/s | 71.0 steps/s
[Step=59000 Epoch=111.2] | Loss=0.00084 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.699 | L2-Norm(final)=12.751 | 4592.2 samples/s | 71.8 steps/s
[Step=59050 Epoch=111.3] | Loss=0.00076 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.700 | L2-Norm(final)=12.751 | 2133.9 samples/s | 33.3 steps/s
[Step=59100 Epoch=111.4] | Loss=0.00070 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.699 | L2-Norm(final)=12.751 | 4509.5 samples/s | 70.5 steps/s
[Step=59150 Epoch=111.5] | Loss=0.00065 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.698 | L2-Norm(final)=12.750 | 4532.2 samples/s | 70.8 steps/s
[Step=59200 Epoch=111.6] | Loss=0.00060 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.697 | L2-Norm(final)=12.751 | 4578.8 samples/s | 71.5 steps/s
[Step=59250 Epoch=111.7] | Loss=0.00056 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.696 | L2-Norm(final)=12.751 | 4703.4 samples/s | 73.5 steps/s
[Step=59300 Epoch=111.8] | Loss=0.00053 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.694 | L2-Norm(final)=12.751 | 4656.5 samples/s | 72.8 steps/s
[Step=59350 Epoch=111.9] | Loss=0.00052 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.692 | L2-Norm(final)=12.751 | 4765.3 samples/s | 74.5 steps/s
[Step=59400 Epoch=112.0] | Loss=0.00053 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.691 | L2-Norm(final)=12.751 | 4556.1 samples/s | 71.2 steps/s
[Step=59450 Epoch=112.1] | Loss=0.00050 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.689 | L2-Norm(final)=12.751 | 4634.4 samples/s | 72.4 steps/s
[Step=59500 Epoch=112.2] | Loss=0.00048 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.688 | L2-Norm(final)=12.751 | 4465.6 samples/s | 69.8 steps/s
[Step=59550 Epoch=112.3] | Loss=0.00045 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.687 | L2-Norm(final)=12.751 | 5630.0 samples/s | 88.0 steps/s
[Step=59600 Epoch=112.3] | Loss=0.00043 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.685 | L2-Norm(final)=12.751 | 1993.5 samples/s | 31.1 steps/s
[Step=59650 Epoch=112.4] | Loss=0.00042 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=12.751 | 4539.8 samples/s | 70.9 steps/s
[Step=59700 Epoch=112.5] | Loss=0.00040 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=12.751 | 4520.8 samples/s | 70.6 steps/s
[Step=59750 Epoch=112.6] | Loss=0.00038 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.679 | L2-Norm(final)=12.751 | 4527.2 samples/s | 70.7 steps/s
[Step=59800 Epoch=112.7] | Loss=0.00037 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.677 | L2-Norm(final)=12.752 | 4535.7 samples/s | 70.9 steps/s
[Step=59850 Epoch=112.8] | Loss=0.00035 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.675 | L2-Norm(final)=12.752 | 4559.1 samples/s | 71.2 steps/s
[Step=59900 Epoch=112.9] | Loss=0.00034 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.673 | L2-Norm(final)=12.752 | 4501.6 samples/s | 70.3 steps/s
[Step=59950 Epoch=113.0] | Loss=0.00033 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.670 | L2-Norm(final)=12.753 | 4527.6 samples/s | 70.7 steps/s
[Step=60000 Epoch=113.1] | Loss=0.00032 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.668 | L2-Norm(final)=12.753 | 4533.0 samples/s | 70.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06398 | acc=0.9723 | tpr=0.9750 | fpr=0.0337 | 4617.8 samples/s | 18.0 steps/s
Avg test loss: 0.07217, Avg test acc: 0.97067, Avg tpr: 0.97389, Avg fpr: 0.03641, total FA: 284

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.96323 | acc=0.3013 | tpr=0.0129 | fpr=0.0723 | 4487.2 samples/s | 17.5 steps/s
Avg test loss: 6.96530, Avg test acc: 0.29862, Avg tpr: 0.01317, Avg fpr: 0.07358, total FA: 574

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.07677 | acc=0.1452 | tpr=0.4779 | fpr=0.8608 | 4621.5 samples/s | 18.1 steps/s
[Step= 100] | Loss=6.03233 | acc=0.1455 | tpr=0.4499 | fpr=0.8602 | 8298.9 samples/s | 32.4 steps/s
[Step= 150] | Loss=6.03115 | acc=0.1460 | tpr=0.4597 | fpr=0.8598 | 8662.2 samples/s | 33.8 steps/s
[Step= 200] | Loss=6.01623 | acc=0.1462 | tpr=0.4590 | fpr=0.8595 | 8327.9 samples/s | 32.5 steps/s
[Step= 250] | Loss=6.01550 | acc=0.1469 | tpr=0.4611 | fpr=0.8588 | 8863.1 samples/s | 34.6 steps/s
[Step= 300] | Loss=6.01467 | acc=0.1472 | tpr=0.4611 | fpr=0.8585 | 8497.0 samples/s | 33.2 steps/s
[Step= 350] | Loss=6.01043 | acc=0.1468 | tpr=0.4602 | fpr=0.8589 | 8166.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.01137 | acc=0.1468 | tpr=0.4568 | fpr=0.8589 | 8452.4 samples/s | 33.0 steps/s
[Step= 450] | Loss=6.01480 | acc=0.1469 | tpr=0.4562 | fpr=0.8588 | 8565.2 samples/s | 33.5 steps/s
[Step= 500] | Loss=6.01707 | acc=0.1470 | tpr=0.4542 | fpr=0.8585 | 8312.0 samples/s | 32.5 steps/s
[Step= 550] | Loss=6.01752 | acc=0.1472 | tpr=0.4548 | fpr=0.8584 | 16076.9 samples/s | 62.8 steps/s
Avg test loss: 6.01879, Avg test acc: 0.14700, Avg tpr: 0.45483, Avg fpr: 0.85860, total FA: 119215

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14944 | acc=0.9830 | tpr=0.9513 | fpr=0.0165 | 4547.6 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.15563 | acc=0.9822 | tpr=0.9510 | fpr=0.0172 | 8443.4 samples/s | 33.0 steps/s
[Step= 150] | Loss=0.16034 | acc=0.9818 | tpr=0.9539 | fpr=0.0177 | 8686.2 samples/s | 33.9 steps/s
[Step= 200] | Loss=0.16149 | acc=0.9816 | tpr=0.9574 | fpr=0.0179 | 8428.7 samples/s | 32.9 steps/s
[Step= 250] | Loss=0.15852 | acc=0.9818 | tpr=0.9528 | fpr=0.0177 | 8738.9 samples/s | 34.1 steps/s
[Step= 300] | Loss=0.16253 | acc=0.9814 | tpr=0.9520 | fpr=0.0181 | 8347.1 samples/s | 32.6 steps/s
[Step= 350] | Loss=0.16593 | acc=0.9811 | tpr=0.9524 | fpr=0.0184 | 8376.7 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.16727 | acc=0.9809 | tpr=0.9513 | fpr=0.0185 | 8494.8 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.17130 | acc=0.9805 | tpr=0.9494 | fpr=0.0189 | 8431.0 samples/s | 32.9 steps/s
[Step= 500] | Loss=0.16981 | acc=0.9806 | tpr=0.9502 | fpr=0.0188 | 8370.1 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.16866 | acc=0.9807 | tpr=0.9495 | fpr=0.0187 | 15777.0 samples/s | 61.6 steps/s
Avg test loss: 0.16842, Avg test acc: 0.98072, Avg tpr: 0.94889, Avg fpr: 0.01870, total FA: 2597

server round 30/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=60001 Epoch=58.6] | Loss=0.04098 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.634 | L2-Norm(final)=12.116 | 4197.3 samples/s | 65.6 steps/s
[Step=60050 Epoch=58.6] | Loss=0.01299 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.634 | L2-Norm(final)=12.123 | 5403.3 samples/s | 84.4 steps/s
[Step=60100 Epoch=58.7] | Loss=0.01197 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.635 | L2-Norm(final)=12.129 | 5500.1 samples/s | 85.9 steps/s
[Step=60150 Epoch=58.7] | Loss=0.01191 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.635 | L2-Norm(final)=12.134 | 5455.8 samples/s | 85.2 steps/s
[Step=60200 Epoch=58.8] | Loss=0.01261 | Reg=0.00186 | acc=0.9688 | L2-Norm=13.635 | L2-Norm(final)=12.140 | 5410.8 samples/s | 84.5 steps/s
[Step=60250 Epoch=58.8] | Loss=0.01245 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.635 | L2-Norm(final)=12.145 | 5536.2 samples/s | 86.5 steps/s
[Step=60300 Epoch=58.9] | Loss=0.01245 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.635 | L2-Norm(final)=12.149 | 5602.4 samples/s | 87.5 steps/s
[Step=60350 Epoch=58.9] | Loss=0.01244 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.635 | L2-Norm(final)=12.154 | 5455.0 samples/s | 85.2 steps/s
[Step=60400 Epoch=59.0] | Loss=0.01241 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.635 | L2-Norm(final)=12.158 | 5641.4 samples/s | 88.1 steps/s
[Step=60450 Epoch=59.0] | Loss=0.01234 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.635 | L2-Norm(final)=12.163 | 5537.0 samples/s | 86.5 steps/s
[Step=60500 Epoch=59.1] | Loss=0.01240 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.635 | L2-Norm(final)=12.167 | 5579.1 samples/s | 87.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=59.1] | Loss=0.00316 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.635 | L2-Norm(final)=12.212 | 4101.0 samples/s | 64.1 steps/s
[Step=60550 Epoch=59.1] | Loss=0.00994 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.640 | L2-Norm(final)=12.217 | 4602.7 samples/s | 71.9 steps/s
[Step=60600 Epoch=59.2] | Loss=0.00960 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.646 | L2-Norm(final)=12.217 | 4669.9 samples/s | 73.0 steps/s
[Step=60650 Epoch=59.2] | Loss=0.00919 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.650 | L2-Norm(final)=12.218 | 4768.9 samples/s | 74.5 steps/s
[Step=60700 Epoch=59.3] | Loss=0.00901 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.653 | L2-Norm(final)=12.219 | 4758.5 samples/s | 74.4 steps/s
[Step=60750 Epoch=59.3] | Loss=0.00871 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=12.221 | 4755.5 samples/s | 74.3 steps/s
[Step=60800 Epoch=59.4] | Loss=0.00855 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.658 | L2-Norm(final)=12.222 | 4811.8 samples/s | 75.2 steps/s
[Step=60850 Epoch=59.4] | Loss=0.00861 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.661 | L2-Norm(final)=12.223 | 4745.1 samples/s | 74.1 steps/s
[Step=60900 Epoch=59.5] | Loss=0.00843 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.663 | L2-Norm(final)=12.224 | 4755.2 samples/s | 74.3 steps/s
[Step=60950 Epoch=59.5] | Loss=0.00819 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.665 | L2-Norm(final)=12.225 | 4827.7 samples/s | 75.4 steps/s
[Step=61000 Epoch=59.6] | Loss=0.00813 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.667 | L2-Norm(final)=12.226 | 4745.2 samples/s | 74.1 steps/s
[Step=61050 Epoch=59.6] | Loss=0.00804 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.669 | L2-Norm(final)=12.226 | 4824.9 samples/s | 75.4 steps/s
[Step=61100 Epoch=59.7] | Loss=0.00803 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.670 | L2-Norm(final)=12.227 | 4818.5 samples/s | 75.3 steps/s
[Step=61150 Epoch=59.7] | Loss=0.00810 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.672 | L2-Norm(final)=12.228 | 4857.7 samples/s | 75.9 steps/s
[Step=61200 Epoch=59.8] | Loss=0.00827 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.673 | L2-Norm(final)=12.228 | 4799.2 samples/s | 75.0 steps/s
[Step=61250 Epoch=59.8] | Loss=0.00837 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.674 | L2-Norm(final)=12.229 | 4788.0 samples/s | 74.8 steps/s
[Step=61300 Epoch=59.8] | Loss=0.00836 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.675 | L2-Norm(final)=12.229 | 4832.8 samples/s | 75.5 steps/s
[Step=61350 Epoch=59.9] | Loss=0.00816 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.676 | L2-Norm(final)=12.230 | 4707.8 samples/s | 73.6 steps/s
[Step=61400 Epoch=59.9] | Loss=0.00815 | Reg=0.00187 | acc=0.9688 | L2-Norm=13.677 | L2-Norm(final)=12.230 | 4765.2 samples/s | 74.5 steps/s
[Step=61450 Epoch=60.0] | Loss=0.00805 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.678 | L2-Norm(final)=12.231 | 4808.2 samples/s | 75.1 steps/s
[Step=61500 Epoch=60.0] | Loss=0.00816 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.679 | L2-Norm(final)=12.232 | 5114.5 samples/s | 79.9 steps/s
[Step=61550 Epoch=60.1] | Loss=0.00828 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.680 | L2-Norm(final)=12.232 | 2078.1 samples/s | 32.5 steps/s
[Step=61600 Epoch=60.1] | Loss=0.00822 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.681 | L2-Norm(final)=12.233 | 4820.9 samples/s | 75.3 steps/s
[Step=61650 Epoch=60.2] | Loss=0.00810 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.682 | L2-Norm(final)=12.234 | 4618.4 samples/s | 72.2 steps/s
[Step=61700 Epoch=60.2] | Loss=0.00794 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=12.234 | 4700.4 samples/s | 73.4 steps/s
[Step=61750 Epoch=60.3] | Loss=0.00788 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.684 | L2-Norm(final)=12.235 | 4779.0 samples/s | 74.7 steps/s
[Step=61800 Epoch=60.3] | Loss=0.00780 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.685 | L2-Norm(final)=12.236 | 4773.4 samples/s | 74.6 steps/s
[Step=61850 Epoch=60.4] | Loss=0.00774 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.686 | L2-Norm(final)=12.236 | 4813.5 samples/s | 75.2 steps/s
[Step=61900 Epoch=60.4] | Loss=0.00768 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.687 | L2-Norm(final)=12.237 | 4810.7 samples/s | 75.2 steps/s
[Step=61950 Epoch=60.5] | Loss=0.00769 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.687 | L2-Norm(final)=12.238 | 4779.9 samples/s | 74.7 steps/s
[Step=62000 Epoch=60.5] | Loss=0.00769 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.688 | L2-Norm(final)=12.239 | 4791.8 samples/s | 74.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step62000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=60001 Epoch=113.1] | Loss=0.00002 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.634 | L2-Norm(final)=12.763 | 4015.1 samples/s | 62.7 steps/s
[Step=60050 Epoch=113.2] | Loss=0.00010 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.634 | L2-Norm(final)=12.763 | 5050.1 samples/s | 78.9 steps/s
[Step=60100 Epoch=113.3] | Loss=0.00006 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.634 | L2-Norm(final)=12.764 | 5097.2 samples/s | 79.6 steps/s
[Step=60150 Epoch=113.4] | Loss=0.00006 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.765 | 5283.4 samples/s | 82.6 steps/s
[Step=60200 Epoch=113.5] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.765 | 5411.4 samples/s | 84.6 steps/s
[Step=60250 Epoch=113.6] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.765 | 5121.4 samples/s | 80.0 steps/s
[Step=60300 Epoch=113.7] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.766 | 5314.1 samples/s | 83.0 steps/s
[Step=60350 Epoch=113.8] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.766 | 5203.0 samples/s | 81.3 steps/s
[Step=60400 Epoch=113.9] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.766 | 5186.2 samples/s | 81.0 steps/s
[Step=60450 Epoch=113.9] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.767 | 5261.1 samples/s | 82.2 steps/s
[Step=60500 Epoch=114.0] | Loss=0.00005 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.767 | 5339.4 samples/s | 83.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=114.0] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.633 | L2-Norm(final)=12.771 | 4056.7 samples/s | 63.4 steps/s
[Step=60550 Epoch=114.1] | Loss=0.00003 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.630 | L2-Norm(final)=12.772 | 4410.3 samples/s | 68.9 steps/s
[Step=60600 Epoch=114.2] | Loss=0.00003 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=12.772 | 4587.5 samples/s | 71.7 steps/s
[Step=60650 Epoch=114.3] | Loss=0.00003 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.624 | L2-Norm(final)=12.773 | 4528.3 samples/s | 70.8 steps/s
[Step=60700 Epoch=114.4] | Loss=0.00002 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.622 | L2-Norm(final)=12.773 | 4527.7 samples/s | 70.7 steps/s
[Step=60750 Epoch=114.5] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.619 | L2-Norm(final)=12.773 | 4542.7 samples/s | 71.0 steps/s
[Step=60800 Epoch=114.6] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.617 | L2-Norm(final)=12.774 | 4627.4 samples/s | 72.3 steps/s
[Step=60850 Epoch=114.7] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.614 | L2-Norm(final)=12.774 | 4566.1 samples/s | 71.3 steps/s
[Step=60900 Epoch=114.8] | Loss=0.00002 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.611 | L2-Norm(final)=12.775 | 4622.3 samples/s | 72.2 steps/s
[Step=60950 Epoch=114.9] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.609 | L2-Norm(final)=12.775 | 4583.3 samples/s | 71.6 steps/s
[Step=61000 Epoch=115.0] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.606 | L2-Norm(final)=12.775 | 4448.9 samples/s | 69.5 steps/s
[Step=61050 Epoch=115.1] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.603 | L2-Norm(final)=12.775 | 2073.3 samples/s | 32.4 steps/s
[Step=61100 Epoch=115.2] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.601 | L2-Norm(final)=12.776 | 4692.5 samples/s | 73.3 steps/s
[Step=61150 Epoch=115.3] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.598 | L2-Norm(final)=12.776 | 4476.0 samples/s | 69.9 steps/s
[Step=61200 Epoch=115.4] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.595 | L2-Norm(final)=12.776 | 4521.7 samples/s | 70.7 steps/s
[Step=61250 Epoch=115.5] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.592 | L2-Norm(final)=12.776 | 4509.9 samples/s | 70.5 steps/s
[Step=61300 Epoch=115.6] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.589 | L2-Norm(final)=12.777 | 4541.5 samples/s | 71.0 steps/s
[Step=61350 Epoch=115.6] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.587 | L2-Norm(final)=12.777 | 4549.3 samples/s | 71.1 steps/s
[Step=61400 Epoch=115.7] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.584 | L2-Norm(final)=12.777 | 4549.0 samples/s | 71.1 steps/s
[Step=61450 Epoch=115.8] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.581 | L2-Norm(final)=12.777 | 4514.2 samples/s | 70.5 steps/s
[Step=61500 Epoch=115.9] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.577 | L2-Norm(final)=12.777 | 4571.3 samples/s | 71.4 steps/s
[Step=61550 Epoch=116.0] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.574 | L2-Norm(final)=12.778 | 5627.6 samples/s | 87.9 steps/s
[Step=61600 Epoch=116.1] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.571 | L2-Norm(final)=12.778 | 1946.9 samples/s | 30.4 steps/s
[Step=61650 Epoch=116.2] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.568 | L2-Norm(final)=12.778 | 4549.9 samples/s | 71.1 steps/s
[Step=61700 Epoch=116.3] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=12.778 | 4564.0 samples/s | 71.3 steps/s
[Step=61750 Epoch=116.4] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.778 | 4722.2 samples/s | 73.8 steps/s
[Step=61800 Epoch=116.5] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.558 | L2-Norm(final)=12.779 | 4610.2 samples/s | 72.0 steps/s
[Step=61850 Epoch=116.6] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.555 | L2-Norm(final)=12.779 | 4731.2 samples/s | 73.9 steps/s
[Step=61900 Epoch=116.7] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.552 | L2-Norm(final)=12.779 | 4637.8 samples/s | 72.5 steps/s
[Step=61950 Epoch=116.8] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.548 | L2-Norm(final)=12.779 | 4672.0 samples/s | 73.0 steps/s
[Step=62000 Epoch=116.9] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.545 | L2-Norm(final)=12.779 | 4562.6 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06950 | acc=0.9741 | tpr=0.9811 | fpr=0.0411 | 4712.0 samples/s | 18.4 steps/s
Avg test loss: 0.07743, Avg test acc: 0.97243, Avg tpr: 0.98042, Avg fpr: 0.04512, total FA: 352

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.01768 | acc=0.2932 | tpr=0.0240 | fpr=0.1222 | 4590.1 samples/s | 17.9 steps/s
Avg test loss: 5.01418, Avg test acc: 0.29061, Avg tpr: 0.02425, Avg fpr: 0.12357, total FA: 964

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.46303 | acc=0.1234 | tpr=0.4735 | fpr=0.8829 | 4620.0 samples/s | 18.0 steps/s
[Step= 100] | Loss=7.41335 | acc=0.1223 | tpr=0.4520 | fpr=0.8839 | 8645.1 samples/s | 33.8 steps/s
[Step= 150] | Loss=7.41504 | acc=0.1223 | tpr=0.4683 | fpr=0.8841 | 8562.8 samples/s | 33.4 steps/s
[Step= 200] | Loss=7.40309 | acc=0.1221 | tpr=0.4667 | fpr=0.8842 | 8226.5 samples/s | 32.1 steps/s
[Step= 250] | Loss=7.40466 | acc=0.1222 | tpr=0.4681 | fpr=0.8841 | 8620.1 samples/s | 33.7 steps/s
[Step= 300] | Loss=7.40273 | acc=0.1224 | tpr=0.4742 | fpr=0.8840 | 8389.1 samples/s | 32.8 steps/s
[Step= 350] | Loss=7.39941 | acc=0.1219 | tpr=0.4809 | fpr=0.8847 | 8580.0 samples/s | 33.5 steps/s
[Step= 400] | Loss=7.39932 | acc=0.1222 | tpr=0.4830 | fpr=0.8843 | 8291.8 samples/s | 32.4 steps/s
[Step= 450] | Loss=7.40069 | acc=0.1222 | tpr=0.4810 | fpr=0.8843 | 8863.3 samples/s | 34.6 steps/s
[Step= 500] | Loss=7.40396 | acc=0.1224 | tpr=0.4802 | fpr=0.8841 | 8052.4 samples/s | 31.5 steps/s
[Step= 550] | Loss=7.40481 | acc=0.1226 | tpr=0.4811 | fpr=0.8840 | 15732.2 samples/s | 61.5 steps/s
Avg test loss: 7.40636, Avg test acc: 0.12242, Avg tpr: 0.48098, Avg fpr: 0.88410, total FA: 122755

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12909 | acc=0.9821 | tpr=0.9469 | fpr=0.0173 | 4595.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.13599 | acc=0.9814 | tpr=0.9531 | fpr=0.0181 | 8493.3 samples/s | 33.2 steps/s
[Step= 150] | Loss=0.14016 | acc=0.9808 | tpr=0.9553 | fpr=0.0187 | 8382.1 samples/s | 32.7 steps/s
[Step= 200] | Loss=0.14169 | acc=0.9809 | tpr=0.9596 | fpr=0.0187 | 8232.3 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.13954 | acc=0.9812 | tpr=0.9581 | fpr=0.0184 | 8923.8 samples/s | 34.9 steps/s
[Step= 300] | Loss=0.14226 | acc=0.9810 | tpr=0.9585 | fpr=0.0186 | 8214.4 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.14465 | acc=0.9808 | tpr=0.9580 | fpr=0.0188 | 8334.5 samples/s | 32.6 steps/s
[Step= 400] | Loss=0.14544 | acc=0.9807 | tpr=0.9573 | fpr=0.0189 | 8692.3 samples/s | 34.0 steps/s
[Step= 450] | Loss=0.14875 | acc=0.9803 | tpr=0.9542 | fpr=0.0192 | 8321.7 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.14769 | acc=0.9803 | tpr=0.9537 | fpr=0.0192 | 8801.6 samples/s | 34.4 steps/s
[Step= 550] | Loss=0.14660 | acc=0.9804 | tpr=0.9530 | fpr=0.0191 | 14319.8 samples/s | 55.9 steps/s
Avg test loss: 0.14648, Avg test acc: 0.98047, Avg tpr: 0.95285, Avg fpr: 0.01903, total FA: 2642

server round 31/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=62001 Epoch=60.5] | Loss=0.00089 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.259 | 4223.5 samples/s | 66.0 steps/s
[Step=62050 Epoch=60.6] | Loss=0.00620 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.261 | 5516.2 samples/s | 86.2 steps/s
[Step=62100 Epoch=60.6] | Loss=0.00700 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.264 | 5560.6 samples/s | 86.9 steps/s
[Step=62150 Epoch=60.7] | Loss=0.00699 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.268 | 5489.7 samples/s | 85.8 steps/s
[Step=62200 Epoch=60.7] | Loss=0.00694 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.562 | L2-Norm(final)=12.272 | 5442.2 samples/s | 85.0 steps/s
[Step=62250 Epoch=60.8] | Loss=0.00706 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.562 | L2-Norm(final)=12.275 | 5561.2 samples/s | 86.9 steps/s
[Step=62300 Epoch=60.8] | Loss=0.00718 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.279 | 5508.0 samples/s | 86.1 steps/s
[Step=62350 Epoch=60.9] | Loss=0.00720 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.562 | L2-Norm(final)=12.282 | 5529.4 samples/s | 86.4 steps/s
[Step=62400 Epoch=60.9] | Loss=0.00729 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.562 | L2-Norm(final)=12.286 | 5534.4 samples/s | 86.5 steps/s
[Step=62450 Epoch=61.0] | Loss=0.00742 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.562 | L2-Norm(final)=12.290 | 5538.2 samples/s | 86.5 steps/s
[Step=62500 Epoch=61.0] | Loss=0.00726 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.562 | L2-Norm(final)=12.294 | 5500.8 samples/s | 85.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=61.0] | Loss=0.00589 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.562 | L2-Norm(final)=12.334 | 4114.4 samples/s | 64.3 steps/s
[Step=62550 Epoch=61.1] | Loss=0.00920 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.565 | L2-Norm(final)=12.336 | 4727.6 samples/s | 73.9 steps/s
[Step=62600 Epoch=61.1] | Loss=0.00761 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.568 | L2-Norm(final)=12.338 | 4718.2 samples/s | 73.7 steps/s
[Step=62650 Epoch=61.2] | Loss=0.00756 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.571 | L2-Norm(final)=12.339 | 4785.9 samples/s | 74.8 steps/s
[Step=62700 Epoch=61.2] | Loss=0.00719 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.573 | L2-Norm(final)=12.340 | 4743.6 samples/s | 74.1 steps/s
[Step=62750 Epoch=61.3] | Loss=0.00733 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.574 | L2-Norm(final)=12.341 | 4708.0 samples/s | 73.6 steps/s
[Step=62800 Epoch=61.3] | Loss=0.00747 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.576 | L2-Norm(final)=12.341 | 4771.9 samples/s | 74.6 steps/s
[Step=62850 Epoch=61.4] | Loss=0.00738 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.577 | L2-Norm(final)=12.342 | 4826.5 samples/s | 75.4 steps/s
[Step=62900 Epoch=61.4] | Loss=0.00756 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=12.343 | 4742.9 samples/s | 74.1 steps/s
[Step=62950 Epoch=61.5] | Loss=0.00758 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.581 | L2-Norm(final)=12.343 | 4846.1 samples/s | 75.7 steps/s
[Step=63000 Epoch=61.5] | Loss=0.00742 | Reg=0.00184 | acc=0.9844 | L2-Norm=13.582 | L2-Norm(final)=12.344 | 4823.2 samples/s | 75.4 steps/s
[Step=63050 Epoch=61.6] | Loss=0.00746 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.584 | L2-Norm(final)=12.345 | 4827.3 samples/s | 75.4 steps/s
[Step=63100 Epoch=61.6] | Loss=0.00752 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.585 | L2-Norm(final)=12.346 | 4835.6 samples/s | 75.6 steps/s
[Step=63150 Epoch=61.7] | Loss=0.00757 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.586 | L2-Norm(final)=12.346 | 4813.6 samples/s | 75.2 steps/s
[Step=63200 Epoch=61.7] | Loss=0.00752 | Reg=0.00185 | acc=0.9688 | L2-Norm=13.588 | L2-Norm(final)=12.347 | 4792.9 samples/s | 74.9 steps/s
[Step=63250 Epoch=61.8] | Loss=0.00767 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.589 | L2-Norm(final)=12.348 | 4797.1 samples/s | 75.0 steps/s
[Step=63300 Epoch=61.8] | Loss=0.00761 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.590 | L2-Norm(final)=12.349 | 4776.1 samples/s | 74.6 steps/s
[Step=63350 Epoch=61.9] | Loss=0.00764 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.591 | L2-Norm(final)=12.349 | 4854.7 samples/s | 75.9 steps/s
[Step=63400 Epoch=61.9] | Loss=0.00760 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.592 | L2-Norm(final)=12.350 | 4763.4 samples/s | 74.4 steps/s
[Step=63450 Epoch=61.9] | Loss=0.00752 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.594 | L2-Norm(final)=12.351 | 4711.4 samples/s | 73.6 steps/s
[Step=63500 Epoch=62.0] | Loss=0.00749 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.595 | L2-Norm(final)=12.352 | 5160.1 samples/s | 80.6 steps/s
[Step=63550 Epoch=62.0] | Loss=0.00738 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.596 | L2-Norm(final)=12.353 | 2124.6 samples/s | 33.2 steps/s
[Step=63600 Epoch=62.1] | Loss=0.00729 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.597 | L2-Norm(final)=12.354 | 4825.2 samples/s | 75.4 steps/s
[Step=63650 Epoch=62.1] | Loss=0.00724 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.598 | L2-Norm(final)=12.355 | 4714.4 samples/s | 73.7 steps/s
[Step=63700 Epoch=62.2] | Loss=0.00720 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.599 | L2-Norm(final)=12.356 | 4776.4 samples/s | 74.6 steps/s
[Step=63750 Epoch=62.2] | Loss=0.00708 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.600 | L2-Norm(final)=12.357 | 4773.7 samples/s | 74.6 steps/s
[Step=63800 Epoch=62.3] | Loss=0.00705 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.601 | L2-Norm(final)=12.358 | 4850.6 samples/s | 75.8 steps/s
[Step=63850 Epoch=62.3] | Loss=0.00700 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.603 | L2-Norm(final)=12.359 | 4746.3 samples/s | 74.2 steps/s
[Step=63900 Epoch=62.4] | Loss=0.00708 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.603 | L2-Norm(final)=12.360 | 4776.6 samples/s | 74.6 steps/s
[Step=63950 Epoch=62.4] | Loss=0.00709 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.604 | L2-Norm(final)=12.361 | 4793.4 samples/s | 74.9 steps/s
[Step=64000 Epoch=62.5] | Loss=0.00712 | Reg=0.00185 | acc=0.9844 | L2-Norm=13.605 | L2-Norm(final)=12.362 | 4872.2 samples/s | 76.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step64000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=62001 Epoch=116.9] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.562 | L2-Norm(final)=12.786 | 4075.1 samples/s | 63.7 steps/s
[Step=62050 Epoch=117.0] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.561 | L2-Norm(final)=12.786 | 4912.2 samples/s | 76.8 steps/s
[Step=62100 Epoch=117.1] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.787 | 5176.7 samples/s | 80.9 steps/s
[Step=62150 Epoch=117.2] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.787 | 5172.5 samples/s | 80.8 steps/s
[Step=62200 Epoch=117.2] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.787 | 5227.6 samples/s | 81.7 steps/s
[Step=62250 Epoch=117.3] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.788 | 5064.0 samples/s | 79.1 steps/s
[Step=62300 Epoch=117.4] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.789 | 5216.7 samples/s | 81.5 steps/s
[Step=62350 Epoch=117.5] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.789 | 5214.6 samples/s | 81.5 steps/s
[Step=62400 Epoch=117.6] | Loss=0.00002 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.790 | 5207.3 samples/s | 81.4 steps/s
[Step=62450 Epoch=117.7] | Loss=0.00003 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.791 | 5253.2 samples/s | 82.1 steps/s
[Step=62500 Epoch=117.8] | Loss=0.00003 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.792 | 5165.3 samples/s | 80.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=117.8] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.560 | L2-Norm(final)=12.802 | 4248.3 samples/s | 66.4 steps/s
[Step=62550 Epoch=117.9] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.555 | L2-Norm(final)=12.803 | 4259.0 samples/s | 66.5 steps/s
[Step=62600 Epoch=118.0] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.550 | L2-Norm(final)=12.804 | 4556.4 samples/s | 71.2 steps/s
[Step=62650 Epoch=118.1] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.544 | L2-Norm(final)=12.805 | 4540.2 samples/s | 70.9 steps/s
[Step=62700 Epoch=118.2] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.538 | L2-Norm(final)=12.805 | 4502.2 samples/s | 70.3 steps/s
[Step=62750 Epoch=118.3] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.532 | L2-Norm(final)=12.806 | 4596.4 samples/s | 71.8 steps/s
[Step=62800 Epoch=118.4] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.526 | L2-Norm(final)=12.806 | 4540.3 samples/s | 70.9 steps/s
[Step=62850 Epoch=118.5] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.520 | L2-Norm(final)=12.807 | 4568.5 samples/s | 71.4 steps/s
[Step=62900 Epoch=118.6] | Loss=0.00001 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=12.807 | 4618.7 samples/s | 72.2 steps/s
[Step=62950 Epoch=118.7] | Loss=0.00001 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.507 | L2-Norm(final)=12.807 | 4578.3 samples/s | 71.5 steps/s
[Step=63000 Epoch=118.8] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.501 | L2-Norm(final)=12.808 | 4617.2 samples/s | 72.1 steps/s
[Step=63050 Epoch=118.9] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.494 | L2-Norm(final)=12.808 | 2096.2 samples/s | 32.8 steps/s
[Step=63100 Epoch=118.9] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.487 | L2-Norm(final)=12.808 | 4578.7 samples/s | 71.5 steps/s
[Step=63150 Epoch=119.0] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.481 | L2-Norm(final)=12.809 | 4502.4 samples/s | 70.3 steps/s
[Step=63200 Epoch=119.1] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.474 | L2-Norm(final)=12.809 | 4561.5 samples/s | 71.3 steps/s
[Step=63250 Epoch=119.2] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.467 | L2-Norm(final)=12.809 | 4529.5 samples/s | 70.8 steps/s
[Step=63300 Epoch=119.3] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.460 | L2-Norm(final)=12.809 | 4555.7 samples/s | 71.2 steps/s
[Step=63350 Epoch=119.4] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.453 | L2-Norm(final)=12.810 | 4588.9 samples/s | 71.7 steps/s
[Step=63400 Epoch=119.5] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.446 | L2-Norm(final)=12.810 | 4489.1 samples/s | 70.1 steps/s
[Step=63450 Epoch=119.6] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.439 | L2-Norm(final)=12.810 | 4466.5 samples/s | 69.8 steps/s
[Step=63500 Epoch=119.7] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.431 | L2-Norm(final)=12.810 | 4549.1 samples/s | 71.1 steps/s
[Step=63550 Epoch=119.8] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.424 | L2-Norm(final)=12.810 | 5667.7 samples/s | 88.6 steps/s
[Step=63600 Epoch=119.9] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.417 | L2-Norm(final)=12.811 | 1969.2 samples/s | 30.8 steps/s
[Step=63650 Epoch=120.0] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.409 | L2-Norm(final)=12.811 | 4468.1 samples/s | 69.8 steps/s
[Step=63700 Epoch=120.1] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.401 | L2-Norm(final)=12.811 | 4591.6 samples/s | 71.7 steps/s
[Step=63750 Epoch=120.2] | Loss=0.00000 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.394 | L2-Norm(final)=12.811 | 4439.5 samples/s | 69.4 steps/s
[Step=63800 Epoch=120.3] | Loss=0.00000 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.386 | L2-Norm(final)=12.812 | 4526.8 samples/s | 70.7 steps/s
[Step=63850 Epoch=120.4] | Loss=0.00000 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.378 | L2-Norm(final)=12.812 | 4591.8 samples/s | 71.7 steps/s
[Step=63900 Epoch=120.5] | Loss=0.00000 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.370 | L2-Norm(final)=12.812 | 4567.0 samples/s | 71.4 steps/s
[Step=63950 Epoch=120.5] | Loss=0.00000 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.362 | L2-Norm(final)=12.812 | 4528.3 samples/s | 70.8 steps/s
[Step=64000 Epoch=120.6] | Loss=0.00000 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.353 | L2-Norm(final)=12.813 | 4526.4 samples/s | 70.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06883 | acc=0.9738 | tpr=0.9807 | fpr=0.0414 | 4497.5 samples/s | 17.6 steps/s
Avg test loss: 0.07640, Avg test acc: 0.97191, Avg tpr: 0.97896, Avg fpr: 0.04358, total FA: 340

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.20539 | acc=0.2896 | tpr=0.0236 | fpr=0.1328 | 4592.2 samples/s | 17.9 steps/s
Avg test loss: 5.20161, Avg test acc: 0.28740, Avg tpr: 0.02366, Avg fpr: 0.13255, total FA: 1034

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.81902 | acc=0.1291 | tpr=0.4646 | fpr=0.8770 | 4596.0 samples/s | 18.0 steps/s
[Step= 100] | Loss=6.76804 | acc=0.1289 | tpr=0.4371 | fpr=0.8768 | 8376.6 samples/s | 32.7 steps/s
[Step= 150] | Loss=6.76856 | acc=0.1294 | tpr=0.4409 | fpr=0.8763 | 8520.1 samples/s | 33.3 steps/s
[Step= 200] | Loss=6.75611 | acc=0.1289 | tpr=0.4350 | fpr=0.8766 | 9013.6 samples/s | 35.2 steps/s
[Step= 250] | Loss=6.75550 | acc=0.1290 | tpr=0.4367 | fpr=0.8766 | 8407.8 samples/s | 32.8 steps/s
[Step= 300] | Loss=6.75396 | acc=0.1289 | tpr=0.4407 | fpr=0.8768 | 8611.4 samples/s | 33.6 steps/s
[Step= 350] | Loss=6.75132 | acc=0.1284 | tpr=0.4452 | fpr=0.8773 | 7823.5 samples/s | 30.6 steps/s
[Step= 400] | Loss=6.75108 | acc=0.1289 | tpr=0.4469 | fpr=0.8769 | 8454.5 samples/s | 33.0 steps/s
[Step= 450] | Loss=6.75310 | acc=0.1290 | tpr=0.4474 | fpr=0.8768 | 8553.8 samples/s | 33.4 steps/s
[Step= 500] | Loss=6.75761 | acc=0.1292 | tpr=0.4454 | fpr=0.8765 | 8491.5 samples/s | 33.2 steps/s
[Step= 550] | Loss=6.75914 | acc=0.1293 | tpr=0.4473 | fpr=0.8765 | 15613.9 samples/s | 61.0 steps/s
Avg test loss: 6.76082, Avg test acc: 0.12916, Avg tpr: 0.44691, Avg fpr: 0.87662, total FA: 121717

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13570 | acc=0.9823 | tpr=0.9469 | fpr=0.0170 | 4648.9 samples/s | 18.2 steps/s
[Step= 100] | Loss=0.14356 | acc=0.9816 | tpr=0.9531 | fpr=0.0179 | 8529.9 samples/s | 33.3 steps/s
[Step= 150] | Loss=0.14846 | acc=0.9810 | tpr=0.9597 | fpr=0.0186 | 8738.0 samples/s | 34.1 steps/s
[Step= 200] | Loss=0.15005 | acc=0.9809 | tpr=0.9639 | fpr=0.0188 | 8685.0 samples/s | 33.9 steps/s
[Step= 250] | Loss=0.14815 | acc=0.9812 | tpr=0.9616 | fpr=0.0185 | 8520.9 samples/s | 33.3 steps/s
[Step= 300] | Loss=0.15082 | acc=0.9809 | tpr=0.9615 | fpr=0.0187 | 9099.2 samples/s | 35.5 steps/s
[Step= 350] | Loss=0.15327 | acc=0.9807 | tpr=0.9606 | fpr=0.0189 | 8029.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.15409 | acc=0.9806 | tpr=0.9590 | fpr=0.0190 | 8480.8 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.15756 | acc=0.9803 | tpr=0.9557 | fpr=0.0193 | 8523.3 samples/s | 33.3 steps/s
[Step= 500] | Loss=0.15658 | acc=0.9802 | tpr=0.9551 | fpr=0.0193 | 8563.1 samples/s | 33.4 steps/s
[Step= 550] | Loss=0.15536 | acc=0.9804 | tpr=0.9546 | fpr=0.0191 | 14979.6 samples/s | 58.5 steps/s
Avg test loss: 0.15518, Avg test acc: 0.98046, Avg tpr: 0.95444, Avg fpr: 0.01906, total FA: 2647

server round 32/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=64001 Epoch=62.5] | Loss=0.01838 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.355 | L2-Norm(final)=12.388 | 4310.2 samples/s | 67.3 steps/s
[Step=64050 Epoch=62.5] | Loss=0.00742 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.390 | 5217.7 samples/s | 81.5 steps/s
[Step=64100 Epoch=62.6] | Loss=0.00650 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.394 | 5527.4 samples/s | 86.4 steps/s
[Step=64150 Epoch=62.6] | Loss=0.00620 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.398 | 5480.2 samples/s | 85.6 steps/s
[Step=64200 Epoch=62.7] | Loss=0.00576 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.402 | 5598.1 samples/s | 87.5 steps/s
[Step=64250 Epoch=62.7] | Loss=0.00609 | Reg=0.00178 | acc=0.9688 | L2-Norm=13.355 | L2-Norm(final)=12.405 | 5492.7 samples/s | 85.8 steps/s
[Step=64300 Epoch=62.8] | Loss=0.00613 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.410 | 5407.8 samples/s | 84.5 steps/s
[Step=64350 Epoch=62.8] | Loss=0.00604 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.414 | 5526.5 samples/s | 86.4 steps/s
[Step=64400 Epoch=62.9] | Loss=0.00596 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.355 | L2-Norm(final)=12.418 | 5524.7 samples/s | 86.3 steps/s
[Step=64450 Epoch=62.9] | Loss=0.00588 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.422 | 5511.3 samples/s | 86.1 steps/s
[Step=64500 Epoch=63.0] | Loss=0.00593 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.426 | 5493.1 samples/s | 85.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=63.0] | Loss=0.00038 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.464 | 4275.8 samples/s | 66.8 steps/s
[Step=64550 Epoch=63.0] | Loss=0.00603 | Reg=0.00178 | acc=0.9844 | L2-Norm=13.358 | L2-Norm(final)=12.467 | 4519.9 samples/s | 70.6 steps/s
[Step=64600 Epoch=63.1] | Loss=0.00592 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.362 | L2-Norm(final)=12.469 | 4740.7 samples/s | 74.1 steps/s
[Step=64650 Epoch=63.1] | Loss=0.00602 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.365 | L2-Norm(final)=12.470 | 4789.4 samples/s | 74.8 steps/s
[Step=64700 Epoch=63.2] | Loss=0.00648 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.368 | L2-Norm(final)=12.472 | 4790.9 samples/s | 74.9 steps/s
[Step=64750 Epoch=63.2] | Loss=0.00643 | Reg=0.00179 | acc=0.9688 | L2-Norm=13.370 | L2-Norm(final)=12.473 | 4771.4 samples/s | 74.6 steps/s
[Step=64800 Epoch=63.3] | Loss=0.00644 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.372 | L2-Norm(final)=12.474 | 4778.8 samples/s | 74.7 steps/s
[Step=64850 Epoch=63.3] | Loss=0.00672 | Reg=0.00179 | acc=0.9688 | L2-Norm=13.374 | L2-Norm(final)=12.475 | 4744.3 samples/s | 74.1 steps/s
[Step=64900 Epoch=63.4] | Loss=0.00704 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.376 | L2-Norm(final)=12.476 | 4772.2 samples/s | 74.6 steps/s
[Step=64950 Epoch=63.4] | Loss=0.00708 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.378 | L2-Norm(final)=12.477 | 4754.6 samples/s | 74.3 steps/s
[Step=65000 Epoch=63.5] | Loss=0.00720 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.380 | L2-Norm(final)=12.477 | 4787.5 samples/s | 74.8 steps/s
[Step=65050 Epoch=63.5] | Loss=0.00724 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.381 | L2-Norm(final)=12.478 | 4762.8 samples/s | 74.4 steps/s
[Step=65100 Epoch=63.6] | Loss=0.00739 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.383 | L2-Norm(final)=12.478 | 4788.6 samples/s | 74.8 steps/s
[Step=65150 Epoch=63.6] | Loss=0.00745 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.384 | L2-Norm(final)=12.479 | 4801.1 samples/s | 75.0 steps/s
[Step=65200 Epoch=63.7] | Loss=0.00749 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.385 | L2-Norm(final)=12.479 | 4797.0 samples/s | 75.0 steps/s
[Step=65250 Epoch=63.7] | Loss=0.00747 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.387 | L2-Norm(final)=12.480 | 4780.4 samples/s | 74.7 steps/s
[Step=65300 Epoch=63.8] | Loss=0.00748 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.388 | L2-Norm(final)=12.481 | 4773.7 samples/s | 74.6 steps/s
[Step=65350 Epoch=63.8] | Loss=0.00734 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.390 | L2-Norm(final)=12.481 | 4815.4 samples/s | 75.2 steps/s
[Step=65400 Epoch=63.9] | Loss=0.00738 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.391 | L2-Norm(final)=12.482 | 4808.9 samples/s | 75.1 steps/s
[Step=65450 Epoch=63.9] | Loss=0.00743 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.392 | L2-Norm(final)=12.483 | 4763.7 samples/s | 74.4 steps/s
[Step=65500 Epoch=64.0] | Loss=0.00739 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.394 | L2-Norm(final)=12.484 | 5149.7 samples/s | 80.5 steps/s
[Step=65550 Epoch=64.0] | Loss=0.00734 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.395 | L2-Norm(final)=12.485 | 2138.6 samples/s | 33.4 steps/s
[Step=65600 Epoch=64.0] | Loss=0.00734 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.396 | L2-Norm(final)=12.485 | 4776.1 samples/s | 74.6 steps/s
[Step=65650 Epoch=64.1] | Loss=0.00728 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.397 | L2-Norm(final)=12.486 | 4792.1 samples/s | 74.9 steps/s
[Step=65700 Epoch=64.1] | Loss=0.00722 | Reg=0.00180 | acc=0.9844 | L2-Norm=13.399 | L2-Norm(final)=12.487 | 4759.5 samples/s | 74.4 steps/s
[Step=65750 Epoch=64.2] | Loss=0.00716 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.400 | L2-Norm(final)=12.488 | 4813.2 samples/s | 75.2 steps/s
[Step=65800 Epoch=64.2] | Loss=0.00706 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.401 | L2-Norm(final)=12.489 | 4759.3 samples/s | 74.4 steps/s
[Step=65850 Epoch=64.3] | Loss=0.00704 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.402 | L2-Norm(final)=12.490 | 4780.5 samples/s | 74.7 steps/s
[Step=65900 Epoch=64.3] | Loss=0.00707 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.403 | L2-Norm(final)=12.491 | 4769.8 samples/s | 74.5 steps/s
[Step=65950 Epoch=64.4] | Loss=0.00696 | Reg=0.00180 | acc=0.9844 | L2-Norm=13.404 | L2-Norm(final)=12.492 | 4805.0 samples/s | 75.1 steps/s
[Step=66000 Epoch=64.4] | Loss=0.00699 | Reg=0.00180 | acc=0.9688 | L2-Norm=13.405 | L2-Norm(final)=12.493 | 4821.1 samples/s | 75.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step66000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=64001 Epoch=120.6] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=12.820 | 4050.7 samples/s | 63.3 steps/s
[Step=64050 Epoch=120.7] | Loss=0.00006 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.352 | L2-Norm(final)=12.823 | 5156.6 samples/s | 80.6 steps/s
[Step=64100 Epoch=120.8] | Loss=0.00004 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.352 | L2-Norm(final)=12.826 | 5304.7 samples/s | 82.9 steps/s
[Step=64150 Epoch=120.9] | Loss=0.00003 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.828 | 5163.3 samples/s | 80.7 steps/s
[Step=64200 Epoch=121.0] | Loss=0.00003 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.830 | 5215.3 samples/s | 81.5 steps/s
[Step=64250 Epoch=121.1] | Loss=0.00003 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.832 | 5141.5 samples/s | 80.3 steps/s
[Step=64300 Epoch=121.2] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.834 | 5189.7 samples/s | 81.1 steps/s
[Step=64350 Epoch=121.3] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.836 | 5239.6 samples/s | 81.9 steps/s
[Step=64400 Epoch=121.4] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.837 | 5144.2 samples/s | 80.4 steps/s
[Step=64450 Epoch=121.5] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.839 | 5163.9 samples/s | 80.7 steps/s
[Step=64500 Epoch=121.6] | Loss=0.00002 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.841 | 5290.0 samples/s | 82.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=121.6] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.351 | L2-Norm(final)=12.858 | 4088.1 samples/s | 63.9 steps/s
[Step=64550 Epoch=121.7] | Loss=0.00000 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.341 | L2-Norm(final)=12.859 | 4425.9 samples/s | 69.2 steps/s
[Step=64600 Epoch=121.8] | Loss=0.00000 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.328 | L2-Norm(final)=12.860 | 4521.5 samples/s | 70.6 steps/s
[Step=64650 Epoch=121.9] | Loss=0.00000 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.314 | L2-Norm(final)=12.861 | 4533.6 samples/s | 70.8 steps/s
[Step=64700 Epoch=122.0] | Loss=0.00000 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.300 | L2-Norm(final)=12.862 | 4527.1 samples/s | 70.7 steps/s
[Step=64750 Epoch=122.1] | Loss=0.00000 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.285 | L2-Norm(final)=12.863 | 4551.8 samples/s | 71.1 steps/s
[Step=64800 Epoch=122.1] | Loss=0.00000 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.271 | L2-Norm(final)=12.864 | 4545.6 samples/s | 71.0 steps/s
[Step=64850 Epoch=122.2] | Loss=0.00000 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.256 | L2-Norm(final)=12.864 | 4680.4 samples/s | 73.1 steps/s
[Step=64900 Epoch=122.3] | Loss=0.00000 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.241 | L2-Norm(final)=12.865 | 4475.8 samples/s | 69.9 steps/s
[Step=64950 Epoch=122.4] | Loss=0.00000 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.227 | L2-Norm(final)=12.865 | 4557.1 samples/s | 71.2 steps/s
[Step=65000 Epoch=122.5] | Loss=0.00000 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.211 | L2-Norm(final)=12.865 | 4594.1 samples/s | 71.8 steps/s
[Step=65050 Epoch=122.6] | Loss=0.00000 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.196 | L2-Norm(final)=12.866 | 2111.2 samples/s | 33.0 steps/s
[Step=65100 Epoch=122.7] | Loss=0.00000 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.181 | L2-Norm(final)=12.866 | 4586.5 samples/s | 71.7 steps/s
[Step=65150 Epoch=122.8] | Loss=0.00000 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.165 | L2-Norm(final)=12.866 | 4443.6 samples/s | 69.4 steps/s
[Step=65200 Epoch=122.9] | Loss=0.00000 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.150 | L2-Norm(final)=12.867 | 4553.3 samples/s | 71.1 steps/s
[Step=65250 Epoch=123.0] | Loss=0.00000 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.134 | L2-Norm(final)=12.867 | 4541.8 samples/s | 71.0 steps/s
[Step=65300 Epoch=123.1] | Loss=0.00000 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.118 | L2-Norm(final)=12.867 | 4580.8 samples/s | 71.6 steps/s
[Step=65350 Epoch=123.2] | Loss=0.00000 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.102 | L2-Norm(final)=12.868 | 4663.0 samples/s | 72.9 steps/s
[Step=65400 Epoch=123.3] | Loss=0.00000 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.086 | L2-Norm(final)=12.868 | 4589.9 samples/s | 71.7 steps/s
[Step=65450 Epoch=123.4] | Loss=0.00000 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.069 | L2-Norm(final)=12.868 | 4606.1 samples/s | 72.0 steps/s
[Step=65500 Epoch=123.5] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.053 | L2-Norm(final)=12.869 | 4546.0 samples/s | 71.0 steps/s
[Step=65550 Epoch=123.6] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.036 | L2-Norm(final)=12.869 | 5731.9 samples/s | 89.6 steps/s
[Step=65600 Epoch=123.7] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.019 | L2-Norm(final)=12.869 | 1963.1 samples/s | 30.7 steps/s
[Step=65650 Epoch=123.8] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.002 | L2-Norm(final)=12.869 | 4488.9 samples/s | 70.1 steps/s
[Step=65700 Epoch=123.8] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.985 | L2-Norm(final)=12.870 | 4553.0 samples/s | 71.1 steps/s
[Step=65750 Epoch=123.9] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.968 | L2-Norm(final)=12.870 | 4558.4 samples/s | 71.2 steps/s
[Step=65800 Epoch=124.0] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.950 | L2-Norm(final)=12.870 | 4528.2 samples/s | 70.8 steps/s
[Step=65850 Epoch=124.1] | Loss=0.00000 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.933 | L2-Norm(final)=12.871 | 4535.2 samples/s | 70.9 steps/s
[Step=65900 Epoch=124.2] | Loss=0.00000 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.915 | L2-Norm(final)=12.871 | 4519.8 samples/s | 70.6 steps/s
[Step=65950 Epoch=124.3] | Loss=0.00000 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.897 | L2-Norm(final)=12.871 | 4558.4 samples/s | 71.2 steps/s
[Step=66000 Epoch=124.4] | Loss=0.00000 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.879 | L2-Norm(final)=12.872 | 4548.2 samples/s | 71.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06597 | acc=0.9736 | tpr=0.9782 | fpr=0.0364 | 4553.2 samples/s | 17.8 steps/s
Avg test loss: 0.07444, Avg test acc: 0.97215, Avg tpr: 0.97733, Avg fpr: 0.03923, total FA: 306

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.24890 | acc=0.2859 | tpr=0.0237 | fpr=0.1449 | 4609.9 samples/s | 18.0 steps/s
Avg test loss: 5.24668, Avg test acc: 0.28304, Avg tpr: 0.02366, Avg fpr: 0.14652, total FA: 1143

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.69263 | acc=0.1283 | tpr=0.4425 | fpr=0.8774 | 4583.9 samples/s | 17.9 steps/s
[Step= 100] | Loss=6.63826 | acc=0.1283 | tpr=0.4072 | fpr=0.8769 | 8207.7 samples/s | 32.1 steps/s
[Step= 150] | Loss=6.64121 | acc=0.1283 | tpr=0.4207 | fpr=0.8771 | 8487.4 samples/s | 33.2 steps/s
[Step= 200] | Loss=6.62907 | acc=0.1280 | tpr=0.4164 | fpr=0.8772 | 8581.6 samples/s | 33.5 steps/s
[Step= 250] | Loss=6.62884 | acc=0.1284 | tpr=0.4218 | fpr=0.8769 | 8406.0 samples/s | 32.8 steps/s
[Step= 300] | Loss=6.62693 | acc=0.1285 | tpr=0.4269 | fpr=0.8770 | 9097.2 samples/s | 35.5 steps/s
[Step= 350] | Loss=6.62332 | acc=0.1278 | tpr=0.4296 | fpr=0.8777 | 8323.4 samples/s | 32.5 steps/s
[Step= 400] | Loss=6.62266 | acc=0.1282 | tpr=0.4289 | fpr=0.8773 | 8114.4 samples/s | 31.7 steps/s
[Step= 450] | Loss=6.62425 | acc=0.1281 | tpr=0.4289 | fpr=0.8774 | 8693.6 samples/s | 34.0 steps/s
[Step= 500] | Loss=6.62884 | acc=0.1284 | tpr=0.4286 | fpr=0.8770 | 8294.8 samples/s | 32.4 steps/s
[Step= 550] | Loss=6.63034 | acc=0.1288 | tpr=0.4310 | fpr=0.8767 | 15181.1 samples/s | 59.3 steps/s
Avg test loss: 6.63168, Avg test acc: 0.12861, Avg tpr: 0.43067, Avg fpr: 0.87688, total FA: 121753

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13695 | acc=0.9826 | tpr=0.9469 | fpr=0.0168 | 4606.0 samples/s | 18.0 steps/s
[Step= 100] | Loss=0.14482 | acc=0.9818 | tpr=0.9531 | fpr=0.0177 | 8633.9 samples/s | 33.7 steps/s
[Step= 150] | Loss=0.15057 | acc=0.9809 | tpr=0.9611 | fpr=0.0187 | 8453.9 samples/s | 33.0 steps/s
[Step= 200] | Loss=0.15224 | acc=0.9808 | tpr=0.9661 | fpr=0.0189 | 8490.6 samples/s | 33.2 steps/s
[Step= 250] | Loss=0.15049 | acc=0.9810 | tpr=0.9633 | fpr=0.0187 | 8944.6 samples/s | 34.9 steps/s
[Step= 300] | Loss=0.15307 | acc=0.9808 | tpr=0.9629 | fpr=0.0189 | 8562.7 samples/s | 33.4 steps/s
[Step= 350] | Loss=0.15557 | acc=0.9804 | tpr=0.9624 | fpr=0.0192 | 8581.0 samples/s | 33.5 steps/s
[Step= 400] | Loss=0.15651 | acc=0.9804 | tpr=0.9612 | fpr=0.0193 | 8732.6 samples/s | 34.1 steps/s
[Step= 450] | Loss=0.16007 | acc=0.9801 | tpr=0.9581 | fpr=0.0195 | 8586.6 samples/s | 33.5 steps/s
[Step= 500] | Loss=0.15911 | acc=0.9801 | tpr=0.9573 | fpr=0.0195 | 8336.8 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.15789 | acc=0.9802 | tpr=0.9566 | fpr=0.0194 | 14971.7 samples/s | 58.5 steps/s
Avg test loss: 0.15770, Avg test acc: 0.98022, Avg tpr: 0.95642, Avg fpr: 0.01934, total FA: 2686

server round 33/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=66001 Epoch=64.4] | Loss=0.00109 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.859 | L2-Norm(final)=12.521 | 4496.2 samples/s | 70.3 steps/s
[Step=66050 Epoch=64.5] | Loss=0.00599 | Reg=0.00165 | acc=0.9844 | L2-Norm=12.859 | L2-Norm(final)=12.524 | 5054.5 samples/s | 79.0 steps/s
[Step=66100 Epoch=64.5] | Loss=0.00633 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.529 | 5577.9 samples/s | 87.2 steps/s
[Step=66150 Epoch=64.6] | Loss=0.00615 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.533 | 5606.5 samples/s | 87.6 steps/s
[Step=66200 Epoch=64.6] | Loss=0.00617 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.538 | 5504.1 samples/s | 86.0 steps/s
[Step=66250 Epoch=64.7] | Loss=0.00609 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.542 | 5437.3 samples/s | 85.0 steps/s
[Step=66300 Epoch=64.7] | Loss=0.00583 | Reg=0.00165 | acc=0.9844 | L2-Norm=12.860 | L2-Norm(final)=12.546 | 5523.7 samples/s | 86.3 steps/s
[Step=66350 Epoch=64.8] | Loss=0.00600 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.551 | 5499.1 samples/s | 85.9 steps/s
[Step=66400 Epoch=64.8] | Loss=0.00609 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.555 | 5593.1 samples/s | 87.4 steps/s
[Step=66450 Epoch=64.9] | Loss=0.00608 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.560 | 5441.4 samples/s | 85.0 steps/s
[Step=66500 Epoch=64.9] | Loss=0.00602 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.564 | 5521.3 samples/s | 86.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=64.9] | Loss=0.00234 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=12.606 | 4429.0 samples/s | 69.2 steps/s
[Step=66550 Epoch=65.0] | Loss=0.00711 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.864 | L2-Norm(final)=12.609 | 4582.5 samples/s | 71.6 steps/s
[Step=66600 Epoch=65.0] | Loss=0.00661 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.870 | L2-Norm(final)=12.611 | 4861.0 samples/s | 76.0 steps/s
[Step=66650 Epoch=65.1] | Loss=0.00702 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.875 | L2-Norm(final)=12.613 | 4910.2 samples/s | 76.7 steps/s
[Step=66700 Epoch=65.1] | Loss=0.00756 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.878 | L2-Norm(final)=12.615 | 4862.8 samples/s | 76.0 steps/s
[Step=66750 Epoch=65.2] | Loss=0.00750 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.882 | L2-Norm(final)=12.616 | 4909.4 samples/s | 76.7 steps/s
[Step=66800 Epoch=65.2] | Loss=0.00731 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.885 | L2-Norm(final)=12.617 | 4912.5 samples/s | 76.8 steps/s
[Step=66850 Epoch=65.3] | Loss=0.00747 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.888 | L2-Norm(final)=12.618 | 4710.2 samples/s | 73.6 steps/s
[Step=66900 Epoch=65.3] | Loss=0.00746 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=12.619 | 4821.4 samples/s | 75.3 steps/s
[Step=66950 Epoch=65.4] | Loss=0.00771 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.893 | L2-Norm(final)=12.620 | 4769.7 samples/s | 74.5 steps/s
[Step=67000 Epoch=65.4] | Loss=0.00765 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.895 | L2-Norm(final)=12.622 | 4785.0 samples/s | 74.8 steps/s
[Step=67050 Epoch=65.5] | Loss=0.00764 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.898 | L2-Norm(final)=12.623 | 4801.5 samples/s | 75.0 steps/s
[Step=67100 Epoch=65.5] | Loss=0.00755 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.900 | L2-Norm(final)=12.625 | 4768.0 samples/s | 74.5 steps/s
[Step=67150 Epoch=65.6] | Loss=0.00740 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.902 | L2-Norm(final)=12.626 | 4755.6 samples/s | 74.3 steps/s
[Step=67200 Epoch=65.6] | Loss=0.00749 | Reg=0.00167 | acc=0.9531 | L2-Norm=12.905 | L2-Norm(final)=12.628 | 4822.0 samples/s | 75.3 steps/s
[Step=67250 Epoch=65.7] | Loss=0.00758 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.907 | L2-Norm(final)=12.629 | 4771.4 samples/s | 74.6 steps/s
[Step=67300 Epoch=65.7] | Loss=0.00761 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.909 | L2-Norm(final)=12.630 | 4769.9 samples/s | 74.5 steps/s
[Step=67350 Epoch=65.8] | Loss=0.00760 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.911 | L2-Norm(final)=12.632 | 4768.6 samples/s | 74.5 steps/s
[Step=67400 Epoch=65.8] | Loss=0.00759 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.912 | L2-Norm(final)=12.633 | 4782.7 samples/s | 74.7 steps/s
[Step=67450 Epoch=65.9] | Loss=0.00762 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.914 | L2-Norm(final)=12.635 | 4791.2 samples/s | 74.9 steps/s
[Step=67500 Epoch=65.9] | Loss=0.00773 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.916 | L2-Norm(final)=12.636 | 5071.3 samples/s | 79.2 steps/s
[Step=67550 Epoch=66.0] | Loss=0.00765 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.918 | L2-Norm(final)=12.637 | 2170.1 samples/s | 33.9 steps/s
[Step=67600 Epoch=66.0] | Loss=0.00761 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.919 | L2-Norm(final)=12.638 | 4909.9 samples/s | 76.7 steps/s
[Step=67650 Epoch=66.0] | Loss=0.00756 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.921 | L2-Norm(final)=12.640 | 4883.9 samples/s | 76.3 steps/s
[Step=67700 Epoch=66.1] | Loss=0.00750 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.923 | L2-Norm(final)=12.641 | 4863.1 samples/s | 76.0 steps/s
[Step=67750 Epoch=66.1] | Loss=0.00747 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.924 | L2-Norm(final)=12.642 | 4878.9 samples/s | 76.2 steps/s
[Step=67800 Epoch=66.2] | Loss=0.00741 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=12.644 | 4930.2 samples/s | 77.0 steps/s
[Step=67850 Epoch=66.2] | Loss=0.00744 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.927 | L2-Norm(final)=12.645 | 4886.5 samples/s | 76.4 steps/s
[Step=67900 Epoch=66.3] | Loss=0.00749 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.929 | L2-Norm(final)=12.646 | 4792.1 samples/s | 74.9 steps/s
[Step=67950 Epoch=66.3] | Loss=0.00752 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.930 | L2-Norm(final)=12.647 | 4769.5 samples/s | 74.5 steps/s
[Step=68000 Epoch=66.4] | Loss=0.00755 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.932 | L2-Norm(final)=12.649 | 4791.8 samples/s | 74.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step68000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=66001 Epoch=124.4] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.859 | L2-Norm(final)=12.882 | 4217.9 samples/s | 65.9 steps/s
[Step=66050 Epoch=124.5] | Loss=0.00012 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.852 | L2-Norm(final)=12.888 | 4905.3 samples/s | 76.6 steps/s
[Step=66100 Epoch=124.6] | Loss=0.00008 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.852 | L2-Norm(final)=12.895 | 5278.6 samples/s | 82.5 steps/s
[Step=66150 Epoch=124.7] | Loss=0.00008 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.901 | 5250.6 samples/s | 82.0 steps/s
[Step=66200 Epoch=124.8] | Loss=0.00006 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.905 | 5076.3 samples/s | 79.3 steps/s
[Step=66250 Epoch=124.9] | Loss=0.00006 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.908 | 5267.2 samples/s | 82.3 steps/s
[Step=66300 Epoch=125.0] | Loss=0.00005 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.911 | 5106.3 samples/s | 79.8 steps/s
[Step=66350 Epoch=125.1] | Loss=0.00005 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.914 | 5225.9 samples/s | 81.7 steps/s
[Step=66400 Epoch=125.2] | Loss=0.00005 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.916 | 5157.8 samples/s | 80.6 steps/s
[Step=66450 Epoch=125.3] | Loss=0.00005 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.919 | 5482.1 samples/s | 85.7 steps/s
[Step=66500 Epoch=125.4] | Loss=0.00004 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.922 | 5437.1 samples/s | 85.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=125.4] | Loss=0.00002 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.851 | L2-Norm(final)=12.945 | 4182.7 samples/s | 65.4 steps/s
[Step=66550 Epoch=125.4] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.830 | L2-Norm(final)=12.946 | 4347.3 samples/s | 67.9 steps/s
[Step=66600 Epoch=125.5] | Loss=0.00000 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.801 | L2-Norm(final)=12.947 | 4644.3 samples/s | 72.6 steps/s
[Step=66650 Epoch=125.6] | Loss=0.00000 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.770 | L2-Norm(final)=12.947 | 4564.3 samples/s | 71.3 steps/s
[Step=66700 Epoch=125.7] | Loss=0.00000 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.738 | L2-Norm(final)=12.947 | 4581.1 samples/s | 71.6 steps/s
[Step=66750 Epoch=125.8] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.707 | L2-Norm(final)=12.947 | 4499.5 samples/s | 70.3 steps/s
[Step=66800 Epoch=125.9] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.676 | L2-Norm(final)=12.948 | 4549.0 samples/s | 71.1 steps/s
[Step=66850 Epoch=126.0] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.645 | L2-Norm(final)=12.948 | 4550.8 samples/s | 71.1 steps/s
[Step=66900 Epoch=126.1] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.613 | L2-Norm(final)=12.948 | 4579.8 samples/s | 71.6 steps/s
[Step=66950 Epoch=126.2] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.582 | L2-Norm(final)=12.948 | 4571.1 samples/s | 71.4 steps/s
[Step=67000 Epoch=126.3] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.550 | L2-Norm(final)=12.948 | 4572.2 samples/s | 71.4 steps/s
[Step=67050 Epoch=126.4] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.518 | L2-Norm(final)=12.949 | 2132.7 samples/s | 33.3 steps/s
[Step=67100 Epoch=126.5] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.486 | L2-Norm(final)=12.949 | 4583.4 samples/s | 71.6 steps/s
[Step=67150 Epoch=126.6] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.453 | L2-Norm(final)=12.949 | 4513.3 samples/s | 70.5 steps/s
[Step=67200 Epoch=126.7] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.421 | L2-Norm(final)=12.949 | 4556.5 samples/s | 71.2 steps/s
[Step=67250 Epoch=126.8] | Loss=0.00000 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.389 | L2-Norm(final)=12.949 | 4485.1 samples/s | 70.1 steps/s
[Step=67300 Epoch=126.9] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.357 | L2-Norm(final)=12.949 | 4649.4 samples/s | 72.6 steps/s
[Step=67350 Epoch=127.0] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.325 | L2-Norm(final)=12.949 | 4688.0 samples/s | 73.2 steps/s
[Step=67400 Epoch=127.0] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.292 | L2-Norm(final)=12.950 | 4526.1 samples/s | 70.7 steps/s
[Step=67450 Epoch=127.1] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.260 | L2-Norm(final)=12.950 | 4615.0 samples/s | 72.1 steps/s
[Step=67500 Epoch=127.2] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.227 | L2-Norm(final)=12.950 | 4506.1 samples/s | 70.4 steps/s
[Step=67550 Epoch=127.3] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.194 | L2-Norm(final)=12.950 | 5700.5 samples/s | 89.1 steps/s
[Step=67600 Epoch=127.4] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.161 | L2-Norm(final)=12.950 | 1964.5 samples/s | 30.7 steps/s
[Step=67650 Epoch=127.5] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.128 | L2-Norm(final)=12.950 | 4502.1 samples/s | 70.3 steps/s
[Step=67700 Epoch=127.6] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.095 | L2-Norm(final)=12.950 | 4538.8 samples/s | 70.9 steps/s
[Step=67750 Epoch=127.7] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.062 | L2-Norm(final)=12.950 | 4509.6 samples/s | 70.5 steps/s
[Step=67800 Epoch=127.8] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.028 | L2-Norm(final)=12.951 | 4488.8 samples/s | 70.1 steps/s
[Step=67850 Epoch=127.9] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.994 | L2-Norm(final)=12.951 | 4510.4 samples/s | 70.5 steps/s
[Step=67900 Epoch=128.0] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.960 | L2-Norm(final)=12.951 | 4623.9 samples/s | 72.2 steps/s
[Step=67950 Epoch=128.1] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.927 | L2-Norm(final)=12.951 | 4535.6 samples/s | 70.9 steps/s
[Step=68000 Epoch=128.2] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.893 | L2-Norm(final)=12.951 | 4568.7 samples/s | 71.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06214 | acc=0.9723 | tpr=0.9763 | fpr=0.0364 | 4534.2 samples/s | 17.7 steps/s
Avg test loss: 0.06942, Avg test acc: 0.97075, Avg tpr: 0.97511, Avg fpr: 0.03884, total FA: 303

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.46358 | acc=0.2806 | tpr=0.0162 | fpr=0.1452 | 4595.0 samples/s | 17.9 steps/s
Avg test loss: 5.46969, Avg test acc: 0.27855, Avg tpr: 0.01690, Avg fpr: 0.14601, total FA: 1139

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.73792 | acc=0.1427 | tpr=0.3761 | fpr=0.8615 | 4650.4 samples/s | 18.2 steps/s
[Step= 100] | Loss=5.69422 | acc=0.1419 | tpr=0.3390 | fpr=0.8618 | 8316.3 samples/s | 32.5 steps/s
[Step= 150] | Loss=5.69298 | acc=0.1422 | tpr=0.3444 | fpr=0.8615 | 8330.4 samples/s | 32.5 steps/s
[Step= 200] | Loss=5.68233 | acc=0.1416 | tpr=0.3421 | fpr=0.8621 | 8722.3 samples/s | 34.1 steps/s
[Step= 250] | Loss=5.68386 | acc=0.1422 | tpr=0.3406 | fpr=0.8614 | 8386.1 samples/s | 32.8 steps/s
[Step= 300] | Loss=5.68196 | acc=0.1420 | tpr=0.3418 | fpr=0.8616 | 8632.3 samples/s | 33.7 steps/s
[Step= 350] | Loss=5.67822 | acc=0.1411 | tpr=0.3375 | fpr=0.8625 | 8212.6 samples/s | 32.1 steps/s
[Step= 400] | Loss=5.67797 | acc=0.1414 | tpr=0.3342 | fpr=0.8621 | 8426.5 samples/s | 32.9 steps/s
[Step= 450] | Loss=5.67983 | acc=0.1413 | tpr=0.3315 | fpr=0.8621 | 8891.9 samples/s | 34.7 steps/s
[Step= 500] | Loss=5.68420 | acc=0.1416 | tpr=0.3330 | fpr=0.8619 | 8327.5 samples/s | 32.5 steps/s
[Step= 550] | Loss=5.68524 | acc=0.1415 | tpr=0.3359 | fpr=0.8620 | 15433.1 samples/s | 60.3 steps/s
Avg test loss: 5.68652, Avg test acc: 0.14134, Avg tpr: 0.33558, Avg fpr: 0.86219, total FA: 119714

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14027 | acc=0.9818 | tpr=0.9469 | fpr=0.0176 | 4491.4 samples/s | 17.5 steps/s
[Step= 100] | Loss=0.14866 | acc=0.9808 | tpr=0.9510 | fpr=0.0187 | 8394.8 samples/s | 32.8 steps/s
[Step= 150] | Loss=0.15475 | acc=0.9801 | tpr=0.9597 | fpr=0.0195 | 8489.7 samples/s | 33.2 steps/s
[Step= 200] | Loss=0.15615 | acc=0.9802 | tpr=0.9639 | fpr=0.0195 | 8323.9 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.15411 | acc=0.9804 | tpr=0.9616 | fpr=0.0192 | 8632.5 samples/s | 33.7 steps/s
[Step= 300] | Loss=0.15682 | acc=0.9801 | tpr=0.9615 | fpr=0.0195 | 8100.3 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.15919 | acc=0.9798 | tpr=0.9612 | fpr=0.0199 | 8867.6 samples/s | 34.6 steps/s
[Step= 400] | Loss=0.16021 | acc=0.9797 | tpr=0.9606 | fpr=0.0199 | 8241.0 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.16381 | acc=0.9794 | tpr=0.9591 | fpr=0.0202 | 8264.1 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.16281 | acc=0.9794 | tpr=0.9581 | fpr=0.0202 | 8480.4 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.16158 | acc=0.9796 | tpr=0.9574 | fpr=0.0200 | 15771.1 samples/s | 61.6 steps/s
Avg test loss: 0.16141, Avg test acc: 0.97962, Avg tpr: 0.95721, Avg fpr: 0.01997, total FA: 2773

server round 34/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=68001 Epoch=66.4] | Loss=0.01355 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.878 | L2-Norm(final)=12.685 | 4456.8 samples/s | 69.6 steps/s
[Step=68050 Epoch=66.4] | Loss=0.01137 | Reg=0.00141 | acc=0.9531 | L2-Norm=11.879 | L2-Norm(final)=12.694 | 5215.2 samples/s | 81.5 steps/s
[Step=68100 Epoch=66.5] | Loss=0.01033 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.703 | 5611.7 samples/s | 87.7 steps/s
[Step=68150 Epoch=66.5] | Loss=0.01036 | Reg=0.00141 | acc=0.9688 | L2-Norm=11.879 | L2-Norm(final)=12.713 | 5673.0 samples/s | 88.6 steps/s
[Step=68200 Epoch=66.6] | Loss=0.01002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.722 | 5557.6 samples/s | 86.8 steps/s
[Step=68250 Epoch=66.6] | Loss=0.01032 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.731 | 5656.0 samples/s | 88.4 steps/s
[Step=68300 Epoch=66.7] | Loss=0.01018 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.740 | 5589.0 samples/s | 87.3 steps/s
[Step=68350 Epoch=66.7] | Loss=0.01035 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.749 | 5500.5 samples/s | 85.9 steps/s
[Step=68400 Epoch=66.8] | Loss=0.01056 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.758 | 5623.0 samples/s | 87.9 steps/s
[Step=68450 Epoch=66.8] | Loss=0.01033 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.766 | 5392.2 samples/s | 84.3 steps/s
[Step=68500 Epoch=66.9] | Loss=0.01032 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=12.774 | 5559.6 samples/s | 86.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=66.9] | Loss=0.01380 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.879 | L2-Norm(final)=12.855 | 4165.6 samples/s | 65.1 steps/s
[Step=68550 Epoch=66.9] | Loss=0.01167 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.889 | L2-Norm(final)=12.860 | 4652.3 samples/s | 72.7 steps/s
[Step=68600 Epoch=67.0] | Loss=0.01059 | Reg=0.00142 | acc=0.9844 | L2-Norm=11.898 | L2-Norm(final)=12.864 | 4923.9 samples/s | 76.9 steps/s
[Step=68650 Epoch=67.0] | Loss=0.00989 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.906 | L2-Norm(final)=12.868 | 4840.9 samples/s | 75.6 steps/s
[Step=68700 Epoch=67.1] | Loss=0.00995 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.912 | L2-Norm(final)=12.872 | 4883.6 samples/s | 76.3 steps/s
[Step=68750 Epoch=67.1] | Loss=0.01020 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.918 | L2-Norm(final)=12.875 | 4917.9 samples/s | 76.8 steps/s
[Step=68800 Epoch=67.2] | Loss=0.01065 | Reg=0.00142 | acc=0.9844 | L2-Norm=11.923 | L2-Norm(final)=12.878 | 4949.9 samples/s | 77.3 steps/s
[Step=68850 Epoch=67.2] | Loss=0.01027 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.928 | L2-Norm(final)=12.880 | 4924.6 samples/s | 76.9 steps/s
[Step=68900 Epoch=67.3] | Loss=0.01028 | Reg=0.00142 | acc=0.9844 | L2-Norm=11.933 | L2-Norm(final)=12.883 | 4887.2 samples/s | 76.4 steps/s
[Step=68950 Epoch=67.3] | Loss=0.01012 | Reg=0.00143 | acc=0.9688 | L2-Norm=11.937 | L2-Norm(final)=12.885 | 4905.2 samples/s | 76.6 steps/s
[Step=69000 Epoch=67.4] | Loss=0.01037 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.941 | L2-Norm(final)=12.887 | 4765.3 samples/s | 74.5 steps/s
[Step=69050 Epoch=67.4] | Loss=0.01028 | Reg=0.00143 | acc=0.9688 | L2-Norm=11.945 | L2-Norm(final)=12.889 | 4810.5 samples/s | 75.2 steps/s
[Step=69100 Epoch=67.5] | Loss=0.01015 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.949 | L2-Norm(final)=12.891 | 4771.1 samples/s | 74.5 steps/s
[Step=69150 Epoch=67.5] | Loss=0.01005 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.953 | L2-Norm(final)=12.894 | 4722.3 samples/s | 73.8 steps/s
[Step=69200 Epoch=67.6] | Loss=0.00983 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.957 | L2-Norm(final)=12.896 | 4819.4 samples/s | 75.3 steps/s
[Step=69250 Epoch=67.6] | Loss=0.00992 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.960 | L2-Norm(final)=12.898 | 4887.2 samples/s | 76.4 steps/s
[Step=69300 Epoch=67.7] | Loss=0.00984 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.964 | L2-Norm(final)=12.900 | 4919.1 samples/s | 76.9 steps/s
[Step=69350 Epoch=67.7] | Loss=0.00973 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.967 | L2-Norm(final)=12.903 | 4913.1 samples/s | 76.8 steps/s
[Step=69400 Epoch=67.8] | Loss=0.00967 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.970 | L2-Norm(final)=12.905 | 4957.7 samples/s | 77.5 steps/s
[Step=69450 Epoch=67.8] | Loss=0.00965 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.973 | L2-Norm(final)=12.907 | 4854.5 samples/s | 75.9 steps/s
[Step=69500 Epoch=67.9] | Loss=0.00952 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.976 | L2-Norm(final)=12.909 | 5278.0 samples/s | 82.5 steps/s
[Step=69550 Epoch=67.9] | Loss=0.00939 | Reg=0.00144 | acc=0.9844 | L2-Norm=11.979 | L2-Norm(final)=12.911 | 2171.3 samples/s | 33.9 steps/s
[Step=69600 Epoch=68.0] | Loss=0.00926 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.982 | L2-Norm(final)=12.913 | 4822.9 samples/s | 75.4 steps/s
[Step=69650 Epoch=68.0] | Loss=0.00910 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.985 | L2-Norm(final)=12.915 | 4917.5 samples/s | 76.8 steps/s
[Step=69700 Epoch=68.1] | Loss=0.00903 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.987 | L2-Norm(final)=12.917 | 4877.3 samples/s | 76.2 steps/s
[Step=69750 Epoch=68.1] | Loss=0.00897 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.990 | L2-Norm(final)=12.919 | 4901.9 samples/s | 76.6 steps/s
[Step=69800 Epoch=68.1] | Loss=0.00895 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.992 | L2-Norm(final)=12.921 | 4894.0 samples/s | 76.5 steps/s
[Step=69850 Epoch=68.2] | Loss=0.00895 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.995 | L2-Norm(final)=12.923 | 4963.1 samples/s | 77.5 steps/s
[Step=69900 Epoch=68.2] | Loss=0.00889 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.997 | L2-Norm(final)=12.925 | 4869.3 samples/s | 76.1 steps/s
[Step=69950 Epoch=68.3] | Loss=0.00883 | Reg=0.00144 | acc=0.9844 | L2-Norm=11.999 | L2-Norm(final)=12.927 | 4912.3 samples/s | 76.8 steps/s
[Step=70000 Epoch=68.3] | Loss=0.00884 | Reg=0.00144 | acc=0.9844 | L2-Norm=12.001 | L2-Norm(final)=12.928 | 4967.7 samples/s | 77.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step70000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=68001 Epoch=128.2] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.878 | L2-Norm(final)=12.958 | 4994.3 samples/s | 78.0 steps/s
[Step=68050 Epoch=128.3] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.867 | L2-Norm(final)=12.962 | 4235.2 samples/s | 66.2 steps/s
[Step=68100 Epoch=128.4] | Loss=0.00007 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.866 | L2-Norm(final)=12.966 | 5108.8 samples/s | 79.8 steps/s
[Step=68150 Epoch=128.5] | Loss=0.00005 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.866 | L2-Norm(final)=12.969 | 5225.2 samples/s | 81.6 steps/s
[Step=68200 Epoch=128.6] | Loss=0.00008 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.974 | 5114.7 samples/s | 79.9 steps/s
[Step=68250 Epoch=128.7] | Loss=0.00006 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.978 | 5177.2 samples/s | 80.9 steps/s
[Step=68300 Epoch=128.7] | Loss=0.00006 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.981 | 5187.6 samples/s | 81.1 steps/s
[Step=68350 Epoch=128.8] | Loss=0.00005 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.984 | 5248.3 samples/s | 82.0 steps/s
[Step=68400 Epoch=128.9] | Loss=0.00005 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.987 | 5138.0 samples/s | 80.3 steps/s
[Step=68450 Epoch=129.0] | Loss=0.00005 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.990 | 5257.8 samples/s | 82.2 steps/s
[Step=68500 Epoch=129.1] | Loss=0.00004 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=12.992 | 5286.2 samples/s | 82.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=129.1] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=13.015 | 4241.8 samples/s | 66.3 steps/s
[Step=68550 Epoch=129.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.824 | L2-Norm(final)=13.016 | 4197.3 samples/s | 65.6 steps/s
[Step=68600 Epoch=129.3] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.772 | L2-Norm(final)=13.017 | 4553.8 samples/s | 71.2 steps/s
[Step=68650 Epoch=129.4] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.718 | L2-Norm(final)=13.017 | 4588.7 samples/s | 71.7 steps/s
[Step=68700 Epoch=129.5] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.663 | L2-Norm(final)=13.017 | 4498.7 samples/s | 70.3 steps/s
[Step=68750 Epoch=129.6] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.607 | L2-Norm(final)=13.018 | 4603.2 samples/s | 71.9 steps/s
[Step=68800 Epoch=129.7] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.552 | L2-Norm(final)=13.018 | 4550.8 samples/s | 71.1 steps/s
[Step=68850 Epoch=129.8] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.497 | L2-Norm(final)=13.018 | 4555.1 samples/s | 71.2 steps/s
[Step=68900 Epoch=129.9] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.442 | L2-Norm(final)=13.018 | 4545.7 samples/s | 71.0 steps/s
[Step=68950 Epoch=130.0] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.387 | L2-Norm(final)=13.019 | 4490.6 samples/s | 70.2 steps/s
[Step=69000 Epoch=130.1] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.333 | L2-Norm(final)=13.019 | 4583.3 samples/s | 71.6 steps/s
[Step=69050 Epoch=130.2] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.280 | L2-Norm(final)=13.019 | 2123.2 samples/s | 33.2 steps/s
[Step=69100 Epoch=130.3] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.227 | L2-Norm(final)=13.019 | 4569.0 samples/s | 71.4 steps/s
[Step=69150 Epoch=130.3] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.174 | L2-Norm(final)=13.019 | 4547.0 samples/s | 71.0 steps/s
[Step=69200 Epoch=130.4] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.121 | L2-Norm(final)=13.019 | 4618.1 samples/s | 72.2 steps/s
[Step=69250 Epoch=130.5] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.069 | L2-Norm(final)=13.020 | 4468.8 samples/s | 69.8 steps/s
[Step=69300 Epoch=130.6] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.016 | L2-Norm(final)=13.020 | 4520.0 samples/s | 70.6 steps/s
[Step=69350 Epoch=130.7] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.964 | L2-Norm(final)=13.020 | 4626.1 samples/s | 72.3 steps/s
[Step=69400 Epoch=130.8] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.911 | L2-Norm(final)=13.020 | 4592.9 samples/s | 71.8 steps/s
[Step=69450 Epoch=130.9] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.859 | L2-Norm(final)=13.021 | 4562.9 samples/s | 71.3 steps/s
[Step=69500 Epoch=131.0] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.807 | L2-Norm(final)=13.021 | 4508.5 samples/s | 70.4 steps/s
[Step=69550 Epoch=131.1] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.755 | L2-Norm(final)=13.022 | 5688.9 samples/s | 88.9 steps/s
[Step=69600 Epoch=131.2] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.704 | L2-Norm(final)=13.022 | 1967.9 samples/s | 30.7 steps/s
[Step=69650 Epoch=131.3] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.652 | L2-Norm(final)=13.022 | 4547.5 samples/s | 71.1 steps/s
[Step=69700 Epoch=131.4] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.600 | L2-Norm(final)=13.023 | 4530.5 samples/s | 70.8 steps/s
[Step=69750 Epoch=131.5] | Loss=0.00004 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=13.023 | 4547.2 samples/s | 71.0 steps/s
[Step=69800 Epoch=131.6] | Loss=0.00004 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.504 | L2-Norm(final)=13.023 | 4553.1 samples/s | 71.1 steps/s
[Step=69850 Epoch=131.7] | Loss=0.00004 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.462 | L2-Norm(final)=13.023 | 4500.8 samples/s | 70.3 steps/s
[Step=69900 Epoch=131.8] | Loss=0.00004 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.423 | L2-Norm(final)=13.023 | 4572.4 samples/s | 71.4 steps/s
[Step=69950 Epoch=131.9] | Loss=0.00004 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.387 | L2-Norm(final)=13.023 | 4524.2 samples/s | 70.7 steps/s
[Step=70000 Epoch=132.0] | Loss=0.00004 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.353 | L2-Norm(final)=13.023 | 4520.9 samples/s | 70.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05674 | acc=0.9718 | tpr=0.9741 | fpr=0.0332 | 4568.8 samples/s | 17.8 steps/s
Avg test loss: 0.06243, Avg test acc: 0.97059, Avg tpr: 0.97377, Avg fpr: 0.03641, total FA: 284

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.61634 | acc=0.2957 | tpr=0.0144 | fpr=0.0934 | 4568.7 samples/s | 17.8 steps/s
Avg test loss: 4.62755, Avg test acc: 0.29305, Avg tpr: 0.01504, Avg fpr: 0.09550, total FA: 745

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.62633 | acc=0.1516 | tpr=0.4425 | fpr=0.8536 | 4509.6 samples/s | 17.6 steps/s
[Step= 100] | Loss=4.59159 | acc=0.1517 | tpr=0.4200 | fpr=0.8533 | 8659.4 samples/s | 33.8 steps/s
[Step= 150] | Loss=4.59048 | acc=0.1512 | tpr=0.4308 | fpr=0.8539 | 8388.1 samples/s | 32.8 steps/s
[Step= 200] | Loss=4.57993 | acc=0.1512 | tpr=0.4306 | fpr=0.8538 | 8516.4 samples/s | 33.3 steps/s
[Step= 250] | Loss=4.58039 | acc=0.1519 | tpr=0.4306 | fpr=0.8532 | 8527.6 samples/s | 33.3 steps/s
[Step= 300] | Loss=4.57765 | acc=0.1515 | tpr=0.4356 | fpr=0.8537 | 8418.1 samples/s | 32.9 steps/s
[Step= 350] | Loss=4.57510 | acc=0.1509 | tpr=0.4383 | fpr=0.8543 | 8330.1 samples/s | 32.5 steps/s
[Step= 400] | Loss=4.57564 | acc=0.1514 | tpr=0.4360 | fpr=0.8538 | 8605.8 samples/s | 33.6 steps/s
[Step= 450] | Loss=4.57795 | acc=0.1515 | tpr=0.4338 | fpr=0.8536 | 8510.1 samples/s | 33.2 steps/s
[Step= 500] | Loss=4.58085 | acc=0.1517 | tpr=0.4339 | fpr=0.8534 | 8216.7 samples/s | 32.1 steps/s
[Step= 550] | Loss=4.58134 | acc=0.1518 | tpr=0.4353 | fpr=0.8533 | 15736.7 samples/s | 61.5 steps/s
Avg test loss: 4.58243, Avg test acc: 0.15168, Avg tpr: 0.43502, Avg fpr: 0.85347, total FA: 118502

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11490 | acc=0.9824 | tpr=0.9602 | fpr=0.0172 | 4491.1 samples/s | 17.5 steps/s
[Step= 100] | Loss=0.12239 | acc=0.9807 | tpr=0.9552 | fpr=0.0188 | 9125.7 samples/s | 35.6 steps/s
[Step= 150] | Loss=0.12807 | acc=0.9799 | tpr=0.9568 | fpr=0.0197 | 8176.6 samples/s | 31.9 steps/s
[Step= 200] | Loss=0.12871 | acc=0.9800 | tpr=0.9607 | fpr=0.0196 | 8177.0 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.12673 | acc=0.9802 | tpr=0.9598 | fpr=0.0195 | 8586.4 samples/s | 33.5 steps/s
[Step= 300] | Loss=0.12942 | acc=0.9799 | tpr=0.9607 | fpr=0.0198 | 8602.2 samples/s | 33.6 steps/s
[Step= 350] | Loss=0.13129 | acc=0.9795 | tpr=0.9612 | fpr=0.0202 | 8972.6 samples/s | 35.0 steps/s
[Step= 400] | Loss=0.13214 | acc=0.9794 | tpr=0.9590 | fpr=0.0202 | 9378.3 samples/s | 36.6 steps/s
[Step= 450] | Loss=0.13514 | acc=0.9791 | tpr=0.9552 | fpr=0.0205 | 8205.7 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.13443 | acc=0.9791 | tpr=0.9546 | fpr=0.0204 | 9118.9 samples/s | 35.6 steps/s
[Step= 550] | Loss=0.13352 | acc=0.9793 | tpr=0.9530 | fpr=0.0202 | 13531.4 samples/s | 52.9 steps/s
Avg test loss: 0.13341, Avg test acc: 0.97927, Avg tpr: 0.95285, Avg fpr: 0.02025, total FA: 2811

server round 35/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=70001 Epoch=68.3] | Loss=0.01504 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.648 | L2-Norm(final)=12.979 | 4226.7 samples/s | 66.0 steps/s
[Step=70050 Epoch=68.4] | Loss=0.02012 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.648 | L2-Norm(final)=12.993 | 5353.2 samples/s | 83.6 steps/s
[Step=70100 Epoch=68.4] | Loss=0.02201 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.649 | L2-Norm(final)=13.009 | 5743.1 samples/s | 89.7 steps/s
[Step=70150 Epoch=68.5] | Loss=0.02269 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.649 | L2-Norm(final)=13.025 | 5467.8 samples/s | 85.4 steps/s
[Step=70200 Epoch=68.5] | Loss=0.02269 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.040 | 5467.6 samples/s | 85.4 steps/s
[Step=70250 Epoch=68.6] | Loss=0.02293 | Reg=0.00113 | acc=0.9688 | L2-Norm=10.649 | L2-Norm(final)=13.056 | 5535.6 samples/s | 86.5 steps/s
[Step=70300 Epoch=68.6] | Loss=0.02254 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.071 | 5564.5 samples/s | 86.9 steps/s
[Step=70350 Epoch=68.7] | Loss=0.02250 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.086 | 5529.9 samples/s | 86.4 steps/s
[Step=70400 Epoch=68.7] | Loss=0.02216 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.101 | 5572.3 samples/s | 87.1 steps/s
[Step=70450 Epoch=68.8] | Loss=0.02207 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.649 | L2-Norm(final)=13.116 | 5533.7 samples/s | 86.5 steps/s
[Step=70500 Epoch=68.8] | Loss=0.02231 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.130 | 5508.0 samples/s | 86.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=68.8] | Loss=0.01656 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=13.274 | 4013.7 samples/s | 62.7 steps/s
[Step=70550 Epoch=68.9] | Loss=0.01938 | Reg=0.00114 | acc=0.9688 | L2-Norm=10.664 | L2-Norm(final)=13.285 | 4787.0 samples/s | 74.8 steps/s
[Step=70600 Epoch=68.9] | Loss=0.01681 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.679 | L2-Norm(final)=13.291 | 4742.0 samples/s | 74.1 steps/s
[Step=70650 Epoch=69.0] | Loss=0.01612 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.691 | L2-Norm(final)=13.297 | 4795.3 samples/s | 74.9 steps/s
[Step=70700 Epoch=69.0] | Loss=0.01553 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.702 | L2-Norm(final)=13.302 | 4846.1 samples/s | 75.7 steps/s
[Step=70750 Epoch=69.1] | Loss=0.01561 | Reg=0.00115 | acc=0.9688 | L2-Norm=10.711 | L2-Norm(final)=13.307 | 4702.1 samples/s | 73.5 steps/s
[Step=70800 Epoch=69.1] | Loss=0.01473 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.720 | L2-Norm(final)=13.311 | 4750.0 samples/s | 74.2 steps/s
[Step=70850 Epoch=69.2] | Loss=0.01478 | Reg=0.00115 | acc=0.9688 | L2-Norm=10.728 | L2-Norm(final)=13.316 | 4791.4 samples/s | 74.9 steps/s
[Step=70900 Epoch=69.2] | Loss=0.01458 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.735 | L2-Norm(final)=13.319 | 4810.8 samples/s | 75.2 steps/s
[Step=70950 Epoch=69.3] | Loss=0.01437 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.742 | L2-Norm(final)=13.323 | 4762.6 samples/s | 74.4 steps/s
[Step=71000 Epoch=69.3] | Loss=0.01414 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.748 | L2-Norm(final)=13.327 | 4813.9 samples/s | 75.2 steps/s
[Step=71050 Epoch=69.4] | Loss=0.01384 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.754 | L2-Norm(final)=13.331 | 4752.0 samples/s | 74.2 steps/s
[Step=71100 Epoch=69.4] | Loss=0.01361 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.760 | L2-Norm(final)=13.334 | 4856.7 samples/s | 75.9 steps/s
[Step=71150 Epoch=69.5] | Loss=0.01332 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.766 | L2-Norm(final)=13.337 | 4973.6 samples/s | 77.7 steps/s
[Step=71200 Epoch=69.5] | Loss=0.01317 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.771 | L2-Norm(final)=13.341 | 4869.7 samples/s | 76.1 steps/s
[Step=71250 Epoch=69.6] | Loss=0.01306 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.776 | L2-Norm(final)=13.344 | 4834.0 samples/s | 75.5 steps/s
[Step=71300 Epoch=69.6] | Loss=0.01287 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.780 | L2-Norm(final)=13.347 | 4817.5 samples/s | 75.3 steps/s
[Step=71350 Epoch=69.7] | Loss=0.01279 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.785 | L2-Norm(final)=13.350 | 4821.6 samples/s | 75.3 steps/s
[Step=71400 Epoch=69.7] | Loss=0.01277 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.790 | L2-Norm(final)=13.353 | 4787.7 samples/s | 74.8 steps/s
[Step=71450 Epoch=69.8] | Loss=0.01269 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.794 | L2-Norm(final)=13.356 | 4813.6 samples/s | 75.2 steps/s
[Step=71500 Epoch=69.8] | Loss=0.01260 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.798 | L2-Norm(final)=13.358 | 5158.0 samples/s | 80.6 steps/s
[Step=71550 Epoch=69.9] | Loss=0.01253 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.802 | L2-Norm(final)=13.361 | 2069.7 samples/s | 32.3 steps/s
[Step=71600 Epoch=69.9] | Loss=0.01244 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.806 | L2-Norm(final)=13.364 | 4774.9 samples/s | 74.6 steps/s
[Step=71650 Epoch=70.0] | Loss=0.01222 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.810 | L2-Norm(final)=13.367 | 4796.9 samples/s | 75.0 steps/s
[Step=71700 Epoch=70.0] | Loss=0.01221 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.814 | L2-Norm(final)=13.370 | 4711.7 samples/s | 73.6 steps/s
[Step=71750 Epoch=70.1] | Loss=0.01203 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.817 | L2-Norm(final)=13.372 | 4799.0 samples/s | 75.0 steps/s
[Step=71800 Epoch=70.1] | Loss=0.01194 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.821 | L2-Norm(final)=13.375 | 4810.4 samples/s | 75.2 steps/s
[Step=71850 Epoch=70.1] | Loss=0.01182 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.824 | L2-Norm(final)=13.377 | 4809.1 samples/s | 75.1 steps/s
[Step=71900 Epoch=70.2] | Loss=0.01166 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.828 | L2-Norm(final)=13.380 | 4802.7 samples/s | 75.0 steps/s
[Step=71950 Epoch=70.2] | Loss=0.01154 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.831 | L2-Norm(final)=13.383 | 4770.6 samples/s | 74.5 steps/s
[Step=72000 Epoch=70.3] | Loss=0.01143 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.834 | L2-Norm(final)=13.385 | 4795.4 samples/s | 74.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step72000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=70001 Epoch=132.0] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.648 | L2-Norm(final)=13.026 | 4125.1 samples/s | 64.5 steps/s
[Step=70050 Epoch=132.0] | Loss=0.00003 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.648 | L2-Norm(final)=13.027 | 4955.0 samples/s | 77.4 steps/s
[Step=70100 Epoch=132.1] | Loss=0.00008 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.648 | L2-Norm(final)=13.029 | 5222.9 samples/s | 81.6 steps/s
[Step=70150 Epoch=132.2] | Loss=0.00006 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.030 | 5144.1 samples/s | 80.4 steps/s
[Step=70200 Epoch=132.3] | Loss=0.00006 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.031 | 5208.9 samples/s | 81.4 steps/s
[Step=70250 Epoch=132.4] | Loss=0.00005 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.032 | 5210.4 samples/s | 81.4 steps/s
[Step=70300 Epoch=132.5] | Loss=0.00005 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.033 | 5183.7 samples/s | 81.0 steps/s
[Step=70350 Epoch=132.6] | Loss=0.00005 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.034 | 5187.4 samples/s | 81.1 steps/s
[Step=70400 Epoch=132.7] | Loss=0.00005 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.035 | 5137.8 samples/s | 80.3 steps/s
[Step=70450 Epoch=132.8] | Loss=0.00006 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.036 | 5240.6 samples/s | 81.9 steps/s
[Step=70500 Epoch=132.9] | Loss=0.00006 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.038 | 5231.6 samples/s | 81.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=132.9] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=13.050 | 4412.7 samples/s | 68.9 steps/s
[Step=70550 Epoch=133.0] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.645 | L2-Norm(final)=13.051 | 4206.8 samples/s | 65.7 steps/s
[Step=70600 Epoch=133.1] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.643 | L2-Norm(final)=13.052 | 4699.8 samples/s | 73.4 steps/s
[Step=70650 Epoch=133.2] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.643 | L2-Norm(final)=13.053 | 4659.8 samples/s | 72.8 steps/s
[Step=70700 Epoch=133.3] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.641 | L2-Norm(final)=13.054 | 4724.1 samples/s | 73.8 steps/s
[Step=70750 Epoch=133.4] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.639 | L2-Norm(final)=13.055 | 4546.9 samples/s | 71.0 steps/s
[Step=70800 Epoch=133.5] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.637 | L2-Norm(final)=13.055 | 4705.0 samples/s | 73.5 steps/s
[Step=70850 Epoch=133.6] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.635 | L2-Norm(final)=13.056 | 4634.2 samples/s | 72.4 steps/s
[Step=70900 Epoch=133.6] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.633 | L2-Norm(final)=13.056 | 4608.9 samples/s | 72.0 steps/s
[Step=70950 Epoch=133.7] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.631 | L2-Norm(final)=13.057 | 4545.1 samples/s | 71.0 steps/s
[Step=71000 Epoch=133.8] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.628 | L2-Norm(final)=13.058 | 4570.9 samples/s | 71.4 steps/s
[Step=71050 Epoch=133.9] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.626 | L2-Norm(final)=13.058 | 2128.4 samples/s | 33.3 steps/s
[Step=71100 Epoch=134.0] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.623 | L2-Norm(final)=13.059 | 4692.0 samples/s | 73.3 steps/s
[Step=71150 Epoch=134.1] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.621 | L2-Norm(final)=13.059 | 4654.9 samples/s | 72.7 steps/s
[Step=71200 Epoch=134.2] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.618 | L2-Norm(final)=13.060 | 4678.9 samples/s | 73.1 steps/s
[Step=71250 Epoch=134.3] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.615 | L2-Norm(final)=13.060 | 4678.6 samples/s | 73.1 steps/s
[Step=71300 Epoch=134.4] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.613 | L2-Norm(final)=13.060 | 4671.7 samples/s | 73.0 steps/s
[Step=71350 Epoch=134.5] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.610 | L2-Norm(final)=13.061 | 4674.3 samples/s | 73.0 steps/s
[Step=71400 Epoch=134.6] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.607 | L2-Norm(final)=13.061 | 4620.3 samples/s | 72.2 steps/s
[Step=71450 Epoch=134.7] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.605 | L2-Norm(final)=13.061 | 4688.5 samples/s | 73.3 steps/s
[Step=71500 Epoch=134.8] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.602 | L2-Norm(final)=13.062 | 4658.3 samples/s | 72.8 steps/s
[Step=71550 Epoch=134.9] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.599 | L2-Norm(final)=13.062 | 5874.2 samples/s | 91.8 steps/s
[Step=71600 Epoch=135.0] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.596 | L2-Norm(final)=13.063 | 1981.5 samples/s | 31.0 steps/s
[Step=71650 Epoch=135.1] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.593 | L2-Norm(final)=13.063 | 4472.8 samples/s | 69.9 steps/s
[Step=71700 Epoch=135.2] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.590 | L2-Norm(final)=13.063 | 4546.1 samples/s | 71.0 steps/s
[Step=71750 Epoch=135.2] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.587 | L2-Norm(final)=13.064 | 4550.9 samples/s | 71.1 steps/s
[Step=71800 Epoch=135.3] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.584 | L2-Norm(final)=13.064 | 4661.4 samples/s | 72.8 steps/s
[Step=71850 Epoch=135.4] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.581 | L2-Norm(final)=13.064 | 4691.8 samples/s | 73.3 steps/s
[Step=71900 Epoch=135.5] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.578 | L2-Norm(final)=13.065 | 4639.0 samples/s | 72.5 steps/s
[Step=71950 Epoch=135.6] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.575 | L2-Norm(final)=13.065 | 4620.6 samples/s | 72.2 steps/s
[Step=72000 Epoch=135.7] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.572 | L2-Norm(final)=13.065 | 4561.7 samples/s | 71.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05692 | acc=0.9719 | tpr=0.9749 | fpr=0.0347 | 4533.7 samples/s | 17.7 steps/s
Avg test loss: 0.06263, Avg test acc: 0.97071, Avg tpr: 0.97459, Avg fpr: 0.03782, total FA: 295

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.63934 | acc=0.2873 | tpr=0.0163 | fpr=0.1244 | 4528.5 samples/s | 17.7 steps/s
Avg test loss: 4.64353, Avg test acc: 0.28504, Avg tpr: 0.01673, Avg fpr: 0.12486, total FA: 974

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.42131 | acc=0.1513 | tpr=0.4027 | fpr=0.8532 | 4527.3 samples/s | 17.7 steps/s
[Step= 100] | Loss=4.39220 | acc=0.1519 | tpr=0.3795 | fpr=0.8524 | 8345.5 samples/s | 32.6 steps/s
[Step= 150] | Loss=4.39354 | acc=0.1510 | tpr=0.3790 | fpr=0.8532 | 8514.6 samples/s | 33.3 steps/s
[Step= 200] | Loss=4.38286 | acc=0.1511 | tpr=0.3749 | fpr=0.8530 | 8916.3 samples/s | 34.8 steps/s
[Step= 250] | Loss=4.38303 | acc=0.1513 | tpr=0.3755 | fpr=0.8528 | 7946.8 samples/s | 31.0 steps/s
[Step= 300] | Loss=4.38058 | acc=0.1511 | tpr=0.3789 | fpr=0.8530 | 8544.0 samples/s | 33.4 steps/s
[Step= 350] | Loss=4.37775 | acc=0.1506 | tpr=0.3788 | fpr=0.8536 | 8432.5 samples/s | 32.9 steps/s
[Step= 400] | Loss=4.37735 | acc=0.1510 | tpr=0.3813 | fpr=0.8531 | 8607.9 samples/s | 33.6 steps/s
[Step= 450] | Loss=4.37982 | acc=0.1510 | tpr=0.3797 | fpr=0.8531 | 8581.7 samples/s | 33.5 steps/s
[Step= 500] | Loss=4.38247 | acc=0.1511 | tpr=0.3775 | fpr=0.8529 | 8869.9 samples/s | 34.6 steps/s
[Step= 550] | Loss=4.38351 | acc=0.1514 | tpr=0.3796 | fpr=0.8528 | 14288.6 samples/s | 55.8 steps/s
Avg test loss: 4.38416, Avg test acc: 0.15121, Avg tpr: 0.37956, Avg fpr: 0.85294, total FA: 118429

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11869 | acc=0.9820 | tpr=0.9469 | fpr=0.0174 | 4545.5 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.12625 | acc=0.9809 | tpr=0.9510 | fpr=0.0185 | 8577.6 samples/s | 33.5 steps/s
[Step= 150] | Loss=0.13194 | acc=0.9803 | tpr=0.9597 | fpr=0.0193 | 8431.9 samples/s | 32.9 steps/s
[Step= 200] | Loss=0.13339 | acc=0.9804 | tpr=0.9639 | fpr=0.0193 | 9070.9 samples/s | 35.4 steps/s
[Step= 250] | Loss=0.13133 | acc=0.9807 | tpr=0.9616 | fpr=0.0190 | 8077.6 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.13374 | acc=0.9804 | tpr=0.9629 | fpr=0.0193 | 8540.1 samples/s | 33.4 steps/s
[Step= 350] | Loss=0.13566 | acc=0.9801 | tpr=0.9618 | fpr=0.0196 | 8295.1 samples/s | 32.4 steps/s
[Step= 400] | Loss=0.13657 | acc=0.9800 | tpr=0.9606 | fpr=0.0196 | 8636.2 samples/s | 33.7 steps/s
[Step= 450] | Loss=0.13975 | acc=0.9797 | tpr=0.9586 | fpr=0.0199 | 8878.0 samples/s | 34.7 steps/s
[Step= 500] | Loss=0.13898 | acc=0.9798 | tpr=0.9581 | fpr=0.0198 | 7923.9 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.13797 | acc=0.9799 | tpr=0.9570 | fpr=0.0196 | 15724.6 samples/s | 61.4 steps/s
Avg test loss: 0.13784, Avg test acc: 0.97996, Avg tpr: 0.95721, Avg fpr: 0.01963, total FA: 2725

server round 36/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=72001 Epoch=70.3] | Loss=0.02258 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.674 | L2-Norm(final)=13.461 | 4346.7 samples/s | 67.9 steps/s
[Step=72050 Epoch=70.3] | Loss=0.01171 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.674 | L2-Norm(final)=13.467 | 5105.4 samples/s | 79.8 steps/s
[Step=72100 Epoch=70.4] | Loss=0.01316 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.474 | 5489.2 samples/s | 85.8 steps/s
[Step=72150 Epoch=70.4] | Loss=0.01316 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.482 | 5561.1 samples/s | 86.9 steps/s
[Step=72200 Epoch=70.5] | Loss=0.01381 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.489 | 5378.9 samples/s | 84.0 steps/s
[Step=72250 Epoch=70.5] | Loss=0.01372 | Reg=0.00114 | acc=0.9531 | L2-Norm=10.675 | L2-Norm(final)=13.496 | 5463.1 samples/s | 85.4 steps/s
[Step=72300 Epoch=70.6] | Loss=0.01342 | Reg=0.00114 | acc=0.9375 | L2-Norm=10.675 | L2-Norm(final)=13.502 | 5524.9 samples/s | 86.3 steps/s
[Step=72350 Epoch=70.6] | Loss=0.01321 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.508 | 5619.3 samples/s | 87.8 steps/s
[Step=72400 Epoch=70.7] | Loss=0.01275 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.675 | L2-Norm(final)=13.515 | 5532.4 samples/s | 86.4 steps/s
[Step=72450 Epoch=70.7] | Loss=0.01274 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.521 | 5356.0 samples/s | 83.7 steps/s
[Step=72500 Epoch=70.8] | Loss=0.01258 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.675 | L2-Norm(final)=13.527 | 5556.8 samples/s | 86.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=70.8] | Loss=0.01375 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.675 | L2-Norm(final)=13.591 | 4120.1 samples/s | 64.4 steps/s
[Step=72550 Epoch=70.8] | Loss=0.01162 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.683 | L2-Norm(final)=13.597 | 4644.3 samples/s | 72.6 steps/s
[Step=72600 Epoch=70.9] | Loss=0.01064 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.691 | L2-Norm(final)=13.602 | 4745.4 samples/s | 74.1 steps/s
[Step=72650 Epoch=70.9] | Loss=0.01110 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.697 | L2-Norm(final)=13.607 | 4788.8 samples/s | 74.8 steps/s
[Step=72700 Epoch=71.0] | Loss=0.01115 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.704 | L2-Norm(final)=13.611 | 4762.2 samples/s | 74.4 steps/s
[Step=72750 Epoch=71.0] | Loss=0.01078 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.710 | L2-Norm(final)=13.615 | 4959.4 samples/s | 77.5 steps/s
[Step=72800 Epoch=71.1] | Loss=0.01075 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.716 | L2-Norm(final)=13.619 | 4850.3 samples/s | 75.8 steps/s
[Step=72850 Epoch=71.1] | Loss=0.01064 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.722 | L2-Norm(final)=13.622 | 4894.6 samples/s | 76.5 steps/s
[Step=72900 Epoch=71.2] | Loss=0.01074 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.727 | L2-Norm(final)=13.625 | 4961.0 samples/s | 77.5 steps/s
[Step=72950 Epoch=71.2] | Loss=0.01062 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=13.628 | 4960.8 samples/s | 77.5 steps/s
[Step=73000 Epoch=71.3] | Loss=0.01072 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.737 | L2-Norm(final)=13.631 | 4852.8 samples/s | 75.8 steps/s
[Step=73050 Epoch=71.3] | Loss=0.01076 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.741 | L2-Norm(final)=13.634 | 4857.5 samples/s | 75.9 steps/s
[Step=73100 Epoch=71.4] | Loss=0.01066 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.746 | L2-Norm(final)=13.637 | 4723.3 samples/s | 73.8 steps/s
[Step=73150 Epoch=71.4] | Loss=0.01046 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.750 | L2-Norm(final)=13.640 | 4778.5 samples/s | 74.7 steps/s
[Step=73200 Epoch=71.5] | Loss=0.01036 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.754 | L2-Norm(final)=13.643 | 4806.2 samples/s | 75.1 steps/s
[Step=73250 Epoch=71.5] | Loss=0.01031 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.759 | L2-Norm(final)=13.647 | 4887.3 samples/s | 76.4 steps/s
[Step=73300 Epoch=71.6] | Loss=0.01032 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.763 | L2-Norm(final)=13.650 | 4816.9 samples/s | 75.3 steps/s
[Step=73350 Epoch=71.6] | Loss=0.01038 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.767 | L2-Norm(final)=13.652 | 4814.4 samples/s | 75.2 steps/s
[Step=73400 Epoch=71.7] | Loss=0.01037 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.770 | L2-Norm(final)=13.655 | 4769.4 samples/s | 74.5 steps/s
[Step=73450 Epoch=71.7] | Loss=0.01030 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.774 | L2-Norm(final)=13.658 | 4836.9 samples/s | 75.6 steps/s
[Step=73500 Epoch=71.8] | Loss=0.01029 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.777 | L2-Norm(final)=13.661 | 5183.3 samples/s | 81.0 steps/s
[Step=73550 Epoch=71.8] | Loss=0.01016 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.781 | L2-Norm(final)=13.663 | 2120.2 samples/s | 33.1 steps/s
[Step=73600 Epoch=71.9] | Loss=0.01003 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.784 | L2-Norm(final)=13.666 | 4794.6 samples/s | 74.9 steps/s
[Step=73650 Epoch=71.9] | Loss=0.00992 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.787 | L2-Norm(final)=13.669 | 4774.3 samples/s | 74.6 steps/s
[Step=73700 Epoch=72.0] | Loss=0.00983 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.790 | L2-Norm(final)=13.671 | 4941.5 samples/s | 77.2 steps/s
[Step=73750 Epoch=72.0] | Loss=0.00972 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.793 | L2-Norm(final)=13.674 | 4856.8 samples/s | 75.9 steps/s
[Step=73800 Epoch=72.1] | Loss=0.00964 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.796 | L2-Norm(final)=13.676 | 4943.5 samples/s | 77.2 steps/s
[Step=73850 Epoch=72.1] | Loss=0.00955 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.799 | L2-Norm(final)=13.678 | 4855.7 samples/s | 75.9 steps/s
[Step=73900 Epoch=72.2] | Loss=0.00958 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.802 | L2-Norm(final)=13.681 | 4811.7 samples/s | 75.2 steps/s
[Step=73950 Epoch=72.2] | Loss=0.00951 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.805 | L2-Norm(final)=13.683 | 4754.5 samples/s | 74.3 steps/s
[Step=74000 Epoch=72.2] | Loss=0.00944 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.808 | L2-Norm(final)=13.686 | 4729.2 samples/s | 73.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step74000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=72001 Epoch=135.7] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.674 | L2-Norm(final)=13.075 | 4220.0 samples/s | 65.9 steps/s
[Step=72050 Epoch=135.8] | Loss=0.00006 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.079 | 5050.0 samples/s | 78.9 steps/s
[Step=72100 Epoch=135.9] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.083 | 5184.3 samples/s | 81.0 steps/s
[Step=72150 Epoch=136.0] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.087 | 5173.0 samples/s | 80.8 steps/s
[Step=72200 Epoch=136.1] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.090 | 5226.4 samples/s | 81.7 steps/s
[Step=72250 Epoch=136.2] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.093 | 5262.6 samples/s | 82.2 steps/s
[Step=72300 Epoch=136.3] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.097 | 5263.5 samples/s | 82.2 steps/s
[Step=72350 Epoch=136.4] | Loss=0.00006 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.100 | 5222.6 samples/s | 81.6 steps/s
[Step=72400 Epoch=136.5] | Loss=0.00005 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.104 | 5204.0 samples/s | 81.3 steps/s
[Step=72450 Epoch=136.6] | Loss=0.00005 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.107 | 5241.2 samples/s | 81.9 steps/s
[Step=72500 Epoch=136.7] | Loss=0.00005 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.110 | 5295.2 samples/s | 82.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=136.7] | Loss=0.00101 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.673 | L2-Norm(final)=13.141 | 4306.7 samples/s | 67.3 steps/s
[Step=72550 Epoch=136.8] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.672 | L2-Norm(final)=13.144 | 4382.4 samples/s | 68.5 steps/s
[Step=72600 Epoch=136.9] | Loss=0.00002 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.667 | L2-Norm(final)=13.145 | 4527.9 samples/s | 70.7 steps/s
[Step=72650 Epoch=136.9] | Loss=0.00002 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.662 | L2-Norm(final)=13.146 | 4625.4 samples/s | 72.3 steps/s
[Step=72700 Epoch=137.0] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.656 | L2-Norm(final)=13.147 | 4515.3 samples/s | 70.6 steps/s
[Step=72750 Epoch=137.1] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.650 | L2-Norm(final)=13.147 | 4659.6 samples/s | 72.8 steps/s
[Step=72800 Epoch=137.2] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.644 | L2-Norm(final)=13.148 | 4561.9 samples/s | 71.3 steps/s
[Step=72850 Epoch=137.3] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.638 | L2-Norm(final)=13.148 | 4503.8 samples/s | 70.4 steps/s
[Step=72900 Epoch=137.4] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.632 | L2-Norm(final)=13.149 | 4592.8 samples/s | 71.8 steps/s
[Step=72950 Epoch=137.5] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.626 | L2-Norm(final)=13.149 | 4517.2 samples/s | 70.6 steps/s
[Step=73000 Epoch=137.6] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.620 | L2-Norm(final)=13.150 | 4698.8 samples/s | 73.4 steps/s
[Step=73050 Epoch=137.7] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.614 | L2-Norm(final)=13.150 | 2109.7 samples/s | 33.0 steps/s
[Step=73100 Epoch=137.8] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.608 | L2-Norm(final)=13.151 | 4641.3 samples/s | 72.5 steps/s
[Step=73150 Epoch=137.9] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.602 | L2-Norm(final)=13.151 | 4536.8 samples/s | 70.9 steps/s
[Step=73200 Epoch=138.0] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.596 | L2-Norm(final)=13.151 | 4537.7 samples/s | 70.9 steps/s
[Step=73250 Epoch=138.1] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.589 | L2-Norm(final)=13.152 | 4507.5 samples/s | 70.4 steps/s
[Step=73300 Epoch=138.2] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.583 | L2-Norm(final)=13.152 | 4618.0 samples/s | 72.2 steps/s
[Step=73350 Epoch=138.3] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.576 | L2-Norm(final)=13.153 | 4654.8 samples/s | 72.7 steps/s
[Step=73400 Epoch=138.4] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.570 | L2-Norm(final)=13.153 | 4662.1 samples/s | 72.8 steps/s
[Step=73450 Epoch=138.5] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.563 | L2-Norm(final)=13.153 | 4659.3 samples/s | 72.8 steps/s
[Step=73500 Epoch=138.5] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.557 | L2-Norm(final)=13.154 | 4640.6 samples/s | 72.5 steps/s
[Step=73550 Epoch=138.6] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=13.154 | 5816.9 samples/s | 90.9 steps/s
[Step=73600 Epoch=138.7] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.543 | L2-Norm(final)=13.155 | 1982.0 samples/s | 31.0 steps/s
[Step=73650 Epoch=138.8] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=13.155 | 4599.2 samples/s | 71.9 steps/s
[Step=73700 Epoch=138.9] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.529 | L2-Norm(final)=13.156 | 4617.5 samples/s | 72.1 steps/s
[Step=73750 Epoch=139.0] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.522 | L2-Norm(final)=13.156 | 4629.2 samples/s | 72.3 steps/s
[Step=73800 Epoch=139.1] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.515 | L2-Norm(final)=13.156 | 4659.7 samples/s | 72.8 steps/s
[Step=73850 Epoch=139.2] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.508 | L2-Norm(final)=13.157 | 4505.6 samples/s | 70.4 steps/s
[Step=73900 Epoch=139.3] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.500 | L2-Norm(final)=13.157 | 4595.1 samples/s | 71.8 steps/s
[Step=73950 Epoch=139.4] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.493 | L2-Norm(final)=13.158 | 4549.0 samples/s | 71.1 steps/s
[Step=74000 Epoch=139.5] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.485 | L2-Norm(final)=13.158 | 4589.0 samples/s | 71.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05846 | acc=0.9730 | tpr=0.9767 | fpr=0.0349 | 4563.2 samples/s | 17.8 steps/s
Avg test loss: 0.06361, Avg test acc: 0.97123, Avg tpr: 0.97593, Avg fpr: 0.03910, total FA: 305

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.74589 | acc=0.2887 | tpr=0.0155 | fpr=0.1182 | 4540.6 samples/s | 17.7 steps/s
Avg test loss: 4.75080, Avg test acc: 0.28576, Avg tpr: 0.01510, Avg fpr: 0.11896, total FA: 928

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.86645 | acc=0.1418 | tpr=0.3761 | fpr=0.8624 | 4644.7 samples/s | 18.1 steps/s
[Step= 100] | Loss=4.83274 | acc=0.1425 | tpr=0.3518 | fpr=0.8614 | 8784.4 samples/s | 34.3 steps/s
[Step= 150] | Loss=4.83303 | acc=0.1421 | tpr=0.3646 | fpr=0.8620 | 7982.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=4.82200 | acc=0.1425 | tpr=0.3607 | fpr=0.8615 | 9018.9 samples/s | 35.2 steps/s
[Step= 250] | Loss=4.82302 | acc=0.1429 | tpr=0.3616 | fpr=0.8611 | 8392.4 samples/s | 32.8 steps/s
[Step= 300] | Loss=4.82090 | acc=0.1425 | tpr=0.3636 | fpr=0.8615 | 8382.9 samples/s | 32.7 steps/s
[Step= 350] | Loss=4.81876 | acc=0.1417 | tpr=0.3626 | fpr=0.8623 | 8605.9 samples/s | 33.6 steps/s
[Step= 400] | Loss=4.81856 | acc=0.1421 | tpr=0.3649 | fpr=0.8620 | 8474.6 samples/s | 33.1 steps/s
[Step= 450] | Loss=4.82046 | acc=0.1419 | tpr=0.3642 | fpr=0.8621 | 8883.5 samples/s | 34.7 steps/s
[Step= 500] | Loss=4.82368 | acc=0.1420 | tpr=0.3621 | fpr=0.8620 | 8444.3 samples/s | 33.0 steps/s
[Step= 550] | Loss=4.82426 | acc=0.1422 | tpr=0.3637 | fpr=0.8618 | 15448.8 samples/s | 60.3 steps/s
Avg test loss: 4.82509, Avg test acc: 0.14207, Avg tpr: 0.36371, Avg fpr: 0.86196, total FA: 119681

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12058 | acc=0.9823 | tpr=0.9513 | fpr=0.0171 | 4534.4 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.12876 | acc=0.9814 | tpr=0.9510 | fpr=0.0181 | 8942.5 samples/s | 34.9 steps/s
[Step= 150] | Loss=0.13443 | acc=0.9807 | tpr=0.9582 | fpr=0.0189 | 8025.5 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.13589 | acc=0.9807 | tpr=0.9628 | fpr=0.0189 | 8523.8 samples/s | 33.3 steps/s
[Step= 250] | Loss=0.13401 | acc=0.9809 | tpr=0.9581 | fpr=0.0187 | 8377.0 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.13628 | acc=0.9806 | tpr=0.9600 | fpr=0.0190 | 8550.0 samples/s | 33.4 steps/s
[Step= 350] | Loss=0.13840 | acc=0.9803 | tpr=0.9593 | fpr=0.0193 | 8291.1 samples/s | 32.4 steps/s
[Step= 400] | Loss=0.13939 | acc=0.9802 | tpr=0.9584 | fpr=0.0194 | 8499.1 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.14255 | acc=0.9800 | tpr=0.9567 | fpr=0.0196 | 8375.1 samples/s | 32.7 steps/s
[Step= 500] | Loss=0.14181 | acc=0.9800 | tpr=0.9559 | fpr=0.0196 | 8697.7 samples/s | 34.0 steps/s
[Step= 550] | Loss=0.14090 | acc=0.9801 | tpr=0.9554 | fpr=0.0195 | 14777.6 samples/s | 57.7 steps/s
Avg test loss: 0.14076, Avg test acc: 0.98010, Avg tpr: 0.95523, Avg fpr: 0.01945, total FA: 2700

server round 37/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=74001 Epoch=72.3] | Loss=0.01345 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.549 | L2-Norm(final)=13.758 | 4704.9 samples/s | 73.5 steps/s
[Step=74050 Epoch=72.3] | Loss=0.00886 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.550 | L2-Norm(final)=13.763 | 5039.9 samples/s | 78.7 steps/s
[Step=74100 Epoch=72.3] | Loss=0.00932 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=13.769 | 5660.1 samples/s | 88.4 steps/s
[Step=74150 Epoch=72.4] | Loss=0.00940 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=13.776 | 5630.0 samples/s | 88.0 steps/s
[Step=74200 Epoch=72.4] | Loss=0.00913 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.550 | L2-Norm(final)=13.782 | 5624.0 samples/s | 87.9 steps/s
[Step=74250 Epoch=72.5] | Loss=0.00892 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.550 | L2-Norm(final)=13.788 | 5453.0 samples/s | 85.2 steps/s
[Step=74300 Epoch=72.5] | Loss=0.00900 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=13.794 | 5593.4 samples/s | 87.4 steps/s
[Step=74350 Epoch=72.6] | Loss=0.00934 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=13.800 | 5471.9 samples/s | 85.5 steps/s
[Step=74400 Epoch=72.6] | Loss=0.00935 | Reg=0.00111 | acc=0.9844 | L2-Norm=10.551 | L2-Norm(final)=13.806 | 5567.4 samples/s | 87.0 steps/s
[Step=74450 Epoch=72.7] | Loss=0.00939 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=13.812 | 5444.8 samples/s | 85.1 steps/s
[Step=74500 Epoch=72.7] | Loss=0.00933 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=13.819 | 5563.9 samples/s | 86.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=72.7] | Loss=0.00350 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.551 | L2-Norm(final)=13.882 | 4197.4 samples/s | 65.6 steps/s
[Step=74550 Epoch=72.8] | Loss=0.00811 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.558 | L2-Norm(final)=13.887 | 4660.4 samples/s | 72.8 steps/s
[Step=74600 Epoch=72.8] | Loss=0.00923 | Reg=0.00112 | acc=0.9688 | L2-Norm=10.565 | L2-Norm(final)=13.890 | 4922.8 samples/s | 76.9 steps/s
[Step=74650 Epoch=72.9] | Loss=0.00972 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.572 | L2-Norm(final)=13.894 | 4928.6 samples/s | 77.0 steps/s
[Step=74700 Epoch=72.9] | Loss=0.01005 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.578 | L2-Norm(final)=13.898 | 4816.7 samples/s | 75.3 steps/s
[Step=74750 Epoch=73.0] | Loss=0.00947 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.584 | L2-Norm(final)=13.901 | 4906.0 samples/s | 76.7 steps/s
[Step=74800 Epoch=73.0] | Loss=0.00931 | Reg=0.00112 | acc=0.9688 | L2-Norm=10.590 | L2-Norm(final)=13.905 | 4922.7 samples/s | 76.9 steps/s
[Step=74850 Epoch=73.1] | Loss=0.00948 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.595 | L2-Norm(final)=13.908 | 4907.0 samples/s | 76.7 steps/s
[Step=74900 Epoch=73.1] | Loss=0.00948 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.600 | L2-Norm(final)=13.911 | 4941.6 samples/s | 77.2 steps/s
[Step=74950 Epoch=73.2] | Loss=0.00955 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.604 | L2-Norm(final)=13.914 | 4915.2 samples/s | 76.8 steps/s
[Step=75000 Epoch=73.2] | Loss=0.00945 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.608 | L2-Norm(final)=13.917 | 4925.4 samples/s | 77.0 steps/s
[Step=75050 Epoch=73.3] | Loss=0.00956 | Reg=0.00113 | acc=0.9531 | L2-Norm=10.612 | L2-Norm(final)=13.920 | 4978.6 samples/s | 77.8 steps/s
[Step=75100 Epoch=73.3] | Loss=0.00986 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.616 | L2-Norm(final)=13.923 | 4936.3 samples/s | 77.1 steps/s
[Step=75150 Epoch=73.4] | Loss=0.00999 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.620 | L2-Norm(final)=13.926 | 4890.7 samples/s | 76.4 steps/s
[Step=75200 Epoch=73.4] | Loss=0.01000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.624 | L2-Norm(final)=13.929 | 4902.1 samples/s | 76.6 steps/s
[Step=75250 Epoch=73.5] | Loss=0.00998 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.628 | L2-Norm(final)=13.932 | 4926.4 samples/s | 77.0 steps/s
[Step=75300 Epoch=73.5] | Loss=0.00997 | Reg=0.00113 | acc=0.9688 | L2-Norm=10.631 | L2-Norm(final)=13.934 | 4937.6 samples/s | 77.1 steps/s
[Step=75350 Epoch=73.6] | Loss=0.00982 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.635 | L2-Norm(final)=13.937 | 4933.4 samples/s | 77.1 steps/s
[Step=75400 Epoch=73.6] | Loss=0.00990 | Reg=0.00113 | acc=0.9688 | L2-Norm=10.638 | L2-Norm(final)=13.940 | 4909.2 samples/s | 76.7 steps/s
[Step=75450 Epoch=73.7] | Loss=0.00987 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.642 | L2-Norm(final)=13.942 | 4913.6 samples/s | 76.8 steps/s
[Step=75500 Epoch=73.7] | Loss=0.00996 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.645 | L2-Norm(final)=13.945 | 5185.0 samples/s | 81.0 steps/s
[Step=75550 Epoch=73.8] | Loss=0.00988 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.648 | L2-Norm(final)=13.947 | 2068.1 samples/s | 32.3 steps/s
[Step=75600 Epoch=73.8] | Loss=0.00984 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.652 | L2-Norm(final)=13.950 | 4827.3 samples/s | 75.4 steps/s
[Step=75650 Epoch=73.9] | Loss=0.00964 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.655 | L2-Norm(final)=13.953 | 4811.5 samples/s | 75.2 steps/s
[Step=75700 Epoch=73.9] | Loss=0.00960 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.658 | L2-Norm(final)=13.955 | 4819.0 samples/s | 75.3 steps/s
[Step=75750 Epoch=74.0] | Loss=0.00947 | Reg=0.00114 | acc=0.9688 | L2-Norm=10.661 | L2-Norm(final)=13.958 | 4692.8 samples/s | 73.3 steps/s
[Step=75800 Epoch=74.0] | Loss=0.00944 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.664 | L2-Norm(final)=13.961 | 4773.2 samples/s | 74.6 steps/s
[Step=75850 Epoch=74.1] | Loss=0.00943 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.667 | L2-Norm(final)=13.963 | 4818.5 samples/s | 75.3 steps/s
[Step=75900 Epoch=74.1] | Loss=0.00937 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.670 | L2-Norm(final)=13.966 | 4852.3 samples/s | 75.8 steps/s
[Step=75950 Epoch=74.2] | Loss=0.00929 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.673 | L2-Norm(final)=13.968 | 4810.0 samples/s | 75.2 steps/s
[Step=76000 Epoch=74.2] | Loss=0.00930 | Reg=0.00114 | acc=0.9844 | L2-Norm=10.676 | L2-Norm(final)=13.971 | 4760.7 samples/s | 74.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step76000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=74001 Epoch=139.5] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.549 | L2-Norm(final)=13.170 | 4001.7 samples/s | 62.5 steps/s
[Step=74050 Epoch=139.6] | Loss=0.00011 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.547 | L2-Norm(final)=13.177 | 5027.2 samples/s | 78.6 steps/s
[Step=74100 Epoch=139.7] | Loss=0.00008 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.184 | 5320.5 samples/s | 83.1 steps/s
[Step=74150 Epoch=139.8] | Loss=0.00008 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.189 | 5332.0 samples/s | 83.3 steps/s
[Step=74200 Epoch=139.9] | Loss=0.00008 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.195 | 5250.4 samples/s | 82.0 steps/s
[Step=74250 Epoch=140.0] | Loss=0.00007 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.200 | 5361.3 samples/s | 83.8 steps/s
[Step=74300 Epoch=140.1] | Loss=0.00006 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.204 | 5279.3 samples/s | 82.5 steps/s
[Step=74350 Epoch=140.2] | Loss=0.00006 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.207 | 5348.5 samples/s | 83.6 steps/s
[Step=74400 Epoch=140.2] | Loss=0.00006 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.211 | 5095.4 samples/s | 79.6 steps/s
[Step=74450 Epoch=140.3] | Loss=0.00005 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.214 | 5076.4 samples/s | 79.3 steps/s
[Step=74500 Epoch=140.4] | Loss=0.00006 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.217 | 5275.2 samples/s | 82.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=140.4] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=13.251 | 4177.3 samples/s | 65.3 steps/s
[Step=74550 Epoch=140.5] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.536 | L2-Norm(final)=13.253 | 4447.9 samples/s | 69.5 steps/s
[Step=74600 Epoch=140.6] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.524 | L2-Norm(final)=13.254 | 4586.1 samples/s | 71.7 steps/s
[Step=74650 Epoch=140.7] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.512 | L2-Norm(final)=13.255 | 4695.7 samples/s | 73.4 steps/s
[Step=74700 Epoch=140.8] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.499 | L2-Norm(final)=13.255 | 4579.0 samples/s | 71.5 steps/s
[Step=74750 Epoch=140.9] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.486 | L2-Norm(final)=13.256 | 4495.6 samples/s | 70.2 steps/s
[Step=74800 Epoch=141.0] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.472 | L2-Norm(final)=13.256 | 4580.0 samples/s | 71.6 steps/s
[Step=74850 Epoch=141.1] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.459 | L2-Norm(final)=13.256 | 4548.4 samples/s | 71.1 steps/s
[Step=74900 Epoch=141.2] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.445 | L2-Norm(final)=13.257 | 4602.5 samples/s | 71.9 steps/s
[Step=74950 Epoch=141.3] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.431 | L2-Norm(final)=13.257 | 4616.8 samples/s | 72.1 steps/s
[Step=75000 Epoch=141.4] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.417 | L2-Norm(final)=13.258 | 4574.7 samples/s | 71.5 steps/s
[Step=75050 Epoch=141.5] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.403 | L2-Norm(final)=13.258 | 2134.5 samples/s | 33.4 steps/s
[Step=75100 Epoch=141.6] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.389 | L2-Norm(final)=13.258 | 4600.5 samples/s | 71.9 steps/s
[Step=75150 Epoch=141.7] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.375 | L2-Norm(final)=13.259 | 4497.1 samples/s | 70.3 steps/s
[Step=75200 Epoch=141.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.360 | L2-Norm(final)=13.259 | 4489.0 samples/s | 70.1 steps/s
[Step=75250 Epoch=141.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.345 | L2-Norm(final)=13.260 | 4560.9 samples/s | 71.3 steps/s
[Step=75300 Epoch=141.9] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.330 | L2-Norm(final)=13.260 | 4547.1 samples/s | 71.0 steps/s
[Step=75350 Epoch=142.0] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.315 | L2-Norm(final)=13.260 | 4600.7 samples/s | 71.9 steps/s
[Step=75400 Epoch=142.1] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.300 | L2-Norm(final)=13.261 | 4535.1 samples/s | 70.9 steps/s
[Step=75450 Epoch=142.2] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=13.261 | 4524.0 samples/s | 70.7 steps/s
[Step=75500 Epoch=142.3] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=13.262 | 4568.6 samples/s | 71.4 steps/s
[Step=75550 Epoch=142.4] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=13.262 | 5655.9 samples/s | 88.4 steps/s
[Step=75600 Epoch=142.5] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=13.263 | 1974.9 samples/s | 30.9 steps/s
[Step=75650 Epoch=142.6] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.222 | L2-Norm(final)=13.263 | 4545.8 samples/s | 71.0 steps/s
[Step=75700 Epoch=142.7] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.206 | L2-Norm(final)=13.264 | 4605.6 samples/s | 72.0 steps/s
[Step=75750 Epoch=142.8] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=13.264 | 4511.7 samples/s | 70.5 steps/s
[Step=75800 Epoch=142.9] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.174 | L2-Norm(final)=13.265 | 4588.0 samples/s | 71.7 steps/s
[Step=75850 Epoch=143.0] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.157 | L2-Norm(final)=13.265 | 4568.6 samples/s | 71.4 steps/s
[Step=75900 Epoch=143.1] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=13.266 | 4542.3 samples/s | 71.0 steps/s
[Step=75950 Epoch=143.2] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.124 | L2-Norm(final)=13.266 | 4526.8 samples/s | 70.7 steps/s
[Step=76000 Epoch=143.3] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.107 | L2-Norm(final)=13.267 | 4606.9 samples/s | 72.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05711 | acc=0.9720 | tpr=0.9727 | fpr=0.0297 | 4633.1 samples/s | 18.1 steps/s
Avg test loss: 0.06276, Avg test acc: 0.96963, Avg tpr: 0.97051, Avg fpr: 0.03230, total FA: 252

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.89019 | acc=0.2938 | tpr=0.0126 | fpr=0.0954 | 4661.1 samples/s | 18.2 steps/s
Avg test loss: 4.89768, Avg test acc: 0.29125, Avg tpr: 0.01253, Avg fpr: 0.09576, total FA: 747

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.13356 | acc=0.1645 | tpr=0.3451 | fpr=0.8388 | 4563.6 samples/s | 17.8 steps/s
[Step= 100] | Loss=4.10043 | acc=0.1649 | tpr=0.3177 | fpr=0.8379 | 8943.4 samples/s | 34.9 steps/s
[Step= 150] | Loss=4.09931 | acc=0.1658 | tpr=0.3256 | fpr=0.8371 | 8417.3 samples/s | 32.9 steps/s
[Step= 200] | Loss=4.08853 | acc=0.1662 | tpr=0.3257 | fpr=0.8367 | 8494.1 samples/s | 33.2 steps/s
[Step= 250] | Loss=4.08934 | acc=0.1667 | tpr=0.3258 | fpr=0.8362 | 8589.1 samples/s | 33.6 steps/s
[Step= 300] | Loss=4.08709 | acc=0.1664 | tpr=0.3287 | fpr=0.8366 | 8605.5 samples/s | 33.6 steps/s
[Step= 350] | Loss=4.08405 | acc=0.1658 | tpr=0.3262 | fpr=0.8371 | 8723.8 samples/s | 34.1 steps/s
[Step= 400] | Loss=4.08402 | acc=0.1663 | tpr=0.3266 | fpr=0.8366 | 8032.4 samples/s | 31.4 steps/s
[Step= 450] | Loss=4.08543 | acc=0.1664 | tpr=0.3257 | fpr=0.8365 | 8579.6 samples/s | 33.5 steps/s
[Step= 500] | Loss=4.08848 | acc=0.1665 | tpr=0.3233 | fpr=0.8363 | 8503.8 samples/s | 33.2 steps/s
[Step= 550] | Loss=4.08924 | acc=0.1665 | tpr=0.3255 | fpr=0.8363 | 15054.6 samples/s | 58.8 steps/s
Avg test loss: 4.09001, Avg test acc: 0.16637, Avg tpr: 0.32567, Avg fpr: 0.83653, total FA: 116150

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11983 | acc=0.9830 | tpr=0.9558 | fpr=0.0165 | 4518.5 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.12758 | acc=0.9822 | tpr=0.9531 | fpr=0.0173 | 8773.4 samples/s | 34.3 steps/s
[Step= 150] | Loss=0.13327 | acc=0.9815 | tpr=0.9582 | fpr=0.0180 | 9032.2 samples/s | 35.3 steps/s
[Step= 200] | Loss=0.13496 | acc=0.9816 | tpr=0.9628 | fpr=0.0181 | 8540.3 samples/s | 33.4 steps/s
[Step= 250] | Loss=0.13314 | acc=0.9817 | tpr=0.9590 | fpr=0.0179 | 8290.5 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.13534 | acc=0.9814 | tpr=0.9600 | fpr=0.0182 | 8576.5 samples/s | 33.5 steps/s
[Step= 350] | Loss=0.13750 | acc=0.9810 | tpr=0.9599 | fpr=0.0186 | 8464.2 samples/s | 33.1 steps/s
[Step= 400] | Loss=0.13860 | acc=0.9808 | tpr=0.9590 | fpr=0.0188 | 8670.6 samples/s | 33.9 steps/s
[Step= 450] | Loss=0.14182 | acc=0.9806 | tpr=0.9572 | fpr=0.0190 | 8849.7 samples/s | 34.6 steps/s
[Step= 500] | Loss=0.14115 | acc=0.9806 | tpr=0.9559 | fpr=0.0190 | 8425.4 samples/s | 32.9 steps/s
[Step= 550] | Loss=0.14023 | acc=0.9807 | tpr=0.9554 | fpr=0.0189 | 14886.3 samples/s | 58.1 steps/s
Avg test loss: 0.14010, Avg test acc: 0.98069, Avg tpr: 0.95563, Avg fpr: 0.01886, total FA: 2618

server round 38/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=76001 Epoch=74.2] | Loss=0.01426 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.139 | L2-Norm(final)=14.042 | 4113.9 samples/s | 64.3 steps/s
[Step=76050 Epoch=74.3] | Loss=0.01237 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=14.051 | 5518.8 samples/s | 86.2 steps/s
[Step=76100 Epoch=74.3] | Loss=0.01162 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=14.061 | 5563.4 samples/s | 86.9 steps/s
[Step=76150 Epoch=74.3] | Loss=0.01151 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=14.072 | 5702.4 samples/s | 89.1 steps/s
[Step=76200 Epoch=74.4] | Loss=0.01093 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=14.084 | 5511.2 samples/s | 86.1 steps/s
[Step=76250 Epoch=74.4] | Loss=0.01100 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.139 | L2-Norm(final)=14.095 | 5691.7 samples/s | 88.9 steps/s
[Step=76300 Epoch=74.5] | Loss=0.01104 | Reg=0.00103 | acc=0.9688 | L2-Norm=10.139 | L2-Norm(final)=14.105 | 5507.0 samples/s | 86.0 steps/s
[Step=76350 Epoch=74.5] | Loss=0.01115 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=14.116 | 5601.2 samples/s | 87.5 steps/s
[Step=76400 Epoch=74.6] | Loss=0.01131 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.140 | L2-Norm(final)=14.126 | 5368.4 samples/s | 83.9 steps/s
[Step=76450 Epoch=74.6] | Loss=0.01150 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.140 | L2-Norm(final)=14.136 | 5585.3 samples/s | 87.3 steps/s
[Step=76500 Epoch=74.7] | Loss=0.01155 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=14.146 | 5712.6 samples/s | 89.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=74.7] | Loss=0.00968 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.140 | L2-Norm(final)=14.247 | 4163.9 samples/s | 65.1 steps/s
[Step=76550 Epoch=74.7] | Loss=0.01236 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.152 | L2-Norm(final)=14.255 | 4479.6 samples/s | 70.0 steps/s
[Step=76600 Epoch=74.8] | Loss=0.01171 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.162 | L2-Norm(final)=14.260 | 4759.7 samples/s | 74.4 steps/s
[Step=76650 Epoch=74.8] | Loss=0.01196 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.171 | L2-Norm(final)=14.264 | 4832.8 samples/s | 75.5 steps/s
[Step=76700 Epoch=74.9] | Loss=0.01166 | Reg=0.00104 | acc=0.9688 | L2-Norm=10.179 | L2-Norm(final)=14.269 | 4674.8 samples/s | 73.0 steps/s
[Step=76750 Epoch=74.9] | Loss=0.01144 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.187 | L2-Norm(final)=14.273 | 4752.1 samples/s | 74.3 steps/s
[Step=76800 Epoch=75.0] | Loss=0.01119 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.193 | L2-Norm(final)=14.277 | 4840.5 samples/s | 75.6 steps/s
[Step=76850 Epoch=75.0] | Loss=0.01148 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.199 | L2-Norm(final)=14.280 | 4738.6 samples/s | 74.0 steps/s
[Step=76900 Epoch=75.1] | Loss=0.01160 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.205 | L2-Norm(final)=14.284 | 4836.8 samples/s | 75.6 steps/s
[Step=76950 Epoch=75.1] | Loss=0.01145 | Reg=0.00104 | acc=0.9688 | L2-Norm=10.211 | L2-Norm(final)=14.288 | 4900.9 samples/s | 76.6 steps/s
[Step=77000 Epoch=75.2] | Loss=0.01128 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.216 | L2-Norm(final)=14.292 | 4849.7 samples/s | 75.8 steps/s
[Step=77050 Epoch=75.2] | Loss=0.01122 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.221 | L2-Norm(final)=14.296 | 4724.3 samples/s | 73.8 steps/s
[Step=77100 Epoch=75.3] | Loss=0.01109 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.226 | L2-Norm(final)=14.300 | 4802.7 samples/s | 75.0 steps/s
[Step=77150 Epoch=75.3] | Loss=0.01086 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.231 | L2-Norm(final)=14.304 | 4752.7 samples/s | 74.3 steps/s
[Step=77200 Epoch=75.4] | Loss=0.01084 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.236 | L2-Norm(final)=14.307 | 4842.7 samples/s | 75.7 steps/s
[Step=77250 Epoch=75.4] | Loss=0.01073 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=14.311 | 4783.5 samples/s | 74.7 steps/s
[Step=77300 Epoch=75.5] | Loss=0.01071 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.245 | L2-Norm(final)=14.315 | 4835.1 samples/s | 75.5 steps/s
[Step=77350 Epoch=75.5] | Loss=0.01067 | Reg=0.00105 | acc=0.9688 | L2-Norm=10.250 | L2-Norm(final)=14.319 | 4835.6 samples/s | 75.6 steps/s
[Step=77400 Epoch=75.6] | Loss=0.01067 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=14.322 | 4794.3 samples/s | 74.9 steps/s
[Step=77450 Epoch=75.6] | Loss=0.01075 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=14.326 | 4782.6 samples/s | 74.7 steps/s
[Step=77500 Epoch=75.7] | Loss=0.01070 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=14.329 | 5185.0 samples/s | 81.0 steps/s
[Step=77550 Epoch=75.7] | Loss=0.01056 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.266 | L2-Norm(final)=14.333 | 2131.5 samples/s | 33.3 steps/s
[Step=77600 Epoch=75.8] | Loss=0.01047 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=14.336 | 4874.3 samples/s | 76.2 steps/s
[Step=77650 Epoch=75.8] | Loss=0.01043 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.273 | L2-Norm(final)=14.339 | 4975.6 samples/s | 77.7 steps/s
[Step=77700 Epoch=75.9] | Loss=0.01051 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.277 | L2-Norm(final)=14.342 | 4817.8 samples/s | 75.3 steps/s
[Step=77750 Epoch=75.9] | Loss=0.01045 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.280 | L2-Norm(final)=14.345 | 4889.2 samples/s | 76.4 steps/s
[Step=77800 Epoch=76.0] | Loss=0.01039 | Reg=0.00106 | acc=0.9844 | L2-Norm=10.284 | L2-Norm(final)=14.348 | 4961.6 samples/s | 77.5 steps/s
[Step=77850 Epoch=76.0] | Loss=0.01035 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.287 | L2-Norm(final)=14.351 | 4985.2 samples/s | 77.9 steps/s
[Step=77900 Epoch=76.1] | Loss=0.01026 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.290 | L2-Norm(final)=14.354 | 4818.7 samples/s | 75.3 steps/s
[Step=77950 Epoch=76.1] | Loss=0.01025 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.293 | L2-Norm(final)=14.357 | 4893.3 samples/s | 76.5 steps/s
[Step=78000 Epoch=76.2] | Loss=0.01018 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.296 | L2-Norm(final)=14.359 | 4940.3 samples/s | 77.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step78000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=76001 Epoch=143.3] | Loss=0.00008 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.139 | L2-Norm(final)=13.282 | 4294.6 samples/s | 67.1 steps/s
[Step=76050 Epoch=143.4] | Loss=0.00007 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.133 | L2-Norm(final)=13.291 | 4926.5 samples/s | 77.0 steps/s
[Step=76100 Epoch=143.4] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.296 | 5202.4 samples/s | 81.3 steps/s
[Step=76150 Epoch=143.5] | Loss=0.00005 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.302 | 5251.1 samples/s | 82.0 steps/s
[Step=76200 Epoch=143.6] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.307 | 5128.3 samples/s | 80.1 steps/s
[Step=76250 Epoch=143.7] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.312 | 5167.8 samples/s | 80.7 steps/s
[Step=76300 Epoch=143.8] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.317 | 5194.7 samples/s | 81.2 steps/s
[Step=76350 Epoch=143.9] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.322 | 5249.7 samples/s | 82.0 steps/s
[Step=76400 Epoch=144.0] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.327 | 5147.5 samples/s | 80.4 steps/s
[Step=76450 Epoch=144.1] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.332 | 5236.8 samples/s | 81.8 steps/s
[Step=76500 Epoch=144.2] | Loss=0.00004 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.337 | 5247.6 samples/s | 82.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=144.2] | Loss=0.00002 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.132 | L2-Norm(final)=13.383 | 4073.5 samples/s | 63.6 steps/s
[Step=76550 Epoch=144.3] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.112 | L2-Norm(final)=13.385 | 4320.1 samples/s | 67.5 steps/s
[Step=76600 Epoch=144.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.083 | L2-Norm(final)=13.386 | 4456.9 samples/s | 69.6 steps/s
[Step=76650 Epoch=144.5] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.053 | L2-Norm(final)=13.387 | 4523.8 samples/s | 70.7 steps/s
[Step=76700 Epoch=144.6] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.023 | L2-Norm(final)=13.388 | 4524.7 samples/s | 70.7 steps/s
[Step=76750 Epoch=144.7] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.993 | L2-Norm(final)=13.388 | 4572.0 samples/s | 71.4 steps/s
[Step=76800 Epoch=144.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.963 | L2-Norm(final)=13.389 | 4495.3 samples/s | 70.2 steps/s
[Step=76850 Epoch=144.9] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.933 | L2-Norm(final)=13.389 | 4666.6 samples/s | 72.9 steps/s
[Step=76900 Epoch=145.0] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.903 | L2-Norm(final)=13.390 | 4731.7 samples/s | 73.9 steps/s
[Step=76950 Epoch=145.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.873 | L2-Norm(final)=13.391 | 4638.1 samples/s | 72.5 steps/s
[Step=77000 Epoch=145.1] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.843 | L2-Norm(final)=13.391 | 4731.5 samples/s | 73.9 steps/s
[Step=77050 Epoch=145.2] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.813 | L2-Norm(final)=13.392 | 2115.3 samples/s | 33.1 steps/s
[Step=77100 Epoch=145.3] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.783 | L2-Norm(final)=13.393 | 4609.5 samples/s | 72.0 steps/s
[Step=77150 Epoch=145.4] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.753 | L2-Norm(final)=13.394 | 4543.8 samples/s | 71.0 steps/s
[Step=77200 Epoch=145.5] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.722 | L2-Norm(final)=13.394 | 4521.4 samples/s | 70.6 steps/s
[Step=77250 Epoch=145.6] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.691 | L2-Norm(final)=13.395 | 4579.0 samples/s | 71.5 steps/s
[Step=77300 Epoch=145.7] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.660 | L2-Norm(final)=13.396 | 4533.8 samples/s | 70.8 steps/s
[Step=77350 Epoch=145.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.629 | L2-Norm(final)=13.396 | 4496.6 samples/s | 70.3 steps/s
[Step=77400 Epoch=145.9] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.598 | L2-Norm(final)=13.397 | 4521.6 samples/s | 70.6 steps/s
[Step=77450 Epoch=146.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.567 | L2-Norm(final)=13.398 | 4561.7 samples/s | 71.3 steps/s
[Step=77500 Epoch=146.1] | Loss=0.00006 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.537 | L2-Norm(final)=13.398 | 4679.1 samples/s | 73.1 steps/s
[Step=77550 Epoch=146.2] | Loss=0.00008 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.511 | L2-Norm(final)=13.399 | 5806.3 samples/s | 90.7 steps/s
[Step=77600 Epoch=146.3] | Loss=0.00008 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.488 | L2-Norm(final)=13.399 | 1958.2 samples/s | 30.6 steps/s
[Step=77650 Epoch=146.4] | Loss=0.00008 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.467 | L2-Norm(final)=13.400 | 4565.3 samples/s | 71.3 steps/s
[Step=77700 Epoch=146.5] | Loss=0.00009 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.448 | L2-Norm(final)=13.400 | 4488.6 samples/s | 70.1 steps/s
[Step=77750 Epoch=146.6] | Loss=0.00009 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.430 | L2-Norm(final)=13.401 | 4588.3 samples/s | 71.7 steps/s
[Step=77800 Epoch=146.7] | Loss=0.00009 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.414 | L2-Norm(final)=13.401 | 4500.2 samples/s | 70.3 steps/s
[Step=77850 Epoch=146.7] | Loss=0.00009 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.399 | L2-Norm(final)=13.402 | 4555.5 samples/s | 71.2 steps/s
[Step=77900 Epoch=146.8] | Loss=0.00008 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.386 | L2-Norm(final)=13.402 | 4620.1 samples/s | 72.2 steps/s
[Step=77950 Epoch=146.9] | Loss=0.00008 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.373 | L2-Norm(final)=13.402 | 4628.7 samples/s | 72.3 steps/s
[Step=78000 Epoch=147.0] | Loss=0.00008 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.360 | L2-Norm(final)=13.403 | 4686.1 samples/s | 73.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06099 | acc=0.9717 | tpr=0.9819 | fpr=0.0503 | 4566.5 samples/s | 17.8 steps/s
Avg test loss: 0.06569, Avg test acc: 0.97039, Avg tpr: 0.98094, Avg fpr: 0.05281, total FA: 412

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.15229 | acc=0.3005 | tpr=0.0086 | fpr=0.0654 | 4586.1 samples/s | 17.9 steps/s
Avg test loss: 5.17225, Avg test acc: 0.29810, Avg tpr: 0.00810, Avg fpr: 0.06409, total FA: 500

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.02898 | acc=0.1277 | tpr=0.4602 | fpr=0.8783 | 4675.0 samples/s | 18.3 steps/s
[Step= 100] | Loss=4.99357 | acc=0.1277 | tpr=0.4350 | fpr=0.8780 | 8681.7 samples/s | 33.9 steps/s
[Step= 150] | Loss=4.99522 | acc=0.1265 | tpr=0.4380 | fpr=0.8792 | 8421.2 samples/s | 32.9 steps/s
[Step= 200] | Loss=4.98481 | acc=0.1262 | tpr=0.4328 | fpr=0.8793 | 8461.0 samples/s | 33.1 steps/s
[Step= 250] | Loss=4.98500 | acc=0.1263 | tpr=0.4367 | fpr=0.8793 | 8323.3 samples/s | 32.5 steps/s
[Step= 300] | Loss=4.98333 | acc=0.1260 | tpr=0.4415 | fpr=0.8798 | 8553.5 samples/s | 33.4 steps/s
[Step= 350] | Loss=4.98217 | acc=0.1255 | tpr=0.4402 | fpr=0.8802 | 8448.0 samples/s | 33.0 steps/s
[Step= 400] | Loss=4.98195 | acc=0.1257 | tpr=0.4404 | fpr=0.8800 | 8387.5 samples/s | 32.8 steps/s
[Step= 450] | Loss=4.98394 | acc=0.1254 | tpr=0.4391 | fpr=0.8803 | 8631.7 samples/s | 33.7 steps/s
[Step= 500] | Loss=4.98685 | acc=0.1258 | tpr=0.4361 | fpr=0.8798 | 8526.4 samples/s | 33.3 steps/s
[Step= 550] | Loss=4.98765 | acc=0.1260 | tpr=0.4381 | fpr=0.8797 | 14469.9 samples/s | 56.5 steps/s
Avg test loss: 4.98842, Avg test acc: 0.12585, Avg tpr: 0.43780, Avg fpr: 0.87982, total FA: 122161

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11708 | acc=0.9837 | tpr=0.9602 | fpr=0.0159 | 4583.6 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.12493 | acc=0.9822 | tpr=0.9552 | fpr=0.0173 | 8929.7 samples/s | 34.9 steps/s
[Step= 150] | Loss=0.13097 | acc=0.9813 | tpr=0.9597 | fpr=0.0183 | 8047.5 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.13198 | acc=0.9813 | tpr=0.9639 | fpr=0.0184 | 8704.0 samples/s | 34.0 steps/s
[Step= 250] | Loss=0.13004 | acc=0.9814 | tpr=0.9598 | fpr=0.0182 | 8490.2 samples/s | 33.2 steps/s
[Step= 300] | Loss=0.13231 | acc=0.9813 | tpr=0.9593 | fpr=0.0183 | 8854.3 samples/s | 34.6 steps/s
[Step= 350] | Loss=0.13458 | acc=0.9810 | tpr=0.9593 | fpr=0.0186 | 8319.2 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.13560 | acc=0.9809 | tpr=0.9584 | fpr=0.0187 | 8897.0 samples/s | 34.8 steps/s
[Step= 450] | Loss=0.13877 | acc=0.9806 | tpr=0.9567 | fpr=0.0190 | 8297.1 samples/s | 32.4 steps/s
[Step= 500] | Loss=0.13810 | acc=0.9806 | tpr=0.9564 | fpr=0.0190 | 8379.6 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.13708 | acc=0.9806 | tpr=0.9554 | fpr=0.0189 | 15803.4 samples/s | 61.7 steps/s
Avg test loss: 0.13691, Avg test acc: 0.98066, Avg tpr: 0.95523, Avg fpr: 0.01888, total FA: 2621

server round 39/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=78001 Epoch=76.2] | Loss=0.01049 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=14.440 | 4263.2 samples/s | 66.6 steps/s
[Step=78050 Epoch=76.2] | Loss=0.02096 | Reg=0.00093 | acc=0.9688 | L2-Norm=9.637 | L2-Norm(final)=14.455 | 5255.5 samples/s | 82.1 steps/s
[Step=78100 Epoch=76.3] | Loss=0.02024 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.637 | L2-Norm(final)=14.471 | 5625.4 samples/s | 87.9 steps/s
[Step=78150 Epoch=76.3] | Loss=0.02041 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.485 | 5582.9 samples/s | 87.2 steps/s
[Step=78200 Epoch=76.3] | Loss=0.02001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.498 | 5628.0 samples/s | 87.9 steps/s
[Step=78250 Epoch=76.4] | Loss=0.01966 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.511 | 5696.5 samples/s | 89.0 steps/s
[Step=78300 Epoch=76.4] | Loss=0.01986 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.637 | L2-Norm(final)=14.524 | 5599.5 samples/s | 87.5 steps/s
[Step=78350 Epoch=76.5] | Loss=0.02016 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.537 | 5594.8 samples/s | 87.4 steps/s
[Step=78400 Epoch=76.5] | Loss=0.02008 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.637 | L2-Norm(final)=14.549 | 5654.9 samples/s | 88.4 steps/s
[Step=78450 Epoch=76.6] | Loss=0.01954 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.562 | 5398.8 samples/s | 84.4 steps/s
[Step=78500 Epoch=76.6] | Loss=0.01950 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.637 | L2-Norm(final)=14.574 | 5511.7 samples/s | 86.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=76.6] | Loss=0.01284 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=14.694 | 4203.1 samples/s | 65.7 steps/s
[Step=78550 Epoch=76.7] | Loss=0.01743 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=14.703 | 4749.2 samples/s | 74.2 steps/s
[Step=78600 Epoch=76.7] | Loss=0.01577 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.670 | L2-Norm(final)=14.709 | 4800.7 samples/s | 75.0 steps/s
[Step=78650 Epoch=76.8] | Loss=0.01504 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.682 | L2-Norm(final)=14.714 | 4852.0 samples/s | 75.8 steps/s
[Step=78700 Epoch=76.8] | Loss=0.01463 | Reg=0.00094 | acc=0.9531 | L2-Norm=9.692 | L2-Norm(final)=14.719 | 4690.7 samples/s | 73.3 steps/s
[Step=78750 Epoch=76.9] | Loss=0.01392 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.702 | L2-Norm(final)=14.725 | 4845.6 samples/s | 75.7 steps/s
[Step=78800 Epoch=76.9] | Loss=0.01411 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.710 | L2-Norm(final)=14.730 | 4763.5 samples/s | 74.4 steps/s
[Step=78850 Epoch=77.0] | Loss=0.01381 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.718 | L2-Norm(final)=14.734 | 4737.4 samples/s | 74.0 steps/s
[Step=78900 Epoch=77.0] | Loss=0.01344 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.726 | L2-Norm(final)=14.739 | 4788.0 samples/s | 74.8 steps/s
[Step=78950 Epoch=77.1] | Loss=0.01336 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.733 | L2-Norm(final)=14.743 | 4746.6 samples/s | 74.2 steps/s
[Step=79000 Epoch=77.1] | Loss=0.01332 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=14.747 | 4785.5 samples/s | 74.8 steps/s
[Step=79050 Epoch=77.2] | Loss=0.01312 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.746 | L2-Norm(final)=14.752 | 4733.6 samples/s | 74.0 steps/s
[Step=79100 Epoch=77.2] | Loss=0.01301 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.752 | L2-Norm(final)=14.755 | 4773.5 samples/s | 74.6 steps/s
[Step=79150 Epoch=77.3] | Loss=0.01287 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.758 | L2-Norm(final)=14.759 | 4905.7 samples/s | 76.7 steps/s
[Step=79200 Epoch=77.3] | Loss=0.01273 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.763 | L2-Norm(final)=14.763 | 4815.8 samples/s | 75.2 steps/s
[Step=79250 Epoch=77.4] | Loss=0.01262 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.769 | L2-Norm(final)=14.767 | 4756.3 samples/s | 74.3 steps/s
[Step=79300 Epoch=77.4] | Loss=0.01261 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.774 | L2-Norm(final)=14.771 | 4776.5 samples/s | 74.6 steps/s
[Step=79350 Epoch=77.5] | Loss=0.01248 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.779 | L2-Norm(final)=14.775 | 4791.2 samples/s | 74.9 steps/s
[Step=79400 Epoch=77.5] | Loss=0.01245 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.784 | L2-Norm(final)=14.778 | 4822.6 samples/s | 75.4 steps/s
[Step=79450 Epoch=77.6] | Loss=0.01228 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.789 | L2-Norm(final)=14.782 | 4775.4 samples/s | 74.6 steps/s
[Step=79500 Epoch=77.6] | Loss=0.01224 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.794 | L2-Norm(final)=14.785 | 5143.6 samples/s | 80.4 steps/s
[Step=79550 Epoch=77.7] | Loss=0.01218 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.799 | L2-Norm(final)=14.789 | 2110.8 samples/s | 33.0 steps/s
[Step=79600 Epoch=77.7] | Loss=0.01206 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.803 | L2-Norm(final)=14.792 | 4776.9 samples/s | 74.6 steps/s
[Step=79650 Epoch=77.8] | Loss=0.01181 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.808 | L2-Norm(final)=14.796 | 4694.7 samples/s | 73.4 steps/s
[Step=79700 Epoch=77.8] | Loss=0.01166 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.812 | L2-Norm(final)=14.800 | 4853.5 samples/s | 75.8 steps/s
[Step=79750 Epoch=77.9] | Loss=0.01156 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.816 | L2-Norm(final)=14.803 | 4702.3 samples/s | 73.5 steps/s
[Step=79800 Epoch=77.9] | Loss=0.01152 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.821 | L2-Norm(final)=14.807 | 4798.6 samples/s | 75.0 steps/s
[Step=79850 Epoch=78.0] | Loss=0.01141 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.825 | L2-Norm(final)=14.810 | 4797.0 samples/s | 75.0 steps/s
[Step=79900 Epoch=78.0] | Loss=0.01135 | Reg=0.00097 | acc=0.9844 | L2-Norm=9.829 | L2-Norm(final)=14.813 | 4863.9 samples/s | 76.0 steps/s
[Step=79950 Epoch=78.1] | Loss=0.01123 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.832 | L2-Norm(final)=14.816 | 4784.6 samples/s | 74.8 steps/s
[Step=80000 Epoch=78.1] | Loss=0.01117 | Reg=0.00097 | acc=0.9688 | L2-Norm=9.836 | L2-Norm(final)=14.819 | 4745.2 samples/s | 74.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step80000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00013, len=1
[Step=78001 Epoch=147.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=13.416 | 4026.4 samples/s | 62.9 steps/s
[Step=78050 Epoch=147.1] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.416 | 5081.1 samples/s | 79.4 steps/s
[Step=78100 Epoch=147.2] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.417 | 5287.8 samples/s | 82.6 steps/s
[Step=78150 Epoch=147.3] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.418 | 5413.7 samples/s | 84.6 steps/s
[Step=78200 Epoch=147.4] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.419 | 5079.8 samples/s | 79.4 steps/s
[Step=78250 Epoch=147.5] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.420 | 5307.8 samples/s | 82.9 steps/s
[Step=78300 Epoch=147.6] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.420 | 5199.1 samples/s | 81.2 steps/s
[Step=78350 Epoch=147.7] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.421 | 5137.3 samples/s | 80.3 steps/s
[Step=78400 Epoch=147.8] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.422 | 5330.7 samples/s | 83.3 steps/s
[Step=78450 Epoch=147.9] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.423 | 5064.0 samples/s | 79.1 steps/s
[Step=78500 Epoch=148.0] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.424 | 5368.1 samples/s | 83.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=148.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.433 | 4497.8 samples/s | 70.3 steps/s
[Step=78550 Epoch=148.1] | Loss=0.00004 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.633 | L2-Norm(final)=13.434 | 3869.4 samples/s | 60.5 steps/s
[Step=78600 Epoch=148.2] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.630 | L2-Norm(final)=13.435 | 4544.4 samples/s | 71.0 steps/s
[Step=78650 Epoch=148.3] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.628 | L2-Norm(final)=13.436 | 4592.5 samples/s | 71.8 steps/s
[Step=78700 Epoch=148.4] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.626 | L2-Norm(final)=13.438 | 4658.9 samples/s | 72.8 steps/s
[Step=78750 Epoch=148.4] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.624 | L2-Norm(final)=13.439 | 4731.2 samples/s | 73.9 steps/s
[Step=78800 Epoch=148.5] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.623 | L2-Norm(final)=13.440 | 4477.9 samples/s | 70.0 steps/s
[Step=78850 Epoch=148.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.621 | L2-Norm(final)=13.441 | 4682.5 samples/s | 73.2 steps/s
[Step=78900 Epoch=148.7] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.619 | L2-Norm(final)=13.443 | 4512.6 samples/s | 70.5 steps/s
[Step=78950 Epoch=148.8] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.617 | L2-Norm(final)=13.444 | 4596.0 samples/s | 71.8 steps/s
[Step=79000 Epoch=148.9] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.615 | L2-Norm(final)=13.445 | 4578.4 samples/s | 71.5 steps/s
[Step=79050 Epoch=149.0] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=13.446 | 2084.1 samples/s | 32.6 steps/s
[Step=79100 Epoch=149.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.611 | L2-Norm(final)=13.447 | 4600.5 samples/s | 71.9 steps/s
[Step=79150 Epoch=149.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.609 | L2-Norm(final)=13.448 | 4505.7 samples/s | 70.4 steps/s
[Step=79200 Epoch=149.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.607 | L2-Norm(final)=13.449 | 4486.8 samples/s | 70.1 steps/s
[Step=79250 Epoch=149.4] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.605 | L2-Norm(final)=13.450 | 4553.0 samples/s | 71.1 steps/s
[Step=79300 Epoch=149.5] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.603 | L2-Norm(final)=13.451 | 4464.5 samples/s | 69.8 steps/s
[Step=79350 Epoch=149.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.601 | L2-Norm(final)=13.451 | 4591.3 samples/s | 71.7 steps/s
[Step=79400 Epoch=149.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.599 | L2-Norm(final)=13.452 | 4521.4 samples/s | 70.6 steps/s
[Step=79450 Epoch=149.8] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.597 | L2-Norm(final)=13.453 | 4537.5 samples/s | 70.9 steps/s
[Step=79500 Epoch=149.9] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.595 | L2-Norm(final)=13.454 | 4553.1 samples/s | 71.1 steps/s
[Step=79550 Epoch=150.0] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.593 | L2-Norm(final)=13.455 | 5662.4 samples/s | 88.5 steps/s
[Step=79600 Epoch=150.0] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.591 | L2-Norm(final)=13.456 | 1951.2 samples/s | 30.5 steps/s
[Step=79650 Epoch=150.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.588 | L2-Norm(final)=13.456 | 4512.9 samples/s | 70.5 steps/s
[Step=79700 Epoch=150.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.586 | L2-Norm(final)=13.457 | 4488.7 samples/s | 70.1 steps/s
[Step=79750 Epoch=150.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.584 | L2-Norm(final)=13.458 | 4540.6 samples/s | 70.9 steps/s
[Step=79800 Epoch=150.4] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.581 | L2-Norm(final)=13.459 | 4567.6 samples/s | 71.4 steps/s
[Step=79850 Epoch=150.5] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.579 | L2-Norm(final)=13.460 | 4535.0 samples/s | 70.9 steps/s
[Step=79900 Epoch=150.6] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.577 | L2-Norm(final)=13.460 | 4535.2 samples/s | 70.9 steps/s
[Step=79950 Epoch=150.7] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.574 | L2-Norm(final)=13.461 | 4573.5 samples/s | 71.5 steps/s
[Step=80000 Epoch=150.8] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.572 | L2-Norm(final)=13.462 | 4520.4 samples/s | 70.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05233 | acc=0.9738 | tpr=0.9798 | fpr=0.0391 | 4641.3 samples/s | 18.1 steps/s
Avg test loss: 0.05916, Avg test acc: 0.97175, Avg tpr: 0.97808, Avg fpr: 0.04217, total FA: 329

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.64974 | acc=0.2966 | tpr=0.0100 | fpr=0.0813 | 4516.1 samples/s | 17.6 steps/s
Avg test loss: 4.65924, Avg test acc: 0.29393, Avg tpr: 0.00991, Avg fpr: 0.08140, total FA: 635

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.60966 | acc=0.1430 | tpr=0.3982 | fpr=0.8616 | 4568.9 samples/s | 17.8 steps/s
[Step= 100] | Loss=4.57774 | acc=0.1429 | tpr=0.3710 | fpr=0.8614 | 8339.1 samples/s | 32.6 steps/s
[Step= 150] | Loss=4.58006 | acc=0.1420 | tpr=0.3804 | fpr=0.8624 | 8763.8 samples/s | 34.2 steps/s
[Step= 200] | Loss=4.56923 | acc=0.1410 | tpr=0.3760 | fpr=0.8632 | 8766.0 samples/s | 34.2 steps/s
[Step= 250] | Loss=4.57102 | acc=0.1414 | tpr=0.3817 | fpr=0.8630 | 8124.8 samples/s | 31.7 steps/s
[Step= 300] | Loss=4.56935 | acc=0.1410 | tpr=0.3847 | fpr=0.8634 | 8878.0 samples/s | 34.7 steps/s
[Step= 350] | Loss=4.56752 | acc=0.1406 | tpr=0.3826 | fpr=0.8638 | 8417.3 samples/s | 32.9 steps/s
[Step= 400] | Loss=4.56694 | acc=0.1409 | tpr=0.3846 | fpr=0.8635 | 8425.8 samples/s | 32.9 steps/s
[Step= 450] | Loss=4.56829 | acc=0.1411 | tpr=0.3861 | fpr=0.8634 | 8632.8 samples/s | 33.7 steps/s
[Step= 500] | Loss=4.57147 | acc=0.1412 | tpr=0.3859 | fpr=0.8632 | 8620.6 samples/s | 33.7 steps/s
[Step= 550] | Loss=4.57237 | acc=0.1415 | tpr=0.3868 | fpr=0.8630 | 15961.2 samples/s | 62.3 steps/s
Avg test loss: 4.57308, Avg test acc: 0.14138, Avg tpr: 0.38669, Avg fpr: 0.86308, total FA: 119837

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10942 | acc=0.9834 | tpr=0.9558 | fpr=0.0161 | 4632.9 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.11639 | acc=0.9823 | tpr=0.9552 | fpr=0.0172 | 8472.1 samples/s | 33.1 steps/s
[Step= 150] | Loss=0.12137 | acc=0.9815 | tpr=0.9611 | fpr=0.0181 | 8280.0 samples/s | 32.3 steps/s
[Step= 200] | Loss=0.12264 | acc=0.9815 | tpr=0.9650 | fpr=0.0182 | 8521.8 samples/s | 33.3 steps/s
[Step= 250] | Loss=0.12088 | acc=0.9817 | tpr=0.9598 | fpr=0.0179 | 8935.8 samples/s | 34.9 steps/s
[Step= 300] | Loss=0.12270 | acc=0.9815 | tpr=0.9585 | fpr=0.0181 | 8171.6 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.12472 | acc=0.9811 | tpr=0.9580 | fpr=0.0184 | 8553.6 samples/s | 33.4 steps/s
[Step= 400] | Loss=0.12562 | acc=0.9811 | tpr=0.9573 | fpr=0.0185 | 8462.8 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.12863 | acc=0.9807 | tpr=0.9557 | fpr=0.0188 | 9173.0 samples/s | 35.8 steps/s
[Step= 500] | Loss=0.12807 | acc=0.9807 | tpr=0.9551 | fpr=0.0188 | 8463.5 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.12718 | acc=0.9808 | tpr=0.9542 | fpr=0.0187 | 14614.9 samples/s | 57.1 steps/s
Avg test loss: 0.12703, Avg test acc: 0.98085, Avg tpr: 0.95404, Avg fpr: 0.01866, total FA: 2591

server round 40/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=80001 Epoch=78.1] | Loss=0.01202 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=14.911 | 4286.2 samples/s | 67.0 steps/s
[Step=80050 Epoch=78.2] | Loss=0.01089 | Reg=0.00094 | acc=0.9688 | L2-Norm=9.690 | L2-Norm(final)=14.915 | 5164.4 samples/s | 80.7 steps/s
[Step=80100 Epoch=78.2] | Loss=0.00969 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.920 | 5505.2 samples/s | 86.0 steps/s
[Step=80150 Epoch=78.3] | Loss=0.01028 | Reg=0.00094 | acc=0.9688 | L2-Norm=9.690 | L2-Norm(final)=14.924 | 5457.9 samples/s | 85.3 steps/s
[Step=80200 Epoch=78.3] | Loss=0.01003 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.928 | 5491.0 samples/s | 85.8 steps/s
[Step=80250 Epoch=78.4] | Loss=0.01046 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.690 | L2-Norm(final)=14.932 | 5484.1 samples/s | 85.7 steps/s
[Step=80300 Epoch=78.4] | Loss=0.01021 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.936 | 5500.8 samples/s | 86.0 steps/s
[Step=80350 Epoch=78.4] | Loss=0.01018 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.940 | 5457.7 samples/s | 85.3 steps/s
[Step=80400 Epoch=78.5] | Loss=0.01013 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.944 | 5607.7 samples/s | 87.6 steps/s
[Step=80450 Epoch=78.5] | Loss=0.01012 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.949 | 5530.6 samples/s | 86.4 steps/s
[Step=80500 Epoch=78.6] | Loss=0.01013 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.690 | L2-Norm(final)=14.953 | 5465.9 samples/s | 85.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=78.6] | Loss=0.00880 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.690 | L2-Norm(final)=14.998 | 4225.3 samples/s | 66.0 steps/s
[Step=80550 Epoch=78.6] | Loss=0.01116 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.694 | L2-Norm(final)=15.002 | 4424.9 samples/s | 69.1 steps/s
[Step=80600 Epoch=78.7] | Loss=0.01063 | Reg=0.00094 | acc=0.9688 | L2-Norm=9.699 | L2-Norm(final)=15.005 | 4744.9 samples/s | 74.1 steps/s
[Step=80650 Epoch=78.7] | Loss=0.01009 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.703 | L2-Norm(final)=15.009 | 4759.1 samples/s | 74.4 steps/s
[Step=80700 Epoch=78.8] | Loss=0.00942 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.707 | L2-Norm(final)=15.012 | 4777.4 samples/s | 74.6 steps/s
[Step=80750 Epoch=78.8] | Loss=0.00898 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.711 | L2-Norm(final)=15.015 | 4748.3 samples/s | 74.2 steps/s
[Step=80800 Epoch=78.9] | Loss=0.00881 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.714 | L2-Norm(final)=15.019 | 4763.4 samples/s | 74.4 steps/s
[Step=80850 Epoch=78.9] | Loss=0.00915 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.717 | L2-Norm(final)=15.021 | 4786.8 samples/s | 74.8 steps/s
[Step=80900 Epoch=79.0] | Loss=0.00891 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.720 | L2-Norm(final)=15.024 | 4795.8 samples/s | 74.9 steps/s
[Step=80950 Epoch=79.0] | Loss=0.00894 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.723 | L2-Norm(final)=15.027 | 4752.6 samples/s | 74.3 steps/s
[Step=81000 Epoch=79.1] | Loss=0.00894 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.726 | L2-Norm(final)=15.029 | 4798.2 samples/s | 75.0 steps/s
[Step=81050 Epoch=79.1] | Loss=0.00880 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.728 | L2-Norm(final)=15.032 | 4813.1 samples/s | 75.2 steps/s
[Step=81100 Epoch=79.2] | Loss=0.00880 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.731 | L2-Norm(final)=15.034 | 4704.5 samples/s | 73.5 steps/s
[Step=81150 Epoch=79.2] | Loss=0.00880 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.734 | L2-Norm(final)=15.037 | 4791.5 samples/s | 74.9 steps/s
[Step=81200 Epoch=79.3] | Loss=0.00887 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.736 | L2-Norm(final)=15.039 | 4811.9 samples/s | 75.2 steps/s
[Step=81250 Epoch=79.3] | Loss=0.00896 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.739 | L2-Norm(final)=15.042 | 4782.8 samples/s | 74.7 steps/s
[Step=81300 Epoch=79.4] | Loss=0.00893 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.741 | L2-Norm(final)=15.044 | 4793.3 samples/s | 74.9 steps/s
[Step=81350 Epoch=79.4] | Loss=0.00892 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.744 | L2-Norm(final)=15.046 | 4799.2 samples/s | 75.0 steps/s
[Step=81400 Epoch=79.5] | Loss=0.00890 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.746 | L2-Norm(final)=15.049 | 4822.9 samples/s | 75.4 steps/s
[Step=81450 Epoch=79.5] | Loss=0.00885 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.748 | L2-Norm(final)=15.051 | 4766.1 samples/s | 74.5 steps/s
[Step=81500 Epoch=79.6] | Loss=0.00877 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.751 | L2-Norm(final)=15.054 | 5102.5 samples/s | 79.7 steps/s
[Step=81550 Epoch=79.6] | Loss=0.00866 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.753 | L2-Norm(final)=15.056 | 2122.7 samples/s | 33.2 steps/s
[Step=81600 Epoch=79.7] | Loss=0.00856 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.755 | L2-Norm(final)=15.058 | 4734.7 samples/s | 74.0 steps/s
[Step=81650 Epoch=79.7] | Loss=0.00853 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.757 | L2-Norm(final)=15.061 | 4780.8 samples/s | 74.7 steps/s
[Step=81700 Epoch=79.8] | Loss=0.00847 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.760 | L2-Norm(final)=15.063 | 4772.2 samples/s | 74.6 steps/s
[Step=81750 Epoch=79.8] | Loss=0.00845 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.762 | L2-Norm(final)=15.066 | 4747.2 samples/s | 74.2 steps/s
[Step=81800 Epoch=79.9] | Loss=0.00842 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.764 | L2-Norm(final)=15.068 | 4800.0 samples/s | 75.0 steps/s
[Step=81850 Epoch=79.9] | Loss=0.00839 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.766 | L2-Norm(final)=15.070 | 4804.1 samples/s | 75.1 steps/s
[Step=81900 Epoch=80.0] | Loss=0.00828 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.768 | L2-Norm(final)=15.073 | 4830.7 samples/s | 75.5 steps/s
[Step=81950 Epoch=80.0] | Loss=0.00829 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.770 | L2-Norm(final)=15.075 | 4919.4 samples/s | 76.9 steps/s
[Step=82000 Epoch=80.1] | Loss=0.00827 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.772 | L2-Norm(final)=15.077 | 4935.0 samples/s | 77.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step82000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=80001 Epoch=150.8] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.487 | 4202.0 samples/s | 65.7 steps/s
[Step=80050 Epoch=150.9] | Loss=0.00006 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.488 | 5198.8 samples/s | 81.2 steps/s
[Step=80100 Epoch=151.0] | Loss=0.00005 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.492 | 5296.5 samples/s | 82.8 steps/s
[Step=80150 Epoch=151.1] | Loss=0.00005 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.495 | 5353.4 samples/s | 83.6 steps/s
[Step=80200 Epoch=151.2] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.497 | 5295.3 samples/s | 82.7 steps/s
[Step=80250 Epoch=151.3] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.499 | 5280.2 samples/s | 82.5 steps/s
[Step=80300 Epoch=151.4] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.502 | 5398.7 samples/s | 84.4 steps/s
[Step=80350 Epoch=151.5] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.504 | 5388.7 samples/s | 84.2 steps/s
[Step=80400 Epoch=151.6] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.507 | 5293.2 samples/s | 82.7 steps/s
[Step=80450 Epoch=151.6] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.509 | 5300.2 samples/s | 82.8 steps/s
[Step=80500 Epoch=151.7] | Loss=0.00004 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.512 | 5425.4 samples/s | 84.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=151.7] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.689 | L2-Norm(final)=13.537 | 4300.8 samples/s | 67.2 steps/s
[Step=80550 Epoch=151.8] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=13.538 | 4155.4 samples/s | 64.9 steps/s
[Step=80600 Epoch=151.9] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.682 | L2-Norm(final)=13.541 | 4539.8 samples/s | 70.9 steps/s
[Step=80650 Epoch=152.0] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.680 | L2-Norm(final)=13.542 | 4582.2 samples/s | 71.6 steps/s
[Step=80700 Epoch=152.1] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.678 | L2-Norm(final)=13.544 | 4556.1 samples/s | 71.2 steps/s
[Step=80750 Epoch=152.2] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.675 | L2-Norm(final)=13.545 | 4552.4 samples/s | 71.1 steps/s
[Step=80800 Epoch=152.3] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.673 | L2-Norm(final)=13.546 | 4607.4 samples/s | 72.0 steps/s
[Step=80850 Epoch=152.4] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.670 | L2-Norm(final)=13.547 | 4647.3 samples/s | 72.6 steps/s
[Step=80900 Epoch=152.5] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.668 | L2-Norm(final)=13.548 | 4495.2 samples/s | 70.2 steps/s
[Step=80950 Epoch=152.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.665 | L2-Norm(final)=13.549 | 4620.6 samples/s | 72.2 steps/s
[Step=81000 Epoch=152.7] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.663 | L2-Norm(final)=13.550 | 4599.9 samples/s | 71.9 steps/s
[Step=81050 Epoch=152.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.660 | L2-Norm(final)=13.550 | 2158.0 samples/s | 33.7 steps/s
[Step=81100 Epoch=152.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.657 | L2-Norm(final)=13.551 | 4627.2 samples/s | 72.3 steps/s
[Step=81150 Epoch=153.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=13.552 | 4511.3 samples/s | 70.5 steps/s
[Step=81200 Epoch=153.1] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.652 | L2-Norm(final)=13.552 | 4544.8 samples/s | 71.0 steps/s
[Step=81250 Epoch=153.2] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.649 | L2-Norm(final)=13.553 | 4475.3 samples/s | 69.9 steps/s
[Step=81300 Epoch=153.3] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.553 | 4528.1 samples/s | 70.8 steps/s
[Step=81350 Epoch=153.3] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.643 | L2-Norm(final)=13.554 | 4535.0 samples/s | 70.9 steps/s
[Step=81400 Epoch=153.4] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.640 | L2-Norm(final)=13.554 | 4492.6 samples/s | 70.2 steps/s
[Step=81450 Epoch=153.5] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=13.555 | 4543.2 samples/s | 71.0 steps/s
[Step=81500 Epoch=153.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.634 | L2-Norm(final)=13.555 | 4550.0 samples/s | 71.1 steps/s
[Step=81550 Epoch=153.7] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.631 | L2-Norm(final)=13.556 | 5691.5 samples/s | 88.9 steps/s
[Step=81600 Epoch=153.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.628 | L2-Norm(final)=13.556 | 2012.0 samples/s | 31.4 steps/s
[Step=81650 Epoch=153.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.625 | L2-Norm(final)=13.557 | 4504.8 samples/s | 70.4 steps/s
[Step=81700 Epoch=154.0] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.622 | L2-Norm(final)=13.557 | 4555.8 samples/s | 71.2 steps/s
[Step=81750 Epoch=154.1] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.619 | L2-Norm(final)=13.558 | 4550.7 samples/s | 71.1 steps/s
[Step=81800 Epoch=154.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.616 | L2-Norm(final)=13.558 | 4473.7 samples/s | 69.9 steps/s
[Step=81850 Epoch=154.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=13.559 | 4533.2 samples/s | 70.8 steps/s
[Step=81900 Epoch=154.4] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.609 | L2-Norm(final)=13.559 | 4537.9 samples/s | 70.9 steps/s
[Step=81950 Epoch=154.5] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.606 | L2-Norm(final)=13.560 | 4532.2 samples/s | 70.8 steps/s
[Step=82000 Epoch=154.6] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.603 | L2-Norm(final)=13.560 | 4605.0 samples/s | 72.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05522 | acc=0.9727 | tpr=0.9787 | fpr=0.0401 | 4540.2 samples/s | 17.7 steps/s
Avg test loss: 0.06032, Avg test acc: 0.97107, Avg tpr: 0.97779, Avg fpr: 0.04371, total FA: 341

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.63559 | acc=0.2953 | tpr=0.0120 | fpr=0.0894 | 4543.4 samples/s | 17.7 steps/s
Avg test loss: 4.64288, Avg test acc: 0.29265, Avg tpr: 0.01271, Avg fpr: 0.09165, total FA: 715

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.59383 | acc=0.1477 | tpr=0.3496 | fpr=0.8559 | 4597.7 samples/s | 18.0 steps/s
[Step= 100] | Loss=4.56052 | acc=0.1466 | tpr=0.3198 | fpr=0.8567 | 8501.9 samples/s | 33.2 steps/s
[Step= 150] | Loss=4.56152 | acc=0.1458 | tpr=0.3285 | fpr=0.8576 | 8750.7 samples/s | 34.2 steps/s
[Step= 200] | Loss=4.54965 | acc=0.1455 | tpr=0.3311 | fpr=0.8579 | 8263.7 samples/s | 32.3 steps/s
[Step= 250] | Loss=4.55114 | acc=0.1458 | tpr=0.3345 | fpr=0.8577 | 8597.4 samples/s | 33.6 steps/s
[Step= 300] | Loss=4.54866 | acc=0.1455 | tpr=0.3360 | fpr=0.8580 | 8527.6 samples/s | 33.3 steps/s
[Step= 350] | Loss=4.54655 | acc=0.1449 | tpr=0.3312 | fpr=0.8585 | 8381.8 samples/s | 32.7 steps/s
[Step= 400] | Loss=4.54608 | acc=0.1451 | tpr=0.3326 | fpr=0.8583 | 9049.3 samples/s | 35.3 steps/s
[Step= 450] | Loss=4.54718 | acc=0.1452 | tpr=0.3306 | fpr=0.8582 | 7901.1 samples/s | 30.9 steps/s
[Step= 500] | Loss=4.55028 | acc=0.1455 | tpr=0.3300 | fpr=0.8578 | 8767.4 samples/s | 34.2 steps/s
[Step= 550] | Loss=4.55106 | acc=0.1456 | tpr=0.3319 | fpr=0.8578 | 15007.1 samples/s | 58.6 steps/s
Avg test loss: 4.55183, Avg test acc: 0.14548, Avg tpr: 0.33201, Avg fpr: 0.85791, total FA: 119119

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11491 | acc=0.9830 | tpr=0.9513 | fpr=0.0165 | 4638.7 samples/s | 18.1 steps/s
[Step= 100] | Loss=0.12253 | acc=0.9819 | tpr=0.9552 | fpr=0.0176 | 8242.9 samples/s | 32.2 steps/s
[Step= 150] | Loss=0.12778 | acc=0.9811 | tpr=0.9625 | fpr=0.0186 | 8747.4 samples/s | 34.2 steps/s
[Step= 200] | Loss=0.12888 | acc=0.9812 | tpr=0.9672 | fpr=0.0186 | 8441.8 samples/s | 33.0 steps/s
[Step= 250] | Loss=0.12711 | acc=0.9813 | tpr=0.9624 | fpr=0.0184 | 8534.1 samples/s | 33.3 steps/s
[Step= 300] | Loss=0.12888 | acc=0.9810 | tpr=0.9622 | fpr=0.0186 | 8662.6 samples/s | 33.8 steps/s
[Step= 350] | Loss=0.13098 | acc=0.9807 | tpr=0.9612 | fpr=0.0190 | 8307.3 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.13177 | acc=0.9806 | tpr=0.9601 | fpr=0.0191 | 8655.8 samples/s | 33.8 steps/s
[Step= 450] | Loss=0.13485 | acc=0.9802 | tpr=0.9586 | fpr=0.0194 | 7049.7 samples/s | 27.5 steps/s
[Step= 500] | Loss=0.13438 | acc=0.9802 | tpr=0.9577 | fpr=0.0194 | 6964.2 samples/s | 27.2 steps/s
[Step= 550] | Loss=0.13352 | acc=0.9803 | tpr=0.9566 | fpr=0.0192 | 13400.9 samples/s | 52.3 steps/s
Avg test loss: 0.13336, Avg test acc: 0.98034, Avg tpr: 0.95642, Avg fpr: 0.01922, total FA: 2669

server round 41/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=82001 Epoch=80.1] | Loss=0.00614 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=15.145 | 4079.9 samples/s | 63.7 steps/s
[Step=82050 Epoch=80.1] | Loss=0.00637 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.148 | 4437.1 samples/s | 69.3 steps/s
[Step=82100 Epoch=80.2] | Loss=0.00747 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.648 | L2-Norm(final)=15.152 | 5244.5 samples/s | 81.9 steps/s
[Step=82150 Epoch=80.2] | Loss=0.00868 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.154 | 5625.7 samples/s | 87.9 steps/s
[Step=82200 Epoch=80.3] | Loss=0.00846 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.648 | L2-Norm(final)=15.157 | 5422.8 samples/s | 84.7 steps/s
[Step=82250 Epoch=80.3] | Loss=0.00858 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.648 | L2-Norm(final)=15.159 | 5451.7 samples/s | 85.2 steps/s
[Step=82300 Epoch=80.4] | Loss=0.00857 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.161 | 5526.9 samples/s | 86.4 steps/s
[Step=82350 Epoch=80.4] | Loss=0.00863 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.648 | L2-Norm(final)=15.164 | 5526.7 samples/s | 86.4 steps/s
[Step=82400 Epoch=80.5] | Loss=0.00886 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.166 | 5573.7 samples/s | 87.1 steps/s
[Step=82450 Epoch=80.5] | Loss=0.00882 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.169 | 5470.2 samples/s | 85.5 steps/s
[Step=82500 Epoch=80.5] | Loss=0.00877 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.171 | 5430.6 samples/s | 84.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=80.5] | Loss=0.00478 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.648 | L2-Norm(final)=15.197 | 4322.3 samples/s | 67.5 steps/s
[Step=82550 Epoch=80.6] | Loss=0.00919 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.651 | L2-Norm(final)=15.200 | 4594.8 samples/s | 71.8 steps/s
[Step=82600 Epoch=80.6] | Loss=0.00860 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=15.203 | 4719.1 samples/s | 73.7 steps/s
[Step=82650 Epoch=80.7] | Loss=0.00852 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.659 | L2-Norm(final)=15.206 | 4783.9 samples/s | 74.7 steps/s
[Step=82700 Epoch=80.7] | Loss=0.00855 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.662 | L2-Norm(final)=15.209 | 4737.9 samples/s | 74.0 steps/s
[Step=82750 Epoch=80.8] | Loss=0.00879 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.666 | L2-Norm(final)=15.212 | 4792.8 samples/s | 74.9 steps/s
[Step=82800 Epoch=80.8] | Loss=0.00860 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.669 | L2-Norm(final)=15.215 | 4798.4 samples/s | 75.0 steps/s
[Step=82850 Epoch=80.9] | Loss=0.00864 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.673 | L2-Norm(final)=15.218 | 4870.9 samples/s | 76.1 steps/s
[Step=82900 Epoch=80.9] | Loss=0.00878 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.676 | L2-Norm(final)=15.221 | 4762.5 samples/s | 74.4 steps/s
[Step=82950 Epoch=81.0] | Loss=0.00884 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.680 | L2-Norm(final)=15.223 | 4771.3 samples/s | 74.6 steps/s
[Step=83000 Epoch=81.0] | Loss=0.00854 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.683 | L2-Norm(final)=15.226 | 4754.7 samples/s | 74.3 steps/s
[Step=83050 Epoch=81.1] | Loss=0.00855 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.686 | L2-Norm(final)=15.228 | 4762.8 samples/s | 74.4 steps/s
[Step=83100 Epoch=81.1] | Loss=0.00860 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.688 | L2-Norm(final)=15.231 | 4895.1 samples/s | 76.5 steps/s
[Step=83150 Epoch=81.2] | Loss=0.00866 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.691 | L2-Norm(final)=15.233 | 4785.1 samples/s | 74.8 steps/s
[Step=83200 Epoch=81.2] | Loss=0.00870 | Reg=0.00094 | acc=0.9688 | L2-Norm=9.694 | L2-Norm(final)=15.235 | 4850.9 samples/s | 75.8 steps/s
[Step=83250 Epoch=81.3] | Loss=0.00874 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.696 | L2-Norm(final)=15.237 | 4769.9 samples/s | 74.5 steps/s
[Step=83300 Epoch=81.3] | Loss=0.00865 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.699 | L2-Norm(final)=15.240 | 4730.4 samples/s | 73.9 steps/s
[Step=83350 Epoch=81.4] | Loss=0.00852 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.701 | L2-Norm(final)=15.242 | 4745.8 samples/s | 74.2 steps/s
[Step=83400 Epoch=81.4] | Loss=0.00855 | Reg=0.00094 | acc=0.9531 | L2-Norm=9.704 | L2-Norm(final)=15.244 | 4765.0 samples/s | 74.5 steps/s
[Step=83450 Epoch=81.5] | Loss=0.00852 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.706 | L2-Norm(final)=15.246 | 4795.8 samples/s | 74.9 steps/s
[Step=83500 Epoch=81.5] | Loss=0.00836 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.708 | L2-Norm(final)=15.249 | 5126.1 samples/s | 80.1 steps/s
[Step=83550 Epoch=81.6] | Loss=0.00828 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.711 | L2-Norm(final)=15.251 | 2077.0 samples/s | 32.5 steps/s
[Step=83600 Epoch=81.6] | Loss=0.00821 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.713 | L2-Norm(final)=15.254 | 4768.8 samples/s | 74.5 steps/s
[Step=83650 Epoch=81.7] | Loss=0.00821 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.715 | L2-Norm(final)=15.256 | 4779.9 samples/s | 74.7 steps/s
[Step=83700 Epoch=81.7] | Loss=0.00815 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.717 | L2-Norm(final)=15.258 | 4747.6 samples/s | 74.2 steps/s
[Step=83750 Epoch=81.8] | Loss=0.00810 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.719 | L2-Norm(final)=15.260 | 4720.9 samples/s | 73.8 steps/s
[Step=83800 Epoch=81.8] | Loss=0.00808 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.721 | L2-Norm(final)=15.263 | 4771.3 samples/s | 74.6 steps/s
[Step=83850 Epoch=81.9] | Loss=0.00808 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.723 | L2-Norm(final)=15.265 | 4738.5 samples/s | 74.0 steps/s
[Step=83900 Epoch=81.9] | Loss=0.00803 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.725 | L2-Norm(final)=15.267 | 4788.9 samples/s | 74.8 steps/s
[Step=83950 Epoch=82.0] | Loss=0.00793 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.727 | L2-Norm(final)=15.269 | 4807.6 samples/s | 75.1 steps/s
[Step=84000 Epoch=82.0] | Loss=0.00787 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.729 | L2-Norm(final)=15.272 | 4758.3 samples/s | 74.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step84000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=82001 Epoch=154.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=13.573 | 4264.6 samples/s | 66.6 steps/s
[Step=82050 Epoch=154.7] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.577 | 4942.9 samples/s | 77.2 steps/s
[Step=82100 Epoch=154.8] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.582 | 5113.9 samples/s | 79.9 steps/s
[Step=82150 Epoch=154.9] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.586 | 5075.2 samples/s | 79.3 steps/s
[Step=82200 Epoch=154.9] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.590 | 5188.5 samples/s | 81.1 steps/s
[Step=82250 Epoch=155.0] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.594 | 5239.3 samples/s | 81.9 steps/s
[Step=82300 Epoch=155.1] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.598 | 5129.9 samples/s | 80.2 steps/s
[Step=82350 Epoch=155.2] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.601 | 5172.1 samples/s | 80.8 steps/s
[Step=82400 Epoch=155.3] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.605 | 5307.9 samples/s | 82.9 steps/s
[Step=82450 Epoch=155.4] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.608 | 5225.1 samples/s | 81.6 steps/s
[Step=82500 Epoch=155.5] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.612 | 5180.9 samples/s | 81.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=155.5] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.646 | L2-Norm(final)=13.651 | 3906.4 samples/s | 61.0 steps/s
[Step=82550 Epoch=155.6] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=13.654 | 4503.8 samples/s | 70.4 steps/s
[Step=82600 Epoch=155.7] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.635 | L2-Norm(final)=13.656 | 4598.5 samples/s | 71.9 steps/s
[Step=82650 Epoch=155.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.629 | L2-Norm(final)=13.657 | 4469.5 samples/s | 69.8 steps/s
[Step=82700 Epoch=155.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.623 | L2-Norm(final)=13.658 | 4596.0 samples/s | 71.8 steps/s
[Step=82750 Epoch=156.0] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.617 | L2-Norm(final)=13.659 | 4558.3 samples/s | 71.2 steps/s
[Step=82800 Epoch=156.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.611 | L2-Norm(final)=13.660 | 4606.3 samples/s | 72.0 steps/s
[Step=82850 Epoch=156.2] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.605 | L2-Norm(final)=13.661 | 4529.6 samples/s | 70.8 steps/s
[Step=82900 Epoch=156.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.599 | L2-Norm(final)=13.662 | 4531.2 samples/s | 70.8 steps/s
[Step=82950 Epoch=156.4] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.593 | L2-Norm(final)=13.663 | 4557.2 samples/s | 71.2 steps/s
[Step=83000 Epoch=156.5] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.587 | L2-Norm(final)=13.663 | 4580.2 samples/s | 71.6 steps/s
[Step=83050 Epoch=156.6] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.580 | L2-Norm(final)=13.664 | 2123.6 samples/s | 33.2 steps/s
[Step=83100 Epoch=156.6] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.574 | L2-Norm(final)=13.664 | 4638.1 samples/s | 72.5 steps/s
[Step=83150 Epoch=156.7] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.567 | L2-Norm(final)=13.665 | 4522.5 samples/s | 70.7 steps/s
[Step=83200 Epoch=156.8] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.561 | L2-Norm(final)=13.666 | 4467.9 samples/s | 69.8 steps/s
[Step=83250 Epoch=156.9] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.554 | L2-Norm(final)=13.666 | 4491.2 samples/s | 70.2 steps/s
[Step=83300 Epoch=157.0] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.547 | L2-Norm(final)=13.667 | 4601.5 samples/s | 71.9 steps/s
[Step=83350 Epoch=157.1] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.541 | L2-Norm(final)=13.667 | 4467.3 samples/s | 69.8 steps/s
[Step=83400 Epoch=157.2] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.534 | L2-Norm(final)=13.668 | 4544.1 samples/s | 71.0 steps/s
[Step=83450 Epoch=157.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.527 | L2-Norm(final)=13.668 | 4491.4 samples/s | 70.2 steps/s
[Step=83500 Epoch=157.4] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.520 | L2-Norm(final)=13.669 | 4611.7 samples/s | 72.1 steps/s
[Step=83550 Epoch=157.5] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.513 | L2-Norm(final)=13.670 | 5642.5 samples/s | 88.2 steps/s
[Step=83600 Epoch=157.6] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.506 | L2-Norm(final)=13.670 | 1975.3 samples/s | 30.9 steps/s
[Step=83650 Epoch=157.7] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.498 | L2-Norm(final)=13.671 | 4669.6 samples/s | 73.0 steps/s
[Step=83700 Epoch=157.8] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.491 | L2-Norm(final)=13.671 | 4605.4 samples/s | 72.0 steps/s
[Step=83750 Epoch=157.9] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.484 | L2-Norm(final)=13.672 | 4617.7 samples/s | 72.2 steps/s
[Step=83800 Epoch=158.0] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.476 | L2-Norm(final)=13.672 | 4550.3 samples/s | 71.1 steps/s
[Step=83850 Epoch=158.1] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.469 | L2-Norm(final)=13.673 | 4546.7 samples/s | 71.0 steps/s
[Step=83900 Epoch=158.2] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.461 | L2-Norm(final)=13.673 | 4584.6 samples/s | 71.6 steps/s
[Step=83950 Epoch=158.2] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.453 | L2-Norm(final)=13.674 | 4469.4 samples/s | 69.8 steps/s
[Step=84000 Epoch=158.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.445 | L2-Norm(final)=13.674 | 4544.6 samples/s | 71.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05837 | acc=0.9730 | tpr=0.9779 | fpr=0.0374 | 4561.1 samples/s | 17.8 steps/s
Avg test loss: 0.06357, Avg test acc: 0.97183, Avg tpr: 0.97680, Avg fpr: 0.03910, total FA: 305

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.76173 | acc=0.2992 | tpr=0.0106 | fpr=0.0741 | 4634.1 samples/s | 18.1 steps/s
Avg test loss: 4.77185, Avg test acc: 0.29642, Avg tpr: 0.01125, Avg fpr: 0.07640, total FA: 596

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.80550 | acc=0.1513 | tpr=0.3673 | fpr=0.8526 | 4574.7 samples/s | 17.9 steps/s
[Step= 100] | Loss=4.76710 | acc=0.1514 | tpr=0.3348 | fpr=0.8520 | 8595.8 samples/s | 33.6 steps/s
[Step= 150] | Loss=4.76910 | acc=0.1512 | tpr=0.3444 | fpr=0.8524 | 8475.6 samples/s | 33.1 steps/s
[Step= 200] | Loss=4.75691 | acc=0.1511 | tpr=0.3432 | fpr=0.8524 | 8419.1 samples/s | 32.9 steps/s
[Step= 250] | Loss=4.75858 | acc=0.1513 | tpr=0.3459 | fpr=0.8522 | 8659.7 samples/s | 33.8 steps/s
[Step= 300] | Loss=4.75552 | acc=0.1510 | tpr=0.3462 | fpr=0.8525 | 8515.4 samples/s | 33.3 steps/s
[Step= 350] | Loss=4.75397 | acc=0.1504 | tpr=0.3419 | fpr=0.8530 | 8170.6 samples/s | 31.9 steps/s
[Step= 400] | Loss=4.75434 | acc=0.1506 | tpr=0.3419 | fpr=0.8529 | 8552.8 samples/s | 33.4 steps/s
[Step= 450] | Loss=4.75599 | acc=0.1507 | tpr=0.3403 | fpr=0.8528 | 8367.8 samples/s | 32.7 steps/s
[Step= 500] | Loss=4.75931 | acc=0.1510 | tpr=0.3388 | fpr=0.8523 | 8368.5 samples/s | 32.7 steps/s
[Step= 550] | Loss=4.76046 | acc=0.1511 | tpr=0.3406 | fpr=0.8523 | 15823.0 samples/s | 61.8 steps/s
Avg test loss: 4.76118, Avg test acc: 0.15095, Avg tpr: 0.34073, Avg fpr: 0.85250, total FA: 118368

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11567 | acc=0.9828 | tpr=0.9513 | fpr=0.0166 | 4546.3 samples/s | 17.8 steps/s
[Step= 100] | Loss=0.12335 | acc=0.9816 | tpr=0.9531 | fpr=0.0178 | 8750.8 samples/s | 34.2 steps/s
[Step= 150] | Loss=0.12859 | acc=0.9810 | tpr=0.9582 | fpr=0.0186 | 8376.7 samples/s | 32.7 steps/s
[Step= 200] | Loss=0.12956 | acc=0.9811 | tpr=0.9639 | fpr=0.0186 | 8590.3 samples/s | 33.6 steps/s
[Step= 250] | Loss=0.12782 | acc=0.9812 | tpr=0.9590 | fpr=0.0184 | 8706.4 samples/s | 34.0 steps/s
[Step= 300] | Loss=0.12961 | acc=0.9810 | tpr=0.9607 | fpr=0.0186 | 8834.2 samples/s | 34.5 steps/s
[Step= 350] | Loss=0.13172 | acc=0.9806 | tpr=0.9599 | fpr=0.0190 | 8643.3 samples/s | 33.8 steps/s
[Step= 400] | Loss=0.13254 | acc=0.9805 | tpr=0.9590 | fpr=0.0191 | 8442.3 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.13560 | acc=0.9802 | tpr=0.9576 | fpr=0.0194 | 8176.3 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.13516 | acc=0.9802 | tpr=0.9568 | fpr=0.0194 | 8687.5 samples/s | 33.9 steps/s
[Step= 550] | Loss=0.13431 | acc=0.9803 | tpr=0.9562 | fpr=0.0193 | 15297.3 samples/s | 59.8 steps/s
Avg test loss: 0.13414, Avg test acc: 0.98032, Avg tpr: 0.95642, Avg fpr: 0.01924, total FA: 2672

server round 42/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=84001 Epoch=82.0] | Loss=0.00048 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.337 | 4929.9 samples/s | 77.0 steps/s
[Step=84050 Epoch=82.1] | Loss=0.00970 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.340 | 4715.3 samples/s | 73.7 steps/s
[Step=84100 Epoch=82.1] | Loss=0.00953 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.477 | L2-Norm(final)=15.345 | 5476.7 samples/s | 85.6 steps/s
[Step=84150 Epoch=82.2] | Loss=0.00897 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.477 | L2-Norm(final)=15.350 | 5324.0 samples/s | 83.2 steps/s
[Step=84200 Epoch=82.2] | Loss=0.00907 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.355 | 5462.1 samples/s | 85.3 steps/s
[Step=84250 Epoch=82.3] | Loss=0.00938 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.477 | L2-Norm(final)=15.360 | 5558.5 samples/s | 86.9 steps/s
[Step=84300 Epoch=82.3] | Loss=0.00922 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.365 | 5689.1 samples/s | 88.9 steps/s
[Step=84350 Epoch=82.4] | Loss=0.00921 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.370 | 5588.6 samples/s | 87.3 steps/s
[Step=84400 Epoch=82.4] | Loss=0.00919 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.477 | L2-Norm(final)=15.374 | 5558.8 samples/s | 86.9 steps/s
[Step=84450 Epoch=82.5] | Loss=0.00941 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.477 | L2-Norm(final)=15.379 | 5499.4 samples/s | 85.9 steps/s
[Step=84500 Epoch=82.5] | Loss=0.00949 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.383 | 5560.8 samples/s | 86.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=82.5] | Loss=0.01268 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=15.428 | 4287.1 samples/s | 67.0 steps/s
[Step=84550 Epoch=82.5] | Loss=0.00872 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.482 | L2-Norm(final)=15.432 | 4683.0 samples/s | 73.2 steps/s
[Step=84600 Epoch=82.6] | Loss=0.00887 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.488 | L2-Norm(final)=15.436 | 4705.3 samples/s | 73.5 steps/s
[Step=84650 Epoch=82.6] | Loss=0.00906 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.492 | L2-Norm(final)=15.439 | 4726.9 samples/s | 73.9 steps/s
[Step=84700 Epoch=82.7] | Loss=0.00896 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.497 | L2-Norm(final)=15.442 | 4790.0 samples/s | 74.8 steps/s
[Step=84750 Epoch=82.7] | Loss=0.00842 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.501 | L2-Norm(final)=15.445 | 4832.9 samples/s | 75.5 steps/s
[Step=84800 Epoch=82.8] | Loss=0.00853 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.505 | L2-Norm(final)=15.448 | 4762.6 samples/s | 74.4 steps/s
[Step=84850 Epoch=82.8] | Loss=0.00883 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.509 | L2-Norm(final)=15.451 | 4730.9 samples/s | 73.9 steps/s
[Step=84900 Epoch=82.9] | Loss=0.00904 | Reg=0.00090 | acc=0.9844 | L2-Norm=9.512 | L2-Norm(final)=15.454 | 4839.5 samples/s | 75.6 steps/s
[Step=84950 Epoch=82.9] | Loss=0.00898 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.515 | L2-Norm(final)=15.456 | 4921.2 samples/s | 76.9 steps/s
[Step=85000 Epoch=83.0] | Loss=0.00898 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.519 | L2-Norm(final)=15.459 | 4764.4 samples/s | 74.4 steps/s
[Step=85050 Epoch=83.0] | Loss=0.00892 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.522 | L2-Norm(final)=15.462 | 4796.2 samples/s | 74.9 steps/s
[Step=85100 Epoch=83.1] | Loss=0.00887 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.525 | L2-Norm(final)=15.465 | 4829.5 samples/s | 75.5 steps/s
[Step=85150 Epoch=83.1] | Loss=0.00890 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.528 | L2-Norm(final)=15.467 | 4980.4 samples/s | 77.8 steps/s
[Step=85200 Epoch=83.2] | Loss=0.00887 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.531 | L2-Norm(final)=15.470 | 4839.8 samples/s | 75.6 steps/s
[Step=85250 Epoch=83.2] | Loss=0.00890 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.534 | L2-Norm(final)=15.473 | 4936.6 samples/s | 77.1 steps/s
[Step=85300 Epoch=83.3] | Loss=0.00883 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.536 | L2-Norm(final)=15.475 | 4944.0 samples/s | 77.3 steps/s
[Step=85350 Epoch=83.3] | Loss=0.00878 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.539 | L2-Norm(final)=15.478 | 4972.7 samples/s | 77.7 steps/s
[Step=85400 Epoch=83.4] | Loss=0.00881 | Reg=0.00091 | acc=0.9688 | L2-Norm=9.542 | L2-Norm(final)=15.481 | 4751.5 samples/s | 74.2 steps/s
[Step=85450 Epoch=83.4] | Loss=0.00871 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.544 | L2-Norm(final)=15.483 | 4791.5 samples/s | 74.9 steps/s
[Step=85500 Epoch=83.5] | Loss=0.00866 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.547 | L2-Norm(final)=15.486 | 5173.8 samples/s | 80.8 steps/s
[Step=85550 Epoch=83.5] | Loss=0.00865 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.549 | L2-Norm(final)=15.488 | 2095.4 samples/s | 32.7 steps/s
[Step=85600 Epoch=83.6] | Loss=0.00854 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.552 | L2-Norm(final)=15.491 | 4806.8 samples/s | 75.1 steps/s
[Step=85650 Epoch=83.6] | Loss=0.00847 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.554 | L2-Norm(final)=15.493 | 4763.2 samples/s | 74.4 steps/s
[Step=85700 Epoch=83.7] | Loss=0.00842 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.556 | L2-Norm(final)=15.496 | 4769.1 samples/s | 74.5 steps/s
[Step=85750 Epoch=83.7] | Loss=0.00835 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.559 | L2-Norm(final)=15.498 | 4838.8 samples/s | 75.6 steps/s
[Step=85800 Epoch=83.8] | Loss=0.00833 | Reg=0.00091 | acc=0.9844 | L2-Norm=9.561 | L2-Norm(final)=15.501 | 4723.5 samples/s | 73.8 steps/s
[Step=85850 Epoch=83.8] | Loss=0.00830 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.563 | L2-Norm(final)=15.503 | 4757.4 samples/s | 74.3 steps/s
[Step=85900 Epoch=83.9] | Loss=0.00833 | Reg=0.00091 | acc=0.9688 | L2-Norm=9.565 | L2-Norm(final)=15.505 | 4769.7 samples/s | 74.5 steps/s
[Step=85950 Epoch=83.9] | Loss=0.00824 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.567 | L2-Norm(final)=15.507 | 4814.6 samples/s | 75.2 steps/s
[Step=86000 Epoch=84.0] | Loss=0.00822 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.569 | L2-Norm(final)=15.510 | 4724.9 samples/s | 73.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step86000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=84001 Epoch=158.3] | Loss=0.00004 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.477 | L2-Norm(final)=13.691 | 3998.3 samples/s | 62.5 steps/s
[Step=84050 Epoch=158.4] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.474 | L2-Norm(final)=13.694 | 5040.0 samples/s | 78.7 steps/s
[Step=84100 Epoch=158.5] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.699 | 5121.4 samples/s | 80.0 steps/s
[Step=84150 Epoch=158.6] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.703 | 5294.5 samples/s | 82.7 steps/s
[Step=84200 Epoch=158.7] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.708 | 5264.5 samples/s | 82.3 steps/s
[Step=84250 Epoch=158.8] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.712 | 5373.8 samples/s | 84.0 steps/s
[Step=84300 Epoch=158.9] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.716 | 5416.3 samples/s | 84.6 steps/s
[Step=84350 Epoch=159.0] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.721 | 5220.3 samples/s | 81.6 steps/s
[Step=84400 Epoch=159.1] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.725 | 5332.9 samples/s | 83.3 steps/s
[Step=84450 Epoch=159.2] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.730 | 5363.7 samples/s | 83.8 steps/s
[Step=84500 Epoch=159.3] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.734 | 5347.5 samples/s | 83.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=159.3] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.473 | L2-Norm(final)=13.780 | 4331.5 samples/s | 67.7 steps/s
[Step=84550 Epoch=159.4] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.463 | L2-Norm(final)=13.784 | 4170.6 samples/s | 65.2 steps/s
[Step=84600 Epoch=159.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.450 | L2-Norm(final)=13.786 | 4522.1 samples/s | 70.7 steps/s
[Step=84650 Epoch=159.6] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.436 | L2-Norm(final)=13.788 | 4591.7 samples/s | 71.7 steps/s
[Step=84700 Epoch=159.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.422 | L2-Norm(final)=13.789 | 4504.3 samples/s | 70.4 steps/s
[Step=84750 Epoch=159.8] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.408 | L2-Norm(final)=13.790 | 4532.9 samples/s | 70.8 steps/s
[Step=84800 Epoch=159.8] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.394 | L2-Norm(final)=13.791 | 4517.3 samples/s | 70.6 steps/s
[Step=84850 Epoch=159.9] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=13.792 | 4556.7 samples/s | 71.2 steps/s
[Step=84900 Epoch=160.0] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.366 | L2-Norm(final)=13.793 | 4553.4 samples/s | 71.1 steps/s
[Step=84950 Epoch=160.1] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.352 | L2-Norm(final)=13.794 | 4622.8 samples/s | 72.2 steps/s
[Step=85000 Epoch=160.2] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.338 | L2-Norm(final)=13.796 | 4563.7 samples/s | 71.3 steps/s
[Step=85050 Epoch=160.3] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.323 | L2-Norm(final)=13.797 | 2095.2 samples/s | 32.7 steps/s
[Step=85100 Epoch=160.4] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=13.798 | 4576.0 samples/s | 71.5 steps/s
[Step=85150 Epoch=160.5] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.295 | L2-Norm(final)=13.799 | 4457.9 samples/s | 69.7 steps/s
[Step=85200 Epoch=160.6] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.280 | L2-Norm(final)=13.800 | 4465.8 samples/s | 69.8 steps/s
[Step=85250 Epoch=160.7] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.265 | L2-Norm(final)=13.800 | 4498.2 samples/s | 70.3 steps/s
[Step=85300 Epoch=160.8] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.250 | L2-Norm(final)=13.801 | 4521.0 samples/s | 70.6 steps/s
[Step=85350 Epoch=160.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.235 | L2-Norm(final)=13.802 | 4542.6 samples/s | 71.0 steps/s
[Step=85400 Epoch=161.0] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.220 | L2-Norm(final)=13.803 | 4549.8 samples/s | 71.1 steps/s
[Step=85450 Epoch=161.1] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.205 | L2-Norm(final)=13.804 | 4542.4 samples/s | 71.0 steps/s
[Step=85500 Epoch=161.2] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.189 | L2-Norm(final)=13.805 | 4545.2 samples/s | 71.0 steps/s
[Step=85550 Epoch=161.3] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=13.806 | 5644.6 samples/s | 88.2 steps/s
[Step=85600 Epoch=161.4] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.158 | L2-Norm(final)=13.807 | 1993.3 samples/s | 31.1 steps/s
[Step=85650 Epoch=161.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.143 | L2-Norm(final)=13.808 | 4443.7 samples/s | 69.4 steps/s
[Step=85700 Epoch=161.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.127 | L2-Norm(final)=13.809 | 4546.2 samples/s | 71.0 steps/s
[Step=85750 Epoch=161.6] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.111 | L2-Norm(final)=13.810 | 4465.3 samples/s | 69.8 steps/s
[Step=85800 Epoch=161.7] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.095 | L2-Norm(final)=13.811 | 4578.6 samples/s | 71.5 steps/s
[Step=85850 Epoch=161.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.079 | L2-Norm(final)=13.812 | 4608.8 samples/s | 72.0 steps/s
[Step=85900 Epoch=161.9] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.062 | L2-Norm(final)=13.813 | 4440.4 samples/s | 69.4 steps/s
[Step=85950 Epoch=162.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.046 | L2-Norm(final)=13.814 | 4580.0 samples/s | 71.6 steps/s
[Step=86000 Epoch=162.1] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.029 | L2-Norm(final)=13.815 | 4634.6 samples/s | 72.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05523 | acc=0.9741 | tpr=0.9804 | fpr=0.0394 | 4545.2 samples/s | 17.8 steps/s
Avg test loss: 0.06106, Avg test acc: 0.97175, Avg tpr: 0.97843, Avg fpr: 0.04294, total FA: 335

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.80570 | acc=0.3006 | tpr=0.0102 | fpr=0.0686 | 4559.0 samples/s | 17.8 steps/s
Avg test loss: 4.81908, Avg test acc: 0.29854, Avg tpr: 0.01037, Avg fpr: 0.06768, total FA: 528

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.77039 | acc=0.1440 | tpr=0.3717 | fpr=0.8601 | 4591.2 samples/s | 17.9 steps/s
[Step= 100] | Loss=4.73495 | acc=0.1446 | tpr=0.3454 | fpr=0.8591 | 8253.8 samples/s | 32.2 steps/s
[Step= 150] | Loss=4.73728 | acc=0.1431 | tpr=0.3516 | fpr=0.8607 | 8866.6 samples/s | 34.6 steps/s
[Step= 200] | Loss=4.72530 | acc=0.1425 | tpr=0.3519 | fpr=0.8613 | 8187.9 samples/s | 32.0 steps/s
[Step= 250] | Loss=4.72747 | acc=0.1429 | tpr=0.3563 | fpr=0.8610 | 8309.1 samples/s | 32.5 steps/s
[Step= 300] | Loss=4.72476 | acc=0.1425 | tpr=0.3556 | fpr=0.8614 | 8592.0 samples/s | 33.6 steps/s
[Step= 350] | Loss=4.72319 | acc=0.1419 | tpr=0.3513 | fpr=0.8619 | 8929.9 samples/s | 34.9 steps/s
[Step= 400] | Loss=4.72293 | acc=0.1420 | tpr=0.3507 | fpr=0.8618 | 8377.4 samples/s | 32.7 steps/s
[Step= 450] | Loss=4.72405 | acc=0.1421 | tpr=0.3486 | fpr=0.8616 | 8537.3 samples/s | 33.3 steps/s
[Step= 500] | Loss=4.72699 | acc=0.1425 | tpr=0.3480 | fpr=0.8612 | 8178.9 samples/s | 31.9 steps/s
[Step= 550] | Loss=4.72748 | acc=0.1427 | tpr=0.3518 | fpr=0.8611 | 15564.3 samples/s | 60.8 steps/s
Avg test loss: 4.72823, Avg test acc: 0.14252, Avg tpr: 0.35182, Avg fpr: 0.86128, total FA: 119587

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11945 | acc=0.9817 | tpr=0.9558 | fpr=0.0178 | 4570.1 samples/s | 17.9 steps/s
[Step= 100] | Loss=0.12662 | acc=0.9808 | tpr=0.9595 | fpr=0.0188 | 8683.1 samples/s | 33.9 steps/s
[Step= 150] | Loss=0.13218 | acc=0.9801 | tpr=0.9611 | fpr=0.0195 | 8505.2 samples/s | 33.2 steps/s
[Step= 200] | Loss=0.13308 | acc=0.9803 | tpr=0.9650 | fpr=0.0194 | 8406.0 samples/s | 32.8 steps/s
[Step= 250] | Loss=0.13156 | acc=0.9804 | tpr=0.9616 | fpr=0.0192 | 9179.5 samples/s | 35.9 steps/s
[Step= 300] | Loss=0.13352 | acc=0.9802 | tpr=0.9629 | fpr=0.0195 | 7976.0 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.13565 | acc=0.9798 | tpr=0.9624 | fpr=0.0199 | 8689.1 samples/s | 33.9 steps/s
[Step= 400] | Loss=0.13658 | acc=0.9797 | tpr=0.9617 | fpr=0.0200 | 8584.6 samples/s | 33.5 steps/s
[Step= 450] | Loss=0.13948 | acc=0.9794 | tpr=0.9596 | fpr=0.0202 | 8356.2 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.13906 | acc=0.9794 | tpr=0.9577 | fpr=0.0202 | 8334.2 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.13824 | acc=0.9795 | tpr=0.9570 | fpr=0.0201 | 15326.9 samples/s | 59.9 steps/s
Avg test loss: 0.13806, Avg test acc: 0.97952, Avg tpr: 0.95721, Avg fpr: 0.02007, total FA: 2787

server round 43/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=86001 Epoch=84.0] | Loss=0.00339 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=15.578 | 4130.0 samples/s | 64.5 steps/s
[Step=86050 Epoch=84.0] | Loss=0.01443 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=15.585 | 5255.9 samples/s | 82.1 steps/s
[Step=86100 Epoch=84.1] | Loss=0.01460 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=15.594 | 5544.9 samples/s | 86.6 steps/s
[Step=86150 Epoch=84.1] | Loss=0.01483 | Reg=0.00082 | acc=0.9688 | L2-Norm=9.048 | L2-Norm(final)=15.602 | 5464.3 samples/s | 85.4 steps/s
[Step=86200 Epoch=84.2] | Loss=0.01440 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=15.609 | 5520.7 samples/s | 86.3 steps/s
[Step=86250 Epoch=84.2] | Loss=0.01431 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=15.615 | 5567.6 samples/s | 87.0 steps/s
[Step=86300 Epoch=84.3] | Loss=0.01470 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.048 | L2-Norm(final)=15.622 | 5466.3 samples/s | 85.4 steps/s
[Step=86350 Epoch=84.3] | Loss=0.01469 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.048 | L2-Norm(final)=15.628 | 5454.6 samples/s | 85.2 steps/s
[Step=86400 Epoch=84.4] | Loss=0.01454 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=15.634 | 5427.9 samples/s | 84.8 steps/s
[Step=86450 Epoch=84.4] | Loss=0.01459 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.048 | L2-Norm(final)=15.640 | 5556.1 samples/s | 86.8 steps/s
[Step=86500 Epoch=84.5] | Loss=0.01476 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.048 | L2-Norm(final)=15.646 | 5514.8 samples/s | 86.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=84.5] | Loss=0.01473 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.048 | L2-Norm(final)=15.706 | 4127.5 samples/s | 64.5 steps/s
[Step=86550 Epoch=84.5] | Loss=0.01496 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.055 | L2-Norm(final)=15.711 | 4709.3 samples/s | 73.6 steps/s
[Step=86600 Epoch=84.6] | Loss=0.01255 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.063 | L2-Norm(final)=15.715 | 4694.9 samples/s | 73.4 steps/s
[Step=86650 Epoch=84.6] | Loss=0.01196 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.069 | L2-Norm(final)=15.719 | 4797.3 samples/s | 75.0 steps/s
[Step=86700 Epoch=84.6] | Loss=0.01166 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.076 | L2-Norm(final)=15.723 | 4717.5 samples/s | 73.7 steps/s
[Step=86750 Epoch=84.7] | Loss=0.01163 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.082 | L2-Norm(final)=15.727 | 4802.8 samples/s | 75.0 steps/s
[Step=86800 Epoch=84.7] | Loss=0.01133 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.087 | L2-Norm(final)=15.730 | 4799.6 samples/s | 75.0 steps/s
[Step=86850 Epoch=84.8] | Loss=0.01116 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.092 | L2-Norm(final)=15.734 | 4808.5 samples/s | 75.1 steps/s
[Step=86900 Epoch=84.8] | Loss=0.01113 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.096 | L2-Norm(final)=15.737 | 4802.4 samples/s | 75.0 steps/s
[Step=86950 Epoch=84.9] | Loss=0.01108 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.101 | L2-Norm(final)=15.740 | 4838.0 samples/s | 75.6 steps/s
[Step=87000 Epoch=84.9] | Loss=0.01118 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.105 | L2-Norm(final)=15.743 | 4722.8 samples/s | 73.8 steps/s
[Step=87050 Epoch=85.0] | Loss=0.01096 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.109 | L2-Norm(final)=15.747 | 4870.3 samples/s | 76.1 steps/s
[Step=87100 Epoch=85.0] | Loss=0.01086 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.113 | L2-Norm(final)=15.750 | 4750.1 samples/s | 74.2 steps/s
[Step=87150 Epoch=85.1] | Loss=0.01083 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.118 | L2-Norm(final)=15.753 | 4837.9 samples/s | 75.6 steps/s
[Step=87200 Epoch=85.1] | Loss=0.01094 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.121 | L2-Norm(final)=15.756 | 4801.8 samples/s | 75.0 steps/s
[Step=87250 Epoch=85.2] | Loss=0.01096 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.125 | L2-Norm(final)=15.759 | 4820.2 samples/s | 75.3 steps/s
[Step=87300 Epoch=85.2] | Loss=0.01089 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.129 | L2-Norm(final)=15.762 | 4785.1 samples/s | 74.8 steps/s
[Step=87350 Epoch=85.3] | Loss=0.01083 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.132 | L2-Norm(final)=15.765 | 4802.6 samples/s | 75.0 steps/s
[Step=87400 Epoch=85.3] | Loss=0.01073 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.136 | L2-Norm(final)=15.768 | 4801.1 samples/s | 75.0 steps/s
[Step=87450 Epoch=85.4] | Loss=0.01060 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.139 | L2-Norm(final)=15.771 | 4771.1 samples/s | 74.5 steps/s
[Step=87500 Epoch=85.4] | Loss=0.01046 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.143 | L2-Norm(final)=15.774 | 5297.8 samples/s | 82.8 steps/s
[Step=87550 Epoch=85.5] | Loss=0.01038 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.146 | L2-Norm(final)=15.777 | 2185.1 samples/s | 34.1 steps/s
[Step=87600 Epoch=85.5] | Loss=0.01021 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.149 | L2-Norm(final)=15.780 | 4865.6 samples/s | 76.0 steps/s
[Step=87650 Epoch=85.6] | Loss=0.01013 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.152 | L2-Norm(final)=15.783 | 4720.3 samples/s | 73.8 steps/s
[Step=87700 Epoch=85.6] | Loss=0.01010 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.155 | L2-Norm(final)=15.786 | 4742.4 samples/s | 74.1 steps/s
[Step=87750 Epoch=85.7] | Loss=0.01004 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.158 | L2-Norm(final)=15.789 | 4841.5 samples/s | 75.6 steps/s
[Step=87800 Epoch=85.7] | Loss=0.00992 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.161 | L2-Norm(final)=15.791 | 4757.0 samples/s | 74.3 steps/s
[Step=87850 Epoch=85.8] | Loss=0.00974 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.164 | L2-Norm(final)=15.794 | 4805.8 samples/s | 75.1 steps/s
[Step=87900 Epoch=85.8] | Loss=0.00974 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.167 | L2-Norm(final)=15.797 | 4856.7 samples/s | 75.9 steps/s
[Step=87950 Epoch=85.9] | Loss=0.00967 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.170 | L2-Norm(final)=15.800 | 4651.5 samples/s | 72.7 steps/s
[Step=88000 Epoch=85.9] | Loss=0.00962 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.172 | L2-Norm(final)=15.802 | 4827.7 samples/s | 75.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step88000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=86001 Epoch=162.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=13.849 | 4002.7 samples/s | 62.5 steps/s
[Step=86050 Epoch=162.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=13.854 | 5039.7 samples/s | 78.7 steps/s
[Step=86100 Epoch=162.3] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.863 | 5222.1 samples/s | 81.6 steps/s
[Step=86150 Epoch=162.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.872 | 5168.6 samples/s | 80.8 steps/s
[Step=86200 Epoch=162.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.879 | 5181.0 samples/s | 81.0 steps/s
[Step=86250 Epoch=162.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.885 | 5201.8 samples/s | 81.3 steps/s
[Step=86300 Epoch=162.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.892 | 5287.2 samples/s | 82.6 steps/s
[Step=86350 Epoch=162.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.899 | 5157.8 samples/s | 80.6 steps/s
[Step=86400 Epoch=162.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.905 | 5235.5 samples/s | 81.8 steps/s
[Step=86450 Epoch=163.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.912 | 5146.2 samples/s | 80.4 steps/s
[Step=86500 Epoch=163.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.918 | 5238.1 samples/s | 81.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=163.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=13.982 | 3881.9 samples/s | 60.7 steps/s
[Step=86550 Epoch=163.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.019 | L2-Norm(final)=13.987 | 4579.2 samples/s | 71.5 steps/s
[Step=86600 Epoch=163.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.992 | L2-Norm(final)=13.990 | 4528.3 samples/s | 70.8 steps/s
[Step=86650 Epoch=163.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.964 | L2-Norm(final)=13.992 | 4519.9 samples/s | 70.6 steps/s
[Step=86700 Epoch=163.4] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.936 | L2-Norm(final)=13.993 | 4515.9 samples/s | 70.6 steps/s
[Step=86750 Epoch=163.5] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.908 | L2-Norm(final)=13.995 | 4517.4 samples/s | 70.6 steps/s
[Step=86800 Epoch=163.6] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.880 | L2-Norm(final)=13.996 | 4667.6 samples/s | 72.9 steps/s
[Step=86850 Epoch=163.7] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.851 | L2-Norm(final)=13.997 | 4615.6 samples/s | 72.1 steps/s
[Step=86900 Epoch=163.8] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.823 | L2-Norm(final)=13.998 | 4676.1 samples/s | 73.1 steps/s
[Step=86950 Epoch=163.9] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.795 | L2-Norm(final)=14.000 | 4593.0 samples/s | 71.8 steps/s
[Step=87000 Epoch=164.0] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.768 | L2-Norm(final)=14.001 | 4619.0 samples/s | 72.2 steps/s
[Step=87050 Epoch=164.1] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.740 | L2-Norm(final)=14.003 | 2095.6 samples/s | 32.7 steps/s
[Step=87100 Epoch=164.2] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=14.004 | 4631.8 samples/s | 72.4 steps/s
[Step=87150 Epoch=164.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.684 | L2-Norm(final)=14.005 | 4626.1 samples/s | 72.3 steps/s
[Step=87200 Epoch=164.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.656 | L2-Norm(final)=14.007 | 4574.9 samples/s | 71.5 steps/s
[Step=87250 Epoch=164.5] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.628 | L2-Norm(final)=14.008 | 4569.2 samples/s | 71.4 steps/s
[Step=87300 Epoch=164.6] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.600 | L2-Norm(final)=14.010 | 4581.1 samples/s | 71.6 steps/s
[Step=87350 Epoch=164.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.572 | L2-Norm(final)=14.011 | 4505.2 samples/s | 70.4 steps/s
[Step=87400 Epoch=164.8] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.545 | L2-Norm(final)=14.013 | 4525.7 samples/s | 70.7 steps/s
[Step=87450 Epoch=164.8] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.517 | L2-Norm(final)=14.014 | 4477.1 samples/s | 70.0 steps/s
[Step=87500 Epoch=164.9] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.490 | L2-Norm(final)=14.016 | 4513.6 samples/s | 70.5 steps/s
[Step=87550 Epoch=165.0] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.463 | L2-Norm(final)=14.018 | 5650.8 samples/s | 88.3 steps/s
[Step=87600 Epoch=165.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.437 | L2-Norm(final)=14.020 | 2046.1 samples/s | 32.0 steps/s
[Step=87650 Epoch=165.2] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.412 | L2-Norm(final)=14.022 | 4549.3 samples/s | 71.1 steps/s
[Step=87700 Epoch=165.3] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.387 | L2-Norm(final)=14.023 | 4676.2 samples/s | 73.1 steps/s
[Step=87750 Epoch=165.4] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.362 | L2-Norm(final)=14.025 | 4647.5 samples/s | 72.6 steps/s
[Step=87800 Epoch=165.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.338 | L2-Norm(final)=14.027 | 4597.0 samples/s | 71.8 steps/s
[Step=87850 Epoch=165.6] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.313 | L2-Norm(final)=14.029 | 4487.4 samples/s | 70.1 steps/s
[Step=87900 Epoch=165.7] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.290 | L2-Norm(final)=14.031 | 4562.0 samples/s | 71.3 steps/s
[Step=87950 Epoch=165.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.266 | L2-Norm(final)=14.033 | 4491.1 samples/s | 70.2 steps/s
[Step=88000 Epoch=165.9] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.243 | L2-Norm(final)=14.035 | 4583.6 samples/s | 71.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05479 | acc=0.9722 | tpr=0.9751 | fpr=0.0342 | 4447.4 samples/s | 17.4 steps/s
Avg test loss: 0.05992, Avg test acc: 0.97019, Avg tpr: 0.97325, Avg fpr: 0.03653, total FA: 285

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.10188 | acc=0.3010 | tpr=0.0103 | fpr=0.0676 | 4534.5 samples/s | 17.7 steps/s
Avg test loss: 5.12255, Avg test acc: 0.29902, Avg tpr: 0.01037, Avg fpr: 0.06615, total FA: 516

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.28439 | acc=0.1572 | tpr=0.3186 | fpr=0.8457 | 4512.5 samples/s | 17.6 steps/s
[Step= 100] | Loss=4.25129 | acc=0.1581 | tpr=0.2985 | fpr=0.8445 | 8909.8 samples/s | 34.8 steps/s
[Step= 150] | Loss=4.25285 | acc=0.1572 | tpr=0.3069 | fpr=0.8455 | 8392.9 samples/s | 32.8 steps/s
[Step= 200] | Loss=4.24226 | acc=0.1570 | tpr=0.3038 | fpr=0.8456 | 8904.9 samples/s | 34.8 steps/s
[Step= 250] | Loss=4.24368 | acc=0.1577 | tpr=0.3039 | fpr=0.8450 | 8356.8 samples/s | 32.6 steps/s
[Step= 300] | Loss=4.24099 | acc=0.1570 | tpr=0.2996 | fpr=0.8456 | 8296.4 samples/s | 32.4 steps/s
[Step= 350] | Loss=4.23909 | acc=0.1566 | tpr=0.2943 | fpr=0.8459 | 8477.9 samples/s | 33.1 steps/s
[Step= 400] | Loss=4.23868 | acc=0.1567 | tpr=0.2970 | fpr=0.8459 | 8620.7 samples/s | 33.7 steps/s
[Step= 450] | Loss=4.23998 | acc=0.1567 | tpr=0.2980 | fpr=0.8459 | 8449.0 samples/s | 33.0 steps/s
[Step= 500] | Loss=4.24255 | acc=0.1571 | tpr=0.2982 | fpr=0.8454 | 8314.1 samples/s | 32.5 steps/s
[Step= 550] | Loss=4.24322 | acc=0.1574 | tpr=0.2996 | fpr=0.8452 | 15393.7 samples/s | 60.1 steps/s
Avg test loss: 4.24401, Avg test acc: 0.15720, Avg tpr: 0.29992, Avg fpr: 0.84539, total FA: 117381

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11645 | acc=0.9817 | tpr=0.9602 | fpr=0.0179 | 4532.1 samples/s | 17.7 steps/s
[Step= 100] | Loss=0.12324 | acc=0.9809 | tpr=0.9616 | fpr=0.0187 | 8517.5 samples/s | 33.3 steps/s
[Step= 150] | Loss=0.12866 | acc=0.9801 | tpr=0.9625 | fpr=0.0196 | 8245.7 samples/s | 32.2 steps/s
[Step= 200] | Loss=0.12938 | acc=0.9802 | tpr=0.9661 | fpr=0.0195 | 8512.0 samples/s | 33.3 steps/s
[Step= 250] | Loss=0.12814 | acc=0.9802 | tpr=0.9651 | fpr=0.0195 | 8225.8 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.13024 | acc=0.9800 | tpr=0.9651 | fpr=0.0198 | 8266.5 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.13209 | acc=0.9795 | tpr=0.9643 | fpr=0.0202 | 8165.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.13290 | acc=0.9795 | tpr=0.9623 | fpr=0.0202 | 8296.1 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.13560 | acc=0.9791 | tpr=0.9596 | fpr=0.0205 | 8830.0 samples/s | 34.5 steps/s
[Step= 500] | Loss=0.13494 | acc=0.9792 | tpr=0.9586 | fpr=0.0204 | 8041.6 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.13420 | acc=0.9793 | tpr=0.9578 | fpr=0.0203 | 16083.9 samples/s | 62.8 steps/s
Avg test loss: 0.13403, Avg test acc: 0.97933, Avg tpr: 0.95800, Avg fpr: 0.02028, total FA: 2816

server round 44/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=88001 Epoch=85.9] | Loss=0.02130 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.352 | L2-Norm(final)=15.880 | 4224.5 samples/s | 66.0 steps/s
[Step=88050 Epoch=86.0] | Loss=0.02417 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.352 | L2-Norm(final)=15.888 | 5351.1 samples/s | 83.6 steps/s
[Step=88100 Epoch=86.0] | Loss=0.02449 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.352 | L2-Norm(final)=15.899 | 5474.9 samples/s | 85.5 steps/s
[Step=88150 Epoch=86.1] | Loss=0.02448 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.352 | L2-Norm(final)=15.909 | 5337.7 samples/s | 83.4 steps/s
[Step=88200 Epoch=86.1] | Loss=0.02487 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.352 | L2-Norm(final)=15.920 | 5542.4 samples/s | 86.6 steps/s
[Step=88250 Epoch=86.2] | Loss=0.02499 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.352 | L2-Norm(final)=15.930 | 5442.8 samples/s | 85.0 steps/s
[Step=88300 Epoch=86.2] | Loss=0.02504 | Reg=0.00070 | acc=0.9531 | L2-Norm=8.352 | L2-Norm(final)=15.940 | 5431.7 samples/s | 84.9 steps/s
[Step=88350 Epoch=86.3] | Loss=0.02491 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.352 | L2-Norm(final)=15.949 | 5537.3 samples/s | 86.5 steps/s
[Step=88400 Epoch=86.3] | Loss=0.02471 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.352 | L2-Norm(final)=15.958 | 5547.5 samples/s | 86.7 steps/s
[Step=88450 Epoch=86.4] | Loss=0.02458 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.352 | L2-Norm(final)=15.967 | 5457.2 samples/s | 85.3 steps/s
[Step=88500 Epoch=86.4] | Loss=0.02481 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.352 | L2-Norm(final)=15.976 | 5537.4 samples/s | 86.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=86.4] | Loss=0.01797 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.352 | L2-Norm(final)=16.063 | 4407.9 samples/s | 68.9 steps/s
[Step=88550 Epoch=86.5] | Loss=0.02379 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.363 | L2-Norm(final)=16.070 | 4342.1 samples/s | 67.8 steps/s
[Step=88600 Epoch=86.5] | Loss=0.02238 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.375 | L2-Norm(final)=16.075 | 4548.6 samples/s | 71.1 steps/s
[Step=88650 Epoch=86.6] | Loss=0.02142 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.385 | L2-Norm(final)=16.080 | 4655.0 samples/s | 72.7 steps/s
[Step=88700 Epoch=86.6] | Loss=0.02009 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.395 | L2-Norm(final)=16.084 | 4689.2 samples/s | 73.3 steps/s
[Step=88750 Epoch=86.7] | Loss=0.01889 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.403 | L2-Norm(final)=16.089 | 4713.0 samples/s | 73.6 steps/s
[Step=88800 Epoch=86.7] | Loss=0.01858 | Reg=0.00071 | acc=0.9688 | L2-Norm=8.411 | L2-Norm(final)=16.094 | 4793.4 samples/s | 74.9 steps/s
[Step=88850 Epoch=86.7] | Loss=0.01802 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.418 | L2-Norm(final)=16.098 | 4693.5 samples/s | 73.3 steps/s
[Step=88900 Epoch=86.8] | Loss=0.01763 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.425 | L2-Norm(final)=16.102 | 4740.7 samples/s | 74.1 steps/s
[Step=88950 Epoch=86.8] | Loss=0.01738 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.431 | L2-Norm(final)=16.106 | 4745.6 samples/s | 74.1 steps/s
[Step=89000 Epoch=86.9] | Loss=0.01698 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.437 | L2-Norm(final)=16.110 | 4726.4 samples/s | 73.8 steps/s
[Step=89050 Epoch=86.9] | Loss=0.01674 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.443 | L2-Norm(final)=16.114 | 4787.7 samples/s | 74.8 steps/s
[Step=89100 Epoch=87.0] | Loss=0.01658 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.449 | L2-Norm(final)=16.118 | 4669.2 samples/s | 73.0 steps/s
[Step=89150 Epoch=87.0] | Loss=0.01634 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.455 | L2-Norm(final)=16.122 | 4689.3 samples/s | 73.3 steps/s
[Step=89200 Epoch=87.1] | Loss=0.01632 | Reg=0.00072 | acc=0.9688 | L2-Norm=8.460 | L2-Norm(final)=16.126 | 4730.6 samples/s | 73.9 steps/s
[Step=89250 Epoch=87.1] | Loss=0.01603 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.465 | L2-Norm(final)=16.129 | 4694.9 samples/s | 73.4 steps/s
[Step=89300 Epoch=87.2] | Loss=0.01581 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.470 | L2-Norm(final)=16.133 | 4709.1 samples/s | 73.6 steps/s
[Step=89350 Epoch=87.2] | Loss=0.01563 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.475 | L2-Norm(final)=16.137 | 4716.2 samples/s | 73.7 steps/s
[Step=89400 Epoch=87.3] | Loss=0.01542 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.480 | L2-Norm(final)=16.140 | 4735.1 samples/s | 74.0 steps/s
[Step=89450 Epoch=87.3] | Loss=0.01515 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.485 | L2-Norm(final)=16.143 | 4686.7 samples/s | 73.2 steps/s
[Step=89500 Epoch=87.4] | Loss=0.01493 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.489 | L2-Norm(final)=16.147 | 5046.6 samples/s | 78.9 steps/s
[Step=89550 Epoch=87.4] | Loss=0.01478 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.494 | L2-Norm(final)=16.150 | 2070.2 samples/s | 32.3 steps/s
[Step=89600 Epoch=87.5] | Loss=0.01453 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.498 | L2-Norm(final)=16.154 | 4658.4 samples/s | 72.8 steps/s
[Step=89650 Epoch=87.5] | Loss=0.01438 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.502 | L2-Norm(final)=16.157 | 4668.2 samples/s | 72.9 steps/s
[Step=89700 Epoch=87.6] | Loss=0.01421 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.507 | L2-Norm(final)=16.161 | 4715.8 samples/s | 73.7 steps/s
[Step=89750 Epoch=87.6] | Loss=0.01404 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.511 | L2-Norm(final)=16.164 | 4613.7 samples/s | 72.1 steps/s
[Step=89800 Epoch=87.7] | Loss=0.01383 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.515 | L2-Norm(final)=16.167 | 4615.5 samples/s | 72.1 steps/s
[Step=89850 Epoch=87.7] | Loss=0.01358 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.519 | L2-Norm(final)=16.170 | 4661.2 samples/s | 72.8 steps/s
[Step=89900 Epoch=87.8] | Loss=0.01341 | Reg=0.00073 | acc=0.9688 | L2-Norm=8.523 | L2-Norm(final)=16.174 | 4810.8 samples/s | 75.2 steps/s
[Step=89950 Epoch=87.8] | Loss=0.01327 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.526 | L2-Norm(final)=16.177 | 4684.3 samples/s | 73.2 steps/s
[Step=90000 Epoch=87.9] | Loss=0.01317 | Reg=0.00073 | acc=0.9844 | L2-Norm=8.530 | L2-Norm(final)=16.180 | 4758.6 samples/s | 74.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step90000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=88001 Epoch=165.9] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.352 | L2-Norm(final)=14.095 | 4119.1 samples/s | 64.4 steps/s
[Step=88050 Epoch=166.0] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.346 | L2-Norm(final)=14.104 | 4739.8 samples/s | 74.1 steps/s
[Step=88100 Epoch=166.1] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.114 | 5093.3 samples/s | 79.6 steps/s
[Step=88150 Epoch=166.2] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.122 | 4988.9 samples/s | 78.0 steps/s
[Step=88200 Epoch=166.3] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.130 | 5083.4 samples/s | 79.4 steps/s
[Step=88250 Epoch=166.4] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.138 | 5062.0 samples/s | 79.1 steps/s
[Step=88300 Epoch=166.4] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.146 | 5038.4 samples/s | 78.7 steps/s
[Step=88350 Epoch=166.5] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.153 | 5054.3 samples/s | 79.0 steps/s
[Step=88400 Epoch=166.6] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.159 | 5025.7 samples/s | 78.5 steps/s
[Step=88450 Epoch=166.7] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.165 | 5249.9 samples/s | 82.0 steps/s
[Step=88500 Epoch=166.8] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.171 | 4898.3 samples/s | 76.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=166.8] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.344 | L2-Norm(final)=14.232 | 3812.2 samples/s | 59.6 steps/s
[Step=88550 Epoch=166.9] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.326 | L2-Norm(final)=14.237 | 4326.8 samples/s | 67.6 steps/s
[Step=88600 Epoch=167.0] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=14.238 | 4280.8 samples/s | 66.9 steps/s
[Step=88650 Epoch=167.1] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.268 | L2-Norm(final)=14.240 | 4391.0 samples/s | 68.6 steps/s
[Step=88700 Epoch=167.2] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.239 | L2-Norm(final)=14.241 | 4439.9 samples/s | 69.4 steps/s
[Step=88750 Epoch=167.3] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.211 | L2-Norm(final)=14.242 | 4540.2 samples/s | 70.9 steps/s
[Step=88800 Epoch=167.4] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.182 | L2-Norm(final)=14.244 | 4425.4 samples/s | 69.1 steps/s
[Step=88850 Epoch=167.5] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.154 | L2-Norm(final)=14.245 | 4318.8 samples/s | 67.5 steps/s
[Step=88900 Epoch=167.6] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=14.246 | 4334.5 samples/s | 67.7 steps/s
[Step=88950 Epoch=167.7] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=14.247 | 4424.5 samples/s | 69.1 steps/s
[Step=89000 Epoch=167.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=14.249 | 4487.9 samples/s | 70.1 steps/s
[Step=89050 Epoch=167.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.042 | L2-Norm(final)=14.250 | 2038.9 samples/s | 31.9 steps/s
[Step=89100 Epoch=168.0] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.015 | L2-Norm(final)=14.252 | 4440.5 samples/s | 69.4 steps/s
[Step=89150 Epoch=168.0] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.988 | L2-Norm(final)=14.253 | 4331.5 samples/s | 67.7 steps/s
[Step=89200 Epoch=168.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.961 | L2-Norm(final)=14.255 | 4238.0 samples/s | 66.2 steps/s
[Step=89250 Epoch=168.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.935 | L2-Norm(final)=14.256 | 4318.6 samples/s | 67.5 steps/s
[Step=89300 Epoch=168.3] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.908 | L2-Norm(final)=14.258 | 4273.2 samples/s | 66.8 steps/s
[Step=89350 Epoch=168.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.882 | L2-Norm(final)=14.259 | 4418.4 samples/s | 69.0 steps/s
[Step=89400 Epoch=168.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.856 | L2-Norm(final)=14.261 | 4369.2 samples/s | 68.3 steps/s
[Step=89450 Epoch=168.6] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.832 | L2-Norm(final)=14.263 | 4422.7 samples/s | 69.1 steps/s
[Step=89500 Epoch=168.7] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.809 | L2-Norm(final)=14.266 | 4283.3 samples/s | 66.9 steps/s
[Step=89550 Epoch=168.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.786 | L2-Norm(final)=14.268 | 5442.9 samples/s | 85.0 steps/s
[Step=89600 Epoch=168.9] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.270 | 1944.9 samples/s | 30.4 steps/s
[Step=89650 Epoch=169.0] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.742 | L2-Norm(final)=14.271 | 4370.7 samples/s | 68.3 steps/s
[Step=89700 Epoch=169.1] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.721 | L2-Norm(final)=14.273 | 4600.1 samples/s | 71.9 steps/s
[Step=89750 Epoch=169.2] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.700 | L2-Norm(final)=14.275 | 4504.2 samples/s | 70.4 steps/s
[Step=89800 Epoch=169.3] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.679 | L2-Norm(final)=14.277 | 4500.8 samples/s | 70.3 steps/s
[Step=89850 Epoch=169.4] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.659 | L2-Norm(final)=14.279 | 4584.2 samples/s | 71.6 steps/s
[Step=89900 Epoch=169.5] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.640 | L2-Norm(final)=14.281 | 4642.9 samples/s | 72.5 steps/s
[Step=89950 Epoch=169.6] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=14.283 | 4581.6 samples/s | 71.6 steps/s
[Step=90000 Epoch=169.7] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.601 | L2-Norm(final)=14.285 | 4504.0 samples/s | 70.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05051 | acc=0.9713 | tpr=0.9795 | fpr=0.0463 | 4587.9 samples/s | 17.9 steps/s
Avg test loss: 0.05497, Avg test acc: 0.97019, Avg tpr: 0.97925, Avg fpr: 0.04974, total FA: 388

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.11309 | acc=0.3042 | tpr=0.0091 | fpr=0.0550 | 4605.3 samples/s | 18.0 steps/s
Avg test loss: 5.13515, Avg test acc: 0.30127, Avg tpr: 0.00828, Avg fpr: 0.05435, total FA: 424

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.15529 | acc=0.1437 | tpr=0.3673 | fpr=0.8603 | 4609.3 samples/s | 18.0 steps/s
[Step= 100] | Loss=4.13060 | acc=0.1441 | tpr=0.3412 | fpr=0.8596 | 8856.3 samples/s | 34.6 steps/s
[Step= 150] | Loss=4.13106 | acc=0.1435 | tpr=0.3458 | fpr=0.8602 | 8329.8 samples/s | 32.5 steps/s
[Step= 200] | Loss=4.12346 | acc=0.1431 | tpr=0.3421 | fpr=0.8605 | 8412.1 samples/s | 32.9 steps/s
[Step= 250] | Loss=4.12464 | acc=0.1435 | tpr=0.3424 | fpr=0.8602 | 8280.3 samples/s | 32.3 steps/s
[Step= 300] | Loss=4.12275 | acc=0.1430 | tpr=0.3404 | fpr=0.8606 | 8793.9 samples/s | 34.4 steps/s
[Step= 350] | Loss=4.12158 | acc=0.1426 | tpr=0.3350 | fpr=0.8609 | 8368.5 samples/s | 32.7 steps/s
[Step= 400] | Loss=4.12159 | acc=0.1426 | tpr=0.3375 | fpr=0.8609 | 8319.0 samples/s | 32.5 steps/s
[Step= 450] | Loss=4.12245 | acc=0.1428 | tpr=0.3374 | fpr=0.8608 | 8635.8 samples/s | 33.7 steps/s
[Step= 500] | Loss=4.12466 | acc=0.1432 | tpr=0.3348 | fpr=0.8603 | 8298.8 samples/s | 32.4 steps/s
[Step= 550] | Loss=4.12533 | acc=0.1432 | tpr=0.3359 | fpr=0.8603 | 15452.1 samples/s | 60.4 steps/s
Avg test loss: 4.12605, Avg test acc: 0.14306, Avg tpr: 0.33637, Avg fpr: 0.86046, total FA: 119473

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10961 | acc=0.9826 | tpr=0.9602 | fpr=0.0170 | 4510.0 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.11556 | acc=0.9814 | tpr=0.9638 | fpr=0.0182 | 8395.8 samples/s | 32.8 steps/s
[Step= 150] | Loss=0.12070 | acc=0.9805 | tpr=0.9640 | fpr=0.0191 | 8780.0 samples/s | 34.3 steps/s
[Step= 200] | Loss=0.12123 | acc=0.9807 | tpr=0.9672 | fpr=0.0191 | 8351.7 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.12007 | acc=0.9808 | tpr=0.9659 | fpr=0.0189 | 8422.9 samples/s | 32.9 steps/s
[Step= 300] | Loss=0.12206 | acc=0.9806 | tpr=0.9665 | fpr=0.0191 | 8753.7 samples/s | 34.2 steps/s
[Step= 350] | Loss=0.12369 | acc=0.9802 | tpr=0.9656 | fpr=0.0195 | 8404.7 samples/s | 32.8 steps/s
[Step= 400] | Loss=0.12458 | acc=0.9801 | tpr=0.9633 | fpr=0.0196 | 8336.0 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.12715 | acc=0.9798 | tpr=0.9615 | fpr=0.0199 | 8370.2 samples/s | 32.7 steps/s
[Step= 500] | Loss=0.12649 | acc=0.9798 | tpr=0.9608 | fpr=0.0198 | 8662.8 samples/s | 33.8 steps/s
[Step= 550] | Loss=0.12585 | acc=0.9799 | tpr=0.9594 | fpr=0.0198 | 14861.5 samples/s | 58.1 steps/s
Avg test loss: 0.12567, Avg test acc: 0.97990, Avg tpr: 0.95959, Avg fpr: 0.01973, total FA: 2740

server round 45/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=90001 Epoch=87.9] | Loss=0.03330 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.770 | L2-Norm(final)=16.272 | 4479.6 samples/s | 70.0 steps/s
[Step=90050 Epoch=87.9] | Loss=0.03240 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.771 | L2-Norm(final)=16.281 | 5221.2 samples/s | 81.6 steps/s
[Step=90100 Epoch=88.0] | Loss=0.03222 | Reg=0.00060 | acc=0.9531 | L2-Norm=7.771 | L2-Norm(final)=16.292 | 5469.3 samples/s | 85.5 steps/s
[Step=90150 Epoch=88.0] | Loss=0.03229 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=16.304 | 5447.1 samples/s | 85.1 steps/s
[Step=90200 Epoch=88.1] | Loss=0.03150 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=16.315 | 5583.5 samples/s | 87.2 steps/s
[Step=90250 Epoch=88.1] | Loss=0.03143 | Reg=0.00060 | acc=0.9688 | L2-Norm=7.771 | L2-Norm(final)=16.326 | 5554.8 samples/s | 86.8 steps/s
[Step=90300 Epoch=88.2] | Loss=0.03195 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.771 | L2-Norm(final)=16.337 | 5683.1 samples/s | 88.8 steps/s
[Step=90350 Epoch=88.2] | Loss=0.03179 | Reg=0.00060 | acc=0.9688 | L2-Norm=7.771 | L2-Norm(final)=16.347 | 5378.4 samples/s | 84.0 steps/s
[Step=90400 Epoch=88.3] | Loss=0.03146 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=16.358 | 5727.8 samples/s | 89.5 steps/s
[Step=90450 Epoch=88.3] | Loss=0.03116 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.771 | L2-Norm(final)=16.368 | 5599.0 samples/s | 87.5 steps/s
[Step=90500 Epoch=88.4] | Loss=0.03131 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.771 | L2-Norm(final)=16.378 | 5582.7 samples/s | 87.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=88.4] | Loss=0.01494 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.771 | L2-Norm(final)=16.476 | 4207.7 samples/s | 65.7 steps/s
[Step=90550 Epoch=88.4] | Loss=0.03405 | Reg=0.00061 | acc=0.9531 | L2-Norm=7.783 | L2-Norm(final)=16.484 | 4792.9 samples/s | 74.9 steps/s
[Step=90600 Epoch=88.5] | Loss=0.03030 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.797 | L2-Norm(final)=16.490 | 4785.5 samples/s | 74.8 steps/s
[Step=90650 Epoch=88.5] | Loss=0.02722 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.810 | L2-Norm(final)=16.496 | 4809.7 samples/s | 75.2 steps/s
[Step=90700 Epoch=88.6] | Loss=0.02548 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.821 | L2-Norm(final)=16.501 | 4778.2 samples/s | 74.7 steps/s
[Step=90750 Epoch=88.6] | Loss=0.02404 | Reg=0.00061 | acc=0.9688 | L2-Norm=7.831 | L2-Norm(final)=16.507 | 4923.3 samples/s | 76.9 steps/s
[Step=90800 Epoch=88.7] | Loss=0.02315 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.841 | L2-Norm(final)=16.512 | 4957.1 samples/s | 77.5 steps/s
[Step=90850 Epoch=88.7] | Loss=0.02242 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.850 | L2-Norm(final)=16.517 | 4815.1 samples/s | 75.2 steps/s
[Step=90900 Epoch=88.7] | Loss=0.02214 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.859 | L2-Norm(final)=16.522 | 4814.9 samples/s | 75.2 steps/s
[Step=90950 Epoch=88.8] | Loss=0.02155 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.867 | L2-Norm(final)=16.527 | 4831.4 samples/s | 75.5 steps/s
[Step=91000 Epoch=88.8] | Loss=0.02115 | Reg=0.00062 | acc=0.9688 | L2-Norm=7.875 | L2-Norm(final)=16.531 | 4747.3 samples/s | 74.2 steps/s
[Step=91050 Epoch=88.9] | Loss=0.02063 | Reg=0.00062 | acc=0.9844 | L2-Norm=7.882 | L2-Norm(final)=16.536 | 4684.6 samples/s | 73.2 steps/s
[Step=91100 Epoch=88.9] | Loss=0.02029 | Reg=0.00062 | acc=0.9844 | L2-Norm=7.890 | L2-Norm(final)=16.540 | 4909.9 samples/s | 76.7 steps/s
[Step=91150 Epoch=89.0] | Loss=0.02023 | Reg=0.00062 | acc=0.9531 | L2-Norm=7.897 | L2-Norm(final)=16.544 | 4937.7 samples/s | 77.2 steps/s
[Step=91200 Epoch=89.0] | Loss=0.01988 | Reg=0.00062 | acc=0.9844 | L2-Norm=7.903 | L2-Norm(final)=16.548 | 4922.8 samples/s | 76.9 steps/s
[Step=91250 Epoch=89.1] | Loss=0.01950 | Reg=0.00063 | acc=0.9688 | L2-Norm=7.910 | L2-Norm(final)=16.552 | 4924.2 samples/s | 76.9 steps/s
[Step=91300 Epoch=89.1] | Loss=0.01921 | Reg=0.00063 | acc=0.9375 | L2-Norm=7.917 | L2-Norm(final)=16.557 | 4886.6 samples/s | 76.4 steps/s
[Step=91350 Epoch=89.2] | Loss=0.01896 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.923 | L2-Norm(final)=16.561 | 4927.7 samples/s | 77.0 steps/s
[Step=91400 Epoch=89.2] | Loss=0.01861 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.929 | L2-Norm(final)=16.565 | 4762.5 samples/s | 74.4 steps/s
[Step=91450 Epoch=89.3] | Loss=0.01850 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.935 | L2-Norm(final)=16.569 | 4778.0 samples/s | 74.7 steps/s
[Step=91500 Epoch=89.3] | Loss=0.01827 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.941 | L2-Norm(final)=16.572 | 5152.6 samples/s | 80.5 steps/s
[Step=91550 Epoch=89.4] | Loss=0.01798 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.947 | L2-Norm(final)=16.576 | 2130.7 samples/s | 33.3 steps/s
[Step=91600 Epoch=89.4] | Loss=0.01775 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.952 | L2-Norm(final)=16.580 | 4744.1 samples/s | 74.1 steps/s
[Step=91650 Epoch=89.5] | Loss=0.01749 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=16.584 | 4837.0 samples/s | 75.6 steps/s
[Step=91700 Epoch=89.5] | Loss=0.01731 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.963 | L2-Norm(final)=16.587 | 4854.6 samples/s | 75.9 steps/s
[Step=91750 Epoch=89.6] | Loss=0.01699 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.968 | L2-Norm(final)=16.591 | 4700.5 samples/s | 73.4 steps/s
[Step=91800 Epoch=89.6] | Loss=0.01681 | Reg=0.00064 | acc=0.9688 | L2-Norm=7.973 | L2-Norm(final)=16.594 | 4765.1 samples/s | 74.5 steps/s
[Step=91850 Epoch=89.7] | Loss=0.01665 | Reg=0.00064 | acc=0.9844 | L2-Norm=7.978 | L2-Norm(final)=16.598 | 4791.6 samples/s | 74.9 steps/s
[Step=91900 Epoch=89.7] | Loss=0.01644 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.983 | L2-Norm(final)=16.601 | 4880.4 samples/s | 76.3 steps/s
[Step=91950 Epoch=89.8] | Loss=0.01626 | Reg=0.00064 | acc=0.9844 | L2-Norm=7.988 | L2-Norm(final)=16.605 | 4827.4 samples/s | 75.4 steps/s
[Step=92000 Epoch=89.8] | Loss=0.01611 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.992 | L2-Norm(final)=16.608 | 4804.9 samples/s | 75.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step92000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=90001 Epoch=169.7] | Loss=0.00003 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=14.342 | 4237.3 samples/s | 66.2 steps/s
[Step=90050 Epoch=169.7] | Loss=0.00002 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.765 | L2-Norm(final)=14.352 | 4790.7 samples/s | 74.9 steps/s
[Step=90100 Epoch=169.8] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.362 | 5340.7 samples/s | 83.4 steps/s
[Step=90150 Epoch=169.9] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.371 | 5211.9 samples/s | 81.4 steps/s
[Step=90200 Epoch=170.0] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.381 | 5114.1 samples/s | 79.9 steps/s
[Step=90250 Epoch=170.1] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.390 | 5281.5 samples/s | 82.5 steps/s
[Step=90300 Epoch=170.2] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.399 | 5111.9 samples/s | 79.9 steps/s
[Step=90350 Epoch=170.3] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.407 | 5177.0 samples/s | 80.9 steps/s
[Step=90400 Epoch=170.4] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.416 | 5394.4 samples/s | 84.3 steps/s
[Step=90450 Epoch=170.5] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.425 | 5107.6 samples/s | 79.8 steps/s
[Step=90500 Epoch=170.6] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.433 | 5233.5 samples/s | 81.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=170.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.764 | L2-Norm(final)=14.519 | 4138.4 samples/s | 64.7 steps/s
[Step=90550 Epoch=170.7] | Loss=0.00001 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.740 | L2-Norm(final)=14.524 | 4396.3 samples/s | 68.7 steps/s
[Step=90600 Epoch=170.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.710 | L2-Norm(final)=14.528 | 4537.1 samples/s | 70.9 steps/s
[Step=90650 Epoch=170.9] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.681 | L2-Norm(final)=14.530 | 4505.9 samples/s | 70.4 steps/s
[Step=90700 Epoch=171.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.652 | L2-Norm(final)=14.533 | 4515.7 samples/s | 70.6 steps/s
[Step=90750 Epoch=171.1] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.624 | L2-Norm(final)=14.535 | 4544.4 samples/s | 71.0 steps/s
[Step=90800 Epoch=171.2] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.596 | L2-Norm(final)=14.537 | 4552.4 samples/s | 71.1 steps/s
[Step=90850 Epoch=171.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.569 | L2-Norm(final)=14.540 | 4564.6 samples/s | 71.3 steps/s
[Step=90900 Epoch=171.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.542 | L2-Norm(final)=14.542 | 4553.2 samples/s | 71.1 steps/s
[Step=90950 Epoch=171.4] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.516 | L2-Norm(final)=14.545 | 4627.2 samples/s | 72.3 steps/s
[Step=91000 Epoch=171.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.490 | L2-Norm(final)=14.547 | 4583.3 samples/s | 71.6 steps/s
[Step=91050 Epoch=171.6] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.464 | L2-Norm(final)=14.550 | 2052.9 samples/s | 32.1 steps/s
[Step=91100 Epoch=171.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.439 | L2-Norm(final)=14.553 | 4597.9 samples/s | 71.8 steps/s
[Step=91150 Epoch=171.8] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.414 | L2-Norm(final)=14.555 | 4519.0 samples/s | 70.6 steps/s
[Step=91200 Epoch=171.9] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.558 | 4559.3 samples/s | 71.2 steps/s
[Step=91250 Epoch=172.0] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.363 | L2-Norm(final)=14.560 | 4541.1 samples/s | 71.0 steps/s
[Step=91300 Epoch=172.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.337 | L2-Norm(final)=14.563 | 4574.4 samples/s | 71.5 steps/s
[Step=91350 Epoch=172.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.314 | L2-Norm(final)=14.566 | 4474.7 samples/s | 69.9 steps/s
[Step=91400 Epoch=172.3] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=14.569 | 4459.8 samples/s | 69.7 steps/s
[Step=91450 Epoch=172.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.268 | L2-Norm(final)=14.572 | 4572.1 samples/s | 71.4 steps/s
[Step=91500 Epoch=172.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.246 | L2-Norm(final)=14.575 | 4571.1 samples/s | 71.4 steps/s
[Step=91550 Epoch=172.6] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.225 | L2-Norm(final)=14.578 | 5715.3 samples/s | 89.3 steps/s
[Step=91600 Epoch=172.7] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.204 | L2-Norm(final)=14.581 | 2018.0 samples/s | 31.5 steps/s
[Step=91650 Epoch=172.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.182 | L2-Norm(final)=14.584 | 4626.7 samples/s | 72.3 steps/s
[Step=91700 Epoch=172.9] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.162 | L2-Norm(final)=14.587 | 4495.6 samples/s | 70.2 steps/s
[Step=91750 Epoch=173.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.141 | L2-Norm(final)=14.589 | 4721.8 samples/s | 73.8 steps/s
[Step=91800 Epoch=173.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=14.592 | 4639.3 samples/s | 72.5 steps/s
[Step=91850 Epoch=173.1] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=14.595 | 4683.1 samples/s | 73.2 steps/s
[Step=91900 Epoch=173.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.080 | L2-Norm(final)=14.598 | 4554.6 samples/s | 71.2 steps/s
[Step=91950 Epoch=173.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.060 | L2-Norm(final)=14.601 | 4537.6 samples/s | 70.9 steps/s
[Step=92000 Epoch=173.4] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.040 | L2-Norm(final)=14.604 | 4541.4 samples/s | 71.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05157 | acc=0.9702 | tpr=0.9720 | fpr=0.0337 | 4531.5 samples/s | 17.7 steps/s
Avg test loss: 0.05523, Avg test acc: 0.96883, Avg tpr: 0.97068, Avg fpr: 0.03525, total FA: 275

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.15405 | acc=0.3027 | tpr=0.0102 | fpr=0.0619 | 4490.5 samples/s | 17.5 steps/s
Avg test loss: 5.18216, Avg test acc: 0.29958, Avg tpr: 0.00892, Avg fpr: 0.06115, total FA: 477

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.64527 | acc=0.1591 | tpr=0.3230 | fpr=0.8439 | 4573.8 samples/s | 17.9 steps/s
[Step= 100] | Loss=3.62208 | acc=0.1594 | tpr=0.3177 | fpr=0.8436 | 8421.8 samples/s | 32.9 steps/s
[Step= 150] | Loss=3.62202 | acc=0.1594 | tpr=0.3213 | fpr=0.8436 | 8172.1 samples/s | 31.9 steps/s
[Step= 200] | Loss=3.61560 | acc=0.1586 | tpr=0.3158 | fpr=0.8442 | 8582.1 samples/s | 33.5 steps/s
[Step= 250] | Loss=3.61739 | acc=0.1587 | tpr=0.3162 | fpr=0.8441 | 8439.1 samples/s | 33.0 steps/s
[Step= 300] | Loss=3.61517 | acc=0.1581 | tpr=0.3113 | fpr=0.8447 | 8534.5 samples/s | 33.3 steps/s
[Step= 350] | Loss=3.61368 | acc=0.1578 | tpr=0.3037 | fpr=0.8448 | 8359.1 samples/s | 32.7 steps/s
[Step= 400] | Loss=3.61389 | acc=0.1579 | tpr=0.3058 | fpr=0.8448 | 8540.6 samples/s | 33.4 steps/s
[Step= 450] | Loss=3.61497 | acc=0.1581 | tpr=0.3072 | fpr=0.8447 | 8619.3 samples/s | 33.7 steps/s
[Step= 500] | Loss=3.61635 | acc=0.1583 | tpr=0.3040 | fpr=0.8443 | 8126.6 samples/s | 31.7 steps/s
[Step= 550] | Loss=3.61713 | acc=0.1583 | tpr=0.3056 | fpr=0.8444 | 16310.4 samples/s | 63.7 steps/s
Avg test loss: 3.61775, Avg test acc: 0.15815, Avg tpr: 0.30626, Avg fpr: 0.84454, total FA: 117263

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12145 | acc=0.9805 | tpr=0.9558 | fpr=0.0191 | 4510.2 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.12890 | acc=0.9793 | tpr=0.9616 | fpr=0.0204 | 8725.0 samples/s | 34.1 steps/s
[Step= 150] | Loss=0.13454 | acc=0.9785 | tpr=0.9611 | fpr=0.0211 | 8097.7 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.13483 | acc=0.9788 | tpr=0.9628 | fpr=0.0210 | 8628.2 samples/s | 33.7 steps/s
[Step= 250] | Loss=0.13348 | acc=0.9788 | tpr=0.9607 | fpr=0.0208 | 8482.0 samples/s | 33.1 steps/s
[Step= 300] | Loss=0.13575 | acc=0.9785 | tpr=0.9622 | fpr=0.0212 | 8443.6 samples/s | 33.0 steps/s
[Step= 350] | Loss=0.13758 | acc=0.9780 | tpr=0.9618 | fpr=0.0217 | 8682.5 samples/s | 33.9 steps/s
[Step= 400] | Loss=0.13843 | acc=0.9779 | tpr=0.9606 | fpr=0.0217 | 8421.7 samples/s | 32.9 steps/s
[Step= 450] | Loss=0.14106 | acc=0.9777 | tpr=0.9581 | fpr=0.0220 | 8453.8 samples/s | 33.0 steps/s
[Step= 500] | Loss=0.14034 | acc=0.9777 | tpr=0.9577 | fpr=0.0219 | 8266.5 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.13960 | acc=0.9778 | tpr=0.9562 | fpr=0.0218 | 15889.4 samples/s | 62.1 steps/s
Avg test loss: 0.13933, Avg test acc: 0.97786, Avg tpr: 0.95642, Avg fpr: 0.02175, total FA: 3020

server round 46/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=92001 Epoch=89.8] | Loss=0.04839 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.217 | L2-Norm(final)=16.709 | 4157.7 samples/s | 65.0 steps/s
[Step=92050 Epoch=89.9] | Loss=0.05038 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.218 | L2-Norm(final)=16.707 | 5428.9 samples/s | 84.8 steps/s
[Step=92100 Epoch=89.9] | Loss=0.04855 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.218 | L2-Norm(final)=16.706 | 5784.2 samples/s | 90.4 steps/s
[Step=92150 Epoch=90.0] | Loss=0.04685 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.218 | L2-Norm(final)=16.705 | 5596.0 samples/s | 87.4 steps/s
[Step=92200 Epoch=90.0] | Loss=0.04644 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.218 | L2-Norm(final)=16.706 | 5422.0 samples/s | 84.7 steps/s
[Step=92250 Epoch=90.1] | Loss=0.04571 | Reg=0.00052 | acc=0.9062 | L2-Norm=7.218 | L2-Norm(final)=16.707 | 5762.7 samples/s | 90.0 steps/s
[Step=92300 Epoch=90.1] | Loss=0.04500 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.218 | L2-Norm(final)=16.709 | 5611.9 samples/s | 87.7 steps/s
[Step=92350 Epoch=90.2] | Loss=0.04487 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.218 | L2-Norm(final)=16.711 | 5499.0 samples/s | 85.9 steps/s
[Step=92400 Epoch=90.2] | Loss=0.04425 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.218 | L2-Norm(final)=16.713 | 5601.7 samples/s | 87.5 steps/s
[Step=92450 Epoch=90.3] | Loss=0.04374 | Reg=0.00052 | acc=0.9531 | L2-Norm=7.218 | L2-Norm(final)=16.716 | 5569.5 samples/s | 87.0 steps/s
[Step=92500 Epoch=90.3] | Loss=0.04329 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.218 | L2-Norm(final)=16.720 | 5470.9 samples/s | 85.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=90.3] | Loss=0.02937 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.218 | L2-Norm(final)=16.754 | 4300.3 samples/s | 67.2 steps/s
[Step=92550 Epoch=90.4] | Loss=0.03346 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.234 | L2-Norm(final)=16.761 | 4384.1 samples/s | 68.5 steps/s
[Step=92600 Epoch=90.4] | Loss=0.03401 | Reg=0.00053 | acc=0.9688 | L2-Norm=7.251 | L2-Norm(final)=16.767 | 4884.3 samples/s | 76.3 steps/s
[Step=92650 Epoch=90.5] | Loss=0.03139 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=16.773 | 4994.7 samples/s | 78.0 steps/s
[Step=92700 Epoch=90.5] | Loss=0.03031 | Reg=0.00053 | acc=0.9531 | L2-Norm=7.281 | L2-Norm(final)=16.779 | 4852.6 samples/s | 75.8 steps/s
[Step=92750 Epoch=90.6] | Loss=0.02905 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.294 | L2-Norm(final)=16.784 | 4919.4 samples/s | 76.9 steps/s
[Step=92800 Epoch=90.6] | Loss=0.02803 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.306 | L2-Norm(final)=16.789 | 4912.5 samples/s | 76.8 steps/s
[Step=92850 Epoch=90.7] | Loss=0.02769 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=16.794 | 4901.5 samples/s | 76.6 steps/s
[Step=92900 Epoch=90.7] | Loss=0.02687 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.328 | L2-Norm(final)=16.799 | 4773.4 samples/s | 74.6 steps/s
[Step=92950 Epoch=90.8] | Loss=0.02617 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.338 | L2-Norm(final)=16.803 | 4909.0 samples/s | 76.7 steps/s
[Step=93000 Epoch=90.8] | Loss=0.02597 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.348 | L2-Norm(final)=16.808 | 4913.3 samples/s | 76.8 steps/s
[Step=93050 Epoch=90.8] | Loss=0.02557 | Reg=0.00054 | acc=0.9531 | L2-Norm=7.357 | L2-Norm(final)=16.812 | 4974.1 samples/s | 77.7 steps/s
[Step=93100 Epoch=90.9] | Loss=0.02496 | Reg=0.00054 | acc=0.9531 | L2-Norm=7.366 | L2-Norm(final)=16.816 | 4852.8 samples/s | 75.8 steps/s
[Step=93150 Epoch=90.9] | Loss=0.02437 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.375 | L2-Norm(final)=16.820 | 4854.7 samples/s | 75.9 steps/s
[Step=93200 Epoch=91.0] | Loss=0.02384 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.383 | L2-Norm(final)=16.825 | 4807.7 samples/s | 75.1 steps/s
[Step=93250 Epoch=91.0] | Loss=0.02351 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.391 | L2-Norm(final)=16.829 | 4771.7 samples/s | 74.6 steps/s
[Step=93300 Epoch=91.1] | Loss=0.02317 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.399 | L2-Norm(final)=16.833 | 4788.1 samples/s | 74.8 steps/s
[Step=93350 Epoch=91.1] | Loss=0.02282 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.406 | L2-Norm(final)=16.836 | 4822.2 samples/s | 75.3 steps/s
[Step=93400 Epoch=91.2] | Loss=0.02261 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.414 | L2-Norm(final)=16.840 | 4767.1 samples/s | 74.5 steps/s
[Step=93450 Epoch=91.2] | Loss=0.02233 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.421 | L2-Norm(final)=16.844 | 4767.8 samples/s | 74.5 steps/s
[Step=93500 Epoch=91.3] | Loss=0.02204 | Reg=0.00055 | acc=0.9375 | L2-Norm=7.428 | L2-Norm(final)=16.848 | 5167.6 samples/s | 80.7 steps/s
[Step=93550 Epoch=91.3] | Loss=0.02180 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.435 | L2-Norm(final)=16.851 | 2143.2 samples/s | 33.5 steps/s
[Step=93600 Epoch=91.4] | Loss=0.02139 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.441 | L2-Norm(final)=16.855 | 4719.6 samples/s | 73.7 steps/s
[Step=93650 Epoch=91.4] | Loss=0.02102 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.448 | L2-Norm(final)=16.859 | 4745.0 samples/s | 74.1 steps/s
[Step=93700 Epoch=91.5] | Loss=0.02066 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.454 | L2-Norm(final)=16.862 | 4763.6 samples/s | 74.4 steps/s
[Step=93750 Epoch=91.5] | Loss=0.02036 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.461 | L2-Norm(final)=16.866 | 4778.5 samples/s | 74.7 steps/s
[Step=93800 Epoch=91.6] | Loss=0.02004 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.467 | L2-Norm(final)=16.870 | 4799.2 samples/s | 75.0 steps/s
[Step=93850 Epoch=91.6] | Loss=0.01979 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.473 | L2-Norm(final)=16.873 | 4771.5 samples/s | 74.6 steps/s
[Step=93900 Epoch=91.7] | Loss=0.01959 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.479 | L2-Norm(final)=16.876 | 4736.3 samples/s | 74.0 steps/s
[Step=93950 Epoch=91.7] | Loss=0.01944 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.485 | L2-Norm(final)=16.880 | 4789.9 samples/s | 74.8 steps/s
[Step=94000 Epoch=91.8] | Loss=0.01930 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.490 | L2-Norm(final)=16.883 | 4788.7 samples/s | 74.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step94000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=92001 Epoch=173.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.217 | L2-Norm(final)=14.706 | 4412.5 samples/s | 68.9 steps/s
[Step=92050 Epoch=173.5] | Loss=0.00559 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.224 | L2-Norm(final)=14.727 | 4866.3 samples/s | 76.0 steps/s
[Step=92100 Epoch=173.6] | Loss=0.00529 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.225 | L2-Norm(final)=14.747 | 5223.8 samples/s | 81.6 steps/s
[Step=92150 Epoch=173.7] | Loss=0.00452 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.225 | L2-Norm(final)=14.763 | 5264.9 samples/s | 82.3 steps/s
[Step=92200 Epoch=173.8] | Loss=0.00463 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.226 | L2-Norm(final)=14.777 | 5211.5 samples/s | 81.4 steps/s
[Step=92250 Epoch=173.9] | Loss=0.00487 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.789 | 5102.9 samples/s | 79.7 steps/s
[Step=92300 Epoch=174.0] | Loss=0.00487 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.800 | 5104.4 samples/s | 79.8 steps/s
[Step=92350 Epoch=174.1] | Loss=0.00482 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.809 | 5493.5 samples/s | 85.8 steps/s
[Step=92400 Epoch=174.2] | Loss=0.00469 | Reg=0.00052 | acc=0.9844 | L2-Norm=7.226 | L2-Norm(final)=14.818 | 5281.7 samples/s | 82.5 steps/s
[Step=92450 Epoch=174.3] | Loss=0.00481 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.826 | 5290.0 samples/s | 82.7 steps/s
[Step=92500 Epoch=174.4] | Loss=0.00454 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.833 | 5212.6 samples/s | 81.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=174.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.226 | L2-Norm(final)=14.906 | 3844.9 samples/s | 60.1 steps/s
[Step=92550 Epoch=174.5] | Loss=0.00070 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.230 | L2-Norm(final)=14.906 | 4584.4 samples/s | 71.6 steps/s
[Step=92600 Epoch=174.6] | Loss=0.00036 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.230 | L2-Norm(final)=14.906 | 4624.2 samples/s | 72.3 steps/s
[Step=92650 Epoch=174.6] | Loss=0.00025 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.229 | L2-Norm(final)=14.906 | 4656.7 samples/s | 72.8 steps/s
[Step=92700 Epoch=174.7] | Loss=0.00019 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.228 | L2-Norm(final)=14.906 | 4616.3 samples/s | 72.1 steps/s
[Step=92750 Epoch=174.8] | Loss=0.00016 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.227 | L2-Norm(final)=14.907 | 4713.9 samples/s | 73.7 steps/s
[Step=92800 Epoch=174.9] | Loss=0.00013 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.225 | L2-Norm(final)=14.907 | 4542.1 samples/s | 71.0 steps/s
[Step=92850 Epoch=175.0] | Loss=0.00012 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.224 | L2-Norm(final)=14.907 | 4627.5 samples/s | 72.3 steps/s
[Step=92900 Epoch=175.1] | Loss=0.00011 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.223 | L2-Norm(final)=14.907 | 4549.2 samples/s | 71.1 steps/s
[Step=92950 Epoch=175.2] | Loss=0.00009 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.222 | L2-Norm(final)=14.907 | 4498.4 samples/s | 70.3 steps/s
[Step=93000 Epoch=175.3] | Loss=0.00009 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.220 | L2-Norm(final)=14.907 | 4551.1 samples/s | 71.1 steps/s
[Step=93050 Epoch=175.4] | Loss=0.00008 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.219 | L2-Norm(final)=14.907 | 2131.6 samples/s | 33.3 steps/s
[Step=93100 Epoch=175.5] | Loss=0.00007 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.218 | L2-Norm(final)=14.907 | 4633.1 samples/s | 72.4 steps/s
[Step=93150 Epoch=175.6] | Loss=0.00007 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.217 | L2-Norm(final)=14.907 | 4497.9 samples/s | 70.3 steps/s
[Step=93200 Epoch=175.7] | Loss=0.00006 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=14.907 | 4532.2 samples/s | 70.8 steps/s
[Step=93250 Epoch=175.8] | Loss=0.00006 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.215 | L2-Norm(final)=14.907 | 4373.5 samples/s | 68.3 steps/s
[Step=93300 Epoch=175.9] | Loss=0.00006 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.214 | L2-Norm(final)=14.907 | 4534.8 samples/s | 70.9 steps/s
[Step=93350 Epoch=176.0] | Loss=0.00005 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.212 | L2-Norm(final)=14.907 | 4549.5 samples/s | 71.1 steps/s
[Step=93400 Epoch=176.1] | Loss=0.00005 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.211 | L2-Norm(final)=14.907 | 4553.8 samples/s | 71.2 steps/s
[Step=93450 Epoch=176.2] | Loss=0.00005 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.210 | L2-Norm(final)=14.907 | 4535.5 samples/s | 70.9 steps/s
[Step=93500 Epoch=176.2] | Loss=0.00005 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.209 | L2-Norm(final)=14.908 | 4510.7 samples/s | 70.5 steps/s
[Step=93550 Epoch=176.3] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.208 | L2-Norm(final)=14.908 | 5655.8 samples/s | 88.4 steps/s
[Step=93600 Epoch=176.4] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.207 | L2-Norm(final)=14.908 | 1959.8 samples/s | 30.6 steps/s
[Step=93650 Epoch=176.5] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.206 | L2-Norm(final)=14.908 | 4532.1 samples/s | 70.8 steps/s
[Step=93700 Epoch=176.6] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.205 | L2-Norm(final)=14.908 | 4536.5 samples/s | 70.9 steps/s
[Step=93750 Epoch=176.7] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.203 | L2-Norm(final)=14.908 | 4546.5 samples/s | 71.0 steps/s
[Step=93800 Epoch=176.8] | Loss=0.00004 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.202 | L2-Norm(final)=14.908 | 4508.0 samples/s | 70.4 steps/s
[Step=93850 Epoch=176.9] | Loss=0.00003 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.201 | L2-Norm(final)=14.908 | 4508.0 samples/s | 70.4 steps/s
[Step=93900 Epoch=177.0] | Loss=0.00003 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.200 | L2-Norm(final)=14.908 | 4517.0 samples/s | 70.6 steps/s
[Step=93950 Epoch=177.1] | Loss=0.00003 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.199 | L2-Norm(final)=14.908 | 4533.6 samples/s | 70.8 steps/s
[Step=94000 Epoch=177.2] | Loss=0.00003 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.198 | L2-Norm(final)=14.908 | 4503.5 samples/s | 70.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.04643 | acc=0.9717 | tpr=0.9803 | fpr=0.0468 | 4522.8 samples/s | 17.7 steps/s
Avg test loss: 0.05022, Avg test acc: 0.96987, Avg tpr: 0.97908, Avg fpr: 0.05038, total FA: 393

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.58716 | acc=0.2953 | tpr=0.0134 | fpr=0.0924 | 4627.5 samples/s | 18.1 steps/s
Avg test loss: 4.60425, Avg test acc: 0.29381, Avg tpr: 0.01282, Avg fpr: 0.08819, total FA: 688

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.57188 | acc=0.1425 | tpr=0.3540 | fpr=0.8613 | 4365.2 samples/s | 17.1 steps/s
[Step= 100] | Loss=3.55675 | acc=0.1413 | tpr=0.3348 | fpr=0.8623 | 8264.5 samples/s | 32.3 steps/s
[Step= 150] | Loss=3.55838 | acc=0.1407 | tpr=0.3329 | fpr=0.8628 | 8436.1 samples/s | 33.0 steps/s
[Step= 200] | Loss=3.55165 | acc=0.1406 | tpr=0.3301 | fpr=0.8628 | 8599.3 samples/s | 33.6 steps/s
[Step= 250] | Loss=3.55277 | acc=0.1410 | tpr=0.3310 | fpr=0.8625 | 8432.9 samples/s | 32.9 steps/s
[Step= 300] | Loss=3.55130 | acc=0.1404 | tpr=0.3287 | fpr=0.8631 | 8615.3 samples/s | 33.7 steps/s
[Step= 350] | Loss=3.55078 | acc=0.1400 | tpr=0.3244 | fpr=0.8633 | 8740.9 samples/s | 34.1 steps/s
[Step= 400] | Loss=3.55099 | acc=0.1403 | tpr=0.3288 | fpr=0.8631 | 8346.1 samples/s | 32.6 steps/s
[Step= 450] | Loss=3.55200 | acc=0.1405 | tpr=0.3301 | fpr=0.8629 | 8124.7 samples/s | 31.7 steps/s
[Step= 500] | Loss=3.55337 | acc=0.1408 | tpr=0.3269 | fpr=0.8625 | 8727.3 samples/s | 34.1 steps/s
[Step= 550] | Loss=3.55403 | acc=0.1409 | tpr=0.3283 | fpr=0.8625 | 15831.3 samples/s | 61.8 steps/s
Avg test loss: 3.55459, Avg test acc: 0.14073, Avg tpr: 0.32884, Avg fpr: 0.86269, total FA: 119783

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10064 | acc=0.9823 | tpr=0.9558 | fpr=0.0173 | 4514.3 samples/s | 17.6 steps/s
[Step= 100] | Loss=0.10685 | acc=0.9811 | tpr=0.9616 | fpr=0.0185 | 8923.8 samples/s | 34.9 steps/s
[Step= 150] | Loss=0.11161 | acc=0.9802 | tpr=0.9640 | fpr=0.0195 | 8619.4 samples/s | 33.7 steps/s
[Step= 200] | Loss=0.11193 | acc=0.9803 | tpr=0.9672 | fpr=0.0194 | 8077.3 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.11081 | acc=0.9806 | tpr=0.9668 | fpr=0.0192 | 8839.1 samples/s | 34.5 steps/s
[Step= 300] | Loss=0.11260 | acc=0.9803 | tpr=0.9673 | fpr=0.0194 | 8078.5 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.11422 | acc=0.9798 | tpr=0.9668 | fpr=0.0199 | 8374.7 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.11494 | acc=0.9797 | tpr=0.9650 | fpr=0.0200 | 8498.3 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.11736 | acc=0.9794 | tpr=0.9625 | fpr=0.0203 | 8357.3 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.11682 | acc=0.9795 | tpr=0.9621 | fpr=0.0202 | 8292.8 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.11618 | acc=0.9795 | tpr=0.9610 | fpr=0.0201 | 15524.7 samples/s | 60.6 steps/s
Avg test loss: 0.11602, Avg test acc: 0.97957, Avg tpr: 0.96117, Avg fpr: 0.02009, total FA: 2790

server round 47/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=94001 Epoch=91.8] | Loss=0.03611 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.356 | L2-Norm(final)=16.983 | 3843.3 samples/s | 60.1 steps/s
[Step=94050 Epoch=91.8] | Loss=0.02937 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.357 | L2-Norm(final)=16.988 | 5581.7 samples/s | 87.2 steps/s
[Step=94100 Epoch=91.9] | Loss=0.02715 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=16.994 | 5748.8 samples/s | 89.8 steps/s
[Step=94150 Epoch=91.9] | Loss=0.02653 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.357 | L2-Norm(final)=17.001 | 5661.1 samples/s | 88.5 steps/s
[Step=94200 Epoch=92.0] | Loss=0.02592 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=17.008 | 5580.7 samples/s | 87.2 steps/s
[Step=94250 Epoch=92.0] | Loss=0.02531 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=17.015 | 5644.7 samples/s | 88.2 steps/s
[Step=94300 Epoch=92.1] | Loss=0.02477 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.357 | L2-Norm(final)=17.022 | 5532.4 samples/s | 86.4 steps/s
[Step=94350 Epoch=92.1] | Loss=0.02434 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.357 | L2-Norm(final)=17.029 | 5576.8 samples/s | 87.1 steps/s
[Step=94400 Epoch=92.2] | Loss=0.02461 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.357 | L2-Norm(final)=17.036 | 5362.0 samples/s | 83.8 steps/s
[Step=94450 Epoch=92.2] | Loss=0.02465 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.357 | L2-Norm(final)=17.043 | 5423.2 samples/s | 84.7 steps/s
[Step=94500 Epoch=92.3] | Loss=0.02460 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=17.050 | 5475.2 samples/s | 85.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=92.3] | Loss=0.05749 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.357 | L2-Norm(final)=17.120 | 4321.2 samples/s | 67.5 steps/s
[Step=94550 Epoch=92.3] | Loss=0.02246 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.367 | L2-Norm(final)=17.127 | 4508.1 samples/s | 70.4 steps/s
[Step=94600 Epoch=92.4] | Loss=0.02147 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.380 | L2-Norm(final)=17.134 | 4791.2 samples/s | 74.9 steps/s
[Step=94650 Epoch=92.4] | Loss=0.02064 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.393 | L2-Norm(final)=17.140 | 4814.8 samples/s | 75.2 steps/s
[Step=94700 Epoch=92.5] | Loss=0.01996 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.403 | L2-Norm(final)=17.145 | 4706.7 samples/s | 73.5 steps/s
[Step=94750 Epoch=92.5] | Loss=0.01935 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.414 | L2-Norm(final)=17.151 | 4763.2 samples/s | 74.4 steps/s
[Step=94800 Epoch=92.6] | Loss=0.01895 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.423 | L2-Norm(final)=17.155 | 4811.1 samples/s | 75.2 steps/s
[Step=94850 Epoch=92.6] | Loss=0.01846 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.432 | L2-Norm(final)=17.160 | 4724.5 samples/s | 73.8 steps/s
[Step=94900 Epoch=92.7] | Loss=0.01841 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.441 | L2-Norm(final)=17.165 | 4811.6 samples/s | 75.2 steps/s
[Step=94950 Epoch=92.7] | Loss=0.01820 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.449 | L2-Norm(final)=17.169 | 4807.5 samples/s | 75.1 steps/s
[Step=95000 Epoch=92.8] | Loss=0.01803 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.457 | L2-Norm(final)=17.173 | 4887.9 samples/s | 76.4 steps/s
[Step=95050 Epoch=92.8] | Loss=0.01775 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.464 | L2-Norm(final)=17.178 | 4764.7 samples/s | 74.4 steps/s
[Step=95100 Epoch=92.8] | Loss=0.01750 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=17.182 | 4758.7 samples/s | 74.4 steps/s
[Step=95150 Epoch=92.9] | Loss=0.01741 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.478 | L2-Norm(final)=17.186 | 4814.5 samples/s | 75.2 steps/s
[Step=95200 Epoch=92.9] | Loss=0.01733 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.485 | L2-Norm(final)=17.190 | 4763.6 samples/s | 74.4 steps/s
[Step=95250 Epoch=93.0] | Loss=0.01724 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.491 | L2-Norm(final)=17.193 | 4778.2 samples/s | 74.7 steps/s
[Step=95300 Epoch=93.0] | Loss=0.01694 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.498 | L2-Norm(final)=17.197 | 4783.1 samples/s | 74.7 steps/s
[Step=95350 Epoch=93.1] | Loss=0.01680 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.504 | L2-Norm(final)=17.201 | 4778.1 samples/s | 74.7 steps/s
[Step=95400 Epoch=93.1] | Loss=0.01673 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.510 | L2-Norm(final)=17.205 | 4784.5 samples/s | 74.8 steps/s
[Step=95450 Epoch=93.2] | Loss=0.01675 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.516 | L2-Norm(final)=17.208 | 4815.9 samples/s | 75.2 steps/s
[Step=95500 Epoch=93.2] | Loss=0.01653 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.522 | L2-Norm(final)=17.212 | 5137.1 samples/s | 80.3 steps/s
[Step=95550 Epoch=93.3] | Loss=0.01631 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.528 | L2-Norm(final)=17.215 | 2111.2 samples/s | 33.0 steps/s
[Step=95600 Epoch=93.3] | Loss=0.01615 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.533 | L2-Norm(final)=17.219 | 4733.6 samples/s | 74.0 steps/s
[Step=95650 Epoch=93.4] | Loss=0.01597 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.539 | L2-Norm(final)=17.222 | 4755.4 samples/s | 74.3 steps/s
[Step=95700 Epoch=93.4] | Loss=0.01576 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.544 | L2-Norm(final)=17.226 | 4762.6 samples/s | 74.4 steps/s
[Step=95750 Epoch=93.5] | Loss=0.01569 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.550 | L2-Norm(final)=17.229 | 4777.6 samples/s | 74.6 steps/s
[Step=95800 Epoch=93.5] | Loss=0.01560 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.555 | L2-Norm(final)=17.233 | 4791.3 samples/s | 74.9 steps/s
[Step=95850 Epoch=93.6] | Loss=0.01542 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.560 | L2-Norm(final)=17.236 | 4836.5 samples/s | 75.6 steps/s
[Step=95900 Epoch=93.6] | Loss=0.01527 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.565 | L2-Norm(final)=17.240 | 4755.5 samples/s | 74.3 steps/s
[Step=95950 Epoch=93.7] | Loss=0.01520 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.570 | L2-Norm(final)=17.243 | 4801.3 samples/s | 75.0 steps/s
[Step=96000 Epoch=93.7] | Loss=0.01507 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.575 | L2-Norm(final)=17.246 | 4777.3 samples/s | 74.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step96000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=94001 Epoch=177.2] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.356 | L2-Norm(final)=14.910 | 4237.7 samples/s | 66.2 steps/s
[Step=94050 Epoch=177.3] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 4891.9 samples/s | 76.4 steps/s
[Step=94100 Epoch=177.4] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5126.3 samples/s | 80.1 steps/s
[Step=94150 Epoch=177.5] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5128.5 samples/s | 80.1 steps/s
[Step=94200 Epoch=177.6] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5201.5 samples/s | 81.3 steps/s
[Step=94250 Epoch=177.7] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5127.6 samples/s | 80.1 steps/s
[Step=94300 Epoch=177.8] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5207.3 samples/s | 81.4 steps/s
[Step=94350 Epoch=177.9] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5245.3 samples/s | 82.0 steps/s
[Step=94400 Epoch=177.9] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5128.7 samples/s | 80.1 steps/s
[Step=94450 Epoch=178.0] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5284.7 samples/s | 82.6 steps/s
[Step=94500 Epoch=178.1] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 5178.0 samples/s | 80.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=178.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.355 | L2-Norm(final)=14.910 | 4156.7 samples/s | 64.9 steps/s
[Step=94550 Epoch=178.2] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.347 | L2-Norm(final)=14.911 | 4134.4 samples/s | 64.6 steps/s
[Step=94600 Epoch=178.3] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.341 | L2-Norm(final)=14.911 | 4630.4 samples/s | 72.4 steps/s
[Step=94650 Epoch=178.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.336 | L2-Norm(final)=14.911 | 4409.1 samples/s | 68.9 steps/s
[Step=94700 Epoch=178.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.332 | L2-Norm(final)=14.911 | 4507.4 samples/s | 70.4 steps/s
[Step=94750 Epoch=178.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.328 | L2-Norm(final)=14.912 | 4528.9 samples/s | 70.8 steps/s
[Step=94800 Epoch=178.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.325 | L2-Norm(final)=14.912 | 4560.4 samples/s | 71.3 steps/s
[Step=94850 Epoch=178.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=14.912 | 4543.4 samples/s | 71.0 steps/s
[Step=94900 Epoch=178.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.319 | L2-Norm(final)=14.912 | 4625.4 samples/s | 72.3 steps/s
[Step=94950 Epoch=179.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=14.912 | 4116.2 samples/s | 64.3 steps/s
[Step=95000 Epoch=179.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.313 | L2-Norm(final)=14.913 | 4000.2 samples/s | 62.5 steps/s
[Step=95050 Epoch=179.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.310 | L2-Norm(final)=14.913 | 1909.6 samples/s | 29.8 steps/s
[Step=95100 Epoch=179.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.307 | L2-Norm(final)=14.913 | 4222.4 samples/s | 66.0 steps/s
[Step=95150 Epoch=179.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=14.913 | 4441.4 samples/s | 69.4 steps/s
[Step=95200 Epoch=179.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.301 | L2-Norm(final)=14.913 | 4279.4 samples/s | 66.9 steps/s
[Step=95250 Epoch=179.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=14.914 | 4393.3 samples/s | 68.6 steps/s
[Step=95300 Epoch=179.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=14.914 | 4313.1 samples/s | 67.4 steps/s
[Step=95350 Epoch=179.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.914 | 4339.9 samples/s | 67.8 steps/s
[Step=95400 Epoch=179.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=14.914 | 4267.8 samples/s | 66.7 steps/s
[Step=95450 Epoch=179.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.287 | L2-Norm(final)=14.914 | 4244.7 samples/s | 66.3 steps/s
[Step=95500 Epoch=180.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.284 | L2-Norm(final)=14.914 | 4432.1 samples/s | 69.3 steps/s
[Step=95550 Epoch=180.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.281 | L2-Norm(final)=14.914 | 5587.2 samples/s | 87.3 steps/s
[Step=95600 Epoch=180.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.278 | L2-Norm(final)=14.915 | 1927.7 samples/s | 30.1 steps/s
[Step=95650 Epoch=180.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.275 | L2-Norm(final)=14.915 | 4384.3 samples/s | 68.5 steps/s
[Step=95700 Epoch=180.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.272 | L2-Norm(final)=14.915 | 4496.5 samples/s | 70.3 steps/s
[Step=95750 Epoch=180.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.269 | L2-Norm(final)=14.915 | 4594.3 samples/s | 71.8 steps/s
[Step=95800 Epoch=180.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.266 | L2-Norm(final)=14.915 | 4537.6 samples/s | 70.9 steps/s
[Step=95850 Epoch=180.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.263 | L2-Norm(final)=14.915 | 4483.7 samples/s | 70.1 steps/s
[Step=95900 Epoch=180.8] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=14.915 | 4590.0 samples/s | 71.7 steps/s
[Step=95950 Epoch=180.9] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.257 | L2-Norm(final)=14.915 | 4501.7 samples/s | 70.3 steps/s
[Step=96000 Epoch=181.0] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.254 | L2-Norm(final)=14.916 | 4502.7 samples/s | 70.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05040 | acc=0.9702 | tpr=0.9718 | fpr=0.0334 | 4528.4 samples/s | 17.7 steps/s
Avg test loss: 0.05384, Avg test acc: 0.96891, Avg tpr: 0.97080, Avg fpr: 0.03525, total FA: 275

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.51692 | acc=0.2984 | tpr=0.0130 | fpr=0.0820 | 4425.4 samples/s | 17.3 steps/s
Avg test loss: 4.53108, Avg test acc: 0.29718, Avg tpr: 0.01317, Avg fpr: 0.07820, total FA: 610

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.66821 | acc=0.1569 | tpr=0.3186 | fpr=0.8460 | 4431.1 samples/s | 17.3 steps/s
[Step= 100] | Loss=3.65089 | acc=0.1573 | tpr=0.3049 | fpr=0.8454 | 8470.5 samples/s | 33.1 steps/s
[Step= 150] | Loss=3.65058 | acc=0.1568 | tpr=0.3012 | fpr=0.8458 | 8402.6 samples/s | 32.8 steps/s
[Step= 200] | Loss=3.64410 | acc=0.1566 | tpr=0.2995 | fpr=0.8460 | 8694.8 samples/s | 34.0 steps/s
[Step= 250] | Loss=3.64536 | acc=0.1564 | tpr=0.2978 | fpr=0.8462 | 7963.4 samples/s | 31.1 steps/s
[Step= 300] | Loss=3.64321 | acc=0.1558 | tpr=0.2953 | fpr=0.8467 | 8426.4 samples/s | 32.9 steps/s
[Step= 350] | Loss=3.64252 | acc=0.1553 | tpr=0.2880 | fpr=0.8471 | 8254.4 samples/s | 32.2 steps/s
[Step= 400] | Loss=3.64285 | acc=0.1554 | tpr=0.2905 | fpr=0.8471 | 8225.4 samples/s | 32.1 steps/s
[Step= 450] | Loss=3.64410 | acc=0.1556 | tpr=0.2926 | fpr=0.8469 | 8471.8 samples/s | 33.1 steps/s
[Step= 500] | Loss=3.64521 | acc=0.1558 | tpr=0.2890 | fpr=0.8466 | 8202.6 samples/s | 32.0 steps/s
[Step= 550] | Loss=3.64588 | acc=0.1559 | tpr=0.2897 | fpr=0.8465 | 14918.5 samples/s | 58.3 steps/s
Avg test loss: 3.64646, Avg test acc: 0.15575, Avg tpr: 0.29041, Avg fpr: 0.84670, total FA: 117562

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11256 | acc=0.9815 | tpr=0.9602 | fpr=0.0181 | 4440.3 samples/s | 17.3 steps/s
[Step= 100] | Loss=0.11951 | acc=0.9803 | tpr=0.9659 | fpr=0.0195 | 8106.5 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.12501 | acc=0.9794 | tpr=0.9683 | fpr=0.0204 | 8017.0 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.12549 | acc=0.9795 | tpr=0.9716 | fpr=0.0203 | 8395.0 samples/s | 32.8 steps/s
[Step= 250] | Loss=0.12419 | acc=0.9798 | tpr=0.9686 | fpr=0.0200 | 8008.1 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.12617 | acc=0.9795 | tpr=0.9695 | fpr=0.0203 | 8029.8 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.12793 | acc=0.9790 | tpr=0.9693 | fpr=0.0208 | 8199.4 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.12871 | acc=0.9789 | tpr=0.9672 | fpr=0.0209 | 8133.0 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.13138 | acc=0.9786 | tpr=0.9649 | fpr=0.0212 | 8498.7 samples/s | 33.2 steps/s
[Step= 500] | Loss=0.13086 | acc=0.9786 | tpr=0.9639 | fpr=0.0211 | 8098.1 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.13005 | acc=0.9787 | tpr=0.9630 | fpr=0.0210 | 13652.8 samples/s | 53.3 steps/s
Avg test loss: 0.12987, Avg test acc: 0.97875, Avg tpr: 0.96315, Avg fpr: 0.02097, total FA: 2911

server round 48/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=96001 Epoch=93.7] | Loss=0.00443 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=17.343 | 4016.6 samples/s | 62.8 steps/s
[Step=96050 Epoch=93.8] | Loss=0.02069 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.390 | L2-Norm(final)=17.344 | 5221.7 samples/s | 81.6 steps/s
[Step=96100 Epoch=93.8] | Loss=0.02209 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=17.342 | 5428.9 samples/s | 84.8 steps/s
[Step=96150 Epoch=93.9] | Loss=0.02268 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=17.340 | 5382.4 samples/s | 84.1 steps/s
[Step=96200 Epoch=93.9] | Loss=0.02222 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.390 | L2-Norm(final)=17.338 | 5471.6 samples/s | 85.5 steps/s
[Step=96250 Epoch=94.0] | Loss=0.02214 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.390 | L2-Norm(final)=17.336 | 5291.1 samples/s | 82.7 steps/s
[Step=96300 Epoch=94.0] | Loss=0.02177 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=17.335 | 5321.1 samples/s | 83.1 steps/s
[Step=96350 Epoch=94.1] | Loss=0.02158 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.390 | L2-Norm(final)=17.334 | 5316.6 samples/s | 83.1 steps/s
[Step=96400 Epoch=94.1] | Loss=0.02111 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.390 | L2-Norm(final)=17.334 | 5300.8 samples/s | 82.8 steps/s
[Step=96450 Epoch=94.2] | Loss=0.02081 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.390 | L2-Norm(final)=17.334 | 5452.0 samples/s | 85.2 steps/s
[Step=96500 Epoch=94.2] | Loss=0.02060 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.390 | L2-Norm(final)=17.334 | 5376.8 samples/s | 84.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=94.2] | Loss=0.02985 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.390 | L2-Norm(final)=17.336 | 4356.5 samples/s | 68.1 steps/s
[Step=96550 Epoch=94.3] | Loss=0.01862 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.397 | L2-Norm(final)=17.339 | 4318.3 samples/s | 67.5 steps/s
[Step=96600 Epoch=94.3] | Loss=0.01718 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.408 | L2-Norm(final)=17.343 | 4597.8 samples/s | 71.8 steps/s
[Step=96650 Epoch=94.4] | Loss=0.01665 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.418 | L2-Norm(final)=17.347 | 4636.5 samples/s | 72.4 steps/s
[Step=96700 Epoch=94.4] | Loss=0.01591 | Reg=0.00055 | acc=0.9688 | L2-Norm=7.428 | L2-Norm(final)=17.351 | 4650.6 samples/s | 72.7 steps/s
[Step=96750 Epoch=94.5] | Loss=0.01612 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.437 | L2-Norm(final)=17.355 | 4643.9 samples/s | 72.6 steps/s
[Step=96800 Epoch=94.5] | Loss=0.01546 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.445 | L2-Norm(final)=17.359 | 4613.4 samples/s | 72.1 steps/s
[Step=96850 Epoch=94.6] | Loss=0.01536 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.454 | L2-Norm(final)=17.363 | 4650.6 samples/s | 72.7 steps/s
[Step=96900 Epoch=94.6] | Loss=0.01542 | Reg=0.00056 | acc=0.9531 | L2-Norm=7.461 | L2-Norm(final)=17.366 | 4797.8 samples/s | 75.0 steps/s
[Step=96950 Epoch=94.7] | Loss=0.01545 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.469 | L2-Norm(final)=17.369 | 4798.1 samples/s | 75.0 steps/s
[Step=97000 Epoch=94.7] | Loss=0.01532 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.476 | L2-Norm(final)=17.373 | 4786.0 samples/s | 74.8 steps/s
[Step=97050 Epoch=94.8] | Loss=0.01542 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.482 | L2-Norm(final)=17.376 | 4787.1 samples/s | 74.8 steps/s
[Step=97100 Epoch=94.8] | Loss=0.01531 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.489 | L2-Norm(final)=17.379 | 4644.6 samples/s | 72.6 steps/s
[Step=97150 Epoch=94.9] | Loss=0.01513 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.495 | L2-Norm(final)=17.382 | 4822.2 samples/s | 75.3 steps/s
[Step=97200 Epoch=94.9] | Loss=0.01516 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.501 | L2-Norm(final)=17.385 | 4659.0 samples/s | 72.8 steps/s
[Step=97250 Epoch=94.9] | Loss=0.01499 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.507 | L2-Norm(final)=17.388 | 4701.2 samples/s | 73.5 steps/s
[Step=97300 Epoch=95.0] | Loss=0.01489 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=17.391 | 4642.7 samples/s | 72.5 steps/s
[Step=97350 Epoch=95.0] | Loss=0.01481 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.518 | L2-Norm(final)=17.394 | 4649.0 samples/s | 72.6 steps/s
[Step=97400 Epoch=95.1] | Loss=0.01472 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.524 | L2-Norm(final)=17.397 | 4630.1 samples/s | 72.3 steps/s
[Step=97450 Epoch=95.1] | Loss=0.01468 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.529 | L2-Norm(final)=17.400 | 4650.6 samples/s | 72.7 steps/s
[Step=97500 Epoch=95.2] | Loss=0.01455 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=17.403 | 4960.5 samples/s | 77.5 steps/s
[Step=97550 Epoch=95.2] | Loss=0.01447 | Reg=0.00057 | acc=0.9688 | L2-Norm=7.539 | L2-Norm(final)=17.406 | 2074.2 samples/s | 32.4 steps/s
[Step=97600 Epoch=95.3] | Loss=0.01435 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.544 | L2-Norm(final)=17.408 | 4639.5 samples/s | 72.5 steps/s
[Step=97650 Epoch=95.3] | Loss=0.01421 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.549 | L2-Norm(final)=17.411 | 4598.0 samples/s | 71.8 steps/s
[Step=97700 Epoch=95.4] | Loss=0.01410 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.554 | L2-Norm(final)=17.414 | 4626.4 samples/s | 72.3 steps/s
[Step=97750 Epoch=95.4] | Loss=0.01392 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.559 | L2-Norm(final)=17.417 | 4618.3 samples/s | 72.2 steps/s
[Step=97800 Epoch=95.5] | Loss=0.01375 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.563 | L2-Norm(final)=17.419 | 4689.6 samples/s | 73.3 steps/s
[Step=97850 Epoch=95.5] | Loss=0.01359 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.568 | L2-Norm(final)=17.422 | 4702.6 samples/s | 73.5 steps/s
[Step=97900 Epoch=95.6] | Loss=0.01344 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.572 | L2-Norm(final)=17.425 | 4673.3 samples/s | 73.0 steps/s
[Step=97950 Epoch=95.6] | Loss=0.01332 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.577 | L2-Norm(final)=17.428 | 4600.2 samples/s | 71.9 steps/s
[Step=98000 Epoch=95.7] | Loss=0.01325 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.581 | L2-Norm(final)=17.430 | 4642.5 samples/s | 72.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step98000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=96001 Epoch=181.0] | Loss=0.00006 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=14.919 | 4431.9 samples/s | 69.2 steps/s
[Step=96050 Epoch=181.1] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.920 | 4531.0 samples/s | 70.8 steps/s
[Step=96100 Epoch=181.1] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.920 | 5254.1 samples/s | 82.1 steps/s
[Step=96150 Epoch=181.2] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.920 | 5119.1 samples/s | 80.0 steps/s
[Step=96200 Epoch=181.3] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.921 | 4956.8 samples/s | 77.5 steps/s
[Step=96250 Epoch=181.4] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.921 | 5352.3 samples/s | 83.6 steps/s
[Step=96300 Epoch=181.5] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=14.921 | 5227.7 samples/s | 81.7 steps/s
[Step=96350 Epoch=181.6] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=14.921 | 5185.6 samples/s | 81.0 steps/s
[Step=96400 Epoch=181.7] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=14.922 | 4924.0 samples/s | 76.9 steps/s
[Step=96450 Epoch=181.8] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=14.922 | 5006.6 samples/s | 78.2 steps/s
[Step=96500 Epoch=181.9] | Loss=0.00003 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=14.922 | 5076.4 samples/s | 79.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=181.9] | Loss=0.00004 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.387 | L2-Norm(final)=14.926 | 4356.7 samples/s | 68.1 steps/s
[Step=96550 Epoch=182.0] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.380 | L2-Norm(final)=14.927 | 4172.8 samples/s | 65.2 steps/s
[Step=96600 Epoch=182.1] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.372 | L2-Norm(final)=14.927 | 4376.8 samples/s | 68.4 steps/s
[Step=96650 Epoch=182.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.365 | L2-Norm(final)=14.928 | 4368.5 samples/s | 68.3 steps/s
[Step=96700 Epoch=182.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=14.928 | 4407.8 samples/s | 68.9 steps/s
[Step=96750 Epoch=182.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=14.928 | 4436.7 samples/s | 69.3 steps/s
[Step=96800 Epoch=182.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.343 | L2-Norm(final)=14.928 | 4386.7 samples/s | 68.5 steps/s
[Step=96850 Epoch=182.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.336 | L2-Norm(final)=14.929 | 4399.6 samples/s | 68.7 steps/s
[Step=96900 Epoch=182.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.330 | L2-Norm(final)=14.929 | 4419.1 samples/s | 69.0 steps/s
[Step=96950 Epoch=182.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.323 | L2-Norm(final)=14.929 | 4437.7 samples/s | 69.3 steps/s
[Step=97000 Epoch=182.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=14.930 | 4465.6 samples/s | 69.8 steps/s
[Step=97050 Epoch=182.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.311 | L2-Norm(final)=14.930 | 2011.6 samples/s | 31.4 steps/s
[Step=97100 Epoch=183.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=14.930 | 4504.1 samples/s | 70.4 steps/s
[Step=97150 Epoch=183.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.298 | L2-Norm(final)=14.930 | 4352.5 samples/s | 68.0 steps/s
[Step=97200 Epoch=183.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=14.930 | 4404.7 samples/s | 68.8 steps/s
[Step=97250 Epoch=183.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.285 | L2-Norm(final)=14.931 | 4447.3 samples/s | 69.5 steps/s
[Step=97300 Epoch=183.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.279 | L2-Norm(final)=14.931 | 4373.9 samples/s | 68.3 steps/s
[Step=97350 Epoch=183.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.273 | L2-Norm(final)=14.931 | 4387.7 samples/s | 68.6 steps/s
[Step=97400 Epoch=183.6] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=14.931 | 4418.4 samples/s | 69.0 steps/s
[Step=97450 Epoch=183.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=14.931 | 4369.8 samples/s | 68.3 steps/s
[Step=97500 Epoch=183.8] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.254 | L2-Norm(final)=14.932 | 4546.8 samples/s | 71.0 steps/s
[Step=97550 Epoch=183.9] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.248 | L2-Norm(final)=14.932 | 5539.4 samples/s | 86.6 steps/s
[Step=97600 Epoch=184.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.241 | L2-Norm(final)=14.932 | 1894.8 samples/s | 29.6 steps/s
[Step=97650 Epoch=184.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.235 | L2-Norm(final)=14.932 | 4406.2 samples/s | 68.8 steps/s
[Step=97700 Epoch=184.2] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.229 | L2-Norm(final)=14.933 | 4437.8 samples/s | 69.3 steps/s
[Step=97750 Epoch=184.3] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.222 | L2-Norm(final)=14.933 | 4378.3 samples/s | 68.4 steps/s
[Step=97800 Epoch=184.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.216 | L2-Norm(final)=14.933 | 4389.3 samples/s | 68.6 steps/s
[Step=97850 Epoch=184.4] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.209 | L2-Norm(final)=14.933 | 4395.2 samples/s | 68.7 steps/s
[Step=97900 Epoch=184.5] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.203 | L2-Norm(final)=14.933 | 4421.2 samples/s | 69.1 steps/s
[Step=97950 Epoch=184.6] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.196 | L2-Norm(final)=14.934 | 4429.3 samples/s | 69.2 steps/s
[Step=98000 Epoch=184.7] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.190 | L2-Norm(final)=14.934 | 4467.9 samples/s | 69.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05193 | acc=0.9699 | tpr=0.9698 | fpr=0.0297 | 4482.7 samples/s | 17.5 steps/s
Avg test loss: 0.05613, Avg test acc: 0.96799, Avg tpr: 0.96812, Avg fpr: 0.03230, total FA: 252

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.76887 | acc=0.3016 | tpr=0.0123 | fpr=0.0701 | 4453.8 samples/s | 17.4 steps/s
Avg test loss: 4.78602, Avg test acc: 0.29962, Avg tpr: 0.01183, Avg fpr: 0.06743, total FA: 526

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.82183 | acc=0.1602 | tpr=0.3407 | fpr=0.8431 | 4348.7 samples/s | 17.0 steps/s
[Step= 100] | Loss=3.80366 | acc=0.1598 | tpr=0.3241 | fpr=0.8432 | 8446.3 samples/s | 33.0 steps/s
[Step= 150] | Loss=3.80341 | acc=0.1589 | tpr=0.3199 | fpr=0.8441 | 7992.9 samples/s | 31.2 steps/s
[Step= 200] | Loss=3.79716 | acc=0.1586 | tpr=0.3158 | fpr=0.8442 | 8175.4 samples/s | 31.9 steps/s
[Step= 250] | Loss=3.79834 | acc=0.1586 | tpr=0.3153 | fpr=0.8443 | 8599.6 samples/s | 33.6 steps/s
[Step= 300] | Loss=3.79605 | acc=0.1580 | tpr=0.3135 | fpr=0.8448 | 8328.1 samples/s | 32.5 steps/s
[Step= 350] | Loss=3.79519 | acc=0.1574 | tpr=0.3100 | fpr=0.8453 | 8129.1 samples/s | 31.8 steps/s
[Step= 400] | Loss=3.79561 | acc=0.1575 | tpr=0.3135 | fpr=0.8454 | 8224.4 samples/s | 32.1 steps/s
[Step= 450] | Loss=3.79705 | acc=0.1577 | tpr=0.3150 | fpr=0.8452 | 8107.9 samples/s | 31.7 steps/s
[Step= 500] | Loss=3.79828 | acc=0.1579 | tpr=0.3115 | fpr=0.8449 | 8079.5 samples/s | 31.6 steps/s
[Step= 550] | Loss=3.79897 | acc=0.1578 | tpr=0.3132 | fpr=0.8450 | 14985.8 samples/s | 58.5 steps/s
Avg test loss: 3.79963, Avg test acc: 0.15763, Avg tpr: 0.31379, Avg fpr: 0.84521, total FA: 117356

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11180 | acc=0.9819 | tpr=0.9558 | fpr=0.0177 | 4334.7 samples/s | 16.9 steps/s
[Step= 100] | Loss=0.11846 | acc=0.9807 | tpr=0.9638 | fpr=0.0189 | 8470.1 samples/s | 33.1 steps/s
[Step= 150] | Loss=0.12396 | acc=0.9797 | tpr=0.9625 | fpr=0.0199 | 7970.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.12438 | acc=0.9799 | tpr=0.9672 | fpr=0.0198 | 8589.3 samples/s | 33.6 steps/s
[Step= 250] | Loss=0.12314 | acc=0.9803 | tpr=0.9659 | fpr=0.0195 | 8323.3 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.12514 | acc=0.9800 | tpr=0.9665 | fpr=0.0198 | 8075.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.12681 | acc=0.9795 | tpr=0.9649 | fpr=0.0203 | 8013.7 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.12759 | acc=0.9794 | tpr=0.9628 | fpr=0.0203 | 8159.1 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.13022 | acc=0.9791 | tpr=0.9606 | fpr=0.0206 | 8398.0 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.12969 | acc=0.9792 | tpr=0.9599 | fpr=0.0205 | 7962.6 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12894 | acc=0.9793 | tpr=0.9594 | fpr=0.0204 | 14414.6 samples/s | 56.3 steps/s
Avg test loss: 0.12875, Avg test acc: 0.97930, Avg tpr: 0.95959, Avg fpr: 0.02035, total FA: 2825

server round 49/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=98001 Epoch=95.7] | Loss=0.00993 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.513 | 4261.0 samples/s | 66.6 steps/s
[Step=98050 Epoch=95.7] | Loss=0.01716 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.296 | L2-Norm(final)=17.517 | 4782.5 samples/s | 74.7 steps/s
[Step=98100 Epoch=95.8] | Loss=0.01768 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.519 | 5333.4 samples/s | 83.3 steps/s
[Step=98150 Epoch=95.8] | Loss=0.01836 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.522 | 5244.8 samples/s | 82.0 steps/s
[Step=98200 Epoch=95.9] | Loss=0.01785 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.296 | L2-Norm(final)=17.526 | 5331.5 samples/s | 83.3 steps/s
[Step=98250 Epoch=95.9] | Loss=0.01754 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.530 | 5428.6 samples/s | 84.8 steps/s
[Step=98300 Epoch=96.0] | Loss=0.01791 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.534 | 5192.0 samples/s | 81.1 steps/s
[Step=98350 Epoch=96.0] | Loss=0.01789 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.296 | L2-Norm(final)=17.538 | 5330.3 samples/s | 83.3 steps/s
[Step=98400 Epoch=96.1] | Loss=0.01784 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.296 | L2-Norm(final)=17.542 | 5326.8 samples/s | 83.2 steps/s
[Step=98450 Epoch=96.1] | Loss=0.01789 | Reg=0.00053 | acc=0.9844 | L2-Norm=7.296 | L2-Norm(final)=17.546 | 5440.3 samples/s | 85.0 steps/s
[Step=98500 Epoch=96.2] | Loss=0.01795 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=17.550 | 5303.2 samples/s | 82.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step98500.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
Not training fc1
LR=0.00006, len=1
[Step=98001 Epoch=184.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.296 | L2-Norm(final)=14.941 | 3835.7 samples/s | 59.9 steps/s
[Step=98050 Epoch=184.8] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.941 | 4977.9 samples/s | 77.8 steps/s
[Step=98100 Epoch=184.9] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.941 | 4976.4 samples/s | 77.8 steps/s
[Step=98150 Epoch=185.0] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.941 | 4960.8 samples/s | 77.5 steps/s
[Step=98200 Epoch=185.1] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.941 | 4993.7 samples/s | 78.0 steps/s
[Step=98250 Epoch=185.2] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.942 | 5030.9 samples/s | 78.6 steps/s
[Step=98300 Epoch=185.3] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.942 | 5113.5 samples/s | 79.9 steps/s
[Step=98350 Epoch=185.4] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.943 | 5123.4 samples/s | 80.1 steps/s
[Step=98400 Epoch=185.5] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.943 | 5007.8 samples/s | 78.2 steps/s
[Step=98450 Epoch=185.6] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.944 | 4993.8 samples/s | 78.0 steps/s
[Step=98500 Epoch=185.7] | Loss=0.00002 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=14.945 | 5087.4 samples/s | 79.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05064 | acc=0.9663 | tpr=0.9678 | fpr=0.0369 | 4347.9 samples/s | 17.0 steps/s
Avg test loss: 0.05399, Avg test acc: 0.96410, Avg tpr: 0.96608, Avg fpr: 0.04025, total FA: 314

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.88843 | acc=0.3063 | tpr=0.0118 | fpr=0.0540 | 4487.2 samples/s | 17.5 steps/s
Avg test loss: 3.89741, Avg test acc: 0.30387, Avg tpr: 0.01113, Avg fpr: 0.05230, total FA: 408

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.97345 | acc=0.1506 | tpr=0.2080 | fpr=0.8504 | 4392.8 samples/s | 17.2 steps/s
[Step= 100] | Loss=2.96012 | acc=0.1515 | tpr=0.2154 | fpr=0.8497 | 8098.1 samples/s | 31.6 steps/s
[Step= 150] | Loss=2.95955 | acc=0.1512 | tpr=0.2248 | fpr=0.8501 | 8344.6 samples/s | 32.6 steps/s
[Step= 200] | Loss=2.95390 | acc=0.1517 | tpr=0.2230 | fpr=0.8496 | 7938.7 samples/s | 31.0 steps/s
[Step= 250] | Loss=2.95536 | acc=0.1522 | tpr=0.2262 | fpr=0.8491 | 8144.4 samples/s | 31.8 steps/s
[Step= 300] | Loss=2.95338 | acc=0.1519 | tpr=0.2247 | fpr=0.8494 | 8084.9 samples/s | 31.6 steps/s
[Step= 350] | Loss=2.95253 | acc=0.1518 | tpr=0.2167 | fpr=0.8494 | 8448.5 samples/s | 33.0 steps/s
[Step= 400] | Loss=2.95297 | acc=0.1520 | tpr=0.2183 | fpr=0.8492 | 8356.7 samples/s | 32.6 steps/s
[Step= 450] | Loss=2.95428 | acc=0.1522 | tpr=0.2181 | fpr=0.8490 | 8208.9 samples/s | 32.1 steps/s
[Step= 500] | Loss=2.95613 | acc=0.1526 | tpr=0.2167 | fpr=0.8486 | 7937.3 samples/s | 31.0 steps/s
[Step= 550] | Loss=2.95690 | acc=0.1526 | tpr=0.2193 | fpr=0.8486 | 15524.7 samples/s | 60.6 steps/s
Avg test loss: 2.95733, Avg test acc: 0.15246, Avg tpr: 0.22029, Avg fpr: 0.84877, total FA: 117850

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08425 | acc=0.9823 | tpr=0.9558 | fpr=0.0173 | 4408.8 samples/s | 17.2 steps/s
[Step= 100] | Loss=0.08954 | acc=0.9813 | tpr=0.9638 | fpr=0.0183 | 8137.9 samples/s | 31.8 steps/s
[Step= 150] | Loss=0.09354 | acc=0.9807 | tpr=0.9669 | fpr=0.0190 | 8201.1 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.09385 | acc=0.9809 | tpr=0.9705 | fpr=0.0189 | 8304.3 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.09283 | acc=0.9811 | tpr=0.9677 | fpr=0.0186 | 8403.8 samples/s | 32.8 steps/s
[Step= 300] | Loss=0.09425 | acc=0.9809 | tpr=0.9680 | fpr=0.0189 | 8497.6 samples/s | 33.2 steps/s
[Step= 350] | Loss=0.09554 | acc=0.9806 | tpr=0.9668 | fpr=0.0192 | 7928.8 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.09611 | acc=0.9804 | tpr=0.9650 | fpr=0.0193 | 8186.1 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.09817 | acc=0.9801 | tpr=0.9620 | fpr=0.0196 | 8132.1 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.09785 | acc=0.9801 | tpr=0.9604 | fpr=0.0195 | 8029.0 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.09721 | acc=0.9803 | tpr=0.9598 | fpr=0.0194 | 15126.0 samples/s | 59.1 steps/s
Avg test loss: 0.09709, Avg test acc: 0.98027, Avg tpr: 0.95998, Avg fpr: 0.01936, total FA: 2688
