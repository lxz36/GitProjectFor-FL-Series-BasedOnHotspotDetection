#clients of iccad2012: 2
#clients of asml1: 2
select ratio: 1.0
Total num clients: 4
client model path: ['models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0', 'models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1', 'models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0', 'models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Resampled dataset to size (32814, 144, 32)
Using transform option: train
#pos = 17102, #neg = 15712
Allocated dataset with size (24958, 144, 32)
Resampled dataset to size (32737, 144, 32)
Using transform option: train
#pos = 17179, #neg = 15558
loading data into the main memory...
Allocated dataset with size (9150, 144, 32)
Resampled dataset to size (16703, 144, 32)
Using transform option: train
#pos = 8134, #neg = 8569
Allocated dataset with size (9150, 144, 32)
Resampled dataset to size (16626, 144, 32)
Using transform option: train
#pos = 8099, #neg = 8527
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 32)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.39431 | Reg=0.00241 | acc=0.4844 | L2-Norm=15.528 | L2-Norm(final)=2.121 | 1353.6 samples/s | 21.1 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.33230 | Reg=0.00232 | acc=0.5000 | L2-Norm=15.243 | L2-Norm(final)=2.118 | 5044.3 samples/s | 78.8 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.32426 | Reg=0.00228 | acc=0.5625 | L2-Norm=15.109 | L2-Norm(final)=2.122 | 5660.9 samples/s | 88.5 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.32268 | Reg=0.00226 | acc=0.6406 | L2-Norm=15.035 | L2-Norm(final)=2.125 | 5682.4 samples/s | 88.8 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.31767 | Reg=0.00225 | acc=0.7188 | L2-Norm=14.990 | L2-Norm(final)=2.126 | 5561.1 samples/s | 86.9 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.31436 | Reg=0.00224 | acc=0.6562 | L2-Norm=14.965 | L2-Norm(final)=2.131 | 5880.5 samples/s | 91.9 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.31267 | Reg=0.00224 | acc=0.6562 | L2-Norm=14.954 | L2-Norm(final)=2.134 | 5500.0 samples/s | 85.9 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.31003 | Reg=0.00224 | acc=0.6250 | L2-Norm=14.949 | L2-Norm(final)=2.139 | 5811.4 samples/s | 90.8 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.30839 | Reg=0.00223 | acc=0.6562 | L2-Norm=14.949 | L2-Norm(final)=2.144 | 5731.3 samples/s | 89.6 steps/s
[Step= 450 Epoch= 0.9] | Loss=0.30725 | Reg=0.00224 | acc=0.8438 | L2-Norm=14.952 | L2-Norm(final)=2.149 | 5633.2 samples/s | 88.0 steps/s
[Step= 500 Epoch= 1.0] | Loss=0.30499 | Reg=0.00224 | acc=0.6875 | L2-Norm=14.962 | L2-Norm(final)=2.155 | 7908.7 samples/s | 123.6 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.0] | Loss=0.28973 | Reg=0.00227 | acc=0.7344 | L2-Norm=15.078 | L2-Norm(final)=2.219 | 5968.1 samples/s | 93.3 steps/s
[Step= 550 Epoch= 1.1] | Loss=0.25712 | Reg=0.00229 | acc=0.7188 | L2-Norm=15.125 | L2-Norm(final)=2.225 | 4362.3 samples/s | 68.2 steps/s
[Step= 600 Epoch= 1.2] | Loss=0.23057 | Reg=0.00230 | acc=0.7500 | L2-Norm=15.176 | L2-Norm(final)=2.231 | 4606.7 samples/s | 72.0 steps/s
[Step= 650 Epoch= 1.3] | Loss=0.21050 | Reg=0.00231 | acc=0.9219 | L2-Norm=15.213 | L2-Norm(final)=2.234 | 4660.1 samples/s | 72.8 steps/s
[Step= 700 Epoch= 1.4] | Loss=0.19555 | Reg=0.00232 | acc=0.8438 | L2-Norm=15.244 | L2-Norm(final)=2.239 | 4686.9 samples/s | 73.2 steps/s
[Step= 750 Epoch= 1.5] | Loss=0.18469 | Reg=0.00233 | acc=0.8750 | L2-Norm=15.271 | L2-Norm(final)=2.243 | 4613.9 samples/s | 72.1 steps/s
[Step= 800 Epoch= 1.6] | Loss=0.17479 | Reg=0.00234 | acc=0.9531 | L2-Norm=15.295 | L2-Norm(final)=2.246 | 4741.4 samples/s | 74.1 steps/s
[Step= 850 Epoch= 1.7] | Loss=0.16747 | Reg=0.00235 | acc=0.8594 | L2-Norm=15.314 | L2-Norm(final)=2.249 | 4544.3 samples/s | 71.0 steps/s
[Step= 900 Epoch= 1.8] | Loss=0.15992 | Reg=0.00235 | acc=0.9531 | L2-Norm=15.332 | L2-Norm(final)=2.252 | 4709.3 samples/s | 73.6 steps/s
[Step= 950 Epoch= 1.9] | Loss=0.15332 | Reg=0.00236 | acc=0.8906 | L2-Norm=15.349 | L2-Norm(final)=2.256 | 4610.8 samples/s | 72.0 steps/s
[Step=1000 Epoch= 2.0] | Loss=0.14865 | Reg=0.00236 | acc=0.8906 | L2-Norm=15.366 | L2-Norm(final)=2.259 | 5938.1 samples/s | 92.8 steps/s
[Step=1050 Epoch= 2.0] | Loss=0.14305 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.383 | L2-Norm(final)=2.263 | 2499.3 samples/s | 39.1 steps/s
[Step=1100 Epoch= 2.1] | Loss=0.13801 | Reg=0.00237 | acc=0.9688 | L2-Norm=15.400 | L2-Norm(final)=2.266 | 4518.4 samples/s | 70.6 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.13298 | Reg=0.00238 | acc=0.9688 | L2-Norm=15.418 | L2-Norm(final)=2.270 | 4638.4 samples/s | 72.5 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.12845 | Reg=0.00238 | acc=0.9531 | L2-Norm=15.437 | L2-Norm(final)=2.274 | 4613.3 samples/s | 72.1 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.12510 | Reg=0.00239 | acc=0.9531 | L2-Norm=15.455 | L2-Norm(final)=2.278 | 4602.5 samples/s | 71.9 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.12199 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.474 | L2-Norm(final)=2.281 | 4646.2 samples/s | 72.6 steps/s
[Step=1350 Epoch= 2.6] | Loss=0.11909 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=2.284 | 4698.5 samples/s | 73.4 steps/s
[Step=1400 Epoch= 2.7] | Loss=0.11646 | Reg=0.00241 | acc=0.9219 | L2-Norm=15.509 | L2-Norm(final)=2.286 | 4565.7 samples/s | 71.3 steps/s
[Step=1450 Epoch= 2.8] | Loss=0.11356 | Reg=0.00241 | acc=0.9531 | L2-Norm=15.527 | L2-Norm(final)=2.289 | 4682.3 samples/s | 73.2 steps/s
[Step=1500 Epoch= 2.9] | Loss=0.11148 | Reg=0.00242 | acc=0.9375 | L2-Norm=15.544 | L2-Norm(final)=2.292 | 4959.8 samples/s | 77.5 steps/s
[Step=1550 Epoch= 3.0] | Loss=0.10903 | Reg=0.00242 | acc=0.9688 | L2-Norm=15.561 | L2-Norm(final)=2.294 | 2689.9 samples/s | 42.0 steps/s
[Step=1600 Epoch= 3.1] | Loss=0.10616 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.579 | L2-Norm(final)=2.297 | 4660.6 samples/s | 72.8 steps/s
[Step=1650 Epoch= 3.2] | Loss=0.10385 | Reg=0.00243 | acc=0.9219 | L2-Norm=15.597 | L2-Norm(final)=2.300 | 4633.5 samples/s | 72.4 steps/s
[Step=1700 Epoch= 3.3] | Loss=0.10132 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.614 | L2-Norm(final)=2.303 | 4533.0 samples/s | 70.8 steps/s
[Step=1750 Epoch= 3.4] | Loss=0.09929 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.632 | L2-Norm(final)=2.306 | 4645.7 samples/s | 72.6 steps/s
[Step=1800 Epoch= 3.5] | Loss=0.09752 | Reg=0.00245 | acc=0.9531 | L2-Norm=15.648 | L2-Norm(final)=2.309 | 4652.7 samples/s | 72.7 steps/s
[Step=1850 Epoch= 3.6] | Loss=0.09580 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.664 | L2-Norm(final)=2.311 | 4612.1 samples/s | 72.1 steps/s
[Step=1900 Epoch= 3.7] | Loss=0.09429 | Reg=0.00246 | acc=0.9375 | L2-Norm=15.681 | L2-Norm(final)=2.314 | 4713.2 samples/s | 73.6 steps/s
[Step=1950 Epoch= 3.8] | Loss=0.09289 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.696 | L2-Norm(final)=2.316 | 4579.2 samples/s | 71.6 steps/s
[Step=2000 Epoch= 3.9] | Loss=0.09160 | Reg=0.00247 | acc=0.9375 | L2-Norm=15.712 | L2-Norm(final)=2.318 | 4648.4 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step2000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.32755 | Reg=0.00288 | acc=0.5625 | L2-Norm=16.981 | L2-Norm(final)=2.029 | 6096.9 samples/s | 95.3 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.33364 | Reg=0.00272 | acc=0.5781 | L2-Norm=16.497 | L2-Norm(final)=2.020 | 5105.6 samples/s | 79.8 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.32500 | Reg=0.00265 | acc=0.6406 | L2-Norm=16.275 | L2-Norm(final)=2.020 | 5680.3 samples/s | 88.8 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.32007 | Reg=0.00261 | acc=0.6875 | L2-Norm=16.154 | L2-Norm(final)=2.025 | 5709.7 samples/s | 89.2 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.31649 | Reg=0.00259 | acc=0.6875 | L2-Norm=16.077 | L2-Norm(final)=2.030 | 5738.1 samples/s | 89.7 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.31257 | Reg=0.00257 | acc=0.6406 | L2-Norm=16.025 | L2-Norm(final)=2.039 | 5620.8 samples/s | 87.8 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.30950 | Reg=0.00256 | acc=0.6406 | L2-Norm=15.991 | L2-Norm(final)=2.049 | 5905.8 samples/s | 92.3 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.30742 | Reg=0.00255 | acc=0.6875 | L2-Norm=15.968 | L2-Norm(final)=2.060 | 5474.1 samples/s | 85.5 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.30609 | Reg=0.00255 | acc=0.7500 | L2-Norm=15.956 | L2-Norm(final)=2.070 | 5630.4 samples/s | 88.0 steps/s
[Step= 450 Epoch= 0.9] | Loss=0.30386 | Reg=0.00254 | acc=0.6719 | L2-Norm=15.951 | L2-Norm(final)=2.080 | 5737.2 samples/s | 89.6 steps/s
[Step= 500 Epoch= 1.0] | Loss=0.30146 | Reg=0.00254 | acc=0.7031 | L2-Norm=15.951 | L2-Norm(final)=2.091 | 7961.6 samples/s | 124.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.0] | Loss=0.32600 | Reg=0.00255 | acc=0.6250 | L2-Norm=15.958 | L2-Norm(final)=2.204 | 6011.5 samples/s | 93.9 steps/s
[Step= 550 Epoch= 1.1] | Loss=0.27062 | Reg=0.00255 | acc=0.7500 | L2-Norm=15.976 | L2-Norm(final)=2.202 | 4391.6 samples/s | 68.6 steps/s
[Step= 600 Epoch= 1.2] | Loss=0.23885 | Reg=0.00257 | acc=0.8750 | L2-Norm=16.017 | L2-Norm(final)=2.214 | 4636.9 samples/s | 72.5 steps/s
[Step= 650 Epoch= 1.3] | Loss=0.22030 | Reg=0.00257 | acc=0.8750 | L2-Norm=16.046 | L2-Norm(final)=2.222 | 4621.9 samples/s | 72.2 steps/s
[Step= 700 Epoch= 1.4] | Loss=0.20571 | Reg=0.00258 | acc=0.8594 | L2-Norm=16.070 | L2-Norm(final)=2.228 | 4720.9 samples/s | 73.8 steps/s
[Step= 750 Epoch= 1.5] | Loss=0.19330 | Reg=0.00259 | acc=0.8906 | L2-Norm=16.091 | L2-Norm(final)=2.236 | 4578.6 samples/s | 71.5 steps/s
[Step= 800 Epoch= 1.6] | Loss=0.18288 | Reg=0.00260 | acc=0.9062 | L2-Norm=16.110 | L2-Norm(final)=2.243 | 4640.2 samples/s | 72.5 steps/s
[Step= 850 Epoch= 1.7] | Loss=0.17538 | Reg=0.00260 | acc=0.9062 | L2-Norm=16.127 | L2-Norm(final)=2.248 | 4561.3 samples/s | 71.3 steps/s
[Step= 900 Epoch= 1.8] | Loss=0.16728 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.142 | L2-Norm(final)=2.253 | 4637.4 samples/s | 72.5 steps/s
[Step= 950 Epoch= 1.9] | Loss=0.16075 | Reg=0.00261 | acc=0.8125 | L2-Norm=16.155 | L2-Norm(final)=2.258 | 4633.0 samples/s | 72.4 steps/s
[Step=1000 Epoch= 2.0] | Loss=0.15538 | Reg=0.00261 | acc=0.9062 | L2-Norm=16.169 | L2-Norm(final)=2.262 | 6069.9 samples/s | 94.8 steps/s
[Step=1050 Epoch= 2.1] | Loss=0.14873 | Reg=0.00262 | acc=0.9531 | L2-Norm=16.183 | L2-Norm(final)=2.267 | 2443.6 samples/s | 38.2 steps/s
[Step=1100 Epoch= 2.2] | Loss=0.14354 | Reg=0.00262 | acc=0.9531 | L2-Norm=16.199 | L2-Norm(final)=2.271 | 4259.3 samples/s | 66.6 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.13824 | Reg=0.00263 | acc=0.9531 | L2-Norm=16.216 | L2-Norm(final)=2.276 | 4510.8 samples/s | 70.5 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.13348 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.233 | L2-Norm(final)=2.281 | 4723.9 samples/s | 73.8 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.12922 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.250 | L2-Norm(final)=2.286 | 4444.0 samples/s | 69.4 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.12618 | Reg=0.00265 | acc=0.9531 | L2-Norm=16.265 | L2-Norm(final)=2.290 | 4593.9 samples/s | 71.8 steps/s
[Step=1350 Epoch= 2.6] | Loss=0.12335 | Reg=0.00265 | acc=0.9375 | L2-Norm=16.281 | L2-Norm(final)=2.294 | 4593.5 samples/s | 71.8 steps/s
[Step=1400 Epoch= 2.7] | Loss=0.12023 | Reg=0.00266 | acc=0.9375 | L2-Norm=16.297 | L2-Norm(final)=2.297 | 4638.7 samples/s | 72.5 steps/s
[Step=1450 Epoch= 2.8] | Loss=0.11745 | Reg=0.00266 | acc=0.9531 | L2-Norm=16.313 | L2-Norm(final)=2.301 | 4652.8 samples/s | 72.7 steps/s
[Step=1500 Epoch= 2.9] | Loss=0.11524 | Reg=0.00267 | acc=0.9219 | L2-Norm=16.328 | L2-Norm(final)=2.304 | 5096.1 samples/s | 79.6 steps/s
[Step=1550 Epoch= 3.0] | Loss=0.11282 | Reg=0.00267 | acc=0.9531 | L2-Norm=16.344 | L2-Norm(final)=2.307 | 2652.2 samples/s | 41.4 steps/s
[Step=1600 Epoch= 3.1] | Loss=0.11011 | Reg=0.00268 | acc=0.9531 | L2-Norm=16.360 | L2-Norm(final)=2.310 | 4635.2 samples/s | 72.4 steps/s
[Step=1650 Epoch= 3.2] | Loss=0.10758 | Reg=0.00268 | acc=0.9688 | L2-Norm=16.376 | L2-Norm(final)=2.314 | 4555.6 samples/s | 71.2 steps/s
[Step=1700 Epoch= 3.3] | Loss=0.10505 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.392 | L2-Norm(final)=2.317 | 4671.6 samples/s | 73.0 steps/s
[Step=1750 Epoch= 3.4] | Loss=0.10274 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.407 | L2-Norm(final)=2.320 | 4607.1 samples/s | 72.0 steps/s
[Step=1800 Epoch= 3.5] | Loss=0.10100 | Reg=0.00270 | acc=0.9219 | L2-Norm=16.423 | L2-Norm(final)=2.324 | 4635.5 samples/s | 72.4 steps/s
[Step=1850 Epoch= 3.6] | Loss=0.09930 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.437 | L2-Norm(final)=2.326 | 4673.3 samples/s | 73.0 steps/s
[Step=1900 Epoch= 3.7] | Loss=0.09795 | Reg=0.00271 | acc=0.9531 | L2-Norm=16.452 | L2-Norm(final)=2.329 | 4599.6 samples/s | 71.9 steps/s
[Step=1950 Epoch= 3.8] | Loss=0.09640 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.465 | L2-Norm(final)=2.331 | 4644.4 samples/s | 72.6 steps/s
[Step=2000 Epoch= 3.9] | Loss=0.09486 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=2.334 | 4618.8 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step2000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.37036 | Reg=0.00326 | acc=0.5000 | L2-Norm=18.069 | L2-Norm(final)=2.090 | 7236.7 samples/s | 113.1 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.25129 | Reg=0.00312 | acc=0.9062 | L2-Norm=17.677 | L2-Norm(final)=2.098 | 4252.3 samples/s | 66.4 steps/s
[Step= 100 Epoch= 0.4] | Loss=0.20541 | Reg=0.00309 | acc=0.9062 | L2-Norm=17.568 | L2-Norm(final)=2.142 | 5298.1 samples/s | 82.8 steps/s
[Step= 150 Epoch= 0.6] | Loss=0.18956 | Reg=0.00307 | acc=0.9375 | L2-Norm=17.525 | L2-Norm(final)=2.179 | 5364.4 samples/s | 83.8 steps/s
[Step= 200 Epoch= 0.8] | Loss=0.17387 | Reg=0.00306 | acc=0.9219 | L2-Norm=17.504 | L2-Norm(final)=2.206 | 5380.6 samples/s | 84.1 steps/s
[Step= 250 Epoch= 1.0] | Loss=0.16332 | Reg=0.00306 | acc=0.9531 | L2-Norm=17.492 | L2-Norm(final)=2.230 | 7551.5 samples/s | 118.0 steps/s
[Step= 300 Epoch= 1.1] | Loss=0.15508 | Reg=0.00306 | acc=0.9531 | L2-Norm=17.485 | L2-Norm(final)=2.252 | 2567.1 samples/s | 40.1 steps/s
[Step= 350 Epoch= 1.3] | Loss=0.14873 | Reg=0.00306 | acc=0.9375 | L2-Norm=17.483 | L2-Norm(final)=2.272 | 5413.2 samples/s | 84.6 steps/s
[Step= 400 Epoch= 1.5] | Loss=0.14242 | Reg=0.00306 | acc=0.9531 | L2-Norm=17.485 | L2-Norm(final)=2.292 | 5365.4 samples/s | 83.8 steps/s
[Step= 450 Epoch= 1.7] | Loss=0.13746 | Reg=0.00306 | acc=0.9844 | L2-Norm=17.491 | L2-Norm(final)=2.311 | 5259.3 samples/s | 82.2 steps/s
[Step= 500 Epoch= 1.9] | Loss=0.13412 | Reg=0.00306 | acc=0.9531 | L2-Norm=17.503 | L2-Norm(final)=2.330 | 6107.4 samples/s | 95.4 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.9] | Loss=0.13500 | Reg=0.00311 | acc=0.9531 | L2-Norm=17.646 | L2-Norm(final)=2.504 | 6474.5 samples/s | 101.2 steps/s
[Step= 550 Epoch= 2.1] | Loss=0.12637 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.599 | L2-Norm(final)=2.483 | 3981.3 samples/s | 62.2 steps/s
[Step= 600 Epoch= 2.3] | Loss=0.08381 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.599 | L2-Norm(final)=2.495 | 4294.4 samples/s | 67.1 steps/s
[Step= 650 Epoch= 2.5] | Loss=0.06475 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.599 | L2-Norm(final)=2.510 | 4420.8 samples/s | 69.1 steps/s
[Step= 700 Epoch= 2.7] | Loss=0.05159 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.600 | L2-Norm(final)=2.523 | 4308.9 samples/s | 67.3 steps/s
[Step= 750 Epoch= 2.9] | Loss=0.04295 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.597 | L2-Norm(final)=2.535 | 5916.4 samples/s | 92.4 steps/s
[Step= 800 Epoch= 3.1] | Loss=0.03677 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.592 | L2-Norm(final)=2.545 | 2343.5 samples/s | 36.6 steps/s
[Step= 850 Epoch= 3.3] | Loss=0.03182 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.584 | L2-Norm(final)=2.554 | 4411.4 samples/s | 68.9 steps/s
[Step= 900 Epoch= 3.4] | Loss=0.02831 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.574 | L2-Norm(final)=2.562 | 4367.9 samples/s | 68.2 steps/s
[Step= 950 Epoch= 3.6] | Loss=0.02554 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.562 | L2-Norm(final)=2.568 | 4430.4 samples/s | 69.2 steps/s
[Step=1000 Epoch= 3.8] | Loss=0.02339 | Reg=0.00308 | acc=0.9844 | L2-Norm=17.550 | L2-Norm(final)=2.575 | 4967.3 samples/s | 77.6 steps/s
[Step=1050 Epoch= 4.0] | Loss=0.02143 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.537 | L2-Norm(final)=2.580 | 2518.5 samples/s | 39.4 steps/s
[Step=1100 Epoch= 4.2] | Loss=0.01971 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.523 | L2-Norm(final)=2.585 | 4461.1 samples/s | 69.7 steps/s
[Step=1150 Epoch= 4.4] | Loss=0.01822 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.508 | L2-Norm(final)=2.590 | 4434.2 samples/s | 69.3 steps/s
[Step=1200 Epoch= 4.6] | Loss=0.01694 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.492 | L2-Norm(final)=2.594 | 4352.0 samples/s | 68.0 steps/s
[Step=1250 Epoch= 4.8] | Loss=0.01583 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.474 | L2-Norm(final)=2.598 | 4371.5 samples/s | 68.3 steps/s
[Step=1300 Epoch= 5.0] | Loss=0.01485 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.456 | L2-Norm(final)=2.601 | 2702.6 samples/s | 42.2 steps/s
[Step=1350 Epoch= 5.2] | Loss=0.01399 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.436 | L2-Norm(final)=2.604 | 4423.9 samples/s | 69.1 steps/s
[Step=1400 Epoch= 5.4] | Loss=0.01321 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.416 | L2-Norm(final)=2.607 | 4412.2 samples/s | 68.9 steps/s
[Step=1450 Epoch= 5.6] | Loss=0.01252 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.395 | L2-Norm(final)=2.610 | 4405.6 samples/s | 68.8 steps/s
[Step=1500 Epoch= 5.7] | Loss=0.01190 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.374 | L2-Norm(final)=2.613 | 4378.5 samples/s | 68.4 steps/s
[Step=1550 Epoch= 5.9] | Loss=0.01134 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.351 | L2-Norm(final)=2.615 | 2728.4 samples/s | 42.6 steps/s
[Step=1600 Epoch= 6.1] | Loss=0.01082 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.329 | L2-Norm(final)=2.617 | 4368.9 samples/s | 68.3 steps/s
[Step=1650 Epoch= 6.3] | Loss=0.01035 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.306 | L2-Norm(final)=2.619 | 4289.2 samples/s | 67.0 steps/s
[Step=1700 Epoch= 6.5] | Loss=0.00992 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.283 | L2-Norm(final)=2.621 | 4284.7 samples/s | 66.9 steps/s
[Step=1750 Epoch= 6.7] | Loss=0.00953 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.259 | L2-Norm(final)=2.623 | 4346.7 samples/s | 67.9 steps/s
[Step=1800 Epoch= 6.9] | Loss=0.00916 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.235 | L2-Norm(final)=2.625 | 6495.8 samples/s | 101.5 steps/s
[Step=1850 Epoch= 7.1] | Loss=0.00883 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.211 | L2-Norm(final)=2.627 | 2281.7 samples/s | 35.7 steps/s
[Step=1900 Epoch= 7.3] | Loss=0.00851 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.187 | L2-Norm(final)=2.629 | 4255.2 samples/s | 66.5 steps/s
[Step=1950 Epoch= 7.5] | Loss=0.00822 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.162 | L2-Norm(final)=2.631 | 4464.8 samples/s | 69.8 steps/s
[Step=2000 Epoch= 7.7] | Loss=0.00795 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.137 | L2-Norm(final)=2.633 | 4334.2 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step2000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.42337 | Reg=0.00358 | acc=0.4375 | L2-Norm=18.909 | L2-Norm(final)=1.893 | 6679.2 samples/s | 104.4 steps/s
[Step=  50 Epoch= 0.2] | Loss=0.26306 | Reg=0.00341 | acc=0.9062 | L2-Norm=18.457 | L2-Norm(final)=1.896 | 4442.2 samples/s | 69.4 steps/s
[Step= 100 Epoch= 0.4] | Loss=0.21507 | Reg=0.00336 | acc=0.8750 | L2-Norm=18.323 | L2-Norm(final)=1.939 | 5279.5 samples/s | 82.5 steps/s
[Step= 150 Epoch= 0.6] | Loss=0.19448 | Reg=0.00334 | acc=0.8438 | L2-Norm=18.269 | L2-Norm(final)=1.978 | 5412.0 samples/s | 84.6 steps/s
[Step= 200 Epoch= 0.8] | Loss=0.17743 | Reg=0.00333 | acc=0.9219 | L2-Norm=18.235 | L2-Norm(final)=2.007 | 5296.4 samples/s | 82.8 steps/s
[Step= 250 Epoch= 1.0] | Loss=0.16700 | Reg=0.00332 | acc=0.9531 | L2-Norm=18.211 | L2-Norm(final)=2.034 | 7747.0 samples/s | 121.0 steps/s
[Step= 300 Epoch= 1.2] | Loss=0.15692 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.191 | L2-Norm(final)=2.059 | 2577.9 samples/s | 40.3 steps/s
[Step= 350 Epoch= 1.3] | Loss=0.15134 | Reg=0.00330 | acc=0.8906 | L2-Norm=18.176 | L2-Norm(final)=2.082 | 5210.0 samples/s | 81.4 steps/s
[Step= 400 Epoch= 1.5] | Loss=0.14567 | Reg=0.00330 | acc=0.9062 | L2-Norm=18.168 | L2-Norm(final)=2.104 | 5575.0 samples/s | 87.1 steps/s
[Step= 450 Epoch= 1.7] | Loss=0.14115 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.167 | L2-Norm(final)=2.123 | 5129.6 samples/s | 80.2 steps/s
[Step= 500 Epoch= 1.9] | Loss=0.13724 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.167 | L2-Norm(final)=2.142 | 6453.4 samples/s | 100.8 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 1.9] | Loss=0.06524 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.185 | L2-Norm(final)=2.317 | 6480.4 samples/s | 101.3 steps/s
[Step= 550 Epoch= 2.1] | Loss=0.10498 | Reg=0.00329 | acc=0.9688 | L2-Norm=18.145 | L2-Norm(final)=2.309 | 3902.1 samples/s | 61.0 steps/s
[Step= 600 Epoch= 2.3] | Loss=0.07224 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.147 | L2-Norm(final)=2.321 | 4372.8 samples/s | 68.3 steps/s
[Step= 650 Epoch= 2.5] | Loss=0.05424 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.141 | L2-Norm(final)=2.334 | 4411.0 samples/s | 68.9 steps/s
[Step= 700 Epoch= 2.7] | Loss=0.04367 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.132 | L2-Norm(final)=2.345 | 4381.5 samples/s | 68.5 steps/s
[Step= 750 Epoch= 2.9] | Loss=0.03674 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.124 | L2-Norm(final)=2.355 | 5968.5 samples/s | 93.3 steps/s
[Step= 800 Epoch= 3.1] | Loss=0.03106 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.114 | L2-Norm(final)=2.363 | 2323.6 samples/s | 36.3 steps/s
[Step= 850 Epoch= 3.3] | Loss=0.02682 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.100 | L2-Norm(final)=2.370 | 4396.6 samples/s | 68.7 steps/s
[Step= 900 Epoch= 3.5] | Loss=0.02376 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.083 | L2-Norm(final)=2.375 | 4325.8 samples/s | 67.6 steps/s
[Step= 950 Epoch= 3.7] | Loss=0.02131 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.063 | L2-Norm(final)=2.381 | 4358.2 samples/s | 68.1 steps/s
[Step=1000 Epoch= 3.8] | Loss=0.01938 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.043 | L2-Norm(final)=2.386 | 5144.7 samples/s | 80.4 steps/s
[Step=1050 Epoch= 4.0] | Loss=0.01775 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.024 | L2-Norm(final)=2.390 | 2485.3 samples/s | 38.8 steps/s
[Step=1100 Epoch= 4.2] | Loss=0.01631 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.004 | L2-Norm(final)=2.394 | 4430.1 samples/s | 69.2 steps/s
[Step=1150 Epoch= 4.4] | Loss=0.01508 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.982 | L2-Norm(final)=2.398 | 4384.3 samples/s | 68.5 steps/s
[Step=1200 Epoch= 4.6] | Loss=0.01401 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.959 | L2-Norm(final)=2.401 | 4349.9 samples/s | 68.0 steps/s
[Step=1250 Epoch= 4.8] | Loss=0.01308 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=2.404 | 4516.3 samples/s | 70.6 steps/s
[Step=1300 Epoch= 5.0] | Loss=0.01227 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.909 | L2-Norm(final)=2.407 | 2663.3 samples/s | 41.6 steps/s
[Step=1350 Epoch= 5.2] | Loss=0.01155 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.883 | L2-Norm(final)=2.409 | 4387.6 samples/s | 68.6 steps/s
[Step=1400 Epoch= 5.4] | Loss=0.01091 | Reg=0.00319 | acc=1.0000 | L2-Norm=17.855 | L2-Norm(final)=2.411 | 4391.3 samples/s | 68.6 steps/s
[Step=1450 Epoch= 5.6] | Loss=0.01034 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.828 | L2-Norm(final)=2.413 | 4432.5 samples/s | 69.3 steps/s
[Step=1500 Epoch= 5.8] | Loss=0.00983 | Reg=0.00317 | acc=1.0000 | L2-Norm=17.800 | L2-Norm(final)=2.415 | 4355.8 samples/s | 68.1 steps/s
[Step=1550 Epoch= 6.0] | Loss=0.00936 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.771 | L2-Norm(final)=2.417 | 2698.9 samples/s | 42.2 steps/s
[Step=1600 Epoch= 6.2] | Loss=0.00894 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.742 | L2-Norm(final)=2.419 | 4440.4 samples/s | 69.4 steps/s
[Step=1650 Epoch= 6.4] | Loss=0.00855 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.713 | L2-Norm(final)=2.420 | 4395.0 samples/s | 68.7 steps/s
[Step=1700 Epoch= 6.5] | Loss=0.00820 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.684 | L2-Norm(final)=2.422 | 4357.3 samples/s | 68.1 steps/s
[Step=1750 Epoch= 6.7] | Loss=0.00787 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.654 | L2-Norm(final)=2.423 | 4446.2 samples/s | 69.5 steps/s
[Step=1800 Epoch= 6.9] | Loss=0.00757 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=2.424 | 7057.9 samples/s | 110.3 steps/s
[Step=1850 Epoch= 7.1] | Loss=0.00729 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.594 | L2-Norm(final)=2.425 | 2188.8 samples/s | 34.2 steps/s
[Step=1900 Epoch= 7.3] | Loss=0.00703 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.564 | L2-Norm(final)=2.427 | 4354.8 samples/s | 68.0 steps/s
[Step=1950 Epoch= 7.5] | Loss=0.00679 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.534 | L2-Norm(final)=2.428 | 4460.9 samples/s | 69.7 steps/s
[Step=2000 Epoch= 7.7] | Loss=0.00656 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.504 | L2-Norm(final)=2.429 | 4379.7 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08796 | acc=0.9349 | tpr=0.9295 | fpr=0.0533 | 5035.3 samples/s | 19.7 steps/s
Avg test loss: 0.08993, Avg test acc: 0.93469, Avg tpr: 0.92977, Avg fpr: 0.05448, total FA: 425

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08058 | acc=0.9389 | tpr=0.9500 | fpr=0.0852 | 5454.3 samples/s | 21.3 steps/s
Avg test loss: 0.08208, Avg test acc: 0.93942, Avg tpr: 0.95063, Avg fpr: 0.08525, total FA: 665

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.53178 | acc=0.3148 | tpr=0.0091 | fpr=0.0213 | 5048.1 samples/s | 19.7 steps/s
Avg test loss: 3.54694, Avg test acc: 0.31212, Avg tpr: 0.00892, Avg fpr: 0.02102, total FA: 164

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=3.82619 | acc=0.3137 | tpr=0.0128 | fpr=0.0330 | 5400.6 samples/s | 21.1 steps/s
Avg test loss: 3.81785, Avg test acc: 0.31257, Avg tpr: 0.01411, Avg fpr: 0.03102, total FA: 242

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.13092 | acc=0.1843 | tpr=0.6991 | fpr=0.8250 | 5365.7 samples/s | 21.0 steps/s
[Step= 100] | Loss=2.12248 | acc=0.1850 | tpr=0.6716 | fpr=0.8241 | 7377.8 samples/s | 28.8 steps/s
[Step= 150] | Loss=2.11892 | acc=0.1871 | tpr=0.6816 | fpr=0.8220 | 7571.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=2.11700 | acc=0.1866 | tpr=0.6667 | fpr=0.8222 | 7864.9 samples/s | 30.7 steps/s
[Step= 250] | Loss=2.11926 | acc=0.1860 | tpr=0.6620 | fpr=0.8227 | 8122.3 samples/s | 31.7 steps/s
[Step= 300] | Loss=2.11793 | acc=0.1856 | tpr=0.6596 | fpr=0.8231 | 8295.9 samples/s | 32.4 steps/s
[Step= 350] | Loss=2.11231 | acc=0.1864 | tpr=0.6600 | fpr=0.8222 | 7746.9 samples/s | 30.3 steps/s
[Step= 400] | Loss=2.11134 | acc=0.1867 | tpr=0.6603 | fpr=0.8219 | 8470.0 samples/s | 33.1 steps/s
[Step= 450] | Loss=2.11153 | acc=0.1865 | tpr=0.6621 | fpr=0.8221 | 8181.7 samples/s | 32.0 steps/s
[Step= 500] | Loss=2.11258 | acc=0.1862 | tpr=0.6665 | fpr=0.8225 | 8185.5 samples/s | 32.0 steps/s
[Step= 550] | Loss=2.11180 | acc=0.1864 | tpr=0.6709 | fpr=0.8224 | 13986.5 samples/s | 54.6 steps/s
Avg test loss: 2.11258, Avg test acc: 0.18638, Avg tpr: 0.67076, Avg fpr: 0.82242, total FA: 114192

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=2.49671 | acc=0.1293 | tpr=0.8363 | fpr=0.8834 | 5043.7 samples/s | 19.7 steps/s
[Step= 100] | Loss=2.50988 | acc=0.1273 | tpr=0.8209 | fpr=0.8856 | 7600.7 samples/s | 29.7 steps/s
[Step= 150] | Loss=2.51484 | acc=0.1269 | tpr=0.8156 | fpr=0.8858 | 7807.1 samples/s | 30.5 steps/s
[Step= 200] | Loss=2.50891 | acc=0.1270 | tpr=0.8120 | fpr=0.8855 | 8325.2 samples/s | 32.5 steps/s
[Step= 250] | Loss=2.51172 | acc=0.1267 | tpr=0.8157 | fpr=0.8859 | 8170.5 samples/s | 31.9 steps/s
[Step= 300] | Loss=2.51186 | acc=0.1265 | tpr=0.8182 | fpr=0.8861 | 8299.9 samples/s | 32.4 steps/s
[Step= 350] | Loss=2.50935 | acc=0.1263 | tpr=0.8147 | fpr=0.8862 | 8105.4 samples/s | 31.7 steps/s
[Step= 400] | Loss=2.50819 | acc=0.1260 | tpr=0.8096 | fpr=0.8864 | 8198.2 samples/s | 32.0 steps/s
[Step= 450] | Loss=2.50936 | acc=0.1255 | tpr=0.8096 | fpr=0.8869 | 8320.0 samples/s | 32.5 steps/s
[Step= 500] | Loss=2.51104 | acc=0.1250 | tpr=0.8101 | fpr=0.8874 | 8127.1 samples/s | 31.7 steps/s
[Step= 550] | Loss=2.50893 | acc=0.1252 | tpr=0.8082 | fpr=0.8872 | 14470.3 samples/s | 56.5 steps/s
Avg test loss: 2.50970, Avg test acc: 0.12515, Avg tpr: 0.80864, Avg fpr: 0.88728, total FA: 123197

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.06464 | acc=0.9833 | tpr=0.8761 | fpr=0.0148 | 5314.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.06330 | acc=0.9835 | tpr=0.9019 | fpr=0.0150 | 7599.7 samples/s | 29.7 steps/s
[Step= 150] | Loss=0.06521 | acc=0.9824 | tpr=0.9063 | fpr=0.0162 | 7469.5 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.06626 | acc=0.9817 | tpr=0.9060 | fpr=0.0169 | 7869.6 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.06603 | acc=0.9820 | tpr=0.9066 | fpr=0.0167 | 8387.4 samples/s | 32.8 steps/s
[Step= 300] | Loss=0.06703 | acc=0.9814 | tpr=0.9018 | fpr=0.0171 | 8187.2 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.06772 | acc=0.9811 | tpr=0.9004 | fpr=0.0174 | 8254.8 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.06860 | acc=0.9808 | tpr=0.8944 | fpr=0.0176 | 8337.3 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.07044 | acc=0.9803 | tpr=0.8909 | fpr=0.0180 | 8123.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.06984 | acc=0.9804 | tpr=0.8934 | fpr=0.0180 | 8120.5 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.06948 | acc=0.9806 | tpr=0.8938 | fpr=0.0179 | 14898.3 samples/s | 58.2 steps/s
Avg test loss: 0.06948, Avg test acc: 0.98053, Avg tpr: 0.89303, Avg fpr: 0.01788, total FA: 2482

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.07827 | acc=0.9787 | tpr=0.9159 | fpr=0.0202 | 5396.8 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.08119 | acc=0.9782 | tpr=0.9168 | fpr=0.0207 | 7483.5 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.08491 | acc=0.9770 | tpr=0.9207 | fpr=0.0220 | 7415.2 samples/s | 29.0 steps/s
[Step= 200] | Loss=0.08581 | acc=0.9771 | tpr=0.9322 | fpr=0.0220 | 8002.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.08595 | acc=0.9773 | tpr=0.9310 | fpr=0.0218 | 8274.0 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.08670 | acc=0.9771 | tpr=0.9280 | fpr=0.0220 | 8012.3 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.08770 | acc=0.9771 | tpr=0.9280 | fpr=0.0221 | 8116.4 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.08879 | acc=0.9767 | tpr=0.9240 | fpr=0.0223 | 8146.5 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.09073 | acc=0.9762 | tpr=0.9192 | fpr=0.0227 | 8326.6 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.09025 | acc=0.9764 | tpr=0.9220 | fpr=0.0227 | 7939.8 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.08989 | acc=0.9765 | tpr=0.9212 | fpr=0.0225 | 14559.1 samples/s | 56.9 steps/s
Avg test loss: 0.08990, Avg test acc: 0.97647, Avg tpr: 0.92076, Avg fpr: 0.02252, total FA: 3127

server round 1/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 3.9] | Loss=0.12525 | Reg=0.00236 | acc=0.8750 | L2-Norm=15.348 | L2-Norm(final)=2.369 | 6417.5 samples/s | 100.3 steps/s
[Step=2050 Epoch= 4.0] | Loss=0.13630 | Reg=0.00236 | acc=0.9375 | L2-Norm=15.373 | L2-Norm(final)=2.383 | 4799.2 samples/s | 75.0 steps/s
[Step=2100 Epoch= 4.1] | Loss=0.13089 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.408 | L2-Norm(final)=2.402 | 5029.4 samples/s | 78.6 steps/s
[Step=2150 Epoch= 4.2] | Loss=0.12931 | Reg=0.00238 | acc=0.9688 | L2-Norm=15.439 | L2-Norm(final)=2.422 | 5208.7 samples/s | 81.4 steps/s
[Step=2200 Epoch= 4.3] | Loss=0.12611 | Reg=0.00239 | acc=0.9219 | L2-Norm=15.468 | L2-Norm(final)=2.440 | 5301.7 samples/s | 82.8 steps/s
[Step=2250 Epoch= 4.4] | Loss=0.12345 | Reg=0.00240 | acc=0.9062 | L2-Norm=15.502 | L2-Norm(final)=2.458 | 5249.9 samples/s | 82.0 steps/s
[Step=2300 Epoch= 4.5] | Loss=0.12141 | Reg=0.00241 | acc=0.8750 | L2-Norm=15.531 | L2-Norm(final)=2.475 | 5101.0 samples/s | 79.7 steps/s
[Step=2350 Epoch= 4.6] | Loss=0.12043 | Reg=0.00242 | acc=0.9219 | L2-Norm=15.560 | L2-Norm(final)=2.489 | 5275.8 samples/s | 82.4 steps/s
[Step=2400 Epoch= 4.7] | Loss=0.11868 | Reg=0.00243 | acc=0.8750 | L2-Norm=15.587 | L2-Norm(final)=2.503 | 5214.7 samples/s | 81.5 steps/s
[Step=2450 Epoch= 4.8] | Loss=0.11832 | Reg=0.00244 | acc=0.9219 | L2-Norm=15.615 | L2-Norm(final)=2.517 | 5306.6 samples/s | 82.9 steps/s
[Step=2500 Epoch= 4.9] | Loss=0.11790 | Reg=0.00245 | acc=0.9375 | L2-Norm=15.642 | L2-Norm(final)=2.530 | 6690.6 samples/s | 104.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.9] | Loss=0.20557 | Reg=0.00253 | acc=0.8906 | L2-Norm=15.907 | L2-Norm(final)=2.657 | 7324.2 samples/s | 114.4 steps/s
[Step=2550 Epoch= 5.0] | Loss=0.11878 | Reg=0.00254 | acc=0.8906 | L2-Norm=15.933 | L2-Norm(final)=2.655 | 3868.2 samples/s | 60.4 steps/s
[Step=2600 Epoch= 5.1] | Loss=0.11402 | Reg=0.00255 | acc=0.9219 | L2-Norm=15.961 | L2-Norm(final)=2.650 | 4627.1 samples/s | 72.3 steps/s
[Step=2650 Epoch= 5.2] | Loss=0.10823 | Reg=0.00255 | acc=0.9531 | L2-Norm=15.984 | L2-Norm(final)=2.648 | 4616.1 samples/s | 72.1 steps/s
[Step=2700 Epoch= 5.3] | Loss=0.10371 | Reg=0.00256 | acc=0.8906 | L2-Norm=16.005 | L2-Norm(final)=2.647 | 4659.2 samples/s | 72.8 steps/s
[Step=2750 Epoch= 5.4] | Loss=0.09913 | Reg=0.00257 | acc=0.9375 | L2-Norm=16.024 | L2-Norm(final)=2.645 | 4600.8 samples/s | 71.9 steps/s
[Step=2800 Epoch= 5.5] | Loss=0.09673 | Reg=0.00257 | acc=0.9688 | L2-Norm=16.042 | L2-Norm(final)=2.645 | 4622.4 samples/s | 72.2 steps/s
[Step=2850 Epoch= 5.6] | Loss=0.09440 | Reg=0.00258 | acc=0.9219 | L2-Norm=16.061 | L2-Norm(final)=2.644 | 4762.0 samples/s | 74.4 steps/s
[Step=2900 Epoch= 5.7] | Loss=0.09249 | Reg=0.00259 | acc=0.9531 | L2-Norm=16.080 | L2-Norm(final)=2.643 | 4513.2 samples/s | 70.5 steps/s
[Step=2950 Epoch= 5.8] | Loss=0.08974 | Reg=0.00259 | acc=0.9375 | L2-Norm=16.099 | L2-Norm(final)=2.643 | 4624.9 samples/s | 72.3 steps/s
[Step=3000 Epoch= 5.9] | Loss=0.08782 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.117 | L2-Norm(final)=2.642 | 5997.8 samples/s | 93.7 steps/s
[Step=3050 Epoch= 5.9] | Loss=0.08484 | Reg=0.00260 | acc=0.9688 | L2-Norm=16.135 | L2-Norm(final)=2.642 | 2456.9 samples/s | 38.4 steps/s
[Step=3100 Epoch= 6.0] | Loss=0.08268 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.152 | L2-Norm(final)=2.643 | 4683.7 samples/s | 73.2 steps/s
[Step=3150 Epoch= 6.1] | Loss=0.08026 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.169 | L2-Norm(final)=2.643 | 4603.1 samples/s | 71.9 steps/s
[Step=3200 Epoch= 6.2] | Loss=0.07795 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.185 | L2-Norm(final)=2.644 | 4669.7 samples/s | 73.0 steps/s
[Step=3250 Epoch= 6.3] | Loss=0.07674 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.201 | L2-Norm(final)=2.645 | 4664.8 samples/s | 72.9 steps/s
[Step=3300 Epoch= 6.4] | Loss=0.07582 | Reg=0.00263 | acc=0.9062 | L2-Norm=16.216 | L2-Norm(final)=2.645 | 4594.2 samples/s | 71.8 steps/s
[Step=3350 Epoch= 6.5] | Loss=0.07449 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.231 | L2-Norm(final)=2.645 | 4625.3 samples/s | 72.3 steps/s
[Step=3400 Epoch= 6.6] | Loss=0.07294 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.246 | L2-Norm(final)=2.646 | 4600.3 samples/s | 71.9 steps/s
[Step=3450 Epoch= 6.7] | Loss=0.07154 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.261 | L2-Norm(final)=2.647 | 4646.2 samples/s | 72.6 steps/s
[Step=3500 Epoch= 6.8] | Loss=0.07050 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.276 | L2-Norm(final)=2.647 | 4976.0 samples/s | 77.7 steps/s
[Step=3550 Epoch= 6.9] | Loss=0.06909 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.290 | L2-Norm(final)=2.648 | 2681.7 samples/s | 41.9 steps/s
[Step=3600 Epoch= 7.0] | Loss=0.06779 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=2.649 | 4668.9 samples/s | 73.0 steps/s
[Step=3650 Epoch= 7.1] | Loss=0.06683 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.318 | L2-Norm(final)=2.650 | 4609.8 samples/s | 72.0 steps/s
[Step=3700 Epoch= 7.2] | Loss=0.06565 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.332 | L2-Norm(final)=2.650 | 4647.6 samples/s | 72.6 steps/s
[Step=3750 Epoch= 7.3] | Loss=0.06442 | Reg=0.00267 | acc=0.9688 | L2-Norm=16.345 | L2-Norm(final)=2.651 | 4748.8 samples/s | 74.2 steps/s
[Step=3800 Epoch= 7.4] | Loss=0.06343 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.358 | L2-Norm(final)=2.652 | 4500.5 samples/s | 70.3 steps/s
[Step=3850 Epoch= 7.5] | Loss=0.06226 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.372 | L2-Norm(final)=2.653 | 4712.3 samples/s | 73.6 steps/s
[Step=3900 Epoch= 7.6] | Loss=0.06149 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=2.654 | 4574.2 samples/s | 71.5 steps/s
[Step=3950 Epoch= 7.7] | Loss=0.06064 | Reg=0.00269 | acc=0.9688 | L2-Norm=16.399 | L2-Norm(final)=2.655 | 4629.8 samples/s | 72.3 steps/s
[Step=4000 Epoch= 7.8] | Loss=0.05992 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.412 | L2-Norm(final)=2.656 | 4660.3 samples/s | 72.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step4000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 3.9] | Loss=0.24234 | Reg=0.00258 | acc=0.8281 | L2-Norm=16.055 | L2-Norm(final)=2.410 | 6445.2 samples/s | 100.7 steps/s
[Step=2050 Epoch= 4.0] | Loss=0.14178 | Reg=0.00259 | acc=0.8906 | L2-Norm=16.096 | L2-Norm(final)=2.420 | 4669.9 samples/s | 73.0 steps/s
[Step=2100 Epoch= 4.1] | Loss=0.13074 | Reg=0.00260 | acc=0.8906 | L2-Norm=16.135 | L2-Norm(final)=2.439 | 5402.7 samples/s | 84.4 steps/s
[Step=2150 Epoch= 4.2] | Loss=0.12617 | Reg=0.00261 | acc=0.8906 | L2-Norm=16.167 | L2-Norm(final)=2.455 | 5036.8 samples/s | 78.7 steps/s
[Step=2200 Epoch= 4.3] | Loss=0.12297 | Reg=0.00262 | acc=0.9219 | L2-Norm=16.194 | L2-Norm(final)=2.465 | 5150.0 samples/s | 80.5 steps/s
[Step=2250 Epoch= 4.4] | Loss=0.12099 | Reg=0.00263 | acc=0.9375 | L2-Norm=16.219 | L2-Norm(final)=2.475 | 5207.9 samples/s | 81.4 steps/s
[Step=2300 Epoch= 4.5] | Loss=0.12080 | Reg=0.00264 | acc=0.8906 | L2-Norm=16.243 | L2-Norm(final)=2.484 | 5214.7 samples/s | 81.5 steps/s
[Step=2350 Epoch= 4.6] | Loss=0.11935 | Reg=0.00265 | acc=0.8750 | L2-Norm=16.269 | L2-Norm(final)=2.495 | 5288.3 samples/s | 82.6 steps/s
[Step=2400 Epoch= 4.7] | Loss=0.11836 | Reg=0.00266 | acc=0.8906 | L2-Norm=16.295 | L2-Norm(final)=2.505 | 5231.5 samples/s | 81.7 steps/s
[Step=2450 Epoch= 4.8] | Loss=0.11804 | Reg=0.00266 | acc=0.9062 | L2-Norm=16.321 | L2-Norm(final)=2.514 | 5230.1 samples/s | 81.7 steps/s
[Step=2500 Epoch= 4.9] | Loss=0.11759 | Reg=0.00267 | acc=0.8125 | L2-Norm=16.348 | L2-Norm(final)=2.524 | 6965.9 samples/s | 108.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.9] | Loss=0.11254 | Reg=0.00276 | acc=0.9219 | L2-Norm=16.605 | L2-Norm(final)=2.615 | 6169.9 samples/s | 96.4 steps/s
[Step=2550 Epoch= 5.0] | Loss=0.12476 | Reg=0.00277 | acc=0.9219 | L2-Norm=16.638 | L2-Norm(final)=2.612 | 4339.1 samples/s | 67.8 steps/s
[Step=2600 Epoch= 5.1] | Loss=0.11585 | Reg=0.00278 | acc=0.8750 | L2-Norm=16.673 | L2-Norm(final)=2.613 | 4566.7 samples/s | 71.4 steps/s
[Step=2650 Epoch= 5.2] | Loss=0.11113 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.697 | L2-Norm(final)=2.612 | 4629.4 samples/s | 72.3 steps/s
[Step=2700 Epoch= 5.3] | Loss=0.10614 | Reg=0.00279 | acc=0.9531 | L2-Norm=16.717 | L2-Norm(final)=2.612 | 4621.6 samples/s | 72.2 steps/s
[Step=2750 Epoch= 5.4] | Loss=0.10219 | Reg=0.00280 | acc=0.8906 | L2-Norm=16.738 | L2-Norm(final)=2.610 | 4675.2 samples/s | 73.0 steps/s
[Step=2800 Epoch= 5.5] | Loss=0.09767 | Reg=0.00281 | acc=0.9375 | L2-Norm=16.758 | L2-Norm(final)=2.609 | 4574.0 samples/s | 71.5 steps/s
[Step=2850 Epoch= 5.6] | Loss=0.09574 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.777 | L2-Norm(final)=2.608 | 4666.0 samples/s | 72.9 steps/s
[Step=2900 Epoch= 5.7] | Loss=0.09323 | Reg=0.00282 | acc=0.9531 | L2-Norm=16.795 | L2-Norm(final)=2.607 | 4658.1 samples/s | 72.8 steps/s
[Step=2950 Epoch= 5.8] | Loss=0.09108 | Reg=0.00283 | acc=0.9219 | L2-Norm=16.813 | L2-Norm(final)=2.606 | 4557.9 samples/s | 71.2 steps/s
[Step=3000 Epoch= 5.9] | Loss=0.08852 | Reg=0.00283 | acc=0.9219 | L2-Norm=16.831 | L2-Norm(final)=2.605 | 6069.8 samples/s | 94.8 steps/s
[Step=3050 Epoch= 6.0] | Loss=0.08493 | Reg=0.00284 | acc=0.9688 | L2-Norm=16.849 | L2-Norm(final)=2.604 | 2444.1 samples/s | 38.2 steps/s
[Step=3100 Epoch= 6.1] | Loss=0.08163 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.868 | L2-Norm(final)=2.605 | 4666.5 samples/s | 72.9 steps/s
[Step=3150 Epoch= 6.2] | Loss=0.07843 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.884 | L2-Norm(final)=2.605 | 4606.6 samples/s | 72.0 steps/s
[Step=3200 Epoch= 6.3] | Loss=0.07688 | Reg=0.00286 | acc=0.9375 | L2-Norm=16.899 | L2-Norm(final)=2.605 | 4610.8 samples/s | 72.0 steps/s
[Step=3250 Epoch= 6.4] | Loss=0.07519 | Reg=0.00286 | acc=0.9688 | L2-Norm=16.915 | L2-Norm(final)=2.605 | 4606.6 samples/s | 72.0 steps/s
[Step=3300 Epoch= 6.5] | Loss=0.07354 | Reg=0.00287 | acc=0.9062 | L2-Norm=16.930 | L2-Norm(final)=2.605 | 4672.8 samples/s | 73.0 steps/s
[Step=3350 Epoch= 6.5] | Loss=0.07229 | Reg=0.00287 | acc=0.9531 | L2-Norm=16.944 | L2-Norm(final)=2.605 | 4613.0 samples/s | 72.1 steps/s
[Step=3400 Epoch= 6.6] | Loss=0.07102 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.958 | L2-Norm(final)=2.605 | 4617.6 samples/s | 72.1 steps/s
[Step=3450 Epoch= 6.7] | Loss=0.07030 | Reg=0.00288 | acc=0.9844 | L2-Norm=16.971 | L2-Norm(final)=2.604 | 4623.0 samples/s | 72.2 steps/s
[Step=3500 Epoch= 6.8] | Loss=0.06957 | Reg=0.00289 | acc=0.9531 | L2-Norm=16.985 | L2-Norm(final)=2.603 | 5128.7 samples/s | 80.1 steps/s
[Step=3550 Epoch= 6.9] | Loss=0.06835 | Reg=0.00289 | acc=0.9219 | L2-Norm=16.998 | L2-Norm(final)=2.603 | 2636.9 samples/s | 41.2 steps/s
[Step=3600 Epoch= 7.0] | Loss=0.06693 | Reg=0.00289 | acc=0.9688 | L2-Norm=17.012 | L2-Norm(final)=2.603 | 4624.1 samples/s | 72.3 steps/s
[Step=3650 Epoch= 7.1] | Loss=0.06595 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.025 | L2-Norm(final)=2.603 | 4590.2 samples/s | 71.7 steps/s
[Step=3700 Epoch= 7.2] | Loss=0.06472 | Reg=0.00290 | acc=0.9688 | L2-Norm=17.038 | L2-Norm(final)=2.603 | 4611.3 samples/s | 72.1 steps/s
[Step=3750 Epoch= 7.3] | Loss=0.06368 | Reg=0.00291 | acc=0.9531 | L2-Norm=17.051 | L2-Norm(final)=2.604 | 4742.1 samples/s | 74.1 steps/s
[Step=3800 Epoch= 7.4] | Loss=0.06262 | Reg=0.00291 | acc=0.9531 | L2-Norm=17.063 | L2-Norm(final)=2.604 | 4554.6 samples/s | 71.2 steps/s
[Step=3850 Epoch= 7.5] | Loss=0.06195 | Reg=0.00292 | acc=0.9531 | L2-Norm=17.076 | L2-Norm(final)=2.604 | 4649.9 samples/s | 72.7 steps/s
[Step=3900 Epoch= 7.6] | Loss=0.06119 | Reg=0.00292 | acc=0.9688 | L2-Norm=17.088 | L2-Norm(final)=2.604 | 4626.2 samples/s | 72.3 steps/s
[Step=3950 Epoch= 7.7] | Loss=0.06056 | Reg=0.00292 | acc=0.9531 | L2-Norm=17.100 | L2-Norm(final)=2.604 | 4651.9 samples/s | 72.7 steps/s
[Step=4000 Epoch= 7.8] | Loss=0.05978 | Reg=0.00293 | acc=0.9531 | L2-Norm=17.113 | L2-Norm(final)=2.604 | 4639.7 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step4000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 7.7] | Loss=0.16296 | Reg=0.00271 | acc=0.8906 | L2-Norm=16.474 | L2-Norm(final)=2.685 | 6297.2 samples/s | 98.4 steps/s
[Step=2050 Epoch= 7.9] | Loss=0.05343 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.559 | L2-Norm(final)=2.665 | 4338.5 samples/s | 67.8 steps/s
[Step=2100 Epoch= 8.0] | Loss=0.04511 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.607 | L2-Norm(final)=2.673 | 4937.1 samples/s | 77.1 steps/s
[Step=2150 Epoch= 8.2] | Loss=0.04334 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.652 | L2-Norm(final)=2.681 | 4954.0 samples/s | 77.4 steps/s
[Step=2200 Epoch= 8.4] | Loss=0.04123 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.702 | L2-Norm(final)=2.690 | 4903.7 samples/s | 76.6 steps/s
[Step=2250 Epoch= 8.6] | Loss=0.03823 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=2.702 | 6727.8 samples/s | 105.1 steps/s
[Step=2300 Epoch= 8.8] | Loss=0.03602 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.792 | L2-Norm(final)=2.716 | 2477.7 samples/s | 38.7 steps/s
[Step=2350 Epoch= 9.0] | Loss=0.03486 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.835 | L2-Norm(final)=2.732 | 5003.2 samples/s | 78.2 steps/s
[Step=2400 Epoch= 9.2] | Loss=0.03367 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.877 | L2-Norm(final)=2.748 | 4876.6 samples/s | 76.2 steps/s
[Step=2450 Epoch= 9.4] | Loss=0.03258 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.916 | L2-Norm(final)=2.765 | 4914.4 samples/s | 76.8 steps/s
[Step=2500 Epoch= 9.6] | Loss=0.03138 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.955 | L2-Norm(final)=2.783 | 5678.2 samples/s | 88.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 9.6] | Loss=0.03320 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.351 | L2-Norm(final)=2.968 | 6173.6 samples/s | 96.5 steps/s
[Step=2550 Epoch= 9.8] | Loss=0.05043 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.455 | L2-Norm(final)=2.956 | 4162.7 samples/s | 65.0 steps/s
[Step=2600 Epoch=10.0] | Loss=0.03449 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.514 | L2-Norm(final)=2.940 | 4426.7 samples/s | 69.2 steps/s
[Step=2650 Epoch=10.2] | Loss=0.02532 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.532 | L2-Norm(final)=2.938 | 4278.6 samples/s | 66.9 steps/s
[Step=2700 Epoch=10.3] | Loss=0.02157 | Reg=0.00308 | acc=0.9844 | L2-Norm=17.536 | L2-Norm(final)=2.939 | 4435.2 samples/s | 69.3 steps/s
[Step=2750 Epoch=10.5] | Loss=0.01823 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.535 | L2-Norm(final)=2.941 | 5766.4 samples/s | 90.1 steps/s
[Step=2800 Epoch=10.7] | Loss=0.01546 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.531 | L2-Norm(final)=2.945 | 2349.9 samples/s | 36.7 steps/s
[Step=2850 Epoch=10.9] | Loss=0.01332 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.523 | L2-Norm(final)=2.949 | 4366.8 samples/s | 68.2 steps/s
[Step=2900 Epoch=11.1] | Loss=0.01169 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.513 | L2-Norm(final)=2.952 | 4410.3 samples/s | 68.9 steps/s
[Step=2950 Epoch=11.3] | Loss=0.01043 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.500 | L2-Norm(final)=2.956 | 4385.5 samples/s | 68.5 steps/s
[Step=3000 Epoch=11.5] | Loss=0.00942 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.485 | L2-Norm(final)=2.959 | 4949.1 samples/s | 77.3 steps/s
[Step=3050 Epoch=11.7] | Loss=0.00858 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.469 | L2-Norm(final)=2.961 | 2492.3 samples/s | 38.9 steps/s
[Step=3100 Epoch=11.9] | Loss=0.00787 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.453 | L2-Norm(final)=2.964 | 4361.4 samples/s | 68.1 steps/s
[Step=3150 Epoch=12.1] | Loss=0.00727 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.435 | L2-Norm(final)=2.966 | 4446.2 samples/s | 69.5 steps/s
[Step=3200 Epoch=12.3] | Loss=0.00675 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.417 | L2-Norm(final)=2.968 | 4339.0 samples/s | 67.8 steps/s
[Step=3250 Epoch=12.5] | Loss=0.00631 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.398 | L2-Norm(final)=2.970 | 4408.1 samples/s | 68.9 steps/s
[Step=3300 Epoch=12.6] | Loss=0.00592 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.379 | L2-Norm(final)=2.972 | 2700.9 samples/s | 42.2 steps/s
[Step=3350 Epoch=12.8] | Loss=0.00557 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.360 | L2-Norm(final)=2.974 | 4345.0 samples/s | 67.9 steps/s
[Step=3400 Epoch=13.0] | Loss=0.00526 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.339 | L2-Norm(final)=2.976 | 4364.0 samples/s | 68.2 steps/s
[Step=3450 Epoch=13.2] | Loss=0.00499 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=2.978 | 4524.8 samples/s | 70.7 steps/s
[Step=3500 Epoch=13.4] | Loss=0.00474 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.298 | L2-Norm(final)=2.979 | 4278.6 samples/s | 66.9 steps/s
[Step=3550 Epoch=13.6] | Loss=0.00451 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.277 | L2-Norm(final)=2.981 | 2720.5 samples/s | 42.5 steps/s
[Step=3600 Epoch=13.8] | Loss=0.00431 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.256 | L2-Norm(final)=2.982 | 4332.3 samples/s | 67.7 steps/s
[Step=3650 Epoch=14.0] | Loss=0.00412 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.234 | L2-Norm(final)=2.984 | 4455.9 samples/s | 69.6 steps/s
[Step=3700 Epoch=14.2] | Loss=0.00395 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.213 | L2-Norm(final)=2.985 | 4363.3 samples/s | 68.2 steps/s
[Step=3750 Epoch=14.4] | Loss=0.00380 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.191 | L2-Norm(final)=2.987 | 4390.1 samples/s | 68.6 steps/s
[Step=3800 Epoch=14.6] | Loss=0.00365 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.168 | L2-Norm(final)=2.988 | 6508.7 samples/s | 101.7 steps/s
[Step=3850 Epoch=14.8] | Loss=0.00352 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.146 | L2-Norm(final)=2.989 | 2249.8 samples/s | 35.2 steps/s
[Step=3900 Epoch=14.9] | Loss=0.00339 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.124 | L2-Norm(final)=2.991 | 4410.0 samples/s | 68.9 steps/s
[Step=3950 Epoch=15.1] | Loss=0.00327 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.101 | L2-Norm(final)=2.992 | 4392.1 samples/s | 68.6 steps/s
[Step=4000 Epoch=15.3] | Loss=0.00317 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.078 | L2-Norm(final)=2.993 | 4392.9 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step4000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 7.7] | Loss=0.55460 | Reg=0.00279 | acc=0.6562 | L2-Norm=16.701 | L2-Norm(final)=2.457 | 6306.3 samples/s | 98.5 steps/s
[Step=2050 Epoch= 7.9] | Loss=0.09888 | Reg=0.00288 | acc=0.9531 | L2-Norm=16.962 | L2-Norm(final)=2.371 | 4359.4 samples/s | 68.1 steps/s
[Step=2100 Epoch= 8.1] | Loss=0.07272 | Reg=0.00292 | acc=0.9688 | L2-Norm=17.094 | L2-Norm(final)=2.361 | 5000.3 samples/s | 78.1 steps/s
[Step=2150 Epoch= 8.3] | Loss=0.06233 | Reg=0.00295 | acc=0.9375 | L2-Norm=17.163 | L2-Norm(final)=2.362 | 4856.8 samples/s | 75.9 steps/s
[Step=2200 Epoch= 8.5] | Loss=0.05630 | Reg=0.00297 | acc=0.9219 | L2-Norm=17.223 | L2-Norm(final)=2.371 | 4884.2 samples/s | 76.3 steps/s
[Step=2250 Epoch= 8.7] | Loss=0.05222 | Reg=0.00299 | acc=0.9688 | L2-Norm=17.283 | L2-Norm(final)=2.381 | 6990.0 samples/s | 109.2 steps/s
[Step=2300 Epoch= 8.9] | Loss=0.04845 | Reg=0.00301 | acc=0.9844 | L2-Norm=17.340 | L2-Norm(final)=2.395 | 2463.6 samples/s | 38.5 steps/s
[Step=2350 Epoch= 9.0] | Loss=0.04572 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.393 | L2-Norm(final)=2.409 | 4976.9 samples/s | 77.8 steps/s
[Step=2400 Epoch= 9.2] | Loss=0.04381 | Reg=0.00304 | acc=0.9844 | L2-Norm=17.444 | L2-Norm(final)=2.425 | 4879.7 samples/s | 76.2 steps/s
[Step=2450 Epoch= 9.4] | Loss=0.04157 | Reg=0.00306 | acc=0.9844 | L2-Norm=17.493 | L2-Norm(final)=2.441 | 4944.3 samples/s | 77.3 steps/s
[Step=2500 Epoch= 9.6] | Loss=0.03966 | Reg=0.00308 | acc=0.9688 | L2-Norm=17.540 | L2-Norm(final)=2.458 | 5823.4 samples/s | 91.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 9.6] | Loss=0.04299 | Reg=0.00324 | acc=0.9688 | L2-Norm=17.993 | L2-Norm(final)=2.634 | 6580.8 samples/s | 102.8 steps/s
[Step=2550 Epoch= 9.8] | Loss=0.07617 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.077 | L2-Norm(final)=2.582 | 3824.6 samples/s | 59.8 steps/s
[Step=2600 Epoch=10.0] | Loss=0.04805 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.113 | L2-Norm(final)=2.581 | 4447.1 samples/s | 69.5 steps/s
[Step=2650 Epoch=10.2] | Loss=0.03447 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=2.591 | 4390.5 samples/s | 68.6 steps/s
[Step=2700 Epoch=10.4] | Loss=0.02820 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=2.600 | 4340.7 samples/s | 67.8 steps/s
[Step=2750 Epoch=10.6] | Loss=0.02345 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.120 | L2-Norm(final)=2.607 | 5990.3 samples/s | 93.6 steps/s
[Step=2800 Epoch=10.8] | Loss=0.02002 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.112 | L2-Norm(final)=2.614 | 2343.2 samples/s | 36.6 steps/s
[Step=2850 Epoch=11.0] | Loss=0.01723 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.101 | L2-Norm(final)=2.619 | 4295.8 samples/s | 67.1 steps/s
[Step=2900 Epoch=11.2] | Loss=0.01515 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.087 | L2-Norm(final)=2.624 | 4410.3 samples/s | 68.9 steps/s
[Step=2950 Epoch=11.4] | Loss=0.01358 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.070 | L2-Norm(final)=2.629 | 4387.1 samples/s | 68.5 steps/s
[Step=3000 Epoch=11.5] | Loss=0.01228 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.053 | L2-Norm(final)=2.633 | 5154.3 samples/s | 80.5 steps/s
[Step=3050 Epoch=11.7] | Loss=0.01118 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.035 | L2-Norm(final)=2.637 | 2471.8 samples/s | 38.6 steps/s
[Step=3100 Epoch=11.9] | Loss=0.01026 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.015 | L2-Norm(final)=2.640 | 4484.2 samples/s | 70.1 steps/s
[Step=3150 Epoch=12.1] | Loss=0.00948 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.994 | L2-Norm(final)=2.644 | 4280.2 samples/s | 66.9 steps/s
[Step=3200 Epoch=12.3] | Loss=0.00881 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.973 | L2-Norm(final)=2.646 | 4451.9 samples/s | 69.6 steps/s
[Step=3250 Epoch=12.5] | Loss=0.00822 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.951 | L2-Norm(final)=2.649 | 4451.4 samples/s | 69.6 steps/s
[Step=3300 Epoch=12.7] | Loss=0.00771 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.929 | L2-Norm(final)=2.651 | 2675.6 samples/s | 41.8 steps/s
[Step=3350 Epoch=12.9] | Loss=0.00726 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.906 | L2-Norm(final)=2.653 | 4391.1 samples/s | 68.6 steps/s
[Step=3400 Epoch=13.1] | Loss=0.00686 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.882 | L2-Norm(final)=2.655 | 4302.6 samples/s | 67.2 steps/s
[Step=3450 Epoch=13.3] | Loss=0.00650 | Reg=0.00319 | acc=1.0000 | L2-Norm=17.858 | L2-Norm(final)=2.657 | 4458.1 samples/s | 69.7 steps/s
[Step=3500 Epoch=13.5] | Loss=0.00618 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.835 | L2-Norm(final)=2.659 | 4305.8 samples/s | 67.3 steps/s
[Step=3550 Epoch=13.7] | Loss=0.00589 | Reg=0.00317 | acc=1.0000 | L2-Norm=17.810 | L2-Norm(final)=2.661 | 2742.2 samples/s | 42.8 steps/s
[Step=3600 Epoch=13.9] | Loss=0.00562 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.786 | L2-Norm(final)=2.662 | 4339.3 samples/s | 67.8 steps/s
[Step=3650 Epoch=14.1] | Loss=0.00538 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.761 | L2-Norm(final)=2.664 | 4405.0 samples/s | 68.8 steps/s
[Step=3700 Epoch=14.2] | Loss=0.00516 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.736 | L2-Norm(final)=2.665 | 4414.4 samples/s | 69.0 steps/s
[Step=3750 Epoch=14.4] | Loss=0.00495 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.711 | L2-Norm(final)=2.667 | 4376.5 samples/s | 68.4 steps/s
[Step=3800 Epoch=14.6] | Loss=0.00476 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.686 | L2-Norm(final)=2.668 | 7078.3 samples/s | 110.6 steps/s
[Step=3850 Epoch=14.8] | Loss=0.00459 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.661 | L2-Norm(final)=2.669 | 2181.7 samples/s | 34.1 steps/s
[Step=3900 Epoch=15.0] | Loss=0.00442 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.636 | L2-Norm(final)=2.670 | 4385.8 samples/s | 68.5 steps/s
[Step=3950 Epoch=15.2] | Loss=0.00427 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.610 | L2-Norm(final)=2.672 | 4389.9 samples/s | 68.6 steps/s
[Step=4000 Epoch=15.4] | Loss=0.00413 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.584 | L2-Norm(final)=2.673 | 4348.3 samples/s | 67.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07665 | acc=0.9502 | tpr=0.9618 | fpr=0.0748 | 5360.7 samples/s | 20.9 steps/s
Avg test loss: 0.07773, Avg test acc: 0.94859, Avg tpr: 0.95914, Avg fpr: 0.07461, total FA: 582

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08564 | acc=0.9475 | tpr=0.9800 | fpr=0.1231 | 5369.7 samples/s | 21.0 steps/s
Avg test loss: 0.08835, Avg test acc: 0.94695, Avg tpr: 0.97954, Avg fpr: 0.12473, total FA: 973

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.71200 | acc=0.3158 | tpr=0.0051 | fpr=0.0097 | 5498.0 samples/s | 21.5 steps/s
Avg test loss: 3.73389, Avg test acc: 0.31281, Avg tpr: 0.00525, Avg fpr: 0.01077, total FA: 84

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.11857 | acc=0.3163 | tpr=0.0092 | fpr=0.0168 | 5148.8 samples/s | 20.1 steps/s
Avg test loss: 4.12116, Avg test acc: 0.31385, Avg tpr: 0.00979, Avg fpr: 0.01743, total FA: 136

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.45346 | acc=0.1636 | tpr=0.7434 | fpr=0.8468 | 5159.9 samples/s | 20.2 steps/s
[Step= 100] | Loss=3.44542 | acc=0.1618 | tpr=0.7207 | fpr=0.8486 | 7547.4 samples/s | 29.5 steps/s
[Step= 150] | Loss=3.44637 | acc=0.1610 | tpr=0.7104 | fpr=0.8491 | 7502.0 samples/s | 29.3 steps/s
[Step= 200] | Loss=3.44089 | acc=0.1605 | tpr=0.7016 | fpr=0.8494 | 8103.0 samples/s | 31.7 steps/s
[Step= 250] | Loss=3.44532 | acc=0.1604 | tpr=0.7022 | fpr=0.8495 | 8501.6 samples/s | 33.2 steps/s
[Step= 300] | Loss=3.44286 | acc=0.1603 | tpr=0.6953 | fpr=0.8494 | 8046.9 samples/s | 31.4 steps/s
[Step= 350] | Loss=3.44257 | acc=0.1606 | tpr=0.6969 | fpr=0.8491 | 8181.7 samples/s | 32.0 steps/s
[Step= 400] | Loss=3.44039 | acc=0.1607 | tpr=0.6926 | fpr=0.8490 | 7968.3 samples/s | 31.1 steps/s
[Step= 450] | Loss=3.43994 | acc=0.1605 | tpr=0.6952 | fpr=0.8493 | 8155.4 samples/s | 31.9 steps/s
[Step= 500] | Loss=3.44112 | acc=0.1604 | tpr=0.6974 | fpr=0.8493 | 8343.7 samples/s | 32.6 steps/s
[Step= 550] | Loss=3.43975 | acc=0.1602 | tpr=0.6960 | fpr=0.8495 | 15130.2 samples/s | 59.1 steps/s
Avg test loss: 3.44134, Avg test acc: 0.16012, Avg tpr: 0.69612, Avg fpr: 0.84963, total FA: 117969

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.79753 | acc=0.1082 | tpr=0.8451 | fpr=0.9050 | 5439.5 samples/s | 21.2 steps/s
[Step= 100] | Loss=3.79781 | acc=0.1072 | tpr=0.8358 | fpr=0.9064 | 7241.2 samples/s | 28.3 steps/s
[Step= 150] | Loss=3.80698 | acc=0.1072 | tpr=0.8386 | fpr=0.9063 | 7420.1 samples/s | 29.0 steps/s
[Step= 200] | Loss=3.80135 | acc=0.1064 | tpr=0.8350 | fpr=0.9069 | 7973.3 samples/s | 31.1 steps/s
[Step= 250] | Loss=3.80548 | acc=0.1064 | tpr=0.8332 | fpr=0.9069 | 8227.6 samples/s | 32.1 steps/s
[Step= 300] | Loss=3.80106 | acc=0.1062 | tpr=0.8313 | fpr=0.9070 | 8365.9 samples/s | 32.7 steps/s
[Step= 350] | Loss=3.79481 | acc=0.1062 | tpr=0.8303 | fpr=0.9069 | 7927.9 samples/s | 31.0 steps/s
[Step= 400] | Loss=3.79335 | acc=0.1070 | tpr=0.8326 | fpr=0.9062 | 8261.3 samples/s | 32.3 steps/s
[Step= 450] | Loss=3.79549 | acc=0.1066 | tpr=0.8306 | fpr=0.9066 | 7986.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=3.79722 | acc=0.1064 | tpr=0.8330 | fpr=0.9067 | 8017.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=3.79391 | acc=0.1068 | tpr=0.8349 | fpr=0.9064 | 15060.7 samples/s | 58.8 steps/s
Avg test loss: 3.79552, Avg test acc: 0.10672, Avg tpr: 0.83518, Avg fpr: 0.90652, total FA: 125869

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11562 | acc=0.9792 | tpr=0.8894 | fpr=0.0192 | 5237.9 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.11917 | acc=0.9783 | tpr=0.9147 | fpr=0.0205 | 7364.6 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.12435 | acc=0.9774 | tpr=0.9251 | fpr=0.0216 | 7613.4 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.12753 | acc=0.9774 | tpr=0.9279 | fpr=0.0217 | 8568.3 samples/s | 33.5 steps/s
[Step= 250] | Loss=0.12546 | acc=0.9775 | tpr=0.9266 | fpr=0.0215 | 8173.7 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.12744 | acc=0.9770 | tpr=0.9222 | fpr=0.0220 | 7988.3 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.12818 | acc=0.9768 | tpr=0.9230 | fpr=0.0222 | 7942.1 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.12934 | acc=0.9765 | tpr=0.9196 | fpr=0.0225 | 8284.5 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.13177 | acc=0.9762 | tpr=0.9182 | fpr=0.0228 | 8188.3 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.13128 | acc=0.9761 | tpr=0.9207 | fpr=0.0229 | 7978.5 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.13068 | acc=0.9763 | tpr=0.9204 | fpr=0.0227 | 14499.7 samples/s | 56.6 steps/s
Avg test loss: 0.13055, Avg test acc: 0.97629, Avg tpr: 0.91957, Avg fpr: 0.02268, total FA: 3149

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.09550 | acc=0.9812 | tpr=0.9292 | fpr=0.0178 | 5445.2 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.10193 | acc=0.9803 | tpr=0.9403 | fpr=0.0190 | 6822.5 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.10564 | acc=0.9794 | tpr=0.9366 | fpr=0.0198 | 8034.5 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.10639 | acc=0.9793 | tpr=0.9399 | fpr=0.0199 | 7986.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.10489 | acc=0.9795 | tpr=0.9389 | fpr=0.0197 | 7999.2 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.10637 | acc=0.9794 | tpr=0.9367 | fpr=0.0199 | 8372.0 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.10756 | acc=0.9792 | tpr=0.9380 | fpr=0.0201 | 8160.4 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.10878 | acc=0.9790 | tpr=0.9338 | fpr=0.0202 | 8238.4 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.11109 | acc=0.9787 | tpr=0.9323 | fpr=0.0204 | 8042.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.11073 | acc=0.9788 | tpr=0.9326 | fpr=0.0204 | 8083.0 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.11008 | acc=0.9788 | tpr=0.9308 | fpr=0.0203 | 14589.7 samples/s | 57.0 steps/s
Avg test loss: 0.10982, Avg test acc: 0.97886, Avg tpr: 0.93067, Avg fpr: 0.02027, total FA: 2814

server round 2/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 7.8] | Loss=0.14302 | Reg=0.00257 | acc=0.8594 | L2-Norm=16.029 | L2-Norm(final)=2.674 | 6132.6 samples/s | 95.8 steps/s
[Step=4050 Epoch= 7.9] | Loss=0.09991 | Reg=0.00258 | acc=0.9219 | L2-Norm=16.067 | L2-Norm(final)=2.715 | 4864.8 samples/s | 76.0 steps/s
[Step=4100 Epoch= 8.0] | Loss=0.10159 | Reg=0.00259 | acc=0.9375 | L2-Norm=16.104 | L2-Norm(final)=2.750 | 5124.6 samples/s | 80.1 steps/s
[Step=4150 Epoch= 8.1] | Loss=0.09737 | Reg=0.00260 | acc=0.9219 | L2-Norm=16.129 | L2-Norm(final)=2.775 | 5204.1 samples/s | 81.3 steps/s
[Step=4200 Epoch= 8.2] | Loss=0.09682 | Reg=0.00261 | acc=0.8750 | L2-Norm=16.155 | L2-Norm(final)=2.802 | 5195.1 samples/s | 81.2 steps/s
[Step=4250 Epoch= 8.3] | Loss=0.09635 | Reg=0.00262 | acc=0.9062 | L2-Norm=16.178 | L2-Norm(final)=2.822 | 5141.2 samples/s | 80.3 steps/s
[Step=4300 Epoch= 8.4] | Loss=0.09439 | Reg=0.00263 | acc=0.9375 | L2-Norm=16.202 | L2-Norm(final)=2.843 | 5301.7 samples/s | 82.8 steps/s
[Step=4350 Epoch= 8.5] | Loss=0.09318 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.227 | L2-Norm(final)=2.865 | 5139.2 samples/s | 80.3 steps/s
[Step=4400 Epoch= 8.6] | Loss=0.09167 | Reg=0.00264 | acc=0.9219 | L2-Norm=16.252 | L2-Norm(final)=2.886 | 5191.0 samples/s | 81.1 steps/s
[Step=4450 Epoch= 8.7] | Loss=0.09061 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.276 | L2-Norm(final)=2.907 | 5217.2 samples/s | 81.5 steps/s
[Step=4500 Epoch= 8.8] | Loss=0.08958 | Reg=0.00266 | acc=0.9062 | L2-Norm=16.300 | L2-Norm(final)=2.926 | 6969.6 samples/s | 108.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.8] | Loss=0.05952 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.554 | L2-Norm(final)=3.121 | 6469.0 samples/s | 101.1 steps/s
[Step=4550 Epoch= 8.9] | Loss=0.09320 | Reg=0.00275 | acc=0.8906 | L2-Norm=16.591 | L2-Norm(final)=3.128 | 4156.5 samples/s | 64.9 steps/s
[Step=4600 Epoch= 9.0] | Loss=0.09333 | Reg=0.00276 | acc=0.9531 | L2-Norm=16.623 | L2-Norm(final)=3.119 | 4663.9 samples/s | 72.9 steps/s
[Step=4650 Epoch= 9.1] | Loss=0.08945 | Reg=0.00277 | acc=0.9219 | L2-Norm=16.647 | L2-Norm(final)=3.108 | 4595.8 samples/s | 71.8 steps/s
[Step=4700 Epoch= 9.2] | Loss=0.08562 | Reg=0.00278 | acc=0.9219 | L2-Norm=16.667 | L2-Norm(final)=3.100 | 4675.4 samples/s | 73.1 steps/s
[Step=4750 Epoch= 9.3] | Loss=0.08316 | Reg=0.00278 | acc=0.9219 | L2-Norm=16.685 | L2-Norm(final)=3.093 | 4667.4 samples/s | 72.9 steps/s
[Step=4800 Epoch= 9.4] | Loss=0.08096 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.700 | L2-Norm(final)=3.087 | 4602.7 samples/s | 71.9 steps/s
[Step=4850 Epoch= 9.5] | Loss=0.07913 | Reg=0.00279 | acc=0.9062 | L2-Norm=16.714 | L2-Norm(final)=3.081 | 4645.7 samples/s | 72.6 steps/s
[Step=4900 Epoch= 9.6] | Loss=0.07671 | Reg=0.00280 | acc=0.9375 | L2-Norm=16.730 | L2-Norm(final)=3.077 | 4601.3 samples/s | 71.9 steps/s
[Step=4950 Epoch= 9.7] | Loss=0.07504 | Reg=0.00280 | acc=0.9531 | L2-Norm=16.745 | L2-Norm(final)=3.073 | 4685.1 samples/s | 73.2 steps/s
[Step=5000 Epoch= 9.8] | Loss=0.07328 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.760 | L2-Norm(final)=3.069 | 5916.2 samples/s | 92.4 steps/s
[Step=5050 Epoch= 9.8] | Loss=0.07079 | Reg=0.00281 | acc=0.9688 | L2-Norm=16.776 | L2-Norm(final)=3.067 | 2492.2 samples/s | 38.9 steps/s
[Step=5100 Epoch= 9.9] | Loss=0.06827 | Reg=0.00282 | acc=0.9375 | L2-Norm=16.792 | L2-Norm(final)=3.066 | 4545.9 samples/s | 71.0 steps/s
[Step=5150 Epoch=10.0] | Loss=0.06703 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.808 | L2-Norm(final)=3.064 | 4652.9 samples/s | 72.7 steps/s
[Step=5200 Epoch=10.1] | Loss=0.06522 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.824 | L2-Norm(final)=3.063 | 4591.4 samples/s | 71.7 steps/s
[Step=5250 Epoch=10.2] | Loss=0.06368 | Reg=0.00284 | acc=0.9219 | L2-Norm=16.840 | L2-Norm(final)=3.063 | 4645.7 samples/s | 72.6 steps/s
[Step=5300 Epoch=10.3] | Loss=0.06254 | Reg=0.00284 | acc=0.9531 | L2-Norm=16.855 | L2-Norm(final)=3.062 | 4694.9 samples/s | 73.4 steps/s
[Step=5350 Epoch=10.4] | Loss=0.06151 | Reg=0.00285 | acc=0.9375 | L2-Norm=16.869 | L2-Norm(final)=3.061 | 4553.5 samples/s | 71.1 steps/s
[Step=5400 Epoch=10.5] | Loss=0.06054 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.882 | L2-Norm(final)=3.060 | 4686.1 samples/s | 73.2 steps/s
[Step=5450 Epoch=10.6] | Loss=0.05935 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.897 | L2-Norm(final)=3.059 | 4553.1 samples/s | 71.1 steps/s
[Step=5500 Epoch=10.7] | Loss=0.05837 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.910 | L2-Norm(final)=3.058 | 5004.3 samples/s | 78.2 steps/s
[Step=5550 Epoch=10.8] | Loss=0.05780 | Reg=0.00286 | acc=0.9688 | L2-Norm=16.924 | L2-Norm(final)=3.057 | 2696.9 samples/s | 42.1 steps/s
[Step=5600 Epoch=10.9] | Loss=0.05650 | Reg=0.00287 | acc=0.9688 | L2-Norm=16.937 | L2-Norm(final)=3.056 | 4566.7 samples/s | 71.4 steps/s
[Step=5650 Epoch=11.0] | Loss=0.05532 | Reg=0.00287 | acc=0.9688 | L2-Norm=16.951 | L2-Norm(final)=3.056 | 4632.0 samples/s | 72.4 steps/s
[Step=5700 Epoch=11.1] | Loss=0.05443 | Reg=0.00288 | acc=0.9688 | L2-Norm=16.964 | L2-Norm(final)=3.056 | 4630.8 samples/s | 72.4 steps/s
[Step=5750 Epoch=11.2] | Loss=0.05388 | Reg=0.00288 | acc=0.9688 | L2-Norm=16.978 | L2-Norm(final)=3.055 | 4688.9 samples/s | 73.3 steps/s
[Step=5800 Epoch=11.3] | Loss=0.05293 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.991 | L2-Norm(final)=3.055 | 4585.9 samples/s | 71.7 steps/s
[Step=5850 Epoch=11.4] | Loss=0.05234 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.003 | L2-Norm(final)=3.055 | 4636.8 samples/s | 72.5 steps/s
[Step=5900 Epoch=11.5] | Loss=0.05173 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.015 | L2-Norm(final)=3.054 | 4676.9 samples/s | 73.1 steps/s
[Step=5950 Epoch=11.6] | Loss=0.05116 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.027 | L2-Norm(final)=3.053 | 4628.8 samples/s | 72.3 steps/s
[Step=6000 Epoch=11.7] | Loss=0.05061 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.039 | L2-Norm(final)=3.053 | 4627.2 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step6000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 7.8] | Loss=0.13199 | Reg=0.00279 | acc=0.8594 | L2-Norm=16.707 | L2-Norm(final)=2.603 | 6152.0 samples/s | 96.1 steps/s
[Step=4050 Epoch= 7.9] | Loss=0.11904 | Reg=0.00281 | acc=0.8906 | L2-Norm=16.758 | L2-Norm(final)=2.646 | 4738.1 samples/s | 74.0 steps/s
[Step=4100 Epoch= 8.0] | Loss=0.11489 | Reg=0.00283 | acc=0.8906 | L2-Norm=16.811 | L2-Norm(final)=2.679 | 5193.2 samples/s | 81.1 steps/s
[Step=4150 Epoch= 8.1] | Loss=0.11269 | Reg=0.00284 | acc=0.9219 | L2-Norm=16.850 | L2-Norm(final)=2.706 | 5231.4 samples/s | 81.7 steps/s
[Step=4200 Epoch= 8.2] | Loss=0.10791 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.888 | L2-Norm(final)=2.736 | 5167.3 samples/s | 80.7 steps/s
[Step=4250 Epoch= 8.3] | Loss=0.10617 | Reg=0.00286 | acc=0.9219 | L2-Norm=16.922 | L2-Norm(final)=2.762 | 5189.9 samples/s | 81.1 steps/s
[Step=4300 Epoch= 8.4] | Loss=0.10453 | Reg=0.00287 | acc=0.9375 | L2-Norm=16.955 | L2-Norm(final)=2.787 | 5301.9 samples/s | 82.8 steps/s
[Step=4350 Epoch= 8.5] | Loss=0.10415 | Reg=0.00289 | acc=0.9375 | L2-Norm=16.987 | L2-Norm(final)=2.812 | 5201.5 samples/s | 81.3 steps/s
[Step=4400 Epoch= 8.6] | Loss=0.10305 | Reg=0.00290 | acc=0.8281 | L2-Norm=17.018 | L2-Norm(final)=2.834 | 5166.0 samples/s | 80.7 steps/s
[Step=4450 Epoch= 8.7] | Loss=0.10246 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.048 | L2-Norm(final)=2.856 | 5241.1 samples/s | 81.9 steps/s
[Step=4500 Epoch= 8.8] | Loss=0.10166 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.077 | L2-Norm(final)=2.877 | 7088.0 samples/s | 110.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.8] | Loss=0.09660 | Reg=0.00301 | acc=0.9375 | L2-Norm=17.360 | L2-Norm(final)=3.096 | 6109.8 samples/s | 95.5 steps/s
[Step=4550 Epoch= 8.9] | Loss=0.09224 | Reg=0.00303 | acc=0.9062 | L2-Norm=17.401 | L2-Norm(final)=3.104 | 4446.6 samples/s | 69.5 steps/s
[Step=4600 Epoch= 9.0] | Loss=0.08492 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.438 | L2-Norm(final)=3.096 | 4539.1 samples/s | 70.9 steps/s
[Step=4650 Epoch= 9.1] | Loss=0.08428 | Reg=0.00305 | acc=0.9531 | L2-Norm=17.466 | L2-Norm(final)=3.088 | 4637.2 samples/s | 72.5 steps/s
[Step=4700 Epoch= 9.2] | Loss=0.08295 | Reg=0.00306 | acc=0.9375 | L2-Norm=17.488 | L2-Norm(final)=3.084 | 4631.8 samples/s | 72.4 steps/s
[Step=4750 Epoch= 9.3] | Loss=0.08097 | Reg=0.00307 | acc=0.9062 | L2-Norm=17.509 | L2-Norm(final)=3.079 | 4589.7 samples/s | 71.7 steps/s
[Step=4800 Epoch= 9.4] | Loss=0.08026 | Reg=0.00307 | acc=0.9531 | L2-Norm=17.528 | L2-Norm(final)=3.072 | 4669.3 samples/s | 73.0 steps/s
[Step=4850 Epoch= 9.5] | Loss=0.07797 | Reg=0.00308 | acc=0.9844 | L2-Norm=17.544 | L2-Norm(final)=3.066 | 4676.7 samples/s | 73.1 steps/s
[Step=4900 Epoch= 9.6] | Loss=0.07520 | Reg=0.00308 | acc=0.9531 | L2-Norm=17.560 | L2-Norm(final)=3.062 | 4613.3 samples/s | 72.1 steps/s
[Step=4950 Epoch= 9.7] | Loss=0.07409 | Reg=0.00309 | acc=0.9531 | L2-Norm=17.575 | L2-Norm(final)=3.058 | 4642.0 samples/s | 72.5 steps/s
[Step=5000 Epoch= 9.8] | Loss=0.07237 | Reg=0.00309 | acc=0.9688 | L2-Norm=17.589 | L2-Norm(final)=3.054 | 6068.8 samples/s | 94.8 steps/s
[Step=5050 Epoch= 9.9] | Loss=0.06941 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.604 | L2-Norm(final)=3.053 | 2445.0 samples/s | 38.2 steps/s
[Step=5100 Epoch=10.0] | Loss=0.06678 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.617 | L2-Norm(final)=3.052 | 4638.1 samples/s | 72.5 steps/s
[Step=5150 Epoch=10.1] | Loss=0.06500 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.631 | L2-Norm(final)=3.051 | 4643.0 samples/s | 72.5 steps/s
[Step=5200 Epoch=10.2] | Loss=0.06380 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.644 | L2-Norm(final)=3.050 | 4644.7 samples/s | 72.6 steps/s
[Step=5250 Epoch=10.3] | Loss=0.06243 | Reg=0.00312 | acc=0.9688 | L2-Norm=17.658 | L2-Norm(final)=3.049 | 4611.6 samples/s | 72.1 steps/s
[Step=5300 Epoch=10.4] | Loss=0.06133 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.672 | L2-Norm(final)=3.048 | 4678.5 samples/s | 73.1 steps/s
[Step=5350 Epoch=10.5] | Loss=0.05998 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.686 | L2-Norm(final)=3.047 | 4605.2 samples/s | 72.0 steps/s
[Step=5400 Epoch=10.6] | Loss=0.05897 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.699 | L2-Norm(final)=3.046 | 4645.3 samples/s | 72.6 steps/s
[Step=5450 Epoch=10.7] | Loss=0.05787 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.711 | L2-Norm(final)=3.046 | 4592.2 samples/s | 71.8 steps/s
[Step=5500 Epoch=10.8] | Loss=0.05732 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.724 | L2-Norm(final)=3.045 | 5132.4 samples/s | 80.2 steps/s
[Step=5550 Epoch=10.9] | Loss=0.05623 | Reg=0.00315 | acc=0.9688 | L2-Norm=17.736 | L2-Norm(final)=3.044 | 2625.1 samples/s | 41.0 steps/s
[Step=5600 Epoch=10.9] | Loss=0.05506 | Reg=0.00315 | acc=0.9531 | L2-Norm=17.749 | L2-Norm(final)=3.043 | 4648.3 samples/s | 72.6 steps/s
[Step=5650 Epoch=11.0] | Loss=0.05419 | Reg=0.00316 | acc=0.9375 | L2-Norm=17.762 | L2-Norm(final)=3.042 | 4590.1 samples/s | 71.7 steps/s
[Step=5700 Epoch=11.1] | Loss=0.05346 | Reg=0.00316 | acc=0.9531 | L2-Norm=17.775 | L2-Norm(final)=3.041 | 4654.3 samples/s | 72.7 steps/s
[Step=5750 Epoch=11.2] | Loss=0.05268 | Reg=0.00316 | acc=0.9531 | L2-Norm=17.787 | L2-Norm(final)=3.041 | 4607.1 samples/s | 72.0 steps/s
[Step=5800 Epoch=11.3] | Loss=0.05183 | Reg=0.00317 | acc=0.9844 | L2-Norm=17.799 | L2-Norm(final)=3.040 | 4646.9 samples/s | 72.6 steps/s
[Step=5850 Epoch=11.4] | Loss=0.05120 | Reg=0.00317 | acc=0.9531 | L2-Norm=17.810 | L2-Norm(final)=3.039 | 4580.6 samples/s | 71.6 steps/s
[Step=5900 Epoch=11.5] | Loss=0.05065 | Reg=0.00318 | acc=0.9688 | L2-Norm=17.822 | L2-Norm(final)=3.038 | 4667.1 samples/s | 72.9 steps/s
[Step=5950 Epoch=11.6] | Loss=0.05016 | Reg=0.00318 | acc=0.9688 | L2-Norm=17.833 | L2-Norm(final)=3.037 | 4660.0 samples/s | 72.8 steps/s
[Step=6000 Epoch=11.7] | Loss=0.04962 | Reg=0.00318 | acc=0.9531 | L2-Norm=17.844 | L2-Norm(final)=3.036 | 4613.8 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step6000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=15.3] | Loss=0.00926 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.372 | L2-Norm(final)=3.032 | 6167.3 samples/s | 96.4 steps/s
[Step=4050 Epoch=15.5] | Loss=0.02184 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.420 | L2-Norm(final)=3.044 | 4369.7 samples/s | 68.3 steps/s
[Step=4100 Epoch=15.7] | Loss=0.01931 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.474 | L2-Norm(final)=3.055 | 4969.3 samples/s | 77.6 steps/s
[Step=4150 Epoch=15.9] | Loss=0.01686 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.515 | L2-Norm(final)=3.073 | 4871.8 samples/s | 76.1 steps/s
[Step=4200 Epoch=16.1] | Loss=0.01569 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.549 | L2-Norm(final)=3.093 | 4991.3 samples/s | 78.0 steps/s
[Step=4250 Epoch=16.3] | Loss=0.01455 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.588 | L2-Norm(final)=3.114 | 6740.8 samples/s | 105.3 steps/s
[Step=4300 Epoch=16.5] | Loss=0.01398 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.622 | L2-Norm(final)=3.136 | 2477.6 samples/s | 38.7 steps/s
[Step=4350 Epoch=16.7] | Loss=0.01298 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.655 | L2-Norm(final)=3.157 | 4994.4 samples/s | 78.0 steps/s
[Step=4400 Epoch=16.9] | Loss=0.01248 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.683 | L2-Norm(final)=3.180 | 4934.7 samples/s | 77.1 steps/s
[Step=4450 Epoch=17.1] | Loss=0.01204 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.710 | L2-Norm(final)=3.201 | 4800.6 samples/s | 75.0 steps/s
[Step=4500 Epoch=17.2] | Loss=0.01143 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.735 | L2-Norm(final)=3.222 | 5666.8 samples/s | 88.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=17.2] | Loss=0.00643 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.973 | L2-Norm(final)=3.439 | 6595.3 samples/s | 103.1 steps/s
[Step=4550 Epoch=17.4] | Loss=0.02597 | Reg=0.00292 | acc=0.9844 | L2-Norm=17.089 | L2-Norm(final)=3.434 | 3814.3 samples/s | 59.6 steps/s
[Step=4600 Epoch=17.6] | Loss=0.02201 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.212 | L2-Norm(final)=3.406 | 4428.2 samples/s | 69.2 steps/s
[Step=4650 Epoch=17.8] | Loss=0.01891 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.271 | L2-Norm(final)=3.393 | 4425.5 samples/s | 69.1 steps/s
[Step=4700 Epoch=18.0] | Loss=0.01538 | Reg=0.00299 | acc=0.9844 | L2-Norm=17.298 | L2-Norm(final)=3.389 | 4345.3 samples/s | 67.9 steps/s
[Step=4750 Epoch=18.2] | Loss=0.01357 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.309 | L2-Norm(final)=3.388 | 5863.3 samples/s | 91.6 steps/s
[Step=4800 Epoch=18.4] | Loss=0.01172 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.313 | L2-Norm(final)=3.388 | 2341.9 samples/s | 36.6 steps/s
[Step=4850 Epoch=18.6] | Loss=0.01023 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.311 | L2-Norm(final)=3.389 | 4406.1 samples/s | 68.8 steps/s
[Step=4900 Epoch=18.8] | Loss=0.00911 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.305 | L2-Norm(final)=3.391 | 4352.2 samples/s | 68.0 steps/s
[Step=4950 Epoch=19.0] | Loss=0.00818 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.295 | L2-Norm(final)=3.393 | 4397.1 samples/s | 68.7 steps/s
[Step=5000 Epoch=19.2] | Loss=0.00740 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.284 | L2-Norm(final)=3.396 | 4997.6 samples/s | 78.1 steps/s
[Step=5050 Epoch=19.3] | Loss=0.00675 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.271 | L2-Norm(final)=3.398 | 2519.6 samples/s | 39.4 steps/s
[Step=5100 Epoch=19.5] | Loss=0.00620 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=3.401 | 4388.0 samples/s | 68.6 steps/s
[Step=5150 Epoch=19.7] | Loss=0.00572 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.239 | L2-Norm(final)=3.403 | 4451.4 samples/s | 69.6 steps/s
[Step=5200 Epoch=19.9] | Loss=0.00532 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.220 | L2-Norm(final)=3.405 | 4319.1 samples/s | 67.5 steps/s
[Step=5250 Epoch=20.1] | Loss=0.00497 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.201 | L2-Norm(final)=3.407 | 4384.0 samples/s | 68.5 steps/s
[Step=5300 Epoch=20.3] | Loss=0.00466 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.181 | L2-Norm(final)=3.409 | 2701.6 samples/s | 42.2 steps/s
[Step=5350 Epoch=20.5] | Loss=0.00439 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.160 | L2-Norm(final)=3.411 | 4487.8 samples/s | 70.1 steps/s
[Step=5400 Epoch=20.7] | Loss=0.00414 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.138 | L2-Norm(final)=3.413 | 4272.1 samples/s | 66.8 steps/s
[Step=5450 Epoch=20.9] | Loss=0.00393 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.115 | L2-Norm(final)=3.414 | 4402.6 samples/s | 68.8 steps/s
[Step=5500 Epoch=21.1] | Loss=0.00373 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.092 | L2-Norm(final)=3.415 | 4493.0 samples/s | 70.2 steps/s
[Step=5550 Epoch=21.3] | Loss=0.00355 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.069 | L2-Norm(final)=3.417 | 2691.4 samples/s | 42.1 steps/s
[Step=5600 Epoch=21.5] | Loss=0.00339 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.045 | L2-Norm(final)=3.419 | 4346.8 samples/s | 67.9 steps/s
[Step=5650 Epoch=21.6] | Loss=0.00324 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.020 | L2-Norm(final)=3.420 | 4392.8 samples/s | 68.6 steps/s
[Step=5700 Epoch=21.8] | Loss=0.00311 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.996 | L2-Norm(final)=3.422 | 4327.2 samples/s | 67.6 steps/s
[Step=5750 Epoch=22.0] | Loss=0.00299 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.970 | L2-Norm(final)=3.424 | 4487.3 samples/s | 70.1 steps/s
[Step=5800 Epoch=22.2] | Loss=0.00287 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.945 | L2-Norm(final)=3.425 | 6294.4 samples/s | 98.3 steps/s
[Step=5850 Epoch=22.4] | Loss=0.00277 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.919 | L2-Norm(final)=3.427 | 2270.7 samples/s | 35.5 steps/s
[Step=5900 Epoch=22.6] | Loss=0.00267 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.893 | L2-Norm(final)=3.429 | 4288.7 samples/s | 67.0 steps/s
[Step=5950 Epoch=22.8] | Loss=0.00258 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.867 | L2-Norm(final)=3.431 | 4424.9 samples/s | 69.1 steps/s
[Step=6000 Epoch=23.0] | Loss=0.00249 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.840 | L2-Norm(final)=3.433 | 4415.0 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step6000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch=15.4] | Loss=0.01445 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.798 | L2-Norm(final)=2.715 | 6310.4 samples/s | 98.6 steps/s
[Step=4050 Epoch=15.6] | Loss=0.02358 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.840 | L2-Norm(final)=2.729 | 4381.9 samples/s | 68.5 steps/s
[Step=4100 Epoch=15.8] | Loss=0.02094 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.886 | L2-Norm(final)=2.743 | 4812.9 samples/s | 75.2 steps/s
[Step=4150 Epoch=16.0] | Loss=0.02065 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.926 | L2-Norm(final)=2.760 | 4899.9 samples/s | 76.6 steps/s
[Step=4200 Epoch=16.2] | Loss=0.01929 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=2.778 | 4940.6 samples/s | 77.2 steps/s
[Step=4250 Epoch=16.4] | Loss=0.01749 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.009 | L2-Norm(final)=2.799 | 6966.7 samples/s | 108.9 steps/s
[Step=4300 Epoch=16.6] | Loss=0.01650 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.048 | L2-Norm(final)=2.823 | 2458.6 samples/s | 38.4 steps/s
[Step=4350 Epoch=16.7] | Loss=0.01573 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.087 | L2-Norm(final)=2.847 | 5162.6 samples/s | 80.7 steps/s
[Step=4400 Epoch=16.9] | Loss=0.01530 | Reg=0.00293 | acc=0.9844 | L2-Norm=17.125 | L2-Norm(final)=2.869 | 4653.8 samples/s | 72.7 steps/s
[Step=4450 Epoch=17.1] | Loss=0.01483 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.162 | L2-Norm(final)=2.892 | 4893.7 samples/s | 76.5 steps/s
[Step=4500 Epoch=17.3] | Loss=0.01438 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.198 | L2-Norm(final)=2.916 | 5822.5 samples/s | 91.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch=17.3] | Loss=0.00587 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.568 | L2-Norm(final)=3.149 | 6522.6 samples/s | 101.9 steps/s
[Step=4550 Epoch=17.5] | Loss=0.02825 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.648 | L2-Norm(final)=3.148 | 3837.2 samples/s | 60.0 steps/s
[Step=4600 Epoch=17.7] | Loss=0.02412 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.716 | L2-Norm(final)=3.122 | 4550.9 samples/s | 71.1 steps/s
[Step=4650 Epoch=17.9] | Loss=0.01843 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.743 | L2-Norm(final)=3.117 | 4267.4 samples/s | 66.7 steps/s
[Step=4700 Epoch=18.1] | Loss=0.01457 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.750 | L2-Norm(final)=3.120 | 4439.4 samples/s | 69.4 steps/s
[Step=4750 Epoch=18.3] | Loss=0.01240 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.748 | L2-Norm(final)=3.126 | 5960.0 samples/s | 93.1 steps/s
[Step=4800 Epoch=18.5] | Loss=0.01070 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.745 | L2-Norm(final)=3.131 | 2328.9 samples/s | 36.4 steps/s
[Step=4850 Epoch=18.7] | Loss=0.00924 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.734 | L2-Norm(final)=3.135 | 4344.9 samples/s | 67.9 steps/s
[Step=4900 Epoch=18.9] | Loss=0.00811 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.719 | L2-Norm(final)=3.139 | 4405.7 samples/s | 68.8 steps/s
[Step=4950 Epoch=19.1] | Loss=0.00722 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.700 | L2-Norm(final)=3.143 | 4386.9 samples/s | 68.5 steps/s
[Step=5000 Epoch=19.2] | Loss=0.00651 | Reg=0.00313 | acc=1.0000 | L2-Norm=17.678 | L2-Norm(final)=3.146 | 5097.8 samples/s | 79.7 steps/s
[Step=5050 Epoch=19.4] | Loss=0.00592 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.656 | L2-Norm(final)=3.150 | 2504.0 samples/s | 39.1 steps/s
[Step=5100 Epoch=19.6] | Loss=0.00543 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.631 | L2-Norm(final)=3.153 | 4345.4 samples/s | 67.9 steps/s
[Step=5150 Epoch=19.8] | Loss=0.00501 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.605 | L2-Norm(final)=3.156 | 4441.3 samples/s | 69.4 steps/s
[Step=5200 Epoch=20.0] | Loss=0.00466 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.577 | L2-Norm(final)=3.159 | 4360.3 samples/s | 68.1 steps/s
[Step=5250 Epoch=20.2] | Loss=0.00435 | Reg=0.00308 | acc=1.0000 | L2-Norm=17.549 | L2-Norm(final)=3.162 | 4478.8 samples/s | 70.0 steps/s
[Step=5300 Epoch=20.4] | Loss=0.00408 | Reg=0.00307 | acc=1.0000 | L2-Norm=17.520 | L2-Norm(final)=3.165 | 2660.4 samples/s | 41.6 steps/s
[Step=5350 Epoch=20.6] | Loss=0.00384 | Reg=0.00306 | acc=1.0000 | L2-Norm=17.491 | L2-Norm(final)=3.168 | 4379.7 samples/s | 68.4 steps/s
[Step=5400 Epoch=20.8] | Loss=0.00363 | Reg=0.00305 | acc=1.0000 | L2-Norm=17.461 | L2-Norm(final)=3.170 | 4414.5 samples/s | 69.0 steps/s
[Step=5450 Epoch=21.0] | Loss=0.00344 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.431 | L2-Norm(final)=3.173 | 4486.3 samples/s | 70.1 steps/s
[Step=5500 Epoch=21.2] | Loss=0.00327 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.400 | L2-Norm(final)=3.175 | 4281.8 samples/s | 66.9 steps/s
[Step=5550 Epoch=21.4] | Loss=0.00311 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.369 | L2-Norm(final)=3.177 | 2679.9 samples/s | 41.9 steps/s
[Step=5600 Epoch=21.6] | Loss=0.00297 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.338 | L2-Norm(final)=3.180 | 4424.1 samples/s | 69.1 steps/s
[Step=5650 Epoch=21.7] | Loss=0.00284 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.306 | L2-Norm(final)=3.182 | 4436.4 samples/s | 69.3 steps/s
[Step=5700 Epoch=21.9] | Loss=0.00272 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.274 | L2-Norm(final)=3.185 | 4315.6 samples/s | 67.4 steps/s
[Step=5750 Epoch=22.1] | Loss=0.00262 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.242 | L2-Norm(final)=3.187 | 4403.8 samples/s | 68.8 steps/s
[Step=5800 Epoch=22.3] | Loss=0.00252 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.210 | L2-Norm(final)=3.190 | 7209.4 samples/s | 112.6 steps/s
[Step=5850 Epoch=22.5] | Loss=0.00242 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=3.192 | 2190.1 samples/s | 34.2 steps/s
[Step=5900 Epoch=22.7] | Loss=0.00234 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.145 | L2-Norm(final)=3.195 | 4386.3 samples/s | 68.5 steps/s
[Step=5950 Epoch=22.9] | Loss=0.00226 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.112 | L2-Norm(final)=3.197 | 4400.1 samples/s | 68.8 steps/s
[Step=6000 Epoch=23.1] | Loss=0.00218 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.079 | L2-Norm(final)=3.200 | 4360.9 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07291 | acc=0.9537 | tpr=0.9581 | fpr=0.0560 | 5411.5 samples/s | 21.1 steps/s
Avg test loss: 0.07442, Avg test acc: 0.95204, Avg tpr: 0.95687, Avg fpr: 0.05858, total FA: 457

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07156 | acc=0.9548 | tpr=0.9622 | fpr=0.0612 | 4962.7 samples/s | 19.4 steps/s
Avg test loss: 0.07431, Avg test acc: 0.95268, Avg tpr: 0.96048, Avg fpr: 0.06448, total FA: 503

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.79533 | acc=0.3141 | tpr=0.0054 | fpr=0.0154 | 5289.4 samples/s | 20.7 steps/s
Avg test loss: 4.81848, Avg test acc: 0.31257, Avg tpr: 0.00606, Avg fpr: 0.01333, total FA: 104

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.16244 | acc=0.3161 | tpr=0.0068 | fpr=0.0124 | 5269.9 samples/s | 20.6 steps/s
Avg test loss: 4.17039, Avg test acc: 0.31481, Avg tpr: 0.00804, Avg fpr: 0.01051, total FA: 82

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.01949 | acc=0.1295 | tpr=0.6814 | fpr=0.8804 | 5243.6 samples/s | 20.5 steps/s
[Step= 100] | Loss=4.00383 | acc=0.1262 | tpr=0.6610 | fpr=0.8838 | 7288.5 samples/s | 28.5 steps/s
[Step= 150] | Loss=3.99935 | acc=0.1253 | tpr=0.6902 | fpr=0.8851 | 7771.3 samples/s | 30.4 steps/s
[Step= 200] | Loss=3.99230 | acc=0.1253 | tpr=0.6820 | fpr=0.8848 | 8123.4 samples/s | 31.7 steps/s
[Step= 250] | Loss=3.99709 | acc=0.1246 | tpr=0.6672 | fpr=0.8853 | 8108.9 samples/s | 31.7 steps/s
[Step= 300] | Loss=3.99338 | acc=0.1251 | tpr=0.6676 | fpr=0.8848 | 8253.5 samples/s | 32.2 steps/s
[Step= 350] | Loss=3.98825 | acc=0.1251 | tpr=0.6625 | fpr=0.8847 | 8271.6 samples/s | 32.3 steps/s
[Step= 400] | Loss=3.98548 | acc=0.1256 | tpr=0.6641 | fpr=0.8842 | 8042.1 samples/s | 31.4 steps/s
[Step= 450] | Loss=3.98437 | acc=0.1256 | tpr=0.6680 | fpr=0.8842 | 8169.5 samples/s | 31.9 steps/s
[Step= 500] | Loss=3.98601 | acc=0.1254 | tpr=0.6687 | fpr=0.8844 | 8035.6 samples/s | 31.4 steps/s
[Step= 550] | Loss=3.98555 | acc=0.1256 | tpr=0.6693 | fpr=0.8842 | 14559.1 samples/s | 56.9 steps/s
Avg test loss: 3.98809, Avg test acc: 0.12554, Avg tpr: 0.66997, Avg fpr: 0.88436, total FA: 122791

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.28620 | acc=0.1495 | tpr=0.7965 | fpr=0.8622 | 5155.2 samples/s | 20.1 steps/s
[Step= 100] | Loss=3.27090 | acc=0.1500 | tpr=0.7783 | fpr=0.8617 | 7309.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=3.26639 | acc=0.1495 | tpr=0.7939 | fpr=0.8624 | 8158.7 samples/s | 31.9 steps/s
[Step= 200] | Loss=3.26155 | acc=0.1481 | tpr=0.7705 | fpr=0.8633 | 8357.8 samples/s | 32.6 steps/s
[Step= 250] | Loss=3.26542 | acc=0.1481 | tpr=0.7633 | fpr=0.8631 | 8354.3 samples/s | 32.6 steps/s
[Step= 300] | Loss=3.26425 | acc=0.1482 | tpr=0.7600 | fpr=0.8629 | 8162.8 samples/s | 31.9 steps/s
[Step= 350] | Loss=3.26065 | acc=0.1481 | tpr=0.7602 | fpr=0.8630 | 8195.6 samples/s | 32.0 steps/s
[Step= 400] | Loss=3.25789 | acc=0.1485 | tpr=0.7626 | fpr=0.8627 | 7903.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=3.26044 | acc=0.1480 | tpr=0.7648 | fpr=0.8632 | 8257.3 samples/s | 32.3 steps/s
[Step= 500] | Loss=3.26036 | acc=0.1480 | tpr=0.7692 | fpr=0.8632 | 8156.2 samples/s | 31.9 steps/s
[Step= 550] | Loss=3.25827 | acc=0.1480 | tpr=0.7700 | fpr=0.8633 | 14353.2 samples/s | 56.1 steps/s
Avg test loss: 3.26032, Avg test acc: 0.14785, Avg tpr: 0.76981, Avg fpr: 0.86346, total FA: 119889

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10735 | acc=0.9805 | tpr=0.9115 | fpr=0.0182 | 5299.7 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.11072 | acc=0.9800 | tpr=0.9360 | fpr=0.0192 | 7015.6 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.11562 | acc=0.9792 | tpr=0.9366 | fpr=0.0200 | 8042.3 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.11911 | acc=0.9792 | tpr=0.9377 | fpr=0.0201 | 8170.7 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.11729 | acc=0.9792 | tpr=0.9371 | fpr=0.0200 | 8399.4 samples/s | 32.8 steps/s
[Step= 300] | Loss=0.11881 | acc=0.9791 | tpr=0.9353 | fpr=0.0201 | 7976.6 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.11932 | acc=0.9789 | tpr=0.9361 | fpr=0.0203 | 7970.6 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.12077 | acc=0.9785 | tpr=0.9333 | fpr=0.0207 | 8045.4 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.12344 | acc=0.9781 | tpr=0.9284 | fpr=0.0210 | 7961.8 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.12260 | acc=0.9780 | tpr=0.9295 | fpr=0.0211 | 8177.2 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.12192 | acc=0.9783 | tpr=0.9284 | fpr=0.0208 | 14346.3 samples/s | 56.0 steps/s
Avg test loss: 0.12176, Avg test acc: 0.97826, Avg tpr: 0.92750, Avg fpr: 0.02081, total FA: 2890

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11221 | acc=0.9795 | tpr=0.9469 | fpr=0.0200 | 5570.0 samples/s | 21.8 steps/s
[Step= 100] | Loss=0.11876 | acc=0.9783 | tpr=0.9510 | fpr=0.0212 | 7216.5 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.12621 | acc=0.9768 | tpr=0.9452 | fpr=0.0226 | 7698.2 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.12955 | acc=0.9766 | tpr=0.9421 | fpr=0.0228 | 7772.4 samples/s | 30.4 steps/s
[Step= 250] | Loss=0.12698 | acc=0.9770 | tpr=0.9459 | fpr=0.0225 | 8307.8 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.12900 | acc=0.9767 | tpr=0.9433 | fpr=0.0227 | 7917.4 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.13029 | acc=0.9766 | tpr=0.9461 | fpr=0.0229 | 8369.6 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.13178 | acc=0.9763 | tpr=0.9442 | fpr=0.0231 | 8254.6 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.13434 | acc=0.9758 | tpr=0.9435 | fpr=0.0236 | 7883.1 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.13343 | acc=0.9759 | tpr=0.9445 | fpr=0.0236 | 8054.7 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.13253 | acc=0.9761 | tpr=0.9439 | fpr=0.0233 | 15041.1 samples/s | 58.8 steps/s
Avg test loss: 0.13227, Avg test acc: 0.97611, Avg tpr: 0.94334, Avg fpr: 0.02329, total FA: 3234

server round 3/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=11.7] | Loss=0.04622 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.640 | L2-Norm(final)=3.026 | 7079.6 samples/s | 110.6 steps/s
[Step=6050 Epoch=11.8] | Loss=0.09732 | Reg=0.00278 | acc=0.9531 | L2-Norm=16.684 | L2-Norm(final)=3.056 | 4365.5 samples/s | 68.2 steps/s
[Step=6100 Epoch=11.9] | Loss=0.09077 | Reg=0.00280 | acc=0.9062 | L2-Norm=16.728 | L2-Norm(final)=3.096 | 5134.6 samples/s | 80.2 steps/s
[Step=6150 Epoch=12.0] | Loss=0.08731 | Reg=0.00281 | acc=0.9062 | L2-Norm=16.759 | L2-Norm(final)=3.127 | 5237.3 samples/s | 81.8 steps/s
[Step=6200 Epoch=12.1] | Loss=0.08548 | Reg=0.00282 | acc=0.8906 | L2-Norm=16.787 | L2-Norm(final)=3.154 | 5302.4 samples/s | 82.9 steps/s
[Step=6250 Epoch=12.2] | Loss=0.08328 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.821 | L2-Norm(final)=3.180 | 5125.4 samples/s | 80.1 steps/s
[Step=6300 Epoch=12.3] | Loss=0.08255 | Reg=0.00284 | acc=0.9219 | L2-Norm=16.856 | L2-Norm(final)=3.207 | 5189.6 samples/s | 81.1 steps/s
[Step=6350 Epoch=12.4] | Loss=0.08239 | Reg=0.00285 | acc=0.9375 | L2-Norm=16.889 | L2-Norm(final)=3.232 | 5224.9 samples/s | 81.6 steps/s
[Step=6400 Epoch=12.5] | Loss=0.08178 | Reg=0.00286 | acc=0.9531 | L2-Norm=16.920 | L2-Norm(final)=3.255 | 5264.8 samples/s | 82.3 steps/s
[Step=6450 Epoch=12.6] | Loss=0.08037 | Reg=0.00287 | acc=0.9219 | L2-Norm=16.952 | L2-Norm(final)=3.278 | 5153.1 samples/s | 80.5 steps/s
[Step=6500 Epoch=12.7] | Loss=0.07922 | Reg=0.00289 | acc=0.9531 | L2-Norm=16.985 | L2-Norm(final)=3.302 | 6956.1 samples/s | 108.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.7] | Loss=0.03040 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.308 | L2-Norm(final)=3.535 | 6746.8 samples/s | 105.4 steps/s
[Step=6550 Epoch=12.8] | Loss=0.08356 | Reg=0.00301 | acc=0.9531 | L2-Norm=17.348 | L2-Norm(final)=3.536 | 4083.1 samples/s | 63.8 steps/s
[Step=6600 Epoch=12.9] | Loss=0.08390 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.383 | L2-Norm(final)=3.520 | 4658.9 samples/s | 72.8 steps/s
[Step=6650 Epoch=13.0] | Loss=0.07914 | Reg=0.00303 | acc=0.9375 | L2-Norm=17.409 | L2-Norm(final)=3.509 | 4648.7 samples/s | 72.6 steps/s
[Step=6700 Epoch=13.1] | Loss=0.07620 | Reg=0.00304 | acc=0.9375 | L2-Norm=17.426 | L2-Norm(final)=3.497 | 4645.6 samples/s | 72.6 steps/s
[Step=6750 Epoch=13.2] | Loss=0.07329 | Reg=0.00304 | acc=0.9219 | L2-Norm=17.442 | L2-Norm(final)=3.487 | 4683.5 samples/s | 73.2 steps/s
[Step=6800 Epoch=13.3] | Loss=0.07113 | Reg=0.00305 | acc=0.9688 | L2-Norm=17.456 | L2-Norm(final)=3.477 | 4618.9 samples/s | 72.2 steps/s
[Step=6850 Epoch=13.4] | Loss=0.06842 | Reg=0.00305 | acc=0.9688 | L2-Norm=17.470 | L2-Norm(final)=3.469 | 4596.3 samples/s | 71.8 steps/s
[Step=6900 Epoch=13.5] | Loss=0.06686 | Reg=0.00306 | acc=0.9688 | L2-Norm=17.483 | L2-Norm(final)=3.462 | 4742.8 samples/s | 74.1 steps/s
[Step=6950 Epoch=13.6] | Loss=0.06450 | Reg=0.00306 | acc=0.9844 | L2-Norm=17.498 | L2-Norm(final)=3.457 | 4510.5 samples/s | 70.5 steps/s
[Step=7000 Epoch=13.7] | Loss=0.06375 | Reg=0.00307 | acc=0.9688 | L2-Norm=17.512 | L2-Norm(final)=3.450 | 5964.3 samples/s | 93.2 steps/s
[Step=7050 Epoch=13.8] | Loss=0.06216 | Reg=0.00307 | acc=0.9531 | L2-Norm=17.527 | L2-Norm(final)=3.445 | 2476.5 samples/s | 38.7 steps/s
[Step=7100 Epoch=13.8] | Loss=0.05962 | Reg=0.00308 | acc=0.9531 | L2-Norm=17.541 | L2-Norm(final)=3.441 | 4577.8 samples/s | 71.5 steps/s
[Step=7150 Epoch=13.9] | Loss=0.05768 | Reg=0.00308 | acc=0.9688 | L2-Norm=17.554 | L2-Norm(final)=3.438 | 4663.1 samples/s | 72.9 steps/s
[Step=7200 Epoch=14.0] | Loss=0.05665 | Reg=0.00309 | acc=1.0000 | L2-Norm=17.567 | L2-Norm(final)=3.435 | 4625.7 samples/s | 72.3 steps/s
[Step=7250 Epoch=14.1] | Loss=0.05559 | Reg=0.00309 | acc=0.9531 | L2-Norm=17.578 | L2-Norm(final)=3.432 | 4638.8 samples/s | 72.5 steps/s
[Step=7300 Epoch=14.2] | Loss=0.05422 | Reg=0.00309 | acc=0.9844 | L2-Norm=17.590 | L2-Norm(final)=3.430 | 4564.3 samples/s | 71.3 steps/s
[Step=7350 Epoch=14.3] | Loss=0.05354 | Reg=0.00310 | acc=0.9375 | L2-Norm=17.601 | L2-Norm(final)=3.428 | 4688.8 samples/s | 73.3 steps/s
[Step=7400 Epoch=14.4] | Loss=0.05281 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.613 | L2-Norm(final)=3.426 | 4619.0 samples/s | 72.2 steps/s
[Step=7450 Epoch=14.5] | Loss=0.05193 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.625 | L2-Norm(final)=3.424 | 4598.2 samples/s | 71.8 steps/s
[Step=7500 Epoch=14.6] | Loss=0.05115 | Reg=0.00311 | acc=0.9531 | L2-Norm=17.637 | L2-Norm(final)=3.422 | 4996.4 samples/s | 78.1 steps/s
[Step=7550 Epoch=14.7] | Loss=0.05039 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.648 | L2-Norm(final)=3.420 | 2683.6 samples/s | 41.9 steps/s
[Step=7600 Epoch=14.8] | Loss=0.04951 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.660 | L2-Norm(final)=3.418 | 4678.4 samples/s | 73.1 steps/s
[Step=7650 Epoch=14.9] | Loss=0.04849 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.671 | L2-Norm(final)=3.416 | 4558.6 samples/s | 71.2 steps/s
[Step=7700 Epoch=15.0] | Loss=0.04779 | Reg=0.00313 | acc=0.9688 | L2-Norm=17.682 | L2-Norm(final)=3.415 | 4630.2 samples/s | 72.3 steps/s
[Step=7750 Epoch=15.1] | Loss=0.04706 | Reg=0.00313 | acc=0.9844 | L2-Norm=17.692 | L2-Norm(final)=3.413 | 4719.2 samples/s | 73.7 steps/s
[Step=7800 Epoch=15.2] | Loss=0.04653 | Reg=0.00313 | acc=0.9375 | L2-Norm=17.703 | L2-Norm(final)=3.412 | 4561.6 samples/s | 71.3 steps/s
[Step=7850 Epoch=15.3] | Loss=0.04594 | Reg=0.00314 | acc=1.0000 | L2-Norm=17.713 | L2-Norm(final)=3.410 | 4651.3 samples/s | 72.7 steps/s
[Step=7900 Epoch=15.4] | Loss=0.04550 | Reg=0.00314 | acc=0.9688 | L2-Norm=17.723 | L2-Norm(final)=3.408 | 4613.3 samples/s | 72.1 steps/s
[Step=7950 Epoch=15.5] | Loss=0.04503 | Reg=0.00314 | acc=0.9844 | L2-Norm=17.733 | L2-Norm(final)=3.406 | 4744.9 samples/s | 74.1 steps/s
[Step=8000 Epoch=15.6] | Loss=0.04519 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.742 | L2-Norm(final)=3.404 | 4563.0 samples/s | 71.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step8000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=11.7] | Loss=0.09225 | Reg=0.00304 | acc=0.9375 | L2-Norm=17.436 | L2-Norm(final)=3.014 | 6398.7 samples/s | 100.0 steps/s
[Step=6050 Epoch=11.8] | Loss=0.09282 | Reg=0.00305 | acc=0.9844 | L2-Norm=17.455 | L2-Norm(final)=3.051 | 4680.1 samples/s | 73.1 steps/s
[Step=6100 Epoch=11.9] | Loss=0.08625 | Reg=0.00306 | acc=0.9062 | L2-Norm=17.482 | L2-Norm(final)=3.090 | 5244.2 samples/s | 81.9 steps/s
[Step=6150 Epoch=12.0] | Loss=0.08410 | Reg=0.00307 | acc=0.9531 | L2-Norm=17.512 | L2-Norm(final)=3.122 | 5088.6 samples/s | 79.5 steps/s
[Step=6200 Epoch=12.1] | Loss=0.08338 | Reg=0.00308 | acc=0.9531 | L2-Norm=17.539 | L2-Norm(final)=3.147 | 5229.0 samples/s | 81.7 steps/s
[Step=6250 Epoch=12.2] | Loss=0.08160 | Reg=0.00309 | acc=0.9375 | L2-Norm=17.567 | L2-Norm(final)=3.173 | 5168.7 samples/s | 80.8 steps/s
[Step=6300 Epoch=12.3] | Loss=0.08143 | Reg=0.00310 | acc=0.9062 | L2-Norm=17.594 | L2-Norm(final)=3.195 | 5348.8 samples/s | 83.6 steps/s
[Step=6350 Epoch=12.4] | Loss=0.08032 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.621 | L2-Norm(final)=3.217 | 5135.7 samples/s | 80.2 steps/s
[Step=6400 Epoch=12.5] | Loss=0.07924 | Reg=0.00311 | acc=0.9375 | L2-Norm=17.648 | L2-Norm(final)=3.239 | 5196.0 samples/s | 81.2 steps/s
[Step=6450 Epoch=12.6] | Loss=0.07864 | Reg=0.00312 | acc=0.9531 | L2-Norm=17.677 | L2-Norm(final)=3.260 | 5223.3 samples/s | 81.6 steps/s
[Step=6500 Epoch=12.7] | Loss=0.07805 | Reg=0.00313 | acc=0.9062 | L2-Norm=17.704 | L2-Norm(final)=3.281 | 7069.9 samples/s | 110.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.7] | Loss=0.05974 | Reg=0.00323 | acc=0.9531 | L2-Norm=17.983 | L2-Norm(final)=3.486 | 6366.9 samples/s | 99.5 steps/s
[Step=6550 Epoch=12.8] | Loss=0.07476 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.025 | L2-Norm(final)=3.487 | 4162.3 samples/s | 65.0 steps/s
[Step=6600 Epoch=12.9] | Loss=0.07291 | Reg=0.00327 | acc=0.9375 | L2-Norm=18.069 | L2-Norm(final)=3.468 | 4678.2 samples/s | 73.1 steps/s
[Step=6650 Epoch=13.0] | Loss=0.07023 | Reg=0.00328 | acc=0.9219 | L2-Norm=18.103 | L2-Norm(final)=3.458 | 4607.2 samples/s | 72.0 steps/s
[Step=6700 Epoch=13.1] | Loss=0.06902 | Reg=0.00329 | acc=0.9688 | L2-Norm=18.131 | L2-Norm(final)=3.449 | 4610.4 samples/s | 72.0 steps/s
[Step=6750 Epoch=13.2] | Loss=0.06760 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.156 | L2-Norm(final)=3.441 | 4613.9 samples/s | 72.1 steps/s
[Step=6800 Epoch=13.3] | Loss=0.06592 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.181 | L2-Norm(final)=3.433 | 4652.3 samples/s | 72.7 steps/s
[Step=6850 Epoch=13.4] | Loss=0.06323 | Reg=0.00331 | acc=0.9531 | L2-Norm=18.203 | L2-Norm(final)=3.428 | 4673.3 samples/s | 73.0 steps/s
[Step=6900 Epoch=13.5] | Loss=0.06221 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.222 | L2-Norm(final)=3.422 | 4578.5 samples/s | 71.5 steps/s
[Step=6950 Epoch=13.6] | Loss=0.06106 | Reg=0.00333 | acc=0.9375 | L2-Norm=18.238 | L2-Norm(final)=3.416 | 4651.1 samples/s | 72.7 steps/s
[Step=7000 Epoch=13.7] | Loss=0.05994 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.253 | L2-Norm(final)=3.410 | 6013.9 samples/s | 94.0 steps/s
[Step=7050 Epoch=13.8] | Loss=0.05806 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.268 | L2-Norm(final)=3.404 | 2434.1 samples/s | 38.0 steps/s
[Step=7100 Epoch=13.9] | Loss=0.05602 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.284 | L2-Norm(final)=3.400 | 4582.0 samples/s | 71.6 steps/s
[Step=7150 Epoch=14.0] | Loss=0.05391 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.299 | L2-Norm(final)=3.398 | 4689.8 samples/s | 73.3 steps/s
[Step=7200 Epoch=14.1] | Loss=0.05290 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.312 | L2-Norm(final)=3.395 | 4556.6 samples/s | 71.2 steps/s
[Step=7250 Epoch=14.2] | Loss=0.05163 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.326 | L2-Norm(final)=3.393 | 4628.3 samples/s | 72.3 steps/s
[Step=7300 Epoch=14.3] | Loss=0.05049 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.338 | L2-Norm(final)=3.391 | 4709.3 samples/s | 73.6 steps/s
[Step=7350 Epoch=14.4] | Loss=0.04983 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.351 | L2-Norm(final)=3.389 | 4561.6 samples/s | 71.3 steps/s
[Step=7400 Epoch=14.5] | Loss=0.04912 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.363 | L2-Norm(final)=3.387 | 4660.8 samples/s | 72.8 steps/s
[Step=7450 Epoch=14.6] | Loss=0.04847 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.375 | L2-Norm(final)=3.385 | 4629.6 samples/s | 72.3 steps/s
[Step=7500 Epoch=14.7] | Loss=0.04805 | Reg=0.00338 | acc=0.9531 | L2-Norm=18.388 | L2-Norm(final)=3.384 | 5117.0 samples/s | 80.0 steps/s
[Step=7550 Epoch=14.8] | Loss=0.04753 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.400 | L2-Norm(final)=3.382 | 2627.3 samples/s | 41.1 steps/s
[Step=7600 Epoch=14.9] | Loss=0.04675 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.412 | L2-Norm(final)=3.380 | 4621.6 samples/s | 72.2 steps/s
[Step=7650 Epoch=15.0] | Loss=0.04582 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.424 | L2-Norm(final)=3.379 | 4599.5 samples/s | 71.9 steps/s
[Step=7700 Epoch=15.1] | Loss=0.04528 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.436 | L2-Norm(final)=3.378 | 4637.5 samples/s | 72.5 steps/s
[Step=7750 Epoch=15.2] | Loss=0.04462 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.448 | L2-Norm(final)=3.377 | 4622.3 samples/s | 72.2 steps/s
[Step=7800 Epoch=15.2] | Loss=0.04408 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.459 | L2-Norm(final)=3.376 | 4585.6 samples/s | 71.6 steps/s
[Step=7850 Epoch=15.3] | Loss=0.04375 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.470 | L2-Norm(final)=3.375 | 4708.5 samples/s | 73.6 steps/s
[Step=7900 Epoch=15.4] | Loss=0.04317 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.481 | L2-Norm(final)=3.375 | 4597.9 samples/s | 71.8 steps/s
[Step=7950 Epoch=15.5] | Loss=0.04261 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.491 | L2-Norm(final)=3.374 | 4609.7 samples/s | 72.0 steps/s
[Step=8000 Epoch=15.6] | Loss=0.04235 | Reg=0.00342 | acc=0.9375 | L2-Norm=18.501 | L2-Norm(final)=3.374 | 4680.4 samples/s | 73.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step8000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=23.0] | Loss=0.26335 | Reg=0.00253 | acc=0.8906 | L2-Norm=15.892 | L2-Norm(final)=3.487 | 5451.8 samples/s | 85.2 steps/s
[Step=6050 Epoch=23.2] | Loss=0.02253 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.096 | L2-Norm(final)=3.435 | 4212.8 samples/s | 65.8 steps/s
[Step=6100 Epoch=23.4] | Loss=0.01381 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.187 | L2-Norm(final)=3.450 | 4752.6 samples/s | 74.3 steps/s
[Step=6150 Epoch=23.6] | Loss=0.01114 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.232 | L2-Norm(final)=3.470 | 4990.0 samples/s | 78.0 steps/s
[Step=6200 Epoch=23.8] | Loss=0.01026 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.266 | L2-Norm(final)=3.489 | 4707.2 samples/s | 73.5 steps/s
[Step=6250 Epoch=23.9] | Loss=0.00933 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.298 | L2-Norm(final)=3.508 | 6820.4 samples/s | 106.6 steps/s
[Step=6300 Epoch=24.1] | Loss=0.00840 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=3.527 | 2477.3 samples/s | 38.7 steps/s
[Step=6350 Epoch=24.3] | Loss=0.00768 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.344 | L2-Norm(final)=3.545 | 4935.6 samples/s | 77.1 steps/s
[Step=6400 Epoch=24.5] | Loss=0.00699 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.362 | L2-Norm(final)=3.564 | 4891.6 samples/s | 76.4 steps/s
[Step=6450 Epoch=24.7] | Loss=0.00662 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=3.585 | 4975.8 samples/s | 77.7 steps/s
[Step=6500 Epoch=24.9] | Loss=0.00632 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.394 | L2-Norm(final)=3.605 | 5528.5 samples/s | 86.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=24.9] | Loss=0.00105 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.559 | L2-Norm(final)=3.808 | 6268.1 samples/s | 97.9 steps/s
[Step=6550 Epoch=25.1] | Loss=0.02888 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.636 | L2-Norm(final)=3.790 | 3939.6 samples/s | 61.6 steps/s
[Step=6600 Epoch=25.3] | Loss=0.02388 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.786 | L2-Norm(final)=3.725 | 4397.0 samples/s | 68.7 steps/s
[Step=6650 Epoch=25.5] | Loss=0.01792 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.851 | L2-Norm(final)=3.705 | 4375.9 samples/s | 68.4 steps/s
[Step=6700 Epoch=25.7] | Loss=0.01392 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.878 | L2-Norm(final)=3.702 | 4384.3 samples/s | 68.5 steps/s
[Step=6750 Epoch=25.9] | Loss=0.01185 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.884 | L2-Norm(final)=3.702 | 5911.2 samples/s | 92.4 steps/s
[Step=6800 Epoch=26.1] | Loss=0.01002 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.881 | L2-Norm(final)=3.705 | 2359.1 samples/s | 36.9 steps/s
[Step=6850 Epoch=26.2] | Loss=0.00864 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.872 | L2-Norm(final)=3.708 | 4419.0 samples/s | 69.0 steps/s
[Step=6900 Epoch=26.4] | Loss=0.00758 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.859 | L2-Norm(final)=3.712 | 4271.6 samples/s | 66.7 steps/s
[Step=6950 Epoch=26.6] | Loss=0.00675 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.841 | L2-Norm(final)=3.715 | 4503.8 samples/s | 70.4 steps/s
[Step=7000 Epoch=26.8] | Loss=0.00616 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.822 | L2-Norm(final)=3.719 | 4847.1 samples/s | 75.7 steps/s
[Step=7050 Epoch=27.0] | Loss=0.00571 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=3.721 | 2545.4 samples/s | 39.8 steps/s
[Step=7100 Epoch=27.2] | Loss=0.00526 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.784 | L2-Norm(final)=3.723 | 4315.8 samples/s | 67.4 steps/s
[Step=7150 Epoch=27.4] | Loss=0.00486 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.764 | L2-Norm(final)=3.726 | 4448.8 samples/s | 69.5 steps/s
[Step=7200 Epoch=27.6] | Loss=0.00451 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.742 | L2-Norm(final)=3.728 | 4334.3 samples/s | 67.7 steps/s
[Step=7250 Epoch=27.8] | Loss=0.00421 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.718 | L2-Norm(final)=3.730 | 4441.8 samples/s | 69.4 steps/s
[Step=7300 Epoch=28.0] | Loss=0.00395 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.694 | L2-Norm(final)=3.733 | 2681.8 samples/s | 41.9 steps/s
[Step=7350 Epoch=28.2] | Loss=0.00372 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.669 | L2-Norm(final)=3.735 | 4373.1 samples/s | 68.3 steps/s
[Step=7400 Epoch=28.4] | Loss=0.00351 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.643 | L2-Norm(final)=3.737 | 4519.7 samples/s | 70.6 steps/s
[Step=7450 Epoch=28.5] | Loss=0.00333 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.616 | L2-Norm(final)=3.738 | 4233.7 samples/s | 66.2 steps/s
[Step=7500 Epoch=28.7] | Loss=0.00316 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.588 | L2-Norm(final)=3.740 | 4432.8 samples/s | 69.3 steps/s
[Step=7550 Epoch=28.9] | Loss=0.00301 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.560 | L2-Norm(final)=3.742 | 2686.8 samples/s | 42.0 steps/s
[Step=7600 Epoch=29.1] | Loss=0.00288 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=3.744 | 4417.2 samples/s | 69.0 steps/s
[Step=7650 Epoch=29.3] | Loss=0.00275 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.503 | L2-Norm(final)=3.746 | 4403.9 samples/s | 68.8 steps/s
[Step=7700 Epoch=29.5] | Loss=0.00264 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.474 | L2-Norm(final)=3.748 | 4449.3 samples/s | 69.5 steps/s
[Step=7750 Epoch=29.7] | Loss=0.00253 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.445 | L2-Norm(final)=3.750 | 4342.2 samples/s | 67.8 steps/s
[Step=7800 Epoch=29.9] | Loss=0.00244 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=3.752 | 6512.8 samples/s | 101.8 steps/s
[Step=7850 Epoch=30.1] | Loss=0.00235 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=3.754 | 2288.9 samples/s | 35.8 steps/s
[Step=7900 Epoch=30.3] | Loss=0.00226 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=3.756 | 4265.2 samples/s | 66.6 steps/s
[Step=7950 Epoch=30.5] | Loss=0.00219 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.324 | L2-Norm(final)=3.758 | 4388.6 samples/s | 68.6 steps/s
[Step=8000 Epoch=30.7] | Loss=0.00211 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.293 | L2-Norm(final)=3.761 | 4265.4 samples/s | 66.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step8000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=23.1] | Loss=0.06189 | Reg=0.00259 | acc=0.9375 | L2-Norm=16.095 | L2-Norm(final)=3.278 | 6556.6 samples/s | 102.4 steps/s
[Step=6050 Epoch=23.3] | Loss=0.01926 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.319 | L2-Norm(final)=3.258 | 4050.4 samples/s | 63.3 steps/s
[Step=6100 Epoch=23.5] | Loss=0.01359 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.434 | L2-Norm(final)=3.276 | 4797.0 samples/s | 75.0 steps/s
[Step=6150 Epoch=23.7] | Loss=0.01121 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.504 | L2-Norm(final)=3.299 | 4961.6 samples/s | 77.5 steps/s
[Step=6200 Epoch=23.9] | Loss=0.01075 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.555 | L2-Norm(final)=3.321 | 4893.9 samples/s | 76.5 steps/s
[Step=6250 Epoch=24.1] | Loss=0.00981 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.600 | L2-Norm(final)=3.342 | 6777.2 samples/s | 105.9 steps/s
[Step=6300 Epoch=24.3] | Loss=0.00894 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.638 | L2-Norm(final)=3.364 | 2432.4 samples/s | 38.0 steps/s
[Step=6350 Epoch=24.4] | Loss=0.00823 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.673 | L2-Norm(final)=3.387 | 5039.8 samples/s | 78.7 steps/s
[Step=6400 Epoch=24.6] | Loss=0.00766 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.701 | L2-Norm(final)=3.411 | 4820.8 samples/s | 75.3 steps/s
[Step=6450 Epoch=24.8] | Loss=0.00720 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.728 | L2-Norm(final)=3.436 | 4896.1 samples/s | 76.5 steps/s
[Step=6500 Epoch=25.0] | Loss=0.00690 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.752 | L2-Norm(final)=3.460 | 5853.2 samples/s | 91.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=25.0] | Loss=0.00275 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.978 | L2-Norm(final)=3.696 | 6124.3 samples/s | 95.7 steps/s
[Step=6550 Epoch=25.2] | Loss=0.02409 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.099 | L2-Norm(final)=3.673 | 3981.5 samples/s | 62.2 steps/s
[Step=6600 Epoch=25.4] | Loss=0.02317 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.297 | L2-Norm(final)=3.613 | 4393.1 samples/s | 68.6 steps/s
[Step=6650 Epoch=25.6] | Loss=0.01878 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.375 | L2-Norm(final)=3.592 | 4348.7 samples/s | 67.9 steps/s
[Step=6700 Epoch=25.8] | Loss=0.01631 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.412 | L2-Norm(final)=3.584 | 4455.4 samples/s | 69.6 steps/s
[Step=6750 Epoch=26.0] | Loss=0.01369 | Reg=0.00304 | acc=0.9844 | L2-Norm=17.432 | L2-Norm(final)=3.580 | 5880.9 samples/s | 91.9 steps/s
[Step=6800 Epoch=26.2] | Loss=0.01156 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.438 | L2-Norm(final)=3.579 | 2329.1 samples/s | 36.4 steps/s
[Step=6850 Epoch=26.4] | Loss=0.00995 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.434 | L2-Norm(final)=3.581 | 4357.9 samples/s | 68.1 steps/s
[Step=6900 Epoch=26.6] | Loss=0.00891 | Reg=0.00304 | acc=1.0000 | L2-Norm=17.422 | L2-Norm(final)=3.583 | 4395.1 samples/s | 68.7 steps/s
[Step=6950 Epoch=26.8] | Loss=0.00811 | Reg=0.00303 | acc=1.0000 | L2-Norm=17.405 | L2-Norm(final)=3.585 | 4362.4 samples/s | 68.2 steps/s
[Step=7000 Epoch=26.9] | Loss=0.00737 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.387 | L2-Norm(final)=3.588 | 5138.3 samples/s | 80.3 steps/s
[Step=7050 Epoch=27.1] | Loss=0.00672 | Reg=0.00302 | acc=1.0000 | L2-Norm=17.367 | L2-Norm(final)=3.592 | 2501.2 samples/s | 39.1 steps/s
[Step=7100 Epoch=27.3] | Loss=0.00616 | Reg=0.00301 | acc=1.0000 | L2-Norm=17.344 | L2-Norm(final)=3.595 | 4356.0 samples/s | 68.1 steps/s
[Step=7150 Epoch=27.5] | Loss=0.00569 | Reg=0.00300 | acc=1.0000 | L2-Norm=17.319 | L2-Norm(final)=3.598 | 4360.8 samples/s | 68.1 steps/s
[Step=7200 Epoch=27.7] | Loss=0.00529 | Reg=0.00299 | acc=1.0000 | L2-Norm=17.292 | L2-Norm(final)=3.601 | 4461.1 samples/s | 69.7 steps/s
[Step=7250 Epoch=27.9] | Loss=0.00494 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.264 | L2-Norm(final)=3.603 | 4435.6 samples/s | 69.3 steps/s
[Step=7300 Epoch=28.1] | Loss=0.00463 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.235 | L2-Norm(final)=3.605 | 2677.4 samples/s | 41.8 steps/s
[Step=7350 Epoch=28.3] | Loss=0.00436 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.205 | L2-Norm(final)=3.608 | 4360.8 samples/s | 68.1 steps/s
[Step=7400 Epoch=28.5] | Loss=0.00412 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=3.610 | 4384.2 samples/s | 68.5 steps/s
[Step=7450 Epoch=28.7] | Loss=0.00390 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.142 | L2-Norm(final)=3.612 | 4436.6 samples/s | 69.3 steps/s
[Step=7500 Epoch=28.9] | Loss=0.00371 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.109 | L2-Norm(final)=3.615 | 4354.9 samples/s | 68.0 steps/s
[Step=7550 Epoch=29.1] | Loss=0.00353 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.077 | L2-Norm(final)=3.619 | 2725.2 samples/s | 42.6 steps/s
[Step=7600 Epoch=29.3] | Loss=0.00337 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.043 | L2-Norm(final)=3.622 | 4379.1 samples/s | 68.4 steps/s
[Step=7650 Epoch=29.4] | Loss=0.00322 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.010 | L2-Norm(final)=3.626 | 4365.4 samples/s | 68.2 steps/s
[Step=7700 Epoch=29.6] | Loss=0.00309 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.976 | L2-Norm(final)=3.630 | 4451.4 samples/s | 69.6 steps/s
[Step=7750 Epoch=29.8] | Loss=0.00297 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.941 | L2-Norm(final)=3.634 | 4471.7 samples/s | 69.9 steps/s
[Step=7800 Epoch=30.0] | Loss=0.00285 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.907 | L2-Norm(final)=3.638 | 6807.7 samples/s | 106.4 steps/s
[Step=7850 Epoch=30.2] | Loss=0.00275 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.872 | L2-Norm(final)=3.643 | 2190.9 samples/s | 34.2 steps/s
[Step=7900 Epoch=30.4] | Loss=0.00265 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.836 | L2-Norm(final)=3.647 | 4447.0 samples/s | 69.5 steps/s
[Step=7950 Epoch=30.6] | Loss=0.00256 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.801 | L2-Norm(final)=3.652 | 4283.4 samples/s | 66.9 steps/s
[Step=8000 Epoch=30.8] | Loss=0.00247 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.765 | L2-Norm(final)=3.657 | 4408.7 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07430 | acc=0.9493 | tpr=0.9560 | fpr=0.0652 | 5183.0 samples/s | 20.2 steps/s
Avg test loss: 0.07475, Avg test acc: 0.94972, Avg tpr: 0.95605, Avg fpr: 0.06422, total FA: 501

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07336 | acc=0.9514 | tpr=0.9506 | fpr=0.0468 | 5286.0 samples/s | 20.6 steps/s
Avg test loss: 0.07753, Avg test acc: 0.95080, Avg tpr: 0.95092, Avg fpr: 0.04948, total FA: 386

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.29448 | acc=0.3152 | tpr=0.0102 | fpr=0.0223 | 5318.4 samples/s | 20.8 steps/s
Avg test loss: 4.30059, Avg test acc: 0.31285, Avg tpr: 0.01049, Avg fpr: 0.02218, total FA: 173

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.16447 | acc=0.3152 | tpr=0.0042 | fpr=0.0097 | 5252.6 samples/s | 20.5 steps/s
Avg test loss: 4.18133, Avg test acc: 0.31257, Avg tpr: 0.00402, Avg fpr: 0.00885, total FA: 69

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.94780 | acc=0.1544 | tpr=0.6947 | fpr=0.8553 | 5236.7 samples/s | 20.5 steps/s
[Step= 100] | Loss=2.94172 | acc=0.1520 | tpr=0.6908 | fpr=0.8581 | 7517.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=2.93850 | acc=0.1518 | tpr=0.6945 | fpr=0.8581 | 7341.5 samples/s | 28.7 steps/s
[Step= 200] | Loss=2.93629 | acc=0.1515 | tpr=0.6874 | fpr=0.8582 | 8254.3 samples/s | 32.2 steps/s
[Step= 250] | Loss=2.93713 | acc=0.1513 | tpr=0.6838 | fpr=0.8584 | 8530.0 samples/s | 33.3 steps/s
[Step= 300] | Loss=2.93060 | acc=0.1516 | tpr=0.6844 | fpr=0.8581 | 8078.3 samples/s | 31.6 steps/s
[Step= 350] | Loss=2.92842 | acc=0.1517 | tpr=0.6769 | fpr=0.8579 | 7734.4 samples/s | 30.2 steps/s
[Step= 400] | Loss=2.92722 | acc=0.1523 | tpr=0.6833 | fpr=0.8574 | 8376.3 samples/s | 32.7 steps/s
[Step= 450] | Loss=2.92559 | acc=0.1526 | tpr=0.6855 | fpr=0.8570 | 8087.3 samples/s | 31.6 steps/s
[Step= 500] | Loss=2.92813 | acc=0.1520 | tpr=0.6819 | fpr=0.8576 | 7937.8 samples/s | 31.0 steps/s
[Step= 550] | Loss=2.92720 | acc=0.1524 | tpr=0.6836 | fpr=0.8573 | 14614.9 samples/s | 57.1 steps/s
Avg test loss: 2.92845, Avg test acc: 0.15237, Avg tpr: 0.68384, Avg fpr: 0.85729, total FA: 119033

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.25592 | acc=0.1767 | tpr=0.6814 | fpr=0.8324 | 5440.0 samples/s | 21.2 steps/s
[Step= 100] | Loss=3.23173 | acc=0.1783 | tpr=0.6780 | fpr=0.8310 | 6735.7 samples/s | 26.3 steps/s
[Step= 150] | Loss=3.22435 | acc=0.1784 | tpr=0.7003 | fpr=0.8312 | 7970.8 samples/s | 31.1 steps/s
[Step= 200] | Loss=3.22092 | acc=0.1786 | tpr=0.6896 | fpr=0.8307 | 8337.3 samples/s | 32.6 steps/s
[Step= 250] | Loss=3.22430 | acc=0.1791 | tpr=0.6934 | fpr=0.8302 | 8266.8 samples/s | 32.3 steps/s
[Step= 300] | Loss=3.21885 | acc=0.1793 | tpr=0.6975 | fpr=0.8301 | 8269.7 samples/s | 32.3 steps/s
[Step= 350] | Loss=3.21354 | acc=0.1792 | tpr=0.6969 | fpr=0.8302 | 7856.0 samples/s | 30.7 steps/s
[Step= 400] | Loss=3.21049 | acc=0.1796 | tpr=0.6975 | fpr=0.8298 | 7785.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=3.21145 | acc=0.1794 | tpr=0.6977 | fpr=0.8300 | 8420.4 samples/s | 32.9 steps/s
[Step= 500] | Loss=3.21190 | acc=0.1790 | tpr=0.7000 | fpr=0.8304 | 8231.6 samples/s | 32.2 steps/s
[Step= 550] | Loss=3.20949 | acc=0.1788 | tpr=0.7012 | fpr=0.8306 | 14310.5 samples/s | 55.9 steps/s
Avg test loss: 3.21122, Avg test acc: 0.17872, Avg tpr: 0.70087, Avg fpr: 0.83077, total FA: 115351

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11282 | acc=0.9797 | tpr=0.8938 | fpr=0.0188 | 5325.0 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.11590 | acc=0.9791 | tpr=0.9318 | fpr=0.0200 | 7592.9 samples/s | 29.7 steps/s
[Step= 150] | Loss=0.11990 | acc=0.9780 | tpr=0.9323 | fpr=0.0211 | 7552.6 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.12155 | acc=0.9779 | tpr=0.9366 | fpr=0.0214 | 8006.4 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.11978 | acc=0.9784 | tpr=0.9389 | fpr=0.0209 | 8283.5 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.12123 | acc=0.9780 | tpr=0.9338 | fpr=0.0211 | 7973.6 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.12267 | acc=0.9777 | tpr=0.9343 | fpr=0.0215 | 8339.3 samples/s | 32.6 steps/s
[Step= 400] | Loss=0.12390 | acc=0.9776 | tpr=0.9322 | fpr=0.0216 | 8047.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.12629 | acc=0.9772 | tpr=0.9304 | fpr=0.0219 | 7999.2 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.12526 | acc=0.9773 | tpr=0.9330 | fpr=0.0219 | 8343.4 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.12502 | acc=0.9774 | tpr=0.9316 | fpr=0.0218 | 14570.4 samples/s | 56.9 steps/s
Avg test loss: 0.12478, Avg test acc: 0.97736, Avg tpr: 0.93185, Avg fpr: 0.02181, total FA: 3028

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11262 | acc=0.9795 | tpr=0.9204 | fpr=0.0195 | 5206.5 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.11718 | acc=0.9788 | tpr=0.9403 | fpr=0.0205 | 7453.4 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.12338 | acc=0.9779 | tpr=0.9467 | fpr=0.0216 | 7804.6 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.12576 | acc=0.9779 | tpr=0.9486 | fpr=0.0215 | 7889.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.12407 | acc=0.9783 | tpr=0.9450 | fpr=0.0211 | 8339.1 samples/s | 32.6 steps/s
[Step= 300] | Loss=0.12690 | acc=0.9779 | tpr=0.9389 | fpr=0.0214 | 8239.8 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.12782 | acc=0.9776 | tpr=0.9424 | fpr=0.0217 | 7931.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.12947 | acc=0.9775 | tpr=0.9387 | fpr=0.0218 | 8465.9 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.13159 | acc=0.9772 | tpr=0.9382 | fpr=0.0221 | 7892.6 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.13122 | acc=0.9771 | tpr=0.9392 | fpr=0.0222 | 8455.2 samples/s | 33.0 steps/s
[Step= 550] | Loss=0.13075 | acc=0.9773 | tpr=0.9407 | fpr=0.0220 | 13658.5 samples/s | 53.4 steps/s
Avg test loss: 0.13047, Avg test acc: 0.97732, Avg tpr: 0.94057, Avg fpr: 0.02201, total FA: 3056

server round 4/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=15.6] | Loss=0.11118 | Reg=0.00300 | acc=0.8906 | L2-Norm=17.332 | L2-Norm(final)=3.315 | 5764.1 samples/s | 90.1 steps/s
[Step=8050 Epoch=15.7] | Loss=0.08170 | Reg=0.00302 | acc=0.8750 | L2-Norm=17.375 | L2-Norm(final)=3.379 | 5127.5 samples/s | 80.1 steps/s
[Step=8100 Epoch=15.8] | Loss=0.07905 | Reg=0.00303 | acc=0.9375 | L2-Norm=17.418 | L2-Norm(final)=3.431 | 5148.7 samples/s | 80.4 steps/s
[Step=8150 Epoch=15.9] | Loss=0.07817 | Reg=0.00305 | acc=0.9531 | L2-Norm=17.458 | L2-Norm(final)=3.470 | 5242.5 samples/s | 81.9 steps/s
[Step=8200 Epoch=16.0] | Loss=0.07715 | Reg=0.00306 | acc=0.9688 | L2-Norm=17.495 | L2-Norm(final)=3.504 | 5146.3 samples/s | 80.4 steps/s
[Step=8250 Epoch=16.1] | Loss=0.07671 | Reg=0.00307 | acc=0.9062 | L2-Norm=17.527 | L2-Norm(final)=3.533 | 5204.8 samples/s | 81.3 steps/s
[Step=8300 Epoch=16.2] | Loss=0.07591 | Reg=0.00308 | acc=0.9375 | L2-Norm=17.560 | L2-Norm(final)=3.560 | 5300.7 samples/s | 82.8 steps/s
[Step=8350 Epoch=16.3] | Loss=0.07524 | Reg=0.00310 | acc=0.9375 | L2-Norm=17.595 | L2-Norm(final)=3.586 | 5088.1 samples/s | 79.5 steps/s
[Step=8400 Epoch=16.4] | Loss=0.07490 | Reg=0.00311 | acc=0.9375 | L2-Norm=17.628 | L2-Norm(final)=3.610 | 5323.1 samples/s | 83.2 steps/s
[Step=8450 Epoch=16.5] | Loss=0.07440 | Reg=0.00312 | acc=0.9219 | L2-Norm=17.660 | L2-Norm(final)=3.633 | 5151.1 samples/s | 80.5 steps/s
[Step=8500 Epoch=16.6] | Loss=0.07387 | Reg=0.00313 | acc=0.9219 | L2-Norm=17.692 | L2-Norm(final)=3.655 | 7011.1 samples/s | 109.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.6] | Loss=0.03482 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.030 | L2-Norm(final)=3.880 | 5866.5 samples/s | 91.7 steps/s
[Step=8550 Epoch=16.7] | Loss=0.06168 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.070 | L2-Norm(final)=3.886 | 4448.3 samples/s | 69.5 steps/s
[Step=8600 Epoch=16.8] | Loss=0.06382 | Reg=0.00328 | acc=0.9062 | L2-Norm=18.108 | L2-Norm(final)=3.875 | 4631.5 samples/s | 72.4 steps/s
[Step=8650 Epoch=16.9] | Loss=0.06162 | Reg=0.00329 | acc=0.9375 | L2-Norm=18.137 | L2-Norm(final)=3.862 | 4634.5 samples/s | 72.4 steps/s
[Step=8700 Epoch=17.0] | Loss=0.06129 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.156 | L2-Norm(final)=3.851 | 4584.5 samples/s | 71.6 steps/s
[Step=8750 Epoch=17.1] | Loss=0.05910 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.174 | L2-Norm(final)=3.842 | 4668.9 samples/s | 73.0 steps/s
[Step=8800 Epoch=17.2] | Loss=0.05987 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.190 | L2-Norm(final)=3.831 | 4578.3 samples/s | 71.5 steps/s
[Step=8850 Epoch=17.3] | Loss=0.05863 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.204 | L2-Norm(final)=3.821 | 4623.4 samples/s | 72.2 steps/s
[Step=8900 Epoch=17.4] | Loss=0.05699 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.218 | L2-Norm(final)=3.813 | 4581.3 samples/s | 71.6 steps/s
[Step=8950 Epoch=17.5] | Loss=0.05675 | Reg=0.00332 | acc=0.9531 | L2-Norm=18.232 | L2-Norm(final)=3.805 | 4634.1 samples/s | 72.4 steps/s
[Step=9000 Epoch=17.6] | Loss=0.05631 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.246 | L2-Norm(final)=3.798 | 5994.0 samples/s | 93.7 steps/s
[Step=9050 Epoch=17.7] | Loss=0.05513 | Reg=0.00333 | acc=1.0000 | L2-Norm=18.260 | L2-Norm(final)=3.792 | 2468.6 samples/s | 38.6 steps/s
[Step=9100 Epoch=17.7] | Loss=0.05315 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.274 | L2-Norm(final)=3.787 | 4681.4 samples/s | 73.1 steps/s
[Step=9150 Epoch=17.8] | Loss=0.05174 | Reg=0.00334 | acc=0.9844 | L2-Norm=18.286 | L2-Norm(final)=3.783 | 4574.8 samples/s | 71.5 steps/s
[Step=9200 Epoch=17.9] | Loss=0.05044 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.298 | L2-Norm(final)=3.780 | 4625.4 samples/s | 72.3 steps/s
[Step=9250 Epoch=18.0] | Loss=0.04975 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.310 | L2-Norm(final)=3.776 | 4652.4 samples/s | 72.7 steps/s
[Step=9300 Epoch=18.1] | Loss=0.04877 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.322 | L2-Norm(final)=3.773 | 4586.5 samples/s | 71.7 steps/s
[Step=9350 Epoch=18.2] | Loss=0.04815 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.334 | L2-Norm(final)=3.770 | 4635.4 samples/s | 72.4 steps/s
[Step=9400 Epoch=18.3] | Loss=0.04745 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.345 | L2-Norm(final)=3.767 | 4734.8 samples/s | 74.0 steps/s
[Step=9450 Epoch=18.4] | Loss=0.04680 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.355 | L2-Norm(final)=3.764 | 4557.2 samples/s | 71.2 steps/s
[Step=9500 Epoch=18.5] | Loss=0.04612 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.365 | L2-Norm(final)=3.760 | 5000.2 samples/s | 78.1 steps/s
[Step=9550 Epoch=18.6] | Loss=0.04530 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.375 | L2-Norm(final)=3.757 | 2699.9 samples/s | 42.2 steps/s
[Step=9600 Epoch=18.7] | Loss=0.04445 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.385 | L2-Norm(final)=3.755 | 4575.8 samples/s | 71.5 steps/s
[Step=9650 Epoch=18.8] | Loss=0.04368 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.395 | L2-Norm(final)=3.752 | 4587.3 samples/s | 71.7 steps/s
[Step=9700 Epoch=18.9] | Loss=0.04300 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.404 | L2-Norm(final)=3.750 | 4624.2 samples/s | 72.3 steps/s
[Step=9750 Epoch=19.0] | Loss=0.04237 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.412 | L2-Norm(final)=3.748 | 4647.3 samples/s | 72.6 steps/s
[Step=9800 Epoch=19.1] | Loss=0.04180 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.421 | L2-Norm(final)=3.746 | 4580.6 samples/s | 71.6 steps/s
[Step=9850 Epoch=19.2] | Loss=0.04133 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.430 | L2-Norm(final)=3.745 | 4624.0 samples/s | 72.3 steps/s
[Step=9900 Epoch=19.3] | Loss=0.04076 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.438 | L2-Norm(final)=3.743 | 4635.6 samples/s | 72.4 steps/s
[Step=9950 Epoch=19.4] | Loss=0.04032 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.446 | L2-Norm(final)=3.741 | 4676.5 samples/s | 73.1 steps/s
[Step=10000 Epoch=19.5] | Loss=0.03985 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.454 | L2-Norm(final)=3.740 | 4646.6 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step10000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=15.6] | Loss=0.08446 | Reg=0.00328 | acc=0.9219 | L2-Norm=18.120 | L2-Norm(final)=3.352 | 6238.1 samples/s | 97.5 steps/s
[Step=8050 Epoch=15.7] | Loss=0.08103 | Reg=0.00330 | acc=0.9062 | L2-Norm=18.171 | L2-Norm(final)=3.440 | 4732.8 samples/s | 74.0 steps/s
[Step=8100 Epoch=15.8] | Loss=0.07668 | Reg=0.00332 | acc=0.8594 | L2-Norm=18.216 | L2-Norm(final)=3.501 | 5154.6 samples/s | 80.5 steps/s
[Step=8150 Epoch=15.9] | Loss=0.07794 | Reg=0.00333 | acc=0.9531 | L2-Norm=18.254 | L2-Norm(final)=3.542 | 5241.9 samples/s | 81.9 steps/s
[Step=8200 Epoch=16.0] | Loss=0.07703 | Reg=0.00335 | acc=0.9375 | L2-Norm=18.292 | L2-Norm(final)=3.576 | 5236.2 samples/s | 81.8 steps/s
[Step=8250 Epoch=16.1] | Loss=0.07454 | Reg=0.00336 | acc=0.9531 | L2-Norm=18.329 | L2-Norm(final)=3.610 | 5216.1 samples/s | 81.5 steps/s
[Step=8300 Epoch=16.2] | Loss=0.07395 | Reg=0.00337 | acc=0.9219 | L2-Norm=18.363 | L2-Norm(final)=3.641 | 5308.0 samples/s | 82.9 steps/s
[Step=8350 Epoch=16.3] | Loss=0.07244 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.397 | L2-Norm(final)=3.671 | 5092.5 samples/s | 79.6 steps/s
[Step=8400 Epoch=16.4] | Loss=0.07196 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.430 | L2-Norm(final)=3.699 | 5178.0 samples/s | 80.9 steps/s
[Step=8450 Epoch=16.5] | Loss=0.07064 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.462 | L2-Norm(final)=3.727 | 5217.2 samples/s | 81.5 steps/s
[Step=8500 Epoch=16.6] | Loss=0.07017 | Reg=0.00342 | acc=0.9531 | L2-Norm=18.493 | L2-Norm(final)=3.755 | 7100.2 samples/s | 110.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.6] | Loss=0.06124 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.795 | L2-Norm(final)=4.014 | 6374.8 samples/s | 99.6 steps/s
[Step=8550 Epoch=16.7] | Loss=0.06599 | Reg=0.00355 | acc=0.9375 | L2-Norm=18.834 | L2-Norm(final)=4.017 | 4203.0 samples/s | 65.7 steps/s
[Step=8600 Epoch=16.8] | Loss=0.06758 | Reg=0.00356 | acc=0.9531 | L2-Norm=18.871 | L2-Norm(final)=3.998 | 4621.6 samples/s | 72.2 steps/s
[Step=8650 Epoch=16.9] | Loss=0.06276 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.902 | L2-Norm(final)=3.982 | 4596.0 samples/s | 71.8 steps/s
[Step=8700 Epoch=17.0] | Loss=0.06079 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.926 | L2-Norm(final)=3.972 | 4638.6 samples/s | 72.5 steps/s
[Step=8750 Epoch=17.1] | Loss=0.06024 | Reg=0.00359 | acc=0.9531 | L2-Norm=18.945 | L2-Norm(final)=3.962 | 4618.3 samples/s | 72.2 steps/s
[Step=8800 Epoch=17.2] | Loss=0.05859 | Reg=0.00359 | acc=0.9375 | L2-Norm=18.959 | L2-Norm(final)=3.952 | 4569.9 samples/s | 71.4 steps/s
[Step=8850 Epoch=17.3] | Loss=0.05757 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.974 | L2-Norm(final)=3.944 | 4619.5 samples/s | 72.2 steps/s
[Step=8900 Epoch=17.4] | Loss=0.05598 | Reg=0.00361 | acc=0.9531 | L2-Norm=18.990 | L2-Norm(final)=3.937 | 4657.9 samples/s | 72.8 steps/s
[Step=8950 Epoch=17.5] | Loss=0.05459 | Reg=0.00361 | acc=0.9688 | L2-Norm=19.003 | L2-Norm(final)=3.931 | 4649.6 samples/s | 72.7 steps/s
[Step=9000 Epoch=17.6] | Loss=0.05430 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.016 | L2-Norm(final)=3.924 | 6015.2 samples/s | 94.0 steps/s
[Step=9050 Epoch=17.7] | Loss=0.05196 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.029 | L2-Norm(final)=3.919 | 2442.8 samples/s | 38.2 steps/s
[Step=9100 Epoch=17.8] | Loss=0.04992 | Reg=0.00363 | acc=0.9375 | L2-Norm=19.040 | L2-Norm(final)=3.916 | 4650.0 samples/s | 72.7 steps/s
[Step=9150 Epoch=17.9] | Loss=0.04868 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.051 | L2-Norm(final)=3.914 | 4583.0 samples/s | 71.6 steps/s
[Step=9200 Epoch=18.0] | Loss=0.04772 | Reg=0.00363 | acc=0.9688 | L2-Norm=19.062 | L2-Norm(final)=3.911 | 4632.2 samples/s | 72.4 steps/s
[Step=9250 Epoch=18.1] | Loss=0.04704 | Reg=0.00364 | acc=0.9375 | L2-Norm=19.072 | L2-Norm(final)=3.909 | 4620.9 samples/s | 72.2 steps/s
[Step=9300 Epoch=18.2] | Loss=0.04647 | Reg=0.00364 | acc=0.9688 | L2-Norm=19.082 | L2-Norm(final)=3.907 | 4630.5 samples/s | 72.4 steps/s
[Step=9350 Epoch=18.3] | Loss=0.04576 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.092 | L2-Norm(final)=3.904 | 4652.6 samples/s | 72.7 steps/s
[Step=9400 Epoch=18.4] | Loss=0.04507 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.103 | L2-Norm(final)=3.902 | 4569.5 samples/s | 71.4 steps/s
[Step=9450 Epoch=18.5] | Loss=0.04440 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.113 | L2-Norm(final)=3.899 | 4648.4 samples/s | 72.6 steps/s
[Step=9500 Epoch=18.6] | Loss=0.04393 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.124 | L2-Norm(final)=3.897 | 5083.2 samples/s | 79.4 steps/s
[Step=9550 Epoch=18.7] | Loss=0.04295 | Reg=0.00366 | acc=0.9375 | L2-Norm=19.134 | L2-Norm(final)=3.894 | 2645.8 samples/s | 41.3 steps/s
[Step=9600 Epoch=18.8] | Loss=0.04207 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.144 | L2-Norm(final)=3.892 | 4639.9 samples/s | 72.5 steps/s
[Step=9650 Epoch=18.9] | Loss=0.04151 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.153 | L2-Norm(final)=3.891 | 4501.6 samples/s | 70.3 steps/s
[Step=9700 Epoch=19.0] | Loss=0.04098 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.162 | L2-Norm(final)=3.888 | 4666.8 samples/s | 72.9 steps/s
[Step=9750 Epoch=19.1] | Loss=0.04031 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.171 | L2-Norm(final)=3.887 | 4580.8 samples/s | 71.6 steps/s
[Step=9800 Epoch=19.2] | Loss=0.03957 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.179 | L2-Norm(final)=3.886 | 4662.4 samples/s | 72.8 steps/s
[Step=9850 Epoch=19.3] | Loss=0.03922 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.187 | L2-Norm(final)=3.885 | 4573.2 samples/s | 71.5 steps/s
[Step=9900 Epoch=19.4] | Loss=0.03897 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.195 | L2-Norm(final)=3.884 | 4697.6 samples/s | 73.4 steps/s
[Step=9950 Epoch=19.5] | Loss=0.03868 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.204 | L2-Norm(final)=3.882 | 4565.8 samples/s | 71.3 steps/s
[Step=10000 Epoch=19.5] | Loss=0.03829 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.212 | L2-Norm(final)=3.880 | 4668.9 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step10000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=30.7] | Loss=0.01810 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.317 | L2-Norm(final)=3.830 | 6233.3 samples/s | 97.4 steps/s
[Step=8050 Epoch=30.8] | Loss=0.01092 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.448 | L2-Norm(final)=3.812 | 4330.8 samples/s | 67.7 steps/s
[Step=8100 Epoch=31.0] | Loss=0.00924 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.525 | L2-Norm(final)=3.836 | 4909.2 samples/s | 76.7 steps/s
[Step=8150 Epoch=31.2] | Loss=0.00794 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.574 | L2-Norm(final)=3.859 | 4910.2 samples/s | 76.7 steps/s
[Step=8200 Epoch=31.4] | Loss=0.00685 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.614 | L2-Norm(final)=3.883 | 4969.3 samples/s | 77.6 steps/s
[Step=8250 Epoch=31.6] | Loss=0.00625 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.651 | L2-Norm(final)=3.910 | 6756.4 samples/s | 105.6 steps/s
[Step=8300 Epoch=31.8] | Loss=0.00576 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.682 | L2-Norm(final)=3.936 | 2483.0 samples/s | 38.8 steps/s
[Step=8350 Epoch=32.0] | Loss=0.00524 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=3.962 | 4904.4 samples/s | 76.6 steps/s
[Step=8400 Epoch=32.2] | Loss=0.00477 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.730 | L2-Norm(final)=3.990 | 4900.0 samples/s | 76.6 steps/s
[Step=8450 Epoch=32.4] | Loss=0.00455 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.749 | L2-Norm(final)=4.017 | 4939.5 samples/s | 77.2 steps/s
[Step=8500 Epoch=32.6] | Loss=0.00451 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.765 | L2-Norm(final)=4.041 | 5669.5 samples/s | 88.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=32.6] | Loss=0.00042 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.914 | L2-Norm(final)=4.278 | 5706.4 samples/s | 89.2 steps/s
[Step=8550 Epoch=32.8] | Loss=0.01458 | Reg=0.00257 | acc=0.9844 | L2-Norm=16.034 | L2-Norm(final)=4.276 | 4193.1 samples/s | 65.5 steps/s
[Step=8600 Epoch=33.0] | Loss=0.01501 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.234 | L2-Norm(final)=4.214 | 4384.9 samples/s | 68.5 steps/s
[Step=8650 Epoch=33.1] | Loss=0.01251 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.336 | L2-Norm(final)=4.189 | 4421.2 samples/s | 69.1 steps/s
[Step=8700 Epoch=33.3] | Loss=0.01051 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.391 | L2-Norm(final)=4.181 | 4366.1 samples/s | 68.2 steps/s
[Step=8750 Epoch=33.5] | Loss=0.00991 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=4.179 | 5880.4 samples/s | 91.9 steps/s
[Step=8800 Epoch=33.7] | Loss=0.00871 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.443 | L2-Norm(final)=4.174 | 2330.9 samples/s | 36.4 steps/s
[Step=8850 Epoch=33.9] | Loss=0.00762 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.451 | L2-Norm(final)=4.172 | 4391.3 samples/s | 68.6 steps/s
[Step=8900 Epoch=34.1] | Loss=0.00673 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.451 | L2-Norm(final)=4.174 | 4362.8 samples/s | 68.2 steps/s
[Step=8950 Epoch=34.3] | Loss=0.00602 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.445 | L2-Norm(final)=4.177 | 4489.6 samples/s | 70.1 steps/s
[Step=9000 Epoch=34.5] | Loss=0.00542 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.433 | L2-Norm(final)=4.180 | 4863.5 samples/s | 76.0 steps/s
[Step=9050 Epoch=34.7] | Loss=0.00493 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.417 | L2-Norm(final)=4.183 | 2494.3 samples/s | 39.0 steps/s
[Step=9100 Epoch=34.9] | Loss=0.00452 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.398 | L2-Norm(final)=4.186 | 4450.2 samples/s | 69.5 steps/s
[Step=9150 Epoch=35.1] | Loss=0.00418 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.377 | L2-Norm(final)=4.188 | 4396.5 samples/s | 68.7 steps/s
[Step=9200 Epoch=35.3] | Loss=0.00388 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=4.191 | 4416.3 samples/s | 69.0 steps/s
[Step=9250 Epoch=35.4] | Loss=0.00362 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=4.193 | 4245.2 samples/s | 66.3 steps/s
[Step=9300 Epoch=35.6] | Loss=0.00340 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.305 | L2-Norm(final)=4.195 | 2755.9 samples/s | 43.1 steps/s
[Step=9350 Epoch=35.8] | Loss=0.00320 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=4.197 | 4395.6 samples/s | 68.7 steps/s
[Step=9400 Epoch=36.0] | Loss=0.00302 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.251 | L2-Norm(final)=4.199 | 4265.1 samples/s | 66.6 steps/s
[Step=9450 Epoch=36.2] | Loss=0.00286 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.223 | L2-Norm(final)=4.200 | 4459.3 samples/s | 69.7 steps/s
[Step=9500 Epoch=36.4] | Loss=0.00272 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.194 | L2-Norm(final)=4.202 | 4280.8 samples/s | 66.9 steps/s
[Step=9550 Epoch=36.6] | Loss=0.00259 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.165 | L2-Norm(final)=4.203 | 2749.9 samples/s | 43.0 steps/s
[Step=9600 Epoch=36.8] | Loss=0.00247 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=4.205 | 4267.5 samples/s | 66.7 steps/s
[Step=9650 Epoch=37.0] | Loss=0.00237 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=4.206 | 4470.1 samples/s | 69.8 steps/s
[Step=9700 Epoch=37.2] | Loss=0.00227 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=4.208 | 4334.8 samples/s | 67.7 steps/s
[Step=9750 Epoch=37.4] | Loss=0.00218 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.044 | L2-Norm(final)=4.209 | 4404.3 samples/s | 68.8 steps/s
[Step=9800 Epoch=37.6] | Loss=0.00209 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.013 | L2-Norm(final)=4.210 | 6406.7 samples/s | 100.1 steps/s
[Step=9850 Epoch=37.7] | Loss=0.00202 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.982 | L2-Norm(final)=4.212 | 2268.7 samples/s | 35.4 steps/s
[Step=9900 Epoch=37.9] | Loss=0.00195 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=4.213 | 4288.3 samples/s | 67.0 steps/s
[Step=9950 Epoch=38.1] | Loss=0.00188 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.919 | L2-Norm(final)=4.214 | 4479.2 samples/s | 70.0 steps/s
[Step=10000 Epoch=38.3] | Loss=0.00182 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.887 | L2-Norm(final)=4.215 | 4371.9 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step10000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=30.8] | Loss=0.03751 | Reg=0.00242 | acc=0.9531 | L2-Norm=15.565 | L2-Norm(final)=3.806 | 6702.5 samples/s | 104.7 steps/s
[Step=8050 Epoch=31.0] | Loss=0.01074 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=3.791 | 4180.6 samples/s | 65.3 steps/s
[Step=8100 Epoch=31.2] | Loss=0.00875 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=3.816 | 5001.3 samples/s | 78.1 steps/s
[Step=8150 Epoch=31.4] | Loss=0.00725 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.842 | L2-Norm(final)=3.836 | 4846.3 samples/s | 75.7 steps/s
[Step=8200 Epoch=31.6] | Loss=0.00645 | Reg=0.00253 | acc=0.9844 | L2-Norm=15.914 | L2-Norm(final)=3.862 | 4981.0 samples/s | 77.8 steps/s
[Step=8250 Epoch=31.8] | Loss=0.00576 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.968 | L2-Norm(final)=3.888 | 6704.8 samples/s | 104.8 steps/s
[Step=8300 Epoch=31.9] | Loss=0.00519 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.011 | L2-Norm(final)=3.916 | 2451.7 samples/s | 38.3 steps/s
[Step=8350 Epoch=32.1] | Loss=0.00471 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.044 | L2-Norm(final)=3.943 | 4949.9 samples/s | 77.3 steps/s
[Step=8400 Epoch=32.3] | Loss=0.00433 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=3.969 | 4930.5 samples/s | 77.0 steps/s
[Step=8450 Epoch=32.5] | Loss=0.00405 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=3.995 | 5090.1 samples/s | 79.5 steps/s
[Step=8500 Epoch=32.7] | Loss=0.00379 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=4.021 | 5607.5 samples/s | 87.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=32.7] | Loss=0.00297 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.294 | L2-Norm(final)=4.277 | 6512.2 samples/s | 101.8 steps/s
[Step=8550 Epoch=32.9] | Loss=0.00358 | Reg=0.00266 | acc=0.9688 | L2-Norm=16.297 | L2-Norm(final)=4.295 | 4026.1 samples/s | 62.9 steps/s
[Step=8600 Epoch=33.1] | Loss=0.01450 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.467 | L2-Norm(final)=4.244 | 4305.7 samples/s | 67.3 steps/s
[Step=8650 Epoch=33.3] | Loss=0.01212 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.616 | L2-Norm(final)=4.205 | 4452.4 samples/s | 69.6 steps/s
[Step=8700 Epoch=33.5] | Loss=0.01017 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=4.188 | 4344.9 samples/s | 67.9 steps/s
[Step=8750 Epoch=33.7] | Loss=0.01055 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=4.176 | 5970.5 samples/s | 93.3 steps/s
[Step=8800 Epoch=33.9] | Loss=0.00974 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.794 | L2-Norm(final)=4.157 | 2338.1 samples/s | 36.5 steps/s
[Step=8850 Epoch=34.1] | Loss=0.00867 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.821 | L2-Norm(final)=4.145 | 4317.1 samples/s | 67.5 steps/s
[Step=8900 Epoch=34.3] | Loss=0.00773 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.833 | L2-Norm(final)=4.136 | 4395.1 samples/s | 68.7 steps/s
[Step=8950 Epoch=34.5] | Loss=0.00697 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.836 | L2-Norm(final)=4.131 | 4451.1 samples/s | 69.5 steps/s
[Step=9000 Epoch=34.6] | Loss=0.00631 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.832 | L2-Norm(final)=4.127 | 4995.4 samples/s | 78.1 steps/s
[Step=9050 Epoch=34.8] | Loss=0.00576 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.823 | L2-Norm(final)=4.126 | 2474.7 samples/s | 38.7 steps/s
[Step=9100 Epoch=35.0] | Loss=0.00529 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.809 | L2-Norm(final)=4.125 | 4375.7 samples/s | 68.4 steps/s
[Step=9150 Epoch=35.2] | Loss=0.00488 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.792 | L2-Norm(final)=4.124 | 4430.4 samples/s | 69.2 steps/s
[Step=9200 Epoch=35.4] | Loss=0.00453 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.771 | L2-Norm(final)=4.124 | 4325.7 samples/s | 67.6 steps/s
[Step=9250 Epoch=35.6] | Loss=0.00423 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=4.124 | 4487.2 samples/s | 70.1 steps/s
[Step=9300 Epoch=35.8] | Loss=0.00397 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.724 | L2-Norm(final)=4.124 | 2649.2 samples/s | 41.4 steps/s
[Step=9350 Epoch=36.0] | Loss=0.00374 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.698 | L2-Norm(final)=4.124 | 4379.1 samples/s | 68.4 steps/s
[Step=9400 Epoch=36.2] | Loss=0.00353 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.671 | L2-Norm(final)=4.124 | 4396.6 samples/s | 68.7 steps/s
[Step=9450 Epoch=36.4] | Loss=0.00335 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.643 | L2-Norm(final)=4.125 | 4379.3 samples/s | 68.4 steps/s
[Step=9500 Epoch=36.6] | Loss=0.00318 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.614 | L2-Norm(final)=4.126 | 4407.2 samples/s | 68.9 steps/s
[Step=9550 Epoch=36.8] | Loss=0.00303 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.584 | L2-Norm(final)=4.127 | 2694.9 samples/s | 42.1 steps/s
[Step=9600 Epoch=37.0] | Loss=0.00289 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.553 | L2-Norm(final)=4.128 | 4437.3 samples/s | 69.3 steps/s
[Step=9650 Epoch=37.1] | Loss=0.00277 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=4.129 | 4296.7 samples/s | 67.1 steps/s
[Step=9700 Epoch=37.3] | Loss=0.00265 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.490 | L2-Norm(final)=4.131 | 4411.2 samples/s | 68.9 steps/s
[Step=9750 Epoch=37.5] | Loss=0.00255 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.458 | L2-Norm(final)=4.132 | 4390.7 samples/s | 68.6 steps/s
[Step=9800 Epoch=37.7] | Loss=0.00245 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.425 | L2-Norm(final)=4.133 | 7133.5 samples/s | 111.5 steps/s
[Step=9850 Epoch=37.9] | Loss=0.00236 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.392 | L2-Norm(final)=4.135 | 2175.3 samples/s | 34.0 steps/s
[Step=9900 Epoch=38.1] | Loss=0.00227 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.359 | L2-Norm(final)=4.137 | 4395.1 samples/s | 68.7 steps/s
[Step=9950 Epoch=38.3] | Loss=0.00220 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.326 | L2-Norm(final)=4.138 | 4343.8 samples/s | 67.9 steps/s
[Step=10000 Epoch=38.5] | Loss=0.00212 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.292 | L2-Norm(final)=4.140 | 4459.3 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07213 | acc=0.9612 | tpr=0.9724 | fpr=0.0632 | 5491.7 samples/s | 21.5 steps/s
Avg test loss: 0.07382, Avg test acc: 0.95845, Avg tpr: 0.97016, Avg fpr: 0.06730, total FA: 525

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07273 | acc=0.9532 | tpr=0.9604 | fpr=0.0624 | 5232.0 samples/s | 20.4 steps/s
Avg test loss: 0.07739, Avg test acc: 0.95196, Avg tpr: 0.95996, Avg fpr: 0.06563, total FA: 512

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.52896 | acc=0.3157 | tpr=0.0084 | fpr=0.0171 | 5414.6 samples/s | 21.2 steps/s
Avg test loss: 4.54660, Avg test acc: 0.31273, Avg tpr: 0.00769, Avg fpr: 0.01641, total FA: 128

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.85778 | acc=0.3166 | tpr=0.0038 | fpr=0.0040 | 5703.3 samples/s | 22.3 steps/s
Avg test loss: 4.87176, Avg test acc: 0.31393, Avg tpr: 0.00408, Avg fpr: 0.00461, total FA: 36

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.74640 | acc=0.1416 | tpr=0.7699 | fpr=0.8697 | 5587.2 samples/s | 21.8 steps/s
[Step= 100] | Loss=4.72234 | acc=0.1378 | tpr=0.7697 | fpr=0.8740 | 7029.5 samples/s | 27.5 steps/s
[Step= 150] | Loss=4.72197 | acc=0.1363 | tpr=0.7637 | fpr=0.8753 | 7471.8 samples/s | 29.2 steps/s
[Step= 200] | Loss=4.72514 | acc=0.1367 | tpr=0.7563 | fpr=0.8746 | 7914.1 samples/s | 30.9 steps/s
[Step= 250] | Loss=4.72753 | acc=0.1373 | tpr=0.7581 | fpr=0.8740 | 8075.0 samples/s | 31.5 steps/s
[Step= 300] | Loss=4.71995 | acc=0.1373 | tpr=0.7578 | fpr=0.8740 | 8197.8 samples/s | 32.0 steps/s
[Step= 350] | Loss=4.71277 | acc=0.1382 | tpr=0.7627 | fpr=0.8731 | 8050.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=4.71239 | acc=0.1382 | tpr=0.7626 | fpr=0.8731 | 8181.8 samples/s | 32.0 steps/s
[Step= 450] | Loss=4.71145 | acc=0.1380 | tpr=0.7629 | fpr=0.8733 | 8237.4 samples/s | 32.2 steps/s
[Step= 500] | Loss=4.71256 | acc=0.1378 | tpr=0.7670 | fpr=0.8736 | 8117.8 samples/s | 31.7 steps/s
[Step= 550] | Loss=4.70893 | acc=0.1380 | tpr=0.7664 | fpr=0.8734 | 14414.3 samples/s | 56.3 steps/s
Avg test loss: 4.70999, Avg test acc: 0.13798, Avg tpr: 0.76664, Avg fpr: 0.87344, total FA: 121276

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.07326 | acc=0.1610 | tpr=0.7699 | fpr=0.8499 | 5168.5 samples/s | 20.2 steps/s
[Step= 100] | Loss=4.05623 | acc=0.1611 | tpr=0.7633 | fpr=0.8502 | 7756.8 samples/s | 30.3 steps/s
[Step= 150] | Loss=4.05583 | acc=0.1605 | tpr=0.7637 | fpr=0.8506 | 7589.9 samples/s | 29.6 steps/s
[Step= 200] | Loss=4.05399 | acc=0.1610 | tpr=0.7585 | fpr=0.8498 | 7685.7 samples/s | 30.0 steps/s
[Step= 250] | Loss=4.05302 | acc=0.1617 | tpr=0.7624 | fpr=0.8492 | 8503.8 samples/s | 33.2 steps/s
[Step= 300] | Loss=4.04716 | acc=0.1610 | tpr=0.7622 | fpr=0.8500 | 8110.4 samples/s | 31.7 steps/s
[Step= 350] | Loss=4.04127 | acc=0.1611 | tpr=0.7621 | fpr=0.8498 | 8146.7 samples/s | 31.8 steps/s
[Step= 400] | Loss=4.03812 | acc=0.1617 | tpr=0.7659 | fpr=0.8493 | 8296.3 samples/s | 32.4 steps/s
[Step= 450] | Loss=4.03934 | acc=0.1616 | tpr=0.7580 | fpr=0.8493 | 8425.7 samples/s | 32.9 steps/s
[Step= 500] | Loss=4.04076 | acc=0.1614 | tpr=0.7577 | fpr=0.8494 | 7973.9 samples/s | 31.1 steps/s
[Step= 550] | Loss=4.03845 | acc=0.1612 | tpr=0.7557 | fpr=0.8496 | 14502.8 samples/s | 56.7 steps/s
Avg test loss: 4.04072, Avg test acc: 0.16111, Avg tpr: 0.75594, Avg fpr: 0.84970, total FA: 117979

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12700 | acc=0.9788 | tpr=0.9336 | fpr=0.0204 | 5258.6 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.13127 | acc=0.9785 | tpr=0.9531 | fpr=0.0210 | 7567.0 samples/s | 29.6 steps/s
[Step= 150] | Loss=0.13544 | acc=0.9779 | tpr=0.9553 | fpr=0.0217 | 7491.6 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.13788 | acc=0.9779 | tpr=0.9552 | fpr=0.0217 | 7980.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.13609 | acc=0.9782 | tpr=0.9537 | fpr=0.0214 | 8270.6 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.13769 | acc=0.9780 | tpr=0.9505 | fpr=0.0215 | 7966.1 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.13946 | acc=0.9778 | tpr=0.9493 | fpr=0.0217 | 8038.4 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.14085 | acc=0.9777 | tpr=0.9469 | fpr=0.0217 | 8316.3 samples/s | 32.5 steps/s
[Step= 450] | Loss=0.14402 | acc=0.9773 | tpr=0.9445 | fpr=0.0221 | 7978.4 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.14338 | acc=0.9774 | tpr=0.9463 | fpr=0.0221 | 8093.4 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.14306 | acc=0.9775 | tpr=0.9451 | fpr=0.0219 | 14906.8 samples/s | 58.2 steps/s
Avg test loss: 0.14271, Avg test acc: 0.97751, Avg tpr: 0.94532, Avg fpr: 0.02190, total FA: 3041

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11189 | acc=0.9799 | tpr=0.9513 | fpr=0.0196 | 5421.6 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.11992 | acc=0.9791 | tpr=0.9488 | fpr=0.0203 | 7119.8 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.12635 | acc=0.9783 | tpr=0.9524 | fpr=0.0212 | 7627.7 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.12867 | acc=0.9782 | tpr=0.9530 | fpr=0.0213 | 8046.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=0.12610 | acc=0.9786 | tpr=0.9511 | fpr=0.0209 | 8310.0 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.12793 | acc=0.9785 | tpr=0.9491 | fpr=0.0210 | 8230.0 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.12918 | acc=0.9783 | tpr=0.9512 | fpr=0.0212 | 7964.9 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.13071 | acc=0.9780 | tpr=0.9502 | fpr=0.0214 | 8191.2 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.13338 | acc=0.9776 | tpr=0.9489 | fpr=0.0218 | 8247.5 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.13281 | acc=0.9777 | tpr=0.9511 | fpr=0.0218 | 7939.1 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.13194 | acc=0.9778 | tpr=0.9515 | fpr=0.0217 | 14505.2 samples/s | 56.7 steps/s
Avg test loss: 0.13170, Avg test acc: 0.97782, Avg tpr: 0.95127, Avg fpr: 0.02169, total FA: 3012

server round 5/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=19.5] | Loss=0.09410 | Reg=0.00325 | acc=0.9219 | L2-Norm=18.022 | L2-Norm(final)=3.696 | 6046.2 samples/s | 94.5 steps/s
[Step=10050 Epoch=19.6] | Loss=0.06707 | Reg=0.00326 | acc=0.9688 | L2-Norm=18.049 | L2-Norm(final)=3.734 | 4824.7 samples/s | 75.4 steps/s
[Step=10100 Epoch=19.7] | Loss=0.06209 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.083 | L2-Norm(final)=3.771 | 5190.9 samples/s | 81.1 steps/s
[Step=10150 Epoch=19.8] | Loss=0.06157 | Reg=0.00328 | acc=0.9688 | L2-Norm=18.116 | L2-Norm(final)=3.806 | 5276.8 samples/s | 82.4 steps/s
[Step=10200 Epoch=19.9] | Loss=0.06087 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.146 | L2-Norm(final)=3.834 | 5328.1 samples/s | 83.3 steps/s
[Step=10250 Epoch=20.0] | Loss=0.05881 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.178 | L2-Norm(final)=3.858 | 5026.5 samples/s | 78.5 steps/s
[Step=10300 Epoch=20.1] | Loss=0.05846 | Reg=0.00332 | acc=0.9531 | L2-Norm=18.208 | L2-Norm(final)=3.883 | 5244.4 samples/s | 81.9 steps/s
[Step=10350 Epoch=20.2] | Loss=0.05922 | Reg=0.00333 | acc=0.9375 | L2-Norm=18.236 | L2-Norm(final)=3.907 | 5235.4 samples/s | 81.8 steps/s
[Step=10400 Epoch=20.3] | Loss=0.05923 | Reg=0.00334 | acc=0.9531 | L2-Norm=18.264 | L2-Norm(final)=3.930 | 5187.3 samples/s | 81.1 steps/s
[Step=10450 Epoch=20.4] | Loss=0.05849 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.292 | L2-Norm(final)=3.953 | 5254.0 samples/s | 82.1 steps/s
[Step=10500 Epoch=20.5] | Loss=0.05796 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.320 | L2-Norm(final)=3.976 | 6888.8 samples/s | 107.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=20.5] | Loss=0.09650 | Reg=0.00346 | acc=0.9219 | L2-Norm=18.593 | L2-Norm(final)=4.197 | 6339.8 samples/s | 99.1 steps/s
[Step=10550 Epoch=20.6] | Loss=0.05469 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.623 | L2-Norm(final)=4.201 | 4189.0 samples/s | 65.5 steps/s
[Step=10600 Epoch=20.7] | Loss=0.05897 | Reg=0.00348 | acc=0.9531 | L2-Norm=18.661 | L2-Norm(final)=4.186 | 4617.4 samples/s | 72.1 steps/s
[Step=10650 Epoch=20.8] | Loss=0.05663 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.691 | L2-Norm(final)=4.174 | 4601.7 samples/s | 71.9 steps/s
[Step=10700 Epoch=20.9] | Loss=0.05517 | Reg=0.00350 | acc=0.9219 | L2-Norm=18.717 | L2-Norm(final)=4.164 | 4718.7 samples/s | 73.7 steps/s
[Step=10750 Epoch=21.0] | Loss=0.05494 | Reg=0.00351 | acc=0.9688 | L2-Norm=18.743 | L2-Norm(final)=4.153 | 4543.1 samples/s | 71.0 steps/s
[Step=10800 Epoch=21.1] | Loss=0.05378 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.767 | L2-Norm(final)=4.145 | 4629.5 samples/s | 72.3 steps/s
[Step=10850 Epoch=21.2] | Loss=0.05401 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.789 | L2-Norm(final)=4.135 | 4660.4 samples/s | 72.8 steps/s
[Step=10900 Epoch=21.3] | Loss=0.05310 | Reg=0.00354 | acc=0.9531 | L2-Norm=18.808 | L2-Norm(final)=4.125 | 4683.1 samples/s | 73.2 steps/s
[Step=10950 Epoch=21.4] | Loss=0.05242 | Reg=0.00354 | acc=0.9688 | L2-Norm=18.826 | L2-Norm(final)=4.117 | 4589.6 samples/s | 71.7 steps/s
[Step=11000 Epoch=21.5] | Loss=0.05120 | Reg=0.00355 | acc=0.9531 | L2-Norm=18.842 | L2-Norm(final)=4.110 | 5994.5 samples/s | 93.7 steps/s
[Step=11050 Epoch=21.6] | Loss=0.04928 | Reg=0.00356 | acc=0.9844 | L2-Norm=18.857 | L2-Norm(final)=4.104 | 2458.6 samples/s | 38.4 steps/s
[Step=11100 Epoch=21.6] | Loss=0.04795 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.871 | L2-Norm(final)=4.099 | 4655.3 samples/s | 72.7 steps/s
[Step=11150 Epoch=21.7] | Loss=0.04640 | Reg=0.00357 | acc=0.9844 | L2-Norm=18.884 | L2-Norm(final)=4.094 | 4671.7 samples/s | 73.0 steps/s
[Step=11200 Epoch=21.8] | Loss=0.04530 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.896 | L2-Norm(final)=4.090 | 4543.0 samples/s | 71.0 steps/s
[Step=11250 Epoch=21.9] | Loss=0.04409 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.907 | L2-Norm(final)=4.087 | 4688.9 samples/s | 73.3 steps/s
[Step=11300 Epoch=22.0] | Loss=0.04345 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.917 | L2-Norm(final)=4.083 | 4568.6 samples/s | 71.4 steps/s
[Step=11350 Epoch=22.1] | Loss=0.04271 | Reg=0.00358 | acc=0.9531 | L2-Norm=18.927 | L2-Norm(final)=4.079 | 4693.5 samples/s | 73.3 steps/s
[Step=11400 Epoch=22.2] | Loss=0.04238 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.938 | L2-Norm(final)=4.075 | 4716.9 samples/s | 73.7 steps/s
[Step=11450 Epoch=22.3] | Loss=0.04225 | Reg=0.00359 | acc=0.9688 | L2-Norm=18.948 | L2-Norm(final)=4.071 | 4510.4 samples/s | 70.5 steps/s
[Step=11500 Epoch=22.4] | Loss=0.04154 | Reg=0.00359 | acc=0.9531 | L2-Norm=18.958 | L2-Norm(final)=4.068 | 5000.5 samples/s | 78.1 steps/s
[Step=11550 Epoch=22.5] | Loss=0.04072 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.967 | L2-Norm(final)=4.064 | 2677.4 samples/s | 41.8 steps/s
[Step=11600 Epoch=22.6] | Loss=0.03965 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.976 | L2-Norm(final)=4.062 | 4649.9 samples/s | 72.7 steps/s
[Step=11650 Epoch=22.7] | Loss=0.03880 | Reg=0.00360 | acc=0.9688 | L2-Norm=18.984 | L2-Norm(final)=4.060 | 4549.4 samples/s | 71.1 steps/s
[Step=11700 Epoch=22.8] | Loss=0.03841 | Reg=0.00361 | acc=0.9375 | L2-Norm=18.992 | L2-Norm(final)=4.058 | 4638.6 samples/s | 72.5 steps/s
[Step=11750 Epoch=22.9] | Loss=0.03793 | Reg=0.00361 | acc=0.9375 | L2-Norm=19.000 | L2-Norm(final)=4.056 | 4582.9 samples/s | 71.6 steps/s
[Step=11800 Epoch=23.0] | Loss=0.03759 | Reg=0.00361 | acc=0.9531 | L2-Norm=19.008 | L2-Norm(final)=4.054 | 4692.6 samples/s | 73.3 steps/s
[Step=11850 Epoch=23.1] | Loss=0.03721 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.015 | L2-Norm(final)=4.052 | 4655.0 samples/s | 72.7 steps/s
[Step=11900 Epoch=23.2] | Loss=0.03683 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.023 | L2-Norm(final)=4.050 | 4575.8 samples/s | 71.5 steps/s
[Step=11950 Epoch=23.3] | Loss=0.03637 | Reg=0.00362 | acc=0.9531 | L2-Norm=19.030 | L2-Norm(final)=4.049 | 4642.6 samples/s | 72.5 steps/s
[Step=12000 Epoch=23.4] | Loss=0.03597 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.036 | L2-Norm(final)=4.047 | 4632.2 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step12000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=19.6] | Loss=0.07663 | Reg=0.00353 | acc=0.9375 | L2-Norm=18.785 | L2-Norm(final)=3.828 | 6270.6 samples/s | 98.0 steps/s
[Step=10050 Epoch=19.6] | Loss=0.07110 | Reg=0.00354 | acc=0.9375 | L2-Norm=18.827 | L2-Norm(final)=3.875 | 4808.9 samples/s | 75.1 steps/s
[Step=10100 Epoch=19.7] | Loss=0.06823 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.871 | L2-Norm(final)=3.910 | 5080.2 samples/s | 79.4 steps/s
[Step=10150 Epoch=19.8] | Loss=0.06784 | Reg=0.00358 | acc=0.9375 | L2-Norm=18.915 | L2-Norm(final)=3.940 | 5213.1 samples/s | 81.5 steps/s
[Step=10200 Epoch=19.9] | Loss=0.06565 | Reg=0.00359 | acc=0.9531 | L2-Norm=18.953 | L2-Norm(final)=3.967 | 5173.4 samples/s | 80.8 steps/s
[Step=10250 Epoch=20.0] | Loss=0.06451 | Reg=0.00361 | acc=0.9531 | L2-Norm=18.990 | L2-Norm(final)=3.995 | 5193.5 samples/s | 81.1 steps/s
[Step=10300 Epoch=20.1] | Loss=0.06353 | Reg=0.00362 | acc=0.9375 | L2-Norm=19.028 | L2-Norm(final)=4.024 | 5279.3 samples/s | 82.5 steps/s
[Step=10350 Epoch=20.2] | Loss=0.06191 | Reg=0.00363 | acc=0.9688 | L2-Norm=19.064 | L2-Norm(final)=4.051 | 5388.0 samples/s | 84.2 steps/s
[Step=10400 Epoch=20.3] | Loss=0.06123 | Reg=0.00365 | acc=0.9375 | L2-Norm=19.099 | L2-Norm(final)=4.079 | 5013.9 samples/s | 78.3 steps/s
[Step=10450 Epoch=20.4] | Loss=0.06058 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.133 | L2-Norm(final)=4.106 | 5172.7 samples/s | 80.8 steps/s
[Step=10500 Epoch=20.5] | Loss=0.06055 | Reg=0.00367 | acc=0.9219 | L2-Norm=19.167 | L2-Norm(final)=4.133 | 7092.8 samples/s | 110.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=20.5] | Loss=0.08583 | Reg=0.00380 | acc=0.9375 | L2-Norm=19.506 | L2-Norm(final)=4.399 | 6769.8 samples/s | 105.8 steps/s
[Step=10550 Epoch=20.6] | Loss=0.05467 | Reg=0.00382 | acc=0.9375 | L2-Norm=19.547 | L2-Norm(final)=4.416 | 4014.4 samples/s | 62.7 steps/s
[Step=10600 Epoch=20.7] | Loss=0.05578 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.584 | L2-Norm(final)=4.402 | 4611.7 samples/s | 72.1 steps/s
[Step=10650 Epoch=20.8] | Loss=0.05492 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.615 | L2-Norm(final)=4.392 | 4670.3 samples/s | 73.0 steps/s
[Step=10700 Epoch=20.9] | Loss=0.05401 | Reg=0.00386 | acc=0.9375 | L2-Norm=19.642 | L2-Norm(final)=4.380 | 4536.4 samples/s | 70.9 steps/s
[Step=10750 Epoch=21.0] | Loss=0.05370 | Reg=0.00387 | acc=0.9375 | L2-Norm=19.665 | L2-Norm(final)=4.371 | 4657.5 samples/s | 72.8 steps/s
[Step=10800 Epoch=21.1] | Loss=0.05228 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.685 | L2-Norm(final)=4.363 | 4603.9 samples/s | 71.9 steps/s
[Step=10850 Epoch=21.2] | Loss=0.05194 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.704 | L2-Norm(final)=4.355 | 4642.3 samples/s | 72.5 steps/s
[Step=10900 Epoch=21.3] | Loss=0.05020 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.722 | L2-Norm(final)=4.348 | 4585.2 samples/s | 71.6 steps/s
[Step=10950 Epoch=21.4] | Loss=0.04913 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.740 | L2-Norm(final)=4.344 | 4631.7 samples/s | 72.4 steps/s
[Step=11000 Epoch=21.5] | Loss=0.04820 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.755 | L2-Norm(final)=4.339 | 6050.1 samples/s | 94.5 steps/s
[Step=11050 Epoch=21.6] | Loss=0.04650 | Reg=0.00391 | acc=0.9531 | L2-Norm=19.769 | L2-Norm(final)=4.335 | 2435.8 samples/s | 38.1 steps/s
[Step=11100 Epoch=21.7] | Loss=0.04498 | Reg=0.00391 | acc=0.9688 | L2-Norm=19.783 | L2-Norm(final)=4.331 | 4649.3 samples/s | 72.6 steps/s
[Step=11150 Epoch=21.8] | Loss=0.04424 | Reg=0.00392 | acc=0.9531 | L2-Norm=19.795 | L2-Norm(final)=4.328 | 4567.2 samples/s | 71.4 steps/s
[Step=11200 Epoch=21.9] | Loss=0.04337 | Reg=0.00392 | acc=0.9688 | L2-Norm=19.806 | L2-Norm(final)=4.324 | 4664.1 samples/s | 72.9 steps/s
[Step=11250 Epoch=22.0] | Loss=0.04257 | Reg=0.00393 | acc=0.9688 | L2-Norm=19.816 | L2-Norm(final)=4.320 | 4543.0 samples/s | 71.0 steps/s
[Step=11300 Epoch=22.1] | Loss=0.04228 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.826 | L2-Norm(final)=4.316 | 4655.8 samples/s | 72.7 steps/s
[Step=11350 Epoch=22.2] | Loss=0.04143 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.835 | L2-Norm(final)=4.312 | 4645.7 samples/s | 72.6 steps/s
[Step=11400 Epoch=22.3] | Loss=0.04070 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.843 | L2-Norm(final)=4.309 | 4618.1 samples/s | 72.2 steps/s
[Step=11450 Epoch=22.4] | Loss=0.04027 | Reg=0.00394 | acc=0.9688 | L2-Norm=19.851 | L2-Norm(final)=4.305 | 4656.6 samples/s | 72.8 steps/s
[Step=11500 Epoch=22.5] | Loss=0.03984 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.859 | L2-Norm(final)=4.302 | 5103.8 samples/s | 79.7 steps/s
[Step=11550 Epoch=22.6] | Loss=0.03899 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.867 | L2-Norm(final)=4.300 | 2635.7 samples/s | 41.2 steps/s
[Step=11600 Epoch=22.7] | Loss=0.03825 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.874 | L2-Norm(final)=4.298 | 4620.7 samples/s | 72.2 steps/s
[Step=11650 Epoch=22.8] | Loss=0.03770 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.881 | L2-Norm(final)=4.297 | 4614.0 samples/s | 72.1 steps/s
[Step=11700 Epoch=22.9] | Loss=0.03697 | Reg=0.00396 | acc=0.9688 | L2-Norm=19.887 | L2-Norm(final)=4.296 | 4627.9 samples/s | 72.3 steps/s
[Step=11750 Epoch=23.0] | Loss=0.03662 | Reg=0.00396 | acc=0.9688 | L2-Norm=19.895 | L2-Norm(final)=4.294 | 4608.6 samples/s | 72.0 steps/s
[Step=11800 Epoch=23.1] | Loss=0.03620 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.902 | L2-Norm(final)=4.292 | 4634.4 samples/s | 72.4 steps/s
[Step=11850 Epoch=23.2] | Loss=0.03582 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.909 | L2-Norm(final)=4.290 | 4646.4 samples/s | 72.6 steps/s
[Step=11900 Epoch=23.3] | Loss=0.03565 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.916 | L2-Norm(final)=4.288 | 4613.0 samples/s | 72.1 steps/s
[Step=11950 Epoch=23.4] | Loss=0.03548 | Reg=0.00397 | acc=1.0000 | L2-Norm=19.924 | L2-Norm(final)=4.286 | 4665.8 samples/s | 72.9 steps/s
[Step=12000 Epoch=23.5] | Loss=0.03515 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.931 | L2-Norm(final)=4.284 | 4570.8 samples/s | 71.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step12000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=38.3] | Loss=0.01984 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.790 | L2-Norm(final)=4.252 | 6199.8 samples/s | 96.9 steps/s
[Step=10050 Epoch=38.5] | Loss=0.00887 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.961 | L2-Norm(final)=4.238 | 4145.8 samples/s | 64.8 steps/s
[Step=10100 Epoch=38.7] | Loss=0.00715 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=4.251 | 4991.5 samples/s | 78.0 steps/s
[Step=10150 Epoch=38.9] | Loss=0.00592 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=4.274 | 4820.8 samples/s | 75.3 steps/s
[Step=10200 Epoch=39.1] | Loss=0.00471 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.175 | L2-Norm(final)=4.299 | 5069.5 samples/s | 79.2 steps/s
[Step=10250 Epoch=39.3] | Loss=0.00431 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=4.325 | 6543.5 samples/s | 102.2 steps/s
[Step=10300 Epoch=39.5] | Loss=0.00384 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.222 | L2-Norm(final)=4.347 | 2504.2 samples/s | 39.1 steps/s
[Step=10350 Epoch=39.7] | Loss=0.00344 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=4.369 | 4810.3 samples/s | 75.2 steps/s
[Step=10400 Epoch=39.8] | Loss=0.00312 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=4.391 | 4935.3 samples/s | 77.1 steps/s
[Step=10450 Epoch=40.0] | Loss=0.00294 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.244 | L2-Norm(final)=4.415 | 4912.3 samples/s | 76.8 steps/s
[Step=10500 Epoch=40.2] | Loss=0.00281 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.248 | L2-Norm(final)=4.436 | 5619.8 samples/s | 87.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=40.2] | Loss=0.00020 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.286 | L2-Norm(final)=4.653 | 6042.8 samples/s | 94.4 steps/s
[Step=10550 Epoch=40.4] | Loss=0.00046 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.279 | L2-Norm(final)=4.675 | 4015.1 samples/s | 62.7 steps/s
[Step=10600 Epoch=40.6] | Loss=0.00880 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.297 | L2-Norm(final)=4.677 | 4469.5 samples/s | 69.8 steps/s
[Step=10650 Epoch=40.8] | Loss=0.01285 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.521 | L2-Norm(final)=4.592 | 4351.8 samples/s | 68.0 steps/s
[Step=10700 Epoch=41.0] | Loss=0.01231 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.671 | L2-Norm(final)=4.531 | 4429.8 samples/s | 69.2 steps/s
[Step=10750 Epoch=41.2] | Loss=0.01102 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.760 | L2-Norm(final)=4.498 | 5717.0 samples/s | 89.3 steps/s
[Step=10800 Epoch=41.4] | Loss=0.00946 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.814 | L2-Norm(final)=4.477 | 2334.9 samples/s | 36.5 steps/s
[Step=10850 Epoch=41.6] | Loss=0.00826 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.846 | L2-Norm(final)=4.465 | 4397.7 samples/s | 68.7 steps/s
[Step=10900 Epoch=41.8] | Loss=0.00729 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.865 | L2-Norm(final)=4.460 | 4399.1 samples/s | 68.7 steps/s
[Step=10950 Epoch=42.0] | Loss=0.00650 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.874 | L2-Norm(final)=4.456 | 4465.4 samples/s | 69.8 steps/s
[Step=11000 Epoch=42.1] | Loss=0.00587 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.875 | L2-Norm(final)=4.454 | 4874.5 samples/s | 76.2 steps/s
[Step=11050 Epoch=42.3] | Loss=0.00534 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.871 | L2-Norm(final)=4.454 | 2525.8 samples/s | 39.5 steps/s
[Step=11100 Epoch=42.5] | Loss=0.00490 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=4.454 | 4410.8 samples/s | 68.9 steps/s
[Step=11150 Epoch=42.7] | Loss=0.00453 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.851 | L2-Norm(final)=4.454 | 4412.2 samples/s | 68.9 steps/s
[Step=11200 Epoch=42.9] | Loss=0.00420 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.837 | L2-Norm(final)=4.454 | 4411.2 samples/s | 68.9 steps/s
[Step=11250 Epoch=43.1] | Loss=0.00393 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.820 | L2-Norm(final)=4.455 | 4332.8 samples/s | 67.7 steps/s
[Step=11300 Epoch=43.3] | Loss=0.00368 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.802 | L2-Norm(final)=4.456 | 2683.7 samples/s | 41.9 steps/s
[Step=11350 Epoch=43.5] | Loss=0.00347 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=4.457 | 4403.4 samples/s | 68.8 steps/s
[Step=11400 Epoch=43.7] | Loss=0.00327 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.761 | L2-Norm(final)=4.458 | 4431.9 samples/s | 69.2 steps/s
[Step=11450 Epoch=43.9] | Loss=0.00310 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.739 | L2-Norm(final)=4.459 | 4438.6 samples/s | 69.4 steps/s
[Step=11500 Epoch=44.1] | Loss=0.00295 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.716 | L2-Norm(final)=4.460 | 4311.1 samples/s | 67.4 steps/s
[Step=11550 Epoch=44.3] | Loss=0.00281 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.693 | L2-Norm(final)=4.461 | 2703.4 samples/s | 42.2 steps/s
[Step=11600 Epoch=44.4] | Loss=0.00268 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.668 | L2-Norm(final)=4.462 | 4382.0 samples/s | 68.5 steps/s
[Step=11650 Epoch=44.6] | Loss=0.00256 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.643 | L2-Norm(final)=4.463 | 4414.8 samples/s | 69.0 steps/s
[Step=11700 Epoch=44.8] | Loss=0.00246 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=4.464 | 4475.5 samples/s | 69.9 steps/s
[Step=11750 Epoch=45.0] | Loss=0.00236 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=4.465 | 4336.7 samples/s | 67.8 steps/s
[Step=11800 Epoch=45.2] | Loss=0.00227 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=4.466 | 6400.0 samples/s | 100.0 steps/s
[Step=11850 Epoch=45.4] | Loss=0.00219 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.540 | L2-Norm(final)=4.467 | 2260.9 samples/s | 35.3 steps/s
[Step=11900 Epoch=45.6] | Loss=0.00211 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=4.468 | 4375.3 samples/s | 68.4 steps/s
[Step=11950 Epoch=45.8] | Loss=0.00204 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=4.469 | 4435.8 samples/s | 69.3 steps/s
[Step=12000 Epoch=46.0] | Loss=0.00197 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.458 | L2-Norm(final)=4.470 | 4322.0 samples/s | 67.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step12000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=38.5] | Loss=0.02636 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.083 | L2-Norm(final)=4.200 | 5531.5 samples/s | 86.4 steps/s
[Step=10050 Epoch=38.7] | Loss=0.01008 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=4.190 | 4554.5 samples/s | 71.2 steps/s
[Step=10100 Epoch=38.9] | Loss=0.00611 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.404 | L2-Norm(final)=4.215 | 4961.7 samples/s | 77.5 steps/s
[Step=10150 Epoch=39.1] | Loss=0.00492 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.450 | L2-Norm(final)=4.241 | 4891.2 samples/s | 76.4 steps/s
[Step=10200 Epoch=39.3] | Loss=0.00430 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=4.265 | 4875.9 samples/s | 76.2 steps/s
[Step=10250 Epoch=39.5] | Loss=0.00387 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.521 | L2-Norm(final)=4.291 | 6948.5 samples/s | 108.6 steps/s
[Step=10300 Epoch=39.6] | Loss=0.00334 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=4.314 | 2462.4 samples/s | 38.5 steps/s
[Step=10350 Epoch=39.8] | Loss=0.00303 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=4.338 | 4866.7 samples/s | 76.0 steps/s
[Step=10400 Epoch=40.0] | Loss=0.00271 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.576 | L2-Norm(final)=4.361 | 4903.2 samples/s | 76.6 steps/s
[Step=10450 Epoch=40.2] | Loss=0.00244 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=4.383 | 4911.5 samples/s | 76.7 steps/s
[Step=10500 Epoch=40.4] | Loss=0.00235 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=4.406 | 5795.4 samples/s | 90.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=40.4] | Loss=0.00035 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=4.642 | 6478.5 samples/s | 101.2 steps/s
[Step=10550 Epoch=40.6] | Loss=0.02114 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=4.548 | 3817.8 samples/s | 59.7 steps/s
[Step=10600 Epoch=40.8] | Loss=0.01641 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=4.483 | 4382.9 samples/s | 68.5 steps/s
[Step=10650 Epoch=41.0] | Loss=0.01297 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.239 | L2-Norm(final)=4.462 | 4464.5 samples/s | 69.8 steps/s
[Step=10700 Epoch=41.2] | Loss=0.01072 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.292 | L2-Norm(final)=4.456 | 4442.2 samples/s | 69.4 steps/s
[Step=10750 Epoch=41.4] | Loss=0.00901 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.319 | L2-Norm(final)=4.453 | 5707.8 samples/s | 89.2 steps/s
[Step=10800 Epoch=41.6] | Loss=0.00767 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=4.453 | 2304.6 samples/s | 36.0 steps/s
[Step=10850 Epoch=41.8] | Loss=0.00668 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=4.456 | 4436.8 samples/s | 69.3 steps/s
[Step=10900 Epoch=42.0] | Loss=0.00647 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=4.455 | 4490.7 samples/s | 70.2 steps/s
[Step=10950 Epoch=42.2] | Loss=0.00586 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.332 | L2-Norm(final)=4.453 | 4280.1 samples/s | 66.9 steps/s
[Step=11000 Epoch=42.3] | Loss=0.00531 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.329 | L2-Norm(final)=4.453 | 5163.8 samples/s | 80.7 steps/s
[Step=11050 Epoch=42.5] | Loss=0.00484 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.321 | L2-Norm(final)=4.454 | 2513.8 samples/s | 39.3 steps/s
[Step=11100 Epoch=42.7] | Loss=0.00444 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=4.456 | 4263.6 samples/s | 66.6 steps/s
[Step=11150 Epoch=42.9] | Loss=0.00411 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.291 | L2-Norm(final)=4.458 | 4434.1 samples/s | 69.3 steps/s
[Step=11200 Epoch=43.1] | Loss=0.00382 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.272 | L2-Norm(final)=4.460 | 4348.5 samples/s | 67.9 steps/s
[Step=11250 Epoch=43.3] | Loss=0.00357 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.251 | L2-Norm(final)=4.462 | 4522.3 samples/s | 70.7 steps/s
[Step=11300 Epoch=43.5] | Loss=0.00335 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.228 | L2-Norm(final)=4.464 | 2680.2 samples/s | 41.9 steps/s
[Step=11350 Epoch=43.7] | Loss=0.00315 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.204 | L2-Norm(final)=4.466 | 4376.7 samples/s | 68.4 steps/s
[Step=11400 Epoch=43.9] | Loss=0.00298 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.178 | L2-Norm(final)=4.469 | 4322.0 samples/s | 67.5 steps/s
[Step=11450 Epoch=44.1] | Loss=0.00282 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.151 | L2-Norm(final)=4.472 | 4362.0 samples/s | 68.2 steps/s
[Step=11500 Epoch=44.3] | Loss=0.00268 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.124 | L2-Norm(final)=4.476 | 4385.9 samples/s | 68.5 steps/s
[Step=11550 Epoch=44.5] | Loss=0.00255 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=4.479 | 2708.5 samples/s | 42.3 steps/s
[Step=11600 Epoch=44.7] | Loss=0.00244 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=4.483 | 4455.2 samples/s | 69.6 steps/s
[Step=11650 Epoch=44.8] | Loss=0.00233 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.036 | L2-Norm(final)=4.487 | 4497.4 samples/s | 70.3 steps/s
[Step=11700 Epoch=45.0] | Loss=0.00224 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.006 | L2-Norm(final)=4.491 | 4245.7 samples/s | 66.3 steps/s
[Step=11750 Epoch=45.2] | Loss=0.00215 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=4.495 | 4400.4 samples/s | 68.8 steps/s
[Step=11800 Epoch=45.4] | Loss=0.00206 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.944 | L2-Norm(final)=4.499 | 7067.0 samples/s | 110.4 steps/s
[Step=11850 Epoch=45.6] | Loss=0.00199 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.912 | L2-Norm(final)=4.503 | 2173.1 samples/s | 34.0 steps/s
[Step=11900 Epoch=45.8] | Loss=0.00192 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=4.507 | 4402.1 samples/s | 68.8 steps/s
[Step=11950 Epoch=46.0] | Loss=0.00185 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.848 | L2-Norm(final)=4.512 | 4449.6 samples/s | 69.5 steps/s
[Step=12000 Epoch=46.2] | Loss=0.00179 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.816 | L2-Norm(final)=4.516 | 4441.5 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06500 | acc=0.9629 | tpr=0.9707 | fpr=0.0540 | 5285.6 samples/s | 20.6 steps/s
Avg test loss: 0.06832, Avg test acc: 0.96158, Avg tpr: 0.96911, Avg fpr: 0.05499, total FA: 429

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07207 | acc=0.9575 | tpr=0.9712 | fpr=0.0723 | 5265.2 samples/s | 20.6 steps/s
Avg test loss: 0.07619, Avg test acc: 0.95665, Avg tpr: 0.97027, Avg fpr: 0.07332, total FA: 572

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.53794 | acc=0.3173 | tpr=0.0039 | fpr=0.0020 | 5574.4 samples/s | 21.8 steps/s
Avg test loss: 4.55216, Avg test acc: 0.31457, Avg tpr: 0.00396, Avg fpr: 0.00231, total FA: 18

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.05920 | acc=0.3131 | tpr=0.0014 | fpr=0.0099 | 5579.5 samples/s | 21.8 steps/s
Avg test loss: 5.06995, Avg test acc: 0.31128, Avg tpr: 0.00187, Avg fpr: 0.00820, total FA: 64

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.69662 | acc=0.1341 | tpr=0.6018 | fpr=0.8743 | 5271.2 samples/s | 20.6 steps/s
[Step= 100] | Loss=4.65483 | acc=0.1339 | tpr=0.5928 | fpr=0.8747 | 7163.1 samples/s | 28.0 steps/s
[Step= 150] | Loss=4.64512 | acc=0.1344 | tpr=0.6066 | fpr=0.8743 | 7847.3 samples/s | 30.7 steps/s
[Step= 200] | Loss=4.64874 | acc=0.1335 | tpr=0.6087 | fpr=0.8752 | 8362.8 samples/s | 32.7 steps/s
[Step= 250] | Loss=4.65190 | acc=0.1340 | tpr=0.6070 | fpr=0.8747 | 7852.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=4.64049 | acc=0.1344 | tpr=0.6124 | fpr=0.8743 | 8754.0 samples/s | 34.2 steps/s
[Step= 350] | Loss=4.63566 | acc=0.1349 | tpr=0.6174 | fpr=0.8739 | 7756.2 samples/s | 30.3 steps/s
[Step= 400] | Loss=4.63721 | acc=0.1355 | tpr=0.6236 | fpr=0.8734 | 7918.4 samples/s | 30.9 steps/s
[Step= 450] | Loss=4.63664 | acc=0.1352 | tpr=0.6212 | fpr=0.8736 | 8259.7 samples/s | 32.3 steps/s
[Step= 500] | Loss=4.63625 | acc=0.1351 | tpr=0.6189 | fpr=0.8736 | 8197.5 samples/s | 32.0 steps/s
[Step= 550] | Loss=4.63564 | acc=0.1352 | tpr=0.6152 | fpr=0.8736 | 14237.1 samples/s | 55.6 steps/s
Avg test loss: 4.63692, Avg test acc: 0.13511, Avg tpr: 0.61569, Avg fpr: 0.87362, total FA: 121301

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.80146 | acc=0.1297 | tpr=0.8053 | fpr=0.8825 | 5462.4 samples/s | 21.3 steps/s
[Step= 100] | Loss=4.75827 | acc=0.1306 | tpr=0.8230 | fpr=0.8823 | 7004.7 samples/s | 27.4 steps/s
[Step= 150] | Loss=4.75758 | acc=0.1303 | tpr=0.8242 | fpr=0.8825 | 7708.6 samples/s | 30.1 steps/s
[Step= 200] | Loss=4.76101 | acc=0.1308 | tpr=0.8142 | fpr=0.8816 | 8075.7 samples/s | 31.5 steps/s
[Step= 250] | Loss=4.75969 | acc=0.1312 | tpr=0.8096 | fpr=0.8811 | 8223.7 samples/s | 32.1 steps/s
[Step= 300] | Loss=4.75906 | acc=0.1318 | tpr=0.8065 | fpr=0.8805 | 8187.5 samples/s | 32.0 steps/s
[Step= 350] | Loss=4.75698 | acc=0.1317 | tpr=0.8096 | fpr=0.8806 | 8052.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=4.75494 | acc=0.1320 | tpr=0.8124 | fpr=0.8804 | 8436.3 samples/s | 33.0 steps/s
[Step= 450] | Loss=4.75607 | acc=0.1312 | tpr=0.8092 | fpr=0.8811 | 7862.4 samples/s | 30.7 steps/s
[Step= 500] | Loss=4.75715 | acc=0.1310 | tpr=0.8132 | fpr=0.8813 | 8212.0 samples/s | 32.1 steps/s
[Step= 550] | Loss=4.75414 | acc=0.1311 | tpr=0.8126 | fpr=0.8813 | 14286.9 samples/s | 55.8 steps/s
Avg test loss: 4.75523, Avg test acc: 0.13104, Avg tpr: 0.81260, Avg fpr: 0.88135, total FA: 122374

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12472 | acc=0.9788 | tpr=0.9381 | fpr=0.0205 | 5163.9 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.12769 | acc=0.9784 | tpr=0.9467 | fpr=0.0210 | 7524.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.13361 | acc=0.9779 | tpr=0.9452 | fpr=0.0215 | 7770.6 samples/s | 30.4 steps/s
[Step= 200] | Loss=0.13623 | acc=0.9779 | tpr=0.9497 | fpr=0.0216 | 8363.6 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.13351 | acc=0.9781 | tpr=0.9476 | fpr=0.0213 | 8268.8 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.13615 | acc=0.9777 | tpr=0.9440 | fpr=0.0217 | 7940.0 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.13757 | acc=0.9774 | tpr=0.9455 | fpr=0.0220 | 8377.9 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.13976 | acc=0.9771 | tpr=0.9420 | fpr=0.0223 | 8250.4 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.14265 | acc=0.9768 | tpr=0.9416 | fpr=0.0225 | 7789.6 samples/s | 30.4 steps/s
[Step= 500] | Loss=0.14166 | acc=0.9770 | tpr=0.9427 | fpr=0.0224 | 8204.4 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.14065 | acc=0.9772 | tpr=0.9427 | fpr=0.0222 | 14910.4 samples/s | 58.2 steps/s
Avg test loss: 0.14032, Avg test acc: 0.97719, Avg tpr: 0.94176, Avg fpr: 0.02216, total FA: 3077

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12107 | acc=0.9798 | tpr=0.9248 | fpr=0.0192 | 5387.3 samples/s | 21.0 steps/s
[Step= 100] | Loss=0.12733 | acc=0.9789 | tpr=0.9403 | fpr=0.0203 | 7778.3 samples/s | 30.4 steps/s
[Step= 150] | Loss=0.13240 | acc=0.9782 | tpr=0.9481 | fpr=0.0212 | 7078.6 samples/s | 27.7 steps/s
[Step= 200] | Loss=0.13547 | acc=0.9782 | tpr=0.9519 | fpr=0.0214 | 8306.3 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.13392 | acc=0.9784 | tpr=0.9520 | fpr=0.0211 | 8164.4 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.13665 | acc=0.9780 | tpr=0.9491 | fpr=0.0215 | 8132.3 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.13745 | acc=0.9778 | tpr=0.9505 | fpr=0.0217 | 7774.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.13946 | acc=0.9776 | tpr=0.9469 | fpr=0.0218 | 8309.0 samples/s | 32.5 steps/s
[Step= 450] | Loss=0.14175 | acc=0.9773 | tpr=0.9445 | fpr=0.0221 | 8210.6 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.14065 | acc=0.9774 | tpr=0.9458 | fpr=0.0220 | 7964.1 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.13967 | acc=0.9775 | tpr=0.9455 | fpr=0.0219 | 14857.2 samples/s | 58.0 steps/s
Avg test loss: 0.13944, Avg test acc: 0.97753, Avg tpr: 0.94532, Avg fpr: 0.02188, total FA: 3038

server round 6/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=23.4] | Loss=0.06471 | Reg=0.00345 | acc=0.9531 | L2-Norm=18.583 | L2-Norm(final)=3.998 | 6403.6 samples/s | 100.1 steps/s
[Step=12050 Epoch=23.5] | Loss=0.06514 | Reg=0.00346 | acc=0.9531 | L2-Norm=18.608 | L2-Norm(final)=4.066 | 4725.9 samples/s | 73.8 steps/s
[Step=12100 Epoch=23.6] | Loss=0.06296 | Reg=0.00347 | acc=0.9375 | L2-Norm=18.634 | L2-Norm(final)=4.120 | 5059.4 samples/s | 79.1 steps/s
[Step=12150 Epoch=23.7] | Loss=0.05953 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.658 | L2-Norm(final)=4.163 | 5263.7 samples/s | 82.2 steps/s
[Step=12200 Epoch=23.8] | Loss=0.05922 | Reg=0.00349 | acc=0.9062 | L2-Norm=18.680 | L2-Norm(final)=4.195 | 5143.0 samples/s | 80.4 steps/s
[Step=12250 Epoch=23.9] | Loss=0.05858 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.700 | L2-Norm(final)=4.220 | 5203.6 samples/s | 81.3 steps/s
[Step=12300 Epoch=24.0] | Loss=0.05813 | Reg=0.00350 | acc=0.9375 | L2-Norm=18.720 | L2-Norm(final)=4.244 | 5275.2 samples/s | 82.4 steps/s
[Step=12350 Epoch=24.1] | Loss=0.05787 | Reg=0.00351 | acc=0.9531 | L2-Norm=18.741 | L2-Norm(final)=4.267 | 5123.5 samples/s | 80.1 steps/s
[Step=12400 Epoch=24.2] | Loss=0.05719 | Reg=0.00352 | acc=0.9688 | L2-Norm=18.762 | L2-Norm(final)=4.288 | 5282.5 samples/s | 82.5 steps/s
[Step=12450 Epoch=24.3] | Loss=0.05807 | Reg=0.00353 | acc=0.9531 | L2-Norm=18.782 | L2-Norm(final)=4.306 | 5215.1 samples/s | 81.5 steps/s
[Step=12500 Epoch=24.4] | Loss=0.05766 | Reg=0.00353 | acc=0.9688 | L2-Norm=18.801 | L2-Norm(final)=4.323 | 6853.1 samples/s | 107.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=24.4] | Loss=0.03240 | Reg=0.00361 | acc=0.9688 | L2-Norm=18.994 | L2-Norm(final)=4.503 | 6189.8 samples/s | 96.7 steps/s
[Step=12550 Epoch=24.5] | Loss=0.06434 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.033 | L2-Norm(final)=4.501 | 4448.8 samples/s | 69.5 steps/s
[Step=12600 Epoch=24.6] | Loss=0.05897 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.080 | L2-Norm(final)=4.487 | 4656.4 samples/s | 72.8 steps/s
[Step=12650 Epoch=24.7] | Loss=0.05798 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.117 | L2-Norm(final)=4.471 | 4589.4 samples/s | 71.7 steps/s
[Step=12700 Epoch=24.8] | Loss=0.05738 | Reg=0.00367 | acc=0.9375 | L2-Norm=19.148 | L2-Norm(final)=4.458 | 4622.8 samples/s | 72.2 steps/s
[Step=12750 Epoch=24.9] | Loss=0.05570 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.177 | L2-Norm(final)=4.445 | 4662.2 samples/s | 72.8 steps/s
[Step=12800 Epoch=25.0] | Loss=0.05317 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.200 | L2-Norm(final)=4.436 | 4644.7 samples/s | 72.6 steps/s
[Step=12850 Epoch=25.1] | Loss=0.05075 | Reg=0.00369 | acc=0.9531 | L2-Norm=19.221 | L2-Norm(final)=4.428 | 4651.6 samples/s | 72.7 steps/s
[Step=12900 Epoch=25.2] | Loss=0.04992 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.241 | L2-Norm(final)=4.421 | 4608.6 samples/s | 72.0 steps/s
[Step=12950 Epoch=25.3] | Loss=0.04927 | Reg=0.00371 | acc=0.9688 | L2-Norm=19.260 | L2-Norm(final)=4.414 | 4634.1 samples/s | 72.4 steps/s
[Step=13000 Epoch=25.4] | Loss=0.04894 | Reg=0.00372 | acc=0.9375 | L2-Norm=19.278 | L2-Norm(final)=4.407 | 5882.3 samples/s | 91.9 steps/s
[Step=13050 Epoch=25.5] | Loss=0.04744 | Reg=0.00372 | acc=0.9688 | L2-Norm=19.296 | L2-Norm(final)=4.401 | 2456.0 samples/s | 38.4 steps/s
[Step=13100 Epoch=25.6] | Loss=0.04563 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.311 | L2-Norm(final)=4.397 | 4624.7 samples/s | 72.3 steps/s
[Step=13150 Epoch=25.6] | Loss=0.04447 | Reg=0.00373 | acc=0.9844 | L2-Norm=19.325 | L2-Norm(final)=4.393 | 4598.2 samples/s | 71.8 steps/s
[Step=13200 Epoch=25.7] | Loss=0.04354 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.338 | L2-Norm(final)=4.387 | 4642.7 samples/s | 72.5 steps/s
[Step=13250 Epoch=25.8] | Loss=0.04234 | Reg=0.00374 | acc=0.9844 | L2-Norm=19.350 | L2-Norm(final)=4.382 | 4690.4 samples/s | 73.3 steps/s
[Step=13300 Epoch=25.9] | Loss=0.04143 | Reg=0.00375 | acc=0.9688 | L2-Norm=19.362 | L2-Norm(final)=4.379 | 4552.6 samples/s | 71.1 steps/s
[Step=13350 Epoch=26.0] | Loss=0.04078 | Reg=0.00375 | acc=0.9531 | L2-Norm=19.373 | L2-Norm(final)=4.375 | 4652.3 samples/s | 72.7 steps/s
[Step=13400 Epoch=26.1] | Loss=0.04033 | Reg=0.00376 | acc=0.9375 | L2-Norm=19.384 | L2-Norm(final)=4.371 | 4652.5 samples/s | 72.7 steps/s
[Step=13450 Epoch=26.2] | Loss=0.03994 | Reg=0.00376 | acc=0.9688 | L2-Norm=19.396 | L2-Norm(final)=4.367 | 4622.9 samples/s | 72.2 steps/s
[Step=13500 Epoch=26.3] | Loss=0.03961 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.408 | L2-Norm(final)=4.363 | 5006.1 samples/s | 78.2 steps/s
[Step=13550 Epoch=26.4] | Loss=0.03898 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.419 | L2-Norm(final)=4.358 | 2661.6 samples/s | 41.6 steps/s
[Step=13600 Epoch=26.5] | Loss=0.03846 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.430 | L2-Norm(final)=4.355 | 4711.8 samples/s | 73.6 steps/s
[Step=13650 Epoch=26.6] | Loss=0.03780 | Reg=0.00378 | acc=0.9531 | L2-Norm=19.440 | L2-Norm(final)=4.351 | 4528.8 samples/s | 70.8 steps/s
[Step=13700 Epoch=26.7] | Loss=0.03720 | Reg=0.00378 | acc=0.9688 | L2-Norm=19.450 | L2-Norm(final)=4.348 | 4597.3 samples/s | 71.8 steps/s
[Step=13750 Epoch=26.8] | Loss=0.03674 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.460 | L2-Norm(final)=4.345 | 4684.0 samples/s | 73.2 steps/s
[Step=13800 Epoch=26.9] | Loss=0.03628 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.469 | L2-Norm(final)=4.342 | 4584.6 samples/s | 71.6 steps/s
[Step=13850 Epoch=27.0] | Loss=0.03578 | Reg=0.00379 | acc=0.9531 | L2-Norm=19.479 | L2-Norm(final)=4.339 | 4637.4 samples/s | 72.5 steps/s
[Step=13900 Epoch=27.1] | Loss=0.03555 | Reg=0.00380 | acc=0.9688 | L2-Norm=19.488 | L2-Norm(final)=4.336 | 4609.4 samples/s | 72.0 steps/s
[Step=13950 Epoch=27.2] | Loss=0.03514 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.498 | L2-Norm(final)=4.333 | 4648.1 samples/s | 72.6 steps/s
[Step=14000 Epoch=27.3] | Loss=0.03470 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.508 | L2-Norm(final)=4.330 | 4652.2 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step14000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=23.5] | Loss=0.09813 | Reg=0.00380 | acc=0.9531 | L2-Norm=19.489 | L2-Norm(final)=4.217 | 6608.6 samples/s | 103.3 steps/s
[Step=12050 Epoch=23.6] | Loss=0.07762 | Reg=0.00381 | acc=0.9375 | L2-Norm=19.521 | L2-Norm(final)=4.295 | 4555.4 samples/s | 71.2 steps/s
[Step=12100 Epoch=23.7] | Loss=0.07133 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.569 | L2-Norm(final)=4.360 | 5273.4 samples/s | 82.4 steps/s
[Step=12150 Epoch=23.8] | Loss=0.06840 | Reg=0.00385 | acc=0.9375 | L2-Norm=19.613 | L2-Norm(final)=4.409 | 5072.1 samples/s | 79.3 steps/s
[Step=12200 Epoch=23.9] | Loss=0.06667 | Reg=0.00386 | acc=0.9531 | L2-Norm=19.655 | L2-Norm(final)=4.450 | 5218.2 samples/s | 81.5 steps/s
[Step=12250 Epoch=23.9] | Loss=0.06593 | Reg=0.00388 | acc=0.9531 | L2-Norm=19.693 | L2-Norm(final)=4.484 | 5020.3 samples/s | 78.4 steps/s
[Step=12300 Epoch=24.0] | Loss=0.06616 | Reg=0.00389 | acc=0.9219 | L2-Norm=19.728 | L2-Norm(final)=4.514 | 5133.7 samples/s | 80.2 steps/s
[Step=12350 Epoch=24.1] | Loss=0.06573 | Reg=0.00391 | acc=0.9531 | L2-Norm=19.762 | L2-Norm(final)=4.539 | 5171.7 samples/s | 80.8 steps/s
[Step=12400 Epoch=24.2] | Loss=0.06494 | Reg=0.00392 | acc=0.9062 | L2-Norm=19.795 | L2-Norm(final)=4.566 | 5213.8 samples/s | 81.5 steps/s
[Step=12450 Epoch=24.3] | Loss=0.06425 | Reg=0.00393 | acc=0.9531 | L2-Norm=19.826 | L2-Norm(final)=4.591 | 5221.4 samples/s | 81.6 steps/s
[Step=12500 Epoch=24.4] | Loss=0.06460 | Reg=0.00394 | acc=0.9219 | L2-Norm=19.855 | L2-Norm(final)=4.616 | 7088.0 samples/s | 110.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=24.4] | Loss=0.02883 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.143 | L2-Norm(final)=4.849 | 6163.6 samples/s | 96.3 steps/s
[Step=12550 Epoch=24.5] | Loss=0.05188 | Reg=0.00407 | acc=0.9688 | L2-Norm=20.184 | L2-Norm(final)=4.862 | 4410.8 samples/s | 68.9 steps/s
[Step=12600 Epoch=24.6] | Loss=0.05515 | Reg=0.00409 | acc=0.9844 | L2-Norm=20.235 | L2-Norm(final)=4.844 | 4509.3 samples/s | 70.5 steps/s
[Step=12650 Epoch=24.7] | Loss=0.05633 | Reg=0.00411 | acc=0.8906 | L2-Norm=20.276 | L2-Norm(final)=4.826 | 4610.3 samples/s | 72.0 steps/s
[Step=12700 Epoch=24.8] | Loss=0.05531 | Reg=0.00412 | acc=0.9531 | L2-Norm=20.303 | L2-Norm(final)=4.810 | 4599.0 samples/s | 71.9 steps/s
[Step=12750 Epoch=24.9] | Loss=0.05385 | Reg=0.00413 | acc=0.9375 | L2-Norm=20.323 | L2-Norm(final)=4.795 | 4652.9 samples/s | 72.7 steps/s
[Step=12800 Epoch=25.0] | Loss=0.05216 | Reg=0.00414 | acc=0.9688 | L2-Norm=20.342 | L2-Norm(final)=4.782 | 4620.2 samples/s | 72.2 steps/s
[Step=12850 Epoch=25.1] | Loss=0.05104 | Reg=0.00415 | acc=0.9531 | L2-Norm=20.359 | L2-Norm(final)=4.770 | 4604.4 samples/s | 71.9 steps/s
[Step=12900 Epoch=25.2] | Loss=0.04989 | Reg=0.00415 | acc=0.9219 | L2-Norm=20.374 | L2-Norm(final)=4.761 | 4624.8 samples/s | 72.3 steps/s
[Step=12950 Epoch=25.3] | Loss=0.04913 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.388 | L2-Norm(final)=4.752 | 4666.8 samples/s | 72.9 steps/s
[Step=13000 Epoch=25.4] | Loss=0.04840 | Reg=0.00416 | acc=0.9531 | L2-Norm=20.402 | L2-Norm(final)=4.743 | 5990.5 samples/s | 93.6 steps/s
[Step=13050 Epoch=25.5] | Loss=0.04682 | Reg=0.00417 | acc=0.9844 | L2-Norm=20.416 | L2-Norm(final)=4.736 | 2448.4 samples/s | 38.3 steps/s
[Step=13100 Epoch=25.6] | Loss=0.04532 | Reg=0.00417 | acc=0.9688 | L2-Norm=20.429 | L2-Norm(final)=4.730 | 4583.8 samples/s | 71.6 steps/s
[Step=13150 Epoch=25.7] | Loss=0.04377 | Reg=0.00418 | acc=0.9844 | L2-Norm=20.440 | L2-Norm(final)=4.725 | 4601.9 samples/s | 71.9 steps/s
[Step=13200 Epoch=25.8] | Loss=0.04292 | Reg=0.00418 | acc=0.9531 | L2-Norm=20.450 | L2-Norm(final)=4.721 | 4695.1 samples/s | 73.4 steps/s
[Step=13250 Epoch=25.9] | Loss=0.04194 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.459 | L2-Norm(final)=4.717 | 4541.9 samples/s | 71.0 steps/s
[Step=13300 Epoch=26.0] | Loss=0.04099 | Reg=0.00419 | acc=0.9688 | L2-Norm=20.467 | L2-Norm(final)=4.713 | 4623.4 samples/s | 72.2 steps/s
[Step=13350 Epoch=26.1] | Loss=0.03978 | Reg=0.00419 | acc=0.9531 | L2-Norm=20.475 | L2-Norm(final)=4.711 | 4576.9 samples/s | 71.5 steps/s
[Step=13400 Epoch=26.2] | Loss=0.03891 | Reg=0.00420 | acc=0.9531 | L2-Norm=20.482 | L2-Norm(final)=4.708 | 4660.4 samples/s | 72.8 steps/s
[Step=13450 Epoch=26.3] | Loss=0.03833 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.488 | L2-Norm(final)=4.705 | 4601.5 samples/s | 71.9 steps/s
[Step=13500 Epoch=26.4] | Loss=0.03800 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.495 | L2-Norm(final)=4.702 | 5148.5 samples/s | 80.4 steps/s
[Step=13550 Epoch=26.5] | Loss=0.03741 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.502 | L2-Norm(final)=4.700 | 2638.8 samples/s | 41.2 steps/s
[Step=13600 Epoch=26.6] | Loss=0.03655 | Reg=0.00421 | acc=0.9688 | L2-Norm=20.510 | L2-Norm(final)=4.697 | 4642.9 samples/s | 72.5 steps/s
[Step=13650 Epoch=26.7] | Loss=0.03607 | Reg=0.00421 | acc=0.9531 | L2-Norm=20.517 | L2-Norm(final)=4.695 | 4527.6 samples/s | 70.7 steps/s
[Step=13700 Epoch=26.8] | Loss=0.03544 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.524 | L2-Norm(final)=4.693 | 4655.1 samples/s | 72.7 steps/s
[Step=13750 Epoch=26.9] | Loss=0.03496 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.530 | L2-Norm(final)=4.691 | 4557.9 samples/s | 71.2 steps/s
[Step=13800 Epoch=27.0] | Loss=0.03462 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.536 | L2-Norm(final)=4.689 | 4664.7 samples/s | 72.9 steps/s
[Step=13850 Epoch=27.1] | Loss=0.03417 | Reg=0.00422 | acc=0.9688 | L2-Norm=20.541 | L2-Norm(final)=4.687 | 4608.3 samples/s | 72.0 steps/s
[Step=13900 Epoch=27.2] | Loss=0.03405 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.548 | L2-Norm(final)=4.685 | 4624.6 samples/s | 72.3 steps/s
[Step=13950 Epoch=27.3] | Loss=0.03368 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.554 | L2-Norm(final)=4.684 | 4608.6 samples/s | 72.0 steps/s
[Step=14000 Epoch=27.4] | Loss=0.03337 | Reg=0.00423 | acc=0.9688 | L2-Norm=20.560 | L2-Norm(final)=4.682 | 4614.5 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step14000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=46.0] | Loss=0.03167 | Reg=0.00211 | acc=0.9688 | L2-Norm=14.526 | L2-Norm(final)=4.497 | 6375.2 samples/s | 99.6 steps/s
[Step=12050 Epoch=46.2] | Loss=0.00458 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=4.502 | 4338.4 samples/s | 67.8 steps/s
[Step=12100 Epoch=46.4] | Loss=0.00333 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.745 | L2-Norm(final)=4.521 | 4778.3 samples/s | 74.7 steps/s
[Step=12150 Epoch=46.6] | Loss=0.00264 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.788 | L2-Norm(final)=4.543 | 4984.6 samples/s | 77.9 steps/s
[Step=12200 Epoch=46.7] | Loss=0.00234 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.810 | L2-Norm(final)=4.566 | 4880.7 samples/s | 76.3 steps/s
[Step=12250 Epoch=46.9] | Loss=0.00227 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=4.588 | 6714.8 samples/s | 104.9 steps/s
[Step=12300 Epoch=47.1] | Loss=0.00205 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=4.609 | 2490.4 samples/s | 38.9 steps/s
[Step=12350 Epoch=47.3] | Loss=0.00183 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=4.630 | 4854.8 samples/s | 75.9 steps/s
[Step=12400 Epoch=47.5] | Loss=0.00165 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.846 | L2-Norm(final)=4.651 | 4893.7 samples/s | 76.5 steps/s
[Step=12450 Epoch=47.7] | Loss=0.00150 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.846 | L2-Norm(final)=4.672 | 5061.9 samples/s | 79.1 steps/s
[Step=12500 Epoch=47.9] | Loss=0.00139 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=4.693 | 5457.8 samples/s | 85.3 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=47.9] | Loss=0.00058 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.814 | L2-Norm(final)=4.904 | 6542.6 samples/s | 102.2 steps/s
[Step=12550 Epoch=48.1] | Loss=0.01656 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=4.884 | 3907.8 samples/s | 61.1 steps/s
[Step=12600 Epoch=48.3] | Loss=0.01509 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=4.786 | 4374.9 samples/s | 68.4 steps/s
[Step=12650 Epoch=48.5] | Loss=0.01241 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.442 | L2-Norm(final)=4.746 | 4338.1 samples/s | 67.8 steps/s
[Step=12700 Epoch=48.7] | Loss=0.01010 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=4.726 | 4383.3 samples/s | 68.5 steps/s
[Step=12750 Epoch=48.9] | Loss=0.00887 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.561 | L2-Norm(final)=4.716 | 5892.5 samples/s | 92.1 steps/s
[Step=12800 Epoch=49.0] | Loss=0.00779 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=4.709 | 2323.1 samples/s | 36.3 steps/s
[Step=12850 Epoch=49.2] | Loss=0.00670 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.594 | L2-Norm(final)=4.707 | 4437.6 samples/s | 69.3 steps/s
[Step=12900 Epoch=49.4] | Loss=0.00588 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.594 | L2-Norm(final)=4.707 | 4387.0 samples/s | 68.5 steps/s
[Step=12950 Epoch=49.6] | Loss=0.00526 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.588 | L2-Norm(final)=4.708 | 4443.7 samples/s | 69.4 steps/s
[Step=13000 Epoch=49.8] | Loss=0.00474 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.577 | L2-Norm(final)=4.710 | 4863.0 samples/s | 76.0 steps/s
[Step=13050 Epoch=50.0] | Loss=0.00431 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=4.712 | 2511.2 samples/s | 39.2 steps/s
[Step=13100 Epoch=50.2] | Loss=0.00395 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.547 | L2-Norm(final)=4.714 | 4359.9 samples/s | 68.1 steps/s
[Step=13150 Epoch=50.4] | Loss=0.00365 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.528 | L2-Norm(final)=4.716 | 4404.3 samples/s | 68.8 steps/s
[Step=13200 Epoch=50.6] | Loss=0.00339 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=4.718 | 4373.0 samples/s | 68.3 steps/s
[Step=13250 Epoch=50.8] | Loss=0.00317 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=4.719 | 4349.9 samples/s | 68.0 steps/s
[Step=13300 Epoch=51.0] | Loss=0.00297 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.462 | L2-Norm(final)=4.721 | 2717.6 samples/s | 42.5 steps/s
[Step=13350 Epoch=51.2] | Loss=0.00279 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.438 | L2-Norm(final)=4.723 | 4302.7 samples/s | 67.2 steps/s
[Step=13400 Epoch=51.3] | Loss=0.00264 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=4.724 | 4426.6 samples/s | 69.2 steps/s
[Step=13450 Epoch=51.5] | Loss=0.00250 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.389 | L2-Norm(final)=4.726 | 4331.0 samples/s | 67.7 steps/s
[Step=13500 Epoch=51.7] | Loss=0.00238 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=4.729 | 4388.1 samples/s | 68.6 steps/s
[Step=13550 Epoch=51.9] | Loss=0.00226 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.337 | L2-Norm(final)=4.731 | 2768.9 samples/s | 43.3 steps/s
[Step=13600 Epoch=52.1] | Loss=0.00216 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=4.734 | 4224.2 samples/s | 66.0 steps/s
[Step=13650 Epoch=52.3] | Loss=0.00207 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.284 | L2-Norm(final)=4.737 | 4333.2 samples/s | 67.7 steps/s
[Step=13700 Epoch=52.5] | Loss=0.00198 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=4.739 | 4378.8 samples/s | 68.4 steps/s
[Step=13750 Epoch=52.7] | Loss=0.00190 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=4.742 | 4357.5 samples/s | 68.1 steps/s
[Step=13800 Epoch=52.9] | Loss=0.00183 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.203 | L2-Norm(final)=4.745 | 6532.4 samples/s | 102.1 steps/s
[Step=13850 Epoch=53.1] | Loss=0.00176 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.175 | L2-Norm(final)=4.748 | 2247.0 samples/s | 35.1 steps/s
[Step=13900 Epoch=53.3] | Loss=0.00170 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=4.751 | 4437.7 samples/s | 69.3 steps/s
[Step=13950 Epoch=53.5] | Loss=0.00164 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=4.754 | 4333.3 samples/s | 67.7 steps/s
[Step=14000 Epoch=53.6] | Loss=0.00159 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.092 | L2-Norm(final)=4.757 | 4367.4 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step14000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=46.2] | Loss=0.00242 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.750 | L2-Norm(final)=4.650 | 6424.2 samples/s | 100.4 steps/s
[Step=12050 Epoch=46.4] | Loss=0.00354 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.820 | L2-Norm(final)=4.675 | 4239.9 samples/s | 66.2 steps/s
[Step=12100 Epoch=46.6] | Loss=0.00244 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=4.682 | 4903.5 samples/s | 76.6 steps/s
[Step=12150 Epoch=46.8] | Loss=0.00201 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.889 | L2-Norm(final)=4.697 | 4986.6 samples/s | 77.9 steps/s
[Step=12200 Epoch=47.0] | Loss=0.00165 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.902 | L2-Norm(final)=4.714 | 4972.3 samples/s | 77.7 steps/s
[Step=12250 Epoch=47.2] | Loss=0.00137 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.906 | L2-Norm(final)=4.732 | 6720.3 samples/s | 105.0 steps/s
[Step=12300 Epoch=47.3] | Loss=0.00149 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=4.746 | 2464.1 samples/s | 38.5 steps/s
[Step=12350 Epoch=47.5] | Loss=0.00134 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=4.762 | 4966.6 samples/s | 77.6 steps/s
[Step=12400 Epoch=47.7] | Loss=0.00125 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=4.778 | 4881.5 samples/s | 76.3 steps/s
[Step=12450 Epoch=47.9] | Loss=0.00115 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=4.793 | 5006.0 samples/s | 78.2 steps/s
[Step=12500 Epoch=48.1] | Loss=0.00108 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=4.808 | 5658.9 samples/s | 88.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=48.1] | Loss=0.00006 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=4.955 | 6771.3 samples/s | 105.8 steps/s
[Step=12550 Epoch=48.3] | Loss=0.00033 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=4.962 | 3844.7 samples/s | 60.1 steps/s
[Step=12600 Epoch=48.5] | Loss=0.01503 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=4.911 | 4431.4 samples/s | 69.2 steps/s
[Step=12650 Epoch=48.7] | Loss=0.01340 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=4.825 | 4368.0 samples/s | 68.2 steps/s
[Step=12700 Epoch=48.9] | Loss=0.01075 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.537 | L2-Norm(final)=4.785 | 4385.5 samples/s | 68.5 steps/s
[Step=12750 Epoch=49.1] | Loss=0.00874 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.622 | L2-Norm(final)=4.767 | 5977.7 samples/s | 93.4 steps/s
[Step=12800 Epoch=49.3] | Loss=0.00731 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.670 | L2-Norm(final)=4.759 | 2331.0 samples/s | 36.4 steps/s
[Step=12850 Epoch=49.5] | Loss=0.00628 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.694 | L2-Norm(final)=4.755 | 4338.9 samples/s | 67.8 steps/s
[Step=12900 Epoch=49.7] | Loss=0.00556 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.703 | L2-Norm(final)=4.754 | 4371.9 samples/s | 68.3 steps/s
[Step=12950 Epoch=49.8] | Loss=0.00501 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=4.754 | 4393.7 samples/s | 68.7 steps/s
[Step=13000 Epoch=50.0] | Loss=0.00461 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.709 | L2-Norm(final)=4.756 | 5125.1 samples/s | 80.1 steps/s
[Step=13050 Epoch=50.2] | Loss=0.00420 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=4.758 | 2518.7 samples/s | 39.4 steps/s
[Step=13100 Epoch=50.4] | Loss=0.00386 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.700 | L2-Norm(final)=4.760 | 4290.0 samples/s | 67.0 steps/s
[Step=13150 Epoch=50.6] | Loss=0.00357 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.689 | L2-Norm(final)=4.763 | 4433.3 samples/s | 69.3 steps/s
[Step=13200 Epoch=50.8] | Loss=0.00332 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=4.766 | 4412.1 samples/s | 68.9 steps/s
[Step=13250 Epoch=51.0] | Loss=0.00310 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.660 | L2-Norm(final)=4.769 | 4408.6 samples/s | 68.9 steps/s
[Step=13300 Epoch=51.2] | Loss=0.00291 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.642 | L2-Norm(final)=4.772 | 2637.4 samples/s | 41.2 steps/s
[Step=13350 Epoch=51.4] | Loss=0.00273 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.622 | L2-Norm(final)=4.774 | 4343.4 samples/s | 67.9 steps/s
[Step=13400 Epoch=51.6] | Loss=0.00258 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=4.777 | 4406.3 samples/s | 68.8 steps/s
[Step=13450 Epoch=51.8] | Loss=0.00245 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=4.779 | 4479.5 samples/s | 70.0 steps/s
[Step=13500 Epoch=52.0] | Loss=0.00233 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.556 | L2-Norm(final)=4.782 | 4366.7 samples/s | 68.2 steps/s
[Step=13550 Epoch=52.2] | Loss=0.00222 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.532 | L2-Norm(final)=4.784 | 2676.7 samples/s | 41.8 steps/s
[Step=13600 Epoch=52.4] | Loss=0.00212 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=4.786 | 4372.9 samples/s | 68.3 steps/s
[Step=13650 Epoch=52.5] | Loss=0.00202 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.482 | L2-Norm(final)=4.788 | 4422.4 samples/s | 69.1 steps/s
[Step=13700 Epoch=52.7] | Loss=0.00194 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.456 | L2-Norm(final)=4.790 | 4341.8 samples/s | 67.8 steps/s
[Step=13750 Epoch=52.9] | Loss=0.00186 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=4.791 | 4389.7 samples/s | 68.6 steps/s
[Step=13800 Epoch=53.1] | Loss=0.00179 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.403 | L2-Norm(final)=4.793 | 7170.0 samples/s | 112.0 steps/s
[Step=13850 Epoch=53.3] | Loss=0.00173 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.377 | L2-Norm(final)=4.795 | 2177.9 samples/s | 34.0 steps/s
[Step=13900 Epoch=53.5] | Loss=0.00166 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=4.797 | 4405.9 samples/s | 68.8 steps/s
[Step=13950 Epoch=53.7] | Loss=0.00161 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=4.799 | 4379.2 samples/s | 68.4 steps/s
[Step=14000 Epoch=53.9] | Loss=0.00155 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=4.800 | 4503.9 samples/s | 70.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07556 | acc=0.9597 | tpr=0.9683 | fpr=0.0590 | 5485.8 samples/s | 21.4 steps/s
Avg test loss: 0.07726, Avg test acc: 0.95909, Avg tpr: 0.96719, Avg fpr: 0.05871, total FA: 458

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06867 | acc=0.9619 | tpr=0.9725 | fpr=0.0612 | 5425.1 samples/s | 21.2 steps/s
Avg test loss: 0.07181, Avg test acc: 0.96085, Avg tpr: 0.97127, Avg fpr: 0.06204, total FA: 484

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.54762 | acc=0.3116 | tpr=0.0089 | fpr=0.0312 | 4808.7 samples/s | 18.8 steps/s
Avg test loss: 4.55614, Avg test acc: 0.30924, Avg tpr: 0.00833, Avg fpr: 0.02897, total FA: 226

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.97313 | acc=0.3130 | tpr=0.0022 | fpr=0.0121 | 5150.2 samples/s | 20.1 steps/s
Avg test loss: 4.98983, Avg test acc: 0.31068, Avg tpr: 0.00227, Avg fpr: 0.01102, total FA: 86

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.05560 | acc=0.1071 | tpr=0.6814 | fpr=0.9032 | 5039.1 samples/s | 19.7 steps/s
[Step= 100] | Loss=6.01489 | acc=0.1079 | tpr=0.7207 | fpr=0.9035 | 7466.0 samples/s | 29.2 steps/s
[Step= 150] | Loss=6.01300 | acc=0.1076 | tpr=0.7219 | fpr=0.9037 | 8281.7 samples/s | 32.4 steps/s
[Step= 200] | Loss=6.01477 | acc=0.1074 | tpr=0.7257 | fpr=0.9038 | 7944.9 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.02272 | acc=0.1079 | tpr=0.7336 | fpr=0.9035 | 8299.4 samples/s | 32.4 steps/s
[Step= 300] | Loss=6.01780 | acc=0.1078 | tpr=0.7345 | fpr=0.9036 | 7962.4 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.01294 | acc=0.1085 | tpr=0.7320 | fpr=0.9028 | 8099.2 samples/s | 31.6 steps/s
[Step= 400] | Loss=6.00870 | acc=0.1090 | tpr=0.7380 | fpr=0.9024 | 6006.9 samples/s | 23.5 steps/s
[Step= 450] | Loss=6.00906 | acc=0.1087 | tpr=0.7429 | fpr=0.9028 | 7939.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.00888 | acc=0.1083 | tpr=0.7427 | fpr=0.9031 | 8266.7 samples/s | 32.3 steps/s
[Step= 550] | Loss=6.00767 | acc=0.1083 | tpr=0.7425 | fpr=0.9032 | 14393.0 samples/s | 56.2 steps/s
Avg test loss: 6.00877, Avg test acc: 0.10825, Avg tpr: 0.74287, Avg fpr: 0.90328, total FA: 125419

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.03663 | acc=0.1201 | tpr=0.7655 | fpr=0.8915 | 5197.2 samples/s | 20.3 steps/s
[Step= 100] | Loss=4.99383 | acc=0.1217 | tpr=0.7591 | fpr=0.8902 | 7272.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=4.99835 | acc=0.1230 | tpr=0.7594 | fpr=0.8887 | 7811.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.00002 | acc=0.1227 | tpr=0.7585 | fpr=0.8889 | 7715.4 samples/s | 30.1 steps/s
[Step= 250] | Loss=4.99893 | acc=0.1229 | tpr=0.7528 | fpr=0.8886 | 7998.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=4.99654 | acc=0.1231 | tpr=0.7520 | fpr=0.8884 | 7970.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.99125 | acc=0.1238 | tpr=0.7545 | fpr=0.8876 | 6559.2 samples/s | 25.6 steps/s
[Step= 400] | Loss=4.98612 | acc=0.1239 | tpr=0.7571 | fpr=0.8876 | 7871.2 samples/s | 30.7 steps/s
[Step= 450] | Loss=4.98521 | acc=0.1239 | tpr=0.7571 | fpr=0.8875 | 8140.8 samples/s | 31.8 steps/s
[Step= 500] | Loss=4.98521 | acc=0.1235 | tpr=0.7599 | fpr=0.8880 | 7847.1 samples/s | 30.7 steps/s
[Step= 550] | Loss=4.98209 | acc=0.1236 | tpr=0.7593 | fpr=0.8880 | 14904.7 samples/s | 58.2 steps/s
Avg test loss: 4.98405, Avg test acc: 0.12348, Avg tpr: 0.75990, Avg fpr: 0.88809, total FA: 123309

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12007 | acc=0.9802 | tpr=0.9381 | fpr=0.0191 | 5126.3 samples/s | 20.0 steps/s
[Step= 100] | Loss=0.12374 | acc=0.9800 | tpr=0.9595 | fpr=0.0196 | 7281.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.13056 | acc=0.9788 | tpr=0.9539 | fpr=0.0207 | 7955.7 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.13271 | acc=0.9789 | tpr=0.9530 | fpr=0.0207 | 7944.0 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.13113 | acc=0.9792 | tpr=0.9511 | fpr=0.0203 | 8000.5 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.13317 | acc=0.9790 | tpr=0.9476 | fpr=0.0205 | 8162.7 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.13446 | acc=0.9787 | tpr=0.9468 | fpr=0.0207 | 6467.1 samples/s | 25.3 steps/s
[Step= 400] | Loss=0.13639 | acc=0.9786 | tpr=0.9453 | fpr=0.0208 | 7886.6 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.13986 | acc=0.9782 | tpr=0.9435 | fpr=0.0212 | 8121.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.13913 | acc=0.9782 | tpr=0.9449 | fpr=0.0212 | 8152.0 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.13809 | acc=0.9785 | tpr=0.9455 | fpr=0.0209 | 14263.4 samples/s | 55.7 steps/s
Avg test loss: 0.13773, Avg test acc: 0.97846, Avg tpr: 0.94453, Avg fpr: 0.02092, total FA: 2905

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12484 | acc=0.9812 | tpr=0.9336 | fpr=0.0179 | 5152.2 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.13196 | acc=0.9803 | tpr=0.9403 | fpr=0.0190 | 7481.4 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.13703 | acc=0.9796 | tpr=0.9496 | fpr=0.0198 | 7081.8 samples/s | 27.7 steps/s
[Step= 200] | Loss=0.14033 | acc=0.9794 | tpr=0.9475 | fpr=0.0200 | 8299.7 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.13837 | acc=0.9795 | tpr=0.9467 | fpr=0.0199 | 7847.9 samples/s | 30.7 steps/s
[Step= 300] | Loss=0.14103 | acc=0.9791 | tpr=0.9469 | fpr=0.0203 | 8091.5 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.14270 | acc=0.9790 | tpr=0.9474 | fpr=0.0205 | 6458.7 samples/s | 25.2 steps/s
[Step= 400] | Loss=0.14430 | acc=0.9788 | tpr=0.9453 | fpr=0.0206 | 8296.5 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.14649 | acc=0.9785 | tpr=0.9430 | fpr=0.0209 | 7999.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.14550 | acc=0.9786 | tpr=0.9441 | fpr=0.0207 | 8326.6 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.14462 | acc=0.9787 | tpr=0.9411 | fpr=0.0206 | 13934.8 samples/s | 54.4 steps/s
Avg test loss: 0.14437, Avg test acc: 0.97874, Avg tpr: 0.94097, Avg fpr: 0.02058, total FA: 2857

server round 7/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=27.3] | Loss=0.06454 | Reg=0.00363 | acc=0.9531 | L2-Norm=19.050 | L2-Norm(final)=4.260 | 6337.9 samples/s | 99.0 steps/s
[Step=14050 Epoch=27.4] | Loss=0.05480 | Reg=0.00364 | acc=0.9375 | L2-Norm=19.069 | L2-Norm(final)=4.308 | 4643.9 samples/s | 72.6 steps/s
[Step=14100 Epoch=27.5] | Loss=0.05233 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.098 | L2-Norm(final)=4.352 | 5201.5 samples/s | 81.3 steps/s
[Step=14150 Epoch=27.6] | Loss=0.05069 | Reg=0.00366 | acc=0.9062 | L2-Norm=19.125 | L2-Norm(final)=4.389 | 5220.2 samples/s | 81.6 steps/s
[Step=14200 Epoch=27.7] | Loss=0.04899 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.150 | L2-Norm(final)=4.419 | 5261.8 samples/s | 82.2 steps/s
[Step=14250 Epoch=27.8] | Loss=0.04780 | Reg=0.00368 | acc=0.9688 | L2-Norm=19.173 | L2-Norm(final)=4.447 | 5293.8 samples/s | 82.7 steps/s
[Step=14300 Epoch=27.9] | Loss=0.04729 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.194 | L2-Norm(final)=4.474 | 5302.4 samples/s | 82.9 steps/s
[Step=14350 Epoch=28.0] | Loss=0.04706 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.215 | L2-Norm(final)=4.500 | 4938.1 samples/s | 77.2 steps/s
[Step=14400 Epoch=28.1] | Loss=0.04629 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.236 | L2-Norm(final)=4.525 | 5327.1 samples/s | 83.2 steps/s
[Step=14450 Epoch=28.2] | Loss=0.04569 | Reg=0.00371 | acc=1.0000 | L2-Norm=19.259 | L2-Norm(final)=4.550 | 5256.2 samples/s | 82.1 steps/s
[Step=14500 Epoch=28.3] | Loss=0.04518 | Reg=0.00372 | acc=0.9844 | L2-Norm=19.281 | L2-Norm(final)=4.575 | 6813.9 samples/s | 106.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=28.3] | Loss=0.07044 | Reg=0.00380 | acc=0.9531 | L2-Norm=19.491 | L2-Norm(final)=4.819 | 6162.5 samples/s | 96.3 steps/s
[Step=14550 Epoch=28.4] | Loss=0.04463 | Reg=0.00381 | acc=0.9531 | L2-Norm=19.524 | L2-Norm(final)=4.817 | 4262.1 samples/s | 66.6 steps/s
[Step=14600 Epoch=28.5] | Loss=0.04843 | Reg=0.00383 | acc=0.9375 | L2-Norm=19.564 | L2-Norm(final)=4.797 | 4633.0 samples/s | 72.4 steps/s
[Step=14650 Epoch=28.6] | Loss=0.04914 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.599 | L2-Norm(final)=4.783 | 4647.1 samples/s | 72.6 steps/s
[Step=14700 Epoch=28.7] | Loss=0.04928 | Reg=0.00385 | acc=0.8750 | L2-Norm=19.631 | L2-Norm(final)=4.771 | 4587.1 samples/s | 71.7 steps/s
[Step=14750 Epoch=28.8] | Loss=0.04891 | Reg=0.00386 | acc=0.9688 | L2-Norm=19.659 | L2-Norm(final)=4.758 | 4614.6 samples/s | 72.1 steps/s
[Step=14800 Epoch=28.9] | Loss=0.04818 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.683 | L2-Norm(final)=4.748 | 4741.8 samples/s | 74.1 steps/s
[Step=14850 Epoch=29.0] | Loss=0.04715 | Reg=0.00388 | acc=0.9688 | L2-Norm=19.707 | L2-Norm(final)=4.740 | 4501.2 samples/s | 70.3 steps/s
[Step=14900 Epoch=29.1] | Loss=0.04585 | Reg=0.00389 | acc=0.9688 | L2-Norm=19.729 | L2-Norm(final)=4.733 | 4691.2 samples/s | 73.3 steps/s
[Step=14950 Epoch=29.2] | Loss=0.04495 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.748 | L2-Norm(final)=4.727 | 4574.8 samples/s | 71.5 steps/s
[Step=15000 Epoch=29.3] | Loss=0.04430 | Reg=0.00391 | acc=0.9688 | L2-Norm=19.766 | L2-Norm(final)=4.720 | 5918.9 samples/s | 92.5 steps/s
[Step=15050 Epoch=29.4] | Loss=0.04278 | Reg=0.00391 | acc=0.9688 | L2-Norm=19.784 | L2-Norm(final)=4.714 | 2445.0 samples/s | 38.2 steps/s
[Step=15100 Epoch=29.5] | Loss=0.04158 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.800 | L2-Norm(final)=4.710 | 4659.9 samples/s | 72.8 steps/s
[Step=15150 Epoch=29.5] | Loss=0.04053 | Reg=0.00393 | acc=0.9531 | L2-Norm=19.815 | L2-Norm(final)=4.705 | 4616.6 samples/s | 72.1 steps/s
[Step=15200 Epoch=29.6] | Loss=0.03945 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.829 | L2-Norm(final)=4.701 | 4618.2 samples/s | 72.2 steps/s
[Step=15250 Epoch=29.7] | Loss=0.03833 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.843 | L2-Norm(final)=4.699 | 4612.6 samples/s | 72.1 steps/s
[Step=15300 Epoch=29.8] | Loss=0.03780 | Reg=0.00394 | acc=0.9219 | L2-Norm=19.856 | L2-Norm(final)=4.696 | 4613.5 samples/s | 72.1 steps/s
[Step=15350 Epoch=29.9] | Loss=0.03725 | Reg=0.00395 | acc=0.9375 | L2-Norm=19.869 | L2-Norm(final)=4.694 | 4632.4 samples/s | 72.4 steps/s
[Step=15400 Epoch=30.0] | Loss=0.03679 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.881 | L2-Norm(final)=4.691 | 4631.8 samples/s | 72.4 steps/s
[Step=15450 Epoch=30.1] | Loss=0.03624 | Reg=0.00396 | acc=1.0000 | L2-Norm=19.893 | L2-Norm(final)=4.689 | 4619.8 samples/s | 72.2 steps/s
[Step=15500 Epoch=30.2] | Loss=0.03580 | Reg=0.00396 | acc=0.9688 | L2-Norm=19.905 | L2-Norm(final)=4.686 | 4985.8 samples/s | 77.9 steps/s
[Step=15550 Epoch=30.3] | Loss=0.03531 | Reg=0.00397 | acc=0.9688 | L2-Norm=19.917 | L2-Norm(final)=4.684 | 2694.5 samples/s | 42.1 steps/s
[Step=15600 Epoch=30.4] | Loss=0.03475 | Reg=0.00397 | acc=0.9844 | L2-Norm=19.928 | L2-Norm(final)=4.681 | 4623.1 samples/s | 72.2 steps/s
[Step=15650 Epoch=30.5] | Loss=0.03419 | Reg=0.00398 | acc=0.9844 | L2-Norm=19.939 | L2-Norm(final)=4.679 | 4614.8 samples/s | 72.1 steps/s
[Step=15700 Epoch=30.6] | Loss=0.03356 | Reg=0.00398 | acc=1.0000 | L2-Norm=19.949 | L2-Norm(final)=4.676 | 4626.8 samples/s | 72.3 steps/s
[Step=15750 Epoch=30.7] | Loss=0.03329 | Reg=0.00398 | acc=0.9688 | L2-Norm=19.958 | L2-Norm(final)=4.673 | 4653.2 samples/s | 72.7 steps/s
[Step=15800 Epoch=30.8] | Loss=0.03291 | Reg=0.00399 | acc=1.0000 | L2-Norm=19.967 | L2-Norm(final)=4.670 | 4600.7 samples/s | 71.9 steps/s
[Step=15850 Epoch=30.9] | Loss=0.03266 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.976 | L2-Norm(final)=4.667 | 4638.4 samples/s | 72.5 steps/s
[Step=15900 Epoch=31.0] | Loss=0.03226 | Reg=0.00399 | acc=0.9844 | L2-Norm=19.985 | L2-Norm(final)=4.664 | 4605.3 samples/s | 72.0 steps/s
[Step=15950 Epoch=31.1] | Loss=0.03200 | Reg=0.00400 | acc=0.9688 | L2-Norm=19.993 | L2-Norm(final)=4.662 | 4651.6 samples/s | 72.7 steps/s
[Step=16000 Epoch=31.2] | Loss=0.03173 | Reg=0.00400 | acc=0.9688 | L2-Norm=20.001 | L2-Norm(final)=4.659 | 4608.6 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step16000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=27.4] | Loss=0.04722 | Reg=0.00402 | acc=0.9531 | L2-Norm=20.053 | L2-Norm(final)=4.638 | 6816.8 samples/s | 106.5 steps/s
[Step=14050 Epoch=27.5] | Loss=0.04976 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.063 | L2-Norm(final)=4.679 | 4467.1 samples/s | 69.8 steps/s
[Step=14100 Epoch=27.6] | Loss=0.05116 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.080 | L2-Norm(final)=4.718 | 5212.3 samples/s | 81.4 steps/s
[Step=14150 Epoch=27.7] | Loss=0.04922 | Reg=0.00404 | acc=0.9531 | L2-Norm=20.099 | L2-Norm(final)=4.739 | 5185.3 samples/s | 81.0 steps/s
[Step=14200 Epoch=27.8] | Loss=0.04864 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.119 | L2-Norm(final)=4.764 | 5230.3 samples/s | 81.7 steps/s
[Step=14250 Epoch=27.9] | Loss=0.04796 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.138 | L2-Norm(final)=4.788 | 5194.1 samples/s | 81.2 steps/s
[Step=14300 Epoch=28.0] | Loss=0.04747 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.158 | L2-Norm(final)=4.808 | 5169.6 samples/s | 80.8 steps/s
[Step=14350 Epoch=28.1] | Loss=0.04707 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.177 | L2-Norm(final)=4.828 | 5236.9 samples/s | 81.8 steps/s
[Step=14400 Epoch=28.2] | Loss=0.04608 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.198 | L2-Norm(final)=4.850 | 5165.6 samples/s | 80.7 steps/s
[Step=14450 Epoch=28.2] | Loss=0.04569 | Reg=0.00409 | acc=0.9375 | L2-Norm=20.219 | L2-Norm(final)=4.873 | 5195.6 samples/s | 81.2 steps/s
[Step=14500 Epoch=28.3] | Loss=0.04515 | Reg=0.00410 | acc=0.9688 | L2-Norm=20.240 | L2-Norm(final)=4.896 | 7086.9 samples/s | 110.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=28.3] | Loss=0.02991 | Reg=0.00418 | acc=1.0000 | L2-Norm=20.453 | L2-Norm(final)=5.119 | 6578.7 samples/s | 102.8 steps/s
[Step=14550 Epoch=28.4] | Loss=0.05010 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.492 | L2-Norm(final)=5.121 | 4102.9 samples/s | 64.1 steps/s
[Step=14600 Epoch=28.5] | Loss=0.04492 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.539 | L2-Norm(final)=5.105 | 4626.4 samples/s | 72.3 steps/s
[Step=14650 Epoch=28.6] | Loss=0.04532 | Reg=0.00423 | acc=0.9375 | L2-Norm=20.575 | L2-Norm(final)=5.093 | 4612.5 samples/s | 72.1 steps/s
[Step=14700 Epoch=28.7] | Loss=0.04596 | Reg=0.00425 | acc=0.9531 | L2-Norm=20.609 | L2-Norm(final)=5.083 | 4679.5 samples/s | 73.1 steps/s
[Step=14750 Epoch=28.8] | Loss=0.04451 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.640 | L2-Norm(final)=5.073 | 4549.3 samples/s | 71.1 steps/s
[Step=14800 Epoch=28.9] | Loss=0.04486 | Reg=0.00427 | acc=1.0000 | L2-Norm=20.667 | L2-Norm(final)=5.065 | 4623.7 samples/s | 72.2 steps/s
[Step=14850 Epoch=29.0] | Loss=0.04399 | Reg=0.00428 | acc=0.9375 | L2-Norm=20.691 | L2-Norm(final)=5.057 | 4636.9 samples/s | 72.5 steps/s
[Step=14900 Epoch=29.1] | Loss=0.04325 | Reg=0.00429 | acc=0.9688 | L2-Norm=20.712 | L2-Norm(final)=5.051 | 4607.2 samples/s | 72.0 steps/s
[Step=14950 Epoch=29.2] | Loss=0.04244 | Reg=0.00430 | acc=0.9531 | L2-Norm=20.731 | L2-Norm(final)=5.045 | 4641.6 samples/s | 72.5 steps/s
[Step=15000 Epoch=29.3] | Loss=0.04176 | Reg=0.00430 | acc=0.9688 | L2-Norm=20.748 | L2-Norm(final)=5.039 | 6075.5 samples/s | 94.9 steps/s
[Step=15050 Epoch=29.4] | Loss=0.04069 | Reg=0.00431 | acc=0.9844 | L2-Norm=20.764 | L2-Norm(final)=5.034 | 2442.4 samples/s | 38.2 steps/s
[Step=15100 Epoch=29.5] | Loss=0.03933 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.778 | L2-Norm(final)=5.029 | 4731.2 samples/s | 73.9 steps/s
[Step=15150 Epoch=29.6] | Loss=0.03810 | Reg=0.00432 | acc=0.9688 | L2-Norm=20.789 | L2-Norm(final)=5.025 | 4528.6 samples/s | 70.8 steps/s
[Step=15200 Epoch=29.7] | Loss=0.03774 | Reg=0.00433 | acc=0.9688 | L2-Norm=20.800 | L2-Norm(final)=5.021 | 4629.2 samples/s | 72.3 steps/s
[Step=15250 Epoch=29.8] | Loss=0.03727 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.812 | L2-Norm(final)=5.015 | 4663.4 samples/s | 72.9 steps/s
[Step=15300 Epoch=29.9] | Loss=0.03663 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.822 | L2-Norm(final)=5.011 | 4647.9 samples/s | 72.6 steps/s
[Step=15350 Epoch=30.0] | Loss=0.03638 | Reg=0.00434 | acc=0.9688 | L2-Norm=20.833 | L2-Norm(final)=5.006 | 4601.8 samples/s | 71.9 steps/s
[Step=15400 Epoch=30.1] | Loss=0.03598 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.843 | L2-Norm(final)=5.000 | 4661.4 samples/s | 72.8 steps/s
[Step=15450 Epoch=30.2] | Loss=0.03543 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.854 | L2-Norm(final)=4.995 | 4684.0 samples/s | 73.2 steps/s
[Step=15500 Epoch=30.3] | Loss=0.03500 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.864 | L2-Norm(final)=4.990 | 5072.8 samples/s | 79.3 steps/s
[Step=15550 Epoch=30.4] | Loss=0.03452 | Reg=0.00436 | acc=0.9688 | L2-Norm=20.873 | L2-Norm(final)=4.985 | 2626.2 samples/s | 41.0 steps/s
[Step=15600 Epoch=30.5] | Loss=0.03386 | Reg=0.00436 | acc=1.0000 | L2-Norm=20.881 | L2-Norm(final)=4.980 | 4622.7 samples/s | 72.2 steps/s
[Step=15650 Epoch=30.6] | Loss=0.03344 | Reg=0.00436 | acc=1.0000 | L2-Norm=20.889 | L2-Norm(final)=4.975 | 4649.5 samples/s | 72.6 steps/s
[Step=15700 Epoch=30.7] | Loss=0.03302 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.896 | L2-Norm(final)=4.971 | 4647.2 samples/s | 72.6 steps/s
[Step=15750 Epoch=30.8] | Loss=0.03260 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.903 | L2-Norm(final)=4.967 | 4564.1 samples/s | 71.3 steps/s
[Step=15800 Epoch=30.9] | Loss=0.03212 | Reg=0.00437 | acc=0.9688 | L2-Norm=20.909 | L2-Norm(final)=4.963 | 4664.1 samples/s | 72.9 steps/s
[Step=15850 Epoch=31.0] | Loss=0.03182 | Reg=0.00437 | acc=0.9844 | L2-Norm=20.915 | L2-Norm(final)=4.959 | 4712.9 samples/s | 73.6 steps/s
[Step=15900 Epoch=31.1] | Loss=0.03146 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.922 | L2-Norm(final)=4.955 | 4644.1 samples/s | 72.6 steps/s
[Step=15950 Epoch=31.2] | Loss=0.03118 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.928 | L2-Norm(final)=4.951 | 4599.6 samples/s | 71.9 steps/s
[Step=16000 Epoch=31.3] | Loss=0.03087 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.934 | L2-Norm(final)=4.948 | 4617.4 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step16000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=53.6] | Loss=0.00089 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.308 | L2-Norm(final)=4.849 | 6591.6 samples/s | 103.0 steps/s
[Step=14050 Epoch=53.8] | Loss=0.00244 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=4.875 | 4186.6 samples/s | 65.4 steps/s
[Step=14100 Epoch=54.0] | Loss=0.00218 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.474 | L2-Norm(final)=4.896 | 4963.6 samples/s | 77.6 steps/s
[Step=14150 Epoch=54.2] | Loss=0.00160 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.525 | L2-Norm(final)=4.914 | 4871.1 samples/s | 76.1 steps/s
[Step=14200 Epoch=54.4] | Loss=0.00144 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.547 | L2-Norm(final)=4.933 | 4899.8 samples/s | 76.6 steps/s
[Step=14250 Epoch=54.6] | Loss=0.00153 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.568 | L2-Norm(final)=4.950 | 6771.9 samples/s | 105.8 steps/s
[Step=14300 Epoch=54.8] | Loss=0.00134 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=4.964 | 2467.3 samples/s | 38.6 steps/s
[Step=14350 Epoch=55.0] | Loss=0.00120 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.608 | L2-Norm(final)=4.979 | 4971.9 samples/s | 77.7 steps/s
[Step=14400 Epoch=55.2] | Loss=0.00107 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.617 | L2-Norm(final)=4.995 | 4896.0 samples/s | 76.5 steps/s
[Step=14450 Epoch=55.4] | Loss=0.00097 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.620 | L2-Norm(final)=5.009 | 4902.1 samples/s | 76.6 steps/s
[Step=14500 Epoch=55.6] | Loss=0.00092 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=5.023 | 5577.3 samples/s | 87.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=55.6] | Loss=0.00025 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=5.155 | 6099.4 samples/s | 95.3 steps/s
[Step=14550 Epoch=55.8] | Loss=0.00019 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=5.165 | 4027.0 samples/s | 62.9 steps/s
[Step=14600 Epoch=55.9] | Loss=0.00615 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.676 | L2-Norm(final)=5.138 | 4374.4 samples/s | 68.3 steps/s
[Step=14650 Epoch=56.1] | Loss=0.00865 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.892 | L2-Norm(final)=5.075 | 4380.8 samples/s | 68.4 steps/s
[Step=14700 Epoch=56.3] | Loss=0.00837 | Reg=0.00226 | acc=0.9531 | L2-Norm=15.043 | L2-Norm(final)=5.031 | 4400.0 samples/s | 68.8 steps/s
[Step=14750 Epoch=56.5] | Loss=0.00796 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.149 | L2-Norm(final)=4.999 | 5900.1 samples/s | 92.2 steps/s
[Step=14800 Epoch=56.7] | Loss=0.00691 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.225 | L2-Norm(final)=4.977 | 2328.7 samples/s | 36.4 steps/s
[Step=14850 Epoch=56.9] | Loss=0.00613 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.275 | L2-Norm(final)=4.961 | 4422.7 samples/s | 69.1 steps/s
[Step=14900 Epoch=57.1] | Loss=0.00550 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.310 | L2-Norm(final)=4.951 | 4376.8 samples/s | 68.4 steps/s
[Step=14950 Epoch=57.3] | Loss=0.00490 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.332 | L2-Norm(final)=4.943 | 4396.9 samples/s | 68.7 steps/s
[Step=15000 Epoch=57.5] | Loss=0.00453 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=4.938 | 5003.6 samples/s | 78.2 steps/s
[Step=15050 Epoch=57.7] | Loss=0.00417 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.353 | L2-Norm(final)=4.933 | 2504.4 samples/s | 39.1 steps/s
[Step=15100 Epoch=57.9] | Loss=0.00384 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=4.930 | 4402.4 samples/s | 68.8 steps/s
[Step=15150 Epoch=58.0] | Loss=0.00354 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.355 | L2-Norm(final)=4.928 | 4537.8 samples/s | 70.9 steps/s
[Step=15200 Epoch=58.2] | Loss=0.00329 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.350 | L2-Norm(final)=4.927 | 4261.2 samples/s | 66.6 steps/s
[Step=15250 Epoch=58.4] | Loss=0.00307 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=4.926 | 4396.4 samples/s | 68.7 steps/s
[Step=15300 Epoch=58.6] | Loss=0.00288 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=4.925 | 2669.7 samples/s | 41.7 steps/s
[Step=15350 Epoch=58.8] | Loss=0.00271 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.321 | L2-Norm(final)=4.924 | 4430.9 samples/s | 69.2 steps/s
[Step=15400 Epoch=59.0] | Loss=0.00256 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=4.924 | 4440.8 samples/s | 69.4 steps/s
[Step=15450 Epoch=59.2] | Loss=0.00243 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.293 | L2-Norm(final)=4.923 | 4456.5 samples/s | 69.6 steps/s
[Step=15500 Epoch=59.4] | Loss=0.00231 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.277 | L2-Norm(final)=4.923 | 4261.5 samples/s | 66.6 steps/s
[Step=15550 Epoch=59.6] | Loss=0.00220 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=4.923 | 2707.5 samples/s | 42.3 steps/s
[Step=15600 Epoch=59.8] | Loss=0.00210 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.242 | L2-Norm(final)=4.923 | 4397.6 samples/s | 68.7 steps/s
[Step=15650 Epoch=60.0] | Loss=0.00201 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.223 | L2-Norm(final)=4.923 | 4361.1 samples/s | 68.1 steps/s
[Step=15700 Epoch=60.2] | Loss=0.00192 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=4.923 | 4421.7 samples/s | 69.1 steps/s
[Step=15750 Epoch=60.3] | Loss=0.00185 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=4.923 | 4434.8 samples/s | 69.3 steps/s
[Step=15800 Epoch=60.5] | Loss=0.00178 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=4.923 | 6307.0 samples/s | 98.5 steps/s
[Step=15850 Epoch=60.7] | Loss=0.00171 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.144 | L2-Norm(final)=4.924 | 2269.7 samples/s | 35.5 steps/s
[Step=15900 Epoch=60.9] | Loss=0.00165 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=4.924 | 4337.9 samples/s | 67.8 steps/s
[Step=15950 Epoch=61.1] | Loss=0.00159 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.102 | L2-Norm(final)=4.925 | 4365.4 samples/s | 68.2 steps/s
[Step=16000 Epoch=61.3] | Loss=0.00154 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.080 | L2-Norm(final)=4.926 | 4474.6 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step16000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=53.9] | Loss=0.00197 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.413 | L2-Norm(final)=4.852 | 6159.7 samples/s | 96.2 steps/s
[Step=14050 Epoch=54.1] | Loss=0.00232 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.502 | L2-Norm(final)=4.867 | 4479.4 samples/s | 70.0 steps/s
[Step=14100 Epoch=54.3] | Loss=0.00160 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.570 | L2-Norm(final)=4.888 | 4877.4 samples/s | 76.2 steps/s
[Step=14150 Epoch=54.5] | Loss=0.00131 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=4.909 | 4948.1 samples/s | 77.3 steps/s
[Step=14200 Epoch=54.7] | Loss=0.00113 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=4.931 | 4898.3 samples/s | 76.5 steps/s
[Step=14250 Epoch=54.9] | Loss=0.00107 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=4.949 | 6896.3 samples/s | 107.8 steps/s
[Step=14300 Epoch=55.0] | Loss=0.00092 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=4.966 | 2452.2 samples/s | 38.3 steps/s
[Step=14350 Epoch=55.2] | Loss=0.00080 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=4.982 | 4915.1 samples/s | 76.8 steps/s
[Step=14400 Epoch=55.4] | Loss=0.00072 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=4.996 | 5005.8 samples/s | 78.2 steps/s
[Step=14450 Epoch=55.6] | Loss=0.00066 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=5.010 | 4780.2 samples/s | 74.7 steps/s
[Step=14500 Epoch=55.8] | Loss=0.00061 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=5.024 | 5874.6 samples/s | 91.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=55.8] | Loss=0.00013 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.586 | L2-Norm(final)=5.166 | 7025.2 samples/s | 109.8 steps/s
[Step=14550 Epoch=56.0] | Loss=0.00008 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=5.177 | 3660.1 samples/s | 57.2 steps/s
[Step=14600 Epoch=56.2] | Loss=0.00102 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.533 | L2-Norm(final)=5.186 | 4402.5 samples/s | 68.8 steps/s
[Step=14650 Epoch=56.4] | Loss=0.01332 | Reg=0.00217 | acc=0.9688 | L2-Norm=14.743 | L2-Norm(final)=5.111 | 4387.8 samples/s | 68.6 steps/s
[Step=14700 Epoch=56.6] | Loss=0.01225 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.984 | L2-Norm(final)=5.028 | 4452.4 samples/s | 69.6 steps/s
[Step=14750 Epoch=56.8] | Loss=0.01060 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=4.982 | 5888.4 samples/s | 92.0 steps/s
[Step=14800 Epoch=57.0] | Loss=0.01005 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=4.950 | 1804.9 samples/s | 28.2 steps/s
[Step=14850 Epoch=57.2] | Loss=0.00895 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=4.927 | 4343.9 samples/s | 67.9 steps/s
[Step=14900 Epoch=57.4] | Loss=0.00793 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=4.911 | 4228.8 samples/s | 66.1 steps/s
[Step=14950 Epoch=57.5] | Loss=0.00707 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.395 | L2-Norm(final)=4.901 | 4378.3 samples/s | 68.4 steps/s
[Step=15000 Epoch=57.7] | Loss=0.00639 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.417 | L2-Norm(final)=4.893 | 5155.3 samples/s | 80.6 steps/s
[Step=15050 Epoch=57.9] | Loss=0.00581 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=4.888 | 2456.4 samples/s | 38.4 steps/s
[Step=15100 Epoch=58.1] | Loss=0.00533 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=4.884 | 4314.1 samples/s | 67.4 steps/s
[Step=15150 Epoch=58.3] | Loss=0.00492 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.436 | L2-Norm(final)=4.881 | 4423.2 samples/s | 69.1 steps/s
[Step=15200 Epoch=58.5] | Loss=0.00457 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.433 | L2-Norm(final)=4.879 | 4440.3 samples/s | 69.4 steps/s
[Step=15250 Epoch=58.7] | Loss=0.00427 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.426 | L2-Norm(final)=4.877 | 4376.7 samples/s | 68.4 steps/s
[Step=15300 Epoch=58.9] | Loss=0.00400 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=4.875 | 2683.8 samples/s | 41.9 steps/s
[Step=15350 Epoch=59.1] | Loss=0.00377 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.405 | L2-Norm(final)=4.874 | 4374.7 samples/s | 68.4 steps/s
[Step=15400 Epoch=59.3] | Loss=0.00356 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.391 | L2-Norm(final)=4.873 | 4326.3 samples/s | 67.6 steps/s
[Step=15450 Epoch=59.5] | Loss=0.00337 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=4.872 | 4394.1 samples/s | 68.7 steps/s
[Step=15500 Epoch=59.7] | Loss=0.00320 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.360 | L2-Norm(final)=4.871 | 4415.1 samples/s | 69.0 steps/s
[Step=15550 Epoch=59.9] | Loss=0.00305 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=4.871 | 2691.1 samples/s | 42.0 steps/s
[Step=15600 Epoch=60.1] | Loss=0.00291 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=4.870 | 4444.0 samples/s | 69.4 steps/s
[Step=15650 Epoch=60.2] | Loss=0.00279 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.306 | L2-Norm(final)=4.870 | 4298.9 samples/s | 67.2 steps/s
[Step=15700 Epoch=60.4] | Loss=0.00267 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=4.870 | 4369.0 samples/s | 68.3 steps/s
[Step=15750 Epoch=60.6] | Loss=0.00257 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=4.870 | 4503.1 samples/s | 70.4 steps/s
[Step=15800 Epoch=60.8] | Loss=0.00247 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.246 | L2-Norm(final)=4.870 | 6871.1 samples/s | 107.4 steps/s
[Step=15850 Epoch=61.0] | Loss=0.00238 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=4.870 | 2166.3 samples/s | 33.8 steps/s
[Step=15900 Epoch=61.2] | Loss=0.00229 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=4.870 | 4448.5 samples/s | 69.5 steps/s
[Step=15950 Epoch=61.4] | Loss=0.00221 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=4.871 | 4351.6 samples/s | 68.0 steps/s
[Step=16000 Epoch=61.6] | Loss=0.00214 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=4.871 | 4397.1 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07246 | acc=0.9580 | tpr=0.9701 | fpr=0.0681 | 5380.6 samples/s | 21.0 steps/s
Avg test loss: 0.07141, Avg test acc: 0.95885, Avg tpr: 0.96981, Avg fpr: 0.06525, total FA: 509

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07620 | acc=0.9603 | tpr=0.9691 | fpr=0.0587 | 5474.3 samples/s | 21.4 steps/s
Avg test loss: 0.07655, Avg test acc: 0.96125, Avg tpr: 0.96893, Avg fpr: 0.05563, total FA: 434

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.02737 | acc=0.3152 | tpr=0.0049 | fpr=0.0111 | 5474.1 samples/s | 21.4 steps/s
Avg test loss: 5.04391, Avg test acc: 0.31188, Avg tpr: 0.00460, Avg fpr: 0.01231, total FA: 96

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.83703 | acc=0.3105 | tpr=0.0042 | fpr=0.0243 | 5302.9 samples/s | 20.7 steps/s
Avg test loss: 4.84134, Avg test acc: 0.30820, Avg tpr: 0.00437, Avg fpr: 0.02359, total FA: 184

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.12926 | acc=0.1202 | tpr=0.8053 | fpr=0.8921 | 5180.0 samples/s | 20.2 steps/s
[Step= 100] | Loss=5.10606 | acc=0.1206 | tpr=0.7953 | fpr=0.8920 | 7748.7 samples/s | 30.3 steps/s
[Step= 150] | Loss=5.10752 | acc=0.1204 | tpr=0.7896 | fpr=0.8920 | 7462.3 samples/s | 29.1 steps/s
[Step= 200] | Loss=5.11359 | acc=0.1202 | tpr=0.7858 | fpr=0.8919 | 8098.0 samples/s | 31.6 steps/s
[Step= 250] | Loss=5.11453 | acc=0.1204 | tpr=0.7860 | fpr=0.8917 | 8210.8 samples/s | 32.1 steps/s
[Step= 300] | Loss=5.11001 | acc=0.1204 | tpr=0.7855 | fpr=0.8917 | 8236.6 samples/s | 32.2 steps/s
[Step= 350] | Loss=5.10389 | acc=0.1210 | tpr=0.7909 | fpr=0.8911 | 8285.6 samples/s | 32.4 steps/s
[Step= 400] | Loss=5.10136 | acc=0.1216 | tpr=0.7943 | fpr=0.8907 | 8031.5 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.10433 | acc=0.1210 | tpr=0.7950 | fpr=0.8912 | 8117.0 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.10203 | acc=0.1211 | tpr=0.7987 | fpr=0.8911 | 8765.6 samples/s | 34.2 steps/s
[Step= 550] | Loss=5.10133 | acc=0.1215 | tpr=0.7994 | fpr=0.8908 | 13564.0 samples/s | 53.0 steps/s
Avg test loss: 5.10207, Avg test acc: 0.12149, Avg tpr: 0.80032, Avg fpr: 0.89085, total FA: 123693

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.00401 | acc=0.1363 | tpr=0.7655 | fpr=0.8750 | 5191.1 samples/s | 20.3 steps/s
[Step= 100] | Loss=5.95320 | acc=0.1374 | tpr=0.7569 | fpr=0.8742 | 7321.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=5.95050 | acc=0.1371 | tpr=0.7608 | fpr=0.8744 | 8034.7 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.95634 | acc=0.1364 | tpr=0.7486 | fpr=0.8748 | 7878.9 samples/s | 30.8 steps/s
[Step= 250] | Loss=5.95699 | acc=0.1369 | tpr=0.7459 | fpr=0.8742 | 8347.8 samples/s | 32.6 steps/s
[Step= 300] | Loss=5.95780 | acc=0.1366 | tpr=0.7447 | fpr=0.8745 | 7901.2 samples/s | 30.9 steps/s
[Step= 350] | Loss=5.95004 | acc=0.1370 | tpr=0.7464 | fpr=0.8741 | 8302.0 samples/s | 32.4 steps/s
[Step= 400] | Loss=5.94274 | acc=0.1375 | tpr=0.7484 | fpr=0.8736 | 8031.7 samples/s | 31.4 steps/s
[Step= 450] | Loss=5.94478 | acc=0.1370 | tpr=0.7454 | fpr=0.8740 | 8150.1 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.94262 | acc=0.1368 | tpr=0.7471 | fpr=0.8742 | 8665.7 samples/s | 33.9 steps/s
[Step= 550] | Loss=5.94028 | acc=0.1369 | tpr=0.7461 | fpr=0.8741 | 14117.5 samples/s | 55.1 steps/s
Avg test loss: 5.94071, Avg test acc: 0.13690, Avg tpr: 0.74683, Avg fpr: 0.87419, total FA: 121379

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12926 | acc=0.9812 | tpr=0.9115 | fpr=0.0175 | 5163.3 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.13896 | acc=0.9809 | tpr=0.9318 | fpr=0.0182 | 7450.4 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.14775 | acc=0.9800 | tpr=0.9352 | fpr=0.0191 | 7573.3 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.15168 | acc=0.9797 | tpr=0.9388 | fpr=0.0196 | 8436.1 samples/s | 33.0 steps/s
[Step= 250] | Loss=0.14925 | acc=0.9798 | tpr=0.9380 | fpr=0.0194 | 8304.1 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.15067 | acc=0.9797 | tpr=0.9360 | fpr=0.0195 | 7940.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.15162 | acc=0.9794 | tpr=0.9374 | fpr=0.0198 | 8171.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.15325 | acc=0.9791 | tpr=0.9338 | fpr=0.0200 | 8149.3 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.15568 | acc=0.9787 | tpr=0.9294 | fpr=0.0204 | 8332.6 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.15522 | acc=0.9788 | tpr=0.9313 | fpr=0.0203 | 8128.2 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.15418 | acc=0.9790 | tpr=0.9300 | fpr=0.0201 | 14246.9 samples/s | 55.7 steps/s
Avg test loss: 0.15376, Avg test acc: 0.97897, Avg tpr: 0.92948, Avg fpr: 0.02013, total FA: 2795

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13862 | acc=0.9788 | tpr=0.9381 | fpr=0.0205 | 5247.0 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.14552 | acc=0.9787 | tpr=0.9488 | fpr=0.0207 | 7175.8 samples/s | 28.0 steps/s
[Step= 150] | Loss=0.15084 | acc=0.9779 | tpr=0.9510 | fpr=0.0216 | 8035.4 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.15460 | acc=0.9778 | tpr=0.9486 | fpr=0.0216 | 8063.3 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.15300 | acc=0.9778 | tpr=0.9467 | fpr=0.0216 | 8125.8 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.15558 | acc=0.9774 | tpr=0.9447 | fpr=0.0220 | 8139.9 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.15750 | acc=0.9771 | tpr=0.9455 | fpr=0.0224 | 7893.0 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.15943 | acc=0.9768 | tpr=0.9415 | fpr=0.0226 | 8257.9 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.16239 | acc=0.9764 | tpr=0.9426 | fpr=0.0229 | 8269.8 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.16153 | acc=0.9766 | tpr=0.9441 | fpr=0.0229 | 7982.1 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.16084 | acc=0.9766 | tpr=0.9431 | fpr=0.0228 | 14622.9 samples/s | 57.1 steps/s
Avg test loss: 0.16054, Avg test acc: 0.97661, Avg tpr: 0.94255, Avg fpr: 0.02277, total FA: 3161

server round 8/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=31.2] | Loss=0.05419 | Reg=0.00383 | acc=0.9688 | L2-Norm=19.560 | L2-Norm(final)=4.581 | 6102.5 samples/s | 95.4 steps/s
[Step=16050 Epoch=31.3] | Loss=0.06706 | Reg=0.00383 | acc=0.9375 | L2-Norm=19.580 | L2-Norm(final)=4.617 | 4814.3 samples/s | 75.2 steps/s
[Step=16100 Epoch=31.4] | Loss=0.06364 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.609 | L2-Norm(final)=4.662 | 5236.0 samples/s | 81.8 steps/s
[Step=16150 Epoch=31.5] | Loss=0.06076 | Reg=0.00386 | acc=0.9219 | L2-Norm=19.634 | L2-Norm(final)=4.694 | 5094.0 samples/s | 79.6 steps/s
[Step=16200 Epoch=31.6] | Loss=0.05774 | Reg=0.00386 | acc=0.9688 | L2-Norm=19.658 | L2-Norm(final)=4.726 | 5202.4 samples/s | 81.3 steps/s
[Step=16250 Epoch=31.7] | Loss=0.05594 | Reg=0.00388 | acc=1.0000 | L2-Norm=19.685 | L2-Norm(final)=4.758 | 5278.0 samples/s | 82.5 steps/s
[Step=16300 Epoch=31.8] | Loss=0.05659 | Reg=0.00389 | acc=1.0000 | L2-Norm=19.712 | L2-Norm(final)=4.785 | 5221.5 samples/s | 81.6 steps/s
[Step=16350 Epoch=31.9] | Loss=0.05569 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.737 | L2-Norm(final)=4.810 | 5285.5 samples/s | 82.6 steps/s
[Step=16400 Epoch=32.0] | Loss=0.05605 | Reg=0.00391 | acc=0.9375 | L2-Norm=19.762 | L2-Norm(final)=4.835 | 5181.6 samples/s | 81.0 steps/s
[Step=16450 Epoch=32.1] | Loss=0.05530 | Reg=0.00392 | acc=0.9688 | L2-Norm=19.788 | L2-Norm(final)=4.858 | 5146.4 samples/s | 80.4 steps/s
[Step=16500 Epoch=32.2] | Loss=0.05473 | Reg=0.00393 | acc=0.9062 | L2-Norm=19.813 | L2-Norm(final)=4.882 | 6877.4 samples/s | 107.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=32.2] | Loss=0.07631 | Reg=0.00402 | acc=0.9375 | L2-Norm=20.057 | L2-Norm(final)=5.118 | 6198.5 samples/s | 96.9 steps/s
[Step=16550 Epoch=32.3] | Loss=0.04756 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.095 | L2-Norm(final)=5.129 | 4207.9 samples/s | 65.7 steps/s
[Step=16600 Epoch=32.4] | Loss=0.04950 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.129 | L2-Norm(final)=5.118 | 4613.6 samples/s | 72.1 steps/s
[Step=16650 Epoch=32.5] | Loss=0.04727 | Reg=0.00406 | acc=0.9688 | L2-Norm=20.160 | L2-Norm(final)=5.108 | 4659.1 samples/s | 72.8 steps/s
[Step=16700 Epoch=32.6] | Loss=0.04813 | Reg=0.00408 | acc=0.9531 | L2-Norm=20.190 | L2-Norm(final)=5.100 | 4644.5 samples/s | 72.6 steps/s
[Step=16750 Epoch=32.7] | Loss=0.04622 | Reg=0.00409 | acc=0.9375 | L2-Norm=20.216 | L2-Norm(final)=5.090 | 4600.8 samples/s | 71.9 steps/s
[Step=16800 Epoch=32.8] | Loss=0.04624 | Reg=0.00410 | acc=0.9531 | L2-Norm=20.240 | L2-Norm(final)=5.082 | 4696.7 samples/s | 73.4 steps/s
[Step=16850 Epoch=32.9] | Loss=0.04428 | Reg=0.00411 | acc=0.9844 | L2-Norm=20.261 | L2-Norm(final)=5.074 | 4567.2 samples/s | 71.4 steps/s
[Step=16900 Epoch=33.0] | Loss=0.04267 | Reg=0.00411 | acc=0.9531 | L2-Norm=20.278 | L2-Norm(final)=5.068 | 4638.2 samples/s | 72.5 steps/s
[Step=16950 Epoch=33.1] | Loss=0.04196 | Reg=0.00412 | acc=0.9375 | L2-Norm=20.294 | L2-Norm(final)=5.060 | 4645.4 samples/s | 72.6 steps/s
[Step=17000 Epoch=33.2] | Loss=0.04176 | Reg=0.00412 | acc=0.9844 | L2-Norm=20.307 | L2-Norm(final)=5.052 | 6004.5 samples/s | 93.8 steps/s
[Step=17050 Epoch=33.3] | Loss=0.04057 | Reg=0.00413 | acc=0.9688 | L2-Norm=20.320 | L2-Norm(final)=5.045 | 2451.5 samples/s | 38.3 steps/s
[Step=17100 Epoch=33.4] | Loss=0.03930 | Reg=0.00413 | acc=1.0000 | L2-Norm=20.333 | L2-Norm(final)=5.039 | 4614.1 samples/s | 72.1 steps/s
[Step=17150 Epoch=33.4] | Loss=0.03840 | Reg=0.00414 | acc=1.0000 | L2-Norm=20.346 | L2-Norm(final)=5.034 | 4638.0 samples/s | 72.5 steps/s
[Step=17200 Epoch=33.5] | Loss=0.03776 | Reg=0.00414 | acc=0.9844 | L2-Norm=20.357 | L2-Norm(final)=5.029 | 4621.6 samples/s | 72.2 steps/s
[Step=17250 Epoch=33.6] | Loss=0.03683 | Reg=0.00415 | acc=0.9688 | L2-Norm=20.368 | L2-Norm(final)=5.025 | 4669.9 samples/s | 73.0 steps/s
[Step=17300 Epoch=33.7] | Loss=0.03600 | Reg=0.00415 | acc=1.0000 | L2-Norm=20.378 | L2-Norm(final)=5.021 | 4527.9 samples/s | 70.7 steps/s
[Step=17350 Epoch=33.8] | Loss=0.03542 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.387 | L2-Norm(final)=5.018 | 4638.7 samples/s | 72.5 steps/s
[Step=17400 Epoch=33.9] | Loss=0.03471 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.396 | L2-Norm(final)=5.015 | 4680.3 samples/s | 73.1 steps/s
[Step=17450 Epoch=34.0] | Loss=0.03422 | Reg=0.00416 | acc=1.0000 | L2-Norm=20.405 | L2-Norm(final)=5.012 | 4576.9 samples/s | 71.5 steps/s
[Step=17500 Epoch=34.1] | Loss=0.03420 | Reg=0.00417 | acc=0.9688 | L2-Norm=20.414 | L2-Norm(final)=5.009 | 4978.5 samples/s | 77.8 steps/s
[Step=17550 Epoch=34.2] | Loss=0.03394 | Reg=0.00417 | acc=0.9688 | L2-Norm=20.423 | L2-Norm(final)=5.005 | 2683.7 samples/s | 41.9 steps/s
[Step=17600 Epoch=34.3] | Loss=0.03371 | Reg=0.00417 | acc=0.9219 | L2-Norm=20.432 | L2-Norm(final)=5.002 | 4660.5 samples/s | 72.8 steps/s
[Step=17650 Epoch=34.4] | Loss=0.03319 | Reg=0.00418 | acc=0.9688 | L2-Norm=20.441 | L2-Norm(final)=4.998 | 4503.2 samples/s | 70.4 steps/s
[Step=17700 Epoch=34.5] | Loss=0.03279 | Reg=0.00418 | acc=0.9688 | L2-Norm=20.451 | L2-Norm(final)=4.994 | 4624.8 samples/s | 72.3 steps/s
[Step=17750 Epoch=34.6] | Loss=0.03250 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.460 | L2-Norm(final)=4.990 | 4605.6 samples/s | 72.0 steps/s
[Step=17800 Epoch=34.7] | Loss=0.03197 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.469 | L2-Norm(final)=4.987 | 4762.7 samples/s | 74.4 steps/s
[Step=17850 Epoch=34.8] | Loss=0.03177 | Reg=0.00419 | acc=0.9688 | L2-Norm=20.477 | L2-Norm(final)=4.984 | 4515.5 samples/s | 70.6 steps/s
[Step=17900 Epoch=34.9] | Loss=0.03158 | Reg=0.00420 | acc=0.9531 | L2-Norm=20.486 | L2-Norm(final)=4.981 | 4723.1 samples/s | 73.8 steps/s
[Step=17950 Epoch=35.0] | Loss=0.03129 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.495 | L2-Norm(final)=4.977 | 4538.2 samples/s | 70.9 steps/s
[Step=18000 Epoch=35.1] | Loss=0.03109 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.504 | L2-Norm(final)=4.974 | 4672.5 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step18000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=31.3] | Loss=0.11518 | Reg=0.00417 | acc=0.8906 | L2-Norm=20.432 | L2-Norm(final)=4.831 | 6279.1 samples/s | 98.1 steps/s
[Step=16050 Epoch=31.4] | Loss=0.06458 | Reg=0.00419 | acc=0.9844 | L2-Norm=20.463 | L2-Norm(final)=4.864 | 4515.0 samples/s | 70.5 steps/s
[Step=16100 Epoch=31.5] | Loss=0.06118 | Reg=0.00420 | acc=0.9219 | L2-Norm=20.500 | L2-Norm(final)=4.905 | 5170.0 samples/s | 80.8 steps/s
[Step=16150 Epoch=31.6] | Loss=0.05789 | Reg=0.00421 | acc=0.9531 | L2-Norm=20.530 | L2-Norm(final)=4.934 | 5149.2 samples/s | 80.5 steps/s
[Step=16200 Epoch=31.7] | Loss=0.05703 | Reg=0.00423 | acc=0.9531 | L2-Norm=20.560 | L2-Norm(final)=4.961 | 5191.2 samples/s | 81.1 steps/s
[Step=16250 Epoch=31.8] | Loss=0.05608 | Reg=0.00424 | acc=0.9531 | L2-Norm=20.591 | L2-Norm(final)=4.990 | 5282.6 samples/s | 82.5 steps/s
[Step=16300 Epoch=31.9] | Loss=0.05574 | Reg=0.00425 | acc=0.9375 | L2-Norm=20.621 | L2-Norm(final)=5.014 | 5206.8 samples/s | 81.4 steps/s
[Step=16350 Epoch=32.0] | Loss=0.05530 | Reg=0.00426 | acc=0.9844 | L2-Norm=20.651 | L2-Norm(final)=5.036 | 5203.5 samples/s | 81.3 steps/s
[Step=16400 Epoch=32.1] | Loss=0.05418 | Reg=0.00428 | acc=0.9844 | L2-Norm=20.680 | L2-Norm(final)=5.060 | 5120.5 samples/s | 80.0 steps/s
[Step=16450 Epoch=32.2] | Loss=0.05314 | Reg=0.00429 | acc=0.9375 | L2-Norm=20.709 | L2-Norm(final)=5.087 | 5333.1 samples/s | 83.3 steps/s
[Step=16500 Epoch=32.3] | Loss=0.05292 | Reg=0.00430 | acc=1.0000 | L2-Norm=20.736 | L2-Norm(final)=5.112 | 6958.4 samples/s | 108.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=32.3] | Loss=0.03779 | Reg=0.00441 | acc=0.9688 | L2-Norm=21.006 | L2-Norm(final)=5.349 | 6691.0 samples/s | 104.5 steps/s
[Step=16550 Epoch=32.4] | Loss=0.03638 | Reg=0.00443 | acc=1.0000 | L2-Norm=21.040 | L2-Norm(final)=5.365 | 4014.5 samples/s | 62.7 steps/s
[Step=16600 Epoch=32.5] | Loss=0.04658 | Reg=0.00444 | acc=0.9531 | L2-Norm=21.076 | L2-Norm(final)=5.354 | 4612.7 samples/s | 72.1 steps/s
[Step=16650 Epoch=32.6] | Loss=0.04722 | Reg=0.00446 | acc=0.9844 | L2-Norm=21.119 | L2-Norm(final)=5.334 | 4639.9 samples/s | 72.5 steps/s
[Step=16700 Epoch=32.6] | Loss=0.04637 | Reg=0.00448 | acc=0.9844 | L2-Norm=21.155 | L2-Norm(final)=5.321 | 4613.2 samples/s | 72.1 steps/s
[Step=16750 Epoch=32.7] | Loss=0.04503 | Reg=0.00449 | acc=0.9844 | L2-Norm=21.183 | L2-Norm(final)=5.311 | 4732.2 samples/s | 73.9 steps/s
[Step=16800 Epoch=32.8] | Loss=0.04359 | Reg=0.00450 | acc=1.0000 | L2-Norm=21.206 | L2-Norm(final)=5.303 | 4555.9 samples/s | 71.2 steps/s
[Step=16850 Epoch=32.9] | Loss=0.04359 | Reg=0.00451 | acc=0.9688 | L2-Norm=21.228 | L2-Norm(final)=5.295 | 4627.3 samples/s | 72.3 steps/s
[Step=16900 Epoch=33.0] | Loss=0.04321 | Reg=0.00451 | acc=0.9219 | L2-Norm=21.247 | L2-Norm(final)=5.287 | 4607.1 samples/s | 72.0 steps/s
[Step=16950 Epoch=33.1] | Loss=0.04178 | Reg=0.00452 | acc=0.9531 | L2-Norm=21.264 | L2-Norm(final)=5.281 | 4621.7 samples/s | 72.2 steps/s
[Step=17000 Epoch=33.2] | Loss=0.04176 | Reg=0.00453 | acc=0.9844 | L2-Norm=21.278 | L2-Norm(final)=5.274 | 6100.1 samples/s | 95.3 steps/s
[Step=17050 Epoch=33.3] | Loss=0.04022 | Reg=0.00453 | acc=1.0000 | L2-Norm=21.291 | L2-Norm(final)=5.269 | 2438.9 samples/s | 38.1 steps/s
[Step=17100 Epoch=33.4] | Loss=0.03860 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.303 | L2-Norm(final)=5.265 | 4615.9 samples/s | 72.1 steps/s
[Step=17150 Epoch=33.5] | Loss=0.03706 | Reg=0.00454 | acc=1.0000 | L2-Norm=21.313 | L2-Norm(final)=5.262 | 4621.2 samples/s | 72.2 steps/s
[Step=17200 Epoch=33.6] | Loss=0.03641 | Reg=0.00455 | acc=1.0000 | L2-Norm=21.322 | L2-Norm(final)=5.259 | 4693.3 samples/s | 73.3 steps/s
[Step=17250 Epoch=33.7] | Loss=0.03553 | Reg=0.00455 | acc=0.9688 | L2-Norm=21.330 | L2-Norm(final)=5.256 | 4530.3 samples/s | 70.8 steps/s
[Step=17300 Epoch=33.8] | Loss=0.03496 | Reg=0.00455 | acc=0.9844 | L2-Norm=21.337 | L2-Norm(final)=5.253 | 4670.3 samples/s | 73.0 steps/s
[Step=17350 Epoch=33.9] | Loss=0.03408 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.343 | L2-Norm(final)=5.250 | 4683.6 samples/s | 73.2 steps/s
[Step=17400 Epoch=34.0] | Loss=0.03345 | Reg=0.00456 | acc=1.0000 | L2-Norm=21.350 | L2-Norm(final)=5.247 | 4553.2 samples/s | 71.1 steps/s
[Step=17450 Epoch=34.1] | Loss=0.03313 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.355 | L2-Norm(final)=5.244 | 4645.9 samples/s | 72.6 steps/s
[Step=17500 Epoch=34.2] | Loss=0.03295 | Reg=0.00456 | acc=0.9844 | L2-Norm=21.361 | L2-Norm(final)=5.241 | 5122.8 samples/s | 80.0 steps/s
[Step=17550 Epoch=34.3] | Loss=0.03260 | Reg=0.00457 | acc=0.9688 | L2-Norm=21.368 | L2-Norm(final)=5.237 | 2628.6 samples/s | 41.1 steps/s
[Step=17600 Epoch=34.4] | Loss=0.03201 | Reg=0.00457 | acc=0.9531 | L2-Norm=21.374 | L2-Norm(final)=5.234 | 4558.0 samples/s | 71.2 steps/s
[Step=17650 Epoch=34.5] | Loss=0.03146 | Reg=0.00457 | acc=0.9531 | L2-Norm=21.380 | L2-Norm(final)=5.232 | 4642.0 samples/s | 72.5 steps/s
[Step=17700 Epoch=34.6] | Loss=0.03118 | Reg=0.00457 | acc=1.0000 | L2-Norm=21.386 | L2-Norm(final)=5.229 | 4588.4 samples/s | 71.7 steps/s
[Step=17750 Epoch=34.7] | Loss=0.03093 | Reg=0.00458 | acc=0.9688 | L2-Norm=21.392 | L2-Norm(final)=5.226 | 4661.1 samples/s | 72.8 steps/s
[Step=17800 Epoch=34.8] | Loss=0.03047 | Reg=0.00458 | acc=0.9688 | L2-Norm=21.398 | L2-Norm(final)=5.223 | 4585.8 samples/s | 71.7 steps/s
[Step=17850 Epoch=34.9] | Loss=0.03008 | Reg=0.00458 | acc=1.0000 | L2-Norm=21.404 | L2-Norm(final)=5.221 | 4665.9 samples/s | 72.9 steps/s
[Step=17900 Epoch=35.0] | Loss=0.02979 | Reg=0.00458 | acc=0.9844 | L2-Norm=21.410 | L2-Norm(final)=5.219 | 4599.4 samples/s | 71.9 steps/s
[Step=17950 Epoch=35.1] | Loss=0.02953 | Reg=0.00459 | acc=0.9688 | L2-Norm=21.415 | L2-Norm(final)=5.217 | 4660.1 samples/s | 72.8 steps/s
[Step=18000 Epoch=35.2] | Loss=0.02932 | Reg=0.00459 | acc=1.0000 | L2-Norm=21.420 | L2-Norm(final)=5.215 | 4631.7 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step18000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=61.3] | Loss=0.00102 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.287 | L2-Norm(final)=4.951 | 6051.4 samples/s | 94.6 steps/s
[Step=16050 Epoch=61.5] | Loss=0.00148 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.364 | L2-Norm(final)=4.965 | 4417.4 samples/s | 69.0 steps/s
[Step=16100 Epoch=61.7] | Loss=0.00112 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.391 | L2-Norm(final)=4.985 | 4921.7 samples/s | 76.9 steps/s
[Step=16150 Epoch=61.9] | Loss=0.00090 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.410 | L2-Norm(final)=5.001 | 4896.1 samples/s | 76.5 steps/s
[Step=16200 Epoch=62.1] | Loss=0.00086 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.421 | L2-Norm(final)=5.016 | 4929.7 samples/s | 77.0 steps/s
[Step=16250 Epoch=62.3] | Loss=0.00100 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.432 | L2-Norm(final)=5.029 | 6796.5 samples/s | 106.2 steps/s
[Step=16300 Epoch=62.5] | Loss=0.00087 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.446 | L2-Norm(final)=5.040 | 2488.6 samples/s | 38.9 steps/s
[Step=16350 Epoch=62.6] | Loss=0.00077 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.453 | L2-Norm(final)=5.051 | 4784.3 samples/s | 74.8 steps/s
[Step=16400 Epoch=62.8] | Loss=0.00069 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.454 | L2-Norm(final)=5.062 | 4901.7 samples/s | 76.6 steps/s
[Step=16450 Epoch=63.0] | Loss=0.00062 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.452 | L2-Norm(final)=5.073 | 4952.8 samples/s | 77.4 steps/s
[Step=16500 Epoch=63.2] | Loss=0.00059 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.447 | L2-Norm(final)=5.083 | 5599.9 samples/s | 87.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=63.2] | Loss=0.00014 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.394 | L2-Norm(final)=5.185 | 6641.3 samples/s | 103.8 steps/s
[Step=16550 Epoch=63.4] | Loss=0.00006 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=5.193 | 3797.9 samples/s | 59.3 steps/s
[Step=16600 Epoch=63.6] | Loss=0.00006 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.344 | L2-Norm(final)=5.198 | 4398.2 samples/s | 68.7 steps/s
[Step=16650 Epoch=63.8] | Loss=0.00376 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.346 | L2-Norm(final)=5.196 | 4309.2 samples/s | 67.3 steps/s
[Step=16700 Epoch=64.0] | Loss=0.00705 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.525 | L2-Norm(final)=5.148 | 4420.6 samples/s | 69.1 steps/s
[Step=16750 Epoch=64.2] | Loss=0.00693 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=5.103 | 5824.1 samples/s | 91.0 steps/s
[Step=16800 Epoch=64.4] | Loss=0.00603 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.803 | L2-Norm(final)=5.074 | 2331.2 samples/s | 36.4 steps/s
[Step=16850 Epoch=64.6] | Loss=0.00541 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=5.056 | 4404.0 samples/s | 68.8 steps/s
[Step=16900 Epoch=64.8] | Loss=0.00519 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=5.041 | 4389.8 samples/s | 68.6 steps/s
[Step=16950 Epoch=64.9] | Loss=0.00472 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.993 | L2-Norm(final)=5.028 | 4452.7 samples/s | 69.6 steps/s
[Step=17000 Epoch=65.1] | Loss=0.00431 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=5.018 | 4912.5 samples/s | 76.8 steps/s
[Step=17050 Epoch=65.3] | Loss=0.00406 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.061 | L2-Norm(final)=5.011 | 2499.7 samples/s | 39.1 steps/s
[Step=17100 Epoch=65.5] | Loss=0.00388 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.084 | L2-Norm(final)=5.004 | 4397.2 samples/s | 68.7 steps/s
[Step=17150 Epoch=65.7] | Loss=0.00370 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.108 | L2-Norm(final)=4.996 | 4396.8 samples/s | 68.7 steps/s
[Step=17200 Epoch=65.9] | Loss=0.00344 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=4.990 | 4420.8 samples/s | 69.1 steps/s
[Step=17250 Epoch=66.1] | Loss=0.00322 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.147 | L2-Norm(final)=4.985 | 4371.6 samples/s | 68.3 steps/s
[Step=17300 Epoch=66.3] | Loss=0.00302 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.158 | L2-Norm(final)=4.981 | 2686.7 samples/s | 42.0 steps/s
[Step=17350 Epoch=66.5] | Loss=0.00284 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=4.978 | 4539.7 samples/s | 70.9 steps/s
[Step=17400 Epoch=66.7] | Loss=0.00268 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=4.977 | 4249.3 samples/s | 66.4 steps/s
[Step=17450 Epoch=66.9] | Loss=0.00254 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=4.975 | 4487.8 samples/s | 70.1 steps/s
[Step=17500 Epoch=67.1] | Loss=0.00242 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=4.975 | 4393.1 samples/s | 68.6 steps/s
[Step=17550 Epoch=67.2] | Loss=0.00230 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=4.974 | 2666.0 samples/s | 41.7 steps/s
[Step=17600 Epoch=67.4] | Loss=0.00220 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=4.974 | 4355.4 samples/s | 68.1 steps/s
[Step=17650 Epoch=67.6] | Loss=0.00210 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.143 | L2-Norm(final)=4.974 | 4391.9 samples/s | 68.6 steps/s
[Step=17700 Epoch=67.8] | Loss=0.00201 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=4.974 | 4422.2 samples/s | 69.1 steps/s
[Step=17750 Epoch=68.0] | Loss=0.00193 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=4.975 | 4356.7 samples/s | 68.1 steps/s
[Step=17800 Epoch=68.2] | Loss=0.00186 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.110 | L2-Norm(final)=4.975 | 6511.5 samples/s | 101.7 steps/s
[Step=17850 Epoch=68.4] | Loss=0.00179 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=4.976 | 2240.4 samples/s | 35.0 steps/s
[Step=17900 Epoch=68.6] | Loss=0.00173 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=4.977 | 4402.6 samples/s | 68.8 steps/s
[Step=17950 Epoch=68.8] | Loss=0.00167 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=4.978 | 4390.6 samples/s | 68.6 steps/s
[Step=18000 Epoch=69.0] | Loss=0.00161 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=4.979 | 4389.1 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step18000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=61.6] | Loss=0.00350 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.419 | L2-Norm(final)=4.880 | 6271.7 samples/s | 98.0 steps/s
[Step=16050 Epoch=61.8] | Loss=0.00527 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.565 | L2-Norm(final)=4.870 | 4321.6 samples/s | 67.5 steps/s
[Step=16100 Epoch=62.0] | Loss=0.00316 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.647 | L2-Norm(final)=4.876 | 4900.3 samples/s | 76.6 steps/s
[Step=16150 Epoch=62.2] | Loss=0.00244 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.693 | L2-Norm(final)=4.897 | 5071.3 samples/s | 79.2 steps/s
[Step=16200 Epoch=62.4] | Loss=0.00204 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=4.915 | 4704.5 samples/s | 73.5 steps/s
[Step=16250 Epoch=62.6] | Loss=0.00168 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.741 | L2-Norm(final)=4.932 | 7046.5 samples/s | 110.1 steps/s
[Step=16300 Epoch=62.7] | Loss=0.00156 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.757 | L2-Norm(final)=4.946 | 2466.7 samples/s | 38.5 steps/s
[Step=16350 Epoch=62.9] | Loss=0.00137 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=4.961 | 4860.2 samples/s | 75.9 steps/s
[Step=16400 Epoch=63.1] | Loss=0.00122 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.774 | L2-Norm(final)=4.976 | 4867.4 samples/s | 76.1 steps/s
[Step=16450 Epoch=63.3] | Loss=0.00110 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.776 | L2-Norm(final)=4.990 | 4890.0 samples/s | 76.4 steps/s
[Step=16500 Epoch=63.5] | Loss=0.00101 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.774 | L2-Norm(final)=5.003 | 5876.4 samples/s | 91.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=63.5] | Loss=0.00003 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.744 | L2-Norm(final)=5.130 | 6032.6 samples/s | 94.3 steps/s
[Step=16550 Epoch=63.7] | Loss=0.00144 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.721 | L2-Norm(final)=5.133 | 4041.4 samples/s | 63.1 steps/s
[Step=16600 Epoch=63.9] | Loss=0.01094 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.900 | L2-Norm(final)=5.084 | 4322.7 samples/s | 67.5 steps/s
[Step=16650 Epoch=64.1] | Loss=0.01081 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.115 | L2-Norm(final)=5.016 | 4400.3 samples/s | 68.8 steps/s
[Step=16700 Epoch=64.3] | Loss=0.00905 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.245 | L2-Norm(final)=4.980 | 4399.0 samples/s | 68.7 steps/s
[Step=16750 Epoch=64.5] | Loss=0.00802 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=4.958 | 5941.1 samples/s | 92.8 steps/s
[Step=16800 Epoch=64.7] | Loss=0.00693 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.379 | L2-Norm(final)=4.944 | 2317.2 samples/s | 36.2 steps/s
[Step=16850 Epoch=64.9] | Loss=0.00599 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=4.936 | 4364.1 samples/s | 68.2 steps/s
[Step=16900 Epoch=65.1] | Loss=0.00526 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=4.933 | 4374.7 samples/s | 68.4 steps/s
[Step=16950 Epoch=65.2] | Loss=0.00468 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=4.931 | 4510.8 samples/s | 70.5 steps/s
[Step=17000 Epoch=65.4] | Loss=0.00424 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.437 | L2-Norm(final)=4.931 | 4981.8 samples/s | 77.8 steps/s
[Step=17050 Epoch=65.6] | Loss=0.00391 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=4.932 | 2498.2 samples/s | 39.0 steps/s
[Step=17100 Epoch=65.8] | Loss=0.00359 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=4.933 | 4425.0 samples/s | 69.1 steps/s
[Step=17150 Epoch=66.0] | Loss=0.00331 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.422 | L2-Norm(final)=4.934 | 4376.7 samples/s | 68.4 steps/s
[Step=17200 Epoch=66.2] | Loss=0.00308 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=4.936 | 4268.3 samples/s | 66.7 steps/s
[Step=17250 Epoch=66.4] | Loss=0.00288 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=4.938 | 4487.8 samples/s | 70.1 steps/s
[Step=17300 Epoch=66.6] | Loss=0.00270 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=4.939 | 2635.4 samples/s | 41.2 steps/s
[Step=17350 Epoch=66.8] | Loss=0.00254 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=4.941 | 4394.6 samples/s | 68.7 steps/s
[Step=17400 Epoch=67.0] | Loss=0.00240 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=4.943 | 4387.6 samples/s | 68.6 steps/s
[Step=17450 Epoch=67.2] | Loss=0.00227 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=4.945 | 4451.0 samples/s | 69.5 steps/s
[Step=17500 Epoch=67.4] | Loss=0.00216 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=4.946 | 4328.1 samples/s | 67.6 steps/s
[Step=17550 Epoch=67.6] | Loss=0.00206 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=4.948 | 2689.8 samples/s | 42.0 steps/s
[Step=17600 Epoch=67.7] | Loss=0.00196 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=4.950 | 4455.3 samples/s | 69.6 steps/s
[Step=17650 Epoch=67.9] | Loss=0.00188 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.247 | L2-Norm(final)=4.951 | 4368.3 samples/s | 68.3 steps/s
[Step=17700 Epoch=68.1] | Loss=0.00180 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.225 | L2-Norm(final)=4.953 | 4309.6 samples/s | 67.3 steps/s
[Step=17750 Epoch=68.3] | Loss=0.00173 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=4.955 | 4407.1 samples/s | 68.9 steps/s
[Step=17800 Epoch=68.5] | Loss=0.00166 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=4.956 | 7038.0 samples/s | 110.0 steps/s
[Step=17850 Epoch=68.7] | Loss=0.00160 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=4.958 | 2170.8 samples/s | 33.9 steps/s
[Step=17900 Epoch=68.9] | Loss=0.00154 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=4.959 | 4421.1 samples/s | 69.1 steps/s
[Step=17950 Epoch=69.1] | Loss=0.00149 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.110 | L2-Norm(final)=4.961 | 4413.9 samples/s | 69.0 steps/s
[Step=18000 Epoch=69.3] | Loss=0.00144 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.087 | L2-Norm(final)=4.963 | 4383.1 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07436 | acc=0.9574 | tpr=0.9573 | fpr=0.0424 | 5488.6 samples/s | 21.4 steps/s
Avg test loss: 0.07784, Avg test acc: 0.95549, Avg tpr: 0.95664, Avg fpr: 0.04705, total FA: 367

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07293 | acc=0.9569 | tpr=0.9572 | fpr=0.0439 | 5395.3 samples/s | 21.1 steps/s
Avg test loss: 0.07309, Avg test acc: 0.95545, Avg tpr: 0.95605, Avg fpr: 0.04589, total FA: 358

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.35629 | acc=0.3131 | tpr=0.0043 | fpr=0.0164 | 5434.0 samples/s | 21.2 steps/s
Avg test loss: 5.37800, Avg test acc: 0.31008, Avg tpr: 0.00408, Avg fpr: 0.01692, total FA: 132

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.04482 | acc=0.3142 | tpr=0.0015 | fpr=0.0067 | 5438.8 samples/s | 21.2 steps/s
Avg test loss: 5.05893, Avg test acc: 0.31140, Avg tpr: 0.00134, Avg fpr: 0.00667, total FA: 52

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.74968 | acc=0.1375 | tpr=0.5796 | fpr=0.8704 | 5044.9 samples/s | 19.7 steps/s
[Step= 100] | Loss=5.70900 | acc=0.1361 | tpr=0.5608 | fpr=0.8718 | 7714.2 samples/s | 30.1 steps/s
[Step= 150] | Loss=5.71408 | acc=0.1364 | tpr=0.5706 | fpr=0.8716 | 7783.1 samples/s | 30.4 steps/s
[Step= 200] | Loss=5.72178 | acc=0.1363 | tpr=0.5607 | fpr=0.8714 | 7957.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.72459 | acc=0.1366 | tpr=0.5607 | fpr=0.8711 | 8299.9 samples/s | 32.4 steps/s
[Step= 300] | Loss=5.72616 | acc=0.1367 | tpr=0.5687 | fpr=0.8712 | 8274.2 samples/s | 32.3 steps/s
[Step= 350] | Loss=5.71486 | acc=0.1374 | tpr=0.5667 | fpr=0.8704 | 7979.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.71301 | acc=0.1379 | tpr=0.5689 | fpr=0.8699 | 8190.8 samples/s | 32.0 steps/s
[Step= 450] | Loss=5.71522 | acc=0.1379 | tpr=0.5711 | fpr=0.8700 | 8078.4 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.71588 | acc=0.1374 | tpr=0.5674 | fpr=0.8704 | 8446.8 samples/s | 33.0 steps/s
[Step= 550] | Loss=5.71740 | acc=0.1373 | tpr=0.5678 | fpr=0.8705 | 13693.7 samples/s | 53.5 steps/s
Avg test loss: 5.71818, Avg test acc: 0.13720, Avg tpr: 0.56815, Avg fpr: 0.87064, total FA: 120886

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.91775 | acc=0.1501 | tpr=0.7699 | fpr=0.8611 | 5342.9 samples/s | 20.9 steps/s
[Step= 100] | Loss=4.89794 | acc=0.1511 | tpr=0.7655 | fpr=0.8604 | 7176.5 samples/s | 28.0 steps/s
[Step= 150] | Loss=4.91025 | acc=0.1514 | tpr=0.7522 | fpr=0.8596 | 7777.8 samples/s | 30.4 steps/s
[Step= 200] | Loss=4.91953 | acc=0.1506 | tpr=0.7421 | fpr=0.8602 | 7977.6 samples/s | 31.2 steps/s
[Step= 250] | Loss=4.91222 | acc=0.1518 | tpr=0.7354 | fpr=0.8589 | 8122.0 samples/s | 31.7 steps/s
[Step= 300] | Loss=4.91123 | acc=0.1514 | tpr=0.7411 | fpr=0.8594 | 8422.0 samples/s | 32.9 steps/s
[Step= 350] | Loss=4.90181 | acc=0.1517 | tpr=0.7408 | fpr=0.8590 | 7967.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=4.89815 | acc=0.1522 | tpr=0.7429 | fpr=0.8586 | 8215.3 samples/s | 32.1 steps/s
[Step= 450] | Loss=4.89801 | acc=0.1517 | tpr=0.7429 | fpr=0.8591 | 7903.2 samples/s | 30.9 steps/s
[Step= 500] | Loss=4.89978 | acc=0.1513 | tpr=0.7441 | fpr=0.8594 | 8229.7 samples/s | 32.1 steps/s
[Step= 550] | Loss=4.89473 | acc=0.1518 | tpr=0.7441 | fpr=0.8590 | 14373.2 samples/s | 56.1 steps/s
Avg test loss: 4.89571, Avg test acc: 0.15169, Avg tpr: 0.74406, Avg fpr: 0.85908, total FA: 119281

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13190 | acc=0.9797 | tpr=0.9469 | fpr=0.0197 | 5380.2 samples/s | 21.0 steps/s
[Step= 100] | Loss=0.13585 | acc=0.9794 | tpr=0.9339 | fpr=0.0198 | 6960.4 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.14245 | acc=0.9779 | tpr=0.9337 | fpr=0.0213 | 7990.5 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.14482 | acc=0.9780 | tpr=0.9366 | fpr=0.0213 | 8236.9 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.14371 | acc=0.9783 | tpr=0.9415 | fpr=0.0210 | 8258.8 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.14559 | acc=0.9781 | tpr=0.9418 | fpr=0.0212 | 8153.4 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.14672 | acc=0.9778 | tpr=0.9424 | fpr=0.0215 | 7942.6 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.14869 | acc=0.9776 | tpr=0.9393 | fpr=0.0217 | 8286.6 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.15199 | acc=0.9772 | tpr=0.9372 | fpr=0.0220 | 8109.5 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.15176 | acc=0.9773 | tpr=0.9379 | fpr=0.0220 | 8123.7 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.15111 | acc=0.9774 | tpr=0.9367 | fpr=0.0219 | 15287.9 samples/s | 59.7 steps/s
Avg test loss: 0.15068, Avg test acc: 0.97741, Avg tpr: 0.93621, Avg fpr: 0.02184, total FA: 3033

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13491 | acc=0.9776 | tpr=0.9425 | fpr=0.0218 | 5406.1 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.14230 | acc=0.9773 | tpr=0.9403 | fpr=0.0220 | 7187.0 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.14886 | acc=0.9769 | tpr=0.9496 | fpr=0.0226 | 7593.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.15197 | acc=0.9766 | tpr=0.9552 | fpr=0.0230 | 7950.6 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.15012 | acc=0.9766 | tpr=0.9493 | fpr=0.0229 | 8191.7 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.15334 | acc=0.9762 | tpr=0.9440 | fpr=0.0232 | 8005.2 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.15485 | acc=0.9760 | tpr=0.9449 | fpr=0.0234 | 8192.0 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.15655 | acc=0.9759 | tpr=0.9437 | fpr=0.0235 | 8140.0 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.15934 | acc=0.9755 | tpr=0.9411 | fpr=0.0238 | 8212.7 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.15812 | acc=0.9757 | tpr=0.9436 | fpr=0.0238 | 7880.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.15683 | acc=0.9759 | tpr=0.9431 | fpr=0.0235 | 14309.7 samples/s | 55.9 steps/s
Avg test loss: 0.15650, Avg test acc: 0.97592, Avg tpr: 0.94295, Avg fpr: 0.02348, total FA: 3260

server round 9/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=35.1] | Loss=0.09799 | Reg=0.00403 | acc=0.8750 | L2-Norm=20.066 | L2-Norm(final)=4.876 | 6345.5 samples/s | 99.1 steps/s
[Step=18050 Epoch=35.2] | Loss=0.04606 | Reg=0.00403 | acc=0.9062 | L2-Norm=20.078 | L2-Norm(final)=4.914 | 4602.7 samples/s | 71.9 steps/s
[Step=18100 Epoch=35.3] | Loss=0.04700 | Reg=0.00404 | acc=0.9531 | L2-Norm=20.092 | L2-Norm(final)=4.955 | 5371.6 samples/s | 83.9 steps/s
[Step=18150 Epoch=35.4] | Loss=0.04658 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.111 | L2-Norm(final)=4.985 | 5110.7 samples/s | 79.9 steps/s
[Step=18200 Epoch=35.5] | Loss=0.04494 | Reg=0.00405 | acc=0.9531 | L2-Norm=20.130 | L2-Norm(final)=5.015 | 5112.8 samples/s | 79.9 steps/s
[Step=18250 Epoch=35.6] | Loss=0.04439 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.147 | L2-Norm(final)=5.041 | 5146.7 samples/s | 80.4 steps/s
[Step=18300 Epoch=35.7] | Loss=0.04338 | Reg=0.00407 | acc=0.9531 | L2-Norm=20.163 | L2-Norm(final)=5.065 | 5204.7 samples/s | 81.3 steps/s
[Step=18350 Epoch=35.8] | Loss=0.04225 | Reg=0.00407 | acc=0.9844 | L2-Norm=20.180 | L2-Norm(final)=5.090 | 5284.3 samples/s | 82.6 steps/s
[Step=18400 Epoch=35.9] | Loss=0.04212 | Reg=0.00408 | acc=0.9688 | L2-Norm=20.198 | L2-Norm(final)=5.113 | 5157.5 samples/s | 80.6 steps/s
[Step=18450 Epoch=36.0] | Loss=0.04154 | Reg=0.00409 | acc=0.9688 | L2-Norm=20.215 | L2-Norm(final)=5.135 | 5288.8 samples/s | 82.6 steps/s
[Step=18500 Epoch=36.1] | Loss=0.04145 | Reg=0.00409 | acc=0.9531 | L2-Norm=20.232 | L2-Norm(final)=5.158 | 6878.6 samples/s | 107.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=36.1] | Loss=0.01449 | Reg=0.00416 | acc=0.9844 | L2-Norm=20.402 | L2-Norm(final)=5.381 | 6509.0 samples/s | 101.7 steps/s
[Step=18550 Epoch=36.2] | Loss=0.03594 | Reg=0.00417 | acc=0.9531 | L2-Norm=20.430 | L2-Norm(final)=5.385 | 4126.2 samples/s | 64.5 steps/s
[Step=18600 Epoch=36.3] | Loss=0.04396 | Reg=0.00419 | acc=0.9375 | L2-Norm=20.471 | L2-Norm(final)=5.369 | 4600.6 samples/s | 71.9 steps/s
[Step=18650 Epoch=36.4] | Loss=0.04122 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.506 | L2-Norm(final)=5.355 | 4671.6 samples/s | 73.0 steps/s
[Step=18700 Epoch=36.5] | Loss=0.04054 | Reg=0.00422 | acc=0.9375 | L2-Norm=20.535 | L2-Norm(final)=5.345 | 4646.0 samples/s | 72.6 steps/s
[Step=18750 Epoch=36.6] | Loss=0.04085 | Reg=0.00423 | acc=0.9688 | L2-Norm=20.559 | L2-Norm(final)=5.336 | 4561.3 samples/s | 71.3 steps/s
[Step=18800 Epoch=36.7] | Loss=0.03972 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.583 | L2-Norm(final)=5.327 | 4675.3 samples/s | 73.1 steps/s
[Step=18850 Epoch=36.8] | Loss=0.03885 | Reg=0.00425 | acc=0.9844 | L2-Norm=20.603 | L2-Norm(final)=5.320 | 4551.5 samples/s | 71.1 steps/s
[Step=18900 Epoch=36.9] | Loss=0.03858 | Reg=0.00425 | acc=0.9688 | L2-Norm=20.623 | L2-Norm(final)=5.313 | 4663.8 samples/s | 72.9 steps/s
[Step=18950 Epoch=37.0] | Loss=0.03777 | Reg=0.00426 | acc=0.9688 | L2-Norm=20.640 | L2-Norm(final)=5.307 | 4665.2 samples/s | 72.9 steps/s
[Step=19000 Epoch=37.1] | Loss=0.03744 | Reg=0.00427 | acc=0.9531 | L2-Norm=20.657 | L2-Norm(final)=5.301 | 5867.7 samples/s | 91.7 steps/s
[Step=19050 Epoch=37.2] | Loss=0.03709 | Reg=0.00427 | acc=0.9531 | L2-Norm=20.673 | L2-Norm(final)=5.294 | 2444.3 samples/s | 38.2 steps/s
[Step=19100 Epoch=37.3] | Loss=0.03587 | Reg=0.00428 | acc=1.0000 | L2-Norm=20.687 | L2-Norm(final)=5.288 | 4603.7 samples/s | 71.9 steps/s
[Step=19150 Epoch=37.3] | Loss=0.03524 | Reg=0.00429 | acc=0.9844 | L2-Norm=20.700 | L2-Norm(final)=5.282 | 4681.5 samples/s | 73.1 steps/s
[Step=19200 Epoch=37.4] | Loss=0.03470 | Reg=0.00429 | acc=1.0000 | L2-Norm=20.714 | L2-Norm(final)=5.276 | 4552.4 samples/s | 71.1 steps/s
[Step=19250 Epoch=37.5] | Loss=0.03448 | Reg=0.00430 | acc=0.9844 | L2-Norm=20.726 | L2-Norm(final)=5.271 | 4719.7 samples/s | 73.7 steps/s
[Step=19300 Epoch=37.6] | Loss=0.03377 | Reg=0.00430 | acc=0.9531 | L2-Norm=20.738 | L2-Norm(final)=5.266 | 4537.8 samples/s | 70.9 steps/s
[Step=19350 Epoch=37.7] | Loss=0.03334 | Reg=0.00431 | acc=0.9844 | L2-Norm=20.749 | L2-Norm(final)=5.262 | 4668.3 samples/s | 72.9 steps/s
[Step=19400 Epoch=37.8] | Loss=0.03280 | Reg=0.00431 | acc=0.9844 | L2-Norm=20.760 | L2-Norm(final)=5.258 | 4582.4 samples/s | 71.6 steps/s
[Step=19450 Epoch=37.9] | Loss=0.03205 | Reg=0.00431 | acc=1.0000 | L2-Norm=20.770 | L2-Norm(final)=5.254 | 4629.1 samples/s | 72.3 steps/s
[Step=19500 Epoch=38.0] | Loss=0.03158 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.780 | L2-Norm(final)=5.251 | 5007.3 samples/s | 78.2 steps/s
[Step=19550 Epoch=38.1] | Loss=0.03124 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.789 | L2-Norm(final)=5.247 | 2674.1 samples/s | 41.8 steps/s
[Step=19600 Epoch=38.2] | Loss=0.03063 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.797 | L2-Norm(final)=5.244 | 4580.8 samples/s | 71.6 steps/s
[Step=19650 Epoch=38.3] | Loss=0.03035 | Reg=0.00433 | acc=0.9531 | L2-Norm=20.804 | L2-Norm(final)=5.241 | 4612.0 samples/s | 72.1 steps/s
[Step=19700 Epoch=38.4] | Loss=0.02983 | Reg=0.00433 | acc=0.9688 | L2-Norm=20.811 | L2-Norm(final)=5.239 | 4652.3 samples/s | 72.7 steps/s
[Step=19750 Epoch=38.5] | Loss=0.02949 | Reg=0.00433 | acc=0.9688 | L2-Norm=20.817 | L2-Norm(final)=5.236 | 4619.1 samples/s | 72.2 steps/s
[Step=19800 Epoch=38.6] | Loss=0.02889 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.823 | L2-Norm(final)=5.233 | 4701.2 samples/s | 73.5 steps/s
[Step=19850 Epoch=38.7] | Loss=0.02852 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.828 | L2-Norm(final)=5.231 | 4588.8 samples/s | 71.7 steps/s
[Step=19900 Epoch=38.8] | Loss=0.02825 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.833 | L2-Norm(final)=5.229 | 4676.1 samples/s | 73.1 steps/s
[Step=19950 Epoch=38.9] | Loss=0.02799 | Reg=0.00434 | acc=0.9688 | L2-Norm=20.839 | L2-Norm(final)=5.227 | 4412.6 samples/s | 68.9 steps/s
[Step=20000 Epoch=39.0] | Loss=0.02781 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.844 | L2-Norm(final)=5.225 | 4566.6 samples/s | 71.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step20000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=35.2] | Loss=0.05984 | Reg=0.00437 | acc=0.9531 | L2-Norm=20.913 | L2-Norm(final)=5.135 | 6269.5 samples/s | 98.0 steps/s
[Step=18050 Epoch=35.3] | Loss=0.05161 | Reg=0.00438 | acc=0.9688 | L2-Norm=20.920 | L2-Norm(final)=5.170 | 4581.1 samples/s | 71.6 steps/s
[Step=18100 Epoch=35.4] | Loss=0.04809 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.934 | L2-Norm(final)=5.206 | 4996.8 samples/s | 78.1 steps/s
[Step=18150 Epoch=35.5] | Loss=0.04665 | Reg=0.00439 | acc=0.9219 | L2-Norm=20.954 | L2-Norm(final)=5.235 | 5159.3 samples/s | 80.6 steps/s
[Step=18200 Epoch=35.6] | Loss=0.04404 | Reg=0.00440 | acc=0.9688 | L2-Norm=20.972 | L2-Norm(final)=5.261 | 5227.0 samples/s | 81.7 steps/s
[Step=18250 Epoch=35.7] | Loss=0.04344 | Reg=0.00441 | acc=0.9844 | L2-Norm=20.991 | L2-Norm(final)=5.286 | 5176.6 samples/s | 80.9 steps/s
[Step=18300 Epoch=35.8] | Loss=0.04201 | Reg=0.00442 | acc=0.9688 | L2-Norm=21.013 | L2-Norm(final)=5.310 | 5174.1 samples/s | 80.8 steps/s
[Step=18350 Epoch=35.9] | Loss=0.04218 | Reg=0.00442 | acc=1.0000 | L2-Norm=21.034 | L2-Norm(final)=5.332 | 5314.3 samples/s | 83.0 steps/s
[Step=18400 Epoch=36.0] | Loss=0.04179 | Reg=0.00443 | acc=0.9688 | L2-Norm=21.053 | L2-Norm(final)=5.352 | 5102.5 samples/s | 79.7 steps/s
[Step=18450 Epoch=36.1] | Loss=0.04113 | Reg=0.00444 | acc=0.9844 | L2-Norm=21.071 | L2-Norm(final)=5.372 | 5317.9 samples/s | 83.1 steps/s
[Step=18500 Epoch=36.2] | Loss=0.04102 | Reg=0.00445 | acc=1.0000 | L2-Norm=21.089 | L2-Norm(final)=5.393 | 6886.9 samples/s | 107.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=36.2] | Loss=0.01493 | Reg=0.00452 | acc=0.9844 | L2-Norm=21.253 | L2-Norm(final)=5.587 | 7002.3 samples/s | 109.4 steps/s
[Step=18550 Epoch=36.3] | Loss=0.03720 | Reg=0.00453 | acc=0.9688 | L2-Norm=21.282 | L2-Norm(final)=5.595 | 3895.8 samples/s | 60.9 steps/s
[Step=18600 Epoch=36.4] | Loss=0.04048 | Reg=0.00455 | acc=0.9375 | L2-Norm=21.320 | L2-Norm(final)=5.582 | 4615.9 samples/s | 72.1 steps/s
[Step=18650 Epoch=36.5] | Loss=0.03882 | Reg=0.00456 | acc=0.9375 | L2-Norm=21.351 | L2-Norm(final)=5.574 | 4621.7 samples/s | 72.2 steps/s
[Step=18700 Epoch=36.6] | Loss=0.04299 | Reg=0.00457 | acc=0.9688 | L2-Norm=21.380 | L2-Norm(final)=5.560 | 4617.0 samples/s | 72.1 steps/s
[Step=18750 Epoch=36.7] | Loss=0.04352 | Reg=0.00458 | acc=0.9688 | L2-Norm=21.410 | L2-Norm(final)=5.545 | 4665.4 samples/s | 72.9 steps/s
[Step=18800 Epoch=36.8] | Loss=0.04349 | Reg=0.00459 | acc=0.9531 | L2-Norm=21.436 | L2-Norm(final)=5.534 | 4642.6 samples/s | 72.5 steps/s
[Step=18850 Epoch=36.9] | Loss=0.04253 | Reg=0.00461 | acc=0.9844 | L2-Norm=21.460 | L2-Norm(final)=5.523 | 4586.7 samples/s | 71.7 steps/s
[Step=18900 Epoch=36.9] | Loss=0.04194 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.482 | L2-Norm(final)=5.514 | 4582.8 samples/s | 71.6 steps/s
[Step=18950 Epoch=37.0] | Loss=0.04138 | Reg=0.00462 | acc=0.9688 | L2-Norm=21.505 | L2-Norm(final)=5.506 | 4672.0 samples/s | 73.0 steps/s
[Step=19000 Epoch=37.1] | Loss=0.04116 | Reg=0.00463 | acc=0.9688 | L2-Norm=21.527 | L2-Norm(final)=5.496 | 6004.5 samples/s | 93.8 steps/s
[Step=19050 Epoch=37.2] | Loss=0.04010 | Reg=0.00464 | acc=0.9844 | L2-Norm=21.548 | L2-Norm(final)=5.488 | 2433.2 samples/s | 38.0 steps/s
[Step=19100 Epoch=37.3] | Loss=0.03877 | Reg=0.00465 | acc=0.9531 | L2-Norm=21.567 | L2-Norm(final)=5.481 | 4681.7 samples/s | 73.2 steps/s
[Step=19150 Epoch=37.4] | Loss=0.03746 | Reg=0.00466 | acc=0.9844 | L2-Norm=21.583 | L2-Norm(final)=5.476 | 4552.3 samples/s | 71.1 steps/s
[Step=19200 Epoch=37.5] | Loss=0.03634 | Reg=0.00466 | acc=0.9375 | L2-Norm=21.598 | L2-Norm(final)=5.472 | 4645.0 samples/s | 72.6 steps/s
[Step=19250 Epoch=37.6] | Loss=0.03566 | Reg=0.00467 | acc=1.0000 | L2-Norm=21.611 | L2-Norm(final)=5.468 | 4614.9 samples/s | 72.1 steps/s
[Step=19300 Epoch=37.7] | Loss=0.03531 | Reg=0.00468 | acc=0.9844 | L2-Norm=21.623 | L2-Norm(final)=5.464 | 4582.2 samples/s | 71.6 steps/s
[Step=19350 Epoch=37.8] | Loss=0.03476 | Reg=0.00468 | acc=0.9531 | L2-Norm=21.635 | L2-Norm(final)=5.459 | 4609.4 samples/s | 72.0 steps/s
[Step=19400 Epoch=37.9] | Loss=0.03454 | Reg=0.00469 | acc=0.9844 | L2-Norm=21.644 | L2-Norm(final)=5.454 | 4677.9 samples/s | 73.1 steps/s
[Step=19450 Epoch=38.0] | Loss=0.03404 | Reg=0.00469 | acc=0.9688 | L2-Norm=21.654 | L2-Norm(final)=5.449 | 4591.3 samples/s | 71.7 steps/s
[Step=19500 Epoch=38.1] | Loss=0.03381 | Reg=0.00469 | acc=0.9531 | L2-Norm=21.664 | L2-Norm(final)=5.443 | 5117.6 samples/s | 80.0 steps/s
[Step=19550 Epoch=38.2] | Loss=0.03333 | Reg=0.00470 | acc=0.9844 | L2-Norm=21.674 | L2-Norm(final)=5.437 | 2629.9 samples/s | 41.1 steps/s
[Step=19600 Epoch=38.3] | Loss=0.03245 | Reg=0.00470 | acc=0.9688 | L2-Norm=21.683 | L2-Norm(final)=5.432 | 4592.1 samples/s | 71.8 steps/s
[Step=19650 Epoch=38.4] | Loss=0.03195 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.691 | L2-Norm(final)=5.428 | 4562.5 samples/s | 71.3 steps/s
[Step=19700 Epoch=38.5] | Loss=0.03138 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.697 | L2-Norm(final)=5.423 | 4619.8 samples/s | 72.2 steps/s
[Step=19750 Epoch=38.6] | Loss=0.03086 | Reg=0.00471 | acc=1.0000 | L2-Norm=21.703 | L2-Norm(final)=5.419 | 4641.9 samples/s | 72.5 steps/s
[Step=19800 Epoch=38.7] | Loss=0.03045 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.708 | L2-Norm(final)=5.415 | 4559.1 samples/s | 71.2 steps/s
[Step=19850 Epoch=38.8] | Loss=0.03008 | Reg=0.00471 | acc=0.9844 | L2-Norm=21.713 | L2-Norm(final)=5.411 | 4678.3 samples/s | 73.1 steps/s
[Step=19900 Epoch=38.9] | Loss=0.02983 | Reg=0.00472 | acc=1.0000 | L2-Norm=21.718 | L2-Norm(final)=5.407 | 4598.3 samples/s | 71.8 steps/s
[Step=19950 Epoch=39.0] | Loss=0.02942 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.724 | L2-Norm(final)=5.403 | 4575.3 samples/s | 71.5 steps/s
[Step=20000 Epoch=39.1] | Loss=0.02907 | Reg=0.00472 | acc=0.9844 | L2-Norm=21.729 | L2-Norm(final)=5.400 | 4680.2 samples/s | 73.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step20000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=69.0] | Loss=0.00270 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.447 | L2-Norm(final)=5.013 | 5914.8 samples/s | 92.4 steps/s
[Step=18050 Epoch=69.2] | Loss=0.00129 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.517 | L2-Norm(final)=5.040 | 4491.8 samples/s | 70.2 steps/s
[Step=18100 Epoch=69.4] | Loss=0.00091 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.563 | L2-Norm(final)=5.061 | 4836.8 samples/s | 75.6 steps/s
[Step=18150 Epoch=69.5] | Loss=0.00080 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.589 | L2-Norm(final)=5.079 | 4897.4 samples/s | 76.5 steps/s
[Step=18200 Epoch=69.7] | Loss=0.00082 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=5.095 | 5007.5 samples/s | 78.2 steps/s
[Step=18250 Epoch=69.9] | Loss=0.00067 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=5.108 | 6641.3 samples/s | 103.8 steps/s
[Step=18300 Epoch=70.1] | Loss=0.00057 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.636 | L2-Norm(final)=5.119 | 2460.5 samples/s | 38.4 steps/s
[Step=18350 Epoch=70.3] | Loss=0.00050 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.634 | L2-Norm(final)=5.128 | 5019.7 samples/s | 78.4 steps/s
[Step=18400 Epoch=70.5] | Loss=0.00046 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=5.137 | 4811.2 samples/s | 75.2 steps/s
[Step=18450 Epoch=70.7] | Loss=0.00041 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=5.146 | 4988.3 samples/s | 77.9 steps/s
[Step=18500 Epoch=70.9] | Loss=0.00039 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=5.154 | 5490.3 samples/s | 85.8 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=70.9] | Loss=0.00007 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.538 | L2-Norm(final)=5.242 | 6485.4 samples/s | 101.3 steps/s
[Step=18550 Epoch=71.1] | Loss=0.00003 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.510 | L2-Norm(final)=5.248 | 4002.2 samples/s | 62.5 steps/s
[Step=18600 Epoch=71.3] | Loss=0.00003 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.472 | L2-Norm(final)=5.252 | 4389.1 samples/s | 68.6 steps/s
[Step=18650 Epoch=71.5] | Loss=0.00003 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.437 | L2-Norm(final)=5.256 | 4311.9 samples/s | 67.4 steps/s
[Step=18700 Epoch=71.7] | Loss=0.00004 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.403 | L2-Norm(final)=5.259 | 4379.8 samples/s | 68.4 steps/s
[Step=18750 Epoch=71.8] | Loss=0.00004 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.371 | L2-Norm(final)=5.264 | 5890.9 samples/s | 92.0 steps/s
[Step=18800 Epoch=72.0] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.340 | L2-Norm(final)=5.268 | 2333.3 samples/s | 36.5 steps/s
[Step=18850 Epoch=72.2] | Loss=0.00003 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.308 | L2-Norm(final)=5.271 | 4373.0 samples/s | 68.3 steps/s
[Step=18900 Epoch=72.4] | Loss=0.00003 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.275 | L2-Norm(final)=5.273 | 4417.8 samples/s | 69.0 steps/s
[Step=18950 Epoch=72.6] | Loss=0.00002 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.242 | L2-Norm(final)=5.275 | 4356.0 samples/s | 68.1 steps/s
[Step=19000 Epoch=72.8] | Loss=0.00002 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.210 | L2-Norm(final)=5.277 | 5009.0 samples/s | 78.3 steps/s
[Step=19050 Epoch=73.0] | Loss=0.00002 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.177 | L2-Norm(final)=5.279 | 2507.3 samples/s | 39.2 steps/s
[Step=19100 Epoch=73.2] | Loss=0.00002 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.145 | L2-Norm(final)=5.281 | 4502.0 samples/s | 70.3 steps/s
[Step=19150 Epoch=73.4] | Loss=0.00002 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.112 | L2-Norm(final)=5.282 | 4279.4 samples/s | 66.9 steps/s
[Step=19200 Epoch=73.6] | Loss=0.00002 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.080 | L2-Norm(final)=5.284 | 4345.5 samples/s | 67.9 steps/s
[Step=19250 Epoch=73.8] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.047 | L2-Norm(final)=5.285 | 4429.1 samples/s | 69.2 steps/s
[Step=19300 Epoch=74.0] | Loss=0.00002 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.015 | L2-Norm(final)=5.286 | 2663.1 samples/s | 41.6 steps/s
[Step=19350 Epoch=74.1] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.983 | L2-Norm(final)=5.288 | 4442.8 samples/s | 69.4 steps/s
[Step=19400 Epoch=74.3] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.951 | L2-Norm(final)=5.289 | 4295.3 samples/s | 67.1 steps/s
[Step=19450 Epoch=74.5] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.919 | L2-Norm(final)=5.290 | 4364.9 samples/s | 68.2 steps/s
[Step=19500 Epoch=74.7] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.886 | L2-Norm(final)=5.291 | 4374.6 samples/s | 68.4 steps/s
[Step=19550 Epoch=74.9] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.855 | L2-Norm(final)=5.292 | 2702.6 samples/s | 42.2 steps/s
[Step=19600 Epoch=75.1] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.823 | L2-Norm(final)=5.293 | 4348.6 samples/s | 67.9 steps/s
[Step=19650 Epoch=75.3] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.791 | L2-Norm(final)=5.294 | 4347.4 samples/s | 67.9 steps/s
[Step=19700 Epoch=75.5] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.759 | L2-Norm(final)=5.296 | 4478.9 samples/s | 70.0 steps/s
[Step=19750 Epoch=75.7] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.727 | L2-Norm(final)=5.297 | 4259.5 samples/s | 66.6 steps/s
[Step=19800 Epoch=75.9] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.695 | L2-Norm(final)=5.298 | 6538.4 samples/s | 102.2 steps/s
[Step=19850 Epoch=76.1] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.664 | L2-Norm(final)=5.299 | 2262.3 samples/s | 35.3 steps/s
[Step=19900 Epoch=76.2] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.632 | L2-Norm(final)=5.300 | 4431.9 samples/s | 69.2 steps/s
[Step=19950 Epoch=76.4] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.601 | L2-Norm(final)=5.301 | 4329.1 samples/s | 67.6 steps/s
[Step=20000 Epoch=76.6] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.569 | L2-Norm(final)=5.302 | 4316.4 samples/s | 67.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step20000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=69.3] | Loss=0.00142 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.367 | L2-Norm(final)=5.013 | 6087.4 samples/s | 95.1 steps/s
[Step=18050 Epoch=69.5] | Loss=0.00192 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.498 | L2-Norm(final)=5.025 | 4420.8 samples/s | 69.1 steps/s
[Step=18100 Epoch=69.7] | Loss=0.00153 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=5.043 | 4897.9 samples/s | 76.5 steps/s
[Step=18150 Epoch=69.9] | Loss=0.00144 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.642 | L2-Norm(final)=5.058 | 4876.7 samples/s | 76.2 steps/s
[Step=18200 Epoch=70.1] | Loss=0.00119 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=5.068 | 4933.8 samples/s | 77.1 steps/s
[Step=18250 Epoch=70.3] | Loss=0.00100 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=5.079 | 7064.1 samples/s | 110.4 steps/s
[Step=18300 Epoch=70.4] | Loss=0.00086 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=5.091 | 2438.1 samples/s | 38.1 steps/s
[Step=18350 Epoch=70.6] | Loss=0.00074 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.682 | L2-Norm(final)=5.101 | 4907.4 samples/s | 76.7 steps/s
[Step=18400 Epoch=70.8] | Loss=0.00068 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.677 | L2-Norm(final)=5.111 | 4916.9 samples/s | 76.8 steps/s
[Step=18450 Epoch=71.0] | Loss=0.00062 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.672 | L2-Norm(final)=5.122 | 4894.7 samples/s | 76.5 steps/s
[Step=18500 Epoch=71.2] | Loss=0.00056 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=5.132 | 5846.5 samples/s | 91.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=71.2] | Loss=0.00000 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.579 | L2-Norm(final)=5.229 | 5747.4 samples/s | 89.8 steps/s
[Step=18550 Epoch=71.4] | Loss=0.00010 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.550 | L2-Norm(final)=5.237 | 4127.3 samples/s | 64.5 steps/s
[Step=18600 Epoch=71.6] | Loss=0.00006 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.520 | L2-Norm(final)=5.245 | 4398.1 samples/s | 68.7 steps/s
[Step=18650 Epoch=71.8] | Loss=0.00005 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.486 | L2-Norm(final)=5.252 | 4381.3 samples/s | 68.5 steps/s
[Step=18700 Epoch=72.0] | Loss=0.00004 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.450 | L2-Norm(final)=5.257 | 4501.8 samples/s | 70.3 steps/s
[Step=18750 Epoch=72.2] | Loss=0.00004 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.415 | L2-Norm(final)=5.261 | 5807.1 samples/s | 90.7 steps/s
[Step=18800 Epoch=72.4] | Loss=0.00003 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.379 | L2-Norm(final)=5.265 | 2310.8 samples/s | 36.1 steps/s
[Step=18850 Epoch=72.6] | Loss=0.00003 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.344 | L2-Norm(final)=5.268 | 4381.5 samples/s | 68.5 steps/s
[Step=18900 Epoch=72.8] | Loss=0.00003 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.308 | L2-Norm(final)=5.271 | 4379.0 samples/s | 68.4 steps/s
[Step=18950 Epoch=72.9] | Loss=0.00002 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.273 | L2-Norm(final)=5.273 | 4403.6 samples/s | 68.8 steps/s
[Step=19000 Epoch=73.1] | Loss=0.00002 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.237 | L2-Norm(final)=5.275 | 5066.5 samples/s | 79.2 steps/s
[Step=19050 Epoch=73.3] | Loss=0.00002 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.202 | L2-Norm(final)=5.276 | 2494.5 samples/s | 39.0 steps/s
[Step=19100 Epoch=73.5] | Loss=0.00002 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.167 | L2-Norm(final)=5.278 | 4263.8 samples/s | 66.6 steps/s
[Step=19150 Epoch=73.7] | Loss=0.00002 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.132 | L2-Norm(final)=5.279 | 4371.7 samples/s | 68.3 steps/s
[Step=19200 Epoch=73.9] | Loss=0.00002 | Reg=0.00199 | acc=1.0000 | L2-Norm=14.097 | L2-Norm(final)=5.281 | 4385.5 samples/s | 68.5 steps/s
[Step=19250 Epoch=74.1] | Loss=0.00002 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.062 | L2-Norm(final)=5.282 | 4496.9 samples/s | 70.3 steps/s
[Step=19300 Epoch=74.3] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.027 | L2-Norm(final)=5.283 | 2696.9 samples/s | 42.1 steps/s
[Step=19350 Epoch=74.5] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.992 | L2-Norm(final)=5.284 | 4277.5 samples/s | 66.8 steps/s
[Step=19400 Epoch=74.7] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.958 | L2-Norm(final)=5.286 | 4383.8 samples/s | 68.5 steps/s
[Step=19450 Epoch=74.9] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.923 | L2-Norm(final)=5.287 | 4492.2 samples/s | 70.2 steps/s
[Step=19500 Epoch=75.1] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.889 | L2-Norm(final)=5.288 | 4306.7 samples/s | 67.3 steps/s
[Step=19550 Epoch=75.3] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.854 | L2-Norm(final)=5.289 | 2692.8 samples/s | 42.1 steps/s
[Step=19600 Epoch=75.4] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.820 | L2-Norm(final)=5.290 | 4312.9 samples/s | 67.4 steps/s
[Step=19650 Epoch=75.6] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.785 | L2-Norm(final)=5.292 | 4433.8 samples/s | 69.3 steps/s
[Step=19700 Epoch=75.8] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.751 | L2-Norm(final)=5.293 | 4365.3 samples/s | 68.2 steps/s
[Step=19750 Epoch=76.0] | Loss=0.00001 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=5.294 | 4434.7 samples/s | 69.3 steps/s
[Step=19800 Epoch=76.2] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=5.295 | 7009.5 samples/s | 109.5 steps/s
[Step=19850 Epoch=76.4] | Loss=0.00001 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.648 | L2-Norm(final)=5.296 | 2181.4 samples/s | 34.1 steps/s
[Step=19900 Epoch=76.6] | Loss=0.00001 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.614 | L2-Norm(final)=5.298 | 4344.5 samples/s | 67.9 steps/s
[Step=19950 Epoch=76.8] | Loss=0.00001 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.580 | L2-Norm(final)=5.299 | 4446.8 samples/s | 69.5 steps/s
[Step=20000 Epoch=77.0] | Loss=0.00001 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.546 | L2-Norm(final)=5.300 | 4443.0 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07819 | acc=0.9567 | tpr=0.9569 | fpr=0.0436 | 5401.8 samples/s | 21.1 steps/s
Avg test loss: 0.07980, Avg test acc: 0.95416, Avg tpr: 0.95518, Avg fpr: 0.04807, total FA: 375

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07993 | acc=0.9617 | tpr=0.9755 | fpr=0.0681 | 5409.5 samples/s | 21.1 steps/s
Avg test loss: 0.08157, Avg test acc: 0.96021, Avg tpr: 0.97470, Avg fpr: 0.07166, total FA: 559

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.32465 | acc=0.3094 | tpr=0.0087 | fpr=0.0377 | 5277.9 samples/s | 20.6 steps/s
Avg test loss: 5.33503, Avg test acc: 0.30700, Avg tpr: 0.00839, Avg fpr: 0.03628, total FA: 283

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.18398 | acc=0.3105 | tpr=0.0079 | fpr=0.0325 | 5369.8 samples/s | 21.0 steps/s
Avg test loss: 5.20193, Avg test acc: 0.30804, Avg tpr: 0.00781, Avg fpr: 0.03166, total FA: 247

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.49783 | acc=0.1433 | tpr=0.6195 | fpr=0.8653 | 5255.3 samples/s | 20.5 steps/s
[Step= 100] | Loss=5.47370 | acc=0.1436 | tpr=0.5991 | fpr=0.8649 | 7302.6 samples/s | 28.5 steps/s
[Step= 150] | Loss=5.48235 | acc=0.1427 | tpr=0.5965 | fpr=0.8657 | 7547.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=5.49770 | acc=0.1417 | tpr=0.5869 | fpr=0.8664 | 8304.0 samples/s | 32.4 steps/s
[Step= 250] | Loss=5.50054 | acc=0.1416 | tpr=0.5808 | fpr=0.8664 | 8094.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.49467 | acc=0.1418 | tpr=0.5956 | fpr=0.8665 | 8216.6 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.48476 | acc=0.1422 | tpr=0.5955 | fpr=0.8660 | 8035.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.47802 | acc=0.1428 | tpr=0.5996 | fpr=0.8655 | 8119.3 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.47905 | acc=0.1427 | tpr=0.6018 | fpr=0.8656 | 7936.2 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.47892 | acc=0.1428 | tpr=0.6004 | fpr=0.8655 | 8078.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.47824 | acc=0.1427 | tpr=0.5953 | fpr=0.8655 | 15638.2 samples/s | 61.1 steps/s
Avg test loss: 5.47982, Avg test acc: 0.14264, Avg tpr: 0.59628, Avg fpr: 0.86561, total FA: 120188

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.43744 | acc=0.1055 | tpr=0.7920 | fpr=0.9068 | 5230.3 samples/s | 20.4 steps/s
[Step= 100] | Loss=5.43361 | acc=0.1068 | tpr=0.7846 | fpr=0.9058 | 7322.5 samples/s | 28.6 steps/s
[Step= 150] | Loss=5.43928 | acc=0.1074 | tpr=0.7896 | fpr=0.9051 | 7732.6 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.45060 | acc=0.1066 | tpr=0.7738 | fpr=0.9056 | 8292.0 samples/s | 32.4 steps/s
[Step= 250] | Loss=5.45519 | acc=0.1069 | tpr=0.7668 | fpr=0.9051 | 7891.0 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.46079 | acc=0.1063 | tpr=0.7745 | fpr=0.9059 | 8254.4 samples/s | 32.2 steps/s
[Step= 350] | Loss=5.45337 | acc=0.1070 | tpr=0.7765 | fpr=0.9052 | 8105.7 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.44855 | acc=0.1075 | tpr=0.7752 | fpr=0.9046 | 8053.6 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.45012 | acc=0.1069 | tpr=0.7790 | fpr=0.9053 | 8307.5 samples/s | 32.5 steps/s
[Step= 500] | Loss=5.45017 | acc=0.1065 | tpr=0.7802 | fpr=0.9056 | 7892.1 samples/s | 30.8 steps/s
[Step= 550] | Loss=5.44633 | acc=0.1066 | tpr=0.7784 | fpr=0.9056 | 14778.8 samples/s | 57.7 steps/s
Avg test loss: 5.44740, Avg test acc: 0.10658, Avg tpr: 0.77892, Avg fpr: 0.90565, total FA: 125747

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15957 | acc=0.9775 | tpr=0.9469 | fpr=0.0220 | 5171.9 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.16417 | acc=0.9778 | tpr=0.9574 | fpr=0.0218 | 7729.1 samples/s | 30.2 steps/s
[Step= 150] | Loss=0.17068 | acc=0.9768 | tpr=0.9524 | fpr=0.0228 | 7526.2 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.17424 | acc=0.9768 | tpr=0.9574 | fpr=0.0228 | 8101.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.17235 | acc=0.9771 | tpr=0.9563 | fpr=0.0225 | 8155.0 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.17535 | acc=0.9767 | tpr=0.9564 | fpr=0.0230 | 8049.4 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.17708 | acc=0.9764 | tpr=0.9574 | fpr=0.0233 | 8096.2 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.17941 | acc=0.9760 | tpr=0.9546 | fpr=0.0236 | 8923.9 samples/s | 34.9 steps/s
[Step= 450] | Loss=0.18312 | acc=0.9757 | tpr=0.9528 | fpr=0.0239 | 7611.1 samples/s | 29.7 steps/s
[Step= 500] | Loss=0.18213 | acc=0.9758 | tpr=0.9533 | fpr=0.0238 | 8123.8 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.18089 | acc=0.9760 | tpr=0.9530 | fpr=0.0236 | 14680.7 samples/s | 57.3 steps/s
Avg test loss: 0.18050, Avg test acc: 0.97598, Avg tpr: 0.95246, Avg fpr: 0.02359, total FA: 3276

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15987 | acc=0.9777 | tpr=0.9558 | fpr=0.0219 | 4907.2 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.16265 | acc=0.9773 | tpr=0.9488 | fpr=0.0221 | 7831.6 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.16779 | acc=0.9764 | tpr=0.9524 | fpr=0.0231 | 8079.2 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.17183 | acc=0.9763 | tpr=0.9574 | fpr=0.0233 | 8020.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.16940 | acc=0.9766 | tpr=0.9572 | fpr=0.0231 | 8227.6 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.17298 | acc=0.9760 | tpr=0.9549 | fpr=0.0236 | 8190.2 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.17456 | acc=0.9757 | tpr=0.9543 | fpr=0.0239 | 8107.2 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.17686 | acc=0.9755 | tpr=0.9508 | fpr=0.0241 | 7914.6 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.18023 | acc=0.9751 | tpr=0.9508 | fpr=0.0245 | 7996.0 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.17918 | acc=0.9752 | tpr=0.9529 | fpr=0.0243 | 8179.9 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.17787 | acc=0.9755 | tpr=0.9522 | fpr=0.0241 | 15278.7 samples/s | 59.7 steps/s
Avg test loss: 0.17752, Avg test acc: 0.97548, Avg tpr: 0.95206, Avg fpr: 0.02410, total FA: 3346

server round 10/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=39.0] | Loss=0.02393 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.089 | L2-Norm(final)=5.157 | 6083.0 samples/s | 95.0 steps/s
[Step=20050 Epoch=39.1] | Loss=0.02233 | Reg=0.00404 | acc=0.9688 | L2-Norm=20.088 | L2-Norm(final)=5.162 | 4728.2 samples/s | 73.9 steps/s
[Step=20100 Epoch=39.2] | Loss=0.02140 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.084 | L2-Norm(final)=5.169 | 5204.9 samples/s | 81.3 steps/s
[Step=20150 Epoch=39.3] | Loss=0.02024 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.081 | L2-Norm(final)=5.177 | 5261.1 samples/s | 82.2 steps/s
[Step=20200 Epoch=39.4] | Loss=0.01907 | Reg=0.00403 | acc=1.0000 | L2-Norm=20.078 | L2-Norm(final)=5.185 | 5106.3 samples/s | 79.8 steps/s
[Step=20250 Epoch=39.5] | Loss=0.01796 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.074 | L2-Norm(final)=5.194 | 5208.1 samples/s | 81.4 steps/s
[Step=20300 Epoch=39.6] | Loss=0.01806 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.071 | L2-Norm(final)=5.203 | 5212.7 samples/s | 81.4 steps/s
[Step=20350 Epoch=39.7] | Loss=0.01766 | Reg=0.00403 | acc=0.9688 | L2-Norm=20.068 | L2-Norm(final)=5.211 | 5286.6 samples/s | 82.6 steps/s
[Step=20400 Epoch=39.8] | Loss=0.01761 | Reg=0.00403 | acc=0.9844 | L2-Norm=20.066 | L2-Norm(final)=5.219 | 5238.7 samples/s | 81.9 steps/s
[Step=20450 Epoch=39.9] | Loss=0.01742 | Reg=0.00403 | acc=0.9531 | L2-Norm=20.063 | L2-Norm(final)=5.225 | 5486.2 samples/s | 85.7 steps/s
[Step=20500 Epoch=40.0] | Loss=0.01741 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.061 | L2-Norm(final)=5.231 | 6493.2 samples/s | 101.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=40.0] | Loss=0.01036 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.039 | L2-Norm(final)=5.287 | 6701.2 samples/s | 104.7 steps/s
[Step=20550 Epoch=40.1] | Loss=0.01818 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.039 | L2-Norm(final)=5.288 | 4065.6 samples/s | 63.5 steps/s
[Step=20600 Epoch=40.2] | Loss=0.01976 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.042 | L2-Norm(final)=5.288 | 4599.0 samples/s | 71.9 steps/s
[Step=20650 Epoch=40.3] | Loss=0.01924 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.044 | L2-Norm(final)=5.287 | 4573.7 samples/s | 71.5 steps/s
[Step=20700 Epoch=40.4] | Loss=0.01885 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.047 | L2-Norm(final)=5.288 | 4678.5 samples/s | 73.1 steps/s
[Step=20750 Epoch=40.5] | Loss=0.01919 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.048 | L2-Norm(final)=5.289 | 4674.5 samples/s | 73.0 steps/s
[Step=20800 Epoch=40.6] | Loss=0.01860 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.049 | L2-Norm(final)=5.289 | 4649.7 samples/s | 72.7 steps/s
[Step=20850 Epoch=40.7] | Loss=0.01838 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.049 | L2-Norm(final)=5.290 | 4652.3 samples/s | 72.7 steps/s
[Step=20900 Epoch=40.8] | Loss=0.01817 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.049 | L2-Norm(final)=5.291 | 4545.1 samples/s | 71.0 steps/s
[Step=20950 Epoch=40.9] | Loss=0.01799 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.049 | L2-Norm(final)=5.292 | 4714.5 samples/s | 73.7 steps/s
[Step=21000 Epoch=41.0] | Loss=0.01765 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.049 | L2-Norm(final)=5.293 | 5868.9 samples/s | 91.7 steps/s
[Step=21050 Epoch=41.1] | Loss=0.01704 | Reg=0.00402 | acc=0.9688 | L2-Norm=20.049 | L2-Norm(final)=5.295 | 2442.8 samples/s | 38.2 steps/s
[Step=21100 Epoch=41.2] | Loss=0.01682 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.048 | L2-Norm(final)=5.297 | 4674.0 samples/s | 73.0 steps/s
[Step=21150 Epoch=41.3] | Loss=0.01653 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.047 | L2-Norm(final)=5.299 | 4566.0 samples/s | 71.3 steps/s
[Step=21200 Epoch=41.3] | Loss=0.01620 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.046 | L2-Norm(final)=5.300 | 4652.1 samples/s | 72.7 steps/s
[Step=21250 Epoch=41.4] | Loss=0.01585 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.045 | L2-Norm(final)=5.302 | 4637.4 samples/s | 72.5 steps/s
[Step=21300 Epoch=41.5] | Loss=0.01575 | Reg=0.00402 | acc=0.9844 | L2-Norm=20.044 | L2-Norm(final)=5.304 | 4547.2 samples/s | 71.0 steps/s
[Step=21350 Epoch=41.6] | Loss=0.01553 | Reg=0.00402 | acc=0.9688 | L2-Norm=20.042 | L2-Norm(final)=5.305 | 4626.7 samples/s | 72.3 steps/s
[Step=21400 Epoch=41.7] | Loss=0.01533 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.041 | L2-Norm(final)=5.306 | 4617.1 samples/s | 72.1 steps/s
[Step=21450 Epoch=41.8] | Loss=0.01521 | Reg=0.00402 | acc=1.0000 | L2-Norm=20.039 | L2-Norm(final)=5.308 | 4719.2 samples/s | 73.7 steps/s
[Step=21500 Epoch=41.9] | Loss=0.01518 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.037 | L2-Norm(final)=5.309 | 4878.1 samples/s | 76.2 steps/s
[Step=21550 Epoch=42.0] | Loss=0.01512 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.036 | L2-Norm(final)=5.310 | 2664.8 samples/s | 41.6 steps/s
[Step=21600 Epoch=42.1] | Loss=0.01485 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.034 | L2-Norm(final)=5.311 | 4647.1 samples/s | 72.6 steps/s
[Step=21650 Epoch=42.2] | Loss=0.01461 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.032 | L2-Norm(final)=5.313 | 4582.3 samples/s | 71.6 steps/s
[Step=21700 Epoch=42.3] | Loss=0.01446 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.030 | L2-Norm(final)=5.315 | 4636.0 samples/s | 72.4 steps/s
[Step=21750 Epoch=42.4] | Loss=0.01429 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.029 | L2-Norm(final)=5.317 | 4658.4 samples/s | 72.8 steps/s
[Step=21800 Epoch=42.5] | Loss=0.01405 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.027 | L2-Norm(final)=5.319 | 4531.5 samples/s | 70.8 steps/s
[Step=21850 Epoch=42.6] | Loss=0.01388 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.024 | L2-Norm(final)=5.321 | 4630.2 samples/s | 72.3 steps/s
[Step=21900 Epoch=42.7] | Loss=0.01387 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.022 | L2-Norm(final)=5.323 | 4628.4 samples/s | 72.3 steps/s
[Step=21950 Epoch=42.8] | Loss=0.01390 | Reg=0.00401 | acc=1.0000 | L2-Norm=20.020 | L2-Norm(final)=5.324 | 4658.3 samples/s | 72.8 steps/s
[Step=22000 Epoch=42.9] | Loss=0.01392 | Reg=0.00401 | acc=0.9844 | L2-Norm=20.017 | L2-Norm(final)=5.326 | 4567.2 samples/s | 71.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step22000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=39.1] | Loss=0.02671 | Reg=0.00439 | acc=0.9688 | L2-Norm=20.945 | L2-Norm(final)=5.303 | 6033.0 samples/s | 94.3 steps/s
[Step=20050 Epoch=39.2] | Loss=0.01811 | Reg=0.00439 | acc=0.9844 | L2-Norm=20.943 | L2-Norm(final)=5.315 | 4831.6 samples/s | 75.5 steps/s
[Step=20100 Epoch=39.3] | Loss=0.01758 | Reg=0.00438 | acc=0.9688 | L2-Norm=20.940 | L2-Norm(final)=5.330 | 5178.5 samples/s | 80.9 steps/s
[Step=20150 Epoch=39.4] | Loss=0.01694 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.936 | L2-Norm(final)=5.340 | 5226.8 samples/s | 81.7 steps/s
[Step=20200 Epoch=39.5] | Loss=0.01633 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.931 | L2-Norm(final)=5.350 | 5295.5 samples/s | 82.7 steps/s
[Step=20250 Epoch=39.6] | Loss=0.01646 | Reg=0.00438 | acc=0.9688 | L2-Norm=20.927 | L2-Norm(final)=5.359 | 5076.6 samples/s | 79.3 steps/s
[Step=20300 Epoch=39.7] | Loss=0.01663 | Reg=0.00438 | acc=0.9844 | L2-Norm=20.923 | L2-Norm(final)=5.367 | 5236.2 samples/s | 81.8 steps/s
[Step=20350 Epoch=39.8] | Loss=0.01625 | Reg=0.00438 | acc=1.0000 | L2-Norm=20.918 | L2-Norm(final)=5.375 | 5175.4 samples/s | 80.9 steps/s
[Step=20400 Epoch=39.9] | Loss=0.01591 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.914 | L2-Norm(final)=5.382 | 5239.5 samples/s | 81.9 steps/s
[Step=20450 Epoch=40.0] | Loss=0.01591 | Reg=0.00437 | acc=1.0000 | L2-Norm=20.910 | L2-Norm(final)=5.389 | 5287.1 samples/s | 82.6 steps/s
[Step=20500 Epoch=40.1] | Loss=0.01566 | Reg=0.00437 | acc=0.9844 | L2-Norm=20.906 | L2-Norm(final)=5.395 | 6979.7 samples/s | 109.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=40.1] | Loss=0.01592 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.865 | L2-Norm(final)=5.462 | 6286.6 samples/s | 98.2 steps/s
[Step=20550 Epoch=40.2] | Loss=0.01611 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.863 | L2-Norm(final)=5.468 | 4221.5 samples/s | 66.0 steps/s
[Step=20600 Epoch=40.3] | Loss=0.01545 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.863 | L2-Norm(final)=5.468 | 4648.8 samples/s | 72.6 steps/s
[Step=20650 Epoch=40.4] | Loss=0.01460 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.861 | L2-Norm(final)=5.470 | 4575.7 samples/s | 71.5 steps/s
[Step=20700 Epoch=40.5] | Loss=0.01415 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.860 | L2-Norm(final)=5.472 | 4603.6 samples/s | 71.9 steps/s
[Step=20750 Epoch=40.6] | Loss=0.01471 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.857 | L2-Norm(final)=5.474 | 4675.4 samples/s | 73.1 steps/s
[Step=20800 Epoch=40.7] | Loss=0.01524 | Reg=0.00435 | acc=0.9531 | L2-Norm=20.856 | L2-Norm(final)=5.476 | 4575.1 samples/s | 71.5 steps/s
[Step=20850 Epoch=40.8] | Loss=0.01576 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.854 | L2-Norm(final)=5.476 | 4614.4 samples/s | 72.1 steps/s
[Step=20900 Epoch=40.9] | Loss=0.01582 | Reg=0.00435 | acc=0.9688 | L2-Norm=20.852 | L2-Norm(final)=5.477 | 4621.4 samples/s | 72.2 steps/s
[Step=20950 Epoch=41.0] | Loss=0.01595 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.850 | L2-Norm(final)=5.478 | 4639.3 samples/s | 72.5 steps/s
[Step=21000 Epoch=41.1] | Loss=0.01607 | Reg=0.00435 | acc=0.9844 | L2-Norm=20.849 | L2-Norm(final)=5.479 | 6041.0 samples/s | 94.4 steps/s
[Step=21050 Epoch=41.2] | Loss=0.01585 | Reg=0.00435 | acc=1.0000 | L2-Norm=20.847 | L2-Norm(final)=5.480 | 2430.5 samples/s | 38.0 steps/s
[Step=21100 Epoch=41.2] | Loss=0.01535 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.845 | L2-Norm(final)=5.481 | 4622.6 samples/s | 72.2 steps/s
[Step=21150 Epoch=41.3] | Loss=0.01508 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.842 | L2-Norm(final)=5.483 | 4675.6 samples/s | 73.1 steps/s
[Step=21200 Epoch=41.4] | Loss=0.01495 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.839 | L2-Norm(final)=5.484 | 4677.1 samples/s | 73.1 steps/s
[Step=21250 Epoch=41.5] | Loss=0.01475 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.835 | L2-Norm(final)=5.486 | 4475.8 samples/s | 69.9 steps/s
[Step=21300 Epoch=41.6] | Loss=0.01464 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.832 | L2-Norm(final)=5.487 | 4768.2 samples/s | 74.5 steps/s
[Step=21350 Epoch=41.7] | Loss=0.01448 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.828 | L2-Norm(final)=5.488 | 4637.8 samples/s | 72.5 steps/s
[Step=21400 Epoch=41.8] | Loss=0.01432 | Reg=0.00434 | acc=0.9844 | L2-Norm=20.825 | L2-Norm(final)=5.489 | 4575.6 samples/s | 71.5 steps/s
[Step=21450 Epoch=41.9] | Loss=0.01427 | Reg=0.00434 | acc=1.0000 | L2-Norm=20.821 | L2-Norm(final)=5.490 | 4579.8 samples/s | 71.6 steps/s
[Step=21500 Epoch=42.0] | Loss=0.01416 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.817 | L2-Norm(final)=5.491 | 5092.1 samples/s | 79.6 steps/s
[Step=21550 Epoch=42.1] | Loss=0.01388 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.813 | L2-Norm(final)=5.492 | 2630.7 samples/s | 41.1 steps/s
[Step=21600 Epoch=42.2] | Loss=0.01367 | Reg=0.00433 | acc=0.9844 | L2-Norm=20.808 | L2-Norm(final)=5.494 | 4577.9 samples/s | 71.5 steps/s
[Step=21650 Epoch=42.3] | Loss=0.01352 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.804 | L2-Norm(final)=5.495 | 4679.1 samples/s | 73.1 steps/s
[Step=21700 Epoch=42.4] | Loss=0.01347 | Reg=0.00433 | acc=1.0000 | L2-Norm=20.800 | L2-Norm(final)=5.497 | 4598.8 samples/s | 71.9 steps/s
[Step=21750 Epoch=42.5] | Loss=0.01344 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.795 | L2-Norm(final)=5.498 | 4621.5 samples/s | 72.2 steps/s
[Step=21800 Epoch=42.6] | Loss=0.01334 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.791 | L2-Norm(final)=5.500 | 4587.1 samples/s | 71.7 steps/s
[Step=21850 Epoch=42.7] | Loss=0.01334 | Reg=0.00432 | acc=0.9688 | L2-Norm=20.787 | L2-Norm(final)=5.501 | 4681.3 samples/s | 73.1 steps/s
[Step=21900 Epoch=42.8] | Loss=0.01322 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.782 | L2-Norm(final)=5.502 | 4595.1 samples/s | 71.8 steps/s
[Step=21950 Epoch=42.9] | Loss=0.01309 | Reg=0.00432 | acc=0.9844 | L2-Norm=20.778 | L2-Norm(final)=5.503 | 4694.1 samples/s | 73.3 steps/s
[Step=22000 Epoch=43.0] | Loss=0.01309 | Reg=0.00432 | acc=1.0000 | L2-Norm=20.774 | L2-Norm(final)=5.504 | 4720.3 samples/s | 73.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step22000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=76.6] | Loss=0.00004 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.399 | L2-Norm(final)=5.335 | 6074.1 samples/s | 94.9 steps/s
[Step=20050 Epoch=76.8] | Loss=0.00509 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.464 | L2-Norm(final)=5.314 | 4372.7 samples/s | 68.3 steps/s
[Step=20100 Epoch=77.0] | Loss=0.00338 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.546 | L2-Norm(final)=5.291 | 4911.8 samples/s | 76.7 steps/s
[Step=20150 Epoch=77.2] | Loss=0.00279 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.585 | L2-Norm(final)=5.287 | 4875.2 samples/s | 76.2 steps/s
[Step=20200 Epoch=77.4] | Loss=0.00232 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.612 | L2-Norm(final)=5.289 | 4971.4 samples/s | 77.7 steps/s
[Step=20250 Epoch=77.6] | Loss=0.00200 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.632 | L2-Norm(final)=5.294 | 6710.0 samples/s | 104.8 steps/s
[Step=20300 Epoch=77.8] | Loss=0.00169 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.647 | L2-Norm(final)=5.298 | 2460.4 samples/s | 38.4 steps/s
[Step=20350 Epoch=78.0] | Loss=0.00146 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.656 | L2-Norm(final)=5.303 | 4918.3 samples/s | 76.8 steps/s
[Step=20400 Epoch=78.2] | Loss=0.00129 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.662 | L2-Norm(final)=5.307 | 4850.7 samples/s | 75.8 steps/s
[Step=20450 Epoch=78.4] | Loss=0.00116 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.665 | L2-Norm(final)=5.311 | 5000.4 samples/s | 78.1 steps/s
[Step=20500 Epoch=78.5] | Loss=0.00105 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.667 | L2-Norm(final)=5.315 | 5555.8 samples/s | 86.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=78.6] | Loss=0.00003 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.684 | L2-Norm(final)=5.354 | 6416.7 samples/s | 100.3 steps/s
[Step=20550 Epoch=78.7] | Loss=0.00005 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.669 | L2-Norm(final)=5.356 | 3845.5 samples/s | 60.1 steps/s
[Step=20600 Epoch=78.9] | Loss=0.00004 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.648 | L2-Norm(final)=5.359 | 4404.3 samples/s | 68.8 steps/s
[Step=20650 Epoch=79.1] | Loss=0.00003 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.627 | L2-Norm(final)=5.360 | 4416.8 samples/s | 69.0 steps/s
[Step=20700 Epoch=79.3] | Loss=0.00005 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.606 | L2-Norm(final)=5.361 | 4400.9 samples/s | 68.8 steps/s
[Step=20750 Epoch=79.5] | Loss=0.00389 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.623 | L2-Norm(final)=5.352 | 5816.6 samples/s | 90.9 steps/s
[Step=20800 Epoch=79.7] | Loss=0.00384 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.658 | L2-Norm(final)=5.337 | 2359.9 samples/s | 36.9 steps/s
[Step=20850 Epoch=79.9] | Loss=0.00347 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.686 | L2-Norm(final)=5.328 | 4324.0 samples/s | 67.6 steps/s
[Step=20900 Epoch=80.1] | Loss=0.00322 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.707 | L2-Norm(final)=5.322 | 4456.0 samples/s | 69.6 steps/s
[Step=20950 Epoch=80.3] | Loss=0.00291 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.722 | L2-Norm(final)=5.318 | 4289.6 samples/s | 67.0 steps/s
[Step=21000 Epoch=80.5] | Loss=0.00268 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.734 | L2-Norm(final)=5.315 | 5000.5 samples/s | 78.1 steps/s
[Step=21050 Epoch=80.7] | Loss=0.00245 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.743 | L2-Norm(final)=5.313 | 2503.0 samples/s | 39.1 steps/s
[Step=21100 Epoch=80.8] | Loss=0.00225 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.749 | L2-Norm(final)=5.312 | 4412.5 samples/s | 68.9 steps/s
[Step=21150 Epoch=81.0] | Loss=0.00208 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.753 | L2-Norm(final)=5.311 | 4389.2 samples/s | 68.6 steps/s
[Step=21200 Epoch=81.2] | Loss=0.00193 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.755 | L2-Norm(final)=5.310 | 4383.8 samples/s | 68.5 steps/s
[Step=21250 Epoch=81.4] | Loss=0.00180 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.757 | L2-Norm(final)=5.310 | 4443.9 samples/s | 69.4 steps/s
[Step=21300 Epoch=81.6] | Loss=0.00169 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.757 | L2-Norm(final)=5.309 | 2701.4 samples/s | 42.2 steps/s
[Step=21350 Epoch=81.8] | Loss=0.00159 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.756 | L2-Norm(final)=5.309 | 4421.4 samples/s | 69.1 steps/s
[Step=21400 Epoch=82.0] | Loss=0.00150 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.754 | L2-Norm(final)=5.309 | 4286.3 samples/s | 67.0 steps/s
[Step=21450 Epoch=82.2] | Loss=0.00143 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.752 | L2-Norm(final)=5.309 | 4371.5 samples/s | 68.3 steps/s
[Step=21500 Epoch=82.4] | Loss=0.00135 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.749 | L2-Norm(final)=5.310 | 4358.1 samples/s | 68.1 steps/s
[Step=21550 Epoch=82.6] | Loss=0.00129 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.746 | L2-Norm(final)=5.310 | 2701.4 samples/s | 42.2 steps/s
[Step=21600 Epoch=82.8] | Loss=0.00123 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.742 | L2-Norm(final)=5.310 | 4369.1 samples/s | 68.3 steps/s
[Step=21650 Epoch=83.0] | Loss=0.00118 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.737 | L2-Norm(final)=5.311 | 4403.8 samples/s | 68.8 steps/s
[Step=21700 Epoch=83.1] | Loss=0.00113 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.733 | L2-Norm(final)=5.311 | 4393.0 samples/s | 68.6 steps/s
[Step=21750 Epoch=83.3] | Loss=0.00109 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.728 | L2-Norm(final)=5.311 | 4428.4 samples/s | 69.2 steps/s
[Step=21800 Epoch=83.5] | Loss=0.00104 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.723 | L2-Norm(final)=5.312 | 6394.6 samples/s | 99.9 steps/s
[Step=21850 Epoch=83.7] | Loss=0.00101 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.717 | L2-Norm(final)=5.312 | 2260.9 samples/s | 35.3 steps/s
[Step=21900 Epoch=83.9] | Loss=0.00097 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.712 | L2-Norm(final)=5.313 | 4279.6 samples/s | 66.9 steps/s
[Step=21950 Epoch=84.1] | Loss=0.00094 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.706 | L2-Norm(final)=5.314 | 4438.8 samples/s | 69.4 steps/s
[Step=22000 Epoch=84.3] | Loss=0.00091 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.700 | L2-Norm(final)=5.314 | 4379.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step22000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=77.0] | Loss=0.01454 | Reg=0.00179 | acc=0.9844 | L2-Norm=13.361 | L2-Norm(final)=5.337 | 6354.1 samples/s | 99.3 steps/s
[Step=20050 Epoch=77.2] | Loss=0.00759 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.512 | L2-Norm(final)=5.306 | 4297.5 samples/s | 67.1 steps/s
[Step=20100 Epoch=77.4] | Loss=0.00454 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.608 | L2-Norm(final)=5.294 | 4943.9 samples/s | 77.2 steps/s
[Step=20150 Epoch=77.6] | Loss=0.00315 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.646 | L2-Norm(final)=5.292 | 4894.7 samples/s | 76.5 steps/s
[Step=20200 Epoch=77.8] | Loss=0.00276 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.667 | L2-Norm(final)=5.293 | 4814.4 samples/s | 75.2 steps/s
[Step=20250 Epoch=78.0] | Loss=0.00259 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=5.295 | 7030.6 samples/s | 109.9 steps/s
[Step=20300 Epoch=78.1] | Loss=0.00221 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.697 | L2-Norm(final)=5.297 | 2444.9 samples/s | 38.2 steps/s
[Step=20350 Epoch=78.3] | Loss=0.00196 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.706 | L2-Norm(final)=5.301 | 4952.0 samples/s | 77.4 steps/s
[Step=20400 Epoch=78.5] | Loss=0.00176 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.713 | L2-Norm(final)=5.304 | 4858.1 samples/s | 75.9 steps/s
[Step=20450 Epoch=78.7] | Loss=0.00158 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.718 | L2-Norm(final)=5.307 | 4927.1 samples/s | 77.0 steps/s
[Step=20500 Epoch=78.9] | Loss=0.00144 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.722 | L2-Norm(final)=5.311 | 5862.1 samples/s | 91.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=78.9] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.753 | L2-Norm(final)=5.346 | 6321.1 samples/s | 98.8 steps/s
[Step=20550 Epoch=79.1] | Loss=0.01017 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.812 | L2-Norm(final)=5.342 | 3898.2 samples/s | 60.9 steps/s
[Step=20600 Epoch=79.3] | Loss=0.00894 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.915 | L2-Norm(final)=5.314 | 4356.6 samples/s | 68.1 steps/s
[Step=20650 Epoch=79.5] | Loss=0.00632 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.962 | L2-Norm(final)=5.300 | 4436.9 samples/s | 69.3 steps/s
[Step=20700 Epoch=79.7] | Loss=0.00489 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.985 | L2-Norm(final)=5.297 | 4425.4 samples/s | 69.1 steps/s
[Step=20750 Epoch=79.9] | Loss=0.00412 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.998 | L2-Norm(final)=5.296 | 5872.6 samples/s | 91.8 steps/s
[Step=20800 Epoch=80.1] | Loss=0.00363 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.005 | L2-Norm(final)=5.295 | 2316.0 samples/s | 36.2 steps/s
[Step=20850 Epoch=80.3] | Loss=0.00313 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.008 | L2-Norm(final)=5.295 | 4321.3 samples/s | 67.5 steps/s
[Step=20900 Epoch=80.5] | Loss=0.00275 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.008 | L2-Norm(final)=5.295 | 4427.2 samples/s | 69.2 steps/s
[Step=20950 Epoch=80.6] | Loss=0.00245 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.007 | L2-Norm(final)=5.295 | 4389.7 samples/s | 68.6 steps/s
[Step=21000 Epoch=80.8] | Loss=0.00221 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.004 | L2-Norm(final)=5.296 | 5051.9 samples/s | 78.9 steps/s
[Step=21050 Epoch=81.0] | Loss=0.00201 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.000 | L2-Norm(final)=5.296 | 2475.4 samples/s | 38.7 steps/s
[Step=21100 Epoch=81.2] | Loss=0.00184 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.996 | L2-Norm(final)=5.297 | 4413.9 samples/s | 69.0 steps/s
[Step=21150 Epoch=81.4] | Loss=0.00170 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.991 | L2-Norm(final)=5.298 | 4336.5 samples/s | 67.8 steps/s
[Step=21200 Epoch=81.6] | Loss=0.00158 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.986 | L2-Norm(final)=5.298 | 4421.5 samples/s | 69.1 steps/s
[Step=21250 Epoch=81.8] | Loss=0.00148 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.980 | L2-Norm(final)=5.299 | 4439.0 samples/s | 69.4 steps/s
[Step=21300 Epoch=82.0] | Loss=0.00139 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.974 | L2-Norm(final)=5.299 | 2659.6 samples/s | 41.6 steps/s
[Step=21350 Epoch=82.2] | Loss=0.00131 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.967 | L2-Norm(final)=5.300 | 4292.8 samples/s | 67.1 steps/s
[Step=21400 Epoch=82.4] | Loss=0.00123 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.961 | L2-Norm(final)=5.301 | 4429.3 samples/s | 69.2 steps/s
[Step=21450 Epoch=82.6] | Loss=0.00117 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.954 | L2-Norm(final)=5.301 | 4330.8 samples/s | 67.7 steps/s
[Step=21500 Epoch=82.8] | Loss=0.00111 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.946 | L2-Norm(final)=5.302 | 4441.5 samples/s | 69.4 steps/s
[Step=21550 Epoch=83.0] | Loss=0.00106 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.939 | L2-Norm(final)=5.302 | 2668.0 samples/s | 41.7 steps/s
[Step=21600 Epoch=83.1] | Loss=0.00101 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.932 | L2-Norm(final)=5.303 | 4500.4 samples/s | 70.3 steps/s
[Step=21650 Epoch=83.3] | Loss=0.00097 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.924 | L2-Norm(final)=5.303 | 4260.5 samples/s | 66.6 steps/s
[Step=21700 Epoch=83.5] | Loss=0.00093 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.917 | L2-Norm(final)=5.304 | 4385.6 samples/s | 68.5 steps/s
[Step=21750 Epoch=83.7] | Loss=0.00089 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.909 | L2-Norm(final)=5.305 | 4398.1 samples/s | 68.7 steps/s
[Step=21800 Epoch=83.9] | Loss=0.00086 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.901 | L2-Norm(final)=5.306 | 7094.5 samples/s | 110.9 steps/s
[Step=21850 Epoch=84.1] | Loss=0.00082 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.893 | L2-Norm(final)=5.306 | 2169.9 samples/s | 33.9 steps/s
[Step=21900 Epoch=84.3] | Loss=0.00080 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.885 | L2-Norm(final)=5.307 | 4356.2 samples/s | 68.1 steps/s
[Step=21950 Epoch=84.5] | Loss=0.00077 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.876 | L2-Norm(final)=5.308 | 4449.1 samples/s | 69.5 steps/s
[Step=22000 Epoch=84.7] | Loss=0.00074 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.868 | L2-Norm(final)=5.309 | 4405.4 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06676 | acc=0.9665 | tpr=0.9774 | fpr=0.0572 | 5264.3 samples/s | 20.6 steps/s
Avg test loss: 0.07058, Avg test acc: 0.96542, Avg tpr: 0.97645, Avg fpr: 0.05884, total FA: 459

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06705 | acc=0.9654 | tpr=0.9707 | fpr=0.0461 | 5359.0 samples/s | 20.9 steps/s
Avg test loss: 0.07311, Avg test acc: 0.96454, Avg tpr: 0.96992, Avg fpr: 0.04730, total FA: 369

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.95596 | acc=0.3114 | tpr=0.0043 | fpr=0.0218 | 5465.0 samples/s | 21.3 steps/s
Avg test loss: 4.96379, Avg test acc: 0.30836, Avg tpr: 0.00379, Avg fpr: 0.02179, total FA: 170

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.03426 | acc=0.3137 | tpr=0.0064 | fpr=0.0188 | 5366.3 samples/s | 21.0 steps/s
Avg test loss: 5.04241, Avg test acc: 0.31116, Avg tpr: 0.00653, Avg fpr: 0.01884, total FA: 147

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.81031 | acc=0.0998 | tpr=0.7301 | fpr=0.9116 | 5361.2 samples/s | 20.9 steps/s
[Step= 100] | Loss=5.79193 | acc=0.1013 | tpr=0.7271 | fpr=0.9104 | 6916.2 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.80133 | acc=0.1016 | tpr=0.7363 | fpr=0.9101 | 8032.0 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.81607 | acc=0.1007 | tpr=0.7311 | fpr=0.9107 | 8125.9 samples/s | 31.7 steps/s
[Step= 250] | Loss=5.81924 | acc=0.1015 | tpr=0.7258 | fpr=0.9099 | 8111.7 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.81995 | acc=0.1018 | tpr=0.7375 | fpr=0.9098 | 7870.2 samples/s | 30.7 steps/s
[Step= 350] | Loss=5.81232 | acc=0.1021 | tpr=0.7389 | fpr=0.9094 | 8375.7 samples/s | 32.7 steps/s
[Step= 400] | Loss=5.80697 | acc=0.1028 | tpr=0.7445 | fpr=0.9089 | 8178.7 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.80712 | acc=0.1023 | tpr=0.7405 | fpr=0.9093 | 8206.8 samples/s | 32.1 steps/s
[Step= 500] | Loss=5.81034 | acc=0.1022 | tpr=0.7405 | fpr=0.9093 | 7977.8 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.80900 | acc=0.1025 | tpr=0.7346 | fpr=0.9090 | 14609.5 samples/s | 57.1 steps/s
Avg test loss: 5.81043, Avg test acc: 0.10247, Avg tpr: 0.73494, Avg fpr: 0.90903, total FA: 126217

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.91026 | acc=0.1291 | tpr=0.6416 | fpr=0.8801 | 5169.8 samples/s | 20.2 steps/s
[Step= 100] | Loss=5.88015 | acc=0.1318 | tpr=0.6311 | fpr=0.8775 | 7544.8 samples/s | 29.5 steps/s
[Step= 150] | Loss=5.87959 | acc=0.1335 | tpr=0.6297 | fpr=0.8756 | 7457.6 samples/s | 29.1 steps/s
[Step= 200] | Loss=5.89456 | acc=0.1322 | tpr=0.6175 | fpr=0.8766 | 8534.0 samples/s | 33.3 steps/s
[Step= 250] | Loss=5.89216 | acc=0.1326 | tpr=0.6183 | fpr=0.8762 | 8149.8 samples/s | 31.8 steps/s
[Step= 300] | Loss=5.89203 | acc=0.1323 | tpr=0.6233 | fpr=0.8766 | 7962.1 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.88301 | acc=0.1326 | tpr=0.6199 | fpr=0.8763 | 8124.1 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.87688 | acc=0.1330 | tpr=0.6225 | fpr=0.8759 | 8273.8 samples/s | 32.3 steps/s
[Step= 450] | Loss=5.87697 | acc=0.1324 | tpr=0.6207 | fpr=0.8765 | 7835.3 samples/s | 30.6 steps/s
[Step= 500] | Loss=5.87706 | acc=0.1323 | tpr=0.6207 | fpr=0.8765 | 8410.1 samples/s | 32.9 steps/s
[Step= 550] | Loss=5.87630 | acc=0.1323 | tpr=0.6188 | fpr=0.8765 | 14042.4 samples/s | 54.9 steps/s
Avg test loss: 5.87707, Avg test acc: 0.13225, Avg tpr: 0.61886, Avg fpr: 0.87660, total FA: 121714

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13085 | acc=0.9782 | tpr=0.9381 | fpr=0.0211 | 5509.2 samples/s | 21.5 steps/s
[Step= 100] | Loss=0.13391 | acc=0.9777 | tpr=0.9467 | fpr=0.0217 | 6745.1 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.14228 | acc=0.9770 | tpr=0.9452 | fpr=0.0225 | 7962.5 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.14521 | acc=0.9770 | tpr=0.9475 | fpr=0.0224 | 8202.8 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.14251 | acc=0.9775 | tpr=0.9476 | fpr=0.0220 | 7980.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14526 | acc=0.9774 | tpr=0.9476 | fpr=0.0221 | 8125.0 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.14608 | acc=0.9771 | tpr=0.9480 | fpr=0.0224 | 8308.5 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.14790 | acc=0.9768 | tpr=0.9453 | fpr=0.0226 | 8151.0 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.15049 | acc=0.9765 | tpr=0.9430 | fpr=0.0229 | 8057.1 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.14965 | acc=0.9766 | tpr=0.9432 | fpr=0.0228 | 7893.9 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.14850 | acc=0.9768 | tpr=0.9427 | fpr=0.0226 | 15125.8 samples/s | 59.1 steps/s
Avg test loss: 0.14812, Avg test acc: 0.97681, Avg tpr: 0.94176, Avg fpr: 0.02256, total FA: 3132

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14881 | acc=0.9766 | tpr=0.9513 | fpr=0.0230 | 5341.3 samples/s | 20.9 steps/s
[Step= 100] | Loss=0.15364 | acc=0.9765 | tpr=0.9424 | fpr=0.0229 | 7322.9 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.15762 | acc=0.9757 | tpr=0.9467 | fpr=0.0237 | 7525.6 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.16051 | acc=0.9754 | tpr=0.9519 | fpr=0.0242 | 8008.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.15767 | acc=0.9759 | tpr=0.9528 | fpr=0.0237 | 8479.0 samples/s | 33.1 steps/s
[Step= 300] | Loss=0.16149 | acc=0.9754 | tpr=0.9491 | fpr=0.0241 | 8242.7 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.16348 | acc=0.9750 | tpr=0.9480 | fpr=0.0245 | 7979.7 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.16520 | acc=0.9748 | tpr=0.9447 | fpr=0.0246 | 7988.0 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.16834 | acc=0.9745 | tpr=0.9440 | fpr=0.0250 | 8120.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.16750 | acc=0.9745 | tpr=0.9445 | fpr=0.0250 | 8110.0 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.16642 | acc=0.9747 | tpr=0.9431 | fpr=0.0248 | 14688.4 samples/s | 57.4 steps/s
Avg test loss: 0.16606, Avg test acc: 0.97468, Avg tpr: 0.94255, Avg fpr: 0.02473, total FA: 3434

server round 11/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=42.9] | Loss=0.00450 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.761 | L2-Norm(final)=5.373 | 6350.4 samples/s | 99.2 steps/s
[Step=22050 Epoch=43.0] | Loss=0.01435 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.759 | L2-Norm(final)=5.394 | 4617.3 samples/s | 72.1 steps/s
[Step=22100 Epoch=43.1] | Loss=0.01473 | Reg=0.00390 | acc=0.9844 | L2-Norm=19.759 | L2-Norm(final)=5.409 | 5161.4 samples/s | 80.6 steps/s
[Step=22150 Epoch=43.2] | Loss=0.01611 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.759 | L2-Norm(final)=5.421 | 5274.9 samples/s | 82.4 steps/s
[Step=22200 Epoch=43.3] | Loss=0.01669 | Reg=0.00390 | acc=1.0000 | L2-Norm=19.760 | L2-Norm(final)=5.431 | 5113.7 samples/s | 79.9 steps/s
[Step=22250 Epoch=43.4] | Loss=0.01765 | Reg=0.00391 | acc=0.9688 | L2-Norm=19.762 | L2-Norm(final)=5.439 | 5191.0 samples/s | 81.1 steps/s
[Step=22300 Epoch=43.5] | Loss=0.01751 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.765 | L2-Norm(final)=5.449 | 5195.3 samples/s | 81.2 steps/s
[Step=22350 Epoch=43.6] | Loss=0.01756 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.767 | L2-Norm(final)=5.458 | 5213.2 samples/s | 81.5 steps/s
[Step=22400 Epoch=43.7] | Loss=0.01756 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.769 | L2-Norm(final)=5.467 | 5210.6 samples/s | 81.4 steps/s
[Step=22450 Epoch=43.8] | Loss=0.01747 | Reg=0.00391 | acc=0.9844 | L2-Norm=19.771 | L2-Norm(final)=5.476 | 5175.6 samples/s | 80.9 steps/s
[Step=22500 Epoch=43.9] | Loss=0.01768 | Reg=0.00391 | acc=1.0000 | L2-Norm=19.774 | L2-Norm(final)=5.486 | 7012.5 samples/s | 109.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=43.9] | Loss=0.01034 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.795 | L2-Norm(final)=5.574 | 5959.8 samples/s | 93.1 steps/s
[Step=22550 Epoch=44.0] | Loss=0.01591 | Reg=0.00392 | acc=0.9844 | L2-Norm=19.803 | L2-Norm(final)=5.577 | 4414.0 samples/s | 69.0 steps/s
[Step=22600 Epoch=44.1] | Loss=0.01811 | Reg=0.00392 | acc=1.0000 | L2-Norm=19.812 | L2-Norm(final)=5.578 | 4646.9 samples/s | 72.6 steps/s
[Step=22650 Epoch=44.2] | Loss=0.01845 | Reg=0.00393 | acc=0.9844 | L2-Norm=19.821 | L2-Norm(final)=5.578 | 4609.2 samples/s | 72.0 steps/s
[Step=22700 Epoch=44.3] | Loss=0.01859 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.829 | L2-Norm(final)=5.579 | 4580.0 samples/s | 71.6 steps/s
[Step=22750 Epoch=44.4] | Loss=0.01932 | Reg=0.00393 | acc=1.0000 | L2-Norm=19.835 | L2-Norm(final)=5.578 | 4615.3 samples/s | 72.1 steps/s
[Step=22800 Epoch=44.5] | Loss=0.01937 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.841 | L2-Norm(final)=5.577 | 4602.3 samples/s | 71.9 steps/s
[Step=22850 Epoch=44.6] | Loss=0.01932 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.846 | L2-Norm(final)=5.576 | 4621.8 samples/s | 72.2 steps/s
[Step=22900 Epoch=44.7] | Loss=0.01950 | Reg=0.00394 | acc=0.9844 | L2-Norm=19.852 | L2-Norm(final)=5.576 | 4659.7 samples/s | 72.8 steps/s
[Step=22950 Epoch=44.8] | Loss=0.01907 | Reg=0.00394 | acc=1.0000 | L2-Norm=19.858 | L2-Norm(final)=5.576 | 4618.4 samples/s | 72.2 steps/s
[Step=23000 Epoch=44.9] | Loss=0.01889 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.862 | L2-Norm(final)=5.576 | 5952.9 samples/s | 93.0 steps/s
[Step=23050 Epoch=45.0] | Loss=0.01850 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.866 | L2-Norm(final)=5.577 | 2455.5 samples/s | 38.4 steps/s
[Step=23100 Epoch=45.1] | Loss=0.01798 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.869 | L2-Norm(final)=5.578 | 4598.8 samples/s | 71.9 steps/s
[Step=23150 Epoch=45.2] | Loss=0.01762 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.872 | L2-Norm(final)=5.579 | 4643.6 samples/s | 72.6 steps/s
[Step=23200 Epoch=45.2] | Loss=0.01723 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.873 | L2-Norm(final)=5.580 | 4554.8 samples/s | 71.2 steps/s
[Step=23250 Epoch=45.3] | Loss=0.01705 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.875 | L2-Norm(final)=5.582 | 4615.7 samples/s | 72.1 steps/s
[Step=23300 Epoch=45.4] | Loss=0.01674 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.876 | L2-Norm(final)=5.583 | 4632.0 samples/s | 72.4 steps/s
[Step=23350 Epoch=45.5] | Loss=0.01664 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.877 | L2-Norm(final)=5.584 | 4635.1 samples/s | 72.4 steps/s
[Step=23400 Epoch=45.6] | Loss=0.01660 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.879 | L2-Norm(final)=5.585 | 4737.5 samples/s | 74.0 steps/s
[Step=23450 Epoch=45.7] | Loss=0.01635 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.880 | L2-Norm(final)=5.586 | 4552.8 samples/s | 71.1 steps/s
[Step=23500 Epoch=45.8] | Loss=0.01610 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.880 | L2-Norm(final)=5.588 | 4961.1 samples/s | 77.5 steps/s
[Step=23550 Epoch=45.9] | Loss=0.01595 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.881 | L2-Norm(final)=5.589 | 2655.3 samples/s | 41.5 steps/s
[Step=23600 Epoch=46.0] | Loss=0.01572 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.882 | L2-Norm(final)=5.590 | 4647.6 samples/s | 72.6 steps/s
[Step=23650 Epoch=46.1] | Loss=0.01546 | Reg=0.00395 | acc=0.9688 | L2-Norm=19.882 | L2-Norm(final)=5.592 | 4597.1 samples/s | 71.8 steps/s
[Step=23700 Epoch=46.2] | Loss=0.01530 | Reg=0.00395 | acc=0.9531 | L2-Norm=19.882 | L2-Norm(final)=5.593 | 4656.3 samples/s | 72.8 steps/s
[Step=23750 Epoch=46.3] | Loss=0.01504 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.882 | L2-Norm(final)=5.595 | 4663.8 samples/s | 72.9 steps/s
[Step=23800 Epoch=46.4] | Loss=0.01484 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.881 | L2-Norm(final)=5.596 | 4538.9 samples/s | 70.9 steps/s
[Step=23850 Epoch=46.5] | Loss=0.01468 | Reg=0.00395 | acc=0.9844 | L2-Norm=19.881 | L2-Norm(final)=5.598 | 4627.3 samples/s | 72.3 steps/s
[Step=23900 Epoch=46.6] | Loss=0.01448 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.880 | L2-Norm(final)=5.600 | 4672.2 samples/s | 73.0 steps/s
[Step=23950 Epoch=46.7] | Loss=0.01438 | Reg=0.00395 | acc=1.0000 | L2-Norm=19.879 | L2-Norm(final)=5.601 | 4654.6 samples/s | 72.7 steps/s
[Step=24000 Epoch=46.8] | Loss=0.01435 | Reg=0.00395 | acc=0.9531 | L2-Norm=19.878 | L2-Norm(final)=5.603 | 4608.6 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step24000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=43.0] | Loss=0.01099 | Reg=0.00419 | acc=1.0000 | L2-Norm=20.477 | L2-Norm(final)=5.538 | 6384.8 samples/s | 99.8 steps/s
[Step=22050 Epoch=43.1] | Loss=0.02267 | Reg=0.00419 | acc=0.9688 | L2-Norm=20.480 | L2-Norm(final)=5.551 | 4704.6 samples/s | 73.5 steps/s
[Step=22100 Epoch=43.2] | Loss=0.02166 | Reg=0.00420 | acc=0.9688 | L2-Norm=20.484 | L2-Norm(final)=5.566 | 5108.6 samples/s | 79.8 steps/s
[Step=22150 Epoch=43.3] | Loss=0.02214 | Reg=0.00420 | acc=0.9531 | L2-Norm=20.487 | L2-Norm(final)=5.578 | 5146.9 samples/s | 80.4 steps/s
[Step=22200 Epoch=43.4] | Loss=0.02089 | Reg=0.00420 | acc=0.9688 | L2-Norm=20.490 | L2-Norm(final)=5.587 | 5174.9 samples/s | 80.9 steps/s
[Step=22250 Epoch=43.5] | Loss=0.01980 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.493 | L2-Norm(final)=5.599 | 5174.8 samples/s | 80.9 steps/s
[Step=22300 Epoch=43.6] | Loss=0.01916 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.496 | L2-Norm(final)=5.612 | 5338.2 samples/s | 83.4 steps/s
[Step=22350 Epoch=43.7] | Loss=0.01914 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.500 | L2-Norm(final)=5.623 | 5097.1 samples/s | 79.6 steps/s
[Step=22400 Epoch=43.8] | Loss=0.01881 | Reg=0.00420 | acc=0.9844 | L2-Norm=20.502 | L2-Norm(final)=5.635 | 5303.2 samples/s | 82.9 steps/s
[Step=22450 Epoch=43.9] | Loss=0.01850 | Reg=0.00420 | acc=1.0000 | L2-Norm=20.505 | L2-Norm(final)=5.646 | 5158.7 samples/s | 80.6 steps/s
[Step=22500 Epoch=44.0] | Loss=0.01879 | Reg=0.00421 | acc=1.0000 | L2-Norm=20.507 | L2-Norm(final)=5.658 | 7171.9 samples/s | 112.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=44.0] | Loss=0.03757 | Reg=0.00421 | acc=0.9688 | L2-Norm=20.530 | L2-Norm(final)=5.763 | 6212.3 samples/s | 97.1 steps/s
[Step=22550 Epoch=44.1] | Loss=0.01812 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.540 | L2-Norm(final)=5.769 | 4185.3 samples/s | 65.4 steps/s
[Step=22600 Epoch=44.2] | Loss=0.01686 | Reg=0.00422 | acc=0.9844 | L2-Norm=20.545 | L2-Norm(final)=5.775 | 4654.3 samples/s | 72.7 steps/s
[Step=22650 Epoch=44.3] | Loss=0.01729 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.548 | L2-Norm(final)=5.777 | 4574.3 samples/s | 71.5 steps/s
[Step=22700 Epoch=44.4] | Loss=0.01869 | Reg=0.00422 | acc=1.0000 | L2-Norm=20.554 | L2-Norm(final)=5.776 | 4754.7 samples/s | 74.3 steps/s
[Step=22750 Epoch=44.5] | Loss=0.01917 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.560 | L2-Norm(final)=5.774 | 4488.3 samples/s | 70.1 steps/s
[Step=22800 Epoch=44.6] | Loss=0.01948 | Reg=0.00423 | acc=0.9688 | L2-Norm=20.565 | L2-Norm(final)=5.772 | 4597.1 samples/s | 71.8 steps/s
[Step=22850 Epoch=44.7] | Loss=0.01913 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.570 | L2-Norm(final)=5.770 | 4661.4 samples/s | 72.8 steps/s
[Step=22900 Epoch=44.8] | Loss=0.01927 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.574 | L2-Norm(final)=5.770 | 4589.4 samples/s | 71.7 steps/s
[Step=22950 Epoch=44.9] | Loss=0.01938 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.577 | L2-Norm(final)=5.768 | 4616.8 samples/s | 72.1 steps/s
[Step=23000 Epoch=45.0] | Loss=0.01904 | Reg=0.00424 | acc=0.9531 | L2-Norm=20.581 | L2-Norm(final)=5.767 | 6069.1 samples/s | 94.8 steps/s
[Step=23050 Epoch=45.1] | Loss=0.01867 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.583 | L2-Norm(final)=5.766 | 2433.4 samples/s | 38.0 steps/s
[Step=23100 Epoch=45.2] | Loss=0.01817 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.586 | L2-Norm(final)=5.765 | 4601.8 samples/s | 71.9 steps/s
[Step=23150 Epoch=45.3] | Loss=0.01775 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.588 | L2-Norm(final)=5.765 | 4595.5 samples/s | 71.8 steps/s
[Step=23200 Epoch=45.4] | Loss=0.01747 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.589 | L2-Norm(final)=5.765 | 4607.2 samples/s | 72.0 steps/s
[Step=23250 Epoch=45.5] | Loss=0.01742 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.589 | L2-Norm(final)=5.765 | 4683.9 samples/s | 73.2 steps/s
[Step=23300 Epoch=45.6] | Loss=0.01707 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.590 | L2-Norm(final)=5.766 | 4560.9 samples/s | 71.3 steps/s
[Step=23350 Epoch=45.6] | Loss=0.01685 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.590 | L2-Norm(final)=5.766 | 4678.3 samples/s | 73.1 steps/s
[Step=23400 Epoch=45.7] | Loss=0.01661 | Reg=0.00424 | acc=0.9688 | L2-Norm=20.590 | L2-Norm(final)=5.767 | 4663.9 samples/s | 72.9 steps/s
[Step=23450 Epoch=45.8] | Loss=0.01639 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.590 | L2-Norm(final)=5.767 | 4575.6 samples/s | 71.5 steps/s
[Step=23500 Epoch=45.9] | Loss=0.01620 | Reg=0.00424 | acc=0.9688 | L2-Norm=20.590 | L2-Norm(final)=5.768 | 5139.0 samples/s | 80.3 steps/s
[Step=23550 Epoch=46.0] | Loss=0.01596 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.589 | L2-Norm(final)=5.769 | 2628.5 samples/s | 41.1 steps/s
[Step=23600 Epoch=46.1] | Loss=0.01568 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.588 | L2-Norm(final)=5.770 | 4583.9 samples/s | 71.6 steps/s
[Step=23650 Epoch=46.2] | Loss=0.01546 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.587 | L2-Norm(final)=5.771 | 4666.2 samples/s | 72.9 steps/s
[Step=23700 Epoch=46.3] | Loss=0.01525 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.586 | L2-Norm(final)=5.772 | 4598.3 samples/s | 71.8 steps/s
[Step=23750 Epoch=46.4] | Loss=0.01500 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.584 | L2-Norm(final)=5.774 | 4621.8 samples/s | 72.2 steps/s
[Step=23800 Epoch=46.5] | Loss=0.01486 | Reg=0.00424 | acc=1.0000 | L2-Norm=20.582 | L2-Norm(final)=5.775 | 4678.7 samples/s | 73.1 steps/s
[Step=23850 Epoch=46.6] | Loss=0.01479 | Reg=0.00424 | acc=0.9844 | L2-Norm=20.580 | L2-Norm(final)=5.776 | 4557.8 samples/s | 71.2 steps/s
[Step=23900 Epoch=46.7] | Loss=0.01470 | Reg=0.00423 | acc=0.9844 | L2-Norm=20.579 | L2-Norm(final)=5.776 | 4655.1 samples/s | 72.7 steps/s
[Step=23950 Epoch=46.8] | Loss=0.01459 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.577 | L2-Norm(final)=5.777 | 4692.0 samples/s | 73.3 steps/s
[Step=24000 Epoch=46.9] | Loss=0.01451 | Reg=0.00423 | acc=1.0000 | L2-Norm=20.575 | L2-Norm(final)=5.778 | 4597.3 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step24000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=84.3] | Loss=0.00025 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.513 | L2-Norm(final)=5.333 | 6177.1 samples/s | 96.5 steps/s
[Step=22050 Epoch=84.5] | Loss=0.00024 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.518 | L2-Norm(final)=5.338 | 4524.5 samples/s | 70.7 steps/s
[Step=22100 Epoch=84.7] | Loss=0.00025 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.520 | L2-Norm(final)=5.341 | 4928.0 samples/s | 77.0 steps/s
[Step=22150 Epoch=84.9] | Loss=0.00021 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.521 | L2-Norm(final)=5.345 | 4696.7 samples/s | 73.4 steps/s
[Step=22200 Epoch=85.1] | Loss=0.00020 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.521 | L2-Norm(final)=5.348 | 4910.0 samples/s | 76.7 steps/s
[Step=22250 Epoch=85.3] | Loss=0.00017 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.522 | L2-Norm(final)=5.351 | 6794.0 samples/s | 106.2 steps/s
[Step=22300 Epoch=85.4] | Loss=0.00015 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.521 | L2-Norm(final)=5.354 | 2461.0 samples/s | 38.5 steps/s
[Step=22350 Epoch=85.6] | Loss=0.00014 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.519 | L2-Norm(final)=5.357 | 4950.9 samples/s | 77.4 steps/s
[Step=22400 Epoch=85.8] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.517 | L2-Norm(final)=5.359 | 4856.3 samples/s | 75.9 steps/s
[Step=22450 Epoch=86.0] | Loss=0.00012 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.514 | L2-Norm(final)=5.362 | 4910.2 samples/s | 76.7 steps/s
[Step=22500 Epoch=86.2] | Loss=0.00011 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.511 | L2-Norm(final)=5.365 | 5681.7 samples/s | 88.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=86.2] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.481 | L2-Norm(final)=5.392 | 6767.6 samples/s | 105.7 steps/s
[Step=22550 Epoch=86.4] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.472 | L2-Norm(final)=5.393 | 3732.0 samples/s | 58.3 steps/s
[Step=22600 Epoch=86.6] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.460 | L2-Norm(final)=5.395 | 4518.1 samples/s | 70.6 steps/s
[Step=22650 Epoch=86.8] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.448 | L2-Norm(final)=5.397 | 4323.2 samples/s | 67.6 steps/s
[Step=22700 Epoch=87.0] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.436 | L2-Norm(final)=5.398 | 4404.5 samples/s | 68.8 steps/s
[Step=22750 Epoch=87.2] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.425 | L2-Norm(final)=5.400 | 5833.9 samples/s | 91.2 steps/s
[Step=22800 Epoch=87.4] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.413 | L2-Norm(final)=5.402 | 2350.0 samples/s | 36.7 steps/s
[Step=22850 Epoch=87.6] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.401 | L2-Norm(final)=5.403 | 4269.5 samples/s | 66.7 steps/s
[Step=22900 Epoch=87.7] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.389 | L2-Norm(final)=5.404 | 4415.2 samples/s | 69.0 steps/s
[Step=22950 Epoch=87.9] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.377 | L2-Norm(final)=5.405 | 4384.5 samples/s | 68.5 steps/s
[Step=23000 Epoch=88.1] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.365 | L2-Norm(final)=5.406 | 4973.6 samples/s | 77.7 steps/s
[Step=23050 Epoch=88.3] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.353 | L2-Norm(final)=5.407 | 2516.3 samples/s | 39.3 steps/s
[Step=23100 Epoch=88.5] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.340 | L2-Norm(final)=5.408 | 4448.3 samples/s | 69.5 steps/s
[Step=23150 Epoch=88.7] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.327 | L2-Norm(final)=5.409 | 4287.9 samples/s | 67.0 steps/s
[Step=23200 Epoch=88.9] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.315 | L2-Norm(final)=5.410 | 4402.6 samples/s | 68.8 steps/s
[Step=23250 Epoch=89.1] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.302 | L2-Norm(final)=5.411 | 4393.5 samples/s | 68.6 steps/s
[Step=23300 Epoch=89.3] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.289 | L2-Norm(final)=5.411 | 2701.1 samples/s | 42.2 steps/s
[Step=23350 Epoch=89.5] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.276 | L2-Norm(final)=5.412 | 4418.7 samples/s | 69.0 steps/s
[Step=23400 Epoch=89.7] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.263 | L2-Norm(final)=5.413 | 4329.8 samples/s | 67.7 steps/s
[Step=23450 Epoch=89.9] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.249 | L2-Norm(final)=5.414 | 4429.4 samples/s | 69.2 steps/s
[Step=23500 Epoch=90.0] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.236 | L2-Norm(final)=5.414 | 4336.7 samples/s | 67.8 steps/s
[Step=23550 Epoch=90.2] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.223 | L2-Norm(final)=5.415 | 2720.0 samples/s | 42.5 steps/s
[Step=23600 Epoch=90.4] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.209 | L2-Norm(final)=5.416 | 4263.0 samples/s | 66.6 steps/s
[Step=23650 Epoch=90.6] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.195 | L2-Norm(final)=5.417 | 4447.6 samples/s | 69.5 steps/s
[Step=23700 Epoch=90.8] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.182 | L2-Norm(final)=5.417 | 4392.1 samples/s | 68.6 steps/s
[Step=23750 Epoch=91.0] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.168 | L2-Norm(final)=5.418 | 4422.9 samples/s | 69.1 steps/s
[Step=23800 Epoch=91.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.154 | L2-Norm(final)=5.419 | 6327.4 samples/s | 98.9 steps/s
[Step=23850 Epoch=91.4] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.140 | L2-Norm(final)=5.420 | 2220.4 samples/s | 34.7 steps/s
[Step=23900 Epoch=91.6] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.126 | L2-Norm(final)=5.420 | 4391.2 samples/s | 68.6 steps/s
[Step=23950 Epoch=91.8] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.111 | L2-Norm(final)=5.421 | 4409.9 samples/s | 68.9 steps/s
[Step=24000 Epoch=92.0] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.097 | L2-Norm(final)=5.422 | 4453.3 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step24000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=84.7] | Loss=0.00386 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.566 | L2-Norm(final)=5.334 | 6349.3 samples/s | 99.2 steps/s
[Step=22050 Epoch=84.9] | Loss=0.00038 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.574 | L2-Norm(final)=5.338 | 4253.5 samples/s | 66.5 steps/s
[Step=22100 Epoch=85.1] | Loss=0.00030 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.578 | L2-Norm(final)=5.342 | 4914.5 samples/s | 76.8 steps/s
[Step=22150 Epoch=85.3] | Loss=0.00025 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=5.347 | 4969.8 samples/s | 77.7 steps/s
[Step=22200 Epoch=85.5] | Loss=0.00020 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=5.351 | 4914.2 samples/s | 76.8 steps/s
[Step=22250 Epoch=85.6] | Loss=0.00020 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.579 | L2-Norm(final)=5.355 | 6981.2 samples/s | 109.1 steps/s
[Step=22300 Epoch=85.8] | Loss=0.00017 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.578 | L2-Norm(final)=5.360 | 2454.3 samples/s | 38.3 steps/s
[Step=22350 Epoch=86.0] | Loss=0.00016 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.577 | L2-Norm(final)=5.364 | 5001.6 samples/s | 78.1 steps/s
[Step=22400 Epoch=86.2] | Loss=0.00014 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.574 | L2-Norm(final)=5.368 | 4981.9 samples/s | 77.8 steps/s
[Step=22450 Epoch=86.4] | Loss=0.00014 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.572 | L2-Norm(final)=5.372 | 4738.7 samples/s | 74.0 steps/s
[Step=22500 Epoch=86.6] | Loss=0.00013 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.569 | L2-Norm(final)=5.376 | 5829.1 samples/s | 91.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=86.6] | Loss=0.00002 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.540 | L2-Norm(final)=5.415 | 5883.3 samples/s | 91.9 steps/s
[Step=22550 Epoch=86.8] | Loss=0.00005 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.530 | L2-Norm(final)=5.418 | 4076.8 samples/s | 63.7 steps/s
[Step=22600 Epoch=87.0] | Loss=0.00004 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.518 | L2-Norm(final)=5.422 | 4435.4 samples/s | 69.3 steps/s
[Step=22650 Epoch=87.2] | Loss=0.00003 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.505 | L2-Norm(final)=5.424 | 4380.9 samples/s | 68.5 steps/s
[Step=22700 Epoch=87.4] | Loss=0.00003 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.492 | L2-Norm(final)=5.426 | 4360.2 samples/s | 68.1 steps/s
[Step=22750 Epoch=87.6] | Loss=0.00002 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.479 | L2-Norm(final)=5.428 | 6028.5 samples/s | 94.2 steps/s
[Step=22800 Epoch=87.8] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.465 | L2-Norm(final)=5.429 | 2303.9 samples/s | 36.0 steps/s
[Step=22850 Epoch=88.0] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.452 | L2-Norm(final)=5.431 | 4388.4 samples/s | 68.6 steps/s
[Step=22900 Epoch=88.2] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.438 | L2-Norm(final)=5.432 | 4415.0 samples/s | 69.0 steps/s
[Step=22950 Epoch=88.3] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.424 | L2-Norm(final)=5.433 | 4325.8 samples/s | 67.6 steps/s
[Step=23000 Epoch=88.5] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.410 | L2-Norm(final)=5.434 | 5096.3 samples/s | 79.6 steps/s
[Step=23050 Epoch=88.7] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.397 | L2-Norm(final)=5.435 | 2450.6 samples/s | 38.3 steps/s
[Step=23100 Epoch=88.9] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.383 | L2-Norm(final)=5.436 | 4414.0 samples/s | 69.0 steps/s
[Step=23150 Epoch=89.1] | Loss=0.00001 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.369 | L2-Norm(final)=5.437 | 4356.0 samples/s | 68.1 steps/s
[Step=23200 Epoch=89.3] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.355 | L2-Norm(final)=5.438 | 4371.0 samples/s | 68.3 steps/s
[Step=23250 Epoch=89.5] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.341 | L2-Norm(final)=5.439 | 4506.3 samples/s | 70.4 steps/s
[Step=23300 Epoch=89.7] | Loss=0.00001 | Reg=0.00178 | acc=1.0000 | L2-Norm=13.326 | L2-Norm(final)=5.440 | 2675.9 samples/s | 41.8 steps/s
[Step=23350 Epoch=89.9] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.312 | L2-Norm(final)=5.441 | 4315.3 samples/s | 67.4 steps/s
[Step=23400 Epoch=90.1] | Loss=0.00001 | Reg=0.00177 | acc=1.0000 | L2-Norm=13.298 | L2-Norm(final)=5.442 | 4417.8 samples/s | 69.0 steps/s
[Step=23450 Epoch=90.3] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.283 | L2-Norm(final)=5.443 | 4336.5 samples/s | 67.8 steps/s
[Step=23500 Epoch=90.5] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.269 | L2-Norm(final)=5.443 | 4432.6 samples/s | 69.3 steps/s
[Step=23550 Epoch=90.7] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.254 | L2-Norm(final)=5.444 | 2709.6 samples/s | 42.3 steps/s
[Step=23600 Epoch=90.8] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.239 | L2-Norm(final)=5.445 | 4299.7 samples/s | 67.2 steps/s
[Step=23650 Epoch=91.0] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.225 | L2-Norm(final)=5.446 | 4488.2 samples/s | 70.1 steps/s
[Step=23700 Epoch=91.2] | Loss=0.00001 | Reg=0.00175 | acc=1.0000 | L2-Norm=13.210 | L2-Norm(final)=5.447 | 4327.2 samples/s | 67.6 steps/s
[Step=23750 Epoch=91.4] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.195 | L2-Norm(final)=5.448 | 4380.7 samples/s | 68.4 steps/s
[Step=23800 Epoch=91.6] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.180 | L2-Norm(final)=5.448 | 7125.5 samples/s | 111.3 steps/s
[Step=23850 Epoch=91.8] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.165 | L2-Norm(final)=5.449 | 2203.2 samples/s | 34.4 steps/s
[Step=23900 Epoch=92.0] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.149 | L2-Norm(final)=5.450 | 4307.0 samples/s | 67.3 steps/s
[Step=23950 Epoch=92.2] | Loss=0.00001 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.134 | L2-Norm(final)=5.451 | 4359.0 samples/s | 68.1 steps/s
[Step=24000 Epoch=92.4] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.118 | L2-Norm(final)=5.452 | 4377.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07315 | acc=0.9636 | tpr=0.9658 | fpr=0.0411 | 5133.0 samples/s | 20.1 steps/s
Avg test loss: 0.07744, Avg test acc: 0.96274, Avg tpr: 0.96555, Avg fpr: 0.04346, total FA: 339

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07837 | acc=0.9659 | tpr=0.9733 | fpr=0.0503 | 5489.1 samples/s | 21.4 steps/s
Avg test loss: 0.08121, Avg test acc: 0.96534, Avg tpr: 0.97214, Avg fpr: 0.04961, total FA: 387

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.49336 | acc=0.3098 | tpr=0.0088 | fpr=0.0367 | 5290.0 samples/s | 20.7 steps/s
Avg test loss: 5.50268, Avg test acc: 0.30760, Avg tpr: 0.00845, Avg fpr: 0.03448, total FA: 269

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.39000 | acc=0.3086 | tpr=0.0108 | fpr=0.0448 | 5308.5 samples/s | 20.7 steps/s
Avg test loss: 5.40293, Avg test acc: 0.30599, Avg tpr: 0.00991, Avg fpr: 0.04282, total FA: 334

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.37024 | acc=0.1362 | tpr=0.5929 | fpr=0.8720 | 5325.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=5.34662 | acc=0.1352 | tpr=0.5864 | fpr=0.8733 | 7547.9 samples/s | 29.5 steps/s
[Step= 150] | Loss=5.35522 | acc=0.1367 | tpr=0.6066 | fpr=0.8720 | 7665.2 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.36751 | acc=0.1364 | tpr=0.5945 | fpr=0.8719 | 7963.7 samples/s | 31.1 steps/s
[Step= 250] | Loss=5.37513 | acc=0.1369 | tpr=0.5895 | fpr=0.8714 | 8159.8 samples/s | 31.9 steps/s
[Step= 300] | Loss=5.36985 | acc=0.1373 | tpr=0.6000 | fpr=0.8712 | 8238.6 samples/s | 32.2 steps/s
[Step= 350] | Loss=5.35728 | acc=0.1379 | tpr=0.5980 | fpr=0.8704 | 8117.4 samples/s | 31.7 steps/s
[Step= 400] | Loss=5.35511 | acc=0.1388 | tpr=0.6012 | fpr=0.8696 | 7879.4 samples/s | 30.8 steps/s
[Step= 450] | Loss=5.35951 | acc=0.1388 | tpr=0.5998 | fpr=0.8696 | 8143.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.36305 | acc=0.1389 | tpr=0.5991 | fpr=0.8694 | 8342.9 samples/s | 32.6 steps/s
[Step= 550] | Loss=5.36557 | acc=0.1389 | tpr=0.5957 | fpr=0.8694 | 14259.1 samples/s | 55.7 steps/s
Avg test loss: 5.36692, Avg test acc: 0.13884, Avg tpr: 0.59628, Avg fpr: 0.86948, total FA: 120725

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.12975 | acc=0.1001 | tpr=0.6726 | fpr=0.9102 | 5228.9 samples/s | 20.4 steps/s
[Step= 100] | Loss=7.09140 | acc=0.1014 | tpr=0.6567 | fpr=0.9090 | 7553.5 samples/s | 29.5 steps/s
[Step= 150] | Loss=7.08842 | acc=0.1022 | tpr=0.6585 | fpr=0.9080 | 7424.2 samples/s | 29.0 steps/s
[Step= 200] | Loss=7.09733 | acc=0.1021 | tpr=0.6579 | fpr=0.9080 | 8159.0 samples/s | 31.9 steps/s
[Step= 250] | Loss=7.09699 | acc=0.1028 | tpr=0.6524 | fpr=0.9072 | 8180.5 samples/s | 32.0 steps/s
[Step= 300] | Loss=7.09390 | acc=0.1028 | tpr=0.6589 | fpr=0.9073 | 8283.9 samples/s | 32.4 steps/s
[Step= 350] | Loss=7.08200 | acc=0.1029 | tpr=0.6569 | fpr=0.9072 | 8377.7 samples/s | 32.7 steps/s
[Step= 400] | Loss=7.07503 | acc=0.1036 | tpr=0.6630 | fpr=0.9066 | 8333.2 samples/s | 32.6 steps/s
[Step= 450] | Loss=7.07644 | acc=0.1031 | tpr=0.6646 | fpr=0.9070 | 7822.4 samples/s | 30.6 steps/s
[Step= 500] | Loss=7.07710 | acc=0.1029 | tpr=0.6634 | fpr=0.9072 | 8337.8 samples/s | 32.6 steps/s
[Step= 550] | Loss=7.07658 | acc=0.1031 | tpr=0.6586 | fpr=0.9070 | 13964.3 samples/s | 54.5 steps/s
Avg test loss: 7.07722, Avg test acc: 0.10308, Avg tpr: 0.65848, Avg fpr: 0.90701, total FA: 125937

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14683 | acc=0.9789 | tpr=0.9513 | fpr=0.0206 | 5423.5 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.15205 | acc=0.9785 | tpr=0.9488 | fpr=0.0209 | 7383.6 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.15892 | acc=0.9773 | tpr=0.9481 | fpr=0.0221 | 7076.6 samples/s | 27.6 steps/s
[Step= 200] | Loss=0.16175 | acc=0.9774 | tpr=0.9530 | fpr=0.0222 | 8245.7 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.15985 | acc=0.9776 | tpr=0.9520 | fpr=0.0219 | 8018.7 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.16309 | acc=0.9773 | tpr=0.9491 | fpr=0.0222 | 8130.0 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.16469 | acc=0.9769 | tpr=0.9493 | fpr=0.0226 | 7869.2 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.16693 | acc=0.9767 | tpr=0.9480 | fpr=0.0228 | 8250.7 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.17049 | acc=0.9763 | tpr=0.9474 | fpr=0.0232 | 8266.3 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.16960 | acc=0.9764 | tpr=0.9480 | fpr=0.0231 | 8179.6 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.16863 | acc=0.9765 | tpr=0.9487 | fpr=0.0230 | 14470.5 samples/s | 56.5 steps/s
Avg test loss: 0.16816, Avg test acc: 0.97651, Avg tpr: 0.94731, Avg fpr: 0.02296, total FA: 3188

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.16665 | acc=0.9768 | tpr=0.9513 | fpr=0.0227 | 5267.3 samples/s | 20.6 steps/s
[Step= 100] | Loss=0.17131 | acc=0.9762 | tpr=0.9510 | fpr=0.0234 | 7198.1 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.17745 | acc=0.9752 | tpr=0.9597 | fpr=0.0245 | 7895.6 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.18062 | acc=0.9752 | tpr=0.9639 | fpr=0.0246 | 8141.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.17763 | acc=0.9757 | tpr=0.9633 | fpr=0.0241 | 7973.8 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.18133 | acc=0.9753 | tpr=0.9607 | fpr=0.0245 | 8427.2 samples/s | 32.9 steps/s
[Step= 350] | Loss=0.18298 | acc=0.9750 | tpr=0.9612 | fpr=0.0248 | 8383.8 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.18475 | acc=0.9748 | tpr=0.9579 | fpr=0.0249 | 8073.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.18828 | acc=0.9745 | tpr=0.9576 | fpr=0.0252 | 8167.6 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.18731 | acc=0.9745 | tpr=0.9586 | fpr=0.0252 | 8256.6 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.18631 | acc=0.9746 | tpr=0.9578 | fpr=0.0251 | 14164.5 samples/s | 55.3 steps/s
Avg test loss: 0.18584, Avg test acc: 0.97462, Avg tpr: 0.95761, Avg fpr: 0.02507, total FA: 3481

server round 12/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=46.8] | Loss=0.00223 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.496 | L2-Norm(final)=5.644 | 6220.4 samples/s | 97.2 steps/s
[Step=24050 Epoch=46.9] | Loss=0.01017 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.495 | L2-Norm(final)=5.651 | 4745.2 samples/s | 74.1 steps/s
[Step=24100 Epoch=47.0] | Loss=0.00992 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.493 | L2-Norm(final)=5.661 | 5226.6 samples/s | 81.7 steps/s
[Step=24150 Epoch=47.1] | Loss=0.00943 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.491 | L2-Norm(final)=5.672 | 5161.6 samples/s | 80.7 steps/s
[Step=24200 Epoch=47.2] | Loss=0.00977 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.489 | L2-Norm(final)=5.681 | 5196.1 samples/s | 81.2 steps/s
[Step=24250 Epoch=47.3] | Loss=0.00992 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.488 | L2-Norm(final)=5.690 | 5190.0 samples/s | 81.1 steps/s
[Step=24300 Epoch=47.4] | Loss=0.01004 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.487 | L2-Norm(final)=5.698 | 5218.0 samples/s | 81.5 steps/s
[Step=24350 Epoch=47.5] | Loss=0.01003 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.485 | L2-Norm(final)=5.704 | 5220.9 samples/s | 81.6 steps/s
[Step=24400 Epoch=47.6] | Loss=0.01000 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.484 | L2-Norm(final)=5.711 | 5192.0 samples/s | 81.1 steps/s
[Step=24450 Epoch=47.7] | Loss=0.01009 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.483 | L2-Norm(final)=5.716 | 5303.1 samples/s | 82.9 steps/s
[Step=24500 Epoch=47.8] | Loss=0.01007 | Reg=0.00380 | acc=0.9531 | L2-Norm=19.482 | L2-Norm(final)=5.722 | 6809.0 samples/s | 106.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=47.8] | Loss=0.02162 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.473 | L2-Norm(final)=5.782 | 6158.4 samples/s | 96.2 steps/s
[Step=24550 Epoch=47.9] | Loss=0.00880 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.474 | L2-Norm(final)=5.790 | 4277.1 samples/s | 66.8 steps/s
[Step=24600 Epoch=48.0] | Loss=0.01143 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.478 | L2-Norm(final)=5.791 | 4620.0 samples/s | 72.2 steps/s
[Step=24650 Epoch=48.1] | Loss=0.01266 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.483 | L2-Norm(final)=5.792 | 4551.4 samples/s | 71.1 steps/s
[Step=24700 Epoch=48.2] | Loss=0.01335 | Reg=0.00380 | acc=0.9688 | L2-Norm=19.490 | L2-Norm(final)=5.792 | 4631.0 samples/s | 72.4 steps/s
[Step=24750 Epoch=48.3] | Loss=0.01516 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.497 | L2-Norm(final)=5.792 | 4654.7 samples/s | 72.7 steps/s
[Step=24800 Epoch=48.4] | Loss=0.01528 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.504 | L2-Norm(final)=5.793 | 4624.3 samples/s | 72.3 steps/s
[Step=24850 Epoch=48.5] | Loss=0.01525 | Reg=0.00381 | acc=0.9688 | L2-Norm=19.510 | L2-Norm(final)=5.794 | 4697.8 samples/s | 73.4 steps/s
[Step=24900 Epoch=48.6] | Loss=0.01559 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.515 | L2-Norm(final)=5.795 | 4625.4 samples/s | 72.3 steps/s
[Step=24950 Epoch=48.7] | Loss=0.01627 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.519 | L2-Norm(final)=5.794 | 4628.1 samples/s | 72.3 steps/s
[Step=25000 Epoch=48.8] | Loss=0.01656 | Reg=0.00381 | acc=0.9844 | L2-Norm=19.524 | L2-Norm(final)=5.794 | 5868.1 samples/s | 91.7 steps/s
[Step=25050 Epoch=48.9] | Loss=0.01597 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.528 | L2-Norm(final)=5.793 | 2438.1 samples/s | 38.1 steps/s
[Step=25100 Epoch=49.0] | Loss=0.01582 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.532 | L2-Norm(final)=5.794 | 4682.3 samples/s | 73.2 steps/s
[Step=25150 Epoch=49.1] | Loss=0.01545 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.535 | L2-Norm(final)=5.794 | 4556.3 samples/s | 71.2 steps/s
[Step=25200 Epoch=49.1] | Loss=0.01541 | Reg=0.00382 | acc=0.9375 | L2-Norm=19.538 | L2-Norm(final)=5.794 | 4705.3 samples/s | 73.5 steps/s
[Step=25250 Epoch=49.2] | Loss=0.01516 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.541 | L2-Norm(final)=5.795 | 4531.4 samples/s | 70.8 steps/s
[Step=25300 Epoch=49.3] | Loss=0.01489 | Reg=0.00382 | acc=0.9688 | L2-Norm=19.543 | L2-Norm(final)=5.796 | 4598.1 samples/s | 71.8 steps/s
[Step=25350 Epoch=49.4] | Loss=0.01501 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.546 | L2-Norm(final)=5.797 | 4713.2 samples/s | 73.6 steps/s
[Step=25400 Epoch=49.5] | Loss=0.01510 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.548 | L2-Norm(final)=5.797 | 4548.9 samples/s | 71.1 steps/s
[Step=25450 Epoch=49.6] | Loss=0.01491 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.550 | L2-Norm(final)=5.798 | 4585.7 samples/s | 71.7 steps/s
[Step=25500 Epoch=49.7] | Loss=0.01505 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.552 | L2-Norm(final)=5.798 | 4998.0 samples/s | 78.1 steps/s
[Step=25550 Epoch=49.8] | Loss=0.01479 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.554 | L2-Norm(final)=5.798 | 2665.2 samples/s | 41.6 steps/s
[Step=25600 Epoch=49.9] | Loss=0.01459 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.555 | L2-Norm(final)=5.799 | 4589.4 samples/s | 71.7 steps/s
[Step=25650 Epoch=50.0] | Loss=0.01435 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.556 | L2-Norm(final)=5.800 | 4561.9 samples/s | 71.3 steps/s
[Step=25700 Epoch=50.1] | Loss=0.01414 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.557 | L2-Norm(final)=5.800 | 4621.5 samples/s | 72.2 steps/s
[Step=25750 Epoch=50.2] | Loss=0.01406 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.558 | L2-Norm(final)=5.801 | 4608.4 samples/s | 72.0 steps/s
[Step=25800 Epoch=50.3] | Loss=0.01392 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.559 | L2-Norm(final)=5.802 | 4644.7 samples/s | 72.6 steps/s
[Step=25850 Epoch=50.4] | Loss=0.01380 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.559 | L2-Norm(final)=5.804 | 4641.2 samples/s | 72.5 steps/s
[Step=25900 Epoch=50.5] | Loss=0.01379 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.560 | L2-Norm(final)=5.805 | 4679.4 samples/s | 73.1 steps/s
[Step=25950 Epoch=50.6] | Loss=0.01367 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.560 | L2-Norm(final)=5.806 | 4559.1 samples/s | 71.2 steps/s
[Step=26000 Epoch=50.7] | Loss=0.01351 | Reg=0.00383 | acc=0.9688 | L2-Norm=19.560 | L2-Norm(final)=5.807 | 4622.0 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step26000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=46.9] | Loss=0.00479 | Reg=0.00407 | acc=1.0000 | L2-Norm=20.164 | L2-Norm(final)=5.809 | 5915.8 samples/s | 92.4 steps/s
[Step=24050 Epoch=47.0] | Loss=0.00991 | Reg=0.00407 | acc=0.9531 | L2-Norm=20.163 | L2-Norm(final)=5.820 | 4940.5 samples/s | 77.2 steps/s
[Step=24100 Epoch=47.1] | Loss=0.00976 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.160 | L2-Norm(final)=5.829 | 5180.2 samples/s | 80.9 steps/s
[Step=24150 Epoch=47.2] | Loss=0.00962 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.158 | L2-Norm(final)=5.838 | 5178.3 samples/s | 80.9 steps/s
[Step=24200 Epoch=47.3] | Loss=0.00972 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.155 | L2-Norm(final)=5.845 | 5200.3 samples/s | 81.3 steps/s
[Step=24250 Epoch=47.4] | Loss=0.01021 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.151 | L2-Norm(final)=5.851 | 5227.5 samples/s | 81.7 steps/s
[Step=24300 Epoch=47.5] | Loss=0.01021 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.149 | L2-Norm(final)=5.857 | 5214.8 samples/s | 81.5 steps/s
[Step=24350 Epoch=47.6] | Loss=0.01007 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.145 | L2-Norm(final)=5.863 | 5233.9 samples/s | 81.8 steps/s
[Step=24400 Epoch=47.7] | Loss=0.00988 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.142 | L2-Norm(final)=5.871 | 5135.5 samples/s | 80.2 steps/s
[Step=24450 Epoch=47.8] | Loss=0.00974 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.139 | L2-Norm(final)=5.878 | 5210.7 samples/s | 81.4 steps/s
[Step=24500 Epoch=47.9] | Loss=0.00973 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.136 | L2-Norm(final)=5.886 | 7151.8 samples/s | 111.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=47.9] | Loss=0.01520 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.104 | L2-Norm(final)=5.953 | 6431.7 samples/s | 100.5 steps/s
[Step=24550 Epoch=48.0] | Loss=0.00778 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.102 | L2-Norm(final)=5.962 | 4364.6 samples/s | 68.2 steps/s
[Step=24600 Epoch=48.1] | Loss=0.01058 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.103 | L2-Norm(final)=5.965 | 4658.0 samples/s | 72.8 steps/s
[Step=24650 Epoch=48.2] | Loss=0.01180 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.105 | L2-Norm(final)=5.964 | 4573.7 samples/s | 71.5 steps/s
[Step=24700 Epoch=48.3] | Loss=0.01250 | Reg=0.00404 | acc=1.0000 | L2-Norm=20.108 | L2-Norm(final)=5.965 | 4587.7 samples/s | 71.7 steps/s
[Step=24750 Epoch=48.4] | Loss=0.01313 | Reg=0.00404 | acc=0.9844 | L2-Norm=20.112 | L2-Norm(final)=5.967 | 4638.4 samples/s | 72.5 steps/s
[Step=24800 Epoch=48.5] | Loss=0.01345 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.115 | L2-Norm(final)=5.968 | 4715.1 samples/s | 73.7 steps/s
[Step=24850 Epoch=48.6] | Loss=0.01434 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.117 | L2-Norm(final)=5.969 | 4627.7 samples/s | 72.3 steps/s
[Step=24900 Epoch=48.7] | Loss=0.01513 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.120 | L2-Norm(final)=5.968 | 4498.2 samples/s | 70.3 steps/s
[Step=24950 Epoch=48.8] | Loss=0.01548 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.124 | L2-Norm(final)=5.967 | 4659.0 samples/s | 72.8 steps/s
[Step=25000 Epoch=48.9] | Loss=0.01580 | Reg=0.00405 | acc=0.9688 | L2-Norm=20.127 | L2-Norm(final)=5.966 | 6026.4 samples/s | 94.2 steps/s
[Step=25050 Epoch=49.0] | Loss=0.01550 | Reg=0.00405 | acc=1.0000 | L2-Norm=20.130 | L2-Norm(final)=5.966 | 2421.1 samples/s | 37.8 steps/s
[Step=25100 Epoch=49.1] | Loss=0.01508 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.133 | L2-Norm(final)=5.966 | 4617.2 samples/s | 72.1 steps/s
[Step=25150 Epoch=49.2] | Loss=0.01492 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.135 | L2-Norm(final)=5.967 | 4662.9 samples/s | 72.9 steps/s
[Step=25200 Epoch=49.3] | Loss=0.01470 | Reg=0.00405 | acc=0.9844 | L2-Norm=20.137 | L2-Norm(final)=5.967 | 4583.0 samples/s | 71.6 steps/s
[Step=25250 Epoch=49.4] | Loss=0.01452 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.139 | L2-Norm(final)=5.968 | 4612.6 samples/s | 72.1 steps/s
[Step=25300 Epoch=49.5] | Loss=0.01457 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.140 | L2-Norm(final)=5.969 | 4622.0 samples/s | 72.2 steps/s
[Step=25350 Epoch=49.6] | Loss=0.01471 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.142 | L2-Norm(final)=5.970 | 4610.5 samples/s | 72.0 steps/s
[Step=25400 Epoch=49.7] | Loss=0.01455 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.143 | L2-Norm(final)=5.970 | 4674.2 samples/s | 73.0 steps/s
[Step=25450 Epoch=49.8] | Loss=0.01441 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.144 | L2-Norm(final)=5.971 | 4621.2 samples/s | 72.2 steps/s
[Step=25500 Epoch=49.9] | Loss=0.01438 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.145 | L2-Norm(final)=5.971 | 5110.3 samples/s | 79.8 steps/s
[Step=25550 Epoch=49.9] | Loss=0.01418 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.146 | L2-Norm(final)=5.972 | 2641.3 samples/s | 41.3 steps/s
[Step=25600 Epoch=50.0] | Loss=0.01402 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.147 | L2-Norm(final)=5.972 | 4596.7 samples/s | 71.8 steps/s
[Step=25650 Epoch=50.1] | Loss=0.01386 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.148 | L2-Norm(final)=5.973 | 4628.2 samples/s | 72.3 steps/s
[Step=25700 Epoch=50.2] | Loss=0.01374 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.148 | L2-Norm(final)=5.974 | 4602.8 samples/s | 71.9 steps/s
[Step=25750 Epoch=50.3] | Loss=0.01360 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.149 | L2-Norm(final)=5.975 | 4614.3 samples/s | 72.1 steps/s
[Step=25800 Epoch=50.4] | Loss=0.01358 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.149 | L2-Norm(final)=5.976 | 4609.0 samples/s | 72.0 steps/s
[Step=25850 Epoch=50.5] | Loss=0.01346 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.149 | L2-Norm(final)=5.976 | 4606.9 samples/s | 72.0 steps/s
[Step=25900 Epoch=50.6] | Loss=0.01346 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.149 | L2-Norm(final)=5.977 | 4639.6 samples/s | 72.5 steps/s
[Step=25950 Epoch=50.7] | Loss=0.01348 | Reg=0.00406 | acc=1.0000 | L2-Norm=20.149 | L2-Norm(final)=5.977 | 4601.5 samples/s | 71.9 steps/s
[Step=26000 Epoch=50.8] | Loss=0.01343 | Reg=0.00406 | acc=0.9844 | L2-Norm=20.149 | L2-Norm(final)=5.978 | 4651.1 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step26000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=92.0] | Loss=0.00005 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.008 | L2-Norm(final)=5.445 | 6703.8 samples/s | 104.7 steps/s
[Step=24050 Epoch=92.2] | Loss=0.00011 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.026 | L2-Norm(final)=5.452 | 4126.7 samples/s | 64.5 steps/s
[Step=24100 Epoch=92.3] | Loss=0.00014 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.041 | L2-Norm(final)=5.457 | 4872.6 samples/s | 76.1 steps/s
[Step=24150 Epoch=92.5] | Loss=0.00031 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.063 | L2-Norm(final)=5.465 | 4908.4 samples/s | 76.7 steps/s
[Step=24200 Epoch=92.7] | Loss=0.00036 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.092 | L2-Norm(final)=5.471 | 5013.0 samples/s | 78.3 steps/s
[Step=24250 Epoch=92.9] | Loss=0.00038 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.116 | L2-Norm(final)=5.478 | 6682.5 samples/s | 104.4 steps/s
[Step=24300 Epoch=93.1] | Loss=0.00032 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.135 | L2-Norm(final)=5.484 | 2491.6 samples/s | 38.9 steps/s
[Step=24350 Epoch=93.3] | Loss=0.00028 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.146 | L2-Norm(final)=5.489 | 4863.4 samples/s | 76.0 steps/s
[Step=24400 Epoch=93.5] | Loss=0.00025 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.152 | L2-Norm(final)=5.494 | 4947.8 samples/s | 77.3 steps/s
[Step=24450 Epoch=93.7] | Loss=0.00022 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.156 | L2-Norm(final)=5.498 | 4825.7 samples/s | 75.4 steps/s
[Step=24500 Epoch=93.9] | Loss=0.00021 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.157 | L2-Norm(final)=5.502 | 5716.3 samples/s | 89.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=93.9] | Loss=0.00006 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.162 | L2-Norm(final)=5.542 | 6178.6 samples/s | 96.5 steps/s
[Step=24550 Epoch=94.1] | Loss=0.00002 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.146 | L2-Norm(final)=5.546 | 3994.1 samples/s | 62.4 steps/s
[Step=24600 Epoch=94.3] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.125 | L2-Norm(final)=5.548 | 4354.9 samples/s | 68.0 steps/s
[Step=24650 Epoch=94.5] | Loss=0.00001 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.102 | L2-Norm(final)=5.549 | 4417.6 samples/s | 69.0 steps/s
[Step=24700 Epoch=94.6] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.079 | L2-Norm(final)=5.550 | 4383.9 samples/s | 68.5 steps/s
[Step=24750 Epoch=94.8] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.057 | L2-Norm(final)=5.552 | 5860.7 samples/s | 91.6 steps/s
[Step=24800 Epoch=95.0] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.036 | L2-Norm(final)=5.554 | 2333.5 samples/s | 36.5 steps/s
[Step=24850 Epoch=95.2] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.013 | L2-Norm(final)=5.556 | 4341.7 samples/s | 67.8 steps/s
[Step=24900 Epoch=95.4] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.991 | L2-Norm(final)=5.557 | 4501.3 samples/s | 70.3 steps/s
[Step=24950 Epoch=95.6] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.968 | L2-Norm(final)=5.558 | 4416.7 samples/s | 69.0 steps/s
[Step=25000 Epoch=95.8] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.945 | L2-Norm(final)=5.560 | 4824.2 samples/s | 75.4 steps/s
[Step=25050 Epoch=96.0] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.922 | L2-Norm(final)=5.561 | 2485.4 samples/s | 38.8 steps/s
[Step=25100 Epoch=96.2] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.899 | L2-Norm(final)=5.561 | 4384.9 samples/s | 68.5 steps/s
[Step=25150 Epoch=96.4] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.876 | L2-Norm(final)=5.562 | 4440.7 samples/s | 69.4 steps/s
[Step=25200 Epoch=96.6] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.852 | L2-Norm(final)=5.563 | 4343.1 samples/s | 67.9 steps/s
[Step=25250 Epoch=96.7] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.828 | L2-Norm(final)=5.564 | 4446.7 samples/s | 69.5 steps/s
[Step=25300 Epoch=96.9] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.805 | L2-Norm(final)=5.564 | 2638.3 samples/s | 41.2 steps/s
[Step=25350 Epoch=97.1] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.781 | L2-Norm(final)=5.565 | 4374.8 samples/s | 68.4 steps/s
[Step=25400 Epoch=97.3] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.757 | L2-Norm(final)=5.566 | 4448.8 samples/s | 69.5 steps/s
[Step=25450 Epoch=97.5] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.733 | L2-Norm(final)=5.566 | 4327.2 samples/s | 67.6 steps/s
[Step=25500 Epoch=97.7] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.708 | L2-Norm(final)=5.567 | 4427.1 samples/s | 69.2 steps/s
[Step=25550 Epoch=97.9] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.684 | L2-Norm(final)=5.567 | 2656.6 samples/s | 41.5 steps/s
[Step=25600 Epoch=98.1] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.659 | L2-Norm(final)=5.568 | 4448.9 samples/s | 69.5 steps/s
[Step=25650 Epoch=98.3] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.635 | L2-Norm(final)=5.569 | 4381.2 samples/s | 68.5 steps/s
[Step=25700 Epoch=98.5] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.610 | L2-Norm(final)=5.569 | 4352.5 samples/s | 68.0 steps/s
[Step=25750 Epoch=98.7] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.585 | L2-Norm(final)=5.570 | 4336.4 samples/s | 67.8 steps/s
[Step=25800 Epoch=98.9] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.560 | L2-Norm(final)=5.570 | 6532.5 samples/s | 102.1 steps/s
[Step=25850 Epoch=99.0] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.534 | L2-Norm(final)=5.571 | 2248.7 samples/s | 35.1 steps/s
[Step=25900 Epoch=99.2] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.509 | L2-Norm(final)=5.571 | 4447.6 samples/s | 69.5 steps/s
[Step=25950 Epoch=99.4] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.483 | L2-Norm(final)=5.572 | 4387.0 samples/s | 68.5 steps/s
[Step=26000 Epoch=99.6] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.458 | L2-Norm(final)=5.573 | 4424.4 samples/s | 69.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step26000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=92.4] | Loss=0.00012 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.045 | L2-Norm(final)=5.477 | 6065.8 samples/s | 94.8 steps/s
[Step=24050 Epoch=92.6] | Loss=0.00014 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.049 | L2-Norm(final)=5.482 | 4377.6 samples/s | 68.4 steps/s
[Step=24100 Epoch=92.8] | Loss=0.00015 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.071 | L2-Norm(final)=5.493 | 4915.9 samples/s | 76.8 steps/s
[Step=24150 Epoch=93.0] | Loss=0.00058 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.102 | L2-Norm(final)=5.496 | 4995.0 samples/s | 78.0 steps/s
[Step=24200 Epoch=93.2] | Loss=0.00059 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.134 | L2-Norm(final)=5.498 | 4879.9 samples/s | 76.2 steps/s
[Step=24250 Epoch=93.3] | Loss=0.00049 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.154 | L2-Norm(final)=5.501 | 6878.1 samples/s | 107.5 steps/s
[Step=24300 Epoch=93.5] | Loss=0.00042 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.166 | L2-Norm(final)=5.504 | 2482.4 samples/s | 38.8 steps/s
[Step=24350 Epoch=93.7] | Loss=0.00036 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.173 | L2-Norm(final)=5.508 | 4914.9 samples/s | 76.8 steps/s
[Step=24400 Epoch=93.9] | Loss=0.00032 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.177 | L2-Norm(final)=5.511 | 4844.0 samples/s | 75.7 steps/s
[Step=24450 Epoch=94.1] | Loss=0.00029 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.179 | L2-Norm(final)=5.515 | 4932.0 samples/s | 77.1 steps/s
[Step=24500 Epoch=94.3] | Loss=0.00026 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.179 | L2-Norm(final)=5.518 | 5792.8 samples/s | 90.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=94.3] | Loss=0.00002 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.174 | L2-Norm(final)=5.551 | 6320.0 samples/s | 98.7 steps/s
[Step=24550 Epoch=94.5] | Loss=0.00003 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.157 | L2-Norm(final)=5.554 | 3893.8 samples/s | 60.8 steps/s
[Step=24600 Epoch=94.7] | Loss=0.00002 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.134 | L2-Norm(final)=5.557 | 4396.5 samples/s | 68.7 steps/s
[Step=24650 Epoch=94.9] | Loss=0.00002 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.109 | L2-Norm(final)=5.559 | 4379.5 samples/s | 68.4 steps/s
[Step=24700 Epoch=95.1] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.085 | L2-Norm(final)=5.560 | 4431.4 samples/s | 69.2 steps/s
[Step=24750 Epoch=95.3] | Loss=0.00001 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.060 | L2-Norm(final)=5.561 | 5914.6 samples/s | 92.4 steps/s
[Step=24800 Epoch=95.5] | Loss=0.00001 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.035 | L2-Norm(final)=5.562 | 2308.3 samples/s | 36.1 steps/s
[Step=24850 Epoch=95.7] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.010 | L2-Norm(final)=5.563 | 4392.7 samples/s | 68.6 steps/s
[Step=24900 Epoch=95.8] | Loss=0.00001 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.985 | L2-Norm(final)=5.564 | 4435.7 samples/s | 69.3 steps/s
[Step=24950 Epoch=96.0] | Loss=0.00001 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.960 | L2-Norm(final)=5.565 | 4385.0 samples/s | 68.5 steps/s
[Step=25000 Epoch=96.2] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.935 | L2-Norm(final)=5.566 | 5042.4 samples/s | 78.8 steps/s
[Step=25050 Epoch=96.4] | Loss=0.00001 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.910 | L2-Norm(final)=5.567 | 2472.7 samples/s | 38.6 steps/s
[Step=25100 Epoch=96.6] | Loss=0.00001 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.885 | L2-Norm(final)=5.567 | 4337.0 samples/s | 67.8 steps/s
[Step=25150 Epoch=96.8] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=5.568 | 4462.9 samples/s | 69.7 steps/s
[Step=25200 Epoch=97.0] | Loss=0.00001 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.835 | L2-Norm(final)=5.569 | 4351.5 samples/s | 68.0 steps/s
[Step=25250 Epoch=97.2] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.810 | L2-Norm(final)=5.569 | 4484.0 samples/s | 70.1 steps/s
[Step=25300 Epoch=97.4] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.785 | L2-Norm(final)=5.570 | 2645.0 samples/s | 41.3 steps/s
[Step=25350 Epoch=97.6] | Loss=0.00001 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.760 | L2-Norm(final)=5.571 | 4360.2 samples/s | 68.1 steps/s
[Step=25400 Epoch=97.8] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.734 | L2-Norm(final)=5.571 | 4440.8 samples/s | 69.4 steps/s
[Step=25450 Epoch=98.0] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.709 | L2-Norm(final)=5.572 | 4424.1 samples/s | 69.1 steps/s
[Step=25500 Epoch=98.2] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.683 | L2-Norm(final)=5.573 | 4350.3 samples/s | 68.0 steps/s
[Step=25550 Epoch=98.4] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.658 | L2-Norm(final)=5.573 | 2694.1 samples/s | 42.1 steps/s
[Step=25600 Epoch=98.5] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.632 | L2-Norm(final)=5.574 | 4383.0 samples/s | 68.5 steps/s
[Step=25650 Epoch=98.7] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.606 | L2-Norm(final)=5.575 | 4431.9 samples/s | 69.2 steps/s
[Step=25700 Epoch=98.9] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.581 | L2-Norm(final)=5.575 | 4356.6 samples/s | 68.1 steps/s
[Step=25750 Epoch=99.1] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.555 | L2-Norm(final)=5.576 | 4456.1 samples/s | 69.6 steps/s
[Step=25800 Epoch=99.3] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.529 | L2-Norm(final)=5.577 | 6973.3 samples/s | 109.0 steps/s
[Step=25850 Epoch=99.5] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.502 | L2-Norm(final)=5.577 | 2191.7 samples/s | 34.2 steps/s
[Step=25900 Epoch=99.7] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.476 | L2-Norm(final)=5.578 | 4329.2 samples/s | 67.6 steps/s
[Step=25950 Epoch=99.9] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.450 | L2-Norm(final)=5.579 | 4407.3 samples/s | 68.9 steps/s
[Step=26000 Epoch=100.1] | Loss=0.00000 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.423 | L2-Norm(final)=5.580 | 4366.5 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08125 | acc=0.9656 | tpr=0.9728 | fpr=0.0500 | 5221.2 samples/s | 20.4 steps/s
Avg test loss: 0.08221, Avg test acc: 0.96550, Avg tpr: 0.97266, Avg fpr: 0.05025, total FA: 392

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07834 | acc=0.9677 | tpr=0.9804 | fpr=0.0600 | 5292.1 samples/s | 20.7 steps/s
Avg test loss: 0.08257, Avg test acc: 0.96727, Avg tpr: 0.97978, Avg fpr: 0.06025, total FA: 470

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.92377 | acc=0.3101 | tpr=0.0064 | fpr=0.0305 | 5603.5 samples/s | 21.9 steps/s
Avg test loss: 5.92902, Avg test acc: 0.30752, Avg tpr: 0.00659, Avg fpr: 0.03064, total FA: 239

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.58347 | acc=0.3030 | tpr=0.0131 | fpr=0.0676 | 5213.3 samples/s | 20.4 steps/s
Avg test loss: 5.60056, Avg test acc: 0.30022, Avg tpr: 0.01241, Avg fpr: 0.06679, total FA: 521

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.65291 | acc=0.1166 | tpr=0.7124 | fpr=0.8941 | 5282.1 samples/s | 20.6 steps/s
[Step= 100] | Loss=6.62313 | acc=0.1160 | tpr=0.6994 | fpr=0.8949 | 7531.8 samples/s | 29.4 steps/s
[Step= 150] | Loss=6.63570 | acc=0.1169 | tpr=0.7104 | fpr=0.8940 | 7379.7 samples/s | 28.8 steps/s
[Step= 200] | Loss=6.65134 | acc=0.1157 | tpr=0.7005 | fpr=0.8950 | 8129.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=6.65817 | acc=0.1166 | tpr=0.6996 | fpr=0.8940 | 7875.5 samples/s | 30.8 steps/s
[Step= 300] | Loss=6.65351 | acc=0.1172 | tpr=0.7047 | fpr=0.8935 | 8351.1 samples/s | 32.6 steps/s
[Step= 350] | Loss=6.64078 | acc=0.1176 | tpr=0.7026 | fpr=0.8930 | 8198.6 samples/s | 32.0 steps/s
[Step= 400] | Loss=6.63393 | acc=0.1186 | tpr=0.7101 | fpr=0.8922 | 8190.4 samples/s | 32.0 steps/s
[Step= 450] | Loss=6.63419 | acc=0.1181 | tpr=0.7093 | fpr=0.8927 | 7900.6 samples/s | 30.9 steps/s
[Step= 500] | Loss=6.63643 | acc=0.1176 | tpr=0.7040 | fpr=0.8930 | 8099.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=6.63615 | acc=0.1178 | tpr=0.7008 | fpr=0.8928 | 14510.2 samples/s | 56.7 steps/s
Avg test loss: 6.63714, Avg test acc: 0.11776, Avg tpr: 0.70087, Avg fpr: 0.89284, total FA: 123969

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.83843 | acc=0.1021 | tpr=0.7301 | fpr=0.9092 | 5451.3 samples/s | 21.3 steps/s
[Step= 100] | Loss=6.81017 | acc=0.1027 | tpr=0.7079 | fpr=0.9086 | 7192.2 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.81386 | acc=0.1038 | tpr=0.7161 | fpr=0.9075 | 7504.2 samples/s | 29.3 steps/s
[Step= 200] | Loss=6.82163 | acc=0.1036 | tpr=0.7213 | fpr=0.9077 | 8111.6 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.81889 | acc=0.1039 | tpr=0.7197 | fpr=0.9073 | 8314.5 samples/s | 32.5 steps/s
[Step= 300] | Loss=6.81974 | acc=0.1040 | tpr=0.7251 | fpr=0.9073 | 8347.4 samples/s | 32.6 steps/s
[Step= 350] | Loss=6.81117 | acc=0.1042 | tpr=0.7207 | fpr=0.9070 | 7885.6 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.80082 | acc=0.1046 | tpr=0.7216 | fpr=0.9066 | 8257.6 samples/s | 32.3 steps/s
[Step= 450] | Loss=6.80082 | acc=0.1042 | tpr=0.7225 | fpr=0.9071 | 8123.5 samples/s | 31.7 steps/s
[Step= 500] | Loss=6.80435 | acc=0.1040 | tpr=0.7229 | fpr=0.9072 | 8041.1 samples/s | 31.4 steps/s
[Step= 550] | Loss=6.80218 | acc=0.1041 | tpr=0.7175 | fpr=0.9071 | 14384.7 samples/s | 56.2 steps/s
Avg test loss: 6.80333, Avg test acc: 0.10404, Avg tpr: 0.71751, Avg fpr: 0.90711, total FA: 125951

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14989 | acc=0.9788 | tpr=0.9336 | fpr=0.0204 | 5536.7 samples/s | 21.6 steps/s
[Step= 100] | Loss=0.15566 | acc=0.9787 | tpr=0.9339 | fpr=0.0205 | 7150.1 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.16244 | acc=0.9773 | tpr=0.9308 | fpr=0.0218 | 7368.9 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.16551 | acc=0.9773 | tpr=0.9366 | fpr=0.0220 | 8377.7 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.16352 | acc=0.9777 | tpr=0.9362 | fpr=0.0216 | 7929.7 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.16659 | acc=0.9773 | tpr=0.9345 | fpr=0.0219 | 7957.2 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.16813 | acc=0.9769 | tpr=0.9361 | fpr=0.0224 | 8215.9 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.17028 | acc=0.9768 | tpr=0.9349 | fpr=0.0225 | 8015.0 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.17394 | acc=0.9764 | tpr=0.9352 | fpr=0.0228 | 8398.0 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.17271 | acc=0.9765 | tpr=0.9357 | fpr=0.0227 | 7855.3 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.17156 | acc=0.9767 | tpr=0.9363 | fpr=0.0226 | 14590.1 samples/s | 57.0 steps/s
Avg test loss: 0.17115, Avg test acc: 0.97668, Avg tpr: 0.93502, Avg fpr: 0.02256, total FA: 3133

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.18026 | acc=0.9749 | tpr=0.9469 | fpr=0.0246 | 5316.7 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.18437 | acc=0.9749 | tpr=0.9510 | fpr=0.0247 | 7325.1 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.19025 | acc=0.9739 | tpr=0.9568 | fpr=0.0258 | 7815.5 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.19389 | acc=0.9740 | tpr=0.9607 | fpr=0.0257 | 7888.6 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.18999 | acc=0.9747 | tpr=0.9598 | fpr=0.0251 | 8090.9 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.19421 | acc=0.9740 | tpr=0.9571 | fpr=0.0256 | 8034.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.19591 | acc=0.9738 | tpr=0.9574 | fpr=0.0259 | 8188.0 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.19758 | acc=0.9736 | tpr=0.9557 | fpr=0.0261 | 8356.5 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.20117 | acc=0.9732 | tpr=0.9552 | fpr=0.0265 | 7961.5 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.20008 | acc=0.9733 | tpr=0.9564 | fpr=0.0264 | 7925.4 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.19887 | acc=0.9735 | tpr=0.9554 | fpr=0.0262 | 15138.2 samples/s | 59.1 steps/s
Avg test loss: 0.19840, Avg test acc: 0.97346, Avg tpr: 0.95483, Avg fpr: 0.02620, total FA: 3638

server round 13/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=50.7] | Loss=0.01703 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.996 | L2-Norm(final)=5.849 | 6598.2 samples/s | 103.1 steps/s
[Step=26050 Epoch=50.8] | Loss=0.00868 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.994 | L2-Norm(final)=5.859 | 4536.9 samples/s | 70.9 steps/s
[Step=26100 Epoch=50.9] | Loss=0.00820 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.992 | L2-Norm(final)=5.866 | 5374.0 samples/s | 84.0 steps/s
[Step=26150 Epoch=51.0] | Loss=0.00780 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.990 | L2-Norm(final)=5.875 | 5085.3 samples/s | 79.5 steps/s
[Step=26200 Epoch=51.1] | Loss=0.00811 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.988 | L2-Norm(final)=5.883 | 5284.4 samples/s | 82.6 steps/s
[Step=26250 Epoch=51.2] | Loss=0.00828 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.987 | L2-Norm(final)=5.889 | 5157.7 samples/s | 80.6 steps/s
[Step=26300 Epoch=51.3] | Loss=0.00816 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.985 | L2-Norm(final)=5.896 | 5255.3 samples/s | 82.1 steps/s
[Step=26350 Epoch=51.4] | Loss=0.00839 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.983 | L2-Norm(final)=5.902 | 5126.1 samples/s | 80.1 steps/s
[Step=26400 Epoch=51.5] | Loss=0.00854 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.981 | L2-Norm(final)=5.908 | 5287.9 samples/s | 82.6 steps/s
[Step=26450 Epoch=51.6] | Loss=0.00854 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.979 | L2-Norm(final)=5.914 | 5132.8 samples/s | 80.2 steps/s
[Step=26500 Epoch=51.7] | Loss=0.00844 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.977 | L2-Norm(final)=5.919 | 7011.2 samples/s | 109.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=51.7] | Loss=0.00735 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.958 | L2-Norm(final)=5.979 | 6329.6 samples/s | 98.9 steps/s
[Step=26550 Epoch=51.8] | Loss=0.01071 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.959 | L2-Norm(final)=5.981 | 4178.4 samples/s | 65.3 steps/s
[Step=26600 Epoch=51.9] | Loss=0.01113 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.964 | L2-Norm(final)=5.985 | 4671.6 samples/s | 73.0 steps/s
[Step=26650 Epoch=52.0] | Loss=0.01324 | Reg=0.00360 | acc=0.9688 | L2-Norm=18.969 | L2-Norm(final)=5.985 | 4644.8 samples/s | 72.6 steps/s
[Step=26700 Epoch=52.1] | Loss=0.01433 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.977 | L2-Norm(final)=5.984 | 4522.2 samples/s | 70.7 steps/s
[Step=26750 Epoch=52.2] | Loss=0.01456 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.984 | L2-Norm(final)=5.986 | 4593.9 samples/s | 71.8 steps/s
[Step=26800 Epoch=52.3] | Loss=0.01459 | Reg=0.00361 | acc=0.9844 | L2-Norm=18.990 | L2-Norm(final)=5.987 | 4631.3 samples/s | 72.4 steps/s
[Step=26850 Epoch=52.4] | Loss=0.01479 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.996 | L2-Norm(final)=5.989 | 4609.2 samples/s | 72.0 steps/s
[Step=26900 Epoch=52.5] | Loss=0.01486 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.002 | L2-Norm(final)=5.990 | 4652.7 samples/s | 72.7 steps/s
[Step=26950 Epoch=52.6] | Loss=0.01531 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.009 | L2-Norm(final)=5.991 | 4652.3 samples/s | 72.7 steps/s
[Step=27000 Epoch=52.7] | Loss=0.01569 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.016 | L2-Norm(final)=5.993 | 5956.5 samples/s | 93.1 steps/s
[Step=27050 Epoch=52.8] | Loss=0.01521 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.023 | L2-Norm(final)=5.995 | 2450.2 samples/s | 38.3 steps/s
[Step=27100 Epoch=52.9] | Loss=0.01512 | Reg=0.00362 | acc=0.9688 | L2-Norm=19.028 | L2-Norm(final)=5.997 | 4623.7 samples/s | 72.2 steps/s
[Step=27150 Epoch=53.0] | Loss=0.01485 | Reg=0.00362 | acc=0.9688 | L2-Norm=19.033 | L2-Norm(final)=6.000 | 4569.8 samples/s | 71.4 steps/s
[Step=27200 Epoch=53.1] | Loss=0.01439 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.037 | L2-Norm(final)=6.002 | 4639.3 samples/s | 72.5 steps/s
[Step=27250 Epoch=53.1] | Loss=0.01422 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.042 | L2-Norm(final)=6.005 | 4670.8 samples/s | 73.0 steps/s
[Step=27300 Epoch=53.2] | Loss=0.01445 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.046 | L2-Norm(final)=6.007 | 4660.4 samples/s | 72.8 steps/s
[Step=27350 Epoch=53.3] | Loss=0.01435 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.050 | L2-Norm(final)=6.009 | 4555.5 samples/s | 71.2 steps/s
[Step=27400 Epoch=53.4] | Loss=0.01424 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.053 | L2-Norm(final)=6.011 | 4644.4 samples/s | 72.6 steps/s
[Step=27450 Epoch=53.5] | Loss=0.01414 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.057 | L2-Norm(final)=6.013 | 4625.1 samples/s | 72.3 steps/s
[Step=27500 Epoch=53.6] | Loss=0.01419 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.060 | L2-Norm(final)=6.014 | 4955.9 samples/s | 77.4 steps/s
[Step=27550 Epoch=53.7] | Loss=0.01403 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.063 | L2-Norm(final)=6.016 | 2670.8 samples/s | 41.7 steps/s
[Step=27600 Epoch=53.8] | Loss=0.01381 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.065 | L2-Norm(final)=6.018 | 4620.3 samples/s | 72.2 steps/s
[Step=27650 Epoch=53.9] | Loss=0.01378 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.067 | L2-Norm(final)=6.021 | 4626.9 samples/s | 72.3 steps/s
[Step=27700 Epoch=54.0] | Loss=0.01367 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.069 | L2-Norm(final)=6.023 | 4582.5 samples/s | 71.6 steps/s
[Step=27750 Epoch=54.1] | Loss=0.01352 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.071 | L2-Norm(final)=6.025 | 4593.4 samples/s | 71.8 steps/s
[Step=27800 Epoch=54.2] | Loss=0.01347 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.073 | L2-Norm(final)=6.027 | 4697.1 samples/s | 73.4 steps/s
[Step=27850 Epoch=54.3] | Loss=0.01347 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.074 | L2-Norm(final)=6.028 | 4588.9 samples/s | 71.7 steps/s
[Step=27900 Epoch=54.4] | Loss=0.01336 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.076 | L2-Norm(final)=6.030 | 4625.3 samples/s | 72.3 steps/s
[Step=27950 Epoch=54.5] | Loss=0.01333 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.077 | L2-Norm(final)=6.031 | 4632.1 samples/s | 72.4 steps/s
[Step=28000 Epoch=54.6] | Loss=0.01328 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.078 | L2-Norm(final)=6.033 | 4611.6 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step28000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=50.8] | Loss=0.00829 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.576 | L2-Norm(final)=5.994 | 6303.9 samples/s | 98.5 steps/s
[Step=26050 Epoch=50.9] | Loss=0.00729 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.574 | L2-Norm(final)=6.003 | 4681.8 samples/s | 73.2 steps/s
[Step=26100 Epoch=51.0] | Loss=0.00834 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.572 | L2-Norm(final)=6.012 | 5158.1 samples/s | 80.6 steps/s
[Step=26150 Epoch=51.1] | Loss=0.00816 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.568 | L2-Norm(final)=6.021 | 5187.4 samples/s | 81.1 steps/s
[Step=26200 Epoch=51.2] | Loss=0.00862 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.563 | L2-Norm(final)=6.030 | 5189.7 samples/s | 81.1 steps/s
[Step=26250 Epoch=51.3] | Loss=0.00876 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.560 | L2-Norm(final)=6.037 | 5338.8 samples/s | 83.4 steps/s
[Step=26300 Epoch=51.4] | Loss=0.00843 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.557 | L2-Norm(final)=6.043 | 5213.9 samples/s | 81.5 steps/s
[Step=26350 Epoch=51.5] | Loss=0.00827 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.554 | L2-Norm(final)=6.051 | 5183.4 samples/s | 81.0 steps/s
[Step=26400 Epoch=51.6] | Loss=0.00833 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.551 | L2-Norm(final)=6.058 | 5233.8 samples/s | 81.8 steps/s
[Step=26450 Epoch=51.7] | Loss=0.00843 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.548 | L2-Norm(final)=6.064 | 5187.4 samples/s | 81.1 steps/s
[Step=26500 Epoch=51.8] | Loss=0.00824 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.545 | L2-Norm(final)=6.070 | 7079.9 samples/s | 110.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=51.8] | Loss=0.00582 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.518 | L2-Norm(final)=6.128 | 7438.0 samples/s | 116.2 steps/s
[Step=26550 Epoch=51.9] | Loss=0.01044 | Reg=0.00381 | acc=0.9688 | L2-Norm=19.519 | L2-Norm(final)=6.134 | 3798.1 samples/s | 59.3 steps/s
[Step=26600 Epoch=52.0] | Loss=0.01173 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.523 | L2-Norm(final)=6.135 | 4672.4 samples/s | 73.0 steps/s
[Step=26650 Epoch=52.1] | Loss=0.01303 | Reg=0.00381 | acc=1.0000 | L2-Norm=19.526 | L2-Norm(final)=6.136 | 4579.5 samples/s | 71.6 steps/s
[Step=26700 Epoch=52.2] | Loss=0.01423 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.533 | L2-Norm(final)=6.137 | 4632.8 samples/s | 72.4 steps/s
[Step=26750 Epoch=52.3] | Loss=0.01461 | Reg=0.00382 | acc=0.9844 | L2-Norm=19.542 | L2-Norm(final)=6.137 | 4585.6 samples/s | 71.7 steps/s
[Step=26800 Epoch=52.4] | Loss=0.01514 | Reg=0.00382 | acc=1.0000 | L2-Norm=19.551 | L2-Norm(final)=6.137 | 4672.4 samples/s | 73.0 steps/s
[Step=26850 Epoch=52.5] | Loss=0.01531 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.558 | L2-Norm(final)=6.137 | 4606.1 samples/s | 72.0 steps/s
[Step=26900 Epoch=52.6] | Loss=0.01519 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.564 | L2-Norm(final)=6.137 | 4652.2 samples/s | 72.7 steps/s
[Step=26950 Epoch=52.7] | Loss=0.01518 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.570 | L2-Norm(final)=6.138 | 4645.4 samples/s | 72.6 steps/s
[Step=27000 Epoch=52.8] | Loss=0.01537 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.575 | L2-Norm(final)=6.138 | 5987.7 samples/s | 93.6 steps/s
[Step=27050 Epoch=52.9] | Loss=0.01531 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.580 | L2-Norm(final)=6.139 | 2435.4 samples/s | 38.1 steps/s
[Step=27100 Epoch=53.0] | Loss=0.01496 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.585 | L2-Norm(final)=6.140 | 4589.1 samples/s | 71.7 steps/s
[Step=27150 Epoch=53.1] | Loss=0.01464 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.588 | L2-Norm(final)=6.142 | 4651.9 samples/s | 72.7 steps/s
[Step=27200 Epoch=53.2] | Loss=0.01446 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.591 | L2-Norm(final)=6.144 | 4657.4 samples/s | 72.8 steps/s
[Step=27250 Epoch=53.3] | Loss=0.01417 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.593 | L2-Norm(final)=6.145 | 4603.5 samples/s | 71.9 steps/s
[Step=27300 Epoch=53.4] | Loss=0.01408 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.595 | L2-Norm(final)=6.147 | 4607.0 samples/s | 72.0 steps/s
[Step=27350 Epoch=53.5] | Loss=0.01402 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.597 | L2-Norm(final)=6.149 | 4718.9 samples/s | 73.7 steps/s
[Step=27400 Epoch=53.6] | Loss=0.01385 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.599 | L2-Norm(final)=6.150 | 4614.4 samples/s | 72.1 steps/s
[Step=27450 Epoch=53.7] | Loss=0.01391 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.600 | L2-Norm(final)=6.152 | 4639.6 samples/s | 72.5 steps/s
[Step=27500 Epoch=53.8] | Loss=0.01385 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.602 | L2-Norm(final)=6.154 | 5118.7 samples/s | 80.0 steps/s
[Step=27550 Epoch=53.9] | Loss=0.01375 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.603 | L2-Norm(final)=6.156 | 2636.9 samples/s | 41.2 steps/s
[Step=27600 Epoch=54.0] | Loss=0.01367 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.605 | L2-Norm(final)=6.158 | 4665.0 samples/s | 72.9 steps/s
[Step=27650 Epoch=54.1] | Loss=0.01347 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.606 | L2-Norm(final)=6.160 | 4583.1 samples/s | 71.6 steps/s
[Step=27700 Epoch=54.2] | Loss=0.01327 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.607 | L2-Norm(final)=6.161 | 4614.9 samples/s | 72.1 steps/s
[Step=27750 Epoch=54.3] | Loss=0.01325 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.607 | L2-Norm(final)=6.163 | 4678.0 samples/s | 73.1 steps/s
[Step=27800 Epoch=54.3] | Loss=0.01308 | Reg=0.00384 | acc=0.9844 | L2-Norm=19.608 | L2-Norm(final)=6.165 | 4717.9 samples/s | 73.7 steps/s
[Step=27850 Epoch=54.4] | Loss=0.01308 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.608 | L2-Norm(final)=6.167 | 4477.2 samples/s | 70.0 steps/s
[Step=27900 Epoch=54.5] | Loss=0.01315 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.609 | L2-Norm(final)=6.168 | 4658.4 samples/s | 72.8 steps/s
[Step=27950 Epoch=54.6] | Loss=0.01314 | Reg=0.00385 | acc=0.9688 | L2-Norm=19.610 | L2-Norm(final)=6.170 | 4663.9 samples/s | 72.9 steps/s
[Step=28000 Epoch=54.7] | Loss=0.01295 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.610 | L2-Norm(final)=6.171 | 4557.0 samples/s | 71.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step28000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=99.6] | Loss=0.00013 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.320 | L2-Norm(final)=5.590 | 6342.8 samples/s | 99.1 steps/s
[Step=26050 Epoch=99.8] | Loss=0.00291 | Reg=0.00153 | acc=0.9844 | L2-Norm=12.373 | L2-Norm(final)=5.592 | 4291.9 samples/s | 67.1 steps/s
[Step=26100 Epoch=100.0] | Loss=0.00212 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.471 | L2-Norm(final)=5.587 | 4847.4 samples/s | 75.7 steps/s
[Step=26150 Epoch=100.2] | Loss=0.00198 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.520 | L2-Norm(final)=5.586 | 4902.8 samples/s | 76.6 steps/s
[Step=26200 Epoch=100.4] | Loss=0.00156 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=5.588 | 4977.5 samples/s | 77.8 steps/s
[Step=26250 Epoch=100.6] | Loss=0.00126 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.590 | 6644.3 samples/s | 103.8 steps/s
[Step=26300 Epoch=100.8] | Loss=0.00111 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.591 | L2-Norm(final)=5.593 | 2466.6 samples/s | 38.5 steps/s
[Step=26350 Epoch=101.0] | Loss=0.00096 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.602 | L2-Norm(final)=5.596 | 4896.7 samples/s | 76.5 steps/s
[Step=26400 Epoch=101.2] | Loss=0.00084 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.609 | L2-Norm(final)=5.598 | 4858.4 samples/s | 75.9 steps/s
[Step=26450 Epoch=101.3] | Loss=0.00075 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.613 | L2-Norm(final)=5.600 | 5070.6 samples/s | 79.2 steps/s
[Step=26500 Epoch=101.5] | Loss=0.00068 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.616 | L2-Norm(final)=5.602 | 5448.8 samples/s | 85.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=101.5] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.632 | L2-Norm(final)=5.622 | 5848.8 samples/s | 91.4 steps/s
[Step=26550 Epoch=101.7] | Loss=0.02437 | Reg=0.00162 | acc=0.9688 | L2-Norm=12.726 | L2-Norm(final)=5.596 | 4116.7 samples/s | 64.3 steps/s
[Step=26600 Epoch=101.9] | Loss=0.01591 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.872 | L2-Norm(final)=5.548 | 4323.9 samples/s | 67.6 steps/s
[Step=26650 Epoch=102.1] | Loss=0.01210 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.936 | L2-Norm(final)=5.528 | 4390.5 samples/s | 68.6 steps/s
[Step=26700 Epoch=102.3] | Loss=0.00996 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.974 | L2-Norm(final)=5.517 | 4358.5 samples/s | 68.1 steps/s
[Step=26750 Epoch=102.5] | Loss=0.00823 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.997 | L2-Norm(final)=5.510 | 5887.4 samples/s | 92.0 steps/s
[Step=26800 Epoch=102.7] | Loss=0.00712 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.012 | L2-Norm(final)=5.506 | 2334.8 samples/s | 36.5 steps/s
[Step=26850 Epoch=102.9] | Loss=0.00611 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.022 | L2-Norm(final)=5.503 | 4385.3 samples/s | 68.5 steps/s
[Step=26900 Epoch=103.1] | Loss=0.00539 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.029 | L2-Norm(final)=5.501 | 4436.5 samples/s | 69.3 steps/s
[Step=26950 Epoch=103.3] | Loss=0.00480 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.034 | L2-Norm(final)=5.500 | 4377.2 samples/s | 68.4 steps/s
[Step=27000 Epoch=103.5] | Loss=0.00432 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.037 | L2-Norm(final)=5.499 | 4976.6 samples/s | 77.8 steps/s
[Step=27050 Epoch=103.6] | Loss=0.00393 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.039 | L2-Norm(final)=5.499 | 2510.3 samples/s | 39.2 steps/s
[Step=27100 Epoch=103.8] | Loss=0.00361 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.039 | L2-Norm(final)=5.499 | 4409.0 samples/s | 68.9 steps/s
[Step=27150 Epoch=104.0] | Loss=0.00333 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.039 | L2-Norm(final)=5.500 | 4373.5 samples/s | 68.3 steps/s
[Step=27200 Epoch=104.2] | Loss=0.00310 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.037 | L2-Norm(final)=5.500 | 4399.7 samples/s | 68.7 steps/s
[Step=27250 Epoch=104.4] | Loss=0.00289 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.036 | L2-Norm(final)=5.500 | 4366.3 samples/s | 68.2 steps/s
[Step=27300 Epoch=104.6] | Loss=0.00271 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.033 | L2-Norm(final)=5.501 | 2679.7 samples/s | 41.9 steps/s
[Step=27350 Epoch=104.8] | Loss=0.00255 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.030 | L2-Norm(final)=5.501 | 4402.0 samples/s | 68.8 steps/s
[Step=27400 Epoch=105.0] | Loss=0.00241 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.027 | L2-Norm(final)=5.502 | 4432.7 samples/s | 69.3 steps/s
[Step=27450 Epoch=105.2] | Loss=0.00229 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.024 | L2-Norm(final)=5.502 | 4372.4 samples/s | 68.3 steps/s
[Step=27500 Epoch=105.4] | Loss=0.00217 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.020 | L2-Norm(final)=5.503 | 4358.5 samples/s | 68.1 steps/s
[Step=27550 Epoch=105.6] | Loss=0.00207 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.016 | L2-Norm(final)=5.504 | 2671.3 samples/s | 41.7 steps/s
[Step=27600 Epoch=105.8] | Loss=0.00198 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.012 | L2-Norm(final)=5.504 | 4399.2 samples/s | 68.7 steps/s
[Step=27650 Epoch=105.9] | Loss=0.00189 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.008 | L2-Norm(final)=5.505 | 4461.8 samples/s | 69.7 steps/s
[Step=27700 Epoch=106.1] | Loss=0.00181 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.004 | L2-Norm(final)=5.506 | 4360.1 samples/s | 68.1 steps/s
[Step=27750 Epoch=106.3] | Loss=0.00174 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.999 | L2-Norm(final)=5.507 | 4468.4 samples/s | 69.8 steps/s
[Step=27800 Epoch=106.5] | Loss=0.00167 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.994 | L2-Norm(final)=5.507 | 6271.9 samples/s | 98.0 steps/s
[Step=27850 Epoch=106.7] | Loss=0.00161 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.990 | L2-Norm(final)=5.508 | 2285.3 samples/s | 35.7 steps/s
[Step=27900 Epoch=106.9] | Loss=0.00156 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.985 | L2-Norm(final)=5.509 | 4246.8 samples/s | 66.4 steps/s
[Step=27950 Epoch=107.1] | Loss=0.00150 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.980 | L2-Norm(final)=5.510 | 4382.9 samples/s | 68.5 steps/s
[Step=28000 Epoch=107.3] | Loss=0.00145 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.975 | L2-Norm(final)=5.511 | 4405.9 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step28000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=100.1] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.318 | L2-Norm(final)=5.602 | 6477.9 samples/s | 101.2 steps/s
[Step=26050 Epoch=100.3] | Loss=0.00007 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.323 | L2-Norm(final)=5.610 | 4175.0 samples/s | 65.2 steps/s
[Step=26100 Epoch=100.5] | Loss=0.00007 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.332 | L2-Norm(final)=5.620 | 4969.5 samples/s | 77.6 steps/s
[Step=26150 Epoch=100.7] | Loss=0.00020 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.352 | L2-Norm(final)=5.630 | 4842.3 samples/s | 75.7 steps/s
[Step=26200 Epoch=100.9] | Loss=0.00029 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.392 | L2-Norm(final)=5.642 | 4896.4 samples/s | 76.5 steps/s
[Step=26250 Epoch=101.0] | Loss=0.00039 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.436 | L2-Norm(final)=5.654 | 6994.7 samples/s | 109.3 steps/s
[Step=26300 Epoch=101.2] | Loss=0.00058 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.484 | L2-Norm(final)=5.663 | 2443.7 samples/s | 38.2 steps/s
[Step=26350 Epoch=101.4] | Loss=0.00051 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.524 | L2-Norm(final)=5.671 | 4955.4 samples/s | 77.4 steps/s
[Step=26400 Epoch=101.6] | Loss=0.00045 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.552 | L2-Norm(final)=5.677 | 4835.2 samples/s | 75.5 steps/s
[Step=26450 Epoch=101.8] | Loss=0.00041 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.572 | L2-Norm(final)=5.683 | 4909.1 samples/s | 76.7 steps/s
[Step=26500 Epoch=102.0] | Loss=0.00037 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.588 | L2-Norm(final)=5.688 | 5902.1 samples/s | 92.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=102.0] | Loss=0.00000 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.721 | L2-Norm(final)=5.738 | 6332.2 samples/s | 98.9 steps/s
[Step=26550 Epoch=102.2] | Loss=0.00864 | Reg=0.00163 | acc=0.9844 | L2-Norm=12.779 | L2-Norm(final)=5.732 | 3888.8 samples/s | 60.8 steps/s
[Step=26600 Epoch=102.4] | Loss=0.01262 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.938 | L2-Norm(final)=5.691 | 4425.7 samples/s | 69.2 steps/s
[Step=26650 Epoch=102.6] | Loss=0.00948 | Reg=0.00169 | acc=0.9844 | L2-Norm=13.016 | L2-Norm(final)=5.669 | 4404.5 samples/s | 68.8 steps/s
[Step=26700 Epoch=102.8] | Loss=0.00778 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.057 | L2-Norm(final)=5.657 | 4363.3 samples/s | 68.2 steps/s
[Step=26750 Epoch=103.0] | Loss=0.00630 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.081 | L2-Norm(final)=5.651 | 5990.8 samples/s | 93.6 steps/s
[Step=26800 Epoch=103.2] | Loss=0.00540 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.097 | L2-Norm(final)=5.647 | 2319.0 samples/s | 36.2 steps/s
[Step=26850 Epoch=103.4] | Loss=0.00464 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.107 | L2-Norm(final)=5.644 | 4424.9 samples/s | 69.1 steps/s
[Step=26900 Epoch=103.5] | Loss=0.00409 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.115 | L2-Norm(final)=5.643 | 4403.0 samples/s | 68.8 steps/s
[Step=26950 Epoch=103.7] | Loss=0.00364 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.120 | L2-Norm(final)=5.643 | 4313.2 samples/s | 67.4 steps/s
[Step=27000 Epoch=103.9] | Loss=0.00328 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.123 | L2-Norm(final)=5.643 | 5136.5 samples/s | 80.3 steps/s
[Step=27050 Epoch=104.1] | Loss=0.00299 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.124 | L2-Norm(final)=5.643 | 2463.9 samples/s | 38.5 steps/s
[Step=27100 Epoch=104.3] | Loss=0.00274 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.123 | L2-Norm(final)=5.644 | 4399.4 samples/s | 68.7 steps/s
[Step=27150 Epoch=104.5] | Loss=0.00253 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.121 | L2-Norm(final)=5.644 | 4388.3 samples/s | 68.6 steps/s
[Step=27200 Epoch=104.7] | Loss=0.00235 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.119 | L2-Norm(final)=5.645 | 4397.8 samples/s | 68.7 steps/s
[Step=27250 Epoch=104.9] | Loss=0.00219 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.116 | L2-Norm(final)=5.645 | 4482.4 samples/s | 70.0 steps/s
[Step=27300 Epoch=105.1] | Loss=0.00206 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.112 | L2-Norm(final)=5.646 | 2645.7 samples/s | 41.3 steps/s
[Step=27350 Epoch=105.3] | Loss=0.00194 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.108 | L2-Norm(final)=5.647 | 4375.4 samples/s | 68.4 steps/s
[Step=27400 Epoch=105.5] | Loss=0.00183 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.104 | L2-Norm(final)=5.648 | 4396.9 samples/s | 68.7 steps/s
[Step=27450 Epoch=105.7] | Loss=0.00173 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.099 | L2-Norm(final)=5.648 | 4383.3 samples/s | 68.5 steps/s
[Step=27500 Epoch=105.9] | Loss=0.00165 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.094 | L2-Norm(final)=5.649 | 4376.3 samples/s | 68.4 steps/s
[Step=27550 Epoch=106.1] | Loss=0.00157 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.089 | L2-Norm(final)=5.651 | 2709.6 samples/s | 42.3 steps/s
[Step=27600 Epoch=106.2] | Loss=0.00150 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.084 | L2-Norm(final)=5.652 | 4314.9 samples/s | 67.4 steps/s
[Step=27650 Epoch=106.4] | Loss=0.00143 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.079 | L2-Norm(final)=5.653 | 4486.5 samples/s | 70.1 steps/s
[Step=27700 Epoch=106.6] | Loss=0.00138 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.074 | L2-Norm(final)=5.654 | 4295.0 samples/s | 67.1 steps/s
[Step=27750 Epoch=106.8] | Loss=0.00132 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.068 | L2-Norm(final)=5.655 | 4384.4 samples/s | 68.5 steps/s
[Step=27800 Epoch=107.0] | Loss=0.00127 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.062 | L2-Norm(final)=5.657 | 7157.7 samples/s | 111.8 steps/s
[Step=27850 Epoch=107.2] | Loss=0.00122 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.057 | L2-Norm(final)=5.658 | 2170.1 samples/s | 33.9 steps/s
[Step=27900 Epoch=107.4] | Loss=0.00118 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.051 | L2-Norm(final)=5.660 | 4425.1 samples/s | 69.1 steps/s
[Step=27950 Epoch=107.6] | Loss=0.00114 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.045 | L2-Norm(final)=5.661 | 4336.9 samples/s | 67.8 steps/s
[Step=28000 Epoch=107.8] | Loss=0.00110 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.039 | L2-Norm(final)=5.663 | 4363.0 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07348 | acc=0.9637 | tpr=0.9669 | fpr=0.0431 | 5662.1 samples/s | 22.1 steps/s
Avg test loss: 0.07808, Avg test acc: 0.96278, Avg tpr: 0.96707, Avg fpr: 0.04666, total FA: 364

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07259 | acc=0.9660 | tpr=0.9725 | fpr=0.0481 | 5223.3 samples/s | 20.4 steps/s
Avg test loss: 0.07758, Avg test acc: 0.96586, Avg tpr: 0.97249, Avg fpr: 0.04871, total FA: 380

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.89576 | acc=0.3116 | tpr=0.0040 | fpr=0.0206 | 5442.0 samples/s | 21.3 steps/s
Avg test loss: 4.89518, Avg test acc: 0.31008, Avg tpr: 0.00583, Avg fpr: 0.02077, total FA: 162

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.59813 | acc=0.3101 | tpr=0.0070 | fpr=0.0317 | 5583.1 samples/s | 21.8 steps/s
Avg test loss: 5.62041, Avg test acc: 0.30744, Avg tpr: 0.00641, Avg fpr: 0.03051, total FA: 238

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.94639 | acc=0.1255 | tpr=0.6327 | fpr=0.8836 | 5538.3 samples/s | 21.6 steps/s
[Step= 100] | Loss=5.92147 | acc=0.1245 | tpr=0.5949 | fpr=0.8843 | 7188.6 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.92400 | acc=0.1256 | tpr=0.6081 | fpr=0.8833 | 7376.7 samples/s | 28.8 steps/s
[Step= 200] | Loss=5.94721 | acc=0.1237 | tpr=0.6044 | fpr=0.8850 | 8002.2 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.95209 | acc=0.1237 | tpr=0.6044 | fpr=0.8850 | 7989.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.94606 | acc=0.1238 | tpr=0.6124 | fpr=0.8851 | 8127.1 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.93358 | acc=0.1245 | tpr=0.6111 | fpr=0.8843 | 8433.2 samples/s | 32.9 steps/s
[Step= 400] | Loss=5.92850 | acc=0.1249 | tpr=0.6154 | fpr=0.8841 | 8116.4 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.93145 | acc=0.1245 | tpr=0.6164 | fpr=0.8844 | 8141.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.93306 | acc=0.1246 | tpr=0.6119 | fpr=0.8842 | 8157.8 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.93493 | acc=0.1246 | tpr=0.6080 | fpr=0.8842 | 14529.1 samples/s | 56.8 steps/s
Avg test loss: 5.93639, Avg test acc: 0.12459, Avg tpr: 0.60777, Avg fpr: 0.88420, total FA: 122769

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.56335 | acc=0.1209 | tpr=0.6416 | fpr=0.8885 | 5350.7 samples/s | 20.9 steps/s
[Step= 100] | Loss=6.53420 | acc=0.1215 | tpr=0.6226 | fpr=0.8878 | 7166.0 samples/s | 28.0 steps/s
[Step= 150] | Loss=6.53262 | acc=0.1213 | tpr=0.6254 | fpr=0.8880 | 7666.9 samples/s | 29.9 steps/s
[Step= 200] | Loss=6.53998 | acc=0.1211 | tpr=0.6197 | fpr=0.8880 | 8266.8 samples/s | 32.3 steps/s
[Step= 250] | Loss=6.54244 | acc=0.1221 | tpr=0.6218 | fpr=0.8870 | 8342.3 samples/s | 32.6 steps/s
[Step= 300] | Loss=6.54297 | acc=0.1215 | tpr=0.6327 | fpr=0.8878 | 7824.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=6.52872 | acc=0.1218 | tpr=0.6281 | fpr=0.8874 | 8784.2 samples/s | 34.3 steps/s
[Step= 400] | Loss=6.51809 | acc=0.1222 | tpr=0.6258 | fpr=0.8870 | 8061.5 samples/s | 31.5 steps/s
[Step= 450] | Loss=6.51742 | acc=0.1221 | tpr=0.6271 | fpr=0.8871 | 8340.3 samples/s | 32.6 steps/s
[Step= 500] | Loss=6.51892 | acc=0.1220 | tpr=0.6286 | fpr=0.8872 | 8165.5 samples/s | 31.9 steps/s
[Step= 550] | Loss=6.51687 | acc=0.1222 | tpr=0.6251 | fpr=0.8869 | 14433.6 samples/s | 56.4 steps/s
Avg test loss: 6.51759, Avg test acc: 0.12220, Avg tpr: 0.62559, Avg fpr: 0.88696, total FA: 123152

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14130 | acc=0.9788 | tpr=0.9469 | fpr=0.0207 | 5012.7 samples/s | 19.6 steps/s
[Step= 100] | Loss=0.14527 | acc=0.9784 | tpr=0.9510 | fpr=0.0211 | 7361.1 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.15282 | acc=0.9771 | tpr=0.9467 | fpr=0.0224 | 8046.6 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.15589 | acc=0.9771 | tpr=0.9508 | fpr=0.0224 | 8571.4 samples/s | 33.5 steps/s
[Step= 250] | Loss=0.15338 | acc=0.9773 | tpr=0.9511 | fpr=0.0222 | 8088.1 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.15553 | acc=0.9770 | tpr=0.9484 | fpr=0.0225 | 8167.1 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.15645 | acc=0.9768 | tpr=0.9480 | fpr=0.0227 | 8207.5 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.15882 | acc=0.9765 | tpr=0.9453 | fpr=0.0229 | 7896.5 samples/s | 30.8 steps/s
[Step= 450] | Loss=0.16213 | acc=0.9762 | tpr=0.9435 | fpr=0.0232 | 8310.2 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.16164 | acc=0.9762 | tpr=0.9445 | fpr=0.0232 | 8093.8 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.16034 | acc=0.9765 | tpr=0.9451 | fpr=0.0229 | 14118.1 samples/s | 55.1 steps/s
Avg test loss: 0.15991, Avg test acc: 0.97654, Avg tpr: 0.94493, Avg fpr: 0.02288, total FA: 3177

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15853 | acc=0.9776 | tpr=0.9425 | fpr=0.0218 | 5289.0 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.16216 | acc=0.9770 | tpr=0.9446 | fpr=0.0224 | 7420.5 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.16905 | acc=0.9760 | tpr=0.9539 | fpr=0.0236 | 7843.2 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.17447 | acc=0.9753 | tpr=0.9574 | fpr=0.0243 | 7938.8 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.17114 | acc=0.9756 | tpr=0.9528 | fpr=0.0240 | 8148.3 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.17444 | acc=0.9753 | tpr=0.9505 | fpr=0.0243 | 8140.8 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.17542 | acc=0.9750 | tpr=0.9518 | fpr=0.0246 | 7966.1 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.17770 | acc=0.9747 | tpr=0.9447 | fpr=0.0248 | 8018.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.18061 | acc=0.9743 | tpr=0.9435 | fpr=0.0252 | 8219.5 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.18027 | acc=0.9744 | tpr=0.9454 | fpr=0.0251 | 8055.7 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.17918 | acc=0.9745 | tpr=0.9451 | fpr=0.0249 | 14781.9 samples/s | 57.7 steps/s
Avg test loss: 0.17881, Avg test acc: 0.97454, Avg tpr: 0.94453, Avg fpr: 0.02492, total FA: 3460

server round 14/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=54.6] | Loss=0.02675 | Reg=0.00357 | acc=0.9844 | L2-Norm=18.903 | L2-Norm(final)=6.083 | 6588.6 samples/s | 102.9 steps/s
[Step=28050 Epoch=54.7] | Loss=0.01607 | Reg=0.00357 | acc=0.9844 | L2-Norm=18.907 | L2-Norm(final)=6.102 | 4859.2 samples/s | 75.9 steps/s
[Step=28100 Epoch=54.8] | Loss=0.01572 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.914 | L2-Norm(final)=6.123 | 5153.7 samples/s | 80.5 steps/s
[Step=28150 Epoch=54.9] | Loss=0.01563 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.922 | L2-Norm(final)=6.140 | 5376.6 samples/s | 84.0 steps/s
[Step=28200 Epoch=55.0] | Loss=0.01626 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.928 | L2-Norm(final)=6.157 | 5024.1 samples/s | 78.5 steps/s
[Step=28250 Epoch=55.1] | Loss=0.01575 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.935 | L2-Norm(final)=6.170 | 5151.0 samples/s | 80.5 steps/s
[Step=28300 Epoch=55.2] | Loss=0.01587 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.941 | L2-Norm(final)=6.183 | 5223.0 samples/s | 81.6 steps/s
[Step=28350 Epoch=55.3] | Loss=0.01563 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.947 | L2-Norm(final)=6.195 | 5231.4 samples/s | 81.7 steps/s
[Step=28400 Epoch=55.4] | Loss=0.01558 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.951 | L2-Norm(final)=6.208 | 5392.9 samples/s | 84.3 steps/s
[Step=28450 Epoch=55.5] | Loss=0.01534 | Reg=0.00359 | acc=0.9688 | L2-Norm=18.955 | L2-Norm(final)=6.220 | 5046.4 samples/s | 78.9 steps/s
[Step=28500 Epoch=55.6] | Loss=0.01524 | Reg=0.00359 | acc=0.9844 | L2-Norm=18.959 | L2-Norm(final)=6.232 | 6960.3 samples/s | 108.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=55.6] | Loss=0.00573 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.005 | L2-Norm(final)=6.349 | 5795.4 samples/s | 90.6 steps/s
[Step=28550 Epoch=55.7] | Loss=0.01227 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.009 | L2-Norm(final)=6.358 | 4469.5 samples/s | 69.8 steps/s
[Step=28600 Epoch=55.8] | Loss=0.01376 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.021 | L2-Norm(final)=6.359 | 4719.1 samples/s | 73.7 steps/s
[Step=28650 Epoch=55.9] | Loss=0.01471 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.033 | L2-Norm(final)=6.361 | 4550.0 samples/s | 71.1 steps/s
[Step=28700 Epoch=56.0] | Loss=0.01503 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.044 | L2-Norm(final)=6.361 | 4537.3 samples/s | 70.9 steps/s
[Step=28750 Epoch=56.1] | Loss=0.01622 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.054 | L2-Norm(final)=6.362 | 4621.7 samples/s | 72.2 steps/s
[Step=28800 Epoch=56.2] | Loss=0.01618 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.062 | L2-Norm(final)=6.365 | 4647.2 samples/s | 72.6 steps/s
[Step=28850 Epoch=56.3] | Loss=0.01653 | Reg=0.00364 | acc=0.9688 | L2-Norm=19.070 | L2-Norm(final)=6.366 | 4627.6 samples/s | 72.3 steps/s
[Step=28900 Epoch=56.4] | Loss=0.01635 | Reg=0.00364 | acc=0.9688 | L2-Norm=19.078 | L2-Norm(final)=6.367 | 4605.3 samples/s | 72.0 steps/s
[Step=28950 Epoch=56.5] | Loss=0.01623 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.086 | L2-Norm(final)=6.369 | 4632.6 samples/s | 72.4 steps/s
[Step=29000 Epoch=56.6] | Loss=0.01635 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.093 | L2-Norm(final)=6.370 | 6000.2 samples/s | 93.8 steps/s
[Step=29050 Epoch=56.7] | Loss=0.01624 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.100 | L2-Norm(final)=6.371 | 2456.9 samples/s | 38.4 steps/s
[Step=29100 Epoch=56.8] | Loss=0.01601 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.106 | L2-Norm(final)=6.372 | 4699.3 samples/s | 73.4 steps/s
[Step=29150 Epoch=56.9] | Loss=0.01564 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.111 | L2-Norm(final)=6.373 | 4510.9 samples/s | 70.5 steps/s
[Step=29200 Epoch=57.0] | Loss=0.01538 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.116 | L2-Norm(final)=6.375 | 4613.5 samples/s | 72.1 steps/s
[Step=29250 Epoch=57.0] | Loss=0.01514 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.120 | L2-Norm(final)=6.376 | 4634.5 samples/s | 72.4 steps/s
[Step=29300 Epoch=57.1] | Loss=0.01518 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.123 | L2-Norm(final)=6.377 | 4595.6 samples/s | 71.8 steps/s
[Step=29350 Epoch=57.2] | Loss=0.01502 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.126 | L2-Norm(final)=6.377 | 4659.8 samples/s | 72.8 steps/s
[Step=29400 Epoch=57.3] | Loss=0.01497 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.130 | L2-Norm(final)=6.378 | 4594.3 samples/s | 71.8 steps/s
[Step=29450 Epoch=57.4] | Loss=0.01486 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.133 | L2-Norm(final)=6.379 | 4648.6 samples/s | 72.6 steps/s
[Step=29500 Epoch=57.5] | Loss=0.01475 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.135 | L2-Norm(final)=6.380 | 4996.6 samples/s | 78.1 steps/s
[Step=29550 Epoch=57.6] | Loss=0.01460 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.138 | L2-Norm(final)=6.381 | 2681.7 samples/s | 41.9 steps/s
[Step=29600 Epoch=57.7] | Loss=0.01427 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.140 | L2-Norm(final)=6.382 | 4676.6 samples/s | 73.1 steps/s
[Step=29650 Epoch=57.8] | Loss=0.01408 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.141 | L2-Norm(final)=6.383 | 4527.6 samples/s | 70.7 steps/s
[Step=29700 Epoch=57.9] | Loss=0.01400 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.143 | L2-Norm(final)=6.384 | 4574.1 samples/s | 71.5 steps/s
[Step=29750 Epoch=58.0] | Loss=0.01378 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.144 | L2-Norm(final)=6.385 | 4615.2 samples/s | 72.1 steps/s
[Step=29800 Epoch=58.1] | Loss=0.01370 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.146 | L2-Norm(final)=6.386 | 4679.9 samples/s | 73.1 steps/s
[Step=29850 Epoch=58.2] | Loss=0.01360 | Reg=0.00367 | acc=0.9531 | L2-Norm=19.147 | L2-Norm(final)=6.387 | 4562.0 samples/s | 71.3 steps/s
[Step=29900 Epoch=58.3] | Loss=0.01340 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.148 | L2-Norm(final)=6.388 | 4655.9 samples/s | 72.7 steps/s
[Step=29950 Epoch=58.4] | Loss=0.01344 | Reg=0.00367 | acc=0.9688 | L2-Norm=19.148 | L2-Norm(final)=6.390 | 4588.1 samples/s | 71.7 steps/s
[Step=30000 Epoch=58.5] | Loss=0.01335 | Reg=0.00367 | acc=1.0000 | L2-Norm=19.149 | L2-Norm(final)=6.390 | 4643.6 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step30000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=54.7] | Loss=0.02149 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.430 | L2-Norm(final)=6.217 | 6509.1 samples/s | 101.7 steps/s
[Step=28050 Epoch=54.8] | Loss=0.01866 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.435 | L2-Norm(final)=6.232 | 4682.7 samples/s | 73.2 steps/s
[Step=28100 Epoch=54.9] | Loss=0.01634 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.442 | L2-Norm(final)=6.253 | 5107.4 samples/s | 79.8 steps/s
[Step=28150 Epoch=55.0] | Loss=0.01601 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.450 | L2-Norm(final)=6.274 | 5141.6 samples/s | 80.3 steps/s
[Step=28200 Epoch=55.1] | Loss=0.01580 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.459 | L2-Norm(final)=6.292 | 5207.6 samples/s | 81.4 steps/s
[Step=28250 Epoch=55.2] | Loss=0.01605 | Reg=0.00379 | acc=0.9688 | L2-Norm=19.467 | L2-Norm(final)=6.308 | 5166.1 samples/s | 80.7 steps/s
[Step=28300 Epoch=55.3] | Loss=0.01557 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.476 | L2-Norm(final)=6.323 | 5180.5 samples/s | 80.9 steps/s
[Step=28350 Epoch=55.4] | Loss=0.01562 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.483 | L2-Norm(final)=6.338 | 5364.5 samples/s | 83.8 steps/s
[Step=28400 Epoch=55.5] | Loss=0.01554 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.491 | L2-Norm(final)=6.352 | 5166.2 samples/s | 80.7 steps/s
[Step=28450 Epoch=55.6] | Loss=0.01562 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.498 | L2-Norm(final)=6.366 | 5213.9 samples/s | 81.5 steps/s
[Step=28500 Epoch=55.7] | Loss=0.01551 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.505 | L2-Norm(final)=6.379 | 6944.7 samples/s | 108.5 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=55.7] | Loss=0.01433 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.570 | L2-Norm(final)=6.512 | 6090.8 samples/s | 95.2 steps/s
[Step=28550 Epoch=55.8] | Loss=0.01143 | Reg=0.00383 | acc=0.9844 | L2-Norm=19.575 | L2-Norm(final)=6.523 | 4275.8 samples/s | 66.8 steps/s
[Step=28600 Epoch=55.9] | Loss=0.01284 | Reg=0.00383 | acc=1.0000 | L2-Norm=19.583 | L2-Norm(final)=6.530 | 4627.8 samples/s | 72.3 steps/s
[Step=28650 Epoch=56.0] | Loss=0.01501 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.591 | L2-Norm(final)=6.532 | 4699.5 samples/s | 73.4 steps/s
[Step=28700 Epoch=56.1] | Loss=0.01528 | Reg=0.00384 | acc=1.0000 | L2-Norm=19.599 | L2-Norm(final)=6.534 | 4628.1 samples/s | 72.3 steps/s
[Step=28750 Epoch=56.2] | Loss=0.01624 | Reg=0.00384 | acc=0.9688 | L2-Norm=19.607 | L2-Norm(final)=6.535 | 4519.4 samples/s | 70.6 steps/s
[Step=28800 Epoch=56.3] | Loss=0.01619 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.616 | L2-Norm(final)=6.536 | 4625.8 samples/s | 72.3 steps/s
[Step=28850 Epoch=56.4] | Loss=0.01605 | Reg=0.00385 | acc=0.9844 | L2-Norm=19.624 | L2-Norm(final)=6.538 | 4645.3 samples/s | 72.6 steps/s
[Step=28900 Epoch=56.5] | Loss=0.01593 | Reg=0.00385 | acc=1.0000 | L2-Norm=19.631 | L2-Norm(final)=6.540 | 4604.3 samples/s | 71.9 steps/s
[Step=28950 Epoch=56.6] | Loss=0.01607 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.637 | L2-Norm(final)=6.541 | 4661.5 samples/s | 72.8 steps/s
[Step=29000 Epoch=56.7] | Loss=0.01596 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.642 | L2-Norm(final)=6.542 | 6049.6 samples/s | 94.5 steps/s
[Step=29050 Epoch=56.8] | Loss=0.01568 | Reg=0.00386 | acc=0.9688 | L2-Norm=19.647 | L2-Norm(final)=6.543 | 2443.9 samples/s | 38.2 steps/s
[Step=29100 Epoch=56.9] | Loss=0.01536 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.651 | L2-Norm(final)=6.545 | 4541.9 samples/s | 71.0 steps/s
[Step=29150 Epoch=57.0] | Loss=0.01511 | Reg=0.00386 | acc=1.0000 | L2-Norm=19.655 | L2-Norm(final)=6.547 | 4611.9 samples/s | 72.1 steps/s
[Step=29200 Epoch=57.1] | Loss=0.01485 | Reg=0.00386 | acc=0.9844 | L2-Norm=19.659 | L2-Norm(final)=6.548 | 4709.4 samples/s | 73.6 steps/s
[Step=29250 Epoch=57.2] | Loss=0.01487 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.662 | L2-Norm(final)=6.549 | 4532.2 samples/s | 70.8 steps/s
[Step=29300 Epoch=57.3] | Loss=0.01464 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.665 | L2-Norm(final)=6.550 | 4643.0 samples/s | 72.5 steps/s
[Step=29350 Epoch=57.4] | Loss=0.01455 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.668 | L2-Norm(final)=6.551 | 4699.4 samples/s | 73.4 steps/s
[Step=29400 Epoch=57.5] | Loss=0.01448 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.671 | L2-Norm(final)=6.552 | 4560.4 samples/s | 71.3 steps/s
[Step=29450 Epoch=57.6] | Loss=0.01436 | Reg=0.00387 | acc=0.9531 | L2-Norm=19.673 | L2-Norm(final)=6.553 | 4664.2 samples/s | 72.9 steps/s
[Step=29500 Epoch=57.7] | Loss=0.01437 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.675 | L2-Norm(final)=6.554 | 5069.4 samples/s | 79.2 steps/s
[Step=29550 Epoch=57.8] | Loss=0.01420 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.678 | L2-Norm(final)=6.555 | 2664.0 samples/s | 41.6 steps/s
[Step=29600 Epoch=57.9] | Loss=0.01395 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.680 | L2-Norm(final)=6.556 | 4532.7 samples/s | 70.8 steps/s
[Step=29650 Epoch=58.0] | Loss=0.01366 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.681 | L2-Norm(final)=6.558 | 4626.4 samples/s | 72.3 steps/s
[Step=29700 Epoch=58.1] | Loss=0.01351 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.682 | L2-Norm(final)=6.559 | 4660.7 samples/s | 72.8 steps/s
[Step=29750 Epoch=58.2] | Loss=0.01332 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.683 | L2-Norm(final)=6.561 | 4553.8 samples/s | 71.2 steps/s
[Step=29800 Epoch=58.3] | Loss=0.01319 | Reg=0.00387 | acc=0.9844 | L2-Norm=19.683 | L2-Norm(final)=6.563 | 4607.0 samples/s | 72.0 steps/s
[Step=29850 Epoch=58.4] | Loss=0.01308 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.684 | L2-Norm(final)=6.564 | 4688.0 samples/s | 73.2 steps/s
[Step=29900 Epoch=58.5] | Loss=0.01297 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.684 | L2-Norm(final)=6.565 | 4606.4 samples/s | 72.0 steps/s
[Step=29950 Epoch=58.6] | Loss=0.01286 | Reg=0.00387 | acc=0.9688 | L2-Norm=19.683 | L2-Norm(final)=6.567 | 4612.3 samples/s | 72.1 steps/s
[Step=30000 Epoch=58.6] | Loss=0.01274 | Reg=0.00387 | acc=1.0000 | L2-Norm=19.683 | L2-Norm(final)=6.568 | 4646.6 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step30000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=107.3] | Loss=0.00050 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.740 | L2-Norm(final)=5.542 | 6628.7 samples/s | 103.6 steps/s
[Step=28050 Epoch=107.5] | Loss=0.00040 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.773 | L2-Norm(final)=5.550 | 4152.2 samples/s | 64.9 steps/s
[Step=28100 Epoch=107.7] | Loss=0.00026 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.788 | L2-Norm(final)=5.555 | 4963.8 samples/s | 77.6 steps/s
[Step=28150 Epoch=107.9] | Loss=0.00021 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.789 | L2-Norm(final)=5.559 | 4862.9 samples/s | 76.0 steps/s
[Step=28200 Epoch=108.1] | Loss=0.00019 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.787 | L2-Norm(final)=5.562 | 4927.3 samples/s | 77.0 steps/s
[Step=28250 Epoch=108.2] | Loss=0.00017 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.785 | L2-Norm(final)=5.566 | 6712.4 samples/s | 104.9 steps/s
[Step=28300 Epoch=108.4] | Loss=0.00017 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.783 | L2-Norm(final)=5.570 | 2526.2 samples/s | 39.5 steps/s
[Step=28350 Epoch=108.6] | Loss=0.00015 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.782 | L2-Norm(final)=5.573 | 4671.7 samples/s | 73.0 steps/s
[Step=28400 Epoch=108.8] | Loss=0.00014 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.780 | L2-Norm(final)=5.576 | 4897.6 samples/s | 76.5 steps/s
[Step=28450 Epoch=109.0] | Loss=0.00013 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.778 | L2-Norm(final)=5.579 | 4917.7 samples/s | 76.8 steps/s
[Step=28500 Epoch=109.2] | Loss=0.00012 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.775 | L2-Norm(final)=5.582 | 5641.5 samples/s | 88.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=109.2] | Loss=0.00003 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.748 | L2-Norm(final)=5.611 | 6018.2 samples/s | 94.0 steps/s
[Step=28550 Epoch=109.4] | Loss=0.00005 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.741 | L2-Norm(final)=5.613 | 4086.2 samples/s | 63.8 steps/s
[Step=28600 Epoch=109.6] | Loss=0.00004 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.734 | L2-Norm(final)=5.616 | 4308.2 samples/s | 67.3 steps/s
[Step=28650 Epoch=109.8] | Loss=0.00003 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.725 | L2-Norm(final)=5.618 | 4405.8 samples/s | 68.8 steps/s
[Step=28700 Epoch=110.0] | Loss=0.00003 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.716 | L2-Norm(final)=5.620 | 4402.6 samples/s | 68.8 steps/s
[Step=28750 Epoch=110.2] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.707 | L2-Norm(final)=5.621 | 5861.2 samples/s | 91.6 steps/s
[Step=28800 Epoch=110.4] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.698 | L2-Norm(final)=5.623 | 2332.2 samples/s | 36.4 steps/s
[Step=28850 Epoch=110.5] | Loss=0.00003 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.689 | L2-Norm(final)=5.625 | 4430.1 samples/s | 69.2 steps/s
[Step=28900 Epoch=110.7] | Loss=0.00002 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.680 | L2-Norm(final)=5.627 | 4371.8 samples/s | 68.3 steps/s
[Step=28950 Epoch=110.9] | Loss=0.00002 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.671 | L2-Norm(final)=5.628 | 4428.8 samples/s | 69.2 steps/s
[Step=29000 Epoch=111.1] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.662 | L2-Norm(final)=5.630 | 4855.7 samples/s | 75.9 steps/s
[Step=29050 Epoch=111.3] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.652 | L2-Norm(final)=5.632 | 2517.1 samples/s | 39.3 steps/s
[Step=29100 Epoch=111.5] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.643 | L2-Norm(final)=5.633 | 4387.7 samples/s | 68.6 steps/s
[Step=29150 Epoch=111.7] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.633 | L2-Norm(final)=5.635 | 4382.6 samples/s | 68.5 steps/s
[Step=29200 Epoch=111.9] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.624 | L2-Norm(final)=5.636 | 4384.9 samples/s | 68.5 steps/s
[Step=29250 Epoch=112.1] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.614 | L2-Norm(final)=5.638 | 4441.2 samples/s | 69.4 steps/s
[Step=29300 Epoch=112.3] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.604 | L2-Norm(final)=5.639 | 2636.6 samples/s | 41.2 steps/s
[Step=29350 Epoch=112.5] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.595 | L2-Norm(final)=5.640 | 4414.6 samples/s | 69.0 steps/s
[Step=29400 Epoch=112.7] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.585 | L2-Norm(final)=5.642 | 4436.6 samples/s | 69.3 steps/s
[Step=29450 Epoch=112.8] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.575 | L2-Norm(final)=5.643 | 4431.6 samples/s | 69.2 steps/s
[Step=29500 Epoch=113.0] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.565 | L2-Norm(final)=5.645 | 4358.0 samples/s | 68.1 steps/s
[Step=29550 Epoch=113.2] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.555 | L2-Norm(final)=5.646 | 2689.5 samples/s | 42.0 steps/s
[Step=29600 Epoch=113.4] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.545 | L2-Norm(final)=5.647 | 4361.0 samples/s | 68.1 steps/s
[Step=29650 Epoch=113.6] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.535 | L2-Norm(final)=5.649 | 4347.2 samples/s | 67.9 steps/s
[Step=29700 Epoch=113.8] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.525 | L2-Norm(final)=5.650 | 4385.0 samples/s | 68.5 steps/s
[Step=29750 Epoch=114.0] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.515 | L2-Norm(final)=5.652 | 4421.0 samples/s | 69.1 steps/s
[Step=29800 Epoch=114.2] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.504 | L2-Norm(final)=5.653 | 6395.4 samples/s | 99.9 steps/s
[Step=29850 Epoch=114.4] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.494 | L2-Norm(final)=5.654 | 2237.6 samples/s | 35.0 steps/s
[Step=29900 Epoch=114.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.483 | L2-Norm(final)=5.656 | 4412.6 samples/s | 68.9 steps/s
[Step=29950 Epoch=114.8] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.473 | L2-Norm(final)=5.657 | 4405.7 samples/s | 68.8 steps/s
[Step=30000 Epoch=114.9] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.462 | L2-Norm(final)=5.659 | 4395.0 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step30000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=107.8] | Loss=0.00203 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.802 | L2-Norm(final)=5.712 | 5587.2 samples/s | 87.3 steps/s
[Step=28050 Epoch=108.0] | Loss=0.00022 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.824 | L2-Norm(final)=5.719 | 4158.8 samples/s | 65.0 steps/s
[Step=28100 Epoch=108.2] | Loss=0.00031 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.831 | L2-Norm(final)=5.722 | 4880.4 samples/s | 76.3 steps/s
[Step=28150 Epoch=108.4] | Loss=0.00024 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.840 | L2-Norm(final)=5.725 | 4906.9 samples/s | 76.7 steps/s
[Step=28200 Epoch=108.6] | Loss=0.00024 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.844 | L2-Norm(final)=5.729 | 4873.6 samples/s | 76.1 steps/s
[Step=28250 Epoch=108.7] | Loss=0.00021 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.848 | L2-Norm(final)=5.734 | 6929.8 samples/s | 108.3 steps/s
[Step=28300 Epoch=108.9] | Loss=0.00018 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.849 | L2-Norm(final)=5.739 | 2447.1 samples/s | 38.2 steps/s
[Step=28350 Epoch=109.1] | Loss=0.00016 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.849 | L2-Norm(final)=5.743 | 4840.5 samples/s | 75.6 steps/s
[Step=28400 Epoch=109.3] | Loss=0.00015 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.848 | L2-Norm(final)=5.747 | 4967.6 samples/s | 77.6 steps/s
[Step=28450 Epoch=109.5] | Loss=0.00013 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.846 | L2-Norm(final)=5.751 | 4996.7 samples/s | 78.1 steps/s
[Step=28500 Epoch=109.7] | Loss=0.00012 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.843 | L2-Norm(final)=5.754 | 5696.4 samples/s | 89.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=109.7] | Loss=0.00001 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.815 | L2-Norm(final)=5.788 | 5969.0 samples/s | 93.3 steps/s
[Step=28550 Epoch=109.9] | Loss=0.00002 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.807 | L2-Norm(final)=5.791 | 4081.5 samples/s | 63.8 steps/s
[Step=28600 Epoch=110.1] | Loss=0.00002 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.797 | L2-Norm(final)=5.793 | 4421.7 samples/s | 69.1 steps/s
[Step=28650 Epoch=110.3] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.787 | L2-Norm(final)=5.794 | 4327.6 samples/s | 67.6 steps/s
[Step=28700 Epoch=110.5] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.777 | L2-Norm(final)=5.796 | 4389.2 samples/s | 68.6 steps/s
[Step=28750 Epoch=110.7] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.767 | L2-Norm(final)=5.799 | 5914.6 samples/s | 92.4 steps/s
[Step=28800 Epoch=110.9] | Loss=0.00002 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.757 | L2-Norm(final)=5.800 | 2350.7 samples/s | 36.7 steps/s
[Step=28850 Epoch=111.1] | Loss=0.00002 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.746 | L2-Norm(final)=5.802 | 4230.3 samples/s | 66.1 steps/s
[Step=28900 Epoch=111.2] | Loss=0.00002 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.736 | L2-Norm(final)=5.804 | 4396.0 samples/s | 68.7 steps/s
[Step=28950 Epoch=111.4] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.726 | L2-Norm(final)=5.805 | 4490.2 samples/s | 70.2 steps/s
[Step=29000 Epoch=111.6] | Loss=0.00001 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.715 | L2-Norm(final)=5.806 | 4999.7 samples/s | 78.1 steps/s
[Step=29050 Epoch=111.8] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.705 | L2-Norm(final)=5.808 | 2478.3 samples/s | 38.7 steps/s
[Step=29100 Epoch=112.0] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.694 | L2-Norm(final)=5.809 | 4367.0 samples/s | 68.2 steps/s
[Step=29150 Epoch=112.2] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.684 | L2-Norm(final)=5.810 | 4396.3 samples/s | 68.7 steps/s
[Step=29200 Epoch=112.4] | Loss=0.00001 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.673 | L2-Norm(final)=5.811 | 4385.4 samples/s | 68.5 steps/s
[Step=29250 Epoch=112.6] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.662 | L2-Norm(final)=5.812 | 4471.8 samples/s | 69.9 steps/s
[Step=29300 Epoch=112.8] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.652 | L2-Norm(final)=5.813 | 2656.3 samples/s | 41.5 steps/s
[Step=29350 Epoch=113.0] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.641 | L2-Norm(final)=5.814 | 4332.4 samples/s | 67.7 steps/s
[Step=29400 Epoch=113.2] | Loss=0.00001 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.630 | L2-Norm(final)=5.816 | 4402.8 samples/s | 68.8 steps/s
[Step=29450 Epoch=113.4] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.619 | L2-Norm(final)=5.817 | 4421.9 samples/s | 69.1 steps/s
[Step=29500 Epoch=113.6] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.609 | L2-Norm(final)=5.818 | 4357.8 samples/s | 68.1 steps/s
[Step=29550 Epoch=113.7] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.598 | L2-Norm(final)=5.819 | 2680.5 samples/s | 41.9 steps/s
[Step=29600 Epoch=113.9] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.587 | L2-Norm(final)=5.820 | 4397.6 samples/s | 68.7 steps/s
[Step=29650 Epoch=114.1] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.821 | 4352.5 samples/s | 68.0 steps/s
[Step=29700 Epoch=114.3] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.565 | L2-Norm(final)=5.822 | 4484.1 samples/s | 70.1 steps/s
[Step=29750 Epoch=114.5] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=5.824 | 4283.4 samples/s | 66.9 steps/s
[Step=29800 Epoch=114.7] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.542 | L2-Norm(final)=5.825 | 7195.8 samples/s | 112.4 steps/s
[Step=29850 Epoch=114.9] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.531 | L2-Norm(final)=5.826 | 2203.2 samples/s | 34.4 steps/s
[Step=29900 Epoch=115.1] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.520 | L2-Norm(final)=5.827 | 4268.0 samples/s | 66.7 steps/s
[Step=29950 Epoch=115.3] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.508 | L2-Norm(final)=5.828 | 4412.2 samples/s | 68.9 steps/s
[Step=30000 Epoch=115.5] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.497 | L2-Norm(final)=5.830 | 4340.1 samples/s | 67.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07300 | acc=0.9664 | tpr=0.9731 | fpr=0.0481 | 5357.0 samples/s | 20.9 steps/s
Avg test loss: 0.07467, Avg test acc: 0.96538, Avg tpr: 0.97301, Avg fpr: 0.05140, total FA: 401

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07609 | acc=0.9657 | tpr=0.9699 | fpr=0.0434 | 5084.1 samples/s | 19.9 steps/s
Avg test loss: 0.07901, Avg test acc: 0.96418, Avg tpr: 0.96888, Avg fpr: 0.04615, total FA: 360

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.22520 | acc=0.3124 | tpr=0.0088 | fpr=0.0282 | 5373.8 samples/s | 21.0 steps/s
Avg test loss: 5.23480, Avg test acc: 0.30964, Avg tpr: 0.00851, Avg fpr: 0.02807, total FA: 219

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.48423 | acc=0.3030 | tpr=0.0096 | fpr=0.0597 | 5279.5 samples/s | 20.6 steps/s
Avg test loss: 5.49326, Avg test acc: 0.30143, Avg tpr: 0.00944, Avg fpr: 0.05640, total FA: 440

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.97570 | acc=0.1095 | tpr=0.6283 | fpr=0.8999 | 5317.4 samples/s | 20.8 steps/s
[Step= 100] | Loss=5.95098 | acc=0.1084 | tpr=0.5885 | fpr=0.9006 | 7241.2 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.95014 | acc=0.1091 | tpr=0.6023 | fpr=0.8999 | 7707.0 samples/s | 30.1 steps/s
[Step= 200] | Loss=5.96737 | acc=0.1083 | tpr=0.6055 | fpr=0.9007 | 8087.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=5.97054 | acc=0.1088 | tpr=0.6017 | fpr=0.9002 | 8105.2 samples/s | 31.7 steps/s
[Step= 300] | Loss=5.96511 | acc=0.1088 | tpr=0.6065 | fpr=0.9002 | 8214.3 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.95211 | acc=0.1091 | tpr=0.6030 | fpr=0.8999 | 7735.6 samples/s | 30.2 steps/s
[Step= 400] | Loss=5.94640 | acc=0.1096 | tpr=0.6078 | fpr=0.8995 | 8161.8 samples/s | 31.9 steps/s
[Step= 450] | Loss=5.94769 | acc=0.1089 | tpr=0.6052 | fpr=0.9001 | 8165.3 samples/s | 31.9 steps/s
[Step= 500] | Loss=5.94938 | acc=0.1089 | tpr=0.6048 | fpr=0.9001 | 8023.9 samples/s | 31.3 steps/s
[Step= 550] | Loss=5.95029 | acc=0.1090 | tpr=0.6029 | fpr=0.8999 | 14936.7 samples/s | 58.3 steps/s
Avg test loss: 5.95167, Avg test acc: 0.10897, Avg tpr: 0.60261, Avg fpr: 0.90000, total FA: 124963

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.59072 | acc=0.1127 | tpr=0.7699 | fpr=0.8992 | 5177.4 samples/s | 20.2 steps/s
[Step= 100] | Loss=6.55192 | acc=0.1138 | tpr=0.7697 | fpr=0.8984 | 7343.7 samples/s | 28.7 steps/s
[Step= 150] | Loss=6.55782 | acc=0.1145 | tpr=0.7795 | fpr=0.8978 | 8114.7 samples/s | 31.7 steps/s
[Step= 200] | Loss=6.56979 | acc=0.1136 | tpr=0.7672 | fpr=0.8983 | 8025.6 samples/s | 31.4 steps/s
[Step= 250] | Loss=6.57532 | acc=0.1143 | tpr=0.7607 | fpr=0.8974 | 8029.5 samples/s | 31.4 steps/s
[Step= 300] | Loss=6.57986 | acc=0.1141 | tpr=0.7629 | fpr=0.8977 | 8250.0 samples/s | 32.2 steps/s
[Step= 350] | Loss=6.56817 | acc=0.1144 | tpr=0.7614 | fpr=0.8973 | 8153.9 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.56043 | acc=0.1149 | tpr=0.7609 | fpr=0.8969 | 7793.4 samples/s | 30.4 steps/s
[Step= 450] | Loss=6.56340 | acc=0.1142 | tpr=0.7585 | fpr=0.8975 | 8327.2 samples/s | 32.5 steps/s
[Step= 500] | Loss=6.56696 | acc=0.1140 | tpr=0.7595 | fpr=0.8976 | 8045.6 samples/s | 31.4 steps/s
[Step= 550] | Loss=6.56443 | acc=0.1141 | tpr=0.7541 | fpr=0.8975 | 15026.9 samples/s | 58.7 steps/s
Avg test loss: 6.56472, Avg test acc: 0.11405, Avg tpr: 0.75357, Avg fpr: 0.89757, total FA: 124626

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15238 | acc=0.9770 | tpr=0.9558 | fpr=0.0227 | 5196.3 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.15659 | acc=0.9771 | tpr=0.9574 | fpr=0.0226 | 7321.5 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.16328 | acc=0.9760 | tpr=0.9553 | fpr=0.0236 | 8209.8 samples/s | 32.1 steps/s
[Step= 200] | Loss=0.16722 | acc=0.9761 | tpr=0.9563 | fpr=0.0235 | 7845.0 samples/s | 30.6 steps/s
[Step= 250] | Loss=0.16440 | acc=0.9766 | tpr=0.9555 | fpr=0.0230 | 7717.2 samples/s | 30.1 steps/s
[Step= 300] | Loss=0.16757 | acc=0.9763 | tpr=0.9527 | fpr=0.0233 | 8496.7 samples/s | 33.2 steps/s
[Step= 350] | Loss=0.16903 | acc=0.9760 | tpr=0.9530 | fpr=0.0236 | 7945.3 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.17134 | acc=0.9758 | tpr=0.9508 | fpr=0.0237 | 8259.4 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.17495 | acc=0.9754 | tpr=0.9499 | fpr=0.0241 | 8349.7 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.17439 | acc=0.9755 | tpr=0.9507 | fpr=0.0241 | 7618.4 samples/s | 29.8 steps/s
[Step= 550] | Loss=0.17320 | acc=0.9756 | tpr=0.9503 | fpr=0.0239 | 15755.0 samples/s | 61.5 steps/s
Avg test loss: 0.17280, Avg test acc: 0.97562, Avg tpr: 0.94929, Avg fpr: 0.02390, total FA: 3319

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.17877 | acc=0.9774 | tpr=0.9513 | fpr=0.0221 | 5244.0 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.18354 | acc=0.9764 | tpr=0.9510 | fpr=0.0231 | 7546.4 samples/s | 29.5 steps/s
[Step= 150] | Loss=0.19052 | acc=0.9754 | tpr=0.9568 | fpr=0.0242 | 7967.6 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.19560 | acc=0.9752 | tpr=0.9628 | fpr=0.0246 | 7749.2 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.19195 | acc=0.9756 | tpr=0.9616 | fpr=0.0242 | 8177.2 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.19640 | acc=0.9750 | tpr=0.9585 | fpr=0.0247 | 8026.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.19793 | acc=0.9748 | tpr=0.9599 | fpr=0.0249 | 8280.1 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.19987 | acc=0.9746 | tpr=0.9579 | fpr=0.0251 | 8089.5 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.20352 | acc=0.9743 | tpr=0.9572 | fpr=0.0254 | 8251.9 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.20268 | acc=0.9744 | tpr=0.9586 | fpr=0.0253 | 8139.7 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.20141 | acc=0.9745 | tpr=0.9566 | fpr=0.0252 | 14787.6 samples/s | 57.8 steps/s
Avg test loss: 0.20091, Avg test acc: 0.97454, Avg tpr: 0.95602, Avg fpr: 0.02513, total FA: 3489

server round 15/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=58.5] | Loss=0.00081 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.857 | L2-Norm(final)=6.417 | 6559.0 samples/s | 102.5 steps/s
[Step=30050 Epoch=58.6] | Loss=0.00763 | Reg=0.00356 | acc=0.9844 | L2-Norm=18.856 | L2-Norm(final)=6.425 | 4542.3 samples/s | 71.0 steps/s
[Step=30100 Epoch=58.7] | Loss=0.00783 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.853 | L2-Norm(final)=6.434 | 5180.9 samples/s | 81.0 steps/s
[Step=30150 Epoch=58.8] | Loss=0.00765 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.850 | L2-Norm(final)=6.443 | 5156.0 samples/s | 80.6 steps/s
[Step=30200 Epoch=58.9] | Loss=0.00761 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.847 | L2-Norm(final)=6.452 | 5326.0 samples/s | 83.2 steps/s
[Step=30250 Epoch=59.0] | Loss=0.00765 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.845 | L2-Norm(final)=6.459 | 5054.0 samples/s | 79.0 steps/s
[Step=30300 Epoch=59.1] | Loss=0.00788 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.842 | L2-Norm(final)=6.466 | 5240.8 samples/s | 81.9 steps/s
[Step=30350 Epoch=59.2] | Loss=0.00783 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.840 | L2-Norm(final)=6.472 | 5310.4 samples/s | 83.0 steps/s
[Step=30400 Epoch=59.3] | Loss=0.00765 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.838 | L2-Norm(final)=6.479 | 5107.5 samples/s | 79.8 steps/s
[Step=30450 Epoch=59.4] | Loss=0.00758 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.836 | L2-Norm(final)=6.485 | 5299.8 samples/s | 82.8 steps/s
[Step=30500 Epoch=59.5] | Loss=0.00761 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.834 | L2-Norm(final)=6.492 | 6867.8 samples/s | 107.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=59.5] | Loss=0.00484 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.813 | L2-Norm(final)=6.557 | 6619.8 samples/s | 103.4 steps/s
[Step=30550 Epoch=59.6] | Loss=0.00786 | Reg=0.00354 | acc=0.9688 | L2-Norm=18.812 | L2-Norm(final)=6.562 | 4057.2 samples/s | 63.4 steps/s
[Step=30600 Epoch=59.7] | Loss=0.01137 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.813 | L2-Norm(final)=6.563 | 4643.9 samples/s | 72.6 steps/s
[Step=30650 Epoch=59.8] | Loss=0.01186 | Reg=0.00354 | acc=0.9688 | L2-Norm=18.819 | L2-Norm(final)=6.562 | 4568.1 samples/s | 71.4 steps/s
[Step=30700 Epoch=59.9] | Loss=0.01385 | Reg=0.00354 | acc=1.0000 | L2-Norm=18.826 | L2-Norm(final)=6.562 | 4680.0 samples/s | 73.1 steps/s
[Step=30750 Epoch=60.0] | Loss=0.01394 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.835 | L2-Norm(final)=6.563 | 4558.7 samples/s | 71.2 steps/s
[Step=30800 Epoch=60.1] | Loss=0.01340 | Reg=0.00355 | acc=0.9688 | L2-Norm=18.843 | L2-Norm(final)=6.566 | 4656.3 samples/s | 72.8 steps/s
[Step=30850 Epoch=60.2] | Loss=0.01363 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.850 | L2-Norm(final)=6.569 | 4598.6 samples/s | 71.9 steps/s
[Step=30900 Epoch=60.3] | Loss=0.01399 | Reg=0.00356 | acc=0.9844 | L2-Norm=18.857 | L2-Norm(final)=6.571 | 4655.2 samples/s | 72.7 steps/s
[Step=30950 Epoch=60.4] | Loss=0.01438 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.865 | L2-Norm(final)=6.573 | 4599.9 samples/s | 71.9 steps/s
[Step=31000 Epoch=60.5] | Loss=0.01412 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.871 | L2-Norm(final)=6.575 | 5945.3 samples/s | 92.9 steps/s
[Step=31050 Epoch=60.6] | Loss=0.01385 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.877 | L2-Norm(final)=6.577 | 2449.4 samples/s | 38.3 steps/s
[Step=31100 Epoch=60.7] | Loss=0.01375 | Reg=0.00357 | acc=0.9844 | L2-Norm=18.882 | L2-Norm(final)=6.579 | 4595.5 samples/s | 71.8 steps/s
[Step=31150 Epoch=60.8] | Loss=0.01373 | Reg=0.00357 | acc=0.9688 | L2-Norm=18.887 | L2-Norm(final)=6.581 | 4666.8 samples/s | 72.9 steps/s
[Step=31200 Epoch=60.9] | Loss=0.01359 | Reg=0.00357 | acc=0.9844 | L2-Norm=18.892 | L2-Norm(final)=6.582 | 4663.1 samples/s | 72.9 steps/s
[Step=31250 Epoch=60.9] | Loss=0.01366 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.897 | L2-Norm(final)=6.584 | 4524.0 samples/s | 70.7 steps/s
[Step=31300 Epoch=61.0] | Loss=0.01345 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.901 | L2-Norm(final)=6.585 | 4678.6 samples/s | 73.1 steps/s
[Step=31350 Epoch=61.1] | Loss=0.01342 | Reg=0.00357 | acc=0.9688 | L2-Norm=18.905 | L2-Norm(final)=6.586 | 4572.5 samples/s | 71.4 steps/s
[Step=31400 Epoch=61.2] | Loss=0.01330 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.908 | L2-Norm(final)=6.587 | 4721.7 samples/s | 73.8 steps/s
[Step=31450 Epoch=61.3] | Loss=0.01317 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.911 | L2-Norm(final)=6.589 | 4559.4 samples/s | 71.2 steps/s
[Step=31500 Epoch=61.4] | Loss=0.01342 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.914 | L2-Norm(final)=6.590 | 4977.2 samples/s | 77.8 steps/s
[Step=31550 Epoch=61.5] | Loss=0.01338 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.917 | L2-Norm(final)=6.591 | 2672.5 samples/s | 41.8 steps/s
[Step=31600 Epoch=61.6] | Loss=0.01335 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.921 | L2-Norm(final)=6.592 | 4621.2 samples/s | 72.2 steps/s
[Step=31650 Epoch=61.7] | Loss=0.01318 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.924 | L2-Norm(final)=6.593 | 4569.4 samples/s | 71.4 steps/s
[Step=31700 Epoch=61.8] | Loss=0.01323 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.926 | L2-Norm(final)=6.595 | 4682.4 samples/s | 73.2 steps/s
[Step=31750 Epoch=61.9] | Loss=0.01312 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.929 | L2-Norm(final)=6.596 | 4570.3 samples/s | 71.4 steps/s
[Step=31800 Epoch=62.0] | Loss=0.01307 | Reg=0.00358 | acc=0.9688 | L2-Norm=18.931 | L2-Norm(final)=6.597 | 4647.8 samples/s | 72.6 steps/s
[Step=31850 Epoch=62.1] | Loss=0.01290 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.934 | L2-Norm(final)=6.598 | 4618.6 samples/s | 72.2 steps/s
[Step=31900 Epoch=62.2] | Loss=0.01274 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.936 | L2-Norm(final)=6.600 | 4655.2 samples/s | 72.7 steps/s
[Step=31950 Epoch=62.3] | Loss=0.01275 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.938 | L2-Norm(final)=6.601 | 4649.1 samples/s | 72.6 steps/s
[Step=32000 Epoch=62.4] | Loss=0.01267 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.939 | L2-Norm(final)=6.602 | 4673.0 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step32000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=58.7] | Loss=0.00517 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.381 | L2-Norm(final)=6.612 | 6557.9 samples/s | 102.5 steps/s
[Step=30050 Epoch=58.7] | Loss=0.00837 | Reg=0.00376 | acc=1.0000 | L2-Norm=19.379 | L2-Norm(final)=6.625 | 4727.4 samples/s | 73.9 steps/s
[Step=30100 Epoch=58.8] | Loss=0.00713 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.375 | L2-Norm(final)=6.636 | 5136.6 samples/s | 80.3 steps/s
[Step=30150 Epoch=58.9] | Loss=0.00692 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.372 | L2-Norm(final)=6.647 | 5171.9 samples/s | 80.8 steps/s
[Step=30200 Epoch=59.0] | Loss=0.00738 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.369 | L2-Norm(final)=6.658 | 5208.7 samples/s | 81.4 steps/s
[Step=30250 Epoch=59.1] | Loss=0.00726 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.367 | L2-Norm(final)=6.666 | 5195.8 samples/s | 81.2 steps/s
[Step=30300 Epoch=59.2] | Loss=0.00697 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.365 | L2-Norm(final)=6.675 | 5378.0 samples/s | 84.0 steps/s
[Step=30350 Epoch=59.3] | Loss=0.00719 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.364 | L2-Norm(final)=6.683 | 5027.2 samples/s | 78.5 steps/s
[Step=30400 Epoch=59.4] | Loss=0.00742 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.362 | L2-Norm(final)=6.691 | 5398.6 samples/s | 84.4 steps/s
[Step=30450 Epoch=59.5] | Loss=0.00749 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.361 | L2-Norm(final)=6.699 | 5069.3 samples/s | 79.2 steps/s
[Step=30500 Epoch=59.6] | Loss=0.00754 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.360 | L2-Norm(final)=6.706 | 7083.9 samples/s | 110.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=59.6] | Loss=0.00578 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.349 | L2-Norm(final)=6.783 | 6810.8 samples/s | 106.4 steps/s
[Step=30550 Epoch=59.7] | Loss=0.01017 | Reg=0.00374 | acc=1.0000 | L2-Norm=19.347 | L2-Norm(final)=6.788 | 4026.1 samples/s | 62.9 steps/s
[Step=30600 Epoch=59.8] | Loss=0.01240 | Reg=0.00375 | acc=0.9844 | L2-Norm=19.353 | L2-Norm(final)=6.787 | 4598.2 samples/s | 71.8 steps/s
[Step=30650 Epoch=59.9] | Loss=0.01426 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.362 | L2-Norm(final)=6.782 | 4571.0 samples/s | 71.4 steps/s
[Step=30700 Epoch=60.0] | Loss=0.01473 | Reg=0.00375 | acc=1.0000 | L2-Norm=19.373 | L2-Norm(final)=6.781 | 4619.0 samples/s | 72.2 steps/s
[Step=30750 Epoch=60.1] | Loss=0.01583 | Reg=0.00376 | acc=0.9688 | L2-Norm=19.384 | L2-Norm(final)=6.778 | 4642.0 samples/s | 72.5 steps/s
[Step=30800 Epoch=60.2] | Loss=0.01659 | Reg=0.00376 | acc=0.9531 | L2-Norm=19.396 | L2-Norm(final)=6.776 | 4622.6 samples/s | 72.2 steps/s
[Step=30850 Epoch=60.3] | Loss=0.01655 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.407 | L2-Norm(final)=6.774 | 4602.1 samples/s | 71.9 steps/s
[Step=30900 Epoch=60.4] | Loss=0.01602 | Reg=0.00377 | acc=1.0000 | L2-Norm=19.417 | L2-Norm(final)=6.772 | 4658.0 samples/s | 72.8 steps/s
[Step=30950 Epoch=60.5] | Loss=0.01621 | Reg=0.00377 | acc=0.9844 | L2-Norm=19.425 | L2-Norm(final)=6.771 | 4603.2 samples/s | 71.9 steps/s
[Step=31000 Epoch=60.6] | Loss=0.01641 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.434 | L2-Norm(final)=6.770 | 6057.2 samples/s | 94.6 steps/s
[Step=31050 Epoch=60.7] | Loss=0.01652 | Reg=0.00378 | acc=1.0000 | L2-Norm=19.441 | L2-Norm(final)=6.768 | 2417.5 samples/s | 37.8 steps/s
[Step=31100 Epoch=60.8] | Loss=0.01627 | Reg=0.00378 | acc=0.9844 | L2-Norm=19.449 | L2-Norm(final)=6.768 | 4630.7 samples/s | 72.4 steps/s
[Step=31150 Epoch=60.9] | Loss=0.01620 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.456 | L2-Norm(final)=6.767 | 4603.3 samples/s | 71.9 steps/s
[Step=31200 Epoch=61.0] | Loss=0.01597 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.462 | L2-Norm(final)=6.766 | 4680.3 samples/s | 73.1 steps/s
[Step=31250 Epoch=61.1] | Loss=0.01580 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.468 | L2-Norm(final)=6.765 | 4642.1 samples/s | 72.5 steps/s
[Step=31300 Epoch=61.2] | Loss=0.01547 | Reg=0.00379 | acc=0.9844 | L2-Norm=19.473 | L2-Norm(final)=6.765 | 4566.5 samples/s | 71.4 steps/s
[Step=31350 Epoch=61.3] | Loss=0.01538 | Reg=0.00379 | acc=1.0000 | L2-Norm=19.477 | L2-Norm(final)=6.764 | 4614.0 samples/s | 72.1 steps/s
[Step=31400 Epoch=61.4] | Loss=0.01516 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.481 | L2-Norm(final)=6.764 | 4635.9 samples/s | 72.4 steps/s
[Step=31450 Epoch=61.5] | Loss=0.01508 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.485 | L2-Norm(final)=6.764 | 4709.2 samples/s | 73.6 steps/s
[Step=31500 Epoch=61.6] | Loss=0.01489 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.488 | L2-Norm(final)=6.764 | 5055.4 samples/s | 79.0 steps/s
[Step=31550 Epoch=61.7] | Loss=0.01457 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.491 | L2-Norm(final)=6.765 | 2666.0 samples/s | 41.7 steps/s
[Step=31600 Epoch=61.8] | Loss=0.01441 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.493 | L2-Norm(final)=6.765 | 4535.0 samples/s | 70.9 steps/s
[Step=31650 Epoch=61.9] | Loss=0.01413 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.495 | L2-Norm(final)=6.766 | 4604.1 samples/s | 71.9 steps/s
[Step=31700 Epoch=62.0] | Loss=0.01394 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.497 | L2-Norm(final)=6.767 | 4574.0 samples/s | 71.5 steps/s
[Step=31750 Epoch=62.1] | Loss=0.01370 | Reg=0.00380 | acc=0.9688 | L2-Norm=19.498 | L2-Norm(final)=6.768 | 4649.0 samples/s | 72.6 steps/s
[Step=31800 Epoch=62.2] | Loss=0.01351 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.499 | L2-Norm(final)=6.769 | 4589.8 samples/s | 71.7 steps/s
[Step=31850 Epoch=62.3] | Loss=0.01338 | Reg=0.00380 | acc=1.0000 | L2-Norm=19.499 | L2-Norm(final)=6.770 | 4639.2 samples/s | 72.5 steps/s
[Step=31900 Epoch=62.4] | Loss=0.01328 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.499 | L2-Norm(final)=6.771 | 4613.7 samples/s | 72.1 steps/s
[Step=31950 Epoch=62.5] | Loss=0.01322 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.500 | L2-Norm(final)=6.772 | 4677.0 samples/s | 73.1 steps/s
[Step=32000 Epoch=62.6] | Loss=0.01315 | Reg=0.00380 | acc=0.9844 | L2-Norm=19.500 | L2-Norm(final)=6.773 | 4625.3 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step32000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=115.0] | Loss=0.00004 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.446 | L2-Norm(final)=5.702 | 6505.2 samples/s | 101.6 steps/s
[Step=30050 Epoch=115.1] | Loss=0.00022 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.463 | L2-Norm(final)=5.708 | 4279.3 samples/s | 66.9 steps/s
[Step=30100 Epoch=115.3] | Loss=0.00026 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.490 | L2-Norm(final)=5.715 | 4892.1 samples/s | 76.4 steps/s
[Step=30150 Epoch=115.5] | Loss=0.00054 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.521 | L2-Norm(final)=5.720 | 4766.3 samples/s | 74.5 steps/s
[Step=30200 Epoch=115.7] | Loss=0.00042 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=5.725 | 4877.2 samples/s | 76.2 steps/s
[Step=30250 Epoch=115.9] | Loss=0.00034 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.563 | L2-Norm(final)=5.729 | 6877.7 samples/s | 107.5 steps/s
[Step=30300 Epoch=116.1] | Loss=0.00029 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.570 | L2-Norm(final)=5.733 | 2483.3 samples/s | 38.8 steps/s
[Step=30350 Epoch=116.3] | Loss=0.00025 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.573 | L2-Norm(final)=5.736 | 4843.8 samples/s | 75.7 steps/s
[Step=30400 Epoch=116.5] | Loss=0.00023 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.574 | L2-Norm(final)=5.739 | 4994.3 samples/s | 78.0 steps/s
[Step=30450 Epoch=116.7] | Loss=0.00021 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.575 | L2-Norm(final)=5.742 | 4879.7 samples/s | 76.2 steps/s
[Step=30500 Epoch=116.9] | Loss=0.00019 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.574 | L2-Norm(final)=5.745 | 5627.2 samples/s | 87.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=116.9] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.564 | L2-Norm(final)=5.773 | 6718.5 samples/s | 105.0 steps/s
[Step=30550 Epoch=117.1] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.550 | L2-Norm(final)=5.775 | 3816.3 samples/s | 59.6 steps/s
[Step=30600 Epoch=117.2] | Loss=0.00002 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.533 | L2-Norm(final)=5.777 | 4507.1 samples/s | 70.4 steps/s
[Step=30650 Epoch=117.4] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.516 | L2-Norm(final)=5.779 | 4304.3 samples/s | 67.3 steps/s
[Step=30700 Epoch=117.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.499 | L2-Norm(final)=5.780 | 4490.5 samples/s | 70.2 steps/s
[Step=30750 Epoch=117.8] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.482 | L2-Norm(final)=5.781 | 5690.5 samples/s | 88.9 steps/s
[Step=30800 Epoch=118.0] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.465 | L2-Norm(final)=5.782 | 2336.3 samples/s | 36.5 steps/s
[Step=30850 Epoch=118.2] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.447 | L2-Norm(final)=5.783 | 4426.0 samples/s | 69.2 steps/s
[Step=30900 Epoch=118.4] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.429 | L2-Norm(final)=5.784 | 4373.7 samples/s | 68.3 steps/s
[Step=30950 Epoch=118.6] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.412 | L2-Norm(final)=5.785 | 4431.2 samples/s | 69.2 steps/s
[Step=31000 Epoch=118.8] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.394 | L2-Norm(final)=5.785 | 4923.8 samples/s | 76.9 steps/s
[Step=31050 Epoch=119.0] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.376 | L2-Norm(final)=5.786 | 2510.8 samples/s | 39.2 steps/s
[Step=31100 Epoch=119.2] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.358 | L2-Norm(final)=5.787 | 4383.7 samples/s | 68.5 steps/s
[Step=31150 Epoch=119.4] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.340 | L2-Norm(final)=5.787 | 4429.3 samples/s | 69.2 steps/s
[Step=31200 Epoch=119.5] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.322 | L2-Norm(final)=5.788 | 4360.5 samples/s | 68.1 steps/s
[Step=31250 Epoch=119.7] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.303 | L2-Norm(final)=5.788 | 4439.5 samples/s | 69.4 steps/s
[Step=31300 Epoch=119.9] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.285 | L2-Norm(final)=5.789 | 2678.4 samples/s | 41.9 steps/s
[Step=31350 Epoch=120.1] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.267 | L2-Norm(final)=5.789 | 4444.6 samples/s | 69.4 steps/s
[Step=31400 Epoch=120.3] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.248 | L2-Norm(final)=5.790 | 4298.6 samples/s | 67.2 steps/s
[Step=31450 Epoch=120.5] | Loss=0.00000 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.229 | L2-Norm(final)=5.790 | 4443.1 samples/s | 69.4 steps/s
[Step=31500 Epoch=120.7] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.211 | L2-Norm(final)=5.791 | 4370.7 samples/s | 68.3 steps/s
[Step=31550 Epoch=120.9] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.192 | L2-Norm(final)=5.791 | 2678.4 samples/s | 41.8 steps/s
[Step=31600 Epoch=121.1] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.173 | L2-Norm(final)=5.792 | 4346.5 samples/s | 67.9 steps/s
[Step=31650 Epoch=121.3] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.154 | L2-Norm(final)=5.792 | 4432.7 samples/s | 69.3 steps/s
[Step=31700 Epoch=121.5] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.135 | L2-Norm(final)=5.793 | 4430.6 samples/s | 69.2 steps/s
[Step=31750 Epoch=121.7] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.116 | L2-Norm(final)=5.793 | 4301.0 samples/s | 67.2 steps/s
[Step=31800 Epoch=121.8] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.096 | L2-Norm(final)=5.794 | 6483.5 samples/s | 101.3 steps/s
[Step=31850 Epoch=122.0] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.077 | L2-Norm(final)=5.794 | 2264.5 samples/s | 35.4 steps/s
[Step=31900 Epoch=122.2] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.057 | L2-Norm(final)=5.795 | 4287.9 samples/s | 67.0 steps/s
[Step=31950 Epoch=122.4] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.038 | L2-Norm(final)=5.795 | 4424.1 samples/s | 69.1 steps/s
[Step=32000 Epoch=122.6] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.018 | L2-Norm(final)=5.796 | 4404.6 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step32000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=115.5] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.457 | L2-Norm(final)=5.867 | 6157.9 samples/s | 96.2 steps/s
[Step=30050 Epoch=115.7] | Loss=0.00012 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.489 | L2-Norm(final)=5.876 | 4374.2 samples/s | 68.3 steps/s
[Step=30100 Epoch=115.9] | Loss=0.00007 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.498 | L2-Norm(final)=5.882 | 4892.8 samples/s | 76.5 steps/s
[Step=30150 Epoch=116.1] | Loss=0.00006 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.496 | L2-Norm(final)=5.887 | 4876.5 samples/s | 76.2 steps/s
[Step=30200 Epoch=116.3] | Loss=0.00005 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.491 | L2-Norm(final)=5.891 | 4930.0 samples/s | 77.0 steps/s
[Step=30250 Epoch=116.4] | Loss=0.00006 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.491 | L2-Norm(final)=5.896 | 6872.9 samples/s | 107.4 steps/s
[Step=30300 Epoch=116.6] | Loss=0.00005 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.492 | L2-Norm(final)=5.901 | 2451.1 samples/s | 38.3 steps/s
[Step=30350 Epoch=116.8] | Loss=0.00005 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.491 | L2-Norm(final)=5.905 | 5078.2 samples/s | 79.3 steps/s
[Step=30400 Epoch=117.0] | Loss=0.00004 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.488 | L2-Norm(final)=5.909 | 4742.3 samples/s | 74.1 steps/s
[Step=30450 Epoch=117.2] | Loss=0.00004 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.484 | L2-Norm(final)=5.913 | 5134.2 samples/s | 80.2 steps/s
[Step=30500 Epoch=117.4] | Loss=0.00004 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.480 | L2-Norm(final)=5.917 | 5566.0 samples/s | 87.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=117.4] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.437 | L2-Norm(final)=5.953 | 6357.0 samples/s | 99.3 steps/s
[Step=30550 Epoch=117.6] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.422 | L2-Norm(final)=5.956 | 3921.2 samples/s | 61.3 steps/s
[Step=30600 Epoch=117.8] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.404 | L2-Norm(final)=5.958 | 4360.1 samples/s | 68.1 steps/s
[Step=30650 Epoch=118.0] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.385 | L2-Norm(final)=5.960 | 4382.5 samples/s | 68.5 steps/s
[Step=30700 Epoch=118.2] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.367 | L2-Norm(final)=5.962 | 4325.9 samples/s | 67.6 steps/s
[Step=30750 Epoch=118.4] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.349 | L2-Norm(final)=5.964 | 5989.6 samples/s | 93.6 steps/s
[Step=30800 Epoch=118.6] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.331 | L2-Norm(final)=5.966 | 2310.3 samples/s | 36.1 steps/s
[Step=30850 Epoch=118.8] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.312 | L2-Norm(final)=5.968 | 4377.7 samples/s | 68.4 steps/s
[Step=30900 Epoch=118.9] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.294 | L2-Norm(final)=5.969 | 4385.7 samples/s | 68.5 steps/s
[Step=30950 Epoch=119.1] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.275 | L2-Norm(final)=5.971 | 4384.2 samples/s | 68.5 steps/s
[Step=31000 Epoch=119.3] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=5.972 | 5150.9 samples/s | 80.5 steps/s
[Step=31050 Epoch=119.5] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.237 | L2-Norm(final)=5.973 | 2487.5 samples/s | 38.9 steps/s
[Step=31100 Epoch=119.7] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.219 | L2-Norm(final)=5.975 | 4462.5 samples/s | 69.7 steps/s
[Step=31150 Epoch=119.9] | Loss=0.00000 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.200 | L2-Norm(final)=5.976 | 4280.2 samples/s | 66.9 steps/s
[Step=31200 Epoch=120.1] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.181 | L2-Norm(final)=5.977 | 4341.3 samples/s | 67.8 steps/s
[Step=31250 Epoch=120.3] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.162 | L2-Norm(final)=5.978 | 4493.2 samples/s | 70.2 steps/s
[Step=31300 Epoch=120.5] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.143 | L2-Norm(final)=5.979 | 2637.5 samples/s | 41.2 steps/s
[Step=31350 Epoch=120.7] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.123 | L2-Norm(final)=5.981 | 4513.4 samples/s | 70.5 steps/s
[Step=31400 Epoch=120.9] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.104 | L2-Norm(final)=5.982 | 4237.1 samples/s | 66.2 steps/s
[Step=31450 Epoch=121.1] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.085 | L2-Norm(final)=5.983 | 4385.8 samples/s | 68.5 steps/s
[Step=31500 Epoch=121.3] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.065 | L2-Norm(final)=5.984 | 4387.1 samples/s | 68.5 steps/s
[Step=31550 Epoch=121.4] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.046 | L2-Norm(final)=5.986 | 2683.8 samples/s | 41.9 steps/s
[Step=31600 Epoch=121.6] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.026 | L2-Norm(final)=5.987 | 4460.1 samples/s | 69.7 steps/s
[Step=31650 Epoch=121.8] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.007 | L2-Norm(final)=5.988 | 4301.1 samples/s | 67.2 steps/s
[Step=31700 Epoch=122.0] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.987 | L2-Norm(final)=5.989 | 4422.0 samples/s | 69.1 steps/s
[Step=31750 Epoch=122.2] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.967 | L2-Norm(final)=5.991 | 4325.7 samples/s | 67.6 steps/s
[Step=31800 Epoch=122.4] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.947 | L2-Norm(final)=5.992 | 7172.0 samples/s | 112.1 steps/s
[Step=31850 Epoch=122.6] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.927 | L2-Norm(final)=5.994 | 2176.1 samples/s | 34.0 steps/s
[Step=31900 Epoch=122.8] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.907 | L2-Norm(final)=5.995 | 4487.4 samples/s | 70.1 steps/s
[Step=31950 Epoch=123.0] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.886 | L2-Norm(final)=5.997 | 4331.0 samples/s | 67.7 steps/s
[Step=32000 Epoch=123.2] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.866 | L2-Norm(final)=5.998 | 4327.7 samples/s | 67.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08129 | acc=0.9661 | tpr=0.9785 | fpr=0.0610 | 5401.6 samples/s | 21.1 steps/s
Avg test loss: 0.08506, Avg test acc: 0.96550, Avg tpr: 0.97774, Avg fpr: 0.06140, total FA: 479

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07982 | acc=0.9654 | tpr=0.9695 | fpr=0.0436 | 5200.1 samples/s | 20.3 steps/s
Avg test loss: 0.08279, Avg test acc: 0.96442, Avg tpr: 0.96893, Avg fpr: 0.04551, total FA: 355

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.46976 | acc=0.3084 | tpr=0.0086 | fpr=0.0404 | 5189.0 samples/s | 20.3 steps/s
Avg test loss: 5.47862, Avg test acc: 0.30708, Avg tpr: 0.00927, Avg fpr: 0.03794, total FA: 296

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.36807 | acc=0.3028 | tpr=0.0110 | fpr=0.0634 | 5240.0 samples/s | 20.5 steps/s
Avg test loss: 5.38070, Avg test acc: 0.30103, Avg tpr: 0.01055, Avg fpr: 0.06012, total FA: 469

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.52503 | acc=0.1131 | tpr=0.7743 | fpr=0.8988 | 5320.6 samples/s | 20.8 steps/s
[Step= 100] | Loss=7.48712 | acc=0.1130 | tpr=0.7377 | fpr=0.8987 | 7057.6 samples/s | 27.6 steps/s
[Step= 150] | Loss=7.48744 | acc=0.1133 | tpr=0.7493 | fpr=0.8984 | 7988.6 samples/s | 31.2 steps/s
[Step= 200] | Loss=7.50584 | acc=0.1127 | tpr=0.7508 | fpr=0.8989 | 8177.4 samples/s | 31.9 steps/s
[Step= 250] | Loss=7.51245 | acc=0.1131 | tpr=0.7415 | fpr=0.8984 | 8360.6 samples/s | 32.7 steps/s
[Step= 300] | Loss=7.51560 | acc=0.1133 | tpr=0.7491 | fpr=0.8983 | 7631.1 samples/s | 29.8 steps/s
[Step= 350] | Loss=7.50179 | acc=0.1135 | tpr=0.7520 | fpr=0.8981 | 8422.4 samples/s | 32.9 steps/s
[Step= 400] | Loss=7.49695 | acc=0.1141 | tpr=0.7577 | fpr=0.8976 | 8026.1 samples/s | 31.4 steps/s
[Step= 450] | Loss=7.49856 | acc=0.1134 | tpr=0.7571 | fpr=0.8983 | 8415.9 samples/s | 32.9 steps/s
[Step= 500] | Loss=7.50354 | acc=0.1130 | tpr=0.7577 | fpr=0.8987 | 7863.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=7.50361 | acc=0.1132 | tpr=0.7545 | fpr=0.8985 | 15201.1 samples/s | 59.4 steps/s
Avg test loss: 7.50435, Avg test acc: 0.11314, Avg tpr: 0.75475, Avg fpr: 0.89852, total FA: 124758

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.90644 | acc=0.1230 | tpr=0.7434 | fpr=0.8881 | 5217.5 samples/s | 20.4 steps/s
[Step= 100] | Loss=6.87815 | acc=0.1245 | tpr=0.7249 | fpr=0.8867 | 7118.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=6.86591 | acc=0.1262 | tpr=0.7334 | fpr=0.8850 | 8104.6 samples/s | 31.7 steps/s
[Step= 200] | Loss=6.88077 | acc=0.1248 | tpr=0.7191 | fpr=0.8860 | 7984.6 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.88058 | acc=0.1256 | tpr=0.7118 | fpr=0.8851 | 8309.7 samples/s | 32.5 steps/s
[Step= 300] | Loss=6.88486 | acc=0.1256 | tpr=0.7135 | fpr=0.8851 | 8314.9 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.87196 | acc=0.1259 | tpr=0.7132 | fpr=0.8848 | 7791.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=6.86142 | acc=0.1260 | tpr=0.7112 | fpr=0.8846 | 8381.1 samples/s | 32.7 steps/s
[Step= 450] | Loss=6.86109 | acc=0.1257 | tpr=0.7118 | fpr=0.8850 | 8505.4 samples/s | 33.2 steps/s
[Step= 500] | Loss=6.86001 | acc=0.1255 | tpr=0.7119 | fpr=0.8851 | 7948.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=6.85660 | acc=0.1256 | tpr=0.7071 | fpr=0.8850 | 14710.8 samples/s | 57.5 steps/s
Avg test loss: 6.85711, Avg test acc: 0.12552, Avg tpr: 0.70721, Avg fpr: 0.88505, total FA: 122888

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.16333 | acc=0.9768 | tpr=0.9469 | fpr=0.0227 | 5518.7 samples/s | 21.6 steps/s
[Step= 100] | Loss=0.16860 | acc=0.9768 | tpr=0.9510 | fpr=0.0228 | 7374.7 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.17467 | acc=0.9754 | tpr=0.9467 | fpr=0.0241 | 7389.8 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.17864 | acc=0.9755 | tpr=0.9508 | fpr=0.0241 | 7678.3 samples/s | 30.0 steps/s
[Step= 250] | Loss=0.17614 | acc=0.9760 | tpr=0.9502 | fpr=0.0236 | 7911.9 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.17937 | acc=0.9757 | tpr=0.9491 | fpr=0.0238 | 8690.3 samples/s | 33.9 steps/s
[Step= 350] | Loss=0.18065 | acc=0.9754 | tpr=0.9499 | fpr=0.0241 | 7887.7 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.18301 | acc=0.9752 | tpr=0.9491 | fpr=0.0244 | 7985.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.18720 | acc=0.9747 | tpr=0.9484 | fpr=0.0248 | 8234.7 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.18639 | acc=0.9748 | tpr=0.9493 | fpr=0.0247 | 8176.9 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.18515 | acc=0.9749 | tpr=0.9495 | fpr=0.0246 | 14138.8 samples/s | 55.2 steps/s
Avg test loss: 0.18468, Avg test acc: 0.97495, Avg tpr: 0.94849, Avg fpr: 0.02457, total FA: 3411

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.16937 | acc=0.9766 | tpr=0.9425 | fpr=0.0227 | 5453.0 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.17526 | acc=0.9758 | tpr=0.9446 | fpr=0.0236 | 7030.5 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.18112 | acc=0.9748 | tpr=0.9524 | fpr=0.0248 | 7422.0 samples/s | 29.0 steps/s
[Step= 200] | Loss=0.18535 | acc=0.9747 | tpr=0.9574 | fpr=0.0249 | 8474.1 samples/s | 33.1 steps/s
[Step= 250] | Loss=0.18198 | acc=0.9753 | tpr=0.9563 | fpr=0.0244 | 8226.5 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.18589 | acc=0.9749 | tpr=0.9527 | fpr=0.0247 | 8243.7 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.18737 | acc=0.9745 | tpr=0.9537 | fpr=0.0251 | 7837.7 samples/s | 30.6 steps/s
[Step= 400] | Loss=0.18916 | acc=0.9744 | tpr=0.9513 | fpr=0.0252 | 8195.3 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.19276 | acc=0.9740 | tpr=0.9513 | fpr=0.0255 | 8156.4 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.19192 | acc=0.9741 | tpr=0.9529 | fpr=0.0255 | 8336.4 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.19070 | acc=0.9742 | tpr=0.9519 | fpr=0.0253 | 14607.0 samples/s | 57.1 steps/s
Avg test loss: 0.19024, Avg test acc: 0.97425, Avg tpr: 0.95127, Avg fpr: 0.02533, total FA: 3517

server round 16/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=62.4] | Loss=0.00200 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.511 | L2-Norm(final)=6.634 | 6387.5 samples/s | 99.8 steps/s
[Step=32050 Epoch=62.5] | Loss=0.00771 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.509 | L2-Norm(final)=6.641 | 4631.3 samples/s | 72.4 steps/s
[Step=32100 Epoch=62.6] | Loss=0.00700 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.506 | L2-Norm(final)=6.649 | 5248.5 samples/s | 82.0 steps/s
[Step=32150 Epoch=62.7] | Loss=0.00672 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.503 | L2-Norm(final)=6.656 | 5359.3 samples/s | 83.7 steps/s
[Step=32200 Epoch=62.8] | Loss=0.00676 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.500 | L2-Norm(final)=6.663 | 5016.5 samples/s | 78.4 steps/s
[Step=32250 Epoch=62.9] | Loss=0.00695 | Reg=0.00342 | acc=0.9688 | L2-Norm=18.497 | L2-Norm(final)=6.669 | 5279.2 samples/s | 82.5 steps/s
[Step=32300 Epoch=63.0] | Loss=0.00714 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.495 | L2-Norm(final)=6.674 | 5121.1 samples/s | 80.0 steps/s
[Step=32350 Epoch=63.1] | Loss=0.00720 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.492 | L2-Norm(final)=6.680 | 5305.6 samples/s | 82.9 steps/s
[Step=32400 Epoch=63.2] | Loss=0.00713 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.490 | L2-Norm(final)=6.685 | 5240.1 samples/s | 81.9 steps/s
[Step=32450 Epoch=63.3] | Loss=0.00704 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.487 | L2-Norm(final)=6.691 | 5079.9 samples/s | 79.4 steps/s
[Step=32500 Epoch=63.4] | Loss=0.00686 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.485 | L2-Norm(final)=6.697 | 6921.3 samples/s | 108.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=63.4] | Loss=0.01080 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.462 | L2-Norm(final)=6.754 | 6567.2 samples/s | 102.6 steps/s
[Step=32550 Epoch=63.5] | Loss=0.00687 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.460 | L2-Norm(final)=6.758 | 4082.3 samples/s | 63.8 steps/s
[Step=32600 Epoch=63.6] | Loss=0.00815 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.459 | L2-Norm(final)=6.759 | 4615.7 samples/s | 72.1 steps/s
[Step=32650 Epoch=63.7] | Loss=0.01030 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.459 | L2-Norm(final)=6.759 | 4611.4 samples/s | 72.1 steps/s
[Step=32700 Epoch=63.8] | Loss=0.01013 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.463 | L2-Norm(final)=6.760 | 4606.4 samples/s | 72.0 steps/s
[Step=32750 Epoch=63.9] | Loss=0.01116 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.466 | L2-Norm(final)=6.762 | 4621.0 samples/s | 72.2 steps/s
[Step=32800 Epoch=64.0] | Loss=0.01180 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.471 | L2-Norm(final)=6.761 | 4656.3 samples/s | 72.8 steps/s
[Step=32850 Epoch=64.1] | Loss=0.01221 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.478 | L2-Norm(final)=6.762 | 4633.2 samples/s | 72.4 steps/s
[Step=32900 Epoch=64.2] | Loss=0.01295 | Reg=0.00342 | acc=0.9688 | L2-Norm=18.485 | L2-Norm(final)=6.762 | 4622.8 samples/s | 72.2 steps/s
[Step=32950 Epoch=64.3] | Loss=0.01311 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.491 | L2-Norm(final)=6.762 | 4635.5 samples/s | 72.4 steps/s
[Step=33000 Epoch=64.4] | Loss=0.01335 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.497 | L2-Norm(final)=6.763 | 5971.8 samples/s | 93.3 steps/s
[Step=33050 Epoch=64.5] | Loss=0.01300 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.503 | L2-Norm(final)=6.764 | 2465.8 samples/s | 38.5 steps/s
[Step=33100 Epoch=64.6] | Loss=0.01311 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.508 | L2-Norm(final)=6.766 | 4528.0 samples/s | 70.7 steps/s
[Step=33150 Epoch=64.7] | Loss=0.01296 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.513 | L2-Norm(final)=6.767 | 4618.4 samples/s | 72.2 steps/s
[Step=33200 Epoch=64.8] | Loss=0.01288 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.518 | L2-Norm(final)=6.768 | 4634.8 samples/s | 72.4 steps/s
[Step=33250 Epoch=64.9] | Loss=0.01277 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.522 | L2-Norm(final)=6.769 | 4724.0 samples/s | 73.8 steps/s
[Step=33300 Epoch=64.9] | Loss=0.01252 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.527 | L2-Norm(final)=6.770 | 4576.2 samples/s | 71.5 steps/s
[Step=33350 Epoch=65.0] | Loss=0.01257 | Reg=0.00343 | acc=1.0000 | L2-Norm=18.531 | L2-Norm(final)=6.772 | 4681.9 samples/s | 73.2 steps/s
[Step=33400 Epoch=65.1] | Loss=0.01255 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.534 | L2-Norm(final)=6.773 | 4580.9 samples/s | 71.6 steps/s
[Step=33450 Epoch=65.2] | Loss=0.01253 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.538 | L2-Norm(final)=6.775 | 4610.0 samples/s | 72.0 steps/s
[Step=33500 Epoch=65.3] | Loss=0.01246 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.541 | L2-Norm(final)=6.777 | 5009.4 samples/s | 78.3 steps/s
[Step=33550 Epoch=65.4] | Loss=0.01236 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.544 | L2-Norm(final)=6.779 | 2664.0 samples/s | 41.6 steps/s
[Step=33600 Epoch=65.5] | Loss=0.01222 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.546 | L2-Norm(final)=6.781 | 4658.6 samples/s | 72.8 steps/s
[Step=33650 Epoch=65.6] | Loss=0.01202 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.549 | L2-Norm(final)=6.783 | 4560.6 samples/s | 71.3 steps/s
[Step=33700 Epoch=65.7] | Loss=0.01186 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.551 | L2-Norm(final)=6.785 | 4644.6 samples/s | 72.6 steps/s
[Step=33750 Epoch=65.8] | Loss=0.01176 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.553 | L2-Norm(final)=6.787 | 4571.0 samples/s | 71.4 steps/s
[Step=33800 Epoch=65.9] | Loss=0.01169 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.555 | L2-Norm(final)=6.789 | 4654.3 samples/s | 72.7 steps/s
[Step=33850 Epoch=66.0] | Loss=0.01165 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.556 | L2-Norm(final)=6.791 | 4635.9 samples/s | 72.4 steps/s
[Step=33900 Epoch=66.1] | Loss=0.01167 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.558 | L2-Norm(final)=6.793 | 4615.8 samples/s | 72.1 steps/s
[Step=33950 Epoch=66.2] | Loss=0.01158 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.560 | L2-Norm(final)=6.795 | 4670.8 samples/s | 73.0 steps/s
[Step=34000 Epoch=66.3] | Loss=0.01153 | Reg=0.00345 | acc=1.0000 | L2-Norm=18.561 | L2-Norm(final)=6.796 | 4614.6 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step34000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=62.6] | Loss=0.00128 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=6.802 | 5868.0 samples/s | 91.7 steps/s
[Step=32050 Epoch=62.7] | Loss=0.00838 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.058 | L2-Norm(final)=6.808 | 5111.4 samples/s | 79.9 steps/s
[Step=32100 Epoch=62.8] | Loss=0.00773 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.058 | L2-Norm(final)=6.815 | 4989.4 samples/s | 78.0 steps/s
[Step=32150 Epoch=62.9] | Loss=0.00728 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.055 | L2-Norm(final)=6.823 | 5170.4 samples/s | 80.8 steps/s
[Step=32200 Epoch=63.0] | Loss=0.00725 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.053 | L2-Norm(final)=6.831 | 5219.5 samples/s | 81.6 steps/s
[Step=32250 Epoch=63.0] | Loss=0.00720 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.051 | L2-Norm(final)=6.838 | 5207.4 samples/s | 81.4 steps/s
[Step=32300 Epoch=63.1] | Loss=0.00680 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.048 | L2-Norm(final)=6.844 | 5217.7 samples/s | 81.5 steps/s
[Step=32350 Epoch=63.2] | Loss=0.00683 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.046 | L2-Norm(final)=6.851 | 5196.4 samples/s | 81.2 steps/s
[Step=32400 Epoch=63.3] | Loss=0.00710 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.043 | L2-Norm(final)=6.858 | 5456.8 samples/s | 85.3 steps/s
[Step=32450 Epoch=63.4] | Loss=0.00706 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.040 | L2-Norm(final)=6.864 | 4990.2 samples/s | 78.0 steps/s
[Step=32500 Epoch=63.5] | Loss=0.00701 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.037 | L2-Norm(final)=6.870 | 7113.1 samples/s | 111.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=63.5] | Loss=0.00092 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.008 | L2-Norm(final)=6.932 | 6716.1 samples/s | 104.9 steps/s
[Step=32550 Epoch=63.6] | Loss=0.00596 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.008 | L2-Norm(final)=6.940 | 4206.6 samples/s | 65.7 steps/s
[Step=32600 Epoch=63.7] | Loss=0.01116 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.012 | L2-Norm(final)=6.941 | 4573.4 samples/s | 71.5 steps/s
[Step=32650 Epoch=63.8] | Loss=0.01130 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.017 | L2-Norm(final)=6.940 | 4664.1 samples/s | 72.9 steps/s
[Step=32700 Epoch=63.9] | Loss=0.01125 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.024 | L2-Norm(final)=6.942 | 4597.2 samples/s | 71.8 steps/s
[Step=32750 Epoch=64.0] | Loss=0.01171 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.032 | L2-Norm(final)=6.944 | 4750.6 samples/s | 74.2 steps/s
[Step=32800 Epoch=64.1] | Loss=0.01196 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.038 | L2-Norm(final)=6.947 | 4510.0 samples/s | 70.5 steps/s
[Step=32850 Epoch=64.2] | Loss=0.01198 | Reg=0.00363 | acc=0.9688 | L2-Norm=19.045 | L2-Norm(final)=6.949 | 4612.8 samples/s | 72.1 steps/s
[Step=32900 Epoch=64.3] | Loss=0.01229 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.052 | L2-Norm(final)=6.951 | 4643.7 samples/s | 72.6 steps/s
[Step=32950 Epoch=64.4] | Loss=0.01270 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.058 | L2-Norm(final)=6.953 | 4647.3 samples/s | 72.6 steps/s
[Step=33000 Epoch=64.5] | Loss=0.01300 | Reg=0.00363 | acc=0.9375 | L2-Norm=19.064 | L2-Norm(final)=6.954 | 6065.8 samples/s | 94.8 steps/s
[Step=33050 Epoch=64.6] | Loss=0.01315 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.070 | L2-Norm(final)=6.954 | 2412.1 samples/s | 37.7 steps/s
[Step=33100 Epoch=64.7] | Loss=0.01277 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.075 | L2-Norm(final)=6.955 | 4717.4 samples/s | 73.7 steps/s
[Step=33150 Epoch=64.8] | Loss=0.01274 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.081 | L2-Norm(final)=6.957 | 4656.7 samples/s | 72.8 steps/s
[Step=33200 Epoch=64.9] | Loss=0.01252 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.085 | L2-Norm(final)=6.959 | 4522.3 samples/s | 70.7 steps/s
[Step=33250 Epoch=65.0] | Loss=0.01255 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.090 | L2-Norm(final)=6.961 | 4606.9 samples/s | 72.0 steps/s
[Step=33300 Epoch=65.1] | Loss=0.01241 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.093 | L2-Norm(final)=6.963 | 4637.0 samples/s | 72.5 steps/s
[Step=33350 Epoch=65.2] | Loss=0.01256 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.097 | L2-Norm(final)=6.965 | 4662.6 samples/s | 72.9 steps/s
[Step=33400 Epoch=65.3] | Loss=0.01251 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.100 | L2-Norm(final)=6.967 | 4597.5 samples/s | 71.8 steps/s
[Step=33450 Epoch=65.4] | Loss=0.01239 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.104 | L2-Norm(final)=6.969 | 4677.0 samples/s | 73.1 steps/s
[Step=33500 Epoch=65.5] | Loss=0.01217 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.107 | L2-Norm(final)=6.972 | 5094.5 samples/s | 79.6 steps/s
[Step=33550 Epoch=65.6] | Loss=0.01218 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.110 | L2-Norm(final)=6.974 | 2623.4 samples/s | 41.0 steps/s
[Step=33600 Epoch=65.7] | Loss=0.01207 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.113 | L2-Norm(final)=6.976 | 4622.8 samples/s | 72.2 steps/s
[Step=33650 Epoch=65.8] | Loss=0.01191 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.115 | L2-Norm(final)=6.979 | 4641.6 samples/s | 72.5 steps/s
[Step=33700 Epoch=65.9] | Loss=0.01190 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.117 | L2-Norm(final)=6.981 | 4559.2 samples/s | 71.2 steps/s
[Step=33750 Epoch=66.0] | Loss=0.01184 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.119 | L2-Norm(final)=6.983 | 4602.8 samples/s | 71.9 steps/s
[Step=33800 Epoch=66.1] | Loss=0.01177 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.121 | L2-Norm(final)=6.985 | 4622.0 samples/s | 72.2 steps/s
[Step=33850 Epoch=66.2] | Loss=0.01165 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.122 | L2-Norm(final)=6.987 | 4680.7 samples/s | 73.1 steps/s
[Step=33900 Epoch=66.3] | Loss=0.01173 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.124 | L2-Norm(final)=6.990 | 4563.9 samples/s | 71.3 steps/s
[Step=33950 Epoch=66.4] | Loss=0.01168 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.126 | L2-Norm(final)=6.992 | 4657.8 samples/s | 72.8 steps/s
[Step=34000 Epoch=66.5] | Loss=0.01174 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.128 | L2-Norm(final)=6.994 | 4621.6 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step34000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=122.6] | Loss=0.00025 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=5.813 | 6292.4 samples/s | 98.3 steps/s
[Step=32050 Epoch=122.8] | Loss=0.00334 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.020 | L2-Norm(final)=5.819 | 4366.3 samples/s | 68.2 steps/s
[Step=32100 Epoch=123.0] | Loss=0.00215 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.140 | L2-Norm(final)=5.814 | 4921.9 samples/s | 76.9 steps/s
[Step=32150 Epoch=123.2] | Loss=0.00150 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.193 | L2-Norm(final)=5.813 | 4764.4 samples/s | 74.4 steps/s
[Step=32200 Epoch=123.4] | Loss=0.00114 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.219 | L2-Norm(final)=5.814 | 5020.6 samples/s | 78.4 steps/s
[Step=32250 Epoch=123.6] | Loss=0.00093 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.233 | L2-Norm(final)=5.816 | 6680.0 samples/s | 104.4 steps/s
[Step=32300 Epoch=123.8] | Loss=0.00079 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.241 | L2-Norm(final)=5.819 | 2485.7 samples/s | 38.8 steps/s
[Step=32350 Epoch=124.0] | Loss=0.00071 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.246 | L2-Norm(final)=5.821 | 4774.1 samples/s | 74.6 steps/s
[Step=32400 Epoch=124.1] | Loss=0.00062 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.251 | L2-Norm(final)=5.824 | 4956.4 samples/s | 77.4 steps/s
[Step=32450 Epoch=124.3] | Loss=0.00057 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.254 | L2-Norm(final)=5.827 | 4926.8 samples/s | 77.0 steps/s
[Step=32500 Epoch=124.5] | Loss=0.00052 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=5.830 | 5572.6 samples/s | 87.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=124.5] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.274 | L2-Norm(final)=5.857 | 6181.5 samples/s | 96.6 steps/s
[Step=32550 Epoch=124.7] | Loss=0.00004 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.254 | L2-Norm(final)=5.859 | 4016.5 samples/s | 62.8 steps/s
[Step=32600 Epoch=124.9] | Loss=0.00062 | Reg=0.00150 | acc=0.9844 | L2-Norm=12.244 | L2-Norm(final)=5.861 | 4348.6 samples/s | 67.9 steps/s
[Step=32650 Epoch=125.1] | Loss=0.00847 | Reg=0.00152 | acc=0.9844 | L2-Norm=12.309 | L2-Norm(final)=5.835 | 4449.5 samples/s | 69.5 steps/s
[Step=32700 Epoch=125.3] | Loss=0.00880 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.397 | L2-Norm(final)=5.801 | 4345.9 samples/s | 67.9 steps/s
[Step=32750 Epoch=125.5] | Loss=0.00798 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.458 | L2-Norm(final)=5.777 | 5757.1 samples/s | 90.0 steps/s
[Step=32800 Epoch=125.7] | Loss=0.00669 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.499 | L2-Norm(final)=5.761 | 2333.1 samples/s | 36.5 steps/s
[Step=32850 Epoch=125.9] | Loss=0.00576 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.528 | L2-Norm(final)=5.750 | 4372.4 samples/s | 68.3 steps/s
[Step=32900 Epoch=126.1] | Loss=0.00505 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=5.743 | 4393.0 samples/s | 68.6 steps/s
[Step=32950 Epoch=126.3] | Loss=0.00454 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.564 | L2-Norm(final)=5.737 | 4379.2 samples/s | 68.4 steps/s
[Step=33000 Epoch=126.4] | Loss=0.00411 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.733 | 4997.6 samples/s | 78.1 steps/s
[Step=33050 Epoch=126.6] | Loss=0.00375 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.585 | L2-Norm(final)=5.730 | 2502.5 samples/s | 39.1 steps/s
[Step=33100 Epoch=126.8] | Loss=0.00344 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.592 | L2-Norm(final)=5.728 | 4372.2 samples/s | 68.3 steps/s
[Step=33150 Epoch=127.0] | Loss=0.00317 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.596 | L2-Norm(final)=5.726 | 4449.1 samples/s | 69.5 steps/s
[Step=33200 Epoch=127.2] | Loss=0.00295 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.599 | L2-Norm(final)=5.725 | 4328.1 samples/s | 67.6 steps/s
[Step=33250 Epoch=127.4] | Loss=0.00275 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.601 | L2-Norm(final)=5.724 | 4405.7 samples/s | 68.8 steps/s
[Step=33300 Epoch=127.6] | Loss=0.00258 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.603 | L2-Norm(final)=5.723 | 2663.9 samples/s | 41.6 steps/s
[Step=33350 Epoch=127.8] | Loss=0.00243 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.603 | L2-Norm(final)=5.723 | 4433.7 samples/s | 69.3 steps/s
[Step=33400 Epoch=128.0] | Loss=0.00230 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.603 | L2-Norm(final)=5.722 | 4360.0 samples/s | 68.1 steps/s
[Step=33450 Epoch=128.2] | Loss=0.00218 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.602 | L2-Norm(final)=5.722 | 4413.3 samples/s | 69.0 steps/s
[Step=33500 Epoch=128.4] | Loss=0.00207 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.601 | L2-Norm(final)=5.722 | 4460.8 samples/s | 69.7 steps/s
[Step=33550 Epoch=128.6] | Loss=0.00197 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.599 | L2-Norm(final)=5.722 | 2684.1 samples/s | 41.9 steps/s
[Step=33600 Epoch=128.7] | Loss=0.00188 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.597 | L2-Norm(final)=5.722 | 4269.9 samples/s | 66.7 steps/s
[Step=33650 Epoch=128.9] | Loss=0.00180 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.595 | L2-Norm(final)=5.722 | 4512.4 samples/s | 70.5 steps/s
[Step=33700 Epoch=129.1] | Loss=0.00173 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.592 | L2-Norm(final)=5.722 | 4309.1 samples/s | 67.3 steps/s
[Step=33750 Epoch=129.3] | Loss=0.00166 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.589 | L2-Norm(final)=5.723 | 4346.9 samples/s | 67.9 steps/s
[Step=33800 Epoch=129.5] | Loss=0.00159 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.586 | L2-Norm(final)=5.723 | 6492.2 samples/s | 101.4 steps/s
[Step=33850 Epoch=129.7] | Loss=0.00154 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.583 | L2-Norm(final)=5.723 | 2238.9 samples/s | 35.0 steps/s
[Step=33900 Epoch=129.9] | Loss=0.00148 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.580 | L2-Norm(final)=5.724 | 4391.1 samples/s | 68.6 steps/s
[Step=33950 Epoch=130.1] | Loss=0.00143 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=5.724 | 4377.0 samples/s | 68.4 steps/s
[Step=34000 Epoch=130.3] | Loss=0.00138 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.572 | L2-Norm(final)=5.724 | 4378.5 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step34000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=123.2] | Loss=0.00002 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.792 | L2-Norm(final)=6.047 | 6125.0 samples/s | 95.7 steps/s
[Step=32050 Epoch=123.4] | Loss=0.00253 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.973 | L2-Norm(final)=6.035 | 4371.1 samples/s | 68.3 steps/s
[Step=32100 Epoch=123.6] | Loss=0.00135 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.063 | L2-Norm(final)=6.036 | 4894.5 samples/s | 76.5 steps/s
[Step=32150 Epoch=123.8] | Loss=0.00098 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.091 | L2-Norm(final)=6.041 | 4985.2 samples/s | 77.9 steps/s
[Step=32200 Epoch=124.0] | Loss=0.00077 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.104 | L2-Norm(final)=6.046 | 4851.3 samples/s | 75.8 steps/s
[Step=32250 Epoch=124.1] | Loss=0.00076 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.113 | L2-Norm(final)=6.052 | 6899.2 samples/s | 107.8 steps/s
[Step=32300 Epoch=124.3] | Loss=0.00093 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.131 | L2-Norm(final)=6.055 | 2455.8 samples/s | 38.4 steps/s
[Step=32350 Epoch=124.5] | Loss=0.00082 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.150 | L2-Norm(final)=6.058 | 4929.0 samples/s | 77.0 steps/s
[Step=32400 Epoch=124.7] | Loss=0.00073 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.163 | L2-Norm(final)=6.061 | 4826.3 samples/s | 75.4 steps/s
[Step=32450 Epoch=124.9] | Loss=0.00066 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.173 | L2-Norm(final)=6.064 | 4897.1 samples/s | 76.5 steps/s
[Step=32500 Epoch=125.1] | Loss=0.00060 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.180 | L2-Norm(final)=6.067 | 5804.5 samples/s | 90.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=125.1] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.235 | L2-Norm(final)=6.097 | 6068.1 samples/s | 94.8 steps/s
[Step=32550 Epoch=125.3] | Loss=0.00058 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.219 | L2-Norm(final)=6.099 | 3988.6 samples/s | 62.3 steps/s
[Step=32600 Epoch=125.5] | Loss=0.01071 | Reg=0.00152 | acc=0.9844 | L2-Norm=12.333 | L2-Norm(final)=6.068 | 4480.8 samples/s | 70.0 steps/s
[Step=32650 Epoch=125.7] | Loss=0.00834 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.427 | L2-Norm(final)=6.034 | 4272.6 samples/s | 66.8 steps/s
[Step=32700 Epoch=125.9] | Loss=0.00650 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.476 | L2-Norm(final)=6.019 | 4345.4 samples/s | 67.9 steps/s
[Step=32750 Epoch=126.1] | Loss=0.00552 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.506 | L2-Norm(final)=6.011 | 6014.4 samples/s | 94.0 steps/s
[Step=32800 Epoch=126.3] | Loss=0.00462 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.525 | L2-Norm(final)=6.006 | 2317.8 samples/s | 36.2 steps/s
[Step=32850 Epoch=126.5] | Loss=0.00398 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.538 | L2-Norm(final)=6.003 | 4453.6 samples/s | 69.6 steps/s
[Step=32900 Epoch=126.6] | Loss=0.00357 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.547 | L2-Norm(final)=6.001 | 4371.1 samples/s | 68.3 steps/s
[Step=32950 Epoch=126.8] | Loss=0.00318 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=6.000 | 4346.4 samples/s | 67.9 steps/s
[Step=33000 Epoch=127.0] | Loss=0.00287 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.558 | L2-Norm(final)=5.998 | 5134.2 samples/s | 80.2 steps/s
[Step=33050 Epoch=127.2] | Loss=0.00261 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.560 | L2-Norm(final)=5.998 | 2491.9 samples/s | 38.9 steps/s
[Step=33100 Epoch=127.4] | Loss=0.00240 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.562 | L2-Norm(final)=5.998 | 4437.7 samples/s | 69.3 steps/s
[Step=33150 Epoch=127.6] | Loss=0.00221 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.562 | L2-Norm(final)=5.998 | 4389.2 samples/s | 68.6 steps/s
[Step=33200 Epoch=127.8] | Loss=0.00206 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.561 | L2-Norm(final)=5.998 | 4292.9 samples/s | 67.1 steps/s
[Step=33250 Epoch=128.0] | Loss=0.00192 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.560 | L2-Norm(final)=5.999 | 4503.9 samples/s | 70.4 steps/s
[Step=33300 Epoch=128.2] | Loss=0.00180 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.558 | L2-Norm(final)=5.999 | 2652.5 samples/s | 41.4 steps/s
[Step=33350 Epoch=128.4] | Loss=0.00170 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.555 | L2-Norm(final)=6.000 | 4446.6 samples/s | 69.5 steps/s
[Step=33400 Epoch=128.6] | Loss=0.00160 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.552 | L2-Norm(final)=6.001 | 4435.2 samples/s | 69.3 steps/s
[Step=33450 Epoch=128.8] | Loss=0.00152 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=6.002 | 4312.1 samples/s | 67.4 steps/s
[Step=33500 Epoch=129.0] | Loss=0.00144 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.545 | L2-Norm(final)=6.003 | 4326.1 samples/s | 67.6 steps/s
[Step=33550 Epoch=129.1] | Loss=0.00138 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.541 | L2-Norm(final)=6.004 | 2721.2 samples/s | 42.5 steps/s
[Step=33600 Epoch=129.3] | Loss=0.00131 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.537 | L2-Norm(final)=6.005 | 4425.3 samples/s | 69.1 steps/s
[Step=33650 Epoch=129.5] | Loss=0.00126 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.533 | L2-Norm(final)=6.006 | 4378.6 samples/s | 68.4 steps/s
[Step=33700 Epoch=129.7] | Loss=0.00120 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.528 | L2-Norm(final)=6.007 | 4314.2 samples/s | 67.4 steps/s
[Step=33750 Epoch=129.9] | Loss=0.00116 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.524 | L2-Norm(final)=6.008 | 4437.7 samples/s | 69.3 steps/s
[Step=33800 Epoch=130.1] | Loss=0.00111 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.519 | L2-Norm(final)=6.010 | 6980.6 samples/s | 109.1 steps/s
[Step=33850 Epoch=130.3] | Loss=0.00107 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.514 | L2-Norm(final)=6.011 | 2186.2 samples/s | 34.2 steps/s
[Step=33900 Epoch=130.5] | Loss=0.00103 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.509 | L2-Norm(final)=6.013 | 4285.6 samples/s | 67.0 steps/s
[Step=33950 Epoch=130.7] | Loss=0.00100 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.504 | L2-Norm(final)=6.014 | 4436.8 samples/s | 69.3 steps/s
[Step=34000 Epoch=130.9] | Loss=0.00096 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.498 | L2-Norm(final)=6.016 | 4407.5 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08927 | acc=0.9680 | tpr=0.9747 | fpr=0.0466 | 5469.5 samples/s | 21.4 steps/s
Avg test loss: 0.09267, Avg test acc: 0.96630, Avg tpr: 0.97383, Avg fpr: 0.05025, total FA: 392

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07605 | acc=0.9630 | tpr=0.9702 | fpr=0.0528 | 5259.2 samples/s | 20.5 steps/s
Avg test loss: 0.07795, Avg test acc: 0.96242, Avg tpr: 0.97027, Avg fpr: 0.05486, total FA: 428

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.96172 | acc=0.3083 | tpr=0.0051 | fpr=0.0334 | 5226.7 samples/s | 20.4 steps/s
Avg test loss: 4.96874, Avg test acc: 0.30527, Avg tpr: 0.00437, Avg fpr: 0.03294, total FA: 257

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.09987 | acc=0.3088 | tpr=0.0100 | fpr=0.0424 | 5348.9 samples/s | 20.9 steps/s
Avg test loss: 5.10228, Avg test acc: 0.30824, Avg tpr: 0.01166, Avg fpr: 0.03948, total FA: 308

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.07133 | acc=0.1235 | tpr=0.6726 | fpr=0.8864 | 5387.2 samples/s | 21.0 steps/s
[Step= 100] | Loss=7.03229 | acc=0.1248 | tpr=0.6525 | fpr=0.8850 | 6920.3 samples/s | 27.0 steps/s
[Step= 150] | Loss=7.03691 | acc=0.1247 | tpr=0.6643 | fpr=0.8852 | 8159.5 samples/s | 31.9 steps/s
[Step= 200] | Loss=7.05489 | acc=0.1230 | tpr=0.6568 | fpr=0.8867 | 8010.7 samples/s | 31.3 steps/s
[Step= 250] | Loss=7.06529 | acc=0.1236 | tpr=0.6472 | fpr=0.8859 | 6118.4 samples/s | 23.9 steps/s
[Step= 300] | Loss=7.06099 | acc=0.1236 | tpr=0.6560 | fpr=0.8861 | 7586.4 samples/s | 29.6 steps/s
[Step= 350] | Loss=7.04840 | acc=0.1244 | tpr=0.6550 | fpr=0.8852 | 8292.9 samples/s | 32.4 steps/s
[Step= 400] | Loss=7.04298 | acc=0.1245 | tpr=0.6608 | fpr=0.8852 | 8168.8 samples/s | 31.9 steps/s
[Step= 450] | Loss=7.04231 | acc=0.1241 | tpr=0.6592 | fpr=0.8856 | 8147.8 samples/s | 31.8 steps/s
[Step= 500] | Loss=7.04500 | acc=0.1242 | tpr=0.6595 | fpr=0.8855 | 8031.4 samples/s | 31.4 steps/s
[Step= 550] | Loss=7.04432 | acc=0.1244 | tpr=0.6566 | fpr=0.8853 | 14422.2 samples/s | 56.3 steps/s
Avg test loss: 7.04601, Avg test acc: 0.12432, Avg tpr: 0.65689, Avg fpr: 0.88536, total FA: 122931

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.55639 | acc=0.1281 | tpr=0.6858 | fpr=0.8819 | 5451.6 samples/s | 21.3 steps/s
[Step= 100] | Loss=5.53815 | acc=0.1317 | tpr=0.6716 | fpr=0.8784 | 6295.4 samples/s | 24.6 steps/s
[Step= 150] | Loss=5.54408 | acc=0.1315 | tpr=0.6772 | fpr=0.8786 | 8064.5 samples/s | 31.5 steps/s
[Step= 200] | Loss=5.55639 | acc=0.1313 | tpr=0.6776 | fpr=0.8787 | 8256.2 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.55264 | acc=0.1321 | tpr=0.6821 | fpr=0.8779 | 6235.2 samples/s | 24.4 steps/s
[Step= 300] | Loss=5.55243 | acc=0.1319 | tpr=0.6924 | fpr=0.8783 | 8168.3 samples/s | 31.9 steps/s
[Step= 350] | Loss=5.54251 | acc=0.1318 | tpr=0.6894 | fpr=0.8783 | 8020.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=5.53649 | acc=0.1320 | tpr=0.6887 | fpr=0.8781 | 8150.8 samples/s | 31.8 steps/s
[Step= 450] | Loss=5.53540 | acc=0.1319 | tpr=0.6879 | fpr=0.8782 | 8223.3 samples/s | 32.1 steps/s
[Step= 500] | Loss=5.54023 | acc=0.1317 | tpr=0.6877 | fpr=0.8783 | 8102.9 samples/s | 31.7 steps/s
[Step= 550] | Loss=5.53791 | acc=0.1317 | tpr=0.6825 | fpr=0.8783 | 14422.3 samples/s | 56.3 steps/s
Avg test loss: 5.53856, Avg test acc: 0.13162, Avg tpr: 0.68225, Avg fpr: 0.87838, total FA: 121962

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14364 | acc=0.9799 | tpr=0.9469 | fpr=0.0195 | 5131.6 samples/s | 20.0 steps/s
[Step= 100] | Loss=0.14993 | acc=0.9796 | tpr=0.9446 | fpr=0.0198 | 7554.6 samples/s | 29.5 steps/s
[Step= 150] | Loss=0.15790 | acc=0.9782 | tpr=0.9424 | fpr=0.0211 | 7744.7 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.16086 | acc=0.9783 | tpr=0.9454 | fpr=0.0211 | 7987.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.15805 | acc=0.9788 | tpr=0.9441 | fpr=0.0206 | 6182.4 samples/s | 24.2 steps/s
[Step= 300] | Loss=0.16002 | acc=0.9785 | tpr=0.9440 | fpr=0.0208 | 7889.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.16120 | acc=0.9783 | tpr=0.9449 | fpr=0.0211 | 8320.7 samples/s | 32.5 steps/s
[Step= 400] | Loss=0.16335 | acc=0.9781 | tpr=0.9398 | fpr=0.0212 | 8215.8 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.16665 | acc=0.9778 | tpr=0.9396 | fpr=0.0215 | 8031.3 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.16600 | acc=0.9778 | tpr=0.9419 | fpr=0.0215 | 8203.3 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.16500 | acc=0.9779 | tpr=0.9399 | fpr=0.0214 | 14837.0 samples/s | 58.0 steps/s
Avg test loss: 0.16465, Avg test acc: 0.97795, Avg tpr: 0.93899, Avg fpr: 0.02134, total FA: 2963

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12424 | acc=0.9786 | tpr=0.9469 | fpr=0.0208 | 5230.7 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.12912 | acc=0.9780 | tpr=0.9446 | fpr=0.0214 | 7143.2 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.13460 | acc=0.9773 | tpr=0.9496 | fpr=0.0221 | 8129.7 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.13683 | acc=0.9771 | tpr=0.9530 | fpr=0.0224 | 6393.0 samples/s | 25.0 steps/s
[Step= 250] | Loss=0.13496 | acc=0.9773 | tpr=0.9528 | fpr=0.0222 | 7332.8 samples/s | 28.6 steps/s
[Step= 300] | Loss=0.13700 | acc=0.9770 | tpr=0.9520 | fpr=0.0225 | 8195.7 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.13828 | acc=0.9768 | tpr=0.9530 | fpr=0.0227 | 7882.3 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.14009 | acc=0.9767 | tpr=0.9491 | fpr=0.0228 | 8259.6 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.14293 | acc=0.9764 | tpr=0.9499 | fpr=0.0231 | 8018.2 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.14220 | acc=0.9764 | tpr=0.9507 | fpr=0.0231 | 8394.2 samples/s | 32.8 steps/s
[Step= 550] | Loss=0.14117 | acc=0.9765 | tpr=0.9495 | fpr=0.0230 | 13744.8 samples/s | 53.7 steps/s
Avg test loss: 0.14083, Avg test acc: 0.97655, Avg tpr: 0.94889, Avg fpr: 0.02295, total FA: 3186

server round 17/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=66.3] | Loss=0.03276 | Reg=0.00339 | acc=0.9688 | L2-Norm=18.423 | L2-Norm(final)=6.851 | 6690.6 samples/s | 104.5 steps/s
[Step=34050 Epoch=66.4] | Loss=0.01713 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.436 | L2-Norm(final)=6.866 | 4472.7 samples/s | 69.9 steps/s
[Step=34100 Epoch=66.5] | Loss=0.01801 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.448 | L2-Norm(final)=6.878 | 5253.8 samples/s | 82.1 steps/s
[Step=34150 Epoch=66.6] | Loss=0.01735 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.456 | L2-Norm(final)=6.893 | 5205.0 samples/s | 81.3 steps/s
[Step=34200 Epoch=66.7] | Loss=0.01743 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.463 | L2-Norm(final)=6.907 | 5104.6 samples/s | 79.8 steps/s
[Step=34250 Epoch=66.8] | Loss=0.01762 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.469 | L2-Norm(final)=6.920 | 5278.0 samples/s | 82.5 steps/s
[Step=34300 Epoch=66.9] | Loss=0.01750 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.475 | L2-Norm(final)=6.932 | 5157.4 samples/s | 80.6 steps/s
[Step=34350 Epoch=67.0] | Loss=0.01693 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.481 | L2-Norm(final)=6.944 | 5207.9 samples/s | 81.4 steps/s
[Step=34400 Epoch=67.1] | Loss=0.01710 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.486 | L2-Norm(final)=6.956 | 5206.5 samples/s | 81.4 steps/s
[Step=34450 Epoch=67.2] | Loss=0.01709 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.492 | L2-Norm(final)=6.967 | 5343.0 samples/s | 83.5 steps/s
[Step=34500 Epoch=67.3] | Loss=0.01721 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.497 | L2-Norm(final)=6.977 | 6733.4 samples/s | 105.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=67.3] | Loss=0.02262 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.549 | L2-Norm(final)=7.081 | 6338.7 samples/s | 99.0 steps/s
[Step=34550 Epoch=67.4] | Loss=0.00941 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.558 | L2-Norm(final)=7.093 | 4213.1 samples/s | 65.8 steps/s
[Step=34600 Epoch=67.5] | Loss=0.01189 | Reg=0.00345 | acc=0.9531 | L2-Norm=18.568 | L2-Norm(final)=7.101 | 4588.5 samples/s | 71.7 steps/s
[Step=34650 Epoch=67.6] | Loss=0.01327 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.581 | L2-Norm(final)=7.103 | 4629.3 samples/s | 72.3 steps/s
[Step=34700 Epoch=67.7] | Loss=0.01308 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.593 | L2-Norm(final)=7.104 | 4637.9 samples/s | 72.5 steps/s
[Step=34750 Epoch=67.8] | Loss=0.01359 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.603 | L2-Norm(final)=7.104 | 4734.9 samples/s | 74.0 steps/s
[Step=34800 Epoch=67.9] | Loss=0.01483 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.612 | L2-Norm(final)=7.104 | 4632.8 samples/s | 72.4 steps/s
[Step=34850 Epoch=68.0] | Loss=0.01508 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.620 | L2-Norm(final)=7.104 | 4512.0 samples/s | 70.5 steps/s
[Step=34900 Epoch=68.1] | Loss=0.01574 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.628 | L2-Norm(final)=7.105 | 4651.4 samples/s | 72.7 steps/s
[Step=34950 Epoch=68.2] | Loss=0.01594 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.637 | L2-Norm(final)=7.105 | 4658.1 samples/s | 72.8 steps/s
[Step=35000 Epoch=68.3] | Loss=0.01608 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.646 | L2-Norm(final)=7.105 | 5852.2 samples/s | 91.4 steps/s
[Step=35050 Epoch=68.4] | Loss=0.01558 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.654 | L2-Norm(final)=7.105 | 2437.6 samples/s | 38.1 steps/s
[Step=35100 Epoch=68.5] | Loss=0.01559 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.662 | L2-Norm(final)=7.106 | 4641.0 samples/s | 72.5 steps/s
[Step=35150 Epoch=68.6] | Loss=0.01549 | Reg=0.00349 | acc=0.9531 | L2-Norm=18.669 | L2-Norm(final)=7.106 | 4598.1 samples/s | 71.8 steps/s
[Step=35200 Epoch=68.7] | Loss=0.01520 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.675 | L2-Norm(final)=7.107 | 4700.3 samples/s | 73.4 steps/s
[Step=35250 Epoch=68.8] | Loss=0.01497 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.680 | L2-Norm(final)=7.107 | 4607.4 samples/s | 72.0 steps/s
[Step=35300 Epoch=68.8] | Loss=0.01489 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.685 | L2-Norm(final)=7.107 | 4648.1 samples/s | 72.6 steps/s
[Step=35350 Epoch=68.9] | Loss=0.01480 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.691 | L2-Norm(final)=7.108 | 4479.8 samples/s | 70.0 steps/s
[Step=35400 Epoch=69.0] | Loss=0.01474 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.695 | L2-Norm(final)=7.108 | 4638.8 samples/s | 72.5 steps/s
[Step=35450 Epoch=69.1] | Loss=0.01489 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.700 | L2-Norm(final)=7.108 | 4635.7 samples/s | 72.4 steps/s
[Step=35500 Epoch=69.2] | Loss=0.01488 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.704 | L2-Norm(final)=7.108 | 4982.0 samples/s | 77.8 steps/s
[Step=35550 Epoch=69.3] | Loss=0.01470 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.708 | L2-Norm(final)=7.109 | 2675.9 samples/s | 41.8 steps/s
[Step=35600 Epoch=69.4] | Loss=0.01447 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.712 | L2-Norm(final)=7.109 | 4570.8 samples/s | 71.4 steps/s
[Step=35650 Epoch=69.5] | Loss=0.01428 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.715 | L2-Norm(final)=7.109 | 4645.9 samples/s | 72.6 steps/s
[Step=35700 Epoch=69.6] | Loss=0.01395 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.718 | L2-Norm(final)=7.110 | 4664.5 samples/s | 72.9 steps/s
[Step=35750 Epoch=69.7] | Loss=0.01385 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.721 | L2-Norm(final)=7.111 | 4574.2 samples/s | 71.5 steps/s
[Step=35800 Epoch=69.8] | Loss=0.01376 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.724 | L2-Norm(final)=7.111 | 4631.4 samples/s | 72.4 steps/s
[Step=35850 Epoch=69.9] | Loss=0.01361 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.726 | L2-Norm(final)=7.112 | 4612.2 samples/s | 72.1 steps/s
[Step=35900 Epoch=70.0] | Loss=0.01341 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.729 | L2-Norm(final)=7.113 | 4740.9 samples/s | 74.1 steps/s
[Step=35950 Epoch=70.1] | Loss=0.01346 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.731 | L2-Norm(final)=7.114 | 4540.4 samples/s | 70.9 steps/s
[Step=36000 Epoch=70.2] | Loss=0.01345 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.733 | L2-Norm(final)=7.114 | 4711.1 samples/s | 73.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step36000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=66.5] | Loss=0.03220 | Reg=0.00361 | acc=0.9688 | L2-Norm=18.989 | L2-Norm(final)=7.048 | 6438.6 samples/s | 100.6 steps/s
[Step=34050 Epoch=66.6] | Loss=0.02004 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.998 | L2-Norm(final)=7.064 | 4888.4 samples/s | 76.4 steps/s
[Step=34100 Epoch=66.7] | Loss=0.01750 | Reg=0.00361 | acc=0.9844 | L2-Norm=19.005 | L2-Norm(final)=7.085 | 5129.1 samples/s | 80.1 steps/s
[Step=34150 Epoch=66.8] | Loss=0.01701 | Reg=0.00361 | acc=0.9688 | L2-Norm=19.011 | L2-Norm(final)=7.103 | 5237.8 samples/s | 81.8 steps/s
[Step=34200 Epoch=66.9] | Loss=0.01641 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.017 | L2-Norm(final)=7.122 | 5143.6 samples/s | 80.4 steps/s
[Step=34250 Epoch=67.0] | Loss=0.01629 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.023 | L2-Norm(final)=7.141 | 5249.3 samples/s | 82.0 steps/s
[Step=34300 Epoch=67.1] | Loss=0.01618 | Reg=0.00362 | acc=0.9844 | L2-Norm=19.030 | L2-Norm(final)=7.159 | 5284.8 samples/s | 82.6 steps/s
[Step=34350 Epoch=67.2] | Loss=0.01584 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.037 | L2-Norm(final)=7.175 | 5143.4 samples/s | 80.4 steps/s
[Step=34400 Epoch=67.3] | Loss=0.01547 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.044 | L2-Norm(final)=7.190 | 5278.5 samples/s | 82.5 steps/s
[Step=34450 Epoch=67.3] | Loss=0.01543 | Reg=0.00363 | acc=0.9688 | L2-Norm=19.051 | L2-Norm(final)=7.206 | 5150.8 samples/s | 80.5 steps/s
[Step=34500 Epoch=67.4] | Loss=0.01532 | Reg=0.00363 | acc=0.9688 | L2-Norm=19.057 | L2-Norm(final)=7.221 | 7082.7 samples/s | 110.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=67.4] | Loss=0.01744 | Reg=0.00366 | acc=0.9844 | L2-Norm=19.119 | L2-Norm(final)=7.369 | 6304.3 samples/s | 98.5 steps/s
[Step=34550 Epoch=67.5] | Loss=0.01147 | Reg=0.00366 | acc=1.0000 | L2-Norm=19.129 | L2-Norm(final)=7.382 | 4229.8 samples/s | 66.1 steps/s
[Step=34600 Epoch=67.6] | Loss=0.01280 | Reg=0.00366 | acc=0.9688 | L2-Norm=19.137 | L2-Norm(final)=7.387 | 4611.5 samples/s | 72.1 steps/s
[Step=34650 Epoch=67.7] | Loss=0.01375 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.146 | L2-Norm(final)=7.390 | 4556.6 samples/s | 71.2 steps/s
[Step=34700 Epoch=67.8] | Loss=0.01427 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.155 | L2-Norm(final)=7.393 | 4627.5 samples/s | 72.3 steps/s
[Step=34750 Epoch=67.9] | Loss=0.01478 | Reg=0.00367 | acc=0.9844 | L2-Norm=19.164 | L2-Norm(final)=7.393 | 4589.6 samples/s | 71.7 steps/s
[Step=34800 Epoch=68.0] | Loss=0.01487 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.172 | L2-Norm(final)=7.393 | 4636.7 samples/s | 72.4 steps/s
[Step=34850 Epoch=68.1] | Loss=0.01494 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.179 | L2-Norm(final)=7.394 | 4642.9 samples/s | 72.5 steps/s
[Step=34900 Epoch=68.2] | Loss=0.01518 | Reg=0.00368 | acc=0.9844 | L2-Norm=19.185 | L2-Norm(final)=7.395 | 4638.5 samples/s | 72.5 steps/s
[Step=34950 Epoch=68.3] | Loss=0.01500 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.191 | L2-Norm(final)=7.395 | 4605.0 samples/s | 72.0 steps/s
[Step=35000 Epoch=68.4] | Loss=0.01492 | Reg=0.00368 | acc=1.0000 | L2-Norm=19.196 | L2-Norm(final)=7.395 | 6051.7 samples/s | 94.6 steps/s
[Step=35050 Epoch=68.5] | Loss=0.01456 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.201 | L2-Norm(final)=7.395 | 2424.7 samples/s | 37.9 steps/s
[Step=35100 Epoch=68.6] | Loss=0.01418 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.204 | L2-Norm(final)=7.396 | 4662.4 samples/s | 72.9 steps/s
[Step=35150 Epoch=68.7] | Loss=0.01377 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.207 | L2-Norm(final)=7.397 | 4602.3 samples/s | 71.9 steps/s
[Step=35200 Epoch=68.8] | Loss=0.01368 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.209 | L2-Norm(final)=7.397 | 4641.2 samples/s | 72.5 steps/s
[Step=35250 Epoch=68.9] | Loss=0.01341 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.210 | L2-Norm(final)=7.398 | 4552.4 samples/s | 71.1 steps/s
[Step=35300 Epoch=69.0] | Loss=0.01321 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.212 | L2-Norm(final)=7.399 | 4708.8 samples/s | 73.6 steps/s
[Step=35350 Epoch=69.1] | Loss=0.01314 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.213 | L2-Norm(final)=7.401 | 4540.8 samples/s | 70.9 steps/s
[Step=35400 Epoch=69.2] | Loss=0.01315 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.213 | L2-Norm(final)=7.401 | 4654.2 samples/s | 72.7 steps/s
[Step=35450 Epoch=69.3] | Loss=0.01307 | Reg=0.00369 | acc=0.9844 | L2-Norm=19.214 | L2-Norm(final)=7.401 | 4737.8 samples/s | 74.0 steps/s
[Step=35500 Epoch=69.4] | Loss=0.01297 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.216 | L2-Norm(final)=7.402 | 4964.3 samples/s | 77.6 steps/s
[Step=35550 Epoch=69.5] | Loss=0.01286 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.217 | L2-Norm(final)=7.403 | 2645.9 samples/s | 41.3 steps/s
[Step=35600 Epoch=69.6] | Loss=0.01281 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.218 | L2-Norm(final)=7.404 | 4584.3 samples/s | 71.6 steps/s
[Step=35650 Epoch=69.7] | Loss=0.01273 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.219 | L2-Norm(final)=7.405 | 4515.3 samples/s | 70.6 steps/s
[Step=35700 Epoch=69.8] | Loss=0.01262 | Reg=0.00369 | acc=0.9688 | L2-Norm=19.220 | L2-Norm(final)=7.406 | 4603.1 samples/s | 71.9 steps/s
[Step=35750 Epoch=69.9] | Loss=0.01252 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.221 | L2-Norm(final)=7.407 | 4616.5 samples/s | 72.1 steps/s
[Step=35800 Epoch=70.0] | Loss=0.01241 | Reg=0.00369 | acc=1.0000 | L2-Norm=19.222 | L2-Norm(final)=7.408 | 4599.4 samples/s | 71.9 steps/s
[Step=35850 Epoch=70.1] | Loss=0.01232 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.223 | L2-Norm(final)=7.409 | 4640.5 samples/s | 72.5 steps/s
[Step=35900 Epoch=70.2] | Loss=0.01232 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.224 | L2-Norm(final)=7.410 | 4710.1 samples/s | 73.6 steps/s
[Step=35950 Epoch=70.3] | Loss=0.01229 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.225 | L2-Norm(final)=7.411 | 4553.7 samples/s | 71.2 steps/s
[Step=36000 Epoch=70.4] | Loss=0.01218 | Reg=0.00370 | acc=1.0000 | L2-Norm=19.226 | L2-Norm(final)=7.412 | 4609.3 samples/s | 72.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step36000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=130.3] | Loss=0.00016 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.364 | L2-Norm(final)=5.738 | 7055.5 samples/s | 110.2 steps/s
[Step=34050 Epoch=130.5] | Loss=0.00014 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.365 | L2-Norm(final)=5.741 | 3964.3 samples/s | 61.9 steps/s
[Step=34100 Epoch=130.7] | Loss=0.00012 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.370 | L2-Norm(final)=5.744 | 4893.6 samples/s | 76.5 steps/s
[Step=34150 Epoch=130.9] | Loss=0.00011 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.371 | L2-Norm(final)=5.748 | 4937.1 samples/s | 77.1 steps/s
[Step=34200 Epoch=131.0] | Loss=0.00012 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.371 | L2-Norm(final)=5.752 | 4971.8 samples/s | 77.7 steps/s
[Step=34250 Epoch=131.2] | Loss=0.00012 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.372 | L2-Norm(final)=5.756 | 6627.1 samples/s | 103.5 steps/s
[Step=34300 Epoch=131.4] | Loss=0.00012 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.374 | L2-Norm(final)=5.760 | 2503.7 samples/s | 39.1 steps/s
[Step=34350 Epoch=131.6] | Loss=0.00011 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.375 | L2-Norm(final)=5.763 | 4788.7 samples/s | 74.8 steps/s
[Step=34400 Epoch=131.8] | Loss=0.00010 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.374 | L2-Norm(final)=5.766 | 4955.8 samples/s | 77.4 steps/s
[Step=34450 Epoch=132.0] | Loss=0.00009 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.373 | L2-Norm(final)=5.769 | 4826.1 samples/s | 75.4 steps/s
[Step=34500 Epoch=132.2] | Loss=0.00009 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.372 | L2-Norm(final)=5.771 | 5704.6 samples/s | 89.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=132.2] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.356 | L2-Norm(final)=5.797 | 6415.1 samples/s | 100.2 steps/s
[Step=34550 Epoch=132.4] | Loss=0.00004 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.351 | L2-Norm(final)=5.800 | 4109.3 samples/s | 64.2 steps/s
[Step=34600 Epoch=132.6] | Loss=0.00003 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.343 | L2-Norm(final)=5.802 | 4445.0 samples/s | 69.5 steps/s
[Step=34650 Epoch=132.8] | Loss=0.00003 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.336 | L2-Norm(final)=5.804 | 4381.1 samples/s | 68.5 steps/s
[Step=34700 Epoch=133.0] | Loss=0.00002 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.328 | L2-Norm(final)=5.805 | 4350.7 samples/s | 68.0 steps/s
[Step=34750 Epoch=133.1] | Loss=0.00002 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.320 | L2-Norm(final)=5.807 | 5856.8 samples/s | 91.5 steps/s
[Step=34800 Epoch=133.3] | Loss=0.00002 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.312 | L2-Norm(final)=5.808 | 2337.0 samples/s | 36.5 steps/s
[Step=34850 Epoch=133.5] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.305 | L2-Norm(final)=5.809 | 4365.1 samples/s | 68.2 steps/s
[Step=34900 Epoch=133.7] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.297 | L2-Norm(final)=5.810 | 4456.9 samples/s | 69.6 steps/s
[Step=34950 Epoch=133.9] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.288 | L2-Norm(final)=5.811 | 4343.5 samples/s | 67.9 steps/s
[Step=35000 Epoch=134.1] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.280 | L2-Norm(final)=5.812 | 4945.2 samples/s | 77.3 steps/s
[Step=35050 Epoch=134.3] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.272 | L2-Norm(final)=5.813 | 1870.0 samples/s | 29.2 steps/s
[Step=35100 Epoch=134.5] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.264 | L2-Norm(final)=5.814 | 4408.3 samples/s | 68.9 steps/s
[Step=35150 Epoch=134.7] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.256 | L2-Norm(final)=5.815 | 4391.5 samples/s | 68.6 steps/s
[Step=35200 Epoch=134.9] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.247 | L2-Norm(final)=5.816 | 4210.4 samples/s | 65.8 steps/s
[Step=35250 Epoch=135.1] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.239 | L2-Norm(final)=5.817 | 4340.4 samples/s | 67.8 steps/s
[Step=35300 Epoch=135.3] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.231 | L2-Norm(final)=5.817 | 2631.8 samples/s | 41.1 steps/s
[Step=35350 Epoch=135.4] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.222 | L2-Norm(final)=5.818 | 4379.2 samples/s | 68.4 steps/s
[Step=35400 Epoch=135.6] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.214 | L2-Norm(final)=5.819 | 4389.2 samples/s | 68.6 steps/s
[Step=35450 Epoch=135.8] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.205 | L2-Norm(final)=5.820 | 4428.1 samples/s | 69.2 steps/s
[Step=35500 Epoch=136.0] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.196 | L2-Norm(final)=5.821 | 4341.5 samples/s | 67.8 steps/s
[Step=35550 Epoch=136.2] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.188 | L2-Norm(final)=5.821 | 2710.4 samples/s | 42.3 steps/s
[Step=35600 Epoch=136.4] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.179 | L2-Norm(final)=5.822 | 4411.9 samples/s | 68.9 steps/s
[Step=35650 Epoch=136.6] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.170 | L2-Norm(final)=5.823 | 4261.6 samples/s | 66.6 steps/s
[Step=35700 Epoch=136.8] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.161 | L2-Norm(final)=5.824 | 4359.1 samples/s | 68.1 steps/s
[Step=35750 Epoch=137.0] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.152 | L2-Norm(final)=5.824 | 4402.5 samples/s | 68.8 steps/s
[Step=35800 Epoch=137.2] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.143 | L2-Norm(final)=5.825 | 6416.6 samples/s | 100.3 steps/s
[Step=35850 Epoch=137.4] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.134 | L2-Norm(final)=5.826 | 2223.6 samples/s | 34.7 steps/s
[Step=35900 Epoch=137.6] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.125 | L2-Norm(final)=5.827 | 4419.2 samples/s | 69.0 steps/s
[Step=35950 Epoch=137.7] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.116 | L2-Norm(final)=5.827 | 4361.5 samples/s | 68.1 steps/s
[Step=36000 Epoch=137.9] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.106 | L2-Norm(final)=5.828 | 4434.1 samples/s | 69.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step36000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=130.9] | Loss=0.00299 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.297 | L2-Norm(final)=6.065 | 6701.2 samples/s | 104.7 steps/s
[Step=34050 Epoch=131.1] | Loss=0.00034 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.324 | L2-Norm(final)=6.068 | 4249.3 samples/s | 66.4 steps/s
[Step=34100 Epoch=131.3] | Loss=0.00031 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.328 | L2-Norm(final)=6.072 | 4810.0 samples/s | 75.2 steps/s
[Step=34150 Epoch=131.5] | Loss=0.00035 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.329 | L2-Norm(final)=6.077 | 5011.9 samples/s | 78.3 steps/s
[Step=34200 Epoch=131.6] | Loss=0.00034 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.333 | L2-Norm(final)=6.081 | 4891.9 samples/s | 76.4 steps/s
[Step=34250 Epoch=131.8] | Loss=0.00029 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.336 | L2-Norm(final)=6.086 | 6788.6 samples/s | 106.1 steps/s
[Step=34300 Epoch=132.0] | Loss=0.00025 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.337 | L2-Norm(final)=6.089 | 2467.7 samples/s | 38.6 steps/s
[Step=34350 Epoch=132.2] | Loss=0.00022 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.337 | L2-Norm(final)=6.093 | 5070.3 samples/s | 79.2 steps/s
[Step=34400 Epoch=132.4] | Loss=0.00020 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.335 | L2-Norm(final)=6.096 | 4834.0 samples/s | 75.5 steps/s
[Step=34450 Epoch=132.6] | Loss=0.00019 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.334 | L2-Norm(final)=6.100 | 4825.9 samples/s | 75.4 steps/s
[Step=34500 Epoch=132.8] | Loss=0.00017 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.333 | L2-Norm(final)=6.103 | 5835.5 samples/s | 91.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=132.8] | Loss=0.00010 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.324 | L2-Norm(final)=6.143 | 6128.9 samples/s | 95.8 steps/s
[Step=34550 Epoch=133.0] | Loss=0.00004 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.313 | L2-Norm(final)=6.145 | 4054.2 samples/s | 63.3 steps/s
[Step=34600 Epoch=133.2] | Loss=0.00003 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.303 | L2-Norm(final)=6.148 | 4416.2 samples/s | 69.0 steps/s
[Step=34650 Epoch=133.4] | Loss=0.00003 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.293 | L2-Norm(final)=6.150 | 4368.1 samples/s | 68.3 steps/s
[Step=34700 Epoch=133.6] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.284 | L2-Norm(final)=6.152 | 4280.3 samples/s | 66.9 steps/s
[Step=34750 Epoch=133.8] | Loss=0.00002 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.274 | L2-Norm(final)=6.154 | 5923.2 samples/s | 92.6 steps/s
[Step=34800 Epoch=134.0] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.265 | L2-Norm(final)=6.156 | 2347.6 samples/s | 36.7 steps/s
[Step=34850 Epoch=134.2] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.255 | L2-Norm(final)=6.158 | 4275.4 samples/s | 66.8 steps/s
[Step=34900 Epoch=134.3] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.245 | L2-Norm(final)=6.159 | 4384.2 samples/s | 68.5 steps/s
[Step=34950 Epoch=134.5] | Loss=0.00002 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.236 | L2-Norm(final)=6.160 | 4377.8 samples/s | 68.4 steps/s
[Step=35000 Epoch=134.7] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.226 | L2-Norm(final)=6.161 | 5111.8 samples/s | 79.9 steps/s
[Step=35050 Epoch=134.9] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.216 | L2-Norm(final)=6.162 | 2509.4 samples/s | 39.2 steps/s
[Step=35100 Epoch=135.1] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.206 | L2-Norm(final)=6.163 | 4288.2 samples/s | 67.0 steps/s
[Step=35150 Epoch=135.3] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.196 | L2-Norm(final)=6.164 | 4418.9 samples/s | 69.0 steps/s
[Step=35200 Epoch=135.5] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.186 | L2-Norm(final)=6.165 | 4325.9 samples/s | 67.6 steps/s
[Step=35250 Epoch=135.7] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.176 | L2-Norm(final)=6.166 | 4460.1 samples/s | 69.7 steps/s
[Step=35300 Epoch=135.9] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.166 | L2-Norm(final)=6.167 | 2641.5 samples/s | 41.3 steps/s
[Step=35350 Epoch=136.1] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.156 | L2-Norm(final)=6.168 | 4402.4 samples/s | 68.8 steps/s
[Step=35400 Epoch=136.3] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.146 | L2-Norm(final)=6.169 | 4378.1 samples/s | 68.4 steps/s
[Step=35450 Epoch=136.5] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.136 | L2-Norm(final)=6.170 | 4382.1 samples/s | 68.5 steps/s
[Step=35500 Epoch=136.7] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.126 | L2-Norm(final)=6.170 | 4399.5 samples/s | 68.7 steps/s
[Step=35550 Epoch=136.8] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.115 | L2-Norm(final)=6.171 | 2680.5 samples/s | 41.9 steps/s
[Step=35600 Epoch=137.0] | Loss=0.00001 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.105 | L2-Norm(final)=6.172 | 4402.5 samples/s | 68.8 steps/s
[Step=35650 Epoch=137.2] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.094 | L2-Norm(final)=6.173 | 4319.7 samples/s | 67.5 steps/s
[Step=35700 Epoch=137.4] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.084 | L2-Norm(final)=6.174 | 4311.1 samples/s | 67.4 steps/s
[Step=35750 Epoch=137.6] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.073 | L2-Norm(final)=6.174 | 4336.8 samples/s | 67.8 steps/s
[Step=35800 Epoch=137.8] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.062 | L2-Norm(final)=6.175 | 6884.3 samples/s | 107.6 steps/s
[Step=35850 Epoch=138.0] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.052 | L2-Norm(final)=6.176 | 2163.0 samples/s | 33.8 steps/s
[Step=35900 Epoch=138.2] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.041 | L2-Norm(final)=6.177 | 4474.3 samples/s | 69.9 steps/s
[Step=35950 Epoch=138.4] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.030 | L2-Norm(final)=6.178 | 4298.4 samples/s | 67.2 steps/s
[Step=36000 Epoch=138.6] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.019 | L2-Norm(final)=6.178 | 4363.9 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08206 | acc=0.9668 | tpr=0.9734 | fpr=0.0476 | 5270.9 samples/s | 20.6 steps/s
Avg test loss: 0.08581, Avg test acc: 0.96566, Avg tpr: 0.97319, Avg fpr: 0.05089, total FA: 397

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07787 | acc=0.9665 | tpr=0.9760 | fpr=0.0543 | 5181.9 samples/s | 20.2 steps/s
Avg test loss: 0.08076, Avg test acc: 0.96718, Avg tpr: 0.97657, Avg fpr: 0.05345, total FA: 417

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.45811 | acc=0.3039 | tpr=0.0068 | fpr=0.0510 | 5274.7 samples/s | 20.6 steps/s
Avg test loss: 5.46396, Avg test acc: 0.30263, Avg tpr: 0.00729, Avg fpr: 0.04781, total FA: 373

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.31454 | acc=0.3056 | tpr=0.0106 | fpr=0.0538 | 5243.0 samples/s | 20.5 steps/s
Avg test loss: 5.32573, Avg test acc: 0.30435, Avg tpr: 0.01102, Avg fpr: 0.05051, total FA: 394

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.12159 | acc=0.1235 | tpr=0.6726 | fpr=0.8864 | 5160.3 samples/s | 20.2 steps/s
[Step= 100] | Loss=7.09965 | acc=0.1237 | tpr=0.6461 | fpr=0.8860 | 6879.5 samples/s | 26.9 steps/s
[Step= 150] | Loss=7.10075 | acc=0.1245 | tpr=0.6643 | fpr=0.8854 | 8614.0 samples/s | 33.6 steps/s
[Step= 200] | Loss=7.11595 | acc=0.1237 | tpr=0.6667 | fpr=0.8862 | 8033.3 samples/s | 31.4 steps/s
[Step= 250] | Loss=7.12298 | acc=0.1244 | tpr=0.6655 | fpr=0.8855 | 7842.9 samples/s | 30.6 steps/s
[Step= 300] | Loss=7.12033 | acc=0.1241 | tpr=0.6749 | fpr=0.8859 | 8425.3 samples/s | 32.9 steps/s
[Step= 350] | Loss=7.11182 | acc=0.1244 | tpr=0.6744 | fpr=0.8856 | 7902.1 samples/s | 30.9 steps/s
[Step= 400] | Loss=7.10690 | acc=0.1252 | tpr=0.6761 | fpr=0.8848 | 8109.2 samples/s | 31.7 steps/s
[Step= 450] | Loss=7.10646 | acc=0.1247 | tpr=0.6743 | fpr=0.8852 | 8348.1 samples/s | 32.6 steps/s
[Step= 500] | Loss=7.10966 | acc=0.1248 | tpr=0.6780 | fpr=0.8852 | 8105.2 samples/s | 31.7 steps/s
[Step= 550] | Loss=7.10725 | acc=0.1250 | tpr=0.6769 | fpr=0.8850 | 13926.8 samples/s | 54.4 steps/s
Avg test loss: 7.10868, Avg test acc: 0.12494, Avg tpr: 0.67789, Avg fpr: 0.88511, total FA: 122896

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.80289 | acc=0.1183 | tpr=0.7345 | fpr=0.8928 | 5074.3 samples/s | 19.8 steps/s
[Step= 100] | Loss=6.77947 | acc=0.1186 | tpr=0.7207 | fpr=0.8926 | 7818.1 samples/s | 30.5 steps/s
[Step= 150] | Loss=6.77208 | acc=0.1190 | tpr=0.7262 | fpr=0.8922 | 7916.9 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.78579 | acc=0.1176 | tpr=0.7333 | fpr=0.8936 | 8016.1 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.78462 | acc=0.1185 | tpr=0.7336 | fpr=0.8927 | 8251.5 samples/s | 32.2 steps/s
[Step= 300] | Loss=6.78801 | acc=0.1182 | tpr=0.7382 | fpr=0.8931 | 8252.7 samples/s | 32.2 steps/s
[Step= 350] | Loss=6.77753 | acc=0.1179 | tpr=0.7376 | fpr=0.8934 | 7985.6 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.77187 | acc=0.1182 | tpr=0.7391 | fpr=0.8931 | 8041.9 samples/s | 31.4 steps/s
[Step= 450] | Loss=6.76928 | acc=0.1176 | tpr=0.7390 | fpr=0.8937 | 8251.4 samples/s | 32.2 steps/s
[Step= 500] | Loss=6.77417 | acc=0.1171 | tpr=0.7370 | fpr=0.8941 | 8009.5 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.76902 | acc=0.1172 | tpr=0.7310 | fpr=0.8939 | 14532.2 samples/s | 56.8 steps/s
Avg test loss: 6.76974, Avg test acc: 0.11716, Avg tpr: 0.73138, Avg fpr: 0.89401, total FA: 124131

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13582 | acc=0.9800 | tpr=0.9381 | fpr=0.0192 | 5155.6 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.14175 | acc=0.9793 | tpr=0.9488 | fpr=0.0202 | 7213.6 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.14750 | acc=0.9783 | tpr=0.9496 | fpr=0.0211 | 7796.5 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.15084 | acc=0.9781 | tpr=0.9530 | fpr=0.0214 | 8315.6 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.14869 | acc=0.9788 | tpr=0.9546 | fpr=0.0208 | 8166.9 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.15081 | acc=0.9785 | tpr=0.9527 | fpr=0.0210 | 8235.8 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.15184 | acc=0.9783 | tpr=0.9537 | fpr=0.0213 | 7897.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.15402 | acc=0.9779 | tpr=0.9502 | fpr=0.0216 | 8444.0 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.15764 | acc=0.9776 | tpr=0.9494 | fpr=0.0219 | 8229.9 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.15676 | acc=0.9776 | tpr=0.9489 | fpr=0.0219 | 8034.1 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.15581 | acc=0.9777 | tpr=0.9483 | fpr=0.0218 | 14845.7 samples/s | 58.0 steps/s
Avg test loss: 0.15543, Avg test acc: 0.97770, Avg tpr: 0.94731, Avg fpr: 0.02174, total FA: 3019

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15694 | acc=0.9768 | tpr=0.9513 | fpr=0.0227 | 5464.7 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.16291 | acc=0.9766 | tpr=0.9488 | fpr=0.0229 | 6727.4 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.16871 | acc=0.9760 | tpr=0.9553 | fpr=0.0237 | 7948.3 samples/s | 31.0 steps/s
[Step= 200] | Loss=0.17218 | acc=0.9760 | tpr=0.9596 | fpr=0.0237 | 8245.3 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.16919 | acc=0.9766 | tpr=0.9581 | fpr=0.0231 | 8024.0 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.17211 | acc=0.9762 | tpr=0.9556 | fpr=0.0234 | 8312.8 samples/s | 32.5 steps/s
[Step= 350] | Loss=0.17335 | acc=0.9759 | tpr=0.9562 | fpr=0.0237 | 8242.8 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.17531 | acc=0.9757 | tpr=0.9519 | fpr=0.0239 | 8021.9 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.17892 | acc=0.9754 | tpr=0.9518 | fpr=0.0242 | 7957.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.17815 | acc=0.9754 | tpr=0.9533 | fpr=0.0242 | 8256.9 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.17714 | acc=0.9755 | tpr=0.9515 | fpr=0.0240 | 14558.8 samples/s | 56.9 steps/s
Avg test loss: 0.17672, Avg test acc: 0.97552, Avg tpr: 0.95087, Avg fpr: 0.02403, total FA: 3337

server round 18/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=70.2] | Loss=0.00555 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.462 | L2-Norm(final)=7.128 | 6322.2 samples/s | 98.8 steps/s
[Step=36050 Epoch=70.3] | Loss=0.00726 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.460 | L2-Norm(final)=7.135 | 4809.5 samples/s | 75.1 steps/s
[Step=36100 Epoch=70.4] | Loss=0.00823 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.458 | L2-Norm(final)=7.143 | 5034.7 samples/s | 78.7 steps/s
[Step=36150 Epoch=70.5] | Loss=0.00782 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.455 | L2-Norm(final)=7.149 | 5133.0 samples/s | 80.2 steps/s
[Step=36200 Epoch=70.6] | Loss=0.00752 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.453 | L2-Norm(final)=7.155 | 5162.7 samples/s | 80.7 steps/s
[Step=36250 Epoch=70.7] | Loss=0.00742 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.450 | L2-Norm(final)=7.161 | 5183.9 samples/s | 81.0 steps/s
[Step=36300 Epoch=70.8] | Loss=0.00712 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.448 | L2-Norm(final)=7.168 | 5306.3 samples/s | 82.9 steps/s
[Step=36350 Epoch=70.9] | Loss=0.00727 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.446 | L2-Norm(final)=7.174 | 5232.6 samples/s | 81.8 steps/s
[Step=36400 Epoch=71.0] | Loss=0.00718 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.444 | L2-Norm(final)=7.180 | 5086.5 samples/s | 79.5 steps/s
[Step=36450 Epoch=71.1] | Loss=0.00719 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.442 | L2-Norm(final)=7.186 | 5342.3 samples/s | 83.5 steps/s
[Step=36500 Epoch=71.2] | Loss=0.00713 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.440 | L2-Norm(final)=7.191 | 6780.2 samples/s | 105.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=71.2] | Loss=0.00420 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.417 | L2-Norm(final)=7.249 | 6127.2 samples/s | 95.7 steps/s
[Step=36550 Epoch=71.3] | Loss=0.00698 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.415 | L2-Norm(final)=7.255 | 4295.6 samples/s | 67.1 steps/s
[Step=36600 Epoch=71.4] | Loss=0.00964 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.417 | L2-Norm(final)=7.258 | 4660.5 samples/s | 72.8 steps/s
[Step=36650 Epoch=71.5] | Loss=0.01053 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.422 | L2-Norm(final)=7.258 | 4609.9 samples/s | 72.0 steps/s
[Step=36700 Epoch=71.6] | Loss=0.01092 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.426 | L2-Norm(final)=7.257 | 4569.0 samples/s | 71.4 steps/s
[Step=36750 Epoch=71.7] | Loss=0.01089 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.430 | L2-Norm(final)=7.258 | 4635.4 samples/s | 72.4 steps/s
[Step=36800 Epoch=71.8] | Loss=0.01155 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.433 | L2-Norm(final)=7.258 | 4652.5 samples/s | 72.7 steps/s
[Step=36850 Epoch=71.9] | Loss=0.01137 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.436 | L2-Norm(final)=7.259 | 4598.0 samples/s | 71.8 steps/s
[Step=36900 Epoch=72.0] | Loss=0.01130 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.439 | L2-Norm(final)=7.259 | 4653.3 samples/s | 72.7 steps/s
[Step=36950 Epoch=72.1] | Loss=0.01127 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.442 | L2-Norm(final)=7.260 | 4604.3 samples/s | 71.9 steps/s
[Step=37000 Epoch=72.2] | Loss=0.01128 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.445 | L2-Norm(final)=7.261 | 5913.4 samples/s | 92.4 steps/s
[Step=37050 Epoch=72.3] | Loss=0.01126 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.448 | L2-Norm(final)=7.263 | 2454.8 samples/s | 38.4 steps/s
[Step=37100 Epoch=72.4] | Loss=0.01125 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.450 | L2-Norm(final)=7.264 | 4592.2 samples/s | 71.8 steps/s
[Step=37150 Epoch=72.5] | Loss=0.01119 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.453 | L2-Norm(final)=7.265 | 4568.8 samples/s | 71.4 steps/s
[Step=37200 Epoch=72.6] | Loss=0.01112 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.455 | L2-Norm(final)=7.266 | 4627.0 samples/s | 72.3 steps/s
[Step=37250 Epoch=72.7] | Loss=0.01111 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.456 | L2-Norm(final)=7.268 | 4590.7 samples/s | 71.7 steps/s
[Step=37300 Epoch=72.7] | Loss=0.01093 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.458 | L2-Norm(final)=7.269 | 4659.9 samples/s | 72.8 steps/s
[Step=37350 Epoch=72.8] | Loss=0.01102 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.459 | L2-Norm(final)=7.271 | 4602.1 samples/s | 71.9 steps/s
[Step=37400 Epoch=72.9] | Loss=0.01111 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.461 | L2-Norm(final)=7.272 | 4671.8 samples/s | 73.0 steps/s
[Step=37450 Epoch=73.0] | Loss=0.01105 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.463 | L2-Norm(final)=7.273 | 4571.1 samples/s | 71.4 steps/s
[Step=37500 Epoch=73.1] | Loss=0.01119 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.464 | L2-Norm(final)=7.274 | 4968.3 samples/s | 77.6 steps/s
[Step=37550 Epoch=73.2] | Loss=0.01127 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.466 | L2-Norm(final)=7.275 | 2687.3 samples/s | 42.0 steps/s
[Step=37600 Epoch=73.3] | Loss=0.01107 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.468 | L2-Norm(final)=7.276 | 4536.9 samples/s | 70.9 steps/s
[Step=37650 Epoch=73.4] | Loss=0.01095 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.470 | L2-Norm(final)=7.277 | 4731.5 samples/s | 73.9 steps/s
[Step=37700 Epoch=73.5] | Loss=0.01083 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.471 | L2-Norm(final)=7.278 | 4522.1 samples/s | 70.7 steps/s
[Step=37750 Epoch=73.6] | Loss=0.01078 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.473 | L2-Norm(final)=7.279 | 4659.6 samples/s | 72.8 steps/s
[Step=37800 Epoch=73.7] | Loss=0.01083 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.474 | L2-Norm(final)=7.280 | 4601.3 samples/s | 71.9 steps/s
[Step=37850 Epoch=73.8] | Loss=0.01089 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.475 | L2-Norm(final)=7.281 | 4657.0 samples/s | 72.8 steps/s
[Step=37900 Epoch=73.9] | Loss=0.01089 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.476 | L2-Norm(final)=7.282 | 4587.0 samples/s | 71.7 steps/s
[Step=37950 Epoch=74.0] | Loss=0.01087 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.477 | L2-Norm(final)=7.283 | 4703.4 samples/s | 73.5 steps/s
[Step=38000 Epoch=74.1] | Loss=0.01075 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.478 | L2-Norm(final)=7.284 | 4582.0 samples/s | 71.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step38000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=70.4] | Loss=0.00629 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.983 | L2-Norm(final)=7.449 | 6459.4 samples/s | 100.9 steps/s
[Step=36050 Epoch=70.5] | Loss=0.00635 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.981 | L2-Norm(final)=7.456 | 4712.9 samples/s | 73.6 steps/s
[Step=36100 Epoch=70.6] | Loss=0.00779 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.979 | L2-Norm(final)=7.464 | 5252.2 samples/s | 82.1 steps/s
[Step=36150 Epoch=70.7] | Loss=0.00726 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.977 | L2-Norm(final)=7.471 | 5099.9 samples/s | 79.7 steps/s
[Step=36200 Epoch=70.8] | Loss=0.00716 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.974 | L2-Norm(final)=7.479 | 5297.1 samples/s | 82.8 steps/s
[Step=36250 Epoch=70.9] | Loss=0.00742 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.972 | L2-Norm(final)=7.488 | 5054.2 samples/s | 79.0 steps/s
[Step=36300 Epoch=71.0] | Loss=0.00735 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.969 | L2-Norm(final)=7.496 | 5208.6 samples/s | 81.4 steps/s
[Step=36350 Epoch=71.1] | Loss=0.00739 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.967 | L2-Norm(final)=7.504 | 5217.1 samples/s | 81.5 steps/s
[Step=36400 Epoch=71.2] | Loss=0.00752 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.965 | L2-Norm(final)=7.511 | 5360.2 samples/s | 83.8 steps/s
[Step=36450 Epoch=71.3] | Loss=0.00735 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.963 | L2-Norm(final)=7.519 | 5088.2 samples/s | 79.5 steps/s
[Step=36500 Epoch=71.4] | Loss=0.00731 | Reg=0.00360 | acc=1.0000 | L2-Norm=18.961 | L2-Norm(final)=7.526 | 7077.2 samples/s | 110.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=71.4] | Loss=0.00561 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.941 | L2-Norm(final)=7.601 | 5892.9 samples/s | 92.1 steps/s
[Step=36550 Epoch=71.5] | Loss=0.00809 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.942 | L2-Norm(final)=7.608 | 4399.3 samples/s | 68.7 steps/s
[Step=36600 Epoch=71.6] | Loss=0.00837 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.946 | L2-Norm(final)=7.610 | 4591.9 samples/s | 71.7 steps/s
[Step=36650 Epoch=71.6] | Loss=0.00982 | Reg=0.00359 | acc=1.0000 | L2-Norm=18.953 | L2-Norm(final)=7.612 | 4698.2 samples/s | 73.4 steps/s
[Step=36700 Epoch=71.7] | Loss=0.01082 | Reg=0.00360 | acc=0.9688 | L2-Norm=18.962 | L2-Norm(final)=7.615 | 4562.6 samples/s | 71.3 steps/s
[Step=36750 Epoch=71.8] | Loss=0.01150 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.971 | L2-Norm(final)=7.617 | 4606.6 samples/s | 72.0 steps/s
[Step=36800 Epoch=71.9] | Loss=0.01269 | Reg=0.00360 | acc=0.9531 | L2-Norm=18.981 | L2-Norm(final)=7.617 | 4725.7 samples/s | 73.8 steps/s
[Step=36850 Epoch=72.0] | Loss=0.01315 | Reg=0.00361 | acc=1.0000 | L2-Norm=18.991 | L2-Norm(final)=7.619 | 4509.9 samples/s | 70.5 steps/s
[Step=36900 Epoch=72.1] | Loss=0.01329 | Reg=0.00361 | acc=0.9688 | L2-Norm=19.000 | L2-Norm(final)=7.620 | 4636.5 samples/s | 72.4 steps/s
[Step=36950 Epoch=72.2] | Loss=0.01332 | Reg=0.00361 | acc=1.0000 | L2-Norm=19.008 | L2-Norm(final)=7.622 | 4674.7 samples/s | 73.0 steps/s
[Step=37000 Epoch=72.3] | Loss=0.01366 | Reg=0.00362 | acc=0.9688 | L2-Norm=19.015 | L2-Norm(final)=7.622 | 6005.8 samples/s | 93.8 steps/s
[Step=37050 Epoch=72.4] | Loss=0.01340 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.022 | L2-Norm(final)=7.623 | 2426.7 samples/s | 37.9 steps/s
[Step=37100 Epoch=72.5] | Loss=0.01312 | Reg=0.00362 | acc=1.0000 | L2-Norm=19.029 | L2-Norm(final)=7.624 | 4581.6 samples/s | 71.6 steps/s
[Step=37150 Epoch=72.6] | Loss=0.01325 | Reg=0.00362 | acc=0.9688 | L2-Norm=19.035 | L2-Norm(final)=7.625 | 4661.3 samples/s | 72.8 steps/s
[Step=37200 Epoch=72.7] | Loss=0.01350 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.041 | L2-Norm(final)=7.626 | 4644.9 samples/s | 72.6 steps/s
[Step=37250 Epoch=72.8] | Loss=0.01337 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.047 | L2-Norm(final)=7.626 | 4571.0 samples/s | 71.4 steps/s
[Step=37300 Epoch=72.9] | Loss=0.01343 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.053 | L2-Norm(final)=7.627 | 4583.6 samples/s | 71.6 steps/s
[Step=37350 Epoch=73.0] | Loss=0.01348 | Reg=0.00363 | acc=1.0000 | L2-Norm=19.059 | L2-Norm(final)=7.628 | 4649.5 samples/s | 72.6 steps/s
[Step=37400 Epoch=73.1] | Loss=0.01361 | Reg=0.00363 | acc=0.9844 | L2-Norm=19.064 | L2-Norm(final)=7.629 | 4671.6 samples/s | 73.0 steps/s
[Step=37450 Epoch=73.2] | Loss=0.01342 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.069 | L2-Norm(final)=7.630 | 4593.8 samples/s | 71.8 steps/s
[Step=37500 Epoch=73.3] | Loss=0.01322 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.073 | L2-Norm(final)=7.631 | 5113.9 samples/s | 79.9 steps/s
[Step=37550 Epoch=73.4] | Loss=0.01309 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.077 | L2-Norm(final)=7.632 | 2629.3 samples/s | 41.1 steps/s
[Step=37600 Epoch=73.5] | Loss=0.01287 | Reg=0.00364 | acc=0.9844 | L2-Norm=19.081 | L2-Norm(final)=7.634 | 4589.0 samples/s | 71.7 steps/s
[Step=37650 Epoch=73.6] | Loss=0.01271 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.084 | L2-Norm(final)=7.635 | 4640.8 samples/s | 72.5 steps/s
[Step=37700 Epoch=73.7] | Loss=0.01254 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.087 | L2-Norm(final)=7.636 | 4605.5 samples/s | 72.0 steps/s
[Step=37750 Epoch=73.8] | Loss=0.01256 | Reg=0.00364 | acc=1.0000 | L2-Norm=19.089 | L2-Norm(final)=7.638 | 4639.0 samples/s | 72.5 steps/s
[Step=37800 Epoch=73.9] | Loss=0.01268 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.092 | L2-Norm(final)=7.639 | 4659.6 samples/s | 72.8 steps/s
[Step=37850 Epoch=74.0] | Loss=0.01260 | Reg=0.00365 | acc=0.9844 | L2-Norm=19.095 | L2-Norm(final)=7.640 | 4614.8 samples/s | 72.1 steps/s
[Step=37900 Epoch=74.1] | Loss=0.01254 | Reg=0.00365 | acc=0.9688 | L2-Norm=19.098 | L2-Norm(final)=7.641 | 4610.2 samples/s | 72.0 steps/s
[Step=37950 Epoch=74.2] | Loss=0.01254 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.101 | L2-Norm(final)=7.642 | 4644.1 samples/s | 72.6 steps/s
[Step=38000 Epoch=74.3] | Loss=0.01252 | Reg=0.00365 | acc=1.0000 | L2-Norm=19.103 | L2-Norm(final)=7.643 | 4625.0 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step38000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=137.9] | Loss=0.00003 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=5.850 | 6636.7 samples/s | 103.7 steps/s
[Step=36050 Epoch=138.1] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.103 | L2-Norm(final)=5.856 | 4156.0 samples/s | 64.9 steps/s
[Step=36100 Epoch=138.3] | Loss=0.00008 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.108 | L2-Norm(final)=5.862 | 4865.3 samples/s | 76.0 steps/s
[Step=36150 Epoch=138.5] | Loss=0.00006 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.112 | L2-Norm(final)=5.867 | 4900.8 samples/s | 76.6 steps/s
[Step=36200 Epoch=138.7] | Loss=0.00009 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.114 | L2-Norm(final)=5.872 | 4943.2 samples/s | 77.2 steps/s
[Step=36250 Epoch=138.9] | Loss=0.00008 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.122 | L2-Norm(final)=5.877 | 6793.0 samples/s | 106.1 steps/s
[Step=36300 Epoch=139.1] | Loss=0.00007 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.126 | L2-Norm(final)=5.882 | 2469.6 samples/s | 38.6 steps/s
[Step=36350 Epoch=139.3] | Loss=0.00007 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.127 | L2-Norm(final)=5.886 | 4950.4 samples/s | 77.3 steps/s
[Step=36400 Epoch=139.5] | Loss=0.00006 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.127 | L2-Norm(final)=5.890 | 4994.5 samples/s | 78.0 steps/s
[Step=36450 Epoch=139.7] | Loss=0.00006 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.126 | L2-Norm(final)=5.894 | 4978.6 samples/s | 77.8 steps/s
[Step=36500 Epoch=139.9] | Loss=0.00005 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.125 | L2-Norm(final)=5.898 | 5415.2 samples/s | 84.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=139.9] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.108 | L2-Norm(final)=5.935 | 6285.2 samples/s | 98.2 steps/s
[Step=36550 Epoch=140.0] | Loss=0.00002 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.097 | L2-Norm(final)=5.938 | 3998.0 samples/s | 62.5 steps/s
[Step=36600 Epoch=140.2] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.082 | L2-Norm(final)=5.940 | 4344.8 samples/s | 67.9 steps/s
[Step=36650 Epoch=140.4] | Loss=0.00001 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.067 | L2-Norm(final)=5.942 | 4352.8 samples/s | 68.0 steps/s
[Step=36700 Epoch=140.6] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.051 | L2-Norm(final)=5.944 | 4421.8 samples/s | 69.1 steps/s
[Step=36750 Epoch=140.8] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.036 | L2-Norm(final)=5.945 | 5745.0 samples/s | 89.8 steps/s
[Step=36800 Epoch=141.0] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.021 | L2-Norm(final)=5.947 | 2320.6 samples/s | 36.3 steps/s
[Step=36850 Epoch=141.2] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.007 | L2-Norm(final)=5.949 | 4435.1 samples/s | 69.3 steps/s
[Step=36900 Epoch=141.4] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.992 | L2-Norm(final)=5.951 | 4338.9 samples/s | 67.8 steps/s
[Step=36950 Epoch=141.6] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.976 | L2-Norm(final)=5.952 | 4431.2 samples/s | 69.2 steps/s
[Step=37000 Epoch=141.8] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.961 | L2-Norm(final)=5.954 | 4915.4 samples/s | 76.8 steps/s
[Step=37050 Epoch=142.0] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.945 | L2-Norm(final)=5.955 | 2501.7 samples/s | 39.1 steps/s
[Step=37100 Epoch=142.2] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.929 | L2-Norm(final)=5.956 | 4404.6 samples/s | 68.8 steps/s
[Step=37150 Epoch=142.3] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.914 | L2-Norm(final)=5.957 | 4401.6 samples/s | 68.8 steps/s
[Step=37200 Epoch=142.5] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.898 | L2-Norm(final)=5.958 | 4373.9 samples/s | 68.3 steps/s
[Step=37250 Epoch=142.7] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.881 | L2-Norm(final)=5.959 | 4363.1 samples/s | 68.2 steps/s
[Step=37300 Epoch=142.9] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=5.961 | 2662.2 samples/s | 41.6 steps/s
[Step=37350 Epoch=143.1] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.849 | L2-Norm(final)=5.962 | 4446.1 samples/s | 69.5 steps/s
[Step=37400 Epoch=143.3] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.833 | L2-Norm(final)=5.963 | 4331.7 samples/s | 67.7 steps/s
[Step=37450 Epoch=143.5] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.816 | L2-Norm(final)=5.964 | 4368.1 samples/s | 68.3 steps/s
[Step=37500 Epoch=143.7] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.799 | L2-Norm(final)=5.965 | 4437.9 samples/s | 69.3 steps/s
[Step=37550 Epoch=143.9] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.783 | L2-Norm(final)=5.966 | 2667.8 samples/s | 41.7 steps/s
[Step=37600 Epoch=144.1] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.766 | L2-Norm(final)=5.967 | 4350.6 samples/s | 68.0 steps/s
[Step=37650 Epoch=144.3] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.749 | L2-Norm(final)=5.968 | 4407.1 samples/s | 68.9 steps/s
[Step=37700 Epoch=144.5] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.732 | L2-Norm(final)=5.969 | 4459.9 samples/s | 69.7 steps/s
[Step=37750 Epoch=144.6] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.715 | L2-Norm(final)=5.970 | 4438.4 samples/s | 69.3 steps/s
[Step=37800 Epoch=144.8] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.698 | L2-Norm(final)=5.971 | 6232.1 samples/s | 97.4 steps/s
[Step=37850 Epoch=145.0] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.681 | L2-Norm(final)=5.972 | 2262.2 samples/s | 35.3 steps/s
[Step=37900 Epoch=145.2] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.663 | L2-Norm(final)=5.973 | 4319.2 samples/s | 67.5 steps/s
[Step=37950 Epoch=145.4] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.646 | L2-Norm(final)=5.974 | 4406.7 samples/s | 68.9 steps/s
[Step=38000 Epoch=145.6] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.628 | L2-Norm(final)=5.975 | 4326.4 samples/s | 67.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step38000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=138.6] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.033 | L2-Norm(final)=6.203 | 6384.4 samples/s | 99.8 steps/s
[Step=36050 Epoch=138.8] | Loss=0.00011 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.042 | L2-Norm(final)=6.208 | 4251.5 samples/s | 66.4 steps/s
[Step=36100 Epoch=139.0] | Loss=0.00008 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.052 | L2-Norm(final)=6.215 | 4913.7 samples/s | 76.8 steps/s
[Step=36150 Epoch=139.2] | Loss=0.00007 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.053 | L2-Norm(final)=6.221 | 4920.8 samples/s | 76.9 steps/s
[Step=36200 Epoch=139.3] | Loss=0.00008 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.059 | L2-Norm(final)=6.228 | 4902.0 samples/s | 76.6 steps/s
[Step=36250 Epoch=139.5] | Loss=0.00007 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.063 | L2-Norm(final)=6.235 | 6910.9 samples/s | 108.0 steps/s
[Step=36300 Epoch=139.7] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.065 | L2-Norm(final)=6.241 | 2510.9 samples/s | 39.2 steps/s
[Step=36350 Epoch=139.9] | Loss=0.00006 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.064 | L2-Norm(final)=6.247 | 4681.8 samples/s | 73.2 steps/s
[Step=36400 Epoch=140.1] | Loss=0.00005 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.062 | L2-Norm(final)=6.252 | 4926.2 samples/s | 77.0 steps/s
[Step=36450 Epoch=140.3] | Loss=0.00005 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.060 | L2-Norm(final)=6.257 | 4872.2 samples/s | 76.1 steps/s
[Step=36500 Epoch=140.5] | Loss=0.00005 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.058 | L2-Norm(final)=6.262 | 5875.2 samples/s | 91.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=140.5] | Loss=0.00001 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.036 | L2-Norm(final)=6.313 | 6218.0 samples/s | 97.2 steps/s
[Step=36550 Epoch=140.7] | Loss=0.00002 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.022 | L2-Norm(final)=6.316 | 3961.4 samples/s | 61.9 steps/s
[Step=36600 Epoch=140.9] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.005 | L2-Norm(final)=6.320 | 4357.6 samples/s | 68.1 steps/s
[Step=36650 Epoch=141.1] | Loss=0.00001 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.988 | L2-Norm(final)=6.323 | 4379.0 samples/s | 68.4 steps/s
[Step=36700 Epoch=141.3] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.970 | L2-Norm(final)=6.325 | 4385.2 samples/s | 68.5 steps/s
[Step=36750 Epoch=141.5] | Loss=0.00001 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.952 | L2-Norm(final)=6.327 | 5986.0 samples/s | 93.5 steps/s
[Step=36800 Epoch=141.7] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.935 | L2-Norm(final)=6.330 | 2310.1 samples/s | 36.1 steps/s
[Step=36850 Epoch=141.9] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.917 | L2-Norm(final)=6.332 | 4372.4 samples/s | 68.3 steps/s
[Step=36900 Epoch=142.0] | Loss=0.00001 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.899 | L2-Norm(final)=6.333 | 4365.7 samples/s | 68.2 steps/s
[Step=36950 Epoch=142.2] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.880 | L2-Norm(final)=6.335 | 4400.8 samples/s | 68.8 steps/s
[Step=37000 Epoch=142.4] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.862 | L2-Norm(final)=6.336 | 5109.4 samples/s | 79.8 steps/s
[Step=37050 Epoch=142.6] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.843 | L2-Norm(final)=6.337 | 2490.9 samples/s | 38.9 steps/s
[Step=37100 Epoch=142.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.824 | L2-Norm(final)=6.339 | 4333.2 samples/s | 67.7 steps/s
[Step=37150 Epoch=143.0] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.805 | L2-Norm(final)=6.340 | 4495.4 samples/s | 70.2 steps/s
[Step=37200 Epoch=143.2] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.786 | L2-Norm(final)=6.341 | 4295.5 samples/s | 67.1 steps/s
[Step=37250 Epoch=143.4] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.767 | L2-Norm(final)=6.342 | 4485.2 samples/s | 70.1 steps/s
[Step=37300 Epoch=143.6] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.748 | L2-Norm(final)=6.344 | 2647.1 samples/s | 41.4 steps/s
[Step=37350 Epoch=143.8] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.729 | L2-Norm(final)=6.345 | 4367.1 samples/s | 68.2 steps/s
[Step=37400 Epoch=144.0] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.709 | L2-Norm(final)=6.346 | 4420.2 samples/s | 69.1 steps/s
[Step=37450 Epoch=144.2] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.689 | L2-Norm(final)=6.347 | 4396.6 samples/s | 68.7 steps/s
[Step=37500 Epoch=144.4] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.670 | L2-Norm(final)=6.348 | 4353.2 samples/s | 68.0 steps/s
[Step=37550 Epoch=144.5] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.650 | L2-Norm(final)=6.350 | 2693.6 samples/s | 42.1 steps/s
[Step=37600 Epoch=144.7] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.630 | L2-Norm(final)=6.351 | 4437.4 samples/s | 69.3 steps/s
[Step=37650 Epoch=144.9] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.610 | L2-Norm(final)=6.352 | 4413.1 samples/s | 69.0 steps/s
[Step=37700 Epoch=145.1] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.589 | L2-Norm(final)=6.353 | 4286.2 samples/s | 67.0 steps/s
[Step=37750 Epoch=145.3] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.569 | L2-Norm(final)=6.355 | 4340.7 samples/s | 67.8 steps/s
[Step=37800 Epoch=145.5] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.548 | L2-Norm(final)=6.356 | 7217.9 samples/s | 112.8 steps/s
[Step=37850 Epoch=145.7] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.528 | L2-Norm(final)=6.358 | 2168.8 samples/s | 33.9 steps/s
[Step=37900 Epoch=145.9] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.507 | L2-Norm(final)=6.359 | 4451.2 samples/s | 69.5 steps/s
[Step=37950 Epoch=146.1] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.486 | L2-Norm(final)=6.360 | 4337.9 samples/s | 67.8 steps/s
[Step=38000 Epoch=146.3] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.465 | L2-Norm(final)=6.362 | 4347.7 samples/s | 67.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08813 | acc=0.9662 | tpr=0.9746 | fpr=0.0520 | 5229.5 samples/s | 20.4 steps/s
Avg test loss: 0.09099, Avg test acc: 0.96514, Avg tpr: 0.97430, Avg fpr: 0.05499, total FA: 429

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07436 | acc=0.9656 | tpr=0.9714 | fpr=0.0468 | 4885.8 samples/s | 19.1 steps/s
Avg test loss: 0.07677, Avg test acc: 0.96574, Avg tpr: 0.97144, Avg fpr: 0.04679, total FA: 365

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.30482 | acc=0.3046 | tpr=0.0080 | fpr=0.0513 | 5261.4 samples/s | 20.6 steps/s
Avg test loss: 5.30797, Avg test acc: 0.30223, Avg tpr: 0.00857, Avg fpr: 0.05192, total FA: 405

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.28965 | acc=0.3065 | tpr=0.0138 | fpr=0.0580 | 5111.5 samples/s | 20.0 steps/s
Avg test loss: 5.30351, Avg test acc: 0.30515, Avg tpr: 0.01323, Avg fpr: 0.05281, total FA: 412

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.23769 | acc=0.1173 | tpr=0.6858 | fpr=0.8929 | 4856.5 samples/s | 19.0 steps/s
[Step= 100] | Loss=7.19725 | acc=0.1192 | tpr=0.6844 | fpr=0.8913 | 7942.7 samples/s | 31.0 steps/s
[Step= 150] | Loss=7.18378 | acc=0.1200 | tpr=0.6945 | fpr=0.8906 | 8081.4 samples/s | 31.6 steps/s
[Step= 200] | Loss=7.19660 | acc=0.1192 | tpr=0.6885 | fpr=0.8912 | 8099.6 samples/s | 31.6 steps/s
[Step= 250] | Loss=7.19784 | acc=0.1194 | tpr=0.6873 | fpr=0.8909 | 8038.4 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.19827 | acc=0.1195 | tpr=0.6938 | fpr=0.8910 | 8138.9 samples/s | 31.8 steps/s
[Step= 350] | Loss=7.18882 | acc=0.1195 | tpr=0.6894 | fpr=0.8908 | 8049.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=7.18251 | acc=0.1204 | tpr=0.6937 | fpr=0.8900 | 8315.9 samples/s | 32.5 steps/s
[Step= 450] | Loss=7.18100 | acc=0.1197 | tpr=0.6933 | fpr=0.8907 | 8004.5 samples/s | 31.3 steps/s
[Step= 500] | Loss=7.18357 | acc=0.1198 | tpr=0.6912 | fpr=0.8905 | 8253.6 samples/s | 32.2 steps/s
[Step= 550] | Loss=7.18098 | acc=0.1200 | tpr=0.6876 | fpr=0.8904 | 14291.0 samples/s | 55.8 steps/s
Avg test loss: 7.18250, Avg test acc: 0.11985, Avg tpr: 0.68700, Avg fpr: 0.89046, total FA: 123639

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.86673 | acc=0.1278 | tpr=0.6150 | fpr=0.8809 | 5105.3 samples/s | 19.9 steps/s
[Step= 100] | Loss=5.83123 | acc=0.1283 | tpr=0.5970 | fpr=0.8805 | 7512.1 samples/s | 29.3 steps/s
[Step= 150] | Loss=5.82103 | acc=0.1290 | tpr=0.6066 | fpr=0.8798 | 7916.8 samples/s | 30.9 steps/s
[Step= 200] | Loss=5.82852 | acc=0.1281 | tpr=0.6077 | fpr=0.8806 | 8186.9 samples/s | 32.0 steps/s
[Step= 250] | Loss=5.82908 | acc=0.1289 | tpr=0.6061 | fpr=0.8798 | 7808.2 samples/s | 30.5 steps/s
[Step= 300] | Loss=5.83021 | acc=0.1291 | tpr=0.6131 | fpr=0.8797 | 8109.5 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.81838 | acc=0.1288 | tpr=0.6055 | fpr=0.8799 | 8036.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.81148 | acc=0.1293 | tpr=0.6007 | fpr=0.8792 | 8225.3 samples/s | 32.1 steps/s
[Step= 450] | Loss=5.80657 | acc=0.1289 | tpr=0.6022 | fpr=0.8797 | 8132.4 samples/s | 31.8 steps/s
[Step= 500] | Loss=5.80966 | acc=0.1287 | tpr=0.6013 | fpr=0.8799 | 7993.0 samples/s | 31.2 steps/s
[Step= 550] | Loss=5.80687 | acc=0.1290 | tpr=0.5973 | fpr=0.8795 | 14639.4 samples/s | 57.2 steps/s
Avg test loss: 5.80810, Avg test acc: 0.12892, Avg tpr: 0.59746, Avg fpr: 0.87960, total FA: 122131

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13949 | acc=0.9788 | tpr=0.9425 | fpr=0.0205 | 5308.4 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.14457 | acc=0.9785 | tpr=0.9531 | fpr=0.0210 | 7127.4 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.14959 | acc=0.9772 | tpr=0.9510 | fpr=0.0224 | 7872.9 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.15341 | acc=0.9770 | tpr=0.9519 | fpr=0.0226 | 7598.5 samples/s | 29.7 steps/s
[Step= 250] | Loss=0.15150 | acc=0.9775 | tpr=0.9537 | fpr=0.0221 | 8619.4 samples/s | 33.7 steps/s
[Step= 300] | Loss=0.15423 | acc=0.9771 | tpr=0.9505 | fpr=0.0224 | 8385.9 samples/s | 32.8 steps/s
[Step= 350] | Loss=0.15506 | acc=0.9769 | tpr=0.9518 | fpr=0.0227 | 8059.2 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.15702 | acc=0.9766 | tpr=0.9480 | fpr=0.0229 | 8256.8 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.16065 | acc=0.9763 | tpr=0.9474 | fpr=0.0232 | 7942.5 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15986 | acc=0.9763 | tpr=0.9471 | fpr=0.0232 | 8327.7 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.15881 | acc=0.9764 | tpr=0.9471 | fpr=0.0231 | 14336.0 samples/s | 56.0 steps/s
Avg test loss: 0.15843, Avg test acc: 0.97640, Avg tpr: 0.94612, Avg fpr: 0.02305, total FA: 3200

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15450 | acc=0.9777 | tpr=0.9558 | fpr=0.0220 | 4976.6 samples/s | 19.4 steps/s
[Step= 100] | Loss=0.16094 | acc=0.9770 | tpr=0.9531 | fpr=0.0225 | 8035.9 samples/s | 31.4 steps/s
[Step= 150] | Loss=0.16591 | acc=0.9763 | tpr=0.9553 | fpr=0.0233 | 7664.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.16979 | acc=0.9761 | tpr=0.9574 | fpr=0.0236 | 7997.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=0.16700 | acc=0.9766 | tpr=0.9581 | fpr=0.0230 | 8158.4 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.17025 | acc=0.9762 | tpr=0.9542 | fpr=0.0234 | 7928.1 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.17115 | acc=0.9760 | tpr=0.9549 | fpr=0.0236 | 8281.8 samples/s | 32.4 steps/s
[Step= 400] | Loss=0.17290 | acc=0.9757 | tpr=0.9502 | fpr=0.0238 | 7802.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.17642 | acc=0.9753 | tpr=0.9503 | fpr=0.0242 | 8550.7 samples/s | 33.4 steps/s
[Step= 500] | Loss=0.17571 | acc=0.9754 | tpr=0.9524 | fpr=0.0242 | 7967.2 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.17465 | acc=0.9755 | tpr=0.9511 | fpr=0.0241 | 14836.9 samples/s | 58.0 steps/s
Avg test loss: 0.17421, Avg test acc: 0.97550, Avg tpr: 0.95048, Avg fpr: 0.02404, total FA: 3338

server round 19/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=74.1] | Loss=0.00055 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.090 | L2-Norm(final)=7.321 | 6774.5 samples/s | 105.9 steps/s
[Step=38050 Epoch=74.2] | Loss=0.00756 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.088 | L2-Norm(final)=7.326 | 4422.6 samples/s | 69.1 steps/s
[Step=38100 Epoch=74.3] | Loss=0.00724 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.086 | L2-Norm(final)=7.332 | 5179.4 samples/s | 80.9 steps/s
[Step=38150 Epoch=74.4] | Loss=0.00710 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.084 | L2-Norm(final)=7.340 | 5178.7 samples/s | 80.9 steps/s
[Step=38200 Epoch=74.5] | Loss=0.00710 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.082 | L2-Norm(final)=7.348 | 5246.3 samples/s | 82.0 steps/s
[Step=38250 Epoch=74.6] | Loss=0.00688 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.080 | L2-Norm(final)=7.354 | 5187.4 samples/s | 81.1 steps/s
[Step=38300 Epoch=74.7] | Loss=0.00683 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.077 | L2-Norm(final)=7.361 | 5221.4 samples/s | 81.6 steps/s
[Step=38350 Epoch=74.8] | Loss=0.00686 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.074 | L2-Norm(final)=7.367 | 5135.5 samples/s | 80.2 steps/s
[Step=38400 Epoch=74.9] | Loss=0.00679 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.072 | L2-Norm(final)=7.372 | 5192.6 samples/s | 81.1 steps/s
[Step=38450 Epoch=75.0] | Loss=0.00663 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.070 | L2-Norm(final)=7.377 | 5204.7 samples/s | 81.3 steps/s
[Step=38500 Epoch=75.1] | Loss=0.00650 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.068 | L2-Norm(final)=7.383 | 6998.9 samples/s | 109.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=75.1] | Loss=0.01206 | Reg=0.00326 | acc=0.9844 | L2-Norm=18.048 | L2-Norm(final)=7.436 | 6841.1 samples/s | 106.9 steps/s
[Step=38550 Epoch=75.2] | Loss=0.00672 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.046 | L2-Norm(final)=7.440 | 4159.5 samples/s | 65.0 steps/s
[Step=38600 Epoch=75.3] | Loss=0.00916 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.046 | L2-Norm(final)=7.442 | 4668.5 samples/s | 72.9 steps/s
[Step=38650 Epoch=75.4] | Loss=0.01041 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.048 | L2-Norm(final)=7.439 | 4534.8 samples/s | 70.9 steps/s
[Step=38700 Epoch=75.5] | Loss=0.01157 | Reg=0.00326 | acc=0.9688 | L2-Norm=18.054 | L2-Norm(final)=7.439 | 4598.8 samples/s | 71.9 steps/s
[Step=38750 Epoch=75.6] | Loss=0.01243 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.063 | L2-Norm(final)=7.437 | 4612.0 samples/s | 72.1 steps/s
[Step=38800 Epoch=75.7] | Loss=0.01313 | Reg=0.00327 | acc=0.9531 | L2-Norm=18.072 | L2-Norm(final)=7.437 | 4663.0 samples/s | 72.9 steps/s
[Step=38850 Epoch=75.8] | Loss=0.01402 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.083 | L2-Norm(final)=7.437 | 4644.7 samples/s | 72.6 steps/s
[Step=38900 Epoch=75.9] | Loss=0.01434 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.095 | L2-Norm(final)=7.439 | 4661.0 samples/s | 72.8 steps/s
[Step=38950 Epoch=76.0] | Loss=0.01425 | Reg=0.00328 | acc=0.9688 | L2-Norm=18.106 | L2-Norm(final)=7.440 | 4565.7 samples/s | 71.3 steps/s
[Step=39000 Epoch=76.1] | Loss=0.01487 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.116 | L2-Norm(final)=7.441 | 5964.6 samples/s | 93.2 steps/s
[Step=39050 Epoch=76.2] | Loss=0.01483 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.126 | L2-Norm(final)=7.443 | 2433.8 samples/s | 38.0 steps/s
[Step=39100 Epoch=76.3] | Loss=0.01443 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.134 | L2-Norm(final)=7.444 | 4664.7 samples/s | 72.9 steps/s
[Step=39150 Epoch=76.4] | Loss=0.01419 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.142 | L2-Norm(final)=7.447 | 4665.5 samples/s | 72.9 steps/s
[Step=39200 Epoch=76.5] | Loss=0.01394 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.149 | L2-Norm(final)=7.449 | 4658.5 samples/s | 72.8 steps/s
[Step=39250 Epoch=76.6] | Loss=0.01388 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.156 | L2-Norm(final)=7.451 | 4576.9 samples/s | 71.5 steps/s
[Step=39300 Epoch=76.7] | Loss=0.01391 | Reg=0.00330 | acc=0.9688 | L2-Norm=18.163 | L2-Norm(final)=7.453 | 4678.7 samples/s | 73.1 steps/s
[Step=39350 Epoch=76.7] | Loss=0.01397 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.169 | L2-Norm(final)=7.454 | 4515.8 samples/s | 70.6 steps/s
[Step=39400 Epoch=76.8] | Loss=0.01408 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.175 | L2-Norm(final)=7.455 | 4677.7 samples/s | 73.1 steps/s
[Step=39450 Epoch=76.9] | Loss=0.01406 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.181 | L2-Norm(final)=7.456 | 4613.1 samples/s | 72.1 steps/s
[Step=39500 Epoch=77.0] | Loss=0.01397 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.187 | L2-Norm(final)=7.457 | 4954.7 samples/s | 77.4 steps/s
[Step=39550 Epoch=77.1] | Loss=0.01372 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.192 | L2-Norm(final)=7.458 | 2657.7 samples/s | 41.5 steps/s
[Step=39600 Epoch=77.2] | Loss=0.01366 | Reg=0.00331 | acc=0.9688 | L2-Norm=18.197 | L2-Norm(final)=7.459 | 4589.9 samples/s | 71.7 steps/s
[Step=39650 Epoch=77.3] | Loss=0.01350 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.201 | L2-Norm(final)=7.460 | 4625.8 samples/s | 72.3 steps/s
[Step=39700 Epoch=77.4] | Loss=0.01329 | Reg=0.00331 | acc=1.0000 | L2-Norm=18.205 | L2-Norm(final)=7.461 | 4665.1 samples/s | 72.9 steps/s
[Step=39750 Epoch=77.5] | Loss=0.01321 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.209 | L2-Norm(final)=7.463 | 4558.3 samples/s | 71.2 steps/s
[Step=39800 Epoch=77.6] | Loss=0.01304 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.213 | L2-Norm(final)=7.464 | 4649.0 samples/s | 72.6 steps/s
[Step=39850 Epoch=77.7] | Loss=0.01291 | Reg=0.00332 | acc=1.0000 | L2-Norm=18.216 | L2-Norm(final)=7.466 | 4662.4 samples/s | 72.9 steps/s
[Step=39900 Epoch=77.8] | Loss=0.01280 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.219 | L2-Norm(final)=7.467 | 4593.7 samples/s | 71.8 steps/s
[Step=39950 Epoch=77.9] | Loss=0.01267 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.223 | L2-Norm(final)=7.469 | 4670.2 samples/s | 73.0 steps/s
[Step=40000 Epoch=78.0] | Loss=0.01265 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.225 | L2-Norm(final)=7.470 | 4636.4 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step40000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=74.3] | Loss=0.00604 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.701 | L2-Norm(final)=7.671 | 6594.5 samples/s | 103.0 steps/s
[Step=38050 Epoch=74.4] | Loss=0.00831 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.700 | L2-Norm(final)=7.679 | 4577.0 samples/s | 71.5 steps/s
[Step=38100 Epoch=74.5] | Loss=0.00735 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.698 | L2-Norm(final)=7.687 | 5126.8 samples/s | 80.1 steps/s
[Step=38150 Epoch=74.6] | Loss=0.00713 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.696 | L2-Norm(final)=7.693 | 5130.4 samples/s | 80.2 steps/s
[Step=38200 Epoch=74.7] | Loss=0.00680 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.694 | L2-Norm(final)=7.699 | 5318.6 samples/s | 83.1 steps/s
[Step=38250 Epoch=74.8] | Loss=0.00669 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.691 | L2-Norm(final)=7.705 | 5184.2 samples/s | 81.0 steps/s
[Step=38300 Epoch=74.9] | Loss=0.00662 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.688 | L2-Norm(final)=7.711 | 5132.2 samples/s | 80.2 steps/s
[Step=38350 Epoch=75.0] | Loss=0.00652 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.685 | L2-Norm(final)=7.717 | 5287.3 samples/s | 82.6 steps/s
[Step=38400 Epoch=75.1] | Loss=0.00630 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.683 | L2-Norm(final)=7.722 | 5132.9 samples/s | 80.2 steps/s
[Step=38450 Epoch=75.2] | Loss=0.00633 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.679 | L2-Norm(final)=7.728 | 5246.8 samples/s | 82.0 steps/s
[Step=38500 Epoch=75.3] | Loss=0.00637 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.677 | L2-Norm(final)=7.733 | 7083.7 samples/s | 110.7 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=75.3] | Loss=0.02613 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.649 | L2-Norm(final)=7.786 | 5780.5 samples/s | 90.3 steps/s
[Step=38550 Epoch=75.4] | Loss=0.00643 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.647 | L2-Norm(final)=7.791 | 4434.8 samples/s | 69.3 steps/s
[Step=38600 Epoch=75.5] | Loss=0.00721 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.648 | L2-Norm(final)=7.794 | 4642.1 samples/s | 72.5 steps/s
[Step=38650 Epoch=75.6] | Loss=0.00842 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.650 | L2-Norm(final)=7.796 | 4582.9 samples/s | 71.6 steps/s
[Step=38700 Epoch=75.7] | Loss=0.00927 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.653 | L2-Norm(final)=7.797 | 4671.0 samples/s | 73.0 steps/s
[Step=38750 Epoch=75.8] | Loss=0.00936 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.657 | L2-Norm(final)=7.798 | 4600.2 samples/s | 71.9 steps/s
[Step=38800 Epoch=75.9] | Loss=0.00948 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.659 | L2-Norm(final)=7.800 | 4616.9 samples/s | 72.1 steps/s
[Step=38850 Epoch=76.0] | Loss=0.00969 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.661 | L2-Norm(final)=7.801 | 4579.0 samples/s | 71.5 steps/s
[Step=38900 Epoch=76.0] | Loss=0.01021 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.664 | L2-Norm(final)=7.803 | 4668.0 samples/s | 72.9 steps/s
[Step=38950 Epoch=76.1] | Loss=0.01092 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.668 | L2-Norm(final)=7.804 | 4590.8 samples/s | 71.7 steps/s
[Step=39000 Epoch=76.2] | Loss=0.01103 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.674 | L2-Norm(final)=7.804 | 6084.5 samples/s | 95.1 steps/s
[Step=39050 Epoch=76.3] | Loss=0.01114 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=7.806 | 2418.1 samples/s | 37.8 steps/s
[Step=39100 Epoch=76.4] | Loss=0.01156 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.686 | L2-Norm(final)=7.807 | 4665.7 samples/s | 72.9 steps/s
[Step=39150 Epoch=76.5] | Loss=0.01144 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.691 | L2-Norm(final)=7.808 | 4563.9 samples/s | 71.3 steps/s
[Step=39200 Epoch=76.6] | Loss=0.01153 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.696 | L2-Norm(final)=7.809 | 4604.1 samples/s | 71.9 steps/s
[Step=39250 Epoch=76.7] | Loss=0.01150 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.700 | L2-Norm(final)=7.810 | 4612.5 samples/s | 72.1 steps/s
[Step=39300 Epoch=76.8] | Loss=0.01141 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.705 | L2-Norm(final)=7.812 | 4675.1 samples/s | 73.0 steps/s
[Step=39350 Epoch=76.9] | Loss=0.01155 | Reg=0.00350 | acc=0.9844 | L2-Norm=18.709 | L2-Norm(final)=7.813 | 4623.5 samples/s | 72.2 steps/s
[Step=39400 Epoch=77.0] | Loss=0.01158 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.712 | L2-Norm(final)=7.814 | 4625.0 samples/s | 72.3 steps/s
[Step=39450 Epoch=77.1] | Loss=0.01150 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.716 | L2-Norm(final)=7.816 | 4610.8 samples/s | 72.0 steps/s
[Step=39500 Epoch=77.2] | Loss=0.01145 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.720 | L2-Norm(final)=7.818 | 5153.6 samples/s | 80.5 steps/s
[Step=39550 Epoch=77.3] | Loss=0.01136 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.724 | L2-Norm(final)=7.820 | 2611.0 samples/s | 40.8 steps/s
[Step=39600 Epoch=77.4] | Loss=0.01127 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.727 | L2-Norm(final)=7.822 | 4632.8 samples/s | 72.4 steps/s
[Step=39650 Epoch=77.5] | Loss=0.01120 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.730 | L2-Norm(final)=7.824 | 4683.8 samples/s | 73.2 steps/s
[Step=39700 Epoch=77.6] | Loss=0.01110 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.732 | L2-Norm(final)=7.826 | 4526.9 samples/s | 70.7 steps/s
[Step=39750 Epoch=77.7] | Loss=0.01094 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.735 | L2-Norm(final)=7.828 | 4637.8 samples/s | 72.5 steps/s
[Step=39800 Epoch=77.8] | Loss=0.01088 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.737 | L2-Norm(final)=7.830 | 4633.3 samples/s | 72.4 steps/s
[Step=39850 Epoch=77.9] | Loss=0.01080 | Reg=0.00351 | acc=1.0000 | L2-Norm=18.738 | L2-Norm(final)=7.832 | 4603.7 samples/s | 71.9 steps/s
[Step=39900 Epoch=78.0] | Loss=0.01067 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.740 | L2-Norm(final)=7.834 | 4650.0 samples/s | 72.7 steps/s
[Step=39950 Epoch=78.1] | Loss=0.01064 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.742 | L2-Norm(final)=7.836 | 4616.3 samples/s | 72.1 steps/s
[Step=40000 Epoch=78.2] | Loss=0.01057 | Reg=0.00351 | acc=0.9844 | L2-Norm=18.743 | L2-Norm(final)=7.838 | 4626.0 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step40000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=145.6] | Loss=0.00031 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.533 | L2-Norm(final)=6.007 | 6485.8 samples/s | 101.3 steps/s
[Step=38050 Epoch=145.8] | Loss=0.00017 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.563 | L2-Norm(final)=6.021 | 4189.9 samples/s | 65.5 steps/s
[Step=38100 Epoch=146.0] | Loss=0.00060 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.603 | L2-Norm(final)=6.040 | 5011.9 samples/s | 78.3 steps/s
[Step=38150 Epoch=146.2] | Loss=0.00081 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.657 | L2-Norm(final)=6.048 | 4775.5 samples/s | 74.6 steps/s
[Step=38200 Epoch=146.4] | Loss=0.00067 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.701 | L2-Norm(final)=6.054 | 4886.4 samples/s | 76.3 steps/s
[Step=38250 Epoch=146.6] | Loss=0.00056 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.730 | L2-Norm(final)=6.060 | 6817.1 samples/s | 106.5 steps/s
[Step=38300 Epoch=146.8] | Loss=0.00047 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.747 | L2-Norm(final)=6.066 | 2497.2 samples/s | 39.0 steps/s
[Step=38350 Epoch=146.9] | Loss=0.00041 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.757 | L2-Norm(final)=6.070 | 4717.8 samples/s | 73.7 steps/s
[Step=38400 Epoch=147.1] | Loss=0.00036 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.764 | L2-Norm(final)=6.074 | 4902.5 samples/s | 76.6 steps/s
[Step=38450 Epoch=147.3] | Loss=0.00033 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.768 | L2-Norm(final)=6.078 | 4925.2 samples/s | 77.0 steps/s
[Step=38500 Epoch=147.5] | Loss=0.00030 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.771 | L2-Norm(final)=6.082 | 5650.8 samples/s | 88.3 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=147.5] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.791 | L2-Norm(final)=6.118 | 6246.8 samples/s | 97.6 steps/s
[Step=38550 Epoch=147.7] | Loss=0.00003 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.776 | L2-Norm(final)=6.121 | 3941.0 samples/s | 61.6 steps/s
[Step=38600 Epoch=147.9] | Loss=0.00914 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.821 | L2-Norm(final)=6.106 | 4374.3 samples/s | 68.3 steps/s
[Step=38650 Epoch=148.1] | Loss=0.00911 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.943 | L2-Norm(final)=6.073 | 4385.4 samples/s | 68.5 steps/s
[Step=38700 Epoch=148.3] | Loss=0.00719 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.014 | L2-Norm(final)=6.051 | 4392.4 samples/s | 68.6 steps/s
[Step=38750 Epoch=148.5] | Loss=0.00584 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.058 | L2-Norm(final)=6.040 | 5843.9 samples/s | 91.3 steps/s
[Step=38800 Epoch=148.7] | Loss=0.00488 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.086 | L2-Norm(final)=6.035 | 2339.9 samples/s | 36.6 steps/s
[Step=38850 Epoch=148.9] | Loss=0.00428 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.105 | L2-Norm(final)=6.031 | 4329.5 samples/s | 67.6 steps/s
[Step=38900 Epoch=149.1] | Loss=0.00376 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.119 | L2-Norm(final)=6.029 | 4407.0 samples/s | 68.9 steps/s
[Step=38950 Epoch=149.2] | Loss=0.00336 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.128 | L2-Norm(final)=6.028 | 4400.1 samples/s | 68.8 steps/s
[Step=39000 Epoch=149.4] | Loss=0.00303 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.135 | L2-Norm(final)=6.027 | 4923.0 samples/s | 76.9 steps/s
[Step=39050 Epoch=149.6] | Loss=0.00277 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.140 | L2-Norm(final)=6.028 | 2504.8 samples/s | 39.1 steps/s
[Step=39100 Epoch=149.8] | Loss=0.00254 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.143 | L2-Norm(final)=6.028 | 4351.3 samples/s | 68.0 steps/s
[Step=39150 Epoch=150.0] | Loss=0.00234 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.145 | L2-Norm(final)=6.028 | 4502.7 samples/s | 70.4 steps/s
[Step=39200 Epoch=150.2] | Loss=0.00218 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.146 | L2-Norm(final)=6.029 | 4263.1 samples/s | 66.6 steps/s
[Step=39250 Epoch=150.4] | Loss=0.00203 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.146 | L2-Norm(final)=6.029 | 4401.9 samples/s | 68.8 steps/s
[Step=39300 Epoch=150.6] | Loss=0.00191 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.145 | L2-Norm(final)=6.030 | 2673.7 samples/s | 41.8 steps/s
[Step=39350 Epoch=150.8] | Loss=0.00180 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.144 | L2-Norm(final)=6.030 | 4455.0 samples/s | 69.6 steps/s
[Step=39400 Epoch=151.0] | Loss=0.00170 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.142 | L2-Norm(final)=6.031 | 4524.2 samples/s | 70.7 steps/s
[Step=39450 Epoch=151.2] | Loss=0.00161 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.140 | L2-Norm(final)=6.032 | 4204.9 samples/s | 65.7 steps/s
[Step=39500 Epoch=151.4] | Loss=0.00153 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.138 | L2-Norm(final)=6.032 | 4425.8 samples/s | 69.2 steps/s
[Step=39550 Epoch=151.5] | Loss=0.00146 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.135 | L2-Norm(final)=6.033 | 2684.8 samples/s | 41.9 steps/s
[Step=39600 Epoch=151.7] | Loss=0.00139 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.132 | L2-Norm(final)=6.034 | 4360.5 samples/s | 68.1 steps/s
[Step=39650 Epoch=151.9] | Loss=0.00133 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.129 | L2-Norm(final)=6.034 | 4384.0 samples/s | 68.5 steps/s
[Step=39700 Epoch=152.1] | Loss=0.00128 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.126 | L2-Norm(final)=6.035 | 4423.8 samples/s | 69.1 steps/s
[Step=39750 Epoch=152.3] | Loss=0.00123 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.122 | L2-Norm(final)=6.036 | 4368.6 samples/s | 68.3 steps/s
[Step=39800 Epoch=152.5] | Loss=0.00118 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.119 | L2-Norm(final)=6.037 | 6579.0 samples/s | 102.8 steps/s
[Step=39850 Epoch=152.7] | Loss=0.00114 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.115 | L2-Norm(final)=6.038 | 2238.3 samples/s | 35.0 steps/s
[Step=39900 Epoch=152.9] | Loss=0.00109 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.111 | L2-Norm(final)=6.039 | 4446.4 samples/s | 69.5 steps/s
[Step=39950 Epoch=153.1] | Loss=0.00106 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.107 | L2-Norm(final)=6.040 | 4421.4 samples/s | 69.1 steps/s
[Step=40000 Epoch=153.3] | Loss=0.00102 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.103 | L2-Norm(final)=6.041 | 4315.2 samples/s | 67.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step40000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=146.3] | Loss=0.00011 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=6.407 | 6270.4 samples/s | 98.0 steps/s
[Step=38050 Epoch=146.5] | Loss=0.00050 | Reg=0.00132 | acc=0.9844 | L2-Norm=11.483 | L2-Norm(final)=6.425 | 4288.6 samples/s | 67.0 steps/s
[Step=38100 Epoch=146.7] | Loss=0.00217 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.603 | L2-Norm(final)=6.419 | 4896.5 samples/s | 76.5 steps/s
[Step=38150 Epoch=146.9] | Loss=0.00152 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.677 | L2-Norm(final)=6.416 | 4891.9 samples/s | 76.4 steps/s
[Step=38200 Epoch=147.0] | Loss=0.00121 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.714 | L2-Norm(final)=6.417 | 4920.9 samples/s | 76.9 steps/s
[Step=38250 Epoch=147.2] | Loss=0.00102 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.738 | L2-Norm(final)=6.419 | 6936.8 samples/s | 108.4 steps/s
[Step=38300 Epoch=147.4] | Loss=0.00086 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.753 | L2-Norm(final)=6.421 | 2443.0 samples/s | 38.2 steps/s
[Step=38350 Epoch=147.6] | Loss=0.00075 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.764 | L2-Norm(final)=6.423 | 4861.7 samples/s | 76.0 steps/s
[Step=38400 Epoch=147.8] | Loss=0.00067 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.770 | L2-Norm(final)=6.425 | 5009.4 samples/s | 78.3 steps/s
[Step=38450 Epoch=148.0] | Loss=0.00060 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.774 | L2-Norm(final)=6.428 | 4792.0 samples/s | 74.9 steps/s
[Step=38500 Epoch=148.2] | Loss=0.00054 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.776 | L2-Norm(final)=6.430 | 5834.1 samples/s | 91.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=148.2] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.792 | L2-Norm(final)=6.449 | 6360.1 samples/s | 99.4 steps/s
[Step=38550 Epoch=148.4] | Loss=0.01193 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.873 | L2-Norm(final)=6.435 | 3867.7 samples/s | 60.4 steps/s
[Step=38600 Epoch=148.6] | Loss=0.01111 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.002 | L2-Norm(final)=6.403 | 4391.6 samples/s | 68.6 steps/s
[Step=38650 Epoch=148.8] | Loss=0.00851 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.064 | L2-Norm(final)=6.385 | 4433.9 samples/s | 69.3 steps/s
[Step=38700 Epoch=149.0] | Loss=0.00675 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=6.375 | 4390.3 samples/s | 68.6 steps/s
[Step=38750 Epoch=149.2] | Loss=0.00550 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.122 | L2-Norm(final)=6.370 | 5903.2 samples/s | 92.2 steps/s
[Step=38800 Epoch=149.4] | Loss=0.00459 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.136 | L2-Norm(final)=6.367 | 2312.5 samples/s | 36.1 steps/s
[Step=38850 Epoch=149.5] | Loss=0.00395 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.145 | L2-Norm(final)=6.365 | 4397.5 samples/s | 68.7 steps/s
[Step=38900 Epoch=149.7] | Loss=0.00346 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.150 | L2-Norm(final)=6.364 | 4343.8 samples/s | 67.9 steps/s
[Step=38950 Epoch=149.9] | Loss=0.00309 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.153 | L2-Norm(final)=6.364 | 4447.8 samples/s | 69.5 steps/s
[Step=39000 Epoch=150.1] | Loss=0.00278 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.155 | L2-Norm(final)=6.364 | 5031.1 samples/s | 78.6 steps/s
[Step=39050 Epoch=150.3] | Loss=0.00253 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.155 | L2-Norm(final)=6.364 | 2488.0 samples/s | 38.9 steps/s
[Step=39100 Epoch=150.5] | Loss=0.00232 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.155 | L2-Norm(final)=6.365 | 4444.2 samples/s | 69.4 steps/s
[Step=39150 Epoch=150.7] | Loss=0.00215 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.153 | L2-Norm(final)=6.365 | 4249.9 samples/s | 66.4 steps/s
[Step=39200 Epoch=150.9] | Loss=0.00199 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.151 | L2-Norm(final)=6.366 | 4418.8 samples/s | 69.0 steps/s
[Step=39250 Epoch=151.1] | Loss=0.00186 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.149 | L2-Norm(final)=6.366 | 4453.6 samples/s | 69.6 steps/s
[Step=39300 Epoch=151.3] | Loss=0.00175 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.146 | L2-Norm(final)=6.367 | 2653.8 samples/s | 41.5 steps/s
[Step=39350 Epoch=151.5] | Loss=0.00164 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.143 | L2-Norm(final)=6.367 | 4520.4 samples/s | 70.6 steps/s
[Step=39400 Epoch=151.7] | Loss=0.00155 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.139 | L2-Norm(final)=6.368 | 4235.1 samples/s | 66.2 steps/s
[Step=39450 Epoch=151.9] | Loss=0.00147 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.135 | L2-Norm(final)=6.368 | 4398.7 samples/s | 68.7 steps/s
[Step=39500 Epoch=152.1] | Loss=0.00140 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.132 | L2-Norm(final)=6.369 | 4353.2 samples/s | 68.0 steps/s
[Step=39550 Epoch=152.2] | Loss=0.00133 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.128 | L2-Norm(final)=6.370 | 2715.1 samples/s | 42.4 steps/s
[Step=39600 Epoch=152.4] | Loss=0.00127 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.123 | L2-Norm(final)=6.370 | 4389.9 samples/s | 68.6 steps/s
[Step=39650 Epoch=152.6] | Loss=0.00122 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.119 | L2-Norm(final)=6.371 | 4433.7 samples/s | 69.3 steps/s
[Step=39700 Epoch=152.8] | Loss=0.00117 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.115 | L2-Norm(final)=6.371 | 4255.4 samples/s | 66.5 steps/s
[Step=39750 Epoch=153.0] | Loss=0.00112 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.110 | L2-Norm(final)=6.372 | 4433.5 samples/s | 69.3 steps/s
[Step=39800 Epoch=153.2] | Loss=0.00108 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.106 | L2-Norm(final)=6.373 | 7006.6 samples/s | 109.5 steps/s
[Step=39850 Epoch=153.4] | Loss=0.00104 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.101 | L2-Norm(final)=6.374 | 2178.1 samples/s | 34.0 steps/s
[Step=39900 Epoch=153.6] | Loss=0.00100 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.096 | L2-Norm(final)=6.375 | 4327.0 samples/s | 67.6 steps/s
[Step=39950 Epoch=153.8] | Loss=0.00097 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.091 | L2-Norm(final)=6.376 | 4398.1 samples/s | 68.7 steps/s
[Step=40000 Epoch=154.0] | Loss=0.00094 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.086 | L2-Norm(final)=6.376 | 4391.2 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08679 | acc=0.9663 | tpr=0.9714 | fpr=0.0448 | 5196.8 samples/s | 20.3 steps/s
Avg test loss: 0.08755, Avg test acc: 0.96490, Avg tpr: 0.97173, Avg fpr: 0.05012, total FA: 391

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.09222 | acc=0.9682 | tpr=0.9795 | fpr=0.0562 | 5344.9 samples/s | 20.9 steps/s
Avg test loss: 0.09495, Avg test acc: 0.96706, Avg tpr: 0.97873, Avg fpr: 0.05858, total FA: 457

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.95907 | acc=0.3127 | tpr=0.0051 | fpr=0.0193 | 5424.7 samples/s | 21.2 steps/s
Avg test loss: 4.97018, Avg test acc: 0.31052, Avg tpr: 0.00577, Avg fpr: 0.01923, total FA: 150

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.11751 | acc=0.3108 | tpr=0.0081 | fpr=0.0320 | 5384.1 samples/s | 21.0 steps/s
Avg test loss: 5.13125, Avg test acc: 0.30900, Avg tpr: 0.00787, Avg fpr: 0.02871, total FA: 224

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.76851 | acc=0.1266 | tpr=0.6858 | fpr=0.8835 | 5432.5 samples/s | 21.2 steps/s
[Step= 100] | Loss=6.72888 | acc=0.1274 | tpr=0.6780 | fpr=0.8829 | 7480.8 samples/s | 29.2 steps/s
[Step= 150] | Loss=6.73717 | acc=0.1272 | tpr=0.6960 | fpr=0.8833 | 7689.4 samples/s | 30.0 steps/s
[Step= 200] | Loss=6.74882 | acc=0.1263 | tpr=0.6984 | fpr=0.8841 | 7624.0 samples/s | 29.8 steps/s
[Step= 250] | Loss=6.75306 | acc=0.1267 | tpr=0.6926 | fpr=0.8836 | 7921.9 samples/s | 30.9 steps/s
[Step= 300] | Loss=6.74712 | acc=0.1267 | tpr=0.6931 | fpr=0.8837 | 8310.7 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.73689 | acc=0.1266 | tpr=0.6850 | fpr=0.8835 | 7894.5 samples/s | 30.8 steps/s
[Step= 400] | Loss=6.73262 | acc=0.1271 | tpr=0.6904 | fpr=0.8831 | 8463.9 samples/s | 33.1 steps/s
[Step= 450] | Loss=6.73185 | acc=0.1265 | tpr=0.6904 | fpr=0.8837 | 7700.8 samples/s | 30.1 steps/s
[Step= 500] | Loss=6.73434 | acc=0.1265 | tpr=0.6894 | fpr=0.8837 | 8581.7 samples/s | 33.5 steps/s
[Step= 550] | Loss=6.73487 | acc=0.1266 | tpr=0.6872 | fpr=0.8836 | 14113.7 samples/s | 55.1 steps/s
Avg test loss: 6.73581, Avg test acc: 0.12660, Avg tpr: 0.68700, Avg fpr: 0.88358, total FA: 122684

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=8.13021 | acc=0.1065 | tpr=0.7655 | fpr=0.9054 | 5040.9 samples/s | 19.7 steps/s
[Step= 100] | Loss=8.10853 | acc=0.1075 | tpr=0.7719 | fpr=0.9049 | 7940.7 samples/s | 31.0 steps/s
[Step= 150] | Loss=8.11013 | acc=0.1084 | tpr=0.7781 | fpr=0.9039 | 7467.5 samples/s | 29.2 steps/s
[Step= 200] | Loss=8.12815 | acc=0.1081 | tpr=0.7803 | fpr=0.9041 | 8131.1 samples/s | 31.8 steps/s
[Step= 250] | Loss=8.12900 | acc=0.1088 | tpr=0.7755 | fpr=0.9034 | 8334.9 samples/s | 32.6 steps/s
[Step= 300] | Loss=8.13724 | acc=0.1085 | tpr=0.7789 | fpr=0.9037 | 7903.2 samples/s | 30.9 steps/s
[Step= 350] | Loss=8.12522 | acc=0.1088 | tpr=0.7765 | fpr=0.9033 | 8136.9 samples/s | 31.8 steps/s
[Step= 400] | Loss=8.11376 | acc=0.1095 | tpr=0.7790 | fpr=0.9026 | 7916.5 samples/s | 30.9 steps/s
[Step= 450] | Loss=8.10955 | acc=0.1089 | tpr=0.7746 | fpr=0.9031 | 8397.8 samples/s | 32.8 steps/s
[Step= 500] | Loss=8.11621 | acc=0.1089 | tpr=0.7740 | fpr=0.9031 | 8321.4 samples/s | 32.5 steps/s
[Step= 550] | Loss=8.11324 | acc=0.1093 | tpr=0.7700 | fpr=0.9027 | 14040.4 samples/s | 54.8 steps/s
Avg test loss: 8.11442, Avg test acc: 0.10924, Avg tpr: 0.77021, Avg fpr: 0.90278, total FA: 125349

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12759 | acc=0.9770 | tpr=0.9381 | fpr=0.0223 | 5212.4 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.13086 | acc=0.9767 | tpr=0.9467 | fpr=0.0228 | 7387.0 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.13831 | acc=0.9754 | tpr=0.9452 | fpr=0.0240 | 7822.6 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.14059 | acc=0.9754 | tpr=0.9454 | fpr=0.0240 | 8268.3 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.13917 | acc=0.9759 | tpr=0.9459 | fpr=0.0236 | 7837.3 samples/s | 30.6 steps/s
[Step= 300] | Loss=0.14219 | acc=0.9756 | tpr=0.9440 | fpr=0.0238 | 8187.8 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.14299 | acc=0.9753 | tpr=0.9455 | fpr=0.0241 | 8116.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.14472 | acc=0.9752 | tpr=0.9420 | fpr=0.0242 | 8336.8 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.14778 | acc=0.9748 | tpr=0.9416 | fpr=0.0246 | 8025.5 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.14721 | acc=0.9748 | tpr=0.9405 | fpr=0.0245 | 8358.7 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.14587 | acc=0.9751 | tpr=0.9407 | fpr=0.0243 | 14114.1 samples/s | 55.1 steps/s
Avg test loss: 0.14547, Avg test acc: 0.97507, Avg tpr: 0.93938, Avg fpr: 0.02429, total FA: 3372

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.16935 | acc=0.9765 | tpr=0.9425 | fpr=0.0229 | 5373.9 samples/s | 21.0 steps/s
[Step= 100] | Loss=0.17162 | acc=0.9768 | tpr=0.9510 | fpr=0.0228 | 7125.4 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.17763 | acc=0.9758 | tpr=0.9568 | fpr=0.0238 | 7592.0 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.18141 | acc=0.9753 | tpr=0.9574 | fpr=0.0243 | 8246.7 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.17740 | acc=0.9757 | tpr=0.9590 | fpr=0.0240 | 8161.2 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.18120 | acc=0.9754 | tpr=0.9549 | fpr=0.0242 | 8093.6 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.18338 | acc=0.9750 | tpr=0.9543 | fpr=0.0246 | 7916.7 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.18529 | acc=0.9748 | tpr=0.9513 | fpr=0.0248 | 8357.9 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.18878 | acc=0.9744 | tpr=0.9518 | fpr=0.0252 | 8199.4 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.18795 | acc=0.9744 | tpr=0.9537 | fpr=0.0252 | 8120.0 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.18660 | acc=0.9747 | tpr=0.9522 | fpr=0.0249 | 14084.9 samples/s | 55.0 steps/s
Avg test loss: 0.18614, Avg test acc: 0.97468, Avg tpr: 0.95166, Avg fpr: 0.02490, total FA: 3458

server round 20/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=78.0] | Loss=0.01229 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.077 | L2-Norm(final)=7.513 | 6832.2 samples/s | 106.8 steps/s
[Step=40050 Epoch=78.1] | Loss=0.01505 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.079 | L2-Norm(final)=7.517 | 4413.8 samples/s | 69.0 steps/s
[Step=40100 Epoch=78.2] | Loss=0.01615 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.081 | L2-Norm(final)=7.525 | 5205.5 samples/s | 81.3 steps/s
[Step=40150 Epoch=78.3] | Loss=0.01568 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.083 | L2-Norm(final)=7.532 | 5154.2 samples/s | 80.5 steps/s
[Step=40200 Epoch=78.4] | Loss=0.01484 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.085 | L2-Norm(final)=7.539 | 5277.0 samples/s | 82.5 steps/s
[Step=40250 Epoch=78.5] | Loss=0.01494 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.087 | L2-Norm(final)=7.547 | 5093.4 samples/s | 79.6 steps/s
[Step=40300 Epoch=78.6] | Loss=0.01453 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.089 | L2-Norm(final)=7.554 | 5371.1 samples/s | 83.9 steps/s
[Step=40350 Epoch=78.7] | Loss=0.01459 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.091 | L2-Norm(final)=7.562 | 5217.6 samples/s | 81.5 steps/s
[Step=40400 Epoch=78.8] | Loss=0.01441 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.093 | L2-Norm(final)=7.568 | 5060.1 samples/s | 79.1 steps/s
[Step=40450 Epoch=78.9] | Loss=0.01447 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=7.575 | 5204.2 samples/s | 81.3 steps/s
[Step=40500 Epoch=79.0] | Loss=0.01421 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.097 | L2-Norm(final)=7.581 | 7003.8 samples/s | 109.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=79.0] | Loss=0.00641 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.116 | L2-Norm(final)=7.646 | 6494.5 samples/s | 101.5 steps/s
[Step=40550 Epoch=79.1] | Loss=0.00990 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.120 | L2-Norm(final)=7.650 | 4075.0 samples/s | 63.7 steps/s
[Step=40600 Epoch=79.2] | Loss=0.01075 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.123 | L2-Norm(final)=7.654 | 4666.4 samples/s | 72.9 steps/s
[Step=40650 Epoch=79.3] | Loss=0.01051 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=7.657 | 4573.9 samples/s | 71.5 steps/s
[Step=40700 Epoch=79.4] | Loss=0.01015 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.659 | 4613.8 samples/s | 72.1 steps/s
[Step=40750 Epoch=79.5] | Loss=0.00976 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.662 | 4661.6 samples/s | 72.8 steps/s
[Step=40800 Epoch=79.6] | Loss=0.00951 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.664 | 4621.6 samples/s | 72.2 steps/s
[Step=40850 Epoch=79.7] | Loss=0.00937 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.666 | 4605.6 samples/s | 72.0 steps/s
[Step=40900 Epoch=79.8] | Loss=0.00917 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.668 | 4665.4 samples/s | 72.9 steps/s
[Step=40950 Epoch=79.9] | Loss=0.00896 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.125 | L2-Norm(final)=7.671 | 4703.0 samples/s | 73.5 steps/s
[Step=41000 Epoch=80.0] | Loss=0.00875 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=7.673 | 5838.8 samples/s | 91.2 steps/s
[Step=41050 Epoch=80.1] | Loss=0.00844 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.124 | L2-Norm(final)=7.675 | 2439.9 samples/s | 38.1 steps/s
[Step=41100 Epoch=80.2] | Loss=0.00833 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.123 | L2-Norm(final)=7.677 | 4621.1 samples/s | 72.2 steps/s
[Step=41150 Epoch=80.3] | Loss=0.00809 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.123 | L2-Norm(final)=7.679 | 4633.9 samples/s | 72.4 steps/s
[Step=41200 Epoch=80.4] | Loss=0.00787 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.122 | L2-Norm(final)=7.681 | 4710.3 samples/s | 73.6 steps/s
[Step=41250 Epoch=80.5] | Loss=0.00773 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.121 | L2-Norm(final)=7.682 | 4567.2 samples/s | 71.4 steps/s
[Step=41300 Epoch=80.6] | Loss=0.00759 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.120 | L2-Norm(final)=7.684 | 4627.3 samples/s | 72.3 steps/s
[Step=41350 Epoch=80.6] | Loss=0.00765 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.119 | L2-Norm(final)=7.686 | 4620.2 samples/s | 72.2 steps/s
[Step=41400 Epoch=80.7] | Loss=0.00764 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.118 | L2-Norm(final)=7.688 | 4658.1 samples/s | 72.8 steps/s
[Step=41450 Epoch=80.8] | Loss=0.00779 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.116 | L2-Norm(final)=7.689 | 4612.1 samples/s | 72.1 steps/s
[Step=41500 Epoch=80.9] | Loss=0.00770 | Reg=0.00328 | acc=0.9688 | L2-Norm=18.115 | L2-Norm(final)=7.691 | 4970.8 samples/s | 77.7 steps/s
[Step=41550 Epoch=81.0] | Loss=0.00760 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.114 | L2-Norm(final)=7.692 | 2649.1 samples/s | 41.4 steps/s
[Step=41600 Epoch=81.1] | Loss=0.00748 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.113 | L2-Norm(final)=7.693 | 4689.2 samples/s | 73.3 steps/s
[Step=41650 Epoch=81.2] | Loss=0.00736 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.111 | L2-Norm(final)=7.695 | 4501.5 samples/s | 70.3 steps/s
[Step=41700 Epoch=81.3] | Loss=0.00727 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.110 | L2-Norm(final)=7.697 | 4716.2 samples/s | 73.7 steps/s
[Step=41750 Epoch=81.4] | Loss=0.00726 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.109 | L2-Norm(final)=7.698 | 4542.0 samples/s | 71.0 steps/s
[Step=41800 Epoch=81.5] | Loss=0.00732 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.107 | L2-Norm(final)=7.699 | 4675.8 samples/s | 73.1 steps/s
[Step=41850 Epoch=81.6] | Loss=0.00730 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.105 | L2-Norm(final)=7.701 | 4628.4 samples/s | 72.3 steps/s
[Step=41900 Epoch=81.7] | Loss=0.00725 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.104 | L2-Norm(final)=7.702 | 4577.1 samples/s | 71.5 steps/s
[Step=41950 Epoch=81.8] | Loss=0.00722 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.102 | L2-Norm(final)=7.703 | 4637.4 samples/s | 72.5 steps/s
[Step=42000 Epoch=81.9] | Loss=0.00717 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.100 | L2-Norm(final)=7.705 | 4644.4 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step42000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=78.2] | Loss=0.01549 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.619 | L2-Norm(final)=7.903 | 6174.9 samples/s | 96.5 steps/s
[Step=40050 Epoch=78.3] | Loss=0.01380 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.621 | L2-Norm(final)=7.911 | 4769.5 samples/s | 74.5 steps/s
[Step=40100 Epoch=78.4] | Loss=0.01434 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.624 | L2-Norm(final)=7.922 | 5190.6 samples/s | 81.1 steps/s
[Step=40150 Epoch=78.5] | Loss=0.01364 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.627 | L2-Norm(final)=7.933 | 5170.9 samples/s | 80.8 steps/s
[Step=40200 Epoch=78.6] | Loss=0.01355 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.631 | L2-Norm(final)=7.943 | 5223.4 samples/s | 81.6 steps/s
[Step=40250 Epoch=78.7] | Loss=0.01376 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.634 | L2-Norm(final)=7.953 | 5218.0 samples/s | 81.5 steps/s
[Step=40300 Epoch=78.8] | Loss=0.01326 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.637 | L2-Norm(final)=7.961 | 5287.0 samples/s | 82.6 steps/s
[Step=40350 Epoch=78.9] | Loss=0.01309 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.640 | L2-Norm(final)=7.970 | 5251.2 samples/s | 82.1 steps/s
[Step=40400 Epoch=79.0] | Loss=0.01288 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.643 | L2-Norm(final)=7.978 | 5047.4 samples/s | 78.9 steps/s
[Step=40450 Epoch=79.1] | Loss=0.01255 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.646 | L2-Norm(final)=7.986 | 5310.2 samples/s | 83.0 steps/s
[Step=40500 Epoch=79.2] | Loss=0.01241 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.648 | L2-Norm(final)=7.994 | 6934.8 samples/s | 108.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=79.2] | Loss=0.01197 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.673 | L2-Norm(final)=8.074 | 6205.3 samples/s | 97.0 steps/s
[Step=40550 Epoch=79.3] | Loss=0.01010 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.676 | L2-Norm(final)=8.080 | 4279.2 samples/s | 66.9 steps/s
[Step=40600 Epoch=79.4] | Loss=0.01001 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.678 | L2-Norm(final)=8.084 | 4606.1 samples/s | 72.0 steps/s
[Step=40650 Epoch=79.5] | Loss=0.00901 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.679 | L2-Norm(final)=8.087 | 4612.1 samples/s | 72.1 steps/s
[Step=40700 Epoch=79.6] | Loss=0.00897 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.680 | L2-Norm(final)=8.091 | 4595.8 samples/s | 71.8 steps/s
[Step=40750 Epoch=79.7] | Loss=0.00882 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=8.094 | 4654.8 samples/s | 72.7 steps/s
[Step=40800 Epoch=79.8] | Loss=0.00900 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=8.096 | 4633.4 samples/s | 72.4 steps/s
[Step=40850 Epoch=79.9] | Loss=0.00910 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.680 | L2-Norm(final)=8.099 | 4623.2 samples/s | 72.2 steps/s
[Step=40900 Epoch=80.0] | Loss=0.00892 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=8.101 | 4558.8 samples/s | 71.2 steps/s
[Step=40950 Epoch=80.1] | Loss=0.00877 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.680 | L2-Norm(final)=8.103 | 4608.9 samples/s | 72.0 steps/s
[Step=41000 Epoch=80.2] | Loss=0.00875 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.679 | L2-Norm(final)=8.105 | 6077.9 samples/s | 95.0 steps/s
[Step=41050 Epoch=80.3] | Loss=0.00857 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.679 | L2-Norm(final)=8.107 | 2444.2 samples/s | 38.2 steps/s
[Step=41100 Epoch=80.3] | Loss=0.00848 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.678 | L2-Norm(final)=8.109 | 4577.7 samples/s | 71.5 steps/s
[Step=41150 Epoch=80.4] | Loss=0.00831 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.677 | L2-Norm(final)=8.111 | 4587.7 samples/s | 71.7 steps/s
[Step=41200 Epoch=80.5] | Loss=0.00815 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.676 | L2-Norm(final)=8.112 | 4604.1 samples/s | 71.9 steps/s
[Step=41250 Epoch=80.6] | Loss=0.00799 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.675 | L2-Norm(final)=8.114 | 4635.7 samples/s | 72.4 steps/s
[Step=41300 Epoch=80.7] | Loss=0.00789 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.673 | L2-Norm(final)=8.116 | 4624.8 samples/s | 72.3 steps/s
[Step=41350 Epoch=80.8] | Loss=0.00779 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.672 | L2-Norm(final)=8.118 | 4599.0 samples/s | 71.9 steps/s
[Step=41400 Epoch=80.9] | Loss=0.00774 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.671 | L2-Norm(final)=8.119 | 4671.5 samples/s | 73.0 steps/s
[Step=41450 Epoch=81.0] | Loss=0.00771 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.669 | L2-Norm(final)=8.121 | 4632.4 samples/s | 72.4 steps/s
[Step=41500 Epoch=81.1] | Loss=0.00760 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.668 | L2-Norm(final)=8.123 | 5065.4 samples/s | 79.1 steps/s
[Step=41550 Epoch=81.2] | Loss=0.00747 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.666 | L2-Norm(final)=8.124 | 2659.8 samples/s | 41.6 steps/s
[Step=41600 Epoch=81.3] | Loss=0.00739 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.664 | L2-Norm(final)=8.126 | 4471.1 samples/s | 69.9 steps/s
[Step=41650 Epoch=81.4] | Loss=0.00737 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.663 | L2-Norm(final)=8.128 | 4622.2 samples/s | 72.2 steps/s
[Step=41700 Epoch=81.5] | Loss=0.00725 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.661 | L2-Norm(final)=8.129 | 4611.3 samples/s | 72.1 steps/s
[Step=41750 Epoch=81.6] | Loss=0.00725 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.659 | L2-Norm(final)=8.131 | 4641.0 samples/s | 72.5 steps/s
[Step=41800 Epoch=81.7] | Loss=0.00718 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.657 | L2-Norm(final)=8.132 | 4616.7 samples/s | 72.1 steps/s
[Step=41850 Epoch=81.8] | Loss=0.00717 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.655 | L2-Norm(final)=8.134 | 4741.5 samples/s | 74.1 steps/s
[Step=41900 Epoch=81.9] | Loss=0.00712 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.653 | L2-Norm(final)=8.135 | 4515.7 samples/s | 70.6 steps/s
[Step=41950 Epoch=82.0] | Loss=0.00712 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.651 | L2-Norm(final)=8.137 | 4656.2 samples/s | 72.8 steps/s
[Step=42000 Epoch=82.1] | Loss=0.00707 | Reg=0.00348 | acc=1.0000 | L2-Norm=18.648 | L2-Norm(final)=8.139 | 4692.4 samples/s | 73.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step42000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=153.3] | Loss=0.00007 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.933 | L2-Norm(final)=6.077 | 6394.5 samples/s | 99.9 steps/s
[Step=40050 Epoch=153.5] | Loss=0.00013 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.936 | L2-Norm(final)=6.080 | 4258.4 samples/s | 66.5 steps/s
[Step=40100 Epoch=153.6] | Loss=0.00015 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.937 | L2-Norm(final)=6.082 | 4908.8 samples/s | 76.7 steps/s
[Step=40150 Epoch=153.8] | Loss=0.00013 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.941 | L2-Norm(final)=6.085 | 4897.7 samples/s | 76.5 steps/s
[Step=40200 Epoch=154.0] | Loss=0.00015 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.943 | L2-Norm(final)=6.087 | 4882.9 samples/s | 76.3 steps/s
[Step=40250 Epoch=154.2] | Loss=0.00014 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.945 | L2-Norm(final)=6.089 | 6841.1 samples/s | 106.9 steps/s
[Step=40300 Epoch=154.4] | Loss=0.00012 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.947 | L2-Norm(final)=6.091 | 2517.8 samples/s | 39.3 steps/s
[Step=40350 Epoch=154.6] | Loss=0.00011 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.948 | L2-Norm(final)=6.093 | 4919.7 samples/s | 76.9 steps/s
[Step=40400 Epoch=154.8] | Loss=0.00010 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.948 | L2-Norm(final)=6.095 | 4875.3 samples/s | 76.2 steps/s
[Step=40450 Epoch=155.0] | Loss=0.00010 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.948 | L2-Norm(final)=6.097 | 4896.5 samples/s | 76.5 steps/s
[Step=40500 Epoch=155.2] | Loss=0.00009 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.948 | L2-Norm(final)=6.098 | 5611.9 samples/s | 87.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=155.2] | Loss=0.00003 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.943 | L2-Norm(final)=6.116 | 5805.2 samples/s | 90.7 steps/s
[Step=40550 Epoch=155.4] | Loss=0.00005 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.941 | L2-Norm(final)=6.118 | 4177.3 samples/s | 65.3 steps/s
[Step=40600 Epoch=155.6] | Loss=0.00003 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.939 | L2-Norm(final)=6.119 | 4306.6 samples/s | 67.3 steps/s
[Step=40650 Epoch=155.8] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.935 | L2-Norm(final)=6.121 | 4351.0 samples/s | 68.0 steps/s
[Step=40700 Epoch=155.9] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.932 | L2-Norm(final)=6.122 | 4394.2 samples/s | 68.7 steps/s
[Step=40750 Epoch=156.1] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.928 | L2-Norm(final)=6.123 | 5889.8 samples/s | 92.0 steps/s
[Step=40800 Epoch=156.3] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.924 | L2-Norm(final)=6.124 | 2338.1 samples/s | 36.5 steps/s
[Step=40850 Epoch=156.5] | Loss=0.00003 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.920 | L2-Norm(final)=6.125 | 4346.4 samples/s | 67.9 steps/s
[Step=40900 Epoch=156.7] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.916 | L2-Norm(final)=6.126 | 4373.6 samples/s | 68.3 steps/s
[Step=40950 Epoch=156.9] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.912 | L2-Norm(final)=6.127 | 4406.4 samples/s | 68.8 steps/s
[Step=41000 Epoch=157.1] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.908 | L2-Norm(final)=6.128 | 4926.0 samples/s | 77.0 steps/s
[Step=41050 Epoch=157.3] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.903 | L2-Norm(final)=6.128 | 2515.9 samples/s | 39.3 steps/s
[Step=41100 Epoch=157.5] | Loss=0.00002 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.899 | L2-Norm(final)=6.129 | 4385.8 samples/s | 68.5 steps/s
[Step=41150 Epoch=157.7] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=6.130 | 4342.1 samples/s | 67.8 steps/s
[Step=41200 Epoch=157.9] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.890 | L2-Norm(final)=6.131 | 4397.1 samples/s | 68.7 steps/s
[Step=41250 Epoch=158.1] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.886 | L2-Norm(final)=6.132 | 4361.4 samples/s | 68.1 steps/s
[Step=41300 Epoch=158.2] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.881 | L2-Norm(final)=6.132 | 2702.4 samples/s | 42.2 steps/s
[Step=41350 Epoch=158.4] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.877 | L2-Norm(final)=6.133 | 4367.7 samples/s | 68.2 steps/s
[Step=41400 Epoch=158.6] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.872 | L2-Norm(final)=6.134 | 4381.8 samples/s | 68.5 steps/s
[Step=41450 Epoch=158.8] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.867 | L2-Norm(final)=6.135 | 4434.1 samples/s | 69.3 steps/s
[Step=41500 Epoch=159.0] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.863 | L2-Norm(final)=6.135 | 4365.8 samples/s | 68.2 steps/s
[Step=41550 Epoch=159.2] | Loss=0.00001 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.858 | L2-Norm(final)=6.136 | 2684.6 samples/s | 41.9 steps/s
[Step=41600 Epoch=159.4] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.853 | L2-Norm(final)=6.137 | 4354.3 samples/s | 68.0 steps/s
[Step=41650 Epoch=159.6] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.848 | L2-Norm(final)=6.138 | 4373.6 samples/s | 68.3 steps/s
[Step=41700 Epoch=159.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.843 | L2-Norm(final)=6.138 | 4368.2 samples/s | 68.3 steps/s
[Step=41750 Epoch=160.0] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.838 | L2-Norm(final)=6.139 | 4386.4 samples/s | 68.5 steps/s
[Step=41800 Epoch=160.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.833 | L2-Norm(final)=6.140 | 6408.4 samples/s | 100.1 steps/s
[Step=41850 Epoch=160.4] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.828 | L2-Norm(final)=6.141 | 2237.0 samples/s | 35.0 steps/s
[Step=41900 Epoch=160.5] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.823 | L2-Norm(final)=6.142 | 4265.4 samples/s | 66.6 steps/s
[Step=41950 Epoch=160.7] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.818 | L2-Norm(final)=6.142 | 4327.4 samples/s | 67.6 steps/s
[Step=42000 Epoch=160.9] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.812 | L2-Norm(final)=6.143 | 4405.7 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step42000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=154.0] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.886 | L2-Norm(final)=6.405 | 6712.4 samples/s | 104.9 steps/s
[Step=40050 Epoch=154.2] | Loss=0.00050 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.893 | L2-Norm(final)=6.402 | 4416.4 samples/s | 69.0 steps/s
[Step=40100 Epoch=154.4] | Loss=0.00031 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.894 | L2-Norm(final)=6.403 | 4846.3 samples/s | 75.7 steps/s
[Step=40150 Epoch=154.6] | Loss=0.00025 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.894 | L2-Norm(final)=6.405 | 4901.5 samples/s | 76.6 steps/s
[Step=40200 Epoch=154.7] | Loss=0.00022 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.894 | L2-Norm(final)=6.407 | 4811.4 samples/s | 75.2 steps/s
[Step=40250 Epoch=154.9] | Loss=0.00022 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.894 | L2-Norm(final)=6.410 | 7046.3 samples/s | 110.1 steps/s
[Step=40300 Epoch=155.1] | Loss=0.00020 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.894 | L2-Norm(final)=6.412 | 2451.0 samples/s | 38.3 steps/s
[Step=40350 Epoch=155.3] | Loss=0.00018 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=6.414 | 5066.0 samples/s | 79.2 steps/s
[Step=40400 Epoch=155.5] | Loss=0.00017 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=6.416 | 4704.4 samples/s | 73.5 steps/s
[Step=40450 Epoch=155.7] | Loss=0.00016 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=6.418 | 4946.5 samples/s | 77.3 steps/s
[Step=40500 Epoch=155.9] | Loss=0.00014 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.895 | L2-Norm(final)=6.420 | 5833.6 samples/s | 91.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=155.9] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.890 | L2-Norm(final)=6.440 | 6100.5 samples/s | 95.3 steps/s
[Step=40550 Epoch=156.1] | Loss=0.00005 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.889 | L2-Norm(final)=6.443 | 3955.3 samples/s | 61.8 steps/s
[Step=40600 Epoch=156.3] | Loss=0.00004 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.886 | L2-Norm(final)=6.444 | 4495.0 samples/s | 70.2 steps/s
[Step=40650 Epoch=156.5] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.883 | L2-Norm(final)=6.445 | 4336.2 samples/s | 67.8 steps/s
[Step=40700 Epoch=156.7] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.879 | L2-Norm(final)=6.446 | 4351.6 samples/s | 68.0 steps/s
[Step=40750 Epoch=156.9] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.876 | L2-Norm(final)=6.447 | 5984.1 samples/s | 93.5 steps/s
[Step=40800 Epoch=157.1] | Loss=0.00003 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.872 | L2-Norm(final)=6.448 | 2326.0 samples/s | 36.3 steps/s
[Step=40850 Epoch=157.2] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.869 | L2-Norm(final)=6.449 | 4356.4 samples/s | 68.1 steps/s
[Step=40900 Epoch=157.4] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=6.450 | 4367.8 samples/s | 68.2 steps/s
[Step=40950 Epoch=157.6] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.861 | L2-Norm(final)=6.451 | 4368.0 samples/s | 68.3 steps/s
[Step=41000 Epoch=157.8] | Loss=0.00002 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.856 | L2-Norm(final)=6.451 | 5122.6 samples/s | 80.0 steps/s
[Step=41050 Epoch=158.0] | Loss=0.00002 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.852 | L2-Norm(final)=6.452 | 2457.6 samples/s | 38.4 steps/s
[Step=41100 Epoch=158.2] | Loss=0.00002 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.848 | L2-Norm(final)=6.452 | 4423.7 samples/s | 69.1 steps/s
[Step=41150 Epoch=158.4] | Loss=0.00002 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.844 | L2-Norm(final)=6.453 | 4417.9 samples/s | 69.0 steps/s
[Step=41200 Epoch=158.6] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.839 | L2-Norm(final)=6.453 | 4286.3 samples/s | 67.0 steps/s
[Step=41250 Epoch=158.8] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.835 | L2-Norm(final)=6.454 | 4497.8 samples/s | 70.3 steps/s
[Step=41300 Epoch=159.0] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.830 | L2-Norm(final)=6.454 | 2654.7 samples/s | 41.5 steps/s
[Step=41350 Epoch=159.2] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.826 | L2-Norm(final)=6.454 | 4391.9 samples/s | 68.6 steps/s
[Step=41400 Epoch=159.4] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.821 | L2-Norm(final)=6.455 | 4380.3 samples/s | 68.4 steps/s
[Step=41450 Epoch=159.6] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.816 | L2-Norm(final)=6.455 | 4330.4 samples/s | 67.7 steps/s
[Step=41500 Epoch=159.7] | Loss=0.00001 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.811 | L2-Norm(final)=6.456 | 4385.6 samples/s | 68.5 steps/s
[Step=41550 Epoch=159.9] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.807 | L2-Norm(final)=6.456 | 2691.0 samples/s | 42.0 steps/s
[Step=41600 Epoch=160.1] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.802 | L2-Norm(final)=6.456 | 4346.0 samples/s | 67.9 steps/s
[Step=41650 Epoch=160.3] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.797 | L2-Norm(final)=6.457 | 4432.4 samples/s | 69.3 steps/s
[Step=41700 Epoch=160.5] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.792 | L2-Norm(final)=6.457 | 4418.6 samples/s | 69.0 steps/s
[Step=41750 Epoch=160.7] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.787 | L2-Norm(final)=6.457 | 4312.3 samples/s | 67.4 steps/s
[Step=41800 Epoch=160.9] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.781 | L2-Norm(final)=6.458 | 7021.2 samples/s | 109.7 steps/s
[Step=41850 Epoch=161.1] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.776 | L2-Norm(final)=6.458 | 2119.1 samples/s | 33.1 steps/s
[Step=41900 Epoch=161.3] | Loss=0.00001 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.771 | L2-Norm(final)=6.458 | 4268.3 samples/s | 66.7 steps/s
[Step=41950 Epoch=161.5] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.766 | L2-Norm(final)=6.459 | 4267.6 samples/s | 66.7 steps/s
[Step=42000 Epoch=161.7] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.760 | L2-Norm(final)=6.459 | 4320.8 samples/s | 67.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.09019 | acc=0.9687 | tpr=0.9771 | fpr=0.0496 | 5503.0 samples/s | 21.5 steps/s
Avg test loss: 0.09126, Avg test acc: 0.96731, Avg tpr: 0.97692, Avg fpr: 0.05384, total FA: 420

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07830 | acc=0.9682 | tpr=0.9751 | fpr=0.0468 | 5361.7 samples/s | 20.9 steps/s
Avg test loss: 0.08170, Avg test acc: 0.96787, Avg tpr: 0.97494, Avg fpr: 0.04769, total FA: 372

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.26771 | acc=0.3087 | tpr=0.0087 | fpr=0.0399 | 5453.4 samples/s | 21.3 steps/s
Avg test loss: 5.27840, Avg test acc: 0.30732, Avg tpr: 0.00927, Avg fpr: 0.03717, total FA: 290

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.70403 | acc=0.2996 | tpr=0.0126 | fpr=0.0771 | 5303.2 samples/s | 20.7 steps/s
Avg test loss: 5.71783, Avg test acc: 0.29818, Avg tpr: 0.01276, Avg fpr: 0.07409, total FA: 578

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.31863 | acc=0.1183 | tpr=0.7124 | fpr=0.8924 | 5386.8 samples/s | 21.0 steps/s
[Step= 100] | Loss=7.28892 | acc=0.1180 | tpr=0.7143 | fpr=0.8932 | 7266.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=7.28889 | acc=0.1190 | tpr=0.7205 | fpr=0.8921 | 7489.1 samples/s | 29.3 steps/s
[Step= 200] | Loss=7.30278 | acc=0.1180 | tpr=0.7202 | fpr=0.8929 | 7910.3 samples/s | 30.9 steps/s
[Step= 250] | Loss=7.30618 | acc=0.1184 | tpr=0.7100 | fpr=0.8924 | 8376.7 samples/s | 32.7 steps/s
[Step= 300] | Loss=7.30205 | acc=0.1182 | tpr=0.7142 | fpr=0.8927 | 8357.8 samples/s | 32.6 steps/s
[Step= 350] | Loss=7.29165 | acc=0.1179 | tpr=0.7126 | fpr=0.8929 | 8017.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=7.27909 | acc=0.1183 | tpr=0.7144 | fpr=0.8926 | 8277.7 samples/s | 32.3 steps/s
[Step= 450] | Loss=7.27919 | acc=0.1176 | tpr=0.7137 | fpr=0.8932 | 7975.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=7.28147 | acc=0.1176 | tpr=0.7154 | fpr=0.8932 | 8260.0 samples/s | 32.3 steps/s
[Step= 550] | Loss=7.28200 | acc=0.1179 | tpr=0.7115 | fpr=0.8928 | 13907.8 samples/s | 54.3 steps/s
Avg test loss: 7.28272, Avg test acc: 0.11785, Avg tpr: 0.71078, Avg fpr: 0.89293, total FA: 123982

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.17882 | acc=0.1251 | tpr=0.6858 | fpr=0.8850 | 5391.1 samples/s | 21.1 steps/s
[Step= 100] | Loss=7.15443 | acc=0.1247 | tpr=0.6588 | fpr=0.8853 | 7417.9 samples/s | 29.0 steps/s
[Step= 150] | Loss=7.14857 | acc=0.1260 | tpr=0.6657 | fpr=0.8839 | 7412.5 samples/s | 29.0 steps/s
[Step= 200] | Loss=7.15736 | acc=0.1252 | tpr=0.6678 | fpr=0.8847 | 8165.1 samples/s | 31.9 steps/s
[Step= 250] | Loss=7.15708 | acc=0.1257 | tpr=0.6672 | fpr=0.8841 | 7936.1 samples/s | 31.0 steps/s
[Step= 300] | Loss=7.16008 | acc=0.1251 | tpr=0.6698 | fpr=0.8848 | 8261.9 samples/s | 32.3 steps/s
[Step= 350] | Loss=7.14792 | acc=0.1251 | tpr=0.6662 | fpr=0.8847 | 8389.2 samples/s | 32.8 steps/s
[Step= 400] | Loss=7.13966 | acc=0.1257 | tpr=0.6658 | fpr=0.8842 | 7827.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=7.13702 | acc=0.1252 | tpr=0.6641 | fpr=0.8845 | 8202.9 samples/s | 32.0 steps/s
[Step= 500] | Loss=7.14054 | acc=0.1250 | tpr=0.6634 | fpr=0.8847 | 7929.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=7.13743 | acc=0.1253 | tpr=0.6594 | fpr=0.8844 | 14712.5 samples/s | 57.5 steps/s
Avg test loss: 7.13810, Avg test acc: 0.12519, Avg tpr: 0.65887, Avg fpr: 0.88451, total FA: 122813

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14896 | acc=0.9767 | tpr=0.9469 | fpr=0.0227 | 5451.2 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.15267 | acc=0.9768 | tpr=0.9531 | fpr=0.0228 | 7127.8 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.15866 | acc=0.9754 | tpr=0.9524 | fpr=0.0242 | 7669.9 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.16148 | acc=0.9752 | tpr=0.9497 | fpr=0.0243 | 7694.3 samples/s | 30.1 steps/s
[Step= 250] | Loss=0.15933 | acc=0.9757 | tpr=0.9493 | fpr=0.0239 | 8534.4 samples/s | 33.3 steps/s
[Step= 300] | Loss=0.16239 | acc=0.9753 | tpr=0.9491 | fpr=0.0242 | 7517.8 samples/s | 29.4 steps/s
[Step= 350] | Loss=0.16345 | acc=0.9750 | tpr=0.9512 | fpr=0.0246 | 8752.7 samples/s | 34.2 steps/s
[Step= 400] | Loss=0.16547 | acc=0.9748 | tpr=0.9480 | fpr=0.0247 | 7847.9 samples/s | 30.7 steps/s
[Step= 450] | Loss=0.16905 | acc=0.9744 | tpr=0.9489 | fpr=0.0251 | 8262.8 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.16829 | acc=0.9744 | tpr=0.9493 | fpr=0.0252 | 8139.9 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.16705 | acc=0.9746 | tpr=0.9479 | fpr=0.0250 | 14066.1 samples/s | 54.9 steps/s
Avg test loss: 0.16664, Avg test acc: 0.97457, Avg tpr: 0.94691, Avg fpr: 0.02493, total FA: 3461

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.18051 | acc=0.9766 | tpr=0.9513 | fpr=0.0230 | 5422.3 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.18479 | acc=0.9760 | tpr=0.9510 | fpr=0.0236 | 7129.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.19213 | acc=0.9748 | tpr=0.9553 | fpr=0.0248 | 7575.2 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.19655 | acc=0.9745 | tpr=0.9585 | fpr=0.0252 | 7763.0 samples/s | 30.3 steps/s
[Step= 250] | Loss=0.19308 | acc=0.9750 | tpr=0.9590 | fpr=0.0247 | 8483.7 samples/s | 33.1 steps/s
[Step= 300] | Loss=0.19724 | acc=0.9746 | tpr=0.9564 | fpr=0.0251 | 8037.1 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.19926 | acc=0.9742 | tpr=0.9574 | fpr=0.0255 | 8372.1 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.20136 | acc=0.9740 | tpr=0.9540 | fpr=0.0256 | 7804.9 samples/s | 30.5 steps/s
[Step= 450] | Loss=0.20533 | acc=0.9735 | tpr=0.9537 | fpr=0.0262 | 8400.8 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.20473 | acc=0.9735 | tpr=0.9551 | fpr=0.0262 | 8332.4 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.20329 | acc=0.9736 | tpr=0.9546 | fpr=0.0260 | 14228.8 samples/s | 55.6 steps/s
Avg test loss: 0.20273, Avg test acc: 0.97367, Avg tpr: 0.95404, Avg fpr: 0.02598, total FA: 3607

server round 21/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=81.9] | Loss=0.01135 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.956 | L2-Norm(final)=7.748 | 6253.1 samples/s | 97.7 steps/s
[Step=42050 Epoch=82.0] | Loss=0.00627 | Reg=0.00322 | acc=0.9531 | L2-Norm=17.955 | L2-Norm(final)=7.752 | 4732.4 samples/s | 73.9 steps/s
[Step=42100 Epoch=82.1] | Loss=0.00592 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.955 | L2-Norm(final)=7.758 | 5169.0 samples/s | 80.8 steps/s
[Step=42150 Epoch=82.2] | Loss=0.00600 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.954 | L2-Norm(final)=7.763 | 5227.4 samples/s | 81.7 steps/s
[Step=42200 Epoch=82.3] | Loss=0.00586 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.954 | L2-Norm(final)=7.769 | 5194.3 samples/s | 81.2 steps/s
[Step=42250 Epoch=82.4] | Loss=0.00627 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.953 | L2-Norm(final)=7.774 | 5263.8 samples/s | 82.2 steps/s
[Step=42300 Epoch=82.5] | Loss=0.00610 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.951 | L2-Norm(final)=7.778 | 5131.6 samples/s | 80.2 steps/s
[Step=42350 Epoch=82.6] | Loss=0.00608 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.950 | L2-Norm(final)=7.783 | 5178.3 samples/s | 80.9 steps/s
[Step=42400 Epoch=82.7] | Loss=0.00611 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.949 | L2-Norm(final)=7.788 | 5245.0 samples/s | 82.0 steps/s
[Step=42450 Epoch=82.8] | Loss=0.00617 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.947 | L2-Norm(final)=7.792 | 5195.2 samples/s | 81.2 steps/s
[Step=42500 Epoch=82.9] | Loss=0.00604 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.946 | L2-Norm(final)=7.797 | 6987.8 samples/s | 109.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=82.9] | Loss=0.00169 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.932 | L2-Norm(final)=7.842 | 6284.3 samples/s | 98.2 steps/s
[Step=42550 Epoch=83.0] | Loss=0.00496 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.933 | L2-Norm(final)=7.847 | 4451.3 samples/s | 69.6 steps/s
[Step=42600 Epoch=83.1] | Loss=0.00537 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.852 | 4542.6 samples/s | 71.0 steps/s
[Step=42650 Epoch=83.2] | Loss=0.00709 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.934 | L2-Norm(final)=7.854 | 4644.4 samples/s | 72.6 steps/s
[Step=42700 Epoch=83.3] | Loss=0.00753 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.855 | 4627.8 samples/s | 72.3 steps/s
[Step=42750 Epoch=83.4] | Loss=0.00729 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.934 | L2-Norm(final)=7.856 | 4602.3 samples/s | 71.9 steps/s
[Step=42800 Epoch=83.5] | Loss=0.00713 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.934 | L2-Norm(final)=7.857 | 4650.2 samples/s | 72.7 steps/s
[Step=42850 Epoch=83.6] | Loss=0.00719 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.859 | 4610.2 samples/s | 72.0 steps/s
[Step=42900 Epoch=83.7] | Loss=0.00758 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.861 | 4669.1 samples/s | 73.0 steps/s
[Step=42950 Epoch=83.8] | Loss=0.00785 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.934 | L2-Norm(final)=7.862 | 4624.9 samples/s | 72.3 steps/s
[Step=43000 Epoch=83.9] | Loss=0.00788 | Reg=0.00322 | acc=0.9844 | L2-Norm=17.934 | L2-Norm(final)=7.864 | 5963.6 samples/s | 93.2 steps/s
[Step=43050 Epoch=84.0] | Loss=0.00807 | Reg=0.00322 | acc=0.9688 | L2-Norm=17.934 | L2-Norm(final)=7.865 | 2444.6 samples/s | 38.2 steps/s
[Step=43100 Epoch=84.1] | Loss=0.00801 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.867 | 4651.6 samples/s | 72.7 steps/s
[Step=43150 Epoch=84.2] | Loss=0.00810 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.934 | L2-Norm(final)=7.869 | 4573.6 samples/s | 71.5 steps/s
[Step=43200 Epoch=84.3] | Loss=0.00795 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.933 | L2-Norm(final)=7.870 | 4722.0 samples/s | 73.8 steps/s
[Step=43250 Epoch=84.4] | Loss=0.00784 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.933 | L2-Norm(final)=7.872 | 4538.5 samples/s | 70.9 steps/s
[Step=43300 Epoch=84.5] | Loss=0.00779 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.932 | L2-Norm(final)=7.874 | 4632.7 samples/s | 72.4 steps/s
[Step=43350 Epoch=84.5] | Loss=0.00773 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.932 | L2-Norm(final)=7.876 | 4635.9 samples/s | 72.4 steps/s
[Step=43400 Epoch=84.6] | Loss=0.00763 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.931 | L2-Norm(final)=7.878 | 4636.3 samples/s | 72.4 steps/s
[Step=43450 Epoch=84.7] | Loss=0.00754 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.930 | L2-Norm(final)=7.880 | 4615.4 samples/s | 72.1 steps/s
[Step=43500 Epoch=84.8] | Loss=0.00754 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.929 | L2-Norm(final)=7.883 | 4980.1 samples/s | 77.8 steps/s
[Step=43550 Epoch=84.9] | Loss=0.00750 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.928 | L2-Norm(final)=7.885 | 2653.3 samples/s | 41.5 steps/s
[Step=43600 Epoch=85.0] | Loss=0.00739 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.927 | L2-Norm(final)=7.887 | 4695.9 samples/s | 73.4 steps/s
[Step=43650 Epoch=85.1] | Loss=0.00738 | Reg=0.00321 | acc=0.9844 | L2-Norm=17.926 | L2-Norm(final)=7.889 | 4526.1 samples/s | 70.7 steps/s
[Step=43700 Epoch=85.2] | Loss=0.00732 | Reg=0.00321 | acc=0.9844 | L2-Norm=17.925 | L2-Norm(final)=7.891 | 4635.3 samples/s | 72.4 steps/s
[Step=43750 Epoch=85.3] | Loss=0.00732 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.923 | L2-Norm(final)=7.892 | 4592.6 samples/s | 71.8 steps/s
[Step=43800 Epoch=85.4] | Loss=0.00724 | Reg=0.00321 | acc=0.9531 | L2-Norm=17.922 | L2-Norm(final)=7.894 | 4660.7 samples/s | 72.8 steps/s
[Step=43850 Epoch=85.5] | Loss=0.00717 | Reg=0.00321 | acc=0.9844 | L2-Norm=17.921 | L2-Norm(final)=7.896 | 4693.9 samples/s | 73.3 steps/s
[Step=43900 Epoch=85.6] | Loss=0.00707 | Reg=0.00321 | acc=0.9688 | L2-Norm=17.919 | L2-Norm(final)=7.898 | 4518.8 samples/s | 70.6 steps/s
[Step=43950 Epoch=85.7] | Loss=0.00711 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.917 | L2-Norm(final)=7.900 | 4686.9 samples/s | 73.2 steps/s
[Step=44000 Epoch=85.8] | Loss=0.00708 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.916 | L2-Norm(final)=7.901 | 4618.3 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step44000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=82.1] | Loss=0.00720 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.484 | L2-Norm(final)=8.184 | 5857.1 samples/s | 91.5 steps/s
[Step=42050 Epoch=82.2] | Loss=0.00497 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.483 | L2-Norm(final)=8.190 | 4977.4 samples/s | 77.8 steps/s
[Step=42100 Epoch=82.3] | Loss=0.00578 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.481 | L2-Norm(final)=8.196 | 5282.0 samples/s | 82.5 steps/s
[Step=42150 Epoch=82.4] | Loss=0.00556 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.480 | L2-Norm(final)=8.201 | 5116.7 samples/s | 79.9 steps/s
[Step=42200 Epoch=82.5] | Loss=0.00603 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.478 | L2-Norm(final)=8.207 | 5267.4 samples/s | 82.3 steps/s
[Step=42250 Epoch=82.6] | Loss=0.00578 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.476 | L2-Norm(final)=8.211 | 5103.7 samples/s | 79.7 steps/s
[Step=42300 Epoch=82.7] | Loss=0.00570 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.474 | L2-Norm(final)=8.216 | 5210.7 samples/s | 81.4 steps/s
[Step=42350 Epoch=82.8] | Loss=0.00580 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.471 | L2-Norm(final)=8.221 | 5206.7 samples/s | 81.4 steps/s
[Step=42400 Epoch=82.9] | Loss=0.00588 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.469 | L2-Norm(final)=8.226 | 5202.6 samples/s | 81.3 steps/s
[Step=42450 Epoch=83.0] | Loss=0.00576 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.468 | L2-Norm(final)=8.231 | 5297.8 samples/s | 82.8 steps/s
[Step=42500 Epoch=83.1] | Loss=0.00566 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.466 | L2-Norm(final)=8.236 | 6935.1 samples/s | 108.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=83.1] | Loss=0.00615 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.448 | L2-Norm(final)=8.284 | 5790.2 samples/s | 90.5 steps/s
[Step=42550 Epoch=83.2] | Loss=0.00690 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.446 | L2-Norm(final)=8.288 | 4480.3 samples/s | 70.0 steps/s
[Step=42600 Epoch=83.3] | Loss=0.00674 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.445 | L2-Norm(final)=8.292 | 4598.3 samples/s | 71.8 steps/s
[Step=42650 Epoch=83.4] | Loss=0.00619 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.445 | L2-Norm(final)=8.296 | 4639.1 samples/s | 72.5 steps/s
[Step=42700 Epoch=83.5] | Loss=0.00730 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.445 | L2-Norm(final)=8.299 | 4626.1 samples/s | 72.3 steps/s
[Step=42750 Epoch=83.6] | Loss=0.00695 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.445 | L2-Norm(final)=8.300 | 4602.7 samples/s | 71.9 steps/s
[Step=42800 Epoch=83.7] | Loss=0.00726 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.445 | L2-Norm(final)=8.302 | 4647.9 samples/s | 72.6 steps/s
[Step=42850 Epoch=83.8] | Loss=0.00738 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.444 | L2-Norm(final)=8.304 | 4595.5 samples/s | 71.8 steps/s
[Step=42900 Epoch=83.9] | Loss=0.00743 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.444 | L2-Norm(final)=8.305 | 4708.6 samples/s | 73.6 steps/s
[Step=42950 Epoch=84.0] | Loss=0.00773 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.443 | L2-Norm(final)=8.307 | 4559.7 samples/s | 71.2 steps/s
[Step=43000 Epoch=84.1] | Loss=0.00768 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.442 | L2-Norm(final)=8.309 | 6056.2 samples/s | 94.6 steps/s
[Step=43050 Epoch=84.2] | Loss=0.00747 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.441 | L2-Norm(final)=8.311 | 2433.8 samples/s | 38.0 steps/s
[Step=43100 Epoch=84.3] | Loss=0.00725 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.440 | L2-Norm(final)=8.312 | 4597.3 samples/s | 71.8 steps/s
[Step=43150 Epoch=84.4] | Loss=0.00710 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.439 | L2-Norm(final)=8.314 | 4595.6 samples/s | 71.8 steps/s
[Step=43200 Epoch=84.5] | Loss=0.00713 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.437 | L2-Norm(final)=8.316 | 4611.4 samples/s | 72.1 steps/s
[Step=43250 Epoch=84.6] | Loss=0.00712 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.435 | L2-Norm(final)=8.318 | 4612.0 samples/s | 72.1 steps/s
[Step=43300 Epoch=84.7] | Loss=0.00713 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.433 | L2-Norm(final)=8.320 | 4673.5 samples/s | 73.0 steps/s
[Step=43350 Epoch=84.7] | Loss=0.00706 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.432 | L2-Norm(final)=8.322 | 4646.5 samples/s | 72.6 steps/s
[Step=43400 Epoch=84.8] | Loss=0.00706 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.430 | L2-Norm(final)=8.323 | 4576.5 samples/s | 71.5 steps/s
[Step=43450 Epoch=84.9] | Loss=0.00700 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.428 | L2-Norm(final)=8.325 | 4651.3 samples/s | 72.7 steps/s
[Step=43500 Epoch=85.0] | Loss=0.00698 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.426 | L2-Norm(final)=8.327 | 5140.5 samples/s | 80.3 steps/s
[Step=43550 Epoch=85.1] | Loss=0.00700 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.424 | L2-Norm(final)=8.328 | 2655.7 samples/s | 41.5 steps/s
[Step=43600 Epoch=85.2] | Loss=0.00699 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.422 | L2-Norm(final)=8.330 | 4492.6 samples/s | 70.2 steps/s
[Step=43650 Epoch=85.3] | Loss=0.00689 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.420 | L2-Norm(final)=8.331 | 4675.5 samples/s | 73.1 steps/s
[Step=43700 Epoch=85.4] | Loss=0.00680 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.418 | L2-Norm(final)=8.333 | 4548.0 samples/s | 71.1 steps/s
[Step=43750 Epoch=85.5] | Loss=0.00673 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.416 | L2-Norm(final)=8.334 | 4643.8 samples/s | 72.6 steps/s
[Step=43800 Epoch=85.6] | Loss=0.00670 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.413 | L2-Norm(final)=8.336 | 4599.1 samples/s | 71.9 steps/s
[Step=43850 Epoch=85.7] | Loss=0.00677 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.411 | L2-Norm(final)=8.338 | 4629.8 samples/s | 72.3 steps/s
[Step=43900 Epoch=85.8] | Loss=0.00670 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.409 | L2-Norm(final)=8.339 | 4685.2 samples/s | 73.2 steps/s
[Step=43950 Epoch=85.9] | Loss=0.00669 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.407 | L2-Norm(final)=8.341 | 4573.2 samples/s | 71.5 steps/s
[Step=44000 Epoch=86.0] | Loss=0.00664 | Reg=0.00339 | acc=1.0000 | L2-Norm=18.404 | L2-Norm(final)=8.342 | 4684.8 samples/s | 73.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step44000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=160.9] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.768 | L2-Norm(final)=6.166 | 6314.3 samples/s | 98.7 steps/s
[Step=42050 Epoch=161.1] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.767 | L2-Norm(final)=6.170 | 4271.3 samples/s | 66.7 steps/s
[Step=42100 Epoch=161.3] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.765 | L2-Norm(final)=6.171 | 5037.8 samples/s | 78.7 steps/s
[Step=42150 Epoch=161.5] | Loss=0.00003 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.764 | L2-Norm(final)=6.174 | 4798.6 samples/s | 75.0 steps/s
[Step=42200 Epoch=161.7] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.764 | L2-Norm(final)=6.176 | 4896.7 samples/s | 76.5 steps/s
[Step=42250 Epoch=161.9] | Loss=0.00003 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.763 | L2-Norm(final)=6.178 | 6769.2 samples/s | 105.8 steps/s
[Step=42300 Epoch=162.1] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.762 | L2-Norm(final)=6.180 | 2479.9 samples/s | 38.7 steps/s
[Step=42350 Epoch=162.3] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.761 | L2-Norm(final)=6.182 | 4812.0 samples/s | 75.2 steps/s
[Step=42400 Epoch=162.5] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.759 | L2-Norm(final)=6.183 | 4935.9 samples/s | 77.1 steps/s
[Step=42450 Epoch=162.7] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.758 | L2-Norm(final)=6.185 | 4985.1 samples/s | 77.9 steps/s
[Step=42500 Epoch=162.8] | Loss=0.00002 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.756 | L2-Norm(final)=6.187 | 5536.0 samples/s | 86.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=162.8] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.739 | L2-Norm(final)=6.205 | 5937.5 samples/s | 92.8 steps/s
[Step=42550 Epoch=163.0] | Loss=0.00001 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.733 | L2-Norm(final)=6.206 | 4026.6 samples/s | 62.9 steps/s
[Step=42600 Epoch=163.2] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.726 | L2-Norm(final)=6.208 | 4430.0 samples/s | 69.2 steps/s
[Step=42650 Epoch=163.4] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.718 | L2-Norm(final)=6.209 | 4359.1 samples/s | 68.1 steps/s
[Step=42700 Epoch=163.6] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.710 | L2-Norm(final)=6.211 | 4363.4 samples/s | 68.2 steps/s
[Step=42750 Epoch=163.8] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.702 | L2-Norm(final)=6.213 | 5853.8 samples/s | 91.5 steps/s
[Step=42800 Epoch=164.0] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.694 | L2-Norm(final)=6.214 | 2350.3 samples/s | 36.7 steps/s
[Step=42850 Epoch=164.2] | Loss=0.00001 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.686 | L2-Norm(final)=6.215 | 4303.8 samples/s | 67.2 steps/s
[Step=42900 Epoch=164.4] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.677 | L2-Norm(final)=6.217 | 4380.7 samples/s | 68.4 steps/s
[Step=42950 Epoch=164.6] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.669 | L2-Norm(final)=6.218 | 4408.1 samples/s | 68.9 steps/s
[Step=43000 Epoch=164.8] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.660 | L2-Norm(final)=6.219 | 4970.1 samples/s | 77.7 steps/s
[Step=43050 Epoch=165.0] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.652 | L2-Norm(final)=6.220 | 2513.4 samples/s | 39.3 steps/s
[Step=43100 Epoch=165.1] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.643 | L2-Norm(final)=6.221 | 4402.3 samples/s | 68.8 steps/s
[Step=43150 Epoch=165.3] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.634 | L2-Norm(final)=6.222 | 4429.9 samples/s | 69.2 steps/s
[Step=43200 Epoch=165.5] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.625 | L2-Norm(final)=6.223 | 4279.5 samples/s | 66.9 steps/s
[Step=43250 Epoch=165.7] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.616 | L2-Norm(final)=6.224 | 4353.9 samples/s | 68.0 steps/s
[Step=43300 Epoch=165.9] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.606 | L2-Norm(final)=6.224 | 2730.6 samples/s | 42.7 steps/s
[Step=43350 Epoch=166.1] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.597 | L2-Norm(final)=6.225 | 4380.3 samples/s | 68.4 steps/s
[Step=43400 Epoch=166.3] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.588 | L2-Norm(final)=6.226 | 4272.7 samples/s | 66.8 steps/s
[Step=43450 Epoch=166.5] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.578 | L2-Norm(final)=6.227 | 4456.1 samples/s | 69.6 steps/s
[Step=43500 Epoch=166.7] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.569 | L2-Norm(final)=6.228 | 4317.2 samples/s | 67.5 steps/s
[Step=43550 Epoch=166.9] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.559 | L2-Norm(final)=6.229 | 2730.2 samples/s | 42.7 steps/s
[Step=43600 Epoch=167.1] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.549 | L2-Norm(final)=6.230 | 4298.1 samples/s | 67.2 steps/s
[Step=43650 Epoch=167.3] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.539 | L2-Norm(final)=6.231 | 4339.3 samples/s | 67.8 steps/s
[Step=43700 Epoch=167.4] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.529 | L2-Norm(final)=6.231 | 4332.3 samples/s | 67.7 steps/s
[Step=43750 Epoch=167.6] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.519 | L2-Norm(final)=6.232 | 4384.1 samples/s | 68.5 steps/s
[Step=43800 Epoch=167.8] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.509 | L2-Norm(final)=6.233 | 6489.8 samples/s | 101.4 steps/s
[Step=43850 Epoch=168.0] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.499 | L2-Norm(final)=6.234 | 2238.0 samples/s | 35.0 steps/s
[Step=43900 Epoch=168.2] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.488 | L2-Norm(final)=6.235 | 4352.8 samples/s | 68.0 steps/s
[Step=43950 Epoch=168.4] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=6.236 | 4439.7 samples/s | 69.4 steps/s
[Step=44000 Epoch=168.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.467 | L2-Norm(final)=6.237 | 4343.3 samples/s | 67.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step44000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=161.7] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.718 | L2-Norm(final)=6.469 | 6226.4 samples/s | 97.3 steps/s
[Step=42050 Epoch=161.9] | Loss=0.00004 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.717 | L2-Norm(final)=6.471 | 4424.4 samples/s | 69.1 steps/s
[Step=42100 Epoch=162.1] | Loss=0.00003 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.716 | L2-Norm(final)=6.474 | 4744.4 samples/s | 74.1 steps/s
[Step=42150 Epoch=162.3] | Loss=0.00003 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.715 | L2-Norm(final)=6.476 | 5023.5 samples/s | 78.5 steps/s
[Step=42200 Epoch=162.4] | Loss=0.00003 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.713 | L2-Norm(final)=6.478 | 4801.9 samples/s | 75.0 steps/s
[Step=42250 Epoch=162.6] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.712 | L2-Norm(final)=6.479 | 6987.9 samples/s | 109.2 steps/s
[Step=42300 Epoch=162.8] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.710 | L2-Norm(final)=6.481 | 2442.0 samples/s | 38.2 steps/s
[Step=42350 Epoch=163.0] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.709 | L2-Norm(final)=6.483 | 4906.5 samples/s | 76.7 steps/s
[Step=42400 Epoch=163.2] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.707 | L2-Norm(final)=6.485 | 5055.7 samples/s | 79.0 steps/s
[Step=42450 Epoch=163.4] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.706 | L2-Norm(final)=6.487 | 4867.9 samples/s | 76.1 steps/s
[Step=42500 Epoch=163.6] | Loss=0.00002 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.704 | L2-Norm(final)=6.489 | 5706.4 samples/s | 89.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=163.6] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.688 | L2-Norm(final)=6.507 | 7570.1 samples/s | 118.3 steps/s
[Step=42550 Epoch=163.8] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.682 | L2-Norm(final)=6.509 | 3697.6 samples/s | 57.8 steps/s
[Step=42600 Epoch=164.0] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.675 | L2-Norm(final)=6.510 | 4203.2 samples/s | 65.7 steps/s
[Step=42650 Epoch=164.2] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.667 | L2-Norm(final)=6.512 | 4374.4 samples/s | 68.3 steps/s
[Step=42700 Epoch=164.4] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.659 | L2-Norm(final)=6.513 | 4448.7 samples/s | 69.5 steps/s
[Step=42750 Epoch=164.6] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.651 | L2-Norm(final)=6.514 | 5859.3 samples/s | 91.6 steps/s
[Step=42800 Epoch=164.8] | Loss=0.00001 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.643 | L2-Norm(final)=6.516 | 2310.9 samples/s | 36.1 steps/s
[Step=42850 Epoch=164.9] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.634 | L2-Norm(final)=6.517 | 4359.8 samples/s | 68.1 steps/s
[Step=42900 Epoch=165.1] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.626 | L2-Norm(final)=6.518 | 4408.0 samples/s | 68.9 steps/s
[Step=42950 Epoch=165.3] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.617 | L2-Norm(final)=6.518 | 4375.3 samples/s | 68.4 steps/s
[Step=43000 Epoch=165.5] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.608 | L2-Norm(final)=6.519 | 5100.2 samples/s | 79.7 steps/s
[Step=43050 Epoch=165.7] | Loss=0.00001 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.599 | L2-Norm(final)=6.520 | 2504.8 samples/s | 39.1 steps/s
[Step=43100 Epoch=165.9] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.590 | L2-Norm(final)=6.521 | 4273.9 samples/s | 66.8 steps/s
[Step=43150 Epoch=166.1] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.581 | L2-Norm(final)=6.521 | 4389.7 samples/s | 68.6 steps/s
[Step=43200 Epoch=166.3] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.571 | L2-Norm(final)=6.522 | 4381.4 samples/s | 68.5 steps/s
[Step=43250 Epoch=166.5] | Loss=0.00001 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.562 | L2-Norm(final)=6.523 | 4482.2 samples/s | 70.0 steps/s
[Step=43300 Epoch=166.7] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.552 | L2-Norm(final)=6.523 | 2708.2 samples/s | 42.3 steps/s
[Step=43350 Epoch=166.9] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.542 | L2-Norm(final)=6.524 | 4219.4 samples/s | 65.9 steps/s
[Step=43400 Epoch=167.1] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.533 | L2-Norm(final)=6.525 | 4399.6 samples/s | 68.7 steps/s
[Step=43450 Epoch=167.3] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.523 | L2-Norm(final)=6.525 | 4414.8 samples/s | 69.0 steps/s
[Step=43500 Epoch=167.4] | Loss=0.00000 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.513 | L2-Norm(final)=6.526 | 4490.3 samples/s | 70.2 steps/s
[Step=43550 Epoch=167.6] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=6.526 | 2676.2 samples/s | 41.8 steps/s
[Step=43600 Epoch=167.8] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.492 | L2-Norm(final)=6.527 | 4421.2 samples/s | 69.1 steps/s
[Step=43650 Epoch=168.0] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.482 | L2-Norm(final)=6.528 | 4301.8 samples/s | 67.2 steps/s
[Step=43700 Epoch=168.2] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.471 | L2-Norm(final)=6.528 | 4368.1 samples/s | 68.3 steps/s
[Step=43750 Epoch=168.4] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.461 | L2-Norm(final)=6.529 | 4386.7 samples/s | 68.5 steps/s
[Step=43800 Epoch=168.6] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.450 | L2-Norm(final)=6.529 | 7117.3 samples/s | 111.2 steps/s
[Step=43850 Epoch=168.8] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.439 | L2-Norm(final)=6.530 | 2173.1 samples/s | 34.0 steps/s
[Step=43900 Epoch=169.0] | Loss=0.00000 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.428 | L2-Norm(final)=6.531 | 4389.7 samples/s | 68.6 steps/s
[Step=43950 Epoch=169.2] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.417 | L2-Norm(final)=6.531 | 4356.6 samples/s | 68.1 steps/s
[Step=44000 Epoch=169.4] | Loss=0.00000 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.406 | L2-Norm(final)=6.532 | 4368.2 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08878 | acc=0.9671 | tpr=0.9725 | fpr=0.0446 | 5319.4 samples/s | 20.8 steps/s
Avg test loss: 0.08972, Avg test acc: 0.96714, Avg tpr: 0.97290, Avg fpr: 0.04551, total FA: 355

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08408 | acc=0.9677 | tpr=0.9706 | fpr=0.0387 | 5250.3 samples/s | 20.5 steps/s
Avg test loss: 0.08716, Avg test acc: 0.96763, Avg tpr: 0.97138, Avg fpr: 0.04064, total FA: 317

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.57840 | acc=0.3086 | tpr=0.0082 | fpr=0.0391 | 5356.9 samples/s | 20.9 steps/s
Avg test loss: 5.59066, Avg test acc: 0.30696, Avg tpr: 0.00874, Avg fpr: 0.03717, total FA: 290

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.61387 | acc=0.2996 | tpr=0.0132 | fpr=0.0785 | 5370.1 samples/s | 21.0 steps/s
Avg test loss: 5.62646, Avg test acc: 0.29818, Avg tpr: 0.01317, Avg fpr: 0.07499, total FA: 585

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.31532 | acc=0.1236 | tpr=0.6947 | fpr=0.8867 | 5466.2 samples/s | 21.4 steps/s
[Step= 100] | Loss=7.29397 | acc=0.1243 | tpr=0.7015 | fpr=0.8865 | 6954.9 samples/s | 27.2 steps/s
[Step= 150] | Loss=7.28521 | acc=0.1245 | tpr=0.7161 | fpr=0.8864 | 7748.3 samples/s | 30.3 steps/s
[Step= 200] | Loss=7.29655 | acc=0.1237 | tpr=0.7180 | fpr=0.8871 | 7953.3 samples/s | 31.1 steps/s
[Step= 250] | Loss=7.30223 | acc=0.1244 | tpr=0.7118 | fpr=0.8863 | 8185.3 samples/s | 32.0 steps/s
[Step= 300] | Loss=7.30021 | acc=0.1245 | tpr=0.7156 | fpr=0.8863 | 8022.4 samples/s | 31.3 steps/s
[Step= 350] | Loss=7.28920 | acc=0.1244 | tpr=0.7145 | fpr=0.8864 | 8101.5 samples/s | 31.6 steps/s
[Step= 400] | Loss=7.28106 | acc=0.1248 | tpr=0.7166 | fpr=0.8859 | 8314.3 samples/s | 32.5 steps/s
[Step= 450] | Loss=7.27996 | acc=0.1243 | tpr=0.7171 | fpr=0.8865 | 8241.2 samples/s | 32.2 steps/s
[Step= 500] | Loss=7.28065 | acc=0.1241 | tpr=0.7154 | fpr=0.8866 | 7768.9 samples/s | 30.3 steps/s
[Step= 550] | Loss=7.28012 | acc=0.1245 | tpr=0.7103 | fpr=0.8862 | 14406.7 samples/s | 56.3 steps/s
Avg test loss: 7.28079, Avg test acc: 0.12439, Avg tpr: 0.71038, Avg fpr: 0.88626, total FA: 123056

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.31686 | acc=0.1319 | tpr=0.6681 | fpr=0.8778 | 5146.3 samples/s | 20.1 steps/s
[Step= 100] | Loss=7.28982 | acc=0.1320 | tpr=0.6418 | fpr=0.8776 | 7497.0 samples/s | 29.3 steps/s
[Step= 150] | Loss=7.28057 | acc=0.1328 | tpr=0.6427 | fpr=0.8766 | 7589.4 samples/s | 29.6 steps/s
[Step= 200] | Loss=7.28995 | acc=0.1324 | tpr=0.6426 | fpr=0.8769 | 8252.2 samples/s | 32.2 steps/s
[Step= 250] | Loss=7.29400 | acc=0.1327 | tpr=0.6454 | fpr=0.8766 | 8042.1 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.29694 | acc=0.1322 | tpr=0.6487 | fpr=0.8772 | 8157.2 samples/s | 31.9 steps/s
[Step= 350] | Loss=7.28473 | acc=0.1323 | tpr=0.6450 | fpr=0.8770 | 8066.1 samples/s | 31.5 steps/s
[Step= 400] | Loss=7.27676 | acc=0.1330 | tpr=0.6455 | fpr=0.8763 | 8090.2 samples/s | 31.6 steps/s
[Step= 450] | Loss=7.27415 | acc=0.1323 | tpr=0.6436 | fpr=0.8770 | 8205.0 samples/s | 32.1 steps/s
[Step= 500] | Loss=7.27843 | acc=0.1321 | tpr=0.6445 | fpr=0.8772 | 7938.7 samples/s | 31.0 steps/s
[Step= 550] | Loss=7.27660 | acc=0.1322 | tpr=0.6399 | fpr=0.8770 | 14600.3 samples/s | 57.0 steps/s
Avg test loss: 7.27718, Avg test acc: 0.13211, Avg tpr: 0.63986, Avg fpr: 0.87712, total FA: 121786

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.15149 | acc=0.9774 | tpr=0.9469 | fpr=0.0220 | 5039.9 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.15530 | acc=0.9771 | tpr=0.9552 | fpr=0.0225 | 7905.5 samples/s | 30.9 steps/s
[Step= 150] | Loss=0.16100 | acc=0.9761 | tpr=0.9539 | fpr=0.0235 | 7630.4 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.16422 | acc=0.9760 | tpr=0.9508 | fpr=0.0236 | 7908.5 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.16191 | acc=0.9764 | tpr=0.9493 | fpr=0.0231 | 8178.4 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.16491 | acc=0.9761 | tpr=0.9484 | fpr=0.0234 | 7899.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.16585 | acc=0.9758 | tpr=0.9505 | fpr=0.0238 | 8461.1 samples/s | 33.1 steps/s
[Step= 400] | Loss=0.16787 | acc=0.9756 | tpr=0.9469 | fpr=0.0239 | 8157.0 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.17167 | acc=0.9752 | tpr=0.9460 | fpr=0.0243 | 8211.7 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.17085 | acc=0.9752 | tpr=0.9467 | fpr=0.0243 | 8079.1 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.16960 | acc=0.9753 | tpr=0.9455 | fpr=0.0241 | 14103.2 samples/s | 55.1 steps/s
Avg test loss: 0.16919, Avg test acc: 0.97533, Avg tpr: 0.94453, Avg fpr: 0.02411, total FA: 3348

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.18374 | acc=0.9756 | tpr=0.9558 | fpr=0.0240 | 5232.5 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.18867 | acc=0.9753 | tpr=0.9531 | fpr=0.0243 | 7329.3 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.19560 | acc=0.9744 | tpr=0.9568 | fpr=0.0253 | 7675.1 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.20039 | acc=0.9741 | tpr=0.9596 | fpr=0.0257 | 8056.5 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.19656 | acc=0.9747 | tpr=0.9598 | fpr=0.0250 | 8131.3 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.20058 | acc=0.9742 | tpr=0.9571 | fpr=0.0254 | 8149.0 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.20232 | acc=0.9740 | tpr=0.9580 | fpr=0.0258 | 8227.1 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.20426 | acc=0.9738 | tpr=0.9551 | fpr=0.0259 | 8008.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.20837 | acc=0.9733 | tpr=0.9547 | fpr=0.0263 | 8163.5 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.20774 | acc=0.9734 | tpr=0.9559 | fpr=0.0263 | 8006.9 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.20632 | acc=0.9735 | tpr=0.9558 | fpr=0.0262 | 14254.6 samples/s | 55.7 steps/s
Avg test loss: 0.20574, Avg test acc: 0.97352, Avg tpr: 0.95523, Avg fpr: 0.02614, total FA: 3630

server round 22/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=85.8] | Loss=0.00302 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.665 | L2-Norm(final)=7.952 | 6613.0 samples/s | 103.3 steps/s
[Step=44050 Epoch=85.9] | Loss=0.00444 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.664 | L2-Norm(final)=7.957 | 4470.5 samples/s | 69.9 steps/s
[Step=44100 Epoch=86.0] | Loss=0.00488 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.663 | L2-Norm(final)=7.962 | 5161.5 samples/s | 80.6 steps/s
[Step=44150 Epoch=86.1] | Loss=0.00489 | Reg=0.00312 | acc=0.9844 | L2-Norm=17.661 | L2-Norm(final)=7.967 | 5151.5 samples/s | 80.5 steps/s
[Step=44200 Epoch=86.2] | Loss=0.00489 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.659 | L2-Norm(final)=7.971 | 5237.0 samples/s | 81.8 steps/s
[Step=44250 Epoch=86.3] | Loss=0.00514 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.657 | L2-Norm(final)=7.976 | 5130.1 samples/s | 80.2 steps/s
[Step=44300 Epoch=86.4] | Loss=0.00542 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.655 | L2-Norm(final)=7.981 | 5211.2 samples/s | 81.4 steps/s
[Step=44350 Epoch=86.5] | Loss=0.00543 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.653 | L2-Norm(final)=7.985 | 5189.8 samples/s | 81.1 steps/s
[Step=44400 Epoch=86.6] | Loss=0.00518 | Reg=0.00312 | acc=1.0000 | L2-Norm=17.651 | L2-Norm(final)=7.989 | 5205.2 samples/s | 81.3 steps/s
[Step=44450 Epoch=86.7] | Loss=0.00516 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.648 | L2-Norm(final)=7.993 | 5207.8 samples/s | 81.4 steps/s
[Step=44500 Epoch=86.8] | Loss=0.00508 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.646 | L2-Norm(final)=7.997 | 6986.5 samples/s | 109.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=86.8] | Loss=0.00007 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=8.038 | 6326.8 samples/s | 98.9 steps/s
[Step=44550 Epoch=86.9] | Loss=0.00469 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.622 | L2-Norm(final)=8.042 | 4277.6 samples/s | 66.8 steps/s
[Step=44600 Epoch=87.0] | Loss=0.00527 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.621 | L2-Norm(final)=8.044 | 4467.4 samples/s | 69.8 steps/s
[Step=44650 Epoch=87.1] | Loss=0.00643 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.622 | L2-Norm(final)=8.047 | 4654.8 samples/s | 72.7 steps/s
[Step=44700 Epoch=87.2] | Loss=0.00697 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.622 | L2-Norm(final)=8.048 | 4609.5 samples/s | 72.0 steps/s
[Step=44750 Epoch=87.3] | Loss=0.00756 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.622 | L2-Norm(final)=8.050 | 4578.4 samples/s | 71.5 steps/s
[Step=44800 Epoch=87.4] | Loss=0.00751 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.622 | L2-Norm(final)=8.051 | 4656.0 samples/s | 72.8 steps/s
[Step=44850 Epoch=87.5] | Loss=0.00753 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.622 | L2-Norm(final)=8.053 | 4611.5 samples/s | 72.1 steps/s
[Step=44900 Epoch=87.6] | Loss=0.00740 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.623 | L2-Norm(final)=8.055 | 4639.1 samples/s | 72.5 steps/s
[Step=44950 Epoch=87.7] | Loss=0.00723 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.623 | L2-Norm(final)=8.058 | 4619.0 samples/s | 72.2 steps/s
[Step=45000 Epoch=87.8] | Loss=0.00709 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=8.060 | 5943.0 samples/s | 92.9 steps/s
[Step=45050 Epoch=87.9] | Loss=0.00708 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=8.063 | 2441.7 samples/s | 38.2 steps/s
[Step=45100 Epoch=88.0] | Loss=0.00710 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.624 | L2-Norm(final)=8.065 | 4608.5 samples/s | 72.0 steps/s
[Step=45150 Epoch=88.1] | Loss=0.00709 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.624 | L2-Norm(final)=8.067 | 4634.2 samples/s | 72.4 steps/s
[Step=45200 Epoch=88.2] | Loss=0.00724 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.623 | L2-Norm(final)=8.069 | 4578.6 samples/s | 71.5 steps/s
[Step=45250 Epoch=88.3] | Loss=0.00721 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.623 | L2-Norm(final)=8.072 | 4648.1 samples/s | 72.6 steps/s
[Step=45300 Epoch=88.4] | Loss=0.00722 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.622 | L2-Norm(final)=8.074 | 4650.7 samples/s | 72.7 steps/s
[Step=45350 Epoch=88.5] | Loss=0.00715 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.621 | L2-Norm(final)=8.076 | 4653.4 samples/s | 72.7 steps/s
[Step=45400 Epoch=88.5] | Loss=0.00707 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.621 | L2-Norm(final)=8.078 | 4655.7 samples/s | 72.7 steps/s
[Step=45450 Epoch=88.6] | Loss=0.00708 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.620 | L2-Norm(final)=8.080 | 4601.7 samples/s | 71.9 steps/s
[Step=45500 Epoch=88.7] | Loss=0.00706 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.619 | L2-Norm(final)=8.081 | 4956.9 samples/s | 77.5 steps/s
[Step=45550 Epoch=88.8] | Loss=0.00704 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=8.083 | 2650.3 samples/s | 41.4 steps/s
[Step=45600 Epoch=88.9] | Loss=0.00707 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.616 | L2-Norm(final)=8.085 | 4698.7 samples/s | 73.4 steps/s
[Step=45650 Epoch=89.0] | Loss=0.00699 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.615 | L2-Norm(final)=8.086 | 4523.9 samples/s | 70.7 steps/s
[Step=45700 Epoch=89.1] | Loss=0.00698 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=8.087 | 4665.1 samples/s | 72.9 steps/s
[Step=45750 Epoch=89.2] | Loss=0.00705 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.612 | L2-Norm(final)=8.089 | 4589.2 samples/s | 71.7 steps/s
[Step=45800 Epoch=89.3] | Loss=0.00700 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.611 | L2-Norm(final)=8.090 | 4697.0 samples/s | 73.4 steps/s
[Step=45850 Epoch=89.4] | Loss=0.00693 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.610 | L2-Norm(final)=8.092 | 4587.6 samples/s | 71.7 steps/s
[Step=45900 Epoch=89.5] | Loss=0.00692 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.608 | L2-Norm(final)=8.093 | 4633.6 samples/s | 72.4 steps/s
[Step=45950 Epoch=89.6] | Loss=0.00689 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.607 | L2-Norm(final)=8.095 | 4617.9 samples/s | 72.2 steps/s
[Step=46000 Epoch=89.7] | Loss=0.00696 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.605 | L2-Norm(final)=8.096 | 4690.2 samples/s | 73.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step46000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=86.0] | Loss=0.00038 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.141 | L2-Norm(final)=8.388 | 6652.8 samples/s | 103.9 steps/s
[Step=44050 Epoch=86.1] | Loss=0.00542 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.138 | L2-Norm(final)=8.390 | 4518.9 samples/s | 70.6 steps/s
[Step=44100 Epoch=86.2] | Loss=0.00480 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.135 | L2-Norm(final)=8.395 | 5132.2 samples/s | 80.2 steps/s
[Step=44150 Epoch=86.3] | Loss=0.00515 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.132 | L2-Norm(final)=8.399 | 5294.0 samples/s | 82.7 steps/s
[Step=44200 Epoch=86.4] | Loss=0.00512 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.129 | L2-Norm(final)=8.404 | 5209.3 samples/s | 81.4 steps/s
[Step=44250 Epoch=86.5] | Loss=0.00481 | Reg=0.00329 | acc=1.0000 | L2-Norm=18.126 | L2-Norm(final)=8.408 | 5064.0 samples/s | 79.1 steps/s
[Step=44300 Epoch=86.6] | Loss=0.00480 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.123 | L2-Norm(final)=8.413 | 5333.8 samples/s | 83.3 steps/s
[Step=44350 Epoch=86.7] | Loss=0.00472 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.120 | L2-Norm(final)=8.417 | 5238.8 samples/s | 81.9 steps/s
[Step=44400 Epoch=86.8] | Loss=0.00469 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.117 | L2-Norm(final)=8.422 | 5035.5 samples/s | 78.7 steps/s
[Step=44450 Epoch=86.9] | Loss=0.00467 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.115 | L2-Norm(final)=8.426 | 5301.6 samples/s | 82.8 steps/s
[Step=44500 Epoch=87.0] | Loss=0.00482 | Reg=0.00328 | acc=1.0000 | L2-Norm=18.112 | L2-Norm(final)=8.430 | 6909.2 samples/s | 108.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=87.0] | Loss=0.00219 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.084 | L2-Norm(final)=8.470 | 6736.1 samples/s | 105.3 steps/s
[Step=44550 Epoch=87.1] | Loss=0.00573 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.082 | L2-Norm(final)=8.474 | 4092.2 samples/s | 63.9 steps/s
[Step=44600 Epoch=87.2] | Loss=0.00522 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.084 | L2-Norm(final)=8.478 | 4594.7 samples/s | 71.8 steps/s
[Step=44650 Epoch=87.3] | Loss=0.00651 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.086 | L2-Norm(final)=8.481 | 4580.1 samples/s | 71.6 steps/s
[Step=44700 Epoch=87.4] | Loss=0.00740 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.087 | L2-Norm(final)=8.483 | 4681.6 samples/s | 73.2 steps/s
[Step=44750 Epoch=87.5] | Loss=0.00731 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.088 | L2-Norm(final)=8.485 | 4539.5 samples/s | 70.9 steps/s
[Step=44800 Epoch=87.6] | Loss=0.00765 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.090 | L2-Norm(final)=8.487 | 4645.3 samples/s | 72.6 steps/s
[Step=44850 Epoch=87.7] | Loss=0.00743 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.091 | L2-Norm(final)=8.490 | 4612.7 samples/s | 72.1 steps/s
[Step=44900 Epoch=87.8] | Loss=0.00764 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.093 | L2-Norm(final)=8.493 | 4634.4 samples/s | 72.4 steps/s
[Step=44950 Epoch=87.9] | Loss=0.00773 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.094 | L2-Norm(final)=8.496 | 4644.8 samples/s | 72.6 steps/s
[Step=45000 Epoch=88.0] | Loss=0.00784 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.094 | L2-Norm(final)=8.498 | 6031.2 samples/s | 94.2 steps/s
[Step=45050 Epoch=88.1] | Loss=0.00770 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=8.501 | 2458.7 samples/s | 38.4 steps/s
[Step=45100 Epoch=88.2] | Loss=0.00745 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=8.504 | 4624.6 samples/s | 72.3 steps/s
[Step=45150 Epoch=88.3] | Loss=0.00738 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.095 | L2-Norm(final)=8.507 | 4562.1 samples/s | 71.3 steps/s
[Step=45200 Epoch=88.4] | Loss=0.00741 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=8.509 | 4554.8 samples/s | 71.2 steps/s
[Step=45250 Epoch=88.5] | Loss=0.00743 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=8.511 | 4653.4 samples/s | 72.7 steps/s
[Step=45300 Epoch=88.6] | Loss=0.00737 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.095 | L2-Norm(final)=8.513 | 4601.3 samples/s | 71.9 steps/s
[Step=45350 Epoch=88.7] | Loss=0.00729 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.094 | L2-Norm(final)=8.516 | 4681.2 samples/s | 73.1 steps/s
[Step=45400 Epoch=88.8] | Loss=0.00735 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.094 | L2-Norm(final)=8.518 | 4567.0 samples/s | 71.4 steps/s
[Step=45450 Epoch=88.9] | Loss=0.00731 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.094 | L2-Norm(final)=8.520 | 4650.4 samples/s | 72.7 steps/s
[Step=45500 Epoch=89.0] | Loss=0.00720 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.093 | L2-Norm(final)=8.522 | 5119.7 samples/s | 80.0 steps/s
[Step=45550 Epoch=89.0] | Loss=0.00716 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.093 | L2-Norm(final)=8.524 | 2633.0 samples/s | 41.1 steps/s
[Step=45600 Epoch=89.1] | Loss=0.00712 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.092 | L2-Norm(final)=8.526 | 4570.4 samples/s | 71.4 steps/s
[Step=45650 Epoch=89.2] | Loss=0.00697 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.091 | L2-Norm(final)=8.528 | 4605.3 samples/s | 72.0 steps/s
[Step=45700 Epoch=89.3] | Loss=0.00688 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.091 | L2-Norm(final)=8.530 | 4598.8 samples/s | 71.9 steps/s
[Step=45750 Epoch=89.4] | Loss=0.00690 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.089 | L2-Norm(final)=8.532 | 4612.3 samples/s | 72.1 steps/s
[Step=45800 Epoch=89.5] | Loss=0.00687 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.088 | L2-Norm(final)=8.534 | 4684.2 samples/s | 73.2 steps/s
[Step=45850 Epoch=89.6] | Loss=0.00679 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.087 | L2-Norm(final)=8.536 | 4587.0 samples/s | 71.7 steps/s
[Step=45900 Epoch=89.7] | Loss=0.00674 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.086 | L2-Norm(final)=8.538 | 4633.3 samples/s | 72.4 steps/s
[Step=45950 Epoch=89.8] | Loss=0.00674 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.084 | L2-Norm(final)=8.539 | 4651.0 samples/s | 72.7 steps/s
[Step=46000 Epoch=89.9] | Loss=0.00670 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.083 | L2-Norm(final)=8.541 | 4624.9 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step46000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=168.6] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.391 | L2-Norm(final)=6.263 | 5465.2 samples/s | 85.4 steps/s
[Step=44050 Epoch=168.8] | Loss=0.00003 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.390 | L2-Norm(final)=6.268 | 4337.7 samples/s | 67.8 steps/s
[Step=44100 Epoch=169.0] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.390 | L2-Norm(final)=6.273 | 4902.7 samples/s | 76.6 steps/s
[Step=44150 Epoch=169.2] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.388 | L2-Norm(final)=6.277 | 4926.1 samples/s | 77.0 steps/s
[Step=44200 Epoch=169.4] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.387 | L2-Norm(final)=6.281 | 4872.2 samples/s | 76.1 steps/s
[Step=44250 Epoch=169.6] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.386 | L2-Norm(final)=6.286 | 6715.1 samples/s | 104.9 steps/s
[Step=44300 Epoch=169.7] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.386 | L2-Norm(final)=6.290 | 2469.8 samples/s | 38.6 steps/s
[Step=44350 Epoch=169.9] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.384 | L2-Norm(final)=6.294 | 4971.6 samples/s | 77.7 steps/s
[Step=44400 Epoch=170.1] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.382 | L2-Norm(final)=6.298 | 4836.2 samples/s | 75.6 steps/s
[Step=44450 Epoch=170.3] | Loss=0.00002 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.381 | L2-Norm(final)=6.302 | 4988.6 samples/s | 77.9 steps/s
[Step=44500 Epoch=170.5] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.379 | L2-Norm(final)=6.306 | 5512.9 samples/s | 86.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=170.5] | Loss=0.00005 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.366 | L2-Norm(final)=6.349 | 6369.4 samples/s | 99.5 steps/s
[Step=44550 Epoch=170.7] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=6.353 | 3909.9 samples/s | 61.1 steps/s
[Step=44600 Epoch=170.9] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.339 | L2-Norm(final)=6.356 | 4418.1 samples/s | 69.0 steps/s
[Step=44650 Epoch=171.1] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.322 | L2-Norm(final)=6.359 | 4308.7 samples/s | 67.3 steps/s
[Step=44700 Epoch=171.3] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.305 | L2-Norm(final)=6.362 | 4353.7 samples/s | 68.0 steps/s
[Step=44750 Epoch=171.5] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.288 | L2-Norm(final)=6.365 | 5851.7 samples/s | 91.4 steps/s
[Step=44800 Epoch=171.7] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.270 | L2-Norm(final)=6.367 | 2313.5 samples/s | 36.1 steps/s
[Step=44850 Epoch=171.8] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.252 | L2-Norm(final)=6.369 | 4391.0 samples/s | 68.6 steps/s
[Step=44900 Epoch=172.0] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.234 | L2-Norm(final)=6.371 | 4472.6 samples/s | 69.9 steps/s
[Step=44950 Epoch=172.2] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.216 | L2-Norm(final)=6.373 | 4279.1 samples/s | 66.9 steps/s
[Step=45000 Epoch=172.4] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.198 | L2-Norm(final)=6.374 | 4957.3 samples/s | 77.5 steps/s
[Step=45050 Epoch=172.6] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.180 | L2-Norm(final)=6.376 | 2535.1 samples/s | 39.6 steps/s
[Step=45100 Epoch=172.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.161 | L2-Norm(final)=6.378 | 4352.9 samples/s | 68.0 steps/s
[Step=45150 Epoch=173.0] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.143 | L2-Norm(final)=6.379 | 4355.7 samples/s | 68.1 steps/s
[Step=45200 Epoch=173.2] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.124 | L2-Norm(final)=6.381 | 4373.1 samples/s | 68.3 steps/s
[Step=45250 Epoch=173.4] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.105 | L2-Norm(final)=6.383 | 4371.8 samples/s | 68.3 steps/s
[Step=45300 Epoch=173.6] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.086 | L2-Norm(final)=6.384 | 2685.6 samples/s | 42.0 steps/s
[Step=45350 Epoch=173.8] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.067 | L2-Norm(final)=6.386 | 4404.1 samples/s | 68.8 steps/s
[Step=45400 Epoch=174.0] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.048 | L2-Norm(final)=6.388 | 4417.8 samples/s | 69.0 steps/s
[Step=45450 Epoch=174.1] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.028 | L2-Norm(final)=6.390 | 4379.9 samples/s | 68.4 steps/s
[Step=45500 Epoch=174.3] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.009 | L2-Norm(final)=6.391 | 4380.5 samples/s | 68.4 steps/s
[Step=45550 Epoch=174.5] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.989 | L2-Norm(final)=6.393 | 2682.7 samples/s | 41.9 steps/s
[Step=45600 Epoch=174.7] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.969 | L2-Norm(final)=6.395 | 4398.1 samples/s | 68.7 steps/s
[Step=45650 Epoch=174.9] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.949 | L2-Norm(final)=6.397 | 4372.9 samples/s | 68.3 steps/s
[Step=45700 Epoch=175.1] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.929 | L2-Norm(final)=6.399 | 4345.8 samples/s | 67.9 steps/s
[Step=45750 Epoch=175.3] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.909 | L2-Norm(final)=6.401 | 4441.1 samples/s | 69.4 steps/s
[Step=45800 Epoch=175.5] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.889 | L2-Norm(final)=6.403 | 6366.8 samples/s | 99.5 steps/s
[Step=45850 Epoch=175.7] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.868 | L2-Norm(final)=6.405 | 2242.9 samples/s | 35.0 steps/s
[Step=45900 Epoch=175.9] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.848 | L2-Norm(final)=6.407 | 4396.4 samples/s | 68.7 steps/s
[Step=45950 Epoch=176.1] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.827 | L2-Norm(final)=6.409 | 4397.5 samples/s | 68.7 steps/s
[Step=46000 Epoch=176.3] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.806 | L2-Norm(final)=6.411 | 4339.5 samples/s | 67.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step46000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=169.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.346 | L2-Norm(final)=6.551 | 6805.7 samples/s | 106.3 steps/s
[Step=44050 Epoch=169.6] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.344 | L2-Norm(final)=6.555 | 4140.6 samples/s | 64.7 steps/s
[Step=44100 Epoch=169.8] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.343 | L2-Norm(final)=6.559 | 4891.7 samples/s | 76.4 steps/s
[Step=44150 Epoch=170.0] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.342 | L2-Norm(final)=6.563 | 4841.0 samples/s | 75.6 steps/s
[Step=44200 Epoch=170.1] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.341 | L2-Norm(final)=6.568 | 5048.3 samples/s | 78.9 steps/s
[Step=44250 Epoch=170.3] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.340 | L2-Norm(final)=6.572 | 6791.9 samples/s | 106.1 steps/s
[Step=44300 Epoch=170.5] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.339 | L2-Norm(final)=6.577 | 2447.1 samples/s | 38.2 steps/s
[Step=44350 Epoch=170.7] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.338 | L2-Norm(final)=6.581 | 4975.7 samples/s | 77.7 steps/s
[Step=44400 Epoch=170.9] | Loss=0.00002 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.336 | L2-Norm(final)=6.585 | 4840.6 samples/s | 75.6 steps/s
[Step=44450 Epoch=171.1] | Loss=0.00002 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.334 | L2-Norm(final)=6.589 | 4853.7 samples/s | 75.8 steps/s
[Step=44500 Epoch=171.3] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.332 | L2-Norm(final)=6.592 | 5874.4 samples/s | 91.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=171.3] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.313 | L2-Norm(final)=6.629 | 6568.2 samples/s | 102.6 steps/s
[Step=44550 Epoch=171.5] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.301 | L2-Norm(final)=6.633 | 3790.4 samples/s | 59.2 steps/s
[Step=44600 Epoch=171.7] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.284 | L2-Norm(final)=6.637 | 4361.4 samples/s | 68.1 steps/s
[Step=44650 Epoch=171.9] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.267 | L2-Norm(final)=6.639 | 4377.8 samples/s | 68.4 steps/s
[Step=44700 Epoch=172.1] | Loss=0.00001 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.250 | L2-Norm(final)=6.642 | 4384.5 samples/s | 68.5 steps/s
[Step=44750 Epoch=172.3] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.232 | L2-Norm(final)=6.644 | 5975.3 samples/s | 93.4 steps/s
[Step=44800 Epoch=172.5] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.214 | L2-Norm(final)=6.646 | 2312.7 samples/s | 36.1 steps/s
[Step=44850 Epoch=172.6] | Loss=0.00001 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.196 | L2-Norm(final)=6.648 | 4368.5 samples/s | 68.3 steps/s
[Step=44900 Epoch=172.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.177 | L2-Norm(final)=6.649 | 4378.6 samples/s | 68.4 steps/s
[Step=44950 Epoch=173.0] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.158 | L2-Norm(final)=6.651 | 4334.8 samples/s | 67.7 steps/s
[Step=45000 Epoch=173.2] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.139 | L2-Norm(final)=6.653 | 5108.9 samples/s | 79.8 steps/s
[Step=45050 Epoch=173.4] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.120 | L2-Norm(final)=6.654 | 2464.1 samples/s | 38.5 steps/s
[Step=45100 Epoch=173.6] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.100 | L2-Norm(final)=6.655 | 4363.1 samples/s | 68.2 steps/s
[Step=45150 Epoch=173.8] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.081 | L2-Norm(final)=6.657 | 4383.3 samples/s | 68.5 steps/s
[Step=45200 Epoch=174.0] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.061 | L2-Norm(final)=6.658 | 4382.2 samples/s | 68.5 steps/s
[Step=45250 Epoch=174.2] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.041 | L2-Norm(final)=6.660 | 4492.0 samples/s | 70.2 steps/s
[Step=45300 Epoch=174.4] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.021 | L2-Norm(final)=6.661 | 2635.7 samples/s | 41.2 steps/s
[Step=45350 Epoch=174.6] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.001 | L2-Norm(final)=6.663 | 4358.3 samples/s | 68.1 steps/s
[Step=45400 Epoch=174.8] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.981 | L2-Norm(final)=6.664 | 4391.6 samples/s | 68.6 steps/s
[Step=45450 Epoch=175.0] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.960 | L2-Norm(final)=6.666 | 4422.1 samples/s | 69.1 steps/s
[Step=45500 Epoch=175.1] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.940 | L2-Norm(final)=6.667 | 4332.4 samples/s | 67.7 steps/s
[Step=45550 Epoch=175.3] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.919 | L2-Norm(final)=6.669 | 2694.2 samples/s | 42.1 steps/s
[Step=45600 Epoch=175.5] | Loss=0.00000 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.898 | L2-Norm(final)=6.670 | 4396.3 samples/s | 68.7 steps/s
[Step=45650 Epoch=175.7] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.877 | L2-Norm(final)=6.672 | 4372.8 samples/s | 68.3 steps/s
[Step=45700 Epoch=175.9] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.856 | L2-Norm(final)=6.673 | 4413.2 samples/s | 69.0 steps/s
[Step=45750 Epoch=176.1] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.835 | L2-Norm(final)=6.675 | 4332.5 samples/s | 67.7 steps/s
[Step=45800 Epoch=176.3] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.813 | L2-Norm(final)=6.677 | 7203.1 samples/s | 112.5 steps/s
[Step=45850 Epoch=176.5] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.792 | L2-Norm(final)=6.679 | 2176.1 samples/s | 34.0 steps/s
[Step=45900 Epoch=176.7] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.770 | L2-Norm(final)=6.680 | 4355.6 samples/s | 68.1 steps/s
[Step=45950 Epoch=176.9] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.748 | L2-Norm(final)=6.682 | 4402.1 samples/s | 68.8 steps/s
[Step=46000 Epoch=177.1] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.726 | L2-Norm(final)=6.684 | 4360.8 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08701 | acc=0.9672 | tpr=0.9747 | fpr=0.0491 | 5232.2 samples/s | 20.4 steps/s
Avg test loss: 0.08748, Avg test acc: 0.96731, Avg tpr: 0.97535, Avg fpr: 0.05038, total FA: 393

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.09387 | acc=0.9677 | tpr=0.9791 | fpr=0.0570 | 5210.3 samples/s | 20.4 steps/s
Avg test loss: 0.09732, Avg test acc: 0.96755, Avg tpr: 0.97832, Avg fpr: 0.05615, total FA: 438

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.53617 | acc=0.3094 | tpr=0.0068 | fpr=0.0337 | 5217.6 samples/s | 20.4 steps/s
Avg test loss: 5.54601, Avg test acc: 0.30696, Avg tpr: 0.00676, Avg fpr: 0.03282, total FA: 256

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.51735 | acc=0.3045 | tpr=0.0086 | fpr=0.0530 | 5256.6 samples/s | 20.5 steps/s
Avg test loss: 5.52663, Avg test acc: 0.30351, Avg tpr: 0.00892, Avg fpr: 0.04858, total FA: 379

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.12654 | acc=0.1158 | tpr=0.7168 | fpr=0.8950 | 5306.4 samples/s | 20.7 steps/s
[Step= 100] | Loss=7.08656 | acc=0.1169 | tpr=0.7271 | fpr=0.8945 | 7095.9 samples/s | 27.7 steps/s
[Step= 150] | Loss=7.08788 | acc=0.1179 | tpr=0.7435 | fpr=0.8937 | 7923.8 samples/s | 31.0 steps/s
[Step= 200] | Loss=7.10052 | acc=0.1169 | tpr=0.7475 | fpr=0.8946 | 7770.2 samples/s | 30.4 steps/s
[Step= 250] | Loss=7.10472 | acc=0.1173 | tpr=0.7441 | fpr=0.8941 | 8388.8 samples/s | 32.8 steps/s
[Step= 300] | Loss=7.10101 | acc=0.1178 | tpr=0.7520 | fpr=0.8938 | 8034.2 samples/s | 31.4 steps/s
[Step= 350] | Loss=7.09095 | acc=0.1178 | tpr=0.7458 | fpr=0.8936 | 8269.4 samples/s | 32.3 steps/s
[Step= 400] | Loss=7.08127 | acc=0.1183 | tpr=0.7505 | fpr=0.8932 | 8168.4 samples/s | 31.9 steps/s
[Step= 450] | Loss=7.08017 | acc=0.1179 | tpr=0.7468 | fpr=0.8935 | 8207.9 samples/s | 32.1 steps/s
[Step= 500] | Loss=7.08223 | acc=0.1177 | tpr=0.7471 | fpr=0.8936 | 8058.1 samples/s | 31.5 steps/s
[Step= 550] | Loss=7.08018 | acc=0.1181 | tpr=0.7417 | fpr=0.8932 | 14172.1 samples/s | 55.4 steps/s
Avg test loss: 7.08030, Avg test acc: 0.11801, Avg tpr: 0.74168, Avg fpr: 0.89332, total FA: 124036

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.73156 | acc=0.1201 | tpr=0.6991 | fpr=0.8903 | 5408.7 samples/s | 21.1 steps/s
[Step= 100] | Loss=7.71158 | acc=0.1203 | tpr=0.6780 | fpr=0.8901 | 7094.0 samples/s | 27.7 steps/s
[Step= 150] | Loss=7.69894 | acc=0.1210 | tpr=0.6830 | fpr=0.8894 | 7662.6 samples/s | 29.9 steps/s
[Step= 200] | Loss=7.70849 | acc=0.1205 | tpr=0.6831 | fpr=0.8897 | 8045.7 samples/s | 31.4 steps/s
[Step= 250] | Loss=7.71299 | acc=0.1211 | tpr=0.6838 | fpr=0.8891 | 8032.4 samples/s | 31.4 steps/s
[Step= 300] | Loss=7.71682 | acc=0.1207 | tpr=0.6887 | fpr=0.8897 | 8358.6 samples/s | 32.7 steps/s
[Step= 350] | Loss=7.70667 | acc=0.1208 | tpr=0.6869 | fpr=0.8895 | 8049.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=7.69784 | acc=0.1215 | tpr=0.6898 | fpr=0.8889 | 8274.1 samples/s | 32.3 steps/s
[Step= 450] | Loss=7.69429 | acc=0.1208 | tpr=0.6889 | fpr=0.8895 | 8025.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=7.69607 | acc=0.1206 | tpr=0.6881 | fpr=0.8897 | 8110.4 samples/s | 31.7 steps/s
[Step= 550] | Loss=7.69382 | acc=0.1208 | tpr=0.6836 | fpr=0.8894 | 14219.4 samples/s | 55.5 steps/s
Avg test loss: 7.69451, Avg test acc: 0.12079, Avg tpr: 0.68304, Avg fpr: 0.88943, total FA: 123495

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13669 | acc=0.9794 | tpr=0.9381 | fpr=0.0199 | 5443.8 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.14112 | acc=0.9785 | tpr=0.9467 | fpr=0.0209 | 7280.1 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.14649 | acc=0.9774 | tpr=0.9452 | fpr=0.0220 | 7370.2 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.14941 | acc=0.9774 | tpr=0.9443 | fpr=0.0220 | 8283.2 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.14735 | acc=0.9778 | tpr=0.9432 | fpr=0.0216 | 8035.9 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.14995 | acc=0.9775 | tpr=0.9433 | fpr=0.0219 | 8017.9 samples/s | 31.3 steps/s
[Step= 350] | Loss=0.15061 | acc=0.9772 | tpr=0.9461 | fpr=0.0222 | 8021.4 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.15235 | acc=0.9770 | tpr=0.9442 | fpr=0.0224 | 8165.3 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.15582 | acc=0.9765 | tpr=0.9440 | fpr=0.0229 | 8009.7 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.15499 | acc=0.9765 | tpr=0.9441 | fpr=0.0229 | 8261.7 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.15383 | acc=0.9767 | tpr=0.9431 | fpr=0.0227 | 14606.6 samples/s | 57.1 steps/s
Avg test loss: 0.15346, Avg test acc: 0.97669, Avg tpr: 0.94216, Avg fpr: 0.02268, total FA: 3149

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15971 | acc=0.9775 | tpr=0.9425 | fpr=0.0219 | 5422.2 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.16488 | acc=0.9771 | tpr=0.9467 | fpr=0.0223 | 7285.5 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.17040 | acc=0.9762 | tpr=0.9524 | fpr=0.0233 | 7536.9 samples/s | 29.4 steps/s
[Step= 200] | Loss=0.17474 | acc=0.9760 | tpr=0.9541 | fpr=0.0236 | 7894.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.17138 | acc=0.9767 | tpr=0.9555 | fpr=0.0229 | 8363.6 samples/s | 32.7 steps/s
[Step= 300] | Loss=0.17465 | acc=0.9763 | tpr=0.9513 | fpr=0.0232 | 7839.3 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.17589 | acc=0.9761 | tpr=0.9524 | fpr=0.0235 | 8138.4 samples/s | 31.8 steps/s
[Step= 400] | Loss=0.17741 | acc=0.9760 | tpr=0.9497 | fpr=0.0236 | 8545.7 samples/s | 33.4 steps/s
[Step= 450] | Loss=0.18096 | acc=0.9755 | tpr=0.9494 | fpr=0.0240 | 7977.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.18018 | acc=0.9755 | tpr=0.9507 | fpr=0.0240 | 7990.0 samples/s | 31.2 steps/s
[Step= 550] | Loss=0.17890 | acc=0.9756 | tpr=0.9491 | fpr=0.0239 | 14702.7 samples/s | 57.4 steps/s
Avg test loss: 0.17843, Avg test acc: 0.97564, Avg tpr: 0.94810, Avg fpr: 0.02386, total FA: 3313

server round 23/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=89.7] | Loss=0.00343 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.164 | L2-Norm(final)=8.137 | 6747.9 samples/s | 105.4 steps/s
[Step=46050 Epoch=89.8] | Loss=0.00528 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.163 | L2-Norm(final)=8.141 | 4375.8 samples/s | 68.4 steps/s
[Step=46100 Epoch=89.9] | Loss=0.00549 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.161 | L2-Norm(final)=8.147 | 5181.8 samples/s | 81.0 steps/s
[Step=46150 Epoch=90.0] | Loss=0.00527 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.160 | L2-Norm(final)=8.150 | 5184.6 samples/s | 81.0 steps/s
[Step=46200 Epoch=90.1] | Loss=0.00523 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.159 | L2-Norm(final)=8.154 | 5311.8 samples/s | 83.0 steps/s
[Step=46250 Epoch=90.2] | Loss=0.00521 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.157 | L2-Norm(final)=8.159 | 5077.3 samples/s | 79.3 steps/s
[Step=46300 Epoch=90.3] | Loss=0.00502 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.156 | L2-Norm(final)=8.163 | 5302.7 samples/s | 82.9 steps/s
[Step=46350 Epoch=90.4] | Loss=0.00517 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.154 | L2-Norm(final)=8.167 | 5113.0 samples/s | 79.9 steps/s
[Step=46400 Epoch=90.5] | Loss=0.00525 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.153 | L2-Norm(final)=8.172 | 5189.3 samples/s | 81.1 steps/s
[Step=46450 Epoch=90.6] | Loss=0.00524 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.152 | L2-Norm(final)=8.176 | 5279.7 samples/s | 82.5 steps/s
[Step=46500 Epoch=90.7] | Loss=0.00534 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.150 | L2-Norm(final)=8.181 | 6846.3 samples/s | 107.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=90.7] | Loss=0.00008 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.138 | L2-Norm(final)=8.227 | 6378.7 samples/s | 99.7 steps/s
[Step=46550 Epoch=90.8] | Loss=0.00626 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.138 | L2-Norm(final)=8.232 | 4121.1 samples/s | 64.4 steps/s
[Step=46600 Epoch=90.9] | Loss=0.00587 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.141 | L2-Norm(final)=8.236 | 4622.5 samples/s | 72.2 steps/s
[Step=46650 Epoch=91.0] | Loss=0.00640 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.144 | L2-Norm(final)=8.240 | 4602.2 samples/s | 71.9 steps/s
[Step=46700 Epoch=91.1] | Loss=0.00639 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.149 | L2-Norm(final)=8.244 | 4620.0 samples/s | 72.2 steps/s
[Step=46750 Epoch=91.2] | Loss=0.00714 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.152 | L2-Norm(final)=8.247 | 4668.6 samples/s | 72.9 steps/s
[Step=46800 Epoch=91.3] | Loss=0.00728 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.154 | L2-Norm(final)=8.249 | 4584.4 samples/s | 71.6 steps/s
[Step=46850 Epoch=91.4] | Loss=0.00763 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.157 | L2-Norm(final)=8.252 | 4620.6 samples/s | 72.2 steps/s
[Step=46900 Epoch=91.5] | Loss=0.00766 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.159 | L2-Norm(final)=8.254 | 4627.4 samples/s | 72.3 steps/s
[Step=46950 Epoch=91.6] | Loss=0.00780 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.161 | L2-Norm(final)=8.256 | 4676.7 samples/s | 73.1 steps/s
[Step=47000 Epoch=91.7] | Loss=0.00775 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.162 | L2-Norm(final)=8.259 | 5881.0 samples/s | 91.9 steps/s
[Step=47050 Epoch=91.8] | Loss=0.00789 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.164 | L2-Norm(final)=8.262 | 2441.7 samples/s | 38.2 steps/s
[Step=47100 Epoch=91.9] | Loss=0.00789 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.166 | L2-Norm(final)=8.265 | 4683.3 samples/s | 73.2 steps/s
[Step=47150 Epoch=92.0] | Loss=0.00784 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.168 | L2-Norm(final)=8.268 | 4640.3 samples/s | 72.5 steps/s
[Step=47200 Epoch=92.1] | Loss=0.00771 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.170 | L2-Norm(final)=8.271 | 4572.0 samples/s | 71.4 steps/s
[Step=47250 Epoch=92.2] | Loss=0.00771 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.171 | L2-Norm(final)=8.275 | 4605.7 samples/s | 72.0 steps/s
[Step=47300 Epoch=92.3] | Loss=0.00767 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.173 | L2-Norm(final)=8.278 | 4673.9 samples/s | 73.0 steps/s
[Step=47350 Epoch=92.4] | Loss=0.00742 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.174 | L2-Norm(final)=8.281 | 4721.1 samples/s | 73.8 steps/s
[Step=47400 Epoch=92.4] | Loss=0.00728 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.175 | L2-Norm(final)=8.284 | 4523.5 samples/s | 70.7 steps/s
[Step=47450 Epoch=92.5] | Loss=0.00730 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.176 | L2-Norm(final)=8.287 | 4651.8 samples/s | 72.7 steps/s
[Step=47500 Epoch=92.6] | Loss=0.00725 | Reg=0.00295 | acc=0.9688 | L2-Norm=17.177 | L2-Norm(final)=8.290 | 4970.5 samples/s | 77.7 steps/s
[Step=47550 Epoch=92.7] | Loss=0.00730 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.177 | L2-Norm(final)=8.292 | 2639.3 samples/s | 41.2 steps/s
[Step=47600 Epoch=92.8] | Loss=0.00728 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.295 | 4603.6 samples/s | 71.9 steps/s
[Step=47650 Epoch=92.9] | Loss=0.00721 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.298 | 4715.5 samples/s | 73.7 steps/s
[Step=47700 Epoch=93.0] | Loss=0.00713 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.178 | L2-Norm(final)=8.300 | 4536.7 samples/s | 70.9 steps/s
[Step=47750 Epoch=93.1] | Loss=0.00709 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.303 | 4683.1 samples/s | 73.2 steps/s
[Step=47800 Epoch=93.2] | Loss=0.00706 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.306 | 4630.7 samples/s | 72.4 steps/s
[Step=47850 Epoch=93.3] | Loss=0.00703 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.178 | L2-Norm(final)=8.308 | 4571.8 samples/s | 71.4 steps/s
[Step=47900 Epoch=93.4] | Loss=0.00703 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.310 | 4623.8 samples/s | 72.2 steps/s
[Step=47950 Epoch=93.5] | Loss=0.00696 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.313 | 4683.0 samples/s | 73.2 steps/s
[Step=48000 Epoch=93.6] | Loss=0.00699 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.178 | L2-Norm(final)=8.315 | 4599.5 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step48000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=89.9] | Loss=0.00039 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.647 | L2-Norm(final)=8.597 | 6482.9 samples/s | 101.3 steps/s
[Step=46050 Epoch=90.0] | Loss=0.00350 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.646 | L2-Norm(final)=8.601 | 4587.2 samples/s | 71.7 steps/s
[Step=46100 Epoch=90.1] | Loss=0.00486 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.645 | L2-Norm(final)=8.605 | 5154.4 samples/s | 80.5 steps/s
[Step=46150 Epoch=90.2] | Loss=0.00472 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.643 | L2-Norm(final)=8.610 | 5405.7 samples/s | 84.5 steps/s
[Step=46200 Epoch=90.3] | Loss=0.00502 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.641 | L2-Norm(final)=8.614 | 4983.8 samples/s | 77.9 steps/s
[Step=46250 Epoch=90.4] | Loss=0.00493 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.639 | L2-Norm(final)=8.618 | 5230.2 samples/s | 81.7 steps/s
[Step=46300 Epoch=90.5] | Loss=0.00511 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.637 | L2-Norm(final)=8.623 | 5197.7 samples/s | 81.2 steps/s
[Step=46350 Epoch=90.6] | Loss=0.00508 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.635 | L2-Norm(final)=8.627 | 5162.0 samples/s | 80.7 steps/s
[Step=46400 Epoch=90.7] | Loss=0.00509 | Reg=0.00311 | acc=0.9688 | L2-Norm=17.634 | L2-Norm(final)=8.631 | 5268.5 samples/s | 82.3 steps/s
[Step=46450 Epoch=90.8] | Loss=0.00512 | Reg=0.00311 | acc=1.0000 | L2-Norm=17.632 | L2-Norm(final)=8.635 | 5167.7 samples/s | 80.7 steps/s
[Step=46500 Epoch=90.9] | Loss=0.00516 | Reg=0.00311 | acc=0.9844 | L2-Norm=17.630 | L2-Norm(final)=8.640 | 7070.6 samples/s | 110.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=90.9] | Loss=0.00291 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.613 | L2-Norm(final)=8.685 | 5988.9 samples/s | 93.6 steps/s
[Step=46550 Epoch=91.0] | Loss=0.00531 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.615 | L2-Norm(final)=8.691 | 4340.5 samples/s | 67.8 steps/s
[Step=46600 Epoch=91.1] | Loss=0.00664 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.616 | L2-Norm(final)=8.695 | 4664.5 samples/s | 72.9 steps/s
[Step=46650 Epoch=91.2] | Loss=0.00670 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.617 | L2-Norm(final)=8.699 | 4570.4 samples/s | 71.4 steps/s
[Step=46700 Epoch=91.3] | Loss=0.00687 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.617 | L2-Norm(final)=8.702 | 4617.3 samples/s | 72.1 steps/s
[Step=46750 Epoch=91.4] | Loss=0.00741 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=8.704 | 4622.5 samples/s | 72.2 steps/s
[Step=46800 Epoch=91.5] | Loss=0.00743 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.618 | L2-Norm(final)=8.706 | 4653.5 samples/s | 72.7 steps/s
[Step=46850 Epoch=91.6] | Loss=0.00727 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.618 | L2-Norm(final)=8.709 | 4594.5 samples/s | 71.8 steps/s
[Step=46900 Epoch=91.7] | Loss=0.00732 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.619 | L2-Norm(final)=8.712 | 4618.5 samples/s | 72.2 steps/s
[Step=46950 Epoch=91.8] | Loss=0.00737 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.619 | L2-Norm(final)=8.715 | 4591.7 samples/s | 71.7 steps/s
[Step=47000 Epoch=91.9] | Loss=0.00739 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.619 | L2-Norm(final)=8.718 | 6042.8 samples/s | 94.4 steps/s
[Step=47050 Epoch=92.0] | Loss=0.00731 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.620 | L2-Norm(final)=8.720 | 2417.4 samples/s | 37.8 steps/s
[Step=47100 Epoch=92.1] | Loss=0.00719 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.620 | L2-Norm(final)=8.723 | 4622.9 samples/s | 72.2 steps/s
[Step=47150 Epoch=92.2] | Loss=0.00716 | Reg=0.00310 | acc=0.9688 | L2-Norm=17.620 | L2-Norm(final)=8.726 | 4662.9 samples/s | 72.9 steps/s
[Step=47200 Epoch=92.3] | Loss=0.00712 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.619 | L2-Norm(final)=8.729 | 4564.5 samples/s | 71.3 steps/s
[Step=47250 Epoch=92.4] | Loss=0.00719 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.619 | L2-Norm(final)=8.731 | 4631.9 samples/s | 72.4 steps/s
[Step=47300 Epoch=92.5] | Loss=0.00719 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.618 | L2-Norm(final)=8.734 | 4611.0 samples/s | 72.0 steps/s
[Step=47350 Epoch=92.6] | Loss=0.00708 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=8.737 | 4627.5 samples/s | 72.3 steps/s
[Step=47400 Epoch=92.7] | Loss=0.00715 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=8.739 | 4688.1 samples/s | 73.3 steps/s
[Step=47450 Epoch=92.8] | Loss=0.00716 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.618 | L2-Norm(final)=8.742 | 4603.6 samples/s | 71.9 steps/s
[Step=47500 Epoch=92.9] | Loss=0.00711 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.617 | L2-Norm(final)=8.744 | 5111.0 samples/s | 79.9 steps/s
[Step=47550 Epoch=93.0] | Loss=0.00710 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.617 | L2-Norm(final)=8.747 | 2656.2 samples/s | 41.5 steps/s
[Step=47600 Epoch=93.1] | Loss=0.00699 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.617 | L2-Norm(final)=8.750 | 4633.1 samples/s | 72.4 steps/s
[Step=47650 Epoch=93.2] | Loss=0.00696 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.617 | L2-Norm(final)=8.752 | 4505.6 samples/s | 70.4 steps/s
[Step=47700 Epoch=93.3] | Loss=0.00691 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.617 | L2-Norm(final)=8.755 | 4594.7 samples/s | 71.8 steps/s
[Step=47750 Epoch=93.4] | Loss=0.00686 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.616 | L2-Norm(final)=8.758 | 4676.9 samples/s | 73.1 steps/s
[Step=47800 Epoch=93.4] | Loss=0.00683 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.615 | L2-Norm(final)=8.761 | 4686.9 samples/s | 73.2 steps/s
[Step=47850 Epoch=93.5] | Loss=0.00689 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.615 | L2-Norm(final)=8.763 | 4513.2 samples/s | 70.5 steps/s
[Step=47900 Epoch=93.6] | Loss=0.00684 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=8.765 | 4640.2 samples/s | 72.5 steps/s
[Step=47950 Epoch=93.7] | Loss=0.00681 | Reg=0.00310 | acc=1.0000 | L2-Norm=17.614 | L2-Norm(final)=8.768 | 4667.8 samples/s | 72.9 steps/s
[Step=48000 Epoch=93.8] | Loss=0.00681 | Reg=0.00310 | acc=0.9844 | L2-Norm=17.614 | L2-Norm(final)=8.770 | 4640.2 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step48000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=176.3] | Loss=0.00004 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.686 | L2-Norm(final)=6.473 | 6580.6 samples/s | 102.8 steps/s
[Step=46050 Epoch=176.4] | Loss=0.00005 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.692 | L2-Norm(final)=6.482 | 4178.1 samples/s | 65.3 steps/s
[Step=46100 Epoch=176.6] | Loss=0.00012 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.710 | L2-Norm(final)=6.496 | 4881.2 samples/s | 76.3 steps/s
[Step=46150 Epoch=176.8] | Loss=0.00018 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.735 | L2-Norm(final)=6.511 | 4864.2 samples/s | 76.0 steps/s
[Step=46200 Epoch=177.0] | Loss=0.00015 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.755 | L2-Norm(final)=6.522 | 4845.5 samples/s | 75.7 steps/s
[Step=46250 Epoch=177.2] | Loss=0.00013 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.767 | L2-Norm(final)=6.531 | 6545.2 samples/s | 102.3 steps/s
[Step=46300 Epoch=177.4] | Loss=0.00011 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.774 | L2-Norm(final)=6.538 | 2459.0 samples/s | 38.4 steps/s
[Step=46350 Epoch=177.6] | Loss=0.00010 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.778 | L2-Norm(final)=6.543 | 4967.6 samples/s | 77.6 steps/s
[Step=46400 Epoch=177.8] | Loss=0.00009 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.781 | L2-Norm(final)=6.548 | 4779.4 samples/s | 74.7 steps/s
[Step=46450 Epoch=178.0] | Loss=0.00008 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.783 | L2-Norm(final)=6.552 | 5086.9 samples/s | 79.5 steps/s
[Step=46500 Epoch=178.2] | Loss=0.00007 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.783 | L2-Norm(final)=6.555 | 5432.7 samples/s | 84.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=178.2] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.789 | L2-Norm(final)=6.588 | 6629.5 samples/s | 103.6 steps/s
[Step=46550 Epoch=178.4] | Loss=0.00001 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.764 | L2-Norm(final)=6.590 | 3773.9 samples/s | 59.0 steps/s
[Step=46600 Epoch=178.6] | Loss=0.00058 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.744 | L2-Norm(final)=6.590 | 4404.3 samples/s | 68.8 steps/s
[Step=46650 Epoch=178.7] | Loss=0.00164 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.766 | L2-Norm(final)=6.585 | 4413.6 samples/s | 69.0 steps/s
[Step=46700 Epoch=178.9] | Loss=0.00165 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.788 | L2-Norm(final)=6.580 | 4335.8 samples/s | 67.7 steps/s
[Step=46750 Epoch=179.1] | Loss=0.00139 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.803 | L2-Norm(final)=6.578 | 5901.0 samples/s | 92.2 steps/s
[Step=46800 Epoch=179.3] | Loss=0.00117 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.812 | L2-Norm(final)=6.577 | 2327.7 samples/s | 36.4 steps/s
[Step=46850 Epoch=179.5] | Loss=0.00101 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.818 | L2-Norm(final)=6.577 | 4352.8 samples/s | 68.0 steps/s
[Step=46900 Epoch=179.7] | Loss=0.00089 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.822 | L2-Norm(final)=6.577 | 4352.7 samples/s | 68.0 steps/s
[Step=46950 Epoch=179.9] | Loss=0.00080 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.825 | L2-Norm(final)=6.577 | 4426.7 samples/s | 69.2 steps/s
[Step=47000 Epoch=180.1] | Loss=0.00072 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.827 | L2-Norm(final)=6.577 | 4933.9 samples/s | 77.1 steps/s
[Step=47050 Epoch=180.3] | Loss=0.00065 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.828 | L2-Norm(final)=6.578 | 2500.9 samples/s | 39.1 steps/s
[Step=47100 Epoch=180.5] | Loss=0.00060 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.829 | L2-Norm(final)=6.578 | 4435.2 samples/s | 69.3 steps/s
[Step=47150 Epoch=180.7] | Loss=0.00056 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.829 | L2-Norm(final)=6.579 | 4371.8 samples/s | 68.3 steps/s
[Step=47200 Epoch=180.9] | Loss=0.00052 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.829 | L2-Norm(final)=6.579 | 4365.8 samples/s | 68.2 steps/s
[Step=47250 Epoch=181.0] | Loss=0.00048 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.828 | L2-Norm(final)=6.580 | 4424.5 samples/s | 69.1 steps/s
[Step=47300 Epoch=181.2] | Loss=0.00045 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.828 | L2-Norm(final)=6.580 | 2667.6 samples/s | 41.7 steps/s
[Step=47350 Epoch=181.4] | Loss=0.00043 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.827 | L2-Norm(final)=6.581 | 4424.5 samples/s | 69.1 steps/s
[Step=47400 Epoch=181.6] | Loss=0.00040 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.826 | L2-Norm(final)=6.581 | 4431.4 samples/s | 69.2 steps/s
[Step=47450 Epoch=181.8] | Loss=0.00038 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.825 | L2-Norm(final)=6.582 | 4411.3 samples/s | 68.9 steps/s
[Step=47500 Epoch=182.0] | Loss=0.00036 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.823 | L2-Norm(final)=6.583 | 4255.4 samples/s | 66.5 steps/s
[Step=47550 Epoch=182.2] | Loss=0.00035 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.822 | L2-Norm(final)=6.583 | 2685.0 samples/s | 42.0 steps/s
[Step=47600 Epoch=182.4] | Loss=0.00033 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.820 | L2-Norm(final)=6.584 | 4384.4 samples/s | 68.5 steps/s
[Step=47650 Epoch=182.6] | Loss=0.00032 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.819 | L2-Norm(final)=6.584 | 4439.1 samples/s | 69.4 steps/s
[Step=47700 Epoch=182.8] | Loss=0.00030 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.817 | L2-Norm(final)=6.585 | 4238.9 samples/s | 66.2 steps/s
[Step=47750 Epoch=183.0] | Loss=0.00029 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.815 | L2-Norm(final)=6.585 | 4432.3 samples/s | 69.3 steps/s
[Step=47800 Epoch=183.2] | Loss=0.00028 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.813 | L2-Norm(final)=6.586 | 6377.2 samples/s | 99.6 steps/s
[Step=47850 Epoch=183.3] | Loss=0.00027 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.812 | L2-Norm(final)=6.586 | 2243.3 samples/s | 35.1 steps/s
[Step=47900 Epoch=183.5] | Loss=0.00026 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.810 | L2-Norm(final)=6.587 | 4386.2 samples/s | 68.5 steps/s
[Step=47950 Epoch=183.7] | Loss=0.00025 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.808 | L2-Norm(final)=6.588 | 4423.9 samples/s | 69.1 steps/s
[Step=48000 Epoch=183.9] | Loss=0.00024 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.805 | L2-Norm(final)=6.588 | 4334.8 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step48000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=177.1] | Loss=0.00005 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.649 | L2-Norm(final)=6.742 | 5760.8 samples/s | 90.0 steps/s
[Step=46050 Epoch=177.3] | Loss=0.00038 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.672 | L2-Norm(final)=6.757 | 4625.2 samples/s | 72.3 steps/s
[Step=46100 Epoch=177.5] | Loss=0.00022 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.705 | L2-Norm(final)=6.771 | 4887.2 samples/s | 76.4 steps/s
[Step=46150 Epoch=177.6] | Loss=0.00016 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.718 | L2-Norm(final)=6.779 | 4942.3 samples/s | 77.2 steps/s
[Step=46200 Epoch=177.8] | Loss=0.00013 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.725 | L2-Norm(final)=6.785 | 4884.7 samples/s | 76.3 steps/s
[Step=46250 Epoch=178.0] | Loss=0.00011 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.729 | L2-Norm(final)=6.790 | 6894.2 samples/s | 107.7 steps/s
[Step=46300 Epoch=178.2] | Loss=0.00010 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.731 | L2-Norm(final)=6.794 | 2444.1 samples/s | 38.2 steps/s
[Step=46350 Epoch=178.4] | Loss=0.00008 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=6.798 | 4923.7 samples/s | 76.9 steps/s
[Step=46400 Epoch=178.6] | Loss=0.00008 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=6.802 | 4955.1 samples/s | 77.4 steps/s
[Step=46450 Epoch=178.8] | Loss=0.00007 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=6.805 | 4899.1 samples/s | 76.5 steps/s
[Step=46500 Epoch=179.0] | Loss=0.00006 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=6.808 | 5838.6 samples/s | 91.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=179.0] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.728 | L2-Norm(final)=6.840 | 6674.4 samples/s | 104.3 steps/s
[Step=46550 Epoch=179.2] | Loss=0.00001 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.703 | L2-Norm(final)=6.842 | 3835.2 samples/s | 59.9 steps/s
[Step=46600 Epoch=179.4] | Loss=0.00001 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.669 | L2-Norm(final)=6.843 | 4365.4 samples/s | 68.2 steps/s
[Step=46650 Epoch=179.6] | Loss=0.00001 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.635 | L2-Norm(final)=6.845 | 4396.9 samples/s | 68.7 steps/s
[Step=46700 Epoch=179.8] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.601 | L2-Norm(final)=6.846 | 4376.3 samples/s | 68.4 steps/s
[Step=46750 Epoch=180.0] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.568 | L2-Norm(final)=6.848 | 5997.6 samples/s | 93.7 steps/s
[Step=46800 Epoch=180.2] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.534 | L2-Norm(final)=6.849 | 2304.6 samples/s | 36.0 steps/s
[Step=46850 Epoch=180.3] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.499 | L2-Norm(final)=6.850 | 4421.3 samples/s | 69.1 steps/s
[Step=46900 Epoch=180.5] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.465 | L2-Norm(final)=6.851 | 4367.1 samples/s | 68.2 steps/s
[Step=46950 Epoch=180.7] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.430 | L2-Norm(final)=6.852 | 4374.9 samples/s | 68.4 steps/s
[Step=47000 Epoch=180.9] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.394 | L2-Norm(final)=6.853 | 5142.2 samples/s | 80.3 steps/s
[Step=47050 Epoch=181.1] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.359 | L2-Norm(final)=6.853 | 2465.2 samples/s | 38.5 steps/s
[Step=47100 Epoch=181.3] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.323 | L2-Norm(final)=6.854 | 4415.2 samples/s | 69.0 steps/s
[Step=47150 Epoch=181.5] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.287 | L2-Norm(final)=6.855 | 4369.8 samples/s | 68.3 steps/s
[Step=47200 Epoch=181.7] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.251 | L2-Norm(final)=6.856 | 4376.3 samples/s | 68.4 steps/s
[Step=47250 Epoch=181.9] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.215 | L2-Norm(final)=6.856 | 4485.5 samples/s | 70.1 steps/s
[Step=47300 Epoch=182.1] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.179 | L2-Norm(final)=6.857 | 2629.8 samples/s | 41.1 steps/s
[Step=47350 Epoch=182.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=6.858 | 4405.9 samples/s | 68.8 steps/s
[Step=47400 Epoch=182.5] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.107 | L2-Norm(final)=6.859 | 4562.9 samples/s | 71.3 steps/s
[Step=47450 Epoch=182.7] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.070 | L2-Norm(final)=6.860 | 4268.0 samples/s | 66.7 steps/s
[Step=47500 Epoch=182.8] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.033 | L2-Norm(final)=6.861 | 4331.9 samples/s | 67.7 steps/s
[Step=47550 Epoch=183.0] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.997 | L2-Norm(final)=6.862 | 2679.9 samples/s | 41.9 steps/s
[Step=47600 Epoch=183.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.960 | L2-Norm(final)=6.863 | 4360.1 samples/s | 68.1 steps/s
[Step=47650 Epoch=183.4] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.923 | L2-Norm(final)=6.864 | 4417.1 samples/s | 69.0 steps/s
[Step=47700 Epoch=183.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.886 | L2-Norm(final)=6.865 | 4373.6 samples/s | 68.3 steps/s
[Step=47750 Epoch=183.8] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.849 | L2-Norm(final)=6.866 | 4487.1 samples/s | 70.1 steps/s
[Step=47800 Epoch=184.0] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=6.867 | 6812.8 samples/s | 106.4 steps/s
[Step=47850 Epoch=184.2] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.775 | L2-Norm(final)=6.868 | 2187.8 samples/s | 34.2 steps/s
[Step=47900 Epoch=184.4] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.738 | L2-Norm(final)=6.869 | 4365.5 samples/s | 68.2 steps/s
[Step=47950 Epoch=184.6] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.700 | L2-Norm(final)=6.870 | 4403.3 samples/s | 68.8 steps/s
[Step=48000 Epoch=184.8] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.662 | L2-Norm(final)=6.872 | 4305.3 samples/s | 67.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08897 | acc=0.9691 | tpr=0.9767 | fpr=0.0476 | 5237.0 samples/s | 20.5 steps/s
Avg test loss: 0.09053, Avg test acc: 0.96706, Avg tpr: 0.97604, Avg fpr: 0.05269, total FA: 411

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08963 | acc=0.9684 | tpr=0.9796 | fpr=0.0557 | 5466.0 samples/s | 21.4 steps/s
Avg test loss: 0.09177, Avg test acc: 0.96755, Avg tpr: 0.97948, Avg fpr: 0.05871, total FA: 458

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.40158 | acc=0.3101 | tpr=0.0073 | fpr=0.0325 | 5419.9 samples/s | 21.2 steps/s
Avg test loss: 5.41745, Avg test acc: 0.30808, Avg tpr: 0.00711, Avg fpr: 0.03000, total FA: 234

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.18141 | acc=0.3068 | tpr=0.0091 | fpr=0.0468 | 5235.5 samples/s | 20.5 steps/s
Avg test loss: 5.18787, Avg test acc: 0.30547, Avg tpr: 0.00863, Avg fpr: 0.04166, total FA: 325

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.14538 | acc=0.1174 | tpr=0.7035 | fpr=0.8931 | 5158.4 samples/s | 20.2 steps/s
[Step= 100] | Loss=7.11809 | acc=0.1160 | tpr=0.6802 | fpr=0.8945 | 7253.1 samples/s | 28.3 steps/s
[Step= 150] | Loss=7.11711 | acc=0.1171 | tpr=0.6830 | fpr=0.8934 | 7976.0 samples/s | 31.2 steps/s
[Step= 200] | Loss=7.12905 | acc=0.1158 | tpr=0.6852 | fpr=0.8946 | 8349.3 samples/s | 32.6 steps/s
[Step= 250] | Loss=7.13222 | acc=0.1163 | tpr=0.6847 | fpr=0.8941 | 7949.4 samples/s | 31.1 steps/s
[Step= 300] | Loss=7.12805 | acc=0.1159 | tpr=0.6895 | fpr=0.8946 | 8284.9 samples/s | 32.4 steps/s
[Step= 350] | Loss=7.11582 | acc=0.1158 | tpr=0.6900 | fpr=0.8946 | 7973.0 samples/s | 31.1 steps/s
[Step= 400] | Loss=7.10740 | acc=0.1163 | tpr=0.6937 | fpr=0.8941 | 8078.1 samples/s | 31.6 steps/s
[Step= 450] | Loss=7.10739 | acc=0.1159 | tpr=0.6928 | fpr=0.8946 | 7849.3 samples/s | 30.7 steps/s
[Step= 500] | Loss=7.10763 | acc=0.1156 | tpr=0.6907 | fpr=0.8948 | 8396.5 samples/s | 32.8 steps/s
[Step= 550] | Loss=7.10728 | acc=0.1160 | tpr=0.6864 | fpr=0.8944 | 14492.6 samples/s | 56.6 steps/s
Avg test loss: 7.10809, Avg test acc: 0.11594, Avg tpr: 0.68661, Avg fpr: 0.89443, total FA: 124190

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.22446 | acc=0.1169 | tpr=0.7434 | fpr=0.8944 | 5151.1 samples/s | 20.1 steps/s
[Step= 100] | Loss=7.18899 | acc=0.1174 | tpr=0.7441 | fpr=0.8943 | 7272.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=7.18168 | acc=0.1176 | tpr=0.7478 | fpr=0.8940 | 8107.5 samples/s | 31.7 steps/s
[Step= 200] | Loss=7.19313 | acc=0.1168 | tpr=0.7432 | fpr=0.8946 | 7964.3 samples/s | 31.1 steps/s
[Step= 250] | Loss=7.19683 | acc=0.1171 | tpr=0.7362 | fpr=0.8942 | 8432.4 samples/s | 32.9 steps/s
[Step= 300] | Loss=7.20364 | acc=0.1166 | tpr=0.7389 | fpr=0.8947 | 8225.8 samples/s | 32.1 steps/s
[Step= 350] | Loss=7.18965 | acc=0.1169 | tpr=0.7339 | fpr=0.8943 | 8018.9 samples/s | 31.3 steps/s
[Step= 400] | Loss=7.18287 | acc=0.1177 | tpr=0.7347 | fpr=0.8935 | 8242.3 samples/s | 32.2 steps/s
[Step= 450] | Loss=7.17777 | acc=0.1170 | tpr=0.7342 | fpr=0.8942 | 8299.4 samples/s | 32.4 steps/s
[Step= 500] | Loss=7.18136 | acc=0.1169 | tpr=0.7330 | fpr=0.8943 | 8202.6 samples/s | 32.0 steps/s
[Step= 550] | Loss=7.17680 | acc=0.1173 | tpr=0.7314 | fpr=0.8939 | 14156.5 samples/s | 55.3 steps/s
Avg test loss: 7.17751, Avg test acc: 0.11724, Avg tpr: 0.73138, Avg fpr: 0.89392, total FA: 124119

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12670 | acc=0.9795 | tpr=0.9381 | fpr=0.0197 | 5404.4 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.13171 | acc=0.9788 | tpr=0.9531 | fpr=0.0207 | 7351.1 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.13644 | acc=0.9779 | tpr=0.9524 | fpr=0.0216 | 7229.5 samples/s | 28.2 steps/s
[Step= 200] | Loss=0.13899 | acc=0.9779 | tpr=0.9497 | fpr=0.0216 | 8180.6 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.13688 | acc=0.9782 | tpr=0.9476 | fpr=0.0212 | 8307.1 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.13903 | acc=0.9778 | tpr=0.9447 | fpr=0.0216 | 7803.5 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.13991 | acc=0.9776 | tpr=0.9468 | fpr=0.0219 | 8176.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.14161 | acc=0.9774 | tpr=0.9442 | fpr=0.0220 | 8082.0 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14480 | acc=0.9771 | tpr=0.9435 | fpr=0.0223 | 8343.5 samples/s | 32.6 steps/s
[Step= 500] | Loss=0.14392 | acc=0.9772 | tpr=0.9432 | fpr=0.0222 | 7859.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.14338 | acc=0.9773 | tpr=0.9415 | fpr=0.0221 | 14800.0 samples/s | 57.8 steps/s
Avg test loss: 0.14302, Avg test acc: 0.97724, Avg tpr: 0.94017, Avg fpr: 0.02208, total FA: 3066

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14582 | acc=0.9786 | tpr=0.9602 | fpr=0.0211 | 5414.5 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.15108 | acc=0.9779 | tpr=0.9638 | fpr=0.0219 | 7141.7 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.15691 | acc=0.9767 | tpr=0.9654 | fpr=0.0231 | 7649.2 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.16043 | acc=0.9767 | tpr=0.9661 | fpr=0.0231 | 8151.3 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.15769 | acc=0.9772 | tpr=0.9677 | fpr=0.0227 | 7930.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.16047 | acc=0.9767 | tpr=0.9629 | fpr=0.0230 | 8096.8 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.16151 | acc=0.9765 | tpr=0.9631 | fpr=0.0233 | 8206.8 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.16276 | acc=0.9763 | tpr=0.9606 | fpr=0.0234 | 7918.0 samples/s | 30.9 steps/s
[Step= 450] | Loss=0.16608 | acc=0.9759 | tpr=0.9596 | fpr=0.0238 | 8122.7 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.16530 | acc=0.9759 | tpr=0.9604 | fpr=0.0238 | 8433.3 samples/s | 32.9 steps/s
[Step= 550] | Loss=0.16404 | acc=0.9760 | tpr=0.9586 | fpr=0.0237 | 13667.5 samples/s | 53.4 steps/s
Avg test loss: 0.16361, Avg test acc: 0.97602, Avg tpr: 0.95800, Avg fpr: 0.02365, total FA: 3284

server round 24/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=93.6] | Loss=0.00758 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.736 | L2-Norm(final)=8.382 | 6794.4 samples/s | 106.2 steps/s
[Step=48050 Epoch=93.7] | Loss=0.00630 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.736 | L2-Norm(final)=8.389 | 4525.4 samples/s | 70.7 steps/s
[Step=48100 Epoch=93.8] | Loss=0.00576 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.736 | L2-Norm(final)=8.397 | 5037.5 samples/s | 78.7 steps/s
[Step=48150 Epoch=93.9] | Loss=0.00580 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.737 | L2-Norm(final)=8.405 | 5293.5 samples/s | 82.7 steps/s
[Step=48200 Epoch=94.0] | Loss=0.00580 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.737 | L2-Norm(final)=8.412 | 5096.1 samples/s | 79.6 steps/s
[Step=48250 Epoch=94.1] | Loss=0.00591 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.737 | L2-Norm(final)=8.419 | 5281.3 samples/s | 82.5 steps/s
[Step=48300 Epoch=94.2] | Loss=0.00598 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.737 | L2-Norm(final)=8.426 | 5173.3 samples/s | 80.8 steps/s
[Step=48350 Epoch=94.3] | Loss=0.00609 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.738 | L2-Norm(final)=8.433 | 5155.4 samples/s | 80.6 steps/s
[Step=48400 Epoch=94.4] | Loss=0.00598 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.738 | L2-Norm(final)=8.440 | 5244.9 samples/s | 82.0 steps/s
[Step=48450 Epoch=94.5] | Loss=0.00604 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.738 | L2-Norm(final)=8.447 | 5158.7 samples/s | 80.6 steps/s
[Step=48500 Epoch=94.6] | Loss=0.00587 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.739 | L2-Norm(final)=8.454 | 7007.9 samples/s | 109.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=94.6] | Loss=0.00063 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.745 | L2-Norm(final)=8.522 | 6490.4 samples/s | 101.4 steps/s
[Step=48550 Epoch=94.7] | Loss=0.00713 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=8.528 | 4121.9 samples/s | 64.4 steps/s
[Step=48600 Epoch=94.8] | Loss=0.00718 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=8.532 | 4634.5 samples/s | 72.4 steps/s
[Step=48650 Epoch=94.9] | Loss=0.00876 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.753 | L2-Norm(final)=8.535 | 4579.0 samples/s | 71.5 steps/s
[Step=48700 Epoch=95.0] | Loss=0.00935 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.759 | L2-Norm(final)=8.537 | 4597.7 samples/s | 71.8 steps/s
[Step=48750 Epoch=95.1] | Loss=0.00890 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.764 | L2-Norm(final)=8.541 | 4715.7 samples/s | 73.7 steps/s
[Step=48800 Epoch=95.2] | Loss=0.00872 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.769 | L2-Norm(final)=8.546 | 4666.2 samples/s | 72.9 steps/s
[Step=48850 Epoch=95.3] | Loss=0.00863 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.774 | L2-Norm(final)=8.551 | 4512.1 samples/s | 70.5 steps/s
[Step=48900 Epoch=95.4] | Loss=0.00888 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.779 | L2-Norm(final)=8.555 | 4634.8 samples/s | 72.4 steps/s
[Step=48950 Epoch=95.5] | Loss=0.00883 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.783 | L2-Norm(final)=8.559 | 4630.1 samples/s | 72.3 steps/s
[Step=49000 Epoch=95.6] | Loss=0.00894 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.787 | L2-Norm(final)=8.563 | 5980.2 samples/s | 93.4 steps/s
[Step=49050 Epoch=95.7] | Loss=0.00885 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.791 | L2-Norm(final)=8.566 | 2440.0 samples/s | 38.1 steps/s
[Step=49100 Epoch=95.8] | Loss=0.00878 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=8.570 | 4612.2 samples/s | 72.1 steps/s
[Step=49150 Epoch=95.9] | Loss=0.00857 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.798 | L2-Norm(final)=8.574 | 4606.0 samples/s | 72.0 steps/s
[Step=49200 Epoch=96.0] | Loss=0.00849 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.801 | L2-Norm(final)=8.578 | 4700.6 samples/s | 73.4 steps/s
[Step=49250 Epoch=96.1] | Loss=0.00832 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=8.581 | 4611.4 samples/s | 72.1 steps/s
[Step=49300 Epoch=96.2] | Loss=0.00819 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=8.585 | 4585.3 samples/s | 71.6 steps/s
[Step=49350 Epoch=96.3] | Loss=0.00809 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.807 | L2-Norm(final)=8.589 | 4638.1 samples/s | 72.5 steps/s
[Step=49400 Epoch=96.3] | Loss=0.00808 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.809 | L2-Norm(final)=8.592 | 4653.5 samples/s | 72.7 steps/s
[Step=49450 Epoch=96.4] | Loss=0.00804 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.810 | L2-Norm(final)=8.595 | 4595.8 samples/s | 71.8 steps/s
[Step=49500 Epoch=96.5] | Loss=0.00804 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.812 | L2-Norm(final)=8.599 | 5002.3 samples/s | 78.2 steps/s
[Step=49550 Epoch=96.6] | Loss=0.00809 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=8.602 | 2663.3 samples/s | 41.6 steps/s
[Step=49600 Epoch=96.7] | Loss=0.00790 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.814 | L2-Norm(final)=8.605 | 4638.4 samples/s | 72.5 steps/s
[Step=49650 Epoch=96.8] | Loss=0.00777 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.815 | L2-Norm(final)=8.609 | 4612.6 samples/s | 72.1 steps/s
[Step=49700 Epoch=96.9] | Loss=0.00775 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.815 | L2-Norm(final)=8.612 | 4670.3 samples/s | 73.0 steps/s
[Step=49750 Epoch=97.0] | Loss=0.00771 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.816 | L2-Norm(final)=8.615 | 4568.4 samples/s | 71.4 steps/s
[Step=49800 Epoch=97.1] | Loss=0.00761 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.816 | L2-Norm(final)=8.618 | 4615.9 samples/s | 72.1 steps/s
[Step=49850 Epoch=97.2] | Loss=0.00756 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.817 | L2-Norm(final)=8.621 | 4679.4 samples/s | 73.1 steps/s
[Step=49900 Epoch=97.3] | Loss=0.00756 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.817 | L2-Norm(final)=8.624 | 4689.2 samples/s | 73.3 steps/s
[Step=49950 Epoch=97.4] | Loss=0.00748 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.817 | L2-Norm(final)=8.626 | 4598.9 samples/s | 71.9 steps/s
[Step=50000 Epoch=97.5] | Loss=0.00741 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.817 | L2-Norm(final)=8.629 | 4622.0 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step50000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=93.8] | Loss=0.00409 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.182 | L2-Norm(final)=8.838 | 6294.1 samples/s | 98.3 steps/s
[Step=48050 Epoch=93.9] | Loss=0.00525 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.182 | L2-Norm(final)=8.847 | 4669.0 samples/s | 73.0 steps/s
[Step=48100 Epoch=94.0] | Loss=0.00636 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.183 | L2-Norm(final)=8.857 | 5253.0 samples/s | 82.1 steps/s
[Step=48150 Epoch=94.1] | Loss=0.00621 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.185 | L2-Norm(final)=8.865 | 5126.1 samples/s | 80.1 steps/s
[Step=48200 Epoch=94.2] | Loss=0.00643 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.187 | L2-Norm(final)=8.873 | 5262.0 samples/s | 82.2 steps/s
[Step=48250 Epoch=94.3] | Loss=0.00642 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.189 | L2-Norm(final)=8.882 | 5178.7 samples/s | 80.9 steps/s
[Step=48300 Epoch=94.4] | Loss=0.00624 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.190 | L2-Norm(final)=8.890 | 5144.1 samples/s | 80.4 steps/s
[Step=48350 Epoch=94.5] | Loss=0.00619 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.191 | L2-Norm(final)=8.898 | 5237.7 samples/s | 81.8 steps/s
[Step=48400 Epoch=94.6] | Loss=0.00631 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.192 | L2-Norm(final)=8.906 | 5194.0 samples/s | 81.2 steps/s
[Step=48450 Epoch=94.7] | Loss=0.00637 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.194 | L2-Norm(final)=8.914 | 5307.5 samples/s | 82.9 steps/s
[Step=48500 Epoch=94.8] | Loss=0.00629 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.195 | L2-Norm(final)=8.922 | 6989.2 samples/s | 109.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=94.8] | Loss=0.00218 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=9.001 | 6183.6 samples/s | 96.6 steps/s
[Step=48550 Epoch=94.9] | Loss=0.00475 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.210 | L2-Norm(final)=9.009 | 4219.8 samples/s | 65.9 steps/s
[Step=48600 Epoch=95.0] | Loss=0.00682 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.213 | L2-Norm(final)=9.014 | 4621.6 samples/s | 72.2 steps/s
[Step=48650 Epoch=95.1] | Loss=0.00689 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.217 | L2-Norm(final)=9.019 | 4635.1 samples/s | 72.4 steps/s
[Step=48700 Epoch=95.2] | Loss=0.00716 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.222 | L2-Norm(final)=9.024 | 4619.9 samples/s | 72.2 steps/s
[Step=48750 Epoch=95.3] | Loss=0.00730 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.226 | L2-Norm(final)=9.028 | 4580.5 samples/s | 71.6 steps/s
[Step=48800 Epoch=95.4] | Loss=0.00810 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.230 | L2-Norm(final)=9.032 | 4656.2 samples/s | 72.8 steps/s
[Step=48850 Epoch=95.5] | Loss=0.00780 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.234 | L2-Norm(final)=9.036 | 4560.0 samples/s | 71.2 steps/s
[Step=48900 Epoch=95.6] | Loss=0.00800 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.238 | L2-Norm(final)=9.040 | 4680.3 samples/s | 73.1 steps/s
[Step=48950 Epoch=95.7] | Loss=0.00798 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.241 | L2-Norm(final)=9.043 | 4597.9 samples/s | 71.8 steps/s
[Step=49000 Epoch=95.8] | Loss=0.00813 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.243 | L2-Norm(final)=9.046 | 6055.1 samples/s | 94.6 steps/s
[Step=49050 Epoch=95.9] | Loss=0.00811 | Reg=0.00297 | acc=0.9844 | L2-Norm=17.246 | L2-Norm(final)=9.049 | 2428.4 samples/s | 37.9 steps/s
[Step=49100 Epoch=96.0] | Loss=0.00789 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.248 | L2-Norm(final)=9.053 | 4611.3 samples/s | 72.1 steps/s
[Step=49150 Epoch=96.1] | Loss=0.00773 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.249 | L2-Norm(final)=9.057 | 4604.2 samples/s | 71.9 steps/s
[Step=49200 Epoch=96.2] | Loss=0.00757 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.250 | L2-Norm(final)=9.060 | 4621.5 samples/s | 72.2 steps/s
[Step=49250 Epoch=96.3] | Loss=0.00760 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.252 | L2-Norm(final)=9.064 | 4622.0 samples/s | 72.2 steps/s
[Step=49300 Epoch=96.4] | Loss=0.00749 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.253 | L2-Norm(final)=9.067 | 4644.0 samples/s | 72.6 steps/s
[Step=49350 Epoch=96.5] | Loss=0.00734 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.253 | L2-Norm(final)=9.070 | 4613.8 samples/s | 72.1 steps/s
[Step=49400 Epoch=96.6] | Loss=0.00741 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=9.074 | 4679.0 samples/s | 73.1 steps/s
[Step=49450 Epoch=96.7] | Loss=0.00741 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=9.077 | 4590.7 samples/s | 71.7 steps/s
[Step=49500 Epoch=96.8] | Loss=0.00736 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=9.080 | 5140.6 samples/s | 80.3 steps/s
[Step=49550 Epoch=96.9] | Loss=0.00736 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=9.083 | 2624.9 samples/s | 41.0 steps/s
[Step=49600 Epoch=97.0] | Loss=0.00729 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=9.086 | 4624.9 samples/s | 72.3 steps/s
[Step=49650 Epoch=97.1] | Loss=0.00724 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.255 | L2-Norm(final)=9.088 | 4614.8 samples/s | 72.1 steps/s
[Step=49700 Epoch=97.2] | Loss=0.00716 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=9.091 | 4633.4 samples/s | 72.4 steps/s
[Step=49750 Epoch=97.3] | Loss=0.00712 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=9.094 | 4653.7 samples/s | 72.7 steps/s
[Step=49800 Epoch=97.4] | Loss=0.00707 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.254 | L2-Norm(final)=9.096 | 4590.2 samples/s | 71.7 steps/s
[Step=49850 Epoch=97.5] | Loss=0.00709 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.253 | L2-Norm(final)=9.099 | 4635.6 samples/s | 72.4 steps/s
[Step=49900 Epoch=97.6] | Loss=0.00709 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.253 | L2-Norm(final)=9.101 | 4672.4 samples/s | 73.0 steps/s
[Step=49950 Epoch=97.7] | Loss=0.00704 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.252 | L2-Norm(final)=9.104 | 4681.1 samples/s | 73.1 steps/s
[Step=50000 Epoch=97.7] | Loss=0.00711 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.252 | L2-Norm(final)=9.106 | 4532.8 samples/s | 70.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step50000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=183.9] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.291 | L2-Norm(final)=6.606 | 6021.8 samples/s | 94.1 steps/s
[Step=48050 Epoch=184.1] | Loss=0.00005 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.298 | L2-Norm(final)=6.609 | 4436.3 samples/s | 69.3 steps/s
[Step=48100 Epoch=184.3] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.300 | L2-Norm(final)=6.611 | 4930.5 samples/s | 77.0 steps/s
[Step=48150 Epoch=184.5] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.299 | L2-Norm(final)=6.612 | 4907.9 samples/s | 76.7 steps/s
[Step=48200 Epoch=184.7] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.299 | L2-Norm(final)=6.614 | 5010.8 samples/s | 78.3 steps/s
[Step=48250 Epoch=184.9] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.298 | L2-Norm(final)=6.615 | 6683.9 samples/s | 104.4 steps/s
[Step=48300 Epoch=185.1] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=6.617 | 2464.6 samples/s | 38.5 steps/s
[Step=48350 Epoch=185.3] | Loss=0.00003 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.297 | L2-Norm(final)=6.619 | 4876.5 samples/s | 76.2 steps/s
[Step=48400 Epoch=185.5] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.296 | L2-Norm(final)=6.621 | 4924.9 samples/s | 77.0 steps/s
[Step=48450 Epoch=185.6] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.296 | L2-Norm(final)=6.623 | 5051.0 samples/s | 78.9 steps/s
[Step=48500 Epoch=185.8] | Loss=0.00002 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.295 | L2-Norm(final)=6.625 | 5527.9 samples/s | 86.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=185.8] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.288 | L2-Norm(final)=6.642 | 6274.5 samples/s | 98.0 steps/s
[Step=48550 Epoch=186.0] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.285 | L2-Norm(final)=6.644 | 3913.6 samples/s | 61.1 steps/s
[Step=48600 Epoch=186.2] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.282 | L2-Norm(final)=6.645 | 4449.8 samples/s | 69.5 steps/s
[Step=48650 Epoch=186.4] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.279 | L2-Norm(final)=6.647 | 4327.9 samples/s | 67.6 steps/s
[Step=48700 Epoch=186.6] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.276 | L2-Norm(final)=6.648 | 4438.1 samples/s | 69.3 steps/s
[Step=48750 Epoch=186.8] | Loss=0.00001 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.272 | L2-Norm(final)=6.650 | 5810.7 samples/s | 90.8 steps/s
[Step=48800 Epoch=187.0] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.269 | L2-Norm(final)=6.651 | 2327.6 samples/s | 36.4 steps/s
[Step=48850 Epoch=187.2] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.265 | L2-Norm(final)=6.653 | 4353.4 samples/s | 68.0 steps/s
[Step=48900 Epoch=187.4] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=6.654 | 4516.0 samples/s | 70.6 steps/s
[Step=48950 Epoch=187.6] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.258 | L2-Norm(final)=6.655 | 4246.2 samples/s | 66.3 steps/s
[Step=49000 Epoch=187.8] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=6.656 | 4980.3 samples/s | 77.8 steps/s
[Step=49050 Epoch=187.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=6.657 | 2509.6 samples/s | 39.2 steps/s
[Step=49100 Epoch=188.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=6.658 | 4352.4 samples/s | 68.0 steps/s
[Step=49150 Epoch=188.3] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.242 | L2-Norm(final)=6.660 | 4442.2 samples/s | 69.4 steps/s
[Step=49200 Epoch=188.5] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=6.661 | 4354.5 samples/s | 68.0 steps/s
[Step=49250 Epoch=188.7] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.234 | L2-Norm(final)=6.662 | 4360.1 samples/s | 68.1 steps/s
[Step=49300 Epoch=188.9] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.230 | L2-Norm(final)=6.663 | 2658.2 samples/s | 41.5 steps/s
[Step=49350 Epoch=189.1] | Loss=0.00001 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.225 | L2-Norm(final)=6.664 | 4404.8 samples/s | 68.8 steps/s
[Step=49400 Epoch=189.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.221 | L2-Norm(final)=6.665 | 4397.4 samples/s | 68.7 steps/s
[Step=49450 Epoch=189.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.217 | L2-Norm(final)=6.666 | 4450.6 samples/s | 69.5 steps/s
[Step=49500 Epoch=189.7] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.212 | L2-Norm(final)=6.667 | 4344.1 samples/s | 67.9 steps/s
[Step=49550 Epoch=189.9] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.668 | 2685.8 samples/s | 42.0 steps/s
[Step=49600 Epoch=190.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.203 | L2-Norm(final)=6.669 | 4418.6 samples/s | 69.0 steps/s
[Step=49650 Epoch=190.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=6.670 | 4384.6 samples/s | 68.5 steps/s
[Step=49700 Epoch=190.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.194 | L2-Norm(final)=6.671 | 4453.8 samples/s | 69.6 steps/s
[Step=49750 Epoch=190.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.189 | L2-Norm(final)=6.672 | 4335.3 samples/s | 67.7 steps/s
[Step=49800 Epoch=190.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.185 | L2-Norm(final)=6.673 | 6476.8 samples/s | 101.2 steps/s
[Step=49850 Epoch=191.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.180 | L2-Norm(final)=6.674 | 2244.2 samples/s | 35.1 steps/s
[Step=49900 Epoch=191.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.175 | L2-Norm(final)=6.675 | 4364.1 samples/s | 68.2 steps/s
[Step=49950 Epoch=191.4] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.170 | L2-Norm(final)=6.676 | 4427.6 samples/s | 69.2 steps/s
[Step=50000 Epoch=191.6] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=6.678 | 4329.5 samples/s | 67.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step50000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=184.8] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.103 | L2-Norm(final)=6.910 | 6773.6 samples/s | 105.8 steps/s
[Step=48050 Epoch=185.0] | Loss=0.00004 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.097 | L2-Norm(final)=6.922 | 4432.7 samples/s | 69.3 steps/s
[Step=48100 Epoch=185.2] | Loss=0.00003 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.100 | L2-Norm(final)=6.932 | 4614.0 samples/s | 72.1 steps/s
[Step=48150 Epoch=185.3] | Loss=0.00003 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=6.942 | 4901.1 samples/s | 76.6 steps/s
[Step=48200 Epoch=185.5] | Loss=0.00003 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.103 | L2-Norm(final)=6.952 | 4859.5 samples/s | 75.9 steps/s
[Step=48250 Epoch=185.7] | Loss=0.00003 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=6.962 | 7020.8 samples/s | 109.7 steps/s
[Step=48300 Epoch=185.9] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.107 | L2-Norm(final)=6.972 | 2441.5 samples/s | 38.1 steps/s
[Step=48350 Epoch=186.1] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=6.980 | 4944.9 samples/s | 77.3 steps/s
[Step=48400 Epoch=186.3] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=6.988 | 4867.8 samples/s | 76.1 steps/s
[Step=48450 Epoch=186.5] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=6.996 | 4960.4 samples/s | 77.5 steps/s
[Step=48500 Epoch=186.7] | Loss=0.00002 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=7.004 | 5770.6 samples/s | 90.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=186.7] | Loss=0.00009 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=7.085 | 6185.7 samples/s | 96.7 steps/s
[Step=48550 Epoch=186.9] | Loss=0.00006 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.080 | L2-Norm(final)=7.096 | 4004.3 samples/s | 62.6 steps/s
[Step=48600 Epoch=187.1] | Loss=0.00216 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=7.094 | 4316.8 samples/s | 67.4 steps/s
[Step=48650 Epoch=187.3] | Loss=0.00301 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.162 | L2-Norm(final)=7.084 | 4414.2 samples/s | 69.0 steps/s
[Step=48700 Epoch=187.5] | Loss=0.00230 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=7.077 | 4326.8 samples/s | 67.6 steps/s
[Step=48750 Epoch=187.7] | Loss=0.00201 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=7.074 | 5971.0 samples/s | 93.3 steps/s
[Step=48800 Epoch=187.9] | Loss=0.00168 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.223 | L2-Norm(final)=7.072 | 2309.0 samples/s | 36.1 steps/s
[Step=48850 Epoch=188.0] | Loss=0.00146 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.232 | L2-Norm(final)=7.071 | 4376.0 samples/s | 68.4 steps/s
[Step=48900 Epoch=188.2] | Loss=0.00128 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=7.070 | 4378.4 samples/s | 68.4 steps/s
[Step=48950 Epoch=188.4] | Loss=0.00114 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.243 | L2-Norm(final)=7.070 | 4356.5 samples/s | 68.1 steps/s
[Step=49000 Epoch=188.6] | Loss=0.00103 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=7.071 | 5141.9 samples/s | 80.3 steps/s
[Step=49050 Epoch=188.8] | Loss=0.00095 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.248 | L2-Norm(final)=7.071 | 2461.6 samples/s | 38.5 steps/s
[Step=49100 Epoch=189.0] | Loss=0.00087 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=7.072 | 4396.9 samples/s | 68.7 steps/s
[Step=49150 Epoch=189.2] | Loss=0.00080 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.251 | L2-Norm(final)=7.073 | 4431.6 samples/s | 69.2 steps/s
[Step=49200 Epoch=189.4] | Loss=0.00074 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=7.073 | 4454.7 samples/s | 69.6 steps/s
[Step=49250 Epoch=189.6] | Loss=0.00070 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.253 | L2-Norm(final)=7.074 | 4410.1 samples/s | 68.9 steps/s
[Step=49300 Epoch=189.8] | Loss=0.00065 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.253 | L2-Norm(final)=7.075 | 2644.8 samples/s | 41.3 steps/s
[Step=49350 Epoch=190.0] | Loss=0.00061 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.253 | L2-Norm(final)=7.075 | 4351.2 samples/s | 68.0 steps/s
[Step=49400 Epoch=190.2] | Loss=0.00058 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.252 | L2-Norm(final)=7.076 | 4385.3 samples/s | 68.5 steps/s
[Step=49450 Epoch=190.4] | Loss=0.00055 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.251 | L2-Norm(final)=7.076 | 4383.6 samples/s | 68.5 steps/s
[Step=49500 Epoch=190.5] | Loss=0.00052 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.251 | L2-Norm(final)=7.077 | 4376.8 samples/s | 68.4 steps/s
[Step=49550 Epoch=190.7] | Loss=0.00050 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=7.077 | 2705.3 samples/s | 42.3 steps/s
[Step=49600 Epoch=190.9] | Loss=0.00048 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.248 | L2-Norm(final)=7.078 | 4365.8 samples/s | 68.2 steps/s
[Step=49650 Epoch=191.1] | Loss=0.00045 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.247 | L2-Norm(final)=7.078 | 4425.0 samples/s | 69.1 steps/s
[Step=49700 Epoch=191.3] | Loss=0.00044 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=7.079 | 4336.5 samples/s | 67.8 steps/s
[Step=49750 Epoch=191.5] | Loss=0.00042 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.244 | L2-Norm(final)=7.079 | 4464.2 samples/s | 69.8 steps/s
[Step=49800 Epoch=191.7] | Loss=0.00040 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.243 | L2-Norm(final)=7.080 | 6940.4 samples/s | 108.4 steps/s
[Step=49850 Epoch=191.9] | Loss=0.00039 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=7.080 | 2185.7 samples/s | 34.2 steps/s
[Step=49900 Epoch=192.1] | Loss=0.00037 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.239 | L2-Norm(final)=7.080 | 4333.9 samples/s | 67.7 steps/s
[Step=49950 Epoch=192.3] | Loss=0.00036 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=7.081 | 4482.8 samples/s | 70.0 steps/s
[Step=50000 Epoch=192.5] | Loss=0.00035 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=7.081 | 4318.9 samples/s | 67.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08355 | acc=0.9674 | tpr=0.9720 | fpr=0.0426 | 5409.9 samples/s | 21.1 steps/s
Avg test loss: 0.08392, Avg test acc: 0.96650, Avg tpr: 0.97179, Avg fpr: 0.04512, total FA: 352

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07718 | acc=0.9693 | tpr=0.9768 | fpr=0.0471 | 5373.4 samples/s | 21.0 steps/s
Avg test loss: 0.07807, Avg test acc: 0.96899, Avg tpr: 0.97704, Avg fpr: 0.04871, total FA: 380

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.45163 | acc=0.3100 | tpr=0.0095 | fpr=0.0374 | 5395.2 samples/s | 21.1 steps/s
Avg test loss: 5.46404, Avg test acc: 0.30828, Avg tpr: 0.00921, Avg fpr: 0.03397, total FA: 265

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.60943 | acc=0.3119 | tpr=0.0039 | fpr=0.0193 | 5373.0 samples/s | 21.0 steps/s
Avg test loss: 5.62468, Avg test acc: 0.30952, Avg tpr: 0.00385, Avg fpr: 0.01820, total FA: 142

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.62256 | acc=0.1230 | tpr=0.6726 | fpr=0.8868 | 5293.5 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.59209 | acc=0.1228 | tpr=0.6439 | fpr=0.8869 | 7100.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.58847 | acc=0.1230 | tpr=0.6484 | fpr=0.8867 | 8020.6 samples/s | 31.3 steps/s
[Step= 200] | Loss=6.60024 | acc=0.1225 | tpr=0.6492 | fpr=0.8871 | 8107.0 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.60548 | acc=0.1230 | tpr=0.6515 | fpr=0.8866 | 7864.8 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.60322 | acc=0.1226 | tpr=0.6545 | fpr=0.8871 | 8329.2 samples/s | 32.5 steps/s
[Step= 350] | Loss=6.59210 | acc=0.1228 | tpr=0.6544 | fpr=0.8868 | 8023.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=6.58468 | acc=0.1234 | tpr=0.6581 | fpr=0.8863 | 8210.8 samples/s | 32.1 steps/s
[Step= 450] | Loss=6.58423 | acc=0.1230 | tpr=0.6587 | fpr=0.8867 | 8370.0 samples/s | 32.7 steps/s
[Step= 500] | Loss=6.58511 | acc=0.1228 | tpr=0.6573 | fpr=0.8868 | 7848.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.58577 | acc=0.1231 | tpr=0.6542 | fpr=0.8866 | 14522.1 samples/s | 56.7 steps/s
Avg test loss: 6.58690, Avg test acc: 0.12300, Avg tpr: 0.65333, Avg fpr: 0.88664, total FA: 123108

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.60120 | acc=0.1162 | tpr=0.7212 | fpr=0.8947 | 5158.5 samples/s | 20.2 steps/s
[Step= 100] | Loss=6.58554 | acc=0.1150 | tpr=0.7122 | fpr=0.8961 | 7270.8 samples/s | 28.4 steps/s
[Step= 150] | Loss=6.58018 | acc=0.1155 | tpr=0.7161 | fpr=0.8955 | 8097.1 samples/s | 31.6 steps/s
[Step= 200] | Loss=6.59394 | acc=0.1146 | tpr=0.7104 | fpr=0.8963 | 8383.5 samples/s | 32.7 steps/s
[Step= 250] | Loss=6.59798 | acc=0.1151 | tpr=0.7039 | fpr=0.8956 | 7951.3 samples/s | 31.1 steps/s
[Step= 300] | Loss=6.60271 | acc=0.1148 | tpr=0.7025 | fpr=0.8959 | 8168.9 samples/s | 31.9 steps/s
[Step= 350] | Loss=6.59047 | acc=0.1152 | tpr=0.6994 | fpr=0.8954 | 8392.4 samples/s | 32.8 steps/s
[Step= 400] | Loss=6.58299 | acc=0.1158 | tpr=0.6997 | fpr=0.8948 | 7833.9 samples/s | 30.6 steps/s
[Step= 450] | Loss=6.57957 | acc=0.1151 | tpr=0.6991 | fpr=0.8955 | 8348.1 samples/s | 32.6 steps/s
[Step= 500] | Loss=6.58336 | acc=0.1149 | tpr=0.6991 | fpr=0.8956 | 8175.7 samples/s | 31.9 steps/s
[Step= 550] | Loss=6.57954 | acc=0.1153 | tpr=0.6948 | fpr=0.8952 | 14256.5 samples/s | 55.7 steps/s
Avg test loss: 6.57998, Avg test acc: 0.11528, Avg tpr: 0.69453, Avg fpr: 0.89525, total FA: 124303

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13548 | acc=0.9781 | tpr=0.9381 | fpr=0.0212 | 5338.0 samples/s | 20.9 steps/s
[Step= 100] | Loss=0.14104 | acc=0.9777 | tpr=0.9510 | fpr=0.0218 | 7777.0 samples/s | 30.4 steps/s
[Step= 150] | Loss=0.14598 | acc=0.9767 | tpr=0.9510 | fpr=0.0228 | 7289.0 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.14859 | acc=0.9768 | tpr=0.9519 | fpr=0.0228 | 8249.3 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.14649 | acc=0.9771 | tpr=0.9511 | fpr=0.0224 | 8115.3 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.14896 | acc=0.9767 | tpr=0.9498 | fpr=0.0228 | 8149.1 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.14967 | acc=0.9764 | tpr=0.9518 | fpr=0.0231 | 8023.3 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.15141 | acc=0.9762 | tpr=0.9491 | fpr=0.0233 | 8598.3 samples/s | 33.6 steps/s
[Step= 450] | Loss=0.15474 | acc=0.9759 | tpr=0.9494 | fpr=0.0237 | 7852.8 samples/s | 30.7 steps/s
[Step= 500] | Loss=0.15389 | acc=0.9758 | tpr=0.9498 | fpr=0.0237 | 8005.2 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.15294 | acc=0.9760 | tpr=0.9487 | fpr=0.0235 | 14761.0 samples/s | 57.7 steps/s
Avg test loss: 0.15257, Avg test acc: 0.97605, Avg tpr: 0.94770, Avg fpr: 0.02344, total FA: 3254

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15210 | acc=0.9788 | tpr=0.9558 | fpr=0.0208 | 5192.6 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.15875 | acc=0.9781 | tpr=0.9510 | fpr=0.0214 | 6978.5 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.16493 | acc=0.9772 | tpr=0.9496 | fpr=0.0223 | 8510.3 samples/s | 33.2 steps/s
[Step= 200] | Loss=0.16790 | acc=0.9771 | tpr=0.9530 | fpr=0.0225 | 8363.5 samples/s | 32.7 steps/s
[Step= 250] | Loss=0.16471 | acc=0.9774 | tpr=0.9511 | fpr=0.0221 | 7648.3 samples/s | 29.9 steps/s
[Step= 300] | Loss=0.16779 | acc=0.9769 | tpr=0.9484 | fpr=0.0226 | 8486.8 samples/s | 33.2 steps/s
[Step= 350] | Loss=0.16885 | acc=0.9767 | tpr=0.9493 | fpr=0.0229 | 8261.2 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.17056 | acc=0.9764 | tpr=0.9453 | fpr=0.0230 | 8235.9 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.17386 | acc=0.9761 | tpr=0.9445 | fpr=0.0234 | 8098.3 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.17285 | acc=0.9761 | tpr=0.9454 | fpr=0.0234 | 7859.2 samples/s | 30.7 steps/s
[Step= 550] | Loss=0.17161 | acc=0.9763 | tpr=0.9459 | fpr=0.0232 | 15051.4 samples/s | 58.8 steps/s
Avg test loss: 0.17120, Avg test acc: 0.97631, Avg tpr: 0.94532, Avg fpr: 0.02313, total FA: 3211

server round 25/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=97.5] | Loss=0.01259 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.687 | L2-Norm(final)=8.711 | 6296.1 samples/s | 98.4 steps/s
[Step=50050 Epoch=97.6] | Loss=0.00625 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.688 | L2-Norm(final)=8.717 | 4809.0 samples/s | 75.1 steps/s
[Step=50100 Epoch=97.7] | Loss=0.00612 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.689 | L2-Norm(final)=8.723 | 5056.2 samples/s | 79.0 steps/s
[Step=50150 Epoch=97.8] | Loss=0.00645 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.690 | L2-Norm(final)=8.730 | 5188.2 samples/s | 81.1 steps/s
[Step=50200 Epoch=97.9] | Loss=0.00642 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.690 | L2-Norm(final)=8.737 | 5159.0 samples/s | 80.6 steps/s
[Step=50250 Epoch=98.0] | Loss=0.00626 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.691 | L2-Norm(final)=8.744 | 5175.4 samples/s | 80.9 steps/s
[Step=50300 Epoch=98.1] | Loss=0.00621 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.691 | L2-Norm(final)=8.751 | 5249.5 samples/s | 82.0 steps/s
[Step=50350 Epoch=98.2] | Loss=0.00592 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.692 | L2-Norm(final)=8.758 | 5338.0 samples/s | 83.4 steps/s
[Step=50400 Epoch=98.3] | Loss=0.00587 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.692 | L2-Norm(final)=8.765 | 5221.0 samples/s | 81.6 steps/s
[Step=50450 Epoch=98.4] | Loss=0.00578 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.693 | L2-Norm(final)=8.772 | 5097.2 samples/s | 79.6 steps/s
[Step=50500 Epoch=98.5] | Loss=0.00569 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.693 | L2-Norm(final)=8.779 | 6920.8 samples/s | 108.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=98.5] | Loss=0.00844 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.696 | L2-Norm(final)=8.850 | 6629.1 samples/s | 103.6 steps/s
[Step=50550 Epoch=98.6] | Loss=0.00391 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.697 | L2-Norm(final)=8.857 | 4065.2 samples/s | 63.5 steps/s
[Step=50600 Epoch=98.7] | Loss=0.00610 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.700 | L2-Norm(final)=8.860 | 4608.0 samples/s | 72.0 steps/s
[Step=50650 Epoch=98.8] | Loss=0.00732 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.703 | L2-Norm(final)=8.863 | 4681.5 samples/s | 73.1 steps/s
[Step=50700 Epoch=98.9] | Loss=0.00812 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.707 | L2-Norm(final)=8.866 | 4547.7 samples/s | 71.1 steps/s
[Step=50750 Epoch=99.0] | Loss=0.00813 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.711 | L2-Norm(final)=8.869 | 4671.8 samples/s | 73.0 steps/s
[Step=50800 Epoch=99.1] | Loss=0.00791 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.715 | L2-Norm(final)=8.872 | 4631.6 samples/s | 72.4 steps/s
[Step=50850 Epoch=99.2] | Loss=0.00823 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.719 | L2-Norm(final)=8.876 | 4625.5 samples/s | 72.3 steps/s
[Step=50900 Epoch=99.3] | Loss=0.00846 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.722 | L2-Norm(final)=8.880 | 4558.8 samples/s | 71.2 steps/s
[Step=50950 Epoch=99.4] | Loss=0.00856 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.725 | L2-Norm(final)=8.884 | 4717.0 samples/s | 73.7 steps/s
[Step=51000 Epoch=99.5] | Loss=0.00856 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.728 | L2-Norm(final)=8.887 | 5822.1 samples/s | 91.0 steps/s
[Step=51050 Epoch=99.6] | Loss=0.00860 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.731 | L2-Norm(final)=8.891 | 2458.8 samples/s | 38.4 steps/s
[Step=51100 Epoch=99.7] | Loss=0.00837 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.734 | L2-Norm(final)=8.895 | 4599.7 samples/s | 71.9 steps/s
[Step=51150 Epoch=99.8] | Loss=0.00826 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.736 | L2-Norm(final)=8.898 | 4601.7 samples/s | 71.9 steps/s
[Step=51200 Epoch=99.9] | Loss=0.00821 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.738 | L2-Norm(final)=8.902 | 4628.7 samples/s | 72.3 steps/s
[Step=51250 Epoch=100.0] | Loss=0.00812 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.740 | L2-Norm(final)=8.905 | 4662.7 samples/s | 72.9 steps/s
[Step=51300 Epoch=100.1] | Loss=0.00802 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.741 | L2-Norm(final)=8.908 | 4527.8 samples/s | 70.7 steps/s
[Step=51350 Epoch=100.2] | Loss=0.00801 | Reg=0.00280 | acc=0.9531 | L2-Norm=16.742 | L2-Norm(final)=8.911 | 4680.9 samples/s | 73.1 steps/s
[Step=51400 Epoch=100.2] | Loss=0.00805 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.744 | L2-Norm(final)=8.913 | 4589.1 samples/s | 71.7 steps/s
[Step=51450 Epoch=100.3] | Loss=0.00799 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.745 | L2-Norm(final)=8.916 | 4652.1 samples/s | 72.7 steps/s
[Step=51500 Epoch=100.4] | Loss=0.00806 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.746 | L2-Norm(final)=8.919 | 4969.8 samples/s | 77.7 steps/s
[Step=51550 Epoch=100.5] | Loss=0.00803 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.747 | L2-Norm(final)=8.921 | 2683.7 samples/s | 41.9 steps/s
[Step=51600 Epoch=100.6] | Loss=0.00791 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.748 | L2-Norm(final)=8.924 | 4557.2 samples/s | 71.2 steps/s
[Step=51650 Epoch=100.7] | Loss=0.00792 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=8.927 | 4632.9 samples/s | 72.4 steps/s
[Step=51700 Epoch=100.8] | Loss=0.00786 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.749 | L2-Norm(final)=8.929 | 4554.7 samples/s | 71.2 steps/s
[Step=51750 Epoch=100.9] | Loss=0.00778 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.750 | L2-Norm(final)=8.932 | 4672.1 samples/s | 73.0 steps/s
[Step=51800 Epoch=101.0] | Loss=0.00776 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=8.934 | 4575.6 samples/s | 71.5 steps/s
[Step=51850 Epoch=101.1] | Loss=0.00776 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.751 | L2-Norm(final)=8.936 | 4707.1 samples/s | 73.5 steps/s
[Step=51900 Epoch=101.2] | Loss=0.00772 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.752 | L2-Norm(final)=8.939 | 4630.7 samples/s | 72.4 steps/s
[Step=51950 Epoch=101.3] | Loss=0.00769 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.752 | L2-Norm(final)=8.941 | 4565.0 samples/s | 71.3 steps/s
[Step=52000 Epoch=101.4] | Loss=0.00763 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.752 | L2-Norm(final)=8.944 | 4629.2 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step52000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=97.8] | Loss=0.00068 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.119 | L2-Norm(final)=9.174 | 6137.1 samples/s | 95.9 steps/s
[Step=50050 Epoch=97.8] | Loss=0.00979 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.129 | L2-Norm(final)=9.177 | 4835.4 samples/s | 75.6 steps/s
[Step=50100 Epoch=97.9] | Loss=0.00865 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.135 | L2-Norm(final)=9.186 | 5237.4 samples/s | 81.8 steps/s
[Step=50150 Epoch=98.0] | Loss=0.00883 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.138 | L2-Norm(final)=9.195 | 5110.5 samples/s | 79.9 steps/s
[Step=50200 Epoch=98.1] | Loss=0.00842 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.142 | L2-Norm(final)=9.205 | 5180.1 samples/s | 80.9 steps/s
[Step=50250 Epoch=98.2] | Loss=0.00793 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.146 | L2-Norm(final)=9.214 | 5179.3 samples/s | 80.9 steps/s
[Step=50300 Epoch=98.3] | Loss=0.00775 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.149 | L2-Norm(final)=9.223 | 5221.6 samples/s | 81.6 steps/s
[Step=50350 Epoch=98.4] | Loss=0.00799 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.152 | L2-Norm(final)=9.232 | 5312.2 samples/s | 83.0 steps/s
[Step=50400 Epoch=98.5] | Loss=0.00806 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.154 | L2-Norm(final)=9.240 | 5090.8 samples/s | 79.5 steps/s
[Step=50450 Epoch=98.6] | Loss=0.00783 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.157 | L2-Norm(final)=9.249 | 5201.2 samples/s | 81.3 steps/s
[Step=50500 Epoch=98.7] | Loss=0.00777 | Reg=0.00294 | acc=0.9844 | L2-Norm=17.159 | L2-Norm(final)=9.257 | 7165.0 samples/s | 112.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=98.7] | Loss=0.00543 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.182 | L2-Norm(final)=9.338 | 6375.4 samples/s | 99.6 steps/s
[Step=50550 Epoch=98.8] | Loss=0.00720 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.185 | L2-Norm(final)=9.345 | 4141.2 samples/s | 64.7 steps/s
[Step=50600 Epoch=98.9] | Loss=0.00741 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.188 | L2-Norm(final)=9.349 | 4621.7 samples/s | 72.2 steps/s
[Step=50650 Epoch=99.0] | Loss=0.00733 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.189 | L2-Norm(final)=9.352 | 4547.0 samples/s | 71.0 steps/s
[Step=50700 Epoch=99.1] | Loss=0.00732 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.190 | L2-Norm(final)=9.356 | 4611.4 samples/s | 72.1 steps/s
[Step=50750 Epoch=99.2] | Loss=0.00695 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.192 | L2-Norm(final)=9.360 | 4579.1 samples/s | 71.5 steps/s
[Step=50800 Epoch=99.3] | Loss=0.00713 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.193 | L2-Norm(final)=9.364 | 4682.9 samples/s | 73.2 steps/s
[Step=50850 Epoch=99.4] | Loss=0.00717 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.195 | L2-Norm(final)=9.368 | 4586.3 samples/s | 71.7 steps/s
[Step=50900 Epoch=99.5] | Loss=0.00758 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.196 | L2-Norm(final)=9.371 | 4613.6 samples/s | 72.1 steps/s
[Step=50950 Epoch=99.6] | Loss=0.00782 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.198 | L2-Norm(final)=9.374 | 4680.0 samples/s | 73.1 steps/s
[Step=51000 Epoch=99.7] | Loss=0.00777 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.200 | L2-Norm(final)=9.377 | 5996.3 samples/s | 93.7 steps/s
[Step=51050 Epoch=99.8] | Loss=0.00760 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.201 | L2-Norm(final)=9.380 | 2448.1 samples/s | 38.3 steps/s
[Step=51100 Epoch=99.9] | Loss=0.00769 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.202 | L2-Norm(final)=9.383 | 4597.6 samples/s | 71.8 steps/s
[Step=51150 Epoch=100.0] | Loss=0.00758 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.203 | L2-Norm(final)=9.386 | 4607.9 samples/s | 72.0 steps/s
[Step=51200 Epoch=100.1] | Loss=0.00748 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.204 | L2-Norm(final)=9.389 | 4661.1 samples/s | 72.8 steps/s
[Step=51250 Epoch=100.2] | Loss=0.00736 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.205 | L2-Norm(final)=9.392 | 4555.5 samples/s | 71.2 steps/s
[Step=51300 Epoch=100.3] | Loss=0.00735 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.205 | L2-Norm(final)=9.395 | 4635.7 samples/s | 72.4 steps/s
[Step=51350 Epoch=100.4] | Loss=0.00733 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=9.398 | 4651.2 samples/s | 72.7 steps/s
[Step=51400 Epoch=100.5] | Loss=0.00733 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=9.401 | 4644.9 samples/s | 72.6 steps/s
[Step=51450 Epoch=100.6] | Loss=0.00732 | Reg=0.00296 | acc=0.9688 | L2-Norm=17.207 | L2-Norm(final)=9.404 | 4583.0 samples/s | 71.6 steps/s
[Step=51500 Epoch=100.7] | Loss=0.00725 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.207 | L2-Norm(final)=9.407 | 5112.9 samples/s | 79.9 steps/s
[Step=51550 Epoch=100.8] | Loss=0.00718 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.208 | L2-Norm(final)=9.410 | 2625.0 samples/s | 41.0 steps/s
[Step=51600 Epoch=100.9] | Loss=0.00716 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.208 | L2-Norm(final)=9.413 | 4686.4 samples/s | 73.2 steps/s
[Step=51650 Epoch=101.0] | Loss=0.00712 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.208 | L2-Norm(final)=9.415 | 4563.2 samples/s | 71.3 steps/s
[Step=51700 Epoch=101.1] | Loss=0.00703 | Reg=0.00296 | acc=0.9531 | L2-Norm=17.208 | L2-Norm(final)=9.418 | 4633.5 samples/s | 72.4 steps/s
[Step=51750 Epoch=101.2] | Loss=0.00699 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.208 | L2-Norm(final)=9.421 | 4601.8 samples/s | 71.9 steps/s
[Step=51800 Epoch=101.3] | Loss=0.00695 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=9.423 | 4716.2 samples/s | 73.7 steps/s
[Step=51850 Epoch=101.4] | Loss=0.00690 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=9.426 | 4587.7 samples/s | 71.7 steps/s
[Step=51900 Epoch=101.5] | Loss=0.00681 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=9.429 | 4607.4 samples/s | 72.0 steps/s
[Step=51950 Epoch=101.6] | Loss=0.00679 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.206 | L2-Norm(final)=9.431 | 4657.9 samples/s | 72.8 steps/s
[Step=52000 Epoch=101.7] | Loss=0.00679 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.206 | L2-Norm(final)=9.434 | 4639.4 samples/s | 72.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step52000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=191.6] | Loss=0.00007 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.223 | L2-Norm(final)=6.709 | 6666.2 samples/s | 104.2 steps/s
[Step=50050 Epoch=191.8] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.234 | L2-Norm(final)=6.714 | 4171.8 samples/s | 65.2 steps/s
[Step=50100 Epoch=192.0] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=6.719 | 4948.8 samples/s | 77.3 steps/s
[Step=50150 Epoch=192.2] | Loss=0.00005 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.238 | L2-Norm(final)=6.724 | 4906.1 samples/s | 76.7 steps/s
[Step=50200 Epoch=192.3] | Loss=0.00004 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.729 | 5090.1 samples/s | 79.5 steps/s
[Step=50250 Epoch=192.5] | Loss=0.00004 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.734 | 6502.7 samples/s | 101.6 steps/s
[Step=50300 Epoch=192.7] | Loss=0.00004 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.739 | 2472.7 samples/s | 38.6 steps/s
[Step=50350 Epoch=192.9] | Loss=0.00003 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.744 | 4893.5 samples/s | 76.5 steps/s
[Step=50400 Epoch=193.1] | Loss=0.00003 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.748 | 4878.2 samples/s | 76.2 steps/s
[Step=50450 Epoch=193.3] | Loss=0.00003 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.241 | L2-Norm(final)=6.752 | 5092.2 samples/s | 79.6 steps/s
[Step=50500 Epoch=193.5] | Loss=0.00003 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.240 | L2-Norm(final)=6.757 | 5472.6 samples/s | 85.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=193.5] | Loss=0.00004 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.236 | L2-Norm(final)=6.798 | 6429.5 samples/s | 100.5 steps/s
[Step=50550 Epoch=193.7] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=6.802 | 3845.1 samples/s | 60.1 steps/s
[Step=50600 Epoch=193.9] | Loss=0.00002 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.224 | L2-Norm(final)=6.806 | 4395.8 samples/s | 68.7 steps/s
[Step=50650 Epoch=194.1] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.216 | L2-Norm(final)=6.809 | 4374.3 samples/s | 68.3 steps/s
[Step=50700 Epoch=194.3] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.208 | L2-Norm(final)=6.812 | 4385.2 samples/s | 68.5 steps/s
[Step=50750 Epoch=194.5] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=6.814 | 5828.7 samples/s | 91.1 steps/s
[Step=50800 Epoch=194.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.190 | L2-Norm(final)=6.816 | 2320.6 samples/s | 36.3 steps/s
[Step=50850 Epoch=194.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.181 | L2-Norm(final)=6.818 | 4367.5 samples/s | 68.2 steps/s
[Step=50900 Epoch=195.0] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.172 | L2-Norm(final)=6.820 | 4368.9 samples/s | 68.3 steps/s
[Step=50950 Epoch=195.2] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.163 | L2-Norm(final)=6.822 | 4438.4 samples/s | 69.4 steps/s
[Step=51000 Epoch=195.4] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.154 | L2-Norm(final)=6.824 | 4921.5 samples/s | 76.9 steps/s
[Step=51050 Epoch=195.6] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=6.826 | 2507.1 samples/s | 39.2 steps/s
[Step=51100 Epoch=195.8] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.135 | L2-Norm(final)=6.828 | 4402.9 samples/s | 68.8 steps/s
[Step=51150 Epoch=196.0] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.125 | L2-Norm(final)=6.829 | 4317.7 samples/s | 67.5 steps/s
[Step=51200 Epoch=196.2] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.115 | L2-Norm(final)=6.831 | 4405.8 samples/s | 68.8 steps/s
[Step=51250 Epoch=196.4] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.106 | L2-Norm(final)=6.833 | 4370.9 samples/s | 68.3 steps/s
[Step=51300 Epoch=196.6] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.096 | L2-Norm(final)=6.834 | 2672.5 samples/s | 41.8 steps/s
[Step=51350 Epoch=196.8] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.086 | L2-Norm(final)=6.836 | 4429.1 samples/s | 69.2 steps/s
[Step=51400 Epoch=196.9] | Loss=0.00001 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.075 | L2-Norm(final)=6.837 | 4343.0 samples/s | 67.9 steps/s
[Step=51450 Epoch=197.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.065 | L2-Norm(final)=6.839 | 4467.3 samples/s | 69.8 steps/s
[Step=51500 Epoch=197.3] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.055 | L2-Norm(final)=6.841 | 4266.8 samples/s | 66.7 steps/s
[Step=51550 Epoch=197.5] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.044 | L2-Norm(final)=6.842 | 2689.4 samples/s | 42.0 steps/s
[Step=51600 Epoch=197.7] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.033 | L2-Norm(final)=6.844 | 4410.4 samples/s | 68.9 steps/s
[Step=51650 Epoch=197.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.023 | L2-Norm(final)=6.846 | 4368.1 samples/s | 68.3 steps/s
[Step=51700 Epoch=198.1] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.012 | L2-Norm(final)=6.848 | 4424.9 samples/s | 69.1 steps/s
[Step=51750 Epoch=198.3] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.001 | L2-Norm(final)=6.849 | 4379.1 samples/s | 68.4 steps/s
[Step=51800 Epoch=198.5] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.990 | L2-Norm(final)=6.851 | 6378.2 samples/s | 99.7 steps/s
[Step=51850 Epoch=198.7] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=6.853 | 2284.4 samples/s | 35.7 steps/s
[Step=51900 Epoch=198.9] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.967 | L2-Norm(final)=6.855 | 4252.9 samples/s | 66.5 steps/s
[Step=51950 Epoch=199.1] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.956 | L2-Norm(final)=6.857 | 4360.4 samples/s | 68.1 steps/s
[Step=52000 Epoch=199.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.944 | L2-Norm(final)=6.859 | 4444.6 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step52000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=192.5] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=7.093 | 6698.0 samples/s | 104.7 steps/s
[Step=50050 Epoch=192.7] | Loss=0.00003 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.098 | 4112.7 samples/s | 64.3 steps/s
[Step=50100 Epoch=192.9] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.099 | 4885.8 samples/s | 76.3 steps/s
[Step=50150 Epoch=193.0] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.101 | 4905.4 samples/s | 76.6 steps/s
[Step=50200 Epoch=193.2] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.102 | 4898.3 samples/s | 76.5 steps/s
[Step=50250 Epoch=193.4] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.104 | 6934.9 samples/s | 108.4 steps/s
[Step=50300 Epoch=193.6] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.200 | L2-Norm(final)=7.105 | 2452.1 samples/s | 38.3 steps/s
[Step=50350 Epoch=193.8] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.200 | L2-Norm(final)=7.107 | 4889.3 samples/s | 76.4 steps/s
[Step=50400 Epoch=194.0] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.200 | L2-Norm(final)=7.109 | 5088.5 samples/s | 79.5 steps/s
[Step=50450 Epoch=194.2] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.200 | L2-Norm(final)=7.110 | 4646.5 samples/s | 72.6 steps/s
[Step=50500 Epoch=194.4] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.111 | 5795.6 samples/s | 90.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=194.4] | Loss=0.00002 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.194 | L2-Norm(final)=7.126 | 6542.6 samples/s | 102.2 steps/s
[Step=50550 Epoch=194.6] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.191 | L2-Norm(final)=7.127 | 3808.2 samples/s | 59.5 steps/s
[Step=50600 Epoch=194.8] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.188 | L2-Norm(final)=7.128 | 4421.8 samples/s | 69.1 steps/s
[Step=50650 Epoch=195.0] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.184 | L2-Norm(final)=7.129 | 4330.5 samples/s | 67.7 steps/s
[Step=50700 Epoch=195.2] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.180 | L2-Norm(final)=7.130 | 4453.2 samples/s | 69.6 steps/s
[Step=50750 Epoch=195.4] | Loss=0.00001 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.176 | L2-Norm(final)=7.131 | 5875.5 samples/s | 91.8 steps/s
[Step=50800 Epoch=195.5] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.172 | L2-Norm(final)=7.131 | 2348.0 samples/s | 36.7 steps/s
[Step=50850 Epoch=195.7] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.169 | L2-Norm(final)=7.132 | 4261.4 samples/s | 66.6 steps/s
[Step=50900 Epoch=195.9] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=7.133 | 4373.4 samples/s | 68.3 steps/s
[Step=50950 Epoch=196.1] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.161 | L2-Norm(final)=7.134 | 4405.5 samples/s | 68.8 steps/s
[Step=51000 Epoch=196.3] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.156 | L2-Norm(final)=7.135 | 5098.6 samples/s | 79.7 steps/s
[Step=51050 Epoch=196.5] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.152 | L2-Norm(final)=7.135 | 2474.5 samples/s | 38.7 steps/s
[Step=51100 Epoch=196.7] | Loss=0.00001 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.148 | L2-Norm(final)=7.136 | 4289.4 samples/s | 67.0 steps/s
[Step=51150 Epoch=196.9] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.144 | L2-Norm(final)=7.137 | 4402.4 samples/s | 68.8 steps/s
[Step=51200 Epoch=197.1] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=7.137 | 4402.8 samples/s | 68.8 steps/s
[Step=51250 Epoch=197.3] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.136 | L2-Norm(final)=7.138 | 4461.9 samples/s | 69.7 steps/s
[Step=51300 Epoch=197.5] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.131 | L2-Norm(final)=7.139 | 2682.5 samples/s | 41.9 steps/s
[Step=51350 Epoch=197.7] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.127 | L2-Norm(final)=7.139 | 4423.5 samples/s | 69.1 steps/s
[Step=51400 Epoch=197.9] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.122 | L2-Norm(final)=7.140 | 4236.8 samples/s | 66.2 steps/s
[Step=51450 Epoch=198.1] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=7.141 | 4406.6 samples/s | 68.9 steps/s
[Step=51500 Epoch=198.2] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.114 | L2-Norm(final)=7.141 | 4401.8 samples/s | 68.8 steps/s
[Step=51550 Epoch=198.4] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.109 | L2-Norm(final)=7.142 | 2674.0 samples/s | 41.8 steps/s
[Step=51600 Epoch=198.6] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.105 | L2-Norm(final)=7.143 | 4365.8 samples/s | 68.2 steps/s
[Step=51650 Epoch=198.8] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.100 | L2-Norm(final)=7.143 | 4434.8 samples/s | 69.3 steps/s
[Step=51700 Epoch=199.0] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.095 | L2-Norm(final)=7.144 | 4500.9 samples/s | 70.3 steps/s
[Step=51750 Epoch=199.2] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.091 | L2-Norm(final)=7.145 | 4208.9 samples/s | 65.8 steps/s
[Step=51800 Epoch=199.4] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.086 | L2-Norm(final)=7.145 | 7186.5 samples/s | 112.3 steps/s
[Step=51850 Epoch=199.6] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.081 | L2-Norm(final)=7.146 | 2169.8 samples/s | 33.9 steps/s
[Step=51900 Epoch=199.8] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.076 | L2-Norm(final)=7.146 | 4438.8 samples/s | 69.4 steps/s
[Step=51950 Epoch=200.0] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.071 | L2-Norm(final)=7.147 | 4318.5 samples/s | 67.5 steps/s
[Step=52000 Epoch=200.2] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.066 | L2-Norm(final)=7.148 | 4415.5 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08562 | acc=0.9670 | tpr=0.9741 | fpr=0.0486 | 5221.4 samples/s | 20.4 steps/s
Avg test loss: 0.08405, Avg test acc: 0.96658, Avg tpr: 0.97412, Avg fpr: 0.04999, total FA: 390

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08760 | acc=0.9680 | tpr=0.9785 | fpr=0.0548 | 5108.9 samples/s | 20.0 steps/s
Avg test loss: 0.08800, Avg test acc: 0.96835, Avg tpr: 0.97908, Avg fpr: 0.05525, total FA: 431

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.37819 | acc=0.3092 | tpr=0.0070 | fpr=0.0344 | 5358.0 samples/s | 20.9 steps/s
Avg test loss: 5.38966, Avg test acc: 0.30748, Avg tpr: 0.00688, Avg fpr: 0.03141, total FA: 245

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.40540 | acc=0.3048 | tpr=0.0105 | fpr=0.0562 | 5424.8 samples/s | 21.2 steps/s
Avg test loss: 5.41879, Avg test acc: 0.30339, Avg tpr: 0.01014, Avg fpr: 0.05166, total FA: 403

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.53996 | acc=0.1230 | tpr=0.7478 | fpr=0.8883 | 5312.8 samples/s | 20.8 steps/s
[Step= 100] | Loss=6.51663 | acc=0.1223 | tpr=0.7207 | fpr=0.8889 | 7191.3 samples/s | 28.1 steps/s
[Step= 150] | Loss=6.51329 | acc=0.1231 | tpr=0.7262 | fpr=0.8880 | 7870.7 samples/s | 30.7 steps/s
[Step= 200] | Loss=6.52578 | acc=0.1218 | tpr=0.7279 | fpr=0.8893 | 7941.5 samples/s | 31.0 steps/s
[Step= 250] | Loss=6.52963 | acc=0.1222 | tpr=0.7197 | fpr=0.8887 | 8156.9 samples/s | 31.9 steps/s
[Step= 300] | Loss=6.52473 | acc=0.1222 | tpr=0.7215 | fpr=0.8887 | 7843.5 samples/s | 30.6 steps/s
[Step= 350] | Loss=6.51537 | acc=0.1224 | tpr=0.7201 | fpr=0.8885 | 8220.4 samples/s | 32.1 steps/s
[Step= 400] | Loss=6.50977 | acc=0.1229 | tpr=0.7199 | fpr=0.8880 | 8159.4 samples/s | 31.9 steps/s
[Step= 450] | Loss=6.50839 | acc=0.1223 | tpr=0.7191 | fpr=0.8885 | 8410.9 samples/s | 32.9 steps/s
[Step= 500] | Loss=6.50926 | acc=0.1220 | tpr=0.7185 | fpr=0.8888 | 7861.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.50792 | acc=0.1223 | tpr=0.7139 | fpr=0.8885 | 15171.4 samples/s | 59.3 steps/s
Avg test loss: 6.50872, Avg test acc: 0.12218, Avg tpr: 0.71355, Avg fpr: 0.88857, total FA: 123376

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.08526 | acc=0.1214 | tpr=0.7478 | fpr=0.8899 | 5414.0 samples/s | 21.1 steps/s
[Step= 100] | Loss=7.06467 | acc=0.1212 | tpr=0.7228 | fpr=0.8900 | 6796.6 samples/s | 26.5 steps/s
[Step= 150] | Loss=7.05059 | acc=0.1227 | tpr=0.7363 | fpr=0.8886 | 8254.7 samples/s | 32.2 steps/s
[Step= 200] | Loss=7.05638 | acc=0.1217 | tpr=0.7355 | fpr=0.8894 | 7675.9 samples/s | 30.0 steps/s
[Step= 250] | Loss=7.06126 | acc=0.1225 | tpr=0.7319 | fpr=0.8886 | 8447.2 samples/s | 33.0 steps/s
[Step= 300] | Loss=7.06461 | acc=0.1218 | tpr=0.7345 | fpr=0.8894 | 8235.4 samples/s | 32.2 steps/s
[Step= 350] | Loss=7.05292 | acc=0.1219 | tpr=0.7320 | fpr=0.8892 | 7918.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=7.04545 | acc=0.1225 | tpr=0.7325 | fpr=0.8886 | 8512.2 samples/s | 33.3 steps/s
[Step= 450] | Loss=7.04024 | acc=0.1219 | tpr=0.7313 | fpr=0.8891 | 8300.4 samples/s | 32.4 steps/s
[Step= 500] | Loss=7.04185 | acc=0.1218 | tpr=0.7295 | fpr=0.8891 | 7892.6 samples/s | 30.8 steps/s
[Step= 550] | Loss=7.03878 | acc=0.1221 | tpr=0.7262 | fpr=0.8889 | 14943.7 samples/s | 58.4 steps/s
Avg test loss: 7.04007, Avg test acc: 0.12204, Avg tpr: 0.72583, Avg fpr: 0.88894, total FA: 123427

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13257 | acc=0.9789 | tpr=0.9425 | fpr=0.0204 | 5326.7 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.13925 | acc=0.9780 | tpr=0.9574 | fpr=0.0216 | 7222.1 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.14444 | acc=0.9768 | tpr=0.9539 | fpr=0.0227 | 7596.1 samples/s | 29.7 steps/s
[Step= 200] | Loss=0.14681 | acc=0.9769 | tpr=0.9530 | fpr=0.0227 | 7912.0 samples/s | 30.9 steps/s
[Step= 250] | Loss=0.14461 | acc=0.9772 | tpr=0.9502 | fpr=0.0223 | 8659.6 samples/s | 33.8 steps/s
[Step= 300] | Loss=0.14685 | acc=0.9768 | tpr=0.9484 | fpr=0.0227 | 8065.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.14748 | acc=0.9765 | tpr=0.9505 | fpr=0.0230 | 8022.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.14921 | acc=0.9763 | tpr=0.9486 | fpr=0.0232 | 7973.4 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.15248 | acc=0.9760 | tpr=0.9484 | fpr=0.0235 | 7884.1 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.15169 | acc=0.9760 | tpr=0.9489 | fpr=0.0236 | 8318.0 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.15068 | acc=0.9762 | tpr=0.9479 | fpr=0.0233 | 13855.7 samples/s | 54.1 steps/s
Avg test loss: 0.15029, Avg test acc: 0.97618, Avg tpr: 0.94691, Avg fpr: 0.02328, total FA: 3233

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15945 | acc=0.9762 | tpr=0.9425 | fpr=0.0231 | 5259.1 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.16545 | acc=0.9763 | tpr=0.9510 | fpr=0.0232 | 7311.9 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.17106 | acc=0.9753 | tpr=0.9539 | fpr=0.0243 | 7952.4 samples/s | 31.1 steps/s
[Step= 200] | Loss=0.17501 | acc=0.9753 | tpr=0.9563 | fpr=0.0244 | 8130.5 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.17159 | acc=0.9759 | tpr=0.9572 | fpr=0.0238 | 7978.8 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.17475 | acc=0.9754 | tpr=0.9527 | fpr=0.0242 | 8062.4 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.17578 | acc=0.9752 | tpr=0.9543 | fpr=0.0244 | 8180.8 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.17752 | acc=0.9750 | tpr=0.9497 | fpr=0.0246 | 8096.5 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.18133 | acc=0.9745 | tpr=0.9499 | fpr=0.0250 | 8207.0 samples/s | 32.1 steps/s
[Step= 500] | Loss=0.18059 | acc=0.9745 | tpr=0.9511 | fpr=0.0251 | 8129.5 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.17928 | acc=0.9747 | tpr=0.9511 | fpr=0.0249 | 11901.1 samples/s | 46.5 steps/s
Avg test loss: 0.17880, Avg test acc: 0.97471, Avg tpr: 0.95048, Avg fpr: 0.02485, total FA: 3451

server round 26/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=101.4] | Loss=0.00522 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.016 | 6298.5 samples/s | 98.4 steps/s
[Step=52050 Epoch=101.5] | Loss=0.00422 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.021 | 4688.6 samples/s | 73.3 steps/s
[Step=52100 Epoch=101.6] | Loss=0.00437 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.565 | L2-Norm(final)=9.025 | 5267.7 samples/s | 82.3 steps/s
[Step=52150 Epoch=101.7] | Loss=0.00467 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.563 | L2-Norm(final)=9.030 | 5044.5 samples/s | 78.8 steps/s
[Step=52200 Epoch=101.8] | Loss=0.00474 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.562 | L2-Norm(final)=9.034 | 5231.9 samples/s | 81.7 steps/s
[Step=52250 Epoch=101.9] | Loss=0.00462 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.561 | L2-Norm(final)=9.037 | 5159.9 samples/s | 80.6 steps/s
[Step=52300 Epoch=102.0] | Loss=0.00455 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.560 | L2-Norm(final)=9.042 | 5332.4 samples/s | 83.3 steps/s
[Step=52350 Epoch=102.1] | Loss=0.00452 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.559 | L2-Norm(final)=9.046 | 5156.6 samples/s | 80.6 steps/s
[Step=52400 Epoch=102.2] | Loss=0.00468 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.557 | L2-Norm(final)=9.050 | 5146.5 samples/s | 80.4 steps/s
[Step=52450 Epoch=102.3] | Loss=0.00471 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.556 | L2-Norm(final)=9.055 | 5224.1 samples/s | 81.6 steps/s
[Step=52500 Epoch=102.4] | Loss=0.00478 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.554 | L2-Norm(final)=9.059 | 7009.2 samples/s | 109.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=102.4] | Loss=0.00670 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.542 | L2-Norm(final)=9.103 | 6399.3 samples/s | 100.0 steps/s
[Step=52550 Epoch=102.5] | Loss=0.00675 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.543 | L2-Norm(final)=9.107 | 4154.2 samples/s | 64.9 steps/s
[Step=52600 Epoch=102.6] | Loss=0.00808 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.545 | L2-Norm(final)=9.109 | 4662.0 samples/s | 72.8 steps/s
[Step=52650 Epoch=102.7] | Loss=0.00986 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.547 | L2-Norm(final)=9.108 | 4557.1 samples/s | 71.2 steps/s
[Step=52700 Epoch=102.8] | Loss=0.00922 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.549 | L2-Norm(final)=9.108 | 4660.9 samples/s | 72.8 steps/s
[Step=52750 Epoch=102.9] | Loss=0.00874 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.550 | L2-Norm(final)=9.110 | 4576.2 samples/s | 71.5 steps/s
[Step=52800 Epoch=103.0] | Loss=0.00841 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.552 | L2-Norm(final)=9.114 | 4626.3 samples/s | 72.3 steps/s
[Step=52850 Epoch=103.1] | Loss=0.00839 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.554 | L2-Norm(final)=9.117 | 4620.9 samples/s | 72.2 steps/s
[Step=52900 Epoch=103.2] | Loss=0.00850 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.556 | L2-Norm(final)=9.120 | 4605.9 samples/s | 72.0 steps/s
[Step=52950 Epoch=103.3] | Loss=0.00841 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.559 | L2-Norm(final)=9.123 | 4616.0 samples/s | 72.1 steps/s
[Step=53000 Epoch=103.4] | Loss=0.00808 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.561 | L2-Norm(final)=9.126 | 5915.7 samples/s | 92.4 steps/s
[Step=53050 Epoch=103.5] | Loss=0.00786 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.562 | L2-Norm(final)=9.130 | 2450.0 samples/s | 38.3 steps/s
[Step=53100 Epoch=103.6] | Loss=0.00790 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.564 | L2-Norm(final)=9.133 | 4599.5 samples/s | 71.9 steps/s
[Step=53150 Epoch=103.7] | Loss=0.00787 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.565 | L2-Norm(final)=9.137 | 4626.0 samples/s | 72.3 steps/s
[Step=53200 Epoch=103.8] | Loss=0.00771 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.565 | L2-Norm(final)=9.140 | 4549.4 samples/s | 71.1 steps/s
[Step=53250 Epoch=103.9] | Loss=0.00761 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.566 | L2-Norm(final)=9.143 | 4623.5 samples/s | 72.2 steps/s
[Step=53300 Epoch=104.0] | Loss=0.00747 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.146 | 4663.5 samples/s | 72.9 steps/s
[Step=53350 Epoch=104.1] | Loss=0.00746 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.567 | L2-Norm(final)=9.149 | 4591.8 samples/s | 71.7 steps/s
[Step=53400 Epoch=104.2] | Loss=0.00741 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.151 | 4629.7 samples/s | 72.3 steps/s
[Step=53450 Epoch=104.2] | Loss=0.00731 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.154 | 4616.9 samples/s | 72.1 steps/s
[Step=53500 Epoch=104.3] | Loss=0.00735 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.157 | 4984.5 samples/s | 77.9 steps/s
[Step=53550 Epoch=104.4] | Loss=0.00732 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.160 | 2662.4 samples/s | 41.6 steps/s
[Step=53600 Epoch=104.5] | Loss=0.00725 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.568 | L2-Norm(final)=9.163 | 4606.9 samples/s | 72.0 steps/s
[Step=53650 Epoch=104.6] | Loss=0.00719 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.166 | 4607.7 samples/s | 72.0 steps/s
[Step=53700 Epoch=104.7] | Loss=0.00719 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.168 | 4639.6 samples/s | 72.5 steps/s
[Step=53750 Epoch=104.8] | Loss=0.00717 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.171 | 4696.0 samples/s | 73.4 steps/s
[Step=53800 Epoch=104.9] | Loss=0.00715 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.568 | L2-Norm(final)=9.174 | 4665.9 samples/s | 72.9 steps/s
[Step=53850 Epoch=105.0] | Loss=0.00708 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.568 | L2-Norm(final)=9.176 | 4521.6 samples/s | 70.7 steps/s
[Step=53900 Epoch=105.1] | Loss=0.00699 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.179 | 4593.5 samples/s | 71.8 steps/s
[Step=53950 Epoch=105.2] | Loss=0.00694 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=9.182 | 4648.2 samples/s | 72.6 steps/s
[Step=54000 Epoch=105.3] | Loss=0.00697 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.566 | L2-Norm(final)=9.184 | 4620.4 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step54000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=101.7] | Loss=0.00710 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.014 | L2-Norm(final)=9.513 | 6758.2 samples/s | 105.6 steps/s
[Step=52050 Epoch=101.8] | Loss=0.00607 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.016 | L2-Norm(final)=9.519 | 4286.4 samples/s | 67.0 steps/s
[Step=52100 Epoch=101.9] | Loss=0.00592 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.018 | L2-Norm(final)=9.527 | 5158.1 samples/s | 80.6 steps/s
[Step=52150 Epoch=102.0] | Loss=0.00542 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.018 | L2-Norm(final)=9.534 | 5309.4 samples/s | 83.0 steps/s
[Step=52200 Epoch=102.0] | Loss=0.00484 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.018 | L2-Norm(final)=9.540 | 5120.1 samples/s | 80.0 steps/s
[Step=52250 Epoch=102.1] | Loss=0.00461 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.017 | L2-Norm(final)=9.547 | 5079.0 samples/s | 79.4 steps/s
[Step=52300 Epoch=102.2] | Loss=0.00480 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.016 | L2-Norm(final)=9.553 | 5168.1 samples/s | 80.8 steps/s
[Step=52350 Epoch=102.3] | Loss=0.00499 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.015 | L2-Norm(final)=9.559 | 5257.2 samples/s | 82.1 steps/s
[Step=52400 Epoch=102.4] | Loss=0.00489 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.014 | L2-Norm(final)=9.564 | 5283.3 samples/s | 82.6 steps/s
[Step=52450 Epoch=102.5] | Loss=0.00488 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.013 | L2-Norm(final)=9.569 | 5149.3 samples/s | 80.5 steps/s
[Step=52500 Epoch=102.6] | Loss=0.00489 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.011 | L2-Norm(final)=9.573 | 6982.6 samples/s | 109.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=102.6] | Loss=0.00288 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.998 | L2-Norm(final)=9.620 | 6754.4 samples/s | 105.5 steps/s
[Step=52550 Epoch=102.7] | Loss=0.00524 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.998 | L2-Norm(final)=9.625 | 3986.4 samples/s | 62.3 steps/s
[Step=52600 Epoch=102.8] | Loss=0.00547 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.998 | L2-Norm(final)=9.628 | 4617.5 samples/s | 72.1 steps/s
[Step=52650 Epoch=102.9] | Loss=0.00600 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.998 | L2-Norm(final)=9.631 | 4653.9 samples/s | 72.7 steps/s
[Step=52700 Epoch=103.0] | Loss=0.00622 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.998 | L2-Norm(final)=9.633 | 4569.9 samples/s | 71.4 steps/s
[Step=52750 Epoch=103.1] | Loss=0.00642 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.998 | L2-Norm(final)=9.636 | 4622.0 samples/s | 72.2 steps/s
[Step=52800 Epoch=103.2] | Loss=0.00683 | Reg=0.00289 | acc=0.9844 | L2-Norm=16.999 | L2-Norm(final)=9.639 | 4614.6 samples/s | 72.1 steps/s
[Step=52850 Epoch=103.3] | Loss=0.00711 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.000 | L2-Norm(final)=9.641 | 4670.2 samples/s | 73.0 steps/s
[Step=52900 Epoch=103.4] | Loss=0.00731 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.002 | L2-Norm(final)=9.644 | 4580.1 samples/s | 71.6 steps/s
[Step=52950 Epoch=103.5] | Loss=0.00745 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.003 | L2-Norm(final)=9.646 | 4634.4 samples/s | 72.4 steps/s
[Step=53000 Epoch=103.6] | Loss=0.00751 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.004 | L2-Norm(final)=9.649 | 6029.3 samples/s | 94.2 steps/s
[Step=53050 Epoch=103.7] | Loss=0.00737 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.006 | L2-Norm(final)=9.652 | 2438.0 samples/s | 38.1 steps/s
[Step=53100 Epoch=103.8] | Loss=0.00731 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.007 | L2-Norm(final)=9.655 | 4628.7 samples/s | 72.3 steps/s
[Step=53150 Epoch=103.9] | Loss=0.00723 | Reg=0.00289 | acc=0.9688 | L2-Norm=17.008 | L2-Norm(final)=9.658 | 4605.9 samples/s | 72.0 steps/s
[Step=53200 Epoch=104.0] | Loss=0.00719 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.009 | L2-Norm(final)=9.661 | 4651.7 samples/s | 72.7 steps/s
[Step=53250 Epoch=104.1] | Loss=0.00723 | Reg=0.00289 | acc=0.9688 | L2-Norm=17.010 | L2-Norm(final)=9.664 | 4555.1 samples/s | 71.2 steps/s
[Step=53300 Epoch=104.2] | Loss=0.00717 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.011 | L2-Norm(final)=9.668 | 4612.1 samples/s | 72.1 steps/s
[Step=53350 Epoch=104.3] | Loss=0.00704 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.012 | L2-Norm(final)=9.671 | 4647.8 samples/s | 72.6 steps/s
[Step=53400 Epoch=104.4] | Loss=0.00706 | Reg=0.00289 | acc=0.9844 | L2-Norm=17.013 | L2-Norm(final)=9.675 | 4632.7 samples/s | 72.4 steps/s
[Step=53450 Epoch=104.5] | Loss=0.00712 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.014 | L2-Norm(final)=9.678 | 4620.4 samples/s | 72.2 steps/s
[Step=53500 Epoch=104.6] | Loss=0.00707 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.015 | L2-Norm(final)=9.681 | 5135.1 samples/s | 80.2 steps/s
[Step=53550 Epoch=104.7] | Loss=0.00704 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.684 | 2638.2 samples/s | 41.2 steps/s
[Step=53600 Epoch=104.8] | Loss=0.00696 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.016 | L2-Norm(final)=9.688 | 4633.4 samples/s | 72.4 steps/s
[Step=53650 Epoch=104.9] | Loss=0.00687 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.691 | 4543.3 samples/s | 71.0 steps/s
[Step=53700 Epoch=105.0] | Loss=0.00676 | Reg=0.00290 | acc=0.9844 | L2-Norm=17.016 | L2-Norm(final)=9.694 | 4654.9 samples/s | 72.7 steps/s
[Step=53750 Epoch=105.1] | Loss=0.00677 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.697 | 4578.9 samples/s | 71.5 steps/s
[Step=53800 Epoch=105.2] | Loss=0.00680 | Reg=0.00290 | acc=0.9688 | L2-Norm=17.016 | L2-Norm(final)=9.700 | 4645.2 samples/s | 72.6 steps/s
[Step=53850 Epoch=105.3] | Loss=0.00680 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.703 | 4716.7 samples/s | 73.7 steps/s
[Step=53900 Epoch=105.4] | Loss=0.00674 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.706 | 4589.6 samples/s | 71.7 steps/s
[Step=53950 Epoch=105.5] | Loss=0.00667 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.016 | L2-Norm(final)=9.709 | 4614.6 samples/s | 72.1 steps/s
[Step=54000 Epoch=105.6] | Loss=0.00663 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.015 | L2-Norm(final)=9.712 | 4625.1 samples/s | 72.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step54000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=199.2] | Loss=0.00021 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.015 | L2-Norm(final)=6.918 | 6458.3 samples/s | 100.9 steps/s
[Step=52050 Epoch=199.4] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.021 | L2-Norm(final)=6.924 | 4212.5 samples/s | 65.8 steps/s
[Step=52100 Epoch=199.6] | Loss=0.00004 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.025 | L2-Norm(final)=6.934 | 4889.2 samples/s | 76.4 steps/s
[Step=52150 Epoch=199.8] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.028 | L2-Norm(final)=6.944 | 4755.5 samples/s | 74.3 steps/s
[Step=52200 Epoch=200.0] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=6.953 | 4852.4 samples/s | 75.8 steps/s
[Step=52250 Epoch=200.2] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.030 | L2-Norm(final)=6.962 | 6501.4 samples/s | 101.6 steps/s
[Step=52300 Epoch=200.4] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.030 | L2-Norm(final)=6.970 | 2420.0 samples/s | 37.8 steps/s
[Step=52350 Epoch=200.6] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.030 | L2-Norm(final)=6.977 | 4883.2 samples/s | 76.3 steps/s
[Step=52400 Epoch=200.8] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=6.985 | 4977.0 samples/s | 77.8 steps/s
[Step=52450 Epoch=201.0] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=6.992 | 4920.5 samples/s | 76.9 steps/s
[Step=52500 Epoch=201.2] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.029 | L2-Norm(final)=6.999 | 5550.3 samples/s | 86.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=201.2] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.027 | L2-Norm(final)=7.074 | 6084.4 samples/s | 95.1 steps/s
[Step=52550 Epoch=201.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.014 | L2-Norm(final)=7.079 | 3972.9 samples/s | 62.1 steps/s
[Step=52600 Epoch=201.5] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=7.084 | 4397.5 samples/s | 68.7 steps/s
[Step=52650 Epoch=201.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.976 | L2-Norm(final)=7.089 | 4364.8 samples/s | 68.2 steps/s
[Step=52700 Epoch=201.9] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.956 | L2-Norm(final)=7.093 | 4365.5 samples/s | 68.2 steps/s
[Step=52750 Epoch=202.1] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.937 | L2-Norm(final)=7.098 | 5852.6 samples/s | 91.4 steps/s
[Step=52800 Epoch=202.3] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.917 | L2-Norm(final)=7.102 | 2351.7 samples/s | 36.7 steps/s
[Step=52850 Epoch=202.5] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.897 | L2-Norm(final)=7.106 | 4312.0 samples/s | 67.4 steps/s
[Step=52900 Epoch=202.7] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.876 | L2-Norm(final)=7.109 | 4332.1 samples/s | 67.7 steps/s
[Step=52950 Epoch=202.9] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.855 | L2-Norm(final)=7.112 | 4479.0 samples/s | 70.0 steps/s
[Step=53000 Epoch=203.1] | Loss=0.00001 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.834 | L2-Norm(final)=7.115 | 4855.8 samples/s | 75.9 steps/s
[Step=53050 Epoch=203.3] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.813 | L2-Norm(final)=7.118 | 2505.7 samples/s | 39.2 steps/s
[Step=53100 Epoch=203.5] | Loss=0.00001 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.792 | L2-Norm(final)=7.121 | 4451.7 samples/s | 69.6 steps/s
[Step=53150 Epoch=203.7] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.770 | L2-Norm(final)=7.124 | 4269.5 samples/s | 66.7 steps/s
[Step=53200 Epoch=203.8] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.748 | L2-Norm(final)=7.127 | 4387.4 samples/s | 68.6 steps/s
[Step=53250 Epoch=204.0] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.726 | L2-Norm(final)=7.130 | 4361.1 samples/s | 68.1 steps/s
[Step=53300 Epoch=204.2] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.704 | L2-Norm(final)=7.132 | 2714.9 samples/s | 42.4 steps/s
[Step=53350 Epoch=204.4] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.682 | L2-Norm(final)=7.135 | 4305.0 samples/s | 67.3 steps/s
[Step=53400 Epoch=204.6] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.659 | L2-Norm(final)=7.138 | 4401.4 samples/s | 68.8 steps/s
[Step=53450 Epoch=204.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.636 | L2-Norm(final)=7.141 | 4446.4 samples/s | 69.5 steps/s
[Step=53500 Epoch=205.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.614 | L2-Norm(final)=7.144 | 4383.6 samples/s | 68.5 steps/s
[Step=53550 Epoch=205.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.591 | L2-Norm(final)=7.148 | 2700.3 samples/s | 42.2 steps/s
[Step=53600 Epoch=205.4] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.568 | L2-Norm(final)=7.151 | 4269.6 samples/s | 66.7 steps/s
[Step=53650 Epoch=205.6] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.544 | L2-Norm(final)=7.154 | 4401.2 samples/s | 68.8 steps/s
[Step=53700 Epoch=205.8] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.521 | L2-Norm(final)=7.157 | 4382.2 samples/s | 68.5 steps/s
[Step=53750 Epoch=206.0] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.497 | L2-Norm(final)=7.160 | 4377.6 samples/s | 68.4 steps/s
[Step=53800 Epoch=206.1] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.474 | L2-Norm(final)=7.164 | 6511.4 samples/s | 101.7 steps/s
[Step=53850 Epoch=206.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.450 | L2-Norm(final)=7.168 | 2223.4 samples/s | 34.7 steps/s
[Step=53900 Epoch=206.5] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.426 | L2-Norm(final)=7.171 | 4373.0 samples/s | 68.3 steps/s
[Step=53950 Epoch=206.7] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.403 | L2-Norm(final)=7.175 | 4410.5 samples/s | 68.9 steps/s
[Step=54000 Epoch=206.9] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.378 | L2-Norm(final)=7.179 | 4400.5 samples/s | 68.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step54000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=200.2] | Loss=0.00003 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.012 | L2-Norm(final)=7.167 | 6344.6 samples/s | 99.1 steps/s
[Step=52050 Epoch=200.4] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.014 | L2-Norm(final)=7.172 | 4308.3 samples/s | 67.3 steps/s
[Step=52100 Epoch=200.6] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.017 | L2-Norm(final)=7.177 | 4807.4 samples/s | 75.1 steps/s
[Step=52150 Epoch=200.7] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.020 | L2-Norm(final)=7.181 | 4884.4 samples/s | 76.3 steps/s
[Step=52200 Epoch=200.9] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.021 | L2-Norm(final)=7.185 | 4886.9 samples/s | 76.4 steps/s
[Step=52250 Epoch=201.1] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.022 | L2-Norm(final)=7.189 | 7020.4 samples/s | 109.7 steps/s
[Step=52300 Epoch=201.3] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.022 | L2-Norm(final)=7.192 | 2452.9 samples/s | 38.3 steps/s
[Step=52350 Epoch=201.5] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.021 | L2-Norm(final)=7.195 | 4989.2 samples/s | 78.0 steps/s
[Step=52400 Epoch=201.7] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.021 | L2-Norm(final)=7.198 | 4777.7 samples/s | 74.7 steps/s
[Step=52450 Epoch=201.9] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.020 | L2-Norm(final)=7.202 | 4903.6 samples/s | 76.6 steps/s
[Step=52500 Epoch=202.1] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.020 | L2-Norm(final)=7.205 | 5884.5 samples/s | 91.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=202.1] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.014 | L2-Norm(final)=7.236 | 6428.2 samples/s | 100.4 steps/s
[Step=52550 Epoch=202.3] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.009 | L2-Norm(final)=7.240 | 3845.9 samples/s | 60.1 steps/s
[Step=52600 Epoch=202.5] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.002 | L2-Norm(final)=7.243 | 4434.0 samples/s | 69.3 steps/s
[Step=52650 Epoch=202.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.994 | L2-Norm(final)=7.246 | 4468.9 samples/s | 69.8 steps/s
[Step=52700 Epoch=202.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.986 | L2-Norm(final)=7.249 | 4278.2 samples/s | 66.8 steps/s
[Step=52750 Epoch=203.1] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.978 | L2-Norm(final)=7.251 | 6044.9 samples/s | 94.5 steps/s
[Step=52800 Epoch=203.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.969 | L2-Norm(final)=7.254 | 2316.5 samples/s | 36.2 steps/s
[Step=52850 Epoch=203.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.961 | L2-Norm(final)=7.256 | 4378.8 samples/s | 68.4 steps/s
[Step=52900 Epoch=203.6] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.952 | L2-Norm(final)=7.258 | 4519.5 samples/s | 70.6 steps/s
[Step=52950 Epoch=203.8] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.943 | L2-Norm(final)=7.260 | 4275.1 samples/s | 66.8 steps/s
[Step=53000 Epoch=204.0] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.934 | L2-Norm(final)=7.262 | 5156.2 samples/s | 80.6 steps/s
[Step=53050 Epoch=204.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.926 | L2-Norm(final)=7.264 | 2460.3 samples/s | 38.4 steps/s
[Step=53100 Epoch=204.4] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.916 | L2-Norm(final)=7.265 | 4363.0 samples/s | 68.2 steps/s
[Step=53150 Epoch=204.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.907 | L2-Norm(final)=7.267 | 4448.9 samples/s | 69.5 steps/s
[Step=53200 Epoch=204.8] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.898 | L2-Norm(final)=7.269 | 4316.8 samples/s | 67.4 steps/s
[Step=53250 Epoch=205.0] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.889 | L2-Norm(final)=7.271 | 4477.8 samples/s | 70.0 steps/s
[Step=53300 Epoch=205.2] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.879 | L2-Norm(final)=7.272 | 2631.6 samples/s | 41.1 steps/s
[Step=53350 Epoch=205.4] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.870 | L2-Norm(final)=7.274 | 4364.2 samples/s | 68.2 steps/s
[Step=53400 Epoch=205.6] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.860 | L2-Norm(final)=7.276 | 4372.2 samples/s | 68.3 steps/s
[Step=53450 Epoch=205.8] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.850 | L2-Norm(final)=7.277 | 4396.8 samples/s | 68.7 steps/s
[Step=53500 Epoch=205.9] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.840 | L2-Norm(final)=7.279 | 4383.8 samples/s | 68.5 steps/s
[Step=53550 Epoch=206.1] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.830 | L2-Norm(final)=7.281 | 2679.8 samples/s | 41.9 steps/s
[Step=53600 Epoch=206.3] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.820 | L2-Norm(final)=7.283 | 4387.9 samples/s | 68.6 steps/s
[Step=53650 Epoch=206.5] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.810 | L2-Norm(final)=7.285 | 4399.2 samples/s | 68.7 steps/s
[Step=53700 Epoch=206.7] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.800 | L2-Norm(final)=7.286 | 4376.8 samples/s | 68.4 steps/s
[Step=53750 Epoch=206.9] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.790 | L2-Norm(final)=7.288 | 4394.0 samples/s | 68.7 steps/s
[Step=53800 Epoch=207.1] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.779 | L2-Norm(final)=7.290 | 7159.0 samples/s | 111.9 steps/s
[Step=53850 Epoch=207.3] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=7.292 | 2162.4 samples/s | 33.8 steps/s
[Step=53900 Epoch=207.5] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.758 | L2-Norm(final)=7.294 | 4424.1 samples/s | 69.1 steps/s
[Step=53950 Epoch=207.7] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.747 | L2-Norm(final)=7.296 | 4405.7 samples/s | 68.8 steps/s
[Step=54000 Epoch=207.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.737 | L2-Norm(final)=7.298 | 4407.0 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08105 | acc=0.9680 | tpr=0.9759 | fpr=0.0491 | 5375.9 samples/s | 21.0 steps/s
Avg test loss: 0.08209, Avg test acc: 0.96727, Avg tpr: 0.97587, Avg fpr: 0.05166, total FA: 403

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.09130 | acc=0.9670 | tpr=0.9787 | fpr=0.0582 | 5480.2 samples/s | 21.4 steps/s
Avg test loss: 0.09328, Avg test acc: 0.96678, Avg tpr: 0.97849, Avg fpr: 0.05897, total FA: 460

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.30107 | acc=0.3105 | tpr=0.0051 | fpr=0.0265 | 5273.4 samples/s | 20.6 steps/s
Avg test loss: 5.30927, Avg test acc: 0.30820, Avg tpr: 0.00478, Avg fpr: 0.02448, total FA: 191

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.12700 | acc=0.3022 | tpr=0.0135 | fpr=0.0709 | 5407.0 samples/s | 21.1 steps/s
Avg test loss: 5.13309, Avg test acc: 0.30099, Avg tpr: 0.01329, Avg fpr: 0.06627, total FA: 517

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=7.02024 | acc=0.1090 | tpr=0.7611 | fpr=0.9027 | 5350.7 samples/s | 20.9 steps/s
[Step= 100] | Loss=6.99721 | acc=0.1086 | tpr=0.7377 | fpr=0.9031 | 6504.1 samples/s | 25.4 steps/s
[Step= 150] | Loss=6.99756 | acc=0.1099 | tpr=0.7565 | fpr=0.9020 | 7731.0 samples/s | 30.2 steps/s
[Step= 200] | Loss=7.01550 | acc=0.1089 | tpr=0.7541 | fpr=0.9029 | 6782.0 samples/s | 26.5 steps/s
[Step= 250] | Loss=7.02272 | acc=0.1091 | tpr=0.7459 | fpr=0.9025 | 8088.9 samples/s | 31.6 steps/s
[Step= 300] | Loss=7.02122 | acc=0.1091 | tpr=0.7476 | fpr=0.9025 | 8109.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=7.01003 | acc=0.1094 | tpr=0.7483 | fpr=0.9022 | 7944.8 samples/s | 31.0 steps/s
[Step= 400] | Loss=7.00227 | acc=0.1097 | tpr=0.7516 | fpr=0.9019 | 8132.7 samples/s | 31.8 steps/s
[Step= 450] | Loss=7.00166 | acc=0.1092 | tpr=0.7522 | fpr=0.9025 | 7971.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=7.00062 | acc=0.1091 | tpr=0.7471 | fpr=0.9024 | 8010.8 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.99991 | acc=0.1093 | tpr=0.7417 | fpr=0.9022 | 14700.7 samples/s | 57.4 steps/s
Avg test loss: 7.00090, Avg test acc: 0.10924, Avg tpr: 0.74128, Avg fpr: 0.90225, total FA: 125275

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.46651 | acc=0.1177 | tpr=0.7788 | fpr=0.8941 | 4615.2 samples/s | 18.0 steps/s
[Step= 100] | Loss=7.44274 | acc=0.1173 | tpr=0.7548 | fpr=0.8946 | 8330.6 samples/s | 32.5 steps/s
[Step= 150] | Loss=7.43139 | acc=0.1180 | tpr=0.7695 | fpr=0.8939 | 7792.6 samples/s | 30.4 steps/s
[Step= 200] | Loss=7.44123 | acc=0.1171 | tpr=0.7683 | fpr=0.8948 | 8440.1 samples/s | 33.0 steps/s
[Step= 250] | Loss=7.44670 | acc=0.1177 | tpr=0.7651 | fpr=0.8941 | 6196.9 samples/s | 24.2 steps/s
[Step= 300] | Loss=7.44896 | acc=0.1177 | tpr=0.7658 | fpr=0.8941 | 7831.6 samples/s | 30.6 steps/s
[Step= 350] | Loss=7.43445 | acc=0.1176 | tpr=0.7614 | fpr=0.8940 | 8198.8 samples/s | 32.0 steps/s
[Step= 400] | Loss=7.42498 | acc=0.1180 | tpr=0.7626 | fpr=0.8937 | 8160.5 samples/s | 31.9 steps/s
[Step= 450] | Loss=7.42002 | acc=0.1173 | tpr=0.7595 | fpr=0.8943 | 8076.3 samples/s | 31.5 steps/s
[Step= 500] | Loss=7.42345 | acc=0.1169 | tpr=0.7568 | fpr=0.8947 | 8152.0 samples/s | 31.8 steps/s
[Step= 550] | Loss=7.41966 | acc=0.1171 | tpr=0.7529 | fpr=0.8945 | 14610.9 samples/s | 57.1 steps/s
Avg test loss: 7.42069, Avg test acc: 0.11705, Avg tpr: 0.75277, Avg fpr: 0.89450, total FA: 124200

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12006 | acc=0.9804 | tpr=0.9336 | fpr=0.0188 | 5223.7 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.12631 | acc=0.9790 | tpr=0.9488 | fpr=0.0205 | 6984.3 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.13123 | acc=0.9778 | tpr=0.9452 | fpr=0.0216 | 8236.1 samples/s | 32.2 steps/s
[Step= 200] | Loss=0.13363 | acc=0.9779 | tpr=0.9464 | fpr=0.0215 | 6379.5 samples/s | 24.9 steps/s
[Step= 250] | Loss=0.13196 | acc=0.9781 | tpr=0.9450 | fpr=0.0213 | 7267.8 samples/s | 28.4 steps/s
[Step= 300] | Loss=0.13387 | acc=0.9777 | tpr=0.9455 | fpr=0.0217 | 8229.6 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.13447 | acc=0.9775 | tpr=0.9487 | fpr=0.0219 | 8035.3 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.13603 | acc=0.9773 | tpr=0.9464 | fpr=0.0221 | 7975.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=0.13898 | acc=0.9769 | tpr=0.9464 | fpr=0.0225 | 8311.8 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.13825 | acc=0.9769 | tpr=0.9463 | fpr=0.0225 | 7960.5 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.13730 | acc=0.9771 | tpr=0.9451 | fpr=0.0224 | 15006.4 samples/s | 58.6 steps/s
Avg test loss: 0.13694, Avg test acc: 0.97708, Avg tpr: 0.94414, Avg fpr: 0.02232, total FA: 3099

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.16194 | acc=0.9757 | tpr=0.9513 | fpr=0.0239 | 5391.0 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.16847 | acc=0.9752 | tpr=0.9574 | fpr=0.0245 | 6864.3 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.17434 | acc=0.9741 | tpr=0.9582 | fpr=0.0256 | 7996.1 samples/s | 31.2 steps/s
[Step= 200] | Loss=0.17813 | acc=0.9740 | tpr=0.9617 | fpr=0.0258 | 6285.8 samples/s | 24.6 steps/s
[Step= 250] | Loss=0.17465 | acc=0.9746 | tpr=0.9616 | fpr=0.0252 | 7596.9 samples/s | 29.7 steps/s
[Step= 300] | Loss=0.17777 | acc=0.9741 | tpr=0.9585 | fpr=0.0257 | 8238.5 samples/s | 32.2 steps/s
[Step= 350] | Loss=0.17878 | acc=0.9739 | tpr=0.9593 | fpr=0.0259 | 7771.3 samples/s | 30.4 steps/s
[Step= 400] | Loss=0.18040 | acc=0.9737 | tpr=0.9557 | fpr=0.0260 | 8209.2 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.18424 | acc=0.9733 | tpr=0.9552 | fpr=0.0264 | 8042.6 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.18355 | acc=0.9733 | tpr=0.9564 | fpr=0.0264 | 8167.3 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.18214 | acc=0.9734 | tpr=0.9566 | fpr=0.0262 | 14512.3 samples/s | 56.7 steps/s
Avg test loss: 0.18166, Avg test acc: 0.97347, Avg tpr: 0.95602, Avg fpr: 0.02622, total FA: 3640

server round 27/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=105.3] | Loss=0.00534 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.225 | L2-Norm(final)=9.260 | 6395.7 samples/s | 99.9 steps/s
[Step=54050 Epoch=105.4] | Loss=0.00524 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.225 | L2-Norm(final)=9.266 | 4671.0 samples/s | 73.0 steps/s
[Step=54100 Epoch=105.5] | Loss=0.00490 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.225 | L2-Norm(final)=9.272 | 5109.1 samples/s | 79.8 steps/s
[Step=54150 Epoch=105.6] | Loss=0.00520 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.224 | L2-Norm(final)=9.279 | 5258.4 samples/s | 82.2 steps/s
[Step=54200 Epoch=105.7] | Loss=0.00512 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=9.285 | 5195.9 samples/s | 81.2 steps/s
[Step=54250 Epoch=105.8] | Loss=0.00524 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.224 | L2-Norm(final)=9.293 | 5404.7 samples/s | 84.4 steps/s
[Step=54300 Epoch=105.9] | Loss=0.00511 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=9.299 | 4954.6 samples/s | 77.4 steps/s
[Step=54350 Epoch=106.0] | Loss=0.00510 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.223 | L2-Norm(final)=9.305 | 5292.9 samples/s | 82.7 steps/s
[Step=54400 Epoch=106.1] | Loss=0.00511 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.223 | L2-Norm(final)=9.312 | 5144.5 samples/s | 80.4 steps/s
[Step=54450 Epoch=106.2] | Loss=0.00532 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.223 | L2-Norm(final)=9.317 | 5349.9 samples/s | 83.6 steps/s
[Step=54500 Epoch=106.3] | Loss=0.00529 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.222 | L2-Norm(final)=9.323 | 6800.8 samples/s | 106.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=106.3] | Loss=0.01050 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.218 | L2-Norm(final)=9.382 | 6115.9 samples/s | 95.6 steps/s
[Step=54550 Epoch=106.4] | Loss=0.00485 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.219 | L2-Norm(final)=9.387 | 4336.9 samples/s | 67.8 steps/s
[Step=54600 Epoch=106.5] | Loss=0.00623 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.224 | L2-Norm(final)=9.392 | 4551.3 samples/s | 71.1 steps/s
[Step=54650 Epoch=106.6] | Loss=0.00673 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.230 | L2-Norm(final)=9.397 | 4620.4 samples/s | 72.2 steps/s
[Step=54700 Epoch=106.7] | Loss=0.00676 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.235 | L2-Norm(final)=9.403 | 4618.3 samples/s | 72.2 steps/s
[Step=54750 Epoch=106.8] | Loss=0.00739 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=9.408 | 4676.0 samples/s | 73.1 steps/s
[Step=54800 Epoch=106.9] | Loss=0.00792 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.244 | L2-Norm(final)=9.413 | 4547.5 samples/s | 71.1 steps/s
[Step=54850 Epoch=107.0] | Loss=0.00782 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.248 | L2-Norm(final)=9.419 | 4672.2 samples/s | 73.0 steps/s
[Step=54900 Epoch=107.1] | Loss=0.00848 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.253 | L2-Norm(final)=9.424 | 4604.5 samples/s | 71.9 steps/s
[Step=54950 Epoch=107.2] | Loss=0.00842 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.257 | L2-Norm(final)=9.429 | 4647.3 samples/s | 72.6 steps/s
[Step=55000 Epoch=107.3] | Loss=0.00843 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.261 | L2-Norm(final)=9.434 | 5865.8 samples/s | 91.7 steps/s
[Step=55050 Epoch=107.4] | Loss=0.00849 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.265 | L2-Norm(final)=9.438 | 2444.1 samples/s | 38.2 steps/s
[Step=55100 Epoch=107.5] | Loss=0.00828 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.269 | L2-Norm(final)=9.443 | 4596.6 samples/s | 71.8 steps/s
[Step=55150 Epoch=107.6] | Loss=0.00824 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.272 | L2-Norm(final)=9.447 | 4639.4 samples/s | 72.5 steps/s
[Step=55200 Epoch=107.7] | Loss=0.00817 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=9.451 | 4613.2 samples/s | 72.1 steps/s
[Step=55250 Epoch=107.8] | Loss=0.00821 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.277 | L2-Norm(final)=9.455 | 4596.7 samples/s | 71.8 steps/s
[Step=55300 Epoch=107.9] | Loss=0.00821 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.280 | L2-Norm(final)=9.459 | 4669.8 samples/s | 73.0 steps/s
[Step=55350 Epoch=108.0] | Loss=0.00812 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.282 | L2-Norm(final)=9.463 | 4701.5 samples/s | 73.5 steps/s
[Step=55400 Epoch=108.1] | Loss=0.00805 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.285 | L2-Norm(final)=9.467 | 4556.4 samples/s | 71.2 steps/s
[Step=55450 Epoch=108.1] | Loss=0.00802 | Reg=0.00265 | acc=0.9688 | L2-Norm=16.287 | L2-Norm(final)=9.471 | 4558.7 samples/s | 71.2 steps/s
[Step=55500 Epoch=108.2] | Loss=0.00795 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.289 | L2-Norm(final)=9.474 | 4978.0 samples/s | 77.8 steps/s
[Step=55550 Epoch=108.3] | Loss=0.00777 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.290 | L2-Norm(final)=9.478 | 2680.5 samples/s | 41.9 steps/s
[Step=55600 Epoch=108.4] | Loss=0.00766 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.292 | L2-Norm(final)=9.481 | 4578.4 samples/s | 71.5 steps/s
[Step=55650 Epoch=108.5] | Loss=0.00751 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.293 | L2-Norm(final)=9.485 | 4657.5 samples/s | 72.8 steps/s
[Step=55700 Epoch=108.6] | Loss=0.00746 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.294 | L2-Norm(final)=9.488 | 4626.1 samples/s | 72.3 steps/s
[Step=55750 Epoch=108.7] | Loss=0.00742 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.295 | L2-Norm(final)=9.492 | 4614.1 samples/s | 72.1 steps/s
[Step=55800 Epoch=108.8] | Loss=0.00736 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.296 | L2-Norm(final)=9.495 | 4616.5 samples/s | 72.1 steps/s
[Step=55850 Epoch=108.9] | Loss=0.00735 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.296 | L2-Norm(final)=9.498 | 4639.3 samples/s | 72.5 steps/s
[Step=55900 Epoch=109.0] | Loss=0.00734 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.297 | L2-Norm(final)=9.501 | 4686.7 samples/s | 73.2 steps/s
[Step=55950 Epoch=109.1] | Loss=0.00724 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.298 | L2-Norm(final)=9.504 | 4564.1 samples/s | 71.3 steps/s
[Step=56000 Epoch=109.2] | Loss=0.00720 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.298 | L2-Norm(final)=9.507 | 4687.8 samples/s | 73.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step56000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=105.6] | Loss=0.01417 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.665 | L2-Norm(final)=9.796 | 5575.1 samples/s | 87.1 steps/s
[Step=54050 Epoch=105.7] | Loss=0.00402 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.662 | L2-Norm(final)=9.801 | 5145.3 samples/s | 80.4 steps/s
[Step=54100 Epoch=105.8] | Loss=0.00467 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.661 | L2-Norm(final)=9.808 | 5262.0 samples/s | 82.2 steps/s
[Step=54150 Epoch=105.9] | Loss=0.00454 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.660 | L2-Norm(final)=9.815 | 5258.4 samples/s | 82.2 steps/s
[Step=54200 Epoch=106.0] | Loss=0.00480 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.660 | L2-Norm(final)=9.821 | 5135.9 samples/s | 80.2 steps/s
[Step=54250 Epoch=106.1] | Loss=0.00481 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.659 | L2-Norm(final)=9.827 | 5276.7 samples/s | 82.4 steps/s
[Step=54300 Epoch=106.2] | Loss=0.00473 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.658 | L2-Norm(final)=9.834 | 5136.3 samples/s | 80.3 steps/s
[Step=54350 Epoch=106.3] | Loss=0.00486 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.658 | L2-Norm(final)=9.840 | 5131.1 samples/s | 80.2 steps/s
[Step=54400 Epoch=106.4] | Loss=0.00494 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.657 | L2-Norm(final)=9.846 | 5213.7 samples/s | 81.5 steps/s
[Step=54450 Epoch=106.4] | Loss=0.00495 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.656 | L2-Norm(final)=9.852 | 5295.9 samples/s | 82.7 steps/s
[Step=54500 Epoch=106.5] | Loss=0.00490 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.655 | L2-Norm(final)=9.857 | 7019.5 samples/s | 109.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=106.5] | Loss=0.00980 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.648 | L2-Norm(final)=9.915 | 6806.8 samples/s | 106.4 steps/s
[Step=54550 Epoch=106.6] | Loss=0.00589 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.649 | L2-Norm(final)=9.921 | 4028.4 samples/s | 62.9 steps/s
[Step=54600 Epoch=106.7] | Loss=0.00718 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.652 | L2-Norm(final)=9.924 | 4577.5 samples/s | 71.5 steps/s
[Step=54650 Epoch=106.8] | Loss=0.00769 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.656 | L2-Norm(final)=9.928 | 4646.0 samples/s | 72.6 steps/s
[Step=54700 Epoch=106.9] | Loss=0.00847 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.662 | L2-Norm(final)=9.932 | 4676.7 samples/s | 73.1 steps/s
[Step=54750 Epoch=107.0] | Loss=0.00884 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.668 | L2-Norm(final)=9.936 | 4531.4 samples/s | 70.8 steps/s
[Step=54800 Epoch=107.1] | Loss=0.00930 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.675 | L2-Norm(final)=9.941 | 4631.2 samples/s | 72.4 steps/s
[Step=54850 Epoch=107.2] | Loss=0.00943 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.681 | L2-Norm(final)=9.946 | 4632.5 samples/s | 72.4 steps/s
[Step=54900 Epoch=107.3] | Loss=0.00972 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.687 | L2-Norm(final)=9.950 | 4583.2 samples/s | 71.6 steps/s
[Step=54950 Epoch=107.4] | Loss=0.00966 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.692 | L2-Norm(final)=9.954 | 4663.2 samples/s | 72.9 steps/s
[Step=55000 Epoch=107.5] | Loss=0.00955 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.697 | L2-Norm(final)=9.958 | 6040.3 samples/s | 94.4 steps/s
[Step=55050 Epoch=107.6] | Loss=0.00931 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.701 | L2-Norm(final)=9.962 | 2413.2 samples/s | 37.7 steps/s
[Step=55100 Epoch=107.7] | Loss=0.00904 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.705 | L2-Norm(final)=9.966 | 4618.8 samples/s | 72.2 steps/s
[Step=55150 Epoch=107.8] | Loss=0.00887 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.708 | L2-Norm(final)=9.970 | 4583.2 samples/s | 71.6 steps/s
[Step=55200 Epoch=107.9] | Loss=0.00871 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.711 | L2-Norm(final)=9.974 | 4659.8 samples/s | 72.8 steps/s
[Step=55250 Epoch=108.0] | Loss=0.00862 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.713 | L2-Norm(final)=9.978 | 4607.7 samples/s | 72.0 steps/s
[Step=55300 Epoch=108.1] | Loss=0.00859 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.715 | L2-Norm(final)=9.981 | 4701.4 samples/s | 73.5 steps/s
[Step=55350 Epoch=108.2] | Loss=0.00852 | Reg=0.00279 | acc=0.9844 | L2-Norm=16.717 | L2-Norm(final)=9.985 | 4541.9 samples/s | 71.0 steps/s
[Step=55400 Epoch=108.3] | Loss=0.00846 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.719 | L2-Norm(final)=9.988 | 4614.5 samples/s | 72.1 steps/s
[Step=55450 Epoch=108.4] | Loss=0.00839 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.721 | L2-Norm(final)=9.991 | 4653.1 samples/s | 72.7 steps/s
[Step=55500 Epoch=108.5] | Loss=0.00835 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.722 | L2-Norm(final)=9.995 | 5082.2 samples/s | 79.4 steps/s
[Step=55550 Epoch=108.6] | Loss=0.00818 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.723 | L2-Norm(final)=9.998 | 2628.4 samples/s | 41.1 steps/s
[Step=55600 Epoch=108.7] | Loss=0.00800 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.724 | L2-Norm(final)=10.001 | 4567.6 samples/s | 71.4 steps/s
[Step=55650 Epoch=108.8] | Loss=0.00788 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.725 | L2-Norm(final)=10.005 | 4635.1 samples/s | 72.4 steps/s
[Step=55700 Epoch=108.9] | Loss=0.00785 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.726 | L2-Norm(final)=10.008 | 4650.9 samples/s | 72.7 steps/s
[Step=55750 Epoch=109.0] | Loss=0.00773 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.727 | L2-Norm(final)=10.011 | 4662.8 samples/s | 72.9 steps/s
[Step=55800 Epoch=109.1] | Loss=0.00770 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.727 | L2-Norm(final)=10.014 | 4544.8 samples/s | 71.0 steps/s
[Step=55850 Epoch=109.2] | Loss=0.00762 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.728 | L2-Norm(final)=10.017 | 4649.4 samples/s | 72.6 steps/s
[Step=55900 Epoch=109.3] | Loss=0.00750 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.728 | L2-Norm(final)=10.021 | 4639.0 samples/s | 72.5 steps/s
[Step=55950 Epoch=109.4] | Loss=0.00743 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.729 | L2-Norm(final)=10.024 | 4640.3 samples/s | 72.5 steps/s
[Step=56000 Epoch=109.5] | Loss=0.00739 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.729 | L2-Norm(final)=10.027 | 4646.4 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step56000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=206.9] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.506 | L2-Norm(final)=7.296 | 5990.7 samples/s | 93.6 steps/s
[Step=54050 Epoch=207.1] | Loss=0.00008 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.515 | L2-Norm(final)=7.320 | 4350.3 samples/s | 68.0 steps/s
[Step=54100 Epoch=207.3] | Loss=0.00040 | Reg=0.00091 | acc=0.9688 | L2-Norm=9.535 | L2-Norm(final)=7.348 | 4985.6 samples/s | 77.9 steps/s
[Step=54150 Epoch=207.5] | Loss=0.00039 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.561 | L2-Norm(final)=7.360 | 4755.9 samples/s | 74.3 steps/s
[Step=54200 Epoch=207.7] | Loss=0.00031 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.581 | L2-Norm(final)=7.369 | 4941.0 samples/s | 77.2 steps/s
[Step=54250 Epoch=207.9] | Loss=0.00025 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.592 | L2-Norm(final)=7.374 | 6750.1 samples/s | 105.5 steps/s
[Step=54300 Epoch=208.1] | Loss=0.00021 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.598 | L2-Norm(final)=7.378 | 1891.2 samples/s | 29.5 steps/s
[Step=54350 Epoch=208.3] | Loss=0.00018 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.602 | L2-Norm(final)=7.382 | 4783.6 samples/s | 74.7 steps/s
[Step=54400 Epoch=208.4] | Loss=0.00016 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.605 | L2-Norm(final)=7.385 | 4980.6 samples/s | 77.8 steps/s
[Step=54450 Epoch=208.6] | Loss=0.00015 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.606 | L2-Norm(final)=7.387 | 4815.6 samples/s | 75.2 steps/s
[Step=54500 Epoch=208.8] | Loss=0.00013 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.607 | L2-Norm(final)=7.389 | 5681.1 samples/s | 88.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=208.8] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.615 | L2-Norm(final)=7.408 | 6719.5 samples/s | 105.0 steps/s
[Step=54550 Epoch=209.0] | Loss=0.00200 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.638 | L2-Norm(final)=7.409 | 3770.9 samples/s | 58.9 steps/s
[Step=54600 Epoch=209.2] | Loss=0.00312 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=7.398 | 4369.1 samples/s | 68.3 steps/s
[Step=54650 Epoch=209.4] | Loss=0.00277 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.716 | L2-Norm(final)=7.385 | 4408.6 samples/s | 68.9 steps/s
[Step=54700 Epoch=209.6] | Loss=0.00243 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.734 | L2-Norm(final)=7.378 | 4417.4 samples/s | 69.0 steps/s
[Step=54750 Epoch=209.8] | Loss=0.00199 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.746 | L2-Norm(final)=7.374 | 5826.4 samples/s | 91.0 steps/s
[Step=54800 Epoch=210.0] | Loss=0.00167 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.754 | L2-Norm(final)=7.372 | 2360.4 samples/s | 36.9 steps/s
[Step=54850 Epoch=210.2] | Loss=0.00144 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.759 | L2-Norm(final)=7.370 | 4294.5 samples/s | 67.1 steps/s
[Step=54900 Epoch=210.4] | Loss=0.00126 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.762 | L2-Norm(final)=7.370 | 4373.1 samples/s | 68.3 steps/s
[Step=54950 Epoch=210.5] | Loss=0.00113 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.764 | L2-Norm(final)=7.370 | 4435.7 samples/s | 69.3 steps/s
[Step=55000 Epoch=210.7] | Loss=0.00105 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.766 | L2-Norm(final)=7.370 | 4953.0 samples/s | 77.4 steps/s
[Step=55050 Epoch=210.9] | Loss=0.00096 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.768 | L2-Norm(final)=7.370 | 2502.2 samples/s | 39.1 steps/s
[Step=55100 Epoch=211.1] | Loss=0.00088 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=7.371 | 4356.7 samples/s | 68.1 steps/s
[Step=55150 Epoch=211.3] | Loss=0.00081 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.770 | L2-Norm(final)=7.371 | 4359.4 samples/s | 68.1 steps/s
[Step=55200 Epoch=211.5] | Loss=0.00076 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.770 | L2-Norm(final)=7.372 | 4410.3 samples/s | 68.9 steps/s
[Step=55250 Epoch=211.7] | Loss=0.00071 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.770 | L2-Norm(final)=7.373 | 4520.6 samples/s | 70.6 steps/s
[Step=55300 Epoch=211.9] | Loss=0.00066 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=7.373 | 2604.5 samples/s | 40.7 steps/s
[Step=55350 Epoch=212.1] | Loss=0.00062 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.769 | L2-Norm(final)=7.374 | 4386.0 samples/s | 68.5 steps/s
[Step=55400 Epoch=212.3] | Loss=0.00059 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.768 | L2-Norm(final)=7.374 | 4377.4 samples/s | 68.4 steps/s
[Step=55450 Epoch=212.5] | Loss=0.00056 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.767 | L2-Norm(final)=7.375 | 4367.2 samples/s | 68.2 steps/s
[Step=55500 Epoch=212.7] | Loss=0.00053 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.766 | L2-Norm(final)=7.375 | 4376.3 samples/s | 68.4 steps/s
[Step=55550 Epoch=212.8] | Loss=0.00051 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.765 | L2-Norm(final)=7.376 | 2683.2 samples/s | 41.9 steps/s
[Step=55600 Epoch=213.0] | Loss=0.00048 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.764 | L2-Norm(final)=7.377 | 4398.4 samples/s | 68.7 steps/s
[Step=55650 Epoch=213.2] | Loss=0.00046 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.763 | L2-Norm(final)=7.377 | 4376.2 samples/s | 68.4 steps/s
[Step=55700 Epoch=213.4] | Loss=0.00044 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=7.378 | 4513.5 samples/s | 70.5 steps/s
[Step=55750 Epoch=213.6] | Loss=0.00043 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.760 | L2-Norm(final)=7.379 | 4266.2 samples/s | 66.7 steps/s
[Step=55800 Epoch=213.8] | Loss=0.00041 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.759 | L2-Norm(final)=7.379 | 6543.3 samples/s | 102.2 steps/s
[Step=55850 Epoch=214.0] | Loss=0.00040 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.757 | L2-Norm(final)=7.380 | 2240.6 samples/s | 35.0 steps/s
[Step=55900 Epoch=214.2] | Loss=0.00038 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.755 | L2-Norm(final)=7.381 | 4458.5 samples/s | 69.7 steps/s
[Step=55950 Epoch=214.4] | Loss=0.00037 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.754 | L2-Norm(final)=7.382 | 4304.4 samples/s | 67.3 steps/s
[Step=56000 Epoch=214.6] | Loss=0.00036 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.752 | L2-Norm(final)=7.382 | 4399.7 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step56000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=207.9] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.542 | L2-Norm(final)=7.357 | 5890.5 samples/s | 92.0 steps/s
[Step=54050 Epoch=208.1] | Loss=0.00010 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.557 | L2-Norm(final)=7.367 | 4710.1 samples/s | 73.6 steps/s
[Step=54100 Epoch=208.3] | Loss=0.00030 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.587 | L2-Norm(final)=7.377 | 4623.0 samples/s | 72.2 steps/s
[Step=54150 Epoch=208.4] | Loss=0.00056 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.624 | L2-Norm(final)=7.385 | 4945.1 samples/s | 77.3 steps/s
[Step=54200 Epoch=208.6] | Loss=0.00043 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.651 | L2-Norm(final)=7.390 | 4836.2 samples/s | 75.6 steps/s
[Step=54250 Epoch=208.8] | Loss=0.00036 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.666 | L2-Norm(final)=7.393 | 7003.4 samples/s | 109.4 steps/s
[Step=54300 Epoch=209.0] | Loss=0.00031 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.677 | L2-Norm(final)=7.397 | 2473.7 samples/s | 38.7 steps/s
[Step=54350 Epoch=209.2] | Loss=0.00027 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=7.400 | 4788.2 samples/s | 74.8 steps/s
[Step=54400 Epoch=209.4] | Loss=0.00023 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.688 | L2-Norm(final)=7.403 | 4886.4 samples/s | 76.3 steps/s
[Step=54450 Epoch=209.6] | Loss=0.00021 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.691 | L2-Norm(final)=7.405 | 4887.8 samples/s | 76.4 steps/s
[Step=54500 Epoch=209.8] | Loss=0.00019 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.693 | L2-Norm(final)=7.408 | 5796.9 samples/s | 90.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=209.8] | Loss=0.00003 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.708 | L2-Norm(final)=7.429 | 6332.0 samples/s | 98.9 steps/s
[Step=54550 Epoch=210.0] | Loss=0.00002 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.700 | L2-Norm(final)=7.430 | 3862.0 samples/s | 60.3 steps/s
[Step=54600 Epoch=210.2] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.687 | L2-Norm(final)=7.432 | 4338.3 samples/s | 67.8 steps/s
[Step=54650 Epoch=210.4] | Loss=0.00001 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.672 | L2-Norm(final)=7.433 | 4389.5 samples/s | 68.6 steps/s
[Step=54700 Epoch=210.6] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.656 | L2-Norm(final)=7.434 | 4353.9 samples/s | 68.0 steps/s
[Step=54750 Epoch=210.8] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.640 | L2-Norm(final)=7.434 | 5990.0 samples/s | 93.6 steps/s
[Step=54800 Epoch=210.9] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.623 | L2-Norm(final)=7.435 | 2329.2 samples/s | 36.4 steps/s
[Step=54850 Epoch=211.1] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.605 | L2-Norm(final)=7.436 | 4387.5 samples/s | 68.6 steps/s
[Step=54900 Epoch=211.3] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.588 | L2-Norm(final)=7.436 | 4370.0 samples/s | 68.3 steps/s
[Step=54950 Epoch=211.5] | Loss=0.00001 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.570 | L2-Norm(final)=7.437 | 4400.7 samples/s | 68.8 steps/s
[Step=55000 Epoch=211.7] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.553 | L2-Norm(final)=7.438 | 5133.8 samples/s | 80.2 steps/s
[Step=55050 Epoch=211.9] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.535 | L2-Norm(final)=7.438 | 2517.1 samples/s | 39.3 steps/s
[Step=55100 Epoch=212.1] | Loss=0.00001 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.517 | L2-Norm(final)=7.439 | 4315.4 samples/s | 67.4 steps/s
[Step=55150 Epoch=212.3] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.499 | L2-Norm(final)=7.439 | 4348.6 samples/s | 67.9 steps/s
[Step=55200 Epoch=212.5] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.480 | L2-Norm(final)=7.440 | 4435.1 samples/s | 69.3 steps/s
[Step=55250 Epoch=212.7] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.462 | L2-Norm(final)=7.440 | 4442.6 samples/s | 69.4 steps/s
[Step=55300 Epoch=212.9] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.443 | L2-Norm(final)=7.440 | 2678.9 samples/s | 41.9 steps/s
[Step=55350 Epoch=213.1] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.425 | L2-Norm(final)=7.441 | 4340.6 samples/s | 67.8 steps/s
[Step=55400 Epoch=213.3] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.406 | L2-Norm(final)=7.441 | 4472.0 samples/s | 69.9 steps/s
[Step=55450 Epoch=213.4] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=7.442 | 4391.7 samples/s | 68.6 steps/s
[Step=55500 Epoch=213.6] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.367 | L2-Norm(final)=7.443 | 4460.4 samples/s | 69.7 steps/s
[Step=55550 Epoch=213.8] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.348 | L2-Norm(final)=7.443 | 2631.8 samples/s | 41.1 steps/s
[Step=55600 Epoch=214.0] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.329 | L2-Norm(final)=7.444 | 4386.9 samples/s | 68.5 steps/s
[Step=55650 Epoch=214.2] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.309 | L2-Norm(final)=7.444 | 4362.2 samples/s | 68.2 steps/s
[Step=55700 Epoch=214.4] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.289 | L2-Norm(final)=7.445 | 4479.9 samples/s | 70.0 steps/s
[Step=55750 Epoch=214.6] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.270 | L2-Norm(final)=7.445 | 4326.2 samples/s | 67.6 steps/s
[Step=55800 Epoch=214.8] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.249 | L2-Norm(final)=7.446 | 7087.5 samples/s | 110.7 steps/s
[Step=55850 Epoch=215.0] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.229 | L2-Norm(final)=7.447 | 2174.1 samples/s | 34.0 steps/s
[Step=55900 Epoch=215.2] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.209 | L2-Norm(final)=7.447 | 4400.0 samples/s | 68.7 steps/s
[Step=55950 Epoch=215.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.188 | L2-Norm(final)=7.448 | 4510.8 samples/s | 70.5 steps/s
[Step=56000 Epoch=215.6] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.168 | L2-Norm(final)=7.449 | 4410.1 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08881 | acc=0.9666 | tpr=0.9792 | fpr=0.0607 | 5414.8 samples/s | 21.2 steps/s
Avg test loss: 0.08911, Avg test acc: 0.96650, Avg tpr: 0.97913, Avg fpr: 0.06127, total FA: 478

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08527 | acc=0.9677 | tpr=0.9793 | fpr=0.0577 | 5547.3 samples/s | 21.7 steps/s
Avg test loss: 0.08786, Avg test acc: 0.96722, Avg tpr: 0.97878, Avg fpr: 0.05820, total FA: 454

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.25598 | acc=0.3104 | tpr=0.0075 | fpr=0.0320 | 5356.0 samples/s | 20.9 steps/s
Avg test loss: 5.26875, Avg test acc: 0.30824, Avg tpr: 0.00729, Avg fpr: 0.02987, total FA: 233

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.26322 | acc=0.3052 | tpr=0.0094 | fpr=0.0525 | 5350.8 samples/s | 20.9 steps/s
Avg test loss: 5.27187, Avg test acc: 0.30403, Avg tpr: 0.00892, Avg fpr: 0.04692, total FA: 366

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.58347 | acc=0.1158 | tpr=0.7699 | fpr=0.8960 | 5272.5 samples/s | 20.6 steps/s
[Step= 100] | Loss=6.55968 | acc=0.1159 | tpr=0.7484 | fpr=0.8959 | 7800.0 samples/s | 30.5 steps/s
[Step= 150] | Loss=6.55422 | acc=0.1167 | tpr=0.7550 | fpr=0.8950 | 7541.9 samples/s | 29.5 steps/s
[Step= 200] | Loss=6.56582 | acc=0.1153 | tpr=0.7530 | fpr=0.8964 | 7949.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=6.57477 | acc=0.1152 | tpr=0.7459 | fpr=0.8963 | 7929.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=6.57175 | acc=0.1148 | tpr=0.7440 | fpr=0.8967 | 7965.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.56221 | acc=0.1150 | tpr=0.7464 | fpr=0.8965 | 8348.7 samples/s | 32.6 steps/s
[Step= 400] | Loss=6.55673 | acc=0.1156 | tpr=0.7473 | fpr=0.8959 | 8279.4 samples/s | 32.3 steps/s
[Step= 450] | Loss=6.55668 | acc=0.1152 | tpr=0.7493 | fpr=0.8963 | 8043.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.55612 | acc=0.1150 | tpr=0.7471 | fpr=0.8964 | 7979.4 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.55682 | acc=0.1152 | tpr=0.7425 | fpr=0.8962 | 14520.9 samples/s | 56.7 steps/s
Avg test loss: 6.55749, Avg test acc: 0.11517, Avg tpr: 0.74247, Avg fpr: 0.89623, total FA: 124440

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.57195 | acc=0.1180 | tpr=0.7611 | fpr=0.8935 | 5314.0 samples/s | 20.8 steps/s
[Step= 100] | Loss=7.54483 | acc=0.1173 | tpr=0.7505 | fpr=0.8946 | 7404.2 samples/s | 28.9 steps/s
[Step= 150] | Loss=7.53957 | acc=0.1177 | tpr=0.7579 | fpr=0.8941 | 7840.2 samples/s | 30.6 steps/s
[Step= 200] | Loss=7.55413 | acc=0.1164 | tpr=0.7628 | fpr=0.8954 | 7830.8 samples/s | 30.6 steps/s
[Step= 250] | Loss=7.56032 | acc=0.1166 | tpr=0.7590 | fpr=0.8951 | 8341.3 samples/s | 32.6 steps/s
[Step= 300] | Loss=7.56209 | acc=0.1162 | tpr=0.7622 | fpr=0.8956 | 7809.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=7.54945 | acc=0.1163 | tpr=0.7602 | fpr=0.8954 | 8266.0 samples/s | 32.3 steps/s
[Step= 400] | Loss=7.54152 | acc=0.1167 | tpr=0.7620 | fpr=0.8950 | 7717.3 samples/s | 30.1 steps/s
[Step= 450] | Loss=7.53708 | acc=0.1161 | tpr=0.7595 | fpr=0.8956 | 8319.2 samples/s | 32.5 steps/s
[Step= 500] | Loss=7.54072 | acc=0.1159 | tpr=0.7555 | fpr=0.8956 | 8028.2 samples/s | 31.4 steps/s
[Step= 550] | Loss=7.53673 | acc=0.1161 | tpr=0.7513 | fpr=0.8954 | 14880.3 samples/s | 58.1 steps/s
Avg test loss: 7.53796, Avg test acc: 0.11608, Avg tpr: 0.75119, Avg fpr: 0.89547, total FA: 124334

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11730 | acc=0.9788 | tpr=0.9381 | fpr=0.0204 | 5118.6 samples/s | 20.0 steps/s
[Step= 100] | Loss=0.12258 | acc=0.9776 | tpr=0.9467 | fpr=0.0218 | 7533.5 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.12899 | acc=0.9766 | tpr=0.9510 | fpr=0.0229 | 7797.2 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.13072 | acc=0.9765 | tpr=0.9508 | fpr=0.0230 | 8101.6 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.12862 | acc=0.9769 | tpr=0.9493 | fpr=0.0226 | 8117.1 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.13054 | acc=0.9766 | tpr=0.9462 | fpr=0.0229 | 8384.4 samples/s | 32.8 steps/s
[Step= 350] | Loss=0.13138 | acc=0.9764 | tpr=0.9487 | fpr=0.0231 | 8104.1 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.13307 | acc=0.9762 | tpr=0.9447 | fpr=0.0233 | 8063.8 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.13597 | acc=0.9758 | tpr=0.9460 | fpr=0.0236 | 8202.3 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.13558 | acc=0.9758 | tpr=0.9467 | fpr=0.0237 | 7694.4 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.13431 | acc=0.9761 | tpr=0.9463 | fpr=0.0234 | 15457.8 samples/s | 60.4 steps/s
Avg test loss: 0.13396, Avg test acc: 0.97610, Avg tpr: 0.94572, Avg fpr: 0.02335, total FA: 3242

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14943 | acc=0.9769 | tpr=0.9602 | fpr=0.0228 | 5412.0 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.15649 | acc=0.9757 | tpr=0.9616 | fpr=0.0240 | 7221.0 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.16153 | acc=0.9749 | tpr=0.9625 | fpr=0.0248 | 7584.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.16464 | acc=0.9749 | tpr=0.9650 | fpr=0.0249 | 8078.1 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.16175 | acc=0.9754 | tpr=0.9651 | fpr=0.0244 | 8111.9 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.16452 | acc=0.9750 | tpr=0.9615 | fpr=0.0247 | 8134.7 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.16543 | acc=0.9748 | tpr=0.9624 | fpr=0.0250 | 7999.7 samples/s | 31.2 steps/s
[Step= 400] | Loss=0.16686 | acc=0.9747 | tpr=0.9579 | fpr=0.0250 | 8192.0 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.17018 | acc=0.9742 | tpr=0.9576 | fpr=0.0255 | 8113.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.16948 | acc=0.9742 | tpr=0.9586 | fpr=0.0255 | 8448.3 samples/s | 33.0 steps/s
[Step= 550] | Loss=0.16820 | acc=0.9744 | tpr=0.9578 | fpr=0.0253 | 14064.5 samples/s | 54.9 steps/s
Avg test loss: 0.16777, Avg test acc: 0.97437, Avg tpr: 0.95681, Avg fpr: 0.02531, total FA: 3514

server round 28/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=109.2] | Loss=0.00673 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.056 | L2-Norm(final)=9.601 | 6382.7 samples/s | 99.7 steps/s
[Step=56050 Epoch=109.3] | Loss=0.00656 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.057 | L2-Norm(final)=9.607 | 4662.1 samples/s | 72.8 steps/s
[Step=56100 Epoch=109.4] | Loss=0.00598 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.059 | L2-Norm(final)=9.614 | 5265.6 samples/s | 82.3 steps/s
[Step=56150 Epoch=109.5] | Loss=0.00576 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.060 | L2-Norm(final)=9.622 | 5263.5 samples/s | 82.2 steps/s
[Step=56200 Epoch=109.6] | Loss=0.00589 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.061 | L2-Norm(final)=9.629 | 4930.2 samples/s | 77.0 steps/s
[Step=56250 Epoch=109.7] | Loss=0.00595 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=9.637 | 5218.3 samples/s | 81.5 steps/s
[Step=56300 Epoch=109.8] | Loss=0.00618 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.063 | L2-Norm(final)=9.644 | 5270.2 samples/s | 82.3 steps/s
[Step=56350 Epoch=109.9] | Loss=0.00617 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.065 | L2-Norm(final)=9.652 | 5134.6 samples/s | 80.2 steps/s
[Step=56400 Epoch=110.0] | Loss=0.00610 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.067 | L2-Norm(final)=9.659 | 5200.5 samples/s | 81.3 steps/s
[Step=56450 Epoch=110.1] | Loss=0.00602 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.068 | L2-Norm(final)=9.667 | 5444.0 samples/s | 85.1 steps/s
[Step=56500 Epoch=110.2] | Loss=0.00619 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.069 | L2-Norm(final)=9.674 | 6676.6 samples/s | 104.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=110.2] | Loss=0.01705 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.080 | L2-Norm(final)=9.747 | 6391.5 samples/s | 99.9 steps/s
[Step=56550 Epoch=110.3] | Loss=0.00534 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.082 | L2-Norm(final)=9.754 | 4240.1 samples/s | 66.3 steps/s
[Step=56600 Epoch=110.4] | Loss=0.00596 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.084 | L2-Norm(final)=9.759 | 4563.0 samples/s | 71.3 steps/s
[Step=56650 Epoch=110.5] | Loss=0.00831 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=9.761 | 4587.7 samples/s | 71.7 steps/s
[Step=56700 Epoch=110.6] | Loss=0.00858 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=9.764 | 4674.1 samples/s | 73.0 steps/s
[Step=56750 Epoch=110.7] | Loss=0.00826 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.101 | L2-Norm(final)=9.769 | 4566.3 samples/s | 71.3 steps/s
[Step=56800 Epoch=110.8] | Loss=0.00825 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.105 | L2-Norm(final)=9.773 | 4645.8 samples/s | 72.6 steps/s
[Step=56850 Epoch=110.9] | Loss=0.00849 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.110 | L2-Norm(final)=9.777 | 4730.1 samples/s | 73.9 steps/s
[Step=56900 Epoch=111.0] | Loss=0.00855 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=9.781 | 4523.1 samples/s | 70.7 steps/s
[Step=56950 Epoch=111.1] | Loss=0.00867 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.118 | L2-Norm(final)=9.785 | 4654.5 samples/s | 72.7 steps/s
[Step=57000 Epoch=111.2] | Loss=0.00871 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.121 | L2-Norm(final)=9.789 | 5992.8 samples/s | 93.6 steps/s
[Step=57050 Epoch=111.3] | Loss=0.00849 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.125 | L2-Norm(final)=9.793 | 2446.6 samples/s | 38.2 steps/s
[Step=57100 Epoch=111.4] | Loss=0.00826 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.128 | L2-Norm(final)=9.797 | 4650.9 samples/s | 72.7 steps/s
[Step=57150 Epoch=111.5] | Loss=0.00803 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=9.801 | 4606.3 samples/s | 72.0 steps/s
[Step=57200 Epoch=111.6] | Loss=0.00804 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.134 | L2-Norm(final)=9.805 | 4707.3 samples/s | 73.6 steps/s
[Step=57250 Epoch=111.7] | Loss=0.00791 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=9.808 | 4532.0 samples/s | 70.8 steps/s
[Step=57300 Epoch=111.8] | Loss=0.00788 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.138 | L2-Norm(final)=9.812 | 4619.2 samples/s | 72.2 steps/s
[Step=57350 Epoch=111.9] | Loss=0.00786 | Reg=0.00260 | acc=0.9531 | L2-Norm=16.140 | L2-Norm(final)=9.815 | 4629.3 samples/s | 72.3 steps/s
[Step=57400 Epoch=112.0] | Loss=0.00772 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=9.819 | 4636.4 samples/s | 72.4 steps/s
[Step=57450 Epoch=112.0] | Loss=0.00783 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=9.822 | 4671.7 samples/s | 73.0 steps/s
[Step=57500 Epoch=112.1] | Loss=0.00779 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=9.825 | 4921.8 samples/s | 76.9 steps/s
[Step=57550 Epoch=112.2] | Loss=0.00763 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=9.829 | 2674.9 samples/s | 41.8 steps/s
[Step=57600 Epoch=112.3] | Loss=0.00744 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.147 | L2-Norm(final)=9.832 | 4582.4 samples/s | 71.6 steps/s
[Step=57650 Epoch=112.4] | Loss=0.00738 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.148 | L2-Norm(final)=9.836 | 4648.2 samples/s | 72.6 steps/s
[Step=57700 Epoch=112.5] | Loss=0.00731 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.149 | L2-Norm(final)=9.839 | 4598.2 samples/s | 71.8 steps/s
[Step=57750 Epoch=112.6] | Loss=0.00727 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.150 | L2-Norm(final)=9.842 | 4592.1 samples/s | 71.8 steps/s
[Step=57800 Epoch=112.7] | Loss=0.00729 | Reg=0.00261 | acc=0.9531 | L2-Norm=16.150 | L2-Norm(final)=9.845 | 4623.8 samples/s | 72.2 steps/s
[Step=57850 Epoch=112.8] | Loss=0.00729 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.151 | L2-Norm(final)=9.848 | 4657.0 samples/s | 72.8 steps/s
[Step=57900 Epoch=112.9] | Loss=0.00725 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.152 | L2-Norm(final)=9.851 | 4612.6 samples/s | 72.1 steps/s
[Step=57950 Epoch=113.0] | Loss=0.00723 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.152 | L2-Norm(final)=9.854 | 4648.8 samples/s | 72.6 steps/s
[Step=58000 Epoch=113.1] | Loss=0.00725 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.153 | L2-Norm(final)=9.858 | 4601.6 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step58000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=109.5] | Loss=0.01564 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.484 | L2-Norm(final)=10.116 | 6212.8 samples/s | 97.1 steps/s
[Step=56050 Epoch=109.6] | Loss=0.00678 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.485 | L2-Norm(final)=10.122 | 4761.2 samples/s | 74.4 steps/s
[Step=56100 Epoch=109.7] | Loss=0.00687 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.487 | L2-Norm(final)=10.131 | 5286.3 samples/s | 82.6 steps/s
[Step=56150 Epoch=109.8] | Loss=0.00671 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.489 | L2-Norm(final)=10.140 | 5078.2 samples/s | 79.3 steps/s
[Step=56200 Epoch=109.9] | Loss=0.00710 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.492 | L2-Norm(final)=10.148 | 5213.7 samples/s | 81.5 steps/s
[Step=56250 Epoch=110.0] | Loss=0.00689 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.494 | L2-Norm(final)=10.155 | 5371.2 samples/s | 83.9 steps/s
[Step=56300 Epoch=110.1] | Loss=0.00687 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.496 | L2-Norm(final)=10.163 | 5117.5 samples/s | 80.0 steps/s
[Step=56350 Epoch=110.2] | Loss=0.00663 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.498 | L2-Norm(final)=10.170 | 5393.5 samples/s | 84.3 steps/s
[Step=56400 Epoch=110.3] | Loss=0.00663 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.500 | L2-Norm(final)=10.177 | 5017.6 samples/s | 78.4 steps/s
[Step=56450 Epoch=110.4] | Loss=0.00652 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.501 | L2-Norm(final)=10.184 | 5166.1 samples/s | 80.7 steps/s
[Step=56500 Epoch=110.5] | Loss=0.00645 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.502 | L2-Norm(final)=10.192 | 7102.1 samples/s | 111.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=110.5] | Loss=0.00571 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.515 | L2-Norm(final)=10.264 | 6367.5 samples/s | 99.5 steps/s
[Step=56550 Epoch=110.6] | Loss=0.00607 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.518 | L2-Norm(final)=10.271 | 4106.8 samples/s | 64.2 steps/s
[Step=56600 Epoch=110.7] | Loss=0.00653 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.520 | L2-Norm(final)=10.277 | 4613.0 samples/s | 72.1 steps/s
[Step=56650 Epoch=110.7] | Loss=0.00699 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.521 | L2-Norm(final)=10.281 | 4670.0 samples/s | 73.0 steps/s
[Step=56700 Epoch=110.8] | Loss=0.00703 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.524 | L2-Norm(final)=10.285 | 4668.8 samples/s | 72.9 steps/s
[Step=56750 Epoch=110.9] | Loss=0.00769 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.528 | L2-Norm(final)=10.288 | 4524.7 samples/s | 70.7 steps/s
[Step=56800 Epoch=111.0] | Loss=0.00772 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.532 | L2-Norm(final)=10.292 | 4628.5 samples/s | 72.3 steps/s
[Step=56850 Epoch=111.1] | Loss=0.00806 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.537 | L2-Norm(final)=10.296 | 4652.6 samples/s | 72.7 steps/s
[Step=56900 Epoch=111.2] | Loss=0.00786 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.541 | L2-Norm(final)=10.300 | 4649.0 samples/s | 72.6 steps/s
[Step=56950 Epoch=111.3] | Loss=0.00825 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.544 | L2-Norm(final)=10.304 | 4578.7 samples/s | 71.5 steps/s
[Step=57000 Epoch=111.4] | Loss=0.00837 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.548 | L2-Norm(final)=10.308 | 6072.7 samples/s | 94.9 steps/s
[Step=57050 Epoch=111.5] | Loss=0.00849 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.552 | L2-Norm(final)=10.312 | 2451.8 samples/s | 38.3 steps/s
[Step=57100 Epoch=111.6] | Loss=0.00843 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.555 | L2-Norm(final)=10.316 | 4527.0 samples/s | 70.7 steps/s
[Step=57150 Epoch=111.7] | Loss=0.00846 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.558 | L2-Norm(final)=10.319 | 4653.6 samples/s | 72.7 steps/s
[Step=57200 Epoch=111.8] | Loss=0.00833 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.560 | L2-Norm(final)=10.323 | 4585.4 samples/s | 71.6 steps/s
[Step=57250 Epoch=111.9] | Loss=0.00821 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.563 | L2-Norm(final)=10.326 | 4616.2 samples/s | 72.1 steps/s
[Step=57300 Epoch=112.0] | Loss=0.00821 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.565 | L2-Norm(final)=10.330 | 4608.4 samples/s | 72.0 steps/s
[Step=57350 Epoch=112.1] | Loss=0.00819 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.567 | L2-Norm(final)=10.333 | 4669.0 samples/s | 73.0 steps/s
[Step=57400 Epoch=112.2] | Loss=0.00815 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.569 | L2-Norm(final)=10.337 | 4619.4 samples/s | 72.2 steps/s
[Step=57450 Epoch=112.3] | Loss=0.00824 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.570 | L2-Norm(final)=10.340 | 4586.7 samples/s | 71.7 steps/s
[Step=57500 Epoch=112.4] | Loss=0.00819 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.572 | L2-Norm(final)=10.343 | 5114.9 samples/s | 79.9 steps/s
[Step=57550 Epoch=112.5] | Loss=0.00810 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.574 | L2-Norm(final)=10.346 | 2632.6 samples/s | 41.1 steps/s
[Step=57600 Epoch=112.6] | Loss=0.00792 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=10.350 | 4617.5 samples/s | 72.1 steps/s
[Step=57650 Epoch=112.7] | Loss=0.00791 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=10.353 | 4582.1 samples/s | 71.6 steps/s
[Step=57700 Epoch=112.8] | Loss=0.00784 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.577 | L2-Norm(final)=10.356 | 4623.1 samples/s | 72.2 steps/s
[Step=57750 Epoch=112.9] | Loss=0.00774 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=10.360 | 4610.7 samples/s | 72.0 steps/s
[Step=57800 Epoch=113.0] | Loss=0.00764 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=10.363 | 4614.6 samples/s | 72.1 steps/s
[Step=57850 Epoch=113.1] | Loss=0.00761 | Reg=0.00275 | acc=0.9688 | L2-Norm=16.580 | L2-Norm(final)=10.366 | 4599.4 samples/s | 71.9 steps/s
[Step=57900 Epoch=113.2] | Loss=0.00756 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=10.369 | 4728.4 samples/s | 73.9 steps/s
[Step=57950 Epoch=113.3] | Loss=0.00747 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=10.372 | 4505.2 samples/s | 70.4 steps/s
[Step=58000 Epoch=113.4] | Loss=0.00742 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.582 | L2-Norm(final)=10.375 | 4646.2 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step58000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=214.6] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=7.408 | 6706.2 samples/s | 104.8 steps/s
[Step=56050 Epoch=214.8] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.441 | L2-Norm(final)=7.410 | 4158.3 samples/s | 65.0 steps/s
[Step=56100 Epoch=215.0] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.441 | L2-Norm(final)=7.412 | 4888.0 samples/s | 76.4 steps/s
[Step=56150 Epoch=215.1] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=7.413 | 5007.4 samples/s | 78.2 steps/s
[Step=56200 Epoch=215.3] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=7.415 | 4844.5 samples/s | 75.7 steps/s
[Step=56250 Epoch=215.5] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=7.417 | 6822.6 samples/s | 106.6 steps/s
[Step=56300 Epoch=215.7] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.439 | L2-Norm(final)=7.419 | 2491.4 samples/s | 38.9 steps/s
[Step=56350 Epoch=215.9] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.439 | L2-Norm(final)=7.420 | 4813.3 samples/s | 75.2 steps/s
[Step=56400 Epoch=216.1] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=7.422 | 4951.5 samples/s | 77.4 steps/s
[Step=56450 Epoch=216.3] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=7.423 | 4841.3 samples/s | 75.6 steps/s
[Step=56500 Epoch=216.5] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.437 | L2-Norm(final)=7.425 | 5675.0 samples/s | 88.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=216.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.433 | L2-Norm(final)=7.442 | 5959.3 samples/s | 93.1 steps/s
[Step=56550 Epoch=216.7] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.431 | L2-Norm(final)=7.444 | 4119.1 samples/s | 64.4 steps/s
[Step=56600 Epoch=216.9] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=7.446 | 4283.6 samples/s | 66.9 steps/s
[Step=56650 Epoch=217.1] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.426 | L2-Norm(final)=7.448 | 4434.5 samples/s | 69.3 steps/s
[Step=56700 Epoch=217.3] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.423 | L2-Norm(final)=7.449 | 4435.0 samples/s | 69.3 steps/s
[Step=56750 Epoch=217.4] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.420 | L2-Norm(final)=7.451 | 5722.9 samples/s | 89.4 steps/s
[Step=56800 Epoch=217.6] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.417 | L2-Norm(final)=7.452 | 2320.1 samples/s | 36.3 steps/s
[Step=56850 Epoch=217.8] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.414 | L2-Norm(final)=7.454 | 4446.7 samples/s | 69.5 steps/s
[Step=56900 Epoch=218.0] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.411 | L2-Norm(final)=7.455 | 4327.2 samples/s | 67.6 steps/s
[Step=56950 Epoch=218.2] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.408 | L2-Norm(final)=7.457 | 4408.0 samples/s | 68.9 steps/s
[Step=57000 Epoch=218.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.404 | L2-Norm(final)=7.458 | 4958.0 samples/s | 77.5 steps/s
[Step=57050 Epoch=218.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.401 | L2-Norm(final)=7.460 | 2503.5 samples/s | 39.1 steps/s
[Step=57100 Epoch=218.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.398 | L2-Norm(final)=7.461 | 4413.3 samples/s | 69.0 steps/s
[Step=57150 Epoch=219.0] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.394 | L2-Norm(final)=7.462 | 4493.2 samples/s | 70.2 steps/s
[Step=57200 Epoch=219.2] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.391 | L2-Norm(final)=7.464 | 4243.4 samples/s | 66.3 steps/s
[Step=57250 Epoch=219.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=7.465 | 4421.4 samples/s | 69.1 steps/s
[Step=57300 Epoch=219.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.384 | L2-Norm(final)=7.466 | 2682.3 samples/s | 41.9 steps/s
[Step=57350 Epoch=219.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=7.468 | 4344.4 samples/s | 67.9 steps/s
[Step=57400 Epoch=219.9] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.376 | L2-Norm(final)=7.469 | 4352.9 samples/s | 68.0 steps/s
[Step=57450 Epoch=220.1] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.373 | L2-Norm(final)=7.471 | 4390.3 samples/s | 68.6 steps/s
[Step=57500 Epoch=220.3] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.369 | L2-Norm(final)=7.472 | 4367.5 samples/s | 68.2 steps/s
[Step=57550 Epoch=220.5] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.365 | L2-Norm(final)=7.473 | 2699.4 samples/s | 42.2 steps/s
[Step=57600 Epoch=220.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.361 | L2-Norm(final)=7.475 | 4338.9 samples/s | 67.8 steps/s
[Step=57650 Epoch=220.9] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.358 | L2-Norm(final)=7.476 | 4386.1 samples/s | 68.5 steps/s
[Step=57700 Epoch=221.1] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.354 | L2-Norm(final)=7.477 | 4394.9 samples/s | 68.7 steps/s
[Step=57750 Epoch=221.3] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.350 | L2-Norm(final)=7.479 | 4367.8 samples/s | 68.2 steps/s
[Step=57800 Epoch=221.5] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.346 | L2-Norm(final)=7.480 | 6477.2 samples/s | 101.2 steps/s
[Step=57850 Epoch=221.7] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.342 | L2-Norm(final)=7.481 | 2257.9 samples/s | 35.3 steps/s
[Step=57900 Epoch=221.9] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.338 | L2-Norm(final)=7.483 | 4310.9 samples/s | 67.4 steps/s
[Step=57950 Epoch=222.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.333 | L2-Norm(final)=7.484 | 4468.8 samples/s | 69.8 steps/s
[Step=58000 Epoch=222.2] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.329 | L2-Norm(final)=7.485 | 4337.6 samples/s | 67.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step58000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=215.6] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.423 | L2-Norm(final)=7.470 | 6924.4 samples/s | 108.2 steps/s
[Step=56050 Epoch=215.8] | Loss=0.00004 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.424 | L2-Norm(final)=7.477 | 4076.6 samples/s | 63.7 steps/s
[Step=56100 Epoch=216.0] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.426 | L2-Norm(final)=7.484 | 4858.9 samples/s | 75.9 steps/s
[Step=56150 Epoch=216.1] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.428 | L2-Norm(final)=7.490 | 4914.8 samples/s | 76.8 steps/s
[Step=56200 Epoch=216.3] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=7.496 | 4887.1 samples/s | 76.4 steps/s
[Step=56250 Epoch=216.5] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=7.501 | 6947.4 samples/s | 108.6 steps/s
[Step=56300 Epoch=216.7] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=7.506 | 2438.2 samples/s | 38.1 steps/s
[Step=56350 Epoch=216.9] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.429 | L2-Norm(final)=7.511 | 4999.2 samples/s | 78.1 steps/s
[Step=56400 Epoch=217.1] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.428 | L2-Norm(final)=7.516 | 5040.6 samples/s | 78.8 steps/s
[Step=56450 Epoch=217.3] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.428 | L2-Norm(final)=7.520 | 4805.5 samples/s | 75.1 steps/s
[Step=56500 Epoch=217.5] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.427 | L2-Norm(final)=7.525 | 5749.8 samples/s | 89.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=217.5] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.424 | L2-Norm(final)=7.573 | 6211.4 samples/s | 97.1 steps/s
[Step=56550 Epoch=217.7] | Loss=0.00002 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.400 | L2-Norm(final)=7.577 | 3936.3 samples/s | 61.5 steps/s
[Step=56600 Epoch=217.9] | Loss=0.00339 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.569 | 4383.3 samples/s | 68.5 steps/s
[Step=56650 Epoch=218.1] | Loss=0.00316 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.455 | L2-Norm(final)=7.558 | 4448.7 samples/s | 69.5 steps/s
[Step=56700 Epoch=218.3] | Loss=0.00247 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.484 | L2-Norm(final)=7.555 | 4308.5 samples/s | 67.3 steps/s
[Step=56750 Epoch=218.5] | Loss=0.00202 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.500 | L2-Norm(final)=7.554 | 5949.1 samples/s | 93.0 steps/s
[Step=56800 Epoch=218.6] | Loss=0.00169 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.511 | L2-Norm(final)=7.555 | 2323.4 samples/s | 36.3 steps/s
[Step=56850 Epoch=218.8] | Loss=0.00145 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.518 | L2-Norm(final)=7.555 | 4490.8 samples/s | 70.2 steps/s
[Step=56900 Epoch=219.0] | Loss=0.00128 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.523 | L2-Norm(final)=7.556 | 4287.0 samples/s | 67.0 steps/s
[Step=56950 Epoch=219.2] | Loss=0.00114 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.526 | L2-Norm(final)=7.557 | 4385.4 samples/s | 68.5 steps/s
[Step=57000 Epoch=219.4] | Loss=0.00103 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.529 | L2-Norm(final)=7.558 | 5132.8 samples/s | 80.2 steps/s
[Step=57050 Epoch=219.6] | Loss=0.00094 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.530 | L2-Norm(final)=7.559 | 2481.9 samples/s | 38.8 steps/s
[Step=57100 Epoch=219.8] | Loss=0.00086 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.531 | L2-Norm(final)=7.560 | 4345.4 samples/s | 67.9 steps/s
[Step=57150 Epoch=220.0] | Loss=0.00079 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.532 | L2-Norm(final)=7.561 | 4408.7 samples/s | 68.9 steps/s
[Step=57200 Epoch=220.2] | Loss=0.00074 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.532 | L2-Norm(final)=7.562 | 4512.9 samples/s | 70.5 steps/s
[Step=57250 Epoch=220.4] | Loss=0.00069 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.531 | L2-Norm(final)=7.563 | 4350.2 samples/s | 68.0 steps/s
[Step=57300 Epoch=220.6] | Loss=0.00065 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.530 | L2-Norm(final)=7.564 | 2660.5 samples/s | 41.6 steps/s
[Step=57350 Epoch=220.8] | Loss=0.00061 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.530 | L2-Norm(final)=7.565 | 4367.9 samples/s | 68.2 steps/s
[Step=57400 Epoch=221.0] | Loss=0.00058 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.528 | L2-Norm(final)=7.566 | 4367.8 samples/s | 68.2 steps/s
[Step=57450 Epoch=221.1] | Loss=0.00055 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.527 | L2-Norm(final)=7.566 | 4385.5 samples/s | 68.5 steps/s
[Step=57500 Epoch=221.3] | Loss=0.00052 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.526 | L2-Norm(final)=7.567 | 4507.8 samples/s | 70.4 steps/s
[Step=57550 Epoch=221.5] | Loss=0.00050 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.524 | L2-Norm(final)=7.568 | 2655.2 samples/s | 41.5 steps/s
[Step=57600 Epoch=221.7] | Loss=0.00047 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.523 | L2-Norm(final)=7.569 | 4374.2 samples/s | 68.3 steps/s
[Step=57650 Epoch=221.9] | Loss=0.00045 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.521 | L2-Norm(final)=7.570 | 4425.7 samples/s | 69.2 steps/s
[Step=57700 Epoch=222.1] | Loss=0.00043 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.519 | L2-Norm(final)=7.571 | 4386.0 samples/s | 68.5 steps/s
[Step=57750 Epoch=222.3] | Loss=0.00042 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.517 | L2-Norm(final)=7.571 | 4343.2 samples/s | 67.9 steps/s
[Step=57800 Epoch=222.5] | Loss=0.00040 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.515 | L2-Norm(final)=7.572 | 7192.0 samples/s | 112.4 steps/s
[Step=57850 Epoch=222.7] | Loss=0.00039 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.513 | L2-Norm(final)=7.573 | 2173.3 samples/s | 34.0 steps/s
[Step=57900 Epoch=222.9] | Loss=0.00037 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.511 | L2-Norm(final)=7.574 | 4381.8 samples/s | 68.5 steps/s
[Step=57950 Epoch=223.1] | Loss=0.00036 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.509 | L2-Norm(final)=7.575 | 4370.4 samples/s | 68.3 steps/s
[Step=58000 Epoch=223.3] | Loss=0.00035 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.507 | L2-Norm(final)=7.575 | 4379.7 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08357 | acc=0.9678 | tpr=0.9773 | fpr=0.0528 | 5400.5 samples/s | 21.1 steps/s
Avg test loss: 0.08570, Avg test acc: 0.96594, Avg tpr: 0.97651, Avg fpr: 0.05730, total FA: 447

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08216 | acc=0.9677 | tpr=0.9707 | fpr=0.0389 | 5312.1 samples/s | 20.8 steps/s
Avg test loss: 0.08585, Avg test acc: 0.96634, Avg tpr: 0.97027, Avg fpr: 0.04230, total FA: 330

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.27927 | acc=0.3079 | tpr=0.0090 | fpr=0.0431 | 5300.6 samples/s | 20.7 steps/s
Avg test loss: 5.28805, Avg test acc: 0.30559, Avg tpr: 0.00822, Avg fpr: 0.04038, total FA: 315

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.81689 | acc=0.3102 | tpr=0.0060 | fpr=0.0295 | 5403.0 samples/s | 21.1 steps/s
Avg test loss: 4.82519, Avg test acc: 0.30808, Avg tpr: 0.00688, Avg fpr: 0.02948, total FA: 230

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.63136 | acc=0.1075 | tpr=0.6947 | fpr=0.9031 | 5128.8 samples/s | 20.0 steps/s
[Step= 100] | Loss=5.61228 | acc=0.1083 | tpr=0.6695 | fpr=0.9022 | 7614.6 samples/s | 29.7 steps/s
[Step= 150] | Loss=5.60727 | acc=0.1096 | tpr=0.6931 | fpr=0.9011 | 7645.2 samples/s | 29.9 steps/s
[Step= 200] | Loss=5.61921 | acc=0.1083 | tpr=0.6863 | fpr=0.9023 | 8329.3 samples/s | 32.5 steps/s
[Step= 250] | Loss=5.62330 | acc=0.1089 | tpr=0.6830 | fpr=0.9016 | 7955.9 samples/s | 31.1 steps/s
[Step= 300] | Loss=5.61902 | acc=0.1089 | tpr=0.6815 | fpr=0.9015 | 8241.6 samples/s | 32.2 steps/s
[Step= 350] | Loss=5.60966 | acc=0.1090 | tpr=0.6775 | fpr=0.9013 | 8042.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.60255 | acc=0.1093 | tpr=0.6844 | fpr=0.9012 | 7827.3 samples/s | 30.6 steps/s
[Step= 450] | Loss=5.60270 | acc=0.1088 | tpr=0.6870 | fpr=0.9017 | 8264.7 samples/s | 32.3 steps/s
[Step= 500] | Loss=5.60250 | acc=0.1086 | tpr=0.6859 | fpr=0.9018 | 8198.2 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.60091 | acc=0.1089 | tpr=0.6805 | fpr=0.9014 | 14613.5 samples/s | 57.1 steps/s
Avg test loss: 5.60194, Avg test acc: 0.10890, Avg tpr: 0.67987, Avg fpr: 0.90147, total FA: 125168

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.09432 | acc=0.1442 | tpr=0.6637 | fpr=0.8651 | 5176.7 samples/s | 20.2 steps/s
[Step= 100] | Loss=6.06932 | acc=0.1451 | tpr=0.6397 | fpr=0.8642 | 7499.8 samples/s | 29.3 steps/s
[Step= 150] | Loss=6.05584 | acc=0.1455 | tpr=0.6484 | fpr=0.8638 | 7812.5 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.06496 | acc=0.1450 | tpr=0.6492 | fpr=0.8642 | 8263.3 samples/s | 32.3 steps/s
[Step= 250] | Loss=6.07024 | acc=0.1456 | tpr=0.6472 | fpr=0.8636 | 7848.5 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.07221 | acc=0.1452 | tpr=0.6524 | fpr=0.8640 | 8098.8 samples/s | 31.6 steps/s
[Step= 350] | Loss=6.05750 | acc=0.1456 | tpr=0.6462 | fpr=0.8634 | 8500.4 samples/s | 33.2 steps/s
[Step= 400] | Loss=6.05019 | acc=0.1462 | tpr=0.6466 | fpr=0.8629 | 8000.5 samples/s | 31.3 steps/s
[Step= 450] | Loss=6.04657 | acc=0.1458 | tpr=0.6461 | fpr=0.8633 | 8207.4 samples/s | 32.1 steps/s
[Step= 500] | Loss=6.05016 | acc=0.1456 | tpr=0.6476 | fpr=0.8634 | 8239.9 samples/s | 32.2 steps/s
[Step= 550] | Loss=6.04866 | acc=0.1457 | tpr=0.6427 | fpr=0.8633 | 14009.9 samples/s | 54.7 steps/s
Avg test loss: 6.04976, Avg test acc: 0.14562, Avg tpr: 0.64263, Avg fpr: 0.86341, total FA: 119883

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12804 | acc=0.9780 | tpr=0.9425 | fpr=0.0214 | 5192.6 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.13449 | acc=0.9772 | tpr=0.9510 | fpr=0.0223 | 7626.2 samples/s | 29.8 steps/s
[Step= 150] | Loss=0.13981 | acc=0.9761 | tpr=0.9496 | fpr=0.0234 | 7512.3 samples/s | 29.3 steps/s
[Step= 200] | Loss=0.14222 | acc=0.9762 | tpr=0.9519 | fpr=0.0234 | 8299.8 samples/s | 32.4 steps/s
[Step= 250] | Loss=0.14035 | acc=0.9763 | tpr=0.9493 | fpr=0.0232 | 8329.9 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.14271 | acc=0.9759 | tpr=0.9462 | fpr=0.0235 | 7939.9 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.14333 | acc=0.9756 | tpr=0.9487 | fpr=0.0239 | 7969.1 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.14486 | acc=0.9754 | tpr=0.9469 | fpr=0.0241 | 8082.6 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14813 | acc=0.9750 | tpr=0.9469 | fpr=0.0244 | 8319.5 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.14758 | acc=0.9751 | tpr=0.9476 | fpr=0.0244 | 7657.0 samples/s | 29.9 steps/s
[Step= 550] | Loss=0.14644 | acc=0.9753 | tpr=0.9471 | fpr=0.0242 | 15484.8 samples/s | 60.5 steps/s
Avg test loss: 0.14608, Avg test acc: 0.97531, Avg tpr: 0.94612, Avg fpr: 0.02416, total FA: 3355

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13884 | acc=0.9773 | tpr=0.9381 | fpr=0.0220 | 5216.1 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.14544 | acc=0.9771 | tpr=0.9424 | fpr=0.0223 | 7351.9 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.15183 | acc=0.9765 | tpr=0.9524 | fpr=0.0231 | 7682.3 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.15489 | acc=0.9762 | tpr=0.9563 | fpr=0.0234 | 8487.9 samples/s | 33.2 steps/s
[Step= 250] | Loss=0.15241 | acc=0.9765 | tpr=0.9563 | fpr=0.0231 | 8293.6 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.15554 | acc=0.9761 | tpr=0.9564 | fpr=0.0235 | 7957.4 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.15662 | acc=0.9759 | tpr=0.9555 | fpr=0.0238 | 7721.1 samples/s | 30.2 steps/s
[Step= 400] | Loss=0.15837 | acc=0.9757 | tpr=0.9508 | fpr=0.0239 | 8578.4 samples/s | 33.5 steps/s
[Step= 450] | Loss=0.16136 | acc=0.9753 | tpr=0.9508 | fpr=0.0243 | 8203.1 samples/s | 32.0 steps/s
[Step= 500] | Loss=0.16065 | acc=0.9753 | tpr=0.9524 | fpr=0.0243 | 7701.6 samples/s | 30.1 steps/s
[Step= 550] | Loss=0.15935 | acc=0.9756 | tpr=0.9522 | fpr=0.0240 | 15121.7 samples/s | 59.1 steps/s
Avg test loss: 0.15893, Avg test acc: 0.97559, Avg tpr: 0.95206, Avg fpr: 0.02398, total FA: 3330

server round 29/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=113.1] | Loss=0.00590 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.050 | L2-Norm(final)=9.951 | 6279.7 samples/s | 98.1 steps/s
[Step=58050 Epoch=113.2] | Loss=0.00593 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.052 | L2-Norm(final)=9.957 | 4741.6 samples/s | 74.1 steps/s
[Step=58100 Epoch=113.3] | Loss=0.00557 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.054 | L2-Norm(final)=9.963 | 5121.8 samples/s | 80.0 steps/s
[Step=58150 Epoch=113.4] | Loss=0.00528 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.055 | L2-Norm(final)=9.970 | 5147.1 samples/s | 80.4 steps/s
[Step=58200 Epoch=113.5] | Loss=0.00571 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.057 | L2-Norm(final)=9.978 | 5190.8 samples/s | 81.1 steps/s
[Step=58250 Epoch=113.6] | Loss=0.00602 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.059 | L2-Norm(final)=9.985 | 5207.1 samples/s | 81.4 steps/s
[Step=58300 Epoch=113.7] | Loss=0.00590 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.060 | L2-Norm(final)=9.992 | 5216.0 samples/s | 81.5 steps/s
[Step=58350 Epoch=113.8] | Loss=0.00612 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.062 | L2-Norm(final)=9.999 | 5239.4 samples/s | 81.9 steps/s
[Step=58400 Epoch=113.9] | Loss=0.00627 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.063 | L2-Norm(final)=10.006 | 5236.1 samples/s | 81.8 steps/s
[Step=58450 Epoch=114.0] | Loss=0.00628 | Reg=0.00258 | acc=0.9844 | L2-Norm=16.065 | L2-Norm(final)=10.014 | 5301.5 samples/s | 82.8 steps/s
[Step=58500 Epoch=114.1] | Loss=0.00630 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.066 | L2-Norm(final)=10.021 | 6712.3 samples/s | 104.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=114.1] | Loss=0.00746 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.080 | L2-Norm(final)=10.092 | 7017.4 samples/s | 109.6 steps/s
[Step=58550 Epoch=114.2] | Loss=0.00631 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.084 | L2-Norm(final)=10.098 | 3975.9 samples/s | 62.1 steps/s
[Step=58600 Epoch=114.3] | Loss=0.00802 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.086 | L2-Norm(final)=10.102 | 4644.5 samples/s | 72.6 steps/s
[Step=58650 Epoch=114.4] | Loss=0.00723 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.088 | L2-Norm(final)=10.105 | 4510.6 samples/s | 70.5 steps/s
[Step=58700 Epoch=114.5] | Loss=0.00733 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.091 | L2-Norm(final)=10.109 | 4669.2 samples/s | 73.0 steps/s
[Step=58750 Epoch=114.6] | Loss=0.00773 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.095 | L2-Norm(final)=10.113 | 4594.1 samples/s | 71.8 steps/s
[Step=58800 Epoch=114.7] | Loss=0.00836 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.100 | L2-Norm(final)=10.117 | 4696.4 samples/s | 73.4 steps/s
[Step=58850 Epoch=114.8] | Loss=0.00854 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.104 | L2-Norm(final)=10.120 | 4582.7 samples/s | 71.6 steps/s
[Step=58900 Epoch=114.9] | Loss=0.00868 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.109 | L2-Norm(final)=10.124 | 4613.5 samples/s | 72.1 steps/s
[Step=58950 Epoch=115.0] | Loss=0.00872 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.112 | L2-Norm(final)=10.128 | 4693.8 samples/s | 73.3 steps/s
[Step=59000 Epoch=115.1] | Loss=0.00891 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.116 | L2-Norm(final)=10.131 | 5897.2 samples/s | 92.1 steps/s
[Step=59050 Epoch=115.2] | Loss=0.00880 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.120 | L2-Norm(final)=10.134 | 2437.8 samples/s | 38.1 steps/s
[Step=59100 Epoch=115.3] | Loss=0.00863 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.123 | L2-Norm(final)=10.138 | 4652.2 samples/s | 72.7 steps/s
[Step=59150 Epoch=115.4] | Loss=0.00862 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.125 | L2-Norm(final)=10.141 | 4659.8 samples/s | 72.8 steps/s
[Step=59200 Epoch=115.5] | Loss=0.00849 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.127 | L2-Norm(final)=10.144 | 4659.6 samples/s | 72.8 steps/s
[Step=59250 Epoch=115.6] | Loss=0.00836 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=10.148 | 4520.5 samples/s | 70.6 steps/s
[Step=59300 Epoch=115.7] | Loss=0.00825 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=10.151 | 4606.4 samples/s | 72.0 steps/s
[Step=59350 Epoch=115.8] | Loss=0.00819 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.133 | L2-Norm(final)=10.154 | 4635.7 samples/s | 72.4 steps/s
[Step=59400 Epoch=115.9] | Loss=0.00809 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=10.156 | 4650.3 samples/s | 72.7 steps/s
[Step=59450 Epoch=116.0] | Loss=0.00815 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=10.159 | 4617.4 samples/s | 72.1 steps/s
[Step=59500 Epoch=116.0] | Loss=0.00808 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.137 | L2-Norm(final)=10.162 | 4947.1 samples/s | 77.3 steps/s
[Step=59550 Epoch=116.1] | Loss=0.00800 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.138 | L2-Norm(final)=10.164 | 2673.5 samples/s | 41.8 steps/s
[Step=59600 Epoch=116.2] | Loss=0.00786 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=10.167 | 4655.9 samples/s | 72.7 steps/s
[Step=59650 Epoch=116.3] | Loss=0.00774 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=10.170 | 4654.9 samples/s | 72.7 steps/s
[Step=59700 Epoch=116.4] | Loss=0.00766 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=10.173 | 4557.6 samples/s | 71.2 steps/s
[Step=59750 Epoch=116.5] | Loss=0.00769 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.141 | L2-Norm(final)=10.176 | 4553.7 samples/s | 71.2 steps/s
[Step=59800 Epoch=116.6] | Loss=0.00760 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=10.179 | 4664.6 samples/s | 72.9 steps/s
[Step=59850 Epoch=116.7] | Loss=0.00755 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=10.181 | 4606.0 samples/s | 72.0 steps/s
[Step=59900 Epoch=116.8] | Loss=0.00745 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=10.184 | 4658.4 samples/s | 72.8 steps/s
[Step=59950 Epoch=116.9] | Loss=0.00740 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=10.187 | 4646.0 samples/s | 72.6 steps/s
[Step=60000 Epoch=117.0] | Loss=0.00735 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=10.189 | 4565.0 samples/s | 71.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step60000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=113.4] | Loss=0.00327 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.476 | L2-Norm(final)=10.467 | 6117.6 samples/s | 95.6 steps/s
[Step=58050 Epoch=113.5] | Loss=0.00518 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.477 | L2-Norm(final)=10.474 | 4807.2 samples/s | 75.1 steps/s
[Step=58100 Epoch=113.6] | Loss=0.00557 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.478 | L2-Norm(final)=10.481 | 5132.1 samples/s | 80.2 steps/s
[Step=58150 Epoch=113.7] | Loss=0.00549 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=10.489 | 5246.8 samples/s | 82.0 steps/s
[Step=58200 Epoch=113.8] | Loss=0.00568 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=10.496 | 5125.4 samples/s | 80.1 steps/s
[Step=58250 Epoch=113.9] | Loss=0.00560 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.480 | L2-Norm(final)=10.503 | 5162.8 samples/s | 80.7 steps/s
[Step=58300 Epoch=114.0] | Loss=0.00554 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.481 | L2-Norm(final)=10.510 | 5283.3 samples/s | 82.6 steps/s
[Step=58350 Epoch=114.1] | Loss=0.00550 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.481 | L2-Norm(final)=10.518 | 5138.2 samples/s | 80.3 steps/s
[Step=58400 Epoch=114.2] | Loss=0.00563 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.482 | L2-Norm(final)=10.525 | 5171.5 samples/s | 80.8 steps/s
[Step=58450 Epoch=114.3] | Loss=0.00569 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.482 | L2-Norm(final)=10.532 | 5210.7 samples/s | 81.4 steps/s
[Step=58500 Epoch=114.4] | Loss=0.00569 | Reg=0.00272 | acc=0.9531 | L2-Norm=16.483 | L2-Norm(final)=10.539 | 7147.6 samples/s | 111.7 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=114.4] | Loss=0.01859 | Reg=0.00272 | acc=0.9688 | L2-Norm=16.486 | L2-Norm(final)=10.608 | 6764.6 samples/s | 105.7 steps/s
[Step=58550 Epoch=114.5] | Loss=0.00598 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.490 | L2-Norm(final)=10.614 | 4209.7 samples/s | 65.8 steps/s
[Step=58600 Epoch=114.6] | Loss=0.00626 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.492 | L2-Norm(final)=10.619 | 4491.2 samples/s | 70.2 steps/s
[Step=58650 Epoch=114.7] | Loss=0.00603 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.495 | L2-Norm(final)=10.623 | 4647.7 samples/s | 72.6 steps/s
[Step=58700 Epoch=114.8] | Loss=0.00634 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.497 | L2-Norm(final)=10.627 | 4600.2 samples/s | 71.9 steps/s
[Step=58750 Epoch=114.9] | Loss=0.00632 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.498 | L2-Norm(final)=10.632 | 4560.1 samples/s | 71.3 steps/s
[Step=58800 Epoch=115.0] | Loss=0.00675 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.500 | L2-Norm(final)=10.636 | 4622.8 samples/s | 72.2 steps/s
[Step=58850 Epoch=115.1] | Loss=0.00662 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.502 | L2-Norm(final)=10.639 | 4654.5 samples/s | 72.7 steps/s
[Step=58900 Epoch=115.1] | Loss=0.00720 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.503 | L2-Norm(final)=10.642 | 4605.7 samples/s | 72.0 steps/s
[Step=58950 Epoch=115.2] | Loss=0.00757 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.505 | L2-Norm(final)=10.645 | 4619.5 samples/s | 72.2 steps/s
[Step=59000 Epoch=115.3] | Loss=0.00783 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.507 | L2-Norm(final)=10.648 | 6028.1 samples/s | 94.2 steps/s
[Step=59050 Epoch=115.4] | Loss=0.00763 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.509 | L2-Norm(final)=10.651 | 2437.1 samples/s | 38.1 steps/s
[Step=59100 Epoch=115.5] | Loss=0.00746 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.511 | L2-Norm(final)=10.654 | 4592.4 samples/s | 71.8 steps/s
[Step=59150 Epoch=115.6] | Loss=0.00770 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.512 | L2-Norm(final)=10.657 | 4662.2 samples/s | 72.8 steps/s
[Step=59200 Epoch=115.7] | Loss=0.00753 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.514 | L2-Norm(final)=10.660 | 4552.7 samples/s | 71.1 steps/s
[Step=59250 Epoch=115.8] | Loss=0.00746 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.515 | L2-Norm(final)=10.663 | 4648.6 samples/s | 72.6 steps/s
[Step=59300 Epoch=115.9] | Loss=0.00736 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.516 | L2-Norm(final)=10.665 | 4612.6 samples/s | 72.1 steps/s
[Step=59350 Epoch=116.0] | Loss=0.00723 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.517 | L2-Norm(final)=10.668 | 4612.7 samples/s | 72.1 steps/s
[Step=59400 Epoch=116.1] | Loss=0.00722 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.518 | L2-Norm(final)=10.672 | 4685.2 samples/s | 73.2 steps/s
[Step=59450 Epoch=116.2] | Loss=0.00726 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.519 | L2-Norm(final)=10.675 | 4673.2 samples/s | 73.0 steps/s
[Step=59500 Epoch=116.3] | Loss=0.00735 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.520 | L2-Norm(final)=10.678 | 4965.9 samples/s | 77.6 steps/s
[Step=59550 Epoch=116.4] | Loss=0.00727 | Reg=0.00273 | acc=0.9688 | L2-Norm=16.521 | L2-Norm(final)=10.680 | 2637.2 samples/s | 41.2 steps/s
[Step=59600 Epoch=116.5] | Loss=0.00721 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.521 | L2-Norm(final)=10.683 | 4707.8 samples/s | 73.6 steps/s
[Step=59650 Epoch=116.6] | Loss=0.00709 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=10.686 | 4504.5 samples/s | 70.4 steps/s
[Step=59700 Epoch=116.7] | Loss=0.00706 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=10.689 | 4627.3 samples/s | 72.3 steps/s
[Step=59750 Epoch=116.8] | Loss=0.00712 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=10.692 | 4588.5 samples/s | 71.7 steps/s
[Step=59800 Epoch=116.9] | Loss=0.00709 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=10.695 | 4628.0 samples/s | 72.3 steps/s
[Step=59850 Epoch=117.0] | Loss=0.00704 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=10.698 | 4678.1 samples/s | 73.1 steps/s
[Step=59900 Epoch=117.1] | Loss=0.00711 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=10.700 | 4645.8 samples/s | 72.6 steps/s
[Step=59950 Epoch=117.2] | Loss=0.00711 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=10.703 | 4582.4 samples/s | 71.6 steps/s
[Step=60000 Epoch=117.3] | Loss=0.00708 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.523 | L2-Norm(final)=10.705 | 4623.1 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step60000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=222.2] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.397 | L2-Norm(final)=7.526 | 5787.3 samples/s | 90.4 steps/s
[Step=58050 Epoch=222.4] | Loss=0.00004 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.400 | L2-Norm(final)=7.533 | 4558.5 samples/s | 71.2 steps/s
[Step=58100 Epoch=222.6] | Loss=0.00005 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.405 | L2-Norm(final)=7.542 | 4889.8 samples/s | 76.4 steps/s
[Step=58150 Epoch=222.8] | Loss=0.00004 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.409 | L2-Norm(final)=7.550 | 4889.3 samples/s | 76.4 steps/s
[Step=58200 Epoch=223.0] | Loss=0.00004 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.411 | L2-Norm(final)=7.556 | 4950.8 samples/s | 77.4 steps/s
[Step=58250 Epoch=223.2] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.412 | L2-Norm(final)=7.562 | 6769.7 samples/s | 105.8 steps/s
[Step=58300 Epoch=223.4] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.568 | 2474.3 samples/s | 38.7 steps/s
[Step=58350 Epoch=223.6] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.573 | 4887.8 samples/s | 76.4 steps/s
[Step=58400 Epoch=223.8] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.578 | 4996.1 samples/s | 78.1 steps/s
[Step=58450 Epoch=224.0] | Loss=0.00003 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.582 | 4791.1 samples/s | 74.9 steps/s
[Step=58500 Epoch=224.2] | Loss=0.00002 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.587 | 5696.9 samples/s | 89.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=224.2] | Loss=0.00006 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.410 | L2-Norm(final)=7.633 | 6655.1 samples/s | 104.0 steps/s
[Step=58550 Epoch=224.3] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.406 | L2-Norm(final)=7.636 | 3766.8 samples/s | 58.9 steps/s
[Step=58600 Epoch=224.5] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.400 | L2-Norm(final)=7.639 | 4394.3 samples/s | 68.7 steps/s
[Step=58650 Epoch=224.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.393 | L2-Norm(final)=7.642 | 4402.9 samples/s | 68.8 steps/s
[Step=58700 Epoch=224.9] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.387 | L2-Norm(final)=7.646 | 4392.5 samples/s | 68.6 steps/s
[Step=58750 Epoch=225.1] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=7.649 | 5871.8 samples/s | 91.7 steps/s
[Step=58800 Epoch=225.3] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.373 | L2-Norm(final)=7.652 | 2326.2 samples/s | 36.3 steps/s
[Step=58850 Epoch=225.5] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.365 | L2-Norm(final)=7.654 | 4389.1 samples/s | 68.6 steps/s
[Step=58900 Epoch=225.7] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.358 | L2-Norm(final)=7.656 | 4366.1 samples/s | 68.2 steps/s
[Step=58950 Epoch=225.9] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.350 | L2-Norm(final)=7.658 | 4532.8 samples/s | 70.8 steps/s
[Step=59000 Epoch=226.1] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.342 | L2-Norm(final)=7.660 | 4826.1 samples/s | 75.4 steps/s
[Step=59050 Epoch=226.3] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.334 | L2-Norm(final)=7.662 | 2507.1 samples/s | 39.2 steps/s
[Step=59100 Epoch=226.5] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.326 | L2-Norm(final)=7.664 | 4398.9 samples/s | 68.7 steps/s
[Step=59150 Epoch=226.6] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.318 | L2-Norm(final)=7.665 | 4347.3 samples/s | 67.9 steps/s
[Step=59200 Epoch=226.8] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.310 | L2-Norm(final)=7.667 | 4511.4 samples/s | 70.5 steps/s
[Step=59250 Epoch=227.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.301 | L2-Norm(final)=7.669 | 4274.3 samples/s | 66.8 steps/s
[Step=59300 Epoch=227.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.293 | L2-Norm(final)=7.670 | 2723.5 samples/s | 42.6 steps/s
[Step=59350 Epoch=227.4] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.284 | L2-Norm(final)=7.672 | 4269.1 samples/s | 66.7 steps/s
[Step=59400 Epoch=227.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.275 | L2-Norm(final)=7.673 | 4397.2 samples/s | 68.7 steps/s
[Step=59450 Epoch=227.8] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.267 | L2-Norm(final)=7.675 | 4439.6 samples/s | 69.4 steps/s
[Step=59500 Epoch=228.0] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.258 | L2-Norm(final)=7.676 | 4339.4 samples/s | 67.8 steps/s
[Step=59550 Epoch=228.2] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.249 | L2-Norm(final)=7.678 | 2699.3 samples/s | 42.2 steps/s
[Step=59600 Epoch=228.4] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.240 | L2-Norm(final)=7.679 | 4348.2 samples/s | 67.9 steps/s
[Step=59650 Epoch=228.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.231 | L2-Norm(final)=7.681 | 4531.3 samples/s | 70.8 steps/s
[Step=59700 Epoch=228.7] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.221 | L2-Norm(final)=7.682 | 4297.2 samples/s | 67.1 steps/s
[Step=59750 Epoch=228.9] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.212 | L2-Norm(final)=7.684 | 4419.2 samples/s | 69.1 steps/s
[Step=59800 Epoch=229.1] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.203 | L2-Norm(final)=7.685 | 6424.7 samples/s | 100.4 steps/s
[Step=59850 Epoch=229.3] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.193 | L2-Norm(final)=7.687 | 2247.9 samples/s | 35.1 steps/s
[Step=59900 Epoch=229.5] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.183 | L2-Norm(final)=7.689 | 4389.7 samples/s | 68.6 steps/s
[Step=59950 Epoch=229.7] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=7.690 | 4363.3 samples/s | 68.2 steps/s
[Step=60000 Epoch=229.9] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.164 | L2-Norm(final)=7.692 | 4445.2 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step60000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=223.3] | Loss=0.00006 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.487 | L2-Norm(final)=7.599 | 6388.6 samples/s | 99.8 steps/s
[Step=58050 Epoch=223.5] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.493 | L2-Norm(final)=7.601 | 4233.1 samples/s | 66.1 steps/s
[Step=58100 Epoch=223.6] | Loss=0.00003 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.492 | L2-Norm(final)=7.604 | 5068.4 samples/s | 79.2 steps/s
[Step=58150 Epoch=223.8] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.492 | L2-Norm(final)=7.606 | 4773.8 samples/s | 74.6 steps/s
[Step=58200 Epoch=224.0] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.492 | L2-Norm(final)=7.608 | 4898.0 samples/s | 76.5 steps/s
[Step=58250 Epoch=224.2] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.491 | L2-Norm(final)=7.610 | 6943.8 samples/s | 108.5 steps/s
[Step=58300 Epoch=224.4] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.491 | L2-Norm(final)=7.612 | 2464.7 samples/s | 38.5 steps/s
[Step=58350 Epoch=224.6] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.490 | L2-Norm(final)=7.614 | 4883.9 samples/s | 76.3 steps/s
[Step=58400 Epoch=224.8] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.490 | L2-Norm(final)=7.616 | 4928.9 samples/s | 77.0 steps/s
[Step=58450 Epoch=225.0] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.489 | L2-Norm(final)=7.619 | 4758.8 samples/s | 74.4 steps/s
[Step=58500 Epoch=225.2] | Loss=0.00002 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.488 | L2-Norm(final)=7.621 | 5881.0 samples/s | 91.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=225.2] | Loss=0.00004 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.481 | L2-Norm(final)=7.642 | 6231.3 samples/s | 97.4 steps/s
[Step=58550 Epoch=225.4] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.479 | L2-Norm(final)=7.644 | 3942.2 samples/s | 61.6 steps/s
[Step=58600 Epoch=225.6] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.475 | L2-Norm(final)=7.646 | 4335.7 samples/s | 67.7 steps/s
[Step=58650 Epoch=225.8] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.472 | L2-Norm(final)=7.647 | 4411.4 samples/s | 68.9 steps/s
[Step=58700 Epoch=226.0] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.468 | L2-Norm(final)=7.649 | 4404.2 samples/s | 68.8 steps/s
[Step=58750 Epoch=226.2] | Loss=0.00001 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.464 | L2-Norm(final)=7.651 | 5959.6 samples/s | 93.1 steps/s
[Step=58800 Epoch=226.3] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.460 | L2-Norm(final)=7.653 | 2333.0 samples/s | 36.5 steps/s
[Step=58850 Epoch=226.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.456 | L2-Norm(final)=7.654 | 4441.1 samples/s | 69.4 steps/s
[Step=58900 Epoch=226.7] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.452 | L2-Norm(final)=7.656 | 4251.8 samples/s | 66.4 steps/s
[Step=58950 Epoch=226.9] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.448 | L2-Norm(final)=7.657 | 4451.3 samples/s | 69.6 steps/s
[Step=59000 Epoch=227.1] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.444 | L2-Norm(final)=7.658 | 5051.4 samples/s | 78.9 steps/s
[Step=59050 Epoch=227.3] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.440 | L2-Norm(final)=7.660 | 2474.7 samples/s | 38.7 steps/s
[Step=59100 Epoch=227.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.435 | L2-Norm(final)=7.661 | 4372.6 samples/s | 68.3 steps/s
[Step=59150 Epoch=227.7] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.431 | L2-Norm(final)=7.662 | 4408.8 samples/s | 68.9 steps/s
[Step=59200 Epoch=227.9] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.427 | L2-Norm(final)=7.663 | 4372.9 samples/s | 68.3 steps/s
[Step=59250 Epoch=228.1] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.422 | L2-Norm(final)=7.665 | 4476.7 samples/s | 69.9 steps/s
[Step=59300 Epoch=228.3] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.418 | L2-Norm(final)=7.666 | 2646.8 samples/s | 41.4 steps/s
[Step=59350 Epoch=228.5] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.413 | L2-Norm(final)=7.667 | 4413.0 samples/s | 69.0 steps/s
[Step=59400 Epoch=228.7] | Loss=0.00001 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.409 | L2-Norm(final)=7.668 | 4355.9 samples/s | 68.1 steps/s
[Step=59450 Epoch=228.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.404 | L2-Norm(final)=7.670 | 4498.3 samples/s | 70.3 steps/s
[Step=59500 Epoch=229.0] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.400 | L2-Norm(final)=7.671 | 4341.9 samples/s | 67.8 steps/s
[Step=59550 Epoch=229.2] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.395 | L2-Norm(final)=7.672 | 2708.3 samples/s | 42.3 steps/s
[Step=59600 Epoch=229.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.390 | L2-Norm(final)=7.673 | 4334.8 samples/s | 67.7 steps/s
[Step=59650 Epoch=229.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.385 | L2-Norm(final)=7.675 | 4412.6 samples/s | 68.9 steps/s
[Step=59700 Epoch=229.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.380 | L2-Norm(final)=7.676 | 4363.1 samples/s | 68.2 steps/s
[Step=59750 Epoch=230.0] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.375 | L2-Norm(final)=7.677 | 4358.2 samples/s | 68.1 steps/s
[Step=59800 Epoch=230.2] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.370 | L2-Norm(final)=7.679 | 7166.9 samples/s | 112.0 steps/s
[Step=59850 Epoch=230.4] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.365 | L2-Norm(final)=7.680 | 2181.4 samples/s | 34.1 steps/s
[Step=59900 Epoch=230.6] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.360 | L2-Norm(final)=7.681 | 4327.0 samples/s | 67.6 steps/s
[Step=59950 Epoch=230.8] | Loss=0.00001 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.355 | L2-Norm(final)=7.683 | 4432.2 samples/s | 69.3 steps/s
[Step=60000 Epoch=231.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.350 | L2-Norm(final)=7.684 | 4356.0 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08591 | acc=0.9698 | tpr=0.9776 | fpr=0.0473 | 5208.0 samples/s | 20.3 steps/s
Avg test loss: 0.08962, Avg test acc: 0.96819, Avg tpr: 0.97698, Avg fpr: 0.05115, total FA: 399

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08153 | acc=0.9668 | tpr=0.9758 | fpr=0.0528 | 5054.0 samples/s | 19.7 steps/s
Avg test loss: 0.08565, Avg test acc: 0.96650, Avg tpr: 0.97581, Avg fpr: 0.05397, total FA: 421

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.56294 | acc=0.3072 | tpr=0.0055 | fpr=0.0377 | 5364.4 samples/s | 21.0 steps/s
Avg test loss: 5.57137, Avg test acc: 0.30583, Avg tpr: 0.00542, Avg fpr: 0.03346, total FA: 261

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=4.86822 | acc=0.3024 | tpr=0.0127 | fpr=0.0684 | 5114.3 samples/s | 20.0 steps/s
Avg test loss: 4.87277, Avg test acc: 0.30103, Avg tpr: 0.01236, Avg fpr: 0.06409, total FA: 500

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.73058 | acc=0.1212 | tpr=0.7301 | fpr=0.8897 | 5221.1 samples/s | 20.4 steps/s
[Step= 100] | Loss=6.69642 | acc=0.1232 | tpr=0.7228 | fpr=0.8879 | 7494.9 samples/s | 29.3 steps/s
[Step= 150] | Loss=6.69174 | acc=0.1245 | tpr=0.7507 | fpr=0.8870 | 7708.5 samples/s | 30.1 steps/s
[Step= 200] | Loss=6.71326 | acc=0.1230 | tpr=0.7410 | fpr=0.8883 | 8054.1 samples/s | 31.5 steps/s
[Step= 250] | Loss=6.72179 | acc=0.1232 | tpr=0.7354 | fpr=0.8880 | 8292.5 samples/s | 32.4 steps/s
[Step= 300] | Loss=6.72030 | acc=0.1228 | tpr=0.7353 | fpr=0.8883 | 7897.2 samples/s | 30.8 steps/s
[Step= 350] | Loss=6.70934 | acc=0.1232 | tpr=0.7332 | fpr=0.8878 | 8636.1 samples/s | 33.7 steps/s
[Step= 400] | Loss=6.70110 | acc=0.1237 | tpr=0.7363 | fpr=0.8874 | 7925.4 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.69919 | acc=0.1233 | tpr=0.7371 | fpr=0.8879 | 7936.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=6.69876 | acc=0.1231 | tpr=0.7370 | fpr=0.8880 | 8281.5 samples/s | 32.3 steps/s
[Step= 550] | Loss=6.69735 | acc=0.1234 | tpr=0.7322 | fpr=0.8877 | 14071.2 samples/s | 55.0 steps/s
Avg test loss: 6.69835, Avg test acc: 0.12331, Avg tpr: 0.73177, Avg fpr: 0.88775, total FA: 123263

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.68829 | acc=0.1243 | tpr=0.7257 | fpr=0.8865 | 5308.7 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.66673 | acc=0.1255 | tpr=0.7228 | fpr=0.8857 | 7353.2 samples/s | 28.7 steps/s
[Step= 150] | Loss=6.66074 | acc=0.1276 | tpr=0.7349 | fpr=0.8836 | 7664.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=6.67213 | acc=0.1268 | tpr=0.7355 | fpr=0.8843 | 7779.5 samples/s | 30.4 steps/s
[Step= 250] | Loss=6.67714 | acc=0.1271 | tpr=0.7284 | fpr=0.8839 | 8528.4 samples/s | 33.3 steps/s
[Step= 300] | Loss=6.67956 | acc=0.1267 | tpr=0.7265 | fpr=0.8843 | 7970.3 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.66432 | acc=0.1270 | tpr=0.7239 | fpr=0.8838 | 8083.9 samples/s | 31.6 steps/s
[Step= 400] | Loss=6.65682 | acc=0.1273 | tpr=0.7243 | fpr=0.8835 | 8214.6 samples/s | 32.1 steps/s
[Step= 450] | Loss=6.65581 | acc=0.1267 | tpr=0.7230 | fpr=0.8841 | 8091.0 samples/s | 31.6 steps/s
[Step= 500] | Loss=6.65848 | acc=0.1265 | tpr=0.7229 | fpr=0.8843 | 7827.7 samples/s | 30.6 steps/s
[Step= 550] | Loss=6.65385 | acc=0.1267 | tpr=0.7167 | fpr=0.8840 | 15146.5 samples/s | 59.2 steps/s
Avg test loss: 6.65557, Avg test acc: 0.12669, Avg tpr: 0.71672, Avg fpr: 0.88404, total FA: 122747

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12785 | acc=0.9795 | tpr=0.9336 | fpr=0.0196 | 5329.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.13497 | acc=0.9784 | tpr=0.9488 | fpr=0.0211 | 6944.4 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.14006 | acc=0.9773 | tpr=0.9467 | fpr=0.0222 | 8105.5 samples/s | 31.7 steps/s
[Step= 200] | Loss=0.14230 | acc=0.9773 | tpr=0.9486 | fpr=0.0222 | 8010.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.14049 | acc=0.9775 | tpr=0.9476 | fpr=0.0219 | 8157.3 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.14264 | acc=0.9771 | tpr=0.9455 | fpr=0.0223 | 7893.6 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.14319 | acc=0.9769 | tpr=0.9487 | fpr=0.0226 | 8270.0 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.14474 | acc=0.9767 | tpr=0.9464 | fpr=0.0227 | 8168.0 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.14790 | acc=0.9764 | tpr=0.9474 | fpr=0.0231 | 8123.0 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.14729 | acc=0.9764 | tpr=0.9476 | fpr=0.0230 | 8140.8 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.14609 | acc=0.9766 | tpr=0.9475 | fpr=0.0229 | 14509.8 samples/s | 56.7 steps/s
Avg test loss: 0.14571, Avg test acc: 0.97661, Avg tpr: 0.94651, Avg fpr: 0.02285, total FA: 3172

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15853 | acc=0.9754 | tpr=0.9381 | fpr=0.0239 | 5296.4 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.16593 | acc=0.9752 | tpr=0.9510 | fpr=0.0244 | 7339.0 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.17152 | acc=0.9742 | tpr=0.9539 | fpr=0.0254 | 7480.1 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.17519 | acc=0.9741 | tpr=0.9596 | fpr=0.0257 | 8343.7 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.17226 | acc=0.9745 | tpr=0.9607 | fpr=0.0252 | 8004.5 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.17550 | acc=0.9740 | tpr=0.9585 | fpr=0.0257 | 8148.9 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.17676 | acc=0.9737 | tpr=0.9587 | fpr=0.0260 | 8260.7 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.17846 | acc=0.9735 | tpr=0.9551 | fpr=0.0262 | 8101.1 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.18207 | acc=0.9731 | tpr=0.9552 | fpr=0.0266 | 7939.1 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.18151 | acc=0.9731 | tpr=0.9559 | fpr=0.0266 | 8227.0 samples/s | 32.1 steps/s
[Step= 550] | Loss=0.18004 | acc=0.9733 | tpr=0.9554 | fpr=0.0264 | 14119.4 samples/s | 55.2 steps/s
Avg test loss: 0.17959, Avg test acc: 0.97329, Avg tpr: 0.95444, Avg fpr: 0.02637, total FA: 3661

server round 30/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=117.0] | Loss=0.00562 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.974 | L2-Norm(final)=10.272 | 6357.1 samples/s | 99.3 steps/s
[Step=60050 Epoch=117.1] | Loss=0.00491 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.974 | L2-Norm(final)=10.274 | 4681.1 samples/s | 73.1 steps/s
[Step=60100 Epoch=117.2] | Loss=0.00446 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.973 | L2-Norm(final)=10.277 | 5132.1 samples/s | 80.2 steps/s
[Step=60150 Epoch=117.3] | Loss=0.00424 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=10.280 | 5187.4 samples/s | 81.1 steps/s
[Step=60200 Epoch=117.4] | Loss=0.00436 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.972 | L2-Norm(final)=10.283 | 5163.7 samples/s | 80.7 steps/s
[Step=60250 Epoch=117.5] | Loss=0.00468 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.972 | L2-Norm(final)=10.286 | 5322.9 samples/s | 83.2 steps/s
[Step=60300 Epoch=117.6] | Loss=0.00482 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=10.289 | 5047.1 samples/s | 78.9 steps/s
[Step=60350 Epoch=117.7] | Loss=0.00464 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.971 | L2-Norm(final)=10.291 | 5213.4 samples/s | 81.5 steps/s
[Step=60400 Epoch=117.8] | Loss=0.00487 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.970 | L2-Norm(final)=10.294 | 5206.8 samples/s | 81.4 steps/s
[Step=60450 Epoch=117.9] | Loss=0.00486 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.970 | L2-Norm(final)=10.296 | 5214.5 samples/s | 81.5 steps/s
[Step=60500 Epoch=118.0] | Loss=0.00483 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.969 | L2-Norm(final)=10.299 | 6988.7 samples/s | 109.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=118.0] | Loss=0.00321 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.325 | 6338.3 samples/s | 99.0 steps/s
[Step=60550 Epoch=118.1] | Loss=0.00406 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.965 | L2-Norm(final)=10.327 | 4229.4 samples/s | 66.1 steps/s
[Step=60600 Epoch=118.2] | Loss=0.00434 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.330 | 4670.4 samples/s | 73.0 steps/s
[Step=60650 Epoch=118.3] | Loss=0.00472 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=10.332 | 4537.2 samples/s | 70.9 steps/s
[Step=60700 Epoch=118.4] | Loss=0.00494 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.334 | 4581.5 samples/s | 71.6 steps/s
[Step=60750 Epoch=118.5] | Loss=0.00504 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.965 | L2-Norm(final)=10.336 | 4645.2 samples/s | 72.6 steps/s
[Step=60800 Epoch=118.6] | Loss=0.00487 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.338 | 4631.2 samples/s | 72.4 steps/s
[Step=60850 Epoch=118.7] | Loss=0.00490 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=10.340 | 4625.9 samples/s | 72.3 steps/s
[Step=60900 Epoch=118.8] | Loss=0.00521 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.966 | L2-Norm(final)=10.342 | 4638.5 samples/s | 72.5 steps/s
[Step=60950 Epoch=118.9] | Loss=0.00512 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=10.344 | 4676.5 samples/s | 73.1 steps/s
[Step=61000 Epoch=119.0] | Loss=0.00508 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.966 | L2-Norm(final)=10.347 | 5835.4 samples/s | 91.2 steps/s
[Step=61050 Epoch=119.1] | Loss=0.00509 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=10.349 | 2439.2 samples/s | 38.1 steps/s
[Step=61100 Epoch=119.2] | Loss=0.00505 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=10.351 | 4622.6 samples/s | 72.2 steps/s
[Step=61150 Epoch=119.3] | Loss=0.00503 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=10.353 | 4705.9 samples/s | 73.5 steps/s
[Step=61200 Epoch=119.4] | Loss=0.00500 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.355 | 4605.3 samples/s | 72.0 steps/s
[Step=61250 Epoch=119.5] | Loss=0.00502 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.357 | 4549.0 samples/s | 71.1 steps/s
[Step=61300 Epoch=119.6] | Loss=0.00492 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.359 | 4655.0 samples/s | 72.7 steps/s
[Step=61350 Epoch=119.7] | Loss=0.00494 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=10.361 | 4612.8 samples/s | 72.1 steps/s
[Step=61400 Epoch=119.8] | Loss=0.00495 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=10.363 | 4624.6 samples/s | 72.3 steps/s
[Step=61450 Epoch=119.9] | Loss=0.00493 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=10.365 | 4614.5 samples/s | 72.1 steps/s
[Step=61500 Epoch=119.9] | Loss=0.00494 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.963 | L2-Norm(final)=10.367 | 4981.8 samples/s | 77.8 steps/s
[Step=61550 Epoch=120.0] | Loss=0.00492 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.963 | L2-Norm(final)=10.368 | 2667.1 samples/s | 41.7 steps/s
[Step=61600 Epoch=120.1] | Loss=0.00490 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=10.370 | 4662.2 samples/s | 72.8 steps/s
[Step=61650 Epoch=120.2] | Loss=0.00486 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=10.372 | 4527.4 samples/s | 70.7 steps/s
[Step=61700 Epoch=120.3] | Loss=0.00481 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=10.374 | 4595.1 samples/s | 71.8 steps/s
[Step=61750 Epoch=120.4] | Loss=0.00477 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.960 | L2-Norm(final)=10.376 | 4633.1 samples/s | 72.4 steps/s
[Step=61800 Epoch=120.5] | Loss=0.00472 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=10.377 | 4659.9 samples/s | 72.8 steps/s
[Step=61850 Epoch=120.6] | Loss=0.00473 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.959 | L2-Norm(final)=10.379 | 4658.7 samples/s | 72.8 steps/s
[Step=61900 Epoch=120.7] | Loss=0.00470 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=10.381 | 4575.0 samples/s | 71.5 steps/s
[Step=61950 Epoch=120.8] | Loss=0.00473 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=10.383 | 4653.4 samples/s | 72.7 steps/s
[Step=62000 Epoch=120.9] | Loss=0.00478 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=10.384 | 4635.2 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step62000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=117.3] | Loss=0.00066 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=10.777 | 6143.2 samples/s | 96.0 steps/s
[Step=60050 Epoch=117.4] | Loss=0.00482 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.359 | L2-Norm(final)=10.780 | 4588.2 samples/s | 71.7 steps/s
[Step=60100 Epoch=117.5] | Loss=0.00516 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.358 | L2-Norm(final)=10.783 | 5167.1 samples/s | 80.7 steps/s
[Step=60150 Epoch=117.6] | Loss=0.00492 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.357 | L2-Norm(final)=10.786 | 5152.9 samples/s | 80.5 steps/s
[Step=60200 Epoch=117.7] | Loss=0.00466 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.357 | L2-Norm(final)=10.789 | 5179.2 samples/s | 80.9 steps/s
[Step=60250 Epoch=117.8] | Loss=0.00463 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.356 | L2-Norm(final)=10.792 | 5191.5 samples/s | 81.1 steps/s
[Step=60300 Epoch=117.9] | Loss=0.00470 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.356 | L2-Norm(final)=10.795 | 5173.2 samples/s | 80.8 steps/s
[Step=60350 Epoch=118.0] | Loss=0.00462 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=10.798 | 5243.6 samples/s | 81.9 steps/s
[Step=60400 Epoch=118.1] | Loss=0.00472 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.354 | L2-Norm(final)=10.801 | 5205.9 samples/s | 81.3 steps/s
[Step=60450 Epoch=118.2] | Loss=0.00464 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.354 | L2-Norm(final)=10.803 | 5199.5 samples/s | 81.2 steps/s
[Step=60500 Epoch=118.3] | Loss=0.00457 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.353 | L2-Norm(final)=10.806 | 7131.0 samples/s | 111.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=118.3] | Loss=0.00067 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=10.834 | 6210.8 samples/s | 97.0 steps/s
[Step=60550 Epoch=118.4] | Loss=0.00407 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.346 | L2-Norm(final)=10.837 | 4207.6 samples/s | 65.7 steps/s
[Step=60600 Epoch=118.5] | Loss=0.00381 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.346 | L2-Norm(final)=10.839 | 4606.1 samples/s | 72.0 steps/s
[Step=60650 Epoch=118.6] | Loss=0.00413 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.346 | L2-Norm(final)=10.841 | 4626.5 samples/s | 72.3 steps/s
[Step=60700 Epoch=118.7] | Loss=0.00474 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=10.843 | 4643.5 samples/s | 72.6 steps/s
[Step=60750 Epoch=118.8] | Loss=0.00473 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.346 | L2-Norm(final)=10.845 | 4582.1 samples/s | 71.6 steps/s
[Step=60800 Epoch=118.9] | Loss=0.00465 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.346 | L2-Norm(final)=10.848 | 4724.5 samples/s | 73.8 steps/s
[Step=60850 Epoch=119.0] | Loss=0.00475 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.345 | L2-Norm(final)=10.850 | 4551.6 samples/s | 71.1 steps/s
[Step=60900 Epoch=119.1] | Loss=0.00481 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.345 | L2-Norm(final)=10.852 | 4664.6 samples/s | 72.9 steps/s
[Step=60950 Epoch=119.2] | Loss=0.00481 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.345 | L2-Norm(final)=10.854 | 4592.9 samples/s | 71.8 steps/s
[Step=61000 Epoch=119.3] | Loss=0.00484 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.344 | L2-Norm(final)=10.856 | 6062.6 samples/s | 94.7 steps/s
[Step=61050 Epoch=119.4] | Loss=0.00484 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.344 | L2-Norm(final)=10.858 | 2440.2 samples/s | 38.1 steps/s
[Step=61100 Epoch=119.4] | Loss=0.00477 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=10.860 | 4541.9 samples/s | 71.0 steps/s
[Step=61150 Epoch=119.5] | Loss=0.00467 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=10.862 | 4622.2 samples/s | 72.2 steps/s
[Step=61200 Epoch=119.6] | Loss=0.00459 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.342 | L2-Norm(final)=10.865 | 4649.5 samples/s | 72.6 steps/s
[Step=61250 Epoch=119.7] | Loss=0.00469 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.341 | L2-Norm(final)=10.867 | 4622.7 samples/s | 72.2 steps/s
[Step=61300 Epoch=119.8] | Loss=0.00461 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.341 | L2-Norm(final)=10.869 | 4579.2 samples/s | 71.5 steps/s
[Step=61350 Epoch=119.9] | Loss=0.00460 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.340 | L2-Norm(final)=10.871 | 4683.5 samples/s | 73.2 steps/s
[Step=61400 Epoch=120.0] | Loss=0.00459 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.339 | L2-Norm(final)=10.872 | 4554.9 samples/s | 71.2 steps/s
[Step=61450 Epoch=120.1] | Loss=0.00460 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.338 | L2-Norm(final)=10.874 | 4680.6 samples/s | 73.1 steps/s
[Step=61500 Epoch=120.2] | Loss=0.00461 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.337 | L2-Norm(final)=10.876 | 5066.9 samples/s | 79.2 steps/s
[Step=61550 Epoch=120.3] | Loss=0.00460 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.336 | L2-Norm(final)=10.878 | 2640.9 samples/s | 41.3 steps/s
[Step=61600 Epoch=120.4] | Loss=0.00460 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.335 | L2-Norm(final)=10.880 | 4683.1 samples/s | 73.2 steps/s
[Step=61650 Epoch=120.5] | Loss=0.00456 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.334 | L2-Norm(final)=10.882 | 4528.1 samples/s | 70.8 steps/s
[Step=61700 Epoch=120.6] | Loss=0.00450 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.333 | L2-Norm(final)=10.884 | 4637.4 samples/s | 72.5 steps/s
[Step=61750 Epoch=120.7] | Loss=0.00447 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.332 | L2-Norm(final)=10.886 | 4670.2 samples/s | 73.0 steps/s
[Step=61800 Epoch=120.8] | Loss=0.00445 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.331 | L2-Norm(final)=10.887 | 4541.6 samples/s | 71.0 steps/s
[Step=61850 Epoch=120.9] | Loss=0.00449 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=10.889 | 4627.3 samples/s | 72.3 steps/s
[Step=61900 Epoch=121.0] | Loss=0.00450 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.329 | L2-Norm(final)=10.891 | 4677.9 samples/s | 73.1 steps/s
[Step=61950 Epoch=121.1] | Loss=0.00450 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.328 | L2-Norm(final)=10.893 | 4675.9 samples/s | 73.1 steps/s
[Step=62000 Epoch=121.2] | Loss=0.00448 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.327 | L2-Norm(final)=10.895 | 4549.9 samples/s | 71.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step62000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=229.9] | Loss=0.00005 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.233 | L2-Norm(final)=7.741 | 6136.7 samples/s | 95.9 steps/s
[Step=60050 Epoch=230.1] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.236 | L2-Norm(final)=7.748 | 4392.8 samples/s | 68.6 steps/s
[Step=60100 Epoch=230.3] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.240 | L2-Norm(final)=7.756 | 4928.3 samples/s | 77.0 steps/s
[Step=60150 Epoch=230.5] | Loss=0.00004 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.243 | L2-Norm(final)=7.762 | 4853.4 samples/s | 75.8 steps/s
[Step=60200 Epoch=230.7] | Loss=0.00003 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.244 | L2-Norm(final)=7.768 | 4848.3 samples/s | 75.8 steps/s
[Step=60250 Epoch=230.9] | Loss=0.00003 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.245 | L2-Norm(final)=7.774 | 6819.9 samples/s | 106.6 steps/s
[Step=60300 Epoch=231.0] | Loss=0.00003 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.246 | L2-Norm(final)=7.779 | 2486.8 samples/s | 38.9 steps/s
[Step=60350 Epoch=231.2] | Loss=0.00003 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.247 | L2-Norm(final)=7.784 | 4960.3 samples/s | 77.5 steps/s
[Step=60400 Epoch=231.4] | Loss=0.00003 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.248 | L2-Norm(final)=7.789 | 4809.8 samples/s | 75.2 steps/s
[Step=60450 Epoch=231.6] | Loss=0.00002 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.248 | L2-Norm(final)=7.794 | 4809.9 samples/s | 75.2 steps/s
[Step=60500 Epoch=231.8] | Loss=0.00002 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.248 | L2-Norm(final)=7.798 | 5676.9 samples/s | 88.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=231.8] | Loss=0.00003 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.252 | L2-Norm(final)=7.844 | 5802.8 samples/s | 90.7 steps/s
[Step=60550 Epoch=232.0] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.248 | L2-Norm(final)=7.849 | 4097.4 samples/s | 64.0 steps/s
[Step=60600 Epoch=232.2] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.241 | L2-Norm(final)=7.853 | 4388.4 samples/s | 68.6 steps/s
[Step=60650 Epoch=232.4] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.233 | L2-Norm(final)=7.856 | 4399.9 samples/s | 68.7 steps/s
[Step=60700 Epoch=232.6] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.225 | L2-Norm(final)=7.859 | 4396.6 samples/s | 68.7 steps/s
[Step=60750 Epoch=232.8] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.217 | L2-Norm(final)=7.862 | 5880.9 samples/s | 91.9 steps/s
[Step=60800 Epoch=233.0] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.209 | L2-Norm(final)=7.864 | 2311.8 samples/s | 36.1 steps/s
[Step=60850 Epoch=233.2] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.200 | L2-Norm(final)=7.867 | 4408.2 samples/s | 68.9 steps/s
[Step=60900 Epoch=233.3] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.191 | L2-Norm(final)=7.869 | 4378.4 samples/s | 68.4 steps/s
[Step=60950 Epoch=233.5] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=7.871 | 4390.6 samples/s | 68.6 steps/s
[Step=61000 Epoch=233.7] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.173 | L2-Norm(final)=7.872 | 4973.9 samples/s | 77.7 steps/s
[Step=61050 Epoch=233.9] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.163 | L2-Norm(final)=7.874 | 2498.6 samples/s | 39.0 steps/s
[Step=61100 Epoch=234.1] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=7.876 | 4462.6 samples/s | 69.7 steps/s
[Step=61150 Epoch=234.3] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.144 | L2-Norm(final)=7.878 | 4415.5 samples/s | 69.0 steps/s
[Step=61200 Epoch=234.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.134 | L2-Norm(final)=7.880 | 4422.4 samples/s | 69.1 steps/s
[Step=61250 Epoch=234.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.125 | L2-Norm(final)=7.882 | 4259.6 samples/s | 66.6 steps/s
[Step=61300 Epoch=234.9] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.115 | L2-Norm(final)=7.883 | 2667.5 samples/s | 41.7 steps/s
[Step=61350 Epoch=235.1] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.104 | L2-Norm(final)=7.885 | 4437.9 samples/s | 69.3 steps/s
[Step=61400 Epoch=235.3] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.094 | L2-Norm(final)=7.887 | 4318.3 samples/s | 67.5 steps/s
[Step=61450 Epoch=235.5] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.889 | 4350.9 samples/s | 68.0 steps/s
[Step=61500 Epoch=235.6] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.073 | L2-Norm(final)=7.890 | 4432.8 samples/s | 69.3 steps/s
[Step=61550 Epoch=235.8] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.063 | L2-Norm(final)=7.892 | 2652.5 samples/s | 41.4 steps/s
[Step=61600 Epoch=236.0] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.052 | L2-Norm(final)=7.894 | 4505.3 samples/s | 70.4 steps/s
[Step=61650 Epoch=236.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=7.896 | 4319.0 samples/s | 67.5 steps/s
[Step=61700 Epoch=236.4] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.030 | L2-Norm(final)=7.898 | 4371.4 samples/s | 68.3 steps/s
[Step=61750 Epoch=236.6] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.019 | L2-Norm(final)=7.899 | 4406.6 samples/s | 68.9 steps/s
[Step=61800 Epoch=236.8] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.008 | L2-Norm(final)=7.901 | 6505.1 samples/s | 101.6 steps/s
[Step=61850 Epoch=237.0] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.903 | 2235.3 samples/s | 34.9 steps/s
[Step=61900 Epoch=237.2] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.985 | L2-Norm(final)=7.905 | 4502.9 samples/s | 70.4 steps/s
[Step=61950 Epoch=237.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.974 | L2-Norm(final)=7.907 | 4259.2 samples/s | 66.5 steps/s
[Step=62000 Epoch=237.6] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.962 | L2-Norm(final)=7.909 | 4362.1 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step62000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=231.0] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.321 | L2-Norm(final)=7.725 | 6873.0 samples/s | 107.4 steps/s
[Step=60050 Epoch=231.2] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.321 | L2-Norm(final)=7.727 | 4025.2 samples/s | 62.9 steps/s
[Step=60100 Epoch=231.3] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.321 | L2-Norm(final)=7.730 | 4901.4 samples/s | 76.6 steps/s
[Step=60150 Epoch=231.5] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=7.733 | 4913.3 samples/s | 76.8 steps/s
[Step=60200 Epoch=231.7] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.323 | L2-Norm(final)=7.736 | 5075.1 samples/s | 79.3 steps/s
[Step=60250 Epoch=231.9] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.324 | L2-Norm(final)=7.739 | 6736.9 samples/s | 105.3 steps/s
[Step=60300 Epoch=232.1] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.324 | L2-Norm(final)=7.742 | 2434.7 samples/s | 38.0 steps/s
[Step=60350 Epoch=232.3] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.324 | L2-Norm(final)=7.745 | 4943.5 samples/s | 77.2 steps/s
[Step=60400 Epoch=232.5] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.325 | L2-Norm(final)=7.747 | 4867.7 samples/s | 76.1 steps/s
[Step=60450 Epoch=232.7] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.325 | L2-Norm(final)=7.750 | 4986.7 samples/s | 77.9 steps/s
[Step=60500 Epoch=232.9] | Loss=0.00002 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.325 | L2-Norm(final)=7.753 | 5755.5 samples/s | 89.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=232.9] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.325 | L2-Norm(final)=7.780 | 6549.5 samples/s | 102.3 steps/s
[Step=60550 Epoch=233.1] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.323 | L2-Norm(final)=7.783 | 3818.3 samples/s | 59.7 steps/s
[Step=60600 Epoch=233.3] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.319 | L2-Norm(final)=7.785 | 4441.2 samples/s | 69.4 steps/s
[Step=60650 Epoch=233.5] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.315 | L2-Norm(final)=7.788 | 4379.4 samples/s | 68.4 steps/s
[Step=60700 Epoch=233.7] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.311 | L2-Norm(final)=7.790 | 4297.6 samples/s | 67.2 steps/s
[Step=60750 Epoch=233.9] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.307 | L2-Norm(final)=7.793 | 5991.4 samples/s | 93.6 steps/s
[Step=60800 Epoch=234.0] | Loss=0.00001 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.303 | L2-Norm(final)=7.795 | 2321.6 samples/s | 36.3 steps/s
[Step=60850 Epoch=234.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.298 | L2-Norm(final)=7.796 | 4288.4 samples/s | 67.0 steps/s
[Step=60900 Epoch=234.4] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.294 | L2-Norm(final)=7.798 | 4396.5 samples/s | 68.7 steps/s
[Step=60950 Epoch=234.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.289 | L2-Norm(final)=7.800 | 4378.4 samples/s | 68.4 steps/s
[Step=61000 Epoch=234.8] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.284 | L2-Norm(final)=7.802 | 5095.9 samples/s | 79.6 steps/s
[Step=61050 Epoch=235.0] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.279 | L2-Norm(final)=7.803 | 2459.0 samples/s | 38.4 steps/s
[Step=61100 Epoch=235.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.275 | L2-Norm(final)=7.805 | 4387.7 samples/s | 68.6 steps/s
[Step=61150 Epoch=235.4] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.270 | L2-Norm(final)=7.806 | 4367.4 samples/s | 68.2 steps/s
[Step=61200 Epoch=235.6] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.265 | L2-Norm(final)=7.808 | 4372.1 samples/s | 68.3 steps/s
[Step=61250 Epoch=235.8] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.259 | L2-Norm(final)=7.809 | 4500.2 samples/s | 70.3 steps/s
[Step=61300 Epoch=236.0] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.254 | L2-Norm(final)=7.811 | 2642.1 samples/s | 41.3 steps/s
[Step=61350 Epoch=236.2] | Loss=0.00001 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.249 | L2-Norm(final)=7.812 | 4416.7 samples/s | 69.0 steps/s
[Step=61400 Epoch=236.4] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.244 | L2-Norm(final)=7.814 | 4413.7 samples/s | 69.0 steps/s
[Step=61450 Epoch=236.5] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.238 | L2-Norm(final)=7.815 | 4323.7 samples/s | 67.6 steps/s
[Step=61500 Epoch=236.7] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.233 | L2-Norm(final)=7.817 | 4401.6 samples/s | 68.8 steps/s
[Step=61550 Epoch=236.9] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.227 | L2-Norm(final)=7.818 | 2728.1 samples/s | 42.6 steps/s
[Step=61600 Epoch=237.1] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.222 | L2-Norm(final)=7.820 | 4333.6 samples/s | 67.7 steps/s
[Step=61650 Epoch=237.3] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.216 | L2-Norm(final)=7.821 | 4317.6 samples/s | 67.5 steps/s
[Step=61700 Epoch=237.5] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.210 | L2-Norm(final)=7.823 | 4383.8 samples/s | 68.5 steps/s
[Step=61750 Epoch=237.7] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.205 | L2-Norm(final)=7.824 | 4451.7 samples/s | 69.6 steps/s
[Step=61800 Epoch=237.9] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.199 | L2-Norm(final)=7.826 | 6944.2 samples/s | 108.5 steps/s
[Step=61850 Epoch=238.1] | Loss=0.00001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.193 | L2-Norm(final)=7.827 | 2168.1 samples/s | 33.9 steps/s
[Step=61900 Epoch=238.3] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.187 | L2-Norm(final)=7.829 | 4399.8 samples/s | 68.7 steps/s
[Step=61950 Epoch=238.5] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.181 | L2-Norm(final)=7.830 | 4395.7 samples/s | 68.7 steps/s
[Step=62000 Epoch=238.7] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.174 | L2-Norm(final)=7.832 | 4456.7 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08772 | acc=0.9674 | tpr=0.9771 | fpr=0.0535 | 5376.8 samples/s | 21.0 steps/s
Avg test loss: 0.08932, Avg test acc: 0.96662, Avg tpr: 0.97639, Avg fpr: 0.05486, total FA: 428

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08942 | acc=0.9672 | tpr=0.9770 | fpr=0.0540 | 5373.1 samples/s | 21.0 steps/s
Avg test loss: 0.09213, Avg test acc: 0.96763, Avg tpr: 0.97674, Avg fpr: 0.05243, total FA: 409

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.49686 | acc=0.3077 | tpr=0.0070 | fpr=0.0394 | 5369.1 samples/s | 21.0 steps/s
Avg test loss: 5.50215, Avg test acc: 0.30639, Avg tpr: 0.00705, Avg fpr: 0.03525, total FA: 275

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.19845 | acc=0.3027 | tpr=0.0110 | fpr=0.0637 | 5359.7 samples/s | 20.9 steps/s
Avg test loss: 5.20213, Avg test acc: 0.30203, Avg tpr: 0.01096, Avg fpr: 0.05781, total FA: 451

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.57985 | acc=0.1221 | tpr=0.7434 | fpr=0.8891 | 5307.7 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.55235 | acc=0.1222 | tpr=0.7292 | fpr=0.8891 | 7480.3 samples/s | 29.2 steps/s
[Step= 150] | Loss=6.55203 | acc=0.1233 | tpr=0.7507 | fpr=0.8882 | 7440.1 samples/s | 29.1 steps/s
[Step= 200] | Loss=6.56556 | acc=0.1223 | tpr=0.7443 | fpr=0.8890 | 8107.5 samples/s | 31.7 steps/s
[Step= 250] | Loss=6.57313 | acc=0.1225 | tpr=0.7380 | fpr=0.8887 | 8172.7 samples/s | 31.9 steps/s
[Step= 300] | Loss=6.57170 | acc=0.1224 | tpr=0.7418 | fpr=0.8889 | 8421.5 samples/s | 32.9 steps/s
[Step= 350] | Loss=6.55877 | acc=0.1226 | tpr=0.7420 | fpr=0.8886 | 7934.8 samples/s | 31.0 steps/s
[Step= 400] | Loss=6.54938 | acc=0.1234 | tpr=0.7462 | fpr=0.8879 | 8432.5 samples/s | 32.9 steps/s
[Step= 450] | Loss=6.54971 | acc=0.1230 | tpr=0.7454 | fpr=0.8883 | 7953.7 samples/s | 31.1 steps/s
[Step= 500] | Loss=6.54947 | acc=0.1226 | tpr=0.7436 | fpr=0.8886 | 8094.3 samples/s | 31.6 steps/s
[Step= 550] | Loss=6.54798 | acc=0.1227 | tpr=0.7382 | fpr=0.8885 | 14487.2 samples/s | 56.6 steps/s
Avg test loss: 6.54890, Avg test acc: 0.12269, Avg tpr: 0.73811, Avg fpr: 0.88850, total FA: 123366

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.46751 | acc=0.1250 | tpr=0.7478 | fpr=0.8862 | 5301.4 samples/s | 20.7 steps/s
[Step= 100] | Loss=7.44937 | acc=0.1249 | tpr=0.7377 | fpr=0.8866 | 7065.7 samples/s | 27.6 steps/s
[Step= 150] | Loss=7.43745 | acc=0.1262 | tpr=0.7507 | fpr=0.8853 | 8036.1 samples/s | 31.4 steps/s
[Step= 200] | Loss=7.44916 | acc=0.1254 | tpr=0.7475 | fpr=0.8860 | 7946.3 samples/s | 31.0 steps/s
[Step= 250] | Loss=7.45444 | acc=0.1259 | tpr=0.7432 | fpr=0.8853 | 8368.7 samples/s | 32.7 steps/s
[Step= 300] | Loss=7.45724 | acc=0.1257 | tpr=0.7433 | fpr=0.8855 | 8265.1 samples/s | 32.3 steps/s
[Step= 350] | Loss=7.44058 | acc=0.1259 | tpr=0.7408 | fpr=0.8853 | 7848.9 samples/s | 30.7 steps/s
[Step= 400] | Loss=7.43179 | acc=0.1262 | tpr=0.7429 | fpr=0.8850 | 8057.4 samples/s | 31.5 steps/s
[Step= 450] | Loss=7.42911 | acc=0.1256 | tpr=0.7415 | fpr=0.8856 | 8326.3 samples/s | 32.5 steps/s
[Step= 500] | Loss=7.43269 | acc=0.1253 | tpr=0.7392 | fpr=0.8858 | 8172.9 samples/s | 31.9 steps/s
[Step= 550] | Loss=7.42994 | acc=0.1255 | tpr=0.7338 | fpr=0.8855 | 14085.4 samples/s | 55.0 steps/s
Avg test loss: 7.43146, Avg test acc: 0.12550, Avg tpr: 0.73376, Avg fpr: 0.88556, total FA: 122958

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12759 | acc=0.9791 | tpr=0.9381 | fpr=0.0202 | 5202.4 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.13453 | acc=0.9781 | tpr=0.9531 | fpr=0.0214 | 7230.4 samples/s | 28.2 steps/s
[Step= 150] | Loss=0.13950 | acc=0.9769 | tpr=0.9496 | fpr=0.0226 | 8016.8 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.14158 | acc=0.9770 | tpr=0.9519 | fpr=0.0225 | 8269.3 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.13986 | acc=0.9772 | tpr=0.9502 | fpr=0.0223 | 7998.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.14207 | acc=0.9768 | tpr=0.9476 | fpr=0.0227 | 7981.3 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.14257 | acc=0.9766 | tpr=0.9505 | fpr=0.0229 | 8450.7 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.14404 | acc=0.9764 | tpr=0.9480 | fpr=0.0230 | 7942.3 samples/s | 31.0 steps/s
[Step= 450] | Loss=0.14717 | acc=0.9761 | tpr=0.9489 | fpr=0.0234 | 8276.9 samples/s | 32.3 steps/s
[Step= 500] | Loss=0.14652 | acc=0.9761 | tpr=0.9489 | fpr=0.0234 | 8339.7 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.14536 | acc=0.9763 | tpr=0.9487 | fpr=0.0232 | 14412.6 samples/s | 56.3 steps/s
Avg test loss: 0.14499, Avg test acc: 0.97630, Avg tpr: 0.94770, Avg fpr: 0.02318, total FA: 3218

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.15563 | acc=0.9762 | tpr=0.9336 | fpr=0.0231 | 5334.3 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.16301 | acc=0.9760 | tpr=0.9488 | fpr=0.0235 | 7336.8 samples/s | 28.7 steps/s
[Step= 150] | Loss=0.16869 | acc=0.9751 | tpr=0.9524 | fpr=0.0245 | 7628.7 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.17205 | acc=0.9750 | tpr=0.9585 | fpr=0.0247 | 8408.5 samples/s | 32.8 steps/s
[Step= 250] | Loss=0.16923 | acc=0.9756 | tpr=0.9598 | fpr=0.0242 | 7995.6 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.17231 | acc=0.9751 | tpr=0.9564 | fpr=0.0245 | 8131.6 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.17349 | acc=0.9749 | tpr=0.9568 | fpr=0.0248 | 8123.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.17516 | acc=0.9747 | tpr=0.9535 | fpr=0.0249 | 8167.1 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.17875 | acc=0.9743 | tpr=0.9537 | fpr=0.0253 | 8076.9 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.17808 | acc=0.9743 | tpr=0.9546 | fpr=0.0254 | 7925.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.17667 | acc=0.9744 | tpr=0.9542 | fpr=0.0252 | 14663.8 samples/s | 57.3 steps/s
Avg test loss: 0.17623, Avg test acc: 0.97445, Avg tpr: 0.95325, Avg fpr: 0.02516, total FA: 3494

server round 31/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=120.9] | Loss=0.00576 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=10.435 | 5909.3 samples/s | 92.3 steps/s
[Step=62050 Epoch=121.0] | Loss=0.00376 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.779 | L2-Norm(final)=10.437 | 5140.3 samples/s | 80.3 steps/s
[Step=62100 Epoch=121.1] | Loss=0.00420 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.779 | L2-Norm(final)=10.441 | 4943.1 samples/s | 77.2 steps/s
[Step=62150 Epoch=121.2] | Loss=0.00439 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.778 | L2-Norm(final)=10.445 | 5187.5 samples/s | 81.1 steps/s
[Step=62200 Epoch=121.3] | Loss=0.00456 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=10.448 | 5183.2 samples/s | 81.0 steps/s
[Step=62250 Epoch=121.4] | Loss=0.00439 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=10.452 | 5223.6 samples/s | 81.6 steps/s
[Step=62300 Epoch=121.5] | Loss=0.00423 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=10.455 | 5367.9 samples/s | 83.9 steps/s
[Step=62350 Epoch=121.6] | Loss=0.00434 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.776 | L2-Norm(final)=10.459 | 5035.6 samples/s | 78.7 steps/s
[Step=62400 Epoch=121.7] | Loss=0.00435 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.776 | L2-Norm(final)=10.462 | 5204.5 samples/s | 81.3 steps/s
[Step=62450 Epoch=121.8] | Loss=0.00445 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=10.466 | 5261.1 samples/s | 82.2 steps/s
[Step=62500 Epoch=121.9] | Loss=0.00450 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.775 | L2-Norm(final)=10.470 | 6945.6 samples/s | 108.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=121.9] | Loss=0.00232 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=10.507 | 6106.1 samples/s | 95.4 steps/s
[Step=62550 Epoch=122.0] | Loss=0.00489 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.770 | L2-Norm(final)=10.511 | 4273.6 samples/s | 66.8 steps/s
[Step=62600 Epoch=122.1] | Loss=0.00481 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.772 | L2-Norm(final)=10.514 | 4706.8 samples/s | 73.5 steps/s
[Step=62650 Epoch=122.2] | Loss=0.00511 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.775 | L2-Norm(final)=10.518 | 4562.7 samples/s | 71.3 steps/s
[Step=62700 Epoch=122.3] | Loss=0.00533 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.777 | L2-Norm(final)=10.521 | 4625.8 samples/s | 72.3 steps/s
[Step=62750 Epoch=122.4] | Loss=0.00530 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=10.524 | 4584.8 samples/s | 71.6 steps/s
[Step=62800 Epoch=122.5] | Loss=0.00545 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.779 | L2-Norm(final)=10.527 | 4556.0 samples/s | 71.2 steps/s
[Step=62850 Epoch=122.6] | Loss=0.00570 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.780 | L2-Norm(final)=10.530 | 4646.1 samples/s | 72.6 steps/s
[Step=62900 Epoch=122.7] | Loss=0.00569 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=10.533 | 4754.3 samples/s | 74.3 steps/s
[Step=62950 Epoch=122.8] | Loss=0.00584 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=10.535 | 4524.6 samples/s | 70.7 steps/s
[Step=63000 Epoch=122.9] | Loss=0.00588 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=10.538 | 5961.9 samples/s | 93.2 steps/s
[Step=63050 Epoch=123.0] | Loss=0.00579 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.782 | L2-Norm(final)=10.541 | 2447.5 samples/s | 38.2 steps/s
[Step=63100 Epoch=123.1] | Loss=0.00572 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=10.544 | 4619.2 samples/s | 72.2 steps/s
[Step=63150 Epoch=123.2] | Loss=0.00568 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.783 | L2-Norm(final)=10.547 | 4618.4 samples/s | 72.2 steps/s
[Step=63200 Epoch=123.3] | Loss=0.00582 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.783 | L2-Norm(final)=10.550 | 4589.8 samples/s | 71.7 steps/s
[Step=63250 Epoch=123.4] | Loss=0.00575 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.784 | L2-Norm(final)=10.553 | 4608.0 samples/s | 72.0 steps/s
[Step=63300 Epoch=123.5] | Loss=0.00568 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.784 | L2-Norm(final)=10.555 | 4648.8 samples/s | 72.6 steps/s
[Step=63350 Epoch=123.6] | Loss=0.00554 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.784 | L2-Norm(final)=10.558 | 4582.6 samples/s | 71.6 steps/s
[Step=63400 Epoch=123.7] | Loss=0.00539 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.784 | L2-Norm(final)=10.560 | 4664.1 samples/s | 72.9 steps/s
[Step=63450 Epoch=123.8] | Loss=0.00540 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.784 | L2-Norm(final)=10.563 | 4610.1 samples/s | 72.0 steps/s
[Step=63500 Epoch=123.8] | Loss=0.00537 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.783 | L2-Norm(final)=10.565 | 4934.6 samples/s | 77.1 steps/s
[Step=63550 Epoch=123.9] | Loss=0.00538 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=10.568 | 2664.7 samples/s | 41.6 steps/s
[Step=63600 Epoch=124.0] | Loss=0.00537 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=10.570 | 4595.8 samples/s | 71.8 steps/s
[Step=63650 Epoch=124.1] | Loss=0.00531 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.783 | L2-Norm(final)=10.572 | 4632.2 samples/s | 72.4 steps/s
[Step=63700 Epoch=124.2] | Loss=0.00526 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=10.575 | 4634.8 samples/s | 72.4 steps/s
[Step=63750 Epoch=124.3] | Loss=0.00522 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=10.577 | 4626.0 samples/s | 72.3 steps/s
[Step=63800 Epoch=124.4] | Loss=0.00520 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=10.580 | 4719.2 samples/s | 73.7 steps/s
[Step=63850 Epoch=124.5] | Loss=0.00521 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.781 | L2-Norm(final)=10.582 | 4535.1 samples/s | 70.9 steps/s
[Step=63900 Epoch=124.6] | Loss=0.00520 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.781 | L2-Norm(final)=10.584 | 4709.2 samples/s | 73.6 steps/s
[Step=63950 Epoch=124.7] | Loss=0.00518 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.780 | L2-Norm(final)=10.586 | 4549.0 samples/s | 71.1 steps/s
[Step=64000 Epoch=124.8] | Loss=0.00510 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.780 | L2-Norm(final)=10.589 | 4693.5 samples/s | 73.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step64000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=121.2] | Loss=0.00805 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.149 | L2-Norm(final)=10.950 | 6727.9 samples/s | 105.1 steps/s
[Step=62050 Epoch=121.3] | Loss=0.00352 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.149 | L2-Norm(final)=10.953 | 4494.7 samples/s | 70.2 steps/s
[Step=62100 Epoch=121.4] | Loss=0.00433 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.148 | L2-Norm(final)=10.957 | 5170.8 samples/s | 80.8 steps/s
[Step=62150 Epoch=121.5] | Loss=0.00451 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.147 | L2-Norm(final)=10.960 | 5162.8 samples/s | 80.7 steps/s
[Step=62200 Epoch=121.6] | Loss=0.00444 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=10.964 | 5173.6 samples/s | 80.8 steps/s
[Step=62250 Epoch=121.7] | Loss=0.00411 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=10.968 | 5183.2 samples/s | 81.0 steps/s
[Step=62300 Epoch=121.8] | Loss=0.00405 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.146 | L2-Norm(final)=10.971 | 5184.9 samples/s | 81.0 steps/s
[Step=62350 Epoch=121.9] | Loss=0.00417 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=10.975 | 5281.5 samples/s | 82.5 steps/s
[Step=62400 Epoch=122.0] | Loss=0.00422 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=10.979 | 5152.4 samples/s | 80.5 steps/s
[Step=62450 Epoch=122.1] | Loss=0.00421 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=10.982 | 5276.3 samples/s | 82.4 steps/s
[Step=62500 Epoch=122.2] | Loss=0.00412 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.143 | L2-Norm(final)=10.986 | 6933.1 samples/s | 108.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=122.2] | Loss=0.02744 | Reg=0.00260 | acc=0.9531 | L2-Norm=16.134 | L2-Norm(final)=11.021 | 6071.1 samples/s | 94.9 steps/s
[Step=62550 Epoch=122.3] | Loss=0.00648 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=11.024 | 4366.4 samples/s | 68.2 steps/s
[Step=62600 Epoch=122.4] | Loss=0.00574 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=11.027 | 4611.6 samples/s | 72.1 steps/s
[Step=62650 Epoch=122.5] | Loss=0.00597 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=11.031 | 4567.6 samples/s | 71.4 steps/s
[Step=62700 Epoch=122.6] | Loss=0.00539 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=11.034 | 4665.1 samples/s | 72.9 steps/s
[Step=62750 Epoch=122.7] | Loss=0.00525 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=11.037 | 4608.0 samples/s | 72.0 steps/s
[Step=62800 Epoch=122.8] | Loss=0.00530 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=11.040 | 4609.3 samples/s | 72.0 steps/s
[Step=62850 Epoch=122.9] | Loss=0.00543 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=11.043 | 4617.9 samples/s | 72.2 steps/s
[Step=62900 Epoch=123.0] | Loss=0.00542 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=11.046 | 4757.8 samples/s | 74.3 steps/s
[Step=62950 Epoch=123.1] | Loss=0.00555 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=11.048 | 4659.3 samples/s | 72.8 steps/s
[Step=63000 Epoch=123.2] | Loss=0.00534 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=11.051 | 5810.2 samples/s | 90.8 steps/s
[Step=63050 Epoch=123.3] | Loss=0.00532 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=11.054 | 2428.9 samples/s | 38.0 steps/s
[Step=63100 Epoch=123.4] | Loss=0.00525 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.140 | L2-Norm(final)=11.057 | 4613.6 samples/s | 72.1 steps/s
[Step=63150 Epoch=123.5] | Loss=0.00534 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.140 | L2-Norm(final)=11.059 | 4711.4 samples/s | 73.6 steps/s
[Step=63200 Epoch=123.6] | Loss=0.00522 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=11.061 | 4526.8 samples/s | 70.7 steps/s
[Step=63250 Epoch=123.7] | Loss=0.00527 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.140 | L2-Norm(final)=11.064 | 4663.5 samples/s | 72.9 steps/s
[Step=63300 Epoch=123.7] | Loss=0.00524 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=11.066 | 4627.8 samples/s | 72.3 steps/s
[Step=63350 Epoch=123.8] | Loss=0.00519 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=11.068 | 4596.5 samples/s | 71.8 steps/s
[Step=63400 Epoch=123.9] | Loss=0.00515 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.139 | L2-Norm(final)=11.071 | 4622.1 samples/s | 72.2 steps/s
[Step=63450 Epoch=124.0] | Loss=0.00508 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=11.073 | 4693.4 samples/s | 73.3 steps/s
[Step=63500 Epoch=124.1] | Loss=0.00508 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.138 | L2-Norm(final)=11.075 | 5061.5 samples/s | 79.1 steps/s
[Step=63550 Epoch=124.2] | Loss=0.00503 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.137 | L2-Norm(final)=11.078 | 2616.5 samples/s | 40.9 steps/s
[Step=63600 Epoch=124.3] | Loss=0.00494 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=11.080 | 4599.0 samples/s | 71.9 steps/s
[Step=63650 Epoch=124.4] | Loss=0.00492 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=11.082 | 4622.2 samples/s | 72.2 steps/s
[Step=63700 Epoch=124.5] | Loss=0.00491 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.135 | L2-Norm(final)=11.084 | 4598.8 samples/s | 71.9 steps/s
[Step=63750 Epoch=124.6] | Loss=0.00489 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=11.087 | 4606.7 samples/s | 72.0 steps/s
[Step=63800 Epoch=124.7] | Loss=0.00489 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=11.089 | 4628.9 samples/s | 72.3 steps/s
[Step=63850 Epoch=124.8] | Loss=0.00484 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.133 | L2-Norm(final)=11.091 | 4677.7 samples/s | 73.1 steps/s
[Step=63900 Epoch=124.9] | Loss=0.00483 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.132 | L2-Norm(final)=11.093 | 4603.3 samples/s | 71.9 steps/s
[Step=63950 Epoch=125.0] | Loss=0.00484 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.131 | L2-Norm(final)=11.095 | 4632.9 samples/s | 72.4 steps/s
[Step=64000 Epoch=125.1] | Loss=0.00486 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.130 | L2-Norm(final)=11.097 | 4683.5 samples/s | 73.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step64000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=237.6] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.970 | 5883.4 samples/s | 91.9 steps/s
[Step=62050 Epoch=237.8] | Loss=0.00003 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=7.980 | 4332.5 samples/s | 67.7 steps/s
[Step=62100 Epoch=237.9] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.997 | L2-Norm(final)=7.991 | 5025.5 samples/s | 78.5 steps/s
[Step=62150 Epoch=238.1] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.998 | L2-Norm(final)=8.000 | 4782.5 samples/s | 74.7 steps/s
[Step=62200 Epoch=238.3] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.999 | L2-Norm(final)=8.010 | 4885.9 samples/s | 76.3 steps/s
[Step=62250 Epoch=238.5] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=8.019 | 6880.3 samples/s | 107.5 steps/s
[Step=62300 Epoch=238.7] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.002 | L2-Norm(final)=8.029 | 2480.3 samples/s | 38.8 steps/s
[Step=62350 Epoch=238.9] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.003 | L2-Norm(final)=8.038 | 4908.6 samples/s | 76.7 steps/s
[Step=62400 Epoch=239.1] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.004 | L2-Norm(final)=8.047 | 4910.9 samples/s | 76.7 steps/s
[Step=62450 Epoch=239.3] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.004 | L2-Norm(final)=8.055 | 4793.7 samples/s | 74.9 steps/s
[Step=62500 Epoch=239.5] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.005 | L2-Norm(final)=8.063 | 5678.9 samples/s | 88.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=239.5] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=8.139 | 6479.0 samples/s | 101.2 steps/s
[Step=62550 Epoch=239.7] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.995 | L2-Norm(final)=8.146 | 3810.8 samples/s | 59.5 steps/s
[Step=62600 Epoch=239.9] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.983 | L2-Norm(final)=8.156 | 4406.8 samples/s | 68.9 steps/s
[Step=62650 Epoch=240.1] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.974 | L2-Norm(final)=8.165 | 4431.0 samples/s | 69.2 steps/s
[Step=62700 Epoch=240.2] | Loss=0.00010 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.970 | L2-Norm(final)=8.173 | 4383.8 samples/s | 68.5 steps/s
[Step=62750 Epoch=240.4] | Loss=0.00008 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.972 | L2-Norm(final)=8.179 | 5742.9 samples/s | 89.7 steps/s
[Step=62800 Epoch=240.6] | Loss=0.00007 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.972 | L2-Norm(final)=8.183 | 2320.7 samples/s | 36.3 steps/s
[Step=62850 Epoch=240.8] | Loss=0.00006 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.971 | L2-Norm(final)=8.186 | 4381.7 samples/s | 68.5 steps/s
[Step=62900 Epoch=241.0] | Loss=0.00005 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.969 | L2-Norm(final)=8.188 | 4452.1 samples/s | 69.6 steps/s
[Step=62950 Epoch=241.2] | Loss=0.00005 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.967 | L2-Norm(final)=8.190 | 4323.2 samples/s | 67.6 steps/s
[Step=63000 Epoch=241.4] | Loss=0.00004 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.965 | L2-Norm(final)=8.192 | 4980.8 samples/s | 77.8 steps/s
[Step=63050 Epoch=241.6] | Loss=0.00004 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.962 | L2-Norm(final)=8.194 | 2506.0 samples/s | 39.2 steps/s
[Step=63100 Epoch=241.8] | Loss=0.00004 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.959 | L2-Norm(final)=8.195 | 4349.6 samples/s | 68.0 steps/s
[Step=63150 Epoch=242.0] | Loss=0.00004 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.956 | L2-Norm(final)=8.196 | 4379.4 samples/s | 68.4 steps/s
[Step=63200 Epoch=242.2] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.953 | L2-Norm(final)=8.197 | 4418.4 samples/s | 69.0 steps/s
[Step=63250 Epoch=242.4] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.950 | L2-Norm(final)=8.199 | 4377.9 samples/s | 68.4 steps/s
[Step=63300 Epoch=242.5] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.947 | L2-Norm(final)=8.199 | 2679.8 samples/s | 41.9 steps/s
[Step=63350 Epoch=242.7] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.944 | L2-Norm(final)=8.200 | 4389.2 samples/s | 68.6 steps/s
[Step=63400 Epoch=242.9] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.940 | L2-Norm(final)=8.201 | 4398.5 samples/s | 68.7 steps/s
[Step=63450 Epoch=243.1] | Loss=0.00003 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.937 | L2-Norm(final)=8.202 | 4319.8 samples/s | 67.5 steps/s
[Step=63500 Epoch=243.3] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.933 | L2-Norm(final)=8.203 | 4391.6 samples/s | 68.6 steps/s
[Step=63550 Epoch=243.5] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.929 | L2-Norm(final)=8.204 | 2677.9 samples/s | 41.8 steps/s
[Step=63600 Epoch=243.7] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.926 | L2-Norm(final)=8.205 | 4353.8 samples/s | 68.0 steps/s
[Step=63650 Epoch=243.9] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.922 | L2-Norm(final)=8.205 | 4401.3 samples/s | 68.8 steps/s
[Step=63700 Epoch=244.1] | Loss=0.00002 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.918 | L2-Norm(final)=8.206 | 4412.2 samples/s | 68.9 steps/s
[Step=63750 Epoch=244.3] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.914 | L2-Norm(final)=8.207 | 4337.0 samples/s | 67.8 steps/s
[Step=63800 Epoch=244.5] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.910 | L2-Norm(final)=8.207 | 6530.7 samples/s | 102.0 steps/s
[Step=63850 Epoch=244.7] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.906 | L2-Norm(final)=8.208 | 2240.0 samples/s | 35.0 steps/s
[Step=63900 Epoch=244.8] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.902 | L2-Norm(final)=8.209 | 4447.1 samples/s | 69.5 steps/s
[Step=63950 Epoch=245.0] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.897 | L2-Norm(final)=8.210 | 4349.4 samples/s | 68.0 steps/s
[Step=64000 Epoch=245.2] | Loss=0.00002 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.893 | L2-Norm(final)=8.210 | 4408.5 samples/s | 68.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step64000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=238.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.076 | L2-Norm(final)=7.877 | 6283.9 samples/s | 98.2 steps/s
[Step=62050 Epoch=238.9] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.881 | 4333.7 samples/s | 67.7 steps/s
[Step=62100 Epoch=239.0] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.081 | L2-Norm(final)=7.888 | 4929.6 samples/s | 77.0 steps/s
[Step=62150 Epoch=239.2] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.082 | L2-Norm(final)=7.894 | 4848.5 samples/s | 75.8 steps/s
[Step=62200 Epoch=239.4] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.083 | L2-Norm(final)=7.900 | 4892.8 samples/s | 76.4 steps/s
[Step=62250 Epoch=239.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.083 | L2-Norm(final)=7.905 | 6956.2 samples/s | 108.7 steps/s
[Step=62300 Epoch=239.8] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.910 | 2438.9 samples/s | 38.1 steps/s
[Step=62350 Epoch=240.0] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.916 | 4940.4 samples/s | 77.2 steps/s
[Step=62400 Epoch=240.2] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.921 | 4902.6 samples/s | 76.6 steps/s
[Step=62450 Epoch=240.4] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.926 | 4929.6 samples/s | 77.0 steps/s
[Step=62500 Epoch=240.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.931 | 5751.9 samples/s | 89.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=240.6] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.084 | L2-Norm(final)=7.983 | 6641.1 samples/s | 103.8 steps/s
[Step=62550 Epoch=240.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=7.988 | 3773.5 samples/s | 59.0 steps/s
[Step=62600 Epoch=241.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.070 | L2-Norm(final)=7.992 | 4358.7 samples/s | 68.1 steps/s
[Step=62650 Epoch=241.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.060 | L2-Norm(final)=7.996 | 4380.0 samples/s | 68.4 steps/s
[Step=62700 Epoch=241.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.050 | L2-Norm(final)=7.999 | 4375.8 samples/s | 68.4 steps/s
[Step=62750 Epoch=241.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=8.003 | 5961.2 samples/s | 93.1 steps/s
[Step=62800 Epoch=241.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.030 | L2-Norm(final)=8.006 | 2320.6 samples/s | 36.3 steps/s
[Step=62850 Epoch=241.9] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.020 | L2-Norm(final)=8.009 | 4382.4 samples/s | 68.5 steps/s
[Step=62900 Epoch=242.1] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.009 | L2-Norm(final)=8.011 | 4410.3 samples/s | 68.9 steps/s
[Step=62950 Epoch=242.3] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.998 | L2-Norm(final)=8.014 | 4344.4 samples/s | 67.9 steps/s
[Step=63000 Epoch=242.5] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.987 | L2-Norm(final)=8.016 | 5109.3 samples/s | 79.8 steps/s
[Step=63050 Epoch=242.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.976 | L2-Norm(final)=8.019 | 2476.2 samples/s | 38.7 steps/s
[Step=63100 Epoch=242.9] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.965 | L2-Norm(final)=8.021 | 4407.3 samples/s | 68.9 steps/s
[Step=63150 Epoch=243.1] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.954 | L2-Norm(final)=8.023 | 4466.8 samples/s | 69.8 steps/s
[Step=63200 Epoch=243.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.942 | L2-Norm(final)=8.026 | 4308.0 samples/s | 67.3 steps/s
[Step=63250 Epoch=243.5] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.930 | L2-Norm(final)=8.028 | 4445.4 samples/s | 69.5 steps/s
[Step=63300 Epoch=243.7] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.919 | L2-Norm(final)=8.030 | 2657.4 samples/s | 41.5 steps/s
[Step=63350 Epoch=243.9] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.907 | L2-Norm(final)=8.033 | 4483.4 samples/s | 70.1 steps/s
[Step=63400 Epoch=244.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.895 | L2-Norm(final)=8.035 | 4237.5 samples/s | 66.2 steps/s
[Step=63450 Epoch=244.2] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.883 | L2-Norm(final)=8.038 | 4412.0 samples/s | 68.9 steps/s
[Step=63500 Epoch=244.4] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.871 | L2-Norm(final)=8.040 | 4415.1 samples/s | 69.0 steps/s
[Step=63550 Epoch=244.6] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.858 | L2-Norm(final)=8.042 | 2708.5 samples/s | 42.3 steps/s
[Step=63600 Epoch=244.8] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.846 | L2-Norm(final)=8.045 | 4397.5 samples/s | 68.7 steps/s
[Step=63650 Epoch=245.0] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.834 | L2-Norm(final)=8.047 | 4247.2 samples/s | 66.4 steps/s
[Step=63700 Epoch=245.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.821 | L2-Norm(final)=8.050 | 4411.7 samples/s | 68.9 steps/s
[Step=63750 Epoch=245.4] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.808 | L2-Norm(final)=8.053 | 4429.0 samples/s | 69.2 steps/s
[Step=63800 Epoch=245.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.795 | L2-Norm(final)=8.055 | 7094.3 samples/s | 110.8 steps/s
[Step=63850 Epoch=245.8] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.782 | L2-Norm(final)=8.058 | 2163.7 samples/s | 33.8 steps/s
[Step=63900 Epoch=246.0] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.769 | L2-Norm(final)=8.061 | 4461.5 samples/s | 69.7 steps/s
[Step=63950 Epoch=246.2] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.756 | L2-Norm(final)=8.064 | 4280.2 samples/s | 66.9 steps/s
[Step=64000 Epoch=246.4] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.743 | L2-Norm(final)=8.067 | 4426.7 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.09298 | acc=0.9688 | tpr=0.9776 | fpr=0.0505 | 5235.8 samples/s | 20.5 steps/s
Avg test loss: 0.09499, Avg test acc: 0.96678, Avg tpr: 0.97616, Avg fpr: 0.05384, total FA: 420

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08486 | acc=0.9689 | tpr=0.9767 | fpr=0.0481 | 5260.1 samples/s | 20.5 steps/s
Avg test loss: 0.08721, Avg test acc: 0.96887, Avg tpr: 0.97639, Avg fpr: 0.04769, total FA: 372

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.61095 | acc=0.3104 | tpr=0.0073 | fpr=0.0315 | 5463.5 samples/s | 21.3 steps/s
Avg test loss: 5.62341, Avg test acc: 0.30900, Avg tpr: 0.00694, Avg fpr: 0.02666, total FA: 208

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.12130 | acc=0.3049 | tpr=0.0102 | fpr=0.0550 | 5361.3 samples/s | 20.9 steps/s
Avg test loss: 5.12296, Avg test acc: 0.30407, Avg tpr: 0.00997, Avg fpr: 0.04910, total FA: 383

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.82788 | acc=0.1251 | tpr=0.7478 | fpr=0.8861 | 5288.7 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.79932 | acc=0.1252 | tpr=0.7441 | fpr=0.8864 | 7080.4 samples/s | 27.7 steps/s
[Step= 150] | Loss=6.79759 | acc=0.1264 | tpr=0.7579 | fpr=0.8852 | 8038.5 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.81282 | acc=0.1253 | tpr=0.7508 | fpr=0.8861 | 8093.3 samples/s | 31.6 steps/s
[Step= 250] | Loss=6.81934 | acc=0.1257 | tpr=0.7459 | fpr=0.8856 | 7941.9 samples/s | 31.0 steps/s
[Step= 300] | Loss=6.81727 | acc=0.1257 | tpr=0.7469 | fpr=0.8856 | 8420.3 samples/s | 32.9 steps/s
[Step= 350] | Loss=6.80271 | acc=0.1259 | tpr=0.7470 | fpr=0.8853 | 7969.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=6.79386 | acc=0.1265 | tpr=0.7505 | fpr=0.8848 | 8340.2 samples/s | 32.6 steps/s
[Step= 450] | Loss=6.79449 | acc=0.1261 | tpr=0.7527 | fpr=0.8853 | 8222.6 samples/s | 32.1 steps/s
[Step= 500] | Loss=6.79402 | acc=0.1257 | tpr=0.7498 | fpr=0.8855 | 7967.8 samples/s | 31.1 steps/s
[Step= 550] | Loss=6.79238 | acc=0.1259 | tpr=0.7457 | fpr=0.8854 | 15077.7 samples/s | 58.9 steps/s
Avg test loss: 6.79341, Avg test acc: 0.12583, Avg tpr: 0.74564, Avg fpr: 0.88544, total FA: 122941

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=7.14635 | acc=0.1291 | tpr=0.7301 | fpr=0.8817 | 5397.1 samples/s | 21.1 steps/s
[Step= 100] | Loss=7.12085 | acc=0.1294 | tpr=0.7143 | fpr=0.8815 | 7049.4 samples/s | 27.5 steps/s
[Step= 150] | Loss=7.11299 | acc=0.1303 | tpr=0.7233 | fpr=0.8807 | 7646.5 samples/s | 29.9 steps/s
[Step= 200] | Loss=7.12349 | acc=0.1293 | tpr=0.7246 | fpr=0.8816 | 8338.4 samples/s | 32.6 steps/s
[Step= 250] | Loss=7.12823 | acc=0.1299 | tpr=0.7231 | fpr=0.8809 | 8008.3 samples/s | 31.3 steps/s
[Step= 300] | Loss=7.13022 | acc=0.1296 | tpr=0.7222 | fpr=0.8812 | 8338.5 samples/s | 32.6 steps/s
[Step= 350] | Loss=7.11445 | acc=0.1296 | tpr=0.7207 | fpr=0.8811 | 7957.4 samples/s | 31.1 steps/s
[Step= 400] | Loss=7.10519 | acc=0.1301 | tpr=0.7226 | fpr=0.8807 | 7847.3 samples/s | 30.7 steps/s
[Step= 450] | Loss=7.10273 | acc=0.1296 | tpr=0.7220 | fpr=0.8812 | 8327.5 samples/s | 32.5 steps/s
[Step= 500] | Loss=7.10587 | acc=0.1292 | tpr=0.7203 | fpr=0.8815 | 8185.2 samples/s | 32.0 steps/s
[Step= 550] | Loss=7.10361 | acc=0.1296 | tpr=0.7155 | fpr=0.8811 | 14304.6 samples/s | 55.9 steps/s
Avg test loss: 7.10506, Avg test acc: 0.12954, Avg tpr: 0.71553, Avg fpr: 0.88111, total FA: 122340

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13334 | acc=0.9788 | tpr=0.9292 | fpr=0.0204 | 5421.8 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.13954 | acc=0.9783 | tpr=0.9488 | fpr=0.0212 | 6960.1 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.14521 | acc=0.9772 | tpr=0.9467 | fpr=0.0223 | 7389.8 samples/s | 28.9 steps/s
[Step= 200] | Loss=0.14711 | acc=0.9772 | tpr=0.9475 | fpr=0.0223 | 8325.4 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.14489 | acc=0.9775 | tpr=0.9476 | fpr=0.0220 | 8140.9 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.14730 | acc=0.9771 | tpr=0.9447 | fpr=0.0223 | 8348.8 samples/s | 32.6 steps/s
[Step= 350] | Loss=0.14789 | acc=0.9769 | tpr=0.9474 | fpr=0.0226 | 7914.9 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.14945 | acc=0.9767 | tpr=0.9453 | fpr=0.0227 | 8299.8 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.15250 | acc=0.9764 | tpr=0.9460 | fpr=0.0230 | 8055.4 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.15200 | acc=0.9764 | tpr=0.9463 | fpr=0.0230 | 8058.4 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.15100 | acc=0.9766 | tpr=0.9459 | fpr=0.0229 | 14528.1 samples/s | 56.8 steps/s
Avg test loss: 0.15061, Avg test acc: 0.97657, Avg tpr: 0.94493, Avg fpr: 0.02285, total FA: 3173

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.14855 | acc=0.9773 | tpr=0.9425 | fpr=0.0220 | 5187.4 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.15544 | acc=0.9767 | tpr=0.9510 | fpr=0.0228 | 7109.6 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.16091 | acc=0.9755 | tpr=0.9553 | fpr=0.0241 | 7891.4 samples/s | 30.8 steps/s
[Step= 200] | Loss=0.16384 | acc=0.9754 | tpr=0.9585 | fpr=0.0243 | 8068.6 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.16099 | acc=0.9758 | tpr=0.9598 | fpr=0.0239 | 8242.9 samples/s | 32.2 steps/s
[Step= 300] | Loss=0.16385 | acc=0.9754 | tpr=0.9585 | fpr=0.0242 | 8161.3 samples/s | 31.9 steps/s
[Step= 350] | Loss=0.16496 | acc=0.9752 | tpr=0.9587 | fpr=0.0245 | 8425.7 samples/s | 32.9 steps/s
[Step= 400] | Loss=0.16642 | acc=0.9750 | tpr=0.9546 | fpr=0.0246 | 7711.9 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.16979 | acc=0.9746 | tpr=0.9547 | fpr=0.0250 | 8389.5 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.16912 | acc=0.9746 | tpr=0.9555 | fpr=0.0250 | 8075.9 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.16775 | acc=0.9748 | tpr=0.9546 | fpr=0.0248 | 14460.1 samples/s | 56.5 steps/s
Avg test loss: 0.16732, Avg test acc: 0.97481, Avg tpr: 0.95365, Avg fpr: 0.02480, total FA: 3444

server round 32/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=124.8] | Loss=0.01147 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.599 | L2-Norm(final)=10.657 | 6319.4 samples/s | 98.7 steps/s
[Step=64050 Epoch=124.9] | Loss=0.00581 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.599 | L2-Norm(final)=10.661 | 4652.4 samples/s | 72.7 steps/s
[Step=64100 Epoch=125.0] | Loss=0.00512 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.599 | L2-Norm(final)=10.665 | 5166.3 samples/s | 80.7 steps/s
[Step=64150 Epoch=125.1] | Loss=0.00562 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.669 | 5084.2 samples/s | 79.4 steps/s
[Step=64200 Epoch=125.2] | Loss=0.00517 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.599 | L2-Norm(final)=10.674 | 4941.9 samples/s | 77.2 steps/s
[Step=64250 Epoch=125.3] | Loss=0.00490 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.679 | 5118.9 samples/s | 80.0 steps/s
[Step=64300 Epoch=125.4] | Loss=0.00488 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.683 | 5110.9 samples/s | 79.9 steps/s
[Step=64350 Epoch=125.5] | Loss=0.00499 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.687 | 5158.2 samples/s | 80.6 steps/s
[Step=64400 Epoch=125.6] | Loss=0.00490 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.692 | 5209.0 samples/s | 81.4 steps/s
[Step=64450 Epoch=125.7] | Loss=0.00494 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.696 | 5284.5 samples/s | 82.6 steps/s
[Step=64500 Epoch=125.8] | Loss=0.00490 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.599 | L2-Norm(final)=10.701 | 6858.5 samples/s | 107.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=125.8] | Loss=0.00114 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.600 | L2-Norm(final)=10.745 | 6891.9 samples/s | 107.7 steps/s
[Step=64550 Epoch=125.9] | Loss=0.00502 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=10.749 | 4045.0 samples/s | 63.2 steps/s
[Step=64600 Epoch=126.0] | Loss=0.00553 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.604 | L2-Norm(final)=10.753 | 4525.2 samples/s | 70.7 steps/s
[Step=64650 Epoch=126.1] | Loss=0.00558 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.606 | L2-Norm(final)=10.757 | 4741.4 samples/s | 74.1 steps/s
[Step=64700 Epoch=126.2] | Loss=0.00597 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.608 | L2-Norm(final)=10.761 | 4487.7 samples/s | 70.1 steps/s
[Step=64750 Epoch=126.3] | Loss=0.00580 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.609 | L2-Norm(final)=10.764 | 4635.0 samples/s | 72.4 steps/s
[Step=64800 Epoch=126.4] | Loss=0.00592 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.610 | L2-Norm(final)=10.767 | 4669.7 samples/s | 73.0 steps/s
[Step=64850 Epoch=126.5] | Loss=0.00601 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.611 | L2-Norm(final)=10.769 | 4705.0 samples/s | 73.5 steps/s
[Step=64900 Epoch=126.6] | Loss=0.00594 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.612 | L2-Norm(final)=10.772 | 4543.7 samples/s | 71.0 steps/s
[Step=64950 Epoch=126.7] | Loss=0.00580 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.613 | L2-Norm(final)=10.775 | 4615.9 samples/s | 72.1 steps/s
[Step=65000 Epoch=126.8] | Loss=0.00599 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.614 | L2-Norm(final)=10.777 | 5956.2 samples/s | 93.1 steps/s
[Step=65050 Epoch=126.9] | Loss=0.00617 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.614 | L2-Norm(final)=10.780 | 2471.2 samples/s | 38.6 steps/s
[Step=65100 Epoch=127.0] | Loss=0.00613 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.615 | L2-Norm(final)=10.782 | 4542.8 samples/s | 71.0 steps/s
[Step=65150 Epoch=127.1] | Loss=0.00600 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.616 | L2-Norm(final)=10.785 | 4600.1 samples/s | 71.9 steps/s
[Step=65200 Epoch=127.2] | Loss=0.00588 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.616 | L2-Norm(final)=10.787 | 4576.2 samples/s | 71.5 steps/s
[Step=65250 Epoch=127.3] | Loss=0.00578 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.616 | L2-Norm(final)=10.790 | 4660.0 samples/s | 72.8 steps/s
[Step=65300 Epoch=127.4] | Loss=0.00572 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.617 | L2-Norm(final)=10.793 | 4581.4 samples/s | 71.6 steps/s
[Step=65350 Epoch=127.5] | Loss=0.00562 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.617 | L2-Norm(final)=10.795 | 4675.1 samples/s | 73.0 steps/s
[Step=65400 Epoch=127.6] | Loss=0.00561 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.798 | 4588.4 samples/s | 71.7 steps/s
[Step=65450 Epoch=127.7] | Loss=0.00556 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.801 | 4604.5 samples/s | 71.9 steps/s
[Step=65500 Epoch=127.8] | Loss=0.00558 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.618 | L2-Norm(final)=10.803 | 4993.7 samples/s | 78.0 steps/s
[Step=65550 Epoch=127.8] | Loss=0.00555 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.806 | 2668.7 samples/s | 41.7 steps/s
[Step=65600 Epoch=127.9] | Loss=0.00551 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.808 | 4569.0 samples/s | 71.4 steps/s
[Step=65650 Epoch=128.0] | Loss=0.00540 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.811 | 4680.7 samples/s | 73.1 steps/s
[Step=65700 Epoch=128.1] | Loss=0.00534 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.813 | 4588.4 samples/s | 71.7 steps/s
[Step=65750 Epoch=128.2] | Loss=0.00529 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.816 | 4603.2 samples/s | 71.9 steps/s
[Step=65800 Epoch=128.3] | Loss=0.00524 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.818 | 4667.5 samples/s | 72.9 steps/s
[Step=65850 Epoch=128.4] | Loss=0.00527 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.618 | L2-Norm(final)=10.821 | 4605.7 samples/s | 72.0 steps/s
[Step=65900 Epoch=128.5] | Loss=0.00528 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.823 | 4672.9 samples/s | 73.0 steps/s
[Step=65950 Epoch=128.6] | Loss=0.00530 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.825 | 4582.0 samples/s | 71.6 steps/s
[Step=66000 Epoch=128.7] | Loss=0.00527 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.618 | L2-Norm(final)=10.828 | 4619.3 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step66000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=125.1] | Loss=0.00396 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=11.159 | 6486.3 samples/s | 101.3 steps/s
[Step=64050 Epoch=125.2] | Loss=0.00633 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.946 | L2-Norm(final)=11.163 | 4575.5 samples/s | 71.5 steps/s
[Step=64100 Epoch=125.3] | Loss=0.00545 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.947 | L2-Norm(final)=11.168 | 5399.2 samples/s | 84.4 steps/s
[Step=64150 Epoch=125.4] | Loss=0.00485 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.948 | L2-Norm(final)=11.173 | 5128.2 samples/s | 80.1 steps/s
[Step=64200 Epoch=125.5] | Loss=0.00470 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=11.178 | 5150.6 samples/s | 80.5 steps/s
[Step=64250 Epoch=125.6] | Loss=0.00480 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.949 | L2-Norm(final)=11.183 | 5205.3 samples/s | 81.3 steps/s
[Step=64300 Epoch=125.7] | Loss=0.00479 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.949 | L2-Norm(final)=11.188 | 5130.6 samples/s | 80.2 steps/s
[Step=64350 Epoch=125.8] | Loss=0.00489 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=11.193 | 5191.0 samples/s | 81.1 steps/s
[Step=64400 Epoch=125.9] | Loss=0.00478 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.950 | L2-Norm(final)=11.198 | 5302.2 samples/s | 82.8 steps/s
[Step=64450 Epoch=126.0] | Loss=0.00481 | Reg=0.00254 | acc=0.9844 | L2-Norm=15.951 | L2-Norm(final)=11.203 | 5119.1 samples/s | 80.0 steps/s
[Step=64500 Epoch=126.1] | Loss=0.00478 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.951 | L2-Norm(final)=11.207 | 7136.5 samples/s | 111.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=126.1] | Loss=0.00099 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=11.253 | 6240.9 samples/s | 97.5 steps/s
[Step=64550 Epoch=126.2] | Loss=0.00500 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.956 | L2-Norm(final)=11.258 | 4272.2 samples/s | 66.8 steps/s
[Step=64600 Epoch=126.3] | Loss=0.00508 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.958 | L2-Norm(final)=11.262 | 4522.4 samples/s | 70.7 steps/s
[Step=64650 Epoch=126.4] | Loss=0.00573 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.960 | L2-Norm(final)=11.266 | 4635.1 samples/s | 72.4 steps/s
[Step=64700 Epoch=126.5] | Loss=0.00572 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.961 | L2-Norm(final)=11.269 | 4591.7 samples/s | 71.7 steps/s
[Step=64750 Epoch=126.6] | Loss=0.00565 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.962 | L2-Norm(final)=11.272 | 4678.1 samples/s | 73.1 steps/s
[Step=64800 Epoch=126.7] | Loss=0.00576 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.963 | L2-Norm(final)=11.275 | 4555.4 samples/s | 71.2 steps/s
[Step=64850 Epoch=126.8] | Loss=0.00573 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=11.279 | 4627.6 samples/s | 72.3 steps/s
[Step=64900 Epoch=126.9] | Loss=0.00573 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=11.282 | 4658.5 samples/s | 72.8 steps/s
[Step=64950 Epoch=127.0] | Loss=0.00570 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=11.285 | 4620.8 samples/s | 72.2 steps/s
[Step=65000 Epoch=127.1] | Loss=0.00570 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=11.287 | 6019.6 samples/s | 94.1 steps/s
[Step=65050 Epoch=127.2] | Loss=0.00561 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=11.290 | 2429.5 samples/s | 38.0 steps/s
[Step=65100 Epoch=127.3] | Loss=0.00547 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=11.293 | 4614.4 samples/s | 72.1 steps/s
[Step=65150 Epoch=127.4] | Loss=0.00552 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.296 | 4591.5 samples/s | 71.7 steps/s
[Step=65200 Epoch=127.5] | Loss=0.00550 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.299 | 4635.9 samples/s | 72.4 steps/s
[Step=65250 Epoch=127.6] | Loss=0.00551 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.301 | 4632.6 samples/s | 72.4 steps/s
[Step=65300 Epoch=127.7] | Loss=0.00545 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.304 | 4685.2 samples/s | 73.2 steps/s
[Step=65350 Epoch=127.8] | Loss=0.00549 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.307 | 4630.5 samples/s | 72.4 steps/s
[Step=65400 Epoch=127.9] | Loss=0.00540 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.309 | 4540.3 samples/s | 70.9 steps/s
[Step=65450 Epoch=128.0] | Loss=0.00537 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.312 | 4664.0 samples/s | 72.9 steps/s
[Step=65500 Epoch=128.1] | Loss=0.00549 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.967 | L2-Norm(final)=11.314 | 5092.9 samples/s | 79.6 steps/s
[Step=65550 Epoch=128.1] | Loss=0.00537 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.967 | L2-Norm(final)=11.317 | 2642.5 samples/s | 41.3 steps/s
[Step=65600 Epoch=128.2] | Loss=0.00534 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.967 | L2-Norm(final)=11.319 | 4577.1 samples/s | 71.5 steps/s
[Step=65650 Epoch=128.3] | Loss=0.00527 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.966 | L2-Norm(final)=11.321 | 4676.0 samples/s | 73.1 steps/s
[Step=65700 Epoch=128.4] | Loss=0.00517 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=11.324 | 4564.0 samples/s | 71.3 steps/s
[Step=65750 Epoch=128.5] | Loss=0.00516 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=11.326 | 4663.4 samples/s | 72.9 steps/s
[Step=65800 Epoch=128.6] | Loss=0.00514 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.966 | L2-Norm(final)=11.328 | 4608.7 samples/s | 72.0 steps/s
[Step=65850 Epoch=128.7] | Loss=0.00511 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=11.331 | 4609.0 samples/s | 72.0 steps/s
[Step=65900 Epoch=128.8] | Loss=0.00513 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.965 | L2-Norm(final)=11.333 | 4641.0 samples/s | 72.5 steps/s
[Step=65950 Epoch=128.9] | Loss=0.00510 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=11.335 | 4645.4 samples/s | 72.6 steps/s
[Step=66000 Epoch=129.0] | Loss=0.00507 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.964 | L2-Norm(final)=11.337 | 4613.0 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step66000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=245.2] | Loss=0.00002 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.812 | L2-Norm(final)=8.231 | 6120.2 samples/s | 95.6 steps/s
[Step=64050 Epoch=245.4] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.233 | 4562.2 samples/s | 71.3 steps/s
[Step=64100 Epoch=245.6] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.235 | 4759.8 samples/s | 74.4 steps/s
[Step=64150 Epoch=245.8] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.238 | 4870.9 samples/s | 76.1 steps/s
[Step=64200 Epoch=246.0] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.240 | 4910.2 samples/s | 76.7 steps/s
[Step=64250 Epoch=246.2] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.242 | 6790.6 samples/s | 106.1 steps/s
[Step=64300 Epoch=246.4] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.244 | 2453.1 samples/s | 38.3 steps/s
[Step=64350 Epoch=246.6] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.246 | 4930.1 samples/s | 77.0 steps/s
[Step=64400 Epoch=246.8] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.248 | 4814.0 samples/s | 75.2 steps/s
[Step=64450 Epoch=246.9] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.251 | 4894.6 samples/s | 76.5 steps/s
[Step=64500 Epoch=247.1] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.811 | L2-Norm(final)=8.253 | 5682.3 samples/s | 88.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=247.1] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.809 | L2-Norm(final)=8.275 | 6067.9 samples/s | 94.8 steps/s
[Step=64550 Epoch=247.3] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.805 | L2-Norm(final)=8.277 | 4051.6 samples/s | 63.3 steps/s
[Step=64600 Epoch=247.5] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.799 | L2-Norm(final)=8.279 | 4301.9 samples/s | 67.2 steps/s
[Step=64650 Epoch=247.7] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.793 | L2-Norm(final)=8.281 | 4347.9 samples/s | 67.9 steps/s
[Step=64700 Epoch=247.9] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.786 | L2-Norm(final)=8.283 | 4370.4 samples/s | 68.3 steps/s
[Step=64750 Epoch=248.1] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.779 | L2-Norm(final)=8.285 | 5896.4 samples/s | 92.1 steps/s
[Step=64800 Epoch=248.3] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.772 | L2-Norm(final)=8.287 | 2322.6 samples/s | 36.3 steps/s
[Step=64850 Epoch=248.5] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.765 | L2-Norm(final)=8.289 | 4379.1 samples/s | 68.4 steps/s
[Step=64900 Epoch=248.7] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.757 | L2-Norm(final)=8.290 | 4432.6 samples/s | 69.3 steps/s
[Step=64950 Epoch=248.9] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.750 | L2-Norm(final)=8.292 | 4385.2 samples/s | 68.5 steps/s
[Step=65000 Epoch=249.1] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.742 | L2-Norm(final)=8.293 | 4958.0 samples/s | 77.5 steps/s
[Step=65050 Epoch=249.2] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.734 | L2-Norm(final)=8.295 | 2490.2 samples/s | 38.9 steps/s
[Step=65100 Epoch=249.4] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.727 | L2-Norm(final)=8.297 | 4385.9 samples/s | 68.5 steps/s
[Step=65150 Epoch=249.6] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.719 | L2-Norm(final)=8.298 | 4447.0 samples/s | 69.5 steps/s
[Step=65200 Epoch=249.8] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=8.300 | 4305.7 samples/s | 67.3 steps/s
[Step=65250 Epoch=250.0] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.703 | L2-Norm(final)=8.301 | 4412.1 samples/s | 68.9 steps/s
[Step=65300 Epoch=250.2] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.694 | L2-Norm(final)=8.303 | 2697.3 samples/s | 42.1 steps/s
[Step=65350 Epoch=250.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.686 | L2-Norm(final)=8.304 | 4303.6 samples/s | 67.2 steps/s
[Step=65400 Epoch=250.6] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.678 | L2-Norm(final)=8.306 | 4434.3 samples/s | 69.3 steps/s
[Step=65450 Epoch=250.8] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.669 | L2-Norm(final)=8.307 | 4362.9 samples/s | 68.2 steps/s
[Step=65500 Epoch=251.0] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.661 | L2-Norm(final)=8.309 | 4419.9 samples/s | 69.1 steps/s
[Step=65550 Epoch=251.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.652 | L2-Norm(final)=8.310 | 2670.1 samples/s | 41.7 steps/s
[Step=65600 Epoch=251.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.643 | L2-Norm(final)=8.312 | 4364.5 samples/s | 68.2 steps/s
[Step=65650 Epoch=251.5] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.634 | L2-Norm(final)=8.313 | 4431.0 samples/s | 69.2 steps/s
[Step=65700 Epoch=251.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.625 | L2-Norm(final)=8.315 | 4489.7 samples/s | 70.2 steps/s
[Step=65750 Epoch=251.9] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.616 | L2-Norm(final)=8.317 | 4287.4 samples/s | 67.0 steps/s
[Step=65800 Epoch=252.1] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.607 | L2-Norm(final)=8.318 | 6436.3 samples/s | 100.6 steps/s
[Step=65850 Epoch=252.3] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.598 | L2-Norm(final)=8.320 | 2253.4 samples/s | 35.2 steps/s
[Step=65900 Epoch=252.5] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.588 | L2-Norm(final)=8.322 | 4391.3 samples/s | 68.6 steps/s
[Step=65950 Epoch=252.7] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.579 | L2-Norm(final)=8.323 | 4440.3 samples/s | 69.4 steps/s
[Step=66000 Epoch=252.9] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.569 | L2-Norm(final)=8.325 | 4245.2 samples/s | 66.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step66000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=246.4] | Loss=0.00003 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.802 | L2-Norm(final)=8.155 | 5889.3 samples/s | 92.0 steps/s
[Step=64050 Epoch=246.6] | Loss=0.00003 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.804 | L2-Norm(final)=8.172 | 4327.5 samples/s | 67.6 steps/s
[Step=64100 Epoch=246.7] | Loss=0.00008 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.813 | L2-Norm(final)=8.189 | 4886.8 samples/s | 76.4 steps/s
[Step=64150 Epoch=246.9] | Loss=0.00007 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.828 | L2-Norm(final)=8.203 | 4823.7 samples/s | 75.4 steps/s
[Step=64200 Epoch=247.1] | Loss=0.00007 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.835 | L2-Norm(final)=8.212 | 4914.0 samples/s | 76.8 steps/s
[Step=64250 Epoch=247.3] | Loss=0.00008 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.842 | L2-Norm(final)=8.218 | 6965.6 samples/s | 108.8 steps/s
[Step=64300 Epoch=247.5] | Loss=0.00007 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.847 | L2-Norm(final)=8.224 | 2470.8 samples/s | 38.6 steps/s
[Step=64350 Epoch=247.7] | Loss=0.00006 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.851 | L2-Norm(final)=8.229 | 4801.4 samples/s | 75.0 steps/s
[Step=64400 Epoch=247.9] | Loss=0.00005 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.854 | L2-Norm(final)=8.233 | 4962.8 samples/s | 77.5 steps/s
[Step=64450 Epoch=248.1] | Loss=0.00005 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.855 | L2-Norm(final)=8.236 | 4791.0 samples/s | 74.9 steps/s
[Step=64500 Epoch=248.3] | Loss=0.00004 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.857 | L2-Norm(final)=8.239 | 5888.6 samples/s | 92.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=248.3] | Loss=0.00001 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.868 | L2-Norm(final)=8.266 | 5537.5 samples/s | 86.5 steps/s
[Step=64550 Epoch=248.5] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.853 | L2-Norm(final)=8.268 | 4217.1 samples/s | 65.9 steps/s
[Step=64600 Epoch=248.7] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.833 | L2-Norm(final)=8.269 | 4426.4 samples/s | 69.2 steps/s
[Step=64650 Epoch=248.9] | Loss=0.00001 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.812 | L2-Norm(final)=8.270 | 4378.4 samples/s | 68.4 steps/s
[Step=64700 Epoch=249.1] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.791 | L2-Norm(final)=8.271 | 4477.0 samples/s | 70.0 steps/s
[Step=64750 Epoch=249.2] | Loss=0.00001 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.769 | L2-Norm(final)=8.272 | 5752.7 samples/s | 89.9 steps/s
[Step=64800 Epoch=249.4] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.748 | L2-Norm(final)=8.273 | 2310.0 samples/s | 36.1 steps/s
[Step=64850 Epoch=249.6] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.726 | L2-Norm(final)=8.273 | 4369.5 samples/s | 68.3 steps/s
[Step=64900 Epoch=249.8] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.704 | L2-Norm(final)=8.274 | 4439.3 samples/s | 69.4 steps/s
[Step=64950 Epoch=250.0] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.682 | L2-Norm(final)=8.274 | 4331.2 samples/s | 67.7 steps/s
[Step=65000 Epoch=250.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.660 | L2-Norm(final)=8.275 | 5094.3 samples/s | 79.6 steps/s
[Step=65050 Epoch=250.4] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.637 | L2-Norm(final)=8.276 | 2463.3 samples/s | 38.5 steps/s
[Step=65100 Epoch=250.6] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.614 | L2-Norm(final)=8.276 | 4388.3 samples/s | 68.6 steps/s
[Step=65150 Epoch=250.8] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.591 | L2-Norm(final)=8.277 | 4444.9 samples/s | 69.5 steps/s
[Step=65200 Epoch=251.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.568 | L2-Norm(final)=8.277 | 4445.0 samples/s | 69.5 steps/s
[Step=65250 Epoch=251.2] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.545 | L2-Norm(final)=8.278 | 4343.0 samples/s | 67.9 steps/s
[Step=65300 Epoch=251.4] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.522 | L2-Norm(final)=8.279 | 2652.9 samples/s | 41.5 steps/s
[Step=65350 Epoch=251.6] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.499 | L2-Norm(final)=8.279 | 4415.0 samples/s | 69.0 steps/s
[Step=65400 Epoch=251.8] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.475 | L2-Norm(final)=8.280 | 4385.8 samples/s | 68.5 steps/s
[Step=65450 Epoch=251.9] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.452 | L2-Norm(final)=8.281 | 4399.2 samples/s | 68.7 steps/s
[Step=65500 Epoch=252.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.428 | L2-Norm(final)=8.281 | 4394.3 samples/s | 68.7 steps/s
[Step=65550 Epoch=252.3] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.404 | L2-Norm(final)=8.282 | 2696.0 samples/s | 42.1 steps/s
[Step=65600 Epoch=252.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.380 | L2-Norm(final)=8.283 | 4443.3 samples/s | 69.4 steps/s
[Step=65650 Epoch=252.7] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.356 | L2-Norm(final)=8.283 | 4423.3 samples/s | 69.1 steps/s
[Step=65700 Epoch=252.9] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.332 | L2-Norm(final)=8.284 | 4285.6 samples/s | 67.0 steps/s
[Step=65750 Epoch=253.1] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.308 | L2-Norm(final)=8.285 | 4409.4 samples/s | 68.9 steps/s
[Step=65800 Epoch=253.3] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.283 | L2-Norm(final)=8.286 | 7127.7 samples/s | 111.4 steps/s
[Step=65850 Epoch=253.5] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.259 | L2-Norm(final)=8.286 | 2171.0 samples/s | 33.9 steps/s
[Step=65900 Epoch=253.7] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.235 | L2-Norm(final)=8.287 | 4370.4 samples/s | 68.3 steps/s
[Step=65950 Epoch=253.9] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.210 | L2-Norm(final)=8.288 | 4445.4 samples/s | 69.5 steps/s
[Step=66000 Epoch=254.1] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.185 | L2-Norm(final)=8.289 | 4334.9 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08692 | acc=0.9680 | tpr=0.9747 | fpr=0.0463 | 5023.4 samples/s | 19.6 steps/s
Avg test loss: 0.08882, Avg test acc: 0.96678, Avg tpr: 0.97406, Avg fpr: 0.04922, total FA: 384

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08707 | acc=0.9680 | tpr=0.9727 | fpr=0.0421 | 5273.9 samples/s | 20.6 steps/s
Avg test loss: 0.08988, Avg test acc: 0.96759, Avg tpr: 0.97255, Avg fpr: 0.04333, total FA: 338

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.47054 | acc=0.3102 | tpr=0.0064 | fpr=0.0300 | 5248.6 samples/s | 20.5 steps/s
Avg test loss: 5.48010, Avg test acc: 0.30868, Avg tpr: 0.00618, Avg fpr: 0.02602, total FA: 203

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.18641 | acc=0.3086 | tpr=0.0081 | fpr=0.0389 | 5246.3 samples/s | 20.5 steps/s
Avg test loss: 5.19129, Avg test acc: 0.30740, Avg tpr: 0.00799, Avg fpr: 0.03410, total FA: 266

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.20900 | acc=0.1316 | tpr=0.7124 | fpr=0.8789 | 5065.7 samples/s | 19.8 steps/s
[Step= 100] | Loss=6.18373 | acc=0.1310 | tpr=0.6972 | fpr=0.8796 | 7362.4 samples/s | 28.8 steps/s
[Step= 150] | Loss=6.17780 | acc=0.1321 | tpr=0.7161 | fpr=0.8786 | 8012.4 samples/s | 31.3 steps/s
[Step= 200] | Loss=6.18977 | acc=0.1310 | tpr=0.7093 | fpr=0.8795 | 7899.2 samples/s | 30.9 steps/s
[Step= 250] | Loss=6.19628 | acc=0.1314 | tpr=0.7013 | fpr=0.8790 | 8396.5 samples/s | 32.8 steps/s
[Step= 300] | Loss=6.19471 | acc=0.1314 | tpr=0.7040 | fpr=0.8791 | 7979.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=6.18194 | acc=0.1317 | tpr=0.7051 | fpr=0.8787 | 8098.9 samples/s | 31.6 steps/s
[Step= 400] | Loss=6.17292 | acc=0.1323 | tpr=0.7046 | fpr=0.8781 | 8394.5 samples/s | 32.8 steps/s
[Step= 450] | Loss=6.17278 | acc=0.1318 | tpr=0.7055 | fpr=0.8786 | 7831.5 samples/s | 30.6 steps/s
[Step= 500] | Loss=6.17282 | acc=0.1314 | tpr=0.7048 | fpr=0.8790 | 7997.3 samples/s | 31.2 steps/s
[Step= 550] | Loss=6.17176 | acc=0.1315 | tpr=0.6984 | fpr=0.8788 | 15137.4 samples/s | 59.1 steps/s
Avg test loss: 6.17289, Avg test acc: 0.13143, Avg tpr: 0.69810, Avg fpr: 0.87887, total FA: 122030

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.62648 | acc=0.1447 | tpr=0.6947 | fpr=0.8652 | 5185.3 samples/s | 20.3 steps/s
[Step= 100] | Loss=6.60334 | acc=0.1460 | tpr=0.6866 | fpr=0.8641 | 7221.4 samples/s | 28.2 steps/s
[Step= 150] | Loss=6.59196 | acc=0.1469 | tpr=0.6988 | fpr=0.8632 | 7909.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.60230 | acc=0.1466 | tpr=0.7016 | fpr=0.8635 | 8329.8 samples/s | 32.5 steps/s
[Step= 250] | Loss=6.60826 | acc=0.1473 | tpr=0.6969 | fpr=0.8627 | 8198.7 samples/s | 32.0 steps/s
[Step= 300] | Loss=6.61017 | acc=0.1471 | tpr=0.6975 | fpr=0.8629 | 8282.4 samples/s | 32.4 steps/s
[Step= 350] | Loss=6.59423 | acc=0.1473 | tpr=0.6900 | fpr=0.8625 | 8175.2 samples/s | 31.9 steps/s
[Step= 400] | Loss=6.58641 | acc=0.1476 | tpr=0.6904 | fpr=0.8623 | 7984.7 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.58380 | acc=0.1469 | tpr=0.6899 | fpr=0.8630 | 8169.9 samples/s | 31.9 steps/s
[Step= 500] | Loss=6.58649 | acc=0.1467 | tpr=0.6903 | fpr=0.8631 | 8005.0 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.58421 | acc=0.1467 | tpr=0.6844 | fpr=0.8630 | 14346.9 samples/s | 56.0 steps/s
Avg test loss: 6.58596, Avg test acc: 0.14667, Avg tpr: 0.68463, Avg fpr: 0.86311, total FA: 119841

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12284 | acc=0.9794 | tpr=0.9381 | fpr=0.0199 | 5488.3 samples/s | 21.4 steps/s
[Step= 100] | Loss=0.12894 | acc=0.9782 | tpr=0.9552 | fpr=0.0214 | 7532.2 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.13390 | acc=0.9771 | tpr=0.9524 | fpr=0.0224 | 7299.3 samples/s | 28.5 steps/s
[Step= 200] | Loss=0.13564 | acc=0.9773 | tpr=0.9541 | fpr=0.0222 | 7653.0 samples/s | 29.9 steps/s
[Step= 250] | Loss=0.13380 | acc=0.9776 | tpr=0.9546 | fpr=0.0220 | 8114.6 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.13581 | acc=0.9772 | tpr=0.9513 | fpr=0.0223 | 8185.5 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.13629 | acc=0.9770 | tpr=0.9537 | fpr=0.0226 | 8201.1 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.13770 | acc=0.9769 | tpr=0.9513 | fpr=0.0226 | 8162.3 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.14069 | acc=0.9765 | tpr=0.9513 | fpr=0.0230 | 8010.3 samples/s | 31.3 steps/s
[Step= 500] | Loss=0.14022 | acc=0.9765 | tpr=0.9511 | fpr=0.0230 | 8147.9 samples/s | 31.8 steps/s
[Step= 550] | Loss=0.13920 | acc=0.9767 | tpr=0.9507 | fpr=0.0228 | 14661.1 samples/s | 57.3 steps/s
Avg test loss: 0.13884, Avg test acc: 0.97669, Avg tpr: 0.94968, Avg fpr: 0.02282, total FA: 3168

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13967 | acc=0.9786 | tpr=0.9513 | fpr=0.0209 | 5099.6 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.14596 | acc=0.9777 | tpr=0.9574 | fpr=0.0219 | 7411.2 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.15134 | acc=0.9767 | tpr=0.9597 | fpr=0.0230 | 7685.5 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.15393 | acc=0.9766 | tpr=0.9617 | fpr=0.0231 | 8247.2 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.15114 | acc=0.9769 | tpr=0.9651 | fpr=0.0229 | 8213.2 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.15378 | acc=0.9766 | tpr=0.9644 | fpr=0.0232 | 7969.4 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.15482 | acc=0.9763 | tpr=0.9656 | fpr=0.0235 | 8451.4 samples/s | 33.0 steps/s
[Step= 400] | Loss=0.15617 | acc=0.9761 | tpr=0.9628 | fpr=0.0237 | 8137.3 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.15931 | acc=0.9757 | tpr=0.9620 | fpr=0.0241 | 7944.3 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.15854 | acc=0.9756 | tpr=0.9626 | fpr=0.0241 | 8125.5 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.15724 | acc=0.9758 | tpr=0.9622 | fpr=0.0240 | 14850.8 samples/s | 58.0 steps/s
Avg test loss: 0.15683, Avg test acc: 0.97582, Avg tpr: 0.96157, Avg fpr: 0.02393, total FA: 3322

server round 33/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=128.7] | Loss=0.00301 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.308 | L2-Norm(final)=10.897 | 6347.3 samples/s | 99.2 steps/s
[Step=66050 Epoch=128.8] | Loss=0.00684 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.308 | L2-Norm(final)=10.900 | 4675.1 samples/s | 73.0 steps/s
[Step=66100 Epoch=128.9] | Loss=0.00697 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.310 | L2-Norm(final)=10.904 | 5120.5 samples/s | 80.0 steps/s
[Step=66150 Epoch=129.0] | Loss=0.00696 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.312 | L2-Norm(final)=10.910 | 5239.2 samples/s | 81.9 steps/s
[Step=66200 Epoch=129.1] | Loss=0.00695 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.314 | L2-Norm(final)=10.915 | 5103.5 samples/s | 79.7 steps/s
[Step=66250 Epoch=129.2] | Loss=0.00679 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.315 | L2-Norm(final)=10.920 | 5236.0 samples/s | 81.8 steps/s
[Step=66300 Epoch=129.3] | Loss=0.00657 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.317 | L2-Norm(final)=10.926 | 5217.0 samples/s | 81.5 steps/s
[Step=66350 Epoch=129.4] | Loss=0.00644 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.318 | L2-Norm(final)=10.931 | 5210.5 samples/s | 81.4 steps/s
[Step=66400 Epoch=129.5] | Loss=0.00645 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=10.936 | 5213.6 samples/s | 81.5 steps/s
[Step=66450 Epoch=129.6] | Loss=0.00635 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.320 | L2-Norm(final)=10.941 | 5206.1 samples/s | 81.3 steps/s
[Step=66500 Epoch=129.7] | Loss=0.00619 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.322 | L2-Norm(final)=10.945 | 6944.9 samples/s | 108.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=129.7] | Loss=0.00992 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.333 | L2-Norm(final)=10.995 | 6457.8 samples/s | 100.9 steps/s
[Step=66550 Epoch=129.8] | Loss=0.00538 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.335 | L2-Norm(final)=10.999 | 4121.1 samples/s | 64.4 steps/s
[Step=66600 Epoch=129.9] | Loss=0.00624 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.339 | L2-Norm(final)=11.003 | 4627.6 samples/s | 72.3 steps/s
[Step=66650 Epoch=130.0] | Loss=0.00662 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.341 | L2-Norm(final)=11.007 | 4599.6 samples/s | 71.9 steps/s
[Step=66700 Epoch=130.1] | Loss=0.00737 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.344 | L2-Norm(final)=11.010 | 4700.7 samples/s | 73.4 steps/s
[Step=66750 Epoch=130.2] | Loss=0.00720 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=11.014 | 4589.9 samples/s | 71.7 steps/s
[Step=66800 Epoch=130.3] | Loss=0.00740 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.349 | L2-Norm(final)=11.018 | 4591.2 samples/s | 71.7 steps/s
[Step=66850 Epoch=130.4] | Loss=0.00761 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=11.021 | 4690.5 samples/s | 73.3 steps/s
[Step=66900 Epoch=130.5] | Loss=0.00766 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.354 | L2-Norm(final)=11.025 | 4576.4 samples/s | 71.5 steps/s
[Step=66950 Epoch=130.6] | Loss=0.00742 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.356 | L2-Norm(final)=11.028 | 4640.8 samples/s | 72.5 steps/s
[Step=67000 Epoch=130.7] | Loss=0.00719 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=11.032 | 5958.3 samples/s | 93.1 steps/s
[Step=67050 Epoch=130.8] | Loss=0.00695 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.361 | L2-Norm(final)=11.035 | 2434.6 samples/s | 38.0 steps/s
[Step=67100 Epoch=130.9] | Loss=0.00679 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=11.039 | 4638.3 samples/s | 72.5 steps/s
[Step=67150 Epoch=131.0] | Loss=0.00667 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=11.042 | 4612.7 samples/s | 72.1 steps/s
[Step=67200 Epoch=131.1] | Loss=0.00648 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=11.046 | 4658.7 samples/s | 72.8 steps/s
[Step=67250 Epoch=131.2] | Loss=0.00644 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=11.049 | 4646.1 samples/s | 72.6 steps/s
[Step=67300 Epoch=131.3] | Loss=0.00641 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.368 | L2-Norm(final)=11.052 | 4645.8 samples/s | 72.6 steps/s
[Step=67350 Epoch=131.4] | Loss=0.00633 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.369 | L2-Norm(final)=11.055 | 4626.6 samples/s | 72.3 steps/s
[Step=67400 Epoch=131.5] | Loss=0.00630 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=11.058 | 4534.1 samples/s | 70.8 steps/s
[Step=67450 Epoch=131.6] | Loss=0.00630 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=11.061 | 4621.3 samples/s | 72.2 steps/s
[Step=67500 Epoch=131.7] | Loss=0.00625 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=11.064 | 4973.7 samples/s | 77.7 steps/s
[Step=67550 Epoch=131.7] | Loss=0.00622 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=11.067 | 2643.7 samples/s | 41.3 steps/s
[Step=67600 Epoch=131.8] | Loss=0.00609 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.373 | L2-Norm(final)=11.070 | 4641.5 samples/s | 72.5 steps/s
[Step=67650 Epoch=131.9] | Loss=0.00610 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.374 | L2-Norm(final)=11.073 | 4655.6 samples/s | 72.7 steps/s
[Step=67700 Epoch=132.0] | Loss=0.00604 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=11.075 | 4589.6 samples/s | 71.7 steps/s
[Step=67750 Epoch=132.1] | Loss=0.00597 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=11.078 | 4637.2 samples/s | 72.5 steps/s
[Step=67800 Epoch=132.2] | Loss=0.00594 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.375 | L2-Norm(final)=11.081 | 4563.1 samples/s | 71.3 steps/s
[Step=67850 Epoch=132.3] | Loss=0.00589 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=11.083 | 4678.6 samples/s | 73.1 steps/s
[Step=67900 Epoch=132.4] | Loss=0.00588 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=11.086 | 4599.6 samples/s | 71.9 steps/s
[Step=67950 Epoch=132.5] | Loss=0.00588 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.376 | L2-Norm(final)=11.089 | 4650.8 samples/s | 72.7 steps/s
[Step=68000 Epoch=132.6] | Loss=0.00586 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.377 | L2-Norm(final)=11.091 | 4621.7 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step68000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=129.0] | Loss=0.00122 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.655 | L2-Norm(final)=11.405 | 6949.6 samples/s | 108.6 steps/s
[Step=66050 Epoch=129.1] | Loss=0.00549 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.655 | L2-Norm(final)=11.410 | 4230.6 samples/s | 66.1 steps/s
[Step=66100 Epoch=129.2] | Loss=0.00523 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.656 | L2-Norm(final)=11.415 | 5180.1 samples/s | 80.9 steps/s
[Step=66150 Epoch=129.3] | Loss=0.00594 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.656 | L2-Norm(final)=11.421 | 5137.8 samples/s | 80.3 steps/s
[Step=66200 Epoch=129.4] | Loss=0.00583 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.657 | L2-Norm(final)=11.426 | 5220.4 samples/s | 81.6 steps/s
[Step=66250 Epoch=129.5] | Loss=0.00561 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.658 | L2-Norm(final)=11.432 | 5171.2 samples/s | 80.8 steps/s
[Step=66300 Epoch=129.6] | Loss=0.00550 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.659 | L2-Norm(final)=11.437 | 5230.3 samples/s | 81.7 steps/s
[Step=66350 Epoch=129.7] | Loss=0.00552 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.660 | L2-Norm(final)=11.441 | 5222.4 samples/s | 81.6 steps/s
[Step=66400 Epoch=129.8] | Loss=0.00548 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.661 | L2-Norm(final)=11.446 | 5281.6 samples/s | 82.5 steps/s
[Step=66450 Epoch=129.9] | Loss=0.00559 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.661 | L2-Norm(final)=11.451 | 5115.7 samples/s | 79.9 steps/s
[Step=66500 Epoch=130.0] | Loss=0.00563 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.662 | L2-Norm(final)=11.456 | 7102.6 samples/s | 111.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=130.0] | Loss=0.00248 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.671 | L2-Norm(final)=11.506 | 6417.8 samples/s | 100.3 steps/s
[Step=66550 Epoch=130.1] | Loss=0.00616 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.674 | L2-Norm(final)=11.510 | 4141.1 samples/s | 64.7 steps/s
[Step=66600 Epoch=130.2] | Loss=0.00688 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.678 | L2-Norm(final)=11.515 | 4634.8 samples/s | 72.4 steps/s
[Step=66650 Epoch=130.3] | Loss=0.00730 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.682 | L2-Norm(final)=11.519 | 4576.3 samples/s | 71.5 steps/s
[Step=66700 Epoch=130.4] | Loss=0.00698 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.686 | L2-Norm(final)=11.523 | 4684.5 samples/s | 73.2 steps/s
[Step=66750 Epoch=130.5] | Loss=0.00679 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=11.527 | 4522.2 samples/s | 70.7 steps/s
[Step=66800 Epoch=130.6] | Loss=0.00674 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.691 | L2-Norm(final)=11.531 | 4627.3 samples/s | 72.3 steps/s
[Step=66850 Epoch=130.7] | Loss=0.00688 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.693 | L2-Norm(final)=11.534 | 4721.2 samples/s | 73.8 steps/s
[Step=66900 Epoch=130.8] | Loss=0.00684 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.695 | L2-Norm(final)=11.538 | 4572.7 samples/s | 71.4 steps/s
[Step=66950 Epoch=130.9] | Loss=0.00670 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.697 | L2-Norm(final)=11.541 | 4672.0 samples/s | 73.0 steps/s
[Step=67000 Epoch=131.0] | Loss=0.00668 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.699 | L2-Norm(final)=11.545 | 5993.2 samples/s | 93.6 steps/s
[Step=67050 Epoch=131.1] | Loss=0.00671 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.700 | L2-Norm(final)=11.549 | 2436.4 samples/s | 38.1 steps/s
[Step=67100 Epoch=131.2] | Loss=0.00653 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.702 | L2-Norm(final)=11.552 | 4603.4 samples/s | 71.9 steps/s
[Step=67150 Epoch=131.3] | Loss=0.00632 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.703 | L2-Norm(final)=11.555 | 4572.0 samples/s | 71.4 steps/s
[Step=67200 Epoch=131.4] | Loss=0.00618 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.704 | L2-Norm(final)=11.558 | 4621.6 samples/s | 72.2 steps/s
[Step=67250 Epoch=131.5] | Loss=0.00606 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.705 | L2-Norm(final)=11.561 | 4714.3 samples/s | 73.7 steps/s
[Step=67300 Epoch=131.6] | Loss=0.00602 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.706 | L2-Norm(final)=11.565 | 4581.6 samples/s | 71.6 steps/s
[Step=67350 Epoch=131.7] | Loss=0.00596 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.707 | L2-Norm(final)=11.568 | 4675.7 samples/s | 73.1 steps/s
[Step=67400 Epoch=131.8] | Loss=0.00584 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.708 | L2-Norm(final)=11.571 | 4564.8 samples/s | 71.3 steps/s
[Step=67450 Epoch=131.9] | Loss=0.00587 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.709 | L2-Norm(final)=11.574 | 4616.0 samples/s | 72.1 steps/s
[Step=67500 Epoch=132.0] | Loss=0.00591 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.709 | L2-Norm(final)=11.577 | 5133.3 samples/s | 80.2 steps/s
[Step=67550 Epoch=132.1] | Loss=0.00595 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.710 | L2-Norm(final)=11.579 | 2616.2 samples/s | 40.9 steps/s
[Step=67600 Epoch=132.2] | Loss=0.00588 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.710 | L2-Norm(final)=11.582 | 4659.4 samples/s | 72.8 steps/s
[Step=67650 Epoch=132.3] | Loss=0.00583 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.711 | L2-Norm(final)=11.585 | 4572.8 samples/s | 71.4 steps/s
[Step=67700 Epoch=132.4] | Loss=0.00578 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.711 | L2-Norm(final)=11.588 | 4623.2 samples/s | 72.2 steps/s
[Step=67750 Epoch=132.4] | Loss=0.00568 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.711 | L2-Norm(final)=11.590 | 4624.4 samples/s | 72.3 steps/s
[Step=67800 Epoch=132.5] | Loss=0.00569 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.712 | L2-Norm(final)=11.593 | 4637.5 samples/s | 72.5 steps/s
[Step=67850 Epoch=132.6] | Loss=0.00567 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=11.596 | 4634.3 samples/s | 72.4 steps/s
[Step=67900 Epoch=132.7] | Loss=0.00563 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=11.598 | 4621.5 samples/s | 72.2 steps/s
[Step=67950 Epoch=132.8] | Loss=0.00560 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.712 | L2-Norm(final)=11.601 | 4617.9 samples/s | 72.2 steps/s
[Step=68000 Epoch=132.9] | Loss=0.00554 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.712 | L2-Norm(final)=11.604 | 4678.3 samples/s | 73.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step68000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=252.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.325 | L2-Norm(final)=8.377 | 6395.2 samples/s | 99.9 steps/s
[Step=66050 Epoch=253.1] | Loss=0.00007 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.330 | L2-Norm(final)=8.390 | 4221.9 samples/s | 66.0 steps/s
[Step=66100 Epoch=253.3] | Loss=0.00005 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.338 | L2-Norm(final)=8.405 | 4908.6 samples/s | 76.7 steps/s
[Step=66150 Epoch=253.5] | Loss=0.00004 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.341 | L2-Norm(final)=8.414 | 4986.2 samples/s | 77.9 steps/s
[Step=66200 Epoch=253.7] | Loss=0.00003 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.343 | L2-Norm(final)=8.422 | 4852.2 samples/s | 75.8 steps/s
[Step=66250 Epoch=253.8] | Loss=0.00003 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=8.429 | 6764.0 samples/s | 105.7 steps/s
[Step=66300 Epoch=254.0] | Loss=0.00003 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.346 | L2-Norm(final)=8.435 | 2463.0 samples/s | 38.5 steps/s
[Step=66350 Epoch=254.2] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.347 | L2-Norm(final)=8.441 | 4927.2 samples/s | 77.0 steps/s
[Step=66400 Epoch=254.4] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.348 | L2-Norm(final)=8.446 | 4903.1 samples/s | 76.6 steps/s
[Step=66450 Epoch=254.6] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.349 | L2-Norm(final)=8.452 | 4871.9 samples/s | 76.1 steps/s
[Step=66500 Epoch=254.8] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.349 | L2-Norm(final)=8.458 | 5636.0 samples/s | 88.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=254.8] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.354 | L2-Norm(final)=8.513 | 6373.6 samples/s | 99.6 steps/s
[Step=66550 Epoch=255.0] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.344 | L2-Norm(final)=8.517 | 3891.5 samples/s | 60.8 steps/s
[Step=66600 Epoch=255.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.332 | L2-Norm(final)=8.522 | 4323.2 samples/s | 67.5 steps/s
[Step=66650 Epoch=255.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.321 | L2-Norm(final)=8.528 | 4390.8 samples/s | 68.6 steps/s
[Step=66700 Epoch=255.6] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.309 | L2-Norm(final)=8.533 | 4366.8 samples/s | 68.2 steps/s
[Step=66750 Epoch=255.8] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.297 | L2-Norm(final)=8.537 | 5861.3 samples/s | 91.6 steps/s
[Step=66800 Epoch=256.0] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=8.541 | 2333.6 samples/s | 36.5 steps/s
[Step=66850 Epoch=256.1] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.271 | L2-Norm(final)=8.545 | 4333.8 samples/s | 67.7 steps/s
[Step=66900 Epoch=256.3] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.257 | L2-Norm(final)=8.547 | 4419.9 samples/s | 69.1 steps/s
[Step=66950 Epoch=256.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.243 | L2-Norm(final)=8.550 | 4454.1 samples/s | 69.6 steps/s
[Step=67000 Epoch=256.7] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.228 | L2-Norm(final)=8.553 | 4879.0 samples/s | 76.2 steps/s
[Step=67050 Epoch=256.9] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.213 | L2-Norm(final)=8.555 | 2540.1 samples/s | 39.7 steps/s
[Step=67100 Epoch=257.1] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.198 | L2-Norm(final)=8.557 | 4306.3 samples/s | 67.3 steps/s
[Step=67150 Epoch=257.3] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.183 | L2-Norm(final)=8.559 | 4311.2 samples/s | 67.4 steps/s
[Step=67200 Epoch=257.5] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.168 | L2-Norm(final)=8.561 | 4401.0 samples/s | 68.8 steps/s
[Step=67250 Epoch=257.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=8.564 | 4396.8 samples/s | 68.7 steps/s
[Step=67300 Epoch=257.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.566 | 2684.6 samples/s | 41.9 steps/s
[Step=67350 Epoch=258.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=8.568 | 4458.9 samples/s | 69.7 steps/s
[Step=67400 Epoch=258.3] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.105 | L2-Norm(final)=8.570 | 4363.5 samples/s | 68.2 steps/s
[Step=67450 Epoch=258.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.089 | L2-Norm(final)=8.572 | 4363.4 samples/s | 68.2 steps/s
[Step=67500 Epoch=258.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=8.575 | 4362.7 samples/s | 68.2 steps/s
[Step=67550 Epoch=258.8] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=8.577 | 2690.6 samples/s | 42.0 steps/s
[Step=67600 Epoch=259.0] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.040 | L2-Norm(final)=8.580 | 4417.0 samples/s | 69.0 steps/s
[Step=67650 Epoch=259.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.024 | L2-Norm(final)=8.582 | 4322.2 samples/s | 67.5 steps/s
[Step=67700 Epoch=259.4] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.007 | L2-Norm(final)=8.585 | 4378.2 samples/s | 68.4 steps/s
[Step=67750 Epoch=259.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.990 | L2-Norm(final)=8.587 | 4356.0 samples/s | 68.1 steps/s
[Step=67800 Epoch=259.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=8.590 | 6536.3 samples/s | 102.1 steps/s
[Step=67850 Epoch=260.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=8.593 | 2270.5 samples/s | 35.5 steps/s
[Step=67900 Epoch=260.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.940 | L2-Norm(final)=8.595 | 4399.6 samples/s | 68.7 steps/s
[Step=67950 Epoch=260.4] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.922 | L2-Norm(final)=8.598 | 4281.0 samples/s | 66.9 steps/s
[Step=68000 Epoch=260.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=8.601 | 4392.7 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step68000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=254.1] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.379 | L2-Norm(final)=8.318 | 6431.3 samples/s | 100.5 steps/s
[Step=66050 Epoch=254.3] | Loss=0.00002 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.323 | 4244.2 samples/s | 66.3 steps/s
[Step=66100 Epoch=254.4] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.328 | 5106.5 samples/s | 79.8 steps/s
[Step=66150 Epoch=254.6] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.372 | L2-Norm(final)=8.332 | 4695.2 samples/s | 73.4 steps/s
[Step=66200 Epoch=254.8] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.336 | 5040.4 samples/s | 78.8 steps/s
[Step=66250 Epoch=255.0] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.340 | 6641.7 samples/s | 103.8 steps/s
[Step=66300 Epoch=255.2] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.345 | 2441.8 samples/s | 38.2 steps/s
[Step=66350 Epoch=255.4] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.350 | 4986.1 samples/s | 77.9 steps/s
[Step=66400 Epoch=255.6] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.354 | 4957.0 samples/s | 77.5 steps/s
[Step=66450 Epoch=255.8] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.359 | 4844.5 samples/s | 75.7 steps/s
[Step=66500 Epoch=256.0] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.363 | 5724.6 samples/s | 89.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=256.0] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.373 | L2-Norm(final)=8.408 | 5791.2 samples/s | 90.5 steps/s
[Step=66550 Epoch=256.2] | Loss=0.00001 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.344 | L2-Norm(final)=8.411 | 4074.7 samples/s | 63.7 steps/s
[Step=66600 Epoch=256.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=8.414 | 4455.0 samples/s | 69.6 steps/s
[Step=66650 Epoch=256.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.264 | L2-Norm(final)=8.417 | 4443.5 samples/s | 69.4 steps/s
[Step=66700 Epoch=256.8] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.225 | L2-Norm(final)=8.421 | 4277.2 samples/s | 66.8 steps/s
[Step=66750 Epoch=256.9] | Loss=0.00016 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.200 | L2-Norm(final)=8.425 | 6020.1 samples/s | 94.1 steps/s
[Step=66800 Epoch=257.1] | Loss=0.00021 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.191 | L2-Norm(final)=8.428 | 2320.9 samples/s | 36.3 steps/s
[Step=66850 Epoch=257.3] | Loss=0.00020 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=8.431 | 4383.9 samples/s | 68.5 steps/s
[Step=66900 Epoch=257.5] | Loss=0.00018 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=8.434 | 4337.1 samples/s | 67.8 steps/s
[Step=66950 Epoch=257.7] | Loss=0.00017 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.181 | L2-Norm(final)=8.436 | 4424.3 samples/s | 69.1 steps/s
[Step=67000 Epoch=257.9] | Loss=0.00015 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.179 | L2-Norm(final)=8.438 | 5122.3 samples/s | 80.0 steps/s
[Step=67050 Epoch=258.1] | Loss=0.00014 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.177 | L2-Norm(final)=8.440 | 2527.3 samples/s | 39.5 steps/s
[Step=67100 Epoch=258.3] | Loss=0.00013 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.175 | L2-Norm(final)=8.442 | 4206.4 samples/s | 65.7 steps/s
[Step=67150 Epoch=258.5] | Loss=0.00012 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.174 | L2-Norm(final)=8.443 | 4431.9 samples/s | 69.2 steps/s
[Step=67200 Epoch=258.7] | Loss=0.00011 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.172 | L2-Norm(final)=8.444 | 4428.0 samples/s | 69.2 steps/s
[Step=67250 Epoch=258.9] | Loss=0.00010 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.171 | L2-Norm(final)=8.445 | 4380.1 samples/s | 68.4 steps/s
[Step=67300 Epoch=259.1] | Loss=0.00010 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.169 | L2-Norm(final)=8.447 | 2690.0 samples/s | 42.0 steps/s
[Step=67350 Epoch=259.3] | Loss=0.00009 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.168 | L2-Norm(final)=8.448 | 4355.4 samples/s | 68.1 steps/s
[Step=67400 Epoch=259.4] | Loss=0.00009 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.166 | L2-Norm(final)=8.448 | 4291.6 samples/s | 67.1 steps/s
[Step=67450 Epoch=259.6] | Loss=0.00008 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.165 | L2-Norm(final)=8.449 | 4382.4 samples/s | 68.5 steps/s
[Step=67500 Epoch=259.8] | Loss=0.00008 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.163 | L2-Norm(final)=8.450 | 4416.4 samples/s | 69.0 steps/s
[Step=67550 Epoch=260.0] | Loss=0.00008 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.162 | L2-Norm(final)=8.451 | 2683.5 samples/s | 41.9 steps/s
[Step=67600 Epoch=260.2] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.161 | L2-Norm(final)=8.452 | 4423.2 samples/s | 69.1 steps/s
[Step=67650 Epoch=260.4] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.159 | L2-Norm(final)=8.452 | 4398.1 samples/s | 68.7 steps/s
[Step=67700 Epoch=260.6] | Loss=0.00007 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.158 | L2-Norm(final)=8.453 | 4390.1 samples/s | 68.6 steps/s
[Step=67750 Epoch=260.8] | Loss=0.00006 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.156 | L2-Norm(final)=8.454 | 4413.8 samples/s | 69.0 steps/s
[Step=67800 Epoch=261.0] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.155 | L2-Norm(final)=8.454 | 7028.2 samples/s | 109.8 steps/s
[Step=67850 Epoch=261.2] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.153 | L2-Norm(final)=8.455 | 2164.3 samples/s | 33.8 steps/s
[Step=67900 Epoch=261.4] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.152 | L2-Norm(final)=8.456 | 4396.4 samples/s | 68.7 steps/s
[Step=67950 Epoch=261.6] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.150 | L2-Norm(final)=8.456 | 4442.9 samples/s | 69.4 steps/s
[Step=68000 Epoch=261.8] | Loss=0.00005 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.148 | L2-Norm(final)=8.457 | 4322.7 samples/s | 67.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08267 | acc=0.9679 | tpr=0.9777 | fpr=0.0535 | 5331.0 samples/s | 20.8 steps/s
Avg test loss: 0.08394, Avg test acc: 0.96666, Avg tpr: 0.97628, Avg fpr: 0.05448, total FA: 425

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08414 | acc=0.9680 | tpr=0.9752 | fpr=0.0476 | 5331.7 samples/s | 20.8 steps/s
Avg test loss: 0.08600, Avg test acc: 0.96783, Avg tpr: 0.97494, Avg fpr: 0.04781, total FA: 373

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.39589 | acc=0.3134 | tpr=0.0052 | fpr=0.0173 | 5301.8 samples/s | 20.7 steps/s
Avg test loss: 5.40896, Avg test acc: 0.31080, Avg tpr: 0.00490, Avg fpr: 0.01641, total FA: 128

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.06196 | acc=0.3092 | tpr=0.0072 | fpr=0.0349 | 5271.3 samples/s | 20.6 steps/s
Avg test loss: 5.06912, Avg test acc: 0.30764, Avg tpr: 0.00711, Avg fpr: 0.03141, total FA: 245

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.15730 | acc=0.1208 | tpr=0.7522 | fpr=0.8906 | 5302.2 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.13843 | acc=0.1199 | tpr=0.7441 | fpr=0.8918 | 6950.9 samples/s | 27.2 steps/s
[Step= 150] | Loss=6.13775 | acc=0.1211 | tpr=0.7651 | fpr=0.8907 | 8234.4 samples/s | 32.2 steps/s
[Step= 200] | Loss=6.15183 | acc=0.1199 | tpr=0.7552 | fpr=0.8916 | 8310.7 samples/s | 32.5 steps/s
[Step= 250] | Loss=6.15861 | acc=0.1204 | tpr=0.7485 | fpr=0.8910 | 8113.4 samples/s | 31.7 steps/s
[Step= 300] | Loss=6.15922 | acc=0.1201 | tpr=0.7505 | fpr=0.8914 | 8153.7 samples/s | 31.9 steps/s
[Step= 350] | Loss=6.14869 | acc=0.1199 | tpr=0.7489 | fpr=0.8915 | 8945.1 samples/s | 34.9 steps/s
[Step= 400] | Loss=6.14115 | acc=0.1206 | tpr=0.7522 | fpr=0.8909 | 7728.9 samples/s | 30.2 steps/s
[Step= 450] | Loss=6.14227 | acc=0.1202 | tpr=0.7551 | fpr=0.8914 | 8459.5 samples/s | 33.0 steps/s
[Step= 500] | Loss=6.14196 | acc=0.1200 | tpr=0.7546 | fpr=0.8915 | 7887.5 samples/s | 30.8 steps/s
[Step= 550] | Loss=6.14032 | acc=0.1202 | tpr=0.7521 | fpr=0.8913 | 14837.2 samples/s | 58.0 steps/s
Avg test loss: 6.14130, Avg test acc: 0.12015, Avg tpr: 0.75238, Avg fpr: 0.89134, total FA: 123761

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.75182 | acc=0.1381 | tpr=0.7566 | fpr=0.8730 | 5389.1 samples/s | 21.1 steps/s
[Step= 100] | Loss=6.72702 | acc=0.1389 | tpr=0.7292 | fpr=0.8721 | 7071.6 samples/s | 27.6 steps/s
[Step= 150] | Loss=6.71930 | acc=0.1400 | tpr=0.7450 | fpr=0.8712 | 7948.2 samples/s | 31.0 steps/s
[Step= 200] | Loss=6.73136 | acc=0.1389 | tpr=0.7421 | fpr=0.8721 | 8309.9 samples/s | 32.5 steps/s
[Step= 250] | Loss=6.73821 | acc=0.1395 | tpr=0.7362 | fpr=0.8713 | 7850.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=6.74019 | acc=0.1394 | tpr=0.7338 | fpr=0.8714 | 8244.2 samples/s | 32.2 steps/s
[Step= 350] | Loss=6.72545 | acc=0.1395 | tpr=0.7332 | fpr=0.8713 | 8075.3 samples/s | 31.5 steps/s
[Step= 400] | Loss=6.71643 | acc=0.1399 | tpr=0.7347 | fpr=0.8709 | 7852.0 samples/s | 30.7 steps/s
[Step= 450] | Loss=6.71473 | acc=0.1392 | tpr=0.7337 | fpr=0.8715 | 8185.6 samples/s | 32.0 steps/s
[Step= 500] | Loss=6.71673 | acc=0.1390 | tpr=0.7326 | fpr=0.8717 | 8193.2 samples/s | 32.0 steps/s
[Step= 550] | Loss=6.71395 | acc=0.1391 | tpr=0.7286 | fpr=0.8716 | 14494.4 samples/s | 56.6 steps/s
Avg test loss: 6.71581, Avg test acc: 0.13908, Avg tpr: 0.72861, Avg fpr: 0.87164, total FA: 121025

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11139 | acc=0.9805 | tpr=0.9513 | fpr=0.0190 | 5180.7 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.11681 | acc=0.9790 | tpr=0.9595 | fpr=0.0206 | 7311.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.12167 | acc=0.9778 | tpr=0.9524 | fpr=0.0217 | 7903.5 samples/s | 30.9 steps/s
[Step= 200] | Loss=0.12328 | acc=0.9780 | tpr=0.9552 | fpr=0.0216 | 8072.9 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.12144 | acc=0.9784 | tpr=0.9555 | fpr=0.0212 | 8165.1 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.12322 | acc=0.9780 | tpr=0.9535 | fpr=0.0215 | 8141.1 samples/s | 31.8 steps/s
[Step= 350] | Loss=0.12370 | acc=0.9778 | tpr=0.9555 | fpr=0.0218 | 7934.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.12483 | acc=0.9777 | tpr=0.9540 | fpr=0.0219 | 8284.0 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.12747 | acc=0.9774 | tpr=0.9537 | fpr=0.0222 | 7993.9 samples/s | 31.2 steps/s
[Step= 500] | Loss=0.12697 | acc=0.9775 | tpr=0.9537 | fpr=0.0221 | 8211.6 samples/s | 32.1 steps/s
[Step= 550] | Loss=0.12607 | acc=0.9776 | tpr=0.9538 | fpr=0.0219 | 14788.3 samples/s | 57.8 steps/s
Avg test loss: 0.12572, Avg test acc: 0.97765, Avg tpr: 0.95285, Avg fpr: 0.02189, total FA: 3040

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13025 | acc=0.9788 | tpr=0.9425 | fpr=0.0206 | 5345.8 samples/s | 20.9 steps/s
[Step= 100] | Loss=0.13647 | acc=0.9786 | tpr=0.9531 | fpr=0.0210 | 7451.1 samples/s | 29.1 steps/s
[Step= 150] | Loss=0.14219 | acc=0.9775 | tpr=0.9582 | fpr=0.0221 | 7689.0 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.14500 | acc=0.9773 | tpr=0.9607 | fpr=0.0224 | 8073.2 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.14202 | acc=0.9778 | tpr=0.9616 | fpr=0.0219 | 8203.5 samples/s | 32.0 steps/s
[Step= 300] | Loss=0.14467 | acc=0.9775 | tpr=0.9585 | fpr=0.0222 | 8215.0 samples/s | 32.1 steps/s
[Step= 350] | Loss=0.14548 | acc=0.9771 | tpr=0.9599 | fpr=0.0226 | 7940.2 samples/s | 31.0 steps/s
[Step= 400] | Loss=0.14677 | acc=0.9770 | tpr=0.9568 | fpr=0.0226 | 8023.8 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.14961 | acc=0.9766 | tpr=0.9562 | fpr=0.0230 | 8237.6 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.14897 | acc=0.9767 | tpr=0.9564 | fpr=0.0229 | 8092.7 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.14782 | acc=0.9768 | tpr=0.9554 | fpr=0.0228 | 14289.8 samples/s | 55.8 steps/s
Avg test loss: 0.14744, Avg test acc: 0.97685, Avg tpr: 0.95483, Avg fpr: 0.02275, total FA: 3159

server round 34/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=132.6] | Loss=0.00325 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=11.167 | 6829.0 samples/s | 106.7 steps/s
[Step=68050 Epoch=132.7] | Loss=0.00840 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=11.172 | 4395.5 samples/s | 68.7 steps/s
[Step=68100 Epoch=132.8] | Loss=0.00783 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=11.177 | 5240.2 samples/s | 81.9 steps/s
[Step=68150 Epoch=132.9] | Loss=0.00733 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=11.184 | 5147.3 samples/s | 80.4 steps/s
[Step=68200 Epoch=133.0] | Loss=0.00700 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.182 | L2-Norm(final)=11.190 | 5215.5 samples/s | 81.5 steps/s
[Step=68250 Epoch=133.1] | Loss=0.00715 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=11.196 | 5230.7 samples/s | 81.7 steps/s
[Step=68300 Epoch=133.2] | Loss=0.00716 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=11.202 | 5305.3 samples/s | 82.9 steps/s
[Step=68350 Epoch=133.3] | Loss=0.00706 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.188 | L2-Norm(final)=11.208 | 5263.8 samples/s | 82.2 steps/s
[Step=68400 Epoch=133.4] | Loss=0.00711 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=11.215 | 5061.4 samples/s | 79.1 steps/s
[Step=68450 Epoch=133.5] | Loss=0.00721 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.191 | L2-Norm(final)=11.221 | 5160.5 samples/s | 80.6 steps/s
[Step=68500 Epoch=133.6] | Loss=0.00706 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.193 | L2-Norm(final)=11.226 | 7001.5 samples/s | 109.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=133.6] | Loss=0.00511 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=11.284 | 5836.6 samples/s | 91.2 steps/s
[Step=68550 Epoch=133.7] | Loss=0.00645 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.215 | L2-Norm(final)=11.290 | 4411.1 samples/s | 68.9 steps/s
[Step=68600 Epoch=133.8] | Loss=0.00793 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.219 | L2-Norm(final)=11.294 | 4645.1 samples/s | 72.6 steps/s
[Step=68650 Epoch=133.9] | Loss=0.00772 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.223 | L2-Norm(final)=11.298 | 4606.3 samples/s | 72.0 steps/s
[Step=68700 Epoch=134.0] | Loss=0.00768 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.227 | L2-Norm(final)=11.303 | 4576.9 samples/s | 71.5 steps/s
[Step=68750 Epoch=134.1] | Loss=0.00804 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.231 | L2-Norm(final)=11.307 | 4634.2 samples/s | 72.4 steps/s
[Step=68800 Epoch=134.2] | Loss=0.00807 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.234 | L2-Norm(final)=11.311 | 4675.4 samples/s | 73.1 steps/s
[Step=68850 Epoch=134.3] | Loss=0.00799 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.236 | L2-Norm(final)=11.314 | 4559.9 samples/s | 71.2 steps/s
[Step=68900 Epoch=134.4] | Loss=0.00773 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.239 | L2-Norm(final)=11.318 | 4628.9 samples/s | 72.3 steps/s
[Step=68950 Epoch=134.5] | Loss=0.00759 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.241 | L2-Norm(final)=11.322 | 4632.3 samples/s | 72.4 steps/s
[Step=69000 Epoch=134.6] | Loss=0.00763 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=11.325 | 5956.8 samples/s | 93.1 steps/s
[Step=69050 Epoch=134.7] | Loss=0.00760 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=11.329 | 2437.1 samples/s | 38.1 steps/s
[Step=69100 Epoch=134.8] | Loss=0.00730 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.247 | L2-Norm(final)=11.332 | 4674.9 samples/s | 73.0 steps/s
[Step=69150 Epoch=134.9] | Loss=0.00718 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.249 | L2-Norm(final)=11.335 | 4545.9 samples/s | 71.0 steps/s
[Step=69200 Epoch=135.0] | Loss=0.00702 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=11.339 | 4609.5 samples/s | 72.0 steps/s
[Step=69250 Epoch=135.1] | Loss=0.00685 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.252 | L2-Norm(final)=11.342 | 4622.8 samples/s | 72.2 steps/s
[Step=69300 Epoch=135.2] | Loss=0.00687 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.253 | L2-Norm(final)=11.345 | 4619.6 samples/s | 72.2 steps/s
[Step=69350 Epoch=135.3] | Loss=0.00687 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=11.348 | 4651.8 samples/s | 72.7 steps/s
[Step=69400 Epoch=135.4] | Loss=0.00683 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.255 | L2-Norm(final)=11.351 | 4614.5 samples/s | 72.1 steps/s
[Step=69450 Epoch=135.5] | Loss=0.00679 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=11.354 | 4636.0 samples/s | 72.4 steps/s
[Step=69500 Epoch=135.6] | Loss=0.00667 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=11.357 | 4910.2 samples/s | 76.7 steps/s
[Step=69550 Epoch=135.6] | Loss=0.00665 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=11.360 | 2688.1 samples/s | 42.0 steps/s
[Step=69600 Epoch=135.7] | Loss=0.00651 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.260 | L2-Norm(final)=11.363 | 4507.1 samples/s | 70.4 steps/s
[Step=69650 Epoch=135.8] | Loss=0.00639 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=11.366 | 4662.2 samples/s | 72.8 steps/s
[Step=69700 Epoch=135.9] | Loss=0.00631 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.262 | L2-Norm(final)=11.369 | 4589.8 samples/s | 71.7 steps/s
[Step=69750 Epoch=136.0] | Loss=0.00629 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.262 | L2-Norm(final)=11.373 | 4625.7 samples/s | 72.3 steps/s
[Step=69800 Epoch=136.1] | Loss=0.00630 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.263 | L2-Norm(final)=11.375 | 4579.8 samples/s | 71.6 steps/s
[Step=69850 Epoch=136.2] | Loss=0.00629 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.264 | L2-Norm(final)=11.378 | 4669.0 samples/s | 73.0 steps/s
[Step=69900 Epoch=136.3] | Loss=0.00628 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.264 | L2-Norm(final)=11.381 | 4594.7 samples/s | 71.8 steps/s
[Step=69950 Epoch=136.4] | Loss=0.00623 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=11.384 | 4673.8 samples/s | 73.0 steps/s
[Step=70000 Epoch=136.5] | Loss=0.00620 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.265 | L2-Norm(final)=11.387 | 4600.8 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step70000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=132.9] | Loss=0.00163 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=11.682 | 6499.6 samples/s | 101.6 steps/s
[Step=68050 Epoch=133.0] | Loss=0.00777 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.508 | L2-Norm(final)=11.688 | 4525.3 samples/s | 70.7 steps/s
[Step=68100 Epoch=133.1] | Loss=0.00767 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.511 | L2-Norm(final)=11.694 | 5191.6 samples/s | 81.1 steps/s
[Step=68150 Epoch=133.2] | Loss=0.00722 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.513 | L2-Norm(final)=11.700 | 5180.7 samples/s | 80.9 steps/s
[Step=68200 Epoch=133.3] | Loss=0.00670 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.516 | L2-Norm(final)=11.706 | 5226.2 samples/s | 81.7 steps/s
[Step=68250 Epoch=133.4] | Loss=0.00681 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.519 | L2-Norm(final)=11.712 | 5191.2 samples/s | 81.1 steps/s
[Step=68300 Epoch=133.5] | Loss=0.00678 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.521 | L2-Norm(final)=11.718 | 5279.8 samples/s | 82.5 steps/s
[Step=68350 Epoch=133.6] | Loss=0.00693 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.524 | L2-Norm(final)=11.724 | 5073.8 samples/s | 79.3 steps/s
[Step=68400 Epoch=133.7] | Loss=0.00704 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.526 | L2-Norm(final)=11.730 | 5206.6 samples/s | 81.4 steps/s
[Step=68450 Epoch=133.8] | Loss=0.00702 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.529 | L2-Norm(final)=11.736 | 5257.7 samples/s | 82.2 steps/s
[Step=68500 Epoch=133.9] | Loss=0.00702 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.531 | L2-Norm(final)=11.741 | 7023.6 samples/s | 109.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=133.9] | Loss=0.00804 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.556 | L2-Norm(final)=11.798 | 5835.1 samples/s | 91.2 steps/s
[Step=68550 Epoch=134.0] | Loss=0.00654 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=11.803 | 4493.8 samples/s | 70.2 steps/s
[Step=68600 Epoch=134.1] | Loss=0.00814 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=11.807 | 4501.9 samples/s | 70.3 steps/s
[Step=68650 Epoch=134.2] | Loss=0.00792 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.568 | L2-Norm(final)=11.810 | 4631.0 samples/s | 72.4 steps/s
[Step=68700 Epoch=134.3] | Loss=0.00749 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.572 | L2-Norm(final)=11.815 | 4668.1 samples/s | 72.9 steps/s
[Step=68750 Epoch=134.4] | Loss=0.00749 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.576 | L2-Norm(final)=11.819 | 4561.6 samples/s | 71.3 steps/s
[Step=68800 Epoch=134.5] | Loss=0.00748 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=11.823 | 4615.9 samples/s | 72.1 steps/s
[Step=68850 Epoch=134.6] | Loss=0.00750 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.582 | L2-Norm(final)=11.827 | 4607.5 samples/s | 72.0 steps/s
[Step=68900 Epoch=134.7] | Loss=0.00741 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=11.831 | 4610.5 samples/s | 72.0 steps/s
[Step=68950 Epoch=134.8] | Loss=0.00737 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.587 | L2-Norm(final)=11.835 | 4673.8 samples/s | 73.0 steps/s
[Step=69000 Epoch=134.9] | Loss=0.00742 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.590 | L2-Norm(final)=11.838 | 5996.5 samples/s | 93.7 steps/s
[Step=69050 Epoch=135.0] | Loss=0.00722 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.592 | L2-Norm(final)=11.842 | 2432.2 samples/s | 38.0 steps/s
[Step=69100 Epoch=135.1] | Loss=0.00708 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.593 | L2-Norm(final)=11.846 | 4617.6 samples/s | 72.2 steps/s
[Step=69150 Epoch=135.2] | Loss=0.00696 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.595 | L2-Norm(final)=11.849 | 4567.1 samples/s | 71.4 steps/s
[Step=69200 Epoch=135.3] | Loss=0.00680 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.596 | L2-Norm(final)=11.852 | 4670.5 samples/s | 73.0 steps/s
[Step=69250 Epoch=135.4] | Loss=0.00668 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.598 | L2-Norm(final)=11.855 | 4624.1 samples/s | 72.3 steps/s
[Step=69300 Epoch=135.5] | Loss=0.00674 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.599 | L2-Norm(final)=11.858 | 4672.8 samples/s | 73.0 steps/s
[Step=69350 Epoch=135.6] | Loss=0.00670 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.600 | L2-Norm(final)=11.861 | 4528.0 samples/s | 70.8 steps/s
[Step=69400 Epoch=135.7] | Loss=0.00661 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.601 | L2-Norm(final)=11.864 | 4666.5 samples/s | 72.9 steps/s
[Step=69450 Epoch=135.8] | Loss=0.00655 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=11.867 | 4606.9 samples/s | 72.0 steps/s
[Step=69500 Epoch=135.9] | Loss=0.00647 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.603 | L2-Norm(final)=11.870 | 5136.0 samples/s | 80.3 steps/s
[Step=69550 Epoch=136.0] | Loss=0.00638 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.604 | L2-Norm(final)=11.873 | 2635.6 samples/s | 41.2 steps/s
[Step=69600 Epoch=136.1] | Loss=0.00634 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.604 | L2-Norm(final)=11.876 | 4675.5 samples/s | 73.1 steps/s
[Step=69650 Epoch=136.2] | Loss=0.00623 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.605 | L2-Norm(final)=11.878 | 4536.0 samples/s | 70.9 steps/s
[Step=69700 Epoch=136.3] | Loss=0.00617 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=11.881 | 4669.4 samples/s | 73.0 steps/s
[Step=69750 Epoch=136.4] | Loss=0.00613 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=11.884 | 4569.8 samples/s | 71.4 steps/s
[Step=69800 Epoch=136.5] | Loss=0.00606 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.606 | L2-Norm(final)=11.887 | 4637.9 samples/s | 72.5 steps/s
[Step=69850 Epoch=136.6] | Loss=0.00597 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=11.889 | 4613.4 samples/s | 72.1 steps/s
[Step=69900 Epoch=136.7] | Loss=0.00593 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=11.892 | 4596.2 samples/s | 71.8 steps/s
[Step=69950 Epoch=136.8] | Loss=0.00591 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=11.895 | 4661.0 samples/s | 72.8 steps/s
[Step=70000 Epoch=136.8] | Loss=0.00587 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.607 | L2-Norm(final)=11.897 | 4619.0 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step70000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=260.6] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.027 | L2-Norm(final)=8.693 | 6872.1 samples/s | 107.4 steps/s
[Step=68050 Epoch=260.7] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.029 | L2-Norm(final)=8.710 | 4078.1 samples/s | 63.7 steps/s
[Step=68100 Epoch=260.9] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.037 | L2-Norm(final)=8.730 | 4916.6 samples/s | 76.8 steps/s
[Step=68150 Epoch=261.1] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.042 | L2-Norm(final)=8.747 | 4917.5 samples/s | 76.8 steps/s
[Step=68200 Epoch=261.3] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.048 | L2-Norm(final)=8.763 | 5093.3 samples/s | 79.6 steps/s
[Step=68250 Epoch=261.5] | Loss=0.00003 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.054 | L2-Norm(final)=8.779 | 6488.3 samples/s | 101.4 steps/s
[Step=68300 Epoch=261.7] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.058 | L2-Norm(final)=8.792 | 2464.3 samples/s | 38.5 steps/s
[Step=68350 Epoch=261.9] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=8.803 | 4937.7 samples/s | 77.2 steps/s
[Step=68400 Epoch=262.1] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=8.813 | 4800.2 samples/s | 75.0 steps/s
[Step=68450 Epoch=262.3] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.063 | L2-Norm(final)=8.822 | 4907.1 samples/s | 76.7 steps/s
[Step=68500 Epoch=262.5] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=8.830 | 5682.7 samples/s | 88.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=262.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=8.911 | 6323.6 samples/s | 98.8 steps/s
[Step=68550 Epoch=262.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.052 | L2-Norm(final)=8.918 | 3952.9 samples/s | 61.8 steps/s
[Step=68600 Epoch=262.9] | Loss=0.00038 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.043 | L2-Norm(final)=8.930 | 4313.3 samples/s | 67.4 steps/s
[Step=68650 Epoch=263.0] | Loss=0.00070 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.056 | L2-Norm(final)=8.936 | 4385.2 samples/s | 68.5 steps/s
[Step=68700 Epoch=263.2] | Loss=0.00066 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=8.940 | 4346.9 samples/s | 67.9 steps/s
[Step=68750 Epoch=263.4] | Loss=0.00055 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=8.943 | 5882.4 samples/s | 91.9 steps/s
[Step=68800 Epoch=263.6] | Loss=0.00046 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=8.946 | 2349.6 samples/s | 36.7 steps/s
[Step=68850 Epoch=263.8] | Loss=0.00039 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.080 | L2-Norm(final)=8.947 | 4317.3 samples/s | 67.5 steps/s
[Step=68900 Epoch=264.0] | Loss=0.00035 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=8.949 | 4346.8 samples/s | 67.9 steps/s
[Step=68950 Epoch=264.2] | Loss=0.00031 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.083 | L2-Norm(final)=8.950 | 4372.4 samples/s | 68.3 steps/s
[Step=69000 Epoch=264.4] | Loss=0.00028 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.951 | 4957.3 samples/s | 77.5 steps/s
[Step=69050 Epoch=264.6] | Loss=0.00025 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.952 | 2494.9 samples/s | 39.0 steps/s
[Step=69100 Epoch=264.8] | Loss=0.00023 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.953 | 4387.3 samples/s | 68.6 steps/s
[Step=69150 Epoch=265.0] | Loss=0.00022 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.954 | 4403.0 samples/s | 68.8 steps/s
[Step=69200 Epoch=265.1] | Loss=0.00020 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.955 | 4485.0 samples/s | 70.1 steps/s
[Step=69250 Epoch=265.3] | Loss=0.00019 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=8.956 | 4269.9 samples/s | 66.7 steps/s
[Step=69300 Epoch=265.5] | Loss=0.00018 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.083 | L2-Norm(final)=8.956 | 2667.8 samples/s | 41.7 steps/s
[Step=69350 Epoch=265.7] | Loss=0.00017 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.083 | L2-Norm(final)=8.957 | 4397.8 samples/s | 68.7 steps/s
[Step=69400 Epoch=265.9] | Loss=0.00016 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=8.957 | 4465.9 samples/s | 69.8 steps/s
[Step=69450 Epoch=266.1] | Loss=0.00015 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=8.958 | 4284.7 samples/s | 66.9 steps/s
[Step=69500 Epoch=266.3] | Loss=0.00014 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.080 | L2-Norm(final)=8.959 | 4439.6 samples/s | 69.4 steps/s
[Step=69550 Epoch=266.5] | Loss=0.00014 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.080 | L2-Norm(final)=8.959 | 2657.6 samples/s | 41.5 steps/s
[Step=69600 Epoch=266.7] | Loss=0.00013 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.079 | L2-Norm(final)=8.960 | 4377.1 samples/s | 68.4 steps/s
[Step=69650 Epoch=266.9] | Loss=0.00012 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=8.960 | 4450.9 samples/s | 69.5 steps/s
[Step=69700 Epoch=267.1] | Loss=0.00012 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.077 | L2-Norm(final)=8.961 | 4378.2 samples/s | 68.4 steps/s
[Step=69750 Epoch=267.3] | Loss=0.00012 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.076 | L2-Norm(final)=8.961 | 4278.0 samples/s | 66.8 steps/s
[Step=69800 Epoch=267.4] | Loss=0.00011 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.075 | L2-Norm(final)=8.962 | 6523.4 samples/s | 101.9 steps/s
[Step=69850 Epoch=267.6] | Loss=0.00011 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=8.962 | 2210.7 samples/s | 34.5 steps/s
[Step=69900 Epoch=267.8] | Loss=0.00010 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=8.963 | 4425.8 samples/s | 69.2 steps/s
[Step=69950 Epoch=268.0] | Loss=0.00010 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.072 | L2-Norm(final)=8.963 | 4390.5 samples/s | 68.6 steps/s
[Step=70000 Epoch=268.2] | Loss=0.00010 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=8.964 | 4380.2 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step70000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=261.8] | Loss=0.00006 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.474 | 5663.1 samples/s | 88.5 steps/s
[Step=68050 Epoch=262.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=8.475 | 4727.0 samples/s | 73.9 steps/s
[Step=68100 Epoch=262.1] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=8.477 | 4897.4 samples/s | 76.5 steps/s
[Step=68150 Epoch=262.3] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.479 | 4801.2 samples/s | 75.0 steps/s
[Step=68200 Epoch=262.5] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.480 | 4856.8 samples/s | 75.9 steps/s
[Step=68250 Epoch=262.7] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.482 | 7016.3 samples/s | 109.6 steps/s
[Step=68300 Epoch=262.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.483 | 2437.3 samples/s | 38.1 steps/s
[Step=68350 Epoch=263.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.484 | 5067.3 samples/s | 79.2 steps/s
[Step=68400 Epoch=263.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.486 | 4716.7 samples/s | 73.7 steps/s
[Step=68450 Epoch=263.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.487 | 4938.5 samples/s | 77.2 steps/s
[Step=68500 Epoch=263.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.145 | L2-Norm(final)=8.489 | 5742.6 samples/s | 89.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=263.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.144 | L2-Norm(final)=8.503 | 6522.6 samples/s | 101.9 steps/s
[Step=68550 Epoch=263.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.143 | L2-Norm(final)=8.505 | 3845.9 samples/s | 60.1 steps/s
[Step=68600 Epoch=264.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=8.506 | 4268.0 samples/s | 66.7 steps/s
[Step=68650 Epoch=264.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.139 | L2-Norm(final)=8.508 | 4353.2 samples/s | 68.0 steps/s
[Step=68700 Epoch=264.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.137 | L2-Norm(final)=8.509 | 4381.9 samples/s | 68.5 steps/s
[Step=68750 Epoch=264.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.135 | L2-Norm(final)=8.510 | 6003.4 samples/s | 93.8 steps/s
[Step=68800 Epoch=264.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.132 | L2-Norm(final)=8.511 | 2314.2 samples/s | 36.2 steps/s
[Step=68850 Epoch=265.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.130 | L2-Norm(final)=8.512 | 4352.7 samples/s | 68.0 steps/s
[Step=68900 Epoch=265.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.128 | L2-Norm(final)=8.513 | 4388.1 samples/s | 68.6 steps/s
[Step=68950 Epoch=265.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=8.514 | 4445.2 samples/s | 69.5 steps/s
[Step=69000 Epoch=265.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.123 | L2-Norm(final)=8.515 | 5031.9 samples/s | 78.6 steps/s
[Step=69050 Epoch=265.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.120 | L2-Norm(final)=8.516 | 2466.0 samples/s | 38.5 steps/s
[Step=69100 Epoch=266.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.117 | L2-Norm(final)=8.517 | 4414.6 samples/s | 69.0 steps/s
[Step=69150 Epoch=266.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.115 | L2-Norm(final)=8.518 | 4507.2 samples/s | 70.4 steps/s
[Step=69200 Epoch=266.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.112 | L2-Norm(final)=8.519 | 4245.2 samples/s | 66.3 steps/s
[Step=69250 Epoch=266.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.109 | L2-Norm(final)=8.520 | 4493.6 samples/s | 70.2 steps/s
[Step=69300 Epoch=266.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.106 | L2-Norm(final)=8.521 | 2652.7 samples/s | 41.4 steps/s
[Step=69350 Epoch=267.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.103 | L2-Norm(final)=8.522 | 4382.5 samples/s | 68.5 steps/s
[Step=69400 Epoch=267.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.523 | 4382.2 samples/s | 68.5 steps/s
[Step=69450 Epoch=267.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=8.524 | 4394.6 samples/s | 68.7 steps/s
[Step=69500 Epoch=267.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=8.525 | 4415.1 samples/s | 69.0 steps/s
[Step=69550 Epoch=267.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.091 | L2-Norm(final)=8.526 | 2677.8 samples/s | 41.8 steps/s
[Step=69600 Epoch=267.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=8.527 | 4369.6 samples/s | 68.3 steps/s
[Step=69650 Epoch=268.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.085 | L2-Norm(final)=8.528 | 4391.1 samples/s | 68.6 steps/s
[Step=69700 Epoch=268.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=8.528 | 4354.1 samples/s | 68.0 steps/s
[Step=69750 Epoch=268.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=8.529 | 4386.5 samples/s | 68.5 steps/s
[Step=69800 Epoch=268.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.075 | L2-Norm(final)=8.530 | 7186.8 samples/s | 112.3 steps/s
[Step=69850 Epoch=268.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=8.531 | 2180.9 samples/s | 34.1 steps/s
[Step=69900 Epoch=269.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.068 | L2-Norm(final)=8.532 | 4351.1 samples/s | 68.0 steps/s
[Step=69950 Epoch=269.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=8.533 | 4406.8 samples/s | 68.9 steps/s
[Step=70000 Epoch=269.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=8.534 | 4414.9 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08130 | acc=0.9677 | tpr=0.9752 | fpr=0.0486 | 5102.1 samples/s | 19.9 steps/s
Avg test loss: 0.08248, Avg test acc: 0.96658, Avg tpr: 0.97453, Avg fpr: 0.05089, total FA: 397

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08246 | acc=0.9669 | tpr=0.9756 | fpr=0.0520 | 5326.7 samples/s | 20.8 steps/s
Avg test loss: 0.08413, Avg test acc: 0.96739, Avg tpr: 0.97564, Avg fpr: 0.05076, total FA: 396

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.74951 | acc=0.3099 | tpr=0.0041 | fpr=0.0260 | 5137.8 samples/s | 20.1 steps/s
Avg test loss: 5.76627, Avg test acc: 0.30764, Avg tpr: 0.00408, Avg fpr: 0.02474, total FA: 193

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.22641 | acc=0.3082 | tpr=0.0070 | fpr=0.0377 | 5426.5 samples/s | 21.2 steps/s
Avg test loss: 5.23298, Avg test acc: 0.30688, Avg tpr: 0.00705, Avg fpr: 0.03371, total FA: 263

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.95006 | acc=0.1298 | tpr=0.7522 | fpr=0.8814 | 5268.1 samples/s | 20.6 steps/s
[Step= 100] | Loss=5.92758 | acc=0.1290 | tpr=0.7463 | fpr=0.8825 | 7398.2 samples/s | 28.9 steps/s
[Step= 150] | Loss=5.92578 | acc=0.1299 | tpr=0.7622 | fpr=0.8817 | 7519.1 samples/s | 29.4 steps/s
[Step= 200] | Loss=5.93838 | acc=0.1287 | tpr=0.7530 | fpr=0.8827 | 8168.0 samples/s | 31.9 steps/s
[Step= 250] | Loss=5.94623 | acc=0.1290 | tpr=0.7397 | fpr=0.8822 | 8061.9 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.94679 | acc=0.1287 | tpr=0.7418 | fpr=0.8825 | 8256.3 samples/s | 32.3 steps/s
[Step= 350] | Loss=5.93648 | acc=0.1288 | tpr=0.7408 | fpr=0.8823 | 7841.3 samples/s | 30.6 steps/s
[Step= 400] | Loss=5.92913 | acc=0.1292 | tpr=0.7445 | fpr=0.8820 | 8127.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.93033 | acc=0.1286 | tpr=0.7473 | fpr=0.8827 | 8382.3 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.92976 | acc=0.1283 | tpr=0.7467 | fpr=0.8829 | 8112.2 samples/s | 31.7 steps/s
[Step= 550] | Loss=5.92851 | acc=0.1285 | tpr=0.7433 | fpr=0.8827 | 14887.0 samples/s | 58.2 steps/s
Avg test loss: 5.92969, Avg test acc: 0.12841, Avg tpr: 0.74326, Avg fpr: 0.88277, total FA: 122571

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.33010 | acc=0.1359 | tpr=0.7345 | fpr=0.8749 | 5303.9 samples/s | 20.7 steps/s
[Step= 100] | Loss=6.31040 | acc=0.1359 | tpr=0.7292 | fpr=0.8751 | 7049.6 samples/s | 27.5 steps/s
[Step= 150] | Loss=6.30288 | acc=0.1357 | tpr=0.7349 | fpr=0.8754 | 7907.0 samples/s | 30.9 steps/s
[Step= 200] | Loss=6.31322 | acc=0.1346 | tpr=0.7377 | fpr=0.8763 | 7978.5 samples/s | 31.2 steps/s
[Step= 250] | Loss=6.31852 | acc=0.1354 | tpr=0.7319 | fpr=0.8755 | 8216.7 samples/s | 32.1 steps/s
[Step= 300] | Loss=6.32205 | acc=0.1354 | tpr=0.7345 | fpr=0.8756 | 8063.7 samples/s | 31.5 steps/s
[Step= 350] | Loss=6.30827 | acc=0.1355 | tpr=0.7307 | fpr=0.8753 | 8382.1 samples/s | 32.7 steps/s
[Step= 400] | Loss=6.29981 | acc=0.1360 | tpr=0.7270 | fpr=0.8747 | 7872.7 samples/s | 30.8 steps/s
[Step= 450] | Loss=6.29784 | acc=0.1352 | tpr=0.7259 | fpr=0.8755 | 8199.9 samples/s | 32.0 steps/s
[Step= 500] | Loss=6.30048 | acc=0.1350 | tpr=0.7242 | fpr=0.8757 | 8108.4 samples/s | 31.7 steps/s
[Step= 550] | Loss=6.29767 | acc=0.1351 | tpr=0.7199 | fpr=0.8755 | 14648.2 samples/s | 57.2 steps/s
Avg test loss: 6.29929, Avg test acc: 0.13510, Avg tpr: 0.71949, Avg fpr: 0.87552, total FA: 121564

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10931 | acc=0.9808 | tpr=0.9558 | fpr=0.0188 | 5416.7 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.11528 | acc=0.9796 | tpr=0.9574 | fpr=0.0199 | 6856.5 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.11987 | acc=0.9786 | tpr=0.9597 | fpr=0.0211 | 7853.2 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.12125 | acc=0.9787 | tpr=0.9563 | fpr=0.0209 | 8166.1 samples/s | 31.9 steps/s
[Step= 250] | Loss=0.11984 | acc=0.9789 | tpr=0.9555 | fpr=0.0207 | 7905.1 samples/s | 30.9 steps/s
[Step= 300] | Loss=0.12148 | acc=0.9787 | tpr=0.9527 | fpr=0.0209 | 8552.6 samples/s | 33.4 steps/s
[Step= 350] | Loss=0.12202 | acc=0.9785 | tpr=0.9549 | fpr=0.0211 | 8188.6 samples/s | 32.0 steps/s
[Step= 400] | Loss=0.12334 | acc=0.9783 | tpr=0.9513 | fpr=0.0212 | 8489.9 samples/s | 33.2 steps/s
[Step= 450] | Loss=0.12581 | acc=0.9780 | tpr=0.9503 | fpr=0.0215 | 7845.7 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.12542 | acc=0.9780 | tpr=0.9502 | fpr=0.0215 | 8699.2 samples/s | 34.0 steps/s
[Step= 550] | Loss=0.12446 | acc=0.9781 | tpr=0.9491 | fpr=0.0214 | 13613.6 samples/s | 53.2 steps/s
Avg test loss: 0.12416, Avg test acc: 0.97809, Avg tpr: 0.94849, Avg fpr: 0.02138, total FA: 2968

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13771 | acc=0.9781 | tpr=0.9425 | fpr=0.0212 | 5462.7 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.14432 | acc=0.9771 | tpr=0.9510 | fpr=0.0224 | 7239.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.14969 | acc=0.9764 | tpr=0.9553 | fpr=0.0233 | 7559.7 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.15221 | acc=0.9763 | tpr=0.9596 | fpr=0.0234 | 8070.3 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.14945 | acc=0.9767 | tpr=0.9607 | fpr=0.0230 | 8082.2 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.15211 | acc=0.9765 | tpr=0.9585 | fpr=0.0232 | 7790.1 samples/s | 30.4 steps/s
[Step= 350] | Loss=0.15316 | acc=0.9762 | tpr=0.9587 | fpr=0.0235 | 8523.8 samples/s | 33.3 steps/s
[Step= 400] | Loss=0.15464 | acc=0.9760 | tpr=0.9557 | fpr=0.0236 | 7974.3 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.15772 | acc=0.9756 | tpr=0.9552 | fpr=0.0240 | 7828.9 samples/s | 30.6 steps/s
[Step= 500] | Loss=0.15699 | acc=0.9756 | tpr=0.9551 | fpr=0.0240 | 8382.4 samples/s | 32.7 steps/s
[Step= 550] | Loss=0.15578 | acc=0.9758 | tpr=0.9550 | fpr=0.0239 | 14211.0 samples/s | 55.5 steps/s
Avg test loss: 0.15540, Avg test acc: 0.97576, Avg tpr: 0.95404, Avg fpr: 0.02385, total FA: 3311

server round 35/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=136.5] | Loss=0.00656 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=11.469 | 7017.4 samples/s | 109.6 steps/s
[Step=70050 Epoch=136.6] | Loss=0.00492 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=11.474 | 4424.1 samples/s | 69.1 steps/s
[Step=70100 Epoch=136.7] | Loss=0.00500 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=11.479 | 5109.2 samples/s | 79.8 steps/s
[Step=70150 Epoch=136.8] | Loss=0.00520 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=11.484 | 5139.4 samples/s | 80.3 steps/s
[Step=70200 Epoch=136.9] | Loss=0.00537 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.207 | L2-Norm(final)=11.489 | 5198.7 samples/s | 81.2 steps/s
[Step=70250 Epoch=137.0] | Loss=0.00561 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.209 | L2-Norm(final)=11.494 | 5264.9 samples/s | 82.3 steps/s
[Step=70300 Epoch=137.1] | Loss=0.00562 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.210 | L2-Norm(final)=11.499 | 5171.3 samples/s | 80.8 steps/s
[Step=70350 Epoch=137.2] | Loss=0.00563 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=11.504 | 5261.5 samples/s | 82.2 steps/s
[Step=70400 Epoch=137.3] | Loss=0.00587 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.212 | L2-Norm(final)=11.509 | 5128.4 samples/s | 80.1 steps/s
[Step=70450 Epoch=137.4] | Loss=0.00592 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.213 | L2-Norm(final)=11.514 | 5243.2 samples/s | 81.9 steps/s
[Step=70500 Epoch=137.5] | Loss=0.00577 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.214 | L2-Norm(final)=11.519 | 6914.0 samples/s | 108.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=137.5] | Loss=0.00290 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.226 | L2-Norm(final)=11.571 | 6321.7 samples/s | 98.8 steps/s
[Step=70550 Epoch=137.6] | Loss=0.00597 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.227 | L2-Norm(final)=11.575 | 4334.5 samples/s | 67.7 steps/s
[Step=70600 Epoch=137.7] | Loss=0.00604 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.230 | L2-Norm(final)=11.580 | 4591.4 samples/s | 71.7 steps/s
[Step=70650 Epoch=137.8] | Loss=0.00661 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.233 | L2-Norm(final)=11.584 | 4623.0 samples/s | 72.2 steps/s
[Step=70700 Epoch=137.9] | Loss=0.00711 | Reg=0.00232 | acc=0.9531 | L2-Norm=15.236 | L2-Norm(final)=11.588 | 4712.7 samples/s | 73.6 steps/s
[Step=70750 Epoch=138.0] | Loss=0.00714 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=11.591 | 4669.6 samples/s | 73.0 steps/s
[Step=70800 Epoch=138.1] | Loss=0.00711 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.240 | L2-Norm(final)=11.595 | 4508.2 samples/s | 70.4 steps/s
[Step=70850 Epoch=138.2] | Loss=0.00719 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.241 | L2-Norm(final)=11.598 | 4660.9 samples/s | 72.8 steps/s
[Step=70900 Epoch=138.3] | Loss=0.00707 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.243 | L2-Norm(final)=11.602 | 4679.6 samples/s | 73.1 steps/s
[Step=70950 Epoch=138.4] | Loss=0.00681 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=11.606 | 4535.6 samples/s | 70.9 steps/s
[Step=71000 Epoch=138.5] | Loss=0.00680 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.247 | L2-Norm(final)=11.609 | 5949.2 samples/s | 93.0 steps/s
[Step=71050 Epoch=138.6] | Loss=0.00670 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.248 | L2-Norm(final)=11.613 | 2462.1 samples/s | 38.5 steps/s
[Step=71100 Epoch=138.7] | Loss=0.00656 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=11.616 | 4595.7 samples/s | 71.8 steps/s
[Step=71150 Epoch=138.8] | Loss=0.00653 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=11.620 | 4599.2 samples/s | 71.9 steps/s
[Step=71200 Epoch=138.9] | Loss=0.00649 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.252 | L2-Norm(final)=11.623 | 4587.6 samples/s | 71.7 steps/s
[Step=71250 Epoch=139.0] | Loss=0.00651 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.253 | L2-Norm(final)=11.626 | 4626.9 samples/s | 72.3 steps/s
[Step=71300 Epoch=139.1] | Loss=0.00642 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=11.629 | 4641.7 samples/s | 72.5 steps/s
[Step=71350 Epoch=139.2] | Loss=0.00632 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.255 | L2-Norm(final)=11.632 | 4645.6 samples/s | 72.6 steps/s
[Step=71400 Epoch=139.3] | Loss=0.00626 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=11.635 | 4693.8 samples/s | 73.3 steps/s
[Step=71450 Epoch=139.4] | Loss=0.00623 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.257 | L2-Norm(final)=11.638 | 4586.5 samples/s | 71.7 steps/s
[Step=71500 Epoch=139.5] | Loss=0.00623 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=11.641 | 4972.2 samples/s | 77.7 steps/s
[Step=71550 Epoch=139.6] | Loss=0.00618 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=11.644 | 2653.4 samples/s | 41.5 steps/s
[Step=71600 Epoch=139.6] | Loss=0.00612 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=11.646 | 4694.4 samples/s | 73.4 steps/s
[Step=71650 Epoch=139.7] | Loss=0.00599 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=11.649 | 4547.8 samples/s | 71.1 steps/s
[Step=71700 Epoch=139.8] | Loss=0.00595 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=11.652 | 4703.7 samples/s | 73.5 steps/s
[Step=71750 Epoch=139.9] | Loss=0.00590 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=11.655 | 4551.0 samples/s | 71.1 steps/s
[Step=71800 Epoch=140.0] | Loss=0.00591 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=11.658 | 4599.1 samples/s | 71.9 steps/s
[Step=71850 Epoch=140.1] | Loss=0.00590 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=11.660 | 4665.0 samples/s | 72.9 steps/s
[Step=71900 Epoch=140.2] | Loss=0.00589 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=11.663 | 4571.2 samples/s | 71.4 steps/s
[Step=71950 Epoch=140.3] | Loss=0.00584 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=11.665 | 4654.0 samples/s | 72.7 steps/s
[Step=72000 Epoch=140.4] | Loss=0.00580 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.261 | L2-Norm(final)=11.668 | 4620.2 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step72000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=136.9] | Loss=0.00927 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.541 | L2-Norm(final)=11.976 | 5729.2 samples/s | 89.5 steps/s
[Step=70050 Epoch=136.9] | Loss=0.00618 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.542 | L2-Norm(final)=11.980 | 5111.0 samples/s | 79.9 steps/s
[Step=70100 Epoch=137.0] | Loss=0.00605 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.543 | L2-Norm(final)=11.985 | 5111.8 samples/s | 79.9 steps/s
[Step=70150 Epoch=137.1] | Loss=0.00585 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.544 | L2-Norm(final)=11.990 | 5139.2 samples/s | 80.3 steps/s
[Step=70200 Epoch=137.2] | Loss=0.00533 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=11.995 | 5178.4 samples/s | 80.9 steps/s
[Step=70250 Epoch=137.3] | Loss=0.00532 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=12.001 | 5201.4 samples/s | 81.3 steps/s
[Step=70300 Epoch=137.4] | Loss=0.00537 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=12.006 | 5210.6 samples/s | 81.4 steps/s
[Step=70350 Epoch=137.5] | Loss=0.00538 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.547 | L2-Norm(final)=12.011 | 5225.4 samples/s | 81.6 steps/s
[Step=70400 Epoch=137.6] | Loss=0.00532 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.548 | L2-Norm(final)=12.016 | 5237.6 samples/s | 81.8 steps/s
[Step=70450 Epoch=137.7] | Loss=0.00527 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=12.022 | 5214.0 samples/s | 81.5 steps/s
[Step=70500 Epoch=137.8] | Loss=0.00531 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=12.027 | 7051.7 samples/s | 110.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=137.8] | Loss=0.00270 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=12.081 | 6285.1 samples/s | 98.2 steps/s
[Step=70550 Epoch=137.9] | Loss=0.00649 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.561 | L2-Norm(final)=12.086 | 4209.8 samples/s | 65.8 steps/s
[Step=70600 Epoch=138.0] | Loss=0.00634 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.564 | L2-Norm(final)=12.090 | 4657.6 samples/s | 72.8 steps/s
[Step=70650 Epoch=138.1] | Loss=0.00682 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=12.094 | 4572.3 samples/s | 71.4 steps/s
[Step=70700 Epoch=138.2] | Loss=0.00719 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.568 | L2-Norm(final)=12.097 | 4630.0 samples/s | 72.3 steps/s
[Step=70750 Epoch=138.3] | Loss=0.00680 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.570 | L2-Norm(final)=12.101 | 4618.3 samples/s | 72.2 steps/s
[Step=70800 Epoch=138.4] | Loss=0.00689 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.572 | L2-Norm(final)=12.104 | 4728.9 samples/s | 73.9 steps/s
[Step=70850 Epoch=138.5] | Loss=0.00678 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.573 | L2-Norm(final)=12.107 | 4552.6 samples/s | 71.1 steps/s
[Step=70900 Epoch=138.6] | Loss=0.00664 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.575 | L2-Norm(final)=12.111 | 4657.9 samples/s | 72.8 steps/s
[Step=70950 Epoch=138.7] | Loss=0.00678 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.576 | L2-Norm(final)=12.114 | 4633.2 samples/s | 72.4 steps/s
[Step=71000 Epoch=138.8] | Loss=0.00650 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.577 | L2-Norm(final)=12.117 | 6029.3 samples/s | 94.2 steps/s
[Step=71050 Epoch=138.9] | Loss=0.00623 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=12.120 | 2427.5 samples/s | 37.9 steps/s
[Step=71100 Epoch=139.0] | Loss=0.00609 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=12.124 | 4664.1 samples/s | 72.9 steps/s
[Step=71150 Epoch=139.1] | Loss=0.00606 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.580 | L2-Norm(final)=12.127 | 4617.7 samples/s | 72.2 steps/s
[Step=71200 Epoch=139.2] | Loss=0.00593 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.581 | L2-Norm(final)=12.130 | 4566.3 samples/s | 71.3 steps/s
[Step=71250 Epoch=139.3] | Loss=0.00590 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.581 | L2-Norm(final)=12.134 | 4619.6 samples/s | 72.2 steps/s
[Step=71300 Epoch=139.4] | Loss=0.00583 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=12.137 | 4665.3 samples/s | 72.9 steps/s
[Step=71350 Epoch=139.5] | Loss=0.00579 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.583 | L2-Norm(final)=12.140 | 4622.3 samples/s | 72.2 steps/s
[Step=71400 Epoch=139.6] | Loss=0.00583 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.583 | L2-Norm(final)=12.143 | 4681.2 samples/s | 73.1 steps/s
[Step=71450 Epoch=139.7] | Loss=0.00577 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.583 | L2-Norm(final)=12.146 | 4602.9 samples/s | 71.9 steps/s
[Step=71500 Epoch=139.8] | Loss=0.00571 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.584 | L2-Norm(final)=12.149 | 5080.3 samples/s | 79.4 steps/s
[Step=71550 Epoch=139.9] | Loss=0.00572 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=12.152 | 2641.9 samples/s | 41.3 steps/s
[Step=71600 Epoch=140.0] | Loss=0.00568 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=12.155 | 4587.7 samples/s | 71.7 steps/s
[Step=71650 Epoch=140.1] | Loss=0.00563 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=12.158 | 4601.5 samples/s | 71.9 steps/s
[Step=71700 Epoch=140.2] | Loss=0.00555 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.585 | L2-Norm(final)=12.160 | 4638.8 samples/s | 72.5 steps/s
[Step=71750 Epoch=140.3] | Loss=0.00551 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=12.163 | 4561.6 samples/s | 71.3 steps/s
[Step=71800 Epoch=140.4] | Loss=0.00552 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=12.166 | 4621.2 samples/s | 72.2 steps/s
[Step=71850 Epoch=140.5] | Loss=0.00549 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.585 | L2-Norm(final)=12.169 | 4655.0 samples/s | 72.7 steps/s
[Step=71900 Epoch=140.6] | Loss=0.00543 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=12.172 | 4544.9 samples/s | 71.0 steps/s
[Step=71950 Epoch=140.7] | Loss=0.00542 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.585 | L2-Norm(final)=12.174 | 4657.8 samples/s | 72.8 steps/s
[Step=72000 Epoch=140.8] | Loss=0.00545 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.585 | L2-Norm(final)=12.177 | 4614.7 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step72000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=268.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.977 | 5688.9 samples/s | 88.9 steps/s
[Step=70050 Epoch=268.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.978 | 4217.1 samples/s | 65.9 steps/s
[Step=70100 Epoch=268.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.979 | 4891.7 samples/s | 76.4 steps/s
[Step=70150 Epoch=268.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.980 | 4870.5 samples/s | 76.1 steps/s
[Step=70200 Epoch=269.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.981 | 4895.6 samples/s | 76.5 steps/s
[Step=70250 Epoch=269.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.982 | 6792.6 samples/s | 106.1 steps/s
[Step=70300 Epoch=269.4] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.100 | L2-Norm(final)=8.983 | 2511.4 samples/s | 39.2 steps/s
[Step=70350 Epoch=269.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.984 | 4843.5 samples/s | 75.7 steps/s
[Step=70400 Epoch=269.7] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.985 | 4853.8 samples/s | 75.8 steps/s
[Step=70450 Epoch=269.9] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.986 | 4980.1 samples/s | 77.8 steps/s
[Step=70500 Epoch=270.1] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=8.987 | 5527.0 samples/s | 86.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=270.1] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=8.997 | 6073.9 samples/s | 94.9 steps/s
[Step=70550 Epoch=270.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.096 | L2-Norm(final)=8.998 | 3993.3 samples/s | 62.4 steps/s
[Step=70600 Epoch=270.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.094 | L2-Norm(final)=8.999 | 4380.4 samples/s | 68.4 steps/s
[Step=70650 Epoch=270.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.092 | L2-Norm(final)=9.000 | 4396.2 samples/s | 68.7 steps/s
[Step=70700 Epoch=270.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.090 | L2-Norm(final)=9.001 | 4418.2 samples/s | 69.0 steps/s
[Step=70750 Epoch=271.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.088 | L2-Norm(final)=9.002 | 5867.1 samples/s | 91.7 steps/s
[Step=70800 Epoch=271.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.086 | L2-Norm(final)=9.002 | 2322.3 samples/s | 36.3 steps/s
[Step=70850 Epoch=271.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.084 | L2-Norm(final)=9.003 | 4512.2 samples/s | 70.5 steps/s
[Step=70900 Epoch=271.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=9.004 | 4313.6 samples/s | 67.4 steps/s
[Step=70950 Epoch=271.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.080 | L2-Norm(final)=9.005 | 4378.9 samples/s | 68.4 steps/s
[Step=71000 Epoch=272.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.078 | L2-Norm(final)=9.006 | 4962.4 samples/s | 77.5 steps/s
[Step=71050 Epoch=272.2] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.076 | L2-Norm(final)=9.007 | 2502.1 samples/s | 39.1 steps/s
[Step=71100 Epoch=272.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.073 | L2-Norm(final)=9.007 | 4451.9 samples/s | 69.6 steps/s
[Step=71150 Epoch=272.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.071 | L2-Norm(final)=9.008 | 4343.3 samples/s | 67.9 steps/s
[Step=71200 Epoch=272.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=9.009 | 4389.1 samples/s | 68.6 steps/s
[Step=71250 Epoch=273.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.066 | L2-Norm(final)=9.010 | 4434.2 samples/s | 69.3 steps/s
[Step=71300 Epoch=273.2] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=9.010 | 2676.2 samples/s | 41.8 steps/s
[Step=71350 Epoch=273.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=9.011 | 4352.8 samples/s | 68.0 steps/s
[Step=71400 Epoch=273.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.059 | L2-Norm(final)=9.012 | 4446.1 samples/s | 69.5 steps/s
[Step=71450 Epoch=273.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=9.013 | 4316.5 samples/s | 67.4 steps/s
[Step=71500 Epoch=274.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.054 | L2-Norm(final)=9.013 | 4493.1 samples/s | 70.2 steps/s
[Step=71550 Epoch=274.2] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.052 | L2-Norm(final)=9.014 | 2669.1 samples/s | 41.7 steps/s
[Step=71600 Epoch=274.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.049 | L2-Norm(final)=9.015 | 4335.6 samples/s | 67.7 steps/s
[Step=71650 Epoch=274.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.046 | L2-Norm(final)=9.016 | 4322.5 samples/s | 67.5 steps/s
[Step=71700 Epoch=274.7] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.044 | L2-Norm(final)=9.017 | 4424.2 samples/s | 69.1 steps/s
[Step=71750 Epoch=274.9] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.041 | L2-Norm(final)=9.017 | 4441.6 samples/s | 69.4 steps/s
[Step=71800 Epoch=275.1] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.038 | L2-Norm(final)=9.018 | 6261.6 samples/s | 97.8 steps/s
[Step=71850 Epoch=275.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.035 | L2-Norm(final)=9.019 | 2236.6 samples/s | 34.9 steps/s
[Step=71900 Epoch=275.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.033 | L2-Norm(final)=9.020 | 4397.1 samples/s | 68.7 steps/s
[Step=71950 Epoch=275.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.030 | L2-Norm(final)=9.020 | 4324.9 samples/s | 67.6 steps/s
[Step=72000 Epoch=275.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.027 | L2-Norm(final)=9.021 | 4394.8 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step72000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=269.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=8.566 | 6195.0 samples/s | 96.8 steps/s
[Step=70050 Epoch=269.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.109 | L2-Norm(final)=8.569 | 4389.2 samples/s | 68.6 steps/s
[Step=70100 Epoch=269.8] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.110 | L2-Norm(final)=8.573 | 4797.6 samples/s | 75.0 steps/s
[Step=70150 Epoch=270.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.111 | L2-Norm(final)=8.578 | 4908.8 samples/s | 76.7 steps/s
[Step=70200 Epoch=270.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=8.583 | 4869.5 samples/s | 76.1 steps/s
[Step=70250 Epoch=270.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.115 | L2-Norm(final)=8.589 | 7033.2 samples/s | 109.9 steps/s
[Step=70300 Epoch=270.6] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.117 | L2-Norm(final)=8.594 | 2456.4 samples/s | 38.4 steps/s
[Step=70350 Epoch=270.8] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.118 | L2-Norm(final)=8.599 | 4931.5 samples/s | 77.1 steps/s
[Step=70400 Epoch=271.0] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.119 | L2-Norm(final)=8.604 | 4871.2 samples/s | 76.1 steps/s
[Step=70450 Epoch=271.2] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.120 | L2-Norm(final)=8.609 | 4894.6 samples/s | 76.5 steps/s
[Step=70500 Epoch=271.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=8.613 | 5883.8 samples/s | 91.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=271.4] | Loss=0.00002 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.127 | L2-Norm(final)=8.659 | 6319.2 samples/s | 98.7 steps/s
[Step=70550 Epoch=271.6] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.123 | L2-Norm(final)=8.662 | 3894.4 samples/s | 60.8 steps/s
[Step=70600 Epoch=271.8] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.119 | L2-Norm(final)=8.666 | 4422.4 samples/s | 69.1 steps/s
[Step=70650 Epoch=272.0] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.114 | L2-Norm(final)=8.670 | 4360.5 samples/s | 68.1 steps/s
[Step=70700 Epoch=272.2] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.108 | L2-Norm(final)=8.673 | 4370.1 samples/s | 68.3 steps/s
[Step=70750 Epoch=272.3] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.102 | L2-Norm(final)=8.675 | 6017.2 samples/s | 94.0 steps/s
[Step=70800 Epoch=272.5] | Loss=0.00001 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.096 | L2-Norm(final)=8.678 | 2306.2 samples/s | 36.0 steps/s
[Step=70850 Epoch=272.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.089 | L2-Norm(final)=8.680 | 4428.2 samples/s | 69.2 steps/s
[Step=70900 Epoch=272.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.083 | L2-Norm(final)=8.682 | 4324.7 samples/s | 67.6 steps/s
[Step=70950 Epoch=273.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.076 | L2-Norm(final)=8.684 | 4354.0 samples/s | 68.0 steps/s
[Step=71000 Epoch=273.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=8.686 | 5127.4 samples/s | 80.1 steps/s
[Step=71050 Epoch=273.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=8.688 | 2495.5 samples/s | 39.0 steps/s
[Step=71100 Epoch=273.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=8.691 | 4302.8 samples/s | 67.2 steps/s
[Step=71150 Epoch=273.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.048 | L2-Norm(final)=8.693 | 4381.3 samples/s | 68.5 steps/s
[Step=71200 Epoch=274.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.040 | L2-Norm(final)=8.695 | 4395.5 samples/s | 68.7 steps/s
[Step=71250 Epoch=274.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.033 | L2-Norm(final)=8.697 | 4479.5 samples/s | 70.0 steps/s
[Step=71300 Epoch=274.5] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.025 | L2-Norm(final)=8.699 | 2643.8 samples/s | 41.3 steps/s
[Step=71350 Epoch=274.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.018 | L2-Norm(final)=8.701 | 4403.2 samples/s | 68.8 steps/s
[Step=71400 Epoch=274.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.010 | L2-Norm(final)=8.703 | 4367.3 samples/s | 68.2 steps/s
[Step=71450 Epoch=275.0] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.002 | L2-Norm(final)=8.705 | 4379.3 samples/s | 68.4 steps/s
[Step=71500 Epoch=275.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=8.707 | 4433.6 samples/s | 69.3 steps/s
[Step=71550 Epoch=275.4] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=8.709 | 2685.0 samples/s | 42.0 steps/s
[Step=71600 Epoch=275.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.978 | L2-Norm(final)=8.711 | 4344.2 samples/s | 67.9 steps/s
[Step=71650 Epoch=275.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.970 | L2-Norm(final)=8.713 | 4459.2 samples/s | 69.7 steps/s
[Step=71700 Epoch=276.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.962 | L2-Norm(final)=8.715 | 4362.1 samples/s | 68.2 steps/s
[Step=71750 Epoch=276.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.953 | L2-Norm(final)=8.717 | 4373.2 samples/s | 68.3 steps/s
[Step=71800 Epoch=276.4] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=8.719 | 7163.4 samples/s | 111.9 steps/s
[Step=71850 Epoch=276.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.936 | L2-Norm(final)=8.722 | 2184.9 samples/s | 34.1 steps/s
[Step=71900 Epoch=276.8] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.927 | L2-Norm(final)=8.724 | 4463.1 samples/s | 69.7 steps/s
[Step=71950 Epoch=277.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.919 | L2-Norm(final)=8.726 | 4208.4 samples/s | 65.8 steps/s
[Step=72000 Epoch=277.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.910 | L2-Norm(final)=8.728 | 4414.1 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08072 | acc=0.9677 | tpr=0.9754 | fpr=0.0488 | 5210.4 samples/s | 20.4 steps/s
Avg test loss: 0.08178, Avg test acc: 0.96650, Avg tpr: 0.97389, Avg fpr: 0.04974, total FA: 388

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08459 | acc=0.9674 | tpr=0.9784 | fpr=0.0565 | 5240.8 samples/s | 20.5 steps/s
Avg test loss: 0.08595, Avg test acc: 0.96803, Avg tpr: 0.97855, Avg fpr: 0.05512, total FA: 430

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.59781 | acc=0.3077 | tpr=0.0066 | fpr=0.0384 | 5285.6 samples/s | 20.6 steps/s
Avg test loss: 5.60644, Avg test acc: 0.30615, Avg tpr: 0.00624, Avg fpr: 0.03423, total FA: 267

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.10058 | acc=0.3081 | tpr=0.0082 | fpr=0.0406 | 5104.3 samples/s | 19.9 steps/s
Avg test loss: 5.10616, Avg test acc: 0.30660, Avg tpr: 0.00787, Avg fpr: 0.03641, total FA: 284

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.01924 | acc=0.1251 | tpr=0.7522 | fpr=0.8862 | 5359.0 samples/s | 20.9 steps/s
[Step= 100] | Loss=5.99455 | acc=0.1239 | tpr=0.7377 | fpr=0.8875 | 6605.7 samples/s | 25.8 steps/s
[Step= 150] | Loss=5.99426 | acc=0.1255 | tpr=0.7536 | fpr=0.8861 | 8484.6 samples/s | 33.1 steps/s
[Step= 200] | Loss=6.00518 | acc=0.1243 | tpr=0.7475 | fpr=0.8871 | 8092.9 samples/s | 31.6 steps/s
[Step= 250] | Loss=6.01202 | acc=0.1247 | tpr=0.7415 | fpr=0.8865 | 7803.7 samples/s | 30.5 steps/s
[Step= 300] | Loss=6.01371 | acc=0.1245 | tpr=0.7447 | fpr=0.8868 | 8476.2 samples/s | 33.1 steps/s
[Step= 350] | Loss=6.00352 | acc=0.1248 | tpr=0.7433 | fpr=0.8864 | 7968.2 samples/s | 31.1 steps/s
[Step= 400] | Loss=5.99581 | acc=0.1255 | tpr=0.7500 | fpr=0.8859 | 8384.7 samples/s | 32.8 steps/s
[Step= 450] | Loss=5.99647 | acc=0.1249 | tpr=0.7527 | fpr=0.8865 | 7782.0 samples/s | 30.4 steps/s
[Step= 500] | Loss=5.99558 | acc=0.1245 | tpr=0.7507 | fpr=0.8868 | 8376.7 samples/s | 32.7 steps/s
[Step= 550] | Loss=5.99452 | acc=0.1246 | tpr=0.7473 | fpr=0.8867 | 13901.2 samples/s | 54.3 steps/s
Avg test loss: 5.99590, Avg test acc: 0.12457, Avg tpr: 0.74762, Avg fpr: 0.88675, total FA: 123124

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.66639 | acc=0.1273 | tpr=0.7655 | fpr=0.8842 | 5045.4 samples/s | 19.7 steps/s
[Step= 100] | Loss=6.64699 | acc=0.1277 | tpr=0.7569 | fpr=0.8840 | 7560.2 samples/s | 29.5 steps/s
[Step= 150] | Loss=6.63393 | acc=0.1284 | tpr=0.7709 | fpr=0.8834 | 8083.2 samples/s | 31.6 steps/s
[Step= 200] | Loss=6.64532 | acc=0.1269 | tpr=0.7694 | fpr=0.8848 | 7825.1 samples/s | 30.6 steps/s
[Step= 250] | Loss=6.65054 | acc=0.1277 | tpr=0.7607 | fpr=0.8839 | 8363.8 samples/s | 32.7 steps/s
[Step= 300] | Loss=6.65375 | acc=0.1274 | tpr=0.7622 | fpr=0.8842 | 8028.4 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.64070 | acc=0.1275 | tpr=0.7602 | fpr=0.8840 | 8495.9 samples/s | 33.2 steps/s
[Step= 400] | Loss=6.63176 | acc=0.1280 | tpr=0.7609 | fpr=0.8835 | 7756.9 samples/s | 30.3 steps/s
[Step= 450] | Loss=6.63065 | acc=0.1271 | tpr=0.7590 | fpr=0.8843 | 8464.7 samples/s | 33.1 steps/s
[Step= 500] | Loss=6.63341 | acc=0.1269 | tpr=0.7573 | fpr=0.8845 | 8288.4 samples/s | 32.4 steps/s
[Step= 550] | Loss=6.63046 | acc=0.1271 | tpr=0.7545 | fpr=0.8843 | 14099.2 samples/s | 55.1 steps/s
Avg test loss: 6.63202, Avg test acc: 0.12708, Avg tpr: 0.75436, Avg fpr: 0.88433, total FA: 122787

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12251 | acc=0.9795 | tpr=0.9469 | fpr=0.0200 | 5327.8 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.12896 | acc=0.9783 | tpr=0.9574 | fpr=0.0213 | 7253.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.13396 | acc=0.9771 | tpr=0.9568 | fpr=0.0225 | 7670.2 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13590 | acc=0.9773 | tpr=0.9585 | fpr=0.0224 | 8006.6 samples/s | 31.3 steps/s
[Step= 250] | Loss=0.13412 | acc=0.9776 | tpr=0.9581 | fpr=0.0221 | 8410.1 samples/s | 32.9 steps/s
[Step= 300] | Loss=0.13618 | acc=0.9771 | tpr=0.9556 | fpr=0.0225 | 7833.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.13681 | acc=0.9769 | tpr=0.9574 | fpr=0.0227 | 8378.1 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.13827 | acc=0.9767 | tpr=0.9546 | fpr=0.0229 | 7702.8 samples/s | 30.1 steps/s
[Step= 450] | Loss=0.14098 | acc=0.9764 | tpr=0.9547 | fpr=0.0233 | 8488.6 samples/s | 33.2 steps/s
[Step= 500] | Loss=0.14045 | acc=0.9764 | tpr=0.9551 | fpr=0.0232 | 8276.0 samples/s | 32.3 steps/s
[Step= 550] | Loss=0.13948 | acc=0.9765 | tpr=0.9546 | fpr=0.0231 | 13997.8 samples/s | 54.7 steps/s
Avg test loss: 0.13917, Avg test acc: 0.97648, Avg tpr: 0.95365, Avg fpr: 0.02310, total FA: 3208

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.13679 | acc=0.9778 | tpr=0.9513 | fpr=0.0217 | 5435.7 samples/s | 21.2 steps/s
[Step= 100] | Loss=0.14326 | acc=0.9770 | tpr=0.9616 | fpr=0.0227 | 7033.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.14844 | acc=0.9762 | tpr=0.9640 | fpr=0.0236 | 7687.8 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.15075 | acc=0.9760 | tpr=0.9661 | fpr=0.0238 | 8143.2 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.14812 | acc=0.9763 | tpr=0.9668 | fpr=0.0235 | 7996.7 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.15072 | acc=0.9760 | tpr=0.9651 | fpr=0.0238 | 8382.7 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.15176 | acc=0.9757 | tpr=0.9662 | fpr=0.0241 | 8032.1 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.15315 | acc=0.9756 | tpr=0.9639 | fpr=0.0242 | 7971.1 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.15613 | acc=0.9751 | tpr=0.9630 | fpr=0.0247 | 8026.2 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.15548 | acc=0.9751 | tpr=0.9630 | fpr=0.0247 | 8043.8 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.15428 | acc=0.9753 | tpr=0.9626 | fpr=0.0245 | 14956.9 samples/s | 58.4 steps/s
Avg test loss: 0.15389, Avg test acc: 0.97529, Avg tpr: 0.96157, Avg fpr: 0.02446, total FA: 3396

server round 36/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=140.4] | Loss=0.00619 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=11.748 | 6354.5 samples/s | 99.3 steps/s
[Step=72050 Epoch=140.5] | Loss=0.00575 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=11.751 | 4943.5 samples/s | 77.2 steps/s
[Step=72100 Epoch=140.6] | Loss=0.00499 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=11.756 | 5025.0 samples/s | 78.5 steps/s
[Step=72150 Epoch=140.7] | Loss=0.00512 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.158 | L2-Norm(final)=11.761 | 5246.4 samples/s | 82.0 steps/s
[Step=72200 Epoch=140.8] | Loss=0.00507 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=11.766 | 5094.9 samples/s | 79.6 steps/s
[Step=72250 Epoch=140.9] | Loss=0.00535 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=11.771 | 5198.4 samples/s | 81.2 steps/s
[Step=72300 Epoch=141.0] | Loss=0.00529 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.160 | L2-Norm(final)=11.776 | 5196.4 samples/s | 81.2 steps/s
[Step=72350 Epoch=141.1] | Loss=0.00546 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.161 | L2-Norm(final)=11.780 | 5284.8 samples/s | 82.6 steps/s
[Step=72400 Epoch=141.2] | Loss=0.00538 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=11.785 | 5280.7 samples/s | 82.5 steps/s
[Step=72450 Epoch=141.3] | Loss=0.00524 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=11.790 | 5130.7 samples/s | 80.2 steps/s
[Step=72500 Epoch=141.4] | Loss=0.00526 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.163 | L2-Norm(final)=11.794 | 6872.1 samples/s | 107.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=141.4] | Loss=0.00623 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=11.841 | 6686.6 samples/s | 104.5 steps/s
[Step=72550 Epoch=141.5] | Loss=0.00540 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.172 | L2-Norm(final)=11.846 | 4094.5 samples/s | 64.0 steps/s
[Step=72600 Epoch=141.6] | Loss=0.00531 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=11.850 | 4547.1 samples/s | 71.0 steps/s
[Step=72650 Epoch=141.7] | Loss=0.00612 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=11.854 | 4595.4 samples/s | 71.8 steps/s
[Step=72700 Epoch=141.8] | Loss=0.00578 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=11.858 | 4729.3 samples/s | 73.9 steps/s
[Step=72750 Epoch=141.9] | Loss=0.00580 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=11.861 | 4538.1 samples/s | 70.9 steps/s
[Step=72800 Epoch=142.0] | Loss=0.00604 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=11.865 | 4617.5 samples/s | 72.1 steps/s
[Step=72850 Epoch=142.1] | Loss=0.00619 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=11.869 | 4666.4 samples/s | 72.9 steps/s
[Step=72900 Epoch=142.2] | Loss=0.00636 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=11.873 | 4596.6 samples/s | 71.8 steps/s
[Step=72950 Epoch=142.3] | Loss=0.00629 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=11.877 | 4643.1 samples/s | 72.5 steps/s
[Step=73000 Epoch=142.4] | Loss=0.00642 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.188 | L2-Norm(final)=11.881 | 5969.9 samples/s | 93.3 steps/s
[Step=73050 Epoch=142.5] | Loss=0.00644 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.190 | L2-Norm(final)=11.884 | 2446.8 samples/s | 38.2 steps/s
[Step=73100 Epoch=142.6] | Loss=0.00626 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.191 | L2-Norm(final)=11.888 | 4616.5 samples/s | 72.1 steps/s
[Step=73150 Epoch=142.7] | Loss=0.00610 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=11.891 | 4648.6 samples/s | 72.6 steps/s
[Step=73200 Epoch=142.8] | Loss=0.00621 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.194 | L2-Norm(final)=11.895 | 4595.6 samples/s | 71.8 steps/s
[Step=73250 Epoch=142.9] | Loss=0.00611 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.194 | L2-Norm(final)=11.898 | 4643.8 samples/s | 72.6 steps/s
[Step=73300 Epoch=143.0] | Loss=0.00596 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=11.901 | 4613.5 samples/s | 72.1 steps/s
[Step=73350 Epoch=143.1] | Loss=0.00597 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=11.904 | 4602.4 samples/s | 71.9 steps/s
[Step=73400 Epoch=143.2] | Loss=0.00593 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=11.907 | 4673.5 samples/s | 73.0 steps/s
[Step=73450 Epoch=143.3] | Loss=0.00595 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.197 | L2-Norm(final)=11.910 | 4607.2 samples/s | 72.0 steps/s
[Step=73500 Epoch=143.4] | Loss=0.00597 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=11.913 | 4956.5 samples/s | 77.4 steps/s
[Step=73550 Epoch=143.5] | Loss=0.00594 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.198 | L2-Norm(final)=11.916 | 2662.2 samples/s | 41.6 steps/s
[Step=73600 Epoch=143.5] | Loss=0.00584 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=11.919 | 4745.1 samples/s | 74.1 steps/s
[Step=73650 Epoch=143.6] | Loss=0.00576 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.199 | L2-Norm(final)=11.922 | 4471.5 samples/s | 69.9 steps/s
[Step=73700 Epoch=143.7] | Loss=0.00575 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=11.925 | 4694.7 samples/s | 73.4 steps/s
[Step=73750 Epoch=143.8] | Loss=0.00571 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=11.928 | 4478.4 samples/s | 70.0 steps/s
[Step=73800 Epoch=143.9] | Loss=0.00570 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=11.931 | 4600.0 samples/s | 71.9 steps/s
[Step=73850 Epoch=144.0] | Loss=0.00568 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.200 | L2-Norm(final)=11.934 | 4687.2 samples/s | 73.2 steps/s
[Step=73900 Epoch=144.1] | Loss=0.00563 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=11.936 | 4704.2 samples/s | 73.5 steps/s
[Step=73950 Epoch=144.2] | Loss=0.00563 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.200 | L2-Norm(final)=11.939 | 4518.0 samples/s | 70.6 steps/s
[Step=74000 Epoch=144.3] | Loss=0.00562 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=11.942 | 4667.5 samples/s | 72.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step74000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=140.8] | Loss=0.00280 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.474 | L2-Norm(final)=12.259 | 6531.1 samples/s | 102.0 steps/s
[Step=72050 Epoch=140.9] | Loss=0.00572 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.475 | L2-Norm(final)=12.264 | 4673.6 samples/s | 73.0 steps/s
[Step=72100 Epoch=141.0] | Loss=0.00524 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=12.270 | 4990.5 samples/s | 78.0 steps/s
[Step=72150 Epoch=141.1] | Loss=0.00507 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.476 | L2-Norm(final)=12.275 | 5225.8 samples/s | 81.7 steps/s
[Step=72200 Epoch=141.1] | Loss=0.00486 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.477 | L2-Norm(final)=12.279 | 5232.1 samples/s | 81.8 steps/s
[Step=72250 Epoch=141.2] | Loss=0.00512 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.477 | L2-Norm(final)=12.284 | 5105.3 samples/s | 79.8 steps/s
[Step=72300 Epoch=141.3] | Loss=0.00510 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.478 | L2-Norm(final)=12.289 | 5207.8 samples/s | 81.4 steps/s
[Step=72350 Epoch=141.4] | Loss=0.00524 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.478 | L2-Norm(final)=12.293 | 5202.4 samples/s | 81.3 steps/s
[Step=72400 Epoch=141.5] | Loss=0.00515 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.479 | L2-Norm(final)=12.298 | 5210.8 samples/s | 81.4 steps/s
[Step=72450 Epoch=141.6] | Loss=0.00510 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=12.303 | 5289.2 samples/s | 82.6 steps/s
[Step=72500 Epoch=141.7] | Loss=0.00493 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.479 | L2-Norm(final)=12.308 | 6991.6 samples/s | 109.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=141.7] | Loss=0.00110 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.483 | L2-Norm(final)=12.355 | 6877.5 samples/s | 107.5 steps/s
[Step=72550 Epoch=141.8] | Loss=0.00481 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.486 | L2-Norm(final)=12.360 | 3959.4 samples/s | 61.9 steps/s
[Step=72600 Epoch=141.9] | Loss=0.00557 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.487 | L2-Norm(final)=12.365 | 4718.0 samples/s | 73.7 steps/s
[Step=72650 Epoch=142.0] | Loss=0.00591 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.489 | L2-Norm(final)=12.368 | 4541.5 samples/s | 71.0 steps/s
[Step=72700 Epoch=142.1] | Loss=0.00590 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.491 | L2-Norm(final)=12.372 | 4615.3 samples/s | 72.1 steps/s
[Step=72750 Epoch=142.2] | Loss=0.00615 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=12.376 | 4530.4 samples/s | 70.8 steps/s
[Step=72800 Epoch=142.3] | Loss=0.00663 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.494 | L2-Norm(final)=12.379 | 4618.3 samples/s | 72.2 steps/s
[Step=72850 Epoch=142.4] | Loss=0.00661 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.495 | L2-Norm(final)=12.383 | 4646.3 samples/s | 72.6 steps/s
[Step=72900 Epoch=142.5] | Loss=0.00658 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.497 | L2-Norm(final)=12.387 | 4630.7 samples/s | 72.4 steps/s
[Step=72950 Epoch=142.6] | Loss=0.00641 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.498 | L2-Norm(final)=12.390 | 4592.1 samples/s | 71.8 steps/s
[Step=73000 Epoch=142.7] | Loss=0.00630 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.499 | L2-Norm(final)=12.394 | 6051.8 samples/s | 94.6 steps/s
[Step=73050 Epoch=142.8] | Loss=0.00626 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.500 | L2-Norm(final)=12.397 | 2434.1 samples/s | 38.0 steps/s
[Step=73100 Epoch=142.9] | Loss=0.00621 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.501 | L2-Norm(final)=12.401 | 4621.9 samples/s | 72.2 steps/s
[Step=73150 Epoch=143.0] | Loss=0.00614 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.502 | L2-Norm(final)=12.404 | 4629.1 samples/s | 72.3 steps/s
[Step=73200 Epoch=143.1] | Loss=0.00603 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.503 | L2-Norm(final)=12.408 | 4587.1 samples/s | 71.7 steps/s
[Step=73250 Epoch=143.2] | Loss=0.00596 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.503 | L2-Norm(final)=12.411 | 4598.8 samples/s | 71.9 steps/s
[Step=73300 Epoch=143.3] | Loss=0.00587 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=12.414 | 4686.3 samples/s | 73.2 steps/s
[Step=73350 Epoch=143.4] | Loss=0.00586 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=12.417 | 4613.8 samples/s | 72.1 steps/s
[Step=73400 Epoch=143.5] | Loss=0.00572 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.504 | L2-Norm(final)=12.420 | 4614.6 samples/s | 72.1 steps/s
[Step=73450 Epoch=143.6] | Loss=0.00569 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.423 | 4721.1 samples/s | 73.8 steps/s
[Step=73500 Epoch=143.7] | Loss=0.00577 | Reg=0.00240 | acc=0.9844 | L2-Norm=15.505 | L2-Norm(final)=12.426 | 4999.5 samples/s | 78.1 steps/s
[Step=73550 Epoch=143.8] | Loss=0.00572 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.429 | 2632.8 samples/s | 41.1 steps/s
[Step=73600 Epoch=143.9] | Loss=0.00572 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.432 | 4586.7 samples/s | 71.7 steps/s
[Step=73650 Epoch=144.0] | Loss=0.00563 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.435 | 4623.1 samples/s | 72.2 steps/s
[Step=73700 Epoch=144.1] | Loss=0.00558 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=12.438 | 4699.5 samples/s | 73.4 steps/s
[Step=73750 Epoch=144.2] | Loss=0.00551 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=12.441 | 4533.7 samples/s | 70.8 steps/s
[Step=73800 Epoch=144.3] | Loss=0.00551 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=12.444 | 4675.1 samples/s | 73.0 steps/s
[Step=73850 Epoch=144.4] | Loss=0.00544 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.506 | L2-Norm(final)=12.446 | 4570.4 samples/s | 71.4 steps/s
[Step=73900 Epoch=144.5] | Loss=0.00544 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.449 | 4611.1 samples/s | 72.0 steps/s
[Step=73950 Epoch=144.6] | Loss=0.00539 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.452 | 4639.5 samples/s | 72.5 steps/s
[Step=74000 Epoch=144.7] | Loss=0.00543 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.505 | L2-Norm(final)=12.454 | 4722.1 samples/s | 73.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step74000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=275.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.982 | L2-Norm(final)=9.045 | 6720.2 samples/s | 105.0 steps/s
[Step=72050 Epoch=276.1] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.983 | L2-Norm(final)=9.048 | 4111.6 samples/s | 64.2 steps/s
[Step=72100 Epoch=276.3] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.985 | L2-Norm(final)=9.051 | 4943.8 samples/s | 77.2 steps/s
[Step=72150 Epoch=276.5] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.985 | L2-Norm(final)=9.054 | 4876.8 samples/s | 76.2 steps/s
[Step=72200 Epoch=276.6] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.057 | 4935.8 samples/s | 77.1 steps/s
[Step=72250 Epoch=276.8] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.060 | 6802.3 samples/s | 106.3 steps/s
[Step=72300 Epoch=277.0] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.063 | 2486.1 samples/s | 38.8 steps/s
[Step=72350 Epoch=277.2] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=9.067 | 4864.0 samples/s | 76.0 steps/s
[Step=72400 Epoch=277.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=9.070 | 4992.6 samples/s | 78.0 steps/s
[Step=72450 Epoch=277.6] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=9.073 | 4792.5 samples/s | 74.9 steps/s
[Step=72500 Epoch=277.8] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=9.076 | 5713.3 samples/s | 89.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=277.8] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=9.107 | 6264.0 samples/s | 97.9 steps/s
[Step=72550 Epoch=278.0] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.110 | 3901.8 samples/s | 61.0 steps/s
[Step=72600 Epoch=278.2] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.982 | L2-Norm(final)=9.113 | 4447.4 samples/s | 69.5 steps/s
[Step=72650 Epoch=278.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.978 | L2-Norm(final)=9.116 | 4358.5 samples/s | 68.1 steps/s
[Step=72700 Epoch=278.6] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=9.119 | 4332.8 samples/s | 67.7 steps/s
[Step=72750 Epoch=278.8] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.969 | L2-Norm(final)=9.122 | 5898.1 samples/s | 92.2 steps/s
[Step=72800 Epoch=278.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.965 | L2-Norm(final)=9.124 | 2322.0 samples/s | 36.3 steps/s
[Step=72850 Epoch=279.1] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.960 | L2-Norm(final)=9.126 | 4368.9 samples/s | 68.3 steps/s
[Step=72900 Epoch=279.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.955 | L2-Norm(final)=9.128 | 4385.6 samples/s | 68.5 steps/s
[Step=72950 Epoch=279.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.950 | L2-Norm(final)=9.130 | 4461.8 samples/s | 69.7 steps/s
[Step=73000 Epoch=279.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.945 | L2-Norm(final)=9.132 | 4881.2 samples/s | 76.3 steps/s
[Step=73050 Epoch=279.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.939 | L2-Norm(final)=9.134 | 2535.9 samples/s | 39.6 steps/s
[Step=73100 Epoch=280.1] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.934 | L2-Norm(final)=9.136 | 4275.0 samples/s | 66.8 steps/s
[Step=73150 Epoch=280.3] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.929 | L2-Norm(final)=9.138 | 4422.1 samples/s | 69.1 steps/s
[Step=73200 Epoch=280.5] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.923 | L2-Norm(final)=9.139 | 4347.9 samples/s | 67.9 steps/s
[Step=73250 Epoch=280.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.918 | L2-Norm(final)=9.141 | 4400.7 samples/s | 68.8 steps/s
[Step=73300 Epoch=280.9] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.912 | L2-Norm(final)=9.143 | 2711.8 samples/s | 42.4 steps/s
[Step=73350 Epoch=281.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.906 | L2-Norm(final)=9.144 | 4363.2 samples/s | 68.2 steps/s
[Step=73400 Epoch=281.2] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.900 | L2-Norm(final)=9.146 | 4361.7 samples/s | 68.2 steps/s
[Step=73450 Epoch=281.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.894 | L2-Norm(final)=9.148 | 4371.3 samples/s | 68.3 steps/s
[Step=73500 Epoch=281.6] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.888 | L2-Norm(final)=9.149 | 4361.5 samples/s | 68.1 steps/s
[Step=73550 Epoch=281.8] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.882 | L2-Norm(final)=9.151 | 2692.6 samples/s | 42.1 steps/s
[Step=73600 Epoch=282.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.876 | L2-Norm(final)=9.153 | 4332.4 samples/s | 67.7 steps/s
[Step=73650 Epoch=282.2] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.870 | L2-Norm(final)=9.154 | 4414.5 samples/s | 69.0 steps/s
[Step=73700 Epoch=282.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.864 | L2-Norm(final)=9.156 | 4361.6 samples/s | 68.2 steps/s
[Step=73750 Epoch=282.6] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.857 | L2-Norm(final)=9.158 | 4422.9 samples/s | 69.1 steps/s
[Step=73800 Epoch=282.8] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.851 | L2-Norm(final)=9.159 | 6472.9 samples/s | 101.1 steps/s
[Step=73850 Epoch=283.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.844 | L2-Norm(final)=9.161 | 2247.6 samples/s | 35.1 steps/s
[Step=73900 Epoch=283.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.838 | L2-Norm(final)=9.163 | 4376.1 samples/s | 68.4 steps/s
[Step=73950 Epoch=283.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.831 | L2-Norm(final)=9.165 | 4370.9 samples/s | 68.3 steps/s
[Step=74000 Epoch=283.5] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=9.167 | 4452.1 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step74000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=277.2] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.977 | L2-Norm(final)=8.799 | 5926.3 samples/s | 92.6 steps/s
[Step=72050 Epoch=277.3] | Loss=0.00003 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.977 | L2-Norm(final)=8.809 | 4669.9 samples/s | 73.0 steps/s
[Step=72100 Epoch=277.5] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.983 | L2-Norm(final)=8.820 | 4649.7 samples/s | 72.7 steps/s
[Step=72150 Epoch=277.7] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=8.832 | 4943.0 samples/s | 77.2 steps/s
[Step=72200 Epoch=277.9] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=8.842 | 4937.1 samples/s | 77.1 steps/s
[Step=72250 Epoch=278.1] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.991 | L2-Norm(final)=8.851 | 6838.4 samples/s | 106.9 steps/s
[Step=72300 Epoch=278.3] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.993 | L2-Norm(final)=8.861 | 2466.5 samples/s | 38.5 steps/s
[Step=72350 Epoch=278.5] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=8.869 | 4867.0 samples/s | 76.0 steps/s
[Step=72400 Epoch=278.7] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=8.878 | 4877.2 samples/s | 76.2 steps/s
[Step=72450 Epoch=278.9] | Loss=0.00002 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.995 | L2-Norm(final)=8.886 | 5156.8 samples/s | 80.6 steps/s
[Step=72500 Epoch=279.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.996 | L2-Norm(final)=8.894 | 5513.2 samples/s | 86.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=279.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.000 | L2-Norm(final)=8.974 | 6059.7 samples/s | 94.7 steps/s
[Step=72550 Epoch=279.3] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.990 | L2-Norm(final)=8.980 | 4018.6 samples/s | 62.8 steps/s
[Step=72600 Epoch=279.5] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.977 | L2-Norm(final)=8.986 | 4340.7 samples/s | 67.8 steps/s
[Step=72650 Epoch=279.7] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.963 | L2-Norm(final)=8.992 | 4429.7 samples/s | 69.2 steps/s
[Step=72700 Epoch=279.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.948 | L2-Norm(final)=8.996 | 4332.9 samples/s | 67.7 steps/s
[Step=72750 Epoch=280.0] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.933 | L2-Norm(final)=9.001 | 6004.1 samples/s | 93.8 steps/s
[Step=72800 Epoch=280.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.917 | L2-Norm(final)=9.005 | 2302.3 samples/s | 36.0 steps/s
[Step=72850 Epoch=280.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.901 | L2-Norm(final)=9.009 | 4447.9 samples/s | 69.5 steps/s
[Step=72900 Epoch=280.6] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.885 | L2-Norm(final)=9.012 | 4295.7 samples/s | 67.1 steps/s
[Step=72950 Epoch=280.8] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.869 | L2-Norm(final)=9.016 | 4392.1 samples/s | 68.6 steps/s
[Step=73000 Epoch=281.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.852 | L2-Norm(final)=9.019 | 5144.9 samples/s | 80.4 steps/s
[Step=73050 Epoch=281.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.835 | L2-Norm(final)=9.023 | 2456.8 samples/s | 38.4 steps/s
[Step=73100 Epoch=281.4] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.819 | L2-Norm(final)=9.026 | 4338.9 samples/s | 67.8 steps/s
[Step=73150 Epoch=281.6] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.802 | L2-Norm(final)=9.029 | 4398.9 samples/s | 68.7 steps/s
[Step=73200 Epoch=281.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.784 | L2-Norm(final)=9.033 | 4410.0 samples/s | 68.9 steps/s
[Step=73250 Epoch=282.0] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.767 | L2-Norm(final)=9.036 | 4464.7 samples/s | 69.8 steps/s
[Step=73300 Epoch=282.2] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.750 | L2-Norm(final)=9.040 | 2626.6 samples/s | 41.0 steps/s
[Step=73350 Epoch=282.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.732 | L2-Norm(final)=9.044 | 4416.7 samples/s | 69.0 steps/s
[Step=73400 Epoch=282.5] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.715 | L2-Norm(final)=9.048 | 4370.0 samples/s | 68.3 steps/s
[Step=73450 Epoch=282.7] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.697 | L2-Norm(final)=9.051 | 4433.7 samples/s | 69.3 steps/s
[Step=73500 Epoch=282.9] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.679 | L2-Norm(final)=9.055 | 4483.1 samples/s | 70.0 steps/s
[Step=73550 Epoch=283.1] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.661 | L2-Norm(final)=9.059 | 2631.5 samples/s | 41.1 steps/s
[Step=73600 Epoch=283.3] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.643 | L2-Norm(final)=9.064 | 4388.3 samples/s | 68.6 steps/s
[Step=73650 Epoch=283.5] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=9.068 | 4402.1 samples/s | 68.8 steps/s
[Step=73700 Epoch=283.7] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.607 | L2-Norm(final)=9.072 | 4361.5 samples/s | 68.1 steps/s
[Step=73750 Epoch=283.9] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.589 | L2-Norm(final)=9.077 | 4413.1 samples/s | 69.0 steps/s
[Step=73800 Epoch=284.1] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.571 | L2-Norm(final)=9.081 | 7078.8 samples/s | 110.6 steps/s
[Step=73850 Epoch=284.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.552 | L2-Norm(final)=9.086 | 2168.4 samples/s | 33.9 steps/s
[Step=73900 Epoch=284.5] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.534 | L2-Norm(final)=9.090 | 4443.4 samples/s | 69.4 steps/s
[Step=73950 Epoch=284.7] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.515 | L2-Norm(final)=9.095 | 4379.5 samples/s | 68.4 steps/s
[Step=74000 Epoch=284.9] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.497 | L2-Norm(final)=9.100 | 4373.3 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08237 | acc=0.9681 | tpr=0.9755 | fpr=0.0478 | 4940.4 samples/s | 19.3 steps/s
Avg test loss: 0.08373, Avg test acc: 0.96698, Avg tpr: 0.97488, Avg fpr: 0.05038, total FA: 393

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08229 | acc=0.9677 | tpr=0.9732 | fpr=0.0441 | 5394.7 samples/s | 21.1 steps/s
Avg test loss: 0.08376, Avg test acc: 0.96759, Avg tpr: 0.97284, Avg fpr: 0.04397, total FA: 343

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.59823 | acc=0.3105 | tpr=0.0046 | fpr=0.0253 | 5333.9 samples/s | 20.8 steps/s
Avg test loss: 5.60746, Avg test acc: 0.30876, Avg tpr: 0.00455, Avg fpr: 0.02218, total FA: 173

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.22409 | acc=0.3105 | tpr=0.0066 | fpr=0.0297 | 5415.1 samples/s | 21.2 steps/s
Avg test loss: 5.22902, Avg test acc: 0.30856, Avg tpr: 0.00670, Avg fpr: 0.02756, total FA: 215

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.35665 | acc=0.1254 | tpr=0.7389 | fpr=0.8856 | 4694.4 samples/s | 18.3 steps/s
[Step= 100] | Loss=6.33285 | acc=0.1241 | tpr=0.7271 | fpr=0.8871 | 6829.4 samples/s | 26.7 steps/s
[Step= 150] | Loss=6.32948 | acc=0.1255 | tpr=0.7450 | fpr=0.8859 | 7325.4 samples/s | 28.6 steps/s
[Step= 200] | Loss=6.34123 | acc=0.1243 | tpr=0.7344 | fpr=0.8868 | 7405.2 samples/s | 28.9 steps/s
[Step= 250] | Loss=6.34757 | acc=0.1246 | tpr=0.7275 | fpr=0.8864 | 8513.6 samples/s | 33.3 steps/s
[Step= 300] | Loss=6.34851 | acc=0.1243 | tpr=0.7302 | fpr=0.8867 | 8139.6 samples/s | 31.8 steps/s
[Step= 350] | Loss=6.33780 | acc=0.1247 | tpr=0.7295 | fpr=0.8863 | 7992.5 samples/s | 31.2 steps/s
[Step= 400] | Loss=6.32931 | acc=0.1252 | tpr=0.7352 | fpr=0.8859 | 7988.5 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.32988 | acc=0.1246 | tpr=0.7371 | fpr=0.8865 | 8128.9 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.32873 | acc=0.1245 | tpr=0.7370 | fpr=0.8866 | 8059.8 samples/s | 31.5 steps/s
[Step= 550] | Loss=6.32743 | acc=0.1247 | tpr=0.7338 | fpr=0.8864 | 14869.2 samples/s | 58.1 steps/s
Avg test loss: 6.32856, Avg test acc: 0.12466, Avg tpr: 0.73376, Avg fpr: 0.88642, total FA: 123077

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.10154 | acc=0.1485 | tpr=0.7124 | fpr=0.8616 | 4625.0 samples/s | 18.1 steps/s
[Step= 100] | Loss=6.08233 | acc=0.1489 | tpr=0.6887 | fpr=0.8611 | 7993.8 samples/s | 31.2 steps/s
[Step= 150] | Loss=6.07211 | acc=0.1497 | tpr=0.6888 | fpr=0.8603 | 7806.9 samples/s | 30.5 steps/s
[Step= 200] | Loss=6.08254 | acc=0.1496 | tpr=0.6951 | fpr=0.8604 | 7428.3 samples/s | 29.0 steps/s
[Step= 250] | Loss=6.08972 | acc=0.1503 | tpr=0.6900 | fpr=0.8596 | 6986.0 samples/s | 27.3 steps/s
[Step= 300] | Loss=6.09231 | acc=0.1502 | tpr=0.6902 | fpr=0.8597 | 8039.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.07795 | acc=0.1505 | tpr=0.6869 | fpr=0.8592 | 8050.4 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.06959 | acc=0.1508 | tpr=0.6882 | fpr=0.8589 | 7980.4 samples/s | 31.2 steps/s
[Step= 450] | Loss=6.06805 | acc=0.1503 | tpr=0.6884 | fpr=0.8595 | 8136.5 samples/s | 31.8 steps/s
[Step= 500] | Loss=6.07027 | acc=0.1499 | tpr=0.6863 | fpr=0.8598 | 8214.3 samples/s | 32.1 steps/s
[Step= 550] | Loss=6.06853 | acc=0.1500 | tpr=0.6828 | fpr=0.8596 | 14250.4 samples/s | 55.7 steps/s
Avg test loss: 6.07001, Avg test acc: 0.14999, Avg tpr: 0.68265, Avg fpr: 0.85970, total FA: 119367

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11550 | acc=0.9804 | tpr=0.9425 | fpr=0.0189 | 5466.1 samples/s | 21.4 steps/s
[Step= 100] | Loss=0.12110 | acc=0.9792 | tpr=0.9531 | fpr=0.0203 | 7267.4 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.12587 | acc=0.9781 | tpr=0.9510 | fpr=0.0214 | 7371.3 samples/s | 28.8 steps/s
[Step= 200] | Loss=0.12783 | acc=0.9781 | tpr=0.9530 | fpr=0.0214 | 6406.6 samples/s | 25.0 steps/s
[Step= 250] | Loss=0.12615 | acc=0.9784 | tpr=0.9528 | fpr=0.0212 | 7505.7 samples/s | 29.3 steps/s
[Step= 300] | Loss=0.12813 | acc=0.9779 | tpr=0.9505 | fpr=0.0216 | 7720.4 samples/s | 30.2 steps/s
[Step= 350] | Loss=0.12867 | acc=0.9777 | tpr=0.9530 | fpr=0.0219 | 7972.9 samples/s | 31.1 steps/s
[Step= 400] | Loss=0.13000 | acc=0.9776 | tpr=0.9497 | fpr=0.0219 | 8148.5 samples/s | 31.8 steps/s
[Step= 450] | Loss=0.13258 | acc=0.9773 | tpr=0.9499 | fpr=0.0222 | 8549.8 samples/s | 33.4 steps/s
[Step= 500] | Loss=0.13202 | acc=0.9773 | tpr=0.9493 | fpr=0.0222 | 7817.8 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.13114 | acc=0.9774 | tpr=0.9499 | fpr=0.0221 | 14600.6 samples/s | 57.0 steps/s
Avg test loss: 0.13082, Avg test acc: 0.97739, Avg tpr: 0.94889, Avg fpr: 0.02209, total FA: 3067

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12575 | acc=0.9798 | tpr=0.9558 | fpr=0.0197 | 5461.1 samples/s | 21.3 steps/s
[Step= 100] | Loss=0.13169 | acc=0.9786 | tpr=0.9659 | fpr=0.0211 | 7081.6 samples/s | 27.7 steps/s
[Step= 150] | Loss=0.13673 | acc=0.9778 | tpr=0.9654 | fpr=0.0220 | 7761.8 samples/s | 30.3 steps/s
[Step= 200] | Loss=0.13895 | acc=0.9777 | tpr=0.9661 | fpr=0.0221 | 6185.4 samples/s | 24.2 steps/s
[Step= 250] | Loss=0.13644 | acc=0.9780 | tpr=0.9677 | fpr=0.0218 | 7474.6 samples/s | 29.2 steps/s
[Step= 300] | Loss=0.13877 | acc=0.9776 | tpr=0.9665 | fpr=0.0222 | 7994.5 samples/s | 31.2 steps/s
[Step= 350] | Loss=0.13964 | acc=0.9773 | tpr=0.9668 | fpr=0.0225 | 8040.9 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.14092 | acc=0.9771 | tpr=0.9639 | fpr=0.0227 | 8304.6 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.14376 | acc=0.9766 | tpr=0.9630 | fpr=0.0232 | 8245.7 samples/s | 32.2 steps/s
[Step= 500] | Loss=0.14306 | acc=0.9766 | tpr=0.9639 | fpr=0.0231 | 7951.9 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.14188 | acc=0.9768 | tpr=0.9634 | fpr=0.0230 | 14581.6 samples/s | 57.0 steps/s
Avg test loss: 0.14153, Avg test acc: 0.97680, Avg tpr: 0.96276, Avg fpr: 0.02295, total FA: 3186

server round 37/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=144.3] | Loss=0.02205 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.992 | L2-Norm(final)=12.025 | 7110.5 samples/s | 111.1 steps/s
[Step=74050 Epoch=144.4] | Loss=0.00783 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=12.028 | 4335.4 samples/s | 67.7 steps/s
[Step=74100 Epoch=144.5] | Loss=0.00708 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.995 | L2-Norm(final)=12.035 | 5273.5 samples/s | 82.4 steps/s
[Step=74150 Epoch=144.6] | Loss=0.00702 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.997 | L2-Norm(final)=12.041 | 5102.6 samples/s | 79.7 steps/s
[Step=74200 Epoch=144.7] | Loss=0.00680 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.998 | L2-Norm(final)=12.046 | 5188.6 samples/s | 81.1 steps/s
[Step=74250 Epoch=144.8] | Loss=0.00691 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=12.052 | 5223.0 samples/s | 81.6 steps/s
[Step=74300 Epoch=144.9] | Loss=0.00700 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=12.058 | 5183.4 samples/s | 81.0 steps/s
[Step=74350 Epoch=145.0] | Loss=0.00678 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=12.063 | 5362.1 samples/s | 83.8 steps/s
[Step=74400 Epoch=145.1] | Loss=0.00679 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=12.069 | 5073.4 samples/s | 79.3 steps/s
[Step=74450 Epoch=145.2] | Loss=0.00667 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=12.075 | 5258.1 samples/s | 82.2 steps/s
[Step=74500 Epoch=145.3] | Loss=0.00666 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=12.080 | 6951.0 samples/s | 108.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=145.3] | Loss=0.00310 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=12.134 | 6436.3 samples/s | 100.6 steps/s
[Step=74550 Epoch=145.4] | Loss=0.00626 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=12.139 | 4111.4 samples/s | 64.2 steps/s
[Step=74600 Epoch=145.5] | Loss=0.00635 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.026 | L2-Norm(final)=12.143 | 4617.1 samples/s | 72.1 steps/s
[Step=74650 Epoch=145.6] | Loss=0.00682 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.030 | L2-Norm(final)=12.148 | 4643.6 samples/s | 72.6 steps/s
[Step=74700 Epoch=145.7] | Loss=0.00738 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=12.152 | 4558.6 samples/s | 71.2 steps/s
[Step=74750 Epoch=145.8] | Loss=0.00763 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=12.155 | 4687.5 samples/s | 73.2 steps/s
[Step=74800 Epoch=145.9] | Loss=0.00768 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=12.159 | 4576.8 samples/s | 71.5 steps/s
[Step=74850 Epoch=146.0] | Loss=0.00765 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=12.163 | 4606.0 samples/s | 72.0 steps/s
[Step=74900 Epoch=146.1] | Loss=0.00769 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.045 | L2-Norm(final)=12.167 | 4608.5 samples/s | 72.0 steps/s
[Step=74950 Epoch=146.2] | Loss=0.00768 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=12.171 | 4699.3 samples/s | 73.4 steps/s
[Step=75000 Epoch=146.3] | Loss=0.00762 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.049 | L2-Norm(final)=12.175 | 5863.7 samples/s | 91.6 steps/s
[Step=75050 Epoch=146.4] | Loss=0.00751 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.051 | L2-Norm(final)=12.179 | 2446.9 samples/s | 38.2 steps/s
[Step=75100 Epoch=146.5] | Loss=0.00738 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.053 | L2-Norm(final)=12.182 | 4625.2 samples/s | 72.3 steps/s
[Step=75150 Epoch=146.6] | Loss=0.00715 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=12.186 | 4644.3 samples/s | 72.6 steps/s
[Step=75200 Epoch=146.7] | Loss=0.00710 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=12.189 | 4600.7 samples/s | 71.9 steps/s
[Step=75250 Epoch=146.8] | Loss=0.00708 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.057 | L2-Norm(final)=12.193 | 4602.2 samples/s | 71.9 steps/s
[Step=75300 Epoch=146.9] | Loss=0.00700 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.058 | L2-Norm(final)=12.196 | 4636.5 samples/s | 72.4 steps/s
[Step=75350 Epoch=147.0] | Loss=0.00691 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.059 | L2-Norm(final)=12.199 | 4649.6 samples/s | 72.6 steps/s
[Step=75400 Epoch=147.1] | Loss=0.00681 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=12.203 | 4596.0 samples/s | 71.8 steps/s
[Step=75450 Epoch=147.2] | Loss=0.00680 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.061 | L2-Norm(final)=12.206 | 4622.5 samples/s | 72.2 steps/s
[Step=75500 Epoch=147.3] | Loss=0.00671 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.062 | L2-Norm(final)=12.209 | 4968.7 samples/s | 77.6 steps/s
[Step=75550 Epoch=147.4] | Loss=0.00665 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=12.212 | 2655.4 samples/s | 41.5 steps/s
[Step=75600 Epoch=147.4] | Loss=0.00656 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=12.215 | 4637.2 samples/s | 72.5 steps/s
[Step=75650 Epoch=147.5] | Loss=0.00647 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=12.219 | 4593.4 samples/s | 71.8 steps/s
[Step=75700 Epoch=147.6] | Loss=0.00640 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=12.222 | 4708.4 samples/s | 73.6 steps/s
[Step=75750 Epoch=147.7] | Loss=0.00631 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=12.225 | 4566.2 samples/s | 71.3 steps/s
[Step=75800 Epoch=147.8] | Loss=0.00627 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=12.228 | 4590.1 samples/s | 71.7 steps/s
[Step=75850 Epoch=147.9] | Loss=0.00623 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=12.231 | 4654.8 samples/s | 72.7 steps/s
[Step=75900 Epoch=148.0] | Loss=0.00620 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=12.233 | 4669.7 samples/s | 73.0 steps/s
[Step=75950 Epoch=148.1] | Loss=0.00617 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.067 | L2-Norm(final)=12.236 | 4612.4 samples/s | 72.1 steps/s
[Step=76000 Epoch=148.2] | Loss=0.00615 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.068 | L2-Norm(final)=12.239 | 4560.6 samples/s | 71.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step76000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=144.7] | Loss=0.01190 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.294 | L2-Norm(final)=12.532 | 6913.9 samples/s | 108.0 steps/s
[Step=74050 Epoch=144.8] | Loss=0.00588 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.296 | L2-Norm(final)=12.538 | 4349.3 samples/s | 68.0 steps/s
[Step=74100 Epoch=144.9] | Loss=0.00625 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.298 | L2-Norm(final)=12.545 | 5236.0 samples/s | 81.8 steps/s
[Step=74150 Epoch=145.0] | Loss=0.00660 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.300 | L2-Norm(final)=12.551 | 5161.8 samples/s | 80.7 steps/s
[Step=74200 Epoch=145.1] | Loss=0.00608 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.301 | L2-Norm(final)=12.557 | 5295.8 samples/s | 82.7 steps/s
[Step=74250 Epoch=145.2] | Loss=0.00603 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.303 | L2-Norm(final)=12.562 | 5149.4 samples/s | 80.5 steps/s
[Step=74300 Epoch=145.3] | Loss=0.00605 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.304 | L2-Norm(final)=12.568 | 5174.8 samples/s | 80.9 steps/s
[Step=74350 Epoch=145.4] | Loss=0.00604 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.306 | L2-Norm(final)=12.574 | 5434.6 samples/s | 84.9 steps/s
[Step=74400 Epoch=145.5] | Loss=0.00597 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=12.580 | 5032.4 samples/s | 78.6 steps/s
[Step=74450 Epoch=145.5] | Loss=0.00603 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=12.586 | 5252.3 samples/s | 82.1 steps/s
[Step=74500 Epoch=145.6] | Loss=0.00599 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=12.591 | 7097.3 samples/s | 110.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=145.6] | Loss=0.00254 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.328 | L2-Norm(final)=12.648 | 6454.6 samples/s | 100.9 steps/s
[Step=74550 Epoch=145.7] | Loss=0.00658 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=12.653 | 4132.8 samples/s | 64.6 steps/s
[Step=74600 Epoch=145.8] | Loss=0.00632 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.334 | L2-Norm(final)=12.659 | 4694.1 samples/s | 73.3 steps/s
[Step=74650 Epoch=145.9] | Loss=0.00637 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.337 | L2-Norm(final)=12.663 | 4535.4 samples/s | 70.9 steps/s
[Step=74700 Epoch=146.0] | Loss=0.00643 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.340 | L2-Norm(final)=12.668 | 4625.2 samples/s | 72.3 steps/s
[Step=74750 Epoch=146.1] | Loss=0.00718 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=12.672 | 4602.4 samples/s | 71.9 steps/s
[Step=74800 Epoch=146.2] | Loss=0.00749 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.346 | L2-Norm(final)=12.675 | 4623.0 samples/s | 72.2 steps/s
[Step=74850 Epoch=146.3] | Loss=0.00746 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=12.679 | 4631.7 samples/s | 72.4 steps/s
[Step=74900 Epoch=146.4] | Loss=0.00760 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=12.682 | 4665.8 samples/s | 72.9 steps/s
[Step=74950 Epoch=146.5] | Loss=0.00752 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.353 | L2-Norm(final)=12.686 | 4689.3 samples/s | 73.3 steps/s
[Step=75000 Epoch=146.6] | Loss=0.00749 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.355 | L2-Norm(final)=12.690 | 5941.0 samples/s | 92.8 steps/s
[Step=75050 Epoch=146.7] | Loss=0.00750 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=12.693 | 2417.7 samples/s | 37.8 steps/s
[Step=75100 Epoch=146.8] | Loss=0.00726 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=12.697 | 4653.1 samples/s | 72.7 steps/s
[Step=75150 Epoch=146.9] | Loss=0.00739 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.360 | L2-Norm(final)=12.700 | 4610.7 samples/s | 72.0 steps/s
[Step=75200 Epoch=147.0] | Loss=0.00741 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.362 | L2-Norm(final)=12.703 | 4626.1 samples/s | 72.3 steps/s
[Step=75250 Epoch=147.1] | Loss=0.00730 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.363 | L2-Norm(final)=12.706 | 4630.8 samples/s | 72.4 steps/s
[Step=75300 Epoch=147.2] | Loss=0.00719 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.364 | L2-Norm(final)=12.709 | 4625.3 samples/s | 72.3 steps/s
[Step=75350 Epoch=147.3] | Loss=0.00709 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.365 | L2-Norm(final)=12.712 | 4593.7 samples/s | 71.8 steps/s
[Step=75400 Epoch=147.4] | Loss=0.00700 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.366 | L2-Norm(final)=12.715 | 4632.9 samples/s | 72.4 steps/s
[Step=75450 Epoch=147.5] | Loss=0.00689 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.367 | L2-Norm(final)=12.718 | 4722.9 samples/s | 73.8 steps/s
[Step=75500 Epoch=147.6] | Loss=0.00678 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.368 | L2-Norm(final)=12.721 | 5052.2 samples/s | 78.9 steps/s
[Step=75550 Epoch=147.7] | Loss=0.00663 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.369 | L2-Norm(final)=12.724 | 2628.6 samples/s | 41.1 steps/s
[Step=75600 Epoch=147.8] | Loss=0.00652 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.369 | L2-Norm(final)=12.726 | 4619.1 samples/s | 72.2 steps/s
[Step=75650 Epoch=147.9] | Loss=0.00640 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=12.729 | 4712.7 samples/s | 73.6 steps/s
[Step=75700 Epoch=148.0] | Loss=0.00629 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.370 | L2-Norm(final)=12.732 | 4520.7 samples/s | 70.6 steps/s
[Step=75750 Epoch=148.1] | Loss=0.00621 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=12.735 | 4641.5 samples/s | 72.5 steps/s
[Step=75800 Epoch=148.2] | Loss=0.00614 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=12.737 | 4646.3 samples/s | 72.6 steps/s
[Step=75850 Epoch=148.3] | Loss=0.00610 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=12.740 | 4597.5 samples/s | 71.8 steps/s
[Step=75900 Epoch=148.4] | Loss=0.00614 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=12.742 | 4631.1 samples/s | 72.4 steps/s
[Step=75950 Epoch=148.5] | Loss=0.00611 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=12.745 | 4602.7 samples/s | 71.9 steps/s
[Step=76000 Epoch=148.6] | Loss=0.00609 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=12.747 | 4672.9 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step76000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=283.5] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.661 | L2-Norm(final)=9.223 | 6027.2 samples/s | 94.2 steps/s
[Step=74050 Epoch=283.7] | Loss=0.00005 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.666 | L2-Norm(final)=9.235 | 4509.5 samples/s | 70.5 steps/s
[Step=74100 Epoch=283.9] | Loss=0.00004 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.674 | L2-Norm(final)=9.249 | 4838.9 samples/s | 75.6 steps/s
[Step=74150 Epoch=284.1] | Loss=0.00003 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.678 | L2-Norm(final)=9.260 | 4953.1 samples/s | 77.4 steps/s
[Step=74200 Epoch=284.3] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.680 | L2-Norm(final)=9.269 | 4855.7 samples/s | 75.9 steps/s
[Step=74250 Epoch=284.5] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.681 | L2-Norm(final)=9.277 | 6869.7 samples/s | 107.3 steps/s
[Step=74300 Epoch=284.7] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.682 | L2-Norm(final)=9.285 | 2453.6 samples/s | 38.3 steps/s
[Step=74350 Epoch=284.9] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.683 | L2-Norm(final)=9.292 | 4976.8 samples/s | 77.8 steps/s
[Step=74400 Epoch=285.1] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.684 | L2-Norm(final)=9.300 | 4846.8 samples/s | 75.7 steps/s
[Step=74450 Epoch=285.3] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.685 | L2-Norm(final)=9.307 | 4973.9 samples/s | 77.7 steps/s
[Step=74500 Epoch=285.5] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.685 | L2-Norm(final)=9.314 | 5592.3 samples/s | 87.4 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=285.5] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.691 | L2-Norm(final)=9.385 | 5819.3 samples/s | 90.9 steps/s
[Step=74550 Epoch=285.6] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.685 | L2-Norm(final)=9.391 | 4114.4 samples/s | 64.3 steps/s
[Step=74600 Epoch=285.8] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.676 | L2-Norm(final)=9.396 | 4401.6 samples/s | 68.8 steps/s
[Step=74650 Epoch=286.0] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.665 | L2-Norm(final)=9.400 | 4466.1 samples/s | 69.8 steps/s
[Step=74700 Epoch=286.2] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.655 | L2-Norm(final)=9.404 | 4335.0 samples/s | 67.7 steps/s
[Step=74750 Epoch=286.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.644 | L2-Norm(final)=9.408 | 5835.3 samples/s | 91.2 steps/s
[Step=74800 Epoch=286.6] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.634 | L2-Norm(final)=9.413 | 1757.9 samples/s | 27.5 steps/s
[Step=74850 Epoch=286.8] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.623 | L2-Norm(final)=9.417 | 4352.4 samples/s | 68.0 steps/s
[Step=74900 Epoch=287.0] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.612 | L2-Norm(final)=9.421 | 4241.6 samples/s | 66.3 steps/s
[Step=74950 Epoch=287.2] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.600 | L2-Norm(final)=9.424 | 4383.8 samples/s | 68.5 steps/s
[Step=75000 Epoch=287.4] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.588 | L2-Norm(final)=9.427 | 4909.0 samples/s | 76.7 steps/s
[Step=75050 Epoch=287.6] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.577 | L2-Norm(final)=9.431 | 2468.6 samples/s | 38.6 steps/s
[Step=75100 Epoch=287.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.565 | L2-Norm(final)=9.434 | 4354.0 samples/s | 68.0 steps/s
[Step=75150 Epoch=287.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.553 | L2-Norm(final)=9.437 | 4432.3 samples/s | 69.3 steps/s
[Step=75200 Epoch=288.1] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.541 | L2-Norm(final)=9.440 | 4386.0 samples/s | 68.5 steps/s
[Step=75250 Epoch=288.3] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.529 | L2-Norm(final)=9.443 | 4369.2 samples/s | 68.3 steps/s
[Step=75300 Epoch=288.5] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.516 | L2-Norm(final)=9.446 | 2684.4 samples/s | 41.9 steps/s
[Step=75350 Epoch=288.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.504 | L2-Norm(final)=9.450 | 4342.6 samples/s | 67.9 steps/s
[Step=75400 Epoch=288.9] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.492 | L2-Norm(final)=9.453 | 4381.4 samples/s | 68.5 steps/s
[Step=75450 Epoch=289.1] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.479 | L2-Norm(final)=9.456 | 4447.3 samples/s | 69.5 steps/s
[Step=75500 Epoch=289.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.466 | L2-Norm(final)=9.459 | 4390.1 samples/s | 68.6 steps/s
[Step=75550 Epoch=289.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.453 | L2-Norm(final)=9.462 | 2673.7 samples/s | 41.8 steps/s
[Step=75600 Epoch=289.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.440 | L2-Norm(final)=9.466 | 4403.4 samples/s | 68.8 steps/s
[Step=75650 Epoch=289.9] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.427 | L2-Norm(final)=9.469 | 4368.1 samples/s | 68.3 steps/s
[Step=75700 Epoch=290.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.414 | L2-Norm(final)=9.473 | 4376.2 samples/s | 68.4 steps/s
[Step=75750 Epoch=290.2] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.401 | L2-Norm(final)=9.476 | 4406.3 samples/s | 68.8 steps/s
[Step=75800 Epoch=290.4] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.388 | L2-Norm(final)=9.480 | 6457.9 samples/s | 100.9 steps/s
[Step=75850 Epoch=290.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.374 | L2-Norm(final)=9.483 | 2265.2 samples/s | 35.4 steps/s
[Step=75900 Epoch=290.8] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.361 | L2-Norm(final)=9.487 | 4302.0 samples/s | 67.2 steps/s
[Step=75950 Epoch=291.0] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.347 | L2-Norm(final)=9.491 | 4425.3 samples/s | 69.1 steps/s
[Step=76000 Epoch=291.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.333 | L2-Norm(final)=9.494 | 4358.4 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step76000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=284.9] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.632 | L2-Norm(final)=9.247 | 6500.4 samples/s | 101.6 steps/s
[Step=74050 Epoch=285.0] | Loss=0.00002 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.633 | L2-Norm(final)=9.268 | 4191.7 samples/s | 65.5 steps/s
[Step=74100 Epoch=285.2] | Loss=0.00002 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.641 | L2-Norm(final)=9.292 | 4902.6 samples/s | 76.6 steps/s
[Step=74150 Epoch=285.4] | Loss=0.00002 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.647 | L2-Norm(final)=9.315 | 4961.1 samples/s | 77.5 steps/s
[Step=74200 Epoch=285.6] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.652 | L2-Norm(final)=9.334 | 4909.5 samples/s | 76.7 steps/s
[Step=74250 Epoch=285.8] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.655 | L2-Norm(final)=9.351 | 6981.1 samples/s | 109.1 steps/s
[Step=74300 Epoch=286.0] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.658 | L2-Norm(final)=9.366 | 2473.7 samples/s | 38.7 steps/s
[Step=74350 Epoch=286.2] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.659 | L2-Norm(final)=9.380 | 4901.6 samples/s | 76.6 steps/s
[Step=74400 Epoch=286.4] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.660 | L2-Norm(final)=9.392 | 4852.1 samples/s | 75.8 steps/s
[Step=74450 Epoch=286.6] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.660 | L2-Norm(final)=9.404 | 4865.3 samples/s | 76.0 steps/s
[Step=74500 Epoch=286.8] | Loss=0.00001 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.661 | L2-Norm(final)=9.415 | 5837.8 samples/s | 91.2 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=286.8] | Loss=0.00002 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.661 | L2-Norm(final)=9.529 | 6453.0 samples/s | 100.8 steps/s
[Step=74550 Epoch=287.0] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.640 | L2-Norm(final)=9.539 | 3842.9 samples/s | 60.0 steps/s
[Step=74600 Epoch=287.2] | Loss=0.00001 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.609 | L2-Norm(final)=9.547 | 4447.3 samples/s | 69.5 steps/s
[Step=74650 Epoch=287.4] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.577 | L2-Norm(final)=9.553 | 4391.2 samples/s | 68.6 steps/s
[Step=74700 Epoch=287.5] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.545 | L2-Norm(final)=9.560 | 4391.1 samples/s | 68.6 steps/s
[Step=74750 Epoch=287.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=9.565 | 5959.8 samples/s | 93.1 steps/s
[Step=74800 Epoch=287.9] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.480 | L2-Norm(final)=9.571 | 2312.4 samples/s | 36.1 steps/s
[Step=74850 Epoch=288.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.447 | L2-Norm(final)=9.576 | 4402.0 samples/s | 68.8 steps/s
[Step=74900 Epoch=288.3] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.415 | L2-Norm(final)=9.581 | 4499.4 samples/s | 70.3 steps/s
[Step=74950 Epoch=288.5] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.382 | L2-Norm(final)=9.587 | 4256.7 samples/s | 66.5 steps/s
[Step=75000 Epoch=288.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=9.592 | 5126.4 samples/s | 80.1 steps/s
[Step=75050 Epoch=288.9] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.319 | L2-Norm(final)=9.599 | 2468.8 samples/s | 38.6 steps/s
[Step=75100 Epoch=289.1] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.288 | L2-Norm(final)=9.605 | 4388.2 samples/s | 68.6 steps/s
[Step=75150 Epoch=289.3] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.258 | L2-Norm(final)=9.612 | 4349.0 samples/s | 68.0 steps/s
[Step=75200 Epoch=289.5] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.228 | L2-Norm(final)=9.619 | 4402.6 samples/s | 68.8 steps/s
[Step=75250 Epoch=289.7] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.198 | L2-Norm(final)=9.625 | 4467.6 samples/s | 69.8 steps/s
[Step=75300 Epoch=289.9] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.170 | L2-Norm(final)=9.632 | 2687.6 samples/s | 42.0 steps/s
[Step=75350 Epoch=290.1] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.148 | L2-Norm(final)=9.641 | 4268.3 samples/s | 66.7 steps/s
[Step=75400 Epoch=290.2] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.130 | L2-Norm(final)=9.649 | 4502.1 samples/s | 70.3 steps/s
[Step=75450 Epoch=290.4] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.114 | L2-Norm(final)=9.657 | 4175.7 samples/s | 65.2 steps/s
[Step=75500 Epoch=290.6] | Loss=0.00016 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=9.664 | 4290.4 samples/s | 67.0 steps/s
[Step=75550 Epoch=290.8] | Loss=0.00015 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.089 | L2-Norm(final)=9.670 | 2694.1 samples/s | 42.1 steps/s
[Step=75600 Epoch=291.0] | Loss=0.00015 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.079 | L2-Norm(final)=9.675 | 4346.0 samples/s | 67.9 steps/s
[Step=75650 Epoch=291.2] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=9.680 | 4471.3 samples/s | 69.9 steps/s
[Step=75700 Epoch=291.4] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.061 | L2-Norm(final)=9.684 | 4298.0 samples/s | 67.2 steps/s
[Step=75750 Epoch=291.6] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.053 | L2-Norm(final)=9.688 | 4433.2 samples/s | 69.3 steps/s
[Step=75800 Epoch=291.8] | Loss=0.00013 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=9.692 | 7060.4 samples/s | 110.3 steps/s
[Step=75850 Epoch=292.0] | Loss=0.00012 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=9.696 | 2176.2 samples/s | 34.0 steps/s
[Step=75900 Epoch=292.2] | Loss=0.00012 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.032 | L2-Norm(final)=9.700 | 4317.9 samples/s | 67.5 steps/s
[Step=75950 Epoch=292.4] | Loss=0.00012 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=9.703 | 4446.0 samples/s | 69.5 steps/s
[Step=76000 Epoch=292.6] | Loss=0.00011 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.020 | L2-Norm(final)=9.706 | 4315.6 samples/s | 67.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.08253 | acc=0.9680 | tpr=0.9758 | fpr=0.0491 | 5233.2 samples/s | 20.4 steps/s
Avg test loss: 0.08458, Avg test acc: 0.96610, Avg tpr: 0.97459, Avg fpr: 0.05256, total FA: 410

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.08255 | acc=0.9667 | tpr=0.9759 | fpr=0.0533 | 5431.7 samples/s | 21.2 steps/s
Avg test loss: 0.08450, Avg test acc: 0.96694, Avg tpr: 0.97587, Avg fpr: 0.05269, total FA: 411

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.37402 | acc=0.3110 | tpr=0.0055 | fpr=0.0255 | 5377.5 samples/s | 21.0 steps/s
Avg test loss: 5.38368, Avg test acc: 0.30876, Avg tpr: 0.00519, Avg fpr: 0.02359, total FA: 184

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.01502 | acc=0.3077 | tpr=0.0052 | fpr=0.0354 | 5264.2 samples/s | 20.6 steps/s
Avg test loss: 5.02127, Avg test acc: 0.30635, Avg tpr: 0.00571, Avg fpr: 0.03243, total FA: 253

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.21411 | acc=0.1276 | tpr=0.7566 | fpr=0.8837 | 5184.4 samples/s | 20.3 steps/s
[Step= 100] | Loss=6.19309 | acc=0.1272 | tpr=0.7505 | fpr=0.8844 | 7500.1 samples/s | 29.3 steps/s
[Step= 150] | Loss=6.18928 | acc=0.1284 | tpr=0.7622 | fpr=0.8832 | 7504.2 samples/s | 29.3 steps/s
[Step= 200] | Loss=6.20315 | acc=0.1272 | tpr=0.7508 | fpr=0.8842 | 8255.8 samples/s | 32.2 steps/s
[Step= 250] | Loss=6.21076 | acc=0.1278 | tpr=0.7424 | fpr=0.8834 | 8132.0 samples/s | 31.8 steps/s
[Step= 300] | Loss=6.21216 | acc=0.1274 | tpr=0.7447 | fpr=0.8838 | 8218.6 samples/s | 32.1 steps/s
[Step= 350] | Loss=6.20202 | acc=0.1276 | tpr=0.7445 | fpr=0.8836 | 7757.8 samples/s | 30.3 steps/s
[Step= 400] | Loss=6.19331 | acc=0.1281 | tpr=0.7495 | fpr=0.8832 | 7939.6 samples/s | 31.0 steps/s
[Step= 450] | Loss=6.19490 | acc=0.1276 | tpr=0.7507 | fpr=0.8837 | 8034.1 samples/s | 31.4 steps/s
[Step= 500] | Loss=6.19450 | acc=0.1273 | tpr=0.7493 | fpr=0.8840 | 7613.1 samples/s | 29.7 steps/s
[Step= 550] | Loss=6.19307 | acc=0.1273 | tpr=0.7465 | fpr=0.8839 | 15481.3 samples/s | 60.5 steps/s
Avg test loss: 6.19440, Avg test acc: 0.12727, Avg tpr: 0.74683, Avg fpr: 0.88400, total FA: 122741

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.33310 | acc=0.1327 | tpr=0.7301 | fpr=0.8780 | 5223.4 samples/s | 20.4 steps/s
[Step= 100] | Loss=6.31683 | acc=0.1325 | tpr=0.7228 | fpr=0.8786 | 7617.6 samples/s | 29.8 steps/s
[Step= 150] | Loss=6.30747 | acc=0.1329 | tpr=0.7305 | fpr=0.8781 | 7401.8 samples/s | 28.9 steps/s
[Step= 200] | Loss=6.32087 | acc=0.1320 | tpr=0.7301 | fpr=0.8789 | 8167.1 samples/s | 31.9 steps/s
[Step= 250] | Loss=6.32752 | acc=0.1325 | tpr=0.7240 | fpr=0.8782 | 8173.8 samples/s | 31.9 steps/s
[Step= 300] | Loss=6.33133 | acc=0.1322 | tpr=0.7229 | fpr=0.8786 | 8249.6 samples/s | 32.2 steps/s
[Step= 350] | Loss=6.31714 | acc=0.1324 | tpr=0.7239 | fpr=0.8783 | 7861.3 samples/s | 30.7 steps/s
[Step= 400] | Loss=6.30812 | acc=0.1330 | tpr=0.7259 | fpr=0.8778 | 8020.5 samples/s | 31.3 steps/s
[Step= 450] | Loss=6.30799 | acc=0.1323 | tpr=0.7244 | fpr=0.8785 | 8155.7 samples/s | 31.9 steps/s
[Step= 500] | Loss=6.31064 | acc=0.1321 | tpr=0.7225 | fpr=0.8785 | 8025.3 samples/s | 31.3 steps/s
[Step= 550] | Loss=6.30909 | acc=0.1322 | tpr=0.7179 | fpr=0.8784 | 15169.4 samples/s | 59.3 steps/s
Avg test loss: 6.31071, Avg test acc: 0.13218, Avg tpr: 0.71791, Avg fpr: 0.87847, total FA: 121974

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11647 | acc=0.9789 | tpr=0.9513 | fpr=0.0206 | 5259.6 samples/s | 20.5 steps/s
[Step= 100] | Loss=0.12192 | acc=0.9779 | tpr=0.9595 | fpr=0.0217 | 7279.1 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.12747 | acc=0.9766 | tpr=0.9582 | fpr=0.0231 | 8048.6 samples/s | 31.4 steps/s
[Step= 200] | Loss=0.12932 | acc=0.9766 | tpr=0.9607 | fpr=0.0231 | 7862.7 samples/s | 30.7 steps/s
[Step= 250] | Loss=0.12745 | acc=0.9770 | tpr=0.9616 | fpr=0.0228 | 7985.9 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.12958 | acc=0.9765 | tpr=0.9585 | fpr=0.0231 | 8100.5 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.13021 | acc=0.9763 | tpr=0.9599 | fpr=0.0234 | 8074.0 samples/s | 31.5 steps/s
[Step= 400] | Loss=0.13139 | acc=0.9762 | tpr=0.9573 | fpr=0.0235 | 8262.4 samples/s | 32.3 steps/s
[Step= 450] | Loss=0.13396 | acc=0.9759 | tpr=0.9572 | fpr=0.0238 | 7765.6 samples/s | 30.3 steps/s
[Step= 500] | Loss=0.13338 | acc=0.9759 | tpr=0.9559 | fpr=0.0238 | 8342.5 samples/s | 32.6 steps/s
[Step= 550] | Loss=0.13246 | acc=0.9760 | tpr=0.9558 | fpr=0.0236 | 15024.8 samples/s | 58.7 steps/s
Avg test loss: 0.13210, Avg test acc: 0.97605, Avg tpr: 0.95523, Avg fpr: 0.02357, total FA: 3273

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.10495 | acc=0.9802 | tpr=0.9646 | fpr=0.0195 | 5402.6 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.11068 | acc=0.9789 | tpr=0.9638 | fpr=0.0208 | 7131.1 samples/s | 27.9 steps/s
[Step= 150] | Loss=0.11564 | acc=0.9779 | tpr=0.9654 | fpr=0.0218 | 7645.3 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.11807 | acc=0.9778 | tpr=0.9672 | fpr=0.0220 | 8346.9 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.11556 | acc=0.9785 | tpr=0.9694 | fpr=0.0214 | 8159.8 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.11748 | acc=0.9782 | tpr=0.9673 | fpr=0.0217 | 7882.3 samples/s | 30.8 steps/s
[Step= 350] | Loss=0.11796 | acc=0.9780 | tpr=0.9674 | fpr=0.0218 | 8010.1 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.11932 | acc=0.9778 | tpr=0.9644 | fpr=0.0220 | 8124.1 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.12193 | acc=0.9773 | tpr=0.9625 | fpr=0.0224 | 8052.7 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.12123 | acc=0.9774 | tpr=0.9630 | fpr=0.0223 | 8077.9 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.12005 | acc=0.9776 | tpr=0.9630 | fpr=0.0221 | 14678.4 samples/s | 57.3 steps/s
Avg test loss: 0.11976, Avg test acc: 0.97764, Avg tpr: 0.96276, Avg fpr: 0.02209, total FA: 3067

server round 38/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=148.2] | Loss=0.01102 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.833 | L2-Norm(final)=12.324 | 6413.7 samples/s | 100.2 steps/s
[Step=76050 Epoch=148.3] | Loss=0.00980 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.836 | L2-Norm(final)=12.331 | 4612.3 samples/s | 72.1 steps/s
[Step=76100 Epoch=148.4] | Loss=0.00923 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.841 | L2-Norm(final)=12.340 | 5347.2 samples/s | 83.6 steps/s
[Step=76150 Epoch=148.5] | Loss=0.00909 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=12.348 | 5086.1 samples/s | 79.5 steps/s
[Step=76200 Epoch=148.6] | Loss=0.00896 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.847 | L2-Norm(final)=12.355 | 5120.9 samples/s | 80.0 steps/s
[Step=76250 Epoch=148.7] | Loss=0.00928 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.850 | L2-Norm(final)=12.362 | 5261.5 samples/s | 82.2 steps/s
[Step=76300 Epoch=148.8] | Loss=0.00907 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.853 | L2-Norm(final)=12.369 | 5204.3 samples/s | 81.3 steps/s
[Step=76350 Epoch=148.9] | Loss=0.00922 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.855 | L2-Norm(final)=12.375 | 5206.5 samples/s | 81.4 steps/s
[Step=76400 Epoch=149.0] | Loss=0.00908 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.858 | L2-Norm(final)=12.382 | 5261.0 samples/s | 82.2 steps/s
[Step=76450 Epoch=149.1] | Loss=0.00900 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=12.389 | 5293.9 samples/s | 82.7 steps/s
[Step=76500 Epoch=149.2] | Loss=0.00887 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=12.396 | 6724.7 samples/s | 105.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=149.2] | Loss=0.00717 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=12.464 | 6312.6 samples/s | 98.6 steps/s
[Step=76550 Epoch=149.3] | Loss=0.00749 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.896 | L2-Norm(final)=12.471 | 4228.9 samples/s | 66.1 steps/s
[Step=76600 Epoch=149.4] | Loss=0.00896 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.901 | L2-Norm(final)=12.476 | 4571.0 samples/s | 71.4 steps/s
[Step=76650 Epoch=149.5] | Loss=0.00951 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.906 | L2-Norm(final)=12.480 | 4670.0 samples/s | 73.0 steps/s
[Step=76700 Epoch=149.6] | Loss=0.00931 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.910 | L2-Norm(final)=12.485 | 4545.6 samples/s | 71.0 steps/s
[Step=76750 Epoch=149.7] | Loss=0.00928 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.914 | L2-Norm(final)=12.489 | 4625.0 samples/s | 72.3 steps/s
[Step=76800 Epoch=149.8] | Loss=0.00982 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.917 | L2-Norm(final)=12.493 | 4632.7 samples/s | 72.4 steps/s
[Step=76850 Epoch=149.9] | Loss=0.00939 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.920 | L2-Norm(final)=12.496 | 4628.3 samples/s | 72.3 steps/s
[Step=76900 Epoch=150.0] | Loss=0.00945 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.923 | L2-Norm(final)=12.500 | 4693.6 samples/s | 73.3 steps/s
[Step=76950 Epoch=150.1] | Loss=0.00937 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=12.503 | 4710.2 samples/s | 73.6 steps/s
[Step=77000 Epoch=150.2] | Loss=0.00921 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.928 | L2-Norm(final)=12.507 | 5787.4 samples/s | 90.4 steps/s
[Step=77050 Epoch=150.3] | Loss=0.00904 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.930 | L2-Norm(final)=12.511 | 2449.5 samples/s | 38.3 steps/s
[Step=77100 Epoch=150.4] | Loss=0.00875 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.932 | L2-Norm(final)=12.514 | 4659.7 samples/s | 72.8 steps/s
[Step=77150 Epoch=150.5] | Loss=0.00855 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.934 | L2-Norm(final)=12.518 | 4581.0 samples/s | 71.6 steps/s
[Step=77200 Epoch=150.6] | Loss=0.00841 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.936 | L2-Norm(final)=12.521 | 4622.2 samples/s | 72.2 steps/s
[Step=77250 Epoch=150.7] | Loss=0.00829 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.937 | L2-Norm(final)=12.525 | 4621.6 samples/s | 72.2 steps/s
[Step=77300 Epoch=150.8] | Loss=0.00815 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=12.528 | 4602.6 samples/s | 71.9 steps/s
[Step=77350 Epoch=150.9] | Loss=0.00808 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.940 | L2-Norm(final)=12.531 | 4620.6 samples/s | 72.2 steps/s
[Step=77400 Epoch=151.0] | Loss=0.00798 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.941 | L2-Norm(final)=12.535 | 4667.4 samples/s | 72.9 steps/s
[Step=77450 Epoch=151.1] | Loss=0.00785 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=12.538 | 4619.5 samples/s | 72.2 steps/s
[Step=77500 Epoch=151.2] | Loss=0.00779 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.944 | L2-Norm(final)=12.541 | 4972.2 samples/s | 77.7 steps/s
[Step=77550 Epoch=151.3] | Loss=0.00775 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=12.544 | 2679.0 samples/s | 41.9 steps/s
[Step=77600 Epoch=151.4] | Loss=0.00769 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=12.547 | 4581.8 samples/s | 71.6 steps/s
[Step=77650 Epoch=151.4] | Loss=0.00755 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=12.550 | 4650.4 samples/s | 72.7 steps/s
[Step=77700 Epoch=151.5] | Loss=0.00746 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=12.553 | 4586.7 samples/s | 71.7 steps/s
[Step=77750 Epoch=151.6] | Loss=0.00739 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.948 | L2-Norm(final)=12.556 | 4615.9 samples/s | 72.1 steps/s
[Step=77800 Epoch=151.7] | Loss=0.00736 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=12.559 | 4594.1 samples/s | 71.8 steps/s
[Step=77850 Epoch=151.8] | Loss=0.00727 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=12.562 | 4636.7 samples/s | 72.4 steps/s
[Step=77900 Epoch=151.9] | Loss=0.00727 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=12.565 | 4602.8 samples/s | 71.9 steps/s
[Step=77950 Epoch=152.0] | Loss=0.00716 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=12.568 | 4638.9 samples/s | 72.5 steps/s
[Step=78000 Epoch=152.1] | Loss=0.00715 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.952 | L2-Norm(final)=12.570 | 4691.3 samples/s | 73.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step78000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=148.6] | Loss=0.00413 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.140 | L2-Norm(final)=12.824 | 6691.9 samples/s | 104.6 steps/s
[Step=76050 Epoch=148.7] | Loss=0.00947 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.144 | L2-Norm(final)=12.830 | 4456.8 samples/s | 69.6 steps/s
[Step=76100 Epoch=148.8] | Loss=0.00853 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.148 | L2-Norm(final)=12.837 | 5181.8 samples/s | 81.0 steps/s
[Step=76150 Epoch=148.9] | Loss=0.00846 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.152 | L2-Norm(final)=12.844 | 5192.7 samples/s | 81.1 steps/s
[Step=76200 Epoch=149.0] | Loss=0.00821 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.156 | L2-Norm(final)=12.851 | 5169.6 samples/s | 80.8 steps/s
[Step=76250 Epoch=149.1] | Loss=0.00847 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=12.858 | 5436.7 samples/s | 84.9 steps/s
[Step=76300 Epoch=149.2] | Loss=0.00856 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.163 | L2-Norm(final)=12.865 | 4977.2 samples/s | 77.8 steps/s
[Step=76350 Epoch=149.3] | Loss=0.00847 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.166 | L2-Norm(final)=12.871 | 5190.0 samples/s | 81.1 steps/s
[Step=76400 Epoch=149.4] | Loss=0.00845 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=12.878 | 5284.5 samples/s | 82.6 steps/s
[Step=76450 Epoch=149.5] | Loss=0.00867 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.173 | L2-Norm(final)=12.884 | 5123.3 samples/s | 80.1 steps/s
[Step=76500 Epoch=149.6] | Loss=0.00862 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=12.890 | 7074.0 samples/s | 110.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=149.6] | Loss=0.01140 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.210 | L2-Norm(final)=12.954 | 6251.2 samples/s | 97.7 steps/s
[Step=76550 Epoch=149.7] | Loss=0.00895 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.215 | L2-Norm(final)=12.959 | 4220.0 samples/s | 65.9 steps/s
[Step=76600 Epoch=149.8] | Loss=0.00962 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.220 | L2-Norm(final)=12.964 | 4562.8 samples/s | 71.3 steps/s
[Step=76650 Epoch=149.8] | Loss=0.00940 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.225 | L2-Norm(final)=12.968 | 4642.4 samples/s | 72.5 steps/s
[Step=76700 Epoch=149.9] | Loss=0.00953 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.229 | L2-Norm(final)=12.973 | 4607.5 samples/s | 72.0 steps/s
[Step=76750 Epoch=150.0] | Loss=0.00958 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.233 | L2-Norm(final)=12.977 | 4631.5 samples/s | 72.4 steps/s
[Step=76800 Epoch=150.1] | Loss=0.00946 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.237 | L2-Norm(final)=12.981 | 4634.0 samples/s | 72.4 steps/s
[Step=76850 Epoch=150.2] | Loss=0.00951 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=12.985 | 4594.1 samples/s | 71.8 steps/s
[Step=76900 Epoch=150.3] | Loss=0.00934 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=12.988 | 4601.0 samples/s | 71.9 steps/s
[Step=76950 Epoch=150.4] | Loss=0.00928 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=12.992 | 4669.8 samples/s | 73.0 steps/s
[Step=77000 Epoch=150.5] | Loss=0.00927 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.248 | L2-Norm(final)=12.995 | 5972.6 samples/s | 93.3 steps/s
[Step=77050 Epoch=150.6] | Loss=0.00892 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.250 | L2-Norm(final)=12.999 | 2433.2 samples/s | 38.0 steps/s
[Step=77100 Epoch=150.7] | Loss=0.00862 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.252 | L2-Norm(final)=13.003 | 4603.5 samples/s | 71.9 steps/s
[Step=77150 Epoch=150.8] | Loss=0.00840 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=13.006 | 4686.2 samples/s | 73.2 steps/s
[Step=77200 Epoch=150.9] | Loss=0.00824 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.256 | L2-Norm(final)=13.009 | 4517.3 samples/s | 70.6 steps/s
[Step=77250 Epoch=151.0] | Loss=0.00826 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.257 | L2-Norm(final)=13.012 | 4776.6 samples/s | 74.6 steps/s
[Step=77300 Epoch=151.1] | Loss=0.00811 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=13.015 | 4467.9 samples/s | 69.8 steps/s
[Step=77350 Epoch=151.2] | Loss=0.00795 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.260 | L2-Norm(final)=13.018 | 4666.8 samples/s | 72.9 steps/s
[Step=77400 Epoch=151.3] | Loss=0.00784 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=13.021 | 4588.9 samples/s | 71.7 steps/s
[Step=77450 Epoch=151.4] | Loss=0.00777 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.262 | L2-Norm(final)=13.024 | 4618.5 samples/s | 72.2 steps/s
[Step=77500 Epoch=151.5] | Loss=0.00776 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=13.027 | 5120.0 samples/s | 80.0 steps/s
[Step=77550 Epoch=151.6] | Loss=0.00768 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.264 | L2-Norm(final)=13.029 | 2621.2 samples/s | 41.0 steps/s
[Step=77600 Epoch=151.7] | Loss=0.00757 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.264 | L2-Norm(final)=13.032 | 4597.4 samples/s | 71.8 steps/s
[Step=77650 Epoch=151.8] | Loss=0.00744 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.265 | L2-Norm(final)=13.035 | 4630.0 samples/s | 72.3 steps/s
[Step=77700 Epoch=151.9] | Loss=0.00732 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.266 | L2-Norm(final)=13.038 | 4676.1 samples/s | 73.1 steps/s
[Step=77750 Epoch=152.0] | Loss=0.00720 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.267 | L2-Norm(final)=13.041 | 4567.8 samples/s | 71.4 steps/s
[Step=77800 Epoch=152.1] | Loss=0.00711 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=13.043 | 4628.5 samples/s | 72.3 steps/s
[Step=77850 Epoch=152.2] | Loss=0.00705 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=13.046 | 4735.0 samples/s | 74.0 steps/s
[Step=77900 Epoch=152.3] | Loss=0.00702 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=13.049 | 4471.1 samples/s | 69.9 steps/s
[Step=77950 Epoch=152.4] | Loss=0.00696 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.269 | L2-Norm(final)=13.051 | 4634.3 samples/s | 72.4 steps/s
[Step=78000 Epoch=152.5] | Loss=0.00689 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=13.054 | 4617.7 samples/s | 72.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step78000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=291.2] | Loss=0.00006 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.279 | L2-Norm(final)=9.611 | 6392.9 samples/s | 99.9 steps/s
[Step=76050 Epoch=291.4] | Loss=0.00007 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=9.645 | 4285.6 samples/s | 67.0 steps/s
[Step=76100 Epoch=291.6] | Loss=0.00007 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.311 | L2-Norm(final)=9.674 | 4853.3 samples/s | 75.8 steps/s
[Step=76150 Epoch=291.8] | Loss=0.00006 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.320 | L2-Norm(final)=9.690 | 5036.7 samples/s | 78.7 steps/s
[Step=76200 Epoch=292.0] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.325 | L2-Norm(final)=9.702 | 4816.4 samples/s | 75.3 steps/s
[Step=76250 Epoch=292.2] | Loss=0.00005 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.330 | L2-Norm(final)=9.712 | 6825.9 samples/s | 106.7 steps/s
[Step=76300 Epoch=292.4] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=9.722 | 2468.9 samples/s | 38.6 steps/s
[Step=76350 Epoch=292.5] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.337 | L2-Norm(final)=9.730 | 4862.8 samples/s | 76.0 steps/s
[Step=76400 Epoch=292.7] | Loss=0.00004 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.340 | L2-Norm(final)=9.737 | 4940.4 samples/s | 77.2 steps/s
[Step=76450 Epoch=292.9] | Loss=0.00003 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.341 | L2-Norm(final)=9.744 | 5040.3 samples/s | 78.8 steps/s
[Step=76500 Epoch=293.1] | Loss=0.00003 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.342 | L2-Norm(final)=9.751 | 5480.5 samples/s | 85.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=293.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.353 | L2-Norm(final)=9.813 | 6305.5 samples/s | 98.5 steps/s
[Step=76550 Epoch=293.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.339 | L2-Norm(final)=9.818 | 3893.9 samples/s | 60.8 steps/s
[Step=76600 Epoch=293.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.320 | L2-Norm(final)=9.821 | 4391.9 samples/s | 68.6 steps/s
[Step=76650 Epoch=293.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.300 | L2-Norm(final)=9.824 | 4391.3 samples/s | 68.6 steps/s
[Step=76700 Epoch=293.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.280 | L2-Norm(final)=9.827 | 4372.1 samples/s | 68.3 steps/s
[Step=76750 Epoch=294.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.260 | L2-Norm(final)=9.830 | 5874.8 samples/s | 91.8 steps/s
[Step=76800 Epoch=294.3] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.239 | L2-Norm(final)=9.832 | 2319.9 samples/s | 36.2 steps/s
[Step=76850 Epoch=294.5] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.218 | L2-Norm(final)=9.834 | 4400.6 samples/s | 68.8 steps/s
[Step=76900 Epoch=294.7] | Loss=0.00001 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.196 | L2-Norm(final)=9.836 | 4408.4 samples/s | 68.9 steps/s
[Step=76950 Epoch=294.8] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.175 | L2-Norm(final)=9.838 | 4385.6 samples/s | 68.5 steps/s
[Step=77000 Epoch=295.0] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.152 | L2-Norm(final)=9.839 | 4946.3 samples/s | 77.3 steps/s
[Step=77050 Epoch=295.2] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.131 | L2-Norm(final)=9.841 | 2529.6 samples/s | 39.5 steps/s
[Step=77100 Epoch=295.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.111 | L2-Norm(final)=9.843 | 4249.7 samples/s | 66.4 steps/s
[Step=77150 Epoch=295.6] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=9.845 | 4434.5 samples/s | 69.3 steps/s
[Step=77200 Epoch=295.8] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.070 | L2-Norm(final)=9.846 | 4387.3 samples/s | 68.6 steps/s
[Step=77250 Epoch=296.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.050 | L2-Norm(final)=9.848 | 4396.4 samples/s | 68.7 steps/s
[Step=77300 Epoch=296.2] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=9.850 | 2657.4 samples/s | 41.5 steps/s
[Step=77350 Epoch=296.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=9.852 | 4477.9 samples/s | 70.0 steps/s
[Step=77400 Epoch=296.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.989 | L2-Norm(final)=9.853 | 4333.8 samples/s | 67.7 steps/s
[Step=77450 Epoch=296.8] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.969 | L2-Norm(final)=9.855 | 4367.7 samples/s | 68.2 steps/s
[Step=77500 Epoch=297.0] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.949 | L2-Norm(final)=9.857 | 4373.2 samples/s | 68.3 steps/s
[Step=77550 Epoch=297.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=9.859 | 2678.8 samples/s | 41.9 steps/s
[Step=77600 Epoch=297.3] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=9.860 | 4393.8 samples/s | 68.7 steps/s
[Step=77650 Epoch=297.5] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.888 | L2-Norm(final)=9.862 | 4492.4 samples/s | 70.2 steps/s
[Step=77700 Epoch=297.7] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=9.864 | 4383.9 samples/s | 68.5 steps/s
[Step=77750 Epoch=297.9] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.848 | L2-Norm(final)=9.866 | 4589.5 samples/s | 71.7 steps/s
[Step=77800 Epoch=298.1] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.827 | L2-Norm(final)=9.868 | 6060.9 samples/s | 94.7 steps/s
[Step=77850 Epoch=298.3] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.807 | L2-Norm(final)=9.870 | 2250.0 samples/s | 35.2 steps/s
[Step=77900 Epoch=298.5] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.787 | L2-Norm(final)=9.872 | 4345.8 samples/s | 67.9 steps/s
[Step=77950 Epoch=298.7] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.766 | L2-Norm(final)=9.874 | 4407.9 samples/s | 68.9 steps/s
[Step=78000 Epoch=298.9] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.746 | L2-Norm(final)=9.877 | 4334.1 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step78000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=292.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.333 | L2-Norm(final)=9.799 | 5925.7 samples/s | 92.6 steps/s
[Step=76050 Epoch=292.7] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.333 | L2-Norm(final)=9.800 | 4486.9 samples/s | 70.1 steps/s
[Step=76100 Epoch=292.9] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=9.801 | 4981.7 samples/s | 77.8 steps/s
[Step=76150 Epoch=293.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=9.802 | 5122.2 samples/s | 80.0 steps/s
[Step=76200 Epoch=293.3] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=9.803 | 4620.1 samples/s | 72.2 steps/s
[Step=76250 Epoch=293.5] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.805 | 7015.8 samples/s | 109.6 steps/s
[Step=76300 Epoch=293.7] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.806 | 2438.3 samples/s | 38.1 steps/s
[Step=76350 Epoch=293.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.807 | 4910.6 samples/s | 76.7 steps/s
[Step=76400 Epoch=294.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.808 | 4876.9 samples/s | 76.2 steps/s
[Step=76450 Epoch=294.3] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.809 | 4901.8 samples/s | 76.6 steps/s
[Step=76500 Epoch=294.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.810 | 5895.3 samples/s | 92.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=294.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.337 | L2-Norm(final)=9.822 | 6317.3 samples/s | 98.7 steps/s
[Step=76550 Epoch=294.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.336 | L2-Norm(final)=9.823 | 3936.6 samples/s | 61.5 steps/s
[Step=76600 Epoch=294.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=9.824 | 4276.6 samples/s | 66.8 steps/s
[Step=76650 Epoch=295.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.333 | L2-Norm(final)=9.825 | 4389.5 samples/s | 68.6 steps/s
[Step=76700 Epoch=295.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.332 | L2-Norm(final)=9.826 | 4445.7 samples/s | 69.5 steps/s
[Step=76750 Epoch=295.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.331 | L2-Norm(final)=9.827 | 5842.9 samples/s | 91.3 steps/s
[Step=76800 Epoch=295.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.330 | L2-Norm(final)=9.828 | 2326.2 samples/s | 36.3 steps/s
[Step=76850 Epoch=295.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.329 | L2-Norm(final)=9.829 | 4314.5 samples/s | 67.4 steps/s
[Step=76900 Epoch=296.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.327 | L2-Norm(final)=9.830 | 4428.3 samples/s | 69.2 steps/s
[Step=76950 Epoch=296.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.326 | L2-Norm(final)=9.831 | 4325.3 samples/s | 67.6 steps/s
[Step=77000 Epoch=296.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.325 | L2-Norm(final)=9.832 | 5162.0 samples/s | 80.7 steps/s
[Step=77050 Epoch=296.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.323 | L2-Norm(final)=9.832 | 2459.9 samples/s | 38.4 steps/s
[Step=77100 Epoch=296.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=9.833 | 4393.8 samples/s | 68.7 steps/s
[Step=77150 Epoch=297.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.320 | L2-Norm(final)=9.834 | 4353.4 samples/s | 68.0 steps/s
[Step=77200 Epoch=297.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.319 | L2-Norm(final)=9.835 | 4377.3 samples/s | 68.4 steps/s
[Step=77250 Epoch=297.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=9.835 | 4488.1 samples/s | 70.1 steps/s
[Step=77300 Epoch=297.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=9.836 | 2651.8 samples/s | 41.4 steps/s
[Step=77350 Epoch=297.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.314 | L2-Norm(final)=9.837 | 4388.7 samples/s | 68.6 steps/s
[Step=77400 Epoch=297.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.312 | L2-Norm(final)=9.838 | 4413.8 samples/s | 69.0 steps/s
[Step=77450 Epoch=298.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.311 | L2-Norm(final)=9.838 | 4355.3 samples/s | 68.1 steps/s
[Step=77500 Epoch=298.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.309 | L2-Norm(final)=9.839 | 4397.6 samples/s | 68.7 steps/s
[Step=77550 Epoch=298.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.307 | L2-Norm(final)=9.840 | 2682.2 samples/s | 41.9 steps/s
[Step=77600 Epoch=298.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.306 | L2-Norm(final)=9.840 | 4375.0 samples/s | 68.4 steps/s
[Step=77650 Epoch=298.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=9.841 | 4438.4 samples/s | 69.4 steps/s
[Step=77700 Epoch=299.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.302 | L2-Norm(final)=9.842 | 4355.3 samples/s | 68.1 steps/s
[Step=77750 Epoch=299.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.300 | L2-Norm(final)=9.842 | 4384.4 samples/s | 68.5 steps/s
[Step=77800 Epoch=299.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.299 | L2-Norm(final)=9.843 | 7156.4 samples/s | 111.8 steps/s
[Step=77850 Epoch=299.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.297 | L2-Norm(final)=9.844 | 2172.6 samples/s | 33.9 steps/s
[Step=77900 Epoch=299.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.295 | L2-Norm(final)=9.844 | 4435.5 samples/s | 69.3 steps/s
[Step=77950 Epoch=300.1] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.293 | L2-Norm(final)=9.845 | 4335.6 samples/s | 67.7 steps/s
[Step=78000 Epoch=300.3] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=9.846 | 4473.0 samples/s | 69.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07904 | acc=0.9673 | tpr=0.9732 | fpr=0.0456 | 5319.0 samples/s | 20.8 steps/s
Avg test loss: 0.07936, Avg test acc: 0.96614, Avg tpr: 0.97249, Avg fpr: 0.04781, total FA: 373

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07791 | acc=0.9673 | tpr=0.9728 | fpr=0.0446 | 5339.7 samples/s | 20.9 steps/s
Avg test loss: 0.08026, Avg test acc: 0.96658, Avg tpr: 0.97173, Avg fpr: 0.04474, total FA: 349

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.46941 | acc=0.3119 | tpr=0.0033 | fpr=0.0181 | 5336.8 samples/s | 20.8 steps/s
Avg test loss: 5.48355, Avg test acc: 0.30968, Avg tpr: 0.00373, Avg fpr: 0.01743, total FA: 136

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.27773 | acc=0.3020 | tpr=0.0076 | fpr=0.0587 | 5290.1 samples/s | 20.7 steps/s
Avg test loss: 5.28145, Avg test acc: 0.30155, Avg tpr: 0.00822, Avg fpr: 0.05333, total FA: 416

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.67091 | acc=0.1262 | tpr=0.7345 | fpr=0.8848 | 5332.3 samples/s | 20.8 steps/s
[Step= 100] | Loss=5.64288 | acc=0.1267 | tpr=0.7313 | fpr=0.8846 | 6908.4 samples/s | 27.0 steps/s
[Step= 150] | Loss=5.63900 | acc=0.1282 | tpr=0.7435 | fpr=0.8832 | 8228.5 samples/s | 32.1 steps/s
[Step= 200] | Loss=5.64990 | acc=0.1275 | tpr=0.7399 | fpr=0.8837 | 7868.3 samples/s | 30.7 steps/s
[Step= 250] | Loss=5.65863 | acc=0.1278 | tpr=0.7293 | fpr=0.8832 | 8351.2 samples/s | 32.6 steps/s
[Step= 300] | Loss=5.66146 | acc=0.1275 | tpr=0.7302 | fpr=0.8835 | 7896.7 samples/s | 30.8 steps/s
[Step= 350] | Loss=5.65169 | acc=0.1277 | tpr=0.7289 | fpr=0.8833 | 8138.7 samples/s | 31.8 steps/s
[Step= 400] | Loss=5.64338 | acc=0.1283 | tpr=0.7352 | fpr=0.8828 | 8250.7 samples/s | 32.2 steps/s
[Step= 450] | Loss=5.64389 | acc=0.1278 | tpr=0.7386 | fpr=0.8833 | 8011.6 samples/s | 31.3 steps/s
[Step= 500] | Loss=5.64269 | acc=0.1274 | tpr=0.7374 | fpr=0.8836 | 8163.6 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.64135 | acc=0.1274 | tpr=0.7346 | fpr=0.8836 | 14328.2 samples/s | 56.0 steps/s
Avg test loss: 5.64249, Avg test acc: 0.12741, Avg tpr: 0.73494, Avg fpr: 0.88364, total FA: 122691

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.86524 | acc=0.1411 | tpr=0.7124 | fpr=0.8692 | 5150.1 samples/s | 20.1 steps/s
[Step= 100] | Loss=5.84745 | acc=0.1407 | tpr=0.7079 | fpr=0.8699 | 7451.0 samples/s | 29.1 steps/s
[Step= 150] | Loss=5.83614 | acc=0.1405 | tpr=0.7161 | fpr=0.8700 | 7846.6 samples/s | 30.7 steps/s
[Step= 200] | Loss=5.84571 | acc=0.1405 | tpr=0.7169 | fpr=0.8699 | 7989.0 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.85460 | acc=0.1411 | tpr=0.7127 | fpr=0.8693 | 8294.3 samples/s | 32.4 steps/s
[Step= 300] | Loss=5.85787 | acc=0.1408 | tpr=0.7142 | fpr=0.8696 | 8104.9 samples/s | 31.7 steps/s
[Step= 350] | Loss=5.84350 | acc=0.1412 | tpr=0.7120 | fpr=0.8692 | 8198.2 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.83465 | acc=0.1416 | tpr=0.7123 | fpr=0.8688 | 8001.2 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.83408 | acc=0.1409 | tpr=0.7128 | fpr=0.8695 | 8364.3 samples/s | 32.7 steps/s
[Step= 500] | Loss=5.83602 | acc=0.1406 | tpr=0.7101 | fpr=0.8696 | 8063.0 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.83416 | acc=0.1406 | tpr=0.7051 | fpr=0.8696 | 14919.9 samples/s | 58.3 steps/s
Avg test loss: 5.83572, Avg test acc: 0.14058, Avg tpr: 0.70523, Avg fpr: 0.86968, total FA: 120754

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10794 | acc=0.9804 | tpr=0.9558 | fpr=0.0192 | 5166.7 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.11255 | acc=0.9793 | tpr=0.9638 | fpr=0.0204 | 7422.0 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.11782 | acc=0.9780 | tpr=0.9582 | fpr=0.0216 | 7816.7 samples/s | 30.5 steps/s
[Step= 200] | Loss=0.11983 | acc=0.9782 | tpr=0.9596 | fpr=0.0214 | 8207.2 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.11779 | acc=0.9784 | tpr=0.9598 | fpr=0.0213 | 8310.2 samples/s | 32.5 steps/s
[Step= 300] | Loss=0.11989 | acc=0.9780 | tpr=0.9593 | fpr=0.0216 | 7767.8 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.12052 | acc=0.9778 | tpr=0.9612 | fpr=0.0219 | 8082.9 samples/s | 31.6 steps/s
[Step= 400] | Loss=0.12158 | acc=0.9777 | tpr=0.9595 | fpr=0.0220 | 8242.4 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.12408 | acc=0.9773 | tpr=0.9596 | fpr=0.0224 | 8113.1 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.12345 | acc=0.9773 | tpr=0.9586 | fpr=0.0224 | 7933.9 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.12256 | acc=0.9775 | tpr=0.9586 | fpr=0.0222 | 14742.6 samples/s | 57.6 steps/s
Avg test loss: 0.12223, Avg test acc: 0.97752, Avg tpr: 0.95880, Avg fpr: 0.02214, total FA: 3074

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12774 | acc=0.9795 | tpr=0.9513 | fpr=0.0200 | 5333.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.13409 | acc=0.9781 | tpr=0.9574 | fpr=0.0215 | 7020.2 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.13933 | acc=0.9772 | tpr=0.9611 | fpr=0.0225 | 8081.2 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.14164 | acc=0.9772 | tpr=0.9639 | fpr=0.0225 | 8198.4 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.13892 | acc=0.9776 | tpr=0.9651 | fpr=0.0222 | 8154.8 samples/s | 31.9 steps/s
[Step= 300] | Loss=0.14115 | acc=0.9773 | tpr=0.9636 | fpr=0.0225 | 7921.9 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.14214 | acc=0.9770 | tpr=0.9637 | fpr=0.0228 | 8032.8 samples/s | 31.4 steps/s
[Step= 400] | Loss=0.14347 | acc=0.9769 | tpr=0.9612 | fpr=0.0228 | 8170.0 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.14648 | acc=0.9764 | tpr=0.9601 | fpr=0.0233 | 7952.4 samples/s | 31.1 steps/s
[Step= 500] | Loss=0.14574 | acc=0.9764 | tpr=0.9599 | fpr=0.0233 | 8309.9 samples/s | 32.5 steps/s
[Step= 550] | Loss=0.14450 | acc=0.9766 | tpr=0.9594 | fpr=0.0231 | 14286.0 samples/s | 55.8 steps/s
Avg test loss: 0.14414, Avg test acc: 0.97659, Avg tpr: 0.95880, Avg fpr: 0.02309, total FA: 3206

server round 39/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=152.1] | Loss=0.04513 | Reg=0.00218 | acc=0.9688 | L2-Norm=14.770 | L2-Norm(final)=12.655 | 6559.2 samples/s | 102.5 steps/s
[Step=78050 Epoch=152.2] | Loss=0.01080 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=12.659 | 4618.9 samples/s | 72.2 steps/s
[Step=78100 Epoch=152.3] | Loss=0.00967 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.777 | L2-Norm(final)=12.664 | 5188.0 samples/s | 81.1 steps/s
[Step=78150 Epoch=152.4] | Loss=0.00961 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.780 | L2-Norm(final)=12.669 | 5128.7 samples/s | 80.1 steps/s
[Step=78200 Epoch=152.5] | Loss=0.00967 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.783 | L2-Norm(final)=12.675 | 5138.1 samples/s | 80.3 steps/s
[Step=78250 Epoch=152.6] | Loss=0.00952 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.786 | L2-Norm(final)=12.681 | 5235.9 samples/s | 81.8 steps/s
[Step=78300 Epoch=152.7] | Loss=0.00939 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.788 | L2-Norm(final)=12.687 | 5227.7 samples/s | 81.7 steps/s
[Step=78350 Epoch=152.8] | Loss=0.00939 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.791 | L2-Norm(final)=12.693 | 5183.1 samples/s | 81.0 steps/s
[Step=78400 Epoch=152.9] | Loss=0.00923 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.793 | L2-Norm(final)=12.700 | 5241.6 samples/s | 81.9 steps/s
[Step=78450 Epoch=153.0] | Loss=0.00912 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.795 | L2-Norm(final)=12.706 | 5177.7 samples/s | 80.9 steps/s
[Step=78500 Epoch=153.1] | Loss=0.00923 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.798 | L2-Norm(final)=12.712 | 6964.5 samples/s | 108.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=153.1] | Loss=0.00842 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.822 | L2-Norm(final)=12.772 | 6267.0 samples/s | 97.9 steps/s
[Step=78550 Epoch=153.2] | Loss=0.00861 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.827 | L2-Norm(final)=12.779 | 4211.7 samples/s | 65.8 steps/s
[Step=78600 Epoch=153.3] | Loss=0.00934 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.833 | L2-Norm(final)=12.784 | 4615.5 samples/s | 72.1 steps/s
[Step=78650 Epoch=153.4] | Loss=0.00951 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=12.789 | 4641.4 samples/s | 72.5 steps/s
[Step=78700 Epoch=153.5] | Loss=0.00952 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=12.794 | 4636.1 samples/s | 72.4 steps/s
[Step=78750 Epoch=153.6] | Loss=0.00957 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=12.799 | 4579.5 samples/s | 71.6 steps/s
[Step=78800 Epoch=153.7] | Loss=0.00957 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.847 | L2-Norm(final)=12.803 | 4654.0 samples/s | 72.7 steps/s
[Step=78850 Epoch=153.8] | Loss=0.00929 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.850 | L2-Norm(final)=12.808 | 4628.8 samples/s | 72.3 steps/s
[Step=78900 Epoch=153.9] | Loss=0.00908 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.853 | L2-Norm(final)=12.812 | 4665.4 samples/s | 72.9 steps/s
[Step=78950 Epoch=154.0] | Loss=0.00921 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.856 | L2-Norm(final)=12.817 | 4588.3 samples/s | 71.7 steps/s
[Step=79000 Epoch=154.1] | Loss=0.00932 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.859 | L2-Norm(final)=12.821 | 5916.7 samples/s | 92.4 steps/s
[Step=79050 Epoch=154.2] | Loss=0.00917 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=12.825 | 2451.9 samples/s | 38.3 steps/s
[Step=79100 Epoch=154.3] | Loss=0.00891 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.864 | L2-Norm(final)=12.829 | 4614.9 samples/s | 72.1 steps/s
[Step=79150 Epoch=154.4] | Loss=0.00859 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.866 | L2-Norm(final)=12.833 | 4643.3 samples/s | 72.6 steps/s
[Step=79200 Epoch=154.5] | Loss=0.00858 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=12.837 | 4573.9 samples/s | 71.5 steps/s
[Step=79250 Epoch=154.6] | Loss=0.00851 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.870 | L2-Norm(final)=12.841 | 4608.9 samples/s | 72.0 steps/s
[Step=79300 Epoch=154.7] | Loss=0.00836 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.872 | L2-Norm(final)=12.844 | 4676.0 samples/s | 73.1 steps/s
[Step=79350 Epoch=154.8] | Loss=0.00824 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.873 | L2-Norm(final)=12.848 | 4651.3 samples/s | 72.7 steps/s
[Step=79400 Epoch=154.9] | Loss=0.00817 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.875 | L2-Norm(final)=12.852 | 4597.7 samples/s | 71.8 steps/s
[Step=79450 Epoch=155.0] | Loss=0.00813 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=12.855 | 4621.6 samples/s | 72.2 steps/s
[Step=79500 Epoch=155.1] | Loss=0.00804 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.878 | L2-Norm(final)=12.859 | 4970.7 samples/s | 77.7 steps/s
[Step=79550 Epoch=155.2] | Loss=0.00793 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.879 | L2-Norm(final)=12.862 | 2671.5 samples/s | 41.7 steps/s
[Step=79600 Epoch=155.3] | Loss=0.00783 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.880 | L2-Norm(final)=12.866 | 4663.5 samples/s | 72.9 steps/s
[Step=79650 Epoch=155.3] | Loss=0.00772 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.881 | L2-Norm(final)=12.869 | 4574.6 samples/s | 71.5 steps/s
[Step=79700 Epoch=155.4] | Loss=0.00757 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.882 | L2-Norm(final)=12.872 | 4716.9 samples/s | 73.7 steps/s
[Step=79750 Epoch=155.5] | Loss=0.00755 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.883 | L2-Norm(final)=12.876 | 4510.9 samples/s | 70.5 steps/s
[Step=79800 Epoch=155.6] | Loss=0.00749 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=12.879 | 4630.0 samples/s | 72.3 steps/s
[Step=79850 Epoch=155.7] | Loss=0.00747 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.885 | L2-Norm(final)=12.882 | 4684.3 samples/s | 73.2 steps/s
[Step=79900 Epoch=155.8] | Loss=0.00739 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.886 | L2-Norm(final)=12.885 | 4594.7 samples/s | 71.8 steps/s
[Step=79950 Epoch=155.9] | Loss=0.00732 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=12.888 | 4676.2 samples/s | 73.1 steps/s
[Step=80000 Epoch=156.0] | Loss=0.00730 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=12.891 | 4563.1 samples/s | 71.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step80000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=152.5] | Loss=0.01208 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.091 | L2-Norm(final)=13.133 | 5208.7 samples/s | 81.4 steps/s
[Step=78050 Epoch=152.6] | Loss=0.00985 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=13.139 | 4881.2 samples/s | 76.3 steps/s
[Step=78100 Epoch=152.7] | Loss=0.00978 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.096 | L2-Norm(final)=13.145 | 5163.7 samples/s | 80.7 steps/s
[Step=78150 Epoch=152.8] | Loss=0.00909 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=13.152 | 5105.7 samples/s | 79.8 steps/s
[Step=78200 Epoch=152.9] | Loss=0.00875 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.100 | L2-Norm(final)=13.158 | 5197.3 samples/s | 81.2 steps/s
[Step=78250 Epoch=153.0] | Loss=0.00877 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.103 | L2-Norm(final)=13.164 | 5256.1 samples/s | 82.1 steps/s
[Step=78300 Epoch=153.1] | Loss=0.00862 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.106 | L2-Norm(final)=13.170 | 5180.9 samples/s | 81.0 steps/s
[Step=78350 Epoch=153.2] | Loss=0.00869 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.109 | L2-Norm(final)=13.176 | 5195.9 samples/s | 81.2 steps/s
[Step=78400 Epoch=153.3] | Loss=0.00886 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.111 | L2-Norm(final)=13.182 | 5229.1 samples/s | 81.7 steps/s
[Step=78450 Epoch=153.4] | Loss=0.00862 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.114 | L2-Norm(final)=13.188 | 5185.9 samples/s | 81.0 steps/s
[Step=78500 Epoch=153.5] | Loss=0.00852 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=13.194 | 7061.9 samples/s | 110.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=153.5] | Loss=0.01587 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.145 | L2-Norm(final)=13.256 | 6060.4 samples/s | 94.7 steps/s
[Step=78550 Epoch=153.6] | Loss=0.00889 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.149 | L2-Norm(final)=13.261 | 4421.4 samples/s | 69.1 steps/s
[Step=78600 Epoch=153.7] | Loss=0.00926 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.155 | L2-Norm(final)=13.266 | 4496.9 samples/s | 70.3 steps/s
[Step=78650 Epoch=153.8] | Loss=0.00990 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.271 | 4630.4 samples/s | 72.3 steps/s
[Step=78700 Epoch=153.9] | Loss=0.00999 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.163 | L2-Norm(final)=13.275 | 4618.2 samples/s | 72.2 steps/s
[Step=78750 Epoch=154.0] | Loss=0.01001 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=13.279 | 4620.2 samples/s | 72.2 steps/s
[Step=78800 Epoch=154.1] | Loss=0.00999 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.171 | L2-Norm(final)=13.283 | 4712.1 samples/s | 73.6 steps/s
[Step=78850 Epoch=154.1] | Loss=0.00984 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.174 | L2-Norm(final)=13.287 | 4528.2 samples/s | 70.8 steps/s
[Step=78900 Epoch=154.2] | Loss=0.00966 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=13.291 | 4585.5 samples/s | 71.6 steps/s
[Step=78950 Epoch=154.3] | Loss=0.00987 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=13.295 | 4646.2 samples/s | 72.6 steps/s
[Step=79000 Epoch=154.4] | Loss=0.00974 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=13.299 | 6067.8 samples/s | 94.8 steps/s
[Step=79050 Epoch=154.5] | Loss=0.00952 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.185 | L2-Norm(final)=13.302 | 2427.3 samples/s | 37.9 steps/s
[Step=79100 Epoch=154.6] | Loss=0.00921 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=13.306 | 4631.7 samples/s | 72.4 steps/s
[Step=79150 Epoch=154.7] | Loss=0.00896 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.189 | L2-Norm(final)=13.309 | 4647.2 samples/s | 72.6 steps/s
[Step=79200 Epoch=154.8] | Loss=0.00870 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.191 | L2-Norm(final)=13.313 | 4569.9 samples/s | 71.4 steps/s
[Step=79250 Epoch=154.9] | Loss=0.00844 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=13.316 | 4605.3 samples/s | 72.0 steps/s
[Step=79300 Epoch=155.0] | Loss=0.00833 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=13.320 | 4701.6 samples/s | 73.5 steps/s
[Step=79350 Epoch=155.1] | Loss=0.00823 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=13.323 | 4536.8 samples/s | 70.9 steps/s
[Step=79400 Epoch=155.2] | Loss=0.00811 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=13.326 | 4696.9 samples/s | 73.4 steps/s
[Step=79450 Epoch=155.3] | Loss=0.00805 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.198 | L2-Norm(final)=13.330 | 4599.6 samples/s | 71.9 steps/s
[Step=79500 Epoch=155.4] | Loss=0.00802 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=13.333 | 5131.2 samples/s | 80.2 steps/s
[Step=79550 Epoch=155.5] | Loss=0.00805 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=13.336 | 2641.1 samples/s | 41.3 steps/s
[Step=79600 Epoch=155.6] | Loss=0.00791 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=13.339 | 4542.3 samples/s | 71.0 steps/s
[Step=79650 Epoch=155.7] | Loss=0.00782 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=13.342 | 4612.0 samples/s | 72.1 steps/s
[Step=79700 Epoch=155.8] | Loss=0.00773 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.203 | L2-Norm(final)=13.345 | 4654.8 samples/s | 72.7 steps/s
[Step=79750 Epoch=155.9] | Loss=0.00761 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=13.348 | 4655.3 samples/s | 72.7 steps/s
[Step=79800 Epoch=156.0] | Loss=0.00756 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.205 | L2-Norm(final)=13.351 | 4558.5 samples/s | 71.2 steps/s
[Step=79850 Epoch=156.1] | Loss=0.00747 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=13.354 | 4638.0 samples/s | 72.5 steps/s
[Step=79900 Epoch=156.2] | Loss=0.00735 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.206 | L2-Norm(final)=13.357 | 4619.0 samples/s | 72.2 steps/s
[Step=79950 Epoch=156.3] | Loss=0.00730 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.207 | L2-Norm(final)=13.360 | 4627.2 samples/s | 72.3 steps/s
[Step=80000 Epoch=156.4] | Loss=0.00728 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=13.363 | 4674.3 samples/s | 73.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step80000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=298.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=9.945 | 5297.0 samples/s | 82.8 steps/s
[Step=78050 Epoch=299.1] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.025 | L2-Norm(final)=9.959 | 4448.5 samples/s | 69.5 steps/s
[Step=78100 Epoch=299.3] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=9.973 | 4945.9 samples/s | 77.3 steps/s
[Step=78150 Epoch=299.4] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=9.986 | 4829.3 samples/s | 75.5 steps/s
[Step=78200 Epoch=299.6] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=10.001 | 4855.7 samples/s | 75.9 steps/s
[Step=78250 Epoch=299.8] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=10.014 | 6873.5 samples/s | 107.4 steps/s
[Step=78300 Epoch=300.0] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.025 | 2494.5 samples/s | 39.0 steps/s
[Step=78350 Epoch=300.2] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.048 | L2-Norm(final)=10.034 | 4761.4 samples/s | 74.4 steps/s
[Step=78400 Epoch=300.4] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.050 | L2-Norm(final)=10.043 | 4959.8 samples/s | 77.5 steps/s
[Step=78450 Epoch=300.6] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.051 | L2-Norm(final)=10.051 | 4821.3 samples/s | 75.3 steps/s
[Step=78500 Epoch=300.8] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=10.060 | 5681.0 samples/s | 88.8 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=300.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.063 | L2-Norm(final)=10.142 | 6362.0 samples/s | 99.4 steps/s
[Step=78550 Epoch=301.0] | Loss=0.00196 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=10.160 | 3862.2 samples/s | 60.3 steps/s
[Step=78600 Epoch=301.2] | Loss=0.00114 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.163 | 4366.6 samples/s | 68.2 steps/s
[Step=78650 Epoch=301.4] | Loss=0.00078 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.109 | L2-Norm(final)=10.164 | 4393.8 samples/s | 68.7 steps/s
[Step=78700 Epoch=301.6] | Loss=0.00059 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.115 | L2-Norm(final)=10.166 | 4342.9 samples/s | 67.9 steps/s
[Step=78750 Epoch=301.7] | Loss=0.00048 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.118 | L2-Norm(final)=10.167 | 5884.4 samples/s | 91.9 steps/s
[Step=78800 Epoch=301.9] | Loss=0.00040 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=10.168 | 2329.9 samples/s | 36.4 steps/s
[Step=78850 Epoch=302.1] | Loss=0.00035 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.121 | L2-Norm(final)=10.169 | 4288.3 samples/s | 67.0 steps/s
[Step=78900 Epoch=302.3] | Loss=0.00030 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=10.170 | 4413.8 samples/s | 69.0 steps/s
[Step=78950 Epoch=302.5] | Loss=0.00027 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=10.170 | 4516.6 samples/s | 70.6 steps/s
[Step=79000 Epoch=302.7] | Loss=0.00024 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=10.171 | 4771.8 samples/s | 74.6 steps/s
[Step=79050 Epoch=302.9] | Loss=0.00022 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=10.172 | 2506.9 samples/s | 39.2 steps/s
[Step=79100 Epoch=303.1] | Loss=0.00021 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.122 | L2-Norm(final)=10.172 | 4362.2 samples/s | 68.2 steps/s
[Step=79150 Epoch=303.3] | Loss=0.00019 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.121 | L2-Norm(final)=10.173 | 4335.7 samples/s | 67.7 steps/s
[Step=79200 Epoch=303.5] | Loss=0.00018 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.121 | L2-Norm(final)=10.174 | 4393.1 samples/s | 68.6 steps/s
[Step=79250 Epoch=303.7] | Loss=0.00017 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=10.174 | 4462.5 samples/s | 69.7 steps/s
[Step=79300 Epoch=303.8] | Loss=0.00016 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.120 | L2-Norm(final)=10.175 | 2651.8 samples/s | 41.4 steps/s
[Step=79350 Epoch=304.0] | Loss=0.00015 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.119 | L2-Norm(final)=10.175 | 4346.8 samples/s | 67.9 steps/s
[Step=79400 Epoch=304.2] | Loss=0.00014 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.118 | L2-Norm(final)=10.176 | 4439.2 samples/s | 69.4 steps/s
[Step=79450 Epoch=304.4] | Loss=0.00013 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.118 | L2-Norm(final)=10.176 | 4370.4 samples/s | 68.3 steps/s
[Step=79500 Epoch=304.6] | Loss=0.00013 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.117 | L2-Norm(final)=10.177 | 4313.5 samples/s | 67.4 steps/s
[Step=79550 Epoch=304.8] | Loss=0.00012 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.116 | L2-Norm(final)=10.177 | 2705.9 samples/s | 42.3 steps/s
[Step=79600 Epoch=305.0] | Loss=0.00011 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.115 | L2-Norm(final)=10.177 | 4391.8 samples/s | 68.6 steps/s
[Step=79650 Epoch=305.2] | Loss=0.00011 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.114 | L2-Norm(final)=10.178 | 4343.4 samples/s | 67.9 steps/s
[Step=79700 Epoch=305.4] | Loss=0.00011 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.114 | L2-Norm(final)=10.178 | 4415.8 samples/s | 69.0 steps/s
[Step=79750 Epoch=305.6] | Loss=0.00010 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.113 | L2-Norm(final)=10.179 | 4351.1 samples/s | 68.0 steps/s
[Step=79800 Epoch=305.8] | Loss=0.00010 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.112 | L2-Norm(final)=10.179 | 6538.7 samples/s | 102.2 steps/s
[Step=79850 Epoch=306.0] | Loss=0.00009 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.111 | L2-Norm(final)=10.180 | 2236.6 samples/s | 34.9 steps/s
[Step=79900 Epoch=306.1] | Loss=0.00009 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.110 | L2-Norm(final)=10.180 | 4373.3 samples/s | 68.3 steps/s
[Step=79950 Epoch=306.3] | Loss=0.00009 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.109 | L2-Norm(final)=10.180 | 4368.8 samples/s | 68.3 steps/s
[Step=80000 Epoch=306.5] | Loss=0.00009 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.108 | L2-Norm(final)=10.181 | 4378.0 samples/s | 68.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step80000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=300.3] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=9.867 | 6188.0 samples/s | 96.7 steps/s
[Step=78050 Epoch=300.4] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.060 | L2-Norm(final)=9.872 | 4401.5 samples/s | 68.8 steps/s
[Step=78100 Epoch=300.6] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.063 | L2-Norm(final)=9.877 | 5020.5 samples/s | 78.4 steps/s
[Step=78150 Epoch=300.8] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.065 | L2-Norm(final)=9.882 | 4742.5 samples/s | 74.1 steps/s
[Step=78200 Epoch=301.0] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=9.888 | 5039.7 samples/s | 78.7 steps/s
[Step=78250 Epoch=301.2] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.072 | L2-Norm(final)=9.893 | 6735.6 samples/s | 105.2 steps/s
[Step=78300 Epoch=301.4] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.074 | L2-Norm(final)=9.898 | 2455.5 samples/s | 38.4 steps/s
[Step=78350 Epoch=301.6] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.076 | L2-Norm(final)=9.903 | 4840.9 samples/s | 75.6 steps/s
[Step=78400 Epoch=301.8] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=9.907 | 4991.1 samples/s | 78.0 steps/s
[Step=78450 Epoch=302.0] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.079 | L2-Norm(final)=9.911 | 4875.7 samples/s | 76.2 steps/s
[Step=78500 Epoch=302.2] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.080 | L2-Norm(final)=9.916 | 5779.8 samples/s | 90.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=302.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=9.957 | 6167.4 samples/s | 96.4 steps/s
[Step=78550 Epoch=302.4] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=9.961 | 3939.0 samples/s | 61.5 steps/s
[Step=78600 Epoch=302.6] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=9.964 | 4416.9 samples/s | 69.0 steps/s
[Step=78650 Epoch=302.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.086 | L2-Norm(final)=9.967 | 4370.8 samples/s | 68.3 steps/s
[Step=78700 Epoch=302.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.084 | L2-Norm(final)=9.969 | 4379.4 samples/s | 68.4 steps/s
[Step=78750 Epoch=303.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=9.972 | 5938.9 samples/s | 92.8 steps/s
[Step=78800 Epoch=303.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=9.974 | 2307.2 samples/s | 36.0 steps/s
[Step=78850 Epoch=303.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=9.976 | 4427.5 samples/s | 69.2 steps/s
[Step=78900 Epoch=303.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.072 | L2-Norm(final)=9.977 | 4359.7 samples/s | 68.1 steps/s
[Step=78950 Epoch=303.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=9.979 | 4378.3 samples/s | 68.4 steps/s
[Step=79000 Epoch=304.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.066 | L2-Norm(final)=9.981 | 5106.4 samples/s | 79.8 steps/s
[Step=79050 Epoch=304.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=9.982 | 2458.0 samples/s | 38.4 steps/s
[Step=79100 Epoch=304.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.059 | L2-Norm(final)=9.984 | 4486.9 samples/s | 70.1 steps/s
[Step=79150 Epoch=304.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.056 | L2-Norm(final)=9.986 | 4305.2 samples/s | 67.3 steps/s
[Step=79200 Epoch=304.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.052 | L2-Norm(final)=9.987 | 4401.0 samples/s | 68.8 steps/s
[Step=79250 Epoch=305.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.048 | L2-Norm(final)=9.989 | 4490.4 samples/s | 70.2 steps/s
[Step=79300 Epoch=305.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=9.990 | 2662.9 samples/s | 41.6 steps/s
[Step=79350 Epoch=305.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.041 | L2-Norm(final)=9.992 | 4344.8 samples/s | 67.9 steps/s
[Step=79400 Epoch=305.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.037 | L2-Norm(final)=9.993 | 4500.5 samples/s | 70.3 steps/s
[Step=79450 Epoch=305.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.034 | L2-Norm(final)=9.995 | 4339.7 samples/s | 67.8 steps/s
[Step=79500 Epoch=306.0] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.030 | L2-Norm(final)=9.996 | 4368.0 samples/s | 68.2 steps/s
[Step=79550 Epoch=306.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=9.998 | 2701.4 samples/s | 42.2 steps/s
[Step=79600 Epoch=306.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.022 | L2-Norm(final)=9.999 | 4276.9 samples/s | 66.8 steps/s
[Step=79650 Epoch=306.6] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.018 | L2-Norm(final)=10.001 | 4403.4 samples/s | 68.8 steps/s
[Step=79700 Epoch=306.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.014 | L2-Norm(final)=10.002 | 4374.9 samples/s | 68.4 steps/s
[Step=79750 Epoch=307.0] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=10.003 | 4373.1 samples/s | 68.3 steps/s
[Step=79800 Epoch=307.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.006 | L2-Norm(final)=10.005 | 7177.4 samples/s | 112.1 steps/s
[Step=79850 Epoch=307.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=10.007 | 2171.0 samples/s | 33.9 steps/s
[Step=79900 Epoch=307.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.997 | L2-Norm(final)=10.008 | 4447.4 samples/s | 69.5 steps/s
[Step=79950 Epoch=307.8] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.993 | L2-Norm(final)=10.010 | 4357.1 samples/s | 68.1 steps/s
[Step=80000 Epoch=308.0] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.988 | L2-Norm(final)=10.011 | 4450.7 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07723 | acc=0.9668 | tpr=0.9791 | fpr=0.0600 | 5075.2 samples/s | 19.8 steps/s
Avg test loss: 0.07895, Avg test acc: 0.96562, Avg tpr: 0.97873, Avg fpr: 0.06320, total FA: 493

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07540 | acc=0.9673 | tpr=0.9766 | fpr=0.0528 | 5151.0 samples/s | 20.1 steps/s
Avg test loss: 0.07655, Avg test acc: 0.96735, Avg tpr: 0.97645, Avg fpr: 0.05269, total FA: 411

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.60645 | acc=0.3117 | tpr=0.0058 | fpr=0.0240 | 5344.2 samples/s | 20.9 steps/s
Avg test loss: 5.61184, Avg test acc: 0.30948, Avg tpr: 0.00571, Avg fpr: 0.02243, total FA: 175

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.33038 | acc=0.3051 | tpr=0.0073 | fpr=0.0483 | 5188.2 samples/s | 20.3 steps/s
Avg test loss: 5.33538, Avg test acc: 0.30447, Avg tpr: 0.00787, Avg fpr: 0.04320, total FA: 337

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.75109 | acc=0.1167 | tpr=0.7699 | fpr=0.8950 | 5326.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=5.72816 | acc=0.1161 | tpr=0.7655 | fpr=0.8960 | 7269.7 samples/s | 28.4 steps/s
[Step= 150] | Loss=5.72445 | acc=0.1165 | tpr=0.7795 | fpr=0.8957 | 7809.3 samples/s | 30.5 steps/s
[Step= 200] | Loss=5.73469 | acc=0.1157 | tpr=0.7716 | fpr=0.8962 | 8122.4 samples/s | 31.7 steps/s
[Step= 250] | Loss=5.74308 | acc=0.1158 | tpr=0.7598 | fpr=0.8960 | 8077.0 samples/s | 31.6 steps/s
[Step= 300] | Loss=5.74463 | acc=0.1152 | tpr=0.7600 | fpr=0.8965 | 8375.6 samples/s | 32.7 steps/s
[Step= 350] | Loss=5.73589 | acc=0.1152 | tpr=0.7583 | fpr=0.8965 | 7782.9 samples/s | 30.4 steps/s
[Step= 400] | Loss=5.72779 | acc=0.1155 | tpr=0.7637 | fpr=0.8963 | 8446.6 samples/s | 33.0 steps/s
[Step= 450] | Loss=5.72832 | acc=0.1150 | tpr=0.7648 | fpr=0.8968 | 7932.2 samples/s | 31.0 steps/s
[Step= 500] | Loss=5.72775 | acc=0.1145 | tpr=0.7643 | fpr=0.8972 | 8203.3 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.72630 | acc=0.1146 | tpr=0.7604 | fpr=0.8971 | 14160.4 samples/s | 55.3 steps/s
Avg test loss: 5.72770, Avg test acc: 0.11455, Avg tpr: 0.76070, Avg fpr: 0.89720, total FA: 124574

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.92209 | acc=0.1307 | tpr=0.7301 | fpr=0.8801 | 5277.4 samples/s | 20.6 steps/s
[Step= 100] | Loss=5.90488 | acc=0.1301 | tpr=0.7228 | fpr=0.8810 | 7042.9 samples/s | 27.5 steps/s
[Step= 150] | Loss=5.89306 | acc=0.1306 | tpr=0.7349 | fpr=0.8805 | 7726.0 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.90329 | acc=0.1299 | tpr=0.7344 | fpr=0.8811 | 8190.6 samples/s | 32.0 steps/s
[Step= 250] | Loss=5.91173 | acc=0.1306 | tpr=0.7284 | fpr=0.8803 | 8442.8 samples/s | 33.0 steps/s
[Step= 300] | Loss=5.91448 | acc=0.1303 | tpr=0.7265 | fpr=0.8805 | 7993.2 samples/s | 31.2 steps/s
[Step= 350] | Loss=5.90171 | acc=0.1302 | tpr=0.7232 | fpr=0.8805 | 7996.8 samples/s | 31.2 steps/s
[Step= 400] | Loss=5.89414 | acc=0.1306 | tpr=0.7232 | fpr=0.8801 | 7924.0 samples/s | 31.0 steps/s
[Step= 450] | Loss=5.89409 | acc=0.1300 | tpr=0.7240 | fpr=0.8808 | 8321.0 samples/s | 32.5 steps/s
[Step= 500] | Loss=5.89644 | acc=0.1300 | tpr=0.7233 | fpr=0.8808 | 8284.2 samples/s | 32.4 steps/s
[Step= 550] | Loss=5.89423 | acc=0.1300 | tpr=0.7191 | fpr=0.8807 | 14183.5 samples/s | 55.4 steps/s
Avg test loss: 5.89585, Avg test acc: 0.13000, Avg tpr: 0.71949, Avg fpr: 0.88071, total FA: 122285

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11937 | acc=0.9806 | tpr=0.9558 | fpr=0.0189 | 5376.4 samples/s | 21.0 steps/s
[Step= 100] | Loss=0.12455 | acc=0.9796 | tpr=0.9595 | fpr=0.0200 | 7393.2 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.13024 | acc=0.9784 | tpr=0.9539 | fpr=0.0212 | 7689.0 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13237 | acc=0.9783 | tpr=0.9530 | fpr=0.0212 | 7738.8 samples/s | 30.2 steps/s
[Step= 250] | Loss=0.12984 | acc=0.9787 | tpr=0.9537 | fpr=0.0209 | 8292.5 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.13209 | acc=0.9784 | tpr=0.9505 | fpr=0.0211 | 8298.3 samples/s | 32.4 steps/s
[Step= 350] | Loss=0.13242 | acc=0.9783 | tpr=0.9524 | fpr=0.0212 | 7916.6 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.13364 | acc=0.9782 | tpr=0.9519 | fpr=0.0213 | 8031.0 samples/s | 31.4 steps/s
[Step= 450] | Loss=0.13659 | acc=0.9778 | tpr=0.9508 | fpr=0.0217 | 8120.8 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.13579 | acc=0.9778 | tpr=0.9511 | fpr=0.0217 | 8154.1 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.13491 | acc=0.9780 | tpr=0.9507 | fpr=0.0215 | 14212.0 samples/s | 55.5 steps/s
Avg test loss: 0.13452, Avg test acc: 0.97797, Avg tpr: 0.95008, Avg fpr: 0.02152, total FA: 2988

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12473 | acc=0.9798 | tpr=0.9558 | fpr=0.0197 | 4907.5 samples/s | 19.2 steps/s
[Step= 100] | Loss=0.13079 | acc=0.9784 | tpr=0.9595 | fpr=0.0212 | 8109.5 samples/s | 31.7 steps/s
[Step= 150] | Loss=0.13623 | acc=0.9773 | tpr=0.9625 | fpr=0.0224 | 7865.0 samples/s | 30.7 steps/s
[Step= 200] | Loss=0.13833 | acc=0.9773 | tpr=0.9639 | fpr=0.0225 | 8060.7 samples/s | 31.5 steps/s
[Step= 250] | Loss=0.13583 | acc=0.9776 | tpr=0.9651 | fpr=0.0221 | 8298.0 samples/s | 32.4 steps/s
[Step= 300] | Loss=0.13815 | acc=0.9773 | tpr=0.9644 | fpr=0.0225 | 7962.6 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.13908 | acc=0.9771 | tpr=0.9656 | fpr=0.0227 | 7896.0 samples/s | 30.8 steps/s
[Step= 400] | Loss=0.14031 | acc=0.9769 | tpr=0.9628 | fpr=0.0228 | 8462.0 samples/s | 33.1 steps/s
[Step= 450] | Loss=0.14331 | acc=0.9764 | tpr=0.9615 | fpr=0.0233 | 7820.0 samples/s | 30.5 steps/s
[Step= 500] | Loss=0.14256 | acc=0.9764 | tpr=0.9621 | fpr=0.0233 | 8116.5 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.14130 | acc=0.9766 | tpr=0.9618 | fpr=0.0232 | 14880.9 samples/s | 58.1 steps/s
Avg test loss: 0.14095, Avg test acc: 0.97658, Avg tpr: 0.96117, Avg fpr: 0.02314, total FA: 3213

server round 40/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=156.0] | Loss=0.00515 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=12.983 | 6431.0 samples/s | 100.5 steps/s
[Step=80050 Epoch=156.1] | Loss=0.00905 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=12.985 | 4623.9 samples/s | 72.2 steps/s
[Step=80100 Epoch=156.2] | Loss=0.00862 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.840 | L2-Norm(final)=12.988 | 5189.7 samples/s | 81.1 steps/s
[Step=80150 Epoch=156.3] | Loss=0.00806 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=12.991 | 5127.3 samples/s | 80.1 steps/s
[Step=80200 Epoch=156.4] | Loss=0.00758 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.843 | L2-Norm(final)=12.994 | 5176.6 samples/s | 80.9 steps/s
[Step=80250 Epoch=156.5] | Loss=0.00736 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=12.997 | 5236.0 samples/s | 81.8 steps/s
[Step=80300 Epoch=156.6] | Loss=0.00746 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.844 | L2-Norm(final)=13.000 | 5171.4 samples/s | 80.8 steps/s
[Step=80350 Epoch=156.7] | Loss=0.00730 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.845 | L2-Norm(final)=13.003 | 5243.6 samples/s | 81.9 steps/s
[Step=80400 Epoch=156.8] | Loss=0.00718 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.846 | L2-Norm(final)=13.006 | 5171.9 samples/s | 80.8 steps/s
[Step=80450 Epoch=156.9] | Loss=0.00721 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.847 | L2-Norm(final)=13.009 | 5310.4 samples/s | 83.0 steps/s
[Step=80500 Epoch=157.0] | Loss=0.00716 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.848 | L2-Norm(final)=13.012 | 6762.5 samples/s | 105.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=157.0] | Loss=0.01296 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.858 | L2-Norm(final)=13.042 | 5871.9 samples/s | 91.7 steps/s
[Step=80550 Epoch=157.1] | Loss=0.00751 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.859 | L2-Norm(final)=13.045 | 4433.3 samples/s | 69.3 steps/s
[Step=80600 Epoch=157.2] | Loss=0.00742 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=13.048 | 4585.0 samples/s | 71.6 steps/s
[Step=80650 Epoch=157.3] | Loss=0.00699 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.863 | L2-Norm(final)=13.050 | 4691.8 samples/s | 73.3 steps/s
[Step=80700 Epoch=157.4] | Loss=0.00674 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=13.053 | 4524.8 samples/s | 70.7 steps/s
[Step=80750 Epoch=157.5] | Loss=0.00681 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=13.056 | 4671.4 samples/s | 73.0 steps/s
[Step=80800 Epoch=157.6] | Loss=0.00675 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.867 | L2-Norm(final)=13.058 | 4599.9 samples/s | 71.9 steps/s
[Step=80850 Epoch=157.7] | Loss=0.00674 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.061 | 4622.7 samples/s | 72.2 steps/s
[Step=80900 Epoch=157.8] | Loss=0.00691 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.869 | L2-Norm(final)=13.063 | 4720.5 samples/s | 73.8 steps/s
[Step=80950 Epoch=157.9] | Loss=0.00680 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=13.065 | 4570.2 samples/s | 71.4 steps/s
[Step=81000 Epoch=158.0] | Loss=0.00675 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.871 | L2-Norm(final)=13.068 | 5931.3 samples/s | 92.7 steps/s
[Step=81050 Epoch=158.1] | Loss=0.00665 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.872 | L2-Norm(final)=13.070 | 2453.9 samples/s | 38.3 steps/s
[Step=81100 Epoch=158.2] | Loss=0.00653 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.873 | L2-Norm(final)=13.072 | 4625.0 samples/s | 72.3 steps/s
[Step=81150 Epoch=158.3] | Loss=0.00649 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.874 | L2-Norm(final)=13.074 | 4610.6 samples/s | 72.0 steps/s
[Step=81200 Epoch=158.4] | Loss=0.00636 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.874 | L2-Norm(final)=13.076 | 4732.6 samples/s | 73.9 steps/s
[Step=81250 Epoch=158.5] | Loss=0.00620 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.875 | L2-Norm(final)=13.079 | 4499.2 samples/s | 70.3 steps/s
[Step=81300 Epoch=158.6] | Loss=0.00611 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.876 | L2-Norm(final)=13.081 | 4676.5 samples/s | 73.1 steps/s
[Step=81350 Epoch=158.7] | Loss=0.00609 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.876 | L2-Norm(final)=13.083 | 4589.4 samples/s | 71.7 steps/s
[Step=81400 Epoch=158.8] | Loss=0.00609 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.877 | L2-Norm(final)=13.085 | 4708.5 samples/s | 73.6 steps/s
[Step=81450 Epoch=158.9] | Loss=0.00611 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.877 | L2-Norm(final)=13.087 | 4596.0 samples/s | 71.8 steps/s
[Step=81500 Epoch=159.0] | Loss=0.00608 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=13.089 | 4911.5 samples/s | 76.7 steps/s
[Step=81550 Epoch=159.1] | Loss=0.00608 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=13.091 | 2667.1 samples/s | 41.7 steps/s
[Step=81600 Epoch=159.2] | Loss=0.00605 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=13.093 | 4625.7 samples/s | 72.3 steps/s
[Step=81650 Epoch=159.2] | Loss=0.00598 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.879 | L2-Norm(final)=13.094 | 4641.4 samples/s | 72.5 steps/s
[Step=81700 Epoch=159.3] | Loss=0.00596 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.880 | L2-Norm(final)=13.096 | 4577.4 samples/s | 71.5 steps/s
[Step=81750 Epoch=159.4] | Loss=0.00593 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.880 | L2-Norm(final)=13.098 | 4592.7 samples/s | 71.8 steps/s
[Step=81800 Epoch=159.5] | Loss=0.00585 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.880 | L2-Norm(final)=13.100 | 4690.1 samples/s | 73.3 steps/s
[Step=81850 Epoch=159.6] | Loss=0.00580 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=13.102 | 4584.9 samples/s | 71.6 steps/s
[Step=81900 Epoch=159.7] | Loss=0.00577 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.881 | L2-Norm(final)=13.104 | 4641.3 samples/s | 72.5 steps/s
[Step=81950 Epoch=159.8] | Loss=0.00578 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.881 | L2-Norm(final)=13.106 | 4623.3 samples/s | 72.2 steps/s
[Step=82000 Epoch=159.9] | Loss=0.00574 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.882 | L2-Norm(final)=13.108 | 4631.9 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step82000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=156.4] | Loss=0.00550 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=13.452 | 6700.3 samples/s | 104.7 steps/s
[Step=80050 Epoch=156.5] | Loss=0.00507 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=13.455 | 4716.1 samples/s | 73.7 steps/s
[Step=80100 Epoch=156.6] | Loss=0.00570 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.163 | L2-Norm(final)=13.458 | 5266.1 samples/s | 82.3 steps/s
[Step=80150 Epoch=156.7] | Loss=0.00603 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.164 | L2-Norm(final)=13.461 | 5159.5 samples/s | 80.6 steps/s
[Step=80200 Epoch=156.8] | Loss=0.00608 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.165 | L2-Norm(final)=13.464 | 5129.0 samples/s | 80.1 steps/s
[Step=80250 Epoch=156.9] | Loss=0.00620 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.166 | L2-Norm(final)=13.467 | 5164.7 samples/s | 80.7 steps/s
[Step=80300 Epoch=157.0] | Loss=0.00651 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.167 | L2-Norm(final)=13.470 | 5402.4 samples/s | 84.4 steps/s
[Step=80350 Epoch=157.1] | Loss=0.00646 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=13.473 | 5158.7 samples/s | 80.6 steps/s
[Step=80400 Epoch=157.2] | Loss=0.00655 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.169 | L2-Norm(final)=13.476 | 5122.9 samples/s | 80.0 steps/s
[Step=80450 Epoch=157.3] | Loss=0.00662 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=13.479 | 5209.6 samples/s | 81.4 steps/s
[Step=80500 Epoch=157.4] | Loss=0.00655 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.171 | L2-Norm(final)=13.482 | 7163.0 samples/s | 111.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=157.4] | Loss=0.00344 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=13.511 | 6272.5 samples/s | 98.0 steps/s
[Step=80550 Epoch=157.5] | Loss=0.00596 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=13.514 | 4190.9 samples/s | 65.5 steps/s
[Step=80600 Epoch=157.6] | Loss=0.00691 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=13.517 | 4603.1 samples/s | 71.9 steps/s
[Step=80650 Epoch=157.7] | Loss=0.00688 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=13.519 | 4662.7 samples/s | 72.9 steps/s
[Step=80700 Epoch=157.8] | Loss=0.00681 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.186 | L2-Norm(final)=13.522 | 4571.5 samples/s | 71.4 steps/s
[Step=80750 Epoch=157.9] | Loss=0.00667 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=13.524 | 4641.6 samples/s | 72.5 steps/s
[Step=80800 Epoch=158.0] | Loss=0.00660 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=13.526 | 4577.3 samples/s | 71.5 steps/s
[Step=80850 Epoch=158.1] | Loss=0.00657 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.189 | L2-Norm(final)=13.529 | 4625.8 samples/s | 72.3 steps/s
[Step=80900 Epoch=158.2] | Loss=0.00651 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.190 | L2-Norm(final)=13.531 | 4618.4 samples/s | 72.2 steps/s
[Step=80950 Epoch=158.3] | Loss=0.00644 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.191 | L2-Norm(final)=13.533 | 4648.8 samples/s | 72.6 steps/s
[Step=81000 Epoch=158.4] | Loss=0.00645 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.192 | L2-Norm(final)=13.536 | 6070.7 samples/s | 94.9 steps/s
[Step=81050 Epoch=158.5] | Loss=0.00631 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.193 | L2-Norm(final)=13.538 | 2429.3 samples/s | 38.0 steps/s
[Step=81100 Epoch=158.5] | Loss=0.00616 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.194 | L2-Norm(final)=13.540 | 4593.2 samples/s | 71.8 steps/s
[Step=81150 Epoch=158.6] | Loss=0.00600 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=13.542 | 4608.2 samples/s | 72.0 steps/s
[Step=81200 Epoch=158.7] | Loss=0.00593 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=13.545 | 4646.8 samples/s | 72.6 steps/s
[Step=81250 Epoch=158.8] | Loss=0.00596 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=13.547 | 4602.0 samples/s | 71.9 steps/s
[Step=81300 Epoch=158.9] | Loss=0.00588 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.196 | L2-Norm(final)=13.549 | 4658.6 samples/s | 72.8 steps/s
[Step=81350 Epoch=159.0] | Loss=0.00584 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.197 | L2-Norm(final)=13.551 | 4549.0 samples/s | 71.1 steps/s
[Step=81400 Epoch=159.1] | Loss=0.00581 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.198 | L2-Norm(final)=13.553 | 4680.3 samples/s | 73.1 steps/s
[Step=81450 Epoch=159.2] | Loss=0.00579 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.198 | L2-Norm(final)=13.555 | 4596.3 samples/s | 71.8 steps/s
[Step=81500 Epoch=159.3] | Loss=0.00575 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=13.557 | 5113.2 samples/s | 79.9 steps/s
[Step=81550 Epoch=159.4] | Loss=0.00566 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=13.560 | 2619.5 samples/s | 40.9 steps/s
[Step=81600 Epoch=159.5] | Loss=0.00561 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.199 | L2-Norm(final)=13.562 | 4619.5 samples/s | 72.2 steps/s
[Step=81650 Epoch=159.6] | Loss=0.00557 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=13.564 | 4649.7 samples/s | 72.7 steps/s
[Step=81700 Epoch=159.7] | Loss=0.00552 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.200 | L2-Norm(final)=13.566 | 4598.9 samples/s | 71.9 steps/s
[Step=81750 Epoch=159.8] | Loss=0.00553 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.201 | L2-Norm(final)=13.568 | 4636.9 samples/s | 72.5 steps/s
[Step=81800 Epoch=159.9] | Loss=0.00555 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=13.570 | 4595.9 samples/s | 71.8 steps/s
[Step=81850 Epoch=160.0] | Loss=0.00548 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=13.572 | 4646.9 samples/s | 72.6 steps/s
[Step=81900 Epoch=160.1] | Loss=0.00540 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=13.574 | 4623.8 samples/s | 72.2 steps/s
[Step=81950 Epoch=160.2] | Loss=0.00538 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=13.576 | 4637.5 samples/s | 72.5 steps/s
[Step=82000 Epoch=160.3] | Loss=0.00535 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.202 | L2-Norm(final)=13.578 | 4647.6 samples/s | 72.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step82000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=306.5] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=10.193 | 5895.8 samples/s | 92.1 steps/s
[Step=80050 Epoch=306.7] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=10.193 | 4506.1 samples/s | 70.4 steps/s
[Step=80100 Epoch=306.9] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=10.194 | 4995.4 samples/s | 78.1 steps/s
[Step=80150 Epoch=307.1] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=10.194 | 4914.9 samples/s | 76.8 steps/s
[Step=80200 Epoch=307.3] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=10.195 | 4868.0 samples/s | 76.1 steps/s
[Step=80250 Epoch=307.5] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.196 | 6808.8 samples/s | 106.4 steps/s
[Step=80300 Epoch=307.7] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.196 | 2473.1 samples/s | 38.6 steps/s
[Step=80350 Epoch=307.9] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.197 | 4918.0 samples/s | 76.8 steps/s
[Step=80400 Epoch=308.1] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=10.198 | 4938.7 samples/s | 77.2 steps/s
[Step=80450 Epoch=308.3] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=10.199 | 4858.7 samples/s | 75.9 steps/s
[Step=80500 Epoch=308.4] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=10.199 | 5664.7 samples/s | 88.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=308.5] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.103 | L2-Norm(final)=10.206 | 6246.7 samples/s | 97.6 steps/s
[Step=80550 Epoch=308.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.103 | L2-Norm(final)=10.207 | 3927.5 samples/s | 61.4 steps/s
[Step=80600 Epoch=308.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.102 | L2-Norm(final)=10.207 | 4358.2 samples/s | 68.1 steps/s
[Step=80650 Epoch=309.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.101 | L2-Norm(final)=10.208 | 4405.5 samples/s | 68.8 steps/s
[Step=80700 Epoch=309.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.101 | L2-Norm(final)=10.209 | 4502.0 samples/s | 70.3 steps/s
[Step=80750 Epoch=309.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.100 | L2-Norm(final)=10.210 | 5677.7 samples/s | 88.7 steps/s
[Step=80800 Epoch=309.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.210 | 2330.4 samples/s | 36.4 steps/s
[Step=80850 Epoch=309.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=10.211 | 4374.5 samples/s | 68.4 steps/s
[Step=80900 Epoch=310.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.098 | L2-Norm(final)=10.211 | 4421.8 samples/s | 69.1 steps/s
[Step=80950 Epoch=310.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.097 | L2-Norm(final)=10.212 | 4436.1 samples/s | 69.3 steps/s
[Step=81000 Epoch=310.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.096 | L2-Norm(final)=10.212 | 4842.9 samples/s | 75.7 steps/s
[Step=81050 Epoch=310.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.095 | L2-Norm(final)=10.213 | 2508.6 samples/s | 39.2 steps/s
[Step=81100 Epoch=310.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.094 | L2-Norm(final)=10.213 | 4378.1 samples/s | 68.4 steps/s
[Step=81150 Epoch=310.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.093 | L2-Norm(final)=10.214 | 4389.6 samples/s | 68.6 steps/s
[Step=81200 Epoch=311.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.214 | 4338.1 samples/s | 67.8 steps/s
[Step=81250 Epoch=311.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.215 | 4403.4 samples/s | 68.8 steps/s
[Step=81300 Epoch=311.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=10.215 | 2693.0 samples/s | 42.1 steps/s
[Step=81350 Epoch=311.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.089 | L2-Norm(final)=10.215 | 4351.5 samples/s | 68.0 steps/s
[Step=81400 Epoch=311.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=10.216 | 4389.5 samples/s | 68.6 steps/s
[Step=81450 Epoch=312.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.087 | L2-Norm(final)=10.216 | 4393.0 samples/s | 68.6 steps/s
[Step=81500 Epoch=312.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=10.217 | 4416.4 samples/s | 69.0 steps/s
[Step=81550 Epoch=312.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.084 | L2-Norm(final)=10.217 | 2659.2 samples/s | 41.6 steps/s
[Step=81600 Epoch=312.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.083 | L2-Norm(final)=10.218 | 4301.2 samples/s | 67.2 steps/s
[Step=81650 Epoch=312.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.082 | L2-Norm(final)=10.218 | 4329.0 samples/s | 67.6 steps/s
[Step=81700 Epoch=313.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=10.219 | 4319.5 samples/s | 67.5 steps/s
[Step=81750 Epoch=313.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.079 | L2-Norm(final)=10.219 | 4340.6 samples/s | 67.8 steps/s
[Step=81800 Epoch=313.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=10.220 | 6427.9 samples/s | 100.4 steps/s
[Step=81850 Epoch=313.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=10.220 | 2235.8 samples/s | 34.9 steps/s
[Step=81900 Epoch=313.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=10.220 | 4358.0 samples/s | 68.1 steps/s
[Step=81950 Epoch=314.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.074 | L2-Norm(final)=10.221 | 4513.5 samples/s | 70.5 steps/s
[Step=82000 Epoch=314.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.073 | L2-Norm(final)=10.221 | 4298.6 samples/s | 67.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step82000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=308.0] | Loss=0.00014 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.054 | L2-Norm(final)=10.059 | 6135.1 samples/s | 95.9 steps/s
[Step=80050 Epoch=308.1] | Loss=0.00005 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=10.065 | 4440.0 samples/s | 69.4 steps/s
[Step=80100 Epoch=308.3] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.061 | L2-Norm(final)=10.073 | 4866.4 samples/s | 76.0 steps/s
[Step=80150 Epoch=308.5] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.066 | L2-Norm(final)=10.081 | 4915.5 samples/s | 76.8 steps/s
[Step=80200 Epoch=308.7] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=10.087 | 4876.0 samples/s | 76.2 steps/s
[Step=80250 Epoch=308.9] | Loss=0.00004 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.071 | L2-Norm(final)=10.093 | 6973.8 samples/s | 109.0 steps/s
[Step=80300 Epoch=309.1] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.073 | L2-Norm(final)=10.099 | 2497.2 samples/s | 39.0 steps/s
[Step=80350 Epoch=309.3] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=10.104 | 4872.6 samples/s | 76.1 steps/s
[Step=80400 Epoch=309.5] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.077 | L2-Norm(final)=10.109 | 4715.2 samples/s | 73.7 steps/s
[Step=80450 Epoch=309.7] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=10.113 | 4934.7 samples/s | 77.1 steps/s
[Step=80500 Epoch=309.9] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.079 | L2-Norm(final)=10.118 | 5841.1 samples/s | 91.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=309.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.164 | 6703.8 samples/s | 104.7 steps/s
[Step=80550 Epoch=310.1] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.169 | 3797.8 samples/s | 59.3 steps/s
[Step=80600 Epoch=310.3] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.090 | L2-Norm(final)=10.173 | 4298.0 samples/s | 67.2 steps/s
[Step=80650 Epoch=310.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.088 | L2-Norm(final)=10.176 | 4406.0 samples/s | 68.8 steps/s
[Step=80700 Epoch=310.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=10.178 | 4404.6 samples/s | 68.8 steps/s
[Step=80750 Epoch=310.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.082 | L2-Norm(final)=10.180 | 5967.4 samples/s | 93.2 steps/s
[Step=80800 Epoch=311.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=10.183 | 2331.8 samples/s | 36.4 steps/s
[Step=80850 Epoch=311.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.075 | L2-Norm(final)=10.184 | 4296.2 samples/s | 67.1 steps/s
[Step=80900 Epoch=311.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.071 | L2-Norm(final)=10.186 | 4379.3 samples/s | 68.4 steps/s
[Step=80950 Epoch=311.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=10.188 | 4407.7 samples/s | 68.9 steps/s
[Step=81000 Epoch=311.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.063 | L2-Norm(final)=10.190 | 5124.8 samples/s | 80.1 steps/s
[Step=81050 Epoch=312.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.059 | L2-Norm(final)=10.191 | 2462.1 samples/s | 38.5 steps/s
[Step=81100 Epoch=312.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.055 | L2-Norm(final)=10.193 | 4380.7 samples/s | 68.4 steps/s
[Step=81150 Epoch=312.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.051 | L2-Norm(final)=10.194 | 4357.5 samples/s | 68.1 steps/s
[Step=81200 Epoch=312.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.196 | 4422.6 samples/s | 69.1 steps/s
[Step=81250 Epoch=312.8] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.042 | L2-Norm(final)=10.197 | 4452.3 samples/s | 69.6 steps/s
[Step=81300 Epoch=313.0] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.037 | L2-Norm(final)=10.199 | 2640.3 samples/s | 41.3 steps/s
[Step=81350 Epoch=313.1] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.200 | 4375.7 samples/s | 68.4 steps/s
[Step=81400 Epoch=313.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=10.202 | 4399.3 samples/s | 68.7 steps/s
[Step=81450 Epoch=313.5] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.024 | L2-Norm(final)=10.203 | 4415.4 samples/s | 69.0 steps/s
[Step=81500 Epoch=313.7] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.019 | L2-Norm(final)=10.204 | 4384.6 samples/s | 68.5 steps/s
[Step=81550 Epoch=313.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.014 | L2-Norm(final)=10.206 | 2675.8 samples/s | 41.8 steps/s
[Step=81600 Epoch=314.1] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.207 | 4440.8 samples/s | 69.4 steps/s
[Step=81650 Epoch=314.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.004 | L2-Norm(final)=10.209 | 4334.8 samples/s | 67.7 steps/s
[Step=81700 Epoch=314.5] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.999 | L2-Norm(final)=10.210 | 4369.1 samples/s | 68.3 steps/s
[Step=81750 Epoch=314.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.994 | L2-Norm(final)=10.212 | 4418.6 samples/s | 69.0 steps/s
[Step=81800 Epoch=314.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.989 | L2-Norm(final)=10.213 | 7152.6 samples/s | 111.8 steps/s
[Step=81850 Epoch=315.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.984 | L2-Norm(final)=10.215 | 2170.7 samples/s | 33.9 steps/s
[Step=81900 Epoch=315.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.979 | L2-Norm(final)=10.217 | 4486.2 samples/s | 70.1 steps/s
[Step=81950 Epoch=315.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.973 | L2-Norm(final)=10.218 | 4278.7 samples/s | 66.9 steps/s
[Step=82000 Epoch=315.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.968 | L2-Norm(final)=10.220 | 4371.3 samples/s | 68.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07576 | acc=0.9689 | tpr=0.9760 | fpr=0.0466 | 5157.7 samples/s | 20.1 steps/s
Avg test loss: 0.07727, Avg test acc: 0.96731, Avg tpr: 0.97441, Avg fpr: 0.04833, total FA: 377

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07768 | acc=0.9671 | tpr=0.9755 | fpr=0.0510 | 5520.6 samples/s | 21.6 steps/s
Avg test loss: 0.07941, Avg test acc: 0.96678, Avg tpr: 0.97494, Avg fpr: 0.05115, total FA: 399

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.47229 | acc=0.3099 | tpr=0.0056 | fpr=0.0292 | 5344.1 samples/s | 20.9 steps/s
Avg test loss: 5.47797, Avg test acc: 0.30832, Avg tpr: 0.00525, Avg fpr: 0.02512, total FA: 196

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.24848 | acc=0.3055 | tpr=0.0076 | fpr=0.0476 | 5239.6 samples/s | 20.5 steps/s
Avg test loss: 5.25327, Avg test acc: 0.30483, Avg tpr: 0.00810, Avg fpr: 0.04256, total FA: 332

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.64381 | acc=0.1296 | tpr=0.7168 | fpr=0.8809 | 5281.3 samples/s | 20.6 steps/s
[Step= 100] | Loss=5.62370 | acc=0.1302 | tpr=0.7036 | fpr=0.8805 | 7356.2 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.62109 | acc=0.1311 | tpr=0.7205 | fpr=0.8798 | 7571.7 samples/s | 29.6 steps/s
[Step= 200] | Loss=5.63127 | acc=0.1301 | tpr=0.7158 | fpr=0.8805 | 8062.7 samples/s | 31.5 steps/s
[Step= 250] | Loss=5.64044 | acc=0.1306 | tpr=0.7074 | fpr=0.8799 | 8264.3 samples/s | 32.3 steps/s
[Step= 300] | Loss=5.64303 | acc=0.1300 | tpr=0.7084 | fpr=0.8805 | 8000.1 samples/s | 31.3 steps/s
[Step= 350] | Loss=5.63245 | acc=0.1300 | tpr=0.7082 | fpr=0.8805 | 8261.1 samples/s | 32.3 steps/s
[Step= 400] | Loss=5.62403 | acc=0.1304 | tpr=0.7123 | fpr=0.8802 | 8279.1 samples/s | 32.3 steps/s
[Step= 450] | Loss=5.62618 | acc=0.1298 | tpr=0.7147 | fpr=0.8808 | 8125.3 samples/s | 31.7 steps/s
[Step= 500] | Loss=5.62599 | acc=0.1294 | tpr=0.7141 | fpr=0.8811 | 8072.7 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.62408 | acc=0.1295 | tpr=0.7095 | fpr=0.8811 | 14813.5 samples/s | 57.9 steps/s
Avg test loss: 5.62530, Avg test acc: 0.12945, Avg tpr: 0.70959, Avg fpr: 0.88109, total FA: 122338

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.13947 | acc=0.1334 | tpr=0.7434 | fpr=0.8776 | 5128.8 samples/s | 20.0 steps/s
[Step= 100] | Loss=6.12342 | acc=0.1328 | tpr=0.7335 | fpr=0.8784 | 7362.9 samples/s | 28.8 steps/s
[Step= 150] | Loss=6.11503 | acc=0.1332 | tpr=0.7435 | fpr=0.8780 | 8178.9 samples/s | 31.9 steps/s
[Step= 200] | Loss=6.12569 | acc=0.1329 | tpr=0.7399 | fpr=0.8781 | 8056.1 samples/s | 31.5 steps/s
[Step= 250] | Loss=6.13518 | acc=0.1334 | tpr=0.7336 | fpr=0.8775 | 7982.5 samples/s | 31.2 steps/s
[Step= 300] | Loss=6.13891 | acc=0.1333 | tpr=0.7338 | fpr=0.8776 | 8036.2 samples/s | 31.4 steps/s
[Step= 350] | Loss=6.12599 | acc=0.1334 | tpr=0.7314 | fpr=0.8775 | 8030.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=6.11750 | acc=0.1337 | tpr=0.7319 | fpr=0.8772 | 8326.0 samples/s | 32.5 steps/s
[Step= 450] | Loss=6.11795 | acc=0.1330 | tpr=0.7308 | fpr=0.8778 | 8358.6 samples/s | 32.7 steps/s
[Step= 500] | Loss=6.12002 | acc=0.1328 | tpr=0.7300 | fpr=0.8779 | 7864.4 samples/s | 30.7 steps/s
[Step= 550] | Loss=6.11765 | acc=0.1331 | tpr=0.7270 | fpr=0.8777 | 14492.2 samples/s | 56.6 steps/s
Avg test loss: 6.11926, Avg test acc: 0.13303, Avg tpr: 0.72702, Avg fpr: 0.87777, total FA: 121876

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11737 | acc=0.9802 | tpr=0.9425 | fpr=0.0191 | 5154.7 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.12348 | acc=0.9789 | tpr=0.9574 | fpr=0.0207 | 7530.4 samples/s | 29.4 steps/s
[Step= 150] | Loss=0.12838 | acc=0.9776 | tpr=0.9553 | fpr=0.0220 | 7679.5 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13025 | acc=0.9777 | tpr=0.9574 | fpr=0.0220 | 8113.8 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.12812 | acc=0.9780 | tpr=0.9598 | fpr=0.0217 | 8208.2 samples/s | 32.1 steps/s
[Step= 300] | Loss=0.13029 | acc=0.9774 | tpr=0.9564 | fpr=0.0222 | 7936.8 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.13086 | acc=0.9771 | tpr=0.9574 | fpr=0.0226 | 8292.8 samples/s | 32.4 steps/s
[Step= 400] | Loss=0.13220 | acc=0.9770 | tpr=0.9551 | fpr=0.0226 | 8067.0 samples/s | 31.5 steps/s
[Step= 450] | Loss=0.13495 | acc=0.9766 | tpr=0.9547 | fpr=0.0230 | 8140.5 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.13431 | acc=0.9766 | tpr=0.9546 | fpr=0.0230 | 7895.7 samples/s | 30.8 steps/s
[Step= 550] | Loss=0.13330 | acc=0.9768 | tpr=0.9542 | fpr=0.0228 | 14651.2 samples/s | 57.2 steps/s
Avg test loss: 0.13295, Avg test acc: 0.97678, Avg tpr: 0.95325, Avg fpr: 0.02279, total FA: 3165

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12369 | acc=0.9792 | tpr=0.9513 | fpr=0.0203 | 5395.7 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.12971 | acc=0.9782 | tpr=0.9595 | fpr=0.0214 | 7478.5 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.13515 | acc=0.9771 | tpr=0.9625 | fpr=0.0226 | 7337.4 samples/s | 28.7 steps/s
[Step= 200] | Loss=0.13718 | acc=0.9771 | tpr=0.9661 | fpr=0.0227 | 8107.4 samples/s | 31.7 steps/s
[Step= 250] | Loss=0.13474 | acc=0.9775 | tpr=0.9677 | fpr=0.0223 | 7878.0 samples/s | 30.8 steps/s
[Step= 300] | Loss=0.13706 | acc=0.9773 | tpr=0.9665 | fpr=0.0226 | 8670.5 samples/s | 33.9 steps/s
[Step= 350] | Loss=0.13797 | acc=0.9770 | tpr=0.9674 | fpr=0.0228 | 7906.5 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.13916 | acc=0.9769 | tpr=0.9655 | fpr=0.0229 | 8018.1 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.14213 | acc=0.9764 | tpr=0.9640 | fpr=0.0234 | 7873.3 samples/s | 30.8 steps/s
[Step= 500] | Loss=0.14136 | acc=0.9764 | tpr=0.9634 | fpr=0.0233 | 8183.1 samples/s | 32.0 steps/s
[Step= 550] | Loss=0.14010 | acc=0.9766 | tpr=0.9630 | fpr=0.0232 | 15055.5 samples/s | 58.8 steps/s
Avg test loss: 0.13974, Avg test acc: 0.97659, Avg tpr: 0.96236, Avg fpr: 0.02315, total FA: 3215

server round 41/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=159.9] | Loss=0.00978 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.836 | L2-Norm(final)=13.165 | 6458.5 samples/s | 100.9 steps/s
[Step=82050 Epoch=160.0] | Loss=0.00590 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.837 | L2-Norm(final)=13.168 | 4620.4 samples/s | 72.2 steps/s
[Step=82100 Epoch=160.1] | Loss=0.00561 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.837 | L2-Norm(final)=13.171 | 5131.5 samples/s | 80.2 steps/s
[Step=82150 Epoch=160.2] | Loss=0.00597 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.838 | L2-Norm(final)=13.174 | 5324.8 samples/s | 83.2 steps/s
[Step=82200 Epoch=160.3] | Loss=0.00605 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.839 | L2-Norm(final)=13.177 | 5050.8 samples/s | 78.9 steps/s
[Step=82250 Epoch=160.4] | Loss=0.00616 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.839 | L2-Norm(final)=13.180 | 5329.5 samples/s | 83.3 steps/s
[Step=82300 Epoch=160.5] | Loss=0.00615 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=13.183 | 5206.8 samples/s | 81.4 steps/s
[Step=82350 Epoch=160.6] | Loss=0.00619 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.840 | L2-Norm(final)=13.186 | 5146.8 samples/s | 80.4 steps/s
[Step=82400 Epoch=160.7] | Loss=0.00618 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.841 | L2-Norm(final)=13.189 | 5232.9 samples/s | 81.8 steps/s
[Step=82450 Epoch=160.8] | Loss=0.00622 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=13.192 | 5178.3 samples/s | 80.9 steps/s
[Step=82500 Epoch=160.9] | Loss=0.00614 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=13.195 | 6930.3 samples/s | 108.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=160.9] | Loss=0.00434 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.847 | L2-Norm(final)=13.224 | 6685.3 samples/s | 104.5 steps/s
[Step=82550 Epoch=161.0] | Loss=0.00687 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.848 | L2-Norm(final)=13.227 | 4033.4 samples/s | 63.0 steps/s
[Step=82600 Epoch=161.1] | Loss=0.00674 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.849 | L2-Norm(final)=13.230 | 4636.0 samples/s | 72.4 steps/s
[Step=82650 Epoch=161.2] | Loss=0.00665 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.850 | L2-Norm(final)=13.232 | 4699.1 samples/s | 73.4 steps/s
[Step=82700 Epoch=161.3] | Loss=0.00638 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.851 | L2-Norm(final)=13.235 | 4511.2 samples/s | 70.5 steps/s
[Step=82750 Epoch=161.4] | Loss=0.00657 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.853 | L2-Norm(final)=13.237 | 4651.4 samples/s | 72.7 steps/s
[Step=82800 Epoch=161.5] | Loss=0.00644 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.854 | L2-Norm(final)=13.240 | 4608.9 samples/s | 72.0 steps/s
[Step=82850 Epoch=161.6] | Loss=0.00650 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.855 | L2-Norm(final)=13.242 | 4646.3 samples/s | 72.6 steps/s
[Step=82900 Epoch=161.7] | Loss=0.00647 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.856 | L2-Norm(final)=13.245 | 4670.4 samples/s | 73.0 steps/s
[Step=82950 Epoch=161.8] | Loss=0.00648 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.857 | L2-Norm(final)=13.247 | 4561.1 samples/s | 71.3 steps/s
[Step=83000 Epoch=161.9] | Loss=0.00660 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.858 | L2-Norm(final)=13.250 | 5929.5 samples/s | 92.6 steps/s
[Step=83050 Epoch=162.0] | Loss=0.00642 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.859 | L2-Norm(final)=13.252 | 2438.6 samples/s | 38.1 steps/s
[Step=83100 Epoch=162.1] | Loss=0.00638 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.860 | L2-Norm(final)=13.255 | 4668.1 samples/s | 72.9 steps/s
[Step=83150 Epoch=162.2] | Loss=0.00640 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.860 | L2-Norm(final)=13.257 | 4560.9 samples/s | 71.3 steps/s
[Step=83200 Epoch=162.3] | Loss=0.00632 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.861 | L2-Norm(final)=13.260 | 4635.6 samples/s | 72.4 steps/s
[Step=83250 Epoch=162.4] | Loss=0.00626 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.862 | L2-Norm(final)=13.262 | 4605.7 samples/s | 72.0 steps/s
[Step=83300 Epoch=162.5] | Loss=0.00615 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.863 | L2-Norm(final)=13.264 | 4626.4 samples/s | 72.3 steps/s
[Step=83350 Epoch=162.6] | Loss=0.00617 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.863 | L2-Norm(final)=13.267 | 4626.7 samples/s | 72.3 steps/s
[Step=83400 Epoch=162.7] | Loss=0.00607 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.864 | L2-Norm(final)=13.269 | 4663.1 samples/s | 72.9 steps/s
[Step=83450 Epoch=162.8] | Loss=0.00606 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.864 | L2-Norm(final)=13.271 | 4680.1 samples/s | 73.1 steps/s
[Step=83500 Epoch=162.9] | Loss=0.00596 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.865 | L2-Norm(final)=13.273 | 4903.7 samples/s | 76.6 steps/s
[Step=83550 Epoch=163.0] | Loss=0.00586 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.865 | L2-Norm(final)=13.276 | 2675.7 samples/s | 41.8 steps/s
[Step=83600 Epoch=163.1] | Loss=0.00577 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=13.278 | 4584.0 samples/s | 71.6 steps/s
[Step=83650 Epoch=163.1] | Loss=0.00570 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.866 | L2-Norm(final)=13.280 | 4682.3 samples/s | 73.2 steps/s
[Step=83700 Epoch=163.2] | Loss=0.00569 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.867 | L2-Norm(final)=13.282 | 4641.6 samples/s | 72.5 steps/s
[Step=83750 Epoch=163.3] | Loss=0.00573 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.867 | L2-Norm(final)=13.284 | 4684.8 samples/s | 73.2 steps/s
[Step=83800 Epoch=163.4] | Loss=0.00571 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.286 | 4521.0 samples/s | 70.6 steps/s
[Step=83850 Epoch=163.5] | Loss=0.00570 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.288 | 4650.1 samples/s | 72.7 steps/s
[Step=83900 Epoch=163.6] | Loss=0.00565 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.290 | 4632.4 samples/s | 72.4 steps/s
[Step=83950 Epoch=163.7] | Loss=0.00567 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.292 | 4610.6 samples/s | 72.0 steps/s
[Step=84000 Epoch=163.8] | Loss=0.00562 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.868 | L2-Norm(final)=13.294 | 4650.5 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step84000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=160.3] | Loss=0.00183 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=13.637 | 6258.5 samples/s | 97.8 steps/s
[Step=82050 Epoch=160.4] | Loss=0.00845 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=13.640 | 4698.0 samples/s | 73.4 steps/s
[Step=82100 Epoch=160.5] | Loss=0.00744 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=13.643 | 5265.2 samples/s | 82.3 steps/s
[Step=82150 Epoch=160.6] | Loss=0.00669 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=13.646 | 5119.5 samples/s | 80.0 steps/s
[Step=82200 Epoch=160.7] | Loss=0.00631 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.158 | L2-Norm(final)=13.649 | 5196.4 samples/s | 81.2 steps/s
[Step=82250 Epoch=160.8] | Loss=0.00638 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.159 | L2-Norm(final)=13.652 | 5175.2 samples/s | 80.9 steps/s
[Step=82300 Epoch=160.9] | Loss=0.00610 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.160 | L2-Norm(final)=13.655 | 5328.4 samples/s | 83.3 steps/s
[Step=82350 Epoch=161.0] | Loss=0.00587 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.160 | L2-Norm(final)=13.658 | 5132.1 samples/s | 80.2 steps/s
[Step=82400 Epoch=161.1] | Loss=0.00591 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=13.661 | 5198.2 samples/s | 81.2 steps/s
[Step=82450 Epoch=161.2] | Loss=0.00591 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.161 | L2-Norm(final)=13.664 | 5202.3 samples/s | 81.3 steps/s
[Step=82500 Epoch=161.3] | Loss=0.00594 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.162 | L2-Norm(final)=13.667 | 7101.7 samples/s | 111.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=161.3] | Loss=0.00891 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.167 | L2-Norm(final)=13.697 | 6725.4 samples/s | 105.1 steps/s
[Step=82550 Epoch=161.4] | Loss=0.00619 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.168 | L2-Norm(final)=13.700 | 4065.4 samples/s | 63.5 steps/s
[Step=82600 Epoch=161.5] | Loss=0.00670 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.169 | L2-Norm(final)=13.702 | 4522.8 samples/s | 70.7 steps/s
[Step=82650 Epoch=161.6] | Loss=0.00660 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.170 | L2-Norm(final)=13.705 | 4565.2 samples/s | 71.3 steps/s
[Step=82700 Epoch=161.7] | Loss=0.00632 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.172 | L2-Norm(final)=13.708 | 4672.4 samples/s | 73.0 steps/s
[Step=82750 Epoch=161.8] | Loss=0.00658 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.173 | L2-Norm(final)=13.711 | 4666.8 samples/s | 72.9 steps/s
[Step=82800 Epoch=161.9] | Loss=0.00644 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.174 | L2-Norm(final)=13.714 | 4633.1 samples/s | 72.4 steps/s
[Step=82850 Epoch=162.0] | Loss=0.00637 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.176 | L2-Norm(final)=13.716 | 4465.4 samples/s | 69.8 steps/s
[Step=82900 Epoch=162.1] | Loss=0.00634 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.177 | L2-Norm(final)=13.719 | 4691.8 samples/s | 73.3 steps/s
[Step=82950 Epoch=162.2] | Loss=0.00634 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.178 | L2-Norm(final)=13.722 | 4577.4 samples/s | 71.5 steps/s
[Step=83000 Epoch=162.3] | Loss=0.00628 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.179 | L2-Norm(final)=13.724 | 6042.9 samples/s | 94.4 steps/s
[Step=83050 Epoch=162.4] | Loss=0.00615 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=13.727 | 2433.5 samples/s | 38.0 steps/s
[Step=83100 Epoch=162.5] | Loss=0.00599 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=13.729 | 4529.7 samples/s | 70.8 steps/s
[Step=83150 Epoch=162.6] | Loss=0.00593 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.181 | L2-Norm(final)=13.731 | 4741.2 samples/s | 74.1 steps/s
[Step=83200 Epoch=162.7] | Loss=0.00582 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.182 | L2-Norm(final)=13.734 | 4636.6 samples/s | 72.4 steps/s
[Step=83250 Epoch=162.8] | Loss=0.00583 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=13.736 | 4465.3 samples/s | 69.8 steps/s
[Step=83300 Epoch=162.8] | Loss=0.00585 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.183 | L2-Norm(final)=13.738 | 4648.7 samples/s | 72.6 steps/s
[Step=83350 Epoch=162.9] | Loss=0.00578 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.184 | L2-Norm(final)=13.740 | 4632.1 samples/s | 72.4 steps/s
[Step=83400 Epoch=163.0] | Loss=0.00571 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.184 | L2-Norm(final)=13.743 | 4592.7 samples/s | 71.8 steps/s
[Step=83450 Epoch=163.1] | Loss=0.00568 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.185 | L2-Norm(final)=13.745 | 4690.0 samples/s | 73.3 steps/s
[Step=83500 Epoch=163.2] | Loss=0.00568 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.185 | L2-Norm(final)=13.747 | 5064.0 samples/s | 79.1 steps/s
[Step=83550 Epoch=163.3] | Loss=0.00563 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=13.749 | 2625.9 samples/s | 41.0 steps/s
[Step=83600 Epoch=163.4] | Loss=0.00561 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=13.751 | 4631.0 samples/s | 72.4 steps/s
[Step=83650 Epoch=163.5] | Loss=0.00551 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.186 | L2-Norm(final)=13.753 | 4621.0 samples/s | 72.2 steps/s
[Step=83700 Epoch=163.6] | Loss=0.00545 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=13.756 | 4628.9 samples/s | 72.3 steps/s
[Step=83750 Epoch=163.7] | Loss=0.00539 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=13.758 | 4634.5 samples/s | 72.4 steps/s
[Step=83800 Epoch=163.8] | Loss=0.00538 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.187 | L2-Norm(final)=13.760 | 4568.3 samples/s | 71.4 steps/s
[Step=83850 Epoch=163.9] | Loss=0.00536 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.188 | L2-Norm(final)=13.762 | 4605.0 samples/s | 72.0 steps/s
[Step=83900 Epoch=164.0] | Loss=0.00538 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=13.764 | 4622.4 samples/s | 72.2 steps/s
[Step=83950 Epoch=164.1] | Loss=0.00535 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=13.766 | 4716.1 samples/s | 73.7 steps/s
[Step=84000 Epoch=164.2] | Loss=0.00536 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.188 | L2-Norm(final)=13.768 | 4551.9 samples/s | 71.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step84000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=314.2] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.043 | L2-Norm(final)=10.235 | 6281.0 samples/s | 98.1 steps/s
[Step=82050 Epoch=314.4] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=10.237 | 4352.8 samples/s | 68.0 steps/s
[Step=82100 Epoch=314.6] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=10.238 | 4971.6 samples/s | 77.7 steps/s
[Step=82150 Epoch=314.8] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=10.240 | 5121.1 samples/s | 80.0 steps/s
[Step=82200 Epoch=315.0] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=10.242 | 4652.1 samples/s | 72.7 steps/s
[Step=82250 Epoch=315.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.243 | 6762.9 samples/s | 105.7 steps/s
[Step=82300 Epoch=315.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.245 | 2484.7 samples/s | 38.8 steps/s
[Step=82350 Epoch=315.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=10.246 | 4795.4 samples/s | 74.9 steps/s
[Step=82400 Epoch=315.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=10.248 | 4955.0 samples/s | 77.4 steps/s
[Step=82450 Epoch=315.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.047 | L2-Norm(final)=10.249 | 4831.4 samples/s | 75.5 steps/s
[Step=82500 Epoch=316.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.048 | L2-Norm(final)=10.251 | 5675.6 samples/s | 88.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=316.1] | Loss=0.00002 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.051 | L2-Norm(final)=10.267 | 6260.5 samples/s | 97.8 steps/s
[Step=82550 Epoch=316.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.050 | L2-Norm(final)=10.268 | 3904.4 samples/s | 61.0 steps/s
[Step=82600 Epoch=316.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.048 | L2-Norm(final)=10.269 | 4355.6 samples/s | 68.1 steps/s
[Step=82650 Epoch=316.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.046 | L2-Norm(final)=10.270 | 4498.1 samples/s | 70.3 steps/s
[Step=82700 Epoch=316.9] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.044 | L2-Norm(final)=10.272 | 4298.0 samples/s | 67.2 steps/s
[Step=82750 Epoch=317.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.042 | L2-Norm(final)=10.273 | 5861.8 samples/s | 91.6 steps/s
[Step=82800 Epoch=317.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.040 | L2-Norm(final)=10.274 | 2323.6 samples/s | 36.3 steps/s
[Step=82850 Epoch=317.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.038 | L2-Norm(final)=10.275 | 4363.8 samples/s | 68.2 steps/s
[Step=82900 Epoch=317.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.036 | L2-Norm(final)=10.277 | 4364.7 samples/s | 68.2 steps/s
[Step=82950 Epoch=317.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.034 | L2-Norm(final)=10.278 | 4420.4 samples/s | 69.1 steps/s
[Step=83000 Epoch=318.0] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.031 | L2-Norm(final)=10.279 | 4926.2 samples/s | 77.0 steps/s
[Step=83050 Epoch=318.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.029 | L2-Norm(final)=10.280 | 2498.1 samples/s | 39.0 steps/s
[Step=83100 Epoch=318.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.026 | L2-Norm(final)=10.281 | 4507.5 samples/s | 70.4 steps/s
[Step=83150 Epoch=318.6] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.024 | L2-Norm(final)=10.282 | 4328.1 samples/s | 67.6 steps/s
[Step=83200 Epoch=318.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.021 | L2-Norm(final)=10.283 | 4381.6 samples/s | 68.5 steps/s
[Step=83250 Epoch=319.0] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.018 | L2-Norm(final)=10.284 | 4349.8 samples/s | 68.0 steps/s
[Step=83300 Epoch=319.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.016 | L2-Norm(final)=10.285 | 2715.3 samples/s | 42.4 steps/s
[Step=83350 Epoch=319.4] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=10.285 | 4325.4 samples/s | 67.6 steps/s
[Step=83400 Epoch=319.6] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.010 | L2-Norm(final)=10.286 | 4360.2 samples/s | 68.1 steps/s
[Step=83450 Epoch=319.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.007 | L2-Norm(final)=10.287 | 4434.7 samples/s | 69.3 steps/s
[Step=83500 Epoch=319.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.004 | L2-Norm(final)=10.288 | 4410.9 samples/s | 68.9 steps/s
[Step=83550 Epoch=320.1] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=10.289 | 2664.7 samples/s | 41.6 steps/s
[Step=83600 Epoch=320.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.998 | L2-Norm(final)=10.290 | 4405.9 samples/s | 68.8 steps/s
[Step=83650 Epoch=320.5] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.995 | L2-Norm(final)=10.291 | 4383.4 samples/s | 68.5 steps/s
[Step=83700 Epoch=320.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.992 | L2-Norm(final)=10.292 | 4388.8 samples/s | 68.6 steps/s
[Step=83750 Epoch=320.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.989 | L2-Norm(final)=10.293 | 4390.4 samples/s | 68.6 steps/s
[Step=83800 Epoch=321.1] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.986 | L2-Norm(final)=10.294 | 6501.4 samples/s | 101.6 steps/s
[Step=83850 Epoch=321.3] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.983 | L2-Norm(final)=10.295 | 2237.6 samples/s | 35.0 steps/s
[Step=83900 Epoch=321.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.979 | L2-Norm(final)=10.296 | 4393.2 samples/s | 68.6 steps/s
[Step=83950 Epoch=321.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.976 | L2-Norm(final)=10.297 | 4361.3 samples/s | 68.1 steps/s
[Step=84000 Epoch=321.9] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.973 | L2-Norm(final)=10.297 | 4444.6 samples/s | 69.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step84000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=315.7] | Loss=0.00003 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.003 | L2-Norm(final)=10.268 | 6603.4 samples/s | 103.2 steps/s
[Step=82050 Epoch=315.8] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.003 | L2-Norm(final)=10.275 | 4205.6 samples/s | 65.7 steps/s
[Step=82100 Epoch=316.0] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.005 | L2-Norm(final)=10.284 | 4861.1 samples/s | 76.0 steps/s
[Step=82150 Epoch=316.2] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.293 | 4899.5 samples/s | 76.6 steps/s
[Step=82200 Epoch=316.4] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.012 | L2-Norm(final)=10.301 | 4933.6 samples/s | 77.1 steps/s
[Step=82250 Epoch=316.6] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.013 | L2-Norm(final)=10.308 | 6856.9 samples/s | 107.1 steps/s
[Step=82300 Epoch=316.8] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.015 | L2-Norm(final)=10.315 | 2442.4 samples/s | 38.2 steps/s
[Step=82350 Epoch=317.0] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.016 | L2-Norm(final)=10.321 | 4871.7 samples/s | 76.1 steps/s
[Step=82400 Epoch=317.2] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.018 | L2-Norm(final)=10.328 | 4956.3 samples/s | 77.4 steps/s
[Step=82450 Epoch=317.4] | Loss=0.00002 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.019 | L2-Norm(final)=10.334 | 4957.3 samples/s | 77.5 steps/s
[Step=82500 Epoch=317.6] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.020 | L2-Norm(final)=10.340 | 5717.6 samples/s | 89.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=317.6] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.028 | L2-Norm(final)=10.400 | 5895.7 samples/s | 92.1 steps/s
[Step=82550 Epoch=317.8] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.024 | L2-Norm(final)=10.405 | 4065.6 samples/s | 63.5 steps/s
[Step=82600 Epoch=318.0] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.017 | L2-Norm(final)=10.409 | 4371.4 samples/s | 68.3 steps/s
[Step=82650 Epoch=318.2] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.413 | 4434.0 samples/s | 69.3 steps/s
[Step=82700 Epoch=318.3] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.001 | L2-Norm(final)=10.416 | 4278.8 samples/s | 66.9 steps/s
[Step=82750 Epoch=318.5] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.993 | L2-Norm(final)=10.419 | 5965.7 samples/s | 93.2 steps/s
[Step=82800 Epoch=318.7] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.984 | L2-Norm(final)=10.423 | 2315.9 samples/s | 36.2 steps/s
[Step=82850 Epoch=318.9] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.976 | L2-Norm(final)=10.425 | 4477.1 samples/s | 70.0 steps/s
[Step=82900 Epoch=319.1] | Loss=0.00001 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.966 | L2-Norm(final)=10.428 | 4446.8 samples/s | 69.5 steps/s
[Step=82950 Epoch=319.3] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.957 | L2-Norm(final)=10.431 | 4379.1 samples/s | 68.4 steps/s
[Step=83000 Epoch=319.5] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.948 | L2-Norm(final)=10.433 | 4938.2 samples/s | 77.2 steps/s
[Step=83050 Epoch=319.7] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.938 | L2-Norm(final)=10.436 | 2473.2 samples/s | 38.6 steps/s
[Step=83100 Epoch=319.9] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.929 | L2-Norm(final)=10.438 | 4388.9 samples/s | 68.6 steps/s
[Step=83150 Epoch=320.1] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.919 | L2-Norm(final)=10.440 | 4378.8 samples/s | 68.4 steps/s
[Step=83200 Epoch=320.3] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.909 | L2-Norm(final)=10.443 | 4402.3 samples/s | 68.8 steps/s
[Step=83250 Epoch=320.5] | Loss=0.00000 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.899 | L2-Norm(final)=10.445 | 4491.9 samples/s | 70.2 steps/s
[Step=83300 Epoch=320.7] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.889 | L2-Norm(final)=10.448 | 2644.0 samples/s | 41.3 steps/s
[Step=83350 Epoch=320.8] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.879 | L2-Norm(final)=10.450 | 4515.9 samples/s | 70.6 steps/s
[Step=83400 Epoch=321.0] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.869 | L2-Norm(final)=10.453 | 4289.3 samples/s | 67.0 steps/s
[Step=83450 Epoch=321.2] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.858 | L2-Norm(final)=10.455 | 4444.6 samples/s | 69.4 steps/s
[Step=83500 Epoch=321.4] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.848 | L2-Norm(final)=10.458 | 4343.6 samples/s | 67.9 steps/s
[Step=83550 Epoch=321.6] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.838 | L2-Norm(final)=10.461 | 2680.2 samples/s | 41.9 steps/s
[Step=83600 Epoch=321.8] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.827 | L2-Norm(final)=10.463 | 4412.6 samples/s | 68.9 steps/s
[Step=83650 Epoch=322.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.816 | L2-Norm(final)=10.466 | 4385.2 samples/s | 68.5 steps/s
[Step=83700 Epoch=322.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=10.469 | 4427.4 samples/s | 69.2 steps/s
[Step=83750 Epoch=322.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.795 | L2-Norm(final)=10.472 | 4441.5 samples/s | 69.4 steps/s
[Step=83800 Epoch=322.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.784 | L2-Norm(final)=10.475 | 6928.1 samples/s | 108.3 steps/s
[Step=83850 Epoch=322.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.773 | L2-Norm(final)=10.478 | 2165.3 samples/s | 33.8 steps/s
[Step=83900 Epoch=323.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.763 | L2-Norm(final)=10.481 | 4366.7 samples/s | 68.2 steps/s
[Step=83950 Epoch=323.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.752 | L2-Norm(final)=10.484 | 4363.5 samples/s | 68.2 steps/s
[Step=84000 Epoch=323.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.741 | L2-Norm(final)=10.487 | 4397.1 samples/s | 68.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07631 | acc=0.9675 | tpr=0.9766 | fpr=0.0523 | 5178.8 samples/s | 20.2 steps/s
Avg test loss: 0.07824, Avg test acc: 0.96634, Avg tpr: 0.97529, Avg fpr: 0.05333, total FA: 416

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07912 | acc=0.9673 | tpr=0.9768 | fpr=0.0533 | 5320.2 samples/s | 20.8 steps/s
Avg test loss: 0.08065, Avg test acc: 0.96710, Avg tpr: 0.97604, Avg fpr: 0.05256, total FA: 410

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.54676 | acc=0.3109 | tpr=0.0046 | fpr=0.0240 | 5034.8 samples/s | 19.7 steps/s
Avg test loss: 5.55378, Avg test acc: 0.30876, Avg tpr: 0.00425, Avg fpr: 0.02154, total FA: 168

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.33059 | acc=0.3088 | tpr=0.0064 | fpr=0.0347 | 5296.5 samples/s | 20.7 steps/s
Avg test loss: 5.33437, Avg test acc: 0.30696, Avg tpr: 0.00659, Avg fpr: 0.03243, total FA: 253

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.73216 | acc=0.1297 | tpr=0.7434 | fpr=0.8813 | 5401.8 samples/s | 21.1 steps/s
[Step= 100] | Loss=5.70832 | acc=0.1306 | tpr=0.7292 | fpr=0.8806 | 7101.5 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.70751 | acc=0.1318 | tpr=0.7450 | fpr=0.8795 | 7592.8 samples/s | 29.7 steps/s
[Step= 200] | Loss=5.71905 | acc=0.1307 | tpr=0.7344 | fpr=0.8802 | 8326.4 samples/s | 32.5 steps/s
[Step= 250] | Loss=5.72892 | acc=0.1309 | tpr=0.7223 | fpr=0.8799 | 8182.6 samples/s | 32.0 steps/s
[Step= 300] | Loss=5.73158 | acc=0.1302 | tpr=0.7244 | fpr=0.8806 | 8058.4 samples/s | 31.5 steps/s
[Step= 350] | Loss=5.72104 | acc=0.1302 | tpr=0.7220 | fpr=0.8805 | 8238.7 samples/s | 32.2 steps/s
[Step= 400] | Loss=5.71247 | acc=0.1305 | tpr=0.7259 | fpr=0.8804 | 8114.2 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.71513 | acc=0.1300 | tpr=0.7283 | fpr=0.8808 | 7993.0 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.71472 | acc=0.1296 | tpr=0.7269 | fpr=0.8811 | 8278.9 samples/s | 32.3 steps/s
[Step= 550] | Loss=5.71287 | acc=0.1296 | tpr=0.7230 | fpr=0.8812 | 14168.8 samples/s | 55.3 steps/s
Avg test loss: 5.71433, Avg test acc: 0.12954, Avg tpr: 0.72306, Avg fpr: 0.88124, total FA: 122359

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=6.37240 | acc=0.1314 | tpr=0.7345 | fpr=0.8794 | 5130.1 samples/s | 20.0 steps/s
[Step= 100] | Loss=6.35441 | acc=0.1305 | tpr=0.7313 | fpr=0.8807 | 7238.7 samples/s | 28.3 steps/s
[Step= 150] | Loss=6.34419 | acc=0.1311 | tpr=0.7435 | fpr=0.8802 | 8037.1 samples/s | 31.4 steps/s
[Step= 200] | Loss=6.35444 | acc=0.1304 | tpr=0.7421 | fpr=0.8808 | 8012.9 samples/s | 31.3 steps/s
[Step= 250] | Loss=6.36495 | acc=0.1310 | tpr=0.7362 | fpr=0.8800 | 8465.2 samples/s | 33.1 steps/s
[Step= 300] | Loss=6.36895 | acc=0.1307 | tpr=0.7345 | fpr=0.8803 | 7956.0 samples/s | 31.1 steps/s
[Step= 350] | Loss=6.35477 | acc=0.1309 | tpr=0.7301 | fpr=0.8799 | 8182.9 samples/s | 32.0 steps/s
[Step= 400] | Loss=6.34603 | acc=0.1313 | tpr=0.7303 | fpr=0.8796 | 8177.9 samples/s | 31.9 steps/s
[Step= 450] | Loss=6.34631 | acc=0.1308 | tpr=0.7303 | fpr=0.8801 | 8432.9 samples/s | 32.9 steps/s
[Step= 500] | Loss=6.34835 | acc=0.1307 | tpr=0.7291 | fpr=0.8801 | 7912.6 samples/s | 30.9 steps/s
[Step= 550] | Loss=6.34610 | acc=0.1309 | tpr=0.7262 | fpr=0.8799 | 14299.8 samples/s | 55.9 steps/s
Avg test loss: 6.34770, Avg test acc: 0.13091, Avg tpr: 0.72623, Avg fpr: 0.87991, total FA: 122174

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11577 | acc=0.9803 | tpr=0.9513 | fpr=0.0192 | 5164.2 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.12188 | acc=0.9790 | tpr=0.9616 | fpr=0.0207 | 7744.0 samples/s | 30.3 steps/s
[Step= 150] | Loss=0.12674 | acc=0.9778 | tpr=0.9597 | fpr=0.0218 | 7644.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.12862 | acc=0.9779 | tpr=0.9607 | fpr=0.0218 | 7939.9 samples/s | 31.0 steps/s
[Step= 250] | Loss=0.12659 | acc=0.9782 | tpr=0.9624 | fpr=0.0215 | 8100.3 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.12869 | acc=0.9776 | tpr=0.9600 | fpr=0.0221 | 7939.3 samples/s | 31.0 steps/s
[Step= 350] | Loss=0.12930 | acc=0.9773 | tpr=0.9612 | fpr=0.0224 | 8368.0 samples/s | 32.7 steps/s
[Step= 400] | Loss=0.13057 | acc=0.9772 | tpr=0.9584 | fpr=0.0225 | 8249.8 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.13327 | acc=0.9768 | tpr=0.9581 | fpr=0.0228 | 8037.8 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.13262 | acc=0.9769 | tpr=0.9573 | fpr=0.0228 | 7948.0 samples/s | 31.0 steps/s
[Step= 550] | Loss=0.13162 | acc=0.9770 | tpr=0.9566 | fpr=0.0227 | 14786.4 samples/s | 57.8 steps/s
Avg test loss: 0.13127, Avg test acc: 0.97698, Avg tpr: 0.95563, Avg fpr: 0.02264, total FA: 3143

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11896 | acc=0.9797 | tpr=0.9469 | fpr=0.0197 | 5332.1 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.12450 | acc=0.9787 | tpr=0.9574 | fpr=0.0209 | 6997.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.12993 | acc=0.9779 | tpr=0.9611 | fpr=0.0218 | 8302.3 samples/s | 32.4 steps/s
[Step= 200] | Loss=0.13196 | acc=0.9778 | tpr=0.9617 | fpr=0.0220 | 8274.0 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.12961 | acc=0.9781 | tpr=0.9633 | fpr=0.0216 | 8058.8 samples/s | 31.5 steps/s
[Step= 300] | Loss=0.13195 | acc=0.9777 | tpr=0.9629 | fpr=0.0220 | 7807.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=0.13275 | acc=0.9775 | tpr=0.9643 | fpr=0.0223 | 8162.0 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.13387 | acc=0.9773 | tpr=0.9617 | fpr=0.0224 | 8176.7 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.13673 | acc=0.9768 | tpr=0.9611 | fpr=0.0229 | 8094.8 samples/s | 31.6 steps/s
[Step= 500] | Loss=0.13597 | acc=0.9769 | tpr=0.9617 | fpr=0.0229 | 8127.9 samples/s | 31.7 steps/s
[Step= 550] | Loss=0.13476 | acc=0.9770 | tpr=0.9610 | fpr=0.0227 | 15112.1 samples/s | 59.0 steps/s
Avg test loss: 0.13443, Avg test acc: 0.97704, Avg tpr: 0.96038, Avg fpr: 0.02266, total FA: 3146

server round 42/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=163.8] | Loss=0.00472 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=13.354 | 6708.5 samples/s | 104.8 steps/s
[Step=84050 Epoch=163.9] | Loss=0.00707 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=13.356 | 4458.2 samples/s | 69.7 steps/s
[Step=84100 Epoch=164.0] | Loss=0.00722 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.775 | L2-Norm(final)=13.359 | 5181.2 samples/s | 81.0 steps/s
[Step=84150 Epoch=164.1] | Loss=0.00711 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.775 | L2-Norm(final)=13.363 | 5194.1 samples/s | 81.2 steps/s
[Step=84200 Epoch=164.2] | Loss=0.00748 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.776 | L2-Norm(final)=13.366 | 5190.0 samples/s | 81.1 steps/s
[Step=84250 Epoch=164.3] | Loss=0.00757 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.777 | L2-Norm(final)=13.369 | 5196.1 samples/s | 81.2 steps/s
[Step=84300 Epoch=164.4] | Loss=0.00763 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.778 | L2-Norm(final)=13.372 | 5282.3 samples/s | 82.5 steps/s
[Step=84350 Epoch=164.5] | Loss=0.00749 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.779 | L2-Norm(final)=13.375 | 5158.7 samples/s | 80.6 steps/s
[Step=84400 Epoch=164.6] | Loss=0.00732 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.780 | L2-Norm(final)=13.378 | 5182.4 samples/s | 81.0 steps/s
[Step=84450 Epoch=164.7] | Loss=0.00723 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.780 | L2-Norm(final)=13.381 | 5291.3 samples/s | 82.7 steps/s
[Step=84500 Epoch=164.8] | Loss=0.00727 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.781 | L2-Norm(final)=13.384 | 6875.0 samples/s | 107.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=164.8] | Loss=0.01408 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.788 | L2-Norm(final)=13.414 | 5877.9 samples/s | 91.8 steps/s
[Step=84550 Epoch=164.9] | Loss=0.00715 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.791 | L2-Norm(final)=13.417 | 4429.5 samples/s | 69.2 steps/s
[Step=84600 Epoch=165.0] | Loss=0.00685 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.792 | L2-Norm(final)=13.420 | 4593.1 samples/s | 71.8 steps/s
[Step=84650 Epoch=165.1] | Loss=0.00743 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.794 | L2-Norm(final)=13.423 | 4668.2 samples/s | 72.9 steps/s
[Step=84700 Epoch=165.2] | Loss=0.00738 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=13.426 | 4575.4 samples/s | 71.5 steps/s
[Step=84750 Epoch=165.3] | Loss=0.00715 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.797 | L2-Norm(final)=13.428 | 4679.8 samples/s | 73.1 steps/s
[Step=84800 Epoch=165.4] | Loss=0.00731 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.799 | L2-Norm(final)=13.431 | 4575.2 samples/s | 71.5 steps/s
[Step=84850 Epoch=165.5] | Loss=0.00734 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.800 | L2-Norm(final)=13.434 | 4580.0 samples/s | 71.6 steps/s
[Step=84900 Epoch=165.6] | Loss=0.00716 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.802 | L2-Norm(final)=13.437 | 4678.6 samples/s | 73.1 steps/s
[Step=84950 Epoch=165.7] | Loss=0.00707 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.803 | L2-Norm(final)=13.439 | 4653.5 samples/s | 72.7 steps/s
[Step=85000 Epoch=165.8] | Loss=0.00700 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.804 | L2-Norm(final)=13.442 | 5885.2 samples/s | 92.0 steps/s
[Step=85050 Epoch=165.9] | Loss=0.00687 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.805 | L2-Norm(final)=13.445 | 2440.8 samples/s | 38.1 steps/s
[Step=85100 Epoch=166.0] | Loss=0.00669 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.806 | L2-Norm(final)=13.447 | 4619.2 samples/s | 72.2 steps/s
[Step=85150 Epoch=166.1] | Loss=0.00659 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=13.449 | 4594.3 samples/s | 71.8 steps/s
[Step=85200 Epoch=166.2] | Loss=0.00651 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.808 | L2-Norm(final)=13.452 | 4659.9 samples/s | 72.8 steps/s
[Step=85250 Epoch=166.3] | Loss=0.00644 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=13.454 | 4552.0 samples/s | 71.1 steps/s
[Step=85300 Epoch=166.4] | Loss=0.00634 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.809 | L2-Norm(final)=13.456 | 4623.2 samples/s | 72.2 steps/s
[Step=85350 Epoch=166.5] | Loss=0.00625 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.810 | L2-Norm(final)=13.459 | 4646.5 samples/s | 72.6 steps/s
[Step=85400 Epoch=166.6] | Loss=0.00623 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.811 | L2-Norm(final)=13.461 | 4628.6 samples/s | 72.3 steps/s
[Step=85450 Epoch=166.7] | Loss=0.00622 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.811 | L2-Norm(final)=13.463 | 4642.1 samples/s | 72.5 steps/s
[Step=85500 Epoch=166.8] | Loss=0.00626 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.812 | L2-Norm(final)=13.465 | 4951.2 samples/s | 77.4 steps/s
[Step=85550 Epoch=166.9] | Loss=0.00626 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.813 | L2-Norm(final)=13.467 | 2660.5 samples/s | 41.6 steps/s
[Step=85600 Epoch=167.0] | Loss=0.00618 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.813 | L2-Norm(final)=13.470 | 4599.3 samples/s | 71.9 steps/s
[Step=85650 Epoch=167.1] | Loss=0.00615 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.814 | L2-Norm(final)=13.472 | 4609.6 samples/s | 72.0 steps/s
[Step=85700 Epoch=167.1] | Loss=0.00604 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.814 | L2-Norm(final)=13.474 | 4648.4 samples/s | 72.6 steps/s
[Step=85750 Epoch=167.2] | Loss=0.00596 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=13.476 | 4682.9 samples/s | 73.2 steps/s
[Step=85800 Epoch=167.3] | Loss=0.00590 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.815 | L2-Norm(final)=13.478 | 4686.9 samples/s | 73.2 steps/s
[Step=85850 Epoch=167.4] | Loss=0.00591 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=13.480 | 4492.3 samples/s | 70.2 steps/s
[Step=85900 Epoch=167.5] | Loss=0.00591 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.816 | L2-Norm(final)=13.482 | 4606.9 samples/s | 72.0 steps/s
[Step=85950 Epoch=167.6] | Loss=0.00589 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.817 | L2-Norm(final)=13.484 | 4706.7 samples/s | 73.5 steps/s
[Step=86000 Epoch=167.7] | Loss=0.00585 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.817 | L2-Norm(final)=13.486 | 4597.5 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step86000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=164.2] | Loss=0.01419 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.092 | L2-Norm(final)=13.827 | 7109.6 samples/s | 111.1 steps/s
[Step=84050 Epoch=164.3] | Loss=0.00738 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=13.830 | 4491.5 samples/s | 70.2 steps/s
[Step=84100 Epoch=164.4] | Loss=0.00718 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.093 | L2-Norm(final)=13.834 | 5316.5 samples/s | 83.1 steps/s
[Step=84150 Epoch=164.5] | Loss=0.00739 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.094 | L2-Norm(final)=13.837 | 5092.2 samples/s | 79.6 steps/s
[Step=84200 Epoch=164.6] | Loss=0.00725 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=13.841 | 5165.5 samples/s | 80.7 steps/s
[Step=84250 Epoch=164.7] | Loss=0.00700 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.096 | L2-Norm(final)=13.845 | 5290.5 samples/s | 82.7 steps/s
[Step=84300 Epoch=164.8] | Loss=0.00691 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.097 | L2-Norm(final)=13.848 | 5229.1 samples/s | 81.7 steps/s
[Step=84350 Epoch=164.9] | Loss=0.00696 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.098 | L2-Norm(final)=13.852 | 5082.2 samples/s | 79.4 steps/s
[Step=84400 Epoch=165.0] | Loss=0.00687 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.099 | L2-Norm(final)=13.855 | 5370.4 samples/s | 83.9 steps/s
[Step=84450 Epoch=165.1] | Loss=0.00706 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.100 | L2-Norm(final)=13.859 | 5070.4 samples/s | 79.2 steps/s
[Step=84500 Epoch=165.2] | Loss=0.00700 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.101 | L2-Norm(final)=13.862 | 7106.2 samples/s | 111.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=165.2] | Loss=0.00918 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.111 | L2-Norm(final)=13.895 | 6076.9 samples/s | 95.0 steps/s
[Step=84550 Epoch=165.3] | Loss=0.00707 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=13.898 | 4298.9 samples/s | 67.2 steps/s
[Step=84600 Epoch=165.4] | Loss=0.00702 | Reg=0.00228 | acc=0.9844 | L2-Norm=15.114 | L2-Norm(final)=13.901 | 4644.0 samples/s | 72.6 steps/s
[Step=84650 Epoch=165.5] | Loss=0.00745 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.116 | L2-Norm(final)=13.904 | 4658.1 samples/s | 72.8 steps/s
[Step=84700 Epoch=165.6] | Loss=0.00725 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.117 | L2-Norm(final)=13.907 | 4548.6 samples/s | 71.1 steps/s
[Step=84750 Epoch=165.7] | Loss=0.00724 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.119 | L2-Norm(final)=13.910 | 4703.0 samples/s | 73.5 steps/s
[Step=84800 Epoch=165.8] | Loss=0.00718 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.120 | L2-Norm(final)=13.912 | 4560.1 samples/s | 71.3 steps/s
[Step=84850 Epoch=165.9] | Loss=0.00703 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.122 | L2-Norm(final)=13.915 | 4693.4 samples/s | 73.3 steps/s
[Step=84900 Epoch=166.0] | Loss=0.00692 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=13.918 | 4587.9 samples/s | 71.7 steps/s
[Step=84950 Epoch=166.1] | Loss=0.00671 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.124 | L2-Norm(final)=13.920 | 4625.5 samples/s | 72.3 steps/s
[Step=85000 Epoch=166.2] | Loss=0.00681 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.125 | L2-Norm(final)=13.923 | 6058.6 samples/s | 94.7 steps/s
[Step=85050 Epoch=166.3] | Loss=0.00664 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.126 | L2-Norm(final)=13.925 | 2405.0 samples/s | 37.6 steps/s
[Step=85100 Epoch=166.4] | Loss=0.00645 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=13.928 | 4731.4 samples/s | 73.9 steps/s
[Step=85150 Epoch=166.5] | Loss=0.00643 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=13.930 | 4479.6 samples/s | 70.0 steps/s
[Step=85200 Epoch=166.6] | Loss=0.00627 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.128 | L2-Norm(final)=13.932 | 4611.8 samples/s | 72.1 steps/s
[Step=85250 Epoch=166.7] | Loss=0.00618 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.129 | L2-Norm(final)=13.934 | 4682.3 samples/s | 73.2 steps/s
[Step=85300 Epoch=166.8] | Loss=0.00614 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.130 | L2-Norm(final)=13.937 | 4609.0 samples/s | 72.0 steps/s
[Step=85350 Epoch=166.9] | Loss=0.00614 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.130 | L2-Norm(final)=13.939 | 4621.2 samples/s | 72.2 steps/s
[Step=85400 Epoch=167.0] | Loss=0.00608 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=13.941 | 4689.4 samples/s | 73.3 steps/s
[Step=85450 Epoch=167.1] | Loss=0.00613 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=13.943 | 4565.0 samples/s | 71.3 steps/s
[Step=85500 Epoch=167.2] | Loss=0.00605 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=13.945 | 5104.3 samples/s | 79.8 steps/s
[Step=85550 Epoch=167.2] | Loss=0.00597 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.132 | L2-Norm(final)=13.948 | 2646.5 samples/s | 41.4 steps/s
[Step=85600 Epoch=167.3] | Loss=0.00590 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=13.950 | 4538.2 samples/s | 70.9 steps/s
[Step=85650 Epoch=167.4] | Loss=0.00582 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.133 | L2-Norm(final)=13.952 | 4659.3 samples/s | 72.8 steps/s
[Step=85700 Epoch=167.5] | Loss=0.00575 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=13.954 | 4659.2 samples/s | 72.8 steps/s
[Step=85750 Epoch=167.6] | Loss=0.00576 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.134 | L2-Norm(final)=13.956 | 4582.2 samples/s | 71.6 steps/s
[Step=85800 Epoch=167.7] | Loss=0.00576 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=13.958 | 4689.5 samples/s | 73.3 steps/s
[Step=85850 Epoch=167.8] | Loss=0.00569 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=13.960 | 4591.4 samples/s | 71.7 steps/s
[Step=85900 Epoch=167.9] | Loss=0.00561 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=13.962 | 4641.8 samples/s | 72.5 steps/s
[Step=85950 Epoch=168.0] | Loss=0.00559 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.136 | L2-Norm(final)=13.964 | 4645.8 samples/s | 72.6 steps/s
[Step=86000 Epoch=168.1] | Loss=0.00560 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.136 | L2-Norm(final)=13.966 | 4575.2 samples/s | 71.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step86000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=321.9] | Loss=0.00007 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.872 | L2-Norm(final)=10.326 | 7084.9 samples/s | 110.7 steps/s
[Step=84050 Epoch=322.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.873 | L2-Norm(final)=10.330 | 4036.6 samples/s | 63.1 steps/s
[Step=84100 Epoch=322.2] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.874 | L2-Norm(final)=10.335 | 4852.2 samples/s | 75.8 steps/s
[Step=84150 Epoch=322.4] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.876 | L2-Norm(final)=10.339 | 5026.1 samples/s | 78.5 steps/s
[Step=84200 Epoch=322.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=10.344 | 4777.0 samples/s | 74.6 steps/s
[Step=84250 Epoch=322.8] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.879 | L2-Norm(final)=10.348 | 6799.1 samples/s | 106.2 steps/s
[Step=84300 Epoch=323.0] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.880 | L2-Norm(final)=10.353 | 2485.4 samples/s | 38.8 steps/s
[Step=84350 Epoch=323.2] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.881 | L2-Norm(final)=10.357 | 4901.6 samples/s | 76.6 steps/s
[Step=84400 Epoch=323.4] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.883 | L2-Norm(final)=10.362 | 4858.7 samples/s | 75.9 steps/s
[Step=84450 Epoch=323.6] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.884 | L2-Norm(final)=10.366 | 4985.1 samples/s | 77.9 steps/s
[Step=84500 Epoch=323.8] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.884 | L2-Norm(final)=10.370 | 5591.4 samples/s | 87.4 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=323.8] | Loss=0.00001 | Reg=0.00048 | acc=1.0000 | L2-Norm=6.893 | L2-Norm(final)=10.411 | 6178.1 samples/s | 96.5 steps/s
[Step=84550 Epoch=324.0] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.890 | L2-Norm(final)=10.415 | 3971.1 samples/s | 62.0 steps/s
[Step=84600 Epoch=324.2] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.886 | L2-Norm(final)=10.417 | 4385.0 samples/s | 68.5 steps/s
[Step=84650 Epoch=324.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.882 | L2-Norm(final)=10.420 | 4366.4 samples/s | 68.2 steps/s
[Step=84700 Epoch=324.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.877 | L2-Norm(final)=10.424 | 4426.1 samples/s | 69.2 steps/s
[Step=84750 Epoch=324.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.873 | L2-Norm(final)=10.426 | 5808.4 samples/s | 90.8 steps/s
[Step=84800 Epoch=324.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.868 | L2-Norm(final)=10.429 | 2328.0 samples/s | 36.4 steps/s
[Step=84850 Epoch=325.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.863 | L2-Norm(final)=10.431 | 4416.8 samples/s | 69.0 steps/s
[Step=84900 Epoch=325.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.857 | L2-Norm(final)=10.433 | 4352.4 samples/s | 68.0 steps/s
[Step=84950 Epoch=325.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.852 | L2-Norm(final)=10.435 | 4353.3 samples/s | 68.0 steps/s
[Step=85000 Epoch=325.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.846 | L2-Norm(final)=10.437 | 4970.8 samples/s | 77.7 steps/s
[Step=85050 Epoch=325.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.840 | L2-Norm(final)=10.439 | 2505.4 samples/s | 39.1 steps/s
[Step=85100 Epoch=326.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.834 | L2-Norm(final)=10.441 | 4349.3 samples/s | 68.0 steps/s
[Step=85150 Epoch=326.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.828 | L2-Norm(final)=10.443 | 4423.4 samples/s | 69.1 steps/s
[Step=85200 Epoch=326.5] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.822 | L2-Norm(final)=10.445 | 4364.3 samples/s | 68.2 steps/s
[Step=85250 Epoch=326.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.816 | L2-Norm(final)=10.447 | 4335.7 samples/s | 67.7 steps/s
[Step=85300 Epoch=326.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.810 | L2-Norm(final)=10.448 | 2689.3 samples/s | 42.0 steps/s
[Step=85350 Epoch=327.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.804 | L2-Norm(final)=10.450 | 4409.1 samples/s | 68.9 steps/s
[Step=85400 Epoch=327.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.797 | L2-Norm(final)=10.452 | 4349.0 samples/s | 68.0 steps/s
[Step=85450 Epoch=327.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.791 | L2-Norm(final)=10.454 | 4407.2 samples/s | 68.9 steps/s
[Step=85500 Epoch=327.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.784 | L2-Norm(final)=10.455 | 4371.3 samples/s | 68.3 steps/s
[Step=85550 Epoch=327.8] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.778 | L2-Norm(final)=10.457 | 2691.6 samples/s | 42.1 steps/s
[Step=85600 Epoch=328.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.771 | L2-Norm(final)=10.459 | 4453.0 samples/s | 69.6 steps/s
[Step=85650 Epoch=328.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.765 | L2-Norm(final)=10.461 | 4436.5 samples/s | 69.3 steps/s
[Step=85700 Epoch=328.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.758 | L2-Norm(final)=10.463 | 4335.3 samples/s | 67.7 steps/s
[Step=85750 Epoch=328.6] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.751 | L2-Norm(final)=10.465 | 4464.0 samples/s | 69.8 steps/s
[Step=85800 Epoch=328.8] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.744 | L2-Norm(final)=10.467 | 6324.9 samples/s | 98.8 steps/s
[Step=85850 Epoch=328.9] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.737 | L2-Norm(final)=10.469 | 2246.3 samples/s | 35.1 steps/s
[Step=85900 Epoch=329.1] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.730 | L2-Norm(final)=10.471 | 4434.5 samples/s | 69.3 steps/s
[Step=85950 Epoch=329.3] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.723 | L2-Norm(final)=10.473 | 4444.9 samples/s | 69.5 steps/s
[Step=86000 Epoch=329.5] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.716 | L2-Norm(final)=10.475 | 4366.5 samples/s | 68.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step86000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=323.4] | Loss=0.00005 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.816 | L2-Norm(final)=10.584 | 6840.4 samples/s | 106.9 steps/s
[Step=84050 Epoch=323.5] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.819 | L2-Norm(final)=10.601 | 4118.4 samples/s | 64.3 steps/s
[Step=84100 Epoch=323.7] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.826 | L2-Norm(final)=10.617 | 4955.9 samples/s | 77.4 steps/s
[Step=84150 Epoch=323.9] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.830 | L2-Norm(final)=10.630 | 4955.6 samples/s | 77.4 steps/s
[Step=84200 Epoch=324.1] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.833 | L2-Norm(final)=10.642 | 4783.7 samples/s | 74.7 steps/s
[Step=84250 Epoch=324.3] | Loss=0.00002 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.835 | L2-Norm(final)=10.652 | 6877.5 samples/s | 107.5 steps/s
[Step=84300 Epoch=324.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.837 | L2-Norm(final)=10.661 | 2454.6 samples/s | 38.4 steps/s
[Step=84350 Epoch=324.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.838 | L2-Norm(final)=10.670 | 4845.6 samples/s | 75.7 steps/s
[Step=84400 Epoch=324.9] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.840 | L2-Norm(final)=10.678 | 4879.4 samples/s | 76.2 steps/s
[Step=84450 Epoch=325.1] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.841 | L2-Norm(final)=10.686 | 4925.4 samples/s | 77.0 steps/s
[Step=84500 Epoch=325.3] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.842 | L2-Norm(final)=10.694 | 5821.9 samples/s | 91.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=325.3] | Loss=0.00000 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.849 | L2-Norm(final)=10.772 | 6387.0 samples/s | 99.8 steps/s
[Step=84550 Epoch=325.5] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.839 | L2-Norm(final)=10.778 | 3939.5 samples/s | 61.6 steps/s
[Step=84600 Epoch=325.7] | Loss=0.00001 | Reg=0.00047 | acc=1.0000 | L2-Norm=6.823 | L2-Norm(final)=10.783 | 4372.5 samples/s | 68.3 steps/s
[Step=84650 Epoch=325.9] | Loss=0.00001 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.806 | L2-Norm(final)=10.787 | 4414.7 samples/s | 69.0 steps/s
[Step=84700 Epoch=326.0] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.789 | L2-Norm(final)=10.791 | 4334.6 samples/s | 67.7 steps/s
[Step=84750 Epoch=326.2] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.772 | L2-Norm(final)=10.795 | 6001.6 samples/s | 93.8 steps/s
[Step=84800 Epoch=326.4] | Loss=0.00000 | Reg=0.00046 | acc=1.0000 | L2-Norm=6.754 | L2-Norm(final)=10.799 | 2309.8 samples/s | 36.1 steps/s
[Step=84850 Epoch=326.6] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.736 | L2-Norm(final)=10.802 | 4386.1 samples/s | 68.5 steps/s
[Step=84900 Epoch=326.8] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.718 | L2-Norm(final)=10.806 | 4405.5 samples/s | 68.8 steps/s
[Step=84950 Epoch=327.0] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.700 | L2-Norm(final)=10.809 | 4368.5 samples/s | 68.3 steps/s
[Step=85000 Epoch=327.2] | Loss=0.00000 | Reg=0.00045 | acc=1.0000 | L2-Norm=6.682 | L2-Norm(final)=10.812 | 5138.5 samples/s | 80.3 steps/s
[Step=85050 Epoch=327.4] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.664 | L2-Norm(final)=10.816 | 2484.5 samples/s | 38.8 steps/s
[Step=85100 Epoch=327.6] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.646 | L2-Norm(final)=10.819 | 4332.9 samples/s | 67.7 steps/s
[Step=85150 Epoch=327.8] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.628 | L2-Norm(final)=10.823 | 4338.2 samples/s | 67.8 steps/s
[Step=85200 Epoch=328.0] | Loss=0.00000 | Reg=0.00044 | acc=1.0000 | L2-Norm=6.610 | L2-Norm(final)=10.827 | 4436.6 samples/s | 69.3 steps/s
[Step=85250 Epoch=328.2] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.592 | L2-Norm(final)=10.831 | 4436.1 samples/s | 69.3 steps/s
[Step=85300 Epoch=328.4] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.575 | L2-Norm(final)=10.834 | 2645.5 samples/s | 41.3 steps/s
[Step=85350 Epoch=328.5] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.557 | L2-Norm(final)=10.838 | 4357.9 samples/s | 68.1 steps/s
[Step=85400 Epoch=328.7] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.540 | L2-Norm(final)=10.842 | 4473.0 samples/s | 69.9 steps/s
[Step=85450 Epoch=328.9] | Loss=0.00000 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.522 | L2-Norm(final)=10.846 | 4321.2 samples/s | 67.5 steps/s
[Step=85500 Epoch=329.1] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.505 | L2-Norm(final)=10.850 | 4448.8 samples/s | 69.5 steps/s
[Step=85550 Epoch=329.3] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.487 | L2-Norm(final)=10.854 | 2659.4 samples/s | 41.6 steps/s
[Step=85600 Epoch=329.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.470 | L2-Norm(final)=10.858 | 4437.4 samples/s | 69.3 steps/s
[Step=85650 Epoch=329.7] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.862 | 4419.3 samples/s | 69.1 steps/s
[Step=85700 Epoch=329.9] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.436 | L2-Norm(final)=10.867 | 4229.7 samples/s | 66.1 steps/s
[Step=85750 Epoch=330.1] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.419 | L2-Norm(final)=10.871 | 4492.1 samples/s | 70.2 steps/s
[Step=85800 Epoch=330.3] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.402 | L2-Norm(final)=10.875 | 6940.9 samples/s | 108.5 steps/s
[Step=85850 Epoch=330.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.385 | L2-Norm(final)=10.880 | 2165.8 samples/s | 33.8 steps/s
[Step=85900 Epoch=330.7] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.368 | L2-Norm(final)=10.885 | 4407.6 samples/s | 68.9 steps/s
[Step=85950 Epoch=330.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.352 | L2-Norm(final)=10.889 | 4407.7 samples/s | 68.9 steps/s
[Step=86000 Epoch=331.0] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.335 | L2-Norm(final)=10.894 | 4355.4 samples/s | 68.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07699 | acc=0.9677 | tpr=0.9781 | fpr=0.0548 | 5280.4 samples/s | 20.6 steps/s
Avg test loss: 0.07863, Avg test acc: 0.96654, Avg tpr: 0.97756, Avg fpr: 0.05768, total FA: 450

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07665 | acc=0.9673 | tpr=0.9716 | fpr=0.0421 | 5367.2 samples/s | 21.0 steps/s
Avg test loss: 0.07828, Avg test acc: 0.96674, Avg tpr: 0.97086, Avg fpr: 0.04230, total FA: 330

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.55910 | acc=0.3116 | tpr=0.0035 | fpr=0.0196 | 5259.8 samples/s | 20.5 steps/s
Avg test loss: 5.56807, Avg test acc: 0.30960, Avg tpr: 0.00367, Avg fpr: 0.01756, total FA: 137

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.38258 | acc=0.3117 | tpr=0.0054 | fpr=0.0230 | 5228.9 samples/s | 20.4 steps/s
Avg test loss: 5.38560, Avg test acc: 0.30916, Avg tpr: 0.00525, Avg fpr: 0.02243, total FA: 175

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.86502 | acc=0.1220 | tpr=0.7522 | fpr=0.8894 | 5272.4 samples/s | 20.6 steps/s
[Step= 100] | Loss=5.84458 | acc=0.1223 | tpr=0.7420 | fpr=0.8893 | 7200.0 samples/s | 28.1 steps/s
[Step= 150] | Loss=5.84248 | acc=0.1228 | tpr=0.7565 | fpr=0.8889 | 8002.3 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.85231 | acc=0.1220 | tpr=0.7508 | fpr=0.8895 | 7997.4 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.86179 | acc=0.1222 | tpr=0.7397 | fpr=0.8890 | 8210.5 samples/s | 32.1 steps/s
[Step= 300] | Loss=5.86384 | acc=0.1217 | tpr=0.7411 | fpr=0.8896 | 7798.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.85369 | acc=0.1214 | tpr=0.7401 | fpr=0.8898 | 8159.6 samples/s | 31.9 steps/s
[Step= 400] | Loss=5.84553 | acc=0.1218 | tpr=0.7423 | fpr=0.8895 | 8060.2 samples/s | 31.5 steps/s
[Step= 450] | Loss=5.84787 | acc=0.1212 | tpr=0.7439 | fpr=0.8901 | 8392.1 samples/s | 32.8 steps/s
[Step= 500] | Loss=5.84759 | acc=0.1209 | tpr=0.7427 | fpr=0.8904 | 8062.9 samples/s | 31.5 steps/s
[Step= 550] | Loss=5.84569 | acc=0.1210 | tpr=0.7394 | fpr=0.8903 | 14404.4 samples/s | 56.3 steps/s
Avg test loss: 5.84702, Avg test acc: 0.12092, Avg tpr: 0.73930, Avg fpr: 0.89032, total FA: 123619

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.60117 | acc=0.1495 | tpr=0.6814 | fpr=0.8601 | 5235.7 samples/s | 20.5 steps/s
[Step= 100] | Loss=5.58527 | acc=0.1493 | tpr=0.6631 | fpr=0.8603 | 7768.3 samples/s | 30.3 steps/s
[Step= 150] | Loss=5.57399 | acc=0.1497 | tpr=0.6787 | fpr=0.8600 | 7429.8 samples/s | 29.0 steps/s
[Step= 200] | Loss=5.58195 | acc=0.1494 | tpr=0.6765 | fpr=0.8602 | 8007.0 samples/s | 31.3 steps/s
[Step= 250] | Loss=5.59192 | acc=0.1499 | tpr=0.6690 | fpr=0.8596 | 7988.1 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.59445 | acc=0.1497 | tpr=0.6691 | fpr=0.8597 | 8660.2 samples/s | 33.8 steps/s
[Step= 350] | Loss=5.58046 | acc=0.1501 | tpr=0.6644 | fpr=0.8593 | 8023.9 samples/s | 31.3 steps/s
[Step= 400] | Loss=5.57269 | acc=0.1504 | tpr=0.6652 | fpr=0.8590 | 7981.9 samples/s | 31.2 steps/s
[Step= 450] | Loss=5.57308 | acc=0.1499 | tpr=0.6660 | fpr=0.8595 | 8100.7 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.57514 | acc=0.1495 | tpr=0.6661 | fpr=0.8598 | 8179.7 samples/s | 32.0 steps/s
[Step= 550] | Loss=5.57318 | acc=0.1494 | tpr=0.6614 | fpr=0.8599 | 14554.4 samples/s | 56.9 steps/s
Avg test loss: 5.57488, Avg test acc: 0.14936, Avg tpr: 0.66086, Avg fpr: 0.85994, total FA: 119401

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11305 | acc=0.9800 | tpr=0.9513 | fpr=0.0195 | 5226.0 samples/s | 20.4 steps/s
[Step= 100] | Loss=0.11908 | acc=0.9788 | tpr=0.9616 | fpr=0.0209 | 7120.3 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.12423 | acc=0.9776 | tpr=0.9597 | fpr=0.0221 | 8022.2 samples/s | 31.3 steps/s
[Step= 200] | Loss=0.12601 | acc=0.9778 | tpr=0.9628 | fpr=0.0219 | 8148.2 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.12402 | acc=0.9780 | tpr=0.9642 | fpr=0.0217 | 8132.7 samples/s | 31.8 steps/s
[Step= 300] | Loss=0.12611 | acc=0.9775 | tpr=0.9629 | fpr=0.0222 | 8085.7 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.12676 | acc=0.9772 | tpr=0.9643 | fpr=0.0226 | 8168.8 samples/s | 31.9 steps/s
[Step= 400] | Loss=0.12789 | acc=0.9771 | tpr=0.9623 | fpr=0.0226 | 8022.3 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.13054 | acc=0.9767 | tpr=0.9615 | fpr=0.0230 | 8664.0 samples/s | 33.8 steps/s
[Step= 500] | Loss=0.12991 | acc=0.9767 | tpr=0.9608 | fpr=0.0230 | 7528.5 samples/s | 29.4 steps/s
[Step= 550] | Loss=0.12895 | acc=0.9768 | tpr=0.9602 | fpr=0.0229 | 15488.4 samples/s | 60.5 steps/s
Avg test loss: 0.12860, Avg test acc: 0.97687, Avg tpr: 0.95998, Avg fpr: 0.02282, total FA: 3169

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11646 | acc=0.9798 | tpr=0.9558 | fpr=0.0198 | 5313.6 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.12133 | acc=0.9787 | tpr=0.9638 | fpr=0.0210 | 7333.6 samples/s | 28.6 steps/s
[Step= 150] | Loss=0.12686 | acc=0.9778 | tpr=0.9669 | fpr=0.0220 | 7484.1 samples/s | 29.2 steps/s
[Step= 200] | Loss=0.12901 | acc=0.9776 | tpr=0.9650 | fpr=0.0221 | 8318.2 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.12687 | acc=0.9780 | tpr=0.9659 | fpr=0.0218 | 8007.9 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.12920 | acc=0.9776 | tpr=0.9651 | fpr=0.0222 | 8296.2 samples/s | 32.4 steps/s
[Step= 350] | Loss=0.12987 | acc=0.9773 | tpr=0.9656 | fpr=0.0225 | 7671.7 samples/s | 30.0 steps/s
[Step= 400] | Loss=0.13091 | acc=0.9771 | tpr=0.9639 | fpr=0.0226 | 8458.8 samples/s | 33.0 steps/s
[Step= 450] | Loss=0.13360 | acc=0.9766 | tpr=0.9630 | fpr=0.0231 | 8121.3 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.13293 | acc=0.9767 | tpr=0.9643 | fpr=0.0231 | 8286.4 samples/s | 32.4 steps/s
[Step= 550] | Loss=0.13172 | acc=0.9769 | tpr=0.9630 | fpr=0.0229 | 13836.8 samples/s | 54.1 steps/s
Avg test loss: 0.13140, Avg test acc: 0.97688, Avg tpr: 0.96236, Avg fpr: 0.02285, total FA: 3173

server round 43/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=167.7] | Loss=0.00416 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=13.549 | 6462.8 samples/s | 101.0 steps/s
[Step=86050 Epoch=167.8] | Loss=0.01053 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=13.551 | 4895.9 samples/s | 76.5 steps/s
[Step=86100 Epoch=167.9] | Loss=0.01014 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=13.554 | 5132.1 samples/s | 80.2 steps/s
[Step=86150 Epoch=168.0] | Loss=0.01083 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=13.557 | 5205.3 samples/s | 81.3 steps/s
[Step=86200 Epoch=168.1] | Loss=0.01103 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=13.561 | 5147.4 samples/s | 80.4 steps/s
[Step=86250 Epoch=168.2] | Loss=0.01078 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=13.564 | 5192.2 samples/s | 81.1 steps/s
[Step=86300 Epoch=168.3] | Loss=0.01111 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.668 | L2-Norm(final)=13.567 | 5220.9 samples/s | 81.6 steps/s
[Step=86350 Epoch=168.4] | Loss=0.01099 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=13.571 | 5230.2 samples/s | 81.7 steps/s
[Step=86400 Epoch=168.5] | Loss=0.01119 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.671 | L2-Norm(final)=13.574 | 5292.2 samples/s | 82.7 steps/s
[Step=86450 Epoch=168.6] | Loss=0.01122 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.673 | L2-Norm(final)=13.577 | 5135.1 samples/s | 80.2 steps/s
[Step=86500 Epoch=168.7] | Loss=0.01112 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=13.580 | 7017.7 samples/s | 109.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=168.7] | Loss=0.00900 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.689 | L2-Norm(final)=13.611 | 5832.4 samples/s | 91.1 steps/s
[Step=86550 Epoch=168.8] | Loss=0.00982 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=13.615 | 4420.0 samples/s | 69.1 steps/s
[Step=86600 Epoch=168.9] | Loss=0.01061 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=13.617 | 4629.1 samples/s | 72.3 steps/s
[Step=86650 Epoch=169.0] | Loss=0.01038 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.697 | L2-Norm(final)=13.620 | 4625.4 samples/s | 72.3 steps/s
[Step=86700 Epoch=169.1] | Loss=0.01048 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.699 | L2-Norm(final)=13.623 | 4583.2 samples/s | 71.6 steps/s
[Step=86750 Epoch=169.2] | Loss=0.01020 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.701 | L2-Norm(final)=13.625 | 4661.5 samples/s | 72.8 steps/s
[Step=86800 Epoch=169.3] | Loss=0.00974 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.703 | L2-Norm(final)=13.628 | 4581.3 samples/s | 71.6 steps/s
[Step=86850 Epoch=169.4] | Loss=0.00941 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=13.631 | 4640.6 samples/s | 72.5 steps/s
[Step=86900 Epoch=169.5] | Loss=0.00925 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=13.633 | 4641.3 samples/s | 72.5 steps/s
[Step=86950 Epoch=169.6] | Loss=0.00920 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.708 | L2-Norm(final)=13.636 | 4709.6 samples/s | 73.6 steps/s
[Step=87000 Epoch=169.7] | Loss=0.00902 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=13.638 | 5835.0 samples/s | 91.2 steps/s
[Step=87050 Epoch=169.8] | Loss=0.00875 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.711 | L2-Norm(final)=13.641 | 2459.4 samples/s | 38.4 steps/s
[Step=87100 Epoch=169.9] | Loss=0.00839 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.713 | L2-Norm(final)=13.643 | 4668.8 samples/s | 73.0 steps/s
[Step=87150 Epoch=170.0] | Loss=0.00818 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.714 | L2-Norm(final)=13.646 | 4530.4 samples/s | 70.8 steps/s
[Step=87200 Epoch=170.1] | Loss=0.00804 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=13.648 | 4637.4 samples/s | 72.5 steps/s
[Step=87250 Epoch=170.2] | Loss=0.00792 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.716 | L2-Norm(final)=13.650 | 4618.5 samples/s | 72.2 steps/s
[Step=87300 Epoch=170.3] | Loss=0.00780 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.717 | L2-Norm(final)=13.653 | 4648.8 samples/s | 72.6 steps/s
[Step=87350 Epoch=170.4] | Loss=0.00777 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.718 | L2-Norm(final)=13.655 | 4599.7 samples/s | 71.9 steps/s
[Step=87400 Epoch=170.5] | Loss=0.00775 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=13.657 | 4638.5 samples/s | 72.5 steps/s
[Step=87450 Epoch=170.6] | Loss=0.00776 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.720 | L2-Norm(final)=13.659 | 4657.5 samples/s | 72.8 steps/s
[Step=87500 Epoch=170.7] | Loss=0.00766 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.721 | L2-Norm(final)=13.662 | 4913.2 samples/s | 76.8 steps/s
[Step=87550 Epoch=170.8] | Loss=0.00762 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.722 | L2-Norm(final)=13.664 | 2652.5 samples/s | 41.4 steps/s
[Step=87600 Epoch=170.9] | Loss=0.00754 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.723 | L2-Norm(final)=13.666 | 4753.6 samples/s | 74.3 steps/s
[Step=87650 Epoch=171.0] | Loss=0.00745 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.724 | L2-Norm(final)=13.668 | 4481.2 samples/s | 70.0 steps/s
[Step=87700 Epoch=171.0] | Loss=0.00741 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.724 | L2-Norm(final)=13.670 | 4614.6 samples/s | 72.1 steps/s
[Step=87750 Epoch=171.1] | Loss=0.00727 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.725 | L2-Norm(final)=13.672 | 4653.0 samples/s | 72.7 steps/s
[Step=87800 Epoch=171.2] | Loss=0.00717 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.726 | L2-Norm(final)=13.674 | 4627.2 samples/s | 72.3 steps/s
[Step=87850 Epoch=171.3] | Loss=0.00710 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=13.676 | 4583.2 samples/s | 71.6 steps/s
[Step=87900 Epoch=171.4] | Loss=0.00702 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=13.678 | 4652.0 samples/s | 72.7 steps/s
[Step=87950 Epoch=171.5] | Loss=0.00703 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.728 | L2-Norm(final)=13.680 | 4688.9 samples/s | 73.3 steps/s
[Step=88000 Epoch=171.6] | Loss=0.00697 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.729 | L2-Norm(final)=13.683 | 4594.2 samples/s | 71.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step88000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=168.1] | Loss=0.00218 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=14.027 | 5968.9 samples/s | 93.3 steps/s
[Step=86050 Epoch=168.2] | Loss=0.01029 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.979 | L2-Norm(final)=14.031 | 4998.1 samples/s | 78.1 steps/s
[Step=86100 Epoch=168.3] | Loss=0.01098 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.982 | L2-Norm(final)=14.035 | 5086.4 samples/s | 79.5 steps/s
[Step=86150 Epoch=168.4] | Loss=0.01060 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=14.038 | 5329.6 samples/s | 83.3 steps/s
[Step=86200 Epoch=168.5] | Loss=0.01093 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=14.042 | 5036.6 samples/s | 78.7 steps/s
[Step=86250 Epoch=168.6] | Loss=0.01068 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.987 | L2-Norm(final)=14.045 | 5215.4 samples/s | 81.5 steps/s
[Step=86300 Epoch=168.7] | Loss=0.01070 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.989 | L2-Norm(final)=14.049 | 5276.9 samples/s | 82.5 steps/s
[Step=86350 Epoch=168.8] | Loss=0.01090 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.990 | L2-Norm(final)=14.052 | 5251.4 samples/s | 82.1 steps/s
[Step=86400 Epoch=168.9] | Loss=0.01078 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=14.055 | 5095.4 samples/s | 79.6 steps/s
[Step=86450 Epoch=169.0] | Loss=0.01082 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=14.058 | 5174.0 samples/s | 80.8 steps/s
[Step=86500 Epoch=169.1] | Loss=0.01080 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=14.062 | 7181.6 samples/s | 112.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=169.1] | Loss=0.00820 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=14.093 | 6367.4 samples/s | 99.5 steps/s
[Step=86550 Epoch=169.2] | Loss=0.01094 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.013 | L2-Norm(final)=14.095 | 4158.2 samples/s | 65.0 steps/s
[Step=86600 Epoch=169.3] | Loss=0.01095 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=14.098 | 4623.2 samples/s | 72.2 steps/s
[Step=86650 Epoch=169.4] | Loss=0.01037 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=14.101 | 4555.2 samples/s | 71.2 steps/s
[Step=86700 Epoch=169.5] | Loss=0.00969 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=14.104 | 4612.1 samples/s | 72.1 steps/s
[Step=86750 Epoch=169.6] | Loss=0.01013 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=14.106 | 4602.9 samples/s | 71.9 steps/s
[Step=86800 Epoch=169.7] | Loss=0.00974 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=14.109 | 4711.4 samples/s | 73.6 steps/s
[Step=86850 Epoch=169.8] | Loss=0.00946 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.025 | L2-Norm(final)=14.111 | 4543.4 samples/s | 71.0 steps/s
[Step=86900 Epoch=169.9] | Loss=0.00921 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.027 | L2-Norm(final)=14.114 | 4614.3 samples/s | 72.1 steps/s
[Step=86950 Epoch=170.0] | Loss=0.00907 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.029 | L2-Norm(final)=14.116 | 4652.6 samples/s | 72.7 steps/s
[Step=87000 Epoch=170.1] | Loss=0.00893 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=14.118 | 6061.9 samples/s | 94.7 steps/s
[Step=87050 Epoch=170.2] | Loss=0.00868 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=14.121 | 2431.2 samples/s | 38.0 steps/s
[Step=87100 Epoch=170.3] | Loss=0.00843 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.033 | L2-Norm(final)=14.123 | 4581.2 samples/s | 71.6 steps/s
[Step=87150 Epoch=170.4] | Loss=0.00815 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.034 | L2-Norm(final)=14.125 | 4623.5 samples/s | 72.2 steps/s
[Step=87200 Epoch=170.5] | Loss=0.00788 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.035 | L2-Norm(final)=14.127 | 4605.0 samples/s | 72.0 steps/s
[Step=87250 Epoch=170.6] | Loss=0.00776 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=14.129 | 4628.9 samples/s | 72.3 steps/s
[Step=87300 Epoch=170.7] | Loss=0.00762 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=14.131 | 4675.4 samples/s | 73.1 steps/s
[Step=87350 Epoch=170.8] | Loss=0.00753 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.038 | L2-Norm(final)=14.134 | 4602.2 samples/s | 71.9 steps/s
[Step=87400 Epoch=170.9] | Loss=0.00748 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.039 | L2-Norm(final)=14.136 | 4652.4 samples/s | 72.7 steps/s
[Step=87450 Epoch=171.0] | Loss=0.00741 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=14.138 | 4633.0 samples/s | 72.4 steps/s
[Step=87500 Epoch=171.1] | Loss=0.00743 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.040 | L2-Norm(final)=14.140 | 5119.1 samples/s | 80.0 steps/s
[Step=87550 Epoch=171.2] | Loss=0.00734 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.041 | L2-Norm(final)=14.142 | 2637.7 samples/s | 41.2 steps/s
[Step=87600 Epoch=171.3] | Loss=0.00714 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.042 | L2-Norm(final)=14.144 | 4626.1 samples/s | 72.3 steps/s
[Step=87650 Epoch=171.4] | Loss=0.00702 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.043 | L2-Norm(final)=14.146 | 4684.6 samples/s | 73.2 steps/s
[Step=87700 Epoch=171.5] | Loss=0.00696 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.043 | L2-Norm(final)=14.148 | 4535.7 samples/s | 70.9 steps/s
[Step=87750 Epoch=171.5] | Loss=0.00685 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=14.150 | 4664.2 samples/s | 72.9 steps/s
[Step=87800 Epoch=171.6] | Loss=0.00682 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=14.152 | 4438.4 samples/s | 69.3 steps/s
[Step=87850 Epoch=171.7] | Loss=0.00679 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.045 | L2-Norm(final)=14.153 | 4576.3 samples/s | 71.5 steps/s
[Step=87900 Epoch=171.8] | Loss=0.00674 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=14.155 | 4511.6 samples/s | 70.5 steps/s
[Step=87950 Epoch=171.9] | Loss=0.00669 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=14.157 | 4562.7 samples/s | 71.3 steps/s
[Step=88000 Epoch=172.0] | Loss=0.00666 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.047 | L2-Norm(final)=14.159 | 4572.4 samples/s | 71.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step88000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=329.5] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.544 | L2-Norm(final)=10.537 | 6447.0 samples/s | 100.7 steps/s
[Step=86050 Epoch=329.7] | Loss=0.00005 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.548 | L2-Norm(final)=10.549 | 4435.7 samples/s | 69.3 steps/s
[Step=86100 Epoch=329.9] | Loss=0.00004 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.553 | L2-Norm(final)=10.560 | 4961.8 samples/s | 77.5 steps/s
[Step=86150 Epoch=330.1] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.557 | L2-Norm(final)=10.571 | 4831.9 samples/s | 75.5 steps/s
[Step=86200 Epoch=330.3] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.560 | L2-Norm(final)=10.580 | 4903.5 samples/s | 76.6 steps/s
[Step=86250 Epoch=330.5] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.563 | L2-Norm(final)=10.589 | 6882.5 samples/s | 107.5 steps/s
[Step=86300 Epoch=330.7] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.565 | L2-Norm(final)=10.597 | 2523.1 samples/s | 39.4 steps/s
[Step=86350 Epoch=330.9] | Loss=0.00003 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.567 | L2-Norm(final)=10.604 | 4664.2 samples/s | 72.9 steps/s
[Step=86400 Epoch=331.1] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.569 | L2-Norm(final)=10.611 | 4997.9 samples/s | 78.1 steps/s
[Step=86450 Epoch=331.2] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.570 | L2-Norm(final)=10.618 | 4797.9 samples/s | 75.0 steps/s
[Step=86500 Epoch=331.4] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.572 | L2-Norm(final)=10.624 | 5627.9 samples/s | 87.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=331.4] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.585 | L2-Norm(final)=10.687 | 6247.0 samples/s | 97.6 steps/s
[Step=86550 Epoch=331.6] | Loss=0.00002 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.580 | L2-Norm(final)=10.692 | 3874.4 samples/s | 60.5 steps/s
[Step=86600 Epoch=331.8] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.574 | L2-Norm(final)=10.697 | 4403.3 samples/s | 68.8 steps/s
[Step=86650 Epoch=332.0] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.568 | L2-Norm(final)=10.701 | 4393.7 samples/s | 68.7 steps/s
[Step=86700 Epoch=332.2] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.560 | L2-Norm(final)=10.704 | 4403.4 samples/s | 68.8 steps/s
[Step=86750 Epoch=332.4] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.552 | L2-Norm(final)=10.707 | 5785.7 samples/s | 90.4 steps/s
[Step=86800 Epoch=332.6] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.544 | L2-Norm(final)=10.710 | 2328.8 samples/s | 36.4 steps/s
[Step=86850 Epoch=332.8] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.536 | L2-Norm(final)=10.712 | 4445.3 samples/s | 69.5 steps/s
[Step=86900 Epoch=333.0] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.528 | L2-Norm(final)=10.715 | 4379.1 samples/s | 68.4 steps/s
[Step=86950 Epoch=333.2] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.519 | L2-Norm(final)=10.717 | 4431.7 samples/s | 69.2 steps/s
[Step=87000 Epoch=333.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.510 | L2-Norm(final)=10.719 | 4885.7 samples/s | 76.3 steps/s
[Step=87050 Epoch=333.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.501 | L2-Norm(final)=10.721 | 2511.1 samples/s | 39.2 steps/s
[Step=87100 Epoch=333.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.492 | L2-Norm(final)=10.722 | 4347.8 samples/s | 67.9 steps/s
[Step=87150 Epoch=333.9] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.482 | L2-Norm(final)=10.724 | 4530.5 samples/s | 70.8 steps/s
[Step=87200 Epoch=334.1] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.472 | L2-Norm(final)=10.726 | 4280.9 samples/s | 66.9 steps/s
[Step=87250 Epoch=334.3] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.463 | L2-Norm(final)=10.728 | 4338.8 samples/s | 67.8 steps/s
[Step=87300 Epoch=334.5] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.453 | L2-Norm(final)=10.729 | 2680.6 samples/s | 41.9 steps/s
[Step=87350 Epoch=334.7] | Loss=0.00000 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.443 | L2-Norm(final)=10.731 | 4428.1 samples/s | 69.2 steps/s
[Step=87400 Epoch=334.9] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.433 | L2-Norm(final)=10.733 | 4476.9 samples/s | 70.0 steps/s
[Step=87450 Epoch=335.1] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.423 | L2-Norm(final)=10.735 | 4270.6 samples/s | 66.7 steps/s
[Step=87500 Epoch=335.3] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.413 | L2-Norm(final)=10.736 | 4375.3 samples/s | 68.4 steps/s
[Step=87550 Epoch=335.5] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.403 | L2-Norm(final)=10.738 | 2684.8 samples/s | 41.9 steps/s
[Step=87600 Epoch=335.7] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.392 | L2-Norm(final)=10.740 | 4411.2 samples/s | 68.9 steps/s
[Step=87650 Epoch=335.8] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.382 | L2-Norm(final)=10.742 | 4391.6 samples/s | 68.6 steps/s
[Step=87700 Epoch=336.0] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.372 | L2-Norm(final)=10.744 | 4477.0 samples/s | 70.0 steps/s
[Step=87750 Epoch=336.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.361 | L2-Norm(final)=10.746 | 4362.1 samples/s | 68.2 steps/s
[Step=87800 Epoch=336.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.351 | L2-Norm(final)=10.748 | 6335.8 samples/s | 99.0 steps/s
[Step=87850 Epoch=336.6] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.340 | L2-Norm(final)=10.750 | 2191.0 samples/s | 34.2 steps/s
[Step=87900 Epoch=336.8] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=10.752 | 4309.3 samples/s | 67.3 steps/s
[Step=87950 Epoch=337.0] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.318 | L2-Norm(final)=10.754 | 4263.4 samples/s | 66.6 steps/s
[Step=88000 Epoch=337.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.307 | L2-Norm(final)=10.756 | 4329.3 samples/s | 67.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step88000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=331.1] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.490 | L2-Norm(final)=11.039 | 6672.8 samples/s | 104.3 steps/s
[Step=86050 Epoch=331.2] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.493 | L2-Norm(final)=11.059 | 4124.8 samples/s | 64.5 steps/s
[Step=86100 Epoch=331.4] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.500 | L2-Norm(final)=11.076 | 5023.8 samples/s | 78.5 steps/s
[Step=86150 Epoch=331.6] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.505 | L2-Norm(final)=11.090 | 4776.4 samples/s | 74.6 steps/s
[Step=86200 Epoch=331.8] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.508 | L2-Norm(final)=11.101 | 4826.5 samples/s | 75.4 steps/s
[Step=86250 Epoch=332.0] | Loss=0.00002 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.510 | L2-Norm(final)=11.112 | 6952.4 samples/s | 108.6 steps/s
[Step=86300 Epoch=332.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.512 | L2-Norm(final)=11.121 | 2466.3 samples/s | 38.5 steps/s
[Step=86350 Epoch=332.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.514 | L2-Norm(final)=11.130 | 4771.1 samples/s | 74.5 steps/s
[Step=86400 Epoch=332.6] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.515 | L2-Norm(final)=11.138 | 4890.7 samples/s | 76.4 steps/s
[Step=86450 Epoch=332.8] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.516 | L2-Norm(final)=11.146 | 4866.5 samples/s | 76.0 steps/s
[Step=86500 Epoch=333.0] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.517 | L2-Norm(final)=11.154 | 5803.8 samples/s | 90.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=333.0] | Loss=0.00001 | Reg=0.00043 | acc=1.0000 | L2-Norm=6.526 | L2-Norm(final)=11.233 | 6127.8 samples/s | 95.7 steps/s
[Step=86550 Epoch=333.2] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.510 | L2-Norm(final)=11.239 | 3926.4 samples/s | 61.4 steps/s
[Step=86600 Epoch=333.4] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.488 | L2-Norm(final)=11.244 | 4325.8 samples/s | 67.6 steps/s
[Step=86650 Epoch=333.5] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.469 | L2-Norm(final)=11.250 | 4371.8 samples/s | 68.3 steps/s
[Step=86700 Epoch=333.7] | Loss=0.00001 | Reg=0.00042 | acc=1.0000 | L2-Norm=6.450 | L2-Norm(final)=11.255 | 4469.0 samples/s | 69.8 steps/s
[Step=86750 Epoch=333.9] | Loss=0.00005 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.435 | L2-Norm(final)=11.260 | 5804.7 samples/s | 90.7 steps/s
[Step=86800 Epoch=334.1] | Loss=0.00006 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.427 | L2-Norm(final)=11.266 | 2309.1 samples/s | 36.1 steps/s
[Step=86850 Epoch=334.3] | Loss=0.00005 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.422 | L2-Norm(final)=11.271 | 4437.2 samples/s | 69.3 steps/s
[Step=86900 Epoch=334.5] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.418 | L2-Norm(final)=11.275 | 4432.8 samples/s | 69.3 steps/s
[Step=86950 Epoch=334.7] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.415 | L2-Norm(final)=11.278 | 4370.0 samples/s | 68.3 steps/s
[Step=87000 Epoch=334.9] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.412 | L2-Norm(final)=11.280 | 5061.7 samples/s | 79.1 steps/s
[Step=87050 Epoch=335.1] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.410 | L2-Norm(final)=11.282 | 2460.8 samples/s | 38.5 steps/s
[Step=87100 Epoch=335.3] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.408 | L2-Norm(final)=11.284 | 4437.2 samples/s | 69.3 steps/s
[Step=87150 Epoch=335.5] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.406 | L2-Norm(final)=11.286 | 4420.2 samples/s | 69.1 steps/s
[Step=87200 Epoch=335.7] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.404 | L2-Norm(final)=11.287 | 4318.9 samples/s | 67.5 steps/s
[Step=87250 Epoch=335.9] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.402 | L2-Norm(final)=11.288 | 4470.2 samples/s | 69.8 steps/s
[Step=87300 Epoch=336.1] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.400 | L2-Norm(final)=11.290 | 2645.4 samples/s | 41.3 steps/s
[Step=87350 Epoch=336.2] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.398 | L2-Norm(final)=11.291 | 4354.2 samples/s | 68.0 steps/s
[Step=87400 Epoch=336.4] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.396 | L2-Norm(final)=11.292 | 4396.6 samples/s | 68.7 steps/s
[Step=87450 Epoch=336.6] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.395 | L2-Norm(final)=11.293 | 4352.9 samples/s | 68.0 steps/s
[Step=87500 Epoch=336.8] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.393 | L2-Norm(final)=11.294 | 4500.6 samples/s | 70.3 steps/s
[Step=87550 Epoch=337.0] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.391 | L2-Norm(final)=11.294 | 2642.1 samples/s | 41.3 steps/s
[Step=87600 Epoch=337.2] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.390 | L2-Norm(final)=11.295 | 4361.4 samples/s | 68.1 steps/s
[Step=87650 Epoch=337.4] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.388 | L2-Norm(final)=11.296 | 4441.5 samples/s | 69.4 steps/s
[Step=87700 Epoch=337.6] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.387 | L2-Norm(final)=11.297 | 4329.3 samples/s | 67.6 steps/s
[Step=87750 Epoch=337.8] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.385 | L2-Norm(final)=11.298 | 4358.8 samples/s | 68.1 steps/s
[Step=87800 Epoch=338.0] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.383 | L2-Norm(final)=11.298 | 7156.4 samples/s | 111.8 steps/s
[Step=87850 Epoch=338.2] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.382 | L2-Norm(final)=11.299 | 2161.9 samples/s | 33.8 steps/s
[Step=87900 Epoch=338.4] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.380 | L2-Norm(final)=11.300 | 4402.6 samples/s | 68.8 steps/s
[Step=87950 Epoch=338.6] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.378 | L2-Norm(final)=11.300 | 4368.2 samples/s | 68.3 steps/s
[Step=88000 Epoch=338.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.301 | 4387.7 samples/s | 68.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07242 | acc=0.9666 | tpr=0.9754 | fpr=0.0525 | 5078.2 samples/s | 19.8 steps/s
Avg test loss: 0.07416, Avg test acc: 0.96550, Avg tpr: 0.97465, Avg fpr: 0.05461, total FA: 426

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07493 | acc=0.9676 | tpr=0.9771 | fpr=0.0530 | 5326.3 samples/s | 20.8 steps/s
Avg test loss: 0.07627, Avg test acc: 0.96702, Avg tpr: 0.97651, Avg fpr: 0.05384, total FA: 420

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.55937 | acc=0.3136 | tpr=0.0031 | fpr=0.0121 | 5415.9 samples/s | 21.2 steps/s
Avg test loss: 5.57010, Avg test acc: 0.31104, Avg tpr: 0.00344, Avg fpr: 0.01243, total FA: 97

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.29490 | acc=0.3105 | tpr=0.0060 | fpr=0.0282 | 5291.0 samples/s | 20.7 steps/s
Avg test loss: 5.30106, Avg test acc: 0.30860, Avg tpr: 0.00606, Avg fpr: 0.02602, total FA: 203

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.42359 | acc=0.1268 | tpr=0.7301 | fpr=0.8840 | 5120.9 samples/s | 20.0 steps/s
[Step= 100] | Loss=5.40639 | acc=0.1269 | tpr=0.7122 | fpr=0.8840 | 7373.6 samples/s | 28.8 steps/s
[Step= 150] | Loss=5.40590 | acc=0.1277 | tpr=0.7334 | fpr=0.8834 | 8009.2 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.41457 | acc=0.1269 | tpr=0.7246 | fpr=0.8840 | 8251.3 samples/s | 32.2 steps/s
[Step= 250] | Loss=5.42516 | acc=0.1269 | tpr=0.7170 | fpr=0.8838 | 8068.5 samples/s | 31.5 steps/s
[Step= 300] | Loss=5.42725 | acc=0.1263 | tpr=0.7200 | fpr=0.8845 | 8028.6 samples/s | 31.4 steps/s
[Step= 350] | Loss=5.41725 | acc=0.1260 | tpr=0.7157 | fpr=0.8847 | 7909.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=5.40940 | acc=0.1264 | tpr=0.7188 | fpr=0.8843 | 8117.5 samples/s | 31.7 steps/s
[Step= 450] | Loss=5.41155 | acc=0.1259 | tpr=0.7210 | fpr=0.8849 | 8233.2 samples/s | 32.2 steps/s
[Step= 500] | Loss=5.41153 | acc=0.1255 | tpr=0.7211 | fpr=0.8853 | 7796.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.40954 | acc=0.1254 | tpr=0.7163 | fpr=0.8854 | 14700.1 samples/s | 57.4 steps/s
Avg test loss: 5.41073, Avg test acc: 0.12531, Avg tpr: 0.71593, Avg fpr: 0.88543, total FA: 122940

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.72313 | acc=0.1349 | tpr=0.7212 | fpr=0.8756 | 5337.8 samples/s | 20.9 steps/s
[Step= 100] | Loss=5.71427 | acc=0.1342 | tpr=0.7164 | fpr=0.8766 | 7752.3 samples/s | 30.3 steps/s
[Step= 150] | Loss=5.70455 | acc=0.1346 | tpr=0.7305 | fpr=0.8764 | 7354.0 samples/s | 28.7 steps/s
[Step= 200] | Loss=5.71436 | acc=0.1341 | tpr=0.7344 | fpr=0.8768 | 7939.5 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.72458 | acc=0.1345 | tpr=0.7275 | fpr=0.8764 | 7889.9 samples/s | 30.8 steps/s
[Step= 300] | Loss=5.72789 | acc=0.1342 | tpr=0.7251 | fpr=0.8765 | 8134.6 samples/s | 31.8 steps/s
[Step= 350] | Loss=5.71422 | acc=0.1343 | tpr=0.7182 | fpr=0.8763 | 8194.6 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.70659 | acc=0.1344 | tpr=0.7194 | fpr=0.8762 | 8188.4 samples/s | 32.0 steps/s
[Step= 450] | Loss=5.70665 | acc=0.1338 | tpr=0.7196 | fpr=0.8768 | 8279.8 samples/s | 32.3 steps/s
[Step= 500] | Loss=5.70902 | acc=0.1335 | tpr=0.7176 | fpr=0.8770 | 7817.9 samples/s | 30.5 steps/s
[Step= 550] | Loss=5.70655 | acc=0.1337 | tpr=0.7143 | fpr=0.8769 | 15073.3 samples/s | 58.9 steps/s
Avg test loss: 5.70800, Avg test acc: 0.13363, Avg tpr: 0.71474, Avg fpr: 0.87694, total FA: 121761

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11074 | acc=0.9801 | tpr=0.9513 | fpr=0.0194 | 5395.6 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.11616 | acc=0.9787 | tpr=0.9595 | fpr=0.0209 | 6903.5 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.12146 | acc=0.9777 | tpr=0.9568 | fpr=0.0219 | 7835.4 samples/s | 30.6 steps/s
[Step= 200] | Loss=0.12315 | acc=0.9780 | tpr=0.9607 | fpr=0.0217 | 8131.8 samples/s | 31.8 steps/s
[Step= 250] | Loss=0.12107 | acc=0.9782 | tpr=0.9624 | fpr=0.0215 | 8038.6 samples/s | 31.4 steps/s
[Step= 300] | Loss=0.12313 | acc=0.9779 | tpr=0.9622 | fpr=0.0219 | 8127.6 samples/s | 31.7 steps/s
[Step= 350] | Loss=0.12373 | acc=0.9775 | tpr=0.9637 | fpr=0.0222 | 8104.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.12476 | acc=0.9774 | tpr=0.9617 | fpr=0.0223 | 8346.9 samples/s | 32.6 steps/s
[Step= 450] | Loss=0.12733 | acc=0.9770 | tpr=0.9606 | fpr=0.0227 | 8053.4 samples/s | 31.5 steps/s
[Step= 500] | Loss=0.12677 | acc=0.9771 | tpr=0.9608 | fpr=0.0226 | 7960.2 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12587 | acc=0.9772 | tpr=0.9602 | fpr=0.0225 | 15083.8 samples/s | 58.9 steps/s
Avg test loss: 0.12553, Avg test acc: 0.97722, Avg tpr: 0.95998, Avg fpr: 0.02246, total FA: 3119

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11899 | acc=0.9796 | tpr=0.9602 | fpr=0.0200 | 5173.6 samples/s | 20.2 steps/s
[Step= 100] | Loss=0.12402 | acc=0.9789 | tpr=0.9638 | fpr=0.0209 | 7694.3 samples/s | 30.1 steps/s
[Step= 150] | Loss=0.12964 | acc=0.9777 | tpr=0.9654 | fpr=0.0221 | 7556.2 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.13149 | acc=0.9777 | tpr=0.9661 | fpr=0.0221 | 8089.2 samples/s | 31.6 steps/s
[Step= 250] | Loss=0.12908 | acc=0.9781 | tpr=0.9686 | fpr=0.0217 | 7943.3 samples/s | 31.0 steps/s
[Step= 300] | Loss=0.13124 | acc=0.9777 | tpr=0.9665 | fpr=0.0221 | 7759.2 samples/s | 30.3 steps/s
[Step= 350] | Loss=0.13201 | acc=0.9774 | tpr=0.9668 | fpr=0.0224 | 8425.6 samples/s | 32.9 steps/s
[Step= 400] | Loss=0.13306 | acc=0.9773 | tpr=0.9650 | fpr=0.0225 | 8103.7 samples/s | 31.7 steps/s
[Step= 450] | Loss=0.13590 | acc=0.9768 | tpr=0.9640 | fpr=0.0230 | 7906.2 samples/s | 30.9 steps/s
[Step= 500] | Loss=0.13522 | acc=0.9769 | tpr=0.9652 | fpr=0.0229 | 8474.6 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.13405 | acc=0.9771 | tpr=0.9642 | fpr=0.0227 | 14144.0 samples/s | 55.3 steps/s
Avg test loss: 0.13372, Avg test acc: 0.97708, Avg tpr: 0.96395, Avg fpr: 0.02268, total FA: 3149

server round 44/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=171.6] | Loss=0.01766 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.638 | L2-Norm(final)=13.743 | 6474.2 samples/s | 101.2 steps/s
[Step=88050 Epoch=171.7] | Loss=0.00972 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.639 | L2-Norm(final)=13.746 | 4569.6 samples/s | 71.4 steps/s
[Step=88100 Epoch=171.8] | Loss=0.01039 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.641 | L2-Norm(final)=13.750 | 5331.1 samples/s | 83.3 steps/s
[Step=88150 Epoch=171.9] | Loss=0.01156 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=13.753 | 5164.0 samples/s | 80.7 steps/s
[Step=88200 Epoch=172.0] | Loss=0.01180 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.645 | L2-Norm(final)=13.756 | 5019.7 samples/s | 78.4 steps/s
[Step=88250 Epoch=172.1] | Loss=0.01146 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.647 | L2-Norm(final)=13.760 | 5176.2 samples/s | 80.9 steps/s
[Step=88300 Epoch=172.2] | Loss=0.01124 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=13.763 | 5228.8 samples/s | 81.7 steps/s
[Step=88350 Epoch=172.3] | Loss=0.01115 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=13.767 | 5232.3 samples/s | 81.8 steps/s
[Step=88400 Epoch=172.4] | Loss=0.01102 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.652 | L2-Norm(final)=13.770 | 5187.2 samples/s | 81.0 steps/s
[Step=88450 Epoch=172.5] | Loss=0.01089 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=13.773 | 5285.1 samples/s | 82.6 steps/s
[Step=88500 Epoch=172.6] | Loss=0.01088 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.656 | L2-Norm(final)=13.777 | 6780.9 samples/s | 106.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=172.6] | Loss=0.00146 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=13.812 | 6381.6 samples/s | 99.7 steps/s
[Step=88550 Epoch=172.7] | Loss=0.01123 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.674 | L2-Norm(final)=13.815 | 4127.8 samples/s | 64.5 steps/s
[Step=88600 Epoch=172.8] | Loss=0.01119 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=13.818 | 4629.5 samples/s | 72.3 steps/s
[Step=88650 Epoch=172.9] | Loss=0.01051 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.679 | L2-Norm(final)=13.821 | 4587.1 samples/s | 71.7 steps/s
[Step=88700 Epoch=173.0] | Loss=0.00975 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.681 | L2-Norm(final)=13.824 | 4640.6 samples/s | 72.5 steps/s
[Step=88750 Epoch=173.1] | Loss=0.00970 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=13.827 | 4587.2 samples/s | 71.7 steps/s
[Step=88800 Epoch=173.2] | Loss=0.00957 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.684 | L2-Norm(final)=13.829 | 4620.4 samples/s | 72.2 steps/s
[Step=88850 Epoch=173.3] | Loss=0.00962 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.686 | L2-Norm(final)=13.832 | 4616.0 samples/s | 72.1 steps/s
[Step=88900 Epoch=173.4] | Loss=0.00971 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.688 | L2-Norm(final)=13.834 | 4664.3 samples/s | 72.9 steps/s
[Step=88950 Epoch=173.5] | Loss=0.00967 | Reg=0.00216 | acc=0.9531 | L2-Norm=14.689 | L2-Norm(final)=13.837 | 4629.6 samples/s | 72.3 steps/s
[Step=89000 Epoch=173.6] | Loss=0.00961 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=13.840 | 5842.5 samples/s | 91.3 steps/s
[Step=89050 Epoch=173.7] | Loss=0.00936 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.692 | L2-Norm(final)=13.842 | 2430.9 samples/s | 38.0 steps/s
[Step=89100 Epoch=173.8] | Loss=0.00902 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.694 | L2-Norm(final)=13.845 | 4670.6 samples/s | 73.0 steps/s
[Step=89150 Epoch=173.9] | Loss=0.00882 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=13.847 | 4549.4 samples/s | 71.1 steps/s
[Step=89200 Epoch=174.0] | Loss=0.00862 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.696 | L2-Norm(final)=13.850 | 4602.6 samples/s | 71.9 steps/s
[Step=89250 Epoch=174.1] | Loss=0.00844 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.698 | L2-Norm(final)=13.852 | 4622.7 samples/s | 72.2 steps/s
[Step=89300 Epoch=174.2] | Loss=0.00846 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.699 | L2-Norm(final)=13.855 | 4669.2 samples/s | 73.0 steps/s
[Step=89350 Epoch=174.3] | Loss=0.00840 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.700 | L2-Norm(final)=13.857 | 4581.1 samples/s | 71.6 steps/s
[Step=89400 Epoch=174.4] | Loss=0.00830 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.701 | L2-Norm(final)=13.859 | 4639.5 samples/s | 72.5 steps/s
[Step=89450 Epoch=174.5] | Loss=0.00834 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.702 | L2-Norm(final)=13.861 | 4672.3 samples/s | 73.0 steps/s
[Step=89500 Epoch=174.6] | Loss=0.00827 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=13.863 | 4891.0 samples/s | 76.4 steps/s
[Step=89550 Epoch=174.7] | Loss=0.00816 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.704 | L2-Norm(final)=13.866 | 2661.3 samples/s | 41.6 steps/s
[Step=89600 Epoch=174.8] | Loss=0.00806 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=13.868 | 4698.8 samples/s | 73.4 steps/s
[Step=89650 Epoch=174.9] | Loss=0.00791 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=13.870 | 4535.8 samples/s | 70.9 steps/s
[Step=89700 Epoch=174.9] | Loss=0.00781 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=13.872 | 4669.2 samples/s | 73.0 steps/s
[Step=89750 Epoch=175.0] | Loss=0.00773 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=13.874 | 4598.9 samples/s | 71.9 steps/s
[Step=89800 Epoch=175.1] | Loss=0.00760 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.708 | L2-Norm(final)=13.876 | 4645.1 samples/s | 72.6 steps/s
[Step=89850 Epoch=175.2] | Loss=0.00759 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.709 | L2-Norm(final)=13.878 | 4589.8 samples/s | 71.7 steps/s
[Step=89900 Epoch=175.3] | Loss=0.00755 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.710 | L2-Norm(final)=13.881 | 4680.4 samples/s | 73.1 steps/s
[Step=89950 Epoch=175.4] | Loss=0.00748 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=13.883 | 4592.6 samples/s | 71.8 steps/s
[Step=90000 Epoch=175.5] | Loss=0.00748 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.711 | L2-Norm(final)=13.885 | 4631.2 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step90000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=172.0] | Loss=0.00967 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.957 | L2-Norm(final)=14.217 | 6132.2 samples/s | 95.8 steps/s
[Step=88050 Epoch=172.1] | Loss=0.01200 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=14.220 | 4628.2 samples/s | 72.3 steps/s
[Step=88100 Epoch=172.2] | Loss=0.01170 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=14.224 | 5116.2 samples/s | 79.9 steps/s
[Step=88150 Epoch=172.3] | Loss=0.01183 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=14.228 | 5163.6 samples/s | 80.7 steps/s
[Step=88200 Epoch=172.4] | Loss=0.01142 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=14.231 | 5233.7 samples/s | 81.8 steps/s
[Step=88250 Epoch=172.5] | Loss=0.01129 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.967 | L2-Norm(final)=14.235 | 5189.4 samples/s | 81.1 steps/s
[Step=88300 Epoch=172.6] | Loss=0.01106 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=14.238 | 5139.6 samples/s | 80.3 steps/s
[Step=88350 Epoch=172.7] | Loss=0.01096 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.971 | L2-Norm(final)=14.242 | 5322.9 samples/s | 83.2 steps/s
[Step=88400 Epoch=172.8] | Loss=0.01090 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=14.245 | 5122.7 samples/s | 80.0 steps/s
[Step=88450 Epoch=172.9] | Loss=0.01076 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=14.249 | 5140.5 samples/s | 80.3 steps/s
[Step=88500 Epoch=173.0] | Loss=0.01089 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=14.252 | 7155.5 samples/s | 111.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=173.0] | Loss=0.01328 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.993 | L2-Norm(final)=14.285 | 6194.2 samples/s | 96.8 steps/s
[Step=88550 Epoch=173.1] | Loss=0.01033 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=14.288 | 4285.7 samples/s | 67.0 steps/s
[Step=88600 Epoch=173.2] | Loss=0.01062 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.998 | L2-Norm(final)=14.291 | 4507.6 samples/s | 70.4 steps/s
[Step=88650 Epoch=173.3] | Loss=0.01081 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.000 | L2-Norm(final)=14.294 | 4663.3 samples/s | 72.9 steps/s
[Step=88700 Epoch=173.4] | Loss=0.01033 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=14.297 | 4659.3 samples/s | 72.8 steps/s
[Step=88750 Epoch=173.5] | Loss=0.01046 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=14.299 | 4511.9 samples/s | 70.5 steps/s
[Step=88800 Epoch=173.6] | Loss=0.01032 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=14.302 | 4607.8 samples/s | 72.0 steps/s
[Step=88850 Epoch=173.7] | Loss=0.01017 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=14.305 | 4641.9 samples/s | 72.5 steps/s
[Step=88900 Epoch=173.8] | Loss=0.00975 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=14.308 | 4706.3 samples/s | 73.5 steps/s
[Step=88950 Epoch=173.9] | Loss=0.00966 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=14.310 | 4575.1 samples/s | 71.5 steps/s
[Step=89000 Epoch=174.0] | Loss=0.00937 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=14.313 | 6113.6 samples/s | 95.5 steps/s
[Step=89050 Epoch=174.1] | Loss=0.00915 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.016 | L2-Norm(final)=14.315 | 2414.7 samples/s | 37.7 steps/s
[Step=89100 Epoch=174.2] | Loss=0.00892 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.017 | L2-Norm(final)=14.318 | 4599.0 samples/s | 71.9 steps/s
[Step=89150 Epoch=174.3] | Loss=0.00877 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.018 | L2-Norm(final)=14.320 | 4565.3 samples/s | 71.3 steps/s
[Step=89200 Epoch=174.4] | Loss=0.00856 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=14.322 | 4743.9 samples/s | 74.1 steps/s
[Step=89250 Epoch=174.5] | Loss=0.00835 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=14.324 | 4486.7 samples/s | 70.1 steps/s
[Step=89300 Epoch=174.6] | Loss=0.00823 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.022 | L2-Norm(final)=14.327 | 4620.2 samples/s | 72.2 steps/s
[Step=89350 Epoch=174.7] | Loss=0.00808 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.023 | L2-Norm(final)=14.329 | 4633.2 samples/s | 72.4 steps/s
[Step=89400 Epoch=174.8] | Loss=0.00806 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.023 | L2-Norm(final)=14.331 | 4613.6 samples/s | 72.1 steps/s
[Step=89450 Epoch=174.9] | Loss=0.00800 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.024 | L2-Norm(final)=14.333 | 4629.0 samples/s | 72.3 steps/s
[Step=89500 Epoch=175.0] | Loss=0.00796 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.025 | L2-Norm(final)=14.335 | 5117.4 samples/s | 80.0 steps/s
[Step=89550 Epoch=175.1] | Loss=0.00784 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=14.337 | 2628.7 samples/s | 41.1 steps/s
[Step=89600 Epoch=175.2] | Loss=0.00779 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.027 | L2-Norm(final)=14.340 | 4567.7 samples/s | 71.4 steps/s
[Step=89650 Epoch=175.3] | Loss=0.00764 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=14.342 | 4591.9 samples/s | 71.7 steps/s
[Step=89700 Epoch=175.4] | Loss=0.00753 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.028 | L2-Norm(final)=14.344 | 4627.8 samples/s | 72.3 steps/s
[Step=89750 Epoch=175.5] | Loss=0.00743 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=14.346 | 4603.3 samples/s | 71.9 steps/s
[Step=89800 Epoch=175.6] | Loss=0.00739 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.030 | L2-Norm(final)=14.348 | 4632.0 samples/s | 72.4 steps/s
[Step=89850 Epoch=175.7] | Loss=0.00729 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=14.350 | 4726.2 samples/s | 73.8 steps/s
[Step=89900 Epoch=175.8] | Loss=0.00723 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=14.352 | 4529.3 samples/s | 70.8 steps/s
[Step=89950 Epoch=175.8] | Loss=0.00718 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=14.354 | 4607.9 samples/s | 72.0 steps/s
[Step=90000 Epoch=175.9] | Loss=0.00717 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.032 | L2-Norm(final)=14.356 | 4651.6 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step90000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=337.2] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=10.822 | 6130.5 samples/s | 95.8 steps/s
[Step=88050 Epoch=337.4] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.379 | L2-Norm(final)=10.835 | 4402.5 samples/s | 68.8 steps/s
[Step=88100 Epoch=337.6] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.388 | L2-Norm(final)=10.852 | 4924.9 samples/s | 77.0 steps/s
[Step=88150 Epoch=337.8] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.394 | L2-Norm(final)=10.863 | 4922.2 samples/s | 76.9 steps/s
[Step=88200 Epoch=338.0] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.398 | L2-Norm(final)=10.871 | 4829.6 samples/s | 75.5 steps/s
[Step=88250 Epoch=338.1] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.400 | L2-Norm(final)=10.878 | 6863.5 samples/s | 107.2 steps/s
[Step=88300 Epoch=338.3] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.403 | L2-Norm(final)=10.884 | 2436.5 samples/s | 38.1 steps/s
[Step=88350 Epoch=338.5] | Loss=0.00003 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.405 | L2-Norm(final)=10.890 | 5000.5 samples/s | 78.1 steps/s
[Step=88400 Epoch=338.7] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.407 | L2-Norm(final)=10.895 | 4833.4 samples/s | 75.5 steps/s
[Step=88450 Epoch=338.9] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.408 | L2-Norm(final)=10.900 | 4818.1 samples/s | 75.3 steps/s
[Step=88500 Epoch=339.1] | Loss=0.00002 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.409 | L2-Norm(final)=10.905 | 5675.2 samples/s | 88.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=339.1] | Loss=0.00000 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.420 | L2-Norm(final)=10.952 | 5951.4 samples/s | 93.0 steps/s
[Step=88550 Epoch=339.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.410 | L2-Norm(final)=10.955 | 4073.7 samples/s | 63.7 steps/s
[Step=88600 Epoch=339.5] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.398 | L2-Norm(final)=10.958 | 4298.2 samples/s | 67.2 steps/s
[Step=88650 Epoch=339.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.387 | L2-Norm(final)=10.962 | 4382.5 samples/s | 68.5 steps/s
[Step=88700 Epoch=339.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.376 | L2-Norm(final)=10.964 | 4516.1 samples/s | 70.6 steps/s
[Step=88750 Epoch=340.1] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=10.967 | 5650.5 samples/s | 88.3 steps/s
[Step=88800 Epoch=340.3] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.352 | L2-Norm(final)=10.969 | 2308.2 samples/s | 36.1 steps/s
[Step=88850 Epoch=340.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.340 | L2-Norm(final)=10.971 | 4353.4 samples/s | 68.0 steps/s
[Step=88900 Epoch=340.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.327 | L2-Norm(final)=10.973 | 4494.3 samples/s | 70.2 steps/s
[Step=88950 Epoch=340.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.314 | L2-Norm(final)=10.975 | 4292.6 samples/s | 67.1 steps/s
[Step=89000 Epoch=341.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.301 | L2-Norm(final)=10.976 | 4912.1 samples/s | 76.8 steps/s
[Step=89050 Epoch=341.2] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.287 | L2-Norm(final)=10.978 | 2495.2 samples/s | 39.0 steps/s
[Step=89100 Epoch=341.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.274 | L2-Norm(final)=10.979 | 4375.3 samples/s | 68.4 steps/s
[Step=89150 Epoch=341.6] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.260 | L2-Norm(final)=10.980 | 4387.8 samples/s | 68.6 steps/s
[Step=89200 Epoch=341.8] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.246 | L2-Norm(final)=10.982 | 4401.7 samples/s | 68.8 steps/s
[Step=89250 Epoch=342.0] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.232 | L2-Norm(final)=10.983 | 4392.8 samples/s | 68.6 steps/s
[Step=89300 Epoch=342.2] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.218 | L2-Norm(final)=10.984 | 2653.8 samples/s | 41.5 steps/s
[Step=89350 Epoch=342.4] | Loss=0.00000 | Reg=0.00039 | acc=1.0000 | L2-Norm=6.204 | L2-Norm(final)=10.986 | 4321.4 samples/s | 67.5 steps/s
[Step=89400 Epoch=342.5] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.190 | L2-Norm(final)=10.987 | 4519.6 samples/s | 70.6 steps/s
[Step=89450 Epoch=342.7] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=10.988 | 4282.6 samples/s | 66.9 steps/s
[Step=89500 Epoch=342.9] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=10.990 | 4450.1 samples/s | 69.5 steps/s
[Step=89550 Epoch=343.1] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.147 | L2-Norm(final)=10.991 | 2667.7 samples/s | 41.7 steps/s
[Step=89600 Epoch=343.3] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.133 | L2-Norm(final)=10.993 | 4339.3 samples/s | 67.8 steps/s
[Step=89650 Epoch=343.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.118 | L2-Norm(final)=10.994 | 4331.4 samples/s | 67.7 steps/s
[Step=89700 Epoch=343.7] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.104 | L2-Norm(final)=10.996 | 4522.1 samples/s | 70.7 steps/s
[Step=89750 Epoch=343.9] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.089 | L2-Norm(final)=10.998 | 4282.0 samples/s | 66.9 steps/s
[Step=89800 Epoch=344.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.075 | L2-Norm(final)=10.999 | 6483.6 samples/s | 101.3 steps/s
[Step=89850 Epoch=344.3] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.060 | L2-Norm(final)=11.001 | 2226.9 samples/s | 34.8 steps/s
[Step=89900 Epoch=344.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.046 | L2-Norm(final)=11.003 | 4376.6 samples/s | 68.4 steps/s
[Step=89950 Epoch=344.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.031 | L2-Norm(final)=11.005 | 4449.5 samples/s | 69.5 steps/s
[Step=90000 Epoch=344.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.017 | L2-Norm(final)=11.007 | 4332.3 samples/s | 67.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step90000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=338.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.374 | L2-Norm(final)=11.320 | 6623.2 samples/s | 103.5 steps/s
[Step=88050 Epoch=338.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.374 | L2-Norm(final)=11.322 | 4171.3 samples/s | 65.2 steps/s
[Step=88100 Epoch=339.1] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.374 | L2-Norm(final)=11.323 | 4851.8 samples/s | 75.8 steps/s
[Step=88150 Epoch=339.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.375 | L2-Norm(final)=11.326 | 4830.9 samples/s | 75.5 steps/s
[Step=88200 Epoch=339.5] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.376 | L2-Norm(final)=11.328 | 4930.9 samples/s | 77.0 steps/s
[Step=88250 Epoch=339.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.376 | L2-Norm(final)=11.330 | 6966.6 samples/s | 108.9 steps/s
[Step=88300 Epoch=339.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.376 | L2-Norm(final)=11.332 | 2451.7 samples/s | 38.3 steps/s
[Step=88350 Epoch=340.1] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.334 | 4884.2 samples/s | 76.3 steps/s
[Step=88400 Epoch=340.3] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.335 | 4875.4 samples/s | 76.2 steps/s
[Step=88450 Epoch=340.5] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.337 | 4995.6 samples/s | 78.1 steps/s
[Step=88500 Epoch=340.7] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.340 | 5780.4 samples/s | 90.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=340.7] | Loss=0.00004 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.380 | L2-Norm(final)=11.360 | 6289.8 samples/s | 98.3 steps/s
[Step=88550 Epoch=340.9] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.380 | L2-Norm(final)=11.362 | 3879.9 samples/s | 60.6 steps/s
[Step=88600 Epoch=341.1] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.378 | L2-Norm(final)=11.364 | 4439.5 samples/s | 69.4 steps/s
[Step=88650 Epoch=341.2] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.377 | L2-Norm(final)=11.366 | 4420.0 samples/s | 69.1 steps/s
[Step=88700 Epoch=341.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.375 | L2-Norm(final)=11.367 | 4350.1 samples/s | 68.0 steps/s
[Step=88750 Epoch=341.6] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.373 | L2-Norm(final)=11.369 | 5919.7 samples/s | 92.5 steps/s
[Step=88800 Epoch=341.8] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.371 | L2-Norm(final)=11.371 | 2301.6 samples/s | 36.0 steps/s
[Step=88850 Epoch=342.0] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.369 | L2-Norm(final)=11.372 | 4390.8 samples/s | 68.6 steps/s
[Step=88900 Epoch=342.2] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.366 | L2-Norm(final)=11.373 | 4343.2 samples/s | 67.9 steps/s
[Step=88950 Epoch=342.4] | Loss=0.00001 | Reg=0.00041 | acc=1.0000 | L2-Norm=6.364 | L2-Norm(final)=11.375 | 4378.9 samples/s | 68.4 steps/s
[Step=89000 Epoch=342.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.362 | L2-Norm(final)=11.376 | 5111.7 samples/s | 79.9 steps/s
[Step=89050 Epoch=342.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.359 | L2-Norm(final)=11.378 | 2464.5 samples/s | 38.5 steps/s
[Step=89100 Epoch=343.0] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.357 | L2-Norm(final)=11.379 | 4448.6 samples/s | 69.5 steps/s
[Step=89150 Epoch=343.2] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.354 | L2-Norm(final)=11.380 | 4310.8 samples/s | 67.4 steps/s
[Step=89200 Epoch=343.4] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.351 | L2-Norm(final)=11.382 | 4388.9 samples/s | 68.6 steps/s
[Step=89250 Epoch=343.6] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.349 | L2-Norm(final)=11.383 | 4460.8 samples/s | 69.7 steps/s
[Step=89300 Epoch=343.8] | Loss=0.00001 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.346 | L2-Norm(final)=11.384 | 2663.9 samples/s | 41.6 steps/s
[Step=89350 Epoch=343.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.343 | L2-Norm(final)=11.386 | 4337.4 samples/s | 67.8 steps/s
[Step=89400 Epoch=344.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.340 | L2-Norm(final)=11.387 | 4370.1 samples/s | 68.3 steps/s
[Step=89450 Epoch=344.3] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.338 | L2-Norm(final)=11.388 | 4393.1 samples/s | 68.6 steps/s
[Step=89500 Epoch=344.5] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.335 | L2-Norm(final)=11.390 | 4413.5 samples/s | 69.0 steps/s
[Step=89550 Epoch=344.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.332 | L2-Norm(final)=11.391 | 2694.4 samples/s | 42.1 steps/s
[Step=89600 Epoch=344.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.329 | L2-Norm(final)=11.392 | 4422.6 samples/s | 69.1 steps/s
[Step=89650 Epoch=345.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.326 | L2-Norm(final)=11.394 | 4290.3 samples/s | 67.0 steps/s
[Step=89700 Epoch=345.3] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.322 | L2-Norm(final)=11.395 | 4460.9 samples/s | 69.7 steps/s
[Step=89750 Epoch=345.5] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.319 | L2-Norm(final)=11.396 | 4366.1 samples/s | 68.2 steps/s
[Step=89800 Epoch=345.7] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.316 | L2-Norm(final)=11.398 | 7043.8 samples/s | 110.1 steps/s
[Step=89850 Epoch=345.9] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.313 | L2-Norm(final)=11.399 | 2180.0 samples/s | 34.1 steps/s
[Step=89900 Epoch=346.1] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.309 | L2-Norm(final)=11.401 | 4395.6 samples/s | 68.7 steps/s
[Step=89950 Epoch=346.3] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.306 | L2-Norm(final)=11.402 | 4379.3 samples/s | 68.4 steps/s
[Step=90000 Epoch=346.4] | Loss=0.00000 | Reg=0.00040 | acc=1.0000 | L2-Norm=6.303 | L2-Norm(final)=11.403 | 4338.6 samples/s | 67.8 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07150 | acc=0.9672 | tpr=0.9770 | fpr=0.0540 | 5088.2 samples/s | 19.9 steps/s
Avg test loss: 0.07366, Avg test acc: 0.96590, Avg tpr: 0.97599, Avg fpr: 0.05627, total FA: 439

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07167 | acc=0.9670 | tpr=0.9757 | fpr=0.0518 | 5217.0 samples/s | 20.4 steps/s
Avg test loss: 0.07281, Avg test acc: 0.96710, Avg tpr: 0.97587, Avg fpr: 0.05217, total FA: 407

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.41384 | acc=0.3137 | tpr=0.0033 | fpr=0.0124 | 5545.3 samples/s | 21.7 steps/s
Avg test loss: 5.42447, Avg test acc: 0.31104, Avg tpr: 0.00373, Avg fpr: 0.01308, total FA: 102

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.26331 | acc=0.3082 | tpr=0.0070 | fpr=0.0377 | 5254.8 samples/s | 20.5 steps/s
Avg test loss: 5.26754, Avg test acc: 0.30660, Avg tpr: 0.00711, Avg fpr: 0.03474, total FA: 271

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.39907 | acc=0.1219 | tpr=0.7566 | fpr=0.8895 | 5100.9 samples/s | 19.9 steps/s
[Step= 100] | Loss=5.38292 | acc=0.1224 | tpr=0.7441 | fpr=0.8892 | 7585.4 samples/s | 29.6 steps/s
[Step= 150] | Loss=5.38241 | acc=0.1228 | tpr=0.7565 | fpr=0.8889 | 7540.9 samples/s | 29.5 steps/s
[Step= 200] | Loss=5.39034 | acc=0.1219 | tpr=0.7508 | fpr=0.8896 | 8096.0 samples/s | 31.6 steps/s
[Step= 250] | Loss=5.40112 | acc=0.1219 | tpr=0.7371 | fpr=0.8893 | 8421.1 samples/s | 32.9 steps/s
[Step= 300] | Loss=5.40323 | acc=0.1212 | tpr=0.7375 | fpr=0.8901 | 8207.7 samples/s | 32.1 steps/s
[Step= 350] | Loss=5.39377 | acc=0.1211 | tpr=0.7370 | fpr=0.8900 | 8205.3 samples/s | 32.1 steps/s
[Step= 400] | Loss=5.38652 | acc=0.1214 | tpr=0.7412 | fpr=0.8899 | 7919.3 samples/s | 30.9 steps/s
[Step= 450] | Loss=5.38927 | acc=0.1209 | tpr=0.7429 | fpr=0.8904 | 7992.3 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.38907 | acc=0.1207 | tpr=0.7436 | fpr=0.8906 | 8216.2 samples/s | 32.1 steps/s
[Step= 550] | Loss=5.38712 | acc=0.1208 | tpr=0.7405 | fpr=0.8905 | 14471.9 samples/s | 56.5 steps/s
Avg test loss: 5.38828, Avg test acc: 0.12073, Avg tpr: 0.74010, Avg fpr: 0.89053, total FA: 123648

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.53283 | acc=0.1323 | tpr=0.7124 | fpr=0.8782 | 5212.9 samples/s | 20.4 steps/s
[Step= 100] | Loss=5.52062 | acc=0.1314 | tpr=0.7122 | fpr=0.8794 | 7342.9 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.51009 | acc=0.1318 | tpr=0.7320 | fpr=0.8793 | 7739.1 samples/s | 30.2 steps/s
[Step= 200] | Loss=5.51844 | acc=0.1314 | tpr=0.7355 | fpr=0.8796 | 8282.8 samples/s | 32.4 steps/s
[Step= 250] | Loss=5.52844 | acc=0.1316 | tpr=0.7284 | fpr=0.8793 | 7849.0 samples/s | 30.7 steps/s
[Step= 300] | Loss=5.53151 | acc=0.1316 | tpr=0.7273 | fpr=0.8793 | 8258.5 samples/s | 32.3 steps/s
[Step= 350] | Loss=5.51884 | acc=0.1315 | tpr=0.7226 | fpr=0.8793 | 8253.3 samples/s | 32.2 steps/s
[Step= 400] | Loss=5.51163 | acc=0.1317 | tpr=0.7248 | fpr=0.8790 | 8088.3 samples/s | 31.6 steps/s
[Step= 450] | Loss=5.51247 | acc=0.1311 | tpr=0.7254 | fpr=0.8797 | 8091.7 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.51450 | acc=0.1309 | tpr=0.7229 | fpr=0.8798 | 8415.4 samples/s | 32.9 steps/s
[Step= 550] | Loss=5.51161 | acc=0.1310 | tpr=0.7191 | fpr=0.8797 | 14261.8 samples/s | 55.7 steps/s
Avg test loss: 5.51299, Avg test acc: 0.13096, Avg tpr: 0.71949, Avg fpr: 0.87974, total FA: 122150

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11383 | acc=0.9790 | tpr=0.9646 | fpr=0.0208 | 5381.4 samples/s | 21.0 steps/s
[Step= 100] | Loss=0.11935 | acc=0.9779 | tpr=0.9723 | fpr=0.0220 | 6731.5 samples/s | 26.3 steps/s
[Step= 150] | Loss=0.12498 | acc=0.9768 | tpr=0.9640 | fpr=0.0229 | 8090.9 samples/s | 31.6 steps/s
[Step= 200] | Loss=0.12661 | acc=0.9770 | tpr=0.9639 | fpr=0.0227 | 8183.4 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.12443 | acc=0.9773 | tpr=0.9659 | fpr=0.0225 | 7959.8 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.12651 | acc=0.9768 | tpr=0.9644 | fpr=0.0229 | 8579.3 samples/s | 33.5 steps/s
[Step= 350] | Loss=0.12724 | acc=0.9765 | tpr=0.9649 | fpr=0.0233 | 7548.6 samples/s | 29.5 steps/s
[Step= 400] | Loss=0.12818 | acc=0.9764 | tpr=0.9633 | fpr=0.0234 | 8405.5 samples/s | 32.8 steps/s
[Step= 450] | Loss=0.13067 | acc=0.9760 | tpr=0.9625 | fpr=0.0237 | 8399.7 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.13016 | acc=0.9761 | tpr=0.9630 | fpr=0.0237 | 7971.2 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12931 | acc=0.9762 | tpr=0.9626 | fpr=0.0235 | 14259.9 samples/s | 55.7 steps/s
Avg test loss: 0.12896, Avg test acc: 0.97626, Avg tpr: 0.96276, Avg fpr: 0.02349, total FA: 3262

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12237 | acc=0.9788 | tpr=0.9513 | fpr=0.0208 | 5278.9 samples/s | 20.6 steps/s
[Step= 100] | Loss=0.12827 | acc=0.9778 | tpr=0.9616 | fpr=0.0219 | 7253.5 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.13402 | acc=0.9768 | tpr=0.9640 | fpr=0.0230 | 7623.5 samples/s | 29.8 steps/s
[Step= 200] | Loss=0.13584 | acc=0.9768 | tpr=0.9650 | fpr=0.0230 | 8327.8 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.13351 | acc=0.9772 | tpr=0.9677 | fpr=0.0227 | 8025.1 samples/s | 31.3 steps/s
[Step= 300] | Loss=0.13591 | acc=0.9768 | tpr=0.9673 | fpr=0.0230 | 8306.2 samples/s | 32.4 steps/s
[Step= 350] | Loss=0.13682 | acc=0.9765 | tpr=0.9681 | fpr=0.0233 | 8015.8 samples/s | 31.3 steps/s
[Step= 400] | Loss=0.13792 | acc=0.9763 | tpr=0.9666 | fpr=0.0235 | 8081.8 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.14082 | acc=0.9758 | tpr=0.9654 | fpr=0.0240 | 7723.8 samples/s | 30.2 steps/s
[Step= 500] | Loss=0.14015 | acc=0.9759 | tpr=0.9661 | fpr=0.0240 | 8463.0 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.13897 | acc=0.9761 | tpr=0.9658 | fpr=0.0238 | 14225.0 samples/s | 55.6 steps/s
Avg test loss: 0.13861, Avg test acc: 0.97608, Avg tpr: 0.96513, Avg fpr: 0.02372, total FA: 3293

server round 45/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=175.5] | Loss=0.01473 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.606 | L2-Norm(final)=13.947 | 6295.9 samples/s | 98.4 steps/s
[Step=90050 Epoch=175.6] | Loss=0.01488 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.606 | L2-Norm(final)=13.949 | 4837.8 samples/s | 75.6 steps/s
[Step=90100 Epoch=175.7] | Loss=0.01385 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.608 | L2-Norm(final)=13.951 | 5153.3 samples/s | 80.5 steps/s
[Step=90150 Epoch=175.8] | Loss=0.01358 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.610 | L2-Norm(final)=13.954 | 5253.3 samples/s | 82.1 steps/s
[Step=90200 Epoch=175.9] | Loss=0.01388 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.612 | L2-Norm(final)=13.957 | 5171.0 samples/s | 80.8 steps/s
[Step=90250 Epoch=176.0] | Loss=0.01400 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.614 | L2-Norm(final)=13.960 | 5195.6 samples/s | 81.2 steps/s
[Step=90300 Epoch=176.1] | Loss=0.01386 | Reg=0.00214 | acc=0.9688 | L2-Norm=14.615 | L2-Norm(final)=13.964 | 5159.4 samples/s | 80.6 steps/s
[Step=90350 Epoch=176.2] | Loss=0.01387 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.617 | L2-Norm(final)=13.967 | 5253.6 samples/s | 82.1 steps/s
[Step=90400 Epoch=176.3] | Loss=0.01366 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=13.970 | 5139.7 samples/s | 80.3 steps/s
[Step=90450 Epoch=176.4] | Loss=0.01343 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.620 | L2-Norm(final)=13.973 | 5197.6 samples/s | 81.2 steps/s
[Step=90500 Epoch=176.5] | Loss=0.01340 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.622 | L2-Norm(final)=13.976 | 6920.7 samples/s | 108.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=176.5] | Loss=0.01778 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.637 | L2-Norm(final)=14.007 | 6210.6 samples/s | 97.0 steps/s
[Step=90550 Epoch=176.6] | Loss=0.01403 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.640 | L2-Norm(final)=14.010 | 4332.9 samples/s | 67.7 steps/s
[Step=90600 Epoch=176.7] | Loss=0.01236 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=14.013 | 4586.3 samples/s | 71.7 steps/s
[Step=90650 Epoch=176.8] | Loss=0.01222 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=14.016 | 4569.6 samples/s | 71.4 steps/s
[Step=90700 Epoch=176.9] | Loss=0.01270 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.647 | L2-Norm(final)=14.018 | 4636.9 samples/s | 72.5 steps/s
[Step=90750 Epoch=177.0] | Loss=0.01215 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.649 | L2-Norm(final)=14.021 | 4623.4 samples/s | 72.2 steps/s
[Step=90800 Epoch=177.1] | Loss=0.01172 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=14.024 | 4599.0 samples/s | 71.9 steps/s
[Step=90850 Epoch=177.2] | Loss=0.01162 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.653 | L2-Norm(final)=14.026 | 4632.4 samples/s | 72.4 steps/s
[Step=90900 Epoch=177.3] | Loss=0.01160 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.655 | L2-Norm(final)=14.029 | 4628.7 samples/s | 72.3 steps/s
[Step=90950 Epoch=177.4] | Loss=0.01123 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=14.032 | 4631.2 samples/s | 72.4 steps/s
[Step=91000 Epoch=177.5] | Loss=0.01115 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.658 | L2-Norm(final)=14.034 | 5964.0 samples/s | 93.2 steps/s
[Step=91050 Epoch=177.6] | Loss=0.01074 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=14.037 | 2439.0 samples/s | 38.1 steps/s
[Step=91100 Epoch=177.7] | Loss=0.01034 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=14.039 | 4662.3 samples/s | 72.8 steps/s
[Step=91150 Epoch=177.8] | Loss=0.01007 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=14.042 | 4636.5 samples/s | 72.4 steps/s
[Step=91200 Epoch=177.9] | Loss=0.00988 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=14.044 | 4652.0 samples/s | 72.7 steps/s
[Step=91250 Epoch=178.0] | Loss=0.00968 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=14.046 | 4557.0 samples/s | 71.2 steps/s
[Step=91300 Epoch=178.1] | Loss=0.00963 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=14.049 | 4655.7 samples/s | 72.7 steps/s
[Step=91350 Epoch=178.2] | Loss=0.00947 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.668 | L2-Norm(final)=14.051 | 4590.5 samples/s | 71.7 steps/s
[Step=91400 Epoch=178.3] | Loss=0.00931 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=14.053 | 4615.8 samples/s | 72.1 steps/s
[Step=91450 Epoch=178.4] | Loss=0.00923 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=14.055 | 4636.2 samples/s | 72.4 steps/s
[Step=91500 Epoch=178.5] | Loss=0.00922 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.671 | L2-Norm(final)=14.058 | 4974.1 samples/s | 77.7 steps/s
[Step=91550 Epoch=178.6] | Loss=0.00907 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.672 | L2-Norm(final)=14.060 | 2671.5 samples/s | 41.7 steps/s
[Step=91600 Epoch=178.7] | Loss=0.00890 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=14.062 | 4651.4 samples/s | 72.7 steps/s
[Step=91650 Epoch=178.8] | Loss=0.00880 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=14.064 | 4582.0 samples/s | 71.6 steps/s
[Step=91700 Epoch=178.9] | Loss=0.00867 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=14.066 | 4618.7 samples/s | 72.2 steps/s
[Step=91750 Epoch=178.9] | Loss=0.00864 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.675 | L2-Norm(final)=14.068 | 4618.6 samples/s | 72.2 steps/s
[Step=91800 Epoch=179.0] | Loss=0.00859 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.676 | L2-Norm(final)=14.070 | 4612.9 samples/s | 72.1 steps/s
[Step=91850 Epoch=179.1] | Loss=0.00856 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.677 | L2-Norm(final)=14.072 | 4610.8 samples/s | 72.0 steps/s
[Step=91900 Epoch=179.2] | Loss=0.00846 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=14.074 | 4647.1 samples/s | 72.6 steps/s
[Step=91950 Epoch=179.3] | Loss=0.00838 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.678 | L2-Norm(final)=14.076 | 4646.8 samples/s | 72.6 steps/s
[Step=92000 Epoch=179.4] | Loss=0.00830 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.679 | L2-Norm(final)=14.078 | 4612.7 samples/s | 72.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step92000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=175.9] | Loss=0.02797 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.926 | L2-Norm(final)=14.416 | 6742.2 samples/s | 105.3 steps/s
[Step=90050 Epoch=176.0] | Loss=0.01446 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.927 | L2-Norm(final)=14.418 | 4485.4 samples/s | 70.1 steps/s
[Step=90100 Epoch=176.1] | Loss=0.01469 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.930 | L2-Norm(final)=14.421 | 5203.2 samples/s | 81.3 steps/s
[Step=90150 Epoch=176.2] | Loss=0.01392 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.932 | L2-Norm(final)=14.425 | 5191.3 samples/s | 81.1 steps/s
[Step=90200 Epoch=176.3] | Loss=0.01385 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.934 | L2-Norm(final)=14.428 | 5275.1 samples/s | 82.4 steps/s
[Step=90250 Epoch=176.4] | Loss=0.01331 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=14.431 | 5260.7 samples/s | 82.2 steps/s
[Step=90300 Epoch=176.5] | Loss=0.01328 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=14.435 | 5014.5 samples/s | 78.4 steps/s
[Step=90350 Epoch=176.6] | Loss=0.01315 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=14.438 | 5250.5 samples/s | 82.0 steps/s
[Step=90400 Epoch=176.7] | Loss=0.01306 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.940 | L2-Norm(final)=14.441 | 5180.0 samples/s | 80.9 steps/s
[Step=90450 Epoch=176.8] | Loss=0.01314 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.942 | L2-Norm(final)=14.444 | 5271.0 samples/s | 82.4 steps/s
[Step=90500 Epoch=176.9] | Loss=0.01322 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.944 | L2-Norm(final)=14.448 | 7019.6 samples/s | 109.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=176.9] | Loss=0.00815 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=14.480 | 6135.0 samples/s | 95.9 steps/s
[Step=90550 Epoch=177.0] | Loss=0.01549 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.964 | L2-Norm(final)=14.483 | 4267.0 samples/s | 66.7 steps/s
[Step=90600 Epoch=177.1] | Loss=0.01421 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=14.485 | 4502.3 samples/s | 70.3 steps/s
[Step=90650 Epoch=177.2] | Loss=0.01300 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=14.488 | 4644.4 samples/s | 72.6 steps/s
[Step=90700 Epoch=177.3] | Loss=0.01240 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=14.490 | 4592.8 samples/s | 71.8 steps/s
[Step=90750 Epoch=177.4] | Loss=0.01221 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=14.493 | 4605.5 samples/s | 72.0 steps/s
[Step=90800 Epoch=177.5] | Loss=0.01204 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.976 | L2-Norm(final)=14.495 | 4662.7 samples/s | 72.9 steps/s
[Step=90850 Epoch=177.6] | Loss=0.01163 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=14.498 | 4602.7 samples/s | 71.9 steps/s
[Step=90900 Epoch=177.7] | Loss=0.01153 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.980 | L2-Norm(final)=14.500 | 4683.8 samples/s | 73.2 steps/s
[Step=90950 Epoch=177.8] | Loss=0.01117 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.982 | L2-Norm(final)=14.503 | 4560.2 samples/s | 71.3 steps/s
[Step=91000 Epoch=177.9] | Loss=0.01094 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.983 | L2-Norm(final)=14.505 | 6044.9 samples/s | 94.5 steps/s
[Step=91050 Epoch=178.0] | Loss=0.01051 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.985 | L2-Norm(final)=14.508 | 2420.7 samples/s | 37.8 steps/s
[Step=91100 Epoch=178.1] | Loss=0.01020 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.986 | L2-Norm(final)=14.510 | 4647.4 samples/s | 72.6 steps/s
[Step=91150 Epoch=178.2] | Loss=0.00989 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.987 | L2-Norm(final)=14.512 | 4628.1 samples/s | 72.3 steps/s
[Step=91200 Epoch=178.3] | Loss=0.00977 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.989 | L2-Norm(final)=14.515 | 4557.2 samples/s | 71.2 steps/s
[Step=91250 Epoch=178.4] | Loss=0.00957 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.990 | L2-Norm(final)=14.517 | 4645.9 samples/s | 72.6 steps/s
[Step=91300 Epoch=178.5] | Loss=0.00937 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=14.519 | 4680.1 samples/s | 73.1 steps/s
[Step=91350 Epoch=178.6] | Loss=0.00925 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=14.521 | 4535.0 samples/s | 70.9 steps/s
[Step=91400 Epoch=178.7] | Loss=0.00908 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.993 | L2-Norm(final)=14.523 | 4675.2 samples/s | 73.1 steps/s
[Step=91450 Epoch=178.8] | Loss=0.00903 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.994 | L2-Norm(final)=14.525 | 4601.9 samples/s | 71.9 steps/s
[Step=91500 Epoch=178.9] | Loss=0.00904 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.995 | L2-Norm(final)=14.528 | 5097.5 samples/s | 79.6 steps/s
[Step=91550 Epoch=179.0] | Loss=0.00893 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.996 | L2-Norm(final)=14.530 | 2661.6 samples/s | 41.6 steps/s
[Step=91600 Epoch=179.1] | Loss=0.00875 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.997 | L2-Norm(final)=14.532 | 4655.3 samples/s | 72.7 steps/s
[Step=91650 Epoch=179.2] | Loss=0.00855 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=14.534 | 4488.1 samples/s | 70.1 steps/s
[Step=91700 Epoch=179.3] | Loss=0.00842 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.999 | L2-Norm(final)=14.536 | 4628.2 samples/s | 72.3 steps/s
[Step=91750 Epoch=179.4] | Loss=0.00834 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=14.538 | 4639.2 samples/s | 72.5 steps/s
[Step=91800 Epoch=179.5] | Loss=0.00828 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=14.540 | 4700.2 samples/s | 73.4 steps/s
[Step=91850 Epoch=179.6] | Loss=0.00818 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.001 | L2-Norm(final)=14.542 | 4567.3 samples/s | 71.4 steps/s
[Step=91900 Epoch=179.7] | Loss=0.00814 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=14.544 | 4657.5 samples/s | 72.8 steps/s
[Step=91950 Epoch=179.8] | Loss=0.00812 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=14.546 | 4656.2 samples/s | 72.8 steps/s
[Step=92000 Epoch=179.9] | Loss=0.00805 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=14.548 | 4589.5 samples/s | 71.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step92000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=344.9] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.165 | L2-Norm(final)=11.064 | 6486.8 samples/s | 101.4 steps/s
[Step=90050 Epoch=345.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.166 | L2-Norm(final)=11.076 | 4262.4 samples/s | 66.6 steps/s
[Step=90100 Epoch=345.2] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.170 | L2-Norm(final)=11.087 | 4793.0 samples/s | 74.9 steps/s
[Step=90150 Epoch=345.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.173 | L2-Norm(final)=11.097 | 4989.6 samples/s | 78.0 steps/s
[Step=90200 Epoch=345.6] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=11.106 | 4986.0 samples/s | 77.9 steps/s
[Step=90250 Epoch=345.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.178 | L2-Norm(final)=11.114 | 6574.3 samples/s | 102.7 steps/s
[Step=90300 Epoch=346.0] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.180 | L2-Norm(final)=11.122 | 2462.1 samples/s | 38.5 steps/s
[Step=90350 Epoch=346.2] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.182 | L2-Norm(final)=11.130 | 4868.5 samples/s | 76.1 steps/s
[Step=90400 Epoch=346.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.183 | L2-Norm(final)=11.137 | 4932.4 samples/s | 77.1 steps/s
[Step=90450 Epoch=346.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.185 | L2-Norm(final)=11.145 | 4957.7 samples/s | 77.5 steps/s
[Step=90500 Epoch=346.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.186 | L2-Norm(final)=11.152 | 5601.9 samples/s | 87.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=346.8] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.196 | L2-Norm(final)=11.220 | 6211.6 samples/s | 97.1 steps/s
[Step=90550 Epoch=347.0] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.188 | L2-Norm(final)=11.227 | 3923.7 samples/s | 61.3 steps/s
[Step=90600 Epoch=347.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.174 | L2-Norm(final)=11.232 | 4378.5 samples/s | 68.4 steps/s
[Step=90650 Epoch=347.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.158 | L2-Norm(final)=11.236 | 4406.6 samples/s | 68.9 steps/s
[Step=90700 Epoch=347.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.142 | L2-Norm(final)=11.240 | 4536.8 samples/s | 70.9 steps/s
[Step=90750 Epoch=347.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.127 | L2-Norm(final)=11.244 | 5632.2 samples/s | 88.0 steps/s
[Step=90800 Epoch=347.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.248 | 2321.4 samples/s | 36.3 steps/s
[Step=90850 Epoch=348.1] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.111 | L2-Norm(final)=11.254 | 4488.9 samples/s | 70.1 steps/s
[Step=90900 Epoch=348.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.106 | L2-Norm(final)=11.258 | 4279.3 samples/s | 66.9 steps/s
[Step=90950 Epoch=348.5] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.102 | L2-Norm(final)=11.261 | 4444.6 samples/s | 69.4 steps/s
[Step=91000 Epoch=348.7] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.099 | L2-Norm(final)=11.264 | 4886.2 samples/s | 76.3 steps/s
[Step=91050 Epoch=348.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.096 | L2-Norm(final)=11.266 | 2532.1 samples/s | 39.6 steps/s
[Step=91100 Epoch=349.1] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.093 | L2-Norm(final)=11.269 | 4423.4 samples/s | 69.1 steps/s
[Step=91150 Epoch=349.3] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.090 | L2-Norm(final)=11.270 | 4264.2 samples/s | 66.6 steps/s
[Step=91200 Epoch=349.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.272 | 4360.7 samples/s | 68.1 steps/s
[Step=91250 Epoch=349.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.085 | L2-Norm(final)=11.274 | 4378.4 samples/s | 68.4 steps/s
[Step=91300 Epoch=349.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.082 | L2-Norm(final)=11.275 | 2696.9 samples/s | 42.1 steps/s
[Step=91350 Epoch=350.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.080 | L2-Norm(final)=11.277 | 4344.5 samples/s | 67.9 steps/s
[Step=91400 Epoch=350.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.077 | L2-Norm(final)=11.278 | 4425.7 samples/s | 69.2 steps/s
[Step=91450 Epoch=350.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.075 | L2-Norm(final)=11.279 | 4385.0 samples/s | 68.5 steps/s
[Step=91500 Epoch=350.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.072 | L2-Norm(final)=11.280 | 4327.6 samples/s | 67.6 steps/s
[Step=91550 Epoch=350.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.070 | L2-Norm(final)=11.281 | 2690.6 samples/s | 42.0 steps/s
[Step=91600 Epoch=351.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=11.282 | 4373.9 samples/s | 68.3 steps/s
[Step=91650 Epoch=351.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.065 | L2-Norm(final)=11.283 | 4387.1 samples/s | 68.5 steps/s
[Step=91700 Epoch=351.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.062 | L2-Norm(final)=11.284 | 4450.8 samples/s | 69.5 steps/s
[Step=91750 Epoch=351.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.060 | L2-Norm(final)=11.285 | 4333.4 samples/s | 67.7 steps/s
[Step=91800 Epoch=351.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=11.286 | 6568.2 samples/s | 102.6 steps/s
[Step=91850 Epoch=351.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.055 | L2-Norm(final)=11.286 | 2242.8 samples/s | 35.0 steps/s
[Step=91900 Epoch=352.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.052 | L2-Norm(final)=11.287 | 4419.5 samples/s | 69.1 steps/s
[Step=91950 Epoch=352.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.049 | L2-Norm(final)=11.288 | 4350.7 samples/s | 68.0 steps/s
[Step=92000 Epoch=352.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.047 | L2-Norm(final)=11.289 | 4381.2 samples/s | 68.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step92000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=346.4] | Loss=0.00000 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.152 | L2-Norm(final)=11.446 | 6107.3 samples/s | 95.4 steps/s
[Step=90050 Epoch=346.6] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.155 | L2-Norm(final)=11.454 | 4402.3 samples/s | 68.8 steps/s
[Step=90100 Epoch=346.8] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.160 | L2-Norm(final)=11.464 | 5031.8 samples/s | 78.6 steps/s
[Step=90150 Epoch=347.0] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.164 | L2-Norm(final)=11.472 | 4799.7 samples/s | 75.0 steps/s
[Step=90200 Epoch=347.2] | Loss=0.00003 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=11.480 | 4866.3 samples/s | 76.0 steps/s
[Step=90250 Epoch=347.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.169 | L2-Norm(final)=11.487 | 6954.5 samples/s | 108.7 steps/s
[Step=90300 Epoch=347.6] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.171 | L2-Norm(final)=11.494 | 2431.6 samples/s | 38.0 steps/s
[Step=90350 Epoch=347.8] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.173 | L2-Norm(final)=11.500 | 4995.7 samples/s | 78.1 steps/s
[Step=90400 Epoch=348.0] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.174 | L2-Norm(final)=11.506 | 4816.2 samples/s | 75.3 steps/s
[Step=90450 Epoch=348.2] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=11.512 | 4939.8 samples/s | 77.2 steps/s
[Step=90500 Epoch=348.4] | Loss=0.00002 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.177 | L2-Norm(final)=11.517 | 5844.0 samples/s | 91.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=348.4] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.189 | L2-Norm(final)=11.574 | 6252.8 samples/s | 97.7 steps/s
[Step=90550 Epoch=348.6] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.187 | L2-Norm(final)=11.579 | 3887.7 samples/s | 60.7 steps/s
[Step=90600 Epoch=348.8] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.184 | L2-Norm(final)=11.583 | 4403.0 samples/s | 68.8 steps/s
[Step=90650 Epoch=348.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.181 | L2-Norm(final)=11.587 | 4455.8 samples/s | 69.6 steps/s
[Step=90700 Epoch=349.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.176 | L2-Norm(final)=11.590 | 4348.2 samples/s | 67.9 steps/s
[Step=90750 Epoch=349.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.172 | L2-Norm(final)=11.593 | 5913.0 samples/s | 92.4 steps/s
[Step=90800 Epoch=349.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.167 | L2-Norm(final)=11.597 | 2328.2 samples/s | 36.4 steps/s
[Step=90850 Epoch=349.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.162 | L2-Norm(final)=11.600 | 4302.5 samples/s | 67.2 steps/s
[Step=90900 Epoch=349.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.157 | L2-Norm(final)=11.602 | 4455.8 samples/s | 69.6 steps/s
[Step=90950 Epoch=350.1] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.152 | L2-Norm(final)=11.605 | 4327.1 samples/s | 67.6 steps/s
[Step=91000 Epoch=350.3] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.146 | L2-Norm(final)=11.607 | 5116.5 samples/s | 79.9 steps/s
[Step=91050 Epoch=350.5] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.140 | L2-Norm(final)=11.610 | 2460.4 samples/s | 38.4 steps/s
[Step=91100 Epoch=350.7] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.134 | L2-Norm(final)=11.612 | 4401.1 samples/s | 68.8 steps/s
[Step=91150 Epoch=350.9] | Loss=0.00001 | Reg=0.00038 | acc=1.0000 | L2-Norm=6.128 | L2-Norm(final)=11.614 | 4442.2 samples/s | 69.4 steps/s
[Step=91200 Epoch=351.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.122 | L2-Norm(final)=11.617 | 4309.1 samples/s | 67.3 steps/s
[Step=91250 Epoch=351.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.116 | L2-Norm(final)=11.619 | 4468.0 samples/s | 69.8 steps/s
[Step=91300 Epoch=351.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.110 | L2-Norm(final)=11.621 | 2638.4 samples/s | 41.2 steps/s
[Step=91350 Epoch=351.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.103 | L2-Norm(final)=11.623 | 4374.0 samples/s | 68.3 steps/s
[Step=91400 Epoch=351.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.097 | L2-Norm(final)=11.626 | 4392.4 samples/s | 68.6 steps/s
[Step=91450 Epoch=352.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.090 | L2-Norm(final)=11.628 | 4450.5 samples/s | 69.5 steps/s
[Step=91500 Epoch=352.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.084 | L2-Norm(final)=11.630 | 4278.2 samples/s | 66.8 steps/s
[Step=91550 Epoch=352.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.077 | L2-Norm(final)=11.632 | 2701.1 samples/s | 42.2 steps/s
[Step=91600 Epoch=352.6] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.070 | L2-Norm(final)=11.635 | 4367.8 samples/s | 68.2 steps/s
[Step=91650 Epoch=352.8] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.064 | L2-Norm(final)=11.637 | 4388.3 samples/s | 68.6 steps/s
[Step=91700 Epoch=353.0] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=11.639 | 4354.8 samples/s | 68.0 steps/s
[Step=91750 Epoch=353.2] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.050 | L2-Norm(final)=11.642 | 4428.4 samples/s | 69.2 steps/s
[Step=91800 Epoch=353.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.644 | 7180.1 samples/s | 112.2 steps/s
[Step=91850 Epoch=353.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.036 | L2-Norm(final)=11.647 | 2175.3 samples/s | 34.0 steps/s
[Step=91900 Epoch=353.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.029 | L2-Norm(final)=11.649 | 4330.1 samples/s | 67.7 steps/s
[Step=91950 Epoch=354.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.021 | L2-Norm(final)=11.652 | 4395.5 samples/s | 68.7 steps/s
[Step=92000 Epoch=354.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.014 | L2-Norm(final)=11.654 | 4493.7 samples/s | 70.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07093 | acc=0.9654 | tpr=0.9723 | fpr=0.0496 | 5038.2 samples/s | 19.7 steps/s
Avg test loss: 0.07235, Avg test acc: 0.96462, Avg tpr: 0.97208, Avg fpr: 0.05179, total FA: 404

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07100 | acc=0.9663 | tpr=0.9798 | fpr=0.0632 | 5156.1 samples/s | 20.1 steps/s
Avg test loss: 0.07253, Avg test acc: 0.96658, Avg tpr: 0.97972, Avg fpr: 0.06230, total FA: 486

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.72240 | acc=0.3137 | tpr=0.0026 | fpr=0.0109 | 5192.1 samples/s | 20.3 steps/s
Avg test loss: 5.73687, Avg test acc: 0.31116, Avg tpr: 0.00280, Avg fpr: 0.01064, total FA: 83

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.33851 | acc=0.3095 | tpr=0.0070 | fpr=0.0337 | 5365.3 samples/s | 21.0 steps/s
Avg test loss: 5.34356, Avg test acc: 0.30744, Avg tpr: 0.00705, Avg fpr: 0.03192, total FA: 249

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.05327 | acc=0.1284 | tpr=0.7212 | fpr=0.8823 | 5421.6 samples/s | 21.2 steps/s
[Step= 100] | Loss=5.03807 | acc=0.1279 | tpr=0.7079 | fpr=0.8829 | 6662.5 samples/s | 26.0 steps/s
[Step= 150] | Loss=5.03752 | acc=0.1279 | tpr=0.7305 | fpr=0.8831 | 8215.5 samples/s | 32.1 steps/s
[Step= 200] | Loss=5.04638 | acc=0.1271 | tpr=0.7246 | fpr=0.8838 | 8441.2 samples/s | 33.0 steps/s
[Step= 250] | Loss=5.05724 | acc=0.1271 | tpr=0.7127 | fpr=0.8836 | 7994.3 samples/s | 31.2 steps/s
[Step= 300] | Loss=5.05864 | acc=0.1264 | tpr=0.7164 | fpr=0.8844 | 8360.6 samples/s | 32.7 steps/s
[Step= 350] | Loss=5.04953 | acc=0.1262 | tpr=0.7107 | fpr=0.8844 | 8036.6 samples/s | 31.4 steps/s
[Step= 400] | Loss=5.04242 | acc=0.1264 | tpr=0.7144 | fpr=0.8843 | 8014.8 samples/s | 31.3 steps/s
[Step= 450] | Loss=5.04485 | acc=0.1258 | tpr=0.7167 | fpr=0.8849 | 8285.1 samples/s | 32.4 steps/s
[Step= 500] | Loss=5.04484 | acc=0.1254 | tpr=0.7167 | fpr=0.8853 | 8079.3 samples/s | 31.6 steps/s
[Step= 550] | Loss=5.04306 | acc=0.1253 | tpr=0.7127 | fpr=0.8853 | 14064.9 samples/s | 54.9 steps/s
Avg test loss: 5.04412, Avg test acc: 0.12527, Avg tpr: 0.71236, Avg fpr: 0.88540, total FA: 122936

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.42028 | acc=0.1273 | tpr=0.7434 | fpr=0.8837 | 5476.4 samples/s | 21.4 steps/s
[Step= 100] | Loss=5.40870 | acc=0.1270 | tpr=0.7292 | fpr=0.8843 | 7346.7 samples/s | 28.7 steps/s
[Step= 150] | Loss=5.39790 | acc=0.1276 | tpr=0.7478 | fpr=0.8838 | 7452.9 samples/s | 29.1 steps/s
[Step= 200] | Loss=5.40617 | acc=0.1271 | tpr=0.7552 | fpr=0.8844 | 7946.4 samples/s | 31.0 steps/s
[Step= 250] | Loss=5.41641 | acc=0.1273 | tpr=0.7476 | fpr=0.8840 | 8320.4 samples/s | 32.5 steps/s
[Step= 300] | Loss=5.41895 | acc=0.1274 | tpr=0.7455 | fpr=0.8839 | 7812.9 samples/s | 30.5 steps/s
[Step= 350] | Loss=5.40650 | acc=0.1272 | tpr=0.7439 | fpr=0.8839 | 8409.2 samples/s | 32.8 steps/s
[Step= 400] | Loss=5.39970 | acc=0.1274 | tpr=0.7440 | fpr=0.8838 | 7793.7 samples/s | 30.4 steps/s
[Step= 450] | Loss=5.40104 | acc=0.1269 | tpr=0.7444 | fpr=0.8843 | 8089.9 samples/s | 31.6 steps/s
[Step= 500] | Loss=5.40306 | acc=0.1267 | tpr=0.7436 | fpr=0.8844 | 8539.8 samples/s | 33.4 steps/s
[Step= 550] | Loss=5.40039 | acc=0.1268 | tpr=0.7398 | fpr=0.8843 | 14922.5 samples/s | 58.3 steps/s
Avg test loss: 5.40173, Avg test acc: 0.12679, Avg tpr: 0.74010, Avg fpr: 0.88436, total FA: 122791

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11048 | acc=0.9805 | tpr=0.9513 | fpr=0.0189 | 5272.2 samples/s | 20.6 steps/s
[Step= 100] | Loss=0.11563 | acc=0.9795 | tpr=0.9616 | fpr=0.0202 | 7403.4 samples/s | 28.9 steps/s
[Step= 150] | Loss=0.12099 | acc=0.9784 | tpr=0.9582 | fpr=0.0212 | 7579.0 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.12276 | acc=0.9784 | tpr=0.9607 | fpr=0.0213 | 7964.9 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.12071 | acc=0.9786 | tpr=0.9633 | fpr=0.0211 | 8625.7 samples/s | 33.7 steps/s
[Step= 300] | Loss=0.12270 | acc=0.9782 | tpr=0.9629 | fpr=0.0216 | 8086.7 samples/s | 31.6 steps/s
[Step= 350] | Loss=0.12316 | acc=0.9779 | tpr=0.9643 | fpr=0.0218 | 8271.7 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.12424 | acc=0.9778 | tpr=0.9623 | fpr=0.0219 | 8019.8 samples/s | 31.3 steps/s
[Step= 450] | Loss=0.12665 | acc=0.9774 | tpr=0.9611 | fpr=0.0223 | 8154.6 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.12606 | acc=0.9775 | tpr=0.9608 | fpr=0.0222 | 8006.4 samples/s | 31.3 steps/s
[Step= 550] | Loss=0.12507 | acc=0.9776 | tpr=0.9606 | fpr=0.0221 | 14558.2 samples/s | 56.9 steps/s
Avg test loss: 0.12474, Avg test acc: 0.97761, Avg tpr: 0.96038, Avg fpr: 0.02207, total FA: 3065

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12023 | acc=0.9791 | tpr=0.9558 | fpr=0.0205 | 5412.3 samples/s | 21.1 steps/s
[Step= 100] | Loss=0.12587 | acc=0.9779 | tpr=0.9638 | fpr=0.0219 | 7242.8 samples/s | 28.3 steps/s
[Step= 150] | Loss=0.13174 | acc=0.9769 | tpr=0.9669 | fpr=0.0229 | 7427.4 samples/s | 29.0 steps/s
[Step= 200] | Loss=0.13350 | acc=0.9767 | tpr=0.9683 | fpr=0.0231 | 8311.1 samples/s | 32.5 steps/s
[Step= 250] | Loss=0.13120 | acc=0.9771 | tpr=0.9703 | fpr=0.0228 | 8085.9 samples/s | 31.6 steps/s
[Step= 300] | Loss=0.13356 | acc=0.9768 | tpr=0.9695 | fpr=0.0231 | 8370.5 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.13443 | acc=0.9764 | tpr=0.9693 | fpr=0.0235 | 7920.3 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.13546 | acc=0.9762 | tpr=0.9683 | fpr=0.0236 | 8221.2 samples/s | 32.1 steps/s
[Step= 450] | Loss=0.13824 | acc=0.9757 | tpr=0.9679 | fpr=0.0242 | 8050.4 samples/s | 31.4 steps/s
[Step= 500] | Loss=0.13764 | acc=0.9757 | tpr=0.9683 | fpr=0.0242 | 8160.6 samples/s | 31.9 steps/s
[Step= 550] | Loss=0.13646 | acc=0.9759 | tpr=0.9678 | fpr=0.0239 | 14751.8 samples/s | 57.6 steps/s
Avg test loss: 0.13611, Avg test acc: 0.97593, Avg tpr: 0.96712, Avg fpr: 0.02391, total FA: 3320

server round 46/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=179.4] | Loss=0.02411 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.617 | L2-Norm(final)=14.139 | 6272.1 samples/s | 98.0 steps/s
[Step=92050 Epoch=179.5] | Loss=0.01571 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.619 | L2-Norm(final)=14.141 | 4687.2 samples/s | 73.2 steps/s
[Step=92100 Epoch=179.6] | Loss=0.01379 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.620 | L2-Norm(final)=14.145 | 5138.6 samples/s | 80.3 steps/s
[Step=92150 Epoch=179.7] | Loss=0.01314 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.622 | L2-Norm(final)=14.148 | 5159.0 samples/s | 80.6 steps/s
[Step=92200 Epoch=179.8] | Loss=0.01325 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=14.152 | 5395.4 samples/s | 84.3 steps/s
[Step=92250 Epoch=179.9] | Loss=0.01342 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.625 | L2-Norm(final)=14.155 | 5045.5 samples/s | 78.8 steps/s
[Step=92300 Epoch=180.0] | Loss=0.01379 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=14.158 | 5185.5 samples/s | 81.0 steps/s
[Step=92350 Epoch=180.1] | Loss=0.01360 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.628 | L2-Norm(final)=14.161 | 5251.3 samples/s | 82.1 steps/s
[Step=92400 Epoch=180.2] | Loss=0.01332 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.630 | L2-Norm(final)=14.163 | 5171.0 samples/s | 80.8 steps/s
[Step=92450 Epoch=180.3] | Loss=0.01325 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=14.166 | 5190.9 samples/s | 81.1 steps/s
[Step=92500 Epoch=180.4] | Loss=0.01332 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.634 | L2-Norm(final)=14.169 | 6990.3 samples/s | 109.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=180.4] | Loss=0.01094 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=14.199 | 6973.3 samples/s | 109.0 steps/s
[Step=92550 Epoch=180.5] | Loss=0.01226 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=14.202 | 3928.2 samples/s | 61.4 steps/s
[Step=92600 Epoch=180.6] | Loss=0.01315 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.653 | L2-Norm(final)=14.205 | 4577.6 samples/s | 71.5 steps/s
[Step=92650 Epoch=180.7] | Loss=0.01263 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.656 | L2-Norm(final)=14.207 | 4647.6 samples/s | 72.6 steps/s
[Step=92700 Epoch=180.8] | Loss=0.01243 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=14.210 | 4574.1 samples/s | 71.5 steps/s
[Step=92750 Epoch=180.9] | Loss=0.01200 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.660 | L2-Norm(final)=14.213 | 4619.1 samples/s | 72.2 steps/s
[Step=92800 Epoch=181.0] | Loss=0.01197 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.662 | L2-Norm(final)=14.215 | 4621.6 samples/s | 72.2 steps/s
[Step=92850 Epoch=181.1] | Loss=0.01158 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=14.218 | 4621.2 samples/s | 72.2 steps/s
[Step=92900 Epoch=181.2] | Loss=0.01127 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=14.221 | 4644.3 samples/s | 72.6 steps/s
[Step=92950 Epoch=181.3] | Loss=0.01116 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.667 | L2-Norm(final)=14.223 | 4656.7 samples/s | 72.8 steps/s
[Step=93000 Epoch=181.4] | Loss=0.01112 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.669 | L2-Norm(final)=14.226 | 5892.5 samples/s | 92.1 steps/s
[Step=93050 Epoch=181.5] | Loss=0.01075 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=14.228 | 2486.2 samples/s | 38.8 steps/s
[Step=93100 Epoch=181.6] | Loss=0.01046 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.671 | L2-Norm(final)=14.231 | 4491.8 samples/s | 70.2 steps/s
[Step=93150 Epoch=181.7] | Loss=0.01015 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.673 | L2-Norm(final)=14.233 | 4643.0 samples/s | 72.5 steps/s
[Step=93200 Epoch=181.8] | Loss=0.01007 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=14.235 | 4561.3 samples/s | 71.3 steps/s
[Step=93250 Epoch=181.9] | Loss=0.01005 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.675 | L2-Norm(final)=14.237 | 4613.8 samples/s | 72.1 steps/s
[Step=93300 Epoch=182.0] | Loss=0.00995 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.676 | L2-Norm(final)=14.240 | 4633.4 samples/s | 72.4 steps/s
[Step=93350 Epoch=182.1] | Loss=0.00974 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.677 | L2-Norm(final)=14.242 | 4608.9 samples/s | 72.0 steps/s
[Step=93400 Epoch=182.2] | Loss=0.00964 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=14.244 | 4622.2 samples/s | 72.2 steps/s
[Step=93450 Epoch=182.3] | Loss=0.00944 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.679 | L2-Norm(final)=14.246 | 4694.5 samples/s | 73.4 steps/s
[Step=93500 Epoch=182.4] | Loss=0.00928 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.680 | L2-Norm(final)=14.249 | 4893.3 samples/s | 76.5 steps/s
[Step=93550 Epoch=182.5] | Loss=0.00910 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=14.251 | 2670.9 samples/s | 41.7 steps/s
[Step=93600 Epoch=182.6] | Loss=0.00892 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.682 | L2-Norm(final)=14.253 | 4637.2 samples/s | 72.5 steps/s
[Step=93650 Epoch=182.7] | Loss=0.00886 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.683 | L2-Norm(final)=14.255 | 4582.1 samples/s | 71.6 steps/s
[Step=93700 Epoch=182.8] | Loss=0.00879 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=14.257 | 4627.7 samples/s | 72.3 steps/s
[Step=93750 Epoch=182.8] | Loss=0.00871 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.684 | L2-Norm(final)=14.259 | 4553.1 samples/s | 71.1 steps/s
[Step=93800 Epoch=182.9] | Loss=0.00862 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.685 | L2-Norm(final)=14.261 | 4492.5 samples/s | 70.2 steps/s
[Step=93850 Epoch=183.0] | Loss=0.00852 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.686 | L2-Norm(final)=14.263 | 4574.9 samples/s | 71.5 steps/s
[Step=93900 Epoch=183.1] | Loss=0.00846 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.687 | L2-Norm(final)=14.265 | 4640.5 samples/s | 72.5 steps/s
[Step=93950 Epoch=183.2] | Loss=0.00840 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.687 | L2-Norm(final)=14.268 | 4644.6 samples/s | 72.6 steps/s
[Step=94000 Epoch=183.3] | Loss=0.00835 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.688 | L2-Norm(final)=14.270 | 4598.8 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step94000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=179.9] | Loss=0.01336 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.943 | L2-Norm(final)=14.607 | 6470.0 samples/s | 101.1 steps/s
[Step=92050 Epoch=180.0] | Loss=0.01489 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.945 | L2-Norm(final)=14.609 | 4654.9 samples/s | 72.7 steps/s
[Step=92100 Epoch=180.1] | Loss=0.01453 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.947 | L2-Norm(final)=14.612 | 5196.6 samples/s | 81.2 steps/s
[Step=92150 Epoch=180.2] | Loss=0.01345 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.949 | L2-Norm(final)=14.615 | 5172.3 samples/s | 80.8 steps/s
[Step=92200 Epoch=180.2] | Loss=0.01348 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=14.618 | 5168.2 samples/s | 80.8 steps/s
[Step=92250 Epoch=180.3] | Loss=0.01350 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=14.621 | 5124.5 samples/s | 80.1 steps/s
[Step=92300 Epoch=180.4] | Loss=0.01362 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=14.624 | 5204.5 samples/s | 81.3 steps/s
[Step=92350 Epoch=180.5] | Loss=0.01340 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=14.627 | 5222.3 samples/s | 81.6 steps/s
[Step=92400 Epoch=180.6] | Loss=0.01340 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.958 | L2-Norm(final)=14.631 | 5216.9 samples/s | 81.5 steps/s
[Step=92450 Epoch=180.7] | Loss=0.01318 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.960 | L2-Norm(final)=14.634 | 5207.3 samples/s | 81.4 steps/s
[Step=92500 Epoch=180.8] | Loss=0.01310 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=14.637 | 7108.6 samples/s | 111.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=180.8] | Loss=0.00246 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=14.668 | 7084.7 samples/s | 110.7 steps/s
[Step=92550 Epoch=180.9] | Loss=0.01452 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=14.671 | 3946.5 samples/s | 61.7 steps/s
[Step=92600 Epoch=181.0] | Loss=0.01308 | Reg=0.00225 | acc=0.9688 | L2-Norm=14.986 | L2-Norm(final)=14.674 | 4595.7 samples/s | 71.8 steps/s
[Step=92650 Epoch=181.1] | Loss=0.01233 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.988 | L2-Norm(final)=14.677 | 4634.2 samples/s | 72.4 steps/s
[Step=92700 Epoch=181.2] | Loss=0.01207 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=14.679 | 4646.5 samples/s | 72.6 steps/s
[Step=92750 Epoch=181.3] | Loss=0.01184 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=14.681 | 4563.2 samples/s | 71.3 steps/s
[Step=92800 Epoch=181.4] | Loss=0.01162 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.994 | L2-Norm(final)=14.684 | 4674.2 samples/s | 73.0 steps/s
[Step=92850 Epoch=181.5] | Loss=0.01147 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.996 | L2-Norm(final)=14.686 | 4747.8 samples/s | 74.2 steps/s
[Step=92900 Epoch=181.6] | Loss=0.01135 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=14.689 | 4502.1 samples/s | 70.3 steps/s
[Step=92950 Epoch=181.7] | Loss=0.01120 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=14.691 | 4598.3 samples/s | 71.8 steps/s
[Step=93000 Epoch=181.8] | Loss=0.01126 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.001 | L2-Norm(final)=14.694 | 6067.7 samples/s | 94.8 steps/s
[Step=93050 Epoch=181.9] | Loss=0.01092 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=14.696 | 2428.1 samples/s | 37.9 steps/s
[Step=93100 Epoch=182.0] | Loss=0.01055 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=14.698 | 4619.0 samples/s | 72.2 steps/s
[Step=93150 Epoch=182.1] | Loss=0.01018 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.005 | L2-Norm(final)=14.701 | 4613.9 samples/s | 72.1 steps/s
[Step=93200 Epoch=182.2] | Loss=0.00989 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=14.703 | 4573.6 samples/s | 71.5 steps/s
[Step=93250 Epoch=182.3] | Loss=0.00972 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=14.705 | 4627.9 samples/s | 72.3 steps/s
[Step=93300 Epoch=182.4] | Loss=0.00956 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=14.707 | 4581.1 samples/s | 71.6 steps/s
[Step=93350 Epoch=182.5] | Loss=0.00947 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.009 | L2-Norm(final)=14.709 | 4679.8 samples/s | 73.1 steps/s
[Step=93400 Epoch=182.6] | Loss=0.00940 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.010 | L2-Norm(final)=14.712 | 4643.9 samples/s | 72.6 steps/s
[Step=93450 Epoch=182.7] | Loss=0.00925 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.011 | L2-Norm(final)=14.714 | 4515.8 samples/s | 70.6 steps/s
[Step=93500 Epoch=182.8] | Loss=0.00916 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.012 | L2-Norm(final)=14.716 | 5130.0 samples/s | 80.2 steps/s
[Step=93550 Epoch=182.9] | Loss=0.00903 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.013 | L2-Norm(final)=14.718 | 2620.8 samples/s | 41.0 steps/s
[Step=93600 Epoch=183.0] | Loss=0.00884 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.014 | L2-Norm(final)=14.720 | 4651.1 samples/s | 72.7 steps/s
[Step=93650 Epoch=183.1] | Loss=0.00872 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.015 | L2-Norm(final)=14.722 | 4552.3 samples/s | 71.1 steps/s
[Step=93700 Epoch=183.2] | Loss=0.00858 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.016 | L2-Norm(final)=14.724 | 4655.8 samples/s | 72.7 steps/s
[Step=93750 Epoch=183.3] | Loss=0.00850 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.017 | L2-Norm(final)=14.727 | 4635.6 samples/s | 72.4 steps/s
[Step=93800 Epoch=183.4] | Loss=0.00840 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.018 | L2-Norm(final)=14.729 | 4558.0 samples/s | 71.2 steps/s
[Step=93850 Epoch=183.5] | Loss=0.00829 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.019 | L2-Norm(final)=14.731 | 4604.1 samples/s | 71.9 steps/s
[Step=93900 Epoch=183.6] | Loss=0.00823 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.019 | L2-Norm(final)=14.733 | 4650.3 samples/s | 72.7 steps/s
[Step=93950 Epoch=183.7] | Loss=0.00817 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.020 | L2-Norm(final)=14.735 | 4599.7 samples/s | 71.9 steps/s
[Step=94000 Epoch=183.8] | Loss=0.00809 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.021 | L2-Norm(final)=14.737 | 4636.4 samples/s | 72.4 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step94000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=352.5] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=11.312 | 6041.5 samples/s | 94.4 steps/s
[Step=92050 Epoch=352.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=11.314 | 4459.5 samples/s | 69.7 steps/s
[Step=92100 Epoch=352.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.083 | L2-Norm(final)=11.318 | 4864.8 samples/s | 76.0 steps/s
[Step=92150 Epoch=353.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.084 | L2-Norm(final)=11.321 | 4933.8 samples/s | 77.1 steps/s
[Step=92200 Epoch=353.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.085 | L2-Norm(final)=11.325 | 4838.3 samples/s | 75.6 steps/s
[Step=92250 Epoch=353.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=11.329 | 6875.7 samples/s | 107.4 steps/s
[Step=92300 Epoch=353.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.086 | L2-Norm(final)=11.333 | 2493.8 samples/s | 39.0 steps/s
[Step=92350 Epoch=353.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.087 | L2-Norm(final)=11.336 | 4849.4 samples/s | 75.8 steps/s
[Step=92400 Epoch=354.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.088 | L2-Norm(final)=11.340 | 4854.5 samples/s | 75.9 steps/s
[Step=92450 Epoch=354.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.088 | L2-Norm(final)=11.343 | 4983.1 samples/s | 77.9 steps/s
[Step=92500 Epoch=354.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.089 | L2-Norm(final)=11.347 | 5520.9 samples/s | 86.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=354.4] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.094 | L2-Norm(final)=11.382 | 6740.7 samples/s | 105.3 steps/s
[Step=92550 Epoch=354.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.093 | L2-Norm(final)=11.385 | 3763.6 samples/s | 58.8 steps/s
[Step=92600 Epoch=354.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.091 | L2-Norm(final)=11.388 | 4356.2 samples/s | 68.1 steps/s
[Step=92650 Epoch=355.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.088 | L2-Norm(final)=11.390 | 4394.0 samples/s | 68.7 steps/s
[Step=92700 Epoch=355.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.084 | L2-Norm(final)=11.393 | 4369.1 samples/s | 68.3 steps/s
[Step=92750 Epoch=355.4] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.081 | L2-Norm(final)=11.395 | 5863.3 samples/s | 91.6 steps/s
[Step=92800 Epoch=355.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.078 | L2-Norm(final)=11.398 | 2318.5 samples/s | 36.2 steps/s
[Step=92850 Epoch=355.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.075 | L2-Norm(final)=11.400 | 4398.7 samples/s | 68.7 steps/s
[Step=92900 Epoch=356.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.071 | L2-Norm(final)=11.402 | 4430.7 samples/s | 69.2 steps/s
[Step=92950 Epoch=356.2] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.068 | L2-Norm(final)=11.404 | 4371.6 samples/s | 68.3 steps/s
[Step=93000 Epoch=356.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.064 | L2-Norm(final)=11.406 | 4855.3 samples/s | 75.9 steps/s
[Step=93050 Epoch=356.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.060 | L2-Norm(final)=11.408 | 2498.4 samples/s | 39.0 steps/s
[Step=93100 Epoch=356.7] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.056 | L2-Norm(final)=11.410 | 4390.6 samples/s | 68.6 steps/s
[Step=93150 Epoch=356.9] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.052 | L2-Norm(final)=11.412 | 4343.7 samples/s | 67.9 steps/s
[Step=93200 Epoch=357.1] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.048 | L2-Norm(final)=11.414 | 4448.5 samples/s | 69.5 steps/s
[Step=93250 Epoch=357.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.044 | L2-Norm(final)=11.416 | 4342.6 samples/s | 67.9 steps/s
[Step=93300 Epoch=357.5] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.039 | L2-Norm(final)=11.418 | 2716.5 samples/s | 42.4 steps/s
[Step=93350 Epoch=357.7] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.035 | L2-Norm(final)=11.420 | 4300.7 samples/s | 67.2 steps/s
[Step=93400 Epoch=357.9] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.030 | L2-Norm(final)=11.422 | 4434.4 samples/s | 69.3 steps/s
[Step=93450 Epoch=358.1] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.026 | L2-Norm(final)=11.423 | 4323.9 samples/s | 67.6 steps/s
[Step=93500 Epoch=358.3] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.021 | L2-Norm(final)=11.425 | 4406.8 samples/s | 68.9 steps/s
[Step=93550 Epoch=358.5] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.017 | L2-Norm(final)=11.427 | 2668.3 samples/s | 41.7 steps/s
[Step=93600 Epoch=358.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.012 | L2-Norm(final)=11.429 | 4419.8 samples/s | 69.1 steps/s
[Step=93650 Epoch=358.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.007 | L2-Norm(final)=11.431 | 4396.2 samples/s | 68.7 steps/s
[Step=93700 Epoch=359.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.002 | L2-Norm(final)=11.433 | 4423.5 samples/s | 69.1 steps/s
[Step=93750 Epoch=359.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.997 | L2-Norm(final)=11.435 | 4283.8 samples/s | 66.9 steps/s
[Step=93800 Epoch=359.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.992 | L2-Norm(final)=11.437 | 6525.9 samples/s | 102.0 steps/s
[Step=93850 Epoch=359.6] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.987 | L2-Norm(final)=11.439 | 2216.1 samples/s | 34.6 steps/s
[Step=93900 Epoch=359.8] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.982 | L2-Norm(final)=11.441 | 4451.8 samples/s | 69.6 steps/s
[Step=93950 Epoch=360.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.977 | L2-Norm(final)=11.443 | 4333.6 samples/s | 67.7 steps/s
[Step=94000 Epoch=360.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.972 | L2-Norm(final)=11.445 | 4349.6 samples/s | 68.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step94000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=354.1] | Loss=0.00003 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.040 | L2-Norm(final)=11.735 | 6033.5 samples/s | 94.3 steps/s
[Step=92050 Epoch=354.3] | Loss=0.00008 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.049 | L2-Norm(final)=11.753 | 4427.6 samples/s | 69.2 steps/s
[Step=92100 Epoch=354.5] | Loss=0.00005 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.057 | L2-Norm(final)=11.766 | 5043.5 samples/s | 78.8 steps/s
[Step=92150 Epoch=354.7] | Loss=0.00004 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.062 | L2-Norm(final)=11.775 | 4795.4 samples/s | 74.9 steps/s
[Step=92200 Epoch=354.9] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.065 | L2-Norm(final)=11.782 | 4943.9 samples/s | 77.2 steps/s
[Step=92250 Epoch=355.1] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.067 | L2-Norm(final)=11.788 | 6929.8 samples/s | 108.3 steps/s
[Step=92300 Epoch=355.3] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.068 | L2-Norm(final)=11.793 | 2489.3 samples/s | 38.9 steps/s
[Step=92350 Epoch=355.5] | Loss=0.00003 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.070 | L2-Norm(final)=11.798 | 4838.7 samples/s | 75.6 steps/s
[Step=92400 Epoch=355.7] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.071 | L2-Norm(final)=11.804 | 4800.7 samples/s | 75.0 steps/s
[Step=92450 Epoch=355.9] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.072 | L2-Norm(final)=11.809 | 4912.9 samples/s | 76.8 steps/s
[Step=92500 Epoch=356.1] | Loss=0.00002 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.073 | L2-Norm(final)=11.814 | 5833.9 samples/s | 91.2 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=356.1] | Loss=0.00000 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.085 | L2-Norm(final)=11.864 | 6140.6 samples/s | 95.9 steps/s
[Step=92550 Epoch=356.3] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.079 | L2-Norm(final)=11.868 | 4002.1 samples/s | 62.5 steps/s
[Step=92600 Epoch=356.5] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.071 | L2-Norm(final)=11.871 | 4353.2 samples/s | 68.0 steps/s
[Step=92650 Epoch=356.6] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.061 | L2-Norm(final)=11.873 | 4386.4 samples/s | 68.5 steps/s
[Step=92700 Epoch=356.8] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.052 | L2-Norm(final)=11.876 | 4426.1 samples/s | 69.2 steps/s
[Step=92750 Epoch=357.0] | Loss=0.00001 | Reg=0.00037 | acc=1.0000 | L2-Norm=6.043 | L2-Norm(final)=11.879 | 5920.2 samples/s | 92.5 steps/s
[Step=92800 Epoch=357.2] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.033 | L2-Norm(final)=11.881 | 2315.6 samples/s | 36.2 steps/s
[Step=92850 Epoch=357.4] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.023 | L2-Norm(final)=11.883 | 4450.0 samples/s | 69.5 steps/s
[Step=92900 Epoch=357.6] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.013 | L2-Norm(final)=11.885 | 4271.8 samples/s | 66.7 steps/s
[Step=92950 Epoch=357.8] | Loss=0.00001 | Reg=0.00036 | acc=1.0000 | L2-Norm=6.002 | L2-Norm(final)=11.887 | 4410.0 samples/s | 68.9 steps/s
[Step=93000 Epoch=358.0] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.991 | L2-Norm(final)=11.889 | 5073.4 samples/s | 79.3 steps/s
[Step=93050 Epoch=358.2] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.980 | L2-Norm(final)=11.891 | 2505.0 samples/s | 39.1 steps/s
[Step=93100 Epoch=358.4] | Loss=0.00000 | Reg=0.00036 | acc=1.0000 | L2-Norm=5.969 | L2-Norm(final)=11.893 | 4285.5 samples/s | 67.0 steps/s
[Step=93150 Epoch=358.6] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.957 | L2-Norm(final)=11.894 | 4330.9 samples/s | 67.7 steps/s
[Step=93200 Epoch=358.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.946 | L2-Norm(final)=11.896 | 4371.7 samples/s | 68.3 steps/s
[Step=93250 Epoch=359.0] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.934 | L2-Norm(final)=11.898 | 4466.2 samples/s | 69.8 steps/s
[Step=93300 Epoch=359.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.923 | L2-Norm(final)=11.899 | 2661.4 samples/s | 41.6 steps/s
[Step=93350 Epoch=359.3] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.911 | L2-Norm(final)=11.901 | 4433.5 samples/s | 69.3 steps/s
[Step=93400 Epoch=359.5] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.900 | L2-Norm(final)=11.903 | 4363.0 samples/s | 68.2 steps/s
[Step=93450 Epoch=359.7] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.888 | L2-Norm(final)=11.905 | 4442.6 samples/s | 69.4 steps/s
[Step=93500 Epoch=359.9] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.876 | L2-Norm(final)=11.907 | 4370.1 samples/s | 68.3 steps/s
[Step=93550 Epoch=360.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.864 | L2-Norm(final)=11.909 | 2642.7 samples/s | 41.3 steps/s
[Step=93600 Epoch=360.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.852 | L2-Norm(final)=11.910 | 4387.7 samples/s | 68.6 steps/s
[Step=93650 Epoch=360.5] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.840 | L2-Norm(final)=11.912 | 4396.9 samples/s | 68.7 steps/s
[Step=93700 Epoch=360.7] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.828 | L2-Norm(final)=11.914 | 4410.2 samples/s | 68.9 steps/s
[Step=93750 Epoch=360.9] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.816 | L2-Norm(final)=11.917 | 4504.9 samples/s | 70.4 steps/s
[Step=93800 Epoch=361.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.804 | L2-Norm(final)=11.919 | 6853.2 samples/s | 107.1 steps/s
[Step=93850 Epoch=361.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.792 | L2-Norm(final)=11.921 | 2157.5 samples/s | 33.7 steps/s
[Step=93900 Epoch=361.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.780 | L2-Norm(final)=11.923 | 4445.7 samples/s | 69.5 steps/s
[Step=93950 Epoch=361.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.768 | L2-Norm(final)=11.925 | 4299.8 samples/s | 67.2 steps/s
[Step=94000 Epoch=361.8] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.755 | L2-Norm(final)=11.928 | 4461.1 samples/s | 69.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06875 | acc=0.9650 | tpr=0.9702 | fpr=0.0463 | 5192.1 samples/s | 20.3 steps/s
Avg test loss: 0.07070, Avg test acc: 0.96474, Avg tpr: 0.97004, Avg fpr: 0.04692, total FA: 366

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.07143 | acc=0.9664 | tpr=0.9733 | fpr=0.0486 | 5140.2 samples/s | 20.1 steps/s
Avg test loss: 0.07270, Avg test acc: 0.96606, Avg tpr: 0.97278, Avg fpr: 0.04871, total FA: 380

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.52275 | acc=0.3133 | tpr=0.0033 | fpr=0.0136 | 5093.3 samples/s | 19.9 steps/s
Avg test loss: 5.53349, Avg test acc: 0.31096, Avg tpr: 0.00350, Avg fpr: 0.01282, total FA: 100

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.14983 | acc=0.3091 | tpr=0.0081 | fpr=0.0372 | 5230.6 samples/s | 20.4 steps/s
Avg test loss: 5.15236, Avg test acc: 0.30720, Avg tpr: 0.00863, Avg fpr: 0.03615, total FA: 282

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.88762 | acc=0.1303 | tpr=0.7257 | fpr=0.8804 | 5269.1 samples/s | 20.6 steps/s
[Step= 100] | Loss=4.87343 | acc=0.1296 | tpr=0.6994 | fpr=0.8810 | 6704.7 samples/s | 26.2 steps/s
[Step= 150] | Loss=4.87248 | acc=0.1301 | tpr=0.7248 | fpr=0.8808 | 7934.5 samples/s | 31.0 steps/s
[Step= 200] | Loss=4.87979 | acc=0.1297 | tpr=0.7191 | fpr=0.8810 | 7845.5 samples/s | 30.6 steps/s
[Step= 250] | Loss=4.89068 | acc=0.1297 | tpr=0.7100 | fpr=0.8808 | 6963.0 samples/s | 27.2 steps/s
[Step= 300] | Loss=4.89261 | acc=0.1292 | tpr=0.7098 | fpr=0.8813 | 7326.2 samples/s | 28.6 steps/s
[Step= 350] | Loss=4.88369 | acc=0.1289 | tpr=0.7070 | fpr=0.8815 | 8028.2 samples/s | 31.4 steps/s
[Step= 400] | Loss=4.87684 | acc=0.1292 | tpr=0.7112 | fpr=0.8814 | 8111.8 samples/s | 31.7 steps/s
[Step= 450] | Loss=4.87909 | acc=0.1286 | tpr=0.7118 | fpr=0.8820 | 8127.2 samples/s | 31.7 steps/s
[Step= 500] | Loss=4.87889 | acc=0.1282 | tpr=0.7101 | fpr=0.8823 | 8573.4 samples/s | 33.5 steps/s
[Step= 550] | Loss=4.87699 | acc=0.1282 | tpr=0.7067 | fpr=0.8823 | 13543.2 samples/s | 52.9 steps/s
Avg test loss: 4.87802, Avg test acc: 0.12809, Avg tpr: 0.70642, Avg fpr: 0.88242, total FA: 122522

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.19848 | acc=0.1399 | tpr=0.7035 | fpr=0.8702 | 5383.0 samples/s | 21.0 steps/s
[Step= 100] | Loss=5.18631 | acc=0.1381 | tpr=0.7015 | fpr=0.8724 | 6747.5 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.17662 | acc=0.1390 | tpr=0.7205 | fpr=0.8717 | 8023.1 samples/s | 31.3 steps/s
[Step= 200] | Loss=5.18381 | acc=0.1390 | tpr=0.7213 | fpr=0.8716 | 8185.2 samples/s | 32.0 steps/s
[Step= 250] | Loss=5.19369 | acc=0.1390 | tpr=0.7092 | fpr=0.8714 | 6348.5 samples/s | 24.8 steps/s
[Step= 300] | Loss=5.19683 | acc=0.1389 | tpr=0.7069 | fpr=0.8714 | 8179.8 samples/s | 32.0 steps/s
[Step= 350] | Loss=5.18445 | acc=0.1391 | tpr=0.7044 | fpr=0.8712 | 8183.0 samples/s | 32.0 steps/s
[Step= 400] | Loss=5.17748 | acc=0.1392 | tpr=0.7035 | fpr=0.8711 | 7851.5 samples/s | 30.7 steps/s
[Step= 450] | Loss=5.17892 | acc=0.1385 | tpr=0.7040 | fpr=0.8717 | 8440.6 samples/s | 33.0 steps/s
[Step= 500] | Loss=5.18056 | acc=0.1384 | tpr=0.7026 | fpr=0.8718 | 8166.9 samples/s | 31.9 steps/s
[Step= 550] | Loss=5.17787 | acc=0.1384 | tpr=0.6984 | fpr=0.8718 | 14281.1 samples/s | 55.8 steps/s
Avg test loss: 5.17919, Avg test acc: 0.13830, Avg tpr: 0.69810, Avg fpr: 0.87187, total FA: 121058

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11115 | acc=0.9798 | tpr=0.9513 | fpr=0.0197 | 5308.9 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.11622 | acc=0.9787 | tpr=0.9638 | fpr=0.0210 | 7197.5 samples/s | 28.1 steps/s
[Step= 150] | Loss=0.12141 | acc=0.9777 | tpr=0.9597 | fpr=0.0220 | 7646.1 samples/s | 29.9 steps/s
[Step= 200] | Loss=0.12309 | acc=0.9778 | tpr=0.9617 | fpr=0.0220 | 8335.8 samples/s | 32.6 steps/s
[Step= 250] | Loss=0.12115 | acc=0.9780 | tpr=0.9642 | fpr=0.0218 | 5984.1 samples/s | 23.4 steps/s
[Step= 300] | Loss=0.12319 | acc=0.9776 | tpr=0.9629 | fpr=0.0221 | 7833.1 samples/s | 30.6 steps/s
[Step= 350] | Loss=0.12382 | acc=0.9773 | tpr=0.9643 | fpr=0.0224 | 8247.5 samples/s | 32.2 steps/s
[Step= 400] | Loss=0.12483 | acc=0.9772 | tpr=0.9623 | fpr=0.0226 | 7963.9 samples/s | 31.1 steps/s
[Step= 450] | Loss=0.12728 | acc=0.9767 | tpr=0.9615 | fpr=0.0230 | 8313.2 samples/s | 32.5 steps/s
[Step= 500] | Loss=0.12671 | acc=0.9767 | tpr=0.9612 | fpr=0.0230 | 7796.5 samples/s | 30.5 steps/s
[Step= 550] | Loss=0.12579 | acc=0.9769 | tpr=0.9606 | fpr=0.0228 | 14481.2 samples/s | 56.6 steps/s
Avg test loss: 0.12545, Avg test acc: 0.97693, Avg tpr: 0.96078, Avg fpr: 0.02278, total FA: 3163

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.12227 | acc=0.9770 | tpr=0.9646 | fpr=0.0227 | 5187.2 samples/s | 20.3 steps/s
[Step= 100] | Loss=0.12802 | acc=0.9764 | tpr=0.9723 | fpr=0.0235 | 7418.8 samples/s | 29.0 steps/s
[Step= 150] | Loss=0.13417 | acc=0.9753 | tpr=0.9741 | fpr=0.0246 | 7679.8 samples/s | 30.0 steps/s
[Step= 200] | Loss=0.13607 | acc=0.9751 | tpr=0.9760 | fpr=0.0249 | 6083.1 samples/s | 23.8 steps/s
[Step= 250] | Loss=0.13398 | acc=0.9754 | tpr=0.9764 | fpr=0.0246 | 7735.0 samples/s | 30.2 steps/s
[Step= 300] | Loss=0.13633 | acc=0.9750 | tpr=0.9745 | fpr=0.0250 | 8201.0 samples/s | 32.0 steps/s
[Step= 350] | Loss=0.13730 | acc=0.9747 | tpr=0.9750 | fpr=0.0253 | 7916.2 samples/s | 30.9 steps/s
[Step= 400] | Loss=0.13837 | acc=0.9745 | tpr=0.9737 | fpr=0.0255 | 8364.7 samples/s | 32.7 steps/s
[Step= 450] | Loss=0.14113 | acc=0.9740 | tpr=0.9732 | fpr=0.0260 | 8124.7 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.14056 | acc=0.9741 | tpr=0.9740 | fpr=0.0259 | 7966.3 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.13932 | acc=0.9742 | tpr=0.9741 | fpr=0.0258 | 14345.1 samples/s | 56.0 steps/s
Avg test loss: 0.13899, Avg test acc: 0.97427, Avg tpr: 0.97425, Avg fpr: 0.02573, total FA: 3573

server round 47/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=183.3] | Loss=0.00268 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.594 | L2-Norm(final)=14.330 | 6576.1 samples/s | 102.8 steps/s
[Step=94050 Epoch=183.4] | Loss=0.01753 | Reg=0.00213 | acc=0.9688 | L2-Norm=14.595 | L2-Norm(final)=14.332 | 4515.0 samples/s | 70.5 steps/s
[Step=94100 Epoch=183.5] | Loss=0.01668 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=14.335 | 5208.7 samples/s | 81.4 steps/s
[Step=94150 Epoch=183.6] | Loss=0.01665 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.598 | L2-Norm(final)=14.337 | 5166.8 samples/s | 80.7 steps/s
[Step=94200 Epoch=183.7] | Loss=0.01617 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.600 | L2-Norm(final)=14.340 | 5200.4 samples/s | 81.3 steps/s
[Step=94250 Epoch=183.8] | Loss=0.01561 | Reg=0.00213 | acc=0.9688 | L2-Norm=14.602 | L2-Norm(final)=14.343 | 5232.4 samples/s | 81.8 steps/s
[Step=94300 Epoch=183.9] | Loss=0.01554 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=14.346 | 5260.2 samples/s | 82.2 steps/s
[Step=94350 Epoch=184.0] | Loss=0.01535 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.606 | L2-Norm(final)=14.349 | 5109.3 samples/s | 79.8 steps/s
[Step=94400 Epoch=184.1] | Loss=0.01533 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.607 | L2-Norm(final)=14.352 | 5293.7 samples/s | 82.7 steps/s
[Step=94450 Epoch=184.2] | Loss=0.01536 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=14.355 | 5267.1 samples/s | 82.3 steps/s
[Step=94500 Epoch=184.3] | Loss=0.01556 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.610 | L2-Norm(final)=14.358 | 6900.0 samples/s | 107.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=184.3] | Loss=0.00456 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.624 | L2-Norm(final)=14.385 | 6050.2 samples/s | 94.5 steps/s
[Step=94550 Epoch=184.4] | Loss=0.01378 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=14.388 | 4315.4 samples/s | 67.4 steps/s
[Step=94600 Epoch=184.5] | Loss=0.01543 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.629 | L2-Norm(final)=14.390 | 4630.1 samples/s | 72.3 steps/s
[Step=94650 Epoch=184.6] | Loss=0.01476 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=14.393 | 4580.6 samples/s | 71.6 steps/s
[Step=94700 Epoch=184.7] | Loss=0.01459 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.634 | L2-Norm(final)=14.396 | 4610.6 samples/s | 72.0 steps/s
[Step=94750 Epoch=184.8] | Loss=0.01413 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.636 | L2-Norm(final)=14.398 | 4651.8 samples/s | 72.7 steps/s
[Step=94800 Epoch=184.9] | Loss=0.01370 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=14.401 | 4599.5 samples/s | 71.9 steps/s
[Step=94850 Epoch=185.0] | Loss=0.01330 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.639 | L2-Norm(final)=14.403 | 4634.8 samples/s | 72.4 steps/s
[Step=94900 Epoch=185.1] | Loss=0.01305 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.641 | L2-Norm(final)=14.406 | 4636.7 samples/s | 72.4 steps/s
[Step=94950 Epoch=185.2] | Loss=0.01273 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.643 | L2-Norm(final)=14.408 | 4694.0 samples/s | 73.3 steps/s
[Step=95000 Epoch=185.3] | Loss=0.01262 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.645 | L2-Norm(final)=14.411 | 5822.9 samples/s | 91.0 steps/s
[Step=95050 Epoch=185.4] | Loss=0.01234 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=14.413 | 2447.7 samples/s | 38.2 steps/s
[Step=95100 Epoch=185.5] | Loss=0.01209 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=14.416 | 4546.9 samples/s | 71.0 steps/s
[Step=95150 Epoch=185.6] | Loss=0.01175 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.649 | L2-Norm(final)=14.418 | 4646.3 samples/s | 72.6 steps/s
[Step=95200 Epoch=185.7] | Loss=0.01140 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.651 | L2-Norm(final)=14.420 | 4580.5 samples/s | 71.6 steps/s
[Step=95250 Epoch=185.8] | Loss=0.01113 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.652 | L2-Norm(final)=14.423 | 4625.1 samples/s | 72.3 steps/s
[Step=95300 Epoch=185.9] | Loss=0.01103 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.653 | L2-Norm(final)=14.425 | 4627.9 samples/s | 72.3 steps/s
[Step=95350 Epoch=186.0] | Loss=0.01095 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=14.427 | 4613.8 samples/s | 72.1 steps/s
[Step=95400 Epoch=186.1] | Loss=0.01078 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.655 | L2-Norm(final)=14.429 | 4651.5 samples/s | 72.7 steps/s
[Step=95450 Epoch=186.2] | Loss=0.01060 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.657 | L2-Norm(final)=14.431 | 4627.1 samples/s | 72.3 steps/s
[Step=95500 Epoch=186.3] | Loss=0.01048 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.658 | L2-Norm(final)=14.433 | 4940.0 samples/s | 77.2 steps/s
[Step=95550 Epoch=186.4] | Loss=0.01033 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.659 | L2-Norm(final)=14.436 | 2641.0 samples/s | 41.3 steps/s
[Step=95600 Epoch=186.5] | Loss=0.01009 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.660 | L2-Norm(final)=14.438 | 4712.0 samples/s | 73.6 steps/s
[Step=95650 Epoch=186.6] | Loss=0.00995 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.661 | L2-Norm(final)=14.440 | 4533.5 samples/s | 70.8 steps/s
[Step=95700 Epoch=186.7] | Loss=0.00982 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.662 | L2-Norm(final)=14.442 | 4678.5 samples/s | 73.1 steps/s
[Step=95750 Epoch=186.7] | Loss=0.00978 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.663 | L2-Norm(final)=14.444 | 4547.5 samples/s | 71.1 steps/s
[Step=95800 Epoch=186.8] | Loss=0.00971 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=14.446 | 4635.8 samples/s | 72.4 steps/s
[Step=95850 Epoch=186.9] | Loss=0.00961 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.664 | L2-Norm(final)=14.448 | 4635.5 samples/s | 72.4 steps/s
[Step=95900 Epoch=187.0] | Loss=0.00950 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.665 | L2-Norm(final)=14.450 | 4618.3 samples/s | 72.2 steps/s
[Step=95950 Epoch=187.1] | Loss=0.00942 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.666 | L2-Norm(final)=14.452 | 4714.6 samples/s | 73.7 steps/s
[Step=96000 Epoch=187.2] | Loss=0.00936 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=14.454 | 4548.3 samples/s | 71.1 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step96000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=183.8] | Loss=0.02454 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.930 | L2-Norm(final)=14.797 | 6296.9 samples/s | 98.4 steps/s
[Step=94050 Epoch=183.9] | Loss=0.01565 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.931 | L2-Norm(final)=14.799 | 4741.6 samples/s | 74.1 steps/s
[Step=94100 Epoch=184.0] | Loss=0.01525 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.933 | L2-Norm(final)=14.802 | 5079.3 samples/s | 79.4 steps/s
[Step=94150 Epoch=184.1] | Loss=0.01498 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.935 | L2-Norm(final)=14.806 | 5211.7 samples/s | 81.4 steps/s
[Step=94200 Epoch=184.2] | Loss=0.01502 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=14.809 | 5183.2 samples/s | 81.0 steps/s
[Step=94250 Epoch=184.3] | Loss=0.01508 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.938 | L2-Norm(final)=14.812 | 5227.4 samples/s | 81.7 steps/s
[Step=94300 Epoch=184.4] | Loss=0.01557 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.940 | L2-Norm(final)=14.815 | 5139.1 samples/s | 80.3 steps/s
[Step=94350 Epoch=184.5] | Loss=0.01531 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.942 | L2-Norm(final)=14.818 | 5400.9 samples/s | 84.4 steps/s
[Step=94400 Epoch=184.5] | Loss=0.01524 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.944 | L2-Norm(final)=14.822 | 5056.6 samples/s | 79.0 steps/s
[Step=94450 Epoch=184.6] | Loss=0.01521 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.946 | L2-Norm(final)=14.824 | 5184.5 samples/s | 81.0 steps/s
[Step=94500 Epoch=184.7] | Loss=0.01496 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=14.827 | 7120.9 samples/s | 111.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=184.7] | Loss=0.02017 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.965 | L2-Norm(final)=14.857 | 6288.6 samples/s | 98.3 steps/s
[Step=94550 Epoch=184.8] | Loss=0.01532 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.968 | L2-Norm(final)=14.860 | 4191.5 samples/s | 65.5 steps/s
[Step=94600 Epoch=184.9] | Loss=0.01486 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=14.863 | 4670.7 samples/s | 73.0 steps/s
[Step=94650 Epoch=185.0] | Loss=0.01495 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.973 | L2-Norm(final)=14.865 | 4548.8 samples/s | 71.1 steps/s
[Step=94700 Epoch=185.1] | Loss=0.01421 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.975 | L2-Norm(final)=14.868 | 4560.7 samples/s | 71.3 steps/s
[Step=94750 Epoch=185.2] | Loss=0.01348 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=14.871 | 4634.5 samples/s | 72.4 steps/s
[Step=94800 Epoch=185.3] | Loss=0.01298 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.979 | L2-Norm(final)=14.873 | 4638.5 samples/s | 72.5 steps/s
[Step=94850 Epoch=185.4] | Loss=0.01279 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=14.876 | 4644.0 samples/s | 72.6 steps/s
[Step=94900 Epoch=185.5] | Loss=0.01253 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.983 | L2-Norm(final)=14.878 | 4579.4 samples/s | 71.6 steps/s
[Step=94950 Epoch=185.6] | Loss=0.01236 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=14.881 | 4663.9 samples/s | 72.9 steps/s
[Step=95000 Epoch=185.7] | Loss=0.01211 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.986 | L2-Norm(final)=14.883 | 6004.1 samples/s | 93.8 steps/s
[Step=95050 Epoch=185.8] | Loss=0.01185 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.988 | L2-Norm(final)=14.885 | 2437.7 samples/s | 38.1 steps/s
[Step=95100 Epoch=185.9] | Loss=0.01151 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.990 | L2-Norm(final)=14.888 | 4639.4 samples/s | 72.5 steps/s
[Step=95150 Epoch=186.0] | Loss=0.01122 | Reg=0.00225 | acc=0.9688 | L2-Norm=14.991 | L2-Norm(final)=14.890 | 4619.0 samples/s | 72.2 steps/s
[Step=95200 Epoch=186.1] | Loss=0.01098 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.992 | L2-Norm(final)=14.892 | 4566.1 samples/s | 71.3 steps/s
[Step=95250 Epoch=186.2] | Loss=0.01063 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.994 | L2-Norm(final)=14.895 | 4663.2 samples/s | 72.9 steps/s
[Step=95300 Epoch=186.3] | Loss=0.01037 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=14.897 | 4648.3 samples/s | 72.6 steps/s
[Step=95350 Epoch=186.4] | Loss=0.01030 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.996 | L2-Norm(final)=14.899 | 4582.4 samples/s | 71.6 steps/s
[Step=95400 Epoch=186.5] | Loss=0.01011 | Reg=0.00225 | acc=0.9844 | L2-Norm=14.997 | L2-Norm(final)=14.901 | 4701.2 samples/s | 73.5 steps/s
[Step=95450 Epoch=186.6] | Loss=0.01003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=14.904 | 4592.9 samples/s | 71.8 steps/s
[Step=95500 Epoch=186.7] | Loss=0.01000 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=14.906 | 5101.9 samples/s | 79.7 steps/s
[Step=95550 Epoch=186.8] | Loss=0.00983 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=14.908 | 2649.6 samples/s | 41.4 steps/s
[Step=95600 Epoch=186.9] | Loss=0.00968 | Reg=0.00225 | acc=0.9688 | L2-Norm=15.001 | L2-Norm(final)=14.910 | 4568.3 samples/s | 71.4 steps/s
[Step=95650 Epoch=187.0] | Loss=0.00948 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.002 | L2-Norm(final)=14.912 | 4586.3 samples/s | 71.7 steps/s
[Step=95700 Epoch=187.1] | Loss=0.00938 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.003 | L2-Norm(final)=14.914 | 4650.8 samples/s | 72.7 steps/s
[Step=95750 Epoch=187.2] | Loss=0.00932 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=14.916 | 4669.0 samples/s | 73.0 steps/s
[Step=95800 Epoch=187.3] | Loss=0.00923 | Reg=0.00225 | acc=0.9688 | L2-Norm=15.005 | L2-Norm(final)=14.918 | 4565.2 samples/s | 71.3 steps/s
[Step=95850 Epoch=187.4] | Loss=0.00916 | Reg=0.00225 | acc=0.9688 | L2-Norm=15.006 | L2-Norm(final)=14.920 | 4644.7 samples/s | 72.6 steps/s
[Step=95900 Epoch=187.5] | Loss=0.00904 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.007 | L2-Norm(final)=14.922 | 4708.1 samples/s | 73.6 steps/s
[Step=95950 Epoch=187.6] | Loss=0.00900 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=14.925 | 4653.5 samples/s | 72.7 steps/s
[Step=96000 Epoch=187.7] | Loss=0.00890 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.008 | L2-Norm(final)=14.927 | 4510.4 samples/s | 70.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step96000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=360.2] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.871 | L2-Norm(final)=11.506 | 6123.8 samples/s | 95.7 steps/s
[Step=94050 Epoch=360.4] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.874 | L2-Norm(final)=11.520 | 4386.8 samples/s | 68.5 steps/s
[Step=94100 Epoch=360.6] | Loss=0.00004 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.880 | L2-Norm(final)=11.533 | 5003.3 samples/s | 78.2 steps/s
[Step=94150 Epoch=360.7] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.885 | L2-Norm(final)=11.545 | 4885.1 samples/s | 76.3 steps/s
[Step=94200 Epoch=360.9] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.889 | L2-Norm(final)=11.556 | 4788.6 samples/s | 74.8 steps/s
[Step=94250 Epoch=361.1] | Loss=0.00003 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.892 | L2-Norm(final)=11.565 | 6877.2 samples/s | 107.5 steps/s
[Step=94300 Epoch=361.3] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.894 | L2-Norm(final)=11.574 | 2469.2 samples/s | 38.6 steps/s
[Step=94350 Epoch=361.5] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=11.582 | 4893.7 samples/s | 76.5 steps/s
[Step=94400 Epoch=361.7] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.898 | L2-Norm(final)=11.589 | 4903.7 samples/s | 76.6 steps/s
[Step=94450 Epoch=361.9] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.900 | L2-Norm(final)=11.597 | 4910.0 samples/s | 76.7 steps/s
[Step=94500 Epoch=362.1] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.901 | L2-Norm(final)=11.604 | 5626.4 samples/s | 87.9 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=362.1] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.916 | L2-Norm(final)=11.676 | 6070.8 samples/s | 94.9 steps/s
[Step=94550 Epoch=362.3] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.914 | L2-Norm(final)=11.682 | 3961.5 samples/s | 61.9 steps/s
[Step=94600 Epoch=362.5] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.909 | L2-Norm(final)=11.686 | 4436.9 samples/s | 69.3 steps/s
[Step=94650 Epoch=362.7] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.903 | L2-Norm(final)=11.691 | 4377.8 samples/s | 68.4 steps/s
[Step=94700 Epoch=362.9] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.897 | L2-Norm(final)=11.696 | 4388.5 samples/s | 68.6 steps/s
[Step=94750 Epoch=363.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.891 | L2-Norm(final)=11.699 | 5848.7 samples/s | 91.4 steps/s
[Step=94800 Epoch=363.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.884 | L2-Norm(final)=11.703 | 2263.0 samples/s | 35.4 steps/s
[Step=94850 Epoch=363.4] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.877 | L2-Norm(final)=11.706 | 4335.5 samples/s | 67.7 steps/s
[Step=94900 Epoch=363.6] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.869 | L2-Norm(final)=11.709 | 4363.8 samples/s | 68.2 steps/s
[Step=94950 Epoch=363.8] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.861 | L2-Norm(final)=11.711 | 4361.9 samples/s | 68.2 steps/s
[Step=95000 Epoch=364.0] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.853 | L2-Norm(final)=11.714 | 4983.5 samples/s | 77.9 steps/s
[Step=95050 Epoch=364.2] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.845 | L2-Norm(final)=11.716 | 2499.2 samples/s | 39.0 steps/s
[Step=95100 Epoch=364.4] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.836 | L2-Norm(final)=11.719 | 4375.9 samples/s | 68.4 steps/s
[Step=95150 Epoch=364.6] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.828 | L2-Norm(final)=11.721 | 4355.7 samples/s | 68.1 steps/s
[Step=95200 Epoch=364.8] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.819 | L2-Norm(final)=11.723 | 4424.6 samples/s | 69.1 steps/s
[Step=95250 Epoch=365.0] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.810 | L2-Norm(final)=11.726 | 4317.1 samples/s | 67.5 steps/s
[Step=95300 Epoch=365.2] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.802 | L2-Norm(final)=11.728 | 2682.5 samples/s | 41.9 steps/s
[Step=95350 Epoch=365.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.793 | L2-Norm(final)=11.731 | 4397.0 samples/s | 68.7 steps/s
[Step=95400 Epoch=365.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.784 | L2-Norm(final)=11.733 | 4361.3 samples/s | 68.1 steps/s
[Step=95450 Epoch=365.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.775 | L2-Norm(final)=11.736 | 4416.6 samples/s | 69.0 steps/s
[Step=95500 Epoch=365.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.766 | L2-Norm(final)=11.738 | 4415.8 samples/s | 69.0 steps/s
[Step=95550 Epoch=366.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.757 | L2-Norm(final)=11.741 | 2661.6 samples/s | 41.6 steps/s
[Step=95600 Epoch=366.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.748 | L2-Norm(final)=11.743 | 4401.5 samples/s | 68.8 steps/s
[Step=95650 Epoch=366.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.738 | L2-Norm(final)=11.746 | 4327.3 samples/s | 67.6 steps/s
[Step=95700 Epoch=366.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.729 | L2-Norm(final)=11.748 | 4393.8 samples/s | 68.7 steps/s
[Step=95750 Epoch=366.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.720 | L2-Norm(final)=11.751 | 4411.6 samples/s | 68.9 steps/s
[Step=95800 Epoch=367.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.711 | L2-Norm(final)=11.754 | 6441.4 samples/s | 100.6 steps/s
[Step=95850 Epoch=367.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.701 | L2-Norm(final)=11.757 | 2250.5 samples/s | 35.2 steps/s
[Step=95900 Epoch=367.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.692 | L2-Norm(final)=11.760 | 4397.1 samples/s | 68.7 steps/s
[Step=95950 Epoch=367.6] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.682 | L2-Norm(final)=11.763 | 4264.2 samples/s | 66.6 steps/s
[Step=96000 Epoch=367.8] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.673 | L2-Norm(final)=11.766 | 4428.6 samples/s | 69.2 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step96000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=361.8] | Loss=0.00019 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.846 | L2-Norm(final)=11.999 | 5728.6 samples/s | 89.5 steps/s
[Step=94050 Epoch=362.0] | Loss=0.00004 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.853 | L2-Norm(final)=12.016 | 4546.5 samples/s | 71.0 steps/s
[Step=94100 Epoch=362.2] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.860 | L2-Norm(final)=12.031 | 4969.3 samples/s | 77.6 steps/s
[Step=94150 Epoch=362.4] | Loss=0.00003 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.864 | L2-Norm(final)=12.042 | 4974.7 samples/s | 77.7 steps/s
[Step=94200 Epoch=362.6] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.867 | L2-Norm(final)=12.052 | 4861.9 samples/s | 76.0 steps/s
[Step=94250 Epoch=362.8] | Loss=0.00002 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.871 | L2-Norm(final)=12.063 | 6650.6 samples/s | 103.9 steps/s
[Step=94300 Epoch=363.0] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.875 | L2-Norm(final)=12.073 | 2440.4 samples/s | 38.1 steps/s
[Step=94350 Epoch=363.2] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.878 | L2-Norm(final)=12.083 | 4956.7 samples/s | 77.4 steps/s
[Step=94400 Epoch=363.4] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.881 | L2-Norm(final)=12.092 | 4895.2 samples/s | 76.5 steps/s
[Step=94450 Epoch=363.6] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.884 | L2-Norm(final)=12.101 | 5025.0 samples/s | 78.5 steps/s
[Step=94500 Epoch=363.8] | Loss=0.00002 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.886 | L2-Norm(final)=12.108 | 5604.5 samples/s | 87.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=363.8] | Loss=0.00000 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.903 | L2-Norm(final)=12.184 | 6114.1 samples/s | 95.5 steps/s
[Step=94550 Epoch=364.0] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.896 | L2-Norm(final)=12.189 | 3947.0 samples/s | 61.7 steps/s
[Step=94600 Epoch=364.2] | Loss=0.00001 | Reg=0.00035 | acc=1.0000 | L2-Norm=5.883 | L2-Norm(final)=12.193 | 4377.1 samples/s | 68.4 steps/s
[Step=94650 Epoch=364.3] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.870 | L2-Norm(final)=12.197 | 4507.9 samples/s | 70.4 steps/s
[Step=94700 Epoch=364.5] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.856 | L2-Norm(final)=12.200 | 4301.5 samples/s | 67.2 steps/s
[Step=94750 Epoch=364.7] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.842 | L2-Norm(final)=12.203 | 5920.5 samples/s | 92.5 steps/s
[Step=94800 Epoch=364.9] | Loss=0.00001 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.827 | L2-Norm(final)=12.206 | 2297.4 samples/s | 35.9 steps/s
[Step=94850 Epoch=365.1] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.812 | L2-Norm(final)=12.208 | 4363.6 samples/s | 68.2 steps/s
[Step=94900 Epoch=365.3] | Loss=0.00000 | Reg=0.00034 | acc=1.0000 | L2-Norm=5.797 | L2-Norm(final)=12.210 | 4427.2 samples/s | 69.2 steps/s
[Step=94950 Epoch=365.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.781 | L2-Norm(final)=12.212 | 4325.7 samples/s | 67.6 steps/s
[Step=95000 Epoch=365.7] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.766 | L2-Norm(final)=12.214 | 5133.2 samples/s | 80.2 steps/s
[Step=95050 Epoch=365.9] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.750 | L2-Norm(final)=12.216 | 2475.6 samples/s | 38.7 steps/s
[Step=95100 Epoch=366.1] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.734 | L2-Norm(final)=12.218 | 4385.6 samples/s | 68.5 steps/s
[Step=95150 Epoch=366.3] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.719 | L2-Norm(final)=12.220 | 4354.8 samples/s | 68.0 steps/s
[Step=95200 Epoch=366.5] | Loss=0.00000 | Reg=0.00033 | acc=1.0000 | L2-Norm=5.703 | L2-Norm(final)=12.223 | 4393.3 samples/s | 68.6 steps/s
[Step=95250 Epoch=366.7] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.688 | L2-Norm(final)=12.225 | 4467.2 samples/s | 69.8 steps/s
[Step=95300 Epoch=366.8] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.673 | L2-Norm(final)=12.228 | 2649.1 samples/s | 41.4 steps/s
[Step=95350 Epoch=367.0] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.657 | L2-Norm(final)=12.230 | 4467.4 samples/s | 69.8 steps/s
[Step=95400 Epoch=367.2] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.642 | L2-Norm(final)=12.233 | 4404.9 samples/s | 68.8 steps/s
[Step=95450 Epoch=367.4] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.627 | L2-Norm(final)=12.235 | 4339.6 samples/s | 67.8 steps/s
[Step=95500 Epoch=367.6] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.612 | L2-Norm(final)=12.238 | 4306.7 samples/s | 67.3 steps/s
[Step=95550 Epoch=367.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.597 | L2-Norm(final)=12.241 | 2692.1 samples/s | 42.1 steps/s
[Step=95600 Epoch=368.0] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.582 | L2-Norm(final)=12.243 | 4365.1 samples/s | 68.2 steps/s
[Step=95650 Epoch=368.2] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.567 | L2-Norm(final)=12.246 | 4335.7 samples/s | 67.7 steps/s
[Step=95700 Epoch=368.4] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.553 | L2-Norm(final)=12.249 | 4397.6 samples/s | 68.7 steps/s
[Step=95750 Epoch=368.6] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.538 | L2-Norm(final)=12.252 | 4427.8 samples/s | 69.2 steps/s
[Step=95800 Epoch=368.8] | Loss=0.00000 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.524 | L2-Norm(final)=12.256 | 7017.6 samples/s | 109.7 steps/s
[Step=95850 Epoch=369.0] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.510 | L2-Norm(final)=12.259 | 2169.4 samples/s | 33.9 steps/s
[Step=95900 Epoch=369.2] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.497 | L2-Norm(final)=12.262 | 4401.3 samples/s | 68.8 steps/s
[Step=95950 Epoch=369.3] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.483 | L2-Norm(final)=12.266 | 4414.0 samples/s | 69.0 steps/s
[Step=96000 Epoch=369.5] | Loss=0.00000 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.470 | L2-Norm(final)=12.269 | 4446.2 samples/s | 69.5 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06714 | acc=0.9651 | tpr=0.9710 | fpr=0.0478 | 5150.3 samples/s | 20.1 steps/s
Avg test loss: 0.06908, Avg test acc: 0.96446, Avg tpr: 0.97039, Avg fpr: 0.04858, total FA: 379

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06956 | acc=0.9663 | tpr=0.9750 | fpr=0.0525 | 5548.3 samples/s | 21.7 steps/s
Avg test loss: 0.07091, Avg test acc: 0.96618, Avg tpr: 0.97435, Avg fpr: 0.05179, total FA: 404

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.64334 | acc=0.3145 | tpr=0.0027 | fpr=0.0087 | 5259.5 samples/s | 20.5 steps/s
Avg test loss: 5.65419, Avg test acc: 0.31164, Avg tpr: 0.00291, Avg fpr: 0.00936, total FA: 73

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.48568 | acc=0.3133 | tpr=0.0042 | fpr=0.0156 | 5206.7 samples/s | 20.3 steps/s
Avg test loss: 5.49067, Avg test acc: 0.31104, Avg tpr: 0.00484, Avg fpr: 0.01551, total FA: 121

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.70193 | acc=0.1307 | tpr=0.7212 | fpr=0.8799 | 5525.7 samples/s | 21.6 steps/s
[Step= 100] | Loss=4.69068 | acc=0.1307 | tpr=0.7122 | fpr=0.8801 | 6911.4 samples/s | 27.0 steps/s
[Step= 150] | Loss=4.68780 | acc=0.1316 | tpr=0.7334 | fpr=0.8795 | 7800.4 samples/s | 30.5 steps/s
[Step= 200] | Loss=4.69489 | acc=0.1312 | tpr=0.7301 | fpr=0.8797 | 7892.0 samples/s | 30.8 steps/s
[Step= 250] | Loss=4.70515 | acc=0.1310 | tpr=0.7179 | fpr=0.8797 | 8293.9 samples/s | 32.4 steps/s
[Step= 300] | Loss=4.70568 | acc=0.1306 | tpr=0.7185 | fpr=0.8801 | 7954.2 samples/s | 31.1 steps/s
[Step= 350] | Loss=4.69673 | acc=0.1304 | tpr=0.7170 | fpr=0.8803 | 7964.7 samples/s | 31.1 steps/s
[Step= 400] | Loss=4.69010 | acc=0.1307 | tpr=0.7194 | fpr=0.8800 | 8514.0 samples/s | 33.3 steps/s
[Step= 450] | Loss=4.69250 | acc=0.1301 | tpr=0.7201 | fpr=0.8806 | 7931.4 samples/s | 31.0 steps/s
[Step= 500] | Loss=4.69219 | acc=0.1297 | tpr=0.7198 | fpr=0.8809 | 8107.1 samples/s | 31.7 steps/s
[Step= 550] | Loss=4.69042 | acc=0.1297 | tpr=0.7159 | fpr=0.8810 | 14390.6 samples/s | 56.2 steps/s
Avg test loss: 4.69154, Avg test acc: 0.12961, Avg tpr: 0.71553, Avg fpr: 0.88104, total FA: 122331

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=5.34691 | acc=0.1316 | tpr=0.7389 | fpr=0.8794 | 5560.4 samples/s | 21.7 steps/s
[Step= 100] | Loss=5.33597 | acc=0.1307 | tpr=0.7271 | fpr=0.8805 | 7242.9 samples/s | 28.3 steps/s
[Step= 150] | Loss=5.32659 | acc=0.1308 | tpr=0.7435 | fpr=0.8805 | 7238.0 samples/s | 28.3 steps/s
[Step= 200] | Loss=5.33233 | acc=0.1305 | tpr=0.7443 | fpr=0.8807 | 7978.9 samples/s | 31.2 steps/s
[Step= 250] | Loss=5.34363 | acc=0.1306 | tpr=0.7336 | fpr=0.8804 | 8219.6 samples/s | 32.1 steps/s
[Step= 300] | Loss=5.34660 | acc=0.1302 | tpr=0.7338 | fpr=0.8808 | 7973.5 samples/s | 31.1 steps/s
[Step= 350] | Loss=5.33566 | acc=0.1304 | tpr=0.7320 | fpr=0.8805 | 8288.8 samples/s | 32.4 steps/s
[Step= 400] | Loss=5.32865 | acc=0.1306 | tpr=0.7309 | fpr=0.8803 | 8328.9 samples/s | 32.5 steps/s
[Step= 450] | Loss=5.33033 | acc=0.1298 | tpr=0.7293 | fpr=0.8811 | 7993.8 samples/s | 31.2 steps/s
[Step= 500] | Loss=5.33191 | acc=0.1296 | tpr=0.7273 | fpr=0.8812 | 8342.8 samples/s | 32.6 steps/s
[Step= 550] | Loss=5.32909 | acc=0.1296 | tpr=0.7218 | fpr=0.8812 | 14232.5 samples/s | 55.6 steps/s
Avg test loss: 5.33039, Avg test acc: 0.12952, Avg tpr: 0.72227, Avg fpr: 0.88126, total FA: 122361

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11115 | acc=0.9801 | tpr=0.9646 | fpr=0.0196 | 5155.6 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.11603 | acc=0.9789 | tpr=0.9701 | fpr=0.0209 | 7291.9 samples/s | 28.5 steps/s
[Step= 150] | Loss=0.12134 | acc=0.9780 | tpr=0.9640 | fpr=0.0217 | 8151.6 samples/s | 31.8 steps/s
[Step= 200] | Loss=0.12300 | acc=0.9780 | tpr=0.9650 | fpr=0.0217 | 7875.2 samples/s | 30.8 steps/s
[Step= 250] | Loss=0.12097 | acc=0.9783 | tpr=0.9677 | fpr=0.0215 | 8395.1 samples/s | 32.8 steps/s
[Step= 300] | Loss=0.12299 | acc=0.9779 | tpr=0.9658 | fpr=0.0218 | 8043.7 samples/s | 31.4 steps/s
[Step= 350] | Loss=0.12370 | acc=0.9777 | tpr=0.9668 | fpr=0.0221 | 8210.4 samples/s | 32.1 steps/s
[Step= 400] | Loss=0.12470 | acc=0.9775 | tpr=0.9650 | fpr=0.0223 | 8100.9 samples/s | 31.6 steps/s
[Step= 450] | Loss=0.12706 | acc=0.9771 | tpr=0.9640 | fpr=0.0227 | 7937.8 samples/s | 31.0 steps/s
[Step= 500] | Loss=0.12654 | acc=0.9770 | tpr=0.9639 | fpr=0.0227 | 7968.5 samples/s | 31.1 steps/s
[Step= 550] | Loss=0.12567 | acc=0.9772 | tpr=0.9630 | fpr=0.0226 | 15218.0 samples/s | 59.4 steps/s
Avg test loss: 0.12533, Avg test acc: 0.97719, Avg tpr: 0.96315, Avg fpr: 0.02256, total FA: 3132

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11312 | acc=0.9799 | tpr=0.9602 | fpr=0.0197 | 5102.9 samples/s | 19.9 steps/s
[Step= 100] | Loss=0.11828 | acc=0.9790 | tpr=0.9680 | fpr=0.0208 | 7277.5 samples/s | 28.4 steps/s
[Step= 150] | Loss=0.12428 | acc=0.9781 | tpr=0.9697 | fpr=0.0218 | 8204.0 samples/s | 32.0 steps/s
[Step= 200] | Loss=0.12633 | acc=0.9778 | tpr=0.9683 | fpr=0.0221 | 8253.6 samples/s | 32.2 steps/s
[Step= 250] | Loss=0.12449 | acc=0.9780 | tpr=0.9686 | fpr=0.0218 | 7957.5 samples/s | 31.1 steps/s
[Step= 300] | Loss=0.12674 | acc=0.9775 | tpr=0.9673 | fpr=0.0223 | 8259.5 samples/s | 32.3 steps/s
[Step= 350] | Loss=0.12761 | acc=0.9773 | tpr=0.9681 | fpr=0.0226 | 8278.9 samples/s | 32.3 steps/s
[Step= 400] | Loss=0.12860 | acc=0.9772 | tpr=0.9661 | fpr=0.0226 | 8315.8 samples/s | 32.5 steps/s
[Step= 450] | Loss=0.13113 | acc=0.9767 | tpr=0.9649 | fpr=0.0231 | 8168.8 samples/s | 31.9 steps/s
[Step= 500] | Loss=0.13048 | acc=0.9767 | tpr=0.9661 | fpr=0.0231 | 8065.6 samples/s | 31.5 steps/s
[Step= 550] | Loss=0.12940 | acc=0.9769 | tpr=0.9650 | fpr=0.0229 | 14578.8 samples/s | 56.9 steps/s
Avg test loss: 0.12908, Avg test acc: 0.97695, Avg tpr: 0.96474, Avg fpr: 0.02283, total FA: 3170

server round 48/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=187.2] | Loss=0.04206 | Reg=0.00212 | acc=0.9531 | L2-Norm=14.546 | L2-Norm(final)=14.516 | 6564.5 samples/s | 102.6 steps/s
[Step=96050 Epoch=187.3] | Loss=0.02553 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.548 | L2-Norm(final)=14.517 | 4708.8 samples/s | 73.6 steps/s
[Step=96100 Epoch=187.4] | Loss=0.02489 | Reg=0.00212 | acc=0.9688 | L2-Norm=14.550 | L2-Norm(final)=14.520 | 5111.6 samples/s | 79.9 steps/s
[Step=96150 Epoch=187.5] | Loss=0.02433 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.551 | L2-Norm(final)=14.523 | 5201.6 samples/s | 81.3 steps/s
[Step=96200 Epoch=187.6] | Loss=0.02368 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.553 | L2-Norm(final)=14.525 | 5354.4 samples/s | 83.7 steps/s
[Step=96250 Epoch=187.7] | Loss=0.02330 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.555 | L2-Norm(final)=14.528 | 5144.5 samples/s | 80.4 steps/s
[Step=96300 Epoch=187.8] | Loss=0.02294 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.557 | L2-Norm(final)=14.530 | 5234.0 samples/s | 81.8 steps/s
[Step=96350 Epoch=187.9] | Loss=0.02282 | Reg=0.00212 | acc=0.9688 | L2-Norm=14.558 | L2-Norm(final)=14.533 | 5255.0 samples/s | 82.1 steps/s
[Step=96400 Epoch=188.0] | Loss=0.02245 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.560 | L2-Norm(final)=14.535 | 5145.3 samples/s | 80.4 steps/s
[Step=96450 Epoch=188.1] | Loss=0.02222 | Reg=0.00212 | acc=0.9688 | L2-Norm=14.561 | L2-Norm(final)=14.538 | 5217.0 samples/s | 81.5 steps/s
[Step=96500 Epoch=188.2] | Loss=0.02208 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.563 | L2-Norm(final)=14.540 | 6864.4 samples/s | 107.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=188.2] | Loss=0.01664 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.578 | L2-Norm(final)=14.564 | 6475.4 samples/s | 101.2 steps/s
[Step=96550 Epoch=188.3] | Loss=0.02549 | Reg=0.00213 | acc=0.9688 | L2-Norm=14.580 | L2-Norm(final)=14.566 | 4152.9 samples/s | 64.9 steps/s
[Step=96600 Epoch=188.4] | Loss=0.02235 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.583 | L2-Norm(final)=14.568 | 4596.5 samples/s | 71.8 steps/s
[Step=96650 Epoch=188.5] | Loss=0.02050 | Reg=0.00213 | acc=0.9688 | L2-Norm=14.585 | L2-Norm(final)=14.570 | 4623.3 samples/s | 72.2 steps/s
[Step=96700 Epoch=188.6] | Loss=0.01938 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.587 | L2-Norm(final)=14.573 | 4673.0 samples/s | 73.0 steps/s
[Step=96750 Epoch=188.7] | Loss=0.01835 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.589 | L2-Norm(final)=14.575 | 4560.5 samples/s | 71.3 steps/s
[Step=96800 Epoch=188.8] | Loss=0.01837 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.591 | L2-Norm(final)=14.578 | 4700.7 samples/s | 73.4 steps/s
[Step=96850 Epoch=188.9] | Loss=0.01820 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.593 | L2-Norm(final)=14.580 | 4600.6 samples/s | 71.9 steps/s
[Step=96900 Epoch=189.0] | Loss=0.01752 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=14.582 | 4613.1 samples/s | 72.1 steps/s
[Step=96950 Epoch=189.1] | Loss=0.01684 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=14.585 | 4644.8 samples/s | 72.6 steps/s
[Step=97000 Epoch=189.2] | Loss=0.01651 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.599 | L2-Norm(final)=14.587 | 5920.6 samples/s | 92.5 steps/s
[Step=97050 Epoch=189.3] | Loss=0.01597 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=14.589 | 2438.0 samples/s | 38.1 steps/s
[Step=97100 Epoch=189.4] | Loss=0.01537 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.602 | L2-Norm(final)=14.592 | 4645.5 samples/s | 72.6 steps/s
[Step=97150 Epoch=189.5] | Loss=0.01480 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.604 | L2-Norm(final)=14.594 | 4570.4 samples/s | 71.4 steps/s
[Step=97200 Epoch=189.6] | Loss=0.01441 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=14.596 | 4713.8 samples/s | 73.7 steps/s
[Step=97250 Epoch=189.7] | Loss=0.01410 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.607 | L2-Norm(final)=14.599 | 4527.0 samples/s | 70.7 steps/s
[Step=97300 Epoch=189.8] | Loss=0.01392 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.609 | L2-Norm(final)=14.601 | 4597.6 samples/s | 71.8 steps/s
[Step=97350 Epoch=189.9] | Loss=0.01366 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.610 | L2-Norm(final)=14.603 | 4654.5 samples/s | 72.7 steps/s
[Step=97400 Epoch=190.0] | Loss=0.01339 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.611 | L2-Norm(final)=14.605 | 4637.3 samples/s | 72.5 steps/s
[Step=97450 Epoch=190.1] | Loss=0.01327 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=14.608 | 4625.1 samples/s | 72.3 steps/s
[Step=97500 Epoch=190.2] | Loss=0.01319 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.614 | L2-Norm(final)=14.610 | 4970.0 samples/s | 77.7 steps/s
[Step=97550 Epoch=190.3] | Loss=0.01304 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.615 | L2-Norm(final)=14.612 | 2661.0 samples/s | 41.6 steps/s
[Step=97600 Epoch=190.4] | Loss=0.01284 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.616 | L2-Norm(final)=14.614 | 4563.2 samples/s | 71.3 steps/s
[Step=97650 Epoch=190.5] | Loss=0.01257 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=14.616 | 4514.6 samples/s | 70.5 steps/s
[Step=97700 Epoch=190.6] | Loss=0.01242 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.619 | L2-Norm(final)=14.618 | 4629.5 samples/s | 72.3 steps/s
[Step=97750 Epoch=190.7] | Loss=0.01222 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.620 | L2-Norm(final)=14.621 | 4612.2 samples/s | 72.1 steps/s
[Step=97800 Epoch=190.7] | Loss=0.01208 | Reg=0.00214 | acc=0.9688 | L2-Norm=14.621 | L2-Norm(final)=14.623 | 4609.5 samples/s | 72.0 steps/s
[Step=97850 Epoch=190.8] | Loss=0.01192 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.622 | L2-Norm(final)=14.625 | 4640.0 samples/s | 72.5 steps/s
[Step=97900 Epoch=190.9] | Loss=0.01184 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.623 | L2-Norm(final)=14.627 | 4626.8 samples/s | 72.3 steps/s
[Step=97950 Epoch=191.0] | Loss=0.01174 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=14.629 | 4609.4 samples/s | 72.0 steps/s
[Step=98000 Epoch=191.1] | Loss=0.01165 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.626 | L2-Norm(final)=14.631 | 4655.5 samples/s | 72.7 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step98000.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=187.7] | Loss=0.01791 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.889 | L2-Norm(final)=14.988 | 6254.4 samples/s | 97.7 steps/s
[Step=96050 Epoch=187.8] | Loss=0.02461 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=14.991 | 4720.6 samples/s | 73.8 steps/s
[Step=96100 Epoch=187.9] | Loss=0.02462 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.893 | L2-Norm(final)=14.993 | 5129.1 samples/s | 80.1 steps/s
[Step=96150 Epoch=188.0] | Loss=0.02459 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.895 | L2-Norm(final)=14.995 | 5448.8 samples/s | 85.1 steps/s
[Step=96200 Epoch=188.1] | Loss=0.02360 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.897 | L2-Norm(final)=14.998 | 5057.5 samples/s | 79.0 steps/s
[Step=96250 Epoch=188.2] | Loss=0.02311 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.900 | L2-Norm(final)=15.001 | 5089.1 samples/s | 79.5 steps/s
[Step=96300 Epoch=188.3] | Loss=0.02235 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.902 | L2-Norm(final)=15.003 | 5273.9 samples/s | 82.4 steps/s
[Step=96350 Epoch=188.4] | Loss=0.02231 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.904 | L2-Norm(final)=15.006 | 5135.8 samples/s | 80.2 steps/s
[Step=96400 Epoch=188.5] | Loss=0.02238 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.906 | L2-Norm(final)=15.009 | 5214.1 samples/s | 81.5 steps/s
[Step=96450 Epoch=188.6] | Loss=0.02257 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.908 | L2-Norm(final)=15.012 | 5212.7 samples/s | 81.4 steps/s
[Step=96500 Epoch=188.7] | Loss=0.02232 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.910 | L2-Norm(final)=15.014 | 7046.6 samples/s | 110.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=188.7] | Loss=0.01852 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=15.041 | 6794.9 samples/s | 106.2 steps/s
[Step=96550 Epoch=188.8] | Loss=0.02024 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.933 | L2-Norm(final)=15.044 | 4100.6 samples/s | 64.1 steps/s
[Step=96600 Epoch=188.9] | Loss=0.01889 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.935 | L2-Norm(final)=15.046 | 4520.3 samples/s | 70.6 steps/s
[Step=96650 Epoch=188.9] | Loss=0.01860 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.938 | L2-Norm(final)=15.049 | 4609.1 samples/s | 72.0 steps/s
[Step=96700 Epoch=189.0] | Loss=0.01868 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.941 | L2-Norm(final)=15.051 | 4597.7 samples/s | 71.8 steps/s
[Step=96750 Epoch=189.1] | Loss=0.01822 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.943 | L2-Norm(final)=15.054 | 4621.6 samples/s | 72.2 steps/s
[Step=96800 Epoch=189.2] | Loss=0.01764 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=15.056 | 4617.3 samples/s | 72.1 steps/s
[Step=96850 Epoch=189.3] | Loss=0.01702 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=15.059 | 4672.9 samples/s | 73.0 steps/s
[Step=96900 Epoch=189.4] | Loss=0.01662 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=15.061 | 4583.3 samples/s | 71.6 steps/s
[Step=96950 Epoch=189.5] | Loss=0.01611 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=15.063 | 4711.2 samples/s | 73.6 steps/s
[Step=97000 Epoch=189.6] | Loss=0.01572 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.953 | L2-Norm(final)=15.066 | 5952.1 samples/s | 93.0 steps/s
[Step=97050 Epoch=189.7] | Loss=0.01519 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=15.068 | 2437.9 samples/s | 38.1 steps/s
[Step=97100 Epoch=189.8] | Loss=0.01483 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=15.070 | 4626.8 samples/s | 72.3 steps/s
[Step=97150 Epoch=189.9] | Loss=0.01448 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.958 | L2-Norm(final)=15.072 | 4692.5 samples/s | 73.3 steps/s
[Step=97200 Epoch=190.0] | Loss=0.01409 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=15.075 | 4611.2 samples/s | 72.1 steps/s
[Step=97250 Epoch=190.1] | Loss=0.01373 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.960 | L2-Norm(final)=15.077 | 4672.5 samples/s | 73.0 steps/s
[Step=97300 Epoch=190.2] | Loss=0.01341 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=15.079 | 4516.3 samples/s | 70.6 steps/s
[Step=97350 Epoch=190.3] | Loss=0.01314 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.963 | L2-Norm(final)=15.081 | 4663.6 samples/s | 72.9 steps/s
[Step=97400 Epoch=190.4] | Loss=0.01286 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.964 | L2-Norm(final)=15.083 | 4606.1 samples/s | 72.0 steps/s
[Step=97450 Epoch=190.5] | Loss=0.01267 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.966 | L2-Norm(final)=15.086 | 4610.4 samples/s | 72.0 steps/s
[Step=97500 Epoch=190.6] | Loss=0.01250 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.967 | L2-Norm(final)=15.088 | 5111.2 samples/s | 79.9 steps/s
[Step=97550 Epoch=190.7] | Loss=0.01227 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.968 | L2-Norm(final)=15.090 | 2651.0 samples/s | 41.4 steps/s
[Step=97600 Epoch=190.8] | Loss=0.01212 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.969 | L2-Norm(final)=15.092 | 4534.0 samples/s | 70.8 steps/s
[Step=97650 Epoch=190.9] | Loss=0.01187 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=15.094 | 4595.0 samples/s | 71.8 steps/s
[Step=97700 Epoch=191.0] | Loss=0.01168 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.972 | L2-Norm(final)=15.097 | 4626.2 samples/s | 72.3 steps/s
[Step=97750 Epoch=191.1] | Loss=0.01148 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.973 | L2-Norm(final)=15.099 | 4598.7 samples/s | 71.9 steps/s
[Step=97800 Epoch=191.2] | Loss=0.01141 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.974 | L2-Norm(final)=15.101 | 4710.1 samples/s | 73.6 steps/s
[Step=97850 Epoch=191.3] | Loss=0.01127 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.975 | L2-Norm(final)=15.103 | 4549.9 samples/s | 71.1 steps/s
[Step=97900 Epoch=191.4] | Loss=0.01119 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=15.105 | 4666.7 samples/s | 72.9 steps/s
[Step=97950 Epoch=191.5] | Loss=0.01117 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=15.107 | 4605.3 samples/s | 72.0 steps/s
[Step=98000 Epoch=191.6] | Loss=0.01101 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.978 | L2-Norm(final)=15.109 | 4602.3 samples/s | 71.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step98000.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=367.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.578 | L2-Norm(final)=11.858 | 6689.4 samples/s | 104.5 steps/s
[Step=96050 Epoch=368.0] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.583 | L2-Norm(final)=11.876 | 4122.3 samples/s | 64.4 steps/s
[Step=96100 Epoch=368.2] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.593 | L2-Norm(final)=11.895 | 4963.5 samples/s | 77.6 steps/s
[Step=96150 Epoch=368.4] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.600 | L2-Norm(final)=11.909 | 4804.3 samples/s | 75.1 steps/s
[Step=96200 Epoch=368.6] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.606 | L2-Norm(final)=11.921 | 4894.8 samples/s | 76.5 steps/s
[Step=96250 Epoch=368.8] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.610 | L2-Norm(final)=11.931 | 6806.5 samples/s | 106.4 steps/s
[Step=96300 Epoch=369.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.613 | L2-Norm(final)=11.940 | 2469.7 samples/s | 38.6 steps/s
[Step=96350 Epoch=369.2] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.616 | L2-Norm(final)=11.949 | 4902.6 samples/s | 76.6 steps/s
[Step=96400 Epoch=369.4] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.619 | L2-Norm(final)=11.957 | 4870.6 samples/s | 76.1 steps/s
[Step=96450 Epoch=369.6] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.621 | L2-Norm(final)=11.964 | 5153.9 samples/s | 80.5 steps/s
[Step=96500 Epoch=369.8] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.623 | L2-Norm(final)=11.972 | 5350.5 samples/s | 83.6 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=369.8] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.643 | L2-Norm(final)=12.042 | 6537.3 samples/s | 102.1 steps/s
[Step=96550 Epoch=369.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.640 | L2-Norm(final)=12.048 | 3868.1 samples/s | 60.4 steps/s
[Step=96600 Epoch=370.1] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.641 | L2-Norm(final)=12.054 | 4460.8 samples/s | 69.7 steps/s
[Step=96650 Epoch=370.3] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.644 | L2-Norm(final)=12.062 | 4318.0 samples/s | 67.5 steps/s
[Step=96700 Epoch=370.5] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.645 | L2-Norm(final)=12.068 | 4339.6 samples/s | 67.8 steps/s
[Step=96750 Epoch=370.7] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.644 | L2-Norm(final)=12.073 | 5878.0 samples/s | 91.8 steps/s
[Step=96800 Epoch=370.9] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.643 | L2-Norm(final)=12.077 | 2335.4 samples/s | 36.5 steps/s
[Step=96850 Epoch=371.1] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.641 | L2-Norm(final)=12.080 | 4345.1 samples/s | 67.9 steps/s
[Step=96900 Epoch=371.3] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.639 | L2-Norm(final)=12.082 | 4400.4 samples/s | 68.8 steps/s
[Step=96950 Epoch=371.5] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.636 | L2-Norm(final)=12.085 | 4413.6 samples/s | 69.0 steps/s
[Step=97000 Epoch=371.7] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.632 | L2-Norm(final)=12.087 | 4915.5 samples/s | 76.8 steps/s
[Step=97050 Epoch=371.9] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.629 | L2-Norm(final)=12.088 | 2514.6 samples/s | 39.3 steps/s
[Step=97100 Epoch=372.1] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.625 | L2-Norm(final)=12.090 | 4350.2 samples/s | 68.0 steps/s
[Step=97150 Epoch=372.2] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.621 | L2-Norm(final)=12.092 | 4362.4 samples/s | 68.2 steps/s
[Step=97200 Epoch=372.4] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.617 | L2-Norm(final)=12.093 | 4396.9 samples/s | 68.7 steps/s
[Step=97250 Epoch=372.6] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.613 | L2-Norm(final)=12.095 | 4374.5 samples/s | 68.4 steps/s
[Step=97300 Epoch=372.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.609 | L2-Norm(final)=12.096 | 2672.3 samples/s | 41.8 steps/s
[Step=97350 Epoch=373.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.605 | L2-Norm(final)=12.098 | 4397.3 samples/s | 68.7 steps/s
[Step=97400 Epoch=373.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.601 | L2-Norm(final)=12.099 | 4418.0 samples/s | 69.0 steps/s
[Step=97450 Epoch=373.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.596 | L2-Norm(final)=12.100 | 4449.7 samples/s | 69.5 steps/s
[Step=97500 Epoch=373.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.592 | L2-Norm(final)=12.102 | 4365.9 samples/s | 68.2 steps/s
[Step=97550 Epoch=373.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.587 | L2-Norm(final)=12.103 | 2659.1 samples/s | 41.5 steps/s
[Step=97600 Epoch=374.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.583 | L2-Norm(final)=12.104 | 4416.7 samples/s | 69.0 steps/s
[Step=97650 Epoch=374.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.578 | L2-Norm(final)=12.106 | 4341.1 samples/s | 67.8 steps/s
[Step=97700 Epoch=374.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.573 | L2-Norm(final)=12.107 | 4425.6 samples/s | 69.2 steps/s
[Step=97750 Epoch=374.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.568 | L2-Norm(final)=12.108 | 4373.5 samples/s | 68.3 steps/s
[Step=97800 Epoch=374.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.564 | L2-Norm(final)=12.110 | 6494.4 samples/s | 101.5 steps/s
[Step=97850 Epoch=374.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.111 | 2273.9 samples/s | 35.5 steps/s
[Step=97900 Epoch=375.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.554 | L2-Norm(final)=12.112 | 4274.0 samples/s | 66.8 steps/s
[Step=97950 Epoch=375.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.549 | L2-Norm(final)=12.114 | 4391.7 samples/s | 68.6 steps/s
[Step=98000 Epoch=375.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=12.115 | 4454.4 samples/s | 69.6 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step98000.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=369.5] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.373 | 6731.8 samples/s | 105.2 steps/s
[Step=96050 Epoch=369.7] | Loss=0.00006 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.570 | L2-Norm(final)=12.394 | 4085.5 samples/s | 63.8 steps/s
[Step=96100 Epoch=369.9] | Loss=0.00005 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.582 | L2-Norm(final)=12.412 | 5011.4 samples/s | 78.3 steps/s
[Step=96150 Epoch=370.1] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.589 | L2-Norm(final)=12.424 | 4756.7 samples/s | 74.3 steps/s
[Step=96200 Epoch=370.3] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.594 | L2-Norm(final)=12.434 | 5017.7 samples/s | 78.4 steps/s
[Step=96250 Epoch=370.5] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.597 | L2-Norm(final)=12.442 | 6778.5 samples/s | 105.9 steps/s
[Step=96300 Epoch=370.7] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.599 | L2-Norm(final)=12.450 | 2434.3 samples/s | 38.0 steps/s
[Step=96350 Epoch=370.9] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.601 | L2-Norm(final)=12.456 | 4941.7 samples/s | 77.2 steps/s
[Step=96400 Epoch=371.1] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.602 | L2-Norm(final)=12.463 | 4995.2 samples/s | 78.1 steps/s
[Step=96450 Epoch=371.3] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.604 | L2-Norm(final)=12.469 | 4875.2 samples/s | 76.2 steps/s
[Step=96500 Epoch=371.5] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.605 | L2-Norm(final)=12.475 | 5767.5 samples/s | 90.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=371.5] | Loss=0.00000 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.618 | L2-Norm(final)=12.537 | 6337.8 samples/s | 99.0 steps/s
[Step=96550 Epoch=371.7] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.612 | L2-Norm(final)=12.542 | 3880.5 samples/s | 60.6 steps/s
[Step=96600 Epoch=371.9] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.617 | L2-Norm(final)=12.552 | 4365.9 samples/s | 68.2 steps/s
[Step=96650 Epoch=372.0] | Loss=0.00003 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.622 | L2-Norm(final)=12.560 | 4443.1 samples/s | 69.4 steps/s
[Step=96700 Epoch=372.2] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.624 | L2-Norm(final)=12.565 | 4398.9 samples/s | 68.7 steps/s
[Step=96750 Epoch=372.4] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.624 | L2-Norm(final)=12.570 | 5950.2 samples/s | 93.0 steps/s
[Step=96800 Epoch=372.6] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.623 | L2-Norm(final)=12.573 | 2320.5 samples/s | 36.3 steps/s
[Step=96850 Epoch=372.8] | Loss=0.00002 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.621 | L2-Norm(final)=12.576 | 4352.8 samples/s | 68.0 steps/s
[Step=96900 Epoch=373.0] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.618 | L2-Norm(final)=12.578 | 4369.1 samples/s | 68.3 steps/s
[Step=96950 Epoch=373.2] | Loss=0.00001 | Reg=0.00032 | acc=1.0000 | L2-Norm=5.616 | L2-Norm(final)=12.580 | 4419.6 samples/s | 69.1 steps/s
[Step=97000 Epoch=373.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.612 | L2-Norm(final)=12.582 | 5051.7 samples/s | 78.9 steps/s
[Step=97050 Epoch=373.6] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.609 | L2-Norm(final)=12.584 | 2447.7 samples/s | 38.2 steps/s
[Step=97100 Epoch=373.8] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.606 | L2-Norm(final)=12.586 | 4358.7 samples/s | 68.1 steps/s
[Step=97150 Epoch=374.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.602 | L2-Norm(final)=12.587 | 4394.6 samples/s | 68.7 steps/s
[Step=97200 Epoch=374.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.598 | L2-Norm(final)=12.589 | 4410.2 samples/s | 68.9 steps/s
[Step=97250 Epoch=374.4] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.594 | L2-Norm(final)=12.590 | 4451.8 samples/s | 69.6 steps/s
[Step=97300 Epoch=374.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.590 | L2-Norm(final)=12.591 | 2672.6 samples/s | 41.8 steps/s
[Step=97350 Epoch=374.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.586 | L2-Norm(final)=12.593 | 4353.4 samples/s | 68.0 steps/s
[Step=97400 Epoch=374.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.582 | L2-Norm(final)=12.594 | 4447.5 samples/s | 69.5 steps/s
[Step=97450 Epoch=375.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.578 | L2-Norm(final)=12.596 | 4330.5 samples/s | 67.7 steps/s
[Step=97500 Epoch=375.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.573 | L2-Norm(final)=12.597 | 4395.5 samples/s | 68.7 steps/s
[Step=97550 Epoch=375.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.569 | L2-Norm(final)=12.599 | 2711.2 samples/s | 42.4 steps/s
[Step=97600 Epoch=375.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.565 | L2-Norm(final)=12.600 | 4339.2 samples/s | 67.8 steps/s
[Step=97650 Epoch=375.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.560 | L2-Norm(final)=12.601 | 4464.7 samples/s | 69.8 steps/s
[Step=97700 Epoch=376.1] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.556 | L2-Norm(final)=12.603 | 4276.9 samples/s | 66.8 steps/s
[Step=97750 Epoch=376.3] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.551 | L2-Norm(final)=12.604 | 4391.5 samples/s | 68.6 steps/s
[Step=97800 Epoch=376.5] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.547 | L2-Norm(final)=12.606 | 7161.9 samples/s | 111.9 steps/s
[Step=97850 Epoch=376.7] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.607 | 2173.3 samples/s | 34.0 steps/s
[Step=97900 Epoch=376.9] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=12.609 | 4376.0 samples/s | 68.4 steps/s
[Step=97950 Epoch=377.0] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.533 | L2-Norm(final)=12.610 | 4442.4 samples/s | 69.4 steps/s
[Step=98000 Epoch=377.2] | Loss=0.00001 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.528 | L2-Norm(final)=12.612 | 4414.2 samples/s | 69.0 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06538 | acc=0.9659 | tpr=0.9750 | fpr=0.0540 | 5313.7 samples/s | 20.8 steps/s
Avg test loss: 0.06720, Avg test acc: 0.96442, Avg tpr: 0.97435, Avg fpr: 0.05743, total FA: 448

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06609 | acc=0.9666 | tpr=0.9764 | fpr=0.0548 | 5260.3 samples/s | 20.5 steps/s
Avg test loss: 0.06759, Avg test acc: 0.96634, Avg tpr: 0.97599, Avg fpr: 0.05486, total FA: 428

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.63193 | acc=0.3131 | tpr=0.0030 | fpr=0.0134 | 5463.6 samples/s | 21.3 steps/s
Avg test loss: 5.64164, Avg test acc: 0.31056, Avg tpr: 0.00309, Avg fpr: 0.01320, total FA: 103

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.41146 | acc=0.3118 | tpr=0.0057 | fpr=0.0235 | 5290.5 samples/s | 20.7 steps/s
Avg test loss: 5.41596, Avg test acc: 0.30916, Avg tpr: 0.00635, Avg fpr: 0.02487, total FA: 194

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.55135 | acc=0.1205 | tpr=0.7522 | fpr=0.8908 | 5456.3 samples/s | 21.3 steps/s
[Step= 100] | Loss=4.53942 | acc=0.1204 | tpr=0.7377 | fpr=0.8911 | 7273.3 samples/s | 28.4 steps/s
[Step= 150] | Loss=4.53724 | acc=0.1211 | tpr=0.7550 | fpr=0.8906 | 7402.3 samples/s | 28.9 steps/s
[Step= 200] | Loss=4.54292 | acc=0.1209 | tpr=0.7519 | fpr=0.8905 | 8128.7 samples/s | 31.8 steps/s
[Step= 250] | Loss=4.55121 | acc=0.1209 | tpr=0.7389 | fpr=0.8904 | 7884.9 samples/s | 30.8 steps/s
[Step= 300] | Loss=4.55062 | acc=0.1205 | tpr=0.7389 | fpr=0.8908 | 8063.5 samples/s | 31.5 steps/s
[Step= 350] | Loss=4.54273 | acc=0.1202 | tpr=0.7351 | fpr=0.8909 | 8576.9 samples/s | 33.5 steps/s
[Step= 400] | Loss=4.53687 | acc=0.1205 | tpr=0.7369 | fpr=0.8907 | 7928.2 samples/s | 31.0 steps/s
[Step= 450] | Loss=4.53951 | acc=0.1200 | tpr=0.7386 | fpr=0.8913 | 7969.3 samples/s | 31.1 steps/s
[Step= 500] | Loss=4.53969 | acc=0.1195 | tpr=0.7383 | fpr=0.8917 | 8210.5 samples/s | 32.1 steps/s
[Step= 550] | Loss=4.53785 | acc=0.1196 | tpr=0.7338 | fpr=0.8916 | 14383.0 samples/s | 56.2 steps/s
Avg test loss: 4.53904, Avg test acc: 0.11949, Avg tpr: 0.73336, Avg fpr: 0.89167, total FA: 123807

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=4.88427 | acc=0.1337 | tpr=0.7478 | fpr=0.8774 | 5400.3 samples/s | 21.1 steps/s
[Step= 100] | Loss=4.87173 | acc=0.1323 | tpr=0.7228 | fpr=0.8787 | 7040.6 samples/s | 27.5 steps/s
[Step= 150] | Loss=4.86114 | acc=0.1326 | tpr=0.7406 | fpr=0.8786 | 7772.4 samples/s | 30.4 steps/s
[Step= 200] | Loss=4.86594 | acc=0.1321 | tpr=0.7366 | fpr=0.8789 | 8222.8 samples/s | 32.1 steps/s
[Step= 250] | Loss=4.87624 | acc=0.1321 | tpr=0.7284 | fpr=0.8788 | 7883.7 samples/s | 30.8 steps/s
[Step= 300] | Loss=4.87923 | acc=0.1320 | tpr=0.7273 | fpr=0.8788 | 8165.7 samples/s | 31.9 steps/s
[Step= 350] | Loss=4.86998 | acc=0.1323 | tpr=0.7264 | fpr=0.8785 | 8374.4 samples/s | 32.7 steps/s
[Step= 400] | Loss=4.86363 | acc=0.1325 | tpr=0.7270 | fpr=0.8783 | 7902.3 samples/s | 30.9 steps/s
[Step= 450] | Loss=4.86551 | acc=0.1317 | tpr=0.7259 | fpr=0.8791 | 8160.7 samples/s | 31.9 steps/s
[Step= 500] | Loss=4.86712 | acc=0.1314 | tpr=0.7251 | fpr=0.8793 | 8320.6 samples/s | 32.5 steps/s
[Step= 550] | Loss=4.86445 | acc=0.1315 | tpr=0.7195 | fpr=0.8792 | 13934.8 samples/s | 54.4 steps/s
Avg test loss: 4.86567, Avg test acc: 0.13143, Avg tpr: 0.71989, Avg fpr: 0.87927, total FA: 122085

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10814 | acc=0.9809 | tpr=0.9469 | fpr=0.0185 | 5157.3 samples/s | 20.1 steps/s
[Step= 100] | Loss=0.11296 | acc=0.9797 | tpr=0.9574 | fpr=0.0199 | 7665.3 samples/s | 29.9 steps/s
[Step= 150] | Loss=0.11808 | acc=0.9788 | tpr=0.9553 | fpr=0.0208 | 7553.1 samples/s | 29.5 steps/s
[Step= 200] | Loss=0.11989 | acc=0.9788 | tpr=0.9585 | fpr=0.0208 | 8179.6 samples/s | 32.0 steps/s
[Step= 250] | Loss=0.11784 | acc=0.9791 | tpr=0.9616 | fpr=0.0206 | 7986.4 samples/s | 31.2 steps/s
[Step= 300] | Loss=0.11988 | acc=0.9786 | tpr=0.9593 | fpr=0.0211 | 8367.2 samples/s | 32.7 steps/s
[Step= 350] | Loss=0.12063 | acc=0.9783 | tpr=0.9612 | fpr=0.0214 | 7852.6 samples/s | 30.7 steps/s
[Step= 400] | Loss=0.12161 | acc=0.9781 | tpr=0.9584 | fpr=0.0215 | 8286.9 samples/s | 32.4 steps/s
[Step= 450] | Loss=0.12396 | acc=0.9777 | tpr=0.9576 | fpr=0.0219 | 8132.7 samples/s | 31.8 steps/s
[Step= 500] | Loss=0.12331 | acc=0.9777 | tpr=0.9577 | fpr=0.0219 | 8046.5 samples/s | 31.4 steps/s
[Step= 550] | Loss=0.12247 | acc=0.9778 | tpr=0.9570 | fpr=0.0218 | 14692.9 samples/s | 57.4 steps/s
Avg test loss: 0.12214, Avg test acc: 0.97786, Avg tpr: 0.95721, Avg fpr: 0.02176, total FA: 3022

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11953 | acc=0.9791 | tpr=0.9646 | fpr=0.0207 | 5332.7 samples/s | 20.8 steps/s
[Step= 100] | Loss=0.12450 | acc=0.9785 | tpr=0.9701 | fpr=0.0213 | 7484.4 samples/s | 29.2 steps/s
[Step= 150] | Loss=0.13049 | acc=0.9774 | tpr=0.9712 | fpr=0.0224 | 7713.1 samples/s | 30.1 steps/s
[Step= 200] | Loss=0.13249 | acc=0.9772 | tpr=0.9716 | fpr=0.0227 | 7960.4 samples/s | 31.1 steps/s
[Step= 250] | Loss=0.13034 | acc=0.9775 | tpr=0.9729 | fpr=0.0225 | 8117.3 samples/s | 31.7 steps/s
[Step= 300] | Loss=0.13275 | acc=0.9770 | tpr=0.9716 | fpr=0.0229 | 7963.7 samples/s | 31.1 steps/s
[Step= 350] | Loss=0.13371 | acc=0.9768 | tpr=0.9724 | fpr=0.0232 | 7700.7 samples/s | 30.1 steps/s
[Step= 400] | Loss=0.13483 | acc=0.9766 | tpr=0.9710 | fpr=0.0233 | 8199.0 samples/s | 32.0 steps/s
[Step= 450] | Loss=0.13761 | acc=0.9761 | tpr=0.9698 | fpr=0.0238 | 8386.4 samples/s | 32.8 steps/s
[Step= 500] | Loss=0.13699 | acc=0.9761 | tpr=0.9705 | fpr=0.0237 | 7913.5 samples/s | 30.9 steps/s
[Step= 550] | Loss=0.13583 | acc=0.9763 | tpr=0.9698 | fpr=0.0236 | 14428.4 samples/s | 56.4 steps/s
Avg test loss: 0.13550, Avg test acc: 0.97632, Avg tpr: 0.96949, Avg fpr: 0.02355, total FA: 3270

server round 49/50

clients selected: [0 1 2 3]

Train client 0: client_asml1_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=191.1] | Loss=0.01005 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=14.694 | 6989.0 samples/s | 109.2 steps/s
[Step=98050 Epoch=191.2] | Loss=0.01915 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.597 | L2-Norm(final)=14.696 | 4357.9 samples/s | 68.1 steps/s
[Step=98100 Epoch=191.3] | Loss=0.01861 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.598 | L2-Norm(final)=14.698 | 5178.2 samples/s | 80.9 steps/s
[Step=98150 Epoch=191.4] | Loss=0.01904 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.600 | L2-Norm(final)=14.701 | 5236.7 samples/s | 81.8 steps/s
[Step=98200 Epoch=191.5] | Loss=0.01919 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.602 | L2-Norm(final)=14.703 | 5189.4 samples/s | 81.1 steps/s
[Step=98250 Epoch=191.6] | Loss=0.01889 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.604 | L2-Norm(final)=14.705 | 5266.4 samples/s | 82.3 steps/s
[Step=98300 Epoch=191.7] | Loss=0.01866 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.605 | L2-Norm(final)=14.708 | 5127.6 samples/s | 80.1 steps/s
[Step=98350 Epoch=191.8] | Loss=0.01835 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.607 | L2-Norm(final)=14.711 | 5200.6 samples/s | 81.3 steps/s
[Step=98400 Epoch=191.9] | Loss=0.01836 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.609 | L2-Norm(final)=14.713 | 5242.9 samples/s | 81.9 steps/s
[Step=98450 Epoch=192.0] | Loss=0.01833 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.610 | L2-Norm(final)=14.716 | 5342.4 samples/s | 83.5 steps/s
[Step=98500 Epoch=192.1] | Loss=0.01818 | Reg=0.00214 | acc=0.9688 | L2-Norm=14.612 | L2-Norm(final)=14.719 | 6740.6 samples/s | 105.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_0/client_state-step98500.h5

Train client 1: client_asml1_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=191.6] | Loss=0.02836 | Reg=0.00223 | acc=0.9688 | L2-Norm=14.946 | L2-Norm(final)=15.170 | 7112.4 samples/s | 111.1 steps/s
[Step=98050 Epoch=191.7] | Loss=0.02093 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.948 | L2-Norm(final)=15.172 | 4300.8 samples/s | 67.2 steps/s
[Step=98100 Epoch=191.8] | Loss=0.01906 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.950 | L2-Norm(final)=15.175 | 5348.4 samples/s | 83.6 steps/s
[Step=98150 Epoch=191.9] | Loss=0.01896 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.952 | L2-Norm(final)=15.177 | 4966.9 samples/s | 77.6 steps/s
[Step=98200 Epoch=192.0] | Loss=0.01853 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.954 | L2-Norm(final)=15.180 | 5309.4 samples/s | 83.0 steps/s
[Step=98250 Epoch=192.1] | Loss=0.01822 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=15.183 | 5153.5 samples/s | 80.5 steps/s
[Step=98300 Epoch=192.2] | Loss=0.01846 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.958 | L2-Norm(final)=15.186 | 5162.2 samples/s | 80.7 steps/s
[Step=98350 Epoch=192.3] | Loss=0.01821 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.960 | L2-Norm(final)=15.189 | 5160.0 samples/s | 80.6 steps/s
[Step=98400 Epoch=192.4] | Loss=0.01793 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.962 | L2-Norm(final)=15.192 | 5234.1 samples/s | 81.8 steps/s
[Step=98450 Epoch=192.5] | Loss=0.01786 | Reg=0.00224 | acc=0.9688 | L2-Norm=14.964 | L2-Norm(final)=15.195 | 5290.1 samples/s | 82.7 steps/s
[Step=98500 Epoch=192.6] | Loss=0.01760 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=15.198 | 7057.6 samples/s | 110.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_asml1_1/client_state-step98500.h5

Train client 2: client_iccad2012_0
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=375.5] | Loss=0.00004 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.543 | L2-Norm(final)=12.158 | 5935.3 samples/s | 92.7 steps/s
[Step=98050 Epoch=375.7] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.545 | L2-Norm(final)=12.168 | 4506.9 samples/s | 70.4 steps/s
[Step=98100 Epoch=375.9] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.551 | L2-Norm(final)=12.181 | 4858.5 samples/s | 75.9 steps/s
[Step=98150 Epoch=376.1] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.555 | L2-Norm(final)=12.191 | 4982.0 samples/s | 77.8 steps/s
[Step=98200 Epoch=376.3] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.559 | L2-Norm(final)=12.202 | 4867.9 samples/s | 76.1 steps/s
[Step=98250 Epoch=376.5] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.563 | L2-Norm(final)=12.212 | 6726.2 samples/s | 105.1 steps/s
[Step=98300 Epoch=376.7] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.566 | L2-Norm(final)=12.221 | 2471.8 samples/s | 38.6 steps/s
[Step=98350 Epoch=376.8] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.569 | L2-Norm(final)=12.229 | 4866.1 samples/s | 76.0 steps/s
[Step=98400 Epoch=377.0] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.571 | L2-Norm(final)=12.237 | 5020.7 samples/s | 78.4 steps/s
[Step=98450 Epoch=377.2] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.573 | L2-Norm(final)=12.244 | 4842.1 samples/s | 75.7 steps/s
[Step=98500 Epoch=377.4] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.575 | L2-Norm(final)=12.252 | 5625.6 samples/s | 87.9 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_0/client_state-step98500.h5

Train client 3: client_iccad2012_1
Restoring client from server.
Restoring layer conv1_1.0
Restoring layer conv1_2.0
Restoring layer conv2_1.0
Restoring layer conv2_2.0
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=377.2] | Loss=0.00006 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.517 | L2-Norm(final)=12.660 | 6053.2 samples/s | 94.6 steps/s
[Step=98050 Epoch=377.4] | Loss=0.00003 | Reg=0.00030 | acc=1.0000 | L2-Norm=5.522 | L2-Norm(final)=12.673 | 4112.1 samples/s | 64.3 steps/s
[Step=98100 Epoch=377.6] | Loss=0.00003 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.528 | L2-Norm(final)=12.685 | 4958.1 samples/s | 77.5 steps/s
[Step=98150 Epoch=377.8] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.532 | L2-Norm(final)=12.697 | 4836.8 samples/s | 75.6 steps/s
[Step=98200 Epoch=378.0] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.535 | L2-Norm(final)=12.706 | 4932.4 samples/s | 77.1 steps/s
[Step=98250 Epoch=378.2] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.537 | L2-Norm(final)=12.714 | 6987.4 samples/s | 109.2 steps/s
[Step=98300 Epoch=378.4] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.539 | L2-Norm(final)=12.723 | 2450.7 samples/s | 38.3 steps/s
[Step=98350 Epoch=378.6] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.542 | L2-Norm(final)=12.732 | 4826.6 samples/s | 75.4 steps/s
[Step=98400 Epoch=378.8] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.544 | L2-Norm(final)=12.740 | 4804.7 samples/s | 75.1 steps/s
[Step=98450 Epoch=379.0] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.546 | L2-Norm(final)=12.748 | 4708.2 samples/s | 73.6 steps/s
[Step=98500 Epoch=379.2] | Loss=0.00002 | Reg=0.00031 | acc=1.0000 | L2-Norm=5.548 | L2-Norm(final)=12.755 | 5716.6 samples/s | 89.3 steps/s
Client model saved at models/model-local_fc2-a2i2-sel1.0-ch26/client_iccad2012_1/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06553 | acc=0.9616 | tpr=0.9641 | fpr=0.0436 | 5174.6 samples/s | 20.2 steps/s
Avg test loss: 0.06695, Avg test acc: 0.95933, Avg tpr: 0.96246, Avg fpr: 0.04756, total FA: 371

Testing client_asml1_1 on asml1
[Step=  50] | Loss=0.06615 | acc=0.9607 | tpr=0.9702 | fpr=0.0600 | 5255.7 samples/s | 20.5 steps/s
Avg test loss: 0.06626, Avg test acc: 0.96037, Avg tpr: 0.96928, Avg fpr: 0.05922, total FA: 462

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.10791 | acc=0.3120 | tpr=0.0056 | fpr=0.0225 | 5347.3 samples/s | 20.9 steps/s
Avg test loss: 5.11437, Avg test acc: 0.30968, Avg tpr: 0.00589, Avg fpr: 0.02218, total FA: 173

Testing client_iccad2012_1 on asml1
[Step=  50] | Loss=5.20940 | acc=0.3096 | tpr=0.0060 | fpr=0.0312 | 5430.5 samples/s | 21.2 steps/s
Avg test loss: 5.21437, Avg test acc: 0.30748, Avg tpr: 0.00641, Avg fpr: 0.03038, total FA: 237

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.62556 | acc=0.1462 | tpr=0.7168 | fpr=0.8640 | 5417.5 samples/s | 21.2 steps/s
[Step= 100] | Loss=3.61695 | acc=0.1455 | tpr=0.7058 | fpr=0.8649 | 7262.9 samples/s | 28.4 steps/s
[Step= 150] | Loss=3.61256 | acc=0.1455 | tpr=0.7161 | fpr=0.8650 | 7312.5 samples/s | 28.6 steps/s
[Step= 200] | Loss=3.61889 | acc=0.1453 | tpr=0.7137 | fpr=0.8650 | 8148.9 samples/s | 31.8 steps/s
[Step= 250] | Loss=3.62611 | acc=0.1455 | tpr=0.7039 | fpr=0.8647 | 8083.8 samples/s | 31.6 steps/s
[Step= 300] | Loss=3.62672 | acc=0.1452 | tpr=0.7011 | fpr=0.8649 | 8041.9 samples/s | 31.4 steps/s
[Step= 350] | Loss=3.62053 | acc=0.1452 | tpr=0.7001 | fpr=0.8648 | 8394.1 samples/s | 32.8 steps/s
[Step= 400] | Loss=3.61551 | acc=0.1455 | tpr=0.6969 | fpr=0.8645 | 7817.8 samples/s | 30.5 steps/s
[Step= 450] | Loss=3.61723 | acc=0.1447 | tpr=0.6991 | fpr=0.8654 | 8268.6 samples/s | 32.3 steps/s
[Step= 500] | Loss=3.61710 | acc=0.1443 | tpr=0.7000 | fpr=0.8657 | 8225.8 samples/s | 32.1 steps/s
[Step= 550] | Loss=3.61425 | acc=0.1443 | tpr=0.6968 | fpr=0.8657 | 14018.2 samples/s | 54.8 steps/s
Avg test loss: 3.61510, Avg test acc: 0.14426, Avg tpr: 0.69612, Avg fpr: 0.86577, total FA: 120210

Testing client_asml1_1 on iccad2012
[Step=  50] | Loss=3.96372 | acc=0.1487 | tpr=0.6637 | fpr=0.8606 | 5374.5 samples/s | 21.0 steps/s
[Step= 100] | Loss=3.95802 | acc=0.1469 | tpr=0.6226 | fpr=0.8620 | 7288.2 samples/s | 28.5 steps/s
[Step= 150] | Loss=3.95128 | acc=0.1479 | tpr=0.6441 | fpr=0.8612 | 7755.2 samples/s | 30.3 steps/s
[Step= 200] | Loss=3.95404 | acc=0.1479 | tpr=0.6470 | fpr=0.8612 | 8141.6 samples/s | 31.8 steps/s
[Step= 250] | Loss=3.96198 | acc=0.1478 | tpr=0.6428 | fpr=0.8612 | 8372.3 samples/s | 32.7 steps/s
[Step= 300] | Loss=3.96379 | acc=0.1476 | tpr=0.6429 | fpr=0.8615 | 7916.5 samples/s | 30.9 steps/s
[Step= 350] | Loss=3.95561 | acc=0.1479 | tpr=0.6399 | fpr=0.8610 | 8109.0 samples/s | 31.7 steps/s
[Step= 400] | Loss=3.95078 | acc=0.1480 | tpr=0.6400 | fpr=0.8609 | 8217.9 samples/s | 32.1 steps/s
[Step= 450] | Loss=3.95152 | acc=0.1473 | tpr=0.6407 | fpr=0.8617 | 8048.5 samples/s | 31.4 steps/s
[Step= 500] | Loss=3.95330 | acc=0.1471 | tpr=0.6410 | fpr=0.8618 | 7969.7 samples/s | 31.1 steps/s
[Step= 550] | Loss=3.95034 | acc=0.1473 | tpr=0.6379 | fpr=0.8616 | 15198.5 samples/s | 59.4 steps/s
Avg test loss: 3.95153, Avg test acc: 0.14728, Avg tpr: 0.63748, Avg fpr: 0.86163, total FA: 119636

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10892 | acc=0.9781 | tpr=0.9513 | fpr=0.0214 | 5038.0 samples/s | 19.7 steps/s
[Step= 100] | Loss=0.11396 | acc=0.9774 | tpr=0.9638 | fpr=0.0223 | 7845.9 samples/s | 30.6 steps/s
[Step= 150] | Loss=0.11864 | acc=0.9765 | tpr=0.9640 | fpr=0.0232 | 7586.3 samples/s | 29.6 steps/s
[Step= 200] | Loss=0.12012 | acc=0.9764 | tpr=0.9661 | fpr=0.0234 | 8210.5 samples/s | 32.1 steps/s
[Step= 250] | Loss=0.11859 | acc=0.9768 | tpr=0.9677 | fpr=0.0231 | 8571.7 samples/s | 33.5 steps/s
[Step= 300] | Loss=0.12067 | acc=0.9763 | tpr=0.9665 | fpr=0.0235 | 8067.7 samples/s | 31.5 steps/s
[Step= 350] | Loss=0.12150 | acc=0.9759 | tpr=0.9674 | fpr=0.0239 | 8106.5 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.12259 | acc=0.9758 | tpr=0.9666 | fpr=0.0241 | 8155.5 samples/s | 31.9 steps/s
[Step= 450] | Loss=0.12496 | acc=0.9753 | tpr=0.9659 | fpr=0.0245 | 8377.8 samples/s | 32.7 steps/s
[Step= 500] | Loss=0.12434 | acc=0.9753 | tpr=0.9665 | fpr=0.0245 | 8089.5 samples/s | 31.6 steps/s
[Step= 550] | Loss=0.12345 | acc=0.9755 | tpr=0.9666 | fpr=0.0244 | 14922.0 samples/s | 58.3 steps/s
Avg test loss: 0.12311, Avg test acc: 0.97550, Avg tpr: 0.96672, Avg fpr: 0.02434, total FA: 3380

Testing client_iccad2012_1 on iccad2012
[Step=  50] | Loss=0.11220 | acc=0.9793 | tpr=0.9513 | fpr=0.0202 | 5290.7 samples/s | 20.7 steps/s
[Step= 100] | Loss=0.11714 | acc=0.9783 | tpr=0.9595 | fpr=0.0213 | 7383.7 samples/s | 28.8 steps/s
[Step= 150] | Loss=0.12243 | acc=0.9774 | tpr=0.9640 | fpr=0.0224 | 7438.5 samples/s | 29.1 steps/s
[Step= 200] | Loss=0.12411 | acc=0.9774 | tpr=0.9661 | fpr=0.0224 | 8271.6 samples/s | 32.3 steps/s
[Step= 250] | Loss=0.12225 | acc=0.9777 | tpr=0.9677 | fpr=0.0221 | 8280.5 samples/s | 32.3 steps/s
[Step= 300] | Loss=0.12448 | acc=0.9773 | tpr=0.9665 | fpr=0.0225 | 7921.1 samples/s | 30.9 steps/s
[Step= 350] | Loss=0.12534 | acc=0.9770 | tpr=0.9674 | fpr=0.0229 | 8109.8 samples/s | 31.7 steps/s
[Step= 400] | Loss=0.12641 | acc=0.9769 | tpr=0.9661 | fpr=0.0229 | 8231.6 samples/s | 32.2 steps/s
[Step= 450] | Loss=0.12899 | acc=0.9764 | tpr=0.9649 | fpr=0.0234 | 8121.9 samples/s | 31.7 steps/s
[Step= 500] | Loss=0.12838 | acc=0.9764 | tpr=0.9656 | fpr=0.0234 | 8475.0 samples/s | 33.1 steps/s
[Step= 550] | Loss=0.12733 | acc=0.9765 | tpr=0.9658 | fpr=0.0233 | 13833.5 samples/s | 54.0 steps/s
Avg test loss: 0.12700, Avg test acc: 0.97653, Avg tpr: 0.96513, Avg fpr: 0.02326, total FA: 3230
