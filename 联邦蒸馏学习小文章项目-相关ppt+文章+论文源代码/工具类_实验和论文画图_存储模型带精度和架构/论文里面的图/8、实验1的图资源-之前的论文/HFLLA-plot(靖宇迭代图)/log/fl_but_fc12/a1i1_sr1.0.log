#clients of iccad2012: 1
#clients of asml1: 1
select ratio: 1.0
Total num clients: 2
client model path: ['models/model-a1i1_sr1.0/client_asml1_0', 'models/model-a1i1_sr1.0/client_iccad2012_0']
client benchmark path: {'asml1': './benchmarks/asml1_train', 'asml2': './benchmarks/asml2_train', 'asml3': './benchmarks/asml3_train', 'asml4': './benchmarks/asml4_train', 'iccad2012': './benchmarks/iccad2012_train'}
loading data into the main memory...
Allocated dataset with size (49916, 144, 32)
Resampled dataset to size (65551, 144, 32)
Using transform option: train
#pos = 34281, #neg = 31270
loading data into the main memory...
Allocated dataset with size (18300, 144, 32)
Resampled dataset to size (33952, 144, 32)
Using transform option: train
#pos = 16856, #neg = 17096
loading data into the main memory...
Allocated dataset with size (24958, 144, 32)
Using transform option: test
#pos = 17157, #neg = 7801
loading data into the main memory...
Allocated dataset with size (141372, 144, 32)
Using transform option: test
#pos = 2524, #neg = 138848
Using device: cuda

server round 0/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.37581 | Reg=0.00355 | acc=0.5156 | L2-Norm=18.849 | L2-Norm(final)=2.082 | 2531.9 samples/s | 39.6 steps/s
[Step=  50 Epoch= 0.0] | Loss=0.33188 | Reg=0.00337 | acc=0.6094 | L2-Norm=18.357 | L2-Norm(final)=2.065 | 4826.2 samples/s | 75.4 steps/s
[Step= 100 Epoch= 0.1] | Loss=0.31645 | Reg=0.00329 | acc=0.7500 | L2-Norm=18.135 | L2-Norm(final)=2.066 | 4744.3 samples/s | 74.1 steps/s
[Step= 150 Epoch= 0.1] | Loss=0.30701 | Reg=0.00325 | acc=0.7031 | L2-Norm=18.013 | L2-Norm(final)=2.069 | 4766.6 samples/s | 74.5 steps/s
[Step= 200 Epoch= 0.2] | Loss=0.30188 | Reg=0.00322 | acc=0.6406 | L2-Norm=17.934 | L2-Norm(final)=2.073 | 4703.6 samples/s | 73.5 steps/s
[Step= 250 Epoch= 0.2] | Loss=0.29490 | Reg=0.00320 | acc=0.8125 | L2-Norm=17.879 | L2-Norm(final)=2.080 | 4805.2 samples/s | 75.1 steps/s
[Step= 300 Epoch= 0.3] | Loss=0.29094 | Reg=0.00318 | acc=0.6875 | L2-Norm=17.843 | L2-Norm(final)=2.088 | 4772.8 samples/s | 74.6 steps/s
[Step= 350 Epoch= 0.3] | Loss=0.28743 | Reg=0.00318 | acc=0.7500 | L2-Norm=17.820 | L2-Norm(final)=2.096 | 4735.5 samples/s | 74.0 steps/s
[Step= 400 Epoch= 0.4] | Loss=0.28401 | Reg=0.00317 | acc=0.7500 | L2-Norm=17.804 | L2-Norm(final)=2.105 | 4784.5 samples/s | 74.8 steps/s
[Step= 450 Epoch= 0.4] | Loss=0.28104 | Reg=0.00317 | acc=0.7188 | L2-Norm=17.794 | L2-Norm(final)=2.115 | 4688.0 samples/s | 73.2 steps/s
[Step= 500 Epoch= 0.5] | Loss=0.27795 | Reg=0.00317 | acc=0.7344 | L2-Norm=17.791 | L2-Norm(final)=2.125 | 4884.9 samples/s | 76.3 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.5] | Loss=0.25271 | Reg=0.00316 | acc=0.7344 | L2-Norm=17.786 | L2-Norm(final)=2.228 | 3387.7 samples/s | 52.9 steps/s
[Step= 550 Epoch= 0.5] | Loss=0.24505 | Reg=0.00316 | acc=0.8125 | L2-Norm=17.770 | L2-Norm(final)=2.228 | 3794.3 samples/s | 59.3 steps/s
[Step= 600 Epoch= 0.6] | Loss=0.22928 | Reg=0.00316 | acc=0.8438 | L2-Norm=17.771 | L2-Norm(final)=2.234 | 3984.4 samples/s | 62.3 steps/s
[Step= 650 Epoch= 0.6] | Loss=0.21121 | Reg=0.00316 | acc=0.7969 | L2-Norm=17.774 | L2-Norm(final)=2.239 | 3863.6 samples/s | 60.4 steps/s
[Step= 700 Epoch= 0.7] | Loss=0.19652 | Reg=0.00316 | acc=0.9375 | L2-Norm=17.779 | L2-Norm(final)=2.244 | 3914.8 samples/s | 61.2 steps/s
[Step= 750 Epoch= 0.7] | Loss=0.18631 | Reg=0.00316 | acc=0.8750 | L2-Norm=17.783 | L2-Norm(final)=2.249 | 3930.7 samples/s | 61.4 steps/s
[Step= 800 Epoch= 0.8] | Loss=0.17920 | Reg=0.00316 | acc=0.9219 | L2-Norm=17.785 | L2-Norm(final)=2.253 | 3936.0 samples/s | 61.5 steps/s
[Step= 850 Epoch= 0.8] | Loss=0.16988 | Reg=0.00316 | acc=0.9844 | L2-Norm=17.785 | L2-Norm(final)=2.256 | 3959.8 samples/s | 61.9 steps/s
[Step= 900 Epoch= 0.9] | Loss=0.16286 | Reg=0.00316 | acc=0.9688 | L2-Norm=17.785 | L2-Norm(final)=2.258 | 3943.9 samples/s | 61.6 steps/s
[Step= 950 Epoch= 0.9] | Loss=0.15751 | Reg=0.00316 | acc=0.9219 | L2-Norm=17.787 | L2-Norm(final)=2.261 | 3962.5 samples/s | 61.9 steps/s
[Step=1000 Epoch= 1.0] | Loss=0.15334 | Reg=0.00316 | acc=0.9375 | L2-Norm=17.789 | L2-Norm(final)=2.264 | 3948.3 samples/s | 61.7 steps/s
[Step=1050 Epoch= 1.0] | Loss=0.14819 | Reg=0.00317 | acc=0.9062 | L2-Norm=17.792 | L2-Norm(final)=2.266 | 3968.8 samples/s | 62.0 steps/s
[Step=1100 Epoch= 1.1] | Loss=0.14467 | Reg=0.00317 | acc=0.9062 | L2-Norm=17.794 | L2-Norm(final)=2.269 | 3928.3 samples/s | 61.4 steps/s
[Step=1150 Epoch= 1.1] | Loss=0.14150 | Reg=0.00317 | acc=0.9531 | L2-Norm=17.795 | L2-Norm(final)=2.271 | 3954.9 samples/s | 61.8 steps/s
[Step=1200 Epoch= 1.2] | Loss=0.13822 | Reg=0.00317 | acc=0.9531 | L2-Norm=17.795 | L2-Norm(final)=2.273 | 3978.4 samples/s | 62.2 steps/s
[Step=1250 Epoch= 1.2] | Loss=0.13482 | Reg=0.00317 | acc=0.9219 | L2-Norm=17.794 | L2-Norm(final)=2.274 | 3957.6 samples/s | 61.8 steps/s
[Step=1300 Epoch= 1.3] | Loss=0.13179 | Reg=0.00317 | acc=0.9531 | L2-Norm=17.792 | L2-Norm(final)=2.276 | 3933.9 samples/s | 61.5 steps/s
[Step=1350 Epoch= 1.3] | Loss=0.12912 | Reg=0.00317 | acc=0.9062 | L2-Norm=17.792 | L2-Norm(final)=2.278 | 3986.1 samples/s | 62.3 steps/s
[Step=1400 Epoch= 1.4] | Loss=0.12694 | Reg=0.00317 | acc=0.9219 | L2-Norm=17.793 | L2-Norm(final)=2.280 | 3967.7 samples/s | 62.0 steps/s
[Step=1450 Epoch= 1.4] | Loss=0.12418 | Reg=0.00317 | acc=0.9688 | L2-Norm=17.794 | L2-Norm(final)=2.282 | 3988.3 samples/s | 62.3 steps/s
[Step=1500 Epoch= 1.5] | Loss=0.12223 | Reg=0.00317 | acc=0.9375 | L2-Norm=17.796 | L2-Norm(final)=2.284 | 4253.0 samples/s | 66.5 steps/s
[Step=1550 Epoch= 1.5] | Loss=0.11968 | Reg=0.00317 | acc=0.9219 | L2-Norm=17.799 | L2-Norm(final)=2.286 | 1673.5 samples/s | 26.1 steps/s
[Step=1600 Epoch= 1.6] | Loss=0.11743 | Reg=0.00317 | acc=0.9688 | L2-Norm=17.802 | L2-Norm(final)=2.288 | 3929.7 samples/s | 61.4 steps/s
[Step=1650 Epoch= 1.6] | Loss=0.11494 | Reg=0.00317 | acc=0.9844 | L2-Norm=17.807 | L2-Norm(final)=2.290 | 3995.5 samples/s | 62.4 steps/s
[Step=1700 Epoch= 1.7] | Loss=0.11254 | Reg=0.00317 | acc=0.9062 | L2-Norm=17.811 | L2-Norm(final)=2.293 | 3896.8 samples/s | 60.9 steps/s
[Step=1750 Epoch= 1.7] | Loss=0.11074 | Reg=0.00317 | acc=0.8906 | L2-Norm=17.814 | L2-Norm(final)=2.295 | 3938.6 samples/s | 61.5 steps/s
[Step=1800 Epoch= 1.8] | Loss=0.10888 | Reg=0.00317 | acc=0.9531 | L2-Norm=17.818 | L2-Norm(final)=2.297 | 3951.5 samples/s | 61.7 steps/s
[Step=1850 Epoch= 1.8] | Loss=0.10728 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.822 | L2-Norm(final)=2.300 | 3962.1 samples/s | 61.9 steps/s
[Step=1900 Epoch= 1.9] | Loss=0.10605 | Reg=0.00318 | acc=0.9219 | L2-Norm=17.827 | L2-Norm(final)=2.302 | 3969.0 samples/s | 62.0 steps/s
[Step=1950 Epoch= 1.9] | Loss=0.10472 | Reg=0.00318 | acc=0.9688 | L2-Norm=17.832 | L2-Norm(final)=2.303 | 3979.4 samples/s | 62.2 steps/s
[Step=2000 Epoch= 2.0] | Loss=0.10333 | Reg=0.00318 | acc=0.9531 | L2-Norm=17.837 | L2-Norm(final)=2.305 | 3967.8 samples/s | 62.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step2000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=   1 Epoch= 0.0] | Loss=0.31149 | Reg=0.00355 | acc=0.5469 | L2-Norm=18.849 | L2-Norm(final)=2.082 | 3164.8 samples/s | 49.4 steps/s
[Step=  50 Epoch= 0.1] | Loss=0.21073 | Reg=0.00343 | acc=0.8594 | L2-Norm=18.509 | L2-Norm(final)=2.104 | 4300.3 samples/s | 67.2 steps/s
[Step= 100 Epoch= 0.2] | Loss=0.17580 | Reg=0.00339 | acc=0.8750 | L2-Norm=18.406 | L2-Norm(final)=2.135 | 4413.2 samples/s | 69.0 steps/s
[Step= 150 Epoch= 0.3] | Loss=0.15577 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.357 | L2-Norm(final)=2.163 | 4379.7 samples/s | 68.4 steps/s
[Step= 200 Epoch= 0.4] | Loss=0.14409 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.325 | L2-Norm(final)=2.187 | 4287.0 samples/s | 67.0 steps/s
[Step= 250 Epoch= 0.5] | Loss=0.13793 | Reg=0.00335 | acc=0.9062 | L2-Norm=18.310 | L2-Norm(final)=2.207 | 4410.5 samples/s | 68.9 steps/s
[Step= 300 Epoch= 0.6] | Loss=0.13329 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.304 | L2-Norm(final)=2.223 | 4375.9 samples/s | 68.4 steps/s
[Step= 350 Epoch= 0.7] | Loss=0.12790 | Reg=0.00335 | acc=0.9375 | L2-Norm=18.299 | L2-Norm(final)=2.237 | 4364.2 samples/s | 68.2 steps/s
[Step= 400 Epoch= 0.8] | Loss=0.12450 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.292 | L2-Norm(final)=2.249 | 4454.7 samples/s | 69.6 steps/s
[Step= 450 Epoch= 0.8] | Loss=0.12051 | Reg=0.00334 | acc=0.8281 | L2-Norm=18.283 | L2-Norm(final)=2.261 | 4353.8 samples/s | 68.0 steps/s
[Step= 500 Epoch= 0.9] | Loss=0.11746 | Reg=0.00334 | acc=0.9375 | L2-Norm=18.276 | L2-Norm(final)=2.274 | 4395.3 samples/s | 68.7 steps/s
All layers training...
LR=0.00100, len=1
[Step= 501 Epoch= 0.9] | Loss=0.04866 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.215 | L2-Norm(final)=2.395 | 3218.9 samples/s | 50.3 steps/s
[Step= 550 Epoch= 1.0] | Loss=0.07740 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.175 | L2-Norm(final)=2.401 | 3492.7 samples/s | 54.6 steps/s
[Step= 600 Epoch= 1.1] | Loss=0.05825 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.163 | L2-Norm(final)=2.414 | 3705.5 samples/s | 57.9 steps/s
[Step= 650 Epoch= 1.2] | Loss=0.05129 | Reg=0.00329 | acc=0.9844 | L2-Norm=18.144 | L2-Norm(final)=2.420 | 3754.2 samples/s | 58.7 steps/s
[Step= 700 Epoch= 1.3] | Loss=0.04340 | Reg=0.00328 | acc=0.9531 | L2-Norm=18.124 | L2-Norm(final)=2.427 | 3669.9 samples/s | 57.3 steps/s
[Step= 750 Epoch= 1.4] | Loss=0.03862 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.104 | L2-Norm(final)=2.433 | 3713.9 samples/s | 58.0 steps/s
[Step= 800 Epoch= 1.5] | Loss=0.03442 | Reg=0.00327 | acc=1.0000 | L2-Norm=18.085 | L2-Norm(final)=2.438 | 3755.6 samples/s | 58.7 steps/s
[Step= 850 Epoch= 1.6] | Loss=0.03083 | Reg=0.00327 | acc=0.9844 | L2-Norm=18.069 | L2-Norm(final)=2.443 | 3717.9 samples/s | 58.1 steps/s
[Step= 900 Epoch= 1.7] | Loss=0.02819 | Reg=0.00326 | acc=1.0000 | L2-Norm=18.053 | L2-Norm(final)=2.448 | 3726.0 samples/s | 58.2 steps/s
[Step= 950 Epoch= 1.8] | Loss=0.02587 | Reg=0.00325 | acc=1.0000 | L2-Norm=18.036 | L2-Norm(final)=2.453 | 3715.9 samples/s | 58.1 steps/s
[Step=1000 Epoch= 1.9] | Loss=0.02358 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.021 | L2-Norm(final)=2.458 | 3765.8 samples/s | 58.8 steps/s
[Step=1050 Epoch= 2.0] | Loss=0.02168 | Reg=0.00324 | acc=1.0000 | L2-Norm=18.006 | L2-Norm(final)=2.462 | 1639.9 samples/s | 25.6 steps/s
[Step=1100 Epoch= 2.1] | Loss=0.02006 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.991 | L2-Norm(final)=2.466 | 3757.8 samples/s | 58.7 steps/s
[Step=1150 Epoch= 2.2] | Loss=0.01866 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.976 | L2-Norm(final)=2.470 | 3724.6 samples/s | 58.2 steps/s
[Step=1200 Epoch= 2.3] | Loss=0.01744 | Reg=0.00323 | acc=1.0000 | L2-Norm=17.961 | L2-Norm(final)=2.474 | 3743.1 samples/s | 58.5 steps/s
[Step=1250 Epoch= 2.4] | Loss=0.01643 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.945 | L2-Norm(final)=2.478 | 3646.7 samples/s | 57.0 steps/s
[Step=1300 Epoch= 2.5] | Loss=0.01552 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.929 | L2-Norm(final)=2.482 | 3706.1 samples/s | 57.9 steps/s
[Step=1350 Epoch= 2.5] | Loss=0.01478 | Reg=0.00321 | acc=1.0000 | L2-Norm=17.914 | L2-Norm(final)=2.485 | 3709.4 samples/s | 58.0 steps/s
[Step=1400 Epoch= 2.6] | Loss=0.01399 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.899 | L2-Norm(final)=2.489 | 3714.3 samples/s | 58.0 steps/s
[Step=1450 Epoch= 2.7] | Loss=0.01334 | Reg=0.00320 | acc=1.0000 | L2-Norm=17.883 | L2-Norm(final)=2.492 | 3734.5 samples/s | 58.4 steps/s
[Step=1500 Epoch= 2.8] | Loss=0.01275 | Reg=0.00319 | acc=1.0000 | L2-Norm=17.867 | L2-Norm(final)=2.496 | 3720.7 samples/s | 58.1 steps/s
[Step=1550 Epoch= 2.9] | Loss=0.01240 | Reg=0.00319 | acc=0.9844 | L2-Norm=17.851 | L2-Norm(final)=2.498 | 4655.2 samples/s | 72.7 steps/s
[Step=1600 Epoch= 3.0] | Loss=0.01209 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.836 | L2-Norm(final)=2.501 | 1514.0 samples/s | 23.7 steps/s
[Step=1650 Epoch= 3.1] | Loss=0.01176 | Reg=0.00318 | acc=1.0000 | L2-Norm=17.823 | L2-Norm(final)=2.503 | 3666.5 samples/s | 57.3 steps/s
[Step=1700 Epoch= 3.2] | Loss=0.01133 | Reg=0.00317 | acc=1.0000 | L2-Norm=17.811 | L2-Norm(final)=2.506 | 3683.3 samples/s | 57.6 steps/s
[Step=1750 Epoch= 3.3] | Loss=0.01097 | Reg=0.00317 | acc=1.0000 | L2-Norm=17.798 | L2-Norm(final)=2.509 | 3673.8 samples/s | 57.4 steps/s
[Step=1800 Epoch= 3.4] | Loss=0.01058 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.785 | L2-Norm(final)=2.511 | 3649.7 samples/s | 57.0 steps/s
[Step=1850 Epoch= 3.5] | Loss=0.01029 | Reg=0.00316 | acc=1.0000 | L2-Norm=17.772 | L2-Norm(final)=2.514 | 3741.1 samples/s | 58.5 steps/s
[Step=1900 Epoch= 3.6] | Loss=0.01017 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.760 | L2-Norm(final)=2.516 | 3726.8 samples/s | 58.2 steps/s
[Step=1950 Epoch= 3.7] | Loss=0.00989 | Reg=0.00315 | acc=1.0000 | L2-Norm=17.750 | L2-Norm(final)=2.518 | 3686.2 samples/s | 57.6 steps/s
[Step=2000 Epoch= 3.8] | Loss=0.00967 | Reg=0.00315 | acc=0.9844 | L2-Norm=17.739 | L2-Norm(final)=2.521 | 3729.7 samples/s | 58.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step2000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.07034 | acc=0.9471 | tpr=0.9471 | fpr=0.0528 | 3615.0 samples/s | 14.1 steps/s
Avg test loss: 0.07059, Avg test acc: 0.94679, Avg tpr: 0.94632, Avg fpr: 0.05217, total FA: 407

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.23931 | acc=0.3225 | tpr=0.0277 | fpr=0.0374 | 3631.3 samples/s | 14.2 steps/s
Avg test loss: 3.24484, Avg test acc: 0.31874, Avg tpr: 0.02541, Avg fpr: 0.03615, total FA: 282

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.29887 | acc=0.1320 | tpr=0.8009 | fpr=0.8800 | 3587.5 samples/s | 14.0 steps/s
[Step= 100] | Loss=2.28699 | acc=0.1345 | tpr=0.7761 | fpr=0.8775 | 7023.3 samples/s | 27.4 steps/s
[Step= 150] | Loss=2.29415 | acc=0.1335 | tpr=0.7839 | fpr=0.8785 | 6838.7 samples/s | 26.7 steps/s
[Step= 200] | Loss=2.28960 | acc=0.1341 | tpr=0.7803 | fpr=0.8777 | 6770.4 samples/s | 26.4 steps/s
[Step= 250] | Loss=2.29027 | acc=0.1344 | tpr=0.7860 | fpr=0.8775 | 7234.7 samples/s | 28.3 steps/s
[Step= 300] | Loss=2.29063 | acc=0.1340 | tpr=0.7913 | fpr=0.8780 | 6829.4 samples/s | 26.7 steps/s
[Step= 350] | Loss=2.29090 | acc=0.1335 | tpr=0.7971 | fpr=0.8785 | 6912.1 samples/s | 27.0 steps/s
[Step= 400] | Loss=2.29107 | acc=0.1342 | tpr=0.7992 | fpr=0.8779 | 6804.9 samples/s | 26.6 steps/s
[Step= 450] | Loss=2.29290 | acc=0.1343 | tpr=0.7999 | fpr=0.8778 | 6923.6 samples/s | 27.0 steps/s
[Step= 500] | Loss=2.29303 | acc=0.1342 | tpr=0.7991 | fpr=0.8778 | 6770.9 samples/s | 26.4 steps/s
[Step= 550] | Loss=2.29350 | acc=0.1338 | tpr=0.8038 | fpr=0.8783 | 12757.8 samples/s | 49.8 steps/s
Avg test loss: 2.29380, Avg test acc: 0.13373, Avg tpr: 0.80428, Avg fpr: 0.87846, total FA: 121973

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.07314 | acc=0.9795 | tpr=0.9558 | fpr=0.0201 | 3652.2 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.07506 | acc=0.9791 | tpr=0.9723 | fpr=0.0208 | 6879.4 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.07709 | acc=0.9781 | tpr=0.9726 | fpr=0.0218 | 6873.8 samples/s | 26.9 steps/s
[Step= 200] | Loss=0.07926 | acc=0.9780 | tpr=0.9770 | fpr=0.0220 | 6890.7 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.07818 | acc=0.9783 | tpr=0.9747 | fpr=0.0217 | 6839.9 samples/s | 26.7 steps/s
[Step= 300] | Loss=0.08005 | acc=0.9779 | tpr=0.9731 | fpr=0.0220 | 7007.8 samples/s | 27.4 steps/s
[Step= 350] | Loss=0.08040 | acc=0.9776 | tpr=0.9724 | fpr=0.0224 | 6865.5 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.08126 | acc=0.9773 | tpr=0.9705 | fpr=0.0226 | 6880.9 samples/s | 26.9 steps/s
[Step= 450] | Loss=0.08284 | acc=0.9770 | tpr=0.9674 | fpr=0.0228 | 6735.0 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.08201 | acc=0.9771 | tpr=0.9687 | fpr=0.0227 | 6802.7 samples/s | 26.6 steps/s
[Step= 550] | Loss=0.08149 | acc=0.9774 | tpr=0.9690 | fpr=0.0225 | 12262.6 samples/s | 47.9 steps/s
Avg test loss: 0.08128, Avg test acc: 0.97737, Avg tpr: 0.96910, Avg fpr: 0.02248, total FA: 3121

server round 1/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 2.0] | Loss=0.28085 | Reg=0.00265 | acc=0.7031 | L2-Norm=16.282 | L2-Norm(final)=2.354 | 3192.1 samples/s | 49.9 steps/s
[Step=2050 Epoch= 2.0] | Loss=0.18342 | Reg=0.00277 | acc=0.8906 | L2-Norm=16.655 | L2-Norm(final)=2.373 | 4291.0 samples/s | 67.0 steps/s
[Step=2100 Epoch= 2.1] | Loss=0.16526 | Reg=0.00283 | acc=0.8438 | L2-Norm=16.826 | L2-Norm(final)=2.404 | 4330.1 samples/s | 67.7 steps/s
[Step=2150 Epoch= 2.1] | Loss=0.16164 | Reg=0.00286 | acc=0.9062 | L2-Norm=16.922 | L2-Norm(final)=2.429 | 4356.3 samples/s | 68.1 steps/s
[Step=2200 Epoch= 2.1] | Loss=0.15291 | Reg=0.00289 | acc=0.8594 | L2-Norm=16.996 | L2-Norm(final)=2.453 | 4463.6 samples/s | 69.7 steps/s
[Step=2250 Epoch= 2.2] | Loss=0.14961 | Reg=0.00291 | acc=0.8906 | L2-Norm=17.055 | L2-Norm(final)=2.475 | 4365.3 samples/s | 68.2 steps/s
[Step=2300 Epoch= 2.2] | Loss=0.14756 | Reg=0.00293 | acc=0.8438 | L2-Norm=17.111 | L2-Norm(final)=2.494 | 4319.9 samples/s | 67.5 steps/s
[Step=2350 Epoch= 2.3] | Loss=0.14540 | Reg=0.00295 | acc=0.8906 | L2-Norm=17.164 | L2-Norm(final)=2.513 | 4408.4 samples/s | 68.9 steps/s
[Step=2400 Epoch= 2.3] | Loss=0.14340 | Reg=0.00296 | acc=0.9219 | L2-Norm=17.211 | L2-Norm(final)=2.533 | 4352.8 samples/s | 68.0 steps/s
[Step=2450 Epoch= 2.4] | Loss=0.14197 | Reg=0.00298 | acc=0.8438 | L2-Norm=17.256 | L2-Norm(final)=2.551 | 4350.0 samples/s | 68.0 steps/s
[Step=2500 Epoch= 2.4] | Loss=0.14001 | Reg=0.00299 | acc=0.8594 | L2-Norm=17.301 | L2-Norm(final)=2.570 | 4312.6 samples/s | 67.4 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 2.4] | Loss=0.18960 | Reg=0.00316 | acc=0.8125 | L2-Norm=17.763 | L2-Norm(final)=2.763 | 3298.2 samples/s | 51.5 steps/s
[Step=2550 Epoch= 2.5] | Loss=0.12833 | Reg=0.00317 | acc=0.8750 | L2-Norm=17.794 | L2-Norm(final)=2.764 | 3904.9 samples/s | 61.0 steps/s
[Step=2600 Epoch= 2.5] | Loss=0.11969 | Reg=0.00317 | acc=0.9375 | L2-Norm=17.814 | L2-Norm(final)=2.757 | 3900.6 samples/s | 60.9 steps/s
[Step=2650 Epoch= 2.6] | Loss=0.11455 | Reg=0.00318 | acc=0.9219 | L2-Norm=17.834 | L2-Norm(final)=2.754 | 3938.2 samples/s | 61.5 steps/s
[Step=2700 Epoch= 2.6] | Loss=0.10920 | Reg=0.00319 | acc=0.9375 | L2-Norm=17.851 | L2-Norm(final)=2.752 | 3893.1 samples/s | 60.8 steps/s
[Step=2750 Epoch= 2.7] | Loss=0.10403 | Reg=0.00319 | acc=0.9375 | L2-Norm=17.866 | L2-Norm(final)=2.752 | 4013.4 samples/s | 62.7 steps/s
[Step=2800 Epoch= 2.7] | Loss=0.10044 | Reg=0.00320 | acc=0.9531 | L2-Norm=17.879 | L2-Norm(final)=2.751 | 3907.2 samples/s | 61.1 steps/s
[Step=2850 Epoch= 2.8] | Loss=0.09844 | Reg=0.00320 | acc=0.9219 | L2-Norm=17.890 | L2-Norm(final)=2.751 | 3955.8 samples/s | 61.8 steps/s
[Step=2900 Epoch= 2.8] | Loss=0.09474 | Reg=0.00321 | acc=0.9375 | L2-Norm=17.903 | L2-Norm(final)=2.752 | 4010.3 samples/s | 62.7 steps/s
[Step=2950 Epoch= 2.9] | Loss=0.09371 | Reg=0.00321 | acc=0.9688 | L2-Norm=17.916 | L2-Norm(final)=2.752 | 3939.4 samples/s | 61.6 steps/s
[Step=3000 Epoch= 2.9] | Loss=0.09109 | Reg=0.00321 | acc=0.9219 | L2-Norm=17.930 | L2-Norm(final)=2.753 | 3894.4 samples/s | 60.9 steps/s
[Step=3050 Epoch= 3.0] | Loss=0.08952 | Reg=0.00322 | acc=0.9219 | L2-Norm=17.943 | L2-Norm(final)=2.753 | 3917.4 samples/s | 61.2 steps/s
[Step=3100 Epoch= 3.0] | Loss=0.08771 | Reg=0.00322 | acc=1.0000 | L2-Norm=17.955 | L2-Norm(final)=2.753 | 3949.2 samples/s | 61.7 steps/s
[Step=3150 Epoch= 3.1] | Loss=0.08629 | Reg=0.00323 | acc=0.9531 | L2-Norm=17.966 | L2-Norm(final)=2.753 | 3942.1 samples/s | 61.6 steps/s
[Step=3200 Epoch= 3.1] | Loss=0.08518 | Reg=0.00323 | acc=0.9375 | L2-Norm=17.977 | L2-Norm(final)=2.753 | 3908.0 samples/s | 61.1 steps/s
[Step=3250 Epoch= 3.2] | Loss=0.08364 | Reg=0.00324 | acc=0.9219 | L2-Norm=17.986 | L2-Norm(final)=2.753 | 3932.7 samples/s | 61.4 steps/s
[Step=3300 Epoch= 3.2] | Loss=0.08262 | Reg=0.00324 | acc=0.9531 | L2-Norm=17.994 | L2-Norm(final)=2.752 | 3932.3 samples/s | 61.4 steps/s
[Step=3350 Epoch= 3.3] | Loss=0.08114 | Reg=0.00324 | acc=0.9219 | L2-Norm=18.002 | L2-Norm(final)=2.751 | 3922.9 samples/s | 61.3 steps/s
[Step=3400 Epoch= 3.3] | Loss=0.08021 | Reg=0.00324 | acc=0.9531 | L2-Norm=18.009 | L2-Norm(final)=2.751 | 3926.6 samples/s | 61.4 steps/s
[Step=3450 Epoch= 3.4] | Loss=0.07903 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.018 | L2-Norm(final)=2.751 | 3978.1 samples/s | 62.2 steps/s
[Step=3500 Epoch= 3.4] | Loss=0.07789 | Reg=0.00325 | acc=0.9375 | L2-Norm=18.026 | L2-Norm(final)=2.751 | 4218.8 samples/s | 65.9 steps/s
[Step=3550 Epoch= 3.5] | Loss=0.07684 | Reg=0.00325 | acc=0.9375 | L2-Norm=18.035 | L2-Norm(final)=2.751 | 1674.9 samples/s | 26.2 steps/s
[Step=3600 Epoch= 3.5] | Loss=0.07540 | Reg=0.00326 | acc=0.9531 | L2-Norm=18.045 | L2-Norm(final)=2.751 | 3911.6 samples/s | 61.1 steps/s
[Step=3650 Epoch= 3.6] | Loss=0.07455 | Reg=0.00326 | acc=0.9531 | L2-Norm=18.054 | L2-Norm(final)=2.751 | 3911.5 samples/s | 61.1 steps/s
[Step=3700 Epoch= 3.6] | Loss=0.07345 | Reg=0.00326 | acc=0.9688 | L2-Norm=18.064 | L2-Norm(final)=2.751 | 3953.2 samples/s | 61.8 steps/s
[Step=3750 Epoch= 3.7] | Loss=0.07236 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.073 | L2-Norm(final)=2.752 | 3898.1 samples/s | 60.9 steps/s
[Step=3800 Epoch= 3.7] | Loss=0.07142 | Reg=0.00327 | acc=0.9531 | L2-Norm=18.081 | L2-Norm(final)=2.752 | 3880.1 samples/s | 60.6 steps/s
[Step=3850 Epoch= 3.8] | Loss=0.07062 | Reg=0.00327 | acc=0.9531 | L2-Norm=18.089 | L2-Norm(final)=2.752 | 3925.8 samples/s | 61.3 steps/s
[Step=3900 Epoch= 3.8] | Loss=0.06994 | Reg=0.00327 | acc=0.9531 | L2-Norm=18.096 | L2-Norm(final)=2.752 | 3948.5 samples/s | 61.7 steps/s
[Step=3950 Epoch= 3.9] | Loss=0.06922 | Reg=0.00328 | acc=0.9688 | L2-Norm=18.103 | L2-Norm(final)=2.752 | 3882.1 samples/s | 60.7 steps/s
[Step=4000 Epoch= 3.9] | Loss=0.06877 | Reg=0.00328 | acc=0.9531 | L2-Norm=18.110 | L2-Norm(final)=2.752 | 3955.5 samples/s | 61.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step4000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=2001 Epoch= 3.8] | Loss=0.09986 | Reg=0.00265 | acc=0.9375 | L2-Norm=16.282 | L2-Norm(final)=2.583 | 3270.9 samples/s | 51.1 steps/s
[Step=2050 Epoch= 3.9] | Loss=0.05433 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.503 | L2-Norm(final)=2.608 | 3776.7 samples/s | 59.0 steps/s
[Step=2100 Epoch= 4.0] | Loss=0.04061 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.619 | L2-Norm(final)=2.636 | 4017.2 samples/s | 62.8 steps/s
[Step=2150 Epoch= 4.1] | Loss=0.03487 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.681 | L2-Norm(final)=2.664 | 4143.6 samples/s | 64.7 steps/s
[Step=2200 Epoch= 4.1] | Loss=0.03136 | Reg=0.00280 | acc=0.9531 | L2-Norm=16.726 | L2-Norm(final)=2.690 | 4136.7 samples/s | 64.6 steps/s
[Step=2250 Epoch= 4.2] | Loss=0.03121 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=2.712 | 4081.8 samples/s | 63.8 steps/s
[Step=2300 Epoch= 4.3] | Loss=0.02868 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=2.731 | 4165.6 samples/s | 65.1 steps/s
[Step=2350 Epoch= 4.4] | Loss=0.02708 | Reg=0.00284 | acc=0.9844 | L2-Norm=16.847 | L2-Norm(final)=2.749 | 4208.9 samples/s | 65.8 steps/s
[Step=2400 Epoch= 4.5] | Loss=0.02553 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.873 | L2-Norm(final)=2.766 | 4226.6 samples/s | 66.0 steps/s
[Step=2450 Epoch= 4.6] | Loss=0.02452 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.897 | L2-Norm(final)=2.783 | 3987.9 samples/s | 62.3 steps/s
[Step=2500 Epoch= 4.7] | Loss=0.02344 | Reg=0.00286 | acc=0.9688 | L2-Norm=16.920 | L2-Norm(final)=2.800 | 4258.1 samples/s | 66.5 steps/s
All layers training...
LR=0.00100, len=1
[Step=2501 Epoch= 4.7] | Loss=0.01469 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.141 | L2-Norm(final)=2.969 | 3511.8 samples/s | 54.9 steps/s
[Step=2550 Epoch= 4.8] | Loss=0.03329 | Reg=0.00295 | acc=0.9844 | L2-Norm=17.179 | L2-Norm(final)=2.965 | 3315.9 samples/s | 51.8 steps/s
[Step=2600 Epoch= 4.9] | Loss=0.02812 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.215 | L2-Norm(final)=2.948 | 3745.8 samples/s | 58.5 steps/s
[Step=2650 Epoch= 5.0] | Loss=0.02487 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.220 | L2-Norm(final)=2.936 | 3719.3 samples/s | 58.1 steps/s
[Step=2700 Epoch= 5.1] | Loss=0.02150 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.221 | L2-Norm(final)=2.929 | 3728.6 samples/s | 58.3 steps/s
[Step=2750 Epoch= 5.2] | Loss=0.01834 | Reg=0.00297 | acc=1.0000 | L2-Norm=17.220 | L2-Norm(final)=2.926 | 3726.3 samples/s | 58.2 steps/s
[Step=2800 Epoch= 5.3] | Loss=0.01566 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.215 | L2-Norm(final)=2.925 | 3725.1 samples/s | 58.2 steps/s
[Step=2850 Epoch= 5.4] | Loss=0.01388 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.207 | L2-Norm(final)=2.926 | 3769.9 samples/s | 58.9 steps/s
[Step=2900 Epoch= 5.5] | Loss=0.01276 | Reg=0.00296 | acc=1.0000 | L2-Norm=17.197 | L2-Norm(final)=2.926 | 3761.6 samples/s | 58.8 steps/s
[Step=2950 Epoch= 5.6] | Loss=0.01160 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.187 | L2-Norm(final)=2.927 | 3690.1 samples/s | 57.7 steps/s
[Step=3000 Epoch= 5.7] | Loss=0.01085 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.177 | L2-Norm(final)=2.927 | 3824.0 samples/s | 59.8 steps/s
[Step=3050 Epoch= 5.7] | Loss=0.01011 | Reg=0.00295 | acc=1.0000 | L2-Norm=17.166 | L2-Norm(final)=2.928 | 1676.1 samples/s | 26.2 steps/s
[Step=3100 Epoch= 5.8] | Loss=0.00930 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.153 | L2-Norm(final)=2.929 | 3760.1 samples/s | 58.8 steps/s
[Step=3150 Epoch= 5.9] | Loss=0.00862 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.139 | L2-Norm(final)=2.930 | 3736.3 samples/s | 58.4 steps/s
[Step=3200 Epoch= 6.0] | Loss=0.00801 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.124 | L2-Norm(final)=2.931 | 3674.9 samples/s | 57.4 steps/s
[Step=3250 Epoch= 6.1] | Loss=0.00762 | Reg=0.00293 | acc=1.0000 | L2-Norm=17.108 | L2-Norm(final)=2.932 | 3740.1 samples/s | 58.4 steps/s
[Step=3300 Epoch= 6.2] | Loss=0.00720 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.092 | L2-Norm(final)=2.933 | 3696.9 samples/s | 57.8 steps/s
[Step=3350 Epoch= 6.3] | Loss=0.00682 | Reg=0.00292 | acc=1.0000 | L2-Norm=17.075 | L2-Norm(final)=2.935 | 3744.5 samples/s | 58.5 steps/s
[Step=3400 Epoch= 6.4] | Loss=0.00652 | Reg=0.00291 | acc=1.0000 | L2-Norm=17.057 | L2-Norm(final)=2.936 | 3749.9 samples/s | 58.6 steps/s
[Step=3450 Epoch= 6.5] | Loss=0.00620 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.040 | L2-Norm(final)=2.937 | 3737.8 samples/s | 58.4 steps/s
[Step=3500 Epoch= 6.6] | Loss=0.00590 | Reg=0.00290 | acc=1.0000 | L2-Norm=17.022 | L2-Norm(final)=2.938 | 3739.4 samples/s | 58.4 steps/s
[Step=3550 Epoch= 6.7] | Loss=0.00566 | Reg=0.00289 | acc=1.0000 | L2-Norm=17.003 | L2-Norm(final)=2.939 | 4690.4 samples/s | 73.3 steps/s
[Step=3600 Epoch= 6.8] | Loss=0.00541 | Reg=0.00289 | acc=1.0000 | L2-Norm=16.984 | L2-Norm(final)=2.940 | 1542.3 samples/s | 24.1 steps/s
[Step=3650 Epoch= 6.9] | Loss=0.00518 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.965 | L2-Norm(final)=2.942 | 3678.9 samples/s | 57.5 steps/s
[Step=3700 Epoch= 7.0] | Loss=0.00497 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.945 | L2-Norm(final)=2.943 | 3740.9 samples/s | 58.5 steps/s
[Step=3750 Epoch= 7.1] | Loss=0.00477 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.924 | L2-Norm(final)=2.944 | 3693.3 samples/s | 57.7 steps/s
[Step=3800 Epoch= 7.2] | Loss=0.00460 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.903 | L2-Norm(final)=2.945 | 3754.1 samples/s | 58.7 steps/s
[Step=3850 Epoch= 7.3] | Loss=0.00455 | Reg=0.00285 | acc=0.9844 | L2-Norm=16.883 | L2-Norm(final)=2.946 | 3740.6 samples/s | 58.4 steps/s
[Step=3900 Epoch= 7.4] | Loss=0.00460 | Reg=0.00285 | acc=0.9688 | L2-Norm=16.865 | L2-Norm(final)=2.947 | 3679.1 samples/s | 57.5 steps/s
[Step=3950 Epoch= 7.4] | Loss=0.00506 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.850 | L2-Norm(final)=2.946 | 3729.8 samples/s | 58.3 steps/s
[Step=4000 Epoch= 7.5] | Loss=0.00511 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.838 | L2-Norm(final)=2.945 | 3698.6 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step4000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06040 | acc=0.9569 | tpr=0.9726 | fpr=0.0773 | 3623.2 samples/s | 14.2 steps/s
Avg test loss: 0.06142, Avg test acc: 0.95597, Avg tpr: 0.97045, Avg fpr: 0.07589, total FA: 592

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=3.03888 | acc=0.3137 | tpr=0.0396 | fpr=0.0909 | 3662.6 samples/s | 14.3 steps/s
Avg test loss: 3.04559, Avg test acc: 0.31176, Avg tpr: 0.03882, Avg fpr: 0.08794, total FA: 686

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.50729 | acc=0.1280 | tpr=0.7832 | fpr=0.8837 | 3654.4 samples/s | 14.3 steps/s
[Step= 100] | Loss=2.49649 | acc=0.1316 | tpr=0.7633 | fpr=0.8801 | 6939.1 samples/s | 27.1 steps/s
[Step= 150] | Loss=2.49379 | acc=0.1323 | tpr=0.7738 | fpr=0.8795 | 6800.2 samples/s | 26.6 steps/s
[Step= 200] | Loss=2.48892 | acc=0.1321 | tpr=0.7727 | fpr=0.8795 | 6998.9 samples/s | 27.3 steps/s
[Step= 250] | Loss=2.49028 | acc=0.1324 | tpr=0.7782 | fpr=0.8793 | 6931.5 samples/s | 27.1 steps/s
[Step= 300] | Loss=2.48761 | acc=0.1320 | tpr=0.7804 | fpr=0.8798 | 6890.7 samples/s | 26.9 steps/s
[Step= 350] | Loss=2.48928 | acc=0.1315 | tpr=0.7833 | fpr=0.8803 | 6745.6 samples/s | 26.3 steps/s
[Step= 400] | Loss=2.48904 | acc=0.1317 | tpr=0.7867 | fpr=0.8802 | 6845.0 samples/s | 26.7 steps/s
[Step= 450] | Loss=2.48834 | acc=0.1318 | tpr=0.7907 | fpr=0.8802 | 6996.1 samples/s | 27.3 steps/s
[Step= 500] | Loss=2.48770 | acc=0.1319 | tpr=0.7916 | fpr=0.8800 | 6638.5 samples/s | 25.9 steps/s
[Step= 550] | Loss=2.48926 | acc=0.1317 | tpr=0.7919 | fpr=0.8802 | 12683.5 samples/s | 49.5 steps/s
Avg test loss: 2.48979, Avg test acc: 0.13165, Avg tpr: 0.79239, Avg fpr: 0.88037, total FA: 122237

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13737 | acc=0.9610 | tpr=0.9690 | fpr=0.0391 | 3618.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.14489 | acc=0.9594 | tpr=0.9723 | fpr=0.0408 | 6959.1 samples/s | 27.2 steps/s
[Step= 150] | Loss=0.15131 | acc=0.9580 | tpr=0.9755 | fpr=0.0424 | 6873.7 samples/s | 26.9 steps/s
[Step= 200] | Loss=0.15292 | acc=0.9574 | tpr=0.9792 | fpr=0.0430 | 6961.9 samples/s | 27.2 steps/s
[Step= 250] | Loss=0.15179 | acc=0.9577 | tpr=0.9790 | fpr=0.0427 | 6833.4 samples/s | 26.7 steps/s
[Step= 300] | Loss=0.15366 | acc=0.9572 | tpr=0.9760 | fpr=0.0432 | 6661.9 samples/s | 26.0 steps/s
[Step= 350] | Loss=0.15459 | acc=0.9569 | tpr=0.9762 | fpr=0.0435 | 6860.2 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.15607 | acc=0.9566 | tpr=0.9737 | fpr=0.0437 | 6930.5 samples/s | 27.1 steps/s
[Step= 450] | Loss=0.15805 | acc=0.9562 | tpr=0.9732 | fpr=0.0441 | 6713.0 samples/s | 26.2 steps/s
[Step= 500] | Loss=0.15765 | acc=0.9562 | tpr=0.9736 | fpr=0.0441 | 6857.0 samples/s | 26.8 steps/s
[Step= 550] | Loss=0.15650 | acc=0.9565 | tpr=0.9721 | fpr=0.0437 | 12718.2 samples/s | 49.7 steps/s
Avg test loss: 0.15612, Avg test acc: 0.95661, Avg tpr: 0.97227, Avg fpr: 0.04367, total FA: 6064

server round 2/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 3.9] | Loss=0.18594 | Reg=0.00264 | acc=0.8750 | L2-Norm=16.241 | L2-Norm(final)=2.739 | 3639.8 samples/s | 56.9 steps/s
[Step=4050 Epoch= 4.0] | Loss=0.13558 | Reg=0.00276 | acc=0.9219 | L2-Norm=16.616 | L2-Norm(final)=2.826 | 3913.2 samples/s | 61.1 steps/s
[Step=4100 Epoch= 4.0] | Loss=0.12772 | Reg=0.00284 | acc=0.8906 | L2-Norm=16.861 | L2-Norm(final)=2.870 | 4300.2 samples/s | 67.2 steps/s
[Step=4150 Epoch= 4.1] | Loss=0.12531 | Reg=0.00289 | acc=0.8438 | L2-Norm=17.007 | L2-Norm(final)=2.900 | 4398.4 samples/s | 68.7 steps/s
[Step=4200 Epoch= 4.1] | Loss=0.12329 | Reg=0.00293 | acc=0.8906 | L2-Norm=17.123 | L2-Norm(final)=2.928 | 4378.4 samples/s | 68.4 steps/s
[Step=4250 Epoch= 4.1] | Loss=0.11970 | Reg=0.00297 | acc=0.8906 | L2-Norm=17.226 | L2-Norm(final)=2.955 | 4368.0 samples/s | 68.3 steps/s
[Step=4300 Epoch= 4.2] | Loss=0.11691 | Reg=0.00300 | acc=0.9219 | L2-Norm=17.313 | L2-Norm(final)=2.981 | 4266.2 samples/s | 66.7 steps/s
[Step=4350 Epoch= 4.2] | Loss=0.11453 | Reg=0.00303 | acc=0.9219 | L2-Norm=17.397 | L2-Norm(final)=3.007 | 4364.1 samples/s | 68.2 steps/s
[Step=4400 Epoch= 4.3] | Loss=0.11347 | Reg=0.00306 | acc=0.9219 | L2-Norm=17.474 | L2-Norm(final)=3.033 | 4364.1 samples/s | 68.2 steps/s
[Step=4450 Epoch= 4.3] | Loss=0.11110 | Reg=0.00308 | acc=0.9062 | L2-Norm=17.551 | L2-Norm(final)=3.059 | 4400.4 samples/s | 68.8 steps/s
[Step=4500 Epoch= 4.4] | Loss=0.10953 | Reg=0.00311 | acc=0.8906 | L2-Norm=17.628 | L2-Norm(final)=3.084 | 4328.2 samples/s | 67.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 4.4] | Loss=0.09747 | Reg=0.00338 | acc=0.9062 | L2-Norm=18.378 | L2-Norm(final)=3.338 | 3290.8 samples/s | 51.4 steps/s
[Step=4550 Epoch= 4.4] | Loss=0.10846 | Reg=0.00339 | acc=0.9219 | L2-Norm=18.408 | L2-Norm(final)=3.337 | 3811.9 samples/s | 59.6 steps/s
[Step=4600 Epoch= 4.5] | Loss=0.09995 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.439 | L2-Norm(final)=3.318 | 3900.0 samples/s | 60.9 steps/s
[Step=4650 Epoch= 4.5] | Loss=0.09618 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.468 | L2-Norm(final)=3.307 | 3910.7 samples/s | 61.1 steps/s
[Step=4700 Epoch= 4.6] | Loss=0.09288 | Reg=0.00342 | acc=0.9375 | L2-Norm=18.490 | L2-Norm(final)=3.298 | 3945.0 samples/s | 61.6 steps/s
[Step=4750 Epoch= 4.6] | Loss=0.08706 | Reg=0.00342 | acc=0.9531 | L2-Norm=18.503 | L2-Norm(final)=3.291 | 3897.2 samples/s | 60.9 steps/s
[Step=4800 Epoch= 4.7] | Loss=0.08347 | Reg=0.00343 | acc=0.9531 | L2-Norm=18.513 | L2-Norm(final)=3.286 | 3966.1 samples/s | 62.0 steps/s
[Step=4850 Epoch= 4.7] | Loss=0.08004 | Reg=0.00343 | acc=0.9062 | L2-Norm=18.522 | L2-Norm(final)=3.282 | 3936.5 samples/s | 61.5 steps/s
[Step=4900 Epoch= 4.8] | Loss=0.07848 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.530 | L2-Norm(final)=3.277 | 4026.4 samples/s | 62.9 steps/s
[Step=4950 Epoch= 4.8] | Loss=0.07733 | Reg=0.00344 | acc=0.9375 | L2-Norm=18.538 | L2-Norm(final)=3.274 | 3963.3 samples/s | 61.9 steps/s
[Step=5000 Epoch= 4.9] | Loss=0.07465 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.546 | L2-Norm(final)=3.271 | 3970.4 samples/s | 62.0 steps/s
[Step=5050 Epoch= 4.9] | Loss=0.07339 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.553 | L2-Norm(final)=3.269 | 3957.4 samples/s | 61.8 steps/s
[Step=5100 Epoch= 5.0] | Loss=0.07197 | Reg=0.00345 | acc=0.9531 | L2-Norm=18.561 | L2-Norm(final)=3.266 | 3949.0 samples/s | 61.7 steps/s
[Step=5150 Epoch= 5.0] | Loss=0.07140 | Reg=0.00345 | acc=0.9375 | L2-Norm=18.568 | L2-Norm(final)=3.264 | 3963.5 samples/s | 61.9 steps/s
[Step=5200 Epoch= 5.1] | Loss=0.07022 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.577 | L2-Norm(final)=3.261 | 4019.0 samples/s | 62.8 steps/s
[Step=5250 Epoch= 5.1] | Loss=0.06899 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.585 | L2-Norm(final)=3.258 | 4005.4 samples/s | 62.6 steps/s
[Step=5300 Epoch= 5.2] | Loss=0.06756 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.593 | L2-Norm(final)=3.257 | 3977.2 samples/s | 62.1 steps/s
[Step=5350 Epoch= 5.2] | Loss=0.06694 | Reg=0.00346 | acc=0.9375 | L2-Norm=18.601 | L2-Norm(final)=3.255 | 3944.2 samples/s | 61.6 steps/s
[Step=5400 Epoch= 5.3] | Loss=0.06606 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.609 | L2-Norm(final)=3.253 | 3953.0 samples/s | 61.8 steps/s
[Step=5450 Epoch= 5.3] | Loss=0.06529 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.617 | L2-Norm(final)=3.251 | 3959.6 samples/s | 61.9 steps/s
[Step=5500 Epoch= 5.4] | Loss=0.06461 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.624 | L2-Norm(final)=3.249 | 4262.4 samples/s | 66.6 steps/s
[Step=5550 Epoch= 5.4] | Loss=0.06363 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.632 | L2-Norm(final)=3.247 | 1676.8 samples/s | 26.2 steps/s
[Step=5600 Epoch= 5.5] | Loss=0.06248 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.641 | L2-Norm(final)=3.246 | 3984.4 samples/s | 62.3 steps/s
[Step=5650 Epoch= 5.5] | Loss=0.06173 | Reg=0.00348 | acc=0.9531 | L2-Norm=18.648 | L2-Norm(final)=3.244 | 3951.8 samples/s | 61.7 steps/s
[Step=5700 Epoch= 5.6] | Loss=0.06065 | Reg=0.00348 | acc=0.9375 | L2-Norm=18.655 | L2-Norm(final)=3.243 | 3962.7 samples/s | 61.9 steps/s
[Step=5750 Epoch= 5.6] | Loss=0.05967 | Reg=0.00348 | acc=0.9531 | L2-Norm=18.662 | L2-Norm(final)=3.242 | 3942.3 samples/s | 61.6 steps/s
[Step=5800 Epoch= 5.7] | Loss=0.05905 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.668 | L2-Norm(final)=3.241 | 3967.6 samples/s | 62.0 steps/s
[Step=5850 Epoch= 5.7] | Loss=0.05814 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.675 | L2-Norm(final)=3.240 | 3958.1 samples/s | 61.8 steps/s
[Step=5900 Epoch= 5.8] | Loss=0.05742 | Reg=0.00349 | acc=0.9375 | L2-Norm=18.682 | L2-Norm(final)=3.239 | 3934.5 samples/s | 61.5 steps/s
[Step=5950 Epoch= 5.8] | Loss=0.05691 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.689 | L2-Norm(final)=3.238 | 3940.0 samples/s | 61.6 steps/s
[Step=6000 Epoch= 5.9] | Loss=0.05652 | Reg=0.00350 | acc=0.9531 | L2-Norm=18.695 | L2-Norm(final)=3.237 | 3987.8 samples/s | 62.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step6000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=4001 Epoch= 7.5] | Loss=0.08822 | Reg=0.00264 | acc=0.9062 | L2-Norm=16.241 | L2-Norm(final)=2.896 | 3252.6 samples/s | 50.8 steps/s
[Step=4050 Epoch= 7.6] | Loss=0.01809 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.422 | L2-Norm(final)=2.956 | 3957.5 samples/s | 61.8 steps/s
[Step=4100 Epoch= 7.7] | Loss=0.01458 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.490 | L2-Norm(final)=2.984 | 4122.9 samples/s | 64.4 steps/s
[Step=4150 Epoch= 7.8] | Loss=0.01379 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.524 | L2-Norm(final)=3.004 | 4123.5 samples/s | 64.4 steps/s
[Step=4200 Epoch= 7.9] | Loss=0.01248 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.548 | L2-Norm(final)=3.021 | 4056.7 samples/s | 63.4 steps/s
[Step=4250 Epoch= 8.0] | Loss=0.01198 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.569 | L2-Norm(final)=3.038 | 4148.8 samples/s | 64.8 steps/s
[Step=4300 Epoch= 8.1] | Loss=0.01127 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.587 | L2-Norm(final)=3.054 | 4081.1 samples/s | 63.8 steps/s
[Step=4350 Epoch= 8.2] | Loss=0.01052 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.599 | L2-Norm(final)=3.069 | 4122.1 samples/s | 64.4 steps/s
[Step=4400 Epoch= 8.3] | Loss=0.01007 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.609 | L2-Norm(final)=3.083 | 4150.9 samples/s | 64.9 steps/s
[Step=4450 Epoch= 8.4] | Loss=0.00956 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.617 | L2-Norm(final)=3.096 | 4167.7 samples/s | 65.1 steps/s
[Step=4500 Epoch= 8.5] | Loss=0.00918 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.624 | L2-Norm(final)=3.109 | 4205.5 samples/s | 65.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=4501 Epoch= 8.5] | Loss=0.00636 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.696 | L2-Norm(final)=3.242 | 3300.4 samples/s | 51.6 steps/s
[Step=4550 Epoch= 8.6] | Loss=0.01548 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.724 | L2-Norm(final)=3.229 | 3452.4 samples/s | 53.9 steps/s
[Step=4600 Epoch= 8.7] | Loss=0.02350 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.778 | L2-Norm(final)=3.187 | 3722.5 samples/s | 58.2 steps/s
[Step=4650 Epoch= 8.8] | Loss=0.01711 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.815 | L2-Norm(final)=3.175 | 3696.6 samples/s | 57.8 steps/s
[Step=4700 Epoch= 8.9] | Loss=0.01426 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.828 | L2-Norm(final)=3.173 | 3731.8 samples/s | 58.3 steps/s
[Step=4750 Epoch= 9.0] | Loss=0.01190 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.831 | L2-Norm(final)=3.174 | 3693.0 samples/s | 57.7 steps/s
[Step=4800 Epoch= 9.0] | Loss=0.01052 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.827 | L2-Norm(final)=3.177 | 3753.9 samples/s | 58.7 steps/s
[Step=4850 Epoch= 9.1] | Loss=0.00992 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.821 | L2-Norm(final)=3.178 | 3770.3 samples/s | 58.9 steps/s
[Step=4900 Epoch= 9.2] | Loss=0.00912 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.813 | L2-Norm(final)=3.179 | 3746.2 samples/s | 58.5 steps/s
[Step=4950 Epoch= 9.3] | Loss=0.00822 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=3.181 | 3699.4 samples/s | 57.8 steps/s
[Step=5000 Epoch= 9.4] | Loss=0.00752 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.795 | L2-Norm(final)=3.183 | 3794.9 samples/s | 59.3 steps/s
[Step=5050 Epoch= 9.5] | Loss=0.00714 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.783 | L2-Norm(final)=3.185 | 1664.0 samples/s | 26.0 steps/s
[Step=5100 Epoch= 9.6] | Loss=0.00660 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.769 | L2-Norm(final)=3.187 | 3720.4 samples/s | 58.1 steps/s
[Step=5150 Epoch= 9.7] | Loss=0.00611 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.754 | L2-Norm(final)=3.190 | 3751.8 samples/s | 58.6 steps/s
[Step=5200 Epoch= 9.8] | Loss=0.00570 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.738 | L2-Norm(final)=3.192 | 3703.0 samples/s | 57.9 steps/s
[Step=5250 Epoch= 9.9] | Loss=0.00532 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.720 | L2-Norm(final)=3.194 | 3720.3 samples/s | 58.1 steps/s
[Step=5300 Epoch=10.0] | Loss=0.00499 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.700 | L2-Norm(final)=3.197 | 3666.5 samples/s | 57.3 steps/s
[Step=5350 Epoch=10.1] | Loss=0.00471 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.680 | L2-Norm(final)=3.199 | 3719.9 samples/s | 58.1 steps/s
[Step=5400 Epoch=10.2] | Loss=0.00445 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.659 | L2-Norm(final)=3.201 | 3670.6 samples/s | 57.4 steps/s
[Step=5450 Epoch=10.3] | Loss=0.00422 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.637 | L2-Norm(final)=3.203 | 3744.3 samples/s | 58.5 steps/s
[Step=5500 Epoch=10.4] | Loss=0.00402 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.615 | L2-Norm(final)=3.205 | 3704.9 samples/s | 57.9 steps/s
[Step=5550 Epoch=10.5] | Loss=0.00384 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.592 | L2-Norm(final)=3.207 | 4655.3 samples/s | 72.7 steps/s
[Step=5600 Epoch=10.6] | Loss=0.00366 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.569 | L2-Norm(final)=3.209 | 1523.4 samples/s | 23.8 steps/s
[Step=5650 Epoch=10.7] | Loss=0.00351 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.545 | L2-Norm(final)=3.211 | 3711.9 samples/s | 58.0 steps/s
[Step=5700 Epoch=10.7] | Loss=0.00336 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.521 | L2-Norm(final)=3.213 | 3792.3 samples/s | 59.3 steps/s
[Step=5750 Epoch=10.8] | Loss=0.00323 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.496 | L2-Norm(final)=3.214 | 3677.2 samples/s | 57.5 steps/s
[Step=5800 Epoch=10.9] | Loss=0.00310 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.471 | L2-Norm(final)=3.216 | 3692.6 samples/s | 57.7 steps/s
[Step=5850 Epoch=11.0] | Loss=0.00299 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.446 | L2-Norm(final)=3.218 | 3745.5 samples/s | 58.5 steps/s
[Step=5900 Epoch=11.1] | Loss=0.00288 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.420 | L2-Norm(final)=3.219 | 3738.2 samples/s | 58.4 steps/s
[Step=5950 Epoch=11.2] | Loss=0.00278 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.393 | L2-Norm(final)=3.220 | 3663.6 samples/s | 57.2 steps/s
[Step=6000 Epoch=11.3] | Loss=0.00269 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.367 | L2-Norm(final)=3.222 | 3745.2 samples/s | 58.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step6000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06039 | acc=0.9573 | tpr=0.9550 | fpr=0.0379 | 3606.7 samples/s | 14.1 steps/s
Avg test loss: 0.06140, Avg test acc: 0.95557, Avg tpr: 0.95273, Avg fpr: 0.03820, total FA: 298

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.25060 | acc=0.3098 | tpr=0.0081 | fpr=0.0352 | 3616.2 samples/s | 14.1 steps/s
Avg test loss: 5.27320, Avg test acc: 0.30784, Avg tpr: 0.00799, Avg fpr: 0.03269, total FA: 255

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.04692 | acc=0.1371 | tpr=0.7522 | fpr=0.8739 | 3574.2 samples/s | 14.0 steps/s
[Step= 100] | Loss=3.02920 | acc=0.1381 | tpr=0.6994 | fpr=0.8724 | 7020.1 samples/s | 27.4 steps/s
[Step= 150] | Loss=3.02400 | acc=0.1382 | tpr=0.6974 | fpr=0.8721 | 6819.2 samples/s | 26.6 steps/s
[Step= 200] | Loss=3.02153 | acc=0.1381 | tpr=0.6962 | fpr=0.8721 | 6755.0 samples/s | 26.4 steps/s
[Step= 250] | Loss=3.02406 | acc=0.1389 | tpr=0.7083 | fpr=0.8715 | 6840.5 samples/s | 26.7 steps/s
[Step= 300] | Loss=3.02378 | acc=0.1387 | tpr=0.7098 | fpr=0.8717 | 6886.6 samples/s | 26.9 steps/s
[Step= 350] | Loss=3.02539 | acc=0.1380 | tpr=0.7107 | fpr=0.8724 | 6706.8 samples/s | 26.2 steps/s
[Step= 400] | Loss=3.02659 | acc=0.1383 | tpr=0.7144 | fpr=0.8722 | 6898.7 samples/s | 26.9 steps/s
[Step= 450] | Loss=3.02749 | acc=0.1384 | tpr=0.7167 | fpr=0.8721 | 6721.0 samples/s | 26.3 steps/s
[Step= 500] | Loss=3.02748 | acc=0.1382 | tpr=0.7128 | fpr=0.8722 | 6669.6 samples/s | 26.1 steps/s
[Step= 550] | Loss=3.02987 | acc=0.1382 | tpr=0.7151 | fpr=0.8723 | 12446.9 samples/s | 48.6 steps/s
Avg test loss: 3.03058, Avg test acc: 0.13815, Avg tpr: 0.71593, Avg fpr: 0.87235, total FA: 121124

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09512 | acc=0.9838 | tpr=0.9425 | fpr=0.0155 | 3609.2 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.09966 | acc=0.9832 | tpr=0.9574 | fpr=0.0163 | 6754.5 samples/s | 26.4 steps/s
[Step= 150] | Loss=0.10335 | acc=0.9826 | tpr=0.9611 | fpr=0.0170 | 6928.9 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.10478 | acc=0.9826 | tpr=0.9617 | fpr=0.0171 | 6882.5 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.10300 | acc=0.9828 | tpr=0.9581 | fpr=0.0168 | 6860.8 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.10456 | acc=0.9825 | tpr=0.9498 | fpr=0.0169 | 7015.2 samples/s | 27.4 steps/s
[Step= 350] | Loss=0.10536 | acc=0.9824 | tpr=0.9512 | fpr=0.0170 | 6734.5 samples/s | 26.3 steps/s
[Step= 400] | Loss=0.10639 | acc=0.9822 | tpr=0.9497 | fpr=0.0173 | 6984.9 samples/s | 27.3 steps/s
[Step= 450] | Loss=0.10837 | acc=0.9818 | tpr=0.9489 | fpr=0.0176 | 6663.6 samples/s | 26.0 steps/s
[Step= 500] | Loss=0.10761 | acc=0.9820 | tpr=0.9502 | fpr=0.0174 | 7020.3 samples/s | 27.4 steps/s
[Step= 550] | Loss=0.10709 | acc=0.9821 | tpr=0.9495 | fpr=0.0173 | 12118.5 samples/s | 47.3 steps/s
Avg test loss: 0.10684, Avg test acc: 0.98211, Avg tpr: 0.94968, Avg fpr: 0.01730, total FA: 2402

server round 3/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch= 5.9] | Loss=0.15239 | Reg=0.00264 | acc=0.8438 | L2-Norm=16.233 | L2-Norm(final)=3.193 | 3172.1 samples/s | 49.6 steps/s
[Step=6050 Epoch= 5.9] | Loss=0.10051 | Reg=0.00270 | acc=0.9531 | L2-Norm=16.426 | L2-Norm(final)=3.232 | 4344.4 samples/s | 67.9 steps/s
[Step=6100 Epoch= 6.0] | Loss=0.09098 | Reg=0.00275 | acc=0.9219 | L2-Norm=16.577 | L2-Norm(final)=3.277 | 4415.6 samples/s | 69.0 steps/s
[Step=6150 Epoch= 6.0] | Loss=0.08781 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.693 | L2-Norm(final)=3.314 | 4355.6 samples/s | 68.1 steps/s
[Step=6200 Epoch= 6.1] | Loss=0.08578 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.798 | L2-Norm(final)=3.348 | 4359.2 samples/s | 68.1 steps/s
[Step=6250 Epoch= 6.1] | Loss=0.08431 | Reg=0.00286 | acc=0.9844 | L2-Norm=16.895 | L2-Norm(final)=3.377 | 4320.9 samples/s | 67.5 steps/s
[Step=6300 Epoch= 6.2] | Loss=0.08133 | Reg=0.00289 | acc=0.9375 | L2-Norm=16.988 | L2-Norm(final)=3.407 | 4388.6 samples/s | 68.6 steps/s
[Step=6350 Epoch= 6.2] | Loss=0.08009 | Reg=0.00292 | acc=0.9531 | L2-Norm=17.074 | L2-Norm(final)=3.437 | 4384.1 samples/s | 68.5 steps/s
[Step=6400 Epoch= 6.2] | Loss=0.07938 | Reg=0.00295 | acc=0.9375 | L2-Norm=17.158 | L2-Norm(final)=3.467 | 4377.5 samples/s | 68.4 steps/s
[Step=6450 Epoch= 6.3] | Loss=0.07858 | Reg=0.00297 | acc=0.9531 | L2-Norm=17.237 | L2-Norm(final)=3.493 | 4412.0 samples/s | 68.9 steps/s
[Step=6500 Epoch= 6.3] | Loss=0.07771 | Reg=0.00300 | acc=0.9844 | L2-Norm=17.308 | L2-Norm(final)=3.517 | 4392.9 samples/s | 68.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch= 6.3] | Loss=0.06935 | Reg=0.00323 | acc=0.9531 | L2-Norm=17.981 | L2-Norm(final)=3.748 | 3298.0 samples/s | 51.5 steps/s
[Step=6550 Epoch= 6.4] | Loss=0.08069 | Reg=0.00325 | acc=0.9531 | L2-Norm=18.038 | L2-Norm(final)=3.753 | 3736.5 samples/s | 58.4 steps/s
[Step=6600 Epoch= 6.4] | Loss=0.07452 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.097 | L2-Norm(final)=3.740 | 3900.8 samples/s | 60.9 steps/s
[Step=6650 Epoch= 6.5] | Loss=0.07106 | Reg=0.00329 | acc=0.9531 | L2-Norm=18.145 | L2-Norm(final)=3.733 | 3921.3 samples/s | 61.3 steps/s
[Step=6700 Epoch= 6.5] | Loss=0.07087 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.183 | L2-Norm(final)=3.724 | 3938.6 samples/s | 61.5 steps/s
[Step=6750 Epoch= 6.6] | Loss=0.06855 | Reg=0.00332 | acc=0.9219 | L2-Norm=18.213 | L2-Norm(final)=3.716 | 3951.8 samples/s | 61.7 steps/s
[Step=6800 Epoch= 6.6] | Loss=0.06594 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.238 | L2-Norm(final)=3.711 | 3940.0 samples/s | 61.6 steps/s
[Step=6850 Epoch= 6.7] | Loss=0.06476 | Reg=0.00333 | acc=0.9531 | L2-Norm=18.258 | L2-Norm(final)=3.706 | 3901.1 samples/s | 61.0 steps/s
[Step=6900 Epoch= 6.7] | Loss=0.06426 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.278 | L2-Norm(final)=3.701 | 3951.0 samples/s | 61.7 steps/s
[Step=6950 Epoch= 6.8] | Loss=0.06347 | Reg=0.00335 | acc=0.8750 | L2-Norm=18.297 | L2-Norm(final)=3.697 | 3914.8 samples/s | 61.2 steps/s
[Step=7000 Epoch= 6.8] | Loss=0.06281 | Reg=0.00335 | acc=0.9844 | L2-Norm=18.313 | L2-Norm(final)=3.692 | 3964.2 samples/s | 61.9 steps/s
[Step=7050 Epoch= 6.9] | Loss=0.06150 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.328 | L2-Norm(final)=3.688 | 3917.6 samples/s | 61.2 steps/s
[Step=7100 Epoch= 6.9] | Loss=0.06028 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.342 | L2-Norm(final)=3.685 | 3948.9 samples/s | 61.7 steps/s
[Step=7150 Epoch= 7.0] | Loss=0.05950 | Reg=0.00337 | acc=0.9844 | L2-Norm=18.355 | L2-Norm(final)=3.680 | 3954.7 samples/s | 61.8 steps/s
[Step=7200 Epoch= 7.0] | Loss=0.05852 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.366 | L2-Norm(final)=3.676 | 3956.7 samples/s | 61.8 steps/s
[Step=7250 Epoch= 7.1] | Loss=0.05784 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.377 | L2-Norm(final)=3.672 | 3951.9 samples/s | 61.7 steps/s
[Step=7300 Epoch= 7.1] | Loss=0.05688 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.387 | L2-Norm(final)=3.668 | 3932.5 samples/s | 61.4 steps/s
[Step=7350 Epoch= 7.2] | Loss=0.05588 | Reg=0.00338 | acc=1.0000 | L2-Norm=18.397 | L2-Norm(final)=3.665 | 3938.4 samples/s | 61.5 steps/s
[Step=7400 Epoch= 7.2] | Loss=0.05516 | Reg=0.00339 | acc=0.9219 | L2-Norm=18.407 | L2-Norm(final)=3.663 | 3944.7 samples/s | 61.6 steps/s
[Step=7450 Epoch= 7.3] | Loss=0.05492 | Reg=0.00339 | acc=0.9688 | L2-Norm=18.418 | L2-Norm(final)=3.659 | 3939.1 samples/s | 61.5 steps/s
[Step=7500 Epoch= 7.3] | Loss=0.05432 | Reg=0.00340 | acc=1.0000 | L2-Norm=18.428 | L2-Norm(final)=3.656 | 4229.1 samples/s | 66.1 steps/s
[Step=7550 Epoch= 7.4] | Loss=0.05350 | Reg=0.00340 | acc=0.9688 | L2-Norm=18.438 | L2-Norm(final)=3.653 | 1663.3 samples/s | 26.0 steps/s
[Step=7600 Epoch= 7.4] | Loss=0.05275 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.448 | L2-Norm(final)=3.650 | 3919.9 samples/s | 61.2 steps/s
[Step=7650 Epoch= 7.5] | Loss=0.05226 | Reg=0.00341 | acc=0.9531 | L2-Norm=18.458 | L2-Norm(final)=3.648 | 3909.3 samples/s | 61.1 steps/s
[Step=7700 Epoch= 7.5] | Loss=0.05154 | Reg=0.00341 | acc=0.9375 | L2-Norm=18.469 | L2-Norm(final)=3.646 | 3910.2 samples/s | 61.1 steps/s
[Step=7750 Epoch= 7.6] | Loss=0.05058 | Reg=0.00341 | acc=1.0000 | L2-Norm=18.479 | L2-Norm(final)=3.646 | 3987.5 samples/s | 62.3 steps/s
[Step=7800 Epoch= 7.6] | Loss=0.05035 | Reg=0.00342 | acc=0.9375 | L2-Norm=18.489 | L2-Norm(final)=3.645 | 3924.9 samples/s | 61.3 steps/s
[Step=7850 Epoch= 7.7] | Loss=0.04995 | Reg=0.00342 | acc=0.9688 | L2-Norm=18.499 | L2-Norm(final)=3.643 | 3934.9 samples/s | 61.5 steps/s
[Step=7900 Epoch= 7.7] | Loss=0.04940 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.509 | L2-Norm(final)=3.642 | 3930.1 samples/s | 61.4 steps/s
[Step=7950 Epoch= 7.8] | Loss=0.04898 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.519 | L2-Norm(final)=3.641 | 3941.1 samples/s | 61.6 steps/s
[Step=8000 Epoch= 7.8] | Loss=0.04873 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.529 | L2-Norm(final)=3.640 | 3986.4 samples/s | 62.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step8000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=6001 Epoch=11.3] | Loss=0.10362 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.233 | L2-Norm(final)=3.259 | 3256.5 samples/s | 50.9 steps/s
[Step=6050 Epoch=11.4] | Loss=0.01363 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.395 | L2-Norm(final)=3.274 | 3794.8 samples/s | 59.3 steps/s
[Step=6100 Epoch=11.5] | Loss=0.00944 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.479 | L2-Norm(final)=3.298 | 4057.3 samples/s | 63.4 steps/s
[Step=6150 Epoch=11.6] | Loss=0.00767 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.518 | L2-Norm(final)=3.320 | 4092.3 samples/s | 63.9 steps/s
[Step=6200 Epoch=11.7] | Loss=0.00742 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=3.336 | 4075.5 samples/s | 63.7 steps/s
[Step=6250 Epoch=11.8] | Loss=0.00664 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.553 | L2-Norm(final)=3.352 | 4128.9 samples/s | 64.5 steps/s
[Step=6300 Epoch=11.9] | Loss=0.00603 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.564 | L2-Norm(final)=3.368 | 4182.4 samples/s | 65.3 steps/s
[Step=6350 Epoch=12.0] | Loss=0.00576 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.570 | L2-Norm(final)=3.384 | 4050.3 samples/s | 63.3 steps/s
[Step=6400 Epoch=12.1] | Loss=0.00539 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=3.401 | 4180.8 samples/s | 65.3 steps/s
[Step=6450 Epoch=12.2] | Loss=0.00503 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.577 | L2-Norm(final)=3.416 | 4155.1 samples/s | 64.9 steps/s
[Step=6500 Epoch=12.3] | Loss=0.00496 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.576 | L2-Norm(final)=3.430 | 4076.2 samples/s | 63.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=6501 Epoch=12.3] | Loss=0.00192 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.575 | L2-Norm(final)=3.564 | 3408.9 samples/s | 53.3 steps/s
[Step=6550 Epoch=12.3] | Loss=0.02089 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.659 | L2-Norm(final)=3.555 | 3394.7 samples/s | 53.0 steps/s
[Step=6600 Epoch=12.4] | Loss=0.01661 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.816 | L2-Norm(final)=3.503 | 3749.2 samples/s | 58.6 steps/s
[Step=6650 Epoch=12.5] | Loss=0.01501 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.900 | L2-Norm(final)=3.476 | 3654.3 samples/s | 57.1 steps/s
[Step=6700 Epoch=12.6] | Loss=0.01288 | Reg=0.00287 | acc=0.9844 | L2-Norm=16.940 | L2-Norm(final)=3.462 | 3767.4 samples/s | 58.9 steps/s
[Step=6750 Epoch=12.7] | Loss=0.01108 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.960 | L2-Norm(final)=3.455 | 3685.7 samples/s | 57.6 steps/s
[Step=6800 Epoch=12.8] | Loss=0.00981 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=3.452 | 3689.3 samples/s | 57.6 steps/s
[Step=6850 Epoch=12.9] | Loss=0.00891 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.969 | L2-Norm(final)=3.450 | 3736.6 samples/s | 58.4 steps/s
[Step=6900 Epoch=13.0] | Loss=0.00903 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.970 | L2-Norm(final)=3.446 | 3694.5 samples/s | 57.7 steps/s
[Step=6950 Epoch=13.1] | Loss=0.00826 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.968 | L2-Norm(final)=3.441 | 3683.8 samples/s | 57.6 steps/s
[Step=7000 Epoch=13.2] | Loss=0.00797 | Reg=0.00288 | acc=0.9688 | L2-Norm=16.962 | L2-Norm(final)=3.437 | 3728.1 samples/s | 58.3 steps/s
[Step=7050 Epoch=13.3] | Loss=0.00749 | Reg=0.00288 | acc=1.0000 | L2-Norm=16.958 | L2-Norm(final)=3.433 | 1606.7 samples/s | 25.1 steps/s
[Step=7100 Epoch=13.4] | Loss=0.00692 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.951 | L2-Norm(final)=3.431 | 3781.0 samples/s | 59.1 steps/s
[Step=7150 Epoch=13.5] | Loss=0.00643 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.940 | L2-Norm(final)=3.429 | 3638.6 samples/s | 56.9 steps/s
[Step=7200 Epoch=13.6] | Loss=0.00598 | Reg=0.00287 | acc=1.0000 | L2-Norm=16.927 | L2-Norm(final)=3.428 | 3692.9 samples/s | 57.7 steps/s
[Step=7250 Epoch=13.7] | Loss=0.00559 | Reg=0.00286 | acc=1.0000 | L2-Norm=16.911 | L2-Norm(final)=3.428 | 3681.7 samples/s | 57.5 steps/s
[Step=7300 Epoch=13.8] | Loss=0.00525 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.892 | L2-Norm(final)=3.428 | 3730.1 samples/s | 58.3 steps/s
[Step=7350 Epoch=13.9] | Loss=0.00496 | Reg=0.00285 | acc=1.0000 | L2-Norm=16.872 | L2-Norm(final)=3.428 | 3687.1 samples/s | 57.6 steps/s
[Step=7400 Epoch=13.9] | Loss=0.00469 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.851 | L2-Norm(final)=3.429 | 3666.5 samples/s | 57.3 steps/s
[Step=7450 Epoch=14.0] | Loss=0.00445 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.829 | L2-Norm(final)=3.430 | 3698.4 samples/s | 57.8 steps/s
[Step=7500 Epoch=14.1] | Loss=0.00423 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.805 | L2-Norm(final)=3.431 | 3763.8 samples/s | 58.8 steps/s
[Step=7550 Epoch=14.2] | Loss=0.00407 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.781 | L2-Norm(final)=3.432 | 4616.9 samples/s | 72.1 steps/s
[Step=7600 Epoch=14.3] | Loss=0.00392 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.757 | L2-Norm(final)=3.432 | 1496.9 samples/s | 23.4 steps/s
[Step=7650 Epoch=14.4] | Loss=0.00379 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.734 | L2-Norm(final)=3.433 | 3664.8 samples/s | 57.3 steps/s
[Step=7700 Epoch=14.5] | Loss=0.00371 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.710 | L2-Norm(final)=3.434 | 3715.8 samples/s | 58.1 steps/s
[Step=7750 Epoch=14.6] | Loss=0.00373 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.687 | L2-Norm(final)=3.434 | 3701.8 samples/s | 57.8 steps/s
[Step=7800 Epoch=14.7] | Loss=0.00361 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.664 | L2-Norm(final)=3.434 | 3738.4 samples/s | 58.4 steps/s
[Step=7850 Epoch=14.8] | Loss=0.00352 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.642 | L2-Norm(final)=3.434 | 3741.9 samples/s | 58.5 steps/s
[Step=7900 Epoch=14.9] | Loss=0.00347 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.621 | L2-Norm(final)=3.434 | 3724.5 samples/s | 58.2 steps/s
[Step=7950 Epoch=15.0] | Loss=0.00339 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.599 | L2-Norm(final)=3.435 | 3680.4 samples/s | 57.5 steps/s
[Step=8000 Epoch=15.1] | Loss=0.00328 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=3.435 | 3714.2 samples/s | 58.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step8000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05746 | acc=0.9573 | tpr=0.9580 | fpr=0.0441 | 3693.9 samples/s | 14.4 steps/s
Avg test loss: 0.05947, Avg test acc: 0.95492, Avg tpr: 0.95500, Avg fpr: 0.04525, total FA: 353

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.61992 | acc=0.3094 | tpr=0.0240 | fpr=0.0709 | 3608.6 samples/s | 14.1 steps/s
Avg test loss: 4.63132, Avg test acc: 0.30896, Avg tpr: 0.02530, Avg fpr: 0.06717, total FA: 524

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=2.53687 | acc=0.1847 | tpr=0.7168 | fpr=0.8249 | 3608.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=2.52436 | acc=0.1873 | tpr=0.6844 | fpr=0.8219 | 7124.7 samples/s | 27.8 steps/s
[Step= 150] | Loss=2.52356 | acc=0.1860 | tpr=0.6873 | fpr=0.8233 | 6621.7 samples/s | 25.9 steps/s
[Step= 200] | Loss=2.51801 | acc=0.1870 | tpr=0.6820 | fpr=0.8221 | 6954.5 samples/s | 27.2 steps/s
[Step= 250] | Loss=2.52010 | acc=0.1871 | tpr=0.6847 | fpr=0.8220 | 6769.8 samples/s | 26.4 steps/s
[Step= 300] | Loss=2.51913 | acc=0.1861 | tpr=0.6844 | fpr=0.8230 | 6950.4 samples/s | 27.1 steps/s
[Step= 350] | Loss=2.51865 | acc=0.1852 | tpr=0.6838 | fpr=0.8239 | 7088.6 samples/s | 27.7 steps/s
[Step= 400] | Loss=2.51799 | acc=0.1853 | tpr=0.6849 | fpr=0.8238 | 6645.3 samples/s | 26.0 steps/s
[Step= 450] | Loss=2.51811 | acc=0.1853 | tpr=0.6908 | fpr=0.8238 | 6805.3 samples/s | 26.6 steps/s
[Step= 500] | Loss=2.51887 | acc=0.1852 | tpr=0.6837 | fpr=0.8238 | 6685.5 samples/s | 26.1 steps/s
[Step= 550] | Loss=2.51953 | acc=0.1850 | tpr=0.6888 | fpr=0.8242 | 12583.9 samples/s | 49.2 steps/s
Avg test loss: 2.52021, Avg test acc: 0.18492, Avg tpr: 0.68938, Avg fpr: 0.82425, total FA: 114446

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11280 | acc=0.9801 | tpr=0.9646 | fpr=0.0196 | 3653.8 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.12133 | acc=0.9786 | tpr=0.9723 | fpr=0.0213 | 6813.2 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12527 | acc=0.9773 | tpr=0.9726 | fpr=0.0226 | 6789.4 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.12758 | acc=0.9772 | tpr=0.9749 | fpr=0.0227 | 7142.2 samples/s | 27.9 steps/s
[Step= 250] | Loss=0.12590 | acc=0.9774 | tpr=0.9721 | fpr=0.0225 | 6749.9 samples/s | 26.4 steps/s
[Step= 300] | Loss=0.12823 | acc=0.9770 | tpr=0.9709 | fpr=0.0229 | 6892.3 samples/s | 26.9 steps/s
[Step= 350] | Loss=0.12933 | acc=0.9767 | tpr=0.9712 | fpr=0.0232 | 6871.3 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.12987 | acc=0.9765 | tpr=0.9705 | fpr=0.0234 | 6848.2 samples/s | 26.8 steps/s
[Step= 450] | Loss=0.13262 | acc=0.9762 | tpr=0.9693 | fpr=0.0237 | 6674.4 samples/s | 26.1 steps/s
[Step= 500] | Loss=0.13185 | acc=0.9763 | tpr=0.9692 | fpr=0.0236 | 6794.1 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.13081 | acc=0.9765 | tpr=0.9682 | fpr=0.0234 | 12552.5 samples/s | 49.0 steps/s
Avg test loss: 0.13056, Avg test acc: 0.97651, Avg tpr: 0.96830, Avg fpr: 0.02334, total FA: 3241

server round 4/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch= 7.8] | Loss=0.14267 | Reg=0.00267 | acc=0.8906 | L2-Norm=16.334 | L2-Norm(final)=3.591 | 3504.2 samples/s | 54.8 steps/s
[Step=8050 Epoch= 7.9] | Loss=0.10005 | Reg=0.00271 | acc=0.8906 | L2-Norm=16.475 | L2-Norm(final)=3.645 | 3958.4 samples/s | 61.8 steps/s
[Step=8100 Epoch= 7.9] | Loss=0.09427 | Reg=0.00276 | acc=0.9062 | L2-Norm=16.616 | L2-Norm(final)=3.689 | 4287.3 samples/s | 67.0 steps/s
[Step=8150 Epoch= 8.0] | Loss=0.09213 | Reg=0.00280 | acc=0.9062 | L2-Norm=16.723 | L2-Norm(final)=3.721 | 4397.2 samples/s | 68.7 steps/s
[Step=8200 Epoch= 8.0] | Loss=0.09014 | Reg=0.00283 | acc=0.8906 | L2-Norm=16.816 | L2-Norm(final)=3.752 | 4347.6 samples/s | 67.9 steps/s
[Step=8250 Epoch= 8.1] | Loss=0.08864 | Reg=0.00286 | acc=0.9062 | L2-Norm=16.898 | L2-Norm(final)=3.777 | 4404.9 samples/s | 68.8 steps/s
[Step=8300 Epoch= 8.1] | Loss=0.08780 | Reg=0.00288 | acc=0.9219 | L2-Norm=16.975 | L2-Norm(final)=3.803 | 4372.4 samples/s | 68.3 steps/s
[Step=8350 Epoch= 8.2] | Loss=0.08651 | Reg=0.00291 | acc=0.9219 | L2-Norm=17.049 | L2-Norm(final)=3.829 | 4469.4 samples/s | 69.8 steps/s
[Step=8400 Epoch= 8.2] | Loss=0.08586 | Reg=0.00293 | acc=0.9375 | L2-Norm=17.122 | L2-Norm(final)=3.857 | 4271.0 samples/s | 66.7 steps/s
[Step=8450 Epoch= 8.3] | Loss=0.08452 | Reg=0.00296 | acc=0.9844 | L2-Norm=17.194 | L2-Norm(final)=3.885 | 4337.2 samples/s | 67.8 steps/s
[Step=8500 Epoch= 8.3] | Loss=0.08417 | Reg=0.00298 | acc=0.9688 | L2-Norm=17.264 | L2-Norm(final)=3.912 | 4419.0 samples/s | 69.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch= 8.3] | Loss=0.07490 | Reg=0.00322 | acc=0.9375 | L2-Norm=17.957 | L2-Norm(final)=4.178 | 3284.5 samples/s | 51.3 steps/s
[Step=8550 Epoch= 8.3] | Loss=0.07731 | Reg=0.00325 | acc=0.9531 | L2-Norm=18.035 | L2-Norm(final)=4.189 | 3910.6 samples/s | 61.1 steps/s
[Step=8600 Epoch= 8.4] | Loss=0.07259 | Reg=0.00328 | acc=0.9531 | L2-Norm=18.113 | L2-Norm(final)=4.170 | 3945.7 samples/s | 61.7 steps/s
[Step=8650 Epoch= 8.4] | Loss=0.06772 | Reg=0.00330 | acc=0.9844 | L2-Norm=18.166 | L2-Norm(final)=4.162 | 3945.9 samples/s | 61.7 steps/s
[Step=8700 Epoch= 8.5] | Loss=0.06560 | Reg=0.00331 | acc=0.9219 | L2-Norm=18.205 | L2-Norm(final)=4.153 | 3954.5 samples/s | 61.8 steps/s
[Step=8750 Epoch= 8.5] | Loss=0.06508 | Reg=0.00333 | acc=0.8438 | L2-Norm=18.239 | L2-Norm(final)=4.146 | 3950.2 samples/s | 61.7 steps/s
[Step=8800 Epoch= 8.6] | Loss=0.06317 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.271 | L2-Norm(final)=4.137 | 3875.4 samples/s | 60.6 steps/s
[Step=8850 Epoch= 8.6] | Loss=0.06179 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.300 | L2-Norm(final)=4.130 | 3919.0 samples/s | 61.2 steps/s
[Step=8900 Epoch= 8.7] | Loss=0.06047 | Reg=0.00336 | acc=0.8906 | L2-Norm=18.323 | L2-Norm(final)=4.123 | 4026.8 samples/s | 62.9 steps/s
[Step=8950 Epoch= 8.7] | Loss=0.05874 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.343 | L2-Norm(final)=4.117 | 3887.1 samples/s | 60.7 steps/s
[Step=9000 Epoch= 8.8] | Loss=0.05789 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.362 | L2-Norm(final)=4.112 | 3911.2 samples/s | 61.1 steps/s
[Step=9050 Epoch= 8.8] | Loss=0.05645 | Reg=0.00338 | acc=0.9688 | L2-Norm=18.379 | L2-Norm(final)=4.108 | 3881.2 samples/s | 60.6 steps/s
[Step=9100 Epoch= 8.9] | Loss=0.05543 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.395 | L2-Norm(final)=4.104 | 3936.5 samples/s | 61.5 steps/s
[Step=9150 Epoch= 8.9] | Loss=0.05444 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.411 | L2-Norm(final)=4.100 | 3921.1 samples/s | 61.3 steps/s
[Step=9200 Epoch= 9.0] | Loss=0.05377 | Reg=0.00340 | acc=0.9375 | L2-Norm=18.426 | L2-Norm(final)=4.095 | 3935.6 samples/s | 61.5 steps/s
[Step=9250 Epoch= 9.0] | Loss=0.05330 | Reg=0.00340 | acc=0.9531 | L2-Norm=18.440 | L2-Norm(final)=4.089 | 3875.1 samples/s | 60.5 steps/s
[Step=9300 Epoch= 9.1] | Loss=0.05260 | Reg=0.00341 | acc=0.9688 | L2-Norm=18.453 | L2-Norm(final)=4.084 | 3913.3 samples/s | 61.1 steps/s
[Step=9350 Epoch= 9.1] | Loss=0.05212 | Reg=0.00341 | acc=0.9531 | L2-Norm=18.465 | L2-Norm(final)=4.079 | 3988.5 samples/s | 62.3 steps/s
[Step=9400 Epoch= 9.2] | Loss=0.05126 | Reg=0.00341 | acc=0.9375 | L2-Norm=18.477 | L2-Norm(final)=4.075 | 3895.6 samples/s | 60.9 steps/s
[Step=9450 Epoch= 9.2] | Loss=0.05066 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.490 | L2-Norm(final)=4.071 | 3908.6 samples/s | 61.1 steps/s
[Step=9500 Epoch= 9.3] | Loss=0.05032 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.502 | L2-Norm(final)=4.067 | 4164.6 samples/s | 65.1 steps/s
[Step=9550 Epoch= 9.3] | Loss=0.04984 | Reg=0.00343 | acc=0.9219 | L2-Norm=18.513 | L2-Norm(final)=4.063 | 1679.9 samples/s | 26.2 steps/s
[Step=9600 Epoch= 9.4] | Loss=0.04905 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.524 | L2-Norm(final)=4.060 | 3846.2 samples/s | 60.1 steps/s
[Step=9650 Epoch= 9.4] | Loss=0.04868 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.535 | L2-Norm(final)=4.056 | 3834.8 samples/s | 59.9 steps/s
[Step=9700 Epoch= 9.5] | Loss=0.04773 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.547 | L2-Norm(final)=4.054 | 3891.5 samples/s | 60.8 steps/s
[Step=9750 Epoch= 9.5] | Loss=0.04715 | Reg=0.00344 | acc=0.9844 | L2-Norm=18.558 | L2-Norm(final)=4.051 | 3885.3 samples/s | 60.7 steps/s
[Step=9800 Epoch= 9.6] | Loss=0.04664 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.569 | L2-Norm(final)=4.049 | 3929.6 samples/s | 61.4 steps/s
[Step=9850 Epoch= 9.6] | Loss=0.04614 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.579 | L2-Norm(final)=4.046 | 3893.7 samples/s | 60.8 steps/s
[Step=9900 Epoch= 9.7] | Loss=0.04576 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.589 | L2-Norm(final)=4.044 | 3934.8 samples/s | 61.5 steps/s
[Step=9950 Epoch= 9.7] | Loss=0.04561 | Reg=0.00346 | acc=0.9062 | L2-Norm=18.599 | L2-Norm(final)=4.041 | 3945.9 samples/s | 61.7 steps/s
[Step=10000 Epoch= 9.8] | Loss=0.04527 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.609 | L2-Norm(final)=4.038 | 3964.5 samples/s | 61.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step10000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=8001 Epoch=15.1] | Loss=0.01486 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.334 | L2-Norm(final)=3.458 | 3413.0 samples/s | 53.3 steps/s
[Step=8050 Epoch=15.2] | Loss=0.00613 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.378 | L2-Norm(final)=3.496 | 3703.5 samples/s | 57.9 steps/s
[Step=8100 Epoch=15.3] | Loss=0.00448 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.393 | L2-Norm(final)=3.533 | 4083.8 samples/s | 63.8 steps/s
[Step=8150 Epoch=15.4] | Loss=0.00394 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.402 | L2-Norm(final)=3.563 | 4196.1 samples/s | 65.6 steps/s
[Step=8200 Epoch=15.5] | Loss=0.00337 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.403 | L2-Norm(final)=3.587 | 4015.4 samples/s | 62.7 steps/s
[Step=8250 Epoch=15.6] | Loss=0.00303 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.399 | L2-Norm(final)=3.608 | 4128.0 samples/s | 64.5 steps/s
[Step=8300 Epoch=15.6] | Loss=0.00280 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.393 | L2-Norm(final)=3.628 | 4086.4 samples/s | 63.9 steps/s
[Step=8350 Epoch=15.7] | Loss=0.00256 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.382 | L2-Norm(final)=3.648 | 4176.0 samples/s | 65.3 steps/s
[Step=8400 Epoch=15.8] | Loss=0.00259 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.371 | L2-Norm(final)=3.667 | 4093.3 samples/s | 64.0 steps/s
[Step=8450 Epoch=15.9] | Loss=0.00250 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.361 | L2-Norm(final)=3.685 | 4152.9 samples/s | 64.9 steps/s
[Step=8500 Epoch=16.0] | Loss=0.00242 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.355 | L2-Norm(final)=3.703 | 4175.5 samples/s | 65.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=8501 Epoch=16.0] | Loss=0.00012 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.310 | L2-Norm(final)=3.876 | 3176.2 samples/s | 49.6 steps/s
[Step=8550 Epoch=16.1] | Loss=0.00375 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.311 | L2-Norm(final)=3.887 | 3570.3 samples/s | 55.8 steps/s
[Step=8600 Epoch=16.2] | Loss=0.01252 | Reg=0.00268 | acc=0.9844 | L2-Norm=16.381 | L2-Norm(final)=3.843 | 3735.7 samples/s | 58.4 steps/s
[Step=8650 Epoch=16.3] | Loss=0.01442 | Reg=0.00272 | acc=0.9844 | L2-Norm=16.483 | L2-Norm(final)=3.773 | 3756.2 samples/s | 58.7 steps/s
[Step=8700 Epoch=16.4] | Loss=0.01148 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.555 | L2-Norm(final)=3.738 | 3717.2 samples/s | 58.1 steps/s
[Step=8750 Epoch=16.5] | Loss=0.00935 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.589 | L2-Norm(final)=3.722 | 3704.2 samples/s | 57.9 steps/s
[Step=8800 Epoch=16.6] | Loss=0.00872 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.603 | L2-Norm(final)=3.712 | 3756.5 samples/s | 58.7 steps/s
[Step=8850 Epoch=16.7] | Loss=0.00806 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.609 | L2-Norm(final)=3.704 | 3754.4 samples/s | 58.7 steps/s
[Step=8900 Epoch=16.8] | Loss=0.00723 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.611 | L2-Norm(final)=3.699 | 3718.0 samples/s | 58.1 steps/s
[Step=8950 Epoch=16.9] | Loss=0.00653 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.608 | L2-Norm(final)=3.698 | 3756.4 samples/s | 58.7 steps/s
[Step=9000 Epoch=17.0] | Loss=0.00609 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.600 | L2-Norm(final)=3.696 | 3797.8 samples/s | 59.3 steps/s
[Step=9050 Epoch=17.1] | Loss=0.00576 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.590 | L2-Norm(final)=3.695 | 1614.9 samples/s | 25.2 steps/s
[Step=9100 Epoch=17.2] | Loss=0.00531 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.579 | L2-Norm(final)=3.694 | 3766.5 samples/s | 58.9 steps/s
[Step=9150 Epoch=17.2] | Loss=0.00510 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.565 | L2-Norm(final)=3.693 | 3755.4 samples/s | 58.7 steps/s
[Step=9200 Epoch=17.3] | Loss=0.00478 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.553 | L2-Norm(final)=3.693 | 3639.5 samples/s | 56.9 steps/s
[Step=9250 Epoch=17.4] | Loss=0.00449 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.539 | L2-Norm(final)=3.693 | 3720.4 samples/s | 58.1 steps/s
[Step=9300 Epoch=17.5] | Loss=0.00428 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=3.693 | 3747.8 samples/s | 58.6 steps/s
[Step=9350 Epoch=17.6] | Loss=0.00432 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.508 | L2-Norm(final)=3.692 | 3731.2 samples/s | 58.3 steps/s
[Step=9400 Epoch=17.7] | Loss=0.00420 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.495 | L2-Norm(final)=3.690 | 3726.0 samples/s | 58.2 steps/s
[Step=9450 Epoch=17.8] | Loss=0.00409 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.484 | L2-Norm(final)=3.689 | 3761.1 samples/s | 58.8 steps/s
[Step=9500 Epoch=17.9] | Loss=0.00390 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.472 | L2-Norm(final)=3.689 | 3691.4 samples/s | 57.7 steps/s
[Step=9550 Epoch=18.0] | Loss=0.00372 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.458 | L2-Norm(final)=3.689 | 4685.2 samples/s | 73.2 steps/s
[Step=9600 Epoch=18.1] | Loss=0.00356 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.442 | L2-Norm(final)=3.689 | 1537.2 samples/s | 24.0 steps/s
[Step=9650 Epoch=18.2] | Loss=0.00340 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.425 | L2-Norm(final)=3.690 | 3713.8 samples/s | 58.0 steps/s
[Step=9700 Epoch=18.3] | Loss=0.00326 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.406 | L2-Norm(final)=3.690 | 3738.4 samples/s | 58.4 steps/s
[Step=9750 Epoch=18.4] | Loss=0.00313 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.385 | L2-Norm(final)=3.691 | 3739.5 samples/s | 58.4 steps/s
[Step=9800 Epoch=18.5] | Loss=0.00302 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.364 | L2-Norm(final)=3.691 | 3722.4 samples/s | 58.2 steps/s
[Step=9850 Epoch=18.6] | Loss=0.00298 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=3.691 | 3757.7 samples/s | 58.7 steps/s
[Step=9900 Epoch=18.7] | Loss=0.00290 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=3.691 | 3745.5 samples/s | 58.5 steps/s
[Step=9950 Epoch=18.8] | Loss=0.00283 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.303 | L2-Norm(final)=3.690 | 3765.4 samples/s | 58.8 steps/s
[Step=10000 Epoch=18.9] | Loss=0.00279 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.283 | L2-Norm(final)=3.690 | 3733.8 samples/s | 58.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step10000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.04992 | acc=0.9654 | tpr=0.9741 | fpr=0.0535 | 3634.7 samples/s | 14.2 steps/s
Avg test loss: 0.05146, Avg test acc: 0.96418, Avg tpr: 0.97196, Avg fpr: 0.05294, total FA: 413

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.55993 | acc=0.3093 | tpr=0.0095 | fpr=0.0396 | 3620.4 samples/s | 14.1 steps/s
Avg test loss: 5.57477, Avg test acc: 0.30724, Avg tpr: 0.00956, Avg fpr: 0.03807, total FA: 297

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.13499 | acc=0.1336 | tpr=0.7035 | fpr=0.8767 | 3632.5 samples/s | 14.2 steps/s
[Step= 100] | Loss=3.12635 | acc=0.1334 | tpr=0.6823 | fpr=0.8769 | 6716.2 samples/s | 26.2 steps/s
[Step= 150] | Loss=3.12351 | acc=0.1326 | tpr=0.6945 | fpr=0.8777 | 7015.9 samples/s | 27.4 steps/s
[Step= 200] | Loss=3.11287 | acc=0.1329 | tpr=0.7049 | fpr=0.8776 | 6800.0 samples/s | 26.6 steps/s
[Step= 250] | Loss=3.11590 | acc=0.1335 | tpr=0.6969 | fpr=0.8768 | 6992.0 samples/s | 27.3 steps/s
[Step= 300] | Loss=3.11562 | acc=0.1330 | tpr=0.7011 | fpr=0.8773 | 6839.6 samples/s | 26.7 steps/s
[Step= 350] | Loss=3.11686 | acc=0.1328 | tpr=0.7044 | fpr=0.8775 | 6800.3 samples/s | 26.6 steps/s
[Step= 400] | Loss=3.11589 | acc=0.1331 | tpr=0.7057 | fpr=0.8773 | 6842.3 samples/s | 26.7 steps/s
[Step= 450] | Loss=3.11558 | acc=0.1334 | tpr=0.7079 | fpr=0.8770 | 6845.8 samples/s | 26.7 steps/s
[Step= 500] | Loss=3.11818 | acc=0.1336 | tpr=0.7097 | fpr=0.8768 | 6672.2 samples/s | 26.1 steps/s
[Step= 550] | Loss=3.11869 | acc=0.1336 | tpr=0.7059 | fpr=0.8769 | 12527.4 samples/s | 48.9 steps/s
Avg test loss: 3.11901, Avg test acc: 0.13351, Avg tpr: 0.70642, Avg fpr: 0.87691, total FA: 121757

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08107 | acc=0.9843 | tpr=0.9513 | fpr=0.0151 | 3575.6 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.08437 | acc=0.9838 | tpr=0.9659 | fpr=0.0158 | 6838.3 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.08655 | acc=0.9828 | tpr=0.9654 | fpr=0.0169 | 7054.7 samples/s | 27.6 steps/s
[Step= 200] | Loss=0.08856 | acc=0.9827 | tpr=0.9661 | fpr=0.0170 | 6717.8 samples/s | 26.2 steps/s
[Step= 250] | Loss=0.08665 | acc=0.9830 | tpr=0.9633 | fpr=0.0166 | 6855.2 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.08833 | acc=0.9828 | tpr=0.9622 | fpr=0.0168 | 6857.2 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.08910 | acc=0.9825 | tpr=0.9631 | fpr=0.0171 | 7048.1 samples/s | 27.5 steps/s
[Step= 400] | Loss=0.08969 | acc=0.9824 | tpr=0.9617 | fpr=0.0172 | 6668.1 samples/s | 26.0 steps/s
[Step= 450] | Loss=0.09149 | acc=0.9822 | tpr=0.9606 | fpr=0.0174 | 6777.4 samples/s | 26.5 steps/s
[Step= 500] | Loss=0.09121 | acc=0.9823 | tpr=0.9608 | fpr=0.0173 | 6798.6 samples/s | 26.6 steps/s
[Step= 550] | Loss=0.09068 | acc=0.9824 | tpr=0.9594 | fpr=0.0172 | 12432.8 samples/s | 48.6 steps/s
Avg test loss: 0.09047, Avg test acc: 0.98239, Avg tpr: 0.95959, Avg fpr: 0.01720, total FA: 2388

server round 5/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch= 9.8] | Loss=0.13137 | Reg=0.00264 | acc=0.9062 | L2-Norm=16.245 | L2-Norm(final)=3.955 | 3212.1 samples/s | 50.2 steps/s
[Step=10050 Epoch= 9.8] | Loss=0.08396 | Reg=0.00269 | acc=0.9062 | L2-Norm=16.404 | L2-Norm(final)=4.012 | 4237.1 samples/s | 66.2 steps/s
[Step=10100 Epoch= 9.9] | Loss=0.08623 | Reg=0.00274 | acc=0.9375 | L2-Norm=16.541 | L2-Norm(final)=4.049 | 4277.1 samples/s | 66.8 steps/s
[Step=10150 Epoch= 9.9] | Loss=0.08357 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.651 | L2-Norm(final)=4.080 | 4282.1 samples/s | 66.9 steps/s
[Step=10200 Epoch=10.0] | Loss=0.07894 | Reg=0.00280 | acc=0.9531 | L2-Norm=16.741 | L2-Norm(final)=4.112 | 4408.0 samples/s | 68.9 steps/s
[Step=10250 Epoch=10.0] | Loss=0.07749 | Reg=0.00283 | acc=0.8906 | L2-Norm=16.824 | L2-Norm(final)=4.144 | 4424.8 samples/s | 69.1 steps/s
[Step=10300 Epoch=10.1] | Loss=0.07757 | Reg=0.00286 | acc=0.9531 | L2-Norm=16.907 | L2-Norm(final)=4.172 | 4340.8 samples/s | 67.8 steps/s
[Step=10350 Epoch=10.1] | Loss=0.07560 | Reg=0.00289 | acc=0.9688 | L2-Norm=16.990 | L2-Norm(final)=4.201 | 4403.7 samples/s | 68.8 steps/s
[Step=10400 Epoch=10.2] | Loss=0.07562 | Reg=0.00291 | acc=0.9531 | L2-Norm=17.068 | L2-Norm(final)=4.229 | 4355.0 samples/s | 68.0 steps/s
[Step=10450 Epoch=10.2] | Loss=0.07466 | Reg=0.00294 | acc=1.0000 | L2-Norm=17.143 | L2-Norm(final)=4.254 | 4378.8 samples/s | 68.4 steps/s
[Step=10500 Epoch=10.3] | Loss=0.07398 | Reg=0.00297 | acc=0.9375 | L2-Norm=17.216 | L2-Norm(final)=4.281 | 4389.4 samples/s | 68.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=10.3] | Loss=0.06417 | Reg=0.00321 | acc=0.9219 | L2-Norm=17.922 | L2-Norm(final)=4.533 | 3217.3 samples/s | 50.3 steps/s
[Step=10550 Epoch=10.3] | Loss=0.06727 | Reg=0.00324 | acc=1.0000 | L2-Norm=17.996 | L2-Norm(final)=4.537 | 3834.4 samples/s | 59.9 steps/s
[Step=10600 Epoch=10.3] | Loss=0.06558 | Reg=0.00326 | acc=0.9688 | L2-Norm=18.058 | L2-Norm(final)=4.511 | 3906.1 samples/s | 61.0 steps/s
[Step=10650 Epoch=10.4] | Loss=0.06400 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.109 | L2-Norm(final)=4.488 | 3916.5 samples/s | 61.2 steps/s
[Step=10700 Epoch=10.4] | Loss=0.06029 | Reg=0.00329 | acc=0.9375 | L2-Norm=18.151 | L2-Norm(final)=4.475 | 3938.6 samples/s | 61.5 steps/s
[Step=10750 Epoch=10.5] | Loss=0.05725 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.185 | L2-Norm(final)=4.467 | 3962.3 samples/s | 61.9 steps/s
[Step=10800 Epoch=10.5] | Loss=0.05462 | Reg=0.00332 | acc=0.9375 | L2-Norm=18.216 | L2-Norm(final)=4.462 | 3932.9 samples/s | 61.5 steps/s
[Step=10850 Epoch=10.6] | Loss=0.05426 | Reg=0.00333 | acc=0.9219 | L2-Norm=18.243 | L2-Norm(final)=4.457 | 3922.4 samples/s | 61.3 steps/s
[Step=10900 Epoch=10.6] | Loss=0.05338 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.269 | L2-Norm(final)=4.451 | 3936.5 samples/s | 61.5 steps/s
[Step=10950 Epoch=10.7] | Loss=0.05242 | Reg=0.00335 | acc=1.0000 | L2-Norm=18.294 | L2-Norm(final)=4.445 | 3947.2 samples/s | 61.7 steps/s
[Step=11000 Epoch=10.7] | Loss=0.05173 | Reg=0.00336 | acc=0.9844 | L2-Norm=18.318 | L2-Norm(final)=4.439 | 3972.6 samples/s | 62.1 steps/s
[Step=11050 Epoch=10.8] | Loss=0.05134 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.341 | L2-Norm(final)=4.432 | 3925.1 samples/s | 61.3 steps/s
[Step=11100 Epoch=10.8] | Loss=0.05033 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.361 | L2-Norm(final)=4.426 | 3946.3 samples/s | 61.7 steps/s
[Step=11150 Epoch=10.9] | Loss=0.04982 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.380 | L2-Norm(final)=4.421 | 3930.4 samples/s | 61.4 steps/s
[Step=11200 Epoch=10.9] | Loss=0.04946 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.399 | L2-Norm(final)=4.414 | 3939.3 samples/s | 61.6 steps/s
[Step=11250 Epoch=11.0] | Loss=0.04860 | Reg=0.00339 | acc=0.9219 | L2-Norm=18.416 | L2-Norm(final)=4.408 | 3969.0 samples/s | 62.0 steps/s
[Step=11300 Epoch=11.0] | Loss=0.04793 | Reg=0.00340 | acc=0.9375 | L2-Norm=18.433 | L2-Norm(final)=4.403 | 3975.2 samples/s | 62.1 steps/s
[Step=11350 Epoch=11.1] | Loss=0.04736 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.449 | L2-Norm(final)=4.397 | 3994.5 samples/s | 62.4 steps/s
[Step=11400 Epoch=11.1] | Loss=0.04673 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.465 | L2-Norm(final)=4.392 | 4056.1 samples/s | 63.4 steps/s
[Step=11450 Epoch=11.2] | Loss=0.04610 | Reg=0.00342 | acc=0.9375 | L2-Norm=18.480 | L2-Norm(final)=4.388 | 3983.7 samples/s | 62.2 steps/s
[Step=11500 Epoch=11.2] | Loss=0.04590 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.495 | L2-Norm(final)=4.383 | 4258.0 samples/s | 66.5 steps/s
[Step=11550 Epoch=11.3] | Loss=0.04538 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.509 | L2-Norm(final)=4.377 | 1659.1 samples/s | 25.9 steps/s
[Step=11600 Epoch=11.3] | Loss=0.04480 | Reg=0.00343 | acc=0.9531 | L2-Norm=18.523 | L2-Norm(final)=4.373 | 3970.1 samples/s | 62.0 steps/s
[Step=11650 Epoch=11.4] | Loss=0.04431 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.536 | L2-Norm(final)=4.369 | 3905.6 samples/s | 61.0 steps/s
[Step=11700 Epoch=11.4] | Loss=0.04375 | Reg=0.00344 | acc=1.0000 | L2-Norm=18.548 | L2-Norm(final)=4.365 | 3959.4 samples/s | 61.9 steps/s
[Step=11750 Epoch=11.5] | Loss=0.04304 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.560 | L2-Norm(final)=4.361 | 3916.6 samples/s | 61.2 steps/s
[Step=11800 Epoch=11.5] | Loss=0.04258 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.573 | L2-Norm(final)=4.357 | 3932.1 samples/s | 61.4 steps/s
[Step=11850 Epoch=11.6] | Loss=0.04229 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.586 | L2-Norm(final)=4.354 | 3984.9 samples/s | 62.3 steps/s
[Step=11900 Epoch=11.6] | Loss=0.04191 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.600 | L2-Norm(final)=4.350 | 3962.6 samples/s | 61.9 steps/s
[Step=11950 Epoch=11.7] | Loss=0.04154 | Reg=0.00347 | acc=0.9219 | L2-Norm=18.613 | L2-Norm(final)=4.346 | 3989.1 samples/s | 62.3 steps/s
[Step=12000 Epoch=11.7] | Loss=0.04132 | Reg=0.00347 | acc=0.9375 | L2-Norm=18.627 | L2-Norm(final)=4.343 | 3950.2 samples/s | 61.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step12000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=10001 Epoch=18.9] | Loss=0.00446 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=3.684 | 3246.3 samples/s | 50.7 steps/s
[Step=10050 Epoch=18.9] | Loss=0.00400 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.266 | L2-Norm(final)=3.716 | 4023.8 samples/s | 62.9 steps/s
[Step=10100 Epoch=19.0] | Loss=0.00252 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.257 | L2-Norm(final)=3.746 | 4095.5 samples/s | 64.0 steps/s
[Step=10150 Epoch=19.1] | Loss=0.00214 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.239 | L2-Norm(final)=3.770 | 4129.0 samples/s | 64.5 steps/s
[Step=10200 Epoch=19.2] | Loss=0.00183 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.218 | L2-Norm(final)=3.790 | 4029.3 samples/s | 63.0 steps/s
[Step=10250 Epoch=19.3] | Loss=0.00178 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.202 | L2-Norm(final)=3.807 | 4178.0 samples/s | 65.3 steps/s
[Step=10300 Epoch=19.4] | Loss=0.00160 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.188 | L2-Norm(final)=3.822 | 4055.3 samples/s | 63.4 steps/s
[Step=10350 Epoch=19.5] | Loss=0.00143 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=3.837 | 4113.9 samples/s | 64.3 steps/s
[Step=10400 Epoch=19.6] | Loss=0.00139 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.155 | L2-Norm(final)=3.851 | 4086.5 samples/s | 63.9 steps/s
[Step=10450 Epoch=19.7] | Loss=0.00133 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.141 | L2-Norm(final)=3.866 | 4179.6 samples/s | 65.3 steps/s
[Step=10500 Epoch=19.8] | Loss=0.00138 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.127 | L2-Norm(final)=3.880 | 4163.8 samples/s | 65.1 steps/s
All layers training...
LR=0.00100, len=1
[Step=10501 Epoch=19.8] | Loss=0.00059 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.975 | L2-Norm(final)=4.009 | 3271.9 samples/s | 51.1 steps/s
[Step=10550 Epoch=19.9] | Loss=0.00775 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.957 | L2-Norm(final)=4.014 | 3437.2 samples/s | 53.7 steps/s
[Step=10600 Epoch=20.0] | Loss=0.01149 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.160 | L2-Norm(final)=3.935 | 3745.3 samples/s | 58.5 steps/s
[Step=10650 Epoch=20.1] | Loss=0.00907 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=3.885 | 3673.0 samples/s | 57.4 steps/s
[Step=10700 Epoch=20.2] | Loss=0.00843 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.400 | L2-Norm(final)=3.853 | 3737.4 samples/s | 58.4 steps/s
[Step=10750 Epoch=20.3] | Loss=0.00775 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.454 | L2-Norm(final)=3.830 | 3661.0 samples/s | 57.2 steps/s
[Step=10800 Epoch=20.4] | Loss=0.00679 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.486 | L2-Norm(final)=3.815 | 3682.9 samples/s | 57.5 steps/s
[Step=10850 Epoch=20.5] | Loss=0.00656 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.504 | L2-Norm(final)=3.805 | 3760.8 samples/s | 58.8 steps/s
[Step=10900 Epoch=20.5] | Loss=0.00600 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.517 | L2-Norm(final)=3.797 | 3714.7 samples/s | 58.0 steps/s
[Step=10950 Epoch=20.6] | Loss=0.00551 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=3.794 | 3730.2 samples/s | 58.3 steps/s
[Step=11000 Epoch=20.7] | Loss=0.00520 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.522 | L2-Norm(final)=3.792 | 3774.5 samples/s | 59.0 steps/s
[Step=11050 Epoch=20.8] | Loss=0.00484 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.520 | L2-Norm(final)=3.790 | 1670.6 samples/s | 26.1 steps/s
[Step=11100 Epoch=20.9] | Loss=0.00448 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.514 | L2-Norm(final)=3.790 | 3743.4 samples/s | 58.5 steps/s
[Step=11150 Epoch=21.0] | Loss=0.00416 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.504 | L2-Norm(final)=3.790 | 3728.7 samples/s | 58.3 steps/s
[Step=11200 Epoch=21.1] | Loss=0.00387 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.492 | L2-Norm(final)=3.791 | 3713.5 samples/s | 58.0 steps/s
[Step=11250 Epoch=21.2] | Loss=0.00363 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.477 | L2-Norm(final)=3.792 | 3694.2 samples/s | 57.7 steps/s
[Step=11300 Epoch=21.3] | Loss=0.00340 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.461 | L2-Norm(final)=3.794 | 3740.1 samples/s | 58.4 steps/s
[Step=11350 Epoch=21.4] | Loss=0.00323 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.442 | L2-Norm(final)=3.795 | 3730.5 samples/s | 58.3 steps/s
[Step=11400 Epoch=21.5] | Loss=0.00305 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.423 | L2-Norm(final)=3.797 | 3705.7 samples/s | 57.9 steps/s
[Step=11450 Epoch=21.6] | Loss=0.00289 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.402 | L2-Norm(final)=3.799 | 3742.4 samples/s | 58.5 steps/s
[Step=11500 Epoch=21.7] | Loss=0.00276 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.381 | L2-Norm(final)=3.801 | 3787.7 samples/s | 59.2 steps/s
[Step=11550 Epoch=21.8] | Loss=0.00263 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.359 | L2-Norm(final)=3.803 | 4647.4 samples/s | 72.6 steps/s
[Step=11600 Epoch=21.9] | Loss=0.00252 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.336 | L2-Norm(final)=3.805 | 1545.8 samples/s | 24.2 steps/s
[Step=11650 Epoch=22.0] | Loss=0.00241 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.313 | L2-Norm(final)=3.807 | 3653.6 samples/s | 57.1 steps/s
[Step=11700 Epoch=22.1] | Loss=0.00231 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.289 | L2-Norm(final)=3.809 | 3704.8 samples/s | 57.9 steps/s
[Step=11750 Epoch=22.1] | Loss=0.00222 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.264 | L2-Norm(final)=3.811 | 3721.5 samples/s | 58.1 steps/s
[Step=11800 Epoch=22.2] | Loss=0.00214 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.239 | L2-Norm(final)=3.813 | 3693.5 samples/s | 57.7 steps/s
[Step=11850 Epoch=22.3] | Loss=0.00206 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.213 | L2-Norm(final)=3.815 | 3657.1 samples/s | 57.1 steps/s
[Step=11900 Epoch=22.4] | Loss=0.00198 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.187 | L2-Norm(final)=3.817 | 3712.4 samples/s | 58.0 steps/s
[Step=11950 Epoch=22.5] | Loss=0.00192 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.160 | L2-Norm(final)=3.819 | 3756.7 samples/s | 58.7 steps/s
[Step=12000 Epoch=22.6] | Loss=0.00185 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.134 | L2-Norm(final)=3.821 | 3704.0 samples/s | 57.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step12000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05285 | acc=0.9645 | tpr=0.9730 | fpr=0.0540 | 3584.2 samples/s | 14.0 steps/s
Avg test loss: 0.05278, Avg test acc: 0.96374, Avg tpr: 0.97144, Avg fpr: 0.05320, total FA: 415

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.19496 | acc=0.3141 | tpr=0.0089 | fpr=0.0233 | 3671.2 samples/s | 14.3 steps/s
Avg test loss: 5.20963, Avg test acc: 0.31184, Avg tpr: 0.00909, Avg fpr: 0.02230, total FA: 174

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.43944 | acc=0.1422 | tpr=0.7035 | fpr=0.8679 | 3663.0 samples/s | 14.3 steps/s
[Step= 100] | Loss=3.43284 | acc=0.1421 | tpr=0.6887 | fpr=0.8681 | 6685.6 samples/s | 26.1 steps/s
[Step= 150] | Loss=3.42545 | acc=0.1417 | tpr=0.6974 | fpr=0.8685 | 6864.7 samples/s | 26.8 steps/s
[Step= 200] | Loss=3.41700 | acc=0.1421 | tpr=0.6852 | fpr=0.8678 | 6947.3 samples/s | 27.1 steps/s
[Step= 250] | Loss=3.41807 | acc=0.1431 | tpr=0.7022 | fpr=0.8670 | 6905.5 samples/s | 27.0 steps/s
[Step= 300] | Loss=3.41269 | acc=0.1429 | tpr=0.7033 | fpr=0.8673 | 6831.3 samples/s | 26.7 steps/s
[Step= 350] | Loss=3.41193 | acc=0.1425 | tpr=0.6938 | fpr=0.8675 | 6769.6 samples/s | 26.4 steps/s
[Step= 400] | Loss=3.41268 | acc=0.1426 | tpr=0.6947 | fpr=0.8674 | 6830.5 samples/s | 26.7 steps/s
[Step= 450] | Loss=3.41335 | acc=0.1429 | tpr=0.6938 | fpr=0.8671 | 6715.9 samples/s | 26.2 steps/s
[Step= 500] | Loss=3.41667 | acc=0.1429 | tpr=0.6899 | fpr=0.8670 | 6764.8 samples/s | 26.4 steps/s
[Step= 550] | Loss=3.41818 | acc=0.1425 | tpr=0.6928 | fpr=0.8675 | 12323.5 samples/s | 48.1 steps/s
Avg test loss: 3.41901, Avg test acc: 0.14248, Avg tpr: 0.69295, Avg fpr: 0.86753, total FA: 120455

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11601 | acc=0.9834 | tpr=0.9690 | fpr=0.0163 | 3614.2 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.12207 | acc=0.9827 | tpr=0.9659 | fpr=0.0170 | 7031.6 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.12663 | acc=0.9818 | tpr=0.9669 | fpr=0.0179 | 6745.0 samples/s | 26.3 steps/s
[Step= 200] | Loss=0.12783 | acc=0.9820 | tpr=0.9661 | fpr=0.0177 | 6902.2 samples/s | 27.0 steps/s
[Step= 250] | Loss=0.12582 | acc=0.9821 | tpr=0.9624 | fpr=0.0176 | 7043.8 samples/s | 27.5 steps/s
[Step= 300] | Loss=0.12764 | acc=0.9819 | tpr=0.9593 | fpr=0.0177 | 6819.9 samples/s | 26.6 steps/s
[Step= 350] | Loss=0.12916 | acc=0.9816 | tpr=0.9593 | fpr=0.0180 | 6961.1 samples/s | 27.2 steps/s
[Step= 400] | Loss=0.13033 | acc=0.9815 | tpr=0.9573 | fpr=0.0181 | 6861.8 samples/s | 26.8 steps/s
[Step= 450] | Loss=0.13266 | acc=0.9812 | tpr=0.9552 | fpr=0.0183 | 6830.3 samples/s | 26.7 steps/s
[Step= 500] | Loss=0.13211 | acc=0.9812 | tpr=0.9559 | fpr=0.0183 | 6775.7 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.13136 | acc=0.9813 | tpr=0.9546 | fpr=0.0182 | 12294.3 samples/s | 48.0 steps/s
Avg test loss: 0.13096, Avg test acc: 0.98137, Avg tpr: 0.95483, Avg fpr: 0.01815, total FA: 2520

server round 6/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=11.7] | Loss=0.20307 | Reg=0.00262 | acc=0.8281 | L2-Norm=16.187 | L2-Norm(final)=4.228 | 3408.3 samples/s | 53.3 steps/s
[Step=12050 Epoch=11.8] | Loss=0.08072 | Reg=0.00268 | acc=0.9375 | L2-Norm=16.381 | L2-Norm(final)=4.275 | 4010.9 samples/s | 62.7 steps/s
[Step=12100 Epoch=11.8] | Loss=0.07937 | Reg=0.00274 | acc=0.9531 | L2-Norm=16.558 | L2-Norm(final)=4.310 | 4263.6 samples/s | 66.6 steps/s
[Step=12150 Epoch=11.9] | Loss=0.07460 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.688 | L2-Norm(final)=4.340 | 4358.6 samples/s | 68.1 steps/s
[Step=12200 Epoch=11.9] | Loss=0.07361 | Reg=0.00282 | acc=0.9062 | L2-Norm=16.801 | L2-Norm(final)=4.370 | 4379.3 samples/s | 68.4 steps/s
[Step=12250 Epoch=12.0] | Loss=0.07383 | Reg=0.00286 | acc=0.9531 | L2-Norm=16.905 | L2-Norm(final)=4.392 | 4329.1 samples/s | 67.6 steps/s
[Step=12300 Epoch=12.0] | Loss=0.07263 | Reg=0.00289 | acc=0.9688 | L2-Norm=16.996 | L2-Norm(final)=4.415 | 4351.4 samples/s | 68.0 steps/s
[Step=12350 Epoch=12.1] | Loss=0.07246 | Reg=0.00292 | acc=0.9219 | L2-Norm=17.077 | L2-Norm(final)=4.437 | 4395.9 samples/s | 68.7 steps/s
[Step=12400 Epoch=12.1] | Loss=0.07210 | Reg=0.00294 | acc=0.9688 | L2-Norm=17.151 | L2-Norm(final)=4.458 | 4447.2 samples/s | 69.5 steps/s
[Step=12450 Epoch=12.2] | Loss=0.07088 | Reg=0.00297 | acc=0.9531 | L2-Norm=17.219 | L2-Norm(final)=4.479 | 4310.5 samples/s | 67.4 steps/s
[Step=12500 Epoch=12.2] | Loss=0.06989 | Reg=0.00299 | acc=0.9375 | L2-Norm=17.286 | L2-Norm(final)=4.501 | 4416.4 samples/s | 69.0 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=12.2] | Loss=0.07611 | Reg=0.00322 | acc=0.9219 | L2-Norm=17.956 | L2-Norm(final)=4.730 | 3344.4 samples/s | 52.3 steps/s
[Step=12550 Epoch=12.3] | Loss=0.06210 | Reg=0.00325 | acc=0.9219 | L2-Norm=18.030 | L2-Norm(final)=4.728 | 3729.6 samples/s | 58.3 steps/s
[Step=12600 Epoch=12.3] | Loss=0.05929 | Reg=0.00328 | acc=0.9844 | L2-Norm=18.097 | L2-Norm(final)=4.706 | 3927.2 samples/s | 61.4 steps/s
[Step=12650 Epoch=12.4] | Loss=0.05705 | Reg=0.00330 | acc=0.9531 | L2-Norm=18.157 | L2-Norm(final)=4.686 | 4002.0 samples/s | 62.5 steps/s
[Step=12700 Epoch=12.4] | Loss=0.05663 | Reg=0.00331 | acc=0.9375 | L2-Norm=18.205 | L2-Norm(final)=4.672 | 3871.9 samples/s | 60.5 steps/s
[Step=12750 Epoch=12.4] | Loss=0.05588 | Reg=0.00333 | acc=0.9688 | L2-Norm=18.244 | L2-Norm(final)=4.661 | 3923.1 samples/s | 61.3 steps/s
[Step=12800 Epoch=12.5] | Loss=0.05429 | Reg=0.00334 | acc=0.9688 | L2-Norm=18.273 | L2-Norm(final)=4.651 | 3954.5 samples/s | 61.8 steps/s
[Step=12850 Epoch=12.5] | Loss=0.05247 | Reg=0.00335 | acc=0.9531 | L2-Norm=18.299 | L2-Norm(final)=4.644 | 3929.8 samples/s | 61.4 steps/s
[Step=12900 Epoch=12.6] | Loss=0.05102 | Reg=0.00336 | acc=0.9688 | L2-Norm=18.322 | L2-Norm(final)=4.639 | 3939.6 samples/s | 61.6 steps/s
[Step=12950 Epoch=12.6] | Loss=0.04982 | Reg=0.00337 | acc=0.9688 | L2-Norm=18.345 | L2-Norm(final)=4.635 | 3917.2 samples/s | 61.2 steps/s
[Step=13000 Epoch=12.7] | Loss=0.04856 | Reg=0.00337 | acc=0.9375 | L2-Norm=18.367 | L2-Norm(final)=4.631 | 4015.0 samples/s | 62.7 steps/s
[Step=13050 Epoch=12.7] | Loss=0.04802 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.387 | L2-Norm(final)=4.627 | 3948.7 samples/s | 61.7 steps/s
[Step=13100 Epoch=12.8] | Loss=0.04761 | Reg=0.00339 | acc=0.9531 | L2-Norm=18.407 | L2-Norm(final)=4.621 | 3932.5 samples/s | 61.4 steps/s
[Step=13150 Epoch=12.8] | Loss=0.04653 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.427 | L2-Norm(final)=4.616 | 3938.1 samples/s | 61.5 steps/s
[Step=13200 Epoch=12.9] | Loss=0.04602 | Reg=0.00340 | acc=0.9375 | L2-Norm=18.445 | L2-Norm(final)=4.612 | 3980.8 samples/s | 62.2 steps/s
[Step=13250 Epoch=12.9] | Loss=0.04515 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.464 | L2-Norm(final)=4.607 | 3958.8 samples/s | 61.9 steps/s
[Step=13300 Epoch=13.0] | Loss=0.04473 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.481 | L2-Norm(final)=4.602 | 3948.9 samples/s | 61.7 steps/s
[Step=13350 Epoch=13.0] | Loss=0.04416 | Reg=0.00342 | acc=0.9531 | L2-Norm=18.497 | L2-Norm(final)=4.599 | 3948.7 samples/s | 61.7 steps/s
[Step=13400 Epoch=13.1] | Loss=0.04384 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.512 | L2-Norm(final)=4.595 | 3933.7 samples/s | 61.5 steps/s
[Step=13450 Epoch=13.1] | Loss=0.04331 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.527 | L2-Norm(final)=4.591 | 4002.4 samples/s | 62.5 steps/s
[Step=13500 Epoch=13.2] | Loss=0.04295 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.541 | L2-Norm(final)=4.587 | 4247.5 samples/s | 66.4 steps/s
[Step=13550 Epoch=13.2] | Loss=0.04250 | Reg=0.00344 | acc=0.9688 | L2-Norm=18.555 | L2-Norm(final)=4.583 | 1666.1 samples/s | 26.0 steps/s
[Step=13600 Epoch=13.3] | Loss=0.04172 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.568 | L2-Norm(final)=4.580 | 3877.9 samples/s | 60.6 steps/s
[Step=13650 Epoch=13.3] | Loss=0.04108 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.581 | L2-Norm(final)=4.577 | 3938.2 samples/s | 61.5 steps/s
[Step=13700 Epoch=13.4] | Loss=0.04058 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.593 | L2-Norm(final)=4.574 | 3916.9 samples/s | 61.2 steps/s
[Step=13750 Epoch=13.4] | Loss=0.04013 | Reg=0.00346 | acc=1.0000 | L2-Norm=18.606 | L2-Norm(final)=4.571 | 3910.9 samples/s | 61.1 steps/s
[Step=13800 Epoch=13.5] | Loss=0.03986 | Reg=0.00347 | acc=0.9219 | L2-Norm=18.618 | L2-Norm(final)=4.569 | 3960.3 samples/s | 61.9 steps/s
[Step=13850 Epoch=13.5] | Loss=0.03947 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.630 | L2-Norm(final)=4.566 | 3939.1 samples/s | 61.5 steps/s
[Step=13900 Epoch=13.6] | Loss=0.03892 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.642 | L2-Norm(final)=4.564 | 3906.2 samples/s | 61.0 steps/s
[Step=13950 Epoch=13.6] | Loss=0.03879 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.654 | L2-Norm(final)=4.562 | 3927.7 samples/s | 61.4 steps/s
[Step=14000 Epoch=13.7] | Loss=0.03874 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.667 | L2-Norm(final)=4.559 | 3993.5 samples/s | 62.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step14000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=12001 Epoch=22.6] | Loss=0.02416 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.187 | L2-Norm(final)=3.874 | 3531.7 samples/s | 55.2 steps/s
[Step=12050 Epoch=22.7] | Loss=0.00326 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.233 | L2-Norm(final)=3.888 | 3528.6 samples/s | 55.1 steps/s
[Step=12100 Epoch=22.8] | Loss=0.00220 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=3.921 | 4051.2 samples/s | 63.3 steps/s
[Step=12150 Epoch=22.9] | Loss=0.00240 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.237 | L2-Norm(final)=3.942 | 4064.2 samples/s | 63.5 steps/s
[Step=12200 Epoch=23.0] | Loss=0.00224 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.255 | L2-Norm(final)=3.958 | 4138.9 samples/s | 64.7 steps/s
[Step=12250 Epoch=23.1] | Loss=0.00220 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.269 | L2-Norm(final)=3.970 | 4095.1 samples/s | 64.0 steps/s
[Step=12300 Epoch=23.2] | Loss=0.00203 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.274 | L2-Norm(final)=3.982 | 4119.4 samples/s | 64.4 steps/s
[Step=12350 Epoch=23.3] | Loss=0.00178 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.271 | L2-Norm(final)=3.994 | 4153.4 samples/s | 64.9 steps/s
[Step=12400 Epoch=23.4] | Loss=0.00165 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.264 | L2-Norm(final)=4.005 | 4129.6 samples/s | 64.5 steps/s
[Step=12450 Epoch=23.5] | Loss=0.00152 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.258 | L2-Norm(final)=4.017 | 4089.6 samples/s | 63.9 steps/s
[Step=12500 Epoch=23.6] | Loss=0.00146 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.250 | L2-Norm(final)=4.030 | 4137.5 samples/s | 64.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=12501 Epoch=23.6] | Loss=0.00004 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.155 | L2-Norm(final)=4.151 | 3154.9 samples/s | 49.3 steps/s
[Step=12550 Epoch=23.7] | Loss=0.00250 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.136 | L2-Norm(final)=4.154 | 3643.2 samples/s | 56.9 steps/s
[Step=12600 Epoch=23.8] | Loss=0.01432 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.325 | L2-Norm(final)=4.089 | 3712.3 samples/s | 58.0 steps/s
[Step=12650 Epoch=23.8] | Loss=0.01263 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.557 | L2-Norm(final)=3.994 | 3671.9 samples/s | 57.4 steps/s
[Step=12700 Epoch=23.9] | Loss=0.01171 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.685 | L2-Norm(final)=3.934 | 3749.5 samples/s | 58.6 steps/s
[Step=12750 Epoch=24.0] | Loss=0.01003 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.758 | L2-Norm(final)=3.902 | 3720.0 samples/s | 58.1 steps/s
[Step=12800 Epoch=24.1] | Loss=0.00897 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.803 | L2-Norm(final)=3.880 | 3715.3 samples/s | 58.1 steps/s
[Step=12850 Epoch=24.2] | Loss=0.00784 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.830 | L2-Norm(final)=3.866 | 3729.8 samples/s | 58.3 steps/s
[Step=12900 Epoch=24.3] | Loss=0.00694 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.842 | L2-Norm(final)=3.857 | 3740.0 samples/s | 58.4 steps/s
[Step=12950 Epoch=24.4] | Loss=0.00622 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.846 | L2-Norm(final)=3.852 | 3781.7 samples/s | 59.1 steps/s
[Step=13000 Epoch=24.5] | Loss=0.00562 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.843 | L2-Norm(final)=3.849 | 3761.6 samples/s | 58.8 steps/s
[Step=13050 Epoch=24.6] | Loss=0.00531 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.834 | L2-Norm(final)=3.846 | 1668.5 samples/s | 26.1 steps/s
[Step=13100 Epoch=24.7] | Loss=0.00497 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.823 | L2-Norm(final)=3.843 | 3742.4 samples/s | 58.5 steps/s
[Step=13150 Epoch=24.8] | Loss=0.00464 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.810 | L2-Norm(final)=3.841 | 3695.2 samples/s | 57.7 steps/s
[Step=13200 Epoch=24.9] | Loss=0.00435 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.794 | L2-Norm(final)=3.840 | 3685.7 samples/s | 57.6 steps/s
[Step=13250 Epoch=25.0] | Loss=0.00412 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.777 | L2-Norm(final)=3.840 | 3700.6 samples/s | 57.8 steps/s
[Step=13300 Epoch=25.1] | Loss=0.00417 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.761 | L2-Norm(final)=3.839 | 3653.8 samples/s | 57.1 steps/s
[Step=13350 Epoch=25.2] | Loss=0.00409 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.749 | L2-Norm(final)=3.837 | 3712.0 samples/s | 58.0 steps/s
[Step=13400 Epoch=25.3] | Loss=0.00405 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.739 | L2-Norm(final)=3.834 | 3714.3 samples/s | 58.0 steps/s
[Step=13450 Epoch=25.4] | Loss=0.00388 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.729 | L2-Norm(final)=3.832 | 3724.7 samples/s | 58.2 steps/s
[Step=13500 Epoch=25.4] | Loss=0.00370 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.717 | L2-Norm(final)=3.830 | 3670.7 samples/s | 57.4 steps/s
[Step=13550 Epoch=25.5] | Loss=0.00352 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.704 | L2-Norm(final)=3.829 | 4735.9 samples/s | 74.0 steps/s
[Step=13600 Epoch=25.6] | Loss=0.00337 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.689 | L2-Norm(final)=3.829 | 1526.2 samples/s | 23.8 steps/s
[Step=13650 Epoch=25.7] | Loss=0.00322 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.672 | L2-Norm(final)=3.829 | 3686.1 samples/s | 57.6 steps/s
[Step=13700 Epoch=25.8] | Loss=0.00317 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.655 | L2-Norm(final)=3.829 | 3663.7 samples/s | 57.2 steps/s
[Step=13750 Epoch=25.9] | Loss=0.00315 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.640 | L2-Norm(final)=3.829 | 3738.9 samples/s | 58.4 steps/s
[Step=13800 Epoch=26.0] | Loss=0.00309 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.627 | L2-Norm(final)=3.827 | 3718.3 samples/s | 58.1 steps/s
[Step=13850 Epoch=26.1] | Loss=0.00301 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.614 | L2-Norm(final)=3.826 | 3728.0 samples/s | 58.3 steps/s
[Step=13900 Epoch=26.2] | Loss=0.00291 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.601 | L2-Norm(final)=3.826 | 3728.7 samples/s | 58.3 steps/s
[Step=13950 Epoch=26.3] | Loss=0.00282 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.586 | L2-Norm(final)=3.826 | 3741.7 samples/s | 58.5 steps/s
[Step=14000 Epoch=26.4] | Loss=0.00273 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.571 | L2-Norm(final)=3.826 | 3694.0 samples/s | 57.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step14000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05155 | acc=0.9627 | tpr=0.9638 | fpr=0.0399 | 3612.9 samples/s | 14.1 steps/s
Avg test loss: 0.05207, Avg test acc: 0.96350, Avg tpr: 0.96334, Avg fpr: 0.03615, total FA: 282

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.34520 | acc=0.3154 | tpr=0.0024 | fpr=0.0050 | 3618.9 samples/s | 14.1 steps/s
Avg test loss: 6.37054, Avg test acc: 0.31212, Avg tpr: 0.00233, Avg fpr: 0.00654, total FA: 51

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.71150 | acc=0.1425 | tpr=0.4823 | fpr=0.8636 | 3701.4 samples/s | 14.5 steps/s
[Step= 100] | Loss=3.69855 | acc=0.1433 | tpr=0.4861 | fpr=0.8631 | 6562.9 samples/s | 25.6 steps/s
[Step= 150] | Loss=3.68999 | acc=0.1424 | tpr=0.5245 | fpr=0.8646 | 6954.5 samples/s | 27.2 steps/s
[Step= 200] | Loss=3.67864 | acc=0.1429 | tpr=0.5257 | fpr=0.8640 | 6859.4 samples/s | 26.8 steps/s
[Step= 250] | Loss=3.68729 | acc=0.1426 | tpr=0.5197 | fpr=0.8643 | 6788.6 samples/s | 26.5 steps/s
[Step= 300] | Loss=3.68505 | acc=0.1428 | tpr=0.5135 | fpr=0.8640 | 6964.9 samples/s | 27.2 steps/s
[Step= 350] | Loss=3.68430 | acc=0.1426 | tpr=0.5128 | fpr=0.8641 | 6898.4 samples/s | 26.9 steps/s
[Step= 400] | Loss=3.68602 | acc=0.1427 | tpr=0.5170 | fpr=0.8641 | 6676.7 samples/s | 26.1 steps/s
[Step= 450] | Loss=3.68733 | acc=0.1432 | tpr=0.5229 | fpr=0.8637 | 6821.3 samples/s | 26.6 steps/s
[Step= 500] | Loss=3.68935 | acc=0.1434 | tpr=0.5216 | fpr=0.8635 | 6899.0 samples/s | 26.9 steps/s
[Step= 550] | Loss=3.69074 | acc=0.1432 | tpr=0.5229 | fpr=0.8637 | 12912.1 samples/s | 50.4 steps/s
Avg test loss: 3.69212, Avg test acc: 0.14309, Avg tpr: 0.52338, Avg fpr: 0.86382, total FA: 119940

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09618 | acc=0.9819 | tpr=0.9558 | fpr=0.0177 | 3647.6 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.09932 | acc=0.9814 | tpr=0.9659 | fpr=0.0183 | 6618.3 samples/s | 25.9 steps/s
[Step= 150] | Loss=0.10353 | acc=0.9803 | tpr=0.9669 | fpr=0.0194 | 6908.2 samples/s | 27.0 steps/s
[Step= 200] | Loss=0.10552 | acc=0.9804 | tpr=0.9661 | fpr=0.0193 | 6866.0 samples/s | 26.8 steps/s
[Step= 250] | Loss=0.10452 | acc=0.9805 | tpr=0.9642 | fpr=0.0192 | 7189.9 samples/s | 28.1 steps/s
[Step= 300] | Loss=0.10561 | acc=0.9803 | tpr=0.9644 | fpr=0.0194 | 6606.4 samples/s | 25.8 steps/s
[Step= 350] | Loss=0.10627 | acc=0.9801 | tpr=0.9643 | fpr=0.0196 | 7013.0 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.10735 | acc=0.9800 | tpr=0.9633 | fpr=0.0197 | 6941.2 samples/s | 27.1 steps/s
[Step= 450] | Loss=0.11024 | acc=0.9796 | tpr=0.9606 | fpr=0.0201 | 6622.4 samples/s | 25.9 steps/s
[Step= 500] | Loss=0.10986 | acc=0.9796 | tpr=0.9590 | fpr=0.0200 | 6636.7 samples/s | 25.9 steps/s
[Step= 550] | Loss=0.10912 | acc=0.9798 | tpr=0.9594 | fpr=0.0198 | 12702.8 samples/s | 49.6 steps/s
Avg test loss: 0.10883, Avg test acc: 0.97980, Avg tpr: 0.95959, Avg fpr: 0.01983, total FA: 2754

server round 7/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=13.7] | Loss=0.09632 | Reg=0.00271 | acc=0.8750 | L2-Norm=16.468 | L2-Norm(final)=4.464 | 3210.6 samples/s | 50.2 steps/s
[Step=14050 Epoch=13.7] | Loss=0.09721 | Reg=0.00277 | acc=0.9062 | L2-Norm=16.658 | L2-Norm(final)=4.521 | 4277.9 samples/s | 66.8 steps/s
[Step=14100 Epoch=13.8] | Loss=0.08910 | Reg=0.00283 | acc=0.9531 | L2-Norm=16.808 | L2-Norm(final)=4.565 | 4275.3 samples/s | 66.8 steps/s
[Step=14150 Epoch=13.8] | Loss=0.08816 | Reg=0.00287 | acc=0.9375 | L2-Norm=16.926 | L2-Norm(final)=4.602 | 4325.7 samples/s | 67.6 steps/s
[Step=14200 Epoch=13.9] | Loss=0.08569 | Reg=0.00290 | acc=0.9531 | L2-Norm=17.030 | L2-Norm(final)=4.635 | 4387.4 samples/s | 68.6 steps/s
[Step=14250 Epoch=13.9] | Loss=0.08536 | Reg=0.00294 | acc=0.9375 | L2-Norm=17.131 | L2-Norm(final)=4.667 | 4284.5 samples/s | 66.9 steps/s
[Step=14300 Epoch=14.0] | Loss=0.08316 | Reg=0.00297 | acc=0.9688 | L2-Norm=17.224 | L2-Norm(final)=4.699 | 4396.5 samples/s | 68.7 steps/s
[Step=14350 Epoch=14.0] | Loss=0.08221 | Reg=0.00300 | acc=0.9375 | L2-Norm=17.311 | L2-Norm(final)=4.731 | 4289.9 samples/s | 67.0 steps/s
[Step=14400 Epoch=14.1] | Loss=0.08046 | Reg=0.00303 | acc=0.9531 | L2-Norm=17.396 | L2-Norm(final)=4.760 | 4411.2 samples/s | 68.9 steps/s
[Step=14450 Epoch=14.1] | Loss=0.08033 | Reg=0.00306 | acc=0.9688 | L2-Norm=17.476 | L2-Norm(final)=4.788 | 4285.7 samples/s | 67.0 steps/s
[Step=14500 Epoch=14.2] | Loss=0.07888 | Reg=0.00308 | acc=0.9688 | L2-Norm=17.553 | L2-Norm(final)=4.814 | 4299.8 samples/s | 67.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=14.2] | Loss=0.11522 | Reg=0.00335 | acc=0.9219 | L2-Norm=18.303 | L2-Norm(final)=5.096 | 3282.0 samples/s | 51.3 steps/s
[Step=14550 Epoch=14.2] | Loss=0.05689 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.361 | L2-Norm(final)=5.108 | 3740.6 samples/s | 58.4 steps/s
[Step=14600 Epoch=14.3] | Loss=0.05939 | Reg=0.00339 | acc=0.9062 | L2-Norm=18.425 | L2-Norm(final)=5.098 | 3870.6 samples/s | 60.5 steps/s
[Step=14650 Epoch=14.3] | Loss=0.05313 | Reg=0.00342 | acc=1.0000 | L2-Norm=18.484 | L2-Norm(final)=5.082 | 3942.5 samples/s | 61.6 steps/s
[Step=14700 Epoch=14.4] | Loss=0.05421 | Reg=0.00343 | acc=0.9688 | L2-Norm=18.526 | L2-Norm(final)=5.065 | 3928.4 samples/s | 61.4 steps/s
[Step=14750 Epoch=14.4] | Loss=0.05461 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.562 | L2-Norm(final)=5.047 | 3930.4 samples/s | 61.4 steps/s
[Step=14800 Epoch=14.4] | Loss=0.05258 | Reg=0.00346 | acc=0.9844 | L2-Norm=18.594 | L2-Norm(final)=5.031 | 3952.4 samples/s | 61.8 steps/s
[Step=14850 Epoch=14.5] | Loss=0.05166 | Reg=0.00347 | acc=0.9375 | L2-Norm=18.620 | L2-Norm(final)=5.018 | 3909.8 samples/s | 61.1 steps/s
[Step=14900 Epoch=14.5] | Loss=0.05094 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.643 | L2-Norm(final)=5.008 | 3966.7 samples/s | 62.0 steps/s
[Step=14950 Epoch=14.6] | Loss=0.05036 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.665 | L2-Norm(final)=4.999 | 3934.9 samples/s | 61.5 steps/s
[Step=15000 Epoch=14.6] | Loss=0.04941 | Reg=0.00349 | acc=0.9688 | L2-Norm=18.685 | L2-Norm(final)=4.992 | 3948.9 samples/s | 61.7 steps/s
[Step=15050 Epoch=14.7] | Loss=0.04824 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.704 | L2-Norm(final)=4.985 | 3944.7 samples/s | 61.6 steps/s
[Step=15100 Epoch=14.7] | Loss=0.04780 | Reg=0.00350 | acc=0.9688 | L2-Norm=18.720 | L2-Norm(final)=4.977 | 3948.6 samples/s | 61.7 steps/s
[Step=15150 Epoch=14.8] | Loss=0.04698 | Reg=0.00351 | acc=0.9531 | L2-Norm=18.736 | L2-Norm(final)=4.970 | 3936.3 samples/s | 61.5 steps/s
[Step=15200 Epoch=14.8] | Loss=0.04594 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.749 | L2-Norm(final)=4.962 | 3973.7 samples/s | 62.1 steps/s
[Step=15250 Epoch=14.9] | Loss=0.04515 | Reg=0.00352 | acc=0.9844 | L2-Norm=18.762 | L2-Norm(final)=4.955 | 3948.7 samples/s | 61.7 steps/s
[Step=15300 Epoch=14.9] | Loss=0.04416 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.775 | L2-Norm(final)=4.948 | 3940.3 samples/s | 61.6 steps/s
[Step=15350 Epoch=15.0] | Loss=0.04368 | Reg=0.00353 | acc=0.9375 | L2-Norm=18.786 | L2-Norm(final)=4.943 | 3942.2 samples/s | 61.6 steps/s
[Step=15400 Epoch=15.0] | Loss=0.04330 | Reg=0.00353 | acc=0.9844 | L2-Norm=18.798 | L2-Norm(final)=4.937 | 3988.8 samples/s | 62.3 steps/s
[Step=15450 Epoch=15.1] | Loss=0.04271 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.808 | L2-Norm(final)=4.931 | 3896.8 samples/s | 60.9 steps/s
[Step=15500 Epoch=15.1] | Loss=0.04284 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.819 | L2-Norm(final)=4.925 | 4262.9 samples/s | 66.6 steps/s
[Step=15550 Epoch=15.2] | Loss=0.04234 | Reg=0.00355 | acc=1.0000 | L2-Norm=18.829 | L2-Norm(final)=4.919 | 1633.1 samples/s | 25.5 steps/s
[Step=15600 Epoch=15.2] | Loss=0.04149 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.840 | L2-Norm(final)=4.914 | 3878.7 samples/s | 60.6 steps/s
[Step=15650 Epoch=15.3] | Loss=0.04102 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.850 | L2-Norm(final)=4.909 | 3915.6 samples/s | 61.2 steps/s
[Step=15700 Epoch=15.3] | Loss=0.04047 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.860 | L2-Norm(final)=4.905 | 3930.3 samples/s | 61.4 steps/s
[Step=15750 Epoch=15.4] | Loss=0.03997 | Reg=0.00356 | acc=0.9688 | L2-Norm=18.869 | L2-Norm(final)=4.901 | 3914.7 samples/s | 61.2 steps/s
[Step=15800 Epoch=15.4] | Loss=0.03964 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.879 | L2-Norm(final)=4.897 | 3903.5 samples/s | 61.0 steps/s
[Step=15850 Epoch=15.5] | Loss=0.03913 | Reg=0.00357 | acc=0.9688 | L2-Norm=18.888 | L2-Norm(final)=4.893 | 3961.8 samples/s | 61.9 steps/s
[Step=15900 Epoch=15.5] | Loss=0.03911 | Reg=0.00357 | acc=0.9688 | L2-Norm=18.897 | L2-Norm(final)=4.889 | 3918.8 samples/s | 61.2 steps/s
[Step=15950 Epoch=15.6] | Loss=0.03866 | Reg=0.00357 | acc=0.9531 | L2-Norm=18.906 | L2-Norm(final)=4.884 | 3921.8 samples/s | 61.3 steps/s
[Step=16000 Epoch=15.6] | Loss=0.03828 | Reg=0.00358 | acc=1.0000 | L2-Norm=18.916 | L2-Norm(final)=4.880 | 3938.7 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step16000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=14001 Epoch=26.4] | Loss=0.01549 | Reg=0.00271 | acc=0.9844 | L2-Norm=16.468 | L2-Norm(final)=3.833 | 3267.0 samples/s | 51.0 steps/s
[Step=14050 Epoch=26.5] | Loss=0.00240 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.468 | L2-Norm(final)=3.858 | 3808.4 samples/s | 59.5 steps/s
[Step=14100 Epoch=26.6] | Loss=0.00149 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.452 | L2-Norm(final)=3.881 | 4081.9 samples/s | 63.8 steps/s
[Step=14150 Epoch=26.7] | Loss=0.00109 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.425 | L2-Norm(final)=3.896 | 4180.7 samples/s | 65.3 steps/s
[Step=14200 Epoch=26.8] | Loss=0.00090 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.392 | L2-Norm(final)=3.912 | 4069.6 samples/s | 63.6 steps/s
[Step=14250 Epoch=26.9] | Loss=0.00082 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.361 | L2-Norm(final)=3.926 | 4112.9 samples/s | 64.3 steps/s
[Step=14300 Epoch=27.0] | Loss=0.00073 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.331 | L2-Norm(final)=3.939 | 4129.1 samples/s | 64.5 steps/s
[Step=14350 Epoch=27.0] | Loss=0.00067 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.304 | L2-Norm(final)=3.951 | 4090.3 samples/s | 63.9 steps/s
[Step=14400 Epoch=27.1] | Loss=0.00064 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.278 | L2-Norm(final)=3.963 | 4142.3 samples/s | 64.7 steps/s
[Step=14450 Epoch=27.2] | Loss=0.00064 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.258 | L2-Norm(final)=3.975 | 4140.6 samples/s | 64.7 steps/s
[Step=14500 Epoch=27.3] | Loss=0.00059 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.238 | L2-Norm(final)=3.986 | 4132.9 samples/s | 64.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=14501 Epoch=27.3] | Loss=0.00000 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.030 | L2-Norm(final)=4.096 | 3223.8 samples/s | 50.4 steps/s
[Step=14550 Epoch=27.4] | Loss=0.00008 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.994 | L2-Norm(final)=4.104 | 3464.0 samples/s | 54.1 steps/s
[Step=14600 Epoch=27.5] | Loss=0.00039 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=4.112 | 3749.7 samples/s | 58.6 steps/s
[Step=14650 Epoch=27.6] | Loss=0.00203 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.954 | L2-Norm(final)=4.113 | 3775.5 samples/s | 59.0 steps/s
[Step=14700 Epoch=27.7] | Loss=0.00635 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.071 | L2-Norm(final)=4.070 | 3697.3 samples/s | 57.8 steps/s
[Step=14750 Epoch=27.8] | Loss=0.00606 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.185 | L2-Norm(final)=4.034 | 3746.3 samples/s | 58.5 steps/s
[Step=14800 Epoch=27.9] | Loss=0.00577 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.267 | L2-Norm(final)=4.005 | 3697.9 samples/s | 57.8 steps/s
[Step=14850 Epoch=28.0] | Loss=0.00544 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.329 | L2-Norm(final)=3.983 | 3714.4 samples/s | 58.0 steps/s
[Step=14900 Epoch=28.1] | Loss=0.00491 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.372 | L2-Norm(final)=3.967 | 3775.9 samples/s | 59.0 steps/s
[Step=14950 Epoch=28.2] | Loss=0.00459 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.399 | L2-Norm(final)=3.955 | 3730.1 samples/s | 58.3 steps/s
[Step=15000 Epoch=28.3] | Loss=0.00421 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=3.946 | 3761.5 samples/s | 58.8 steps/s
[Step=15050 Epoch=28.4] | Loss=0.00384 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.425 | L2-Norm(final)=3.941 | 1670.9 samples/s | 26.1 steps/s
[Step=15100 Epoch=28.5] | Loss=0.00354 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.429 | L2-Norm(final)=3.937 | 3729.0 samples/s | 58.3 steps/s
[Step=15150 Epoch=28.6] | Loss=0.00328 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.428 | L2-Norm(final)=3.934 | 3736.3 samples/s | 58.4 steps/s
[Step=15200 Epoch=28.7] | Loss=0.00305 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.423 | L2-Norm(final)=3.931 | 3705.9 samples/s | 57.9 steps/s
[Step=15250 Epoch=28.7] | Loss=0.00289 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.415 | L2-Norm(final)=3.929 | 3753.0 samples/s | 58.6 steps/s
[Step=15300 Epoch=28.8] | Loss=0.00279 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.405 | L2-Norm(final)=3.927 | 3729.5 samples/s | 58.3 steps/s
[Step=15350 Epoch=28.9] | Loss=0.00263 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.393 | L2-Norm(final)=3.926 | 3779.6 samples/s | 59.1 steps/s
[Step=15400 Epoch=29.0] | Loss=0.00248 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.380 | L2-Norm(final)=3.925 | 3741.8 samples/s | 58.5 steps/s
[Step=15450 Epoch=29.1] | Loss=0.00235 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.365 | L2-Norm(final)=3.924 | 3735.6 samples/s | 58.4 steps/s
[Step=15500 Epoch=29.2] | Loss=0.00224 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.349 | L2-Norm(final)=3.923 | 3725.8 samples/s | 58.2 steps/s
[Step=15550 Epoch=29.3] | Loss=0.00213 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.331 | L2-Norm(final)=3.923 | 4728.6 samples/s | 73.9 steps/s
[Step=15600 Epoch=29.4] | Loss=0.00204 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.313 | L2-Norm(final)=3.922 | 1517.0 samples/s | 23.7 steps/s
[Step=15650 Epoch=29.5] | Loss=0.00195 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.294 | L2-Norm(final)=3.922 | 3738.9 samples/s | 58.4 steps/s
[Step=15700 Epoch=29.6] | Loss=0.00187 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.275 | L2-Norm(final)=3.923 | 3654.6 samples/s | 57.1 steps/s
[Step=15750 Epoch=29.7] | Loss=0.00180 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.254 | L2-Norm(final)=3.923 | 3672.4 samples/s | 57.4 steps/s
[Step=15800 Epoch=29.8] | Loss=0.00173 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.233 | L2-Norm(final)=3.923 | 3747.0 samples/s | 58.5 steps/s
[Step=15850 Epoch=29.9] | Loss=0.00167 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.212 | L2-Norm(final)=3.923 | 3713.4 samples/s | 58.0 steps/s
[Step=15900 Epoch=30.0] | Loss=0.00161 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.189 | L2-Norm(final)=3.924 | 3694.9 samples/s | 57.7 steps/s
[Step=15950 Epoch=30.1] | Loss=0.00155 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.167 | L2-Norm(final)=3.924 | 3741.1 samples/s | 58.5 steps/s
[Step=16000 Epoch=30.2] | Loss=0.00150 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.144 | L2-Norm(final)=3.924 | 3757.9 samples/s | 58.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step16000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05383 | acc=0.9646 | tpr=0.9643 | fpr=0.0347 | 3598.6 samples/s | 14.1 steps/s
Avg test loss: 0.05544, Avg test acc: 0.96290, Avg tpr: 0.96107, Avg fpr: 0.03307, total FA: 258

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.62244 | acc=0.3093 | tpr=0.0064 | fpr=0.0330 | 3623.2 samples/s | 14.2 steps/s
Avg test loss: 6.64749, Avg test acc: 0.30720, Avg tpr: 0.00659, Avg fpr: 0.03166, total FA: 247

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.07480 | acc=0.1534 | tpr=0.5265 | fpr=0.8533 | 3605.6 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.05306 | acc=0.1528 | tpr=0.5373 | fpr=0.8544 | 6996.1 samples/s | 27.3 steps/s
[Step= 150] | Loss=4.04750 | acc=0.1519 | tpr=0.5807 | fpr=0.8560 | 6816.2 samples/s | 26.6 steps/s
[Step= 200] | Loss=4.04094 | acc=0.1526 | tpr=0.5738 | fpr=0.8551 | 7090.9 samples/s | 27.7 steps/s
[Step= 250] | Loss=4.04978 | acc=0.1520 | tpr=0.5677 | fpr=0.8556 | 7008.7 samples/s | 27.4 steps/s
[Step= 300] | Loss=4.04981 | acc=0.1517 | tpr=0.5680 | fpr=0.8559 | 6625.6 samples/s | 25.9 steps/s
[Step= 350] | Loss=4.04699 | acc=0.1517 | tpr=0.5711 | fpr=0.8559 | 6849.6 samples/s | 26.8 steps/s
[Step= 400] | Loss=4.04937 | acc=0.1519 | tpr=0.5717 | fpr=0.8557 | 6792.2 samples/s | 26.5 steps/s
[Step= 450] | Loss=4.04788 | acc=0.1520 | tpr=0.5784 | fpr=0.8557 | 6895.6 samples/s | 26.9 steps/s
[Step= 500] | Loss=4.05085 | acc=0.1524 | tpr=0.5784 | fpr=0.8553 | 6551.3 samples/s | 25.6 steps/s
[Step= 550] | Loss=4.05330 | acc=0.1521 | tpr=0.5810 | fpr=0.8557 | 12777.2 samples/s | 49.9 steps/s
Avg test loss: 4.05524, Avg test acc: 0.15212, Avg tpr: 0.58162, Avg fpr: 0.85569, total FA: 118811

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10791 | acc=0.9838 | tpr=0.9646 | fpr=0.0159 | 3657.8 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.11420 | acc=0.9826 | tpr=0.9723 | fpr=0.0172 | 6588.2 samples/s | 25.7 steps/s
[Step= 150] | Loss=0.11851 | acc=0.9820 | tpr=0.9726 | fpr=0.0178 | 6947.7 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.12048 | acc=0.9819 | tpr=0.9716 | fpr=0.0179 | 6876.1 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.11765 | acc=0.9822 | tpr=0.9651 | fpr=0.0175 | 6922.3 samples/s | 27.0 steps/s
[Step= 300] | Loss=0.11968 | acc=0.9818 | tpr=0.9622 | fpr=0.0178 | 6856.8 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.12060 | acc=0.9815 | tpr=0.9624 | fpr=0.0182 | 6778.2 samples/s | 26.5 steps/s
[Step= 400] | Loss=0.12153 | acc=0.9813 | tpr=0.9606 | fpr=0.0184 | 6879.6 samples/s | 26.9 steps/s
[Step= 450] | Loss=0.12442 | acc=0.9809 | tpr=0.9572 | fpr=0.0187 | 6738.6 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.12356 | acc=0.9810 | tpr=0.9581 | fpr=0.0186 | 6976.5 samples/s | 27.3 steps/s
[Step= 550] | Loss=0.12255 | acc=0.9811 | tpr=0.9578 | fpr=0.0185 | 11694.0 samples/s | 45.7 steps/s
Avg test loss: 0.12221, Avg test acc: 0.98115, Avg tpr: 0.95800, Avg fpr: 0.01843, total FA: 2559

server round 8/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=15.6] | Loss=0.10719 | Reg=0.00269 | acc=0.9219 | L2-Norm=16.399 | L2-Norm(final)=4.762 | 3279.4 samples/s | 51.2 steps/s
[Step=16050 Epoch=15.7] | Loss=0.05966 | Reg=0.00274 | acc=0.9688 | L2-Norm=16.544 | L2-Norm(final)=4.802 | 4155.8 samples/s | 64.9 steps/s
[Step=16100 Epoch=15.7] | Loss=0.05778 | Reg=0.00278 | acc=0.9375 | L2-Norm=16.678 | L2-Norm(final)=4.833 | 4309.8 samples/s | 67.3 steps/s
[Step=16150 Epoch=15.8] | Loss=0.05702 | Reg=0.00282 | acc=0.9688 | L2-Norm=16.798 | L2-Norm(final)=4.856 | 4355.6 samples/s | 68.1 steps/s
[Step=16200 Epoch=15.8] | Loss=0.05818 | Reg=0.00286 | acc=0.9375 | L2-Norm=16.900 | L2-Norm(final)=4.871 | 4362.2 samples/s | 68.2 steps/s
[Step=16250 Epoch=15.9] | Loss=0.05721 | Reg=0.00289 | acc=0.9219 | L2-Norm=16.986 | L2-Norm(final)=4.885 | 4381.4 samples/s | 68.5 steps/s
[Step=16300 Epoch=15.9] | Loss=0.05619 | Reg=0.00291 | acc=0.9844 | L2-Norm=17.060 | L2-Norm(final)=4.901 | 4445.2 samples/s | 69.5 steps/s
[Step=16350 Epoch=16.0] | Loss=0.05575 | Reg=0.00293 | acc=0.9375 | L2-Norm=17.127 | L2-Norm(final)=4.918 | 4317.4 samples/s | 67.5 steps/s
[Step=16400 Epoch=16.0] | Loss=0.05416 | Reg=0.00296 | acc=0.9375 | L2-Norm=17.188 | L2-Norm(final)=4.936 | 4412.8 samples/s | 68.9 steps/s
[Step=16450 Epoch=16.1] | Loss=0.05274 | Reg=0.00298 | acc=1.0000 | L2-Norm=17.247 | L2-Norm(final)=4.955 | 4382.8 samples/s | 68.5 steps/s
[Step=16500 Epoch=16.1] | Loss=0.05212 | Reg=0.00300 | acc=0.9531 | L2-Norm=17.302 | L2-Norm(final)=4.973 | 4408.3 samples/s | 68.9 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=16.1] | Loss=0.03603 | Reg=0.00319 | acc=0.9688 | L2-Norm=17.852 | L2-Norm(final)=5.149 | 3269.9 samples/s | 51.1 steps/s
[Step=16550 Epoch=16.2] | Loss=0.04431 | Reg=0.00321 | acc=0.9531 | L2-Norm=17.913 | L2-Norm(final)=5.169 | 3825.2 samples/s | 59.8 steps/s
[Step=16600 Epoch=16.2] | Loss=0.04797 | Reg=0.00323 | acc=0.9531 | L2-Norm=17.978 | L2-Norm(final)=5.154 | 3949.4 samples/s | 61.7 steps/s
[Step=16650 Epoch=16.3] | Loss=0.04802 | Reg=0.00325 | acc=0.9688 | L2-Norm=18.033 | L2-Norm(final)=5.145 | 3938.1 samples/s | 61.5 steps/s
[Step=16700 Epoch=16.3] | Loss=0.04724 | Reg=0.00327 | acc=0.9688 | L2-Norm=18.085 | L2-Norm(final)=5.134 | 3950.5 samples/s | 61.7 steps/s
[Step=16750 Epoch=16.4] | Loss=0.04650 | Reg=0.00329 | acc=0.9688 | L2-Norm=18.126 | L2-Norm(final)=5.124 | 3918.7 samples/s | 61.2 steps/s
[Step=16800 Epoch=16.4] | Loss=0.04567 | Reg=0.00330 | acc=1.0000 | L2-Norm=18.163 | L2-Norm(final)=5.115 | 3964.0 samples/s | 61.9 steps/s
[Step=16850 Epoch=16.5] | Loss=0.04445 | Reg=0.00331 | acc=0.9844 | L2-Norm=18.196 | L2-Norm(final)=5.107 | 3952.9 samples/s | 61.8 steps/s
[Step=16900 Epoch=16.5] | Loss=0.04411 | Reg=0.00332 | acc=0.9688 | L2-Norm=18.227 | L2-Norm(final)=5.097 | 3959.4 samples/s | 61.9 steps/s
[Step=16950 Epoch=16.5] | Loss=0.04347 | Reg=0.00333 | acc=0.9844 | L2-Norm=18.257 | L2-Norm(final)=5.088 | 3827.6 samples/s | 59.8 steps/s
[Step=17000 Epoch=16.6] | Loss=0.04303 | Reg=0.00334 | acc=1.0000 | L2-Norm=18.284 | L2-Norm(final)=5.080 | 3832.7 samples/s | 59.9 steps/s
[Step=17050 Epoch=16.6] | Loss=0.04223 | Reg=0.00335 | acc=0.9688 | L2-Norm=18.312 | L2-Norm(final)=5.074 | 3837.7 samples/s | 60.0 steps/s
[Step=17100 Epoch=16.7] | Loss=0.04185 | Reg=0.00336 | acc=1.0000 | L2-Norm=18.338 | L2-Norm(final)=5.068 | 3868.9 samples/s | 60.5 steps/s
[Step=17150 Epoch=16.7] | Loss=0.04154 | Reg=0.00337 | acc=0.9531 | L2-Norm=18.363 | L2-Norm(final)=5.062 | 3980.7 samples/s | 62.2 steps/s
[Step=17200 Epoch=16.8] | Loss=0.04100 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.386 | L2-Norm(final)=5.056 | 3969.6 samples/s | 62.0 steps/s
[Step=17250 Epoch=16.8] | Loss=0.04033 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.408 | L2-Norm(final)=5.051 | 3944.8 samples/s | 61.6 steps/s
[Step=17300 Epoch=16.9] | Loss=0.03995 | Reg=0.00340 | acc=0.9844 | L2-Norm=18.430 | L2-Norm(final)=5.046 | 3961.2 samples/s | 61.9 steps/s
[Step=17350 Epoch=16.9] | Loss=0.03961 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.451 | L2-Norm(final)=5.041 | 3999.3 samples/s | 62.5 steps/s
[Step=17400 Epoch=17.0] | Loss=0.03957 | Reg=0.00341 | acc=0.9844 | L2-Norm=18.472 | L2-Norm(final)=5.036 | 3918.8 samples/s | 61.2 steps/s
[Step=17450 Epoch=17.0] | Loss=0.03912 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.491 | L2-Norm(final)=5.031 | 3953.2 samples/s | 61.8 steps/s
[Step=17500 Epoch=17.1] | Loss=0.03881 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.511 | L2-Norm(final)=5.026 | 4311.3 samples/s | 67.4 steps/s
[Step=17550 Epoch=17.1] | Loss=0.03846 | Reg=0.00343 | acc=0.9844 | L2-Norm=18.530 | L2-Norm(final)=5.022 | 1664.6 samples/s | 26.0 steps/s
[Step=17600 Epoch=17.2] | Loss=0.03790 | Reg=0.00344 | acc=0.9531 | L2-Norm=18.548 | L2-Norm(final)=5.017 | 3950.1 samples/s | 61.7 steps/s
[Step=17650 Epoch=17.2] | Loss=0.03722 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.566 | L2-Norm(final)=5.013 | 3889.5 samples/s | 60.8 steps/s
[Step=17700 Epoch=17.3] | Loss=0.03710 | Reg=0.00345 | acc=0.9688 | L2-Norm=18.582 | L2-Norm(final)=5.009 | 3926.8 samples/s | 61.4 steps/s
[Step=17750 Epoch=17.3] | Loss=0.03670 | Reg=0.00346 | acc=0.9688 | L2-Norm=18.599 | L2-Norm(final)=5.005 | 3926.0 samples/s | 61.3 steps/s
[Step=17800 Epoch=17.4] | Loss=0.03634 | Reg=0.00347 | acc=0.9844 | L2-Norm=18.615 | L2-Norm(final)=5.001 | 3927.4 samples/s | 61.4 steps/s
[Step=17850 Epoch=17.4] | Loss=0.03587 | Reg=0.00347 | acc=0.9688 | L2-Norm=18.630 | L2-Norm(final)=4.998 | 3988.0 samples/s | 62.3 steps/s
[Step=17900 Epoch=17.5] | Loss=0.03539 | Reg=0.00348 | acc=0.9688 | L2-Norm=18.645 | L2-Norm(final)=4.994 | 3906.7 samples/s | 61.0 steps/s
[Step=17950 Epoch=17.5] | Loss=0.03531 | Reg=0.00348 | acc=0.9531 | L2-Norm=18.659 | L2-Norm(final)=4.991 | 3960.0 samples/s | 61.9 steps/s
[Step=18000 Epoch=17.6] | Loss=0.03506 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.673 | L2-Norm(final)=4.987 | 3978.3 samples/s | 62.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step18000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=16001 Epoch=30.2] | Loss=0.00184 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.399 | L2-Norm(final)=3.936 | 3332.6 samples/s | 52.1 steps/s
[Step=16050 Epoch=30.3] | Loss=0.00145 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=3.956 | 4041.4 samples/s | 63.1 steps/s
[Step=16100 Epoch=30.3] | Loss=0.00145 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.347 | L2-Norm(final)=3.981 | 4100.2 samples/s | 64.1 steps/s
[Step=16150 Epoch=30.4] | Loss=0.00138 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.351 | L2-Norm(final)=3.995 | 4131.8 samples/s | 64.6 steps/s
[Step=16200 Epoch=30.5] | Loss=0.00146 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=4.007 | 4096.4 samples/s | 64.0 steps/s
[Step=16250 Epoch=30.6] | Loss=0.00143 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=4.015 | 4109.6 samples/s | 64.2 steps/s
[Step=16300 Epoch=30.7] | Loss=0.00126 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.360 | L2-Norm(final)=4.022 | 4111.3 samples/s | 64.2 steps/s
[Step=16350 Epoch=30.8] | Loss=0.00114 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.352 | L2-Norm(final)=4.028 | 4191.4 samples/s | 65.5 steps/s
[Step=16400 Epoch=30.9] | Loss=0.00102 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.339 | L2-Norm(final)=4.035 | 4101.6 samples/s | 64.1 steps/s
[Step=16450 Epoch=31.0] | Loss=0.00093 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.322 | L2-Norm(final)=4.042 | 4113.1 samples/s | 64.3 steps/s
[Step=16500 Epoch=31.1] | Loss=0.00086 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.306 | L2-Norm(final)=4.050 | 4170.9 samples/s | 65.2 steps/s
All layers training...
LR=0.00100, len=1
[Step=16501 Epoch=31.1] | Loss=0.00009 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.142 | L2-Norm(final)=4.125 | 3642.8 samples/s | 56.9 steps/s
[Step=16550 Epoch=31.2] | Loss=0.00004 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.104 | L2-Norm(final)=4.130 | 3267.3 samples/s | 51.1 steps/s
[Step=16600 Epoch=31.3] | Loss=0.00254 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.084 | L2-Norm(final)=4.132 | 3749.5 samples/s | 58.6 steps/s
[Step=16650 Epoch=31.4] | Loss=0.00597 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.215 | L2-Norm(final)=4.097 | 3739.4 samples/s | 58.4 steps/s
[Step=16700 Epoch=31.5] | Loss=0.00589 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.355 | L2-Norm(final)=4.058 | 3675.8 samples/s | 57.4 steps/s
[Step=16750 Epoch=31.6] | Loss=0.00575 | Reg=0.00271 | acc=1.0000 | L2-Norm=16.452 | L2-Norm(final)=4.038 | 3697.0 samples/s | 57.8 steps/s
[Step=16800 Epoch=31.7] | Loss=0.00514 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.528 | L2-Norm(final)=4.025 | 3762.0 samples/s | 58.8 steps/s
[Step=16850 Epoch=31.8] | Loss=0.00478 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.581 | L2-Norm(final)=4.017 | 3724.3 samples/s | 58.2 steps/s
[Step=16900 Epoch=31.9] | Loss=0.00459 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.623 | L2-Norm(final)=4.012 | 3713.8 samples/s | 58.0 steps/s
[Step=16950 Epoch=32.0] | Loss=0.00452 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.661 | L2-Norm(final)=4.008 | 3743.8 samples/s | 58.5 steps/s
[Step=17000 Epoch=32.0] | Loss=0.00422 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.692 | L2-Norm(final)=4.005 | 3756.2 samples/s | 58.7 steps/s
[Step=17050 Epoch=32.1] | Loss=0.00390 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.715 | L2-Norm(final)=4.003 | 1666.6 samples/s | 26.0 steps/s
[Step=17100 Epoch=32.2] | Loss=0.00361 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.731 | L2-Norm(final)=4.002 | 3728.7 samples/s | 58.3 steps/s
[Step=17150 Epoch=32.3] | Loss=0.00334 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.741 | L2-Norm(final)=4.002 | 3729.2 samples/s | 58.3 steps/s
[Step=17200 Epoch=32.4] | Loss=0.00310 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.745 | L2-Norm(final)=4.003 | 3704.6 samples/s | 57.9 steps/s
[Step=17250 Epoch=32.5] | Loss=0.00291 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.744 | L2-Norm(final)=4.003 | 3748.4 samples/s | 58.6 steps/s
[Step=17300 Epoch=32.6] | Loss=0.00273 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.741 | L2-Norm(final)=4.004 | 3722.2 samples/s | 58.2 steps/s
[Step=17350 Epoch=32.7] | Loss=0.00257 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.735 | L2-Norm(final)=4.005 | 3647.0 samples/s | 57.0 steps/s
[Step=17400 Epoch=32.8] | Loss=0.00244 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.726 | L2-Norm(final)=4.006 | 3764.4 samples/s | 58.8 steps/s
[Step=17450 Epoch=32.9] | Loss=0.00231 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.716 | L2-Norm(final)=4.007 | 3710.1 samples/s | 58.0 steps/s
[Step=17500 Epoch=33.0] | Loss=0.00221 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.704 | L2-Norm(final)=4.009 | 3740.4 samples/s | 58.4 steps/s
[Step=17550 Epoch=33.1] | Loss=0.00213 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.691 | L2-Norm(final)=4.010 | 4588.8 samples/s | 71.7 steps/s
[Step=17600 Epoch=33.2] | Loss=0.00206 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.680 | L2-Norm(final)=4.011 | 1536.6 samples/s | 24.0 steps/s
[Step=17650 Epoch=33.3] | Loss=0.00200 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.668 | L2-Norm(final)=4.012 | 3663.4 samples/s | 57.2 steps/s
[Step=17700 Epoch=33.4] | Loss=0.00195 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.658 | L2-Norm(final)=4.013 | 3639.9 samples/s | 56.9 steps/s
[Step=17750 Epoch=33.5] | Loss=0.00215 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.651 | L2-Norm(final)=4.013 | 3702.9 samples/s | 57.9 steps/s
[Step=17800 Epoch=33.6] | Loss=0.00221 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.651 | L2-Norm(final)=4.010 | 3727.9 samples/s | 58.2 steps/s
[Step=17850 Epoch=33.6] | Loss=0.00229 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.653 | L2-Norm(final)=4.006 | 3729.7 samples/s | 58.3 steps/s
[Step=17900 Epoch=33.7] | Loss=0.00232 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.656 | L2-Norm(final)=4.001 | 3742.2 samples/s | 58.5 steps/s
[Step=17950 Epoch=33.8] | Loss=0.00225 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.658 | L2-Norm(final)=3.996 | 3652.7 samples/s | 57.1 steps/s
[Step=18000 Epoch=33.9] | Loss=0.00226 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.659 | L2-Norm(final)=3.992 | 3713.4 samples/s | 58.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step18000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05246 | acc=0.9680 | tpr=0.9752 | fpr=0.0478 | 3609.1 samples/s | 14.1 steps/s
Avg test loss: 0.05289, Avg test acc: 0.96710, Avg tpr: 0.97389, Avg fpr: 0.04781, total FA: 373

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.04946 | acc=0.3024 | tpr=0.0143 | fpr=0.0719 | 3595.7 samples/s | 14.0 steps/s
Avg test loss: 5.06797, Avg test acc: 0.30058, Avg tpr: 0.01341, Avg fpr: 0.06781, total FA: 529

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.11871 | acc=0.1384 | tpr=0.7257 | fpr=0.8722 | 3587.2 samples/s | 14.0 steps/s
[Step= 100] | Loss=5.10278 | acc=0.1391 | tpr=0.7100 | fpr=0.8716 | 6764.1 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.09989 | acc=0.1387 | tpr=0.7305 | fpr=0.8722 | 6828.0 samples/s | 26.7 steps/s
[Step= 200] | Loss=5.09285 | acc=0.1377 | tpr=0.7224 | fpr=0.8729 | 7123.5 samples/s | 27.8 steps/s
[Step= 250] | Loss=5.10163 | acc=0.1381 | tpr=0.7258 | fpr=0.8726 | 6912.9 samples/s | 27.0 steps/s
[Step= 300] | Loss=5.09654 | acc=0.1380 | tpr=0.7287 | fpr=0.8727 | 6575.6 samples/s | 25.7 steps/s
[Step= 350] | Loss=5.09483 | acc=0.1379 | tpr=0.7251 | fpr=0.8728 | 6920.9 samples/s | 27.0 steps/s
[Step= 400] | Loss=5.10023 | acc=0.1382 | tpr=0.7172 | fpr=0.8723 | 6814.3 samples/s | 26.6 steps/s
[Step= 450] | Loss=5.09974 | acc=0.1385 | tpr=0.7201 | fpr=0.8721 | 6690.4 samples/s | 26.1 steps/s
[Step= 500] | Loss=5.10165 | acc=0.1389 | tpr=0.7229 | fpr=0.8716 | 6889.2 samples/s | 26.9 steps/s
[Step= 550] | Loss=5.10481 | acc=0.1389 | tpr=0.7262 | fpr=0.8718 | 12504.1 samples/s | 48.8 steps/s
Avg test loss: 5.10634, Avg test acc: 0.13887, Avg tpr: 0.72623, Avg fpr: 0.87180, total FA: 121048

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08917 | acc=0.9827 | tpr=0.9735 | fpr=0.0172 | 3650.4 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.09505 | acc=0.9811 | tpr=0.9829 | fpr=0.0189 | 6870.5 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.09800 | acc=0.9802 | tpr=0.9813 | fpr=0.0199 | 6910.6 samples/s | 27.0 steps/s
[Step= 200] | Loss=0.09838 | acc=0.9806 | tpr=0.9803 | fpr=0.0194 | 6729.3 samples/s | 26.3 steps/s
[Step= 250] | Loss=0.09741 | acc=0.9805 | tpr=0.9782 | fpr=0.0195 | 6842.5 samples/s | 26.7 steps/s
[Step= 300] | Loss=0.09927 | acc=0.9801 | tpr=0.9775 | fpr=0.0198 | 6771.3 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.09993 | acc=0.9799 | tpr=0.9775 | fpr=0.0200 | 7183.7 samples/s | 28.1 steps/s
[Step= 400] | Loss=0.10096 | acc=0.9797 | tpr=0.9770 | fpr=0.0203 | 6590.8 samples/s | 25.7 steps/s
[Step= 450] | Loss=0.10291 | acc=0.9794 | tpr=0.9752 | fpr=0.0205 | 6835.9 samples/s | 26.7 steps/s
[Step= 500] | Loss=0.10234 | acc=0.9794 | tpr=0.9753 | fpr=0.0205 | 6790.1 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.10159 | acc=0.9795 | tpr=0.9749 | fpr=0.0204 | 12630.5 samples/s | 49.3 steps/s
Avg test loss: 0.10138, Avg test acc: 0.97954, Avg tpr: 0.97504, Avg fpr: 0.02038, total FA: 2830

server round 9/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=17.6] | Loss=0.12654 | Reg=0.00281 | acc=0.9062 | L2-Norm=16.777 | L2-Norm(final)=4.894 | 3308.0 samples/s | 51.7 steps/s
[Step=18050 Epoch=17.6] | Loss=0.08572 | Reg=0.00285 | acc=0.9531 | L2-Norm=16.877 | L2-Norm(final)=4.937 | 3954.3 samples/s | 61.8 steps/s
[Step=18100 Epoch=17.7] | Loss=0.08336 | Reg=0.00288 | acc=0.9062 | L2-Norm=16.976 | L2-Norm(final)=4.975 | 4373.2 samples/s | 68.3 steps/s
[Step=18150 Epoch=17.7] | Loss=0.08189 | Reg=0.00291 | acc=0.8594 | L2-Norm=17.069 | L2-Norm(final)=5.009 | 4329.8 samples/s | 67.7 steps/s
[Step=18200 Epoch=17.8] | Loss=0.07951 | Reg=0.00294 | acc=0.9531 | L2-Norm=17.159 | L2-Norm(final)=5.043 | 4384.6 samples/s | 68.5 steps/s
[Step=18250 Epoch=17.8] | Loss=0.07692 | Reg=0.00297 | acc=0.9375 | L2-Norm=17.237 | L2-Norm(final)=5.074 | 4353.9 samples/s | 68.0 steps/s
[Step=18300 Epoch=17.9] | Loss=0.07516 | Reg=0.00300 | acc=0.8906 | L2-Norm=17.308 | L2-Norm(final)=5.103 | 4398.1 samples/s | 68.7 steps/s
[Step=18350 Epoch=17.9] | Loss=0.07386 | Reg=0.00302 | acc=0.9844 | L2-Norm=17.376 | L2-Norm(final)=5.132 | 4373.0 samples/s | 68.3 steps/s
[Step=18400 Epoch=18.0] | Loss=0.07247 | Reg=0.00304 | acc=0.9844 | L2-Norm=17.439 | L2-Norm(final)=5.158 | 4374.4 samples/s | 68.3 steps/s
[Step=18450 Epoch=18.0] | Loss=0.07139 | Reg=0.00306 | acc=0.9375 | L2-Norm=17.499 | L2-Norm(final)=5.183 | 4402.2 samples/s | 68.8 steps/s
[Step=18500 Epoch=18.1] | Loss=0.07071 | Reg=0.00308 | acc=0.9688 | L2-Norm=17.558 | L2-Norm(final)=5.209 | 4396.9 samples/s | 68.7 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=18.1] | Loss=0.05216 | Reg=0.00329 | acc=0.9688 | L2-Norm=18.151 | L2-Norm(final)=5.480 | 3257.4 samples/s | 50.9 steps/s
[Step=18550 Epoch=18.1] | Loss=0.05757 | Reg=0.00332 | acc=0.9844 | L2-Norm=18.226 | L2-Norm(final)=5.496 | 3765.8 samples/s | 58.8 steps/s
[Step=18600 Epoch=18.2] | Loss=0.05627 | Reg=0.00335 | acc=0.9531 | L2-Norm=18.311 | L2-Norm(final)=5.476 | 3840.0 samples/s | 60.0 steps/s
[Step=18650 Epoch=18.2] | Loss=0.05269 | Reg=0.00338 | acc=0.9844 | L2-Norm=18.376 | L2-Norm(final)=5.456 | 3883.8 samples/s | 60.7 steps/s
[Step=18700 Epoch=18.3] | Loss=0.04978 | Reg=0.00339 | acc=0.9844 | L2-Norm=18.425 | L2-Norm(final)=5.443 | 3951.5 samples/s | 61.7 steps/s
[Step=18750 Epoch=18.3] | Loss=0.04912 | Reg=0.00341 | acc=0.9531 | L2-Norm=18.467 | L2-Norm(final)=5.431 | 3984.3 samples/s | 62.3 steps/s
[Step=18800 Epoch=18.4] | Loss=0.04786 | Reg=0.00342 | acc=0.9844 | L2-Norm=18.505 | L2-Norm(final)=5.422 | 3962.1 samples/s | 61.9 steps/s
[Step=18850 Epoch=18.4] | Loss=0.04660 | Reg=0.00344 | acc=0.9375 | L2-Norm=18.539 | L2-Norm(final)=5.414 | 3932.6 samples/s | 61.4 steps/s
[Step=18900 Epoch=18.5] | Loss=0.04539 | Reg=0.00345 | acc=0.9844 | L2-Norm=18.569 | L2-Norm(final)=5.408 | 3965.1 samples/s | 62.0 steps/s
[Step=18950 Epoch=18.5] | Loss=0.04461 | Reg=0.00346 | acc=0.9531 | L2-Norm=18.596 | L2-Norm(final)=5.401 | 3985.4 samples/s | 62.3 steps/s
[Step=19000 Epoch=18.6] | Loss=0.04418 | Reg=0.00347 | acc=1.0000 | L2-Norm=18.621 | L2-Norm(final)=5.393 | 3929.3 samples/s | 61.4 steps/s
[Step=19050 Epoch=18.6] | Loss=0.04366 | Reg=0.00348 | acc=0.9844 | L2-Norm=18.645 | L2-Norm(final)=5.384 | 3959.6 samples/s | 61.9 steps/s
[Step=19100 Epoch=18.6] | Loss=0.04355 | Reg=0.00349 | acc=0.9844 | L2-Norm=18.667 | L2-Norm(final)=5.375 | 3924.2 samples/s | 61.3 steps/s
[Step=19150 Epoch=18.7] | Loss=0.04305 | Reg=0.00349 | acc=1.0000 | L2-Norm=18.689 | L2-Norm(final)=5.368 | 3940.8 samples/s | 61.6 steps/s
[Step=19200 Epoch=18.7] | Loss=0.04242 | Reg=0.00350 | acc=1.0000 | L2-Norm=18.711 | L2-Norm(final)=5.359 | 3971.2 samples/s | 62.0 steps/s
[Step=19250 Epoch=18.8] | Loss=0.04178 | Reg=0.00351 | acc=0.9531 | L2-Norm=18.730 | L2-Norm(final)=5.352 | 3897.1 samples/s | 60.9 steps/s
[Step=19300 Epoch=18.8] | Loss=0.04121 | Reg=0.00352 | acc=0.9688 | L2-Norm=18.749 | L2-Norm(final)=5.345 | 3946.2 samples/s | 61.7 steps/s
[Step=19350 Epoch=18.9] | Loss=0.04086 | Reg=0.00352 | acc=0.9688 | L2-Norm=18.767 | L2-Norm(final)=5.338 | 3907.9 samples/s | 61.1 steps/s
[Step=19400 Epoch=18.9] | Loss=0.04070 | Reg=0.00353 | acc=1.0000 | L2-Norm=18.785 | L2-Norm(final)=5.332 | 3949.0 samples/s | 61.7 steps/s
[Step=19450 Epoch=19.0] | Loss=0.04012 | Reg=0.00354 | acc=0.9531 | L2-Norm=18.804 | L2-Norm(final)=5.326 | 3933.6 samples/s | 61.5 steps/s
[Step=19500 Epoch=19.0] | Loss=0.03969 | Reg=0.00354 | acc=0.9844 | L2-Norm=18.822 | L2-Norm(final)=5.320 | 4265.8 samples/s | 66.7 steps/s
[Step=19550 Epoch=19.1] | Loss=0.03905 | Reg=0.00355 | acc=0.9844 | L2-Norm=18.840 | L2-Norm(final)=5.315 | 1655.7 samples/s | 25.9 steps/s
[Step=19600 Epoch=19.1] | Loss=0.03843 | Reg=0.00356 | acc=0.9844 | L2-Norm=18.858 | L2-Norm(final)=5.310 | 3843.0 samples/s | 60.0 steps/s
[Step=19650 Epoch=19.2] | Loss=0.03782 | Reg=0.00356 | acc=1.0000 | L2-Norm=18.874 | L2-Norm(final)=5.305 | 3917.7 samples/s | 61.2 steps/s
[Step=19700 Epoch=19.2] | Loss=0.03719 | Reg=0.00357 | acc=1.0000 | L2-Norm=18.891 | L2-Norm(final)=5.301 | 3964.4 samples/s | 61.9 steps/s
[Step=19750 Epoch=19.3] | Loss=0.03686 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.908 | L2-Norm(final)=5.297 | 3943.2 samples/s | 61.6 steps/s
[Step=19800 Epoch=19.3] | Loss=0.03662 | Reg=0.00358 | acc=0.9844 | L2-Norm=18.925 | L2-Norm(final)=5.293 | 3949.9 samples/s | 61.7 steps/s
[Step=19850 Epoch=19.4] | Loss=0.03639 | Reg=0.00359 | acc=0.9688 | L2-Norm=18.941 | L2-Norm(final)=5.288 | 3912.2 samples/s | 61.1 steps/s
[Step=19900 Epoch=19.4] | Loss=0.03601 | Reg=0.00359 | acc=0.9688 | L2-Norm=18.957 | L2-Norm(final)=5.284 | 3934.7 samples/s | 61.5 steps/s
[Step=19950 Epoch=19.5] | Loss=0.03567 | Reg=0.00360 | acc=0.9844 | L2-Norm=18.973 | L2-Norm(final)=5.279 | 3959.8 samples/s | 61.9 steps/s
[Step=20000 Epoch=19.5] | Loss=0.03543 | Reg=0.00361 | acc=0.9688 | L2-Norm=18.988 | L2-Norm(final)=5.275 | 3923.6 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step20000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00100, len=1
[Step=18001 Epoch=33.9] | Loss=0.00485 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.777 | L2-Norm(final)=3.858 | 3154.1 samples/s | 49.3 steps/s
[Step=18050 Epoch=34.0] | Loss=0.00208 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.727 | L2-Norm(final)=3.875 | 3931.3 samples/s | 61.4 steps/s
[Step=18100 Epoch=34.1] | Loss=0.00146 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.704 | L2-Norm(final)=3.896 | 4138.8 samples/s | 64.7 steps/s
[Step=18150 Epoch=34.2] | Loss=0.00123 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.681 | L2-Norm(final)=3.914 | 4126.1 samples/s | 64.5 steps/s
[Step=18200 Epoch=34.3] | Loss=0.00098 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.660 | L2-Norm(final)=3.928 | 4069.9 samples/s | 63.6 steps/s
[Step=18250 Epoch=34.4] | Loss=0.00096 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=3.942 | 4155.0 samples/s | 64.9 steps/s
[Step=18300 Epoch=34.5] | Loss=0.00084 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.627 | L2-Norm(final)=3.955 | 4089.1 samples/s | 63.9 steps/s
[Step=18350 Epoch=34.6] | Loss=0.00076 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.612 | L2-Norm(final)=3.966 | 4158.3 samples/s | 65.0 steps/s
[Step=18400 Epoch=34.7] | Loss=0.00069 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.595 | L2-Norm(final)=3.978 | 4059.9 samples/s | 63.4 steps/s
[Step=18450 Epoch=34.8] | Loss=0.00064 | Reg=0.00275 | acc=1.0000 | L2-Norm=16.578 | L2-Norm(final)=3.988 | 4067.5 samples/s | 63.6 steps/s
[Step=18500 Epoch=34.9] | Loss=0.00060 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.561 | L2-Norm(final)=3.998 | 4259.5 samples/s | 66.6 steps/s
All layers training...
LR=0.00100, len=1
[Step=18501 Epoch=34.9] | Loss=0.00005 | Reg=0.00269 | acc=1.0000 | L2-Norm=16.399 | L2-Norm(final)=4.100 | 3322.9 samples/s | 51.9 steps/s
[Step=18550 Epoch=35.0] | Loss=0.00009 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.380 | L2-Norm(final)=4.109 | 3331.7 samples/s | 52.1 steps/s
[Step=18600 Epoch=35.1] | Loss=0.00005 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.344 | L2-Norm(final)=4.113 | 3728.7 samples/s | 58.3 steps/s
[Step=18650 Epoch=35.2] | Loss=0.00005 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=4.116 | 3717.9 samples/s | 58.1 steps/s
[Step=18700 Epoch=35.2] | Loss=0.00005 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.271 | L2-Norm(final)=4.120 | 3737.2 samples/s | 58.4 steps/s
[Step=18750 Epoch=35.3] | Loss=0.00005 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.240 | L2-Norm(final)=4.123 | 3660.2 samples/s | 57.2 steps/s
[Step=18800 Epoch=35.4] | Loss=0.00004 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.207 | L2-Norm(final)=4.126 | 3693.3 samples/s | 57.7 steps/s
[Step=18850 Epoch=35.5] | Loss=0.00004 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.174 | L2-Norm(final)=4.129 | 3765.9 samples/s | 58.8 steps/s
[Step=18900 Epoch=35.6] | Loss=0.00004 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.140 | L2-Norm(final)=4.131 | 3669.4 samples/s | 57.3 steps/s
[Step=18950 Epoch=35.7] | Loss=0.00004 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.107 | L2-Norm(final)=4.133 | 3716.2 samples/s | 58.1 steps/s
[Step=19000 Epoch=35.8] | Loss=0.00005 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.075 | L2-Norm(final)=4.135 | 3715.1 samples/s | 58.0 steps/s
[Step=19050 Epoch=35.9] | Loss=0.00004 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.045 | L2-Norm(final)=4.138 | 1653.5 samples/s | 25.8 steps/s
[Step=19100 Epoch=36.0] | Loss=0.00004 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.016 | L2-Norm(final)=4.140 | 3733.5 samples/s | 58.3 steps/s
[Step=19150 Epoch=36.1] | Loss=0.00004 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.986 | L2-Norm(final)=4.142 | 3749.6 samples/s | 58.6 steps/s
[Step=19200 Epoch=36.2] | Loss=0.00004 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.955 | L2-Norm(final)=4.144 | 3728.2 samples/s | 58.3 steps/s
[Step=19250 Epoch=36.3] | Loss=0.00003 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.924 | L2-Norm(final)=4.146 | 3674.5 samples/s | 57.4 steps/s
[Step=19300 Epoch=36.4] | Loss=0.00003 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.893 | L2-Norm(final)=4.147 | 3694.9 samples/s | 57.7 steps/s
[Step=19350 Epoch=36.5] | Loss=0.00003 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.862 | L2-Norm(final)=4.149 | 3726.6 samples/s | 58.2 steps/s
[Step=19400 Epoch=36.6] | Loss=0.00003 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.831 | L2-Norm(final)=4.150 | 3693.2 samples/s | 57.7 steps/s
[Step=19450 Epoch=36.7] | Loss=0.00003 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.800 | L2-Norm(final)=4.152 | 3751.4 samples/s | 58.6 steps/s
[Step=19500 Epoch=36.8] | Loss=0.00003 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.769 | L2-Norm(final)=4.153 | 3714.2 samples/s | 58.0 steps/s
[Step=19550 Epoch=36.9] | Loss=0.00003 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.738 | L2-Norm(final)=4.154 | 4696.0 samples/s | 73.4 steps/s
[Step=19600 Epoch=36.9] | Loss=0.00003 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.707 | L2-Norm(final)=4.156 | 1524.5 samples/s | 23.8 steps/s
[Step=19650 Epoch=37.0] | Loss=0.00002 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.676 | L2-Norm(final)=4.157 | 3774.4 samples/s | 59.0 steps/s
[Step=19700 Epoch=37.1] | Loss=0.00002 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.644 | L2-Norm(final)=4.158 | 3771.3 samples/s | 58.9 steps/s
[Step=19750 Epoch=37.2] | Loss=0.00002 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.613 | L2-Norm(final)=4.159 | 3657.4 samples/s | 57.1 steps/s
[Step=19800 Epoch=37.3] | Loss=0.00002 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.582 | L2-Norm(final)=4.160 | 3761.9 samples/s | 58.8 steps/s
[Step=19850 Epoch=37.4] | Loss=0.00002 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=4.161 | 3728.0 samples/s | 58.2 steps/s
[Step=19900 Epoch=37.5] | Loss=0.00002 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.520 | L2-Norm(final)=4.162 | 3754.6 samples/s | 58.7 steps/s
[Step=19950 Epoch=37.6] | Loss=0.00002 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.489 | L2-Norm(final)=4.163 | 3765.0 samples/s | 58.8 steps/s
[Step=20000 Epoch=37.7] | Loss=0.00002 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.458 | L2-Norm(final)=4.164 | 3700.9 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step20000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05550 | acc=0.9638 | tpr=0.9651 | fpr=0.0389 | 3655.3 samples/s | 14.3 steps/s
Avg test loss: 0.05524, Avg test acc: 0.96306, Avg tpr: 0.96334, Avg fpr: 0.03756, total FA: 293

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.20530 | acc=0.3045 | tpr=0.0152 | fpr=0.0671 | 3617.9 samples/s | 14.1 steps/s
Avg test loss: 6.21086, Avg test acc: 0.30339, Avg tpr: 0.01527, Avg fpr: 0.06294, total FA: 491

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.15030 | acc=0.1405 | tpr=0.7655 | fpr=0.8707 | 3641.2 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.14789 | acc=0.1415 | tpr=0.7633 | fpr=0.8701 | 6790.9 samples/s | 26.5 steps/s
[Step= 150] | Loss=4.14611 | acc=0.1397 | tpr=0.7695 | fpr=0.8719 | 6997.7 samples/s | 27.3 steps/s
[Step= 200] | Loss=4.13345 | acc=0.1406 | tpr=0.7672 | fpr=0.8708 | 6805.6 samples/s | 26.6 steps/s
[Step= 250] | Loss=4.13512 | acc=0.1404 | tpr=0.7668 | fpr=0.8710 | 6982.2 samples/s | 27.3 steps/s
[Step= 300] | Loss=4.13071 | acc=0.1403 | tpr=0.7665 | fpr=0.8711 | 6821.2 samples/s | 26.6 steps/s
[Step= 350] | Loss=4.12901 | acc=0.1401 | tpr=0.7683 | fpr=0.8713 | 7025.3 samples/s | 27.4 steps/s
[Step= 400] | Loss=4.13372 | acc=0.1402 | tpr=0.7702 | fpr=0.8712 | 6652.5 samples/s | 26.0 steps/s
[Step= 450] | Loss=4.13643 | acc=0.1407 | tpr=0.7731 | fpr=0.8708 | 6873.8 samples/s | 26.9 steps/s
[Step= 500] | Loss=4.13807 | acc=0.1407 | tpr=0.7722 | fpr=0.8707 | 6823.6 samples/s | 26.7 steps/s
[Step= 550] | Loss=4.13854 | acc=0.1408 | tpr=0.7740 | fpr=0.8707 | 12228.9 samples/s | 47.8 steps/s
Avg test loss: 4.14040, Avg test acc: 0.14076, Avg tpr: 0.77377, Avg fpr: 0.87075, total FA: 120902

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12083 | acc=0.9836 | tpr=0.9602 | fpr=0.0160 | 3641.1 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.12886 | acc=0.9823 | tpr=0.9659 | fpr=0.0173 | 6708.1 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.13173 | acc=0.9815 | tpr=0.9669 | fpr=0.0182 | 6959.5 samples/s | 27.2 steps/s
[Step= 200] | Loss=0.13370 | acc=0.9817 | tpr=0.9694 | fpr=0.0181 | 6846.3 samples/s | 26.7 steps/s
[Step= 250] | Loss=0.13217 | acc=0.9816 | tpr=0.9677 | fpr=0.0181 | 6804.6 samples/s | 26.6 steps/s
[Step= 300] | Loss=0.13534 | acc=0.9814 | tpr=0.9644 | fpr=0.0183 | 6830.5 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.13596 | acc=0.9812 | tpr=0.9656 | fpr=0.0185 | 6847.5 samples/s | 26.7 steps/s
[Step= 400] | Loss=0.13706 | acc=0.9810 | tpr=0.9644 | fpr=0.0187 | 6850.6 samples/s | 26.8 steps/s
[Step= 450] | Loss=0.13996 | acc=0.9807 | tpr=0.9625 | fpr=0.0189 | 6872.0 samples/s | 26.8 steps/s
[Step= 500] | Loss=0.13910 | acc=0.9808 | tpr=0.9630 | fpr=0.0189 | 6470.3 samples/s | 25.3 steps/s
[Step= 550] | Loss=0.13825 | acc=0.9809 | tpr=0.9618 | fpr=0.0188 | 12392.9 samples/s | 48.4 steps/s
Avg test loss: 0.13790, Avg test acc: 0.98089, Avg tpr: 0.96197, Avg fpr: 0.01877, total FA: 2606

server round 10/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=19.5] | Loss=0.02623 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.262 | L2-Norm(final)=5.148 | 3373.8 samples/s | 52.7 steps/s
[Step=20050 Epoch=19.6] | Loss=0.02768 | Reg=0.00266 | acc=0.9844 | L2-Norm=16.300 | L2-Norm(final)=5.165 | 3948.0 samples/s | 61.7 steps/s
[Step=20100 Epoch=19.6] | Loss=0.02689 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.331 | L2-Norm(final)=5.184 | 4422.5 samples/s | 69.1 steps/s
[Step=20150 Epoch=19.7] | Loss=0.02675 | Reg=0.00267 | acc=0.9844 | L2-Norm=16.352 | L2-Norm(final)=5.199 | 4294.1 samples/s | 67.1 steps/s
[Step=20200 Epoch=19.7] | Loss=0.02651 | Reg=0.00268 | acc=1.0000 | L2-Norm=16.370 | L2-Norm(final)=5.212 | 4276.8 samples/s | 66.8 steps/s
[Step=20250 Epoch=19.8] | Loss=0.02680 | Reg=0.00269 | acc=0.9531 | L2-Norm=16.387 | L2-Norm(final)=5.222 | 4392.1 samples/s | 68.6 steps/s
[Step=20300 Epoch=19.8] | Loss=0.02655 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.402 | L2-Norm(final)=5.232 | 4329.6 samples/s | 67.6 steps/s
[Step=20350 Epoch=19.9] | Loss=0.02593 | Reg=0.00270 | acc=1.0000 | L2-Norm=16.418 | L2-Norm(final)=5.242 | 4348.0 samples/s | 67.9 steps/s
[Step=20400 Epoch=19.9] | Loss=0.02591 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.433 | L2-Norm(final)=5.253 | 4332.2 samples/s | 67.7 steps/s
[Step=20450 Epoch=20.0] | Loss=0.02557 | Reg=0.00271 | acc=0.9531 | L2-Norm=16.448 | L2-Norm(final)=5.262 | 4456.7 samples/s | 69.6 steps/s
[Step=20500 Epoch=20.0] | Loss=0.02521 | Reg=0.00271 | acc=0.9531 | L2-Norm=16.463 | L2-Norm(final)=5.272 | 4342.5 samples/s | 67.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=20.0] | Loss=0.00544 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.607 | L2-Norm(final)=5.374 | 3156.3 samples/s | 49.3 steps/s
[Step=20550 Epoch=20.1] | Loss=0.02121 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.624 | L2-Norm(final)=5.383 | 3801.2 samples/s | 59.4 steps/s
[Step=20600 Epoch=20.1] | Loss=0.02338 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.640 | L2-Norm(final)=5.383 | 3940.4 samples/s | 61.6 steps/s
[Step=20650 Epoch=20.2] | Loss=0.02432 | Reg=0.00277 | acc=0.9688 | L2-Norm=16.652 | L2-Norm(final)=5.380 | 3908.5 samples/s | 61.1 steps/s
[Step=20700 Epoch=20.2] | Loss=0.02442 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.665 | L2-Norm(final)=5.380 | 3950.1 samples/s | 61.7 steps/s
[Step=20750 Epoch=20.3] | Loss=0.02390 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.678 | L2-Norm(final)=5.381 | 3954.9 samples/s | 61.8 steps/s
[Step=20800 Epoch=20.3] | Loss=0.02360 | Reg=0.00279 | acc=0.9375 | L2-Norm=16.690 | L2-Norm(final)=5.382 | 3931.6 samples/s | 61.4 steps/s
[Step=20850 Epoch=20.4] | Loss=0.02333 | Reg=0.00279 | acc=0.9688 | L2-Norm=16.700 | L2-Norm(final)=5.383 | 3968.6 samples/s | 62.0 steps/s
[Step=20900 Epoch=20.4] | Loss=0.02387 | Reg=0.00279 | acc=1.0000 | L2-Norm=16.710 | L2-Norm(final)=5.385 | 3915.7 samples/s | 61.2 steps/s
[Step=20950 Epoch=20.5] | Loss=0.02327 | Reg=0.00280 | acc=0.9844 | L2-Norm=16.718 | L2-Norm(final)=5.386 | 3921.2 samples/s | 61.3 steps/s
[Step=21000 Epoch=20.5] | Loss=0.02320 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.727 | L2-Norm(final)=5.387 | 3987.5 samples/s | 62.3 steps/s
[Step=21050 Epoch=20.6] | Loss=0.02287 | Reg=0.00280 | acc=0.9688 | L2-Norm=16.735 | L2-Norm(final)=5.388 | 3920.0 samples/s | 61.3 steps/s
[Step=21100 Epoch=20.6] | Loss=0.02268 | Reg=0.00280 | acc=1.0000 | L2-Norm=16.742 | L2-Norm(final)=5.390 | 3947.1 samples/s | 61.7 steps/s
[Step=21150 Epoch=20.6] | Loss=0.02272 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.749 | L2-Norm(final)=5.391 | 3907.3 samples/s | 61.1 steps/s
[Step=21200 Epoch=20.7] | Loss=0.02236 | Reg=0.00281 | acc=0.9531 | L2-Norm=16.756 | L2-Norm(final)=5.391 | 3956.9 samples/s | 61.8 steps/s
[Step=21250 Epoch=20.7] | Loss=0.02230 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.762 | L2-Norm(final)=5.392 | 3940.4 samples/s | 61.6 steps/s
[Step=21300 Epoch=20.8] | Loss=0.02231 | Reg=0.00281 | acc=0.9844 | L2-Norm=16.768 | L2-Norm(final)=5.393 | 3946.1 samples/s | 61.7 steps/s
[Step=21350 Epoch=20.8] | Loss=0.02232 | Reg=0.00281 | acc=1.0000 | L2-Norm=16.773 | L2-Norm(final)=5.393 | 3930.7 samples/s | 61.4 steps/s
[Step=21400 Epoch=20.9] | Loss=0.02211 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.779 | L2-Norm(final)=5.394 | 3949.7 samples/s | 61.7 steps/s
[Step=21450 Epoch=20.9] | Loss=0.02185 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.785 | L2-Norm(final)=5.395 | 3926.3 samples/s | 61.3 steps/s
[Step=21500 Epoch=21.0] | Loss=0.02161 | Reg=0.00282 | acc=0.9844 | L2-Norm=16.791 | L2-Norm(final)=5.396 | 4212.5 samples/s | 65.8 steps/s
[Step=21550 Epoch=21.0] | Loss=0.02158 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.797 | L2-Norm(final)=5.396 | 1598.7 samples/s | 25.0 steps/s
[Step=21600 Epoch=21.1] | Loss=0.02123 | Reg=0.00282 | acc=1.0000 | L2-Norm=16.803 | L2-Norm(final)=5.397 | 3909.1 samples/s | 61.1 steps/s
[Step=21650 Epoch=21.1] | Loss=0.02100 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.809 | L2-Norm(final)=5.397 | 3922.1 samples/s | 61.3 steps/s
[Step=21700 Epoch=21.2] | Loss=0.02063 | Reg=0.00283 | acc=0.9375 | L2-Norm=16.814 | L2-Norm(final)=5.399 | 3904.7 samples/s | 61.0 steps/s
[Step=21750 Epoch=21.2] | Loss=0.02041 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.820 | L2-Norm(final)=5.400 | 3938.4 samples/s | 61.5 steps/s
[Step=21800 Epoch=21.3] | Loss=0.02026 | Reg=0.00283 | acc=0.9688 | L2-Norm=16.825 | L2-Norm(final)=5.401 | 3936.3 samples/s | 61.5 steps/s
[Step=21850 Epoch=21.3] | Loss=0.02030 | Reg=0.00283 | acc=1.0000 | L2-Norm=16.830 | L2-Norm(final)=5.402 | 3944.9 samples/s | 61.6 steps/s
[Step=21900 Epoch=21.4] | Loss=0.02015 | Reg=0.00283 | acc=0.9844 | L2-Norm=16.836 | L2-Norm(final)=5.403 | 3980.8 samples/s | 62.2 steps/s
[Step=21950 Epoch=21.4] | Loss=0.01998 | Reg=0.00284 | acc=0.9688 | L2-Norm=16.840 | L2-Norm(final)=5.404 | 3888.4 samples/s | 60.8 steps/s
[Step=22000 Epoch=21.5] | Loss=0.01988 | Reg=0.00284 | acc=1.0000 | L2-Norm=16.845 | L2-Norm(final)=5.404 | 4012.9 samples/s | 62.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step22000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=20001 Epoch=37.7] | Loss=0.00446 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.262 | L2-Norm(final)=4.192 | 3464.4 samples/s | 54.1 steps/s
[Step=20050 Epoch=37.8] | Loss=0.00419 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.218 | L2-Norm(final)=4.198 | 3639.7 samples/s | 56.9 steps/s
[Step=20100 Epoch=37.9] | Loss=0.00361 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.231 | L2-Norm(final)=4.199 | 4195.9 samples/s | 65.6 steps/s
[Step=20150 Epoch=38.0] | Loss=0.00299 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=4.205 | 4042.5 samples/s | 63.2 steps/s
[Step=20200 Epoch=38.1] | Loss=0.00259 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.252 | L2-Norm(final)=4.213 | 4121.6 samples/s | 64.4 steps/s
[Step=20250 Epoch=38.2] | Loss=0.00212 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.254 | L2-Norm(final)=4.220 | 4093.6 samples/s | 64.0 steps/s
[Step=20300 Epoch=38.3] | Loss=0.00215 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.252 | L2-Norm(final)=4.226 | 4114.5 samples/s | 64.3 steps/s
[Step=20350 Epoch=38.4] | Loss=0.00196 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.250 | L2-Norm(final)=4.232 | 4166.3 samples/s | 65.1 steps/s
[Step=20400 Epoch=38.5] | Loss=0.00183 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.248 | L2-Norm(final)=4.240 | 4096.2 samples/s | 64.0 steps/s
[Step=20450 Epoch=38.5] | Loss=0.00178 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.247 | L2-Norm(final)=4.247 | 4126.2 samples/s | 64.5 steps/s
[Step=20500 Epoch=38.6] | Loss=0.00162 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.245 | L2-Norm(final)=4.253 | 4136.3 samples/s | 64.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=20501 Epoch=38.6] | Loss=0.00002 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=4.310 | 3394.2 samples/s | 53.0 steps/s
[Step=20550 Epoch=38.7] | Loss=0.00038 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.198 | L2-Norm(final)=4.314 | 3375.3 samples/s | 52.7 steps/s
[Step=20600 Epoch=38.8] | Loss=0.00616 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.228 | L2-Norm(final)=4.307 | 3692.8 samples/s | 57.7 steps/s
[Step=20650 Epoch=38.9] | Loss=0.00539 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.282 | L2-Norm(final)=4.288 | 3748.1 samples/s | 58.6 steps/s
[Step=20700 Epoch=39.0] | Loss=0.00459 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.314 | L2-Norm(final)=4.278 | 3693.0 samples/s | 57.7 steps/s
[Step=20750 Epoch=39.1] | Loss=0.00409 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.333 | L2-Norm(final)=4.272 | 3731.1 samples/s | 58.3 steps/s
[Step=20800 Epoch=39.2] | Loss=0.00359 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.344 | L2-Norm(final)=4.268 | 3735.7 samples/s | 58.4 steps/s
[Step=20850 Epoch=39.3] | Loss=0.00314 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.350 | L2-Norm(final)=4.266 | 3768.5 samples/s | 58.9 steps/s
[Step=20900 Epoch=39.4] | Loss=0.00283 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.352 | L2-Norm(final)=4.265 | 3728.8 samples/s | 58.3 steps/s
[Step=20950 Epoch=39.5] | Loss=0.00265 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.352 | L2-Norm(final)=4.264 | 3725.1 samples/s | 58.2 steps/s
[Step=21000 Epoch=39.6] | Loss=0.00242 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.350 | L2-Norm(final)=4.263 | 3843.2 samples/s | 60.1 steps/s
[Step=21050 Epoch=39.7] | Loss=0.00221 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.347 | L2-Norm(final)=4.262 | 1669.8 samples/s | 26.1 steps/s
[Step=21100 Epoch=39.8] | Loss=0.00203 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.343 | L2-Norm(final)=4.262 | 3694.8 samples/s | 57.7 steps/s
[Step=21150 Epoch=39.9] | Loss=0.00188 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.337 | L2-Norm(final)=4.262 | 3713.9 samples/s | 58.0 steps/s
[Step=21200 Epoch=40.0] | Loss=0.00175 | Reg=0.00267 | acc=1.0000 | L2-Norm=16.330 | L2-Norm(final)=4.263 | 3717.1 samples/s | 58.1 steps/s
[Step=21250 Epoch=40.1] | Loss=0.00163 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.323 | L2-Norm(final)=4.263 | 3706.0 samples/s | 57.9 steps/s
[Step=21300 Epoch=40.2] | Loss=0.00154 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.315 | L2-Norm(final)=4.263 | 3789.6 samples/s | 59.2 steps/s
[Step=21350 Epoch=40.2] | Loss=0.00145 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.307 | L2-Norm(final)=4.264 | 3719.0 samples/s | 58.1 steps/s
[Step=21400 Epoch=40.3] | Loss=0.00138 | Reg=0.00266 | acc=1.0000 | L2-Norm=16.298 | L2-Norm(final)=4.264 | 3671.6 samples/s | 57.4 steps/s
[Step=21450 Epoch=40.4] | Loss=0.00130 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.289 | L2-Norm(final)=4.265 | 3698.1 samples/s | 57.8 steps/s
[Step=21500 Epoch=40.5] | Loss=0.00124 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.279 | L2-Norm(final)=4.265 | 3723.2 samples/s | 58.2 steps/s
[Step=21550 Epoch=40.6] | Loss=0.00119 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.269 | L2-Norm(final)=4.266 | 4722.5 samples/s | 73.8 steps/s
[Step=21600 Epoch=40.7] | Loss=0.00113 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.260 | L2-Norm(final)=4.266 | 1541.9 samples/s | 24.1 steps/s
[Step=21650 Epoch=40.8] | Loss=0.00109 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.249 | L2-Norm(final)=4.267 | 3679.4 samples/s | 57.5 steps/s
[Step=21700 Epoch=40.9] | Loss=0.00104 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.239 | L2-Norm(final)=4.268 | 3738.4 samples/s | 58.4 steps/s
[Step=21750 Epoch=41.0] | Loss=0.00100 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.228 | L2-Norm(final)=4.268 | 3672.8 samples/s | 57.4 steps/s
[Step=21800 Epoch=41.1] | Loss=0.00096 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.217 | L2-Norm(final)=4.269 | 3704.1 samples/s | 57.9 steps/s
[Step=21850 Epoch=41.2] | Loss=0.00093 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.206 | L2-Norm(final)=4.269 | 3770.7 samples/s | 58.9 steps/s
[Step=21900 Epoch=41.3] | Loss=0.00089 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.195 | L2-Norm(final)=4.270 | 3725.6 samples/s | 58.2 steps/s
[Step=21950 Epoch=41.4] | Loss=0.00086 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.183 | L2-Norm(final)=4.270 | 3744.9 samples/s | 58.5 steps/s
[Step=22000 Epoch=41.5] | Loss=0.00083 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.172 | L2-Norm(final)=4.271 | 3756.4 samples/s | 58.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step22000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05376 | acc=0.9703 | tpr=0.9748 | fpr=0.0394 | 3632.4 samples/s | 14.2 steps/s
Avg test loss: 0.05443, Avg test acc: 0.96883, Avg tpr: 0.97249, Avg fpr: 0.03923, total FA: 306

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.87034 | acc=0.3082 | tpr=0.0171 | fpr=0.0597 | 3653.4 samples/s | 14.3 steps/s
Avg test loss: 6.86215, Avg test acc: 0.30595, Avg tpr: 0.01801, Avg fpr: 0.06076, total FA: 474

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.15329 | acc=0.1235 | tpr=0.6593 | fpr=0.8861 | 3634.0 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.16301 | acc=0.1244 | tpr=0.6887 | fpr=0.8861 | 6943.9 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.15490 | acc=0.1236 | tpr=0.7118 | fpr=0.8872 | 6629.3 samples/s | 25.9 steps/s
[Step= 200] | Loss=5.14201 | acc=0.1240 | tpr=0.7016 | fpr=0.8865 | 6757.3 samples/s | 26.4 steps/s
[Step= 250] | Loss=5.14333 | acc=0.1243 | tpr=0.6978 | fpr=0.8861 | 6857.3 samples/s | 26.8 steps/s
[Step= 300] | Loss=5.13876 | acc=0.1243 | tpr=0.6996 | fpr=0.8861 | 6836.7 samples/s | 26.7 steps/s
[Step= 350] | Loss=5.13868 | acc=0.1240 | tpr=0.7013 | fpr=0.8864 | 6825.0 samples/s | 26.7 steps/s
[Step= 400] | Loss=5.14237 | acc=0.1242 | tpr=0.6997 | fpr=0.8863 | 6713.5 samples/s | 26.2 steps/s
[Step= 450] | Loss=5.14398 | acc=0.1242 | tpr=0.7006 | fpr=0.8863 | 6702.4 samples/s | 26.2 steps/s
[Step= 500] | Loss=5.14563 | acc=0.1246 | tpr=0.7000 | fpr=0.8858 | 6912.5 samples/s | 27.0 steps/s
[Step= 550] | Loss=5.14629 | acc=0.1244 | tpr=0.7016 | fpr=0.8860 | 12205.2 samples/s | 47.7 steps/s
Avg test loss: 5.14793, Avg test acc: 0.12442, Avg tpr: 0.70166, Avg fpr: 0.88607, total FA: 123029

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.14409 | acc=0.9827 | tpr=0.9690 | fpr=0.0171 | 3579.4 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.15558 | acc=0.9812 | tpr=0.9701 | fpr=0.0186 | 6926.8 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.15997 | acc=0.9806 | tpr=0.9697 | fpr=0.0192 | 6741.2 samples/s | 26.3 steps/s
[Step= 200] | Loss=0.16103 | acc=0.9807 | tpr=0.9738 | fpr=0.0192 | 6695.6 samples/s | 26.2 steps/s
[Step= 250] | Loss=0.15986 | acc=0.9807 | tpr=0.9703 | fpr=0.0191 | 6849.6 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.16377 | acc=0.9803 | tpr=0.9665 | fpr=0.0195 | 6966.3 samples/s | 27.2 steps/s
[Step= 350] | Loss=0.16533 | acc=0.9800 | tpr=0.9662 | fpr=0.0197 | 6693.9 samples/s | 26.1 steps/s
[Step= 400] | Loss=0.16634 | acc=0.9799 | tpr=0.9644 | fpr=0.0198 | 6941.8 samples/s | 27.1 steps/s
[Step= 450] | Loss=0.17065 | acc=0.9795 | tpr=0.9625 | fpr=0.0202 | 6590.3 samples/s | 25.7 steps/s
[Step= 500] | Loss=0.16934 | acc=0.9796 | tpr=0.9630 | fpr=0.0201 | 6687.9 samples/s | 26.1 steps/s
[Step= 550] | Loss=0.16824 | acc=0.9799 | tpr=0.9618 | fpr=0.0198 | 12746.8 samples/s | 49.8 steps/s
Avg test loss: 0.16785, Avg test acc: 0.97988, Avg tpr: 0.96197, Avg fpr: 0.01980, total FA: 2749

server round 11/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=21.5] | Loss=0.08020 | Reg=0.00257 | acc=0.9219 | L2-Norm=16.031 | L2-Norm(final)=5.428 | 3341.3 samples/s | 52.2 steps/s
[Step=22050 Epoch=21.5] | Loss=0.02827 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.059 | L2-Norm(final)=5.446 | 4155.4 samples/s | 64.9 steps/s
[Step=22100 Epoch=21.6] | Loss=0.02812 | Reg=0.00259 | acc=1.0000 | L2-Norm=16.089 | L2-Norm(final)=5.462 | 4457.6 samples/s | 69.6 steps/s
[Step=22150 Epoch=21.6] | Loss=0.02799 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.114 | L2-Norm(final)=5.474 | 4332.9 samples/s | 67.7 steps/s
[Step=22200 Epoch=21.7] | Loss=0.02771 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.138 | L2-Norm(final)=5.484 | 4311.0 samples/s | 67.4 steps/s
[Step=22250 Epoch=21.7] | Loss=0.02710 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.159 | L2-Norm(final)=5.493 | 4384.2 samples/s | 68.5 steps/s
[Step=22300 Epoch=21.8] | Loss=0.02728 | Reg=0.00262 | acc=0.9531 | L2-Norm=16.177 | L2-Norm(final)=5.501 | 4354.1 samples/s | 68.0 steps/s
[Step=22350 Epoch=21.8] | Loss=0.02666 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.195 | L2-Norm(final)=5.507 | 4409.7 samples/s | 68.9 steps/s
[Step=22400 Epoch=21.9] | Loss=0.02601 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.214 | L2-Norm(final)=5.516 | 4352.5 samples/s | 68.0 steps/s
[Step=22450 Epoch=21.9] | Loss=0.02622 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.231 | L2-Norm(final)=5.524 | 4365.0 samples/s | 68.2 steps/s
[Step=22500 Epoch=22.0] | Loss=0.02641 | Reg=0.00264 | acc=0.9688 | L2-Norm=16.248 | L2-Norm(final)=5.531 | 4413.9 samples/s | 69.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=22.0] | Loss=0.04277 | Reg=0.00269 | acc=0.9844 | L2-Norm=16.411 | L2-Norm(final)=5.601 | 3394.4 samples/s | 53.0 steps/s
[Step=22550 Epoch=22.0] | Loss=0.02495 | Reg=0.00270 | acc=0.9688 | L2-Norm=16.426 | L2-Norm(final)=5.606 | 3611.8 samples/s | 56.4 steps/s
[Step=22600 Epoch=22.1] | Loss=0.02428 | Reg=0.00270 | acc=0.9844 | L2-Norm=16.445 | L2-Norm(final)=5.608 | 3925.7 samples/s | 61.3 steps/s
[Step=22650 Epoch=22.1] | Loss=0.02446 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.460 | L2-Norm(final)=5.606 | 3945.8 samples/s | 61.7 steps/s
[Step=22700 Epoch=22.2] | Loss=0.02445 | Reg=0.00271 | acc=0.9688 | L2-Norm=16.474 | L2-Norm(final)=5.605 | 3979.9 samples/s | 62.2 steps/s
[Step=22750 Epoch=22.2] | Loss=0.02464 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.488 | L2-Norm(final)=5.603 | 3959.9 samples/s | 61.9 steps/s
[Step=22800 Epoch=22.3] | Loss=0.02432 | Reg=0.00272 | acc=1.0000 | L2-Norm=16.502 | L2-Norm(final)=5.602 | 3934.6 samples/s | 61.5 steps/s
[Step=22850 Epoch=22.3] | Loss=0.02354 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.514 | L2-Norm(final)=5.602 | 3975.7 samples/s | 62.1 steps/s
[Step=22900 Epoch=22.4] | Loss=0.02345 | Reg=0.00273 | acc=1.0000 | L2-Norm=16.525 | L2-Norm(final)=5.602 | 3967.7 samples/s | 62.0 steps/s
[Step=22950 Epoch=22.4] | Loss=0.02367 | Reg=0.00273 | acc=0.9844 | L2-Norm=16.536 | L2-Norm(final)=5.601 | 3938.0 samples/s | 61.5 steps/s
[Step=23000 Epoch=22.5] | Loss=0.02383 | Reg=0.00274 | acc=0.9844 | L2-Norm=16.546 | L2-Norm(final)=5.600 | 3957.9 samples/s | 61.8 steps/s
[Step=23050 Epoch=22.5] | Loss=0.02327 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.556 | L2-Norm(final)=5.599 | 3947.8 samples/s | 61.7 steps/s
[Step=23100 Epoch=22.6] | Loss=0.02303 | Reg=0.00274 | acc=1.0000 | L2-Norm=16.565 | L2-Norm(final)=5.598 | 3964.0 samples/s | 61.9 steps/s
[Step=23150 Epoch=22.6] | Loss=0.02291 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.573 | L2-Norm(final)=5.598 | 3983.6 samples/s | 62.2 steps/s
[Step=23200 Epoch=22.7] | Loss=0.02305 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.582 | L2-Norm(final)=5.598 | 3975.3 samples/s | 62.1 steps/s
[Step=23250 Epoch=22.7] | Loss=0.02265 | Reg=0.00275 | acc=0.9844 | L2-Norm=16.590 | L2-Norm(final)=5.597 | 3939.2 samples/s | 61.6 steps/s
[Step=23300 Epoch=22.7] | Loss=0.02245 | Reg=0.00275 | acc=0.9531 | L2-Norm=16.597 | L2-Norm(final)=5.597 | 3961.3 samples/s | 61.9 steps/s
[Step=23350 Epoch=22.8] | Loss=0.02235 | Reg=0.00276 | acc=0.9688 | L2-Norm=16.605 | L2-Norm(final)=5.597 | 3978.1 samples/s | 62.2 steps/s
[Step=23400 Epoch=22.8] | Loss=0.02197 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.611 | L2-Norm(final)=5.597 | 4007.9 samples/s | 62.6 steps/s
[Step=23450 Epoch=22.9] | Loss=0.02195 | Reg=0.00276 | acc=1.0000 | L2-Norm=16.618 | L2-Norm(final)=5.597 | 3953.5 samples/s | 61.8 steps/s
[Step=23500 Epoch=22.9] | Loss=0.02194 | Reg=0.00276 | acc=0.9844 | L2-Norm=16.625 | L2-Norm(final)=5.598 | 4215.1 samples/s | 65.9 steps/s
[Step=23550 Epoch=23.0] | Loss=0.02157 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.632 | L2-Norm(final)=5.598 | 1659.7 samples/s | 25.9 steps/s
[Step=23600 Epoch=23.0] | Loss=0.02131 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.639 | L2-Norm(final)=5.599 | 3977.4 samples/s | 62.1 steps/s
[Step=23650 Epoch=23.1] | Loss=0.02119 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.646 | L2-Norm(final)=5.599 | 3923.3 samples/s | 61.3 steps/s
[Step=23700 Epoch=23.1] | Loss=0.02088 | Reg=0.00277 | acc=1.0000 | L2-Norm=16.652 | L2-Norm(final)=5.600 | 3906.9 samples/s | 61.0 steps/s
[Step=23750 Epoch=23.2] | Loss=0.02060 | Reg=0.00277 | acc=0.9844 | L2-Norm=16.658 | L2-Norm(final)=5.601 | 3943.3 samples/s | 61.6 steps/s
[Step=23800 Epoch=23.2] | Loss=0.02029 | Reg=0.00278 | acc=0.9688 | L2-Norm=16.664 | L2-Norm(final)=5.602 | 3941.7 samples/s | 61.6 steps/s
[Step=23850 Epoch=23.3] | Loss=0.02013 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.669 | L2-Norm(final)=5.603 | 3929.6 samples/s | 61.4 steps/s
[Step=23900 Epoch=23.3] | Loss=0.01995 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.675 | L2-Norm(final)=5.604 | 3925.1 samples/s | 61.3 steps/s
[Step=23950 Epoch=23.4] | Loss=0.01995 | Reg=0.00278 | acc=0.9844 | L2-Norm=16.681 | L2-Norm(final)=5.605 | 4021.2 samples/s | 62.8 steps/s
[Step=24000 Epoch=23.4] | Loss=0.01984 | Reg=0.00278 | acc=1.0000 | L2-Norm=16.686 | L2-Norm(final)=5.606 | 3958.3 samples/s | 61.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step24000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=22001 Epoch=41.5] | Loss=0.00002 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.031 | L2-Norm(final)=4.285 | 3204.3 samples/s | 50.1 steps/s
[Step=22050 Epoch=41.6] | Loss=0.00023 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.991 | L2-Norm(final)=4.291 | 4022.1 samples/s | 62.8 steps/s
[Step=22100 Epoch=41.7] | Loss=0.00018 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.973 | L2-Norm(final)=4.297 | 4104.7 samples/s | 64.1 steps/s
[Step=22150 Epoch=41.8] | Loss=0.00016 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.957 | L2-Norm(final)=4.302 | 4100.5 samples/s | 64.1 steps/s
[Step=22200 Epoch=41.8] | Loss=0.00017 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.945 | L2-Norm(final)=4.308 | 4081.3 samples/s | 63.8 steps/s
[Step=22250 Epoch=41.9] | Loss=0.00016 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.935 | L2-Norm(final)=4.313 | 4143.6 samples/s | 64.7 steps/s
[Step=22300 Epoch=42.0] | Loss=0.00015 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.926 | L2-Norm(final)=4.318 | 4098.8 samples/s | 64.0 steps/s
[Step=22350 Epoch=42.1] | Loss=0.00013 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.918 | L2-Norm(final)=4.322 | 4180.8 samples/s | 65.3 steps/s
[Step=22400 Epoch=42.2] | Loss=0.00012 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.908 | L2-Norm(final)=4.326 | 4055.1 samples/s | 63.4 steps/s
[Step=22450 Epoch=42.3] | Loss=0.00011 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.899 | L2-Norm(final)=4.330 | 4115.8 samples/s | 64.3 steps/s
[Step=22500 Epoch=42.4] | Loss=0.00010 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.889 | L2-Norm(final)=4.333 | 4124.6 samples/s | 64.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=22501 Epoch=42.4] | Loss=0.00002 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.795 | L2-Norm(final)=4.368 | 3259.8 samples/s | 50.9 steps/s
[Step=22550 Epoch=42.5] | Loss=0.00002 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=4.369 | 3357.8 samples/s | 52.5 steps/s
[Step=22600 Epoch=42.6] | Loss=0.00002 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.758 | L2-Norm(final)=4.371 | 3749.7 samples/s | 58.6 steps/s
[Step=22650 Epoch=42.7] | Loss=0.00002 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.737 | L2-Norm(final)=4.373 | 3647.6 samples/s | 57.0 steps/s
[Step=22700 Epoch=42.8] | Loss=0.00001 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.717 | L2-Norm(final)=4.374 | 3712.9 samples/s | 58.0 steps/s
[Step=22750 Epoch=42.9] | Loss=0.00002 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.698 | L2-Norm(final)=4.375 | 3683.4 samples/s | 57.6 steps/s
[Step=22800 Epoch=43.0] | Loss=0.00002 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.679 | L2-Norm(final)=4.377 | 3761.7 samples/s | 58.8 steps/s
[Step=22850 Epoch=43.1] | Loss=0.00002 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.660 | L2-Norm(final)=4.379 | 3701.7 samples/s | 57.8 steps/s
[Step=22900 Epoch=43.2] | Loss=0.00002 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.641 | L2-Norm(final)=4.381 | 3663.9 samples/s | 57.2 steps/s
[Step=22950 Epoch=43.3] | Loss=0.00001 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.622 | L2-Norm(final)=4.382 | 3731.8 samples/s | 58.3 steps/s
[Step=23000 Epoch=43.4] | Loss=0.00001 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.603 | L2-Norm(final)=4.384 | 3812.4 samples/s | 59.6 steps/s
[Step=23050 Epoch=43.4] | Loss=0.00001 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.584 | L2-Norm(final)=4.385 | 1645.5 samples/s | 25.7 steps/s
[Step=23100 Epoch=43.5] | Loss=0.00001 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.565 | L2-Norm(final)=4.387 | 3755.2 samples/s | 58.7 steps/s
[Step=23150 Epoch=43.6] | Loss=0.00001 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.546 | L2-Norm(final)=4.388 | 3734.4 samples/s | 58.3 steps/s
[Step=23200 Epoch=43.7] | Loss=0.00001 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.526 | L2-Norm(final)=4.389 | 3712.6 samples/s | 58.0 steps/s
[Step=23250 Epoch=43.8] | Loss=0.00001 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.507 | L2-Norm(final)=4.390 | 3723.8 samples/s | 58.2 steps/s
[Step=23300 Epoch=43.9] | Loss=0.00001 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.488 | L2-Norm(final)=4.391 | 3715.4 samples/s | 58.1 steps/s
[Step=23350 Epoch=44.0] | Loss=0.00001 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.468 | L2-Norm(final)=4.392 | 3759.6 samples/s | 58.7 steps/s
[Step=23400 Epoch=44.1] | Loss=0.00001 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.449 | L2-Norm(final)=4.393 | 3675.8 samples/s | 57.4 steps/s
[Step=23450 Epoch=44.2] | Loss=0.00001 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=4.394 | 3725.6 samples/s | 58.2 steps/s
[Step=23500 Epoch=44.3] | Loss=0.00001 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.410 | L2-Norm(final)=4.395 | 3718.9 samples/s | 58.1 steps/s
[Step=23550 Epoch=44.4] | Loss=0.00001 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.390 | L2-Norm(final)=4.396 | 4646.1 samples/s | 72.6 steps/s
[Step=23600 Epoch=44.5] | Loss=0.00001 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=4.397 | 1498.8 samples/s | 23.4 steps/s
[Step=23650 Epoch=44.6] | Loss=0.00001 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.351 | L2-Norm(final)=4.398 | 3733.9 samples/s | 58.3 steps/s
[Step=23700 Epoch=44.7] | Loss=0.00001 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=4.398 | 3709.5 samples/s | 58.0 steps/s
[Step=23750 Epoch=44.8] | Loss=0.00001 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=4.399 | 3679.4 samples/s | 57.5 steps/s
[Step=23800 Epoch=44.9] | Loss=0.00001 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.291 | L2-Norm(final)=4.400 | 3725.2 samples/s | 58.2 steps/s
[Step=23850 Epoch=45.0] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.271 | L2-Norm(final)=4.401 | 3643.2 samples/s | 56.9 steps/s
[Step=23900 Epoch=45.1] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.251 | L2-Norm(final)=4.402 | 3738.5 samples/s | 58.4 steps/s
[Step=23950 Epoch=45.1] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=4.402 | 3695.2 samples/s | 57.7 steps/s
[Step=24000 Epoch=45.2] | Loss=0.00001 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.211 | L2-Norm(final)=4.403 | 3685.1 samples/s | 57.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step24000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05237 | acc=0.9712 | tpr=0.9764 | fpr=0.0401 | 3592.2 samples/s | 14.0 steps/s
Avg test loss: 0.05330, Avg test acc: 0.97047, Avg tpr: 0.97540, Avg fpr: 0.04038, total FA: 315

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.59505 | acc=0.3063 | tpr=0.0218 | fpr=0.0761 | 3646.6 samples/s | 14.2 steps/s
Avg test loss: 6.58223, Avg test acc: 0.30495, Avg tpr: 0.02261, Avg fpr: 0.07409, total FA: 578

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.23153 | acc=0.1206 | tpr=0.6726 | fpr=0.8893 | 3643.9 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.24301 | acc=0.1227 | tpr=0.6908 | fpr=0.8879 | 6746.0 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.24271 | acc=0.1208 | tpr=0.6974 | fpr=0.8898 | 6976.3 samples/s | 27.3 steps/s
[Step= 200] | Loss=5.22818 | acc=0.1206 | tpr=0.6995 | fpr=0.8899 | 6802.5 samples/s | 26.6 steps/s
[Step= 250] | Loss=5.23067 | acc=0.1211 | tpr=0.6926 | fpr=0.8893 | 6896.0 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.22427 | acc=0.1214 | tpr=0.6895 | fpr=0.8890 | 6922.0 samples/s | 27.0 steps/s
[Step= 350] | Loss=5.22094 | acc=0.1211 | tpr=0.6900 | fpr=0.8893 | 6899.3 samples/s | 27.0 steps/s
[Step= 400] | Loss=5.22661 | acc=0.1209 | tpr=0.6898 | fpr=0.8895 | 6695.9 samples/s | 26.2 steps/s
[Step= 450] | Loss=5.22838 | acc=0.1205 | tpr=0.6938 | fpr=0.8899 | 6882.9 samples/s | 26.9 steps/s
[Step= 500] | Loss=5.23111 | acc=0.1209 | tpr=0.6943 | fpr=0.8895 | 7208.2 samples/s | 28.2 steps/s
[Step= 550] | Loss=5.23256 | acc=0.1211 | tpr=0.6952 | fpr=0.8894 | 12257.9 samples/s | 47.9 steps/s
Avg test loss: 5.23391, Avg test acc: 0.12099, Avg tpr: 0.69493, Avg fpr: 0.88945, total FA: 123498

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13150 | acc=0.9819 | tpr=0.9646 | fpr=0.0178 | 3587.3 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.14025 | acc=0.9815 | tpr=0.9680 | fpr=0.0182 | 7024.1 samples/s | 27.4 steps/s
[Step= 150] | Loss=0.14248 | acc=0.9807 | tpr=0.9683 | fpr=0.0191 | 7025.4 samples/s | 27.4 steps/s
[Step= 200] | Loss=0.14411 | acc=0.9809 | tpr=0.9716 | fpr=0.0190 | 6734.9 samples/s | 26.3 steps/s
[Step= 250] | Loss=0.14297 | acc=0.9808 | tpr=0.9677 | fpr=0.0190 | 6927.5 samples/s | 27.1 steps/s
[Step= 300] | Loss=0.14582 | acc=0.9804 | tpr=0.9644 | fpr=0.0193 | 6974.4 samples/s | 27.2 steps/s
[Step= 350] | Loss=0.14630 | acc=0.9803 | tpr=0.9649 | fpr=0.0195 | 6775.3 samples/s | 26.5 steps/s
[Step= 400] | Loss=0.14730 | acc=0.9800 | tpr=0.9633 | fpr=0.0197 | 6760.9 samples/s | 26.4 steps/s
[Step= 450] | Loss=0.15040 | acc=0.9797 | tpr=0.9606 | fpr=0.0199 | 6814.1 samples/s | 26.6 steps/s
[Step= 500] | Loss=0.14977 | acc=0.9797 | tpr=0.9608 | fpr=0.0199 | 6764.3 samples/s | 26.4 steps/s
[Step= 550] | Loss=0.14879 | acc=0.9799 | tpr=0.9594 | fpr=0.0197 | 12559.4 samples/s | 49.1 steps/s
Avg test loss: 0.14843, Avg test acc: 0.97993, Avg tpr: 0.95959, Avg fpr: 0.01971, total FA: 2736

server round 12/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=23.4] | Loss=0.00837 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.487 | L2-Norm(final)=5.636 | 3594.3 samples/s | 56.2 steps/s
[Step=24050 Epoch=23.5] | Loss=0.01488 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.515 | L2-Norm(final)=5.645 | 3830.1 samples/s | 59.8 steps/s
[Step=24100 Epoch=23.5] | Loss=0.01382 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.534 | L2-Norm(final)=5.656 | 4399.6 samples/s | 68.7 steps/s
[Step=24150 Epoch=23.6] | Loss=0.01365 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.550 | L2-Norm(final)=5.665 | 4360.3 samples/s | 68.1 steps/s
[Step=24200 Epoch=23.6] | Loss=0.01386 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.565 | L2-Norm(final)=5.672 | 4293.0 samples/s | 67.1 steps/s
[Step=24250 Epoch=23.7] | Loss=0.01480 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.578 | L2-Norm(final)=5.680 | 4350.3 samples/s | 68.0 steps/s
[Step=24300 Epoch=23.7] | Loss=0.01431 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.589 | L2-Norm(final)=5.687 | 4389.5 samples/s | 68.6 steps/s
[Step=24350 Epoch=23.8] | Loss=0.01390 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.600 | L2-Norm(final)=5.694 | 4352.9 samples/s | 68.0 steps/s
[Step=24400 Epoch=23.8] | Loss=0.01378 | Reg=0.00244 | acc=0.9688 | L2-Norm=15.611 | L2-Norm(final)=5.701 | 4348.1 samples/s | 67.9 steps/s
[Step=24450 Epoch=23.9] | Loss=0.01368 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.621 | L2-Norm(final)=5.708 | 4407.0 samples/s | 68.9 steps/s
[Step=24500 Epoch=23.9] | Loss=0.01370 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.630 | L2-Norm(final)=5.714 | 4343.9 samples/s | 67.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=23.9] | Loss=0.02383 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.722 | L2-Norm(final)=5.770 | 3386.3 samples/s | 52.9 steps/s
[Step=24550 Epoch=24.0] | Loss=0.01467 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.734 | L2-Norm(final)=5.776 | 3740.3 samples/s | 58.4 steps/s
[Step=24600 Epoch=24.0] | Loss=0.01593 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.748 | L2-Norm(final)=5.773 | 3927.2 samples/s | 61.4 steps/s
[Step=24650 Epoch=24.1] | Loss=0.01784 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.761 | L2-Norm(final)=5.770 | 3909.6 samples/s | 61.1 steps/s
[Step=24700 Epoch=24.1] | Loss=0.01749 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.775 | L2-Norm(final)=5.770 | 3907.5 samples/s | 61.1 steps/s
[Step=24750 Epoch=24.2] | Loss=0.01822 | Reg=0.00249 | acc=0.9688 | L2-Norm=15.788 | L2-Norm(final)=5.772 | 3903.6 samples/s | 61.0 steps/s
[Step=24800 Epoch=24.2] | Loss=0.01883 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.801 | L2-Norm(final)=5.771 | 3901.5 samples/s | 61.0 steps/s
[Step=24850 Epoch=24.3] | Loss=0.01913 | Reg=0.00250 | acc=0.9531 | L2-Norm=15.814 | L2-Norm(final)=5.771 | 3980.1 samples/s | 62.2 steps/s
[Step=24900 Epoch=24.3] | Loss=0.01963 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.825 | L2-Norm(final)=5.771 | 3990.0 samples/s | 62.3 steps/s
[Step=24950 Epoch=24.4] | Loss=0.01937 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.837 | L2-Norm(final)=5.771 | 3939.2 samples/s | 61.6 steps/s
[Step=25000 Epoch=24.4] | Loss=0.01896 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.848 | L2-Norm(final)=5.772 | 3917.6 samples/s | 61.2 steps/s
[Step=25050 Epoch=24.5] | Loss=0.01907 | Reg=0.00251 | acc=0.9375 | L2-Norm=15.858 | L2-Norm(final)=5.773 | 3920.2 samples/s | 61.3 steps/s
[Step=25100 Epoch=24.5] | Loss=0.01922 | Reg=0.00252 | acc=0.9688 | L2-Norm=15.869 | L2-Norm(final)=5.773 | 3940.2 samples/s | 61.6 steps/s
[Step=25150 Epoch=24.6] | Loss=0.01958 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.880 | L2-Norm(final)=5.773 | 3951.4 samples/s | 61.7 steps/s
[Step=25200 Epoch=24.6] | Loss=0.01992 | Reg=0.00253 | acc=0.9688 | L2-Norm=15.892 | L2-Norm(final)=5.773 | 3889.1 samples/s | 60.8 steps/s
[Step=25250 Epoch=24.7] | Loss=0.01999 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.904 | L2-Norm(final)=5.773 | 3936.1 samples/s | 61.5 steps/s
[Step=25300 Epoch=24.7] | Loss=0.02006 | Reg=0.00253 | acc=1.0000 | L2-Norm=15.915 | L2-Norm(final)=5.772 | 3959.1 samples/s | 61.9 steps/s
[Step=25350 Epoch=24.8] | Loss=0.01982 | Reg=0.00254 | acc=1.0000 | L2-Norm=15.927 | L2-Norm(final)=5.772 | 3963.3 samples/s | 61.9 steps/s
[Step=25400 Epoch=24.8] | Loss=0.01976 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.938 | L2-Norm(final)=5.773 | 3949.4 samples/s | 61.7 steps/s
[Step=25450 Epoch=24.8] | Loss=0.01966 | Reg=0.00254 | acc=0.9688 | L2-Norm=15.948 | L2-Norm(final)=5.772 | 3958.4 samples/s | 61.8 steps/s
[Step=25500 Epoch=24.9] | Loss=0.01976 | Reg=0.00255 | acc=0.9688 | L2-Norm=15.959 | L2-Norm(final)=5.772 | 4229.7 samples/s | 66.1 steps/s
[Step=25550 Epoch=24.9] | Loss=0.01947 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.970 | L2-Norm(final)=5.772 | 1637.4 samples/s | 25.6 steps/s
[Step=25600 Epoch=25.0] | Loss=0.01911 | Reg=0.00255 | acc=1.0000 | L2-Norm=15.980 | L2-Norm(final)=5.773 | 3945.9 samples/s | 61.7 steps/s
[Step=25650 Epoch=25.0] | Loss=0.01898 | Reg=0.00256 | acc=1.0000 | L2-Norm=15.990 | L2-Norm(final)=5.773 | 3864.6 samples/s | 60.4 steps/s
[Step=25700 Epoch=25.1] | Loss=0.01884 | Reg=0.00256 | acc=0.9688 | L2-Norm=15.999 | L2-Norm(final)=5.773 | 3919.3 samples/s | 61.2 steps/s
[Step=25750 Epoch=25.1] | Loss=0.01893 | Reg=0.00256 | acc=1.0000 | L2-Norm=16.008 | L2-Norm(final)=5.773 | 3926.5 samples/s | 61.4 steps/s
[Step=25800 Epoch=25.2] | Loss=0.01875 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.017 | L2-Norm(final)=5.773 | 3974.0 samples/s | 62.1 steps/s
[Step=25850 Epoch=25.2] | Loss=0.01868 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.026 | L2-Norm(final)=5.773 | 3957.6 samples/s | 61.8 steps/s
[Step=25900 Epoch=25.3] | Loss=0.01857 | Reg=0.00257 | acc=0.9531 | L2-Norm=16.035 | L2-Norm(final)=5.774 | 3923.0 samples/s | 61.3 steps/s
[Step=25950 Epoch=25.3] | Loss=0.01836 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.043 | L2-Norm(final)=5.774 | 3929.3 samples/s | 61.4 steps/s
[Step=26000 Epoch=25.4] | Loss=0.01838 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.051 | L2-Norm(final)=5.774 | 3937.7 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step26000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=24001 Epoch=45.2] | Loss=0.00027 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.487 | L2-Norm(final)=4.426 | 3329.2 samples/s | 52.0 steps/s
[Step=24050 Epoch=45.3] | Loss=0.00150 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.485 | L2-Norm(final)=4.437 | 3763.6 samples/s | 58.8 steps/s
[Step=24100 Epoch=45.4] | Loss=0.00113 | Reg=0.00241 | acc=1.0000 | L2-Norm=15.529 | L2-Norm(final)=4.443 | 4005.7 samples/s | 62.6 steps/s
[Step=24150 Epoch=45.5] | Loss=0.00132 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.551 | L2-Norm(final)=4.450 | 4094.9 samples/s | 64.0 steps/s
[Step=24200 Epoch=45.6] | Loss=0.00153 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=4.450 | 4102.2 samples/s | 64.1 steps/s
[Step=24250 Epoch=45.7] | Loss=0.00127 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.602 | L2-Norm(final)=4.452 | 4172.3 samples/s | 65.2 steps/s
[Step=24300 Epoch=45.8] | Loss=0.00111 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.617 | L2-Norm(final)=4.455 | 4020.3 samples/s | 62.8 steps/s
[Step=24350 Epoch=45.9] | Loss=0.00096 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.626 | L2-Norm(final)=4.457 | 4069.1 samples/s | 63.6 steps/s
[Step=24400 Epoch=46.0] | Loss=0.00087 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.629 | L2-Norm(final)=4.460 | 4123.4 samples/s | 64.4 steps/s
[Step=24450 Epoch=46.1] | Loss=0.00078 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.630 | L2-Norm(final)=4.462 | 4143.4 samples/s | 64.7 steps/s
[Step=24500 Epoch=46.2] | Loss=0.00070 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.630 | L2-Norm(final)=4.465 | 4200.8 samples/s | 65.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=24501 Epoch=46.2] | Loss=0.00000 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.612 | L2-Norm(final)=4.488 | 3411.5 samples/s | 53.3 steps/s
[Step=24550 Epoch=46.3] | Loss=0.00006 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.591 | L2-Norm(final)=4.490 | 3412.1 samples/s | 53.3 steps/s
[Step=24600 Epoch=46.4] | Loss=0.00053 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.570 | L2-Norm(final)=4.493 | 3693.0 samples/s | 57.7 steps/s
[Step=24650 Epoch=46.5] | Loss=0.00777 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.625 | L2-Norm(final)=4.473 | 3697.6 samples/s | 57.8 steps/s
[Step=24700 Epoch=46.6] | Loss=0.00686 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.688 | L2-Norm(final)=4.450 | 3735.6 samples/s | 58.4 steps/s
[Step=24750 Epoch=46.7] | Loss=0.00569 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.726 | L2-Norm(final)=4.435 | 3659.9 samples/s | 57.2 steps/s
[Step=24800 Epoch=46.7] | Loss=0.00482 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.751 | L2-Norm(final)=4.426 | 3715.7 samples/s | 58.1 steps/s
[Step=24850 Epoch=46.8] | Loss=0.00423 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.767 | L2-Norm(final)=4.419 | 3759.3 samples/s | 58.7 steps/s
[Step=24900 Epoch=46.9] | Loss=0.00374 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=4.415 | 3703.5 samples/s | 57.9 steps/s
[Step=24950 Epoch=47.0] | Loss=0.00341 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.785 | L2-Norm(final)=4.412 | 3718.7 samples/s | 58.1 steps/s
[Step=25000 Epoch=47.1] | Loss=0.00307 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.790 | L2-Norm(final)=4.410 | 3768.8 samples/s | 58.9 steps/s
[Step=25050 Epoch=47.2] | Loss=0.00287 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.792 | L2-Norm(final)=4.408 | 1663.7 samples/s | 26.0 steps/s
[Step=25100 Epoch=47.3] | Loss=0.00264 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.793 | L2-Norm(final)=4.406 | 3761.4 samples/s | 58.8 steps/s
[Step=25150 Epoch=47.4] | Loss=0.00244 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.793 | L2-Norm(final)=4.405 | 3721.5 samples/s | 58.1 steps/s
[Step=25200 Epoch=47.5] | Loss=0.00227 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.791 | L2-Norm(final)=4.404 | 3734.7 samples/s | 58.4 steps/s
[Step=25250 Epoch=47.6] | Loss=0.00212 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.789 | L2-Norm(final)=4.403 | 3749.1 samples/s | 58.6 steps/s
[Step=25300 Epoch=47.7] | Loss=0.00199 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.786 | L2-Norm(final)=4.402 | 3697.9 samples/s | 57.8 steps/s
[Step=25350 Epoch=47.8] | Loss=0.00187 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.782 | L2-Norm(final)=4.402 | 3769.8 samples/s | 58.9 steps/s
[Step=25400 Epoch=47.9] | Loss=0.00177 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.778 | L2-Norm(final)=4.401 | 3708.6 samples/s | 57.9 steps/s
[Step=25450 Epoch=48.0] | Loss=0.00168 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.773 | L2-Norm(final)=4.401 | 3748.5 samples/s | 58.6 steps/s
[Step=25500 Epoch=48.1] | Loss=0.00160 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.768 | L2-Norm(final)=4.401 | 3718.1 samples/s | 58.1 steps/s
[Step=25550 Epoch=48.2] | Loss=0.00153 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.763 | L2-Norm(final)=4.401 | 4677.7 samples/s | 73.1 steps/s
[Step=25600 Epoch=48.3] | Loss=0.00146 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.757 | L2-Norm(final)=4.401 | 1505.8 samples/s | 23.5 steps/s
[Step=25650 Epoch=48.4] | Loss=0.00140 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.751 | L2-Norm(final)=4.401 | 3706.4 samples/s | 57.9 steps/s
[Step=25700 Epoch=48.4] | Loss=0.00134 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.745 | L2-Norm(final)=4.401 | 3729.7 samples/s | 58.3 steps/s
[Step=25750 Epoch=48.5] | Loss=0.00128 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.739 | L2-Norm(final)=4.402 | 3718.5 samples/s | 58.1 steps/s
[Step=25800 Epoch=48.6] | Loss=0.00124 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=4.402 | 3698.0 samples/s | 57.8 steps/s
[Step=25850 Epoch=48.7] | Loss=0.00119 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.725 | L2-Norm(final)=4.402 | 3769.5 samples/s | 58.9 steps/s
[Step=25900 Epoch=48.8] | Loss=0.00115 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.718 | L2-Norm(final)=4.403 | 3731.9 samples/s | 58.3 steps/s
[Step=25950 Epoch=48.9] | Loss=0.00111 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.711 | L2-Norm(final)=4.403 | 3726.7 samples/s | 58.2 steps/s
[Step=26000 Epoch=49.0] | Loss=0.00107 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.703 | L2-Norm(final)=4.403 | 3751.4 samples/s | 58.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step26000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05282 | acc=0.9698 | tpr=0.9732 | fpr=0.0377 | 3625.6 samples/s | 14.2 steps/s
Avg test loss: 0.05266, Avg test acc: 0.96915, Avg tpr: 0.97231, Avg fpr: 0.03782, total FA: 295

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.62047 | acc=0.3003 | tpr=0.0260 | fpr=0.1041 | 3611.0 samples/s | 14.1 steps/s
Avg test loss: 6.62287, Avg test acc: 0.29902, Avg tpr: 0.02681, Avg fpr: 0.10229, total FA: 798

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.91318 | acc=0.1348 | tpr=0.6947 | fpr=0.8753 | 3625.7 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.90984 | acc=0.1377 | tpr=0.7164 | fpr=0.8731 | 6977.5 samples/s | 27.3 steps/s
[Step= 150] | Loss=4.90974 | acc=0.1364 | tpr=0.7406 | fpr=0.8747 | 6828.8 samples/s | 26.7 steps/s
[Step= 200] | Loss=4.89523 | acc=0.1366 | tpr=0.7290 | fpr=0.8741 | 6963.0 samples/s | 27.2 steps/s
[Step= 250] | Loss=4.89811 | acc=0.1367 | tpr=0.7284 | fpr=0.8741 | 6871.4 samples/s | 26.8 steps/s
[Step= 300] | Loss=4.89142 | acc=0.1370 | tpr=0.7251 | fpr=0.8737 | 6791.5 samples/s | 26.5 steps/s
[Step= 350] | Loss=4.88692 | acc=0.1369 | tpr=0.7314 | fpr=0.8739 | 7124.6 samples/s | 27.8 steps/s
[Step= 400] | Loss=4.89080 | acc=0.1367 | tpr=0.7287 | fpr=0.8740 | 6796.2 samples/s | 26.5 steps/s
[Step= 450] | Loss=4.89125 | acc=0.1368 | tpr=0.7322 | fpr=0.8740 | 6609.2 samples/s | 25.8 steps/s
[Step= 500] | Loss=4.89375 | acc=0.1372 | tpr=0.7339 | fpr=0.8735 | 6808.1 samples/s | 26.6 steps/s
[Step= 550] | Loss=4.89569 | acc=0.1372 | tpr=0.7378 | fpr=0.8737 | 12646.2 samples/s | 49.4 steps/s
Avg test loss: 4.89712, Avg test acc: 0.13721, Avg tpr: 0.73811, Avg fpr: 0.87371, total FA: 121313

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13924 | acc=0.9825 | tpr=0.9469 | fpr=0.0169 | 3587.6 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.14701 | acc=0.9812 | tpr=0.9616 | fpr=0.0185 | 6893.0 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.15060 | acc=0.9801 | tpr=0.9611 | fpr=0.0196 | 6832.5 samples/s | 26.7 steps/s
[Step= 200] | Loss=0.15240 | acc=0.9801 | tpr=0.9639 | fpr=0.0196 | 6743.6 samples/s | 26.3 steps/s
[Step= 250] | Loss=0.14996 | acc=0.9801 | tpr=0.9633 | fpr=0.0196 | 6860.3 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.15246 | acc=0.9798 | tpr=0.9585 | fpr=0.0198 | 6865.5 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.15369 | acc=0.9795 | tpr=0.9593 | fpr=0.0202 | 6882.0 samples/s | 26.9 steps/s
[Step= 400] | Loss=0.15531 | acc=0.9793 | tpr=0.9590 | fpr=0.0203 | 6704.1 samples/s | 26.2 steps/s
[Step= 450] | Loss=0.15832 | acc=0.9789 | tpr=0.9572 | fpr=0.0207 | 7007.1 samples/s | 27.4 steps/s
[Step= 500] | Loss=0.15737 | acc=0.9790 | tpr=0.9586 | fpr=0.0206 | 6705.1 samples/s | 26.2 steps/s
[Step= 550] | Loss=0.15644 | acc=0.9792 | tpr=0.9578 | fpr=0.0204 | 12572.6 samples/s | 49.1 steps/s
Avg test loss: 0.15615, Avg test acc: 0.97924, Avg tpr: 0.95800, Avg fpr: 0.02037, total FA: 2829

server round 13/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=25.4] | Loss=0.02144 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.596 | L2-Norm(final)=5.785 | 3156.4 samples/s | 49.3 steps/s
[Step=26050 Epoch=25.4] | Loss=0.02391 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.634 | L2-Norm(final)=5.807 | 4261.4 samples/s | 66.6 steps/s
[Step=26100 Epoch=25.5] | Loss=0.02412 | Reg=0.00245 | acc=0.9688 | L2-Norm=15.665 | L2-Norm(final)=5.829 | 4262.8 samples/s | 66.6 steps/s
[Step=26150 Epoch=25.5] | Loss=0.02458 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.692 | L2-Norm(final)=5.843 | 4326.9 samples/s | 67.6 steps/s
[Step=26200 Epoch=25.6] | Loss=0.02394 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.713 | L2-Norm(final)=5.857 | 4443.5 samples/s | 69.4 steps/s
[Step=26250 Epoch=25.6] | Loss=0.02377 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.732 | L2-Norm(final)=5.872 | 4307.4 samples/s | 67.3 steps/s
[Step=26300 Epoch=25.7] | Loss=0.02366 | Reg=0.00248 | acc=0.9531 | L2-Norm=15.750 | L2-Norm(final)=5.883 | 4400.6 samples/s | 68.8 steps/s
[Step=26350 Epoch=25.7] | Loss=0.02344 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.767 | L2-Norm(final)=5.894 | 4262.5 samples/s | 66.6 steps/s
[Step=26400 Epoch=25.8] | Loss=0.02292 | Reg=0.00249 | acc=0.9844 | L2-Norm=15.784 | L2-Norm(final)=5.907 | 4408.7 samples/s | 68.9 steps/s
[Step=26450 Epoch=25.8] | Loss=0.02265 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.800 | L2-Norm(final)=5.918 | 4461.6 samples/s | 69.7 steps/s
[Step=26500 Epoch=25.9] | Loss=0.02240 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.815 | L2-Norm(final)=5.930 | 4294.6 samples/s | 67.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=25.9] | Loss=0.01561 | Reg=0.00255 | acc=0.9844 | L2-Norm=15.966 | L2-Norm(final)=6.037 | 3264.0 samples/s | 51.0 steps/s
[Step=26550 Epoch=25.9] | Loss=0.02135 | Reg=0.00256 | acc=0.9844 | L2-Norm=15.989 | L2-Norm(final)=6.043 | 3783.0 samples/s | 59.1 steps/s
[Step=26600 Epoch=26.0] | Loss=0.02222 | Reg=0.00256 | acc=0.9844 | L2-Norm=16.013 | L2-Norm(final)=6.037 | 3928.2 samples/s | 61.4 steps/s
[Step=26650 Epoch=26.0] | Loss=0.02310 | Reg=0.00257 | acc=1.0000 | L2-Norm=16.035 | L2-Norm(final)=6.031 | 3876.9 samples/s | 60.6 steps/s
[Step=26700 Epoch=26.1] | Loss=0.02130 | Reg=0.00258 | acc=1.0000 | L2-Norm=16.051 | L2-Norm(final)=6.026 | 3925.6 samples/s | 61.3 steps/s
[Step=26750 Epoch=26.1] | Loss=0.02129 | Reg=0.00258 | acc=0.9688 | L2-Norm=16.065 | L2-Norm(final)=6.024 | 3920.5 samples/s | 61.3 steps/s
[Step=26800 Epoch=26.2] | Loss=0.02181 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.079 | L2-Norm(final)=6.023 | 3940.0 samples/s | 61.6 steps/s
[Step=26850 Epoch=26.2] | Loss=0.02232 | Reg=0.00259 | acc=0.9844 | L2-Norm=16.093 | L2-Norm(final)=6.021 | 3950.7 samples/s | 61.7 steps/s
[Step=26900 Epoch=26.3] | Loss=0.02224 | Reg=0.00259 | acc=0.9688 | L2-Norm=16.106 | L2-Norm(final)=6.019 | 3977.2 samples/s | 62.1 steps/s
[Step=26950 Epoch=26.3] | Loss=0.02199 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.117 | L2-Norm(final)=6.018 | 3988.6 samples/s | 62.3 steps/s
[Step=27000 Epoch=26.4] | Loss=0.02170 | Reg=0.00260 | acc=1.0000 | L2-Norm=16.128 | L2-Norm(final)=6.019 | 3950.3 samples/s | 61.7 steps/s
[Step=27050 Epoch=26.4] | Loss=0.02150 | Reg=0.00260 | acc=0.9844 | L2-Norm=16.137 | L2-Norm(final)=6.019 | 3988.8 samples/s | 62.3 steps/s
[Step=27100 Epoch=26.5] | Loss=0.02118 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.145 | L2-Norm(final)=6.020 | 3980.6 samples/s | 62.2 steps/s
[Step=27150 Epoch=26.5] | Loss=0.02101 | Reg=0.00261 | acc=0.9844 | L2-Norm=16.154 | L2-Norm(final)=6.021 | 3965.4 samples/s | 62.0 steps/s
[Step=27200 Epoch=26.6] | Loss=0.02065 | Reg=0.00261 | acc=0.9688 | L2-Norm=16.162 | L2-Norm(final)=6.022 | 3946.6 samples/s | 61.7 steps/s
[Step=27250 Epoch=26.6] | Loss=0.02036 | Reg=0.00261 | acc=1.0000 | L2-Norm=16.170 | L2-Norm(final)=6.023 | 3981.0 samples/s | 62.2 steps/s
[Step=27300 Epoch=26.7] | Loss=0.02033 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.179 | L2-Norm(final)=6.024 | 3958.9 samples/s | 61.9 steps/s
[Step=27350 Epoch=26.7] | Loss=0.02026 | Reg=0.00262 | acc=0.9844 | L2-Norm=16.186 | L2-Norm(final)=6.025 | 3905.1 samples/s | 61.0 steps/s
[Step=27400 Epoch=26.8] | Loss=0.02009 | Reg=0.00262 | acc=1.0000 | L2-Norm=16.194 | L2-Norm(final)=6.025 | 3954.5 samples/s | 61.8 steps/s
[Step=27450 Epoch=26.8] | Loss=0.01984 | Reg=0.00262 | acc=0.9688 | L2-Norm=16.201 | L2-Norm(final)=6.026 | 3956.8 samples/s | 61.8 steps/s
[Step=27500 Epoch=26.8] | Loss=0.01988 | Reg=0.00263 | acc=0.9688 | L2-Norm=16.209 | L2-Norm(final)=6.027 | 4268.5 samples/s | 66.7 steps/s
[Step=27550 Epoch=26.9] | Loss=0.01980 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.216 | L2-Norm(final)=6.028 | 1653.6 samples/s | 25.8 steps/s
[Step=27600 Epoch=26.9] | Loss=0.01941 | Reg=0.00263 | acc=0.9844 | L2-Norm=16.223 | L2-Norm(final)=6.029 | 3931.2 samples/s | 61.4 steps/s
[Step=27650 Epoch=27.0] | Loss=0.01912 | Reg=0.00263 | acc=1.0000 | L2-Norm=16.230 | L2-Norm(final)=6.030 | 3963.7 samples/s | 61.9 steps/s
[Step=27700 Epoch=27.0] | Loss=0.01887 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.236 | L2-Norm(final)=6.031 | 3898.9 samples/s | 60.9 steps/s
[Step=27750 Epoch=27.1] | Loss=0.01878 | Reg=0.00264 | acc=0.9531 | L2-Norm=16.243 | L2-Norm(final)=6.031 | 3954.7 samples/s | 61.8 steps/s
[Step=27800 Epoch=27.1] | Loss=0.01868 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.249 | L2-Norm(final)=6.032 | 3969.6 samples/s | 62.0 steps/s
[Step=27850 Epoch=27.2] | Loss=0.01845 | Reg=0.00264 | acc=0.9844 | L2-Norm=16.255 | L2-Norm(final)=6.033 | 3927.4 samples/s | 61.4 steps/s
[Step=27900 Epoch=27.2] | Loss=0.01825 | Reg=0.00264 | acc=1.0000 | L2-Norm=16.262 | L2-Norm(final)=6.034 | 3955.5 samples/s | 61.8 steps/s
[Step=27950 Epoch=27.3] | Loss=0.01817 | Reg=0.00265 | acc=1.0000 | L2-Norm=16.268 | L2-Norm(final)=6.035 | 3908.3 samples/s | 61.1 steps/s
[Step=28000 Epoch=27.3] | Loss=0.01815 | Reg=0.00265 | acc=0.9844 | L2-Norm=16.274 | L2-Norm(final)=6.035 | 3990.2 samples/s | 62.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step28000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=26001 Epoch=49.0] | Loss=0.00028 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.596 | L2-Norm(final)=4.414 | 3484.9 samples/s | 54.5 steps/s
[Step=26050 Epoch=49.1] | Loss=0.00042 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.579 | L2-Norm(final)=4.417 | 3728.5 samples/s | 58.3 steps/s
[Step=26100 Epoch=49.2] | Loss=0.00035 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=4.421 | 4076.4 samples/s | 63.7 steps/s
[Step=26150 Epoch=49.3] | Loss=0.00034 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.567 | L2-Norm(final)=4.424 | 4145.1 samples/s | 64.8 steps/s
[Step=26200 Epoch=49.4] | Loss=0.00031 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.566 | L2-Norm(final)=4.428 | 4197.5 samples/s | 65.6 steps/s
[Step=26250 Epoch=49.5] | Loss=0.00027 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.563 | L2-Norm(final)=4.431 | 4131.6 samples/s | 64.6 steps/s
[Step=26300 Epoch=49.6] | Loss=0.00025 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.559 | L2-Norm(final)=4.435 | 4110.2 samples/s | 64.2 steps/s
[Step=26350 Epoch=49.7] | Loss=0.00022 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.554 | L2-Norm(final)=4.438 | 4229.5 samples/s | 66.1 steps/s
[Step=26400 Epoch=49.8] | Loss=0.00021 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.549 | L2-Norm(final)=4.442 | 4086.8 samples/s | 63.9 steps/s
[Step=26450 Epoch=49.9] | Loss=0.00020 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.545 | L2-Norm(final)=4.445 | 4170.4 samples/s | 65.2 steps/s
[Step=26500 Epoch=50.0] | Loss=0.00019 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.541 | L2-Norm(final)=4.449 | 4147.2 samples/s | 64.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=26501 Epoch=50.0] | Loss=0.00002 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.492 | L2-Norm(final)=4.480 | 3306.0 samples/s | 51.7 steps/s
[Step=26550 Epoch=50.0] | Loss=0.00004 | Reg=0.00240 | acc=1.0000 | L2-Norm=15.480 | L2-Norm(final)=4.482 | 3473.8 samples/s | 54.3 steps/s
[Step=26600 Epoch=50.1] | Loss=0.00004 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.466 | L2-Norm(final)=4.484 | 3736.4 samples/s | 58.4 steps/s
[Step=26650 Epoch=50.2] | Loss=0.00003 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.452 | L2-Norm(final)=4.486 | 3697.7 samples/s | 57.8 steps/s
[Step=26700 Epoch=50.3] | Loss=0.00003 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.439 | L2-Norm(final)=4.487 | 3792.3 samples/s | 59.3 steps/s
[Step=26750 Epoch=50.4] | Loss=0.00003 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.425 | L2-Norm(final)=4.489 | 3701.9 samples/s | 57.8 steps/s
[Step=26800 Epoch=50.5] | Loss=0.00002 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.411 | L2-Norm(final)=4.490 | 3744.1 samples/s | 58.5 steps/s
[Step=26850 Epoch=50.6] | Loss=0.00003 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.398 | L2-Norm(final)=4.492 | 3738.8 samples/s | 58.4 steps/s
[Step=26900 Epoch=50.7] | Loss=0.00002 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.384 | L2-Norm(final)=4.493 | 3773.0 samples/s | 59.0 steps/s
[Step=26950 Epoch=50.8] | Loss=0.00002 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.371 | L2-Norm(final)=4.494 | 3685.8 samples/s | 57.6 steps/s
[Step=27000 Epoch=50.9] | Loss=0.00002 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.357 | L2-Norm(final)=4.496 | 3791.5 samples/s | 59.2 steps/s
[Step=27050 Epoch=51.0] | Loss=0.00002 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.343 | L2-Norm(final)=4.497 | 1617.5 samples/s | 25.3 steps/s
[Step=27100 Epoch=51.1] | Loss=0.00002 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.330 | L2-Norm(final)=4.498 | 3744.3 samples/s | 58.5 steps/s
[Step=27150 Epoch=51.2] | Loss=0.00002 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.316 | L2-Norm(final)=4.499 | 3719.5 samples/s | 58.1 steps/s
[Step=27200 Epoch=51.3] | Loss=0.00002 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.302 | L2-Norm(final)=4.499 | 3739.4 samples/s | 58.4 steps/s
[Step=27250 Epoch=51.4] | Loss=0.00002 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=4.500 | 3727.4 samples/s | 58.2 steps/s
[Step=27300 Epoch=51.5] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.273 | L2-Norm(final)=4.501 | 3765.0 samples/s | 58.8 steps/s
[Step=27350 Epoch=51.6] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=4.502 | 3735.5 samples/s | 58.4 steps/s
[Step=27400 Epoch=51.6] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.245 | L2-Norm(final)=4.502 | 3716.6 samples/s | 58.1 steps/s
[Step=27450 Epoch=51.7] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.231 | L2-Norm(final)=4.503 | 3768.1 samples/s | 58.9 steps/s
[Step=27500 Epoch=51.8] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.216 | L2-Norm(final)=4.504 | 3764.1 samples/s | 58.8 steps/s
[Step=27550 Epoch=51.9] | Loss=0.00001 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.201 | L2-Norm(final)=4.505 | 4601.9 samples/s | 71.9 steps/s
[Step=27600 Epoch=52.0] | Loss=0.00001 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.187 | L2-Norm(final)=4.505 | 1540.5 samples/s | 24.1 steps/s
[Step=27650 Epoch=52.1] | Loss=0.00001 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.172 | L2-Norm(final)=4.506 | 3722.7 samples/s | 58.2 steps/s
[Step=27700 Epoch=52.2] | Loss=0.00001 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.157 | L2-Norm(final)=4.506 | 3701.9 samples/s | 57.8 steps/s
[Step=27750 Epoch=52.3] | Loss=0.00001 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.142 | L2-Norm(final)=4.507 | 3706.8 samples/s | 57.9 steps/s
[Step=27800 Epoch=52.4] | Loss=0.00001 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.127 | L2-Norm(final)=4.508 | 3755.5 samples/s | 58.7 steps/s
[Step=27850 Epoch=52.5] | Loss=0.00001 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=4.508 | 3774.6 samples/s | 59.0 steps/s
[Step=27900 Epoch=52.6] | Loss=0.00001 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.097 | L2-Norm(final)=4.509 | 3743.5 samples/s | 58.5 steps/s
[Step=27950 Epoch=52.7] | Loss=0.00001 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.082 | L2-Norm(final)=4.509 | 3745.5 samples/s | 58.5 steps/s
[Step=28000 Epoch=52.8] | Loss=0.00001 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=4.510 | 3749.9 samples/s | 58.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step28000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05263 | acc=0.9721 | tpr=0.9789 | fpr=0.0426 | 3613.4 samples/s | 14.1 steps/s
Avg test loss: 0.05165, Avg test acc: 0.97067, Avg tpr: 0.97785, Avg fpr: 0.04512, total FA: 352

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.35544 | acc=0.3047 | tpr=0.0306 | fpr=0.1001 | 3590.5 samples/s | 14.0 steps/s
Avg test loss: 6.34679, Avg test acc: 0.30419, Avg tpr: 0.03305, Avg fpr: 0.09947, total FA: 776

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.04683 | acc=0.1314 | tpr=0.7212 | fpr=0.8792 | 3662.3 samples/s | 14.3 steps/s
[Step= 100] | Loss=5.04690 | acc=0.1330 | tpr=0.7207 | fpr=0.8780 | 6720.2 samples/s | 26.3 steps/s
[Step= 150] | Loss=5.05323 | acc=0.1319 | tpr=0.7363 | fpr=0.8792 | 6662.7 samples/s | 26.0 steps/s
[Step= 200] | Loss=5.03929 | acc=0.1318 | tpr=0.7213 | fpr=0.8790 | 6991.8 samples/s | 27.3 steps/s
[Step= 250] | Loss=5.04438 | acc=0.1321 | tpr=0.7301 | fpr=0.8788 | 6919.9 samples/s | 27.0 steps/s
[Step= 300] | Loss=5.04047 | acc=0.1323 | tpr=0.7280 | fpr=0.8786 | 6612.4 samples/s | 25.8 steps/s
[Step= 350] | Loss=5.03764 | acc=0.1323 | tpr=0.7289 | fpr=0.8785 | 6932.4 samples/s | 27.1 steps/s
[Step= 400] | Loss=5.04283 | acc=0.1322 | tpr=0.7281 | fpr=0.8786 | 6588.8 samples/s | 25.7 steps/s
[Step= 450] | Loss=5.04300 | acc=0.1322 | tpr=0.7303 | fpr=0.8787 | 6764.3 samples/s | 26.4 steps/s
[Step= 500] | Loss=5.04386 | acc=0.1325 | tpr=0.7326 | fpr=0.8784 | 6681.9 samples/s | 26.1 steps/s
[Step= 550] | Loss=5.04352 | acc=0.1324 | tpr=0.7362 | fpr=0.8785 | 12971.5 samples/s | 50.7 steps/s
Avg test loss: 5.04452, Avg test acc: 0.13235, Avg tpr: 0.73574, Avg fpr: 0.87862, total FA: 121994

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13248 | acc=0.9822 | tpr=0.9646 | fpr=0.0175 | 3585.0 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.14060 | acc=0.9811 | tpr=0.9680 | fpr=0.0187 | 6942.6 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.14341 | acc=0.9804 | tpr=0.9669 | fpr=0.0194 | 6992.2 samples/s | 27.3 steps/s
[Step= 200] | Loss=0.14475 | acc=0.9803 | tpr=0.9694 | fpr=0.0195 | 6735.1 samples/s | 26.3 steps/s
[Step= 250] | Loss=0.14320 | acc=0.9803 | tpr=0.9677 | fpr=0.0195 | 7033.6 samples/s | 27.5 steps/s
[Step= 300] | Loss=0.14569 | acc=0.9798 | tpr=0.9636 | fpr=0.0199 | 6835.7 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.14630 | acc=0.9796 | tpr=0.9637 | fpr=0.0201 | 7014.1 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.14759 | acc=0.9794 | tpr=0.9639 | fpr=0.0203 | 6661.8 samples/s | 26.0 steps/s
[Step= 450] | Loss=0.15078 | acc=0.9790 | tpr=0.9611 | fpr=0.0206 | 6767.6 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.15000 | acc=0.9791 | tpr=0.9612 | fpr=0.0206 | 6936.4 samples/s | 27.1 steps/s
[Step= 550] | Loss=0.14891 | acc=0.9793 | tpr=0.9610 | fpr=0.0204 | 12443.7 samples/s | 48.6 steps/s
Avg test loss: 0.14856, Avg test acc: 0.97932, Avg tpr: 0.96117, Avg fpr: 0.02035, total FA: 2826

server round 14/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=27.3] | Loss=0.00391 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=6.050 | 3242.8 samples/s | 50.7 steps/s
[Step=28050 Epoch=27.4] | Loss=0.01404 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.351 | L2-Norm(final)=6.061 | 4125.0 samples/s | 64.5 steps/s
[Step=28100 Epoch=27.4] | Loss=0.01358 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.369 | L2-Norm(final)=6.073 | 4409.3 samples/s | 68.9 steps/s
[Step=28150 Epoch=27.5] | Loss=0.01330 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.383 | L2-Norm(final)=6.084 | 4329.5 samples/s | 67.6 steps/s
[Step=28200 Epoch=27.5] | Loss=0.01327 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.396 | L2-Norm(final)=6.094 | 4368.8 samples/s | 68.3 steps/s
[Step=28250 Epoch=27.6] | Loss=0.01292 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.408 | L2-Norm(final)=6.101 | 4362.6 samples/s | 68.2 steps/s
[Step=28300 Epoch=27.6] | Loss=0.01285 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.420 | L2-Norm(final)=6.109 | 4360.8 samples/s | 68.1 steps/s
[Step=28350 Epoch=27.7] | Loss=0.01242 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.430 | L2-Norm(final)=6.116 | 4453.8 samples/s | 69.6 steps/s
[Step=28400 Epoch=27.7] | Loss=0.01247 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.439 | L2-Norm(final)=6.123 | 4478.7 samples/s | 70.0 steps/s
[Step=28450 Epoch=27.8] | Loss=0.01247 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.448 | L2-Norm(final)=6.129 | 4377.0 samples/s | 68.4 steps/s
[Step=28500 Epoch=27.8] | Loss=0.01256 | Reg=0.00239 | acc=1.0000 | L2-Norm=15.457 | L2-Norm(final)=6.135 | 4356.8 samples/s | 68.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=27.8] | Loss=0.00790 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.541 | L2-Norm(final)=6.194 | 3091.7 samples/s | 48.3 steps/s
[Step=28550 Epoch=27.9] | Loss=0.01289 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.555 | L2-Norm(final)=6.197 | 4015.6 samples/s | 62.7 steps/s
[Step=28600 Epoch=27.9] | Loss=0.01474 | Reg=0.00242 | acc=1.0000 | L2-Norm=15.571 | L2-Norm(final)=6.195 | 3913.5 samples/s | 61.1 steps/s
[Step=28650 Epoch=28.0] | Loss=0.01503 | Reg=0.00243 | acc=0.9688 | L2-Norm=15.586 | L2-Norm(final)=6.193 | 3887.2 samples/s | 60.7 steps/s
[Step=28700 Epoch=28.0] | Loss=0.01543 | Reg=0.00243 | acc=0.9844 | L2-Norm=15.602 | L2-Norm(final)=6.193 | 3950.4 samples/s | 61.7 steps/s
[Step=28750 Epoch=28.1] | Loss=0.01603 | Reg=0.00244 | acc=1.0000 | L2-Norm=15.617 | L2-Norm(final)=6.193 | 3915.2 samples/s | 61.2 steps/s
[Step=28800 Epoch=28.1] | Loss=0.01638 | Reg=0.00244 | acc=0.9531 | L2-Norm=15.630 | L2-Norm(final)=6.193 | 3927.4 samples/s | 61.4 steps/s
[Step=28850 Epoch=28.2] | Loss=0.01689 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.643 | L2-Norm(final)=6.193 | 3990.6 samples/s | 62.4 steps/s
[Step=28900 Epoch=28.2] | Loss=0.01698 | Reg=0.00245 | acc=0.9531 | L2-Norm=15.656 | L2-Norm(final)=6.192 | 3967.6 samples/s | 62.0 steps/s
[Step=28950 Epoch=28.3] | Loss=0.01721 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.668 | L2-Norm(final)=6.192 | 4000.1 samples/s | 62.5 steps/s
[Step=29000 Epoch=28.3] | Loss=0.01702 | Reg=0.00246 | acc=0.9844 | L2-Norm=15.680 | L2-Norm(final)=6.192 | 3945.1 samples/s | 61.6 steps/s
[Step=29050 Epoch=28.4] | Loss=0.01717 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.692 | L2-Norm(final)=6.192 | 3982.0 samples/s | 62.2 steps/s
[Step=29100 Epoch=28.4] | Loss=0.01728 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.704 | L2-Norm(final)=6.191 | 3970.1 samples/s | 62.0 steps/s
[Step=29150 Epoch=28.5] | Loss=0.01751 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.715 | L2-Norm(final)=6.191 | 3973.7 samples/s | 62.1 steps/s
[Step=29200 Epoch=28.5] | Loss=0.01745 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.725 | L2-Norm(final)=6.191 | 3945.5 samples/s | 61.6 steps/s
[Step=29250 Epoch=28.6] | Loss=0.01755 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=6.191 | 3996.4 samples/s | 62.4 steps/s
[Step=29300 Epoch=28.6] | Loss=0.01764 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.746 | L2-Norm(final)=6.190 | 3992.7 samples/s | 62.4 steps/s
[Step=29350 Epoch=28.7] | Loss=0.01767 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=6.191 | 3969.9 samples/s | 62.0 steps/s
[Step=29400 Epoch=28.7] | Loss=0.01776 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.766 | L2-Norm(final)=6.191 | 3928.6 samples/s | 61.4 steps/s
[Step=29450 Epoch=28.8] | Loss=0.01796 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.776 | L2-Norm(final)=6.191 | 3929.5 samples/s | 61.4 steps/s
[Step=29500 Epoch=28.8] | Loss=0.01786 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.786 | L2-Norm(final)=6.191 | 4222.0 samples/s | 66.0 steps/s
[Step=29550 Epoch=28.9] | Loss=0.01789 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.796 | L2-Norm(final)=6.191 | 1654.4 samples/s | 25.8 steps/s
[Step=29600 Epoch=28.9] | Loss=0.01774 | Reg=0.00250 | acc=0.9844 | L2-Norm=15.807 | L2-Norm(final)=6.191 | 3911.8 samples/s | 61.1 steps/s
[Step=29650 Epoch=28.9] | Loss=0.01746 | Reg=0.00250 | acc=1.0000 | L2-Norm=15.817 | L2-Norm(final)=6.192 | 3967.3 samples/s | 62.0 steps/s
[Step=29700 Epoch=29.0] | Loss=0.01721 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.827 | L2-Norm(final)=6.193 | 3912.6 samples/s | 61.1 steps/s
[Step=29750 Epoch=29.0] | Loss=0.01695 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.836 | L2-Norm(final)=6.193 | 3926.2 samples/s | 61.3 steps/s
[Step=29800 Epoch=29.1] | Loss=0.01668 | Reg=0.00251 | acc=1.0000 | L2-Norm=15.845 | L2-Norm(final)=6.195 | 3938.7 samples/s | 61.5 steps/s
[Step=29850 Epoch=29.1] | Loss=0.01669 | Reg=0.00251 | acc=0.9844 | L2-Norm=15.854 | L2-Norm(final)=6.196 | 3926.3 samples/s | 61.3 steps/s
[Step=29900 Epoch=29.2] | Loss=0.01661 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.863 | L2-Norm(final)=6.196 | 3934.8 samples/s | 61.5 steps/s
[Step=29950 Epoch=29.2] | Loss=0.01661 | Reg=0.00252 | acc=0.9844 | L2-Norm=15.872 | L2-Norm(final)=6.197 | 3968.6 samples/s | 62.0 steps/s
[Step=30000 Epoch=29.3] | Loss=0.01649 | Reg=0.00252 | acc=1.0000 | L2-Norm=15.880 | L2-Norm(final)=6.197 | 3926.7 samples/s | 61.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step30000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=28001 Epoch=52.8] | Loss=0.00005 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.331 | L2-Norm(final)=4.527 | 3449.6 samples/s | 53.9 steps/s
[Step=28050 Epoch=52.9] | Loss=0.00024 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=4.538 | 3671.6 samples/s | 57.4 steps/s
[Step=28100 Epoch=53.0] | Loss=0.00024 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.306 | L2-Norm(final)=4.550 | 4089.6 samples/s | 63.9 steps/s
[Step=28150 Epoch=53.1] | Loss=0.00069 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=4.558 | 4148.2 samples/s | 64.8 steps/s
[Step=28200 Epoch=53.2] | Loss=0.00068 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.359 | L2-Norm(final)=4.562 | 4090.7 samples/s | 63.9 steps/s
[Step=28250 Epoch=53.3] | Loss=0.00057 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.382 | L2-Norm(final)=4.566 | 4108.0 samples/s | 64.2 steps/s
[Step=28300 Epoch=53.3] | Loss=0.00060 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.399 | L2-Norm(final)=4.570 | 4132.9 samples/s | 64.6 steps/s
[Step=28350 Epoch=53.4] | Loss=0.00054 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.414 | L2-Norm(final)=4.574 | 4105.4 samples/s | 64.1 steps/s
[Step=28400 Epoch=53.5] | Loss=0.00049 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.423 | L2-Norm(final)=4.579 | 4113.4 samples/s | 64.3 steps/s
[Step=28450 Epoch=53.6] | Loss=0.00045 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.428 | L2-Norm(final)=4.583 | 4088.7 samples/s | 63.9 steps/s
[Step=28500 Epoch=53.7] | Loss=0.00041 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.429 | L2-Norm(final)=4.587 | 4224.1 samples/s | 66.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=28501 Epoch=53.7] | Loss=0.00000 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=4.628 | 3239.3 samples/s | 50.6 steps/s
[Step=28550 Epoch=53.8] | Loss=0.00001 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.416 | L2-Norm(final)=4.629 | 3561.9 samples/s | 55.7 steps/s
[Step=28600 Epoch=53.9] | Loss=0.00002 | Reg=0.00237 | acc=1.0000 | L2-Norm=15.394 | L2-Norm(final)=4.630 | 3767.5 samples/s | 58.9 steps/s
[Step=28650 Epoch=54.0] | Loss=0.00002 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.372 | L2-Norm(final)=4.632 | 3720.3 samples/s | 58.1 steps/s
[Step=28700 Epoch=54.1] | Loss=0.00002 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.348 | L2-Norm(final)=4.633 | 3747.7 samples/s | 58.6 steps/s
[Step=28750 Epoch=54.2] | Loss=0.00002 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.325 | L2-Norm(final)=4.634 | 3686.4 samples/s | 57.6 steps/s
[Step=28800 Epoch=54.3] | Loss=0.00002 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.301 | L2-Norm(final)=4.635 | 3735.3 samples/s | 58.4 steps/s
[Step=28850 Epoch=54.4] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.277 | L2-Norm(final)=4.636 | 3701.9 samples/s | 57.8 steps/s
[Step=28900 Epoch=54.5] | Loss=0.00001 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.253 | L2-Norm(final)=4.636 | 3671.4 samples/s | 57.4 steps/s
[Step=28950 Epoch=54.6] | Loss=0.00001 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.229 | L2-Norm(final)=4.637 | 3723.4 samples/s | 58.2 steps/s
[Step=29000 Epoch=54.7] | Loss=0.00001 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.204 | L2-Norm(final)=4.638 | 3803.4 samples/s | 59.4 steps/s
[Step=29050 Epoch=54.8] | Loss=0.00001 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.180 | L2-Norm(final)=4.638 | 1609.1 samples/s | 25.1 steps/s
[Step=29100 Epoch=54.9] | Loss=0.00001 | Reg=0.00230 | acc=1.0000 | L2-Norm=15.156 | L2-Norm(final)=4.639 | 3680.0 samples/s | 57.5 steps/s
[Step=29150 Epoch=54.9] | Loss=0.00001 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.131 | L2-Norm(final)=4.639 | 3719.6 samples/s | 58.1 steps/s
[Step=29200 Epoch=55.0] | Loss=0.00001 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.106 | L2-Norm(final)=4.640 | 3712.8 samples/s | 58.0 steps/s
[Step=29250 Epoch=55.1] | Loss=0.00001 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.081 | L2-Norm(final)=4.640 | 3683.6 samples/s | 57.6 steps/s
[Step=29300 Epoch=55.2] | Loss=0.00001 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=4.640 | 3708.3 samples/s | 57.9 steps/s
[Step=29350 Epoch=55.3] | Loss=0.00001 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.031 | L2-Norm(final)=4.641 | 3687.3 samples/s | 57.6 steps/s
[Step=29400 Epoch=55.4] | Loss=0.00001 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.006 | L2-Norm(final)=4.641 | 3746.2 samples/s | 58.5 steps/s
[Step=29450 Epoch=55.5] | Loss=0.00001 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=4.641 | 3707.5 samples/s | 57.9 steps/s
[Step=29500 Epoch=55.6] | Loss=0.00001 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=4.642 | 3746.0 samples/s | 58.5 steps/s
[Step=29550 Epoch=55.7] | Loss=0.00001 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=4.642 | 4670.3 samples/s | 73.0 steps/s
[Step=29600 Epoch=55.8] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.904 | L2-Norm(final)=4.642 | 1524.9 samples/s | 23.8 steps/s
[Step=29650 Epoch=55.9] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.878 | L2-Norm(final)=4.642 | 3702.1 samples/s | 57.8 steps/s
[Step=29700 Epoch=56.0] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.852 | L2-Norm(final)=4.643 | 3734.2 samples/s | 58.3 steps/s
[Step=29750 Epoch=56.1] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.825 | L2-Norm(final)=4.643 | 3735.3 samples/s | 58.4 steps/s
[Step=29800 Epoch=56.2] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.799 | L2-Norm(final)=4.643 | 3689.2 samples/s | 57.6 steps/s
[Step=29850 Epoch=56.3] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=4.643 | 3742.5 samples/s | 58.5 steps/s
[Step=29900 Epoch=56.4] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.746 | L2-Norm(final)=4.644 | 3730.3 samples/s | 58.3 steps/s
[Step=29950 Epoch=56.5] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.719 | L2-Norm(final)=4.644 | 3730.0 samples/s | 58.3 steps/s
[Step=30000 Epoch=56.6] | Loss=0.00000 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=4.644 | 3733.4 samples/s | 58.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step30000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05601 | acc=0.9697 | tpr=0.9716 | fpr=0.0344 | 3656.5 samples/s | 14.3 steps/s
Avg test loss: 0.05784, Avg test acc: 0.96975, Avg tpr: 0.97144, Avg fpr: 0.03397, total FA: 265

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.89600 | acc=0.3048 | tpr=0.0265 | fpr=0.0909 | 3614.1 samples/s | 14.1 steps/s
Avg test loss: 6.88282, Avg test acc: 0.30395, Avg tpr: 0.02675, Avg fpr: 0.08640, total FA: 674

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.24087 | acc=0.1337 | tpr=0.6150 | fpr=0.8750 | 3637.3 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.22670 | acc=0.1364 | tpr=0.6354 | fpr=0.8729 | 6965.1 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.23138 | acc=0.1353 | tpr=0.6470 | fpr=0.8742 | 6679.8 samples/s | 26.1 steps/s
[Step= 200] | Loss=5.21458 | acc=0.1348 | tpr=0.6437 | fpr=0.8745 | 6862.1 samples/s | 26.8 steps/s
[Step= 250] | Loss=5.21977 | acc=0.1350 | tpr=0.6507 | fpr=0.8744 | 7090.3 samples/s | 27.7 steps/s
[Step= 300] | Loss=5.21636 | acc=0.1357 | tpr=0.6480 | fpr=0.8737 | 6700.4 samples/s | 26.2 steps/s
[Step= 350] | Loss=5.21341 | acc=0.1352 | tpr=0.6500 | fpr=0.8741 | 7065.4 samples/s | 27.6 steps/s
[Step= 400] | Loss=5.21872 | acc=0.1354 | tpr=0.6488 | fpr=0.8740 | 6678.7 samples/s | 26.1 steps/s
[Step= 450] | Loss=5.21767 | acc=0.1356 | tpr=0.6495 | fpr=0.8737 | 6655.8 samples/s | 26.0 steps/s
[Step= 500] | Loss=5.21831 | acc=0.1356 | tpr=0.6511 | fpr=0.8737 | 6879.3 samples/s | 26.9 steps/s
[Step= 550] | Loss=5.21965 | acc=0.1356 | tpr=0.6554 | fpr=0.8739 | 12387.0 samples/s | 48.4 steps/s
Avg test loss: 5.22138, Avg test acc: 0.13554, Avg tpr: 0.65531, Avg fpr: 0.87391, total FA: 121341

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12634 | acc=0.9823 | tpr=0.9646 | fpr=0.0174 | 3614.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.13548 | acc=0.9813 | tpr=0.9680 | fpr=0.0184 | 6856.1 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.13682 | acc=0.9809 | tpr=0.9669 | fpr=0.0189 | 6919.3 samples/s | 27.0 steps/s
[Step= 200] | Loss=0.13811 | acc=0.9809 | tpr=0.9705 | fpr=0.0189 | 7054.5 samples/s | 27.6 steps/s
[Step= 250] | Loss=0.13673 | acc=0.9813 | tpr=0.9677 | fpr=0.0185 | 6636.8 samples/s | 25.9 steps/s
[Step= 300] | Loss=0.13935 | acc=0.9809 | tpr=0.9636 | fpr=0.0188 | 6953.1 samples/s | 27.2 steps/s
[Step= 350] | Loss=0.13963 | acc=0.9807 | tpr=0.9631 | fpr=0.0190 | 6810.9 samples/s | 26.6 steps/s
[Step= 400] | Loss=0.14071 | acc=0.9805 | tpr=0.9628 | fpr=0.0192 | 6719.0 samples/s | 26.2 steps/s
[Step= 450] | Loss=0.14382 | acc=0.9801 | tpr=0.9606 | fpr=0.0195 | 6751.1 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.14314 | acc=0.9801 | tpr=0.9612 | fpr=0.0195 | 6848.0 samples/s | 26.7 steps/s
[Step= 550] | Loss=0.14214 | acc=0.9803 | tpr=0.9602 | fpr=0.0193 | 12086.6 samples/s | 47.2 steps/s
Avg test loss: 0.14178, Avg test acc: 0.98034, Avg tpr: 0.96038, Avg fpr: 0.01929, total FA: 2679

server round 15/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=29.3] | Loss=0.00256 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.805 | L2-Norm(final)=6.211 | 3137.1 samples/s | 49.0 steps/s
[Step=30050 Epoch=29.3] | Loss=0.01483 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.828 | L2-Norm(final)=6.216 | 4329.9 samples/s | 67.7 steps/s
[Step=30100 Epoch=29.4] | Loss=0.01250 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.842 | L2-Norm(final)=6.225 | 4381.5 samples/s | 68.5 steps/s
[Step=30150 Epoch=29.4] | Loss=0.01185 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.852 | L2-Norm(final)=6.232 | 4441.2 samples/s | 69.4 steps/s
[Step=30200 Epoch=29.5] | Loss=0.01205 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.860 | L2-Norm(final)=6.237 | 4345.5 samples/s | 67.9 steps/s
[Step=30250 Epoch=29.5] | Loss=0.01204 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.868 | L2-Norm(final)=6.241 | 4375.0 samples/s | 68.4 steps/s
[Step=30300 Epoch=29.6] | Loss=0.01194 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.876 | L2-Norm(final)=6.245 | 4312.0 samples/s | 67.4 steps/s
[Step=30350 Epoch=29.6] | Loss=0.01153 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.884 | L2-Norm(final)=6.249 | 4483.4 samples/s | 70.1 steps/s
[Step=30400 Epoch=29.7] | Loss=0.01167 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.891 | L2-Norm(final)=6.253 | 4379.2 samples/s | 68.4 steps/s
[Step=30450 Epoch=29.7] | Loss=0.01166 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.898 | L2-Norm(final)=6.255 | 4344.6 samples/s | 67.9 steps/s
[Step=30500 Epoch=29.8] | Loss=0.01151 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.905 | L2-Norm(final)=6.259 | 4377.1 samples/s | 68.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=29.8] | Loss=0.01863 | Reg=0.00224 | acc=0.9844 | L2-Norm=14.978 | L2-Norm(final)=6.288 | 3310.8 samples/s | 51.7 steps/s
[Step=30550 Epoch=29.8] | Loss=0.01142 | Reg=0.00225 | acc=0.9688 | L2-Norm=14.988 | L2-Norm(final)=6.292 | 3665.7 samples/s | 57.3 steps/s
[Step=30600 Epoch=29.9] | Loss=0.01461 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.998 | L2-Norm(final)=6.284 | 3897.5 samples/s | 60.9 steps/s
[Step=30650 Epoch=29.9] | Loss=0.01624 | Reg=0.00225 | acc=0.9688 | L2-Norm=15.012 | L2-Norm(final)=6.281 | 3948.8 samples/s | 61.7 steps/s
[Step=30700 Epoch=30.0] | Loss=0.01550 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.026 | L2-Norm(final)=6.281 | 3922.9 samples/s | 61.3 steps/s
[Step=30750 Epoch=30.0] | Loss=0.01527 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.039 | L2-Norm(final)=6.282 | 3926.9 samples/s | 61.4 steps/s
[Step=30800 Epoch=30.1] | Loss=0.01564 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=6.284 | 3926.2 samples/s | 61.3 steps/s
[Step=30850 Epoch=30.1] | Loss=0.01583 | Reg=0.00227 | acc=0.9531 | L2-Norm=15.066 | L2-Norm(final)=6.286 | 3939.2 samples/s | 61.5 steps/s
[Step=30900 Epoch=30.2] | Loss=0.01615 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.081 | L2-Norm(final)=6.287 | 3875.7 samples/s | 60.6 steps/s
[Step=30950 Epoch=30.2] | Loss=0.01667 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.095 | L2-Norm(final)=6.287 | 3954.3 samples/s | 61.8 steps/s
[Step=31000 Epoch=30.3] | Loss=0.01679 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.109 | L2-Norm(final)=6.287 | 3939.4 samples/s | 61.6 steps/s
[Step=31050 Epoch=30.3] | Loss=0.01660 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=6.287 | 3963.9 samples/s | 61.9 steps/s
[Step=31100 Epoch=30.4] | Loss=0.01660 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.137 | L2-Norm(final)=6.288 | 3901.5 samples/s | 61.0 steps/s
[Step=31150 Epoch=30.4] | Loss=0.01686 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.150 | L2-Norm(final)=6.289 | 3903.5 samples/s | 61.0 steps/s
[Step=31200 Epoch=30.5] | Loss=0.01711 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.165 | L2-Norm(final)=6.290 | 3961.0 samples/s | 61.9 steps/s
[Step=31250 Epoch=30.5] | Loss=0.01737 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.179 | L2-Norm(final)=6.291 | 3947.0 samples/s | 61.7 steps/s
[Step=31300 Epoch=30.6] | Loss=0.01738 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.194 | L2-Norm(final)=6.292 | 3946.1 samples/s | 61.7 steps/s
[Step=31350 Epoch=30.6] | Loss=0.01741 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.208 | L2-Norm(final)=6.293 | 3917.2 samples/s | 61.2 steps/s
[Step=31400 Epoch=30.7] | Loss=0.01739 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.221 | L2-Norm(final)=6.294 | 3931.5 samples/s | 61.4 steps/s
[Step=31450 Epoch=30.7] | Loss=0.01730 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.234 | L2-Norm(final)=6.295 | 3951.3 samples/s | 61.7 steps/s
[Step=31500 Epoch=30.8] | Loss=0.01742 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.246 | L2-Norm(final)=6.295 | 4204.5 samples/s | 65.7 steps/s
[Step=31550 Epoch=30.8] | Loss=0.01740 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=6.296 | 1630.0 samples/s | 25.5 steps/s
[Step=31600 Epoch=30.9] | Loss=0.01716 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=6.296 | 3902.7 samples/s | 61.0 steps/s
[Step=31650 Epoch=30.9] | Loss=0.01692 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.282 | L2-Norm(final)=6.296 | 3903.5 samples/s | 61.0 steps/s
[Step=31700 Epoch=30.9] | Loss=0.01669 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.292 | L2-Norm(final)=6.297 | 3879.3 samples/s | 60.6 steps/s
[Step=31750 Epoch=31.0] | Loss=0.01658 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.303 | L2-Norm(final)=6.298 | 3951.2 samples/s | 61.7 steps/s
[Step=31800 Epoch=31.0] | Loss=0.01667 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.313 | L2-Norm(final)=6.299 | 3865.4 samples/s | 60.4 steps/s
[Step=31850 Epoch=31.1] | Loss=0.01664 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.324 | L2-Norm(final)=6.300 | 3890.3 samples/s | 60.8 steps/s
[Step=31900 Epoch=31.1] | Loss=0.01661 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.334 | L2-Norm(final)=6.300 | 3949.4 samples/s | 61.7 steps/s
[Step=31950 Epoch=31.2] | Loss=0.01657 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.343 | L2-Norm(final)=6.301 | 3934.4 samples/s | 61.5 steps/s
[Step=32000 Epoch=31.2] | Loss=0.01649 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.353 | L2-Norm(final)=6.302 | 3946.6 samples/s | 61.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step32000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=30001 Epoch=56.6] | Loss=0.00014 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.805 | L2-Norm(final)=4.652 | 3472.1 samples/s | 54.3 steps/s
[Step=30050 Epoch=56.6] | Loss=0.00088 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.829 | L2-Norm(final)=4.665 | 3741.0 samples/s | 58.5 steps/s
[Step=30100 Epoch=56.7] | Loss=0.00140 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.891 | L2-Norm(final)=4.668 | 4057.2 samples/s | 63.4 steps/s
[Step=30150 Epoch=56.8] | Loss=0.00165 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.936 | L2-Norm(final)=4.667 | 4059.5 samples/s | 63.4 steps/s
[Step=30200 Epoch=56.9] | Loss=0.00152 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=4.667 | 4217.3 samples/s | 65.9 steps/s
[Step=30250 Epoch=57.0] | Loss=0.00148 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.000 | L2-Norm(final)=4.667 | 4037.2 samples/s | 63.1 steps/s
[Step=30300 Epoch=57.1] | Loss=0.00129 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.017 | L2-Norm(final)=4.668 | 4067.8 samples/s | 63.6 steps/s
[Step=30350 Epoch=57.2] | Loss=0.00121 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.029 | L2-Norm(final)=4.670 | 4149.1 samples/s | 64.8 steps/s
[Step=30400 Epoch=57.3] | Loss=0.00108 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.037 | L2-Norm(final)=4.671 | 4135.9 samples/s | 64.6 steps/s
[Step=30450 Epoch=57.4] | Loss=0.00097 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.042 | L2-Norm(final)=4.673 | 4077.9 samples/s | 63.7 steps/s
[Step=30500 Epoch=57.5] | Loss=0.00090 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.044 | L2-Norm(final)=4.675 | 4148.5 samples/s | 64.8 steps/s
All layers training...
LR=0.00050, len=1
[Step=30501 Epoch=57.5] | Loss=0.00004 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.063 | L2-Norm(final)=4.695 | 3485.9 samples/s | 54.5 steps/s
[Step=30550 Epoch=57.6] | Loss=0.00003 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.036 | L2-Norm(final)=4.695 | 3416.6 samples/s | 53.4 steps/s
[Step=30600 Epoch=57.7] | Loss=0.01072 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.054 | L2-Norm(final)=4.685 | 3668.3 samples/s | 57.3 steps/s
[Step=30650 Epoch=57.8] | Loss=0.00839 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.139 | L2-Norm(final)=4.664 | 3743.2 samples/s | 58.5 steps/s
[Step=30700 Epoch=57.9] | Loss=0.00793 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.187 | L2-Norm(final)=4.651 | 3694.0 samples/s | 57.7 steps/s
[Step=30750 Epoch=58.0] | Loss=0.00697 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.219 | L2-Norm(final)=4.641 | 3753.6 samples/s | 58.7 steps/s
[Step=30800 Epoch=58.1] | Loss=0.00643 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=4.634 | 3734.8 samples/s | 58.4 steps/s
[Step=30850 Epoch=58.2] | Loss=0.00578 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.261 | L2-Norm(final)=4.628 | 3747.3 samples/s | 58.6 steps/s
[Step=30900 Epoch=58.2] | Loss=0.00514 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.273 | L2-Norm(final)=4.623 | 3731.5 samples/s | 58.3 steps/s
[Step=30950 Epoch=58.3] | Loss=0.00465 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.282 | L2-Norm(final)=4.619 | 3716.0 samples/s | 58.1 steps/s
[Step=31000 Epoch=58.4] | Loss=0.00419 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.288 | L2-Norm(final)=4.617 | 3790.3 samples/s | 59.2 steps/s
[Step=31050 Epoch=58.5] | Loss=0.00382 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.292 | L2-Norm(final)=4.614 | 1631.9 samples/s | 25.5 steps/s
[Step=31100 Epoch=58.6] | Loss=0.00351 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=4.613 | 3740.3 samples/s | 58.4 steps/s
[Step=31150 Epoch=58.7] | Loss=0.00324 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.295 | L2-Norm(final)=4.612 | 3683.3 samples/s | 57.6 steps/s
[Step=31200 Epoch=58.8] | Loss=0.00301 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.295 | L2-Norm(final)=4.611 | 3732.3 samples/s | 58.3 steps/s
[Step=31250 Epoch=58.9] | Loss=0.00281 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.294 | L2-Norm(final)=4.610 | 3715.0 samples/s | 58.0 steps/s
[Step=31300 Epoch=59.0] | Loss=0.00264 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.292 | L2-Norm(final)=4.609 | 3762.5 samples/s | 58.8 steps/s
[Step=31350 Epoch=59.1] | Loss=0.00248 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.289 | L2-Norm(final)=4.609 | 3738.4 samples/s | 58.4 steps/s
[Step=31400 Epoch=59.2] | Loss=0.00235 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=4.608 | 3757.5 samples/s | 58.7 steps/s
[Step=31450 Epoch=59.3] | Loss=0.00223 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.283 | L2-Norm(final)=4.608 | 3715.4 samples/s | 58.1 steps/s
[Step=31500 Epoch=59.4] | Loss=0.00212 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.280 | L2-Norm(final)=4.608 | 3789.3 samples/s | 59.2 steps/s
[Step=31550 Epoch=59.5] | Loss=0.00202 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.276 | L2-Norm(final)=4.608 | 4674.8 samples/s | 73.0 steps/s
[Step=31600 Epoch=59.6] | Loss=0.00193 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.272 | L2-Norm(final)=4.608 | 1513.0 samples/s | 23.6 steps/s
[Step=31650 Epoch=59.7] | Loss=0.00184 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.268 | L2-Norm(final)=4.607 | 3735.3 samples/s | 58.4 steps/s
[Step=31700 Epoch=59.8] | Loss=0.00177 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.263 | L2-Norm(final)=4.607 | 3733.8 samples/s | 58.3 steps/s
[Step=31750 Epoch=59.8] | Loss=0.00170 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.259 | L2-Norm(final)=4.607 | 3671.1 samples/s | 57.4 steps/s
[Step=31800 Epoch=59.9] | Loss=0.00163 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.254 | L2-Norm(final)=4.607 | 3776.4 samples/s | 59.0 steps/s
[Step=31850 Epoch=60.0] | Loss=0.00157 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.249 | L2-Norm(final)=4.607 | 3719.1 samples/s | 58.1 steps/s
[Step=31900 Epoch=60.1] | Loss=0.00152 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.243 | L2-Norm(final)=4.608 | 3771.1 samples/s | 58.9 steps/s
[Step=31950 Epoch=60.2] | Loss=0.00146 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.238 | L2-Norm(final)=4.608 | 3734.6 samples/s | 58.4 steps/s
[Step=32000 Epoch=60.3] | Loss=0.00142 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.232 | L2-Norm(final)=4.608 | 3719.0 samples/s | 58.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step32000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06077 | acc=0.9707 | tpr=0.9804 | fpr=0.0503 | 3631.4 samples/s | 14.2 steps/s
Avg test loss: 0.05971, Avg test acc: 0.97071, Avg tpr: 0.97960, Avg fpr: 0.04884, total FA: 381

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.76414 | acc=0.3051 | tpr=0.0131 | fpr=0.0610 | 3613.7 samples/s | 14.1 steps/s
Avg test loss: 5.75735, Avg test acc: 0.30311, Avg tpr: 0.01411, Avg fpr: 0.06127, total FA: 478

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=6.36737 | acc=0.1222 | tpr=0.8186 | fpr=0.8903 | 3643.0 samples/s | 14.2 steps/s
[Step= 100] | Loss=6.35286 | acc=0.1227 | tpr=0.7996 | fpr=0.8900 | 6720.6 samples/s | 26.3 steps/s
[Step= 150] | Loss=6.36093 | acc=0.1215 | tpr=0.8156 | fpr=0.8913 | 7046.9 samples/s | 27.5 steps/s
[Step= 200] | Loss=6.34031 | acc=0.1223 | tpr=0.8066 | fpr=0.8902 | 6789.7 samples/s | 26.5 steps/s
[Step= 250] | Loss=6.34626 | acc=0.1222 | tpr=0.8105 | fpr=0.8904 | 6758.1 samples/s | 26.4 steps/s
[Step= 300] | Loss=6.34123 | acc=0.1221 | tpr=0.8058 | fpr=0.8903 | 6967.1 samples/s | 27.2 steps/s
[Step= 350] | Loss=6.34147 | acc=0.1218 | tpr=0.8065 | fpr=0.8906 | 7066.0 samples/s | 27.6 steps/s
[Step= 400] | Loss=6.34631 | acc=0.1218 | tpr=0.8053 | fpr=0.8906 | 6718.7 samples/s | 26.2 steps/s
[Step= 450] | Loss=6.34660 | acc=0.1221 | tpr=0.8053 | fpr=0.8903 | 6990.8 samples/s | 27.3 steps/s
[Step= 500] | Loss=6.34933 | acc=0.1225 | tpr=0.8070 | fpr=0.8899 | 6669.5 samples/s | 26.1 steps/s
[Step= 550] | Loss=6.35337 | acc=0.1225 | tpr=0.8074 | fpr=0.8899 | 12486.2 samples/s | 48.8 steps/s
Avg test loss: 6.35511, Avg test acc: 0.12249, Avg tpr: 0.80784, Avg fpr: 0.88997, total FA: 123571

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11687 | acc=0.9815 | tpr=0.9646 | fpr=0.0182 | 3588.9 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.12397 | acc=0.9796 | tpr=0.9659 | fpr=0.0201 | 6996.0 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.12730 | acc=0.9789 | tpr=0.9669 | fpr=0.0208 | 6762.3 samples/s | 26.4 steps/s
[Step= 200] | Loss=0.12963 | acc=0.9788 | tpr=0.9694 | fpr=0.0210 | 6927.9 samples/s | 27.1 steps/s
[Step= 250] | Loss=0.12776 | acc=0.9789 | tpr=0.9703 | fpr=0.0210 | 6695.9 samples/s | 26.2 steps/s
[Step= 300] | Loss=0.13050 | acc=0.9785 | tpr=0.9687 | fpr=0.0214 | 6861.2 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.13170 | acc=0.9781 | tpr=0.9681 | fpr=0.0217 | 6773.5 samples/s | 26.5 steps/s
[Step= 400] | Loss=0.13294 | acc=0.9779 | tpr=0.9672 | fpr=0.0219 | 6649.9 samples/s | 26.0 steps/s
[Step= 450] | Loss=0.13584 | acc=0.9775 | tpr=0.9635 | fpr=0.0223 | 6837.8 samples/s | 26.7 steps/s
[Step= 500] | Loss=0.13465 | acc=0.9775 | tpr=0.9630 | fpr=0.0222 | 6580.1 samples/s | 25.7 steps/s
[Step= 550] | Loss=0.13383 | acc=0.9777 | tpr=0.9622 | fpr=0.0220 | 12482.5 samples/s | 48.8 steps/s
Avg test loss: 0.13350, Avg test acc: 0.97769, Avg tpr: 0.96236, Avg fpr: 0.02203, total FA: 3059

server round 16/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=31.2] | Loss=0.01959 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=6.325 | 3414.9 samples/s | 53.4 steps/s
[Step=32050 Epoch=31.3] | Loss=0.03631 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.123 | L2-Norm(final)=6.339 | 3820.1 samples/s | 59.7 steps/s
[Step=32100 Epoch=31.3] | Loss=0.03203 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.165 | L2-Norm(final)=6.356 | 4387.2 samples/s | 68.5 steps/s
[Step=32150 Epoch=31.4] | Loss=0.03035 | Reg=0.00231 | acc=1.0000 | L2-Norm=15.195 | L2-Norm(final)=6.369 | 4375.9 samples/s | 68.4 steps/s
[Step=32200 Epoch=31.4] | Loss=0.02910 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.220 | L2-Norm(final)=6.378 | 4310.9 samples/s | 67.4 steps/s
[Step=32250 Epoch=31.5] | Loss=0.02802 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.240 | L2-Norm(final)=6.386 | 4350.7 samples/s | 68.0 steps/s
[Step=32300 Epoch=31.5] | Loss=0.02729 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.258 | L2-Norm(final)=6.395 | 4325.5 samples/s | 67.6 steps/s
[Step=32350 Epoch=31.6] | Loss=0.02678 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.274 | L2-Norm(final)=6.403 | 4381.5 samples/s | 68.5 steps/s
[Step=32400 Epoch=31.6] | Loss=0.02642 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.290 | L2-Norm(final)=6.411 | 4364.3 samples/s | 68.2 steps/s
[Step=32450 Epoch=31.7] | Loss=0.02584 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.307 | L2-Norm(final)=6.420 | 4441.9 samples/s | 69.4 steps/s
[Step=32500 Epoch=31.7] | Loss=0.02556 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.322 | L2-Norm(final)=6.429 | 4387.9 samples/s | 68.6 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=31.7] | Loss=0.01866 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.477 | L2-Norm(final)=6.519 | 3186.1 samples/s | 49.8 steps/s
[Step=32550 Epoch=31.8] | Loss=0.02215 | Reg=0.00240 | acc=0.9688 | L2-Norm=15.495 | L2-Norm(final)=6.527 | 3877.7 samples/s | 60.6 steps/s
[Step=32600 Epoch=31.8] | Loss=0.02043 | Reg=0.00241 | acc=0.9844 | L2-Norm=15.515 | L2-Norm(final)=6.522 | 3898.4 samples/s | 60.9 steps/s
[Step=32650 Epoch=31.9] | Loss=0.02088 | Reg=0.00241 | acc=0.9688 | L2-Norm=15.532 | L2-Norm(final)=6.520 | 3932.9 samples/s | 61.5 steps/s
[Step=32700 Epoch=31.9] | Loss=0.01990 | Reg=0.00242 | acc=0.9844 | L2-Norm=15.548 | L2-Norm(final)=6.518 | 3942.3 samples/s | 61.6 steps/s
[Step=32750 Epoch=32.0] | Loss=0.01897 | Reg=0.00242 | acc=0.9531 | L2-Norm=15.562 | L2-Norm(final)=6.519 | 3941.7 samples/s | 61.6 steps/s
[Step=32800 Epoch=32.0] | Loss=0.01906 | Reg=0.00243 | acc=1.0000 | L2-Norm=15.574 | L2-Norm(final)=6.519 | 3953.3 samples/s | 61.8 steps/s
[Step=32850 Epoch=32.1] | Loss=0.01937 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.586 | L2-Norm(final)=6.520 | 3961.5 samples/s | 61.9 steps/s
[Step=32900 Epoch=32.1] | Loss=0.01873 | Reg=0.00243 | acc=0.9375 | L2-Norm=15.596 | L2-Norm(final)=6.521 | 3963.3 samples/s | 61.9 steps/s
[Step=32950 Epoch=32.2] | Loss=0.01890 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.606 | L2-Norm(final)=6.522 | 3992.1 samples/s | 62.4 steps/s
[Step=33000 Epoch=32.2] | Loss=0.01870 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.617 | L2-Norm(final)=6.523 | 3974.1 samples/s | 62.1 steps/s
[Step=33050 Epoch=32.3] | Loss=0.01839 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.627 | L2-Norm(final)=6.524 | 4012.4 samples/s | 62.7 steps/s
[Step=33100 Epoch=32.3] | Loss=0.01861 | Reg=0.00244 | acc=0.9844 | L2-Norm=15.636 | L2-Norm(final)=6.524 | 3959.1 samples/s | 61.9 steps/s
[Step=33150 Epoch=32.4] | Loss=0.01835 | Reg=0.00245 | acc=1.0000 | L2-Norm=15.645 | L2-Norm(final)=6.524 | 3990.2 samples/s | 62.3 steps/s
[Step=33200 Epoch=32.4] | Loss=0.01814 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.653 | L2-Norm(final)=6.525 | 3970.3 samples/s | 62.0 steps/s
[Step=33250 Epoch=32.5] | Loss=0.01840 | Reg=0.00245 | acc=0.9844 | L2-Norm=15.662 | L2-Norm(final)=6.525 | 3950.2 samples/s | 61.7 steps/s
[Step=33300 Epoch=32.5] | Loss=0.01863 | Reg=0.00246 | acc=0.9688 | L2-Norm=15.671 | L2-Norm(final)=6.524 | 3997.3 samples/s | 62.5 steps/s
[Step=33350 Epoch=32.6] | Loss=0.01875 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.680 | L2-Norm(final)=6.523 | 3941.3 samples/s | 61.6 steps/s
[Step=33400 Epoch=32.6] | Loss=0.01864 | Reg=0.00246 | acc=1.0000 | L2-Norm=15.689 | L2-Norm(final)=6.522 | 3994.2 samples/s | 62.4 steps/s
[Step=33450 Epoch=32.7] | Loss=0.01845 | Reg=0.00246 | acc=0.9531 | L2-Norm=15.697 | L2-Norm(final)=6.522 | 3929.4 samples/s | 61.4 steps/s
[Step=33500 Epoch=32.7] | Loss=0.01844 | Reg=0.00247 | acc=1.0000 | L2-Norm=15.705 | L2-Norm(final)=6.522 | 4267.3 samples/s | 66.7 steps/s
[Step=33550 Epoch=32.8] | Loss=0.01827 | Reg=0.00247 | acc=0.9844 | L2-Norm=15.713 | L2-Norm(final)=6.521 | 1632.9 samples/s | 25.5 steps/s
[Step=33600 Epoch=32.8] | Loss=0.01809 | Reg=0.00247 | acc=0.9531 | L2-Norm=15.721 | L2-Norm(final)=6.522 | 3985.6 samples/s | 62.3 steps/s
[Step=33650 Epoch=32.9] | Loss=0.01787 | Reg=0.00247 | acc=0.9688 | L2-Norm=15.729 | L2-Norm(final)=6.522 | 3965.4 samples/s | 62.0 steps/s
[Step=33700 Epoch=32.9] | Loss=0.01761 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.736 | L2-Norm(final)=6.522 | 3902.7 samples/s | 61.0 steps/s
[Step=33750 Epoch=33.0] | Loss=0.01740 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.743 | L2-Norm(final)=6.523 | 3949.1 samples/s | 61.7 steps/s
[Step=33800 Epoch=33.0] | Loss=0.01739 | Reg=0.00248 | acc=1.0000 | L2-Norm=15.749 | L2-Norm(final)=6.524 | 3969.5 samples/s | 62.0 steps/s
[Step=33850 Epoch=33.0] | Loss=0.01738 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.756 | L2-Norm(final)=6.524 | 3969.4 samples/s | 62.0 steps/s
[Step=33900 Epoch=33.1] | Loss=0.01720 | Reg=0.00248 | acc=0.9844 | L2-Norm=15.762 | L2-Norm(final)=6.524 | 3947.1 samples/s | 61.7 steps/s
[Step=33950 Epoch=33.1] | Loss=0.01721 | Reg=0.00249 | acc=0.9531 | L2-Norm=15.768 | L2-Norm(final)=6.525 | 3878.5 samples/s | 60.6 steps/s
[Step=34000 Epoch=33.2] | Loss=0.01708 | Reg=0.00249 | acc=1.0000 | L2-Norm=15.774 | L2-Norm(final)=6.526 | 3997.4 samples/s | 62.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step34000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=32001 Epoch=60.3] | Loss=0.00090 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.075 | L2-Norm(final)=4.611 | 3354.1 samples/s | 52.4 steps/s
[Step=32050 Epoch=60.4] | Loss=0.00031 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=4.613 | 3774.6 samples/s | 59.0 steps/s
[Step=32100 Epoch=60.5] | Loss=0.00023 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.071 | L2-Norm(final)=4.618 | 4087.1 samples/s | 63.9 steps/s
[Step=32150 Epoch=60.6] | Loss=0.00020 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=4.622 | 4045.4 samples/s | 63.2 steps/s
[Step=32200 Epoch=60.7] | Loss=0.00017 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.072 | L2-Norm(final)=4.626 | 4156.3 samples/s | 64.9 steps/s
[Step=32250 Epoch=60.8] | Loss=0.00016 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.070 | L2-Norm(final)=4.630 | 4088.0 samples/s | 63.9 steps/s
[Step=32300 Epoch=60.9] | Loss=0.00014 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.067 | L2-Norm(final)=4.634 | 4162.6 samples/s | 65.0 steps/s
[Step=32350 Epoch=61.0] | Loss=0.00013 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.064 | L2-Norm(final)=4.637 | 4145.0 samples/s | 64.8 steps/s
[Step=32400 Epoch=61.1] | Loss=0.00012 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.060 | L2-Norm(final)=4.641 | 4110.7 samples/s | 64.2 steps/s
[Step=32450 Epoch=61.2] | Loss=0.00011 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.056 | L2-Norm(final)=4.644 | 4063.6 samples/s | 63.5 steps/s
[Step=32500 Epoch=61.3] | Loss=0.00011 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.052 | L2-Norm(final)=4.647 | 4216.1 samples/s | 65.9 steps/s
All layers training...
LR=0.00050, len=1
[Step=32501 Epoch=61.3] | Loss=0.00007 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=4.679 | 3333.5 samples/s | 52.1 steps/s
[Step=32550 Epoch=61.4] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.015 | L2-Norm(final)=4.681 | 3578.0 samples/s | 55.9 steps/s
[Step=32600 Epoch=61.5] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.004 | L2-Norm(final)=4.683 | 3668.3 samples/s | 57.3 steps/s
[Step=32650 Epoch=61.5] | Loss=0.00003 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=4.685 | 3669.2 samples/s | 57.3 steps/s
[Step=32700 Epoch=61.6] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.981 | L2-Norm(final)=4.686 | 3758.5 samples/s | 58.7 steps/s
[Step=32750 Epoch=61.7] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.970 | L2-Norm(final)=4.688 | 3754.6 samples/s | 58.7 steps/s
[Step=32800 Epoch=61.8] | Loss=0.00002 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=4.689 | 3693.2 samples/s | 57.7 steps/s
[Step=32850 Epoch=61.9] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.948 | L2-Norm(final)=4.691 | 3713.4 samples/s | 58.0 steps/s
[Step=32900 Epoch=62.0] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.937 | L2-Norm(final)=4.692 | 3722.1 samples/s | 58.2 steps/s
[Step=32950 Epoch=62.1] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.927 | L2-Norm(final)=4.693 | 3727.0 samples/s | 58.2 steps/s
[Step=33000 Epoch=62.2] | Loss=0.00002 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.916 | L2-Norm(final)=4.695 | 3771.2 samples/s | 58.9 steps/s
[Step=33050 Epoch=62.3] | Loss=0.00002 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.906 | L2-Norm(final)=4.696 | 1617.6 samples/s | 25.3 steps/s
[Step=33100 Epoch=62.4] | Loss=0.00002 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.895 | L2-Norm(final)=4.697 | 3800.6 samples/s | 59.4 steps/s
[Step=33150 Epoch=62.5] | Loss=0.00002 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.884 | L2-Norm(final)=4.698 | 3647.8 samples/s | 57.0 steps/s
[Step=33200 Epoch=62.6] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.874 | L2-Norm(final)=4.699 | 3702.5 samples/s | 57.9 steps/s
[Step=33250 Epoch=62.7] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.863 | L2-Norm(final)=4.700 | 3778.8 samples/s | 59.0 steps/s
[Step=33300 Epoch=62.8] | Loss=0.00001 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.852 | L2-Norm(final)=4.700 | 3708.2 samples/s | 57.9 steps/s
[Step=33350 Epoch=62.9] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.841 | L2-Norm(final)=4.701 | 3709.5 samples/s | 58.0 steps/s
[Step=33400 Epoch=63.0] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.830 | L2-Norm(final)=4.702 | 3685.6 samples/s | 57.6 steps/s
[Step=33450 Epoch=63.1] | Loss=0.00001 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.819 | L2-Norm(final)=4.703 | 3768.9 samples/s | 58.9 steps/s
[Step=33500 Epoch=63.1] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.807 | L2-Norm(final)=4.704 | 3679.7 samples/s | 57.5 steps/s
[Step=33550 Epoch=63.2] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.796 | L2-Norm(final)=4.704 | 4751.7 samples/s | 74.2 steps/s
[Step=33600 Epoch=63.3] | Loss=0.00001 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.785 | L2-Norm(final)=4.705 | 1536.0 samples/s | 24.0 steps/s
[Step=33650 Epoch=63.4] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.773 | L2-Norm(final)=4.706 | 3714.6 samples/s | 58.0 steps/s
[Step=33700 Epoch=63.5] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.762 | L2-Norm(final)=4.707 | 3687.4 samples/s | 57.6 steps/s
[Step=33750 Epoch=63.6] | Loss=0.00001 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.750 | L2-Norm(final)=4.707 | 3661.0 samples/s | 57.2 steps/s
[Step=33800 Epoch=63.7] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.739 | L2-Norm(final)=4.708 | 3711.9 samples/s | 58.0 steps/s
[Step=33850 Epoch=63.8] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.727 | L2-Norm(final)=4.709 | 3728.1 samples/s | 58.3 steps/s
[Step=33900 Epoch=63.9] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=4.709 | 3728.0 samples/s | 58.3 steps/s
[Step=33950 Epoch=64.0] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=4.710 | 3718.8 samples/s | 58.1 steps/s
[Step=34000 Epoch=64.1] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.691 | L2-Norm(final)=4.711 | 3699.7 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step34000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05792 | acc=0.9714 | tpr=0.9784 | fpr=0.0439 | 3577.9 samples/s | 14.0 steps/s
Avg test loss: 0.05979, Avg test acc: 0.97003, Avg tpr: 0.97587, Avg fpr: 0.04282, total FA: 334

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.70690 | acc=0.3070 | tpr=0.0235 | fpr=0.0776 | 3571.9 samples/s | 14.0 steps/s
Avg test loss: 5.69181, Avg test acc: 0.30700, Avg tpr: 0.02483, Avg fpr: 0.07243, total FA: 565

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.68668 | acc=0.1373 | tpr=0.7566 | fpr=0.8738 | 3618.9 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.65110 | acc=0.1400 | tpr=0.7676 | fpr=0.8717 | 6789.7 samples/s | 26.5 steps/s
[Step= 150] | Loss=5.65947 | acc=0.1386 | tpr=0.7723 | fpr=0.8730 | 6788.2 samples/s | 26.5 steps/s
[Step= 200] | Loss=5.63964 | acc=0.1388 | tpr=0.7585 | fpr=0.8724 | 7029.8 samples/s | 27.5 steps/s
[Step= 250] | Loss=5.64284 | acc=0.1394 | tpr=0.7633 | fpr=0.8720 | 6788.4 samples/s | 26.5 steps/s
[Step= 300] | Loss=5.64012 | acc=0.1393 | tpr=0.7542 | fpr=0.8719 | 6777.4 samples/s | 26.5 steps/s
[Step= 350] | Loss=5.63619 | acc=0.1386 | tpr=0.7520 | fpr=0.8725 | 6857.5 samples/s | 26.8 steps/s
[Step= 400] | Loss=5.64312 | acc=0.1385 | tpr=0.7484 | fpr=0.8726 | 6835.9 samples/s | 26.7 steps/s
[Step= 450] | Loss=5.64281 | acc=0.1389 | tpr=0.7522 | fpr=0.8723 | 6899.7 samples/s | 27.0 steps/s
[Step= 500] | Loss=5.64314 | acc=0.1391 | tpr=0.7524 | fpr=0.8719 | 6786.3 samples/s | 26.5 steps/s
[Step= 550] | Loss=5.64239 | acc=0.1394 | tpr=0.7561 | fpr=0.8718 | 12792.1 samples/s | 50.0 steps/s
Avg test loss: 5.64331, Avg test acc: 0.13938, Avg tpr: 0.75634, Avg fpr: 0.87183, total FA: 121052

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12237 | acc=0.9812 | tpr=0.9646 | fpr=0.0185 | 3711.8 samples/s | 14.5 steps/s
[Step= 100] | Loss=0.12991 | acc=0.9802 | tpr=0.9638 | fpr=0.0195 | 6604.9 samples/s | 25.8 steps/s
[Step= 150] | Loss=0.13347 | acc=0.9793 | tpr=0.9611 | fpr=0.0203 | 6897.1 samples/s | 26.9 steps/s
[Step= 200] | Loss=0.13518 | acc=0.9792 | tpr=0.9661 | fpr=0.0205 | 6753.4 samples/s | 26.4 steps/s
[Step= 250] | Loss=0.13331 | acc=0.9794 | tpr=0.9659 | fpr=0.0203 | 6987.1 samples/s | 27.3 steps/s
[Step= 300] | Loss=0.13611 | acc=0.9789 | tpr=0.9636 | fpr=0.0208 | 6778.0 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.13687 | acc=0.9787 | tpr=0.9624 | fpr=0.0210 | 7100.6 samples/s | 27.7 steps/s
[Step= 400] | Loss=0.13810 | acc=0.9784 | tpr=0.9612 | fpr=0.0212 | 6629.6 samples/s | 25.9 steps/s
[Step= 450] | Loss=0.14122 | acc=0.9780 | tpr=0.9576 | fpr=0.0216 | 6738.1 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.14062 | acc=0.9781 | tpr=0.9590 | fpr=0.0216 | 6635.1 samples/s | 25.9 steps/s
[Step= 550] | Loss=0.13950 | acc=0.9783 | tpr=0.9594 | fpr=0.0213 | 13122.4 samples/s | 51.3 steps/s
Avg test loss: 0.13913, Avg test acc: 0.97833, Avg tpr: 0.95959, Avg fpr: 0.02133, total FA: 2961

server round 17/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=33.2] | Loss=0.00170 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=6.543 | 3556.8 samples/s | 55.6 steps/s
[Step=34050 Epoch=33.2] | Loss=0.00961 | Reg=0.00225 | acc=0.9844 | L2-Norm=15.000 | L2-Norm(final)=6.553 | 3911.5 samples/s | 61.1 steps/s
[Step=34100 Epoch=33.3] | Loss=0.01020 | Reg=0.00226 | acc=1.0000 | L2-Norm=15.020 | L2-Norm(final)=6.563 | 4289.5 samples/s | 67.0 steps/s
[Step=34150 Epoch=33.3] | Loss=0.01140 | Reg=0.00226 | acc=0.9688 | L2-Norm=15.033 | L2-Norm(final)=6.570 | 4331.8 samples/s | 67.7 steps/s
[Step=34200 Epoch=33.4] | Loss=0.01179 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.042 | L2-Norm(final)=6.574 | 4392.4 samples/s | 68.6 steps/s
[Step=34250 Epoch=33.4] | Loss=0.01157 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.050 | L2-Norm(final)=6.577 | 4430.4 samples/s | 69.2 steps/s
[Step=34300 Epoch=33.5] | Loss=0.01173 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.058 | L2-Norm(final)=6.581 | 4442.7 samples/s | 69.4 steps/s
[Step=34350 Epoch=33.5] | Loss=0.01146 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.065 | L2-Norm(final)=6.585 | 4351.2 samples/s | 68.0 steps/s
[Step=34400 Epoch=33.6] | Loss=0.01132 | Reg=0.00227 | acc=0.9688 | L2-Norm=15.071 | L2-Norm(final)=6.590 | 4379.4 samples/s | 68.4 steps/s
[Step=34450 Epoch=33.6] | Loss=0.01130 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.076 | L2-Norm(final)=6.593 | 4313.3 samples/s | 67.4 steps/s
[Step=34500 Epoch=33.7] | Loss=0.01132 | Reg=0.00227 | acc=0.9844 | L2-Norm=15.082 | L2-Norm(final)=6.597 | 4478.1 samples/s | 70.0 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=33.7] | Loss=0.00499 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.135 | L2-Norm(final)=6.629 | 3469.1 samples/s | 54.2 steps/s
[Step=34550 Epoch=33.7] | Loss=0.00975 | Reg=0.00229 | acc=0.9844 | L2-Norm=15.143 | L2-Norm(final)=6.632 | 3567.3 samples/s | 55.7 steps/s
[Step=34600 Epoch=33.8] | Loss=0.01335 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.154 | L2-Norm(final)=6.631 | 3920.6 samples/s | 61.3 steps/s
[Step=34650 Epoch=33.8] | Loss=0.01465 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.170 | L2-Norm(final)=6.628 | 3937.4 samples/s | 61.5 steps/s
[Step=34700 Epoch=33.9] | Loss=0.01514 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.186 | L2-Norm(final)=6.626 | 3931.1 samples/s | 61.4 steps/s
[Step=34750 Epoch=33.9] | Loss=0.01564 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.201 | L2-Norm(final)=6.625 | 3889.1 samples/s | 60.8 steps/s
[Step=34800 Epoch=34.0] | Loss=0.01602 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.214 | L2-Norm(final)=6.624 | 3903.6 samples/s | 61.0 steps/s
[Step=34850 Epoch=34.0] | Loss=0.01562 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.228 | L2-Norm(final)=6.625 | 3983.1 samples/s | 62.2 steps/s
[Step=34900 Epoch=34.1] | Loss=0.01554 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.241 | L2-Norm(final)=6.627 | 3919.6 samples/s | 61.2 steps/s
[Step=34950 Epoch=34.1] | Loss=0.01546 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.254 | L2-Norm(final)=6.627 | 3927.4 samples/s | 61.4 steps/s
[Step=35000 Epoch=34.2] | Loss=0.01562 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.266 | L2-Norm(final)=6.627 | 3977.1 samples/s | 62.1 steps/s
[Step=35050 Epoch=34.2] | Loss=0.01569 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.277 | L2-Norm(final)=6.627 | 4002.9 samples/s | 62.5 steps/s
[Step=35100 Epoch=34.3] | Loss=0.01589 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.288 | L2-Norm(final)=6.627 | 3921.1 samples/s | 61.3 steps/s
[Step=35150 Epoch=34.3] | Loss=0.01569 | Reg=0.00234 | acc=0.9688 | L2-Norm=15.299 | L2-Norm(final)=6.627 | 3936.9 samples/s | 61.5 steps/s
[Step=35200 Epoch=34.4] | Loss=0.01580 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.309 | L2-Norm(final)=6.627 | 3997.3 samples/s | 62.5 steps/s
[Step=35250 Epoch=34.4] | Loss=0.01605 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.319 | L2-Norm(final)=6.627 | 3965.7 samples/s | 62.0 steps/s
[Step=35300 Epoch=34.5] | Loss=0.01619 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.329 | L2-Norm(final)=6.626 | 3944.3 samples/s | 61.6 steps/s
[Step=35350 Epoch=34.5] | Loss=0.01640 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.339 | L2-Norm(final)=6.624 | 3984.0 samples/s | 62.3 steps/s
[Step=35400 Epoch=34.6] | Loss=0.01637 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.348 | L2-Norm(final)=6.624 | 3896.9 samples/s | 60.9 steps/s
[Step=35450 Epoch=34.6] | Loss=0.01630 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.358 | L2-Norm(final)=6.623 | 3975.0 samples/s | 62.1 steps/s
[Step=35500 Epoch=34.7] | Loss=0.01634 | Reg=0.00236 | acc=0.9844 | L2-Norm=15.368 | L2-Norm(final)=6.622 | 4220.4 samples/s | 65.9 steps/s
[Step=35550 Epoch=34.7] | Loss=0.01628 | Reg=0.00236 | acc=1.0000 | L2-Norm=15.378 | L2-Norm(final)=6.623 | 1650.3 samples/s | 25.8 steps/s
[Step=35600 Epoch=34.8] | Loss=0.01622 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.388 | L2-Norm(final)=6.623 | 3940.2 samples/s | 61.6 steps/s
[Step=35650 Epoch=34.8] | Loss=0.01619 | Reg=0.00237 | acc=0.9844 | L2-Norm=15.398 | L2-Norm(final)=6.623 | 3866.1 samples/s | 60.4 steps/s
[Step=35700 Epoch=34.9] | Loss=0.01613 | Reg=0.00237 | acc=0.9531 | L2-Norm=15.407 | L2-Norm(final)=6.624 | 3881.7 samples/s | 60.7 steps/s
[Step=35750 Epoch=34.9] | Loss=0.01606 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.416 | L2-Norm(final)=6.624 | 3954.9 samples/s | 61.8 steps/s
[Step=35800 Epoch=35.0] | Loss=0.01607 | Reg=0.00238 | acc=0.9844 | L2-Norm=15.425 | L2-Norm(final)=6.624 | 3923.5 samples/s | 61.3 steps/s
[Step=35850 Epoch=35.0] | Loss=0.01594 | Reg=0.00238 | acc=1.0000 | L2-Norm=15.435 | L2-Norm(final)=6.624 | 3934.7 samples/s | 61.5 steps/s
[Step=35900 Epoch=35.1] | Loss=0.01575 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.444 | L2-Norm(final)=6.625 | 3954.9 samples/s | 61.8 steps/s
[Step=35950 Epoch=35.1] | Loss=0.01576 | Reg=0.00239 | acc=0.9688 | L2-Norm=15.453 | L2-Norm(final)=6.625 | 3883.2 samples/s | 60.7 steps/s
[Step=36000 Epoch=35.1] | Loss=0.01569 | Reg=0.00239 | acc=0.9844 | L2-Norm=15.462 | L2-Norm(final)=6.626 | 3923.3 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step36000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=34001 Epoch=64.1] | Loss=0.00003 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.974 | L2-Norm(final)=4.731 | 3390.7 samples/s | 53.0 steps/s
[Step=34050 Epoch=64.2] | Loss=0.00022 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=4.736 | 3790.8 samples/s | 59.2 steps/s
[Step=34100 Epoch=64.3] | Loss=0.00018 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=4.742 | 4148.8 samples/s | 64.8 steps/s
[Step=34150 Epoch=64.4] | Loss=0.00015 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=4.747 | 4113.0 samples/s | 64.3 steps/s
[Step=34200 Epoch=64.5] | Loss=0.00012 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.947 | L2-Norm(final)=4.752 | 4059.6 samples/s | 63.4 steps/s
[Step=34250 Epoch=64.6] | Loss=0.00011 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.938 | L2-Norm(final)=4.757 | 4166.0 samples/s | 65.1 steps/s
[Step=34300 Epoch=64.7] | Loss=0.00011 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.930 | L2-Norm(final)=4.761 | 4125.1 samples/s | 64.5 steps/s
[Step=34350 Epoch=64.8] | Loss=0.00011 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.924 | L2-Norm(final)=4.766 | 4018.0 samples/s | 62.8 steps/s
[Step=34400 Epoch=64.8] | Loss=0.00010 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.919 | L2-Norm(final)=4.770 | 4111.4 samples/s | 64.2 steps/s
[Step=34450 Epoch=64.9] | Loss=0.00010 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=4.776 | 4110.6 samples/s | 64.2 steps/s
[Step=34500 Epoch=65.0] | Loss=0.00011 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.911 | L2-Norm(final)=4.781 | 4188.1 samples/s | 65.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=34501 Epoch=65.0] | Loss=0.00001 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.887 | L2-Norm(final)=4.829 | 3238.0 samples/s | 50.6 steps/s
[Step=34550 Epoch=65.1] | Loss=0.00002 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.873 | L2-Norm(final)=4.832 | 3627.5 samples/s | 56.7 steps/s
[Step=34600 Epoch=65.2] | Loss=0.00003 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.852 | L2-Norm(final)=4.833 | 3756.7 samples/s | 58.7 steps/s
[Step=34650 Epoch=65.3] | Loss=0.00002 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.832 | L2-Norm(final)=4.836 | 3732.6 samples/s | 58.3 steps/s
[Step=34700 Epoch=65.4] | Loss=0.00002 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.811 | L2-Norm(final)=4.837 | 3681.7 samples/s | 57.5 steps/s
[Step=34750 Epoch=65.5] | Loss=0.00002 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.789 | L2-Norm(final)=4.839 | 3731.6 samples/s | 58.3 steps/s
[Step=34800 Epoch=65.6] | Loss=0.00002 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.768 | L2-Norm(final)=4.840 | 3733.6 samples/s | 58.3 steps/s
[Step=34850 Epoch=65.7] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.747 | L2-Norm(final)=4.841 | 3709.3 samples/s | 58.0 steps/s
[Step=34900 Epoch=65.8] | Loss=0.00001 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.726 | L2-Norm(final)=4.843 | 3720.5 samples/s | 58.1 steps/s
[Step=34950 Epoch=65.9] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=4.844 | 3761.0 samples/s | 58.8 steps/s
[Step=35000 Epoch=66.0] | Loss=0.00001 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.683 | L2-Norm(final)=4.845 | 3764.0 samples/s | 58.8 steps/s
[Step=35050 Epoch=66.1] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.661 | L2-Norm(final)=4.846 | 1652.3 samples/s | 25.8 steps/s
[Step=35100 Epoch=66.2] | Loss=0.00001 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.640 | L2-Norm(final)=4.846 | 3753.1 samples/s | 58.6 steps/s
[Step=35150 Epoch=66.3] | Loss=0.00001 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=4.847 | 3714.0 samples/s | 58.0 steps/s
[Step=35200 Epoch=66.4] | Loss=0.00001 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.596 | L2-Norm(final)=4.848 | 3704.9 samples/s | 57.9 steps/s
[Step=35250 Epoch=66.4] | Loss=0.00001 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.574 | L2-Norm(final)=4.849 | 3757.4 samples/s | 58.7 steps/s
[Step=35300 Epoch=66.5] | Loss=0.00001 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=4.849 | 3721.3 samples/s | 58.1 steps/s
[Step=35350 Epoch=66.6] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.529 | L2-Norm(final)=4.850 | 3724.7 samples/s | 58.2 steps/s
[Step=35400 Epoch=66.7] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.507 | L2-Norm(final)=4.850 | 3748.9 samples/s | 58.6 steps/s
[Step=35450 Epoch=66.8] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.484 | L2-Norm(final)=4.851 | 3711.4 samples/s | 58.0 steps/s
[Step=35500 Epoch=66.9] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.461 | L2-Norm(final)=4.852 | 3711.0 samples/s | 58.0 steps/s
[Step=35550 Epoch=67.0] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.439 | L2-Norm(final)=4.852 | 4673.9 samples/s | 73.0 steps/s
[Step=35600 Epoch=67.1] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.416 | L2-Norm(final)=4.853 | 1531.8 samples/s | 23.9 steps/s
[Step=35650 Epoch=67.2] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.393 | L2-Norm(final)=4.853 | 3682.4 samples/s | 57.5 steps/s
[Step=35700 Epoch=67.3] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.370 | L2-Norm(final)=4.854 | 3708.6 samples/s | 57.9 steps/s
[Step=35750 Epoch=67.4] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.346 | L2-Norm(final)=4.854 | 3730.5 samples/s | 58.3 steps/s
[Step=35800 Epoch=67.5] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.323 | L2-Norm(final)=4.855 | 3690.4 samples/s | 57.7 steps/s
[Step=35850 Epoch=67.6] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.299 | L2-Norm(final)=4.855 | 3734.7 samples/s | 58.4 steps/s
[Step=35900 Epoch=67.7] | Loss=0.00001 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.275 | L2-Norm(final)=4.856 | 3743.6 samples/s | 58.5 steps/s
[Step=35950 Epoch=67.8] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.252 | L2-Norm(final)=4.857 | 3776.2 samples/s | 59.0 steps/s
[Step=36000 Epoch=67.9] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.228 | L2-Norm(final)=4.857 | 3695.8 samples/s | 57.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step36000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06066 | acc=0.9706 | tpr=0.9755 | fpr=0.0399 | 3632.8 samples/s | 14.2 steps/s
Avg test loss: 0.06056, Avg test acc: 0.96947, Avg tpr: 0.97435, Avg fpr: 0.04128, total FA: 322

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.23009 | acc=0.3050 | tpr=0.0265 | fpr=0.0902 | 3630.2 samples/s | 14.2 steps/s
Avg test loss: 6.21966, Avg test acc: 0.30495, Avg tpr: 0.02780, Avg fpr: 0.08550, total FA: 667

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.66854 | acc=0.1334 | tpr=0.6637 | fpr=0.8762 | 3620.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.64108 | acc=0.1361 | tpr=0.6780 | fpr=0.8740 | 6944.4 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.63782 | acc=0.1348 | tpr=0.6902 | fpr=0.8755 | 6833.0 samples/s | 26.7 steps/s
[Step= 200] | Loss=5.61778 | acc=0.1347 | tpr=0.6874 | fpr=0.8754 | 6910.7 samples/s | 27.0 steps/s
[Step= 250] | Loss=5.61960 | acc=0.1345 | tpr=0.6865 | fpr=0.8756 | 6890.4 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.61712 | acc=0.1348 | tpr=0.6844 | fpr=0.8752 | 7032.7 samples/s | 27.5 steps/s
[Step= 350] | Loss=5.61446 | acc=0.1344 | tpr=0.6857 | fpr=0.8756 | 6722.1 samples/s | 26.3 steps/s
[Step= 400] | Loss=5.61765 | acc=0.1342 | tpr=0.6800 | fpr=0.8757 | 6856.7 samples/s | 26.8 steps/s
[Step= 450] | Loss=5.61679 | acc=0.1344 | tpr=0.6796 | fpr=0.8755 | 6782.1 samples/s | 26.5 steps/s
[Step= 500] | Loss=5.62138 | acc=0.1349 | tpr=0.6815 | fpr=0.8750 | 6921.8 samples/s | 27.0 steps/s
[Step= 550] | Loss=5.62209 | acc=0.1352 | tpr=0.6852 | fpr=0.8748 | 12542.9 samples/s | 49.0 steps/s
Avg test loss: 5.62295, Avg test acc: 0.13516, Avg tpr: 0.68542, Avg fpr: 0.87484, total FA: 121470

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12558 | acc=0.9816 | tpr=0.9646 | fpr=0.0181 | 3659.5 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.13316 | acc=0.9807 | tpr=0.9659 | fpr=0.0190 | 6696.4 samples/s | 26.2 steps/s
[Step= 150] | Loss=0.13537 | acc=0.9801 | tpr=0.9654 | fpr=0.0196 | 7011.0 samples/s | 27.4 steps/s
[Step= 200] | Loss=0.13686 | acc=0.9800 | tpr=0.9683 | fpr=0.0198 | 6679.1 samples/s | 26.1 steps/s
[Step= 250] | Loss=0.13517 | acc=0.9801 | tpr=0.9668 | fpr=0.0197 | 6963.6 samples/s | 27.2 steps/s
[Step= 300] | Loss=0.13779 | acc=0.9797 | tpr=0.9636 | fpr=0.0200 | 6782.2 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.13818 | acc=0.9796 | tpr=0.9643 | fpr=0.0201 | 6975.5 samples/s | 27.2 steps/s
[Step= 400] | Loss=0.13922 | acc=0.9794 | tpr=0.9633 | fpr=0.0203 | 6691.7 samples/s | 26.1 steps/s
[Step= 450] | Loss=0.14234 | acc=0.9791 | tpr=0.9601 | fpr=0.0206 | 6608.2 samples/s | 25.8 steps/s
[Step= 500] | Loss=0.14166 | acc=0.9790 | tpr=0.9604 | fpr=0.0206 | 6779.0 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.14065 | acc=0.9792 | tpr=0.9602 | fpr=0.0205 | 12382.2 samples/s | 48.4 steps/s
Avg test loss: 0.14029, Avg test acc: 0.97923, Avg tpr: 0.96038, Avg fpr: 0.02043, total FA: 2837

server round 18/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=35.1] | Loss=0.01344 | Reg=0.00209 | acc=0.9844 | L2-Norm=14.443 | L2-Norm(final)=6.645 | 3276.5 samples/s | 51.2 steps/s
[Step=36050 Epoch=35.2] | Loss=0.00941 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.465 | L2-Norm(final)=6.650 | 4163.9 samples/s | 65.1 steps/s
[Step=36100 Epoch=35.2] | Loss=0.01070 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.480 | L2-Norm(final)=6.655 | 4297.9 samples/s | 67.2 steps/s
[Step=36150 Epoch=35.3] | Loss=0.01101 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.490 | L2-Norm(final)=6.658 | 4362.0 samples/s | 68.2 steps/s
[Step=36200 Epoch=35.3] | Loss=0.01028 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.498 | L2-Norm(final)=6.663 | 4308.1 samples/s | 67.3 steps/s
[Step=36250 Epoch=35.4] | Loss=0.01076 | Reg=0.00210 | acc=0.9844 | L2-Norm=14.505 | L2-Norm(final)=6.668 | 4356.1 samples/s | 68.1 steps/s
[Step=36300 Epoch=35.4] | Loss=0.01038 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.511 | L2-Norm(final)=6.672 | 4345.6 samples/s | 67.9 steps/s
[Step=36350 Epoch=35.5] | Loss=0.01049 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.517 | L2-Norm(final)=6.677 | 4362.0 samples/s | 68.2 steps/s
[Step=36400 Epoch=35.5] | Loss=0.01039 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.522 | L2-Norm(final)=6.682 | 4381.8 samples/s | 68.5 steps/s
[Step=36450 Epoch=35.6] | Loss=0.01040 | Reg=0.00211 | acc=0.9844 | L2-Norm=14.527 | L2-Norm(final)=6.687 | 4324.2 samples/s | 67.6 steps/s
[Step=36500 Epoch=35.6] | Loss=0.01040 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.533 | L2-Norm(final)=6.692 | 4356.3 samples/s | 68.1 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=35.6] | Loss=0.01044 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.590 | L2-Norm(final)=6.739 | 3343.8 samples/s | 52.2 steps/s
[Step=36550 Epoch=35.7] | Loss=0.01221 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.599 | L2-Norm(final)=6.745 | 3646.7 samples/s | 57.0 steps/s
[Step=36600 Epoch=35.7] | Loss=0.01401 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=6.745 | 3917.1 samples/s | 61.2 steps/s
[Step=36650 Epoch=35.8] | Loss=0.01617 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.629 | L2-Norm(final)=6.743 | 3926.6 samples/s | 61.4 steps/s
[Step=36700 Epoch=35.8] | Loss=0.01541 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.642 | L2-Norm(final)=6.741 | 3847.5 samples/s | 60.1 steps/s
[Step=36750 Epoch=35.9] | Loss=0.01560 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.655 | L2-Norm(final)=6.741 | 3901.1 samples/s | 61.0 steps/s
[Step=36800 Epoch=35.9] | Loss=0.01578 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=6.742 | 3971.5 samples/s | 62.1 steps/s
[Step=36850 Epoch=36.0] | Loss=0.01530 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.680 | L2-Norm(final)=6.741 | 3912.9 samples/s | 61.1 steps/s
[Step=36900 Epoch=36.0] | Loss=0.01517 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.694 | L2-Norm(final)=6.742 | 3945.0 samples/s | 61.6 steps/s
[Step=36950 Epoch=36.1] | Loss=0.01552 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.709 | L2-Norm(final)=6.743 | 3926.8 samples/s | 61.4 steps/s
[Step=37000 Epoch=36.1] | Loss=0.01531 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.722 | L2-Norm(final)=6.744 | 3974.4 samples/s | 62.1 steps/s
[Step=37050 Epoch=36.2] | Loss=0.01568 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.735 | L2-Norm(final)=6.746 | 3911.6 samples/s | 61.1 steps/s
[Step=37100 Epoch=36.2] | Loss=0.01600 | Reg=0.00218 | acc=1.0000 | L2-Norm=14.748 | L2-Norm(final)=6.746 | 3998.2 samples/s | 62.5 steps/s
[Step=37150 Epoch=36.3] | Loss=0.01598 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.761 | L2-Norm(final)=6.746 | 3926.5 samples/s | 61.4 steps/s
[Step=37200 Epoch=36.3] | Loss=0.01606 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.774 | L2-Norm(final)=6.747 | 3976.7 samples/s | 62.1 steps/s
[Step=37250 Epoch=36.4] | Loss=0.01596 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.786 | L2-Norm(final)=6.748 | 3970.5 samples/s | 62.0 steps/s
[Step=37300 Epoch=36.4] | Loss=0.01612 | Reg=0.00219 | acc=0.9688 | L2-Norm=14.799 | L2-Norm(final)=6.748 | 3915.0 samples/s | 61.2 steps/s
[Step=37350 Epoch=36.5] | Loss=0.01614 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.811 | L2-Norm(final)=6.748 | 3950.2 samples/s | 61.7 steps/s
[Step=37400 Epoch=36.5] | Loss=0.01644 | Reg=0.00220 | acc=0.9688 | L2-Norm=14.823 | L2-Norm(final)=6.748 | 3959.4 samples/s | 61.9 steps/s
[Step=37450 Epoch=36.6] | Loss=0.01630 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.835 | L2-Norm(final)=6.748 | 3992.0 samples/s | 62.4 steps/s
[Step=37500 Epoch=36.6] | Loss=0.01635 | Reg=0.00220 | acc=0.9844 | L2-Norm=14.847 | L2-Norm(final)=6.748 | 4264.6 samples/s | 66.6 steps/s
[Step=37550 Epoch=36.7] | Loss=0.01630 | Reg=0.00221 | acc=0.9844 | L2-Norm=14.858 | L2-Norm(final)=6.748 | 1638.6 samples/s | 25.6 steps/s
[Step=37600 Epoch=36.7] | Loss=0.01615 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.870 | L2-Norm(final)=6.749 | 3966.4 samples/s | 62.0 steps/s
[Step=37650 Epoch=36.8] | Loss=0.01617 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.881 | L2-Norm(final)=6.750 | 3906.0 samples/s | 61.0 steps/s
[Step=37700 Epoch=36.8] | Loss=0.01607 | Reg=0.00222 | acc=0.9844 | L2-Norm=14.892 | L2-Norm(final)=6.751 | 3927.0 samples/s | 61.4 steps/s
[Step=37750 Epoch=36.9] | Loss=0.01610 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.903 | L2-Norm(final)=6.752 | 3935.5 samples/s | 61.5 steps/s
[Step=37800 Epoch=36.9] | Loss=0.01615 | Reg=0.00222 | acc=0.9688 | L2-Norm=14.914 | L2-Norm(final)=6.753 | 3945.5 samples/s | 61.6 steps/s
[Step=37850 Epoch=37.0] | Loss=0.01609 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.925 | L2-Norm(final)=6.755 | 3989.0 samples/s | 62.3 steps/s
[Step=37900 Epoch=37.0] | Loss=0.01613 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.935 | L2-Norm(final)=6.755 | 3952.4 samples/s | 61.8 steps/s
[Step=37950 Epoch=37.1] | Loss=0.01599 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.946 | L2-Norm(final)=6.756 | 3973.1 samples/s | 62.1 steps/s
[Step=38000 Epoch=37.1] | Loss=0.01602 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.955 | L2-Norm(final)=6.757 | 3920.3 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step38000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=36001 Epoch=67.9] | Loss=0.00047 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.443 | L2-Norm(final)=4.875 | 3137.2 samples/s | 49.0 steps/s
[Step=36050 Epoch=68.0] | Loss=0.00169 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.496 | L2-Norm(final)=4.874 | 4034.5 samples/s | 63.0 steps/s
[Step=36100 Epoch=68.0] | Loss=0.00141 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.557 | L2-Norm(final)=4.877 | 4043.0 samples/s | 63.2 steps/s
[Step=36150 Epoch=68.1] | Loss=0.00119 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.592 | L2-Norm(final)=4.878 | 4155.9 samples/s | 64.9 steps/s
[Step=36200 Epoch=68.2] | Loss=0.00093 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.609 | L2-Norm(final)=4.881 | 4122.0 samples/s | 64.4 steps/s
[Step=36250 Epoch=68.3] | Loss=0.00079 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.616 | L2-Norm(final)=4.885 | 4094.0 samples/s | 64.0 steps/s
[Step=36300 Epoch=68.4] | Loss=0.00069 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=4.889 | 4185.0 samples/s | 65.4 steps/s
[Step=36350 Epoch=68.5] | Loss=0.00074 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=4.893 | 4059.0 samples/s | 63.4 steps/s
[Step=36400 Epoch=68.6] | Loss=0.00075 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.632 | L2-Norm(final)=4.897 | 4124.0 samples/s | 64.4 steps/s
[Step=36450 Epoch=68.7] | Loss=0.00068 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.637 | L2-Norm(final)=4.899 | 4201.3 samples/s | 65.6 steps/s
[Step=36500 Epoch=68.8] | Loss=0.00062 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.640 | L2-Norm(final)=4.902 | 4169.7 samples/s | 65.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=36501 Epoch=68.8] | Loss=0.00000 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.658 | L2-Norm(final)=4.928 | 3304.0 samples/s | 51.6 steps/s
[Step=36550 Epoch=68.9] | Loss=0.00932 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=4.916 | 3482.7 samples/s | 54.4 steps/s
[Step=36600 Epoch=69.0] | Loss=0.00838 | Reg=0.00219 | acc=0.9844 | L2-Norm=14.813 | L2-Norm(final)=4.880 | 3753.9 samples/s | 58.7 steps/s
[Step=36650 Epoch=69.1] | Loss=0.00794 | Reg=0.00221 | acc=1.0000 | L2-Norm=14.882 | L2-Norm(final)=4.858 | 3634.2 samples/s | 56.8 steps/s
[Step=36700 Epoch=69.2] | Loss=0.00626 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.921 | L2-Norm(final)=4.844 | 3696.5 samples/s | 57.8 steps/s
[Step=36750 Epoch=69.3] | Loss=0.00513 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=4.837 | 3724.9 samples/s | 58.2 steps/s
[Step=36800 Epoch=69.4] | Loss=0.00440 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.959 | L2-Norm(final)=4.833 | 3752.6 samples/s | 58.6 steps/s
[Step=36850 Epoch=69.5] | Loss=0.00388 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.969 | L2-Norm(final)=4.831 | 3764.5 samples/s | 58.8 steps/s
[Step=36900 Epoch=69.6] | Loss=0.00380 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.977 | L2-Norm(final)=4.829 | 3728.6 samples/s | 58.3 steps/s
[Step=36950 Epoch=69.7] | Loss=0.00351 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.984 | L2-Norm(final)=4.827 | 3748.3 samples/s | 58.6 steps/s
[Step=37000 Epoch=69.7] | Loss=0.00324 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.991 | L2-Norm(final)=4.825 | 3775.2 samples/s | 59.0 steps/s
[Step=37050 Epoch=69.8] | Loss=0.00305 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.996 | L2-Norm(final)=4.824 | 1658.7 samples/s | 25.9 steps/s
[Step=37100 Epoch=69.9] | Loss=0.00280 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=4.823 | 3718.8 samples/s | 58.1 steps/s
[Step=37150 Epoch=70.0] | Loss=0.00259 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=4.822 | 3683.2 samples/s | 57.5 steps/s
[Step=37200 Epoch=70.1] | Loss=0.00240 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=4.821 | 3776.2 samples/s | 59.0 steps/s
[Step=37250 Epoch=70.2] | Loss=0.00225 | Reg=0.00225 | acc=1.0000 | L2-Norm=15.001 | L2-Norm(final)=4.821 | 3745.4 samples/s | 58.5 steps/s
[Step=37300 Epoch=70.3] | Loss=0.00211 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.999 | L2-Norm(final)=4.821 | 3744.5 samples/s | 58.5 steps/s
[Step=37350 Epoch=70.4] | Loss=0.00199 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.997 | L2-Norm(final)=4.821 | 3761.0 samples/s | 58.8 steps/s
[Step=37400 Epoch=70.5] | Loss=0.00188 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.995 | L2-Norm(final)=4.821 | 3795.7 samples/s | 59.3 steps/s
[Step=37450 Epoch=70.6] | Loss=0.00178 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.992 | L2-Norm(final)=4.821 | 3729.1 samples/s | 58.3 steps/s
[Step=37500 Epoch=70.7] | Loss=0.00169 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.988 | L2-Norm(final)=4.821 | 3758.5 samples/s | 58.7 steps/s
[Step=37550 Epoch=70.8] | Loss=0.00161 | Reg=0.00225 | acc=1.0000 | L2-Norm=14.985 | L2-Norm(final)=4.821 | 4722.0 samples/s | 73.8 steps/s
[Step=37600 Epoch=70.9] | Loss=0.00154 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.980 | L2-Norm(final)=4.821 | 1519.9 samples/s | 23.7 steps/s
[Step=37650 Epoch=71.0] | Loss=0.00147 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.976 | L2-Norm(final)=4.821 | 3671.0 samples/s | 57.4 steps/s
[Step=37700 Epoch=71.1] | Loss=0.00141 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.971 | L2-Norm(final)=4.821 | 3764.3 samples/s | 58.8 steps/s
[Step=37750 Epoch=71.2] | Loss=0.00136 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.966 | L2-Norm(final)=4.822 | 3639.3 samples/s | 56.9 steps/s
[Step=37800 Epoch=71.3] | Loss=0.00130 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.961 | L2-Norm(final)=4.822 | 3704.0 samples/s | 57.9 steps/s
[Step=37850 Epoch=71.3] | Loss=0.00126 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.956 | L2-Norm(final)=4.822 | 3728.2 samples/s | 58.3 steps/s
[Step=37900 Epoch=71.4] | Loss=0.00121 | Reg=0.00224 | acc=1.0000 | L2-Norm=14.951 | L2-Norm(final)=4.823 | 3756.5 samples/s | 58.7 steps/s
[Step=37950 Epoch=71.5] | Loss=0.00117 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.945 | L2-Norm(final)=4.823 | 3678.7 samples/s | 57.5 steps/s
[Step=38000 Epoch=71.6] | Loss=0.00113 | Reg=0.00223 | acc=1.0000 | L2-Norm=14.939 | L2-Norm(final)=4.824 | 3763.2 samples/s | 58.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step38000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05936 | acc=0.9709 | tpr=0.9788 | fpr=0.0463 | 3639.9 samples/s | 14.2 steps/s
Avg test loss: 0.06149, Avg test acc: 0.96943, Avg tpr: 0.97698, Avg fpr: 0.04717, total FA: 368

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.09890 | acc=0.2998 | tpr=0.0171 | fpr=0.0862 | 3637.3 samples/s | 14.2 steps/s
Avg test loss: 6.10878, Avg test acc: 0.29734, Avg tpr: 0.01725, Avg fpr: 0.08666, total FA: 676

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.07636 | acc=0.1395 | tpr=0.7478 | fpr=0.8714 | 3612.6 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.06868 | acc=0.1415 | tpr=0.7335 | fpr=0.8695 | 6802.0 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.06679 | acc=0.1408 | tpr=0.7291 | fpr=0.8701 | 6714.2 samples/s | 26.2 steps/s
[Step= 200] | Loss=5.04703 | acc=0.1414 | tpr=0.7126 | fpr=0.8689 | 6797.6 samples/s | 26.6 steps/s
[Step= 250] | Loss=5.05499 | acc=0.1422 | tpr=0.7188 | fpr=0.8683 | 6934.7 samples/s | 27.1 steps/s
[Step= 300] | Loss=5.05474 | acc=0.1425 | tpr=0.7135 | fpr=0.8679 | 6772.2 samples/s | 26.5 steps/s
[Step= 350] | Loss=5.04952 | acc=0.1423 | tpr=0.7132 | fpr=0.8680 | 6794.6 samples/s | 26.5 steps/s
[Step= 400] | Loss=5.05376 | acc=0.1419 | tpr=0.7057 | fpr=0.8684 | 6899.4 samples/s | 27.0 steps/s
[Step= 450] | Loss=5.05555 | acc=0.1420 | tpr=0.7064 | fpr=0.8683 | 6770.6 samples/s | 26.4 steps/s
[Step= 500] | Loss=5.05686 | acc=0.1421 | tpr=0.7088 | fpr=0.8682 | 6727.3 samples/s | 26.3 steps/s
[Step= 550] | Loss=5.05542 | acc=0.1424 | tpr=0.7095 | fpr=0.8679 | 12495.0 samples/s | 48.8 steps/s
Avg test loss: 5.05631, Avg test acc: 0.14228, Avg tpr: 0.70959, Avg fpr: 0.86804, total FA: 120525

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.13039 | acc=0.9812 | tpr=0.9513 | fpr=0.0182 | 3577.4 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.13701 | acc=0.9808 | tpr=0.9638 | fpr=0.0189 | 6987.1 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.13957 | acc=0.9801 | tpr=0.9654 | fpr=0.0197 | 6566.5 samples/s | 25.7 steps/s
[Step= 200] | Loss=0.14139 | acc=0.9800 | tpr=0.9672 | fpr=0.0198 | 6946.6 samples/s | 27.1 steps/s
[Step= 250] | Loss=0.13887 | acc=0.9803 | tpr=0.9659 | fpr=0.0195 | 6868.3 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.14175 | acc=0.9799 | tpr=0.9636 | fpr=0.0198 | 6818.1 samples/s | 26.6 steps/s
[Step= 350] | Loss=0.14234 | acc=0.9796 | tpr=0.9643 | fpr=0.0202 | 6853.4 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.14304 | acc=0.9794 | tpr=0.9633 | fpr=0.0203 | 6769.1 samples/s | 26.4 steps/s
[Step= 450] | Loss=0.14698 | acc=0.9790 | tpr=0.9606 | fpr=0.0207 | 7049.6 samples/s | 27.5 steps/s
[Step= 500] | Loss=0.14634 | acc=0.9791 | tpr=0.9599 | fpr=0.0206 | 6635.3 samples/s | 25.9 steps/s
[Step= 550] | Loss=0.14536 | acc=0.9793 | tpr=0.9594 | fpr=0.0204 | 12528.5 samples/s | 48.9 steps/s
Avg test loss: 0.14501, Avg test acc: 0.97930, Avg tpr: 0.95959, Avg fpr: 0.02035, total FA: 2825

server round 19/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=37.1] | Loss=0.03428 | Reg=0.00217 | acc=0.9844 | L2-Norm=14.728 | L2-Norm(final)=6.773 | 3435.6 samples/s | 53.7 steps/s
[Step=38050 Epoch=37.1] | Loss=0.02703 | Reg=0.00218 | acc=0.9844 | L2-Norm=14.772 | L2-Norm(final)=6.787 | 4045.7 samples/s | 63.2 steps/s
[Step=38100 Epoch=37.2] | Loss=0.02605 | Reg=0.00219 | acc=1.0000 | L2-Norm=14.805 | L2-Norm(final)=6.804 | 4427.7 samples/s | 69.2 steps/s
[Step=38150 Epoch=37.2] | Loss=0.02533 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.826 | L2-Norm(final)=6.817 | 4362.5 samples/s | 68.2 steps/s
[Step=38200 Epoch=37.3] | Loss=0.02416 | Reg=0.00220 | acc=1.0000 | L2-Norm=14.843 | L2-Norm(final)=6.830 | 4325.0 samples/s | 67.6 steps/s
[Step=38250 Epoch=37.3] | Loss=0.02308 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.858 | L2-Norm(final)=6.842 | 4379.4 samples/s | 68.4 steps/s
[Step=38300 Epoch=37.4] | Loss=0.02305 | Reg=0.00221 | acc=0.9688 | L2-Norm=14.874 | L2-Norm(final)=6.852 | 4382.9 samples/s | 68.5 steps/s
[Step=38350 Epoch=37.4] | Loss=0.02262 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.888 | L2-Norm(final)=6.862 | 4446.1 samples/s | 69.5 steps/s
[Step=38400 Epoch=37.5] | Loss=0.02206 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.901 | L2-Norm(final)=6.871 | 4430.6 samples/s | 69.2 steps/s
[Step=38450 Epoch=37.5] | Loss=0.02172 | Reg=0.00222 | acc=1.0000 | L2-Norm=14.914 | L2-Norm(final)=6.881 | 4463.5 samples/s | 69.7 steps/s
[Step=38500 Epoch=37.6] | Loss=0.02120 | Reg=0.00223 | acc=0.9844 | L2-Norm=14.926 | L2-Norm(final)=6.892 | 4379.0 samples/s | 68.4 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=37.6] | Loss=0.01386 | Reg=0.00226 | acc=0.9844 | L2-Norm=15.046 | L2-Norm(final)=7.001 | 3312.3 samples/s | 51.8 steps/s
[Step=38550 Epoch=37.6] | Loss=0.01966 | Reg=0.00227 | acc=1.0000 | L2-Norm=15.066 | L2-Norm(final)=7.006 | 3851.2 samples/s | 60.2 steps/s
[Step=38600 Epoch=37.7] | Loss=0.01990 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.083 | L2-Norm(final)=7.009 | 3939.2 samples/s | 61.5 steps/s
[Step=38650 Epoch=37.7] | Loss=0.01890 | Reg=0.00228 | acc=0.9688 | L2-Norm=15.099 | L2-Norm(final)=7.010 | 3994.5 samples/s | 62.4 steps/s
[Step=38700 Epoch=37.8] | Loss=0.01797 | Reg=0.00228 | acc=1.0000 | L2-Norm=15.112 | L2-Norm(final)=7.009 | 3952.4 samples/s | 61.8 steps/s
[Step=38750 Epoch=37.8] | Loss=0.01788 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.123 | L2-Norm(final)=7.010 | 3922.8 samples/s | 61.3 steps/s
[Step=38800 Epoch=37.9] | Loss=0.01739 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.134 | L2-Norm(final)=7.010 | 3940.5 samples/s | 61.6 steps/s
[Step=38850 Epoch=37.9] | Loss=0.01784 | Reg=0.00229 | acc=1.0000 | L2-Norm=15.145 | L2-Norm(final)=7.009 | 3943.5 samples/s | 61.6 steps/s
[Step=38900 Epoch=38.0] | Loss=0.01809 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.155 | L2-Norm(final)=7.008 | 3964.9 samples/s | 62.0 steps/s
[Step=38950 Epoch=38.0] | Loss=0.01769 | Reg=0.00230 | acc=0.9844 | L2-Norm=15.167 | L2-Norm(final)=7.007 | 4007.4 samples/s | 62.6 steps/s
[Step=39000 Epoch=38.1] | Loss=0.01767 | Reg=0.00230 | acc=0.9688 | L2-Norm=15.177 | L2-Norm(final)=7.007 | 3949.4 samples/s | 61.7 steps/s
[Step=39050 Epoch=38.1] | Loss=0.01768 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.187 | L2-Norm(final)=7.007 | 3975.6 samples/s | 62.1 steps/s
[Step=39100 Epoch=38.2] | Loss=0.01766 | Reg=0.00231 | acc=0.9688 | L2-Norm=15.197 | L2-Norm(final)=7.007 | 3947.6 samples/s | 61.7 steps/s
[Step=39150 Epoch=38.2] | Loss=0.01750 | Reg=0.00231 | acc=0.9844 | L2-Norm=15.207 | L2-Norm(final)=7.007 | 3964.4 samples/s | 61.9 steps/s
[Step=39200 Epoch=38.3] | Loss=0.01758 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.216 | L2-Norm(final)=7.007 | 3951.9 samples/s | 61.7 steps/s
[Step=39250 Epoch=38.3] | Loss=0.01756 | Reg=0.00232 | acc=0.9688 | L2-Norm=15.226 | L2-Norm(final)=7.008 | 3997.7 samples/s | 62.5 steps/s
[Step=39300 Epoch=38.4] | Loss=0.01745 | Reg=0.00232 | acc=1.0000 | L2-Norm=15.235 | L2-Norm(final)=7.008 | 3979.2 samples/s | 62.2 steps/s
[Step=39350 Epoch=38.4] | Loss=0.01732 | Reg=0.00232 | acc=0.9844 | L2-Norm=15.244 | L2-Norm(final)=7.008 | 3956.4 samples/s | 61.8 steps/s
[Step=39400 Epoch=38.5] | Loss=0.01742 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.253 | L2-Norm(final)=7.009 | 3958.3 samples/s | 61.8 steps/s
[Step=39450 Epoch=38.5] | Loss=0.01754 | Reg=0.00233 | acc=0.9688 | L2-Norm=15.261 | L2-Norm(final)=7.008 | 3992.6 samples/s | 62.4 steps/s
[Step=39500 Epoch=38.6] | Loss=0.01746 | Reg=0.00233 | acc=1.0000 | L2-Norm=15.270 | L2-Norm(final)=7.008 | 4249.9 samples/s | 66.4 steps/s
[Step=39550 Epoch=38.6] | Loss=0.01735 | Reg=0.00233 | acc=0.9844 | L2-Norm=15.279 | L2-Norm(final)=7.007 | 1645.7 samples/s | 25.7 steps/s
[Step=39600 Epoch=38.7] | Loss=0.01733 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.287 | L2-Norm(final)=7.007 | 3952.6 samples/s | 61.8 steps/s
[Step=39650 Epoch=38.7] | Loss=0.01715 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.295 | L2-Norm(final)=7.006 | 3878.0 samples/s | 60.6 steps/s
[Step=39700 Epoch=38.8] | Loss=0.01708 | Reg=0.00234 | acc=0.9844 | L2-Norm=15.303 | L2-Norm(final)=7.006 | 3958.3 samples/s | 61.8 steps/s
[Step=39750 Epoch=38.8] | Loss=0.01709 | Reg=0.00234 | acc=1.0000 | L2-Norm=15.311 | L2-Norm(final)=7.005 | 3970.5 samples/s | 62.0 steps/s
[Step=39800 Epoch=38.9] | Loss=0.01712 | Reg=0.00235 | acc=1.0000 | L2-Norm=15.319 | L2-Norm(final)=7.004 | 3940.3 samples/s | 61.6 steps/s
[Step=39850 Epoch=38.9] | Loss=0.01699 | Reg=0.00235 | acc=0.9688 | L2-Norm=15.327 | L2-Norm(final)=7.003 | 3962.8 samples/s | 61.9 steps/s
[Step=39900 Epoch=39.0] | Loss=0.01689 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.334 | L2-Norm(final)=7.002 | 3986.9 samples/s | 62.3 steps/s
[Step=39950 Epoch=39.0] | Loss=0.01674 | Reg=0.00235 | acc=0.9844 | L2-Norm=15.342 | L2-Norm(final)=7.001 | 3984.7 samples/s | 62.3 steps/s
[Step=40000 Epoch=39.1] | Loss=0.01673 | Reg=0.00236 | acc=0.9688 | L2-Norm=15.349 | L2-Norm(final)=7.001 | 3941.1 samples/s | 61.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step40000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00050, len=1
[Step=38001 Epoch=71.6] | Loss=0.00012 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.728 | L2-Norm(final)=4.840 | 3461.5 samples/s | 54.1 steps/s
[Step=38050 Epoch=71.7] | Loss=0.00016 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=4.845 | 3718.6 samples/s | 58.1 steps/s
[Step=38100 Epoch=71.8] | Loss=0.00015 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.714 | L2-Norm(final)=4.850 | 4081.2 samples/s | 63.8 steps/s
[Step=38150 Epoch=71.9] | Loss=0.00015 | Reg=0.00217 | acc=1.0000 | L2-Norm=14.715 | L2-Norm(final)=4.855 | 4213.3 samples/s | 65.8 steps/s
[Step=38200 Epoch=72.0] | Loss=0.00013 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.712 | L2-Norm(final)=4.859 | 4070.2 samples/s | 63.6 steps/s
[Step=38250 Epoch=72.1] | Loss=0.00013 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.709 | L2-Norm(final)=4.862 | 4140.5 samples/s | 64.7 steps/s
[Step=38300 Epoch=72.2] | Loss=0.00012 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.706 | L2-Norm(final)=4.866 | 4149.5 samples/s | 64.8 steps/s
[Step=38350 Epoch=72.3] | Loss=0.00011 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=4.869 | 4161.1 samples/s | 65.0 steps/s
[Step=38400 Epoch=72.4] | Loss=0.00010 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.699 | L2-Norm(final)=4.873 | 4049.9 samples/s | 63.3 steps/s
[Step=38450 Epoch=72.5] | Loss=0.00010 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.695 | L2-Norm(final)=4.876 | 4172.3 samples/s | 65.2 steps/s
[Step=38500 Epoch=72.6] | Loss=0.00009 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.690 | L2-Norm(final)=4.880 | 4174.7 samples/s | 65.2 steps/s
All layers training...
LR=0.00050, len=1
[Step=38501 Epoch=72.6] | Loss=0.00001 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.646 | L2-Norm(final)=4.914 | 3218.9 samples/s | 50.3 steps/s
[Step=38550 Epoch=72.7] | Loss=0.00002 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.638 | L2-Norm(final)=4.918 | 3559.6 samples/s | 55.6 steps/s
[Step=38600 Epoch=72.8] | Loss=0.00002 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.627 | L2-Norm(final)=4.921 | 3732.7 samples/s | 58.3 steps/s
[Step=38650 Epoch=72.9] | Loss=0.00003 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.617 | L2-Norm(final)=4.923 | 3687.5 samples/s | 57.6 steps/s
[Step=38700 Epoch=73.0] | Loss=0.00002 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.606 | L2-Norm(final)=4.925 | 3678.9 samples/s | 57.5 steps/s
[Step=38750 Epoch=73.0] | Loss=0.00002 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.595 | L2-Norm(final)=4.927 | 3712.4 samples/s | 58.0 steps/s
[Step=38800 Epoch=73.1] | Loss=0.00002 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.584 | L2-Norm(final)=4.929 | 3696.6 samples/s | 57.8 steps/s
[Step=38850 Epoch=73.2] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=4.931 | 3709.4 samples/s | 58.0 steps/s
[Step=38900 Epoch=73.3] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.562 | L2-Norm(final)=4.933 | 3751.4 samples/s | 58.6 steps/s
[Step=38950 Epoch=73.4] | Loss=0.00002 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.552 | L2-Norm(final)=4.934 | 3746.4 samples/s | 58.5 steps/s
[Step=39000 Epoch=73.5] | Loss=0.00002 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.541 | L2-Norm(final)=4.936 | 3727.7 samples/s | 58.2 steps/s
[Step=39050 Epoch=73.6] | Loss=0.00002 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.530 | L2-Norm(final)=4.937 | 1604.2 samples/s | 25.1 steps/s
[Step=39100 Epoch=73.7] | Loss=0.00001 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.519 | L2-Norm(final)=4.938 | 3721.3 samples/s | 58.1 steps/s
[Step=39150 Epoch=73.8] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.508 | L2-Norm(final)=4.940 | 3684.9 samples/s | 57.6 steps/s
[Step=39200 Epoch=73.9] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.497 | L2-Norm(final)=4.941 | 3706.7 samples/s | 57.9 steps/s
[Step=39250 Epoch=74.0] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.485 | L2-Norm(final)=4.942 | 3671.3 samples/s | 57.4 steps/s
[Step=39300 Epoch=74.1] | Loss=0.00001 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.474 | L2-Norm(final)=4.943 | 3666.7 samples/s | 57.3 steps/s
[Step=39350 Epoch=74.2] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.463 | L2-Norm(final)=4.944 | 3727.1 samples/s | 58.2 steps/s
[Step=39400 Epoch=74.3] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.451 | L2-Norm(final)=4.946 | 3721.2 samples/s | 58.1 steps/s
[Step=39450 Epoch=74.4] | Loss=0.00001 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.440 | L2-Norm(final)=4.947 | 3723.5 samples/s | 58.2 steps/s
[Step=39500 Epoch=74.5] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.428 | L2-Norm(final)=4.948 | 3703.5 samples/s | 57.9 steps/s
[Step=39550 Epoch=74.6] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.417 | L2-Norm(final)=4.949 | 4731.6 samples/s | 73.9 steps/s
[Step=39600 Epoch=74.6] | Loss=0.00001 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.405 | L2-Norm(final)=4.950 | 1533.1 samples/s | 24.0 steps/s
[Step=39650 Epoch=74.7] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.393 | L2-Norm(final)=4.951 | 3692.3 samples/s | 57.7 steps/s
[Step=39700 Epoch=74.8] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.381 | L2-Norm(final)=4.952 | 3743.5 samples/s | 58.5 steps/s
[Step=39750 Epoch=74.9] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.369 | L2-Norm(final)=4.952 | 3745.0 samples/s | 58.5 steps/s
[Step=39800 Epoch=75.0] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.357 | L2-Norm(final)=4.953 | 3711.8 samples/s | 58.0 steps/s
[Step=39850 Epoch=75.1] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.345 | L2-Norm(final)=4.954 | 3767.6 samples/s | 58.9 steps/s
[Step=39900 Epoch=75.2] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.333 | L2-Norm(final)=4.955 | 3747.0 samples/s | 58.5 steps/s
[Step=39950 Epoch=75.3] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.321 | L2-Norm(final)=4.956 | 3697.0 samples/s | 57.8 steps/s
[Step=40000 Epoch=75.4] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.308 | L2-Norm(final)=4.957 | 3712.5 samples/s | 58.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step40000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05760 | acc=0.9698 | tpr=0.9776 | fpr=0.0473 | 3574.8 samples/s | 14.0 steps/s
Avg test loss: 0.05689, Avg test acc: 0.96983, Avg tpr: 0.97721, Avg fpr: 0.04640, total FA: 362

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.78018 | acc=0.3027 | tpr=0.0212 | fpr=0.0860 | 3610.4 samples/s | 14.1 steps/s
Avg test loss: 5.77406, Avg test acc: 0.30135, Avg tpr: 0.02314, Avg fpr: 0.08678, total FA: 677

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.72821 | acc=0.1163 | tpr=0.7832 | fpr=0.8957 | 3627.0 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.72750 | acc=0.1170 | tpr=0.7740 | fpr=0.8953 | 6754.5 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.72825 | acc=0.1166 | tpr=0.7738 | fpr=0.8955 | 6816.9 samples/s | 26.6 steps/s
[Step= 200] | Loss=5.71128 | acc=0.1170 | tpr=0.7672 | fpr=0.8948 | 6928.8 samples/s | 27.1 steps/s
[Step= 250] | Loss=5.71424 | acc=0.1174 | tpr=0.7703 | fpr=0.8945 | 6881.2 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.71158 | acc=0.1179 | tpr=0.7695 | fpr=0.8940 | 6802.4 samples/s | 26.6 steps/s
[Step= 350] | Loss=5.70795 | acc=0.1176 | tpr=0.7733 | fpr=0.8943 | 7109.8 samples/s | 27.8 steps/s
[Step= 400] | Loss=5.71336 | acc=0.1175 | tpr=0.7675 | fpr=0.8943 | 6614.1 samples/s | 25.8 steps/s
[Step= 450] | Loss=5.71369 | acc=0.1177 | tpr=0.7658 | fpr=0.8940 | 6814.2 samples/s | 26.6 steps/s
[Step= 500] | Loss=5.71480 | acc=0.1177 | tpr=0.7678 | fpr=0.8940 | 6899.4 samples/s | 27.0 steps/s
[Step= 550] | Loss=5.71482 | acc=0.1180 | tpr=0.7712 | fpr=0.8939 | 12519.4 samples/s | 48.9 steps/s
Avg test loss: 5.71568, Avg test acc: 0.11793, Avg tpr: 0.77139, Avg fpr: 0.89395, total FA: 124123

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12110 | acc=0.9812 | tpr=0.9558 | fpr=0.0183 | 3615.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.12800 | acc=0.9809 | tpr=0.9638 | fpr=0.0187 | 6873.5 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.13029 | acc=0.9803 | tpr=0.9640 | fpr=0.0194 | 6821.8 samples/s | 26.6 steps/s
[Step= 200] | Loss=0.13224 | acc=0.9803 | tpr=0.9672 | fpr=0.0195 | 6989.4 samples/s | 27.3 steps/s
[Step= 250] | Loss=0.13031 | acc=0.9804 | tpr=0.9651 | fpr=0.0193 | 6780.7 samples/s | 26.5 steps/s
[Step= 300] | Loss=0.13259 | acc=0.9800 | tpr=0.9629 | fpr=0.0197 | 6994.7 samples/s | 27.3 steps/s
[Step= 350] | Loss=0.13297 | acc=0.9798 | tpr=0.9643 | fpr=0.0200 | 6731.2 samples/s | 26.3 steps/s
[Step= 400] | Loss=0.13389 | acc=0.9796 | tpr=0.9639 | fpr=0.0201 | 6798.5 samples/s | 26.6 steps/s
[Step= 450] | Loss=0.13744 | acc=0.9792 | tpr=0.9606 | fpr=0.0205 | 7037.3 samples/s | 27.5 steps/s
[Step= 500] | Loss=0.13707 | acc=0.9791 | tpr=0.9608 | fpr=0.0205 | 6649.0 samples/s | 26.0 steps/s
[Step= 550] | Loss=0.13635 | acc=0.9793 | tpr=0.9606 | fpr=0.0203 | 12811.8 samples/s | 50.0 steps/s
Avg test loss: 0.13597, Avg test acc: 0.97934, Avg tpr: 0.96078, Avg fpr: 0.02032, total FA: 2822

server round 20/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=39.1] | Loss=0.01243 | Reg=0.00212 | acc=0.9844 | L2-Norm=14.577 | L2-Norm(final)=6.983 | 3308.8 samples/s | 51.7 steps/s
[Step=40050 Epoch=39.1] | Loss=0.01164 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.591 | L2-Norm(final)=6.988 | 4032.3 samples/s | 63.0 steps/s
[Step=40100 Epoch=39.2] | Loss=0.01157 | Reg=0.00213 | acc=1.0000 | L2-Norm=14.601 | L2-Norm(final)=6.993 | 4476.2 samples/s | 69.9 steps/s
[Step=40150 Epoch=39.2] | Loss=0.01125 | Reg=0.00213 | acc=0.9688 | L2-Norm=14.606 | L2-Norm(final)=6.999 | 4278.8 samples/s | 66.9 steps/s
[Step=40200 Epoch=39.2] | Loss=0.01072 | Reg=0.00213 | acc=0.9844 | L2-Norm=14.610 | L2-Norm(final)=7.004 | 4409.3 samples/s | 68.9 steps/s
[Step=40250 Epoch=39.3] | Loss=0.01040 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.613 | L2-Norm(final)=7.010 | 4279.7 samples/s | 66.9 steps/s
[Step=40300 Epoch=39.3] | Loss=0.01038 | Reg=0.00214 | acc=0.9844 | L2-Norm=14.616 | L2-Norm(final)=7.014 | 4384.7 samples/s | 68.5 steps/s
[Step=40350 Epoch=39.4] | Loss=0.01002 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.618 | L2-Norm(final)=7.019 | 4326.6 samples/s | 67.6 steps/s
[Step=40400 Epoch=39.4] | Loss=0.00971 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.621 | L2-Norm(final)=7.022 | 4356.8 samples/s | 68.1 steps/s
[Step=40450 Epoch=39.5] | Loss=0.00984 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.623 | L2-Norm(final)=7.026 | 4402.7 samples/s | 68.8 steps/s
[Step=40500 Epoch=39.5] | Loss=0.00993 | Reg=0.00214 | acc=1.0000 | L2-Norm=14.625 | L2-Norm(final)=7.030 | 4376.0 samples/s | 68.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=39.5] | Loss=0.00140 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=7.061 | 3261.3 samples/s | 51.0 steps/s
[Step=40550 Epoch=39.6] | Loss=0.00907 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.648 | L2-Norm(final)=7.065 | 3720.9 samples/s | 58.1 steps/s
[Step=40600 Epoch=39.6] | Loss=0.00944 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.650 | L2-Norm(final)=7.068 | 3942.2 samples/s | 61.6 steps/s
[Step=40650 Epoch=39.7] | Loss=0.00985 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.654 | L2-Norm(final)=7.071 | 3918.9 samples/s | 61.2 steps/s
[Step=40700 Epoch=39.7] | Loss=0.01026 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.656 | L2-Norm(final)=7.072 | 3956.0 samples/s | 61.8 steps/s
[Step=40750 Epoch=39.8] | Loss=0.01055 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.659 | L2-Norm(final)=7.074 | 3918.1 samples/s | 61.2 steps/s
[Step=40800 Epoch=39.8] | Loss=0.01060 | Reg=0.00215 | acc=0.9688 | L2-Norm=14.662 | L2-Norm(final)=7.075 | 3974.3 samples/s | 62.1 steps/s
[Step=40850 Epoch=39.9] | Loss=0.01036 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.665 | L2-Norm(final)=7.075 | 3943.0 samples/s | 61.6 steps/s
[Step=40900 Epoch=39.9] | Loss=0.01042 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.667 | L2-Norm(final)=7.076 | 3951.2 samples/s | 61.7 steps/s
[Step=40950 Epoch=40.0] | Loss=0.01041 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.670 | L2-Norm(final)=7.077 | 3890.4 samples/s | 60.8 steps/s
[Step=41000 Epoch=40.0] | Loss=0.01029 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.672 | L2-Norm(final)=7.078 | 3954.0 samples/s | 61.8 steps/s
[Step=41050 Epoch=40.1] | Loss=0.01028 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.674 | L2-Norm(final)=7.079 | 3972.2 samples/s | 62.1 steps/s
[Step=41100 Epoch=40.1] | Loss=0.01039 | Reg=0.00215 | acc=0.9844 | L2-Norm=14.676 | L2-Norm(final)=7.080 | 3917.6 samples/s | 61.2 steps/s
[Step=41150 Epoch=40.2] | Loss=0.01056 | Reg=0.00215 | acc=1.0000 | L2-Norm=14.678 | L2-Norm(final)=7.081 | 3915.5 samples/s | 61.2 steps/s
[Step=41200 Epoch=40.2] | Loss=0.01043 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.681 | L2-Norm(final)=7.082 | 3963.9 samples/s | 61.9 steps/s
[Step=41250 Epoch=40.3] | Loss=0.01040 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.683 | L2-Norm(final)=7.083 | 3868.2 samples/s | 60.4 steps/s
[Step=41300 Epoch=40.3] | Loss=0.01050 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.685 | L2-Norm(final)=7.085 | 3948.4 samples/s | 61.7 steps/s
[Step=41350 Epoch=40.4] | Loss=0.01049 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.687 | L2-Norm(final)=7.086 | 3915.2 samples/s | 61.2 steps/s
[Step=41400 Epoch=40.4] | Loss=0.01049 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.689 | L2-Norm(final)=7.087 | 3854.6 samples/s | 60.2 steps/s
[Step=41450 Epoch=40.5] | Loss=0.01056 | Reg=0.00216 | acc=0.9375 | L2-Norm=14.691 | L2-Norm(final)=7.088 | 3941.5 samples/s | 61.6 steps/s
[Step=41500 Epoch=40.5] | Loss=0.01066 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.692 | L2-Norm(final)=7.089 | 4168.4 samples/s | 65.1 steps/s
[Step=41550 Epoch=40.6] | Loss=0.01073 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.694 | L2-Norm(final)=7.090 | 1636.8 samples/s | 25.6 steps/s
[Step=41600 Epoch=40.6] | Loss=0.01065 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.696 | L2-Norm(final)=7.091 | 3909.9 samples/s | 61.1 steps/s
[Step=41650 Epoch=40.7] | Loss=0.01047 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.698 | L2-Norm(final)=7.092 | 3893.0 samples/s | 60.8 steps/s
[Step=41700 Epoch=40.7] | Loss=0.01032 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.700 | L2-Norm(final)=7.094 | 3906.2 samples/s | 61.0 steps/s
[Step=41750 Epoch=40.8] | Loss=0.01019 | Reg=0.00216 | acc=0.9844 | L2-Norm=14.702 | L2-Norm(final)=7.095 | 3928.6 samples/s | 61.4 steps/s
[Step=41800 Epoch=40.8] | Loss=0.01006 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.703 | L2-Norm(final)=7.097 | 3914.1 samples/s | 61.2 steps/s
[Step=41850 Epoch=40.9] | Loss=0.01008 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.705 | L2-Norm(final)=7.098 | 3961.0 samples/s | 61.9 steps/s
[Step=41900 Epoch=40.9] | Loss=0.01015 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.707 | L2-Norm(final)=7.099 | 4008.5 samples/s | 62.6 steps/s
[Step=41950 Epoch=41.0] | Loss=0.01014 | Reg=0.00216 | acc=0.9688 | L2-Norm=14.708 | L2-Norm(final)=7.100 | 3910.9 samples/s | 61.1 steps/s
[Step=42000 Epoch=41.0] | Loss=0.01014 | Reg=0.00216 | acc=1.0000 | L2-Norm=14.710 | L2-Norm(final)=7.101 | 3916.2 samples/s | 61.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step42000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=40001 Epoch=75.4] | Loss=0.00003 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.577 | L2-Norm(final)=4.984 | 3275.9 samples/s | 51.2 steps/s
[Step=40050 Epoch=75.5] | Loss=0.00090 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=4.988 | 3835.0 samples/s | 59.9 steps/s
[Step=40100 Epoch=75.6] | Loss=0.00054 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.577 | L2-Norm(final)=4.993 | 4056.1 samples/s | 63.4 steps/s
[Step=40150 Epoch=75.7] | Loss=0.00042 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.576 | L2-Norm(final)=4.998 | 4068.1 samples/s | 63.6 steps/s
[Step=40200 Epoch=75.8] | Loss=0.00034 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.573 | L2-Norm(final)=5.002 | 4065.4 samples/s | 63.5 steps/s
[Step=40250 Epoch=75.9] | Loss=0.00029 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.571 | L2-Norm(final)=5.005 | 4121.9 samples/s | 64.4 steps/s
[Step=40300 Epoch=76.0] | Loss=0.00025 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.567 | L2-Norm(final)=5.009 | 4129.1 samples/s | 64.5 steps/s
[Step=40350 Epoch=76.1] | Loss=0.00023 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.564 | L2-Norm(final)=5.012 | 4082.8 samples/s | 63.8 steps/s
[Step=40400 Epoch=76.2] | Loss=0.00022 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.561 | L2-Norm(final)=5.015 | 4163.2 samples/s | 65.1 steps/s
[Step=40450 Epoch=76.2] | Loss=0.00020 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.558 | L2-Norm(final)=5.019 | 4096.4 samples/s | 64.0 steps/s
[Step=40500 Epoch=76.3] | Loss=0.00019 | Reg=0.00212 | acc=1.0000 | L2-Norm=14.555 | L2-Norm(final)=5.022 | 4117.2 samples/s | 64.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=40501 Epoch=76.3] | Loss=0.00008 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.522 | L2-Norm(final)=5.055 | 3247.5 samples/s | 50.7 steps/s
[Step=40550 Epoch=76.4] | Loss=0.00004 | Reg=0.00211 | acc=1.0000 | L2-Norm=14.516 | L2-Norm(final)=5.057 | 3525.4 samples/s | 55.1 steps/s
[Step=40600 Epoch=76.5] | Loss=0.00003 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.506 | L2-Norm(final)=5.059 | 3676.2 samples/s | 57.4 steps/s
[Step=40650 Epoch=76.6] | Loss=0.00004 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.496 | L2-Norm(final)=5.061 | 3754.9 samples/s | 58.7 steps/s
[Step=40700 Epoch=76.7] | Loss=0.00003 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.486 | L2-Norm(final)=5.062 | 3690.3 samples/s | 57.7 steps/s
[Step=40750 Epoch=76.8] | Loss=0.00003 | Reg=0.00210 | acc=1.0000 | L2-Norm=14.476 | L2-Norm(final)=5.063 | 3756.3 samples/s | 58.7 steps/s
[Step=40800 Epoch=76.9] | Loss=0.00003 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.465 | L2-Norm(final)=5.064 | 3688.5 samples/s | 57.6 steps/s
[Step=40850 Epoch=77.0] | Loss=0.00002 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.455 | L2-Norm(final)=5.065 | 3710.8 samples/s | 58.0 steps/s
[Step=40900 Epoch=77.1] | Loss=0.00002 | Reg=0.00209 | acc=1.0000 | L2-Norm=14.444 | L2-Norm(final)=5.066 | 3725.9 samples/s | 58.2 steps/s
[Step=40950 Epoch=77.2] | Loss=0.00002 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.433 | L2-Norm(final)=5.067 | 3689.2 samples/s | 57.6 steps/s
[Step=41000 Epoch=77.3] | Loss=0.00002 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.422 | L2-Norm(final)=5.068 | 3784.6 samples/s | 59.1 steps/s
[Step=41050 Epoch=77.4] | Loss=0.00002 | Reg=0.00208 | acc=1.0000 | L2-Norm=14.411 | L2-Norm(final)=5.069 | 1674.9 samples/s | 26.2 steps/s
[Step=41100 Epoch=77.5] | Loss=0.00002 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.400 | L2-Norm(final)=5.070 | 3775.9 samples/s | 59.0 steps/s
[Step=41150 Epoch=77.6] | Loss=0.00002 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.389 | L2-Norm(final)=5.070 | 3700.7 samples/s | 57.8 steps/s
[Step=41200 Epoch=77.7] | Loss=0.00001 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.378 | L2-Norm(final)=5.071 | 3730.9 samples/s | 58.3 steps/s
[Step=41250 Epoch=77.8] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.366 | L2-Norm(final)=5.072 | 3726.8 samples/s | 58.2 steps/s
[Step=41300 Epoch=77.9] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.355 | L2-Norm(final)=5.072 | 3736.5 samples/s | 58.4 steps/s
[Step=41350 Epoch=77.9] | Loss=0.00001 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.343 | L2-Norm(final)=5.073 | 3762.7 samples/s | 58.8 steps/s
[Step=41400 Epoch=78.0] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.331 | L2-Norm(final)=5.073 | 3682.6 samples/s | 57.5 steps/s
[Step=41450 Epoch=78.1] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.319 | L2-Norm(final)=5.074 | 3827.5 samples/s | 59.8 steps/s
[Step=41500 Epoch=78.2] | Loss=0.00001 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.307 | L2-Norm(final)=5.074 | 3760.8 samples/s | 58.8 steps/s
[Step=41550 Epoch=78.3] | Loss=0.00001 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.295 | L2-Norm(final)=5.075 | 4734.2 samples/s | 74.0 steps/s
[Step=41600 Epoch=78.4] | Loss=0.00001 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.283 | L2-Norm(final)=5.076 | 1537.9 samples/s | 24.0 steps/s
[Step=41650 Epoch=78.5] | Loss=0.00001 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.270 | L2-Norm(final)=5.076 | 3740.1 samples/s | 58.4 steps/s
[Step=41700 Epoch=78.6] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.258 | L2-Norm(final)=5.077 | 3763.2 samples/s | 58.8 steps/s
[Step=41750 Epoch=78.7] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.245 | L2-Norm(final)=5.077 | 3740.4 samples/s | 58.4 steps/s
[Step=41800 Epoch=78.8] | Loss=0.00001 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.232 | L2-Norm(final)=5.078 | 3794.0 samples/s | 59.3 steps/s
[Step=41850 Epoch=78.9] | Loss=0.00001 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.219 | L2-Norm(final)=5.079 | 3746.1 samples/s | 58.5 steps/s
[Step=41900 Epoch=79.0] | Loss=0.00001 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.206 | L2-Norm(final)=5.079 | 3765.9 samples/s | 58.8 steps/s
[Step=41950 Epoch=79.1] | Loss=0.00001 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.193 | L2-Norm(final)=5.080 | 3823.9 samples/s | 59.7 steps/s
[Step=42000 Epoch=79.2] | Loss=0.00001 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.180 | L2-Norm(final)=5.080 | 3919.3 samples/s | 61.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step42000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05676 | acc=0.9727 | tpr=0.9775 | fpr=0.0379 | 3956.3 samples/s | 15.5 steps/s
Avg test loss: 0.05784, Avg test acc: 0.97135, Avg tpr: 0.97604, Avg fpr: 0.03897, total FA: 304

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.33869 | acc=0.3027 | tpr=0.0240 | fpr=0.0919 | 3985.4 samples/s | 15.6 steps/s
Avg test loss: 6.33149, Avg test acc: 0.30231, Avg tpr: 0.02553, Avg fpr: 0.08896, total FA: 694

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.47289 | acc=0.1401 | tpr=0.7522 | fpr=0.8709 | 4109.1 samples/s | 16.1 steps/s
[Step= 100] | Loss=5.46885 | acc=0.1415 | tpr=0.7612 | fpr=0.8701 | 8230.3 samples/s | 32.1 steps/s
[Step= 150] | Loss=5.46428 | acc=0.1398 | tpr=0.7522 | fpr=0.8715 | 8042.5 samples/s | 31.4 steps/s
[Step= 200] | Loss=5.44475 | acc=0.1406 | tpr=0.7399 | fpr=0.8703 | 8259.0 samples/s | 32.3 steps/s
[Step= 250] | Loss=5.44731 | acc=0.1408 | tpr=0.7354 | fpr=0.8700 | 7904.5 samples/s | 30.9 steps/s
[Step= 300] | Loss=5.44503 | acc=0.1410 | tpr=0.7295 | fpr=0.8698 | 6729.6 samples/s | 26.3 steps/s
[Step= 350] | Loss=5.44235 | acc=0.1408 | tpr=0.7326 | fpr=0.8699 | 6865.6 samples/s | 26.8 steps/s
[Step= 400] | Loss=5.44870 | acc=0.1404 | tpr=0.7270 | fpr=0.8703 | 6969.1 samples/s | 27.2 steps/s
[Step= 450] | Loss=5.44857 | acc=0.1405 | tpr=0.7274 | fpr=0.8701 | 6713.8 samples/s | 26.2 steps/s
[Step= 500] | Loss=5.45042 | acc=0.1406 | tpr=0.7291 | fpr=0.8700 | 4831.4 samples/s | 18.9 steps/s
[Step= 550] | Loss=5.45141 | acc=0.1408 | tpr=0.7362 | fpr=0.8700 | 8619.2 samples/s | 33.7 steps/s
Avg test loss: 5.45227, Avg test acc: 0.14072, Avg tpr: 0.73613, Avg fpr: 0.87010, total FA: 120812

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12776 | acc=0.9809 | tpr=0.9513 | fpr=0.0185 | 3612.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.13582 | acc=0.9802 | tpr=0.9595 | fpr=0.0195 | 6818.4 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.13744 | acc=0.9798 | tpr=0.9611 | fpr=0.0198 | 6775.4 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.13981 | acc=0.9799 | tpr=0.9661 | fpr=0.0198 | 7094.4 samples/s | 27.7 steps/s
[Step= 250] | Loss=0.13784 | acc=0.9801 | tpr=0.9659 | fpr=0.0196 | 6686.1 samples/s | 26.1 steps/s
[Step= 300] | Loss=0.14015 | acc=0.9798 | tpr=0.9629 | fpr=0.0199 | 6349.0 samples/s | 24.8 steps/s
[Step= 350] | Loss=0.14011 | acc=0.9796 | tpr=0.9643 | fpr=0.0201 | 6627.6 samples/s | 25.9 steps/s
[Step= 400] | Loss=0.14090 | acc=0.9795 | tpr=0.9633 | fpr=0.0203 | 6775.5 samples/s | 26.5 steps/s
[Step= 450] | Loss=0.14422 | acc=0.9791 | tpr=0.9591 | fpr=0.0206 | 6728.2 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.14381 | acc=0.9791 | tpr=0.9599 | fpr=0.0206 | 4428.2 samples/s | 17.3 steps/s
[Step= 550] | Loss=0.14303 | acc=0.9792 | tpr=0.9598 | fpr=0.0204 | 12835.1 samples/s | 50.1 steps/s
Avg test loss: 0.14263, Avg test acc: 0.97925, Avg tpr: 0.95998, Avg fpr: 0.02040, total FA: 2832

server round 21/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=41.0] | Loss=0.00488 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.207 | L2-Norm(final)=7.125 | 3403.2 samples/s | 53.2 steps/s
[Step=42050 Epoch=41.1] | Loss=0.00813 | Reg=0.00202 | acc=0.9688 | L2-Norm=14.215 | L2-Norm(final)=7.130 | 4067.6 samples/s | 63.6 steps/s
[Step=42100 Epoch=41.1] | Loss=0.00893 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.220 | L2-Norm(final)=7.133 | 4307.8 samples/s | 67.3 steps/s
[Step=42150 Epoch=41.2] | Loss=0.00919 | Reg=0.00202 | acc=0.9844 | L2-Norm=14.223 | L2-Norm(final)=7.138 | 4359.0 samples/s | 68.1 steps/s
[Step=42200 Epoch=41.2] | Loss=0.00897 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.227 | L2-Norm(final)=7.142 | 4407.6 samples/s | 68.9 steps/s
[Step=42250 Epoch=41.3] | Loss=0.00904 | Reg=0.00203 | acc=0.9375 | L2-Norm=14.230 | L2-Norm(final)=7.146 | 4386.4 samples/s | 68.5 steps/s
[Step=42300 Epoch=41.3] | Loss=0.00875 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.234 | L2-Norm(final)=7.150 | 4239.4 samples/s | 66.2 steps/s
[Step=42350 Epoch=41.3] | Loss=0.00881 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.237 | L2-Norm(final)=7.153 | 4373.1 samples/s | 68.3 steps/s
[Step=42400 Epoch=41.4] | Loss=0.00898 | Reg=0.00203 | acc=1.0000 | L2-Norm=14.240 | L2-Norm(final)=7.156 | 4469.9 samples/s | 69.8 steps/s
[Step=42450 Epoch=41.4] | Loss=0.00890 | Reg=0.00203 | acc=0.9844 | L2-Norm=14.242 | L2-Norm(final)=7.159 | 4292.1 samples/s | 67.1 steps/s
[Step=42500 Epoch=41.5] | Loss=0.00872 | Reg=0.00203 | acc=0.9844 | L2-Norm=14.245 | L2-Norm(final)=7.162 | 4322.5 samples/s | 67.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=41.5] | Loss=0.00079 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.270 | L2-Norm(final)=7.192 | 3365.4 samples/s | 52.6 steps/s
[Step=42550 Epoch=41.5] | Loss=0.00858 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.274 | L2-Norm(final)=7.195 | 3625.9 samples/s | 56.7 steps/s
[Step=42600 Epoch=41.6] | Loss=0.00843 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.279 | L2-Norm(final)=7.198 | 3891.2 samples/s | 60.8 steps/s
[Step=42650 Epoch=41.6] | Loss=0.00932 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.285 | L2-Norm(final)=7.199 | 3871.2 samples/s | 60.5 steps/s
[Step=42700 Epoch=41.7] | Loss=0.00985 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.290 | L2-Norm(final)=7.200 | 3988.5 samples/s | 62.3 steps/s
[Step=42750 Epoch=41.7] | Loss=0.01055 | Reg=0.00204 | acc=0.9844 | L2-Norm=14.295 | L2-Norm(final)=7.202 | 3899.2 samples/s | 60.9 steps/s
[Step=42800 Epoch=41.8] | Loss=0.01046 | Reg=0.00204 | acc=1.0000 | L2-Norm=14.299 | L2-Norm(final)=7.204 | 3912.4 samples/s | 61.1 steps/s
[Step=42850 Epoch=41.8] | Loss=0.01060 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.304 | L2-Norm(final)=7.205 | 3912.0 samples/s | 61.1 steps/s
[Step=42900 Epoch=41.9] | Loss=0.01038 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.309 | L2-Norm(final)=7.207 | 3963.5 samples/s | 61.9 steps/s
[Step=42950 Epoch=41.9] | Loss=0.01037 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.313 | L2-Norm(final)=7.209 | 3934.7 samples/s | 61.5 steps/s
[Step=43000 Epoch=42.0] | Loss=0.01028 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.318 | L2-Norm(final)=7.211 | 3955.9 samples/s | 61.8 steps/s
[Step=43050 Epoch=42.0] | Loss=0.01022 | Reg=0.00205 | acc=1.0000 | L2-Norm=14.322 | L2-Norm(final)=7.213 | 3937.5 samples/s | 61.5 steps/s
[Step=43100 Epoch=42.1] | Loss=0.01040 | Reg=0.00205 | acc=0.9688 | L2-Norm=14.326 | L2-Norm(final)=7.215 | 3976.3 samples/s | 62.1 steps/s
[Step=43150 Epoch=42.1] | Loss=0.01044 | Reg=0.00205 | acc=0.9844 | L2-Norm=14.330 | L2-Norm(final)=7.216 | 3960.0 samples/s | 61.9 steps/s
[Step=43200 Epoch=42.2] | Loss=0.01043 | Reg=0.00205 | acc=0.9688 | L2-Norm=14.333 | L2-Norm(final)=7.218 | 3915.5 samples/s | 61.2 steps/s
[Step=43250 Epoch=42.2] | Loss=0.01073 | Reg=0.00206 | acc=0.9219 | L2-Norm=14.337 | L2-Norm(final)=7.219 | 3951.5 samples/s | 61.7 steps/s
[Step=43300 Epoch=42.3] | Loss=0.01072 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.340 | L2-Norm(final)=7.220 | 3965.6 samples/s | 62.0 steps/s
[Step=43350 Epoch=42.3] | Loss=0.01070 | Reg=0.00206 | acc=0.9688 | L2-Norm=14.344 | L2-Norm(final)=7.221 | 3936.3 samples/s | 61.5 steps/s
[Step=43400 Epoch=42.4] | Loss=0.01087 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.347 | L2-Norm(final)=7.222 | 3947.1 samples/s | 61.7 steps/s
[Step=43450 Epoch=42.4] | Loss=0.01090 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.350 | L2-Norm(final)=7.223 | 3928.1 samples/s | 61.4 steps/s
[Step=43500 Epoch=42.5] | Loss=0.01103 | Reg=0.00206 | acc=0.9688 | L2-Norm=14.353 | L2-Norm(final)=7.224 | 4250.2 samples/s | 66.4 steps/s
[Step=43550 Epoch=42.5] | Loss=0.01085 | Reg=0.00206 | acc=0.9844 | L2-Norm=14.356 | L2-Norm(final)=7.226 | 1653.5 samples/s | 25.8 steps/s
[Step=43600 Epoch=42.6] | Loss=0.01070 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.360 | L2-Norm(final)=7.227 | 3901.8 samples/s | 61.0 steps/s
[Step=43650 Epoch=42.6] | Loss=0.01061 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.363 | L2-Norm(final)=7.229 | 3950.4 samples/s | 61.7 steps/s
[Step=43700 Epoch=42.7] | Loss=0.01063 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.366 | L2-Norm(final)=7.231 | 3897.1 samples/s | 60.9 steps/s
[Step=43750 Epoch=42.7] | Loss=0.01057 | Reg=0.00206 | acc=1.0000 | L2-Norm=14.369 | L2-Norm(final)=7.232 | 3926.6 samples/s | 61.4 steps/s
[Step=43800 Epoch=42.8] | Loss=0.01048 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.372 | L2-Norm(final)=7.234 | 3979.7 samples/s | 62.2 steps/s
[Step=43850 Epoch=42.8] | Loss=0.01038 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.375 | L2-Norm(final)=7.236 | 3981.3 samples/s | 62.2 steps/s
[Step=43900 Epoch=42.9] | Loss=0.01034 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.378 | L2-Norm(final)=7.238 | 3943.1 samples/s | 61.6 steps/s
[Step=43950 Epoch=42.9] | Loss=0.01029 | Reg=0.00207 | acc=1.0000 | L2-Norm=14.381 | L2-Norm(final)=7.239 | 3960.4 samples/s | 61.9 steps/s
[Step=44000 Epoch=43.0] | Loss=0.01030 | Reg=0.00207 | acc=0.9844 | L2-Norm=14.384 | L2-Norm(final)=7.241 | 3943.1 samples/s | 61.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step44000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=42001 Epoch=79.2] | Loss=0.00003 | Reg=0.00202 | acc=1.0000 | L2-Norm=14.207 | L2-Norm(final)=5.098 | 3072.9 samples/s | 48.0 steps/s
[Step=42050 Epoch=79.3] | Loss=0.00006 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.194 | L2-Norm(final)=5.105 | 4096.5 samples/s | 64.0 steps/s
[Step=42100 Epoch=79.4] | Loss=0.00005 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.185 | L2-Norm(final)=5.108 | 4103.3 samples/s | 64.1 steps/s
[Step=42150 Epoch=79.5] | Loss=0.00004 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.178 | L2-Norm(final)=5.112 | 4144.6 samples/s | 64.8 steps/s
[Step=42200 Epoch=79.5] | Loss=0.00004 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.171 | L2-Norm(final)=5.115 | 4112.3 samples/s | 64.3 steps/s
[Step=42250 Epoch=79.6] | Loss=0.00005 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.165 | L2-Norm(final)=5.119 | 4159.3 samples/s | 65.0 steps/s
[Step=42300 Epoch=79.7] | Loss=0.00005 | Reg=0.00201 | acc=1.0000 | L2-Norm=14.160 | L2-Norm(final)=5.124 | 4062.8 samples/s | 63.5 steps/s
[Step=42350 Epoch=79.8] | Loss=0.00004 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.155 | L2-Norm(final)=5.127 | 4186.7 samples/s | 65.4 steps/s
[Step=42400 Epoch=79.9] | Loss=0.00004 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.150 | L2-Norm(final)=5.131 | 4132.3 samples/s | 64.6 steps/s
[Step=42450 Epoch=80.0] | Loss=0.00004 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.145 | L2-Norm(final)=5.135 | 4017.5 samples/s | 62.8 steps/s
[Step=42500 Epoch=80.1] | Loss=0.00004 | Reg=0.00200 | acc=1.0000 | L2-Norm=14.139 | L2-Norm(final)=5.139 | 4153.3 samples/s | 64.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=42501 Epoch=80.1] | Loss=0.00002 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.083 | L2-Norm(final)=5.175 | 3169.8 samples/s | 49.5 steps/s
[Step=42550 Epoch=80.2] | Loss=0.00001 | Reg=0.00198 | acc=1.0000 | L2-Norm=14.067 | L2-Norm(final)=5.178 | 3656.3 samples/s | 57.1 steps/s
[Step=42600 Epoch=80.3] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.047 | L2-Norm(final)=5.180 | 3753.8 samples/s | 58.7 steps/s
[Step=42650 Epoch=80.4] | Loss=0.00001 | Reg=0.00197 | acc=1.0000 | L2-Norm=14.026 | L2-Norm(final)=5.181 | 3695.1 samples/s | 57.7 steps/s
[Step=42700 Epoch=80.5] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=14.004 | L2-Norm(final)=5.183 | 3734.6 samples/s | 58.4 steps/s
[Step=42750 Epoch=80.6] | Loss=0.00001 | Reg=0.00196 | acc=1.0000 | L2-Norm=13.983 | L2-Norm(final)=5.184 | 3738.8 samples/s | 58.4 steps/s
[Step=42800 Epoch=80.7] | Loss=0.00001 | Reg=0.00195 | acc=1.0000 | L2-Norm=13.961 | L2-Norm(final)=5.185 | 3760.4 samples/s | 58.8 steps/s
[Step=42850 Epoch=80.8] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.939 | L2-Norm(final)=5.186 | 3697.1 samples/s | 57.8 steps/s
[Step=42900 Epoch=80.9] | Loss=0.00001 | Reg=0.00194 | acc=1.0000 | L2-Norm=13.917 | L2-Norm(final)=5.187 | 3743.7 samples/s | 58.5 steps/s
[Step=42950 Epoch=81.0] | Loss=0.00001 | Reg=0.00193 | acc=1.0000 | L2-Norm=13.895 | L2-Norm(final)=5.188 | 3723.9 samples/s | 58.2 steps/s
[Step=43000 Epoch=81.1] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.873 | L2-Norm(final)=5.189 | 3765.3 samples/s | 58.8 steps/s
[Step=43050 Epoch=81.1] | Loss=0.00001 | Reg=0.00192 | acc=1.0000 | L2-Norm=13.852 | L2-Norm(final)=5.191 | 1639.8 samples/s | 25.6 steps/s
[Step=43100 Epoch=81.2] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.830 | L2-Norm(final)=5.192 | 3678.3 samples/s | 57.5 steps/s
[Step=43150 Epoch=81.3] | Loss=0.00001 | Reg=0.00191 | acc=1.0000 | L2-Norm=13.807 | L2-Norm(final)=5.193 | 3722.2 samples/s | 58.2 steps/s
[Step=43200 Epoch=81.4] | Loss=0.00001 | Reg=0.00190 | acc=1.0000 | L2-Norm=13.785 | L2-Norm(final)=5.194 | 3702.5 samples/s | 57.9 steps/s
[Step=43250 Epoch=81.5] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.762 | L2-Norm(final)=5.195 | 3665.3 samples/s | 57.3 steps/s
[Step=43300 Epoch=81.6] | Loss=0.00001 | Reg=0.00189 | acc=1.0000 | L2-Norm=13.739 | L2-Norm(final)=5.196 | 3748.3 samples/s | 58.6 steps/s
[Step=43350 Epoch=81.7] | Loss=0.00000 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.716 | L2-Norm(final)=5.197 | 3746.8 samples/s | 58.5 steps/s
[Step=43400 Epoch=81.8] | Loss=0.00000 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.692 | L2-Norm(final)=5.197 | 3728.2 samples/s | 58.3 steps/s
[Step=43450 Epoch=81.9] | Loss=0.00000 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.669 | L2-Norm(final)=5.198 | 3700.4 samples/s | 57.8 steps/s
[Step=43500 Epoch=82.0] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.645 | L2-Norm(final)=5.199 | 3738.5 samples/s | 58.4 steps/s
[Step=43550 Epoch=82.1] | Loss=0.00000 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.621 | L2-Norm(final)=5.200 | 4704.5 samples/s | 73.5 steps/s
[Step=43600 Epoch=82.2] | Loss=0.00000 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.597 | L2-Norm(final)=5.201 | 1518.2 samples/s | 23.7 steps/s
[Step=43650 Epoch=82.3] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.572 | L2-Norm(final)=5.202 | 3749.1 samples/s | 58.6 steps/s
[Step=43700 Epoch=82.4] | Loss=0.00000 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.548 | L2-Norm(final)=5.203 | 3695.7 samples/s | 57.7 steps/s
[Step=43750 Epoch=82.5] | Loss=0.00000 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.523 | L2-Norm(final)=5.204 | 3740.6 samples/s | 58.4 steps/s
[Step=43800 Epoch=82.6] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.498 | L2-Norm(final)=5.204 | 3667.7 samples/s | 57.3 steps/s
[Step=43850 Epoch=82.7] | Loss=0.00000 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.473 | L2-Norm(final)=5.205 | 3696.0 samples/s | 57.8 steps/s
[Step=43900 Epoch=82.8] | Loss=0.00000 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.448 | L2-Norm(final)=5.206 | 3722.7 samples/s | 58.2 steps/s
[Step=43950 Epoch=82.8] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.423 | L2-Norm(final)=5.207 | 3725.6 samples/s | 58.2 steps/s
[Step=44000 Epoch=82.9] | Loss=0.00000 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.397 | L2-Norm(final)=5.208 | 3700.3 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step44000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05866 | acc=0.9728 | tpr=0.9803 | fpr=0.0434 | 3649.4 samples/s | 14.3 steps/s
Avg test loss: 0.05918, Avg test acc: 0.97203, Avg tpr: 0.97937, Avg fpr: 0.04410, total FA: 344

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=6.03333 | acc=0.3018 | tpr=0.0226 | fpr=0.0919 | 3618.5 samples/s | 14.1 steps/s
Avg test loss: 6.02518, Avg test acc: 0.30119, Avg tpr: 0.02326, Avg fpr: 0.08755, total FA: 683

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.67612 | acc=0.1297 | tpr=0.7655 | fpr=0.8817 | 3569.0 samples/s | 13.9 steps/s
[Step= 100] | Loss=5.67476 | acc=0.1295 | tpr=0.7633 | fpr=0.8823 | 6972.4 samples/s | 27.2 steps/s
[Step= 150] | Loss=5.67224 | acc=0.1272 | tpr=0.7608 | fpr=0.8844 | 5969.7 samples/s | 23.3 steps/s
[Step= 200] | Loss=5.65305 | acc=0.1272 | tpr=0.7497 | fpr=0.8841 | 6856.6 samples/s | 26.8 steps/s
[Step= 250] | Loss=5.65666 | acc=0.1276 | tpr=0.7467 | fpr=0.8837 | 6883.0 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.65507 | acc=0.1281 | tpr=0.7455 | fpr=0.8832 | 6840.8 samples/s | 26.7 steps/s
[Step= 350] | Loss=5.65253 | acc=0.1278 | tpr=0.7439 | fpr=0.8834 | 4482.7 samples/s | 17.5 steps/s
[Step= 400] | Loss=5.65844 | acc=0.1274 | tpr=0.7374 | fpr=0.8837 | 6807.2 samples/s | 26.6 steps/s
[Step= 450] | Loss=5.65802 | acc=0.1276 | tpr=0.7386 | fpr=0.8835 | 7097.5 samples/s | 27.7 steps/s
[Step= 500] | Loss=5.65936 | acc=0.1279 | tpr=0.7396 | fpr=0.8832 | 6458.9 samples/s | 25.2 steps/s
[Step= 550] | Loss=5.66000 | acc=0.1282 | tpr=0.7461 | fpr=0.8830 | 12346.5 samples/s | 48.2 steps/s
Avg test loss: 5.66101, Avg test acc: 0.12820, Avg tpr: 0.74643, Avg fpr: 0.88304, total FA: 122608

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.12156 | acc=0.9808 | tpr=0.9425 | fpr=0.0185 | 3613.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.12871 | acc=0.9803 | tpr=0.9510 | fpr=0.0191 | 6836.9 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.12967 | acc=0.9799 | tpr=0.9539 | fpr=0.0196 | 5320.4 samples/s | 20.8 steps/s
[Step= 200] | Loss=0.13169 | acc=0.9800 | tpr=0.9596 | fpr=0.0196 | 6925.2 samples/s | 27.1 steps/s
[Step= 250] | Loss=0.12988 | acc=0.9802 | tpr=0.9598 | fpr=0.0194 | 6708.0 samples/s | 26.2 steps/s
[Step= 300] | Loss=0.13226 | acc=0.9799 | tpr=0.9578 | fpr=0.0197 | 6417.5 samples/s | 25.1 steps/s
[Step= 350] | Loss=0.13214 | acc=0.9798 | tpr=0.9599 | fpr=0.0199 | 5341.1 samples/s | 20.9 steps/s
[Step= 400] | Loss=0.13274 | acc=0.9796 | tpr=0.9595 | fpr=0.0201 | 6741.1 samples/s | 26.3 steps/s
[Step= 450] | Loss=0.13587 | acc=0.9792 | tpr=0.9567 | fpr=0.0204 | 6672.4 samples/s | 26.1 steps/s
[Step= 500] | Loss=0.13537 | acc=0.9792 | tpr=0.9577 | fpr=0.0204 | 6932.0 samples/s | 27.1 steps/s
[Step= 550] | Loss=0.13451 | acc=0.9794 | tpr=0.9582 | fpr=0.0202 | 12328.4 samples/s | 48.2 steps/s
Avg test loss: 0.13415, Avg test acc: 0.97944, Avg tpr: 0.95840, Avg fpr: 0.02018, total FA: 2802

server round 22/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=43.0] | Loss=0.00999 | Reg=0.00181 | acc=0.9844 | L2-Norm=13.464 | L2-Norm(final)=7.286 | 3459.3 samples/s | 54.1 steps/s
[Step=44050 Epoch=43.0] | Loss=0.00727 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.474 | L2-Norm(final)=7.290 | 3969.3 samples/s | 62.0 steps/s
[Step=44100 Epoch=43.1] | Loss=0.01012 | Reg=0.00182 | acc=0.9844 | L2-Norm=13.480 | L2-Norm(final)=7.297 | 4252.0 samples/s | 66.4 steps/s
[Step=44150 Epoch=43.1] | Loss=0.00984 | Reg=0.00182 | acc=0.9531 | L2-Norm=13.485 | L2-Norm(final)=7.302 | 4361.8 samples/s | 68.2 steps/s
[Step=44200 Epoch=43.2] | Loss=0.00925 | Reg=0.00182 | acc=0.9844 | L2-Norm=13.490 | L2-Norm(final)=7.308 | 4441.4 samples/s | 69.4 steps/s
[Step=44250 Epoch=43.2] | Loss=0.00909 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.495 | L2-Norm(final)=7.314 | 4204.2 samples/s | 65.7 steps/s
[Step=44300 Epoch=43.3] | Loss=0.00878 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.500 | L2-Norm(final)=7.320 | 4392.7 samples/s | 68.6 steps/s
[Step=44350 Epoch=43.3] | Loss=0.00875 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.504 | L2-Norm(final)=7.326 | 4414.0 samples/s | 69.0 steps/s
[Step=44400 Epoch=43.3] | Loss=0.00863 | Reg=0.00182 | acc=1.0000 | L2-Norm=13.508 | L2-Norm(final)=7.330 | 4436.0 samples/s | 69.3 steps/s
[Step=44450 Epoch=43.4] | Loss=0.00861 | Reg=0.00183 | acc=0.9844 | L2-Norm=13.512 | L2-Norm(final)=7.334 | 4418.8 samples/s | 69.0 steps/s
[Step=44500 Epoch=43.4] | Loss=0.00866 | Reg=0.00183 | acc=1.0000 | L2-Norm=13.515 | L2-Norm(final)=7.339 | 4380.1 samples/s | 68.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=43.4] | Loss=0.00049 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.550 | L2-Norm(final)=7.381 | 3450.6 samples/s | 53.9 steps/s
[Step=44550 Epoch=43.5] | Loss=0.00894 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.554 | L2-Norm(final)=7.380 | 3701.9 samples/s | 57.8 steps/s
[Step=44600 Epoch=43.5] | Loss=0.00929 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.559 | L2-Norm(final)=7.383 | 3933.5 samples/s | 61.5 steps/s
[Step=44650 Epoch=43.6] | Loss=0.00968 | Reg=0.00184 | acc=0.9688 | L2-Norm=13.565 | L2-Norm(final)=7.385 | 3934.2 samples/s | 61.5 steps/s
[Step=44700 Epoch=43.6] | Loss=0.01074 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.571 | L2-Norm(final)=7.387 | 3942.2 samples/s | 61.6 steps/s
[Step=44750 Epoch=43.7] | Loss=0.01132 | Reg=0.00184 | acc=1.0000 | L2-Norm=13.577 | L2-Norm(final)=7.387 | 3987.9 samples/s | 62.3 steps/s
[Step=44800 Epoch=43.7] | Loss=0.01134 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.583 | L2-Norm(final)=7.388 | 3954.5 samples/s | 61.8 steps/s
[Step=44850 Epoch=43.8] | Loss=0.01132 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.590 | L2-Norm(final)=7.390 | 3953.9 samples/s | 61.8 steps/s
[Step=44900 Epoch=43.8] | Loss=0.01104 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.596 | L2-Norm(final)=7.393 | 3946.1 samples/s | 61.7 steps/s
[Step=44950 Epoch=43.9] | Loss=0.01107 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.602 | L2-Norm(final)=7.395 | 3975.8 samples/s | 62.1 steps/s
[Step=45000 Epoch=43.9] | Loss=0.01090 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.607 | L2-Norm(final)=7.398 | 3959.5 samples/s | 61.9 steps/s
[Step=45050 Epoch=44.0] | Loss=0.01084 | Reg=0.00185 | acc=0.9531 | L2-Norm=13.613 | L2-Norm(final)=7.401 | 3964.2 samples/s | 61.9 steps/s
[Step=45100 Epoch=44.0] | Loss=0.01087 | Reg=0.00185 | acc=1.0000 | L2-Norm=13.618 | L2-Norm(final)=7.404 | 3954.6 samples/s | 61.8 steps/s
[Step=45150 Epoch=44.1] | Loss=0.01122 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.623 | L2-Norm(final)=7.406 | 3952.6 samples/s | 61.8 steps/s
[Step=45200 Epoch=44.1] | Loss=0.01122 | Reg=0.00186 | acc=0.9531 | L2-Norm=13.627 | L2-Norm(final)=7.407 | 3952.9 samples/s | 61.8 steps/s
[Step=45250 Epoch=44.2] | Loss=0.01111 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.632 | L2-Norm(final)=7.409 | 3924.9 samples/s | 61.3 steps/s
[Step=45300 Epoch=44.2] | Loss=0.01121 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.637 | L2-Norm(final)=7.410 | 3982.8 samples/s | 62.2 steps/s
[Step=45350 Epoch=44.3] | Loss=0.01116 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.641 | L2-Norm(final)=7.412 | 3905.4 samples/s | 61.0 steps/s
[Step=45400 Epoch=44.3] | Loss=0.01125 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.646 | L2-Norm(final)=7.414 | 3960.0 samples/s | 61.9 steps/s
[Step=45450 Epoch=44.4] | Loss=0.01138 | Reg=0.00186 | acc=0.9844 | L2-Norm=13.650 | L2-Norm(final)=7.416 | 3935.1 samples/s | 61.5 steps/s
[Step=45500 Epoch=44.4] | Loss=0.01149 | Reg=0.00186 | acc=1.0000 | L2-Norm=13.654 | L2-Norm(final)=7.418 | 4275.6 samples/s | 66.8 steps/s
[Step=45550 Epoch=44.5] | Loss=0.01138 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.659 | L2-Norm(final)=7.420 | 1608.0 samples/s | 25.1 steps/s
[Step=45600 Epoch=44.5] | Loss=0.01121 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.663 | L2-Norm(final)=7.423 | 3967.9 samples/s | 62.0 steps/s
[Step=45650 Epoch=44.6] | Loss=0.01107 | Reg=0.00187 | acc=0.9688 | L2-Norm=13.667 | L2-Norm(final)=7.425 | 3951.3 samples/s | 61.7 steps/s
[Step=45700 Epoch=44.6] | Loss=0.01097 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.671 | L2-Norm(final)=7.428 | 3895.0 samples/s | 60.9 steps/s
[Step=45750 Epoch=44.7] | Loss=0.01087 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.675 | L2-Norm(final)=7.430 | 3927.6 samples/s | 61.4 steps/s
[Step=45800 Epoch=44.7] | Loss=0.01075 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.679 | L2-Norm(final)=7.433 | 3944.4 samples/s | 61.6 steps/s
[Step=45850 Epoch=44.8] | Loss=0.01067 | Reg=0.00187 | acc=1.0000 | L2-Norm=13.683 | L2-Norm(final)=7.435 | 3928.2 samples/s | 61.4 steps/s
[Step=45900 Epoch=44.8] | Loss=0.01067 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.687 | L2-Norm(final)=7.437 | 3965.3 samples/s | 62.0 steps/s
[Step=45950 Epoch=44.9] | Loss=0.01083 | Reg=0.00187 | acc=0.9844 | L2-Norm=13.691 | L2-Norm(final)=7.439 | 3923.9 samples/s | 61.3 steps/s
[Step=46000 Epoch=44.9] | Loss=0.01075 | Reg=0.00188 | acc=1.0000 | L2-Norm=13.695 | L2-Norm(final)=7.441 | 3951.4 samples/s | 61.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step46000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=44001 Epoch=82.9] | Loss=0.00002 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.464 | L2-Norm(final)=5.236 | 3340.7 samples/s | 52.2 steps/s
[Step=44050 Epoch=83.0] | Loss=0.00003 | Reg=0.00181 | acc=1.0000 | L2-Norm=13.444 | L2-Norm(final)=5.242 | 3758.9 samples/s | 58.7 steps/s
[Step=44100 Epoch=83.1] | Loss=0.00003 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.434 | L2-Norm(final)=5.249 | 4052.4 samples/s | 63.3 steps/s
[Step=44150 Epoch=83.2] | Loss=0.00003 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.424 | L2-Norm(final)=5.256 | 4182.6 samples/s | 65.4 steps/s
[Step=44200 Epoch=83.3] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.415 | L2-Norm(final)=5.263 | 3964.7 samples/s | 61.9 steps/s
[Step=44250 Epoch=83.4] | Loss=0.00002 | Reg=0.00180 | acc=1.0000 | L2-Norm=13.405 | L2-Norm(final)=5.269 | 4225.1 samples/s | 66.0 steps/s
[Step=44300 Epoch=83.5] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.396 | L2-Norm(final)=5.275 | 4033.0 samples/s | 63.0 steps/s
[Step=44350 Epoch=83.6] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.387 | L2-Norm(final)=5.280 | 4134.1 samples/s | 64.6 steps/s
[Step=44400 Epoch=83.7] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.377 | L2-Norm(final)=5.285 | 4090.4 samples/s | 63.9 steps/s
[Step=44450 Epoch=83.8] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.369 | L2-Norm(final)=5.291 | 4091.1 samples/s | 63.9 steps/s
[Step=44500 Epoch=83.9] | Loss=0.00002 | Reg=0.00179 | acc=1.0000 | L2-Norm=13.361 | L2-Norm(final)=5.296 | 4199.9 samples/s | 65.6 steps/s
All layers training...
LR=0.00025, len=1
[Step=44501 Epoch=83.9] | Loss=0.00004 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.280 | L2-Norm(final)=5.349 | 3259.2 samples/s | 50.9 steps/s
[Step=44550 Epoch=84.0] | Loss=0.00001 | Reg=0.00176 | acc=1.0000 | L2-Norm=13.249 | L2-Norm(final)=5.353 | 3441.4 samples/s | 53.8 steps/s
[Step=44600 Epoch=84.1] | Loss=0.00001 | Reg=0.00174 | acc=1.0000 | L2-Norm=13.208 | L2-Norm(final)=5.355 | 3737.5 samples/s | 58.4 steps/s
[Step=44650 Epoch=84.2] | Loss=0.00000 | Reg=0.00173 | acc=1.0000 | L2-Norm=13.166 | L2-Norm(final)=5.357 | 3646.8 samples/s | 57.0 steps/s
[Step=44700 Epoch=84.3] | Loss=0.00000 | Reg=0.00172 | acc=1.0000 | L2-Norm=13.124 | L2-Norm(final)=5.359 | 3701.0 samples/s | 57.8 steps/s
[Step=44750 Epoch=84.4] | Loss=0.00000 | Reg=0.00171 | acc=1.0000 | L2-Norm=13.082 | L2-Norm(final)=5.361 | 3702.7 samples/s | 57.9 steps/s
[Step=44800 Epoch=84.4] | Loss=0.00000 | Reg=0.00170 | acc=1.0000 | L2-Norm=13.040 | L2-Norm(final)=5.363 | 3710.9 samples/s | 58.0 steps/s
[Step=44850 Epoch=84.5] | Loss=0.00000 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.997 | L2-Norm(final)=5.364 | 3757.2 samples/s | 58.7 steps/s
[Step=44900 Epoch=84.6] | Loss=0.00000 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.954 | L2-Norm(final)=5.366 | 3692.3 samples/s | 57.7 steps/s
[Step=44950 Epoch=84.7] | Loss=0.00000 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.912 | L2-Norm(final)=5.368 | 3739.3 samples/s | 58.4 steps/s
[Step=45000 Epoch=84.8] | Loss=0.00000 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.869 | L2-Norm(final)=5.370 | 3793.9 samples/s | 59.3 steps/s
[Step=45050 Epoch=84.9] | Loss=0.00000 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.827 | L2-Norm(final)=5.372 | 1635.1 samples/s | 25.5 steps/s
[Step=45100 Epoch=85.0] | Loss=0.00000 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.785 | L2-Norm(final)=5.374 | 3720.8 samples/s | 58.1 steps/s
[Step=45150 Epoch=85.1] | Loss=0.00000 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.742 | L2-Norm(final)=5.375 | 3671.6 samples/s | 57.4 steps/s
[Step=45200 Epoch=85.2] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.699 | L2-Norm(final)=5.377 | 3745.9 samples/s | 58.5 steps/s
[Step=45250 Epoch=85.3] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.656 | L2-Norm(final)=5.379 | 3725.8 samples/s | 58.2 steps/s
[Step=45300 Epoch=85.4] | Loss=0.00000 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.613 | L2-Norm(final)=5.381 | 3681.2 samples/s | 57.5 steps/s
[Step=45350 Epoch=85.5] | Loss=0.00000 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.569 | L2-Norm(final)=5.382 | 3692.5 samples/s | 57.7 steps/s
[Step=45400 Epoch=85.6] | Loss=0.00000 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.526 | L2-Norm(final)=5.384 | 3777.1 samples/s | 59.0 steps/s
[Step=45450 Epoch=85.7] | Loss=0.00000 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.482 | L2-Norm(final)=5.386 | 3712.4 samples/s | 58.0 steps/s
[Step=45500 Epoch=85.8] | Loss=0.00006 | Reg=0.00155 | acc=0.9844 | L2-Norm=12.440 | L2-Norm(final)=5.387 | 3704.9 samples/s | 57.9 steps/s
[Step=45550 Epoch=85.9] | Loss=0.00027 | Reg=0.00154 | acc=0.9844 | L2-Norm=12.406 | L2-Norm(final)=5.387 | 4661.2 samples/s | 72.8 steps/s
[Step=45600 Epoch=86.0] | Loss=0.00031 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.379 | L2-Norm(final)=5.386 | 1530.5 samples/s | 23.9 steps/s
[Step=45650 Epoch=86.1] | Loss=0.00032 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.354 | L2-Norm(final)=5.385 | 3698.3 samples/s | 57.8 steps/s
[Step=45700 Epoch=86.1] | Loss=0.00031 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.332 | L2-Norm(final)=5.385 | 3663.9 samples/s | 57.2 steps/s
[Step=45750 Epoch=86.2] | Loss=0.00030 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.311 | L2-Norm(final)=5.384 | 3721.9 samples/s | 58.2 steps/s
[Step=45800 Epoch=86.3] | Loss=0.00029 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.292 | L2-Norm(final)=5.384 | 3744.2 samples/s | 58.5 steps/s
[Step=45850 Epoch=86.4] | Loss=0.00028 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.274 | L2-Norm(final)=5.384 | 3671.4 samples/s | 57.4 steps/s
[Step=45900 Epoch=86.5] | Loss=0.00027 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.257 | L2-Norm(final)=5.384 | 3724.0 samples/s | 58.2 steps/s
[Step=45950 Epoch=86.6] | Loss=0.00026 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.242 | L2-Norm(final)=5.384 | 3717.2 samples/s | 58.1 steps/s
[Step=46000 Epoch=86.7] | Loss=0.00026 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.227 | L2-Norm(final)=5.384 | 3681.0 samples/s | 57.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step46000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05797 | acc=0.9709 | tpr=0.9791 | fpr=0.0471 | 3660.9 samples/s | 14.3 steps/s
Avg test loss: 0.05818, Avg test acc: 0.97055, Avg tpr: 0.97820, Avg fpr: 0.04628, total FA: 361

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.11183 | acc=0.3069 | tpr=0.0148 | fpr=0.0590 | 3611.4 samples/s | 14.1 steps/s
Avg test loss: 5.10678, Avg test acc: 0.30639, Avg tpr: 0.01545, Avg fpr: 0.05371, total FA: 419

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.41691 | acc=0.1265 | tpr=0.7522 | fpr=0.8848 | 3604.2 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.40750 | acc=0.1268 | tpr=0.7548 | fpr=0.8849 | 6831.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=5.40146 | acc=0.1255 | tpr=0.7550 | fpr=0.8861 | 4492.9 samples/s | 17.6 steps/s
[Step= 200] | Loss=5.38482 | acc=0.1254 | tpr=0.7454 | fpr=0.8859 | 6108.5 samples/s | 23.9 steps/s
[Step= 250] | Loss=5.38898 | acc=0.1255 | tpr=0.7450 | fpr=0.8857 | 7014.3 samples/s | 27.4 steps/s
[Step= 300] | Loss=5.38607 | acc=0.1261 | tpr=0.7447 | fpr=0.8852 | 6794.1 samples/s | 26.5 steps/s
[Step= 350] | Loss=5.38397 | acc=0.1255 | tpr=0.7458 | fpr=0.8857 | 6918.4 samples/s | 27.0 steps/s
[Step= 400] | Loss=5.38923 | acc=0.1251 | tpr=0.7369 | fpr=0.8861 | 6842.1 samples/s | 26.7 steps/s
[Step= 450] | Loss=5.39028 | acc=0.1253 | tpr=0.7410 | fpr=0.8859 | 6616.4 samples/s | 25.8 steps/s
[Step= 500] | Loss=5.39200 | acc=0.1254 | tpr=0.7427 | fpr=0.8857 | 7001.4 samples/s | 27.3 steps/s
[Step= 550] | Loss=5.39240 | acc=0.1258 | tpr=0.7485 | fpr=0.8856 | 12546.2 samples/s | 49.0 steps/s
Avg test loss: 5.39333, Avg test acc: 0.12573, Avg tpr: 0.74881, Avg fpr: 0.88560, total FA: 122964

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11182 | acc=0.9809 | tpr=0.9513 | fpr=0.0186 | 3663.8 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.11669 | acc=0.9803 | tpr=0.9595 | fpr=0.0193 | 6668.6 samples/s | 26.0 steps/s
[Step= 150] | Loss=0.11952 | acc=0.9793 | tpr=0.9582 | fpr=0.0203 | 4216.1 samples/s | 16.5 steps/s
[Step= 200] | Loss=0.12165 | acc=0.9794 | tpr=0.9628 | fpr=0.0203 | 6856.2 samples/s | 26.8 steps/s
[Step= 250] | Loss=0.11975 | acc=0.9795 | tpr=0.9616 | fpr=0.0202 | 7018.6 samples/s | 27.4 steps/s
[Step= 300] | Loss=0.12215 | acc=0.9791 | tpr=0.9607 | fpr=0.0205 | 6842.4 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.12246 | acc=0.9790 | tpr=0.9606 | fpr=0.0207 | 6849.5 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.12330 | acc=0.9787 | tpr=0.9584 | fpr=0.0209 | 6817.0 samples/s | 26.6 steps/s
[Step= 450] | Loss=0.12607 | acc=0.9785 | tpr=0.9562 | fpr=0.0211 | 7129.1 samples/s | 27.8 steps/s
[Step= 500] | Loss=0.12562 | acc=0.9785 | tpr=0.9573 | fpr=0.0211 | 6526.7 samples/s | 25.5 steps/s
[Step= 550] | Loss=0.12467 | acc=0.9788 | tpr=0.9570 | fpr=0.0208 | 12385.9 samples/s | 48.4 steps/s
Avg test loss: 0.12436, Avg test acc: 0.97880, Avg tpr: 0.95721, Avg fpr: 0.02081, total FA: 2889

server round 23/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=44.9] | Loss=0.04340 | Reg=0.00160 | acc=0.9688 | L2-Norm=12.663 | L2-Norm(final)=7.498 | 3333.1 samples/s | 52.1 steps/s
[Step=46050 Epoch=45.0] | Loss=0.01701 | Reg=0.00161 | acc=0.9688 | L2-Norm=12.682 | L2-Norm(final)=7.514 | 3913.0 samples/s | 61.1 steps/s
[Step=46100 Epoch=45.0] | Loss=0.01610 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.696 | L2-Norm(final)=7.532 | 4329.9 samples/s | 67.7 steps/s
[Step=46150 Epoch=45.1] | Loss=0.01445 | Reg=0.00161 | acc=0.9844 | L2-Norm=12.707 | L2-Norm(final)=7.548 | 4363.3 samples/s | 68.2 steps/s
[Step=46200 Epoch=45.1] | Loss=0.01391 | Reg=0.00162 | acc=0.9844 | L2-Norm=12.716 | L2-Norm(final)=7.562 | 4320.8 samples/s | 67.5 steps/s
[Step=46250 Epoch=45.2] | Loss=0.01390 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.724 | L2-Norm(final)=7.575 | 4325.4 samples/s | 67.6 steps/s
[Step=46300 Epoch=45.2] | Loss=0.01349 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.733 | L2-Norm(final)=7.587 | 4339.8 samples/s | 67.8 steps/s
[Step=46350 Epoch=45.3] | Loss=0.01314 | Reg=0.00162 | acc=0.9531 | L2-Norm=12.740 | L2-Norm(final)=7.599 | 4344.9 samples/s | 67.9 steps/s
[Step=46400 Epoch=45.3] | Loss=0.01313 | Reg=0.00162 | acc=0.9844 | L2-Norm=12.747 | L2-Norm(final)=7.610 | 4274.7 samples/s | 66.8 steps/s
[Step=46450 Epoch=45.4] | Loss=0.01279 | Reg=0.00163 | acc=0.9688 | L2-Norm=12.754 | L2-Norm(final)=7.620 | 4414.9 samples/s | 69.0 steps/s
[Step=46500 Epoch=45.4] | Loss=0.01254 | Reg=0.00163 | acc=0.9844 | L2-Norm=12.761 | L2-Norm(final)=7.630 | 4276.0 samples/s | 66.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=45.4] | Loss=0.00649 | Reg=0.00164 | acc=0.9844 | L2-Norm=12.823 | L2-Norm(final)=7.727 | 3122.6 samples/s | 48.8 steps/s
[Step=46550 Epoch=45.4] | Loss=0.01312 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.833 | L2-Norm(final)=7.737 | 3769.1 samples/s | 58.9 steps/s
[Step=46600 Epoch=45.5] | Loss=0.01406 | Reg=0.00165 | acc=0.9531 | L2-Norm=12.844 | L2-Norm(final)=7.740 | 3898.9 samples/s | 60.9 steps/s
[Step=46650 Epoch=45.5] | Loss=0.01341 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.855 | L2-Norm(final)=7.744 | 3918.7 samples/s | 61.2 steps/s
[Step=46700 Epoch=45.6] | Loss=0.01381 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.864 | L2-Norm(final)=7.747 | 3875.9 samples/s | 60.6 steps/s
[Step=46750 Epoch=45.6] | Loss=0.01293 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.872 | L2-Norm(final)=7.751 | 3936.0 samples/s | 61.5 steps/s
[Step=46800 Epoch=45.7] | Loss=0.01305 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.879 | L2-Norm(final)=7.755 | 3939.2 samples/s | 61.6 steps/s
[Step=46850 Epoch=45.7] | Loss=0.01338 | Reg=0.00166 | acc=0.9688 | L2-Norm=12.886 | L2-Norm(final)=7.758 | 3870.4 samples/s | 60.5 steps/s
[Step=46900 Epoch=45.8] | Loss=0.01345 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.892 | L2-Norm(final)=7.761 | 3958.9 samples/s | 61.9 steps/s
[Step=46950 Epoch=45.8] | Loss=0.01318 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.898 | L2-Norm(final)=7.764 | 3991.2 samples/s | 62.4 steps/s
[Step=47000 Epoch=45.9] | Loss=0.01310 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.905 | L2-Norm(final)=7.767 | 3914.7 samples/s | 61.2 steps/s
[Step=47050 Epoch=45.9] | Loss=0.01319 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.911 | L2-Norm(final)=7.770 | 3951.9 samples/s | 61.7 steps/s
[Step=47100 Epoch=46.0] | Loss=0.01304 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.918 | L2-Norm(final)=7.773 | 3953.4 samples/s | 61.8 steps/s
[Step=47150 Epoch=46.0] | Loss=0.01295 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.924 | L2-Norm(final)=7.776 | 3977.1 samples/s | 62.1 steps/s
[Step=47200 Epoch=46.1] | Loss=0.01300 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.930 | L2-Norm(final)=7.779 | 3954.0 samples/s | 61.8 steps/s
[Step=47250 Epoch=46.1] | Loss=0.01284 | Reg=0.00167 | acc=0.9844 | L2-Norm=12.936 | L2-Norm(final)=7.782 | 3965.5 samples/s | 62.0 steps/s
[Step=47300 Epoch=46.2] | Loss=0.01279 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.942 | L2-Norm(final)=7.785 | 3931.3 samples/s | 61.4 steps/s
[Step=47350 Epoch=46.2] | Loss=0.01292 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.947 | L2-Norm(final)=7.788 | 3964.3 samples/s | 61.9 steps/s
[Step=47400 Epoch=46.3] | Loss=0.01284 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.953 | L2-Norm(final)=7.790 | 3972.7 samples/s | 62.1 steps/s
[Step=47450 Epoch=46.3] | Loss=0.01294 | Reg=0.00168 | acc=1.0000 | L2-Norm=12.958 | L2-Norm(final)=7.793 | 3971.6 samples/s | 62.1 steps/s
[Step=47500 Epoch=46.4] | Loss=0.01285 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.963 | L2-Norm(final)=7.796 | 4181.7 samples/s | 65.3 steps/s
[Step=47550 Epoch=46.4] | Loss=0.01279 | Reg=0.00168 | acc=0.9531 | L2-Norm=12.969 | L2-Norm(final)=7.799 | 1668.2 samples/s | 26.1 steps/s
[Step=47600 Epoch=46.5] | Loss=0.01263 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.974 | L2-Norm(final)=7.802 | 3948.6 samples/s | 61.7 steps/s
[Step=47650 Epoch=46.5] | Loss=0.01247 | Reg=0.00168 | acc=0.9844 | L2-Norm=12.979 | L2-Norm(final)=7.805 | 3911.6 samples/s | 61.1 steps/s
[Step=47700 Epoch=46.6] | Loss=0.01232 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.984 | L2-Norm(final)=7.808 | 3932.6 samples/s | 61.4 steps/s
[Step=47750 Epoch=46.6] | Loss=0.01231 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.988 | L2-Norm(final)=7.811 | 3919.3 samples/s | 61.2 steps/s
[Step=47800 Epoch=46.7] | Loss=0.01215 | Reg=0.00169 | acc=1.0000 | L2-Norm=12.993 | L2-Norm(final)=7.814 | 3963.3 samples/s | 61.9 steps/s
[Step=47850 Epoch=46.7] | Loss=0.01215 | Reg=0.00169 | acc=0.9844 | L2-Norm=12.998 | L2-Norm(final)=7.817 | 3964.9 samples/s | 62.0 steps/s
[Step=47900 Epoch=46.8] | Loss=0.01218 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.002 | L2-Norm(final)=7.820 | 3985.0 samples/s | 62.3 steps/s
[Step=47950 Epoch=46.8] | Loss=0.01206 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.006 | L2-Norm(final)=7.822 | 3979.0 samples/s | 62.2 steps/s
[Step=48000 Epoch=46.9] | Loss=0.01200 | Reg=0.00169 | acc=1.0000 | L2-Norm=13.011 | L2-Norm(final)=7.825 | 3990.1 samples/s | 62.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step48000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=46001 Epoch=86.7] | Loss=0.00000 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.663 | L2-Norm(final)=5.384 | 3071.0 samples/s | 48.0 steps/s
[Step=46050 Epoch=86.8] | Loss=0.00006 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.657 | L2-Norm(final)=5.385 | 3984.7 samples/s | 62.3 steps/s
[Step=46100 Epoch=86.9] | Loss=0.00005 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.656 | L2-Norm(final)=5.387 | 4078.6 samples/s | 63.7 steps/s
[Step=46150 Epoch=87.0] | Loss=0.00005 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.655 | L2-Norm(final)=5.389 | 4132.9 samples/s | 64.6 steps/s
[Step=46200 Epoch=87.1] | Loss=0.00005 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.655 | L2-Norm(final)=5.391 | 4090.3 samples/s | 63.9 steps/s
[Step=46250 Epoch=87.2] | Loss=0.00005 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.654 | L2-Norm(final)=5.393 | 4085.1 samples/s | 63.8 steps/s
[Step=46300 Epoch=87.3] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.654 | L2-Norm(final)=5.394 | 4105.4 samples/s | 64.1 steps/s
[Step=46350 Epoch=87.4] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.654 | L2-Norm(final)=5.396 | 4114.9 samples/s | 64.3 steps/s
[Step=46400 Epoch=87.5] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.653 | L2-Norm(final)=5.398 | 4104.3 samples/s | 64.1 steps/s
[Step=46450 Epoch=87.6] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.652 | L2-Norm(final)=5.399 | 4050.9 samples/s | 63.3 steps/s
[Step=46500 Epoch=87.7] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.652 | L2-Norm(final)=5.401 | 4232.9 samples/s | 66.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=46501 Epoch=87.7] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.644 | L2-Norm(final)=5.417 | 3346.2 samples/s | 52.3 steps/s
[Step=46550 Epoch=87.7] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.641 | L2-Norm(final)=5.418 | 3358.3 samples/s | 52.5 steps/s
[Step=46600 Epoch=87.8] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.637 | L2-Norm(final)=5.419 | 3667.2 samples/s | 57.3 steps/s
[Step=46650 Epoch=87.9] | Loss=0.00002 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.633 | L2-Norm(final)=5.420 | 3662.3 samples/s | 57.2 steps/s
[Step=46700 Epoch=88.0] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.629 | L2-Norm(final)=5.421 | 3754.7 samples/s | 58.7 steps/s
[Step=46750 Epoch=88.1] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.625 | L2-Norm(final)=5.423 | 3749.6 samples/s | 58.6 steps/s
[Step=46800 Epoch=88.2] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.621 | L2-Norm(final)=5.424 | 3701.9 samples/s | 57.8 steps/s
[Step=46850 Epoch=88.3] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.617 | L2-Norm(final)=5.425 | 3735.0 samples/s | 58.4 steps/s
[Step=46900 Epoch=88.4] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.613 | L2-Norm(final)=5.426 | 3717.9 samples/s | 58.1 steps/s
[Step=46950 Epoch=88.5] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.609 | L2-Norm(final)=5.427 | 3745.5 samples/s | 58.5 steps/s
[Step=47000 Epoch=88.6] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.604 | L2-Norm(final)=5.428 | 3745.1 samples/s | 58.5 steps/s
[Step=47050 Epoch=88.7] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.600 | L2-Norm(final)=5.429 | 1613.7 samples/s | 25.2 steps/s
[Step=47100 Epoch=88.8] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.596 | L2-Norm(final)=5.430 | 3736.9 samples/s | 58.4 steps/s
[Step=47150 Epoch=88.9] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.591 | L2-Norm(final)=5.431 | 3676.1 samples/s | 57.4 steps/s
[Step=47200 Epoch=89.0] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.587 | L2-Norm(final)=5.432 | 3691.9 samples/s | 57.7 steps/s
[Step=47250 Epoch=89.1] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.582 | L2-Norm(final)=5.433 | 3727.2 samples/s | 58.2 steps/s
[Step=47300 Epoch=89.2] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.578 | L2-Norm(final)=5.433 | 3751.2 samples/s | 58.6 steps/s
[Step=47350 Epoch=89.3] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.573 | L2-Norm(final)=5.434 | 3784.3 samples/s | 59.1 steps/s
[Step=47400 Epoch=89.3] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.569 | L2-Norm(final)=5.435 | 3704.7 samples/s | 57.9 steps/s
[Step=47450 Epoch=89.4] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.564 | L2-Norm(final)=5.436 | 3743.9 samples/s | 58.5 steps/s
[Step=47500 Epoch=89.5] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.559 | L2-Norm(final)=5.436 | 3700.8 samples/s | 57.8 steps/s
[Step=47550 Epoch=89.6] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.554 | L2-Norm(final)=5.437 | 4661.0 samples/s | 72.8 steps/s
[Step=47600 Epoch=89.7] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.549 | L2-Norm(final)=5.438 | 1497.3 samples/s | 23.4 steps/s
[Step=47650 Epoch=89.8] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.544 | L2-Norm(final)=5.439 | 3716.8 samples/s | 58.1 steps/s
[Step=47700 Epoch=89.9] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.539 | L2-Norm(final)=5.440 | 3691.5 samples/s | 57.7 steps/s
[Step=47750 Epoch=90.0] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.534 | L2-Norm(final)=5.441 | 3763.4 samples/s | 58.8 steps/s
[Step=47800 Epoch=90.1] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.529 | L2-Norm(final)=5.442 | 3729.7 samples/s | 58.3 steps/s
[Step=47850 Epoch=90.2] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.523 | L2-Norm(final)=5.443 | 3734.5 samples/s | 58.4 steps/s
[Step=47900 Epoch=90.3] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.518 | L2-Norm(final)=5.444 | 3720.7 samples/s | 58.1 steps/s
[Step=47950 Epoch=90.4] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.512 | L2-Norm(final)=5.445 | 3775.4 samples/s | 59.0 steps/s
[Step=48000 Epoch=90.5] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.507 | L2-Norm(final)=5.446 | 3706.1 samples/s | 57.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step48000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05844 | acc=0.9716 | tpr=0.9752 | fpr=0.0364 | 2700.5 samples/s | 10.5 steps/s
Avg test loss: 0.05848, Avg test acc: 0.97075, Avg tpr: 0.97395, Avg fpr: 0.03628, total FA: 283

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.22212 | acc=0.3045 | tpr=0.0241 | fpr=0.0865 | 2684.5 samples/s | 10.5 steps/s
Avg test loss: 5.21337, Avg test acc: 0.30379, Avg tpr: 0.02518, Avg fpr: 0.08345, total FA: 651

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.73717 | acc=0.1247 | tpr=0.7389 | fpr=0.8864 | 3632.2 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.71401 | acc=0.1268 | tpr=0.7249 | fpr=0.8844 | 7069.0 samples/s | 27.6 steps/s
[Step= 150] | Loss=5.71412 | acc=0.1244 | tpr=0.7233 | fpr=0.8866 | 6852.4 samples/s | 26.8 steps/s
[Step= 200] | Loss=5.69556 | acc=0.1245 | tpr=0.7169 | fpr=0.8863 | 6745.7 samples/s | 26.4 steps/s
[Step= 250] | Loss=5.69995 | acc=0.1252 | tpr=0.7197 | fpr=0.8856 | 6767.4 samples/s | 26.4 steps/s
[Step= 300] | Loss=5.69687 | acc=0.1254 | tpr=0.7193 | fpr=0.8854 | 6874.4 samples/s | 26.9 steps/s
[Step= 350] | Loss=5.69506 | acc=0.1249 | tpr=0.7195 | fpr=0.8859 | 6726.7 samples/s | 26.3 steps/s
[Step= 400] | Loss=5.70319 | acc=0.1245 | tpr=0.7117 | fpr=0.8862 | 6790.1 samples/s | 26.5 steps/s
[Step= 450] | Loss=5.70398 | acc=0.1247 | tpr=0.7157 | fpr=0.8860 | 6775.6 samples/s | 26.5 steps/s
[Step= 500] | Loss=5.70586 | acc=0.1250 | tpr=0.7181 | fpr=0.8857 | 6605.0 samples/s | 25.8 steps/s
[Step= 550] | Loss=5.70671 | acc=0.1252 | tpr=0.7238 | fpr=0.8857 | 12524.3 samples/s | 48.9 steps/s
Avg test loss: 5.70762, Avg test acc: 0.12519, Avg tpr: 0.72425, Avg fpr: 0.88570, total FA: 122977

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11892 | acc=0.9804 | tpr=0.9469 | fpr=0.0190 | 3607.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.12465 | acc=0.9796 | tpr=0.9574 | fpr=0.0200 | 6823.7 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.12588 | acc=0.9791 | tpr=0.9597 | fpr=0.0205 | 6774.7 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.12797 | acc=0.9792 | tpr=0.9650 | fpr=0.0205 | 6865.1 samples/s | 26.8 steps/s
[Step= 250] | Loss=0.12640 | acc=0.9794 | tpr=0.9642 | fpr=0.0203 | 6828.3 samples/s | 26.7 steps/s
[Step= 300] | Loss=0.12877 | acc=0.9790 | tpr=0.9615 | fpr=0.0207 | 6730.9 samples/s | 26.3 steps/s
[Step= 350] | Loss=0.12869 | acc=0.9789 | tpr=0.9624 | fpr=0.0208 | 7014.4 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.12927 | acc=0.9785 | tpr=0.9623 | fpr=0.0212 | 6839.7 samples/s | 26.7 steps/s
[Step= 450] | Loss=0.13206 | acc=0.9782 | tpr=0.9601 | fpr=0.0214 | 6749.4 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.13164 | acc=0.9782 | tpr=0.9604 | fpr=0.0215 | 6615.9 samples/s | 25.8 steps/s
[Step= 550] | Loss=0.13082 | acc=0.9784 | tpr=0.9602 | fpr=0.0212 | 12859.3 samples/s | 50.2 steps/s
Avg test loss: 0.13048, Avg test acc: 0.97845, Avg tpr: 0.96038, Avg fpr: 0.02122, total FA: 2946

server round 24/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=46.9] | Loss=0.01088 | Reg=0.00161 | acc=0.9844 | L2-Norm=12.680 | L2-Norm(final)=7.903 | 3296.8 samples/s | 51.5 steps/s
[Step=48050 Epoch=46.9] | Loss=0.00813 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.692 | L2-Norm(final)=7.910 | 4016.2 samples/s | 62.8 steps/s
[Step=48100 Epoch=47.0] | Loss=0.00862 | Reg=0.00161 | acc=0.9844 | L2-Norm=12.699 | L2-Norm(final)=7.917 | 4366.6 samples/s | 68.2 steps/s
[Step=48150 Epoch=47.0] | Loss=0.00820 | Reg=0.00161 | acc=0.9844 | L2-Norm=12.705 | L2-Norm(final)=7.924 | 4343.5 samples/s | 67.9 steps/s
[Step=48200 Epoch=47.1] | Loss=0.00788 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.710 | L2-Norm(final)=7.931 | 4318.2 samples/s | 67.5 steps/s
[Step=48250 Epoch=47.1] | Loss=0.00788 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.714 | L2-Norm(final)=7.938 | 4291.6 samples/s | 67.1 steps/s
[Step=48300 Epoch=47.2] | Loss=0.00794 | Reg=0.00162 | acc=0.9844 | L2-Norm=12.719 | L2-Norm(final)=7.944 | 4368.2 samples/s | 68.3 steps/s
[Step=48350 Epoch=47.2] | Loss=0.00767 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.723 | L2-Norm(final)=7.951 | 4365.1 samples/s | 68.2 steps/s
[Step=48400 Epoch=47.3] | Loss=0.00767 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.727 | L2-Norm(final)=7.958 | 4399.9 samples/s | 68.7 steps/s
[Step=48450 Epoch=47.3] | Loss=0.00768 | Reg=0.00162 | acc=1.0000 | L2-Norm=12.731 | L2-Norm(final)=7.964 | 4393.0 samples/s | 68.6 steps/s
[Step=48500 Epoch=47.4] | Loss=0.00772 | Reg=0.00162 | acc=0.9844 | L2-Norm=12.735 | L2-Norm(final)=7.970 | 4412.8 samples/s | 69.0 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=47.4] | Loss=0.00066 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.776 | L2-Norm(final)=8.027 | 3273.2 samples/s | 51.1 steps/s
[Step=48550 Epoch=47.4] | Loss=0.00775 | Reg=0.00163 | acc=1.0000 | L2-Norm=12.782 | L2-Norm(final)=8.033 | 3723.5 samples/s | 58.2 steps/s
[Step=48600 Epoch=47.5] | Loss=0.01009 | Reg=0.00163 | acc=0.9375 | L2-Norm=12.787 | L2-Norm(final)=8.035 | 3910.9 samples/s | 61.1 steps/s
[Step=48650 Epoch=47.5] | Loss=0.01006 | Reg=0.00164 | acc=0.9688 | L2-Norm=12.792 | L2-Norm(final)=8.036 | 3874.6 samples/s | 60.5 steps/s
[Step=48700 Epoch=47.5] | Loss=0.01025 | Reg=0.00164 | acc=0.9844 | L2-Norm=12.797 | L2-Norm(final)=8.039 | 3899.8 samples/s | 60.9 steps/s
[Step=48750 Epoch=47.6] | Loss=0.01050 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.803 | L2-Norm(final)=8.041 | 3895.4 samples/s | 60.9 steps/s
[Step=48800 Epoch=47.6] | Loss=0.01062 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.808 | L2-Norm(final)=8.043 | 3964.9 samples/s | 62.0 steps/s
[Step=48850 Epoch=47.7] | Loss=0.01083 | Reg=0.00164 | acc=1.0000 | L2-Norm=12.813 | L2-Norm(final)=8.045 | 3945.5 samples/s | 61.6 steps/s
[Step=48900 Epoch=47.7] | Loss=0.01078 | Reg=0.00164 | acc=0.9688 | L2-Norm=12.818 | L2-Norm(final)=8.047 | 3890.3 samples/s | 60.8 steps/s
[Step=48950 Epoch=47.8] | Loss=0.01070 | Reg=0.00164 | acc=0.9844 | L2-Norm=12.824 | L2-Norm(final)=8.050 | 3919.2 samples/s | 61.2 steps/s
[Step=49000 Epoch=47.8] | Loss=0.01065 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.829 | L2-Norm(final)=8.053 | 3936.0 samples/s | 61.5 steps/s
[Step=49050 Epoch=47.9] | Loss=0.01069 | Reg=0.00165 | acc=0.9844 | L2-Norm=12.835 | L2-Norm(final)=8.056 | 3935.6 samples/s | 61.5 steps/s
[Step=49100 Epoch=47.9] | Loss=0.01095 | Reg=0.00165 | acc=0.9844 | L2-Norm=12.840 | L2-Norm(final)=8.059 | 3911.2 samples/s | 61.1 steps/s
[Step=49150 Epoch=48.0] | Loss=0.01107 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.845 | L2-Norm(final)=8.061 | 3948.2 samples/s | 61.7 steps/s
[Step=49200 Epoch=48.0] | Loss=0.01104 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.850 | L2-Norm(final)=8.065 | 3933.9 samples/s | 61.5 steps/s
[Step=49250 Epoch=48.1] | Loss=0.01099 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.855 | L2-Norm(final)=8.068 | 3946.4 samples/s | 61.7 steps/s
[Step=49300 Epoch=48.1] | Loss=0.01109 | Reg=0.00165 | acc=1.0000 | L2-Norm=12.860 | L2-Norm(final)=8.071 | 3895.8 samples/s | 60.9 steps/s
[Step=49350 Epoch=48.2] | Loss=0.01123 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.865 | L2-Norm(final)=8.074 | 3876.7 samples/s | 60.6 steps/s
[Step=49400 Epoch=48.2] | Loss=0.01112 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.870 | L2-Norm(final)=8.077 | 3936.6 samples/s | 61.5 steps/s
[Step=49450 Epoch=48.3] | Loss=0.01112 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.875 | L2-Norm(final)=8.080 | 3949.8 samples/s | 61.7 steps/s
[Step=49500 Epoch=48.3] | Loss=0.01108 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.880 | L2-Norm(final)=8.083 | 4288.0 samples/s | 67.0 steps/s
[Step=49550 Epoch=48.4] | Loss=0.01109 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.885 | L2-Norm(final)=8.086 | 1653.6 samples/s | 25.8 steps/s
[Step=49600 Epoch=48.4] | Loss=0.01104 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.890 | L2-Norm(final)=8.089 | 3907.6 samples/s | 61.1 steps/s
[Step=49650 Epoch=48.5] | Loss=0.01097 | Reg=0.00166 | acc=1.0000 | L2-Norm=12.895 | L2-Norm(final)=8.092 | 3928.9 samples/s | 61.4 steps/s
[Step=49700 Epoch=48.5] | Loss=0.01095 | Reg=0.00166 | acc=0.9844 | L2-Norm=12.900 | L2-Norm(final)=8.095 | 3921.2 samples/s | 61.3 steps/s
[Step=49750 Epoch=48.6] | Loss=0.01090 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.904 | L2-Norm(final)=8.098 | 3884.4 samples/s | 60.7 steps/s
[Step=49800 Epoch=48.6] | Loss=0.01074 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.909 | L2-Norm(final)=8.101 | 3974.2 samples/s | 62.1 steps/s
[Step=49850 Epoch=48.7] | Loss=0.01064 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.913 | L2-Norm(final)=8.104 | 3922.1 samples/s | 61.3 steps/s
[Step=49900 Epoch=48.7] | Loss=0.01048 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.917 | L2-Norm(final)=8.108 | 3969.1 samples/s | 62.0 steps/s
[Step=49950 Epoch=48.8] | Loss=0.01045 | Reg=0.00167 | acc=0.9688 | L2-Norm=12.922 | L2-Norm(final)=8.111 | 3904.2 samples/s | 61.0 steps/s
[Step=50000 Epoch=48.8] | Loss=0.01040 | Reg=0.00167 | acc=1.0000 | L2-Norm=12.926 | L2-Norm(final)=8.114 | 3943.7 samples/s | 61.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step50000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=48001 Epoch=90.5] | Loss=0.00000 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.680 | L2-Norm(final)=5.480 | 3335.1 samples/s | 52.1 steps/s
[Step=48050 Epoch=90.6] | Loss=0.00005 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.674 | L2-Norm(final)=5.484 | 3814.2 samples/s | 59.6 steps/s
[Step=48100 Epoch=90.7] | Loss=0.00005 | Reg=0.00161 | acc=1.0000 | L2-Norm=12.670 | L2-Norm(final)=5.489 | 4145.3 samples/s | 64.8 steps/s
[Step=48150 Epoch=90.8] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.668 | L2-Norm(final)=5.493 | 4081.7 samples/s | 63.8 steps/s
[Step=48200 Epoch=90.9] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.667 | L2-Norm(final)=5.498 | 4134.1 samples/s | 64.6 steps/s
[Step=48250 Epoch=91.0] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.665 | L2-Norm(final)=5.503 | 4138.2 samples/s | 64.7 steps/s
[Step=48300 Epoch=91.0] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.663 | L2-Norm(final)=5.506 | 4066.3 samples/s | 63.5 steps/s
[Step=48350 Epoch=91.1] | Loss=0.00004 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.661 | L2-Norm(final)=5.510 | 4121.5 samples/s | 64.4 steps/s
[Step=48400 Epoch=91.2] | Loss=0.00003 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.659 | L2-Norm(final)=5.513 | 4231.3 samples/s | 66.1 steps/s
[Step=48450 Epoch=91.3] | Loss=0.00003 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.657 | L2-Norm(final)=5.517 | 4137.8 samples/s | 64.7 steps/s
[Step=48500 Epoch=91.4] | Loss=0.00003 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.654 | L2-Norm(final)=5.520 | 4118.2 samples/s | 64.3 steps/s
All layers training...
LR=0.00025, len=1
[Step=48501 Epoch=91.4] | Loss=0.00002 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.629 | L2-Norm(final)=5.550 | 3453.0 samples/s | 54.0 steps/s
[Step=48550 Epoch=91.5] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.621 | L2-Norm(final)=5.553 | 3278.0 samples/s | 51.2 steps/s
[Step=48600 Epoch=91.6] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.612 | L2-Norm(final)=5.555 | 3703.4 samples/s | 57.9 steps/s
[Step=48650 Epoch=91.7] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.602 | L2-Norm(final)=5.557 | 3685.5 samples/s | 57.6 steps/s
[Step=48700 Epoch=91.8] | Loss=0.00001 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.592 | L2-Norm(final)=5.559 | 3718.0 samples/s | 58.1 steps/s
[Step=48750 Epoch=91.9] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.582 | L2-Norm(final)=5.561 | 3788.5 samples/s | 59.2 steps/s
[Step=48800 Epoch=92.0] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.571 | L2-Norm(final)=5.563 | 3729.6 samples/s | 58.3 steps/s
[Step=48850 Epoch=92.1] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.561 | L2-Norm(final)=5.564 | 3724.2 samples/s | 58.2 steps/s
[Step=48900 Epoch=92.2] | Loss=0.00001 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.551 | L2-Norm(final)=5.566 | 3783.8 samples/s | 59.1 steps/s
[Step=48950 Epoch=92.3] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.540 | L2-Norm(final)=5.567 | 3747.4 samples/s | 58.6 steps/s
[Step=49000 Epoch=92.4] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.530 | L2-Norm(final)=5.568 | 3799.4 samples/s | 59.4 steps/s
[Step=49050 Epoch=92.5] | Loss=0.00001 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.519 | L2-Norm(final)=5.570 | 1649.2 samples/s | 25.8 steps/s
[Step=49100 Epoch=92.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.508 | L2-Norm(final)=5.571 | 3737.1 samples/s | 58.4 steps/s
[Step=49150 Epoch=92.6] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.497 | L2-Norm(final)=5.572 | 3666.5 samples/s | 57.3 steps/s
[Step=49200 Epoch=92.7] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.486 | L2-Norm(final)=5.574 | 3740.9 samples/s | 58.5 steps/s
[Step=49250 Epoch=92.8] | Loss=0.00001 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.475 | L2-Norm(final)=5.575 | 3680.4 samples/s | 57.5 steps/s
[Step=49300 Epoch=92.9] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.463 | L2-Norm(final)=5.576 | 3734.8 samples/s | 58.4 steps/s
[Step=49350 Epoch=93.0] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.452 | L2-Norm(final)=5.577 | 3769.3 samples/s | 58.9 steps/s
[Step=49400 Epoch=93.1] | Loss=0.00001 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.440 | L2-Norm(final)=5.578 | 3685.5 samples/s | 57.6 steps/s
[Step=49450 Epoch=93.2] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.429 | L2-Norm(final)=5.580 | 3658.3 samples/s | 57.2 steps/s
[Step=49500 Epoch=93.3] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.417 | L2-Norm(final)=5.581 | 3757.8 samples/s | 58.7 steps/s
[Step=49550 Epoch=93.4] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.405 | L2-Norm(final)=5.582 | 4639.1 samples/s | 72.5 steps/s
[Step=49600 Epoch=93.5] | Loss=0.00001 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.393 | L2-Norm(final)=5.583 | 1486.0 samples/s | 23.2 steps/s
[Step=49650 Epoch=93.6] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.381 | L2-Norm(final)=5.584 | 3697.9 samples/s | 57.8 steps/s
[Step=49700 Epoch=93.7] | Loss=0.00001 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.368 | L2-Norm(final)=5.585 | 3696.5 samples/s | 57.8 steps/s
[Step=49750 Epoch=93.8] | Loss=0.00000 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.356 | L2-Norm(final)=5.586 | 3657.3 samples/s | 57.1 steps/s
[Step=49800 Epoch=93.9] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.343 | L2-Norm(final)=5.587 | 3704.2 samples/s | 57.9 steps/s
[Step=49850 Epoch=94.0] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.330 | L2-Norm(final)=5.588 | 3737.2 samples/s | 58.4 steps/s
[Step=49900 Epoch=94.1] | Loss=0.00000 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.317 | L2-Norm(final)=5.589 | 3686.0 samples/s | 57.6 steps/s
[Step=49950 Epoch=94.2] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.304 | L2-Norm(final)=5.590 | 3642.5 samples/s | 56.9 steps/s
[Step=50000 Epoch=94.3] | Loss=0.00000 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.291 | L2-Norm(final)=5.591 | 3699.4 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step50000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05919 | acc=0.9720 | tpr=0.9788 | fpr=0.0429 | 3594.5 samples/s | 14.0 steps/s
Avg test loss: 0.06023, Avg test acc: 0.97107, Avg tpr: 0.97698, Avg fpr: 0.04192, total FA: 327

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.35180 | acc=0.3046 | tpr=0.0228 | fpr=0.0835 | 3624.7 samples/s | 14.2 steps/s
Avg test loss: 5.34523, Avg test acc: 0.30375, Avg tpr: 0.02372, Avg fpr: 0.08037, total FA: 627

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.72227 | acc=0.1230 | tpr=0.6903 | fpr=0.8871 | 3584.1 samples/s | 14.0 steps/s
[Step= 100] | Loss=5.70982 | acc=0.1261 | tpr=0.6866 | fpr=0.8844 | 6940.5 samples/s | 27.1 steps/s
[Step= 150] | Loss=5.70757 | acc=0.1248 | tpr=0.6873 | fpr=0.8856 | 6884.5 samples/s | 26.9 steps/s
[Step= 200] | Loss=5.68585 | acc=0.1248 | tpr=0.6765 | fpr=0.8853 | 6824.8 samples/s | 26.7 steps/s
[Step= 250] | Loss=5.68997 | acc=0.1253 | tpr=0.6812 | fpr=0.8848 | 6791.0 samples/s | 26.5 steps/s
[Step= 300] | Loss=5.68735 | acc=0.1260 | tpr=0.6807 | fpr=0.8841 | 6985.7 samples/s | 27.3 steps/s
[Step= 350] | Loss=5.68659 | acc=0.1258 | tpr=0.6800 | fpr=0.8843 | 6882.6 samples/s | 26.9 steps/s
[Step= 400] | Loss=5.69158 | acc=0.1252 | tpr=0.6767 | fpr=0.8848 | 6682.7 samples/s | 26.1 steps/s
[Step= 450] | Loss=5.69166 | acc=0.1251 | tpr=0.6787 | fpr=0.8849 | 6852.4 samples/s | 26.8 steps/s
[Step= 500] | Loss=5.69337 | acc=0.1253 | tpr=0.6841 | fpr=0.8848 | 6574.2 samples/s | 25.7 steps/s
[Step= 550] | Loss=5.69421 | acc=0.1256 | tpr=0.6900 | fpr=0.8847 | 12678.4 samples/s | 49.5 steps/s
Avg test loss: 5.69540, Avg test acc: 0.12558, Avg tpr: 0.69057, Avg fpr: 0.88469, total FA: 122838

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11633 | acc=0.9811 | tpr=0.9513 | fpr=0.0184 | 3591.8 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.12215 | acc=0.9804 | tpr=0.9595 | fpr=0.0192 | 6803.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.12306 | acc=0.9799 | tpr=0.9611 | fpr=0.0197 | 6956.7 samples/s | 27.2 steps/s
[Step= 200] | Loss=0.12505 | acc=0.9799 | tpr=0.9650 | fpr=0.0198 | 6801.6 samples/s | 26.6 steps/s
[Step= 250] | Loss=0.12346 | acc=0.9801 | tpr=0.9633 | fpr=0.0196 | 7059.7 samples/s | 27.6 steps/s
[Step= 300] | Loss=0.12562 | acc=0.9797 | tpr=0.9615 | fpr=0.0199 | 6780.1 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.12537 | acc=0.9796 | tpr=0.9618 | fpr=0.0200 | 6944.5 samples/s | 27.1 steps/s
[Step= 400] | Loss=0.12581 | acc=0.9793 | tpr=0.9617 | fpr=0.0204 | 6643.3 samples/s | 26.0 steps/s
[Step= 450] | Loss=0.12870 | acc=0.9790 | tpr=0.9596 | fpr=0.0206 | 6924.0 samples/s | 27.0 steps/s
[Step= 500] | Loss=0.12824 | acc=0.9790 | tpr=0.9599 | fpr=0.0206 | 6954.2 samples/s | 27.2 steps/s
[Step= 550] | Loss=0.12740 | acc=0.9792 | tpr=0.9602 | fpr=0.0204 | 11752.1 samples/s | 45.9 steps/s
Avg test loss: 0.12708, Avg test acc: 0.97925, Avg tpr: 0.96038, Avg fpr: 0.02041, total FA: 2834

server round 25/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=48.8] | Loss=0.00135 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.411 | L2-Norm(final)=8.194 | 3435.7 samples/s | 53.7 steps/s
[Step=50050 Epoch=48.9] | Loss=0.01050 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.423 | L2-Norm(final)=8.197 | 3958.3 samples/s | 61.8 steps/s
[Step=50100 Epoch=48.9] | Loss=0.00979 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.430 | L2-Norm(final)=8.203 | 4238.5 samples/s | 66.2 steps/s
[Step=50150 Epoch=49.0] | Loss=0.00932 | Reg=0.00155 | acc=0.9844 | L2-Norm=12.434 | L2-Norm(final)=8.209 | 4344.1 samples/s | 67.9 steps/s
[Step=50200 Epoch=49.0] | Loss=0.00849 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.438 | L2-Norm(final)=8.216 | 4400.8 samples/s | 68.8 steps/s
[Step=50250 Epoch=49.1] | Loss=0.00828 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.441 | L2-Norm(final)=8.223 | 4310.7 samples/s | 67.4 steps/s
[Step=50300 Epoch=49.1] | Loss=0.00806 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.445 | L2-Norm(final)=8.229 | 4331.1 samples/s | 67.7 steps/s
[Step=50350 Epoch=49.2] | Loss=0.00833 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.449 | L2-Norm(final)=8.234 | 4356.0 samples/s | 68.1 steps/s
[Step=50400 Epoch=49.2] | Loss=0.00856 | Reg=0.00155 | acc=0.9844 | L2-Norm=12.452 | L2-Norm(final)=8.239 | 4406.1 samples/s | 68.8 steps/s
[Step=50450 Epoch=49.3] | Loss=0.00841 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.456 | L2-Norm(final)=8.244 | 4369.0 samples/s | 68.3 steps/s
[Step=50500 Epoch=49.3] | Loss=0.00847 | Reg=0.00155 | acc=1.0000 | L2-Norm=12.459 | L2-Norm(final)=8.249 | 4338.8 samples/s | 67.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=49.3] | Loss=0.00599 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.494 | L2-Norm(final)=8.300 | 3353.6 samples/s | 52.4 steps/s
[Step=50550 Epoch=49.4] | Loss=0.00884 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.499 | L2-Norm(final)=8.303 | 3594.4 samples/s | 56.2 steps/s
[Step=50600 Epoch=49.4] | Loss=0.00816 | Reg=0.00156 | acc=1.0000 | L2-Norm=12.506 | L2-Norm(final)=8.306 | 3880.2 samples/s | 60.6 steps/s
[Step=50650 Epoch=49.5] | Loss=0.00895 | Reg=0.00157 | acc=0.9844 | L2-Norm=12.514 | L2-Norm(final)=8.309 | 3897.6 samples/s | 60.9 steps/s
[Step=50700 Epoch=49.5] | Loss=0.00970 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.521 | L2-Norm(final)=8.313 | 3919.6 samples/s | 61.2 steps/s
[Step=50750 Epoch=49.5] | Loss=0.00964 | Reg=0.00157 | acc=0.9844 | L2-Norm=12.528 | L2-Norm(final)=8.316 | 3925.3 samples/s | 61.3 steps/s
[Step=50800 Epoch=49.6] | Loss=0.00984 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.535 | L2-Norm(final)=8.320 | 3903.7 samples/s | 61.0 steps/s
[Step=50850 Epoch=49.6] | Loss=0.01023 | Reg=0.00157 | acc=1.0000 | L2-Norm=12.542 | L2-Norm(final)=8.324 | 3939.5 samples/s | 61.6 steps/s
[Step=50900 Epoch=49.7] | Loss=0.01029 | Reg=0.00157 | acc=0.9688 | L2-Norm=12.549 | L2-Norm(final)=8.327 | 3949.9 samples/s | 61.7 steps/s
[Step=50950 Epoch=49.7] | Loss=0.01032 | Reg=0.00158 | acc=0.9844 | L2-Norm=12.556 | L2-Norm(final)=8.331 | 3932.1 samples/s | 61.4 steps/s
[Step=51000 Epoch=49.8] | Loss=0.01041 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.563 | L2-Norm(final)=8.336 | 3984.8 samples/s | 62.3 steps/s
[Step=51050 Epoch=49.8] | Loss=0.01043 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.569 | L2-Norm(final)=8.340 | 3943.3 samples/s | 61.6 steps/s
[Step=51100 Epoch=49.9] | Loss=0.01047 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.576 | L2-Norm(final)=8.344 | 3940.1 samples/s | 61.6 steps/s
[Step=51150 Epoch=49.9] | Loss=0.01054 | Reg=0.00158 | acc=0.9844 | L2-Norm=12.582 | L2-Norm(final)=8.348 | 3968.3 samples/s | 62.0 steps/s
[Step=51200 Epoch=50.0] | Loss=0.01067 | Reg=0.00158 | acc=1.0000 | L2-Norm=12.588 | L2-Norm(final)=8.352 | 3927.0 samples/s | 61.4 steps/s
[Step=51250 Epoch=50.0] | Loss=0.01072 | Reg=0.00159 | acc=0.9844 | L2-Norm=12.594 | L2-Norm(final)=8.355 | 3939.2 samples/s | 61.5 steps/s
[Step=51300 Epoch=50.1] | Loss=0.01068 | Reg=0.00159 | acc=0.9844 | L2-Norm=12.600 | L2-Norm(final)=8.360 | 3956.4 samples/s | 61.8 steps/s
[Step=51350 Epoch=50.1] | Loss=0.01074 | Reg=0.00159 | acc=0.9844 | L2-Norm=12.606 | L2-Norm(final)=8.363 | 3945.4 samples/s | 61.6 steps/s
[Step=51400 Epoch=50.2] | Loss=0.01076 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.611 | L2-Norm(final)=8.367 | 3935.3 samples/s | 61.5 steps/s
[Step=51450 Epoch=50.2] | Loss=0.01101 | Reg=0.00159 | acc=0.9688 | L2-Norm=12.617 | L2-Norm(final)=8.370 | 3940.5 samples/s | 61.6 steps/s
[Step=51500 Epoch=50.3] | Loss=0.01116 | Reg=0.00159 | acc=0.9844 | L2-Norm=12.623 | L2-Norm(final)=8.373 | 4241.8 samples/s | 66.3 steps/s
[Step=51550 Epoch=50.3] | Loss=0.01114 | Reg=0.00159 | acc=1.0000 | L2-Norm=12.628 | L2-Norm(final)=8.376 | 1671.1 samples/s | 26.1 steps/s
[Step=51600 Epoch=50.4] | Loss=0.01109 | Reg=0.00160 | acc=0.9688 | L2-Norm=12.634 | L2-Norm(final)=8.379 | 3967.0 samples/s | 62.0 steps/s
[Step=51650 Epoch=50.4] | Loss=0.01098 | Reg=0.00160 | acc=0.9844 | L2-Norm=12.639 | L2-Norm(final)=8.382 | 3920.3 samples/s | 61.3 steps/s
[Step=51700 Epoch=50.5] | Loss=0.01098 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.645 | L2-Norm(final)=8.385 | 3890.5 samples/s | 60.8 steps/s
[Step=51750 Epoch=50.5] | Loss=0.01105 | Reg=0.00160 | acc=0.9844 | L2-Norm=12.650 | L2-Norm(final)=8.388 | 3923.9 samples/s | 61.3 steps/s
[Step=51800 Epoch=50.6] | Loss=0.01097 | Reg=0.00160 | acc=0.9844 | L2-Norm=12.655 | L2-Norm(final)=8.391 | 3923.5 samples/s | 61.3 steps/s
[Step=51850 Epoch=50.6] | Loss=0.01094 | Reg=0.00160 | acc=0.9844 | L2-Norm=12.660 | L2-Norm(final)=8.394 | 3930.0 samples/s | 61.4 steps/s
[Step=51900 Epoch=50.7] | Loss=0.01102 | Reg=0.00160 | acc=1.0000 | L2-Norm=12.665 | L2-Norm(final)=8.396 | 3947.3 samples/s | 61.7 steps/s
[Step=51950 Epoch=50.7] | Loss=0.01097 | Reg=0.00161 | acc=0.9688 | L2-Norm=12.670 | L2-Norm(final)=8.399 | 3897.6 samples/s | 60.9 steps/s
[Step=52000 Epoch=50.8] | Loss=0.01095 | Reg=0.00161 | acc=0.9844 | L2-Norm=12.675 | L2-Norm(final)=8.402 | 3885.1 samples/s | 60.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step52000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=50001 Epoch=94.3] | Loss=0.00007 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.411 | L2-Norm(final)=5.624 | 3241.0 samples/s | 50.6 steps/s
[Step=50050 Epoch=94.3] | Loss=0.00009 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.404 | L2-Norm(final)=5.632 | 3975.6 samples/s | 62.1 steps/s
[Step=50100 Epoch=94.4] | Loss=0.00006 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.408 | L2-Norm(final)=5.641 | 3991.6 samples/s | 62.4 steps/s
[Step=50150 Epoch=94.5] | Loss=0.00005 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.406 | L2-Norm(final)=5.647 | 4115.2 samples/s | 64.3 steps/s
[Step=50200 Epoch=94.6] | Loss=0.00004 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.402 | L2-Norm(final)=5.653 | 4064.5 samples/s | 63.5 steps/s
[Step=50250 Epoch=94.7] | Loss=0.00004 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.398 | L2-Norm(final)=5.659 | 4146.2 samples/s | 64.8 steps/s
[Step=50300 Epoch=94.8] | Loss=0.00003 | Reg=0.00154 | acc=1.0000 | L2-Norm=12.393 | L2-Norm(final)=5.665 | 4073.7 samples/s | 63.7 steps/s
[Step=50350 Epoch=94.9] | Loss=0.00003 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.388 | L2-Norm(final)=5.671 | 4028.3 samples/s | 62.9 steps/s
[Step=50400 Epoch=95.0] | Loss=0.00003 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.383 | L2-Norm(final)=5.677 | 4204.1 samples/s | 65.7 steps/s
[Step=50450 Epoch=95.1] | Loss=0.00003 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.378 | L2-Norm(final)=5.682 | 4058.4 samples/s | 63.4 steps/s
[Step=50500 Epoch=95.2] | Loss=0.00003 | Reg=0.00153 | acc=1.0000 | L2-Norm=12.373 | L2-Norm(final)=5.687 | 4100.1 samples/s | 64.1 steps/s
All layers training...
LR=0.00025, len=1
[Step=50501 Epoch=95.2] | Loss=0.00001 | Reg=0.00152 | acc=1.0000 | L2-Norm=12.320 | L2-Norm(final)=5.743 | 3424.5 samples/s | 53.5 steps/s
[Step=50550 Epoch=95.3] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.305 | L2-Norm(final)=5.746 | 3348.3 samples/s | 52.3 steps/s
[Step=50600 Epoch=95.4] | Loss=0.00001 | Reg=0.00151 | acc=1.0000 | L2-Norm=12.283 | L2-Norm(final)=5.751 | 3688.0 samples/s | 57.6 steps/s
[Step=50650 Epoch=95.5] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.261 | L2-Norm(final)=5.754 | 3722.6 samples/s | 58.2 steps/s
[Step=50700 Epoch=95.6] | Loss=0.00001 | Reg=0.00150 | acc=1.0000 | L2-Norm=12.238 | L2-Norm(final)=5.757 | 3737.8 samples/s | 58.4 steps/s
[Step=50750 Epoch=95.7] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.216 | L2-Norm(final)=5.759 | 3685.8 samples/s | 57.6 steps/s
[Step=50800 Epoch=95.8] | Loss=0.00001 | Reg=0.00149 | acc=1.0000 | L2-Norm=12.193 | L2-Norm(final)=5.761 | 3671.7 samples/s | 57.4 steps/s
[Step=50850 Epoch=95.9] | Loss=0.00001 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.170 | L2-Norm(final)=5.763 | 3696.7 samples/s | 57.8 steps/s
[Step=50900 Epoch=95.9] | Loss=0.00000 | Reg=0.00148 | acc=1.0000 | L2-Norm=12.146 | L2-Norm(final)=5.765 | 3712.4 samples/s | 58.0 steps/s
[Step=50950 Epoch=96.0] | Loss=0.00000 | Reg=0.00147 | acc=1.0000 | L2-Norm=12.123 | L2-Norm(final)=5.768 | 3706.2 samples/s | 57.9 steps/s
[Step=51000 Epoch=96.1] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.100 | L2-Norm(final)=5.770 | 3790.7 samples/s | 59.2 steps/s
[Step=51050 Epoch=96.2] | Loss=0.00000 | Reg=0.00146 | acc=1.0000 | L2-Norm=12.076 | L2-Norm(final)=5.772 | 1652.3 samples/s | 25.8 steps/s
[Step=51100 Epoch=96.3] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.052 | L2-Norm(final)=5.774 | 3742.7 samples/s | 58.5 steps/s
[Step=51150 Epoch=96.4] | Loss=0.00000 | Reg=0.00145 | acc=1.0000 | L2-Norm=12.029 | L2-Norm(final)=5.776 | 3678.3 samples/s | 57.5 steps/s
[Step=51200 Epoch=96.5] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.004 | L2-Norm(final)=5.778 | 3672.8 samples/s | 57.4 steps/s
[Step=51250 Epoch=96.6] | Loss=0.00000 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.980 | L2-Norm(final)=5.779 | 3680.5 samples/s | 57.5 steps/s
[Step=51300 Epoch=96.7] | Loss=0.00000 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.955 | L2-Norm(final)=5.781 | 3748.3 samples/s | 58.6 steps/s
[Step=51350 Epoch=96.8] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.931 | L2-Norm(final)=5.783 | 3711.0 samples/s | 58.0 steps/s
[Step=51400 Epoch=96.9] | Loss=0.00000 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.906 | L2-Norm(final)=5.785 | 3786.9 samples/s | 59.2 steps/s
[Step=51450 Epoch=97.0] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.881 | L2-Norm(final)=5.787 | 3690.1 samples/s | 57.7 steps/s
[Step=51500 Epoch=97.1] | Loss=0.00000 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.856 | L2-Norm(final)=5.789 | 3726.2 samples/s | 58.2 steps/s
[Step=51550 Epoch=97.2] | Loss=0.00000 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.830 | L2-Norm(final)=5.790 | 4615.3 samples/s | 72.1 steps/s
[Step=51600 Epoch=97.3] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.805 | L2-Norm(final)=5.792 | 1535.8 samples/s | 24.0 steps/s
[Step=51650 Epoch=97.4] | Loss=0.00000 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.779 | L2-Norm(final)=5.794 | 3740.0 samples/s | 58.4 steps/s
[Step=51700 Epoch=97.5] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.753 | L2-Norm(final)=5.796 | 3636.6 samples/s | 56.8 steps/s
[Step=51750 Epoch=97.5] | Loss=0.00000 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.727 | L2-Norm(final)=5.798 | 3705.3 samples/s | 57.9 steps/s
[Step=51800 Epoch=97.6] | Loss=0.00000 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.701 | L2-Norm(final)=5.800 | 3732.4 samples/s | 58.3 steps/s
[Step=51850 Epoch=97.7] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.675 | L2-Norm(final)=5.802 | 3722.9 samples/s | 58.2 steps/s
[Step=51900 Epoch=97.8] | Loss=0.00000 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.648 | L2-Norm(final)=5.804 | 3735.8 samples/s | 58.4 steps/s
[Step=51950 Epoch=97.9] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.621 | L2-Norm(final)=5.807 | 3685.7 samples/s | 57.6 steps/s
[Step=52000 Epoch=98.0] | Loss=0.00000 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.594 | L2-Norm(final)=5.809 | 3740.9 samples/s | 58.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step52000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05903 | acc=0.9715 | tpr=0.9752 | fpr=0.0367 | 3719.9 samples/s | 14.5 steps/s
Avg test loss: 0.05872, Avg test acc: 0.97083, Avg tpr: 0.97435, Avg fpr: 0.03692, total FA: 288

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.12381 | acc=0.2997 | tpr=0.0227 | fpr=0.0989 | 3614.5 samples/s | 14.1 steps/s
Avg test loss: 5.11532, Avg test acc: 0.29850, Avg tpr: 0.02384, Avg fpr: 0.09742, total FA: 760

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.41168 | acc=0.1370 | tpr=0.6947 | fpr=0.8731 | 3653.8 samples/s | 14.3 steps/s
[Step= 100] | Loss=5.40265 | acc=0.1391 | tpr=0.6908 | fpr=0.8712 | 6808.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=5.40310 | acc=0.1371 | tpr=0.6974 | fpr=0.8733 | 6889.2 samples/s | 26.9 steps/s
[Step= 200] | Loss=5.38322 | acc=0.1372 | tpr=0.6885 | fpr=0.8728 | 6749.6 samples/s | 26.4 steps/s
[Step= 250] | Loss=5.38616 | acc=0.1378 | tpr=0.6917 | fpr=0.8723 | 6909.1 samples/s | 27.0 steps/s
[Step= 300] | Loss=5.38354 | acc=0.1381 | tpr=0.6916 | fpr=0.8720 | 6821.9 samples/s | 26.6 steps/s
[Step= 350] | Loss=5.38194 | acc=0.1376 | tpr=0.6944 | fpr=0.8725 | 6989.8 samples/s | 27.3 steps/s
[Step= 400] | Loss=5.38825 | acc=0.1376 | tpr=0.6871 | fpr=0.8724 | 6785.3 samples/s | 26.5 steps/s
[Step= 450] | Loss=5.38818 | acc=0.1376 | tpr=0.6874 | fpr=0.8723 | 6630.0 samples/s | 25.9 steps/s
[Step= 500] | Loss=5.38949 | acc=0.1378 | tpr=0.6916 | fpr=0.8722 | 6835.9 samples/s | 26.7 steps/s
[Step= 550] | Loss=5.38998 | acc=0.1379 | tpr=0.6980 | fpr=0.8722 | 12507.3 samples/s | 48.9 steps/s
Avg test loss: 5.39099, Avg test acc: 0.13791, Avg tpr: 0.69849, Avg fpr: 0.87228, total FA: 121114

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11578 | acc=0.9800 | tpr=0.9602 | fpr=0.0196 | 3645.3 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.12196 | acc=0.9794 | tpr=0.9659 | fpr=0.0204 | 6869.0 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.12333 | acc=0.9788 | tpr=0.9654 | fpr=0.0210 | 6871.4 samples/s | 26.8 steps/s
[Step= 200] | Loss=0.12530 | acc=0.9788 | tpr=0.9694 | fpr=0.0210 | 7045.9 samples/s | 27.5 steps/s
[Step= 250] | Loss=0.12378 | acc=0.9789 | tpr=0.9677 | fpr=0.0209 | 6692.0 samples/s | 26.1 steps/s
[Step= 300] | Loss=0.12600 | acc=0.9785 | tpr=0.9651 | fpr=0.0213 | 7037.0 samples/s | 27.5 steps/s
[Step= 350] | Loss=0.12583 | acc=0.9783 | tpr=0.9662 | fpr=0.0214 | 7014.6 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.12623 | acc=0.9780 | tpr=0.9650 | fpr=0.0217 | 6539.6 samples/s | 25.5 steps/s
[Step= 450] | Loss=0.12903 | acc=0.9777 | tpr=0.9625 | fpr=0.0220 | 6944.6 samples/s | 27.1 steps/s
[Step= 500] | Loss=0.12853 | acc=0.9777 | tpr=0.9626 | fpr=0.0220 | 6847.5 samples/s | 26.7 steps/s
[Step= 550] | Loss=0.12756 | acc=0.9780 | tpr=0.9626 | fpr=0.0217 | 11939.2 samples/s | 46.6 steps/s
Avg test loss: 0.12726, Avg test acc: 0.97803, Avg tpr: 0.96276, Avg fpr: 0.02169, total FA: 3012

server round 26/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=50.8] | Loss=0.02255 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.705 | L2-Norm(final)=8.477 | 3577.7 samples/s | 55.9 steps/s
[Step=52050 Epoch=50.8] | Loss=0.01048 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.720 | L2-Norm(final)=8.482 | 3735.9 samples/s | 58.4 steps/s
[Step=52100 Epoch=50.9] | Loss=0.00961 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.728 | L2-Norm(final)=8.493 | 4314.5 samples/s | 67.4 steps/s
[Step=52150 Epoch=50.9] | Loss=0.00892 | Reg=0.00138 | acc=0.9844 | L2-Norm=11.733 | L2-Norm(final)=8.505 | 4302.0 samples/s | 67.2 steps/s
[Step=52200 Epoch=51.0] | Loss=0.00894 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.738 | L2-Norm(final)=8.515 | 4353.0 samples/s | 68.0 steps/s
[Step=52250 Epoch=51.0] | Loss=0.00905 | Reg=0.00138 | acc=0.9688 | L2-Norm=11.744 | L2-Norm(final)=8.524 | 4331.4 samples/s | 67.7 steps/s
[Step=52300 Epoch=51.1] | Loss=0.00918 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.749 | L2-Norm(final)=8.533 | 4305.1 samples/s | 67.3 steps/s
[Step=52350 Epoch=51.1] | Loss=0.00919 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.753 | L2-Norm(final)=8.541 | 4345.9 samples/s | 67.9 steps/s
[Step=52400 Epoch=51.2] | Loss=0.00920 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.758 | L2-Norm(final)=8.549 | 4350.8 samples/s | 68.0 steps/s
[Step=52450 Epoch=51.2] | Loss=0.00912 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.763 | L2-Norm(final)=8.557 | 4332.5 samples/s | 67.7 steps/s
[Step=52500 Epoch=51.3] | Loss=0.00920 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.768 | L2-Norm(final)=8.565 | 4253.0 samples/s | 66.5 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=51.3] | Loss=0.00164 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.816 | L2-Norm(final)=8.643 | 3259.8 samples/s | 50.9 steps/s
[Step=52550 Epoch=51.3] | Loss=0.00969 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.821 | L2-Norm(final)=8.649 | 3827.7 samples/s | 59.8 steps/s
[Step=52600 Epoch=51.4] | Loss=0.01199 | Reg=0.00140 | acc=0.9688 | L2-Norm=11.828 | L2-Norm(final)=8.654 | 3876.8 samples/s | 60.6 steps/s
[Step=52650 Epoch=51.4] | Loss=0.01230 | Reg=0.00140 | acc=0.9844 | L2-Norm=11.837 | L2-Norm(final)=8.657 | 3947.2 samples/s | 61.7 steps/s
[Step=52700 Epoch=51.5] | Loss=0.01245 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.845 | L2-Norm(final)=8.660 | 3894.0 samples/s | 60.8 steps/s
[Step=52750 Epoch=51.5] | Loss=0.01179 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.854 | L2-Norm(final)=8.666 | 3864.4 samples/s | 60.4 steps/s
[Step=52800 Epoch=51.6] | Loss=0.01173 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.862 | L2-Norm(final)=8.671 | 3900.4 samples/s | 60.9 steps/s
[Step=52850 Epoch=51.6] | Loss=0.01153 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.869 | L2-Norm(final)=8.676 | 3925.8 samples/s | 61.3 steps/s
[Step=52900 Epoch=51.6] | Loss=0.01171 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.877 | L2-Norm(final)=8.681 | 3951.5 samples/s | 61.7 steps/s
[Step=52950 Epoch=51.7] | Loss=0.01186 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.884 | L2-Norm(final)=8.687 | 3932.0 samples/s | 61.4 steps/s
[Step=53000 Epoch=51.7] | Loss=0.01175 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.892 | L2-Norm(final)=8.691 | 3843.2 samples/s | 60.0 steps/s
[Step=53050 Epoch=51.8] | Loss=0.01190 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.898 | L2-Norm(final)=8.696 | 3894.9 samples/s | 60.9 steps/s
[Step=53100 Epoch=51.8] | Loss=0.01197 | Reg=0.00142 | acc=0.9844 | L2-Norm=11.906 | L2-Norm(final)=8.700 | 3968.4 samples/s | 62.0 steps/s
[Step=53150 Epoch=51.9] | Loss=0.01186 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.913 | L2-Norm(final)=8.705 | 3913.8 samples/s | 61.2 steps/s
[Step=53200 Epoch=51.9] | Loss=0.01174 | Reg=0.00142 | acc=0.9688 | L2-Norm=11.919 | L2-Norm(final)=8.710 | 3926.3 samples/s | 61.3 steps/s
[Step=53250 Epoch=52.0] | Loss=0.01144 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.926 | L2-Norm(final)=8.715 | 3901.6 samples/s | 61.0 steps/s
[Step=53300 Epoch=52.0] | Loss=0.01151 | Reg=0.00142 | acc=1.0000 | L2-Norm=11.933 | L2-Norm(final)=8.720 | 3909.3 samples/s | 61.1 steps/s
[Step=53350 Epoch=52.1] | Loss=0.01145 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.939 | L2-Norm(final)=8.725 | 3951.3 samples/s | 61.7 steps/s
[Step=53400 Epoch=52.1] | Loss=0.01157 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.946 | L2-Norm(final)=8.730 | 3967.1 samples/s | 62.0 steps/s
[Step=53450 Epoch=52.2] | Loss=0.01158 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.953 | L2-Norm(final)=8.734 | 3943.7 samples/s | 61.6 steps/s
[Step=53500 Epoch=52.2] | Loss=0.01148 | Reg=0.00143 | acc=1.0000 | L2-Norm=11.959 | L2-Norm(final)=8.738 | 4193.8 samples/s | 65.5 steps/s
[Step=53550 Epoch=52.3] | Loss=0.01151 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.966 | L2-Norm(final)=8.743 | 1648.0 samples/s | 25.7 steps/s
[Step=53600 Epoch=52.3] | Loss=0.01147 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.972 | L2-Norm(final)=8.747 | 3912.5 samples/s | 61.1 steps/s
[Step=53650 Epoch=52.4] | Loss=0.01136 | Reg=0.00143 | acc=0.9844 | L2-Norm=11.978 | L2-Norm(final)=8.751 | 3846.5 samples/s | 60.1 steps/s
[Step=53700 Epoch=52.4] | Loss=0.01136 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.984 | L2-Norm(final)=8.755 | 3897.9 samples/s | 60.9 steps/s
[Step=53750 Epoch=52.5] | Loss=0.01132 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.990 | L2-Norm(final)=8.758 | 3912.6 samples/s | 61.1 steps/s
[Step=53800 Epoch=52.5] | Loss=0.01127 | Reg=0.00144 | acc=1.0000 | L2-Norm=11.996 | L2-Norm(final)=8.762 | 3947.9 samples/s | 61.7 steps/s
[Step=53850 Epoch=52.6] | Loss=0.01122 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.001 | L2-Norm(final)=8.766 | 3871.1 samples/s | 60.5 steps/s
[Step=53900 Epoch=52.6] | Loss=0.01119 | Reg=0.00144 | acc=0.9844 | L2-Norm=12.007 | L2-Norm(final)=8.770 | 3926.7 samples/s | 61.4 steps/s
[Step=53950 Epoch=52.7] | Loss=0.01111 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.012 | L2-Norm(final)=8.774 | 3919.1 samples/s | 61.2 steps/s
[Step=54000 Epoch=52.7] | Loss=0.01107 | Reg=0.00144 | acc=1.0000 | L2-Norm=12.017 | L2-Norm(final)=8.778 | 3999.4 samples/s | 62.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step54000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=52001 Epoch=98.0] | Loss=0.00013 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.705 | L2-Norm(final)=5.877 | 3546.4 samples/s | 55.4 steps/s
[Step=52050 Epoch=98.1] | Loss=0.00004 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.690 | L2-Norm(final)=5.896 | 3688.1 samples/s | 57.6 steps/s
[Step=52100 Epoch=98.2] | Loss=0.00003 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.685 | L2-Norm(final)=5.913 | 4121.7 samples/s | 64.4 steps/s
[Step=52150 Epoch=98.3] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.678 | L2-Norm(final)=5.926 | 4088.2 samples/s | 63.9 steps/s
[Step=52200 Epoch=98.4] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.670 | L2-Norm(final)=5.937 | 4100.0 samples/s | 64.1 steps/s
[Step=52250 Epoch=98.5] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.663 | L2-Norm(final)=5.948 | 4088.0 samples/s | 63.9 steps/s
[Step=52300 Epoch=98.6] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.658 | L2-Norm(final)=5.959 | 4120.1 samples/s | 64.4 steps/s
[Step=52350 Epoch=98.7] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.654 | L2-Norm(final)=5.969 | 4078.3 samples/s | 63.7 steps/s
[Step=52400 Epoch=98.8] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.649 | L2-Norm(final)=5.978 | 4072.7 samples/s | 63.6 steps/s
[Step=52450 Epoch=98.9] | Loss=0.00002 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.643 | L2-Norm(final)=5.986 | 4179.9 samples/s | 65.3 steps/s
[Step=52500 Epoch=99.0] | Loss=0.00002 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.636 | L2-Norm(final)=5.993 | 4106.2 samples/s | 64.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=52501 Epoch=99.0] | Loss=0.00000 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.568 | L2-Norm(final)=6.067 | 3306.2 samples/s | 51.7 steps/s
[Step=52550 Epoch=99.1] | Loss=0.00001 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.534 | L2-Norm(final)=6.072 | 3340.5 samples/s | 52.2 steps/s
[Step=52600 Epoch=99.2] | Loss=0.00000 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.489 | L2-Norm(final)=6.076 | 3750.6 samples/s | 58.6 steps/s
[Step=52650 Epoch=99.2] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.444 | L2-Norm(final)=6.081 | 3715.2 samples/s | 58.0 steps/s
[Step=52700 Epoch=99.3] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.400 | L2-Norm(final)=6.086 | 3712.2 samples/s | 58.0 steps/s
[Step=52750 Epoch=99.4] | Loss=0.00000 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.355 | L2-Norm(final)=6.090 | 3645.2 samples/s | 57.0 steps/s
[Step=52800 Epoch=99.5] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.310 | L2-Norm(final)=6.094 | 3704.8 samples/s | 57.9 steps/s
[Step=52850 Epoch=99.6] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.265 | L2-Norm(final)=6.098 | 3744.7 samples/s | 58.5 steps/s
[Step=52900 Epoch=99.7] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.221 | L2-Norm(final)=6.102 | 3744.0 samples/s | 58.5 steps/s
[Step=52950 Epoch=99.8] | Loss=0.00057 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.193 | L2-Norm(final)=6.104 | 3749.6 samples/s | 58.6 steps/s
[Step=53000 Epoch=99.9] | Loss=0.00065 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.183 | L2-Norm(final)=6.103 | 3779.0 samples/s | 59.0 steps/s
[Step=53050 Epoch=100.0] | Loss=0.00064 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.175 | L2-Norm(final)=6.102 | 1671.0 samples/s | 26.1 steps/s
[Step=53100 Epoch=100.1] | Loss=0.00060 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.169 | L2-Norm(final)=6.102 | 3754.8 samples/s | 58.7 steps/s
[Step=53150 Epoch=100.2] | Loss=0.00056 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.163 | L2-Norm(final)=6.101 | 3624.0 samples/s | 56.6 steps/s
[Step=53200 Epoch=100.3] | Loss=0.00053 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.158 | L2-Norm(final)=6.101 | 3754.3 samples/s | 58.7 steps/s
[Step=53250 Epoch=100.4] | Loss=0.00050 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.154 | L2-Norm(final)=6.102 | 3684.7 samples/s | 57.6 steps/s
[Step=53300 Epoch=100.5] | Loss=0.00048 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.150 | L2-Norm(final)=6.102 | 3703.6 samples/s | 57.9 steps/s
[Step=53350 Epoch=100.6] | Loss=0.00046 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.147 | L2-Norm(final)=6.103 | 3678.9 samples/s | 57.5 steps/s
[Step=53400 Epoch=100.7] | Loss=0.00044 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.143 | L2-Norm(final)=6.103 | 3755.3 samples/s | 58.7 steps/s
[Step=53450 Epoch=100.8] | Loss=0.00042 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.140 | L2-Norm(final)=6.104 | 3747.0 samples/s | 58.5 steps/s
[Step=53500 Epoch=100.8] | Loss=0.00040 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.137 | L2-Norm(final)=6.104 | 3699.0 samples/s | 57.8 steps/s
[Step=53550 Epoch=100.9] | Loss=0.00039 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.134 | L2-Norm(final)=6.105 | 4666.6 samples/s | 72.9 steps/s
[Step=53600 Epoch=101.0] | Loss=0.00038 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.132 | L2-Norm(final)=6.106 | 1490.0 samples/s | 23.3 steps/s
[Step=53650 Epoch=101.1] | Loss=0.00037 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.130 | L2-Norm(final)=6.106 | 3703.3 samples/s | 57.9 steps/s
[Step=53700 Epoch=101.2] | Loss=0.00035 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.128 | L2-Norm(final)=6.107 | 3717.4 samples/s | 58.1 steps/s
[Step=53750 Epoch=101.3] | Loss=0.00034 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.126 | L2-Norm(final)=6.107 | 3747.3 samples/s | 58.6 steps/s
[Step=53800 Epoch=101.4] | Loss=0.00033 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.124 | L2-Norm(final)=6.108 | 3705.2 samples/s | 57.9 steps/s
[Step=53850 Epoch=101.5] | Loss=0.00031 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.122 | L2-Norm(final)=6.108 | 3736.2 samples/s | 58.4 steps/s
[Step=53900 Epoch=101.6] | Loss=0.00030 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.120 | L2-Norm(final)=6.109 | 3742.6 samples/s | 58.5 steps/s
[Step=53950 Epoch=101.7] | Loss=0.00029 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.117 | L2-Norm(final)=6.109 | 3777.5 samples/s | 59.0 steps/s
[Step=54000 Epoch=101.8] | Loss=0.00028 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.115 | L2-Norm(final)=6.110 | 3715.5 samples/s | 58.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step54000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05858 | acc=0.9708 | tpr=0.9731 | fpr=0.0342 | 3612.4 samples/s | 14.1 steps/s
Avg test loss: 0.05944, Avg test acc: 0.96959, Avg tpr: 0.97167, Avg fpr: 0.03500, total FA: 273

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.40658 | acc=0.3152 | tpr=0.0094 | fpr=0.0208 | 3621.9 samples/s | 14.1 steps/s
Avg test loss: 5.41557, Avg test acc: 0.31228, Avg tpr: 0.00927, Avg fpr: 0.02128, total FA: 166

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.77427 | acc=0.1594 | tpr=0.7301 | fpr=0.8509 | 3599.8 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.76864 | acc=0.1622 | tpr=0.7058 | fpr=0.8479 | 6948.3 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.76665 | acc=0.1608 | tpr=0.7046 | fpr=0.8492 | 6831.4 samples/s | 26.7 steps/s
[Step= 200] | Loss=4.74605 | acc=0.1608 | tpr=0.6995 | fpr=0.8490 | 6946.5 samples/s | 27.1 steps/s
[Step= 250] | Loss=4.74989 | acc=0.1606 | tpr=0.7013 | fpr=0.8492 | 6705.6 samples/s | 26.2 steps/s
[Step= 300] | Loss=4.74947 | acc=0.1612 | tpr=0.6975 | fpr=0.8486 | 6839.1 samples/s | 26.7 steps/s
[Step= 350] | Loss=4.74882 | acc=0.1611 | tpr=0.6982 | fpr=0.8487 | 6733.2 samples/s | 26.3 steps/s
[Step= 400] | Loss=4.75487 | acc=0.1609 | tpr=0.6964 | fpr=0.8488 | 6903.5 samples/s | 27.0 steps/s
[Step= 450] | Loss=4.75524 | acc=0.1611 | tpr=0.6996 | fpr=0.8487 | 6547.9 samples/s | 25.6 steps/s
[Step= 500] | Loss=4.75664 | acc=0.1611 | tpr=0.7040 | fpr=0.8487 | 6804.2 samples/s | 26.6 steps/s
[Step= 550] | Loss=4.75719 | acc=0.1613 | tpr=0.7075 | fpr=0.8486 | 12156.1 samples/s | 47.5 steps/s
Avg test loss: 4.75801, Avg test acc: 0.16126, Avg tpr: 0.70800, Avg fpr: 0.84868, total FA: 117838

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09921 | acc=0.9820 | tpr=0.9469 | fpr=0.0173 | 3591.2 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.10445 | acc=0.9811 | tpr=0.9595 | fpr=0.0185 | 6853.4 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.10663 | acc=0.9800 | tpr=0.9582 | fpr=0.0196 | 7011.4 samples/s | 27.4 steps/s
[Step= 200] | Loss=0.10786 | acc=0.9802 | tpr=0.9607 | fpr=0.0195 | 6662.3 samples/s | 26.0 steps/s
[Step= 250] | Loss=0.10664 | acc=0.9803 | tpr=0.9581 | fpr=0.0193 | 6875.8 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.10858 | acc=0.9797 | tpr=0.9564 | fpr=0.0198 | 6775.1 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.10938 | acc=0.9795 | tpr=0.9574 | fpr=0.0201 | 6890.9 samples/s | 26.9 steps/s
[Step= 400] | Loss=0.10997 | acc=0.9793 | tpr=0.9568 | fpr=0.0203 | 6752.5 samples/s | 26.4 steps/s
[Step= 450] | Loss=0.11280 | acc=0.9789 | tpr=0.9547 | fpr=0.0207 | 7047.4 samples/s | 27.5 steps/s
[Step= 500] | Loss=0.11249 | acc=0.9789 | tpr=0.9555 | fpr=0.0207 | 6641.5 samples/s | 25.9 steps/s
[Step= 550] | Loss=0.11170 | acc=0.9790 | tpr=0.9550 | fpr=0.0205 | 12820.3 samples/s | 50.1 steps/s
Avg test loss: 0.11138, Avg test acc: 0.97908, Avg tpr: 0.95523, Avg fpr: 0.02049, total FA: 2845

server round 27/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=52.7] | Loss=0.02018 | Reg=0.00132 | acc=0.9844 | L2-Norm=11.475 | L2-Norm(final)=8.891 | 3298.6 samples/s | 51.5 steps/s
[Step=54050 Epoch=52.8] | Loss=0.01611 | Reg=0.00132 | acc=0.9531 | L2-Norm=11.496 | L2-Norm(final)=8.912 | 4120.0 samples/s | 64.4 steps/s
[Step=54100 Epoch=52.8] | Loss=0.01834 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.513 | L2-Norm(final)=8.932 | 4306.1 samples/s | 67.3 steps/s
[Step=54150 Epoch=52.9] | Loss=0.01812 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.526 | L2-Norm(final)=8.950 | 4316.1 samples/s | 67.4 steps/s
[Step=54200 Epoch=52.9] | Loss=0.01804 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=8.966 | 4316.4 samples/s | 67.4 steps/s
[Step=54250 Epoch=53.0] | Loss=0.01751 | Reg=0.00133 | acc=0.9688 | L2-Norm=11.548 | L2-Norm(final)=8.980 | 4366.7 samples/s | 68.2 steps/s
[Step=54300 Epoch=53.0] | Loss=0.01700 | Reg=0.00134 | acc=0.9688 | L2-Norm=11.559 | L2-Norm(final)=8.995 | 4291.7 samples/s | 67.1 steps/s
[Step=54350 Epoch=53.1] | Loss=0.01711 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.569 | L2-Norm(final)=9.010 | 4342.7 samples/s | 67.9 steps/s
[Step=54400 Epoch=53.1] | Loss=0.01689 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.579 | L2-Norm(final)=9.022 | 4348.1 samples/s | 67.9 steps/s
[Step=54450 Epoch=53.2] | Loss=0.01621 | Reg=0.00134 | acc=0.9844 | L2-Norm=11.588 | L2-Norm(final)=9.035 | 4292.0 samples/s | 67.1 steps/s
[Step=54500 Epoch=53.2] | Loss=0.01602 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.597 | L2-Norm(final)=9.046 | 4343.4 samples/s | 67.9 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=53.2] | Loss=0.01493 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.682 | L2-Norm(final)=9.163 | 3309.0 samples/s | 51.7 steps/s
[Step=54550 Epoch=53.3] | Loss=0.01274 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.693 | L2-Norm(final)=9.173 | 3739.3 samples/s | 58.4 steps/s
[Step=54600 Epoch=53.3] | Loss=0.01240 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.705 | L2-Norm(final)=9.179 | 3862.7 samples/s | 60.4 steps/s
[Step=54650 Epoch=53.4] | Loss=0.01326 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.715 | L2-Norm(final)=9.183 | 3884.2 samples/s | 60.7 steps/s
[Step=54700 Epoch=53.4] | Loss=0.01310 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.724 | L2-Norm(final)=9.186 | 3964.1 samples/s | 61.9 steps/s
[Step=54750 Epoch=53.5] | Loss=0.01276 | Reg=0.00138 | acc=0.9844 | L2-Norm=11.733 | L2-Norm(final)=9.190 | 3919.0 samples/s | 61.2 steps/s
[Step=54800 Epoch=53.5] | Loss=0.01330 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.742 | L2-Norm(final)=9.193 | 3876.7 samples/s | 60.6 steps/s
[Step=54850 Epoch=53.6] | Loss=0.01352 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.750 | L2-Norm(final)=9.196 | 3920.8 samples/s | 61.3 steps/s
[Step=54900 Epoch=53.6] | Loss=0.01342 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.757 | L2-Norm(final)=9.199 | 3937.7 samples/s | 61.5 steps/s
[Step=54950 Epoch=53.6] | Loss=0.01331 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.763 | L2-Norm(final)=9.201 | 3985.4 samples/s | 62.3 steps/s
[Step=55000 Epoch=53.7] | Loss=0.01369 | Reg=0.00139 | acc=0.9531 | L2-Norm=11.770 | L2-Norm(final)=9.204 | 3939.4 samples/s | 61.6 steps/s
[Step=55050 Epoch=53.7] | Loss=0.01383 | Reg=0.00139 | acc=0.9844 | L2-Norm=11.776 | L2-Norm(final)=9.206 | 3869.5 samples/s | 60.5 steps/s
[Step=55100 Epoch=53.8] | Loss=0.01384 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.782 | L2-Norm(final)=9.209 | 3932.2 samples/s | 61.4 steps/s
[Step=55150 Epoch=53.8] | Loss=0.01368 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.788 | L2-Norm(final)=9.212 | 3917.8 samples/s | 61.2 steps/s
[Step=55200 Epoch=53.9] | Loss=0.01345 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.794 | L2-Norm(final)=9.215 | 3946.1 samples/s | 61.7 steps/s
[Step=55250 Epoch=53.9] | Loss=0.01337 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.800 | L2-Norm(final)=9.218 | 3910.7 samples/s | 61.1 steps/s
[Step=55300 Epoch=54.0] | Loss=0.01320 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.805 | L2-Norm(final)=9.221 | 3925.2 samples/s | 61.3 steps/s
[Step=55350 Epoch=54.0] | Loss=0.01307 | Reg=0.00139 | acc=0.9844 | L2-Norm=11.811 | L2-Norm(final)=9.224 | 3923.5 samples/s | 61.3 steps/s
[Step=55400 Epoch=54.1] | Loss=0.01319 | Reg=0.00140 | acc=0.9844 | L2-Norm=11.816 | L2-Norm(final)=9.227 | 3833.0 samples/s | 59.9 steps/s
[Step=55450 Epoch=54.1] | Loss=0.01319 | Reg=0.00140 | acc=0.9844 | L2-Norm=11.821 | L2-Norm(final)=9.230 | 3859.4 samples/s | 60.3 steps/s
[Step=55500 Epoch=54.2] | Loss=0.01302 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.826 | L2-Norm(final)=9.233 | 4167.6 samples/s | 65.1 steps/s
[Step=55550 Epoch=54.2] | Loss=0.01285 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.832 | L2-Norm(final)=9.236 | 1668.9 samples/s | 26.1 steps/s
[Step=55600 Epoch=54.3] | Loss=0.01267 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.837 | L2-Norm(final)=9.240 | 3865.0 samples/s | 60.4 steps/s
[Step=55650 Epoch=54.3] | Loss=0.01252 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.842 | L2-Norm(final)=9.243 | 3882.5 samples/s | 60.7 steps/s
[Step=55700 Epoch=54.4] | Loss=0.01233 | Reg=0.00140 | acc=0.9844 | L2-Norm=11.847 | L2-Norm(final)=9.247 | 3910.0 samples/s | 61.1 steps/s
[Step=55750 Epoch=54.4] | Loss=0.01228 | Reg=0.00140 | acc=1.0000 | L2-Norm=11.851 | L2-Norm(final)=9.250 | 3903.7 samples/s | 61.0 steps/s
[Step=55800 Epoch=54.5] | Loss=0.01211 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.856 | L2-Norm(final)=9.253 | 3936.6 samples/s | 61.5 steps/s
[Step=55850 Epoch=54.5] | Loss=0.01202 | Reg=0.00141 | acc=0.9688 | L2-Norm=11.861 | L2-Norm(final)=9.256 | 3945.3 samples/s | 61.6 steps/s
[Step=55900 Epoch=54.6] | Loss=0.01194 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.865 | L2-Norm(final)=9.260 | 3940.8 samples/s | 61.6 steps/s
[Step=55950 Epoch=54.6] | Loss=0.01189 | Reg=0.00141 | acc=1.0000 | L2-Norm=11.870 | L2-Norm(final)=9.263 | 3927.4 samples/s | 61.4 steps/s
[Step=56000 Epoch=54.7] | Loss=0.01188 | Reg=0.00141 | acc=0.9844 | L2-Norm=11.874 | L2-Norm(final)=9.266 | 3897.6 samples/s | 60.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step56000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=54001 Epoch=101.8] | Loss=0.00017 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.475 | L2-Norm(final)=6.127 | 3381.6 samples/s | 52.8 steps/s
[Step=54050 Epoch=101.9] | Loss=0.00005 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.468 | L2-Norm(final)=6.129 | 3856.7 samples/s | 60.3 steps/s
[Step=54100 Epoch=102.0] | Loss=0.00004 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.467 | L2-Norm(final)=6.132 | 4114.2 samples/s | 64.3 steps/s
[Step=54150 Epoch=102.1] | Loss=0.00004 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.466 | L2-Norm(final)=6.136 | 4073.7 samples/s | 63.7 steps/s
[Step=54200 Epoch=102.2] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.465 | L2-Norm(final)=6.139 | 4117.4 samples/s | 64.3 steps/s
[Step=54250 Epoch=102.3] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=6.142 | 4173.9 samples/s | 65.2 steps/s
[Step=54300 Epoch=102.4] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=6.146 | 4137.5 samples/s | 64.6 steps/s
[Step=54350 Epoch=102.5] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=6.150 | 4209.9 samples/s | 65.8 steps/s
[Step=54400 Epoch=102.5] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.464 | L2-Norm(final)=6.154 | 4065.8 samples/s | 63.5 steps/s
[Step=54450 Epoch=102.6] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.463 | L2-Norm(final)=6.157 | 4156.4 samples/s | 64.9 steps/s
[Step=54500 Epoch=102.7] | Loss=0.00003 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.462 | L2-Norm(final)=6.161 | 4212.4 samples/s | 65.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=54501 Epoch=102.7] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.452 | L2-Norm(final)=6.195 | 3126.3 samples/s | 48.8 steps/s
[Step=54550 Epoch=102.8] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.449 | L2-Norm(final)=6.198 | 3625.1 samples/s | 56.6 steps/s
[Step=54600 Epoch=102.9] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.445 | L2-Norm(final)=6.201 | 3714.2 samples/s | 58.0 steps/s
[Step=54650 Epoch=103.0] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.441 | L2-Norm(final)=6.204 | 3697.4 samples/s | 57.8 steps/s
[Step=54700 Epoch=103.1] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.437 | L2-Norm(final)=6.206 | 3695.1 samples/s | 57.7 steps/s
[Step=54750 Epoch=103.2] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.433 | L2-Norm(final)=6.208 | 3720.2 samples/s | 58.1 steps/s
[Step=54800 Epoch=103.3] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.429 | L2-Norm(final)=6.211 | 3715.4 samples/s | 58.1 steps/s
[Step=54850 Epoch=103.4] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.424 | L2-Norm(final)=6.213 | 3703.1 samples/s | 57.9 steps/s
[Step=54900 Epoch=103.5] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.420 | L2-Norm(final)=6.215 | 3702.8 samples/s | 57.9 steps/s
[Step=54950 Epoch=103.6] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.416 | L2-Norm(final)=6.217 | 3741.1 samples/s | 58.5 steps/s
[Step=55000 Epoch=103.7] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.412 | L2-Norm(final)=6.219 | 3727.3 samples/s | 58.2 steps/s
[Step=55050 Epoch=103.8] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.407 | L2-Norm(final)=6.221 | 1652.0 samples/s | 25.8 steps/s
[Step=55100 Epoch=103.9] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.403 | L2-Norm(final)=6.222 | 3754.4 samples/s | 58.7 steps/s
[Step=55150 Epoch=104.0] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.398 | L2-Norm(final)=6.224 | 3730.8 samples/s | 58.3 steps/s
[Step=55200 Epoch=104.1] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.394 | L2-Norm(final)=6.226 | 3690.7 samples/s | 57.7 steps/s
[Step=55250 Epoch=104.1] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.389 | L2-Norm(final)=6.228 | 3675.7 samples/s | 57.4 steps/s
[Step=55300 Epoch=104.2] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.385 | L2-Norm(final)=6.229 | 3689.7 samples/s | 57.7 steps/s
[Step=55350 Epoch=104.3] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.380 | L2-Norm(final)=6.231 | 3704.2 samples/s | 57.9 steps/s
[Step=55400 Epoch=104.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.375 | L2-Norm(final)=6.232 | 3742.6 samples/s | 58.5 steps/s
[Step=55450 Epoch=104.5] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.370 | L2-Norm(final)=6.234 | 3715.2 samples/s | 58.0 steps/s
[Step=55500 Epoch=104.6] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.366 | L2-Norm(final)=6.235 | 3753.7 samples/s | 58.7 steps/s
[Step=55550 Epoch=104.7] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.361 | L2-Norm(final)=6.237 | 4599.1 samples/s | 71.9 steps/s
[Step=55600 Epoch=104.8] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.356 | L2-Norm(final)=6.238 | 1524.7 samples/s | 23.8 steps/s
[Step=55650 Epoch=104.9] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.351 | L2-Norm(final)=6.240 | 3714.0 samples/s | 58.0 steps/s
[Step=55700 Epoch=105.0] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.346 | L2-Norm(final)=6.241 | 3691.7 samples/s | 57.7 steps/s
[Step=55750 Epoch=105.1] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.341 | L2-Norm(final)=6.243 | 3667.0 samples/s | 57.3 steps/s
[Step=55800 Epoch=105.2] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.336 | L2-Norm(final)=6.244 | 3710.3 samples/s | 58.0 steps/s
[Step=55850 Epoch=105.3] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.331 | L2-Norm(final)=6.246 | 3715.9 samples/s | 58.1 steps/s
[Step=55900 Epoch=105.4] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.326 | L2-Norm(final)=6.247 | 3694.8 samples/s | 57.7 steps/s
[Step=55950 Epoch=105.5] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=6.249 | 3713.5 samples/s | 58.0 steps/s
[Step=56000 Epoch=105.6] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.315 | L2-Norm(final)=6.250 | 3741.4 samples/s | 58.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step56000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05933 | acc=0.9694 | tpr=0.9735 | fpr=0.0396 | 3636.3 samples/s | 14.2 steps/s
Avg test loss: 0.06054, Avg test acc: 0.96871, Avg tpr: 0.97231, Avg fpr: 0.03923, total FA: 306

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.99291 | acc=0.3077 | tpr=0.0157 | fpr=0.0585 | 3613.7 samples/s | 14.1 steps/s
Avg test loss: 4.99119, Avg test acc: 0.30672, Avg tpr: 0.01708, Avg fpr: 0.05627, total FA: 439

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.57813 | acc=0.1638 | tpr=0.6947 | fpr=0.8458 | 3597.2 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.57613 | acc=0.1645 | tpr=0.6866 | fpr=0.8453 | 6822.3 samples/s | 26.6 steps/s
[Step= 150] | Loss=4.57070 | acc=0.1635 | tpr=0.6960 | fpr=0.8463 | 6856.2 samples/s | 26.8 steps/s
[Step= 200] | Loss=4.55337 | acc=0.1638 | tpr=0.6863 | fpr=0.8457 | 7020.5 samples/s | 27.4 steps/s
[Step= 250] | Loss=4.55533 | acc=0.1636 | tpr=0.6926 | fpr=0.8460 | 6824.7 samples/s | 26.7 steps/s
[Step= 300] | Loss=4.55501 | acc=0.1640 | tpr=0.6902 | fpr=0.8456 | 6653.3 samples/s | 26.0 steps/s
[Step= 350] | Loss=4.55397 | acc=0.1636 | tpr=0.6913 | fpr=0.8459 | 6871.4 samples/s | 26.8 steps/s
[Step= 400] | Loss=4.55982 | acc=0.1632 | tpr=0.6876 | fpr=0.8463 | 7039.7 samples/s | 27.5 steps/s
[Step= 450] | Loss=4.56081 | acc=0.1632 | tpr=0.6918 | fpr=0.8464 | 6716.5 samples/s | 26.2 steps/s
[Step= 500] | Loss=4.56095 | acc=0.1634 | tpr=0.6965 | fpr=0.8462 | 6748.5 samples/s | 26.4 steps/s
[Step= 550] | Loss=4.56112 | acc=0.1635 | tpr=0.7027 | fpr=0.8463 | 12536.2 samples/s | 49.0 steps/s
Avg test loss: 4.56215, Avg test acc: 0.16346, Avg tpr: 0.70285, Avg fpr: 0.84634, total FA: 117513

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10514 | acc=0.9810 | tpr=0.9558 | fpr=0.0185 | 3733.5 samples/s | 14.6 steps/s
[Step= 100] | Loss=0.11035 | acc=0.9804 | tpr=0.9616 | fpr=0.0193 | 6410.1 samples/s | 25.0 steps/s
[Step= 150] | Loss=0.11212 | acc=0.9796 | tpr=0.9625 | fpr=0.0201 | 6944.4 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.11394 | acc=0.9798 | tpr=0.9661 | fpr=0.0200 | 7001.6 samples/s | 27.3 steps/s
[Step= 250] | Loss=0.11272 | acc=0.9800 | tpr=0.9651 | fpr=0.0197 | 6763.6 samples/s | 26.4 steps/s
[Step= 300] | Loss=0.11477 | acc=0.9796 | tpr=0.9622 | fpr=0.0201 | 6827.5 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.11519 | acc=0.9794 | tpr=0.9631 | fpr=0.0203 | 7019.2 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.11566 | acc=0.9790 | tpr=0.9628 | fpr=0.0207 | 6906.2 samples/s | 27.0 steps/s
[Step= 450] | Loss=0.11843 | acc=0.9787 | tpr=0.9611 | fpr=0.0210 | 6692.1 samples/s | 26.1 steps/s
[Step= 500] | Loss=0.11824 | acc=0.9787 | tpr=0.9612 | fpr=0.0210 | 7192.0 samples/s | 28.1 steps/s
[Step= 550] | Loss=0.11749 | acc=0.9789 | tpr=0.9614 | fpr=0.0208 | 11619.5 samples/s | 45.4 steps/s
Avg test loss: 0.11716, Avg test acc: 0.97889, Avg tpr: 0.96157, Avg fpr: 0.02079, total FA: 2887

server round 28/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=54.7] | Loss=0.01427 | Reg=0.00132 | acc=0.9844 | L2-Norm=11.501 | L2-Norm(final)=9.363 | 3451.4 samples/s | 53.9 steps/s
[Step=56050 Epoch=54.7] | Loss=0.01019 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.514 | L2-Norm(final)=9.370 | 4059.6 samples/s | 63.4 steps/s
[Step=56100 Epoch=54.8] | Loss=0.00960 | Reg=0.00133 | acc=0.9688 | L2-Norm=11.520 | L2-Norm(final)=9.379 | 4348.7 samples/s | 67.9 steps/s
[Step=56150 Epoch=54.8] | Loss=0.00976 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.527 | L2-Norm(final)=9.389 | 4296.2 samples/s | 67.1 steps/s
[Step=56200 Epoch=54.9] | Loss=0.00966 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.533 | L2-Norm(final)=9.399 | 4316.9 samples/s | 67.5 steps/s
[Step=56250 Epoch=54.9] | Loss=0.00945 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.538 | L2-Norm(final)=9.408 | 4419.1 samples/s | 69.0 steps/s
[Step=56300 Epoch=55.0] | Loss=0.00921 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.544 | L2-Norm(final)=9.417 | 4367.6 samples/s | 68.2 steps/s
[Step=56350 Epoch=55.0] | Loss=0.00949 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.549 | L2-Norm(final)=9.426 | 4373.7 samples/s | 68.3 steps/s
[Step=56400 Epoch=55.1] | Loss=0.00928 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.555 | L2-Norm(final)=9.434 | 4363.6 samples/s | 68.2 steps/s
[Step=56450 Epoch=55.1] | Loss=0.00944 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.560 | L2-Norm(final)=9.443 | 4365.1 samples/s | 68.2 steps/s
[Step=56500 Epoch=55.2] | Loss=0.00931 | Reg=0.00134 | acc=1.0000 | L2-Norm=11.565 | L2-Norm(final)=9.451 | 4312.4 samples/s | 67.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=55.2] | Loss=0.04265 | Reg=0.00135 | acc=0.9375 | L2-Norm=11.619 | L2-Norm(final)=9.536 | 3407.9 samples/s | 53.2 steps/s
[Step=56550 Epoch=55.2] | Loss=0.00787 | Reg=0.00135 | acc=1.0000 | L2-Norm=11.624 | L2-Norm(final)=9.542 | 3682.2 samples/s | 57.5 steps/s
[Step=56600 Epoch=55.3] | Loss=0.00972 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.631 | L2-Norm(final)=9.546 | 3877.9 samples/s | 60.6 steps/s
[Step=56650 Epoch=55.3] | Loss=0.00897 | Reg=0.00135 | acc=0.9844 | L2-Norm=11.637 | L2-Norm(final)=9.549 | 3939.6 samples/s | 61.6 steps/s
[Step=56700 Epoch=55.4] | Loss=0.00974 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.644 | L2-Norm(final)=9.554 | 3899.8 samples/s | 60.9 steps/s
[Step=56750 Epoch=55.4] | Loss=0.01003 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.650 | L2-Norm(final)=9.557 | 3850.1 samples/s | 60.2 steps/s
[Step=56800 Epoch=55.5] | Loss=0.01014 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.656 | L2-Norm(final)=9.561 | 3893.8 samples/s | 60.8 steps/s
[Step=56850 Epoch=55.5] | Loss=0.01061 | Reg=0.00136 | acc=0.9844 | L2-Norm=11.662 | L2-Norm(final)=9.565 | 3987.0 samples/s | 62.3 steps/s
[Step=56900 Epoch=55.6] | Loss=0.01092 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.668 | L2-Norm(final)=9.568 | 3970.5 samples/s | 62.0 steps/s
[Step=56950 Epoch=55.6] | Loss=0.01121 | Reg=0.00136 | acc=1.0000 | L2-Norm=11.674 | L2-Norm(final)=9.570 | 3920.6 samples/s | 61.3 steps/s
[Step=57000 Epoch=55.7] | Loss=0.01142 | Reg=0.00136 | acc=0.9688 | L2-Norm=11.680 | L2-Norm(final)=9.573 | 3924.5 samples/s | 61.3 steps/s
[Step=57050 Epoch=55.7] | Loss=0.01136 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.686 | L2-Norm(final)=9.576 | 3924.4 samples/s | 61.3 steps/s
[Step=57100 Epoch=55.7] | Loss=0.01131 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.691 | L2-Norm(final)=9.579 | 3981.3 samples/s | 62.2 steps/s
[Step=57150 Epoch=55.8] | Loss=0.01150 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.697 | L2-Norm(final)=9.582 | 3926.8 samples/s | 61.4 steps/s
[Step=57200 Epoch=55.8] | Loss=0.01124 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.703 | L2-Norm(final)=9.586 | 3933.3 samples/s | 61.5 steps/s
[Step=57250 Epoch=55.9] | Loss=0.01119 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.709 | L2-Norm(final)=9.590 | 3934.6 samples/s | 61.5 steps/s
[Step=57300 Epoch=55.9] | Loss=0.01148 | Reg=0.00137 | acc=1.0000 | L2-Norm=11.715 | L2-Norm(final)=9.593 | 3934.0 samples/s | 61.5 steps/s
[Step=57350 Epoch=56.0] | Loss=0.01156 | Reg=0.00137 | acc=0.9844 | L2-Norm=11.721 | L2-Norm(final)=9.596 | 3852.6 samples/s | 60.2 steps/s
[Step=57400 Epoch=56.0] | Loss=0.01154 | Reg=0.00138 | acc=0.9844 | L2-Norm=11.727 | L2-Norm(final)=9.599 | 3892.7 samples/s | 60.8 steps/s
[Step=57450 Epoch=56.1] | Loss=0.01143 | Reg=0.00138 | acc=0.9844 | L2-Norm=11.733 | L2-Norm(final)=9.602 | 3882.1 samples/s | 60.7 steps/s
[Step=57500 Epoch=56.1] | Loss=0.01144 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.739 | L2-Norm(final)=9.605 | 4228.7 samples/s | 66.1 steps/s
[Step=57550 Epoch=56.2] | Loss=0.01141 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.744 | L2-Norm(final)=9.609 | 1665.0 samples/s | 26.0 steps/s
[Step=57600 Epoch=56.2] | Loss=0.01136 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.750 | L2-Norm(final)=9.612 | 3915.3 samples/s | 61.2 steps/s
[Step=57650 Epoch=56.3] | Loss=0.01129 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.755 | L2-Norm(final)=9.615 | 3934.8 samples/s | 61.5 steps/s
[Step=57700 Epoch=56.3] | Loss=0.01119 | Reg=0.00138 | acc=1.0000 | L2-Norm=11.761 | L2-Norm(final)=9.619 | 3839.8 samples/s | 60.0 steps/s
[Step=57750 Epoch=56.4] | Loss=0.01114 | Reg=0.00138 | acc=0.9844 | L2-Norm=11.766 | L2-Norm(final)=9.623 | 3896.9 samples/s | 60.9 steps/s
[Step=57800 Epoch=56.4] | Loss=0.01108 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.772 | L2-Norm(final)=9.627 | 3937.4 samples/s | 61.5 steps/s
[Step=57850 Epoch=56.5] | Loss=0.01104 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.777 | L2-Norm(final)=9.630 | 3971.3 samples/s | 62.1 steps/s
[Step=57900 Epoch=56.5] | Loss=0.01102 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.782 | L2-Norm(final)=9.633 | 3921.1 samples/s | 61.3 steps/s
[Step=57950 Epoch=56.6] | Loss=0.01102 | Reg=0.00139 | acc=0.9844 | L2-Norm=11.787 | L2-Norm(final)=9.637 | 3912.0 samples/s | 61.1 steps/s
[Step=58000 Epoch=56.6] | Loss=0.01107 | Reg=0.00139 | acc=1.0000 | L2-Norm=11.792 | L2-Norm(final)=9.639 | 3908.5 samples/s | 61.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step58000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=56001 Epoch=105.6] | Loss=0.00007 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.501 | L2-Norm(final)=6.291 | 3288.8 samples/s | 51.4 steps/s
[Step=56050 Epoch=105.7] | Loss=0.00004 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.495 | L2-Norm(final)=6.299 | 3775.0 samples/s | 59.0 steps/s
[Step=56100 Epoch=105.7] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.496 | L2-Norm(final)=6.311 | 4136.9 samples/s | 64.6 steps/s
[Step=56150 Epoch=105.8] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.494 | L2-Norm(final)=6.321 | 4037.3 samples/s | 63.1 steps/s
[Step=56200 Epoch=105.9] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.492 | L2-Norm(final)=6.330 | 4078.6 samples/s | 63.7 steps/s
[Step=56250 Epoch=106.0] | Loss=0.00003 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.490 | L2-Norm(final)=6.338 | 4068.5 samples/s | 63.6 steps/s
[Step=56300 Epoch=106.1] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.488 | L2-Norm(final)=6.347 | 4055.2 samples/s | 63.4 steps/s
[Step=56350 Epoch=106.2] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.485 | L2-Norm(final)=6.354 | 4116.4 samples/s | 64.3 steps/s
[Step=56400 Epoch=106.3] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.482 | L2-Norm(final)=6.361 | 4105.4 samples/s | 64.1 steps/s
[Step=56450 Epoch=106.4] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.480 | L2-Norm(final)=6.368 | 4080.9 samples/s | 63.8 steps/s
[Step=56500 Epoch=106.5] | Loss=0.00002 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=6.375 | 4149.9 samples/s | 64.8 steps/s
All layers training...
LR=0.00025, len=1
[Step=56501 Epoch=106.5] | Loss=0.00002 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=6.443 | 3375.2 samples/s | 52.7 steps/s
[Step=56550 Epoch=106.6] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.446 | L2-Norm(final)=6.447 | 3398.3 samples/s | 53.1 steps/s
[Step=56600 Epoch=106.7] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.435 | L2-Norm(final)=6.451 | 3717.7 samples/s | 58.1 steps/s
[Step=56650 Epoch=106.8] | Loss=0.00001 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.424 | L2-Norm(final)=6.455 | 3744.9 samples/s | 58.5 steps/s
[Step=56700 Epoch=106.9] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.414 | L2-Norm(final)=6.458 | 3689.3 samples/s | 57.6 steps/s
[Step=56750 Epoch=107.0] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.403 | L2-Norm(final)=6.461 | 3677.4 samples/s | 57.5 steps/s
[Step=56800 Epoch=107.1] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.392 | L2-Norm(final)=6.464 | 3708.2 samples/s | 57.9 steps/s
[Step=56850 Epoch=107.2] | Loss=0.00001 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.382 | L2-Norm(final)=6.467 | 3719.7 samples/s | 58.1 steps/s
[Step=56900 Epoch=107.3] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.371 | L2-Norm(final)=6.470 | 3703.4 samples/s | 57.9 steps/s
[Step=56950 Epoch=107.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.360 | L2-Norm(final)=6.473 | 3692.9 samples/s | 57.7 steps/s
[Step=57000 Epoch=107.4] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.350 | L2-Norm(final)=6.476 | 3745.4 samples/s | 58.5 steps/s
[Step=57050 Epoch=107.5] | Loss=0.00001 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.339 | L2-Norm(final)=6.478 | 1611.9 samples/s | 25.2 steps/s
[Step=57100 Epoch=107.6] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.328 | L2-Norm(final)=6.481 | 3725.2 samples/s | 58.2 steps/s
[Step=57150 Epoch=107.7] | Loss=0.00001 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.317 | L2-Norm(final)=6.483 | 3710.0 samples/s | 58.0 steps/s
[Step=57200 Epoch=107.8] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.306 | L2-Norm(final)=6.486 | 3803.1 samples/s | 59.4 steps/s
[Step=57250 Epoch=107.9] | Loss=0.00000 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.295 | L2-Norm(final)=6.488 | 3667.3 samples/s | 57.3 steps/s
[Step=57300 Epoch=108.0] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.284 | L2-Norm(final)=6.490 | 3698.0 samples/s | 57.8 steps/s
[Step=57350 Epoch=108.1] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.273 | L2-Norm(final)=6.492 | 3752.1 samples/s | 58.6 steps/s
[Step=57400 Epoch=108.2] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.262 | L2-Norm(final)=6.494 | 3716.3 samples/s | 58.1 steps/s
[Step=57450 Epoch=108.3] | Loss=0.00000 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.251 | L2-Norm(final)=6.496 | 3687.3 samples/s | 57.6 steps/s
[Step=57500 Epoch=108.4] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.239 | L2-Norm(final)=6.499 | 3777.7 samples/s | 59.0 steps/s
[Step=57550 Epoch=108.5] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.228 | L2-Norm(final)=6.501 | 4593.1 samples/s | 71.8 steps/s
[Step=57600 Epoch=108.6] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.216 | L2-Norm(final)=6.503 | 1541.2 samples/s | 24.1 steps/s
[Step=57650 Epoch=108.7] | Loss=0.00000 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.205 | L2-Norm(final)=6.505 | 3672.4 samples/s | 57.4 steps/s
[Step=57700 Epoch=108.8] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.193 | L2-Norm(final)=6.507 | 3728.6 samples/s | 58.3 steps/s
[Step=57750 Epoch=108.9] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.181 | L2-Norm(final)=6.509 | 3704.2 samples/s | 57.9 steps/s
[Step=57800 Epoch=109.0] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.169 | L2-Norm(final)=6.511 | 3736.8 samples/s | 58.4 steps/s
[Step=57850 Epoch=109.0] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.157 | L2-Norm(final)=6.513 | 3712.2 samples/s | 58.0 steps/s
[Step=57900 Epoch=109.1] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.145 | L2-Norm(final)=6.515 | 3690.4 samples/s | 57.7 steps/s
[Step=57950 Epoch=109.2] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.133 | L2-Norm(final)=6.517 | 3729.1 samples/s | 58.3 steps/s
[Step=58000 Epoch=109.3] | Loss=0.00000 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.121 | L2-Norm(final)=6.520 | 3744.9 samples/s | 58.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step58000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05904 | acc=0.9700 | tpr=0.9748 | fpr=0.0404 | 3605.7 samples/s | 14.1 steps/s
Avg test loss: 0.05987, Avg test acc: 0.96963, Avg tpr: 0.97435, Avg fpr: 0.04076, total FA: 318

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.10972 | acc=0.3044 | tpr=0.0165 | fpr=0.0706 | 3605.6 samples/s | 14.1 steps/s
Avg test loss: 5.10539, Avg test acc: 0.30351, Avg tpr: 0.01719, Avg fpr: 0.06679, total FA: 521

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.52741 | acc=0.1347 | tpr=0.7478 | fpr=0.8763 | 3615.8 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.52708 | acc=0.1374 | tpr=0.7591 | fpr=0.8742 | 7002.7 samples/s | 27.4 steps/s
[Step= 150] | Loss=5.53075 | acc=0.1366 | tpr=0.7608 | fpr=0.8749 | 6847.9 samples/s | 26.7 steps/s
[Step= 200] | Loss=5.50900 | acc=0.1370 | tpr=0.7519 | fpr=0.8742 | 6946.9 samples/s | 27.1 steps/s
[Step= 250] | Loss=5.51521 | acc=0.1370 | tpr=0.7528 | fpr=0.8742 | 6883.5 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.51507 | acc=0.1373 | tpr=0.7505 | fpr=0.8739 | 6807.7 samples/s | 26.6 steps/s
[Step= 350] | Loss=5.51379 | acc=0.1369 | tpr=0.7520 | fpr=0.8743 | 6994.2 samples/s | 27.3 steps/s
[Step= 400] | Loss=5.52233 | acc=0.1365 | tpr=0.7500 | fpr=0.8747 | 6897.5 samples/s | 26.9 steps/s
[Step= 450] | Loss=5.52382 | acc=0.1363 | tpr=0.7551 | fpr=0.8749 | 6736.0 samples/s | 26.3 steps/s
[Step= 500] | Loss=5.52542 | acc=0.1365 | tpr=0.7590 | fpr=0.8747 | 6960.5 samples/s | 27.2 steps/s
[Step= 550] | Loss=5.52476 | acc=0.1368 | tpr=0.7652 | fpr=0.8746 | 12246.7 samples/s | 47.8 steps/s
Avg test loss: 5.52632, Avg test acc: 0.13677, Avg tpr: 0.76545, Avg fpr: 0.87466, total FA: 121445

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10431 | acc=0.9818 | tpr=0.9602 | fpr=0.0178 | 3606.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.11001 | acc=0.9812 | tpr=0.9638 | fpr=0.0185 | 6840.8 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.11104 | acc=0.9805 | tpr=0.9625 | fpr=0.0192 | 6990.7 samples/s | 27.3 steps/s
[Step= 200] | Loss=0.11272 | acc=0.9806 | tpr=0.9672 | fpr=0.0192 | 6781.8 samples/s | 26.5 steps/s
[Step= 250] | Loss=0.11154 | acc=0.9807 | tpr=0.9642 | fpr=0.0190 | 6982.5 samples/s | 27.3 steps/s
[Step= 300] | Loss=0.11356 | acc=0.9804 | tpr=0.9615 | fpr=0.0193 | 6874.9 samples/s | 26.9 steps/s
[Step= 350] | Loss=0.11356 | acc=0.9802 | tpr=0.9624 | fpr=0.0195 | 6822.1 samples/s | 26.6 steps/s
[Step= 400] | Loss=0.11389 | acc=0.9799 | tpr=0.9612 | fpr=0.0197 | 6782.7 samples/s | 26.5 steps/s
[Step= 450] | Loss=0.11664 | acc=0.9796 | tpr=0.9591 | fpr=0.0201 | 6696.9 samples/s | 26.2 steps/s
[Step= 500] | Loss=0.11634 | acc=0.9796 | tpr=0.9595 | fpr=0.0200 | 6768.8 samples/s | 26.4 steps/s
[Step= 550] | Loss=0.11565 | acc=0.9798 | tpr=0.9586 | fpr=0.0199 | 12196.8 samples/s | 47.6 steps/s
Avg test loss: 0.11535, Avg test acc: 0.97978, Avg tpr: 0.95880, Avg fpr: 0.01983, total FA: 2754

server round 29/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=56.6] | Loss=0.00583 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.263 | L2-Norm(final)=9.723 | 3351.3 samples/s | 52.4 steps/s
[Step=58050 Epoch=56.7] | Loss=0.00987 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.285 | L2-Norm(final)=9.732 | 3967.9 samples/s | 62.0 steps/s
[Step=58100 Epoch=56.7] | Loss=0.00958 | Reg=0.00128 | acc=0.9844 | L2-Norm=11.292 | L2-Norm(final)=9.738 | 4343.6 samples/s | 67.9 steps/s
[Step=58150 Epoch=56.8] | Loss=0.00837 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.296 | L2-Norm(final)=9.746 | 4395.9 samples/s | 68.7 steps/s
[Step=58200 Epoch=56.8] | Loss=0.00811 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.300 | L2-Norm(final)=9.754 | 4309.8 samples/s | 67.3 steps/s
[Step=58250 Epoch=56.9] | Loss=0.00840 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.305 | L2-Norm(final)=9.762 | 4343.4 samples/s | 67.9 steps/s
[Step=58300 Epoch=56.9] | Loss=0.00834 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.310 | L2-Norm(final)=9.770 | 4330.0 samples/s | 67.7 steps/s
[Step=58350 Epoch=57.0] | Loss=0.00822 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.315 | L2-Norm(final)=9.777 | 4353.4 samples/s | 68.0 steps/s
[Step=58400 Epoch=57.0] | Loss=0.00841 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.320 | L2-Norm(final)=9.783 | 4393.2 samples/s | 68.6 steps/s
[Step=58450 Epoch=57.1] | Loss=0.00840 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.324 | L2-Norm(final)=9.789 | 4303.3 samples/s | 67.2 steps/s
[Step=58500 Epoch=57.1] | Loss=0.00832 | Reg=0.00128 | acc=1.0000 | L2-Norm=11.329 | L2-Norm(final)=9.795 | 4363.0 samples/s | 68.2 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=57.1] | Loss=0.00427 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.374 | L2-Norm(final)=9.860 | 3310.7 samples/s | 51.7 steps/s
[Step=58550 Epoch=57.2] | Loss=0.01029 | Reg=0.00129 | acc=1.0000 | L2-Norm=11.378 | L2-Norm(final)=9.864 | 3687.8 samples/s | 57.6 steps/s
[Step=58600 Epoch=57.2] | Loss=0.01105 | Reg=0.00130 | acc=0.9531 | L2-Norm=11.385 | L2-Norm(final)=9.868 | 3912.6 samples/s | 61.1 steps/s
[Step=58650 Epoch=57.3] | Loss=0.01132 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.391 | L2-Norm(final)=9.870 | 3910.5 samples/s | 61.1 steps/s
[Step=58700 Epoch=57.3] | Loss=0.01122 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.397 | L2-Norm(final)=9.873 | 3870.2 samples/s | 60.5 steps/s
[Step=58750 Epoch=57.4] | Loss=0.01116 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.404 | L2-Norm(final)=9.876 | 3886.9 samples/s | 60.7 steps/s
[Step=58800 Epoch=57.4] | Loss=0.01103 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.410 | L2-Norm(final)=9.880 | 3887.8 samples/s | 60.7 steps/s
[Step=58850 Epoch=57.5] | Loss=0.01109 | Reg=0.00130 | acc=1.0000 | L2-Norm=11.416 | L2-Norm(final)=9.885 | 3895.2 samples/s | 60.9 steps/s
[Step=58900 Epoch=57.5] | Loss=0.01090 | Reg=0.00130 | acc=0.9844 | L2-Norm=11.422 | L2-Norm(final)=9.889 | 3922.8 samples/s | 61.3 steps/s
[Step=58950 Epoch=57.6] | Loss=0.01102 | Reg=0.00131 | acc=0.9844 | L2-Norm=11.428 | L2-Norm(final)=9.893 | 3872.3 samples/s | 60.5 steps/s
[Step=59000 Epoch=57.6] | Loss=0.01119 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.434 | L2-Norm(final)=9.898 | 3902.9 samples/s | 61.0 steps/s
[Step=59050 Epoch=57.7] | Loss=0.01122 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.441 | L2-Norm(final)=9.902 | 3942.8 samples/s | 61.6 steps/s
[Step=59100 Epoch=57.7] | Loss=0.01125 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.447 | L2-Norm(final)=9.906 | 3909.0 samples/s | 61.1 steps/s
[Step=59150 Epoch=57.8] | Loss=0.01102 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.454 | L2-Norm(final)=9.911 | 3945.9 samples/s | 61.7 steps/s
[Step=59200 Epoch=57.8] | Loss=0.01108 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.460 | L2-Norm(final)=9.915 | 3896.1 samples/s | 60.9 steps/s
[Step=59250 Epoch=57.8] | Loss=0.01104 | Reg=0.00131 | acc=1.0000 | L2-Norm=11.466 | L2-Norm(final)=9.919 | 3905.6 samples/s | 61.0 steps/s
[Step=59300 Epoch=57.9] | Loss=0.01122 | Reg=0.00132 | acc=0.9688 | L2-Norm=11.472 | L2-Norm(final)=9.924 | 3934.1 samples/s | 61.5 steps/s
[Step=59350 Epoch=57.9] | Loss=0.01118 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.478 | L2-Norm(final)=9.928 | 3945.1 samples/s | 61.6 steps/s
[Step=59400 Epoch=58.0] | Loss=0.01128 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.485 | L2-Norm(final)=9.932 | 3925.2 samples/s | 61.3 steps/s
[Step=59450 Epoch=58.0] | Loss=0.01123 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.490 | L2-Norm(final)=9.935 | 3953.3 samples/s | 61.8 steps/s
[Step=59500 Epoch=58.1] | Loss=0.01122 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.496 | L2-Norm(final)=9.939 | 4220.9 samples/s | 66.0 steps/s
[Step=59550 Epoch=58.1] | Loss=0.01112 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.502 | L2-Norm(final)=9.943 | 1606.5 samples/s | 25.1 steps/s
[Step=59600 Epoch=58.2] | Loss=0.01106 | Reg=0.00132 | acc=1.0000 | L2-Norm=11.508 | L2-Norm(final)=9.947 | 3881.9 samples/s | 60.7 steps/s
[Step=59650 Epoch=58.2] | Loss=0.01097 | Reg=0.00133 | acc=0.9688 | L2-Norm=11.513 | L2-Norm(final)=9.951 | 3869.1 samples/s | 60.5 steps/s
[Step=59700 Epoch=58.3] | Loss=0.01100 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.519 | L2-Norm(final)=9.954 | 3929.3 samples/s | 61.4 steps/s
[Step=59750 Epoch=58.3] | Loss=0.01101 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.524 | L2-Norm(final)=9.958 | 3916.8 samples/s | 61.2 steps/s
[Step=59800 Epoch=58.4] | Loss=0.01102 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.530 | L2-Norm(final)=9.961 | 3926.6 samples/s | 61.4 steps/s
[Step=59850 Epoch=58.4] | Loss=0.01097 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.535 | L2-Norm(final)=9.964 | 3924.7 samples/s | 61.3 steps/s
[Step=59900 Epoch=58.5] | Loss=0.01098 | Reg=0.00133 | acc=0.9844 | L2-Norm=11.540 | L2-Norm(final)=9.967 | 3964.1 samples/s | 61.9 steps/s
[Step=59950 Epoch=58.5] | Loss=0.01100 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.546 | L2-Norm(final)=9.970 | 3902.1 samples/s | 61.0 steps/s
[Step=60000 Epoch=58.6] | Loss=0.01090 | Reg=0.00133 | acc=1.0000 | L2-Norm=11.551 | L2-Norm(final)=9.973 | 3926.6 samples/s | 61.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step60000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00025, len=1
[Step=58001 Epoch=109.3] | Loss=0.00008 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.263 | L2-Norm(final)=6.585 | 3922.9 samples/s | 61.3 steps/s
[Step=58050 Epoch=109.4] | Loss=0.00004 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.258 | L2-Norm(final)=6.603 | 3223.4 samples/s | 50.4 steps/s
[Step=58100 Epoch=109.5] | Loss=0.00003 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.258 | L2-Norm(final)=6.623 | 4101.3 samples/s | 64.1 steps/s
[Step=58150 Epoch=109.6] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.256 | L2-Norm(final)=6.638 | 4091.3 samples/s | 63.9 steps/s
[Step=58200 Epoch=109.7] | Loss=0.00002 | Reg=0.00127 | acc=1.0000 | L2-Norm=11.251 | L2-Norm(final)=6.651 | 4186.0 samples/s | 65.4 steps/s
[Step=58250 Epoch=109.8] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.247 | L2-Norm(final)=6.662 | 4048.3 samples/s | 63.3 steps/s
[Step=58300 Epoch=109.9] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.241 | L2-Norm(final)=6.671 | 4179.3 samples/s | 65.3 steps/s
[Step=58350 Epoch=110.0] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.236 | L2-Norm(final)=6.681 | 4123.8 samples/s | 64.4 steps/s
[Step=58400 Epoch=110.1] | Loss=0.00002 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.231 | L2-Norm(final)=6.691 | 4081.6 samples/s | 63.8 steps/s
[Step=58450 Epoch=110.2] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.226 | L2-Norm(final)=6.700 | 4124.6 samples/s | 64.4 steps/s
[Step=58500 Epoch=110.3] | Loss=0.00001 | Reg=0.00126 | acc=1.0000 | L2-Norm=11.220 | L2-Norm(final)=6.708 | 4186.8 samples/s | 65.4 steps/s
All layers training...
LR=0.00025, len=1
[Step=58501 Epoch=110.3] | Loss=0.00000 | Reg=0.00125 | acc=1.0000 | L2-Norm=11.166 | L2-Norm(final)=6.793 | 3076.5 samples/s | 48.1 steps/s
[Step=58550 Epoch=110.4] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.150 | L2-Norm(final)=6.800 | 3628.4 samples/s | 56.7 steps/s
[Step=58600 Epoch=110.5] | Loss=0.00001 | Reg=0.00124 | acc=1.0000 | L2-Norm=11.129 | L2-Norm(final)=6.807 | 3687.6 samples/s | 57.6 steps/s
[Step=58650 Epoch=110.6] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.107 | L2-Norm(final)=6.811 | 3721.1 samples/s | 58.1 steps/s
[Step=58700 Epoch=110.7] | Loss=0.00000 | Reg=0.00123 | acc=1.0000 | L2-Norm=11.085 | L2-Norm(final)=6.815 | 3687.7 samples/s | 57.6 steps/s
[Step=58750 Epoch=110.7] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.062 | L2-Norm(final)=6.820 | 3690.7 samples/s | 57.7 steps/s
[Step=58800 Epoch=110.8] | Loss=0.00000 | Reg=0.00122 | acc=1.0000 | L2-Norm=11.040 | L2-Norm(final)=6.824 | 3711.9 samples/s | 58.0 steps/s
[Step=58850 Epoch=110.9] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=11.018 | L2-Norm(final)=6.828 | 3710.8 samples/s | 58.0 steps/s
[Step=58900 Epoch=111.0] | Loss=0.00000 | Reg=0.00121 | acc=1.0000 | L2-Norm=10.996 | L2-Norm(final)=6.832 | 3714.5 samples/s | 58.0 steps/s
[Step=58950 Epoch=111.1] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.973 | L2-Norm(final)=6.835 | 3709.6 samples/s | 58.0 steps/s
[Step=59000 Epoch=111.2] | Loss=0.00000 | Reg=0.00120 | acc=1.0000 | L2-Norm=10.952 | L2-Norm(final)=6.839 | 3723.5 samples/s | 58.2 steps/s
[Step=59050 Epoch=111.3] | Loss=0.00001 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.930 | L2-Norm(final)=6.844 | 1640.6 samples/s | 25.6 steps/s
[Step=59100 Epoch=111.4] | Loss=0.00001 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.910 | L2-Norm(final)=6.848 | 3714.7 samples/s | 58.0 steps/s
[Step=59150 Epoch=111.5] | Loss=0.00001 | Reg=0.00119 | acc=1.0000 | L2-Norm=10.889 | L2-Norm(final)=6.852 | 3702.1 samples/s | 57.8 steps/s
[Step=59200 Epoch=111.6] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.867 | L2-Norm(final)=6.856 | 3724.6 samples/s | 58.2 steps/s
[Step=59250 Epoch=111.7] | Loss=0.00000 | Reg=0.00118 | acc=1.0000 | L2-Norm=10.845 | L2-Norm(final)=6.860 | 3764.4 samples/s | 58.8 steps/s
[Step=59300 Epoch=111.8] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.823 | L2-Norm(final)=6.863 | 3677.7 samples/s | 57.5 steps/s
[Step=59350 Epoch=111.9] | Loss=0.00000 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.801 | L2-Norm(final)=6.867 | 3771.2 samples/s | 58.9 steps/s
[Step=59400 Epoch=112.0] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.778 | L2-Norm(final)=6.870 | 3669.3 samples/s | 57.3 steps/s
[Step=59450 Epoch=112.1] | Loss=0.00000 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.755 | L2-Norm(final)=6.874 | 3721.0 samples/s | 58.1 steps/s
[Step=59500 Epoch=112.2] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.733 | L2-Norm(final)=6.878 | 3720.2 samples/s | 58.1 steps/s
[Step=59550 Epoch=112.3] | Loss=0.00000 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.710 | L2-Norm(final)=6.881 | 4670.2 samples/s | 73.0 steps/s
[Step=59600 Epoch=112.3] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.687 | L2-Norm(final)=6.885 | 1540.5 samples/s | 24.1 steps/s
[Step=59650 Epoch=112.4] | Loss=0.00000 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.664 | L2-Norm(final)=6.889 | 3750.7 samples/s | 58.6 steps/s
[Step=59700 Epoch=112.5] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.641 | L2-Norm(final)=6.893 | 3667.5 samples/s | 57.3 steps/s
[Step=59750 Epoch=112.6] | Loss=0.00000 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.617 | L2-Norm(final)=6.896 | 3702.3 samples/s | 57.8 steps/s
[Step=59800 Epoch=112.7] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.594 | L2-Norm(final)=6.900 | 3704.6 samples/s | 57.9 steps/s
[Step=59850 Epoch=112.8] | Loss=0.00000 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.570 | L2-Norm(final)=6.904 | 3706.1 samples/s | 57.9 steps/s
[Step=59900 Epoch=112.9] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.546 | L2-Norm(final)=6.908 | 3778.4 samples/s | 59.0 steps/s
[Step=59950 Epoch=113.0] | Loss=0.00000 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.522 | L2-Norm(final)=6.912 | 3703.2 samples/s | 57.9 steps/s
[Step=60000 Epoch=113.1] | Loss=0.00000 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.498 | L2-Norm(final)=6.916 | 3769.5 samples/s | 58.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step60000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06310 | acc=0.9697 | tpr=0.9710 | fpr=0.0332 | 3610.2 samples/s | 14.1 steps/s
Avg test loss: 0.06486, Avg test acc: 0.96863, Avg tpr: 0.97027, Avg fpr: 0.03500, total FA: 273

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.35150 | acc=0.3082 | tpr=0.0124 | fpr=0.0496 | 3651.7 samples/s | 14.3 steps/s
Avg test loss: 5.35000, Avg test acc: 0.30660, Avg tpr: 0.01276, Avg fpr: 0.04717, total FA: 368

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.14758 | acc=0.1477 | tpr=0.7832 | fpr=0.8638 | 3601.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.14545 | acc=0.1517 | tpr=0.7676 | fpr=0.8598 | 7082.8 samples/s | 27.7 steps/s
[Step= 150] | Loss=5.14231 | acc=0.1510 | tpr=0.7637 | fpr=0.8603 | 6664.1 samples/s | 26.0 steps/s
[Step= 200] | Loss=5.12176 | acc=0.1512 | tpr=0.7574 | fpr=0.8599 | 6947.6 samples/s | 27.1 steps/s
[Step= 250] | Loss=5.12370 | acc=0.1511 | tpr=0.7607 | fpr=0.8600 | 6776.0 samples/s | 26.5 steps/s
[Step= 300] | Loss=5.12400 | acc=0.1514 | tpr=0.7571 | fpr=0.8596 | 6839.5 samples/s | 26.7 steps/s
[Step= 350] | Loss=5.12485 | acc=0.1511 | tpr=0.7545 | fpr=0.8599 | 6734.7 samples/s | 26.3 steps/s
[Step= 400] | Loss=5.13131 | acc=0.1505 | tpr=0.7511 | fpr=0.8604 | 6939.6 samples/s | 27.1 steps/s
[Step= 450] | Loss=5.13327 | acc=0.1506 | tpr=0.7527 | fpr=0.8603 | 6931.9 samples/s | 27.1 steps/s
[Step= 500] | Loss=5.13417 | acc=0.1509 | tpr=0.7573 | fpr=0.8600 | 6515.3 samples/s | 25.5 steps/s
[Step= 550] | Loss=5.13512 | acc=0.1511 | tpr=0.7628 | fpr=0.8601 | 12240.1 samples/s | 47.8 steps/s
Avg test loss: 5.13613, Avg test acc: 0.15101, Avg tpr: 0.76307, Avg fpr: 0.86011, total FA: 119425

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10111 | acc=0.9823 | tpr=0.9558 | fpr=0.0173 | 3597.8 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.10590 | acc=0.9821 | tpr=0.9616 | fpr=0.0175 | 6778.7 samples/s | 26.5 steps/s
[Step= 150] | Loss=0.10740 | acc=0.9814 | tpr=0.9625 | fpr=0.0182 | 6804.5 samples/s | 26.6 steps/s
[Step= 200] | Loss=0.10924 | acc=0.9815 | tpr=0.9661 | fpr=0.0182 | 6883.8 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.10788 | acc=0.9815 | tpr=0.9616 | fpr=0.0182 | 7019.1 samples/s | 27.4 steps/s
[Step= 300] | Loss=0.11002 | acc=0.9811 | tpr=0.9593 | fpr=0.0185 | 6673.4 samples/s | 26.1 steps/s
[Step= 350] | Loss=0.11003 | acc=0.9810 | tpr=0.9593 | fpr=0.0186 | 7016.5 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.11042 | acc=0.9808 | tpr=0.9590 | fpr=0.0188 | 7041.6 samples/s | 27.5 steps/s
[Step= 450] | Loss=0.11307 | acc=0.9805 | tpr=0.9567 | fpr=0.0191 | 6540.4 samples/s | 25.5 steps/s
[Step= 500] | Loss=0.11263 | acc=0.9806 | tpr=0.9568 | fpr=0.0190 | 6813.2 samples/s | 26.6 steps/s
[Step= 550] | Loss=0.11197 | acc=0.9807 | tpr=0.9562 | fpr=0.0188 | 12082.7 samples/s | 47.2 steps/s
Avg test loss: 0.11170, Avg test acc: 0.98075, Avg tpr: 0.95642, Avg fpr: 0.01881, total FA: 2612

server round 30/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=58.6] | Loss=0.00740 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.629 | L2-Norm(final)=10.067 | 3559.7 samples/s | 55.6 steps/s
[Step=60050 Epoch=58.6] | Loss=0.01061 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.639 | L2-Norm(final)=10.072 | 3729.2 samples/s | 58.3 steps/s
[Step=60100 Epoch=58.7] | Loss=0.01124 | Reg=0.00113 | acc=0.9688 | L2-Norm=10.644 | L2-Norm(final)=10.080 | 4248.3 samples/s | 66.4 steps/s
[Step=60150 Epoch=58.7] | Loss=0.01070 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.647 | L2-Norm(final)=10.086 | 4347.1 samples/s | 67.9 steps/s
[Step=60200 Epoch=58.8] | Loss=0.01021 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.650 | L2-Norm(final)=10.093 | 4414.7 samples/s | 69.0 steps/s
[Step=60250 Epoch=58.8] | Loss=0.01032 | Reg=0.00113 | acc=0.9844 | L2-Norm=10.653 | L2-Norm(final)=10.101 | 4263.0 samples/s | 66.6 steps/s
[Step=60300 Epoch=58.9] | Loss=0.00973 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.656 | L2-Norm(final)=10.108 | 4372.9 samples/s | 68.3 steps/s
[Step=60350 Epoch=58.9] | Loss=0.00947 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.659 | L2-Norm(final)=10.115 | 4392.2 samples/s | 68.6 steps/s
[Step=60400 Epoch=59.0] | Loss=0.00961 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.663 | L2-Norm(final)=10.122 | 4345.9 samples/s | 67.9 steps/s
[Step=60450 Epoch=59.0] | Loss=0.00973 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.666 | L2-Norm(final)=10.129 | 4359.8 samples/s | 68.1 steps/s
[Step=60500 Epoch=59.1] | Loss=0.00964 | Reg=0.00114 | acc=1.0000 | L2-Norm=10.669 | L2-Norm(final)=10.136 | 4391.8 samples/s | 68.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=59.1] | Loss=0.02820 | Reg=0.00114 | acc=0.9688 | L2-Norm=10.700 | L2-Norm(final)=10.202 | 3271.8 samples/s | 51.1 steps/s
[Step=60550 Epoch=59.1] | Loss=0.00880 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.704 | L2-Norm(final)=10.208 | 3669.7 samples/s | 57.3 steps/s
[Step=60600 Epoch=59.2] | Loss=0.00873 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.709 | L2-Norm(final)=10.214 | 3883.3 samples/s | 60.7 steps/s
[Step=60650 Epoch=59.2] | Loss=0.00940 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.714 | L2-Norm(final)=10.219 | 3943.0 samples/s | 61.6 steps/s
[Step=60700 Epoch=59.3] | Loss=0.00967 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.719 | L2-Norm(final)=10.223 | 3924.8 samples/s | 61.3 steps/s
[Step=60750 Epoch=59.3] | Loss=0.00925 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.723 | L2-Norm(final)=10.228 | 3940.7 samples/s | 61.6 steps/s
[Step=60800 Epoch=59.4] | Loss=0.00915 | Reg=0.00115 | acc=0.9844 | L2-Norm=10.727 | L2-Norm(final)=10.233 | 3916.5 samples/s | 61.2 steps/s
[Step=60850 Epoch=59.4] | Loss=0.00903 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.732 | L2-Norm(final)=10.237 | 3899.1 samples/s | 60.9 steps/s
[Step=60900 Epoch=59.5] | Loss=0.00905 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.736 | L2-Norm(final)=10.242 | 3994.2 samples/s | 62.4 steps/s
[Step=60950 Epoch=59.5] | Loss=0.00918 | Reg=0.00115 | acc=0.9375 | L2-Norm=10.740 | L2-Norm(final)=10.246 | 3957.5 samples/s | 61.8 steps/s
[Step=61000 Epoch=59.6] | Loss=0.00925 | Reg=0.00115 | acc=1.0000 | L2-Norm=10.744 | L2-Norm(final)=10.250 | 3923.5 samples/s | 61.3 steps/s
[Step=61050 Epoch=59.6] | Loss=0.00926 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.747 | L2-Norm(final)=10.255 | 3953.1 samples/s | 61.8 steps/s
[Step=61100 Epoch=59.7] | Loss=0.00936 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.751 | L2-Norm(final)=10.259 | 3906.3 samples/s | 61.0 steps/s
[Step=61150 Epoch=59.7] | Loss=0.00936 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.755 | L2-Norm(final)=10.264 | 3961.5 samples/s | 61.9 steps/s
[Step=61200 Epoch=59.8] | Loss=0.00955 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.759 | L2-Norm(final)=10.268 | 3937.0 samples/s | 61.5 steps/s
[Step=61250 Epoch=59.8] | Loss=0.00949 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.762 | L2-Norm(final)=10.273 | 3922.7 samples/s | 61.3 steps/s
[Step=61300 Epoch=59.8] | Loss=0.00954 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.766 | L2-Norm(final)=10.277 | 3953.0 samples/s | 61.8 steps/s
[Step=61350 Epoch=59.9] | Loss=0.00947 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.769 | L2-Norm(final)=10.281 | 3968.8 samples/s | 62.0 steps/s
[Step=61400 Epoch=59.9] | Loss=0.00942 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.773 | L2-Norm(final)=10.286 | 3928.4 samples/s | 61.4 steps/s
[Step=61450 Epoch=60.0] | Loss=0.00953 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.776 | L2-Norm(final)=10.289 | 3902.6 samples/s | 61.0 steps/s
[Step=61500 Epoch=60.0] | Loss=0.00953 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.779 | L2-Norm(final)=10.293 | 4190.1 samples/s | 65.5 steps/s
[Step=61550 Epoch=60.1] | Loss=0.00940 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.782 | L2-Norm(final)=10.297 | 1619.2 samples/s | 25.3 steps/s
[Step=61600 Epoch=60.1] | Loss=0.00928 | Reg=0.00116 | acc=0.9844 | L2-Norm=10.786 | L2-Norm(final)=10.301 | 3907.0 samples/s | 61.0 steps/s
[Step=61650 Epoch=60.2] | Loss=0.00913 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.789 | L2-Norm(final)=10.305 | 3950.2 samples/s | 61.7 steps/s
[Step=61700 Epoch=60.2] | Loss=0.00905 | Reg=0.00116 | acc=1.0000 | L2-Norm=10.792 | L2-Norm(final)=10.309 | 3906.2 samples/s | 61.0 steps/s
[Step=61750 Epoch=60.3] | Loss=0.00899 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.795 | L2-Norm(final)=10.312 | 3920.9 samples/s | 61.3 steps/s
[Step=61800 Epoch=60.3] | Loss=0.00894 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.798 | L2-Norm(final)=10.316 | 3962.3 samples/s | 61.9 steps/s
[Step=61850 Epoch=60.4] | Loss=0.00887 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.801 | L2-Norm(final)=10.320 | 3961.9 samples/s | 61.9 steps/s
[Step=61900 Epoch=60.4] | Loss=0.00890 | Reg=0.00117 | acc=0.9844 | L2-Norm=10.804 | L2-Norm(final)=10.324 | 3958.0 samples/s | 61.8 steps/s
[Step=61950 Epoch=60.5] | Loss=0.00890 | Reg=0.00117 | acc=0.9688 | L2-Norm=10.807 | L2-Norm(final)=10.327 | 3919.8 samples/s | 61.2 steps/s
[Step=62000 Epoch=60.5] | Loss=0.00884 | Reg=0.00117 | acc=1.0000 | L2-Norm=10.809 | L2-Norm(final)=10.330 | 3938.6 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step62000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=60001 Epoch=113.1] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.629 | L2-Norm(final)=7.047 | 3278.8 samples/s | 51.2 steps/s
[Step=60050 Epoch=113.2] | Loss=0.00003 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.619 | L2-Norm(final)=7.062 | 3927.1 samples/s | 61.4 steps/s
[Step=60100 Epoch=113.3] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.615 | L2-Norm(final)=7.075 | 4102.4 samples/s | 64.1 steps/s
[Step=60150 Epoch=113.4] | Loss=0.00002 | Reg=0.00113 | acc=1.0000 | L2-Norm=10.611 | L2-Norm(final)=7.084 | 4144.1 samples/s | 64.8 steps/s
[Step=60200 Epoch=113.5] | Loss=0.00002 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.606 | L2-Norm(final)=7.093 | 4028.9 samples/s | 63.0 steps/s
[Step=60250 Epoch=113.6] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.601 | L2-Norm(final)=7.100 | 4169.1 samples/s | 65.1 steps/s
[Step=60300 Epoch=113.7] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.597 | L2-Norm(final)=7.108 | 4099.7 samples/s | 64.1 steps/s
[Step=60350 Epoch=113.8] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.593 | L2-Norm(final)=7.115 | 4143.5 samples/s | 64.7 steps/s
[Step=60400 Epoch=113.9] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.588 | L2-Norm(final)=7.122 | 4084.1 samples/s | 63.8 steps/s
[Step=60450 Epoch=113.9] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.584 | L2-Norm(final)=7.128 | 4123.2 samples/s | 64.4 steps/s
[Step=60500 Epoch=114.0] | Loss=0.00001 | Reg=0.00112 | acc=1.0000 | L2-Norm=10.579 | L2-Norm(final)=7.134 | 4176.6 samples/s | 65.3 steps/s
All layers training...
LR=0.00013, len=1
[Step=60501 Epoch=114.0] | Loss=0.00003 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.535 | L2-Norm(final)=7.195 | 3518.8 samples/s | 55.0 steps/s
[Step=60550 Epoch=114.1] | Loss=0.00001 | Reg=0.00111 | acc=1.0000 | L2-Norm=10.522 | L2-Norm(final)=7.201 | 3271.6 samples/s | 51.1 steps/s
[Step=60600 Epoch=114.2] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.501 | L2-Norm(final)=7.205 | 3731.3 samples/s | 58.3 steps/s
[Step=60650 Epoch=114.3] | Loss=0.00001 | Reg=0.00110 | acc=1.0000 | L2-Norm=10.479 | L2-Norm(final)=7.209 | 3760.9 samples/s | 58.8 steps/s
[Step=60700 Epoch=114.4] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.456 | L2-Norm(final)=7.213 | 3727.0 samples/s | 58.2 steps/s
[Step=60750 Epoch=114.5] | Loss=0.00000 | Reg=0.00109 | acc=1.0000 | L2-Norm=10.434 | L2-Norm(final)=7.217 | 3746.3 samples/s | 58.5 steps/s
[Step=60800 Epoch=114.6] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.411 | L2-Norm(final)=7.221 | 3702.7 samples/s | 57.9 steps/s
[Step=60850 Epoch=114.7] | Loss=0.00000 | Reg=0.00108 | acc=1.0000 | L2-Norm=10.388 | L2-Norm(final)=7.224 | 3761.5 samples/s | 58.8 steps/s
[Step=60900 Epoch=114.8] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.365 | L2-Norm(final)=7.227 | 3752.3 samples/s | 58.6 steps/s
[Step=60950 Epoch=114.9] | Loss=0.00000 | Reg=0.00107 | acc=1.0000 | L2-Norm=10.342 | L2-Norm(final)=7.231 | 3703.1 samples/s | 57.9 steps/s
[Step=61000 Epoch=115.0] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.318 | L2-Norm(final)=7.234 | 3690.6 samples/s | 57.7 steps/s
[Step=61050 Epoch=115.1] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.294 | L2-Norm(final)=7.237 | 1631.8 samples/s | 25.5 steps/s
[Step=61100 Epoch=115.2] | Loss=0.00000 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.271 | L2-Norm(final)=7.240 | 3705.4 samples/s | 57.9 steps/s
[Step=61150 Epoch=115.3] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.247 | L2-Norm(final)=7.243 | 3704.7 samples/s | 57.9 steps/s
[Step=61200 Epoch=115.4] | Loss=0.00000 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.223 | L2-Norm(final)=7.247 | 3662.8 samples/s | 57.2 steps/s
[Step=61250 Epoch=115.5] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.199 | L2-Norm(final)=7.250 | 3707.0 samples/s | 57.9 steps/s
[Step=61300 Epoch=115.6] | Loss=0.00000 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.175 | L2-Norm(final)=7.254 | 3702.4 samples/s | 57.8 steps/s
[Step=61350 Epoch=115.6] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.151 | L2-Norm(final)=7.258 | 3664.3 samples/s | 57.3 steps/s
[Step=61400 Epoch=115.7] | Loss=0.00000 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.127 | L2-Norm(final)=7.262 | 3697.7 samples/s | 57.8 steps/s
[Step=61450 Epoch=115.8] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.103 | L2-Norm(final)=7.266 | 3702.6 samples/s | 57.9 steps/s
[Step=61500 Epoch=115.9] | Loss=0.00000 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.079 | L2-Norm(final)=7.270 | 3682.3 samples/s | 57.5 steps/s
[Step=61550 Epoch=116.0] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.055 | L2-Norm(final)=7.274 | 4619.4 samples/s | 72.2 steps/s
[Step=61600 Epoch=116.1] | Loss=0.00000 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.031 | L2-Norm(final)=7.278 | 1500.8 samples/s | 23.5 steps/s
[Step=61650 Epoch=116.2] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.006 | L2-Norm(final)=7.283 | 3637.6 samples/s | 56.8 steps/s
[Step=61700 Epoch=116.3] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.982 | L2-Norm(final)=7.287 | 3718.7 samples/s | 58.1 steps/s
[Step=61750 Epoch=116.4] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.957 | L2-Norm(final)=7.291 | 3665.7 samples/s | 57.3 steps/s
[Step=61800 Epoch=116.5] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.932 | L2-Norm(final)=7.295 | 3697.5 samples/s | 57.8 steps/s
[Step=61850 Epoch=116.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.907 | L2-Norm(final)=7.300 | 3718.1 samples/s | 58.1 steps/s
[Step=61900 Epoch=116.7] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.883 | L2-Norm(final)=7.305 | 3742.4 samples/s | 58.5 steps/s
[Step=61950 Epoch=116.8] | Loss=0.00008 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.861 | L2-Norm(final)=7.310 | 3702.3 samples/s | 57.8 steps/s
[Step=62000 Epoch=116.9] | Loss=0.00008 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.842 | L2-Norm(final)=7.314 | 3725.0 samples/s | 58.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step62000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05781 | acc=0.9712 | tpr=0.9767 | fpr=0.0409 | 3605.6 samples/s | 14.1 steps/s
Avg test loss: 0.05962, Avg test acc: 0.96991, Avg tpr: 0.97599, Avg fpr: 0.04346, total FA: 339

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.04902 | acc=0.3035 | tpr=0.0129 | fpr=0.0654 | 3616.2 samples/s | 14.1 steps/s
Avg test loss: 4.04940, Avg test acc: 0.30207, Avg tpr: 0.01364, Avg fpr: 0.06358, total FA: 496

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.76601 | acc=0.1447 | tpr=0.7743 | fpr=0.8666 | 3587.1 samples/s | 14.0 steps/s
[Step= 100] | Loss=4.76936 | acc=0.1473 | tpr=0.7591 | fpr=0.8641 | 6798.7 samples/s | 26.6 steps/s
[Step= 150] | Loss=4.77009 | acc=0.1462 | tpr=0.7594 | fpr=0.8650 | 6918.7 samples/s | 27.0 steps/s
[Step= 200] | Loss=4.75421 | acc=0.1457 | tpr=0.7443 | fpr=0.8652 | 6886.3 samples/s | 26.9 steps/s
[Step= 250] | Loss=4.75951 | acc=0.1456 | tpr=0.7511 | fpr=0.8655 | 6806.9 samples/s | 26.6 steps/s
[Step= 300] | Loss=4.75917 | acc=0.1460 | tpr=0.7520 | fpr=0.8651 | 6822.3 samples/s | 26.6 steps/s
[Step= 350] | Loss=4.75995 | acc=0.1455 | tpr=0.7539 | fpr=0.8656 | 6840.7 samples/s | 26.7 steps/s
[Step= 400] | Loss=4.76706 | acc=0.1450 | tpr=0.7451 | fpr=0.8659 | 6864.6 samples/s | 26.8 steps/s
[Step= 450] | Loss=4.76915 | acc=0.1450 | tpr=0.7507 | fpr=0.8660 | 6869.9 samples/s | 26.8 steps/s
[Step= 500] | Loss=4.76957 | acc=0.1454 | tpr=0.7564 | fpr=0.8657 | 6657.9 samples/s | 26.0 steps/s
[Step= 550] | Loss=4.76997 | acc=0.1455 | tpr=0.7596 | fpr=0.8656 | 12903.5 samples/s | 50.4 steps/s
Avg test loss: 4.77095, Avg test acc: 0.14545, Avg tpr: 0.75990, Avg fpr: 0.86572, total FA: 120203

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08286 | acc=0.9814 | tpr=0.9602 | fpr=0.0182 | 3596.4 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.08743 | acc=0.9803 | tpr=0.9616 | fpr=0.0193 | 6893.1 samples/s | 26.9 steps/s
[Step= 150] | Loss=0.08813 | acc=0.9798 | tpr=0.9611 | fpr=0.0199 | 6789.5 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.08980 | acc=0.9798 | tpr=0.9628 | fpr=0.0199 | 7141.1 samples/s | 27.9 steps/s
[Step= 250] | Loss=0.08909 | acc=0.9797 | tpr=0.9607 | fpr=0.0199 | 6649.8 samples/s | 26.0 steps/s
[Step= 300] | Loss=0.09076 | acc=0.9793 | tpr=0.9607 | fpr=0.0203 | 7105.5 samples/s | 27.8 steps/s
[Step= 350] | Loss=0.09068 | acc=0.9792 | tpr=0.9606 | fpr=0.0205 | 6915.7 samples/s | 27.0 steps/s
[Step= 400] | Loss=0.09112 | acc=0.9789 | tpr=0.9595 | fpr=0.0207 | 6614.7 samples/s | 25.8 steps/s
[Step= 450] | Loss=0.09310 | acc=0.9785 | tpr=0.9572 | fpr=0.0211 | 6851.9 samples/s | 26.8 steps/s
[Step= 500] | Loss=0.09284 | acc=0.9786 | tpr=0.9577 | fpr=0.0211 | 6733.3 samples/s | 26.3 steps/s
[Step= 550] | Loss=0.09234 | acc=0.9788 | tpr=0.9574 | fpr=0.0208 | 12270.7 samples/s | 47.9 steps/s
Avg test loss: 0.09213, Avg test acc: 0.97879, Avg tpr: 0.95761, Avg fpr: 0.02083, total FA: 2892

server round 31/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=60.5] | Loss=0.00976 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.997 | L2-Norm(final)=10.435 | 3195.2 samples/s | 49.9 steps/s
[Step=62050 Epoch=60.6] | Loss=0.01665 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.009 | L2-Norm(final)=10.451 | 4183.5 samples/s | 65.4 steps/s
[Step=62100 Epoch=60.6] | Loss=0.01500 | Reg=0.00100 | acc=0.9531 | L2-Norm=10.020 | L2-Norm(final)=10.471 | 4355.9 samples/s | 68.1 steps/s
[Step=62150 Epoch=60.7] | Loss=0.01512 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.029 | L2-Norm(final)=10.487 | 4322.3 samples/s | 67.5 steps/s
[Step=62200 Epoch=60.7] | Loss=0.01485 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.037 | L2-Norm(final)=10.501 | 4353.5 samples/s | 68.0 steps/s
[Step=62250 Epoch=60.8] | Loss=0.01436 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.044 | L2-Norm(final)=10.515 | 4318.8 samples/s | 67.5 steps/s
[Step=62300 Epoch=60.8] | Loss=0.01429 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.052 | L2-Norm(final)=10.528 | 4391.5 samples/s | 68.6 steps/s
[Step=62350 Epoch=60.9] | Loss=0.01417 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.059 | L2-Norm(final)=10.540 | 4487.8 samples/s | 70.1 steps/s
[Step=62400 Epoch=60.9] | Loss=0.01379 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.066 | L2-Norm(final)=10.551 | 4278.2 samples/s | 66.8 steps/s
[Step=62450 Epoch=61.0] | Loss=0.01370 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.073 | L2-Norm(final)=10.562 | 4342.0 samples/s | 67.8 steps/s
[Step=62500 Epoch=61.0] | Loss=0.01375 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.079 | L2-Norm(final)=10.572 | 4350.3 samples/s | 68.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=61.0] | Loss=0.00987 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.136 | L2-Norm(final)=10.667 | 3450.5 samples/s | 53.9 steps/s
[Step=62550 Epoch=61.1] | Loss=0.00972 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.143 | L2-Norm(final)=10.675 | 3675.9 samples/s | 57.4 steps/s
[Step=62600 Epoch=61.1] | Loss=0.00992 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.151 | L2-Norm(final)=10.683 | 3865.0 samples/s | 60.4 steps/s
[Step=62650 Epoch=61.2] | Loss=0.01043 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.159 | L2-Norm(final)=10.689 | 3928.9 samples/s | 61.4 steps/s
[Step=62700 Epoch=61.2] | Loss=0.01067 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=10.694 | 3915.1 samples/s | 61.2 steps/s
[Step=62750 Epoch=61.3] | Loss=0.01145 | Reg=0.00103 | acc=0.9688 | L2-Norm=10.171 | L2-Norm(final)=10.699 | 3907.4 samples/s | 61.1 steps/s
[Step=62800 Epoch=61.3] | Loss=0.01120 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.177 | L2-Norm(final)=10.703 | 3971.9 samples/s | 62.1 steps/s
[Step=62850 Epoch=61.4] | Loss=0.01125 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.182 | L2-Norm(final)=10.708 | 3888.5 samples/s | 60.8 steps/s
[Step=62900 Epoch=61.4] | Loss=0.01092 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.187 | L2-Norm(final)=10.713 | 3979.3 samples/s | 62.2 steps/s
[Step=62950 Epoch=61.5] | Loss=0.01126 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.192 | L2-Norm(final)=10.718 | 3891.1 samples/s | 60.8 steps/s
[Step=63000 Epoch=61.5] | Loss=0.01146 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.197 | L2-Norm(final)=10.722 | 3996.9 samples/s | 62.5 steps/s
[Step=63050 Epoch=61.6] | Loss=0.01128 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.202 | L2-Norm(final)=10.727 | 3895.4 samples/s | 60.9 steps/s
[Step=63100 Epoch=61.6] | Loss=0.01113 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.206 | L2-Norm(final)=10.731 | 3949.5 samples/s | 61.7 steps/s
[Step=63150 Epoch=61.7] | Loss=0.01108 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.211 | L2-Norm(final)=10.735 | 3975.2 samples/s | 62.1 steps/s
[Step=63200 Epoch=61.7] | Loss=0.01108 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.215 | L2-Norm(final)=10.740 | 3954.7 samples/s | 61.8 steps/s
[Step=63250 Epoch=61.8] | Loss=0.01110 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.219 | L2-Norm(final)=10.744 | 3893.2 samples/s | 60.8 steps/s
[Step=63300 Epoch=61.8] | Loss=0.01100 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.223 | L2-Norm(final)=10.748 | 3954.0 samples/s | 61.8 steps/s
[Step=63350 Epoch=61.9] | Loss=0.01090 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.228 | L2-Norm(final)=10.752 | 3942.4 samples/s | 61.6 steps/s
[Step=63400 Epoch=61.9] | Loss=0.01105 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.231 | L2-Norm(final)=10.756 | 3942.1 samples/s | 61.6 steps/s
[Step=63450 Epoch=61.9] | Loss=0.01102 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.235 | L2-Norm(final)=10.760 | 3937.6 samples/s | 61.5 steps/s
[Step=63500 Epoch=62.0] | Loss=0.01105 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.239 | L2-Norm(final)=10.764 | 4206.0 samples/s | 65.7 steps/s
[Step=63550 Epoch=62.0] | Loss=0.01082 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.243 | L2-Norm(final)=10.768 | 1704.8 samples/s | 26.6 steps/s
[Step=63600 Epoch=62.1] | Loss=0.01072 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.246 | L2-Norm(final)=10.772 | 3802.9 samples/s | 59.4 steps/s
[Step=63650 Epoch=62.1] | Loss=0.01053 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=10.776 | 3955.9 samples/s | 61.8 steps/s
[Step=63700 Epoch=62.2] | Loss=0.01045 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.254 | L2-Norm(final)=10.780 | 3861.3 samples/s | 60.3 steps/s
[Step=63750 Epoch=62.2] | Loss=0.01041 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.257 | L2-Norm(final)=10.784 | 3871.2 samples/s | 60.5 steps/s
[Step=63800 Epoch=62.3] | Loss=0.01032 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.260 | L2-Norm(final)=10.788 | 3871.2 samples/s | 60.5 steps/s
[Step=63850 Epoch=62.3] | Loss=0.01020 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.264 | L2-Norm(final)=10.792 | 3953.2 samples/s | 61.8 steps/s
[Step=63900 Epoch=62.4] | Loss=0.01015 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.267 | L2-Norm(final)=10.796 | 3905.4 samples/s | 61.0 steps/s
[Step=63950 Epoch=62.4] | Loss=0.01013 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.270 | L2-Norm(final)=10.800 | 3980.3 samples/s | 62.2 steps/s
[Step=64000 Epoch=62.5] | Loss=0.01008 | Reg=0.00106 | acc=1.0000 | L2-Norm=10.273 | L2-Norm(final)=10.803 | 3906.8 samples/s | 61.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step64000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=62001 Epoch=116.9] | Loss=0.00004 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.997 | L2-Norm(final)=7.442 | 3404.8 samples/s | 53.2 steps/s
[Step=62050 Epoch=117.0] | Loss=0.00007 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=7.444 | 3887.7 samples/s | 60.7 steps/s
[Step=62100 Epoch=117.1] | Loss=0.00006 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=7.446 | 4049.5 samples/s | 63.3 steps/s
[Step=62150 Epoch=117.2] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=7.448 | 4084.0 samples/s | 63.8 steps/s
[Step=62200 Epoch=117.2] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.996 | L2-Norm(final)=7.450 | 4057.9 samples/s | 63.4 steps/s
[Step=62250 Epoch=117.3] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.996 | L2-Norm(final)=7.452 | 4083.9 samples/s | 63.8 steps/s
[Step=62300 Epoch=117.4] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.997 | L2-Norm(final)=7.454 | 4163.8 samples/s | 65.1 steps/s
[Step=62350 Epoch=117.5] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=7.456 | 4032.6 samples/s | 63.0 steps/s
[Step=62400 Epoch=117.6] | Loss=0.00005 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=7.458 | 4161.4 samples/s | 65.0 steps/s
[Step=62450 Epoch=117.7] | Loss=0.00004 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.999 | L2-Norm(final)=7.460 | 4067.0 samples/s | 63.5 steps/s
[Step=62500 Epoch=117.8] | Loss=0.00004 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.000 | L2-Norm(final)=7.462 | 4154.2 samples/s | 64.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=62501 Epoch=117.8] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.003 | L2-Norm(final)=7.479 | 3289.9 samples/s | 51.4 steps/s
[Step=62550 Epoch=117.9] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.002 | L2-Norm(final)=7.480 | 3540.7 samples/s | 55.3 steps/s
[Step=62600 Epoch=118.0] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.000 | L2-Norm(final)=7.481 | 3694.8 samples/s | 57.7 steps/s
[Step=62650 Epoch=118.1] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=7.482 | 3667.6 samples/s | 57.3 steps/s
[Step=62700 Epoch=118.2] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.996 | L2-Norm(final)=7.483 | 3720.4 samples/s | 58.1 steps/s
[Step=62750 Epoch=118.3] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.994 | L2-Norm(final)=7.484 | 3637.1 samples/s | 56.8 steps/s
[Step=62800 Epoch=118.4] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.992 | L2-Norm(final)=7.485 | 3716.6 samples/s | 58.1 steps/s
[Step=62850 Epoch=118.5] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.990 | L2-Norm(final)=7.486 | 3706.8 samples/s | 57.9 steps/s
[Step=62900 Epoch=118.6] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.989 | L2-Norm(final)=7.487 | 3680.4 samples/s | 57.5 steps/s
[Step=62950 Epoch=118.7] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.987 | L2-Norm(final)=7.488 | 3710.0 samples/s | 58.0 steps/s
[Step=63000 Epoch=118.8] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.985 | L2-Norm(final)=7.489 | 3715.3 samples/s | 58.1 steps/s
[Step=63050 Epoch=118.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=7.490 | 1678.7 samples/s | 26.2 steps/s
[Step=63100 Epoch=118.9] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.981 | L2-Norm(final)=7.491 | 3721.8 samples/s | 58.2 steps/s
[Step=63150 Epoch=119.0] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=7.492 | 3676.7 samples/s | 57.4 steps/s
[Step=63200 Epoch=119.1] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.977 | L2-Norm(final)=7.493 | 3710.8 samples/s | 58.0 steps/s
[Step=63250 Epoch=119.2] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.975 | L2-Norm(final)=7.494 | 3704.3 samples/s | 57.9 steps/s
[Step=63300 Epoch=119.3] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.973 | L2-Norm(final)=7.494 | 3653.0 samples/s | 57.1 steps/s
[Step=63350 Epoch=119.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.971 | L2-Norm(final)=7.495 | 3749.6 samples/s | 58.6 steps/s
[Step=63400 Epoch=119.5] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.969 | L2-Norm(final)=7.496 | 3758.2 samples/s | 58.7 steps/s
[Step=63450 Epoch=119.6] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.967 | L2-Norm(final)=7.497 | 3680.3 samples/s | 57.5 steps/s
[Step=63500 Epoch=119.7] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.965 | L2-Norm(final)=7.498 | 3709.3 samples/s | 58.0 steps/s
[Step=63550 Epoch=119.8] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.963 | L2-Norm(final)=7.498 | 4534.0 samples/s | 70.8 steps/s
[Step=63600 Epoch=119.9] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.961 | L2-Norm(final)=7.499 | 1504.0 samples/s | 23.5 steps/s
[Step=63650 Epoch=120.0] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.958 | L2-Norm(final)=7.499 | 3640.3 samples/s | 56.9 steps/s
[Step=63700 Epoch=120.1] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.956 | L2-Norm(final)=7.500 | 3678.4 samples/s | 57.5 steps/s
[Step=63750 Epoch=120.2] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.954 | L2-Norm(final)=7.501 | 3733.4 samples/s | 58.3 steps/s
[Step=63800 Epoch=120.3] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.951 | L2-Norm(final)=7.501 | 3755.2 samples/s | 58.7 steps/s
[Step=63850 Epoch=120.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.949 | L2-Norm(final)=7.502 | 3658.5 samples/s | 57.2 steps/s
[Step=63900 Epoch=120.5] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.947 | L2-Norm(final)=7.502 | 3723.1 samples/s | 58.2 steps/s
[Step=63950 Epoch=120.5] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.944 | L2-Norm(final)=7.503 | 3727.1 samples/s | 58.2 steps/s
[Step=64000 Epoch=120.6] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.942 | L2-Norm(final)=7.503 | 3675.5 samples/s | 57.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step64000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05889 | acc=0.9715 | tpr=0.9782 | fpr=0.0431 | 3602.8 samples/s | 14.1 steps/s
Avg test loss: 0.05982, Avg test acc: 0.97035, Avg tpr: 0.97733, Avg fpr: 0.04499, total FA: 351

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.11113 | acc=0.3009 | tpr=0.0202 | fpr=0.0897 | 3630.4 samples/s | 14.2 steps/s
Avg test loss: 5.10657, Avg test acc: 0.30014, Avg tpr: 0.02168, Avg fpr: 0.08742, total FA: 682

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.79726 | acc=0.1336 | tpr=0.8053 | fpr=0.8785 | 3617.8 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.80190 | acc=0.1360 | tpr=0.7974 | fpr=0.8763 | 6984.9 samples/s | 27.3 steps/s
[Step= 150] | Loss=4.80263 | acc=0.1355 | tpr=0.7954 | fpr=0.8767 | 6892.8 samples/s | 26.9 steps/s
[Step= 200] | Loss=4.78648 | acc=0.1356 | tpr=0.7836 | fpr=0.8762 | 6807.8 samples/s | 26.6 steps/s
[Step= 250] | Loss=4.79105 | acc=0.1354 | tpr=0.7921 | fpr=0.8766 | 6899.1 samples/s | 26.9 steps/s
[Step= 300] | Loss=4.79022 | acc=0.1354 | tpr=0.7927 | fpr=0.8766 | 6857.9 samples/s | 26.8 steps/s
[Step= 350] | Loss=4.79150 | acc=0.1347 | tpr=0.7934 | fpr=0.8772 | 6961.5 samples/s | 27.2 steps/s
[Step= 400] | Loss=4.79780 | acc=0.1343 | tpr=0.7899 | fpr=0.8776 | 6749.2 samples/s | 26.4 steps/s
[Step= 450] | Loss=4.80086 | acc=0.1342 | tpr=0.7936 | fpr=0.8777 | 6786.6 samples/s | 26.5 steps/s
[Step= 500] | Loss=4.80185 | acc=0.1344 | tpr=0.7965 | fpr=0.8775 | 6979.9 samples/s | 27.3 steps/s
[Step= 550] | Loss=4.80225 | acc=0.1347 | tpr=0.7990 | fpr=0.8774 | 12275.5 samples/s | 48.0 steps/s
Avg test loss: 4.80317, Avg test acc: 0.13457, Avg tpr: 0.79913, Avg fpr: 0.87751, total FA: 121840

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11073 | acc=0.9818 | tpr=0.9602 | fpr=0.0178 | 3617.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.11523 | acc=0.9811 | tpr=0.9574 | fpr=0.0185 | 7039.3 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.11620 | acc=0.9804 | tpr=0.9582 | fpr=0.0191 | 6914.7 samples/s | 27.0 steps/s
[Step= 200] | Loss=0.11845 | acc=0.9806 | tpr=0.9628 | fpr=0.0191 | 6639.6 samples/s | 25.9 steps/s
[Step= 250] | Loss=0.11729 | acc=0.9807 | tpr=0.9616 | fpr=0.0189 | 7045.8 samples/s | 27.5 steps/s
[Step= 300] | Loss=0.11947 | acc=0.9804 | tpr=0.9600 | fpr=0.0192 | 6811.0 samples/s | 26.6 steps/s
[Step= 350] | Loss=0.11908 | acc=0.9803 | tpr=0.9606 | fpr=0.0193 | 6899.3 samples/s | 27.0 steps/s
[Step= 400] | Loss=0.11944 | acc=0.9801 | tpr=0.9601 | fpr=0.0195 | 6829.1 samples/s | 26.7 steps/s
[Step= 450] | Loss=0.12227 | acc=0.9798 | tpr=0.9581 | fpr=0.0198 | 6724.9 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.12181 | acc=0.9799 | tpr=0.9581 | fpr=0.0197 | 7054.1 samples/s | 27.6 steps/s
[Step= 550] | Loss=0.12130 | acc=0.9800 | tpr=0.9582 | fpr=0.0196 | 11962.9 samples/s | 46.7 steps/s
Avg test loss: 0.12102, Avg test acc: 0.98002, Avg tpr: 0.95840, Avg fpr: 0.01958, total FA: 2719

server round 32/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=62.5] | Loss=0.01750 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.072 | L2-Norm(final)=10.916 | 3264.2 samples/s | 51.0 steps/s
[Step=64050 Epoch=62.5] | Loss=0.00951 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.085 | L2-Norm(final)=10.923 | 4053.5 samples/s | 63.3 steps/s
[Step=64100 Epoch=62.6] | Loss=0.00918 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.091 | L2-Norm(final)=10.931 | 4276.6 samples/s | 66.8 steps/s
[Step=64150 Epoch=62.6] | Loss=0.00934 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.095 | L2-Norm(final)=10.938 | 4340.2 samples/s | 67.8 steps/s
[Step=64200 Epoch=62.7] | Loss=0.00903 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.099 | L2-Norm(final)=10.945 | 4274.5 samples/s | 66.8 steps/s
[Step=64250 Epoch=62.7] | Loss=0.00916 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.103 | L2-Norm(final)=10.951 | 4306.5 samples/s | 67.3 steps/s
[Step=64300 Epoch=62.8] | Loss=0.00874 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.107 | L2-Norm(final)=10.958 | 4322.0 samples/s | 67.5 steps/s
[Step=64350 Epoch=62.8] | Loss=0.00891 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.111 | L2-Norm(final)=10.964 | 4383.7 samples/s | 68.5 steps/s
[Step=64400 Epoch=62.9] | Loss=0.00888 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.114 | L2-Norm(final)=10.970 | 4347.4 samples/s | 67.9 steps/s
[Step=64450 Epoch=62.9] | Loss=0.00893 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=10.976 | 4351.7 samples/s | 68.0 steps/s
[Step=64500 Epoch=63.0] | Loss=0.00886 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.121 | L2-Norm(final)=10.983 | 4390.2 samples/s | 68.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=63.0] | Loss=0.02799 | Reg=0.00103 | acc=0.9688 | L2-Norm=10.152 | L2-Norm(final)=11.044 | 3286.1 samples/s | 51.3 steps/s
[Step=64550 Epoch=63.0] | Loss=0.00969 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.156 | L2-Norm(final)=11.050 | 3662.4 samples/s | 57.2 steps/s
[Step=64600 Epoch=63.1] | Loss=0.00883 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.161 | L2-Norm(final)=11.056 | 3870.9 samples/s | 60.5 steps/s
[Step=64650 Epoch=63.1] | Loss=0.00937 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.165 | L2-Norm(final)=11.061 | 3862.3 samples/s | 60.3 steps/s
[Step=64700 Epoch=63.2] | Loss=0.00923 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.170 | L2-Norm(final)=11.066 | 3844.2 samples/s | 60.1 steps/s
[Step=64750 Epoch=63.2] | Loss=0.00979 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.174 | L2-Norm(final)=11.071 | 3884.5 samples/s | 60.7 steps/s
[Step=64800 Epoch=63.3] | Loss=0.00984 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.178 | L2-Norm(final)=11.075 | 3894.4 samples/s | 60.9 steps/s
[Step=64850 Epoch=63.3] | Loss=0.00991 | Reg=0.00104 | acc=0.9688 | L2-Norm=10.183 | L2-Norm(final)=11.080 | 3873.6 samples/s | 60.5 steps/s
[Step=64900 Epoch=63.4] | Loss=0.00963 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.188 | L2-Norm(final)=11.085 | 3906.9 samples/s | 61.0 steps/s
[Step=64950 Epoch=63.4] | Loss=0.00949 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.193 | L2-Norm(final)=11.090 | 3914.7 samples/s | 61.2 steps/s
[Step=65000 Epoch=63.5] | Loss=0.00948 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.197 | L2-Norm(final)=11.094 | 3925.7 samples/s | 61.3 steps/s
[Step=65050 Epoch=63.5] | Loss=0.00956 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.202 | L2-Norm(final)=11.099 | 3857.3 samples/s | 60.3 steps/s
[Step=65100 Epoch=63.6] | Loss=0.00979 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.206 | L2-Norm(final)=11.103 | 3897.5 samples/s | 60.9 steps/s
[Step=65150 Epoch=63.6] | Loss=0.00960 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.210 | L2-Norm(final)=11.108 | 3902.6 samples/s | 61.0 steps/s
[Step=65200 Epoch=63.7] | Loss=0.00943 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.214 | L2-Norm(final)=11.112 | 3937.5 samples/s | 61.5 steps/s
[Step=65250 Epoch=63.7] | Loss=0.00956 | Reg=0.00104 | acc=0.9844 | L2-Norm=10.218 | L2-Norm(final)=11.117 | 3939.1 samples/s | 61.5 steps/s
[Step=65300 Epoch=63.8] | Loss=0.00952 | Reg=0.00104 | acc=1.0000 | L2-Norm=10.222 | L2-Norm(final)=11.121 | 3956.4 samples/s | 61.8 steps/s
[Step=65350 Epoch=63.8] | Loss=0.00971 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.226 | L2-Norm(final)=11.125 | 3937.9 samples/s | 61.5 steps/s
[Step=65400 Epoch=63.9] | Loss=0.00970 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.230 | L2-Norm(final)=11.129 | 3899.8 samples/s | 60.9 steps/s
[Step=65450 Epoch=63.9] | Loss=0.00975 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.234 | L2-Norm(final)=11.133 | 3917.3 samples/s | 61.2 steps/s
[Step=65500 Epoch=64.0] | Loss=0.00977 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.237 | L2-Norm(final)=11.137 | 4230.4 samples/s | 66.1 steps/s
[Step=65550 Epoch=64.0] | Loss=0.00967 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.241 | L2-Norm(final)=11.140 | 1638.2 samples/s | 25.6 steps/s
[Step=65600 Epoch=64.0] | Loss=0.00968 | Reg=0.00105 | acc=0.9531 | L2-Norm=10.244 | L2-Norm(final)=11.144 | 3882.6 samples/s | 60.7 steps/s
[Step=65650 Epoch=64.1] | Loss=0.00965 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.247 | L2-Norm(final)=11.147 | 3911.4 samples/s | 61.1 steps/s
[Step=65700 Epoch=64.1] | Loss=0.00948 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.250 | L2-Norm(final)=11.151 | 3908.3 samples/s | 61.1 steps/s
[Step=65750 Epoch=64.2] | Loss=0.00943 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.253 | L2-Norm(final)=11.155 | 3893.7 samples/s | 60.8 steps/s
[Step=65800 Epoch=64.2] | Loss=0.00940 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.256 | L2-Norm(final)=11.158 | 3938.7 samples/s | 61.5 steps/s
[Step=65850 Epoch=64.3] | Loss=0.00932 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.259 | L2-Norm(final)=11.162 | 3890.1 samples/s | 60.8 steps/s
[Step=65900 Epoch=64.3] | Loss=0.00928 | Reg=0.00105 | acc=1.0000 | L2-Norm=10.262 | L2-Norm(final)=11.165 | 3942.2 samples/s | 61.6 steps/s
[Step=65950 Epoch=64.4] | Loss=0.00916 | Reg=0.00105 | acc=0.9688 | L2-Norm=10.265 | L2-Norm(final)=11.169 | 3938.5 samples/s | 61.5 steps/s
[Step=66000 Epoch=64.4] | Loss=0.00920 | Reg=0.00105 | acc=0.9844 | L2-Norm=10.268 | L2-Norm(final)=11.172 | 3922.1 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step66000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=64001 Epoch=120.6] | Loss=0.00005 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.072 | L2-Norm(final)=7.518 | 3535.1 samples/s | 55.2 steps/s
[Step=64050 Epoch=120.7] | Loss=0.00004 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.520 | 3696.3 samples/s | 57.8 steps/s
[Step=64100 Epoch=120.8] | Loss=0.00004 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.068 | L2-Norm(final)=7.524 | 4039.0 samples/s | 63.1 steps/s
[Step=64150 Epoch=120.9] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.528 | 4145.9 samples/s | 64.8 steps/s
[Step=64200 Epoch=121.0] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.532 | 4104.0 samples/s | 64.1 steps/s
[Step=64250 Epoch=121.1] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.536 | 4093.4 samples/s | 64.0 steps/s
[Step=64300 Epoch=121.2] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.539 | 4129.2 samples/s | 64.5 steps/s
[Step=64350 Epoch=121.3] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.069 | L2-Norm(final)=7.543 | 4065.4 samples/s | 63.5 steps/s
[Step=64400 Epoch=121.4] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.068 | L2-Norm(final)=7.546 | 4079.5 samples/s | 63.7 steps/s
[Step=64450 Epoch=121.5] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.068 | L2-Norm(final)=7.549 | 4120.2 samples/s | 64.4 steps/s
[Step=64500 Epoch=121.6] | Loss=0.00002 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.067 | L2-Norm(final)=7.552 | 4189.3 samples/s | 65.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=64501 Epoch=121.6] | Loss=0.00003 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.059 | L2-Norm(final)=7.580 | 3204.5 samples/s | 50.1 steps/s
[Step=64550 Epoch=121.7] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.056 | L2-Norm(final)=7.582 | 3612.3 samples/s | 56.4 steps/s
[Step=64600 Epoch=121.8] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.052 | L2-Norm(final)=7.584 | 3683.5 samples/s | 57.6 steps/s
[Step=64650 Epoch=121.9] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.047 | L2-Norm(final)=7.585 | 3719.3 samples/s | 58.1 steps/s
[Step=64700 Epoch=122.0] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.042 | L2-Norm(final)=7.586 | 3703.5 samples/s | 57.9 steps/s
[Step=64750 Epoch=122.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.037 | L2-Norm(final)=7.587 | 3731.5 samples/s | 58.3 steps/s
[Step=64800 Epoch=122.1] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.032 | L2-Norm(final)=7.588 | 3764.0 samples/s | 58.8 steps/s
[Step=64850 Epoch=122.2] | Loss=0.00001 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.027 | L2-Norm(final)=7.589 | 3693.1 samples/s | 57.7 steps/s
[Step=64900 Epoch=122.3] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.022 | L2-Norm(final)=7.590 | 3751.5 samples/s | 58.6 steps/s
[Step=64950 Epoch=122.4] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.017 | L2-Norm(final)=7.591 | 3773.7 samples/s | 59.0 steps/s
[Step=65000 Epoch=122.5] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.011 | L2-Norm(final)=7.592 | 3769.8 samples/s | 58.9 steps/s
[Step=65050 Epoch=122.6] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.006 | L2-Norm(final)=7.593 | 1612.9 samples/s | 25.2 steps/s
[Step=65100 Epoch=122.7] | Loss=0.00001 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.001 | L2-Norm(final)=7.594 | 3744.9 samples/s | 58.5 steps/s
[Step=65150 Epoch=122.8] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=7.594 | 3712.9 samples/s | 58.0 steps/s
[Step=65200 Epoch=122.9] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.990 | L2-Norm(final)=7.595 | 3691.0 samples/s | 57.7 steps/s
[Step=65250 Epoch=123.0] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.984 | L2-Norm(final)=7.596 | 3697.1 samples/s | 57.8 steps/s
[Step=65300 Epoch=123.1] | Loss=0.00000 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.979 | L2-Norm(final)=7.597 | 3783.4 samples/s | 59.1 steps/s
[Step=65350 Epoch=123.2] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.973 | L2-Norm(final)=7.597 | 3775.7 samples/s | 59.0 steps/s
[Step=65400 Epoch=123.3] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.967 | L2-Norm(final)=7.598 | 3749.5 samples/s | 58.6 steps/s
[Step=65450 Epoch=123.4] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.961 | L2-Norm(final)=7.599 | 3706.2 samples/s | 57.9 steps/s
[Step=65500 Epoch=123.5] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.956 | L2-Norm(final)=7.600 | 3720.9 samples/s | 58.1 steps/s
[Step=65550 Epoch=123.6] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.950 | L2-Norm(final)=7.600 | 4704.0 samples/s | 73.5 steps/s
[Step=65600 Epoch=123.7] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.944 | L2-Norm(final)=7.601 | 1471.7 samples/s | 23.0 steps/s
[Step=65650 Epoch=123.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.938 | L2-Norm(final)=7.602 | 3595.2 samples/s | 56.2 steps/s
[Step=65700 Epoch=123.8] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.932 | L2-Norm(final)=7.603 | 3612.4 samples/s | 56.4 steps/s
[Step=65750 Epoch=123.9] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.925 | L2-Norm(final)=7.603 | 3551.3 samples/s | 55.5 steps/s
[Step=65800 Epoch=124.0] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.919 | L2-Norm(final)=7.604 | 3602.6 samples/s | 56.3 steps/s
[Step=65850 Epoch=124.1] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.913 | L2-Norm(final)=7.605 | 3669.3 samples/s | 57.3 steps/s
[Step=65900 Epoch=124.2] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.907 | L2-Norm(final)=7.606 | 3587.0 samples/s | 56.0 steps/s
[Step=65950 Epoch=124.3] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.900 | L2-Norm(final)=7.606 | 3611.6 samples/s | 56.4 steps/s
[Step=66000 Epoch=124.4] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.894 | L2-Norm(final)=7.607 | 3735.3 samples/s | 58.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step66000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06032 | acc=0.9711 | tpr=0.9765 | fpr=0.0406 | 3617.3 samples/s | 14.1 steps/s
Avg test loss: 0.06304, Avg test acc: 0.96971, Avg tpr: 0.97529, Avg fpr: 0.04256, total FA: 332

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.01177 | acc=0.3016 | tpr=0.0223 | fpr=0.0917 | 3624.7 samples/s | 14.2 steps/s
Avg test loss: 5.00506, Avg test acc: 0.29990, Avg tpr: 0.02349, Avg fpr: 0.09217, total FA: 719

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.03145 | acc=0.1395 | tpr=0.7655 | fpr=0.8717 | 3630.4 samples/s | 14.2 steps/s
[Step= 100] | Loss=5.03607 | acc=0.1425 | tpr=0.7548 | fpr=0.8690 | 6858.8 samples/s | 26.8 steps/s
[Step= 150] | Loss=5.03970 | acc=0.1416 | tpr=0.7522 | fpr=0.8696 | 6810.9 samples/s | 26.6 steps/s
[Step= 200] | Loss=5.02095 | acc=0.1417 | tpr=0.7421 | fpr=0.8692 | 7022.8 samples/s | 27.4 steps/s
[Step= 250] | Loss=5.02596 | acc=0.1414 | tpr=0.7424 | fpr=0.8695 | 6702.9 samples/s | 26.2 steps/s
[Step= 300] | Loss=5.02567 | acc=0.1416 | tpr=0.7433 | fpr=0.8694 | 6958.5 samples/s | 27.2 steps/s
[Step= 350] | Loss=5.02704 | acc=0.1410 | tpr=0.7445 | fpr=0.8700 | 6896.9 samples/s | 26.9 steps/s
[Step= 400] | Loss=5.03284 | acc=0.1403 | tpr=0.7374 | fpr=0.8705 | 6619.1 samples/s | 25.9 steps/s
[Step= 450] | Loss=5.03598 | acc=0.1402 | tpr=0.7434 | fpr=0.8707 | 6583.8 samples/s | 25.7 steps/s
[Step= 500] | Loss=5.03644 | acc=0.1404 | tpr=0.7485 | fpr=0.8706 | 6658.4 samples/s | 26.0 steps/s
[Step= 550] | Loss=5.03735 | acc=0.1406 | tpr=0.7549 | fpr=0.8705 | 12497.6 samples/s | 48.8 steps/s
Avg test loss: 5.03848, Avg test acc: 0.14052, Avg tpr: 0.75515, Avg fpr: 0.87066, total FA: 120889

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.11168 | acc=0.9817 | tpr=0.9646 | fpr=0.0180 | 3560.5 samples/s | 13.9 steps/s
[Step= 100] | Loss=0.11615 | acc=0.9810 | tpr=0.9616 | fpr=0.0187 | 6905.6 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.11717 | acc=0.9802 | tpr=0.9611 | fpr=0.0194 | 6938.6 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.11936 | acc=0.9804 | tpr=0.9661 | fpr=0.0193 | 6908.2 samples/s | 27.0 steps/s
[Step= 250] | Loss=0.11802 | acc=0.9805 | tpr=0.9633 | fpr=0.0192 | 6968.0 samples/s | 27.2 steps/s
[Step= 300] | Loss=0.12033 | acc=0.9801 | tpr=0.9615 | fpr=0.0196 | 6861.1 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.11992 | acc=0.9799 | tpr=0.9624 | fpr=0.0197 | 6752.7 samples/s | 26.4 steps/s
[Step= 400] | Loss=0.12027 | acc=0.9796 | tpr=0.9617 | fpr=0.0200 | 7221.7 samples/s | 28.2 steps/s
[Step= 450] | Loss=0.12314 | acc=0.9794 | tpr=0.9601 | fpr=0.0203 | 6752.2 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.12261 | acc=0.9795 | tpr=0.9612 | fpr=0.0202 | 6867.5 samples/s | 26.8 steps/s
[Step= 550] | Loss=0.12203 | acc=0.9796 | tpr=0.9610 | fpr=0.0200 | 11603.2 samples/s | 45.3 steps/s
Avg test loss: 0.12177, Avg test acc: 0.97966, Avg tpr: 0.96117, Avg fpr: 0.02001, total FA: 2778

server round 33/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=64.4] | Loss=0.00881 | Reg=0.00100 | acc=0.9844 | L2-Norm=9.985 | L2-Norm(final)=11.277 | 3491.3 samples/s | 54.6 steps/s
[Step=66050 Epoch=64.5] | Loss=0.00934 | Reg=0.00100 | acc=0.9844 | L2-Norm=9.992 | L2-Norm(final)=11.281 | 3899.2 samples/s | 60.9 steps/s
[Step=66100 Epoch=64.5] | Loss=0.00897 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.995 | L2-Norm(final)=11.287 | 4293.8 samples/s | 67.1 steps/s
[Step=66150 Epoch=64.6] | Loss=0.00894 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.998 | L2-Norm(final)=11.294 | 4334.6 samples/s | 67.7 steps/s
[Step=66200 Epoch=64.6] | Loss=0.00910 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.001 | L2-Norm(final)=11.300 | 4332.7 samples/s | 67.7 steps/s
[Step=66250 Epoch=64.7] | Loss=0.00914 | Reg=0.00100 | acc=0.9844 | L2-Norm=10.005 | L2-Norm(final)=11.306 | 4405.1 samples/s | 68.8 steps/s
[Step=66300 Epoch=64.7] | Loss=0.00879 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.008 | L2-Norm(final)=11.312 | 4324.8 samples/s | 67.6 steps/s
[Step=66350 Epoch=64.8] | Loss=0.00860 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.012 | L2-Norm(final)=11.318 | 4348.9 samples/s | 68.0 steps/s
[Step=66400 Epoch=64.8] | Loss=0.00827 | Reg=0.00100 | acc=0.9688 | L2-Norm=10.015 | L2-Norm(final)=11.325 | 4346.9 samples/s | 67.9 steps/s
[Step=66450 Epoch=64.9] | Loss=0.00814 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.019 | L2-Norm(final)=11.331 | 4318.5 samples/s | 67.5 steps/s
[Step=66500 Epoch=64.9] | Loss=0.00809 | Reg=0.00100 | acc=1.0000 | L2-Norm=10.022 | L2-Norm(final)=11.337 | 4361.1 samples/s | 68.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=64.9] | Loss=0.00348 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.054 | L2-Norm(final)=11.394 | 3308.9 samples/s | 51.7 steps/s
[Step=66550 Epoch=65.0] | Loss=0.00738 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.058 | L2-Norm(final)=11.400 | 3669.5 samples/s | 57.3 steps/s
[Step=66600 Epoch=65.0] | Loss=0.00840 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.064 | L2-Norm(final)=11.405 | 3825.2 samples/s | 59.8 steps/s
[Step=66650 Epoch=65.1] | Loss=0.00849 | Reg=0.00101 | acc=0.9844 | L2-Norm=10.069 | L2-Norm(final)=11.410 | 3885.5 samples/s | 60.7 steps/s
[Step=66700 Epoch=65.1] | Loss=0.00906 | Reg=0.00101 | acc=1.0000 | L2-Norm=10.073 | L2-Norm(final)=11.414 | 3876.8 samples/s | 60.6 steps/s
[Step=66750 Epoch=65.2] | Loss=0.00896 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.078 | L2-Norm(final)=11.418 | 3864.0 samples/s | 60.4 steps/s
[Step=66800 Epoch=65.2] | Loss=0.00924 | Reg=0.00102 | acc=0.9531 | L2-Norm=10.082 | L2-Norm(final)=11.422 | 3914.2 samples/s | 61.2 steps/s
[Step=66850 Epoch=65.3] | Loss=0.00921 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.085 | L2-Norm(final)=11.426 | 3875.0 samples/s | 60.5 steps/s
[Step=66900 Epoch=65.3] | Loss=0.00948 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.089 | L2-Norm(final)=11.430 | 3959.6 samples/s | 61.9 steps/s
[Step=66950 Epoch=65.4] | Loss=0.00927 | Reg=0.00102 | acc=0.9688 | L2-Norm=10.093 | L2-Norm(final)=11.434 | 3952.9 samples/s | 61.8 steps/s
[Step=67000 Epoch=65.4] | Loss=0.00932 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.097 | L2-Norm(final)=11.438 | 3902.6 samples/s | 61.0 steps/s
[Step=67050 Epoch=65.5] | Loss=0.00944 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.101 | L2-Norm(final)=11.442 | 3943.3 samples/s | 61.6 steps/s
[Step=67100 Epoch=65.5] | Loss=0.00929 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.104 | L2-Norm(final)=11.446 | 3884.8 samples/s | 60.7 steps/s
[Step=67150 Epoch=65.6] | Loss=0.00942 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.108 | L2-Norm(final)=11.450 | 3873.6 samples/s | 60.5 steps/s
[Step=67200 Epoch=65.6] | Loss=0.00930 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.111 | L2-Norm(final)=11.454 | 3963.5 samples/s | 61.9 steps/s
[Step=67250 Epoch=65.7] | Loss=0.00932 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.114 | L2-Norm(final)=11.458 | 3915.0 samples/s | 61.2 steps/s
[Step=67300 Epoch=65.7] | Loss=0.00934 | Reg=0.00102 | acc=1.0000 | L2-Norm=10.118 | L2-Norm(final)=11.462 | 3890.2 samples/s | 60.8 steps/s
[Step=67350 Epoch=65.8] | Loss=0.00930 | Reg=0.00102 | acc=0.9844 | L2-Norm=10.121 | L2-Norm(final)=11.466 | 3945.9 samples/s | 61.7 steps/s
[Step=67400 Epoch=65.8] | Loss=0.00925 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.124 | L2-Norm(final)=11.469 | 3913.4 samples/s | 61.1 steps/s
[Step=67450 Epoch=65.9] | Loss=0.00925 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.128 | L2-Norm(final)=11.474 | 3985.4 samples/s | 62.3 steps/s
[Step=67500 Epoch=65.9] | Loss=0.00933 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.131 | L2-Norm(final)=11.477 | 4188.2 samples/s | 65.4 steps/s
[Step=67550 Epoch=66.0] | Loss=0.00938 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.134 | L2-Norm(final)=11.481 | 1640.0 samples/s | 25.6 steps/s
[Step=67600 Epoch=66.0] | Loss=0.00931 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.137 | L2-Norm(final)=11.485 | 3961.2 samples/s | 61.9 steps/s
[Step=67650 Epoch=66.0] | Loss=0.00919 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.140 | L2-Norm(final)=11.489 | 3889.6 samples/s | 60.8 steps/s
[Step=67700 Epoch=66.1] | Loss=0.00914 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.143 | L2-Norm(final)=11.492 | 3934.6 samples/s | 61.5 steps/s
[Step=67750 Epoch=66.1] | Loss=0.00906 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.146 | L2-Norm(final)=11.496 | 3908.7 samples/s | 61.1 steps/s
[Step=67800 Epoch=66.2] | Loss=0.00898 | Reg=0.00103 | acc=0.9844 | L2-Norm=10.149 | L2-Norm(final)=11.500 | 3922.0 samples/s | 61.3 steps/s
[Step=67850 Epoch=66.2] | Loss=0.00889 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.152 | L2-Norm(final)=11.504 | 3976.5 samples/s | 62.1 steps/s
[Step=67900 Epoch=66.3] | Loss=0.00885 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.155 | L2-Norm(final)=11.507 | 3959.6 samples/s | 61.9 steps/s
[Step=67950 Epoch=66.3] | Loss=0.00878 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.158 | L2-Norm(final)=11.511 | 3919.7 samples/s | 61.2 steps/s
[Step=68000 Epoch=66.4] | Loss=0.00878 | Reg=0.00103 | acc=1.0000 | L2-Norm=10.160 | L2-Norm(final)=11.515 | 3904.7 samples/s | 61.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step68000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=66001 Epoch=124.4] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.985 | L2-Norm(final)=7.631 | 3336.7 samples/s | 52.1 steps/s
[Step=66050 Epoch=124.5] | Loss=0.00004 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=7.638 | 3829.6 samples/s | 59.8 steps/s
[Step=66100 Epoch=124.6] | Loss=0.00003 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.984 | L2-Norm(final)=7.646 | 4045.6 samples/s | 63.2 steps/s
[Step=66150 Epoch=124.7] | Loss=0.00003 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.983 | L2-Norm(final)=7.652 | 4095.7 samples/s | 64.0 steps/s
[Step=66200 Epoch=124.8] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.982 | L2-Norm(final)=7.658 | 4127.7 samples/s | 64.5 steps/s
[Step=66250 Epoch=124.9] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.980 | L2-Norm(final)=7.664 | 4127.5 samples/s | 64.5 steps/s
[Step=66300 Epoch=125.0] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.978 | L2-Norm(final)=7.669 | 4170.5 samples/s | 65.2 steps/s
[Step=66350 Epoch=125.1] | Loss=0.00002 | Reg=0.00100 | acc=1.0000 | L2-Norm=9.976 | L2-Norm(final)=7.674 | 4028.1 samples/s | 62.9 steps/s
[Step=66400 Epoch=125.2] | Loss=0.00002 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.974 | L2-Norm(final)=7.679 | 4128.4 samples/s | 64.5 steps/s
[Step=66450 Epoch=125.3] | Loss=0.00002 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.972 | L2-Norm(final)=7.684 | 4266.3 samples/s | 66.7 steps/s
[Step=66500 Epoch=125.4] | Loss=0.00002 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.970 | L2-Norm(final)=7.689 | 4093.4 samples/s | 64.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=66501 Epoch=125.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.949 | L2-Norm(final)=7.737 | 3373.0 samples/s | 52.7 steps/s
[Step=66550 Epoch=125.4] | Loss=0.00001 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.942 | L2-Norm(final)=7.740 | 3383.3 samples/s | 52.9 steps/s
[Step=66600 Epoch=125.5] | Loss=0.00000 | Reg=0.00099 | acc=1.0000 | L2-Norm=9.931 | L2-Norm(final)=7.743 | 3752.2 samples/s | 58.6 steps/s
[Step=66650 Epoch=125.6] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.919 | L2-Norm(final)=7.745 | 3670.9 samples/s | 57.4 steps/s
[Step=66700 Epoch=125.7] | Loss=0.00001 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.908 | L2-Norm(final)=7.747 | 3719.1 samples/s | 58.1 steps/s
[Step=66750 Epoch=125.8] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.896 | L2-Norm(final)=7.749 | 3714.1 samples/s | 58.0 steps/s
[Step=66800 Epoch=125.9] | Loss=0.00000 | Reg=0.00098 | acc=1.0000 | L2-Norm=9.885 | L2-Norm(final)=7.751 | 3676.3 samples/s | 57.4 steps/s
[Step=66850 Epoch=126.0] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.873 | L2-Norm(final)=7.752 | 3719.7 samples/s | 58.1 steps/s
[Step=66900 Epoch=126.1] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.861 | L2-Norm(final)=7.754 | 3721.6 samples/s | 58.2 steps/s
[Step=66950 Epoch=126.2] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.849 | L2-Norm(final)=7.756 | 3732.1 samples/s | 58.3 steps/s
[Step=67000 Epoch=126.3] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.837 | L2-Norm(final)=7.758 | 3715.2 samples/s | 58.1 steps/s
[Step=67050 Epoch=126.4] | Loss=0.00000 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.825 | L2-Norm(final)=7.760 | 1654.9 samples/s | 25.9 steps/s
[Step=67100 Epoch=126.5] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.812 | L2-Norm(final)=7.761 | 3683.5 samples/s | 57.6 steps/s
[Step=67150 Epoch=126.6] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.800 | L2-Norm(final)=7.763 | 3693.5 samples/s | 57.7 steps/s
[Step=67200 Epoch=126.7] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.787 | L2-Norm(final)=7.764 | 3697.6 samples/s | 57.8 steps/s
[Step=67250 Epoch=126.8] | Loss=0.00000 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.774 | L2-Norm(final)=7.766 | 3710.4 samples/s | 58.0 steps/s
[Step=67300 Epoch=126.9] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.761 | L2-Norm(final)=7.768 | 3713.3 samples/s | 58.0 steps/s
[Step=67350 Epoch=127.0] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.749 | L2-Norm(final)=7.769 | 3702.8 samples/s | 57.9 steps/s
[Step=67400 Epoch=127.0] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.736 | L2-Norm(final)=7.771 | 3694.8 samples/s | 57.7 steps/s
[Step=67450 Epoch=127.1] | Loss=0.00000 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.722 | L2-Norm(final)=7.772 | 3765.1 samples/s | 58.8 steps/s
[Step=67500 Epoch=127.2] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.709 | L2-Norm(final)=7.774 | 3669.1 samples/s | 57.3 steps/s
[Step=67550 Epoch=127.3] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.696 | L2-Norm(final)=7.776 | 4594.2 samples/s | 71.8 steps/s
[Step=67600 Epoch=127.4] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.682 | L2-Norm(final)=7.777 | 1515.8 samples/s | 23.7 steps/s
[Step=67650 Epoch=127.5] | Loss=0.00000 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.669 | L2-Norm(final)=7.779 | 3653.7 samples/s | 57.1 steps/s
[Step=67700 Epoch=127.6] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.655 | L2-Norm(final)=7.781 | 3640.0 samples/s | 56.9 steps/s
[Step=67750 Epoch=127.7] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=7.783 | 3708.3 samples/s | 57.9 steps/s
[Step=67800 Epoch=127.8] | Loss=0.00000 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.627 | L2-Norm(final)=7.785 | 3643.5 samples/s | 56.9 steps/s
[Step=67850 Epoch=127.9] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.613 | L2-Norm(final)=7.786 | 3708.9 samples/s | 58.0 steps/s
[Step=67900 Epoch=128.0] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.599 | L2-Norm(final)=7.788 | 3741.2 samples/s | 58.5 steps/s
[Step=67950 Epoch=128.1] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.585 | L2-Norm(final)=7.790 | 3662.5 samples/s | 57.2 steps/s
[Step=68000 Epoch=128.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.570 | L2-Norm(final)=7.792 | 3698.3 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step68000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06092 | acc=0.9702 | tpr=0.9709 | fpr=0.0315 | 3623.1 samples/s | 14.2 steps/s
Avg test loss: 0.06315, Avg test acc: 0.96903, Avg tpr: 0.96998, Avg fpr: 0.03307, total FA: 258

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.11578 | acc=0.3029 | tpr=0.0195 | fpr=0.0818 | 3589.2 samples/s | 14.0 steps/s
Avg test loss: 5.11225, Avg test acc: 0.30147, Avg tpr: 0.02034, Avg fpr: 0.08025, total FA: 626

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.47761 | acc=0.1623 | tpr=0.6770 | fpr=0.8469 | 3618.3 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.48785 | acc=0.1633 | tpr=0.6844 | fpr=0.8464 | 6878.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=4.48999 | acc=0.1621 | tpr=0.6945 | fpr=0.8477 | 6992.6 samples/s | 27.3 steps/s
[Step= 200] | Loss=4.47483 | acc=0.1617 | tpr=0.6852 | fpr=0.8478 | 6816.8 samples/s | 26.6 steps/s
[Step= 250] | Loss=4.47996 | acc=0.1613 | tpr=0.6900 | fpr=0.8483 | 6932.2 samples/s | 27.1 steps/s
[Step= 300] | Loss=4.47869 | acc=0.1610 | tpr=0.6887 | fpr=0.8486 | 6991.0 samples/s | 27.3 steps/s
[Step= 350] | Loss=4.47911 | acc=0.1604 | tpr=0.6907 | fpr=0.8492 | 6751.0 samples/s | 26.4 steps/s
[Step= 400] | Loss=4.48489 | acc=0.1601 | tpr=0.6822 | fpr=0.8493 | 6724.0 samples/s | 26.3 steps/s
[Step= 450] | Loss=4.48805 | acc=0.1600 | tpr=0.6870 | fpr=0.8495 | 6848.6 samples/s | 26.8 steps/s
[Step= 500] | Loss=4.48884 | acc=0.1603 | tpr=0.6907 | fpr=0.8493 | 6828.8 samples/s | 26.7 steps/s
[Step= 550] | Loss=4.48942 | acc=0.1602 | tpr=0.6980 | fpr=0.8495 | 12388.4 samples/s | 48.4 steps/s
Avg test loss: 4.49065, Avg test acc: 0.16013, Avg tpr: 0.69849, Avg fpr: 0.84966, total FA: 117973

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.10378 | acc=0.9822 | tpr=0.9558 | fpr=0.0173 | 3611.4 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.10833 | acc=0.9817 | tpr=0.9616 | fpr=0.0179 | 6983.1 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.10905 | acc=0.9811 | tpr=0.9611 | fpr=0.0185 | 6927.1 samples/s | 27.1 steps/s
[Step= 200] | Loss=0.11086 | acc=0.9812 | tpr=0.9661 | fpr=0.0185 | 6919.2 samples/s | 27.0 steps/s
[Step= 250] | Loss=0.10939 | acc=0.9813 | tpr=0.9633 | fpr=0.0184 | 6785.9 samples/s | 26.5 steps/s
[Step= 300] | Loss=0.11162 | acc=0.9808 | tpr=0.9615 | fpr=0.0188 | 6954.2 samples/s | 27.2 steps/s
[Step= 350] | Loss=0.11135 | acc=0.9808 | tpr=0.9624 | fpr=0.0189 | 7067.5 samples/s | 27.6 steps/s
[Step= 400] | Loss=0.11170 | acc=0.9805 | tpr=0.9617 | fpr=0.0192 | 6722.6 samples/s | 26.3 steps/s
[Step= 450] | Loss=0.11436 | acc=0.9802 | tpr=0.9601 | fpr=0.0194 | 6687.3 samples/s | 26.1 steps/s
[Step= 500] | Loss=0.11376 | acc=0.9804 | tpr=0.9617 | fpr=0.0193 | 6884.5 samples/s | 26.9 steps/s
[Step= 550] | Loss=0.11318 | acc=0.9805 | tpr=0.9610 | fpr=0.0191 | 12407.3 samples/s | 48.5 steps/s
Avg test loss: 0.11295, Avg test acc: 0.98055, Avg tpr: 0.96117, Avg fpr: 0.01910, total FA: 2652

server round 34/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=66.4] | Loss=0.00715 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.638 | L2-Norm(final)=11.619 | 3396.3 samples/s | 53.1 steps/s
[Step=68050 Epoch=66.4] | Loss=0.01029 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.645 | L2-Norm(final)=11.627 | 4005.2 samples/s | 62.6 steps/s
[Step=68100 Epoch=66.5] | Loss=0.01155 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.651 | L2-Norm(final)=11.637 | 4289.9 samples/s | 67.0 steps/s
[Step=68150 Epoch=66.5] | Loss=0.01140 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.657 | L2-Norm(final)=11.646 | 4330.2 samples/s | 67.7 steps/s
[Step=68200 Epoch=66.6] | Loss=0.01083 | Reg=0.00093 | acc=0.9844 | L2-Norm=9.662 | L2-Norm(final)=11.655 | 4314.8 samples/s | 67.4 steps/s
[Step=68250 Epoch=66.6] | Loss=0.01020 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.667 | L2-Norm(final)=11.664 | 4423.2 samples/s | 69.1 steps/s
[Step=68300 Epoch=66.7] | Loss=0.01003 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.671 | L2-Norm(final)=11.672 | 4383.6 samples/s | 68.5 steps/s
[Step=68350 Epoch=66.7] | Loss=0.00981 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.676 | L2-Norm(final)=11.680 | 4283.5 samples/s | 66.9 steps/s
[Step=68400 Epoch=66.8] | Loss=0.00967 | Reg=0.00094 | acc=0.9844 | L2-Norm=9.680 | L2-Norm(final)=11.688 | 4346.3 samples/s | 67.9 steps/s
[Step=68450 Epoch=66.8] | Loss=0.00942 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.684 | L2-Norm(final)=11.696 | 4352.1 samples/s | 68.0 steps/s
[Step=68500 Epoch=66.9] | Loss=0.00933 | Reg=0.00094 | acc=1.0000 | L2-Norm=9.688 | L2-Norm(final)=11.703 | 4322.1 samples/s | 67.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=66.9] | Loss=0.01030 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.727 | L2-Norm(final)=11.776 | 3600.8 samples/s | 56.3 steps/s
[Step=68550 Epoch=66.9] | Loss=0.00934 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.734 | L2-Norm(final)=11.783 | 3539.7 samples/s | 55.3 steps/s
[Step=68600 Epoch=67.0] | Loss=0.00923 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.740 | L2-Norm(final)=11.788 | 3960.3 samples/s | 61.9 steps/s
[Step=68650 Epoch=67.0] | Loss=0.01047 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.746 | L2-Norm(final)=11.794 | 3894.8 samples/s | 60.9 steps/s
[Step=68700 Epoch=67.1] | Loss=0.01062 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.752 | L2-Norm(final)=11.799 | 3953.2 samples/s | 61.8 steps/s
[Step=68750 Epoch=67.1] | Loss=0.01090 | Reg=0.00095 | acc=0.9844 | L2-Norm=9.758 | L2-Norm(final)=11.804 | 3903.7 samples/s | 61.0 steps/s
[Step=68800 Epoch=67.2] | Loss=0.01077 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.763 | L2-Norm(final)=11.809 | 3956.8 samples/s | 61.8 steps/s
[Step=68850 Epoch=67.2] | Loss=0.01090 | Reg=0.00095 | acc=1.0000 | L2-Norm=9.768 | L2-Norm(final)=11.814 | 3904.6 samples/s | 61.0 steps/s
[Step=68900 Epoch=67.3] | Loss=0.01088 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.773 | L2-Norm(final)=11.819 | 3949.2 samples/s | 61.7 steps/s
[Step=68950 Epoch=67.3] | Loss=0.01076 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.778 | L2-Norm(final)=11.824 | 3949.6 samples/s | 61.7 steps/s
[Step=69000 Epoch=67.4] | Loss=0.01063 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.783 | L2-Norm(final)=11.829 | 3958.8 samples/s | 61.9 steps/s
[Step=69050 Epoch=67.4] | Loss=0.01053 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.788 | L2-Norm(final)=11.834 | 3967.1 samples/s | 62.0 steps/s
[Step=69100 Epoch=67.5] | Loss=0.01054 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.793 | L2-Norm(final)=11.839 | 3951.7 samples/s | 61.7 steps/s
[Step=69150 Epoch=67.5] | Loss=0.01052 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.798 | L2-Norm(final)=11.844 | 3920.8 samples/s | 61.3 steps/s
[Step=69200 Epoch=67.6] | Loss=0.01044 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.802 | L2-Norm(final)=11.849 | 3941.5 samples/s | 61.6 steps/s
[Step=69250 Epoch=67.6] | Loss=0.01025 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.807 | L2-Norm(final)=11.854 | 3941.2 samples/s | 61.6 steps/s
[Step=69300 Epoch=67.7] | Loss=0.01021 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.811 | L2-Norm(final)=11.858 | 3919.6 samples/s | 61.2 steps/s
[Step=69350 Epoch=67.7] | Loss=0.01008 | Reg=0.00096 | acc=1.0000 | L2-Norm=9.815 | L2-Norm(final)=11.863 | 3948.2 samples/s | 61.7 steps/s
[Step=69400 Epoch=67.8] | Loss=0.00995 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.819 | L2-Norm(final)=11.868 | 3879.1 samples/s | 60.6 steps/s
[Step=69450 Epoch=67.8] | Loss=0.00992 | Reg=0.00096 | acc=0.9844 | L2-Norm=9.823 | L2-Norm(final)=11.873 | 3923.5 samples/s | 61.3 steps/s
[Step=69500 Epoch=67.9] | Loss=0.00990 | Reg=0.00097 | acc=0.9844 | L2-Norm=9.827 | L2-Norm(final)=11.877 | 4267.2 samples/s | 66.7 steps/s
[Step=69550 Epoch=67.9] | Loss=0.00980 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.831 | L2-Norm(final)=11.882 | 1645.4 samples/s | 25.7 steps/s
[Step=69600 Epoch=68.0] | Loss=0.00976 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.835 | L2-Norm(final)=11.887 | 3879.5 samples/s | 60.6 steps/s
[Step=69650 Epoch=68.0] | Loss=0.00962 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.839 | L2-Norm(final)=11.891 | 3973.1 samples/s | 62.1 steps/s
[Step=69700 Epoch=68.1] | Loss=0.00951 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.843 | L2-Norm(final)=11.896 | 3863.5 samples/s | 60.4 steps/s
[Step=69750 Epoch=68.1] | Loss=0.00941 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.846 | L2-Norm(final)=11.900 | 3920.1 samples/s | 61.3 steps/s
[Step=69800 Epoch=68.1] | Loss=0.00937 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.850 | L2-Norm(final)=11.904 | 3833.5 samples/s | 59.9 steps/s
[Step=69850 Epoch=68.2] | Loss=0.00940 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.853 | L2-Norm(final)=11.909 | 3916.6 samples/s | 61.2 steps/s
[Step=69900 Epoch=68.2] | Loss=0.00942 | Reg=0.00097 | acc=0.9844 | L2-Norm=9.856 | L2-Norm(final)=11.913 | 3926.0 samples/s | 61.3 steps/s
[Step=69950 Epoch=68.3] | Loss=0.00940 | Reg=0.00097 | acc=1.0000 | L2-Norm=9.860 | L2-Norm(final)=11.917 | 3875.8 samples/s | 60.6 steps/s
[Step=70000 Epoch=68.3] | Loss=0.00938 | Reg=0.00097 | acc=0.9844 | L2-Norm=9.863 | L2-Norm(final)=11.921 | 3936.8 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step70000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=68001 Epoch=128.2] | Loss=0.00007 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.638 | L2-Norm(final)=7.854 | 3272.2 samples/s | 51.1 steps/s
[Step=68050 Epoch=128.3] | Loss=0.00006 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.639 | L2-Norm(final)=7.874 | 3892.9 samples/s | 60.8 steps/s
[Step=68100 Epoch=128.4] | Loss=0.00004 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.649 | L2-Norm(final)=7.886 | 4108.3 samples/s | 64.2 steps/s
[Step=68150 Epoch=128.5] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.651 | L2-Norm(final)=7.894 | 4135.0 samples/s | 64.6 steps/s
[Step=68200 Epoch=128.6] | Loss=0.00003 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.650 | L2-Norm(final)=7.899 | 4030.0 samples/s | 63.0 steps/s
[Step=68250 Epoch=128.7] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.647 | L2-Norm(final)=7.903 | 4070.2 samples/s | 63.6 steps/s
[Step=68300 Epoch=128.7] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.644 | L2-Norm(final)=7.908 | 4091.0 samples/s | 63.9 steps/s
[Step=68350 Epoch=128.8] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.641 | L2-Norm(final)=7.912 | 4114.3 samples/s | 64.3 steps/s
[Step=68400 Epoch=128.9] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.637 | L2-Norm(final)=7.916 | 4104.3 samples/s | 64.1 steps/s
[Step=68450 Epoch=129.0] | Loss=0.00002 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.634 | L2-Norm(final)=7.920 | 4171.1 samples/s | 65.2 steps/s
[Step=68500 Epoch=129.1] | Loss=0.00001 | Reg=0.00093 | acc=1.0000 | L2-Norm=9.631 | L2-Norm(final)=7.923 | 4067.3 samples/s | 63.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=68501 Epoch=129.1] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.597 | L2-Norm(final)=7.962 | 3324.5 samples/s | 51.9 steps/s
[Step=68550 Epoch=129.2] | Loss=0.00000 | Reg=0.00092 | acc=1.0000 | L2-Norm=9.580 | L2-Norm(final)=7.964 | 3495.8 samples/s | 54.6 steps/s
[Step=68600 Epoch=129.3] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.557 | L2-Norm(final)=7.967 | 3741.1 samples/s | 58.5 steps/s
[Step=68650 Epoch=129.4] | Loss=0.00000 | Reg=0.00091 | acc=1.0000 | L2-Norm=9.533 | L2-Norm(final)=7.969 | 3697.0 samples/s | 57.8 steps/s
[Step=68700 Epoch=129.5] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.509 | L2-Norm(final)=7.971 | 3728.3 samples/s | 58.3 steps/s
[Step=68750 Epoch=129.6] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.486 | L2-Norm(final)=7.974 | 3712.7 samples/s | 58.0 steps/s
[Step=68800 Epoch=129.7] | Loss=0.00000 | Reg=0.00090 | acc=1.0000 | L2-Norm=9.462 | L2-Norm(final)=7.976 | 3695.6 samples/s | 57.7 steps/s
[Step=68850 Epoch=129.8] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.438 | L2-Norm(final)=7.978 | 3787.3 samples/s | 59.2 steps/s
[Step=68900 Epoch=129.9] | Loss=0.00000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.414 | L2-Norm(final)=7.980 | 3703.7 samples/s | 57.9 steps/s
[Step=68950 Epoch=130.0] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.390 | L2-Norm(final)=7.982 | 3760.0 samples/s | 58.7 steps/s
[Step=69000 Epoch=130.1] | Loss=0.00000 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.365 | L2-Norm(final)=7.985 | 3767.7 samples/s | 58.9 steps/s
[Step=69050 Epoch=130.2] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.340 | L2-Norm(final)=7.987 | 1656.4 samples/s | 25.9 steps/s
[Step=69100 Epoch=130.3] | Loss=0.00000 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.316 | L2-Norm(final)=7.989 | 3743.1 samples/s | 58.5 steps/s
[Step=69150 Epoch=130.3] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.291 | L2-Norm(final)=7.991 | 3723.1 samples/s | 58.2 steps/s
[Step=69200 Epoch=130.4] | Loss=0.00000 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.265 | L2-Norm(final)=7.993 | 3675.8 samples/s | 57.4 steps/s
[Step=69250 Epoch=130.5] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.240 | L2-Norm(final)=7.995 | 3703.6 samples/s | 57.9 steps/s
[Step=69300 Epoch=130.6] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.215 | L2-Norm(final)=7.997 | 3727.5 samples/s | 58.2 steps/s
[Step=69350 Epoch=130.7] | Loss=0.00000 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.189 | L2-Norm(final)=8.000 | 3739.2 samples/s | 58.4 steps/s
[Step=69400 Epoch=130.8] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.164 | L2-Norm(final)=8.002 | 3693.0 samples/s | 57.7 steps/s
[Step=69450 Epoch=130.9] | Loss=0.00000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.138 | L2-Norm(final)=8.005 | 3744.9 samples/s | 58.5 steps/s
[Step=69500 Epoch=131.0] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.114 | L2-Norm(final)=8.008 | 3732.8 samples/s | 58.3 steps/s
[Step=69550 Epoch=131.1] | Loss=0.00000 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=8.011 | 4683.7 samples/s | 73.2 steps/s
[Step=69600 Epoch=131.2] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.064 | L2-Norm(final)=8.014 | 1515.4 samples/s | 23.7 steps/s
[Step=69650 Epoch=131.3] | Loss=0.00000 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.040 | L2-Norm(final)=8.017 | 3668.9 samples/s | 57.3 steps/s
[Step=69700 Epoch=131.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.014 | L2-Norm(final)=8.020 | 3719.0 samples/s | 58.1 steps/s
[Step=69750 Epoch=131.5] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.989 | L2-Norm(final)=8.023 | 3717.6 samples/s | 58.1 steps/s
[Step=69800 Epoch=131.6] | Loss=0.00004 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.967 | L2-Norm(final)=8.026 | 3756.3 samples/s | 58.7 steps/s
[Step=69850 Epoch=131.7] | Loss=0.00005 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.947 | L2-Norm(final)=8.029 | 3722.7 samples/s | 58.2 steps/s
[Step=69900 Epoch=131.8] | Loss=0.00005 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.929 | L2-Norm(final)=8.032 | 3724.3 samples/s | 58.2 steps/s
[Step=69950 Epoch=131.9] | Loss=0.00005 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.912 | L2-Norm(final)=8.034 | 3730.7 samples/s | 58.3 steps/s
[Step=70000 Epoch=132.0] | Loss=0.00004 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.897 | L2-Norm(final)=8.037 | 3742.2 samples/s | 58.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step70000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05768 | acc=0.9702 | tpr=0.9750 | fpr=0.0404 | 3622.9 samples/s | 14.2 steps/s
Avg test loss: 0.05987, Avg test acc: 0.96987, Avg tpr: 0.97558, Avg fpr: 0.04269, total FA: 333

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.49945 | acc=0.3084 | tpr=0.0145 | fpr=0.0533 | 3655.1 samples/s | 14.3 steps/s
Avg test loss: 4.49916, Avg test acc: 0.30672, Avg tpr: 0.01475, Avg fpr: 0.05115, total FA: 399

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.65412 | acc=0.1477 | tpr=0.7124 | fpr=0.8625 | 3632.4 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.66345 | acc=0.1498 | tpr=0.7207 | fpr=0.8608 | 6879.6 samples/s | 26.9 steps/s
[Step= 150] | Loss=4.66625 | acc=0.1484 | tpr=0.7262 | fpr=0.8623 | 6959.2 samples/s | 27.2 steps/s
[Step= 200] | Loss=4.65114 | acc=0.1482 | tpr=0.7158 | fpr=0.8621 | 6898.5 samples/s | 26.9 steps/s
[Step= 250] | Loss=4.65717 | acc=0.1477 | tpr=0.7223 | fpr=0.8628 | 6682.1 samples/s | 26.1 steps/s
[Step= 300] | Loss=4.65527 | acc=0.1480 | tpr=0.7207 | fpr=0.8624 | 6897.3 samples/s | 26.9 steps/s
[Step= 350] | Loss=4.65590 | acc=0.1477 | tpr=0.7239 | fpr=0.8627 | 6954.5 samples/s | 27.2 steps/s
[Step= 400] | Loss=4.66168 | acc=0.1473 | tpr=0.7188 | fpr=0.8631 | 6698.0 samples/s | 26.2 steps/s
[Step= 450] | Loss=4.66497 | acc=0.1472 | tpr=0.7235 | fpr=0.8632 | 7254.5 samples/s | 28.3 steps/s
[Step= 500] | Loss=4.66565 | acc=0.1474 | tpr=0.7260 | fpr=0.8630 | 6766.6 samples/s | 26.4 steps/s
[Step= 550] | Loss=4.66624 | acc=0.1475 | tpr=0.7314 | fpr=0.8631 | 12087.9 samples/s | 47.2 steps/s
Avg test loss: 4.66746, Avg test acc: 0.14739, Avg tpr: 0.73177, Avg fpr: 0.86323, total FA: 119858

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08732 | acc=0.9813 | tpr=0.9602 | fpr=0.0183 | 3659.2 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.09126 | acc=0.9807 | tpr=0.9680 | fpr=0.0191 | 6804.6 samples/s | 26.6 steps/s
[Step= 150] | Loss=0.09221 | acc=0.9798 | tpr=0.9654 | fpr=0.0199 | 6811.0 samples/s | 26.6 steps/s
[Step= 200] | Loss=0.09312 | acc=0.9800 | tpr=0.9694 | fpr=0.0198 | 6943.2 samples/s | 27.1 steps/s
[Step= 250] | Loss=0.09232 | acc=0.9801 | tpr=0.9703 | fpr=0.0197 | 6904.6 samples/s | 27.0 steps/s
[Step= 300] | Loss=0.09398 | acc=0.9796 | tpr=0.9673 | fpr=0.0202 | 6978.1 samples/s | 27.3 steps/s
[Step= 350] | Loss=0.09426 | acc=0.9794 | tpr=0.9674 | fpr=0.0204 | 6764.7 samples/s | 26.4 steps/s
[Step= 400] | Loss=0.09492 | acc=0.9792 | tpr=0.9672 | fpr=0.0206 | 6844.2 samples/s | 26.7 steps/s
[Step= 450] | Loss=0.09729 | acc=0.9788 | tpr=0.9649 | fpr=0.0210 | 6830.8 samples/s | 26.7 steps/s
[Step= 500] | Loss=0.09696 | acc=0.9789 | tpr=0.9652 | fpr=0.0209 | 6728.1 samples/s | 26.3 steps/s
[Step= 550] | Loss=0.09639 | acc=0.9791 | tpr=0.9650 | fpr=0.0206 | 12520.1 samples/s | 48.9 steps/s
Avg test loss: 0.09618, Avg test acc: 0.97914, Avg tpr: 0.96513, Avg fpr: 0.02061, total FA: 2861

server round 35/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=68.3] | Loss=0.03002 | Reg=0.00083 | acc=0.9688 | L2-Norm=9.119 | L2-Norm(final)=12.044 | 3301.4 samples/s | 51.6 steps/s
[Step=70050 Epoch=68.4] | Loss=0.01786 | Reg=0.00083 | acc=0.9844 | L2-Norm=9.130 | L2-Norm(final)=12.059 | 4024.1 samples/s | 62.9 steps/s
[Step=70100 Epoch=68.4] | Loss=0.01697 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.140 | L2-Norm(final)=12.077 | 4315.9 samples/s | 67.4 steps/s
[Step=70150 Epoch=68.5] | Loss=0.01598 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.149 | L2-Norm(final)=12.095 | 4301.9 samples/s | 67.2 steps/s
[Step=70200 Epoch=68.5] | Loss=0.01607 | Reg=0.00084 | acc=0.9531 | L2-Norm=9.158 | L2-Norm(final)=12.112 | 4322.4 samples/s | 67.5 steps/s
[Step=70250 Epoch=68.6] | Loss=0.01579 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.166 | L2-Norm(final)=12.127 | 4319.0 samples/s | 67.5 steps/s
[Step=70300 Epoch=68.6] | Loss=0.01544 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.175 | L2-Norm(final)=12.142 | 4396.2 samples/s | 68.7 steps/s
[Step=70350 Epoch=68.7] | Loss=0.01534 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=12.155 | 4348.7 samples/s | 67.9 steps/s
[Step=70400 Epoch=68.7] | Loss=0.01498 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.190 | L2-Norm(final)=12.168 | 4289.3 samples/s | 67.0 steps/s
[Step=70450 Epoch=68.8] | Loss=0.01442 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.197 | L2-Norm(final)=12.180 | 4367.4 samples/s | 68.2 steps/s
[Step=70500 Epoch=68.8] | Loss=0.01435 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.205 | L2-Norm(final)=12.192 | 4333.7 samples/s | 67.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=68.8] | Loss=0.01167 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.275 | L2-Norm(final)=12.309 | 3475.1 samples/s | 54.3 steps/s
[Step=70550 Epoch=68.9] | Loss=0.01320 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.282 | L2-Norm(final)=12.315 | 3466.1 samples/s | 54.2 steps/s
[Step=70600 Epoch=68.9] | Loss=0.01322 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.291 | L2-Norm(final)=12.321 | 3854.2 samples/s | 60.2 steps/s
[Step=70650 Epoch=69.0] | Loss=0.01317 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.300 | L2-Norm(final)=12.328 | 3873.8 samples/s | 60.5 steps/s
[Step=70700 Epoch=69.0] | Loss=0.01339 | Reg=0.00087 | acc=0.9844 | L2-Norm=9.307 | L2-Norm(final)=12.333 | 3888.5 samples/s | 60.8 steps/s
[Step=70750 Epoch=69.1] | Loss=0.01324 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.314 | L2-Norm(final)=12.338 | 3858.1 samples/s | 60.3 steps/s
[Step=70800 Epoch=69.1] | Loss=0.01336 | Reg=0.00087 | acc=0.9844 | L2-Norm=9.320 | L2-Norm(final)=12.343 | 3938.6 samples/s | 61.5 steps/s
[Step=70850 Epoch=69.2] | Loss=0.01324 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.326 | L2-Norm(final)=12.348 | 3914.0 samples/s | 61.2 steps/s
[Step=70900 Epoch=69.2] | Loss=0.01307 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.332 | L2-Norm(final)=12.352 | 3926.6 samples/s | 61.4 steps/s
[Step=70950 Epoch=69.3] | Loss=0.01273 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.337 | L2-Norm(final)=12.357 | 3890.1 samples/s | 60.8 steps/s
[Step=71000 Epoch=69.3] | Loss=0.01244 | Reg=0.00087 | acc=0.9531 | L2-Norm=9.343 | L2-Norm(final)=12.361 | 3941.5 samples/s | 61.6 steps/s
[Step=71050 Epoch=69.4] | Loss=0.01229 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.348 | L2-Norm(final)=12.366 | 3878.4 samples/s | 60.6 steps/s
[Step=71100 Epoch=69.4] | Loss=0.01202 | Reg=0.00087 | acc=0.9844 | L2-Norm=9.353 | L2-Norm(final)=12.371 | 3949.2 samples/s | 61.7 steps/s
[Step=71150 Epoch=69.5] | Loss=0.01209 | Reg=0.00088 | acc=0.9688 | L2-Norm=9.359 | L2-Norm(final)=12.376 | 3850.7 samples/s | 60.2 steps/s
[Step=71200 Epoch=69.5] | Loss=0.01188 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.364 | L2-Norm(final)=12.381 | 3943.2 samples/s | 61.6 steps/s
[Step=71250 Epoch=69.6] | Loss=0.01168 | Reg=0.00088 | acc=0.9688 | L2-Norm=9.369 | L2-Norm(final)=12.386 | 3940.6 samples/s | 61.6 steps/s
[Step=71300 Epoch=69.6] | Loss=0.01161 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.374 | L2-Norm(final)=12.391 | 3954.9 samples/s | 61.8 steps/s
[Step=71350 Epoch=69.7] | Loss=0.01168 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.379 | L2-Norm(final)=12.396 | 3930.6 samples/s | 61.4 steps/s
[Step=71400 Epoch=69.7] | Loss=0.01167 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.384 | L2-Norm(final)=12.400 | 3914.4 samples/s | 61.2 steps/s
[Step=71450 Epoch=69.8] | Loss=0.01166 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.389 | L2-Norm(final)=12.405 | 3902.1 samples/s | 61.0 steps/s
[Step=71500 Epoch=69.8] | Loss=0.01159 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.394 | L2-Norm(final)=12.410 | 4207.6 samples/s | 65.7 steps/s
[Step=71550 Epoch=69.9] | Loss=0.01152 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.398 | L2-Norm(final)=12.414 | 1651.6 samples/s | 25.8 steps/s
[Step=71600 Epoch=69.9] | Loss=0.01136 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.402 | L2-Norm(final)=12.419 | 3940.7 samples/s | 61.6 steps/s
[Step=71650 Epoch=70.0] | Loss=0.01127 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.407 | L2-Norm(final)=12.423 | 3905.1 samples/s | 61.0 steps/s
[Step=71700 Epoch=70.0] | Loss=0.01116 | Reg=0.00089 | acc=0.9844 | L2-Norm=9.411 | L2-Norm(final)=12.427 | 3921.9 samples/s | 61.3 steps/s
[Step=71750 Epoch=70.1] | Loss=0.01106 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.415 | L2-Norm(final)=12.432 | 3926.1 samples/s | 61.3 steps/s
[Step=71800 Epoch=70.1] | Loss=0.01096 | Reg=0.00089 | acc=0.9688 | L2-Norm=9.419 | L2-Norm(final)=12.436 | 3902.8 samples/s | 61.0 steps/s
[Step=71850 Epoch=70.1] | Loss=0.01093 | Reg=0.00089 | acc=0.9844 | L2-Norm=9.423 | L2-Norm(final)=12.440 | 3883.7 samples/s | 60.7 steps/s
[Step=71900 Epoch=70.2] | Loss=0.01084 | Reg=0.00089 | acc=0.9844 | L2-Norm=9.427 | L2-Norm(final)=12.444 | 3919.4 samples/s | 61.2 steps/s
[Step=71950 Epoch=70.2] | Loss=0.01077 | Reg=0.00089 | acc=0.9688 | L2-Norm=9.431 | L2-Norm(final)=12.448 | 3976.8 samples/s | 62.1 steps/s
[Step=72000 Epoch=70.3] | Loss=0.01073 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.435 | L2-Norm(final)=12.452 | 3922.8 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step72000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=70001 Epoch=132.0] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.119 | L2-Norm(final)=8.113 | 3513.4 samples/s | 54.9 steps/s
[Step=70050 Epoch=132.0] | Loss=0.00005 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.117 | L2-Norm(final)=8.115 | 3348.7 samples/s | 52.3 steps/s
[Step=70100 Epoch=132.1] | Loss=0.00007 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.119 | L2-Norm(final)=8.119 | 4116.1 samples/s | 64.3 steps/s
[Step=70150 Epoch=132.2] | Loss=0.00006 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=8.122 | 4098.7 samples/s | 64.0 steps/s
[Step=70200 Epoch=132.3] | Loss=0.00005 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.123 | L2-Norm(final)=8.124 | 4139.4 samples/s | 64.7 steps/s
[Step=70250 Epoch=132.4] | Loss=0.00005 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.123 | L2-Norm(final)=8.127 | 4127.8 samples/s | 64.5 steps/s
[Step=70300 Epoch=132.5] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.123 | L2-Norm(final)=8.129 | 4036.1 samples/s | 63.1 steps/s
[Step=70350 Epoch=132.6] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.123 | L2-Norm(final)=8.131 | 4142.8 samples/s | 64.7 steps/s
[Step=70400 Epoch=132.7] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=8.133 | 4105.7 samples/s | 64.2 steps/s
[Step=70450 Epoch=132.8] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=8.136 | 4116.9 samples/s | 64.3 steps/s
[Step=70500 Epoch=132.9] | Loss=0.00004 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.122 | L2-Norm(final)=8.138 | 4200.4 samples/s | 65.6 steps/s
All layers training...
LR=0.00013, len=1
[Step=70501 Epoch=132.9] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.120 | L2-Norm(final)=8.159 | 3397.9 samples/s | 53.1 steps/s
[Step=70550 Epoch=133.0] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.119 | L2-Norm(final)=8.161 | 3426.1 samples/s | 53.5 steps/s
[Step=70600 Epoch=133.1] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.117 | L2-Norm(final)=8.163 | 3711.1 samples/s | 58.0 steps/s
[Step=70650 Epoch=133.2] | Loss=0.00002 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.115 | L2-Norm(final)=8.164 | 3735.1 samples/s | 58.4 steps/s
[Step=70700 Epoch=133.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.113 | L2-Norm(final)=8.166 | 3743.6 samples/s | 58.5 steps/s
[Step=70750 Epoch=133.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.110 | L2-Norm(final)=8.167 | 3707.1 samples/s | 57.9 steps/s
[Step=70800 Epoch=133.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.108 | L2-Norm(final)=8.168 | 3716.0 samples/s | 58.1 steps/s
[Step=70850 Epoch=133.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.105 | L2-Norm(final)=8.169 | 3776.1 samples/s | 59.0 steps/s
[Step=70900 Epoch=133.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.102 | L2-Norm(final)=8.170 | 3719.8 samples/s | 58.1 steps/s
[Step=70950 Epoch=133.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.100 | L2-Norm(final)=8.171 | 3688.2 samples/s | 57.6 steps/s
[Step=71000 Epoch=133.8] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.097 | L2-Norm(final)=8.172 | 3825.2 samples/s | 59.8 steps/s
[Step=71050 Epoch=133.9] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.094 | L2-Norm(final)=8.173 | 1666.2 samples/s | 26.0 steps/s
[Step=71100 Epoch=134.0] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.092 | L2-Norm(final)=8.174 | 3674.0 samples/s | 57.4 steps/s
[Step=71150 Epoch=134.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.089 | L2-Norm(final)=8.175 | 3694.7 samples/s | 57.7 steps/s
[Step=71200 Epoch=134.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.086 | L2-Norm(final)=8.176 | 3683.3 samples/s | 57.6 steps/s
[Step=71250 Epoch=134.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.083 | L2-Norm(final)=8.177 | 3675.5 samples/s | 57.4 steps/s
[Step=71300 Epoch=134.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.080 | L2-Norm(final)=8.177 | 3740.7 samples/s | 58.4 steps/s
[Step=71350 Epoch=134.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.077 | L2-Norm(final)=8.178 | 3726.1 samples/s | 58.2 steps/s
[Step=71400 Epoch=134.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.074 | L2-Norm(final)=8.179 | 3771.1 samples/s | 58.9 steps/s
[Step=71450 Epoch=134.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.071 | L2-Norm(final)=8.180 | 3738.1 samples/s | 58.4 steps/s
[Step=71500 Epoch=134.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.068 | L2-Norm(final)=8.181 | 3724.5 samples/s | 58.2 steps/s
[Step=71550 Epoch=134.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.065 | L2-Norm(final)=8.181 | 4689.8 samples/s | 73.3 steps/s
[Step=71600 Epoch=135.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.061 | L2-Norm(final)=8.182 | 1496.9 samples/s | 23.4 steps/s
[Step=71650 Epoch=135.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.058 | L2-Norm(final)=8.183 | 3677.7 samples/s | 57.5 steps/s
[Step=71700 Epoch=135.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.055 | L2-Norm(final)=8.184 | 3749.1 samples/s | 58.6 steps/s
[Step=71750 Epoch=135.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.051 | L2-Norm(final)=8.184 | 3685.9 samples/s | 57.6 steps/s
[Step=71800 Epoch=135.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.048 | L2-Norm(final)=8.185 | 3722.4 samples/s | 58.2 steps/s
[Step=71850 Epoch=135.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.044 | L2-Norm(final)=8.186 | 3714.0 samples/s | 58.0 steps/s
[Step=71900 Epoch=135.5] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.041 | L2-Norm(final)=8.187 | 3807.5 samples/s | 59.5 steps/s
[Step=71950 Epoch=135.6] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.037 | L2-Norm(final)=8.187 | 3658.7 samples/s | 57.2 steps/s
[Step=72000 Epoch=135.7] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.033 | L2-Norm(final)=8.188 | 3777.6 samples/s | 59.0 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step72000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05864 | acc=0.9707 | tpr=0.9750 | fpr=0.0387 | 3627.6 samples/s | 14.2 steps/s
Avg test loss: 0.06092, Avg test acc: 0.96987, Avg tpr: 0.97406, Avg fpr: 0.03935, total FA: 307

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.61668 | acc=0.3030 | tpr=0.0176 | fpr=0.0771 | 3597.9 samples/s | 14.1 steps/s
Avg test loss: 4.61288, Avg test acc: 0.30219, Avg tpr: 0.01883, Avg fpr: 0.07461, total FA: 582

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.46640 | acc=0.1540 | tpr=0.7611 | fpr=0.8569 | 3607.6 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.47099 | acc=0.1551 | tpr=0.7463 | fpr=0.8559 | 6992.6 samples/s | 27.3 steps/s
[Step= 150] | Loss=4.47487 | acc=0.1538 | tpr=0.7450 | fpr=0.8571 | 6851.0 samples/s | 26.8 steps/s
[Step= 200] | Loss=4.46111 | acc=0.1536 | tpr=0.7311 | fpr=0.8569 | 7093.0 samples/s | 27.7 steps/s
[Step= 250] | Loss=4.46641 | acc=0.1532 | tpr=0.7380 | fpr=0.8575 | 6755.8 samples/s | 26.4 steps/s
[Step= 300] | Loss=4.46491 | acc=0.1537 | tpr=0.7360 | fpr=0.8569 | 6894.8 samples/s | 26.9 steps/s
[Step= 350] | Loss=4.46543 | acc=0.1535 | tpr=0.7401 | fpr=0.8571 | 6785.3 samples/s | 26.5 steps/s
[Step= 400] | Loss=4.47154 | acc=0.1528 | tpr=0.7369 | fpr=0.8578 | 6836.2 samples/s | 26.7 steps/s
[Step= 450] | Loss=4.47407 | acc=0.1531 | tpr=0.7415 | fpr=0.8576 | 6900.1 samples/s | 27.0 steps/s
[Step= 500] | Loss=4.47440 | acc=0.1533 | tpr=0.7454 | fpr=0.8574 | 6571.3 samples/s | 25.7 steps/s
[Step= 550] | Loss=4.47552 | acc=0.1533 | tpr=0.7505 | fpr=0.8576 | 12450.4 samples/s | 48.6 steps/s
Avg test loss: 4.47639, Avg test acc: 0.15315, Avg tpr: 0.75079, Avg fpr: 0.85771, total FA: 119092

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09453 | acc=0.9821 | tpr=0.9558 | fpr=0.0174 | 3576.9 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.09867 | acc=0.9816 | tpr=0.9638 | fpr=0.0181 | 7048.2 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.09909 | acc=0.9809 | tpr=0.9625 | fpr=0.0188 | 6755.7 samples/s | 26.4 steps/s
[Step= 200] | Loss=0.10066 | acc=0.9811 | tpr=0.9672 | fpr=0.0187 | 6626.6 samples/s | 25.9 steps/s
[Step= 250] | Loss=0.09960 | acc=0.9811 | tpr=0.9642 | fpr=0.0186 | 6849.3 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.10153 | acc=0.9806 | tpr=0.9622 | fpr=0.0191 | 6790.7 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.10135 | acc=0.9806 | tpr=0.9631 | fpr=0.0191 | 6888.9 samples/s | 26.9 steps/s
[Step= 400] | Loss=0.10173 | acc=0.9804 | tpr=0.9623 | fpr=0.0193 | 6780.0 samples/s | 26.5 steps/s
[Step= 450] | Loss=0.10424 | acc=0.9800 | tpr=0.9601 | fpr=0.0196 | 6976.3 samples/s | 27.3 steps/s
[Step= 500] | Loss=0.10374 | acc=0.9801 | tpr=0.9612 | fpr=0.0196 | 6597.1 samples/s | 25.8 steps/s
[Step= 550] | Loss=0.10325 | acc=0.9803 | tpr=0.9614 | fpr=0.0193 | 12668.3 samples/s | 49.5 steps/s
Avg test loss: 0.10302, Avg test acc: 0.98035, Avg tpr: 0.96157, Avg fpr: 0.01931, total FA: 2681

server round 36/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=70.3] | Loss=0.01173 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.189 | L2-Norm(final)=12.575 | 3353.4 samples/s | 52.4 steps/s
[Step=72050 Epoch=70.3] | Loss=0.00994 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.198 | L2-Norm(final)=12.583 | 4154.3 samples/s | 64.9 steps/s
[Step=72100 Epoch=70.4] | Loss=0.00961 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.204 | L2-Norm(final)=12.590 | 4330.2 samples/s | 67.7 steps/s
[Step=72150 Epoch=70.4] | Loss=0.00973 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.209 | L2-Norm(final)=12.598 | 4332.3 samples/s | 67.7 steps/s
[Step=72200 Epoch=70.5] | Loss=0.00974 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.214 | L2-Norm(final)=12.607 | 4345.9 samples/s | 67.9 steps/s
[Step=72250 Epoch=70.5] | Loss=0.00944 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.219 | L2-Norm(final)=12.615 | 4342.0 samples/s | 67.8 steps/s
[Step=72300 Epoch=70.6] | Loss=0.00913 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.224 | L2-Norm(final)=12.623 | 4364.1 samples/s | 68.2 steps/s
[Step=72350 Epoch=70.6] | Loss=0.00913 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.228 | L2-Norm(final)=12.631 | 4339.1 samples/s | 67.8 steps/s
[Step=72400 Epoch=70.7] | Loss=0.00913 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.233 | L2-Norm(final)=12.639 | 4369.4 samples/s | 68.3 steps/s
[Step=72450 Epoch=70.7] | Loss=0.00892 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.238 | L2-Norm(final)=12.647 | 4351.3 samples/s | 68.0 steps/s
[Step=72500 Epoch=70.8] | Loss=0.00890 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.242 | L2-Norm(final)=12.655 | 4383.6 samples/s | 68.5 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=70.8] | Loss=0.01138 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.288 | L2-Norm(final)=12.734 | 3268.3 samples/s | 51.1 steps/s
[Step=72550 Epoch=70.8] | Loss=0.00887 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.295 | L2-Norm(final)=12.741 | 3645.2 samples/s | 57.0 steps/s
[Step=72600 Epoch=70.9] | Loss=0.00900 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.302 | L2-Norm(final)=12.747 | 3948.6 samples/s | 61.7 steps/s
[Step=72650 Epoch=70.9] | Loss=0.00965 | Reg=0.00087 | acc=0.9688 | L2-Norm=9.307 | L2-Norm(final)=12.752 | 3833.3 samples/s | 59.9 steps/s
[Step=72700 Epoch=71.0] | Loss=0.01022 | Reg=0.00087 | acc=0.9844 | L2-Norm=9.312 | L2-Norm(final)=12.756 | 3936.9 samples/s | 61.5 steps/s
[Step=72750 Epoch=71.0] | Loss=0.01013 | Reg=0.00087 | acc=0.9688 | L2-Norm=9.317 | L2-Norm(final)=12.761 | 3925.8 samples/s | 61.3 steps/s
[Step=72800 Epoch=71.1] | Loss=0.00992 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.322 | L2-Norm(final)=12.767 | 3913.9 samples/s | 61.2 steps/s
[Step=72850 Epoch=71.1] | Loss=0.00980 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.328 | L2-Norm(final)=12.772 | 3886.7 samples/s | 60.7 steps/s
[Step=72900 Epoch=71.2] | Loss=0.00974 | Reg=0.00087 | acc=0.9688 | L2-Norm=9.333 | L2-Norm(final)=12.778 | 3942.3 samples/s | 61.6 steps/s
[Step=72950 Epoch=71.2] | Loss=0.00996 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.337 | L2-Norm(final)=12.782 | 3919.1 samples/s | 61.2 steps/s
[Step=73000 Epoch=71.3] | Loss=0.00996 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.342 | L2-Norm(final)=12.787 | 3877.8 samples/s | 60.6 steps/s
[Step=73050 Epoch=71.3] | Loss=0.00988 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.347 | L2-Norm(final)=12.792 | 3905.1 samples/s | 61.0 steps/s
[Step=73100 Epoch=71.4] | Loss=0.01012 | Reg=0.00087 | acc=1.0000 | L2-Norm=9.352 | L2-Norm(final)=12.796 | 3922.6 samples/s | 61.3 steps/s
[Step=73150 Epoch=71.4] | Loss=0.01035 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.356 | L2-Norm(final)=12.800 | 3946.0 samples/s | 61.7 steps/s
[Step=73200 Epoch=71.5] | Loss=0.01034 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.361 | L2-Norm(final)=12.804 | 3958.0 samples/s | 61.8 steps/s
[Step=73250 Epoch=71.5] | Loss=0.01031 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.365 | L2-Norm(final)=12.808 | 3889.6 samples/s | 60.8 steps/s
[Step=73300 Epoch=71.6] | Loss=0.01029 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.370 | L2-Norm(final)=12.812 | 3972.7 samples/s | 62.1 steps/s
[Step=73350 Epoch=71.6] | Loss=0.01018 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.374 | L2-Norm(final)=12.816 | 3906.3 samples/s | 61.0 steps/s
[Step=73400 Epoch=71.7] | Loss=0.01017 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.379 | L2-Norm(final)=12.820 | 3948.6 samples/s | 61.7 steps/s
[Step=73450 Epoch=71.7] | Loss=0.01019 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.383 | L2-Norm(final)=12.825 | 3938.2 samples/s | 61.5 steps/s
[Step=73500 Epoch=71.8] | Loss=0.01025 | Reg=0.00088 | acc=0.9844 | L2-Norm=9.387 | L2-Norm(final)=12.829 | 4215.1 samples/s | 65.9 steps/s
[Step=73550 Epoch=71.8] | Loss=0.01023 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.391 | L2-Norm(final)=12.833 | 1675.9 samples/s | 26.2 steps/s
[Step=73600 Epoch=71.9] | Loss=0.01022 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.396 | L2-Norm(final)=12.837 | 3862.9 samples/s | 60.4 steps/s
[Step=73650 Epoch=71.9] | Loss=0.01013 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.400 | L2-Norm(final)=12.840 | 3897.8 samples/s | 60.9 steps/s
[Step=73700 Epoch=72.0] | Loss=0.01005 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.403 | L2-Norm(final)=12.844 | 3914.3 samples/s | 61.2 steps/s
[Step=73750 Epoch=72.0] | Loss=0.01003 | Reg=0.00088 | acc=1.0000 | L2-Norm=9.407 | L2-Norm(final)=12.848 | 3928.1 samples/s | 61.4 steps/s
[Step=73800 Epoch=72.1] | Loss=0.00998 | Reg=0.00089 | acc=0.9844 | L2-Norm=9.411 | L2-Norm(final)=12.852 | 3891.4 samples/s | 60.8 steps/s
[Step=73850 Epoch=72.1] | Loss=0.01000 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.415 | L2-Norm(final)=12.855 | 3967.9 samples/s | 62.0 steps/s
[Step=73900 Epoch=72.2] | Loss=0.00990 | Reg=0.00089 | acc=0.9844 | L2-Norm=9.418 | L2-Norm(final)=12.859 | 3901.5 samples/s | 61.0 steps/s
[Step=73950 Epoch=72.2] | Loss=0.00985 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.422 | L2-Norm(final)=12.863 | 3942.6 samples/s | 61.6 steps/s
[Step=74000 Epoch=72.2] | Loss=0.00984 | Reg=0.00089 | acc=1.0000 | L2-Norm=9.426 | L2-Norm(final)=12.867 | 3916.9 samples/s | 61.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step74000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=72001 Epoch=135.7] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.189 | L2-Norm(final)=8.210 | 3375.8 samples/s | 52.7 steps/s
[Step=72050 Epoch=135.8] | Loss=0.00006 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.187 | L2-Norm(final)=8.216 | 3863.1 samples/s | 60.4 steps/s
[Step=72100 Epoch=135.9] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.187 | L2-Norm(final)=8.223 | 4082.1 samples/s | 63.8 steps/s
[Step=72150 Epoch=136.0] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.187 | L2-Norm(final)=8.229 | 4148.9 samples/s | 64.8 steps/s
[Step=72200 Epoch=136.1] | Loss=0.00004 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=8.234 | 4035.5 samples/s | 63.1 steps/s
[Step=72250 Epoch=136.2] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.186 | L2-Norm(final)=8.239 | 4063.5 samples/s | 63.5 steps/s
[Step=72300 Epoch=136.3] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.185 | L2-Norm(final)=8.245 | 4148.8 samples/s | 64.8 steps/s
[Step=72350 Epoch=136.4] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.184 | L2-Norm(final)=8.249 | 4160.6 samples/s | 65.0 steps/s
[Step=72400 Epoch=136.5] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=8.254 | 4119.5 samples/s | 64.4 steps/s
[Step=72450 Epoch=136.6] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.181 | L2-Norm(final)=8.258 | 4218.9 samples/s | 65.9 steps/s
[Step=72500 Epoch=136.7] | Loss=0.00003 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.180 | L2-Norm(final)=8.263 | 4105.0 samples/s | 64.1 steps/s
All layers training...
LR=0.00013, len=1
[Step=72501 Epoch=136.7] | Loss=0.00002 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.166 | L2-Norm(final)=8.307 | 3439.6 samples/s | 53.7 steps/s
[Step=72550 Epoch=136.8] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.161 | L2-Norm(final)=8.310 | 3350.0 samples/s | 52.3 steps/s
[Step=72600 Epoch=136.9] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.155 | L2-Norm(final)=8.313 | 3674.2 samples/s | 57.4 steps/s
[Step=72650 Epoch=136.9] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.148 | L2-Norm(final)=8.315 | 3738.9 samples/s | 58.4 steps/s
[Step=72700 Epoch=137.0] | Loss=0.00001 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.141 | L2-Norm(final)=8.318 | 3721.0 samples/s | 58.1 steps/s
[Step=72750 Epoch=137.1] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.134 | L2-Norm(final)=8.320 | 3683.7 samples/s | 57.6 steps/s
[Step=72800 Epoch=137.2] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.127 | L2-Norm(final)=8.322 | 3732.7 samples/s | 58.3 steps/s
[Step=72850 Epoch=137.3] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.120 | L2-Norm(final)=8.324 | 3734.9 samples/s | 58.4 steps/s
[Step=72900 Epoch=137.4] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.113 | L2-Norm(final)=8.326 | 3743.7 samples/s | 58.5 steps/s
[Step=72950 Epoch=137.5] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.105 | L2-Norm(final)=8.328 | 3727.5 samples/s | 58.2 steps/s
[Step=73000 Epoch=137.6] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.098 | L2-Norm(final)=8.329 | 3791.8 samples/s | 59.2 steps/s
[Step=73050 Epoch=137.7] | Loss=0.00001 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.090 | L2-Norm(final)=8.331 | 1645.3 samples/s | 25.7 steps/s
[Step=73100 Epoch=137.8] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.082 | L2-Norm(final)=8.333 | 3750.9 samples/s | 58.6 steps/s
[Step=73150 Epoch=137.9] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.075 | L2-Norm(final)=8.334 | 3717.8 samples/s | 58.1 steps/s
[Step=73200 Epoch=138.0] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.067 | L2-Norm(final)=8.336 | 3678.4 samples/s | 57.5 steps/s
[Step=73250 Epoch=138.1] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.059 | L2-Norm(final)=8.337 | 3750.2 samples/s | 58.6 steps/s
[Step=73300 Epoch=138.2] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.051 | L2-Norm(final)=8.339 | 3732.4 samples/s | 58.3 steps/s
[Step=73350 Epoch=138.3] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.043 | L2-Norm(final)=8.340 | 3720.2 samples/s | 58.1 steps/s
[Step=73400 Epoch=138.4] | Loss=0.00001 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.035 | L2-Norm(final)=8.342 | 3658.7 samples/s | 57.2 steps/s
[Step=73450 Epoch=138.5] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.026 | L2-Norm(final)=8.343 | 3700.0 samples/s | 57.8 steps/s
[Step=73500 Epoch=138.5] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.018 | L2-Norm(final)=8.345 | 3744.1 samples/s | 58.5 steps/s
[Step=73550 Epoch=138.6] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.010 | L2-Norm(final)=8.346 | 4710.1 samples/s | 73.6 steps/s
[Step=73600 Epoch=138.7] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.001 | L2-Norm(final)=8.347 | 1523.9 samples/s | 23.8 steps/s
[Step=73650 Epoch=138.8] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.992 | L2-Norm(final)=8.349 | 3667.9 samples/s | 57.3 steps/s
[Step=73700 Epoch=138.9] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.984 | L2-Norm(final)=8.350 | 3728.5 samples/s | 58.3 steps/s
[Step=73750 Epoch=139.0] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.975 | L2-Norm(final)=8.351 | 3657.7 samples/s | 57.2 steps/s
[Step=73800 Epoch=139.1] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.966 | L2-Norm(final)=8.353 | 3657.4 samples/s | 57.1 steps/s
[Step=73850 Epoch=139.2] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.957 | L2-Norm(final)=8.354 | 3740.6 samples/s | 58.4 steps/s
[Step=73900 Epoch=139.3] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.948 | L2-Norm(final)=8.355 | 3665.8 samples/s | 57.3 steps/s
[Step=73950 Epoch=139.4] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.939 | L2-Norm(final)=8.357 | 3724.3 samples/s | 58.2 steps/s
[Step=74000 Epoch=139.5] | Loss=0.00000 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.929 | L2-Norm(final)=8.358 | 3642.9 samples/s | 56.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step74000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06122 | acc=0.9694 | tpr=0.9717 | fpr=0.0357 | 3587.1 samples/s | 14.0 steps/s
Avg test loss: 0.06280, Avg test acc: 0.96855, Avg tpr: 0.97074, Avg fpr: 0.03628, total FA: 283

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.80472 | acc=0.3038 | tpr=0.0199 | fpr=0.0795 | 3597.5 samples/s | 14.1 steps/s
Avg test loss: 4.80277, Avg test acc: 0.30271, Avg tpr: 0.02034, Avg fpr: 0.07627, total FA: 595

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.62820 | acc=0.1512 | tpr=0.7301 | fpr=0.8592 | 3595.6 samples/s | 14.0 steps/s
[Step= 100] | Loss=4.63463 | acc=0.1534 | tpr=0.7292 | fpr=0.8573 | 6799.7 samples/s | 26.6 steps/s
[Step= 150] | Loss=4.63892 | acc=0.1525 | tpr=0.7320 | fpr=0.8582 | 6844.1 samples/s | 26.7 steps/s
[Step= 200] | Loss=4.62309 | acc=0.1523 | tpr=0.7169 | fpr=0.8579 | 6893.0 samples/s | 26.9 steps/s
[Step= 250] | Loss=4.62850 | acc=0.1519 | tpr=0.7249 | fpr=0.8585 | 6844.3 samples/s | 26.7 steps/s
[Step= 300] | Loss=4.62556 | acc=0.1527 | tpr=0.7244 | fpr=0.8578 | 6872.3 samples/s | 26.8 steps/s
[Step= 350] | Loss=4.62547 | acc=0.1523 | tpr=0.7270 | fpr=0.8581 | 6742.5 samples/s | 26.3 steps/s
[Step= 400] | Loss=4.63125 | acc=0.1519 | tpr=0.7216 | fpr=0.8585 | 6766.8 samples/s | 26.4 steps/s
[Step= 450] | Loss=4.63459 | acc=0.1518 | tpr=0.7254 | fpr=0.8586 | 6874.5 samples/s | 26.9 steps/s
[Step= 500] | Loss=4.63463 | acc=0.1520 | tpr=0.7286 | fpr=0.8584 | 6741.8 samples/s | 26.3 steps/s
[Step= 550] | Loss=4.63537 | acc=0.1521 | tpr=0.7342 | fpr=0.8585 | 12622.5 samples/s | 49.3 steps/s
Avg test loss: 4.63633, Avg test acc: 0.15196, Avg tpr: 0.73455, Avg fpr: 0.85863, total FA: 119219

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09970 | acc=0.9819 | tpr=0.9646 | fpr=0.0178 | 3621.0 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.10411 | acc=0.9813 | tpr=0.9680 | fpr=0.0185 | 6916.1 samples/s | 27.0 steps/s
[Step= 150] | Loss=0.10455 | acc=0.9805 | tpr=0.9654 | fpr=0.0192 | 6750.0 samples/s | 26.4 steps/s
[Step= 200] | Loss=0.10629 | acc=0.9808 | tpr=0.9705 | fpr=0.0190 | 6933.4 samples/s | 27.1 steps/s
[Step= 250] | Loss=0.10501 | acc=0.9807 | tpr=0.9668 | fpr=0.0190 | 7061.9 samples/s | 27.6 steps/s
[Step= 300] | Loss=0.10703 | acc=0.9803 | tpr=0.9651 | fpr=0.0194 | 6829.5 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.10680 | acc=0.9803 | tpr=0.9656 | fpr=0.0195 | 6857.6 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.10712 | acc=0.9800 | tpr=0.9644 | fpr=0.0197 | 6927.3 samples/s | 27.1 steps/s
[Step= 450] | Loss=0.10974 | acc=0.9797 | tpr=0.9625 | fpr=0.0200 | 6762.9 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.10920 | acc=0.9798 | tpr=0.9634 | fpr=0.0199 | 6811.1 samples/s | 26.6 steps/s
[Step= 550] | Loss=0.10865 | acc=0.9800 | tpr=0.9634 | fpr=0.0197 | 12718.4 samples/s | 49.7 steps/s
Avg test loss: 0.10843, Avg test acc: 0.97998, Avg tpr: 0.96355, Avg fpr: 0.01972, total FA: 2738

server round 37/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=72.3] | Loss=0.00631 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.039 | L2-Norm(final)=12.978 | 3249.3 samples/s | 50.8 steps/s
[Step=74050 Epoch=72.3] | Loss=0.01049 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.047 | L2-Norm(final)=12.985 | 4257.7 samples/s | 66.5 steps/s
[Step=74100 Epoch=72.3] | Loss=0.00903 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.053 | L2-Norm(final)=12.994 | 4323.0 samples/s | 67.5 steps/s
[Step=74150 Epoch=72.4] | Loss=0.00874 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.059 | L2-Norm(final)=13.003 | 4365.6 samples/s | 68.2 steps/s
[Step=74200 Epoch=72.4] | Loss=0.00900 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.064 | L2-Norm(final)=13.011 | 4317.7 samples/s | 67.5 steps/s
[Step=74250 Epoch=72.5] | Loss=0.00855 | Reg=0.00082 | acc=0.9844 | L2-Norm=9.069 | L2-Norm(final)=13.020 | 4349.6 samples/s | 68.0 steps/s
[Step=74300 Epoch=72.5] | Loss=0.00875 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.074 | L2-Norm(final)=13.028 | 4283.5 samples/s | 66.9 steps/s
[Step=74350 Epoch=72.6] | Loss=0.00883 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.078 | L2-Norm(final)=13.036 | 4344.5 samples/s | 67.9 steps/s
[Step=74400 Epoch=72.6] | Loss=0.00895 | Reg=0.00082 | acc=0.9688 | L2-Norm=9.083 | L2-Norm(final)=13.043 | 4413.3 samples/s | 69.0 steps/s
[Step=74450 Epoch=72.7] | Loss=0.00884 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.087 | L2-Norm(final)=13.050 | 4395.2 samples/s | 68.7 steps/s
[Step=74500 Epoch=72.7] | Loss=0.00880 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.092 | L2-Norm(final)=13.057 | 4354.3 samples/s | 68.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=72.7] | Loss=0.00738 | Reg=0.00083 | acc=1.0000 | L2-Norm=9.135 | L2-Norm(final)=13.126 | 3378.9 samples/s | 52.8 steps/s
[Step=74550 Epoch=72.8] | Loss=0.01009 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.142 | L2-Norm(final)=13.132 | 3640.6 samples/s | 56.9 steps/s
[Step=74600 Epoch=72.8] | Loss=0.00888 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.148 | L2-Norm(final)=13.136 | 3951.6 samples/s | 61.7 steps/s
[Step=74650 Epoch=72.9] | Loss=0.01022 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.154 | L2-Norm(final)=13.142 | 3882.2 samples/s | 60.7 steps/s
[Step=74700 Epoch=72.9] | Loss=0.01015 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.160 | L2-Norm(final)=13.147 | 3928.9 samples/s | 61.4 steps/s
[Step=74750 Epoch=73.0] | Loss=0.01082 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.166 | L2-Norm(final)=13.152 | 3849.8 samples/s | 60.2 steps/s
[Step=74800 Epoch=73.0] | Loss=0.01066 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.172 | L2-Norm(final)=13.157 | 3932.9 samples/s | 61.5 steps/s
[Step=74850 Epoch=73.1] | Loss=0.01021 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.177 | L2-Norm(final)=13.161 | 3932.3 samples/s | 61.4 steps/s
[Step=74900 Epoch=73.1] | Loss=0.01000 | Reg=0.00084 | acc=1.0000 | L2-Norm=9.182 | L2-Norm(final)=13.166 | 3918.7 samples/s | 61.2 steps/s
[Step=74950 Epoch=73.2] | Loss=0.00998 | Reg=0.00084 | acc=0.9844 | L2-Norm=9.187 | L2-Norm(final)=13.171 | 3963.4 samples/s | 61.9 steps/s
[Step=75000 Epoch=73.2] | Loss=0.00983 | Reg=0.00084 | acc=0.9688 | L2-Norm=9.191 | L2-Norm(final)=13.175 | 3932.1 samples/s | 61.4 steps/s
[Step=75050 Epoch=73.3] | Loss=0.00985 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.196 | L2-Norm(final)=13.180 | 3957.4 samples/s | 61.8 steps/s
[Step=75100 Epoch=73.3] | Loss=0.00989 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.200 | L2-Norm(final)=13.185 | 3896.7 samples/s | 60.9 steps/s
[Step=75150 Epoch=73.4] | Loss=0.01001 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.205 | L2-Norm(final)=13.190 | 3946.1 samples/s | 61.7 steps/s
[Step=75200 Epoch=73.4] | Loss=0.01005 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.209 | L2-Norm(final)=13.194 | 3862.3 samples/s | 60.3 steps/s
[Step=75250 Epoch=73.5] | Loss=0.00996 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.214 | L2-Norm(final)=13.198 | 3933.0 samples/s | 61.5 steps/s
[Step=75300 Epoch=73.5] | Loss=0.00992 | Reg=0.00085 | acc=0.9844 | L2-Norm=9.218 | L2-Norm(final)=13.202 | 3963.7 samples/s | 61.9 steps/s
[Step=75350 Epoch=73.6] | Loss=0.00995 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.223 | L2-Norm(final)=13.207 | 3935.6 samples/s | 61.5 steps/s
[Step=75400 Epoch=73.6] | Loss=0.00992 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.227 | L2-Norm(final)=13.211 | 3953.9 samples/s | 61.8 steps/s
[Step=75450 Epoch=73.7] | Loss=0.00986 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.231 | L2-Norm(final)=13.215 | 3905.0 samples/s | 61.0 steps/s
[Step=75500 Epoch=73.7] | Loss=0.00987 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.235 | L2-Norm(final)=13.219 | 4226.1 samples/s | 66.0 steps/s
[Step=75550 Epoch=73.8] | Loss=0.00993 | Reg=0.00085 | acc=0.9688 | L2-Norm=9.239 | L2-Norm(final)=13.223 | 1642.4 samples/s | 25.7 steps/s
[Step=75600 Epoch=73.8] | Loss=0.00991 | Reg=0.00085 | acc=1.0000 | L2-Norm=9.243 | L2-Norm(final)=13.227 | 3812.8 samples/s | 59.6 steps/s
[Step=75650 Epoch=73.9] | Loss=0.00986 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.247 | L2-Norm(final)=13.231 | 3840.5 samples/s | 60.0 steps/s
[Step=75700 Epoch=73.9] | Loss=0.00972 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.251 | L2-Norm(final)=13.235 | 3896.4 samples/s | 60.9 steps/s
[Step=75750 Epoch=74.0] | Loss=0.00965 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.254 | L2-Norm(final)=13.239 | 3940.9 samples/s | 61.6 steps/s
[Step=75800 Epoch=74.0] | Loss=0.00960 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.258 | L2-Norm(final)=13.243 | 3875.5 samples/s | 60.6 steps/s
[Step=75850 Epoch=74.1] | Loss=0.00965 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.262 | L2-Norm(final)=13.247 | 3927.9 samples/s | 61.4 steps/s
[Step=75900 Epoch=74.1] | Loss=0.00956 | Reg=0.00086 | acc=0.9844 | L2-Norm=9.265 | L2-Norm(final)=13.251 | 3909.9 samples/s | 61.1 steps/s
[Step=75950 Epoch=74.2] | Loss=0.00954 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.269 | L2-Norm(final)=13.255 | 3896.3 samples/s | 60.9 steps/s
[Step=76000 Epoch=74.2] | Loss=0.00946 | Reg=0.00086 | acc=1.0000 | L2-Norm=9.272 | L2-Norm(final)=13.259 | 3915.7 samples/s | 61.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step76000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=74001 Epoch=139.5] | Loss=0.00006 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.039 | L2-Norm(final)=8.402 | 3412.6 samples/s | 53.3 steps/s
[Step=74050 Epoch=139.6] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.034 | L2-Norm(final)=8.413 | 3623.6 samples/s | 56.6 steps/s
[Step=74100 Epoch=139.7] | Loss=0.00003 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.032 | L2-Norm(final)=8.424 | 4069.1 samples/s | 63.6 steps/s
[Step=74150 Epoch=139.8] | Loss=0.00002 | Reg=0.00082 | acc=1.0000 | L2-Norm=9.029 | L2-Norm(final)=8.434 | 4053.7 samples/s | 63.3 steps/s
[Step=74200 Epoch=139.9] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.026 | L2-Norm(final)=8.443 | 4068.5 samples/s | 63.6 steps/s
[Step=74250 Epoch=140.0] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.023 | L2-Norm(final)=8.452 | 4070.5 samples/s | 63.6 steps/s
[Step=74300 Epoch=140.1] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.020 | L2-Norm(final)=8.460 | 4163.9 samples/s | 65.1 steps/s
[Step=74350 Epoch=140.2] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.017 | L2-Norm(final)=8.469 | 4050.8 samples/s | 63.3 steps/s
[Step=74400 Epoch=140.2] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.014 | L2-Norm(final)=8.477 | 4119.9 samples/s | 64.4 steps/s
[Step=74450 Epoch=140.3] | Loss=0.00002 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.011 | L2-Norm(final)=8.484 | 4081.1 samples/s | 63.8 steps/s
[Step=74500 Epoch=140.4] | Loss=0.00001 | Reg=0.00081 | acc=1.0000 | L2-Norm=9.007 | L2-Norm(final)=8.491 | 4157.7 samples/s | 65.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=74501 Epoch=140.4] | Loss=0.00000 | Reg=0.00081 | acc=1.0000 | L2-Norm=8.972 | L2-Norm(final)=8.560 | 3263.5 samples/s | 51.0 steps/s
[Step=74550 Epoch=140.5] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.961 | L2-Norm(final)=8.566 | 3504.8 samples/s | 54.8 steps/s
[Step=74600 Epoch=140.6] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.947 | L2-Norm(final)=8.570 | 3655.3 samples/s | 57.1 steps/s
[Step=74650 Epoch=140.7] | Loss=0.00001 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.931 | L2-Norm(final)=8.574 | 3726.2 samples/s | 58.2 steps/s
[Step=74700 Epoch=140.8] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.914 | L2-Norm(final)=8.577 | 3659.7 samples/s | 57.2 steps/s
[Step=74750 Epoch=140.9] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.898 | L2-Norm(final)=8.580 | 3746.3 samples/s | 58.5 steps/s
[Step=74800 Epoch=141.0] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.881 | L2-Norm(final)=8.583 | 3674.8 samples/s | 57.4 steps/s
[Step=74850 Epoch=141.1] | Loss=0.00000 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.865 | L2-Norm(final)=8.586 | 3669.6 samples/s | 57.3 steps/s
[Step=74900 Epoch=141.2] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.848 | L2-Norm(final)=8.588 | 3768.0 samples/s | 58.9 steps/s
[Step=74950 Epoch=141.3] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.831 | L2-Norm(final)=8.591 | 3718.2 samples/s | 58.1 steps/s
[Step=75000 Epoch=141.4] | Loss=0.00000 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.814 | L2-Norm(final)=8.594 | 3723.9 samples/s | 58.2 steps/s
[Step=75050 Epoch=141.5] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.797 | L2-Norm(final)=8.597 | 1606.1 samples/s | 25.1 steps/s
[Step=75100 Epoch=141.6] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.780 | L2-Norm(final)=8.599 | 3708.6 samples/s | 57.9 steps/s
[Step=75150 Epoch=141.7] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.763 | L2-Norm(final)=8.602 | 3647.2 samples/s | 57.0 steps/s
[Step=75200 Epoch=141.8] | Loss=0.00000 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.746 | L2-Norm(final)=8.605 | 3643.1 samples/s | 56.9 steps/s
[Step=75250 Epoch=141.8] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.728 | L2-Norm(final)=8.608 | 3740.3 samples/s | 58.4 steps/s
[Step=75300 Epoch=141.9] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=8.610 | 3737.0 samples/s | 58.4 steps/s
[Step=75350 Epoch=142.0] | Loss=0.00000 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.693 | L2-Norm(final)=8.613 | 3685.0 samples/s | 57.6 steps/s
[Step=75400 Epoch=142.1] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.675 | L2-Norm(final)=8.616 | 3757.8 samples/s | 58.7 steps/s
[Step=75450 Epoch=142.2] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.658 | L2-Norm(final)=8.619 | 3706.2 samples/s | 57.9 steps/s
[Step=75500 Epoch=142.3] | Loss=0.00000 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.640 | L2-Norm(final)=8.622 | 3741.7 samples/s | 58.5 steps/s
[Step=75550 Epoch=142.4] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.622 | L2-Norm(final)=8.625 | 4630.3 samples/s | 72.3 steps/s
[Step=75600 Epoch=142.5] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.604 | L2-Norm(final)=8.628 | 1521.3 samples/s | 23.8 steps/s
[Step=75650 Epoch=142.6] | Loss=0.00000 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.586 | L2-Norm(final)=8.632 | 3681.3 samples/s | 57.5 steps/s
[Step=75700 Epoch=142.7] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.568 | L2-Norm(final)=8.635 | 3670.8 samples/s | 57.4 steps/s
[Step=75750 Epoch=142.8] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.550 | L2-Norm(final)=8.638 | 3718.1 samples/s | 58.1 steps/s
[Step=75800 Epoch=142.9] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.531 | L2-Norm(final)=8.642 | 3703.6 samples/s | 57.9 steps/s
[Step=75850 Epoch=143.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.513 | L2-Norm(final)=8.645 | 3693.8 samples/s | 57.7 steps/s
[Step=75900 Epoch=143.1] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.495 | L2-Norm(final)=8.649 | 3763.1 samples/s | 58.8 steps/s
[Step=75950 Epoch=143.2] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.477 | L2-Norm(final)=8.653 | 3719.2 samples/s | 58.1 steps/s
[Step=76000 Epoch=143.3] | Loss=0.00004 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.460 | L2-Norm(final)=8.658 | 3728.8 samples/s | 58.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step76000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06405 | acc=0.9703 | tpr=0.9712 | fpr=0.0317 | 3720.2 samples/s | 14.5 steps/s
Avg test loss: 0.06523, Avg test acc: 0.96923, Avg tpr: 0.97074, Avg fpr: 0.03410, total FA: 266

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.10554 | acc=0.3123 | tpr=0.0170 | fpr=0.0463 | 3620.8 samples/s | 14.1 steps/s
Avg test loss: 4.10180, Avg test acc: 0.30992, Avg tpr: 0.01708, Avg fpr: 0.04602, total FA: 359

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.82402 | acc=0.1487 | tpr=0.7389 | fpr=0.8619 | 3610.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.82999 | acc=0.1518 | tpr=0.7271 | fpr=0.8589 | 6955.5 samples/s | 27.2 steps/s
[Step= 150] | Loss=4.83263 | acc=0.1504 | tpr=0.7305 | fpr=0.8603 | 6984.2 samples/s | 27.3 steps/s
[Step= 200] | Loss=4.81505 | acc=0.1504 | tpr=0.7213 | fpr=0.8600 | 6784.1 samples/s | 26.5 steps/s
[Step= 250] | Loss=4.82149 | acc=0.1499 | tpr=0.7284 | fpr=0.8606 | 6912.4 samples/s | 27.0 steps/s
[Step= 300] | Loss=4.81905 | acc=0.1503 | tpr=0.7287 | fpr=0.8603 | 6982.1 samples/s | 27.3 steps/s
[Step= 350] | Loss=4.81824 | acc=0.1500 | tpr=0.7326 | fpr=0.8606 | 6654.9 samples/s | 26.0 steps/s
[Step= 400] | Loss=4.82407 | acc=0.1496 | tpr=0.7281 | fpr=0.8609 | 6787.4 samples/s | 26.5 steps/s
[Step= 450] | Loss=4.82788 | acc=0.1495 | tpr=0.7322 | fpr=0.8611 | 6795.1 samples/s | 26.5 steps/s
[Step= 500] | Loss=4.82864 | acc=0.1498 | tpr=0.7335 | fpr=0.8607 | 6855.0 samples/s | 26.8 steps/s
[Step= 550] | Loss=4.82902 | acc=0.1499 | tpr=0.7402 | fpr=0.8608 | 12584.4 samples/s | 49.2 steps/s
Avg test loss: 4.83002, Avg test acc: 0.14980, Avg tpr: 0.74049, Avg fpr: 0.86094, total FA: 119540

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.06733 | acc=0.9838 | tpr=0.9558 | fpr=0.0157 | 3623.2 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.06956 | acc=0.9831 | tpr=0.9552 | fpr=0.0164 | 7113.4 samples/s | 27.8 steps/s
[Step= 150] | Loss=0.07007 | acc=0.9826 | tpr=0.9553 | fpr=0.0169 | 6655.0 samples/s | 26.0 steps/s
[Step= 200] | Loss=0.07116 | acc=0.9825 | tpr=0.9596 | fpr=0.0171 | 6887.6 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.07012 | acc=0.9824 | tpr=0.9555 | fpr=0.0171 | 6886.5 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.07134 | acc=0.9820 | tpr=0.9520 | fpr=0.0174 | 6887.8 samples/s | 26.9 steps/s
[Step= 350] | Loss=0.07140 | acc=0.9818 | tpr=0.9537 | fpr=0.0176 | 6872.5 samples/s | 26.8 steps/s
[Step= 400] | Loss=0.07188 | acc=0.9818 | tpr=0.9540 | fpr=0.0177 | 6790.5 samples/s | 26.5 steps/s
[Step= 450] | Loss=0.07361 | acc=0.9815 | tpr=0.9523 | fpr=0.0180 | 6916.5 samples/s | 27.0 steps/s
[Step= 500] | Loss=0.07311 | acc=0.9816 | tpr=0.9537 | fpr=0.0179 | 6619.3 samples/s | 25.9 steps/s
[Step= 550] | Loss=0.07267 | acc=0.9817 | tpr=0.9530 | fpr=0.0177 | 12629.0 samples/s | 49.3 steps/s
Avg test loss: 0.07254, Avg test acc: 0.98174, Avg tpr: 0.95325, Avg fpr: 0.01774, total FA: 2463

server round 38/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=74.2] | Loss=0.00622 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.606 | L2-Norm(final)=13.378 | 3319.8 samples/s | 51.9 steps/s
[Step=76050 Epoch=74.3] | Loss=0.01826 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.618 | L2-Norm(final)=13.396 | 4102.5 samples/s | 64.1 steps/s
[Step=76100 Epoch=74.3] | Loss=0.01651 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.632 | L2-Norm(final)=13.415 | 4284.7 samples/s | 66.9 steps/s
[Step=76150 Epoch=74.3] | Loss=0.01610 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.643 | L2-Norm(final)=13.433 | 4298.3 samples/s | 67.2 steps/s
[Step=76200 Epoch=74.4] | Loss=0.01504 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.654 | L2-Norm(final)=13.450 | 4256.8 samples/s | 66.5 steps/s
[Step=76250 Epoch=74.4] | Loss=0.01455 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.664 | L2-Norm(final)=13.465 | 4367.1 samples/s | 68.2 steps/s
[Step=76300 Epoch=74.5] | Loss=0.01452 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.673 | L2-Norm(final)=13.480 | 4338.0 samples/s | 67.8 steps/s
[Step=76350 Epoch=74.5] | Loss=0.01424 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.683 | L2-Norm(final)=13.493 | 4397.1 samples/s | 68.7 steps/s
[Step=76400 Epoch=74.6] | Loss=0.01376 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.692 | L2-Norm(final)=13.506 | 4289.2 samples/s | 67.0 steps/s
[Step=76450 Epoch=74.6] | Loss=0.01400 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.700 | L2-Norm(final)=13.518 | 4432.8 samples/s | 69.3 steps/s
[Step=76500 Epoch=74.7] | Loss=0.01373 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=13.530 | 4215.6 samples/s | 65.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=74.7] | Loss=0.00718 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.786 | L2-Norm(final)=13.642 | 3224.6 samples/s | 50.4 steps/s
[Step=76550 Epoch=74.7] | Loss=0.01010 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.794 | L2-Norm(final)=13.650 | 3878.1 samples/s | 60.6 steps/s
[Step=76600 Epoch=74.8] | Loss=0.01359 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.803 | L2-Norm(final)=13.656 | 3847.3 samples/s | 60.1 steps/s
[Step=76650 Epoch=74.8] | Loss=0.01350 | Reg=0.00078 | acc=0.9844 | L2-Norm=8.811 | L2-Norm(final)=13.660 | 3919.2 samples/s | 61.2 steps/s
[Step=76700 Epoch=74.9] | Loss=0.01410 | Reg=0.00078 | acc=0.9844 | L2-Norm=8.819 | L2-Norm(final)=13.664 | 3895.4 samples/s | 60.9 steps/s
[Step=76750 Epoch=74.9] | Loss=0.01422 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.825 | L2-Norm(final)=13.667 | 3887.0 samples/s | 60.7 steps/s
[Step=76800 Epoch=75.0] | Loss=0.01422 | Reg=0.00078 | acc=0.9844 | L2-Norm=8.832 | L2-Norm(final)=13.671 | 3926.2 samples/s | 61.3 steps/s
[Step=76850 Epoch=75.0] | Loss=0.01424 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.839 | L2-Norm(final)=13.675 | 3920.9 samples/s | 61.3 steps/s
[Step=76900 Epoch=75.1] | Loss=0.01388 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.845 | L2-Norm(final)=13.680 | 3970.1 samples/s | 62.0 steps/s
[Step=76950 Epoch=75.1] | Loss=0.01361 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.852 | L2-Norm(final)=13.684 | 3909.9 samples/s | 61.1 steps/s
[Step=77000 Epoch=75.2] | Loss=0.01360 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.858 | L2-Norm(final)=13.688 | 3924.8 samples/s | 61.3 steps/s
[Step=77050 Epoch=75.2] | Loss=0.01343 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.864 | L2-Norm(final)=13.693 | 3891.7 samples/s | 60.8 steps/s
[Step=77100 Epoch=75.3] | Loss=0.01317 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.870 | L2-Norm(final)=13.697 | 3992.3 samples/s | 62.4 steps/s
[Step=77150 Epoch=75.3] | Loss=0.01292 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.875 | L2-Norm(final)=13.701 | 3905.5 samples/s | 61.0 steps/s
[Step=77200 Epoch=75.4] | Loss=0.01284 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.881 | L2-Norm(final)=13.705 | 3942.3 samples/s | 61.6 steps/s
[Step=77250 Epoch=75.4] | Loss=0.01288 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.886 | L2-Norm(final)=13.709 | 3939.0 samples/s | 61.5 steps/s
[Step=77300 Epoch=75.5] | Loss=0.01270 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.891 | L2-Norm(final)=13.712 | 3924.5 samples/s | 61.3 steps/s
[Step=77350 Epoch=75.5] | Loss=0.01274 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.896 | L2-Norm(final)=13.716 | 3933.7 samples/s | 61.5 steps/s
[Step=77400 Epoch=75.6] | Loss=0.01259 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.901 | L2-Norm(final)=13.720 | 3951.5 samples/s | 61.7 steps/s
[Step=77450 Epoch=75.6] | Loss=0.01246 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.905 | L2-Norm(final)=13.724 | 3920.2 samples/s | 61.3 steps/s
[Step=77500 Epoch=75.7] | Loss=0.01244 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.910 | L2-Norm(final)=13.727 | 4250.2 samples/s | 66.4 steps/s
[Step=77550 Epoch=75.7] | Loss=0.01225 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.914 | L2-Norm(final)=13.731 | 1627.9 samples/s | 25.4 steps/s
[Step=77600 Epoch=75.8] | Loss=0.01219 | Reg=0.00080 | acc=0.9688 | L2-Norm=8.919 | L2-Norm(final)=13.734 | 3907.8 samples/s | 61.1 steps/s
[Step=77650 Epoch=75.8] | Loss=0.01214 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.923 | L2-Norm(final)=13.738 | 3848.6 samples/s | 60.1 steps/s
[Step=77700 Epoch=75.9] | Loss=0.01210 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.927 | L2-Norm(final)=13.741 | 3898.2 samples/s | 60.9 steps/s
[Step=77750 Epoch=75.9] | Loss=0.01190 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.931 | L2-Norm(final)=13.745 | 3872.0 samples/s | 60.5 steps/s
[Step=77800 Epoch=76.0] | Loss=0.01177 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.935 | L2-Norm(final)=13.748 | 3926.8 samples/s | 61.4 steps/s
[Step=77850 Epoch=76.0] | Loss=0.01163 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.939 | L2-Norm(final)=13.752 | 3876.9 samples/s | 60.6 steps/s
[Step=77900 Epoch=76.1] | Loss=0.01150 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.943 | L2-Norm(final)=13.756 | 3930.1 samples/s | 61.4 steps/s
[Step=77950 Epoch=76.1] | Loss=0.01138 | Reg=0.00080 | acc=0.9688 | L2-Norm=8.947 | L2-Norm(final)=13.759 | 3922.9 samples/s | 61.3 steps/s
[Step=78000 Epoch=76.2] | Loss=0.01136 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.951 | L2-Norm(final)=13.763 | 3933.6 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step78000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=76001 Epoch=143.3] | Loss=0.00041 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.606 | L2-Norm(final)=8.794 | 3355.5 samples/s | 52.4 steps/s
[Step=76050 Epoch=143.4] | Loss=0.00110 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.660 | L2-Norm(final)=8.800 | 3735.3 samples/s | 58.4 steps/s
[Step=76100 Epoch=143.4] | Loss=0.00080 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.682 | L2-Norm(final)=8.815 | 4053.9 samples/s | 63.3 steps/s
[Step=76150 Epoch=143.5] | Loss=0.00060 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.695 | L2-Norm(final)=8.827 | 4144.1 samples/s | 64.8 steps/s
[Step=76200 Epoch=143.6] | Loss=0.00048 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.705 | L2-Norm(final)=8.837 | 4193.9 samples/s | 65.5 steps/s
[Step=76250 Epoch=143.7] | Loss=0.00044 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.713 | L2-Norm(final)=8.846 | 4041.2 samples/s | 63.1 steps/s
[Step=76300 Epoch=143.8] | Loss=0.00038 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.718 | L2-Norm(final)=8.854 | 4094.4 samples/s | 64.0 steps/s
[Step=76350 Epoch=143.9] | Loss=0.00035 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.723 | L2-Norm(final)=8.861 | 4142.0 samples/s | 64.7 steps/s
[Step=76400 Epoch=144.0] | Loss=0.00031 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.726 | L2-Norm(final)=8.867 | 4112.2 samples/s | 64.3 steps/s
[Step=76450 Epoch=144.1] | Loss=0.00029 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.729 | L2-Norm(final)=8.874 | 4127.7 samples/s | 64.5 steps/s
[Step=76500 Epoch=144.2] | Loss=0.00027 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.732 | L2-Norm(final)=8.879 | 4142.8 samples/s | 64.7 steps/s
All layers training...
LR=0.00013, len=1
[Step=76501 Epoch=144.2] | Loss=0.00004 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.756 | L2-Norm(final)=8.937 | 3197.1 samples/s | 50.0 steps/s
[Step=76550 Epoch=144.3] | Loss=0.00004 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.756 | L2-Norm(final)=8.941 | 3522.0 samples/s | 55.0 steps/s
[Step=76600 Epoch=144.4] | Loss=0.00004 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.754 | L2-Norm(final)=8.944 | 3747.1 samples/s | 58.5 steps/s
[Step=76650 Epoch=144.5] | Loss=0.00004 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.752 | L2-Norm(final)=8.946 | 3674.1 samples/s | 57.4 steps/s
[Step=76700 Epoch=144.6] | Loss=0.00004 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.749 | L2-Norm(final)=8.949 | 3699.4 samples/s | 57.8 steps/s
[Step=76750 Epoch=144.7] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.746 | L2-Norm(final)=8.950 | 3685.3 samples/s | 57.6 steps/s
[Step=76800 Epoch=144.8] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.743 | L2-Norm(final)=8.952 | 3694.3 samples/s | 57.7 steps/s
[Step=76850 Epoch=144.9] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.740 | L2-Norm(final)=8.953 | 3740.6 samples/s | 58.4 steps/s
[Step=76900 Epoch=145.0] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.736 | L2-Norm(final)=8.955 | 3767.8 samples/s | 58.9 steps/s
[Step=76950 Epoch=145.1] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.733 | L2-Norm(final)=8.956 | 3703.1 samples/s | 57.9 steps/s
[Step=77000 Epoch=145.1] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.730 | L2-Norm(final)=8.957 | 3774.2 samples/s | 59.0 steps/s
[Step=77050 Epoch=145.2] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.726 | L2-Norm(final)=8.958 | 1667.7 samples/s | 26.1 steps/s
[Step=77100 Epoch=145.3] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.722 | L2-Norm(final)=8.958 | 3728.5 samples/s | 58.3 steps/s
[Step=77150 Epoch=145.4] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.719 | L2-Norm(final)=8.959 | 3707.4 samples/s | 57.9 steps/s
[Step=77200 Epoch=145.5] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=8.960 | 3694.8 samples/s | 57.7 steps/s
[Step=77250 Epoch=145.6] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=8.961 | 3735.5 samples/s | 58.4 steps/s
[Step=77300 Epoch=145.7] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.707 | L2-Norm(final)=8.961 | 3712.8 samples/s | 58.0 steps/s
[Step=77350 Epoch=145.8] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.703 | L2-Norm(final)=8.962 | 3742.9 samples/s | 58.5 steps/s
[Step=77400 Epoch=145.9] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.699 | L2-Norm(final)=8.963 | 3706.0 samples/s | 57.9 steps/s
[Step=77450 Epoch=146.0] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.695 | L2-Norm(final)=8.963 | 3691.0 samples/s | 57.7 steps/s
[Step=77500 Epoch=146.1] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.691 | L2-Norm(final)=8.964 | 3749.2 samples/s | 58.6 steps/s
[Step=77550 Epoch=146.2] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.687 | L2-Norm(final)=8.965 | 4718.8 samples/s | 73.7 steps/s
[Step=77600 Epoch=146.3] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.683 | L2-Norm(final)=8.965 | 1489.2 samples/s | 23.3 steps/s
[Step=77650 Epoch=146.4] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.679 | L2-Norm(final)=8.966 | 3742.3 samples/s | 58.5 steps/s
[Step=77700 Epoch=146.5] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.675 | L2-Norm(final)=8.967 | 3664.4 samples/s | 57.3 steps/s
[Step=77750 Epoch=146.6] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.671 | L2-Norm(final)=8.967 | 3705.7 samples/s | 57.9 steps/s
[Step=77800 Epoch=146.7] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.666 | L2-Norm(final)=8.968 | 3691.6 samples/s | 57.7 steps/s
[Step=77850 Epoch=146.7] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.662 | L2-Norm(final)=8.968 | 3731.1 samples/s | 58.3 steps/s
[Step=77900 Epoch=146.8] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.658 | L2-Norm(final)=8.969 | 3746.9 samples/s | 58.5 steps/s
[Step=77950 Epoch=146.9] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.653 | L2-Norm(final)=8.969 | 3715.9 samples/s | 58.1 steps/s
[Step=78000 Epoch=147.0] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.649 | L2-Norm(final)=8.970 | 3756.3 samples/s | 58.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step78000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05721 | acc=0.9697 | tpr=0.9738 | fpr=0.0391 | 3670.1 samples/s | 14.3 steps/s
Avg test loss: 0.05927, Avg test acc: 0.96931, Avg tpr: 0.97348, Avg fpr: 0.03987, total FA: 311

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.86100 | acc=0.3030 | tpr=0.0201 | fpr=0.0825 | 3641.6 samples/s | 14.2 steps/s
Avg test loss: 4.85282, Avg test acc: 0.30207, Avg tpr: 0.02069, Avg fpr: 0.07909, total FA: 617

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.23448 | acc=0.1575 | tpr=0.7699 | fpr=0.8535 | 3615.2 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.24183 | acc=0.1589 | tpr=0.7676 | fpr=0.8524 | 6954.2 samples/s | 27.2 steps/s
[Step= 150] | Loss=4.24539 | acc=0.1581 | tpr=0.7651 | fpr=0.8531 | 6815.9 samples/s | 26.6 steps/s
[Step= 200] | Loss=4.23050 | acc=0.1580 | tpr=0.7530 | fpr=0.8528 | 6835.5 samples/s | 26.7 steps/s
[Step= 250] | Loss=4.23454 | acc=0.1576 | tpr=0.7624 | fpr=0.8534 | 6870.4 samples/s | 26.8 steps/s
[Step= 300] | Loss=4.23210 | acc=0.1582 | tpr=0.7636 | fpr=0.8529 | 6842.5 samples/s | 26.7 steps/s
[Step= 350] | Loss=4.23187 | acc=0.1581 | tpr=0.7708 | fpr=0.8531 | 6860.5 samples/s | 26.8 steps/s
[Step= 400] | Loss=4.23643 | acc=0.1577 | tpr=0.7653 | fpr=0.8534 | 6790.5 samples/s | 26.5 steps/s
[Step= 450] | Loss=4.23963 | acc=0.1576 | tpr=0.7683 | fpr=0.8535 | 6713.4 samples/s | 26.2 steps/s
[Step= 500] | Loss=4.23854 | acc=0.1579 | tpr=0.7718 | fpr=0.8532 | 6697.2 samples/s | 26.2 steps/s
[Step= 550] | Loss=4.23886 | acc=0.1577 | tpr=0.7760 | fpr=0.8535 | 12284.3 samples/s | 48.0 steps/s
Avg test loss: 4.23957, Avg test acc: 0.15763, Avg tpr: 0.77575, Avg fpr: 0.85361, total FA: 118522

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09902 | acc=0.9830 | tpr=0.9602 | fpr=0.0165 | 3596.0 samples/s | 14.0 steps/s
[Step= 100] | Loss=0.10304 | acc=0.9821 | tpr=0.9638 | fpr=0.0176 | 7030.8 samples/s | 27.5 steps/s
[Step= 150] | Loss=0.10367 | acc=0.9815 | tpr=0.9625 | fpr=0.0181 | 6769.8 samples/s | 26.4 steps/s
[Step= 200] | Loss=0.10552 | acc=0.9814 | tpr=0.9661 | fpr=0.0183 | 6846.4 samples/s | 26.7 steps/s
[Step= 250] | Loss=0.10415 | acc=0.9814 | tpr=0.9616 | fpr=0.0183 | 6883.8 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.10593 | acc=0.9810 | tpr=0.9585 | fpr=0.0186 | 6817.1 samples/s | 26.6 steps/s
[Step= 350] | Loss=0.10597 | acc=0.9809 | tpr=0.9593 | fpr=0.0187 | 7006.9 samples/s | 27.4 steps/s
[Step= 400] | Loss=0.10635 | acc=0.9807 | tpr=0.9590 | fpr=0.0189 | 6657.3 samples/s | 26.0 steps/s
[Step= 450] | Loss=0.10879 | acc=0.9804 | tpr=0.9572 | fpr=0.0192 | 6933.7 samples/s | 27.1 steps/s
[Step= 500] | Loss=0.10817 | acc=0.9804 | tpr=0.9586 | fpr=0.0192 | 6647.5 samples/s | 26.0 steps/s
[Step= 550] | Loss=0.10756 | acc=0.9807 | tpr=0.9586 | fpr=0.0189 | 13005.3 samples/s | 50.8 steps/s
Avg test loss: 0.10732, Avg test acc: 0.98067, Avg tpr: 0.95880, Avg fpr: 0.01893, total FA: 2629

server round 39/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=76.2] | Loss=0.00374 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.721 | L2-Norm(final)=13.872 | 3152.9 samples/s | 49.3 steps/s
[Step=78050 Epoch=76.2] | Loss=0.01268 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.738 | L2-Norm(final)=13.879 | 4163.3 samples/s | 65.1 steps/s
[Step=78100 Epoch=76.3] | Loss=0.01134 | Reg=0.00077 | acc=0.9844 | L2-Norm=8.748 | L2-Norm(final)=13.887 | 4296.1 samples/s | 67.1 steps/s
[Step=78150 Epoch=76.3] | Loss=0.01086 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.755 | L2-Norm(final)=13.897 | 4346.6 samples/s | 67.9 steps/s
[Step=78200 Epoch=76.3] | Loss=0.01088 | Reg=0.00077 | acc=0.9844 | L2-Norm=8.761 | L2-Norm(final)=13.906 | 4279.0 samples/s | 66.9 steps/s
[Step=78250 Epoch=76.4] | Loss=0.01048 | Reg=0.00077 | acc=0.9688 | L2-Norm=8.766 | L2-Norm(final)=13.914 | 4312.2 samples/s | 67.4 steps/s
[Step=78300 Epoch=76.4] | Loss=0.01042 | Reg=0.00077 | acc=0.9844 | L2-Norm=8.772 | L2-Norm(final)=13.923 | 4323.3 samples/s | 67.6 steps/s
[Step=78350 Epoch=76.5] | Loss=0.01034 | Reg=0.00077 | acc=0.9844 | L2-Norm=8.777 | L2-Norm(final)=13.930 | 4372.5 samples/s | 68.3 steps/s
[Step=78400 Epoch=76.5] | Loss=0.01035 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.783 | L2-Norm(final)=13.938 | 4354.5 samples/s | 68.0 steps/s
[Step=78450 Epoch=76.6] | Loss=0.01041 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.788 | L2-Norm(final)=13.945 | 4366.0 samples/s | 68.2 steps/s
[Step=78500 Epoch=76.6] | Loss=0.01038 | Reg=0.00077 | acc=1.0000 | L2-Norm=8.793 | L2-Norm(final)=13.952 | 4354.2 samples/s | 68.0 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=76.6] | Loss=0.01980 | Reg=0.00078 | acc=0.9844 | L2-Norm=8.844 | L2-Norm(final)=14.020 | 3398.8 samples/s | 53.1 steps/s
[Step=78550 Epoch=76.7] | Loss=0.01117 | Reg=0.00078 | acc=1.0000 | L2-Norm=8.852 | L2-Norm(final)=14.025 | 3623.4 samples/s | 56.6 steps/s
[Step=78600 Epoch=76.7] | Loss=0.01110 | Reg=0.00078 | acc=0.9844 | L2-Norm=8.858 | L2-Norm(final)=14.030 | 3871.2 samples/s | 60.5 steps/s
[Step=78650 Epoch=76.8] | Loss=0.01085 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.863 | L2-Norm(final)=14.034 | 3868.1 samples/s | 60.4 steps/s
[Step=78700 Epoch=76.8] | Loss=0.01036 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.869 | L2-Norm(final)=14.039 | 3914.4 samples/s | 61.2 steps/s
[Step=78750 Epoch=76.9] | Loss=0.01046 | Reg=0.00079 | acc=0.9531 | L2-Norm=8.875 | L2-Norm(final)=14.043 | 3926.4 samples/s | 61.4 steps/s
[Step=78800 Epoch=76.9] | Loss=0.01106 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.880 | L2-Norm(final)=14.046 | 3926.2 samples/s | 61.3 steps/s
[Step=78850 Epoch=77.0] | Loss=0.01106 | Reg=0.00079 | acc=0.9688 | L2-Norm=8.884 | L2-Norm(final)=14.049 | 3929.3 samples/s | 61.4 steps/s
[Step=78900 Epoch=77.0] | Loss=0.01078 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.888 | L2-Norm(final)=14.052 | 3941.5 samples/s | 61.6 steps/s
[Step=78950 Epoch=77.1] | Loss=0.01054 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.892 | L2-Norm(final)=14.056 | 3987.0 samples/s | 62.3 steps/s
[Step=79000 Epoch=77.1] | Loss=0.01056 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.897 | L2-Norm(final)=14.059 | 3895.5 samples/s | 60.9 steps/s
[Step=79050 Epoch=77.2] | Loss=0.01039 | Reg=0.00079 | acc=1.0000 | L2-Norm=8.901 | L2-Norm(final)=14.063 | 3890.3 samples/s | 60.8 steps/s
[Step=79100 Epoch=77.2] | Loss=0.01044 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.905 | L2-Norm(final)=14.066 | 3950.5 samples/s | 61.7 steps/s
[Step=79150 Epoch=77.3] | Loss=0.01043 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.909 | L2-Norm(final)=14.069 | 3995.2 samples/s | 62.4 steps/s
[Step=79200 Epoch=77.3] | Loss=0.01034 | Reg=0.00079 | acc=0.9844 | L2-Norm=8.913 | L2-Norm(final)=14.073 | 3903.8 samples/s | 61.0 steps/s
[Step=79250 Epoch=77.4] | Loss=0.01032 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.917 | L2-Norm(final)=14.076 | 3945.1 samples/s | 61.6 steps/s
[Step=79300 Epoch=77.4] | Loss=0.01051 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.922 | L2-Norm(final)=14.079 | 3912.6 samples/s | 61.1 steps/s
[Step=79350 Epoch=77.5] | Loss=0.01051 | Reg=0.00080 | acc=0.9688 | L2-Norm=8.926 | L2-Norm(final)=14.083 | 3936.9 samples/s | 61.5 steps/s
[Step=79400 Epoch=77.5] | Loss=0.01057 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.930 | L2-Norm(final)=14.086 | 3936.8 samples/s | 61.5 steps/s
[Step=79450 Epoch=77.6] | Loss=0.01062 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.933 | L2-Norm(final)=14.089 | 3846.8 samples/s | 60.1 steps/s
[Step=79500 Epoch=77.6] | Loss=0.01070 | Reg=0.00080 | acc=0.9688 | L2-Norm=8.937 | L2-Norm(final)=14.092 | 4247.0 samples/s | 66.4 steps/s
[Step=79550 Epoch=77.7] | Loss=0.01067 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.941 | L2-Norm(final)=14.095 | 1640.7 samples/s | 25.6 steps/s
[Step=79600 Epoch=77.7] | Loss=0.01052 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.945 | L2-Norm(final)=14.098 | 3874.4 samples/s | 60.5 steps/s
[Step=79650 Epoch=77.8] | Loss=0.01037 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.949 | L2-Norm(final)=14.102 | 3899.9 samples/s | 60.9 steps/s
[Step=79700 Epoch=77.8] | Loss=0.01024 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.952 | L2-Norm(final)=14.105 | 3929.5 samples/s | 61.4 steps/s
[Step=79750 Epoch=77.9] | Loss=0.01023 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.956 | L2-Norm(final)=14.108 | 3880.8 samples/s | 60.6 steps/s
[Step=79800 Epoch=77.9] | Loss=0.01006 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.960 | L2-Norm(final)=14.111 | 3919.0 samples/s | 61.2 steps/s
[Step=79850 Epoch=78.0] | Loss=0.00999 | Reg=0.00080 | acc=0.9844 | L2-Norm=8.963 | L2-Norm(final)=14.114 | 3892.9 samples/s | 60.8 steps/s
[Step=79900 Epoch=78.0] | Loss=0.00989 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.967 | L2-Norm(final)=14.118 | 3930.1 samples/s | 61.4 steps/s
[Step=79950 Epoch=78.1] | Loss=0.00983 | Reg=0.00080 | acc=1.0000 | L2-Norm=8.970 | L2-Norm(final)=14.121 | 3902.4 samples/s | 61.0 steps/s
[Step=80000 Epoch=78.1] | Loss=0.00976 | Reg=0.00081 | acc=0.9844 | L2-Norm=8.974 | L2-Norm(final)=14.124 | 3922.7 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step80000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00013, len=1
[Step=78001 Epoch=147.0] | Loss=0.00005 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.721 | L2-Norm(final)=8.987 | 3330.3 samples/s | 52.0 steps/s
[Step=78050 Epoch=147.1] | Loss=0.00005 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.719 | L2-Norm(final)=8.992 | 3787.2 samples/s | 59.2 steps/s
[Step=78100 Epoch=147.2] | Loss=0.00004 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.717 | L2-Norm(final)=8.997 | 4061.7 samples/s | 63.5 steps/s
[Step=78150 Epoch=147.3] | Loss=0.00004 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.717 | L2-Norm(final)=9.002 | 4141.3 samples/s | 64.7 steps/s
[Step=78200 Epoch=147.4] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.716 | L2-Norm(final)=9.007 | 4084.1 samples/s | 63.8 steps/s
[Step=78250 Epoch=147.5] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.715 | L2-Norm(final)=9.011 | 4074.3 samples/s | 63.7 steps/s
[Step=78300 Epoch=147.6] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.714 | L2-Norm(final)=9.015 | 4166.3 samples/s | 65.1 steps/s
[Step=78350 Epoch=147.7] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.712 | L2-Norm(final)=9.019 | 4067.5 samples/s | 63.6 steps/s
[Step=78400 Epoch=147.8] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.711 | L2-Norm(final)=9.022 | 4190.5 samples/s | 65.5 steps/s
[Step=78450 Epoch=147.9] | Loss=0.00003 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.709 | L2-Norm(final)=9.026 | 4019.5 samples/s | 62.8 steps/s
[Step=78500 Epoch=148.0] | Loss=0.00002 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.708 | L2-Norm(final)=9.029 | 4156.8 samples/s | 64.9 steps/s
All layers training...
LR=0.00013, len=1
[Step=78501 Epoch=148.0] | Loss=0.00001 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.690 | L2-Norm(final)=9.062 | 3297.5 samples/s | 51.5 steps/s
[Step=78550 Epoch=148.1] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.686 | L2-Norm(final)=9.065 | 3484.9 samples/s | 54.5 steps/s
[Step=78600 Epoch=148.2] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.679 | L2-Norm(final)=9.067 | 3667.6 samples/s | 57.3 steps/s
[Step=78650 Epoch=148.3] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.673 | L2-Norm(final)=9.069 | 3713.4 samples/s | 58.0 steps/s
[Step=78700 Epoch=148.4] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.666 | L2-Norm(final)=9.071 | 3720.6 samples/s | 58.1 steps/s
[Step=78750 Epoch=148.4] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.659 | L2-Norm(final)=9.073 | 3760.3 samples/s | 58.8 steps/s
[Step=78800 Epoch=148.5] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.652 | L2-Norm(final)=9.074 | 3730.5 samples/s | 58.3 steps/s
[Step=78850 Epoch=148.6] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.645 | L2-Norm(final)=9.076 | 3758.1 samples/s | 58.7 steps/s
[Step=78900 Epoch=148.7] | Loss=0.00001 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.638 | L2-Norm(final)=9.077 | 3729.0 samples/s | 58.3 steps/s
[Step=78950 Epoch=148.8] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.631 | L2-Norm(final)=9.079 | 3720.6 samples/s | 58.1 steps/s
[Step=79000 Epoch=148.9] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.623 | L2-Norm(final)=9.080 | 3745.8 samples/s | 58.5 steps/s
[Step=79050 Epoch=149.0] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.616 | L2-Norm(final)=9.082 | 1662.4 samples/s | 26.0 steps/s
[Step=79100 Epoch=149.1] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.608 | L2-Norm(final)=9.083 | 3675.7 samples/s | 57.4 steps/s
[Step=79150 Epoch=149.2] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.600 | L2-Norm(final)=9.084 | 3690.4 samples/s | 57.7 steps/s
[Step=79200 Epoch=149.3] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.592 | L2-Norm(final)=9.085 | 3639.6 samples/s | 56.9 steps/s
[Step=79250 Epoch=149.4] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.584 | L2-Norm(final)=9.087 | 3690.9 samples/s | 57.7 steps/s
[Step=79300 Epoch=149.5] | Loss=0.00001 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.576 | L2-Norm(final)=9.088 | 3732.8 samples/s | 58.3 steps/s
[Step=79350 Epoch=149.6] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.568 | L2-Norm(final)=9.089 | 3690.1 samples/s | 57.7 steps/s
[Step=79400 Epoch=149.7] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.560 | L2-Norm(final)=9.090 | 3678.4 samples/s | 57.5 steps/s
[Step=79450 Epoch=149.8] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.552 | L2-Norm(final)=9.091 | 3778.6 samples/s | 59.0 steps/s
[Step=79500 Epoch=149.9] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.543 | L2-Norm(final)=9.092 | 3661.7 samples/s | 57.2 steps/s
[Step=79550 Epoch=150.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.535 | L2-Norm(final)=9.093 | 4610.7 samples/s | 72.0 steps/s
[Step=79600 Epoch=150.0] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.526 | L2-Norm(final)=9.095 | 1518.4 samples/s | 23.7 steps/s
[Step=79650 Epoch=150.1] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.518 | L2-Norm(final)=9.096 | 3649.6 samples/s | 57.0 steps/s
[Step=79700 Epoch=150.2] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.509 | L2-Norm(final)=9.097 | 3729.0 samples/s | 58.3 steps/s
[Step=79750 Epoch=150.3] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.500 | L2-Norm(final)=9.098 | 3789.1 samples/s | 59.2 steps/s
[Step=79800 Epoch=150.4] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.491 | L2-Norm(final)=9.099 | 3623.0 samples/s | 56.6 steps/s
[Step=79850 Epoch=150.5] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.482 | L2-Norm(final)=9.100 | 3720.5 samples/s | 58.1 steps/s
[Step=79900 Epoch=150.6] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.473 | L2-Norm(final)=9.101 | 3730.7 samples/s | 58.3 steps/s
[Step=79950 Epoch=150.7] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.464 | L2-Norm(final)=9.103 | 3724.4 samples/s | 58.2 steps/s
[Step=80000 Epoch=150.8] | Loss=0.00000 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.455 | L2-Norm(final)=9.104 | 3663.8 samples/s | 57.2 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step80000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.06039 | acc=0.9708 | tpr=0.9807 | fpr=0.0508 | 3576.1 samples/s | 14.0 steps/s
Avg test loss: 0.06192, Avg test acc: 0.97079, Avg tpr: 0.98053, Avg fpr: 0.05063, total FA: 395

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.71806 | acc=0.3044 | tpr=0.0211 | fpr=0.0805 | 3601.1 samples/s | 14.1 steps/s
Avg test loss: 4.71464, Avg test acc: 0.30327, Avg tpr: 0.02168, Avg fpr: 0.07743, total FA: 604

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.42999 | acc=0.1234 | tpr=0.7699 | fpr=0.8882 | 3602.7 samples/s | 14.1 steps/s
[Step= 100] | Loss=5.43391 | acc=0.1252 | tpr=0.7676 | fpr=0.8868 | 6867.3 samples/s | 26.8 steps/s
[Step= 150] | Loss=5.43756 | acc=0.1236 | tpr=0.7637 | fpr=0.8882 | 7068.7 samples/s | 27.6 steps/s
[Step= 200] | Loss=5.42291 | acc=0.1233 | tpr=0.7574 | fpr=0.8882 | 6785.1 samples/s | 26.5 steps/s
[Step= 250] | Loss=5.42849 | acc=0.1231 | tpr=0.7659 | fpr=0.8886 | 6874.6 samples/s | 26.9 steps/s
[Step= 300] | Loss=5.42582 | acc=0.1235 | tpr=0.7673 | fpr=0.8882 | 6932.3 samples/s | 27.1 steps/s
[Step= 350] | Loss=5.42603 | acc=0.1230 | tpr=0.7702 | fpr=0.8887 | 6854.2 samples/s | 26.8 steps/s
[Step= 400] | Loss=5.43216 | acc=0.1226 | tpr=0.7653 | fpr=0.8890 | 6826.2 samples/s | 26.7 steps/s
[Step= 450] | Loss=5.43668 | acc=0.1223 | tpr=0.7702 | fpr=0.8895 | 6850.5 samples/s | 26.8 steps/s
[Step= 500] | Loss=5.43729 | acc=0.1223 | tpr=0.7718 | fpr=0.8894 | 7126.5 samples/s | 27.8 steps/s
[Step= 550] | Loss=5.43845 | acc=0.1224 | tpr=0.7756 | fpr=0.8895 | 12073.7 samples/s | 47.2 steps/s
Avg test loss: 5.43932, Avg test acc: 0.12232, Avg tpr: 0.77575, Avg fpr: 0.88956, total FA: 123514

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09998 | acc=0.9817 | tpr=0.9646 | fpr=0.0180 | 3609.4 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.10476 | acc=0.9804 | tpr=0.9701 | fpr=0.0195 | 6853.9 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.10553 | acc=0.9796 | tpr=0.9669 | fpr=0.0202 | 6961.7 samples/s | 27.2 steps/s
[Step= 200] | Loss=0.10709 | acc=0.9798 | tpr=0.9705 | fpr=0.0200 | 6798.1 samples/s | 26.6 steps/s
[Step= 250] | Loss=0.10584 | acc=0.9798 | tpr=0.9686 | fpr=0.0200 | 6783.1 samples/s | 26.5 steps/s
[Step= 300] | Loss=0.10786 | acc=0.9794 | tpr=0.9665 | fpr=0.0203 | 7110.9 samples/s | 27.8 steps/s
[Step= 350] | Loss=0.10794 | acc=0.9794 | tpr=0.9662 | fpr=0.0204 | 6941.6 samples/s | 27.1 steps/s
[Step= 400] | Loss=0.10836 | acc=0.9792 | tpr=0.9655 | fpr=0.0206 | 6601.8 samples/s | 25.8 steps/s
[Step= 450] | Loss=0.11081 | acc=0.9788 | tpr=0.9635 | fpr=0.0209 | 7045.9 samples/s | 27.5 steps/s
[Step= 500] | Loss=0.11027 | acc=0.9789 | tpr=0.9652 | fpr=0.0209 | 6785.7 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.10967 | acc=0.9791 | tpr=0.9650 | fpr=0.0206 | 12207.8 samples/s | 47.7 steps/s
Avg test loss: 0.10944, Avg test acc: 0.97912, Avg tpr: 0.96513, Avg fpr: 0.02063, total FA: 2864

server round 40/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=78.1] | Loss=0.00616 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.568 | L2-Norm(final)=14.219 | 3366.4 samples/s | 52.6 steps/s
[Step=80050 Epoch=78.2] | Loss=0.01245 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.574 | L2-Norm(final)=14.222 | 4156.5 samples/s | 64.9 steps/s
[Step=80100 Epoch=78.2] | Loss=0.01093 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.577 | L2-Norm(final)=14.226 | 4425.3 samples/s | 69.1 steps/s
[Step=80150 Epoch=78.3] | Loss=0.01062 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.580 | L2-Norm(final)=14.230 | 4328.3 samples/s | 67.6 steps/s
[Step=80200 Epoch=78.3] | Loss=0.01067 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.583 | L2-Norm(final)=14.234 | 4384.5 samples/s | 68.5 steps/s
[Step=80250 Epoch=78.4] | Loss=0.00994 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.586 | L2-Norm(final)=14.238 | 4339.9 samples/s | 67.8 steps/s
[Step=80300 Epoch=78.4] | Loss=0.00981 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.589 | L2-Norm(final)=14.242 | 4385.7 samples/s | 68.5 steps/s
[Step=80350 Epoch=78.4] | Loss=0.00953 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.592 | L2-Norm(final)=14.246 | 4384.1 samples/s | 68.5 steps/s
[Step=80400 Epoch=78.5] | Loss=0.00945 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.595 | L2-Norm(final)=14.250 | 4384.0 samples/s | 68.5 steps/s
[Step=80450 Epoch=78.5] | Loss=0.00935 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.598 | L2-Norm(final)=14.254 | 4343.8 samples/s | 67.9 steps/s
[Step=80500 Epoch=78.6] | Loss=0.00929 | Reg=0.00074 | acc=1.0000 | L2-Norm=8.601 | L2-Norm(final)=14.258 | 4460.0 samples/s | 69.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=78.6] | Loss=0.01608 | Reg=0.00074 | acc=0.9844 | L2-Norm=8.629 | L2-Norm(final)=14.298 | 3344.1 samples/s | 52.3 steps/s
[Step=80550 Epoch=78.6] | Loss=0.00958 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.633 | L2-Norm(final)=14.302 | 3576.3 samples/s | 55.9 steps/s
[Step=80600 Epoch=78.7] | Loss=0.00934 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.636 | L2-Norm(final)=14.305 | 3833.1 samples/s | 59.9 steps/s
[Step=80650 Epoch=78.7] | Loss=0.00937 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.640 | L2-Norm(final)=14.308 | 3887.2 samples/s | 60.7 steps/s
[Step=80700 Epoch=78.8] | Loss=0.00942 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.644 | L2-Norm(final)=14.311 | 3898.8 samples/s | 60.9 steps/s
[Step=80750 Epoch=78.8] | Loss=0.00943 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.648 | L2-Norm(final)=14.314 | 3917.6 samples/s | 61.2 steps/s
[Step=80800 Epoch=78.9] | Loss=0.00918 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.651 | L2-Norm(final)=14.317 | 3957.8 samples/s | 61.8 steps/s
[Step=80850 Epoch=78.9] | Loss=0.00928 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.655 | L2-Norm(final)=14.321 | 3909.1 samples/s | 61.1 steps/s
[Step=80900 Epoch=79.0] | Loss=0.00913 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.658 | L2-Norm(final)=14.324 | 3856.4 samples/s | 60.3 steps/s
[Step=80950 Epoch=79.0] | Loss=0.00907 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.661 | L2-Norm(final)=14.327 | 3899.5 samples/s | 60.9 steps/s
[Step=81000 Epoch=79.1] | Loss=0.00921 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.664 | L2-Norm(final)=14.329 | 3943.4 samples/s | 61.6 steps/s
[Step=81050 Epoch=79.1] | Loss=0.00924 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.667 | L2-Norm(final)=14.332 | 3958.6 samples/s | 61.9 steps/s
[Step=81100 Epoch=79.2] | Loss=0.00931 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.670 | L2-Norm(final)=14.335 | 3902.8 samples/s | 61.0 steps/s
[Step=81150 Epoch=79.2] | Loss=0.00910 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.673 | L2-Norm(final)=14.337 | 3960.4 samples/s | 61.9 steps/s
[Step=81200 Epoch=79.3] | Loss=0.00912 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.676 | L2-Norm(final)=14.340 | 3911.8 samples/s | 61.1 steps/s
[Step=81250 Epoch=79.3] | Loss=0.00908 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.679 | L2-Norm(final)=14.343 | 3880.7 samples/s | 60.6 steps/s
[Step=81300 Epoch=79.4] | Loss=0.00906 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.682 | L2-Norm(final)=14.345 | 3922.2 samples/s | 61.3 steps/s
[Step=81350 Epoch=79.4] | Loss=0.00906 | Reg=0.00075 | acc=1.0000 | L2-Norm=8.685 | L2-Norm(final)=14.348 | 3925.8 samples/s | 61.3 steps/s
[Step=81400 Epoch=79.5] | Loss=0.00896 | Reg=0.00075 | acc=0.9844 | L2-Norm=8.688 | L2-Norm(final)=14.351 | 3881.3 samples/s | 60.6 steps/s
[Step=81450 Epoch=79.5] | Loss=0.00887 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.690 | L2-Norm(final)=14.353 | 3884.1 samples/s | 60.7 steps/s
[Step=81500 Epoch=79.6] | Loss=0.00888 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.693 | L2-Norm(final)=14.356 | 4238.9 samples/s | 66.2 steps/s
[Step=81550 Epoch=79.6] | Loss=0.00883 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.696 | L2-Norm(final)=14.358 | 1661.5 samples/s | 26.0 steps/s
[Step=81600 Epoch=79.7] | Loss=0.00879 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.698 | L2-Norm(final)=14.361 | 3845.7 samples/s | 60.1 steps/s
[Step=81650 Epoch=79.7] | Loss=0.00868 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.701 | L2-Norm(final)=14.363 | 3817.8 samples/s | 59.7 steps/s
[Step=81700 Epoch=79.8] | Loss=0.00864 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.704 | L2-Norm(final)=14.366 | 3918.8 samples/s | 61.2 steps/s
[Step=81750 Epoch=79.8] | Loss=0.00860 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.706 | L2-Norm(final)=14.368 | 3872.1 samples/s | 60.5 steps/s
[Step=81800 Epoch=79.9] | Loss=0.00855 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.709 | L2-Norm(final)=14.371 | 3890.9 samples/s | 60.8 steps/s
[Step=81850 Epoch=79.9] | Loss=0.00852 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.711 | L2-Norm(final)=14.373 | 3867.5 samples/s | 60.4 steps/s
[Step=81900 Epoch=80.0] | Loss=0.00845 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.713 | L2-Norm(final)=14.376 | 3875.8 samples/s | 60.6 steps/s
[Step=81950 Epoch=80.0] | Loss=0.00843 | Reg=0.00076 | acc=1.0000 | L2-Norm=8.716 | L2-Norm(final)=14.378 | 3916.7 samples/s | 61.2 steps/s
[Step=82000 Epoch=80.1] | Loss=0.00836 | Reg=0.00076 | acc=0.9844 | L2-Norm=8.718 | L2-Norm(final)=14.381 | 3896.9 samples/s | 60.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step82000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=80001 Epoch=150.8] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.568 | L2-Norm(final)=9.140 | 3121.2 samples/s | 48.8 steps/s
[Step=80050 Epoch=150.9] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.564 | L2-Norm(final)=9.143 | 3956.6 samples/s | 61.8 steps/s
[Step=80100 Epoch=151.0] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.562 | L2-Norm(final)=9.147 | 4007.8 samples/s | 62.6 steps/s
[Step=80150 Epoch=151.1] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.560 | L2-Norm(final)=9.151 | 4082.8 samples/s | 63.8 steps/s
[Step=80200 Epoch=151.2] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.558 | L2-Norm(final)=9.156 | 4104.0 samples/s | 64.1 steps/s
[Step=80250 Epoch=151.3] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.556 | L2-Norm(final)=9.160 | 4172.5 samples/s | 65.2 steps/s
[Step=80300 Epoch=151.4] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.554 | L2-Norm(final)=9.163 | 4101.2 samples/s | 64.1 steps/s
[Step=80350 Epoch=151.5] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.552 | L2-Norm(final)=9.167 | 4153.5 samples/s | 64.9 steps/s
[Step=80400 Epoch=151.6] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.550 | L2-Norm(final)=9.170 | 4051.2 samples/s | 63.3 steps/s
[Step=80450 Epoch=151.6] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.548 | L2-Norm(final)=9.174 | 4153.4 samples/s | 64.9 steps/s
[Step=80500 Epoch=151.7] | Loss=0.00002 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.546 | L2-Norm(final)=9.177 | 4095.2 samples/s | 64.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=80501 Epoch=151.7] | Loss=0.00000 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.525 | L2-Norm(final)=9.210 | 3284.2 samples/s | 51.3 steps/s
[Step=80550 Epoch=151.8] | Loss=0.00001 | Reg=0.00073 | acc=1.0000 | L2-Norm=8.520 | L2-Norm(final)=9.213 | 3510.3 samples/s | 54.8 steps/s
[Step=80600 Epoch=151.9] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.512 | L2-Norm(final)=9.215 | 3696.3 samples/s | 57.8 steps/s
[Step=80650 Epoch=152.0] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.504 | L2-Norm(final)=9.217 | 3742.0 samples/s | 58.5 steps/s
[Step=80700 Epoch=152.1] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.496 | L2-Norm(final)=9.219 | 3710.7 samples/s | 58.0 steps/s
[Step=80750 Epoch=152.2] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.488 | L2-Norm(final)=9.221 | 3708.8 samples/s | 57.9 steps/s
[Step=80800 Epoch=152.3] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.479 | L2-Norm(final)=9.222 | 3781.4 samples/s | 59.1 steps/s
[Step=80850 Epoch=152.4] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.471 | L2-Norm(final)=9.224 | 3625.0 samples/s | 56.6 steps/s
[Step=80900 Epoch=152.5] | Loss=0.00001 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.462 | L2-Norm(final)=9.226 | 3754.2 samples/s | 58.7 steps/s
[Step=80950 Epoch=152.6] | Loss=0.00001 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.453 | L2-Norm(final)=9.227 | 3676.2 samples/s | 57.4 steps/s
[Step=81000 Epoch=152.7] | Loss=0.00001 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.445 | L2-Norm(final)=9.229 | 3771.3 samples/s | 58.9 steps/s
[Step=81050 Epoch=152.8] | Loss=0.00001 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.436 | L2-Norm(final)=9.230 | 1628.4 samples/s | 25.4 steps/s
[Step=81100 Epoch=152.9] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.427 | L2-Norm(final)=9.232 | 3705.3 samples/s | 57.9 steps/s
[Step=81150 Epoch=153.0] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.417 | L2-Norm(final)=9.233 | 3655.9 samples/s | 57.1 steps/s
[Step=81200 Epoch=153.1] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.408 | L2-Norm(final)=9.234 | 3721.2 samples/s | 58.1 steps/s
[Step=81250 Epoch=153.2] | Loss=0.00000 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.399 | L2-Norm(final)=9.236 | 3713.3 samples/s | 58.0 steps/s
[Step=81300 Epoch=153.3] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.389 | L2-Norm(final)=9.237 | 3709.3 samples/s | 58.0 steps/s
[Step=81350 Epoch=153.3] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.380 | L2-Norm(final)=9.238 | 3723.0 samples/s | 58.2 steps/s
[Step=81400 Epoch=153.4] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.370 | L2-Norm(final)=9.240 | 3745.6 samples/s | 58.5 steps/s
[Step=81450 Epoch=153.5] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.360 | L2-Norm(final)=9.241 | 3701.3 samples/s | 57.8 steps/s
[Step=81500 Epoch=153.6] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.350 | L2-Norm(final)=9.243 | 3769.0 samples/s | 58.9 steps/s
[Step=81550 Epoch=153.7] | Loss=0.00000 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.341 | L2-Norm(final)=9.244 | 4662.5 samples/s | 72.9 steps/s
[Step=81600 Epoch=153.8] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.331 | L2-Norm(final)=9.245 | 1518.6 samples/s | 23.7 steps/s
[Step=81650 Epoch=153.9] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.321 | L2-Norm(final)=9.247 | 3715.9 samples/s | 58.1 steps/s
[Step=81700 Epoch=154.0] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.310 | L2-Norm(final)=9.248 | 3686.7 samples/s | 57.6 steps/s
[Step=81750 Epoch=154.1] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.300 | L2-Norm(final)=9.250 | 3732.2 samples/s | 58.3 steps/s
[Step=81800 Epoch=154.2] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.290 | L2-Norm(final)=9.251 | 3719.7 samples/s | 58.1 steps/s
[Step=81850 Epoch=154.3] | Loss=0.00000 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.280 | L2-Norm(final)=9.253 | 3725.7 samples/s | 58.2 steps/s
[Step=81900 Epoch=154.4] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.269 | L2-Norm(final)=9.254 | 3703.9 samples/s | 57.9 steps/s
[Step=81950 Epoch=154.5] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.259 | L2-Norm(final)=9.256 | 3740.9 samples/s | 58.5 steps/s
[Step=82000 Epoch=154.6] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.248 | L2-Norm(final)=9.257 | 3739.4 samples/s | 58.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step82000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05794 | acc=0.9709 | tpr=0.9771 | fpr=0.0426 | 3631.5 samples/s | 14.2 steps/s
Avg test loss: 0.05982, Avg test acc: 0.97019, Avg tpr: 0.97674, Avg fpr: 0.04423, total FA: 345

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.88010 | acc=0.3053 | tpr=0.0169 | fpr=0.0684 | 3679.6 samples/s | 14.4 steps/s
Avg test loss: 4.88106, Avg test acc: 0.30407, Avg tpr: 0.01737, Avg fpr: 0.06538, total FA: 510

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.91439 | acc=0.1305 | tpr=0.8142 | fpr=0.8818 | 3632.0 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.92084 | acc=0.1331 | tpr=0.8081 | fpr=0.8795 | 7030.9 samples/s | 27.5 steps/s
[Step= 150] | Loss=4.92553 | acc=0.1321 | tpr=0.8040 | fpr=0.8802 | 6709.6 samples/s | 26.2 steps/s
[Step= 200] | Loss=4.91076 | acc=0.1321 | tpr=0.7945 | fpr=0.8799 | 6995.6 samples/s | 27.3 steps/s
[Step= 250] | Loss=4.91586 | acc=0.1314 | tpr=0.7991 | fpr=0.8807 | 6891.3 samples/s | 26.9 steps/s
[Step= 300] | Loss=4.91412 | acc=0.1319 | tpr=0.8029 | fpr=0.8803 | 6772.8 samples/s | 26.5 steps/s
[Step= 350] | Loss=4.91406 | acc=0.1315 | tpr=0.8084 | fpr=0.8808 | 7130.3 samples/s | 27.9 steps/s
[Step= 400] | Loss=4.91993 | acc=0.1312 | tpr=0.8063 | fpr=0.8811 | 6860.5 samples/s | 26.8 steps/s
[Step= 450] | Loss=4.92399 | acc=0.1309 | tpr=0.8101 | fpr=0.8814 | 6552.7 samples/s | 25.6 steps/s
[Step= 500] | Loss=4.92380 | acc=0.1311 | tpr=0.8101 | fpr=0.8811 | 7165.4 samples/s | 28.0 steps/s
[Step= 550] | Loss=4.92473 | acc=0.1312 | tpr=0.8138 | fpr=0.8812 | 12285.9 samples/s | 48.0 steps/s
Avg test loss: 4.92545, Avg test acc: 0.13112, Avg tpr: 0.81379, Avg fpr: 0.88129, total FA: 122365

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09454 | acc=0.9828 | tpr=0.9646 | fpr=0.0169 | 3601.9 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.09891 | acc=0.9815 | tpr=0.9638 | fpr=0.0181 | 6847.0 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.09932 | acc=0.9810 | tpr=0.9625 | fpr=0.0186 | 6981.0 samples/s | 27.3 steps/s
[Step= 200] | Loss=0.10099 | acc=0.9811 | tpr=0.9672 | fpr=0.0187 | 6750.5 samples/s | 26.4 steps/s
[Step= 250] | Loss=0.09964 | acc=0.9810 | tpr=0.9642 | fpr=0.0186 | 6774.0 samples/s | 26.5 steps/s
[Step= 300] | Loss=0.10156 | acc=0.9807 | tpr=0.9622 | fpr=0.0189 | 6805.1 samples/s | 26.6 steps/s
[Step= 350] | Loss=0.10159 | acc=0.9806 | tpr=0.9631 | fpr=0.0191 | 6802.9 samples/s | 26.6 steps/s
[Step= 400] | Loss=0.10191 | acc=0.9804 | tpr=0.9623 | fpr=0.0193 | 6695.7 samples/s | 26.2 steps/s
[Step= 450] | Loss=0.10437 | acc=0.9800 | tpr=0.9606 | fpr=0.0196 | 6697.7 samples/s | 26.2 steps/s
[Step= 500] | Loss=0.10380 | acc=0.9801 | tpr=0.9617 | fpr=0.0196 | 6715.4 samples/s | 26.2 steps/s
[Step= 550] | Loss=0.10330 | acc=0.9803 | tpr=0.9618 | fpr=0.0194 | 12506.0 samples/s | 48.9 steps/s
Avg test loss: 0.10309, Avg test acc: 0.98029, Avg tpr: 0.96197, Avg fpr: 0.01938, total FA: 2691

server round 41/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=80.1] | Loss=0.01384 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.315 | L2-Norm(final)=14.456 | 3114.7 samples/s | 48.7 steps/s
[Step=82050 Epoch=80.1] | Loss=0.01205 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.320 | L2-Norm(final)=14.460 | 4286.3 samples/s | 67.0 steps/s
[Step=82100 Epoch=80.2] | Loss=0.01187 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.325 | L2-Norm(final)=14.465 | 4324.1 samples/s | 67.6 steps/s
[Step=82150 Epoch=80.2] | Loss=0.01192 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.329 | L2-Norm(final)=14.469 | 4265.4 samples/s | 66.6 steps/s
[Step=82200 Epoch=80.3] | Loss=0.01153 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.333 | L2-Norm(final)=14.474 | 4288.4 samples/s | 67.0 steps/s
[Step=82250 Epoch=80.3] | Loss=0.01167 | Reg=0.00070 | acc=0.9688 | L2-Norm=8.337 | L2-Norm(final)=14.479 | 4337.5 samples/s | 67.8 steps/s
[Step=82300 Epoch=80.4] | Loss=0.01132 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.341 | L2-Norm(final)=14.483 | 4356.1 samples/s | 68.1 steps/s
[Step=82350 Epoch=80.4] | Loss=0.01124 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.345 | L2-Norm(final)=14.488 | 4435.8 samples/s | 69.3 steps/s
[Step=82400 Epoch=80.5] | Loss=0.01097 | Reg=0.00070 | acc=1.0000 | L2-Norm=8.349 | L2-Norm(final)=14.492 | 4277.3 samples/s | 66.8 steps/s
[Step=82450 Epoch=80.5] | Loss=0.01109 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.353 | L2-Norm(final)=14.496 | 4333.2 samples/s | 67.7 steps/s
[Step=82500 Epoch=80.5] | Loss=0.01109 | Reg=0.00070 | acc=0.9844 | L2-Norm=8.357 | L2-Norm(final)=14.501 | 4322.3 samples/s | 67.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=80.5] | Loss=0.00460 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.397 | L2-Norm(final)=14.542 | 3396.4 samples/s | 53.1 steps/s
[Step=82550 Epoch=80.6] | Loss=0.01232 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.401 | L2-Norm(final)=14.546 | 3722.2 samples/s | 58.2 steps/s
[Step=82600 Epoch=80.6] | Loss=0.01263 | Reg=0.00071 | acc=0.9688 | L2-Norm=8.405 | L2-Norm(final)=14.549 | 3892.1 samples/s | 60.8 steps/s
[Step=82650 Epoch=80.7] | Loss=0.01181 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.410 | L2-Norm(final)=14.552 | 3890.1 samples/s | 60.8 steps/s
[Step=82700 Epoch=80.7] | Loss=0.01104 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.414 | L2-Norm(final)=14.555 | 3936.9 samples/s | 61.5 steps/s
[Step=82750 Epoch=80.8] | Loss=0.01050 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.418 | L2-Norm(final)=14.558 | 3891.1 samples/s | 60.8 steps/s
[Step=82800 Epoch=80.8] | Loss=0.01056 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.422 | L2-Norm(final)=14.561 | 3961.4 samples/s | 61.9 steps/s
[Step=82850 Epoch=80.9] | Loss=0.01069 | Reg=0.00071 | acc=0.9688 | L2-Norm=8.426 | L2-Norm(final)=14.564 | 3946.7 samples/s | 61.7 steps/s
[Step=82900 Epoch=80.9] | Loss=0.01080 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.430 | L2-Norm(final)=14.567 | 3896.7 samples/s | 60.9 steps/s
[Step=82950 Epoch=81.0] | Loss=0.01074 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.434 | L2-Norm(final)=14.570 | 3924.5 samples/s | 61.3 steps/s
[Step=83000 Epoch=81.0] | Loss=0.01058 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.437 | L2-Norm(final)=14.573 | 3954.5 samples/s | 61.8 steps/s
[Step=83050 Epoch=81.1] | Loss=0.01046 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.441 | L2-Norm(final)=14.576 | 3934.4 samples/s | 61.5 steps/s
[Step=83100 Epoch=81.1] | Loss=0.01029 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.444 | L2-Norm(final)=14.579 | 3909.4 samples/s | 61.1 steps/s
[Step=83150 Epoch=81.2] | Loss=0.01023 | Reg=0.00071 | acc=0.9844 | L2-Norm=8.448 | L2-Norm(final)=14.582 | 3961.1 samples/s | 61.9 steps/s
[Step=83200 Epoch=81.2] | Loss=0.01028 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.451 | L2-Norm(final)=14.585 | 3922.6 samples/s | 61.3 steps/s
[Step=83250 Epoch=81.3] | Loss=0.01016 | Reg=0.00071 | acc=1.0000 | L2-Norm=8.455 | L2-Norm(final)=14.588 | 3931.8 samples/s | 61.4 steps/s
[Step=83300 Epoch=81.3] | Loss=0.01007 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.458 | L2-Norm(final)=14.590 | 3934.5 samples/s | 61.5 steps/s
[Step=83350 Epoch=81.4] | Loss=0.00997 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.462 | L2-Norm(final)=14.593 | 3938.9 samples/s | 61.5 steps/s
[Step=83400 Epoch=81.4] | Loss=0.00994 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.465 | L2-Norm(final)=14.596 | 3934.7 samples/s | 61.5 steps/s
[Step=83450 Epoch=81.5] | Loss=0.00987 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.468 | L2-Norm(final)=14.599 | 3917.6 samples/s | 61.2 steps/s
[Step=83500 Epoch=81.5] | Loss=0.00997 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.472 | L2-Norm(final)=14.602 | 4234.9 samples/s | 66.2 steps/s
[Step=83550 Epoch=81.6] | Loss=0.00993 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.475 | L2-Norm(final)=14.605 | 1623.7 samples/s | 25.4 steps/s
[Step=83600 Epoch=81.6] | Loss=0.00985 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.478 | L2-Norm(final)=14.607 | 3957.6 samples/s | 61.8 steps/s
[Step=83650 Epoch=81.7] | Loss=0.00975 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.481 | L2-Norm(final)=14.610 | 3864.2 samples/s | 60.4 steps/s
[Step=83700 Epoch=81.7] | Loss=0.00962 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.484 | L2-Norm(final)=14.613 | 3920.9 samples/s | 61.3 steps/s
[Step=83750 Epoch=81.8] | Loss=0.00957 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.487 | L2-Norm(final)=14.615 | 3921.6 samples/s | 61.3 steps/s
[Step=83800 Epoch=81.8] | Loss=0.00951 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.490 | L2-Norm(final)=14.618 | 3955.8 samples/s | 61.8 steps/s
[Step=83850 Epoch=81.9] | Loss=0.00947 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.493 | L2-Norm(final)=14.621 | 3931.6 samples/s | 61.4 steps/s
[Step=83900 Epoch=81.9] | Loss=0.00939 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.496 | L2-Norm(final)=14.623 | 3918.4 samples/s | 61.2 steps/s
[Step=83950 Epoch=82.0] | Loss=0.00934 | Reg=0.00072 | acc=1.0000 | L2-Norm=8.499 | L2-Norm(final)=14.626 | 3930.7 samples/s | 61.4 steps/s
[Step=84000 Epoch=82.0] | Loss=0.00936 | Reg=0.00072 | acc=0.9844 | L2-Norm=8.501 | L2-Norm(final)=14.628 | 3975.0 samples/s | 62.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step84000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=82001 Epoch=154.6] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.315 | L2-Norm(final)=9.305 | 3248.2 samples/s | 50.8 steps/s
[Step=82050 Epoch=154.7] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.311 | L2-Norm(final)=9.314 | 3905.1 samples/s | 61.0 steps/s
[Step=82100 Epoch=154.8] | Loss=0.00002 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.308 | L2-Norm(final)=9.320 | 4057.1 samples/s | 63.4 steps/s
[Step=82150 Epoch=154.9] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.304 | L2-Norm(final)=9.326 | 4172.6 samples/s | 65.2 steps/s
[Step=82200 Epoch=154.9] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.300 | L2-Norm(final)=9.331 | 4158.2 samples/s | 65.0 steps/s
[Step=82250 Epoch=155.0] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.296 | L2-Norm(final)=9.337 | 4075.0 samples/s | 63.7 steps/s
[Step=82300 Epoch=155.1] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.292 | L2-Norm(final)=9.341 | 4151.9 samples/s | 64.9 steps/s
[Step=82350 Epoch=155.2] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.288 | L2-Norm(final)=9.346 | 4123.5 samples/s | 64.4 steps/s
[Step=82400 Epoch=155.3] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.284 | L2-Norm(final)=9.350 | 4114.9 samples/s | 64.3 steps/s
[Step=82450 Epoch=155.4] | Loss=0.00001 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.280 | L2-Norm(final)=9.355 | 4063.1 samples/s | 63.5 steps/s
[Step=82500 Epoch=155.5] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.276 | L2-Norm(final)=9.359 | 4211.7 samples/s | 65.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=82501 Epoch=155.5] | Loss=0.00000 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.236 | L2-Norm(final)=9.401 | 3630.6 samples/s | 56.7 steps/s
[Step=82550 Epoch=155.6] | Loss=0.00001 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.224 | L2-Norm(final)=9.405 | 3192.0 samples/s | 49.9 steps/s
[Step=82600 Epoch=155.7] | Loss=0.00001 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.208 | L2-Norm(final)=9.408 | 3679.9 samples/s | 57.5 steps/s
[Step=82650 Epoch=155.8] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.191 | L2-Norm(final)=9.411 | 3717.3 samples/s | 58.1 steps/s
[Step=82700 Epoch=155.9] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.175 | L2-Norm(final)=9.413 | 3697.5 samples/s | 57.8 steps/s
[Step=82750 Epoch=156.0] | Loss=0.00000 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.158 | L2-Norm(final)=9.416 | 3764.3 samples/s | 58.8 steps/s
[Step=82800 Epoch=156.1] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=9.419 | 3714.8 samples/s | 58.0 steps/s
[Step=82850 Epoch=156.2] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.123 | L2-Norm(final)=9.421 | 3684.3 samples/s | 57.6 steps/s
[Step=82900 Epoch=156.3] | Loss=0.00000 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.106 | L2-Norm(final)=9.424 | 3731.6 samples/s | 58.3 steps/s
[Step=82950 Epoch=156.4] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.089 | L2-Norm(final)=9.426 | 3780.5 samples/s | 59.1 steps/s
[Step=83000 Epoch=156.5] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.072 | L2-Norm(final)=9.429 | 3821.2 samples/s | 59.7 steps/s
[Step=83050 Epoch=156.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=9.432 | 1666.8 samples/s | 26.0 steps/s
[Step=83100 Epoch=156.6] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.038 | L2-Norm(final)=9.435 | 3846.0 samples/s | 60.1 steps/s
[Step=83150 Epoch=156.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.020 | L2-Norm(final)=9.437 | 3771.6 samples/s | 58.9 steps/s
[Step=83200 Epoch=156.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.003 | L2-Norm(final)=9.440 | 3715.5 samples/s | 58.1 steps/s
[Step=83250 Epoch=156.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.986 | L2-Norm(final)=9.443 | 3683.8 samples/s | 57.6 steps/s
[Step=83300 Epoch=157.0] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.968 | L2-Norm(final)=9.446 | 3761.8 samples/s | 58.8 steps/s
[Step=83350 Epoch=157.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.951 | L2-Norm(final)=9.448 | 3727.4 samples/s | 58.2 steps/s
[Step=83400 Epoch=157.2] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.934 | L2-Norm(final)=9.452 | 3723.2 samples/s | 58.2 steps/s
[Step=83450 Epoch=157.3] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.920 | L2-Norm(final)=9.455 | 3758.1 samples/s | 58.7 steps/s
[Step=83500 Epoch=157.4] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.908 | L2-Norm(final)=9.459 | 3750.3 samples/s | 58.6 steps/s
[Step=83550 Epoch=157.5] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.898 | L2-Norm(final)=9.462 | 4677.7 samples/s | 73.1 steps/s
[Step=83600 Epoch=157.6] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.888 | L2-Norm(final)=9.465 | 1553.4 samples/s | 24.3 steps/s
[Step=83650 Epoch=157.7] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.879 | L2-Norm(final)=9.468 | 3744.9 samples/s | 58.5 steps/s
[Step=83700 Epoch=157.8] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.871 | L2-Norm(final)=9.471 | 3663.7 samples/s | 57.2 steps/s
[Step=83750 Epoch=157.9] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.863 | L2-Norm(final)=9.473 | 3653.1 samples/s | 57.1 steps/s
[Step=83800 Epoch=158.0] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.856 | L2-Norm(final)=9.476 | 3718.0 samples/s | 58.1 steps/s
[Step=83850 Epoch=158.1] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.849 | L2-Norm(final)=9.478 | 3743.6 samples/s | 58.5 steps/s
[Step=83900 Epoch=158.2] | Loss=0.00002 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.843 | L2-Norm(final)=9.480 | 3696.4 samples/s | 57.8 steps/s
[Step=83950 Epoch=158.2] | Loss=0.00002 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.837 | L2-Norm(final)=9.482 | 3690.9 samples/s | 57.7 steps/s
[Step=84000 Epoch=158.3] | Loss=0.00002 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.831 | L2-Norm(final)=9.484 | 3681.1 samples/s | 57.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step84000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05685 | acc=0.9704 | tpr=0.9791 | fpr=0.0486 | 3551.6 samples/s | 13.9 steps/s
Avg test loss: 0.05883, Avg test acc: 0.97003, Avg tpr: 0.97873, Avg fpr: 0.04910, total FA: 383

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=5.05889 | acc=0.3111 | tpr=0.0103 | fpr=0.0357 | 3593.0 samples/s | 14.0 steps/s
Avg test loss: 5.06119, Avg test acc: 0.30900, Avg tpr: 0.01084, Avg fpr: 0.03525, total FA: 275

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.85617 | acc=0.1228 | tpr=0.8142 | fpr=0.8896 | 3555.1 samples/s | 13.9 steps/s
[Step= 100] | Loss=4.85767 | acc=0.1247 | tpr=0.8017 | fpr=0.8879 | 6891.9 samples/s | 26.9 steps/s
[Step= 150] | Loss=4.86378 | acc=0.1233 | tpr=0.7983 | fpr=0.8892 | 7083.1 samples/s | 27.7 steps/s
[Step= 200] | Loss=4.85070 | acc=0.1229 | tpr=0.7923 | fpr=0.8893 | 6579.8 samples/s | 25.7 steps/s
[Step= 250] | Loss=4.85615 | acc=0.1226 | tpr=0.7974 | fpr=0.8897 | 7068.0 samples/s | 27.6 steps/s
[Step= 300] | Loss=4.85457 | acc=0.1229 | tpr=0.8015 | fpr=0.8895 | 6730.1 samples/s | 26.3 steps/s
[Step= 350] | Loss=4.85446 | acc=0.1224 | tpr=0.8071 | fpr=0.8900 | 6821.3 samples/s | 26.6 steps/s
[Step= 400] | Loss=4.85991 | acc=0.1220 | tpr=0.8058 | fpr=0.8904 | 6705.5 samples/s | 26.2 steps/s
[Step= 450] | Loss=4.86352 | acc=0.1217 | tpr=0.8082 | fpr=0.8908 | 6792.3 samples/s | 26.5 steps/s
[Step= 500] | Loss=4.86344 | acc=0.1218 | tpr=0.8097 | fpr=0.8906 | 6759.7 samples/s | 26.4 steps/s
[Step= 550] | Loss=4.86430 | acc=0.1220 | tpr=0.8126 | fpr=0.8905 | 12436.9 samples/s | 48.6 steps/s
Avg test loss: 4.86483, Avg test acc: 0.12193, Avg tpr: 0.81220, Avg fpr: 0.89062, total FA: 123661

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08855 | acc=0.9813 | tpr=0.9646 | fpr=0.0184 | 3662.2 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.09275 | acc=0.9803 | tpr=0.9638 | fpr=0.0194 | 6653.7 samples/s | 26.0 steps/s
[Step= 150] | Loss=0.09320 | acc=0.9797 | tpr=0.9640 | fpr=0.0200 | 6827.8 samples/s | 26.7 steps/s
[Step= 200] | Loss=0.09385 | acc=0.9800 | tpr=0.9694 | fpr=0.0198 | 6922.9 samples/s | 27.0 steps/s
[Step= 250] | Loss=0.09299 | acc=0.9799 | tpr=0.9659 | fpr=0.0198 | 6867.8 samples/s | 26.8 steps/s
[Step= 300] | Loss=0.09483 | acc=0.9796 | tpr=0.9636 | fpr=0.0201 | 6830.3 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.09465 | acc=0.9794 | tpr=0.9643 | fpr=0.0203 | 6888.5 samples/s | 26.9 steps/s
[Step= 400] | Loss=0.09506 | acc=0.9792 | tpr=0.9633 | fpr=0.0205 | 6740.7 samples/s | 26.3 steps/s
[Step= 450] | Loss=0.09704 | acc=0.9789 | tpr=0.9620 | fpr=0.0208 | 6985.3 samples/s | 27.3 steps/s
[Step= 500] | Loss=0.09662 | acc=0.9789 | tpr=0.9626 | fpr=0.0208 | 6792.1 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.09617 | acc=0.9791 | tpr=0.9622 | fpr=0.0205 | 12956.5 samples/s | 50.6 steps/s
Avg test loss: 0.09594, Avg test acc: 0.97917, Avg tpr: 0.96236, Avg fpr: 0.02053, total FA: 2850

server round 42/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=82.0] | Loss=0.02340 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.062 | L2-Norm(final)=14.701 | 3390.7 samples/s | 53.0 steps/s
[Step=84050 Epoch=82.1] | Loss=0.01818 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=14.707 | 4176.8 samples/s | 65.3 steps/s
[Step=84100 Epoch=82.1] | Loss=0.01695 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.075 | L2-Norm(final)=14.714 | 4302.4 samples/s | 67.2 steps/s
[Step=84150 Epoch=82.2] | Loss=0.01621 | Reg=0.00065 | acc=0.9688 | L2-Norm=8.081 | L2-Norm(final)=14.721 | 4245.8 samples/s | 66.3 steps/s
[Step=84200 Epoch=82.2] | Loss=0.01542 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.087 | L2-Norm(final)=14.728 | 4309.5 samples/s | 67.3 steps/s
[Step=84250 Epoch=82.3] | Loss=0.01549 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.093 | L2-Norm(final)=14.734 | 4290.9 samples/s | 67.0 steps/s
[Step=84300 Epoch=82.3] | Loss=0.01508 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.099 | L2-Norm(final)=14.741 | 4322.9 samples/s | 67.5 steps/s
[Step=84350 Epoch=82.4] | Loss=0.01502 | Reg=0.00066 | acc=0.9688 | L2-Norm=8.104 | L2-Norm(final)=14.747 | 4319.2 samples/s | 67.5 steps/s
[Step=84400 Epoch=82.4] | Loss=0.01487 | Reg=0.00066 | acc=0.9844 | L2-Norm=8.110 | L2-Norm(final)=14.753 | 4431.4 samples/s | 69.2 steps/s
[Step=84450 Epoch=82.5] | Loss=0.01460 | Reg=0.00066 | acc=0.9844 | L2-Norm=8.115 | L2-Norm(final)=14.759 | 4286.6 samples/s | 67.0 steps/s
[Step=84500 Epoch=82.5] | Loss=0.01450 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.121 | L2-Norm(final)=14.764 | 4396.1 samples/s | 68.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=82.5] | Loss=0.01226 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.174 | L2-Norm(final)=14.820 | 3484.6 samples/s | 54.4 steps/s
[Step=84550 Epoch=82.5] | Loss=0.01378 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=14.824 | 3649.5 samples/s | 57.0 steps/s
[Step=84600 Epoch=82.6] | Loss=0.01339 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.187 | L2-Norm(final)=14.829 | 3898.6 samples/s | 60.9 steps/s
[Step=84650 Epoch=82.6] | Loss=0.01209 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.193 | L2-Norm(final)=14.833 | 3916.2 samples/s | 61.2 steps/s
[Step=84700 Epoch=82.7] | Loss=0.01227 | Reg=0.00067 | acc=0.9688 | L2-Norm=8.199 | L2-Norm(final)=14.836 | 3845.8 samples/s | 60.1 steps/s
[Step=84750 Epoch=82.7] | Loss=0.01190 | Reg=0.00067 | acc=0.9688 | L2-Norm=8.205 | L2-Norm(final)=14.840 | 3917.6 samples/s | 61.2 steps/s
[Step=84800 Epoch=82.8] | Loss=0.01154 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.210 | L2-Norm(final)=14.844 | 3955.0 samples/s | 61.8 steps/s
[Step=84850 Epoch=82.8] | Loss=0.01134 | Reg=0.00067 | acc=0.9844 | L2-Norm=8.215 | L2-Norm(final)=14.847 | 3930.4 samples/s | 61.4 steps/s
[Step=84900 Epoch=82.9] | Loss=0.01159 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.220 | L2-Norm(final)=14.850 | 3847.4 samples/s | 60.1 steps/s
[Step=84950 Epoch=82.9] | Loss=0.01191 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.225 | L2-Norm(final)=14.854 | 3902.4 samples/s | 61.0 steps/s
[Step=85000 Epoch=83.0] | Loss=0.01180 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.229 | L2-Norm(final)=14.857 | 3958.3 samples/s | 61.8 steps/s
[Step=85050 Epoch=83.0] | Loss=0.01180 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.233 | L2-Norm(final)=14.860 | 3938.0 samples/s | 61.5 steps/s
[Step=85100 Epoch=83.1] | Loss=0.01160 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.238 | L2-Norm(final)=14.863 | 3895.4 samples/s | 60.9 steps/s
[Step=85150 Epoch=83.1] | Loss=0.01162 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.242 | L2-Norm(final)=14.866 | 3936.4 samples/s | 61.5 steps/s
[Step=85200 Epoch=83.2] | Loss=0.01147 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.246 | L2-Norm(final)=14.869 | 3957.2 samples/s | 61.8 steps/s
[Step=85250 Epoch=83.2] | Loss=0.01149 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.251 | L2-Norm(final)=14.872 | 3930.2 samples/s | 61.4 steps/s
[Step=85300 Epoch=83.3] | Loss=0.01139 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.255 | L2-Norm(final)=14.875 | 3940.3 samples/s | 61.6 steps/s
[Step=85350 Epoch=83.3] | Loss=0.01149 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.259 | L2-Norm(final)=14.878 | 3962.2 samples/s | 61.9 steps/s
[Step=85400 Epoch=83.4] | Loss=0.01132 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.263 | L2-Norm(final)=14.881 | 3925.0 samples/s | 61.3 steps/s
[Step=85450 Epoch=83.4] | Loss=0.01120 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.267 | L2-Norm(final)=14.884 | 3929.3 samples/s | 61.4 steps/s
[Step=85500 Epoch=83.5] | Loss=0.01120 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.271 | L2-Norm(final)=14.886 | 4217.1 samples/s | 65.9 steps/s
[Step=85550 Epoch=83.5] | Loss=0.01113 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.274 | L2-Norm(final)=14.889 | 1666.3 samples/s | 26.0 steps/s
[Step=85600 Epoch=83.6] | Loss=0.01099 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.278 | L2-Norm(final)=14.892 | 3921.6 samples/s | 61.3 steps/s
[Step=85650 Epoch=83.6] | Loss=0.01087 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=14.895 | 3868.7 samples/s | 60.4 steps/s
[Step=85700 Epoch=83.7] | Loss=0.01080 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=14.897 | 3840.2 samples/s | 60.0 steps/s
[Step=85750 Epoch=83.7] | Loss=0.01064 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.289 | L2-Norm(final)=14.900 | 3881.0 samples/s | 60.6 steps/s
[Step=85800 Epoch=83.8] | Loss=0.01054 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.292 | L2-Norm(final)=14.903 | 3909.2 samples/s | 61.1 steps/s
[Step=85850 Epoch=83.8] | Loss=0.01051 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.296 | L2-Norm(final)=14.905 | 3888.7 samples/s | 60.8 steps/s
[Step=85900 Epoch=83.9] | Loss=0.01040 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.299 | L2-Norm(final)=14.908 | 3918.4 samples/s | 61.2 steps/s
[Step=85950 Epoch=83.9] | Loss=0.01032 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.302 | L2-Norm(final)=14.911 | 3886.6 samples/s | 60.7 steps/s
[Step=86000 Epoch=84.0] | Loss=0.01029 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.306 | L2-Norm(final)=14.913 | 3925.5 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step86000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=84001 Epoch=158.3] | Loss=0.00004 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=9.540 | 3391.4 samples/s | 53.0 steps/s
[Step=84050 Epoch=158.4] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=9.542 | 3689.7 samples/s | 57.7 steps/s
[Step=84100 Epoch=158.5] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.059 | L2-Norm(final)=9.543 | 4142.3 samples/s | 64.7 steps/s
[Step=84150 Epoch=158.6] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.059 | L2-Norm(final)=9.545 | 3995.8 samples/s | 62.4 steps/s
[Step=84200 Epoch=158.7] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.058 | L2-Norm(final)=9.547 | 4067.7 samples/s | 63.6 steps/s
[Step=84250 Epoch=158.8] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=9.548 | 4101.9 samples/s | 64.1 steps/s
[Step=84300 Epoch=158.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.056 | L2-Norm(final)=9.550 | 4113.7 samples/s | 64.3 steps/s
[Step=84350 Epoch=159.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=9.551 | 4081.1 samples/s | 63.8 steps/s
[Step=84400 Epoch=159.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=9.553 | 4083.0 samples/s | 63.8 steps/s
[Step=84450 Epoch=159.2] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.054 | L2-Norm(final)=9.554 | 4121.0 samples/s | 64.4 steps/s
[Step=84500 Epoch=159.3] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.053 | L2-Norm(final)=9.556 | 4148.4 samples/s | 64.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=84501 Epoch=159.3] | Loss=0.00000 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.047 | L2-Norm(final)=9.572 | 3145.4 samples/s | 49.1 steps/s
[Step=84550 Epoch=159.4] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.045 | L2-Norm(final)=9.573 | 3473.8 samples/s | 54.3 steps/s
[Step=84600 Epoch=159.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.043 | L2-Norm(final)=9.574 | 3691.1 samples/s | 57.7 steps/s
[Step=84650 Epoch=159.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.040 | L2-Norm(final)=9.575 | 3686.7 samples/s | 57.6 steps/s
[Step=84700 Epoch=159.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.038 | L2-Norm(final)=9.577 | 3673.8 samples/s | 57.4 steps/s
[Step=84750 Epoch=159.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.036 | L2-Norm(final)=9.578 | 3680.0 samples/s | 57.5 steps/s
[Step=84800 Epoch=159.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.033 | L2-Norm(final)=9.579 | 3700.6 samples/s | 57.8 steps/s
[Step=84850 Epoch=159.9] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.031 | L2-Norm(final)=9.580 | 3690.9 samples/s | 57.7 steps/s
[Step=84900 Epoch=160.0] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.028 | L2-Norm(final)=9.581 | 3671.8 samples/s | 57.4 steps/s
[Step=84950 Epoch=160.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.025 | L2-Norm(final)=9.582 | 3761.4 samples/s | 58.8 steps/s
[Step=85000 Epoch=160.2] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.023 | L2-Norm(final)=9.583 | 3781.5 samples/s | 59.1 steps/s
[Step=85050 Epoch=160.3] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.020 | L2-Norm(final)=9.584 | 1627.6 samples/s | 25.4 steps/s
[Step=85100 Epoch=160.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.017 | L2-Norm(final)=9.585 | 3681.1 samples/s | 57.5 steps/s
[Step=85150 Epoch=160.5] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=9.586 | 3680.2 samples/s | 57.5 steps/s
[Step=85200 Epoch=160.6] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.011 | L2-Norm(final)=9.586 | 3640.8 samples/s | 56.9 steps/s
[Step=85250 Epoch=160.7] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=9.587 | 3735.2 samples/s | 58.4 steps/s
[Step=85300 Epoch=160.8] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.005 | L2-Norm(final)=9.588 | 3726.3 samples/s | 58.2 steps/s
[Step=85350 Epoch=160.9] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.002 | L2-Norm(final)=9.589 | 3679.1 samples/s | 57.5 steps/s
[Step=85400 Epoch=161.0] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.998 | L2-Norm(final)=9.590 | 3713.0 samples/s | 58.0 steps/s
[Step=85450 Epoch=161.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.995 | L2-Norm(final)=9.591 | 3726.3 samples/s | 58.2 steps/s
[Step=85500 Epoch=161.2] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.992 | L2-Norm(final)=9.591 | 3752.9 samples/s | 58.6 steps/s
[Step=85550 Epoch=161.3] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.989 | L2-Norm(final)=9.592 | 4638.2 samples/s | 72.5 steps/s
[Step=85600 Epoch=161.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.985 | L2-Norm(final)=9.593 | 1522.0 samples/s | 23.8 steps/s
[Step=85650 Epoch=161.5] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.982 | L2-Norm(final)=9.594 | 3739.5 samples/s | 58.4 steps/s
[Step=85700 Epoch=161.5] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.978 | L2-Norm(final)=9.595 | 3694.3 samples/s | 57.7 steps/s
[Step=85750 Epoch=161.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.975 | L2-Norm(final)=9.595 | 3721.7 samples/s | 58.2 steps/s
[Step=85800 Epoch=161.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.971 | L2-Norm(final)=9.596 | 3677.6 samples/s | 57.5 steps/s
[Step=85850 Epoch=161.8] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.968 | L2-Norm(final)=9.597 | 3757.1 samples/s | 58.7 steps/s
[Step=85900 Epoch=161.9] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.964 | L2-Norm(final)=9.598 | 3737.2 samples/s | 58.4 steps/s
[Step=85950 Epoch=162.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.960 | L2-Norm(final)=9.599 | 3768.5 samples/s | 58.9 steps/s
[Step=86000 Epoch=162.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.956 | L2-Norm(final)=9.599 | 3690.3 samples/s | 57.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step86000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05642 | acc=0.9700 | tpr=0.9746 | fpr=0.0399 | 3631.5 samples/s | 14.2 steps/s
Avg test loss: 0.05824, Avg test acc: 0.96983, Avg tpr: 0.97441, Avg fpr: 0.04025, total FA: 314

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.83110 | acc=0.3061 | tpr=0.0189 | fpr=0.0704 | 3615.3 samples/s | 14.1 steps/s
Avg test loss: 4.82973, Avg test acc: 0.30431, Avg tpr: 0.01888, Avg fpr: 0.06794, total FA: 530

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.59132 | acc=0.1355 | tpr=0.8097 | fpr=0.8766 | 3660.7 samples/s | 14.3 steps/s
[Step= 100] | Loss=4.59620 | acc=0.1378 | tpr=0.7910 | fpr=0.8744 | 6821.6 samples/s | 26.6 steps/s
[Step= 150] | Loss=4.60144 | acc=0.1365 | tpr=0.7882 | fpr=0.8755 | 6764.5 samples/s | 26.4 steps/s
[Step= 200] | Loss=4.58897 | acc=0.1365 | tpr=0.7858 | fpr=0.8753 | 6897.5 samples/s | 26.9 steps/s
[Step= 250] | Loss=4.59275 | acc=0.1358 | tpr=0.7913 | fpr=0.8762 | 7055.7 samples/s | 27.6 steps/s
[Step= 300] | Loss=4.59172 | acc=0.1365 | tpr=0.7927 | fpr=0.8754 | 6799.7 samples/s | 26.6 steps/s
[Step= 350] | Loss=4.59223 | acc=0.1362 | tpr=0.8003 | fpr=0.8759 | 6929.2 samples/s | 27.1 steps/s
[Step= 400] | Loss=4.59791 | acc=0.1358 | tpr=0.8003 | fpr=0.8762 | 7099.8 samples/s | 27.7 steps/s
[Step= 450] | Loss=4.60099 | acc=0.1358 | tpr=0.8038 | fpr=0.8763 | 6423.0 samples/s | 25.1 steps/s
[Step= 500] | Loss=4.60087 | acc=0.1358 | tpr=0.8035 | fpr=0.8763 | 6923.2 samples/s | 27.0 steps/s
[Step= 550] | Loss=4.60185 | acc=0.1359 | tpr=0.8066 | fpr=0.8763 | 12562.9 samples/s | 49.1 steps/s
Avg test loss: 4.60244, Avg test acc: 0.13580, Avg tpr: 0.80626, Avg fpr: 0.87638, total FA: 121684

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09866 | acc=0.9812 | tpr=0.9690 | fpr=0.0185 | 3645.7 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.10320 | acc=0.9803 | tpr=0.9680 | fpr=0.0195 | 6928.7 samples/s | 27.1 steps/s
[Step= 150] | Loss=0.10368 | acc=0.9796 | tpr=0.9654 | fpr=0.0201 | 7014.8 samples/s | 27.4 steps/s
[Step= 200] | Loss=0.10521 | acc=0.9798 | tpr=0.9705 | fpr=0.0201 | 6809.9 samples/s | 26.6 steps/s
[Step= 250] | Loss=0.10403 | acc=0.9797 | tpr=0.9677 | fpr=0.0201 | 6942.3 samples/s | 27.1 steps/s
[Step= 300] | Loss=0.10606 | acc=0.9793 | tpr=0.9658 | fpr=0.0205 | 6865.1 samples/s | 26.8 steps/s
[Step= 350] | Loss=0.10598 | acc=0.9792 | tpr=0.9662 | fpr=0.0206 | 6901.4 samples/s | 27.0 steps/s
[Step= 400] | Loss=0.10639 | acc=0.9789 | tpr=0.9650 | fpr=0.0208 | 7011.8 samples/s | 27.4 steps/s
[Step= 450] | Loss=0.10878 | acc=0.9786 | tpr=0.9630 | fpr=0.0211 | 6731.5 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.10822 | acc=0.9786 | tpr=0.9639 | fpr=0.0211 | 6889.1 samples/s | 26.9 steps/s
[Step= 550] | Loss=0.10769 | acc=0.9789 | tpr=0.9638 | fpr=0.0208 | 12472.8 samples/s | 48.7 steps/s
Avg test loss: 0.10747, Avg test acc: 0.97894, Avg tpr: 0.96395, Avg fpr: 0.02079, total FA: 2886

server round 43/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=84.0] | Loss=0.00404 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=14.987 | 3401.2 samples/s | 53.1 steps/s
[Step=86050 Epoch=84.0] | Loss=0.01069 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.087 | L2-Norm(final)=14.991 | 3985.5 samples/s | 62.3 steps/s
[Step=86100 Epoch=84.1] | Loss=0.01228 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.092 | L2-Norm(final)=14.995 | 4301.8 samples/s | 67.2 steps/s
[Step=86150 Epoch=84.1] | Loss=0.01156 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.097 | L2-Norm(final)=14.999 | 4421.1 samples/s | 69.1 steps/s
[Step=86200 Epoch=84.2] | Loss=0.01155 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.102 | L2-Norm(final)=15.004 | 4298.4 samples/s | 67.2 steps/s
[Step=86250 Epoch=84.2] | Loss=0.01156 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.107 | L2-Norm(final)=15.008 | 4354.4 samples/s | 68.0 steps/s
[Step=86300 Epoch=84.3] | Loss=0.01146 | Reg=0.00066 | acc=0.9688 | L2-Norm=8.112 | L2-Norm(final)=15.012 | 4415.7 samples/s | 69.0 steps/s
[Step=86350 Epoch=84.3] | Loss=0.01119 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.116 | L2-Norm(final)=15.016 | 4313.2 samples/s | 67.4 steps/s
[Step=86400 Epoch=84.4] | Loss=0.01107 | Reg=0.00066 | acc=0.9844 | L2-Norm=8.120 | L2-Norm(final)=15.020 | 4356.0 samples/s | 68.1 steps/s
[Step=86450 Epoch=84.4] | Loss=0.01120 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.125 | L2-Norm(final)=15.024 | 4389.4 samples/s | 68.6 steps/s
[Step=86500 Epoch=84.5] | Loss=0.01119 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.129 | L2-Norm(final)=15.028 | 4450.1 samples/s | 69.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=84.5] | Loss=0.00655 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.169 | L2-Norm(final)=15.065 | 3141.3 samples/s | 49.1 steps/s
[Step=86550 Epoch=84.5] | Loss=0.01084 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.174 | L2-Norm(final)=15.068 | 3923.5 samples/s | 61.3 steps/s
[Step=86600 Epoch=84.6] | Loss=0.01154 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.180 | L2-Norm(final)=15.071 | 3850.1 samples/s | 60.2 steps/s
[Step=86650 Epoch=84.6] | Loss=0.01123 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.184 | L2-Norm(final)=15.074 | 3887.8 samples/s | 60.7 steps/s
[Step=86700 Epoch=84.6] | Loss=0.01111 | Reg=0.00067 | acc=0.9844 | L2-Norm=8.188 | L2-Norm(final)=15.077 | 3886.8 samples/s | 60.7 steps/s
[Step=86750 Epoch=84.7] | Loss=0.01054 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.193 | L2-Norm(final)=15.080 | 3908.8 samples/s | 61.1 steps/s
[Step=86800 Epoch=84.7] | Loss=0.01020 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.198 | L2-Norm(final)=15.084 | 3857.8 samples/s | 60.3 steps/s
[Step=86850 Epoch=84.8] | Loss=0.01025 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.202 | L2-Norm(final)=15.087 | 3846.3 samples/s | 60.1 steps/s
[Step=86900 Epoch=84.8] | Loss=0.01022 | Reg=0.00067 | acc=0.9688 | L2-Norm=8.207 | L2-Norm(final)=15.090 | 3897.3 samples/s | 60.9 steps/s
[Step=86950 Epoch=84.9] | Loss=0.01012 | Reg=0.00067 | acc=0.9844 | L2-Norm=8.211 | L2-Norm(final)=15.093 | 3891.4 samples/s | 60.8 steps/s
[Step=87000 Epoch=84.9] | Loss=0.01033 | Reg=0.00067 | acc=1.0000 | L2-Norm=8.215 | L2-Norm(final)=15.096 | 3869.2 samples/s | 60.5 steps/s
[Step=87050 Epoch=85.0] | Loss=0.01037 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.219 | L2-Norm(final)=15.099 | 3888.6 samples/s | 60.8 steps/s
[Step=87100 Epoch=85.0] | Loss=0.01040 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.223 | L2-Norm(final)=15.101 | 3893.7 samples/s | 60.8 steps/s
[Step=87150 Epoch=85.1] | Loss=0.01037 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.227 | L2-Norm(final)=15.104 | 3894.3 samples/s | 60.8 steps/s
[Step=87200 Epoch=85.1] | Loss=0.01014 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.231 | L2-Norm(final)=15.107 | 3925.1 samples/s | 61.3 steps/s
[Step=87250 Epoch=85.2] | Loss=0.01003 | Reg=0.00068 | acc=0.9688 | L2-Norm=8.235 | L2-Norm(final)=15.110 | 3879.0 samples/s | 60.6 steps/s
[Step=87300 Epoch=85.2] | Loss=0.01012 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.238 | L2-Norm(final)=15.113 | 3887.5 samples/s | 60.7 steps/s
[Step=87350 Epoch=85.3] | Loss=0.01015 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.242 | L2-Norm(final)=15.115 | 3885.1 samples/s | 60.7 steps/s
[Step=87400 Epoch=85.3] | Loss=0.01006 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.246 | L2-Norm(final)=15.118 | 3903.1 samples/s | 61.0 steps/s
[Step=87450 Epoch=85.4] | Loss=0.01003 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.249 | L2-Norm(final)=15.121 | 3959.9 samples/s | 61.9 steps/s
[Step=87500 Epoch=85.4] | Loss=0.01003 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.253 | L2-Norm(final)=15.123 | 4157.5 samples/s | 65.0 steps/s
[Step=87550 Epoch=85.5] | Loss=0.00992 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.256 | L2-Norm(final)=15.126 | 1637.2 samples/s | 25.6 steps/s
[Step=87600 Epoch=85.5] | Loss=0.00983 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.260 | L2-Norm(final)=15.128 | 3885.6 samples/s | 60.7 steps/s
[Step=87650 Epoch=85.6] | Loss=0.00982 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.263 | L2-Norm(final)=15.131 | 3929.2 samples/s | 61.4 steps/s
[Step=87700 Epoch=85.6] | Loss=0.00973 | Reg=0.00068 | acc=1.0000 | L2-Norm=8.266 | L2-Norm(final)=15.133 | 3802.8 samples/s | 59.4 steps/s
[Step=87750 Epoch=85.7] | Loss=0.00976 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.269 | L2-Norm(final)=15.136 | 3906.2 samples/s | 61.0 steps/s
[Step=87800 Epoch=85.7] | Loss=0.00972 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.273 | L2-Norm(final)=15.138 | 3898.7 samples/s | 60.9 steps/s
[Step=87850 Epoch=85.8] | Loss=0.00967 | Reg=0.00068 | acc=0.9844 | L2-Norm=8.276 | L2-Norm(final)=15.141 | 3951.0 samples/s | 61.7 steps/s
[Step=87900 Epoch=85.8] | Loss=0.00967 | Reg=0.00069 | acc=0.9844 | L2-Norm=8.279 | L2-Norm(final)=15.143 | 3916.2 samples/s | 61.2 steps/s
[Step=87950 Epoch=85.9] | Loss=0.00957 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.282 | L2-Norm(final)=15.145 | 3901.9 samples/s | 61.0 steps/s
[Step=88000 Epoch=85.9] | Loss=0.00952 | Reg=0.00069 | acc=1.0000 | L2-Norm=8.285 | L2-Norm(final)=15.148 | 3930.3 samples/s | 61.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step88000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=86001 Epoch=162.1] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.081 | L2-Norm(final)=9.623 | 3300.9 samples/s | 51.6 steps/s
[Step=86050 Epoch=162.2] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.077 | L2-Norm(final)=9.627 | 3827.6 samples/s | 59.8 steps/s
[Step=86100 Epoch=162.3] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=9.631 | 4098.5 samples/s | 64.0 steps/s
[Step=86150 Epoch=162.4] | Loss=0.00002 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.072 | L2-Norm(final)=9.635 | 4199.0 samples/s | 65.6 steps/s
[Step=86200 Epoch=162.5] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=9.639 | 4046.0 samples/s | 63.2 steps/s
[Step=86250 Epoch=162.6] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.067 | L2-Norm(final)=9.642 | 4173.9 samples/s | 65.2 steps/s
[Step=86300 Epoch=162.7] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.064 | L2-Norm(final)=9.645 | 4048.3 samples/s | 63.3 steps/s
[Step=86350 Epoch=162.8] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.062 | L2-Norm(final)=9.648 | 4094.3 samples/s | 64.0 steps/s
[Step=86400 Epoch=162.9] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=9.651 | 4126.2 samples/s | 64.5 steps/s
[Step=86450 Epoch=163.0] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.057 | L2-Norm(final)=9.654 | 4086.9 samples/s | 63.9 steps/s
[Step=86500 Epoch=163.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=9.656 | 4177.0 samples/s | 65.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=86501 Epoch=163.1] | Loss=0.00001 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.031 | L2-Norm(final)=9.684 | 3395.0 samples/s | 53.0 steps/s
[Step=86550 Epoch=163.1] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.026 | L2-Norm(final)=9.687 | 3400.8 samples/s | 53.1 steps/s
[Step=86600 Epoch=163.2] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.020 | L2-Norm(final)=9.689 | 3675.0 samples/s | 57.4 steps/s
[Step=86650 Epoch=163.3] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=9.691 | 3763.6 samples/s | 58.8 steps/s
[Step=86700 Epoch=163.4] | Loss=0.00001 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.008 | L2-Norm(final)=9.693 | 3692.4 samples/s | 57.7 steps/s
[Step=86750 Epoch=163.5] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.001 | L2-Norm(final)=9.694 | 3756.8 samples/s | 58.7 steps/s
[Step=86800 Epoch=163.6] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.994 | L2-Norm(final)=9.696 | 3702.8 samples/s | 57.9 steps/s
[Step=86850 Epoch=163.7] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.987 | L2-Norm(final)=9.698 | 3760.5 samples/s | 58.8 steps/s
[Step=86900 Epoch=163.8] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.980 | L2-Norm(final)=9.699 | 3729.0 samples/s | 58.3 steps/s
[Step=86950 Epoch=163.9] | Loss=0.00000 | Reg=0.00064 | acc=1.0000 | L2-Norm=7.973 | L2-Norm(final)=9.701 | 3725.2 samples/s | 58.2 steps/s
[Step=87000 Epoch=164.0] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.966 | L2-Norm(final)=9.702 | 3808.8 samples/s | 59.5 steps/s
[Step=87050 Epoch=164.1] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.959 | L2-Norm(final)=9.704 | 1617.7 samples/s | 25.3 steps/s
[Step=87100 Epoch=164.2] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.951 | L2-Norm(final)=9.706 | 3779.8 samples/s | 59.1 steps/s
[Step=87150 Epoch=164.3] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.944 | L2-Norm(final)=9.707 | 3715.8 samples/s | 58.1 steps/s
[Step=87200 Epoch=164.4] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.937 | L2-Norm(final)=9.709 | 3661.0 samples/s | 57.2 steps/s
[Step=87250 Epoch=164.5] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.929 | L2-Norm(final)=9.710 | 3760.0 samples/s | 58.7 steps/s
[Step=87300 Epoch=164.6] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.922 | L2-Norm(final)=9.712 | 3749.5 samples/s | 58.6 steps/s
[Step=87350 Epoch=164.7] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.914 | L2-Norm(final)=9.714 | 3784.8 samples/s | 59.1 steps/s
[Step=87400 Epoch=164.8] | Loss=0.00000 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.906 | L2-Norm(final)=9.715 | 3697.1 samples/s | 57.8 steps/s
[Step=87450 Epoch=164.8] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.899 | L2-Norm(final)=9.717 | 3718.1 samples/s | 58.1 steps/s
[Step=87500 Epoch=164.9] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.891 | L2-Norm(final)=9.719 | 3746.8 samples/s | 58.5 steps/s
[Step=87550 Epoch=165.0] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.883 | L2-Norm(final)=9.720 | 4646.7 samples/s | 72.6 steps/s
[Step=87600 Epoch=165.1] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.875 | L2-Norm(final)=9.722 | 1549.8 samples/s | 24.2 steps/s
[Step=87650 Epoch=165.2] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.868 | L2-Norm(final)=9.724 | 3698.0 samples/s | 57.8 steps/s
[Step=87700 Epoch=165.3] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.860 | L2-Norm(final)=9.725 | 3740.3 samples/s | 58.4 steps/s
[Step=87750 Epoch=165.4] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.852 | L2-Norm(final)=9.727 | 3680.1 samples/s | 57.5 steps/s
[Step=87800 Epoch=165.5] | Loss=0.00000 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.844 | L2-Norm(final)=9.729 | 3731.4 samples/s | 58.3 steps/s
[Step=87850 Epoch=165.6] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.836 | L2-Norm(final)=9.731 | 3779.8 samples/s | 59.1 steps/s
[Step=87900 Epoch=165.7] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.828 | L2-Norm(final)=9.733 | 3754.1 samples/s | 58.7 steps/s
[Step=87950 Epoch=165.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.819 | L2-Norm(final)=9.735 | 3718.3 samples/s | 58.1 steps/s
[Step=88000 Epoch=165.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.811 | L2-Norm(final)=9.737 | 3748.5 samples/s | 58.6 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step88000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05606 | acc=0.9712 | tpr=0.9770 | fpr=0.0411 | 3639.5 samples/s | 14.2 steps/s
Avg test loss: 0.05778, Avg test acc: 0.97039, Avg tpr: 0.97616, Avg fpr: 0.04230, total FA: 330

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.87583 | acc=0.3077 | tpr=0.0201 | fpr=0.0676 | 3665.5 samples/s | 14.3 steps/s
Avg test loss: 4.87585, Avg test acc: 0.30531, Avg tpr: 0.01988, Avg fpr: 0.06691, total FA: 522

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.79019 | acc=0.1288 | tpr=0.7965 | fpr=0.8833 | 3628.4 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.79329 | acc=0.1305 | tpr=0.7740 | fpr=0.8815 | 6778.4 samples/s | 26.5 steps/s
[Step= 150] | Loss=4.79892 | acc=0.1292 | tpr=0.7738 | fpr=0.8827 | 6988.3 samples/s | 27.3 steps/s
[Step= 200] | Loss=4.78548 | acc=0.1289 | tpr=0.7639 | fpr=0.8827 | 6965.9 samples/s | 27.2 steps/s
[Step= 250] | Loss=4.78969 | acc=0.1283 | tpr=0.7721 | fpr=0.8834 | 7010.5 samples/s | 27.4 steps/s
[Step= 300] | Loss=4.78776 | acc=0.1289 | tpr=0.7731 | fpr=0.8828 | 6858.2 samples/s | 26.8 steps/s
[Step= 350] | Loss=4.78812 | acc=0.1285 | tpr=0.7790 | fpr=0.8833 | 6755.0 samples/s | 26.4 steps/s
[Step= 400] | Loss=4.79347 | acc=0.1282 | tpr=0.7768 | fpr=0.8836 | 6737.6 samples/s | 26.3 steps/s
[Step= 450] | Loss=4.79650 | acc=0.1280 | tpr=0.7804 | fpr=0.8839 | 6814.8 samples/s | 26.6 steps/s
[Step= 500] | Loss=4.79665 | acc=0.1281 | tpr=0.7828 | fpr=0.8837 | 6925.9 samples/s | 27.1 steps/s
[Step= 550] | Loss=4.79721 | acc=0.1282 | tpr=0.7851 | fpr=0.8838 | 12441.2 samples/s | 48.6 steps/s
Avg test loss: 4.79788, Avg test acc: 0.12808, Avg tpr: 0.78487, Avg fpr: 0.88386, total FA: 122722

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09826 | acc=0.9820 | tpr=0.9690 | fpr=0.0178 | 3674.7 samples/s | 14.4 steps/s
[Step= 100] | Loss=0.10295 | acc=0.9808 | tpr=0.9701 | fpr=0.0190 | 6690.7 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.10367 | acc=0.9801 | tpr=0.9669 | fpr=0.0197 | 6678.2 samples/s | 26.1 steps/s
[Step= 200] | Loss=0.10549 | acc=0.9802 | tpr=0.9716 | fpr=0.0197 | 7021.4 samples/s | 27.4 steps/s
[Step= 250] | Loss=0.10414 | acc=0.9801 | tpr=0.9677 | fpr=0.0197 | 6730.6 samples/s | 26.3 steps/s
[Step= 300] | Loss=0.10623 | acc=0.9797 | tpr=0.9658 | fpr=0.0200 | 6844.6 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.10628 | acc=0.9796 | tpr=0.9662 | fpr=0.0202 | 6740.3 samples/s | 26.3 steps/s
[Step= 400] | Loss=0.10672 | acc=0.9794 | tpr=0.9655 | fpr=0.0204 | 6822.6 samples/s | 26.7 steps/s
[Step= 450] | Loss=0.10912 | acc=0.9791 | tpr=0.9635 | fpr=0.0207 | 6760.1 samples/s | 26.4 steps/s
[Step= 500] | Loss=0.10854 | acc=0.9791 | tpr=0.9643 | fpr=0.0206 | 6582.5 samples/s | 25.7 steps/s
[Step= 550] | Loss=0.10800 | acc=0.9793 | tpr=0.9638 | fpr=0.0204 | 12395.6 samples/s | 48.4 steps/s
Avg test loss: 0.10778, Avg test acc: 0.97935, Avg tpr: 0.96395, Avg fpr: 0.02037, total FA: 2828

server round 44/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=85.9] | Loss=0.00474 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.916 | L2-Norm(final)=15.216 | 3359.7 samples/s | 52.5 steps/s
[Step=88050 Epoch=86.0] | Loss=0.01357 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.922 | L2-Norm(final)=15.219 | 4021.2 samples/s | 62.8 steps/s
[Step=88100 Epoch=86.0] | Loss=0.01218 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.927 | L2-Norm(final)=15.224 | 4319.0 samples/s | 67.5 steps/s
[Step=88150 Epoch=86.1] | Loss=0.01197 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.932 | L2-Norm(final)=15.228 | 4276.0 samples/s | 66.8 steps/s
[Step=88200 Epoch=86.1] | Loss=0.01191 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.937 | L2-Norm(final)=15.232 | 4339.4 samples/s | 67.8 steps/s
[Step=88250 Epoch=86.2] | Loss=0.01203 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.942 | L2-Norm(final)=15.237 | 4427.0 samples/s | 69.2 steps/s
[Step=88300 Epoch=86.2] | Loss=0.01209 | Reg=0.00063 | acc=0.9844 | L2-Norm=7.947 | L2-Norm(final)=15.241 | 4357.8 samples/s | 68.1 steps/s
[Step=88350 Epoch=86.3] | Loss=0.01191 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.952 | L2-Norm(final)=15.245 | 4342.4 samples/s | 67.8 steps/s
[Step=88400 Epoch=86.3] | Loss=0.01175 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.957 | L2-Norm(final)=15.250 | 4355.9 samples/s | 68.1 steps/s
[Step=88450 Epoch=86.4] | Loss=0.01146 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.961 | L2-Norm(final)=15.254 | 4409.7 samples/s | 68.9 steps/s
[Step=88500 Epoch=86.4] | Loss=0.01148 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.966 | L2-Norm(final)=15.258 | 4435.2 samples/s | 69.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=86.4] | Loss=0.00652 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.014 | L2-Norm(final)=15.302 | 3292.2 samples/s | 51.4 steps/s
[Step=88550 Epoch=86.5] | Loss=0.01017 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.019 | L2-Norm(final)=15.306 | 3846.4 samples/s | 60.1 steps/s
[Step=88600 Epoch=86.5] | Loss=0.01112 | Reg=0.00064 | acc=0.9844 | L2-Norm=8.024 | L2-Norm(final)=15.309 | 3884.3 samples/s | 60.7 steps/s
[Step=88650 Epoch=86.6] | Loss=0.01071 | Reg=0.00064 | acc=1.0000 | L2-Norm=8.029 | L2-Norm(final)=15.313 | 3892.9 samples/s | 60.8 steps/s
[Step=88700 Epoch=86.6] | Loss=0.01109 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.035 | L2-Norm(final)=15.317 | 3908.6 samples/s | 61.1 steps/s
[Step=88750 Epoch=86.7] | Loss=0.01103 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.040 | L2-Norm(final)=15.320 | 3889.7 samples/s | 60.8 steps/s
[Step=88800 Epoch=86.7] | Loss=0.01124 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.045 | L2-Norm(final)=15.323 | 3945.0 samples/s | 61.6 steps/s
[Step=88850 Epoch=86.7] | Loss=0.01097 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.050 | L2-Norm(final)=15.327 | 3942.7 samples/s | 61.6 steps/s
[Step=88900 Epoch=86.8] | Loss=0.01108 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.055 | L2-Norm(final)=15.330 | 3922.7 samples/s | 61.3 steps/s
[Step=88950 Epoch=86.8] | Loss=0.01081 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.060 | L2-Norm(final)=15.333 | 3910.5 samples/s | 61.1 steps/s
[Step=89000 Epoch=86.9] | Loss=0.01073 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.065 | L2-Norm(final)=15.336 | 3960.4 samples/s | 61.9 steps/s
[Step=89050 Epoch=86.9] | Loss=0.01071 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.069 | L2-Norm(final)=15.339 | 3920.2 samples/s | 61.3 steps/s
[Step=89100 Epoch=87.0] | Loss=0.01078 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.074 | L2-Norm(final)=15.343 | 3930.3 samples/s | 61.4 steps/s
[Step=89150 Epoch=87.0] | Loss=0.01073 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.078 | L2-Norm(final)=15.346 | 3872.5 samples/s | 60.5 steps/s
[Step=89200 Epoch=87.1] | Loss=0.01070 | Reg=0.00065 | acc=1.0000 | L2-Norm=8.082 | L2-Norm(final)=15.349 | 3944.2 samples/s | 61.6 steps/s
[Step=89250 Epoch=87.1] | Loss=0.01056 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.086 | L2-Norm(final)=15.352 | 3924.0 samples/s | 61.3 steps/s
[Step=89300 Epoch=87.2] | Loss=0.01062 | Reg=0.00065 | acc=0.9844 | L2-Norm=8.090 | L2-Norm(final)=15.354 | 3952.2 samples/s | 61.8 steps/s
[Step=89350 Epoch=87.2] | Loss=0.01061 | Reg=0.00066 | acc=0.9688 | L2-Norm=8.094 | L2-Norm(final)=15.357 | 3840.7 samples/s | 60.0 steps/s
[Step=89400 Epoch=87.3] | Loss=0.01050 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.098 | L2-Norm(final)=15.360 | 3900.3 samples/s | 60.9 steps/s
[Step=89450 Epoch=87.3] | Loss=0.01048 | Reg=0.00066 | acc=0.9844 | L2-Norm=8.102 | L2-Norm(final)=15.363 | 3962.9 samples/s | 61.9 steps/s
[Step=89500 Epoch=87.4] | Loss=0.01040 | Reg=0.00066 | acc=0.9844 | L2-Norm=8.105 | L2-Norm(final)=15.365 | 4221.8 samples/s | 66.0 steps/s
[Step=89550 Epoch=87.4] | Loss=0.01020 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.109 | L2-Norm(final)=15.368 | 1666.7 samples/s | 26.0 steps/s
[Step=89600 Epoch=87.5] | Loss=0.01012 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.113 | L2-Norm(final)=15.371 | 3927.5 samples/s | 61.4 steps/s
[Step=89650 Epoch=87.5] | Loss=0.01008 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.116 | L2-Norm(final)=15.373 | 3901.1 samples/s | 61.0 steps/s
[Step=89700 Epoch=87.6] | Loss=0.00998 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.120 | L2-Norm(final)=15.376 | 3896.2 samples/s | 60.9 steps/s
[Step=89750 Epoch=87.6] | Loss=0.00991 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.124 | L2-Norm(final)=15.379 | 3900.1 samples/s | 60.9 steps/s
[Step=89800 Epoch=87.7] | Loss=0.00981 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.127 | L2-Norm(final)=15.381 | 3942.4 samples/s | 61.6 steps/s
[Step=89850 Epoch=87.7] | Loss=0.00972 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.131 | L2-Norm(final)=15.384 | 3882.2 samples/s | 60.7 steps/s
[Step=89900 Epoch=87.8] | Loss=0.00973 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.134 | L2-Norm(final)=15.386 | 3932.8 samples/s | 61.5 steps/s
[Step=89950 Epoch=87.8] | Loss=0.00970 | Reg=0.00066 | acc=0.9688 | L2-Norm=8.137 | L2-Norm(final)=15.389 | 3869.1 samples/s | 60.5 steps/s
[Step=90000 Epoch=87.9] | Loss=0.00960 | Reg=0.00066 | acc=1.0000 | L2-Norm=8.141 | L2-Norm(final)=15.391 | 3886.0 samples/s | 60.7 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step90000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=88001 Epoch=165.9] | Loss=0.00001 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.916 | L2-Norm(final)=9.797 | 3526.4 samples/s | 55.1 steps/s
[Step=88050 Epoch=166.0] | Loss=0.00002 | Reg=0.00063 | acc=1.0000 | L2-Norm=7.909 | L2-Norm(final)=9.806 | 3696.9 samples/s | 57.8 steps/s
[Step=88100 Epoch=166.1] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.905 | L2-Norm(final)=9.815 | 4055.8 samples/s | 63.4 steps/s
[Step=88150 Epoch=166.2] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.900 | L2-Norm(final)=9.822 | 4065.4 samples/s | 63.5 steps/s
[Step=88200 Epoch=166.3] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.896 | L2-Norm(final)=9.828 | 4156.7 samples/s | 64.9 steps/s
[Step=88250 Epoch=166.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.892 | L2-Norm(final)=9.835 | 4138.3 samples/s | 64.7 steps/s
[Step=88300 Epoch=166.4] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.888 | L2-Norm(final)=9.841 | 4099.1 samples/s | 64.0 steps/s
[Step=88350 Epoch=166.5] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.884 | L2-Norm(final)=9.847 | 4115.7 samples/s | 64.3 steps/s
[Step=88400 Epoch=166.6] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.880 | L2-Norm(final)=9.853 | 4181.6 samples/s | 65.3 steps/s
[Step=88450 Epoch=166.7] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.876 | L2-Norm(final)=9.859 | 4151.9 samples/s | 64.9 steps/s
[Step=88500 Epoch=166.8] | Loss=0.00001 | Reg=0.00062 | acc=1.0000 | L2-Norm=7.872 | L2-Norm(final)=9.864 | 4160.7 samples/s | 65.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=88501 Epoch=166.8] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.832 | L2-Norm(final)=9.918 | 3310.1 samples/s | 51.7 steps/s
[Step=88550 Epoch=166.9] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.822 | L2-Norm(final)=9.924 | 3428.3 samples/s | 53.6 steps/s
[Step=88600 Epoch=167.0] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.809 | L2-Norm(final)=9.928 | 3700.1 samples/s | 57.8 steps/s
[Step=88650 Epoch=167.1] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.795 | L2-Norm(final)=9.932 | 3727.2 samples/s | 58.2 steps/s
[Step=88700 Epoch=167.2] | Loss=0.00000 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.782 | L2-Norm(final)=9.936 | 3717.9 samples/s | 58.1 steps/s
[Step=88750 Epoch=167.3] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.768 | L2-Norm(final)=9.939 | 3728.4 samples/s | 58.3 steps/s
[Step=88800 Epoch=167.4] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.754 | L2-Norm(final)=9.943 | 3693.5 samples/s | 57.7 steps/s
[Step=88850 Epoch=167.5] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.740 | L2-Norm(final)=9.946 | 3707.9 samples/s | 57.9 steps/s
[Step=88900 Epoch=167.6] | Loss=0.00000 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.726 | L2-Norm(final)=9.950 | 3714.1 samples/s | 58.0 steps/s
[Step=88950 Epoch=167.7] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.712 | L2-Norm(final)=9.953 | 3778.9 samples/s | 59.0 steps/s
[Step=89000 Epoch=167.8] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.698 | L2-Norm(final)=9.957 | 3764.1 samples/s | 58.8 steps/s
[Step=89050 Epoch=167.9] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.684 | L2-Norm(final)=9.960 | 1626.7 samples/s | 25.4 steps/s
[Step=89100 Epoch=168.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.670 | L2-Norm(final)=9.964 | 3756.1 samples/s | 58.7 steps/s
[Step=89150 Epoch=168.0] | Loss=0.00000 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.656 | L2-Norm(final)=9.968 | 3699.0 samples/s | 57.8 steps/s
[Step=89200 Epoch=168.1] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.641 | L2-Norm(final)=9.971 | 3709.1 samples/s | 58.0 steps/s
[Step=89250 Epoch=168.2] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.627 | L2-Norm(final)=9.975 | 3725.8 samples/s | 58.2 steps/s
[Step=89300 Epoch=168.3] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.613 | L2-Norm(final)=9.979 | 3721.4 samples/s | 58.1 steps/s
[Step=89350 Epoch=168.4] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.599 | L2-Norm(final)=9.983 | 3768.0 samples/s | 58.9 steps/s
[Step=89400 Epoch=168.5] | Loss=0.00000 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.585 | L2-Norm(final)=9.987 | 3718.2 samples/s | 58.1 steps/s
[Step=89450 Epoch=168.6] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.571 | L2-Norm(final)=9.991 | 3756.0 samples/s | 58.7 steps/s
[Step=89500 Epoch=168.7] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.558 | L2-Norm(final)=9.995 | 3698.7 samples/s | 57.8 steps/s
[Step=89550 Epoch=168.8] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.544 | L2-Norm(final)=10.000 | 4693.7 samples/s | 73.3 steps/s
[Step=89600 Epoch=168.9] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=10.004 | 1519.0 samples/s | 23.7 steps/s
[Step=89650 Epoch=169.0] | Loss=0.00000 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.517 | L2-Norm(final)=10.009 | 3709.3 samples/s | 58.0 steps/s
[Step=89700 Epoch=169.1] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.504 | L2-Norm(final)=10.013 | 3685.4 samples/s | 57.6 steps/s
[Step=89750 Epoch=169.2] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.491 | L2-Norm(final)=10.018 | 3707.5 samples/s | 57.9 steps/s
[Step=89800 Epoch=169.3] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.477 | L2-Norm(final)=10.022 | 3745.6 samples/s | 58.5 steps/s
[Step=89850 Epoch=169.4] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.464 | L2-Norm(final)=10.027 | 3739.9 samples/s | 58.4 steps/s
[Step=89900 Epoch=169.5] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.450 | L2-Norm(final)=10.032 | 3719.8 samples/s | 58.1 steps/s
[Step=89950 Epoch=169.6] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.437 | L2-Norm(final)=10.036 | 3723.9 samples/s | 58.2 steps/s
[Step=90000 Epoch=169.7] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.424 | L2-Norm(final)=10.041 | 3674.9 samples/s | 57.4 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step90000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05732 | acc=0.9696 | tpr=0.9733 | fpr=0.0384 | 3576.6 samples/s | 14.0 steps/s
Avg test loss: 0.05921, Avg test acc: 0.96951, Avg tpr: 0.97366, Avg fpr: 0.03961, total FA: 309

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.85475 | acc=0.3074 | tpr=0.0185 | fpr=0.0652 | 3609.7 samples/s | 14.1 steps/s
Avg test loss: 4.85592, Avg test acc: 0.30539, Avg tpr: 0.01789, Avg fpr: 0.06230, total FA: 486

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.61023 | acc=0.1353 | tpr=0.7699 | fpr=0.8761 | 3624.4 samples/s | 14.2 steps/s
[Step= 100] | Loss=4.61673 | acc=0.1371 | tpr=0.7441 | fpr=0.8743 | 6742.6 samples/s | 26.3 steps/s
[Step= 150] | Loss=4.62166 | acc=0.1363 | tpr=0.7478 | fpr=0.8750 | 6668.2 samples/s | 26.0 steps/s
[Step= 200] | Loss=4.60916 | acc=0.1364 | tpr=0.7443 | fpr=0.8747 | 7054.2 samples/s | 27.6 steps/s
[Step= 250] | Loss=4.61280 | acc=0.1361 | tpr=0.7546 | fpr=0.8752 | 6695.6 samples/s | 26.2 steps/s
[Step= 300] | Loss=4.61101 | acc=0.1364 | tpr=0.7535 | fpr=0.8749 | 6840.8 samples/s | 26.7 steps/s
[Step= 350] | Loss=4.61124 | acc=0.1360 | tpr=0.7595 | fpr=0.8753 | 7004.9 samples/s | 27.4 steps/s
[Step= 400] | Loss=4.61589 | acc=0.1356 | tpr=0.7560 | fpr=0.8756 | 6707.9 samples/s | 26.2 steps/s
[Step= 450] | Loss=4.61948 | acc=0.1354 | tpr=0.7590 | fpr=0.8759 | 6753.8 samples/s | 26.4 steps/s
[Step= 500] | Loss=4.61967 | acc=0.1356 | tpr=0.7608 | fpr=0.8757 | 6793.0 samples/s | 26.5 steps/s
[Step= 550] | Loss=4.62004 | acc=0.1356 | tpr=0.7628 | fpr=0.8758 | 12419.2 samples/s | 48.5 steps/s
Avg test loss: 4.62070, Avg test acc: 0.13547, Avg tpr: 0.76268, Avg fpr: 0.87594, total FA: 121622

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09644 | acc=0.9816 | tpr=0.9690 | fpr=0.0182 | 3642.6 samples/s | 14.2 steps/s
[Step= 100] | Loss=0.10147 | acc=0.9809 | tpr=0.9723 | fpr=0.0190 | 6671.3 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.10290 | acc=0.9800 | tpr=0.9683 | fpr=0.0198 | 7169.5 samples/s | 28.0 steps/s
[Step= 200] | Loss=0.10445 | acc=0.9802 | tpr=0.9727 | fpr=0.0197 | 6666.0 samples/s | 26.0 steps/s
[Step= 250] | Loss=0.10323 | acc=0.9801 | tpr=0.9694 | fpr=0.0197 | 6933.5 samples/s | 27.1 steps/s
[Step= 300] | Loss=0.10526 | acc=0.9796 | tpr=0.9673 | fpr=0.0201 | 6650.8 samples/s | 26.0 steps/s
[Step= 350] | Loss=0.10567 | acc=0.9795 | tpr=0.9681 | fpr=0.0203 | 6992.6 samples/s | 27.3 steps/s
[Step= 400] | Loss=0.10618 | acc=0.9793 | tpr=0.9666 | fpr=0.0205 | 6821.7 samples/s | 26.6 steps/s
[Step= 450] | Loss=0.10862 | acc=0.9789 | tpr=0.9649 | fpr=0.0208 | 6728.8 samples/s | 26.3 steps/s
[Step= 500] | Loss=0.10810 | acc=0.9790 | tpr=0.9652 | fpr=0.0207 | 7090.0 samples/s | 27.7 steps/s
[Step= 550] | Loss=0.10750 | acc=0.9791 | tpr=0.9646 | fpr=0.0206 | 12025.2 samples/s | 47.0 steps/s
Avg test loss: 0.10728, Avg test acc: 0.97915, Avg tpr: 0.96474, Avg fpr: 0.02058, total FA: 2858

server round 45/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=87.9] | Loss=0.04288 | Reg=0.00057 | acc=0.9688 | L2-Norm=7.556 | L2-Norm(final)=15.467 | 3278.0 samples/s | 51.2 steps/s
[Step=90050 Epoch=87.9] | Loss=0.01903 | Reg=0.00057 | acc=0.9688 | L2-Norm=7.565 | L2-Norm(final)=15.473 | 4131.8 samples/s | 64.6 steps/s
[Step=90100 Epoch=88.0] | Loss=0.01861 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.573 | L2-Norm(final)=15.480 | 4339.0 samples/s | 67.8 steps/s
[Step=90150 Epoch=88.0] | Loss=0.01733 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.580 | L2-Norm(final)=15.486 | 4377.0 samples/s | 68.4 steps/s
[Step=90200 Epoch=88.1] | Loss=0.01748 | Reg=0.00058 | acc=0.9688 | L2-Norm=7.587 | L2-Norm(final)=15.492 | 4338.3 samples/s | 67.8 steps/s
[Step=90250 Epoch=88.1] | Loss=0.01742 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.594 | L2-Norm(final)=15.498 | 4348.1 samples/s | 67.9 steps/s
[Step=90300 Epoch=88.2] | Loss=0.01671 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.601 | L2-Norm(final)=15.504 | 4413.5 samples/s | 69.0 steps/s
[Step=90350 Epoch=88.2] | Loss=0.01670 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.607 | L2-Norm(final)=15.509 | 4332.9 samples/s | 67.7 steps/s
[Step=90400 Epoch=88.3] | Loss=0.01666 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.614 | L2-Norm(final)=15.515 | 4434.5 samples/s | 69.3 steps/s
[Step=90450 Epoch=88.3] | Loss=0.01655 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=15.520 | 4255.3 samples/s | 66.5 steps/s
[Step=90500 Epoch=88.4] | Loss=0.01643 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.625 | L2-Norm(final)=15.525 | 4355.8 samples/s | 68.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=88.4] | Loss=0.00620 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.682 | L2-Norm(final)=15.574 | 3373.3 samples/s | 52.7 steps/s
[Step=90550 Epoch=88.4] | Loss=0.01668 | Reg=0.00059 | acc=0.9688 | L2-Norm=7.688 | L2-Norm(final)=15.578 | 3865.3 samples/s | 60.4 steps/s
[Step=90600 Epoch=88.5] | Loss=0.01604 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.696 | L2-Norm(final)=15.583 | 3890.1 samples/s | 60.8 steps/s
[Step=90650 Epoch=88.5] | Loss=0.01560 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.703 | L2-Norm(final)=15.587 | 3871.2 samples/s | 60.5 steps/s
[Step=90700 Epoch=88.6] | Loss=0.01487 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.710 | L2-Norm(final)=15.591 | 3959.2 samples/s | 61.9 steps/s
[Step=90750 Epoch=88.6] | Loss=0.01462 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.716 | L2-Norm(final)=15.595 | 3861.7 samples/s | 60.3 steps/s
[Step=90800 Epoch=88.7] | Loss=0.01418 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.723 | L2-Norm(final)=15.599 | 3883.2 samples/s | 60.7 steps/s
[Step=90850 Epoch=88.7] | Loss=0.01388 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.728 | L2-Norm(final)=15.602 | 3949.0 samples/s | 61.7 steps/s
[Step=90900 Epoch=88.7] | Loss=0.01381 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.734 | L2-Norm(final)=15.606 | 3965.4 samples/s | 62.0 steps/s
[Step=90950 Epoch=88.8] | Loss=0.01348 | Reg=0.00060 | acc=0.9531 | L2-Norm=7.739 | L2-Norm(final)=15.609 | 3957.5 samples/s | 61.8 steps/s
[Step=91000 Epoch=88.8] | Loss=0.01343 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.745 | L2-Norm(final)=15.613 | 3896.7 samples/s | 60.9 steps/s
[Step=91050 Epoch=88.9] | Loss=0.01313 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.750 | L2-Norm(final)=15.616 | 3932.8 samples/s | 61.5 steps/s
[Step=91100 Epoch=88.9] | Loss=0.01310 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.755 | L2-Norm(final)=15.619 | 3909.4 samples/s | 61.1 steps/s
[Step=91150 Epoch=89.0] | Loss=0.01304 | Reg=0.00060 | acc=0.9688 | L2-Norm=7.760 | L2-Norm(final)=15.623 | 3994.0 samples/s | 62.4 steps/s
[Step=91200 Epoch=89.0] | Loss=0.01310 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.765 | L2-Norm(final)=15.626 | 3936.2 samples/s | 61.5 steps/s
[Step=91250 Epoch=89.1] | Loss=0.01301 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.770 | L2-Norm(final)=15.629 | 3923.3 samples/s | 61.3 steps/s
[Step=91300 Epoch=89.1] | Loss=0.01291 | Reg=0.00060 | acc=0.9844 | L2-Norm=7.775 | L2-Norm(final)=15.632 | 3951.6 samples/s | 61.7 steps/s
[Step=91350 Epoch=89.2] | Loss=0.01283 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.780 | L2-Norm(final)=15.635 | 3926.5 samples/s | 61.4 steps/s
[Step=91400 Epoch=89.2] | Loss=0.01272 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.785 | L2-Norm(final)=15.638 | 3965.2 samples/s | 62.0 steps/s
[Step=91450 Epoch=89.3] | Loss=0.01274 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.789 | L2-Norm(final)=15.641 | 3951.3 samples/s | 61.7 steps/s
[Step=91500 Epoch=89.3] | Loss=0.01269 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.794 | L2-Norm(final)=15.644 | 4194.9 samples/s | 65.5 steps/s
[Step=91550 Epoch=89.4] | Loss=0.01257 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.798 | L2-Norm(final)=15.647 | 1644.8 samples/s | 25.7 steps/s
[Step=91600 Epoch=89.4] | Loss=0.01239 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.803 | L2-Norm(final)=15.650 | 3909.2 samples/s | 61.1 steps/s
[Step=91650 Epoch=89.5] | Loss=0.01224 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.807 | L2-Norm(final)=15.653 | 3889.2 samples/s | 60.8 steps/s
[Step=91700 Epoch=89.5] | Loss=0.01210 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.812 | L2-Norm(final)=15.656 | 3921.2 samples/s | 61.3 steps/s
[Step=91750 Epoch=89.6] | Loss=0.01196 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.816 | L2-Norm(final)=15.659 | 3922.2 samples/s | 61.3 steps/s
[Step=91800 Epoch=89.6] | Loss=0.01177 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.820 | L2-Norm(final)=15.662 | 3945.3 samples/s | 61.6 steps/s
[Step=91850 Epoch=89.7] | Loss=0.01170 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.824 | L2-Norm(final)=15.665 | 3973.4 samples/s | 62.1 steps/s
[Step=91900 Epoch=89.7] | Loss=0.01158 | Reg=0.00061 | acc=1.0000 | L2-Norm=7.829 | L2-Norm(final)=15.668 | 3943.9 samples/s | 61.6 steps/s
[Step=91950 Epoch=89.8] | Loss=0.01146 | Reg=0.00061 | acc=0.9844 | L2-Norm=7.833 | L2-Norm(final)=15.671 | 3898.2 samples/s | 60.9 steps/s
[Step=92000 Epoch=89.8] | Loss=0.01139 | Reg=0.00061 | acc=0.9688 | L2-Norm=7.837 | L2-Norm(final)=15.673 | 3957.6 samples/s | 61.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step92000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=90001 Epoch=169.7] | Loss=0.00006 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.556 | L2-Norm(final)=10.186 | 3213.1 samples/s | 50.2 steps/s
[Step=90050 Epoch=169.7] | Loss=0.00002 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.554 | L2-Norm(final)=10.205 | 3907.0 samples/s | 61.0 steps/s
[Step=90100 Epoch=169.8] | Loss=0.00002 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.550 | L2-Norm(final)=10.217 | 4105.3 samples/s | 64.1 steps/s
[Step=90150 Epoch=169.9] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.545 | L2-Norm(final)=10.227 | 4188.6 samples/s | 65.4 steps/s
[Step=90200 Epoch=170.0] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.540 | L2-Norm(final)=10.235 | 4055.8 samples/s | 63.4 steps/s
[Step=90250 Epoch=170.1] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.535 | L2-Norm(final)=10.243 | 4055.9 samples/s | 63.4 steps/s
[Step=90300 Epoch=170.2] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.531 | L2-Norm(final)=10.251 | 4163.7 samples/s | 65.1 steps/s
[Step=90350 Epoch=170.3] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.526 | L2-Norm(final)=10.259 | 4105.3 samples/s | 64.1 steps/s
[Step=90400 Epoch=170.4] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.522 | L2-Norm(final)=10.266 | 4142.2 samples/s | 64.7 steps/s
[Step=90450 Epoch=170.5] | Loss=0.00001 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.518 | L2-Norm(final)=10.274 | 4075.5 samples/s | 63.7 steps/s
[Step=90500 Epoch=170.6] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.514 | L2-Norm(final)=10.281 | 4159.5 samples/s | 65.0 steps/s
All layers training...
LR=0.00006, len=1
[Step=90501 Epoch=170.6] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=10.351 | 3234.7 samples/s | 50.5 steps/s
[Step=90550 Epoch=170.7] | Loss=0.00000 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.459 | L2-Norm(final)=10.356 | 3450.7 samples/s | 53.9 steps/s
[Step=90600 Epoch=170.8] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.440 | L2-Norm(final)=10.361 | 3724.2 samples/s | 58.2 steps/s
[Step=90650 Epoch=170.9] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.421 | L2-Norm(final)=10.366 | 3711.3 samples/s | 58.0 steps/s
[Step=90700 Epoch=171.0] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.402 | L2-Norm(final)=10.370 | 3670.6 samples/s | 57.4 steps/s
[Step=90750 Epoch=171.1] | Loss=0.00000 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.383 | L2-Norm(final)=10.374 | 3695.2 samples/s | 57.7 steps/s
[Step=90800 Epoch=171.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.364 | L2-Norm(final)=10.378 | 3757.4 samples/s | 58.7 steps/s
[Step=90850 Epoch=171.3] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.345 | L2-Norm(final)=10.382 | 3698.4 samples/s | 57.8 steps/s
[Step=90900 Epoch=171.3] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.326 | L2-Norm(final)=10.387 | 3689.8 samples/s | 57.7 steps/s
[Step=90950 Epoch=171.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.308 | L2-Norm(final)=10.392 | 3673.5 samples/s | 57.4 steps/s
[Step=91000 Epoch=171.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=10.398 | 3747.6 samples/s | 58.6 steps/s
[Step=91050 Epoch=171.6] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.274 | L2-Norm(final)=10.403 | 1623.9 samples/s | 25.4 steps/s
[Step=91100 Epoch=171.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.256 | L2-Norm(final)=10.408 | 3689.0 samples/s | 57.6 steps/s
[Step=91150 Epoch=171.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.239 | L2-Norm(final)=10.413 | 3724.8 samples/s | 58.2 steps/s
[Step=91200 Epoch=171.9] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.221 | L2-Norm(final)=10.418 | 3659.1 samples/s | 57.2 steps/s
[Step=91250 Epoch=172.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.204 | L2-Norm(final)=10.422 | 3698.7 samples/s | 57.8 steps/s
[Step=91300 Epoch=172.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.187 | L2-Norm(final)=10.427 | 3704.6 samples/s | 57.9 steps/s
[Step=91350 Epoch=172.2] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.171 | L2-Norm(final)=10.432 | 3673.7 samples/s | 57.4 steps/s
[Step=91400 Epoch=172.3] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=10.437 | 3691.2 samples/s | 57.7 steps/s
[Step=91450 Epoch=172.4] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.145 | L2-Norm(final)=10.441 | 3716.1 samples/s | 58.1 steps/s
[Step=91500 Epoch=172.5] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.134 | L2-Norm(final)=10.444 | 3692.4 samples/s | 57.7 steps/s
[Step=91550 Epoch=172.6] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.124 | L2-Norm(final)=10.448 | 4634.7 samples/s | 72.4 steps/s
[Step=91600 Epoch=172.7] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.115 | L2-Norm(final)=10.451 | 1524.3 samples/s | 23.8 steps/s
[Step=91650 Epoch=172.8] | Loss=0.00003 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.106 | L2-Norm(final)=10.454 | 3653.2 samples/s | 57.1 steps/s
[Step=91700 Epoch=172.9] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=10.457 | 3731.3 samples/s | 58.3 steps/s
[Step=91750 Epoch=173.0] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.091 | L2-Norm(final)=10.459 | 3652.9 samples/s | 57.1 steps/s
[Step=91800 Epoch=173.0] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.085 | L2-Norm(final)=10.462 | 3718.6 samples/s | 58.1 steps/s
[Step=91850 Epoch=173.1] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.078 | L2-Norm(final)=10.464 | 3718.3 samples/s | 58.1 steps/s
[Step=91900 Epoch=173.2] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.073 | L2-Norm(final)=10.466 | 3742.0 samples/s | 58.5 steps/s
[Step=91950 Epoch=173.3] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.067 | L2-Norm(final)=10.468 | 3698.0 samples/s | 57.8 steps/s
[Step=92000 Epoch=173.4] | Loss=0.00003 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.062 | L2-Norm(final)=10.470 | 3730.4 samples/s | 58.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step92000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05377 | acc=0.9702 | tpr=0.9740 | fpr=0.0379 | 3590.3 samples/s | 14.0 steps/s
Avg test loss: 0.05521, Avg test acc: 0.97011, Avg tpr: 0.97412, Avg fpr: 0.03871, total FA: 302

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.89890 | acc=0.3079 | tpr=0.0100 | fpr=0.0453 | 3606.8 samples/s | 14.1 steps/s
Avg test loss: 4.90112, Avg test acc: 0.30567, Avg tpr: 0.01003, Avg fpr: 0.04410, total FA: 344

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.57297 | acc=0.1272 | tpr=0.7920 | fpr=0.8848 | 3608.6 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.57691 | acc=0.1298 | tpr=0.7804 | fpr=0.8824 | 6941.4 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.58120 | acc=0.1288 | tpr=0.7824 | fpr=0.8832 | 6875.6 samples/s | 26.9 steps/s
[Step= 200] | Loss=4.56939 | acc=0.1285 | tpr=0.7760 | fpr=0.8833 | 6841.3 samples/s | 26.7 steps/s
[Step= 250] | Loss=4.57317 | acc=0.1280 | tpr=0.7843 | fpr=0.8840 | 6853.7 samples/s | 26.8 steps/s
[Step= 300] | Loss=4.57179 | acc=0.1282 | tpr=0.7855 | fpr=0.8838 | 6951.3 samples/s | 27.2 steps/s
[Step= 350] | Loss=4.57222 | acc=0.1278 | tpr=0.7921 | fpr=0.8843 | 6981.7 samples/s | 27.3 steps/s
[Step= 400] | Loss=4.57758 | acc=0.1275 | tpr=0.7899 | fpr=0.8846 | 6682.6 samples/s | 26.1 steps/s
[Step= 450] | Loss=4.58014 | acc=0.1271 | tpr=0.7955 | fpr=0.8850 | 6893.8 samples/s | 26.9 steps/s
[Step= 500] | Loss=4.58040 | acc=0.1271 | tpr=0.7965 | fpr=0.8850 | 6894.2 samples/s | 26.9 steps/s
[Step= 550] | Loss=4.58054 | acc=0.1271 | tpr=0.7975 | fpr=0.8851 | 12741.8 samples/s | 49.8 steps/s
Avg test loss: 4.58112, Avg test acc: 0.12701, Avg tpr: 0.79715, Avg fpr: 0.88518, total FA: 122905

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08534 | acc=0.9823 | tpr=0.9690 | fpr=0.0174 | 3621.8 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.09017 | acc=0.9811 | tpr=0.9680 | fpr=0.0187 | 6869.8 samples/s | 26.8 steps/s
[Step= 150] | Loss=0.09163 | acc=0.9804 | tpr=0.9669 | fpr=0.0193 | 6847.8 samples/s | 26.7 steps/s
[Step= 200] | Loss=0.09325 | acc=0.9805 | tpr=0.9716 | fpr=0.0193 | 6864.3 samples/s | 26.8 steps/s
[Step= 250] | Loss=0.09216 | acc=0.9805 | tpr=0.9694 | fpr=0.0193 | 6895.1 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.09394 | acc=0.9801 | tpr=0.9687 | fpr=0.0197 | 6846.9 samples/s | 26.7 steps/s
[Step= 350] | Loss=0.09422 | acc=0.9799 | tpr=0.9687 | fpr=0.0199 | 7056.8 samples/s | 27.6 steps/s
[Step= 400] | Loss=0.09479 | acc=0.9797 | tpr=0.9677 | fpr=0.0201 | 6639.4 samples/s | 25.9 steps/s
[Step= 450] | Loss=0.09689 | acc=0.9794 | tpr=0.9649 | fpr=0.0203 | 6958.0 samples/s | 27.2 steps/s
[Step= 500] | Loss=0.09647 | acc=0.9795 | tpr=0.9656 | fpr=0.0203 | 6830.4 samples/s | 26.7 steps/s
[Step= 550] | Loss=0.09590 | acc=0.9796 | tpr=0.9654 | fpr=0.0201 | 12283.6 samples/s | 48.0 steps/s
Avg test loss: 0.09570, Avg test acc: 0.97967, Avg tpr: 0.96553, Avg fpr: 0.02007, total FA: 2787

server round 46/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=89.8] | Loss=0.02409 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.354 | L2-Norm(final)=15.756 | 3395.0 samples/s | 53.0 steps/s
[Step=92050 Epoch=89.9] | Loss=0.02249 | Reg=0.00054 | acc=0.9688 | L2-Norm=7.363 | L2-Norm(final)=15.763 | 4106.0 samples/s | 64.2 steps/s
[Step=92100 Epoch=89.9] | Loss=0.02088 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.372 | L2-Norm(final)=15.771 | 4356.1 samples/s | 68.1 steps/s
[Step=92150 Epoch=90.0] | Loss=0.02015 | Reg=0.00054 | acc=0.9844 | L2-Norm=7.380 | L2-Norm(final)=15.779 | 4351.3 samples/s | 68.0 steps/s
[Step=92200 Epoch=90.0] | Loss=0.01945 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=15.786 | 4347.3 samples/s | 67.9 steps/s
[Step=92250 Epoch=90.1] | Loss=0.01943 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.397 | L2-Norm(final)=15.793 | 4355.1 samples/s | 68.0 steps/s
[Step=92300 Epoch=90.1] | Loss=0.01904 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.405 | L2-Norm(final)=15.799 | 4313.4 samples/s | 67.4 steps/s
[Step=92350 Epoch=90.2] | Loss=0.01876 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.412 | L2-Norm(final)=15.806 | 4394.5 samples/s | 68.7 steps/s
[Step=92400 Epoch=90.2] | Loss=0.01856 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.419 | L2-Norm(final)=15.812 | 4335.6 samples/s | 67.7 steps/s
[Step=92450 Epoch=90.3] | Loss=0.01859 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.427 | L2-Norm(final)=15.819 | 4416.6 samples/s | 69.0 steps/s
[Step=92500 Epoch=90.3] | Loss=0.01849 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.434 | L2-Norm(final)=15.825 | 4308.6 samples/s | 67.3 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=90.3] | Loss=0.02034 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.505 | L2-Norm(final)=15.883 | 3179.0 samples/s | 49.7 steps/s
[Step=92550 Epoch=90.4] | Loss=0.01489 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.513 | L2-Norm(final)=15.888 | 3960.2 samples/s | 61.9 steps/s
[Step=92600 Epoch=90.4] | Loss=0.01489 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.522 | L2-Norm(final)=15.893 | 3914.4 samples/s | 61.2 steps/s
[Step=92650 Epoch=90.5] | Loss=0.01548 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.530 | L2-Norm(final)=15.898 | 3892.4 samples/s | 60.8 steps/s
[Step=92700 Epoch=90.5] | Loss=0.01471 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.538 | L2-Norm(final)=15.902 | 3896.7 samples/s | 60.9 steps/s
[Step=92750 Epoch=90.6] | Loss=0.01484 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.547 | L2-Norm(final)=15.907 | 3882.1 samples/s | 60.7 steps/s
[Step=92800 Epoch=90.6] | Loss=0.01485 | Reg=0.00057 | acc=0.9688 | L2-Norm=7.554 | L2-Norm(final)=15.911 | 3950.2 samples/s | 61.7 steps/s
[Step=92850 Epoch=90.7] | Loss=0.01460 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.561 | L2-Norm(final)=15.915 | 3849.9 samples/s | 60.2 steps/s
[Step=92900 Epoch=90.7] | Loss=0.01435 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.567 | L2-Norm(final)=15.919 | 3943.1 samples/s | 61.6 steps/s
[Step=92950 Epoch=90.8] | Loss=0.01425 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.574 | L2-Norm(final)=15.923 | 3905.1 samples/s | 61.0 steps/s
[Step=93000 Epoch=90.8] | Loss=0.01406 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.580 | L2-Norm(final)=15.927 | 3956.0 samples/s | 61.8 steps/s
[Step=93050 Epoch=90.8] | Loss=0.01404 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.586 | L2-Norm(final)=15.930 | 3905.6 samples/s | 61.0 steps/s
[Step=93100 Epoch=90.9] | Loss=0.01404 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.592 | L2-Norm(final)=15.934 | 3878.2 samples/s | 60.6 steps/s
[Step=93150 Epoch=90.9] | Loss=0.01377 | Reg=0.00058 | acc=0.9688 | L2-Norm=7.598 | L2-Norm(final)=15.937 | 3955.4 samples/s | 61.8 steps/s
[Step=93200 Epoch=91.0] | Loss=0.01363 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.604 | L2-Norm(final)=15.941 | 3886.4 samples/s | 60.7 steps/s
[Step=93250 Epoch=91.0] | Loss=0.01352 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.609 | L2-Norm(final)=15.944 | 3921.9 samples/s | 61.3 steps/s
[Step=93300 Epoch=91.1] | Loss=0.01335 | Reg=0.00058 | acc=0.9688 | L2-Norm=7.615 | L2-Norm(final)=15.948 | 3934.6 samples/s | 61.5 steps/s
[Step=93350 Epoch=91.1] | Loss=0.01332 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.620 | L2-Norm(final)=15.951 | 3853.9 samples/s | 60.2 steps/s
[Step=93400 Epoch=91.2] | Loss=0.01322 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.625 | L2-Norm(final)=15.954 | 3936.5 samples/s | 61.5 steps/s
[Step=93450 Epoch=91.2] | Loss=0.01323 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.630 | L2-Norm(final)=15.957 | 3885.3 samples/s | 60.7 steps/s
[Step=93500 Epoch=91.3] | Loss=0.01320 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.635 | L2-Norm(final)=15.960 | 4184.3 samples/s | 65.4 steps/s
[Step=93550 Epoch=91.3] | Loss=0.01302 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.640 | L2-Norm(final)=15.963 | 1642.9 samples/s | 25.7 steps/s
[Step=93600 Epoch=91.4] | Loss=0.01290 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.645 | L2-Norm(final)=15.966 | 3891.2 samples/s | 60.8 steps/s
[Step=93650 Epoch=91.4] | Loss=0.01282 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.650 | L2-Norm(final)=15.970 | 3860.2 samples/s | 60.3 steps/s
[Step=93700 Epoch=91.5] | Loss=0.01267 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.655 | L2-Norm(final)=15.973 | 3894.5 samples/s | 60.9 steps/s
[Step=93750 Epoch=91.5] | Loss=0.01252 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.660 | L2-Norm(final)=15.976 | 3894.6 samples/s | 60.9 steps/s
[Step=93800 Epoch=91.6] | Loss=0.01240 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.664 | L2-Norm(final)=15.979 | 3916.9 samples/s | 61.2 steps/s
[Step=93850 Epoch=91.6] | Loss=0.01230 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.669 | L2-Norm(final)=15.982 | 3907.1 samples/s | 61.0 steps/s
[Step=93900 Epoch=91.7] | Loss=0.01217 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.673 | L2-Norm(final)=15.985 | 3928.0 samples/s | 61.4 steps/s
[Step=93950 Epoch=91.7] | Loss=0.01211 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.678 | L2-Norm(final)=15.988 | 3904.5 samples/s | 61.0 steps/s
[Step=94000 Epoch=91.8] | Loss=0.01199 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.682 | L2-Norm(final)=15.991 | 3922.0 samples/s | 61.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step94000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=92001 Epoch=173.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.354 | L2-Norm(final)=10.523 | 3233.5 samples/s | 50.5 steps/s
[Step=92050 Epoch=173.5] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.353 | L2-Norm(final)=10.524 | 3853.0 samples/s | 60.2 steps/s
[Step=92100 Epoch=173.6] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.352 | L2-Norm(final)=10.525 | 4129.1 samples/s | 64.5 steps/s
[Step=92150 Epoch=173.7] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.351 | L2-Norm(final)=10.526 | 4069.3 samples/s | 63.6 steps/s
[Step=92200 Epoch=173.8] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.351 | L2-Norm(final)=10.527 | 4119.4 samples/s | 64.4 steps/s
[Step=92250 Epoch=173.9] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=10.528 | 4047.4 samples/s | 63.2 steps/s
[Step=92300 Epoch=174.0] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.350 | L2-Norm(final)=10.529 | 4121.9 samples/s | 64.4 steps/s
[Step=92350 Epoch=174.1] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.349 | L2-Norm(final)=10.530 | 4164.7 samples/s | 65.1 steps/s
[Step=92400 Epoch=174.2] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.349 | L2-Norm(final)=10.531 | 4151.8 samples/s | 64.9 steps/s
[Step=92450 Epoch=174.3] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.348 | L2-Norm(final)=10.532 | 4124.6 samples/s | 64.4 steps/s
[Step=92500 Epoch=174.4] | Loss=0.00002 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.348 | L2-Norm(final)=10.533 | 4064.8 samples/s | 63.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=92501 Epoch=174.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.345 | L2-Norm(final)=10.543 | 3110.4 samples/s | 48.6 steps/s
[Step=92550 Epoch=174.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.344 | L2-Norm(final)=10.544 | 3592.6 samples/s | 56.1 steps/s
[Step=92600 Epoch=174.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.343 | L2-Norm(final)=10.545 | 3727.6 samples/s | 58.2 steps/s
[Step=92650 Epoch=174.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.342 | L2-Norm(final)=10.545 | 3686.7 samples/s | 57.6 steps/s
[Step=92700 Epoch=174.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.340 | L2-Norm(final)=10.546 | 3695.5 samples/s | 57.7 steps/s
[Step=92750 Epoch=174.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.339 | L2-Norm(final)=10.547 | 3690.9 samples/s | 57.7 steps/s
[Step=92800 Epoch=174.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.338 | L2-Norm(final)=10.548 | 3750.0 samples/s | 58.6 steps/s
[Step=92850 Epoch=175.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.336 | L2-Norm(final)=10.548 | 3720.2 samples/s | 58.1 steps/s
[Step=92900 Epoch=175.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.335 | L2-Norm(final)=10.549 | 3721.2 samples/s | 58.1 steps/s
[Step=92950 Epoch=175.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.333 | L2-Norm(final)=10.550 | 3766.7 samples/s | 58.9 steps/s
[Step=93000 Epoch=175.3] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.331 | L2-Norm(final)=10.550 | 3777.1 samples/s | 59.0 steps/s
[Step=93050 Epoch=175.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.330 | L2-Norm(final)=10.551 | 1673.2 samples/s | 26.1 steps/s
[Step=93100 Epoch=175.5] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.328 | L2-Norm(final)=10.551 | 3722.1 samples/s | 58.2 steps/s
[Step=93150 Epoch=175.6] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.326 | L2-Norm(final)=10.552 | 3675.6 samples/s | 57.4 steps/s
[Step=93200 Epoch=175.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.324 | L2-Norm(final)=10.553 | 3731.6 samples/s | 58.3 steps/s
[Step=93250 Epoch=175.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.323 | L2-Norm(final)=10.553 | 3737.9 samples/s | 58.4 steps/s
[Step=93300 Epoch=175.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.321 | L2-Norm(final)=10.554 | 3701.7 samples/s | 57.8 steps/s
[Step=93350 Epoch=176.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.319 | L2-Norm(final)=10.554 | 3743.5 samples/s | 58.5 steps/s
[Step=93400 Epoch=176.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.317 | L2-Norm(final)=10.555 | 3767.7 samples/s | 58.9 steps/s
[Step=93450 Epoch=176.2] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.315 | L2-Norm(final)=10.555 | 3704.0 samples/s | 57.9 steps/s
[Step=93500 Epoch=176.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.313 | L2-Norm(final)=10.556 | 3692.9 samples/s | 57.7 steps/s
[Step=93550 Epoch=176.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.310 | L2-Norm(final)=10.557 | 4674.4 samples/s | 73.0 steps/s
[Step=93600 Epoch=176.4] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.308 | L2-Norm(final)=10.557 | 1492.2 samples/s | 23.3 steps/s
[Step=93650 Epoch=176.5] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.306 | L2-Norm(final)=10.558 | 3737.8 samples/s | 58.4 steps/s
[Step=93700 Epoch=176.6] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.304 | L2-Norm(final)=10.558 | 3741.7 samples/s | 58.5 steps/s
[Step=93750 Epoch=176.7] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.302 | L2-Norm(final)=10.559 | 3713.6 samples/s | 58.0 steps/s
[Step=93800 Epoch=176.8] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.299 | L2-Norm(final)=10.559 | 3721.7 samples/s | 58.2 steps/s
[Step=93850 Epoch=176.9] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.297 | L2-Norm(final)=10.560 | 3727.1 samples/s | 58.2 steps/s
[Step=93900 Epoch=177.0] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.295 | L2-Norm(final)=10.560 | 3693.5 samples/s | 57.7 steps/s
[Step=93950 Epoch=177.1] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.292 | L2-Norm(final)=10.561 | 3732.3 samples/s | 58.3 steps/s
[Step=94000 Epoch=177.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=10.562 | 3779.5 samples/s | 59.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step94000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05394 | acc=0.9710 | tpr=0.9754 | fpr=0.0384 | 3603.5 samples/s | 14.1 steps/s
Avg test loss: 0.05512, Avg test acc: 0.97039, Avg tpr: 0.97482, Avg fpr: 0.03935, total FA: 307

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.69272 | acc=0.3083 | tpr=0.0145 | fpr=0.0538 | 3677.7 samples/s | 14.4 steps/s
Avg test loss: 4.69350, Avg test acc: 0.30619, Avg tpr: 0.01463, Avg fpr: 0.05256, total FA: 410

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.54528 | acc=0.1292 | tpr=0.7655 | fpr=0.8822 | 3600.9 samples/s | 14.1 steps/s
[Step= 100] | Loss=4.54726 | acc=0.1322 | tpr=0.7569 | fpr=0.8795 | 6936.8 samples/s | 27.1 steps/s
[Step= 150] | Loss=4.55216 | acc=0.1305 | tpr=0.7594 | fpr=0.8810 | 6881.6 samples/s | 26.9 steps/s
[Step= 200] | Loss=4.54023 | acc=0.1300 | tpr=0.7585 | fpr=0.8815 | 6999.6 samples/s | 27.3 steps/s
[Step= 250] | Loss=4.54429 | acc=0.1294 | tpr=0.7642 | fpr=0.8821 | 6954.0 samples/s | 27.2 steps/s
[Step= 300] | Loss=4.54309 | acc=0.1297 | tpr=0.7636 | fpr=0.8818 | 6892.2 samples/s | 26.9 steps/s
[Step= 350] | Loss=4.54324 | acc=0.1293 | tpr=0.7702 | fpr=0.8823 | 6927.2 samples/s | 27.1 steps/s
[Step= 400] | Loss=4.54793 | acc=0.1291 | tpr=0.7675 | fpr=0.8825 | 7027.0 samples/s | 27.4 steps/s
[Step= 450] | Loss=4.55055 | acc=0.1289 | tpr=0.7712 | fpr=0.8827 | 6559.6 samples/s | 25.6 steps/s
[Step= 500] | Loss=4.55021 | acc=0.1292 | tpr=0.7727 | fpr=0.8824 | 6937.4 samples/s | 27.1 steps/s
[Step= 550] | Loss=4.55036 | acc=0.1293 | tpr=0.7748 | fpr=0.8825 | 12285.9 samples/s | 48.0 steps/s
Avg test loss: 4.55086, Avg test acc: 0.12919, Avg tpr: 0.77456, Avg fpr: 0.88254, total FA: 122539

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09254 | acc=0.9817 | tpr=0.9646 | fpr=0.0180 | 3649.3 samples/s | 14.3 steps/s
[Step= 100] | Loss=0.09730 | acc=0.9807 | tpr=0.9680 | fpr=0.0191 | 6829.1 samples/s | 26.7 steps/s
[Step= 150] | Loss=0.09824 | acc=0.9800 | tpr=0.9654 | fpr=0.0197 | 6635.0 samples/s | 25.9 steps/s
[Step= 200] | Loss=0.10005 | acc=0.9802 | tpr=0.9705 | fpr=0.0196 | 6971.0 samples/s | 27.2 steps/s
[Step= 250] | Loss=0.09887 | acc=0.9802 | tpr=0.9686 | fpr=0.0196 | 6644.5 samples/s | 26.0 steps/s
[Step= 300] | Loss=0.10075 | acc=0.9798 | tpr=0.9665 | fpr=0.0200 | 6925.6 samples/s | 27.1 steps/s
[Step= 350] | Loss=0.10088 | acc=0.9796 | tpr=0.9668 | fpr=0.0201 | 6639.4 samples/s | 25.9 steps/s
[Step= 400] | Loss=0.10138 | acc=0.9795 | tpr=0.9661 | fpr=0.0203 | 6768.6 samples/s | 26.4 steps/s
[Step= 450] | Loss=0.10366 | acc=0.9791 | tpr=0.9640 | fpr=0.0206 | 6858.2 samples/s | 26.8 steps/s
[Step= 500] | Loss=0.10314 | acc=0.9792 | tpr=0.9648 | fpr=0.0206 | 6729.6 samples/s | 26.3 steps/s
[Step= 550] | Loss=0.10262 | acc=0.9793 | tpr=0.9646 | fpr=0.0204 | 12803.1 samples/s | 50.0 steps/s
Avg test loss: 0.10241, Avg test acc: 0.97937, Avg tpr: 0.96474, Avg fpr: 0.02037, total FA: 2828

server round 47/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=91.8] | Loss=0.01582 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=16.078 | 3395.7 samples/s | 53.1 steps/s
[Step=94050 Epoch=91.8] | Loss=0.01347 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.478 | L2-Norm(final)=16.083 | 3956.7 samples/s | 61.8 steps/s
[Step=94100 Epoch=91.9] | Loss=0.01352 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.484 | L2-Norm(final)=16.087 | 4235.2 samples/s | 66.2 steps/s
[Step=94150 Epoch=91.9] | Loss=0.01289 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.490 | L2-Norm(final)=16.091 | 4284.0 samples/s | 66.9 steps/s
[Step=94200 Epoch=92.0] | Loss=0.01289 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.495 | L2-Norm(final)=16.096 | 4320.5 samples/s | 67.5 steps/s
[Step=94250 Epoch=92.0] | Loss=0.01270 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.500 | L2-Norm(final)=16.100 | 4356.7 samples/s | 68.1 steps/s
[Step=94300 Epoch=92.1] | Loss=0.01258 | Reg=0.00056 | acc=0.9688 | L2-Norm=7.506 | L2-Norm(final)=16.104 | 4378.3 samples/s | 68.4 steps/s
[Step=94350 Epoch=92.1] | Loss=0.01259 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.511 | L2-Norm(final)=16.109 | 4364.1 samples/s | 68.2 steps/s
[Step=94400 Epoch=92.2] | Loss=0.01273 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.517 | L2-Norm(final)=16.113 | 4328.4 samples/s | 67.6 steps/s
[Step=94450 Epoch=92.2] | Loss=0.01271 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.522 | L2-Norm(final)=16.117 | 4290.2 samples/s | 67.0 steps/s
[Step=94500 Epoch=92.3] | Loss=0.01251 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.527 | L2-Norm(final)=16.121 | 4381.2 samples/s | 68.5 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=92.3] | Loss=0.01148 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.579 | L2-Norm(final)=16.162 | 3267.7 samples/s | 51.1 steps/s
[Step=94550 Epoch=92.3] | Loss=0.01032 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.585 | L2-Norm(final)=16.166 | 3766.7 samples/s | 58.9 steps/s
[Step=94600 Epoch=92.4] | Loss=0.01236 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.592 | L2-Norm(final)=16.170 | 3892.5 samples/s | 60.8 steps/s
[Step=94650 Epoch=92.4] | Loss=0.01231 | Reg=0.00058 | acc=0.9688 | L2-Norm=7.599 | L2-Norm(final)=16.173 | 3882.2 samples/s | 60.7 steps/s
[Step=94700 Epoch=92.5] | Loss=0.01257 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.605 | L2-Norm(final)=16.177 | 3905.0 samples/s | 61.0 steps/s
[Step=94750 Epoch=92.5] | Loss=0.01244 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.611 | L2-Norm(final)=16.180 | 3916.9 samples/s | 61.2 steps/s
[Step=94800 Epoch=92.6] | Loss=0.01254 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.617 | L2-Norm(final)=16.184 | 3946.0 samples/s | 61.7 steps/s
[Step=94850 Epoch=92.6] | Loss=0.01219 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.623 | L2-Norm(final)=16.187 | 3908.4 samples/s | 61.1 steps/s
[Step=94900 Epoch=92.7] | Loss=0.01204 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.629 | L2-Norm(final)=16.190 | 3952.0 samples/s | 61.7 steps/s
[Step=94950 Epoch=92.7] | Loss=0.01169 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.634 | L2-Norm(final)=16.193 | 3961.5 samples/s | 61.9 steps/s
[Step=95000 Epoch=92.8] | Loss=0.01177 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.639 | L2-Norm(final)=16.196 | 3900.2 samples/s | 60.9 steps/s
[Step=95050 Epoch=92.8] | Loss=0.01201 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.644 | L2-Norm(final)=16.199 | 3971.1 samples/s | 62.0 steps/s
[Step=95100 Epoch=92.8] | Loss=0.01200 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.649 | L2-Norm(final)=16.202 | 3905.1 samples/s | 61.0 steps/s
[Step=95150 Epoch=92.9] | Loss=0.01202 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.654 | L2-Norm(final)=16.205 | 3949.5 samples/s | 61.7 steps/s
[Step=95200 Epoch=92.9] | Loss=0.01194 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.659 | L2-Norm(final)=16.208 | 3923.9 samples/s | 61.3 steps/s
[Step=95250 Epoch=93.0] | Loss=0.01189 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.663 | L2-Norm(final)=16.210 | 3945.4 samples/s | 61.6 steps/s
[Step=95300 Epoch=93.0] | Loss=0.01171 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.668 | L2-Norm(final)=16.213 | 3971.7 samples/s | 62.1 steps/s
[Step=95350 Epoch=93.1] | Loss=0.01169 | Reg=0.00059 | acc=0.9531 | L2-Norm=7.673 | L2-Norm(final)=16.216 | 3931.2 samples/s | 61.4 steps/s
[Step=95400 Epoch=93.1] | Loss=0.01164 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.677 | L2-Norm(final)=16.218 | 3925.9 samples/s | 61.3 steps/s
[Step=95450 Epoch=93.2] | Loss=0.01163 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.682 | L2-Norm(final)=16.221 | 3938.9 samples/s | 61.5 steps/s
[Step=95500 Epoch=93.2] | Loss=0.01152 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.686 | L2-Norm(final)=16.224 | 4219.0 samples/s | 65.9 steps/s
[Step=95550 Epoch=93.3] | Loss=0.01138 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.691 | L2-Norm(final)=16.226 | 1679.7 samples/s | 26.2 steps/s
[Step=95600 Epoch=93.3] | Loss=0.01130 | Reg=0.00059 | acc=0.9688 | L2-Norm=7.695 | L2-Norm(final)=16.229 | 3950.5 samples/s | 61.7 steps/s
[Step=95650 Epoch=93.4] | Loss=0.01117 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.699 | L2-Norm(final)=16.231 | 3915.9 samples/s | 61.2 steps/s
[Step=95700 Epoch=93.4] | Loss=0.01108 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.703 | L2-Norm(final)=16.234 | 3911.9 samples/s | 61.1 steps/s
[Step=95750 Epoch=93.5] | Loss=0.01094 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.707 | L2-Norm(final)=16.236 | 3928.0 samples/s | 61.4 steps/s
[Step=95800 Epoch=93.5] | Loss=0.01081 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.711 | L2-Norm(final)=16.238 | 3940.0 samples/s | 61.6 steps/s
[Step=95850 Epoch=93.6] | Loss=0.01075 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.715 | L2-Norm(final)=16.241 | 3965.8 samples/s | 62.0 steps/s
[Step=95900 Epoch=93.6] | Loss=0.01067 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.718 | L2-Norm(final)=16.243 | 3961.1 samples/s | 61.9 steps/s
[Step=95950 Epoch=93.7] | Loss=0.01062 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.722 | L2-Norm(final)=16.246 | 3921.1 samples/s | 61.3 steps/s
[Step=96000 Epoch=93.7] | Loss=0.01061 | Reg=0.00060 | acc=1.0000 | L2-Norm=7.726 | L2-Norm(final)=16.248 | 3937.0 samples/s | 61.5 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step96000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=94001 Epoch=177.2] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.472 | L2-Norm(final)=10.579 | 3323.6 samples/s | 51.9 steps/s
[Step=94050 Epoch=177.3] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.469 | L2-Norm(final)=10.581 | 3760.6 samples/s | 58.8 steps/s
[Step=94100 Epoch=177.4] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.467 | L2-Norm(final)=10.584 | 4063.5 samples/s | 63.5 steps/s
[Step=94150 Epoch=177.5] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.466 | L2-Norm(final)=10.586 | 4085.6 samples/s | 63.8 steps/s
[Step=94200 Epoch=177.6] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.465 | L2-Norm(final)=10.589 | 4139.2 samples/s | 64.7 steps/s
[Step=94250 Epoch=177.7] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.463 | L2-Norm(final)=10.592 | 4188.0 samples/s | 65.4 steps/s
[Step=94300 Epoch=177.8] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.462 | L2-Norm(final)=10.594 | 4189.8 samples/s | 65.5 steps/s
[Step=94350 Epoch=177.9] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.461 | L2-Norm(final)=10.597 | 4182.8 samples/s | 65.4 steps/s
[Step=94400 Epoch=177.9] | Loss=0.00002 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.459 | L2-Norm(final)=10.599 | 4102.7 samples/s | 64.1 steps/s
[Step=94450 Epoch=178.0] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.458 | L2-Norm(final)=10.601 | 4100.7 samples/s | 64.1 steps/s
[Step=94500 Epoch=178.1] | Loss=0.00001 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.456 | L2-Norm(final)=10.603 | 4228.8 samples/s | 66.1 steps/s
All layers training...
LR=0.00006, len=1
[Step=94501 Epoch=178.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.442 | L2-Norm(final)=10.625 | 3330.9 samples/s | 52.0 steps/s
[Step=94550 Epoch=178.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.439 | L2-Norm(final)=10.627 | 3560.1 samples/s | 55.6 steps/s
[Step=94600 Epoch=178.3] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.434 | L2-Norm(final)=10.629 | 3707.5 samples/s | 57.9 steps/s
[Step=94650 Epoch=178.4] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.430 | L2-Norm(final)=10.630 | 3716.6 samples/s | 58.1 steps/s
[Step=94700 Epoch=178.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.426 | L2-Norm(final)=10.632 | 3730.2 samples/s | 58.3 steps/s
[Step=94750 Epoch=178.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.421 | L2-Norm(final)=10.633 | 3711.8 samples/s | 58.0 steps/s
[Step=94800 Epoch=178.7] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.416 | L2-Norm(final)=10.635 | 3754.9 samples/s | 58.7 steps/s
[Step=94850 Epoch=178.8] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.411 | L2-Norm(final)=10.636 | 3715.4 samples/s | 58.1 steps/s
[Step=94900 Epoch=178.9] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.406 | L2-Norm(final)=10.637 | 3759.9 samples/s | 58.7 steps/s
[Step=94950 Epoch=179.0] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.401 | L2-Norm(final)=10.639 | 3734.4 samples/s | 58.4 steps/s
[Step=95000 Epoch=179.1] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.396 | L2-Norm(final)=10.640 | 3802.0 samples/s | 59.4 steps/s
[Step=95050 Epoch=179.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.390 | L2-Norm(final)=10.641 | 1660.4 samples/s | 25.9 steps/s
[Step=95100 Epoch=179.3] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.385 | L2-Norm(final)=10.642 | 3708.5 samples/s | 57.9 steps/s
[Step=95150 Epoch=179.4] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.380 | L2-Norm(final)=10.644 | 3672.8 samples/s | 57.4 steps/s
[Step=95200 Epoch=179.5] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.374 | L2-Norm(final)=10.645 | 3696.0 samples/s | 57.7 steps/s
[Step=95250 Epoch=179.5] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.369 | L2-Norm(final)=10.646 | 3785.0 samples/s | 59.1 steps/s
[Step=95300 Epoch=179.6] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.363 | L2-Norm(final)=10.647 | 3714.3 samples/s | 58.0 steps/s
[Step=95350 Epoch=179.7] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.357 | L2-Norm(final)=10.649 | 3761.0 samples/s | 58.8 steps/s
[Step=95400 Epoch=179.8] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.352 | L2-Norm(final)=10.650 | 3720.1 samples/s | 58.1 steps/s
[Step=95450 Epoch=179.9] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.346 | L2-Norm(final)=10.651 | 3768.5 samples/s | 58.9 steps/s
[Step=95500 Epoch=180.0] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.340 | L2-Norm(final)=10.652 | 3711.8 samples/s | 58.0 steps/s
[Step=95550 Epoch=180.1] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.334 | L2-Norm(final)=10.653 | 4688.3 samples/s | 73.3 steps/s
[Step=95600 Epoch=180.2] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.328 | L2-Norm(final)=10.655 | 1506.6 samples/s | 23.5 steps/s
[Step=95650 Epoch=180.3] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=10.656 | 3692.6 samples/s | 57.7 steps/s
[Step=95700 Epoch=180.4] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.316 | L2-Norm(final)=10.657 | 3701.0 samples/s | 57.8 steps/s
[Step=95750 Epoch=180.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.310 | L2-Norm(final)=10.658 | 3731.6 samples/s | 58.3 steps/s
[Step=95800 Epoch=180.6] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.303 | L2-Norm(final)=10.660 | 3671.4 samples/s | 57.4 steps/s
[Step=95850 Epoch=180.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.297 | L2-Norm(final)=10.661 | 3684.7 samples/s | 57.6 steps/s
[Step=95900 Epoch=180.8] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.291 | L2-Norm(final)=10.662 | 3716.1 samples/s | 58.1 steps/s
[Step=95950 Epoch=180.9] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.284 | L2-Norm(final)=10.664 | 3728.9 samples/s | 58.3 steps/s
[Step=96000 Epoch=181.0] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.278 | L2-Norm(final)=10.665 | 3698.8 samples/s | 57.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step96000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05455 | acc=0.9712 | tpr=0.9795 | fpr=0.0468 | 3569.4 samples/s | 13.9 steps/s
Avg test loss: 0.05595, Avg test acc: 0.97047, Avg tpr: 0.97908, Avg fpr: 0.04846, total FA: 378

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.70447 | acc=0.3080 | tpr=0.0171 | fpr=0.0605 | 3590.8 samples/s | 14.0 steps/s
Avg test loss: 4.70496, Avg test acc: 0.30579, Avg tpr: 0.01690, Avg fpr: 0.05884, total FA: 459

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=4.91342 | acc=0.1195 | tpr=0.8097 | fpr=0.8929 | 3577.0 samples/s | 14.0 steps/s
[Step= 100] | Loss=4.91375 | acc=0.1221 | tpr=0.7953 | fpr=0.8904 | 6787.6 samples/s | 26.5 steps/s
[Step= 150] | Loss=4.92107 | acc=0.1209 | tpr=0.7939 | fpr=0.8915 | 6763.5 samples/s | 26.4 steps/s
[Step= 200] | Loss=4.90962 | acc=0.1206 | tpr=0.7923 | fpr=0.8916 | 6852.9 samples/s | 26.8 steps/s
[Step= 250] | Loss=4.91478 | acc=0.1204 | tpr=0.7965 | fpr=0.8919 | 6867.7 samples/s | 26.8 steps/s
[Step= 300] | Loss=4.91316 | acc=0.1208 | tpr=0.8036 | fpr=0.8916 | 6889.1 samples/s | 26.9 steps/s
[Step= 350] | Loss=4.91367 | acc=0.1205 | tpr=0.8115 | fpr=0.8921 | 6752.6 samples/s | 26.4 steps/s
[Step= 400] | Loss=4.91893 | acc=0.1201 | tpr=0.8096 | fpr=0.8924 | 6977.7 samples/s | 27.3 steps/s
[Step= 450] | Loss=4.92247 | acc=0.1199 | tpr=0.8126 | fpr=0.8927 | 6707.9 samples/s | 26.2 steps/s
[Step= 500] | Loss=4.92239 | acc=0.1201 | tpr=0.8123 | fpr=0.8924 | 6857.6 samples/s | 26.8 steps/s
[Step= 550] | Loss=4.92207 | acc=0.1202 | tpr=0.8138 | fpr=0.8924 | 12320.5 samples/s | 48.1 steps/s
Avg test loss: 4.92262, Avg test acc: 0.12012, Avg tpr: 0.81339, Avg fpr: 0.89249, total FA: 123920

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09861 | acc=0.9808 | tpr=0.9690 | fpr=0.0190 | 3598.0 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.10372 | acc=0.9798 | tpr=0.9701 | fpr=0.0200 | 7072.3 samples/s | 27.6 steps/s
[Step= 150] | Loss=0.10479 | acc=0.9792 | tpr=0.9669 | fpr=0.0206 | 6786.0 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.10657 | acc=0.9794 | tpr=0.9716 | fpr=0.0205 | 6781.8 samples/s | 26.5 steps/s
[Step= 250] | Loss=0.10537 | acc=0.9792 | tpr=0.9703 | fpr=0.0206 | 6876.8 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.10728 | acc=0.9788 | tpr=0.9687 | fpr=0.0210 | 6794.9 samples/s | 26.5 steps/s
[Step= 350] | Loss=0.10744 | acc=0.9787 | tpr=0.9687 | fpr=0.0211 | 6942.4 samples/s | 27.1 steps/s
[Step= 400] | Loss=0.10801 | acc=0.9786 | tpr=0.9688 | fpr=0.0212 | 6741.4 samples/s | 26.3 steps/s
[Step= 450] | Loss=0.11039 | acc=0.9782 | tpr=0.9669 | fpr=0.0216 | 7025.9 samples/s | 27.4 steps/s
[Step= 500] | Loss=0.10987 | acc=0.9783 | tpr=0.9674 | fpr=0.0215 | 6948.8 samples/s | 27.1 steps/s
[Step= 550] | Loss=0.10930 | acc=0.9785 | tpr=0.9670 | fpr=0.0213 | 11941.3 samples/s | 46.6 steps/s
Avg test loss: 0.10908, Avg test acc: 0.97849, Avg tpr: 0.96712, Avg fpr: 0.02130, total FA: 2958

server round 48/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=93.7] | Loss=0.02583 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.413 | L2-Norm(final)=16.318 | 3194.9 samples/s | 49.9 steps/s
[Step=96050 Epoch=93.8] | Loss=0.01449 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.418 | L2-Norm(final)=16.321 | 4265.3 samples/s | 66.6 steps/s
[Step=96100 Epoch=93.8] | Loss=0.01322 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.424 | L2-Norm(final)=16.325 | 4324.8 samples/s | 67.6 steps/s
[Step=96150 Epoch=93.9] | Loss=0.01275 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.431 | L2-Norm(final)=16.330 | 4337.1 samples/s | 67.8 steps/s
[Step=96200 Epoch=93.9] | Loss=0.01262 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.436 | L2-Norm(final)=16.334 | 4321.2 samples/s | 67.5 steps/s
[Step=96250 Epoch=94.0] | Loss=0.01229 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.442 | L2-Norm(final)=16.339 | 4352.8 samples/s | 68.0 steps/s
[Step=96300 Epoch=94.0] | Loss=0.01245 | Reg=0.00055 | acc=0.9844 | L2-Norm=7.447 | L2-Norm(final)=16.343 | 4281.5 samples/s | 66.9 steps/s
[Step=96350 Epoch=94.1] | Loss=0.01244 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.452 | L2-Norm(final)=16.347 | 4391.4 samples/s | 68.6 steps/s
[Step=96400 Epoch=94.1] | Loss=0.01197 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.457 | L2-Norm(final)=16.351 | 4444.7 samples/s | 69.4 steps/s
[Step=96450 Epoch=94.2] | Loss=0.01187 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.463 | L2-Norm(final)=16.355 | 4333.1 samples/s | 67.7 steps/s
[Step=96500 Epoch=94.2] | Loss=0.01221 | Reg=0.00056 | acc=1.0000 | L2-Norm=7.468 | L2-Norm(final)=16.359 | 4334.5 samples/s | 67.7 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=94.2] | Loss=0.01167 | Reg=0.00056 | acc=0.9844 | L2-Norm=7.516 | L2-Norm(final)=16.397 | 3376.9 samples/s | 52.8 steps/s
[Step=96550 Epoch=94.3] | Loss=0.00950 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.522 | L2-Norm(final)=16.400 | 3578.3 samples/s | 55.9 steps/s
[Step=96600 Epoch=94.3] | Loss=0.01156 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.527 | L2-Norm(final)=16.403 | 3821.7 samples/s | 59.7 steps/s
[Step=96650 Epoch=94.4] | Loss=0.01208 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.533 | L2-Norm(final)=16.406 | 3839.8 samples/s | 60.0 steps/s
[Step=96700 Epoch=94.4] | Loss=0.01228 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.539 | L2-Norm(final)=16.409 | 3957.6 samples/s | 61.8 steps/s
[Step=96750 Epoch=94.5] | Loss=0.01190 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.545 | L2-Norm(final)=16.412 | 3891.5 samples/s | 60.8 steps/s
[Step=96800 Epoch=94.5] | Loss=0.01188 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.551 | L2-Norm(final)=16.415 | 3934.1 samples/s | 61.5 steps/s
[Step=96850 Epoch=94.6] | Loss=0.01169 | Reg=0.00057 | acc=0.9688 | L2-Norm=7.557 | L2-Norm(final)=16.418 | 3913.3 samples/s | 61.1 steps/s
[Step=96900 Epoch=94.6] | Loss=0.01144 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.563 | L2-Norm(final)=16.422 | 3922.6 samples/s | 61.3 steps/s
[Step=96950 Epoch=94.7] | Loss=0.01147 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.568 | L2-Norm(final)=16.425 | 3910.0 samples/s | 61.1 steps/s
[Step=97000 Epoch=94.7] | Loss=0.01134 | Reg=0.00057 | acc=0.9844 | L2-Norm=7.574 | L2-Norm(final)=16.428 | 3921.0 samples/s | 61.3 steps/s
[Step=97050 Epoch=94.8] | Loss=0.01138 | Reg=0.00057 | acc=1.0000 | L2-Norm=7.579 | L2-Norm(final)=16.431 | 3894.9 samples/s | 60.9 steps/s
[Step=97100 Epoch=94.8] | Loss=0.01138 | Reg=0.00058 | acc=0.9688 | L2-Norm=7.584 | L2-Norm(final)=16.434 | 3953.6 samples/s | 61.8 steps/s
[Step=97150 Epoch=94.9] | Loss=0.01133 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.588 | L2-Norm(final)=16.437 | 3949.5 samples/s | 61.7 steps/s
[Step=97200 Epoch=94.9] | Loss=0.01127 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.593 | L2-Norm(final)=16.440 | 3897.2 samples/s | 60.9 steps/s
[Step=97250 Epoch=94.9] | Loss=0.01130 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.598 | L2-Norm(final)=16.443 | 3965.2 samples/s | 62.0 steps/s
[Step=97300 Epoch=95.0] | Loss=0.01136 | Reg=0.00058 | acc=0.9844 | L2-Norm=7.602 | L2-Norm(final)=16.445 | 3912.9 samples/s | 61.1 steps/s
[Step=97350 Epoch=95.0] | Loss=0.01134 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.606 | L2-Norm(final)=16.448 | 3904.7 samples/s | 61.0 steps/s
[Step=97400 Epoch=95.1] | Loss=0.01128 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.611 | L2-Norm(final)=16.451 | 3955.9 samples/s | 61.8 steps/s
[Step=97450 Epoch=95.1] | Loss=0.01124 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.615 | L2-Norm(final)=16.453 | 3929.0 samples/s | 61.4 steps/s
[Step=97500 Epoch=95.2] | Loss=0.01114 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.619 | L2-Norm(final)=16.456 | 4221.8 samples/s | 66.0 steps/s
[Step=97550 Epoch=95.2] | Loss=0.01119 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.623 | L2-Norm(final)=16.459 | 1642.7 samples/s | 25.7 steps/s
[Step=97600 Epoch=95.3] | Loss=0.01104 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.627 | L2-Norm(final)=16.461 | 3911.3 samples/s | 61.1 steps/s
[Step=97650 Epoch=95.3] | Loss=0.01094 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.631 | L2-Norm(final)=16.464 | 3868.2 samples/s | 60.4 steps/s
[Step=97700 Epoch=95.4] | Loss=0.01090 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.635 | L2-Norm(final)=16.466 | 3923.1 samples/s | 61.3 steps/s
[Step=97750 Epoch=95.4] | Loss=0.01081 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.639 | L2-Norm(final)=16.469 | 3973.1 samples/s | 62.1 steps/s
[Step=97800 Epoch=95.5] | Loss=0.01076 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.643 | L2-Norm(final)=16.471 | 3918.1 samples/s | 61.2 steps/s
[Step=97850 Epoch=95.5] | Loss=0.01070 | Reg=0.00058 | acc=1.0000 | L2-Norm=7.646 | L2-Norm(final)=16.473 | 3907.0 samples/s | 61.0 steps/s
[Step=97900 Epoch=95.6] | Loss=0.01063 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.650 | L2-Norm(final)=16.476 | 3934.7 samples/s | 61.5 steps/s
[Step=97950 Epoch=95.6] | Loss=0.01061 | Reg=0.00059 | acc=1.0000 | L2-Norm=7.654 | L2-Norm(final)=16.478 | 3995.3 samples/s | 62.4 steps/s
[Step=98000 Epoch=95.7] | Loss=0.01056 | Reg=0.00059 | acc=0.9844 | L2-Norm=7.657 | L2-Norm(final)=16.480 | 3910.6 samples/s | 61.1 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step98000.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=96001 Epoch=181.0] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.413 | L2-Norm(final)=10.706 | 3253.1 samples/s | 50.8 steps/s
[Step=96050 Epoch=181.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.407 | L2-Norm(final)=10.711 | 3844.1 samples/s | 60.1 steps/s
[Step=96100 Epoch=181.1] | Loss=0.00002 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.403 | L2-Norm(final)=10.717 | 4011.0 samples/s | 62.7 steps/s
[Step=96150 Epoch=181.2] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.399 | L2-Norm(final)=10.722 | 4108.5 samples/s | 64.2 steps/s
[Step=96200 Epoch=181.3] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.396 | L2-Norm(final)=10.727 | 4075.0 samples/s | 63.7 steps/s
[Step=96250 Epoch=181.4] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.392 | L2-Norm(final)=10.732 | 4086.4 samples/s | 63.8 steps/s
[Step=96300 Epoch=181.5] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.389 | L2-Norm(final)=10.736 | 4046.2 samples/s | 63.2 steps/s
[Step=96350 Epoch=181.6] | Loss=0.00001 | Reg=0.00055 | acc=1.0000 | L2-Norm=7.385 | L2-Norm(final)=10.741 | 4131.6 samples/s | 64.6 steps/s
[Step=96400 Epoch=181.7] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.382 | L2-Norm(final)=10.745 | 4055.8 samples/s | 63.4 steps/s
[Step=96450 Epoch=181.8] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.378 | L2-Norm(final)=10.749 | 4067.8 samples/s | 63.6 steps/s
[Step=96500 Epoch=181.9] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.375 | L2-Norm(final)=10.754 | 4150.0 samples/s | 64.8 steps/s
All layers training...
LR=0.00006, len=1
[Step=96501 Epoch=181.9] | Loss=0.00000 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.340 | L2-Norm(final)=10.795 | 3136.3 samples/s | 49.0 steps/s
[Step=96550 Epoch=182.0] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.332 | L2-Norm(final)=10.799 | 3580.1 samples/s | 55.9 steps/s
[Step=96600 Epoch=182.1] | Loss=0.00001 | Reg=0.00054 | acc=1.0000 | L2-Norm=7.322 | L2-Norm(final)=10.802 | 3677.7 samples/s | 57.5 steps/s
[Step=96650 Epoch=182.2] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.312 | L2-Norm(final)=10.806 | 3661.6 samples/s | 57.2 steps/s
[Step=96700 Epoch=182.3] | Loss=0.00001 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.301 | L2-Norm(final)=10.808 | 3691.9 samples/s | 57.7 steps/s
[Step=96750 Epoch=182.4] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.290 | L2-Norm(final)=10.811 | 3703.3 samples/s | 57.9 steps/s
[Step=96800 Epoch=182.5] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.278 | L2-Norm(final)=10.814 | 3693.4 samples/s | 57.7 steps/s
[Step=96850 Epoch=182.6] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.267 | L2-Norm(final)=10.816 | 3745.9 samples/s | 58.5 steps/s
[Step=96900 Epoch=182.7] | Loss=0.00000 | Reg=0.00053 | acc=1.0000 | L2-Norm=7.256 | L2-Norm(final)=10.819 | 3664.0 samples/s | 57.3 steps/s
[Step=96950 Epoch=182.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.244 | L2-Norm(final)=10.822 | 3739.9 samples/s | 58.4 steps/s
[Step=97000 Epoch=182.8] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.233 | L2-Norm(final)=10.824 | 3726.7 samples/s | 58.2 steps/s
[Step=97050 Epoch=182.9] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.222 | L2-Norm(final)=10.827 | 1637.3 samples/s | 25.6 steps/s
[Step=97100 Epoch=183.0] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.210 | L2-Norm(final)=10.830 | 3695.5 samples/s | 57.7 steps/s
[Step=97150 Epoch=183.1] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.198 | L2-Norm(final)=10.832 | 3713.4 samples/s | 58.0 steps/s
[Step=97200 Epoch=183.2] | Loss=0.00000 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.187 | L2-Norm(final)=10.835 | 3745.5 samples/s | 58.5 steps/s
[Step=97250 Epoch=183.3] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.175 | L2-Norm(final)=10.837 | 3651.6 samples/s | 57.1 steps/s
[Step=97300 Epoch=183.4] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.163 | L2-Norm(final)=10.840 | 3721.5 samples/s | 58.1 steps/s
[Step=97350 Epoch=183.5] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.151 | L2-Norm(final)=10.842 | 3693.1 samples/s | 57.7 steps/s
[Step=97400 Epoch=183.6] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.140 | L2-Norm(final)=10.845 | 3711.8 samples/s | 58.0 steps/s
[Step=97450 Epoch=183.7] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.128 | L2-Norm(final)=10.848 | 3717.0 samples/s | 58.1 steps/s
[Step=97500 Epoch=183.8] | Loss=0.00000 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.116 | L2-Norm(final)=10.851 | 3692.4 samples/s | 57.7 steps/s
[Step=97550 Epoch=183.9] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.104 | L2-Norm(final)=10.853 | 4678.1 samples/s | 73.1 steps/s
[Step=97600 Epoch=184.0] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.092 | L2-Norm(final)=10.856 | 1549.4 samples/s | 24.2 steps/s
[Step=97650 Epoch=184.1] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=10.859 | 3678.3 samples/s | 57.5 steps/s
[Step=97700 Epoch=184.2] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.069 | L2-Norm(final)=10.862 | 3719.4 samples/s | 58.1 steps/s
[Step=97750 Epoch=184.3] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.057 | L2-Norm(final)=10.865 | 3730.9 samples/s | 58.3 steps/s
[Step=97800 Epoch=184.4] | Loss=0.00000 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.045 | L2-Norm(final)=10.868 | 3747.6 samples/s | 58.6 steps/s
[Step=97850 Epoch=184.4] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.033 | L2-Norm(final)=10.872 | 3683.8 samples/s | 57.6 steps/s
[Step=97900 Epoch=184.5] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.021 | L2-Norm(final)=10.875 | 3705.0 samples/s | 57.9 steps/s
[Step=97950 Epoch=184.6] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=7.009 | L2-Norm(final)=10.878 | 3743.2 samples/s | 58.5 steps/s
[Step=98000 Epoch=184.7] | Loss=0.00000 | Reg=0.00049 | acc=1.0000 | L2-Norm=6.998 | L2-Norm(final)=10.882 | 3707.9 samples/s | 57.9 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step98000.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05499 | acc=0.9712 | tpr=0.9799 | fpr=0.0478 | 3635.2 samples/s | 14.2 steps/s
Avg test loss: 0.05565, Avg test acc: 0.97067, Avg tpr: 0.97954, Avg fpr: 0.04884, total FA: 381

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.95261 | acc=0.3090 | tpr=0.0145 | fpr=0.0515 | 3662.7 samples/s | 14.3 steps/s
Avg test loss: 4.95397, Avg test acc: 0.30643, Avg tpr: 0.01364, Avg fpr: 0.04961, total FA: 387

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=5.04880 | acc=0.1141 | tpr=0.8142 | fpr=0.8984 | 3669.4 samples/s | 14.3 steps/s
[Step= 100] | Loss=5.05196 | acc=0.1175 | tpr=0.8060 | fpr=0.8953 | 6747.9 samples/s | 26.4 steps/s
[Step= 150] | Loss=5.05844 | acc=0.1162 | tpr=0.7997 | fpr=0.8964 | 7005.3 samples/s | 27.4 steps/s
[Step= 200] | Loss=5.04651 | acc=0.1161 | tpr=0.7934 | fpr=0.8962 | 6726.1 samples/s | 26.3 steps/s
[Step= 250] | Loss=5.05141 | acc=0.1158 | tpr=0.7991 | fpr=0.8966 | 7036.8 samples/s | 27.5 steps/s
[Step= 300] | Loss=5.04977 | acc=0.1164 | tpr=0.8015 | fpr=0.8960 | 6743.3 samples/s | 26.3 steps/s
[Step= 350] | Loss=5.05053 | acc=0.1159 | tpr=0.8071 | fpr=0.8966 | 6876.4 samples/s | 26.9 steps/s
[Step= 400] | Loss=5.05630 | acc=0.1157 | tpr=0.8069 | fpr=0.8969 | 6936.2 samples/s | 27.1 steps/s
[Step= 450] | Loss=5.05958 | acc=0.1153 | tpr=0.8116 | fpr=0.8973 | 6711.3 samples/s | 26.2 steps/s
[Step= 500] | Loss=5.05984 | acc=0.1154 | tpr=0.8115 | fpr=0.8972 | 6923.9 samples/s | 27.0 steps/s
[Step= 550] | Loss=5.05976 | acc=0.1156 | tpr=0.8130 | fpr=0.8971 | 12390.9 samples/s | 48.4 steps/s
Avg test loss: 5.06015, Avg test acc: 0.11549, Avg tpr: 0.81260, Avg fpr: 0.89718, total FA: 124572

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.09428 | acc=0.9812 | tpr=0.9690 | fpr=0.0185 | 3622.1 samples/s | 14.1 steps/s
[Step= 100] | Loss=0.09958 | acc=0.9804 | tpr=0.9701 | fpr=0.0194 | 6993.0 samples/s | 27.3 steps/s
[Step= 150] | Loss=0.10081 | acc=0.9798 | tpr=0.9697 | fpr=0.0200 | 6791.0 samples/s | 26.5 steps/s
[Step= 200] | Loss=0.10230 | acc=0.9800 | tpr=0.9738 | fpr=0.0199 | 6899.6 samples/s | 27.0 steps/s
[Step= 250] | Loss=0.10123 | acc=0.9799 | tpr=0.9712 | fpr=0.0200 | 6920.8 samples/s | 27.0 steps/s
[Step= 300] | Loss=0.10309 | acc=0.9795 | tpr=0.9702 | fpr=0.0203 | 6907.8 samples/s | 27.0 steps/s
[Step= 350] | Loss=0.10335 | acc=0.9794 | tpr=0.9706 | fpr=0.0205 | 6663.5 samples/s | 26.0 steps/s
[Step= 400] | Loss=0.10388 | acc=0.9793 | tpr=0.9694 | fpr=0.0205 | 6708.7 samples/s | 26.2 steps/s
[Step= 450] | Loss=0.10617 | acc=0.9790 | tpr=0.9684 | fpr=0.0208 | 6839.2 samples/s | 26.7 steps/s
[Step= 500] | Loss=0.10565 | acc=0.9791 | tpr=0.9683 | fpr=0.0207 | 6875.5 samples/s | 26.9 steps/s
[Step= 550] | Loss=0.10511 | acc=0.9792 | tpr=0.9678 | fpr=0.0206 | 12170.5 samples/s | 47.5 steps/s
Avg test loss: 0.10490, Avg test acc: 0.97925, Avg tpr: 0.96791, Avg fpr: 0.02054, total FA: 2852

server round 49/50

clients selected: [0 1]

Train client 0: client_asml1_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=95.7] | Loss=0.02385 | Reg=0.00051 | acc=0.9688 | L2-Norm=7.133 | L2-Norm(final)=16.550 | 3266.9 samples/s | 51.0 steps/s
[Step=98050 Epoch=95.7] | Loss=0.01952 | Reg=0.00051 | acc=0.9844 | L2-Norm=7.142 | L2-Norm(final)=16.553 | 4104.3 samples/s | 64.1 steps/s
[Step=98100 Epoch=95.8] | Loss=0.01880 | Reg=0.00051 | acc=0.9844 | L2-Norm=7.149 | L2-Norm(final)=16.559 | 4251.2 samples/s | 66.4 steps/s
[Step=98150 Epoch=95.8] | Loss=0.01842 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.157 | L2-Norm(final)=16.564 | 4326.4 samples/s | 67.6 steps/s
[Step=98200 Epoch=95.9] | Loss=0.01910 | Reg=0.00051 | acc=0.9844 | L2-Norm=7.165 | L2-Norm(final)=16.570 | 4297.3 samples/s | 67.1 steps/s
[Step=98250 Epoch=95.9] | Loss=0.01855 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.172 | L2-Norm(final)=16.574 | 4361.5 samples/s | 68.1 steps/s
[Step=98300 Epoch=96.0] | Loss=0.01825 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.178 | L2-Norm(final)=16.579 | 4272.5 samples/s | 66.8 steps/s
[Step=98350 Epoch=96.0] | Loss=0.01777 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.185 | L2-Norm(final)=16.584 | 4359.7 samples/s | 68.1 steps/s
[Step=98400 Epoch=96.1] | Loss=0.01766 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.191 | L2-Norm(final)=16.588 | 4277.2 samples/s | 66.8 steps/s
[Step=98450 Epoch=96.1] | Loss=0.01749 | Reg=0.00052 | acc=1.0000 | L2-Norm=7.197 | L2-Norm(final)=16.593 | 4359.2 samples/s | 68.1 steps/s
[Step=98500 Epoch=96.2] | Loss=0.01719 | Reg=0.00052 | acc=0.9688 | L2-Norm=7.203 | L2-Norm(final)=16.597 | 4308.7 samples/s | 67.3 steps/s
Client model saved at models/model-a1i1_sr1.0/client_asml1_0/client_state-step98500.h5

Train client 1: client_iccad2012_0
Restoring client from server.
Local layers training...
Not training conv1_1
Not training conv1_2
Not training conv2_1
Not training conv2_2
LR=0.00006, len=1
[Step=98001 Epoch=184.7] | Loss=0.00004 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.133 | L2-Norm(final)=10.986 | 3333.3 samples/s | 52.1 steps/s
[Step=98050 Epoch=184.8] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.124 | L2-Norm(final)=10.995 | 3775.5 samples/s | 59.0 steps/s
[Step=98100 Epoch=184.9] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.118 | L2-Norm(final)=11.005 | 4172.2 samples/s | 65.2 steps/s
[Step=98150 Epoch=185.0] | Loss=0.00001 | Reg=0.00051 | acc=1.0000 | L2-Norm=7.111 | L2-Norm(final)=11.013 | 4001.1 samples/s | 62.5 steps/s
[Step=98200 Epoch=185.1] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.105 | L2-Norm(final)=11.021 | 4057.2 samples/s | 63.4 steps/s
[Step=98250 Epoch=185.2] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.099 | L2-Norm(final)=11.029 | 4114.0 samples/s | 64.3 steps/s
[Step=98300 Epoch=185.3] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.093 | L2-Norm(final)=11.036 | 4110.7 samples/s | 64.2 steps/s
[Step=98350 Epoch=185.4] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.087 | L2-Norm(final)=11.043 | 4161.4 samples/s | 65.0 steps/s
[Step=98400 Epoch=185.5] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.081 | L2-Norm(final)=11.050 | 4098.5 samples/s | 64.0 steps/s
[Step=98450 Epoch=185.6] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.076 | L2-Norm(final)=11.057 | 4097.2 samples/s | 64.0 steps/s
[Step=98500 Epoch=185.7] | Loss=0.00001 | Reg=0.00050 | acc=1.0000 | L2-Norm=7.071 | L2-Norm(final)=11.063 | 4144.5 samples/s | 64.8 steps/s
Client model saved at models/model-a1i1_sr1.0/client_iccad2012_0/client_state-step98500.h5

Start Fed Avg...
Merging layer: conv1_1.0
Merging layer: conv1_2.0
Merging layer: conv2_1.0
Merging layer: conv2_2.0
Merging layer: fc1.0
Merging layer: final_fc

Testing client_asml1_0 on asml1
[Step=  50] | Loss=0.05590 | acc=0.9659 | tpr=0.9666 | fpr=0.0354 | 3647.4 samples/s | 14.2 steps/s
Avg test loss: 0.05670, Avg test acc: 0.96526, Avg tpr: 0.96596, Avg fpr: 0.03628, total FA: 283

Testing client_iccad2012_0 on asml1
[Step=  50] | Loss=4.56492 | acc=0.3091 | tpr=0.0145 | fpr=0.0510 | 3607.5 samples/s | 14.1 steps/s
Avg test loss: 4.56595, Avg test acc: 0.30684, Avg tpr: 0.01422, Avg fpr: 0.04961, total FA: 387

Testing client_asml1_0 on iccad2012
[Step=  50] | Loss=3.44312 | acc=0.1459 | tpr=0.7699 | fpr=0.8654 | 3612.0 samples/s | 14.1 steps/s
[Step= 100] | Loss=3.44994 | acc=0.1478 | tpr=0.7612 | fpr=0.8636 | 6782.5 samples/s | 26.5 steps/s
[Step= 150] | Loss=3.45548 | acc=0.1460 | tpr=0.7550 | fpr=0.8652 | 7074.3 samples/s | 27.6 steps/s
[Step= 200] | Loss=3.44652 | acc=0.1455 | tpr=0.7519 | fpr=0.8656 | 6737.3 samples/s | 26.3 steps/s
[Step= 250] | Loss=3.45028 | acc=0.1450 | tpr=0.7598 | fpr=0.8662 | 6809.5 samples/s | 26.6 steps/s
[Step= 300] | Loss=3.44858 | acc=0.1451 | tpr=0.7622 | fpr=0.8661 | 7051.4 samples/s | 27.5 steps/s
[Step= 350] | Loss=3.44853 | acc=0.1446 | tpr=0.7646 | fpr=0.8666 | 6904.6 samples/s | 27.0 steps/s
[Step= 400] | Loss=3.45180 | acc=0.1445 | tpr=0.7615 | fpr=0.8668 | 6705.8 samples/s | 26.2 steps/s
[Step= 450] | Loss=3.45402 | acc=0.1442 | tpr=0.7668 | fpr=0.8671 | 7062.5 samples/s | 27.6 steps/s
[Step= 500] | Loss=3.45306 | acc=0.1443 | tpr=0.7678 | fpr=0.8669 | 6509.5 samples/s | 25.4 steps/s
[Step= 550] | Loss=3.45273 | acc=0.1445 | tpr=0.7700 | fpr=0.8669 | 12356.0 samples/s | 48.3 steps/s
Avg test loss: 3.45313, Avg test acc: 0.14442, Avg tpr: 0.76981, Avg fpr: 0.86695, total FA: 120374

Testing client_iccad2012_0 on iccad2012
[Step=  50] | Loss=0.08771 | acc=0.9820 | tpr=0.9646 | fpr=0.0177 | 3694.5 samples/s | 14.4 steps/s
[Step= 100] | Loss=0.09254 | acc=0.9809 | tpr=0.9659 | fpr=0.0188 | 6676.5 samples/s | 26.1 steps/s
[Step= 150] | Loss=0.09327 | acc=0.9802 | tpr=0.9625 | fpr=0.0195 | 6886.5 samples/s | 26.9 steps/s
[Step= 200] | Loss=0.09480 | acc=0.9804 | tpr=0.9683 | fpr=0.0194 | 6875.3 samples/s | 26.9 steps/s
[Step= 250] | Loss=0.09378 | acc=0.9803 | tpr=0.9668 | fpr=0.0194 | 6895.7 samples/s | 26.9 steps/s
[Step= 300] | Loss=0.09543 | acc=0.9800 | tpr=0.9658 | fpr=0.0197 | 6915.0 samples/s | 27.0 steps/s
[Step= 350] | Loss=0.09544 | acc=0.9799 | tpr=0.9662 | fpr=0.0199 | 7164.9 samples/s | 28.0 steps/s
[Step= 400] | Loss=0.09587 | acc=0.9797 | tpr=0.9650 | fpr=0.0200 | 6770.1 samples/s | 26.4 steps/s
[Step= 450] | Loss=0.09802 | acc=0.9794 | tpr=0.9630 | fpr=0.0203 | 6910.1 samples/s | 27.0 steps/s
[Step= 500] | Loss=0.09755 | acc=0.9794 | tpr=0.9639 | fpr=0.0203 | 6793.9 samples/s | 26.5 steps/s
[Step= 550] | Loss=0.09709 | acc=0.9796 | tpr=0.9638 | fpr=0.0201 | 12459.4 samples/s | 48.7 steps/s
Avg test loss: 0.09689, Avg test acc: 0.97962, Avg tpr: 0.96395, Avg fpr: 0.02009, total FA: 2790
